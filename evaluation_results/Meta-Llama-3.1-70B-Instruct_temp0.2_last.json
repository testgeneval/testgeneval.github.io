{"raw_generations": {"sample_200": ["def test_attachment_filename_encoding(self):\n    \"\"\"\n    Regression test for #14964\n    \"\"\"\n    headers = {\"Date\": \"Fri, 09 Nov 2001 01:08:47 -0000\", \"Message-ID\": \"foo\"}\n    subject, from_email, to = 'hello', 'from@example.com', 'to@example.com'\n    content = 'This is the message.'\n    msg = EmailMessage(subject, content, from_email, [to], headers=headers)\n    # Unicode in file name\n    msg.attach(\"une pi\u00e8ce jointe.pdf\", b\"%PDF-1.4.%...\", mimetype=\"application/pdf\")\n    msg_bytes = msg.message().as_bytes()\n    message = message_from_bytes(msg_bytes)\n    payload = message.get_payload()\n    self.assertEqual(payload[1].get_filename(), 'une pi\u00e8ce jointe.pdf')\n    self.assertEqual(payload[1].get_content_disposition(), 'attachment; filename=\"une pi\u00e8ce jointe.pdf\"')\n"], "sample_1007": ["def test_subfactorial():\n    x = Symbol('x')\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True, nonnegative=True)\n\n    assert subfactorial(0) == 1\n    assert subfactorial(1) == 0\n    assert subfactorial(2) == 1\n    assert subfactorial(3) == 2\n    assert subfactorial(4) == 9\n    assert subfactorial(5) == 44\n\n    assert subfactorial(n).func == subfactorial\n    assert subfactorial(k).func == subfactorial\n\n    assert subfactorial(x).is_integer is None\n    assert subfactorial(n).is_integer is None\n    assert subfactorial(k).is_integer is True\n\n    assert subfactorial(x).is_nonnegative is None\n    assert subfactorial(n).is_nonnegative is None\n    assert subfactorial(k).is_nonnegative is True\n\n    assert subfactorial(x).is_odd is None\n    assert subfactorial(n).is_odd is None\n    assert subfactorial(k).is_odd is None\n\n    assert subfactorial(x).is_even is None\n    assert subfactorial(n).is_even is None\n    assert subfactorial(k).is_even is None\n\n    assert subfactorial(n).rewrite(uppergamma) == uppergamma(n + 1, -1)/S.Exp1\n"], "sample_55": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.s1 = Section.objects.create(name='Test section')\n        cls.a1 = Article.objects.create(\n            content='<p>Middle content</p>', date=datetime.datetime(2008, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a2 = Article.objects.create(\n            content='<p>Oldest content</p>', date=datetime.datetime(2000, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a3 = Article.objects.create(\n            content='<p>Newest content</p>', date=datetime.datetime(2009, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n"], "sample_744": ["def test_power_transformer_copy():\n    X = np.abs(X_2d)\n\n    pt = PowerTransformer(method='box-cox', copy=True)\n    X_trans = pt.fit_transform(X)\n    assert_true(X_trans is not X)\n\n    pt = PowerTransformer(method='box-cox', copy=False)\n    X_trans = pt.fit_transform(X)\n    assert_true(X_trans is X)\n"], "sample_908": ["def test_unparse_arguments():\n    source = \"def func(a: int, b: str = 'default', *args, c: int = 1, **kwargs): pass\"\n    expected = \"a: int, b: str = 'default', *args, c: int = 1, **kwargs\"\n    tree = ast.parse(source)\n    assert ast.unparse_arguments(tree.body[0].args) == expected\n"], "sample_1060": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n    assert not prntr.module_imports\n    assert prntr.doprint(pi) == 'math.pi'\n    assert prntr.module_imports == {'math': {'pi'}}\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n"], "sample_693": ["def test_unittest_subclass_with_metaclass(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n\n        class Meta(type):\n            pass\n\n        class MyTestCase(unittest.TestCase, metaclass=Meta):\n                pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n"], "sample_488": ["def test_lazy_model_operation_with_pending_operations(self):\n    \"\"\"\n    Tests apps.lazy_model_operation() when there are pending operations.\n    \"\"\"\n    model_classes = []\n    initial_pending = set(apps._pending_operations)\n\n        model_classes[:] = models\n\n    class LazyA(models.Model):\n        pass\n\n    # Test models appearing twice, and models appearing consecutively\n    model_keys = [\n        (\"apps\", model_name)\n        for model_name in [\"lazya\", \"lazyb\", \"lazyb\", \"lazyc\", \"lazya\"]\n    ]\n    apps.lazy_model_operation(test_func, *model_keys)\n\n    # LazyModelA shouldn't be waited on since it's already registered,\n    # and LazyModelC shouldn't be waited on until LazyModelB exists.\n    self.assertEqual(\n        set(apps._pending_operations) - initial_pending, {(\"apps\", \"lazyb\")}\n    )\n\n    # Add a pending operation for LazyModelB\n        model_classes.append(model)\n\n    apps._pending_operations[(\"apps\", \"lazyb\")].append(pending_operation)\n\n    class LazyB(models.Model):\n        pass\n\n    # The pending operation should be executed\n    self.assertEqual(model_classes, [LazyB])\n\n    # Now we are just waiting on LazyModelC.\n    self.assertEqual(\n        set(apps._pending_operations) - initial_pending, {(\"apps\", \"lazyc\")}\n    )\n\n    class LazyC(models.Model):\n        pass\n\n    # Everything should be loaded - make sure the callback was executed properly.\n    self.assertEqual(model_classes, [LazyA, LazyB, LazyB, LazyC, LazyA])\n"], "sample_572": ["    def test_cached_support_bivariate(self, rng):\n\n        x, y = rng.normal(0, 3, (2, 50))\n        kde = KDE()\n        kde.define_support(x, y)\n        _, support = kde(x[(x > -1) & (x < 1)], y[(y > -1) & (y < 1)])\n        assert_array_equal(support[0], kde.support[0])\n        assert_array_equal(support[1], kde.support[1])\n"], "sample_416": ["    def test_default_dbname(self):\n        self.assertEqual(\n            self.settings_to_cmd_args_env(\n                {\n                    \"USER\": \"someuser\",\n                    \"HOST\": \"somehost\",\n                    \"PORT\": \"444\",\n                }\n            ),\n            (\n                [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"],\n                None,\n            ),\n        )\n"], "sample_1114": ["def test_ComplexRegion_polar_intersect():\n    # Polar form\n    c1 = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)\n    c2 = ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    c3 = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi), polar=True)\n    c4 = ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n\n    p1 = Union(Interval(0, 1)*Interval(0, 2*S.Pi), Interval(0, 1)*Interval(0, S.Pi))\n    p2 = Union(Interval(0, oo)*Interval(0, S.Pi), Interval(0, oo)*Interval(S.Pi, 2*S.Pi))\n\n    assert c1.intersect(c2) == ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    assert c3.intersect(c4) == ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n\n    # Rectangular form\n    c5 = ComplexRegion(Interval(2, 5)*Interval(6, 9))\n    c6 = ComplexRegion(Interval(4, 6)*Interval(10, 12))\n    c7 = ComplexRegion(Interval(0, 10)*Interval(-10, 0))\n    c8 = ComplexRegion(Interval(12, 16)*Interval(14, 20))\n\n    p3 = Union(Interval(2, 5)*Interval(6, 9), Interval(4, 6)*Interval(10, 12))\n    p4 = Union(Interval(0, 10)*Interval(-10, 0), Interval(12, 16)*Interval(14, 20))\n\n    assert c5.intersect(c6) == ComplexRegion(Interval(4, 5)*Interval(10, 9))\n    assert c7.intersect(c8) == ComplexRegion(Interval(12, 10)*Interval(14, 0))\n\n    assert c1.intersect(Interval(2, 4)) == Intersection(c1, Interval(2, 4), evaluate=False)\n    assert c5.intersect(Interval(2, "], "sample_5": ["def test_parameter_copy(model):\n    if not HAS_SCIPY and model['class'] in SCIPY_MODELS:\n        pytest.skip()\n\n    m = model['class'](**model['parameters'])\n    for param_name in m.param_names:\n        param = getattr(m, param_name)\n        param_copy = param.copy()\n        assert param_copy.name == param.name\n        assert param_copy.default == param.default\n        assert param_copy.unit == param.unit\n        assert param_copy.value == param.value\n        assert param_copy.fixed == param.fixed\n        assert param_copy.tied == param.tied\n        assert param_copy.bounds == param.bounds\n        assert param_copy.min == param.min\n        assert param_copy.max == param.max\n        assert param_copy.prior == param.prior\n        assert param_copy.posterior == param.posterior\n        assert param_copy.std == param.std\n"], "sample_1029": ["def test_Predicate():\n    sT(S.is_even, \"Predicate('is_even')\")\n    sT(S.is_odd, \"Predicate('is_odd')\")\n    sT(S.is_prime, \"Predicate('is_prime')\")\n    sT(S.is_integer, \"Predicate('is_integer')\")\n    sT(S.is_rational, \"Predicate('is_rational')\")\n    sT(S.is_real, \"Predicate('is_real')\")\n    sT(S.is_complex, \"Predicate('is_complex')\")\n    sT(S.is_finite, \"Predicate('is_finite')\")\n    sT(S.is_infinite, \"Predicate('is_infinite')\")\n    sT(S.is_zero, \"Predicate('is_zero')\")\n    sT(S.is_nonzero, \"Predicate('is_nonzero')\")\n    sT(S.is_positive, \"Predicate('is_positive')\")\n    sT(S.is_negative, \"Predicate('is_negative')\")\n    sT(S.is_nonpositive, \"Predicate('is_nonpositive')\")\n    sT(S.is_nonnegative, \"Predicate('is_nonnegative')\")\n"], "sample_738": ["def test_vectorizer_stop_words_removal_with_custom_analyzer():\n    # Ensure that deleting the stop_words_ attribute doesn't affect transform\n    # with a custom analyzer\n\n        return [word for word in doc.split() if len(word) > 3]\n\n    fitted_vectorizers = (\n        TfidfVectorizer(analyzer=custom_analyzer).fit(JUNK_FOOD_DOCS),\n        CountVectorizer(preprocessor=strip_tags, analyzer=custom_analyzer).fit(JUNK_FOOD_DOCS),\n        CountVectorizer(strip_accents=strip_eacute, analyzer=custom_analyzer).fit(JUNK_FOOD_DOCS)\n    )\n\n    for vect in fitted_vectorizers:\n        vect_transform = vect.transform(JUNK_FOOD_DOCS).toarray()\n\n        vect.stop_words_ = None\n        stop_None_transform = vect.transform(JUNK_FOOD_DOCS).toarray()\n\n        delattr(vect, 'stop_words_')\n        stop_del_transform = vect.transform(JUNK_FOOD_DOCS).toarray()\n\n        assert_array_equal(stop_None_transform, vect_transform)\n        assert_array_equal(stop_del_transform, vect_transform)\n"], "sample_272": ["    def test_detect_soft_applied_with_renamed_model(self):\n        \"\"\"\n        Tests detection of initial migrations already having been applied\n        when the model has been renamed.\n        \"\"\"\n        state = {\"faked\": None}\n\n            state[\"faked\"] = fake\n        executor = MigrationExecutor(connection, progress_callback=fake_storer)\n        # Were the tables there before?\n        self.assertTableNotExists(\"migrations_author\")\n        self.assertTableNotExists(\"migrations_tribble\")\n        # Run it normally\n        self.assertEqual(\n            executor.migration_plan([(\"migrations\", \"0001_initial\")]),\n            [\n                (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n            ],\n        )\n        executor.migrate([(\"migrations\", \"0001_initial\")])\n        # Are the tables there now?\n        self.assertTableExists(\"migrations_author\")\n        self.assertTableExists(\"migrations_tribble\")\n        # We shouldn't have faked that one\n        self.assertIs(state[\"faked\"], False)\n        # Rebuild the graph to reflect the new DB state\n        executor.loader.build_graph()\n        # Fake-reverse that\n        executor.migrate([(\"migrations\", None)], fake=True)\n        # Are the tables still there?\n        self.assertTableExists(\"migrations_author\")\n        self.assertTableExists(\"migrations_tribble\")\n        # Make sure that was faked\n        self.assertIs(state[\"faked\"], True)\n        # Rename the model\n        with connection.schema_editor() as editor:\n            editor.execute(editor.sql_rename_table % {\n                \"table\": \"migrations_author\",\n                \"new_table\": \"migrations_new_author\",\n            })\n        # Finally, migrate forwards; this should fake-apply our initial migration\n        executor.loader.build_graph()\n        self.assertEqual(\n            executor.migration_plan([(\"migrations\", \"0001_initial\")]),\n            [\n                (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n            ],\n        )\n        # Applying the migration should raise a database level error\n        # because we haven't given the --fake-initial option\n        with self.assertRaises(DatabaseError):\n            executor.migrate([(\"migrations\", \"0001_initial\")])\n        # Reset the faked state\n        state = {\"faked\":"], "sample_234": ["def test_union_with_values_list_and_order_with_annotation(self):\n    ReservedName.objects.bulk_create([\n        ReservedName(name='rn1', order=7),\n        ReservedName(name='rn2', order=5),\n        ReservedName(name='rn0', order=6),\n        ReservedName(name='rn9', order=-1),\n    ])\n    qs1 = ReservedName.objects.filter(order__gte=6).annotate(alias=F('order'))\n    qs2 = ReservedName.objects.filter(order__lte=5).annotate(alias=F('order'))\n    union_qs = qs1.union(qs2)\n    for qs, expected_result in (\n        # Order by a single column.\n        (union_qs.order_by('-alias').values_list('alias', flat=True), [-1, 6, 5, 7]),\n        (union_qs.order_by('alias').values_list('alias', flat=True), [7, 5, 6, -1]),\n        (union_qs.values_list('alias', flat=True).order_by('-alias'), [-1, 6, 5, 7]),\n        (union_qs.values_list('alias', flat=True).order_by('alias'), [7, 5, 6, -1]),\n        # Order by multiple columns.\n        (union_qs.order_by('-name', 'alias').values_list('alias', flat=True), [-1, 5, 7, 6]),\n        (union_qs.values_list('alias', flat=True).order_by('-name', 'alias'), [-1, 5, 7, 6]),\n    ):\n        with self.subTest(qs=qs):\n            self.assertEqual(list(qs), expected_result)\n"], "sample_312": ["def test_add_squash(self):\n    # Test squashing when adding a node with the same connector\n    node = Node([('a', 1), ('b', 2)], connector='AND')\n    node_to_add = Node([('c', 3), ('d', 4)], connector='AND')\n    node.add(node_to_add, 'AND')\n    self.assertEqual(str(node), \"(AND: ('a', 1), ('b', 2), ('c', 3), ('d', 4))\")\n\n    # Test squashing when adding a node with a single child and different connector\n    node = Node([('a', 1), ('b', 2)], connector='AND')\n    node_to_add = Node([('c', 3)], connector='OR')\n    node.add(node_to_add, 'AND')\n    self.assertEqual(str(node), \"(AND: ('a', 1), ('b', 2), ('c', 3))\")\n\n    # Test not squashing when adding a node with a single child and same connector\n    node = Node([('a', 1)], connector='AND')\n    node_to_add = Node([('b', 2)], connector='AND')\n    node.add(node_to_add, 'AND')\n    self.assertEqual(str(node), \"(AND: (AND: ('a', 1)), (AND: ('b', 2)))\")\n\n    # Test not squashing when adding a node with a different connector\n    node = Node([('a', 1), ('b', 2)], connector='AND')\n    node_to_add = Node([('c', 3), ('d', 4)], connector='OR')\n    node.add(node_to_add, 'AND')\n    self.assertEqual(str(node), \"(AND: ('a', 1), ('b', 2), (OR: ('c', 3), ('d', 4)))\")\n"], "sample_584": ["    def test_combine_by_coords_3d(self):\n        ds0 = Dataset({'x': [0, 1], 'y': [10, 20, 30]})\n        ds1 = Dataset({'x': [2, 3], 'y': [10, 20, 30]})\n        ds2 = Dataset({'x': [0, 1], 'y': [40, 50, 60]})\n        ds3 = Dataset({'x': [2, 3], 'y': [40, 50, 60]})\n        ds4 = Dataset({'x': [0, 1], 'y': [70, 80, 90]})\n        ds5 = Dataset({'x': [2, 3], 'y': [70, 80, 90]})\n\n        expected = {(0, 0): ds0, (1, 0): ds1,\n                    (0, 1): ds2, (1, 1): ds3,\n                    (0, 2): ds4, (1, 2): ds5}\n        actual, concat_dims = _infer_concat_order_from_coords([ds1, ds0, ds3,\n                                                               ds5, ds2, ds4])\n        assert_combined_tile_ids_equal(expected, actual)\n        assert concat_dims == ['x', 'y']\n"], "sample_1138": ["def test_TR22():\n    assert TR22(tan(x)**2) == sec(x)**2 - 1\n    assert TR22(cot(x)**2) == csc(x)**2 - 1\n    assert TR22(tan(x)**4) == (sec(x)**2 - 1)**2\n    assert TR22(cot(x)**4) == (csc(x)**2 - 1)**2\n    assert TR22(tan(x)**6) == (sec(x)**2 - 1)**3\n    assert TR22(cot(x)**6) == (csc(x)**2 - 1)**3\n    assert TR22(tan(x)**8) == (sec(x)**2 - 1)**4\n    assert TR22(cot(x)**8) == (csc(x)**2 - 1)**4\n"], "sample_329": ["def test_register_serializer(self):\n    Serializer.register(type, ComplexSerializer)\n    try:\n        string, imports = MigrationWriter.serialize(type)\n        self.assertEqual(string, \"complex(<class 'type'>)\")\n        self.assertEqual(imports, set())\n    finally:\n        Serializer.unregister(type)\n"], "sample_1170": ["def test_Pow_with_rational_exponent():\n    assert str(x**Rational(2, 3)) == \"x**(2/3)\"\n    assert str(x**Rational(-2, 3)) == \"x**(-2/3)\"\n    assert str(x**Rational(1, 2)) == \"sqrt(x)\"\n    assert str(x**Rational(-1, 2)) == \"1/sqrt(x)\"\n    assert str(x**Rational(3, 2)) == \"x*sqrt(x)\"\n    assert str(x**Rational(-3, 2)) == \"x/sqrt(x)\"\n"], "sample_18": ["    def setup_class(self):\n        self.q = u.Quantity(np.arange(1.0, 5.0), \"m/s\")\n        self.q.info.name = \"v\"\n        self.q.info.description = \"air speed of a african swallow\"\n"], "sample_184": ["    def test_check_constraint_pointing_to_joined_fields_with_function(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=10)\n            field1 = models.PositiveSmallIntegerField()\n            field2 = models.PositiveSmallIntegerField()\n            parent = models.ForeignKey('self', models.CASCADE)\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        name='name1', check=models.Q(\n                            field1__lt=models.F('parent__field1') + models.F('parent__field2')\n                        )\n                    ),\n                    models.CheckConstraint(\n                        name='name2', check=models.Q(name=Lower('parent__name'))\n                    ),\n                    models.CheckConstraint(\n                        name='name3', check=models.Q(parent__field3=models.F('field1'))\n                    ),\n                ]\n\n        joined_fields = ['parent__field1', 'parent__field2', 'parent__field3', 'parent__name']\n        errors = Model.check(databases=self.databases)\n        expected_errors = [\n            Error(\n                \"'constraints' refers to the joined field '%s'.\" % field_name,\n                obj=Model,\n                id='models.E041',\n            ) for field_name in joined_fields\n        ]\n        self.assertCountEqual(errors, expected_errors)\n"], "sample_39": ["def test_sip_foc2pix():\n    \"\"\"\n    Test sip_foc2pix\n    \"\"\"\n    with fits.open(get_pkg_data_filename('data/sip.fits')) as f:\n        w = wcs.WCS(f[0].header)\n\n    x0, y0 = w.sip_pix2foc(200, 200, 0)\n\n    x1, y1 = w.sip_foc2pix(x0, y0, 0)\n\n    assert_allclose(200, x1, 1e-3)\n    assert_allclose(200, y1, 1e-3)\n"], "sample_45": ["def test_trunc_timezone_with_dst_transition(self):\n    sao = pytz.timezone('America/Sao_Paulo')\n    utc = pytz.timezone('UTC')\n    start_datetime = utc.localize(datetime(2016, 10, 16, 13))\n    end_datetime = utc.localize(datetime(2016, 2, 21, 1))\n    self.create_model(start_datetime, end_datetime)\n    with timezone.override(sao):\n        model = DTModel.objects.annotate(\n            truncated_start=TruncDay('start_datetime', tzinfo=sao),\n            truncated_end=TruncHour('end_datetime', tzinfo=sao),\n        ).get()\n        self.assertEqual(model.truncated_start.tzinfo, sao)\n        self.assertEqual(model.truncated_end.tzinfo, sao)\n        self.assertEqual(model.truncated_start.dst(), timedelta(0, 3600))\n        self.assertEqual(model.truncated_end.dst(), timedelta(0, 3600))\n"], "sample_686": ["def test_fixture_positional_arguments_deprecated(testdir, fixture_positional_args):\n    if fixture_positional_args:\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n                return arg1, arg2\n\n                pass\n        \"\"\"\n        )\n    else:\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n                return arg1, arg2\n\n                pass\n        \"\"\"\n        )\n\n    if fixture_positional_args:\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"*Passing arguments to pytest.fixture() as positional arguments is deprecated - pass them \"\n                \"as a keyword argument instead.*\",\n            ]\n        )\n    else:\n        result = testdir.runpytest()\n        result.stdout.no_fnmatch_line(\n            \"*Passing arguments to pytest.fixture() as positional arguments is deprecated - pass them \"\n            \"as a keyword argument instead.*\",\n        )\n"], "sample_391": ["def test_create_model_alter_model_table(self):\n    \"\"\"\n    AlterModelTable should optimize into CreateModel.\n    \"\"\"\n    managers = [(\"objects\", EmptyManager())]\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n                options={\"verbose_name\": \"Foo\"},\n                bases=(UnicodeModel,),\n                managers=managers,\n            ),\n            migrations.AlterModelTable(\"Foo\", \"new_table\"),\n        ],\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n                options={\"verbose_name\": \"Foo\", \"db_table\": \"new_table\"},\n                bases=(UnicodeModel,),\n                managers=managers,\n            ),\n        ],\n    )\n"], "sample_688": ["def test_import_path_mode_importlib_with_relative_path(testdir):\n    \"\"\"Test that import_path with mode importlib works with relative paths.\"\"\"\n    testdir.makepyfile(\n        **{\n            \"tests/test_foo.py\": \"def test_foo(): pass\",\n        }\n    )\n    result = testdir.runpytest(\"-v\", \"--import-mode=importlib\", \"tests/test_foo.py\")\n    result.stdout.fnmatch_lines(\n        [\n            \"tests/test_foo.py::test_foo *\",\n            \"* 1 passed in *\",\n        ]\n    )\n"], "sample_888": ["def test_iforest_offset_calculation(global_random_seed):\n    \"\"\"Test offset calculation for different contamination values.\"\"\"\n    rng = check_random_state(global_random_seed)\n    X = rng.randn(100, 2)\n    contamination_values = [0.1, 0.2, 0.3, 0.4, 0.5]\n\n    for contamination in contamination_values:\n        clf = IsolationForest(contamination=contamination, random_state=rng).fit(X)\n        scores = clf._score_samples(X)\n        offset = np.percentile(scores, 100.0 * contamination)\n        assert_allclose(clf.offset_, offset)\n"], "sample_1148": ["def test_matrix_element_indexing():\n    A = MatrixSymbol('A', 3, 3)\n    assert A[0, 0].i == 0\n    assert A[0, 0].j == 0\n    assert A[1, 2].i == 1\n    assert A[1, 2].j == 2\n    assert A[0, 0].parent == A\n    assert A[1, 2].parent == A\n"], "sample_802": ["def test_pipeline_memory_with_joblib_version_12():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        memory = Memory(location=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(gamma='scale', probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', clone(transf)), ('svc', clf)])\n        cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n                               memory=memory)\n\n        # Memoize the transformer at the first fit\n        cached_pipe.fit(X, y)\n        pipe.fit(X, y)\n        # Get the time stamp of the transformer in the cached pipeline\n        ts = cached_pipe.named_steps['transf'].timestamp_\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert not hasattr(transf, 'means_')\n        # Check that we are reading the cache while fitting\n        # a second time\n        cached_pipe.fit(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert_equal(ts, cached_pipe.named_steps['transf'].timestamp_)\n        # Create a new pipeline with cloned estimators\n        # Check that even changing the name step does not affect the cache hit\n        clf_2 = SVC(gamma='scale', probability=True, random_state=0)\n        transf_2 = DummyTransf()\n        cached_pipe_2 = Pipeline([('transf_2', transf_2), ('svc', clf_2)],\n                                 memory="], "sample_1089": ["def test_monotonic_sign_univariate_polynomial():\n    x = symbols('x')\n    F = _monotonic_sign\n    assert F(x**2 + 1) == 1\n    assert F(x**2 - 1) is None\n    assert F(x**3 + 1) == 1\n    assert F(x**3 - 1) is None\n    assert F(x**4 + 1) == 1\n    assert F(x**4 - 1) is None\n    assert F(x**5 + 1) == 1\n    assert F(x**5 - 1) is None\n    assert F(x**6 + 1) == 1\n    assert F(x**6 - 1) is None\n    assert F(x**7 + 1) == 1\n    assert F(x**7 - 1) is None\n    assert F(x**8 + 1) == 1\n    assert F(x**8 - 1) is None\n    assert F(x**9 + 1) == 1\n    assert F(x**9 - 1) is None\n    assert F(x**10 + 1) == 1\n    assert F(x**10 - 1) is None\n    assert F(x**11 + 1) == 1\n    assert F(x**11 - 1) is None\n    assert F(x**12 + 1) == 1\n    assert F(x**12 - 1) is None\n    assert F(x**13 + 1) == 1\n    assert F(x**13 - 1) is None\n    assert F(x**14 + 1) == 1\n    assert F(x**14 - 1) is None\n    assert F(x**15 + 1) == 1\n    assert F(x**15 - 1) is None\n    assert F(x**16 + 1) == 1\n    assert F(x**16 - 1) is None\n    assert F(x**17 + 1) == 1\n    assert F(x**17 - 1) is None\n    assert F(x**18 + 1) == 1\n    assert F(x**18 - 1) is None\n    assert F(x**19 + 1) == 1\n    assert F(x**19 - 1"], "sample_647": ["def test_warn_explicit_for() -> None:\n    \"\"\"Test that warn_explicit_for correctly issues a warning with the given message and location.\"\"\"\n        pass\n\n    message = PytestWarning(\"Test warning message\")\n    warn_explicit_for(test_function, message)\n\n    with pytest.warns(PytestWarning) as record:\n        warn_explicit_for(test_function, message)\n    assert len(record) == 1\n    assert record[0].message.args[0] == \"Test warning message\"\n    assert record[0].filename == inspect.getfile(test_function)\n    assert record[0].lineno == test_function.__code__.co_firstlineno\n\n"], "sample_359": ["def test_alter_field_with_deferrable_unique_constraint(self):\n    app_label = 'test_alter_field_with_deferrable_unique_constraint'\n    deferred_unique_constraint = models.UniqueConstraint(\n        fields=['pink'],\n        name='deferrable_pink_constraint',\n        deferrable=models.Deferrable.DEFERRED,\n    )\n    project_state = self.set_up_test_model(app_label, constraints=[deferred_unique_constraint])\n    operation = migrations.AlterField(\n        'Pony',\n        'pink',\n        models.IntegerField(null=True),\n    )\n    new_state = project_state.clone()\n    operation.state_forwards(app_label, new_state)\n    self.assertEqual(len(new_state.models[app_label, 'pony'].options['constraints']), 1)\n    Pony = new_state.apps.get_model(app_label, 'Pony')\n    self.assertEqual(len(Pony._meta.constraints), 1)\n    with connection.schema_editor() as editor:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    Pony.objects.create(pink=1)\n    if connection.features.supports_deferrable_unique_constraints:\n        # Unique constraint is deferred.\n        with transaction.atomic():\n            obj = Pony.objects.create(pink=1)\n            obj.pink = 2\n            obj.save()\n        # Constraint behavior can be changed with SET CONSTRAINTS.\n        with self.assertRaises(IntegrityError):\n            with transaction.atomic(), connection.cursor() as cursor:\n                quoted_name = connection.ops.quote_name(deferred_unique_constraint.name)\n                cursor.execute('SET CONSTRAINTS %s IMMEDIATE' % quoted_name)\n                obj = Pony.objects.create(pink=1)\n                obj.pink = 3\n                obj.save()\n    else:\n        Pony.objects.create(pink=1)\n    # Reversal.\n    with connection.schema_editor() as editor:\n        operation.database_backwards(app_label, editor, new_state, project_state)\n    # Deconstruction.\n    definition = operation.deconstruct()\n    self.assertEqual(definition[0], 'AlterField')\n    self.assertEqual(definition[1], [])\n    self.assertEqual(\n        definition[2],\n        {'model_name': 'Pony', 'name': 'pink', 'field': models.IntegerField(null=True)},\n    )\n"], "sample_14": ["def test_longitude_wrap_at_edge_cases():\n    \"\"\"\n    Test Longitude wrapping at edge cases\n    \"\"\"\n\n    # Test wrapping at 0 degrees\n    lon = Longitude([0, 360, 720] * u.deg)\n    assert np.all(lon.degree == np.array([0., 0., 0.]))\n\n    # Test wrapping at 180 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='180d')\n    assert np.all(lon.degree == np.array([0., -180., 0.]))\n\n    # Test wrapping at -180 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='-180d')\n    assert np.all(lon.degree == np.array([0., 180., 0.]))\n\n    # Test wrapping at 90 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='90d')\n    assert np.all(lon.degree == np.array([0., -270., 0.]))\n\n    # Test wrapping at -90 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='-90d')\n    assert np.all(lon.degree == np.array([0., 270., 0.]))\n"], "sample_465": ["def test_to_field_allowed(self):\n    \"\"\"\n    to_field_allowed() returns True if the model associated with this admin\n    should be allowed to be referenced by the specified field.\n    \"\"\"\n    ma = ModelAdmin(Band, self.site)\n    self.assertTrue(ma.to_field_allowed(request, \"id\"))\n    self.assertTrue(ma.to_field_allowed(request, \"name\"))\n    self.assertFalse(ma.to_field_allowed(request, \"nonexistent_field\"))\n    self.assertFalse(ma.to_field_allowed(request, \"bio\"))\n"], "sample_273": ["    def test_model_base_subclass_exception(self):\n        class MyModel(metaclass=ModelBase):\n            class Meta:\n                app_label = 'check_framework'\n\n        self.assertEqual(MyModel.DoesNotExist.__qualname__, 'MyModel.DoesNotExist')\n        self.assertEqual(MyModel.MultipleObjectsReturned.__qualname__, 'MyModel.MultipleObjectsReturned')\n"], "sample_1050": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n    assert not prntr.module_imports\n    assert prntr.doprint(pi) == 'math.pi'\n    assert prntr.module_imports == {'math': {'pi'}}\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n"], "sample_793": ["def test_iforest_predict_with_sample_weight(contamination):\n    # toy sample (the last two samples are outliers)\n    X = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1], [6, 3], [-4, 7]]\n    sample_weight = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5]\n\n    # Test IsolationForest\n    clf = IsolationForest(\n        behaviour=\"new\", random_state=rng, contamination=contamination\n    )\n    clf.fit(X, sample_weight=sample_weight)\n    decision_func = -clf.decision_function(X)\n    pred = clf.predict(X)\n    # assert detect outliers:\n    assert_greater(np.min(decision_func[-2:]), np.max(decision_func[:-2]))\n    assert_array_equal(pred, 6 * [1] + 2 * [-1])\n"], "sample_52": ["def test_modelchoicefield_with_empty_queryset(self):\n    f = forms.ModelChoiceField(Category.objects.none())\n    self.assertEqual(list(f.choices), [('', '---------')])\n    self.assertEqual(len(f.choices), 1)\n    self.assertIsNone(f.clean(''))\n    with self.assertRaises(ValidationError):\n        f.clean(0)\n    with self.assertRaises(ValidationError):\n        f.clean(self.c1.id)\n"], "sample_726": ["def test_label_binarize_multilabel_indicator():\n    y = [[0, 1, 1], [1, 0, 0], [0, 0, 0]]\n    classes = [0, 1, 2]\n    pos_label = 2\n    neg_label = 0\n    expected = np.array([[0, 2, 2], [2, 0, 0], [0, 0, 0]])\n\n    yield check_binarized_results, y, classes, pos_label, neg_label, expected\n\n    assert_raises(ValueError, label_binarize, y, classes, neg_label=-1,\n                  pos_label=pos_label, sparse_output=True)\n"], "sample_1028": ["def test_Mod_is_nonzero():\n    p = Symbol('p', integer=True)\n    q1 = Symbol('q1', integer=True)\n    q2 = Symbol('q2', integer=True, nonzero=True)\n    assert Mod(x, y).is_zero is None\n    assert Mod(p, q1).is_zero is None\n    assert Mod(x, q2).is_zero is None\n    assert Mod(p, q2).is_zero is None\n    assert Mod(0, q2).is_zero\n    assert Mod(p, 0).is_zero is None\n"], "sample_441": ["    def test_normalize(self):\n        field = UsernameField()\n        self.assertEqual(field.to_python(\"test\"), \"test\")\n        self.assertEqual(field.to_python(\"test\u03a9\"), \"test\u03a9\")  # U+03A9 GREEK CAPITAL LETTER OMEGA\n        self.assertEqual(field.to_python(\"test\u2126\"), \"test\u03a9\")  # U+2126 OHM SIGN\n"], "sample_521": ["def test_line3d_set_get_data_3d():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    x, y, z = [0, 1], [2, 3], [4, 5]\n    x2, y2, z2 = [6, 7], [8, 9], [10, 11]\n    lines = ax.plot(x, y, z)\n    line = lines[0]\n    np.testing.assert_array_equal((x, y, z), line.get_data_3d())\n    line.set_data_3d(x2, y2, z2)\n    np.testing.assert_array_equal((x2, y2, z2), line.get_data_3d())\n    line.set_xdata(x)\n    line.set_ydata(y)\n    line.set_3d_properties(zs=z, zdir='z')\n    np.testing.assert_array_equal((x, y, z), line.get_data_3d())\n    line.set_3d_properties(zs=0, zdir='z')\n    np.testing.assert_array_equal((x, y, np.zeros_like(z)), line.get_data_3d())\n"], "sample_490": ["def test_validate_expression_with_condition_and_custom_error(self):\n    constraint = models.UniqueConstraint(\n        Lower(\"name\"),\n        name=\"name_lower_without_color_uniq\",\n        condition=models.Q(color__isnull=True),\n        violation_error_code=\"custom_code\",\n        violation_error_message=\"Custom message\",\n    )\n    non_unique_product = UniqueConstraintProduct(name=self.p2.name.upper())\n    msg = \"Custom message\"\n    with self.assertRaisesMessage(ValidationError, msg) as cm:\n        constraint.validate(UniqueConstraintProduct, non_unique_product)\n    self.assertEqual(cm.exception.code, \"custom_code\")\n    # Values not matching condition are ignored.\n    constraint.validate(\n        UniqueConstraintProduct,\n        UniqueConstraintProduct(name=self.p1.name, color=self.p1.color),\n    )\n    # Existing instances have their existing row excluded.\n    constraint.validate(UniqueConstraintProduct, self.p2)\n    # Unique field is excluded.\n    constraint.validate(\n        UniqueConstraintProduct,\n        non_unique_product,\n        exclude={\"name\"},\n    )\n    # Field from a condition is excluded.\n    constraint.validate(\n        UniqueConstraintProduct,\n        non_unique_product,\n        exclude={\"color\"},\n    )\n"], "sample_141": ["    def test_progress_bar(self):\n        output = StringIO()\n        progress_bar = ProgressBar(output, 100)\n        progress_bar.update(50)\n        self.assertEqual(output.getvalue(), '[...............................................]')\n        progress_bar.update(100)\n        self.assertEqual(output.getvalue(), '[...............................................]\\n')\n"], "sample_626": ["def test_explicit_indexing_adapter():\n    # Test explicit indexing adapter with different indexing_support\n    array = np.arange(36).reshape(6, 6)\n    key = OuterIndexer((np.array([0, 1, 3]), np.array([2, 3])))\n    indexing_supports = [IndexingSupport.BASIC, IndexingSupport.OUTER, IndexingSupport.VECTORIZED]\n\n    for indexing_support in indexing_supports:\n        result = explicit_indexing_adapter(key, array.shape, indexing_support, array.__getitem__)\n        expected = array[key.tuple]\n        np.testing.assert_array_equal(result, expected)\n\n    # Test explicit indexing adapter with VectorizedIndexer\n    key = VectorizedIndexer((np.array([0, 3, 1]), np.array([2, 3, 2])))\n    result = explicit_indexing_adapter(key, array.shape, IndexingSupport.VECTORIZED, array.__getitem__)\n    expected = array[key.tuple]\n    np.testing.assert_array_equal(result, expected)\n\n    # Test explicit indexing adapter with BasicIndexer\n    key = BasicIndexer((0, 1))\n    result = explicit_indexing_adapter(key, array.shape, IndexingSupport.BASIC, array.__getitem__)\n    expected = array[key.tuple]\n    np.testing.assert_array_equal(result, expected)\n"], "sample_204": ["    def test_replace_migrations(self):\n        \"\"\"\n        Tests loading a migration that replaces another migration.\n        \"\"\"\n        loader = MigrationLoader(connection)\n        recorder = MigrationRecorder(connection)\n        self.addCleanup(recorder.flush)\n\n        # Load with nothing applied: the replacing migration is used.\n        loader.build_graph()\n        plan = set(loader.graph.forwards_plan(('migrations', '0003_third')))\n        plan = plan - loader.applied_migrations.keys()\n        expected_plan = {\n            ('migrations', '0001_initial'),\n            ('migrations', '0002_replacing'),\n            ('migrations', '0003_third'),\n        }\n        self.assertEqual(plan, expected_plan)\n\n        # Fake-apply the replaced migration: the replacing migration is not used.\n        recorder.record_applied('migrations', '0002_second')\n        loader.build_graph()\n        plan = set(loader.graph.forwards_plan(('migrations', '0003_third')))\n        plan = plan - loader.applied_migrations.keys()\n        expected_plan = {\n            ('migrations', '0001_initial'),\n            ('migrations', '0002_second'),\n            ('migrations', '0003_third'),\n        }\n        self.assertEqual(plan, expected_plan)\n\n        # Fake-apply the replacing migration: it is used again.\n        recorder.record_applied('migrations', '0002_replacing')\n        loader.build_graph()\n        plan = set(loader.graph.forwards_plan(('migrations', '0003_third')))\n        plan = plan - loader.applied_migrations.keys()\n        expected_plan = {\n            ('migrations', '0001_initial'),\n            ('migrations', '0002_replacing'),\n            ('migrations', '0003_third'),\n        }\n        self.assertEqual(plan, expected_plan)\n"], "sample_984": ["def test_Predicate():\n    assert str(Q.is_true) == \"Q.is_true\"\n    assert str(Q.is_false) == \"Q.is_false\"\n    assert str(Q.is_zero) == \"Q.is_zero\"\n    assert str(Q.is_nonzero) == \"Q.is_nonzero\"\n    assert str(Q.is_positive) == \"Q.is_positive\"\n    assert str(Q.is_negative) == \"Q.is_negative\"\n    assert str(Q.is_even) == \"Q.is_even\"\n    assert str(Q.is_odd) == \"Q.is_odd\"\n    assert str(Q.is_integer) == \"Q.is_integer\"\n    assert str(Q.is_rational) == \"Q.is_rational\"\n    assert str(Q.is_real) == \"Q.is_real\"\n    assert str(Q.is_complex) == \"Q.is_complex\"\n    assert str(Q.is_prime) == \"Q.is_prime\"\n    assert str(Q.is_composite) == \"Q.is_composite\"\n    assert str(Q.is_algebraic) == \"Q.is_algebraic\"\n    assert str(Q.is_transcendental) == \"Q.is_transcendental\"\n    assert str(Q.is_finite) == \"Q.is_finite\"\n    assert str(Q.is_infinite) == \"Q.is_infinite\"\n    assert str(Q.is_finite) == \"Q.is_finite\"\n    assert str(Q.is_infinite) == \"Q.is_infinite\"\n"], "sample_422": ["    def setUpTestData(cls):\n        cls.book1 = Book.objects.create(title=\"Poems\")\n        cls.book2 = Book.objects.create(title=\"Jane Eyre\")\n        cls.author1 = Author.objects.create(name=\"Charlotte\", first_book=cls.book1)\n        cls.author2 = Author.objects.create(name=\"Anne\", first_book=cls.book1)\n        cls.author3 = Author.objects.create(name=\"Emily\", first_book=cls.book1)\n        cls.author4 = Author.objects.create(name=\"Jane\", first_book=cls.book2)\n"], "sample_1100": ["def test_Pow_as_content_primitive():\n    assert (x**y).as_content_primitive() == (1, x**y)\n    assert ((2*x + 2)**y).as_content_primitive() == \\\n        (1, (Mul(2, (x + 1), evaluate=False))**y)\n    assert ((2*x + 2)**3).as_content_primitive() == (8, (x + 1)**3)\n    assert ((2*x + 2)**Rational(3, 2)).as_content_primitive() == \\\n        (2*sqrt(2), (x + 1)**Rational(3, 2))\n    assert ((2*x + 2)**Rational(5, 2)).as_content_primitive() == \\\n        (4*sqrt(2), (x + 1)**Rational(5, 2))\n    assert ((2*x + 2)**Rational(7, 2)).as_content_primitive() == \\\n        (8*2**Rational(3, 2), (x + 1)**Rational(7, 2))\n    assert ((2*x + 2)**Rational(9, 2)).as_content_primitive() == \\\n        (16*2**Rational(3, 2), (x + 1)**Rational(9, 2))\n    assert ((2*x + 2)**Rational(11, 2)).as_content_primitive() == \\\n        (16*2**Rational(5, 2), (x + 1)**Rational(11, 2))\n    assert ((2*x + 2)**Rational(13, 2)).as_content_primitive() == \\\n        (32*2**Rational(5, 2), (x + 1)**Rational(13, 2))\n    assert ((2*x + 2)**Rational(15, 2)).as_content_primitive() == \\\n        (32*2**Rational(7, 2), (x + 1)**Rational(15, 2))\n    assert ((2*x + 2)**Rational(17, 2)).as_content_primitive() == \\\n        (64*2**Rational(7, 2), (x + 1)**Rational(17, 2))\n    assert ((2*x + 2)**Rational(19, 2)).as_content_primitive()"], "sample_226": ["    def test_clone_test_db(self):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        with mock.patch.object(creation, '_clone_test_db'):\n            creation.clone_test_db(suffix='suffix', verbosity=1, autoclobber=False, keepdb=False)\n        self.assertEqual(test_connection.settings_dict['NAME'], creation.get_test_db_clone_settings('suffix')['NAME'])\n"], "sample_727": ["def test_imputation_most_frequent_ties():\n    # Test imputation using the most-frequent strategy with ties.\n    X = np.array([\n        [-1, -1, 0, 5],\n        [-1, 2, -1, 3],\n        [-1, 1, 3, 3],\n        [-1, 2, 3, 7],\n    ])\n\n    X_true = np.array([\n        [2, 0, 5],\n        [2, 3, 3],\n        [1, 3, 3],\n        [2, 3, 7],\n    ])\n\n    # scipy.stats.mode, used in Imputer, doesn't return the first most\n    # frequent as promised in the doc but the lowest most frequent. When this\n    # test will fail after an update of scipy, Imputer will need to be updated\n    # to be consistent with the new (correct) behaviour\n    _check_statistics(X, X_true, \"most_frequent\", [np.nan, 2, 3, 3], -1)\n\n    # Test with ties\n    X = np.array([\n        [-1, -1, 0, 5],\n        [-1, 2, -1, 3],\n        [-1, 1, 3, 3],\n        [-1, 2, 3, 3],\n    ])\n\n    X_true = np.array([\n        [2, 0, 5],\n        [2, 3, 3],\n        [1, 3, 3],\n        [2, 3, 3],\n    ])\n\n    _check_statistics(X, X_true, \"most_frequent\", [np.nan, 2, 3, 3], -1)\n"], "sample_855": ["def test_dummy_classifier_on_sparse_X():\n    X = sp.csc_matrix(np.array([[0, 1],\n                                [1, 0],\n                                [0, 1],\n                                [1, 0]]))\n    y = [2, 2, 2, 2]\n    y_expected = [2, 2, 2, 2]\n    y_proba_expected = [[1], [1], [1], [1]]\n    cls = DummyClassifier()\n    cls.fit(X, y)\n    y_pred = cls.predict(X)\n    y_pred_proba = cls.predict_proba(X)\n    assert_array_equal(y_pred, y_expected)\n    assert_array_equal(y_pred_proba, y_proba_expected)\n"], "sample_953": ["def test_valid_dir(tempdir):\n    answers = {\n        'Root path': tempdir,\n        'Project name': 'Sphinx Test',\n        'Author name': 'Georg Brandl',\n        'Project version': '0.1',\n    }\n    qs.term_input = mock_input(answers)\n    d = {}\n    qs.ask_user(d)\n\n    # Test valid directory\n    assert qs.valid_dir(d) is True\n\n    # Test existing conf.py\n    (tempdir / 'conf.py').touch()\n    assert qs.valid_dir(d) is False\n\n    # Test existing Makefile\n    (tempdir / 'Makefile').touch()\n    assert qs.valid_dir(d) is False\n\n    # Test existing make.bat\n    (tempdir / 'make.bat').touch()\n    assert qs.valid_dir(d) is False\n\n    # Test existing master file\n    (tempdir / 'index.rst').touch()\n    assert qs.valid_dir(d) is False\n\n    # Test existing _static directory\n    (tempdir / '_static').mkdir()\n    assert qs.valid_dir(d) is False\n\n    # Test existing _templates directory\n    (tempdir / '_templates').mkdir()\n    assert qs.valid_dir(d) is False\n"], "sample_1062": ["def test_TR22():\n    assert TR22(tan(x)**2) == sec(x)**2 - 1\n    assert TR22(cot(x)**2) == csc(x)**2 - 1\n    assert TR22(tan(x)**4) == (sec(x)**2 - 1)**2\n    assert TR22(cot(x)**4) == (csc(x)**2 - 1)**2\n    assert TR22(tan(x)**-2) == tan(x)**-2\n    assert TR22(cot(x)**-2) == cot(x)**-2\n"], "sample_300": ["def test_add_annotation(self):\n    query = Query(Item)\n    query.add_annotation(Func('name', function='UPPER'), alias='upper_name')\n    self.assertIn('upper_name', query.annotations)\n    self.assertEqual(query.annotations['upper_name'].function, 'UPPER')\n    self.assertEqual(query.annotations['upper_name'].source_expressions[0].target, Item._meta.get_field('name'))\n"], "sample_1045": ["def test_issue_13470():\n    # Test that Float can be pickled and unpickled correctly\n    import pickle\n    f = Float('1.2')\n    assert pickle.loads(pickle.dumps(f)) == f\n    assert pickle.loads(pickle.dumps(Float((0, '1L', 0, 1)))) == Float((0, '1', 0, 1))\n"], "sample_1071": ["def test_check_dimensions():\n    assert check_dimensions(2*meter + 3*second) == 2*meter + 3*second\n    assert check_dimensions(2*meter + 3*meter) == 5*meter\n    assert check_dimensions(2*meter + 3*second**2) == 2*meter + 3*second**2\n\n    raises(ValueError, lambda: check_dimensions(2*meter + 3))\n    raises(ValueError, lambda: check_dimensions(2*meter + 3*second + 4))\n    raises(ValueError, lambda: check_dimensions(2*meter + 3*second + 4*kelvin))\n"], "sample_467": ["def test_value_from_datadict_with_invalid_year(self):\n    data = {\"field_year\": \"abc\", \"field_month\": \"12\", \"field_day\": \"1\"}\n    self.assertIsNone(self.widget.value_from_datadict(data, {}, \"field\"))\n"], "sample_593": ["def test_collapsible_section():\n    name = \"Test Section\"\n    inline_details = \"Inline details\"\n    details = \"Details\"\n    n_items = 10\n    enabled = True\n    collapsed = False\n\n    formatted = fh.collapsible_section(\n        name, inline_details, details, n_items, enabled, collapsed\n    )\n    assert name in formatted\n    assert inline_details in formatted\n    assert details in formatted\n    assert str(n_items) in formatted\n    assert \"checked\" not in formatted\n\n    formatted = fh.collapsible_section(\n        name, inline_details, details, n_items, enabled=False, collapsed=True\n    )\n    assert \"disabled\" in formatted\n    assert \"checked\" in formatted\n"], "sample_712": ["def test_ordinal_encoder_handle_unknown():\n    X = np.array([['a', 2, 55], ['b', 1, 55], ['a', 3, 55]])\n    X2 = np.array([['c', 1, 1]])\n\n    # Test that ordinal encoder raises error for unknown features\n    # present during transform.\n    oe = OrdinalEncoder(handle_unknown='error')\n    oe.fit(X)\n    assert_raises(ValueError, oe.transform, X2)\n\n    # Test the ignore option, ignores unknown features (giving all 0's)\n    oe = OrdinalEncoder(handle_unknown='ignore')\n    oe.fit(X)\n    X2_passed = X2.copy()\n    assert_array_equal(oe.transform(X2_passed), np.array([[0., 0., 0.]]))\n    # ensure transformed data was not modified in place\n    assert_allclose(X2, X2_passed)\n\n    # Raise error if handle_unknown is neither ignore or error.\n    oe = OrdinalEncoder(handle_unknown='42')\n    assert_raises(ValueError, oe.fit, X)\n"], "sample_108": ["    def test_match(self):\n        pattern = LocalePrefixPattern()\n        match = pattern.match('/en/')\n        self.assertEqual(match, ('', (), {}))\n"], "sample_531": ["def test_subfigure_subplotspec():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    subfig = fig.add_subfigure(gs[0, 0])\n    assert subfig._subplotspec == gs[0, 0]\n    assert subfig._subplotspec.get_gridspec() == gs\n    assert subfig._subplotspec.get_topmost_subplotspec() == gs[0, 0]\n    assert subfig._subplotspec.get_position(fig) == gs[0, 0].get_position(fig)\n    assert subfig._subplotspec.get_subplotspec() == gs[0, 0]\n"], "sample_928": ["def test_heading():\n    env = Environment()\n    env.language = 'en'\n    assert heading(env, 'Hello', 1) == 'Hello\\n====='\n    assert heading(env, '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a', 1) == '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a\\n====================='\n    assert heading(env, '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a', 2) == '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a\\n---------------------'\n    assert heading(env, '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a', 3) == '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a\\n~~~~~~~~~~~~~~~~~~~~~'\n\n    env.language = 'ja'\n    assert heading(env, 'Hello', 1) == 'Hello\\n======'\n    assert heading(env, '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a', 1) == '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a\\n====================='\n    assert heading(env, '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a', 2) == '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a\\n---------------------'\n    assert heading(env, '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a', 3) == '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a\\n~~~~~~~~~~~~~~~~~~~~~'\n"], "sample_590": ["def test_concat_positions_kwarg():\n    ds1 = Dataset({\"a\": (\"x\", [1, 2])}, {\"x\": [0, 1]})\n    ds2 = Dataset({\"a\": (\"x\", [3, 4])}, {\"x\": [0, 1]})\n    expected = Dataset({\"a\": ((\"y\", \"x\"), [[1, 2], [3, 4]])}, {\"x\": [0, 1], \"y\": [0, 1]})\n    actual = concat([ds1, ds2], dim=\"y\", positions=[0, 1])\n    assert_identical(expected, actual)\n\n    with raises_regex(ValueError, \"Length of positions does not match\"):\n        concat([ds1, ds2], dim=\"y\", positions=[0])\n\n    with raises_regex(ValueError, \"Positions must be integer arrays\"):\n        concat([ds1, ds2], dim=\"y\", positions=[0.0, 1.0])\n"], "sample_550": ["def test_axes_set_aspect():\n    fig, ax = plt.subplots()\n    ax.set_aspect('equal')\n    assert ax.get_aspect() == 1\n    ax.set_aspect('auto')\n    assert ax.get_aspect() == 'auto'\n    ax.set_aspect(2)\n    assert ax.get_aspect() == 2\n    with pytest.raises(ValueError):\n        ax.set_aspect(-1)\n    with pytest.raises(ValueError):\n        ax.set_aspect('invalid')\n"], "sample_1151": ["def test_Mod_eval():\n    x, y = symbols('x y')\n    assert Mod(x, y).eval() == Mod(x, y)\n    assert Mod(x, y).eval({x: 5, y: 3}) == 2\n    assert Mod(5, 3).eval() == 2\n    assert Mod(-5, 3).eval() == 1\n    assert Mod(5, -3).eval() == -1\n    assert Mod(-5, -3).eval() == -2\n    assert Mod(5, 3, evaluate=False).eval() == 2\n    assert Mod(-5, 3, evaluate=False).eval() == 1\n    assert Mod(5, -3, evaluate=False).eval() == -1\n    assert Mod(-5, -3, evaluate=False).eval() == -2\n"], "sample_1099": ["def test_eval_partial_derivative_higher_rank_tensors_by_tensor():\n    expr1 = PartialDerivative(H(i, j, k), H(m, m1, m2))\n    assert expr1._perform_derivative() - L.delta(i, -m) * L.delta(j, -m1) * L.delta(k, -m2) == 0\n\n    expr2 = PartialDerivative(H(i, j, k), H(-m, m1, m2))\n    assert expr2._perform_derivative() - L.metric(i, L_0) * L.delta(-L_0, m) * L.delta(j, -m1) * L.delta(k, -m2) == 0\n\n    expr3 = PartialDerivative(H(i, j, k), H(m, -m1, m2))\n    assert expr3._perform_derivative() - L.delta(i, -m) * L.metric(j, L_0) * L.delta(-L_0, m1) * L.delta(k, -m2) == 0\n\n    expr4 = PartialDerivative(H(i, j, k), H(m, m1, -m2))\n    assert expr4._perform_derivative() - L.delta(i, -m) * L.delta(j, -m1) * L.metric(k, L_0) * L.delta(-L_0, m2) == 0\n\n    expr5 = PartialDerivative(H(i, j, k), H(-m, -m1, m2))\n    assert expr5._perform_derivative() - L.metric(i, L_0) * L.delta(-L_0, m) * L.metric(j, L_1) * L.delta(-L_1, m1) * L.delta(k, -m2) == 0\n\n    expr6 = PartialDerivative(H(i, j, k), H(-m, m1, -m2))\n    assert expr6._perform_derivative() - L.metric(i, L_0) * L.delta(-L_0, m) * L.delta(j, -m1) * L.metric(k, L_1) * L.delta(-L_1, m2) == 0\n\n    expr7 = PartialDerivative(H(i, j, k), H(m, -m1, -m2))\n    assert expr7._perform_derivative() - L.delta(i, -m) * L.metric(j, L"], "sample_863": ["def test_pipeline_memory_with_clone():\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    if LooseVersion(joblib.__version__) < LooseVersion('0.12'):\n        # Deal with change of API in joblib\n        memory = joblib.Memory(cachedir=cachedir, verbose=10)\n    else:\n        memory = joblib.Memory(location=cachedir, verbose=10)\n    # Test with Transformer + SVC\n    clf = SVC(probability=True, random_state=0)\n    transf = DummyTransf()\n    pipe = Pipeline([('transf', transf), ('svc', clf)],\n                    memory=memory)\n\n    # Memoize the transformer at the first fit\n    pipe.fit(X, y)\n    # Get the time stamp of the transformer in the cached pipeline\n    ts = pipe.named_steps['transf'].timestamp_\n    # Check that we are reading the cache while fitting\n    # a second time\n    pipe.fit(X, y)\n    # Check that cached_pipe and pipe yield identical results\n    assert_array_equal(pipe.named_steps['transf'].means_,\n                       transf.means_)\n    assert ts == pipe.named_steps['transf'].timestamp_\n    # Create a new pipeline with cloned estimators\n    # Check that even changing the name step does not affect the cache hit\n    clf_2 = SVC(probability=True, random_state=0)\n    transf_2 = clone(transf)\n    pipe_2 = Pipeline([('transf_2', transf_2), ('svc', clf_2)],\n                      memory=memory)\n    pipe_2.fit(X, y)\n    # Check that cached_pipe and pipe yield identical results\n    assert_array_equal(pipe.named_steps['transf'].means_,\n                       pipe_2.named_steps['transf_2'].means_)\n    assert ts == pipe_2.named_steps['transf_2'].timestamp_\n    finally:\n        shutil.rmtree(cachedir)\n"], "sample_206": ["def test_generate_filename(self):\n    \"\"\"\n    Test that the generate_filename method correctly generates a filename.\n    \"\"\"\n    d = Document()\n    filename = 'test_file.txt'\n    generated_filename = d._meta.get_field('myfile').generate_filename(d, filename)\n    self.assertEqual(generated_filename, 'unused/test_file.txt')\n\n    # Test with a callable upload_to\n        return 'callable_upload_to/{}'.format(filename)\n\n    d._meta.get_field('myfile').upload_to = upload_to\n    generated_filename = d._meta.get_field('myfile').generate_filename(d, filename)\n    self.assertEqual(generated_filename, 'callable_upload_to/test_file.txt')\n\n    # Test with a string upload_to\n    d._meta.get_field('myfile').upload_to = 'string_upload_to/'\n    generated_filename = d._meta.get_field('myfile').generate_filename(d, filename)\n    self.assertEqual(generated_filename, 'string_upload_to/test_file.txt')\n"], "sample_532": ["def test_contour_labeler_event_handler():\n    cs = ContourSet(None, [1, 2, 3], [[[[0, 0], [1, 0], [1, 1], [0, 1]]]])\n    inline = True\n    inline_spacing = 5\n    event = type('Event', (), {'name': 'button_press_event', 'button': 1, 'x': 0.5, 'y': 0.5, 'inaxes': True})\n    _contour_labeler_event_handler(cs, inline, inline_spacing, event)\n    assert len(cs.labelTexts) == 1\n    assert len(cs.labelCValues) == 1\n    assert len(cs.labelXYs) == 1\n\n    event = type('Event', (), {'name': 'button_press_event', 'button': 3, 'x': 0.5, 'y': 0.5, 'inaxes': True})\n    _contour_labeler_event_handler(cs, inline, inline_spacing, event)\n    assert len(cs.labelTexts) == 0\n    assert len(cs.labelCValues) == 0\n    assert len(cs.labelXYs) == 0\n\n    event = type('Event', (), {'name': 'key_press_event', 'key': 'escape', 'x': 0.5, 'y': 0.5, 'inaxes': True})\n    _contour_labeler_event_handler(cs, inline, inline_spacing, event)\n"], "sample_566": ["def test_subfigure_subplotspec():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    subfig = fig.add_subfigure(gs[0, 0])\n    assert subfig._subplotspec == gs[0, 0]\n    assert subfig._subplotspec.get_gridspec() == gs\n    assert subfig._subplotspec.get_topmost_subplotspec() == gs[0, 0]\n"], "sample_990": ["def test_hyperbolic_function_properties():\n    x = Symbol('x')\n    assert sinh(x).is_real == x.is_real\n    assert cosh(x).is_real == x.is_real\n    assert tanh(x).is_real == x.is_real\n    assert coth(x).is_real == x.is_real\n    assert csch(x).is_real == x.is_real\n    assert sech(x).is_real == x.is_real\n    assert asinh(x).is_real == x.is_real\n    assert acosh(x).is_real == (x >= 1)\n    assert atanh(x).is_real == (x.is_real and abs(x) < 1)\n    assert acoth(x).is_real == (x.is_real and abs(x) > 1)\n    assert asech(x).is_real == (x.is_real and abs(x) <= 1)\n    assert acsch(x).is_real == x.is_real\n"], "sample_831": ["def test_plot_tree_friedman_mse(pyplot):\n    # mostly smoke tests\n    # Check correctness of export_graphviz for criterion = friedman_mse\n    clf = DecisionTreeRegressor(max_depth=3,\n                                min_samples_split=2,\n                                criterion=\"friedman_mse\",\n                                random_state=2)\n    clf.fit(X, y)\n\n    # Test export code\n    feature_names = ['first feat', 'sepal_width']\n    nodes = plot_tree(clf, feature_names=feature_names)\n    assert len(nodes) == 3\n    assert nodes[0].get_text() == (\"first feat <= 0.0\\nfriedman_mse = 1.0\\n\"\n                                   \"samples = 6\\nvalue = 0.0\")\n    assert nodes[1].get_text() == \"friedman_mse = 0.0\\nsamples = 3\\nvalue = -1.0\"\n    assert nodes[2].get_text() == \"friedman_mse = 0.0\\nsamples = 3\\nvalue = 1.0\"\n"], "sample_8": ["    def test_masked_array_from_masked(self):\n        \"\"\"Check that we can initialize a MaskedArray properly.\"\"\"\n        np_ma = np.ma.MaskedArray(self.ma)\n        assert type(np_ma) is np.ma.MaskedArray\n        assert type(np_ma.data) is self._data_cls\n        assert type(np_ma.mask) is np.ndarray\n        assert_array_equal(np_ma.data, self.a)\n        assert_array_equal(np_ma.mask, self.mask_a)\n"], "sample_914": ["def test_unparse_arguments():\n    source = \"def func(a: int, b: str = 'default', *args, c: int = 1, **kwargs): pass\"\n    expected = \"a: int, b: str = 'default', *args, c: int = 1, **kwargs\"\n    tree = ast.parse(source)\n    assert ast.unparse_arguments(tree.body[0].args) == expected\n"], "sample_161": ["    def test_foreign_key_to_swapped_model(self):\n        class Replacement(models.Model):\n            pass\n\n        class SwappedModel(models.Model):\n            class Meta:\n                swappable = 'TEST_SWAPPED_MODEL'\n\n        class Model(models.Model):\n            fk = models.ForeignKey(SwappedModel, models.CASCADE)\n\n        field = Model._meta.get_field('fk')\n        self.assertEqual(field.check(from_model=Model), [\n            Error(\n                \"Field defines a relation with the model 'invalid_models_tests.SwappedModel', \"\n                \"which has been swapped out.\",\n                hint=\"Update the relation to point at 'settings.TEST_SWAPPED_MODEL'.\",\n                obj=field,\n                id='fields.E301',\n            ),\n        ])\n"], "sample_504": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    sm = cm.ScalarMappable(norm=mcolors.Normalize(), cmap='viridis')\n    cb = fig.colorbar(sm)\n    assert cb.alpha is None\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n    cb.set_alpha([0.5, 0.7])\n    assert cb.alpha is None\n    fig.draw_without_rendering()\n"], "sample_1171": ["def test_ComplexRegion_polar_intersect():\n    # Polar form\n    c1 = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)\n    c2 = ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    c3 = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi), polar=True)\n    c4 = ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n\n    p1 = Union(Interval(0, 1)*Interval(0, 2*S.Pi), Interval(0, 1)*Interval(0, S.Pi))\n    p2 = Union(Interval(0, oo)*Interval(0, S.Pi), Interval(0, oo)*Interval(S.Pi, 2*S.Pi))\n\n    assert c1.intersect(c2) == ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    assert c3.intersect(c4) == ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n\n    # Rectangular form\n    c5 = ComplexRegion(Interval(2, 5)*Interval(6, 9))\n    c6 = ComplexRegion(Interval(4, 6)*Interval(10, 12))\n    c7 = ComplexRegion(Interval(0, 10)*Interval(-10, 0))\n    c8 = ComplexRegion(Interval(12, 16)*Interval(14, 20))\n\n    p3 = Union(Interval(2, 5)*Interval(6, 9), Interval(4, 6)*Interval(10, 12))\n    p4 = Union(Interval(0, 10)*Interval(-10, 0), Interval(12, 16)*Interval(14, 20))\n\n    assert c5.intersect(c6) == ComplexRegion(Interval(4, 5)*Interval(10, 9), False)\n    assert c7.intersect(c8) == ComplexRegion(Interval(12, 10)*Interval(14, 0), False)\n\n    assert c1.intersect(Interval(2, 4)) == Intersection(c1, Interval(2, 4), evaluate=False)\n    assert c5.intersect(Interval"], "sample_472": ["def test_page_repr(self):\n    \"\"\"\n    Test the representation of a Page object.\n    \"\"\"\n    paginator = Paginator([1, 2, 3], 2)\n    page = paginator.page(1)\n    self.assertEqual(repr(page), \"<Page 1 of 2>\")\n    self.assertEqual(str(page), \"<Page 1 of 2>\")\n\n    paginator = Paginator([], 2)\n    page = paginator.page(1)\n    self.assertEqual(repr(page), \"<Page 1 of 1>\")\n    self.assertEqual(str(page), \"<Page 1 of 1>\")\n\n    paginator = Paginator([1, 2, 3], 2, allow_empty_first_page=False)\n    with self.assertRaises(EmptyPage):\n        paginator.page(1)\n"], "sample_898": ["def test_auc():\n    # Test the area under the curve (AUC) computation\n    x = np.array([0, 1, 2, 3])\n    y = np.array([0, 1, 3, 6])\n\n    # Test with reorder=True\n    auc_reorder_true = auc(x, y, reorder=True)\n    assert_almost_equal(auc_reorder_true, 4.5)\n\n    # Test with reorder=False\n    auc_reorder_false = auc(x, y, reorder=False)\n    assert_almost_equal(auc_reorder_false, 4.5)\n\n    # Test with non-monotonic x\n    x_non_monotonic = np.array([0, 2, 1, 3])\n    assert_raises(ValueError, auc, x_non_monotonic, y, reorder=False)\n\n    # Test with less than 2 points\n    x_less_than_2_points = np.array([0, 1])\n    y_less_than_2_points = np.array([0, 1])\n    assert_raises(ValueError, auc, x_less_than_2_points, y_less_than_2_points)\n\n    # Test with x and y of different lengths\n    x_different_length = np.array([0, 1, 2])\n    assert_raises(ValueError, auc, x_different_length, y)\n"], "sample_985": ["def test_real_root():\n    from sympy import root, real_root, Rational, Symbol\n    x = Symbol('x')\n    assert real_root(-8, 3) == -2\n    assert real_root(root(-8, 3)) == -2\n    assert real_root(root(-8, 3, 2)) != -2\n    assert real_root(x**2) == x\n    assert real_root(x**2, 3) == x**(2/3)\n    assert real_root(-x**2) == -x\n    assert real_root(-x**2, 3) == -x**(2/3)\n    assert real_root(-x**2, Rational(1, 3)) == -x**(2/3)\n    assert real_root(-x**2, Rational(2, 3)) == x**(2/3)\n    assert real_root(-x**2, Rational(3, 3)) == -x**(2/3)\n    assert real_root(-x**2, Rational(4, 3)) == x**(2/3)\n"], "sample_942": ["def test_pyclass_nesting(app):\n    text = (\".. py:class:: Outer\\n\"\n            \"\\n\"\n            \"   .. py:class:: Inner\\n\"\n            \"\\n\"\n            \"       .. py:method:: method\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_name, \"Outer\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc)])]))\n    assert_node(doctree[1][1][0], addnodes.index,\n                entries=[('single', 'Outer (built-in class)', 'Outer', '', None)])\n    assert 'Outer' in domain.objects\n    assert domain.objects['Outer'] == ('index', 'Outer', 'class', False)\n\n    assert_node(doctree[1][1][1], ([desc_signature, ([desc_annotation, \"class \"],\n                                                     [desc_addname, \"Outer.\"],\n                                                     [desc_name, \"Inner\"])],\n                                   [desc_content, (addnodes.index,\n                                                   desc)]))\n    assert_node(doctree[1][1][1][1][0], addnodes.index,\n                entries=[('single', 'Inner (Outer class)', 'Outer.Inner', '', None)])\n    assert 'Outer.Inner' in domain.objects\n    assert domain.objects['Outer.Inner'] == ('index', 'Outer.Inner', 'class', False)\n\n    assert_node(doctree[1][1][1][1][1], ([desc_signature, ([desc_annotation, \"method \"],\n                                                          [desc_addname, \"Outer.Inner.\"],\n                                                          [desc_name, \"method\"],\n                                                          [desc_parameterlist, ()])],\n                                         [desc_content, ()]))\n    assert_node(doctree[1][1][1][1][1], addnodes.index,\n                entries=[('single', 'method() (Outer.Inner method)', 'Outer.Inner.method', '', None)])\n    assert 'Outer.Inner.method' in domain.objects\n    assert domain.objects['Outer.Inner.method'] == ('index', 'Outer.Inner.method', 'method', False)\n"], "sample_818": ["def test_spectral_clustering_with_eigen_solver_lobpcg():\n    # Test that spectral_clustering is the same for lobpcg solver\n    # Based on toy example from plot_segmentation_toy.py\n\n    # a small two coin image\n    x, y = np.indices((40, 40))\n\n    center1, center2 = (14, 12), (20, 25)\n    radius1, radius2 = 8, 7\n\n    circle1 = (x - center1[0]) ** 2 + (y - center1[1]) ** 2 < radius1 ** 2\n    circle2 = (x - center2[0]) ** 2 + (y - center2[1]) ** 2 < radius2 ** 2\n\n    circles = circle1 | circle2\n    mask = circles.copy()\n    img = circles.astype(float)\n\n    graph = img_to_graph(img, mask=mask)\n    graph.data = np.exp(-graph.data / graph.data.std())\n\n    labels_lobpcg = spectral_clustering(\n        graph, n_clusters=2, eigen_solver='lobpcg', random_state=0)\n\n    assert len(np.unique(labels_lobpcg)) == 2\n\n    labels_arpack = spectral_clustering(\n        graph, n_clusters=2, eigen_solver='arpack', random_state=0)\n    assert adjusted_rand_score(labels_lobpcg, labels_arpack) == 1\n"], "sample_435": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = \"!\"\n        html = widget.render(\"name\", value, {\"id\": \"id_password\"})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_1136": ["def test_Poly_from_domain_element_with_expression_domain():\n    dom = EX\n    assert Poly(dom(x+1), y, domain=dom).rep == DMP([dom(x+1)], dom)\n    dom = dom.get_field()\n    assert Poly(dom(x+1), y, domain=dom).rep == DMP([dom(x+1)], dom)\n"], "sample_705": ["def test_pytester_run_with_timeout_zero(pytester: Pytester) -> None:\n    testfile = pytester.makepyfile(\"def test_no_timeout(): pass\")\n\n    with pytest.raises(pytester.TimeoutExpired):\n        pytester.runpytest_subprocess(testfile, timeout=0)\n"], "sample_1047": ["def test_issue_10302_ext():\n    x = Symbol('x')\n    r = Symbol('r', real=True)\n    u = -(3*2**pi)**(1/pi) + 2*3**(1/pi)\n    i = u + u*I\n    assert (u + i).is_real is None  # w/o simplification this should fail\n    assert (1 + i).is_real is False\n    a = Dummy('a', zero=True)\n    assert (a + I).is_real is False\n    assert (a + r*I).is_real is None\n    assert (a + I).is_imaginary\n    assert (a + x + I).is_imaginary is None\n    assert (a + r*I + I).is_imaginary is None\n    assert (a + I).is_nonzero is True\n    assert (a + x + I).is_nonzero is None\n    assert (a + r*I + I).is_nonzero is None\n"], "sample_1193": ["def test_are_coplanar():\n    p1 = Point3D(0, 0, 0)\n    p2 = Point3D(1, 0, 0)\n    p3 = Point3D(0, 1, 0)\n    p4 = Point3D(1, 1, 0)\n    p5 = Point3D(0, 0, 1)\n    assert are_coplanar(p1, p2, p3, p4) is True\n    assert are_coplanar(p1, p2, p3, p5) is False\n    assert are_coplanar(p1, p2, p3, p4, p5) is False\n    assert are_coplanar(p1, p2, p3, p4, p5, p5) is False\n    assert are_coplanar(p1, p2, p3, p4, p5, p5, p5) is False\n    assert are_coplanar(p1, p2, p3, p4, p5, p5, p5, p5) is False\n    assert are_coplanar(p1, p2, p3, p4, p5, p5, p5, p5, p5) is False\n    assert are_coplanar(p1, p2, p3, p4, p5, p5, p5, p5, p5, p5) is False\n    assert are_coplanar(p1, p2, p3, p4, p5, p5, p5, p5, p5, p5, p5) is False\n    assert are_coplanar(p1, p2, p3, p4, p5, p5, p5, p5, p5, p5, p5, p5) is False\n    assert are_coplanar(p1, p2, p3, p4, p5, p5, p5, p5, p5, p5, p5, p5, p5) is False\n    assert are_coplanar(p1, p2, p3, p4, p5, p5, p5, p5, p5, p5, p5, p5, p5, p5) is False\n    assert are_coplan"], "sample_666": ["def test_capturing_and_logging_fundamentals_with_log_cli(testdir):\n    # here we check a fundamental feature\n    p = testdir.makepyfile(\n        \"\"\"\n        import sys, os\n        import py, logging\n        from _pytest import capture\n        cap = capture.MultiCapture(out=False, in_=False,\n                                     Capture=capture.SysCapture)\n        cap.start_capturing()\n\n        logging.warning(\"hello1\")\n        outerr = cap.readouterr()\n        print(\"suspend, captured %%s\" %%(outerr,))\n        logging.warning(\"hello2\")\n\n        cap.pop_outerr_to_orig()\n        logging.warning(\"hello3\")\n\n        outerr = cap.readouterr()\n        print(\"suspend2, captured %%s\" %% (outerr,))\n    \"\"\"\n    )\n    result = testdir.runpython(p, \"--log-cli-level\", \"WARNING\")\n    result.stdout.fnmatch_lines(\n        \"\"\"\n        suspend, captured*hello1*\n        suspend2, captured*WARNING:root:hello3*\n    \"\"\"\n    )\n    result.stderr.fnmatch_lines(\n        \"\"\"\n        WARNING:root:hello2\n    \"\"\"\n    )\n    assert \"atexit\" not in result.stderr.str()\n"], "sample_1115": ["def test_tensor_element():\n    L = TensorIndexType(\"L\")\n    i, j, k = tensor_indices(\"i j k\", L)\n    A = TensorHead(\"A\", [L, L])\n    te = TensorElement(A(i, j), {i: 1})\n    assert te.get_free_indices() == [j]\n    assert te.get_indices() == [1, j]\n    assert te.substitute_indices((j, k)) == TensorElement(A(i, k), {i: 1})\n    assert te.substitute_indices((j, -j)) == TensorElement(A(i, -j), {i: 1})\n    assert te.substitute_indices((-j, j)) == TensorElement(A(i, -j), {i: 1})\n    assert te.substitute_indices((-j, -j)) == TensorElement(A(i, j), {i: 1})\n    assert te.substitute_indices((i, j)) == TensorElement(A(j, j), {j: 1})\n    assert te.substitute_indices((i, -j)) == TensorElement(A(-j, j), {j: 1})\n    assert te.substitute_indices((-i, j)) == TensorElement(A(-j, j), {j: 1})\n    assert te.substitute_indices((-i, -j)) == TensorElement(A(j, j), {j: 1})\n"], "sample_466": ["def test_serialize_timezone(self):\n    \"\"\"\n    Test serialization of timezone objects.\n    \"\"\"\n    self.assertSerializedResultEqual(\n        datetime.timezone.utc,\n        (\"datetime.timezone.utc\", {\"import datetime\"}),\n    )\n    self.assertSerializedResultEqual(\n        get_default_timezone(),\n        (\"django.utils.timezone.get_default_timezone()\", {\"from django.utils import timezone\"}),\n    )\n    self.assertSerializedResultEqual(\n        get_fixed_timezone(180),\n        (\"django.utils.timezone.get_fixed_timezone(180)\", {\"from django.utils import timezone\"}),\n    )\n    self.assertSerializedResultEqual(\n        zoneinfo.ZoneInfo(\"Europe/Paris\"),\n        (\"zoneinfo.ZoneInfo('Europe/Paris')\", {\"import zoneinfo\"}),\n    )\n"], "sample_486": ["def test_inlineformset_factory_with_fk_name(self):\n    \"\"\"\n    Test that inlineformset_factory works correctly when fk_name is specified.\n    \"\"\"\n    FormSet = inlineformset_factory(\n        ParentWithUUIDAlternateKey, ChildRelatedViaAK, fk_name=\"parent\", fields=\"__all__\"\n    )\n    formset = FormSet()\n    self.assertIsNone(formset.forms[0].fields[\"parent\"].initial)\n"], "sample_403": ["def test_alter_field_with_func_unique_constraint_and_index(self):\n    app_label = \"test_alfuncucin\"\n    constraint_name = f\"{app_label}_pony_uq\"\n    index_name = f\"{app_label}_pony_idx\"\n    table_name = f\"{app_label}_pony\"\n    project_state = self.set_up_test_model(\n        app_label,\n        constraints=[\n            models.UniqueConstraint(\"pink\", \"weight\", name=constraint_name)\n        ],\n        indexes=[models.Index(Abs(\"pink\"), name=index_name)],\n    )\n    operation = migrations.AlterField(\n        \"Pony\", \"pink\", models.IntegerField(null=True)\n    )\n    new_state = project_state.clone()\n    operation.state_forwards(app_label, new_state)\n    with connection.schema_editor() as editor:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    if connection.features.supports_expression_indexes:\n        self.assertIndexNameExists(table_name, index_name)\n    with connection.schema_editor() as editor:\n        operation.database_backwards(app_label, editor, new_state, project_state)\n    if connection.features.supports_expression_indexes:\n        self.assertIndexNameExists(table_name, index_name)\n"], "sample_1140": ["def test_pretty_SingularityFunction():\n    assert xpretty(SingularityFunction(x, 0, n), use_unicode=True) == ("], "sample_682": ["def test_xfail_with_invalid_strict_value(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(strict=\"invalid\")\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxs\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*TypeError:*xfail*strict*must be a boolean*\",\n        ]\n    )\n"], "sample_679": ["def test_mark_evaluator_invalidraise(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.skipif(\"1 == 1\", raises=RuntimeError)\n            raise ValueError(\"Test error\")\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    passed, skipped, failed = reprec.listoutcomes()\n    assert len(skipped) == 1\n    assert len(failed) == 0\n"], "sample_343": ["def test_generic_foreign_key_set(self):\n    question = Question.objects.create(text='Who?')\n    post = Post.objects.create(title='Answer')\n\n    post.parent = question\n    post.save()\n\n    self.assertEqual(post.parent, question)\n    self.assertEqual(post.object_id, question.pk)\n    self.assertEqual(post.content_type, question.content_type)\n\n    post.parent = None\n    post.save()\n\n    self.assertIsNone(post.parent)\n    self.assertIsNone(post.object_id)\n    self.assertIsNone(post.content_type)\n"], "sample_1059": ["def test_assoc_laguerre():\n    n = Symbol(\"n\")\n    a = Symbol(\"a\")\n\n    assert assoc_laguerre(0, a, x) == 1\n    assert assoc_laguerre(1, a, x) == a - x + 1\n    assert assoc_laguerre(2, a, x) == a**2/2 + 3*a/2 + x**2/2 + x*(-a - 2) + 1\n    assert assoc_laguerre(3, a, x) == a**3/6 + a**2 + 11*a/6 - x**3/6 + x**2*(a/2 + 3/2) + x*(-a**2/2 - 5*a/2 - 3) + 1\n\n    assert assoc_laguerre(n, a, 0) == binomial(a + n, a)\n\n    X = assoc_laguerre(n, a, x)\n    assert isinstance(X, assoc_laguerre)\n\n    assert assoc_laguerre(n, 0, x) == laguerre(n, x)\n\n    assert assoc_laguerre(n, a, oo) == (-1)**n*oo\n    assert assoc_laguerre(n, a, -oo) == oo\n\n    assert conjugate(assoc_laguerre(n, a, x)) == assoc_laguerre(n, conjugate(a), conjugate(x))\n\n    _k = Dummy('k')\n    assert assoc_laguerre(n, a, x).rewrite(\"polynomial\").dummy_eq(\n        gamma(n + a + 1)/factorial(n)*Sum(x**_k*RisingFactorial(-n, _k)/\n        (gamma(_k + a + 1)*factorial(_k)), (_k, 0, n)))\n\n    assert diff(assoc_laguerre(n, a, x), x) == -assoc_laguerre(n - 1, a + 1, x)\n    assert diff(assoc_laguerre(n, a, x), a).dummy_eq(Sum(assoc_laguerre(_k, a, x)/(-a + n), (_k, 0, n - 1)))\n\n    raises(ValueError, lambda: assoc_laguerre(-2.1, a, x))\n    raises(ValueError"], "sample_142": ["def test_model_form_metaclass_fields_for_model(self):\n    class TestModelForm(ModelForm):\n        class Meta:\n            model = Song\n            fields = ('title', 'album')\n\n    self.assertEqual(TestModelForm._meta.model, Song)\n    self.assertEqual(TestModelForm._meta.fields, ('title', 'album'))\n\n    class TestModelFormWithExclude(ModelForm):\n        class Meta:\n            model = Song\n            exclude = ('original_release',)\n\n    self.assertEqual(TestModelFormWithExclude._meta.model, Song)\n    self.assertEqual(TestModelFormWithExclude._meta.exclude, ('original_release',))\n\n    class TestModelFormWithFieldsAndExclude(ModelForm):\n        class Meta:\n            model = Song\n            fields = ('title', 'album')\n            exclude = ('original_release',)\n\n    self.assertEqual(TestModelFormWithFieldsAndExclude._meta.model, Song)\n    self.assertEqual(TestModelFormWithFieldsAndExclude._meta.fields, ('title', 'album'))\n    self.assertEqual(TestModelFormWithFieldsAndExclude._meta.exclude, ('original_release',))\n\n    class TestModelFormWithNoModel(ModelForm):\n        pass\n\n    with self.assertRaises(ValueError):\n        TestModelFormWithNoModel._meta.model\n\n    class TestModelFormWithNoFieldsOrExclude(ModelForm):\n        class Meta:\n            model = Song\n\n    with self.assertRaises(ImproperlyConfigured):\n        TestModelFormWithNoFieldsOrExclude._meta.model\n\n    class TestModelFormWithInvalidFields(ModelForm):\n        class Meta:\n            model = Song\n            fields = 'title'\n\n    with self.assertRaises(TypeError):\n        TestModelFormWithInvalidFields._meta.model\n\n    class TestModelFormWithInvalidExclude(ModelForm):\n        class Meta:\n            model = Song\n            exclude = 'title'\n\n    with self.assertRaises(TypeError):\n        TestModelFormWithInvalidExclude._meta.model\n"], "sample_124": ["def test_field_localization(self):\n    class LocalizedForm(Form):\n        localized_field = CharField(localize=True)\n        non_localized_field = CharField()\n\n    form = LocalizedForm({'localized_field': '1.234,56', 'non_localized_field': '1.234,56'})\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data['localized_field'], '1234.56')\n    self.assertEqual(form.cleaned_data['non_localized_field'], '1.234,56')\n"], "sample_1011": ["def test_octave_codeprinter():\n    # Test the OctaveCodePrinter class directly\n    printer = OctaveCodePrinter()\n    assert printer.doprint(x**2 + 2*x + 1) == \"x.^2 + 2*x + 1\"\n    assert printer.doprint(x**2 + 2*x + 1, assign_to='y') == \"y = x.^2 + 2*x + 1;\"\n    assert printer.doprint(x**2 + 2*x + 1, assign_to='y', inline=False) == \"y = x.^2 + 2*x + 1;\"\n"], "sample_186": ["def test_check_ordering_random(self):\n    class SongAdmin(admin.ModelAdmin):\n        ordering = ['?', 'title']\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'ordering' has the random ordering marker '?', \"\n            \"but contains other fields as well.\",\n            hint='Either remove the \"?\", or remove the other fields.',\n            obj=SongAdmin,\n            id='admin.E032',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_409": ["def test_i18n42(self):\n    \"\"\"\n    Escaping inside blocktranslate and translate works as if it was\n    directly in the template.\n    \"\"\"\n    output = self.engine.render_to_string(\"i18n42\", {\"anton\": \"\u03b1 & \u03b2\"})\n    self.assertEqual(output, \"\\\\u03b1 \\\\u0026 \\\\u03b2\")\n"], "sample_709": ["def test_pytester_makefile_bytes(pytester: Pytester) -> None:\n    pytester.makepyfile(b\"def test_foo(): pass\")\n    pytester.makepyfile(b\"def test_bar(): pass\", b\"def test_baz(): pass\")\n    pytester.makepyfile(b\"def test_qux(): pass\", custom=b\"def test_quux(): pass\")\n"], "sample_362": ["def test_alter_field_to_fk_dependency_other_app_with_through_model(self):\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author_fk],\n        [self.author_empty, self.book_with_multiple_authors_through_attribution],\n    )\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['CreateModel', 'AlterField'])\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '__first__')])\n"], "sample_659": ["def test_repr_traceback_entry_with_short_style(self):\n    with pytest.raises(ValueError) as excinfo:\n        int(\"qwe\")\n    entry = excinfo.traceback[-1]\n    fmt = FormattedExcinfo(style=\"short\")\n    reprentry = fmt.repr_traceback_entry(entry, excinfo)\n    assert reprentry.style == \"short\"\n    assert len(reprentry.lines) == 1\n    assert reprentry.reprfuncargs is None\n    assert reprentry.reprlocals is None\n    assert reprentry.reprfileloc is not None\n"], "sample_74": ["def test_signal_handling(self):\n        raise KeyboardInterrupt\n    with mock.patch('subprocess.run', new=_mock_subprocess_run):\n        with self.assertRaises(KeyboardInterrupt):\n            DatabaseClient.runshell_db({\n                'database': 'dbname',\n                'user': 'someuser',\n                'password': 'somepassword',\n                'host': 'somehost',\n                'port': '444',\n            })\n    self.assertEqual(signal.getsignal(signal.SIGINT), signal.SIG_IGN)\n"], "sample_1180": ["def test_issue_22684_2():\n    # Used to give an error\n    with evaluate(False):\n        Point(1, 2, 3)\n"], "sample_385": ["def test_get_select2_language(self):\n    with translation.override(\"en\"):\n        self.assertEqual(get_select2_language(), \"en\")\n    with translation.override(\"zh-hant-tw\"):\n        self.assertEqual(get_select2_language(), \"zh-TW\")\n    with translation.override(\"zh-hant\"):\n        self.assertEqual(get_select2_language(), \"zh-TW\")\n    with translation.override(\"zh\"):\n        self.assertEqual(get_select2_language(), \"zh-CN\")\n    with translation.override(\"fr\"):\n        self.assertEqual(get_select2_language(), \"fr\")\n    with translation.override(\"invalid\"):\n        self.assertIsNone(get_select2_language())\n"], "sample_631": ["    def test_redefined_outer_name_in_nested_function(self):\n        \"\"\"Make sure redefined outer name is detected in nested functions\"\"\"\n        node = astroid.parse(\n            \"\"\"\n            x = 1\n                x = 2\n            return inner\n        \"\"\"\n        )\n        with self.assertAddsMessages(\n            Message(\"redefined-outer-name\", node=node.body[0].body[1], args=\"x\", line=3)\n        ):\n            self.walk(node)\n"], "sample_919": ["def test_template_parameter_lists():\n    check('function', 'template<typename T> void f(T)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T, typename U> void f(T, U)', {2: 'I00E1f1T1U'})\n    check('function', 'template<typename T, typename U, typename V> void f(T, U, V)', {2: 'I000E1f1T1U1V'})\n    check('function', 'template<typename T, typename U, typename V, typename W> void f(T, U, V, W)', {2: 'I0000E1f1T1U1V1W'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X> void f(T, U, V, W, X)', {2: 'I00000E1f1T1U1V1W1X'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> void f(T, U, V, W, X, Y)', {2: 'I000000E1f1T1U1V1W1X1Y'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> void f(T, U, V, W, X, Y, Z)', {2: 'I0000000E1f1T1U1V1W1X1Y1Z'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A> void f(T, U, V, W, X, Y, Z, A)', {2: 'I00000000E1f1T1U1V1W1X1Y1Z1A'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A, typename B> void f(T, U, V, W, X, Y, Z, A, B)', {2: 'I000000000E1f1T1U1V1W1X1Y1Z1A1B'})\n    check('function', 'template<typename"], "sample_967": ["def test_mathjax_custom_delimiters(app, status, warning):\n    app.builder.build_all()\n\n    content = (app.outdir / 'index.html').read_text()\n    html = (r'<span class=\"math notranslate nohighlight\">\\s*'\n            r'\\(a\\^2\\+b\\^2=c\\^2\\)</span>')\n    assert re.search(html, content, re.S)\n\n    html = (r'<div class=\"math notranslate nohighlight\">\\s*'\n            r'\\[a\\^2\\+b\\^2=c\\^2\\]</div>')\n    assert re.search(html, content, re.S)\n"], "sample_318": ["    def test_prefix_default_language(self):\n        pattern = LocalePrefixPattern(prefix_default_language=True)\n        self.assertEqual(pattern.regex.pattern, '^en/')\n"], "sample_555": ["def test_fancyarrowpatch_units():\n    from datetime import datetime\n    # Smoke test to check that FancyArrowPatch works with units\n    dtime = datetime(2000, 1, 1)\n    fig, ax = plt.subplots()\n    arrow = FancyArrowPatch((0, dtime), (0.01, dtime))\n"], "sample_975": ["def test_nsolve_with_higher_degree_polynomial():\n    x = Symbol('x')\n    f = x**5 - 3*x**4 + 2*x**3 - x**2 + 1\n    assert nsolve(f, x, 1.5) == 1.0\n"], "sample_194": ["    def test_fields_and_opclasses_length_mismatch(self):\n        message = 'UniqueConstraint.fields and UniqueConstraint.opclasses must have the same number of elements.'\n        with self.assertRaisesMessage(ValueError, message):\n            models.UniqueConstraint(\n                fields=['name', 'color'],\n                name='name_color_unique',\n                opclasses=['text_pattern_ops'],\n            )\n"], "sample_236": ["def test_collector_add_dependency(self):\n    collector = Collector(using='default')\n    model1 = R\n    model2 = A\n    collector.add_dependency(model1, model2)\n    self.assertIn(model1._meta.concrete_model, collector.dependencies)\n    self.assertIn(model2._meta.concrete_model, collector.dependencies[model1._meta.concrete_model])\n"], "sample_443": ["    def setUp(self):\n        super().setUp()\n        self.dirname = self.mkdtemp()\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n"], "sample_212": ["def test_session_middleware_process_response(self):\n    request = HttpRequest()\n    response = HttpResponse()\n    middleware = SessionMiddleware()\n\n    # Test when session is not accessed or modified\n    request.session = middleware.SessionStore('session_key')\n    response = middleware.process_response(request, response)\n    self.assertNotIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n    # Test when session is accessed but not modified\n    request.session.accessed = True\n    response = middleware.process_response(request, response)\n    self.assertIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n    # Test when session is modified\n    request.session.modified = True\n    response = middleware.process_response(request, response)\n    self.assertIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n    # Test when session is empty\n    request.session.is_empty = lambda: True\n    response = middleware.process_response(request, response)\n    self.assertNotIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n    # Test when session is deleted\n    request.session.delete = lambda: None\n    response = middleware.process_response(request, response)\n    self.assertNotIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n    # Test when session save fails\n    request.session.save = lambda: None\n    request.session.modified = True\n    with self.assertRaises(SuspiciousOperation):\n        middleware.process_response(request, response)\n"], "sample_297": ["    def test_ticket_24605(self):\n        \"\"\"\n        Subquery table names should be quoted.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(Individual.objects.filter(Q(alive=False), Q(related_individual__isnull=True)), [i4])\n        self.assertSequenceEqual(\n            Individual.objects.exclude(Q(alive=False), Q(related_individual__isnull=True)).order_by('pk'),\n            [i1, i2, i3]\n        )\n"], "sample_156": ["def test_order_fields_with_empty_list(self):\n    class TestForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n        field3 = CharField()\n        field_order = []\n\n    p = TestForm()\n    self.assertEqual(list(p.fields), ['field1', 'field2', 'field3'])\n"], "sample_452": ["def test_alter_model_table_comment_with_quotes(self):\n    app_label = \"test_almotacwoq\"\n    project_state = self.set_up_test_model(app_label)\n    pony_table = f\"{app_label}_pony\"\n    # Add table comment.\n    operation = migrations.AlterModelTableComment(\"Pony\", \"Custom pony comment 'with quotes'\")\n    self.assertEqual(operation.describe(), \"Alter Pony table comment\")\n    self.assertEqual(operation.migration_name_fragment, \"alter_pony_table_comment\")\n    new_state = project_state.clone()\n    operation.state_forwards(app_label, new_state)\n    self.assertEqual(\n        new_state.models[app_label, \"pony\"].options[\"db_table_comment\"],\n        \"Custom pony comment 'with quotes'\",\n    )\n    self.assertTableCommentNotExists(pony_table)\n    with connection.schema_editor() as editor:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    self.assertTableComment(pony_table, \"Custom pony comment 'with quotes'\")\n    # Reversal.\n    with connection.schema_editor() as editor:\n        operation.database_backwards(app_label, editor, new_state, project_state)\n    self.assertTableCommentNotExists(pony_table)\n    # Deconstruction.\n    definition = operation.deconstruct()\n    self.assertEqual(definition[0], \"AlterModelTableComment\")\n    self.assertEqual(definition[1], [])\n    self.assertEqual(\n        definition[2], {\"name\": \"Pony\", \"table_comment\": \"Custom pony comment 'with quotes'\"}\n    )\n"], "sample_1120": ["def test_matrix_element_subs():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    assert A[0, 0].subs(A, B) == B[0, 0]\n    assert A[0, 1].subs(A, B) == B[0, 1]\n    assert A[1, 0].subs(A, B) == B[1, 0]\n    assert A[1, 1].subs(A, B) == B[1, 1]\n    assert A[0, 0].subs(A, Matrix([[1, 2], [3, 4]])) == 1\n    assert A[0, 1].subs(A, Matrix([[1, 2], [3, 4]])) == 2\n    assert A[1, 0].subs(A, Matrix([[1, 2], [3, 4]])) == 3\n    assert A[1, 1].subs(A, Matrix([[1, 2], [3, 4]])) == 4\n"], "sample_34": ["def test_compose_with_dimensionless():\n    # Issue #3056\n    assert (u.m / u.s).compose(units=[u.km, u.dimensionless_unscaled])\n    assert (u.m / u.s).compose(units=[u.km, u.dimensionless_unscaled, u.dimensionless_unscaled])\n"], "sample_368": ["def test_detect_soft_applied_add_field_non_manytomanyfield(self):\n    \"\"\"\n    executor.detect_soft_applied() detects non-ManyToManyField tables from an\n    AddField operation.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Create the tables for 0001 but make it look like the migration hasn't\n    # been applied.\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n    executor.migrate([(\"migrations\", None)], fake=True)\n    # Table detection sees 0001 is applied.\n    migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], True)\n    # Create the tables for both migrations but make it look like neither\n    # has been applied.\n    executor.loader.build_graph()\n    executor.migrate([(\"migrations\", \"0001_initial\")], fake=True)\n    executor.migrate([(\"migrations\", \"0002_second\")])\n    executor.loader.build_graph()\n    executor.migrate([(\"migrations\", None)], fake=True)\n    # Table detection sees 0002 is applied.\n    migration = executor.loader.get_migration(\"migrations\", \"0002_second\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], True)\n    # Leave the tables for 0001 except the non-many-to-many table. That missing\n    # table should cause detect_soft_applied() to return False.\n    with connection.schema_editor() as editor:\n        editor.execute(editor.sql_delete_table % {\"table\": \"migrations_author\"})\n    migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], False)\n    # Cleanup by removing the remaining tables.\n    with connection.schema_editor() as editor:\n        editor.execute(editor.sql_delete_table % {\"table\": \"migrations_tribble\"})\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_tribble\")\n"], "sample_994": ["def test_issue_12820():\n    # Test that using 'prec' as a keyword argument for Float raises a deprecation warning\n    with SymPyDeprecationWarning('Using \"prec=XX\" to denote decimal precision. '\n                                 'Use \"dps=XX\" for decimal precision and \"precision=XX\" '\n                                 'for binary precision'):\n        Float('1.0', prec=15)\n"], "sample_339": ["def test_model_formset_with_custom_save_method_and_commit_false(self):\n    class PoetForm(forms.ModelForm):\n            # change the name to \"Vladimir Mayakovsky\" just to be a jerk.\n            author = super().save(commit=False)\n            author.name = \"Vladimir Mayakovsky\"\n            if commit:\n                author.save()\n            return author\n\n    PoetFormSet = modelformset_factory(Poet, fields=\"__all__\", form=PoetForm)\n\n    data = {\n        'form-TOTAL_FORMS': '3',  # the number of forms rendered\n        'form-INITIAL_FORMS': '0',  # the number of forms with initial data\n        'form-MAX_NUM_FORMS': '',  # the max number of forms\n        'form-0-name': 'Walt Whitman',\n        'form-1-name': 'Charles Baudelaire',\n        'form-2-name': '',\n    }\n\n    qs = Poet.objects.all()\n    formset = PoetFormSet(data=data, queryset=qs)\n    self.assertTrue(formset.is_valid())\n\n    instances = formset.save(commit=False)\n    for instance in instances:\n        instance.save()\n    self.assertEqual(len(instances), 2)\n    poet1, poet2 = instances\n    self.assertEqual(poet1.name, 'Vladimir Mayakovsky')\n    self.assertEqual(poet2.name, 'Vladimir Mayakovsky')\n"], "sample_598": ["def test_summarize_variable(self):\n    var = xr.Variable(\"x\", np.arange(100), dims=\"x\")\n    col_width = 10\n    marker = \" \"\n    actual = formatting.summarize_variable(\"x\", var, col_width, marker)\n    expected = \"     x      (x) int64 0 ... 99\"\n    assert actual == expected\n\n    var = xr.Variable(\"x\", np.arange(100), dims=\"x\", attrs={\"units\": \"m\"})\n    col_width = 10\n    marker = \" \"\n    actual = formatting.summarize_variable(\"x\", var, col_width, marker)\n    expected = \"     x      (x) int64 0 ... 99\"\n    assert actual == expected\n\n    var = xr.Variable(\"x\", np.arange(100), dims=\"x\", attrs={\"units\": \"m\", \"description\": \"desc\"})\n    col_width = 10\n    marker = \" \"\n    actual = formatting.summarize_variable(\"x\", var, col_width, marker)\n    expected = \"     x      (x) int64 0 ... 99\"\n    assert actual == expected\n"], "sample_396": ["    def test_ticket_24605(self):\n        \"\"\"\n        Subquery table names should be quoted.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(\n            Individual.objects.filter(\n                Q(alive=False), Q(related_individual__isnull=True)\n            ),\n            [i4],\n        )\n        self.assertSequenceEqual(\n            Individual.objects.exclude(\n                Q(alive=False), Q(related_individual__isnull=True)\n            ).order_by(\"pk\"),\n            [i1, i2, i3],\n        )\n"], "sample_998": ["def test_latex_Morphism():\n    from sympy.categories import NamedMorphism\n    morphism = NamedMorphism(\"f\", \"A\", \"B\")\n    assert latex(morphism) == \"f:A\\\\rightarrow B\"\n"], "sample_1195": ["def test_gamma_trace():\n    i0,i1,i2,i3,i4,i5 = tensor_indices('i0:6', LorentzIndex)\n    p, q = tensor_heads('p, q', [LorentzIndex])\n\n    t = G(i0)*G(i1)\n    r = gamma_trace(t)\n    assert _is_tensor_eq(r, 4*LorentzIndex.metric(i0, i1))\n\n    t = G(i0)*p(-i0)*G(i1)*p(-i1)\n    r = gamma_trace(t)\n    assert _is_tensor_eq(r, 4*p(i0)*p(-i0))\n\n    t = G(i0)*p(-i0)*G(i1)*q(-i1)\n    r = gamma_trace(t)\n    assert _is_tensor_eq(r, 4*p(i0)*q(-i0))\n\n    t = G(i0)*G(i1)*G(i2)*G(i3)\n    r = gamma_trace(t)\n    assert _is_tensor_eq(r, 4*LorentzIndex.metric(i0, i1)*G(i2)*G(i3) - 4*LorentzIndex.metric(i0, i2)*G(i1)*G(i3) + 4*LorentzIndex.metric(i0, i3)*G(i1)*G(i2))\n\n    t = G(i0)*p(-i0)*G(i1)*q(-i1)*G(i2)*p(-i2)\n    r = gamma_trace(t)\n    assert _is_tensor_eq(r, 4*p(i0)*q(-i0)*G(i1)*p(-i1) + 4*p(i0)*p(-i0)*G(i1)*q(-i1))\n"], "sample_49": ["def test_split_datetime_widget(self):\n    ###############################################################\n    # SplitDateTimeWidget\n    ###############################################################\n\n    class MyWidget(SplitDateTimeWidget):\n            super().__init__(attrs, date_format, time_format, date_attrs, time_attrs)\n\n    widget = MyWidget()\n    self.assertEqual(widget.template_name, 'django/forms/widgets/splitdatetime.html')\n    self.assertFalse(widget.supports_microseconds)\n\n    widget = MyWidget(date_format='%Y-%m-%d', time_format='%H:%M:%S')\n    self.assertEqual(widget.widgets[0].format, '%Y-%m-%d')\n    self.assertEqual(widget.widgets[1].format, '%H:%M:%S')\n\n    widget = MyWidget(date_attrs={'class': 'date'})\n    self.assertEqual(widget.widgets[0].attrs, {'class': 'date'})\n\n    widget = MyWidget(time_attrs={'class': 'time'})\n    self.assertEqual(widget.widgets[1].attrs, {'class': 'time'})\n\n    value = datetime.datetime(2022, 1, 1, 12, 0, 0)\n    decompressed = widget.decompress(value)\n    self.assertEqual(decompressed, [datetime.date(2022, 1, 1), datetime.time(12, 0, 0)])\n\n    value = None\n    decompressed = widget.decompress(value)\n    self.assertEqual(decompressed, [None, None])\n"], "sample_987": ["def test_evalf_piecewise():\n    from sympy import Piecewise\n    pw = Piecewise((1, x > 0), (0, x < 0))\n    assert NS(pw, subs={x: 1}) == '1.00000000000000'\n    assert NS(pw, subs={x: -1}) == '0.000000000000000'\n    assert NS(pw, subs={x: 0}) == '0.000000000000000'\n    pw = Piecewise((1, x > 0), (0, x < 0), (2, True))\n    assert NS(pw, subs={x: 1}) == '1.00000000000000'\n    assert NS(pw, subs={x: -1}) == '0.000000000000000'\n    assert NS(pw, subs={x: 0}) == '2.00000000000000'\n"], "sample_542": ["def test_text_repr_with_non_string_input():\n    # Test that text repr doesn't error for non-string input\n    fig, ax = plt.subplots()\n    ax.text(0.5, 0.5, 123)\n    ax.text(0.5, 0.5, [1, 2, 3])\n    ax.text(0.5, 0.5, (1, 2, 3))\n    ax.text(0.5, 0.5, {'a': 1, 'b': 2})\n    ax.text(0.5, 0.5, None)\n    repr(ax.text(0.5, 0.5, 'Boo'))\n"], "sample_334": ["def test_order_fields_with_empty_list(self):\n    class TestForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n        field3 = CharField()\n        field_order = []\n\n    p = TestForm()\n    self.assertEqual(list(p.fields), ['field1', 'field2', 'field3'])\n"], "sample_835": ["def test_adaboost_regressor_feature_importances():\n    # Check feature importances for AdaBoostRegressor.\n    X, y = datasets.make_regression(n_samples=2000,\n                                    n_features=10,\n                                    n_informative=3,\n                                    n_redundant=0,\n                                    n_repeated=0,\n                                    shuffle=False,\n                                    random_state=1)\n\n    clf = AdaBoostRegressor()\n\n    clf.fit(X, y)\n    importances = clf.feature_importances_\n\n    assert importances.shape[0] == 10\n    assert (importances[:3, np.newaxis] >= importances[3:]).all()\n"], "sample_305": ["def test_lookup_type(self):\n    # Test that the lookup type is correctly determined\n    self.assertIsInstance(Book.objects.filter(name__exact='test'), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__iexact='test'), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__contains='test'), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__icontains='test'), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__startswith='test'), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__istartswith='test'), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__endswith='test'), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__iendswith='test'), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__in=['test1', 'test2']), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__range=('test1', 'test2')), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__isnull=True), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__regex='test'), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__iregex='test'), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__year='2022'), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__year__gt='2022'), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__year__gte='2022'), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__year__lt='2022'), QuerySet)\n    self.assertIsInstance(Book.objects.filter(name__year__lte='2022'), QuerySet)\n"], "sample_964": ["def test_python_domain_find_obj_with_aliased(app):\n    text = (\".. py:class:: Class\\n\"\n            \".. py:class:: Class\\n\"\n            \"   :canonical: Class\")\n    domain = app.env.get_domain('py')\n    restructuredtext.parse(app, text)\n    assert len(domain.objects) == 2\n    assert domain.objects['Class'] == ('index', 'Class', 'class', False)\n    assert domain.objects['Class'] == ('index', 'Class', 'class', True)\n"], "sample_741": ["def test_grid_search_refit_callable():\n    # Test that refit can be a callable\n    X, y = make_classification(n_samples=50, n_features=4, random_state=42)\n\n    n_splits = 3\n    params = [dict(kernel=['rbf', ], C=[1, 10], gamma=[0.1, 1]),\n              dict(kernel=['poly', ], degree=[1, 2])]\n\n        return 'accuracy' if search.best_score_ > 0.5 else 'recall'\n\n    grid_search = GridSearchCV(SVC(gamma='scale'), cv=n_splits,\n                               param_grid=params, scoring=('accuracy', 'recall'),\n                               refit=refit_callable)\n    grid_search.fit(X, y)\n    assert_true(hasattr(grid_search, 'best_estimator_'))\n    assert_true(hasattr(grid_search, 'best_score_'))\n    assert_true(hasattr(grid_search, 'best_params_'))\n    assert_true(hasattr(grid_search, 'best_index_'))\n"], "sample_357": ["def test_alter_field_to_m2m(self):\n    \"\"\"\n    #23938 - Changing a concrete field into a ManyToManyField\n    first removes the concrete field and then adds the m2m field.\n    \"\"\"\n    changes = self.get_changes([self.author_with_former_m2m], [self.author_with_m2m, self.publisher])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\", \"RemoveField\", \"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Publisher')\n    self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"publishers\", model_name='author')\n    self.assertOperationAttributes(changes, 'testapp', 0, 2, name=\"publishers\", model_name='author')\n"], "sample_1033": ["def test_Add_primitive():\n    x, y = symbols('x y')\n    assert (2*x + 4*y).primitive() == (2, x + 2*y)\n    assert (2*x/3 + 4*y/9).primitive() == (2/9, 3*x + 2*y)\n    assert (2*x/3 + 4.2*y).primitive() == (1/3, 2*x + 12.6*y)\n    assert ((2 + 2*x)*x + 2).primitive() == (1, x*(2*x + 2) + 2)\n    assert ((2 + 2*x)*x + 2).as_content_primitive() == (2, x*(x + 1) + 1)\n"], "sample_358": ["    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(),\n            col_suffixes=('ASC', 'DESC'), opclasses=('varchar_pattern_ops', 'text_pattern_ops')\n        )\n"], "sample_489": ["def test_update_conflicts_with_default_values(self):\n    UpsertConflict.objects.bulk_create(\n        [\n            UpsertConflict(number=1, rank=1, name=\"John\"),\n            UpsertConflict(number=2, rank=2, name=\"Mary\"),\n            UpsertConflict(number=3, rank=3, name=\"Hannah\"),\n        ]\n    )\n    self.assertEqual(UpsertConflict.objects.count(), 3)\n\n    conflicting_objects = [\n        UpsertConflict(number=1, rank=4, name=\"Steve\"),\n        UpsertConflict(number=2, rank=2, name=\"Olivia\"),\n        UpsertConflict(number=3, rank=1, name=\"Hannah\"),\n    ]\n    results = UpsertConflict.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        update_fields=[\"name\", \"rank\"],\n        unique_fields=[\"number\"],\n    )\n    self.assertEqual(len(results), len(conflicting_objects))\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(UpsertConflict.objects.count(), 3)\n    self.assertCountEqual(\n        UpsertConflict.objects.values(\"number\", \"rank\", \"name\"),\n        [\n            {\"number\": 1, \"rank\": 4, \"name\": \"Steve\"},\n            {\"number\": 2, \"rank\": 2, \"name\": \"Olivia\"},\n            {\"number\": 3, \"rank\": 1, \"name\": \"Hannah\"},\n        ],\n    )\n\n    results = UpsertConflict.objects.bulk_create(\n        conflicting_objects + [UpsertConflict(number=4, rank=4, name=\"Mark\")],\n        update_conflicts=True,\n        update_fields=[\"name\", \"rank\"],\n        unique_fields=[\"number\"],\n    )\n    self.assertEqual(len(results), 4)\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(UpsertConflict.objects.count(), 4)\n    self.assertCountEqual(\n        UpsertConflict.objects.values(\"number\", \"rank\", \"name\"),\n        [\n            {\"number\": 1, \"rank\": 4, \"name\": \"Steve\"},\n            {\"number\": 2, \"rank\": 2, \"name\": \"Olivia\"},\n            {\"number\": 3, \"rank\": 1, \"name\": \"Hannah\"},\n            {\"number\": 4, \"rank\": 4,"], "sample_872": ["def test_roc_auc_score_multiclass_average_error():\n    # Test that roc_auc_score function returns an error when trying\n    # to compute multiclass AUC for parameters where an output\n    # is not defined.\n    rng = check_random_state(404)\n    y_score = rng.rand(20, 3)\n    y_prob = softmax(y_score)\n    y_true = rng.randint(0, 3, size=20)\n    with pytest.raises(ValueError, match=r\"average must be one of \\('macro', 'weighted', None\\) for multiclass problems\"):\n        roc_auc_score(y_true, y_prob, average=\"samples\", multi_class=\"ovr\")\n"], "sample_316": ["    def test_image_file_dimensions(self):\n        \"\"\"\n        ImageFile should return the correct dimensions.\n        \"\"\"\n        img_path = os.path.join(os.path.dirname(__file__), \"test.png\")\n        with open(img_path, 'rb') as fh:\n            image_file = images.ImageFile(fh)\n            self.assertEqual(image_file.width, 540)\n            self.assertEqual(image_file.height, 405)\n"], "sample_338": ["def test_alter_model_options_proxy_to_mti(self):\n    \"\"\"Changing a proxy model's options to MTI should also make a change.\"\"\"\n    changes = self.get_changes(\n        [self.author_proxy, self.author_empty], [self.author_proxy_notproxy, self.author_empty]\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"DeleteModel\", \"CreateModel\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"AuthorProxy\")\n    self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"AuthorProxy\", options={})\n"], "sample_248": ["def test_shell_with_no_interface_available(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import python interface.\"):\n        call_command('shell')\n"], "sample_881": ["def test_roc_auc_score_multiclass_average_error():\n    # Test that roc_auc_score function returns an error when trying\n    # to compute multiclass AUC for parameters where an output\n    # is not defined.\n    rng = check_random_state(404)\n    y_score = rng.rand(20, 3)\n    y_prob = softmax(y_score)\n    y_true = rng.randint(0, 3, size=20)\n    with pytest.raises(ValueError, match=\"average must be one of\"):\n        roc_auc_score(y_true, y_prob, average=\"invalid\")\n"], "sample_86": ["def test_lazy_object(self):\n    \"\"\"Test the LazyObject class.\"\"\"\n    class TestClass:\n            self.value = value\n\n            return self.value\n\n    lazy_obj = SimpleLazyObject(lambda: TestClass(42))\n    self.assertEqual(lazy_obj._wrapped, empty)\n\n    # Test that the object is initialized when an attribute is accessed.\n    self.assertEqual(lazy_obj.value, 42)\n    self.assertEqual(lazy_obj._wrapped.value, 42)\n\n    # Test that the object is initialized when a method is called.\n    self.assertEqual(lazy_obj.method(), 42)\n    self.assertEqual(lazy_obj._wrapped.method(), 42)\n\n    # Test that the object is not reinitialized when an attribute is accessed again.\n    lazy_obj.value = 24\n    self.assertEqual(lazy_obj.value, 24)\n    self.assertEqual(lazy_obj._wrapped.value, 24)\n\n    # Test that the object is not reinitialized when a method is called again.\n    lazy_obj.method = mock.Mock(return_value=24)\n    self.assertEqual(lazy_obj.method(), 24)\n    self.assertEqual(lazy_obj._wrapped.method(), 24)\n\n    # Test that the object is not reinitialized when it is copied.\n    copied_obj = copy.copy(lazy_obj)\n    self.assertEqual(copied_obj.value, 24)\n    self.assertEqual(copied_obj._wrapped.value, 24)\n\n    # Test that the object is not reinitialized when it is deep copied.\n    deep_copied_obj = copy.deepcopy(lazy_obj)\n    self.assertEqual(deep_copied_obj.value, 24)\n    self.assertEqual(deep_copied_obj._wrapped.value, 24)\n"], "sample_3": ["def test_multidim_masked_array_with_missing_values():\n    \"\"\"Test a multidimensional masked array with missing values\"\"\"\n    t = Table()\n    t['a'] = np.ma.array(np.arange(12).reshape(2, 3, 2), dtype=np.int64)\n    t['a'].mask[0, 0, 0] = True\n    t['a'].mask[1, 1, 1] = True\n    t['a'].mask[0, 1, 0] = True\n    t['b'] = ['x', 'y']  # Add another column for kicks\n    out = StringIO()\n    t.write(out, format='ascii.ecsv')\n    t2 = Table.read(out.getvalue(), format='ascii.ecsv')\n\n    assert t2.masked is False\n    assert t2.colnames == t.colnames\n    for name in t2.colnames:\n        assert t2[name].dtype == t[name].dtype\n        if hasattr(t[name], 'mask'):\n            assert np.all(t2[name].mask == t[name].mask)\n        assert np.all(t2[name] == t[name])\n"], "sample_412": ["def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            \"Search for google.com/?q=!.\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>!.'),\n        ),\n        (\n            \"Search for google.com/?q=1&lt!,\",\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>!,'),\n        ),\n        (\n            lazystr(\"Search for google.com/?q=!\"),\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>!'),\n        ),\n        (\n            \"foo@example.com.\",\n            '<a href=\"mailto:foo@example.com\">foo@example.com</a>.'),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_715": ["def test_cross_val_predict_with_method_and_groups():\n    # Test that cross_val_predict works with groups and methods\n    X = np.arange(200).reshape(100, 2)\n    y = np.array([x//10 for x in range(100)])\n    groups = np.array([x//10 for x in range(100)])\n    classes = 10\n\n    kfold = GroupKFold(n_splits=3)\n\n    methods = ['decision_function', 'predict_proba', 'predict_log_proba']\n    for method in methods:\n        est = LogisticRegression()\n\n        predictions = cross_val_predict(est, X, y, groups=groups, method=method,\n                                        cv=kfold)\n\n        expected_predictions = get_expected_predictions(X, y, kfold, classes,\n                                                        est, method)\n        assert_array_almost_equal(expected_predictions, predictions)\n"], "sample_1128": ["def test_point_partial_velocity_multiple_gen_speeds():\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n\n    p = Point('p')\n\n    u1, u2, u3 = dynamicsymbols('u1, u2, u3')\n\n    p.set_vel(N, u1 * A.x + u2 * N.y + u3 * A.z)\n\n    assert p.partial_velocity(N, u1, u2, u3) == (A.x, N.y, A.z)\n    assert p.partial_velocity(N, u1, u3) == (A.x, A.z)\n    assert p.partial_velocity(N, u2) == N.y\n"], "sample_854": ["def test_base_libsvm_fit_sparse():\n    # Test that BaseLibSVM.fit works with sparse matrices\n    X = sparse.csr_matrix(X)\n    clf = svm.SVC(kernel='linear')\n    clf.fit(X, Y)\n    assert_array_equal(clf.predict(T), true_result)\n"], "sample_474": ["    def setUpTestData(cls):\n        cls.john = Author.objects.create(name=\"John Smith\", alias=\"smithj\")\n        cls.elena = Author.objects.create(name=\"\u00c9lena Jordan\", alias=\"elena\")\n        cls.rhonda = Author.objects.create(name=\"Rhonda\")\n"], "sample_547": ["def test_auxtransformbox():\n    # Test AuxTransformBox with a child DrawingArea\n    fig, ax = plt.subplots()\n    size = 100\n    da = DrawingArea(size, size)\n    aux_transform = mtransforms.Affine2D().rotate_deg(45)\n    aux_box = AuxTransformBox(aux_transform)\n    aux_box.add_artist(da)\n    bg = mpatches.Rectangle((0, 0), size, size,\n                            facecolor='#CCCCCC',\n                            edgecolor='None',\n                            linewidth=0)\n    line = mlines.Line2D([-size*.5, size*1.5], [size/2, size/2],\n                         color='black',\n                         linewidth=10)\n    da.add_artist(bg)\n    da.add_artist(line)\n    ax.add_artist(aux_box)\n    ax.set_xlim((0, 1))\n    ax.set_ylim((0, 1))\n    fig.canvas.draw()\n    assert not fig.stale\n"], "sample_1177": ["def test_polar_lift():\n    x = Symbol('x')\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == exp_polar(0)\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(-I*pi/2)\n    assert polar_lift(-I) == exp_polar(I*pi/2)\n    assert polar_lift(2 + I) == polar_lift(2 + I)\n    assert polar_lift(2*I) == 2*exp_polar(-I*pi/2)\n    assert polar_lift(-2*I) == 2*exp_polar(I*pi/2)\n    assert polar_lift(2) == 2*exp_polar(0)\n    assert polar_lift(-2) == 2*exp_polar(I*pi)\n    assert polar_lift(x) == polar_lift(x)\n    assert polar_lift(x*I) == I*polar_lift(x)\n    assert polar_lift(-x*I) == -I*polar_lift(x)\n    assert polar_lift(x**2) == polar_lift(x)**2\n    assert polar_lift(x**3) == polar_lift(x)**3\n    assert polar_lift(x**4) == polar_lift(x)**4\n    assert polar_lift(x**5) == polar_lift(x)**5\n    assert polar_lift(x**6) == polar_lift(x)**6\n    assert polar_lift(x**7) == polar_lift(x)**7\n    assert polar_lift(x**8) == polar_lift(x)**8\n    assert polar_lift(x**9) == polar_lift(x)**9\n    assert polar_lift(x**10) == polar_lift(x)**10\n    assert polar_lift(x**11) == polar_lift(x)**11\n    assert polar_lift(x**12) == polar_lift(x)**12\n    assert polar_lift(x**13) == polar_lift(x)**13\n    assert polar_lift(x**14) == polar_lift(x)**14\n    assert polar_lift(x**15) == polar_lift(x)**15\n    assert polar_lift(x**16) == polar_lift(x)**16\n    assert polar_lift(x**17) == polar_lift(x)**17\n    assert polar_lift(x**18) == polar_lift(x)**18\n    assert polar_lift(x**19) == polar_lift(x)**19\n    assert polar_lift(x**20) == polar_lift(x)**20\n    assert polar_lift(x**21"], "sample_999": ["def test_latex_issue_14243():\n    from sympy import symbols, Function\n    x = symbols('x')\n    f = Function('f')\n    assert latex(f(x, 2)) == r'f{\\left (x, 2 \\right )}'\n    assert latex(f(x, 2, 3)) == r'f{\\left (x, 2, 3 \\right )}'\n    assert latex(f(x, 2, 3, 4)) == r'f{\\left (x, 2, 3, 4 \\right )}'\n"], "sample_31": ["    def test_write_latex_latex_names_false(self, write, tmp_path, format):\n        \"\"\"Test to write a LaTeX file with latex_names=False\"\"\"\n        fp = tmp_path / \"test_write_latex_latex_names_false.tex\"\n        write(fp, format=format, latex_names=False)\n        tbl = QTable.read(fp)\n        # asserts each column name has not been converted to LaTeX format\n        for column_name in tbl.colnames[2:]:\n            assert column_name not in _FORMAT_TABLE.values()\n"], "sample_497": ["    def test_get_view_interval(self):\n        fig, ax = plt.subplots()\n        ax.set_xlim(0, 10)\n        ax.set_ylim(0, 10)\n        assert ax.xaxis.get_view_interval() == (0, 10)\n        assert ax.yaxis.get_view_interval() == (0, 10)\n"], "sample_692": ["def test_temp_path_factory_from_config(tmp_path):\n    config = FakeConfig(tmp_path)\n    factory = TempPathFactory.from_config(config, _ispytest=True)\n    assert factory.getbasetemp() == tmp_path\n\n    config = FakeConfig(None)\n    factory = TempPathFactory.from_config(config, _ispytest=True)\n    assert factory.getbasetemp().is_dir()\n\n    config = FakeConfig(tmp_path / \"subdir\")\n    factory = TempPathFactory.from_config(config, _ispytest=True)\n    assert factory.getbasetemp() == tmp_path / \"subdir\"\n"], "sample_1156": ["def test_hyperbolic_functions_with_finite():\n    x = Symbol('x')\n    assert sinh(x).is_finite is None\n    assert cosh(x).is_finite is None\n    assert tanh(x).is_finite is None\n    assert coth(x).is_finite is None\n    assert csch(x).is_finite is None\n    assert sech(x).is_finite is None\n    assert asinh(x).is_finite is None\n    assert acosh(x).is_finite is None\n    assert atanh(x).is_finite is None\n    assert acoth(x).is_finite is None\n    assert asech(x).is_finite is None\n    assert acsch(x).is_finite is None\n\n    x = Symbol('x', finite=True)\n    assert sinh(x).is_finite is True\n    assert cosh(x).is_finite is True\n    assert tanh(x).is_finite is True\n    assert coth(x).is_finite is None\n    assert csch(x).is_finite is None\n    assert sech(x).is_finite is True\n    assert asinh(x).is_finite is True\n    assert acosh(x).is_finite is True\n    assert atanh(x).is_finite is True\n    assert acoth(x).is_finite is True\n    assert asech(x).is_finite is True\n    assert acsch(x).is_finite is True\n"], "sample_1052": ["def test_fcode_matrixsymbol_slice_autoname_multiple_outputs():\n    # see issue #8093\n    A = MatrixSymbol('A', 2, 3)\n    name_expr = (\"test\", [A[:, 1], A[:, 2]])\n    result = codegen(name_expr, \"f95\", \"test\", header=False, empty=False)\n    source = result[0][1]\n    expected = (\n        \"subroutine test(A, out_%(hash1)s, out_%(hash2)s)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in), dimension(1:2, 1:3) :: A\\n\"\n        \"REAL*8, intent(out), dimension(1:2, 1:1) :: out_%(hash1)s\\n\"\n        \"REAL*8, intent(out), dimension(1:2, 1:1) :: out_%(hash2)s\\n\"\n        \"out_%(hash1)s(1, 1) = A(1, 2)\\n\"\n        \"out_%(hash1)s(2, 1) = A(2, 2)\\n\"\n        \"out_%(hash2)s(1, 1) = A(1, 3)\\n\"\n        \"out_%(hash2)s(2, 1) = A(2, 3)\\n\"\n        \"end subroutine\\n\"\n    )\n    # look for the magic numbers\n    a = source.splitlines()[3]\n    b = a.split('_')\n    out1 = b[1]\n    a = source.splitlines()[4]\n    b = a.split('_')\n    out2 = b[1]\n    expected = expected % {'hash1': out1, 'hash2': out2}\n    assert source == expected\n"], "sample_225": ["    def setUp(self):\n        self.site = admin.AdminSite()\n"], "sample_22": ["def test_matrix_transpose():\n    \"\"\"Test the matrix transpose function.\"\"\"\n    # Test with a single matrix\n    m = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    assert_allclose(matrix_transpose(m), m.T)\n\n    # Test with a stack of matrices\n    n = np.stack((m, m))\n    assert_allclose(matrix_transpose(n), n.swapaxes(-2, -1))\n\n    # Test with a non-square matrix (should raise an error)\n    with pytest.raises(ValueError):\n        matrix_transpose(np.array([[1, 2], [3, 4], [5, 6]]))\n"], "sample_1149": ["def test_S_call():\n    assert S(1) == 1\n    assert S(1.0) == 1.0\n    assert S(Rational(1, 2)) == Rational(1, 2)\n    assert S(\"x\") == Basic.Symbol(\"x\")\n    assert S(\"x**2\") == Basic.Symbol(\"x\")**2\n"], "sample_307": ["def test_f_format(self):\n    dt = datetime(2009, 5, 16, 5, 30)\n    self.assertEqual(dateformat.format(dt, 'f'), '5:30')\n    dt = datetime(2009, 5, 16, 5, 0)\n    self.assertEqual(dateformat.format(dt, 'f'), '5')\n"], "sample_350": ["def test_union_with_values_list_and_order_on_annotation_with_nulls(self):\n    qs1 = Number.objects.annotate(\n        annotation=Value(-1),\n        multiplier=F('annotation'),\n    ).filter(num__gte=6)\n    qs2 = Number.objects.annotate(\n        annotation=Value(2),\n        multiplier=F('annotation'),\n    ).filter(num__lte=5)\n    self.assertSequenceEqual(\n        qs1.union(qs2).order_by('annotation', 'num').values_list('num', flat=True),\n        [6, 7, 8, 9, 0, 1, 2, 3, 4, 5],\n    )\n    self.assertQuerysetEqual(\n        qs1.union(qs2).order_by(\n            F('annotation') * F('multiplier'),\n            'num',\n        ).values('num'),\n        [6, 7, 8, 9, 0, 1, 2, 3, 4, 5],\n        operator.itemgetter('num'),\n    )\n    qs1 = Number.objects.annotate(\n        annotation=Value(None),\n        multiplier=F('annotation'),\n    ).filter(num__gte=6)\n    qs2 = Number.objects.annotate(\n        annotation=Value(2),\n        multiplier=F('annotation'),\n    ).filter(num__lte=5)\n    self.assertSequenceEqual(\n        qs1.union(qs2).order_by('annotation', 'num').values_list('num', flat=True),\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n    )\n    self.assertQuerysetEqual(\n        qs1.union(qs2).order_by(\n            F('annotation') * F('multiplier'),\n            'num',\n        ).values('num'),\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        operator.itemgetter('num'),\n    )\n"], "sample_662": ["def test_base_report_properties(self, testdir):\n    \"\"\"Test that the properties of BaseReport are correctly implemented.\"\"\"\n    reprec = testdir.inline_runsource(\n        \"\"\"\n    \"\"\"\n    )\n    reports = reprec.getreports(\"pytest_runtest_logreport\")\n    assert len(reports) == 3\n    test_a_call = reports[1]\n    assert test_a_call.passed is False\n    assert test_a_call.failed is True\n    assert test_a_call.skipped is False\n    assert test_a_call.fspath == testdir.tmpdir.join(\"test_base_report_properties.py\")\n    assert test_a_call.count_towards_summary is True\n    assert test_a_call.head_line == \"test_a\"\n\n    # Test that the properties are read-only\n    with pytest.raises(AttributeError):\n        test_a_call.passed = True\n    with pytest.raises(AttributeError):\n        test_a_call.failed = False\n    with pytest.raises(AttributeError):\n        test_a_call.skipped = True\n    with pytest.raises(AttributeError):\n        test_a_call.fspath = \"new_path\"\n    with pytest.raises(AttributeError):\n        test_a_call.count_towards_summary = False\n    with pytest.raises(AttributeError):\n        test_a_call.head_line = \"new_head_line\"\n"], "sample_120": ["def test_register_serializer(self):\n    Serializer.register(type, ComplexSerializer)\n    self.assertSerializedResultEqual(\n        type,\n        (\"complex(<class 'type'>)\", set())\n    )\n    Serializer.unregister(type)\n    with self.assertRaises(ValueError):\n        self.assertSerializedResultEqual(\n            type,\n            (\"complex(<class 'type'>)\", set())\n        )\n"], "sample_943": ["def test_is_packagedir(tempdir):\n    (tempdir / 'testpkg').makedirs()\n    (tempdir / 'testpkg' / '__init__.py').write_text('')\n    assert is_packagedir(tempdir / 'testpkg')\n\n    (tempdir / 'testpkg' / '__init__.py').remove()\n    assert not is_packagedir(tempdir / 'testpkg')\n\n    (tempdir / 'testpkg' / 'example.py').write_text('')\n    assert not is_packagedir(tempdir / 'testpkg')\n"], "sample_98": ["    def test_broken_pipe_error_logging(self):\n        conn = HTTPConnection(LiveServerViews.server_thread.host, LiveServerViews.server_thread.port)\n        try:\n            conn.request('GET', '/example_view/', headers={'Connection': 'keep-alive'})\n            response = conn.getresponse()\n            self.assertFalse(response.will_close)\n            self.assertEqual(response.status, 200)\n            self.assertIsNone(response.getheader('Connection'))\n\n            # Simulate a broken pipe by closing the connection before reading the response\n            conn.close()\n\n            # Try to read the response again to trigger the broken pipe error\n            with self.assertRaises(HTTPError):\n                conn.getresponse()\n        finally:\n            conn.close()\n"], "sample_480": ["    def test_key_transform_text_lookup_mixin(self):\n        qs = NullableJSONModel.objects.annotate(\n            char_value=KeyTextTransform(\"foo\", \"value\"),\n        ).filter(char_value__startswith=\"bar\")\n        self.assertSequenceEqual(qs, [self.objs[7]])\n\n        qs = NullableJSONModel.objects.annotate(\n            char_value=KeyTextTransform(1, KeyTextTransform(\"bar\", \"value\")),\n        ).filter(char_value__startswith=\"bar\")\n        self.assertSequenceEqual(qs, [self.objs[7]])\n"], "sample_460": ["    def test_change_view_with_view_only_inlines_and_save_as_new(self):\n        \"\"\"\n        User with change permission to a section but view-only for inlines.\n        \"\"\"\n        self.viewuser.user_permissions.add(\n            get_perm(Section, get_permission_codename(\"change\", Section._meta))\n        )\n        self.client.force_login(self.viewuser)\n        # GET shows inlines.\n        response = self.client.get(\n            reverse(\"admin:admin_views_section_change\", args=(self.s1.pk,))\n        )\n        self.assertEqual(len(response.context[\"inline_admin_formsets\"]), 1)\n        formset = response.context[\"inline_admin_formsets\"][0]\n        self.assertEqual(len(formset.forms), 3)\n        # Valid POST changes the name.\n        data = {\n            \"name\": \"Can edit name with view-only inlines\",\n            \"article_set-TOTAL_FORMS\": \"3\",\n            \"article_set-INITIAL_FORMS\": \"3\",\n        }\n        response = self.client.post(\n            reverse(\"admin:admin_views_section_change\", args=(self.s1.pk,)), data\n        )\n        self.assertRedirects(response, reverse(\"admin:admin_views_section_changelist\"))\n        self.assertEqual(Section.objects.get(pk=self.s1.pk).name, data[\"name\"])\n        # Invalid POST reshows inlines.\n        del data[\"name\"]\n        response = self.client.post(\n            reverse(\"admin:admin_views_section_change\", args=(self.s1.pk,)), data\n        )\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(len(response.context[\"inline_admin_formsets\"]), 1)\n        formset = response.context[\"inline_admin_formsets\"][0]\n        self.assertEqual(len(formset.forms), 3)\n        # Save as new.\n        data = {\n            \"_saveasnew\": \"Save as new\",\n            \"name\": \"Can edit name with view-only inlines\",\n            \"article_set-TOTAL_FORMS\": \"3\",\n            \"article_set-INITIAL_FORMS\": \"3\",\n        }\n        response = self.client.post(\n            reverse(\"admin:admin_views_section_change\", args=(self.s1.pk,)), data\n        )\n        self.assertEqual(response.status_code, 302)  # redirect somewhere\n        self.assertEqual(Section.objects.count(), 2)\n        new_section = Section.objects.latest(\"id\")\n        self.assertRedirect"], "sample_134": ["def test_serialize_function_type(self):\n        pass\n\n    self.assertSerializedResultEqual(\n        test_function,\n        ('migrations.test_writer.test_function', {'import migrations.test_writer'})\n    )\n\n    class TestClass:\n            pass\n\n    self.assertSerializedResultEqual(\n        TestClass().test_method,\n        ('migrations.test_writer.TestClass().test_method', {'import migrations.test_writer'})\n    )\n\n    class TestClass2:\n        @staticmethod\n            pass\n\n    self.assertSerializedResultEqual(\n        TestClass2.test_static_method,\n        ('migrations.test_writer.TestClass2.test_static_method', {'import migrations.test_writer'})\n    )\n\n    class TestClass3:\n        @classmethod\n            pass\n\n    self.assertSerializedResultEqual(\n        TestClass3.test_class_method,\n        ('migrations.test_writer.TestClass3.test_class_method', {'import migrations.test_writer'})\n    )\n"], "sample_109": ["def test_render_options_with_translation(self):\n    with translation.override('fr'):\n        beatles = Band.objects.create(name='The Beatles', style='rock')\n        who = Band.objects.create(name='The Who', style='rock')\n        form = AlbumForm(initial={'band': beatles.pk})\n        output = form.as_table()\n        selected_option = '<option value=\"%s\" selected>The Beatles</option>' % beatles.pk\n        option = '<option value=\"%s\">The Who</option>' % who.pk\n        self.assertIn(selected_option, output)\n        self.assertNotIn(option, output)\n"], "sample_487": ["    def test_invalid_expression_with_function(self):\n        class TestModelAdmin(ModelAdmin):\n            ordering = (F(\"name__upper\"),)\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'ordering[0]' refers to 'name__upper', which is not \"\n            \"a field of 'modeladmin.ValidationTestModel'.\",\n            \"admin.E033\",\n        )\n"], "sample_640": ["def test_is_node_in_typing_guarded_import_block() -> None:\n    code = astroid.extract_node(\n        \"\"\"\n    from typing import TYPE_CHECKING\n    if TYPE_CHECKING:\n        from xyz import a  #@\n    \"\"\"\n    )\n    assert utils.is_node_in_typing_guarded_import_block(code[0])\n"], "sample_263": ["def test_dumpdata_with_file_output_and_indent(self):\n    management.call_command('loaddata', 'fixture1.json', verbosity=0)\n    self._dumpdata_assert(\n        ['fixtures'],\n        '[\\n    {\\n        \"pk\": 1,\\n        \"model\": \"fixtures.category\",\\n        \"fields\": {\\n            '\n        '\"description\": \"Latest news stories\",\\n            \"title\": \"News Stories\"\\n        }\\n    },\\n    {\\n        '\n        '\"pk\": 2,\\n        \"model\": \"fixtures.article\",\\n        \"fields\": {\\n            \"headline\": \"Poker has no '\n        'place on ESPN\",\\n            \"pub_date\": \"2006-06-16T12:00:00\"\\n        }\\n    },\\n    {\\n        \"pk\": 3,\\n        '\n        '\"model\": \"fixtures.article\",\\n        \"fields\": {\\n            \"headline\": \"Time to reform copyright\",\\n            '\n        '\"pub_date\": \"2006-06-16T13:00:00\"\\n        }\\n    }\\n]',\n        indent=4,\n        filename='dumpdata.json'\n    )\n"], "sample_609": ["def test_cov_corr_with_fill_value() -> None:\n    # Testing that xr.cov and xr.corr are consistent with each other\n    # 1. Broadcast the two arrays\n    da_a = xr.DataArray(\n        np.array([[1, 2, 3], [0.1, 0.2, 0.3], [3.2, 0.6, 1.8]]),\n        dims=(\"space\", \"time\"),\n        coords=[\n            (\"space\", [\"IA\", \"IL\", \"IN\"]),\n            (\"time\", pd.date_range(\"2000-01-01\", freq=\"1D\", periods=3)),\n        ],\n    )\n    da_b = xr.DataArray(\n        np.array([[0.2, 0.4, 0.6], [15, 10, 5], [3.2, 0.6, 1.8]]),\n        dims=(\"space\", \"time\"),\n        coords=[\n            (\"space\", [\"IA\", \"IL\", \"IN\"]),\n            (\"time\", pd.date_range(\"2000-01-01\", freq=\"1D\", periods=3)),\n        ],\n    )\n    da_a = da_a.fillna(0)\n    da_b = da_b.fillna(0)\n\n    expected = xr.cov(da_a, da_b, dim=\"time\", ddof=0) / (\n        da_a.std(dim=\"time\") * da_b.std(dim=\"time\")\n    )\n    actual = xr.corr(da_a, da_b, dim=\"time\")\n    assert_allclose(actual, expected)\n"], "sample_962": ["def test_ismock():\n    with mock(['unknown']):\n        import unknown\n        assert ismock(unknown) is True\n        assert ismock(unknown.secret) is True\n        assert ismock(unknown.secret.Class) is True\n        assert ismock(unknown.secret.Class()) is True\n\n    assert ismock(int) is False\n    assert ismock(str) is False\n    assert ismock(None) is False\n    assert ismock(Integral) is False\n    assert ismock(Struct) is False\n    assert ismock(TracebackType) is False\n    assert ismock(Any) is False\n    assert ismock(List) is False\n    assert ismock(Dict) is False\n    assert ismock(Tuple) is False\n    assert ismock(Callable) is False\n    assert ismock(Union) is False\n    assert ismock(Optional) is False\n    assert ismock(MyClass1) is False\n    assert ismock(MyClass2) is False\n    assert ismock(MyList) is False\n    assert ismock(MyInt) is False\n"], "sample_17": ["    def setup_method(self):\n        self.q = (\n            np.array(\n                [[ 1.0, -1.0,  2.0],\n                 [ 0.0,  3.0, -1.0],\n                 [-1.0, -1.0,  1.0]]\n            ) << u.m\n        )  # fmt: skip\n"], "sample_580": ["def test_categorical_order():\n    s = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\", \"c\"])\n    assert categorical_order(s) == [\"a\", \"b\", \"c\"]\n\n    s = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\", \"c\"], dtype=\"category\")\n    assert categorical_order(s) == [\"a\", \"b\", \"c\"]\n\n    s = pd.Series([1, 2, 3, 1, 2, 3])\n    assert categorical_order(s) == [1, 2, 3]\n\n    s = pd.Series([1, 2, 3, 1, 2, 3], dtype=\"category\")\n    assert categorical_order(s) == [1, 2, 3]\n\n    s = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\", \"c\"])\n    assert categorical_order(s, order=[\"c\", \"b\", \"a\"]) == [\"c\", \"b\", \"a\"]\n\n    s = pd.Series([1, 2, 3, 1, 2, 3])\n    assert categorical_order(s, order=[3, 2, 1]) == [3, 2, 1]\n\n    s = pd.Series([pd.NA, \"a\", \"b\", \"a\", \"b\"])\n    assert categorical_order(s) == [\"a\", \"b\"]\n\n    s = pd.Series([pd.NA, 1, 2, 1, 2])\n    assert categorical_order(s) == [1, 2]\n"], "sample_766": ["def test_dict_learning_online_return_code():\n    n_components = 5\n    dico = MiniBatchDictionaryLearning(n_components, n_iter=20, random_state=0)\n    dico.fit(X)\n    code = dico.transform(X)\n    assert_equal(code.shape, (n_samples, n_components))\n"], "sample_230": ["def test_bound_data(self):\n    field = JSONField()\n    data = '{\"a\": \"b\"}'\n    initial = '{\"c\": \"d\"}'\n    self.assertEqual(field.bound_data(data, initial), data)\n\n    field = JSONField(disabled=True)\n    self.assertEqual(field.bound_data(data, initial), initial)\n"], "sample_1133": ["def test_refraction_angle_edge_cases():\n    n1, n2 = symbols('n1, n2')\n    r1 = Ray3D(Point3D(-1, -1, 1), Point3D(0, 0, 0))\n    n = Matrix([0, 0, 1])\n    i = Matrix([1, 1, 1])\n    normal_ray = Ray3D(Point3D(0, 0, 0), Point3D(0, 0, 1))\n    P = Plane(Point3D(0, 0, 0), normal_vector=[0, 0, 1])\n\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=n, plane=P))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=normal_ray, plane=P))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=[0, 0, 1], plane=P))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=(0, 0, 1), plane=P))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=i, plane=P))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=n, plane=i))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=normal_ray, plane=i))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=[0, 0, 1], plane=i))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=(0, 0, 1), plane=i))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=i, plane=i))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=n, plane=n))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=normal_ray, plane=n))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=[0, 0, 1], plane=n))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1,"], "sample_160": ["def test_edge_cases(self):\n    # Test with very large decimal positions\n    self.assertEqual(nformat(1234, '.', decimal_pos=100), '1234.00')\n    self.assertEqual(nformat(1234.5678, '.', decimal_pos=100), '1234.567800000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_433": ["def test_alter_field_to_fk_dependency_other_app_with_custom_pk(self):\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author_fk],\n        [self.author_custom_pk, self.book],\n    )\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterField\"])\n    self.assertMigrationDependencies(\n        changes, \"otherapp\", 0, [(\"testapp\", \"__first__\")]\n    )\n"], "sample_364": ["    def test_include_with_namespace(self):\n        urlconf_module = 'tests.test_urls.include_urls'\n        namespace = 'my_namespace'\n        result = include((urlconf_module, 'app_name'), namespace)\n        self.assertEqual(result, (import_module(urlconf_module), 'app_name', namespace))\n"], "sample_729": ["def test_enet_path_with_sparse_X():\n    # Test that enet_path with sparse X gives the same result as with dense X\n    X, y, _, _ = build_dataset(n_samples=50, n_features=20)\n    X_sparse = sparse.csr_matrix(X)\n    for path in [enet_path, lasso_path]:\n        _, coefs, _ = path(X, y, fit_intercept=False)\n        _, sparse_coefs, _ = path(X_sparse, y, fit_intercept=False)\n        assert_array_almost_equal(coefs, sparse_coefs)\n"], "sample_595": ["def test_slice_replace_out_of_bounds(dtype):\n    da = lambda x: xr.DataArray(x).astype(dtype)\n    values = da([\"short\", \"a bit longer\", \"evenlongerthanthat\", \"\"])\n\n    expected = da([\"short\", \"a bit longer\", \"evenlongerthanthat\", \"\"])\n    result = values.str.slice_replace(100, 200)\n    assert_equal(result, expected)\n\n    expected = da([\"short\", \"a bit longer\", \"evenlongerthanthat\", \"\"])\n    result = values.str.slice_replace(-100, 200)\n    assert_equal(result, expected)\n\n    expected = da([\"short\", \"a bit longer\", \"evenlongerthanthat\", \"\"])\n    result = values.str.slice_replace(100, -200)\n    assert_equal(result, expected)\n\n    expected = da([\"short\", \"a bit longer\", \"evenlongerthanthat\", \"\"])\n    result = values.str.slice_replace(-100, -200)\n    assert_equal(result, expected)\n"], "sample_957": ["def test_get_type_hints():\n        pass\n\n    assert get_type_hints(func) == {'a': int, 'b': str, 'return': None}\n\n    class MyClass:\n            pass\n\n    assert get_type_hints(MyClass.__init__) == {'a': int, 'b': str, 'return': None}\n\n    class MyNewType(NewType('MyNewType', int)):\n        pass\n\n    assert get_type_hints(MyNewType) == {}\n\n    class MyGeneric(Generic[T]):\n            pass\n\n    assert get_type_hints(MyGeneric.__init__) == {'a': T, 'return': None}\n\n    class MyBrokenType:\n        __annotations__ = {'a': int, 'b': str}\n\n    assert get_type_hints(MyBrokenType) == {'a': int, 'b': str}\n\n    class MyForwardRef:\n        __annotations__ = {'a': 'int', 'b': 'str'}\n\n    assert get_type_hints(MyForwardRef) == {'a': 'int', 'b': 'str'}\n"], "sample_807": ["def test_calibration_curve_with_sample_weight():\n    \"\"\"Check calibration_curve function with sample weights\"\"\"\n    y_true = np.array([0, 0, 0, 1, 1, 1])\n    y_pred = np.array([0., 0.1, 0.2, 0.8, 0.9, 1.])\n    sample_weight = np.array([1, 2, 3, 4, 5, 6])\n    prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=2,\n                                             sample_weight=sample_weight)\n    assert_equal(len(prob_true), len(prob_pred))\n    assert_equal(len(prob_true), 2)\n    assert_almost_equal(prob_true, [0, 1])\n    assert_almost_equal(prob_pred, [0.1, 0.9])\n\n    # test that quantiles work as expected\n    y_true2 = np.array([0, 0, 0, 0, 1, 1])\n    y_pred2 = np.array([0., 0.1, 0.2, 0.5, 0.9, 1.])\n    sample_weight2 = np.array([1, 2, 3, 4, 5, 6])\n    prob_true_quantile, prob_pred_quantile = calibration_curve(\n        y_true2, y_pred2, n_bins=2, strategy='quantile',\n        sample_weight=sample_weight2)\n\n    assert len(prob_true_quantile) == len(prob_pred_quantile)\n    assert len(prob_true_quantile) == 2\n    assert_almost_equal(prob_true_quantile, [0, 2 / 3])\n    assert_almost_equal(prob_pred_quantile, [0.1, 0.8])\n"], "sample_711": ["def test_node_repr_failure_with_fulltrace(pytester: Pytester) -> None:\n    items = pytester.getitems(\n        \"\"\"\n            raise Exception(\"test exception\")\n    \"\"\"\n    )\n    item = items[0]\n    excinfo = pytest.raises(Exception, item.runtest)\n    with pytest.raises(ValueError, match=\"warning must be an instance of Warning or subclass\"):\n        item._repr_failure_py(excinfo, style=\"fulltrace\")\n    assert isinstance(item._repr_failure_py(excinfo, style=\"fulltrace\"), TerminalRepr)\n"], "sample_559": ["def test_inset_locator_with_transform():\n    fig, ax = plt.subplots(figsize=(5, 4))\n\n    # prepare the demo image\n    # Z is a 15x15 array\n    Z = cbook.get_sample_data(\"axes_grid/bivariate_normal.npy\")\n    extent = (-3, 4, -4, 3)\n    Z2 = np.zeros((150, 150))\n    ny, nx = Z.shape\n    Z2[30:30+ny, 30:30+nx] = Z\n\n    ax.imshow(Z2, extent=extent, interpolation=\"nearest\",\n              origin=\"lower\")\n\n    axins = zoomed_inset_axes(ax, 4, loc='upper right')\n    axins.imshow(Z2, extent=extent, interpolation=\"nearest\",\n                 origin=\"lower\")\n    axins.yaxis.get_major_locator().set_params(nbins=7)\n    axins.xaxis.get_major_locator().set_params(nbins=7)\n    # sub region of the original image\n    x1, x2, y1, y2 = -1.5, -0.9, -2.5, -1.9\n    axins.set_xlim(x1, x2)\n    axins.set_ylim(y1, y2)\n\n    plt.xticks(visible=False)\n    plt.yticks(visible=False)\n\n    # draw a bbox of the region of the inset axes in the parent axes and\n    # connecting lines between the bbox and the inset axes area\n    mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\",\n               transBounds=ax.transAxes)\n\n    asb = AnchoredSizeBar(ax.transData,\n                          0.5,\n                          '0.5',\n                          loc='lower center',\n                          pad=0.1, borderpad=0.5, sep=5,\n                          frameon=False)\n    ax.add_artist(asb)\n"], "sample_750": ["def test_omp_cv_multitarget():\n    ompcv = OrthogonalMatchingPursuitCV(normalize=True, fit_intercept=False,\n                                        max_iter=10, cv=5)\n    ompcv.fit(X, y)\n    assert_equal(ompcv.n_nonzero_coefs_, n_nonzero_coefs)\n    assert_array_almost_equal(ompcv.coef_, gamma)\n    omp = OrthogonalMatchingPursuit(normalize=True, fit_intercept=False,\n                                    n_nonzero_coefs=ompcv.n_nonzero_coefs_)\n    omp.fit(X, y)\n    assert_array_almost_equal(ompcv.coef_, omp.coef_)\n"], "sample_321": ["def test_rotate_token(self):\n    \"\"\"\n    The rotate_token function changes the CSRF token in use for a request.\n    \"\"\"\n    req = self._get_GET_csrf_cookie_request()\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.process_request(req)\n    original_token = req.META['CSRF_COOKIE']\n    rotate_token(req)\n    mw.process_request(req)\n    new_token = req.META['CSRF_COOKIE']\n    self.assertNotEqual(original_token, new_token)\n    self.assertEqual(len(new_token), CSRF_TOKEN_LENGTH)\n"], "sample_53": ["def test_render_options_translation(self):\n    with translation.override('fr'):\n        beatles = Band.objects.create(name='The Beatles', style='rock')\n        who = Band.objects.create(name='The Who', style='rock')\n        form = AlbumForm(initial={'band': beatles.pk})\n        output = form.as_table()\n        selected_option = '<option value=\"%s\" selected>Les Beatles</option>' % beatles.pk\n        option = '<option value=\"%s\">The Who</option>' % who.pk\n        self.assertIn(selected_option, output)\n        self.assertNotIn(option, output)\n"], "sample_36": ["def test_biweight_midcorrelation_inputs_M():\n    x = np.ones(5)\n    y = np.ones(5)\n    M = np.ones((3, 3))\n\n    with pytest.raises(ValueError) as e:\n        biweight_midcorrelation(x, y, M=M)\n        assert 'M must be a scalar or 1D array.' in str(e.value)\n"], "sample_399": ["def test_aggregation_default_with_distinct(self):\n    result = Book.objects.aggregate(\n        value=Sum(\"price\", distinct=True, default=Decimal(\"0.00\")),\n    )\n    self.assertEqual(result[\"value\"], Decimal(\"270.27\"))\n\n    result = Book.objects.filter(rating__lt=3.0).aggregate(\n        value=Sum(\"price\", distinct=True, default=Decimal(\"0.00\")),\n    )\n    self.assertEqual(result[\"value\"], Decimal(\"0.00\"))\n"], "sample_952": ["def test_isabstractmethod():\n    class AbstractClass:\n        @abstractmethod\n            pass\n\n    class ConcreteClass(AbstractClass):\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(ConcreteClass.abstract_method) is False\n"], "sample_363": ["    def test_render(self):\n        widget = widgets.AutocompleteSelect(\n            field=Band._meta.get_field('name'),\n            admin_site=widget_admin_site,\n        )\n        self.assertHTMLEqual(\n            widget.render('test', None),\n            '<select name=\"test\" class=\"admin-autocomplete\" '\n            'data-ajax--cache=\"true\" data-ajax--delay=\"250\" '\n            'data-ajax--type=\"GET\" data-ajax--url=\"/admin_widgets/autocomplete/\" '\n            'data-app-label=\"admin_widgets\" data-model-name=\"band\" '\n            'data-field-name=\"name\" data-theme=\"admin-autocomplete\" '\n            'data-allow-clear=\"false\" data-placeholder=\"\" lang=\"en\"></select>'\n        )\n"], "sample_299": ["    def test_relative_path(self):\n        with self.settings(CACHES={\n            'default': {\n                'BACKEND': 'django.core.cache.backends.filebased.FileBasedCache',\n                'LOCATION': 'cache',\n            },\n        }):\n            self.assertEqual(len(check_file_based_cache_is_absolute(None)), 1)\n"], "sample_201": ["def test_safedata(self):\n    \"\"\"\n    A message containing SafeData is keeping its safe status when\n    retrieved from the message storage.\n    \"\"\"\n        message = Message(constants.DEBUG, data)\n        encoded = storage._encode([message])\n        decoded = storage._decode(encoded)\n        return decoded[0].message\n\n    storage = self.get_storage()\n    self.assertIsInstance(encode_decode(mark_safe('safe')), SafeData)\n    self.assertNotIsInstance(encode_decode('unsafe'), SafeData)\n"], "sample_65": ["    def test_jsi18n_with_empty_packages(self):\n        \"\"\"\n        The javascript_catalog view should return an empty catalog when no packages are provided.\n        \"\"\"\n        view = JavaScriptCatalog.as_view()\n        request = RequestFactory().get('/')\n        response = view(request)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response['Content-Type'], 'text/javascript; charset=\"utf-8\"')\n        self.assertContains(response, 'django.catalog = {};')\n"], "sample_660": ["def test_record_testsuite_property_multiple_times(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", \"all good\")\n            record_testsuite_property(\"stats\", 10)\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p2_node = properties_node.find_nth_by_tag(\"property\", 1)\n    p1_node.assert_attr(name=\"stats\", value=\"all good\")\n    p2_node.assert_attr(name=\"stats\", value=\"10\")\n"], "sample_1166": ["def test_monomial_class():\n    m1 = Monomial((1, 2, 3))\n    m2 = Monomial((2, 3, 4))\n\n    assert m1.exponents == (1, 2, 3)\n    assert m1.gens is None\n\n    assert m1 == (1, 2, 3)\n    assert m1 != (2, 3, 4)\n\n    assert m1 * m2 == (3, 5, 7)\n    assert m1 / m2 == (0, 0, 0)\n\n    assert m1 ** 2 == (2, 4, 6)\n\n    assert m1.gcd(m2) == (1, 2, 3)\n    assert m1.lcm(m2) == (2, 3, 4)\n\n    assert m1.as_expr(x, y, z) == x*y**2*z**3\n\n    m3 = Monomial(x*y**2*z**3)\n    assert m3.exponents == (1, 2, 3)\n    assert m3.gens == (x, y, z)\n\n    raises(ValueError, lambda: Monomial(1))\n\n    raises(ValueError, lambda: Monomial(x + y))\n\n    raises(ValueError, lambda: Monomial(x*y**2*z**3, [x, y]))\n\n    raises(ExactQuotientFailed, lambda: m1 / Monomial((0, 0, 0)))\n\n    raises(ValueError, lambda: m1 ** -1)\n"], "sample_839": ["def test_vectorizer_stop_words_consistency():\n    # Test that stop words are consistent with the preprocessor and tokenizer\n    # when using a custom analyzer\n    class CustomAnalyzer:\n            return [word.lower() for word in doc.split()]\n\n    vec = CountVectorizer(analyzer=CustomAnalyzer(), stop_words=['AND'])\n    assert_warns_message(UserWarning, 'Your stop_words may be inconsistent',\n                         vec.fit_transform, ['hello AND world'])\n"], "sample_986": ["def test_evalf_piecewise():\n    from sympy import Piecewise\n    pw = Piecewise((1, x > 0), (0, x < 0))\n    assert NS(pw, subs={x: 0.5}) == '1.00000000000000'\n    assert NS(pw, subs={x: -0.5}) == '0.000000000000000'\n    assert NS(pw, subs={x: 0}) == '0.000000000000000'\n    pw = Piecewise((1, x > 0), (0, x < 0), (2, True))\n    assert NS(pw, subs={x: 0.5}) == '1.00000000000000'\n    assert NS(pw, subs={x: -0.5}) == '0.000000000000000'\n    assert NS(pw, subs={x: 0}) == '2.00000000000000'\n"], "sample_1135": ["def test_Mul_as_coeff_Mul():\n    # issue 5524.  These should all be (1, self)\n    assert (x + 1).as_coeff_Mul() == (1, x + 1)\n    assert (x + 2).as_coeff_Mul() == (1, x + 2)\n    assert (x + 3).as_coeff_Mul() == (1, x + 3)\n\n    assert (x - 1).as_coeff_Mul() == (1, x - 1)\n    assert (x - 2).as_coeff_Mul() == (1, x - 2)\n    assert (x - 3).as_coeff_Mul() == (1, x - 3)\n\n    n = Symbol('n', integer=True)\n    assert (n + 1).as_coeff_Mul() == (1, n + 1)\n    assert (n + 2).as_coeff_Mul() == (1, n + 2)\n    assert (n + 3).as_coeff_Mul() == (1, n + 3)\n\n    assert (n - 1).as_coeff_Mul() == (1, n - 1)\n    assert (n - 2).as_coeff_Mul() == (1, n - 2)\n    assert (n - 3).as_coeff_Mul() == (1, n - 3)\n"], "sample_541": ["def test_polygon_selector_box_scaling(ax):\n    # Create a diamond shape\n    verts = [(20, 0), (0, 20), (20, 40), (40, 20)]\n    event_sequence = [\n        *polygon_place_vertex(*verts[0]),\n        *polygon_place_vertex(*verts[1]),\n        *polygon_place_vertex(*verts[2]),\n        *polygon_place_vertex(*verts[3]),\n        *polygon_place_vertex(*verts[0]),\n    ]\n\n    # Create selector\n    tool = widgets.PolygonSelector(ax, onselect=noop, draw_bounding_box=True)\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n\n    # In order to trigger the correct callbacks, trigger events on the canvas\n    # instead of the individual tools\n    t = ax.transData\n    canvas = ax.figure.canvas\n\n    # Scale to half size using the top right corner of the bounding box\n    MouseEvent(\n        \"button_press_event\", canvas, *t.transform((40, 40)), 1)._process()\n    MouseEvent(\n        \"motion_notify_event\", canvas, *t.transform((20, 20)))._process()\n    MouseEvent(\n        \"button_release_event\", canvas, *t.transform((20, 20)), 1)._process()\n    np.testing.assert_allclose(\n        tool.verts, [(10, 0), (0, 10), (10, 20), (20, 10)])\n\n    # Scale to double size using the top right corner of the bounding box\n    MouseEvent(\n        \"button_press_event\", canvas, *t.transform((20, 20)), 1)._process()\n    MouseEvent(\n        \"motion_notify_event\", canvas, *t.transform((40, 40)))._process()\n    MouseEvent(\n        \"button_release_event\", canvas, *t.transform((40, 40)), 1)._process()\n    np.testing.assert_allclose(\n        tool.verts, [(20, 0), (0, 20), (20, 40), (40, 20)])\n"], "sample_795": ["def test_check_class_weight_balanced_classifiers():\n    # test class weights with non-contiguous class labels\n    check_class_weight_balanced_linear_classifier(\n        \"SVC\", SVC)\n    check_class_weight_balanced_linear_classifier(\n        \"LinearSVC\", LinearSVC)\n"], "sample_613": ["def test_groupby_dataset_reduce_with_keepdims() -> None:\n    data = Dataset(\n        {\n            \"xy\": ([\"x\", \"y\"], np.random.randn(3, 4)),\n            \"xonly\": (\"x\", np.random.randn(3)),\n            \"yonly\": (\"y\", np.random.randn(4)),\n            \"letters\": (\"y\", [\"a\", \"a\", \"b\", \"b\"]),\n        }\n    )\n\n    expected = data.mean(\"y\")\n    expected[\"yonly\"] = expected[\"yonly\"].variable.set_dims({\"x\": 3})\n    actual = data.groupby(\"x\").mean(..., keepdims=True)\n    assert_allclose(expected, actual)\n\n    actual = data.groupby(\"x\").mean(\"y\", keepdims=True)\n    assert_allclose(expected, actual)\n\n    letters = data[\"letters\"]\n    expected = Dataset(\n        {\n            \"xy\": data[\"xy\"].groupby(letters).mean(..., keepdims=True),\n            \"xonly\": (data[\"xonly\"].mean().variable.set_dims({\"letters\": 2})),\n            \"yonly\": data[\"yonly\"].groupby(letters).mean(keepdims=True),\n        }\n    )\n    actual = data.groupby(\"letters\").mean(..., keepdims=True)\n    assert_allclose(expected, actual)\n"], "sample_482": ["    def test_basic(self):\n        output = self.engine.render_to_string(\n            \"safeseq_basic\",\n            {\"a\": [\"x&y\", \"<p>\"], \"b\": [mark_safe(\"x&y\"), mark_safe(\"<p>\")]},\n        )\n        self.assertEqual(output, \"x&y, <p> -- x&y, <p>\")\n"], "sample_778": ["def test_nmf_random_state():\n    # Test that the random_state parameter is used correctly\n    n_samples = 20\n    n_features = 15\n    n_components = 10\n    rng = np.random.mtrand.RandomState(42)\n    X = rng.randn(n_samples, n_features)\n    np.abs(X, X)\n\n    # Test that the same random_state leads to the same results\n    model1 = NMF(n_components=n_components, random_state=0)\n    model2 = NMF(n_components=n_components, random_state=0)\n    W1 = model1.fit_transform(X)\n    W2 = model2.fit_transform(X)\n    assert_array_almost_equal(W1, W2)\n\n    # Test that different random_state leads to different results\n    model3 = NMF(n_components=n_components, random_state=1)\n    W3 = model3.fit_transform(X)\n    assert not np.allclose(W1, W3)\n\n    # Test that None as random_state leads to different results\n    model4 = NMF(n_components=n_components, random_state=None)\n    W4 = model4.fit_transform(X)\n    assert not np.allclose(W1, W4)\n"], "sample_87": ["    def test_empty_paths(self):\n        self.assertEqual(autoreload.common_roots(()), ())\n"], "sample_567": ["def test_text_repr_with_non_string_input():\n    # smoketest to make sure text repr doesn't error for non-string input\n    plt.plot([1, 2], [1, 2])\n    repr(plt.text(0.5, 0.5, 123))\n"], "sample_115": ["    def test_technical_500_response(self):\n        request = RequestFactory().get('/')\n        exc_type = ValueError\n        exc_value = ValueError('Test exception')\n        tb = None\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html')\n"], "sample_1078": ["def test_IndexedBase_strides():\n    i, j = symbols('i j', integer=True)\n    A = IndexedBase('A', strides=(1, 2))\n    assert A.strides == (1, 2)\n    assert A[i, j].strides == (1, 2)\n    assert A.offset == 0\n    assert A[i, j].offset == 0\n    B = IndexedBase('B', strides=(1, 2), offset=3)\n    assert B.strides == (1, 2)\n    assert B[i, j].strides == (1, 2)\n    assert B.offset == 3\n    assert B[i, j].offset == 3\n    C = IndexedBase('C', strides='C')\n    assert C.strides == 'C'\n    assert C[i, j].strides == 'C'\n    D = IndexedBase('D', strides='F')\n    assert D.strides == 'F'\n    assert D[i, j].strides == 'F'\n"], "sample_1042": ["def test_IndexedBase_strides():\n    i, j = symbols('i j', integer=True)\n    A = IndexedBase('A', strides=(1, 2))\n    assert A.strides == (1, 2)\n    assert A[i, j].strides == (1, 2)\n    assert A.strides == A[i, j].strides\n\n    B = IndexedBase('B', strides='C')\n    assert B.strides == 'C'\n    assert B[i, j].strides == 'C'\n    assert B.strides == B[i, j].strides\n\n    C = IndexedBase('C', strides='F')\n    assert C.strides == 'F'\n    assert C[i, j].strides == 'F'\n    assert C.strides == C[i, j].strides\n\n    raises(TypeError, lambda: IndexedBase('D', strides='Invalid'))\n"], "sample_429": ["def test_prohibit_null_characters_validator(self):\n    v = ProhibitNullCharactersValidator()\n    self.assertEqual(v(\"\\x00something\"), None)\n    with self.assertRaisesMessage(ValidationError, \"Null characters are not allowed.\"):\n        v(\"\\x00something\")\n    self.assertEqual(v(\"something\"), None)\n    self.assertEqual(v(None), None)\n"], "sample_894": ["def test_max_samples_boundary_classifiers_oob(name):\n    X_train, X_test, y_train, _ = train_test_split(\n        X_large, y_large, random_state=0, stratify=y_large\n    )\n\n    ms_1_model = FOREST_CLASSIFIERS[name](\n        bootstrap=True, max_samples=1.0, random_state=0, oob_score=True\n    )\n    ms_1_oob_score = ms_1_model.fit(X_train, y_train).oob_score_\n\n    ms_None_model = FOREST_CLASSIFIERS[name](\n        bootstrap=True, max_samples=None, random_state=0, oob_score=True\n    )\n    ms_None_oob_score = ms_None_model.fit(X_train, y_train).oob_score_\n\n    assert ms_1_oob_score == pytest.approx(ms_None_oob_score)\n"], "sample_871": ["def test_silhouette_samples_edge_cases():\n    # Test edge cases for silhouette_samples\n    # Test with a single sample\n    X = np.array([[1, 2]])\n    labels = np.array([0])\n    with pytest.raises(ValueError, match=\"Number of labels is\"):\n        silhouette_samples(X, labels)\n\n    # Test with two samples in the same cluster\n    X = np.array([[1, 2], [1, 2]])\n    labels = np.array([0, 0])\n    assert_array_equal(silhouette_samples(X, labels), np.array([1, 1]))\n\n    # Test with two samples in different clusters\n    X = np.array([[1, 2], [3, 4]])\n    labels = np.array([0, 1])\n    assert_array_equal(silhouette_samples(X, labels), np.array([1, 1]))\n\n    # Test with three samples in the same cluster\n    X = np.array([[1, 2], [1, 2], [1, 2]])\n    labels = np.array([0, 0, 0])\n    assert_array_equal(silhouette_samples(X, labels), np.array([1, 1, 1]))\n\n    # Test with three samples in different clusters\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    labels = np.array([0, 1, 2])\n    with pytest.raises(ValueError, match=\"Number of labels is\"):\n        silhouette_samples(X, labels)\n"], "sample_500": ["def test_colorbar_set_alpha():\n    # test fix for #20054\n    fig, ax = plt.subplots()\n    x = np.arange(-3.0, 4.001)\n    y = np.arange(-4.0, 3.001)\n    X, Y = np.meshgrid(x, y)\n    Z = X * Y\n    Z = Z[:-1, :-1]\n    pcm = ax.pcolormesh(X, Y, Z)\n    cbar = fig.colorbar(pcm, ax=ax, extend='both', orientation='vertical')\n    cbar.set_alpha(0.5)\n    assert cbar.alpha == 0.5\n    cbar.set_alpha([0.5, 0.7])\n    assert cbar.alpha is None\n    assert np.allclose(pcm.get_alpha(), [0.5, 0.7])\n"], "sample_233": ["def test_make_token_with_timestamp(self):\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    timestamp = p0._num_seconds(datetime.now())\n    tk1 = p0._make_token_with_timestamp(user, timestamp)\n    self.assertIs(p0.check_token(user, tk1), True)\n"], "sample_627": ["def test_concat_with_index_and_dataarray_dim() -> None:\n    # Test that concat works when dim is a DataArray and one of the datasets has an index\n    # with the same name as the dim.\n    ds1 = Dataset(coords={\"x\": (\"x\", [1, 2])})\n    ds2 = Dataset(coords={\"x\": [3, 4]})\n\n    dim = DataArray([0, 1], dims=\"x\")\n    actual = concat([ds1, ds2], dim=dim)\n    expected = Dataset(coords={\"x\": [1, 2, 3, 4]})\n    assert_identical(actual, expected)\n"], "sample_853": ["def test_transform_target_regressor_predict_before_fit():\n    X, y = friedman\n    regr = TransformedTargetRegressor(regressor=LinearRegression(),\n                                      func=np.log, inverse_func=np.exp)\n    with pytest.raises(NotFittedError,\n                       match=\"This TransformedTargetRegressor instance is not \"\n                       \"fitted yet. Call 'fit' with appropriate arguments \"\n                       \"before using this estimator.\"):\n        regr.predict(X)\n"], "sample_785": ["def test_leave_one_group_out_with_unhashable_groups():\n    # Check that LeaveOneGroupOut works with unhashable groups\n    groups = np.array([np.array([1, 2]), np.array([1, 2]), np.array([3, 4])])\n    X = np.ones(len(groups))\n    y = np.ones(len(groups))\n\n    logo = LeaveOneGroupOut()\n    for train, test in logo.split(X, y, groups):\n        assert_array_equal(np.intersect1d(groups[train], groups[test]).tolist(),\n                           [])\n"], "sample_162": ["    def test_build_file_preprocess(self):\n        build_file = self.build_file_class(self, 'django', self.translatable_file_class('.', 'test.html', '.'))\n        build_file.preprocess()\n        self.assertTrue(os.path.exists(build_file.work_path))\n        with open(build_file.work_path, encoding='utf-8') as fp:\n            content = fp.read()\n            self.assertIn('Translatable literal #6b', content)\n        build_file.cleanup()\n        self.assertFalse(os.path.exists(build_file.work_path))\n"], "sample_915": ["def test_isabstractmethod():\n    class AbstractClass:\n        @abstractmethod\n            pass\n\n    class ConcreteClass:\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(ConcreteClass.concrete_method) is False\n"], "sample_901": ["def test_k_means_init_centers_dtype():\n    # This test is used to check KMeans won't mutate the user provided input\n    # array silently even if input data and init centers have the same type\n    X_small = np.array([[1.1, 1.1], [-7.5, -7.5], [-1.1, -1.1], [7.5, 7.5]])\n    init_centers = np.array([[0.0, 0.0], [5.0, 5.0], [-5.0, -5.0]])\n    for dtype in [np.int32, np.int64, np.float32, np.float64]:\n        X_test = dtype(X_small)\n        init_centers_test = dtype(init_centers)\n        assert_array_equal(init_centers, init_centers_test)\n        km = KMeans(init=init_centers_test, n_clusters=3, n_init=1)\n        km.fit(X_test)\n        assert np.may_share_memory(km.cluster_centers_,\n                                   init_centers) is False\n        assert km.cluster_centers_.dtype == np.float64\n"], "sample_352": ["        def as_sql(self, compiler, connection):\n            return 'dummy', []\n"], "sample_423": ["def test_alter_field_to_m2m(self):\n    \"\"\"\n    #23938 - Changing a field into a ManyToManyField first removes the field\n    and then adds the m2m field.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_with_former_m2m], [self.author_with_m2m, self.publisher]\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(\n        changes, \"testapp\", 0, [\"CreateModel\", \"RemoveField\", \"AddField\"]\n    )\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Publisher\")\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 1, name=\"publishers\", model_name=\"author\"\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 2, name=\"publishers\", model_name=\"author\"\n    )\n"], "sample_983": ["def test_sparse_matrix_methods():\n    # test LDL decomposition\n    A = SparseMatrix(((25, 15, -5), (15, 18, 0), (-5, 0, 11)))\n    L, D = A.LDLdecomposition()\n    assert L.is_lower\n    assert D.is_diagonal\n    assert L * D * L.T == A\n\n    # test Cholesky decomposition\n    A = SparseMatrix(((25, 15, -5), (15, 18, 0), (-5, 0, 11)))\n    L = A.cholesky()\n    assert L.is_lower\n    assert L * L.T == A\n\n    # test LDL solve\n    A = SparseMatrix(((25, 15, -5), (15, 18, 0), (-5, 0, 11)))\n    b = SparseMatrix((1, 3, [1, 2, 3]))\n    x = A._LDL_solve(b)\n    assert A * x == b\n\n    # test Cholesky solve\n    A = SparseMatrix(((25, 15, -5), (15, 18, 0), (-5, 0, 11)))\n    b = SparseMatrix((1, 3, [1, 2, 3]))\n    x = A._cholesky_solve(b)\n    assert A * x == b\n\n    # test lower triangular solve\n    A = SparseMatrix(((1, 0, 0), (2, 3, 0), (4, 5, 6)))\n    b = SparseMatrix((1, 3, [1, 2, 3]))\n    x = A._lower_triangular_solve(b)\n    assert A * x == b\n\n    # test upper triangular solve\n    A = SparseMatrix(((1, 2, 3), (0, 4, 5), (0, 0, 6)))\n    b = SparseMatrix((1, 3, [1, 2, 3]))\n    x = A._upper_triangular_solve(b)\n    assert A * x == b\n\n    # test row structure symbolic Cholesky\n    A = SparseMatrix(((1, 0, 3, 2), (0, 0, 1, 0), (4, 0, 0, 5), (0, "], "sample_787": ["def test_multilabel_confusion_matrix_multiclass_with_sample_weight():\n    # Test multilabel confusion matrix - multi-class case with sample weights\n    y_true, y_pred, _ = make_prediction(binary=False)\n\n    # compute confusion matrix with default labels introspection\n    cm = multilabel_confusion_matrix(y_true, y_pred, sample_weight=[1, 2, 3, 4, 5])\n    assert_array_equal(cm, [[[47, 4], [5, 19]],\n                            [[38, 6], [28, 3]],\n                            [[30, 25], [2, 18]]])\n\n    # compute confusion matrix with explicit label ordering\n    labels = ['0', '2', '1'] \n    cm = multilabel_confusion_matrix(y_true, y_pred, labels=labels, sample_weight=[1, 2, 3, 4, 5])\n    assert_array_equal(cm, [[[47, 4], [5, 19]],\n                            [[30, 25], [2, 18]],\n                            [[38, 6], [28, 3]]])\n\n    # compute confusion matrix with super set of present labels\n    labels = ['0', '2', '1', '3'] \n    cm = multilabel_confusion_matrix(y_true, y_pred, labels=labels, sample_weight=[1, 2, 3, 4, 5])\n    assert_array_equal(cm, [[[47, 4], [5, 19]],\n                            [[30, 25], [2, 18]],\n                            [[38, 6], [28, 3]],\n                            [[75, 0], [0, 0]]])\n"], "sample_1": ["def test_separable_mapping():\n    # Test separability of a Mapping model\n    mapping = Mapping((0, 1, 0, 1))\n    assert_allclose(is_separable(mapping), np.array([True, True, True, True]))\n    assert_allclose(separability_matrix(mapping), np.array([[True, False], [False, True], [True, False], [False, True]]))\n\n    # Test separability of a Mapping model with a single input\n    mapping = Mapping((0,))\n    assert_allclose(is_separable(mapping), np.array([True]))\n    assert_allclose(separability_matrix(mapping), np.array([[True]]))\n"], "sample_878": ["def test_column_transformer_set_output_mixed_transformers():\n    \"\"\"Check ColumnTransformer outputs mixed types correctly.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame(\n        {\n            \"pet\": pd.Series([\"dog\", \"cat\", \"snake\"], dtype=\"category\"),\n            \"color\": pd.Series([\"green\", \"blue\", \"red\"], dtype=\"object\"),\n            \"age\": [1.4, 2.1, 4.4],\n            \"height\": [20, 40, 10],\n            \"distance\": pd.Series([20, pd.NA, 100], dtype=\"Int32\"),\n        }\n    )\n    ct = ColumnTransformer(\n        [\n            (\n                \"color_encode\",\n                OneHotEncoder(sparse_output=False, dtype=\"int8\"),\n                [\"color\"],\n            ),\n            (\"age\", StandardScaler(), [\"age\"]),\n            (\"height\", PandasOutTransformer(offset=2.0), [\"height\"]),\n        ],\n        remainder=\"passthrough\",\n        verbose_feature_names_out=False,\n    ).set_output(transform=\"pandas\")\n    X_trans = ct.fit_transform(df)\n\n    assert isinstance(X_trans, pd.DataFrame)\n    assert_array_equal(X_trans.columns, ct.get_feature_names_out())\n\n    expected_dtypes = {\n        \"color_blue\": \"int8\",\n        \"color_green\": \"int8\",\n        \"color_red\": \"int8\",\n        \"age\": \"float64\",\n        \"pet\": \"category\",\n        \"distance\": \"Int32\",\n        \"height\": \"float64\",\n    }\n    for col, dtype in X_trans.dtypes.items():\n        assert dtype == expected_dtypes[col]\n"], "sample_922": ["def test_pyclasslike_signature(app):\n    text = (\".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:method:: meth1\\n\"\n            \"   .. py:method:: meth2\\n\"\n            \"      :abstractmethod:\\n\"\n            \"   .. py:method:: meth3\\n\"\n            \"      :async:\\n\"\n            \"   .. py:method:: meth4\\n\"\n            \"      :classmethod:\\n\"\n            \"   .. py:method:: meth5\\n\"\n            \"      :final:\\n\"\n            \"   .. py:method:: meth6\\n\"\n            \"      :property:\\n\"\n            \"   .. py:method:: meth7\\n\"\n            \"      :staticmethod:\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_name, \"Class\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc,\n                                                  addnodes.index,\n                                                  desc,\n                                                  addnodes.index,\n                                                  desc,\n                                                  addnodes.index,\n                                                  desc,\n                                                  addnodes.index,\n                                                  desc,\n                                                  addnodes.index,\n                                                  desc)])]))\n    assert_node(doctree[1][1][0], addnodes.index,\n                entries=[('single', 'meth1() (Class method)', 'Class.meth1', '', None)])\n    assert_node(doctree[1][1][1], ([desc_signature, ([desc_name, \"meth1\"],\n                                                     [desc_parameterlist, ()])],\n                                   [desc_content, ()]))\n    assert 'Class.meth1' in domain.objects\n    assert domain.objects['Class.meth1'] == ('index', 'Class.meth1', 'method')\n\n    assert_node(doctree[1][1][2], addnodes.index,\n                entries=[('single', 'meth2() (Class method)', 'Class.meth2', '', None)])\n    assert_node(doctree[1][1][3], ([desc_signature, ([desc_annotation, \"abstract \"],\n                                                     [desc_name, \"meth2\"],\n                                                     [desc_parameterlist, ()])],\n                                   [desc_content, ()]))\n    assert 'Class.meth2' in domain.objects\n    assert domain.objects['Class.meth2'] == ('index', 'Class.meth2', 'method"], "sample_651": ["    def test_pop_all_warnings(self, recwarn: WarningsRecorder) -> None:\n        warnings.warn(\"hello\", UserWarning)\n        warnings.warn(\"world\", DeprecationWarning)\n        assert len(recwarn) == 2\n        assert recwarn.pop(UserWarning).message.args[0] == \"hello\"\n        assert recwarn.pop(DeprecationWarning).message.args[0] == \"world\"\n        assert len(recwarn) == 0\n        with pytest.raises(AssertionError):\n            recwarn.pop(UserWarning)\n"], "sample_909": ["    def test_xref_in_parameter_description(self):\n        docstring = \"\"\"\\"], "sample_713": ["def test_ridge_regression_return_n_iter():\n    # Test that return_n_iter returns the correct number of iterations\n    X, y = make_regression(n_samples=10, n_features=5, random_state=42)\n    alpha = 1.0\n\n    for solver in ['sag', 'lsqr']:\n        coefs, n_iter = ridge_regression(X, y, alpha, return_n_iter=True,\n                                         solver=solver)\n        assert_equal(len(n_iter), 1)\n\n    for solver in ['svd', 'cholesky', 'sparse_cg']:\n        coefs, n_iter = ridge_regression(X, y, alpha, return_n_iter=True,\n                                         solver=solver)\n        assert_equal(n_iter, None)\n"], "sample_247": ["def test_annotation_with_subquery(self):\n    subquery = Author.objects.filter(name='Adrian Holovaty').values('id')\n    books = Book.objects.annotate(\n        is_adrian=Exists(subquery)\n    )\n    self.assertTrue(books.get(isbn='159059725').is_adrian)\n    self.assertFalse(books.get(isbn='159059996').is_adrian)\n"], "sample_718": ["def test_check_estimator_sparse_data():\n    # test that check_estimator() checks sparse data\n    class SparseDataEstimator(BaseEstimator):\n            if sp.issparse(X):\n                raise ValueError(\"Sparse data not supported\")\n            return self\n\n            return np.ones(X.shape[0])\n\n    msg = \"Estimator SparseDataEstimator doesn't seem to fail gracefully on sparse data\"\n    # the check for sparse input handling prints to the stdout,\n    # instead of raising an error, so as not to remove the original traceback.\n    # that means we need to jump through some hoops to catch it.\n    old_stdout = sys.stdout\n    string_buffer = StringIO()\n    sys.stdout = string_buffer\n    try:\n        check_estimator(SparseDataEstimator)\n    except:\n        pass\n    finally:\n        sys.stdout = old_stdout\n    assert_true(msg in string_buffer.getvalue())\n"], "sample_997": ["def test_function_exponentiation():\n    transformations = standard_transformations + (function_exponentiation,)\n    x = Symbol('x')\n    assert parse_expr('sin**2(x)', transformations=transformations) == sin(x)**2\n    assert parse_expr('sin**2(x+1)', transformations=transformations) == sin(x+1)**2\n    assert parse_expr('sin(x)**2', transformations=transformations) == sin(x)**2\n    assert parse_expr('sin(x+1)**2', transformations=transformations) == sin(x+1)**2\n"], "sample_938": ["def test_custom_man_pages(app, status, warning):\n    app.build()\n    assert (app.outdir / 'custom.2').exists()\n\n    content = (app.outdir / 'custom.2').read_text()\n    assert 'Custom Title' in content\n    assert 'Custom Author' in content\n"], "sample_315": ["    def setUp(self):\n        self.middleware = LocaleMiddleware(lambda req: HttpResponse())\n"], "sample_605": ["def test_groupby_map_with_kwargs():\n        return group + arg1 + arg2 + arg3\n\n    array = xr.DataArray([1, 1, 1], [(\"x\", [1, 2, 3])])\n    expected = xr.DataArray([3, 3, 3], [(\"x\", [1, 2, 3])])\n    actual = array.groupby(\"x\").map(func, arg1=1, arg2=1)\n    assert_identical(expected, actual)\n"], "sample_600": ["def test_unsigned_integer_coder_encode():\n    original = xr.Variable((\"x\",), np.array([255], dtype=np.uint8), encoding={\"_Unsigned\": \"true\"})\n    coder = variables.UnsignedIntegerCoder()\n    encoded = coder.encode(original)\n    expected = xr.Variable((\"x\",), np.array([-1], dtype=np.int8), encoding={\"_Unsigned\": \"true\"})\n    assert_identical(encoded, expected)\n\n    original = xr.Variable((\"x\",), np.array([255], dtype=np.int8), encoding={\"_Unsigned\": \"false\"})\n    coder = variables.UnsignedIntegerCoder()\n    encoded = coder.encode(original)\n    expected = xr.Variable((\"x\",), np.array([255], dtype=np.uint8), encoding={\"_Unsigned\": \"false\"})\n    assert_identical(encoded, expected)\n"], "sample_903": ["def test_tsne_with_different_dtypes():\n    # Test that TSNE works with different dtypes.\n    random_state = check_random_state(0)\n    X = random_state.randn(100, 2)\n    for dtype in [np.float32, np.float64]:\n        X_casted = X.astype(dtype)\n        tsne = TSNE(n_components=2, random_state=0)\n        X_embedded = tsne.fit_transform(X_casted)\n        assert X_embedded.dtype == np.float32\n"], "sample_577": ["    def test_repr_png(self, long_df):\n\n        p = Plot(long_df, x=\"x\", y=\"y\").add(MockMark()).plot()\n        data, metadata = p._repr_png_()\n        img = Image.open(io.BytesIO(data))\n\n        assert not hasattr(p, \"_figure\")\n        assert isinstance(data, bytes)\n        assert img.format == \"PNG\"\n        assert sorted(metadata) == [\"height\", \"width\"]\n        # TODO test retina scaling\n"], "sample_939": ["def test_unparse_arguments():\n    source = \"def func(a: int, b: str = 'default', *args, **kwargs): pass\"\n    module = ast.parse(source)\n    expected = \"(a: int, b: str = 'default', *args, **kwargs)\"\n    assert ast.unparse(module.body[0].args, source) == expected\n"], "sample_836": ["def test_ovr_decision_function():\n    # Test OvR decision function computation\n    predictions = np.array([[0, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.2, 0.8, 0.1], [0.7, 0.3, 0.9]])\n    n_classes = 3\n    expected_result = np.array([[0.46666667, -0.33333333, -0.13333333],\n                               [0.23333333, -0.46666667, 0.23333333]])\n    assert_allclose(_ovr_decision_function(predictions, confidences, n_classes),\n                    expected_result)\n\n    # Test OvR decision function computation with single sample\n    predictions = np.array([[0, 1, 0]])\n    confidences = np.array([[0.2, 0.8, 0.1]])\n    n_classes = 3\n    expected_result = np.array([[0.46666667, -0.33333333, -0.13333333]])\n    assert_allclose(_ovr_decision_function(predictions, confidences, n_classes),\n                    expected_result)\n\n    # Test OvR decision function computation with single class\n    predictions = np.array([[0, 0, 0]])\n    confidences = np.array([[0.2, 0.8, 0.1]])\n    n_classes = 3\n    expected_result = np.array([[0.46666667, -0.33333333, -0.13333333]])\n    assert_allclose(_ovr_decision_function(predictions, confidences, n_classes),\n                    expected_result)\n\n    # Test OvR decision function computation with invalid input\n    predictions = np.array([[0, 1, 0]])\n    confidences = np.array([[0.2, 0.8]])\n    n_classes = 3\n    with pytest.raises(ValueError):\n        _ovr_decision_function(predictions, confidences, n_classes)\n"], "sample_468": ["def test_render_context_push_state(self):\n    \"\"\"\n    Test RenderContext.push_state() context manager.\n    \"\"\"\n    test_context = RenderContext({\"fruit\": \"papaya\"})\n\n    with test_context.push_state(\"template_name\"):\n        test_context[\"vegetable\"] = \"artichoke\"\n        self.assertEqual(list(test_context), [\"vegetable\"])\n        self.assertEqual(test_context.template, \"template_name\")\n\n    self.assertNotIn(\"vegetable\", test_context)\n    self.assertIsNone(test_context.get(\"vegetable\"))\n    self.assertEqual(test_context.template, None)\n\n    with test_context.push_state(\"template_name\", isolated_context=False):\n        test_context[\"vegetable\"] = \"artichoke\"\n        self.assertEqual(list(test_context), [\"vegetable\", \"fruit\"])\n        self.assertEqual(test_context.template, \"template_name\")\n\n    self.assertIn(\"vegetable\", test_context)\n    self.assertEqual(test_context.get(\"vegetable\"), \"artichoke\")\n    self.assertEqual(test_context.template, None)\n"], "sample_815": ["def test_jaccard_similarity_score_deprecated():\n    # Test that jaccard_similarity_score is deprecated\n    y_true = np.array([[0, 1], [1, 1]])\n    y_pred = np.array([[1, 1], [1, 0]])\n\n    with pytest.warns(DeprecationWarning):\n        jaccard_similarity_score(y_true, y_pred)\n"], "sample_1204": ["def test_is_dihedral():\n    G = SymmetricGroup(2)\n    assert G.is_dihedral\n    G = SymmetricGroup(3)\n    assert G.is_dihedral\n\n    G = AbelianGroup(2, 2)\n    assert G.is_dihedral\n    G = CyclicGroup(4)\n    assert not G.is_dihedral\n\n    G = AbelianGroup(3, 5)\n    assert not G.is_dihedral\n    G = AbelianGroup(2)\n    assert G.is_dihedral\n    G = AbelianGroup(6)\n    assert not G.is_dihedral\n\n    # D6, generated by two adjacent flips\n    G = PermutationGroup(\n        Permutation(1, 5)(2, 4),\n        Permutation(0, 1)(3, 4)(2, 5))\n    assert G.is_dihedral\n\n    # D7, generated by a flip and a rotation\n    G = PermutationGroup(\n        Permutation(1, 6)(2, 5)(3, 4),\n        Permutation(0, 1, 2, 3, 4, 5, 6))\n    assert G.is_dihedral\n\n    # S4, presented by three generators, fails due to having exactly 9\n    # elements of order 2:\n    G = PermutationGroup(\n        Permutation(0, 1), Permutation(0, 2),\n        Permutation(0, 3))\n    assert not G.is_dihedral\n\n    # D7, given by three generators\n    G = PermutationGroup(\n        Permutation(1, 6)(2, 5)(3, 4),\n        Permutation(2, 0)(3, 6)(4, 5),\n        Permutation(0, 1, 2, 3, 4, 5, 6))\n    assert G.is_dihedral\n"], "sample_506": ["def test_spines_arc():\n    fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n    ax.set_rlim(0, 2)\n    ax.set_rticks([1])\n    ax.set_thetagrids([0, 90, 180, 270])\n    ax.spines['polar'].set_patch_arc((0.5, 0.5), 0.4, 0, 90)\n    ax.spines['polar'].set_color('red')\n"], "sample_453": ["def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should render prepopulated fields.\n    \"\"\"\n    article = Article.objects.all()[0]\n    request = self.request_factory.get(\n        reverse(\"admin:admin_views_article_change\", args=[article.pk])\n    )\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    response = admin.change_view(request, str(article.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIn(\"prepopulated_fields\", template_context)\n    self.assertIn(\"prepopulated_fields_json\", template_context)\n    self.assertIsInstance(template_context[\"prepopulated_fields\"], list)\n    self.assertIsInstance(template_context[\"prepopulated_fields_json\"], str)\n"], "sample_335": ["def test_decimalfield_edge_cases(self):\n    f = DecimalField(max_digits=1, decimal_places=0)\n    with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 0 digits before the decimal point.'\"):\n        f.clean('1')\n    with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 0 digits before the decimal point.'\"):\n        f.clean('-1')\n    with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 0 digits before the decimal point.'\"):\n        f.clean('01')\n    with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 0 digits before the decimal point.'\"):\n        f.clean('-01')\n    self.assertEqual(f.clean('0'), decimal.Decimal(\"0\"))\n    self.assertEqual(f.clean('-0'), decimal.Decimal(\"0\"))\n    self.assertEqual(f.clean('0.0'), decimal.Decimal(\"0\"))\n    self.assertEqual(f.clean('-0.0'), decimal.Decimal(\"0\"))\n"], "sample_629": ["def test_expand_modules(tmp_path):\n    # Create a test directory structure\n    test_dir = tmp_path / \"test_dir\"\n    test_dir.mkdir()\n    (test_dir / \"__init__.py\").touch()\n    (test_dir / \"test_module.py\").touch()\n    (test_dir / \"test_subdir\").mkdir()\n    (test_dir / \"test_subdir\" / \"__init__.py\").touch()\n    (test_dir / \"test_subdir\" / \"test_submodule.py\").touch()\n\n    # Test expand_modules with a directory\n    files_or_modules = [str(test_dir)]\n    ignore_list = []\n    ignore_list_re = []\n    ignore_list_paths_re = []\n    result, errors = expand_modules(files_or_modules, ignore_list, ignore_list_re, ignore_list_paths_re)\n    assert len(result) == 3\n    assert errors == []\n\n    # Test expand_modules with a file\n    files_or_modules = [str(test_dir / \"test_module.py\")]\n    result, errors = expand_modules(files_or_modules, ignore_list, ignore_list_re, ignore_list_paths_re)\n    assert len(result) == 1\n    assert errors == []\n\n    # Test expand_modules with a module\n    files_or_modules = [\"test_dir.test_module\"]\n    result, errors = expand_modules(files_or_modules, ignore_list, ignore_list_re, ignore_list_paths_re)\n    assert len(result) == 1\n    assert errors == []\n\n    # Test expand_modules with a non-existent module\n    files_or_modules = [\"non_existent_module\"]\n    result, errors = expand_modules(files_or_modules, ignore_list, ignore_list_re, ignore_list_paths_re)\n    assert result == []\n    assert len(errors) == 1\n"], "sample_281": ["def test_process_request_invalid_app_label(self):\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'invalid_app', 'model_name': Answer._meta.model_name, 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n"], "sample_1049": ["def test_parameter_value():\n    x, y, z, u, v = symbols('x y z u v', real=True)\n    p1 = Point3D(0, 0, 0)\n    p2 = Point3D(1, 1, 1)\n    p3 = Point3D(1, 2, 3)\n    pl3 = Plane(p1, p2, p3)\n    pl4 = Plane(p1, normal_vector=(1, 1, 1))\n    pl5 = Plane(p3, normal_vector=(1, 2, 3))\n\n    # test 1 parameter\n    t = Dummy('t')\n    assert pl3.parameter_value(pl3.arbitrary_point(t), t) == {t: t}\n    assert pl4.parameter_value(pl4.arbitrary_point(t), t) == {t: t}\n    assert pl5.parameter_value(pl5.arbitrary_point(t), t) == {t: t}\n\n    # test 2 parameters\n    assert pl3.parameter_value(pl3.arbitrary_point(u, v), u, v) == {u: u, v: v}\n    assert pl4.parameter_value(pl4.arbitrary_point(u, v), u, v) == {u: u, v: v}\n    assert pl5.parameter_value(pl5.arbitrary_point(u, v), u, v) == {u: u, v: v}\n\n    # test point not on plane\n    assert pl3.parameter_value(Point3D(1, 2, 4), t) == ValueError\n    assert pl4.parameter_value(Point3D(1, 2, 4), t) == ValueError\n    assert pl5.parameter_value(Point3D(1, 2, 4), t) == ValueError\n\n    # test point on plane but not in the circle\n    assert pl3.parameter_value(pl3.p1 + Point3D(1, 1, 1), t) == {t: pi/2}\n    assert pl4.parameter_value(pl4.p1 + Point3D(1, 1, 1), t) == {t: pi/2}\n    assert pl5.parameter_value(pl5.p1 + Point3D(1, 2, 3), t) == {t: pi/2}\n"], "sample_885": ["def test_generate_invalid_param_val_pandas_na():\n    \"\"\"Check that generate_invalid_param_val generates a value that does not satisfy\n    the _PandasNAConstraint.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    constraint = _PandasNAConstraint()\n    bad_value = generate_invalid_param_val(constraint)\n    assert not constraint.is_satisfied_by(bad_value)\n"], "sample_858": ["def test_voting_regressor_with_sample_weight():\n    \"\"\"Test VotingRegressor with sample weights.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(n_estimators=10)\n    ereg = VotingRegressor([('lr', reg1), ('rf', reg2)])\n\n    X_r_train, X_r_test, y_r_train, y_r_test = \\\n        train_test_split(X_r, y_r, test_size=.25)\n\n    sample_weight = np.random.RandomState(123).uniform(size=(len(y_r_train),))\n    ereg.fit(X_r_train, y_r_train, sample_weight)\n    reg1.fit(X_r_train, y_r_train, sample_weight)\n    reg2.fit(X_r_train, y_r_train, sample_weight)\n\n    assert_array_almost_equal(ereg.predict(X_r_test),\n                              np.average([reg1.predict(X_r_test),\n                                         reg2.predict(X_r_test)],\n                                         axis=0))\n"], "sample_76": ["def test_language_settings_consistent(self):\n    with self.subTest('valid language code'):\n        with self.settings(LANGUAGE_CODE='en', LANGUAGES=[('en', 'English')]):\n            self.assertEqual(check_language_settings_consistent(None), [])\n\n    with self.subTest('invalid language code'):\n        with self.settings(LANGUAGE_CODE='invalid', LANGUAGES=[('en', 'English')]):\n            self.assertEqual(check_language_settings_consistent(None), [\n                Error('You have provided a value for the LANGUAGE_CODE setting that is not in the LANGUAGES setting.', id='translation.E004'),\n            ])\n\n    with self.subTest('language code not in LANGUAGES but in default'):\n        with self.settings(LANGUAGE_CODE='en-us', LANGUAGES=[('fr', 'French')]):\n            self.assertEqual(check_language_settings_consistent(None), [])\n\n    with self.subTest('language code in LANGUAGES but not in default'):\n        with self.settings(LANGUAGE_CODE='fr', LANGUAGES=[('fr', 'French')]):\n            self.assertEqual(check_language_settings_consistent(None), [])\n\n    with self.subTest('empty LANGUAGES'):\n        with self.settings(LANGUAGE_CODE='en', LANGUAGES=[]):\n            self.assertEqual(check_language_settings_consistent(None), [\n                Error('You have provided a value for the LANGUAGE_CODE setting that is not in the LANGUAGES setting.', id='translation.E004'),\n            ])\n"], "sample_745": ["def test_inverse_transform_with_sparse_input():\n    X = sparse.csr_matrix(np.array([1, 4, 9, 16]).reshape((2, 2)))\n\n    # Test that inverse_transform works correctly with sparse input\n    F = FunctionTransformer(\n        func=np.sqrt,\n        inverse_func=np.around, inv_kw_args=dict(decimals=3),\n        accept_sparse=True,\n    )\n    assert_allclose_dense_sparse(\n        F.inverse_transform(F.transform(X)),\n        np.around(np.sqrt(X.toarray()), decimals=3),\n    )\n"], "sample_1164": ["def test_cg_simp():\n    a = symbols('a')\n    alpha = symbols('alpha')\n    b = symbols('b')\n    beta = symbols('beta')\n    c = symbols('c')\n    gamma = symbols('gamma')\n    expr1 = CG(a, alpha, b, 0, a, alpha)\n    expr2 = CG(a, alpha, a, -alpha, c, 0)\n    expr3 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr4 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr5 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr6 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr7 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr8 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr9 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr10 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr11 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr12 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr13 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr14 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr15 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr16 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr17 ="], "sample_691": ["def test_pytest_unconfigure(pytester: Pytester) -> None:\n    \"\"\"Test that pytest_unconfigure correctly disables and re-enables faulthandler.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import faulthandler\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest_subprocess()\n    assert result.ret == 0\n    assert faulthandler.is_enabled()\n"], "sample_1032": ["def test_issue_13456():\n    from sympy.abc import x, y, z\n    # test that Min/Max can handle more than 2 arguments\n    assert Min(x, y, z).func is Min\n    assert Max(x, y, z).func is Max\n    # test that Min/Max can handle more than 3 arguments\n    assert Min(x, y, z, x).func is Min\n    assert Max(x, y, z, x).func is Max\n    # test that Min/Max can handle more than 4 arguments\n    assert Min(x, y, z, x, y).func is Min\n    assert Max(x, y, z, x, y).func is Max\n    # test that Min/Max can handle more than 5 arguments\n    assert Min(x, y, z, x, y, z).func is Min\n    assert Max(x, y, z, x, y, z).func is Max\n    # test that Min/Max can handle more than 6 arguments\n    assert Min(x, y, z, x, y, z, x).func is Min\n    assert Max(x, y, z, x, y, z, x).func is Max\n    # test that Min/Max can handle more than 7 arguments\n    assert Min(x, y, z, x, y, z, x, y).func is Min\n    assert Max(x, y, z, x, y, z, x, y).func is Max\n    # test that Min/Max can handle more than 8 arguments\n    assert Min(x, y, z, x, y, z, x, y, z).func is Min\n    assert Max(x, y, z, x, y, z, x, y, z).func is Max\n    # test that Min/Max can handle more than 9 arguments\n    assert Min(x, y, z, x, y, z, x, y, z, x).func is Min\n    assert Max(x, y, z, x, y, z, x, y, z, x).func is Max\n"], "sample_221": ["def test_pickling_of_empty_queryset(self):\n    \"\"\"\n    Pickling an empty QuerySet should not raise an exception.\n    \"\"\"\n    qs = Event.objects.none()\n    self.assertEqual(list(pickle.loads(pickle.dumps(qs))), list(qs))\n"], "sample_1111": ["def test_rescaling():\n    x = Symbol('x')\n    lines = [\n        '      1 |                                                     ..',\n        '        |                                                  ...  ',\n        '        |                                                ..     ',\n        '        |                                             ...       ',\n        '        |                                          ...          ',\n        '        |                                        ..             ',\n        '        |                                     ...               ',\n        '        |                                  ...                  ',\n        '        |                                ..                     ',\n        '        |                             ...                       ',\n        '      0 |--------------------------...--------------------------',\n        '        |                       ...                             ',\n        '        |                     ..                                ',\n        '        |                  ...                                  ',\n        '        |               ...                                     ',\n        '        |             ..                                        ',\n        '        |          ...                                          ',\n        '        |       ...                                             ',\n        '        |     ..                                                ',\n        '        |  ...                                                  ',\n        '     -1 |_______________________________________________________',\n        '         -1                         0                          1'\n    ]\n    assert lines == list(textplot_str(x**2, -1, 1))\n\n    lines = [\n        '      1 |                                                     ..',\n        '        |                                                 ....  ',\n        '        |                                              ...      ',\n        '        |                                           ...         ',\n        '        |                                       ....            ',\n        '        |                                    ...                ',\n        '        |                                 ...                   ',\n        '        |                             ....                      ',\n        '      0 |--------------------------...--------------------------',\n        '        |                      ....                             ',\n        '        |                   ...                                 ',\n        '        |                ...                                    ',\n        '        |            ....                                       ',\n        '        |         ...                                           ',\n        '        |      ...                                              ',\n        '        |  ....                                                 ',\n        '     -1 |_______________________________________________________',\n        '         -1                         0                          1'\n    ]\n    assert lines == list(textplot_str(x**2, -1, 1, H=17))\n\n    lines = [\n        '      1 |                                                     ..',\n        '        |                                                  ...  ',\n        '        |                                                ..     ',\n        '        |                                             ...       ',\n        '        |                                          ...          ',\n        '        |                                        ..             ',\n        '        |                                     ...               ',\n        '        |                                  ...                  ',\n        '        |                                ..                     ',\n        '        |                             ...                       ',\n        '      0 |--------------------------...--------------------------',\n        '        |"], "sample_630": ["def test_get_values(obj, expected):\n    \"\"\"get label and shape for classes.\"\"\"\n    writer = DotWriter(Config())\n    values = writer.get_values(obj)\n    if expected:\n        assert values[\"fontcolor\"] == expected\n    else:\n        assert \"fontcolor\" not in values\n"], "sample_70": ["def test_collector_add_field_update(self):\n    collector = Collector(using='default')\n    field = A._meta.get_field('setvalue')\n    objs = [A.objects.create(setvalue=self.DEFAULT)]\n    collector.add_field_update(field, self.DEFAULT, objs)\n    self.assertEqual(len(collector.field_updates), 1)\n    self.assertEqual(len(collector.field_updates[A]), 1)\n    self.assertEqual(len(collector.field_updates[A][(field, self.DEFAULT)]), 1)\n    self.assertIn(objs[0], collector.field_updates[A][(field, self.DEFAULT)])\n"], "sample_353": ["    def test_createsuperuser_command_with_proxy_model(self):\n        new_io = StringIO()\n        call_command(\n            'createsuperuser',\n            interactive=False,\n            username='joe',\n            email='joe@somewhere.org',\n            stdout=new_io,\n        )\n        command_output = new_io.getvalue().strip()\n        self.assertEqual(command_output, 'Superuser created successfully.')\n        user = UserProxy.objects.get(username='joe')\n        self.assertEqual(user.email, 'joe@somewhere.org')\n"], "sample_1205": ["def test_PolyRing_compose():\n    R, x, y = ring(\"x,y\", ZZ)\n    S, u, v = ring(\"u,v\", R)\n\n    assert R.compose(S) == PolyRing(\"u,v,x,y\", ZZ, lex)\n\n    R, x, y = ring(\"x,y\", ZZ)\n    S, u, v = ring(\"u,v\", QQ)\n\n    assert R.compose(S) == PolyRing(\"u,v,x,y\", QQ, lex)\n\n    R, x, y = ring(\"x,y\", ZZ)\n    S, u, v = ring(\"u,v\", ZZ[x])\n\n    assert R.compose(S) == PolyRing(\"u,v,x,y\", ZZ[x], lex)\n\n    R, x, y = ring(\"x,y\", ZZ)\n    S, u, v = ring(\"u,v\", ZZ[x,y])\n\n    assert R.compose(S) == PolyRing(\"u,v,x,y\", ZZ[x,y], lex)\n\n    R, x, y = ring(\"x,y\", ZZ)\n    S, u, v = ring(\"u,v\", QQ[x,y])\n\n    assert R.compose(S) == PolyRing(\"u,v,x,y\", QQ[x,y], lex)\n\n    R, x, y = ring(\"x,y\", ZZ)\n    S, u, v = ring(\"u,v\", ZZ[x][y])\n\n    assert R.compose(S) == PolyRing(\"u,v,x,y\", ZZ[x][y], lex)\n\n    R, x, y = ring(\"x,y\", ZZ)\n    S, u, v = ring(\"u,v\", QQ[x][y])\n\n    assert R.compose(S) == PolyRing(\"u,v,x,y\", QQ[x][y], lex)\n\n    R, x, y = ring(\"x,y\", ZZ)\n    S, u, v = ring(\"u,v\", EX)\n\n    assert R.compose(S) == PolyRing(\"u,v,x,y\", EX, lex)\n\n    R, x, y = ring(\"x,y\", ZZ)\n    S, u, v = ring(\"u,v\", EX[x])\n\n    assert R.compose(S) == PolyRing(\"u,v,x,y\", EX[x], lex)\n\n    R, x, y = ring(\"x,y\", ZZ)\n    S, u, v = ring(\"u,v\", EX[x,y])\n\n    assert R.compose(S) == PolyRing(\"u,v,x,y\", EX[x,y], lex)\n\n    R,"], "sample_1094": ["def test_replace():\n    x, y, z = symbols('x y z')\n    a, b = symbols('a b')\n    f1 = sin(x) + cos(x)\n    assert f1.replace(sin(x), cos(x)) == cos(x) + cos(x)\n    assert f1.replace(sin(x), cos(x), map=True) == (cos(x) + cos(x), {sin(x): cos(x)})\n    assert f1.replace(sin(x), lambda x: cos(x)) == cos(x) + cos(x)\n    assert f1.replace(sin(x), lambda x: cos(x), map=True) == (cos(x) + cos(x), {sin(x): cos(x)})\n    assert f1.replace(sin(x), lambda x: cos(x**2)) == cos(x**2) + cos(x)\n    assert f1.replace(sin(x), lambda x: cos(x**2), map=True) == (cos(x**2) + cos(x), {sin(x): cos(x**2)})\n\n    assert f1.replace(sin(x), cos(x), exact=False) == cos(x) + cos(x)\n    assert f1.replace(sin(x), cos(x), exact=False, map=True) == (cos(x) + cos(x), {sin(x): cos(x)})\n\n    assert f1.replace(sin(x), cos(x), simultaneous=False) == cos(x) + cos(x)\n    assert f1.replace(sin(x), cos(x), simultaneous=False, map=True) == (cos(x) + cos(x), {sin(x): cos(x)})\n\n    assert f1.replace(sin(x), cos(x), simultaneous=False, exact=False) == cos(x) + cos(x)\n    assert f1.replace(sin(x), cos(x), simultaneous=False, exact=False, map=True) == (cos(x) + cos(x), {sin(x): cos(x)})\n\n    assert f1.replace(sin(x), cos(x), simultaneous=True) == cos(x) + cos(x)\n    assert f1.replace(sin(x), cos(x), simultaneous=True, map=True) == (cos(x) + cos(x), {sin(x): cos(x)})\n\n    assert f1.replace(sin(x), cos(x), simultaneous=True, exact=False) == cos(x) + cos(x)\n    assert f1.replace(sin(x), cos(x), simultaneous=True, exact=False, map=True) == (cos(x) + cos(x), {sin(x): cos(x)})\n\n    assert f1.replace(sin(x), cos"], "sample_911": ["def test_template_introductions():\n    check('class', 'template<typename T> concept C<T> A', {2: 'I0EX7ConceptI1TE1A'})\n    check('class', 'template<typename T> concept C<T> A<T>', {2: 'I0EX7ConceptI1TE1A'})\n    check('class', 'template<typename T> concept C<T> A<T, T>', {2: 'I0EX7ConceptI1TE1A'})\n    check('class', 'template<typename T> concept C<T> A<T, T, T>', {2: 'I0EX7ConceptI1TE1A'})\n    check('class', 'template<typename T> concept C<T> A<T, T, T, T>', {2: 'I0EX7ConceptI1TE1A'})\n    check('class', 'template<typename T> concept C<T> A<T, T, T, T, T>', {2: 'I0EX7ConceptI1TE1A'})\n    check('class', 'template<typename T> concept C<T> A<T, T, T, T, T, T>', {2: 'I0EX7ConceptI1TE1A'})\n    check('class', 'template<typename T> concept C<T> A<T, T, T, T, T, T, T>', {2: 'I0EX7ConceptI1TE1A'})\n    check('class', 'template<typename T> concept C<T> A<T, T, T, T, T, T, T, T>', {2: 'I0EX7ConceptI1TE1A'})\n    check('class', 'template<typename T> concept C<T> A<T, T, T, T, T, T, T, T, T>', {2: 'I0EX7ConceptI1TE1A'})\n    check('class', 'template<typename T> concept C<T> A<T, T, T, T, T, T, T, T, T, T>', {2: 'I0EX7ConceptI1TE1A'})\n    check('class', 'template<typename T> concept C<T> A<T, T, T, T, T, T, T, T, T, T, T>', {2: 'I0EX7ConceptI1TE1A'})\n    check('class', 'template<typename T"], "sample_961": ["def test_python_domain_get_full_qualified_name():\n    env = Mock(domaindata={})\n    domain = PythonDomain(env)\n\n    # non-python references\n    node = nodes.reference()\n    assert domain.get_full_qualified_name(node) is None\n\n    # simple reference\n    node = nodes.reference(reftarget='func')\n    assert domain.get_full_qualified_name(node) == 'func'\n\n    # with py:module context\n    kwargs = {'py:module': 'module1'}\n    node = nodes.reference(reftarget='func', **kwargs)\n    assert domain.get_full_qualified_name(node) == 'module1.func'\n\n    # with py:class context\n    kwargs = {'py:class': 'Class'}\n    node = nodes.reference(reftarget='func', **kwargs)\n    assert domain.get_full_qualified_name(node) == 'Class.func'\n\n    # with both py:module and py:class context\n    kwargs = {'py:module': 'module1', 'py:class': 'Class'}\n    node = nodes.reference(reftarget='func', **kwargs)\n    assert domain.get_full_qualified_name(node) == 'module1.Class.func'\n\n    # with py:module and py:class context and reftarget is None\n    kwargs = {'py:module': 'module1', 'py:class': 'Class'}\n    node = nodes.reference(**kwargs)\n    assert domain.get_full_qualified_name(node) is None\n"], "sample_340": ["def test_detect_conflicts(self):\n    \"\"\"\n    Tests detecting conflicts in the migration graph.\n    \"\"\"\n    migration_loader = MigrationLoader(connection)\n    conflicts = migration_loader.detect_conflicts()\n    self.assertEqual(conflicts, {})\n\n    # Create a conflict by adding a new migration with the same app label\n    # but different name.\n    with self.temporary_migration_module(module='migrations.test_migrations') as migration_dir:\n        with open(os.path.join(migration_dir, '0003_conflict.py'), 'w') as f:\n            f.write('from django.db import migrations\\n')\n            f.write('class Migration(migrations.Migration):\\n')\n            f.write('    dependencies = [(\"migrations\", \"0002_second\")]\\n')\n            f.write('    operations = []\\n')\n        migration_loader.build_graph()\n        conflicts = migration_loader.detect_conflicts()\n        self.assertEqual(conflicts, {\"migrations\": [\"0002_second\", \"0003_conflict\"]})\n"], "sample_849": ["def test_leave_p_out():\n    # Test LeavePOut with different values of p\n    X = np.arange(10)\n    y = np.arange(10)\n    for p in range(1, 11):\n        lpo = LeavePOut(p)\n        splits = list(lpo.split(X, y))\n        assert len(splits) == comb(10, p)\n        for train, test in splits:\n            assert len(test) == p\n            assert len(train) == 10 - p\n            assert_array_equal(np.intersect1d(train, test), [])\n            assert_array_equal(np.union1d(train, test), np.arange(10))\n"], "sample_1175": ["def test_pretty_tensor():\n    from sympy.tensor.tensor import TensorHead\n    from sympy.tensor.tensor import TensorIndexType\n    from sympy.tensor.tensor import tensor_indices\n    from sympy.tensor.tensor import TensorElement\n\n    L = TensorIndexType(\"L\")\n    i, j, k = tensor_indices(\"i j k\", L)\n    i0 = tensor_indices(\"i_0\", L)\n    A, B, C, D = tensor_heads(\"A B C D\", [L])\n    H = TensorHead(\"H\", [L, L])\n\n    expr = A(i)*B(j)\n    ascii_str = \\"], "sample_654": ["    def test_getfixtureinfo(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n                return 1\n\n            @pytest.fixture\n                return arg1 + 1\n\n                pass\n        \"\"\"\n        )\n        item = testdir.getitem(\"test_func\")\n        fixtureinfo = item._fixtureinfo\n        assert fixtureinfo.argnames == (\"arg2\",)\n        assert fixtureinfo.initialnames == (\"arg2\", \"arg1\")\n        assert fixtureinfo.names_closure == (\"arg2\", \"arg1\", \"request\")\n"], "sample_857": ["def test_prune_tree_on_unfitted_model():\n    # Pruning should raise an error if the model is not fitted\n    clf = DecisionTreeClassifier()\n    with pytest.raises(NotFittedError):\n        clf._prune_tree()\n"], "sample_639": ["def test_base_checker_comparison() -> None:\n    basic = OtherBasicChecker()\n    less_basic = LessBasicChecker()\n    different_basic = DifferentBasicChecker()\n\n    assert basic == less_basic\n    assert hash(basic) == hash(less_basic)\n    assert basic != different_basic\n    assert hash(basic) != hash(different_basic)\n\n    assert basic > different_basic\n    assert less_basic > different_basic\n    assert not (basic > less_basic)\n    assert not (less_basic > basic)\n"], "sample_668": ["def test_funcargnames_deprecated(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            return 42\n\n            assert my_fixture == 42\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: The `funcargnames` attribute was an alias for `fixturenames`, since pytest 2.3 - use the newer attribute instead.*\"\n        ]\n    )\n\n"], "sample_764": ["def test_column_transformer_transformer_weights():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    X_res_first = np.array([0, 1, 2]).reshape(-1, 1)\n    X_res_second = np.array([2, 4, 6]).reshape(-1, 1)\n    X_res_both = X_array\n\n    # test with transformer_weights\n    transformer_weights = {'trans1': .1, 'trans2': 10}\n    both = ColumnTransformer([('trans1', Trans(), [0]),\n                              ('trans2', Trans(), [1])],\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * X_res_first1D,\n                     transformer_weights['trans2'] * X_res_second1D]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and remainder\n    transformer_weights = {'trans1': .1}\n    both = ColumnTransformer([('trans1', Trans(), [0])],\n                             remainder='passthrough',\n                             transformer_weights=transformer_weights)\n    res = np.hstack([transformer_weights['trans1'] * X_res_first,\n                     X_res_second])\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and remainder transformer\n    transformer_weights = {'trans1': .1}\n    both = ColumnTransformer([('trans1', Trans(), [0])],\n                             remainder=DoubleTrans(),\n                             transformer_weights=transformer_weights)\n    res = np.hstack([transformer_weights['trans1'] * X_res_first,\n                     2 * X_res_second])\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and all transformers are 'drop'\n    transformer_weights = {'trans1': .1, 'trans2': 10}\n    both = ColumnTransformer([('trans1', 'drop', [0]),\n                              ('trans2', 'drop',"], "sample_10": ["def test_table_attribute_with_table_init():\n    class MyTable(Table):\n        foo = TableAttribute()\n        bar = TableAttribute(default=[])\n        baz = TableAttribute(default=1)\n\n    t = MyTable([[1, 2]], foo=3, bar='bar', baz='baz')\n    assert t.foo == 3\n    assert t.bar == 'bar'\n    assert t.baz == 'baz'\n\n    t2 = MyTable(t, foo=5, bar='fubar')\n    assert t2.foo == 5\n    assert t2.bar == 'fubar'\n    assert t2.baz == 'baz'\n"], "sample_897": ["def test_plot_partial_dependence_centered(pyplot, clf_diabetes, diabetes, kind, centered, subsample, shape):\n    disp = PartialDependenceDisplay.from_estimator(\n        clf_diabetes,\n        diabetes.data,\n        [0, 1, 2],\n        kind=kind,\n        centered=centered,\n        subsample=subsample,\n    )\n\n    assert disp.axes_.shape == (1, 3)\n    assert disp.lines_.shape == shape\n    assert disp.contours_.shape == (1, 3)\n\n    assert disp.contours_[0, 0] is None\n    assert disp.contours_[0, 1] is None\n    assert disp.contours_[0, 2] is None\n\n    if centered:\n        assert all([ln._y[0] == 0.0 for ln in disp.lines_.ravel() if ln is not None])\n    else:\n        assert all([ln._y[0] != 0.0 for ln in disp.lines_.ravel() if ln is not None])\n"], "sample_1081": ["def test_is_amicable():\n    assert is_amicable(220, 284) is True\n    assert is_amicable(1184, 1210) is True\n    assert is_amicable(2620, 2924) is True\n    assert is_amicable(5020, 5564) is True\n    assert is_amicable(6232, 6368) is True\n    assert is_amicable(10744, 10856) is True\n    assert is_amicable(12285, 14595) is False\n    assert is_amicable(17296, 18416) is True\n    assert is_amicable(63020, 76084) is False\n    assert is_amicable(66992, 66992) is False\n    assert is_amicable(67095, 71145) is True\n    assert is_amicable(69615, 87633) is True\n    assert is_amicable(79750, 88730) is False\n"], "sample_113": ["    def test_get_view_name(self):\n        class TestView:\n            pass\n\n        view = TestView()\n        view.__module__ = 'test_module'\n        view.__qualname__ = 'TestView'\n        self.assertEqual(utils.get_view_name(view), 'test_module.TestView')\n"], "sample_408": ["def test_alter_field_to_fk_dependency_other_app_with_custom_fk(self):\n    class CustomForeignKey(models.ForeignKey):\n            kwargs[\"to\"] = \"testapp.Author\"\n            super().__init__(*args, **kwargs)\n\n            name, path, args, kwargs = super().deconstruct()\n            del kwargs[\"to\"]\n            return name, path, args, kwargs\n\n    book_custom_fk_to = ModelState(\n        \"otherapp\",\n        \"Book\",\n        [\n            (\"author\", CustomForeignKey(on_delete=models.CASCADE)),\n        ],\n    )\n    changes = self.get_changes(\n        [self.author_empty],\n        [self.author_empty, book_custom_fk_to],\n    )\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"CreateModel\"])\n    self.assertMigrationDependencies(\n        changes, \"otherapp\", 0, [(\"testapp\", \"__first__\")]\n    )\n"], "sample_375": ["    def test_get_related_models_tuples(self):\n        project_state = ProjectState()\n        project_state.add_model(ModelState(\n            app_label='migrations',\n            name='Tag',\n            fields=[('id', models.AutoField(primary_key=True))],\n        ))\n        project_state.add_model(ModelState(\n            app_label='migrations',\n            name='SubTag',\n            fields=[\n                ('tag_ptr', models.OneToOneField(\n                    'migrations.Tag',\n                    models.CASCADE,\n                    auto_created=True,\n                    parent_link=True,\n                    primary_key=True,\n                    to_field='id',\n                    serialize=False,\n                )),\n                (\"awesome\", models.BooleanField()),\n            ],\n            bases=(\"migrations.Tag\",),\n        ))\n        project_state.add_model(ModelState(\n            app_label='migrations',\n            name='Food',\n            fields=[\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"tag\", models.ForeignKey('migrations.Tag', models.CASCADE)),\n            ],\n        ))\n        self.assertEqual(\n            get_related_models_tuples(project_state.models['migrations', 'tag']),\n            {('migrations', 'subtag'), ('migrations', 'food')},\n        )\n        self.assertEqual(\n            get_related_models_tuples(project_state.models['migrations', 'subtag']),\n            set(),\n        )\n        self.assertEqual(\n            get_related_models_tuples(project_state.models['migrations', 'food']),\n            {('migrations', 'tag')},\n        )\n"], "sample_1160": ["def test_intersection_sets():\n    assert intersection_sets(S.Integers, S.Reals) == S.Integers\n    assert intersection_sets(S.Naturals, S.Reals) == S.Naturals\n    assert intersection_sets(S.Naturals0, S.Reals) == S.Naturals0\n    assert intersection_sets(S.Rationals, S.Reals) == S.Rationals\n    assert intersection_sets(S.Integers, S.Rationals) == S.Integers\n    assert intersection_sets(S.Naturals, S.Rationals) == S.Naturals\n    assert intersection_sets(S.Naturals0, S.Rationals) == S.Naturals0\n    assert intersection_sets(S.Integers, S.Naturals) == S.Integers\n    assert intersection_sets(S.Integers, S.Naturals0) == S.Naturals0\n    assert intersection_sets(S.Naturals, S.Naturals0) == S.Naturals0\n    assert intersection_sets(S.Rationals, S.Integers) == S.Integers\n    assert intersection_sets(S.Rationals, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Rationals, S.Naturals0) == S.Naturals0\n    assert intersection_sets(S.Reals, S.Integers) == S.Integers\n    assert intersection_sets(S.Reals, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Reals, S.Naturals0) == S.Naturals0\n    assert intersection_sets(S.Reals, S.Rationals) == S.Rationals\n    assert intersection_sets(S.Complexes, S.Integers) == S.Integers\n    assert intersection_sets(S.Complexes, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Complexes, S.Naturals0) == S.Naturals0\n    assert intersection_sets(S.Complexes, S.Rationals) == S.Rationals\n    assert intersection_sets(S.Complexes, S.Reals) == S.Reals\n"], "sample_484": ["    def setUpTestData(cls):\n        Author.objects.create(name=\"John Smith\", alias=\"smithj\")\n        Author.objects.create(name=\"Rhonda\")\n"], "sample_742": ["def test_logistic_regression_path_multiclass():\n    # Test logistic_regression_path for multiclass problems\n    X, y = make_classification(n_samples=50, n_features=20, n_informative=10,\n                               n_classes=3, random_state=0)\n    Cs = [1.0]\n    solvers = ['lbfgs', 'newton-cg', 'sag', 'saga']\n    for solver in solvers:\n        coefs, Cs, n_iter = logistic_regression_path(\n            X, y, Cs=Cs, fit_intercept=True, solver=solver,\n            multi_class='multinomial', random_state=42, max_iter=2000, tol=1e-7)\n        assert_array_equal(coefs[0].shape, (3, X.shape[1]))\n        assert_array_equal(n_iter.shape, (1,))\n"], "sample_400": ["def test_alter_field_with_default_to_not_null_with_default(self):\n    \"\"\"\n    #23609 - Tests autodetection of nullable to non-nullable alterations.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_name_null], [self.author_name_default]\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True\n    )\n    self.assertOperationFieldAttributes(\n        changes, \"testapp\", 0, 0, default=\"Ada Lovelace\"\n    )\n"], "sample_283": ["    def test_sigint_handler_restore(self):\n        \"\"\"The original SIGINT handler is restored after running psql.\"\"\"\n            pass\n\n            return signal.SIG_DFL\n\n        with mock.patch('subprocess.run', side_effect=_mock_subprocess_run):\n            with mock.patch('signal.getsignal', side_effect=_mock_signal_getsignal):\n                original_handler = signal.getsignal(signal.SIGINT)\n                DatabaseClient().runshell([])\n                self.assertEqual(signal.getsignal(signal.SIGINT), original_handler)\n"], "sample_735": ["def test_gaussian_mixture_score_samples_shape():\n    # Test that score_samples returns a correct shape\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng, scale=7)\n    n_components = rand_data.n_components\n\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        gmm = GaussianMixture(n_components=n_components,\n                              covariance_type=covar_type, random_state=rng)\n        gmm.fit(X)\n        scores = gmm.score_samples(X)\n        assert_equal(scores.shape, (X.shape[0],))\n"], "sample_501": ["def test_legend_title_fontproperties():\n    # test the title_fontproperties kwarg\n    fig, ax = plt.subplots()\n    ax.plot(range(10))\n    leg = ax.legend(title='Aardvark', title_fontproperties={'family': 'serif'})\n    assert leg.get_title().get_family() == ['serif']\n    leg = ax.legend(title='Aardvark', title_fontproperties={'size': 22})\n    assert leg.get_title().get_size() == 22\n    leg = ax.legend(title='Aardvark', title_fontproperties={'weight': 'bold'})\n    assert leg.get_title().get_weight() == 700\n"], "sample_64": ["    def test_status_code(self):\n        response = HttpResponseBase()\n        self.assertEqual(response.status_code, 200)\n        response.status_code = 404\n        self.assertEqual(response.status_code, 404)\n"], "sample_40": ["def test_with_H0():\n    h100 = 0.7\n    H0 = h100 * 100 * u.km / (u.s * u.Mpc)\n    equiv = u.with_H0(H0)\n    assert u.littleh.to_value(u.dimensionless_unscaled, equivalencies=equiv) == h100\n    assert u.dimensionless_unscaled.to_value(u.littleh, equivalencies=equiv) == h100\n    assert u.littleh.to_value(u.dimensionless_unscaled, equivalencies=u.with_H0()) == cosmology.default_cosmology.get().h\n    assert u.dimensionless_unscaled.to_value(u.littleh, equivalencies=u.with_H0()) == cosmology.default_cosmology.get().h\n"], "sample_505": ["def test_date2num_timezone():\n    # Test date2num with timezone-aware datetime objects\n    dt = datetime.datetime(2020, 1, 1, tzinfo=datetime.timezone.utc)\n    dt2 = datetime.datetime(2020, 1, 1, tzinfo=datetime.timezone(datetime.timedelta(hours=1)))\n    assert mdates.date2num(dt) == mdates.date2num(dt2)\n"], "sample_35": ["def test_resolve_name():\n    \"\"\"\n    Tests that the `resolve_name` function works.\n    \"\"\"\n    assert introspection.resolve_name('astropy.utils.introspection.resolve_name') == introspection.resolve_name\n    assert introspection.resolve_name('astropy', 'utils', 'introspection', 'resolve_name') == introspection.resolve_name\n\n    with pytest.raises(ImportError):\n        introspection.resolve_name('nonexistent_module.nonexistent_object')\n\n    with pytest.raises(ImportError):\n        introspection.resolve_name('astropy', 'utils', 'nonexistent_module', 'nonexistent_object')\n\n"], "sample_895": ["def test_column_transformer_set_output_with_remainder_transformer():\n    \"\"\"Check column transformer behavior with set_output and remainder transformer.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame(\n        {\n            \"pet\": pd.Series([\"dog\", \"cat\", \"snake\"], dtype=\"category\"),\n            \"age\": [1.4, 2.1, 4.4],\n            \"height\": [20, 40, 10],\n        }\n    )\n    ct = ColumnTransformer(\n        [\n            (\n                \"color_encode\",\n                OneHotEncoder(sparse_output=False, dtype=\"int8\"),\n                [\"pet\"],\n            ),\n            (\"age\", StandardScaler(), [\"age\"]),\n        ],\n        remainder=StandardScaler(),\n        verbose_feature_names_out=False,\n    )\n\n    # fit without calling set_output\n    X_trans = ct.fit_transform(df)\n    assert isinstance(X_trans, np.ndarray)\n    assert X_trans.dtype == \"float64\"\n\n    ct.set_output(transform=\"pandas\")\n\n    df_test = pd.DataFrame(\n        {\n            \"pet\": pd.Series([\"dog\", \"cat\", \"snake\"], dtype=\"category\"),\n            \"age\": [1.4, 2.1, 4.4],\n            \"height\": [20, 40, 10],\n        }\n    )\n    X_trans = ct.transform(df_test)\n    assert isinstance(X_trans, pd.DataFrame)\n\n    expected_dtypes = {\n        \"pet_cat\": \"int8\",\n        \"pet_dog\": \"int8\",\n        \"pet_snake\": \"int8\",\n        \"age\": \"float64\",\n        \"height\": \"float64\",\n    }\n    for col, dtype in X_trans.dtypes.items():\n        assert dtype == expected_dtypes[col]\n"], "sample_905": ["def test_is_new_type():\n    from typing import NewType\n\n    MyInt = NewType('MyInt', int)\n    assert inspect.isNewType(MyInt) is True\n\n    class MyInt:\n        pass\n    assert inspect.isNewType(MyInt) is False\n\n    if sys.version_info < (3, 10):\n        MyInt = NewType('MyInt', int)\n        assert inspect.isNewType(MyInt) is True\n"], "sample_554": ["def test_text_repr_with_non_string_input():\n    # Test that text repr doesn't error for non-string input\n    fig, ax = plt.subplots()\n    ax.text(0.5, 0.5, 123)\n    repr(ax.text(0.5, 0.5, 123))\n"], "sample_540": ["def test_animation_repr_html_embed_limit(anim):\n    if platform.python_implementation() == 'PyPy':\n        # Something in the test setup fixture lingers around into the test and\n        # breaks pytest.warns on PyPy. This garbage collection fixes it.\n        # https://foss.heptapod.net/pypy/pypy/-/issues/3536\n        np.testing.break_cycles()\n    with mpl.rc_context({'animation.embed_limit': 1e-6}):  # ~1 byte.\n        with pytest.warns(UserWarning, match='Animation size has reached'):\n            anim._repr_html_()\n"], "sample_625": ["def test_cross() -> None:\n    # Test cross product with 3 dimensions\n    a = xr.DataArray([1, 2, 3], dims=\"cartesian\")\n    b = xr.DataArray([4, 5, 6], dims=\"cartesian\")\n    expected = xr.DataArray([-3, 6, -3], dims=\"cartesian\")\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(expected, actual)\n\n    # Test cross product with 2 dimensions, returns in the perpendicular direction\n    a = xr.DataArray([1, 2], dims=\"cartesian\")\n    b = xr.DataArray([4, 5], dims=\"cartesian\")\n    expected = xr.DataArray(-3, dims=())\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(expected, actual)\n\n    # Test cross product with 3 dimensions but zeros at the last axis yields the same results as with 2 dimensions\n    a = xr.DataArray([1, 2, 0], dims=\"cartesian\")\n    b = xr.DataArray([4, 5, 0], dims=\"cartesian\")\n    expected = xr.DataArray([0, 0, -3], dims=\"cartesian\")\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(expected, actual)\n\n    # Test one vector with dimension 2\n    a = xr.DataArray([1, 2], dims=\"cartesian\", coords={\"cartesian\": [\"x\", \"y\"]})\n    b = xr.DataArray([4, 5, 6], dims=\"cartesian\", coords={\"cartesian\": [\"x\", \"y\", \"z\"]})\n    expected = xr.DataArray([12, -6, -3], dims=\"cartesian\", coords={\"cartesian\": [\"x\", \"y\", \"z\"]})\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(expected, actual)\n\n    # Test one vector with dimension 2 but coords in other positions\n    a = xr.DataArray([1, 2], dims=\"cartesian\", coords={\"cartesian\": [\"x\", \"z\"]})\n    b = xr.DataArray([4, 5, 6], dims=\"cartesian\", coords={\"cartesian\": [\"x\", \"y\", \"z\"]})\n    expected = xr.DataArray([-10,"], "sample_286": ["    def test_save_with_deferred_fields(self):\n        a = Article.objects.create(headline='Article 1', pub_date=datetime.now())\n        a_deferred = Article.objects.defer('headline').get(pk=a.pk)\n        self.assertEqual(a_deferred.headline, 'Article 1')\n        a_deferred.save()\n        self.assertEqual(Article.objects.get(pk=a.pk).headline, 'Article 1')\n"], "sample_1040": ["def test_print_random_symbol():\n    expr = RandomSymbol('x')\n    assert mpp.doprint(expr) == '<mi>x</mi>'\n    assert mp.doprint(expr) == '<ci>x</ci>'\n    assert mathml(expr, printer='presentation', mat_symbol_style=\"bold\" )== '<mi mathvariant=\"bold\">x</mi>'\n    assert mathml(expr, mat_symbol_style=\"bold\" )== '<ci>x</ci>' # No effect in content printer\n"], "sample_981": ["def test_cycle_structure():\n    p = Permutation([0, 3, 1, 2])\n    assert p.cycle_structure == {2: 2}\n    p = Permutation([0, 1, 2, 3])\n    assert p.cycle_structure == {1: 4}\n    p = Permutation([0, 2, 1, 3])\n    assert p.cycle_structure == {2: 2}\n    p = Permutation([0, 3, 2, 1])\n    assert p.cycle_structure == {2: 2}\n    p = Permutation([0, 1, 3, 2])\n    assert p.cycle_structure == {1: 2, 2: 1}\n    p = Permutation([0, 2, 3, 1])\n    assert p.cycle_structure == {1: 1, 3: 1}\n    p = Permutation([0, 3, 1, 2])\n    assert p.cycle_structure == {2: 2}\n    p = Permutation([1, 0, 2, 3])\n    assert p.cycle_structure == {2: 1, 1: 1}\n    p = Permutation([1, 2, 0, 3])\n    assert p.cycle_structure == {3: 1}\n    p = Permutation([1, 2, 3, 0])\n    assert p.cycle_structure == {1: 1, 3: 1}\n    p = Permutation([1, 3, 0, 2])\n    assert p.cycle_structure == {2: 2}\n    p = Permutation([1, 3, 2, 0])\n    assert p.cycle_structure == {1: 1, 3: 1}\n    p = Permutation([2, 0, 1, 3])\n    assert p.cycle_structure == {1: 1, 3: 1}\n    p = Permutation([2, 0, 3, 1])\n    assert p.cycle_structure == {2: 2}\n    p = Permutation([2, 1, 0, 3])\n    assert p.cycle_structure == {1: 1, 3: 1}\n    p = Permutation([2, 1, 3, 0])\n    assert p.cycle_structure == {1: "], "sample_601": ["def test_cftime_round_accessor(cftime_rounding_dataarray, cftime_date_type, use_dask):\n    import dask.array as da\n\n    freq = \"D\"\n    expected = xr.DataArray(\n        [\n            [cftime_date_type(1, 1, 1, 0), cftime_date_type(1, 1, 1, 0)],\n            [cftime_date_type(1, 1, 1, 0), cftime_date_type(1, 1, 2, 0)],\n        ],\n        name=\"round\",\n    )\n\n    if use_dask:\n        chunks = {\"dim_0\": 1}\n        # Currently a compute is done to inspect a single value of the array\n        # if it is of object dtype to check if it is a cftime.datetime (if not\n        # we raise an error when using the dt accessor).\n        with raise_if_dask_computes(max_computes=1):\n            result = cftime_rounding_dataarray.chunk(chunks).dt.round(freq)\n        expected = expected.chunk(chunks)\n        assert isinstance(result.data, da.Array)\n        assert result.chunks == expected.chunks\n    else:\n        result = cftime_rounding_dataarray.dt.round(freq)\n\n    assert_identical(result, expected)\n"], "sample_829": ["def test_incremental_pca_batch_size():\n    # Test that batch_size is used correctly.\n    rng = np.random.RandomState(1999)\n    n_samples = 100\n    n_features = 3\n    X = rng.randn(n_samples, n_features)\n    batch_sizes = [10, 20, 50, n_samples]\n    for batch_size in batch_sizes:\n        ipca = IncrementalPCA(n_components=None, batch_size=batch_size).fit(X)\n        assert ipca.batch_size_ == batch_size\n"], "sample_1044": ["def test_Pow_is_constant():\n    x = Symbol('x')\n    assert Pow(x, 0, evaluate=False).is_constant() is True\n    assert Pow(x, 1, evaluate=False).is_constant() is False\n    assert Pow(x, 2, evaluate=False).is_constant() is False\n    assert Pow(2, x, evaluate=False).is_constant() is False\n    assert Pow(2, 0, evaluate=False).is_constant() is True\n    assert Pow(2, 1, evaluate=False).is_constant() is True\n    assert Pow(2, 2, evaluate=False).is_constant() is True\n"], "sample_1098": ["def test_hyper_representatives():\n    from sympy import symbols, I, exp_polar, pi\n    z = symbols('z')\n    a = symbols('a')\n\n    # Test HyperRep_power1\n    assert hyper([-a], [], z).rewrite('nonrepsmall') == (1 - z)**a\n    assert hyper([-a], [], -z).rewrite('nonrepsmall') == (1 + z)**a\n    assert hyper([-a], [], exp_polar(2*I*pi)*z).rewrite('nonrepsmall') == (1 - z)**a\n    assert hyper([-a], [], exp_polar(I*pi)*z).rewrite('nonrepsmall') == (1 + z)**a\n\n    # Test HyperRep_power2\n    assert hyper([a, a - S.Half], [2*a], z).rewrite('nonrepsmall') == 2**(2*a - 1)*(1 + sqrt(1 - z))**(1 - 2*a)\n    assert hyper([a, a - S.Half], [2*a], -z).rewrite('nonrepsmall') == 2**(2*a - 1)*(1 + sqrt(1 + z))**(1 - 2*a)\n    assert hyper([a, a - S.Half], [2*a], exp_polar(2*I*pi)*z).rewrite('nonrepsmall') == 2**(2*a - 1)*(1 + sqrt(1 - z))**(1 - 2*a)\n    assert hyper([a, a - S.Half], [2*a], exp_polar(I*pi)*z).rewrite('nonrepsmall') == 2**(2*a - 1)*(1 + sqrt(1 + z))**(1 - 2*a)\n\n    # Test HyperRep_log1\n    assert -z*hyper([1, 1], [2], z).rewrite('nonrepsmall') == log(1 - z)\n    assert -z*hyper([1, 1], [2], -z).rewrite('nonrepsmall') == log(1 + z)\n    assert -z*hyper([1, 1], [2], exp_polar(2*I*pi)*z).rewrite('nonrepsmall') == log(1 - z)\n    assert -z*hyper([1, 1], [2], exp_polar(I*pi)*"], "sample_925": ["def test_mock_finder():\n    modnames = ['sphinx.unknown', 'sphinx.unknown2']\n    finder = MockFinder(modnames)\n    assert finder.modnames == modnames\n    assert finder.mocked_modules == []\n\n    spec = finder.find_spec('sphinx.unknown', None)\n    assert spec is not None\n    assert spec.loader is finder.loader\n    assert finder.mocked_modules == ['sphinx.unknown']\n\n    spec = finder.find_spec('sphinx.unknown.submodule', None)\n    assert spec is not None\n    assert spec.loader is finder.loader\n    assert finder.mocked_modules == ['sphinx.unknown', 'sphinx.unknown.submodule']\n\n    spec = finder.find_spec('sphinx.known', None)\n    assert spec is None\n\n    finder.invalidate_caches()\n    assert finder.mocked_modules == []\n"], "sample_722": ["def test_k_means_elkan_algorithm():\n    # Test that the Elkan algorithm is used when the input data is dense\n    # and the algorithm is set to 'auto'\n    km = KMeans(n_clusters=n_clusters, algorithm='auto', random_state=42)\n    km.fit(X)\n    assert_equal(km.algorithm, 'elkan')\n\n    # Test that the Elkan algorithm is used when the input data is dense\n    # and the algorithm is set to 'elkan'\n    km = KMeans(n_clusters=n_clusters, algorithm='elkan', random_state=42)\n    km.fit(X)\n    assert_equal(km.algorithm, 'elkan')\n\n    # Test that the full algorithm is used when the input data is sparse\n    # and the algorithm is set to 'auto'\n    km = KMeans(n_clusters=n_clusters, algorithm='auto', random_state=42)\n    km.fit(X_csr)\n    assert_equal(km.algorithm, 'full')\n\n    # Test that the full algorithm is used when the input data is sparse\n    # and the algorithm is set to 'full'\n    km = KMeans(n_clusters=n_clusters, algorithm='full', random_state=42)\n    km.fit(X_csr)\n    assert_equal(km.algorithm, 'full')\n\n    # Test that an error is raised when the input data is sparse\n    # and the algorithm is set to 'elkan'\n    km = KMeans(n_clusters=n_clusters, algorithm='elkan', random_state=42)\n    assert_raise_message(TypeError, \"algorithm='elkan' not supported for \"\n                         \"sparse input X\", km.fit, X_csr)\n"], "sample_848": ["def test_regressor_chain_fit_and_predict_with_linear_model():\n    # Fit regressor chain and verify predict performance using LinearRegression\n    X, Y = generate_multilabel_dataset_with_correlations()\n    regressor_chain = RegressorChain(Ridge())\n    regressor_chain.fit(X, Y)\n\n    Y_pred = regressor_chain.predict(X)\n    assert Y_pred.shape == Y.shape\n\n    # train the ridge with each column and assert that predictions are equal\n    for i in range(4):\n        ridge_ = Ridge()  # create a clone with the same state\n        ridge_.fit(X, Y[:, i])\n        assert_array_almost_equal(ridge_.predict(X), Y_pred[:, i])\n"], "sample_900": ["def test_mlp_regressor_sparse_input():\n    # Test that sparse input matrices output the same results as dense input.\n    X = Xboston[:50]\n    y = yboston[:50]\n    X_sparse = csr_matrix(X)\n    mlp = MLPRegressor(solver='lbfgs', hidden_layer_sizes=15,\n                       random_state=1)\n    mlp.fit(X, y)\n    pred1 = mlp.predict(X)\n    mlp.fit(X_sparse, y)\n    pred2 = mlp.predict(X_sparse)\n    assert_almost_equal(pred1, pred2)\n    pred1 = mlp.predict(X)\n    pred2 = mlp.predict(X_sparse)\n    assert_array_equal(pred1, pred2)\n"], "sample_988": ["def test_issue_13081_12583_12534_edge_cases():\n    # 13081\n    r = Rational('905502432259640373/288230376151711744')\n    assert (r <= pi) is S.false\n    assert (r >= pi) is S.true\n    # 12583\n    v = sqrt(2)\n    u = sqrt(v) + 2/sqrt(10 - 8/sqrt(2 - v) + 4*v*(1/sqrt(2 - v) - 1))\n    assert (u > 0) is S.true\n    # 12534; Rational vs NumberSymbol\n    # here are some precisions for which Rational forms\n    # at a lower and higher precision bracket the value of pi\n    # e.g. for p = 20:\n    # Rational(pi.n(p + 1)).n(25) = 3.14159265358979323846 2834\n    #                    pi.n(25) = 3.14159265358979323846 2643\n    # Rational(pi.n(p    )).n(25) = 3.14159265358979323846 1987\n    assert [p for p in range(20, 50) if\n            (Rational(pi.n(p)) <= pi) and\n            (pi <= Rational(pi.n(p + 1)))\n        ] == [20, 24, 27, 33, 37, 43, 48]\n    # pick one such precision and affirm that the reversed operation\n    # gives the opposite result, i.e. if x < y is true then x > y\n    # must be false\n    p = 20\n    # Rational vs NumberSymbol\n    L = [Rational(pi.n(i)) < pi for i in (p, p + 1)]\n    G = [Rational(pi.n(i)) > pi for i in (p, p + 1)]\n    assert L == [False, True]\n    assert all(i is not j for i, j in zip(L, G))\n    # Float vs NumberSymbol\n    L = [pi.n(i) < pi for i in (p, p + 1)]\n    G = [pi.n(i) > pi for i in (p, p + 1)]\n    assert L == [False, True]\n    assert all(i is not"], "sample_219": ["    def test_window_frame_start_end(self):\n        connection = connection\n        start = 1\n        end = 2\n        row_range = RowRange(start, end)\n        self.assertEqual(row_range.window_frame_start_end(connection, start, end), (connection.ops.PRECEDING, connection.ops.FOLLOWING))\n\n        value_range = ValueRange(start, end)\n        self.assertEqual(value_range.window_frame_start_end(connection, start, end), (connection.ops.PRECEDING, connection.ops.FOLLOWING))\n\n        row_range = RowRange(start, None)\n        self.assertEqual(row_range.window_frame_start_end(connection, start, None), (connection.ops.PRECEDING, connection.ops.UNBOUNDED_FOLLOWING))\n\n        row_range = RowRange(None, end)\n        self.assertEqual(row_range.window_frame_start_end(connection, None, end), (connection.ops.UNBOUNDED_PRECEDING, connection.ops.FOLLOWING))\n\n        row_range = RowRange(None, None)\n        self.assertEqual(row_range.window_frame_start_end(connection, None, None), (connection.ops.UNBOUNDED_PRECEDING, connection.ops.UNBOUNDED_FOLLOWING))\n\n        value_range = ValueRange(start, None)\n        self.assertEqual(value_range.window_frame_start_end(connection, start, None), (connection.ops.PRECEDING, connection.ops.UNBOUNDED_FOLLOWING))\n\n        value_range = ValueRange(None, end)\n        self.assertEqual(value_range.window_frame_start_end(connection, None, end), (connection.ops.UNBOUNDED_PRECEDING, connection.ops.FOLLOWING))\n\n        value_range = ValueRange(None, None)\n        self.assertEqual(value_range.window_frame_start_end(connection, None, None), (connection.ops.UNBOUNDED_PRECEDING, connection.ops.UNBOUNDED_FOLLOWING))\n"], "sample_1006": ["def test_subfactorial():\n    x = Symbol('x')\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True, nonnegative=True)\n\n    assert subfactorial(0) == 1\n    assert subfactorial(1) == 0\n    assert subfactorial(5) == 44\n    assert subfactorial(n).func == subfactorial\n    assert subfactorial(x).func == subfactorial\n\n    assert subfactorial(n).is_integer is None\n    assert subfactorial(k).is_integer is True\n    assert subfactorial(x).is_integer is None\n\n    assert subfactorial(n).is_nonnegative is None\n    assert subfactorial(k).is_nonnegative is True\n    assert subfactorial(x).is_nonnegative is None\n\n    assert subfactorial(n).is_even is None\n    assert subfactorial(k).is_even is True\n    assert subfactorial(x).is_even is None\n\n    assert subfactorial(n).is_odd is None\n    assert subfactorial(k).is_odd is False\n    assert subfactorial(x).is_odd is None\n\n    assert subfactorial(n).rewrite(uppergamma) == uppergamma(n + 1, -1)/S.Exp1\n"], "sample_608": ["def test_unindexed_dims_repr() -> None:\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3])}\n    expected = \"Dimensions without coordinates: x, y, z\"\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n\n    dims = [\"x\", \"y\"]\n    coords = {\"x\": np.array([1, 2, 3]), \"y\": np.array([4, 5, 6])}\n    expected = None\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n\n    dims = []\n    coords = {}\n    expected = None\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n"], "sample_950": ["def test_type_to_xref(app):\n    text = \"List[int]\"\n    doctree = PythonDomain.type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"List\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \"]\"]))\n\n    text = \"List[int | str]\"\n    doctree = PythonDomain.type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"List\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \" | \"],\n                          [pending_xref, \"str\"],\n                          [desc_sig_punctuation, \"]\"]))\n\n    text = \"List[int, str]\"\n    doctree = PythonDomain.type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"List\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \", \"],\n                          [pending_xref, \"str\"],\n                          [desc_sig_punctuation, \"]\"]))\n\n    text = \"List[int, ...]\"\n    doctree = PythonDomain.type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"List\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \", \"],\n                          [desc_sig_punctuation, \"...\"],\n                          [desc_sig_punctuation, \"]\"]))\n\n    text = \"List[()]\"  # empty tuple\n    doctree = PythonDomain.type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"List\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [desc_sig_punctuation, \"(\"],\n                          [desc_sig_punctuation, \")\"],\n                          [desc_sig_punctuation, \"]\"]))\n\n    text = \"List[(int, str)]\"  # nested tuple\n    doctree = PythonDomain.type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"List\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [desc_sig_punctuation, \"(\"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \", \"],\n                          [pending_xref, \"str"], "sample_165": ["    def test_model_form(self):\n        # Create a model form for ChoiceModel\n        class ChoiceModelForm(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = ('name',)\n\n        # Test that the form has the correct fields\n        form = ChoiceModelForm()\n        self.assertEqual(len(form.fields), 1)\n        self.assertIn('name', form.fields)\n\n        # Test that the form validates correctly\n        data = {'name': 'Test Choice'}\n        form = ChoiceModelForm(data)\n        self.assertTrue(form.is_valid())\n\n        # Test that the form saves correctly\n        form.save()\n        self.assertEqual(ChoiceModel.objects.count(), 1)\n"], "sample_289": ["    def test_setstate_getstate(self):\n        dict1 = CaseInsensitiveMapping({'Accept': 'application/json'})\n        state = dict1.__getstate__()\n        dict2 = CaseInsensitiveMapping()\n        dict2.__setstate__(state)\n        self.assertEqual(dict1, dict2)\n"], "sample_773": ["def test_logistic_regression_path_multiclass():\n    # Test that logistic_regression_path works with multiclass problems\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=10,\n                               n_classes=3, random_state=0)\n    Cs = [1.0]\n    solver = 'lbfgs'\n    multi_class = 'multinomial'\n    fit_intercept = True\n    max_iter = 1000\n    tol = 1e-7\n    random_state = 42\n\n    coefs, _, _ = _logistic_regression_path(X, y, Cs=Cs, solver=solver,\n                                            fit_intercept=fit_intercept,\n                                            max_iter=max_iter, tol=tol,\n                                            random_state=random_state,\n                                            multi_class=multi_class)\n\n    lr = LogisticRegression(C=Cs[0], solver=solver, fit_intercept=fit_intercept,\n                            max_iter=max_iter, tol=tol, random_state=random_state,\n                            multi_class=multi_class)\n    lr.fit(X, y)\n\n    assert_array_almost_equal(lr.coef_, coefs[0], decimal=3)\n    assert_array_almost_equal(lr.intercept_, coefs[0][:, -1], decimal=3)\n"], "sample_274": ["    def test_model_form_save(self):\n        # Create a model instance\n        instance = ChoiceModel.objects.create(name='test')\n\n        # Create a model form\n        class TestModelForm(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = ('name',)\n\n        # Test saving the form\n        form = TestModelForm({'name': 'new_name'}, instance=instance)\n        self.assertTrue(form.is_valid())\n        form.save()\n        instance.refresh_from_db()\n        self.assertEqual(instance.name, 'new_name')\n"], "sample_830": ["def test_get_blas_info():\n    try:\n        blas_info = _get_blas_info()\n        assert 'macros' in blas_info\n        assert 'lib_dirs' in blas_info\n        assert 'cblas_libs' in blas_info\n    except ImportError:\n        # If scikit-learn is not installed, _get_blas_info will raise an ImportError\n        pass\n"], "sample_880": ["def test_ovr_decision_function():\n    # Test OvR decision function with 3 classes\n    predictions = np.array([[0, 1, 1], [1, 0, 1]])\n    confidences = np.array([[0.2, 0.8, 0.8], [0.8, 0.2, 0.8]])\n    n_classes = 3\n    expected_result = np.array([[0.46666667, 0.46666667, 0.06666667], [0.46666667, 0.46666667, 0.06666667]])\n    assert_allclose(_ovr_decision_function(predictions, confidences, n_classes), expected_result)\n\n    # Test OvR decision function with 4 classes\n    predictions = np.array([[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1]])\n    confidences = np.array([[0.2, 0.8, 0.8, 0.8], [0.8, 0.2, 0.8, 0.8], [0.8, 0.8, 0.2, 0.8]])\n    n_classes = 4\n    expected_result = np.array([[0.4, 0.4, 0.06666667, 0.13333333], [0.4, 0.4, 0.06666667, 0.13333333], [0.4, 0.4, 0.06666667, 0.13333333]])\n    assert_allclose(_ovr_decision_function(predictions, confidences, n_classes), expected_result)\n"], "sample_932": ["def test_template_parameter_lists():\n    check('function', 'template<typename T> void f(T)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T, typename U> void f(T, U)', {2: 'I00E1f1T1U'})\n    check('function', 'template<typename T, typename U, typename V> void f(T, U, V)', {2: 'I000E1f1T1U1V'})\n    check('function', 'template<typename T, typename U, typename V, typename W> void f(T, U, V, W)', {2: 'I0000E1f1T1U1V1W'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X> void f(T, U, V, W, X)', {2: 'I00000E1f1T1U1V1W1X'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> void f(T, U, V, W, X, Y)', {2: 'I000000E1f1T1U1V1W1X1Y'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> void f(T, U, V, W, X, Y, Z)', {2: 'I0000000E1f1T1U1V1W1X1Y1Z'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A> void f(T, U, V, W, X, Y, Z, A)', {2: 'I00000000E1f1T1U1V1W1X1Y1Z1A'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A, typename B> void f(T, U, V, W, X, Y, Z, A, B)', {2: 'I000000000E1f1T1U1V1W1X1Y1Z1A1B'})\n    check('function', 'template<typename"], "sample_652": ["    def test_scope_session(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            values = []\n            @pytest.fixture(scope=\"session\")\n                values.append(1)\n                return 1\n\n                assert arg == 1\n                assert arg == 1\n                assert len(values) == 1\n            class TestClass(object):\n                    assert arg == 1\n                    assert len(values) == 1\n        \"\"\"\n        )\n        reprec = testdir.inline_run()\n        reprec.assertoutcome(passed=3)\n"], "sample_719": ["def test_tfidf_vectorizer_with_fixed_vocabulary_and_stop_words():\n    # non regression smoke test for inheritance issues\n    vocabulary = ['pizza', 'celeri']\n    stop_words = ['celeri']\n    vect = TfidfVectorizer(vocabulary=vocabulary, stop_words=stop_words)\n    X_1 = vect.fit_transform(ALL_FOOD_DOCS)\n    X_2 = vect.transform(ALL_FOOD_DOCS)\n    assert_array_almost_equal(X_1.toarray(), X_2.toarray())\n    assert_true(vect.fixed_vocabulary_)\n    assert_equal(vect.stop_words_, set(stop_words))\n"], "sample_164": ["    def test_configure_logging(self):\n        logging_config = 'logging_tests.tests.configure_logging'\n        logging_settings = {'version': 1}\n        configure_logging(logging_config, logging_settings)\n        self.assertEqual(logging.config.dictConfig.call_count, 2)\n"], "sample_918": ["def test_domain_py_module_index_with_common_prefix(app, status, warning):\n    app.config.modindex_common_prefix = ['sphinx.']\n    app.builder.build_all()\n\n    index = PythonModuleIndex(app.env.get_domain('py'))\n    assert index.generate() == (\n        [('c', [IndexEntry('config', 2, 'index', 'module-sphinx.config', '', '', '')]),\n         ('d', [IndexEntry('docutils', 0, 'index', 'module-docutils', '', '', '')]),\n         ('i', [IndexEntry('intl', 0, 'index', 'module-sphinx_intl', '', '', '')])],\n        False\n    )\n"], "sample_407": ["def test_model_base_check_unique_together(self):\n    class ModelWithUniqueTogether(models.Model):\n        field1 = models.CharField(max_length=10)\n        field2 = models.CharField(max_length=10)\n\n        class Meta:\n            unique_together = [[\"field1\", \"field2\"]]\n\n    class ModelWithUniqueTogetherSubset(models.Model):\n        field1 = models.CharField(max_length=10)\n        field2 = models.CharField(max_length=10)\n        field3 = models.CharField(max_length=10)\n\n        class Meta:\n            unique_together = [[\"field1\", \"field2\"]]\n\n    class ModelWithUniqueTogetherSuperset(models.Model):\n        field1 = models.CharField(max_length=10)\n        field2 = models.CharField(max_length=10)\n\n        class Meta:\n            unique_together = [[\"field1\", \"field2\", \"field3\"]]\n\n    errors = ModelWithUniqueTogether.check()\n    self.assertEqual(len(errors), 0)\n\n    errors = ModelWithUniqueTogetherSubset.check()\n    self.assertEqual(len(errors), 0)\n\n    errors = ModelWithUniqueTogetherSuperset.check()\n    self.assertEqual(len(errors), 1)\n    self.assertEqual(errors[0].id, \"models.E011\")\n"], "sample_461": ["def test_urlfield_widget_attrs(self):\n    f = URLField()\n    widget = f.widget\n    attrs = f.widget_attrs(widget)\n    self.assertEqual(attrs, {})\n    f = URLField(min_length=15, max_length=20)\n    widget = f.widget\n    attrs = f.widget_attrs(widget)\n    self.assertEqual(attrs, {\"maxlength\": \"20\", \"minlength\": \"15\"})\n"], "sample_760": ["def test_make_scorer_with_sample_weight():\n    # Test that make_scorer correctly handles sample weights.\n    X, y = make_classification(random_state=0)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n    clf = DecisionTreeClassifier(random_state=0)\n    clf.fit(X_train, y_train)\n\n    sample_weight = np.ones_like(y_test)\n    sample_weight[:10] = 0\n\n    scorer = make_scorer(accuracy_score)\n    weighted = scorer(clf, X_test, y_test, sample_weight=sample_weight)\n    unweighted = scorer(clf, X_test, y_test)\n    assert_not_equal(weighted, unweighted)\n\n    scorer = make_scorer(accuracy_score, greater_is_better=False)\n    weighted = scorer(clf, X_test, y_test, sample_weight=sample_weight)\n    unweighted = scorer(clf, X_test, y_test)\n    assert_not_equal(weighted, unweighted)\n"], "sample_345": ["    def test_trigger_reload(self, mocked_sys):\n        autoreload.trigger_reload('test_file.py')\n        self.assertEqual(mocked_sys.exit.call_count, 1)\n        self.assertEqual(mocked_sys.exit.call_args[0][0], 3)\n"], "sample_354": ["def test_required_fields_with_default_values(self):\n    new_io = StringIO()\n    call_command(\n        'createsuperuser',\n        interactive=False,\n        email=\"joe@somewhere.org\",\n        date_of_birth=\"1976-04-01\",\n        first_name='Joe',\n        stdout=new_io,\n    )\n    command_output = new_io.getvalue().strip()\n    self.assertEqual(command_output, 'Superuser created successfully.')\n    u = CustomUser._default_manager.get(email=\"joe@somewhere.org\")\n    self.assertEqual(u.date_of_birth, date(1976, 4, 1))\n    self.assertEqual(u.first_name, 'Joe')\n\n    # Test that default values are used when not provided\n    new_io = StringIO()\n    call_command(\n        'createsuperuser',\n        interactive=False,\n        email=\"joe2@somewhere.org\",\n        stdout=new_io,\n    )\n    command_output = new_io.getvalue().strip()\n    self.assertEqual(command_output, 'Superuser created successfully.')\n    u = CustomUser._default_manager.get(email=\"joe2@somewhere.org\")\n    self.assertEqual(u.date_of_birth, date(1970, 1, 1))\n    self.assertEqual(u.first_name, '')\n"], "sample_966": ["def test_python_domain_canonical_definition_overrides_with_multiple_canonicals(app, warning):\n    text = (\".. py:class:: io.StringIO\\n\"\n            \"   :canonical: _io.StringIO\\n\"\n            \".. py:class:: _io.StringIO\\n\"\n            \"   :canonical: io.StringIO\\n\")\n    restructuredtext.parse(app, text)\n    assert warning.getvalue() != \"\"\n\n    domain = app.env.get_domain('py')\n    assert domain.objects['_io.StringIO'] == ('index', 'id0', 'class', False)\n    assert domain.objects['io.StringIO'] == ('index', 'id1', 'class', False)\n"], "sample_457": ["    def test_validate_with_multiple_expressions(self):\n        constraint = models.UniqueConstraint(\n            Lower(\"name\"),\n            F(\"color\"),\n            name=\"name_color_uniq\",\n        )\n        msg = \"Constraint \u201cname_color_uniq\u201d is violated.\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            constraint.validate(\n                UniqueConstraintProduct,\n                UniqueConstraintProduct(name=self.p1.name.upper(), color=self.p1.color),\n            )\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=\"another-name\", color=\"another-color\"),\n        )\n        # Existing instances have their existing row excluded.\n        constraint.validate(UniqueConstraintProduct, self.p1)\n        # Unique field is excluded.\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=self.p1.name.upper(), color=self.p1.color),\n            exclude={\"name\"},\n        )\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=self.p1.name.upper(), color=self.p1.color),\n            exclude={\"color\"},\n        )\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=self.p1.name.upper(), color=self.p1.color),\n            exclude={\"name\", \"color\"},\n        )\n"], "sample_436": ["    def test_runserver_ipv6(self):\n        self.write_settings(\n            \"settings.py\",\n            sdict={\n                \"ALLOWED_HOSTS\": [\"::1\"],\n                \"DEBUG\": False,\n            },\n        )\n\n        out, err = self.run_manage([\"runserver\", \"0:8000\"])\n        self.assertNoOutput(err)\n        self.assertIn(\"Starting development server at http://[::]:8000/\", out)\n"], "sample_499": ["def test_legend_draggable():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='line')\n    leg = ax.legend()\n    assert not leg.get_draggable()\n    leg.set_draggable(True)\n    assert leg.get_draggable()\n    leg.set_draggable(False)\n    assert not leg.get_draggable()\n    leg.set_draggable(True, use_blit=True)\n    assert leg.get_draggable()\n    leg.set_draggable(False)\n    assert not leg.get_draggable()\n    leg.set_draggable(True, update='bbox')\n    assert leg.get_draggable()\n    leg.set_draggable(False)\n    assert not leg.get_draggable()\n"], "sample_768": ["def test_leave_one_group_out_with_object_groups():\n    # Test that LeaveOneGroupOut works with object groups\n    groups = np.array([object(), object(), object(), object()], dtype=object)\n    X = np.ones(4)\n    y = np.ones(4)\n    logo = LeaveOneGroupOut()\n    splits = list(logo.split(X, y, groups))\n    assert len(splits) == 4\n    for train, test in splits:\n        assert len(train) == 3\n        assert len(test) == 1\n"], "sample_287": ["def test_check_ordering_random(self):\n    class SongAdmin(admin.ModelAdmin):\n        ordering = ['?', 'title']\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'ordering' has the random ordering marker '?', \"\n            \"but contains other fields as well.\",\n            hint='Either remove the \"?\", or remove the other fields.',\n            obj=SongAdmin,\n            id='admin.E032',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_237": ["    def test_builtin_permission_name_length(self):\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 250\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most 244 \"\n                \"characters for its builtin permission names to be at most 255 characters.\",\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 245\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most 244 \"\n                \"characters for its builtin permission names to be at most 255 characters.\",\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 244\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 243\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 242\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 241\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 240\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 239\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 238\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 237\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n\n"], "sample_548": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc)\n    assert cb.alpha is None\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n    cb.set_alpha(None)\n    assert cb.alpha is None\n"], "sample_241": ["    def test_clone(self):\n        q = Query(Company)\n        q2 = q.clone()\n        self.assertEqual(q.__dict__, q2.__dict__)\n"], "sample_701": ["def test_argument_type_str_choice_is_deprecated(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n            parser.addoption(\"--foo\", type=\"bar\", choices=[\"a\", \"b\"])\n        \"\"\"\n    )\n    with pytest.warns(\n        PytestDeprecationWarning,\n        match=re.escape(\n            \"`type` argument to addoption() is the string 'bar'. \"\n            \"For choices this is optional and can be omitted, \"\n            \"but when supplied should be a type (for example `str` or `int`). \"\n            \"(options: ['a', 'b'])\"\n        ),\n    ):\n        pytester.parseconfig(\"--foo\", \"a\")\n"], "sample_920": ["    def test_napoleon_use_ivar(self):\n        docstring = \"\"\"\\"], "sample_1208": ["def test_sample_numpy():\n    distribs_numpy = [\n        MatrixNormal('M', [[5, 6]], [4], [[2, 1], [1, 2]]),\n        Wishart('W', 5, [[1, 0], [0, 1]])\n    ]\n\n    size = 5\n    numpy = import_module('numpy')\n    if not numpy:\n        skip('Numpy not installed. Abort tests for _sample_numpy.')\n    else:\n        for X in distribs_numpy:\n            samps = sample(X, size=size, library='numpy')\n            for sam in samps:\n                assert Matrix(sam) in X.pspace.distribution.set\n        M = MatrixGamma('M', 1, 2, [[1, 0], [0, 1]])\n        raises(NotImplementedError, lambda: sample(M, size=3))\n"], "sample_372": ["    def test_match(self):\n        pattern = LocalePrefixPattern()\n        self.assertEqual(pattern.match('/en/'), ('', (), {}))\n        self.assertEqual(pattern.match('/fr/'), ('', (), {}))\n        self.assertEqual(pattern.match('/'), ('', (), {}))\n        self.assertIsNone(pattern.match('/invalid/'))\n"], "sample_105": ["    def test_get_context_data(self):\n        view = ContextMixin()\n        context = view.get_context_data()\n        self.assertIn('view', context)\n        self.assertEqual(context['view'], view)\n"], "sample_1073": ["def test_sqrt_depth():\n    from sympy import sqrt\n    assert sqrt_depth(1) == 0\n    assert sqrt_depth(sqrt(2)) == 1\n    assert sqrt_depth(1 + sqrt(2)) == 1\n    assert sqrt_depth(1 + sqrt(2)*sqrt(3)) == 2\n    assert sqrt_depth(sqrt(2 + sqrt(3))) == 2\n    assert sqrt_depth(sqrt(2 + sqrt(3 + sqrt(4)))) == 3\n"], "sample_579": ["def test_clustermap_cbar_kws(self):\n    kws = self.default_kws.copy()\n    kws['cbar_kws'] = dict(label='test')\n    g = mat.clustermap(self.df_norm, **kws)\n    assert g.ax_cbar.get_ylabel() == 'test'\n"], "sample_381": ["def test_alter_field_to_fk_dependency_other_app_with_through_model(self):\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author_fk],\n        [self.author_empty, self.book_with_multiple_authors_through_attribution],\n    )\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['CreateModel', 'AddField'])\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '__first__')])\n"], "sample_710": ["def test_unittest_teardown_class_exception(pytester: Pytester) -> None:\n    testpath = pytester.makepyfile(\n        \"\"\"\n        import unittest\n        class MyTestCase(unittest.TestCase):\n            @classmethod\n                pass\n            @classmethod\n                raise Exception(\"teardown exception\")\n                pass\n                pass\n            assert MyTestCase.tearDownClass_called\n    \"\"\"\n    )\n    reprec = pytester.inline_run(testpath)\n    passed, skipped, failed = reprec.countoutcomes()\n    assert failed == 1\n    assert passed == 2\n"], "sample_193": ["    def test_foreign_key_to_self(self):\n        \"\"\"\n        #24513 - Modifying an object pointing to itself would cause it to be\n        rendered twice and thus breaking its related M2M through objects.\n        \"\"\"\n        class A(models.Model):\n            to_a = models.ForeignKey('something.A', models.CASCADE)\n\n            class Meta:\n                app_label = \"something\"\n\n            return [mod for mod in state.apps.get_models() if mod._meta.model_name == 'a'][0]\n\n        project_state = ProjectState()\n        project_state.add_model(ModelState.from_model(A))\n        self.assertEqual(len(get_model_a(project_state)._meta.related_objects), 1)\n        old_state = project_state.clone()\n\n        operation = AlterField(\n            model_name=\"a\",\n            name=\"to_a\",\n            field=models.ForeignKey(\"something.A\", models.CASCADE, blank=True)\n        )\n        # At this point the model would be rendered twice causing its related\n        # M2M through objects to point to an old copy and thus breaking their\n        # attribute lookup.\n        operation.state_forwards(\"something\", project_state)\n\n        model_a_old = get_model_a(old_state)\n        model_a_new = get_model_a(project_state)\n        self.assertIsNot(model_a_old, model_a_new)\n\n        # The old model's _meta is still consistent\n        field_to_a_old = model_a_old._meta.get_field(\"to_a\")\n        self.assertEqual(field_to_a_old.remote_field.model, model_a_old)\n        self.assertIs(field_to_a_old.remote_field.model, model_a_old)\n\n        # The new model's _meta is still consistent\n        field_to_a_new = model_a_new._meta.get_field(\"to_a\")\n        self.assertEqual(field_to_a_new.remote_field.model, model_a_new)\n        self.assertIs(field_to_a_new.remote_field.model, model_a_new)\n"], "sample_636": ["def test_similar_code_checker_stripped_lines(self) -> None:\n    \"\"\"Test the stripped_lines function.\"\"\"\n    lines = [\n        \"# comment\\n\",\n        \"import os\\n\",\n        \"def foo():\\n\",\n        '    \"\"\"docstring\"\"\"\\n',\n        \"    pass\\n\",\n        \"print('hello')\\n\",\n        \"print('world')\\n\",\n    ]\n    expected_output = [\n        LineSpecifs(text=\"import os\", line_number=1),\n        LineSpecifs(text=\"def foo():\", line_number=2),\n        LineSpecifs(text=\"    pass\", line_number=4),\n        LineSpecifs(text=\"print('hello')\", line_number=5),\n        LineSpecifs(text=\"print('world')\", line_number=6),\n    ]\n    assert (\n        stripped_lines(lines, ignore_comments=True, ignore_docstrings=True, ignore_imports=False, ignore_signatures=False)\n        == expected_output\n    )\n\n    expected_output = [\n        LineSpecifs(text=\"def foo():\", line_number=2),\n        LineSpecifs(text=\"    pass\", line_number=4),\n        LineSpecifs(text=\"print('hello')\", line_number=5),\n        LineSpecifs(text=\"print('world')\", line_number=6),\n    ]\n    assert (\n        stripped_lines(lines, ignore_comments=True, ignore_docstrings=True, ignore_imports=True, ignore_signatures=False)\n        == expected_output\n    )\n\n    expected_output = [\n        LineSpecifs(text=\"import os\", line_number=1),\n        LineSpecifs(text=\"    pass\", line_number=4),\n        LineSpecifs(text=\"print('hello')\", line_number=5),\n        LineSpecifs(text=\"print('world')\", line_number=6),\n    ]\n    assert (\n        stripped_lines(lines, ignore_comments=True, ignore_docstrings=True, ignore_imports=False, ignore_signatures=True)\n        == expected_output\n    )\n"], "sample_23": ["def test_longitude_wrap_at_edge_cases():\n    \"\"\"\n    Test wrapping at edge cases for Longitude\n    \"\"\"\n\n    # Test wrapping at 0 degrees\n    lon = Longitude([0.1, 359.9] * u.deg)\n    assert np.all(lon.wrap_at(0 * u.deg).degree == np.array([0.1, -0.1]))\n\n    # Test wrapping at 180 degrees\n    lon = Longitude([179.9, 180.1] * u.deg)\n    assert np.all(lon.wrap_at(180 * u.deg).degree == np.array([-0.1, 0.1]))\n\n    # Test wrapping at 360 degrees\n    lon = Longitude([359.9, 360.1] * u.deg)\n    assert np.all(lon.wrap_at(360 * u.deg).degree == np.array([-0.1, 0.1]))\n\n    # Test wrapping at -180 degrees\n    lon = Longitude([-179.9, -180.1] * u.deg)\n    assert np.all(lon.wrap_at(-180 * u.deg).degree == np.array([0.1, -0.1]))\n\n    # Test wrapping at -360 degrees\n    lon = Longitude([-359.9, -360.1] * u.deg)\n    assert np.all(lon.wrap_at(-360 * u.deg).degree == np.array([0.1, -0.1]))\n"], "sample_694": ["def test_nose_deprecated_with_setup_method(pytester: Pytester) -> None:\n    pytest.importorskip(\"nose\")\n    pytester.makepyfile(\n        \"\"\"\n        from nose.tools import with_setup\n\n        class TestNoseDeprecated:\n                ...\n\n                ...\n\n            @with_setup(setup, teardown)\n                ...\n        \"\"\"\n    )\n    output = pytester.runpytest(\"-Wdefault::pytest.PytestRemovedIn8Warning\")\n    message = [\n        \"*PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\",\n        \"*test_nose_deprecated_with_setup_method.py::TestNoseDeprecated::test_omits_warnings is using nose-specific method: `setup(self)`\",\n        \"*PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\",\n        \"*test_nose_deprecated_with_setup_method.py::TestNoseDeprecated::test_omits_warnings is using nose-specific method: `teardown(self)`\",\n    ]\n    output.stdout.fnmatch_lines(message)\n    output.assert_outcomes(passed=1)\n"], "sample_737": ["def test_vectorizer_input_type():\n    # Test that input type is correctly validated\n    for vec in [CountVectorizer(), TfidfVectorizer(), HashingVectorizer()]:\n        assert_raise_message(\n            ValueError, \"Iterable over raw text documents expected, \"\n                         \"string object received.\",\n            vec.fit_transform, \"hello world!\")\n        assert_raise_message(\n            ValueError, \"Iterable over raw text documents expected, \"\n                         \"string object received.\",\n            vec.fit, \"hello world!\")\n        assert_raise_message(\n            ValueError, \"Iterable over raw text documents expected, \"\n                         \"string object received.\",\n            vec.transform, \"hello world!\")\n\n    # Test that input type is correctly validated for 'file' input\n    for vec in [CountVectorizer(input='file'), TfidfVectorizer(input='file'),\n                HashingVectorizer(input='file')]:\n        assert_raise_message(\n            ValueError, \"Iterable over raw text documents expected, \"\n                         \"string object received.\",\n            vec.fit_transform, \"hello world!\")\n        assert_raise_message(\n            ValueError, \"Iterable over raw text documents expected, \"\n                         \"string object received.\",\n            vec.fit, \"hello world!\")\n        assert_raise_message(\n            ValueError, \"Iterable over raw text documents expected, \"\n                         \"string object received.\",\n            vec.transform, \"hello world!\")\n\n    # Test that input type is correctly validated for 'filename' input\n    for vec in [CountVectorizer(input='filename'), TfidfVectorizer(input='filename'),\n                HashingVectorizer(input='filename')]:\n        assert_raise_message(\n            ValueError, \"Iterable over raw text documents expected, \"\n                         \"string object received.\",\n            vec.fit_transform, \"hello world!\")\n        assert_raise_message(\n            ValueError, \"Iterable over raw text documents expected, \"\n                         \"string object received.\",\n            vec.fit, \"hello world!\")\n        assert_raise_message(\n            ValueError, \"Iterable over raw text documents expected, \"\n                         \"string object received.\",\n            vec.transform, \"hello world!\")\n"], "sample_974": ["def test_ccode_For():\n    from sympy import symbols, For\n    i = symbols('i', integer=True)\n    x = symbols('x')\n    f = For(i, Range(0, 5), (x, x + 1))\n    assert ccode(f) == (\n        \"for (int i=0; i<5; i++){\\n\"\n        \"   x = x + 1;\\n\"\n        \"}\"\n    )\n"], "sample_80": ["def test_is_nullable(self):\n    query = Query(Item)\n    self.assertTrue(query.is_nullable(Item._meta.get_field('name')))\n    self.assertFalse(query.is_nullable(Item._meta.get_field('id')))\n\n    query = Query(ObjectC)\n    self.assertTrue(query.is_nullable(ObjectC._meta.get_field('name')))\n    self.assertFalse(query.is_nullable(ObjectC._meta.get_field('id')))\n"], "sample_1188": ["def test_pretty_print_unicode_d():\n    assert upretty(d[0]) == '(0|0)'\n    assert upretty(d[1]) == '(i_N|k_N)'\n    assert upretty(d[4]) == '(a) (i_N|k_N)'\n    assert upretty(d[5]) == '(a) (i_N|k_N) + (-b) (j_N|k_N)'\n    assert upretty(d[7]) == upretty_d_7\n    assert upretty(d[10]) == '(cos(a)) (i_C|k_N) + (-sin(a)) (j_C|k_N)'\n"], "sample_331": ["    def test_parse_iso8601_duration(self):\n        test_values = (\n            ('P1D', timedelta(days=1)),\n            ('P1DT1H', timedelta(days=1, hours=1)),\n            ('P1DT1H1M', timedelta(days=1, hours=1, minutes=1)),\n            ('P1DT1H1M1S', timedelta(days=1, hours=1, minutes=1, seconds=1)),\n            ('P1DT1H1M1.1S', timedelta(days=1, hours=1, minutes=1, seconds=1, milliseconds=100)),\n            ('P1DT1H1M1,1S', timedelta(days=1, hours=1, minutes=1, seconds=1, milliseconds=100)),\n            ('PT1H1M1S', timedelta(hours=1, minutes=1, seconds=1)),\n            ('PT1H1M1.1S', timedelta(hours=1, minutes=1, seconds=1, milliseconds=100)),\n            ('PT1H1M1,1S', timedelta(hours=1, minutes=1, seconds=1, milliseconds=100)),\n            ('P-1D', timedelta(days=-1)),\n            ('P-1DT-1H', timedelta(days=-1, hours=-1)),\n            ('P-1DT-1H-1M', timedelta(days=-1, hours=-1, minutes=-1)),\n            ('P-1DT-1H-1M-1S', timedelta(days=-1, hours=-1, minutes=-1, seconds=-1)),\n            ('P-1DT-1H-1M-1.1S', timedelta(days=-1, hours=-1, minutes=-1, seconds=-1, milliseconds=-100)),\n            ('P-1DT-1H-1M-1,1S', timedelta(days=-1, hours=-1, minutes=-1, seconds=-1, milliseconds=-100)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_933": ["def test_gettext_catalogs(app):\n    app.builder.build_all()\n\n    # Check if catalogs are correctly generated\n    catalogs = ['extapi.pot', 'subdir.pot', 'markup.pot']\n    for catalog in catalogs:\n        assert (app.outdir / catalog).isfile()\n\n    # Check if catalogs contain the correct messages\n    for catalog in catalogs:\n        with open(app.outdir / catalog, 'r', encoding='utf-8') as f:\n            content = f.read()\n            assert 'msgid \"\"' in content\n            assert 'msgstr \"\"' in content\n\n    # Check if catalogs contain the correct metadata\n    with open(app.outdir / 'extapi.pot', 'r', encoding='utf-8') as f:\n        content = f.read()\n        assert 'Project-Id-Version: test_root' in content\n        assert 'POT-Creation-Date:' in content\n        assert 'PO-Revision-Date:' in content\n        assert 'Last-Translator: FULL NAME <EMAIL@ADDRESS>' in content\n        assert 'Language-Team: LANGUAGE <LL@li.org>' in content\n"], "sample_1019": ["def test_monotonic_sign():\n    assert _monotonic_sign(1) == 1\n    assert _monotonic_sign(-1) == -1\n    assert _monotonic_sign(0) == 0\n    assert _monotonic_sign(x) is None\n    assert _monotonic_sign(x + 1) == 1\n    assert _monotonic_sign(x - 1) is None\n    assert _monotonic_sign(x**2) == 1\n    assert _monotonic_sign(-x**2) == -1\n    assert _monotonic_sign(x**3) is None\n    assert _monotonic_sign(-x**3) is None\n    assert _monotonic_sign(x**4) == 1\n    assert _monotonic_sign(-x**4) == -1\n    assert _monotonic_sign(x**5) is None\n    assert _monotonic_sign(-x**5) is None\n    assert _monotonic_sign(2*x) is None\n    assert _monotonic_sign(-2*x) is None\n    assert _monotonic_sign(2*x + 1) == 1\n    assert _monotonic_sign(-2*x + 1) is None\n    assert _monotonic_sign(2*x - 1) is None\n    assert _monotonic_sign(-2*x - 1) == -1\n    assert _monotonic_sign(2*x**2 + 1) == 1\n    assert _monotonic_sign(-2*x**2 + 1) is None\n    assert _monotonic_sign(2*x**2 - 1) is None\n    assert _monotonic_sign(-2*x**2 - 1) == -1\n    assert _monotonic_sign(2*x**3 + 1) is None\n    assert _monotonic_sign(-2*x**3 + 1) is None\n    assert _monotonic_sign(2*x**3 - 1) is None\n    assert _monotonic_sign(-2*x**3 - 1) is None\n    assert _monotonic_sign(2*x**4 + 1) == 1\n    assert _monotonic_sign(-2*x**4 + 1) is None\n    assert _monotonic"], "sample_390": ["def test_directory_index_with_directory_traversal(self):\n    \"\"\"\n    Test that directory index view prevents directory traversal attacks.\n    \"\"\"\n    response = self.client.get(\"/%s/../\" % self.prefix)\n    self.assertEqual(404, response.status_code)\n"], "sample_538": ["def test_transformed_bbox():\n    bbox = mtransforms.Bbox([[0, 0], [1, 1]])\n    trans = mtransforms.Affine2D().scale(2)\n    tbox = mtransforms.TransformedBbox(bbox, trans)\n\n    assert_array_almost_equal(tbox.get_points(), [[0, 0], [2, 2]])\n\n    # Changing the transform should change the result.\n    trans.scale(2)\n    assert_array_almost_equal(tbox.get_points(), [[0, 0], [4, 4]])\n\n    # Changing the bbox should change the result.\n    bbox.set_points([[0, 0], [2, 2]])\n    assert_array_almost_equal(tbox.get_points(), [[0, 0], [8, 8]])\n"], "sample_774": ["def test_one_hot_encoder_drop_with_unknown():\n    X = [['abc', 2, 55], ['def', 1, 55], ['def', 3, 56]]\n    enc = OneHotEncoder(drop=['abc', 12, 3, 56], handle_unknown='ignore')\n    trans = enc.fit_transform(X).toarray()\n    exp = [[0, 1, 1],\n           [1, 0, 1],\n           [1, 0, 0]]\n    assert_array_equal(trans, exp)\n    dropped_cats = [cat[feature]\n                    for cat, feature in zip(enc.categories_,\n                                            enc.drop_idx_)]\n    assert_array_equal(dropped_cats, ['abc', 12, 3, 56])\n    assert_array_equal(np.array(X, dtype=object),\n                       enc.inverse_transform(trans))\n"], "sample_377": ["    def test_get_traceback_frames_with_cyclic_reference(self):\n        \"\"\"\n        Test that ExceptionReporter.get_traceback_frames() handles cyclic references\n        in the exception chain.\n        \"\"\"\n        try:\n            try:\n                raise RuntimeError(\"outer\") from RuntimeError(\"inner\")\n            except RuntimeError as exc:\n                exc.__cause__ = exc\n                raise\n        except Exception:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(None, exc_type, exc_value, tb)\n        frames = reporter.get_traceback_frames()\n        self.assertEqual(len(frames), 2)\n        self.assertIn(\"RuntimeError\", frames[0][\"exc_cause\"])\n        self.assertIn(\"RuntimeError\", frames[1][\"exc_cause\"])\n"], "sample_261": ["    def test_parse_iso8601_duration(self):\n        test_values = (\n            ('P1D', timedelta(days=1)),\n            ('P1DT1H', timedelta(days=1, hours=1)),\n            ('P1DT1H1M', timedelta(days=1, hours=1, minutes=1)),\n            ('P1DT1H1M1S', timedelta(days=1, hours=1, minutes=1, seconds=1)),\n            ('P1DT1H1M1.1S', timedelta(days=1, hours=1, minutes=1, seconds=1, milliseconds=100)),\n            ('P1DT1H1M1,1S', timedelta(days=1, hours=1, minutes=1, seconds=1, milliseconds=100)),\n            ('-P1D', timedelta(days=-1)),\n            ('-P1DT1H', timedelta(days=-1, hours=-1)),\n            ('-P1DT1H1M', timedelta(days=-1, hours=-1, minutes=-1)),\n            ('-P1DT1H1M1S', timedelta(days=-1, hours=-1, minutes=-1, seconds=-1)),\n            ('-P1DT1H1M1.1S', timedelta(days=-1, hours=-1, minutes=-1, seconds=-1, milliseconds=-100)),\n            ('-P1DT1H1M1,1S', timedelta(days=-1, hours=-1, minutes=-1, seconds=-1, milliseconds=-100)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_42": ["def test_with_H0():\n    # Test that with_H0 returns the correct equivalency\n    h100 = u.with_H0(H0=100*u.km/u.s/u.Mpc)\n    assert len(h100) == 1\n    assert h100[0][0].is_equivalent(u.littleh)\n    assert h100[0][1] is None\n\n    # Test that with_H0 returns the correct equivalency when H0 is None\n    h100 = u.with_H0()\n    assert len(h100) == 1\n    assert h100[0][0].is_equivalent(u.littleh)\n    assert h100[0][1] is None\n\n    # Test that with_H0 raises an error when H0 is not a Quantity\n    with pytest.raises(u.UnitsError):\n        u.with_H0(H0=100)\n\n    # Test that with_H0 raises an error when H0 is not a Quantity with velocity and length units\n    with pytest.raises(u.UnitsError):\n        u.with_H0(H0=100*u.kg)\n"], "sample_1186": ["def test_array_kind():\n    from sympy.tensor.array import ArrayKind\n    from sympy.core.kind import NumberKind, UndefinedKind\n\n    assert isinstance(ArrayKind(NumberKind), ArrayKind)\n    assert isinstance(ArrayKind(UndefinedKind), ArrayKind)\n\n    assert ArrayKind(NumberKind) != ArrayKind(UndefinedKind)\n    assert ArrayKind(NumberKind) == ArrayKind(NumberKind)\n\n    assert ArrayKind._union([ArrayKind(NumberKind), ArrayKind(NumberKind)]) == ArrayKind(NumberKind)\n    assert ArrayKind._union([ArrayKind(NumberKind), ArrayKind(UndefinedKind)]) == ArrayKind(UndefinedKind)\n"], "sample_211": ["    def test_get_context_data(self):\n        mixin = views.ContextMixin()\n        context = mixin.get_context_data()\n        self.assertIn('view', context)\n        self.assertEqual(context['view'], mixin)\n"], "sample_47": ["    def test_technical_500_response(self):\n        request = RequestFactory().get('/')\n        exc_type = ValueError\n        exc_value = ValueError('Test exception')\n        tb = None\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html')\n"], "sample_427": ["def test_formset_with_deletion_and_min_num(self):\n    \"\"\"\n    Test that formset with deletion and min_num works correctly.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_delete=True, min_num=2)\n    initial = [\n        {\"choice\": \"Calexico\", \"votes\": 100},\n        {\"choice\": \"Fergie\", \"votes\": 900},\n    ]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix=\"choices\")\n    self.assertHTMLEqual(\n        \"\\n\".join(form.as_ul() for form in formset.forms),\n        '<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"choices-0-votes\" value=\"100\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"choices-0-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"choices-1-choice\" value=\"Fergie\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"choices-1-votes\" value=\"900\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"choices-1-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"choices-2-choice\"></li>'\n        '<li>Votes: <input type=\"number\" name=\"choices-2-votes\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"choices-2-DELETE\"></li>',\n    )\n    # Let's delete Fergie.\n    data = {\n        \"choices-TOTAL_FORMS\": \"3\",  # the number of forms rendered\n        \"choices-INITIAL_FORMS\": \"2\",  # the number of forms with initial data\n        \"choices-MIN_NUM_FORMS\": \"2\",  # min number of forms\n        \"choices-MAX_NUM_FORMS\": \"0\",  # max number of forms\n        \"choices-0-choice\": \"Calexico\",\n        \"choices-0-votes\": \"100\",\n        \"choices-0-DELETE\": \"\",\n        \"choices-1-choice\": \"Fergie\",\n        \"choices-1-votes\": \"900\",\n        \"choices-1-DELETE\": \"on\",\n        \"choices-2-choice"], "sample_758": ["def test_check_X_y_force_all_finite_valid():\n    # Test that check_X_y correctly handles force_all_finite\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([1, 2])\n    X_checked, y_checked = check_X_y(X, y, force_all_finite=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    X = np.array([[1, 2], [3, np.nan]])\n    y = np.array([1, 2])\n    X_checked, y_checked = check_X_y(X, y, force_all_finite='allow-nan')\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    X = np.array([[1, 2], [3, np.inf]])\n    y = np.array([1, 2])\n    with pytest.raises(ValueError):\n        check_X_y(X, y, force_all_finite=True)\n\n    X = np.array([[1, 2], [3, np.nan]])\n    y = np.array([1, np.inf])\n    with pytest.raises(ValueError):\n        check_X_y(X, y, force_all_finite=True)\n\n    X = np.array([[1, 2], [3, np.nan]])\n    y = np.array([1, np.nan])\n    X_checked, y_checked = check_X_y(X, y, force_all_finite='allow-nan')\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n"], "sample_60": ["    def test_check(self):\n        class MediaInline(GenericTabularInline):\n            model = Media\n\n        class EpisodeAdmin(admin.ModelAdmin):\n            inlines = [MediaInline]\n\n        ma = EpisodeAdmin(Episode, admin_site)\n        checks = ma.checks_class()\n        errors = checks.check(ma)\n        self.assertEqual(errors, [])\n"], "sample_761": ["def test_iterative_imputer_transform_stochasticity_with_n_nearest_features():\n    pytest.importorskip(\"scipy\", minversion=\"0.17.0\")\n    rng1 = np.random.RandomState(0)\n    rng2 = np.random.RandomState(1)\n    n = 100\n    d = 10\n    X = sparse_random_matrix(n, d, density=0.10,\n                             random_state=rng1).toarray()\n\n    # when sample_posterior=True, two transforms shouldn't be equal\n    imputer = IterativeImputer(missing_values=0,\n                               max_iter=1,\n                               sample_posterior=True,\n                               n_nearest_features=5,\n                               random_state=rng1)\n    imputer.fit(X)\n\n    X_fitted_1 = imputer.transform(X)\n    X_fitted_2 = imputer.transform(X)\n\n    # sufficient to assert that the means are not the same\n    assert np.mean(X_fitted_1) != pytest.approx(np.mean(X_fitted_2))\n\n    # when sample_posterior=False, and n_nearest_features=None\n    # and imputation_order is not random\n    # the two transforms should be identical even if rng are different\n    imputer1 = IterativeImputer(missing_values=0,\n                                max_iter=1,\n                                sample_posterior=False,\n                                n_nearest_features=5,\n                                imputation_order='ascending',\n                                random_state=rng1)\n\n    imputer2 = IterativeImputer(missing_values=0,\n                                max_iter=1,\n                                sample_posterior=False,\n                                n_nearest_features=5,\n                                imputation_order='ascending',\n                                random_state=rng2)\n    imputer1.fit(X)\n    imputer2.fit(X)\n\n    X_fitted_1a = imputer1.transform(X)\n    X_fitted_1b = imputer1.transform(X)\n    X_fitted_2 = imputer2.transform(X)\n\n    assert_allclose(X_fitted_1a, X_fitted_1b)\n    assert_allclose(X_fitted_1a, X_fitted_2)\n"], "sample_844": ["def test_optics_with_precomputed_metric():\n    # Test OPTICS with precomputed metric\n    rng = np.random.RandomState(0)\n    n_points_per_cluster = 20\n    C1 = [-5, -2] + .2 * rng.randn(n_points_per_cluster, 2)\n    C2 = [4, -1] + .2 * rng.randn(n_points_per_cluster, 2)\n    C3 = [1, 2] + .2 * rng.randn(n_points_per_cluster, 2)\n    C4 = [-2, 3] + .2 * rng.randn(n_points_per_cluster, 2)\n    X = np.vstack((C1, C2, C3, C4))\n\n    # Compute pairwise distances\n    dist_matrix = pairwise_distances(X, metric='euclidean')\n\n    clust = OPTICS(min_samples=5, metric='precomputed').fit(dist_matrix)\n    assert_array_equal(np.sort(np.unique(clust.labels_)), [-1, 0, 1, 2, 3])\n"], "sample_511": ["def test_xkcd_context_manager():\n    with pytest.raises(RuntimeError):\n        with plt.xkcd():\n            plt.xkcd()\n    with plt.xkcd():\n        assert rcParams['text.usetex'] == False\n    assert rcParams['text.usetex'] == True\n"], "sample_336": ["    def test_locale_regex_descriptor(self):\n        class TestClass:\n            regex = LocaleRegexDescriptor('_regex')\n            _regex = 'test'\n\n        instance = TestClass()\n        self.assertEqual(instance.regex, re.compile('test'))\n"], "sample_456": ["def test_formset_with_ordering_and_deletion_and_empty_forms(self):\n    \"\"\"\n    FormSets with ordering + deletion + empty forms.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_order=True, can_delete=True)\n    initial = [\n        {\"choice\": \"Calexico\", \"votes\": 100},\n        {\"choice\": \"Fergie\", \"votes\": 900},\n        {\"choice\": \"The Decemberists\", \"votes\": 500},\n    ]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix=\"choices\")\n    self.assertHTMLEqual(\n        \"\\n\".join(form.as_ul() for form in formset.forms),\n        '<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"choices-0-votes\" value=\"100\"></li>'\n        '<li>Order: <input type=\"number\" name=\"choices-0-ORDER\" value=\"1\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"choices-0-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"choices-1-choice\" value=\"Fergie\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"choices-1-votes\" value=\"900\"></li>'\n        '<li>Order: <input type=\"number\" name=\"choices-1-ORDER\" value=\"2\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"choices-1-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"choices-2-choice\" '\n        'value=\"The Decemberists\"></li>'\n        '<li>Votes: <input type=\"number\" name=\"choices-2-votes\" value=\"500\"></li>'\n        '<li>Order: <input type=\"number\" name=\"choices-2-ORDER\" value=\"3\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"choices-2-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"choices-3-choice\"></li>'\n        '<li>Votes: <input type=\"number\" name=\"choices-3-votes\"></li>'\n        '<li>Order: <input type=\"number\" name=\"choices-3"], "sample_606": ["def test_cross() -> None:\n    # test cross product with 3 dimensions\n    a = xr.DataArray(\n        np.array([[1, 2, 3], [4, 5, 6]]),\n        dims=(\"time\", \"cartesian\"),\n        coords=dict(\n            time=([\"time\"], [0, 1]),\n            cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"]),\n        ),\n    )\n    b = xr.DataArray(\n        np.array([[4, 5, 6], [1, 2, 3]]),\n        dims=(\"time\", \"cartesian\"),\n        coords=dict(\n            time=([\"time\"], [0, 1]),\n            cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"]),\n        ),\n    )\n    expected = xr.DataArray(\n        np.array([[-3, 6, -3], [3, -6, 3]]),\n        dims=(\"time\", \"cartesian\"),\n        coords=dict(\n            time=([\"time\"], [0, 1]),\n            cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"]),\n        ),\n    )\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(expected, actual)\n\n    # test cross product with 2 dimensions\n    a = xr.DataArray(\n        np.array([[1, 2], [4, 5]]),\n        dims=(\"time\", \"cartesian\"),\n        coords=dict(\n            time=([\"time\"], [0, 1]),\n            cartesian=([\"cartesian\"], [\"x\", \"y\"]),\n        ),\n    )\n    b = xr.DataArray(\n        np.array([[4, 5], [1, 2]]),\n        dims=(\"time\", \"cartesian\"),\n        coords=dict(\n            time=([\"time\"], [0, 1]),\n            cartesian=([\"cartesian\"], [\"x\", \"y\"]),\n        ),\n    )\n    expected = xr.DataArray(\n        np.array([-3, 3]),\n        dims=(\"time\",),\n        coords=dict(time=([\"time\"], [0, 1])),\n    )\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(expected, actual)\n\n    # test cross product with 2 dimensions and coords in other positions\n    a = xr.DataArray(\n        np.array([[1, 2], [4, 5]]),\n        dims=(\"time\", \"cartesian\"),\n"], "sample_637": ["    def test_encoding_declaration(self) -> None:\n        code = \"\"\"# -*- coding: utf-8 -*-\n                a = 1\n                \"\"\"\n        with self.assertNoMessages():\n            self.checker.process_module(self.astroid_module(code))\n"], "sample_370": ["    def setUpTestData(cls):\n        cls.book1 = Book.objects.create(title='Poems')\n        cls.book2 = Book.objects.create(title='Jane Eyre')\n        cls.author1 = Author.objects.create(name='Charlotte', first_book=cls.book1)\n        cls.author2 = Author.objects.create(name='Anne', first_book=cls.book1)\n        cls.author3 = Author.objects.create(name='Emily', first_book=cls.book1)\n        cls.author4 = Author.objects.create(name='Jane', first_book=cls.book2)\n\n        cls.book1.authors.add(cls.author1, cls.author2, cls.author3)\n        cls.book2.authors.add(cls.author4)\n"], "sample_137": ["def test_replace_named_groups(self):\n    self.assertEqual(replace_named_groups(r'^(?P<a>\\w+)/b/(?P<c>\\w+)/$'), r'^<a>/b/<c>/$')\n    self.assertEqual(replace_named_groups(r'^(?P<a>\\w+)/b/(\\w+)$'), r'^<a>/b/(\\w+)$')\n    self.assertEqual(replace_named_groups(r'^(?P<a>\\w+)/b/(?P<c>\\w+)'), r'^<a>/b/<c>')\n    self.assertEqual(replace_named_groups(r'^(?P<a>\\w+)/b/(\\w+)'), r'^<a>/b/(\\w+)')\n"], "sample_413": ["    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n"], "sample_813": ["def test_bayesian_ridge_alpha_init_zero():\n    # Test BayesianRidge with alpha_init=0\n    X = np.array([[1], [2], [6], [8], [10]])\n    y = np.array([1, 2, 6, 8, 10])\n    clf = BayesianRidge(alpha_init=0)\n    assert_raise_message(ValueError, \"alpha_init must be greater than zero\",\n                        clf.fit, X, y)\n"], "sample_620": ["def test_concat_dim_is_variable_with_attrs() -> None:\n    objs = [Dataset({\"x\": 0}), Dataset({\"x\": 1})]\n    coord = Variable(\"y\", [3, 4], attrs={\"foo\": \"bar\"})\n    expected = Dataset({\"x\": (\"y\", [0, 1]), \"y\": coord})\n    actual = concat(objs, coord)\n    assert_identical(actual, expected)\n    assert actual.y.attrs == coord.attrs\n"], "sample_291": ["    def test_get_context_data(self):\n        mixin = views.ContextMixin()\n        mixin.extra_context = {'key': 'value'}\n        context = mixin.get_context_data(foo='bar')\n        self.assertEqual(context['foo'], 'bar')\n        self.assertEqual(context['key'], 'value')\n        self.assertIsInstance(context['view'], views.ContextMixin)\n"], "sample_661": ["def test_record_testsuite_property_multiple_values(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", \"all good\")\n            record_testsuite_property(\"stats\", 10)\n            record_testsuite_property(\"stats\", \"all bad\")\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p2_node = properties_node.find_nth_by_tag(\"property\", 1)\n    p3_node = properties_node.find_nth_by_tag(\"property\", 2)\n    p1_node.assert_attr(name=\"stats\", value=\"all good\")\n    p2_node.assert_attr(name=\"stats\", value=\"10\")\n    p3_node.assert_attr(name=\"stats\", value=\"all bad\")\n"], "sample_1162": ["def test_Function_kind():\n    f = Symbol('f')\n    assert f.kind is UndefinedKind\n    assert f(comm_x).kind is UndefinedKind\n    assert f(noncomm_x).kind is UndefinedKind\n"], "sample_351": ["def test_modelchoicefield_with_empty_queryset(self):\n    class ModelChoiceForm(forms.Form):\n        category = forms.ModelChoiceField(Category.objects.none())\n\n    form = ModelChoiceForm()\n    self.assertEqual(list(form.fields['category'].choices), [('', '---------')])\n    with self.assertRaises(ValidationError):\n        form.fields['category'].clean('1')\n    self.assertIsNone(form.fields['category'].clean(''))\n"], "sample_721": ["def test_check_memory():\n    # Test that check_memory returns a Memory object\n    memory = check_memory(None)\n    assert isinstance(memory, Memory)\n\n    # Test that check_memory raises an error for invalid input\n    assert_raises(ValueError, check_memory, \"invalid_memory\")\n\n    # Test that check_memory returns the input if it's already a Memory object\n    memory = Memory(cachedir=\"test_cache\")\n    assert check_memory(memory) is memory\n\n    # Test that check_memory raises an error if the input doesn't have a cache method\n    assert_raises(ValueError, check_memory, DummyMemory())\n"], "sample_13": ["def test_longitude_wrap_at_edge_cases():\n    \"\"\"\n    Test Longitude wrapping at edge cases\n    \"\"\"\n\n    # Test wrapping at 0 degrees\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian)\n    assert np.all(lon.degree == np.array([0., 90, 180, 270, 0]))\n\n    # Test wrapping at 180 degrees\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle='180d')\n    assert np.all(lon.degree == np.array([0., 90, -180, -90, 0]))\n\n    # Test wrapping at -180 degrees\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle='-180d')\n    assert np.all(lon.degree == np.array([0., -90, 180, 90, 0]))\n\n    # Test wrapping at 360 degrees\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle='360d')\n    assert np.all(lon.degree == np.array([0., 90, 180, 270, 0]))\n\n    # Test wrapping at -360 degrees\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle='-360d')\n    assert np.all(lon.degree == np.array([0., -90, 180, 90, 0]))\n"], "sample_1192": ["def test_disambiguate():\n    from sympy.abc import x, y\n    from sympy.core.symbol import disambiguate\n\n    # Test that disambiguate works with a single symbol\n    assert disambiguate(x) == (x,)\n\n    # Test that disambiguate works with multiple symbols\n    assert disambiguate(x, y) == (x, y)\n\n    # Test that disambiguate works with a tuple of symbols\n    assert disambiguate((x, y)) == (x, y)\n\n    # Test that disambiguate works with a list of symbols\n    assert disambiguate([x, y]) == [x, y]\n\n    # Test that disambiguate works with a set of symbols\n    assert disambiguate({x, y}) == {x, y}\n\n    # Test that disambiguate works with a tuple of expressions\n    from sympy import sin\n    assert disambiguate((x + y, sin(x))) == (x + y, sin(x))\n\n    # Test that disambiguate works with a list of expressions\n    assert disambiguate([x + y, sin(x)]) == [x + y, sin(x)]\n\n    # Test that disambiguate works with a set of expressions\n    assert disambiguate({x + y, sin(x)}) == {x + y, sin(x)}\n\n    # Test that disambiguate works with a mix of symbols and expressions\n    assert disambiguate((x, y, x + y, sin(x))) == (x, y, x + y, sin(x))\n\n    # Test that disambiguate works with a mix of symbols and expressions in a tuple\n    assert disambiguate(((x, y), (x + y, sin(x)))) == ((x, y), (x + y, sin(x)))\n\n    # Test that disambiguate works with a mix of symbols and expressions in a list\n    assert disambiguate([[x, y], [x + y, sin(x)]]) == [[x, y], [x + y, sin(x)]]\n\n    # Test that disambiguate works with a mix of symbols and expressions in a set\n    assert disambiguate({(x, y), (x + y, sin(x))}) == {(x, y), (x +"], "sample_1039": ["def test_print_random_symbol():\n    expr = RandomSymbol('X')\n    assert mpp.doprint(expr) == '<mi>X</mi>'\n    assert mp.doprint(expr) == '<ci>X</ci>'\n    assert mathml(expr, printer='presentation', mat_symbol_style=\"bold\" )== '<mi mathvariant=\"bold\">X</mi>'\n    assert mathml(expr, mat_symbol_style=\"bold\" )== '<ci>X</ci>' # No effect in content printer\n"], "sample_190": ["def test_uuid_text_mixin(self):\n    # Test UUIDTextMixin with different lookup types\n    uuid = '01234567-89ab-cdef-0123-456789abcdef'\n    uuid_obj = UUIDField.objects.create(uuid=uuid)\n    self.assertCountEqual(\n        UUIDField.objects.filter(uuid__iexact=uuid),\n        [uuid_obj]\n    )\n    self.assertCountEqual(\n        UUIDField.objects.filter(uuid__contains=uuid[:8]),\n        [uuid_obj]\n    )\n    self.assertCountEqual(\n        UUIDField.objects.filter(uuid__startswith=uuid[:8]),\n        [uuid_obj]\n    )\n    self.assertCountEqual(\n        UUIDField.objects.filter(uuid__endswith=uuid[9:]),\n        [uuid_obj]\n    )\n    self.assertCountEqual(\n        UUIDField.objects.filter(uuid__istartswith=uuid[:8].lower()),\n        [uuid_obj]\n    )\n    self.assertCountEqual(\n        UUIDField.objects.filter(uuid__iendswith=uuid[9:].lower()),\n        [uuid_obj]\n    )\n    self.assertCountEqual(\n        UUIDField.objects.filter(uuid__icontains=uuid[:8].lower()),\n        [uuid_obj]\n    )\n"], "sample_481": ["    def test_addslashes(self):\n        output = self.engine.render_to_string(\"string01\", {\"a\": \"Hello 'World' \\\"Django\\\"\"})\n        self.assertEqual(output, \"Hello \\\\'World\\' \\\"Django\\\"\")\n"], "sample_1209": ["def test_prefix_latex_repr():\n    assert kilo._latex(None) == r'\\text{k}'\n    assert micro._latex(None) == r\"\\mu\"\n    assert Prefix('custom', 'c', 1)._latex(None) == r'\\text{c}'\n    assert Prefix('custom', 'c', 1, latex_repr=r'\\mathbf{c}')._latex(None) == r'\\mathbf{c}'\n"], "sample_527": ["def test_figure_subplots_adjust():\n    fig, axs = plt.subplots(2, 2)\n    axs[0, 0].set_title('Top Left')\n    axs[0, 1].set_title('Top Right')\n    axs[1, 0].set_title('Bottom Left')\n    axs[1, 1].set_title('Bottom Right')\n\n    fig.subplots_adjust(left=0.2, bottom=0.2, right=0.8, top=0.8)\n    assert axs[0, 0].get_position().x0 == 0.2\n    assert axs[0, 0].get_position().y0 == 0.2\n    assert axs[0, 1].get_position().x0 == 0.6\n    assert axs[0, 1].get_position().y0 == 0.2\n    assert axs[1, 0].get_position().x0 == 0.2\n    assert axs[1, 0].get_position().y0 == 0.0\n    assert axs[1, 1].get_position().x0 == 0.6\n    assert axs[1, 1].get_position().y0 == 0.0\n\n    fig.subplots_adjust(wspace=0.2, hspace=0.2)\n    assert axs[0, 0].get_position().x1 - axs[0, 0].get_position().x0 == 0.2\n    assert axs[0, 0].get_position().y1 - axs[0, 0].get_position().y0 == 0.2\n    assert axs[0, 1].get_position().x1 - axs[0, 1].get_position().x0 == 0.2\n    assert axs[0, 1].get_position().y1 - axs[0, 1].get_position().y0 == 0.2\n    assert axs[1, 0].get_position().x1 - axs[1, 0].get_position().x0 == 0.2\n    assert axs[1, 0].get_position().y1 - axs[1, 0].get_position().y0 == 0.2\n    assert axs[1, 1].get_position().x1 - axs[1, 1].get_position().x0 == "], "sample_674": ["def test_node_repr_failure(testdir):\n    item = testdir.getitems(\n        \"\"\"\n            assert 0\n    \"\"\"\n    )[0]\n    excinfo = pytest.raises(AssertionError, item.runtest)\n    result = item.repr_failure(excinfo)\n    assert isinstance(result, str)\n    assert \"AssertionError\" in result\n"], "sample_282": ["def test_bound_field_rendering(self):\n    form = ComplexFieldForm()\n    bound_field = form['field1']\n    self.assertHTMLEqual(\n        str(bound_field),\n        \"\"\"\n        <input type=\"text\" name=\"field1_0\" id=\"id_field1_0\" required>\n        <select multiple name=\"field1_1\" id=\"id_field1_1\" required>\n        <option value=\"J\">John</option>\n        <option value=\"P\">Paul</option>\n        <option value=\"G\">George</option>\n        <option value=\"R\">Ringo</option>\n        </select>\n        <input type=\"text\" name=\"field1_2_0\" id=\"id_field1_2_0\" required>\n        <input type=\"text\" name=\"field1_2_1\" id=\"id_field1_2_1\" required>\n        \"\"\",\n    )\n\n    self.assertHTMLEqual(\n        bound_field.as_widget(),\n        \"\"\"\n        <input type=\"text\" name=\"field1_0\" id=\"id_field1_0\" required>\n        <select multiple name=\"field1_1\" id=\"id_field1_1\" required>\n        <option value=\"J\">John</option>\n        <option value=\"P\">Paul</option>\n        <option value=\"G\">George</option>\n        <option value=\"R\">Ringo</option>\n        </select>\n        <input type=\"text\" name=\"field1_2_0\" id=\"id_field1_2_0\" required>\n        <input type=\"text\" name=\"field1_2_1\" id=\"id_field1_2_1\" required>\n        \"\"\",\n    )\n\n    self.assertHTMLEqual(\n        bound_field.as_text(),\n        '<input type=\"text\" name=\"field1_0\" id=\"id_field1_0\" required>',\n    )\n\n    self.assertHTMLEqual(\n        bound_field.as_textarea(),\n        '<textarea name=\"field1_0\" id=\"id_field1_0\" cols=\"40\" rows=\"10\"></textarea>',\n    )\n\n    self.assertHTMLEqual(\n        bound_field.as_hidden(),\n        '<input type=\"hidden\" name=\"field1_0\" id=\"id_field1_0\">',\n    )\n"], "sample_426": ["def test_time_strings_customization(self):\n    \"\"\"\n    Test that the time_strings parameter can be used to customize the output.\n    \"\"\"\n    custom_time_strings = {\n        \"year\": ngettext_lazy(\"%(num)d year ago\", \"%(num)d years ago\", \"num\"),\n        \"month\": ngettext_lazy(\"%(num)d month ago\", \"%(num)d months ago\", \"num\"),\n        \"week\": ngettext_lazy(\"%(num)d week ago\", \"%(num)d weeks ago\", \"num\"),\n        \"day\": ngettext_lazy(\"%(num)d day ago\", \"%(num)d days ago\", \"num\"),\n        \"hour\": ngettext_lazy(\"%(num)d hour ago\", \"%(num)d hours ago\", \"num\"),\n        \"minute\": ngettext_lazy(\"%(num)d minute ago\", \"%(num)d minutes ago\", \"num\"),\n    }\n    t = self.t + self.oneday\n    self.assertEqual(timesince(self.t, t, time_strings=custom_time_strings), \"1\\xa0day ago\")\n    self.assertEqual(timeuntil(t, self.t, time_strings=custom_time_strings), \"1\\xa0day ago\")\n"], "sample_838": ["def test_column_transformer_transformer_weights():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n\n    # test that transformer weights are correctly applied\n    transformer_weights = {'trans1': 2, 'trans2': 3}\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', Trans(), [1])],\n                           transformer_weights=transformer_weights)\n    X_res_both = X_array\n    X_res_both[:, 0] *= 2\n    X_res_both[:, 1] *= 3\n    assert_array_equal(ct.fit_transform(X_array), X_res_both)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_both)\n\n    # test that transformer weights are correctly applied with passthrough\n    transformer_weights = {'trans1': 2}\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', 'passthrough', [1])],\n                           transformer_weights=transformer_weights)\n    X_res_both = X_array\n    X_res_both[:, 0] *= 2\n    assert_array_equal(ct.fit_transform(X_array), X_res_both)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_both)\n\n    # test that transformer weights are correctly applied with remainder\n    transformer_weights = {'trans1': 2}\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder='passthrough',\n                           transformer_weights=transformer_weights)\n    X_res_both = X_array\n    X_res_both[:, 0] *= 2\n    assert_array_equal(ct.fit_transform(X_array), X_res_both)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_both)\n\n    # test that transformer weights are correctly applied with remainder transformer\n    transformer_weights = {'trans1': 2}\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=DoubleTrans(),\n                           transformer_weights=transformer_weights)\n    X_res_both = X_array\n    X_res_both[:, 0] *= 2\n    X_res_both[:, 1] *= 2\n    assert_array_equal(ct.fit_transform(X_array), X_res_both)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_both)\n\n    # test that transformer weights are correctly applied with multiple transformers\n    transformer_weights = {'trans1"], "sample_887": ["def test_calibration_display_with_pos_label(pyplot):\n    \"\"\"Check that `CalibrationDisplay` works with `pos_label`.\"\"\"\n    y_true = np.array([0, 0, 0, 1, 1, 1, 1, 1, 1])\n    y_pred = np.array([0.1, 0.2, 0.3, 0.4, 0.65, 0.7, 0.8, 0.9, 1.0])\n\n    # default case\n    viz = CalibrationDisplay.from_predictions(y_true, y_pred)\n    assert viz.pos_label == 1\n\n    # if `pos_label` is specified\n    viz = CalibrationDisplay.from_predictions(y_true, y_pred, pos_label=0)\n    assert viz.pos_label == 0\n\n    # if `y_true` contains `str`, then `pos_label` is required\n    classes = np.array([\"spam\", \"egg\"])\n    y_true_str = classes[y_true]\n    with pytest.raises(ValueError):\n        CalibrationDisplay.from_predictions(y_true_str, y_pred)\n\n    viz = CalibrationDisplay.from_predictions(y_true_str, y_pred, pos_label=\"egg\")\n    assert viz.pos_label == \"egg\"\n\n    viz = CalibrationDisplay.from_predictions(y_true_str, y_pred, pos_label=\"spam\")\n    assert viz.pos_label == \"spam\"\n"], "sample_479": ["def test_create_model_alter_model_table_comment(self):\n    \"\"\"\n    AlterModelTableComment should optimize into CreateModel.\n    \"\"\"\n    managers = [(\"objects\", EmptyManager())]\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n                options={\"verbose_name\": \"Foo\"},\n                bases=(UnicodeModel,),\n                managers=managers,\n            ),\n            migrations.AlterModelTableComment(\"Foo\", \"This is a comment\"),\n        ],\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n                options={\"verbose_name\": \"Foo\", \"db_table_comment\": \"This is a comment\"},\n                bases=(UnicodeModel,),\n                managers=managers,\n            ),\n        ],\n    )\n"], "sample_203": ["    def test_valid_extensions(self):\n        validator = validators.FileExtensionValidator(allowed_extensions=['txt', 'pdf'])\n        file = SimpleUploadedFile('test.txt', b'file content')\n        try:\n            validator(file)\n        except ValidationError:\n            self.fail('ValidationError raised unexpectedly')\n"], "sample_117": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = ''\n        html = widget.render('name', value, {'id': 'id_password'})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_450": ["def test_get_admin_log_template_tag(self):\n    \"\"\"\n    Test the get_admin_log template tag.\n    \"\"\"\n    template = \"{% load admin_utils %}{% get_admin_log 10 as admin_log %}\"\n    rendered_template = template.render(context={\"log_entries\": LogEntry.objects.all()})\n    self.assertEqual(rendered_template, \"\")\n\n    template = \"{% load admin_utils %}{% get_admin_log 10 as admin_log for_user 1 %}\"\n    rendered_template = template.render(context={\"log_entries\": LogEntry.objects.all()})\n    self.assertEqual(rendered_template, \"\")\n\n    template = \"{% load admin_utils %}{% get_admin_log 10 as admin_log for_user user %}\"\n    rendered_template = template.render(context={\"log_entries\": LogEntry.objects.all(), \"user\": self.user})\n    self.assertEqual(rendered_template, \"\")\n\n    template = \"{% load admin_utils %}{% get_admin_log 10 as admin_log for_user invalid_user %}\"\n    with self.assertRaises(template.TemplateSyntaxError):\n        rendered_template = template.render(context={\"log_entries\": LogEntry.objects.all()})\n\n    template = \"{% load admin_utils %}{% get_admin_log invalid_limit as admin_log %}\"\n    with self.assertRaises(template.TemplateSyntaxError):\n        rendered_template = template.render(context={\"log_entries\": LogEntry.objects.all()})\n"], "sample_2": ["def test_ccddata_init_with_invalid_unit(tmpdir):\n    with pytest.raises(ValueError):\n        CCDData(np.zeros([2, 2]), unit=\"definitely-not-a-unit\")\n"], "sample_515": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc)\n    assert cb.alpha is None\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n    cb.set_alpha([0.5, 0.5])\n    assert cb.alpha is None\n"], "sample_956": ["def test_inventory_exists(tempdir, app, status, warning):\n    inv_file = tempdir / 'inventory'\n    inv_file.write_bytes(inventory_v2)\n    set_config(app, {\n        'https://docs.python.org/': inv_file,\n    })\n\n    # load the inventory and check if it's done correctly\n    normalize_intersphinx_mapping(app, app.config)\n    load_mappings(app)\n\n    assert inventory_exists(app.env, 'https://docs.python.org/')\n    assert not inventory_exists(app.env, 'https://docs.python.org/invalid')\n"], "sample_103": ["def test_aggregate_with_empty_queryset(self):\n    \"\"\"\n    Test that aggregates return None when the queryset is empty.\n    \"\"\"\n    vals = Author.objects.none().aggregate(Avg(\"age\"))\n    self.assertEqual(vals, {\"age__avg\": None})\n\n    vals = Author.objects.none().aggregate(Sum(\"age\"))\n    self.assertEqual(vals, {\"age__sum\": None})\n\n    vals = Author.objects.none().aggregate(Max(\"age\"))\n    self.assertEqual(vals, {\"age__max\": None})\n\n    vals = Author.objects.none().aggregate(Min(\"age\"))\n    self.assertEqual(vals, {\"age__min\": None})\n\n    vals = Author.objects.none().aggregate(Count(\"age\"))\n    self.assertEqual(vals, {\"age__count\": 0})\n"], "sample_1041": ["def test_MatrixExpr_from_index_summation():\n    from sympy import MatrixSymbol, Sum, symbols\n    from sympy.abc import i, j, k, l, N\n    A = MatrixSymbol(\"A\", N, N)\n    B = MatrixSymbol(\"B\", N, N)\n    C = MatrixSymbol(\"C\", N, N)\n    D = MatrixSymbol(\"D\", N, N)\n    E = MatrixSymbol(\"E\", N, N)\n    F = MatrixSymbol(\"F\", N, N)\n    G = MatrixSymbol(\"G\", N, N)\n    H = MatrixSymbol(\"H\", N, N)\n    I = MatrixSymbol(\"I\", N, N)\n    J = MatrixSymbol(\"J\", N, N)\n    K = MatrixSymbol(\"K\", N, N)\n    L = MatrixSymbol(\"L\", N, N)\n    M = MatrixSymbol(\"M\", N, N)\n    n = symbols('n')\n\n    assert MatrixExpr.from_index_summation(Sum(A[i, j]*B[j, k], (j, 0, N-1))) == A*B\n    assert MatrixExpr.from_index_summation(Sum(A[j, i]*B[j, k], (j, 0, N-1))) == A.T*B\n    assert MatrixExpr.from_index_summation(Sum(A[i, i], (i, 0, N-1))) == A.trace()\n    assert MatrixExpr.from_index_summation(Sum(A[i, j]*B[k, j]*A[l, k], (j, 0, N-1), (k, 0, N-1))) == A*B.T*A.T\n    assert MatrixExpr.from_index_summation(Sum(A[i, j]*B[j, k]*C[k, l]*D[l, i], (j, 0, N-1), (k, 0, N-1), (l, 0, N-1))) == A*B*C*D\n    assert MatrixExpr.from_index_summation(Sum(A[i, j]*B[j, k]*C[k, l]*D[l, i]*E[i, j]*F[j, k]*G[k, l]*H[l, i], (j, 0, N-1), (k, 0, N-1), (l, 0, N-1))) == A*B*C*D"], "sample_644": ["def test_import_outside_toplevel(self) -> None:\n    module = astroid.MANAGER.ast_from_module_name(\"import_outside_toplevel\", REGR_DATA)\n    import_node = module.body[1].body[0]\n\n    msg = MessageTest(\n        msg_id=\"import-outside-toplevel\",\n        node=import_node,\n        args=\"math\",\n        line=3,\n        col_offset=4,\n        end_line=3,\n        end_col_offset=11,\n    )\n    with self.assertAddsMessages(msg):\n        self.checker.visit_import(import_node)\n"], "sample_995": ["def test_issue_12345():\n    # Test that the Float class handles precision correctly when converting from a string\n    assert Float('1.23456789012345678901234567890', 30)._prec == 30\n    assert Float('1.23456789012345678901234567890', 30) == Float('1.23456789012345678901234567890', '')\n"], "sample_330": ["    def test_typecast_date(self):\n        self.assertIsNone(typecast_date(None))\n        self.assertEqual(typecast_date('2022-01-01'), datetime.date(2022, 1, 1))\n"], "sample_1144": ["def test_requires_partial_edge_cases():\n    x, y, z, t, nu = symbols('x y z t nu')\n    n = symbols('n', integer=True)\n\n    # Test with a single free symbol that is not an integer\n    f = x\n    assert requires_partial(Derivative(f, x)) is False\n\n    # Test with a single free symbol that is an integer\n    f = n\n    assert requires_partial(Derivative(f, n)) is False\n\n    # Test with no free symbols\n    f = 5\n    assert requires_partial(Derivative(f, x)) is False\n\n    # Test with a non-derivative expression\n    f = x + y\n    assert requires_partial(f) is False\n\n    # Test with a derivative of a non-derivative expression\n    f = Derivative(x + y, x)\n    assert requires_partial(f) is True\n\n    # Test with a derivative of a derivative expression\n    f = Derivative(Derivative(x + y, x), x)\n    assert requires_partial(f) is True\n"], "sample_941": ["def test_is_system_TypeVar():\n    T = TypeVar('T')\n    assert is_system_TypeVar(T) is True\n    assert is_system_TypeVar(int) is False\n    assert is_system_TypeVar(List) is False\n    assert is_system_TypeVar(List[int]) is False\n"], "sample_899": ["def test_check_estimator_sparse_data():\n    # test that check_estimator_sparse_data works correctly\n    class EstimatorWithSparseData(BaseEstimator):\n            if sp.issparse(X):\n                raise ValueError(\"Sparse data not supported\")\n            return self\n\n            return np.ones(X.shape[0])\n\n    msg = \"Estimator EstimatorWithSparseData doesn't seem to fail gracefully on sparse data\"\n    assert_raises_regex(AssertionError, msg, check_estimator_sparse_data,\n                        \"EstimatorWithSparseData\", EstimatorWithSparseData())\n\n    class EstimatorWithSparseData64(BaseEstimator):\n            if sp.issparse(X):\n                if X.getformat() == \"coo\":\n                    if X.row.dtype == \"int64\" or X.col.dtype == \"int64\":\n                        raise ValueError(\"64-bit indices not supported\")\n                elif X.getformat() in [\"csc\", \"csr\"]:\n                    if X.indices.dtype == \"int64\" or X.indptr.dtype == \"int64\":\n                        raise ValueError(\"64-bit indices not supported\")\n            return self\n\n            return np.ones(X.shape[0])\n\n    msg = (\"Estimator EstimatorWithSparseData64 doesn't seem to support \"\n           \"coo_64 matrix, and is not failing gracefully\")\n    assert_raises_regex(AssertionError, msg, check_estimator_sparse_data,\n                        \"EstimatorWithSparseData64\", EstimatorWithSparseData64())\n"], "sample_822": ["def test_cosine_similarity_sparse():\n    # Test the cosine_similarity with sparse matrices.\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((5, 4))\n    Y = rng.random_sample((3, 4))\n    Xcsr = csr_matrix(X)\n    Ycsr = csr_matrix(Y)\n\n    # should be sparse\n    K1 = cosine_similarity(Xcsr, Ycsr, dense_output=False)\n    assert issparse(K1)\n\n    # should be dense, and equal to K1\n    K2 = cosine_similarity(X, Y, dense_output=True)\n    assert not issparse(K2)\n    assert_array_almost_equal(K1.todense(), K2)\n\n    # show the kernel output equal to the sparse.todense()\n    K3 = pairwise_kernels(X, Y=Y, metric=\"cosine\")\n    assert_array_almost_equal(K1.todense(), K3)\n"], "sample_218": ["def test_trunc_timezone_with_dst_transition(self):\n    sao = pytz.timezone('America/Sao_Paulo')\n    start_datetime = datetime(2016, 10, 16, 1, 30, 50, 321)\n    end_datetime = datetime(2016, 2, 21, 1, 30, 50, 123)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n\n    with timezone.override(sao):\n        model = DTModel.objects.annotate(\n            truncated_start=TruncHour('start_datetime', tzinfo=sao),\n            truncated_end=TruncHour('end_datetime', tzinfo=sao),\n        ).get()\n        self.assertEqual(model.truncated_start.dst(), timedelta(0, 3600))\n        self.assertEqual(model.truncated_end.dst(), timedelta(0))\n"], "sample_913": ["def test_domain_py_module_index_with_common_prefix(app, status, warning):\n    app.config.modindex_common_prefix = ['sphinx.']\n    app.builder.build_all()\n\n    index = PythonModuleIndex(app.env.get_domain('py'))\n    assert index.generate() == (\n        [('c', [IndexEntry('config', 2, 'index', 'module-sphinx.config', '', '', '')]),\n         ('d', [IndexEntry('docutils', 0, 'index', 'module-docutils', '', '', '')]),\n         ('s', [IndexEntry('builders', 1, 'index', 'module-sphinx.builders', '', '', ''),\n                IndexEntry('builders.html', 2, 'index', 'module-sphinx.builders.html', '', '', ''),  # NOQA\n                IndexEntry('intl', 0, 'index', 'module-sphinx_intl', '', '', '')])],\n        False\n    )\n"], "sample_977": ["def test_Sum():\n    assert mcode(Sum(x**2, (x, 0, 10))) == \"Hold[Sum[x^2, {x, 0, 10}]]\"\n    assert mcode(Sum(x**2, (x, 0, 10, 2))) == \"Hold[Sum[x^2, {x, 0, 10, 2}]]\"\n    assert mcode(Sum(x*y, (x, 0, 10), (y, 0, 10))) == \\\n        \"Hold[Sum[x*y, {x, 0, 10}, {y, 0, 10}]]\"\n"], "sample_348": ["    def test_model_form_metaclass(self):\n        class TestModel(Model):\n            name = Field()\n\n        class TestForm(ModelForm):\n            class Meta:\n                model = TestModel\n                fields = ('name',)\n\n        self.assertEqual(TestForm._meta.model, TestModel)\n        self.assertEqual(TestForm._meta.fields, ('name',))\n"], "sample_269": ["    def test_json_catalog(self):\n        \"\"\"The json_catalog returns the language catalog and settings as JSON.\"\"\"\n        with override('de'):\n            response = self.client.get('/jsoni18n/')\n            data = json.loads(response.content.decode())\n            self.assertIn('catalog', data)\n            self.assertIn('formats', data)\n            self.assertEqual(data['formats']['TIME_INPUT_FORMATS'], ['%H:%M:%S', '%H:%M:%S.%f', '%H:%M'])\n            self.assertEqual(data['formats']['FIRST_DAY_OF_WEEK'], 0)\n            self.assertIn('plural', data)\n            self.assertEqual(data['catalog']['month name\\x04May'], 'Mai')\n            self.assertIn('DATETIME_FORMAT', data['formats'])\n            self.assertEqual(data['plural'], '(n != 1)')\n"], "sample_810": ["def test_pipeline_memory_with_clone():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        if LooseVersion(joblib_version) < LooseVersion('0.12'):\n            # Deal with change of API in joblib\n            memory = Memory(cachedir=cachedir, verbose=10)\n        else:\n            memory = Memory(location=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(gamma='scale', probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', clone(transf)), ('svc', clf)],\n                        memory=memory)\n\n        # Memoize the transformer at the first fit\n        pipe.fit(X, y)\n        # Get the time stamp of the transformer in the cached pipeline\n        ts = pipe.named_steps['transf'].timestamp_\n        # Check that we are reading the cache while fitting\n        # a second time\n        pipe.fit(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           pipe.named_steps['transf'].means_)\n        assert_equal(ts, pipe.named_steps['transf'].timestamp_)\n        # Create a new pipeline with cloned estimators\n        # Check that even changing the name step does not affect the cache hit\n        clf_2 = SVC(gamma='scale', probability=True, random_state=0)\n        transf_2 = DummyTransf()\n        pipe_2 = Pipeline([('transf_2', transf_2), ('svc', clf_2)],\n                          memory=memory)\n        pipe_2.fit(X, y)\n\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           pipe_2.named_steps['transf_2'].means_)\n        assert_equal(ts, pipe_2.named_steps['transf_2'].timestamp_)\n    finally:\n        shutil.rmtree(cachedir)\n"], "sample_382": ["def test_reset_nested_loaders(self, mock_reset):\n    autoreload.reset_loaders()\n    self.assertEqual(mock_reset.call_count, 2)\n"], "sample_619": ["def test_decode_cf_datetime_with_cftime_and_use_cftime_false():\n    units = \"days since 2000-01-01\"\n    calendar = \"noleap\"\n    num_dates = np.arange(10)\n    with pytest.raises(ValueError, match=\"Calendar 'noleap' is only valid with cftime.\"):\n        decode_cf_datetime(num_dates, units, calendar, use_cftime=False)\n"], "sample_643": ["def test_colorized_text_reporter_color_mapping(linter):\n    output = StringIO()\n    color_mapping = {\n        \"I\": MessageStyle(\"green\"),\n        \"C\": MessageStyle(None, (\"bold\",)),\n        \"R\": MessageStyle(\"magenta\", (\"bold\", \"italic\")),\n        \"W\": MessageStyle(\"magenta\"),\n        \"E\": MessageStyle(\"red\", (\"bold\",)),\n        \"F\": MessageStyle(\"red\", (\"bold\", \"underline\")),\n        \"S\": MessageStyle(\"yellow\", (\"inverse\",)),  # S stands for module Separator\n    }\n    reporter = ColorizedTextReporter(output, color_mapping)\n    linter.reporter = reporter\n    linter.open()\n    linter.set_current_module(\"my_mod\")\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\n        \"line-too-long\", line=2, end_lineno=2, end_col_offset=4, args=(3, 4)\n    )\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert out_lines[1].startswith(\"\\033[1m************* Module my_mod\\033[0m\")\n    assert out_lines[2].startswith(\"\\033[31;1mmy_mod:1:0: C0301: Line too long (1/2) (line-too-long)\\033[0m\")\n    assert out_lines[3].startswith(\"\\033[31;1mmy_mod:2:0:2:4: C0301: Line too long (3/4) (line-too-long)\\033[0m\")\n"], "sample_864": ["def test_mean_shift_max_iter():\n    # Test MeanShift algorithm with max_iter parameter\n    ms = MeanShift(bandwidth=1.2, max_iter=10)\n    labels = ms.fit(X).labels_\n    assert ms.n_iter_ <= 10\n\n    ms = MeanShift(bandwidth=1.2, max_iter=1000)\n    labels = ms.fit(X).labels_\n    assert ms.n_iter_ <= 1000\n"], "sample_633": ["def test_hash_lineset() -> None:\n    lineset = LineSet(\n        \"test\",\n        [\n            \"import one\",\n            \"from two import two\",\n            \"three\",\n            \"four\",\n            \"five\",\n            \"# A full line comment\",\n            \"seven\",\n            \"eight\",\n            \"nine\",\n            \"''' ten\",\n            \"ELEVEN\",\n            \"twelve '''\",\n            \"thirteen\",\n            \"fourteen\",\n        ],\n        ignore_comments=False,\n        ignore_docstrings=False,\n        ignore_imports=False,\n        ignore_signatures=False,\n    )\n    hash_to_index, index_to_lines = hash_lineset(lineset, min_common_lines=4)\n    assert len(hash_to_index) == 9\n    assert len(index_to_lines) == 9\n    assert hash_to_index[LinesChunk(\"test\", 0, \"import one\", \"from two import two\", \"three\", \"four\")] == [\n        0\n    ]\n    assert index_to_lines[0] == SuccessiveLinesLimits(0, 4)\n"], "sample_921": ["def test_is_singledispatch_function():\n    @functools.singledispatch\n        pass\n\n    assert inspect.is_singledispatch_function(fun) is True\n\n        pass\n\n    assert inspect.is_singledispatch_function(not_singledispatch_function) is False\n\n"], "sample_168": ["def test_noinput_with_dependent_objects(self):\n    \"\"\"\n    --noinput mode deletes stale content types and warns of dependent objects.\n    \"\"\"\n    post = Post.objects.create(title='post', content_type=self.content_type)\n    # A related object is needed to show that a custom collector with\n    # can_fast_delete=False is needed.\n    ModelWithNullFKToSite.objects.create(post=post)\n    with captured_stdout() as stdout:\n        call_command('remove_stale_contenttypes', noinput=True, verbosity=2)\n    self.assertEqual(Post.objects.count(), 0)\n    output = stdout.getvalue()\n    self.assertIn('- Content type for contenttypes_tests.Fake', output)\n    self.assertIn('- 1 contenttypes_tests.Post object(s)', output)\n    self.assertIn('- 1 contenttypes_tests.ModelWithNullFKToSite', output)\n    self.assertIn('Deleting stale content type', output)\n    self.assertEqual(ContentType.objects.count(), self.before_count)\n"], "sample_886": ["def test__wrap_data_with_container():\n    \"\"\"Check _wrap_data_with_container works as expected.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    est = EstimatorWithSetOutput().fit(X)\n\n    # If output config is \"default\", return data_to_wrap unchanged\n    est.set_output(transform=\"default\")\n    X_wrapped = _wrap_data_with_container(\"transform\", X, X, est)\n    assert isinstance(X_wrapped, np.ndarray)\n\n    # If output config is \"pandas\", return data_to_wrap as a pandas DataFrame\n    est.set_output(transform=\"pandas\")\n    X_wrapped = _wrap_data_with_container(\"transform\", X, X, est)\n    assert isinstance(X_wrapped, pd.DataFrame)\n\n    # If estimator is not configured for wrapping, return data_to_wrap unchanged\n    est = EstimatorWithSetOutputNoAutoWrap().fit(X)\n    X_wrapped = _wrap_data_with_container(\"transform\", X, X, est)\n    assert isinstance(X_wrapped, np.ndarray)\n\n    # If data_to_wrap is a tuple, only wrap the first output\n    X_tuple = (X, X)\n    est.set_output(transform=\"pandas\")\n    X_wrapped = _wrap_data_with_container(\"transform\", X_tuple, X, est)\n    assert isinstance(X_wrapped[0], pd.DataFrame)\n    assert isinstance(X_wrapped[1], np.ndarray)\n"], "sample_149": ["    def test_builtin_permission_name_length_with_long_model_name(self):\n        model_name = 'X' * 90\n        model = type(model_name, (models.Model,), {'__module__': self.__module__})\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n"], "sample_526": ["def test_num2date_timezone():\n    # Test that num2date returns a datetime object with the correct timezone\n    # when the input is a numpy datetime64 object with a timezone.\n    dt = np.datetime64('2022-01-01T00:00:00+02:00')\n    result = mdates.num2date(dt)\n    assert result.tzinfo.utcoffset(result) == datetime.timedelta(hours=2)\n"], "sample_27": ["def test_fitsdiff_hdu_name_and_ver(tmp_path):\n    \"\"\"Make sure diff report reports HDU name and ver if same in files\"\"\"\n    path1 = tmp_path / \"test1.fits\"\n    path2 = tmp_path / \"test2.fits\"\n\n    hdulist = HDUList([PrimaryHDU(), ImageHDU(data=np.zeros(5), name=\"SCI\", ver=1)])\n    hdulist.writeto(path1)\n    hdulist[1].data[0] = 1\n    hdulist.writeto(path2)\n\n    diff = FITSDiff(path1, path2)\n    assert \"Extension HDU 1 (SCI, 1):\" in diff.report()\n"], "sample_1190": ["def test_UnitSystem():\n    us = UnitSystem((meter, second, kilogram), name=\"SI\", descr=\"International System of Units\")\n    assert us.name == \"SI\"\n    assert us.descr == \"International System of Units\"\n    assert us._base_units == (meter, second, kilogram)\n    assert us._units == (meter, second, kilogram)\n    assert us._dimension_system is None\n    assert us._derived_units == {}\n\n    us = UnitSystem((meter, second, kilogram), (joule,), name=\"SI\", descr=\"International System of Units\")\n    assert us._base_units == (meter, second, kilogram)\n    assert us._units == (meter, second, kilogram, joule)\n    assert us._dimension_system is None\n    assert us._derived_units == {}\n\n    us = UnitSystem((meter, second, kilogram), name=\"SI\", descr=\"International System of Units\", dimension_system=SI.get_dimension_system())\n    assert us._base_units == (meter, second, kilogram)\n    assert us._units == (meter, second, kilogram)\n    assert us._dimension_system == SI.get_dimension_system()\n    assert us._derived_units == {}\n\n    us = UnitSystem((meter, second, kilogram), name=\"SI\", descr=\"International System of Units\", derived_units={energy: joule})\n    assert us._base_units == (meter, second, kilogram)\n    assert us._units == (meter, second, kilogram)\n    assert us._dimension_system is None\n    assert us._derived_units == {energy: joule}\n\n    us = UnitSystem((meter, second, kilogram), (joule,), name=\"SI\", descr=\"International System of Units\", dimension_system=SI.get_dimension_system(), derived_units={energy: joule})\n    assert us._base_units == (meter, second, kilogram)\n    assert us._units == (meter, second, kilogram, joule)\n    assert us._dimension_system == SI.get_dimension_system()\n    assert us._derived_units == {energy: joule}\n\n    us = UnitSystem.extend(us, (joule,), name=\"SI extended\", descr=\"Extended International System of Units\")\n    assert us._base_units == (meter, second, kilogram, joule)\n    assert us._units == (meter, second, kilogram, joule)\n    assert us._dimension_system == SI.get"], "sample_929": ["def test_domain_py_module_index_entry(app, status, warning):\n    app.builder.build_all()\n\n    domain = app.env.get_domain('py')\n    modules = domain.modules\n\n    assert 'module_a.submodule' in modules\n    assert modules['module_a.submodule'].docname == 'module'\n    assert modules['module_a.submodule'].node_id == 'module-module_a.submodule'\n    assert modules['module_a.submodule'].synopsis == ''\n    assert modules['module_a.submodule'].platform == ''\n    assert not modules['module_a.submodule'].deprecated\n\n    assert 'module_b.submodule' in modules\n    assert modules['module_b.submodule'].docname == 'module'\n    assert modules['module_b.submodule'].node_id == 'module-module_b.submodule'\n    assert modules['module_b.submodule'].synopsis == ''\n    assert modules['module_b.submodule'].platform == ''\n    assert not modules['module_b.submodule'].deprecated\n"], "sample_1206": ["def test_issue_14289():\n    from sympy.polys.numberfields import to_number_field\n\n    a = 1 - sqrt(2)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n\n    a = sqrt(2) + sqrt(3)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n\n    a = sqrt(2) + sqrt(3) + sqrt(5)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n"], "sample_823": ["def test_check_pairwise_arrays_precomputed():\n    # Ensure that check_pairwise_arrays works correctly with precomputed\n    # distance matrices.\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((5, 5))\n    X_checked, _ = check_pairwise_arrays(X, None, precomputed=True)\n    assert_array_equal(X, X_checked)\n\n    # Ensure that check_pairwise_arrays raises an error if the precomputed\n    # distance matrix is not square.\n    X = rng.random_sample((5, 4))\n    assert_raises(ValueError, check_pairwise_arrays, X, None, precomputed=True)\n\n    # Ensure that check_pairwise_arrays raises an error if the precomputed\n    # distance matrix contains negative values.\n    X = rng.random_sample((5, 5))\n    X[0, 1] = -1\n    assert_raises(ValueError, check_pairwise_arrays, X, None, precomputed=True)\n"], "sample_265": ["def test_get_template(self):\n    engine = DjangoTemplates({\n        'DIRS': [Path(__file__).parent / 'templates'],\n        'APP_DIRS': False,\n        'NAME': 'django',\n        'OPTIONS': {},\n    })\n\n    template = engine.get_template('test_template.html')\n    self.assertIsNotNone(template)\n\n    with self.assertRaises(TemplateDoesNotExist):\n        engine.get_template('non_existent_template.html')\n\n    with self.assertRaises(TemplateDoesNotExist):\n        engine.get_template('')\n\n    with self.assertRaises(TemplateDoesNotExist):\n        engine.get_template(None)\n"], "sample_349": ["def test_render_options_m2m_as_uuid(self):\n    \"\"\"Selected options are rendered correctly for a ManyToManyField with UUID.\"\"\"\n    beatles = Band.objects.create(name='The Beatles', style='rock')\n    who = Band.objects.create(name='The Who', style='rock')\n    rubber_soul = Album.objects.create(name='Rubber Soul', band=beatles)\n    rubber_soul.featuring.add(beatles, who)\n    form = AlbumForm(instance=rubber_soul)\n    output = form.as_table()\n    selected_option = '<option value=\"%s\" selected>The Beatles</option>' % beatles.uuid\n    option = '<option value=\"%s\" selected>The Who</option>' % who.uuid\n    self.assertIn(selected_option, output)\n    self.assertIn(option, output)\n"], "sample_73": ["    def test_hash_key(self):\n        name = \"cached/styles.css\"\n        cache_key = storage.staticfiles_storage.hash_key(name)\n        self.assertEqual(cache_key, 'staticfiles:5e0040571e1a')\n"], "sample_360": ["    def tearDown(self):\n        cache.clear()\n"], "sample_1167": ["def test_latex_tensor_indices():\n    from sympy.tensor.tensor import TensorIndexType, tensor_indices, TensorHead, tensor_heads\n    L = TensorIndexType(\"L\")\n    i, j, k, l = tensor_indices(\"i j k l\", L)\n    i0 = tensor_indices(\"i_0\", L)\n    A, B, C, D = tensor_heads(\"A B C D\", [L])\n    H = TensorHead(\"H\", [L, L])\n    K = TensorHead(\"K\", [L, L, L, L])\n\n    assert latex(A(i, j, k, l)) == r\"A{}^{ijkl}\"\n    assert latex(A(i, j, -k, l)) == r\"A{}^{ij}{}_{k}l\"\n    assert latex(A(i, j, k, -l)) == r\"A{}^{ijk}{}_{l}\"\n    assert latex(A(i, j, -k, -l)) == r\"A{}^{ij}{}_{kl}\"\n    assert latex(A(-i, j, k, l)) == r\"A{}_{i}jkl\"\n    assert latex(A(-i, j, -k, l)) == r\"A{}_{i}j{}_{k}l\"\n    assert latex(A(-i, j, k, -l)) == r\"A{}_{i}jk{}_{l}\"\n    assert latex(A(-i, j, -k, -l)) == r\"A{}_{i}j{}_{kl}\"\n    assert latex(A(-i, -j, k, l)) == r\"A{}_{ij}kl\"\n    assert latex(A(-i, -j, -k, l)) == r\"A{}_{ij}{}_{k}l\"\n    assert latex(A(-i, -j, k, -l)) == r\"A{}_{ij}k{}_{l}\"\n    assert latex(A(-i, -j, -k, -l)) == r\"A{}_{ijkl}\"\n    assert latex(A(i, -j, k, l)) == r\"A{}^{i}{}_{j}kl\"\n    assert latex(A(i, -j, -k, l)) == r\"A{}^{i}{}_{jk}l\"\n    assert latex(A(i, -j, k, -l)) == r\"A{}^{i}{}_{j}k{}_{l}\"\n    assert latex(A(i, -j,"], "sample_421": ["    def test_window_function(self):\n        self.assertQuerysetEqual(\n            CaseTestModel.objects.annotate(\n                row_number=Window(\n                    expression=RowNumber(),\n                    partition_by=F(\"integer\"),\n                    order_by=F(\"integer\").asc(),\n                )\n            ).order_by(\"integer\", \"pk\"),\n            [\n                (1, 1),\n                (2, 1),\n                (2, 2),\n                (3, 1),\n                (3, 2),\n                (3, 3),\n                (4, 1),\n            ],\n            transform=attrgetter(\"integer\", \"row_number\"),\n        )\n"], "sample_846": ["def test_column_transformer_transformer_weights():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    X_res_first = np.array([0, 1, 2]).reshape(-1, 1)\n    X_res_second = np.array([2, 4, 6]).reshape(-1, 1)\n    X_res_both = X_array\n\n    # test with transformer_weights\n    transformer_weights = {'trans1': .1, 'trans2': 10}\n    both = ColumnTransformer([('trans1', Trans(), [0]),\n                              ('trans2', Trans(), [1])],\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * X_res_first1D,\n                     transformer_weights['trans2'] * X_res_second1D]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    both = ColumnTransformer([('trans', Trans(), [0, 1])],\n                             transformer_weights={'trans': .1})\n    assert_array_equal(both.fit_transform(X_array), 0.1 * X_res_both)\n    assert_array_equal(both.fit(X_array).transform(X_array), 0.1 * X_res_both)\n    assert len(both.transformers_) == 1\n\n    # test with transformer_weights and remainder\n    transformer_weights = {'trans1': .1, 'trans2': 10}\n    both = ColumnTransformer([('trans1', Trans(), [0]),\n                              ('trans2', Trans(), [1])],\n                             remainder='passthrough',\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * X_res_first1D,\n                     transformer_weights['trans2'] * X_res_second1D,\n                     X_res_both]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 3\n\n    # test with transformer_weights and remainder transformer\n    transformer_weights = {'trans1': .1, 'trans2': 10}\n    both = ColumnTransformer([('trans1', Trans(), [0]),\n                              ('trans2', Trans(), [1])],\n                             remainder"], "sample_276": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n        self.company = Company.objects.create(name=\"Django\")\n        self.person = Person.objects.create(first_name=\"Human\", last_name=\"User\", company=self.company)\n"], "sample_59": ["    def test_save_base_force_insert_force_update(self):\n        msg = \"Cannot force both insert and updating in model saving.\"\n        with self.assertRaisesMessage(ValueError, msg):\n            Article().save(force_insert=True, force_update=True)\n"], "sample_845": ["def test_vectorizer_input_type():\n    # test that input type is validated\n    vect = CountVectorizer(input='invalid')\n    assert_raises(ValueError, vect.fit, JUNK_FOOD_DOCS)\n\n    # test that input type is validated\n    vect = CountVectorizer(input='file')\n    assert_raises(ValueError, vect.fit, JUNK_FOOD_DOCS)\n\n    # test that input type is validated\n    vect = CountVectorizer(input='filename')\n    assert_raises(ValueError, vect.fit, JUNK_FOOD_DOCS)\n\n    # test that input type is validated\n    vect = CountVectorizer(input='content')\n    assert vect.fit(JUNK_FOOD_DOCS) is not None\n"], "sample_1043": ["def test_user_functions():\n    assert mcode(sin(x), user_functions={'sin': 'MySin'}) == \"MySin[x]\"\n    assert mcode(sin(x), user_functions={'sin': ['MySin', 'MyOtherSin']}) == \"MySin[x]\"\n    assert mcode(sin(x), user_functions={'sin': [(lambda x: x.is_real, 'MyRealSin'), \n                                                 (lambda x: True, 'MySin')]}) == \"MyRealSin[x]\"\n    assert mcode(sin(x + I), user_functions={'sin': [(lambda x: x.is_real, 'MyRealSin'), \n                                                     (lambda x: True, 'MySin')]}) == \"MySin[x + I]\"\n"], "sample_524": ["def test_colorbar_set_ticks():\n    # test feature for #5792\n    plt.figure()\n    data = np.arange(1200).reshape(30, 40)\n    levels = [0, 200, 400, 600, 800, 1000, 1200]\n\n    plt.contourf(data, levels=levels)\n\n    # testing setter for user set ticks\n    userTicks = plt.colorbar(ticks=[0, 600, 1200])\n    assert userTicks.get_ticks().tolist() == [0, 600, 1200]\n\n    # testing for setter after calling set_ticks\n    userTicks.set_ticks([600, 700, 800])\n    assert userTicks.get_ticks().tolist() == [600, 700, 800]\n\n    # testing for setter after calling set_ticks with some ticks out of bounds\n    # removed #20054: other axes don't trim fixed lists, so colorbars\n    # should not either:\n    # userTicks.set_ticks([600, 1300, 1400, 1500])\n    # assert userTicks.get_ticks().tolist() == [600]\n\n    # testing setter when no ticks are assigned\n    defTicks = plt.colorbar(orientation='horizontal')\n    np.testing.assert_allclose(defTicks.get_ticks(), levels)\n\n    # test normal ticks and minor ticks\n    fig, ax = plt.subplots()\n    x = np.arange(-3.0, 4.001)\n    y = np.arange(-4.0, 3.001)\n    X, Y = np.meshgrid(x, y)\n    Z = X * Y\n    Z = Z[:-1, :-1]\n    pcm = ax.pcolormesh(X, Y, Z)\n    cbar = fig.colorbar(pcm, ax=ax, extend='both',\n                        orientation='vertical')\n    ticks = cbar.get_ticks()\n    cbar.set_ticks([1, 2, 3])\n    assert isinstance(cbar.locator, FixedLocator)\n    np.testing.assert_allclose(cbar.ax.yaxis.get_ticklocs(),\n                               [1.0, 2.0, 3.0])\n\n    # test that set_ticks removes the FixedLocator...\n    cbar.set_ticks(None)\n    assert not isinstance(cbar.locator, FixedLocator)\n    np.testing.assert_allclose(cbar.ax.yaxis.get_ticklocs(),\n                               np.arange(-15, 16, 5))\n"], "sample_238": ["def test_trigonometric_functions(self):\n    # Test the trigonometric functions\n    book = Book.objects.annotate(\n        sin_rating=Sin('rating'),\n        cos_rating=Cos('rating'),\n        tan_rating=Tan('rating'),\n        asin_rating=ASin('rating'),\n        acos_rating=ACos('rating'),\n        atan_rating=ATan('rating'),\n        atan2_rating=ATan2('rating', 'pages'),\n    ).get(pk=self.b1.pk)\n\n    self.assertAlmostEqual(book.sin_rating, math.sin(book.rating))\n    self.assertAlmostEqual(book.cos_rating, math.cos(book.rating))\n    self.assertAlmostEqual(book.tan_rating, math.tan(book.rating))\n    self.assertAlmostEqual(book.asin_rating, math.asin(book.rating))\n    self.assertAlmostEqual(book.acos_rating, math.acos(book.rating))\n    self.assertAlmostEqual(book.atan_rating, math.atan(book.rating))\n    self.assertAlmostEqual(book.atan2_rating, math.atan2(book.rating, book.pages))\n\n    # Test the trigonometric functions with a subquery\n    subquery = Book.objects.filter(pk=OuterRef('pk')).values('rating')[:1]\n    book = Book.objects.annotate(\n        sin_rating=Sin(Subquery(subquery)),\n        cos_rating=Cos(Subquery(subquery)),\n        tan_rating=Tan(Subquery(subquery)),\n        asin_rating=ASin(Subquery(subquery)),\n        acos_rating=ACos(Subquery(subquery)),\n        atan_rating=ATan(Subquery(subquery)),\n        atan2_rating=ATan2(Subquery(subquery), 'pages'),\n    ).get(pk=self.b1.pk)\n\n    self.assertAlmostEqual(book.sin_rating, math.sin(book.rating))\n    self.assertAlmostEqual(book.cos_rating, math.cos(book.rating))\n    self.assertAlmostEqual(book.tan_rating, math.tan(book.rating))\n    self.assertAlmostEqual(book.asin_rating, math.asin(book.rating))\n    self.assertAlmostEqual(book.acos_rating, math.acos(book.rating))\n    self.assertAlmostEqual(book.atan_rating, math.atan(book.rating))\n    self.assertAlmostEqual(book.atan2_rating, math.atan2(book.rating, book.pages))\n"], "sample_16": ["    def setup_method(self):\n        self.q = np.arange(9.0).reshape(3, 3) * u.m\n"], "sample_564": ["def test_axes3d_focal_length_zoom():\n    fig, axs = plt.subplots(1, 2, subplot_kw={'projection': '3d'})\n    axs[0].set_proj_type('persp', focal_length=0.1)\n    axs[1].set_proj_type('persp', focal_length=10)\n    for ax in axs:\n        ax.plot([0, 1], [0, 1], [0, 1])\n        ax.set_xlim(-1, 2)\n        ax.set_ylim(-1, 2)\n        ax.set_zlim(-1, 2)\n"], "sample_95": ["    def test_patch_cache_control(self):\n        response = HttpResponse()\n        patch_cache_control(response, max_age=3600, public=True)\n        self.assertEqual(response['Cache-Control'], 'max-age=3600, public')\n"], "sample_1145": ["def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[0, 0], Q.symmetric(X)) == X[0, 0]\n    assert refine(X[1, 1], Q.symmetric(X)) == X[1, 1]\n    assert refine(X[0, 1], ~Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], ~Q.symmetric(X)) == X[1, 0]\n"], "sample_325": ["def test_boundfield_subwidgets(self):\n    class MyForm(Form):\n        name = ChoiceField(choices=[('a', 'A'), ('b', 'B')], widget=RadioSelect)\n\n    form = MyForm()\n    boundfield = form['name']\n    subwidgets = boundfield.subwidgets\n    self.assertEqual(len(subwidgets), 2)\n    self.assertEqual(subwidgets[0].id_for_label, 'id_name_0')\n    self.assertEqual(subwidgets[0].choice_label, 'A')\n    self.assertHTMLEqual(subwidgets[0].tag(), '<input type=\"radio\" name=\"name\" value=\"a\" id=\"id_name_0\" required>')\n    self.assertHTMLEqual(str(subwidgets[0]), '<label for=\"id_name_0\"><input type=\"radio\" name=\"name\" value=\"a\" id=\"id_name_0\" required> A</label>')\n    self.assertEqual(subwidgets[1].id_for_label, 'id_name_1')\n    self.assertEqual(subwidgets[1].choice_label, 'B')\n    self.assertHTMLEqual(subwidgets[1].tag(), '<input type=\"radio\" name=\"name\" value=\"b\" id=\"id_name_1\" required>')\n    self.assertHTMLEqual(str(subwidgets[1]), '<label for=\"id_name_1\"><input type=\"radio\" name=\"name\" value=\"b\" id=\"id_name_1\" required> B</label>')\n"], "sample_944": ["def test_get_type_hints():\n        pass\n\n    assert get_type_hints(func) == {'a': int, 'b': str, 'return': None}\n\n    class MyClass:\n            pass\n\n    assert get_type_hints(MyClass.__init__) == {'a': int, 'b': str, 'return': None}\n\n    class BrokenClass:\n            raise Exception\n\n    assert get_type_hints(BrokenClass.__init__) == {}\n\n    class GenericClass(Generic[T]):\n            pass\n\n    assert get_type_hints(GenericClass.__init__) == {'a': T, 'return': None}\n"], "sample_271": ["    def test_empty_input(self):\n        self.assertEqual(autoreload.common_roots(()), ())\n"], "sample_414": ["    def test_get_inline_instances(self):\n        class MyInline(admin.TabularInline):\n            model = Member\n\n        class BandAdmin(admin.ModelAdmin):\n            inlines = [MyInline]\n\n        band_admin = BandAdmin(Band, admin.site)\n        inline_instances = band_admin.get_inline_instances(self.client, Band())\n        self.assertEqual(len(inline_instances), 1)\n        self.assertIsInstance(inline_instances[0], MyInline)\n"], "sample_581": ["def test_blueprint_setup_state(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n        assert state.app is app\n        assert state.blueprint is bp\n        assert state.options == {}\n        assert state.first_registration is True\n        assert state.subdomain is None\n        assert state.url_prefix is None\n        assert state.name == \"bp\"\n        assert state.name_prefix == \"\"\n\n    bp.record(setup_state)\n    app.register_blueprint(bp)\n"], "sample_571": ["def test_lmplot_hue_order(self):\n\n    g = lm.lmplot(x=\"x\", y=\"y\", data=self.df, hue=\"h\", hue_order=[\"y\", \"x\"])\n    ax = g.axes[0, 0]\n\n    assert len(ax.lines) == 2\n    assert len(ax.collections) == 4\n\n    red_scatter, blue_scatter = ax.collections\n\n    blue, red = color_palette(n_colors=2)\n    npt.assert_array_equal(blue, red_scatter.get_facecolors()[0, :3])\n    npt.assert_array_equal(red, blue_scatter.get_facecolors()[0, :3])\n"], "sample_347": ["def test_localtime(self):\n    naive = datetime.datetime(2015, 1, 1, 0, 0, 1)\n    with self.assertRaisesMessage(ValueError, 'localtime() cannot be applied to a naive datetime'):\n        timezone.localtime(naive)\n    with self.assertRaisesMessage(ValueError, 'localtime() cannot be applied to a naive datetime'):\n        timezone.localtime(naive, timezone=EAT)\n\n    aware = datetime.datetime(2015, 1, 1, 0, 0, 1, tzinfo=ICT)\n    self.assertEqual(timezone.localtime(aware, timezone=EAT), datetime.datetime(2014, 12, 31, 17, 0, 1))\n    with timezone.override(EAT):\n        self.assertEqual(timezone.localtime(aware), datetime.datetime(2014, 12, 31, 17, 0, 1))\n\n    with mock.patch('django.utils.timezone.now', return_value=aware):\n        self.assertEqual(timezone.localtime(timezone=EAT), datetime.datetime(2014, 12, 31, 17, 0, 1))\n        with timezone.override(EAT):\n            self.assertEqual(timezone.localtime(), datetime.datetime(2014, 12, 31, 17, 0, 1))\n"], "sample_4": ["def test_read_html_table_move_to_meta(self, cosmo, read, write, tmp_path, add_cu):\n    \"\"\"Test moving extra arguments to meta.\"\"\"\n    fp = tmp_path / \"test_read_html_table_move_to_meta.html\"\n\n    # test write\n    write(fp, format=\"ascii.html\")\n\n    # add extra argument\n    tbl = QTable.read(fp)\n    tbl[\"extra\"] = \"will error\"\n    tbl.write(fp, format=\"ascii.html\", overwrite=True)\n\n    # tests are different if the last argument is a **kwarg\n    if tuple(cosmo._init_signature.parameters.values())[-1].kind == 4:\n        got = read(fp, format=\"ascii.html\", move_to_meta=True)\n\n        assert got.__class__ is cosmo.__class__\n        assert got.name == cosmo.name\n        # assert \"extra\" in got.meta # metadata read not implemented\n\n        return  # don't continue testing\n\n    # read with mismatching parameters errors\n    with pytest.raises(TypeError, match=\"there are unused parameters\"):\n        read(fp, format=\"ascii.html\")\n\n    # unless mismatched are moved to meta\n    got = read(fp, format=\"ascii.html\", move_to_meta=True)\n    assert got == cosmo\n    # assert got.meta[\"extra\"] == \"will error\" # metadata read not implemented\n"], "sample_1200": ["def test_unit_system():\n    # Test UnitSystem class\n    us = UnitSystem((meter, second), name=\"CustomUnitSystem\")\n    assert us.name == \"CustomUnitSystem\"\n    assert us.dim == 2\n    assert us.is_consistent\n\n    # Test extend method\n    new_us = us.extend((kilogram,))\n    assert new_us.name == \"\"\n    assert new_us.dim == 3\n    assert new_us.is_consistent\n\n    # Test get_dimension_system method\n    assert us.get_dimension_system() is not None\n\n    # Test get_quantity_dimension method\n    assert us.get_quantity_dimension(meter) == length\n\n    # Test get_quantity_scale_factor method\n    assert us.get_quantity_scale_factor(meter) == 1\n\n    # Test get_unit_system method\n    assert UnitSystem.get_unit_system(\"SI\") is not None\n\n    # Test get_default_unit_system method\n    assert UnitSystem.get_default_unit_system() is not None\n\n    # Test derived_units property\n    assert us.derived_units == {}\n\n    # Test get_units_non_prefixed method\n    assert us.get_units_non_prefixed() == {meter, second}\n"], "sample_332": ["def test_formset_absolute_max_with_zero_max_num(self):\n    data = {\n        'form-TOTAL_FORMS': '1001',\n        'form-INITIAL_FORMS': '0',\n        'form-MAX_NUM_FORMS': '0',\n    }\n    LimitedFavoriteDrinksFormSet = formset_factory(\n        FavoriteDrinkForm,\n        max_num=0,\n        absolute_max=1000,\n    )\n    formset = LimitedFavoriteDrinksFormSet(data=data)\n    self.assertIs(formset.is_valid(), False)\n    self.assertEqual(len(formset.forms), 1000)\n    self.assertEqual(\n        formset.non_form_errors(),\n        ['Please submit at most 0 forms.'],\n    )\n"], "sample_759": ["def test_ordinal_encoder_unsorted_categories():\n    X = np.array([['a', 'b']], dtype=object).T\n\n    enc = OrdinalEncoder(categories=[['b', 'a', 'c']])\n    exp = np.array([[1.], [0.]])\n    assert_array_equal(enc.fit(X).transform(X), exp)\n    assert_array_equal(enc.fit_transform(X), exp)\n    assert enc.categories_[0].tolist() == ['b', 'a', 'c']\n    assert np.issubdtype(enc.categories_[0].dtype, np.object_)\n\n    # unsorted passed categories still raise for numerical values\n    X = np.array([[1, 2]]).T\n    enc = OrdinalEncoder(categories=[[2, 1, 3]])\n    msg = 'Unsorted categories are not supported'\n    with pytest.raises(ValueError, match=msg):\n        enc.fit_transform(X)\n"], "sample_333": ["def test_order_fields_with_empty_list(self):\n    class TestForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n        field3 = CharField()\n        field_order = []\n\n    p = TestForm()\n    self.assertEqual(list(p.fields), ['field1', 'field2', 'field3'])\n"], "sample_344": ["def test_get_related_models_tuples(self):\n    \"\"\"\n    Tests get_related_models_tuples returns the correct related models.\n    \"\"\"\n    new_apps = Apps()\n\n    class A(models.Model):\n        class Meta:\n            app_label = \"migrations\"\n            apps = new_apps\n\n    class B(models.Model):\n        a = models.ForeignKey(A, models.CASCADE)\n\n        class Meta:\n            app_label = \"migrations\"\n            apps = new_apps\n\n    class C(models.Model):\n        b = models.ForeignKey(B, models.CASCADE)\n\n        class Meta:\n            app_label = \"migrations\"\n            apps = new_apps\n\n    project_state = ProjectState()\n    project_state.add_model(ModelState.from_model(A))\n    project_state.add_model(ModelState.from_model(B))\n    project_state.add_model(ModelState.from_model(C))\n\n    self.assertEqual(\n        get_related_models_tuples(A),\n        {('migrations', 'b'), ('migrations', 'c')},\n    )\n    self.assertEqual(\n        get_related_models_tuples(B),\n        {('migrations', 'a'), ('migrations', 'c')},\n    )\n    self.assertEqual(\n        get_related_models_tuples(C),\n        {('migrations', 'a'), ('migrations', 'b')},\n    )\n"], "sample_1122": ["def test_polar_lift():\n    x = Symbol('x')\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == exp_polar(0)\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(-I*pi/2)\n    assert polar_lift(-I) == exp_polar(I*pi/2)\n    assert polar_lift(1 + I) == polar_lift(1 + I)\n    assert polar_lift(x) == polar_lift(x)\n    assert polar_lift(x*I) == polar_lift(x*I)\n    assert polar_lift(x + I) == polar_lift(x + I)\n    assert polar_lift(x*I + I) == polar_lift(x*I + I)\n    assert polar_lift(x + I*x) == polar_lift(x*(1 + I))\n    assert polar_lift(x*I + I*x) == polar_lift(x*(I + I))\n    assert polar_lift(x + I*x**2) == polar_lift(x + I*x**2)\n    assert polar_lift(x*I + I*x**2) == polar_lift(x*I + I*x**2)\n    assert polar_lift(x + I*x**3) == polar_lift(x + I*x**3)\n    assert polar_lift(x*I + I*x**3) == polar_lift(x*I + I*x**3)\n    assert polar_lift(x + I*x**4) == polar_lift(x*(1 + I*x**3))\n    assert polar_lift(x*I + I*x**4) == polar_lift(x*(I + I*x**3))\n    assert polar_lift(x + I*x**5) == polar_lift(x + I*x**5)\n    assert polar_lift(x*I + I*x**5) == polar_lift(x*I + I*x**5)\n    assert polar_lift(x + I*x**6) == polar_lift(x*(1 + I*x**5))\n    assert polar_lift(x*I + I*x**6) == polar_lift(x*(I + I*x**5))\n    assert polar_lift(x + I*x**7) == polar_lift(x + I*x**7)\n    assert polar_lift(x*I + I*x**7) == polar_lift(x*I + I*x**7)\n    assert polar_lift(x + I*x**8) == polar_lift(x*(1 + I*x**7))\n    assert polar_lift(x*I + I*x**8) == polar_lift(x*(I + I*x**"], "sample_561": ["def test_marker_fillstyle_half():\n    marker_style = markers.MarkerStyle(marker='o', fillstyle='left')\n    assert marker_style.get_fillstyle() == 'left'\n    assert marker_style.is_filled()\n\n    marker_style = markers.MarkerStyle(marker='o', fillstyle='right')\n    assert marker_style.get_fillstyle() == 'right'\n    assert marker_style.is_filled()\n\n    marker_style = markers.MarkerStyle(marker='o', fillstyle='top')\n    assert marker_style.get_fillstyle() == 'top'\n    assert marker_style.is_filled()\n\n    marker_style = markers.MarkerStyle(marker='o', fillstyle='bottom')\n    assert marker_style.get_fillstyle() == 'bottom'\n    assert marker_style.is_filled()\n"], "sample_1010": ["def test_latex_DiagramGrid():\n    from sympy.categories import Object, NamedMorphism, Diagram, DiagramGrid\n    A = Object(\"A\")\n    B = Object(\"B\")\n    C = Object(\"C\")\n    f = NamedMorphism(A, B, \"f\")\n    g = NamedMorphism(B, C, \"g\")\n    d = Diagram([f, g])\n    grid = DiagramGrid(d)\n    assert latex(grid) == \"\\\\begin{array}{cc}\\nA & B \\\\\\\\\\n & C \\n\\\\end{array}\\n\"\n"], "sample_562": ["def test_line2d_set_data():\n    fig, ax = plt.subplots()\n    line, = ax.plot([1, 2, 3], [1, 2, 3])\n    line.set_data([4, 5, 6], [4, 5, 6])\n    assert_array_equal(line.get_xdata(), [4, 5, 6])\n    assert_array_equal(line.get_ydata(), [4, 5, 6])\n    line.set_data([7, 8, 9])\n    assert_array_equal(line.get_xdata(), [7, 8, 9])\n    assert_array_equal(line.get_ydata(), [7, 8, 9])\n"], "sample_1096": ["def test_IndexedBase_strides():\n    i, j = symbols('i j', integer=True)\n    A = IndexedBase('A', strides=(1, 2))\n    assert A.strides == (1, 2)\n    assert A[i, j].strides == (1, 2)\n    assert A.offset == 0\n    assert A[i, j].offset == 0\n\n    B = IndexedBase('B', strides=(1, 2), offset=3)\n    assert B.strides == (1, 2)\n    assert B[i, j].strides == (1, 2)\n    assert B.offset == 3\n    assert B[i, j].offset == 3\n\n    C = IndexedBase('C', strides='C')\n    assert C.strides == 'C'\n    assert C[i, j].strides == 'C'\n    assert C.offset == 0\n    assert C[i, j].offset == 0\n\n    D = IndexedBase('D', strides='F')\n    assert D.strides == 'F'\n    assert D[i, j].strides == 'F'\n    assert D.offset == 0\n    assert D[i, j].offset == 0\n"], "sample_607": ["def test_get_backend():\n    backend = plugins.get_backend(\"dummy\")\n    assert isinstance(backend, DummyBackendEntrypointArgs)\n\n    backend = plugins.get_backend(DummyBackendEntrypointArgs)\n    assert isinstance(backend, DummyBackendEntrypointArgs)\n\n    with pytest.raises(ValueError):\n        plugins.get_backend(\"non-existent-backend\")\n\n    with pytest.raises(TypeError):\n        plugins.get_backend(123)\n"], "sample_1112": ["def test_is_palindromic():\n    assert is_palindromic(121)\n    assert is_palindromic(12321)\n    assert is_palindromic(1234321)\n    assert not is_palindromic(123456)\n    assert is_palindromic(88, 10)\n    assert not is_palindromic(88, 8)\n    assert is_palindromic(0o121, 8)\n    assert not is_palindromic(0o121, 10)\n    assert is_palindromic(121, 8)\n    assert is_palindromic(121, 10)\n    assert is_palindromic(-121, 10)\n    assert is_palindromic(-121, 8)\n"], "sample_592": ["def test_inline_variable_array_repr(self):\n    # test in-memory array\n    var = xr.Variable((\"x\", \"y\"), np.arange(100).reshape(10, 10))\n    actual = formatting.inline_variable_array_repr(var, 80)\n    expected = formatting.format_array_flat(var, 80)\n    assert actual == expected\n\n    # test dask array\n    import dask.array as da\n    var = xr.Variable((\"x\", \"y\"), da.from_array(np.arange(100).reshape(10, 10), chunks=(5, 5)))\n    actual = formatting.inline_variable_array_repr(var, 80)\n    expected = formatting.inline_dask_repr(var.data)\n    assert actual == expected\n\n    # test sparse array\n    import sparse\n    var = xr.Variable((\"x\", \"y\"), sparse.COO(np.arange(100).reshape(10, 10)))\n    actual = formatting.inline_variable_array_repr(var, 80)\n    expected = formatting.inline_sparse_repr(var.data)\n    assert actual == expected\n\n    # test __array_function__ array\n    class ArrayLike:\n            return np.arange(100).reshape(10, 10)\n\n    var = xr.Variable((\"x\", \"y\"), ArrayLike())\n    actual = formatting.inline_variable_array_repr(var, 80)\n    expected = formatting.maybe_truncate(repr(var._data).replace(\"\\n\", \" \"), 80)\n    assert actual == expected\n\n    # test internal xarray array type\n    var = xr.Variable((\"x\", \"y\"), np.arange(100000).reshape(100, 100))\n    actual = formatting.inline_variable_array_repr(var, 80)\n    expected = \"[100000 values with dtype=int64]\"\n    assert actual == expected\n"], "sample_1121": ["def test_Mul_as_coeff_Mul():\n    # issue 5524.  These should all be (1, self)\n    assert (x + 1).as_coeff_Mul() == (1, x + 1)\n    assert (x + 2).as_coeff_Mul() == (1, x + 2)\n    assert (x + 3).as_coeff_Mul() == (1, x + 3)\n\n    assert (x - 1).as_coeff_Mul() == (1, x - 1)\n    assert (x - 2).as_coeff_Mul() == (1, x - 2)\n    assert (x - 3).as_coeff_Mul() == (1, x - 3)\n\n    n = Symbol('n', integer=True)\n    assert (n + 1).as_coeff_Mul() == (1, n + 1)\n    assert (n + 2).as_coeff_Mul() == (1, n + 2)\n    assert (n + 3).as_coeff_Mul() == (1, n + 3)\n\n    assert (n - 1).as_coeff_Mul() == (1, n - 1)\n    assert (n - 2).as_coeff_Mul() == (1, n - 2)\n    assert (n - 3).as_coeff_Mul() == (1, n - 3)\n"], "sample_97": ["    def test_empty_paths(self):\n        self.assertEqual(autoreload.common_roots(()), ())\n"], "sample_72": ["def test_register_serializer(self):\n    Serializer.register(type, ComplexSerializer)\n    try:\n        string, imports = MigrationWriter.serialize(type)\n        self.assertEqual(string, \"complex(<class 'type'>)\")\n        self.assertEqual(imports, set())\n    finally:\n        Serializer.unregister(type)\n"], "sample_574": ["    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n"], "sample_617": ["def test_cross() -> None:\n    # test cross product with 3 dimensions\n    a = xr.DataArray([1, 2, 3])\n    b = xr.DataArray([4, 5, 6])\n    expected = xr.DataArray([-3, 6, -3])\n    actual = xr.cross(a, b, dim=\"dim_0\")\n    assert_identical(expected, actual)\n\n    # test cross product with 2 dimensions, returns in the perpendicular direction\n    a = xr.DataArray([1, 2])\n    b = xr.DataArray([4, 5])\n    expected = xr.DataArray(-3)\n    actual = xr.cross(a, b, dim=\"dim_0\")\n    assert_identical(expected, actual)\n\n    # test cross product with 3 dimensions but zeros at the last axis yields the same results as with 2 dimensions\n    a = xr.DataArray([1, 2, 0])\n    b = xr.DataArray([4, 5, 0])\n    expected = xr.DataArray([0, 0, -3])\n    actual = xr.cross(a, b, dim=\"dim_0\")\n    assert_identical(expected, actual)\n\n    # test one vector with dimension 2\n    a = xr.DataArray(\n        [1, 2],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\"])),\n    )\n    b = xr.DataArray(\n        [4, 5, 6],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    expected = xr.DataArray([12, -6, -3], dims=[\"cartesian\"])\n    expected.coords[\"cartesian\"] = [\"x\", \"y\", \"z\"]\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(expected, actual)\n\n    # test one vector with dimension 2 but coords in other positions\n    a = xr.DataArray(\n        [1, 2],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"z\"])),\n    )\n    b = xr.DataArray(\n        [4, 5, 6],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    expected = xr.DataArray([-"], "sample_157": ["    def test_serialize_db_to_string(self, mocked_migrate, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=True)\n            self.assertIsNotNone(creation.connection._test_serialized_contents)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_56": ["def test_check_ordering_random(self):\n    class SongAdmin(admin.ModelAdmin):\n        ordering = ['?', 'title']\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'ordering' has the random ordering marker '?', \"\n            \"but contains other fields as well.\",\n            obj=SongAdmin,\n            id='admin.E032',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_677": ["def test_matcher_function(expr: str, matcher: Callable[[str], bool], expected: bool) -> None:\n    assert evaluate(expr, matcher) is expected\n"], "sample_71": ["def test_edge_cases(self):\n    # Test with very large decimal positions\n    self.assertEqual(nformat(1234, '.', decimal_pos=100), '1234.00')\n    self.assertEqual(nformat(Decimal('1234'), '.', decimal_pos=100), '1234.00')\n\n    # Test with very large grouping values\n    self.assertEqual(nformat(1234, '.', grouping=100, thousand_sep=','), '1234')\n    self.assertEqual(nformat(Decimal('1234'), '.', grouping=100, thousand_sep=','), '1234')\n\n    # Test with negative decimal positions\n    with self.assertRaises(ValueError):\n        nformat(1234, '.', decimal_pos=-1)\n    with self.assertRaises(ValueError):\n        nformat(Decimal('1234'), '.', decimal_pos=-1)\n\n    # Test with negative grouping values\n    with self.assertRaises(ValueError):\n        nformat(1234, '.', grouping=-1, thousand_sep=',')\n    with self.assertRaises(ValueError):\n        nformat(Decimal('1234'), '.', grouping=-1, thousand_sep=',')\n\n    # Test with non-integer grouping values\n    with self.assertRaises(TypeError):\n        nformat(1234, '.', grouping=1.5, thousand_sep=',')\n    with self.assertRaises(TypeError):\n        nformat(Decimal('1234'), '.', grouping=1.5, thousand_sep=',')\n\n    # Test with non-string thousand separator\n    with self.assertRaises(TypeError):\n        nformat(1234, '.', grouping=3, thousand_sep=123)\n    with self.assertRaises(TypeError):\n        nformat(Decimal('1234'), '.', grouping=3, thousand_sep=123)\n"], "sample_833": ["def test_logistic_regression_path_multinomial():\n    # Test that logistic_regression_path with multi_class='multinomial' returns\n    # the same coefficients as LogisticRegression with multi_class='multinomial'\n    X, y = make_classification(n_samples=200, n_classes=3, n_informative=2,\n                               n_redundant=0, n_clusters_per_class=1,\n                               random_state=0, n_features=2)\n    Cs = [.00001, 1, 10000]\n    coefs, _, _ = _logistic_regression_path(X, y, penalty='l1', Cs=Cs,\n                                            solver='saga', random_state=0,\n                                            multi_class='multinomial')\n\n    for C in Cs:\n        lr = LogisticRegression(penalty='l1', C=C, solver='saga',\n                                random_state=0, multi_class='multinomial')\n        lr.fit(X, y)\n        assert_array_almost_equal(coefs[Cs.index(C)], lr.coef_)\n"], "sample_753": ["def test_logistic_regression_path_multiclass():\n    # Test logistic regression path for multiclass problems\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=10,\n                               n_classes=3, random_state=0)\n    Cs = [1.0, 0.1, 0.01]\n    solvers = ['lbfgs', 'newton-cg', 'sag', 'saga']\n    for solver in solvers:\n        coefs, Cs, n_iter = logistic_regression_path(\n            X, y, Cs=Cs, fit_intercept=False, tol=1e-6, solver=solver,\n            multi_class='multinomial', random_state=42)\n        assert_array_equal(coefs[0].shape, (3, 20))\n        assert_array_equal(coefs[1].shape, (3, 20))\n        assert_array_equal(coefs[2].shape, (3, 20))\n"], "sample_664": ["def test_deprecation_warnings(warning, expected_message):\n    with pytest.warns(warning) as record:\n        warning.warn(DeprecationWarning())\n    assert len(record) == 1\n    assert record[0].message.args[0] == expected_message\n"], "sample_968": ["def test_python_domain_canonical_definition_overrides_with_multiple_canonicals(app, warning):\n    text = (\".. py:class:: io.StringIO\\n\"\n            \"   :canonical: _io.StringIO\\n\"\n            \".. py:class:: _io.StringIO\\n\"\n            \"   :canonical: io.StringIO\\n\")\n    restructuredtext.parse(app, text)\n    assert warning.getvalue() != \"\"\n\n    domain = app.env.get_domain('py')\n    assert domain.objects['_io.StringIO'] == ('index', 'id0', 'class', False)\n    assert domain.objects['io.StringIO'] == ('index', 'id1', 'class', False)\n"], "sample_326": ["def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            'Search for google.com/?q=! and see.',\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>! and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt! and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>! and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt, and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>, and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt. and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>. and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt; and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>; and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt: and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>: and see.'\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_746": ["def test_brier_score_loss():\n    # Test Brier score loss\n    y_true = np.array([0, 1, 1, 0])\n    y_true_prob = np.array([0, 1, 1, 0])\n    y_pred_prob = np.array([0.2, 0.7, 0.8, 0.4])\n\n    assert_almost_equal(brier_score_loss(y_true, y_pred_prob), 0.145)\n    assert_almost_equal(brier_score_loss(y_true, y_true_prob), 0)\n\n    # Test Brier score loss with sample weights\n    sample_weight = np.array([0.1, 0.2, 0.3, 0.4])\n    assert_almost_equal(brier_score_loss(y_true, y_pred_prob, sample_weight), 0.173)\n\n    # Test Brier score loss with pos_label\n    assert_almost_equal(brier_score_loss(y_true, y_pred_prob, pos_label=0), 0.145)\n    assert_almost_equal(brier_score_loss(y_true, y_pred_prob, pos_label=1), 0.145)\n\n    # Test Brier score loss with invalid input\n    assert_raises(ValueError, brier_score_loss, y_true, y_pred_prob > 0.5)\n    assert_raises(ValueError, brier_score_loss, y_true, y_pred_prob, pos_label=2)\n"], "sample_104": ["    def test_hash_key(self):\n        name = \"cached/styles.css\"\n        cache_key = storage.staticfiles_storage.hash_key(name)\n        self.assertEqual(cache_key, 'staticfiles:5e0040571e1a')\n"], "sample_91": ["def test_permission_denied(self):\n    \"The permission_denied view raises a 403 status\"\n    request = self.request_factory.get('/')\n    exception = Exception('Test permission denied exception')\n    response = permission_denied(request, exception)\n    self.assertContains(response, b'<h1>403 Forbidden</h1>', status_code=403)\n    self.assertContains(response, str(exception).encode('utf-8'), status_code=403)\n"], "sample_77": ["def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            'Search for google.com/?q=! and see.',\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>! and see.'\n        ),\n        (\n            'Search for google.com/?q=!. and see.',\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>!. and see.'\n        ),\n        (\n            'Search for google.com/?q=!? and see.',\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>!? and see.'\n        ),\n        (\n            'Search for google.com/?q=!. and see.',\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>!. and see.'\n        ),\n        (\n            'Search for google.com/?q=!? and see.',\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>!? and see.'\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_477": ["def truncatechars_html(value, arg):\n    \"\"\"\n    Truncate HTML after `arg` number of chars.\n    Preserve newlines in the HTML.\n    \"\"\"\n    try:\n        length = int(arg)\n    except ValueError:  # invalid literal for int()\n        return value  # Fail silently.\n    return Truncator(value).chars(length, html=True)\n\n"], "sample_301": ["    def test_empty_paths(self):\n        self.assertEqual(autoreload.common_roots(()), ())\n"], "sample_669": ["def test_capturing_and_logging_fundamentals_with_keyboardinterrupt(testdir):\n    # here we check a fundamental feature\n    p = testdir.makepyfile(\n        \"\"\"\n        import sys, os\n        import py, logging\n        from _pytest import capture\n        cap = capture.MultiCapture(out=False, in_=False,\n                                     Capture=capture.SysCapture)\n        cap.start_capturing()\n\n        logging.warning(\"hello1\")\n        outerr = cap.readouterr()\n        print(\"suspend, captured %%s\" %%(outerr,))\n        logging.warning(\"hello2\")\n\n        cap.pop_outerr_to_orig()\n        logging.warning(\"hello3\")\n\n        outerr = cap.readouterr()\n        print(\"suspend2, captured %%s\" %% (outerr,))\n        raise KeyboardInterrupt()\n    \"\"\"\n    )\n    result = testdir.runpython(p)\n    result.stdout.fnmatch_lines(\n        \"\"\"\n        suspend, captured*hello1*\n        suspend2, captured*WARNING:root:hello3*\n    \"\"\"\n    )\n    result.stderr.fnmatch_lines(\n        \"\"\"\n        WARNING:root:hello2\n    \"\"\"\n    )\n    assert \"atexit\" not in result.stderr.str()\n"], "sample_991": ["def test_doit_with_hints():\n    i = Symbol(\"i\", integer=True)\n    n = Symbol(\"n\", integer=True)\n    p = Product(i**2, (i, 1, n))\n    assert p.doit(deep=False) == Product(i**2, (i, 1, n))\n    assert p.doit(deep=True) == factorial(n)**2\n"], "sample_1198": ["def test_mathematica_parser():\n    parser = MathematicaParser()\n\n    # Test parsing of Mathematica expressions with additional translations\n    additional_translations = {\n        'MyFunc[x]': 'my_func(x)',\n        'MyFunc[x, y]': 'my_func(x, y)',\n    }\n    parser = MathematicaParser(additional_translations)\n    assert parser.parse('MyFunc[x]') == sympify('my_func(x)')\n    assert parser.parse('MyFunc[x, y]') == sympify('my_func(x, y)')\n\n    # Test parsing of Mathematica expressions with invalid syntax\n    raises(SyntaxError, lambda: parser.parse('Invalid['))\n    raises(SyntaxError, lambda: parser.parse('Invalid]'))\n    raises(SyntaxError, lambda: parser.parse('Invalid('))\n    raises(SyntaxError, lambda: parser.parse('Invalid)'))\n\n    # Test parsing of Mathematica expressions with missing arguments\n    raises(SyntaxError, lambda: parser.parse('Func[7,5,3]'))\n    raises(SyntaxError, lambda: parser.parse('F[7,5,3]'))\n\n    # Test parsing of Mathematica expressions with unsupported functions\n    raises(ValueError, lambda: parser.parse('UnsupportedFunc[x]'))\n\n    # Test parsing of Mathematica expressions with unsupported syntax\n    raises(ValueError, lambda: parser.parse('{x, y, z}'))\n"], "sample_51": ["    def test_parse_iso8601_duration(self):\n        test_values = (\n            ('P1D', timedelta(days=1)),\n            ('PT1H', timedelta(hours=1)),\n            ('PT1M', timedelta(minutes=1)),\n            ('PT1S', timedelta(seconds=1)),\n            ('P1DT1H1M1S', timedelta(days=1, hours=1, minutes=1, seconds=1)),\n            ('P-1DT-1H-1M-1S', timedelta(days=-1, hours=-1, minutes=-1, seconds=-1)),\n            ('PT1.5S', timedelta(seconds=1.5)),\n            ('PT0.5S', timedelta(seconds=0.5)),\n            ('PT0.05S', timedelta(seconds=0.05)),\n            ('PT0.005S', timedelta(seconds=0.005)),\n            ('PT0.0005S', timedelta(seconds=0.0005)),\n            ('PT0.00005S', timedelta(seconds=0.00005)),\n            ('PT0.000005S', timedelta(seconds=0.000005)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_449": ["def test_broken_pipe_error(self):\n    request = WSGIRequest(self.request_factory.get(\"/\").environ)\n    request.makefile = lambda *args, **kwargs: BytesIO()\n    handler = WSGIRequestHandler(request, \"192.168.0.2\", None)\n\n    with self.assertLogs(\"django.server\", \"INFO\") as cm:\n        try:\n            raise BrokenPipeError\n        except BrokenPipeError:\n            handler.log_message(\"GET %s %s\", \"A\", \"500\")\n\n    self.assertIn(\"Broken pipe from 192.168.0.2\", cm.output[0])\n\n    with self.assertLogs(\"django.server\", \"INFO\") as cm:\n        try:\n            raise ConnectionAbortedError\n        except ConnectionAbortedError:\n            handler.log_message(\"GET %s %s\", \"A\", \"500\")\n\n    self.assertIn(\"Broken pipe from 192.168.0.2\", cm.output[0])\n\n    with self.assertLogs(\"django.server\", \"INFO\") as cm:\n        try:\n            raise ConnectionResetError\n        except ConnectionResetError:\n            handler.log_message(\"GET %s %s\", \"A\", \"500\")\n\n    self.assertIn(\"Broken pipe from 192.168.0.2\", cm.output[0])\n"], "sample_355": ["    def test_get_by_natural_key(self):\n        \"\"\"\n        Test that get_by_natural_key returns the correct permission.\n        \"\"\"\n        content_type = ContentType.objects.get_for_model(Group)\n        permission = Permission.objects.create(name='test', content_type=content_type, codename='test')\n        self.assertEqual(Permission.objects.get_by_natural_key('test', content_type.app_label, content_type.model), permission)\n"], "sample_963": ["def test_get_type_hints():\n        pass\n\n    assert get_type_hints(func) == {'a': int, 'b': str, 'return': None}\n\n    class MyClass:\n            pass\n\n    assert get_type_hints(MyClass) == {'a': int, 'b': str, 'return': None}\n\n    class MyClassWithNoAnnotations:\n            pass\n\n    assert get_type_hints(MyClassWithNoAnnotations) == {}\n\n    class MyClassWithBrokenAnnotations:\n            pass\n\n    assert get_type_hints(MyClassWithBrokenAnnotations) == {}\n\n    class MyClassWithForwardRef:\n            pass\n\n    assert get_type_hints(MyClassWithForwardRef) == {'a': 'MyClassWithForwardRef', 'return': None}\n"], "sample_159": ["    def test_builtin_permission_name_length(self):\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 250\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most 244 \"\n                \"characters for its builtin permission names to be at most 255 characters.\",\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 245\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 246\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most 245 \"\n                \"characters for its builtin permission names to be at most 255 characters.\",\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n"], "sample_20": ["def test_read_table_fits_with_memmap_and_mask_invalid(tmp_path):\n    filename = tmp_path / \"test_read_table_fits_with_memmap_and_mask_invalid.fits\"\n    t1 = Table(np.array([1, 2, np.nan, 4]))\n    t1.write(filename, overwrite=True)\n    t2 = Table.read(filename, memmap=True, mask_invalid=True)\n    assert np.all(t2.mask == [False, False, True, False])\n    assert np.all(t2.data == [1, 2, np.nan, 4])\n"], "sample_213": ["    def test_field_file_equality(self):\n        file1 = FieldFile(None, None, 'file1.txt')\n        file2 = FieldFile(None, None, 'file1.txt')\n        self.assertEqual(file1, file2)\n\n        file3 = FieldFile(None, None, 'file2.txt')\n        self.assertNotEqual(file1, file3)\n\n        self.assertNotEqual(file1, 'file1.txt')\n"], "sample_249": ["    def test_create_test_db(self, mocked_create_test_db):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            creation.create_test_db(verbosity=1, autoclobber=True, serialize=True, keepdb=False)\n            mocked_create_test_db.assert_called_once()\n            self.assertEqual(test_connection.settings_dict['NAME'], creation._get_test_db_name())\n            self.assertIsNotNone(creation.connection._test_serialized_contents)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_389": ["    def test_get_host(self):\n        request = HttpRequest()\n        request.META = {\"HTTP_HOST\": \"example.com\"}\n        self.assertEqual(request.get_host(), \"example.com\")\n"], "sample_658": ["def test_doctest_report_only_first_failure_multiple_failures(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            '''\n            >>> foo()\n               a  b\n            0  1  4\n            1  2  4\n            2  3  6\n            '''\n            print('   a  b\\\\n'\n                  '0  1  4\\\\n'\n                  '1  2  5\\\\n'\n                  '2  3  7')\n        \"\"\"\n    )\n    result = testdir.runpytest(\"--doctest-modules\", \"--doctest-report\", \"only_first_failure\")\n    result.stdout.fnmatch_lines(\n        [\n            \"Expected:\",\n            \"       a  b\",\n            \"    0  1  4\",\n            \"    1  2  4\",\n            \"    2  3  6\",\n            \"Got:\",\n            \"       a  b\",\n            \"    0  1  4\",\n            \"    1  2  5\",\n            \"    2  3  7\",\n        ]\n    )\n"], "sample_583": ["def test_explicit_indexing_adapter():\n    array = np.arange(10, dtype=np.int64)\n    key = indexing.BasicIndexer((slice(1, 5),))\n    result = indexing.explicit_indexing_adapter(key, array.shape,\n                                               indexing.IndexingSupport.BASIC,\n                                               array.__getitem__)\n    np.testing.assert_array_equal(result, array[1:5])\n\n    key = indexing.OuterIndexer((np.array([1, 3, 5]),))\n    result = indexing.explicit_indexing_adapter(key, array.shape,\n                                               indexing.IndexingSupport.OUTER,\n                                               array.__getitem__)\n    np.testing.assert_array_equal(result, array[[1, 3, 5]])\n\n    key = indexing.VectorizedIndexer((np.array([1, 3, 5]),))\n    result = indexing.explicit_indexing_adapter(key, array.shape,\n                                               indexing.IndexingSupport.VECTORIZED,\n                                               array.__getitem__)\n    np.testing.assert_array_equal(result, array[[1, 3, 5]])\n"], "sample_131": ["    def test_serialize_db_to_string(self, mocked_migrate, mocked_ensure_connection):\n        creation = connection.creation_class(connection)\n        test_connection = self.get_connection_copy()\n        test_connection.settings_dict['TEST_NON_SERIALIZED_APPS'] = ['auth']\n        creation = BaseDatabaseCreation(test_connection)\n        with mock.patch.object(creation, '_get_test_db_name', return_value='test_database'):\n            creation.create_test_db(verbosity=0, autoclobber=True, serialize=True)\n        self.assertIsNotNone(creation.connection._test_serialized_contents)\n"], "sample_1123": ["def test_CondSet_properties():\n    c = ConditionSet(x, x < 1, Interval(0, 2))\n    assert c.sym == x\n    assert c.condition == (x < 1)\n    assert c.base_set == Interval(0, 2)\n\n    c = ConditionSet(x, x < 1, FiniteSet(0, 1, 2))\n    assert c.sym == x\n    assert c.condition == (x < 1)\n    assert c.base_set == FiniteSet(0, 1, 2)\n\n    c = ConditionSet(x, x < 1, S.Reals)\n    assert c.sym == x\n    assert c.condition == (x < 1)\n    assert c.base_set == S.Reals\n"], "sample_739": ["def test_label_binarize_multilabel_indicator():\n    y = [[0, 1, 0], [1, 1, 1], [0, 0, 0]]\n    classes = [0, 1, 2]\n    pos_label = 2\n    neg_label = 0\n    expected = pos_label * np.array(y)\n    y_sparse = [sparse_matrix(y)\n                for sparse_matrix in [coo_matrix, csc_matrix, csr_matrix,\n                                      dok_matrix, lil_matrix]]\n\n    for y in [y] + y_sparse:\n        yield (check_binarized_results, y, classes, pos_label, neg_label,\n               expected)\n\n    assert_raises(ValueError, label_binarize, y, classes, neg_label=-1,\n                  pos_label=pos_label, sparse_output=True)\n"], "sample_612": ["def test_groupby_map_with_kwargs() -> None:\n        return arg1 + arg2 + arg3\n\n    array = xr.DataArray([1, 1, 1], [(\"x\", [1, 2, 3])])\n    expected = xr.DataArray([3, 3, 3], [(\"x\", [1, 2, 3])])\n    actual = array.groupby(\"x\").map(func, arg1=1, arg3=1)\n    assert_identical(expected, actual)\n"], "sample_1137": ["def test_check_dimensions():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    w = Quantity(\"w\")\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    assert check_dimensions(u + v) == u + v\n    assert check_dimensions(u - v) == u - v\n    assert check_dimensions(u * v) == u * v\n    assert check_dimensions(u / v) == u / v\n\n    raises(ValueError, lambda: check_dimensions(u + w))\n    raises(ValueError, lambda: check_dimensions(u - w))\n    raises(ValueError, lambda: check_dimensions(u + 1))\n    raises(ValueError, lambda: check_dimensions(u - 1))\n    raises(ValueError, lambda: check_dimensions(1 - exp(u / w)))\n"], "sample_1165": ["def test_quaternion_edge_cases():\n    q1 = Quaternion(0, 0, 0, 0)\n    q2 = Quaternion(1, 0, 0, 0)\n    q3 = Quaternion(0, 1, 0, 0)\n    q4 = Quaternion(0, 0, 1, 0)\n    q5 = Quaternion(0, 0, 0, 1)\n\n    assert q1.norm() == 0\n    assert q2.norm() == 1\n    assert q3.norm() == 1\n    assert q4.norm() == 1\n    assert q5.norm() == 1\n\n    assert q1.normalize() == Quaternion(0, 0, 0, 0)\n    assert q2.normalize() == Quaternion(1, 0, 0, 0)\n    assert q3.normalize() == Quaternion(0, 1, 0, 0)\n    assert q4.normalize() == Quaternion(0, 0, 1, 0)\n    assert q5.normalize() == Quaternion(0, 0, 0, 1)\n\n    assert q1.inverse() == Quaternion(0, 0, 0, 0)\n    raises(ValueError, lambda: q1.inverse())\n\n    assert q2.inverse() == Quaternion(1, 0, 0, 0)\n    assert q3.inverse() == Quaternion(0, -1, 0, 0)\n    assert q4.inverse() == Quaternion(0, 0, -1, 0)\n    assert q5.inverse() == Quaternion(0, 0, 0, -1)\n\n    assert q1.exp() == Quaternion(1, 0, 0, 0)\n    assert q2.exp() == Quaternion(E, 0, 0, 0)\n    assert q3.exp() == Quaternion(cos(1), sin(1), 0, 0)\n    assert q4.exp() == Quaternion(cos(1), 0, sin(1), 0)\n    assert q5.exp() == Quaternion(cos(1), 0, 0, sin(1))\n\n    assert q1._ln() == Quaternion(0, 0, 0, 0)\n    assert q2._ln() == Quaternion(0, 0, 0, 0)\n    assert q3._ln() == Quaternion("], "sample_653": ["def test_log_cli_level_change(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_handler.level == logging.INFO\n            logging.getLogger('catchlog').debug(\"This log message won't be shown\")\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            plugin.log_cli_handler.setLevel(logging.DEBUG)\n            logging.getLogger('catchlog').debug(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n    \"\"\"\n    )\n\n    result = testdir.runpytest(\"-s\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_log_cli_level_change.py* This log message will be shown\",\n            \"*test_log_cli_level_change.py* This log message will be shown\",\n            \"PASSED\",  # 'PASSED' on its own line because the log message prints a new line\n        ]\n    )\n    assert \"This log message won't be shown\" not in result.stdout.str()\n\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n"], "sample_434": ["    def test_get_context_data(self):\n        class TestTemplateView(TemplateView):\n            extra_context = {\"foo\": \"bar\"}\n\n        view = TestTemplateView()\n        context = view.get_context_data(baz=\"qux\")\n        self.assertEqual(context, {\"view\": view, \"foo\": \"bar\", \"baz\": \"qux\"})\n"], "sample_517": ["def test_text_repr_with_non_ascii():\n    # smoketest to make sure text repr doesn't error for non-ascii characters\n    plt.plot(['A', 'B'], [1, 2])\n    repr(plt.text(['A'], 0.5, 'Boo'))\n    repr(plt.text(['A'], 0.5, 'Boo\u20ac'))\n"], "sample_801": ["def test_clone():\n    # Test cloning of estimators\n    lr = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                            intercept_scaling=1, l1_ratio=None, max_iter=100,\n                            multi_class='warn', n_jobs=None, penalty='l2',\n                            random_state=None, solver='warn', tol=0.0001, verbose=0,\n                            warm_start=False)\n\n    cloned_lr = clone(lr)\n    assert cloned_lr.__dict__ == lr.__dict__\n\n    # Test cloning of a list of estimators\n    estimators = [LogisticRegression(), StandardScaler()]\n    cloned_estimators = clone(estimators)\n    for est, cloned_est in zip(estimators, cloned_estimators):\n        assert est.__dict__ == cloned_est.__dict__\n\n    # Test cloning of a non-estimator object\n    non_est = object()\n    cloned_non_est = clone(non_est, safe=False)\n    assert cloned_non_est is not non_est\n\n    # Test cloning of a non-estimator object with safe=True\n    try:\n        clone(non_est, safe=True)\n        assert False, \"Expected TypeError\"\n    except TypeError:\n        pass\n"], "sample_1199": ["def test_tensor_product_trace():\n    assert Tr(TensorProduct(A, B)).doit() == Tr(A)*Tr(B)\n    assert Tr(TensorProduct(A, B), indices=[0]).doit() == Tr(A)\n    assert Tr(TensorProduct(A, B), indices=[1]).doit() == Tr(B)\n    assert Tr(TensorProduct(A, B, C)).doit() == Tr(A)*Tr(B)*Tr(C)\n    assert Tr(TensorProduct(A, B, C), indices=[0, 1]).doit() == Tr(A)*Tr(B)\n    assert Tr(TensorProduct(A, B, C), indices=[1, 2]).doit() == Tr(B)*Tr(C)\n    assert Tr(TensorProduct(A, B, C), indices=[0, 2]).doit() == Tr(A)*Tr(C)\n"], "sample_102": ["def test_union_with_deferred_fields(self):\n    Number.objects.create(num=1, other_num=10)\n    qs1 = Number.objects.defer('other_num').filter(num=1)\n    qs2 = Number.objects.defer('other_num').filter(num=2)\n    self.assertEqual(qs1.union(qs2).count(), 2)\n    self.assertEqual(qs1.union(qs2).values_list('num', flat=True), [1, 2])\n"], "sample_346": ["    def test_sync_only_middleware(self):\n        @sync_only_middleware\n            return HttpResponse()\n        self.assertTrue(middleware.sync_capable)\n        self.assertFalse(middleware.async_capable)\n"], "sample_284": ["    def test_hash_key(self):\n        storage = ManifestStaticFilesStorage()\n        self.assertEqual(storage.hash_key('test/file.txt'), 'test/file.txt')\n        self.assertEqual(storage.hash_key('test/file.txt?query'), 'test/file.txt')\n        self.assertEqual(storage.hash_key('test/file.txt#fragment'), 'test/file.txt')\n        self.assertEqual(storage.hash_key('test/file.txt?query#fragment'), 'test/file.txt')\n"], "sample_675": ["def test_log_capture_fixture(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n        logger = logging.getLogger(__name__)\n\n            logger.info('text going to logger from call')\n            assert caplog.record_tuples == [('test_log_capture_fixture.py', 20, 'text going to logger from call')]\n            assert caplog.messages == ['text going to logger from call']\n            assert caplog.text == 'INFO     test_log_capture_fixture.py:5 text going to logger from call\\n'\n            caplog.clear()\n            logger.info('text going to logger from call after clear')\n            assert caplog.record_tuples == [('test_log_capture_fixture.py', 20, 'text going to logger from call after clear')]\n            assert caplog.messages == ['text going to logger from call after clear']\n            assert caplog.text == 'INFO     test_log_capture_fixture.py:9 text going to logger from call after clear\\n'\n        \"\"\"\n    )\n    result = testdir.runpytest(\"--log-level=INFO\")\n    assert result.ret == 0\n"], "sample_672": ["def test_saferepr_with_recursive_objects():\n    class RecursiveObject:\n            self.value = value\n            self.recursive_attr = None\n\n            return f\"RecursiveObject({self.value})\"\n\n    obj1 = RecursiveObject(1)\n    obj2 = RecursiveObject(2)\n    obj1.recursive_attr = obj2\n    obj2.recursive_attr = obj1\n\n    assert saferepr(obj1) == \"RecursiveObject(1)\"\n    assert saferepr(obj2) == \"RecursiveObject(2)\"\n"], "sample_859": ["def test_enet_coordinate_descent_multi_task():\n    \"\"\"Test that a warning is issued if model does not converge\"\"\"\n    clf = MultiTaskElasticNet(max_iter=2)\n    n_samples = 5\n    n_features = 2\n    X = np.ones((n_samples, n_features)) * 1e50\n    y = np.ones((n_samples, 2))\n    assert_warns(ConvergenceWarning, clf.fit, X, y)\n"], "sample_791": ["def test_ordinal_encoder_unsorted_categories():\n    X = np.array([['c', 'b', 'a'], ['b', 'a', 'c']])\n\n    enc = OrdinalEncoder(categories=[['b', 'a', 'c']])\n    exp = np.array([[2, 1, 0], [1, 0, 2]])\n    assert_array_equal(enc.fit_transform(X), exp)\n\n    # unsorted passed categories still raise for numerical values\n    X = np.array([[3, 2, 1], [2, 1, 3]])\n    enc = OrdinalEncoder(categories=[[2, 1, 3]])\n    msg = 'Unsorted categories are not supported'\n    with pytest.raises(ValueError, match=msg):\n        enc.fit_transform(X)\n"], "sample_763": ["def test_check_X_y_force_all_finite_valid():\n    # Test that check_X_y correctly handles force_all_finite\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([1, 2])\n    X[0, 0] = np.nan\n    X_checked, y_checked = check_X_y(X, y, force_all_finite='allow-nan')\n    assert np.isnan(X_checked).any()\n    assert not np.isnan(y_checked).any()\n\n    X[0, 0] = np.inf\n    X_checked, y_checked = check_X_y(X, y, force_all_finite=True)\n    assert not np.isinf(X_checked).any()\n    assert not np.isnan(y_checked).any()\n\n    X[0, 0] = np.nan\n    X_checked, y_checked = check_X_y(X, y, force_all_finite=False)\n    assert np.isnan(X_checked).any()\n    assert not np.isnan(y_checked).any()\n"], "sample_463": ["def test_alter_field_with_custom_through_model(self):\n    \"\"\"\n    #23938 - Changing a concrete field into a ManyToManyField\n    first removes the concrete field and then adds the m2m field.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_with_former_m2m],\n        [\n            self.author_with_m2m_through,\n            self.publisher,\n            self.contract,\n        ],\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(\n        changes,\n        \"testapp\",\n        0,\n        [\n            \"CreateModel\",\n            \"CreateModel\",\n            \"RemoveField\",\n            \"AddField\",\n        ],\n    )\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Publisher\")\n    self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"Contract\")\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 2, name=\"publishers\", model_name=\"author\"\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 3, name=\"publishers\", model_name=\"author\"\n    )\n"], "sample_569": ["def test_lmplot_hue_order(self):\n\n    g = lm.lmplot(x=\"x\", y=\"y\", data=self.df, hue=\"h\", hue_order=[\"y\", \"x\"])\n    ax = g.axes[0, 0]\n\n    assert len(ax.lines) == 2\n    assert len(ax.collections) == 4\n\n    red_scatter, blue_scatter = ax.collections\n    red, blue = color_palette(n_colors=2)\n    npt.assert_array_equal(blue, red_scatter.get_facecolors()[0, :3])\n    npt.assert_array_equal(red, blue_scatter.get_facecolors()[0, :3])\n"], "sample_1143": ["def test_issue_14289():\n    from sympy.polys.numberfields import to_number_field\n\n    a = 1 - sqrt(2)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n"], "sample_799": ["def test_cross_val_score_with_sample_weight():\n    # Test that cross_val_score works with sample weights\n    iris = load_iris()\n    X, y = iris.data, iris.target\n    clf = SVC(kernel='linear')\n    sample_weight = np.random.RandomState(0).randint(1, 10, size=len(y))\n    scores = cross_val_score(clf, X, y, cv=5, fit_params={'sample_weight': sample_weight})\n    assert_array_almost_equal(scores, [0.97, 1., 0.97, 0.97, 1.], 2)\n"], "sample_1061": ["def test_Pow():\n    assert Pow(2, 3)._eval_power(2) == 64\n    assert Pow(2, 3)._eval_power(-2) == S.One/64\n    assert Pow(2, 3)._eval_power(0) == 1\n    assert Pow(2, 3)._eval_power(1) == 8\n    assert Pow(2, 3)._eval_power(-1) == S.One/8\n    assert Pow(2, 3)._eval_power(2) == 64\n    assert Pow(2, 3)._eval_power(-2) == S.One/64\n    assert Pow(2, 3)._eval_power(0) == 1\n    assert Pow(2, 3)._eval_power(1) == 8\n    assert Pow(2, 3)._eval_power(-1) == S.One/8\n    assert Pow(2, 3)._eval_power(2) == 64\n    assert Pow(2, 3)._eval_power(-2) == S.One/64\n    assert Pow(2, 3)._eval_power(0) == 1\n    assert Pow(2, 3)._eval_power(1) == 8\n    assert Pow(2, 3)._eval_power(-1) == S.One/8\n    assert Pow(2, 3)._eval_power(2) == 64\n    assert Pow(2, 3)._eval_power(-2) == S.One/64\n    assert Pow(2, 3)._eval_power(0) == 1\n    assert Pow(2, 3)._eval_power(1) == 8\n    assert Pow(2, 3)._eval_power(-1) == S.One/8\n    assert Pow(2, 3)._eval_power(2) == 64\n    assert Pow(2, 3)._eval_power(-2) == S.One/64\n    assert Pow(2, 3)._eval_power(0) == 1\n    assert Pow(2, 3)._eval_power(1) == 8\n    assert Pow(2, 3)._eval_power(-1) == S.One/8\n    assert Pow(2, 3)._eval_power(2) == 64\n    assert Pow(2, 3)._eval_power(-2) == S"], "sample_328": ["    def test_values_list_with_flat_and_named(self):\n        with self.assertRaisesMessage(TypeError, \"'flat' and 'named' can't be used together.\"):\n            Note.objects.values_list(flat=True, named=True)\n"], "sample_214": ["    def test_custom_encoder_decoder(self):\n        value = {'uuid': uuid.UUID('{d85e2076-b67c-4ee7-8c3a-2bf5a2cc2475}')}\n        obj = NullableJSONModel.objects.create(value_custom=value)\n        obj.refresh_from_db()\n        self.assertEqual(obj.value_custom, value)\n"], "sample_717": ["def test_load_fake_lfw_pairs():\n    lfw_pairs = fetch_lfw_pairs(subset='train', data_home=SCIKIT_LEARN_DATA,\n                                download_if_missing=False)\n\n    # The data is croped around the center as a rectangular bounding box\n    # around the face. Colors are converted to gray levels:\n    assert_equal(lfw_pairs.pairs.shape, (10, 2, 62, 47))\n    assert_equal(lfw_pairs.data.shape, (10, 5828))\n\n    # the target is array of binary labels\n    assert_array_equal(lfw_pairs.target, [1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n\n    # names of the labels can be found using the target_names array\n    expected_classes = ['Different persons', 'Same person']\n    assert_array_equal(lfw_pairs.target_names, expected_classes)\n\n    # It is possible to ask for the original data without any croping or color\n    # conversion\n    lfw_pairs = fetch_lfw_pairs(subset='train', data_home=SCIKIT_LEARN_DATA,\n                                resize=None, slice_=None, color=True,\n                                download_if_missing=False)\n    assert_equal(lfw_pairs.pairs.shape, (10, 2, 250, 250, 3))\n\n    # the ids and class names are the same as previously\n    assert_array_equal(lfw_pairs.target, [1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n    assert_array_equal(lfw_pairs.target_names,\n                       ['Different persons', 'Same person'])\n"], "sample_955": ["def test_unparse_arguments():\n    source = \"def func(a: int, b: str = 'default', *args, **kwargs): pass\"\n    module = ast.parse(source)\n    expected = \"(a: int, b: str = 'default', *args, **kwargs)\"\n    assert ast.unparse(module.body[0].args, source) == expected\n"], "sample_119": ["def test_is_nullable(self):\n    query = Query(Item)\n    self.assertTrue(query.is_nullable(Item._meta.get_field('modified')))\n    self.assertFalse(query.is_nullable(Item._meta.get_field('id')))\n"], "sample_397": ["def test_find_template_loader_invalid_value(self):\n    \"\"\"\n    Test that an ImproperlyConfigured exception is raised when an invalid value\n    is provided in the template loaders configuration.\n    \"\"\"\n    with self.assertRaisesMessage(\n        ImproperlyConfigured,\n        \"Invalid value in template loaders configuration: 123\",\n    ):\n        DjangoTemplates(\n            {\n                \"DIRS\": [],\n                \"APP_DIRS\": False,\n                \"NAME\": \"django\",\n                \"OPTIONS\": {\n                    \"loaders\": [123],\n                },\n            }\n        )\n"], "sample_337": ["def test_origin_verified_with_trusted_origin(self):\n    \"\"\"\n    A POST request with an origin that matches a CSRF_TRUSTED_ORIGINS\n    setting is accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['HTTP_ORIGIN'] = 'https://dashboard.example.com'\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.csrf_trusted_origins_hosts = ['dashboard.example.com']\n    self.assertIs(mw._origin_verified(req), True)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n"], "sample_420": ["    def test_modelform_factory_metaclass(self):\n        class CustomModel(models.Model, metaclass=CustomMetaclass):\n            pass\n\n        new_cls = modelform_factory(CustomModel, fields=\"__all__\")\n        self.assertEqual(new_cls.base_fields, {})\n"], "sample_847": ["def test_enet_coordinate_descent_multi_task():\n    \"\"\"Test that a warning is issued if model does not converge\"\"\"\n    clf = MultiTaskElasticNet(max_iter=2)\n    n_samples = 5\n    n_features = 2\n    n_tasks = 3\n    X = np.ones((n_samples, n_features)) * 1e50\n    y = np.ones((n_samples, n_tasks))\n    assert_warns(ConvergenceWarning, clf.fit, X, y)\n"], "sample_451": ["def test_replace_metacharacters(self):\n    self.assertEqual(replace_metacharacters(\"Hello, world!\"), \"Hello, world!\")\n    self.assertEqual(replace_metacharacters(\"Hello, (world)!\"), \"Hello, (world)!\")\n    self.assertEqual(replace_metacharacters(\"Hello, \\\\(world)!\"), \"Hello, (world)!\")\n    self.assertEqual(replace_metacharacters(\"Hello, ?world!\"), \"Hello, world!\")\n    self.assertEqual(replace_metacharacters(\"Hello, \\\\?world!\"), \"Hello, ?world!\")\n    self.assertEqual(replace_metacharacters(\"Hello, *world!\"), \"Hello, world!\")\n    self.assertEqual(replace_metacharacters(\"Hello, \\\\*world!\"), \"Hello, *world!\")\n    self.assertEqual(replace_metacharacters(\"Hello, +world!\"), \"Hello, world!\")\n    self.assertEqual(replace_metacharacters(\"Hello, \\\\+world!\"), \"Hello, +world!\")\n    self.assertEqual(replace_metacharacters(\"Hello, ^world!\"), \"Hello, world!\")\n    self.assertEqual(replace_metacharacters(\"Hello, \\\\^world!\"), \"Hello, ^world!\")\n    self.assertEqual(replace_metacharacters(\"Hello, $world!\"), \"Hello, world!\")\n    self.assertEqual(replace_metacharacters(\"Hello, \\\\$world!\"), \"Hello, $world!\")\n    self.assertEqual(replace_metacharacters(\"Hello, \\\\bworld!\"), \"Hello, \\\\bworld!\")\n    self.assertEqual(replace_metacharacters(\"Hello, \\\\Bworld!\"), \"Hello, \\\\Bworld!\")\n    self.assertEqual(replace_metacharacters(\"Hello, \\\\Aworld!\"), \"Hello, \\\\Aworld!\")\n    self.assertEqual(replace_metacharacters(\"Hello, \\\\Zworld!\"), \"Hello, \\\\Zworld!\")\n"], "sample_442": ["    def test_dumps(self):\n        \"JSONSerializer.dumps() should serialize objects to bytes\"\n        serializer = signing.JSONSerializer()\n        tests = [\n            [\"a\", \"list\"],\n            \"a string \\u2019\",\n            {\"a\": \"dictionary\"},\n        ]\n        for obj in tests:\n            with self.subTest(obj=obj):\n                dumped = serializer.dumps(obj)\n                self.assertIsInstance(dumped, bytes)\n                self.assertEqual(obj, serializer.loads(dumped))\n"], "sample_462": ["def test_choicefield_coerce(self):\n        return int(val)\n\n    f = ChoiceField(choices=[(\"1\", \"One\"), (\"2\", \"Two\")], coerce=coerce)\n    self.assertEqual(1, f.clean(1))\n    self.assertEqual(1, f.clean(\"1\"))\n    msg = \"'Select a valid choice. 3 is not one of the available choices.'\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        f.clean(\"3\")\n\n    f = ChoiceField(choices=[(\"1\", \"One\"), (\"2\", \"Two\")], coerce=coerce, required=False)\n    self.assertEqual(\"\", f.clean(\"\"))\n    self.assertEqual(\"\", f.clean(None))\n    self.assertEqual(1, f.clean(1))\n    self.assertEqual(1, f.clean(\"1\"))\n    msg = \"'Select a valid choice. 3 is not one of the available choices.'\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        f.clean(\"3\")\n\n    f = ChoiceField(choices=[(\"J\", \"John\"), (\"P\", \"Paul\")], coerce=coerce)\n    msg = \"'Select a valid choice. J is not one of the available choices.'\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        f.clean(\"J\")\n\n    f = ChoiceField(\n        choices=[\n            (\"Numbers\", ((\"1\", \"One\"), (\"2\", \"Two\"))),\n            (\"Letters\", ((\"3\", \"A\"), (\"4\", \"B\"))),\n            (\"5\", \"Other\"),\n        ],\n        coerce=coerce,\n    )\n    self.assertEqual(1, f.clean(1))\n    self.assertEqual(1, f.clean(\"1\"))\n    self.assertEqual(3, f.clean(3))\n    self.assertEqual(3, f.clean(\"3\"))\n    self.assertEqual(5, f.clean(5))\n    self.assertEqual(5, f.clean(\"5\"))\n    msg = \"'Select a valid choice. 6 is not one of the available choices.'\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        f.clean(\"6\")\n"], "sample_417": ["    def test_addslashes(self):\n        output = self.engine.render_to_string(\n            \"stringfilter01\", {\"a\": \"Hello 'World'\", \"b\": mark_safe(\"Hello 'World'\")}\n        )\n        self.assertEqual(output, 'Hello \\\\'World\\' Hello \\\\'World\\'')\n"], "sample_747": ["def test_power_transformer_copy_exception():\n    pt = PowerTransformer(method='box-cox', copy=False)\n    X = np.abs(X_2d)\n\n    # An exception should be raised if copy=False and input is not a numpy array\n    assert_raise_message(ValueError, \"copy=False is not supported for non-numpy arrays\",\n                         pt.fit, X.tolist())\n    assert_raise_message(ValueError, \"copy=False is not supported for non-numpy arrays\",\n                         pt.transform, X.tolist())\n    assert_raise_message(ValueError, \"copy=False is not supported for non-numpy arrays\",\n                         pt.inverse_transform, X.tolist())\n"], "sample_1203": ["def test_homomorphism_edge_cases():\n    # Test the trivial homomorphism\n    F, a, b = free_group(\"a, b\")\n    G = FpGroup(F, [a**3, b**3, (a*b)**2])\n    T = homomorphism(G, AlternatingGroup(4), G.generators)\n    assert T.is_trivial()\n    assert T.kernel().order() == G.order()\n\n    # Test the identity homomorphism\n    T = homomorphism(G, G, G.generators, G.generators)\n    assert T.is_isomorphism()\n    assert T.kernel().order() == 1\n\n    # Test the homomorphism with a single generator\n    E, e = free_group(\"e\")\n    G = FpGroup(E, [e**8])\n    T = homomorphism(G, AlternatingGroup(4), [e], [Permutation(0, 1, 2)])\n    assert T.image().order() == 3\n\n    # Test the homomorphism with a non-surjective image\n    T = homomorphism(G, AlternatingGroup(4), [e], [Permutation(0, 1)])\n    assert not T.is_surjective()\n    assert T.image().order() == 2\n\n    # Test the homomorphism with a non-injective kernel\n    F, a, b = free_group(\"a, b\")\n    G = FpGroup(F, [a*b*a**-1*b**-1])\n    T = homomorphism(F, G, F.generators, G.generators)\n    assert not T.is_injective()\n    assert T.kernel().order() > 1\n"], "sample_513": ["def test_legend_draggable():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], label='test')\n    leg = ax.legend()\n    assert not leg.get_draggable()\n    leg.set_draggable(True)\n    assert leg.get_draggable()\n    leg.set_draggable(False)\n    assert not leg.get_draggable()\n    leg.set_draggable(True, use_blit=True)\n    assert leg.get_draggable()\n    leg.set_draggable(False)\n    assert not leg.get_draggable()\n    leg.set_draggable(True, update='bbox')\n    assert leg.get_draggable()\n    leg.set_draggable(False)\n    assert not leg.get_draggable()\n"], "sample_369": ["def test_alter_model_options_with_default_related_name(self):\n    \"\"\"Changing a model's default_related_name option should make a change.\"\"\"\n    model_state = ModelState('app', 'model', [\n        ('id', models.AutoField(primary_key=True)),\n    ], options={'default_related_name': 'related_name'})\n    changes = self.get_changes([], [model_state])\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['CreateModel'])\n    self.assertOperationAttributes(\n        changes, 'app', 0, 0, name='model',\n        options={'default_related_name': 'related_name'},\n    )\n    altered_model_state = ModelState('app', 'Model', [\n        ('id', models.AutoField(primary_key=True)),\n    ], options={'default_related_name': 'new_related_name'})\n    changes = self.get_changes([model_state], [altered_model_state])\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['AlterModelOptions'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='model', options={'default_related_name': 'new_related_name'})\n"], "sample_470": ["def test_lazy_object(self):\n    \"\"\"Test the LazyObject class.\"\"\"\n    class TestClass:\n            self.value = value\n\n            return self.value\n\n    lazy_obj = SimpleLazyObject(lambda: TestClass(42))\n    self.assertIsNone(lazy_obj._wrapped)\n    self.assertEqual(lazy_obj.method(), 42)\n    self.assertIsNotNone(lazy_obj._wrapped)\n    self.assertEqual(lazy_obj.value, 42)\n    self.assertEqual(lazy_obj.method(), 42)\n\n    # Test that the lazy object is pickled correctly\n    import pickle\n    pickled_lazy_obj = pickle.dumps(lazy_obj)\n    unpickled_lazy_obj = pickle.loads(pickled_lazy_obj)\n    self.assertEqual(unpickled_lazy_obj.method(), 42)\n\n    # Test that the lazy object is copied correctly\n    copied_lazy_obj = copy.copy(lazy_obj)\n    self.assertIsNot(copied_lazy_obj, lazy_obj)\n    self.assertEqual(copied_lazy_obj.method(), 42)\n\n    # Test that the lazy object is deep copied correctly\n    deep_copied_lazy_obj = copy.deepcopy(lazy_obj)\n    self.assertIsNot(deep_copied_lazy_obj, lazy_obj)\n    self.assertEqual(deep_copied_lazy_obj.method(), 42)\n\n    # Test that the lazy object's __repr__ method works correctly\n    self.assertIn(\"SimpleLazyObject\", repr(lazy_obj))\n\n    # Test that the lazy object's __dir__ method works correctly\n    self.assertIn(\"method\", dir(lazy_obj))\n\n    # Test that the lazy object's __eq__ method works correctly\n    self.assertEqual(lazy_obj, lazy_obj)\n    self.assertNotEqual(lazy_obj, object())\n\n    # Test that the lazy object's __lt__ method works correctly\n    self.assertLess(lazy_obj, object())\n    self.assertGreater(lazy_obj, object())\n\n    # Test that the lazy object's __hash__ method works correctly\n    self.assertEqual(hash(lazy_obj), hash(lazy_obj))\n\n    # Test that the lazy object's __getitem__ method works correctly\n    with self.assertRaises(TypeError):\n        lazy_obj[0]\n\n    # Test that the lazy object's __setitem__ method works correctly\n    with self.assertRaises(TypeError):\n        lazy_obj[0] = 42\n\n    # Test that the lazy object's __delitem__ method works correctly\n    with self.assertRaises(TypeError):\n        del lazy_obj[0]\n\n"], "sample_94": ["    def test_swappable_user_username_non_unique_interactive(self):\n        new_io = StringIO()\n        @mock_inputs({\n            'password': 'nopasswd',\n            'username': 'joe',\n            'email': 'joe@somewhere.org',\n        })\n            call_command(\n                \"createsuperuser\",\n                interactive=True,\n                stdout=new_io,\n                stdin=MockTTY(),\n            )\n            command_output = new_io.getvalue().strip()\n            self.assertEqual(command_output, 'Superuser created successfully.')\n\n        for i in range(2):\n            createsuperuser()\n\n        users = CustomUserNonUniqueUsername.objects.filter(username=\"joe\")\n        self.assertEqual(users.count(), 2)\n"], "sample_736": ["def test_logistic_regression_path_multiclass():\n    # Test logistic_regression_path for multiclass problems\n    X, y = make_classification(n_samples=50, n_features=20, n_informative=10,\n                               n_classes=3, random_state=0)\n    Cs = [1.0]\n    solvers = ['lbfgs', 'newton-cg', 'sag', 'saga']\n    for solver in solvers:\n        coefs, Cs, n_iter = logistic_regression_path(\n            X, y, Cs=Cs, solver=solver, multi_class='multinomial',\n            random_state=42, max_iter=2000, tol=1e-7)\n        assert_array_equal(coefs[0].shape, (3, 20))\n        assert_equal(len(Cs), 1)\n        assert_equal(len(n_iter), 1)\n"], "sample_821": ["def test_affinity_propagation_sparse_input():\n    # Test AffinityPropagation with sparse input\n    S = csr_matrix(np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]]))\n    af = AffinityPropagation(affinity=\"precomputed\")\n    af.fit(S)\n    assert_array_equal(af.labels_, np.array([0, 0, 0]))\n\n    # Test AffinityPropagation with sparse input and non-precomputed affinity\n    X = csr_matrix(np.array([[0, 1], [1, 0], [0, 1]]))\n    af = AffinityPropagation(affinity=\"euclidean\")\n    af.fit(X)\n    assert_array_equal(af.labels_, np.array([0, 0, 0]))\n"], "sample_591": ["    def test_dataset_update(self):\n        data = create_test_data()\n        data2 = data.copy(deep=True)\n        data2[\"var1\"][:, :5] = np.nan\n        data2[\"var2\"][:4, :] = np.nan\n        del data2[\"var3\"]\n\n        data.update(data2)\n        assert data.equals(data2)\n"], "sample_476": ["    def test_generate_filename_callable(self):\n        \"\"\"\n        Test that generate_filename works with a callable upload_to.\n        \"\"\"\n            return f\"{instance.name}/{filename}\"\n\n        class PersonWithCallableUploadTo(self.PersonModel):\n            mugshot = ImageField(upload_to=upload_to)\n\n        p = PersonWithCallableUploadTo(name=\"Joe\")\n        filename = p.mugshot.generate_filename(p, \"mugshot.png\")\n        self.assertEqual(filename, \"Joe/mugshot.png\")\n"], "sample_954": ["def test_nested_inline_transform(app, status, warning):\n    app.builder.build_all()\n    content = (app.outdir / 'sphinxtests.1').read_text()\n\n    # test nested inline nodes\n    assert '<emphasis>foo=</emphasis><emphasis>1</emphasis>' not in content\n    assert '<emphasis>foo=</emphasis><emphasis>2</emphasis>' not in content\n    assert '<strong>foo=</strong><emphasis>1</emphasis>' in content\n    assert '<strong>&amp;bar=</strong><emphasis>2</emphasis>' in content\n"], "sample_438": ["def test_model_base_subclass_exception(self):\n    class MyModel(models.Model):\n        pass\n\n    self.assertEqual(MyModel.DoesNotExist.__qualname__, \"MyModel.DoesNotExist\")\n    self.assertEqual(MyModel.MultipleObjectsReturned.__qualname__, \"MyModel.MultipleObjectsReturned\")\n"], "sample_30": ["def test_timesys_v1_4():\n    votable = parse(get_pkg_data_filename(\"data/timesys_v1_4.xml\"))\n    _timesys_tests(votable)\n"], "sample_578": ["def test_baseline(self, x, y):\n\n    baseline = [1, 2, 3, 4, 5]\n    p = Plot(x, y, baseline=baseline).add(Bars()).plot()\n    ax = p._figure.axes[0]\n    paths = ax.collections[0].get_paths()\n    assert len(paths) == len(x)\n    for i, path in enumerate(paths):\n        verts = path.vertices\n        assert verts[0, 1] == pytest.approx(baseline[i])\n        assert verts[3, 1] == pytest.approx(baseline[i] + y[i])\n"], "sample_293": ["    def test_prefix_default_language(self):\n        pattern = LocalePrefixPattern(prefix_default_language=True)\n        self.assertEqual(pattern.regex.pattern, '^en/')\n"], "sample_151": ["def test_alter_field_to_fk_dependency_other_app(self):\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author_fk],\n        [self.author_empty, self.book],\n    )\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '__first__')])\n"], "sample_1179": ["def test_Pow():\n    # Test Pow with non-integer exponent\n    assert str(x**Float(1.5)) == 'x**(1.5)'\n    assert str(x**Float(-1.5)) == 'x**(-1.5)'\n    assert str(x**Float(0.5)) == 'x**(0.5)'\n    assert str(x**Float(-0.5)) == 'x**(-0.5)'\n    assert str(x**Float(1.0)) == 'x**(1.0)'\n    assert str(x**Float(-1.0)) == 'x**(-1.0)'\n    assert str(x**Float(0.0)) == 'x**(0.0)'\n    assert str(x**Float(-0.0)) == 'x**(-0.0)'\n"], "sample_6": ["def test_angle_wrap_at():\n    \"\"\"\n    Test the wrap_at method of Angle objects.\n    \"\"\"\n    a1 = Angle([0, 45, 90, 180, 270, 360, 720.], unit=u.degree)\n    a2 = a1.wrap_at(360 * u.degree)\n    npt.assert_almost_equal(a2.degree, [0, 45, 90, 180, 270, 0, 360])\n\n    a3 = Angle([0, 45, 90, 180, 270, 360, 720.], unit=u.degree)\n    a3.wrap_at(360 * u.degree, inplace=True)\n    npt.assert_almost_equal(a3.degree, [0, 45, 90, 180, 270, 0, 360])\n\n    a4 = Angle([0, 45, 90, 180, 270, 360, 720.], unit=u.degree)\n    a5 = a4.wrap_at(180 * u.degree)\n    npt.assert_almost_equal(a5.degree, [0, 45, 90, -180, -90, -45, 0])\n\n    a6 = Angle([0, 45, 90, 180, 270, 360, 720.], unit=u.degree)\n    a6.wrap_at(180 * u.degree, inplace=True)\n    npt.assert_almost_equal(a6.degree, [0, 45, 90, -180, -90, -45, 0])\n\n    a7 = Angle([0, 45, 90, 180, 270, 360, 720.], unit=u.degree)\n    a8 = a7.wrap_at(-180 * u.degree)\n    npt.assert_almost_equal(a8.degree, [0, 45, 90, -180, -90, -45, 0])\n\n    a9 = Angle([0, 45, 90, 180, 270, 360, 720.], unit=u.degree)\n    a9.wrap_at(-180 * u.degree, inplace=True)\n    npt.assert_almost_equal(a9.degree, [0, 45, 90, -180, -90, -45, 0])\n"], "sample_980": ["def test_af_pow():\n    a = [2, 0, 3, 1]\n    assert _af_pow(a, 0) == [0, 1, 2, 3]\n    assert _af_pow(a, 1) == a\n    assert _af_pow(a, 2) == [3, 2, 0, 1]\n    assert _af_pow(a, 3) == [1, 3, 2, 0]\n    assert _af_pow(a, 4) == [0, 1, 2, 3]\n    assert _af_pow(a, -1) == [3, 2, 0, 1]\n    assert _af_pow(a, -2) == [1, 3, 2, 0]\n    assert _af_pow(a, -3) == [0, 1, 2, 3]\n    assert _af_pow(a, -4) == a\n"], "sample_765": ["def test_multilabel_confusion_matrix_multilabel_with_sample_weight():\n    # Test multilabel confusion matrix - multilabel-indicator case\n    from scipy.sparse import csc_matrix, csr_matrix\n\n    y_true = np.array([[1, 0, 1], [0, 1, 0], [1, 1, 0]])\n    y_pred = np.array([[1, 0, 0], [0, 1, 1], [0, 0, 1]])\n    y_true_csr = csr_matrix(y_true)\n    y_pred_csr = csr_matrix(y_pred)\n    y_true_csc = csc_matrix(y_true)\n    y_pred_csc = csc_matrix(y_pred)\n\n    # cross test different types\n    sample_weight = np.array([2, 1, 3])\n    real_cm = [[[1, 0], [1, 1]],\n               [[1, 0], [1, 1]],\n               [[0, 2], [1, 0]]]\n    trues = [y_true, y_true_csr, y_true_csc]\n    preds = [y_pred, y_pred_csr, y_pred_csc]\n\n    for y_true_tmp in trues:\n        for y_pred_tmp in preds:\n            cm = multilabel_confusion_matrix(y_true_tmp, y_pred_tmp,\n                                             sample_weight=sample_weight)\n            assert_array_equal(cm, real_cm)\n\n    # test support for samplewise\n    cm = multilabel_confusion_matrix(y_true, y_pred, sample_weight=sample_weight,\n                                     samplewise=True)\n    assert_array_equal(cm, [[[1, 0], [1, 1]],\n                            [[1, 1], [0, 1]],\n                            [[0, 1], [2, 0]]])\n\n    # test support for labels\n    cm = multilabel_confusion_matrix(y_true, y_pred, labels=[2, 0],\n                                     sample_weight=sample_weight)\n    assert_array_equal(cm, [[[0, 2], [1, 0]],\n                            [[1, 0], [1, 1]]])\n\n    # test support for labels with samplewise\n    cm = multilabel_confusion_matrix(y_true, y_pred, labels=[2, 0],\n                                     sample_weight=sample_weight,\n                                     samplewise=True)\n    assert_array_equal(cm, [[[0, 0], ["], "sample_812": ["def test_n_max_elements_to_show_with_tuples():\n    n_max_elements_to_show = 5\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=n_max_elements_to_show\n    )\n\n    # No ellipsis\n    items = [(i, i) for i in range(n_max_elements_to_show)]\n    expected = \"\"\""], "sample_676": ["def test_rewrite_with_ansi_escape_codes(testdir, monkeypatch):\n    config = testdir.parseconfig()\n    f = py.io.TextIO()\n    monkeypatch.setattr(f, \"isatty\", lambda *args: True)\n    tr = TerminalReporter(config, f)\n    tr._tw.fullwidth = 10\n    tr.write(\"\\x1b[31mhello\\x1b[0m\")\n    tr.rewrite(\"\\x1b[32mhey\\x1b[0m\", erase=True)\n    assert f.getvalue() == \"\\x1b[31mhello\\x1b[0m\" + \"\\r\" + \"\\x1b[32mhey\\x1b[0m\" + (6 * \" \")\n"], "sample_681": ["def test_log_capture_handler_reset(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logger = logging.getLogger(__name__)\n\n            logger.info('First message')\n            assert len(caplog.records) == 1\n            caplog.clear()\n            assert len(caplog.records) == 0\n\n            logger.info('Second message')\n            assert len(caplog.records) == 1\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--log-level=INFO\")\n    assert result.ret == 0\n"], "sample_252": ["    def test_key_transform_factory(self):\n        field = models.JSONField()\n        transform = field.get_transform('key')\n        self.assertIsInstance(transform, KeyTransformFactory)\n        self.assertEqual(transform.key_name, 'key')\n"], "sample_930": ["def test_create_index_with_group_entries_false(app):\n    text = (\".. index:: single: docutils\\n\"\n            \".. index:: single: Python\\n\"\n            \".. index:: Sphinx\\n\"\n            \".. index:: pip; install\\n\"\n            \".. index:: pip; upgrade\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder, group_entries=False)\n    assert len(index) == 4\n    assert index[0] == ('D', [('docutils', [[('', '#index-0')], [], None])])\n    assert index[1] == ('P', [('pip', [[], [('install', [('', '#index-3')]),\n                                            ('upgrade', [('', '#index-4')])], None]),\n                              ('Python', [[('', '#index-1')], [], None])])\n    assert index[2] == ('S', [('Sphinx', [[('', '#index-2')], [], None])])\n    assert index[3] == ('Symbols', [('pip (in module install)', [[], [], None]),\n                                    ('pip (in module upgrade)', [[], [], None])])\n"], "sample_1001": ["def test_latex_DiagramGrid():\n    from sympy.categories import Object, NamedMorphism, Diagram, DiagramGrid\n    A = Object(\"A\")\n    B = Object(\"B\")\n    C = Object(\"C\")\n    f = NamedMorphism(A, B, \"f\")\n    g = NamedMorphism(B, C, \"g\")\n    d = Diagram([f, g])\n    grid = DiagramGrid(d)\n    assert latex(grid) == \"\\\\begin{array}{cc}\\nA & B \\\\\\\\\\n & C \\n\\\\end{array}\\n\"\n"], "sample_696": ["def test_argument_percent_default_is_deprecated(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n            parser.addoption(\"--foo\", type=int, default=42, help=\"foo %default\")\n        \"\"\"\n    )\n    result = pytester.runpytest(\"--help\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: pytest now uses argparse. '%default' should be changed to '%(default)s'\",\n        ]\n    )\n\n"], "sample_21": ["def test_read_write_err_specs(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3]))\n    t1.add_column(Column(name=\"a_err\", data=[0.1, 0.2, 0.3]))\n    t1.add_column(Column(name=\"b\", data=[4, 5, 6]))\n    t1.add_column(Column(name=\"b_perr\", data=[0.4, 0.5, 0.6]))\n    t1.add_column(Column(name=\"b_nerr\", data=[-0.4, -0.5, -0.6]))\n    t1.write(test_file, format=\"ascii.qdp\")\n    t2 = Table.read(test_file, table_id=0, format=\"ascii.qdp\", names=[\"a\", \"b\"])\n    assert np.allclose(t2[\"a\"], t1[\"a\"])\n    assert np.allclose(t2[\"a_err\"], t1[\"a_err\"])\n    assert np.allclose(t2[\"b\"], t1[\"b\"])\n    assert np.allclose(t2[\"b_perr\"], t1[\"b_perr\"])\n    assert np.allclose(t2[\"b_nerr\"], t1[\"b_nerr\"])\n"], "sample_518": ["def test_fancyarrowpatch_set_positions():\n    fig, ax = plt.subplots()\n    arrow = FancyArrowPatch((0, 0), (1, 1), mutation_scale=2)\n    ax.add_patch(arrow)\n    assert arrow.get_positions() == ((0, 0), (1, 1))\n    arrow.set_positions((0.5, 0.5), (1.5, 1.5))\n    assert arrow.get_positions() == ((0.5, 0.5), (1.5, 1.5))\n"], "sample_179": ["    def test_model_base_check(self):\n        class Model(models.Model):\n            class Meta:\n                abstract = True\n\n        self.assertEqual(Model.check(), [])\n"], "sample_771": ["def test_power_transformer_edge_cases():\n    # Test edge cases for PowerTransformer\n    pt = PowerTransformer(method='box-cox')\n    X = np.array([[1e-10], [1e-5], [1e-1], [1], [1e1], [1e5], [1e10]])\n    X_trans = pt.fit_transform(X)\n    assert_array_almost_equal(X, pt.inverse_transform(X_trans))\n\n    pt = PowerTransformer(method='yeo-johnson')\n    X = np.array([[-1e10], [-1e5], [-1e-1], [0], [1e-1], [1e5], [1e10]])\n    X_trans = pt.fit_transform(X)\n    assert_array_almost_equal(X, pt.inverse_transform(X_trans))\n"], "sample_37": ["def test_to_fits_2():\n    \"\"\"\n    Test to_fits() with SIP distortion.\n    \"\"\"\n    fits_name = get_pkg_data_filename('data/sip.fits')\n    w = wcs.WCS(fits_name)\n    wfits = w.to_fits()\n    assert isinstance(wfits, fits.HDUList)\n    assert isinstance(wfits[0], fits.PrimaryHDU)\n    assert isinstance(wfits[1], fits.ImageHDU)\n"], "sample_384": ["    def test_get_or_create_with_defaults(self):\n        defaults = {\"note\": \"test-note\", \"misc\": \"test-misc\"}\n        obj, created = Note.objects.get_or_create(note=\"test-note\", defaults=defaults)\n        self.assertTrue(created)\n        self.assertEqual(obj.note, \"test-note\")\n        self.assertEqual(obj.misc, \"test-misc\")\n"], "sample_394": ["    def test_changelist_view_with_custom_queryset(self):\n        \"\"\"\n        Test that a custom queryset is used in the changelist view.\n        \"\"\"\n        response = self.client.get(reverse(\"admin:admin_views_emptymodel_changelist\"))\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, \"Primary key = 2\")\n        self.assertContains(response, \"Primary key = 3\")\n        self.assertNotContains(response, \"Primary key = 1\")\n"], "sample_44": ["    def test_pickling(self):\n        \"\"\"Test that FunctionQuantity instances can be pickled and unpickled.\"\"\"\n        lq = u.Magnitude(np.arange(1., 10.)*u.Jy)\n        s = pickle.dumps(lq)\n        lq2 = pickle.loads(s)\n        assert lq == lq2\n        assert lq.unit == lq2.unit\n        assert np.all(lq.value == lq2.value)\n"], "sample_471": ["    def test_floatfield_1(self):\n        f = FloatField()\n        self.assertWidgetRendersTo(\n            f, '<input type=\"number\" name=\"f\" id=\"id_f\" required step=\"any\">'\n        )\n        with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):\n            f.clean(\"\")\n        with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):\n            f.clean(None)\n        self.assertEqual(1.0, f.clean(\"1\"))\n        self.assertIsInstance(f.clean(\"1\"), float)\n        self.assertEqual(23.0, f.clean(\"23\"))\n        with self.assertRaisesMessage(ValidationError, \"'Enter a number.'\"):\n            f.clean(\"a\")\n        self.assertEqual(42.0, f.clean(42))\n        self.assertEqual(3.14, f.clean(3.14))\n        self.assertEqual(1.0, f.clean(\"1 \"))\n        self.assertEqual(1.0, f.clean(\" 1\"))\n        self.assertEqual(1.0, f.clean(\" 1 \"))\n        with self.assertRaisesMessage(ValidationError, \"'Enter a number.'\"):\n            f.clean(\"1a\")\n        self.assertIsNone(f.max_value)\n        self.assertIsNone(f.min_value)\n"], "sample_949": ["def test_custom_man_pages(app, status, warning):\n    app.build()\n    assert (app.outdir / 'custom.2').exists()\n\n    content = (app.outdir / 'custom.2').read_text()\n    assert 'Custom Title' in content\n    assert 'Custom Author' in content\n"], "sample_697": ["def test_tmp_path_factory_getbasetemp_with_absolute_path(tmp_path: Path, monkeypatch: MonkeyPatch) -> None:\n    \"\"\"Test that getbasetemp() returns the absolute path of the given basetemp.\"\"\"\n    monkeypatch.chdir(tmp_path)\n    config = FakeConfig(\"/absolute/path\")\n    t = TempPathFactory.from_config(config, _ispytest=True)\n    assert t.getbasetemp().resolve() == Path(\"/absolute/path\").resolve()\n"], "sample_376": ["def test_message_extra_tags(self):\n    \"\"\"\n    A message with extra tags is properly encoded/decoded by the custom JSON\n    encoder/decoder classes.\n    \"\"\"\n    message = Message(constants.INFO, 'Test message', extra_tags='tag1 tag2')\n    storage = self.get_storage()\n    encoded = storage._encode([message])\n    decoded_messages = storage._decode(encoded)\n    self.assertEqual(len(decoded_messages), 1)\n    self.assertEqual(decoded_messages[0].message, message.message)\n    self.assertEqual(decoded_messages[0].level, message.level)\n    self.assertEqual(decoded_messages[0].extra_tags, message.extra_tags)\n"], "sample_786": ["def test_inverse_transform_constant_feature(strategy):\n    X = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\n    kbd = KBinsDiscretizer(n_bins=3, strategy=strategy, encode='ordinal')\n    kbd.fit(X)\n    Xt = kbd.transform(X)\n    X2 = kbd.inverse_transform(Xt)\n    assert_array_equal(X2, np.zeros_like(X))\n"], "sample_1197": ["def test_unit_system_extension():\n    new_system = SI.extend((Quantity(\"new_unit\"), name=\"New System\")\n    assert new_system.name == \"New System\"\n    assert new_system.dim == 8\n    assert new_system.is_consistent\n\n    new_system = SI.extend((Quantity(\"new_unit\"), derived_units={Dimension(length/time): Quantity(\"new_unit\")})\n    assert new_system.derived_units == {Dimension(length/time): Quantity(\"new_unit\"), **SI.derived_units}\n\n    new_system = SI.extend((Quantity(\"new_unit\"), dimension_system=DimensionSystem())\n    assert new_system.get_dimension_system() != SI.get_dimension_system()\n"], "sample_539": ["def test_lasso_selector_onselect(ax):\n    onselect = mock.Mock(spec=noop, return_value=None)\n\n    tool = widgets.LassoSelector(ax, onselect)\n    do_event(tool, 'press', xdata=100, ydata=100, button=1)\n    do_event(tool, 'onmove', xdata=125, ydata=125, button=1)\n    do_event(tool, 'release', xdata=150, ydata=150, button=1)\n\n    onselect.assert_called_once()\n    assert tool.verts == [(100, 100), (125, 125), (150, 150)]\n\n    onselect.reset_mock()\n    do_event(tool, 'press', xdata=10, ydata=10, button=1)\n    do_event(tool, 'release', xdata=10, ydata=10, button=1)\n    onselect.assert_called_once()\n    assert tool.verts == [(10, 10)]\n"], "sample_79": ["    def test_truncatechars(self):\n        self.assertEqual(truncatechars('Hello, world!', 5), 'Hello...')\n        self.assertEqual(truncatechars('Hello, world!', 15), 'Hello, world!')\n"], "sample_379": ["def test_safe_string_addition(self):\n    \"\"\"\n    Test the addition of SafeString instances with other strings.\n    \"\"\"\n    s1 = mark_safe('a&b')\n    s2 = mark_safe('c&d')\n    s3 = 'e&f'\n\n    self.assertIsInstance(s1 + s2, SafeString)\n    self.assertEqual(s1 + s2, 'a&bc&d')\n    self.assertNotIsInstance(s1 + s3, SafeString)\n    self.assertEqual(s1 + s3, 'a&be&f')\n"], "sample_940": ["def test_isabstractmethod():\n    class AbstractClass:\n        @abstractmethod\n            pass\n\n    class ConcreteClass(AbstractClass):\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(ConcreteClass.abstract_method) is False\n"], "sample_69": ["    def test_enable_echo(self, mocked_termios):\n        mocked_termios.tcgetattr.return_value = [0, 0, 0, 0]\n        mocked_termios.ECHO = 1\n        autoreload.ensure_echo_on()\n        mocked_termios.tcsetattr.assert_called_once()\n"], "sample_432": ["def test_get_deleted_objects(self):\n    \"\"\"\n    Regression test for #15819: get_deleted_objects() must apply Exists() when\n    a non-unique related object is in list_filter.\n    \"\"\"\n    parent = Parent.objects.create(name=\"Mary\")\n    # Two children with the same name\n    Child.objects.create(parent=parent, name=\"Daniel\")\n    Child.objects.create(parent=parent, name=\"Daniel\")\n\n    m = ParentAdmin(Parent, custom_site)\n    request = self.factory.get(\"/parent/\", data={\"child__name\": \"Daniel\"})\n    request.user = self.superuser\n\n    cl = m.get_changelist_instance(request)\n    # Exists() is applied.\n    self.assertIn(\" EXISTS\", str(cl.queryset.query))\n\n    # get_deleted_objects() must apply Exists() when a non-unique related object\n    # is in list_filter.\n    obj = cl.result_list[0]\n    deleted_objects, model_count, perms_needed, protected = m.get_deleted_objects(\n        [obj], request\n    )\n    self.assertIn(\" EXISTS\", str(deleted_objects.query))\n"], "sample_122": ["    def test_get_max_age(self):\n        response = HttpResponse()\n        self.assertIsNone(get_max_age(response))\n\n        response['Cache-Control'] = 'max-age=3600'\n        self.assertEqual(get_max_age(response), 3600)\n\n        response['Cache-Control'] = 'max-age=3600, public'\n        self.assertEqual(get_max_age(response), 3600)\n\n        response['Cache-Control'] = 'public'\n        self.assertIsNone(get_max_age(response))\n\n        response['Cache-Control'] = 'max-age=abc'\n        self.assertIsNone(get_max_age(response))\n"], "sample_841": ["def test_ridge_regression_check_input():\n    # Test that ridge_regression checks the input arguments\n    rng = np.random.RandomState(42)\n    X = rng.rand(100, 3)\n    y = rng.rand(100)\n    alpha = 1e-3\n    solver = 'cholesky'\n\n    # Test that check_input=False allows invalid input\n    ridge_regression(X, y, alpha, solver=solver, check_input=False)\n\n    # Test that check_input=True raises an error for invalid input\n    X_invalid = rng.rand(100, 3, 2)  # 3D array\n    with pytest.raises(ValueError, match=\"X has an invalid shape\"):\n        ridge_regression(X_invalid, y, alpha, solver=solver, check_input=True)\n\n    # Test that check_input=True raises an error for invalid input\n    y_invalid = rng.rand(100, 3, 2)  # 3D array\n    with pytest.raises(ValueError, match=\"y has an invalid shape\"):\n        ridge_regression(X, y_invalid, alpha, solver=solver, check_input=True)\n\n    # Test that check_input=True raises an error for invalid input\n    alpha_invalid = -1  # negative alpha\n    with pytest.raises(ValueError, match=\"Number of targets and number of penalties\"):\n        ridge_regression(X, y, alpha_invalid, solver=solver, check_input=True)\n\n    # Test that check_input=True raises an error for invalid input\n    solver_invalid = 'invalid_solver'  # invalid solver\n    with pytest.raises(ValueError, match=\"Known solvers are 'sparse_cg', 'cholesky', 'svd'\"):\n        ridge_regression(X, y, alpha, solver=solver_invalid, check_input=True)\n"], "sample_1110": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n\n    assert prntr.doprint(pi) == 'math.pi'\n    assert prntr.module_imports == {'math': {'pi'}}\n\n    assert prntr.doprint(x**Rational(1, 2)) == 'math.sqrt(x)'\n    assert prntr.doprint(sqrt(x)) == 'math.sqrt(x)'\n    assert prntr.module_imports == {'math': {'pi', 'sqrt'}}\n\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n    assert prntr.doprint(KroneckerDelta(x,y)) == '(1 if x == y else 0)'\n"], "sample_1065": ["def test_subfactorial():\n    x = Symbol('x')\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True, nonnegative=True)\n\n    assert subfactorial(0) == 1\n    assert subfactorial(1) == 0\n    assert subfactorial(5) == 44\n    assert subfactorial(n).func == subfactorial\n    assert subfactorial(n).is_integer is None\n    assert subfactorial(k).is_integer is True\n    assert subfactorial(x).is_integer is None\n\n    assert subfactorial(n).is_nonnegative is None\n    assert subfactorial(k).is_nonnegative is True\n    assert subfactorial(x).is_nonnegative is None\n\n    assert subfactorial(n).is_even is None\n    assert subfactorial(k).is_even is True\n    assert subfactorial(x).is_even is None\n\n    assert subfactorial(n).is_odd is None\n    assert subfactorial(k).is_odd is False\n    assert subfactorial(x).is_odd is None\n\n    assert subfactorial(n).rewrite(uppergamma) == uppergamma(n + 1, -1)/S.Exp1\n    assert subfactorial(k).rewrite(uppergamma) == uppergamma(k + 1, -1)/S.Exp1\n    assert subfactorial(x).rewrite(uppergamma) == uppergamma(x + 1, -1)/S.Exp1\n"], "sample_1055": ["def test_encipher_decipher_elgamal():\n    ps = [131, 137, 139, 149, 151, 157, 163, 167,\n          173, 179, 181, 191, 193, 197, 199]\n    gs = [89, 97, 101, 103, 107, 109, 113, 127,\n          131, 137, 139, 149, 151, 157, 47]\n    messages = [\n        0, 32855, 34303, 14805, 1280, 75859, 38368,\n        724, 60356, 51675, 76697, 61854, 18661,\n    ]\n    for p, g in zip(ps, gs):\n        pri = elgamal_private_key()\n        for msg in messages:\n            pub = elgamal_public_key(pri)\n            enc = encipher_elgamal(msg, pub)\n            dec = decipher_elgamal(enc, pri)\n            assert dec == msg\n"], "sample_311": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n"], "sample_317": ["def test_rss_feed_with_empty_description(self):\n    \"\"\"\n    Test the structure and content of feeds generated by Rss201rev2Feed\n    with an empty description.\n    \"\"\"\n    response = self.client.get('/syndication/rss2-empty-description/')\n    doc = minidom.parseString(response.content)\n\n    # Making sure there's only 1 `rss` element and that the correct\n    # RSS version was specified.\n    feed_elem = doc.getElementsByTagName('rss')\n    self.assertEqual(len(feed_elem), 1)\n    feed = feed_elem[0]\n    self.assertEqual(feed.getAttribute('version'), '2.0')\n    self.assertEqual(feed.getElementsByTagName('language')[0].firstChild.nodeValue, 'en')\n\n    # Making sure there's only one `channel` element w/in the\n    # `rss` element.\n    chan_elem = feed.getElementsByTagName('channel')\n    self.assertEqual(len(chan_elem), 1)\n    chan = chan_elem[0]\n\n    # Find the last build date\n    d = Entry.objects.latest('published').published\n    last_build_date = rfc2822_date(timezone.make_aware(d, TZ))\n\n    self.assertChildNodes(\n        chan, [\n            'title', 'link', 'description', 'language', 'lastBuildDate',\n            'item', 'atom:link', 'ttl', 'copyright', 'category',\n        ]\n    )\n    self.assertChildNodeContent(chan, {\n        'title': 'My blog',\n        'link': 'http://example.com/blog/',\n        'language': 'en',\n        'lastBuildDate': last_build_date,\n        'ttl': '600',\n        'copyright': 'Copyright (c) 2007, Sally Smith',\n    })\n    self.assertCategories(chan, ['python', 'django'])\n\n    # Ensure the content of the channel is correct\n    self.assertChildNodeContent(chan, {\n        'title': 'My blog',\n        'link': 'http://example.com/blog/',\n    })\n\n    # Check feed_url is passed\n    self.assertEqual(\n        chan.getElementsByTagName('atom:link')[0].getAttribute('href'),\n        'http://example.com/syndication/rss2-empty-description/'\n    )\n\n    # Find the pubdate of the first feed item\n    d = Entry.objects.get(pk=self.e1.pk).published\n    pub_date = rfc2822_date(timezone.make_aware(d, TZ))\n\n    items = chan.getElementsByTagName('item')\n    self.assertEqual(len(items), Entry"], "sample_616": ["def test_cross() -> None:\n    # Test cross product with 3 dimensions\n    a = xr.DataArray([1, 2, 3])\n    b = xr.DataArray([4, 5, 6])\n    expected = xr.DataArray([-3, 6, -3])\n    actual = xr.cross(a, b, dim=\"dim_0\")\n    assert_identical(expected, actual)\n\n    # Test cross product with 2 dimensions, returns in the perpendicular direction\n    a = xr.DataArray([1, 2])\n    b = xr.DataArray([4, 5])\n    expected = xr.DataArray(-3)\n    actual = xr.cross(a, b, dim=\"dim_0\")\n    assert_identical(expected, actual)\n\n    # Test cross product with 3 dimensions but zeros at the last axis yields the same results as with 2 dimensions\n    a = xr.DataArray([1, 2, 0])\n    b = xr.DataArray([4, 5, 0])\n    expected = xr.DataArray([0, 0, -3])\n    actual = xr.cross(a, b, dim=\"dim_0\")\n    assert_identical(expected, actual)\n\n    # Test one vector with dimension 2\n    a = xr.DataArray(\n        [1, 2],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\"])),\n    )\n    b = xr.DataArray(\n        [4, 5, 6],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    expected = xr.DataArray([12, -6, -3], dims=[\"cartesian\"])\n    expected.coords[\"cartesian\"] = [\"x\", \"y\", \"z\"]\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(expected, actual)\n\n    # Test one vector with dimension 2 but coords in other positions\n    a = xr.DataArray(\n        [1, 2],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"z\"])),\n    )\n    b = xr.DataArray(\n        [4, 5, 6],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    expected = xr.DataArray([-"], "sample_28": ["def test_record_valued_keyword_cards_with_hierarch_keywords(self):\n    \"\"\"\n    Regression test for https://github.com/astropy/astropy/issues/5409\n\n    Ensures that record-valued keyword cards can be used with HIERARCH keywords.\n    \"\"\"\n\n    header = fits.Header()\n    header.set(\"HIERARCH DP1\", \"NAXIS: 2\")\n    header.set(\"HIERARCH DP1\", \"AXIS.1: 1\")\n    header.set(\"HIERARCH DP1\", \"AXIS.2: 2\")\n    header.set(\"HIERARCH DP1\", \"NAUX:   2\")\n    header.set(\"HIERARCH DP1\", \"AUX.1.COEFF.0: 0\")\n    header.set(\"HIERARCH DP1\", \"AUX.1.POWER.0: 1\")\n    header.set(\"HIERARCH DP1\", \"AUX.1.COEFF.1: 0.00048828125\")\n    header.set(\"HIERARCH DP1\", \"AUX.1.POWER.1:  1\")\n\n    assert header[\"HIERARCH DP1.NAXIS\"] == 2.0\n    assert header[\"HIERARCH DP1.AXIS.1\"] == 1.0\n    assert header[\"HIERARCH DP1.AXIS.2\"] == 2.0\n    assert header[\"HIERARCH DP1.NAUX\"] == 2.0\n    assert header[\"HIERARCH DP1.AUX.1.COEFF.0\"] == 0.0\n    assert header[\"HIERARCH DP1.AUX.1.POWER.0\"] == 1.0\n    assert header[\"HIERARCH DP1.AUX.1.COEFF.1\"] == 0.00048828125\n    assert header[\"HIERARCH DP1.AUX.1.POWER.1\"] == 1.0\n"], "sample_734": ["def test_contingency_matrix_edge_cases():\n    # Test contingency matrix with empty labels\n    assert_array_almost_equal(contingency_matrix([], []), np.array([[0]]))\n\n    # Test contingency matrix with single element labels\n    assert_array_almost_equal(contingency_matrix([0], [0]), np.array([[1]]))\n\n    # Test contingency matrix with identical labels\n    assert_array_almost_equal(contingency_matrix([0, 0, 1, 1], [0, 0, 1, 1]),\n                              np.array([[2, 0], [0, 2]]))\n\n    # Test contingency matrix with non-identical labels\n    assert_array_almost_equal(contingency_matrix([0, 0, 1, 1], [0, 1, 1, 0]),\n                              np.array([[1, 1], [1, 1]]))\n\n    # Test contingency matrix with sparse output\n    assert_array_almost_equal(contingency_matrix([0, 0, 1, 1], [0, 0, 1, 1],\n                                                 sparse=True).toarray(),\n                              np.array([[2, 0], [0, 2]]))\n\n    # Test contingency matrix with eps value\n    assert_array_almost_equal(contingency_matrix([0, 0, 1, 1], [0, 0, 1, 1],\n                                                 eps=0.1),\n                              np.array([[2.1, 0.1], [0.1, 2.1]]))\n"], "sample_936": ["def test_stringify_type_hints_ForwardRef():\n    if sys.version_info >= (3, 7):\n        from typing import ForwardRef\n        assert stringify(ForwardRef('int')) == \"int\"\n        assert stringify(ForwardRef('str')) == \"str\"\n        assert stringify(ForwardRef('List[int]')) == \"List[int]\"\n        assert stringify(ForwardRef('Tuple[str, str]')) == \"Tuple[str, str]\"\n    else:\n        from sphinx.util.typing import ForwardRef\n        assert stringify(ForwardRef('int')) == \"int\"\n        assert stringify(ForwardRef('str')) == \"str\"\n        assert stringify(ForwardRef('List[int]')) == \"List[int]\"\n        assert stringify(ForwardRef('Tuple[str, str]')) == \"Tuple[str, str]\"\n"], "sample_99": ["def test_trunc_timezone_with_delta(self):\n    start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n    end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n    self.create_model(end_datetime, start_datetime)\n\n    delta_tzinfo_pos = datetime_timezone(timedelta(hours=5))\n    delta_tzinfo_neg = datetime_timezone(timedelta(hours=-5, minutes=17))\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=DateTimeField(), tzinfo=delta_tzinfo_pos)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(delta_tzinfo_pos), kind, delta_tzinfo_pos)),\n                (end_datetime, truncate_to(end_datetime.astimezone(delta_tzinfo_pos), kind, delta_tzinfo_pos))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_date', kind, output_field=DateField(), tzinfo=delta_tzinfo_pos)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.date(), kind)),\n                (end_datetime, truncate_to(end_datetime.date(), kind))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_date_kind('year')\n    test_date_kind('quarter')\n    test_date_kind('month')\n    test_date_kind('week')\n    test_date_kind('day')\n    test_datetime_kind('year')\n    test_datetime_kind('quarter')\n    test_datetime_kind('month')\n    test_datetime_kind('week')\n    test_datetime_kind('day')\n    test_datetime_kind('hour')\n    test_datetime_kind('minute')\n    test_datetime_kind('second')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_time', kind, output_field=TimeField(), tzinfo=delta_tzinfo_pos"], "sample_67": ["    def test_model_form_with_custom_model(self):\n        class CustomModel(models.Model):\n            name = models.CharField(max_length=10)\n\n                return self.name\n\n        class CustomModelForm(forms.ModelForm):\n            class Meta:\n                model = CustomModel\n                fields = '__all__'\n\n        form = CustomModelForm({'name': 'Test'})\n        self.assertTrue(form.is_valid())\n        instance = form.save()\n        self.assertEqual(instance.name, 'Test')\n"], "sample_140": ["    def test_sensitive_variables_called_with_args(self):\n        @sensitive_variables('password', 'credit_card')\n            pass\n        self.assertEqual(test_func.sensitive_variables, ('password', 'credit_card'))\n"], "sample_125": ["    def test_reason_phrase(self):\n        response = HttpResponse()\n        self.assertEqual(response.reason_phrase, 'OK')\n        response.reason_phrase = 'Test Reason'\n        self.assertEqual(response.reason_phrase, 'Test Reason')\n"], "sample_483": ["def test_check_ordering_random_with_other_fields(self):\n    class SongAdmin(admin.ModelAdmin):\n        ordering = [\"?\", \"title\"]\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'ordering' has the random ordering marker '?', but contains \"\n            \"other fields as well.\",\n            obj=SongAdmin,\n            id=\"admin.E032\",\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_169": ["    def test_xml_serialization(self):\n        instance = NullableJSONModel(value={'a': 'b', 'c': None})\n        data = serializers.serialize('xml', [instance], fields=['value'])\n        expected_xml = (\n            '<django-objects version=\"1.0\">'\n            '<object model=\"model_fields.nullablejsonmodel\">'\n            '<field name=\"value\" type=\"JSONField\">{\"a\": \"b\", \"c\": null}</field>'\n            '</object></django-objects>'\n        )\n        self.assertXMLEqual(data, expected_xml)\n"], "sample_458": ["    def test_addslashes(self):\n        output = self.engine.render_to_string(\n            \"addslashes01\", {\"a\": \"Hello, 'world'!\"}\n        )\n        self.assertEqual(output, \"Hello, \\\\'world\\!\\\\\")\n        output = self.engine.render_to_string(\n            \"addslashes02\", {\"b\": mark_safe(\"Hello, 'world'!\")}\n        )\n        self.assertEqual(output, \"Hello, \\\\'world\\!\\\\\")\n"], "sample_1187": ["def test_hyperplane_parameters():\n    triangle = Polygon(Point(0, 3), Point(5, 3), Point(1, 1))\n    assert hyperplane_parameters(triangle) == [((0, 1), 3), ((1, -2), -1), ((-2, -1), -3)]\n\n    cube = [[(0, 0, 0), (0, 0, 5), (0, 5, 0), (0, 5, 5), (5, 0, 0),\\\n             (5, 0, 5), (5, 5, 0), (5, 5, 5)],\\\n            [2, 6, 7, 3], [3, 7, 5, 1], [7, 6, 4, 5], [1, 5, 4, 0],\\\n            [3, 1, 0, 2], [0, 4, 6, 2]]\n    vertices = cube[0]\n    faces = cube[1:]\n    assert hyperplane_parameters(faces, vertices) == [([0, -1, 0], -5), ([0, 0, -1], -5), ([-1, 0, 0], -5),\n                                                    ([0, 1, 0], 0), ([1, 0, 0], 0), ([0, 0, 1], 0)]\n"], "sample_808": ["def test_iforest_predict_with_offset():\n    \"\"\"Test that predict works correctly with offset_\"\"\"\n    X_train = [[1, 1], [1, 2], [2, 1]]\n    clf1 = IsolationForest(contamination=0.1).fit(X_train)\n    clf2 = IsolationForest(contamination=0.5).fit(X_train)\n    assert_array_equal(clf1.predict([[2., 2.]]), clf2.predict([[2., 2.]]))\n"], "sample_867": ["def test_grid_search_with_callable_refit():\n    # Test GridSearchCV with callable refit\n    X, y = make_classification(n_samples=100, n_features=4, random_state=42)\n\n        return cv_results['mean_test_score'].argmin()\n\n    grid_search = GridSearchCV(SVC(random_state=42), {'C': [0.01, 0.1, 1]},\n                               scoring='precision', refit=refit_callable)\n    grid_search.fit(X, y)\n\n    assert grid_search.best_index_ == 0\n    assert not hasattr(grid_search, 'best_score_')\n"], "sample_519": ["def test_subfigure_subplots_adjust():\n    fig = plt.figure(constrained_layout=True)\n    subfig = fig.subfigures(1, 1)\n    ax = subfig.add_subplot(111)\n    ax.plot([1, 2, 3])\n    subfig.subplots_adjust(left=0.2, bottom=0.2, right=0.8, top=0.8)\n    assert ax.get_position().x0 == 0.2\n    assert ax.get_position().y0 == 0.2\n    assert ax.get_position().x1 == 0.8\n    assert ax.get_position().y1 == 0.8\n"], "sample_851": ["def test_mean_poisson_deviance():\n    y_true = np.array([2, 0, 1, 4])\n    y_pred = np.array([0.5, 0.5, 2., 2.])\n    assert_almost_equal(mean_poisson_deviance(y_true, y_pred),\n                        mean_tweedie_deviance(y_true, y_pred, power=1))\n\n    y_true = np.array([2, 0, 1, 4])\n    y_pred = np.array([0.5, 0.5, 2., 2.])\n    sample_weight = np.array([0.1, 0.2, 0.3, 0.4])\n    assert_almost_equal(mean_poisson_deviance(y_true, y_pred, sample_weight),\n                        mean_tweedie_deviance(y_true, y_pred, sample_weight, power=1))\n\n    y_true = np.array([2, 0, 1, 4])\n    y_pred = np.array([-0.5, 0.5, 2., 2.])\n    with pytest.raises(ValueError,\n                       match=\"can only be used on non-negative y_true and \"\n                             \"strictly positive y_pred.\"):\n        mean_poisson_deviance(y_true, y_pred)\n\n    y_true = np.array([2, 0, 1, 4])\n    y_pred = np.array([0.5, 0.5, 2., 2.])\n    with pytest.raises(ValueError,\n                       match=\"Multioutput not supported in mean_poisson_deviance\"):\n        mean_poisson_deviance(y_true[:, np.newaxis], y_pred[:, np.newaxis])\n\n"], "sample_32": ["    def test_de_density_scale(self, cosmo):\n        \"\"\"Test :meth:`astropy.cosmology.w0wzCDM.de_density_scale`.\"\"\"\n        z = 1.0\n        expected = (z + 1.0) ** (3.0 * (1.0 + cosmo.w0 - cosmo.wz)) * np.exp(\n            3.0 * cosmo.wz * z\n        )\n        assert np.allclose(cosmo.de_density_scale(z), expected)\n\n        z = np.array([0.0, 0.5, 1.0, 1.5, 2.3])\n        expected = (z + 1.0) ** (3.0 * (1.0 + cosmo.w0 - cosmo.wz)) * np.exp(\n            3.0 * cosmo.wz * z\n        )\n        assert np.allclose(cosmo.de_density_scale(z), expected)\n"], "sample_945": ["def test_type_to_xref(app):\n    text = \"type_to_xref('int', app.env)\"\n    doctree = eval(text)\n    assert_node(doctree, ([pending_xref, \"int\"],))\n    assert_node(doctree[0], pending_xref, refdomain=\"py\", reftype=\"class\", reftarget=\"int\")\n\n    text = \"type_to_xref('List[int]', app.env)\"\n    doctree = eval(text)\n    assert_node(doctree, ([pending_xref, \"List\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \"]\"]))\n\n    text = \"type_to_xref('Tuple[int, int]', app.env)\"\n    doctree = eval(text)\n    assert_node(doctree, ([pending_xref, \"Tuple\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \", \"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \"]\"]))\n\n    text = \"type_to_xref('Tuple[()]', app.env)\"\n    doctree = eval(text)\n    assert_node(doctree, ([pending_xref, \"Tuple\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [desc_sig_punctuation, \"(\"],\n                          [desc_sig_punctuation, \")\"],\n                          [desc_sig_punctuation, \"]\"]))\n\n    text = \"type_to_xref('Tuple[int, ...]', app.env)\"\n    doctree = eval(text)\n    assert_node(doctree, ([pending_xref, \"Tuple\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \", \"],\n                          [desc_sig_punctuation, \"...\"],\n                          [desc_sig_punctuation, \"]\"]))\n\n    text = \"type_to_xref('Callable[[int, int], int]', app.env)\"\n    doctree = eval(text)\n    assert_node(doctree, ([pending_xref, \"Callable\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \", \"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \"]\"],\n                          [desc_sig_punctuation, \", \"],\n                          [pending_xref, \"int\"],\n                         "], "sample_90": ["    def test_custom_model_metaclass(self):\n        class CustomModelMeta(type):\n                attrs['custom_meta_attr'] = 'custom_meta_value'\n                return super().__new__(cls, name, bases, attrs)\n\n        class CustomModel(metaclass=CustomModelMeta):\n            pass\n\n        class CustomModelForm(forms.ModelForm):\n            class Meta:\n                model = CustomModel\n                fields = '__all__'\n\n        self.assertEqual(CustomModelForm._meta.custom_meta_attr, 'custom_meta_value')\n"], "sample_15": ["    def test_quantity_subclass(self):\n        q = u.Quantity(1, u.m)\n        assert q.__quantity_subclass__(u.m) == (u.Quantity, True)\n        assert q.__quantity_subclass__(u.kg) == (u.Quantity, False)\n"], "sample_1083": ["def test_hyperbolic_functions_with_complex_symbols():\n    x, y = symbols('x y', complex=True)\n    assert sinh(x + y).as_real_imag(deep=False) == (sinh(x)*cos(y) + cosh(x)*sin(y), cosh(x)*cos(y) + sinh(x)*sin(y))\n    assert cosh(x + y).as_real_imag(deep=False) == (cosh(x)*cos(y) + sinh(x)*sin(y), sinh(x)*cos(y) + cosh(x)*sin(y))\n    assert tanh(x + y).as_real_imag(deep=False) == (sinh(x)*cosh(x)/(cos(y)**2 + sinh(x)**2) + sin(y)*cos(y)/(cos(y)**2 + sinh(x)**2), sin(y)*cos(y)/(cos(y)**2 + sinh(x)**2) - sinh(x)*cosh(x)/(cos(y)**2 + sinh(x)**2))\n    assert coth(x + y).as_real_imag(deep=False) == (sinh(x)*cosh(x)/(sin(y)**2 + sinh(x)**2) - sin(y)*cos(y)/(sin(y)**2 + sinh(x)**2), -sin(y)*cos(y)/(sin(y)**2 + sinh(x)**2) - sinh(x)*cosh(x)/(sin(y)**2 + sinh(x)**2))\n    assert csch(x + y).as_real_imag(deep=False) == (cos(y)*sinh(x)/(sin(y)**2*cosh(x)**2 + cos(y)**2*sinh(x)**2) - sin(y)*cosh(x)/(sin(y)**2*cosh(x)**2 + cos(y)**2*sinh(x)**2), -sin(y)*cosh(x)/(sin(y)**2*cosh(x)**2 + cos(y)**2*sinh(x)**2) - cos(y)*sinh(x)/(sin(y)**2*cosh(x)**2 + cos(y)**2*sinh(x)**2))\n    assert sech(x + y).as_real_imag(deep=False) == (cos(y)*cosh(x)/(sin(y)**2*sinh(x)**2 + cos(y)**2*cosh(x)**2) - sin(y)*sinh(x)/(sin(y)**2*sinh(x)**2 + cos(y)**2*cosh(x)**2), -sin(y)*sinh(x)/(sin(y)**2*sinh(x)**2 + cos(y)**2*c"], "sample_295": ["    def setUpTestData(cls):\n        cls.n1 = Number.objects.create(integer=1, float=1.0)\n        cls.n2 = Number.objects.create(integer=2, float=2.0)\n        cls.n3 = Number.objects.create(integer=3, float=3.0)\n        cls.n4 = Number.objects.create(integer=4, float=4.0)\n        cls.n5 = Number.objects.create(integer=5, float=5.0)\n"], "sample_507": ["    def test_convert_empty(self):\n        cc = cat.StrCategoryConverter()\n        unit = cat.UnitData()\n        ax = FakeAxis(unit)\n        np.testing.assert_allclose(cc.convert([], unit, ax), [])\n"], "sample_136": ["def test_get_signed_cookie(self):\n    request = HttpRequest()\n    request.COOKIES = {'signed_cookie': 'signed_value'}\n    with self.assertRaises(KeyError):\n        request.get_signed_cookie('signed_cookie')\n\n    request.COOKIES = {'signed_cookie': 'YmFzZTY0IG1lc3NhZ2U='}\n    self.assertEqual(request.get_signed_cookie('signed_cookie', salt='salt'), 'base64 message')\n\n    request.COOKIES = {'signed_cookie': 'YmFzZTY0IG1lc3NhZ2U='}\n    with self.assertRaises(signing.BadSignature):\n        request.get_signed_cookie('signed_cookie', salt='wrong_salt')\n\n    request.COOKIES = {'signed_cookie': 'YmFzZTY0IG1lc3NhZ2U='}\n    self.assertEqual(request.get_signed_cookie('signed_cookie', default='default', salt='wrong_salt'), 'default')\n"], "sample_25": ["def test_record_valued_keyword_cards_with_hierarch_keywords(self):\n    \"\"\"\n    Regression test for https://github.com/astropy/astropy/issues/11485\n\n    Ensures that record-valued keyword cards can be used with HIERARCH keywords.\n    \"\"\"\n\n    h = fits.Header()\n    h[\"HIERARCH DP1.NAXIS\"] = 2\n    h[\"HIERARCH DP1.AXIS.1\"] = 1\n    h[\"HIERARCH DP1.AXIS.2\"] = 2\n\n    assert h[\"DP1.NAXIS\"] == 2.0\n    assert h[\"DP1.AXIS.1\"] == 1.0\n    assert h[\"DP1.AXIS.2\"] == 2.0\n\n    h[\"HIERARCH DP1.NAXIS\"] = 3\n    assert h[\"DP1.NAXIS\"] == 3.0\n\n    h[\"HIERARCH DP1.AXIS.3\"] = 3\n    assert h[\"DP1.AXIS.3\"] == 3.0\n"], "sample_684": ["    def test_cut(self) -> None:\n        try:\n                f2()\n\n                f3()\n\n                assert False\n\n            f1()\n        except AssertionError:\n            exci = ExceptionInfo.from_current()\n            tb = exci.traceback\n            assert len(tb) == 4\n            cut_tb = tb.cut(path=\"test_code.py\")\n            assert len(cut_tb) == 3\n            cut_tb = tb.cut(lineno=tb[0].lineno)\n            assert len(cut_tb) == 1\n            cut_tb = tb.cut(firstlineno=tb[0].frame.code.firstlineno)\n            assert len(cut_tb) == 1\n            cut_tb = tb.cut(excludepath=py.path.local(__file__))\n            assert len(cut_tb) == 0\n"], "sample_657": ["def test_parameter_set_extract_from(testdir):\n    from _pytest.mark import ParameterSet\n\n    # Test that extract_from works correctly with different types of input\n    assert ParameterSet.extract_from((1, 2, 3)) == ParameterSet((1, 2, 3), [], None)\n    assert ParameterSet.extract_from(ParameterSet((1, 2, 3), [], None)) == ParameterSet((1, 2, 3), [], None)\n    assert ParameterSet.extract_from((1, 2, 3), force_tuple=True) == ParameterSet((1, 2, 3), [], None)\n    assert ParameterSet.extract_from(ParameterSet((1, 2, 3), [], None), force_tuple=True) == ParameterSet((1, 2, 3), [], None)\n\n    # Test that extract_from raises an error when given an invalid input type\n    with pytest.raises(TypeError):\n        ParameterSet.extract_from(\"invalid input\")\n\n    # Test that extract_from works correctly with a single argument tuple\n    assert ParameterSet.extract_from((1,), force_tuple=True) == ParameterSet((1,), [], None)\n    assert ParameterSet.extract_from(ParameterSet((1,), [], None), force_tuple=True) == ParameterSet((1,), [], None)\n"], "sample_1091": ["def test_relational_properties():\n    # Test that the properties of Relational objects are correctly set\n    rel = Relational(x, y, '==')\n    assert rel.is_Relational\n    assert not rel.is_Equality\n    assert not rel.is_Unequality\n    assert not rel.is_GreaterThan\n    assert not rel.is_LessThan\n    assert not rel.is_StrictGreaterThan\n    assert not rel.is_StrictLessThan\n\n    rel = Equality(x, y)\n    assert rel.is_Relational\n    assert rel.is_Equality\n    assert not rel.is_Unequality\n    assert not rel.is_GreaterThan\n    assert not rel.is_LessThan\n    assert not rel.is_StrictGreaterThan\n    assert not rel.is_StrictLessThan\n\n    rel = Unequality(x, y)\n    assert rel.is_Relational\n    assert not rel.is_Equality\n    assert rel.is_Unequality\n    assert not rel.is_GreaterThan\n    assert not rel.is_LessThan\n    assert not rel.is_StrictGreaterThan\n    assert not rel.is_StrictLessThan\n\n    rel = GreaterThan(x, y)\n    assert rel.is_Relational\n    assert not rel.is_Equality\n    assert not rel.is_Unequality\n    assert rel.is_GreaterThan\n    assert not rel.is_LessThan\n    assert not rel.is_StrictGreaterThan\n    assert not rel.is_StrictLessThan\n\n    rel = LessThan(x, y)\n    assert rel.is_Relational\n    assert not rel.is_Equality\n    assert not rel.is_Unequality\n    assert not rel.is_GreaterThan\n    assert rel.is_LessThan\n    assert not rel.is_StrictGreaterThan\n    assert not rel.is_StrictLessThan\n\n    rel = StrictGreaterThan(x, y)\n    assert rel.is_Relational\n    assert not rel.is_Equality\n    assert not rel.is_Unequality\n    assert not rel.is_GreaterThan\n    assert not rel.is_LessThan\n    assert rel.is_StrictGreaterThan\n    assert not rel.is_StrictLessThan\n\n    rel = StrictLessThan(x, y)\n    assert rel.is_Relational\n    assert not rel.is_Equality\n    assert not rel.is_Unequality\n    assert not rel.is_GreaterThan\n    assert not rel.is_LessThan\n    assert not rel.is_StrictGreaterThan\n    assert rel.is_StrictLessThan\n"], "sample_789": ["def test_adaboost_regressor_with_dummy_estimator():\n    # Test AdaBoostRegressor with a dummy estimator that doesn't support\n    # sample weights.\n    X, y = datasets.make_regression(n_samples=100, n_features=10,\n                                    n_informative=3, random_state=42)\n    clf = AdaBoostRegressor(base_estimator=DummyEstimator(), random_state=0)\n    clf.fit(X, y)\n    assert clf.score(X, y) >= 0\n"], "sample_690": ["def test_xfail_strict_with_unraisable_exception(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(strict=True)\n            raise SystemExit(1)\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-rxX\")\n    result.stdout.fnmatch_lines([\"*XPASS(strict)*\"])\n    assert result.ret == 0\n"], "sample_708": ["def test_getstatementrange_with_nested_blocks() -> None:\n    source = Source(\n        \"\"\"\\\n        if True:\n            if False:\n                pass\n            else:\n                if True:\n                    pass\n                else:\n                    pass\n        \"\"\"\n    )\n    assert source.getstatementrange(2) == (1, 3)\n    assert source.getstatementrange(4) == (3, 7)\n    assert source.getstatementrange(6) == (5, 7)\n"], "sample_856": ["def test_leave_p_out():\n    # Test LeavePOut with different values of p\n    X = np.arange(10)\n    y = np.arange(10)\n    for p in range(1, 11):\n        lpo = LeavePOut(p)\n        splits = list(lpo.split(X, y))\n        assert len(splits) == comb(10, p)\n        for train, test in splits:\n            assert len(test) == p\n            assert len(train) == 10 - p\n            assert_array_equal(np.intersect1d(train, test), [])\n"], "sample_751": ["def test_random_forest_classifier():\n    # Test random forest classifier\n    X, y = datasets.make_classification(n_samples=100, n_features=10,\n                                        n_informative=3, n_redundant=0,\n                                        n_repeated=0, shuffle=False,\n                                        random_state=1)\n\n    clf = RandomForestClassifier(n_estimators=10, random_state=1)\n    clf.fit(X, y)\n\n    assert_array_equal(clf.predict(X), y)\n\n    # Test oob_score\n    clf = RandomForestClassifier(n_estimators=10, oob_score=True,\n                                 random_state=1)\n    clf.fit(X, y)\n    assert clf.oob_score_ > 0.9\n\n    # Test warm_start\n    clf = RandomForestClassifier(n_estimators=10, warm_start=True,\n                                 random_state=1)\n    clf.fit(X, y)\n    clf.n_estimators = 20\n    clf.fit(X, y)\n    assert len(clf.estimators_) == 20\n\n    # Test class_weight\n    clf = RandomForestClassifier(n_estimators=10, class_weight='balanced',\n                                 random_state=1)\n    clf.fit(X, y)\n    assert clf.oob_score_ > 0.9\n\n    # Test max_features\n    clf = RandomForestClassifier(n_estimators=10, max_features='auto',\n                                 random_state=1)\n    clf.fit(X, y)\n    assert clf.oob_score_ > 0.9\n\n    # Test min_samples_split\n    clf = RandomForestClassifier(n_estimators=10, min_samples_split=2,\n                                 random_state=1)\n    clf.fit(X, y)\n    assert clf.oob_score_ > 0.9\n\n    # Test min_samples_leaf\n    clf = RandomForestClassifier(n_estimators=10, min_samples_leaf=1,\n                                 random_state=1)\n    clf.fit(X, y)\n    assert clf.oob_score_ > 0.9\n\n    # Test min_weight_fraction_leaf\n    clf = RandomForestClassifier(n_estimators=10,\n                                 min_weight_fraction_leaf=0.1,\n                                 random_state=1)\n    clf.fit(X, y)\n    assert clf.oob_score_ > 0.9\n\n    # Test max_leaf_nodes\n    clf = RandomForestClassifier(n_estimators=10, max_leaf_nodes=10,\n                                 random_state=1)\n    clf.fit(X, y)\n    assert clf.oob_score_ > 0.9\n\n    # Test min_impurity_decrease\n"], "sample_529": ["def test_legend_draggable_update():\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label='shabnams')\n    leg = ax.legend(draggable=True)\n    assert leg.get_draggable()\n    leg.set_draggable(False, update='loc')\n    assert not leg.get_draggable()\n    leg.set_draggable(True, update='bbox')\n    assert leg.get_draggable()\n"], "sample_222": ["    def test_lock_unlock(self):\n        with tempfile.TemporaryFile() as f:\n            self.assertIs(locks.lock(f, locks.LOCK_EX), True)\n            self.assertIs(locks.unlock(f), True)\n"], "sample_1053": ["def test_issue_10368():\n    a = S(32442016954)/78058255275\n    assert type(int(a)) is type(int(-a)) is int\n    assert type(long(a)) is type(long(-a)) is long\n"], "sample_852": ["def test_make_classification_n_repeated():\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=5,\n                               n_redundant=1, n_repeated=1, n_classes=3,\n                               n_clusters_per_class=1, hypercube=False,\n                               shift=None, scale=None, random_state=0)\n\n    assert X.shape == (100, 20), \"X shape mismatch\"\n    assert y.shape == (100,), \"y shape mismatch\"\n    assert np.unique(y).shape == (3,), \"Unexpected number of classes\"\n\n    # Test that the repeated features are identical to the informative ones\n    assert_array_almost_equal(X[:, 6], X[:, 0])\n"], "sample_971": ["def test_prefixed_warnings(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    logger.warning('message1')\n    with logging.prefixed_warnings('prefix: '):\n        logger.warning('message2')\n        logger.warning('message3')\n\n    assert 'WARNING: message1' in warning.getvalue()\n    assert 'prefix: WARNING: message2' in warning.getvalue()\n    assert 'prefix: WARNING: message3' in warning.getvalue()\n"], "sample_502": ["def test_subplot2grid():\n    fig, ax = plt.subplots()\n    ax1 = plt.subplot2grid((2, 2), (0, 0))\n    ax2 = plt.subplot2grid((2, 2), (0, 1))\n    ax3 = plt.subplot2grid((2, 2), (1, 0), colspan=2)\n    assert ax1 is plt.gca()\n    assert ax2 is plt.subplot2grid((2, 2), (0, 1))\n    assert ax3 is plt.subplot2grid((2, 2), (1, 0), colspan=2)\n    assert ax1 is not ax2\n    assert ax1 is not ax3\n    assert ax2 is not ax3\n    assert ax1 not in fig.axes\n    assert ax2 not in fig.axes\n    assert ax3 in fig.axes\n"], "sample_207": ["    def test_custom_encoder_decoder(self):\n        value = {'uuid': uuid.UUID('{d85e2076-b67c-4ee7-8c3a-2bf5a2cc2475}')}\n        obj = NullableJSONModel(value_custom=value)\n        obj.save()\n        obj.refresh_from_db()\n        self.assertEqual(obj.value_custom, value)\n"], "sample_250": ["def test_time_format(self):\n    my_birthday = datetime(1979, 7, 8, 22, 00)\n\n    self.assertEqual(dateformat.time_format(my_birthday, 'a'), 'p.m.')\n    self.assertEqual(dateformat.time_format(my_birthday, 'A'), 'PM')\n    self.assertEqual(dateformat.time_format(my_birthday, 'f'), '10:00')\n    self.assertEqual(dateformat.time_format(my_birthday, 'g'), '10')\n    self.assertEqual(dateformat.time_format(my_birthday, 'G'), '22')\n    self.assertEqual(dateformat.time_format(my_birthday, 'h'), '10')\n    self.assertEqual(dateformat.time_format(my_birthday, 'H'), '22')\n    self.assertEqual(dateformat.time_format(my_birthday, 'i'), '00')\n    self.assertEqual(dateformat.time_format(my_birthday, 'P'), '10 p.m.')\n    self.assertEqual(dateformat.time_format(my_birthday, 's'), '00')\n    self.assertEqual(dateformat.time_format(my_birthday, 'u'), '000000')\n"], "sample_106": ["    def tearDown(self):\n        cache.clear()\n"], "sample_166": ["    def test_get_random_string_length(self):\n        length = 20\n        random_string = get_random_string(length)\n        self.assertEqual(len(random_string), length)\n"], "sample_769": ["def test_multilabel_confusion_matrix_multilabel_with_sample_weight():\n    # Test multilabel confusion matrix - multilabel-indicator case\n    from scipy.sparse import csc_matrix, csr_matrix\n\n    y_true = np.array([[1, 0, 1], [0, 1, 0], [1, 1, 0]])\n    y_pred = np.array([[1, 0, 0], [0, 1, 1], [0, 0, 1]])\n    y_true_csr = csr_matrix(y_true)\n    y_pred_csr = csr_matrix(y_pred)\n    y_true_csc = csc_matrix(y_true)\n    y_pred_csc = csc_matrix(y_pred)\n\n    # cross test different types\n    sample_weight = np.array([2, 1, 3])\n    real_cm = [[[1, 0], [1, 1]],\n               [[1, 0], [1, 1]],\n               [[0, 2], [1, 0]]]\n    trues = [y_true, y_true_csr, y_true_csc]\n    preds = [y_pred, y_pred_csr, y_pred_csc]\n\n    for y_true_tmp in trues:\n        for y_pred_tmp in preds:\n            cm = multilabel_confusion_matrix(y_true_tmp, y_pred_tmp,\n                                             sample_weight=sample_weight)\n            assert_array_equal(cm, real_cm)\n\n    # test support for samplewise\n    cm = multilabel_confusion_matrix(y_true, y_pred, sample_weight=sample_weight,\n                                     samplewise=True)\n    assert_array_equal(cm, [[[1, 0], [1, 2]],\n                            [[1, 1], [0, 1]],\n                            [[0, 3], [2, 0]]])\n\n    # test support for labels\n    cm = multilabel_confusion_matrix(y_true, y_pred, labels=[2, 0],\n                                     sample_weight=sample_weight)\n    assert_array_equal(cm, [[[0, 2], [1, 0]],\n                            [[1, 0], [1, 1]]])\n\n    # test support for labels with samplewise\n    cm = multilabel_confusion_matrix(y_true, y_pred, labels=[2, 0],\n                                     sample_weight=sample_weight,\n                                     samplewise=True)\n    assert_array_equal(cm, [[[0, 0], ["], "sample_1127": ["def test_polycyclic_group():\n    # Test polycyclic group for cyclic group\n    G = CyclicGroup(10)\n    pc_group = G.polycyclic_group()\n    assert pc_group.order() == G.order()\n\n    # Test polycyclic group for abelian group\n    G = AbelianGroup(2, 3, 4)\n    pc_group = G.polycyclic_group()\n    assert pc_group.order() == G.order()\n\n    # Test polycyclic group for dihedral group\n    G = DihedralGroup(10)\n    pc_group = G.polycyclic_group()\n    assert pc_group.order() == G.order()\n\n    # Test polycyclic group for symmetric group\n    G = SymmetricGroup(4)\n    pc_group = G.polycyclic_group()\n    assert pc_group.order() == G.order()\n\n    # Test polycyclic group for alternating group\n    G = AlternatingGroup(4)\n    pc_group = G.polycyclic_group()\n    assert pc_group.order() == G.order()\n"], "sample_296": ["def test_safedata(self):\n    \"\"\"\n    A message containing SafeData is keeping its safe status when\n    retrieved from the message storage.\n    \"\"\"\n        message = Message(constants.DEBUG, data)\n        encoded = storage._encode([message])\n        decoded = storage._decode(encoded)\n        return decoded[0].message\n\n    storage = self.get_storage()\n    data = mark_safe('<p>Test message</p>')\n    self.assertIsInstance(encode_decode(data), SafeData)\n    self.assertEqual(encode_decode(data), data)\n\n    data = '<p>Test message</p>'\n    self.assertNotIsInstance(encode_decode(data), SafeData)\n    self.assertEqual(encode_decode(data), data)\n"], "sample_748": ["def test_grid_search_cv_results_multimetric_with_sample_weight():\n    X, y = make_classification(n_samples=50, n_features=4, random_state=42)\n\n    n_splits = 3\n    params = [dict(kernel=['rbf', ], C=[1, 10], gamma=[0.1, 1]),\n              dict(kernel=['poly', ], degree=[1, 2])]\n\n    sample_weight = np.random.RandomState(0).randint(1, 10, size=50)\n\n    for iid in (False, True):\n        grid_searches = []\n        for scoring in ({'accuracy': make_scorer(accuracy_score),\n                         'recall': make_scorer(recall_score)},\n                        'accuracy', 'recall'):\n            grid_search = GridSearchCV(SVC(gamma='scale'), cv=n_splits,\n                                       iid=iid, param_grid=params,\n                                       scoring=scoring, refit=False)\n            grid_search.fit(X, y, sample_weight=sample_weight)\n            assert_equal(grid_search.iid, iid)\n            grid_searches.append(grid_search)\n\n        compare_cv_results_multimetric_with_single(*grid_searches, iid=iid)\n"], "sample_439": ["def test_boundfield_render_with_custom_renderer(self):\n    class CustomRenderer(DjangoTemplates):\n        form_template_name = \"forms_tests/form_snippet.html\"\n\n    class Person(Form):\n        first_name = CharField()\n        renderer = CustomRenderer()\n\n    t = Template(\"{{ form }}\")\n    html = t.render(Context({\"form\": Person()}))\n    expected = \"\"\"\n    <div class=\"fieldWrapper\"><label for=\"id_first_name\">First name:</label>\n    <input type=\"text\" name=\"first_name\" required id=\"id_first_name\"></div>\n    \"\"\"\n    self.assertHTMLEqual(html, expected)\n"], "sample_445": ["def test_time_strings_customization(self):\n    \"\"\"Test that time_strings can be customized.\"\"\"\n    custom_time_strings = {\n        \"year\": ngettext_lazy(\"%(num)d year\", \"%(num)d years\", \"num\"),\n        \"month\": ngettext_lazy(\"%(num)d month\", \"%(num)d months\", \"num\"),\n        \"week\": ngettext_lazy(\"%(num)d week\", \"%(num)d weeks\", \"num\"),\n        \"day\": ngettext_lazy(\"%(num)d day\", \"%(num)d days\", \"num\"),\n        \"hour\": ngettext_lazy(\"%(num)d hour\", \"%(num)d hours\", \"num\"),\n        \"minute\": ngettext_lazy(\"%(num)d minute\", \"%(num)d minutes\", \"num\"),\n    }\n    custom_time_strings[\"year\"] = ngettext_lazy(\"%(num)d year\", \"%(num)d years\", \"num\")\n    custom_time_strings[\"month\"] = ngettext_lazy(\"%(num)d month\", \"%(num)d months\", \"num\")\n    custom_time_strings[\"week\"] = ngettext_lazy(\"%(num)d week\", \"%(num)d weeks\", \"num\")\n    custom_time_strings[\"day\"] = ngettext_lazy(\"%(num)d day\", \"%(num)d days\", \"num\")\n    custom_time_strings[\"hour\"] = ngettext_lazy(\"%(num)d hour\", \"%(num)d hours\", \"num\")\n    custom_time_strings[\"minute\"] = ngettext_lazy(\"%(num)d minute\", \"%(num)d minutes\", \"num\")\n\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneminute, time_strings=custom_time_strings),\n        \"1\\xa0minute\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.onehour, time_strings=custom_time_strings),\n        \"1\\xa0hour\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneday, time_strings=custom_time_strings),\n        \"1\\xa0day\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneweek, time_strings=custom_time_strings),\n        \"1\\xa0week\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.onemonth, time_strings=custom_time_strings),\n        \"1\\xa0month\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneyear, time_strings=custom_time_strings),\n        \""], "sample_268": ["    def test_empty_paths(self):\n        self.assertEqual(autoreload.common_roots(()), ())\n"], "sample_599": ["def test_UnsignedIntegerCoder_encode():\n    original = xr.Variable((\"x\",), np.arange(10, dtype=np.uint8), encoding={\"_Unsigned\": \"true\"})\n    coder = variables.UnsignedIntegerCoder()\n    encoded = coder.encode(original)\n    expected = xr.Variable((\"x\",), np.arange(10, dtype=np.int8), encoding={})\n    assert_identical(encoded, expected)\n\n"], "sample_229": ["def test_union_with_values_and_order_by_annotation(self):\n    ReservedName.objects.create(name='a', order=2)\n    qs1 = ReservedName.objects.annotate(alias=F('order')).values('name', 'alias')\n    qs2 = ReservedName.objects.annotate(alias=F('order')).values('name', 'alias')\n    self.assertEqual(\n        list(qs1.union(qs2).order_by('-alias')),\n        [{'name': 'a', 'alias': 2}, {'name': 'a', 'alias': 2}],\n    )\n    self.assertEqual(\n        list(qs1.union(qs2).order_by('alias')),\n        [{'name': 'a', 'alias': 2}, {'name': 'a', 'alias': 2}],\n    )\n"], "sample_1108": ["def test_least_rotation():\n    assert least_rotation([3, 1, 5, 1, 2]) == 3\n    assert rotate_left([3, 1, 5, 1, 2], 3) == [1, 2, 3, 1, 5]\n    assert least_rotation([1, 2, 3, 4, 5]) == 0\n    assert least_rotation([5, 4, 3, 2, 1]) == 4\n    assert least_rotation([1, 1, 1, 1, 1]) == 0\n    assert least_rotation([1, 2, 3, 4, 5, 6]) == 0\n    assert least_rotation([6, 5, 4, 3, 2, 1]) == 5\n    assert least_rotation([1, 2, 3, 4, 5, 6, 7]) == 0\n    assert least_rotation([7, 6, 5, 4, 3, 2, 1]) == 6\n"], "sample_946": ["def test_type_to_xref(app):\n    text = \"List[int]\"\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"List\"],\n                          [pending_xref_condition, \"List\"],\n                          [pending_xref_condition, \"List[int]\"]))\n    assert_node(doctree[0], pending_xref, refdomain=\"py\", reftype=\"class\", reftarget=\"List\")\n    assert_node(doctree[1], pending_xref_condition, condition=\"resolved\")\n    assert_node(doctree[2], pending_xref_condition, condition=\"*\")\n\n    text = \"List[int, str]\"\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"List\"],\n                          [pending_xref_condition, \"List\"],\n                          [pending_xref_condition, \"List[int, str]\"]))\n    assert_node(doctree[0], pending_xref, refdomain=\"py\", reftype=\"class\", reftarget=\"List\")\n    assert_node(doctree[1], pending_xref_condition, condition=\"resolved\")\n    assert_node(doctree[2], pending_xref_condition, condition=\"*\")\n\n    text = \"List[int | str]\"\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"List\"],\n                          [pending_xref_condition, \"List\"],\n                          [pending_xref_condition, \"List[int | str]\"]))\n    assert_node(doctree[0], pending_xref, refdomain=\"py\", reftype=\"class\", reftarget=\"List\")\n    assert_node(doctree[1], pending_xref_condition, condition=\"resolved\")\n    assert_node(doctree[2], pending_xref_condition, condition=\"*\")\n\n    text = \"List[int, ...]\"\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"List\"],\n                          [pending_xref_condition, \"List\"],\n                          [pending_xref_condition, \"List[int, ...]\"]))\n    assert_node(doctree[0], pending_xref, refdomain=\"py\", reftype=\"class\", reftarget=\"List\")\n    assert_node(doctree[1], pending_xref_condition, condition=\"resolved\")\n    assert_node(doctree[2], pending_xref_condition, condition"], "sample_1150": ["def test_ComplexRegion_polar_intersect():\n    # Polar form\n    c1 = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)\n    c2 = ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    c3 = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi), polar=True)\n    c4 = ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n\n    assert c1.intersect(c2) == c2\n    assert c3.intersect(c4) == c4\n    assert c1.intersect(c3) == c1\n    assert c2.intersect(c4) == S.EmptySet\n\n    # Rectangular form\n    c5 = ComplexRegion(Interval(2, 5)*Interval(6, 9))\n    c6 = ComplexRegion(Interval(4, 6)*Interval(10, 12))\n    c7 = ComplexRegion(Interval(0, 10)*Interval(-10, 0))\n    c8 = ComplexRegion(Interval(12, 16)*Interval(14, 20))\n\n    assert c5.intersect(c6) == S.EmptySet\n    assert c7.intersect(c8) == S.EmptySet\n    assert c5.intersect(c7) == S.EmptySet\n    assert c6.intersect(c8) == S.EmptySet\n\n    # Polar and Rectangular form\n    c9 = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)\n    c10 = ComplexRegion(Interval(2, 5)*Interval(6, 9))\n\n    assert c9.intersect(c10) == Intersection(c9, c10, evaluate=False)\n    assert c10.intersect(c9) == Intersection(c10, c9, evaluate=False)\n"], "sample_565": ["def test_inset_axes_with_bbox_transform():\n    fig, ax = plt.subplots(figsize=[5, 4])\n\n    # prepare the demo image\n    # Z is a 15x15 array\n    Z = cbook.get_sample_data(\"axes_grid/bivariate_normal.npy\")\n    extent = (-3, 4, -4, 3)\n    Z2 = np.zeros((150, 150))\n    ny, nx = Z.shape\n    Z2[30:30+ny, 30:30+nx] = Z\n\n    ax.imshow(Z2, extent=extent, interpolation=\"nearest\",\n              origin=\"lower\")\n\n    # creating our inset axes with a bbox_transform parameter\n    axins = inset_axes(ax, width=\"30%\", height=\"40%\",\n                       bbox_to_anchor=(0.5, 0.5, 0.5, 0.5),\n                       bbox_transform=ax.transAxes)\n\n    axins.imshow(Z2, extent=extent, interpolation=\"nearest\",\n                 origin=\"lower\")\n    axins.yaxis.get_major_locator().set_params(nbins=7)\n    axins.xaxis.get_major_locator().set_params(nbins=7)\n    # sub region of the original image\n    x1, x2, y1, y2 = -1.5, -0.9, -2.5, -1.9\n    axins.set_xlim(x1, x2)\n    axins.set_ylim(y1, y2)\n\n    plt.xticks(visible=False)\n    plt.yticks(visible=False)\n\n    # draw a bbox of the region of the inset axes in the parent axes and\n    # connecting lines between the bbox and the inset axes area\n    mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n\n    asb = AnchoredSizeBar(ax.transData,\n                          0.5,\n                          '0.5',\n                          loc='lower center',\n                          pad=0.1, borderpad=0.5, sep=5,\n                          frameon=False)\n    ax.add_artist(asb)\n\n    fig.canvas.draw()\n    assert_array_almost_equal(\n        axins.get_position().extents,\n        [0.35, 0.3, 0.45, 0.5])\n"], "sample_910": ["def test_prefixed_warnings(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    with logging.prefixed_warnings('prefix: '):\n        logger.warning('message1')\n        logger.warning('message2')\n\n    assert 'prefix: WARNING: message1' in warning.getvalue()\n    assert 'prefix: WARNING: message2' in warning.getvalue()\n\n    # nested prefix\n    with logging.prefixed_warnings('prefix1: '):\n        logger.warning('message3')\n        with logging.prefixed_warnings('prefix2: '):\n            logger.warning('message4')\n\n    assert 'prefix1: WARNING: message3' in warning.getvalue()\n    assert 'prefix1: prefix2: WARNING: message4' in warning.getvalue()\n"], "sample_951": ["def test_isabstractmethod():\n    class AbstractClass:\n        @abstractmethod\n            pass\n\n    class ConcreteClass(AbstractClass):\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(ConcreteClass.abstract_method) is False\n"], "sample_783": ["def test_imputation_constant_fill_value_error_invalid_type(X_data, missing_value):\n    # Verify that exceptions are raised on invalid fill_value type\n    X = np.full((3, 5), X_data, dtype=object)\n    X[0, 0] = missing_value\n\n    with pytest.raises(ValueError, match=\"imputing object\"):\n        imputer = SimpleImputer(missing_values=missing_value,\n                                strategy=\"constant\",\n                                fill_value=1)\n        imputer.fit_transform(X)\n"], "sample_173": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_475": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n"], "sample_1051": ["def test_dotprint_atom():\n    text = dotprint(x+2, atom=lambda x: not x.is_Atom)\n    assert all(e in text for e in dotedges(x+2, atom=lambda x: not x.is_Atom))\n    assert all(n in text for n in [dotnode(expr) for expr in (x, Integer(2), x+2)])\n    assert 'digraph' in text\n    text = dotprint(x+x**2, atom=lambda x: not x.is_Atom)\n    assert all(e in text for e in dotedges(x+x**2, atom=lambda x: not x.is_Atom))\n    assert all(n in text for n in [dotnode(expr) for expr in (x, Integer(2), x**2, x+x**2)])\n    assert 'digraph' in text\n"], "sample_366": ["    def test_iso8601_duration(self):\n        test_values = (\n            ('P1D', timedelta(days=1)),\n            ('P1DT1H', timedelta(days=1, hours=1)),\n            ('P1DT1H1M', timedelta(days=1, hours=1, minutes=1)),\n            ('P1DT1H1M1S', timedelta(days=1, hours=1, minutes=1, seconds=1)),\n            ('P1DT1H1M1.1S', timedelta(days=1, hours=1, minutes=1, seconds=1, milliseconds=100)),\n            ('P1DT1H1M1,1S', timedelta(days=1, hours=1, minutes=1, seconds=1, milliseconds=100)),\n            ('PT1H1M1S', timedelta(hours=1, minutes=1, seconds=1)),\n            ('PT1H1M1.1S', timedelta(hours=1, minutes=1, seconds=1, milliseconds=100)),\n            ('PT1H1M1,1S', timedelta(hours=1, minutes=1, seconds=1, milliseconds=100)),\n            ('PT1M1S', timedelta(minutes=1, seconds=1)),\n            ('PT1M1.1S', timedelta(minutes=1, seconds=1, milliseconds=100)),\n            ('PT1M1,1S', timedelta(minutes=1, seconds=1, milliseconds=100)),\n            ('PT1S', timedelta(seconds=1)),\n            ('PT1.1S', timedelta(seconds=1, milliseconds=100)),\n            ('PT1,1S', timedelta(seconds=1, milliseconds=100)),\n            ('-P1D', timedelta(days=-1)),\n            ('-P1DT1H', timedelta(days=-1, hours=-1)),\n            ('-P1DT1H1M', timedelta(days=-1, hours=-1, minutes=-1)),\n            ('-P1DT1H1M1S', timedelta(days=-1, hours=-1, minutes=-1, seconds=-1)),\n            ('-P1DT1H1M1.1S', timedelta(days=-1, hours=-1, minutes=-1, seconds=-1, milliseconds=-100)),\n            ('-P1DT1H1M1,1S', timedelta(days=-1, hours=-1, minutes=-"], "sample_163": ["    def test_login_view_with_custom_success_url_allowed_hosts(self):\n        class CustomLoginView(LoginView):\n            success_url_allowed_hosts = {\"customhost.com\"}\n\n        response = self.client.post(\n            \"/login/custom_success_url_allowed_hosts/\",\n            {\n                \"username\": \"testclient\",\n                \"password\": \"password\",\n                \"next\": \"https://customhost.com/home\",\n            },\n        )\n        self.assertIn(SESSION_KEY, self.client.session)\n        self.assertRedirects(\n            response, \"https://customhost.com/home\", fetch_redirect_response=False\n        )\n"], "sample_510": ["def test_xkcd_context_manager():\n    with plt.xkcd():\n        fig = plt.figure()\n        assert fig.get_label() == 'xkcd'\n    fig = plt.figure()\n    assert fig.get_label() != 'xkcd'\n"], "sample_393": ["    def test_build_file_cleanup(self):\n        build_file = self.build_file_class(\n            MakeMessagesCommand(), \"django\", self.translatable_file_class(\"path\", \"file\", \"locale\")\n        )\n        build_file.preprocess()\n        self.assertTrue(os.path.exists(build_file.work_path))\n        build_file.cleanup()\n        self.assertFalse(os.path.exists(build_file.work_path))\n"], "sample_386": ["def test_mark_safe_decorator_on_function_with_return_value(self):\n    \"\"\"\n    mark_safe used as a decorator marks the return value of a function as safe.\n    \"\"\"\n\n    @mark_safe\n        return \"<html><body>dummy</body></html>\"\n\n    self.assertIsInstance(clean_string_provider(), SafeString)\n    self.assertEqual(clean_string_provider().__html__(), \"<html><body>dummy</body></html>\")\n"], "sample_92": ["    def setUpTestData(cls):\n        cls.user = User.objects.create_user('test', 'test@example.com', 'test')\n"], "sample_508": ["def test_set_transform():\n    \"\"\"Test setting the transform of an Artist.\"\"\"\n    art = martist.Artist()\n    assert not art.is_transform_set()\n    art.set_transform(mtransforms.IdentityTransform())\n    assert art.is_transform_set()\n    assert isinstance(art.get_transform(), mtransforms.IdentityTransform)\n    art.set_transform(None)\n    assert not art.is_transform_set()\n    assert isinstance(art.get_transform(), mtransforms.IdentityTransform)\n"], "sample_891": ["def test_roc_auc_score_multiclass_ovo_average_none():\n    # Test that average=None raises NotImplemented error\n    y_true = np.array([0, 1, 2, 2])\n    y_scores = np.array(\n        [[0.1, 0.8, 0.1], [0.3, 0.4, 0.3], [0.35, 0.5, 0.15], [0, 0.2, 0.8]]\n    )\n    error_message = \"average=None is not implemented for multi_class='ovo'.\"\n    with pytest.raises(NotImplementedError, match=error_message):\n        roc_auc_score(y_true, y_scores, multi_class=\"ovo\", average=None)\n"], "sample_1085": ["def test_issue_12345():\n    # Test case description\n    # Test that the Float class correctly handles the conversion of a string\n    # representation of a float to a Float object.\n    assert Float('1.23456789012345678901234567890') == Float(1.23456789012345678901234567890)\n    assert Float('1.23456789012345678901234567890', 30) == Float(1.23456789012345678901234567890, 30)\n    assert Float('1.23456789012345678901234567890', '') == Float(1.23456789012345678901234567890, '')\n"], "sample_185": ["    def test_get_format_lazy(self):\n        format_lazy = get_format_lazy('DATE_FORMAT')\n        self.assertEqual(format_lazy, get_format('DATE_FORMAT'))\n"], "sample_824": ["def test_check_pairwise_arrays_precomputed():\n    # Ensure that check_pairwise_arrays works correctly with precomputed\n    # distance matrices.\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((5, 5))\n    X_checked, _ = check_pairwise_arrays(X, None, precomputed=True)\n    assert_array_equal(X, X_checked)\n\n    # Ensure that check_pairwise_arrays raises an error when the input is not\n    # square.\n    X = rng.random_sample((5, 4))\n    assert_raises(ValueError, check_pairwise_arrays, X, None, precomputed=True)\n\n    # Ensure that check_pairwise_arrays raises an error when the input contains\n    # negative values.\n    X = rng.random_sample((5, 5))\n    X[0, 0] = -1\n    assert_raises(ValueError, check_pairwise_arrays, X, None, precomputed=True)\n"], "sample_0": ["def test_conversion_between_supported_types(UncertClass, other_uncert_class):\n    uncert = np.arange(1, 11).reshape(2, 5) * u.adu\n    start_uncert = UncertClass(uncert)\n    final_uncert = start_uncert.represent_as(other_uncert_class)\n    assert isinstance(final_uncert, other_uncert_class)\n    assert_array_equal(start_uncert.quantity.value, final_uncert.quantity.value)\n    assert start_uncert.quantity.unit == final_uncert.quantity.unit\n"], "sample_811": ["def test_check_pairwise_arrays_dtype():\n    # Ensure that check_pairwise_arrays returns the correct dtype\n    X = np.arange(40, dtype=np.float32).reshape(5, 8)\n    Y = np.arange(40, dtype=np.float64).reshape(5, 8)\n    X_checked, Y_checked = check_pairwise_arrays(X, Y)\n    assert_equal(X_checked.dtype, np.float)\n    assert_equal(Y_checked.dtype, np.float)\n\n    X = np.arange(40, dtype=np.float32).reshape(5, 8)\n    Y = np.arange(40, dtype=np.float32).reshape(5, 8)\n    X_checked, Y_checked = check_pairwise_arrays(X, Y)\n    assert_equal(X_checked.dtype, np.float32)\n    assert_equal(Y_checked.dtype, np.float32)\n\n    X = np.arange(40, dtype=np.float64).reshape(5, 8)\n    Y = np.arange(40, dtype=np.float64).reshape(5, 8)\n    X_checked, Y_checked = check_pairwise_arrays(X, Y)\n    assert_equal(X_checked.dtype, np.float)\n    assert_equal(Y_checked.dtype, np.float)\n"], "sample_130": ["def test_add_annotation(self):\n    query = Query(Author)\n    query.add_annotation(Lower('name'), alias='lower_name')\n    self.assertEqual(query.annotations['lower_name'].output_field, CharField())\n    self.assertEqual(query.annotation_select, {'lower_name': Lower(SimpleCol(None, 'name'))})\n"], "sample_754": ["def test_mini_batch_fit_transform_tall(norm_comp):\n    alpha = 1\n    rng = np.random.RandomState(0)\n    Y, _, _ = generate_toy_data(3, 65, (8, 8), random_state=rng)  # tall array\n    spca_lars = MiniBatchSparsePCA(n_components=3, random_state=0,\n                                   alpha=alpha,\n                                   normalize_components=norm_comp).fit(Y)\n    U1 = spca_lars.transform(Y)\n    # Test multiple CPUs\n    if sys.platform == 'win32':  # fake parallelism for win32\n        import sklearn.externals.joblib.parallel as joblib_par\n        _mp = joblib_par.multiprocessing\n        joblib_par.multiprocessing = None\n        try:\n            spca = MiniBatchSparsePCA(n_components=3, n_jobs=2, alpha=alpha,\n                                      random_state=0,\n                                      normalize_components=norm_comp)\n            U2 = spca.fit(Y).transform(Y)\n        finally:\n            joblib_par.multiprocessing = _mp\n    else:  # we can efficiently use parallelism\n        spca = MiniBatchSparsePCA(n_components=3, n_jobs=2, alpha=alpha,\n                                  random_state=0,\n                                  normalize_components=norm_comp)\n        U2 = spca.fit(Y).transform(Y)\n    assert_true(not np.all(spca_lars.components_ == 0))\n    assert_array_almost_equal(U1, U2)\n    # Test that CD gives similar results\n    spca_lasso = MiniBatchSparsePCA(n_components=3, method='cd', alpha=alpha,\n                                    random_state=0,\n                                    normalize_components=norm_comp).fit(Y)\n    assert_array_almost_equal(spca_lasso.components_, spca_lars.components_)\n"], "sample_180": ["    def test_modelbase_subclass_exception(self):\n        class TestModel(models.Model):\n            pass\n\n        class TestException(Exception):\n            pass\n\n        subclass_exception('TestException', (TestException,), 'invalid_models_tests', TestModel)\n        self.assertEqual(TestModel.TestException.__module__, 'invalid_models_tests')\n        self.assertEqual(TestModel.TestException.__qualname__, 'TestModel.TestException')\n"], "sample_772": ["def check_feature_importances_permutation(name):\n    # Test that feature importances are computed correctly when features are\n    # permuted.\n    ForestEstimator = FOREST_ESTIMATORS[name]\n    est = ForestEstimator(n_estimators=10, random_state=0)\n    est.fit(X_large, y_large)\n    importances = est.feature_importances_\n\n    # Permute features\n    idx = np.arange(X_large.shape[1])\n    idx = np.random.permutation(idx)\n    X_large_permuted = X_large[:, idx]\n\n    est.fit(X_large_permuted, y_large)\n    importances_permuted = est.feature_importances_\n\n    # Check importances are permuted accordingly\n    assert_array_almost_equal(importances_permuted[idx], importances)\n\n"], "sample_187": ["def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('hello'), 'hello')\n    self.assertEqual(text.camel_case_to_spaces(''), '')\n    self.assertEqual(text.camel_case_to_spaces(lazystr('HelloWorld')), 'hello world')\n"], "sample_365": ["def test_lazy_object(self):\n    class Klazz:\n            self.value = value\n\n            return str(self.value)\n\n    lazy_obj = lazy(lambda: Klazz(123), Klazz)()\n    self.assertEqual(str(lazy_obj), '123')\n    self.assertEqual(lazy_obj.value, 123)\n\n    lazy_obj = lazy(lambda: Klazz('hello'), Klazz)()\n    self.assertEqual(str(lazy_obj), 'hello')\n    self.assertEqual(lazy_obj.value, 'hello')\n"], "sample_1095": ["def test_permutation_resize():\n    p = Permutation(0, 1, 2)\n    assert p.resize(5) == Permutation(0, 1, 2, size=5)\n    assert p.resize(4) == Permutation(0, 1, 2, size=4)\n    assert p.resize(3) == p\n    raises(ValueError, lambda: p.resize(2))\n\n    p = Permutation(0, 1, 2)(3, 4)(5, 6)\n    assert p.resize(3) == Permutation(0, 1, 2)\n    raises(ValueError, lambda: p.resize(4))\n\n    p = Permutation(0, 1, 2)(3, 4)(5, 6)\n    assert p.resize(7) == p\n    assert p.resize(8) == Permutation(0, 1, 2)(3, 4)(5, 6, size=8)\n"], "sample_1191": ["def test_hermite_normal_form():\n    m = DM([[12, 6, 4], [3, 9, 6], [2, 16, 14]], ZZ)\n    hnf = DM([[10, 0, 2], [0, 15, 3], [0, 0, 2]], ZZ)\n    assert hermite_normal_form(m).to_dense() == hnf\n\n    m = DM([[1, 2, 3], [4, 5, 6]], ZZ)\n    hnf = DM([[1, 0, 1], [0, 2, 1]], ZZ)\n    assert hermite_normal_form(m).to_dense() == hnf\n\n    m = DM([[1, 2], [3, 4], [5, 6]], ZZ)\n    raises(DMShapeError, lambda: hermite_normal_form(m, D=1))\n\n    m = DM([[1, 2, 3], [4, 5, 6]], ZZ)\n    raises(DMDomainError, lambda: hermite_normal_form(m, D=1.5))\n\n    m = DM([[1, 2, 3], [4, 5, 6]], ZZ)\n    raises(DMDomainError, lambda: hermite_normal_form(m, D='a'))\n\n    m = DM([[1, 2, 3], [4, 5, 6]], ZZ)\n    hnf = DM([[1, 0, 1], [0, 2, 1]], ZZ)\n    assert hermite_normal_form(m, D=10).to_dense() == hnf\n\n    m = DM([[1, 2, 3], [4, 5, 6]], ZZ)\n    hnf = DM([[1, 0, 1], [0, 2, 1]], ZZ)\n    assert hermite_normal_form(m, D=10, check_rank=True).to_dense() == hnf\n"], "sample_1189": ["def test_lambdify_cse():\n        return (), exprs\n\n        from sympy.simplify.cse_main import cse_release_variables, cse\n        return cse(exprs, postprocess=cse_release_variables)\n\n    class Case:\n            self.args = args\n            self.exprs = exprs\n            self.num_args = num_args\n            subs_dict = dict(zip(self.args, self.num_args))\n            self.ref = [e.subs(subs_dict).evalf() for e in exprs]\n            self.requires_numpy = requires_numpy\n\n            return lambdify(self.args, self.exprs, cse=cse)\n\n            if self.requires_numpy:\n                assert all(numpy.allclose(result[i], numpy.asarray(r, dtype=float),\n                                          rtol=reltol, atol=abstol)\n                           for i, r in enumerate(self.ref))\n                return\n\n            for i, r in enumerate(self.ref):\n                abs_err = abs(result[i] - r)\n                if r == 0:\n                    assert abs_err < abstol\n                else:\n                    assert abs_err/abs(r) < reltol\n\n    cases = [\n        Case(args=(x,), exprs=[x**2 + x + 1, x**2 + x + 2], num_args=(1,)),\n        Case(args=(x, y), exprs=[x**2 + y**2, x**2 + y**2 + 1], num_args=(1, 2)),\n        Case(args=(x,), exprs=[x**2 + x + 1, x**2 + x + 2, x**2 + x + 3], num_args=(1,)),\n        Case(args=(x, y), exprs=[x**2 + y**2, x**2 + y**2 + 1, x**2 + y**2 + 2], num_args=(1, 2)),\n        Case(args=(x,), exprs=[x**2 + x + 1, x**2 + x + 2, x**2 + x + 3, x**2 +"], "sample_792": ["def test_complementnb_partial_fit():\n    # Test whether ComplementNB's partial_fit method works correctly\n    X = np.array([[1, 1, 0, 0, 0, 0],\n                  [0, 1, 0, 0, 1, 0],\n                  [0, 1, 0, 1, 0, 0],\n                  [0, 1, 1, 0, 0, 1]])\n\n    # Classes are China (0), Japan (1).\n    Y = np.array([0, 0, 0, 1])\n\n    # Check that weights are correct. See steps 4-6 in Table 4 of\n    # Rennie et al. (2003).\n    theta = np.array([\n        [\n            (0 + 1) / (3 + 6),\n            (1 + 1) / (3 + 6),\n            (1 + 1) / (3 + 6),\n            (0 + 1) / (3 + 6),\n            (0 + 1) / (3 + 6),\n            (1 + 1) / (3 + 6)\n        ],\n        [\n            (1 + 1) / (6 + 6),\n            (3 + 1) / (6 + 6),\n            (0 + 1) / (6 + 6),\n            (1 + 1) / (6 + 6),\n            (1 + 1) / (6 + 6),\n            (0 + 1) / (6 + 6)\n        ]])\n\n    weights = np.zeros(theta.shape)\n    normed_weights = np.zeros(theta.shape)\n    for i in range(2):\n        weights[i] = -np.log(theta[i])\n        normed_weights[i] = weights[i] / weights[i].sum()\n\n    # Verify inputs are nonnegative.\n    clf = ComplementNB(alpha=1.0)\n    assert_raises(ValueError, clf.fit, -X, Y)\n\n    clf = ComplementNB(alpha=1.0)\n    clf.partial_fit(X[:2], Y[:2], classes=[0, 1])\n    clf.partial_fit(X[2:], Y[2:])\n\n    # Check that counts/weights are correct.\n    feature_count = np.array([[1, 3, 0, 1, 1, 0],"], "sample_698": ["def test_logcapturefixture() -> None:\n    from _pytest.logging import LogCaptureFixture, LogCaptureHandler\n\n    fixture = LogCaptureFixture(None)\n\n    # Test set_level method\n    fixture.set_level(logging.INFO)\n    assert fixture.handler.level == logging.INFO\n\n    # Test at_level context manager\n    with fixture.at_level(logging.DEBUG):\n        assert fixture.handler.level == logging.DEBUG\n    assert fixture.handler.level == logging.INFO\n\n    # Test get_records method\n    handler = LogCaptureHandler()\n    handler.setLevel(logging.INFO)\n    record = logging.LogRecord(\n        name=\"dummy\",\n        level=logging.INFO,\n        pathname=\"dummypath\",\n        lineno=10,\n        msg=\"Test Message\",\n        args=(),\n        exc_info=None,\n    )\n    handler.emit(record)\n    fixture._item = type(\"Item\", (), {\"_store\": {LogCaptureFixture.caplog_records_key: {\"setup\": handler.records}}})\n    assert fixture.get_records(\"setup\") == [record]\n\n    # Test text property\n    assert fixture.text == \"\"\n\n    # Test records property\n    assert fixture.records == []\n\n    # Test record_tuples property\n    assert fixture.record_tuples == []\n\n    # Test messages property\n    assert fixture.messages == []\n\n    # Test clear method\n    fixture.clear()\n    assert fixture.text == \"\"\n    assert fixture.records == []\n    assert fixture.record_tuples == []\n    assert fixture.messages == []\n"], "sample_1172": ["def test_solve_generic():\n    x0, y0, x1, y1, r = symbols('x0 y0 x1 y1 r')\n\n    f_1 = (x - 1)**2 + (y - 1)**2 - r**2\n    f_2 = (x - 2)**2 + (y - 2)**2 - r**2\n    s = sqrt(2*r**2 - 1)\n    a = (3 - s)/2\n    b = (3 + s)/2\n    assert solve_generic([f_1, f_2], Poly(f_1, x, y).options) == [(a, b), (b, a)]\n\n    f_1 = (x - 1)**2 + (y - 2)**2 - r**2\n    f_2 = (x - 1)**2 + (y - 1)**2 - r**2\n\n    assert solve_generic([f_1, f_2], Poly(f_1, x, y).options) == \\\n        [(1 - sqrt((2*r - 1)*(2*r + 1))/2, Rational(3, 2)),\n         (1 + sqrt((2*r - 1)*(2*r + 1))/2, Rational(3, 2))]\n\n    query = lambda expr: expr.is_Pow and expr.exp is S.Half\n\n    f_1 = (x - 1 )**2 + (y - 2)**2 - r**2\n    f_2 = (x - x1)**2 + (y - 1)**2 - r**2\n\n    result = solve_generic([f_1, f_2], Poly(f_1, x, y).options)\n\n    assert len(result) == 2 and all(len(r) == 2 for r in result)\n    assert all(r.count(query) == 1 for r in flatten(result))\n\n    f_1 = (x - x0)**2 + (y - y0)**2 - r**2\n    f_2 = (x - x1)**2 + (y - y1)**2 - r**2\n\n    result = solve_generic([f_1, f_2], Poly(f_1, x, y).options)\n\n    assert len(result) == 2 and all(len(r) == 2 for r in result)\n   "], "sample_58": ["def test_order_fields_with_empty_list(self):\n    class TestForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n        field3 = CharField()\n        field_order = []\n\n    p = TestForm()\n    self.assertEqual(list(p.fields), ['field1', 'field2', 'field3'])\n"], "sample_804": ["def test_ordinal_encoder_unsorted_categories():\n    X = np.array([[1, 2]]).T\n    enc = OrdinalEncoder(categories=[[2, 1, 3]])\n    msg = 'Unsorted categories are not supported'\n    with pytest.raises(ValueError, match=msg):\n        enc.fit_transform(X)\n"], "sample_877": ["def test_isotonic_regression_out_of_bounds_edge_cases():\n    # Test edge cases for out_of_bounds parameter\n    x = np.array([1, 2, 3, 4, 5])\n    y = np.array([1, 2, 3, 4, 5])\n\n    # Test 'nan' edge case\n    ir = IsotonicRegression(out_of_bounds='nan')\n    ir.fit(x, y)\n    assert np.isnan(ir.predict([0]))  # below min\n    assert np.isnan(ir.predict([6]))  # above max\n\n    # Test 'clip' edge case\n    ir = IsotonicRegression(out_of_bounds='clip')\n    ir.fit(x, y)\n    assert ir.predict([0]) == 1  # below min\n    assert ir.predict([6]) == 5  # above max\n\n    # Test 'raise' edge case\n    ir = IsotonicRegression(out_of_bounds='raise')\n    ir.fit(x, y)\n    with pytest.raises(ValueError, match='below the interpolation range'):\n        ir.predict([0])  # below min\n    with pytest.raises(ValueError, match='above the interpolation range'):\n        ir.predict([6])  # above max\n"], "sample_597": ["    def test_merge_coords(self):\n        coords1 = xr.Dataset(coords={\"x\": [1, 2]})\n        coords2 = xr.Dataset(coords={\"x\": [2, 3]})\n        expected = xr.Dataset(coords={\"x\": [1, 2, 3]})\n        assert expected.identical(xr.merge([coords1, coords2]))\n"], "sample_1202": ["def test_issue_14289():\n    from sympy.polys.numberfields import to_number_field\n\n    a = 1 - sqrt(2)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n"], "sample_866": ["def test_affinity_propagation_damping():\n    # Test that the damping factor is validated\n    with pytest.raises(ValueError):\n        AffinityPropagation(damping=0.4)\n\n    with pytest.raises(ValueError):\n        AffinityPropagation(damping=1.0)\n\n    # Test that the damping factor is used correctly\n    X = np.array([[0, 0], [1, 1], [-2, -2]])\n    af = AffinityPropagation(preference=-10, damping=0.9)\n    af.fit(X)\n\n    af2 = AffinityPropagation(preference=-10, damping=0.5)\n    af2.fit(X)\n\n    assert not np.array_equal(af.cluster_centers_, af2.cluster_centers_)\n"], "sample_678": ["def test_ensure_deletable(tmp_path):\n    \"\"\"Test ensure_deletable function.\"\"\"\n    path = tmp_path / \"test\"\n    path.mkdir()\n    lock_path = get_lock_path(path)\n    assert ensure_deletable(path, 0) is False\n\n    # Create a lock file\n    lock_path.touch()\n    assert ensure_deletable(path, 0) is False\n\n    # Make the lock file old enough to be considered dead\n    lock_path.touch(0)\n    assert ensure_deletable(path, 1) is True\n\n    # Test that the lock file is removed\n    assert lock_path.exists() is False\n"], "sample_235": ["def test_on_commit_with_nested_transactions_and_error(self):\n    try:\n        with transaction.atomic():\n            with transaction.atomic():\n                self.do(1)\n                transaction.on_commit(lambda: self.notify('error'))\n            self.do(2)\n            raise ForcedError()\n    except ForcedError:\n        pass\n\n    self.assertDone([2])\n"], "sample_673": ["def test_doctest_report_choice_only_first_failure_with_multiple_failures(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            '''\n            >>> 1 + 1\n            3\n            >>> 2 + 2\n            5\n            '''\n            pass\n        \"\"\"\n    )\n    result = testdir.runpytest(\"--doctest-modules\", \"--doctest-report=only_first_failure\")\n    result.stdout.fnmatch_lines(\n        [\n            \"Expected:\",\n            \"    3\",\n            \"Got:\",\n            \"    2\",\n            \"*1 failed*\",\n        ]\n    )\n    result.stdout.no_fnmatch_line(\"*2 + 2*\")\n"], "sample_1176": ["def test_issue_12345():\n    # Test that Float instances can be used as dictionary keys\n    d = {Float(1.0): 'one', Float(2.0): 'two'}\n    assert d[Float(1.0)] == 'one'\n    assert d[Float(2.0)] == 'two'\n    assert Float(1.0) in d\n    assert Float(2.0) in d\n    assert Float(3.0) not in d\n"], "sample_820": ["def test_voting_regressor_set_params():\n    \"\"\"Test set_params method for VotingRegressor\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor()\n    ereg = VotingRegressor([('lr', reg1), ('rf', reg2)])\n\n    ereg.set_params(lr__fit_intercept=False)\n    assert ereg.estimators[0][1].get_params()['fit_intercept'] is False\n\n    ereg.set_params(rf__n_estimators=100)\n    assert ereg.estimators[1][1].get_params()['n_estimators'] == 100\n\n    ereg.set_params(weights=[1, 2])\n    assert ereg.weights == [1, 2]\n\n    ereg.set_params(lr=None)\n    assert ereg.estimators[0][1] is None\n\n    with pytest.raises(ValueError, match='All estimators are None or \"drop\". At least one is required!'):\n        ereg.set_params(rf=None).fit(X_r, y_r)\n"], "sample_714": ["def test_brier_score_loss():\n    # Test Brier score loss\n    y_true = [0, 1, 1, 0]\n    y_pred = [0.1, 0.9, 0.8, 0.4]\n    assert_almost_equal(brier_score_loss(y_true, y_pred), 0.045)\n\n    y_true = [0, 1, 1, 0]\n    y_pred = [0, 1, 1, 0]\n    assert_almost_equal(brier_score_loss(y_true, y_pred), 0)\n\n    y_true = [0, 1, 1, 0]\n    y_pred = [1, 0, 0, 1]\n    assert_almost_equal(brier_score_loss(y_true, y_pred), 1)\n\n    y_true = [0, 1, 1, 0]\n    y_pred = [0.5, 0.5, 0.5, 0.5]\n    assert_almost_equal(brier_score_loss(y_true, y_pred), 0.25)\n\n    y_true = [0, 1, 1, 0]\n    y_pred = [0.1, 0.9, 0.8, 0.4]\n    sample_weight = [0.1, 0.3, 0.2, 0.4]\n    assert_almost_equal(brier_score_loss(y_true, y_pred, sample_weight), 0.061)\n\n    y_true = [0, 1, 1, 0]\n    y_pred = [0.1, 0.9, 0.8, 0.4]\n    assert_almost_equal(brier_score_loss(y_true, y_pred, pos_label=0), 0.045)\n\n    y_true = [0, 1, 1, 0]\n    y_pred = [0.1, 0.9, 0.8, 0.4]\n    assert_almost_equal(brier_score_loss(y_true, y_pred, pos_label=1), 0.045)\n\n    y_true = [\"ham\", \"spam\", \"spam\", \"ham\"]\n    y_pred = [0.1, 0.9, 0.8, 0.4]\n    assert_almost_equal(brier_score_loss(y_true, y_pred, pos_label=\"spam\"), 0.045)\n\n"], "sample_663": ["def test_collect_with_conftest_in_subdir(testdir):\n    \"\"\"Test that conftest.py in subdirectory is not collected as a test.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    testdir.mkpydir(\"sub\")\n    testdir.makeconftest(\n        \"\"\"\n            parser.addoption(\"--foo\", action=\"store_true\")\n    \"\"\",\n        path=testdir.tmpdir.join(\"sub\"),\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed in*\"])\n    assert result.ret == 0\n"], "sample_1183": ["def test_FracField():\n    F, x, y = field(\"x,y\", ZZ)\n    assert F.domain_new(1) == F.one\n    assert F.domain_new(2) == F(2)\n    assert F.domain_new(-1) == F(-1)\n    assert F.domain_new(0) == F.zero\n\n    assert F.ground_new(1) == F.one\n    assert F.ground_new(2) == F(2)\n    assert F.ground_new(-1) == F(-1)\n    assert F.ground_new(0) == F.zero\n\n    assert F.field_new(1) == F.one\n    assert F.field_new(2) == F(2)\n    assert F.field_new(-1) == F(-1)\n    assert F.field_new(0) == F.zero\n\n    assert F.field_new(F(1)) == F.one\n    assert F.field_new(F(2)) == F(2)\n    assert F.field_new(F(-1)) == F(-1)\n    assert F.field_new(F(0)) == F.zero\n\n    assert F.field_new((1, 1)) == F.one\n    assert F.field_new((2, 1)) == F(2)\n    assert F.field_new((-1, 1)) == F(-1)\n    assert F.field_new((0, 1)) == F.zero\n\n    assert F.field_new((1, 2)) == F(1, 2)\n    assert F.field_new((2, 2)) == F(1)\n    assert F.field_new((-1, 2)) == F(-1, 2)\n    assert F.field_new((0, 2)) == F.zero\n\n    assert F.field_new(x) == F(x)\n    assert F.field_new(y) == F(y)\n    assert F.field_new(x + y) == F(x + y)\n    assert F.field_new(x * y) == F(x * y)\n\n    assert F.field_new(1/x) == F(1, x)\n    assert F.field_new(1/y) == F(1, y)\n    assert F.field_new(1/(x + y)) == F(1, x + y)\n    assert F.field_new(1/(x * y)) == F(1, x * y)\n\n    assert F.field_new(x/y) == F(x, y)\n    assert F.field_new(y/x) == F"], "sample_615": ["def test_cross() -> None:\n    # Test cross product with 3D vectors\n    a = xr.DataArray(\n        [[1, 2, 3], [4, 5, 6]],\n        dims=(\"time\", \"cartesian\"),\n        coords=dict(\n            time=([\"time\"], [0, 1]),\n            cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"]),\n        ),\n    )\n    b = xr.DataArray(\n        [[7, 8, 9], [10, 11, 12]],\n        dims=(\"time\", \"cartesian\"),\n        coords=dict(\n            time=([\"time\"], [0, 1]),\n            cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"]),\n        ),\n    )\n    expected = xr.DataArray(\n        [[-3, 6, -3], [-3, 6, -3]],\n        dims=(\"time\", \"cartesian\"),\n        coords=dict(\n            time=([\"time\"], [0, 1]),\n            cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"]),\n        ),\n    )\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(expected, actual)\n\n    # Test cross product with 2D vectors\n    a = xr.DataArray(\n        [[1, 2], [4, 5]],\n        dims=(\"time\", \"cartesian\"),\n        coords=dict(\n            time=([\"time\"], [0, 1]),\n            cartesian=([\"cartesian\"], [\"x\", \"y\"]),\n        ),\n    )\n    b = xr.DataArray(\n        [[7, 8], [10, 11]],\n        dims=(\"time\", \"cartesian\"),\n        coords=dict(\n            time=([\"time\"], [0, 1]),\n            cartesian=([\"cartesian\"], [\"x\", \"y\"]),\n        ),\n    )\n    expected = xr.DataArray(\n        [-3, -3],\n        dims=(\"time\",),\n        coords=dict(time=([\"time\"], [0, 1])),\n    )\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(expected, actual)\n\n    # Test cross product with 2D vectors and different coordinate names\n    a = xr.DataArray(\n        [[1, 2], [4, 5]],\n        dims=(\"time\", \"cartesian\"),\n        coords=dict(\n            time=([\"time\"], [0, 1]),\n            cartesian"], "sample_979": ["def test_MatrixElement_as_coeff_Mul():\n    assert A[0, 0].as_coeff_Mul()[0] == 1\n    assert A[0, 0].as_coeff_Mul()[1] == A[0, 0]\n"], "sample_1002": ["def test_issue_14289():\n    from sympy.polys.numberfields import to_number_field\n\n    a = 1 - sqrt(2)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n"], "sample_245": ["    def test_build_file_cleanup(self):\n        build_file = self.build_file_class(None, 'django', self.translatable_file_class('.', 'test.py', '.'))\n        build_file.preprocess()\n        self.assertTrue(os.path.exists(build_file.work_path))\n        build_file.cleanup()\n        self.assertFalse(os.path.exists(build_file.work_path))\n"], "sample_294": ["def test_rotate_token(self):\n    \"\"\"\n    Rotate the CSRF token on login.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.process_request(req)\n    mw.process_view(req, post_form_view, (), {})\n    resp = mw(req)\n    csrf_cookie = resp.cookies.get(settings.CSRF_COOKIE_NAME, None)\n    self.assertIsNotNone(csrf_cookie)\n    self.assertNotEqual(csrf_cookie.value, self._csrf_id_cookie)\n\n    # Rotate the token\n    rotate_token(req)\n    mw.process_request(req)\n    mw.process_view(req, post_form_view, (), {})\n    resp = mw(req)\n    new_csrf_cookie = resp.cookies.get(settings.CSRF_COOKIE_NAME, None)\n    self.assertIsNotNone(new_csrf_cookie)\n    self.assertNotEqual(new_csrf_cookie.value, csrf_cookie.value)\n"], "sample_536": ["def test_polygon_selector_add_state(ax):\n    tool = widgets.PolygonSelector(ax, onselect=noop)\n\n    with pytest.raises(ValueError):\n        tool.add_state('unsupported_state')\n\n    with pytest.raises(ValueError):\n        tool.add_state('clear')\n    tool.add_state('move_vertex')\n    tool.add_state('move_all')\n    tool.add_state('clear')\n"], "sample_198": ["    def test_window_function(self):\n        # Create some data\n        Experiment.objects.create(name='Experiment 1', assigned=datetime.date(2010, 6, 25), start=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000), end=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000))\n        Experiment.objects.create(name='Experiment 2', assigned=datetime.date(2010, 6, 25), start=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000), end=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000))\n        Experiment.objects.create(name='Experiment 3', assigned=datetime.date(2010, 6, 25), start=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000), end=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000))\n\n        # Use a window function\n        experiments = Experiment.objects.annotate(\n            row_number=Window(expression=RowNumber(), partition_by=F('assigned'), order_by=F('start'))\n        ).order_by('assigned', 'start')\n\n        # Check the results\n        self.assertEqual(experiments[0].row_number, 1)\n        self.assertEqual(experiments[1].row_number, 2)\n        self.assertEqual(experiments[2].row_number, 3)\n"], "sample_38": ["def test_sip_with_altkey_2():\n    \"\"\"\n    Test that when creating a WCS object using a key, CTYPE with\n    that key is looked at and not the primary CTYPE.\n    fix for #5443.\n    \"\"\"\n    with fits.open(get_pkg_data_filename('data/sip.fits')) as f:\n        w = wcs.WCS(f[0].header)\n    # create a header with two WCSs.\n    h1 = w.to_header(relax=True, key='A')\n    h2 = w.to_header(relax=False)\n    h1['CTYPE1A'] = \"RA---SIN-SIP\"\n    h1['CTYPE2A'] = \"DEC--SIN-SIP\"\n    h1.update(h2)\n    w = wcs.WCS(h1, key='A')\n    assert (w.wcs.ctype == np.array(['RA---SIN-SIP', 'DEC--SIN-SIP'])).all()\n    # Test that the WCS object is correctly created when the key is not\n    # specified.\n    w = wcs.WCS(h1)\n    assert (w.wcs.ctype == np.array(['RA---TAN-SIP', 'DEC--TAN-SIP'])).all()\n"], "sample_139": ["def test_dynamic_sortable_by(self):\n    \"\"\"\n    Regression tests for #17646: dynamic sortable_by support.\n    \"\"\"\n    parent = Parent.objects.create(name='parent')\n    for i in range(10):\n        Child.objects.create(name='child %s' % i, parent=parent)\n\n    user_noparents = self._create_superuser('noparents')\n    user_parents = self._create_superuser('parents')\n\n    # Test with user 'noparents'\n    m = DynamicListDisplayChildAdmin(Child, custom_site)\n    request = self._mocked_authenticated_request('/child/', user_noparents)\n    response = m.changelist_view(request)\n    self.assertEqual(response.context_data['cl'].sortable_by, ['name', 'age'])\n\n    # Test with user 'parents'\n    m = DynamicListDisplayChildAdmin(Child, custom_site)\n    request = self._mocked_authenticated_request('/child/', user_parents)\n    response = m.changelist_view(request)\n    self.assertEqual(response.context_data['cl'].sortable_by, ('parent', 'name', 'age'))\n"], "sample_563": ["def test_offsetimage():\n    # smoke test OffsetImage for correct rendering\n    fig, ax = plt.subplots()\n    im = np.random.rand(10, 10)\n    oi = OffsetImage(im, zoom=3)\n    ab = AnchoredOffsetbox('upper left', child=oi)\n    ax.add_artist(ab)\n    fig.draw_without_rendering()\n"], "sample_667": ["def test_getbasetemp_custom_removes_old_with_cleanup_lock(testdir):\n    mytemp = testdir.tmpdir.join(\"xyz\")\n    p = testdir.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    testdir.runpytest(p, \"--basetemp=%s\" % mytemp)\n    mytemp.check()\n    mytemp.ensure(\"hello\")\n\n    from _pytest.pathlib import create_cleanup_lock\n\n    cleanup_lock = create_cleanup_lock(mytemp.join(\"hello\"))\n    testdir.runpytest(p, \"--basetemp=%s\" % mytemp)\n    mytemp.check()\n    assert not mytemp.join(\"hello\").check()\n    assert not cleanup_lock.exists()\n"], "sample_419": ["def test_formset_with_filefield(self):\n    \"\"\"\n    Formset works with FileField.\n    \"\"\"\n    class FileForm(Form):\n        file = FileField()\n\n    FileFormSet = formset_factory(FileForm, extra=1)\n    formset = FileFormSet(files={\"form-0-file\": SimpleUploadedFile(\"test.txt\", b\"Hello World!\")})\n    self.assertTrue(formset.is_valid())\n    self.assertEqual(formset.forms[0].cleaned_data, {\"file\": \"test.txt\"})\n"], "sample_341": ["def test_formset_absolute_max_with_min_num(self):\n    data = {\n        'form-TOTAL_FORMS': '1001',\n        'form-INITIAL_FORMS': '0',\n        'form-MIN_NUM_FORMS': '0',\n        'form-MAX_NUM_FORMS': '0',\n    }\n    LimitedFavoriteDrinksFormSet = formset_factory(\n        FavoriteDrinkForm,\n        min_num=30,\n        absolute_max=1000,\n    )\n    formset = LimitedFavoriteDrinksFormSet(data=data)\n    self.assertIs(formset.is_valid(), False)\n    self.assertEqual(len(formset.forms), 1000)\n    self.assertEqual(\n        formset.non_form_errors(),\n        ['Please submit at least 30 forms.'],\n    )\n"], "sample_1201": ["def test_conversion_to_from_cgs_gauss():\n    assert convert_to(statampere, ampere, cgs_gauss) == ampere/2997924580\n    assert convert_to(ampere, statampere, cgs_gauss) == 2997924580*statampere\n    assert convert_to(statvolt, volt, cgs_gauss) == volt*10**6/speed_of_light\n    assert convert_to(volt, statvolt, cgs_gauss) == 10**-6*speed_of_light*statvolt\n    assert convert_to(gauss, tesla, cgs_gauss) == tesla/10**4\n    assert convert_to(tesla, gauss, cgs_gauss) == 10**4*gauss\n    assert convert_to(maxwell, weber, cgs_gauss) == weber/10**8\n    assert convert_to(weber, maxwell, cgs_gauss) == 10**8*maxwell\n    assert convert_to(debye, statcoulomb*centimeter, cgs_gauss) == 10**18*statcoulomb*centimeter\n    assert convert_to(statcoulomb*centimeter, debye, cgs_gauss) == debye/10**18\n    assert convert_to(oersted, sqrt(gram/centimeter)/second, cgs_gauss) == sqrt(gram/centimeter)/second\n    assert convert_to(sqrt(gram/centimeter)/second, oersted, cgs_gauss) == oersted\n    assert convert_to(ohm, second/centimeter, cgs_gauss) == 10**5/speed_of_light**2*second/centimeter\n    assert convert_to(second/centimeter, ohm, cgs_gauss) == ohm/10**5/speed_of_light**2\n    assert convert_to(farad, centimeter, cgs_gauss) == 10**-5*speed_of_light**2*centimeter\n    assert convert_to(centimeter, farad, cgs_gauss) == farad/10**-5/speed_of_light**2\n    assert convert_to(henry, centimeter**2/second**2, cgs_gauss) == 10**5/speed_of_light**2/centimeter*second**2\n    assert convert_to(cent"], "sample_655": ["def test_capture_manager_suspend_resume(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n            print(\"before suspend\")\n            with capsys.disabled():\n                print(\"while suspended\")\n            print(\"after resume\")\n        \"\"\"\n    )\n    result = testdir.runpytest_subprocess(p)\n    result.stdout.fnmatch_lines(\n        \"\"\"\n        *before suspend*\n        *while suspended*\n        *after resume*\n    \"\"\"\n    )\n"], "sample_832": ["def test_bayesian_ridge_alpha_init():\n    # Test BayesianRidge with alpha_init=0\n    X = np.array([[1], [2], [6], [8], [10]])\n    Y = np.array([1, 2, 6, 8, 10])\n    clf = BayesianRidge(alpha_init=0)\n    msg = \"alpha_init must be greater than zero.\"\n    assert_raise_message(ValueError, msg, clf.fit, X, Y)\n"], "sample_275": ["    def test_get_or_create_with_defaults(self):\n        # Test that get_or_create() works correctly with defaults.\n        defaults = {'pagecount': 100}\n        book, created = Book.objects.get_or_create(id=1, defaults=defaults)\n        self.assertTrue(created)\n        self.assertEqual(book.pagecount, 100)\n\n        # Test that get_or_create() doesn't create a new object if it already exists.\n        book, created = Book.objects.get_or_create(id=1, defaults=defaults)\n        self.assertFalse(created)\n        self.assertEqual(book.pagecount, 100)\n"], "sample_695": ["def test_node_repr_failure(pytester: Pytester) -> None:\n    items = pytester.getitems(\n        \"\"\"\n            raise ValueError(\"some message\")\n    \"\"\"\n    )\n    item = items[0]\n    excinfo = pytest.raises(ValueError, item.runtest)\n    result = item.repr_failure(excinfo)\n    assert isinstance(result, str)\n    assert \"ValueError: some message\" in result\n"], "sample_649": ["def test_log_cli_level_from_config_file(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n        log_cli_level=DEBUG\n        \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_handler.level == logging.DEBUG\n            logging.getLogger('catchlog').debug(\"This log message will be shown\")\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n\n    result = pytester.runpytest(\"-s\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_log_cli_level_from_config_file.py* This log message will be shown\",\n            \"*test_log_cli_level_from_config_file.py* This log message will be shown\",\n            \"PASSED\",  # 'PASSED' on its own line because the log message prints a new line\n        ]\n    )\n\n    # make sure that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n"], "sample_665": ["def test_collect_with_parametrized_tests(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"x\", [1, 2])\n            assert x in [1, 2]\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--collect-only\")\n    result.stdout.fnmatch_lines(\n        [\n            \"collected 2 items\",\n            \"<Module test_collect_with_parametrized_tests.py>\",\n            \"  <Function test_foo[1]>\",\n            \"  <Function test_foo[2]>\",\n        ]\n    )\n"], "sample_1031": ["def test_quantity_scale_factors():\n    # Test that the scale factors of the quantities are correctly defined\n    assert m.get_scale_factor() == 1\n    assert kg.get_scale_factor() == 1\n    assert s.get_scale_factor() == 1\n    assert c.get_scale_factor() == 299792458*m/s\n\n    # Test that the scale factors of derived units are correctly calculated\n    assert N.get_scale_factor() == kg*m/s**2\n    assert J.get_scale_factor() == N*m\n    assert W.get_scale_factor() == J/s\n\n    # Test that the scale factors of other units are correctly defined\n    assert g.get_scale_factor() == kg/kilo\n    assert mg.get_scale_factor() == milli*g\n    assert ug.get_scale_factor() == micro*g\n\n    # Test that the scale factors of time units are correctly defined\n    assert ms.get_scale_factor() == milli*s\n    assert us.get_scale_factor() == micro*s\n    assert ns.get_scale_factor() == nano*s\n    assert ps.get_scale_factor() == pico*s\n\n    # Test that the scale factors of Planck units are correctly defined\n    assert planck_mass.get_scale_factor() == sqrt(hbar*c/G)\n    assert planck_time.get_scale_factor() == sqrt(hbar*G/c**5)\n    assert planck_temperature.get_scale_factor() == sqrt(hbar*c**5/G/boltzmann**2)\n    assert planck_length.get_scale_factor() == sqrt(hbar*G/c**3)\n    assert planck_charge.get_scale_factor() == sqrt(4*pi*electric_constant*hbar*c)\n"], "sample_796": ["def test_huber_epsilon_value_error():\n    # Test that HuberRegressor raises an error when epsilon is less than 1.0\n    X, y = make_regression_with_outliers()\n    huber = HuberRegressor(fit_intercept=True, epsilon=0.5)\n    with pytest.raises(ValueError):\n        huber.fit(X, y)\n"], "sample_304": ["    def test_url_validator_with_custom_schemes(self):\n        validator = URLValidator(schemes=['custom_scheme'])\n        with self.assertRaises(ValidationError):\n            validator('http://example.com')\n        self.assertIsNone(validator('custom_scheme://example.com'))\n"], "sample_192": ["def test_formset_with_deletion_and_can_delete_extra_false(self):\n    \"\"\"\n    Test that can_delete_extra=False prevents deletion of extra forms.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_delete=True, can_delete_extra=False, extra=2)\n    initial = [{'choice': 'Calexico', 'votes': 100}]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_503": ["def test_line2d_update_from():\n    line1 = mlines.Line2D([], [], linestyle='--', color='r', marker='o')\n    line2 = mlines.Line2D([], [], linestyle='-', color='b', marker='s')\n\n    line1.update_from(line2)\n\n    assert line1.get_linestyle() == line2.get_linestyle()\n    assert line1.get_color() == line2.get_color()\n    assert line1.get_marker() == line2.get_marker()\n"], "sample_127": ["def test_bulk_update(self):\n    # Create some objects\n    TwoFields.objects.bulk_create([\n        TwoFields(f1=i, f2=i + 1) for i in range(0, 10)\n    ])\n\n    # Update all objects\n    TwoFields.objects.bulk_update(TwoFields.objects.all(), ['f1', 'f2'])\n\n    # Check that all objects were updated\n    self.assertEqual(TwoFields.objects.filter(f1__gte=0, f2__gte=1).count(), 10)\n\n    # Update some objects\n    TwoFields.objects.bulk_update(TwoFields.objects.filter(f1__gte=5), ['f1', 'f2'])\n\n    # Check that only some objects were updated\n    self.assertEqual(TwoFields.objects.filter(f1__gte=5, f2__gte=6).count(), 5)\n\n    # Update with expressions\n    TwoFields.objects.bulk_update(TwoFields.objects.all(), ['f1'], batch_size=5)\n\n    # Check that all objects were updated\n    self.assertEqual(TwoFields.objects.filter(f1__gte=0).count(), 10)\n\n    # Test that bulk_update() raises an error when the model has no primary key\n    with self.assertRaises(ValueError):\n        NoFields.objects.bulk_update(NoFields.objects.all(), ['field1'])\n"], "sample_1009": ["def test_vector_subs():\n    q1, q2, q3, q4 = dynamicsymbols('q1 q2 q3 q4')\n    q1d, q2d, q3d, q4d = dynamicsymbols('q1 q2 q3 q4', 1)\n    q1dd, q2dd, q3dd, q4dd = dynamicsymbols('q1 q2 q3 q4', 2)\n    N = ReferenceFrame('N')\n    A = N.orientnew('A', 'Axis', [q3, N.z])\n    B = A.orientnew('B', 'Axis', [q2, A.x])\n    v1 = q2 * A.x + q3 * N.y\n    v2 = q3 * B.x + v1\n    v3 = v1.dt(B)\n    v4 = v2.dt(B)\n    v5 = q1*A.x + q2*A.y + q3*A.z\n\n    assert v1.subs({q2: 0}) == q3 * N.y\n    assert v1.subs({q3: 0}) == q2 * A.x\n    assert v1.subs({q2: 0, q3: 0}) == Vector(0)\n    assert v2.subs({q2: 0}) == q3 * B.x + q3 * N.y\n    assert v2.subs({q3: 0}) == q2 * A.x\n    assert v2.subs({q2: 0, q3: 0}) == Vector(0)\n    assert v3.subs({q2: 0}) == q3d * N.y\n    assert v3.subs({q3: 0}) == q2d * A.x\n    assert v3.subs({q2: 0, q3: 0}) == Vector(0)\n    assert v4.subs({q2: 0}) == q3d * B.x + q3d * N.y\n    assert v4.subs({q3: 0}) == q2d * A.x\n    assert v4.subs({q2: 0, q3: 0}) == Vector(0)\n    assert v5.subs({q1: 0}) == q2*A.y + q3*A.z\n    assert v5"], "sample_469": ["def test_annotation_with_subquery(self):\n    subquery = Book.objects.filter(pages__gt=400).values(\"publisher\")\n    publishers = Publisher.objects.annotate(\n        has_long_books=Exists(subquery)\n    ).order_by(\"name\")\n    self.assertQuerySetEqual(\n        publishers,\n        [\n            {\"name\": \"Apress\", \"has_long_books\": True},\n            {\"name\": \"Jonno's House of Books\", \"has_long_books\": False},\n            {\"name\": \"Morgan Kaufmann\", \"has_long_books\": True},\n            {\"name\": \"Prentice Hall\", \"has_long_books\": True},\n            {\"name\": \"Sams\", \"has_long_books\": True},\n        ],\n        lambda p: (p.name, p.has_long_books),\n    )\n"], "sample_123": ["    def test_fields_limit(self):\n        with self.assertRaisesMessage(TooManyFieldsSent, 'The number of GET/POST parameters exceeded settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'):\n            limited_parse_qsl('a=1&b=2&c=3', fields_limit=2)\n"], "sample_1012": ["def test_SciPyPrinter_SparseMatrix():\n    p = SciPyPrinter()\n    smat = SparseMatrix(3, 3, {(0, 0): 1, (1, 1): 2, (2, 2): 3})\n    assert p.doprint(smat) == 'scipy.sparse.coo_matrix([1, 2, 3], ([0, 1, 2], [0, 1, 2]), shape=(3, 3))'\n    assert 'scipy.sparse' in p.module_imports\n"], "sample_220": ["    def test_content_type(self):\n        response = HttpResponse(content_type='text/plain')\n        self.assertEqual(response['Content-Type'], 'text/plain')\n"], "sample_989": ["def test_issue_12820():\n    # Test that using 'prec' as a keyword argument to Float raises a deprecation warning\n    with SymPyDeprecationWarning('Using \"prec=XX\" to denote decimal precision. '\n                                 'Use \"dps=XX\" for decimal precision and \"precision=XX\" '\n                                 'for binary precision.'):\n        Float(1, prec=10)\n"], "sample_879": ["def test_one_hot_encoder_infrequent_categories_with_drop():\n    \"\"\"Test that the infrequent categories are correctly handled when drop is set.\"\"\"\n    X = np.array([[\"a\"] * 5 + [\"b\"] * 20 + [\"c\"] * 10 + [\"d\"] * 3]).T\n    ohe = OneHotEncoder(\n        handle_unknown=\"infrequent_if_exist\", max_categories=2, drop=\"first\"\n    ).fit(X)\n    assert_array_equal(ohe.infrequent_categories_, [[\"a\", \"c\", \"d\"]])\n\n    X_test = [[\"b\"], [\"a\"], [\"c\"], [\"d\"], [\"e\"]]\n    expected = np.array([[0], [1], [1], [1], [1]])\n\n    X_trans = ohe.transform(X_test)\n    assert_allclose(expected, X_trans)\n\n    expected_inv = [[\"b\"], [\"infrequent_sklearn\"], [\"infrequent_sklearn\"], [\"infrequent_sklearn\"], [\"infrequent_sklearn\"]]\n    X_inv = ohe.inverse_transform(X_trans)\n    assert_array_equal(expected_inv, X_inv)\n\n    feature_names = ohe.get_feature_names_out()\n    assert_array_equal([\"x0_b\", \"x0_infrequent_sklearn\"], feature_names)\n"], "sample_776": ["def test_lars_path_return_n_iter():\n    # Test that the return_n_iter parameter works correctly\n    alphas, active, coefs, n_iter = linear_model.lars_path(\n        diabetes.data, diabetes.target, return_path=True, return_n_iter=True)\n    assert n_iter == len(alphas) - 1\n\n    alphas, active, coefs = linear_model.lars_path(\n        diabetes.data, diabetes.target, return_path=True, return_n_iter=False)\n    assert not hasattr(alphas, 'n_iter')\n\n    alpha, active, coefs, n_iter = linear_model.lars_path(\n        diabetes.data, diabetes.target, return_path=False, return_n_iter=True)\n    assert n_iter == 1\n\n    alpha, active, coefs = linear_model.lars_path(\n        diabetes.data, diabetes.target, return_path=False, return_n_iter=False)\n    assert not hasattr(alpha, 'n_iter')\n"], "sample_756": ["def test_extract_dbscan_with_min_samples():\n    # Test extract_dbscan with different min_samples values\n    centers = [[1, 1], [-1, -1], [1, -1]]\n    X, labels_true = make_blobs(n_samples=750, centers=centers,\n                                cluster_std=0.4, random_state=0)\n\n    # Compute OPTICS\n    clust = OPTICS(min_samples=10).fit(X)\n    core_optics, labels_optics = clust.extract_dbscan(0.3)\n\n    # calculate dbscan labels\n    db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n\n    contingency = contingency_matrix(db.labels_, labels_optics)\n    agree = min(np.sum(np.max(contingency, axis=0)),\n                np.sum(np.max(contingency, axis=1)))\n    disagree = X.shape[0] - agree\n\n    # verify core_labels match\n    assert_array_equal(core_optics, db.core_sample_indices_)\n\n    non_core_count = len(labels_optics) - len(core_optics)\n    percent_mismatch = np.round((disagree - 1) / non_core_count, 2)\n\n    # verify label mismatch is <= 5% labels\n    assert percent_mismatch <= 0.05\n\n    # Test with different min_samples values\n    for min_samples in [5, 15, 20]:\n        clust = OPTICS(min_samples=min_samples).fit(X)\n        core_optics, labels_optics = clust.extract_dbscan(0.3)\n\n        # calculate dbscan labels\n        db = DBSCAN(eps=0.3, min_samples=min_samples).fit(X)\n\n        contingency = contingency_matrix(db.labels_, labels_optics)\n        agree = min(np.sum(np.max(contingency, axis=0)),\n                    np.sum(np.max(contingency, axis=1)))\n        disagree = X.shape[0] - agree\n\n        # verify core_labels match\n        assert_array_equal(core_optics, db.core_sample_indices_)\n\n        non_core_count = len(labels_optics) - len(core_optics)\n        percent_mismatch = np.round((disagree - 1) / non_core_count, 2)\n\n        # verify label mismatch is <= 5% labels\n        assert percent_mismatch <= 0.05\n"], "sample_623": ["def test_chunks_with_auto():\n    \"\"\"Test that chunks='auto' uses the backend's preferred chunks.\"\"\"\n    initial = xr.Dataset(\n        {\n            \"data\": xr.Variable(\n                (\"x\", \"y\"),\n                np.empty((5, 6), dtype=np.dtype(\"V1\")),\n                encoding={\"preferred_chunks\": (4, 2)},\n            )\n        }\n    )\n    final = xr.open_dataset(initial, engine=PassThroughBackendEntrypoint, chunks=\"auto\")\n    assert final[\"data\"].chunks == ((4, 1), (2, 2, 2))\n"], "sample_573": ["def test_x_nunique_less_than_order(self, df):\n\n    groupby = GroupBy([\"group\"])\n    df[\"x\"] = np.repeat([1, 2], 50)\n    res = PolyFit(order=3)(df, groupby, \"x\", {})\n\n    assert res.columns.to_list() == [\"x\", \"y\", \"group\"]\n    assert res[\"x\"].empty\n    assert res[\"y\"].empty\n"], "sample_553": ["def test_animation_repr_html_embed_limit(anim):\n    if platform.python_implementation() == 'PyPy':\n        # Something in the test setup fixture lingers around into the test and\n        # breaks pytest.warns on PyPy. This garbage collection fixes it.\n        # https://foss.heptapod.net/pypy/pypy/-/issues/3536\n        np.testing.break_cycles()\n    with mpl.rc_context({'animation.embed_limit': 1e-6}):  # ~1 byte.\n        with pytest.warns(UserWarning, match=\"Animation size has reached\"):\n            anim.to_html5_video()\n"], "sample_1016": ["def test_octave_codeprinter():\n    # Test the OctaveCodePrinter class directly\n    printer = OctaveCodePrinter()\n    assert printer.doprint(x**2 + 2*x + 1) == \"x.^2 + 2*x + 1\"\n    assert printer.doprint(x**2 + 2*x + 1, assign_to='y') == \"y = x.^2 + 2*x + 1;\"\n    assert printer.doprint(x**2 + 2*x + 1, assign_to='y', inline=False) == \"y = x.^2 + 2*x + 1;\"\n"], "sample_794": ["def test_ridge_regression_return_n_iter():\n    # Test that return_n_iter works correctly for all solvers\n    rng = np.random.RandomState(42)\n    X = rng.rand(100, 3)\n    y = rng.rand(100)\n    alpha = 1e-3\n\n    for solver in ['sag', 'lsqr']:\n        out = ridge_regression(X, y, alpha=alpha, solver=solver,\n                               return_n_iter=True)\n        assert len(out) == 2\n        assert len(out[1].shape) == 1\n        assert out[1].dtype == np.int32\n\n    for solver in ['svd', 'cholesky', 'sparse_cg']:\n        out = ridge_regression(X, y, alpha=alpha, solver=solver,\n                               return_n_iter=True)\n        assert len(out) == 1\n        assert out[1] is None\n"], "sample_1092": ["def test_cse_Unevaluated():\n    e = Unevaluated(Add, (x, y, z))\n    substs, reduced = cse([e])\n    assert substs == []\n    assert reduced == [x + y + z]\n    e = Unevaluated(Add, (x, y, z))\n    substs, reduced = cse([e, x + y + z])\n    assert substs == [(x0, x + y + z)]\n    assert reduced == [x0, x0]\n"], "sample_19": ["def test_pixel_bounds():\n    \"\"\"\n    Test WCS pixel bounds\n    \"\"\"\n    w = wcs.WCS(naxis=2)\n    w.wcs.ctype = [\"RA---CAR\", \"DEC--CAR\"]\n    w.wcs.cdelt = [10, 10]\n    w.wcs.crval = [-90, 90]\n    w.wcs.crpix = [1, 1]\n    w._naxis = [100, 200]\n    assert w.pixel_bounds == [(0, 100), (0, 200)]\n    assert w.pixel_shape == (100, 200)\n    assert w.array_shape == (200, 100)\n\n    w.pixel_bounds = [(0, 50), (0, 100)]\n    assert w._naxis == [50, 100]\n    assert w.pixel_shape == (100, 50)\n    assert w.array_shape == (50, 100)\n\n    w.array_bounds = [(0, 50), (0, 100)]\n    assert w._naxis == [50, 100]\n    assert w.pixel_shape == (100, 50)\n    assert w.array_shape == (50, 100)\n\n    w.pixel_bounds = None\n    assert w._naxis == [None, None]\n    assert w.pixel_shape is None\n    assert w.array_shape is None\n"], "sample_912": ["def test_pyvariable_signature(app):\n    text = (\".. py:variable:: var\\n\"\n            \"   :type: int\\n\"\n            \"   :value: 1\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"var\"],\n                                                    [desc_annotation, \": int\"],\n                                                    [desc_annotation, \" = 1\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n\n    assert 'var' in domain.objects\n    assert domain.objects['var'] == ('index', 'var', 'data')\n"], "sample_313": ["def test_get_template_directories_with_cached_loader(self):\n    self.assertSetEqual(\n        autoreload.get_template_directories(),\n        {\n            ROOT / 'templates',\n        }\n    )\n"], "sample_1104": ["def test_Pow_with_noncommutative_base():\n    A, B = symbols('A B', commutative=False)\n    assert str(A**2) == \"A**2\"\n    assert str(A**-2) == \"A**(-2)\"\n    assert str(A**B) == \"A**B\"\n    assert str(A**(B + 1)) == \"A**(B + 1)\"\n    assert str(A**(B - 1)) == \"A**(B - 1)\"\n    assert str(A**(B**2)) == \"A**(B**2)\"\n    assert str(A**(B**-2)) == \"A**(B**(-2))\"\n"], "sample_1014": ["def test_mutable_ndim_array():\n    mda = MutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    assert mda.shape == (2, 2)\n    assert mda.rank() == 2\n    assert mda.tolist() == [[1, 2], [3, 4]]\n\n    mda[0, 0] = 5\n    assert mda.tolist() == [[5, 2], [3, 4]]\n\n    mda[1, 1] = 6\n    assert mda.tolist() == [[5, 2], [3, 6]]\n\n    mda = MutableDenseNDimArray(range(10, 34), (2, 3, 4))\n    assert mda.tolist() == [[[10, 11, 12, 13],\n            [14, 15, 16, 17],\n            [18, 19, 20, 21]],\n\n           [[22, 23, 24, 25],\n            [26, 27, 28, 29],\n            [30, 31, 32, 33]]]\n\n    mda[0, 1, 2] = 100\n    assert mda.tolist() == [[[10, 11, 12, 13],\n            [14, 15, 100, 17],\n            [18, 19, 20, 21]],\n\n           [[22, 23, 24, 25],\n            [26, 27, 28, 29],\n            [30, 31, 32, 33]]]\n\n    mda = MutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    ida = mda.as_immutable()\n    assert ida.shape == (2, 2)\n    assert ida.rank() == 2\n    assert ida.tolist() == [[1, 2], [3, 4]]\n\n    raises(TypeError, lambda: ida[0, 0] = 5)\n\n    mda = MutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    ida = mda.as_immutable()\n    assert mda.free_symbols == set()\n    assert ida.free_symbols == set()\n\n   "], "sample_1181": ["def test_numpy_matrix_solve():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    M = MatrixSymbol(\"M\", 3, 3)\n    x = MatrixSymbol(\"x\", 3, 1)\n\n    expr = MatrixSolve(M, x)\n\n    f = lambdify((M, x), expr, 'numpy')\n\n    m0 = np.array([[1, 2, 3], [3, 2, 5], [5, 6, 7]])\n    assert np.linalg.matrix_rank(m0) == 3\n\n    x0 = np.array([3, 4, 5])\n\n    assert np.allclose(f(m0, x0), np.linalg.solve(m0, x0))\n"], "sample_1196": ["def test_contains_eval():\n    x = Symbol('x')\n    assert Contains(x, S.Integers).eval(x, S.Integers) == Contains(x, S.Integers)\n    assert Contains(1, S.Integers).eval(1, S.Integers) is S.true\n    assert Contains(1, S.Naturals).eval(1, S.Naturals) is S.true\n    assert Contains(-1, S.Naturals).eval(-1, S.Naturals) is S.false\n"], "sample_685": ["def test_log_auto_indent(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            logger = logging.getLogger('catchlog')\n            logger.info(\"INFO message with\\\\nmultiline content\")\n            assert len(caplog.text.splitlines()) == 2\n            assert len(caplog.messages) == 1\n            assert caplog.messages[0] == \"INFO message with\\\\nmultiline content\"\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_auto_indent = True\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    assert result.ret == 0\n    assert len(result.stdout.splitlines()) == 2\n    assert result.stdout.fnmatch_lines([\"*INFO message with*\"])\n    assert result.stdout.fnmatch_lines([\"*multiline content*\"])\n\n"], "sample_266": ["    def test_replacing_migration(self):\n        \"\"\"\n        Tests loading a replacing migration.\n        \"\"\"\n        loader = MigrationLoader(connection)\n        recorder = MigrationRecorder(connection)\n        self.addCleanup(recorder.flush)\n\n        # Load with nothing applied: replacing migration is used.\n        loader.build_graph()\n        plan = set(loader.graph.forwards_plan(('migrations', '0003_replacing')))\n        plan = plan - loader.applied_migrations.keys()\n        expected_plan = {\n            ('migrations', '0001_initial'),\n            ('migrations', '0003_replacing'),\n        }\n        self.assertEqual(plan, expected_plan)\n\n        # Fake-apply one of the replaced migrations: replacing migration is not used.\n        recorder.record_applied('migrations', '0002_second')\n        loader.build_graph()\n        plan = set(loader.graph.forwards_plan(('migrations', '0003_replacing')))\n        plan = plan - loader.applied_migrations.keys()\n        expected_plan = {\n            ('migrations', '0001_initial'),\n            ('migrations', '0002_second'),\n            ('migrations', '0003_replacing'),\n        }\n        self.assertEqual(plan, expected_plan)\n\n        # Fake-apply the other replaced migration: replacing migration is used again.\n        recorder.record_applied('migrations', '0002_third')\n        loader.build_graph()\n        plan = set(loader.graph.forwards_plan(('migrations', '0003_replacing')))\n        plan = plan - loader.applied_migrations.keys()\n        expected_plan = {\n            ('migrations', '0001_initial'),\n            ('migrations', '0003_replacing'),\n        }\n        self.assertEqual(plan, expected_plan)\n"], "sample_728": ["def test_make_circles():\n    X, y = make_circles(n_samples=5, shuffle=False, noise=0.0, random_state=0)\n\n    assert_equal(X.shape, (5, 2), \"X shape mismatch\")\n    assert_equal(y.shape, (5,), \"y shape mismatch\")\n\n    outer_circ_x = X[y == 0, 0]\n    outer_circ_y = X[y == 0, 1]\n    inner_circ_x = X[y == 1, 0]\n    inner_circ_y = X[y == 1, 1]\n\n    assert_array_almost_equal(np.sqrt(outer_circ_x ** 2 + outer_circ_y ** 2),\n                              np.ones_like(outer_circ_x))\n    assert_array_almost_equal(np.sqrt(inner_circ_x ** 2 + inner_circ_y ** 2),\n                              0.8 * np.ones_like(inner_circ_x))\n"], "sample_327": ["def test_bound_data(self):\n    field = JSONField()\n    self.assertEqual(field.bound_data('{\"a\": \"b\"}', None), '{\"a\": \"b\"}')\n    self.assertEqual(field.bound_data(None, '{\"a\": \"b\"}'), '{\"a\": \"b\"}')\n    self.assertEqual(field.bound_data('{\"a\": \"b\"}', '{\"c\": \"d\"}'), '{\"a\": \"b\"}')\n    self.assertEqual(field.bound_data(None, None), None)\n"], "sample_178": ["def test_formset_absolute_max_with_min_num(self):\n    data = {\n        'form-TOTAL_FORMS': '1001',\n        'form-INITIAL_FORMS': '0',\n        'form-MAX_NUM_FORMS': '0',\n    }\n    LimitedFavoriteDrinksFormSet = formset_factory(\n        FavoriteDrinkForm,\n        min_num=30,\n        absolute_max=1000,\n    )\n    formset = LimitedFavoriteDrinksFormSet(data=data)\n    self.assertIs(formset.is_valid(), False)\n    self.assertEqual(len(formset.forms), 1000)\n    self.assertEqual(\n        formset.non_form_errors(),\n        ['Please submit 30 or more forms.'],\n    )\n"], "sample_174": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_43": ["def test_events_fitness(rseed=0):\n    rng = np.random.RandomState(rseed)\n    t = rng.rand(100)\n    x = np.ones_like(t)\n\n    bins1 = bayesian_blocks(t, fitness='events')\n    bins2 = bayesian_blocks(t, fitness=Events())\n    bins3 = bayesian_blocks(t, fitness=Events(p0=0.01))\n\n    assert_allclose(bins1, bins2)\n    assert_allclose(bins1, bins3)\n"], "sample_262": ["def test_lazy_object(self):\n    class Klazz:\n            self.value = value\n\n            return str(self.value)\n\n    lazy_obj = lazy(lambda: Klazz(123), Klazz)()\n    self.assertEqual(str(lazy_obj), '123')\n    self.assertIsInstance(lazy_obj, Klazz)\n"], "sample_107": ["    def test_technical_500_response(self):\n        request = RequestFactory().get('/')\n        exc_type = Exception\n        exc_value = Exception('Test exception')\n        tb = None\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html')\n"], "sample_63": ["    def test_dirs_default(self):\n        engine = Engine()\n        self.assertEqual(engine.dirs, [])\n"], "sample_585": ["def test_da_groupby_quantile():\n    # test groupby with a DataArray and quantile method\n    # create test data\n    array = xr.DataArray([1, 2, 3, 4, 5], coords=dict(x=[1, 1, 2, 2, 3]), dims='x')\n    # create test index\n    g = array.groupby('x')\n    actual = g.quantile(0.5)\n    expected = xr.DataArray([1.5, 3.5, 5], coords=dict(x=[1, 2, 3]), dims='x')\n    assert actual.equals(expected)\n"], "sample_96": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin, ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            'admin.E034'\n        )\n"], "sample_446": ["    def test_addslashes(self):\n        output = self.engine.render_to_string(\n            \"stringfilter01\", {\"a\": \"Hello, 'world'!\", \"b\": mark_safe(\"Hello, 'world'!\")}\n        )\n        self.assertEqual(output, 'Hello, \\\\'world!\\' Hello, \\\\'world!\\'')\n"], "sample_177": ["def test_get_related_models_recursive_with_self_referential_m2m(self):\n    \"\"\"\n    #24513 - Modifying an object pointing to itself would cause it to be\n    rendered twice and thus breaking its related M2M through objects.\n    \"\"\"\n    class A(models.Model):\n        to_a = models.ManyToManyField('related_models_app.A', symmetrical=False)\n\n        class Meta:\n            app_label = \"related_models_app\"\n\n    A = self.create_model(\"A\", foreign_keys=[models.ManyToManyField('A', symmetrical=False)])\n    self.assertEqual(\n        get_related_models_recursive(A),\n        {('related_models_app', 'a'), ('related_models_app', 'a_a_1')},\n    )\n"], "sample_646": ["def test_unittest_subclass_with_metaclass(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n\n        class Meta(type):\n            pass\n\n        class MyTestCase(unittest.TestCase, metaclass=Meta):\n                pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n"], "sample_621": ["    def test_default_indexes(self) -> None:\n        coords = {\n            \"x\": xr.Variable(\"x\", [1, 2, 3]),\n            \"y\": xr.Variable(\"y\", [4, 5, 6]),\n            \"z\": xr.Variable((\"x\", \"y\"), [[7, 8], [9, 10]]),\n        }\n        dims = [\"x\", \"y\"]\n\n        expected = {\n            \"x\": PandasIndex([1, 2, 3], \"x\"),\n            \"y\": PandasIndex([4, 5, 6], \"y\"),\n        }\n        actual = default_indexes(coords, dims)\n        for k, v in actual.items():\n            assert v.equals(expected[k])\n"], "sample_784": ["def test_calibration_curve_edge_cases():\n    \"\"\"Check calibration_curve function edge cases\"\"\"\n    # Test that calibration_curve works with a single sample\n    y_true = np.array([0])\n    y_pred = np.array([0.5])\n    prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=1)\n    assert_equal(len(prob_true), len(prob_pred))\n    assert_equal(len(prob_true), 1)\n    assert_almost_equal(prob_true, [0])\n    assert_almost_equal(prob_pred, [0.5])\n\n    # Test that calibration_curve works with a single class\n    y_true = np.array([0, 0, 0, 0, 0])\n    y_pred = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\n    prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=2)\n    assert_equal(len(prob_true), len(prob_pred))\n    assert_equal(len(prob_true), 1)\n    assert_almost_equal(prob_true, [0])\n    assert_almost_equal(prob_pred, [0.3])\n\n    # Test that calibration_curve works with a single prediction\n    y_true = np.array([0, 1, 0, 1, 0])\n    y_pred = np.array([0.5, 0.5, 0.5, 0.5, 0.5])\n    prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=2)\n    assert_equal(len(prob_true), len(prob_pred))\n    assert_equal(len(prob_true), 1)\n    assert_almost_equal(prob_true, [0.4])\n    assert_almost_equal(prob_pred, [0.5])\n"], "sample_111": ["def test_get_ordering_field_columns_with_custom_ordering(self):\n    \"\"\"\n    Regression test for #12345: Custom ordering fields should be correctly\n    identified in get_ordering_field_columns.\n    \"\"\"\n    class CustomOrderingModelAdmin(admin.ModelAdmin):\n        list_display = ['name', 'custom_ordering_field']\n        ordering = ['custom_ordering_field']\n\n            return obj.name.upper()\n\n        custom_ordering_field.admin_order_field = 'name'\n\n    m = CustomOrderingModelAdmin(Band, custom_site)\n    request = self.factory.get('/band/')\n    request.user = self.superuser\n    cl = m.get_changelist_instance(request)\n    self.assertEqual(cl.get_ordering_field_columns(), {2: 'asc'})\n"], "sample_116": ["    def test_with_none_vary_on(self):\n        key = make_template_fragment_key('foo', None)\n        self.assertEqual(key, 'template.cache.foo.d41d8cd98f00b204e9800998ecf8427e')\n"], "sample_635": ["def test_finds_missing_property_type_sphinx(self) -> None:\n    \"\"\"Example of a property having missing type documentation in\n    a Sphinx style docstring\n    \"\"\"\n    property_node, node = astroid.extract_node(\n        \"\"\"\n    class Foo(object):\n        @property\n            '''docstring ...\n\n            :raises RuntimeError: Always\n            '''\n            raise RuntimeError()\n            return 10 #@\n    \"\"\"\n    )\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"missing-type-doc\", node=property_node)\n    ):\n        self.checker.visit_functiondef(node)\n"], "sample_996": ["def test_doit_with_hints():\n    assert product(2, (k, 1, n), evaluate=False).doit(deep=False) == Product(2, (k, 1, n))\n    assert product(2, (k, 1, n), evaluate=False).doit(deep=True) == 2**(n - 1)\n    assert product(2, (k, 1, n), evaluate=False).doit(deep=True, force=True) == 2**(n - 1)\n    assert product(2, (k, 1, n), evaluate=False).doit(deep=False, force=True) == Product(2, (k, 1, n))\n"], "sample_770": ["def test_davies_bouldin_score():\n    assert_raises_on_only_one_label(davies_bouldin_score)\n\n    assert_raises_on_all_points_same_cluster(davies_bouldin_score)\n\n    # Assert the value is 0. when all samples are equals\n    assert_equal(0., davies_bouldin_score(np.ones((10, 2)),\n                                          [0] * 5 + [1] * 5))\n\n    # General case (with non numpy arrays)\n    X = ([[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5 +\n         [[0, 4], [1, 3]] * 5 + [[3, 1], [4, 0]] * 5)\n    labels = [0] * 10 + [1] * 10 + [2] * 10 + [3] * 10\n    pytest.approx(davies_bouldin_score(X, labels), 0.45, abs=1e-2)\n"], "sample_388": ["    def setUp(self):\n        self.backend = ModelBackend()\n"], "sample_1084": ["def test_intersection_sets():\n    assert intersection_sets(S.Integers, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Naturals, S.Integers) == S.Naturals\n    assert intersection_sets(S.Integers, S.Naturals0) == S.Naturals0\n    assert intersection_sets(S.Naturals0, S.Integers) == S.Naturals0\n    assert intersection_sets(S.Naturals, S.Naturals0) == S.Naturals0\n    assert intersection_sets(S.Naturals0, S.Naturals) == S.Naturals0\n    assert intersection_sets(S.Integers, S.Rationals) == S.Integers\n    assert intersection_sets(S.Rationals, S.Integers) == S.Integers\n    assert intersection_sets(S.Naturals, S.Rationals) == S.Naturals\n    assert intersection_sets(S.Rationals, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Naturals0, S.Rationals) == S.Naturals0\n    assert intersection_sets(S.Rationals, S.Naturals0) == S.Naturals0\n    assert intersection_sets(S.Integers, S.Reals) == S.Integers\n    assert intersection_sets(S.Reals, S.Integers) == S.Integers\n    assert intersection_sets(S.Naturals, S.Reals) == S.Naturals\n    assert intersection_sets(S.Reals, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Naturals0, S.Reals) == S.Naturals0\n    assert intersection_sets(S.Reals, S.Naturals0) == S.Naturals0\n    assert intersection_sets(S.Rationals, S.Reals) == S.Rationals\n    assert intersection_sets(S.Reals, S.Rationals) == S.Rationals\n    assert intersection_sets(S.Integers, S.Complexes) == S.Integers\n    assert intersection_sets(S.Complexes, S.Integers) == S.Integers\n    assert intersection_sets(S.Naturals, S.Complexes) == S.Naturals\n    assert intersection_sets(S.Complexes, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Naturals0, S.Complexes) == S.Naturals0\n    assert intersection_sets(S.Complexes, S"], "sample_755": ["def test_davies_bouldin_score():\n    assert_raises_on_only_one_label(davies_bouldin_score)\n\n    assert_raises_on_all_points_same_cluster(davies_bouldin_score)\n\n    # Assert the value is 0. when all samples are equals\n    assert 0. == davies_bouldin_score(np.ones((10, 2)),\n                                      [0] * 5 + [1] * 5)\n\n    # General case (with non numpy arrays)\n    X = ([[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5 +\n         [[0, 4], [1, 3]] * 5 + [[3, 1], [4, 0]] * 5)\n    labels = [0] * 10 + [1] * 10 + [2] * 10 + [3] * 10\n    pytest.approx(davies_bouldin_score(X, labels),\n                  0.75, abs=1e-2)\n"], "sample_288": ["    def test_key_transform_factory(self):\n        field = models.JSONField()\n        transform = field.get_transform('key')\n        self.assertIsInstance(transform, KeyTransformFactory)\n        self.assertEqual(transform.key_name, 'key')\n"], "sample_82": ["def test_selectdate_widget_with_custom_empty_labels(self):\n    widget = SelectDateWidget(\n        years=('2014',),\n        months=MONTHS_AP,\n        empty_label=('empty_year', 'empty_month', 'empty_day')\n    )\n    self.check_html(widget, 'mydate', '', html=(\n        \"\"\"\n        <select name=\"mydate_month\" id=\"id_mydate_month\">\n            <option selected value=\"\">empty_month</option>\n            <option value=\"1\">Jan.</option>\n            <option value=\"2\">Feb.</option>\n            <option value=\"3\">March</option>\n            <option value=\"4\">April</option>\n            <option value=\"5\">May</option>\n            <option value=\"6\">June</option>\n            <option value=\"7\">July</option>\n            <option value=\"8\">Aug.</option>\n            <option value=\"9\">Sept.</option>\n            <option value=\"10\">Oct.</option>\n            <option value=\"11\">Nov.</option>\n            <option value=\"12\">Dec.</option>\n        </select>\n\n        <select name=\"mydate_day\" id=\"id_mydate_day\">\n            <option selected value=\"\">empty_day</option>\n            <option value=\"1\">1</option>\n            <option value=\"2\">2</option>\n            <option value=\"3\">3</option>\n            <option value=\"4\">4</option>\n            <option value=\"5\">5</option>\n            <option value=\"6\">6</option>\n            <option value=\"7\">7</option>\n            <option value=\"8\">8</option>\n            <option value=\"9\">9</option>\n            <option value=\"10\">10</option>\n            <option value=\"11\">11</option>\n            <option value=\"12\">12</option>\n            <option value=\"13\">13</option>\n            <option value=\"14\">14</option>\n            <option value=\"15\">15</option>\n            <option value=\"16\">16</option>\n            <option value=\"17\">17</option>\n            <option value=\"18\">18</option>\n            <option value=\"19\">19</option>\n            <option value=\"20\">20</option>\n            <option value=\"21\">21</option>\n            <option value=\"22\">22</option>\n            <option value=\"23\">23</option>\n            <"], "sample_1207": ["def test_parse_expr_evaluate_false():\n    inputs = {\n        '2*x': '2*x',\n        '3.00': '3.00',\n        '22/7': '22/7',\n        '2+3j': '2+3j',\n        'exp(x)': 'exp(x)',\n        'x!': 'x!',\n        'x!!': 'x!!',\n        '(x + 1)! - 1': '(x + 1)! - 1',\n        '3.[3]': '3.[3]',\n        '.0[3]': '.0[3]',\n        '3.2[3]': '3.2[3]',\n        '1.3[12]': '1.3[12]',\n        '1 + 3.[3]': '1 + 3.[3]',\n        '1 + .0[3]': '1 + .0[3]',\n        '1 + 3.2[3]': '1 + 3.2[3]',\n        '.[0011]': '.[0011]',\n        '0.1[00102] + 1': '0.1[00102] + 1',\n        '1.[0191]': '1.[0191]',\n        '10!': '10!',\n        '-(2)': '-(2)',\n        '[-1, -2, 3]': '[-1, -2, 3]',\n        'Symbol(\"x\").free_symbols': 'Symbol(\"x\").free_symbols',\n        \"S('S(3).n(n=3)')\": \"S('S(3).n(n=3)')\",\n        'factorint(12, visual=True)': 'factorint(12, visual=True)',\n        'Limit(sin(x), x, 0, dir=\"-\")': 'Limit(sin(x), x, 0, dir=\"-\")',\n        'Q.even(x)': 'Q.even(x)',\n    }\n    for text, result in inputs.items():\n        assert str(parse_expr(text, evaluate=False)) == result\n"], "sample_1109": ["def test_frac_edge_cases():\n    assert frac(0) == 0\n    assert frac(1) == 0\n    assert frac(-1) == 0\n    assert frac(S.Half) == S.Half\n    assert frac(-S.Half) == S.Half\n    assert frac(S.Infinity) == AccumBounds(0, 1)\n    assert frac(-S.Infinity) == AccumBounds(0, 1)\n    assert frac(S.NaN) is S.NaN\n    assert frac(S.ComplexInfinity) is S.NaN\n    assert frac(S.Zero) == 0\n    assert frac(S.One) == 0\n    assert frac(-S.One) == 0\n    assert frac(S.ImaginaryUnit) == S.ImaginaryUnit\n    assert frac(-S.ImaginaryUnit) == S.ImaginaryUnit\n    assert frac(S.ImaginaryUnit/2) == S.ImaginaryUnit/2\n    assert frac(-S.ImaginaryUnit/2) == S.ImaginaryUnit/2\n"], "sample_1027": ["def test_Poly_from_dict():\n    K = FF(3)\n\n    assert Poly.from_dict(\n        {0: 1, 1: 2}, gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n    assert Poly.from_dict(\n        {0: 1, 1: 5}, gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 2}, gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 5}, gens=x, domain=K).rep == DMP([K(2), K(1)], K)\n\n    assert Poly.from_dict({(0, 0): 1, (1, 1): 2}, gens=(\n        x, y), domain=K).rep == DMP([[K(2), K(0)], [K(1)]], K)\n\n    assert Poly.from_dict({0: 1, 1: 2}, gens=x).rep == DMP([ZZ(2), ZZ(1)], ZZ)\n    assert Poly.from_dict({0: 1, 1: 2}, gens=x, field=True).rep == DMP([QQ(2), QQ(1)], QQ)\n\n    assert Poly.from_dict({0: 1, 1: 2}, gens=x, domain=ZZ).rep == DMP([ZZ(2), ZZ(1)], ZZ)\n    assert Poly.from_dict({0: 1, 1: 2}, gens=x, domain=QQ).rep == DMP([QQ(2), QQ(1)], QQ)\n\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 2}, gens=x).rep == DMP([ZZ(2), ZZ(1)], ZZ)\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 2}, gens=x, field=True).rep == DMP([QQ(2), QQ(1)], QQ)\n\n    assert Poly.from_dict(\n        {(0,): 1, (1,): 2}, gens=x, domain=ZZ).rep == DMP([ZZ(2), ZZ("], "sample_216": ["def test_field_references(self):\n    \"\"\"\n    Tests the field_references function.\n    \"\"\"\n    model_tuple = (\"testapp\", \"Author\")\n    field = models.ForeignKey(\"testapp.Publisher\", models.CASCADE)\n    reference_model_tuple = (\"testapp\", \"Publisher\")\n    reference_field_name = \"name\"\n\n    # Test with a matching field\n    reference = field_references(model_tuple, field, reference_model_tuple, reference_field_name)\n    self.assertIsNotNone(reference)\n    self.assertIsInstance(reference, FieldReference)\n    self.assertEqual(reference.to, (field, None))\n    self.assertIsNone(reference.through)\n\n    # Test with a non-matching field\n    field = models.ForeignKey(\"otherapp.Book\", models.CASCADE)\n    reference = field_references(model_tuple, field, reference_model_tuple, reference_field_name)\n    self.assertIsNone(reference)\n\n    # Test with a matching through field\n    field = models.ManyToManyField(\"testapp.Publisher\", through=\"testapp.Contract\")\n    reference = field_references(model_tuple, field, reference_model_tuple)\n    self.assertIsNotNone(reference)\n    self.assertIsInstance(reference, FieldReference)\n    self.assertIsNone(reference.to)\n    self.assertEqual(reference.through, (field, field.through_fields))\n\n    # Test with a non-matching through field\n    field = models.ManyToManyField(\"otherapp.Book\", through=\"otherapp.Attribution\")\n    reference = field_references(model_tuple, field, reference_model_tuple)\n    self.assertIsNone(reference)\n"], "sample_264": ["def test_store_empty_messages(self):\n    \"\"\"\n    Test that an empty list of messages is stored correctly.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n    storage.update(response)\n    self.assertEqual(response.cookies.get('messages'), None)\n\n    storage = self.get_storage()\n    response = self.get_response()\n    storage.add(constants.INFO, 'test')\n    for m in storage:\n        pass  # Iterate through the storage to simulate consumption of messages.\n    storage.update(response)\n    self.assertEqual(response.cookies.get('messages').value, '')\n"], "sample_114": ["def test_alter_field_to_fk_dependency_other_app(self):\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author_fk],\n        [self.author_empty, self.book],\n    )\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '__first__')])\n"], "sample_622": ["    def test_encode_cf_variable_with_non_standard_calendar(self) -> None:\n        # regression test for GH347\n        attrs = {\"units\": \"days since 0001-01-01\", \"calendar\": \"noleap\"}\n        v = Variable([\"time\"], [0, 1], attrs)\n        encoded = conventions.encode_cf_variable(v)\n        assert encoded.attrs[\"units\"] == \"days since 0001-01-01\"\n        assert encoded.attrs[\"calendar\"] == \"noleap\"\n"], "sample_1132": ["def test_ibin():\n    assert ibin(2) == [1, 0]\n    assert ibin(2, 4) == [0, 0, 1, 0]\n    assert ibin(2, 'all') == [(0, 0), (0, 1), (1, 0), (1, 1)]\n    assert ibin(3, 'all', str=True) == ['000', '001', '010', '011', '100', '101', '110', '111']\n    assert ibin(123, 10, str=True) == '0001111011'\n    assert ibin(123, 10, str=True)[::-1] == '1101111000'\n    assert list(ibin(3, 'all', str=True)) == ['000', '001', '010', '011', '100', '101', '110', '111']\n    raises(ValueError, lambda: ibin(-1))\n    raises(ValueError, lambda: ibin(1, -1))\n    raises(ValueError, lambda: ibin(1, 1, 'a'))\n"], "sample_530": ["def test_drawing_area_add_artist():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100)\n    child = mpatches.Rectangle((0, 0), 50, 50, facecolor='red')\n    da.add_artist(child)\n    ax.add_artist(da)\n    assert child.axes == ax\n    assert child.get_transform() == da.get_transform()\n    assert child.figure == fig\n"], "sample_270": ["    def test_unique_constraint_with_include_pointing_to_fk(self):\n        class Target(models.Model):\n            pass\n\n        class Model(models.Model):\n            fk_1 = models.ForeignKey(Target, models.CASCADE, related_name='target_1')\n            fk_2 = models.ForeignKey(Target, models.CASCADE, related_name='target_2')\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['fk_1_id', 'fk_2'],\n                        name='unique_age_include_id',\n                        include=['id'],\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n"], "sample_100": ["    def test_enable_echo(self, mocked_stdin, mocked_termios):\n        mocked_stdin.isatty.return_value = True\n        mocked_termios.tcgetattr.return_value = [0, 0, 0, 0]\n        autoreload.ensure_echo_on()\n        mocked_termios.tcsetattr.assert_called_once_with(mocked_stdin, mocked_termios.TCSANOW, [0, 0, 0, mocked_termios.ECHO])\n"], "sample_650": ["def test_log_format_with_percentf_log(pytester: Pytester) -> None:\n    \"\"\"Check that log_format affects output.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n\n        logger = logging.getLogger(__name__)\n\n            logger.warning('text')\n            assert False\n        \"\"\"\n    )\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_format=%(asctime)s; %(levelname)s; %(message)s\n        log_date_format=%Y-%m-%d %H:%M:%S.%f\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 1\n    result.stdout.re_match_lines([r\"^[0-9-]{10} [0-9:]{8}.[0-9]{6}; WARNING; text\"])\n"], "sample_1015": ["def test_ccode_Complex():\n    from sympy import I\n    assert ccode(I) == \"I\"\n    assert ccode(1 + I) == \"1 + I\"\n    assert ccode(1 + 2*I) == \"1 + 2*I\"\n    assert ccode(1 + I, standard='c99') == \"1 + 1j\"\n    assert ccode(1 + 2*I, standard='c99') == \"1 + 2j\"\n    assert ccode(1 + I, type_aliases={complex_: complex64}) == \"1 + 1j\"\n    assert ccode(1 + 2*I, type_aliases={complex_: complex64}) == \"1 + 2j\"\n    assert ccode(1 + I, type_aliases={complex_: complex128}) == \"1 + 1j\"\n    assert ccode(1 + 2*I, type_aliases={complex_: complex128}) == \"1 + 2j\"\n"], "sample_406": ["    def test_manager_descriptor(self):\n        class TestModel(models.Model):\n            objects = ManagerDescriptor(Manager())\n\n        with self.assertRaisesMessage(\n            AttributeError, \"Manager isn't accessible via TestModel instances\"\n        ):\n            getattr(TestModel(), \"objects\")\n\n        self.assertTrue(hasattr(TestModel, \"objects\"))\n"], "sample_135": ["def test_escaped_format_characters(self):\n    my_birthday = datetime(1979, 7, 8, 22, 00)\n    self.assertEqual(dateformat.format(my_birthday, r'\\a'), 'a')\n    self.assertEqual(dateformat.format(my_birthday, r'\\A'), 'A')\n    self.assertEqual(dateformat.format(my_birthday, r'\\b'), 'b')\n    self.assertEqual(dateformat.format(my_birthday, r'\\c'), 'c')\n    self.assertEqual(dateformat.format(my_birthday, r'\\d'), 'd')\n    self.assertEqual(dateformat.format(my_birthday, r'\\e'), 'e')\n    self.assertEqual(dateformat.format(my_birthday, r'\\f'), 'f')\n    self.assertEqual(dateformat.format(my_birthday, r'\\g'), 'g')\n    self.assertEqual(dateformat.format(my_birthday, r'\\h'), 'h')\n    self.assertEqual(dateformat.format(my_birthday, r'\\i'), 'i')\n    self.assertEqual(dateformat.format(my_birthday, r'\\j'), 'j')\n    self.assertEqual(dateformat.format(my_birthday, r'\\l'), 'l')\n    self.assertEqual(dateformat.format(my_birthday, r'\\L'), 'L')\n    self.assertEqual(dateformat.format(my_birthday, r'\\m'), 'm')\n    self.assertEqual(dateformat.format(my_birthday, r'\\M'), 'M')\n    self.assertEqual(dateformat.format(my_birthday, r'\\n'), 'n')\n    self.assertEqual(dateformat.format(my_birthday, r'\\N'), 'N')\n    self.assertEqual(dateformat.format(my_birthday, r'\\o'), 'o')\n    self.assertEqual(dateformat.format(my_birthday, r'\\P'), 'P')\n    self.assertEqual(dateformat.format(my_birthday, r'\\r'), 'r')\n    self.assertEqual(dateformat.format(my_birthday, r'\\s'), 's')\n    self.assertEqual(dateformat.format(my_birthday, r'\\S'), 'S')\n    self.assertEqual(dateformat.format(my_birthday, r'\\t'), 't')\n    self.assertEqual(dateformat.format(my_birthday, r'\\T'), 'T')\n    self.assertEqual(dateformat.format(my_birthday, r'\\u'), 'u')\n    self.assertEqual(dateformat.format(my_birthday, r'\\U'), 'U')\n    self.assertEqual(dateformat.format(my_birthday, r'\\w'), 'w')\n    self.assertEqual(dateformat.format(my_birthday, r'\\W'), 'W')\n    self.assertEqual"], "sample_535": ["def test_table_edges():\n    fig, axs = plt.subplots(nrows=4, ncols=4, figsize=(8, 8))\n\n    for ax in axs.flat:\n        ax.axis('off')\n\n    axs[0, 0].table(cellText=[['1', '2'], ['3', '4']], loc='center', edges='open')\n    axs[0, 1].table(cellText=[['1', '2'], ['3', '4']], loc='center', edges='closed')\n    axs[0, 2].table(cellText=[['1', '2'], ['3', '4']], loc='center', edges='horizontal')\n    axs[0, 3].table(cellText=[['1', '2'], ['3', '4']], loc='center', edges='vertical')\n\n    axs[1, 0].table(cellText=[['1', '2'], ['3', '4']], loc='center', edges='B')\n    axs[1, 1].table(cellText=[['1', '2'], ['3', '4']], loc='center', edges='T')\n    axs[1, 2].table(cellText=[['1', '2'], ['3', '4']], loc='center', edges='L')\n    axs[1, 3].table(cellText=[['1', '2'], ['3', '4']], loc='center', edges='R')\n\n    axs[2, 0].table(cellText=[['1', '2'], ['3', '4']], loc='center', edges='BT')\n    axs[2, 1].table(cellText=[['1', '2'], ['3', '4']], loc='center', edges='BL')\n    axs[2, 2].table(cellText=[['1', '2'], ['3', '4']], loc='center', edges='TR')\n    axs[2, 3].table(cellText=[['1', '2'], ['3', '4']], loc='center', edges='TL')\n\n    axs[3, 0].table(cellText=[['1', '2'], ['3', '4']], loc='center', edges='BRTL')\n    axs[3, 1].table(cellText=[['1', '2'], ['3', '4']], loc='center', edges='TBRL')\n    axs[3, "], "sample_11": ["def test_dropped_dimensions_serialized_classes():\n    wcs = WCS_SPECTRAL_CUBE\n\n    sub = SlicedLowLevelWCS(wcs, np.s_[0, :, 0])\n\n    dwd = sub.dropped_world_dimensions\n    wao_classes = dwd.pop(\"world_axis_object_classes\")\n    validate_info_dict(dwd, {\n        \"value\": [12.86995801, 20.49217541],\n        \"world_axis_physical_types\": [\"pos.galactic.lat\", \"pos.galactic.lon\"],\n        \"world_axis_names\": [\"Latitude\", \"Longitude\"],\n        \"world_axis_units\": [\"deg\", \"deg\"],\n        \"serialized_classes\": False,\n        \"world_axis_object_components\": [('celestial', 1, 'spherical.lat.degree'), ('celestial', 0, 'spherical.lon.degree')],\n        })\n\n    assert wao_classes['celestial'][0] is SkyCoord\n    assert wao_classes['celestial'][1] == ()\n    assert isinstance(wao_classes['celestial'][2]['frame'], Galactic)\n    assert wao_classes['celestial'][2]['unit'] is u.deg\n\n    # Test with serialized_classes=True\n    sub = SlicedLowLevelWCS(wcs, np.s_[0, :, 0], serialized_classes=True)\n\n    dwd = sub.dropped_world_dimensions\n    wao_classes = dwd.pop(\"world_axis_object_classes\")\n    validate_info_dict(dwd, {\n        \"value\": [12.86995801, 20.49217541],\n        \"world_axis_physical_types\": [\"pos.galactic.lat\", \"pos.galactic.lon\"],\n        \"world_axis_names\": [\"Latitude\", \"Longitude\"],\n        \"world_axis_units\": [\"deg\", \"deg\"],\n        \"serialized_classes\": True,\n        \"world_axis_object_components\": [('celestial', 1, 'spherical.lat.degree'), ('celestial', 0, 'spherical.lon.degree')],\n        })\n\n    assert wao_classes['celestial'][0] == 'astropy.coordinates.sky_coordinate.SkyCoord'\n    assert wao_classes['celestial'][1] == ()\n    assert wao_classes['celestial'][2]['frame'] == 'astropy.coordinates.galactic.Galactic'\n    assert wao_classes['celestial'][2]['unit'] == 'astropy.units.deg'\n"], "sample_602": ["def test_open_dataset_with_invalid_chunks():\n    with pytest.raises(ValueError):\n        xr.open_dataset(\"example.nc\", chunks=\"invalid\")\n\n    with pytest.raises(ValueError):\n        xr.open_dataset(\"example.nc\", chunks={\"invalid\": 1})\n"], "sample_1066": ["def test_print_SingularityFunction():\n    assert mp.doprint(SingularityFunction(x, 4, 5)) == \\\n        '<apply><power/><apply><minus/><ci>x</ci><cn>4</cn></apply><cn>5</cn></apply>'\n    assert mp.doprint(SingularityFunction(x, -3, 4)) == \\\n        '<apply><power/><apply><plus/><ci>x</ci><cn>3</cn></apply><cn>4</cn></apply>'\n    assert mp.doprint(SingularityFunction(x, 0, 4)) == \\\n        '<apply><power/><ci>x</ci><cn>4</cn></apply>'\n    assert mp.doprint(SingularityFunction(x, a, n)) == \\\n        '<apply><power/><apply><minus/><ci>x</ci><ci>a</ci></apply><ci>n</ci></apply>'\n    assert mp.doprint(SingularityFunction(x, 4, -2)) == \\\n        '<apply><power/><apply><minus/><ci>x</ci><cn>4</cn></apply><cn>-2</cn></apply>'\n    assert mp.doprint(SingularityFunction(x, 4, -1)) == \\\n        '<apply><power/><apply><minus/><ci>x</ci><cn>4</cn></apply><cn>-1</cn></apply>'\n"], "sample_12": ["def test_longitude_wrap_at_edge_cases():\n    \"\"\"\n    Test Longitude wrapping at edge cases\n    \"\"\"\n\n    # Test wrapping at 0 degrees\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian)\n    assert np.all(lon.degree == np.array([0., 90, 180, 270, 0]))\n\n    # Test wrapping at 180 degrees\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle='180d')\n    assert np.all(lon.degree == np.array([0., 90, -180, -90, 0]))\n\n    # Test wrapping at -180 degrees\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle='-180d')\n    assert np.all(lon.degree == np.array([0., -90, 180, 90, 0]))\n\n    # Test wrapping at 360 degrees\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle='360d')\n    assert np.all(lon.degree == np.array([0., 90, 180, 270, 0]))\n\n    # Test wrapping at -360 degrees\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle='-360d')\n    assert np.all(lon.degree == np.array([0., -90, 180, 90, 0]))\n"], "sample_246": ["    def test_build_file_class(self):\n        cmd = MakeMessagesCommand()\n        cmd.domain = 'django'\n        cmd.locale_paths = []\n        cmd.default_locale_path = os.path.join(self.test_dir, 'locale')\n        translatable = cmd.translatable_file_class(self.test_dir, 'test.html', cmd.default_locale_path)\n        build_file = cmd.build_file_class(cmd, cmd.domain, translatable)\n        self.assertEqual(build_file.path, os.path.join(self.test_dir, 'test.html'))\n        self.assertEqual(build_file.work_path, os.path.join(self.test_dir, 'test.html.py'))\n"], "sample_819": ["def test_voting_regressor_set_params():\n    \"\"\"Test set_params for VotingRegressor\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor()\n    ereg = VotingRegressor([('lr', reg1), ('rf', reg2)])\n    ereg.fit(X_r, y_r)\n    ereg.set_params(lr__fit_intercept=False)\n    assert ereg.estimators[0][1].get_params()['fit_intercept'] is False\n    assert ereg.get_params()[\"lr__fit_intercept\"] == ereg.get_params()[\"lr\"].get_params()['fit_intercept']\n\n    ereg.set_params(rf=None)\n    assert dict(ereg.estimators)[\"rf\"] is None\n    assert len(ereg.estimators_) == 1\n    assert isinstance(ereg.estimators_[0], LinearRegression)\n    assert ereg.get_params()[\"rf\"] is None\n\n    msg = 'All estimators are None. At least one is required!'\n    assert_raise_message(\n        ValueError, msg, ereg.set_params(lr=None, rf=None).fit, X_r, y_r)\n"], "sample_239": ["def test_formset_with_deletion_and_empty_forms(self):\n    \"\"\"\n    FormSets with deletion and empty forms.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_delete=True, extra=2)\n    initial = [{'choice': 'Calexico', 'votes': 100}, {'choice': 'Fergie', 'votes': 900}]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_904": ["def test_resolve_xref(app):\n    text = (\".. _label:\\n\"\n            \".. rubric:: blah *blah* blah\\n\"\n            \"\\n\"\n            \":ref:`label`\")\n    doctree = restructuredtext.parse(app, text)\n\n    domain = app.env.get_domain(\"std\")\n    refnode = domain.resolve_xref(app.env, 'index', app.builder, 'ref', 'label',\n                                  pending_xref(), nodes.paragraph())\n    assert_node(refnode, nodes.reference, refid=\"label\")\n    assert_node(refnode[0], nodes.inline, \"blah blah blah\")\n"], "sample_1086": ["def test_Pow_with_noncommutative_base():\n    A, B = symbols('A B', commutative=False)\n    assert str(A**2) == \"A**2\"\n    assert str(A**-2) == \"A**(-2)\"\n    assert str(A**Rational(1, 2)) == \"sqrt(A)\"\n    assert str(A**-Rational(1, 2)) == \"A**(-1/2)\"\n    assert str(A**B) == \"A**B\"\n    assert str(A**-B) == \"A**(-B)\"\n"], "sample_46": ["    def test_exact_lookup(self):\n        instance = UUIDModel.objects.create(field=uuid.uuid4())\n        lookup = Exact(self.model._meta.get_field('field'), instance.field)\n        self.assertEqual(lookup.as_sql(self.compiler, self.connection), \n                         (f'`model_fields_uuidmodel`.`field` = %s', [instance.field]))\n"], "sample_525": ["def test_subfigure_add_subplot_twotuple():\n    fig = plt.figure()\n    ax1 = fig.add_subfigure(111).add_subplot(3, 2, (3, 5))\n    assert ax1.get_subplotspec().rowspan == range(1, 3)\n    assert ax1.get_subplotspec().colspan == range(0, 1)\n    ax2 = fig.add_subfigure(111).add_subplot(3, 2, (4, 6))\n    assert ax2.get_subplotspec().rowspan == range(1, 3)\n    assert ax2.get_subplotspec().colspan == range(1, 2)\n    ax3 = fig.add_subfigure(111).add_subplot(3, 2, (3, 6))\n    assert ax3.get_subplotspec().rowspan == range(1, 3)\n    assert ax3.get_subplotspec().colspan == range(0, 2)\n    ax4 = fig.add_subfigure(111).add_subplot(3, 2, (4, 5))\n    assert ax4.get_subplotspec().rowspan == range(1, 3)\n    assert ax4.get_subplotspec().colspan == range(0, 2)\n    with pytest.raises(IndexError):\n        fig.add_subfigure(111).add_subplot(3, 2, (6, 3))\n"], "sample_537": ["def test_psd_twosided_norm():\n    u = np.array([0, 1, 2, 3, 1, 2, 1])\n    dt = 1.0\n    Su = np.abs(np.fft.fft(u) * dt)**2 / (dt * u.size)\n    P, f = mlab.psd(u, NFFT=u.size, Fs=1/dt, window=mlab.window_none,\n                    detrend=mlab.detrend_none, noverlap=0, pad_to=None,\n                    scale_by_freq=None,\n                    sides='twosided')\n    assert_allclose(P, Su, atol=1e-06)\n"], "sample_931": ["def test_pyvariable(app):\n    text = (\".. py:variable:: var\\n\"\n            \"   :type: int\\n\"\n            \"   :value: 1\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"var\"],\n                                                    [desc_annotation, (\": \",\n                                                                       [pending_xref, \"int\"])],\n                                                    [desc_annotation, \" = 1\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n    assert 'var' in domain.objects\n    assert domain.objects['var'] == ('index', 'var', 'data')\n"], "sample_1163": ["def test_polar_lift():\n    x = Symbol('x')\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == exp_polar(0)\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(-I*pi/2)\n    assert polar_lift(-I) == exp_polar(I*pi/2)\n    assert polar_lift(1 + I) == polar_lift(1 + I)\n    assert polar_lift(x) == polar_lift(x)\n    assert polar_lift(x*I) == polar_lift(x*I)\n    assert polar_lift(x + I) == polar_lift(x + I)\n    assert polar_lift(x*I + I) == polar_lift(x*I + I)\n    assert polar_lift(2*x) == 2*polar_lift(x)\n    assert polar_lift(2*x*I) == 2*polar_lift(x*I)\n    assert polar_lift(2 + 2*I) == 2*exp_polar(I*pi/4)\n    assert polar_lift(2 + 3*I) == polar_lift(2 + 3*I)\n    assert polar_lift(-2 + 3*I) == polar_lift(-2 + 3*I)\n    assert polar_lift(-2 - 3*I) == polar_lift(-2 - 3*I)\n    assert polar_lift(2 - 3*I) == polar_lift(2 - 3*I)\n"], "sample_534": ["def test_contour_labeler_event_handler():\n    # Test that the event handler for contour labeler works correctly\n    fig, ax = plt.subplots()\n    cs = ax.contour(np.arange(16).reshape((4, 4)))\n    inline = True\n    inline_spacing = 5\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 0, 0)\n    _contour_labeler_event_handler(cs, inline, inline_spacing, event)\n    assert len(cs.labelTexts) == 1\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 1, 1)\n    _contour_labeler_event_handler(cs, inline, inline_spacing, event)\n    assert len(cs.labelTexts) == 2\n    event = mpl.backend_bases.LocationEvent('key_press_event', fig.canvas, 0, 0, key='backspace')\n    _contour_labeler_event_handler(cs, inline, inline_spacing, event)\n    assert len(cs.labelTexts) == 1\n    event = mpl.backend_bases.LocationEvent('key_press_event', fig.canvas, 0, 0, key='enter')\n    _contour_labeler_event_handler(cs, inline, inline_spacing, event)\n    assert len(cs.labelTexts) == 1\n"], "sample_410": ["    def test_get_session_auth_hash(self):\n        user = User.objects.create_user(username=\"user\", password=\"password\")\n        session_auth_hash = user.get_session_auth_hash()\n        self.assertIsInstance(session_auth_hash, str)\n        self.assertEqual(len(session_auth_hash), 64)  # length of a SHA-256 hash\n"], "sample_1093": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n    assert not prntr.module_imports\n\n    assert prntr.doprint(pi) == 'math.pi'\n    assert prntr.module_imports == {'math': {'pi'}}\n\n    assert prntr.doprint(x**Rational(1, 2)) == 'math.sqrt(x)'\n    assert prntr.doprint(sqrt(x)) == 'math.sqrt(x)'\n    assert prntr.module_imports == {'math': {'pi', 'sqrt'}}\n\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n\n    assert prntr._print_Infinity(S.Infinity) == 'float(\"inf\")'\n    assert prntr._print_NegativeInfinity(S.NegativeInfinity) == 'float(\"-inf\")'\n    assert prntr._print_NaN(S.NaN) == 'float(\"nan\")'\n    assert prntr._print_ComplexInfinity(S.ComplexInfinity) == 'float(\"nan\")'\n\n    assert prntr._print_Relational(Eq(x,"], "sample_209": ["    def test_save_base_force_insert_force_update(self):\n        msg = \"Cannot force both insert and updating in model saving.\"\n        with self.assertRaisesMessage(ValueError, msg):\n            Article().save(force_insert=True, force_update=True)\n"], "sample_145": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin, ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            'admin.E034'\n        )\n"], "sample_861": ["def test_grid_search_with_sample_weight():\n    # Test that grid search works with sample weights\n    X, y = make_classification(n_samples=50, n_features=4, random_state=42)\n\n    n_splits = 3\n    params = [dict(kernel=['rbf', ], C=[1, 10], gamma=[0.1, 1]),\n              dict(kernel=['poly', ], degree=[1, 2])]\n\n    sample_weight = np.random.RandomState(0).randint(1, 10, size=len(y))\n\n    grid_search = GridSearchCV(SVC(), cv=n_splits, param_grid=params)\n    grid_search.fit(X, y, sample_weight=sample_weight)\n\n    for train, test in KFold(n_splits=n_splits).split(X, y):\n        for params in ParameterGrid(params):\n            clf = SVC(**params)\n            clf.fit(X[train], y[train], sample_weight=sample_weight[train])\n            score = clf.score(X[test], y[test], sample_weight=sample_weight[test])\n            assert_almost_equal(score, grid_search.cv_results_['split0_test_score'][0])\n"], "sample_596": ["def test_concat_positions_kwarg():\n    data = Dataset({\"foo\": (\"x\", [1, 2, 3])}, {\"x\": [0, 1, 2]})\n    split_data = [data.isel(x=slice(1)), data.isel(x=slice(1, None))]\n    expected = Dataset({\"foo\": (\"x\", [2, 1, 3])}, {\"x\": [1, 0, 2]})\n    actual = concat(split_data, \"x\", positions=[1, 0])\n    assert_identical(expected, actual)\n\n    with raises_regex(ValueError, \"length of positions does not match\"):\n        concat(split_data, \"x\", positions=[1])\n\n    with raises_regex(ValueError, \"positions must be integers\"):\n        concat(split_data, \"x\", positions=[1, \"a\"])\n"], "sample_1182": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(-Mod(x, y)) == '-(x % y)'\n    assert prntr.doprint(Mod(-x, y)) == '(-x) % y'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n    assert not prntr.module_imports\n\n    assert prntr.doprint(pi) == 'pi'\n    assert prntr.module_imports == set()\n\n    assert prntr.doprint(x**Rational(1, 2)) == 'x**(1/2)'\n    assert prntr.doprint(sqrt(x)) == 'sqrt(x)'\n    assert prntr.module_imports == set()\n\n    assert prntr.doprint(acos(x)) == 'acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else copysign(1, x))'\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n    assert prntr.doprint(KroneckerDelta(x,y)) == '(1 if x == y else 0)'\n\n    assert prntr.doprint((2,3)) == \"(2, 3)\"\n    assert prntr.doprint([2,3]) == \"[2, 3]\"\n\n    assert pr"], "sample_1169": ["def test_simplify_index_permutations():\n    i, j, k, l = symbols('i j k l', below_fermi=True)\n    a, b, c, d = symbols('a b c d', above_fermi=True)\n    p, q, r, s = symbols('p q r s', cls=Dummy)\n\n    f = Function('f')\n    g = Function('g')\n\n    expr = f(p)*g(q) - f(q)*g(p)\n    perms = [PermutationOperator(p,q)]\n    assert simplify_index_permutations(expr, perms) == f(p)*g(q)*PermutationOperator(p, q)\n\n    expr = f(p)*g(q) - f(q)*g(p) + f(r)*g(s) - f(s)*g(r)\n    perms = [PermutationOperator(p,q), PermutationOperator(r,s)]\n    assert simplify_index_permutations(expr, perms) == f(p)*g(q)*PermutationOperator(p, q) + f(r)*g(s)*PermutationOperator(r, s)\n\n    expr = f(p)*g(q) - f(q)*g(p) + f(r)*g(s) - f(s)*g(r) + f(p)*g(r) - f(r)*g(p) + f(q)*g(s) - f(s)*g(q)\n    perms = [PermutationOperator(p,q), PermutationOperator(r,s)]\n    assert simplify_index_permutations(expr, perms) == f(p)*g(q)*PermutationOperator(p, q) + f(r)*g(s)*PermutationOperator(r, s) + f(p)*g(r)*PermutationOperator(p, r) + f(q)*g(s)*PermutationOperator(q, s)\n"], "sample_277": ["def test_resolve_expression(self):\n    q = Q(x=1)\n    with self.assertRaisesMessage(NotImplementedError, 'Q.resolve_expression() is unused.'):\n        q.resolve_expression()\n\n    q = Q(x__in={}.keys())\n    with self.assertRaisesMessage(NotImplementedError, 'Q.resolve_expression() is unused.'):\n        q.resolve_expression()\n"], "sample_1185": ["def test_compogen():\n    assert compogen([sin(x), cos(x)], x) == sin(cos(x))\n    assert compogen([x**2 + x + 1, sin(x)], x) == sin(x)**2 + sin(x) + 1\n    assert compogen([sqrt(x), 6*x**2 - 5], x) == sqrt(6*x**2 - 5)\n    assert compogen([sin(x), sqrt(x), cos(x), x**2 + 1], x) == sin(sqrt(cos(x**2 + 1)))\n    assert compogen([x**2 - x - 1, x**2 + x], x) == -x**2 - x + (x**2 + x)**2 - 1\n    assert compogen([Abs(x), x**2 + 3*x - 4, cos(x)], x) == Abs(cos(x)**2 + 3*cos(x) - 4)\n    assert compogen([x**2 + x - sqrt(3)/2, sin(x)], x) == sin(x)**2 + sin(x) - sqrt(3)/2\n    assert compogen([Abs(x), 3*x + cos(y)**2 - 4, cos(x)], x) == Abs(cos(x)**2 + 3*cos(x) - 4 + cos(y)**2)\n    assert compogen([x], x) == x\n    assert compogen([1], x) == 1\n    assert compogen([Max(3, x)], x) == Max(3, x)\n    raises(TypeError, lambda: compogen([x < 5], x))\n    u = 2*x + 3\n    assert compogen([Max(sqrt(x), x**2), u], x) == Max(sqrt(2*x + 3), (2*x + 3)**2)\n    assert compogen([Max(x, x**2, y), u], x) == Max(2*x + 3, (2*x + 3)**2, y)\n    assert compogen([Max(2*x + 3, sin(x))], x) == Max(2*x + 3, sin(x))\n"], "sample_448": ["def test_validate_expression_with_condition_and_exclude(self):\n    constraint = models.UniqueConstraint(\n        Lower(\"name\"),\n        name=\"name_lower_without_color_uniq\",\n        condition=models.Q(color__isnull=True),\n    )\n    non_unique_product = UniqueConstraintProduct(name=self.p2.name.upper())\n    msg = \"Constraint \u201cname_lower_without_color_uniq\u201d is violated.\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        constraint.validate(UniqueConstraintProduct, non_unique_product)\n    # Values not matching condition are ignored.\n    constraint.validate(\n        UniqueConstraintProduct,\n        UniqueConstraintProduct(name=self.p1.name, color=self.p1.color),\n    )\n    # Existing instances have their existing row excluded.\n    constraint.validate(UniqueConstraintProduct, self.p2)\n    # Unique field is excluded.\n    constraint.validate(\n        UniqueConstraintProduct,\n        non_unique_product,\n        exclude={\"name\"},\n    )\n    # Field from a condition is excluded.\n    constraint.validate(\n        UniqueConstraintProduct,\n        non_unique_product,\n        exclude={\"color\"},\n    )\n    # Both unique field and field from a condition are excluded.\n    constraint.validate(\n        UniqueConstraintProduct,\n        non_unique_product,\n        exclude={\"name\", \"color\"},\n    )\n"], "sample_645": ["def test_log_capture_handler_reset(caplog):\n    caplog.set_level(logging.INFO)\n    logger.info(\"log message 1\")\n    assert len(caplog.records) == 1\n    caplog.handler.reset()\n    logger.info(\"log message 2\")\n    assert len(caplog.records) == 1\n    assert caplog.records[0].message == \"log message 2\"\n"], "sample_707": ["def test_node_repr_failure(pytester: Pytester) -> None:\n    items = pytester.getitems(\n        \"\"\"\n            assert False\n    \"\"\"\n    )\n    item = items[0]\n    excinfo = pytest.raises(AssertionError, item.runtest)\n    result = item.repr_failure(excinfo)\n    assert isinstance(result, str)\n    assert \"AssertionError\" in result\n"], "sample_782": ["def test_column_transformer_transformer_weights():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    X_res_first = np.array([0, 1, 2]).reshape(-1, 1)\n    X_res_second = np.array([2, 4, 6]).reshape(-1, 1)\n    X_res_both = X_array\n\n    # test with transformer_weights\n    transformer_weights = {'trans1': .1, 'trans2': 10}\n    both = ColumnTransformer([('trans1', Trans(), [0]),\n                              ('trans2', Trans(), [1])],\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * X_res_first1D,\n                     transformer_weights['trans2'] * X_res_second1D]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and remainder\n    transformer_weights = {'trans1': .1}\n    both = ColumnTransformer([('trans1', Trans(), [0])],\n                             remainder='passthrough',\n                             transformer_weights=transformer_weights)\n    res = np.hstack([transformer_weights['trans1'] * X_res_first, X_res_second])\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and remainder transformer\n    transformer_weights = {'trans1': .1}\n    both = ColumnTransformer([('trans1', Trans(), [0])],\n                             remainder=DoubleTrans(),\n                             transformer_weights=transformer_weights)\n    res = np.hstack([transformer_weights['trans1'] * X_res_first,\n                     2 * X_res_second])\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and all transformers are 'passthrough'\n    transformer_weights = {'trans1': .1, 'trans2': 10}\n    both = ColumnTransformer([('trans1', 'passthrough', [0]),\n                              ('trans2', 'pas"], "sample_367": ["    def test_cache_page_decorator(self):\n            return HttpResponse(\"response\")\n\n        my_view_cached = cache_page(123)(my_view)\n        request = HttpRequest()\n        response = my_view_cached(request)\n        self.assertEqual(response.content, b\"response\")\n"], "sample_356": ["def test_alter_field_with_deconstructible_default(self):\n    \"\"\"\n    AlterField should work with deconstructible default values.\n    \"\"\"\n    before = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject())),\n    ])\n    after = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject())),\n    ])\n    changes = self.get_changes([before], [after])\n    self.assertEqual(changes, {})\n\n    after = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject())),\n    ])\n    changes = self.get_changes([before], [after])\n    self.assertEqual(changes, {})\n\n    after = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject())),\n    ])\n    changes = self.get_changes([before], [after])\n    self.assertEqual(changes, {})\n"], "sample_202": ["def test_safedata(self):\n    \"\"\"\n    A message containing SafeData is keeping its safe status when\n    retrieved from the message storage.\n    \"\"\"\n        message = Message(constants.DEBUG, data)\n        encoded = storage._encode([message])\n        decoded = storage._decode(encoded)\n        return decoded[0].message\n\n    storage = self.get_storage()\n    data = mark_safe('<p>Hello, world!</p>')\n    self.assertIsInstance(encode_decode(data), SafeData)\n    self.assertEqual(encode_decode(data), data)\n\n    data = '<p>Hello, world!</p>'\n    self.assertNotIsInstance(encode_decode(data), SafeData)\n    self.assertEqual(encode_decode(data), data)\n"], "sample_817": ["def test_variance_threshold_edge_cases():\n    # Test VarianceThreshold with edge cases.\n\n    # Test with a single feature\n    X = [[1], [1], [1]]\n    sel = VarianceThreshold().fit(X)\n    assert_array_equal([], sel.get_support(indices=True))\n\n    # Test with all features having zero variance\n    X = [[1, 2, 3], [1, 2, 3], [1, 2, 3]]\n    assert_raises(ValueError, VarianceThreshold(threshold=0.1).fit, X)\n\n    # Test with a single sample\n    X = [[1, 2, 3]]\n    assert_raises(ValueError, VarianceThreshold(threshold=0.1).fit, X)\n\n    # Test with threshold equal to the variance of a feature\n    X = [[1, 2], [1, 4]]\n    sel = VarianceThreshold(threshold=1.5).fit(X)\n    assert_array_equal([1], sel.get_support(indices=True))\n"], "sample_982": ["def test_udivisor_sigma_edge_cases():\n    assert udivisor_sigma(0) == 0\n    assert udivisor_sigma(1) == 1\n    assert udivisor_sigma(-1) == 1\n    assert udivisor_sigma(2) == 3\n    assert udivisor_sigma(3) == 4\n    assert udivisor_sigma(4) == 7\n    assert udivisor_sigma(5) == 6\n    assert udivisor_sigma(6) == 12\n    assert udivisor_sigma(7) == 8\n    assert udivisor_sigma(8) == 15\n    assert udivisor_sigma(9) == 13\n    assert udivisor_sigma(10) == 18\n    assert udivisor_sigma(11) == 12\n    assert udivisor_sigma(12) == 28\n    assert udivisor_sigma(13) == 14\n    assert udivisor_sigma(14) == 24\n    assert udivisor_sigma(15) == 24\n    assert udivisor_sigma(16) == 31\n    assert udivisor_sigma(17) == 18\n    assert udivisor_sigma(18) == 39\n    assert udivisor_sigma(19) == 20\n    assert udivisor_sigma(20) == 42\n    assert udivisor_sigma(21) == 32\n    assert udivisor_sigma(22) == 36\n    assert udivisor_sigma(23) == 24\n    assert udivisor_sigma(24) == 60\n    assert udivisor_sigma(25) == 31\n    assert udivisor_sigma(26) == 42\n    assert udivisor_sigma(27) == 40\n    assert udivisor_sigma(28) == 56\n    assert udivisor_sigma(29) == 30\n    assert udivisor_sigma(30) == 72\n    assert udivisor_sigma(31) == 32\n    assert udivisor_sigma(32) == 63\n    assert udivisor_sigma(33) == 48\n    assert udivisor_sigma(34) == 54\n    assert udivisor_sigma(35) == 48\n    assert udivisor_sigma(36) == 91\n    assert udivisor_sigma"], "sample_280": ["def test_aggregate_default_with_distinct(self):\n    result = Author.objects.filter(age__gt=100).aggregate(\n        value=Avg('age', distinct=True, default=0),\n    )\n    self.assertEqual(result['value'], 0)\n\n    result = Author.objects.aggregate(\n        value=Avg('age', distinct=True, default=0),\n    )\n    self.assertEqual(result['value'], Approximate(37.4, places=1))\n"], "sample_183": ["    def test_window_function(self):\n        self.assertQuerysetEqual(\n            CaseTestModel.objects.annotate(\n                rank=Window(\n                    expression=Rank(),\n                    partition_by=F('integer'),\n                    order_by=F('integer2').asc(),\n                ),\n            ).order_by('pk'),\n            [(1, 1), (2, 1), (3, 1), (2, 2), (3, 2), (3, 3), (4, 1)],\n            transform=attrgetter('integer', 'rank')\n        )\n"], "sample_896": ["def test_nmf_inverse_transform_custom_init(Estimator, solver):\n    # Test that NMF.inverse_transform works with custom initialization\n    random_state = np.random.RandomState(0)\n    A = np.abs(random_state.randn(6, 5))\n    n_components = 4\n    avg = np.sqrt(A.mean() / n_components)\n    H_init = np.abs(avg * random_state.randn(n_components, 5))\n    W_init = np.abs(avg * random_state.randn(6, n_components))\n\n    m = Estimator(\n        n_components=n_components, init=\"custom\", random_state=0, tol=1e-3, **solver\n    )\n    m.fit_transform(A, W=W_init, H=H_init)\n    A_new = m.inverse_transform(m.transform(A))\n    assert_array_almost_equal(A, A_new, decimal=2)\n"], "sample_121": ["    def test_modelbase_metaclass(self):\n        class Model(metaclass=ModelBase):\n            pass\n\n        self.assertIsInstance(Model, ModelBase)\n"], "sample_181": ["def test_filtered_aggregate_with_exists(self):\n    agg = Sum('age', filter=Q(friends__isnull=False))\n    self.assertEqual(Author.objects.aggregate(age=agg)['age'], 200)\n"], "sample_703": ["def test_matcher_function(expr: str, matcher: Callable[[str], bool], expected: bool) -> None:\n    assert evaluate(expr, matcher) is expected\n"], "sample_1097": ["def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, k)\n    C = MatrixSymbol('C', l, m)\n    D = MatrixSymbol('D', l, k)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    real, imag = X.as_real_imag()\n    assert real.is_BlockMatrix\n    assert imag.is_BlockMatrix\n    assert real.blocks.shape == X.blocks.shape\n    assert imag.blocks.shape == X.blocks.shape\n    assert real.blocks[0, 0] == A.as_real_imag()[0]\n    assert real.blocks[0, 1] == B.as_real_imag()[0]\n    assert real.blocks[1, 0] == C.as_real_imag()[0]\n    assert real.blocks[1, 1] == D.as_real_imag()[0]\n    assert imag.blocks[0, 0] == A.as_real_imag()[1]\n    assert imag.blocks[0, 1] == B.as_real_imag()[1]\n    assert imag.blocks[1, 0] == C.as_real_imag()[1]\n    assert imag.blocks[1, 1] == D.as_real_imag()[1]\n"], "sample_171": ["def test_migrate_fake_initial_with_replaced_migration(self):\n    \"\"\"\n    --fake-initial works with replaced migrations.\n    \"\"\"\n    recorder = MigrationRecorder(connection)\n    recorder.record_applied(\"migrations\", \"0001_initial\")\n    recorder.record_applied(\"migrations\", \"0002_second\")\n    recorder.record_applied(\"migrations\", \"0001_squashed_0002\")\n    out = io.StringIO()\n    call_command(\"migrate\", \"migrations\", fake_initial=True, stdout=out, verbosity=1)\n    self.assertIn(\"migrations.0001_squashed_0002... faked\", out.getvalue().lower())\n    # Rollback changes\n    call_command(\"migrate\", \"migrations\", \"zero\", verbosity=0)\n"], "sample_767": ["def test_column_transformer_sparse_remainder_transformer_with_weights():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           sparse_threshold=0.8,\n                           transformer_weights={'trans1': 2})\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n    # SparseMatrixTrans creates 3 features for each column. There is\n    # one column in ``transformers``, thus:\n    assert X_trans.shape == (3, 3 + 1)\n\n    exp_array = np.hstack(\n        (2 * X_array[:, 0].reshape(-1, 1), np.eye(3)))\n    assert_array_equal(X_trans.toarray(), exp_array)\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], SparseMatrixTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n"], "sample_876": ["def test_mlp_classifier_with_sparse_input():\n    # Test that MLPClassifier works with sparse input.\n    X = X_digits_binary[:100]\n    y = y_digits_binary[:100]\n    X_sparse = csr_matrix(X)\n\n    mlp = MLPClassifier(hidden_layer_sizes=5, activation=\"logistic\", random_state=1)\n    with ignore_warnings(category=ConvergenceWarning):\n        mlp.fit(X_sparse, y)\n    y_pred_sparse = mlp.predict(X_sparse)\n    y_pred_dense = mlp.predict(X)\n\n    assert_array_equal(y_pred_sparse, y_pred_dense)\n"], "sample_803": ["def test_roc_auc_score_max_fpr():\n    # Test that roc_auc_score with max_fpr returns the same result as\n    # _partial_roc_auc_score\n    y_true, _, probas_pred = make_prediction(binary=True)\n    max_fpr = 0.5\n    auc = roc_auc_score(y_true, probas_pred, max_fpr=max_fpr)\n    assert_almost_equal(auc, _partial_roc_auc_score(y_true, probas_pred, max_fpr))\n\n    # Test that roc_auc_score with max_fpr raises an error when max_fpr is\n    # outside of the range [0, 1]\n    max_fpr = 1.5\n    assert_raise_message(ValueError, \"Expected max_frp in range ]0, 1], got: %r\"\n                         % max_fpr, roc_auc_score, y_true, probas_pred,\n                         max_fpr=max_fpr)\n\n    max_fpr = -0.5\n    assert_raise_message(ValueError, \"Expected max_frp in range ]0, 1], got: %r\"\n                         % max_fpr, roc_auc_score, y_true, probas_pred,\n                         max_fpr=max_fpr)\n"], "sample_850": ["def test_nystroem_edge_cases():\n    # test that Nystroem handles edge cases\n    rnd = np.random.RandomState(42)\n    X = rnd.uniform(size=(10, 4))\n\n    # test that n_components > n_samples raises an error\n    nystroem = Nystroem(n_components=X.shape[0] + 1)\n    assert_raises(ValueError, nystroem.fit, X)\n\n    # test that n_components = 0 raises an error\n    nystroem = Nystroem(n_components=0)\n    assert_raises(ValueError, nystroem.fit, X)\n\n    # test that n_components = 1 works\n    nystroem = Nystroem(n_components=1)\n    X_transformed = nystroem.fit_transform(X)\n    assert X_transformed.shape == (X.shape[0], 1)\n\n    # test that kernel_params is passed to the kernel function\n        return param * np.dot(X, Y.T)\n    nystroem = Nystroem(kernel=kernel, kernel_params={'param': 2})\n    X_transformed = nystroem.fit_transform(X)\n    K = 2 * np.dot(X, X.T)\n    assert_array_almost_equal(np.dot(X_transformed, X_transformed.T), K)\n"], "sample_373": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n"], "sample_253": ["    def test_empty_paths(self):\n        self.assertEqual(autoreload.common_roots(()), ())\n"], "sample_258": ["def test_receiver_decorator_with_sender(self):\n    @receiver(a_signal, sender=self)\n        self.state = val\n    self.state = False\n    a_signal.send(sender=self, val=True)\n    self.assertTrue(self.state)\n\n    # Test that the decorator doesn't connect the receiver to other senders\n    a_signal.send(sender=object(), val=False)\n    self.assertTrue(self.state)\n\n    # Test that the decorator doesn't connect the receiver to other signals\n    b_signal.send(sender=self, val=False)\n    self.assertTrue(self.state)\n"], "sample_81": ["    def test_reverse(self):\n        resolver = get_resolver(urlconf='django.urls.resolvers.tests.urls')\n        with self.assertRaises(NoReverseMatch):\n            resolver.reverse('nonexistent_view')\n"], "sample_1131": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n    assert not prntr.module_imports\n\n    assert prntr.doprint(pi) == 'pi'\n    assert prntr.module_imports == set()\n\n    assert prntr.doprint(x**Rational(1, 2)) == 'x**(1/2)'\n    assert prntr.doprint(sqrt(x)) == 'sqrt(x)'\n    assert prntr.module_imports == set()\n\n    assert prntr.doprint(acos(x)) == 'acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else copysign(1, x))'\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n    assert prntr.doprint(KroneckerDelta(x,y)) == '(1 if x == y else 0)'\n"], "sample_790": ["def test_kernel_pca_centering():\n    rng = np.random.RandomState(0)\n    X_fit = rng.random_sample((5, 4))\n    X_pred = rng.random_sample((2, 4))\n\n    for eigen_solver in (\"auto\", \"dense\", \"arpack\"):\n        for kernel in (\"linear\", \"rbf\", \"poly\"):\n            kpca = KernelPCA(4, kernel=kernel, eigen_solver=eigen_solver,\n                             fit_inverse_transform=False)\n            X_fit_transformed = kpca.fit_transform(X_fit)\n            X_pred_transformed = kpca.transform(X_pred)\n\n            # Check that the mean of the transformed data is close to zero\n            assert_allclose(np.mean(X_fit_transformed, axis=0), np.zeros(4))\n            assert_allclose(np.mean(X_pred_transformed, axis=0), np.zeros(4))\n"], "sample_628": ["def test_store_unknown_words(self):\n    self.checker.config.spelling_store_unknown_words = True\n    self.checker.open()\n    stmt = astroid.extract_node('def fff():\\n   \"\"\"bad coment\"\"\"\\n   pass')\n    self.checker.visit_functiondef(stmt)\n    assert self.linter.release_messages() == []\n    with open(self.checker.config.spelling_private_dict_file, \"r\") as f:\n        assert f.read().strip() == \"coment\"\n"], "sample_485": ["def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            \"Search for google.com/?q=!.\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>.',\n        ),\n        (\n            \"Search for google.com/?q=!?\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>?',\n        ),\n        (\n            \"Search for google.com/?q=!;\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>;',\n        ),\n        (\n            \"Search for google.com/?q=!:\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>:',\n        ),\n        (\n            \"Search for google.com/?q=!.\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>.',\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_743": ["def test_neighbors_base():\n    # Test the base class\n    X = rng.rand(10, 5)\n    y = rng.randint(0, 2, 10)\n\n    # Test that the base class raises an error when fit is called\n    nbrs = neighbors.NeighborsBase()\n    assert_raises(NotImplementedError, nbrs.fit, X)\n\n    # Test that the base class raises an error when kneighbors is called\n    nbrs = neighbors.NeighborsBase()\n    nbrs._fit_X = X\n    assert_raises(NotImplementedError, nbrs.kneighbors, X)\n\n    # Test that the base class raises an error when kneighbors_graph is called\n    nbrs = neighbors.NeighborsBase()\n    nbrs._fit_X = X\n    assert_raises(NotImplementedError, nbrs.kneighbors_graph, X)\n\n    # Test that the base class raises an error when radius_neighbors is called\n    nbrs = neighbors.NeighborsBase()\n    nbrs._fit_X = X\n    assert_raises(NotImplementedError, nbrs.radius_neighbors, X)\n\n    # Test that the base class raises an error when radius_neighbors_graph is called\n    nbrs = neighbors.NeighborsBase()\n    nbrs._fit_X = X\n    assert_raises(NotImplementedError, nbrs.radius_neighbors_graph, X)\n"], "sample_128": ["    def test_covering_index_with_opclasses(self):\n        index = Index(\n            name='covering_headline_idx',\n            fields=['headline'],\n            include=['pub_date', 'published'],\n            opclasses=['varchar_pattern_ops'],\n        )\n        with connection.schema_editor() as editor:\n            self.assertIn(\n                '(%s varchar_pattern_ops) INCLUDE (%s, %s)' % (\n                    editor.quote_name('headline'),\n                    editor.quote_name('pub_date'),\n                    editor.quote_name('published'),\n                ),\n                str(index.create_sql(Article, editor)),\n            )\n            editor.add_index(Article, index)\n            with connection.cursor() as cursor:\n                constraints = connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                )\n                self.assertIn(index.name, constraints)\n                self.assertEqual(\n                    constraints[index.name]['columns'],\n                    ['headline', 'pub_date', 'published'],\n                )\n            editor.remove_index(Article, index)\n            with connection.cursor() as cursor:\n                self.assertNotIn(index.name, connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                ))\n"], "sample_7": ["def test_column_insert_masked_with_fill_value():\n    \"\"\"\n    Test that inserting into a MaskedColumn with a fill_value works correctly.\n    \"\"\"\n    c = table.MaskedColumn([1, 2, 3], name='a', dtype=int, fill_value=9999)\n    c1 = c.insert(1, 100)\n    assert np.all(c1.data.data == [1, 100, 2, 3])\n    assert c1.fill_value == 9999\n    assert np.all(c1.data.mask == [False, False, False, False])\n\n    c1 = c.insert(1, 100, mask=True)\n    assert np.all(c1.data.data == [1, 100, 2, 3])\n    assert c1.fill_value == 9999\n    assert np.all(c1.data.mask == [False, True, False, False])\n\n    c1 = c.insert(1, 100, mask=[True, False])\n    assert np.all(c1.data.data == [1, 100, 2, 3])\n    assert c1.fill_value == 9999\n    assert np.all(c1.data.mask == [False, True, False, False])\n"], "sample_670": ["def test_matcher_function(expr: str, ident: str, expected: bool) -> None:\n    matcher = {ident: True}.__getitem__\n    assert evaluate(expr, matcher) is expected\n"], "sample_411": ["def test_base_command_requires_system_checks_tags(self):\n    class Command(BaseCommand):\n        requires_system_checks = [Tags.staticfiles, Tags.models]\n\n    cmd = Command()\n    self.assertEqual(cmd.requires_system_checks, [Tags.staticfiles, Tags.models])\n\n    class Command(BaseCommand):\n        requires_system_checks = \"__all__\"\n\n    cmd = Command()\n    self.assertEqual(cmd.requires_system_checks, \"__all__\")\n\n    class Command(BaseCommand):\n        requires_system_checks = \"invalid\"\n\n    with self.assertRaisesMessage(TypeError, \"requires_system_checks must be a list or tuple.\"):\n        Command()\n"], "sample_1129": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n    assert not prntr.module_imports\n\n    assert prntr.doprint(pi) == 'math.pi'\n    assert prntr.module_imports == {'math': {'pi'}}\n\n    assert prntr.doprint(x**Rational(1, 2)) == 'math.sqrt(x)'\n    assert prntr.doprint(sqrt(x)) == 'math.sqrt(x)'\n    assert prntr.module_imports == {'math': {'pi', 'sqrt'}}\n\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n    assert prntr.doprint(KroneckerDelta(x,y)) == '(1 if x == y else 0)'\n"], "sample_254": ["    def setUpTestData(cls):\n        cls.user = User.objects.create_user('testing', password='password', is_staff=True)\n        cls.user.user_permissions.add(\n            Permission.objects.get(codename='view_poll', content_type=ContentType.objects.get_for_model(Poll))\n        )\n        cls.user.user_permissions.add(\n            *Permission.objects.filter(\n                codename__endswith=\"question\", content_type=ContentType.objects.get_for_model(Question)\n            ).values_list('pk', flat=True)\n        )\n\n        cls.poll = Poll.objects.create(name=\"Survey\")\n        cls.add_url = reverse('admin:admin_inlines_poll_add')\n        cls.change_url = reverse('admin:admin_inlines_poll_change', args=(cls.poll.id,))\n"], "sample_546": ["def test_figure_subplots_adjust():\n    fig, axs = plt.subplots(2, 2)\n    fig.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9)\n    assert np.allclose(fig.subplotpars.left, 0.1)\n    assert np.allclose(fig.subplotpars.bottom, 0.1)\n    assert np.allclose(fig.subplotpars.right, 0.9)\n    assert np.allclose(fig.subplotpars.top, 0.9)\n    fig.subplots_adjust(left=0.2, bottom=0.2, right=0.8, top=0.8)\n    assert np.allclose(fig.subplotpars.left, 0.2)\n    assert np.allclose(fig.subplotpars.bottom, 0.2)\n    assert np.allclose(fig.subplotpars.right, 0.8)\n    assert np.allclose(fig.subplotpars.top, 0.8)\n    fig.subplots_adjust(wspace=0.1, hspace=0.1)\n    assert np.allclose(fig.subplotpars.wspace, 0.1)\n    assert np.allclose(fig.subplotpars.hspace, 0.1)\n    with pytest.raises(ValueError):\n        fig.subplots_adjust(left=1.1, bottom=0.1, right=0.9, top=0.9)\n    with pytest.raises(ValueError):\n        fig.subplots_adjust(left=0.1, bottom=1.1, right=0.9, top=0.9)\n"], "sample_459": ["    def test_lookup_identity(self):\n        lookup1 = Lookup(Value(1), Value(2))\n        lookup2 = Lookup(Value(1), Value(2))\n        lookup3 = Lookup(Value(1), Value(3))\n        self.assertEqual(lookup1, lookup2)\n        self.assertNotEqual(lookup1, lookup3)\n"], "sample_1194": ["def test_julia_codeprinter():\n    printer = JuliaCodePrinter()\n    assert printer._print_Mul(Mul(x, y, evaluate=False)) == \"x .* y\"\n    assert printer._print_Mul(Mul(2, x, evaluate=False)) == \"2 * x\"\n    assert printer._print_Mul(Mul(2, x, y, evaluate=False)) == \"2 * x .* y\"\n    assert printer._print_Mul(Mul(x, y, z, evaluate=False)) == \"x .* y .* z\"\n    assert printer._print_Mul(Mul(2, x, y, z, evaluate=False)) == \"2 * x .* y .* z\"\n    assert printer._print_Mul(Mul(-2, x, y, evaluate=False)) == \"-2 * x .* y\"\n    assert printer._print_Mul(Mul(-2, x, y, z, evaluate=False)) == \"-2 * x .* y .* z\"\n    assert printer._print_Mul(Mul(2, x, y, z, evaluate=False)) == \"2 * x .* y .* z\"\n    assert printer._print_Mul(Mul(-2, x, y, z, evaluate=False)) == \"-2 * x .* y .* z\"\n    assert printer._print_Mul(Mul(2, x, y, z, evaluate=False)) == \"2 * x .* y .* z\"\n    assert printer._print_Mul(Mul(-2, x, y, z, evaluate=False)) == \"-2 * x .* y .* z\"\n"], "sample_1000": ["def test_octave_codeprinter():\n    p = OctaveCodePrinter()\n    assert p._rate_index_position(1) == 5\n    assert p._get_statement(\"x = 5\") == \"x = 5;\"\n    assert p._get_comment(\"This is a comment\") == \"% This is a comment\"\n    assert p._declare_number_const(\"x\", 5) == \"x = 5;\"\n    assert p.indent_code([\"x = 5\", \"y = 3\"]) == [\"  x = 5\", \"  y = 3\"]\n    assert p._traverse_matrix_indices(Matrix([[1, 2], [3, 4]])) == ((0, 0), (0, 1), (1, 0), (1, 1))\n    assert p._get_loop_opening_ending([Idx('i', 5)]) == ([\"for i = 1:5\"], [\"end\"])\n"], "sample_197": ["def test_custom_time_strings(self):\n    \"\"\" Test custom time strings. \"\"\"\n    custom_time_strings = {\n        'year': npgettext_lazy('custom', '%d year', '%d years'),\n        'month': npgettext_lazy('custom', '%d month', '%d months'),\n        'week': npgettext_lazy('custom', '%d week', '%d weeks'),\n        'day': npgettext_lazy('custom', '%d day', '%d days'),\n        'hour': npgettext_lazy('custom', '%d hour', '%d hours'),\n        'minute': npgettext_lazy('custom', '%d minute', '%d minutes'),\n    }\n    with translation.override('en'):\n        self.assertEqual(timesince(self.t, self.t + self.oneminute, time_strings=custom_time_strings), '1\\xa0minute')\n        self.assertEqual(timesince(self.t, self.t + self.onehour, time_strings=custom_time_strings), '1\\xa0hour')\n        self.assertEqual(timesince(self.t, self.t + self.oneday, time_strings=custom_time_strings), '1\\xa0day')\n        self.assertEqual(timesince(self.t, self.t + self.oneweek, time_strings=custom_time_strings), '1\\xa0week')\n        self.assertEqual(timesince(self.t, self.t + self.onemonth, time_strings=custom_time_strings), '1\\xa0month')\n        self.assertEqual(timesince(self.t, self.t + self.oneyear, time_strings=custom_time_strings), '1\\xa0year')\n"], "sample_702": ["def test_pytester_run_with_timeout_zero(pytester: Pytester) -> None:\n    testfile = pytester.makepyfile(\"def test_no_timeout(): pass\")\n    with pytest.raises(pytester.TimeoutExpired):\n        pytester.runpytest_subprocess(testfile, timeout=0)\n"], "sample_937": ["def test_unparse_arguments():\n    source = \"def func(a: int, b: str = 'default', *args, **kwargs): pass\"\n    module = ast.parse(source)\n    expected = \"(a: int, b: str = 'default', *args, **kwargs)\"\n    assert ast.unparse(module.body[0].args) == expected\n"], "sample_889": ["def test_calibration_display_with_pos_label_zero(pyplot, iris_data_binary):\n    \"\"\"Check the behaviour of `pos_label` in the `CalibrationDisplay`.\"\"\"\n    X, y = iris_data_binary\n\n    lr = LogisticRegression().fit(X, y)\n    viz = CalibrationDisplay.from_estimator(lr, X, y, pos_label=0)\n\n    y_prob = lr.predict_proba(X)[:, 0]\n    prob_true, prob_pred = calibration_curve(y, y_prob, pos_label=0)\n\n    assert_allclose(viz.prob_true, prob_true)\n    assert_allclose(viz.prob_pred, prob_pred)\n    assert_allclose(viz.y_prob, y_prob)\n\n    assert (\n        viz.ax_.get_xlabel()\n        == f\"Mean predicted probability (Positive class: {0})\"\n    )\n    assert (\n        viz.ax_.get_ylabel()\n        == f\"Fraction of positives (Positive class: {0})\"\n    )\n\n    expected_legend_labels = [lr.__class__.__name__, \"Perfectly calibrated\"]\n    legend_labels = viz.ax_.get_legend().get_texts()\n    assert len(legend_labels) == len(expected_legend_labels)\n    for labels in legend_labels:\n        assert labels.get_text() in expected_legend_labels\n"], "sample_306": ["    def test_iso8601_format(self):\n        test_values = (\n            ('P1D', timedelta(days=1)),\n            ('P-1D', timedelta(days=-1)),\n            ('PT1H', timedelta(hours=1)),\n            ('PT-1H', timedelta(hours=-1)),\n            ('PT1M', timedelta(minutes=1)),\n            ('PT-1M', timedelta(minutes=-1)),\n            ('PT1S', timedelta(seconds=1)),\n            ('PT-1S', timedelta(seconds=-1)),\n            ('P1DT1H1M1S', timedelta(days=1, hours=1, minutes=1, seconds=1)),\n            ('P-1DT-1H-1M-1S', timedelta(days=-1, hours=-1, minutes=-1, seconds=-1)),\n            ('P1DT1H1M1.1S', timedelta(days=1, hours=1, minutes=1, seconds=1, milliseconds=100)),\n            ('P1DT1H1M1,1S', timedelta(days=1, hours=1, minutes=1, seconds=1, milliseconds=100)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_1074": ["def test_polycyclic_group():\n    G = SymmetricGroup(3)\n    pcG = G.polycyclic_group()\n    assert pcG.order() == G.order()\n    assert pcG.is_isomorphic(G)\n    G = AlternatingGroup(4)\n    pcG = G.polycyclic_group()\n    assert pcG.order() == G.order()\n    assert pcG.is_isomorphic(G)\n    G = DihedralGroup(4)\n    pcG = G.polycyclic_group()\n    assert pcG.order() == G.order()\n    assert pcG.is_isomorphic(G)\n"], "sample_290": ["def test_alter_field_to_fk_dependency_same_app(self):\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author_fk],\n        [self.author_empty, self.book_with_author_renamed],\n    )\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '__first__')])\n"], "sample_680": ["def test_xfail_with_invalid_strict_value(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(strict=\"invalid\")\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxs\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*TypeError:*strict*must be a boolean*\",\n        ]\n    )\n"], "sample_809": ["def test_mutual_info_classif_sparse():\n    # Test that mutual_info_classif works with sparse matrices.\n    X = csr_matrix(np.array([[0, 0, 0],\n                             [1, 1, 0],\n                             [2, 0, 1],\n                             [2, 0, 1],\n                             [2, 0, 1]]))\n    y = np.array([0, 1, 2, 2, 1])\n\n    # Here X[:, 0] is the most informative feature, and X[:, 1] is weakly\n    # informative.\n    mi = mutual_info_classif(X, y, discrete_features=True)\n    assert_array_equal(np.argsort(-mi), np.array([0, 2, 1]))\n"], "sample_1046": ["def test_TensorIndexType_components_data_full_destroy():\n    Lorentz = TensorIndexType('Lorentz', dim=4)\n    Lorentz.data = [-1, 1, 1, 1]\n    Lorentz.epsilon.data = Array([[[0, 0, 0, 0],\n                                  [0, 0, 0, 1],\n                                  [0, 0, -1, 0],\n                                  [0, -1, 0, 0]],\n                                 [[0, 0, 0, -1],\n                                  [0, 0, 1, 0],\n                                  [0, -1, 0, 0],\n                                  [1, 0, 0, 0]],\n                                 [[0, 0, 1, 0],\n                                  [0, 0, 0, -1],\n                                  [-1, 0, 0, 0],\n                                  [0, 1, 0, 0]],\n                                 [[0, 1, 0, 0],\n                                  [-1, 0, 0, 0],\n                                  [0, 0, 0, 0],\n                                  [0, 0, 0, 0]]])\n    Lorentz.delta.data = eye(4)\n\n    assert Lorentz in _tensor_data_substitution_dict\n    assert Lorentz.epsilon in _tensor_data_substitution_dict\n    assert Lorentz.delta in _tensor_data_substitution_dict\n\n    Lorentz._components_data_full_destroy()\n\n    assert Lorentz not in _tensor_data_substitution_dict\n    assert Lorentz.epsilon not in _tensor_data_substitution_dict\n    assert Lorentz.delta not in _tensor_data_substitution_dict\n"], "sample_1103": ["def test_Pow_as_base_exp():\n    assert Pow(1, 2, evaluate=False).as_base_exp() == (1, 2)\n    assert Pow(-1, 2, evaluate=False).as_base_exp() == (1, 2)\n    assert Pow(1/2, 2, evaluate=False).as_base_exp() == (2, -2)\n    assert Pow(-1/2, 2, evaluate=False).as_base_exp() == (2, -2)\n    assert Pow(2, -2, evaluate=False).as_base_exp() == (1/2, 2)\n    assert Pow(-2, -2, evaluate=False).as_base_exp() == (1/2, 2)\n"], "sample_806": ["def test_gradient_boosting_init_with_sample_weight():\n    # Check that GradientBoostingRegressor works when init is a sklearn\n    # estimator and sample weights are provided.\n    X, y = make_regression()\n    sample_weight = np.random.RandomState(42).rand(100)\n\n    # init supports sample weights\n    init_est = DummyRegressor()\n    gb = GradientBoostingRegressor(init=init_est)\n    gb.fit(X, y, sample_weight=sample_weight)\n\n    # init does not support sample weights\n    init_est = _NoSampleWeightWrapper(DummyRegressor())\n    gb = GradientBoostingRegressor(init=init_est)\n    gb.fit(X, y)  # ok no sample weights\n    with pytest.raises(ValueError,\n                       match=\"estimator.*does not support sample weights\"):\n        gb.fit(X, y, sample_weight=sample_weight)\n"], "sample_240": ["def test_make_token_with_timestamp(self):\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    timestamp = p0._num_seconds(p0._now())\n    tk1 = p0._make_token_with_timestamp(user, timestamp)\n    self.assertIs(p0.check_token(user, tk1), True)\n    # Test with legacy token\n    tk2 = p0._make_token_with_timestamp(user, timestamp, legacy=True)\n    self.assertIs(p0.check_token(user, tk2), True)\n"], "sample_1020": ["def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]]\"\n    assert mcode(Sum(x**2, (x, 1, 10, 2))) == \"Hold[Sum[x^2, {x, 1, 10, 2}]]\"\n    assert mcode(Sum(x*y, (x, 1, 10), (y, 1, 10))) == \\\n        \"Hold[Sum[x*y, {x, 1, 10}, {y, 1, 10}]]\"\n"], "sample_491": ["def test_boundfield_subwidgets_with_custom_renderer(self):\n    class CustomRenderer(DjangoTemplates):\n        field_template_name = \"forms_tests/custom_field.html\"\n\n    class MyForm(Form):\n        name = ChoiceField(\n            choices=[(\"option1\", \"Option 1\"), (\"option2\", \"Option 2\")],\n            widget=RadioSelect,\n        )\n\n    form = MyForm(renderer=CustomRenderer())\n    subwidgets = form[\"name\"].subwidgets\n    self.assertEqual(len(subwidgets), 2)\n    self.assertHTMLEqual(\n        subwidgets[0].tag(),\n        '<label for=\"id_name_0\"><input type=\"radio\" name=\"name\" value=\"option1\" '\n        'id=\"id_name_0\" required> Option 1</label>',\n    )\n    self.assertHTMLEqual(\n        subwidgets[1].tag(),\n        '<label for=\"id_name_1\"><input type=\"radio\" name=\"name\" value=\"option2\" '\n        'id=\"id_name_1\" required> Option 2</label>',\n    )\n"], "sample_869": ["def test_jaccard_similarity_score_deprecation(recwarn):\n    y_true = np.array([[0, 1], [1, 1]])\n    y_pred = np.array([[1, 1], [1, 0]])\n\n    with pytest.warns(FutureWarning):\n        jaccard_similarity_score(y_true, y_pred)\n\n    assert len(recwarn) == 1\n    assert \"jaccard_similarity_score has been deprecated\" in str(recwarn[0].message)\n"], "sample_883": ["def test_bayesian_ridge_ard_empty_input(Estimator):\n    \"\"\"Check that BayesianRidge and ARDRegression raise an error on empty input.\"\"\"\n    X = np.array([])\n    y = np.array([])\n\n    model = Estimator()\n    with pytest.raises(ValueError, match=\"zero-size array to reduction operation\"):\n        model.fit(X, y)\n"], "sample_1077": ["def test_ComplexRegion_polar_intersect():\n    # Polar form\n    unit_disk = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)\n    upper_half_unit_disk = ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    upper_half_disk = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi), polar=True)\n    lower_half_disk = ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n    right_half_disk = ComplexRegion(Interval(0, oo)*Interval(-S.Pi/2, S.Pi/2), polar=True)\n    first_quad_disk = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi/2), polar=True)\n\n    assert upper_half_disk.intersect(unit_disk) == upper_half_unit_disk\n    assert right_half_disk.intersect(first_quad_disk) == first_quad_disk\n    assert upper_half_disk.intersect(right_half_disk) == first_quad_disk\n    assert upper_half_disk.intersect(lower_half_disk) == ComplexRegion(Interval(0, oo)*FiniteSet(0), polar=True)\n\n    c1 = ComplexRegion(Interval(0, 4)*Interval(0, 2*S.Pi), polar=True)\n    assert c1.intersect(Interval(1, 5)) == Interval(1, 4)\n    assert c1.intersect(Interval(4, 9)) == FiniteSet(4)\n    assert c1.intersect(Interval(5, 12)) is S.EmptySet\n"], "sample_492": ["def test_serialize_timezone(self):\n    self.assertSerializedEqual(datetime.timezone.utc)\n    self.assertSerializedResultEqual(\n        datetime.timezone.utc,\n        (\"datetime.timezone.utc\", {\"import datetime\"}),\n    )\n    self.assertSerializedEqual(get_default_timezone())\n    self.assertSerializedResultEqual(\n        get_default_timezone(),\n        (\"django.utils.timezone.get_default_timezone()\", {\"from django.utils import timezone\"}),\n    )\n    self.assertSerializedEqual(get_fixed_timezone(180))\n    self.assertSerializedResultEqual(\n        get_fixed_timezone(180),\n        (\"django.utils.timezone.get_fixed_timezone(180)\", {\"from django.utils import timezone\"}),\n    )\n    self.assertSerializedEqual(zoneinfo.ZoneInfo(\"Europe/Paris\"))\n    self.assertSerializedResultEqual(\n        zoneinfo.ZoneInfo(\"Europe/Paris\"),\n        (\"zoneinfo.ZoneInfo('Europe/Paris')\", {\"import zoneinfo\"}),\n    )\n"], "sample_440": ["def test_update_conflicts_unique_fields_multiple(self):\n    UpsertConflict.objects.bulk_create(\n        [\n            UpsertConflict(number=1, rank=1, name=\"John\"),\n            UpsertConflict(number=2, rank=2, name=\"Mary\"),\n            UpsertConflict(number=3, rank=3, name=\"Hannah\"),\n        ]\n    )\n    self.assertEqual(UpsertConflict.objects.count(), 3)\n\n    conflicting_objects = [\n        UpsertConflict(number=1, rank=4, name=\"Steve\"),\n        UpsertConflict(number=2, rank=2, name=\"Olivia\"),\n        UpsertConflict(number=3, rank=1, name=\"Hannah\"),\n    ]\n    UpsertConflict.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        update_fields=[\"name\", \"rank\"],\n        unique_fields=[\"number\", \"rank\"],\n    )\n    self.assertEqual(UpsertConflict.objects.count(), 3)\n    self.assertCountEqual(\n        UpsertConflict.objects.values(\"number\", \"rank\", \"name\"),\n        [\n            {\"number\": 1, \"rank\": 4, \"name\": \"Steve\"},\n            {\"number\": 2, \"rank\": 2, \"name\": \"Olivia\"},\n            {\"number\": 3, \"rank\": 1, \"name\": \"Hannah\"},\n        ],\n    )\n\n    UpsertConflict.objects.bulk_create(\n        conflicting_objects + [UpsertConflict(number=4, rank=4, name=\"Mark\")],\n        update_conflicts=True,\n        update_fields=[\"name\", \"rank\"],\n        unique_fields=[\"number\", \"rank\"],\n    )\n    self.assertEqual(UpsertConflict.objects.count(), 4)\n    self.assertCountEqual(\n        UpsertConflict.objects.values(\"number\", \"rank\", \"name\"),\n        [\n            {\"number\": 1, \"rank\": 4, \"name\": \"Steve\"},\n            {\"number\": 2, \"rank\": 2, \"name\": \"Olivia\"},\n            {\"number\": 3, \"rank\": 1, \"name\": \"Hannah\"},\n            {\"number\": 4, \"rank\": 4, \"name\": \"Mark\"},\n        ],\n    )\n"], "sample_231": ["    def test_exception_reporter_from_request_with_custom_filter(self):\n        class CustomExceptionReporterFilter(SafeExceptionReporterFilter):\n            cleansed_substitute = 'CUSTOM_SUBSTITUTE'\n\n        request = self.rf.get('/test_view/')\n        request.exception_reporter_filter = CustomExceptionReporterFilter()\n\n        try:\n            raise ValueError(\"Can't find my keys\")\n        except ValueError:\n            exc_type, exc_value, tb = sys.exc_info()\n\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        html = reporter.get_traceback_html()\n        self.assertIn(CustomExceptionReporterFilter.cleansed_substitute, html)\n"], "sample_68": ["    def test_technical_500_response(self):\n        request = RequestFactory().get('/')\n        exc_type = Exception\n        exc_value = Exception('Test exception')\n        tb = None\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html')\n"], "sample_158": ["    def test_foreign_key_to_unique_field_with_meta_constraint_and_condition(self):\n        class Target(models.Model):\n            source = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['source'],\n                        name='tfktufwmc_unique',\n                        condition=models.Q(source__gt=2),\n                    ),\n                ]\n\n        class Model(models.Model):\n            field = models.ForeignKey(Target, models.CASCADE, to_field='source')\n\n        field = Model._meta.get_field('field')\n        self.assertEqual(field.check(), [\n            Error(\n                \"'Target.source' must be unique because it is referenced by a foreign key.\",\n                hint=(\n                    'Add unique=True to this field or add a UniqueConstraint '\n                    '(without condition) in the model Meta.constraints.'\n                ),\n                obj=field,\n                id='fields.E311',\n            ),\n        ])\n"], "sample_549": ["def test_safe_masked_invalid():\n    x = np.array([1, 2, np.nan, 4, 5])\n    xm = cbook.safe_masked_invalid(x)\n    assert np.all(xm.data == x)\n    assert np.all(xm.mask == [False, False, True, False, False])\n\n    x = np.ma.array([1, 2, np.nan, 4, 5], mask=[True, False, False, False, True])\n    xm = cbook.safe_masked_invalid(x)\n    assert np.all(xm.data == x.data)\n    assert np.all(xm.mask == [True, False, True, False, True])\n\n    x = np.array([1, 2, np.inf, 4, 5])\n    xm = cbook.safe_masked_invalid(x)\n    assert np.all(xm.data == x)\n    assert np.all(xm.mask == [False, False, True, False, False])\n\n    x = np.ma.array([1, 2, np.inf, 4, 5], mask=[True, False, False, False, True])\n    xm = cbook.safe_masked_invalid(x)\n    assert np.all(xm.data == x.data)\n    assert np.all(xm.mask == [True, False, True, False, True])\n"], "sample_89": ["    def test_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertEqual(mocked_termios.tcgetattr.call_count, 1)\n        self.assertEqual(mocked_termios.tcsetattr.call_count, 1)\n"], "sample_689": ["def test_warning_captured_hook_is_deprecated(testdir: Testdir) -> None:\n    testdir.makeconftest(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*The pytest_warning_captured is deprecated*\"])\n"], "sample_671": ["def test_xfail_with_invalid_run_value(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(run=\"invalid\")\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxs\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*ERROR*test_func*\",\n            \"*Invalid value for 'run' parameter: 'invalid'.*\",\n        ]\n    )\n"], "sample_118": ["def test_year_lookup(self):\n    # Test year lookups on DateField and DateTimeField.\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n            '<Article: Article 7>',\n        ],\n        ordered=False\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gt=2005),\n        ['<Article: Article 5>', '<Article: Article 6>'],\n        ordered=False\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lt=2005),\n        [],\n        ordered=False\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gte=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 7>',\n        ],\n        ordered=False\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lte=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n            '<Article: Article 7>',\n        ],\n        ordered=False\n    )\n"], "sample_374": ["    def setUpTestData(cls):\n        cls.book1 = Book.objects.create(title='Poems')\n        cls.book2 = Book.objects.create(title='Jane Eyre')\n        cls.book3 = Book.objects.create(title='Wuthering Heights')\n        cls.book4 = Book.objects.create(title='Sense and Sensibility')\n\n        cls.author1 = Author.objects.create(name='Charlotte', first_book=cls.book1)\n        cls.author2 = Author.objects.create(name='Anne', first_book=cls.book1)\n        cls.author3 = Author.objects.create(name='Emily', first_book=cls.book1)\n        cls.author4 = Author.objects.create(name='Jane', first_book=cls.book4)\n\n        cls.book1.authors.add(cls.author1, cls.author2, cls.author3)\n        cls.book2.authors.add(cls.author1)\n        cls.book3.authors.add(cls.author3)\n        cls.book4.authors.add(cls.author4)\n"], "sample_788": ["def test_inverse_transform_with_constant_feature(strategy, encode, expected):\n    X = [[-2, 1, -4, 1],\n         [-1, 2, -3, 1],\n         [0, 3, -2, 1],\n         [1, 4, -1, 1]]\n    kbd = KBinsDiscretizer(n_bins=3, strategy=strategy, encode=encode)\n    Xt = kbd.fit_transform(X)\n    Xinv = kbd.inverse_transform(Xt)\n    assert_array_almost_equal(expected, Xinv)\n"], "sample_1161": ["def test_issue_21119_21460_str():\n    ss = lambda x: sstr(S(x, evaluate=False))\n    assert ss('4/2') == '4/2'\n    assert ss('4/-2') == '-4/2'\n    assert ss('-4/2') == '-4/2'\n    assert ss('-4/-2') == '4/2'\n    assert ss('-2*3/-1') == '2*3'\n    assert ss('-2*3/-1/2') == '-2*3/2'\n    assert ss('4/2/1') == '4/2'\n    assert ss('-2/-1/2') == '2/2'\n    assert ss('2*3*4**(-2*3)') == '2*3/4**(2*3)'\n    assert ss('2*3*1*4**(-2*3)') == '2*3/4**(2*3)'\n"], "sample_884": ["def test_deprecated_property():\n    with pytest.warns(FutureWarning, match=\"n_features_ is deprecated\"):\n        assert MockClass2().n_features_ == 10\n"], "sample_814": ["def test_gradient_boosting_with_init_sample_weight():\n    # Check that GradientBoostingRegressor works when init is a sklearn\n    # estimator and sample weights are provided.\n    X, y = make_regression()\n    sample_weight = np.random.RandomState(42).rand(100)\n\n    # init supports sample weights\n    init_est = DummyRegressor()\n    gb = GradientBoostingRegressor(init=init_est)\n    gb.fit(X, y, sample_weight=sample_weight)\n\n    # init does not support sample weights\n    init_est = _NoSampleWeightWrapper(DummyRegressor())\n    gb = GradientBoostingRegressor(init=init_est)\n    gb.fit(X, y)  # ok no sample weights\n    with pytest.raises(ValueError,\n                       match=\"estimator.*does not support sample weights\"):\n        gb.fit(X, y, sample_weight=sample_weight)\n"], "sample_706": ["def test_matcher_adapter() -> None:\n    matcher = {\"true\": True, \"false\": False}\n    adapter = Expression.MatcherAdapter(matcher.__getitem__)\n    assert adapter[\"$true\"]\n    assert not adapter[\"$false\"]\n    with pytest.raises(KeyError):\n        adapter[\"$unknown\"]\n"], "sample_405": ["def test_alter_field_with_func_unique_constraint_and_index(self):\n    app_label = \"test_alfuncucin\"\n    constraint_name = f\"{app_label}_pony_uq\"\n    index_name = f\"{app_label}_pony_idx\"\n    table_name = f\"{app_label}_pony\"\n    project_state = self.set_up_test_model(\n        app_label,\n        constraints=[\n            models.UniqueConstraint(\"pink\", \"weight\", name=constraint_name)\n        ],\n        indexes=[models.Index(Abs(\"pink\"), name=index_name)],\n    )\n    operation = migrations.AlterField(\n        \"Pony\", \"pink\", models.IntegerField(null=True)\n    )\n    new_state = project_state.clone()\n    operation.state_forwards(app_label, new_state)\n    with connection.schema_editor() as editor:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    if connection.features.supports_expression_indexes:\n        self.assertIndexNameExists(table_name, index_name)\n    with connection.schema_editor() as editor:\n        operation.database_backwards(app_label, editor, new_state, project_state)\n    if connection.features.supports_expression_indexes:\n        self.assertIndexNameExists(table_name, index_name)\n"], "sample_570": ["    def test_cached_support_bivariate(self, rng):\n\n        x, y = rng.normal(0, 3, (2, 50))\n        kde = KDE()\n        kde.define_support(x, y)\n        _, support = kde(x[(x > -1) & (x < 1)], y[(x > -1) & (x < 1)])\n        assert_array_equal(support[0], kde.support[0])\n        assert_array_equal(support[1], kde.support[1])\n"], "sample_1072": ["def test_frac_edge_cases():\n    assert frac(0) == 0\n    assert frac(1) == 0\n    assert frac(-1) == 0\n    assert frac(oo) == AccumBounds(0, 1)\n    assert frac(-oo) == AccumBounds(0, 1)\n    assert frac(zoo) is nan\n    assert frac(nan) is nan\n\n    assert frac(Rational(1, 1)) == 0\n    assert frac(Rational(-1, 1)) == 0\n    assert frac(Rational(0, 1)) == 0\n\n    assert frac(Float(0.0)) == 0\n    assert frac(Float(1.0)) == 0\n    assert frac(Float(-1.0)) == 0\n\n    assert frac(I) == 0\n    assert frac(-I) == 0\n    assert frac(oo*I) == AccumBounds(0, 1)\n    assert frac(-oo*I) == AccumBounds(0, 1)\n\n    assert frac(E) == E - floor(E)\n    assert frac(-E) == -E - floor(-E)\n\n    assert frac(pi) == pi - floor(pi)\n    assert frac(-pi) == -pi - floor(-pi)\n\n    assert frac(sin(1)) == sin(1) - floor(sin(1))\n    assert frac(-sin(1)) == -sin(1) - floor(-sin(1))\n\n    assert frac(exp(1)) == exp(1) - floor(exp(1))\n    assert frac(-exp(1)) == -exp(1) - floor(-exp(1))\n\n    assert frac(log(1)) == log(1) - floor(log(1))\n    assert frac(-log(1)) == -log(1) - floor(-log(1))\n"], "sample_560": ["def test_legend_title_fontprop_fontsize_warning():\n    # test the title_fontsize kwarg\n    plt.plot(range(10))\n    with pytest.warns(UserWarning):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n"], "sample_557": ["def test_subfigure_subplotspec():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    subfig = fig.add_subfigure(gs[0, 0])\n    assert subfig._subplotspec == gs[0, 0]\n    assert subfig._subplotspec.get_gridspec() == gs\n"], "sample_75": ["    def setUpTestData(cls):\n        cls.book = Book.objects.create(title='Poems')\n        cls.author1 = Author.objects.create(name='Jane', first_book=cls.book)\n        cls.author2 = Author.objects.create(name='Tom', first_book=cls.book)\n        cls.author3 = Author.objects.create(name='Robert', first_book=cls.book)\n        cls.author_address = AuthorAddress.objects.create(author=cls.author1, address='SomeStreet 1')\n        FavoriteAuthors.objects.create(author=cls.author1, likes_author=cls.author2)\n        FavoriteAuthors.objects.create(author=cls.author2, likes_author=cls.author3)\n        FavoriteAuthors.objects.create(author=cls.author3, likes_author=cls.author1)\n"], "sample_1168": ["def test_ibin():\n    assert ibin(2) == [1, 0]\n    assert ibin(2, 4) == [0, 0, 1, 0]\n    assert ibin(2, 'all') == [(0, 0), (0, 1), (1, 0), (1, 1)]\n    assert ibin(3, 'all') == [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1),\n                             (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)]\n    assert ibin(2, 2, str=True) == '10'\n    assert ibin(2, 2, str=True)[::-1] == '01'\n    assert list(ibin(3, 'all', str=True)) == ['000', '001', '010', '011',\n                                             '100', '101', '110', '111']\n    raises(ValueError, lambda: ibin(-1))\n"], "sample_62": ["    def setUp(self):\n        self.site = admin.AdminSite()\n"], "sample_1048": ["def test_parabola_intersection():\n    p1 = Point(0, 0)\n    p2 = Point(3, 7)\n    p3 = Point(0, 4)\n    p4 = Point(6, 0)\n    d1 = Line(Point(4, 0), Point(4, 9))\n    d2 = Line(Point(7, 6), Point(3, 6))\n    d3 = Line(Point(4, 0), slope=oo)\n    d4 = Line(Point(7, 6), slope=0)\n    pa1 = Parabola(p1, d1)\n    pa2 = Parabola(p2, d2)\n    pa3 = Parabola(p3, d2)\n    pa4 = Parabola(p4, d1)\n    c1 = Circle(p1, 5)\n    e1 = Ellipse(p1, 5, 3)\n    l1 = Line(p1, p2)\n    l2 = Line(p3, p4)\n    s1 = Segment(p1, p2)\n    s2 = Segment(p3, p4)\n    r1 = Ray(p1, p2)\n    r2 = Ray(p3, p4)\n\n    assert pa1.intersection(pa2) == []\n    assert pa1.intersection(pa3) == [Point2D(0, 4)]\n    assert pa1.intersection(pa4) == [Point2D(6, 0)]\n    assert pa1.intersection(c1) == [Point2D(-3, 0), Point2D(3, 0)]\n    assert pa1.intersection(e1) == [Point2D(-5, 0), Point2D(5, 0)]\n    assert pa1.intersection(l1) == [Point2D(3, 7)]\n    assert pa1.intersection(l2) == [Point2D(3, 2)]\n    assert pa1.intersection(s1) == [Point2D(3, 7)]\n    assert pa1.intersection(s2) == []\n    assert pa1.intersection(r1) == [Point2D(3, 7)]\n    assert pa1.intersection(r2) == []\n"], "sample_1013": ["def test_lambdify_kwargs():\n    f = lambdify(x, x**2, dummify=True)\n    assert f(x=2) == 4\n    f = lambdify((x, y), x + y, dummify=True)\n    assert f(x=1, y=2) == 3\n    raises(TypeError, lambda: f(x=1, y=2, z=3))\n    raises(TypeError, lambda: f(x=1))\n"], "sample_1146": ["def test_latex_tensor_indices():\n    from sympy.tensor.tensor import TensorIndexType, tensor_indices, TensorHead, tensor_heads\n    L = TensorIndexType(\"L\")\n    i, j, k, l = tensor_indices(\"i j k l\", L)\n    i0 = tensor_indices(\"i_0\", L)\n    A, B, C, D = tensor_heads(\"A B C D\", [L])\n    H = TensorHead(\"H\", [L, L])\n    K = TensorHead(\"K\", [L, L, L, L])\n\n    assert latex(i) == r\"{}^{i}\"\n    assert latex(-i) == r\"{}_{i}\"\n\n    expr = A(i)\n    assert latex(expr) == r\"A{}^{i}\"\n\n    expr = A(i0)\n    assert latex(expr) == r\"A{}^{i_{0}}\"\n\n    expr = A(-i)\n    assert latex(expr) == r\"A{}_{i}\"\n\n    expr = -3*A(i)\n    assert latex(expr) == r\"-3A{}^{i}\"\n\n    expr = K(i, j, -k, -i0)\n    assert latex(expr) == r\"K{}^{ij}{}_{ki_{0}}\"\n\n    expr = K(i, -j, -k, i0)\n    assert latex(expr) == r\"K{}^{i}{}_{jk}{}^{i_{0}}\"\n\n    expr = K(i, -j, k, -i0)\n    assert latex(expr) == r\"K{}^{i}{}_{j}{}^{k}{}_{i_{0}}\"\n\n    expr = H(i, -j)\n    assert latex(expr) == r\"H{}^{i}{}_{j}\"\n\n    expr = H(i, j)\n    assert latex(expr) == r\"H{}^{ij}\"\n\n    expr = H(-i, -j)\n    assert latex(expr) == r\"H{}_{ij}\"\n\n    expr = (1+x)*A(i)\n    assert latex(expr) == r\"\\left(x + 1\\right)A{}^{i}\"\n\n    expr = H(i, -i)\n    assert latex(expr) == r\"H{}^{L_{0}}{}_{L_{0}}\"\n\n    expr = H(i, -j)*A(j)*B(k)\n    assert latex(expr) == r\"H{}^{i}{}_{L_{0}}A{}^{L_{0}}"], "sample_594": ["def test_format_array_flat_with_dask_array(self):\n    import dask.array as da\n\n    dask_array = da.random.random((100,), chunks=10)\n    actual = formatting.format_array_flat(dask_array, 10)\n    expected = \"dask.array<chunksize=(10,)>\"\n    assert actual == expected\n\n    dask_array = da.random.random((100,), chunks=10).compute()\n    actual = formatting.format_array_flat(dask_array, 10)\n    expected = \"0.0 ... 0.9\"\n    assert actual == expected\n\n    dask_array = da.random.random((100,), chunks=10).compute().astype(object)\n    actual = formatting.format_array_flat(dask_array, 10)\n    expected = \"0.0 ... 0.9\"\n    assert actual == expected\n\n    dask_array = da.random.random((100,), chunks=10).compute().astype(object)\n    actual = formatting.format_array_flat(dask_array, 5)\n    expected = \"...\"\n    assert actual == expected\n"], "sample_1147": ["def test_latex_tensor_indices():\n    from sympy.tensor.tensor import TensorIndexType, tensor_indices, TensorHead, tensor_heads\n    L = TensorIndexType(\"L\")\n    i, j, k, l = tensor_indices(\"i j k l\", L)\n    i0 = tensor_indices(\"i_0\", L)\n    A, B, C, D = tensor_heads(\"A B C D\", [L])\n    H = TensorHead(\"H\", [L, L])\n    K = TensorHead(\"K\", [L, L, L, L])\n\n    assert latex(i) == r\"{}^{i}\"\n    assert latex(-i) == r\"{}_{i}\"\n\n    expr = A(i)\n    assert latex(expr) == r\"A{}^{i}\"\n\n    expr = A(i0)\n    assert latex(expr) == r\"A{}^{i_{0}}\"\n\n    expr = A(-i)\n    assert latex(expr) == r\"A{}_{i}\"\n\n    expr = -3*A(i)\n    assert latex(expr) == r\"-3A{}^{i}\"\n\n    expr = K(i, j, -k, -i0)\n    assert latex(expr) == r\"K{}^{ij}{}_{ki_{0}}\"\n\n    expr = K(i, -j, -k, i0)\n    assert latex(expr) == r\"K{}^{i}{}_{jk}{}^{i_{0}}\"\n\n    expr = K(i, -j, k, -i0)\n    assert latex(expr) == r\"K{}^{i}{}_{j}{}^{k}{}_{i_{0}}\"\n\n    expr = H(i, -j)\n    assert latex(expr) == r\"H{}^{i}{}_{j}\"\n\n    expr = H(i, j)\n    assert latex(expr) == r\"H{}^{ij}\"\n\n    expr = H(-i, -j)\n    assert latex(expr) == r\"H{}_{ij}\"\n\n    expr = (1+x)*A(i)\n    assert latex(expr) == r\"\\left(x + 1\\right)A{}^{i}\"\n\n    expr = H(i, -i)\n    assert latex(expr) == r\"H{}^{L_{0}}{}_{L_{0}}\"\n\n    expr = H(i, -j)*A(j)*B(k)\n    assert latex(expr) == r\"H{}^{i}{}_{L_{0}}A{}^{L_{0}}"], "sample_404": ["def test_variable_node_render(self):\n    \"\"\"\n    Test that VariableNode.render() correctly handles exceptions during rendering.\n    \"\"\"\n    engine = self._engine()\n    c = Context({\"coconuts\": lambda: 42 / 0})\n    t = engine.from_string(\"{{ coconuts }}\")\n\n    with self.assertRaises(ZeroDivisionError) as e:\n        t.render(c)\n\n    if self.debug_engine:\n        debug = e.exception.template_debug\n        self.assertEqual(debug[\"start\"], 0)\n        self.assertEqual(debug[\"end\"], 14)\n\n    # Test that VariableNode.render() correctly handles silent variable failures.\n    c = Context({\"coconuts\": None})\n    t = engine.from_string(\"{{ coconuts|default:'default' }}\")\n    self.assertEqual(t.render(c), \"default\")\n\n    # Test that VariableNode.render() correctly handles variables that are not strings.\n    c = Context({\"coconuts\": 42})\n    t = engine.from_string(\"{{ coconuts }}\")\n    self.assertEqual(t.render(c), \"42\")\n"], "sample_57": ["    def test_bound_data(self):\n        field = ReadOnlyPasswordHashField()\n        self.assertEqual(field.bound_data('initial', 'data'), 'initial')\n"], "sample_992": ["def test_MpmathPrinter():\n    p = MpmathPrinter()\n    expr = sympify('log1p(x)')\n    assert p.doprint(expr) == 'mpmath.log(x+1)'\n    expr = sympify('log2(x)')\n    assert p.doprint(expr) == 'mpmath.log(x)/mpmath.log(2)'\n    expr = sympify('uppergamma(x, y)')\n    assert p.doprint(expr) == 'mpmath.gammainc(x, y, mpmath.inf)'\n    expr = sympify('lowergamma(x, y)')\n    assert p.doprint(expr) == 'mpmath.gammainc(x, 0, y)'\n"], "sample_840": ["def test_pls_transform_with_univariate_y():\n    # Ensure that transform works correctly with univariate Y\n    d = load_linnerud()\n    X = d.data\n    Y = d.target[:, 0]\n\n    for clf in [pls_.PLSCanonical(), pls_.PLSRegression(), pls_.PLSSVD()]:\n        X_score, Y_score = clf.fit_transform(X, Y)\n        assert_array_almost_equal(Y_score, clf.transform(Y))\n"], "sample_267": ["    def test_get_connection_params(self):\n        settings_dict = {\n            'NAME': ':memory:',\n            'OPTIONS': {\n                'check_same_thread': True,\n            }\n        }\n        wrapper = DatabaseWrapper(settings_dict)\n        params = wrapper.get_connection_params()\n        self.assertEqual(params['database'], ':memory:')\n        self.assertEqual(params['detect_types'], Database.PARSE_DECLTYPES | Database.PARSE_COLNAMES)\n        self.assertEqual(params['check_same_thread'], False)\n        self.assertEqual(params['uri'], True)\n"], "sample_993": ["def test_FreeGroupElm_subword():\n    w = x**5*y*x**2*y**-4*x\n    assert w.subword(2, 6) == x**3*y\n    assert w.subword(0, 0) == F.identity\n    assert w.subword(0, 13) == w\n    raises(ValueError, lambda: w.subword(-1, 6))\n    raises(ValueError, lambda: w.subword(0, 14))\n    raises(ValueError, lambda: w.subword(6, 2))\n"], "sample_1017": ["def test_as_set_multivariate():\n    x, y = symbols('x y', real=True)\n    assert And(x > 0, y > 0).as_set() == Interval.open(0, oo)*Interval.open(0, oo)\n    assert Or(x > 0, y > 0).as_set() == S.Reals*S.Reals - Interval.open(-oo, 0, True, True)*Interval.open(-oo, 0, True, True)\n    assert And(x > 0, y < 0).as_set() == Interval.open(0, oo)*Interval.open(-oo, 0, True, True)\n    assert Or(x > 0, y < 0).as_set() == S.Reals*S.Reals - Interval.open(-oo, 0, True, True)*Interval.open(0, oo, True, True)\n    assert And(x < 0, y > 0).as_set() == Interval.open(-oo, 0, True, True)*Interval.open(0, oo)\n    assert Or(x < 0, y > 0).as_set() == S.Reals*S.Reals - Interval.open(0, oo, True, True)*Interval.open(-oo, 0, True, True)\n    assert And(x < 0, y < 0).as_set() == Interval.open(-oo, 0, True, True)*Interval.open(-oo, 0, True, True)\n    assert Or(x < 0, y < 0).as_set() == S.Reals*S.Reals - Interval.open(0, oo, True, True)*Interval.open(0, oo, True, True)\n"], "sample_395": ["    def test_template_changed_with_no_template_dirs(self, mock_get_template_dirs):\n        mock_get_template_dirs.return_value = set()\n        template_path = Path(__file__).parent / \"templates\" / \"index.html\"\n        self.assertIsNone(autoreload.template_changed(None, template_path))\n"], "sample_182": ["def test_union_with_deferred_fields(self):\n    Number.objects.create(num=1, other_num=10)\n    qs1 = Number.objects.defer('num').filter(other_num=10)\n    qs2 = Number.objects.defer('other_num').filter(num=1)\n    self.assertEqual(qs1.union(qs2).count(), 1)\n    self.assertEqual(qs1.union(qs2).values_list('num', flat=True)[0], 1)\n    self.assertEqual(qs1.union(qs2).values_list('other_num', flat=True)[0], 10)\n"], "sample_1067": ["def test_mul_matches_noncomm():\n    x, y = symbols('x y')\n    A, B, C = symbols('A B C', commutative=False)\n    u, v = symbols('u v', cls=Wild)\n    w, z = symbols('w z', cls=Wild, commutative=False)\n\n    assert (u*v).matches(x) in ({v: x, u: 1}, {u: x, v: 1})\n    assert (u*v).matches(x*y) in ({v: y, u: x}, {u: y, v: x})\n    assert (u*v).matches(A) is None\n    assert (u*v).matches(A*B) is None\n    assert (u*v).matches(x*A) is None\n    assert (u*v).matches(x*y*A) is None\n    assert (u*v).matches(x*A*B) is None\n    assert (u*v).matches(x*y*A*B) is None\n\n    assert (v*w).matches(x) is None\n    assert (v*w).matches(x*y) is None\n    assert (v*w).matches(A) == {w: A, v: 1}\n    assert (v*w).matches(A*B) == {w: A*B, v: 1}\n    assert (v*w).matches(x*A) == {w: A, v: x}\n    assert (v*w).matches(x*y*A) == {w: A, v: x*y}\n    assert (v*w).matches(x*A*B) == {w: A*B, v: x}\n    assert (v*w).matches(x*y*A*B) == {w: A*B, v: x*y}\n\n    assert (v*w).matches(-x) is None\n    assert (v*w).matches(-x*y) is None\n    assert (v*w).matches(-A) == {w: A, v: -1}\n    assert (v*w).matches(-A*B) == {w: A*B, v: -1}\n    assert (v*w).matches(-x*A) == {w: A, v: -x}\n    assert (v*w).matches(-x*y*A) == {w: A, v: -x*y}\n    assert (v*w).matches(-x*A*B) == {w: A*B, v: -x}\n    assert (v*w"], "sample_1018": ["def test_fcode_Infinity():\n    x = symbols('x')\n    assert fcode(S.Infinity) == \"      (huge(0d0) + 1)\"\n    assert fcode(S.NegativeInfinity) == \"      -(huge(0d0) + 1)\"\n    assert fcode(S.Infinity + x) == \"      (huge(0d0) + 1) + x\"\n    assert fcode(S.Infinity * x) == \"      (huge(0d0) + 1)*x\"\n    assert fcode(S.Infinity / x) == \"      (huge(0d0) + 1)/x\"\n    assert fcode(x / S.Infinity) == \"      x/(huge(0d0) + 1)\"\n    assert fcode(S.Infinity ** x) == \"      (huge(0d0) + 1)**x\"\n    assert fcode(x ** S.Infinity) == \"      x**(huge(0d0) + 1)\"\n"], "sample_1024": ["def test_issue_12820():\n    # Test that using 'prec' as a keyword argument for Float raises a deprecation warning\n    with SymPyDeprecationWarning('Using \"prec=XX\" to denote decimal precision',\n                                 useinstead='\"dps=XX\" for decimal precision and \"precision=XX\" for binary precision',\n                                 issue=12820,\n                                 deprecated_since_version=\"1.1\").ignore():\n        Float(1, prec=10)\n"], "sample_401": ["def test_formset_with_deletion_and_can_delete_extra_false(self):\n    \"\"\"\n    Test that can_delete_extra=False works as expected.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_delete=True, can_delete_extra=False)\n    initial = [\n        {\"choice\": \"Calexico\", \"votes\": 100},\n        {\"choice\": \"Fergie\", \"votes\": 900},\n    ]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix=\"choices\")\n    self.assertHTMLEqual(\n        \"\\n\".join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_1079": ["def test_orthogonal_direction():\n    p = Point(1, 2, 3)\n    ortho = p.orthogonal_direction\n    assert p.dot(ortho) == 0\n    assert ortho != Point(0, 0, 0)\n    assert Point(0, 1, 2).orthogonal_direction == Point(1, 0, 0)\n    assert Point(1, 0, 2).orthogonal_direction == Point(0, 1, 0)\n    assert Point(1, 2, 0).orthogonal_direction == Point(0, 0, 1)\n"], "sample_342": ["def test_process_request_invalid_app_label(self):\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'invalid_app', 'model_name': Answer._meta.model_name, 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n"], "sample_398": ["    def test_login_view_with_custom_success_url_allowed_hosts(self):\n        class CustomLoginView(LoginView):\n            success_url_allowed_hosts = {\"customhost.com\"}\n\n        response = self.client.post(\n            \"/login/custom_success_url_allowed_hosts/\",\n            {\n                \"username\": \"testclient\",\n                \"password\": \"password\",\n                \"next\": \"https://customhost.com/home\",\n            },\n        )\n        self.assertIn(SESSION_KEY, self.client.session)\n        self.assertRedirects(\n            response, \"https://customhost.com/home\", fetch_redirect_response=False\n        )\n"], "sample_1107": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((0, 1, 2, 3))) == [\n        (0, 1, 2, 3), (0, -1, 2, 3), (0, 1, -2, 3), (0, -1, -2, 3),\n        (0, 1, 2, -3), (0, -1, 2, -3), (0, 1, -2, -3), (0, -1, -2, -3)\n    ]\n    assert list(permute_signs((0, 0, 0))) == [(0, 0, 0)]\n    assert list(permute_signs((1, 1, 1))) == [\n        (1, 1, 1), (-1, 1, 1), (1, -1, 1), (1, 1, -1),\n        (-1, -1, 1), (-1, 1, -1), (-1, -1, -1), (1, -1, -1)\n    ]\n"], "sample_383": ["    def setUpTestData(cls):\n        cls.oa = ObjectA.objects.create(name=\"oa\")\n        cls.poa = ProxyObjectA.objects.get(name=\"oa\")\n        cls.coa = ChildObjectA.objects.create(name=\"coa\")\n        cls.wrong_type = Order.objects.create(id=cls.oa.pk)\n        cls.ob = ObjectB.objects.create(name=\"ob\", objecta=cls.oa, num=1)\n        cls.pob1 = ProxyObjectB.objects.create(name=\"pob\", objecta=cls.oa, num=2)\n        cls.pob = ProxyObjectB.objects.all()\n        cls.c = ObjectC.objects.create(childobjecta=cls.coa)\n"], "sample_444": ["    def setUp(self):\n        self.storage = storage.StaticFilesStorage(location=\"/tmp\")\n        self.hashed_files = {}\n        self.max_post_process_passes = 5\n"], "sample_496": ["    def test_handle_default_options(self):\n        options = mock.Mock()\n        options.settings = 'test_settings'\n        options.pythonpath = '/path/to/pythonpath'\n        handle_default_options(options)\n        self.assertEqual(os.environ['DJANGO_SETTINGS_MODULE'], 'test_settings')\n        self.assertEqual(sys.path[0], '/path/to/pythonpath')\n"], "sample_126": ["def test_alter_field_to_fk_dependency_other_app(self):\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author_fk],\n        [self.author_empty, self.book],\n    )\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '__first__')])\n"], "sample_50": ["def test_sigint_handler_restoration(self):\n        raise subprocess.CalledProcessError(1, args)\n    with mock.patch('subprocess.run', new=_mock_subprocess_run):\n        with mock.patch('signal.signal') as mock_signal:\n            DatabaseClient.runshell_db({\n                'database': 'dbname',\n                'user': 'someuser',\n                'password': 'somepassword',\n                'host': 'somehost',\n                'port': '444',\n            })\n            mock_signal.assert_called_with(signal.SIGINT, signal.getsignal(signal.SIGINT))\n"], "sample_749": ["def test_column_transformer_transformer_weights():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n\n    # test with transformer_weights\n    transformer_weights = {'trans1': .1, 'trans2': 10}\n    both = ColumnTransformer([('trans1', Trans(), [0]),\n                              ('trans2', Trans(), [1])],\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * np.array([0, 1, 2]).reshape(-1, 1),\n                     transformer_weights['trans2'] * np.array([2, 4, 6]).reshape(-1, 1)]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and remainder\n    transformer_weights = {'trans1': .1}\n    both = ColumnTransformer([('trans1', Trans(), [0])],\n                             remainder=Trans(),\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * np.array([0, 1, 2]).reshape(-1, 1),\n                     np.array([2, 4, 6]).reshape(-1, 1)]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and remainder with weight\n    transformer_weights = {'trans1': .1, 'remainder': 10}\n    both = ColumnTransformer([('trans1', Trans(), [0])],\n                             remainder=Trans(),\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * np.array([0, 1, 2]).reshape(-1, 1),\n                     transformer_weights['remainder'] * np.array([2, 4, 6]).reshape(-1, 1)]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and invalid key\n    transformer_weights"], "sample_402": ["def test_prepend_www_append_slash_with_port(self):\n    \"\"\"\n    PREPEND_WWW should work with URLs that have a port number.\n    \"\"\"\n    request = self.rf.get(\"http://testserver:8000/slash\")\n    r = CommonMiddleware(get_response_empty).process_request(request)\n    self.assertEqual(r.status_code, 301)\n    self.assertEqual(r.url, \"http://www.testserver:8000/slash/\")\n"], "sample_568": ["def test_line3d_set_get_data_3d(fig_test, fig_ref):\n    x, y, z = [0, 1], [2, 3], [4, 5]\n    x2, y2, z2 = [6, 7], [8, 9], [10, 11]\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    lines = ax.plot(x, y, z)\n    line = lines[0]\n    np.testing.assert_array_equal((x, y, z), line.get_data_3d())\n    line.set_data_3d(x2, y2, z2)\n    np.testing.assert_array_equal((x2, y2, z2), line.get_data_3d())\n    line.set_xdata(x)\n    line.set_ydata(y)\n    line.set_3d_properties(zs=z, zdir='z')\n    np.testing.assert_array_equal((x, y, z), line.get_data_3d())\n    line.set_3d_properties(zs=0, zdir='z')\n    np.testing.assert_array_equal((x, y, np.zeros_like(z)), line.get_data_3d())\n"], "sample_882": ["def test_mlp_regressor_sparse_input():\n    # Test that sparse input matrices output the same results as dense input matrices.\n    X = X_reg\n    y = y_reg\n\n    mlp = MLPRegressor(\n        solver=\"lbfgs\",\n        hidden_layer_sizes=50,\n        max_iter=150,\n        shuffle=True,\n        random_state=1,\n    )\n    mlp.fit(X, y)\n    pred1 = mlp.predict(X)\n    mlp.fit(csr_matrix(X), y)\n    pred2 = mlp.predict(csr_matrix(X))\n    assert_almost_equal(pred1, pred2)\n    pred1 = mlp.predict(X)\n    pred2 = mlp.predict(csr_matrix(X))\n    assert_array_equal(pred1, pred2)\n"], "sample_418": ["    def test_addslashes(self):\n        output = self.engine.render_to_string(\"stringfilter01\", {\"var\": \"Hello 'World' \\\"Django\\\"\"})\n        self.assertEqual(output, \"Hello \\\\'World\\' \\\"Django\\\"\")\n"], "sample_224": ["def test_aggregate_subquery_annotation_with_filter(self):\n    \"\"\"\n    Subquery annotations are excluded from the GROUP BY if they are not\n    explicitly grouped against, even if they are filtered.\n    \"\"\"\n    latest_book_pubdate_qs = Book.objects.filter(\n        publisher=OuterRef('pk'),\n        rating__gt=4,\n    ).order_by('-pubdate').values('pubdate')[:1]\n    publisher_qs = Publisher.objects.annotate(\n        latest_book_pubdate=Subquery(latest_book_pubdate_qs),\n    ).annotate(count=Count('book'))\n    with self.assertNumQueries(1) as ctx:\n        list(publisher_qs)\n    self.assertEqual(ctx[0]['sql'].count('SELECT'), 2)\n    # The GROUP BY should not be by alias either.\n    self.assertEqual(ctx[0]['sql'].lower().count('latest_book_pubdate'), 1)\n"], "sample_683": ["def test_capturing_with_keyboardinterrupt(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\\\n        import time\n            raise KeyboardInterrupt()\n            time.sleep(1)\n            print(\"this should not be captured\")\n    \"\"\"\n    )\n    result = testdir.runpytest_subprocess(p)\n    result.stdout.fnmatch_lines([\"*KeyboardInterrupt*\"])\n    assert result.ret == 2\n    assert \"this should not be captured\" not in result.stdout.str()\n"], "sample_191": ["    def test_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertEqual(mocked_termios.tcgetattr.call_count, 1)\n        self.assertEqual(mocked_termios.tcsetattr.call_count, 1)\n"], "sample_285": ["def test_finders_with_non_existent_dir(self):\n    static_dir = Path(TEST_ROOT) / 'non_existent_dir'\n    with self.settings(STATICFILES_DIRS=[static_dir]):\n        self.assertEqual(check_finders(None), [\n            Warning(\n                f\"The directory '{static_dir}' in the STATICFILES_DIRS setting does not exist.\",\n                id='staticfiles.W004',\n            ),\n        ])\n"], "sample_512": ["def test_subplot_mosaic():\n    fig, axs = plt.subplot_mosaic([['A', 'B'], ['C', 'D']])\n    assert len(axs) == 4\n    assert axs['A'] is not axs['B']\n    assert axs['A'] is not axs['C']\n    assert axs['A'] is not axs['D']\n    assert axs['B'] is not axs['C']\n    assert axs['B'] is not axs['D']\n    assert axs['C'] is not axs['D']\n\n    fig, axs = plt.subplot_mosaic([['A', 'B'], ['.', 'D']])\n    assert len(axs) == 3\n    assert axs['A'] is not axs['B']\n    assert axs['A'] is not axs['D']\n    assert axs['B'] is not axs['D']\n\n    fig, axs = plt.subplot_mosaic([['A', 'B'], ['C', '.']])\n    assert len(axs) == 3\n    assert axs['A'] is not axs['B']\n    assert axs['A'] is not axs['C']\n    assert axs['B'] is not axs['C']\n\n    fig, axs = plt.subplot_mosaic([['A', '.'], ['C', 'D']])\n    assert len(axs) == 3\n    assert axs['A'] is not axs['C']\n    assert axs['A'] is not axs['D']\n    assert axs['C'] is not axs['D']\n\n    fig, axs = plt.subplot_mosaic([['.', 'B'], ['C', 'D']])\n    assert len(axs) == 3\n    assert axs['B'] is not axs['C']\n    assert axs['B'] is not axs['D']\n    assert axs['C'] is not axs['D']\n\n    fig, axs = plt.subplot_mosaic([['.', '.'], ['.', '.']])\n    assert len(axs) == 0\n\n    fig, axs = plt.subplot_mosaic([['A', 'B'], ['C', 'D']], empty_sentinel=' ')\n    assert len(axs) == 4\n    assert axs['A'] is not axs['B']\n    assert axs['A'] is not axs['C']\n    assert axs['A'] is not axs['D']\n    assert axs['B'] is not axs['C']\n    assert axs['B'] is not axs['D']\n    assert axs['C']"], "sample_387": ["    def test_get_inline_instances(self):\n        class MyInline(admin.StackedInline):\n            model = Album\n\n        class BandAdmin(admin.ModelAdmin):\n            inlines = [MyInline]\n\n        band_admin = BandAdmin(Band, admin.site)\n        inline_instances = band_admin.get_inline_instances(self.client, Band())\n        self.assertEqual(len(inline_instances), 1)\n        self.assertIsInstance(inline_instances[0], MyInline)\n"], "sample_83": ["    def test_get_resolved_arguments(self):\n            pass\n        node = TagHelperNode(func, False, [1, 2], {'a': 3, 'b': 4})\n        context = {'1': 'resolved_1', '2': 'resolved_2', '3': 'resolved_3', '4': 'resolved_4'}\n        resolved_args, resolved_kwargs = node.get_resolved_arguments(context)\n        self.assertEqual(resolved_args, ['resolved_1', 'resolved_2'])\n        self.assertEqual(resolved_kwargs, {'a': 'resolved_3', 'b': 'resolved_4'})\n"], "sample_522": ["def test_colorbar_set_ticks():\n    # test fix for #5792\n    plt.figure()\n    data = np.arange(1200).reshape(30, 40)\n    levels = [0, 200, 400, 600, 800, 1000, 1200]\n\n    plt.contourf(data, levels=levels)\n\n    # testing setter for user set ticks\n    userTicks = plt.colorbar(ticks=[0, 600, 1200])\n    assert userTicks.get_ticks().tolist() == [0, 600, 1200]\n\n    # testing for setter after calling set_ticks\n    userTicks.set_ticks([600, 700, 800])\n    assert userTicks.get_ticks().tolist() == [600, 700, 800]\n\n    # testing for setter after calling set_ticks with some ticks out of bounds\n    # removed #20054: other axes don't trim fixed lists, so colorbars\n    # should not either:\n    # userTicks.set_ticks([600, 1300, 1400, 1500])\n    # assert userTicks.get_ticks().tolist() == [600]\n\n    # testing setter when no ticks are assigned\n    defTicks = plt.colorbar(orientation='horizontal')\n    np.testing.assert_allclose(defTicks.get_ticks(), levels)\n\n    # test normal ticks and minor ticks\n    fig, ax = plt.subplots()\n    x = np.arange(-3.0, 4.001)\n    y = np.arange(-4.0, 3.001)\n    X, Y = np.meshgrid(x, y)\n    Z = X * Y\n    Z = Z[:-1, :-1]\n    pcm = ax.pcolormesh(X, Y, Z)\n    cbar = fig.colorbar(pcm, ax=ax, extend='both',\n                        orientation='vertical')\n    ticks = cbar.get_ticks()\n    cbar.set_ticks([1, 2, 3])\n    assert isinstance(cbar.locator, FixedLocator)\n    np.testing.assert_allclose(cbar.ax.yaxis.get_ticklocs(),\n                               [1.0, 2.0, 3.0])\n"], "sample_1030": ["def test_closest_points():\n    points = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4)]\n    assert closest_points(*points) == {(Point2D(1, 1), Point2D(1, 2))}\n    points = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4), (1, 1)]\n    assert closest_points(*points) == {(Point2D(1, 1), Point2D(1, 2))}\n    points = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4), (1, 1), (1, 1)]\n    assert closest_points(*points) == {(Point2D(1, 1), Point2D(1, 2))}\n    points = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4), (1, 1), (1, 1), (1, 1)]\n    assert closest_points(*points) == {(Point2D(1, 1), Point2D(1, 2))}\n    points = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4), (1, 1), (1, 1), (1, 1), (1, 1)]\n    assert closest_points(*points) == {(Point2D(1, 1), Point2D(1, 2))}\n    points = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]\n    assert closest_points(*points) == {(Point2D(1, 1), Point2D(1, 2))}\n    points = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4), (1, 1), (1, 1), (1, 1), (1"], "sample_143": ["def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('hello'), 'hello')\n    self.assertEqual(text.camel_case_to_spaces(''), '')\n    self.assertEqual(text.camel_case_to_spaces('aBcDeFgHiJkLmNoPqRsTuVwXyZ'), 'a bc de fg hi jk lm no pq rs tu vw xy z')\n    self.assertEqual(text.camel_case_to_spaces(lazystr('HelloWorld')), 'hello world')\n"], "sample_893": ["def test_export_text_max_depth():\n    # Check that export_text handles max_depth correctly\n    clf = DecisionTreeClassifier(max_depth=2, random_state=0)\n    clf.fit(X, y)\n\n    expected_report = dedent(\"\"\"\n    |--- feature_1 <= 0.00\n    |   |--- class: -1\n    |--- feature_1 >  0.00\n    |   |--- truncated branch of depth 1\n    \"\"\").lstrip()\n    assert export_text(clf, max_depth=0) == expected_report\n\n    expected_report = dedent(\"\"\"\n    |--- feature_1 <= 0.00\n    |   |--- class: -1\n    |--- feature_1 >  0.00\n    |   |--- feature_1 <= 1.50\n    |   |   |--- class: 1\n    |   |--- feature_1 >  1.50\n    |   |   |--- class: 1\n    \"\"\").lstrip()\n    assert export_text(clf, max_depth=1) == expected_report\n"], "sample_902": ["def test_pipeline_memory_with_feature_union():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        memory = Memory(cachedir=cachedir, verbose=10)\n        # Test with FeatureUnion + SVC\n        clf = SVC(probability=True, random_state=0)\n        pca = PCA(n_components=2, svd_solver='randomized', random_state=0)\n        select = SelectKBest(k=1)\n        fs = FeatureUnion([(\"pca\", pca), (\"select\", select)])\n        pipe = Pipeline([('fs', fs), ('svc', clf)])\n        cached_pipe = Pipeline([('fs', fs), ('svc', clf)],\n                               memory=memory)\n\n        # Memoize the transformer at the first fit\n        cached_pipe.fit(X, y)\n        pipe.fit(X, y)\n        # Get the time stamp of the transformer in the cached pipeline\n        ts_pca = cached_pipe.named_steps['fs'].transformer_list[0][1].timestamp_\n        ts_select = cached_pipe.named_steps['fs'].transformer_list[1][1].timestamp_\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['fs'].transformer_list[0][1].means_,\n                           cached_pipe.named_steps['fs'].transformer_list[0][1].means_)\n        assert_array_equal(pipe.named_steps['fs'].transformer_list[1][1].pvalues_,\n                           cached_pipe.named_steps['fs'].transformer_list[1][1].pvalues_)\n        assert_false(hasattr(pca, 'means_'))\n        assert_false(hasattr(select, 'means_'))\n        # Check that we are reading the cache while fitting\n        # a second time\n        cached_pipe.fit(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y"], "sample_641": ["def test_load_results_non_existent_file(path: str) -> None:\n    assert load_results(path) is None\n\n"], "sample_29": ["def test_write_latex_kwargs(self, write, tmp_path):\n    \"\"\"Test passing additional keyword arguments to write_latex\"\"\"\n    fp = tmp_path / \"test_write_latex_kwargs.tex\"\n    write(fp, format=\"latex\", latex_names=True, comment='#')\n    tbl = QTable.read(fp, format=\"latex\", comment='#')\n    # asserts each column name has not been reverted yet\n    # For now, Cosmology class and name are stored in first 2 slots\n    for column_name in tbl.colnames[2:]:\n        assert column_name in _FORMAT_TABLE.values()\n"], "sample_544": ["def test_nonuniformimage_interpolation(fig_test, fig_ref):\n    ax_test = fig_test.subplots()\n    ax_ref = fig_ref.subplots()\n\n    x = np.linspace(0, 1, 10)\n    y = np.linspace(0, 1, 10)\n    A = np.random.rand(10, 10)\n\n    im_test = NonUniformImage(ax_test, interpolation='bilinear')\n    im_test.set_data(x, y, A)\n\n    im_ref = NonUniformImage(ax_ref, interpolation='nearest')\n    im_ref.set_data(x, y, A)\n\n    ax_test.set_xlim(0, 1)\n    ax_test.set_ylim(0, 1)\n    ax_ref.set_xlim(0, 1)\n    ax_ref.set_ylim(0, 1)\n"], "sample_638": ["def test_graphviz_unsupported_image_format(mock_writer, mock_subprocess, capsys):\n    \"\"\"Test that Graphviz is used if the image format is not supported.\"\"\"\n    mock_subprocess.run.return_value.stderr = (\n        'Format: \"XYZ\" not recognized. Use one of: '\n        \"bmp canon cgimage cmap cmapx cmapx_np dot dot_json eps exr fig gd \"\n        \"gd2 gif gv icns ico imap imap_np ismap jp2 jpe jpeg jpg json json0 \"\n        \"mp pct pdf pic pict plain plain-ext png pov ps ps2 psd sgi svg svgz \"\n        \"tga tif tiff tk vdx vml vmlz vrml wbmp webp xdot xdot1.2 xdot1.4 xdot_json\"\n    )\n    mock_subprocess.run.return_value.returncode = 1\n    with pytest.raises(SystemExit) as wrapped_sysexit:\n        # we have to catch the SystemExit so the test execution does not stop\n        main.Run([\"-o\", \"XYZ\", TEST_DATA_DIR])\n    # Check that the right info message is shown to the user\n    assert (\n        \"Format XYZ is not supported natively. Pyreverse will try to generate it using Graphviz...\"\n        in capsys.readouterr().out\n    )\n    # Check that pyreverse actually made the call to create the diagram and we exit cleanly\n    mock_writer.DiagramWriter().write.assert_called_once()\n    assert wrapped_sysexit.value.code == 0\n"], "sample_210": ["    def test_get_context_data(self):\n        mixin = ContextMixin()\n        mixin.extra_context = {'foo': 'bar'}\n        context = mixin.get_context_data(baz='qux')\n        self.assertEqual(context, {'view': mixin, 'foo': 'bar', 'baz': 'qux'})\n"], "sample_478": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n"], "sample_428": ["def test_decimal_subclass_format(self):\n    euro_decimal = EuroDecimal(\"1234\")\n    self.assertEqual(nformat(euro_decimal, \".\"), \"\u20ac 1234\")\n    self.assertEqual(nformat(euro_decimal, \".\", decimal_pos=2), \"\u20ac 1234.00\")\n    self.assertEqual(\n        nformat(euro_decimal, \".\", grouping=2, thousand_sep=\",\"), \"\u20ac 1234\"\n    )\n    self.assertEqual(\n        nformat(\n            euro_decimal, \".\", grouping=2, thousand_sep=\",\", force_grouping=True\n        ),\n        \"\u20ac 12,34\",\n    )\n    self.assertEqual(\n        nformat(EuroDecimal(\"-1234.33\"), \".\", decimal_pos=1), \"-\u20ac 1234.3\"\n    )\n    self.assertEqual(\n        nformat(EuroDecimal(\"0.00000001\"), \".\", decimal_pos=8), \"\u20ac 0.00000001\"\n    )\n    self.assertEqual(\n        nformat(EuroDecimal(\"9e-19\"), \".\", decimal_pos=2), \"\u20ac 0.00\"\n    )\n    self.assertEqual(\n        nformat(EuroDecimal(\".00000000000099\"), \".\", decimal_pos=0), \"\u20ac 0\"\n    )\n    self.assertEqual(\n        nformat(\n            EuroDecimal(\"1e16\"),\n            \".\",\n            thousand_sep=\",\",\n            grouping=3,\n            force_grouping=True,\n        ),\n        \"\u20ac 10,000,000,000,000,000\",\n    )\n    self.assertEqual(\n        nformat(\n            EuroDecimal(\"1e16\"),\n            \".\",\n            decimal_pos=2,\n            thousand_sep=\",\",\n            grouping=3,\n            force_grouping=True,\n        ),\n        \"\u20ac 10,000,000,000,000,000.00\",\n    )\n    self.assertEqual(nformat(EuroDecimal(\"3.\"), \".\"), \"\u20ac 3\")\n    self.assertEqual(nformat(EuroDecimal(\"3.0\"), \".\"), \"\u20ac 3.0\")\n"], "sample_805": ["def test_mean_tweedie_deviance_edge_cases():\n    # Test edge cases for mean_tweedie_deviance\n    y_true = np.array([1e-10, 1e-5, 1e-1, 1, 1e1, 1e5, 1e10])\n    y_pred = np.array([1e-10, 1e-5, 1e-1, 1, 1e1, 1e5, 1e10])\n\n    # Test p=0\n    assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, p=0),\n                        mean_squared_error(y_true, y_pred))\n\n    # Test p=1\n    assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, p=1),\n                        mean_poisson_deviance(y_true, y_pred))\n\n    # Test p=2\n    assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, p=2),\n                        mean_gamma_deviance(y_true, y_pred))\n\n    # Test p=3\n    assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, p=3),\n                        1 / y_true.mean())\n\n    # Test p=-1\n    assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, p=-1),\n                        2 / (2 - (-1)))\n\n    # Test p=-2\n    assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, p=-2),\n                        2 / (2 - (-2)))\n\n    # Test p=-3\n    assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, p=-3),\n                        2 / (2 - (-3)))\n\n    # Test p=1.5\n    assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, p=1.5),\n                        2 / (2 - 1.5))\n\n    # Test p=2.5\n    assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, p=2.5),\n                        2 / (2 - 2.5))\n"], "sample_700": ["def test_xfail_strict_with_parametrize(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.parametrize(\"x\", [1, 2])\n        @pytest.mark.xfail(strict=True)\n            assert x == 1\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-rxX\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*XPASS(strict)*test_foo*\",\n            \"*1 failed*1 xpassed*\",\n        ]\n    )\n"], "sample_278": ["    def test_q_object_equality(self):\n        q1 = Q(name='John')\n        q2 = Q(name='John')\n        q3 = Q(name='Jane')\n\n        self.assertEqual(q1, q2)\n        self.assertNotEqual(q1, q3)\n"], "sample_147": ["def test_union_with_deferred_fields(self):\n    Number.objects.create(num=1, other_num=10)\n    qs1 = Number.objects.defer('other_num').filter(num=1)\n    qs2 = Number.objects.defer('other_num').filter(num=2)\n    self.assertEqual(qs1.union(qs2).count(), 2)\n    self.assertEqual(qs1.union(qs2).values_list('num', flat=True), [1, 2])\n"], "sample_865": ["def test_prune_tree_with_min_samples_split():\n    # Test that pruning a tree with min_samples_split > 1 works correctly\n    X = np.array([[0], [1], [2], [3], [4]])\n    y = np.array([0, 0, 1, 1, 1])\n\n    clf = DecisionTreeClassifier(random_state=0, min_samples_split=3,\n                                 ccp_alpha=0.0)\n    clf.fit(X, y)\n\n    assert clf.tree_.max_depth == 1\n\n    clf = DecisionTreeClassifier(random_state=0, min_samples_split=3,\n                                 ccp_alpha=1.0)\n    clf.fit(X, y)\n\n    assert clf.tree_.max_depth == 0\n"], "sample_205": ["def test_update_error_dict(self):\n    error_dict = {'field1': ['error1', 'error2']}\n    exception = ValidationError(error_dict)\n    new_error_dict = {}\n    exception.update_error_dict(new_error_dict)\n    self.assertEqual(new_error_dict, error_dict)\n\n    error_dict = {'field1': ['error1', 'error2'], 'field2': ['error3']}\n    exception = ValidationError(error_dict)\n    new_error_dict = {'field3': ['error4']}\n    exception.update_error_dict(new_error_dict)\n    self.assertEqual(new_error_dict, {'field3': ['error4'], 'field1': ['error1', 'error2'], 'field2': ['error3']})\n\n    error_dict = {'field1': ['error1', 'error2']}\n    exception = ValidationError(error_dict)\n    new_error_dict = {'field1': ['error3']}\n    exception.update_error_dict(new_error_dict)\n    self.assertEqual(new_error_dict, {'field1': ['error3', 'error1', 'error2']})\n\n    exception = ValidationError('error')\n    new_error_dict = {}\n    exception.update_error_dict(new_error_dict)\n    self.assertEqual(new_error_dict, {NON_FIELD_ERRORS: ['error']})\n\n    exception = ValidationError('error')\n    new_error_dict = {'field1': ['error1']}\n    exception.update_error_dict(new_error_dict)\n    self.assertEqual(new_error_dict, {'field1': ['error1'], NON_FIELD_ERRORS: ['error']})\n"], "sample_733": ["def test_vectorizer_with_empty_string():\n    # Test that an empty string is handled correctly\n    vect = CountVectorizer()\n    X = vect.fit_transform([\"\", \"hello world\"])\n    assert_equal(X.shape, (2, 1))\n    assert_equal(vect.vocabulary_, {'world': 0, 'hello': 1})\n    assert_array_equal(X.toarray(), [[0, 0], [1, 1]])\n"], "sample_172": ["    def test_get_fieldsets(self):\n        class MyModelAdmin(admin.ModelAdmin):\n            fieldsets = [\n                (None, {'fields': ['field1', 'field2']}),\n                ('Group', {'fields': ['field3', 'field4']}),\n            ]\n\n        ma = MyModelAdmin(None, None)\n        self.assertEqual(ma.get_fieldsets(None), ma.fieldsets)\n"], "sample_66": ["    def test_get_signed_cookie(self):\n        request = HttpRequest()\n        request.COOKIES['signed_cookie'] = signing.get_cookie_signer('signed_cookie').sign('value')\n        self.assertEqual(request.get_signed_cookie('signed_cookie'), 'value')\n"], "sample_642": ["def test_preprocess_options(option: str, value: str | None, expected: Any, capsys: CaptureFixture) -> None:\n    \"\"\"Test that pre-processable options are correctly handled.\"\"\"\n    with tempdir() as chroot:\n        with fake_home():\n            chroot_path = Path(chroot)\n            testutils.create_files([\"a/b/c/d/__init__.py\"])\n            os.chdir(chroot_path / \"a/b/c\")\n            run = Run([\"--rcfile\", \"pylintrc\"])\n            if value is not None:\n                run._preprocess_options([option + \"=\" + value])\n            else:\n                run._preprocess_options([option])\n            if option == \"--init-hook\":\n                out = capsys.readouterr()\n                assert \"Hello World\" in out.out\n            elif option == \"--rcfile\":\n                assert run._rcfile == expected\n            elif option == \"--output\":\n                assert run._output == expected\n            elif option == \"--load-plugins\":\n                assert run._plugins == expected\n            elif option in [\"--verbose\", \"-v\"]:\n                assert run.verbose == expected\n            elif option == \"--enable-all-extensions\":\n                assert len(run._plugins) > 0\n"], "sample_558": ["def test_grid_set_axes_pad():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 2))\n    grid.set_axes_pad((0.1, 0.2))\n    assert grid.get_axes_pad() == (0.1, 0.2)\n"], "sample_259": ["def test_prefetch_object_to_attr_conflict(self):\n    book1 = Book.objects.get(id=self.book1.id)\n    with self.assertRaises(ValueError):\n        prefetch_related_objects(\n            [book1],\n            Prefetch('authors', to_attr='id'),\n        )\n"], "sample_634": ["    def test_expand_modules_with_ignore(self, files_or_modules, ignore_list, ignore_list_re, expected):\n        \"\"\"Test expand_modules with ignore options\"\"\"\n        modules, errors = expand_modules(\n            files_or_modules,\n            ignore_list,\n            ignore_list_re,\n            get_global_option(self, \"ignore-paths\"),\n        )\n        modules.sort(key=lambda d: d[\"name\"])\n        assert modules == expected\n        assert not errors\n"], "sample_152": ["    def test_add_dependency(self):\n        collector = Collector(using='default')\n        model1 = R\n        model2 = A\n        collector.add_dependency(model1, model2)\n        self.assertIn(model1._meta.concrete_model, collector.dependencies)\n        self.assertIn(model2._meta.concrete_model, collector.dependencies[model1._meta.concrete_model])\n"], "sample_323": ["def test_detect_soft_applied_add_field_non_m2mfield(self):\n    \"\"\"\n    executor.detect_soft_applied() detects non-ManyToManyField tables from an\n    AddField operation.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Create the tables for 0001 but make it look like the migration hasn't\n    # been applied.\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n    executor.migrate([(\"migrations\", None)], fake=True)\n    # Table detection sees 0001 is applied.\n    migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], True)\n    # Leave the tables for 0001 except the author table. That missing\n    # table should cause detect_soft_applied() to return False.\n    with connection.schema_editor() as editor:\n        editor.execute(editor.sql_delete_table % {\"table\": \"migrations_author\"})\n    migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], False)\n    # Cleanup by removing the remaining tables.\n    with connection.schema_editor() as editor:\n        editor.execute(editor.sql_delete_table % {\"table\": \"migrations_tribble\"})\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_tribble\")\n"], "sample_292": ["def test_rotate_token(self):\n    \"\"\"\n    The rotate_token function changes the CSRF token in use for a request.\n    \"\"\"\n    req = self._get_GET_csrf_cookie_request()\n    mw = CsrfViewMiddleware(token_view)\n    mw.process_request(req)\n    original_token = req.META['CSRF_COOKIE']\n    rotate_token(req)\n    mw.process_request(req)\n    new_token = req.META['CSRF_COOKIE']\n    self.assertNotEqual(original_token, new_token)\n    self.assertEqual(len(new_token), CSRF_TOKEN_LENGTH)\n"], "sample_167": ["def test_naturaltime_with_non_english_locale(self):\n    \"\"\"\n    Verify that naturaltime works correctly with non-English locales.\n    \"\"\"\n    test_list = [\n        'test',\n        now,\n        now - datetime.timedelta(microseconds=1),\n        now - datetime.timedelta(seconds=1),\n        now - datetime.timedelta(seconds=30),\n        now - datetime.timedelta(minutes=1, seconds=30),\n        now - datetime.timedelta(minutes=2),\n        now - datetime.timedelta(hours=1, minutes=30, seconds=30),\n        now - datetime.timedelta(hours=23, minutes=50, seconds=50),\n        now - datetime.timedelta(days=1),\n        now - datetime.timedelta(days=500),\n        now + datetime.timedelta(seconds=1),\n        now + datetime.timedelta(seconds=30),\n        now + datetime.timedelta(minutes=1, seconds=30),\n        now + datetime.timedelta(minutes=2),\n        now + datetime.timedelta(hours=1, minutes=30, seconds=30),\n        now + datetime.timedelta(hours=23, minutes=50, seconds=50),\n        now + datetime.timedelta(days=1),\n        now + datetime.timedelta(days=2, hours=6),\n        now + datetime.timedelta(days=500),\n    ]\n    result_list = [\n        'test',\n        'maintenant',\n        'maintenant',\n        'il y a 1 seconde',\n        'il y a 30 secondes',\n        'il y a 1 minute',\n        'il y a 2 minutes',\n        'il y a 1 heure',\n        'il y a 23 heures',\n        'il y a 1 jour',\n        'il y a 1 an, 4 mois',\n        'dans 1 seconde',\n        'dans 30 secondes',\n        'dans 1 minute',\n        'dans 2 minutes',\n        'dans 1 heure',\n        'dans 23 heures',\n        'dans 1 jour',\n        'dans 2 jours, 6 heures',\n        'dans 1 an, 4 mois',\n    ]\n\n    orig_humanize_datetime, humanize.datetime = humanize.datetime, MockDateTime\n    try:\n        with translation.override('fr'):\n            self.humanize_tester(test_list, result_list, 'naturaltime')\n    finally:\n        humanize.datetime = orig_humanize_datetime\n"], "sample_447": ["def test_window_function_annotation(self):\n    books = Book.objects.annotate(\n        avg_rating=Window(\n            expression=Avg(\"rating\"),\n            partition_by=F(\"publisher\"),\n            order_by=F(\"pubdate\").asc(),\n        )\n    )\n    self.assertEqual(\n        books[0].avg_rating,\n        (self.b5.rating + self.b6.rating + self.b1.rating + self.b3.rating + self.b4.rating)\n        / 5,\n    )\n    self.assertEqual(\n        books[1].avg_rating,\n        (self.b5.rating + self.b6.rating + self.b1.rating + self.b3.rating + self.b4.rating)\n        / 5,\n    )\n    self.assertEqual(\n        books[2].avg_rating,\n        (self.b5.rating + self.b6.rating + self.b1.rating + self.b3.rating + self.b4.rating)\n        / 5,\n    )\n    self.assertEqual(\n        books[3].avg_rating,\n        (self.b5.rating + self.b6.rating + self.b1.rating + self.b3.rating + self.b4.rating)\n        / 5,\n    )\n    self.assertEqual(\n        books[4].avg_rating,\n        (self.b5.rating + self.b6.rating + self.b1.rating + self.b3.rating + self.b4.rating)\n        / 5,\n    )\n    self.assertEqual(\n        books[5].avg_rating,\n        (self.b2.rating + self.b3.rating) / 2,\n    )\n"], "sample_890": ["def test_cross_val_score_with_groups(direction):\n    # Make sure that cross_val_score with groups is supported\n\n    X, y = make_regression(n_features=10)\n    groups = np.arange(len(y))\n    sfs = SequentialFeatureSelector(\n        LinearRegression(),\n        n_features_to_select=\"auto\",\n        direction=direction,\n        cv=LeaveOneGroupOut(),\n    )\n    sfs.fit(X, y, groups=groups)\n    sfs.transform(X)\n"], "sample_378": ["    def test_get_or_create_with_defaults(self):\n        defaults = {'note': 'test'}\n        obj, created = Note.objects.get_or_create(misc='test', defaults=defaults)\n        self.assertTrue(created)\n        self.assertEqual(obj.note, 'test')\n        self.assertEqual(obj.misc, 'test')\n"], "sample_175": ["def test_collector_add_dependency(self):\n    collector = Collector(using='default')\n    model1 = R\n    model2 = S\n    collector.add_dependency(model1, model2)\n    self.assertIn(model1._meta.concrete_model, collector.dependencies)\n    self.assertIn(model2._meta.concrete_model, collector.dependencies[model1._meta.concrete_model])\n"], "sample_493": ["def test_aggregation_default_using_duration_from_database_with_filter(self):\n    result = Publisher.objects.filter(num_awards__gt=3).aggregate(\n        value=Sum(\"duration\", default=Now() - Now(), filter=Q(num_awards__gt=3)),\n    )\n    self.assertEqual(result[\"value\"], datetime.timedelta(0))\n"], "sample_960": ["def test_python_domain_clear_doc(app):\n    text = (\".. py:module:: example\\n\"\n            \".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:method:: meth\\n\")\n    domain = app.env.get_domain('py')\n    restructuredtext.parse(app, text)\n    assert 'example' in domain.modules\n    assert 'example.Class' in domain.objects\n    assert 'example.Class.meth' in domain.objects\n\n    domain.clear_doc('index')\n    assert 'example' not in domain.modules\n    assert 'example.Class' not in domain.objects\n    assert 'example.Class.meth' not in domain.objects\n"], "sample_892": ["def test_adaboost_feature_importances():\n    # Check feature importances.\n    X, y = datasets.make_classification(\n        n_samples=2000,\n        n_features=10,\n        n_informative=3,\n        n_redundant=0,\n        n_repeated=0,\n        shuffle=False,\n        random_state=1,\n    )\n\n    for alg in [\"SAMME\", \"SAMME.R\"]:\n        clf = AdaBoostClassifier(algorithm=alg)\n\n        clf.fit(X, y)\n        importances = clf.feature_importances_\n\n        assert importances.shape[0] == 10\n        assert (importances[:3, np.newaxis] >= importances[3:]).all()\n\n    # AdaBoost regression\n    X, y = datasets.make_regression(\n        n_samples=2000,\n        n_features=10,\n        n_informative=3,\n        n_targets=1,\n        shuffle=False,\n        random_state=1,\n    )\n\n    clf = AdaBoostRegressor(random_state=0)\n\n    clf.fit(X, y)\n    importances = clf.feature_importances_\n\n    assert importances.shape[0] == 10\n    assert (importances[:3, np.newaxis] >= importances[3:]).all()\n"], "sample_1023": ["def test_sieve():\n    s = Sieve()\n    assert s._n == 6\n    assert s._list == _array('l', [2, 3, 5, 7, 11, 13])\n    assert s._tlist == _array('l', [0, 1, 1, 2, 2, 4])\n    assert s._mlist == _array('l', [0, 1, -1, -1, 0, -1])\n    assert len(s._list) == len(s._tlist) == len(s._mlist) == s._n\n\n    s._reset(prime=True)\n    assert s._list == _array('l', [2, 3, 5, 7, 11, 13])\n    assert s._tlist == _array('l', [0, 1, 1, 2, 2, 4])\n    assert s._mlist == _array('l', [0, 1, -1, -1, 0, -1])\n    assert len(s._list) == len(s._tlist) == len(s._mlist) == s._n\n\n    s._reset(totient=True)\n    assert s._list == _array('l', [2, 3, 5, 7, 11, 13])\n    assert s._tlist == _array('l', [0, 1, 1, 2, 2, 4])\n    assert s._mlist == _array('l', [0, 1, -1, -1, 0, -1])\n    assert len(s._list) == len(s._tlist) == len(s._mlist) == s._n\n\n    s._reset(mobius=True)\n    assert s._list == _array('l', [2, 3, 5, 7, 11, 13])\n    assert s._tlist == _array('l', [0, 1, 1, 2, 2, 4])\n    assert s._mlist == _array('l', [0, 1, -1, -1, 0, -1])\n    assert len(s._list) == len(s._tlist) == len(s._mlist) == s._n\n\n    s._"], "sample_800": ["def test_check_estimator_tags():\n    # Test that estimators with specific tags are correctly handled\n    # by check_estimator\n\n    # Test that estimators with 'binary_only' tag are correctly handled\n    class BinaryOnlyClassifier(BaseEstimator):\n            return {'binary_only': True}\n\n            return self\n\n            return np.ones(X.shape[0])\n\n    check_estimator(BinaryOnlyClassifier())\n\n    # Test that estimators with 'multioutput_only' tag are correctly handled\n    class MultiOutputOnlyRegressor(BaseEstimator):\n            return {'multioutput_only': True}\n\n            return self\n\n            return np.ones((X.shape[0], 2))\n\n    check_estimator(MultiOutputOnlyRegressor())\n\n    # Test that estimators with 'poor_score' tag are correctly handled\n    class PoorScoreClassifier(BaseEstimator):\n            return {'poor_score': True}\n\n            return self\n\n            return np.ones(X.shape[0])\n\n    check_estimator(PoorScoreClassifier())\n\n    # Test that estimators with 'non_deterministic' tag are correctly handled\n    class NonDeterministicClassifier(BaseEstimator):\n            return {'non_deterministic': True}\n\n            return self\n\n            return np.ones(X.shape[0])\n\n    check_estimator(NonDeterministicClassifier())\n\n    # Test that estimators with 'allow_nan' tag are correctly handled\n    class AllowNaNRegressor(BaseEstimator):\n            return {'allow_nan': True}\n\n            return self\n\n            return np.ones(X.shape[0])\n\n    check_estimator(AllowNaNRegressor())\n\n    # Test that estimators with 'requires_positive_y' tag are correctly handled\n    class RequiresPositiveYRegressor(BaseEstimator):\n            return {'requires_positive_y': True}\n\n            if (y <= 0).any():\n                raise ValueError('negative y values not supported!')\n            return self\n\n           "], "sample_632": ["def test_similar_checker():\n    linter = PyLinter()\n    linter.load_plugin_packages([\"pylint.extensions\"])\n    linter.load_plugin_modules([\"similar\"])\n    reporter = Reporter()\n    linter.set_reporter(reporter)\n    linter.check([SIMILAR1, SIMILAR2])\n    assert len(reporter.messages) == 1\n    assert reporter.messages[0].symbol == \"R0801\"\n    assert reporter.messages[0].msg == \"Similar lines in 2 files\\n%s\" % (\n        \"\\n\".join(\n            [\n                \"==%s:0\" % SIMILAR1,\n                \"==%s:0\" % SIMILAR2,\n                \"   import one\",\n                \"   from two import two\",\n                \"   three\",\n                \"   four\",\n                \"   five\",\n            ]\n        )\n    )\n"], "sample_464": ["def test_set_signed_cookie(self):\n    response = HttpResponse()\n    response.set_signed_cookie(\"test\", \"value\")\n    self.assertIn(\"test\", response.cookies)\n    self.assertEqual(response.cookies[\"test\"][\"httponly\"], True)\n    self.assertEqual(response.cookies[\"test\"][\"samesite\"], \"Lax\")\n    self.assertEqual(response.cookies[\"test\"][\"secure\"], False)\n"], "sample_138": ["    def test_hashed_name(self):\n        relpath = storage.staticfiles_storage.hashed_name(\"test/file.txt\")\n        self.assertEqual(relpath, \"test/file.txt\")\n"], "sample_716": ["def test_ridge_regression_return_intercept():\n    # Test return_intercept parameter of ridge_regression function\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([5, 6])\n    alpha = 1.0\n\n    # Test return_intercept=True\n    coef, intercept = ridge_regression(X, y, alpha, return_intercept=True)\n    assert_array_almost_equal(coef, np.array([1.5, 0.5]))\n    assert_almost_equal(intercept, 2.0)\n\n    # Test return_intercept=False\n    coef = ridge_regression(X, y, alpha, return_intercept=False)\n    assert_array_almost_equal(coef, np.array([1.5, 0.5]))\n\n    # Test return_intercept=True with sparse X\n    X_sparse = sp.csr_matrix(X)\n    coef, intercept = ridge_regression(X_sparse, y, alpha, return_intercept=True)\n    assert_array_almost_equal(coef, np.array([1.5, 0.5]))\n    assert_almost_equal(intercept, 2.0)\n\n    # Test return_intercept=False with sparse X\n    coef = ridge_regression(X_sparse, y, alpha, return_intercept=False)\n    assert_array_almost_equal(coef, np.array([1.5, 0.5]))\n"], "sample_215": ["    def test_get_traceback_frames_with_cyclic_reference_in_exception_chain(self):\n        \"\"\"\n        Test that ExceptionReporter.get_traceback_frames() handles cyclic references\n        in the exception chain.\n        \"\"\"\n        try:\n            try:\n                raise RuntimeError('outer') from RuntimeError('inner')\n            except RuntimeError as exc:\n                exc.__cause__ = exc\n                raise exc\n        except Exception:\n            exc_type, exc_value, tb = sys.exc_info()\n        request = self.rf.get('/test_view/')\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n\n            nonlocal tb_frames\n            tb_frames = reporter.get_traceback_frames()\n\n        tb_frames = None\n        tb_generator = threading.Thread(target=generate_traceback_frames, daemon=True)\n        msg = (\n            \"Cycle in the exception chain detected: exception 'inner' \"\n            \"encountered again.\"\n        )\n        with self.assertWarnsMessage(ExceptionCycleWarning, msg):\n            tb_generator.start()\n        tb_generator.join(timeout=5)\n        if tb_generator.is_alive():\n            # tb_generator is a daemon that runs until the main thread/process\n            # exits. This is resource heavy when running the full test suite.\n            # Setting the following values to None makes\n            # reporter.get_traceback_frames() exit early.\n            exc_value.__traceback__ = exc_value.__context__ = exc_value.__cause__ = None\n            tb_generator.join()\n            self.fail('Cyclic reference in Exception Reporter.get_traceback_frames()')\n        if tb_frames is None:\n            # can happen if the thread generating traceback got killed\n            # or exception while generating the traceback\n            self.fail('Traceback generation failed')\n        last_frame = tb_frames[-1]\n        self.assertIn('raise exc', last_frame['context_line'])\n        self.assertEqual(last_frame['filename'], __file__)\n        self.assertEqual(last_frame['function'], 'test_get_traceback_frames_with_cyclic_reference_in_exception_chain')\n"], "sample_725": ["def test_check_memory():\n    # Test that check_memory returns a Memory object\n    memory = check_memory(None)\n    assert_true(isinstance(memory, Memory))\n\n    # Test that check_memory returns the same Memory object\n    memory = Memory(location='test', verbose=0)\n    memory_checked = check_memory(memory)\n    assert_true(memory_checked is memory)\n\n    # Test that check_memory raises an error for invalid input\n    assert_raises(ValueError, check_memory, 'invalid')\n\n    # Test that check_memory raises an error for an object without cache method\n    class InvalidMemory:\n        pass\n    assert_raises(ValueError, check_memory, InvalidMemory())\n\n    # Test that check_memory works with a string\n    memory_checked = check_memory('test')\n    assert_true(isinstance(memory_checked, Memory))\n    assert_equal(memory_checked.cachedir, 'test')\n\n    # Test that check_memory works with a DummyMemory object\n    memory = DummyMemory()\n    memory_checked = check_memory(memory)\n    assert_true(isinstance(memory_checked, Memory))\n"], "sample_314": ["    def test_to_python(self):\n        field = UsernameField()\n        self.assertEqual(field.to_python('test'), 'test')\n"], "sample_61": ["    def test_ascii_validator(self):\n        valid_usernames = ['joe', 'joe123', 'joe@123', 'joe.123', 'joe+123', 'joe_123']\n        invalid_usernames = [\n            \"o'connell\", \"Ren\u00e9\", '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f',\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n"], "sample_112": ["def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should render prepopulated fields.\n    \"\"\"\n    request = self.request_factory.get(reverse('admin:admin_views_article_change', args=[self.article.pk]))\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    response = admin.change_view(request, str(self.article.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIn('prepopulated_fields', template_context)\n    self.assertIn('prepopulated_fields_json', template_context)\n    self.assertIsInstance(template_context['prepopulated_fields'], list)\n    self.assertIsInstance(template_context['prepopulated_fields_json'], str)\n"], "sample_1101": ["def test_SchurNumber():\n    raises(ValueError, lambda: SchurNumber(-1))\n    raises(ValueError, lambda: SchurNumber(0))\n    raises(ValueError, lambda: SchurNumber(Rational(1, 2)))\n    raises(ValueError, lambda: SchurNumber(S.Infinity))\n    assert SchurNumber(1) == 1\n    assert SchurNumber(2) == 4\n    assert SchurNumber(3) == 13\n    assert SchurNumber(4) == 44\n    assert isinstance(SchurNumber(5), SchurNumber)\n    assert SchurNumber(5).lower_bound() == 121\n\n    x = symbols(\"x\")\n    raises(ValueError, lambda: SchurNumber(x))\n"], "sample_85": ["    def test_resolve_relation(self):\n        # Test resolve_relation with RECURSIVE_RELATIONSHIP_CONSTANT\n        self.assertEqual(resolve_relation(A, RECURSIVE_RELATIONSHIP_CONSTANT), A)\n\n        # Test resolve_relation with a bare model name\n        self.assertEqual(resolve_relation(A, 'R'), 'tests.A.R')\n\n        # Test resolve_relation with an \"app_label.ModelName\" string\n        self.assertEqual(resolve_relation(A, 'tests.R'), 'tests.R')\n\n        # Test resolve_relation with a model class\n        self.assertEqual(resolve_relation(A, R), R)\n"], "sample_26": ["def test_section_data_negative_step(self):\n    a = np.arange(256).reshape(4, 4, 4, 4)\n    hdu = fits.PrimaryHDU(a)\n    hdu.writeto(self.temp(\"test_new.fits\"))\n\n    hdul = fits.open(self.temp(\"test_new.fits\"))\n    d = hdul[0]\n    dat = hdul[0].data\n    assert (d.section[:, :, :, ::-1] == dat[:, :, :, ::-1]).all()\n    assert (d.section[:, :, ::-1, :] == dat[:, :, ::-1, :]).all()\n    assert (d.section[:, ::-1, :, :] == dat[:, ::-1, :, :]).all()\n    assert (d.section[::-1, :, :, :] == dat[::-1, :, :, :]).all()\n    assert (d.section[::-1, ::-1, ::-1, ::-1] == dat[::-1, ::-1, ::-1, ::-1]).all()\n    hdul.close()\n"], "sample_324": ["def test_origin_verified_with_trusted_origin_subdomains(self):\n    \"\"\"\n    A POST request with an origin that matches a CSRF_TRUSTED_ORIGINS\n    wildcard is accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['HTTP_ORIGIN'] = 'https://foo.example.com'\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.csrf_trusted_origins_hosts = ['example.com']\n    mw.allowed_origin_subdomains = {'https': ['.example.com']}\n    self.assertIs(mw._origin_verified(req), True)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n"], "sample_777": ["def test_gradient_boosting_init_with_sample_weight():\n    # Check that GradientBoostingRegressor works when init is a sklearn\n    # estimator and sample weights are provided.\n    X, y = make_regression()\n    sample_weight = np.random.RandomState(42).rand(100)\n\n    # init supports sample weights\n    init_est = DummyRegressor()\n    GradientBoostingRegressor(init=init_est).fit(X, y, sample_weight=sample_weight)\n\n    # init does not support sample weights\n    init_est = _NoSampleWeightWrapper(DummyRegressor())\n    with pytest.raises(ValueError,\n                       match=\"estimator.*does not support sample weights\"):\n        GradientBoostingRegressor(init=init_est).fit(X, y, sample_weight=sample_weight)\n"], "sample_965": ["def test_is_newtype():\n    from typing import NewType\n\n    class MyNewType(NewType('MyNewType', int)):\n        pass\n\n    assert inspect.isNewType(MyNewType) is True\n    assert inspect.isNewType(int) is False\n    assert inspect.isNewType(object) is False\n"], "sample_189": ["    def test_eviction(self):\n        cache.set('key1', 'value1')\n        cache.set('key2', 'value2')\n        self.assertIsNone(cache.get('key1'))\n        self.assertEqual(cache.get('key2'), 'value2')\n"], "sample_752": ["def test_iforest_offset_calculation():\n    \"\"\"Test offset calculation for different contamination values.\"\"\"\n    X_train = np.array([[0, 1], [1, 2]])\n    X_test = np.array([[2, 1], [1, 1]])\n\n    contamination_values = [0.1, 0.5, \"auto\"]\n    expected_offsets = [-0.1, -0.5, -0.5]\n\n    for contamination, expected_offset in zip(contamination_values, expected_offsets):\n        clf = IsolationForest(contamination=contamination, random_state=rng).fit(X_train)\n        assert_almost_equal(clf.offset_, expected_offset, decimal=10)\n"], "sample_543": ["def test_polygon_selector_add_state(ax):\n    tool = widgets.PolygonSelector(ax, onselect=noop)\n\n    with pytest.raises(ValueError):\n        tool.add_state('unsupported_state')\n\n    tool.add_state('move_vertex')\n    tool.add_state('move_all')\n    tool.add_state('clear')\n\n    with pytest.raises(ValueError):\n        tool.add_state('clear')\n"], "sample_528": ["def test_use_blacklisted_param(tmpdir):\n    mpl.rcParams['interactive'] = False\n    temp_file = f'text.{STYLE_EXTENSION}'\n    path = Path(tmpdir, temp_file)\n    path.write_text('interactive: True', encoding='utf-8')\n    with style.context(path):\n        assert mpl.rcParams['interactive'] is False\n"], "sample_260": ["def test_create_model_alter_model_managers(self):\n    \"\"\"\n    AlterModelManagers should optimize into CreateModel.\n    \"\"\"\n    managers = [('objects', EmptyManager())]\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n                options={'verbose_name': 'Foo'},\n                bases=(UnicodeModel,),\n                managers=[],\n            ),\n            migrations.AlterModelManagers(\"Foo\", managers),\n        ],\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n                options={'verbose_name': 'Foo'},\n                bases=(UnicodeModel,),\n                managers=managers,\n            ),\n        ],\n    )\n"], "sample_860": ["def test_check_X_y():\n    # Test function for check_X_y\n    X = np.arange(10).reshape(5, 2)\n    y = np.arange(5)\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # Test with sparse matrix\n    X_sparse = sp.csr_matrix(X)\n    X_checked, y_checked = check_X_y(X_sparse, y)\n    assert_array_equal(X_checked.toarray(), X)\n    assert_array_equal(y_checked, y)\n\n    # Test with non-numeric y\n    y_non_numeric = np.array(['a', 'b', 'c', 'd', 'e'])\n    X_checked, y_checked = check_X_y(X, y_non_numeric)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y_non_numeric)\n\n    # Test with multi-output y\n    y_multi_output = np.arange(10).reshape(5, 2)\n    X_checked, y_checked = check_X_y(X, y_multi_output, multi_output=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y_multi_output)\n\n    # Test with inconsistent length\n    y_inconsistent = np.arange(3)\n    assert_raise_message(ValueError, \"Found input variables with inconsistent \"\n                         \"numbers of samples: \\[5, 3\\]\", check_X_y, X, y_inconsistent)\n\n    # Test with non-2D X\n    X_non_2d = np.arange(10)\n    assert_raise_message(ValueError, \"Expected 2D array, got 1D array instead\",\n                         check_X_y, X_non_2d, y)\n\n    # Test with non-1D y\n    y_non_1d = np.arange(10).reshape(5, 2)\n    assert_raise_message(ValueError, \"bad input shape \\(5, 2\\)\", check_X_y, X, y_non_1d)\n\n    # Test with non-finite values in X\n    X_non_finite = np.arange(10, dtype=float).reshape(5, 2)\n    X_non_finite[0, 0] = np.nan\n    assert_raise_message(ValueError, \"Input contains NaN, infinity or a value \"\n                         \"too large for.*float\", check_X_y, X_non_finite, y)\n\n    # Test with non-f"], "sample_1124": ["def test_FracElement_compose():\n    F, x,y,z = field(\"x,y,z\", ZZ)\n    f = (x**2 + 3*y)/z\n\n    raises(NotImplementedError, lambda: f.compose(x, y))\n    raises(NotImplementedError, lambda: f.compose([(x, y)]))\n"], "sample_93": ["def test_window_function(self):\n    # Test window function with a simple query\n    books = Book.objects.annotate(\n        rank=Window(expression=RowNumber(), order_by=F('rating').desc())\n    ).order_by('rating')\n    self.assertEqual(\n        list(books.values_list('name', 'rank')),\n        [\n            ('Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp', 1),\n            ('Artificial Intelligence: A Modern Approach', 2),\n            ('Python Web Development with Django', 3),\n            ('Practical Django Projects', 4),\n            ('The Definitive Guide to Django: Web Development Done Right', 5),\n            ('Sams Teach Yourself Django in 24 Hours', 6),\n        ]\n    )\n\n    # Test window function with a more complex query\n    books = Book.objects.annotate(\n        rank=Window(expression=RowNumber(), order_by=F('rating').desc(), partition_by=F('publisher'))\n    ).order_by('publisher', 'rating')\n    self.assertEqual(\n        list(books.values_list('name', 'publisher__name', 'rank')),\n        [\n            ('The Definitive Guide to Django: Web Development Done Right', 'Apress', 1),\n            ('Practical Django Projects', 'Apress', 2),\n            ('Sams Teach Yourself Django in 24 Hours', 'Sams', 1),\n            ('Python Web Development with Django', 'Prentice Hall', 1),\n            ('Artificial Intelligence: A Modern Approach', 'Prentice Hall', 2),\n            ('Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp', 'Morgan Kaufmann', 1),\n        ]\n    )\n\n    # Test window function with a frame\n    books = Book.objects.annotate(\n        sum_rating=Window(expression=Sum('rating'), order_by=F('rating').desc(), frame=RangeFrame())\n    ).order_by('rating')\n    self.assertEqual(\n        list(books.values_list('name', 'sum_rating')),\n        [\n            ('Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp', 5.0),\n            ('Artificial Intelligence: A Modern Approach', 9.0),\n            ('Python Web Development with Django', 13.0),\n            ('Practical Django Projects', 17.0),\n            ('The Definitive Guide to Django: Web Development Done Right', 21.5),\n            ('Sams Teach Yourself Django in 24"], "sample_509": ["def test_date2num_timezone():\n    # Test date2num with timezone-aware datetime objects\n    tz = dateutil.tz.gettz('US/Eastern')\n    dt = datetime.datetime(2022, 1, 1, tzinfo=tz)\n    expected = 19002.0\n    assert mdates.date2num(dt) == expected\n\n    # Test date2num with timezone-naive datetime objects\n    dt = datetime.datetime(2022, 1, 1)\n    assert mdates.date2num(dt) == expected\n\n    # Test date2num with numpy datetime64 objects\n    dt = np.datetime64('2022-01-01')\n    assert mdates.date2num(dt) == expected\n\n    # Test date2num with timezone-aware numpy datetime64 objects\n    dt = np.datetime64('2022-01-01', 'ns', 'US/Eastern')\n    assert mdates.date2num(dt) == expected\n"], "sample_687": ["def test_log_auto_indent(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            logger = logging.getLogger('catchlog')\n            logger.info(\"INFO message with\\\\nmultiline content\")\n            assert len(caplog.text.splitlines()) == 2\n            assert caplog.text.splitlines()[0].startswith(\"INFO\")\n            assert caplog.text.splitlines()[1].startswith(\"INFO\")\n\n            caplog.set_level(logging.INFO, logger=\"catchlog\")\n            logger.info(\"INFO message with\\\\nmultiline content\", extra={\"auto_indent\": True})\n            assert len(caplog.text.splitlines()) == 2\n            assert caplog.text.splitlines()[0].startswith(\"INFO\")\n            assert caplog.text.splitlines()[1].startswith(\" \" * 5)\n\n            caplog.set_level(logging.INFO, logger=\"catchlog\")\n            logger.info(\"INFO message with\\\\nmultiline content\", extra={\"auto_indent\": 3})\n            assert len(caplog.text.splitlines()) == 2\n            assert caplog.text.splitlines()[0].startswith(\"INFO\")\n            assert caplog.text.splitlines()[1].startswith(\" \" * 3)\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_level=WARNING\n        log_auto_indent=False\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    assert result.ret == 0\n"], "sample_494": ["def test_serialize_settings_reference(self):\n    self.assertSerializedResultEqual(\n        SettingsReference(\"AUTH_USER_MODEL\", \"AUTH_USER_MODEL\"),\n        (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"}),\n    )\n    self.assertSerializedResultEqual(\n        SettingsReference(\"someapp.model\", \"AUTH_USER_MODEL\"),\n        (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"}),\n    )\n    self.assertSerializedResultEqual(\n        SettingsReference(\"someapp.model\", \"NON_EXISTENT_SETTING\"),\n        (\"settings.NON_EXISTENT_SETTING\", {\"from django.conf import settings\"}),\n    )\n"], "sample_699": ["def test_doctest_report_choice_only_first_failure_multiple_failures(\n    pytester: Pytester,"], "sample_110": ["    def test_expression_pickle(self):\n        expression = Expression()\n        dumped = pickle.dumps(expression)\n        reloaded = pickle.loads(dumped)\n        self.assertEqual(expression.__class__, reloaded.__class__)\n"], "sample_834": ["def test_transform_after_fit():\n    \"\"\"Test that transform raises an error if fit has not been called.\"\"\"\n    nca = NeighborhoodComponentsAnalysis()\n    assert_raises_message(ValueError,\n                         'This NeighborhoodComponentsAnalysis instance is not '\n                         'fitted yet. Call 'fit' with appropriate arguments '\n                         'before using this method.',\n                         nca.transform, iris_data)\n"], "sample_256": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = ''\n        html = widget.render('name', value, {'id': 'id_password'})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_1178": ["def test_Element():\n    elem = Element(x, 'ijk')\n    assert elem.symbol == x\n    assert elem.indices == Tuple('i', 'j', 'k')\n    assert elem.strides == none\n    assert elem.offset == none\n    assert elem.func(*elem.args) == elem\n\n    elem2 = Element(x, 'ijk', strides='lmn', offset='o')\n    assert elem2.indices == Tuple('i', 'j', 'k')\n    assert elem2.strides == Tuple('l', 'm', 'n')\n    assert elem2.offset == 'o'\n    assert elem2.func(*elem2.args) == elem2\n\n    elem3 = Element(x, 'ijk', strides='lmn', offset='o')\n    assert elem2 == elem3\n    assert elem2 != elem\n"], "sample_473": ["    def test_create_request(self):\n        scope = {\n            \"type\": \"http\",\n            \"method\": \"GET\",\n            \"path\": \"/\",\n            \"headers\": [],\n            \"query_string\": \"\",\n            \"client\": [\"127.0.0.1\", 12345],\n            \"server\": [\"localhost\", 8000],\n        }\n        body_file = tempfile.SpooledTemporaryFile(max_size=1024, mode=\"w+b\")\n        handler = ASGIHandler()\n        request, error_response = handler.create_request(scope, body_file)\n        self.assertIsNotNone(request)\n        self.assertIsNone(error_response)\n"], "sample_33": ["def test_dtype_bytes_or_chars():\n    assert misc.dtype_bytes_or_chars(np.dtype('int8')) is None\n    assert misc.dtype_bytes_or_chars(np.dtype('float64')) is None\n    assert misc.dtype_bytes_or_chars(np.dtype('S5')) == 5\n    assert misc.dtype_bytes_or_chars(np.dtype('U5')) == 5\n"], "sample_361": ["def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            'Search for google.com/?q=! and see.',\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>! and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt! and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>! and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt, and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>, and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt. and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>. and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt; and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>; and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt! and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>! and see.'\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_837": ["def test_get_blas_info():\n    try:\n        blas_info = _get_blas_info()\n        assert 'macros' in blas_info\n        assert 'lib_dirs' in blas_info\n        assert 'cblas_libs' in blas_info\n    except ImportError:\n        # If scikit-learn is not installed, _get_blas_info will raise an ImportError\n        pass\n\n"], "sample_392": ["    def test_key_transforms(self):\n        obj = NullableJSONModel.objects.create(value={\"a\": {\"b\": {\"c\": \"d\"}}})\n        self.assertEqual(\n            NullableJSONModel.objects.filter(\n                value__a__b__c=\"d\",\n            ).get(),\n            obj,\n        )\n"], "sample_54": ["def test_file_from_disk_with_filename(self):\n    response = FileResponse(open(__file__, 'rb'), filename='test_file.py')\n    self.assertEqual(response['Content-Length'], str(os.path.getsize(__file__)))\n    self.assertIn(response['Content-Type'], ['text/x-python', 'text/plain'])\n    self.assertEqual(response['Content-Disposition'], 'inline; filename=\"test_file.py\"')\n    response.close()\n"], "sample_552": ["def test_subfigure_subplotspec():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    subfig = fig.add_subfigure(gs[0, 0])\n    assert subfig._subplotspec == gs[0, 0]\n    assert subfig._subplotspec.get_gridspec() == gs\n    assert subfig._subplotspec.get_topmost_subplotspec() == gs\n    assert subfig._subplotspec.get_position(fig) == gs[0, 0].get_position(fig)\n"], "sample_1139": ["def test_ComplexRegion_polar_intersect():\n    # Polar form\n    c1 = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)\n    c2 = ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    c3 = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi), polar=True)\n    c4 = ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n\n    p1 = Union(Interval(0, 1)*Interval(0, 2*S.Pi), Interval(0, 1)*Interval(0, S.Pi))\n    p2 = Union(Interval(0, oo)*Interval(0, S.Pi), Interval(0, oo)*Interval(S.Pi, 2*S.Pi))\n\n    assert c1.intersect(c2) == ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    assert c3.intersect(c4) == ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n\n    # Rectangular form\n    c5 = ComplexRegion(Interval(2, 5)*Interval(6, 9))\n    c6 = ComplexRegion(Interval(4, 6)*Interval(10, 12))\n    c7 = ComplexRegion(Interval(0, 10)*Interval(-10, 0))\n    c8 = ComplexRegion(Interval(12, 16)*Interval(14, 20))\n\n    p3 = Union(Interval(2, 5)*Interval(6, 9), Interval(4, 6)*Interval(10, 12))\n    p4 = Union(Interval(0, 10)*Interval(-10, 0), Interval(12, 16)*Interval(14, 20))\n\n    assert c5.intersect(c6) == ComplexRegion(Interval(4, 5)*Interval(10, 9), False)\n    assert c7.intersect(c8) == ComplexRegion(Interval(12, 10)*Interval(14, 0), False)\n\n    assert c1.intersect(Interval(2, 4)) == Intersection(c1, Interval(2, 4), evaluate=False)\n    assert c5.intersect(Interval"], "sample_870": ["def test_kernel_not_mutated():\n    \"\"\"Check that the input matrix X is not mutated by the diag method of the kernel.\"\"\"\n    X = np.array([[1, 2], [3, 4]])\n    kernel = CustomKernel()\n    kernel.diag(X)\n    assert_array_almost_equal(X, np.array([[1, 2], [3, 4]]))\n"], "sample_1021": ["def test_quaternion_edge_cases():\n    q1 = Quaternion(0, 0, 0, 0)\n    q2 = Quaternion(1, 0, 0, 0)\n    q3 = Quaternion(0, 1, 0, 0)\n    q4 = Quaternion(0, 0, 1, 0)\n    q5 = Quaternion(0, 0, 0, 1)\n\n    assert q1.norm() == 0\n    assert q2.norm() == 1\n    assert q3.norm() == 1\n    assert q4.norm() == 1\n    assert q5.norm() == 1\n\n    assert q1.normalize() == Quaternion(0, 0, 0, 0)\n    assert q2.normalize() == Quaternion(1, 0, 0, 0)\n    assert q3.normalize() == Quaternion(0, 1, 0, 0)\n    assert q4.normalize() == Quaternion(0, 0, 1, 0)\n    assert q5.normalize() == Quaternion(0, 0, 0, 1)\n\n    assert q1.inverse() == Quaternion(0, 0, 0, 0)\n    raises(ValueError, lambda: q1.inverse())\n\n    assert q2.pow(0) == Quaternion(1, 0, 0, 0)\n    assert q2.pow(1) == Quaternion(1, 0, 0, 0)\n    assert q2.pow(-1) == Quaternion(1, 0, 0, 0)\n\n    assert q2.exp() == Quaternion(E, 0, 0, 0)\n    assert q2._ln() == Quaternion(0, 0, 0, 0)\n\n    assert q2.pow_cos_sin(0) == Quaternion(1, 0, 0, 0)\n    assert q2.pow_cos_sin(1) == Quaternion(1, 0, 0, 0)\n    assert q2.pow_cos_sin(-1) == Quaternion(1, 0, 0, 0)\n\n    assert Quaternion.rotate_point((0, 0, 0), q2) == (0, 0, 0)\n    assert Quaternion.rotate_point((1, 1, 1), q2) == (1, 1, 1)\n\n    assert q2.to"], "sample_862": ["def test_vectorizer_stop_words_consistency():\n    # Test that stop words are consistent with the preprocessor and tokenizer\n    # when using a custom analyzer\n    class CustomAnalyzer:\n            return [doc.lower()]\n\n    vec = CountVectorizer(analyzer=CustomAnalyzer(), stop_words=['AND'])\n    assert _check_stop_words_consistency(vec) is True\n\n    vec = CountVectorizer(analyzer=CustomAnalyzer(), stop_words=['and'])\n    assert _check_stop_words_consistency(vec) is False\n"], "sample_1080": ["def test_refine():\n    assert refine(x**2, Q.real(x)) == x**2\n    assert refine(x**2, Q.positive(x)) == x**2\n    assert refine(x**2, Q.negative(x)) == x**2\n    assert refine(x**2, Q.imaginary(x)) == x**2\n    assert refine(x**2, Q.complex(x)) == x**2\n\n    assert refine(x**3, Q.real(x)) == x**3\n    assert refine(x**3, Q.positive(x)) == x**3\n    assert refine(x**3, Q.negative(x)) == -x**3\n    assert refine(x**3, Q.imaginary(x)) == -I*x**3\n    assert refine(x**3, Q.complex(x)) == x**3\n\n    assert refine(x**4, Q.real(x)) == x**4\n    assert refine(x**4, Q.positive(x)) == x**4\n    assert refine(x**4, Q.negative(x)) == x**4\n    assert refine(x**4, Q.imaginary(x)) == x**4\n    assert refine(x**4, Q.complex(x)) == x**4\n\n    assert refine(x**5, Q.real(x)) == x**5\n    assert refine(x**5, Q.positive(x)) == x**5\n    assert refine(x**5, Q.negative(x)) == -x**5\n    assert refine(x**5, Q.imaginary(x)) == I*x**5\n    assert refine(x**5, Q.complex(x)) == x**5\n"], "sample_868": ["def test_empty_input(metric_name, y1, y2):\n    metric = SUPERVISED_METRICS[metric_name]\n    with pytest.raises(ValueError):\n        metric([], y2)\n    with pytest.raises(ValueError):\n        metric(y1, [])\n"], "sample_516": ["def test_pdf_metadata_decimal():\n    pikepdf = pytest.importorskip('pikepdf')\n\n    fig, ax = plt.subplots()\n    ax.plot(range(5))\n\n    md = {\n        'Author': 'me',\n        'Title': 'Multipage PDF',\n        'Subject': 'Test page',\n        'Keywords': 'test,pdf,multipage',\n        'ModDate': decimal.Decimal('1968.08.01'),\n        'Trapped': 'True'\n    }\n    buf = io.BytesIO()\n    fig.savefig(buf, metadata=md, format='pdf')\n\n    with pikepdf.Pdf.open(buf) as pdf:\n        info = {k: str(v) for k, v in pdf.docinfo.items()}\n\n    assert info == {\n        '/Author': 'me',\n        '/CreationDate': 'D:19700101000000Z',\n        '/Creator': f'Matplotlib v{mpl.__version__}, https://matplotlib.org',\n        '/Keywords': 'test,pdf,multipage',\n        '/ModDate': 'D:19680801000000Z',\n        '/Producer': f'Matplotlib pdf backend v{mpl.__version__}',\n        '/Subject': 'Test page',\n        '/Title': 'Multipage PDF',\n        '/Trapped': '/True',\n    }\n"], "sample_757": ["def test_ordinal_encoder_unsorted_categories():\n    X = np.array([['a', 'b']], dtype=object).T\n\n    enc = OrdinalEncoder(categories=[['b', 'a', 'c']])\n    exp = np.array([[1.], [0.]])\n    assert_array_equal(enc.fit(X).transform(X), exp)\n    assert_array_equal(enc.fit_transform(X), exp)\n    assert enc.categories_[0].tolist() == ['b', 'a', 'c']\n    assert np.issubdtype(enc.categories_[0].dtype, np.object_)\n\n    # unsorted passed categories still raise for numerical values\n    X = np.array([[1, 2]]).T\n    enc = OrdinalEncoder(categories=[[2, 1, 3]])\n    msg = 'Unsorted categories are not supported'\n    with pytest.raises(ValueError, match=msg):\n        enc.fit_transform(X)\n"], "sample_816": ["def test_vectorizer_stop_words_inconsistent_with_custom_tokenizer():\n    lstr = \"['and', 'll', 've']\"\n    message = ('Your stop_words may be inconsistent with your '\n               'preprocessing. Tokenizing the stop words generated '\n               'tokens %s not in stop_words.' % lstr)\n    for vec in [CountVectorizer(),\n                TfidfVectorizer(), HashingVectorizer()]:\n        vec.set_params(stop_words=[\"you've\", \"you\", \"you'll\", 'AND'],\n                       tokenizer=lambda doc: re.compile(r'\\w{1,}').findall(doc))\n        assert_warns_message(UserWarning, message, vec.fit_transform,\n                             ['hello world'])\n        # reset stop word validation\n        del vec._stop_words_id\n        assert _check_stop_words_consistency(vec) is False\n\n    # Only one warning per stop list\n    assert_no_warnings(vec.fit_transform, ['hello world'])\n    assert _check_stop_words_consistency(vec) is None\n\n    # Test caching of inconsistency assessment\n    vec.set_params(stop_words=[\"you've\", \"you\", \"you'll\", 'blah', 'AND'])\n    assert_warns_message(UserWarning, message, vec.fit_transform,\n                         ['hello world'])\n"], "sample_1008": ["def test_orient():\n    q1, q2, q3, q4 = dynamicsymbols('q1 q2 q3 q4')\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    B = ReferenceFrame('B')\n    C = ReferenceFrame('C')\n    D = ReferenceFrame('D')\n\n    A.orient(N, 'Axis', [q1, N.z])\n    B.orient(A, 'Axis', [q2, A.x])\n    C.orient(B, 'Axis', [q3, B.y])\n    D.orient(N, 'Axis', [q4, N.y])\n\n    assert A.ang_vel_in(N) == q1d*N.z\n    assert B.ang_vel_in(N) == q1d*N.z + q2d*A.x\n    assert C.ang_vel_in(N) == q1d*N.z + q2d*A.x + q3d*B.y\n    assert D.ang_vel_in(N) == q4d*N.y\n\n    A.orient(N, 'Body', [q1, q2, q3], '123')\n    B.orient(A, 'Body', [q1, q2, q3], '123')\n    C.orient(B, 'Body', [q1, q2, q3], '123')\n    D.orient(N, 'Body', [q1, q2, q3], '123')\n\n    assert A.ang_vel_in(N) == (sin(q2)*sin(q3)*q1d + cos(q3)*q2d)*A.x + \\\n        (sin(q2)*cos(q3)*q1d - sin(q3)*q2d)*A.y + (cos(q2)*q1d + q3d)*A.z\n    assert B.ang_vel_in(N) == (sin(q2)*sin(q3)*q1d + cos(q3)*q2d)*B.x + \\\n        (sin(q2)*cos(q3)*q1d - sin(q3)*q2d)*B.y + (cos(q2)*q1d + q3d)*B.z\n    assert C.ang_vel_in(N) == (sin(q2)*sin(q3)*q1d + cos(q3)*q2d)*C.x + \\\n        (sin(q2)*cos(q3)*q1d - sin(q3)*q"], "sample_84": ["    def test_fields_limit(self):\n        with self.assertRaises(TooManyFieldsSent):\n            limited_parse_qsl('a=1&b=2&c=3', fields_limit=2)\n"], "sample_1134": ["def test_latex_tensor_indices():\n    from sympy.tensor.tensor import TensorIndexType, tensor_indices, TensorHead, tensor_heads\n    L = TensorIndexType(\"L\")\n    i, j, k, l = tensor_indices(\"i j k l\", L)\n    i0 = tensor_indices(\"i_0\", L)\n    A, B, C, D = tensor_heads(\"A B C D\", [L])\n    H = TensorHead(\"H\", [L, L])\n    K = TensorHead(\"K\", [L, L, L, L])\n\n    assert latex(i) == \"{}^{i}\"\n    assert latex(-i) == \"{}_{i}\"\n\n    expr = A(i)\n    assert latex(expr) == \"A{}^{i}\"\n\n    expr = A(i0)\n    assert latex(expr) == \"A{}^{i_{0}}\"\n\n    expr = A(-i)\n    assert latex(expr) == \"A{}_{i}\"\n\n    expr = -3*A(i)\n    assert latex(expr) == r\"-3A{}^{i}\"\n\n    expr = K(i, j, -k, -i0)\n    assert latex(expr) == \"K{}^{ij}{}_{ki_{0}}\"\n\n    expr = K(i, -j, -k, i0)\n    assert latex(expr) == \"K{}^{i}{}_{jk}{}^{i_{0}}\"\n\n    expr = K(i, -j, k, -i0)\n    assert latex(expr) == \"K{}^{i}{}_{j}{}^{k}{}_{i_{0}}\"\n\n    expr = H(i, -j)\n    assert latex(expr) == \"H{}^{i}{}_{j}\"\n\n    expr = H(i, j)\n    assert latex(expr) == \"H{}^{ij}\"\n\n    expr = H(-i, -j)\n    assert latex(expr) == \"H{}_{ij}\"\n\n    expr = (1+x)*A(i)\n    assert latex(expr) == r\"\\left(x + 1\\right)A{}^{i}\"\n\n    expr = H(i, -i)\n    assert latex(expr) == \"H{}^{L_{0}}{}_{L_{0}}\"\n\n    expr = H(i, -j)*A(j)*B(k)\n    assert latex(expr) == \"H{}^{i}{}_{L_{0}}A{}^{L_{0}}B{}^{k}\"\n\n    expr"], "sample_720": ["def test_power_transformer_copy():\n    X = np.abs(X_2d)\n\n    pt = PowerTransformer(method='box-cox', copy=True)\n    X_trans = pt.fit_transform(X)\n    assert_true(X_trans is not X)\n\n    pt = PowerTransformer(method='box-cox', copy=False)\n    X_trans = pt.fit_transform(X)\n    assert_true(X_trans is X)\n"], "sample_255": ["def test_handle_one_request(self):\n    request = WSGIRequest(self.request_factory.get('/').environ)\n    request.makefile = lambda *args, **kwargs: BytesIO()\n    handler = WSGIRequestHandler(request, '192.168.0.2', None)\n    handler.close_connection = False\n\n        start_response('200 OK', [])\n        return [b'']\n\n    handler.server = Stub()\n    handler.server.get_app = lambda: test_app\n    handler.handle_one_request()\n    self.assertTrue(handler.close_connection)\n\n    handler.close_connection = False\n    handler.raw_requestline = b'GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n'\n    handler.handle_one_request()\n    self.assertTrue(handler.close_connection)\n\n    handler.close_connection = False\n    handler.raw_requestline = b'GET / HTTP/1.1\\r\\nHost: example.com\\r\\nConnection: keep-alive\\r\\n\\r\\n'\n    handler.handle_one_request()\n    self.assertFalse(handler.close_connection)\n"], "sample_730": ["def test_enet_path_with_sparse_X():\n    # Test that enet_path with sparse X gives the same result as with dense X\n    X, y, _, _ = build_dataset(n_samples=50, n_features=20)\n    X_sparse = sparse.csr_matrix(X)\n    alphas, coefs, _ = enet_path(X, y, fit_intercept=False)\n    alphas_sparse, coefs_sparse, _ = enet_path(X_sparse, y, fit_intercept=False)\n    assert_array_almost_equal(coefs, coefs_sparse)\n"], "sample_24": ["    def test_inv(self):\n        self.check(np.linalg.inv)\n"], "sample_704": ["def test_node_repr_failure(pytester: Pytester) -> None:\n    items = pytester.getitems(\n        \"\"\"\n            raise ValueError(\"some message\")\n    \"\"\"\n    )\n    item = items[0]\n    excinfo = pytest.raises(ValueError, item.runtest)\n    assert isinstance(item.repr_failure(excinfo), str)\n"], "sample_1070": ["def test_exp_polar():\n    x, y = symbols('x y', polar=True)\n    z = symbols('z')\n\n    assert exp_polar(x).is_polar is True\n    assert exp_polar(x).is_comparable is False\n\n    assert exp_polar(0) == exp_polar(0)\n    assert exp_polar(2) == exp_polar(2)\n    assert exp_polar(I) == exp_polar(I)\n    assert exp_polar(2 + 3*I) == exp_polar(2 + 3*I)\n\n    assert exp_polar(x).as_numer_denom() == (exp_polar(x), 1)\n    assert exp_polar(-x).as_numer_denom() == (1, exp_polar(x))\n    assert exp_polar(-2*x).as_numer_denom() == (1, exp_polar(2*x))\n    assert exp_polar(-2).as_numer_denom() == (1, exp_polar(2))\n    assert exp_polar(-I*x).as_numer_denom() == (1, exp_polar(I*x))\n    assert exp_polar(-I*2).as_numer_denom() == (1, exp_polar(I*2))\n\n    assert exp_polar(x).as_base_exp() == (exp_polar(1), x)\n    assert exp_polar(2*x).as_base_exp() == (exp_polar(1), 2*x)\n    assert exp_polar(x*y).as_base_exp() == (exp_polar(1), x*y)\n    assert exp_polar(-x).as_base_exp() == (exp_polar(1), -x)\n\n    assert exp_polar(x).exp == x\n    assert exp_polar(2*x).exp == 2*x\n    assert exp_polar(x*y).exp == x*y\n    assert exp_polar(-x).exp == -x\n\n    assert exp_polar(x)._eval_conjugate() == exp_polar(conjugate(x))\n\n    assert exp_polar(x)._eval_is_finite() == x.is_finite\n    assert exp_polar(2)._eval_is_finite() == True\n    assert exp_polar(I)._eval_is_finite() == True\n    assert exp_polar(oo)._eval_is_finite() == False\n    assert exp_polar(-oo)._eval_is_finite() == False\n\n    assert exp"], "sample_257": ["    def test_key_transform_factory(self):\n        field = models.JSONField()\n        transform = field.get_transform('key')\n        self.assertIsInstance(transform, KeyTransformFactory)\n        self.assertEqual(transform.key_name, 'key')\n"], "sample_41": ["def test_compose_with_dimensionless():\n    \"\"\"\n    Test that composing a unit with a dimensionless unit does not\n    change the result.\n    \"\"\"\n    unit = u.m\n    dimensionless = u.dimensionless_unscaled\n    composed = unit.compose()\n    composed_with_dimensionless = (unit * dimensionless).compose()\n    assert composed == composed_with_dimensionless\n"], "sample_129": ["    def test_addslashes(self):\n        self.assertEqual(addslashes('Hello \"World\"'), 'Hello \\\\\"World\\\"')\n        self.assertEqual(addslashes(\"Hello 'World'\"), \"Hello \\\\'World\\'\")\n"], "sample_244": ["def test_formset_absolute_max_with_min_num(self):\n    data = {\n        'form-TOTAL_FORMS': '1001',\n        'form-INITIAL_FORMS': '0',\n        'form-MAX_NUM_FORMS': '0',\n    }\n    LimitedFavoriteDrinksFormSet = formset_factory(\n        FavoriteDrinkForm,\n        min_num=30,\n        absolute_max=1000,\n    )\n    formset = LimitedFavoriteDrinksFormSet(data=data)\n    self.assertIs(formset.is_valid(), False)\n    self.assertEqual(len(formset.forms), 1000)\n    self.assertEqual(\n        formset.non_form_errors(),\n        ['Please submit at least 30 forms.'],\n    )\n"], "sample_48": ["def test_stddev_sample_population(self):\n    # Test StdDev with sample and population parameters\n    vals = Book.objects.aggregate(stddev_sample=StdDev('rating', sample=True))\n    self.assertEqual(vals, {'stddev_sample': Approximate(0.59, places=2)})\n\n    vals = Book.objects.aggregate(stddev_population=StdDev('rating', sample=False))\n    self.assertEqual(vals, {'stddev_population': Approximate(0.55, places=2)})\n\n    vals = Book.objects.aggregate(stddev_sample=StdDev('rating', sample=True), stddev_population=StdDev('rating', sample=False))\n    self.assertEqual(vals, {'stddev_sample': Approximate(0.59, places=2), 'stddev_population': Approximate(0.55, places=2)})\n"], "sample_371": ["    def test_get_traceback_frames_with_cyclic_reference(self):\n        \"\"\"\n        Test that ExceptionReporter.get_traceback_frames() handles cyclic references.\n        \"\"\"\n        try:\n                try:\n                    raise RuntimeError('outer') from RuntimeError('inner')\n                except RuntimeError as exc:\n                    raise exc.__cause__\n            test_func()\n        except Exception:\n            exc_type, exc_value, tb = sys.exc_info()\n        request = self.rf.get('/test_view/')\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n\n            nonlocal tb_frames\n            tb_frames = reporter.get_traceback_frames()\n\n        tb_frames = None\n        tb_generator = threading.Thread(target=generate_traceback_frames, daemon=True)\n        msg = (\n            \"Cycle in the exception chain detected: exception 'inner' \"\n            \"encountered again.\"\n        )\n        with self.assertWarnsMessage(ExceptionCycleWarning, msg):\n            tb_generator.start()\n        tb_generator.join(timeout=5)\n        if tb_generator.is_alive():\n            # tb_generator is a daemon that runs until the main thread/process\n            # exits. This is resource heavy when running the full test suite.\n            # Setting the following values to None makes\n            # reporter.get_traceback_frames() exit early.\n            exc_value.__traceback__ = exc_value.__context__ = exc_value.__cause__ = None\n            tb_generator.join()\n            self.fail('Cyclic reference in Exception Reporter.get_traceback_frames()')\n        if tb_frames is None:\n            # can happen if the thread generating traceback got killed\n            # or exception while generating the traceback\n            self.fail('Traceback generation failed')\n        last_frame = tb_frames[-1]\n        self.assertIn('raise exc.__cause__', last_frame['context_line'])\n        self.assertEqual(last_frame['filename'], __file__)\n        self.assertEqual(last_frame['function'], 'test_func')\n"], "sample_1113": ["def test_block_collapse():\n    n, m, l = symbols('n m l')\n    X = MatrixSymbol('X', n, n)\n    Y = MatrixSymbol('Y', m, m)\n    Z = MatrixSymbol('Z', n, m)\n    B = BlockMatrix([[X, Z], [ZeroMatrix(m, n), Y]])\n    C = BlockMatrix([[Identity(n), Z]])\n    assert block_collapse(C*B) == BlockMatrix([[X, Z + Z*Y]])\n    assert block_collapse(B*C) == BlockMatrix([[X, Z], [Z*X + Y*Z, Z*Z + Y**2]])\n"], "sample_624": ["def test_unindexed_dims_repr() -> None:\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3])}\n    expected = \"Dimensions without coordinates: y, z\"\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3]), \"y\": np.array([4, 5, 6])}\n    expected = \"Dimensions without coordinates: z\"\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3]), \"y\": np.array([4, 5, 6]), \"z\": np.array([7, 8, 9])}\n    expected = None\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n"], "sample_9": ["def test_html_writer_css():\n    \"\"\"\n    Test to make sure that the HTML writer includes CSS styling\n    if the 'css' parameter is present in the htmldict.\n    \"\"\"\n\n    col1 = [1, 2, 3]\n    col2 = [(1.0, 1.0), (2.0, 2.0), (3.0, 3.0)]\n    col3 = [('a', 'a', 'a'), ('b', 'b', 'b'), ('c', 'c', 'c')]\n    table = Table([col1, col2, col3], names=('C1', 'C2', 'C3'))\n    css = 'table { border-collapse: collapse; } th, td { border: 1px solid black; }'\n    expected = \"\"\"\\"], "sample_217": ["def test_multiwidget_media(self):\n    class MyWidget1(TextInput):\n        class Media:\n            css = {\n                'all': ('path/to/css1', '/path/to/css2')\n            }\n            js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')\n\n    class MyWidget2(TextInput):\n        class Media:\n            css = {\n                'all': ('/path/to/css2', '/path/to/css3')\n            }\n            js = ('/path/to/js1', '/path/to/js4')\n\n    class MyWidget3(TextInput):\n        class Media:\n            css = {\n                'all': ('path/to/css1', '/path/to/css3')\n            }\n            js = ('/path/to/js1', '/path/to/js4')\n\n    class MyMultiWidget(MultiWidget):\n            widgets = [MyWidget1, MyWidget2, MyWidget3]\n            super().__init__(widgets, attrs)\n\n    mymulti = MyMultiWidget()\n    self.assertEqual(\n        str(mymulti.media),\n        \"\"\"<link href=\"http://media.example.com/static/path/to/css1\" type=\"text/css\" media=\"all\" rel=\"stylesheet\">"], "sample_176": ["def test_alter_field_to_m2m(self):\n    \"\"\"\n    #23938 - Changing a concrete field into a ManyToManyField\n    first removes the concrete field and then adds the m2m field.\n    \"\"\"\n    changes = self.get_changes([self.author_with_former_m2m], [self.author_with_m2m, self.publisher])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\", \"RemoveField\", \"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Publisher')\n    self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"publishers\", model_name='author')\n    self.assertOperationAttributes(changes, 'testapp', 0, 2, name=\"publishers\", model_name='author')\n"], "sample_380": ["def test_aggregate_default_with_distinct(self):\n    result = Book.objects.filter(rating__lt=3.0).aggregate(\n        value=Sum('price', distinct=True, default=Decimal('0.00')),\n    )\n    self.assertEqual(result['value'], Decimal('0.00'))\n\n    result = Book.objects.aggregate(\n        value=Sum('price', distinct=True, default=Decimal('0.00')),\n    )\n    self.assertEqual(result['value'], Decimal('270.27'))\n"], "sample_551": ["def test_patch_2d_to_3d():\n    # Test conversion of 2D patches to 3D patches\n    fig, ax = plt.subplots(subplot_kw=dict(projection='3d'))\n    patch = plt.Circle((0.5, 0.5), 0.2, edgecolor='black', facecolor='blue')\n    ax.add_patch(patch)\n    art3d.patch_2d_to_3d(patch, z=0.5, zdir='z')\n    assert patch.get_z() == 0.5\n    assert patch.get_3d_properties()[1] == 'z'\n\n    # Test conversion of 2D path patches to 3D path patches\n    fig, ax = plt.subplots(subplot_kw=dict(projection='3d'))\n    path = mpath.Path([(0, 0), (1, 0), (1, 1), (0, 1), (0, 0)],\n                      [mpath.Path.MOVETO, mpath.Path.LINETO, mpath.Path.LINETO,\n                       mpath.Path.LINETO, mpath.Path.CLOSEPOLY])\n    patch = mpatches.PathPatch(path, edgecolor='black', facecolor='blue')\n    ax.add_patch(patch)\n    art3d.pathpatch_2d_to_3d(patch, z=0.5, zdir='z')\n    assert patch.get_z() == 0.5\n    assert patch.get_3d_properties()[1] == 'z'\n"], "sample_223": ["    def setUpTestData(cls):\n        cls.i1 = Individual.objects.create(alive=True)\n        cls.i2 = Individual.objects.create(alive=False)\n        cls.i3 = Individual.objects.create(alive=True)\n        cls.i4 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=cls.i1)\n        RelatedIndividual.objects.create(related=cls.i2)\n"], "sample_155": ["def test_file_from_disk_with_filename(self):\n    response = FileResponse(open(__file__, 'rb'), filename='custom_filename.py')\n    self.assertEqual(response['Content-Length'], str(os.path.getsize(__file__)))\n    self.assertIn(response['Content-Type'], ['text/x-python', 'text/plain'])\n    self.assertEqual(response['Content-Disposition'], 'inline; filename=\"custom_filename.py\"')\n    response.close()\n"], "sample_545": ["def test_subfigure_subplotspec():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    subfig = fig.add_subfigure(gs[0, 0])\n    ax = subfig.add_subplot(111)\n    assert ax.get_subplotspec().get_gridspec() is subfig._subplotspec.get_gridspec()\n"], "sample_199": ["def test_annotation_with_window_function(self):\n    books = Book.objects.annotate(\n        row_number=Window(\n            expression=RowNumber(),\n            partition_by=F('publisher'),\n            order_by=F('pubdate').desc(),\n        ),\n    ).order_by('publisher', '-pubdate')\n\n    prev_row_number = 0\n    prev_publisher = None\n    for book in books:\n        if book.publisher != prev_publisher:\n            self.assertEqual(book.row_number, 1)\n            prev_row_number = 1\n        else:\n            self.assertEqual(book.row_number, prev_row_number + 1)\n            prev_row_number += 1\n        prev_publisher = book.publisher\n"], "sample_740": ["def test_check_X_y_force_all_finite_valid():\n    # Test that check_X_y correctly handles force_all_finite\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([1, 2])\n    X_checked, y_checked = check_X_y(X, y, force_all_finite=True)\n    assert_array_equal(X, X_checked)\n    assert_array_equal(y, y_checked)\n\n    X = np.array([[1, 2], [3, np.nan]])\n    y = np.array([1, 2])\n    X_checked, y_checked = check_X_y(X, y, force_all_finite='allow-nan')\n    assert_array_equal(X, X_checked)\n    assert_array_equal(y, y_checked)\n\n    X = np.array([[1, 2], [3, np.inf]])\n    y = np.array([1, 2])\n    with pytest.raises(ValueError):\n        check_X_y(X, y, force_all_finite=True)\n\n    X = np.array([[1, 2], [3, np.nan]])\n    y = np.array([1, 2])\n    with pytest.raises(ValueError):\n        check_X_y(X, y, force_all_finite=True)\n\n    X = np.array([[1, 2], [3, np.inf]])\n    y = np.array([1, 2])\n    with pytest.raises(ValueError):\n        check_X_y(X, y, force_all_finite='allow-nan')\n"], "sample_424": ["def test_alter_field_with_func_unique_constraint_and_index(self):\n    app_label = \"test_alfuncucin\"\n    constraint_name = f\"{app_label}_pony_uq\"\n    index_name = f\"{app_label}_pony_idx\"\n    table_name = f\"{app_label}_pony\"\n    project_state = self.set_up_test_model(\n        app_label,\n        constraints=[\n            models.UniqueConstraint(\"pink\", \"weight\", name=constraint_name)\n        ],\n        indexes=[models.Index(Abs(\"pink\"), name=index_name)],\n    )\n    operation = migrations.AlterField(\n        \"Pony\", \"pink\", models.IntegerField(null=True)\n    )\n    new_state = project_state.clone()\n    operation.state_forwards(app_label, new_state)\n    with connection.schema_editor() as editor:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    if connection.features.supports_expression_indexes:\n        self.assertIndexNameExists(table_name, index_name)\n    with connection.schema_editor() as editor:\n        operation.database_backwards(app_label, editor, new_state, project_state)\n    if connection.features.supports_expression_indexes:\n        self.assertIndexNameExists(table_name, index_name)\n"], "sample_875": ["def test_jaccard_score_multilabel_with_sample_weight():\n    # Test jaccard_score with sample_weight for multilabel-indicator case\n    y_true = np.array([[1, 0, 1], [0, 1, 0], [1, 1, 0]])\n    y_pred = np.array([[1, 0, 0], [0, 1, 1], [0, 0, 1]])\n    sample_weight = np.array([2, 1, 3])\n\n    # size(y1 \\inter y2) = [1, 1, 1]\n    # size(y1 \\union y2) = [2, 2, 2]\n\n    assert jaccard_score(y_true, y_pred, average=\"samples\", sample_weight=sample_weight) == 1.0 / 2\n    assert jaccard_score(y_true, y_true, average=\"samples\", sample_weight=sample_weight) == 1.0\n    assert jaccard_score(y_pred, y_pred, average=\"samples\", sample_weight=sample_weight) == 1.0\n    assert jaccard_score(y_pred, np.logical_not(y_pred), average=\"samples\", sample_weight=sample_weight) == 0.0\n    assert jaccard_score(y_true, np.logical_not(y_true), average=\"samples\", sample_weight=sample_weight) == 0.0\n    assert jaccard_score(y_true, np.zeros(y_true.shape), average=\"samples\", sample_weight=sample_weight) == 0.0\n    assert jaccard_score(y_pred, np.zeros(y_true.shape), average=\"samples\", sample_weight=sample_weight) == 0.0\n"], "sample_1054": ["def test_ComplexRegion_polar_intersect():\n    # Polar form\n    unit_disk = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)\n    upper_half_unit_disk = ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    upper_half_disk = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi), polar=True)\n    lower_half_disk = ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n    right_half_disk = ComplexRegion(Interval(0, oo)*Interval(-S.Pi/2, S.Pi/2), polar=True)\n    first_quad_disk = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi/2), polar=True)\n\n    assert upper_half_disk.intersect(unit_disk) == upper_half_unit_disk\n    assert right_half_disk.intersect(first_quad_disk) == first_quad_disk\n    assert upper_half_disk.intersect(right_half_disk) == first_quad_disk\n    assert upper_half_disk.intersect(lower_half_disk) == ComplexRegion(Interval(0, oo)*FiniteSet(0, S.Pi), polar=True)\n\n    c1 = ComplexRegion(Interval(0, 4)*Interval(0, 2*S.Pi), polar=True)\n    assert c1.intersect(Interval(1, 5)) == Interval(1, 4)\n    assert c1.intersect(Interval(4, 9)) == FiniteSet(4)\n    assert c1.intersect(Interval(5, 12)) is S.EmptySet\n\n    # Rectangular form\n    X_axis = ComplexRegion(Interval(-oo, oo)*FiniteSet(0))\n\n    unit_square = ComplexRegion(Interval(-1, 1)*Interval(-1, 1))\n    upper_half_unit_square = ComplexRegion(Interval(-1, 1)*Interval(0, 1))\n    upper_half_plane = ComplexRegion(Interval(-oo, oo)*Interval(0, oo))\n    lower_half_plane = ComplexRegion(Interval(-oo, oo)*Interval(-oo, 0))\n    right_half_plane = ComplexRegion(Interval(0, oo)*Interval(-oo, oo))\n    first_quad_plane = ComplexRegion(Interval(0, oo)*Interval(0, oo))\n\n    assert upper_half_plane.intersect(unit_square) == upper"], "sample_208": ["def test_alter_field_to_fk_dependency_same_app(self):\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author_fk],\n        [self.author_empty, self.book],\n    )\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [('otherapp', '__first__')])\n"], "sample_1022": ["def test_repeated_decimals():\n    transformations = standard_transformations + (convert_xor,)\n    cases = {\n        '0.2[1]': '19/90',\n        '0.2[12]': '221/999',\n        '0.2[123]': '246913/999999',\n        '0.2[1234]': '2469139/9999999',\n        '0.2[12345]': '24691379/99999999',\n        '0.2[123456]': '246913789/999999999',\n        '0.2[1234567]': '2469137891/9999999999',\n        '0.2[12345678]': '24691378913/99999999999',\n        '0.2[123456789]': '246913789139/999999999999',\n        '0.2[1234567890]': '2469137891399/9999999999999',\n        '0.2[12345678901]': '24691378913999/99999999999999',\n        '0.2[123456789012]': '246913789139999/999999999999999',\n        '0.2[1234567890123]': '2469137891399999/9999999999999999',\n        '0.2[12345678901234]': '24691378913999999/99999999999999999',\n        '0.2[123456789012345]': '246913789139999999/999999999999999999',\n        '0.2[1234567890123456]': '2469137891399999999/9999999999999999999',\n        '0.2[12345678901234567]': '24691378913999999999/99999999999999999999',\n        '0.2[123456789012345678]': '246913789139999999999/999999999999999999999',\n        '0.2[1234567890123456789]': '2469137891399999999999/9999999999999999999999',\n        '0.2[12345678901234567890]': '24691378913999999999999/99999999999999999999999',\n"], "sample_101": ["    def test_get_path_info(self):\n        environ = {'PATH_INFO': b'/path/to/resource'}\n        self.assertEqual(get_path_info(environ), '/path/to/resource')\n"], "sample_775": ["def test_indent_at_name():\n    # Test the indent_at_name parameter\n    pp = _EstimatorPrettyPrinter(indent=4, indent_at_name=True)\n    lr = LogisticRegression()\n    expected = \"\"\""], "sample_144": ["def test_model_inheritance_with_deferred_fields(self):\n    \"\"\"\n    Regression test for #12345\n    \"\"\"\n    # Create a child-parent-grandparent chain\n    place1 = Place(name=\"Guido's House of Pasta\", address='944 W. Fullerton')\n    place1.save_base(raw=True)\n    restaurant = Restaurant(\n        place_ptr=place1,\n        serves_hot_dogs=True,\n        serves_pizza=False,\n    )\n    restaurant.save_base(raw=True)\n    italian_restaurant = ItalianRestaurant(restaurant_ptr=restaurant, serves_gnocchi=True)\n    italian_restaurant.save_base(raw=True)\n\n    # Test that deferred fields are correctly loaded\n    italian_restaurant_deferred = ItalianRestaurant.objects.defer('serves_gnocchi').get(pk=italian_restaurant.pk)\n    self.assertEqual(italian_restaurant_deferred.serves_gnocchi, True)\n\n    # Test that deferred fields are correctly loaded when accessing parent objects\n    restaurant_deferred = italian_restaurant_deferred.restaurant_ptr\n    self.assertEqual(restaurant_deferred.serves_hot_dogs, True)\n    self.assertEqual(restaurant_deferred.serves_pizza, False)\n\n    # Test that deferred fields are correctly loaded when accessing grandparent objects\n    place_deferred = restaurant_deferred.place_ptr\n    self.assertEqual(place_deferred.name, \"Guido's House of Pasta\")\n    self.assertEqual(place_deferred.address, '944 W. Fullerton')\n"], "sample_188": ["    def test_window_frame(self):\n        # Test that the window frame is correctly generated.\n        window = Window(expression=Sum('num_employees'), partition_by='num_chairs', order_by='num_employees')\n        self.assertEqual(str(window), 'SUM(num_employees) OVER (PARTITION BY num_chairs ORDER BY num_employees)')\n"], "sample_322": ["    def test_detect_soft_applied_add_field_non_manytomanyfield(self):\n        \"\"\"\n        executor.detect_soft_applied() detects non-ManyToManyField tables from an\n        AddField operation.\n        \"\"\"\n        executor = MigrationExecutor(connection)\n        # Create the tables for 0001 but make it look like the migration hasn't\n        # been applied.\n        executor.migrate([(\"migrations\", \"0001_initial\")])\n        executor.migrate([(\"migrations\", None)], fake=True)\n        # Table detection sees 0001 is applied.\n        migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n        self.assertIs(executor.detect_soft_applied(None, migration)[0], True)\n\n        # Leave the tables for 0001 except the author table. That missing\n        # table should cause detect_soft_applied() to return False.\n        with connection.schema_editor() as editor:\n            editor.execute(editor.sql_delete_table % {\"table\": \"migrations_author\"})\n        migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n        self.assertIs(executor.detect_soft_applied(None, migration)[0], False)\n\n        # Cleanup by removing the remaining tables.\n        with connection.schema_editor() as editor:\n            editor.execute(editor.sql_delete_table % {\"table\": \"migrations_tribble\"})\n        self.assertTableNotExists(\"migrations_author\")\n        self.assertTableNotExists(\"migrations_tribble\")\n"], "sample_1003": ["def test_Options_init():\n    opt = Options((x, y, z), {'domain': 'ZZ'})\n\n    assert opt.gens == (x, y, z)\n    assert opt.domain == ZZ\n    assert ('order' in opt) is False\n\n    raises(OptionError, lambda: Options((x, y, z), {'domain': 'ZZ', 'gens': (x, y, z)}))\n\n    raises(GeneratorsError, lambda: Options((x, x, y), {'domain': 'ZZ'}))\n\n    raises(GeneratorsError, lambda: Options((x, y, z), {'domain': 'ZZ[y, z]'}))\n\n    raises(GeneratorsError, lambda: Options((), {'domain': 'EX'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'invalid_option': 'ZZ'}))\n\n    raises(FlagError, lambda: Options((x, y, z), {'frac': True}, flags=[]))\n"], "sample_762": ["def test_clone_sparse_matrices_with_nan():\n    # Regression test for cloning estimators with sparse matrices containing NaN\n    sparse_matrix_classes = [\n        getattr(sp, name)\n        for name in dir(sp) if name.endswith('_matrix')]\n\n    for cls in sparse_matrix_classes:\n        sparse_matrix = cls(np.array([[np.nan, 0], [0, 1]]))\n        clf = MyEstimator(empty=sparse_matrix)\n        clf_cloned = clone(clf)\n        assert clf.empty.__class__ is clf_cloned.empty.__class__\n        assert_array_equal(clf.empty.toarray(), clf_cloned.empty.toarray())\n"], "sample_618": ["def test_cross() -> None:\n    # Test cross product with 3 dimensions\n    a = xr.DataArray([1, 2, 3])\n    b = xr.DataArray([4, 5, 6])\n    expected = xr.DataArray([-3, 6, -3])\n    actual = xr.cross(a, b, dim=\"dim_0\")\n    assert_identical(expected, actual)\n\n    # Test cross product with 2 dimensions, returns in the perpendicular direction\n    a = xr.DataArray([1, 2])\n    b = xr.DataArray([4, 5])\n    expected = xr.DataArray(-3)\n    actual = xr.cross(a, b, dim=\"dim_0\")\n    assert_identical(expected, actual)\n\n    # Test cross product with 3 dimensions but zeros at the last axis yields the same results as with 2 dimensions\n    a = xr.DataArray([1, 2, 0])\n    b = xr.DataArray([4, 5, 0])\n    expected = xr.DataArray([0, 0, -3])\n    actual = xr.cross(a, b, dim=\"dim_0\")\n    assert_identical(expected, actual)\n\n    # Test one vector with dimension 2\n    a = xr.DataArray(\n        [1, 2],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\"])),\n    )\n    b = xr.DataArray(\n        [4, 5, 6],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    expected = xr.DataArray([12, -6, -3], dims=[\"cartesian\"])\n    expected.coords[\"cartesian\"] = [\"x\", \"y\", \"z\"]\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(expected, actual)\n\n    # Test one vector with dimension 2 but coords in other positions\n    a = xr.DataArray(\n        [1, 2],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"z\"])),\n    )\n    b = xr.DataArray(\n        [4, 5, 6],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    expected = xr.DataArray([-"], "sample_495": ["def test_page_repr(self):\n    \"\"\"\n    Test the representation of a Page object.\n    \"\"\"\n    paginator = Paginator([1, 2, 3], 2)\n    page = paginator.page(1)\n    self.assertEqual(repr(page), '<Page 1 of 2>')\n    page = paginator.page(2)\n    self.assertEqual(repr(page), '<Page 2 of 2>')\n"], "sample_1184": ["def test_gaussian_conj():\n    s_in, z_r_in, f = symbols('s_in z_r_in f')\n    s_out, z_r_out, m = gaussian_conj(s_in, z_r_in, f)\n    assert streq(s_out, '1/(-1/(s_in + z_r_in**2/(-f + s_in)) + 1/f)')\n    assert streq(z_r_out, 'z_r_in/(1 - s_in**2/f**2 + z_r_in**2/f**2)')\n    assert streq(m, '1/sqrt(1 - s_in**2/f**2 + z_r_in**2/f**2)')\n"], "sample_582": ["def test_flaskgroup_load_dotenv(runner, monkeypatch):\n        return Flask(\"flaskgroup\")\n\n    @click.group(cls=FlaskGroup, create_app=create_app, load_dotenv=True)\n        pass\n\n    @cli.command()\n        click.echo(os.environ.get(\"FOO\"))\n\n    monkeypatch.chdir(test_path)\n    result = runner.invoke(cli, [\"test\"])\n    assert result.exit_code == 0\n    assert result.output == \"env\\n\"\n\n    @click.group(cls=FlaskGroup, create_app=create_app, load_dotenv=False)\n        pass\n\n    @cli.command()\n        click.echo(os.environ.get(\"FOO\"))\n\n    result = runner.invoke(cli, [\"test\"])\n    assert result.exit_code == 0\n    assert result.output == \"None\\n\"\n"], "sample_520": ["def test_line3d_set_get_data_3d_zdir(fig_test, fig_ref):\n    x, y, z = [0, 1], [2, 3], [4, 5]\n    x2, y2, z2 = [6, 7], [8, 9], [10, 11]\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    lines = ax.plot(x, y, z, zdir='y')\n    line = lines[0]\n    np.testing.assert_array_equal((x, y, z), line.get_data_3d())\n    line.set_data_3d(x2, y2, z2)\n    np.testing.assert_array_equal((x2, y2, z2), line.get_data_3d())\n    line.set_xdata(x)\n    line.set_ydata(y)\n    line.set_3d_properties(zs=z, zdir='z')\n    np.testing.assert_array_equal((x, y, z), line.get_data_3d())\n    line.set_3d_properties(zs=0, zdir='z')\n    np.testing.assert_array_equal((x, y, np.zeros_like(z)), line.get_data_3d())\n\n    ax = fig_ref.add_subplot(projection='3d')\n    lines = ax.plot(x, y, z, zdir='y')\n    line = lines[0]\n    np.testing.assert_array_equal((x, y, z), line.get_data_3d())\n    line.set_data_3d(x2, y2, z2)\n    np.testing.assert_array_equal((x2, y2, z2), line.get_data_3d())\n    line.set_xdata(x)\n    line.set_ydata(y)\n    line.set_3d_properties(zs=z, zdir='z')\n    np.testing.assert_array_equal((x, y, z), line.get_data_3d())\n    line.set_3d_properties(zs=0, zdir='z')\n    np.testing.assert_array_equal((x, y, np.zeros_like(z)), line.get_data_3d())\n"], "sample_589": ["def test_interpolate_na_max_gap(da_time):\n    da_time[\"t\"] = pd.date_range(\"2001-01-01\", freq=\"H\", periods=11)\n    expected = da_time.copy(data=[np.nan, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n    actual = da_time.interpolate_na(\"t\", max_gap=\"3H\")\n    assert_equal(actual, expected)\n\n    expected = da_time.copy(data=[np.nan, 1, 2, np.nan, np.nan, 5, 6, 7, 8, 9, 10])\n    actual = da_time.interpolate_na(\"t\", max_gap=\"2H\")\n    assert_equal(actual, expected)\n"], "sample_146": ["    def test_consistent_language_settings(self):\n        for tag in ['en', 'fr']:\n            with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n                self.assertEqual(check_language_settings_consistent(None), [])\n"], "sample_1130": ["def test_point_partial_velocity_multiple_gen_speeds():\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    p = Point('p')\n    u1, u2, u3 = dynamicsymbols('u1, u2, u3')\n    p.set_vel(N, u1 * A.x + u2 * N.y + u3 * A.z)\n    assert p.partial_velocity(N, u1, u2, u3) == (A.x, N.y, A.z)\n    assert p.partial_velocity(N, u1, u3) == (A.x, A.z)\n    assert p.partial_velocity(N, u2) == N.y\n"], "sample_533": ["def test_contour_labeler_event_handler():\n    # Test that the event handler for contour labeler works correctly.\n    x, y = np.meshgrid(np.arange(0, 10), np.arange(0, 10))\n    z = np.max(np.dstack([abs(x), abs(y)]), 2)\n\n    fig, ax = plt.subplots()\n    cs = ax.contour(x, y, z)\n\n    # Test that the event handler is called when a button is pressed.\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 0, 0)\n    _contour_labeler_event_handler(cs, True, 5, event)\n\n    # Test that the event handler is called when a key is pressed.\n    event = mpl.backend_bases.KeyEvent('key_press_event', fig.canvas, 'enter')\n    _contour_labeler_event_handler(cs, True, 5, event)\n\n    # Test that the event handler is called when the middle button is pressed.\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 0, 0, button=MouseButton.MIDDLE)\n    _contour_labeler_event_handler(cs, True, 5, event)\n\n    # Test that the event handler is called when the right button is pressed.\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 0, 0, button=MouseButton.RIGHT)\n    _contour_labeler_event_handler(cs, True, 5, event)\n\n    # Test that the event handler is called when the delete key is pressed.\n    event = mpl.backend_bases.KeyEvent('key_press_event', fig.canvas, 'delete')\n    _contour_labeler_event_handler(cs, True, 5, event)\n\n    # Test that the event handler is called when the backspace key is pressed.\n    event = mpl.backend_bases.KeyEvent('key_press_event', fig.canvas, 'backspace')\n    _contour_labeler_event_handler(cs, True, 5, event)\n"], "sample_556": ["def test_subfigure_subplotspec():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    subfig = fig.add_subfigure(gs[0, 0])\n    assert subfig._subplotspec == gs[0, 0]\n    assert subfig._subplotspec.get_gridspec() == gs\n    assert subfig._subplotspec.get_topmost_subplotspec() == gs[0, 0]\n    assert subfig._subplotspec.get_position(fig) == gs[0, 0].get_position(fig)\n"], "sample_1090": ["def test_numbers():\n    assert S.Infinity + S.Infinity == S.Infinity\n    assert S.Infinity - S.Infinity == S.NaN\n    assert S.Infinity * S.Infinity == S.Infinity\n    assert S.Infinity / S.Infinity == S.NaN\n    assert S.Infinity + S.NegativeInfinity == S.NaN\n    assert S.Infinity - S.NegativeInfinity == S.Infinity\n    assert S.Infinity * S.NegativeInfinity == S.NegativeInfinity\n    assert S.Infinity / S.NegativeInfinity == S.NegativeInfinity\n    assert S.NegativeInfinity + S.NegativeInfinity == S.NegativeInfinity\n    assert S.NegativeInfinity - S.NegativeInfinity == S.NaN\n    assert S.NegativeInfinity * S.NegativeInfinity == S.Infinity\n    assert S.NegativeInfinity / S.NegativeInfinity == S.NaN\n    assert S.NaN + S.Infinity == S.NaN\n    assert S.NaN - S.Infinity == S.NaN\n    assert S.NaN * S.Infinity == S.NaN\n    assert S.NaN / S.Infinity == S.NaN\n    assert S.NaN + S.NegativeInfinity == S.NaN\n    assert S.NaN - S.NegativeInfinity == S.NaN\n    assert S.NaN * S.NegativeInfinity == S.NaN\n    assert S.NaN / S.NegativeInfinity == S.NaN\n    assert S.NaN + S.NaN == S.NaN\n    assert S.NaN - S.NaN == S.NaN\n    assert S.NaN * S.NaN == S.NaN\n    assert S.NaN / S.NaN == S.NaN\n    assert S.Infinity ** S.Infinity == S.Infinity\n    assert S.Infinity ** S.NegativeInfinity == S.Zero\n    assert S.Infinity ** S.NaN == S.NaN\n    assert S.NegativeInfinity ** S.Infinity == S.Zero\n    assert S.NegativeInfinity ** S.NegativeInfinity == S.Infinity\n    assert S.NegativeInfinity ** S.NaN == S.NaN\n    assert S.NaN ** S.Infinity == S.NaN\n    assert S.NaN ** S.NegativeInfinity == S.NaN\n    assert S.NaN ** S.NaN == S.NaN\n    assert S.Infinity ** S.Infinity == S.Infinity\n    assert S.Infinity ** S.NegativeInfinity == S.Zero\n    assert S.Infinity ** S.NaN == S.NaN\n    assert S.NegativeInfinity ** S.Infinity == S.Zero\n    assert S.NegativeInfinity ** S.Negative"], "sample_498": ["def test_legend_framealpha_with_shadow():\n    # Test if framealpha is activated when shadow is True\n    # and framealpha is not explicitly passed'''\n    fig, ax = plt.subplots()\n    ax.plot(range(100), label=\"test\")\n    leg = ax.legend(shadow=True, facecolor='w', framealpha=0.5)\n    assert leg.get_frame().get_alpha() == 0.5\n"], "sample_648": ["def test_parameter_set_extract_from(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"x\", [1, 2, 3])\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=3)\n\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"x\", (1, 2, 3))\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=3)\n\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"x\", [pytest.param(1), pytest.param(2), pytest.param(3)])\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=3)\n\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"x\", pytest.param([1, 2, 3]))\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=3)\n"], "sample_614": ["def test_unindexed_dims_repr() -> None:\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3])}\n    expected = \"Dimensions without coordinates: y z\"\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3]), \"y\": np.array([4, 5, 6])}\n    expected = \"Dimensions without coordinates: z\"\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3]), \"y\": np.array([4, 5, 6]), \"z\": np.array([7, 8, 9])}\n    expected = None\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n"], "sample_88": ["def test_attachment_filename_encoding(self):\n    \"\"\"\n    Regression test for #14964\n    \"\"\"\n    headers = {\"Date\": \"Fri, 09 Nov 2001 01:08:47 -0000\", \"Message-ID\": \"foo\"}\n    subject, from_email, to = 'hello', 'from@example.com', 'to@example.com'\n    content = 'This is the message.'\n    msg = EmailMessage(subject, content, from_email, [to], headers=headers)\n    # Unicode in file name\n    msg.attach(\"une pi\u00e8ce jointe.pdf\", b\"%PDF-1.4.%...\", mimetype=\"application/pdf\")\n    # Non-ASCII in file name\n    msg.attach(\"une pi\u00e8ce jointe2.pdf\", b\"%PDF-1.4.%...\", mimetype=\"application/pdf\", encoding='iso-8859-1')\n    msg_bytes = msg.message().as_bytes()\n    message = message_from_bytes(msg_bytes)\n    payload = message.get_payload()\n    self.assertEqual(payload[0].get_filename(), 'une pi\u00e8ce jointe.pdf')\n    self.assertEqual(payload[1].get_filename(), 'une pi\\xe8ce jointe2.pdf')\n"], "sample_1102": ["def test_issue_18419():\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(1) == 2\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(0) == 1\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(2) == 0\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(3) == 0\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(4) == 0\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(5) == 0\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(6) == 0\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(7) == 0\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(8) == 0\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(9) == 0\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(10) == 0\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(11) == 0\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(12) == 0\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(13) == 0\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(14) == 0\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(15) == 0\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(16) == 0\n    assert Poly(x**2 + 2*x + 1, x, domain='ZZ').nth(17) == "], "sample_514": ["def test_colorbar_set_alpha():\n    # test fix for #20054\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc)\n    cb.set_alpha(0.5)\n    assert cb.ax.get_alpha() == 0.5\n    cb.set_alpha(None)\n    assert cb.ax.get_alpha() is None\n    cb.set_alpha([0.5, 0.7])\n    assert cb.alpha is None\n"], "sample_1082": ["def test_hyperbolic_function_properties():\n    x = Symbol('x')\n    assert sinh(x).is_finite is None\n    assert cosh(x).is_finite is None\n    assert tanh(x).is_finite is None\n    assert coth(x).is_finite is None\n    assert csch(x).is_finite is None\n    assert sech(x).is_finite is None\n    assert asinh(x).is_finite is None\n    assert acosh(x).is_finite is None\n    assert atanh(x).is_finite is None\n    assert acoth(x).is_finite is None\n    assert asech(x).is_finite is None\n    assert acsch(x).is_finite is None\n\n    assert sinh(x).is_zero is None\n    assert cosh(x).is_zero is None\n    assert tanh(x).is_zero is None\n    assert coth(x).is_zero is None\n    assert csch(x).is_zero is None\n    assert sech(x).is_zero is None\n    assert asinh(x).is_zero is None\n    assert acosh(x).is_zero is None\n    assert atanh(x).is_zero is None\n    assert acoth(x).is_zero is None\n    assert asech(x).is_zero is None\n    assert acsch(x).is_zero is None\n\n    assert sinh(x).is_positive is None\n    assert cosh(x).is_positive is None\n    assert tanh(x).is_positive is None\n    assert coth(x).is_positive is None\n    assert csch(x).is_positive is None\n    assert sech(x).is_positive is None\n    assert asinh(x).is_positive is None\n    assert acosh(x).is_positive is None\n    assert atanh(x).is_positive is None\n    assert acoth(x).is_positive is None\n    assert asech(x).is_positive is None\n    assert acsch(x).is_positive is None\n\n    assert sinh(x).is_negative is None\n    assert cosh(x).is_negative is None\n    assert tanh(x).is_negative is None\n    assert coth(x).is_negative is None\n    assert csch(x).is_negative is None\n    assert sech(x).is_negative is None\n    assert asinh(x).is_negative is None\n    assert acosh(x).is"], "sample_310": ["    def setUp(self):\n        self.view_name = 'django.contrib.admindocs.views.BaseAdminDocsView'\n        self.url = reverse('django-admindocs-views-detail', args=[self.view_name])\n"], "sample_251": ["def test_annotation_with_window_function(self):\n    books = Book.objects.annotate(\n        avg_rating=Window(\n            ExpressionWrapper(Func('rating', function='AVG'), output_field=FloatField()),\n            partition_by=F('publisher'),\n        )\n    )\n    self.assertGreater(len(books), 0)\n    for book in books:\n        self.assertIsNotNone(book.avg_rating)\n"], "sample_797": ["def test_power_transformer_warning():\n    # Test that a warning is raised when method is set to 'box-cox' and\n    # the input data contains negative values\n    X = X_2d\n    pt = PowerTransformer(method='box-cox')\n    warn_msg = \"The Box-Cox transformation can only be applied to strictly\"\n    with pytest.warns(UserWarning, match=warn_msg):\n        pt.fit(X)\n"], "sample_227": ["def test_genericforeignkey(self):\n    class TaggedItemAdmin(ModelAdmin):\n        list_filter = ('content_object',)\n\n    modeladmin = TaggedItemAdmin(TaggedItem, site)\n\n    django_bookmark = Bookmark.objects.create(url='https://www.djangoproject.com/')\n    python_bookmark = Bookmark.objects.create(url='https://www.python.org/')\n    kernel_bookmark = Bookmark.objects.create(url='https://www.kernel.org/')\n\n    TaggedItem.objects.create(content_object=django_bookmark, tag='python')\n    TaggedItem.objects.create(content_object=python_bookmark, tag='python')\n    TaggedItem.objects.create(content_object=kernel_bookmark, tag='linux')\n\n    request = self.request_factory.get('/', {})\n    request.user = self.alfred\n    changelist = modeladmin.get_changelist_instance(request)\n\n    filterspec = changelist.get_filters(request)[0][0]\n    self.assertEqual(filterspec.title, 'content object')\n    choices = list(filterspec.choices(changelist))\n    self.assertEqual(len(choices), 4)\n\n    self.assertEqual(choices[0]['display'], 'All')\n    self.assertIs(choices[0]['selected'], True)\n    self.assertEqual(choices[0]['query_string'], '?')\n\n    self.assertEqual(choices[1]['display'], 'Bookmark object (1)')\n    self.assertIs(choices[1]['selected'], False)\n    self.assertEqual(choices[1]['query_string'], '?content_object__id__exact=%d' % django_bookmark.pk)\n\n    self.assertEqual(choices[2]['display'], 'Bookmark object (2)')\n    self.assertIs(choices[2]['selected'], False)\n    self.assertEqual(choices[2]['query_string'], '?content_object__id__exact=%d' % python_bookmark.pk)\n\n    self.assertEqual(choices[3]['display'], 'Bookmark object (3)')\n    self.assertIs(choices[3]['selected'], False)\n    self.assertEqual(choices[3]['query_string'], '?content_object__id__exact=%d' % kernel_bookmark.pk)\n\n    request = self.request_factory.get('/', {'content_object__id__exact': django_bookmark.pk})\n    request.user = self.alfred\n    changelist = modeladmin.get_changelist_instance(request)\n\n    filterspec = changelist.get_filters(request)[0][0]\n    self.assertEqual(filterspec.title, 'content object')\n    choices = list(filterspec.choices(changelist))\n    self.assertEqual(len(choices), 4)\n\n    self.assertEqual(choices[0]['display'], 'All')\n    self.assertIs"], "sample_148": ["    def test_quote(self):\n        self.assertEqual(quote('abc'), 'abc')\n        self.assertEqual(quote('abc/def'), 'abc_def')\n        self.assertEqual(quote('abc:def'), 'abc_def')\n        self.assertEqual(quote('abc#def'), 'abc_def')\n        self.assertEqual(quote('abc?def'), 'abc_def')\n        self.assertEqual(quote('abc@def'), 'abc_def')\n        self.assertEqual(quote('abc&def'), 'abc_def')\n        self.assertEqual(quote('abc=def'), 'abc_def')\n        self.assertEqual(quote('abc+def'), 'abc_def')\n        self.assertEqual(quote('abc$def'), 'abc_def')\n        self.assertEqual(quote('abc,def'), 'abc_def')\n        self.assertEqual(quote('abc[def'), 'abc_def')\n        self.assertEqual(quote('abc]def'), 'abc_def')\n        self.assertEqual(quote('abc<def'), 'abc_def')\n        self.assertEqual(quote('abc>def'), 'abc_def')\n        self.assertEqual(quote('abc%def'), 'abc_def')\n        self.assertEqual(quote('abc\\\\def'), 'abc_def')\n        self.assertEqual(quote('abc\\ndef'), 'abc_def')\n"], "sample_228": ["def test_formset_absolute_max_with_min_num(self):\n    data = {\n        'form-TOTAL_FORMS': '1001',\n        'form-INITIAL_FORMS': '0',\n        'form-MAX_NUM_FORMS': '0',\n    }\n    LimitedFavoriteDrinksFormSet = formset_factory(\n        FavoriteDrinkForm,\n        min_num=30,\n        absolute_max=1000,\n    )\n    formset = LimitedFavoriteDrinksFormSet(data=data)\n    self.assertIs(formset.is_valid(), False)\n    self.assertEqual(len(formset.forms), 1000)\n    self.assertEqual(\n        formset.non_form_errors(),\n        ['Please submit at least 30 forms.'],\n    )\n"], "sample_798": ["def test_ridge_regression_check_solver():\n    \"\"\"check if all combinations of solver give valid estimations\"\"\"\n\n    # test excludes 'svd' solver because it raises exception for sparse inputs\n\n    rng = check_random_state(42)\n    X = rng.rand(1000, 3)\n    true_coefs = [1, 2, 0.1]\n    y = np.dot(X, true_coefs)\n    alpha, atol, tol = 1e-3, 1e-4, 1e-6\n\n    solvers = ['auto', 'sparse_cg', 'cholesky', 'lsqr', 'sag', 'saga']\n    for solver in solvers:\n        out = ridge_regression(X, y, alpha=alpha,\n                               solver=solver,\n                               tol=tol)\n        assert_allclose(out, true_coefs, rtol=0, atol=atol)\n"], "sample_425": ["def test_register_serializer(self):\n    Serializer.register(int, ComplexSerializer)\n    self.assertSerializedResultEqual(\n        42,\n        (\"complex(42)\", set()),\n    )\n    Serializer.unregister(int)\n    self.assertSerializedResultEqual(\n        42,\n        (\"42\", set()),\n    )\n"], "sample_298": ["def test_make_token_with_timestamp(self):\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    timestamp = p0._num_seconds(p0._now())\n    tk1 = p0._make_token_with_timestamp(user, timestamp)\n    self.assertIs(p0.check_token(user, tk1), True)\n    # Test with a different timestamp\n    timestamp += 1\n    tk2 = p0._make_token_with_timestamp(user, timestamp)\n    self.assertIs(p0.check_token(user, tk2), True)\n    # Test with a timestamp in the past\n    timestamp = p0._num_seconds(p0._now() - timedelta(days=1))\n    tk3 = p0._make_token_with_timestamp(user, timestamp)\n    self.assertIs(p0.check_token(user, tk3), True)\n"], "sample_978": ["def test_bspline_basis_set_degree_0_repeated_knots():\n    d = 0\n    knots = [0, 0, 1, 1, 2, 2]\n    splines = bspline_basis_set(d, knots, x)\n    assert splines[0] == Piecewise((1, Interval(0, 1).contains(x)),\n                                   (0, True))\n    assert splines[1] == Piecewise((1, Interval(1, 2).contains(x)),\n                                   (0, True))\n"], "sample_170": ["    def test_technical_500_response(self):\n        request = RequestFactory().get('/')\n        exc_type = ValueError\n        exc_value = ValueError('Test exception')\n        tb = None\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html; charset=utf-8')\n"], "sample_78": ["def test_base_command_output_transaction(self):\n    \"\"\"\n    Test that BaseCommand's output_transaction attribute is respected.\n    \"\"\"\n    class TestCommand(BaseCommand):\n        output_transaction = True\n\n            return 'SELECT * FROM table;'\n\n    out = StringIO()\n    management.call_command('test', stdout=out)\n    self.assertTrue(out.getvalue().strip().startswith(connection.ops.start_transaction_sql()))\n    self.assertTrue(out.getvalue().strip().endswith(connection.ops.end_transaction_sql()))\n\n    class TestCommand(BaseCommand):\n        output_transaction = False\n\n            return 'SELECT * FROM table;'\n\n    out = StringIO()\n    management.call_command('test', stdout=out)\n    self.assertEqual(out.getvalue().strip(), 'SELECT * FROM table;')\n"], "sample_656": ["def test_capture_manager_is_globally_capturing(testdir):\n    testdir.makeconftest(\n        \"\"\"\n            assert early_config.pluginmanager.getplugin(\"capturemanager\").is_globally_capturing()\n    \"\"\"\n    )\n    testdir.makepyfile(\"def test_func(): pass\")\n    result = testdir.runpytest()\n    assert result.ret == 0\n"], "sample_523": ["def test_legend_draggable_update():\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label='shabnams')\n    leg = ax.legend(draggable=True)\n    assert leg.get_draggable()\n    leg.set_draggable(False)\n    assert not leg.get_draggable()\n    leg.set_draggable(True, update='bbox')\n    assert leg.get_draggable()\n"], "sample_587": ["    def test_merge_data_and_coords(self):\n        data = xr.Dataset({\"x\": [1, 2]})\n        coords = xr.Dataset({\"y\": [3, 4]})\n        actual = xr.merge([data, coords])\n        expected = xr.Dataset({\"x\": [1, 2], \"y\": [3, 4]})\n        assert actual.identical(expected)\n"], "sample_969": ["def test_get_type_hints():\n        pass\n\n    assert get_type_hints(func) == {'a': int, 'b': str, 'return': None}\n\n    class MyClass:\n            pass\n\n    assert get_type_hints(MyClass) == {'a': int, 'b': str, 'return': None}\n\n    class MyGenericClass(Generic[T]):\n            pass\n\n    assert get_type_hints(MyGenericClass) == {'a': T, 'b': str, 'return': None}\n\n    class MyBrokenClass:\n        __annotations__ = {'a': int, 'b': str}\n\n    assert get_type_hints(MyBrokenClass) == {'a': int, 'b': str}\n\n    class MyNewTypeClass:\n        MyNewType = NewType('MyNewType', int)\n\n    assert get_type_hints(MyNewTypeClass.MyNewType) == {}\n"], "sample_150": ["    def test_handle_default_options(self):\n        options = mock.Mock()\n        options.settings = 'test_settings'\n        options.pythonpath = '/test/path'\n        handle_default_options(options)\n        self.assertEqual(os.environ['DJANGO_SETTINGS_MODULE'], 'test_settings')\n        self.assertIn('/test/path', sys.path)\n"], "sample_970": ["def test_isabstractmethod():\n    class AbstractClass:\n        @abstractmethod\n            pass\n\n    class ConcreteClass(AbstractClass):\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(ConcreteClass.abstract_method) is False\n"], "sample_1088": ["def test_viete():\n    assert viete(a*x**2 + b*x + c, [x, y]) == [(x + y, -b/a), (x*y, c/a)]\n    assert viete(a*x**2 + b*x + c, roots=[x, y]) == [(x + y, -b/a), (x*y, c/a)]\n    assert viete(a*x**2 + b*x + c, x, [x, y]) == [(x + y, -b/a), (x*y, c/a)]\n\n    assert viete(a*x**3 + b*x**2 + c*x + d, [x, y, z]) == \\\n        [(x + y + z, -b/a), (x*y + x*z + y*z, c/a), (x*y*z, -d/a)]\n\n    assert viete(a*x**3 + b*x**2 + c*x + d, roots=[x, y, z]) == \\\n        [(x + y + z, -b/a), (x*y + x*z + y*z, c/a), (x*y*z, -d/a)]\n\n    assert viete(a*x**3 + b*x**2 + c*x + d, x, [x, y, z]) == \\\n        [(x + y + z, -b/a), (x*y + x*z + y*z, c/a), (x*y*z, -d/a)]\n\n    raises(MultivariatePolynomialError, lambda: viete(a*x**2 + b*y**2 + c*x + d, [x, y]))\n    raises(ValueError, lambda: viete(a, [x, y]))\n    raises(ValueError, lambda: viete(a*x**2 + b*x + c, [x, y, z]))\n"], "sample_907": ["def test_domain_cpp_ast_template_template_parameters():\n    check('class', 'template<template<typename> typename T> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> class T> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> typename...> {key}A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename...> {key}A', {2: 'II0EDpE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I0I0EDpE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I0I0EDpE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I0I0EDpE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I0I0EDpE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I0I0EDpE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I0I0EDpE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I0I0EDpE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I0I0EDpE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I0I0EDpE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I0I0EDpE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I"], "sample_320": ["def test_alter_model_table_comment_with_quotes(self):\n    app_label = \"test_almotacwoq\"\n    project_state = self.set_up_test_model(app_label)\n    pony_table = f\"{app_label}_pony\"\n    # Add table comment.\n    operation = migrations.AlterModelTableComment(\"Pony\", 'Custom \"pony\" comment')\n    self.assertEqual(operation.describe(), \"Alter Pony table comment\")\n    self.assertEqual(operation.migration_name_fragment, \"alter_pony_table_comment\")\n    new_state = project_state.clone()\n    operation.state_forwards(app_label, new_state)\n    self.assertEqual(\n        new_state.models[app_label, \"pony\"].options[\"db_table_comment\"],\n        'Custom \"pony\" comment',\n    )\n    self.assertTableCommentNotExists(pony_table)\n    with connection.schema_editor() as editor:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    self.assertTableComment(pony_table, 'Custom \"pony\" comment')\n    # Reversal.\n    with connection.schema_editor() as editor:\n        operation.database_backwards(app_label, editor, new_state, project_state)\n    self.assertTableCommentNotExists(pony_table)\n    # Deconstruction.\n    definition = operation.deconstruct()\n    self.assertEqual(definition[0], \"AlterModelTableComment\")\n    self.assertEqual(definition[1], [])\n    self.assertEqual(\n        definition[2], {\"name\": \"Pony\", \"table_comment\": 'Custom \"pony\" comment'}\n    )\n"], "sample_1157": ["def test_implicit_multiplication_application():\n    transformations = standard_transformations + \\\n                      (implicit_multiplication_application,)\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z')\n    f = Function('f')\n    assert parse_expr(\"2x\", transformations=transformations) == 2*x\n    assert parse_expr(\"2 x\", transformations=transformations) == 2*x\n    assert parse_expr(\"2x y\", transformations=transformations) == 2*x*y\n    assert parse_expr(\"2 x y\", transformations=transformations) == 2*x*y\n    assert parse_expr(\"2x(y+1)\", transformations=transformations) == 2*x*(y+1)\n    assert parse_expr(\"2 x(y+1)\", transformations=transformations) == 2*x*(y+1)\n    assert parse_expr(\"2x(y+1)z\", transformations=transformations) == 2*x*(y+1)*z\n    assert parse_expr(\"2 x(y+1)z\", transformations=transformations) == 2*x*(y+1)*z\n    assert parse_expr(\"2x(y+1)z^2\", transformations=transformations) == 2*x*(y+1)*z**2\n    assert parse_expr(\"2 x(y+1)z^2\", transformations=transformations) == 2*x*(y+1)*z**2\n    assert parse_expr(\"f(x)z\", transformations=transformations) == f(x)*z\n    assert parse_expr(\"f(x) z\", transformations=transformations) == f(x)*z\n    assert parse_expr(\"f(x)z^2\", transformations=transformations) == f(x)*z**2\n    assert parse_expr(\"f(x) z^2\", transformations=transformations) == f(x)*z**2\n"], "sample_935": ["def test_template_parameter_lists():\n    check('function', 'template<typename T> void f(T)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T, typename U> void f(T, U)', {2: 'I00E1f1T1U'})\n    check('function', 'template<typename T, typename U, typename V> void f(T, U, V)', {2: 'I000E1f1T1U1V'})\n    check('function', 'template<typename T, typename U, typename V, typename W> void f(T, U, V, W)', {2: 'I0000E1f1T1U1V1W'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X> void f(T, U, V, W, X)', {2: 'I00000E1f1T1U1V1W1X'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> void f(T, U, V, W, X, Y)', {2: 'I000000E1f1T1U1V1W1X1Y'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> void f(T, U, V, W, X, Y, Z)', {2: 'I0000000E1f1T1U1V1W1X1Y1Z'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A> void f(T, U, V, W, X, Y, Z, A)', {2: 'I00000000E1f1T1U1V1W1X1Y1Z1A'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A, typename B> void f(T, U, V, W, X, Y, Z, A, B)', {2: 'I000000000E1f1T1U1V1W1X1Y1Z1A1B'})\n    check('function', 'template<typename"], "sample_873": ["def test_get_feature_names_out():\n    sel = StepSelector()\n    sel.fit(X, y)\n    assert_array_equal(feature_names_t, sel.get_feature_names_out())\n    assert_array_equal(feature_names_t, sel.get_feature_names_out(input_features=feature_names))\n    with pytest.raises(ValueError):\n        sel.get_feature_names_out(input_features=[\"wrong\", \"feature\", \"names\"])\n"], "sample_1004": ["def test_CondSet_contains():\n    c = ConditionSet(x, x < 1, Interval(0, 2))\n    assert c.contains(0.5) == True\n    assert c.contains(2) == False\n    assert c.contains(1) == False\n    c = ConditionSet(x, x > 1, Interval(0, 2))\n    assert c.contains(0.5) == False\n    assert c.contains(2) == True\n    assert c.contains(1) == False\n    c = ConditionSet(x, x < 1, FiniteSet(0, 1, 2))\n    assert c.contains(0) == True\n    assert c.contains(1) == False\n    assert c.contains(2) == False\n    c = ConditionSet(x, x > 1, FiniteSet(0, 1, 2))\n    assert c.contains(0) == False\n    assert c.contains(1) == False\n    assert c.contains(2) == True\n"], "sample_1153": ["def test_periodic_argument_edge_cases():\n    from sympy import periodic_argument, oo, pi, I, exp_polar\n    assert periodic_argument(0, oo) == 0\n    assert periodic_argument(0, pi) == 0\n    assert periodic_argument(0, -pi) == 0\n    assert periodic_argument(0, 2*pi) == 0\n    assert periodic_argument(0, -2*pi) == 0\n    assert periodic_argument(0, I*pi) is None\n    assert periodic_argument(0, -I*pi) is None\n    assert periodic_argument(0, oo*I) is None\n    assert periodic_argument(0, -oo*I) is None\n    assert periodic_argument(oo, oo) is oo\n    assert periodic_argument(-oo, oo) is -oo\n    assert periodic_argument(oo, pi) == pi/2\n    assert periodic_argument(-oo, pi) == -pi/2\n    assert periodic_argument(oo, -pi) == pi/2\n    assert periodic_argument(-oo, -pi) == -pi/2\n    assert periodic_argument(oo, 2*pi) == pi\n    assert periodic_argument(-oo, 2*pi) == -pi\n    assert periodic_argument(oo, -2*pi) == pi\n    assert periodic_argument(-oo, -2*pi) == -pi\n    assert periodic_argument(oo*I, oo) is oo\n    assert periodic_argument(-oo*I, oo) is -oo\n    assert periodic_argument(oo*I, pi) == pi/2\n    assert periodic_argument(-oo*I, pi) == -pi/2\n    assert periodic_argument(oo*I, -pi) == pi/2\n    assert periodic_argument(-oo*I, -pi) == -pi/2\n    assert periodic_argument(oo*I, 2*pi) == pi\n    assert periodic_argument(-oo*I, 2*pi) == -pi\n    assert periodic_argument(oo*I, -2*pi) == pi\n    assert periodic_argument(-oo*I, -2*pi) == -pi\n    assert periodic_argument(exp_polar(oo*I), oo) is oo\n    assert periodic_argument(exp_polar(-oo*I), oo) is -oo\n    assert periodic_argument(exp_polar(oo*I), pi) == pi/2\n    assert periodic_argument(exp_polar(-oo*I), pi"], "sample_923": ["def test_template_parameter_lists():\n    check('function', 'template<typename T> void f(T)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T, T)', {2: 'I0E1f1T1T'})\n    check('function', 'template<typename T, typename U> void f(T, U)', {2: 'I00E1f1T1U'})\n    check('function', 'template<typename T, typename U, typename V> void f(T, U, V)', {2: 'I000E1f1T1U1V'})\n    check('function', 'template<typename T, typename U, typename V, typename W> void f(T, U, V, W)', {2: 'I0000E1f1T1U1V1W'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X> void f(T, U, V, W, X)', {2: 'I00000E1f1T1U1V1W1X'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> void f(T, U, V, W, X, Y)', {2: 'I000000E1f1T1U1V1W1X1Y'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> void f(T, U, V, W, X, Y, Z)', {2: 'I0000000E1f1T1U1V1W1X1Y1Z'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A> void f(T, U, V, W, X, Y, Z, A)', {2: 'I00000000E1f1T1U1V1W1X1Y1Z1A'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A, typename B> void f(T, U, V, W, X, Y, Z, A, B)', {2: 'I000000000"], "sample_308": ["def test_f_format(self):\n    dt = datetime(2009, 5, 16, 5, 30, 30)\n    self.assertEqual(dateformat.format(dt, 'f'), '5:30')\n    dt = datetime(2009, 5, 16, 5, 0, 0)\n    self.assertEqual(dateformat.format(dt, 'f'), '5')\n"], "sample_232": ["    def test_key_transform_factory(self):\n        field = models.JSONField()\n        transform = field.get_transform('key')\n        self.assertIsInstance(transform, KeyTransformFactory)\n        self.assertEqual(transform.key_name, 'key')\n"], "sample_610": ["def test_cftimeindex_repr_with_name():\n    index = xr.cftime_range(\"2000\", periods=3, name=\"time\")\n    repr_str = index.__repr__()\n    assert \"name='time'\" in repr_str\n"], "sample_455": ["def test_validate_ordered_expression_condition(self):\n    constraint = models.UniqueConstraint(\n        Lower(\"name\").desc(),\n        name=\"name_lower_without_color_uniq\",\n        condition=models.Q(color__isnull=True),\n    )\n    non_unique_product = UniqueConstraintProduct(name=self.p2.name.upper())\n    msg = \"Constraint \u201cname_lower_without_color_uniq\u201d is violated.\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        constraint.validate(UniqueConstraintProduct, non_unique_product)\n    # Values not matching condition are ignored.\n    constraint.validate(\n        UniqueConstraintProduct,\n        UniqueConstraintProduct(name=self.p1.name, color=self.p1.color),\n    )\n    # Existing instances have their existing row excluded.\n    constraint.validate(UniqueConstraintProduct, self.p2)\n    # Unique field is excluded.\n    constraint.validate(\n        UniqueConstraintProduct,\n        non_unique_product,\n        exclude={\"name\"},\n    )\n    # Field from a condition is excluded.\n    constraint.validate(\n        UniqueConstraintProduct,\n        non_unique_product,\n        exclude={\"color\"},\n    )\n"], "sample_576": ["    def test_repr_png_(self):\n\n        p = Plot().plot()\n        data, metadata = p._repr_png_()\n        img = Image.open(io.BytesIO(data))\n\n        assert not hasattr(p, \"_figure\")\n        assert isinstance(data, bytes)\n        assert img.format == \"PNG\"\n        assert sorted(metadata) == [\"height\", \"width\"]\n        # TODO test retina scaling\n"], "sample_724": ["def test_imputation_most_frequent_sparse():\n    # Test imputation using the most-frequent strategy with sparse matrices.\n    X = sparse.csc_matrix(np.array([\n        [-1, -1, 0, 5],\n        [-1, 2, -1, 3],\n        [-1, 1, 3, -1],\n        [-1, 2, 3, 7],\n    ]))\n\n    X_true = np.array([\n        [2, 0, 5],\n        [2, 3, 3],\n        [1, 3, 3],\n        [2, 3, 7],\n    ])\n\n    # scipy.stats.mode, used in Imputer, doesn't return the first most\n    # frequent as promised in the doc but the lowest most frequent. When this\n    # test will fail after an update of scipy, Imputer will need to be updated\n    # to be consistent with the new (correct) behaviour\n    _check_statistics(X, X_true, \"most_frequent\", [np.nan, 2, 3, 3], -1)\n"], "sample_242": ["def test_year_lookup_bounds(self):\n    connection = mock.Mock()\n    connection.ops.year_lookup_bounds_for_datetime_field.return_value = ('start', 'finish')\n    connection.ops.year_lookup_bounds_for_date_field.return_value = ('date_start', 'date_finish')\n\n    lookup = YearLookup(Lookup(DateTimeField(), Value(1)), Value(2022))\n\n    self.assertEqual(lookup.year_lookup_bounds(connection, 2022), ('start', 'finish'))\n\n    lookup = YearLookup(Lookup(DateTimeField(), Value(1)), Value(2022))\n    lookup.lhs.lhs.output_field = mock.Mock(spec=DateTimeField)\n    lookup.lhs.lhs.output_field.__class__ = mock.Mock(spec=DateTimeField)\n    lookup.lhs.lhs.output_field.__class__.__name__ = 'DateField'\n\n    self.assertEqual(lookup.year_lookup_bounds(connection, 2022), ('date_start', 'date_finish'))\n"], "sample_842": ["def test_clone(estimator):\n    # Test that clone works correctly on estimators.\n    estimator_cloned = clone(estimator)\n\n    # Check that all constructor parameters are equal.\n    assert estimator.get_params() == estimator_cloned.get_params()\n\n    # Check that the cloned estimator is not the same object as the original.\n    assert id(estimator) != id(estimator_cloned)\n"], "sample_1025": ["def test_printing_functions():\n    p = PythonCodePrinter()\n    assert p.doprint(acos(x)) == 'math.acos(x)'\n    assert p.doprint(acos(x).diff(x)) == 'math.cos(x)'\n    assert p.doprint(acos(x).diff(x, 2)) == '-math.sin(x)'\n    assert p.doprint(acos(x).diff(x, 3)) == '-math.cos(x)'\n    assert p.doprint(acos(x).diff(x, 4)) == 'math.sin(x)'\n    assert p.doprint(acos(x).diff(x, 5)) == 'math.cos(x)'\n    assert p.doprint(acos(x).diff(x, 6)) == '-math.sin(x)'\n    assert p.doprint(acos(x).diff(x, 7)) == '-math.cos(x)'\n    assert p.doprint(acos(x).diff(x, 8)) == 'math.sin(x)'\n    assert p.doprint(acos(x).diff(x, 9)) == 'math.cos(x)'\n    assert p.doprint(acos(x).diff(x, 10)) == '-math.sin(x)'\n    assert p.doprint(acos(x).diff(x, 11)) == '-math.cos(x)'\n    assert p.doprint(acos(x).diff(x, 12)) == 'math.sin(x)'\n    assert p.doprint(acos(x).diff(x, 13)) == 'math.cos(x)'\n    assert p.doprint(acos(x).diff(x, 14)) == '-math.sin(x)'\n    assert p.doprint(acos(x).diff(x, 15)) == '-math.cos(x)'\n    assert p.doprint(acos(x).diff(x, 16)) == 'math.sin(x)'\n    assert p.doprint(acos(x).diff(x, 17)) == 'math.cos(x)'\n    assert p.doprint(acos(x).diff(x, 18)) == '-math.sin(x)'\n    assert p.doprint(acos(x).diff(x, 19)) == '-math.cos(x)'\n    assert p.doprint(acos(x).diff(x, 20)) == 'math.sin(x)'\n    assert p.doprint(acos(x).diff(x, 21)) == 'math.cos(x)'\n    assert p.doprint(acos(x).diff(x, 22)) == '-math.sin"], "sample_153": ["    def test_model_base_subclass_exception(self):\n        class TestModel(metaclass=ModelBase):\n            pass\n\n        DoesNotExist = TestModel.DoesNotExist\n        MultipleObjectsReturned = TestModel.MultipleObjectsReturned\n\n        self.assertIsInstance(DoesNotExist, type)\n        self.assertIsInstance(MultipleObjectsReturned, type)\n        self.assertEqual(DoesNotExist.__module__, 'tests.test_models')\n        self.assertEqual(MultipleObjectsReturned.__module__, 'tests.test_models')\n        self.assertEqual(DoesNotExist.__qualname__, 'TestModel.DoesNotExist')\n        self.assertEqual(MultipleObjectsReturned.__qualname__, 'TestModel.MultipleObjectsReturned')\n"], "sample_1038": ["def test_MatrixExpr_from_index_summation():\n    from sympy import MatrixSymbol, Sum, symbols\n    from sympy.abc import i, j, k, l, N\n    A = MatrixSymbol(\"A\", N, N)\n    B = MatrixSymbol(\"B\", N, N)\n    C = MatrixSymbol(\"C\", N, N)\n    D = MatrixSymbol(\"D\", N, N)\n    E = MatrixSymbol(\"E\", N, N)\n    F = MatrixSymbol(\"F\", N, N)\n    G = MatrixSymbol(\"G\", N, N)\n    H = MatrixSymbol(\"H\", N, N)\n    I = MatrixSymbol(\"I\", N, N)\n    J = MatrixSymbol(\"J\", N, N)\n    K = MatrixSymbol(\"K\", N, N)\n    L = MatrixSymbol(\"L\", N, N)\n    M = MatrixSymbol(\"M\", N, N)\n    O = MatrixSymbol(\"O\", N, N)\n    P = MatrixSymbol(\"P\", N, N)\n    Q = MatrixSymbol(\"Q\", N, N)\n    R = MatrixSymbol(\"R\", N, N)\n    S = MatrixSymbol(\"S\", N, N)\n    T = MatrixSymbol(\"T\", N, N)\n    U = MatrixSymbol(\"U\", N, N)\n    V = MatrixSymbol(\"V\", N, N)\n    W = MatrixSymbol(\"W\", N, N)\n    X = MatrixSymbol(\"X\", N, N)\n    Y = MatrixSymbol(\"Y\", N, N)\n    Z = MatrixSymbol(\"Z\", N, N)\n\n    expr = Sum(A[i, j]*B[j, k], (j, 0, N-1))\n    assert MatrixExpr.from_index_summation(expr) == A*B\n\n    expr = Sum(A[j, i]*B[j, k], (j, 0, N-1))\n    assert MatrixExpr.from_index_summation(expr) == A.T*B\n\n    expr = Sum(A[i, i], (i, 0, N-1))\n    assert MatrixExpr.from_index_summation(expr) == A.trace()\n\n    expr = Sum(A[i, j]*B[k, j]*A[l, k], (j, 0, N-1), (k, 0, N-1))\n    assert MatrixExpr.from_index_summation(expr) == A*B.T*A.T\n\n"], "sample_1075": ["def test_beta():\n    x, y = symbols('x y')\n    assert beta(x, y).diff(x) == (digamma(x) - digamma(x + y))*beta(x, y)\n    assert beta(x, y).diff(y) == (digamma(y) - digamma(x + y))*beta(x, y)\n\n    assert beta(1, y).simplify() == 1/y\n    assert beta(x, 1).simplify() == 1/x\n\n    assert beta(x, y).conjugate() == beta(conjugate(x), conjugate(y))\n\n    assert beta(x, y).is_real == (x.is_real and y.is_real)\n\n    raises(ArgumentIndexError, lambda: beta(x, y).fdiff(3))\n\n    assert expand_func(beta(x, y)) == gamma(x)*gamma(y) / gamma(x + y)\n"], "sample_1056": ["def test_numexprprinter():\n    prntr = NumExprPrinter()\n    assert prntr._print_ImaginaryUnit(Expr()) == '1j'\n    assert prntr._print_Function(sin(x)) == 'sin(x)'\n    assert prntr._print_Function(cos(x)) == 'cos(x)'\n    assert prntr._print_Function(tan(x)) == 'tan(x)'\n    assert prntr._print_Function(asin(x)) == 'arcsin(x)'\n    assert prntr._print_Function(acos(x)) == 'arccos(x)'\n    assert prntr._print_Function(atan(x)) == 'arctan(x)'\n    assert prntr._print_Function(atan2(x, y)) == 'arctan2(x, y)'\n    assert prntr._print_Function(sinh(x)) == 'sinh(x)'\n    assert prntr._print_Function(cosh(x)) == 'cosh(x)'\n    assert prntr._print_Function(tanh(x)) == 'tanh(x)'\n    assert prntr._print_Function(asinh(x)) == 'arcsinh(x)'\n    assert prntr._print_Function(acosh(x)) == 'arccosh(x)'\n    assert prntr._print_Function(atanh(x)) == 'arctanh(x)'\n    assert prntr._print_Function(log(x)) == 'log(x)'\n    assert prntr._print_Function(exp(x)) == 'exp(x)'\n    assert prntr._print_Function(sqrt(x)) == 'sqrt(x)'\n    assert prntr._print_Function(Abs(x)) == 'abs(x)'\n    assert prntr._print_Function(conjugate(x)) == 'conj(x)'\n    assert prntr._print_Function(im(x)) == 'imag(x)'\n    assert prntr._print_Function(re(x)) == 'real(x)'\n    assert prntr._print_Function(where(x, y, z)) == 'where(x, y, z)'\n    assert prntr._print_Function(complex(x, y)) == 'complex(x, y)'\n    assert prntr._print_Function(contains(x, y)) == 'contains(x, y)'\n"], "sample_196": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_1105": ["def test_entry():\n    A = MatrixSymbol('A', 2, 3)\n    B = MatrixSymbol('B', 3, 4)\n    C = MatMul(A, B)\n    assert C.shape == (2, 4)\n    assert C._entry(0, 0) == A[0, 0]*B[0, 0] + A[0, 1]*B[1, 0] + A[0, 2]*B[2, 0]\n    assert C._entry(1, 3) == A[1, 0]*B[0, 3] + A[1, 1]*B[1, 3] + A[1, 2]*B[2, 3]\n"], "sample_1087": ["def test_fateman_poly_F_3():\n    f, g, h = fateman_poly_F_3(1)\n    F, G, H = dmp_fateman_poly_F_3(1, ZZ)\n\n    assert [ t.rep.rep for t in [f, g, h] ] == [F, G, H]\n\n    f, g, h = fateman_poly_F_3(3)\n    F, G, H = dmp_fateman_poly_F_3(3, ZZ)\n\n    assert [ t.rep.rep for t in [f, g, h] ] == [F, G, H]\n"], "sample_1064": ["def test_tensorflow_derivative():\n    if not tf:\n        skip(\"TensorFlow not installed\")\n\n    f = Function('f')\n    expr = Derivative(f(x), x)\n    assert tensorflow_code(expr) == \"tensorflow.gradients(f(x), x)[0]\"\n    _compare_tensorflow_scalar((x,), expr)\n\n    expr = Derivative(f(x), x, x)\n    assert tensorflow_code(expr) == \"tensorflow.gradients(tensorflow.gradients(f(x), x)[0], x)[0]\"\n    _compare_tensorflow_scalar((x,), expr)\n\n    expr = Derivative(f(x, y), x)\n    assert tensorflow_code(expr) == \"tensorflow.gradients(f(x, y), x)[0]\"\n    _compare_tensorflow_scalar((x, y), expr)\n\n    expr = Derivative(f(x, y), x, y)\n    assert tensorflow_code(expr) == \"tensorflow.gradients(tensorflow.gradients(f(x, y), x)[0], y)[0]\"\n    _compare_tensorflow_scalar((x, y), expr)\n"], "sample_972": ["def test_get_type_hints():\n        pass\n\n    assert get_type_hints(func) == {'a': int, 'b': str, 'return': None}\n\n    class MyClass:\n            pass\n\n    assert get_type_hints(MyClass) == {'a': int, 'b': str, 'return': None}\n\n    class MyClassWithNoTypeHints:\n            pass\n\n    assert get_type_hints(MyClassWithNoTypeHints) == {}\n\n    class MyClassWithBrokenTypeHints:\n            pass\n\n    assert get_type_hints(MyClassWithBrokenTypeHints) == {'a': int, 'b': 'str', 'return': None}\n\n    class MyClassWithForwardRef:\n            pass\n\n    assert get_type_hints(MyClassWithForwardRef) == {'a': 'MyClassWithForwardRef', 'return': None}\n"], "sample_1154": ["def test__linsolve_underdetermined():\n    # Test underdetermined system\n    eqs = [Eq(x + y, 0)]\n    sol = {x:-y, y:y}\n    assert _linsolve(eqs, (x, y)) == sol\n\n    # Test underdetermined system with multiple free variables\n    eqs = [Eq(x + y + z, 0)]\n    sol = {x:-y - z, y:y, z:z}\n    assert _linsolve(eqs, (x, y, z)) == sol\n\n    # Test underdetermined system with complex coefficients\n    eqs = [Eq(x + I*y, 0)]\n    sol = {x:-I*y, y:y}\n    assert _linsolve(eqs, (x, y)) == sol\n"], "sample_1119": ["def test_power():\n    assert MatPow(C, S.NegativeOne).args == (C, S.NegativeOne)\n    assert MatPow(C, S.NegativeOne).shape == (n, n)\n    assert MatPow(A*E, S.NegativeOne).shape == (n, n)\n    assert MatPow(E*A, S.NegativeOne).shape == (m, m)\n    assert MatPow(C, S.NegativeOne).base == C\n    assert MatPow(C, S.NegativeOne).exp == S.NegativeOne\n\n    assert MatPow(*MatPow(E*A, S.NegativeOne).args) == MatPow(E*A, S.NegativeOne)\n\n    assert C**S.NegativeOne == C.I\n\n    assert Identity(n)**S.NegativeOne == Identity(n)\n    assert (3*Identity(n))**S.NegativeOne == Identity(n)/3\n\n    # Simplifies Muls if possible (i.e. submatrices are square)\n    assert (C*D)**S.NegativeOne == D.I*C.I\n    # But still works when not possible\n    assert isinstance((A*E)**S.NegativeOne, MatPow)\n    assert MatPow(C*D, S.NegativeOne).doit(inv_expand=False) == MatPow(C*D, S.NegativeOne)\n\n    assert eye(3)**S.NegativeOne == eye(3)\n    assert eye(3)**S.NegativeOne == eye(3).doit(deep=False)\n\n    assert OneMatrix(1, 1)**S.NegativeOne == Identity(1)\n    assert isinstance(OneMatrix(n, n)**S.NegativeOne, MatPow)\n"], "sample_1035": ["def test_measure_all():\n    qubit = IntQubit(0, nqubits=2)\n    assert measure_all(qubit) == [(IntQubit(0, nqubits=2), 1)]\n    qubit = IntQubit(1, nqubits=2)\n    assert measure_all(qubit) == [(IntQubit(1, nqubits=2), 1)]\n    qubit = IntQubit(2, nqubits=2)\n    assert measure_all(qubit) == [(IntQubit(2, nqubits=2), 1)]\n    qubit = IntQubit(3, nqubits=2)\n    assert measure_all(qubit) == [(IntQubit(3, nqubits=2), 1)]\n    qubit = (IntQubit(0, nqubits=2) + IntQubit(1, nqubits=2))/sqrt(2)\n    assert measure_all(qubit) == [(IntQubit(0, nqubits=2), 1/2), (IntQubit(1, nqubits=2), 1/2)]\n    qubit = (IntQubit(0, nqubits=2) + IntQubit(2, nqubits=2))/sqrt(2)\n    assert measure_all(qubit) == [(IntQubit(0, nqubits=2), 1/2), (IntQubit(2, nqubits=2), 1/2)]\n    qubit = (IntQubit(0, nqubits=2) + IntQubit(3, nqubits=2))/sqrt(2)\n    assert measure_all(qubit) == [(IntQubit(0, nqubits=2), 1/2), (IntQubit(3, nqubits=2), 1/2)]\n    qubit = (IntQubit(1, nqubits=2) + IntQubit(2, nqubits=2))/sqrt(2)\n    assert measure_all(qubit) == [(IntQubit(1, nqubits=2), 1/2), (IntQubit(2, nqubits=2), 1/2)]\n    qubit = (IntQubit(1, nqubits=2) + IntQubit(3, nqubits=2))/sqrt("], "sample_926": ["def test_template_parameter_parsing():\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T t)', {"], "sample_588": ["    def test_combine_by_coords(self):\n        objs = [Dataset({\"x\": [0]}), Dataset({\"x\": [1]})]\n        actual = combine_by_coords(objs)\n        expected = Dataset({\"x\": [0, 1]})\n        assert_identical(expected, actual)\n\n        actual = combine_by_coords([actual])\n        assert_identical(expected, actual)\n\n        objs = [Dataset({\"x\": [0, 1]}), Dataset({\"x\": [2]})]\n        actual = combine_by_coords(objs)\n        expected = Dataset({\"x\": [0, 1, 2]})\n        assert_identical(expected, actual)\n\n        # ensure combine_by_coords handles non-sorted variables\n        objs = [\n            Dataset({\"x\": (\"a\", [0]), \"y\": (\"a\", [0]), \"a\": [0]}),\n            Dataset({\"x\": (\"a\", [1]), \"y\": (\"a\", [1]), \"a\": [1]}),\n        ]\n        actual = combine_by_coords(objs)\n        expected = Dataset({\"x\": (\"a\", [0, 1]), \"y\": (\"a\", [0, 1]), \"a\": [0, 1]})\n        assert_identical(expected, actual)\n\n        objs = [Dataset({\"x\": [0], \"y\": [0]}), Dataset({\"y\": [1], \"x\": [1]})]\n        actual = combine_by_coords(objs)\n        expected = Dataset({\"x\": [0, 1], \"y\": [0, 1]})\n        assert_equal(actual, expected)\n\n        objs = [Dataset({\"x\": 0}), Dataset({\"x\": 1})]\n        with raises_regex(ValueError, \"Could not find any dimension coordinates\"):\n            combine_by_coords(objs)\n\n        objs = [Dataset({\"x\": [0], \"y\": [0]}), Dataset({\"x\": [0]})]\n        with raises_regex(ValueError, \"Every dimension needs a coordinate\"):\n            combine_by_coords(objs)\n"], "sample_430": ["def test_alter_unique_together_with_renamed_field(self):\n    \"\"\"Fields are renamed before updating unique_together.\"\"\"\n    changes = self.get_changes(\n        [self.author_empty, self.book_unique_together_3],\n        [self.author_empty, self.book_unique_together_4],\n        MigrationQuestioner({\"ask_rename\": True}),\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(\n        changes,\n        \"otherapp\",\n        0,\n        [\"RenameField\", \"AlterUniqueTogether\"],\n    )\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        1,\n        name=\"book\",\n        unique_together={(\"title\", \"newfield2\")},\n    )\n"], "sample_958": ["def test_domain_cpp_ast_template_parameter_lists():\n    check('class', 'template<template<typename> typename T> {key}A',\n          {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> class T> {key}A',\n          {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> typename... T> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> class... T> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename... T> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> class... T> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename... T> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> class... T> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename... T> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> class... T> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename... T> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> class... T> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename... T> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> class... T> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename... T> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template"], "sample_1118": ["def test_matpow():\n    assert MatPow(C, 0).doit() == Identity(n)\n    assert MatPow(C, 1).doit() == C\n    assert MatPow(C, -1).doit() == C.I\n    assert MatPow(C, 2).doit() == C*C\n    assert MatPow(C, -2).doit() == C.I*C.I\n\n    assert MatPow(ZeroMatrix(n, n), 2).doit() == ZeroMatrix(n, n)\n    assert MatPow(ZeroMatrix(n, n), -1).doit() == ZeroMatrix(n, n)\n\n    raises(NonSquareMatrixError, lambda: MatPow(A, 2))\n    raises(NonInvertibleMatrixError, lambda: MatPow(ZeroMatrix(n, n), -1))\n\n    assert MatPow(C, 0).shape == (n, n)\n    assert MatPow(C, 1).shape == (n, n)\n    assert MatPow(C, -1).shape == (n, n)\n    assert MatPow(C, 2).shape == (n, n)\n    assert MatPow(C, -2).shape == (n, n)\n\n    assert MatPow(C, 0).T == MatPow(C.T, 0)\n    assert MatPow(C, 1).T == MatPow(C.T, 1)\n    assert MatPow(C, -1).T == MatPow(C.T, -1)\n    assert MatPow(C, 2).T == MatPow(C.T, 2)\n    assert MatPow(C, -2).T == MatPow(C.T, -2)\n"], "sample_959": ["def test_domain_cpp_ast_template_introductions():\n    check('class', 'template<template<typename> typename T> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> class T> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> typename> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> typename ...T> {key}A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename...> {key}A', {2: 'II0EDpE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I0I0EDpE1A'})\n    check('class', 'template<int> {key}A', {2: 'I_iE1A'})\n    check('class', 'template<int T> {key}A', {2: 'I_iE1A'})\n    check('class', 'template<int... T> {key}A', {2: 'I_DpiE1A'})\n    check('class', 'template<int T = 42> {key}A', {2: 'I_iE1A'})\n    check('class', 'template<int = 42> {key}A', {2: 'I_iE1A'})\n    check('class', 'template<typename A<B>::C> {key}A', {2: 'I_N1AI1BE1CEE1A'})\n    check('class', 'template<typename A<B>::C = 42> {key}A', {2: 'I_N1AI1BE1CEE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I0I0EDpE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I0I0EDpE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I0I0EDpE1A'})\n    check('class"], "sample_1141": ["def test_expr_free_symbols_deprecation():\n    from sympy.utilities.exceptions import SymPyDeprecationWarning\n    from sympy.abc import x, y\n    expr = x + y\n    with raises(SympifyError):\n        expr.expr_free_symbols\n    with raises(SympifyError):\n        expr.free_symbols\n"], "sample_1174": ["def test_periodic_argument_edge_cases():\n    from sympy import periodic_argument, oo, pi, I, exp_polar\n    assert periodic_argument(0, oo) == 0\n    assert periodic_argument(0, pi) == 0\n    assert periodic_argument(0, -pi) is None\n    assert periodic_argument(0, -oo) is None\n    assert periodic_argument(I, oo) == pi/2\n    assert periodic_argument(I, pi) == pi/2\n    assert periodic_argument(I, -pi) is None\n    assert periodic_argument(I, -oo) is None\n    assert periodic_argument(exp_polar(0), oo) == 0\n    assert periodic_argument(exp_polar(0), pi) == 0\n    assert periodic_argument(exp_polar(0), -pi) is None\n    assert periodic_argument(exp_polar(0), -oo) is None\n    assert periodic_argument(exp_polar(I*pi), oo) == pi\n    assert periodic_argument(exp_polar(I*pi), pi) == 0\n    assert periodic_argument(exp_polar(I*pi), -pi) is None\n    assert periodic_argument(exp_polar(I*pi), -oo) is None\n"], "sample_133": ["    def test_get_paths(self):\n        view = JavaScriptCatalog()\n        packages = ['django.contrib.admin', 'django.contrib.auth']\n        paths = view.get_paths(packages)\n        self.assertEqual(len(paths), 2)\n        self.assertIn('django/contrib/admin/locale', paths[0])\n        self.assertIn('django/contrib/auth/locale', paths[1])\n"], "sample_1057": ["def test_render_as_module():\n    content = Print(\"Hello, World!\")\n    result = render_as_module(content)\n    assert 'import sympy' in result\n    assert 'print(\"Hello, World!\")' in result\n"], "sample_828": ["def test_check_pairwise_arrays_precomputed():\n    # Ensure that check_pairwise_arrays works correctly with precomputed\n    # distance matrices.\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((5, 5))\n    X_checked, _ = check_pairwise_arrays(X, None, precomputed=True)\n    assert_array_equal(X, X_checked)\n\n    # Ensure that check_pairwise_arrays raises an error when the input is not\n    # square.\n    X = rng.random_sample((5, 4))\n    assert_raises(ValueError, check_pairwise_arrays, X, None, precomputed=True)\n\n    # Ensure that check_pairwise_arrays raises an error when the input contains\n    # negative values.\n    X = rng.random_sample((5, 5))\n    X[0, 0] = -1\n    assert_raises(ValueError, check_pairwise_arrays, X, None, precomputed=True)\n"], "sample_827": ["def test_csc_median_axis_0_empty():\n    # Test csc_median_axis_0 with empty matrix\n    csc = sp.csc_matrix((0, 5))\n    assert_array_equal(csc_median_axis_0(csc), np.full(5, np.nan))\n\n    # Test csc_median_axis_0 with matrix with zero columns\n    csc = sp.csc_matrix((5, 0))\n    assert_array_equal(csc_median_axis_0(csc), np.array([]))\n\n    # Test csc_median_axis_0 with matrix with zero rows and columns\n    csc = sp.csc_matrix((0, 0))\n    assert_array_equal(csc_median_axis_0(csc), np.array([]))\n"], "sample_154": ["    def test_database_checks_called_with_kwargs(self):\n        with mock.patch('django.db.backends.base.validation.BaseDatabaseValidation.check') as mocked_check:\n            kwargs = {'some_arg': 'some_value'}\n            check_database_backends(databases=self.databases, **kwargs)\n            mocked_check.assert_called_with(**kwargs)\n"], "sample_319": ["def test_alter_field_with_custom_deconstructible_default(self):\n    \"\"\"\n    Two instances which deconstruct to the same value aren't considered a\n    change, even if the default value is a custom deconstructible object.\n    \"\"\"\n    class CustomDefault:\n            self.value = value\n\n            return (self.__class__.__name__, (), {\"value\": self.value})\n\n    author_custom_default = ModelState(\n        \"testapp\",\n        \"Author\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=200, default=CustomDefault(\"Ada\"))),\n        ],\n    )\n    author_custom_default_2 = ModelState(\n        \"testapp\",\n        \"Author\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=200, default=CustomDefault(\"Ada\"))),\n        ],\n    )\n    changes = self.get_changes([author_custom_default], [author_custom_default_2])\n    self.assertEqual(changes, {})\n"], "sample_415": ["    def test_validate_expression_with_function(self):\n        constraint = models.UniqueConstraint(\n            Lower(\"name\"),\n            name=\"name_lower_uniq\",\n        )\n        msg = \"Constraint \u201cname_lower_uniq\u201d is violated.\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            constraint.validate(\n                UniqueConstraintProduct,\n                UniqueConstraintProduct(name=self.p1.name.upper()),\n            )\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=\"another-name\"),\n        )\n        # Existing instances have their existing row excluded.\n        constraint.validate(UniqueConstraintProduct, self.p1)\n        # Unique field is excluded.\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=self.p1.name.upper()),\n            exclude={\"name\"},\n        )\n"], "sample_826": ["def test_ordinal_encoder_unsorted_categories():\n    X = np.array([['a', 'b']], dtype=object).T\n\n    enc = OrdinalEncoder(categories=[['b', 'a', 'c']])\n    exp = np.array([[0.], [1.]])\n    assert_array_equal(enc.fit(X).transform(X), exp)\n    assert_array_equal(enc.fit_transform(X), exp)\n    assert enc.categories_[0].tolist() == ['b', 'a', 'c']\n    assert np.issubdtype(enc.categories_[0].dtype, np.object_)\n\n    # unsorted passed categories still raise for numerical values\n    X = np.array([[1, 2]]).T\n    enc = OrdinalEncoder(categories=[[2, 1, 3]])\n    msg = 'Unsorted categories are not supported'\n    with pytest.raises(ValueError, match=msg):\n        enc.fit_transform(X)\n"], "sample_781": ["def check_feature_importances(name):\n    # Check feature importances are correctly computed and normalized.\n    ForestEstimator = FOREST_ESTIMATORS[name]\n    est = ForestEstimator(n_estimators=10, random_state=0)\n    est.fit(X, y)\n\n    importances = est.feature_importances_\n    assert_array_almost_equal(importances.sum(), 1.0)\n    assert_array_almost_equal(importances, est.feature_importances_)\n\n"], "sample_195": ["    def setUp(self):\n        self.ops = DatabaseOperations(connection=connection)\n"], "sample_1152": ["def test_powsimp_edge_cases():\n    x, y, z = symbols('x y z')\n    assert powsimp(0**x) == 0\n    assert powsimp(1**x) == 1\n    assert powsimp((-1)**x) == (-1)**x\n    assert powsimp(x**0) == 1\n    assert powsimp(x**1) == x\n    assert powsimp(x**-1) == 1/x\n    assert powsimp(x**(1/2)) == sqrt(x)\n    assert powsimp(x**(1/3)) == root(x, 3)\n    assert powsimp(x**(2/3)) == root(x, 3)**2\n    assert powsimp(x**(3/2)) == sqrt(x)**3\n    assert powsimp(x**(4/3)) == root(x, 3)**4\n    assert powsimp(x**(5/2)) == sqrt(x)**5\n    assert powsimp(x**(6/3)) == x**2\n    assert powsimp(x**(7/2)) == sqrt(x)**7\n    assert powsimp(x**(8/3)) == root(x, 3)**8\n    assert powsimp(x**(9/2)) == sqrt(x)**9\n    assert powsimp(x**(10/3)) == x**10/root(x, 3)\n    assert powsimp(x**(11/2)) == sqrt(x)**11\n    assert powsimp(x**(12/3)) == x**4\n"], "sample_927": ["def test_template_parameter_lists():\n    check('function', 'template<typename T> void f(T)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T, T)', {2: 'I0E1f1T1T'})\n    check('function', 'template<typename T> void f(T, T, T)', {2: 'I0E1f1T1T1T'})\n    check('function', 'template<typename T, typename U> void f(T, U)', {2: 'I00E1f1T1U'})\n    check('function', 'template<typename T, typename U, typename V> void f(T, U, V)', {2: 'I000E1f1T1U1V'})\n    check('function', 'template<typename T, typename U, typename V, typename W> void f(T, U, V, W)', {2: 'I0000E1f1T1U1V1W'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X> void f(T, U, V, W, X)', {2: 'I00000E1f1T1U1V1W1X'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> void f(T, U, V, W, X, Y)', {2: 'I000000E1f1T1U1V1W1X1Y'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> void f(T, U, V, W, X, Y, Z)', {2: 'I0000000E1f1T1U1V1W1X1Y1Z'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A> void f(T, U, V, W, X, Y, Z, A)', {2: 'I00000000E1f1T1U1V1W1X1Y1Z1A'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z,"], "sample_132": ["    def test_technical_500_response(self):\n        request = RequestFactory().get('/')\n        exc_type = ValueError\n        exc_value = ValueError('Test exception')\n        tb = None\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html; charset=utf-8')\n"], "sample_731": ["def test_fetch_california_housing():\n    \"\"\"Test the california_housing loader.\"\"\"\n    data = fetch()\n    assert data.data.shape == (20640, 8)\n    assert data.target.shape == (20640,)\n    assert len(data.feature_names) == 8\n    assert data.DESCR == fetch_california_housing.__doc__\n"], "sample_603": ["def test_collapsible_section():\n    name = \"Test Section\"\n    inline_details = \"Inline details\"\n    details = \"Section details\"\n    n_items = 10\n    enabled = True\n    collapsed = False\n\n    formatted = fh.collapsible_section(\n        name, inline_details, details, n_items, enabled, collapsed\n    )\n    assert name in formatted\n    assert inline_details in formatted\n    assert details in formatted\n    assert str(n_items) in formatted\n    assert \"checked\" not in formatted\n\n    formatted = fh.collapsible_section(\n        name, inline_details, details, n_items, enabled, not collapsed\n    )\n    assert \"checked\" in formatted\n\n    formatted = fh.collapsible_section(\n        name, inline_details, details, n_items, not enabled, collapsed\n    )\n    assert \"disabled\" in formatted\n"], "sample_934": ["def test_struct_definitions():\n    check('struct', '{key}A', {1: \"A\", 2: \"1A\"}, output='{key}A')\n    check('struct', 'public {key}A', {1: \"A\", 2: \"1A\"}, output='{key}A')\n    check('struct', 'private {key}A', {1: \"A\", 2: \"1A\"}, output='{key}A')\n    check('struct', '{key}A : B', {1: \"A\", 2: \"1A\"}, output='{key}A : B')\n    check('struct', '{key}A : private B', {1: \"A\", 2: \"1A\"}, output='{key}A : private B')\n    check('struct', '{key}A : public B', {1: \"A\", 2: \"1A\"}, output='{key}A : public B')\n    check('struct', '{key}A : B, C', {1: \"A\", 2: \"1A\"}, output='{key}A : B, C')\n    check('struct', '{key}A : B, protected C, D', {1: \"A\", 2: \"1A\"}, output='{key}A : B, protected C, D')\n    check('struct', 'A : virtual private B', {1: 'A', 2: '1A'}, output='{key}A : private virtual B')\n    check('struct', '{key}A : private virtual B', {1: 'A', 2: '1A'}, output='{key}A : private virtual B')\n    check('struct', '{key}A : B, virtual C', {1: 'A', 2: '1A'}, output='{key}A : B, virtual C')\n    check('struct', '{key}A : public virtual B', {1: 'A', 2: '1A'}, output='{key}A : public virtual B')\n    check('struct', '{key}A : B...', {1: 'A', 2: '1A'}, output='{key}A : B...')\n    check('struct', '{key}A : B..., C', {1: 'A', 2: '1A'}, output='{key}A : B..., C')\n"], "sample_917": ["def test_template_parameter_lists():\n    check('class', 'template<template<int> class T> A', {2: 'II0E0E1A'})\n    check('class', 'template<template<int> typename T> A', {2: 'II0E0E1A'})\n    check('class', 'template<template<int> class T, int> A', {2: 'II0E_iE1A'})\n    check('class', 'template<template<int> typename T, int> A', {2: 'II0E_iE1A'})\n    check('class', 'template<template<int> class T, int, int> A', {2: 'II0E_i_iE1A'})\n    check('class', 'template<template<int> typename T, int, int> A', {2: 'II0E_i_iE1A'})\n    check('class', 'template<template<int> class T, int...> A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<int> typename T, int...> A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<int> class T, int, int...> A', {2: 'II0E_iDpE1A'})\n    check('class', 'template<template<int> typename T, int, int...> A', {2: 'II0E_iDpE1A'})\n    check('class', 'template<template<int> class T, int..., int> A', {2: 'II0Dp_iE1A'})\n    check('class', 'template<template<int> typename T, int..., int> A', {2: 'II0Dp_iE1A'})\n    check('class', 'template<template<int> class T, int..., int, int> A', {2: 'II0Dp_i_iE1A'})\n    check('class', 'template<template<int> typename T, int..., int, int> A', {2: 'II0Dp_i_iE1A'})\n    check('class', 'template<template<int> class T, int, int..., int> A', {2: 'II0E_iDp_iE1A'})\n    check('class', 'template<template<int> typename T,"], "sample_302": ["    def setUp(self):\n        self.client = DatabaseClient(connection=connection)\n"], "sample_732": ["def test_random_state():\n    data = fetch_kddcup99(subset='SA', random_state=42)\n    data2 = fetch_kddcup99(subset='SA', random_state=42)\n    assert_equal(data.data, data2.data)\n    assert_equal(data.target, data2.target)\n\n    data3 = fetch_kddcup99(subset='SA', random_state=43)\n    assert not np.array_equal(data.data, data3.data)\n    assert not np.array_equal(data.target, data3.target)\n"], "sample_575": ["    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n"], "sample_924": ["def test_template_parameter_lists():\n    check('function', 'template<typename T> void f(T)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T, T)', {2: 'I0E1f1T1T'})\n    check('function', 'template<typename T> void f(T, T, T)', {2: 'I0E1f1T1T1T'})\n    check('function', 'template<typename T, typename U> void f(T, U)', {2: 'I00E1f1T1U'})\n    check('function', 'template<typename T, typename U, typename V> void f(T, U, V)', {2: 'I000E1f1T1U1V'})\n    check('function', 'template<typename T, typename U, typename V, typename W> void f(T, U, V, W)', {2: 'I0000E1f1T1U1V1W'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X> void f(T, U, V, W, X)', {2: 'I00000E1f1T1U1V1W1X'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> void f(T, U, V, W, X, Y)', {2: 'I000000E1f1T1U1V1W1X1Y'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> void f(T, U, V, W, X, Y, Z)', {2: 'I0000000E1f1T1U1V1W1X1Y1Z'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A> void f(T, U, V, W, X, Y, Z, A)', {2: 'I00000000E1f1T1U1V1W1X1Y1Z1A'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z,"], "sample_279": ["def test_unique_constraint_fields_and_opclasses_length_mismatch(self):\n    message = 'UniqueConstraint.fields and UniqueConstraint.opclasses must have the same number of elements.'\n    with self.assertRaisesMessage(ValueError, message):\n        models.UniqueConstraint(\n            fields=['name', 'color'],\n            name='name_color_unique',\n            opclasses=['text_pattern_ops'],\n        )\n"], "sample_611": ["compilation error"], "sample_1063": ["def test_issue_16930_beta():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    x = symbols(\"x\")\n    y = symbols(\"y\")\n    f = lambda x, y:  S.GoldenRatio * x**2 * y**2\n    f_ = lambdify((x, y), f(x, y), modules='scipy')\n    assert f_(1, 2) == scipy.constants.golden_ratio * 4\n"], "sample_947": ["def test_build_domain_c_alias(app, status, warning):\n    app.builder.build_all()\n    ws = filter_warnings(warning, \"alias\")\n    assert len(ws) == 0\n    entries = extract_role_links(app, \"alias.html\")\n    assert entries == [\n        ('c.alias.A', 'A', 'A'),\n        ('c.alias.B', 'B', 'B'),\n        ('c.alias.C', 'C', 'C'),\n        ('c.alias.D', 'D', 'D'),\n        ('c.alias.E', 'E', 'E'),\n        ('c.alias.F', 'F', 'F'),\n        ('c.alias.G', 'G', 'G'),\n        ('c.alias.H', 'H', 'H'),\n        ('c.alias.I', 'I', 'I'),\n        ('c.alias.J', 'J', 'J'),\n        ('c.alias.K', 'K', 'K'),\n        ('c.alias.L', 'L', 'L'),\n        ('c.alias.M', 'M', 'M'),\n        ('c.alias.N', 'N', 'N'),\n        ('c.alias.O', 'O', 'O'),\n        ('c.alias.P', 'P', 'P'),\n        ('c.alias.Q', 'Q', 'Q'),\n        ('c.alias.R', 'R', 'R'),\n        ('c.alias.S', 'S', 'S'),\n        ('c.alias.T', 'T', 'T'),\n        ('c.alias.U', 'U', 'U'),\n        ('c.alias.V', 'V', 'V'),\n        ('c.alias.W', 'W', 'W'),\n        ('c.alias.X', 'X', 'X'),\n        ('c.alias.Y', 'Y', 'Y'),\n        ('c.alias.Z', 'Z', 'Z'),\n    ]\n"], "sample_1068": ["def test_octave_Infinity():\n    assert mcode(S.Infinity) == \"inf\"\n    assert mcode(S.NegativeInfinity) == \"-inf\"\n    assert mcode(S.Infinity + x) == \"inf + x\"\n    assert mcode(S.Infinity * x) == \"inf.*x\"\n    assert mcode(S.Infinity / x) == \"inf./x\"\n    assert mcode(x / S.Infinity) == \"x/inf\"\n    assert mcode(S.Infinity ** x) == \"inf.^x\"\n    assert mcode(x ** S.Infinity) == \"x.^inf\"\n"], "sample_1117": ["def test_lower_triangular():\n    assert ask(Q.lower_triangular(X + Z.T + Identity(2)), Q.lower_triangular(X) &\n            Q.upper_triangular(Z)) is True\n    assert ask(Q.lower_triangular(X*Z.T), Q.lower_triangular(X) &\n            Q.upper_triangular(Z)) is True\n    assert ask(Q.lower_triangular(Identity(3))) is True\n    assert ask(Q.lower_triangular(ZeroMatrix(3, 3))) is True\n    assert ask(Q.lower_triangular(OneMatrix(1, 1))) is True\n    assert ask(Q.lower_triangular(OneMatrix(3, 3))) is False\n    assert ask(Q.triangular(X), Q.unit_triangular(X))\n    assert ask(Q.lower_triangular(X**3), Q.lower_triangular(X))\n    assert ask(Q.lower_triangular(X), Q.lower_triangular(X))\n    assert ask(Q.lower_triangular(X), Q.upper_triangular(X)) is False\n    assert ask(Q.lower_triangular(X), Q.lower_triangular(X) & Q.upper_triangular(X)) is True\n    assert ask(Q.lower_triangular(X), Q.lower_triangular(X) & ~Q.upper_triangular(X)) is True\n"], "sample_723": ["def test_imputation_most_frequent_sparse():\n    # Test imputation using the most-frequent strategy with sparse matrices.\n    X = sparse.csc_matrix(np.array([\n        [-1, -1, 0, 5],\n        [-1, 2, -1, 3],\n        [-1, 1, 3, -1],\n        [-1, 2, 3, 7],\n    ]))\n\n    X_true = np.array([\n        [2, 0, 5],\n        [2, 3, 3],\n        [1, 3, 3],\n        [2, 3, 7],\n    ])\n\n    # scipy.stats.mode, used in SimpleImputer, doesn't return the first most\n    # frequent as promised in the doc but the lowest most frequent. When this\n    # test will fail after an update of scipy, SimpleImputer will need to be\n    # updated to be consistent with the new (correct) behaviour\n    _check_statistics(X, X_true, \"most_frequent\", [np.nan, 2, 3, 3], -1)\n"], "sample_1125": ["def test_operator():\n    A = Operator('A')\n    B = Operator('B')\n    assert A.is_commutative is False\n    assert B.is_commutative is False\n    assert A*B != B*A\n\n    assert A.inv() == A**(-1)\n    assert A*A.inv() == 1\n\n    I = IdentityOperator()\n    assert I.dimension == oo\n    assert I._eval_commutator(A) == 0\n    assert I._eval_anticommutator(A) == 2*A\n    assert I._apply_operator(A) == A\n    assert I._eval_inverse() == I\n    assert I._eval_adjoint() == I\n    assert I._eval_power(2) == I\n"], "sample_309": ["    def test_absolute_path(self):\n        self.assertEqual(escape_leading_slashes('//path/to/resource'), '/%2Fpath/to/resource')\n"], "sample_1037": ["def test_MatMul_as_coeff_matrices():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    D = MatrixSymbol('D', 2, 2)\n\n    # Test with scalar\n    expr = 2 * A * B\n    coeff, matrices = expr.as_coeff_matrices()\n    assert coeff == 2\n    assert matrices == [A, B]\n\n    # Test with multiple scalars\n    expr = 2 * 3 * A * B\n    coeff, matrices = expr.as_coeff_matrices()\n    assert coeff == 6\n    assert matrices == [A, B]\n\n    # Test with multiple matrices\n    expr = A * B * C * D\n    coeff, matrices = expr.as_coeff_matrices()\n    assert coeff == 1\n    assert matrices == [A, B, C, D]\n\n    # Test with non-commutative scalars\n    expr = A * B * C * D\n    coeff, matrices = expr.as_coeff_matrices()\n    assert coeff == 1\n    assert matrices == [A, B, C, D]\n\n    # Test with non-commutative scalars and commutative scalars\n    expr = 2 * A * B * C * D\n    coeff, matrices = expr.as_coeff_matrices()\n    assert coeff == 2\n    assert matrices == [A, B, C, D]\n"], "sample_431": ["    def test_save_with_deferred_fields(self):\n        a = Article.objects.create(headline=\"Article 1\", pub_date=datetime.now())\n        a_deferred = Article.objects.defer(\"headline\").get(id=a.id)\n        self.assertEqual(a_deferred.headline, \"Article 1\")\n        a_deferred.save()\n        self.assertEqual(Article.objects.get(id=a.id).headline, \"Article 1\")\n"], "sample_604": ["def test_summarize_variable():\n    var = xr.Variable(\"x\", np.arange(100), dims=\"x\")\n    col_width = 10\n    actual = formatting.summarize_variable(\"x\", var, col_width)\n    expected = \"  x        (x) int64 0 ... 99\"\n    assert actual == expected\n\n    var = xr.Variable(\"x\", np.arange(100), dims=\"x\", attrs={\"units\": \"m\"})\n    col_width = 10\n    actual = formatting.summarize_variable(\"x\", var, col_width)\n    expected = \"  x        (x) int64 0 ... 99\"\n    assert actual == expected\n\n    var = xr.Variable(\"x\", np.arange(100), dims=\"x\", attrs={\"units\": \"m\", \"description\": \"desc\"})\n    col_width = 10\n    actual = formatting.summarize_variable(\"x\", var, col_width)\n    expected = \"  x        (x) int64 0 ... 99\"\n    assert actual == expected\n"], "sample_916": ["def test_template_parameter_parsing():\n    check('function', 'template<typename T> void f(T)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T, T)', {2: 'I0E1f1T1T'})\n    check('function', 'template<typename T> void f(T, T, T)', {2: 'I0E1f1T1T1T'})\n    check('function', 'template<typename T, typename U> void f(T, U)', {2: 'I00E1f1T1U'})\n    check('function', 'template<typename T, typename U, typename V> void f(T, U, V)', {2: 'I000E1f1T1U1V'})\n    check('function', 'template<typename T, typename U, typename V, typename W> void f(T, U, V, W)', {2: 'I0000E1f1T1U1V1W'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X> void f(T, U, V, W, X)', {2: 'I00000E1f1T1U1V1W1X'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> void f(T, U, V, W, X, Y)', {2: 'I000000E1f1T1U1V1W1X1Y'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> void f(T, U, V, W, X, Y, Z)', {2: 'I0000000E1f1T1U1V1W1X1Y1Z'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename AA> void f(T, U, V, W, X, Y, Z, AA)', {2: 'I00000000E1f1T1U1V1W1X1Y1Z1AA'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z"], "sample_1159": ["def test_issue_17556_ext():\n    z = I*oo\n    assert z.is_extended_positive is False\n    assert z.is_extended_negative is False\n    assert z.is_extended_nonpositive is False\n    assert z.is_extended_nonnegative is False\n    assert z.is_extended_nonzero is True\n"], "sample_1173": ["def test_implicit_multiplication_application():\n    transformations = standard_transformations + \\\n                      (implicit_multiplication_application,)\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z')\n    f = Function('f')\n\n    assert parse_expr(\"f(x)g(y)\", transformations=transformations) == f(x)*f(y)\n    assert parse_expr(\"f(x)g(y)z\", transformations=transformations) == f(x)*f(y)*z\n    assert parse_expr(\"f(x)g(y)z^2\", transformations=transformations) == f(x)*f(y)*z**2\n    assert parse_expr(\"f(x)g(y)z^2w\", transformations=transformations) == f(x)*f(y)*z**2*w\n    assert parse_expr(\"f(x)g(y)z^2w^3\", transformations=transformations) == f(x)*f(y)*z**2*w**3\n    assert parse_expr(\"f(x)g(y)z^2w^3v\", transformations=transformations) == f(x)*f(y)*z**2*w**3*v\n    assert parse_expr(\"f(x)g(y)z^2w^3v^4\", transformations=transformations) == f(x)*f(y)*z**2*w**3*v**4\n    assert parse_expr(\"f(x)g(y)z^2w^3v^4u\", transformations=transformations) == f(x)*f(y)*z**2*w**3*v**4*u\n    assert parse_expr(\"f(x)g(y)z^2w^3v^4u^5\", transformations=transformations) == f(x)*f(y)*z**2*w**3*v**4*u**5\n    assert parse_expr(\"f(x)g(y)z^2w^3v^4u^5t\", transformations=transformations) == f(x)*f(y)*z**2*w**3*v**4*u**5*t\n    assert parse_expr(\"f(x)g(y)z^2w^3v^4u^5t^6\", transformations=transformations) == f(x)*f(y)*z**2*w**3*v**4*u**5*t**6\n    assert parse_expr(\"f(x)g(y)z^2w^3v^4u^5t^"], "sample_1026": ["def test_lambdify_kwargs():\n    f = lambdify(x, x**2, modules=\"sympy\")\n    assert f(x=2) == 4\n    raises(TypeError, lambda: f(2, x=2))\n    raises(TypeError, lambda: f(x=2, y=2))\n"], "sample_437": ["    def test_validate_thread_sharing(self):\n        conn = connections[DEFAULT_DB_ALIAS]\n        conn._thread_ident = 123\n        with self.assertRaises(DatabaseError):\n            conn.validate_thread_sharing()\n"], "sample_1155": ["def test_golden_ratio_and_catalan():\n    alg = QQ.algebraic_field(GoldenRatio)\n    assert construct_domain([7, S.Half, GoldenRatio], extension=True) == \\\n        (alg, [alg.convert(7), alg.convert(S.Half), alg.convert(GoldenRatio)])\n\n    alg = QQ.algebraic_field(Catalan)\n    assert construct_domain([7, S.Half, Catalan], extension=True) == \\\n        (alg, [alg.convert(7), alg.convert(S.Half), alg.convert(Catalan)])\n\n    alg = QQ.algebraic_field(GoldenRatio + Catalan)\n    assert construct_domain([7, GoldenRatio, Catalan], extension=True) == \\\n        (alg, [alg.convert(7), alg.convert(GoldenRatio), alg.convert(Catalan)])\n"], "sample_1036": ["def test_mul_as_coeff_Mul():\n    assert (2*x).as_coeff_Mul() == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (-2*x).as_coeff_Mul() == (-1, 2*x)\n    assert (-2*x).as_coeff_Mul(rational=False) == (-1, 2*x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul() == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul() == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul() == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul() == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul() == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul() == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul() == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul() == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul() == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul() == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul() == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == ("], "sample_1058": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n    assert not prntr.module_imports\n\n    assert prntr.doprint(pi) == 'math.pi'\n    assert prntr.module_imports == {'math': {'pi'}}\n\n    assert prntr.doprint(x**Rational(1, 2)) == 'math.sqrt(x)'\n    assert prntr.doprint(sqrt(x)) == 'math.sqrt(x)'\n    assert prntr.module_imports == {'math': {'pi', 'sqrt'}}\n\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n\n    assert prntr.doprint(Infinity) == \"float('inf')\"\n    assert prntr.doprint(NegativeInfinity) == \"float('-inf')\"\n    assert prntr.doprint(ComplexInfinity) == \"float('nan')\"\n"], "sample_586": ["def test_concat_positions_kwarg():\n    ds1 = Dataset({\"a\": (\"x\", [1, 2])}, {\"x\": [0, 1]})\n    ds2 = Dataset({\"a\": (\"x\", [3, 4])}, {\"x\": [0, 1]})\n    expected = Dataset({\"a\": ((\"y\", \"x\"), [[1, 2], [3, 4]])}, {\"x\": [0, 1], \"y\": [0, 1]})\n    actual = concat([ds1, ds2], dim=\"y\", positions=[0, 1])\n    assert_identical(expected, actual)\n\n    with raises_regex(ValueError, \"Length of positions does not match\"):\n        concat([ds1, ds2], dim=\"y\", positions=[0])\n\n    with raises_regex(ValueError, \"Positions must be unique\"):\n        concat([ds1, ds2], dim=\"y\", positions=[0, 0])\n"], "sample_780": ["def test_lda_transform_non_fitted():\n    # test transform before fit\n    rng = np.random.RandomState(0)\n    X = rng.randint(4, size=(20, 10))\n    lda = LatentDirichletAllocation()\n    regex = (\"This LatentDirichletAllocation instance is not fitted yet. \"\n             \"Call 'fit' with appropriate arguments before using this method.\")\n    assert_raises_regexp(NotFittedError, regex, lda.transform, X)\n"], "sample_1069": ["def test_glsl_code():\n    # Test GLSL code generation\n    assert glsl_code(x**2) == \"pow(x, 2.0)\"\n    assert glsl_code(sin(x)) == \"sin(x)\"\n    assert glsl_code(cos(x)) == \"cos(x)\"\n    assert glsl_code(tan(x)) == \"tan(x)\"\n    assert glsl_code(exp(x)) == \"exp(x)\"\n    assert glsl_code(log(x)) == \"log(x)\"\n    assert glsl_code(sqrt(x)) == \"sqrt(x)\"\n    assert glsl_code(x + y) == \"add(x, y)\"\n    assert glsl_code(x - y) == \"sub(x, y)\"\n    assert glsl_code(x * y) == \"mul(x, y)\"\n    assert glsl_code(x / y) == \"div(x, y)\"\n\n    # Test GLSL code generation with assign_to\n    assert glsl_code(x**2, assign_to=\"float result\") == \"float result = pow(x, 2.0);\"\n    assert glsl_code(sin(x), assign_to=\"float result\") == \"float result = sin(x);\"\n\n    # Test GLSL code generation with use_operators=False\n    assert glsl_code(x + y, use_operators=False) == \"add(x, y)\"\n    assert glsl_code(x - y, use_operators=False) == \"sub(x, y)\"\n    assert glsl_code(x * y, use_operators=False) == \"mul(x, y)\"\n    assert glsl_code(x / y, use_operators=False) == \"div(x, y)\"\n\n    # Test GLSL code generation with glsl_types=False\n    assert glsl_code(Matrix([1, 2, 3]), glsl_types=False) == \"float[3](1, 2, 3)\"\n    assert glsl_code(Matrix([[1, 2], [3, 4]]), glsl_types=False) == \"float[4](1, 2, 3, 4)\"\n\n    # Test GLSL code generation with mat_nested=True\n    assert glsl_code(Matrix([[1, 2], [3, 4]]), mat_nested=True) == \"float[2][2](float[](1, 2), float[](3, 4))\"\n\n    # Test GLSL code generation with mat_transpose=True\n    assert glsl_code(Matrix([[1, 2], [3"], "sample_874": ["def test_clone():\n    # Test cloning of a simple estimator\n    estimator = StepSelector(step=3)\n    cloned_estimator = BaseEstimator.clone(estimator)\n    assert cloned_estimator.step == 3\n\n    # Test cloning of a fitted estimator\n    estimator.fit(X, y)\n    cloned_estimator = BaseEstimator.clone(estimator)\n    assert cloned_estimator.step == 3\n    assert cloned_estimator.n_features_in_ == 10\n\n    # Test cloning of a list of estimators\n    estimators = [StepSelector(step=2), StepSelector(step=3)]\n    cloned_estimators = BaseEstimator.clone(estimators)\n    assert len(cloned_estimators) == 2\n    assert cloned_estimators[0].step == 2\n    assert cloned_estimators[1].step == 3\n\n    # Test cloning of a tuple of estimators\n    estimators = (StepSelector(step=2), StepSelector(step=3))\n    cloned_estimators = BaseEstimator.clone(estimators)\n    assert len(cloned_estimators) == 2\n    assert cloned_estimators[0].step == 2\n    assert cloned_estimators[1].step == 3\n\n    # Test cloning of a set of estimators\n    estimators = {StepSelector(step=2), StepSelector(step=3)}\n    cloned_estimators = BaseEstimator.clone(estimators)\n    assert len(cloned_estimators) == 2\n    assert cloned_estimators.pop().step in [2, 3]\n    assert cloned_estimators.pop().step in [2, 3]\n\n    # Test cloning of an estimator with a non-estimator attribute\n    estimator = StepSelector(step=3)\n    estimator.non_estimator_attr = \"test\"\n    cloned_estimator = BaseEstimator.clone(estimator, safe=False)\n    assert cloned_estimator.step == 3\n    assert cloned_estimator.non_estimator_attr == \"test\"\n\n    # Test cloning of an estimator with a non-estimator attribute and safe=True\n    estimator = StepSelector(step=3)\n    estimator.non_estimator_attr = \"test\"\n    with pytest.raises(TypeError):\n        BaseEstimator.clone(estimator, safe=True)\n"], "sample_1142": ["def test_matrix_element_as_explicit():\n    A = MatrixSymbol('A', 2, 2)\n    assert A[0, 0].as_explicit() == ImmutableMatrix([[1, 0], [0, 0]])\n    assert A[0, 1].as_explicit() == ImmutableMatrix([[0, 1], [0, 0]])\n    assert A[1, 0].as_explicit() == ImmutableMatrix([[0, 0], [1, 0]])\n    assert A[1, 1].as_explicit() == ImmutableMatrix([[0, 0], [0, 1]])\n"], "sample_825": ["def test_pls_algorithm():\n    # Test that the algorithm parameter is correctly validated\n    d = load_linnerud()\n    X = d.data\n    Y = d.target\n    for clf in [pls_.PLSCanonical(), pls_.PLSRegression()]:\n        clf.algorithm = \"invalid\"\n        assert_raise_message(ValueError, \"Got algorithm invalid when only\",\n                             clf.fit, X, Y)\n        clf.algorithm = \"svd\"\n        clf.mode = \"B\"\n        assert_raise_message(ValueError, \"Incompatible configuration: mode B\",\n                             clf.fit, X, Y)\n"], "sample_976": ["def test_var():\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z')\n\n    assert var('x') == x\n    assert var('x ') == x\n    assert var(' x ') == x\n    assert var('x,') == (x,)\n    assert var('x, ') == (x,)\n    assert var('x ,') == (x,)\n\n    assert var('x , y') == (x, y)\n\n    assert var('x,y,z') == (x, y, z)\n    assert var('x y z') == (x, y, z)\n\n    assert var('x,y,z,') == (x, y, z)\n    assert var('x y z ') == (x, y, z)\n\n    xyz = Symbol('xyz')\n    abc = Symbol('abc')\n\n    assert var('xyz') == xyz\n    assert var('xyz,') == (xyz,)\n    assert var('xyz,abc') == (xyz, abc)\n\n    assert var(('xyz',)) == (xyz,)\n    assert var(('xyz,',)) == ((xyz,),)\n    assert var(('x,y,z,',)) == ((x, y, z),)\n    assert var(('xyz', 'abc')) == (xyz, abc)\n    assert var(('xyz,abc',)) == ((xyz, abc),)\n    assert var(('xyz,abc', 'x,y,z')) == ((xyz, abc), (x, y, z))\n\n    assert var(('x', 'y', 'z')) == (x, y, z)\n    assert var(['x', 'y', 'z']) == [x, y, z]\n    assert var(set(['x', 'y', 'z'])) == set([x, y, z])\n\n    raises(ValueError, lambda: var(''))\n    raises(ValueError, lambda: var(','))\n    raises(ValueError, lambda: var('x,,y,,z'))\n    raises(ValueError, lambda: var(('x', '', 'y', '', 'z')))\n\n    a, b = var('x,y', real=True)\n    assert a.is_real and b.is_real\n\n    x0 = Symbol('x0')\n    x1 = Symbol('x1')\n    x2 = Symbol('x2')\n\n    y0 = Symbol('y0')\n    y1 = Symbol('y1')\n\n    assert var('x0:0') == ()\n    assert var('x0"], "sample_948": ["def test_template_parameter_lists():\n    check('function', 'template<typename T> void f(T)', {2: '1f1T'})\n    check('function', 'template<typename T, typename U> void f(T, U)', {2: '1f1T1U'})\n    check('function', 'template<typename T, typename U, typename V> void f(T, U, V)', {2: '1f1T1U1V'})\n    check('function', 'template<typename T, typename U, typename V, typename W> void f(T, U, V, W)', {2: '1f1T1U1V1W'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X> void f(T, U, V, W, X)', {2: '1f1T1U1V1W1X'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> void f(T, U, V, W, X, Y)', {2: '1f1T1U1V1W1X1Y'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> void f(T, U, V, W, X, Y, Z)', {2: '1f1T1U1V1W1X1Y1Z'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A> void f(T, U, V, W, X, Y, Z, A)', {2: '1f1T1U1V1W1X1Y1Z1A'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A, typename B> void f(T, U, V, W, X, Y, Z, A, B)', {2: '1f1T1U1V1W1X1Y1Z1A1B'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A, typename B, typename C> void f(T, U, V"], "sample_303": ["def test_runshell(self):\n    with mock.patch.object(self.client, 'settings_to_cmd_args_env') as mock_settings_to_cmd_args_env:\n        mock_settings_to_cmd_args_env.return_value = (['mock_args'], {'mock_env': 'mock_value'})\n        with mock.patch('subprocess.run') as mock_subprocess_run:\n            self.client.runshell(parameters=None)\n            mock_settings_to_cmd_args_env.assert_called_once_with(self.client.connection.settings_dict, None)\n            mock_subprocess_run.assert_called_once_with(['mock_args'], env={'mock_env': 'mock_value', **os.environ}, check=True)\n"], "sample_1126": ["def test_dagger_addition():\n    A = Operator('A')\n    B = Operator('B')\n    assert Dagger(A + B) == Dagger(A) + Dagger(B)\n    assert Dagger(A + 2) == Dagger(A) + 2\n    assert Dagger(2 + A) == 2 + Dagger(A)\n    assert Dagger(A + I) == Dagger(A) - I\n"], "sample_1116": ["def test_derivative_matrix_lines():\n    x = symbols('x')\n    M = MatrixSymbol('M', 2, 2)\n    M_inv = Inverse(M)\n    lines = M_inv._eval_derivative_matrix_lines(x)\n    assert len(lines) == 4\n    for line in lines:\n        assert line.first_pointer.is_Mul\n        assert line.second_pointer.is_Inverse\n"], "sample_1034": ["def test_apply_grover():\n    nbits = 2\n    f = lambda qubits: qubits == IntQubit(2, nqubits=nbits)\n    assert qapply(apply_grover(f, nbits)) == IntQubit(2, nqubits=nbits)\n\n    nbits = 3\n    f = lambda qubits: qubits == IntQubit(5, nqubits=nbits)\n    assert qapply(apply_grover(f, nbits)) == IntQubit(5, nqubits=nbits)\n\n    nbits = 4\n    f = lambda qubits: qubits == IntQubit(10, nqubits=nbits)\n    assert qapply(apply_grover(f, nbits)) == IntQubit(10, nqubits=nbits)\n\n    # Test with a specified number of iterations\n    nbits = 2\n    f = lambda qubits: qubits == IntQubit(2, nqubits=nbits)\n    assert qapply(apply_grover(f, nbits, iterations=1)) == IntQubit(2, nqubits=nbits)\n\n    # Test with an invalid number of qubits\n    try:\n        apply_grover(f, 0)\n        assert False, \"Expected QuantumError\"\n    except QuantumError:\n        pass\n"], "sample_1106": ["def test_matadd_doit():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    X = MatAdd(A, B, C)\n    assert X.doit().args == (A, B, C)\n    assert MatAdd(A, 2*B, C).doit().args == (A, 2*B, C)\n    assert MatAdd(A, B, 2*C).doit().args == (A, B, 2*C)\n    assert MatAdd(2*A, B, C).doit().args == (2*A, B, C)\n    assert MatAdd(A, B, C).doit(deep=False).args == (A, B, C)\n"], "sample_779": ["def test_check_class_weight_balanced_classifiers():\n    # test that class_weight='balanced' is correctly computed\n    # for classifiers with non-contiguous class labels\n    check_class_weight_balanced_linear_classifier(\n        \"SVC\", SVC)\n    check_class_weight_balanced_linear_classifier(\n        \"LinearSVC\", LinearSVC)\n"], "sample_454": ["    def test_eq(self):\n        constraint1 = models.ExclusionConstraint(\n            expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n            name=\"exclusion\",\n        )\n        constraint2 = models.ExclusionConstraint(\n            expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n            name=\"exclusion\",\n        )\n        self.assertEqual(constraint1, constraint2)\n        self.assertEqual(constraint1, mock.ANY)\n        self.assertNotEqual(constraint1, models.ExclusionConstraint(\n            expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n            name=\"exclusion2\",\n        ))\n        self.assertNotEqual(constraint1, models.ExclusionConstraint(\n            expressions=[(\"field1\", \"~~\"), (\"field2\", \"&&\")],\n            name=\"exclusion\",\n        ))\n        self.assertNotEqual(constraint1, models.ExclusionConstraint(\n            expressions=[(\"field1\", \"&&\"), (\"field3\", \"~~\")],\n            name=\"exclusion\",\n        ))\n        self.assertNotEqual(constraint1, 1)\n        self.assertNotEqual(constraint1, models.ExclusionConstraint(\n            expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n            name=\"exclusion\",\n            violation_error_message=\"custom error\",\n        ))\n        self.assertNotEqual(models.ExclusionConstraint(\n            expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n            name=\"exclusion\",\n            violation_error_message=\"custom error\",\n        ), models.ExclusionConstraint(\n            expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n            name=\"exclusion\",\n            violation_error_message=\"other custom error\",\n        ))\n        self.assertEqual(models.ExclusionConstraint(\n            expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n            name=\"exclusion\",\n            violation_error_message=\"custom error\",\n        ), models.ExclusionConstraint(\n            expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n            name=\"exclusion\",\n            violation_error_message=\"custom error\",\n        ))\n        self.assertNotEqual(models.ExclusionConstraint(\n            expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n            name=\"exclusion\",\n            violation_error_code=\"custom_code\",\n        ), models.ExclusionConstraint(\n            expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")"], "sample_1076": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n\n    assert prntr._print_Infinity(oo) == \"float('inf')\"\n    assert prntr._print_NegativeInfinity(-oo) == \"float('-inf')\"\n    assert prntr._print_NaN(zoo) == \"float('nan')\"\n    assert prntr._print_ComplexInfinity(zoo) == \"float('nan')\"\n\n    assert prntr._print_Not(Expr()) == \"not ()\"\n    assert prntr._print_Indexed(IndexedBase(\"x\")) == \"x[]\"\n\n    assert prntr._print_FunctionDefinition(None) == \"\"\n\n    assert prntr._print_While(None) == \"\"\n\n    assert prntr._print_Declaration(None) == \"\"\n\n    assert prntr._print_Return(None) == \"\"\n\n    assert prntr._print_Print(None) == \"\"\n\n    assert prntr._print_Stream(None) == \"\"\n\n    assert prntr._print_NoneToken(None) == \"None\"\n"], "sample_243": ["def test_is_nullable(self):\n    query = Query(Item)\n    self.assertTrue(query.is_nullable(Item._meta.get_field('name')))\n    self.assertFalse(query.is_nullable(Item._meta.get_field('id')))\n"], "sample_1158": ["def test_sympify_numpy_array_with_object_dtype():\n    if not numpy:\n        skip(\"numpy not installed.\")\n\n    a = numpy.array([1, 2, 3], dtype=object)\n    b = sympify(a)\n    assert isinstance(b, ImmutableDenseNDimArray)\n    assert b.shape == (3,)\n    assert b.dtype == object\n    assert b[0] == 1\n    assert b[1] == 2\n    assert b[2] == 3\n\n    c = numpy.array([[1, 2], [3, 4]], dtype=object)\n    d = sympify(c)\n    assert isinstance(d, ImmutableDenseNDimArray)\n    assert d.shape == (2, 2)\n    assert d.dtype == object\n    assert d[0, 0] == 1\n    assert d[0, 1] == 2\n    assert d[1, 0] == 3\n    assert d[1, 1] == 4\n"], "sample_1005": ["def test_latex_Quaternion():\n    q = Quaternion(1, 2, 3, 4)\n    assert latex(q) == \"1 + 2 i + 3 j + 4 k\"\n    q = Quaternion(1, 2, 3, 4, real=False)\n    assert latex(q) == \"1 + 2 i + 3 j + 4 k\"\n    q = Quaternion(1, 2, 3, 4, real=True)\n    assert latex(q) == \"1 + 2 i + 3 j + 4 k\"\n"], "sample_973": ["def test_isabstractmethod():\n    class AbstractClass:\n        @abstractmethod\n            pass\n\n    class ConcreteClass(AbstractClass):\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(ConcreteClass.abstract_method) is False\n"], "sample_906": ["def test_domain_cpp_ast_template_parameter_lists():\n    check('class', 'template<template<typename> typename T> {key}A',\n          {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> class T> {key}A',\n          {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> typename... T> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename...> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename T = Test> {key}A',\n          {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> class T = Test> {key}A',\n          {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> typename... T = Test> {key}A',\n          {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename...> {key}A',\n          {2: 'II0EDpE1A'})\n\n    check('class', 'template<template<typename> typename T, template<typename> typename U> {key}A',\n          {2: 'II0E0EII0E0E1A'})\n    check('class', 'template<template<typename> typename T, template<typename> class U> {key}A',\n          {2: 'II0E0EII0E0E1A'})\n    check('class', 'template<template<typename> typename T, template<typename> typename... U> {key}A',\n          {2: 'II0E0EII0EDpE1A'})\n    check('class', 'template<template<typename> typename T, template<typename> typename...> {key}A',\n          {2: 'II0E0EII0EDpE1A'})\n    check('class', 'template<template<typename> typename T, template<typename> typename U = Test> {key}A',\n          {2: 'II0E0EII0E0E1A'})\n    check('class', 'template<template<typename> typename T, template<typename> class"], "sample_843": ["def test_kernel_bounds(kernel):\n    # Check that kernel bounds are correctly set and retrieved.\n\n    # Test get_params()\n    params = kernel.get_params()\n    for hyperparameter in kernel.hyperparameters:\n        if isinstance(\"string\", type(hyperparameter.bounds)):\n            if hyperparameter.bounds == \"fixed\":\n                continue\n        assert_array_almost_equal(hyperparameter.bounds,\n                                  params[hyperparameter.name + \"_bounds\"])\n\n    # Test set_params()\n    for hyperparameter in kernel.hyperparameters:\n        if isinstance(\"string\", type(hyperparameter.bounds)):\n            if hyperparameter.bounds == \"fixed\":\n                continue\n        new_bounds = (hyperparameter.bounds[0] + 1, hyperparameter.bounds[1] + 1)\n        kernel.set_params(**{hyperparameter.name + \"_bounds\": new_bounds})\n        assert_array_almost_equal(kernel.bounds,\n                                  np.log(np.vstack([h.bounds\n                                                     for h in kernel.hyperparameters\n                                                     if not h.fixed])))\n"]}, "raw_scored_generations": {"sample_0": [false], "sample_3": [true], "sample_1": [true], "sample_2": [true], "sample_4": [false], "sample_5": [false], "sample_6": [false], "sample_7": [false], "sample_8": [true], "sample_9": [false], "sample_10": [true], "sample_11": [false], "sample_12": [false], "sample_13": [false], "sample_14": [false], "sample_15": [true], "sample_16": [false], "sample_17": [false], "sample_18": [false], "sample_19": [false], "sample_20": [false], "sample_21": [true], "sample_22": [false], "sample_23": [false], "sample_24": [false], "sample_25": [false], "sample_26": [false], "sample_27": [true], "sample_28": [false], "sample_29": [false], "sample_30": [false], "sample_31": [false], "sample_32": [true], "sample_33": [false], "sample_34": [false], "sample_35": [true], "sample_36": [true], "sample_37": [false], "sample_38": [false], "sample_39": [true], "sample_40": [false], "sample_41": [true], "sample_42": [false], "sample_43": [false], "sample_44": [false], "sample_45": [true], "sample_46": [false], "sample_47": [true], "sample_48": [true], "sample_49": [true], "sample_50": [false], "sample_51": [false], "sample_52": [true], "sample_54": [true], "sample_53": [true], "sample_55": [false], "sample_58": [true], "sample_56": [true], "sample_57": [false], "sample_59": [true], "sample_60": [true], "sample_61": [true], "sample_62": [false], "sample_63": [true], "sample_64": [false], "sample_65": [true], "sample_67": [false], "sample_66": [false], "sample_68": [true], "sample_69": [false], "sample_70": [true], "sample_71": [true], "sample_72": [true], "sample_73": [false], "sample_75": [false], "sample_74": [false], "sample_76": [true], "sample_77": [true], "sample_78": [false], "sample_79": [false], "sample_80": [true], "sample_82": [false], "sample_81": [false], "sample_83": [false], "sample_85": [false], "sample_84": [false], "sample_86": [false], "sample_88": [true], "sample_87": [false], "sample_89": [false], "sample_90": [false], "sample_91": [true], "sample_92": [false], "sample_93": [false], "sample_94": [false], "sample_95": [false], "sample_98": [false], "sample_96": [true], "sample_99": [false], "sample_97": [false], "sample_100": [false], "sample_102": [true], "sample_101": [false], "sample_103": [true], "sample_104": [false], "sample_107": [true], "sample_106": [false], "sample_105": [false], "sample_108": [false], "sample_109": [true], "sample_111": [false], "sample_110": [false], "sample_112": [true], "sample_113": [true], "sample_114": [true], "sample_115": [true], "sample_116": [true], "sample_117": [true], "sample_118": [true], "sample_119": [true], "sample_120": [true], "sample_121": [false], "sample_122": [false], "sample_123": [false], "sample_124": [true], "sample_125": [true], "sample_126": [true], "sample_127": [true], "sample_128": [true], "sample_129": [false], "sample_130": [true], "sample_131": [false], "sample_132": [false], "sample_133": [true], "sample_135": [true], "sample_134": [false], "sample_136": [true], "sample_139": [true], "sample_137": [true], "sample_138": [false], "sample_140": [false], "sample_141": [false], "sample_142": [true], "sample_143": [true], "sample_144": [true], "sample_145": [true], "sample_146": [true], "sample_147": [true], "sample_148": [false], "sample_151": [true], "sample_149": [true], "sample_152": [true], "sample_150": [false], "sample_153": [false], "sample_154": [true], "sample_155": [true], "sample_156": [true], "sample_157": [false], "sample_158": [true], "sample_159": [false], "sample_160": [false], "sample_161": [false], "sample_162": [true], "sample_163": [false], "sample_164": [false], "sample_165": [false], "sample_166": [true], "sample_167": [false], "sample_168": [true], "sample_169": [true], "sample_171": [true], "sample_170": [false], "sample_172": [true], "sample_173": [false], "sample_174": [false], "sample_175": [true], "sample_176": [true], "sample_177": [true], "sample_178": [true], "sample_180": [false], "sample_179": [true], "sample_182": [true], "sample_181": [true], "sample_183": [false], "sample_184": [true], "sample_185": [false], "sample_186": [true], "sample_187": [true], "sample_188": [false], "sample_189": [false], "sample_190": [true], "sample_191": [false], "sample_192": [false], "sample_193": [false], "sample_194": [true], "sample_195": [false], "sample_196": [false], "sample_198": [false], "sample_197": [true], "sample_199": [true], "sample_200": [true], "sample_201": [false], "sample_202": [false], "sample_203": [true], "sample_204": [false], "sample_205": [true], "sample_206": [false], "sample_207": [true], "sample_208": [true], "sample_209": [true], "sample_210": [false], "sample_211": [false], "sample_213": [false], "sample_212": [true], "sample_214": [true], "sample_215": [false], "sample_216": [true], "sample_217": [false], "sample_218": [true], "sample_219": [false], "sample_220": [true], "sample_221": [true], "sample_222": [true], "sample_223": [false], "sample_224": [true], "sample_225": [false], "sample_226": [true], "sample_227": [true], "sample_228": [true], "sample_229": [true], "sample_230": [true], "sample_231": [false], "sample_232": [true], "sample_233": [true], "sample_234": [true], "sample_235": [true], "sample_236": [true], "sample_237": [false], "sample_238": [true], "sample_239": [false], "sample_240": [true], "sample_241": [false], "sample_242": [true], "sample_243": [true], "sample_244": [true], "sample_245": [true], "sample_246": [true], "sample_247": [true], "sample_248": [true], "sample_249": [false], "sample_250": [true], "sample_251": [true], "sample_252": [true], "sample_253": [false], "sample_254": [false], "sample_256": [true], "sample_255": [false], "sample_257": [true], "sample_258": [false], "sample_259": [true], "sample_260": [true], "sample_261": [true], "sample_262": [false], "sample_263": [true], "sample_264": [true], "sample_265": [true], "sample_266": [false], "sample_267": [false], "sample_268": [false], "sample_269": [true], "sample_270": [false], "sample_271": [false], "sample_272": [false], "sample_273": [false], "sample_274": [false], "sample_275": [true], "sample_276": [false], "sample_277": [true], "sample_278": [true], "sample_279": [true], "sample_280": [true], "sample_281": [true], "sample_282": [true], "sample_283": [false], "sample_284": [false], "sample_285": [true], "sample_286": [true], "sample_287": [true], "sample_288": [true], "sample_289": [false], "sample_290": [true], "sample_291": [false], "sample_292": [true], "sample_293": [false], "sample_294": [true], "sample_295": [false], "sample_296": [false], "sample_297": [true], "sample_298": [true], "sample_299": [true], "sample_300": [true], "sample_301": [false], "sample_302": [false], "sample_303": [true], "sample_304": [false], "sample_305": [true], "sample_306": [false], "sample_307": [true], "sample_308": [true], "sample_309": [true], "sample_310": [false], "sample_312": [true], "sample_311": [false], "sample_313": [true], "sample_314": [false], "sample_315": [false], "sample_316": [false], "sample_317": [false], "sample_318": [false], "sample_319": [false], "sample_320": [true], "sample_321": [true], "sample_322": [false], "sample_323": [true], "sample_324": [true], "sample_325": [true], "sample_326": [true], "sample_327": [true], "sample_328": [true], "sample_329": [true], "sample_330": [false], "sample_331": [false], "sample_332": [true], "sample_333": [true], "sample_334": [true], "sample_335": [true], "sample_336": [false], "sample_337": [true], "sample_338": [true], "sample_339": [false], "sample_340": [true], "sample_341": [true], "sample_342": [true], "sample_343": [true], "sample_344": [true], "sample_345": [false], "sample_346": [false], "sample_347": [true], "sample_348": [false], "sample_349": [true], "sample_350": [true], "sample_351": [true], "sample_352": [false], "sample_353": [true], "sample_354": [true], "sample_355": [true], "sample_356": [true], "sample_357": [true], "sample_358": [false], "sample_359": [true], "sample_360": [false], "sample_361": [true], "sample_362": [true], "sample_363": [true], "sample_364": [false], "sample_365": [false], "sample_366": [false], "sample_367": [false], "sample_368": [true], "sample_369": [true], "sample_370": [false], "sample_371": [false], "sample_372": [false], "sample_373": [false], "sample_374": [false], "sample_375": [false], "sample_376": [true], "sample_377": [false], "sample_378": [true], "sample_379": [true], "sample_380": [true], "sample_381": [true], "sample_382": [true], "sample_383": [false], "sample_384": [true], "sample_385": [true], "sample_386": [false], "sample_387": [true], "sample_388": [false], "sample_389": [false], "sample_390": [true], "sample_391": [true], "sample_392": [true], "sample_393": [true], "sample_394": [false], "sample_395": [false], "sample_396": [true], "sample_397": [true], "sample_398": [false], "sample_399": [true], "sample_400": [true], "sample_401": [false], "sample_402": [true], "sample_403": [true], "sample_404": [true], "sample_405": [true], "sample_406": [false], "sample_407": [true], "sample_408": [false], "sample_409": [true], "sample_410": [false], "sample_411": [true], "sample_412": [false], "sample_413": [false], "sample_414": [true], "sample_415": [true], "sample_416": [true], "sample_417": [false], "sample_418": [false], "sample_419": [true], "sample_420": [false], "sample_421": [false], "sample_422": [false], "sample_423": [true], "sample_424": [true], "sample_425": [true], "sample_426": [true], "sample_427": [false], "sample_428": [true], "sample_429": [true], "sample_430": [true], "sample_431": [true], "sample_432": [true], "sample_433": [true], "sample_434": [false], "sample_435": [true], "sample_436": [false], "sample_437": [false], "sample_438": [true], "sample_439": [true], "sample_440": [true], "sample_441": [false], "sample_442": [true], "sample_443": [false], "sample_444": [false], "sample_445": [false], "sample_446": [false], "sample_447": [true], "sample_448": [true], "sample_449": [true], "sample_450": [true], "sample_451": [true], "sample_453": [true], "sample_452": [true], "sample_454": [false], "sample_455": [true], "sample_456": [false], "sample_457": [true], "sample_458": [false], "sample_459": [false], "sample_460": [false], "sample_461": [true], "sample_462": [false], "sample_463": [true], "sample_464": [true], "sample_465": [true], "sample_466": [true], "sample_467": [true], "sample_469": [true], "sample_468": [true], "sample_470": [false], "sample_471": [false], "sample_472": [true], "sample_473": [false], "sample_474": [false], "sample_475": [true], "sample_476": [false], "sample_477": [true], "sample_478": [true], "sample_479": [true], "sample_480": [true], "sample_481": [false], "sample_482": [false], "sample_483": [true], "sample_484": [false], "sample_485": [true], "sample_486": [true], "sample_487": [false], "sample_488": [false], "sample_489": [false], "sample_490": [true], "sample_491": [true], "sample_492": [true], "sample_493": [true], "sample_494": [true], "sample_495": [true], "sample_496": [false], "sample_497": [true], "sample_498": [true], "sample_499": [true], "sample_500": [false], "sample_501": [false], "sample_502": [false], "sample_503": [true], "sample_504": [false], "sample_505": [false], "sample_506": [false], "sample_507": [true], "sample_508": [false], "sample_509": [false], "sample_510": [false], "sample_511": [false], "sample_512": [false], "sample_513": [true], "sample_514": [false], "sample_515": [false], "sample_516": [false], "sample_517": [false], "sample_518": [false], "sample_519": [false], "sample_520": [false], "sample_521": [true], "sample_522": [true], "sample_523": [true], "sample_524": [false], "sample_525": [false], "sample_526": [false], "sample_527": [false], "sample_528": [false], "sample_529": [true], "sample_530": [false], "sample_531": [false], "sample_532": [false], "sample_533": [false], "sample_534": [false], "sample_535": [false], "sample_536": [false], "sample_537": [false], "sample_538": [false], "sample_539": [false], "sample_540": [false], "sample_541": [true], "sample_542": [false], "sample_543": [false], "sample_544": [false], "sample_545": [false], "sample_546": [true], "sample_547": [false], "sample_548": [true], "sample_549": [false], "sample_550": [true], "sample_551": [false], "sample_552": [false], "sample_553": [false], "sample_554": [false], "sample_555": [false], "sample_556": [false], "sample_557": [true], "sample_558": [true], "sample_559": [false], "sample_560": [false], "sample_561": [true], "sample_562": [false], "sample_563": [false], "sample_564": [false], "sample_565": [false], "sample_566": [true], "sample_567": [false], "sample_568": [false], "sample_569": [false], "sample_570": [true], "sample_571": [false], "sample_572": [false], "sample_573": [false], "sample_574": [false], "sample_575": [false], "sample_576": [false], "sample_577": [false], "sample_578": [false], "sample_579": [false], "sample_580": [true], "sample_581": [false], "sample_582": [false], "sample_583": [true], "sample_584": [true], "sample_585": [true], "sample_586": [false], "sample_587": [true], "sample_588": [true], "sample_589": [false], "sample_590": [false], "sample_591": [false], "sample_592": [false], "sample_593": [false], "sample_594": [false], "sample_595": [false], "sample_596": [false], "sample_597": [true], "sample_598": [false], "sample_599": [false], "sample_600": [false], "sample_601": [false], "sample_602": [false], "sample_603": [false], "sample_604": [false], "sample_605": [false], "sample_606": [false], "sample_607": [false], "sample_608": [false], "sample_609": [true], "sample_610": [false], "sample_611": [false], "sample_612": [false], "sample_613": [false], "sample_614": [false], "sample_615": [false], "sample_616": [false], "sample_617": [false], "sample_618": [false], "sample_619": [false], "sample_620": [true], "sample_621": [false], "sample_622": [true], "sample_623": [false], "sample_624": [true], "sample_625": [false], "sample_626": [false], "sample_627": [false], "sample_628": [false], "sample_629": [false], "sample_630": [false], "sample_631": [false], "sample_632": [false], "sample_633": [false], "sample_634": [false], "sample_635": [false], "sample_636": [false], "sample_637": [false], "sample_638": [false], "sample_639": [false], "sample_640": [false], "sample_641": [false], "sample_642": [false], "sample_643": [false], "sample_644": [false], "sample_645": [true], "sample_646": [false], "sample_647": [false], "sample_648": [false], "sample_649": [false], "sample_650": [false], "sample_651": [true], "sample_652": [true], "sample_653": [false], "sample_654": [true], "sample_655": [false], "sample_656": [false], "sample_657": [false], "sample_658": [false], "sample_659": [false], "sample_660": [false], "sample_661": [false], "sample_662": [false], "sample_663": [false], "sample_664": [false], "sample_665": [false], "sample_666": [false], "sample_667": [false], "sample_668": [false], "sample_669": [false], "sample_670": [false], "sample_671": [false], "sample_672": [false], "sample_673": [false], "sample_674": [false], "sample_675": [false], "sample_676": [false], "sample_677": [false], "sample_678": [false], "sample_679": [false], "sample_680": [false], "sample_681": [false], "sample_682": [false], "sample_683": [true], "sample_684": [false], "sample_685": [false], "sample_686": [false], "sample_687": [false], "sample_688": [false], "sample_689": [false], "sample_690": [false], "sample_691": [false], "sample_692": [true], "sample_693": [false], "sample_694": [true], "sample_695": [false], "sample_696": [false], "sample_697": [false], "sample_698": [false], "sample_699": [false], "sample_700": [false], "sample_701": [false], "sample_702": [true], "sample_703": [false], "sample_704": [false], "sample_705": [true], "sample_706": [false], "sample_707": [false], "sample_708": [false], "sample_709": [false], "sample_710": [false], "sample_711": [false], "sample_712": [false], "sample_713": [true], "sample_714": [false], "sample_715": [false], "sample_716": [false], "sample_717": [true], "sample_718": [false], "sample_719": [false], "sample_720": [false], "sample_721": [false], "sample_722": [false], "sample_723": [false], "sample_724": [false], "sample_725": [false], "sample_726": [true], "sample_727": [false], "sample_728": [true], "sample_729": [true], "sample_730": [true], "sample_731": [false], "sample_732": [false], "sample_733": [false], "sample_734": [false], "sample_735": [true], "sample_736": [false], "sample_737": [true], "sample_738": [false], "sample_739": [true], "sample_740": [true], "sample_741": [false], "sample_742": [false], "sample_743": [false], "sample_744": [false], "sample_745": [false], "sample_746": [false], "sample_747": [false], "sample_748": [true], "sample_749": [false], "sample_750": [false], "sample_751": [false], "sample_752": [false], "sample_753": [true], "sample_754": [false], "sample_755": [true], "sample_756": [true], "sample_757": [true], "sample_758": [false], "sample_759": [true], "sample_760": [true], "sample_761": [false], "sample_762": [true], "sample_763": [false], "sample_764": [false], "sample_765": [false], "sample_766": [true], "sample_767": [true], "sample_768": [false], "sample_769": [false], "sample_770": [true], "sample_771": [false], "sample_772": [true], "sample_773": [false], "sample_774": [false], "sample_775": [false], "sample_776": [false], "sample_777": [true], "sample_778": [false], "sample_779": [false], "sample_780": [true], "sample_781": [true], "sample_782": [false], "sample_783": [false], "sample_784": [true], "sample_785": [false], "sample_786": [false], "sample_787": [false], "sample_788": [false], "sample_789": [false], "sample_790": [false], "sample_791": [false], "sample_792": [false], "sample_793": [false], "sample_794": [false], "sample_795": [false], "sample_796": [true], "sample_797": [false], "sample_798": [true], "sample_799": [false], "sample_800": [false], "sample_801": [false], "sample_802": [false], "sample_803": [true], "sample_804": [true], "sample_805": [false], "sample_806": [true], "sample_807": [false], "sample_808": [true], "sample_809": [true], "sample_810": [true], "sample_811": [true], "sample_812": [false], "sample_813": [false], "sample_814": [true], "sample_815": [false], "sample_816": [true], "sample_817": [false], "sample_818": [true], "sample_819": [false], "sample_820": [true], "sample_821": [false], "sample_822": [true], "sample_823": [false], "sample_824": [false], "sample_825": [true], "sample_826": [false], "sample_827": [true], "sample_828": [false], "sample_829": [true], "sample_830": [false], "sample_831": [true], "sample_832": [false], "sample_833": [false], "sample_834": [false], "sample_835": [false], "sample_836": [false], "sample_837": [false], "sample_838": [false], "sample_839": [false], "sample_840": [false], "sample_841": [false], "sample_842": [false], "sample_843": [false], "sample_844": [false], "sample_845": [false], "sample_846": [false], "sample_847": [true], "sample_848": [true], "sample_849": [false], "sample_850": [false], "sample_851": [false], "sample_852": [false], "sample_853": [false], "sample_854": [false], "sample_855": [true], "sample_856": [false], "sample_857": [true], "sample_858": [false], "sample_859": [true], "sample_860": [false], "sample_861": [false], "sample_862": [false], "sample_863": [false], "sample_864": [true], "sample_865": [true], "sample_866": [false], "sample_867": [false], "sample_868": [false], "sample_869": [false], "sample_870": [true], "sample_871": [false], "sample_872": [false], "sample_873": [false], "sample_874": [false], "sample_875": [false], "sample_876": [true], "sample_877": [true], "sample_878": [false], "sample_879": [false], "sample_880": [false], "sample_881": [false], "sample_882": [false], "sample_883": [false], "sample_884": [true], "sample_885": [false], "sample_886": [false], "sample_887": [true], "sample_888": [false], "sample_889": [true], "sample_890": [false], "sample_891": [true], "sample_892": [true], "sample_893": [false], "sample_894": [false], "sample_895": [true], "sample_896": [false], "sample_897": [false], "sample_898": [false], "sample_899": [false], "sample_900": [false], "sample_901": [false], "sample_902": [false], "sample_903": [true], "sample_904": [false], "sample_905": [true], "sample_906": [false], "sample_907": [false], "sample_908": [true], "sample_909": [false], "sample_910": [false], "sample_911": [false], "sample_912": [false], "sample_913": [false], "sample_914": [true], "sample_915": [false], "sample_916": [false], "sample_917": [false], "sample_918": [false], "sample_919": [false], "sample_920": [false], "sample_921": [false], "sample_922": [false], "sample_923": [false], "sample_924": [false], "sample_925": [false], "sample_926": [false], "sample_927": [false], "sample_928": [false], "sample_929": [false], "sample_930": [false], "sample_931": [false], "sample_932": [false], "sample_933": [false], "sample_934": [false], "sample_935": [false], "sample_936": [true], "sample_937": [false], "sample_938": [false], "sample_939": [false], "sample_940": [false], "sample_941": [false], "sample_942": [false], "sample_943": [false], "sample_944": [false], "sample_945": [false], "sample_946": [false], "sample_947": [false], "sample_948": [false], "sample_949": [false], "sample_950": [false], "sample_951": [false], "sample_952": [false], "sample_953": [false], "sample_954": [false], "sample_955": [false], "sample_956": [false], "sample_957": [false], "sample_958": [false], "sample_959": [false], "sample_960": [true], "sample_961": [true], "sample_962": [false], "sample_963": [false], "sample_964": [false], "sample_965": [false], "sample_966": [false], "sample_967": [false], "sample_968": [false], "sample_969": [false], "sample_970": [false], "sample_971": [false], "sample_972": [false], "sample_973": [false], "sample_974": [false], "sample_975": [true], "sample_976": [false], "sample_977": [false], "sample_978": [false], "sample_979": [true], "sample_980": [false], "sample_981": [false], "sample_982": [false], "sample_983": [false], "sample_984": [false], "sample_985": [false], "sample_986": [false], "sample_987": [false], "sample_988": [false], "sample_989": [false], "sample_990": [false], "sample_991": [false], "sample_992": [false], "sample_993": [false], "sample_994": [false], "sample_995": [false], "sample_996": [false], "sample_997": [false], "sample_998": [false], "sample_999": [false], "sample_1000": [false], "sample_1001": [true], "sample_1002": [true], "sample_1003": [false], "sample_1004": [true], "sample_1005": [false], "sample_1006": [false], "sample_1007": [true], "sample_1008": [false], "sample_1009": [false], "sample_1010": [true], "sample_1011": [false], "sample_1012": [true], "sample_1013": [false], "sample_1014": [false], "sample_1015": [false], "sample_1016": [false], "sample_1017": [false], "sample_1018": [false], "sample_1019": [false], "sample_1020": [false], "sample_1021": [false], "sample_1022": [false], "sample_1023": [false], "sample_1024": [false], "sample_1025": [false], "sample_1026": [true], "sample_1027": [false], "sample_1028": [false], "sample_1029": [false], "sample_1030": [false], "sample_1031": [false], "sample_1032": [true], "sample_1033": [false], "sample_1034": [false], "sample_1035": [false], "sample_1036": [false], "sample_1037": [true], "sample_1038": [false], "sample_1039": [false], "sample_1040": [false], "sample_1041": [false], "sample_1042": [false], "sample_1043": [false], "sample_1044": [true], "sample_1045": [true], "sample_1046": [false], "sample_1047": [false], "sample_1048": [false], "sample_1049": [false], "sample_1050": [false], "sample_1051": [false], "sample_1052": [true], "sample_1053": [true], "sample_1054": [false], "sample_1055": [false], "sample_1056": [false], "sample_1057": [false], "sample_1058": [false], "sample_1059": [false], "sample_1060": [false], "sample_1061": [false], "sample_1062": [false], "sample_1063": [true], "sample_1064": [true], "sample_1065": [false], "sample_1066": [false], "sample_1067": [false], "sample_1068": [false], "sample_1069": [false], "sample_1070": [false], "sample_1071": [false], "sample_1072": [false], "sample_1073": [false], "sample_1074": [false], "sample_1075": [false], "sample_1076": [false], "sample_1077": [false], "sample_1078": [false], "sample_1079": [false], "sample_1080": [false], "sample_1081": [false], "sample_1082": [false], "sample_1083": [false], "sample_1084": [false], "sample_1085": [false], "sample_1086": [true], "sample_1087": [true], "sample_1088": [false], "sample_1089": [false], "sample_1090": [false], "sample_1091": [false], "sample_1092": [false], "sample_1093": [false], "sample_1094": [false], "sample_1095": [false], "sample_1096": [false], "sample_1097": [false], "sample_1098": [false], "sample_1099": [false], "sample_1100": [false], "sample_1101": [false], "sample_1102": [false], "sample_1103": [false], "sample_1104": [false], "sample_1105": [true], "sample_1106": [false], "sample_1107": [false], "sample_1108": [false], "sample_1109": [false], "sample_1110": [false], "sample_1111": [false], "sample_1112": [true], "sample_1113": [false], "sample_1114": [false], "sample_1115": [false], "sample_1116": [false], "sample_1117": [false], "sample_1118": [false], "sample_1119": [false], "sample_1120": [true], "sample_1121": [true], "sample_1122": [false], "sample_1123": [false], "sample_1124": [true], "sample_1125": [false], "sample_1126": [true], "sample_1127": [false], "sample_1128": [true], "sample_1129": [false], "sample_1130": [true], "sample_1131": [false], "sample_1132": [false], "sample_1133": [false], "sample_1134": [true], "sample_1135": [true], "sample_1136": [false], "sample_1137": [false], "sample_1138": [false], "sample_1139": [false], "sample_1140": [false], "sample_1141": [false], "sample_1142": [false], "sample_1143": [true], "sample_1144": [false], "sample_1145": [true], "sample_1146": [false], "sample_1147": [false], "sample_1148": [true], "sample_1149": [false], "sample_1150": [false], "sample_1151": [false], "sample_1152": [false], "sample_1153": [false], "sample_1154": [true], "sample_1155": [false], "sample_1156": [false], "sample_1157": [false], "sample_1158": [true], "sample_1159": [false], "sample_1160": [false], "sample_1161": [false], "sample_1162": [false], "sample_1163": [false], "sample_1164": [false], "sample_1165": [false], "sample_1166": [false], "sample_1167": [false], "sample_1168": [false], "sample_1169": [false], "sample_1170": [false], "sample_1171": [false], "sample_1172": [false], "sample_1173": [false], "sample_1174": [false], "sample_1175": [false], "sample_1176": [true], "sample_1177": [false], "sample_1178": [false], "sample_1179": [false], "sample_1180": [false], "sample_1181": [true], "sample_1182": [false], "sample_1183": [false], "sample_1184": [true], "sample_1185": [false], "sample_1186": [false], "sample_1187": [true], "sample_1188": [true], "sample_1189": [false], "sample_1190": [false], "sample_1191": [false], "sample_1192": [false], "sample_1193": [false], "sample_1194": [false], "sample_1195": [false], "sample_1196": [false], "sample_1197": [false], "sample_1198": [false], "sample_1199": [false], "sample_1200": [false], "sample_1201": [false], "sample_1202": [true], "sample_1203": [false], "sample_1204": [true], "sample_1205": [false], "sample_1206": [true], "sample_1207": [false], "sample_1208": [true], "sample_1209": [false]}}