{"raw_generations": {"sample_200": ["def test_email_message_with_attachment(self):\n    subject = 'Test email with attachment'\n    body = 'This is a test email with an attachment.'\n    from_email = 'from@example.com'\n    to = ['to@example.com']\n    attachment_filename = 'test.txt'\n    attachment_content = b'Hello, world!'\n    attachment_mimetype = 'text/plain'\n\n    email = EmailMessage(\n        subject=subject,\n        body=body,\n        from_email=from_email,\n        to=to,\n    )\n    email.attach(attachment_filename, attachment_content, attachment_mimetype)\n\n    expected_headers = {\n        ('Subject', subject),\n        ('From', from_email),\n        ('To', ', '.join(to)),\n    }\n    self.assertMessageHasHeaders(email.message().as_bytes(), expected_headers)\n\n    decoded_attachments = self.get_decoded_attachments(email)\n    self.assertEqual(len(decoded_attachments), 1)\n    filename, content, mimetype = decoded_attachments[0]\n    self.assertEqual(filename, attachment_filename)\n    self.assertEqual(content, attachment_content)\n    self.assertEqual(mimetype, attachment_mimetype)\n"], "sample_1007": ["def test_binomial():\n    n, k = symbols('n k', integer=True)\n    assert binomial(n, k).fdiff(1) == binomial(n, k)*(polygamma(0, n + 1) - polygamma(0, n - k + 1))\n    assert binomial(n, k).fdiff(2) == binomial(n, k)*(polygamma(0, n - k + 1) - polygamma(0, k + 1))\n\n    assert binomial(15, 8) == 6435\n    assert binomial(n, -1) == 0\n    assert binomial(Rational(5, 4), 3) == -5/128\n    assert binomial(Rational(-5, 4), 3) == -195/128\n\n    assert binomial(n, 3).expand(func=True) == n**3/6 - n**2/2 + n/3\n    assert expand_func(binomial(n, 3)) == n*(n - 2)*(n - 1)/6\n\n    assert binomial(n, k).rewrite(factorial) == factorial(n)/(factorial(k)*factorial(n - k))\n    assert binomial(n, k).rewrite(gamma) == gamma(n + 1)/(gamma(k + 1)*gamma(n - k + 1))\n    assert binomial(n, k).rewrite(ff) == ff(n, k) / factorial(k)\n\n    assert binomial(10, 5).is_integer\n    assert binomial(n, k).is_integer == (n.is_integer and k.is_integer)\n\n    assert binomial(10, 5).is_nonnegative\n    assert binomial(n, k).is_nonnegative == (n.is_integer and k.is_integer and n.is_nonnegative and k.is_nonnegative)\n"], "sample_55": ["    def test_inline_admin_formset_fields(self):\n        \"\"\"\n        Test that InlineAdminFormSet.fields() returns the correct fields.\n        \"\"\"\n        inline_admin = InlineAdminFormSet(\n            inline=Article,\n            formset=Article.objects.all(),\n            fieldsets=[('General', {'fields': ['title', 'content']})],\n            prepopulated_fields={'title': ('slug',)},\n            readonly_fields=('date',),\n            model_admin=ArticleAdmin,\n        )\n        fields = list(inline_admin.fields())\n        self.assertEqual(len(fields), 3)\n        self.assertEqual(fields[0]['name'], 'title')\n        self.assertEqual(fields[0]['label'], 'Title')\n        self.assertEqual(fields[0]['widget']['is_hidden'], False)\n        self.assertEqual(fields[0]['required'], True)\n        self.assertEqual(fields[0]['help_text'], '')\n        self.assertEqual(fields[1]['name'], 'content')\n        self.assertEqual(fields[1]['label'], 'Content')\n        self.assertEqual(fields[1]['widget']['is_hidden'], False)\n        self.assertEqual(fields[1]['required'], False)\n        self.assertEqual(fields[1]['help_text'], '')\n        self.assertEqual(fields[2]['name'], 'date')\n        self.assertEqual(fields[2]['label'], 'Date')\n        self.assertEqual(fields[2]['widget']['is_hidden'], False)\n        self.assertEqual(fields[2]['required'], False)\n        self.assertEqual(fields[2]['help_text'], '')\n"], "sample_744": ["def test_power_transformer():\n    # Test that the power transformer works correctly\n    pt = PowerTransformer()\n    X = np.array([[1, 2], [3, 2], [4, 5]])\n    X_trans = pt.fit_transform(X)\n    assert_array_almost_equal(X_trans, [[-1.332, -0.707], [0.256, -0.707], [1.076, 1.414]])\n\n    # Test that the inverse transform works correctly\n    X_inv = pt.inverse_transform(X_trans)\n    assert_array_almost_equal(X_inv, X)\n\n    # Test that the power transformer works correctly with a single feature\n    X = np.array([[1], [3], [4]])\n    X_trans = pt.fit_transform(X)\n    assert_array_almost_equal(X_trans, [[-1.332], [0.256], [1.076]])\n\n    # Test that the inverse transform works correctly with a single feature\n    X_inv = pt.inverse_transform(X_trans)\n    assert_array_almost_equal(X_inv, X)\n\n    # Test that the power transformer raises an error for non-positive data\n    X = np.array([[-1, 2], [3, 2], [4, 5]])\n    pt = PowerTransformer()\n    assert_raises(ValueError, pt.fit, X)\n\n    # Test that the power transformer raises an error for non-numeric data\n    X = np.array([['a', 2], [3, 2], [4, 5]])\n    pt = PowerTransformer()\n    assert_raises(ValueError, pt.fit, X)\n"], "sample_908": ["def test_unparse_arguments(source, expected):\n    tree = ast.parse(source)\n    assert ast.unparse_arguments(tree.body[0].args) == expected\n"], "sample_1060": ["def test_printers():\n    # Test PythonCodePrinter\n    printer = PythonCodePrinter()\n    assert printer._print_Infinity(oo) == \"float('inf')\"\n    assert printer._print_NegativeInfinity(-oo) == \"float('-inf')\"\n    assert printer._print_NaN(zoo) == \"float('nan')\"\n    assert printer._print_ComplexInfinity(zoo) == \"float('nan')\"\n    assert printer._print_Mod(Mod(x, y)) == \"(x % y)\"\n    assert printer._print_Piecewise(Piecewise((x, Eq(y, 0)), (y, True))) == \"((x if (y == 0) else y) if True else None)\"\n    assert printer._print_Relational(Eq(x, y)) == \"(x == y)\"\n    assert printer._print_Relational(Le(x, y)) == \"(x <= y)\"\n    assert printer._print_Relational(Gt(x, y)) == \"(x > y)\"\n    assert printer._print_ITE(Piecewise((x, Eq(y, 0)), (y, True))) == \"((x if (y == 0) else y) if True else None)\"\n    assert printer._print_Sum(x*(y**z)) == \"(builtins.sum((x*(y**z) for z in range(0, 1+1)))\"\n    assert printer._print_ImaginaryUnit(1j) == \"1j\"\n    assert printer._print_MatrixBase(MatrixSymbol('x', 2, 2)) == \"sympy.Matrix([[x_0_0, x_0_1], [x_1_0, x_1_1]])\"\n    assert printer._print_FunctionDefinition(Assignment(x, y)) == \"def x(y):\\n    return y\"\n    assert printer._print_While(Assignment(x, y)) == \"while True:\\n    x = y\"\n    assert printer._print_Declaration(Assignment(x, y)) == \"x = y\"\n    assert printer._print_Return(Assignment(x, y)) == \"return y\"\n    assert printer._print_Print(Assignment(x, y)) == \"print(y)\"\n    assert printer._print_Stream(x) == \"x\"\n    assert printer._print_NoneToken(none) == \"None\"\n\n    # Test MpmathPrinter\n    printer = MpmathPrinter()\n    assert printer._print_Float(R"], "sample_693": ["def test_is_skipped(monkeypatch: MonkeyPatch) -> None:\n    class TestClass:\n            pass\n\n    test_class = TestClass()\n    assert not _is_skipped(test_class)\n\n    monkeypatch.setattr(test_class, \"__unittest_skip__\", True)\n    assert _is_skipped(test_class)\n\n    monkeypatch.setattr(test_class, \"__unittest_skip__\", False)\n    assert not _is_skipped(test_class)\n"], "sample_488": ["def test_lazy_model_operation(self):\n    # Create a new registry with some installed apps.\n    registry = Apps(SOME_INSTALLED_APPS)\n\n    # Define a function that will be called when the model is ready.\n        self.assertIsInstance(model, LogEntry)\n\n    # Use lazy_model_operation to call the function when the model is ready.\n    registry.lazy_model_operation(callback, (\"admin\", \"logentry\"))\n\n    # Populate the registry to make the model ready.\n    registry.populate()\n\n    # Check that the callback was called.\n    self.assertTrue(registry.ready_event.is_set())\n"], "sample_572": ["    def test_cumulative(self, x):\n        \"\"\"Test that the cumulative option works.\"\"\"\n        kde = KDE(cumulative=True)\n        y, x = kde(x)\n        assert_array_almost_equal(y[-1], 1)\n"], "sample_416": ["def test_settings_to_cmd_args_env(self):\n    settings_dict = {\n        \"HOST\": \"localhost\",\n        \"PORT\": 5432,\n        \"NAME\": \"mydb\",\n        \"USER\": \"myuser\",\n        \"PASSWORD\": \"mypassword\",\n        \"OPTIONS\": {\n            \"passfile\": \"/path/to/passfile\",\n            \"service\": \"myservice\",\n            \"sslmode\": \"require\",\n            \"sslrootcert\": \"/path/to/sslrootcert\",\n            \"sslcert\": \"/path/to/sslcert\",\n            \"sslkey\": \"/path/to/sslkey\",\n        },\n    }\n    parameters = [\"-c\", \"SELECT 1;\"]\n    args, env = self.settings_to_cmd_args_env(settings_dict, parameters)\n    self.assertEqual(args, [\n        \"psql\",\n        \"-U\", \"myuser\",\n        \"-h\", \"localhost\",\n        \"-p\", \"5432\",\n        \"-c\", \"SELECT 1;\",\n        \"mydb\",\n    ])\n    self.assertEqual(env, {\n        \"PGPASSWORD\": \"mypassword\",\n        \"PGSERVICE\": \"myservice\",\n        \"PGSSLMODE\": \"require\",\n        \"PGSSLROOTCERT\": \"/path/to/sslrootcert\",\n        \"PGSSLCERT\": \"/path/to/sslcert\",\n        \"PGSSLKEY\": \"/path/to/sslkey\",\n        \"PGPASSFILE\": \"/path/to/passfile\",\n    })\n"], "sample_1114": ["def test_ComplexRegion():\n    a, b = Interval(2, 3), Interval(4, 5)\n    c = Interval(1, 7)\n    C1 = ComplexRegion(a*b)\n    C2 = ComplexRegion(Union(a*b, b*c))\n    assert C1.sets == ProductSet(a, b)\n    assert C2.sets == Union(ProductSet(a, b), ProductSet(b, c))\n    assert C1.psets == (ProductSet(a, b),)\n    assert C2.psets == (ProductSet(a, b), ProductSet(b, c))\n    assert C1.a_interval == a\n    assert C2.a_interval == Union(a, b)\n    assert C1.b_interval == b\n    assert C2.b_interval == c\n    assert C1.measure == 3\n    assert C2.measure == 21\n    assert 2.5 + 4.5*I in C1\n    assert 2.5 + 6.5*I not in C1\n    assert ComplexRegion.from_real(Interval(0,1)) == CartesianComplexRegion(ProductSet(Interval(0, 1), FiniteSet(0)))\n\n    r = Interval(0, 1)\n    theta = Interval(0, 2*pi)\n    C2 = ComplexRegion(r*theta, polar=True)\n    assert C2.polar\n    assert C2.sets == ProductSet(r, normalize_theta_set(theta))\n    assert C2.psets == (ProductSet(r, normalize_theta_set(theta)),)\n    assert C2.a_interval == r\n    assert C2.b_interval == normalize_theta_set(theta)\n    assert C2.measure == pi\n    assert 0.5 + 0.5*I in C2\n    assert 1 + 2*I not in C2\n\n    unit_disk = ComplexRegion(Interval(0, 1)*Interval(0, 2*pi), polar=True)\n    upper_half_unit_disk = ComplexRegion(Interval(0, 1)*Interval(0, pi), polar=True)\n    intersection = unit_disk.intersect(upper_half_unit_disk)\n    assert intersection == upper_half_unit_disk\n"], "sample_5": ["def test_parameter_copy():\n    param = Parameter('test', 'test', 1.0, unit=u.m)\n    param_copy = param.copy()\n    assert param_copy.name == param.name\n    assert param_copy.description == param.description\n    assert param_copy.default == param.default\n    assert param_copy.unit == param.unit\n"], "sample_1029": ["def test_srepr_FractionField():\n    sT(field(QQ, x), \"FractionField(PolyRing(ZZ, x, lex))\")\n"], "sample_738": ["def test_tfidfvectorizer():\n    # Test that the vocabulary is correctly filtered by max_df\n    v = TfidfVectorizer(max_df=0.5)\n    X = v.fit_transform(JUNK_FOOD_DOCS)\n    assert_equal(len(v.vocabulary_), 4)\n\n    # Test that the vocabulary is correctly filtered by min_df\n    v = TfidfVectorizer(min_df=0.5)\n    X = v.fit_transform(JUNK_FOOD_DOCS)\n    assert_equal(len(v.vocabulary_), 3)\n\n    # Test that the vocabulary is correctly filtered by max_features\n    v = TfidfVectorizer(max_features=3)\n    X = v.fit_transform(JUNK_FOOD_DOCS)\n    assert_equal(len(v.vocabulary_), 3)\n\n    # Test that the vocabulary is correctly filtered by max_df and min_df\n    v = TfidfVectorizer(max_df=0.5, min_df=0.5)\n    X = v.fit_transform(JUNK_FOOD_DOCS)\n    assert_equal(len(v.vocabulary_), 2)\n\n    # Test that the vocabulary is correctly filtered by max_features and max_df\n    v = TfidfVectorizer(max_features=3, max_df=0.5)\n    X = v.fit_transform(JUNK_FOOD_DOCS)\n    assert_equal(len(v.vocabulary_), 3)\n\n    # Test that the vocabulary is correctly filtered by max_features and min_df\n    v = TfidfVectorizer(max_features=3, min_df=0.5)\n    X = v.fit_transform(JUNK_FOOD_DOCS)\n    assert_equal(len(v.vocabulary_), 3)\n\n    # Test that the vocabulary is correctly filtered by max_features, max_df, and min_df\n    v = TfidfVectorizer(max_features=3, max_df=0.5, min_df=0.5)\n    X = v.fit_transform(JUNK_FOOD_DOCS)\n    assert_equal(len(v.vocabulary_), 2)\n\n    # Test that the vocabulary is correctly filtered by max_df and stop_words\n    v = TfidfVectorizer(max_df=0.5, stop_words='english')\n    X = v.fit_transform(JUNK_FOOD_DOCS)\n    assert_equal(len(v.vocabulary_), 3)\n\n    # Test that the vocabulary is correctly filtered by min_df and stop_words\n    v = TfidfVectorizer(min_df=0.5, stop_words='english')\n    X = v.fit_transform(JUNK_FOOD_DOCS)\n    assert_equal(len"], "sample_272": ["    def test_migration_plan_with_clean_start(self):\n        \"\"\"\n        Test that migration_plan with clean_start=True returns the correct plan.\n        \"\"\"\n        # Create a migration graph with two apps, each with two migrations\n        graph = MigrationGraph()\n        graph.add_node((\"app1\", \"0001_initial\"), dependencies=[])\n        graph.add_node((\"app1\", \"0002_second\"), dependencies=[(\"app1\", \"0001_initial\")])\n        graph.add_node((\"app2\", \"0001_initial\"), dependencies=[])\n        graph.add_node((\"app2\", \"0002_second\"), dependencies=[(\"app2\", \"0001_initial\")])\n\n        # Create a migration loader with the graph\n        loader = MigrationLoader(connection)\n        loader.graph = graph\n\n        # Create a migration executor with the loader\n        executor = MigrationExecutor(connection)\n        executor.loader = loader\n\n        # Test that migration_plan with clean_start=True returns the correct plan\n        plan = executor.migration_plan([(\"app1\", \"0002_second\"), (\"app2\", \"0002_second\")], clean_start=True)\n        self.assertEqual(len(plan), 4)\n        self.assertEqual(plan[0][0].app_label, \"app1\")\n        self.assertEqual(plan[0][0].name, \"0001_initial\")\n        self.assertEqual(plan[1][0].app_label, \"app1\")\n        self.assertEqual(plan[1][0].name, \"0002_second\")\n        self.assertEqual(plan[2][0].app_label, \"app2\")\n        self.assertEqual(plan[2][0].name, \"0001_initial\")\n        self.assertEqual(plan[3][0].app_label, \"app2\")\n        self.assertEqual(plan[3][0].name, \"0002_second\")\n"], "sample_234": ["    def test_union_with_empty_queryset(self):\n        empty_qs = Number.objects.none()\n        qs = Number.objects.all()\n        union_qs = qs.union(empty_qs)\n        self.assertEqual(union_qs.count(), 10)\n\n        qs = empty_qs.union(Number.objects.all())\n        self.assertEqual(qs.count(), 10)\n\n        qs = empty_qs.union(empty_qs)\n        self.assertEqual(qs.count(), 0)\n"], "sample_312": ["def test_add(self):\n    node3 = Node([('c', 3)])\n    self.node1.add(node3, 'DEFAULT')\n    self.assertIn(node3, self.node1)\n    self.assertEqual(len(self.node1), 3)\n    self.assertEqual(self.node1.connector, 'DEFAULT')\n\n    node4 = Node([('d', 4)], connector='OR')\n    self.node1.add(node4, 'OR', squash=False)\n    self.assertIn(node4, self.node1)\n    self.assertEqual(len(self.node1), 4)\n    self.assertEqual(self.node1.connector, 'DEFAULT')\n\n    node5 = Node([('e', 5)], connector='DEFAULT')\n    self.node1.add(node5, 'DEFAULT')\n    self.assertEqual(len(self.node1), 5)\n    self.assertEqual(self.node1.connector, 'DEFAULT')\n"], "sample_584": ["    def datasets(self):\n        times = pd.date_range('2000-01-01', periods=3)\n        times2 = pd.date_range('2000-01-04', periods=3)\n        return [\n            Dataset({'foo': ('time', np.arange(3))}, {'time': times}),\n            Dataset({'foo': ('time', np.arange(3))}, {'time': times2}),\n        ]\n"], "sample_1138": ["def test_hyper_as_trig():\n    x = Symbol('x')\n    t, f = hyper_as_trig(sinh(x)**2 + cosh(x)**2)\n    assert f(fu(t)) == cosh(2*x)\n\n    t, f = hyper_as_trig(sinh(x)*cosh(x))\n    assert f(fu(t)) == sinh(2*x)/2\n\n    t, f = hyper_as_trig(sinh(x)**3 + cosh(x)**3)\n    assert f(fu(t)) == cosh(3*x)\n\n    t, f = hyper_as_trig(sinh(x)**4 + cosh(x)**4)\n    assert f(fu(t)) == cosh(4*x)\n\n    t, f = hyper_as_trig(sinh(x)**5 + cosh(x)**5)\n    assert f(fu(t)) == cosh(5*x)\n\n    t, f = hyper_as_trig(sinh(x)**6 + cosh(x)**6)\n    assert f(fu(t)) == cosh(6*x)\n\n    t, f = hyper_as_trig(sinh(x)**7 + cosh(x)**7)\n    assert f(fu(t)) == cosh(7*x)\n\n    t, f = hyper_as_trig(sinh(x)**8 + cosh(x)**8)\n    assert f(fu(t)) == cosh(8*x)\n\n    t, f = hyper_as_trig(sinh(x)**9 + cosh(x)**9)\n    assert f(fu(t)) == cosh(9*x)\n\n    t, f = hyper_as_trig(sinh(x)**10 + cosh(x)**10)\n    assert f(fu(t)) == cosh(10*x)\n\n    t, f = hyper_as_trig(sinh(x)**11 + cosh(x)**11)\n    assert f(fu(t)) == cosh(11*x)\n\n    t, f = hyper_as_trig(sinh(x)**12 + cosh(x)**12)\n    assert f(fu(t)) == cosh(12*x)\n\n    t, f = hyper_as_trig(sinh(x)**13 + cosh(x)**13)\n    assert f(fu(t)) == cosh(13*x)\n\n    t, f = hyper_as_trig(sinh(x)**14 + cosh(x)**14)\n    assert f(fu(t)) == cosh(14*x)\n\n    t, f = hyper_as_tr"], "sample_329": ["    def test_serializer_factory(self):\n        # Test that serializer_factory returns the correct serializer for each type\n        self.assertIsInstance(serializer_factory(1), BaseSimpleSerializer)\n        self.assertIsInstance(serializer_factory('a'), BaseSimpleSerializer)\n        self.assertIsInstance(serializer_factory(b'a'), BaseSimpleSerializer)\n        self.assertIsInstance(serializer_factory(1.0), FloatSerializer)\n        self.assertIsInstance(serializer_factory(decimal.Decimal('1.0')), DecimalSerializer)\n        self.assertIsInstance(serializer_factory(datetime.date(2022, 1, 1)), DateTimeSerializer)\n        self.assertIsInstance(serializer_factory(datetime.datetime(2022, 1, 1, tzinfo=utc)), DatetimeDatetimeSerializer)\n        self.assertIsInstance(serializer_factory(datetime.timedelta(days=1)), DateTimeSerializer)\n        self.assertIsInstance(serializer_factory(datetime.time(12, 0)), DateTimeSerializer)\n        self.assertIsInstance(serializer_factory(uuid.UUID('00000000-0000-0000-0000-000000000000')), UUIDSerializer)\n        self.assertIsInstance(serializer_factory(pathlib.Path('/path/to/file')), PathSerializer)\n        self.assertIsInstance(serializer_factory(os.PathLike('/path/to/file')), PathLikeSerializer)\n        self.assertIsInstance(serializer_factory(re.compile('pattern')), RegexSerializer)\n        self.assertIsInstance(serializer_factory(models.Field()), ModelFieldSerializer)\n        self.assertIsInstance(serializer_factory(models.Manager()), ModelManagerSerializer)\n        self.assertIsInstance(serializer_factory(migrations.CreateModel('Model', [('field', models.Field())])), OperationSerializer)\n        self.assertIsInstance(serializer_factory(TextEnum.A), EnumSerializer)\n        self.assertIsInstance(serializer_factory(IntEnum.A), EnumSerializer)\n        self.assertIsInstance(serializer_factory(TextTranslatedEnum.A), EnumSerializer)\n        self.assertIsInstance(serializer_factory(BinaryEnum.A), EnumSerializer)\n        self.assertIsInstance(serializer_factory(DeconstructibleInstances()), DeconstructableSerializer)\n        self.assertIsInstance(serializer_factory(Money('1.0')), DeconstructableSerializer)\n        self.assertIsInstance(serializer_factory(FoodManager()), ModelManagerSerializer)\n        self.assertIsInstance(serializer_factory(FoodQuerySet()), DeconstructableSerializer)\n        self.assertIsInstance(serializer_factory(SettingsReference('SETTING')), SettingsReferenceSerializer)\n        self.assertIsInstance(serializer_factory(functools.partial(lambda x: x)), FunctoolsPartialSerializer)\n        self.assertIsInstance(serializer_factory(functools.partialmethod(lambda x: x)), FunctoolsPartialSerializer)\n        self.assertIsInstance(serializer_factory(lambda x: x), FunctionTypeSerializer)\n        self.assertIsInstance(serializer_factory(EmailValidator()), DeconstructableSerializer)\n        self.assertIsInstance(serializer_factory(RegexValidator(re.compile('pattern'))), DeconstructableSerializer)\n        self.assertIsInstance(serializer_factory(Simple"], "sample_1170": ["def test_strprinter():\n    printer = StrPrinter()\n    assert printer._print_Str(\"Hello\") == \"Str('Hello')\"\n    assert printer._print_str(\"Hello\") == \"Hello\"\n    assert printer._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert sstr(\"Hello\") == \"Hello\"\n    assert sstrrepr(\"Hello\") == \"'Hello'\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\"))"], "sample_18": ["def test_quantity_info_copy(self):\n    q_copy = copy.copy(self.q)\n    assert_info_equal(self.q, q_copy)\n    assert_no_info(self.q.value)\n\n    q_deepcopy = copy.deepcopy(self.q)\n    assert_info_equal(self.q, q_deepcopy)\n    assert_no_info(self.q.value)\n"], "sample_184": ["    def test_check_long_column_names(self):\n        # Create a model with a field that has a long column name.\n        class LongNameModel(models.Model):\n            long_name_field = models.CharField(max_length=255)\n\n        # Check that the model raises an error if the column name is too long.\n        errors = LongNameModel.check()\n        max_length, db_alias = get_max_column_name_length()\n        if max_length is not None:\n            self.assertEqual(len(errors), 1)\n            self.assertEqual(errors[0].id, 'models.E018')\n            self.assertEqual(errors[0].msg, \"Autogenerated column name too long for field \\\"long_name_field\\\". Maximum length is \\\"%s\\\" for database \\\"%s\\\".\" % (max_length, db_alias))\n        else:\n            self.assertEqual(len(errors), 0)\n\n        # Check that the model does not raise an error if the column name is not too long.\n        class ShortNameModel(models.Model):\n            short_name_field = models.CharField(max_length=10, db_column='short_name')\n\n        errors = ShortNameModel.check()\n        self.assertEqual(len(errors), 0)\n"], "sample_39": ["def test_wcs_to_header_string(self):\n    # Test that WCS.to_header_string() returns a string containing the\n    # header cards.\n    filename = get_pkg_data_filename('wcs/6007I-c.fits')\n    with fits.open(filename) as hdul:\n        w = wcs.WCS(hdul[0].header)\n        header_string = w.to_header_string()\n        assert isinstance(header_string, str)\n        assert len(header_string) > 0\n"], "sample_45": ["    def test_trunc_timezone_conversion(self):\n        tz = pytz.timezone('America/New_York')\n        dt = datetime(2022, 3, 13, 1, 59, tzinfo=tz)\n        self.assertEqual(\n            Trunc(dt, 'hour', tzinfo=tz),\n            truncate_to(dt, 'hour', tzinfo=tz)\n        )\n        self.assertEqual(\n            Trunc(dt, 'day', tzinfo=tz),\n            truncate_to(dt, 'day', tzinfo=tz)\n        )\n        self.assertEqual(\n            Trunc(dt, 'month', tzinfo=tz),\n            truncate_to(dt, 'month', tzinfo=tz)\n        )\n        self.assertEqual(\n            Trunc(dt, 'year', tzinfo=tz),\n            truncate_to(dt, 'year', tzinfo=tz)\n        )\n        self.assertEqual(\n            Trunc(dt, 'quarter', tzinfo=tz),\n            truncate_to(dt, 'quarter', tzinfo=tz)\n        )\n        self.assertEqual(\n            Trunc(dt, 'week', tzinfo=tz),\n            truncate_to(dt, 'week', tzinfo=tz)\n        )\n        self.assertEqual(\n            Trunc(dt, 'minute', tzinfo=tz),\n            truncate_to(dt, 'minute', tzinfo=tz)\n        )\n        self.assertEqual(\n            Trunc(dt, 'second', tzinfo=tz),\n            truncate_to(dt, 'second', tzinfo=tz)\n        )\n"], "sample_686": ["def test_deprecated_external_plugins():\n    \"\"\"Test that deprecated external plugins are correctly defined.\"\"\"\n    assert isinstance(DEPRECATED_EXTERNAL_PLUGINS, set)\n    assert len(DEPRECATED_EXTERNAL_PLUGINS) == 3\n    assert \"pytest_catchlog\" in DEPRECATED_EXTERNAL_PLUGINS\n    assert \"pytest_capturelog\" in DEPRECATED_EXTERNAL_PLUGINS\n    assert \"pytest_faulthandler\" in DEPRECATED_EXTERNAL_PLUGINS\n"], "sample_391": ["def test_rename_model(self):\n    operations = [\n        migrations.CreateModel(\n            name=\"ModelA\",\n            fields=[\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=255)),\n            ],\n        ),\n        migrations.RenameModel(\n            old_name=\"ModelA\",\n            new_name=\"ModelB\",\n        ),\n        migrations.RenameModel(\n            old_name=\"ModelB\",\n            new_name=\"ModelC\",\n        ),\n    ]\n    expected = [\n        migrations.CreateModel(\n            name=\"ModelC\",\n            fields=[\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=255)),\n            ],\n        ),\n    ]\n    self.assertOptimizesTo(operations, expected)\n"], "sample_688": ["def test_import_path(tmp_path: Path):\n    # Create a test module\n    test_module = tmp_path / \"test_module.py\"\n    test_module.write_text(\"def test_function(): pass\")\n\n    # Test import_path with prepend mode\n    module = import_path(test_module, mode=\"prepend\")\n    assert module.__name__ == \"test_module\"\n\n    # Test import_path with append mode\n    module = import_path(test_module, mode=\"append\")\n    assert module.__name__ == \"test_module\"\n\n    # Test import_path with importlib mode\n    module = import_path(test_module, mode=\"importlib\")\n    assert module.__name__ == \"test_module\"\n\n    # Test import_path with a package\n    package = tmp_path / \"package\"\n    package.mkdir()\n    (package / \"__init__.py\").touch()\n    (package / \"test_module.py\").write_text(\"def test_function(): pass\")\n    module = import_path(package, mode=\"prepend\")\n    assert module.__name__ == \"package\"\n\n    # Test import_path with a non-existent file\n    with pytest.raises(ImportError):\n        import_path(tmp_path / \"non_existent_file.py\")\n\n    # Test import_path with a non-python file\n    (tmp_path / \"non_python_file.txt\").touch()\n    with pytest.raises(ImportError):\n        import_path(tmp_path / \"non_python_file.txt\")\n\n    # Test import_path with a directory\n    with pytest.raises(ImportError):\n        import_path(tmp_path)\n"], "sample_888": ["def test_isolation_forest_score_samples():\n    # Test that the score_samples method returns the correct scores.\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    iforest = IsolationForest(n_estimators=10, random_state=0)\n    iforest.fit(X)\n    scores = iforest.score_samples(X)\n    assert_array_almost_equal(scores, [-0.2231435513, -0.2231435513, -0.2231435513])\n"], "sample_1148": ["def test_matrix_element():\n    i, j = symbols('i j', integer=True)\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, m)\n\n    assert MatrixElement(A, i, j).parent == A\n    assert MatrixElement(A, i, j).i == i\n    assert MatrixElement(A, i, j).j == j\n\n    assert MatrixElement(A, i, j).doit() == A[i, j]\n\n    assert MatrixElement(A, i, j).diff(A[i, j]) == KroneckerDelta(i, i, (0, n-1))*KroneckerDelta(j, j, (0, m-1))\n\n    assert MatrixElement(A, i, j).diff(B[i, j]) == 0\n\n    assert MatrixElement(A, i, j)._eval_derivative(x) == 0\n\n    assert MatrixElement(A, i, j)._eval_derivative(A[i, j]) == KroneckerDelta(i, i, (0, n-1))*KroneckerDelta(j, j, (0, m-1))\n\n    assert MatrixElement(A, i, j)._eval_derivative(B[i, j]) == 0\n"], "sample_802": ["def test_pipeline_memory():\n    # Test that the memory is properly set in the pipeline\n    memory = Memory(location=mkdtemp(), verbose=0)\n    pipeline = Pipeline([('scaler', StandardScaler()), ('svc', SVC())], memory=memory)\n    assert pipeline.memory is memory\n    assert pipeline.steps[0][1].memory is memory\n    assert pipeline.steps[1][1].memory is memory\n\n    # Test that the memory is properly set in the feature union\n    feature_union = FeatureUnion([('scaler', StandardScaler()), ('pca', PCA())], n_jobs=1)\n    assert feature_union.memory is None\n    assert feature_union.transformer_list[0][1].memory is None\n    assert feature_union.transformer_list[1][1].memory is None\n\n    # Test that the memory is properly set in the feature union with n_jobs > 1\n    feature_union = FeatureUnion([('scaler', StandardScaler()), ('pca', PCA())], n_jobs=2)\n    assert feature_union.memory is None\n    assert feature_union.transformer_list[0][1].memory is None\n    assert feature_union.transformer_list[1][1].memory is None\n\n    # Test that the memory is properly set in the pipeline with n_jobs > 1\n    pipeline = Pipeline([('scaler', StandardScaler()), ('svc', SVC())], memory=memory)\n    assert pipeline.memory is memory\n    assert pipeline.steps[0][1].memory is memory\n    assert pipeline.steps[1][1].memory is memory\n\n    # Test that the memory is properly set in the feature union with n_jobs > 1 and memory\n    feature_union = FeatureUnion([('scaler', StandardScaler()), ('pca', PCA())], n_jobs=2, memory=memory)\n    assert feature_union.memory is memory\n    assert feature_union.transformer_list[0][1].memory is memory\n    assert feature_union.transformer_list[1][1].memory is memory\n\n    # Clean up\n    shutil.rmtree(memory.location)\n"], "sample_1089": ["def test_factor_nc():\n    A = Symbol('A', commutative=False)\n    B = Symbol('B', commutative=False)\n    assert factor_nc((x**2 + 2*A*x + A**2).expand()) == (x + A)**2\n    assert factor_nc(((x + A)*(x + B)).expand()) == (x + A)*(x + B)\n    assert factor_nc((x + A)*(x + B) + (x + A)*(x + B)) == 2*(x + A)*(x + B)\n    assert factor_nc((x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B)) == 3*(x + A)*(x + B)\n    assert factor_nc((x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B)) == 4*(x + A)*(x + B)\n    assert factor_nc((x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B)) == 5*(x + A)*(x + B)\n    assert factor_nc((x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B)) == 6*(x + A)*(x + B)\n    assert factor_nc((x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B)) == 7*(x + A)*(x + B)\n    assert factor_nc((x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B) + (x + A)*(x + B) + (x +"], "sample_647": ["def test_warn_explicit_for():\n        pass\n\n    warning = PytestWarning(\"Test warning\")\n    warn_explicit_for(test_function, warning)\n\n    with pytest.warns(PytestWarning) as record:\n        warn_explicit_for(test_function, warning)\n    assert len(record) == 1\n    assert record[0].message == warning\n"], "sample_359": ["    def test_alter_model_options(self):\n        \"\"\"\n        Test AlterModelOptions operation.\n        \"\"\"\n        operation = AlterModelOptions('testmodel', {'verbose_name': 'Test Model'})\n        self.assertState(\n            operation.state_forwards('app_label', ProjectState()),\n            [\n                ModelState(\n                    'app_label',\n                    'testmodel',\n                    fields=[],\n                    options={'verbose_name': 'Test Model'},\n                    bases=(models.Model,),\n                    managers=[],\n                ),\n            ],\n        )\n"], "sample_14": ["def test_longitude_wrap_at():\n    lon = Longitude([10, 20, 30] * u.deg, wrap_angle=0 * u.deg)\n    assert_allclose(lon.wrap_at(180 * u.deg).wrap_angle, 180 * u.deg)\n    assert_allclose(lon.wrap_at(180 * u.deg).value, [-170, -160, -150] * u.deg)\n\n    lon = Longitude([10, 20, 30] * u.deg, wrap_angle=180 * u.deg)\n    assert_allclose(lon.wrap_at(0 * u.deg).wrap_angle, 0 * u.deg)\n    assert_allclose(lon.wrap_at(0 * u.deg).value, [190, 200, 210] * u.deg)\n\n    lon = Longitude([10, 20, 30] * u.deg, wrap_angle=0 * u.deg)\n    lon.wrap_at(180 * u.deg, inplace=True)\n    assert_allclose(lon.wrap_angle, 180 * u.deg)\n    assert_allclose(lon.value, [-170, -160, -150] * u.deg)\n"], "sample_465": ["    def test_get_inline_instances(self):\n        class ConcertInline(TabularInline):\n            model = Concert\n\n        class BandAdmin(ModelAdmin):\n            inlines = [ConcertInline]\n\n        band_admin = BandAdmin(Band, self.site)\n        inline_instances = band_admin.get_inline_instances(request, self.band)\n        self.assertEqual(len(inline_instances), 1)\n        self.assertIsInstance(inline_instances[0], ConcertInline)\n"], "sample_273": ["    def test_modelbase_prepare_called(self, mock_prepare):\n        class TestModel(models.Model):\n            pass\n        self.assertTrue(mock_prepare.called)\n"], "sample_1050": ["def test_print_Declaration():\n    printer = PythonCodePrinter()\n    decl = Assignment(x, 5)\n    assert printer._print_Declaration(decl) == \"x = 5\"\n"], "sample_793": ["def test_isolation_forest_sparse_input():\n    \"\"\"Test that IsolationForest works with sparse input.\"\"\"\n    X = csc_matrix(iris.data)\n    y = iris.target\n    iforest = IsolationForest(n_estimators=10, random_state=rng)\n    iforest.fit(X, y)\n    assert_array_almost_equal(iforest.predict(X), iforest.predict(X.todense()))\n\n    X = csr_matrix(iris.data)\n    iforest.fit(X, y)\n    assert_array_almost_equal(iforest.predict(X), iforest.predict(X.todense()))\n"], "sample_52": ["    def test_modelchoicefield_prepare_value(self):\n        class TestForm(forms.Form):\n            category = forms.ModelChoiceField(Category.objects.all())\n\n        form = TestForm({'category': self.c1.pk})\n        self.assertEqual(form.fields['category'].prepare_value(self.c1), self.c1.pk)\n\n        form = TestForm({'category': self.c1})\n        self.assertEqual(form.fields['category'].prepare_value(self.c1), self.c1.pk)\n\n        form = TestForm({'category': None})\n        self.assertIsNone(form.fields['category'].prepare_value(None))\n\n        form = TestForm({'category': ''})\n        self.assertEqual(form.fields['category'].prepare_value(''), '')\n"], "sample_726": ["def test_inverse_binarize_thresholding():\n    # Test binary classification\n    y = np.array([[0.7, 0.3], [0.4, 0.6]])\n    classes = np.array([0, 1])\n    y_inv = _inverse_binarize_thresholding(y, \"binary\", classes, 0.5)\n    assert_array_equal(y_inv, np.array([0, 1]))\n\n    # Test multiclass classification\n    y = np.array([[0.7, 0.2, 0.1], [0.1, 0.7, 0.2]])\n    classes = np.array([0, 1, 2])\n    y_inv = _inverse_binarize_thresholding(y, \"multiclass\", classes, 0.5)\n    assert_array_equal(y_inv, np.array([0, 1]))\n\n    # Test multilabel classification\n    y = np.array([[0.7, 0.3], [0.4, 0.6]])\n    classes = np.array([0, 1])\n    y_inv = _inverse_binarize_thresholding(y, \"multilabel-indicator\", classes, 0.5)\n    assert_array_equal(y_inv, np.array([[1, 0], [0, 1]]))\n\n    # Test sparse matrix\n    y = csr_matrix(np.array([[0.7, 0.3], [0.4, 0.6]]))\n    classes = np.array([0, 1])\n    y_inv = _inverse_binarize_thresholding(y, \"binary\", classes, 0.5)\n    assert_array_equal(toarray(y_inv), np.array([0, 1]))\n\n    # Test invalid output type\n    assert_raise_message(ValueError, \"unknown format is not supported\",\n                        _inverse_binarize_thresholding, y, \"unknown\", classes, 0.5)\n\n    # Test invalid threshold\n    assert_raise_message(ValueError, \"output_type='binary', but y.shape = (2, 3)\",\n                        _inverse_binarize_thresholding, np.array([[0.7, 0.2, 0.1], [0.1, 0.7, 0.2]]), \"binary\", classes, 0.5)\n\n    # Test invalid number of classes\n    assert_raise_message(ValueError, \"The number of class is not equal to the number of"], "sample_1028": ["def test_Mod_eval():\n    assert Mod(x**2, y).subs({x: 5, y: 6}) == 1\n    assert Mod(x**2, y).subs({x: -5, y: 6}) == 1\n    assert Mod(x**2, y).subs({x: 5, y: -6}) == 25\n    assert Mod(x**2, y).subs({x: -5, y: -6}) == 25\n    assert Mod(x**2, 2).subs({x: 5}) == 1\n    assert Mod(x**2, 2).subs({x: -5}) == 1\n    assert Mod(x**2, 2).subs({x: 4}) == 0\n    assert Mod(x**2, 2).subs({x: -4}) == 0\n    assert Mod(x**2, 2).subs({x: 3}) == 1\n    assert Mod(x**2, 2).subs({x: -3}) == 1\n    assert Mod(x**2, 2).subs({x: 2}) == 0\n    assert Mod(x**2, 2).subs({x: -2}) == 0\n    assert Mod(x**2, 2).subs({x: 1}) == 1\n    assert Mod(x**2, 2).subs({x: -1}) == 1\n    assert Mod(x**2, 2).subs({x: 0}) == 0\n    assert Mod(x**2, 2).subs({x: -0}) == 0\n    assert Mod(x**2, 2).subs({x: nan}) == nan\n    assert Mod(x**2, 2).subs({x: oo}) == nan\n    assert Mod(x**2, 2).subs({x: -oo}) == nan\n    assert Mod(x**2, 2).subs({x: zoo}) == nan\n    assert Mod(x**2, 2).subs({x: -zoo}) == nan\n    assert Mod(x**2, 2).subs({x: pi}) == Mod(pi**2, 2)\n    assert Mod(x**2, 2).subs({x: -pi}) == Mod(pi**2, 2)\n    assert Mod"], "sample_441": ["    def test_render(self):\n        widget = ReadOnlyPasswordHashWidget()\n        html = widget.render(\"password\", \"password\")\n        self.assertRegex(html, r\"<dl>.*</dl>\")\n"], "sample_521": ["def test_patch_2d_to_3d():\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    patch = Circle((0.5, 0.5), 0.2)\n    art3d.patch_2d_to_3d(patch, z=0.5, zdir='z')\n    ax.add_patch(patch)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_zlim(0, 1)\n    plt.close(fig)\n"], "sample_490": ["    def test_base_constraint_repr(self):\n        constraint = BaseConstraint(name='test_constraint')\n        self.assertEqual(repr(constraint), \"<BaseConstraint: name='test_constraint'>\")\n"], "sample_141": ["    def test_deserialization_error_with_data(self):\n        error = DeserializationError.WithData(\n            original_exc=\"Test exception\",\n            model=\"serializers.category\",\n            fk=\"pk\",\n            field_value=\"test_value\"\n        )\n        self.assertEqual(\n            str(error),\n            \"Test exception: (serializers.category:pk=pk) field_value was 'test_value'\"\n        )\n"], "sample_626": ["def test_explicit_indexing_adapter():\n    # Test explicit indexing adapter with different indexing support\n    array = np.arange(36).reshape(6, 6)\n    key = OuterIndexer((np.array([0, 1, 3]), np.array([2, 3])))\n    result = explicit_indexing_adapter(key, array.shape, IndexingSupport.OUTER, array.__getitem__)\n    expected = np.array([[2, 3], [14, 15], [8, 9]])\n    assert_array_equal(result, expected)\n\n    key = VectorizedIndexer((np.array([0, 2, 1]), np.array([0, 1, 0])))\n    result = explicit_indexing_adapter(key, array.shape, IndexingSupport.VECTORIZED, array.__getitem__)\n    expected = np.array([2, 21, 8])\n    assert_array_equal(result, expected)\n\n    key = BasicIndexer((slice(0, 3), slice(2, 4)))\n    result = explicit_indexing_adapter(key, array.shape, IndexingSupport.BASIC, array.__getitem__)\n    expected = np.array([[2, 3], [8, 9], [14, 15]])\n    assert_array_equal(result, expected)\n"], "sample_204": ["    def test_load_disk(self):\n        \"\"\"\n        Test that loading migrations from disk works.\n        \"\"\"\n        loader = MigrationLoader(connection=connection)\n        loader.load_disk()\n        self.assertIsNotNone(loader.disk_migrations)\n"], "sample_984": ["def test_strprinter():\n    printer = StrPrinter()\n    assert printer._print_StrPrinter(printer) == \"StrPrinter()\"\n    assert printer._print_StrReprPrinter(StrReprPrinter()) == \"StrReprPrinter()\"\n    assert printer._print_Dict(Dict({x: 1, y: 2})) == \"{x: 1, y: 2}\"\n    assert printer._print_Tuple(Tuple(x, y, z)) == \"(x, y, z)\"\n    assert printer._print_FiniteSet(FiniteSet(x, y, z)) == \"{x, y, z}\"\n    assert printer._print_AccumBounds(AccumBounds(x, y)) == \"AccumBounds(x, y)\"\n    assert printer._print_UnevaluatedExpr(UnevaluatedExpr(x + y)) == \"x + y\"\n    assert printer._print_Eq(Eq(x, y)) == \"Eq(x, y)\"\n    assert printer._print_Ne(Ne(x, y)) == \"Ne(x, y)\"\n    assert printer._print_Relational(Rel(x, y, \">\")) == \"x > y\"\n    assert printer._print_Complement(Complement(x, y)) == \"x \\ y\"\n    assert printer._print_SymmetricDifference(SymmetricDifference(x, y)) == \"x ^ y\"\n    assert printer._print_Xor(Xor(x, y)) == \"x ^ y\"\n    assert printer._print_Equivalent(Equivalent(x, y)) == \"x <=> y\"\n"], "sample_422": ["    def test_prefetch_related_objects_with_forward_one_to_one(self):\n        # Create a Bio instance for author1\n        bio = Bio.objects.create(author=self.author1, bio=\"Bio for author1\")\n\n        # Prefetch the bio for authors\n        authors = Author.objects.prefetch_related(\"bio\").all()\n\n        # Check that the bio is prefetched\n        with self.assertNumQueries(1):\n            for author in authors:\n                if author == self.author1:\n                    self.assertEqual(author.bio.bio, \"Bio for author1\")\n                else:\n                    with self.assertRaises(ObjectDoesNotExist):\n                        author.bio\n"], "sample_1100": ["def test_isqrt():\n    assert Pow.isqrt(0) == 0\n    assert Pow.isqrt(1) == 1\n    assert Pow.isqrt(2) == 1\n    assert Pow.isqrt(3) == 1\n    assert Pow.isqrt(4) == 2\n    assert Pow.isqrt(5) == 2\n    assert Pow.isqrt(8) == 2\n    assert Pow.isqrt(9) == 3\n    assert Pow.isqrt(16) == 4\n    assert Pow.isqrt(25) == 5\n    assert Pow.isqrt(36) == 6\n    assert Pow.isqrt(49) == 7\n    assert Pow.isqrt(64) == 8\n    assert Pow.isqrt(81) == 9\n    assert Pow.isqrt(100) == 10\n    assert Pow.isqrt(121) == 11\n    assert Pow.isqrt(144) == 12\n    assert Pow.isqrt(169) == 13\n    assert Pow.isqrt(196) == 14\n    assert Pow.isqrt(225) == 15\n    assert Pow.isqrt(256) == 16\n    assert Pow.isqrt(289) == 17\n    assert Pow.isqrt(324) == 18\n    assert Pow.isqrt(361) == 19\n    assert Pow.isqrt(400) == 20\n    assert Pow.isqrt(441) == 21\n    assert Pow.isqrt(484) == 22\n    assert Pow.isqrt(529) == 23\n    assert Pow.isqrt(576) == 24\n    assert Pow.isqrt(625) == 25\n    assert Pow.isqrt(676) == 26\n    assert Pow.isqrt(729) == 27\n    assert Pow.isqrt(784) == 28\n    assert Pow.isqrt(841) == 29\n    assert Pow.isqrt(900) == 30\n    assert Pow.isqrt(961) == 31\n    assert Pow.isqrt(1024) == 32\n    assert Pow.isqrt(1089) == 33\n    assert Pow.isqrt(1156) == 34\n    assert Pow.isqrt(1225) == 35\n    assert Pow.isqrt(1296) == 36\n    assert Pow.isqrt(136"], "sample_226": ["def test_test_db_signature(self):\n    test_connection = get_connection_copy()\n    creation = BaseDatabaseCreation(test_connection)\n    signature = creation.test_db_signature()\n    self.assertEqual(len(signature), 4)\n    self.assertEqual(signature[0], test_connection.settings_dict['HOST'])\n    self.assertEqual(signature[1], test_connection.settings_dict['PORT'])\n    self.assertEqual(signature[2], test_connection.settings_dict['ENGINE'])\n    self.assertEqual(signature[3], TEST_DATABASE_PREFIX + test_connection.settings_dict['NAME'])\n"], "sample_727": ["def test_imputer_with_pipeline():\n    # Test that Imputer can be used in a pipeline\n    X = np.array([[1, 2], [np.nan, 3], [7, 6]])\n    y = np.array([0, 0, 1])\n\n    pipeline = Pipeline([('imputer', Imputer(strategy='mean')), ('tree', tree.DecisionTreeClassifier())])\n    pipeline.fit(X, y)\n\n    assert_equal(pipeline.predict(X), [0, 0, 1])\n\n    # Test that Imputer can be used in a GridSearchCV\n    param_grid = {'imputer__strategy': ['mean', 'median', 'most_frequent']}\n    grid_search = GridSearchCV(pipeline, param_grid, cv=2)\n    grid_search.fit(X, y)\n\n    assert_equal(grid_search.predict(X), [0, 0, 1])\n"], "sample_855": ["def test_dummy_regressor_quantile():\n    # Test quantile strategy\n    X = np.array([1, 2, 3, 4, 5])\n    y = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n    clf = DummyRegressor(strategy='quantile', quantile=0.5)\n    clf.fit(X, y)\n    assert_array_almost_equal(clf.predict(X), np.array([[3]] * 5))\n\n    # Test quantile strategy with sample weights\n    X = np.array([1, 2, 3, 4, 5])\n    y = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n    sample_weight = np.array([1, 1, 1, 1, 1])\n    clf = DummyRegressor(strategy='quantile', quantile=0.5)\n    clf.fit(X, y, sample_weight=sample_weight)\n    assert_array_almost_equal(clf.predict(X), np.array([[3]] * 5))\n\n    # Test quantile strategy with multi-output\n    X = np.array([1, 2, 3, 4, 5])\n    y = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n    clf = DummyRegressor(strategy='quantile', quantile=0.5)\n    clf.fit(X, y)\n    assert_array_almost_equal(clf.predict(X), np.array([[3, 4]] * 5))\n\n    # Test quantile strategy with sample weights and multi-output\n    X = np.array([1, 2, 3, 4, 5])\n    y = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n    sample_weight = np.array([1, 1, 1, 1, 1])\n    clf = DummyRegressor(strategy='quantile', quantile=0.5)\n    clf.fit(X, y, sample_weight=sample_weight)\n    assert_array_almost_equal(clf.predict(X), np.array([[3, 4]] * 5))\n\n    # Test quantile strategy with quantile value out of range\n    X = np.array([1, 2,"], "sample_953": ["def test_ask_user(capsys):\n    qs.term_input = mock_input({\n        'Root path for the documentation': 'test',\n        'Separate source and build directories (y/n)': 'y',\n        'Name prefix for templates and static dir': '_',\n        'Project name': 'Test Project',\n        'Author name(s)': 'John Doe',\n        'Project version': '1.0',\n        'Project release': '1.0',\n        'Project language': 'en',\n        'Source file suffix': '.rst',\n        'Name of your master document (without suffix)': 'index',\n        'autodoc: automatically insert docstrings from modules (y/n)': 'y',\n        'doctest: automatically test code snippets in doctest blocks (y/n)': 'y',\n        'intersphinx: link between Sphinx documentation of different projects (y/n)': 'y',\n        'todo: write \"todo\" entries that can be shown or hidden on build (y/n)': 'y',\n        'coverage: checks for documentation coverage (y/n)': 'y',\n        'imgmath: include math, rendered as PNG or SVG images (y/n)': 'y',\n        'mathjax: include math, rendered in the browser by MathJax (y/n)': 'y',\n        'ifconfig: conditional inclusion of content based on config values (y/n)': 'y',\n        'viewcode: include links to the source code of documented Python objects (y/n)': 'y',\n        'githubpages: create .nojekyll file to publish the document on GitHub pages (y/n)': 'y',\n        'Create Makefile? (y/n)': 'y',\n        'Create Windows command file? (y/n)': 'y',\n    }, needanswer=True)\n\n    d = {}\n    qs.ask_user(d)\n    captured = capsys.readouterr()\n    assert 'Welcome to the Sphinx' in captured.out\n    assert 'Please enter values for the following settings' in captured.out\n    assert 'Finished: An initial directory structure has been created.' in captured.out\n"], "sample_1062": ["def test_hyper_as_trig():\n    x, y = symbols('x y')\n    expr = sinh(x)**2 + cosh(x)**2 + cos(y)**2 + sin(y)**2\n    t, f = hyper_as_trig(expr)\n    assert expr == f(t)\n    assert t.has(sinh, cosh)\n    assert not t.has(sin, cos)\n    assert f(t).has(sin, cos)\n    assert not f(t).has(sinh, cosh)\n"], "sample_300": ["def test_is_nullable(self):\n    query = Query(Item)\n    self.assertTrue(query.is_nullable(CharField(null=True)))\n    self.assertFalse(query.is_nullable(CharField(null=False)))\n    self.assertTrue(query.is_nullable(CharField(null=False, blank=True)))\n    self.assertFalse(query.is_nullable(CharField(null=False, blank=False)))\n    self.assertTrue(query.is_nullable(BooleanField(null=True)))\n    self.assertFalse(query.is_nullable(BooleanField(null=False)))\n"], "sample_1045": ["def test_comp():\n    assert comp(1, 1) == True\n    assert comp(1, 2) == True\n    assert comp(1, 3) == False\n    assert comp(1, 1.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_1071": ["def test_check_dimensions():\n    # Test that adding a number to a dimensional quantity raises an error\n    raises(ValueError, lambda: check_dimensions(1 + meter))\n    raises(ValueError, lambda: check_dimensions(meter + 1))\n\n    # Test that adding quantities with different dimensions raises an error\n    raises(ValueError, lambda: check_dimensions(meter + second))\n\n    # Test that adding quantities with the same dimension does not raise an error\n    assert check_dimensions(meter + meter) == meter + meter\n\n    # Test that adding quantities with the same dimension and a number does not raise an error\n    assert check_dimensions(meter + meter + 1) == meter + meter + 1\n\n    # Test that adding quantities with different dimensions and a number raises an error\n    raises(ValueError, lambda: check_dimensions(meter + second + 1))\n\n    # Test that a quantity with a dimensionless quantity does not raise an error\n    assert check_dimensions(meter * pi) == meter * pi\n\n    # Test that a quantity with a dimensionless quantity and a number does not raise an error\n    assert check_dimensions(meter * pi + 1) == meter * pi + 1\n\n    # Test that a quantity with a dimensionless quantity and another quantity with a different dimension raises an error\n    raises(ValueError, lambda: check_dimensions(meter * pi + second))\n\n    # Test that a quantity with a dimensionless quantity and another quantity with the same dimension does not raise an error\n    assert check_dimensions(meter * pi + meter) == meter * pi + meter\n\n    # Test that a quantity with a dimensionless quantity and another quantity with the same dimension and a number does not raise an error\n    assert check_dimensions(meter * pi + meter + 1) == meter * pi + meter + 1\n"], "sample_467": ["def test_select_date_widget_format_value(self):\n    widget = SelectDateWidget()\n    value = date(2022, 12, 31)\n    formatted_value = widget.format_value(value)\n    self.assertEqual(formatted_value, {\"year\": 2022, \"month\": 12, \"day\": 31})\n\n    value = \"2022-12-31\"\n    formatted_value = widget.format_value(value)\n    self.assertEqual(formatted_value, {\"year\": 2022, \"month\": 12, \"day\": 31})\n\n    value = None\n    formatted_value = widget.format_value(value)\n    self.assertEqual(formatted_value, {\"year\": None, \"month\": None, \"day\": None})\n\n    value = \"\"\n    formatted_value = widget.format_value(value)\n    self.assertEqual(formatted_value, {\"year\": \"\", \"month\": \"\", \"day\": \"\"})\n"], "sample_593": ["def test_array_repr():\n    arr = xr.DataArray(np.random.RandomState(0).randn(4, 6))\n    html = fh.array_repr(arr)\n    assert \"<div class='xr-array-wrap'>\" in html\n    assert \"<div class='xr-array-preview xr-preview'>\" in html\n    assert \"<div class='xr-array-data'>\" in html\n\n"], "sample_712": ["def test_ordinal_encoder():\n    # Test OrdinalEncoder with categorical features\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 2.], [1., 1.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([['Male', 1], ['Female', 3], ['Female', 2]], dtype=object))\n\n    # Test OrdinalEncoder with numerical features\n    X = [[1, 2], [3, 4], [5, 6]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 1.], [2., 2.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([[1, 2], [3, 4], [5, 6]], dtype=object))\n\n    # Test OrdinalEncoder with mixed-type features\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 2.], [1., 1.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([['Male', 1], ['Female', 3], ['Female', 2]], dtype=object))\n\n    # Test OrdinalEncoder with categories\n    enc = OrdinalEncoder(categories=[['Male', 'Female'], [1, 2, 3]])\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 2.], [1., 1.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([['Male', 1], ['Female', 3], ['Female', 2]], dtype=object))\n\n    # Test OrdinalEncoder with unknown categories\n    enc = OrdinalEncoder(handle_unknown='error')\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    with assert_raises(ValueError):\n        enc.transform([['"], "sample_108": ["def test_reverse_with_prefix(self):\n    urlconf = [\n        path('hello/', empty_view, name='hello'),\n        path('world/', empty_view, name='world'),\n    ]\n    resolver = URLResolver(RegexPattern(r'^/'), urlconf)\n    self.assertEqual(resolver.reverse('hello'), '/hello/')\n    self.assertEqual(resolver.reverse('world'), '/world/')\n    self.assertEqual(resolver._reverse_with_prefix('hello', 'prefix/'), 'prefix/hello/')\n    self.assertEqual(resolver._reverse_with_prefix('world', 'prefix/'), 'prefix/world/')\n    with self.assertRaises(NoReverseMatch):\n        resolver.reverse('nonexistent')\n    with self.assertRaises(NoReverseMatch):\n        resolver._reverse_with_prefix('nonexistent', 'prefix/')\n"], "sample_531": ["def test_subfigure_layout_engine():\n    fig = Figure()\n    subfig = fig.add_subfigure(gridspec.GridSpec(1, 1)[0, 0])\n    assert subfig.get_layout_engine() is None\n    subfig.set_layout_engine('constrained')\n    assert isinstance(subfig.get_layout_engine(), ConstrainedLayoutEngine)\n    subfig.set_layout_engine('tight')\n    assert isinstance(subfig.get_layout_engine(), TightLayoutEngine)\n    subfig.set_layout_engine(None)\n    assert subfig.get_layout_engine() is None\n    with pytest.raises(ValueError):\n        subfig.set_layout_engine('invalid')\n"], "sample_928": ["def test_default_role_found():\n    env = Environment()\n    with default_role('test_docname', 'emphasis'):\n        assert docutils.get_role('') is not None\n"], "sample_590": ["def test_concat_dataset_with_fill_value():\n    # Create test data\n    data = create_test_data()\n    ds1 = data[0]\n    ds2 = data[1]\n\n    # Concatenate datasets with a fill value\n    concatenated = concat([ds1, ds2], dim='time', fill_value=dtypes.NA)\n\n    # Check that the fill value is correctly applied\n    assert concatenated['temperature'].isel(time=-1).values == dtypes.NA\n\n    # Check that the concatenated dataset has the correct shape\n    assert concatenated['temperature'].shape == (10, 2, 3)\n\n    # Check that the concatenated dataset has the correct coordinates\n    assert concatenated['time'].shape == (10,)\n    assert concatenated['x'].shape == (2,)\n    assert concatenated['y'].shape == (3,)\n\n    # Check that the concatenated dataset has the correct attributes\n    assert concatenated.attrs == ds1.attrs\n"], "sample_550": ["def test_axes_init():\n    fig = Figure()\n    ax = fig.add_subplot(111)\n    assert ax.get_frame_on()\n    assert ax.get_axisbelow() == 'line'\n    assert ax.get_rasterization_zorder() is None\n    assert ax.get_navigate()\n    assert ax.get_navigate_mode() is None\n    assert ax.get_window_extent() is not None\n    assert ax.get_tightbbox() is not None\n    assert ax.get_children() is not None\n    assert ax.contains_point((0, 0)) is False\n    assert ax.get_default_bbox_extra_artists() is not None\n    assert ax.get_shared_x_axes() is not None\n    assert ax.get_shared_y_axes() is not None\n"], "sample_1151": ["def test_mod_eval():\n    assert Mod(x**2, y).evalf(subs={x: 5, y: 6}) == 1.0\n    assert Mod(x**2, y).evalf(subs={x: -5, y: 6}) == 1.0\n    assert Mod(x**2, y).evalf(subs={x: 5, y: -6}) == 25.0\n    assert Mod(x**2, y).evalf(subs={x: -5, y: -6}) == 25.0\n    assert Mod(x**2, 2).evalf(subs={x: 5}) == 1.0\n    assert Mod(x**2, 2).evalf(subs={x: -5}) == 1.0\n    assert Mod(x**2, 2).evalf(subs={x: 4}) == 0.0\n    assert Mod(x**2, 2).evalf(subs={x: -4}) == 0.0\n    assert Mod(x**2, 2).evalf(subs={x: 3}) == 1.0\n    assert Mod(x**2, 2).evalf(subs={x: -3}) == 1.0\n"], "sample_1099": ["def test_partial_derivative():\n    expr = PartialDerivative(A(i), A(j))\n    assert expr.get_indices() == [i, -j]\n    assert expr.get_free_indices() == [i, j]\n\n    expr = PartialDerivative(A(i), A(i))\n    assert expr.get_indices() == [L_0, -L_0]\n    assert expr.get_free_indices() == []\n\n    expr = PartialDerivative(A(i)*B(j), A(k))\n    assert expr.get_indices() == [i, j, -k]\n    assert expr.get_free_indices() == [i, j, k]\n\n    expr = PartialDerivative(A(i)*B(j), A(i))\n    assert expr.get_indices() == [L_0, j, -L_0]\n    assert expr.get_free_indices() == [j]\n\n    expr = PartialDerivative(A(i)*B(j), A(i), A(j))\n    assert expr.get_indices() == [L_0, L_1, -L_0, -L_1]\n    assert expr.get_free_indices() == []\n\n    expr = PartialDerivative(A(i)*B(j), A(k), A(m))\n    assert expr.get_indices() == [i, j, -k, -m]\n    assert expr.get_free_indices() == [i, j, k, m]\n\n    expr = PartialDerivative(H(i, j), A(k))\n    assert expr.get_indices() == [i, j, -k]\n    assert expr.get_free_indices() == [i, j, k]\n\n    expr = PartialDerivative(H(i, j), A(i))\n    assert expr.get_indices() == [L_0, j, -L_0]\n    assert expr.get_free_indices() == [j]\n\n    expr = PartialDerivative(H(i, j), A(i), A(j))\n    assert expr.get_indices() == [L_0, L_1, -L_0, -L_1]\n    assert expr.get_free_indices() == []\n\n    expr = PartialDerivative(H(i, j), A(k), A(m))\n    assert expr.get_indices() == [i, j, -k, -m]\n    assert expr.get_free_indices() == [i, j, k, m]\n\n    expr = PartialDerivative(A(i)*B(j)*C(k), A(i), A(j))\n    assert expr.get_indices() == [L_0, L_1, k, -"], "sample_863": ["def test_pipeline_fit_transform_with_sample_weight():\n    # Test that fit_transform works with sample weights\n    X = iris.data\n    y = iris.target\n    pipe = make_pipeline(StandardScaler(), LogisticRegression())\n    sample_weight = np.random.rand(len(X))\n    Xt = pipe.fit_transform(X, y, logisticregression__sample_weight=sample_weight)\n    assert Xt.shape[0] == len(X)\n"], "sample_206": ["def test_filefield_delete(self):\n    with tempfile.NamedTemporaryFile(suffix='.txt') as tmp:\n        file = File(tmp)\n        document = Document(docfile=file)\n        document.save()\n        self.assertIsNotNone(document.docfile)\n        document.docfile.delete(save=True)\n        self.assertIsNone(document.docfile)\n        with self.assertRaises(ValueError):\n            document.docfile.path\n        with self.assertRaises(ValueError):\n            document.docfile.url\n        with self.assertRaises(ValueError):\n            document.docfile.size\n"], "sample_532": ["def test_contour_labeler_event_handler():\n    fig, ax = plt.subplots()\n    cs = ContourSet(ax, [1, 2, 3], [[[(0, 0), (1, 0), (1, 1), (0, 1), (0, 0)]]],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    [None], [None], [None], [None], [None], [None], [None],\n                    ["], "sample_566": ["def test_subfigure_layout():\n    fig = plt.figure()\n    gs = gridspec.GridSpec(2, 2)\n    sfig1 = fig.add_subfigure(gs[0, 0])\n    sfig2 = fig.add_subfigure(gs[1, 0])\n    ax1 = sfig1.add_subplot()\n    ax2 = sfig2.add_subplot()\n    ax1.plot([1, 2, 3])\n    ax2.plot([4, 5, 6])\n    ax1.set_ylabel('YLabel 1')\n    ax2.set_ylabel('YLabel 2')\n    fig.align_ylabels()\n    fig.canvas.draw()\n    assert ax1.yaxis.label.get_window_extent().y0 < ax2.yaxis.label.get_window_extent().y0\n"], "sample_990": ["def test_hyperbolic_functions():\n    x = symbols('x')\n    z = Symbol('z')\n\n    # Test sinh\n    assert sinh(nan) == nan\n    assert sinh(oo) == oo\n    assert sinh(-oo) == -oo\n    assert sinh(0) == 0\n    assert sinh(pi*I/2) == I\n    assert sinh(-pi*I/2) == -I\n    assert sinh(z).diff(z) == cosh(z)\n    assert sinh(z).inverse() == asinh\n\n    # Test cosh\n    assert cosh(nan) == nan\n    assert cosh(oo) == oo\n    assert cosh(-oo) == oo\n    assert cosh(0) == 1\n    assert cosh(pi*I/2) == 0\n    assert cosh(-pi*I/2) == 0\n    assert cosh(z).diff(z) == sinh(z)\n    assert cosh(z).inverse() == acosh\n\n    # Test tanh\n    assert tanh(nan) == nan\n    assert tanh(oo) == 1\n    assert tanh(-oo) == -1\n    assert tanh(0) == 0\n    assert tanh(pi*I/4) == I\n    assert tanh(-pi*I/4) == -I\n    assert tanh(z).diff(z) == 1 - tanh(z)**2\n    assert tanh(z).inverse() == atanh\n\n    # Test coth\n    assert coth(nan) == nan\n    assert coth(oo) == 1\n    assert coth(-oo) == -1\n    assert coth(0) == zoo\n    assert coth(pi*I/4) == -I\n    assert coth(-pi*I/4) == I\n    assert coth(z).diff(z) == -1/sinh(z)**2\n    assert coth(z).inverse() == acoth\n\n    # Test csch\n    assert csch(nan) == nan\n    assert csch(oo) == 0\n    assert csch(-oo) == 0\n    assert csch(0) == zoo\n    assert csch(pi*I/2) == -I\n    assert csch(-pi*I/2) == I\n    assert csch(z).diff(z) == -coth"], "sample_831": ["def test_export_text():\n    # Test export_text with a decision tree classifier\n    clf = DecisionTreeClassifier(random_state=0)\n    clf.fit(X, y)\n    export_text(clf, feature_names=[\"feature1\", \"feature2\"])\n\n    # Test export_text with a decision tree regressor\n    reg = DecisionTreeRegressor(random_state=0)\n    reg.fit(X, y)\n    export_text(reg, feature_names=[\"feature1\", \"feature2\"])\n\n    # Test export_text with a multi-output decision tree regressor\n    reg = DecisionTreeRegressor(random_state=0)\n    reg.fit(X, y2)\n    export_text(reg, feature_names=[\"feature1\", \"feature2\"])\n\n    # Test export_text with a decision tree classifier and weights\n    clf = DecisionTreeClassifier(random_state=0)\n    clf.fit(X, y, sample_weight=w)\n    export_text(clf, feature_names=[\"feature1\", \"feature2\"], show_weights=True)\n\n    # Test export_text with a decision tree regressor and weights\n    reg = DecisionTreeRegressor(random_state=0)\n    reg.fit(X, y, sample_weight=w)\n    export_text(reg, feature_names=[\"feature1\", \"feature2\"])\n\n    # Test export_text with a decision tree classifier and max_depth\n    clf = DecisionTreeClassifier(random_state=0, max_depth=1)\n    clf.fit(X, y)\n    export_text(clf, feature_names=[\"feature1\", \"feature2\"], max_depth=1)\n\n    # Test export_text with a decision tree regressor and max_depth\n    reg = DecisionTreeRegressor(random_state=0, max_depth=1)\n    reg.fit(X, y)\n    export_text(reg, feature_names=[\"feature1\", \"feature2\"], max_depth=1)\n\n    # Test export_text with a decision tree classifier and decimals\n    clf = DecisionTreeClassifier(random_state=0)\n    clf.fit(X, y)\n    export_text(clf, feature_names=[\"feature1\", \"feature2\"], decimals=4)\n\n    # Test export_text with a decision tree regressor and decimals\n    reg = DecisionTreeRegressor(random_state=0)\n    reg.fit(X, y)\n    export_text(reg, feature_names=[\"feature1\", \"feature2\"], decimals=4)\n\n    # Test export_text with a decision tree classifier and spacing\n    clf = DecisionTreeClassifier(random_state=0)\n    clf.fit(X, y)\n    export_text(clf, feature_names=[\"feature1"], "sample_8": ["def test_masked_nanfunc(self):\n    # Test that masked values are treated as NaN in nanfunctions\n    a = Masked(np.array([1, 2, 3, 4, 5]), mask=[True, False, False, True, False])\n    assert_array_equal(nansum(a), 9)\n    assert_array_equal(nanmean(a), 3)\n    assert_array_equal(nanmedian(a), 3)\n    assert_array_equal(nanmin(a), 2)\n    assert_array_equal(nanmax(a), 5)\n    assert_array_equal(nanprod(a), 10)\n    assert_array_equal(nanstd(a), np.sqrt(2))\n    assert_array_equal(nanvar(a), 2)\n    assert_array_equal(nanargmin(a), 1)\n    assert_array_equal(nanargmax(a), 4)\n"], "sample_914": ["def test_unparse_arguments(source, expected):\n    tree = ast.parse(source)\n    assert ast.unparse_arguments(tree.body[0].args) == expected\n"], "sample_161": ["def test_foreign_object_check_to_fields_exist(self):\n    class Model(models.Model):\n        pass\n\n    class RelatedModel(models.Model):\n        pass\n\n    field = ForeignObject(to=RelatedModel, on_delete=models.CASCADE, from_fields=['id'], to_fields=['nonexistent_field'])\n    errors = field.check()\n    self.assertEqual(len(errors), 1)\n    self.assertIsInstance(errors[0], Error)\n    self.assertEqual(errors[0].id, 'fields.E312')\n"], "sample_504": ["def test_colorbar_extension_length():\n    \"\"\"\n    Test colorbar extension length for uniform and proportional spacing.\n    \"\"\"\n    _colorbar_extension_length('uniform')\n    _colorbar_extension_length('proportional')\n\n"], "sample_1171": ["def test_ComplexRegion():\n    x, y = symbols('x y', real=True)\n    r, theta = symbols('r theta', real=True)\n    assert ComplexRegion(Interval(0, 1)*Interval(0, 2*pi), polar=True)._contains(1 + I) is True\n    assert ComplexRegion(Interval(0, 1)*Interval(0, 2*pi), polar=True)._contains(1 - I) is False\n    assert ComplexRegion(Interval(0, 1)*Interval(0, pi), polar=True)._contains(1 + I) is True\n    assert ComplexRegion(Interval(0, 1)*Interval(0, pi), polar=True)._contains(1 - I) is False\n    assert ComplexRegion(Interval(0, 1)*Interval(0, 2*pi), polar=True)._contains(2 + I) is False\n    assert ComplexRegion(Interval(0, 1)*Interval(0, 2*pi), polar=True)._contains(1 + 2*I) is False\n    assert ComplexRegion(Interval(0, 1)*Interval(0, 2*pi), polar=True)._contains(0) is True\n    assert ComplexRegion(Interval(0, 1)*Interval(0, 2*pi), polar=True)._contains(0 + 0*I) is True\n    assert ComplexRegion(Interval(0, 1)*Interval(0, 2*pi), polar=True)._contains(1 + 0*I) is True\n    assert ComplexRegion(Interval(0, 1)*Interval(0, 2*pi), polar=True)._contains(0 + 1*I) is True\n    assert ComplexRegion(Interval(0, 1)*Interval(0, 2*pi), polar=True)._contains(1 + 1*I) is True\n    assert ComplexRegion(Interval(0, 1)*Interval(0, 2*pi), polar=True)._contains(2 + 0*I) is False\n    assert ComplexRegion(Interval(0, 1)*Interval(0, 2*pi), polar=True)._contains(0 + 2*I) is False\n    assert ComplexRegion(Interval(0, 1)*Interval(0, 2*pi), polar=True)._contains(2 + 2*I) is False\n    assert ComplexRegion(Interval(0, 1)*Interval(0, 2*pi"], "sample_472": ["    def test_get_elided_page_range(self):\n        paginator = Paginator(range(50), 10)\n        self.assertEqual(\n            list(paginator.get_elided_page_range(1)),\n            [1, 2, 3, 4, 5, \"...\", 46, 47, 48, 49, 50],\n        )\n        self.assertEqual(\n            list(paginator.get_elided_page_range(5)),\n            [1, 2, \"...\", 3, 4, 5, 6, 7, \"...\", 49, 50],\n        )\n        self.assertEqual(\n            list(paginator.get_elided_page_range(50)),\n            [1, 2, \"...\", 46, 47, 48, 49, 50],\n        )\n        self.assertEqual(\n            list(paginator.get_elided_page_range(1, on_each_side=1, on_ends=1)),\n            [1, 2, \"...\", 49, 50],\n        )\n        self.assertEqual(\n            list(paginator.get_elided_page_range(5, on_each_side=2, on_ends=2)),\n            [1, 2, 3, \"...\", 3, 4, 5, 6, 7, \"...\", 48, 49, 50],\n        )\n"], "sample_898": ["def test_roc_auc_score():\n    # Test that roc_auc_score raises an error when there is only one class\n    y_true = np.array([1, 1, 1, 1])\n    y_score = np.array([0.1, 0.4, 0.35, 0.8])\n    assert_raises(ValueError, roc_auc_score, y_true, y_score)\n\n    # Test that roc_auc_score raises an error when y_true is not binary\n    y_true = np.array([0, 1, 2, 0])\n    y_score = np.array([0.1, 0.4, 0.35, 0.8])\n    assert_raises(ValueError, roc_auc_score, y_true, y_score)\n\n    # Test that roc_auc_score raises an error when y_score is not 1D\n    y_true = np.array([0, 1, 0, 1])\n    y_score = np.array([[0.1, 0.2], [0.4, 0.5], [0.35, 0.45], [0.8, 0.9]])\n    assert_raises(ValueError, roc_auc_score, y_true, y_score)\n\n    # Test that roc_auc_score raises an error when y_true and y_score have different lengths\n    y_true = np.array([0, 1, 0, 1])\n    y_score = np.array([0.1, 0.4, 0.35, 0.8, 0.9])\n    assert_raises(ValueError, roc_auc_score, y_true, y_score)\n\n    # Test that roc_auc_score raises an error when max_fpr is not in (0, 1]\n    y_true = np.array([0, 1, 0, 1])\n    y_score = np.array([0.1, 0.4, 0.35, 0.8])\n    assert_raises(ValueError, roc_auc_score, y_true, y_score, max_fpr=2)\n\n    # Test that roc_auc_score raises an error when max_fpr is not a float\n    y_true = np.array([0, 1, 0, 1])\n    y_score = np.array([0.1, 0.4, 0.35, 0.8])\n    assert_raises(ValueError, roc_auc_score, y_true, y_score, max_f"], "sample_985": ["def test_max_min():\n    x, y = symbols('x y')\n    assert Max(x, -2).subs(x, 3) == 3\n    assert Max(x, y) == Max(y, x)\n    assert Max(x, Max(y, 1)) == Max(x, y, 1)\n    assert Max(1, x, float('inf')) == float('inf')\n    assert Min(x, -2).subs(x, 3) == -2\n    assert Min(x, y) == Min(y, x)\n    assert Min(x, Min(y, 1)) == Min(x, y, 1)\n    assert Min(1, x, float('-inf')) == float('-inf')\n"], "sample_942": ["def test_parse_annotation():\n    env = Mock(spec=['ref_context'])\n    env.ref_context = {'py:module': 'test_module'}\n    annotation = 'List[int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 4\n    assert isinstance(result[0], desc_sig_punctuation)\n    assert result[0].astext() == '['\n    assert isinstance(result[1], pending_xref)\n    assert result[1].astext() == 'List'\n    assert isinstance(result[2], desc_sig_punctuation)\n    assert result[2].astext() == '['\n    assert isinstance(result[3], desc_sig_punctuation)\n    assert result[3].astext() == ']'\n\n    annotation = 'Union[int, str]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 7\n    assert isinstance(result[0], desc_sig_punctuation)\n    assert result[0].astext() == '('\n    assert isinstance(result[1], pending_xref)\n    assert result[1].astext() == 'Union'\n    assert isinstance(result[2], desc_sig_punctuation)\n    assert result[2].astext() == '['\n    assert isinstance(result[3], pending_xref)\n    assert result[3].astext() == 'int'\n    assert isinstance(result[4], desc_sig_punctuation)\n    assert result[4].astext() == ','\n    assert isinstance(result[5], pending_xref)\n    assert result[5].astext() == 'str'\n    assert isinstance(result[6], desc_sig_punctuation)\n    assert result[6].astext() == ']'\n\n    annotation = 'Tuple[int, ...]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 6\n    assert isinstance(result[0], desc_sig_punctuation)\n    assert result[0].astext() == '('\n    assert isinstance(result[1], pending_xref)\n    assert result[1].astext() == 'Tuple'\n    assert isinstance(result[2], desc_sig_punctuation)\n    assert result[2].astext() == '['\n    assert isinstance(result[3], pending_xref)\n    assert result[3].astext() == 'int'\n    assert isinstance(result[4], desc_sig_punctuation)\n    assert result[4].astext() == ','\n    assert isinstance(result[5], desc_sig_punctuation)\n    assert result"], "sample_818": ["def test_spectral_clustering():\n    # Test that spectral clustering can handle a variety of affinity matrices\n    n_samples = 10\n    for affinity in ['rbf', 'nearest_neighbors', 'precomputed']:\n        if affinity == 'precomputed':\n            X = np.random.rand(n_samples, n_samples)\n            X = (X + X.T) / 2  # Ensure symmetry\n        else:\n            X, _ = make_blobs(n_samples=n_samples, centers=3, random_state=0)\n\n        clustering = SpectralClustering(n_clusters=3, affinity=affinity,\n                                       random_state=0)\n        clustering.fit(X)\n\n        assert_equal(clustering.labels_.shape, (n_samples,))\n        assert_equal(len(np.unique(clustering.labels_)), 3)\n\n"], "sample_435": ["    def test_widget(self):\n        field = ReadOnlyPasswordHashField()\n        widget = field.widget\n        self.assertEqual(widget.template_name, \"auth/widgets/read_only_password_hash.html\")\n        self.assertTrue(widget.read_only)\n"], "sample_1136": ["def test_expression_domain():\n    K = EX()\n\n    # Test conversion from SymPy objects\n    assert K.from_sympy(1) == K.one\n    assert K.from_sympy(2) == K(2)\n    assert K.from_sympy(x) == K(x)\n\n    # Test conversion from Python objects\n    assert K.from_ZZ_python(1) == K.one\n    assert K.from_ZZ_python(2) == K(2)\n    assert K.from_QQ_python(Rational(1, 2)) == K(Rational(1, 2))\n\n    # Test conversion from GMPY objects\n    # Note: GMPY is not a standard library, so we skip these tests\n    # assert K.from_ZZ_gmpy(mpz(1)) == K.one\n    # assert K.from_ZZ_gmpy(mpz(2)) == K(2)\n    # assert K.from_QQ_gmpy(mpq(1, 2)) == K(Rational(1, 2))\n\n    # Test conversion from GaussianIntegerRing and GaussianRationalField\n    assert K.from_GaussianIntegerRing(ZZ_I(1)) == K(1)\n    assert K.from_GaussianIntegerRing(ZZ_I(2)) == K(2)\n    assert K.from_GaussianRationalField(QQ_I(1, 2)) == K(Rational(1, 2))\n\n    # Test conversion from RealField\n    assert K.from_RealField(RR(1)) == K(1)\n    assert K.from_RealField(RR(2)) == K(2)\n\n    # Test conversion from PolynomialRing and FractionField\n    assert K.from_PolynomialRing(Poly(x, x)) == K(x)\n    assert K.from_FractionField(Poly(x, x) / Poly(x, x)) == K(x / x)\n\n    # Test conversion from ExpressionDomain\n    assert K.from_ExpressionDomain(K(1)) == K(1)\n    assert K.from_ExpressionDomain(K(x)) == K(x)\n\n    # Test get_ring and get_field\n    assert K.get_ring() == K\n    assert K.get_field() == K\n\n    # Test is_positive, is_negative, is_nonpositive, is_nonnegative\n    assert K.is_positive(K(1))\n    assert not K.is_positive(K(-1))\n    assert K.is_negative(K(-1))\n    assert not K.is_negative(K"], "sample_705": ["def test_pytester_makefile(tmp_path_factory, pytester):\n    pytester = pytester(tmp_path_factory, _ispytest=True)\n    pytester.makefile(\".txt\", \"line1\", \"line2\")\n    assert pytester.path.joinpath(\"test_makefile.txt\").exists()\n    pytester.makefile(\".txt\", custom=\"line3\")\n    assert pytester.path.joinpath(\"custom.txt\").exists()\n    pytester.makefile(\".txt\", custom2=\"line4\", custom3=\"line5\")\n    assert pytester.path.joinpath(\"custom2.txt\").exists()\n    assert pytester.path.joinpath(\"custom3.txt\").exists()\n"], "sample_1047": ["def test_ask():\n    x = Symbol('x')\n    assert x.is_real is None\n    assert x.is_complex is None\n    assert x.is_integer is None\n    assert x.is_prime is None\n    assert x.is_composite is None\n    assert x.is_negative is None\n    assert x.is_positive is None\n    assert x.is_nonpositive is None\n    assert x.is_nonnegative is None\n    assert x.is_zero is None\n    assert x.is_nonzero is None\n    assert x.is_rational is None\n    assert x.is_algebraic is None\n    assert x.is_transcendental is None\n    assert x.is_irrational is None\n    assert x.is_finite is None\n    assert x.is_infinite is None\n    assert x.is_hermitian is None\n    assert x.is_antihermitian is None\n    assert x.is_commutative is None\n\n    x = Symbol('x', real=True)\n    assert x.is_real is True\n    assert x.is_complex is True\n    assert x.is_integer is None\n    assert x.is_prime is None\n    assert x.is_composite is None\n    assert x.is_negative is None\n    assert x.is_positive is None\n    assert x.is_nonpositive is None\n    assert x.is_nonnegative is None\n    assert x.is_zero is None\n    assert x.is_nonzero is None\n    assert x.is_rational is None\n    assert x.is_algebraic is True\n    assert x.is_transcendental is None\n    assert x.is_irrational is None\n    assert x.is_finite is True\n    assert x.is_infinite is False\n    assert x.is_hermitian is True\n    assert x.is_antihermitian is False\n    assert x.is_commutative is True\n\n    x = Symbol('x', real=True, positive=True)\n    assert x.is_real is True\n    assert x.is_complex is True\n    assert x.is_integer is None\n    assert x.is_prime is None\n    assert x.is_composite is None\n    assert x.is_negative is False\n    assert x.is_positive is True\n    assert x.is_nonpositive is False\n    assert x.is_nonnegative is True\n    assert x.is_zero is False\n    assert x.is_nonzero is True\n    assert x.is_rational is None\n    assert x.is_algebraic is"], "sample_1193": ["def test_are_coplanar():\n    p1, p2, p3, p4 = Point3D(0, 0, 0), Point3D(1, 0, 0), Point3D(0, 1, 0), Point3D(0, 0, 1)\n    assert are_coplanar(p1, p2, p3) is True\n    assert are_coplanar(p1, p2, p3, p4) is False\n    l1, l2 = Line3D(p1, p2), Line3D(p3, p4)\n    assert are_coplanar(l1, l2) is False\n    p = Plane(p1, p2, p3)\n    assert are_coplanar(p, p1, p2, p3) is True\n    assert are_coplanar(p, p1, p2, p4) is False\n"], "sample_666": ["    def test_catching_logs(self, caplog):\n        with caplog.at_level(logging.INFO):\n            logging.info(\"Test log message\")\n        assert len(caplog.records) == 1\n        assert caplog.records[0].getMessage() == \"Test log message\"\n"], "sample_1115": ["def test_TensorElement():\n    L = TensorIndexType(\"L\")\n    i, j, k = symbols(\"i j k\")\n    A = TensorHead(\"A\", [L, L], TensorSymmetry.fully_symmetric(2))\n    te = TensorElement(A(i, j), {i: 2})\n    assert te.get_free_indices() == [j]\n    assert te.get_indices() == [2, j]\n    assert te.expr == A(i, j)\n    assert te.index_map == {i: 2}\n    assert te.coeff == 1\n    assert te.nocoeff == te\n    assert te.free == [(j, 1)]\n    assert te.dum == []\n    assert te._replace_indices({j: k}) == TensorElement(A(i, k), {i: 2})\n    assert te.get_indices() == [2, j]\n    assert te._extract_data({A(i, j): Array([[1, 2], [3, 4]])}) == ([j], Array([[3], [4]]))\n"], "sample_466": ["    def test_operation_writer_serialize(self):\n        class TestOperation(migrations.operations.base.Operation):\n                return (\"TestOperation\", [], {})\n\n        writer = OperationWriter(TestOperation())\n        serialized, imports = writer.serialize()\n        self.assertEqual(serialized, \"migrations.TestOperation(),\")\n        self.assertEqual(imports, set())\n\n        class TestOperationWithArgs(migrations.operations.base.Operation):\n                self.arg1 = arg1\n                self.arg2 = arg2\n\n                return (\"TestOperationWithArgs\", [self.arg1], {\"arg2\": self.arg2})\n\n        writer = OperationWriter(TestOperationWithArgs(\"arg1\", \"arg2\"))\n        serialized, imports = writer.serialize()\n        self.assertEqual(serialized, \"migrations.TestOperationWithArgs(arg1='arg1', arg2='arg2'),\")\n        self.assertEqual(imports, set())\n\n        class TestOperationWithListArg(migrations.operations.base.Operation):\n                self.arg = arg\n\n                return (\"TestOperationWithListArg\", [self.arg], {})\n\n        writer = OperationWriter(TestOperationWithListArg([1, 2, 3]))\n        serialized, imports = writer.serialize()\n        self.assertEqual(serialized, \"migrations.TestOperationWithListArg(arg=[1, 2, 3]),\")\n        self.assertEqual(imports, set())\n\n        class TestOperationWithDictArg(migrations.operations.base.Operation):\n                self.arg = arg\n\n                return (\"TestOperationWithDictArg\", [self.arg], {})\n\n        writer = OperationWriter(TestOperationWithDictArg({\"a\": 1, \"b\": 2}))\n        serialized, imports = writer.serialize()\n        self.assertEqual(serialized, \"migrations.TestOperationWithDictArg(arg={'a': 1, 'b': 2}),\")\n        self.assertEqual(imports, set())\n"], "sample_486": ["def test_inlineformset_factory_with_editable_child_pk(self):\n    ChildFormSet = inlineformset_factory(\n        AutoPKParent, ChildWithEditablePK, fields=(\"child_field\",)\n    )\n    parent = AutoPKParent.objects.create()\n    child = ChildWithEditablePK.objects.create(parent=parent, child_field=\"child\")\n    formset = ChildFormSet(instance=parent)\n    self.assertEqual(len(formset.forms), 1)\n    self.assertEqual(formset.forms[0].instance, child)\n    self.assertEqual(formset.forms[0].fields[\"id\"].widget.attrs[\"type\"], \"number\")\n"], "sample_403": ["    def test_rename_index(self):\n        # Create a model with an index\n        operation = migrations.CreateModel(\n            \"TestModel\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=255)),\n            ],\n            options={\"indexes\": [models.Index(fields=[\"name\"])]},\n        )\n        self.apply_operations(operation)\n\n        # Rename the index\n        operation = migrations.RenameIndex(\n            \"TestModel\", \"new_name\", \"TestModel_name_5f5dfb_idx\"\n        )\n        self.apply_operations(operation)\n\n        # Check the index was renamed\n        with connection.cursor() as cursor:\n            cursor.execute(\n                \"SELECT relname FROM pg_class WHERE relname = 'TestModel_new_name'\"\n            )\n            self.assertEqual(len(cursor.fetchall()), 1)\n\n        # Reverse the operation\n        self.reverse_operations(operation)\n\n        # Check the index was renamed back\n        with connection.cursor() as cursor:\n            cursor.execute(\n                \"SELECT relname FROM pg_class WHERE relname = 'TestModel_name_5f5dfb_idx'\"\n            )\n            self.assertEqual(len(cursor.fetchall()), 1)\n"], "sample_1140": ["def test_tensor():\n    i = TensorIndexType('i')\n    j = TensorIndexType('j')\n    k = TensorIndexType('k')\n    l = TensorIndexType('l')\n    m = TensorIndexType('m')\n    n = TensorIndexType('n')\n    p = TensorIndexType('p')\n    q = TensorIndexType('q')\n    r = TensorIndexType('r')\n    s = TensorIndexType('s')\n    t = TensorIndexType('t')\n    u = TensorIndexType('u')\n    v = TensorIndexType('v')\n    w = TensorIndexType('w')\n    x = TensorIndexType('x')\n    y = TensorIndexType('y')\n    z = TensorIndexType('z')\n    a = TensorIndexType('a')\n    b = TensorIndexType('b')\n    c = TensorIndexType('c')\n    d = TensorIndexType('d')\n    e = TensorIndexType('e')\n    f = TensorIndexType('f')\n    g = TensorIndexType('g')\n    h = TensorIndexType('h')\n\n    A = TensorHead('A', [i, j])\n    B = TensorHead('B', [k, l])\n    C = TensorHead('C', [m, n])\n    D = TensorHead('D', [p, q])\n    E = TensorHead('E', [r, s])\n    F = TensorHead('F', [t, u])\n    G = TensorHead('G', [v, w])\n    H = TensorHead('H', [x, y])\n    I = TensorHead('I', [z, a])\n    J = TensorHead('J', [b, c])\n    K = TensorHead('K', [d, e])\n    L = TensorHead('L', [f, g])\n    M = TensorHead('M', [h, i])\n\n    assert pretty(A(i, j)) == \"A_ij\"\n    assert pretty(B(k, l)) == \"B_kl\"\n    assert pretty(C(m, n)) == \"C_mn\"\n    assert pretty(D(p, q)) == \"D_pq\"\n    assert pretty(E(r, s)) == \"E_rs\"\n    assert pretty(F(t, u)) == \"F_tu\"\n    assert pretty(G(v, w)) == \"G_vw\"\n    assert pretty(H(x, y)) == \"H_xy\"\n    assert"], "sample_682": ["def test_evaluate_xfail_marks_with_strict_and_run_true(testdir: Testdir) -> None:\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xfail(strict=True, run=True)\n            assert 1 == 2\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=0, failed=1, xfailed=0)\n    result.assert_reprecinfo(\"assert 1 == 2\")\n"], "sample_679": ["    def test_mark_evaluator_invalidraise(self, capsys):\n        item = mock.Mock(spec=Node)\n        item.iter_markers.return_value = [Mark(\"raises\", (\"Exception\",))]\n        evaluator = MarkEvaluator(item, \"raises\")\n        exc = Exception()\n        assert evaluator.invalidraise(exc) is True\n        assert evaluator.invalidraise(Exception) is True\n        assert evaluator.invalidraise(object) is False\n        assert evaluator.invalidraise(None) is None\n"], "sample_343": ["def test_generic_foreign_key_get_filter_kwargs_for_object(self):\n    post = Post.objects.create()\n    answer = Answer.objects.create(content_object=post)\n    gfk = GenericForeignKey()\n    filter_kwargs = gfk.get_filter_kwargs_for_object(answer)\n    self.assertEqual(filter_kwargs, {'object_id': answer.object_id, 'content_type': answer.content_type})\n"], "sample_1059": ["def test_jacobi_normalized():\n    n = Symbol('n')\n    a = Symbol('a')\n    b = Symbol('b')\n    x = Symbol('x')\n\n    assert jacobi_normalized(0, a, b, x) == 1\n    assert jacobi_normalized(1, a, b, x) == jacobi(1, a, b, x) / sqrt(2**(a + b + 1)*gamma(a + 1)*gamma(b + 1)/((a + b + 1)*gamma(a + b + 1)))\n    assert jacobi_normalized(n, a, b, x) == jacobi(n, a, b, x) / sqrt(2**(a + b + 1)*gamma(a + n + 1)*gamma(b + n + 1)/((a + b + 2*n + 1)*factorial(n)*gamma(a + b + n + 1)))\n\n    assert jacobi_normalized(0, 0, 0, x) == 1\n    assert jacobi_normalized(1, 0, 0, x) == x\n    assert jacobi_normalized(2, 0, 0, x) == (3*x**2 - 1)/2\n\n    assert jacobi_normalized(0, 1/2, 1/2, x) == 1\n    assert jacobi_normalized(1, 1/2, 1/2, x) == 2*x\n    assert jacobi_normalized(2, 1/2, 1/2, x) == 4*x**2 - 1\n\n    assert jacobi_normalized(0, -1/2, -1/2, x) == 1\n    assert jacobi_normalized(1, -1/2, -1/2, x) == x\n    assert jacobi_normalized(2, -1/2, -1/2, x) == 2*x**2 - 1\n\n    assert jacobi_normalized(0, a, a, x) == 1\n    assert jacobi_normalized(1, a, a, x) == (2*a + 1)*x / sqrt(2**(2*a + 1)*gamma(a + 1)**2/(2*a + 1)*gamma(2*a + 1))\n    assert jacobi_normalized(2, a, a, x) =="], "sample_142": ["    def test_model_to_dict(self):\n        album = Album.objects.create(title='Test Album')\n        data = model_to_dict(album)\n        self.assertEqual(data, {'id': album.id, 'title': 'Test Album'})\n"], "sample_124": ["    def test_uuid_field(self):\n        class UUIDForm(Form):\n            uuid = UUIDField()\n\n        form = UUIDForm({'uuid': '123e4567-e89b-12d3-a456-426655440000'})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['uuid'], uuid.UUID('123e4567-e89b-12d3-a456-426655440000'))\n\n        form = UUIDForm({'uuid': '123e4567-e89b-12d3-a456-42665544000'})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors['uuid'], ['Enter a valid UUID.'])\n\n        form = UUIDForm({'uuid': '123e4567-e89b-12d3-a456-426655440000', 'uuid': '123e4567-e89b-12d3-a456-426655440001'})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors['uuid'], ['Enter a valid UUID.'])\n\n        form = UUIDForm({'uuid': uuid.UUID('123e4567-e89b-12d3-a456-426655440000')})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['uuid'], uuid.UUID('123e4567-e89b-12d3-a456-426655440000'))\n"], "sample_1011": ["def test_octave_code():\n    assert octave_code(sin(x).series(x).removeO()) == 'x.^5/120 - x.^3/6 + x'\n    assert octave_code((2*tau)**Rational(7, 2)) == '8*sqrt(2)*tau.^(7/2)'\n    assert octave_code(sin(pi*x*y), assign_to=\"s\") == 's = sin(pi*x.*y);'\n    assert octave_code(3*pi*A**3) == '(3*pi)*A^3'\n    assert octave_code(x**2*y*A**3) == '(x.^2.*y)*A^3'\n    assert octave_code(mat, assign_to='A') == 'A = [x.^2 sin(x) ceil(x)];'\n    assert octave_code(pw, assign_to=tau) == 'tau = ((x > 0).*(x + 1) + (~(x > 0)).*(x));'\n    assert octave_code(mat, assign_to='A') == 'A = [x.^2 ((x > 0).*(x + 1) + (~(x > 0)).*(x)) sin(x)];'\n    assert octave_code(f(x) + g(x) + g(mat), user_functions=custom_functions) == 'existing_octave_fcn(x) + my_fcn(x) + my_mat_fcn([1 x])'\n    assert octave_code(e.rhs, assign_to=e.lhs, contract=False) == 'Dy(i) = (y(i + 1) - y(i))./(t(i + 1) - t(i));'\n"], "sample_186": ["    def test_modeladmin_checks(self):\n        site = AdminSite()\n        admin_obj = ValidFields(Song, site)\n        errors = admin_obj.check()\n        self.assertEqual(errors, [])\n\n        admin_obj = ValidFormFieldsets(Song, site)\n        errors = admin_obj.check()\n        self.assertEqual(errors, [])\n\n        admin_obj = MyAdmin(Song, site)\n        errors = admin_obj.check()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0], 'error!')\n\n        class InvalidFields(admin.ModelAdmin):\n            fields = ['invalid_field']\n\n        admin_obj = InvalidFields(Song, site)\n        errors = admin_obj.check()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'admin.E006')\n\n        class InvalidFieldsets(admin.ModelAdmin):\n            fieldsets = (\n                ('Invalid', {\n                    'fields': ('invalid_field',),\n                }),\n            )\n\n        admin_obj = InvalidFieldsets(Song, site)\n        errors = admin_obj.check()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'admin.E012')\n\n        class InvalidExclude(admin.ModelAdmin):\n            exclude = ['invalid_field']\n\n        admin_obj = InvalidExclude(Song, site)\n        errors = admin_obj.check()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'admin.E015')\n\n        class InvalidForm(admin.ModelAdmin):\n            form = forms.Form\n\n        admin_obj = InvalidForm(Song, site)\n        errors = admin_obj.check()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'admin.E016')\n\n        class InvalidFilterVertical(admin.ModelAdmin):\n            filter_vertical = ['invalid_field']\n\n        admin_obj = InvalidFilterVertical(Song, site)\n        errors = admin_obj.check()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'admin.E019')\n\n        class InvalidFilterHorizontal(admin.ModelAdmin):\n            filter_horizontal = ['invalid_field']\n\n        admin_obj = InvalidFilterHorizontal(Song, site)\n        errors = admin_obj.check()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'admin.E019')\n\n        class InvalidRadioFields(admin.ModelAdmin):\n            radio_fields = {'invalid_field': 'invalid_value'}\n\n        admin_obj = InvalidRadioFields(Song, site)\n        errors = admin_obj.check()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id"], "sample_409": ["    def test_blocktranslate_with_context(self, tag_name=\"blocktranslate\"):\n        template = Template(\"{% load i18n %}{% blocktranslate with bar='foo' context 'greeting' %}\"\n                            \"This is {{ bar }}.\"\n                            \"{% endblocktranslate %}\")\n        with translation.override(\"fr\"):\n            rendered = template.render(Context({\"bar\": \"baz\"}))\n            self.assertEqual(rendered, \"This is baz.\")\n"], "sample_709": ["def test_pytester_runitem(pytester: Pytester) -> None:\n    class TestClass:\n                return item.runtest()\n\n            return run\n\n    pytester._request.instance = TestClass()\n    source = \"\"\"\n            assert 1 == 1\n    \"\"\"\n    pytester.runitem(source)\n"], "sample_362": ["def test_altered_unique_together(self):\n    before_state = self.make_project_state([\n        self.book_foo_together,\n    ])\n    after_state = self.make_project_state([\n        self.book_foo_together_2,\n    ])\n    changes = self.get_changes(before_state, after_state)\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\"])\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 0, unique_together={(\"title\", \"author\")})\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 1, index_together={(\"title\", \"author\")})\n"], "sample_659": ["def test_traceback_entry_repr():\n    class FakeFrame:\n            self.f_lineno = lineno\n            self.f_code = type(\"Code\", (), {\"co_filename\": filename, \"co_name\": name})\n\n    entry = TracebackEntry(type(\"FakeTraceback\", (), {\"tb_lineno\": 10, \"tb_frame\": FakeFrame(\"test_file.py\", 10, \"test_func\")}))\n    assert repr(entry) == \"<TracebackEntry test_file.py:10>\"\n"], "sample_74": ["def test_runshell_db_with_ssl(self):\n    dbinfo = {\n        'host': 'localhost',\n        'port': 5432,\n        'database': 'mydb',\n        'user': 'myuser',\n        'password': 'mypassword',\n        'sslmode': 'require',\n        'sslrootcert': '/path/to/sslrootcert',\n        'sslcert': '/path/to/sslcert',\n        'sslkey': '/path/to/sslkey',\n    }\n    args, pg_env = self._run_it(dbinfo)\n    self.assertEqual(args, [\n        'psql', '-U', 'myuser', '-h', 'localhost', '-p', '5432', 'mydb'\n    ])\n    self.assertEqual(pg_env, {\n        'PGPASSWORD': 'mypassword',\n        'PGSSLMODE': 'require',\n        'PGSSLROOTCERT': '/path/to/sslrootcert',\n        'PGSSLCERT': '/path/to/sslcert',\n        'PGSSLKEY': '/path/to/sslkey',\n    })\n"], "sample_1180": ["def test_point():\n    p1 = Point(1, 2, 3)\n    p2 = Point(4, 5, 6)\n    p3 = Point(7, 8, 9)\n\n    assert p1.is_collinear(p2, p3) == True\n    assert p1.is_concyclic(p2, p3) == False\n\n    p4 = Point(1, 1, 1)\n    p5 = Point(2, 2, 2)\n    p6 = Point(3, 3, 3)\n\n    assert p4.is_collinear(p5, p6) == True\n    assert p4.is_concyclic(p5, p6) == True\n\n    p7 = Point(1, 2)\n    p8 = Point(3, 4)\n    p9 = Point(5, 6)\n\n    assert p7.is_collinear(p8, p9) == True\n    assert p7.is_concyclic(p8, p9) == True\n\n    p10 = Point(1, 2, 3, 4)\n    p11 = Point(5, 6, 7, 8)\n    p12 = Point(9, 10, 11, 12)\n\n    assert p10.is_collinear(p11, p12) == True\n    assert p10.is_concyclic(p11, p12) == False\n\n    p13 = Point(1, 2, 3, 4, 5)\n    p14 = Point(6, 7, 8, 9, 10)\n    p15 = Point(11, 12, 13, 14, 15)\n\n    assert p13.is_collinear(p14, p15) == True\n    assert p13.is_concyclic(p14, p15) == False\n\n    p16 = Point(1, 2, 3, 4, 5, 6)\n    p17 = Point(7, 8, 9, 10, 11, 12)\n    p18 = Point(13, 14, 15, 16, 17, 18)\n\n    assert p16.is_collinear(p17, p18) == True\n    assert p16.is_concyclic(p17, p18) == False\n\n    p19 = Point(1, 2"], "sample_385": ["    def test_autocomplete_select_multiple(self):\n        class AlbumForm(forms.ModelForm):\n            class Meta:\n                model = Album\n                fields = [\"band\", \"featuring\"]\n                widgets = {\n                    \"band\": AutocompleteSelectMultiple(\n                        Album._meta.get_field(\"band\"),\n                        admin.site,\n                        attrs={\"class\": \"my-class\"},\n                    ),\n                    \"featuring\": AutocompleteSelectMultiple(\n                        Album._meta.get_field(\"featuring\"),\n                        admin.site,\n                    ),\n                }\n\n        form = AlbumForm()\n        html = form.as_p()\n        self.assertIn(\"data-ajax--url\", html)\n        self.assertIn(\"data-app-label\", html)\n        self.assertIn(\"data-model-name\", html)\n        self.assertIn(\"data-field-name\", html)\n        self.assertIn(\"data-theme\", html)\n        self.assertIn(\"data-allow-clear\", html)\n        self.assertIn(\"lang\", html)\n        self.assertIn(\"class='admin-autocomplete\", html)\n"], "sample_631": ["def test_visit_assignname_with_augassign(self):\n    \"\"\"Test visit_assignname with AugAssign\"\"\"\n    node = astroid.extract_node(\n        \"\"\"\n        x = 5\n        x += 1\n    \"\"\"\n    )\n    with self.assertAddsMessages(\n        Message(\"used-before-assignment\", node=node.body[1].targets[0], args=(\"x\",))\n    ):\n        self.checker.visit_assignname(node.body[1].targets[0])\n"], "sample_919": ["def test_template_introduction():\n    input = \"template <typename T> concept C<T> { }\"\n    idDict = {2: \"I0XSt4CIXT_EE\", 3: \"I0XSt4CIXT_EE\", 4: \"I0XSt4CIXT_EE\"}\n    output = \"template <typename T> concept C<T> { }\"\n    check(\"concept\", input, idDict, output)\n"], "sample_967": ["def test_mathjax_rendering(app, status, warning):\n    # Test that mathjax is correctly rendered in HTML\n    app.build()\n    html = (app.outdir / 'index.html').read_text()\n    assert '<script src=\"' + MATHJAX_URL + '\" defer></script>' in html\n    assert '<span class=\"math notranslate nohighlight\">' in html\n    assert '<div class=\"math notranslate nohighlight\">' in html\n"], "sample_318": ["    def test_reverse_lazy(self):\n        from django.urls import reverse_lazy\n        from . import urlconf_outer\n        resolver = get_resolver(urlconf_outer)\n        self.assertEqual(resolver.reverse('urlobject-view', args=['42', '37']), '/test1/inner/42/37/')\n        self.assertEqual(resolver.reverse('urlobject-view', kwargs={'arg1': '42', 'arg2': '37'}), '/test1/inner/42/37/')\n        self.assertEqual(resolver.reverse('urlobject-view', args=['42', '37'], namespace='test-ns1'), '/test1/inner/42/37/')\n        self.assertEqual(resolver.reverse('urlobject-view', kwargs={'arg1': '42', 'arg2': '37'}, namespace='test-ns1'), '/test1/inner/42/37/')\n"], "sample_555": ["def test_annulus():\n    annulus = Annulus((0, 0), 1, 0.5)\n    assert_almost_equal(annulus.center, (0, 0))\n    assert_almost_equal(annulus.width, 0.5)\n    assert_almost_equal(annulus.angle, 0)\n    assert_almost_equal(annulus.a, 1)\n    assert_almost_equal(annulus.b, 1)\n    assert_almost_equal(annulus.radii, (1, 1))\n\n    annulus.set_center((1, 1))\n    annulus.set_width(0.2)\n    annulus.set_angle(45)\n    annulus.set_semimajor(2)\n    annulus.set_semiminor(3)\n    annulus.set_radii((4, 5))\n\n    assert_almost_equal(annulus.center, (1, 1))\n    assert_almost_equal(annulus.width, 0.2)\n    assert_almost_equal(annulus.angle, 45)\n    assert_almost_equal(annulus.a, 2)\n    assert_almost_equal(annulus.b, 3)\n    assert_almost_equal(annulus.radii, (2, 3))\n\n    annulus.set_center((0, 0))\n    annulus.set_width(0.5)\n    annulus.set_angle(0)\n    annulus.set_radii(1)\n\n    assert_almost_equal(annulus.center, (0, 0))\n    assert_almost_equal(annulus.width, 0.5)\n    assert_almost_equal(annulus.angle, 0)\n    assert_almost_equal(annulus.a, 1)\n    assert_almost_equal(annulus.b, 1)\n    assert_almost_equal(annulus.radii, (1, 1))\n"], "sample_975": ["def test_nsolve():\n    x = Symbol('x')\n    f = lambdify(x, sin(x) - x/2, 'mpmath')\n    assert nsolve(f, 3) == mpf(1.895494267033981)\n    assert nsolve(f, 3, solver='bisect') == mpf(1.895494267033981)\n    assert nsolve(f, 3, solver='secant') == mpf(1.895494267033981)\n    assert nsolve(f, 3, solver='newton') == mpf(1.895494267033981)\n    assert nsolve(f, 3, solver='mnewton') == mpf(1.895494267033981)\n    assert nsolve(f, 3, solver='brentq') == mpf(1.895494267033981)\n    assert nsolve(f, 3, solver='brentq', maxsteps=100) == mpf(1.895494267033981)\n    assert nsolve(f, 3, solver='brentq', maxsteps=100, bisection=(1, 4)) == mpf(1.895494267033981)\n    assert nsolve(f, 3, solver='ridder') == mpf(1.895494267033981)\n    assert nsolve(f, 3, solver='anderson') == mpf(1.895494267033981)\n    assert nsolve(f, 3, solver='krylov') == mpf(1.895494267033981)\n    assert nsolve(f, 3, solver='df-sane') == mpf(1.895494267033981)\n    assert nsolve(f, 3, solver='newton', fprime=lambda x: cos(x) - S.Half) == mpf(1.895494267033981)\n    assert nsolve(f, 3, solver='mnewton', fprime=lambda x: cos(x) - S.Half) == mpf(1.895494267033981)\n    assert nsolve(f, 3, solver='brentq', fprime=lambda x: cos(x) - S.Half) == mpf(1.895494267033981)\n    assert nsolve(f, 3, solver='brentq', fprime=lambda x: cos(x) - S.H"], "sample_194": ["    def test_check_constraint_creation(self):\n        with atomic():\n            constraint = BaseConstraint(name='test_constraint')\n            with self.assertRaises(NotImplementedError):\n                constraint.create_sql(ChildModel, connection.schema_editor)\n"], "sample_236": ["def test_collector_add_dependency(self):\n    collector = Collector(using='default')\n    model1 = A\n    model2 = B\n    collector.add_dependency(model1, model2)\n    self.assertIn(model2._meta.concrete_model, collector.dependencies[model1._meta.concrete_model])\n    self.assertIn(model2, collector.data)\n\n    collector = Collector(using='default')\n    model1 = A\n    model2 = B\n    collector.add_dependency(model1, model2, reverse_dependency=True)\n    self.assertIn(model1._meta.concrete_model, collector.dependencies[model2._meta.concrete_model])\n    self.assertIn(model1, collector.data)\n"], "sample_443": ["    def setUp(self):\n        self.cache = caches[\"default\"]\n"], "sample_212": ["def test_session_middleware_process_response(self):\n    # Create a mock request and response\n    request = HttpRequest()\n    request.COOKIES = {}\n    request.session = {}\n    response = HttpResponse()\n\n    # Test that the session cookie is set when the session is modified\n    request.session['test'] = 'value'\n    request.session.modified = True\n    SessionMiddleware().process_response(request, response)\n    self.assertIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n    # Test that the session cookie is deleted when the session is empty\n    request.session = {}\n    request.session.accessed = True\n    request.session.modified = False\n    request.COOKIES[settings.SESSION_COOKIE_NAME] = 'session_key'\n    SessionMiddleware().process_response(request, response)\n    self.assertNotIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n    # Test that the session cookie is not set when the response status code is 500\n    request.session['test'] = 'value'\n    request.session.modified = True\n    response.status_code = 500\n    SessionMiddleware().process_response(request, response)\n    self.assertNotIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n    # Test that a SuspiciousOperation is raised when the session is deleted before the request completes\n    request.session['test'] = 'value'\n    request.session.modified = True\n    request.session.delete()\n    with self.assertRaises(SuspiciousOperation):\n        SessionMiddleware().process_response(request, response)\n"], "sample_297": ["    def test_query_clone(self):\n        query = Query(Item)\n        query.add_filter(('name', 'one'))\n        query.add_ordering('name')\n        query.add_annotation(Count('*'), alias='count', is_summary=True)\n        query.select_for_update = True\n\n        cloned_query = query.clone()\n        self.assertEqual(cloned_query.where, query.where)\n        self.assertEqual(cloned_query.order_by, query.order_by)\n        self.assertEqual(cloned_query.annotations, query.annotations)\n        self.assertEqual(cloned_query.select_for_update, query.select_for_update)\n\n        # Test that cloning doesn't affect the original query\n        cloned_query.add_filter(('name', 'two'))\n        self.assertNotEqual(cloned_query.where, query.where)\n\n        # Test that cloning preserves the query's class\n        self.assertIsInstance(cloned_query, Query)\n\n        # Test that cloning preserves the query's attributes\n        self.assertEqual(cloned_query.model, query.model)\n        self.assertEqual(cloned_query.alias_prefix, query.alias_prefix)\n        self.assertEqual(cloned_query.compiler, query.compiler)\n"], "sample_156": ["def test_form_order_fields(self):\n    class MyForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n        field3 = CharField()\n\n    form = MyForm(field_order=['field3', 'field1'])\n    self.assertEqual(list(form.fields.keys()), ['field3', 'field1', 'field2'])\n\n    form = MyForm(field_order=['field3', 'field1', 'field4'])\n    self.assertEqual(list(form.fields.keys()), ['field3', 'field1', 'field2'])\n\n    form = MyForm(field_order=None)\n    self.assertEqual(list(form.fields.keys()), ['field1', 'field2', 'field3'])\n"], "sample_452": ["    def test_rename_index(self):\n        # Test renaming an index\n        operation = RenameIndex(\"testmodel\", \"new_index\", \"old_index\")\n        self.apply_operations(\n            [\n                migrations.CreateModel(\n                    \"TestModel\",\n                    [\n                        (\"id\", models.AutoField(primary_key=True)),\n                        (\"field\", models.IntegerField()),\n                    ],\n                    options={\"indexes\": [models.Index(fields=[\"field\"], name=\"old_index\")]},\n                ),\n                operation,\n            ],\n            [\n                migrations.CreateModel(\n                    \"TestModel\",\n                    [\n                        (\"id\", models.AutoField(primary_key=True)),\n                        (\"field\", models.IntegerField()),\n                    ],\n                    options={\"indexes\": [models.Index(fields=[\"field\"], name=\"new_index\")]},\n                ),\n            ],\n        )\n\n        # Test renaming an unnamed index\n        operation = RenameIndex(\"testmodel\", \"new_index\", old_fields=[\"field\"])\n        self.apply_operations(\n            [\n                migrations.CreateModel(\n                    \"TestModel\",\n                    [\n                        (\"id\", models.AutoField(primary_key=True)),\n                        (\"field\", models.IntegerField()),\n                    ],\n                    options={\"indexes\": [models.Index(fields=[\"field\"])]},\n                ),\n                operation,\n            ],\n            [\n                migrations.CreateModel(\n                    \"TestModel\",\n                    [\n                        (\"id\", models.AutoField(primary_key=True)),\n                        (\"field\", models.IntegerField()),\n                    ],\n                    options={\"indexes\": [models.Index(fields=[\"field\"], name=\"new_index\")]},\n                ),\n            ],\n        )\n\n        # Test renaming an index with the same name as the new index\n        operation = RenameIndex(\"testmodel\", \"new_index\", \"new_index\")\n        self.apply_operations(\n            [\n                migrations.CreateModel(\n                    \"TestModel\",\n                    [\n                        (\"id\", models.AutoField(primary_key=True)),\n                        (\"field\", models.IntegerField()),\n                    ],\n                    options={\"indexes\": [models.Index(fields=[\"field\"], name=\"new_index\")]},\n                ),\n                operation,\n            ],\n            [\n                migrations.CreateModel(\n                    \"TestModel\",\n                    [\n                        (\"id\", models.AutoField(primary_key=True)),\n                        (\"field\", models.IntegerField()),\n                    ],\n                    options={\"indexes\": [models.Index(fields=[\"field\"], name=\"new_index\")]},\n                ),\n            ],\n        )\n\n        # Test renaming an index that does not exist\n        operation = RenameIndex(\"testmodel\", \"new_index\", \"nonexistent_index\")\n        with self.assertRaises(FieldDoesNotExist):\n            self.apply_operations(\n                [\n                    migrations.CreateModel(\n                        \"TestModel\",\n                        [\n                            (\"id\", models.AutoField(primary_key"], "sample_1120": ["def test_matrix_element():\n    i, j = symbols('i j', integer=True)\n    M = MatrixSymbol('M', n, m)\n    ME = MatrixElement(M, i, j)\n    assert ME.parent == M\n    assert ME.i == i\n    assert ME.j == j\n    assert ME.indices == (i, j)\n    assert ME.diff(M) == KroneckerDelta(i, i, (0, n-1))*KroneckerDelta(j, j, (0, m-1))\n    assert ME.diff(M[1, 1]) == S.Zero\n    assert ME.diff(i) == S.Zero\n    assert ME.diff(j) == S.Zero\n    assert ME.diff(x) == S.Zero\n"], "sample_34": ["def test_composite_unit():\n    # Test that CompositeUnit can be created with a scale\n    cu = u.CompositeUnit(2.0, [u.m, u.s], [1, -1])\n    assert cu.scale == 2.0\n    assert cu.bases == [u.m, u.s]\n    assert cu.powers == [1, -1]\n\n    # Test that CompositeUnit can be created without a scale\n    cu = u.CompositeUnit(1.0, [u.m, u.s], [1, -1])\n    assert cu.scale == 1.0\n    assert cu.bases == [u.m, u.s]\n    assert cu.powers == [1, -1]\n\n    # Test that CompositeUnit can be created with a scale and bases\n    cu = u.CompositeUnit(2.0, [u.m, u.s], [1, -1])\n    assert cu.scale == 2.0\n    assert cu.bases == [u.m, u.s]\n    assert cu.powers == [1, -1]\n\n    # Test that CompositeUnit can be created with a scale, bases, and powers\n    cu = u.CompositeUnit(2.0, [u.m, u.s], [1, -1])\n    assert cu.scale == 2.0\n    assert cu.bases == [u.m, u.s]\n    assert cu.powers == [1, -1]\n\n    # Test that CompositeUnit raises an error when created with invalid scale\n    with raises(ValueError):\n        u.CompositeUnit('a', [u.m, u.s], [1, -1])\n\n    # Test that CompositeUnit raises an error when created with invalid bases\n    with raises(TypeError):\n        u.CompositeUnit(2.0, 'a', [1, -1])\n\n    # Test that CompositeUnit raises an error when created with invalid powers\n    with raises(TypeError):\n        u.CompositeUnit(2.0, [u.m, u.s], 'a')\n\n    # Test that CompositeUnit can be copied\n    cu_copy = cu.__copy__()\n    assert cu_copy.scale == cu.scale\n    assert cu_copy.bases == cu.bases\n    assert cu_copy.powers == cu.powers\n\n    # Test that CompositeUnit can be decomposed\n    cu_decomposed = cu.decompose()\n    assert cu_decomposed.scale == cu.scale\n    assert cu_decomposed"], "sample_368": ["    def test_migration_plan_with_replacements(self):\n        \"\"\"\n        Test that migration_plan correctly handles replacement migrations.\n        \"\"\"\n        # Create a migration graph with a replacement migration\n        graph = MigrationGraph()\n        app_label = \"migrations\"\n        migration1 = migrations.Migration(app_label, \"0001_initial\")\n        migration2 = migrations.Migration(app_label, \"0002_replace\")\n        migration2.replaces = [(\"migrations\", \"0001_initial\")]\n        graph.add_migration(app_label, migration1)\n        graph.add_migration(app_label, migration2)\n        graph.add_dependency(migration2, migration1)\n\n        # Create a MigrationLoader with the migration graph\n        loader = MigrationLoader(connection)\n        loader.graph = graph\n\n        # Create a MigrationExecutor with the MigrationLoader\n        executor = MigrationExecutor(connection)\n        executor.loader = loader\n\n        # Test that migration_plan correctly handles replacement migrations\n        targets = [(app_label, \"0002_replace\")]\n        plan = executor.migration_plan(targets)\n        self.assertEqual(len(plan), 1)\n        self.assertEqual(plan[0][0].name, \"0002_replace\")\n        self.assertFalse(plan[0][1])  # Should be a forwards migration\n\n        # Test that migration_plan correctly handles replacement migrations when\n        # the replaced migration is already applied\n        recorder = MigrationRecorder(connection)\n        recorder.record_applied(app_label, \"0001_initial\")\n        plan = executor.migration_plan(targets)\n        self.assertEqual(len(plan), 1)\n        self.assertEqual(plan[0][0].name, \"0002_replace\")\n        self.assertTrue(plan[0][1])  # Should be a backwards migration\n"], "sample_994": ["def test_comp():\n    assert comp(1, 1) == True\n    assert comp(1, 2) == True\n    assert comp(1, 1.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_339": ["    def test_model_form_metaclass(self):\n        class TestModel(models.Model):\n            name = models.CharField(max_length=10)\n\n        class TestForm(forms.ModelForm):\n            class Meta:\n                model = TestModel\n                fields = ('name',)\n\n        self.assertEqual(TestForm._meta.model, TestModel)\n        self.assertEqual(TestForm._meta.fields, ('name',))\n"], "sample_598": ["def test_format_array_flat():\n    array = np.arange(10)\n    assert formatting.format_array_flat(array, 20) == \"0 1 2 3 4 5 6 7 8 9\"\n    assert formatting.format_array_flat(array, 10) == \"0 1 2 ... 7 8 9\"\n    assert formatting.format_array_flat(array, 5) == \"0 ... 9\"\n\n    array = np.arange(100)\n    assert formatting.format_array_flat(array, 20) == \"0 1 2 ... 97 98 99\"\n    assert formatting.format_array_flat(array, 10) == \"0 ... 99\"\n    assert formatting.format_array_flat(array, 5) == \"0 ... 99\"\n\n    array = np.arange(1000)\n    assert formatting.format_array_flat(array, 20) == \"0 1 2 ... 997 998 999\"\n    assert formatting.format_array_flat(array, 10) == \"0 ... 999\"\n    assert formatting.format_array_flat(array, 5) == \"0 ... 999\"\n"], "sample_396": ["    def test_is_nullable(self):\n        # Test that is_nullable() returns True for fields that are nullable\n        # or have empty_strings_allowed=True and the database backend interprets\n        # empty strings as nulls.\n        field = Item._meta.get_field('name')\n        self.assertFalse(field.null)\n        self.assertFalse(field.empty_strings_allowed)\n        self.assertFalse(self.i1.is_nullable(field))\n\n        field = Item._meta.get_field('note')\n        self.assertTrue(field.null)\n        self.assertFalse(field.empty_strings_allowed)\n        self.assertTrue(self.i1.is_nullable(field))\n\n        field = ExtraInfo._meta.get_field('info')\n        self.assertFalse(field.null)\n        self.assertTrue(field.empty_strings_allowed)\n        with connection.cursor() as cursor:\n            cursor.execute('SELECT true FROM pg_settings WHERE name = %s AND setting = %s', ['extra_float_digits', 3])\n            if cursor.fetchone():\n                self.assertTrue(self.e1.is_nullable(field))\n            else:\n                self.assertFalse(self.e1.is_nullable(field))\n"], "sample_998": ["def test_latex_printing():\n    # Test latex printing of various sympy objects\n    assert latex(x) == 'x'\n    assert latex(x**2) == 'x^{2}'\n    assert latex(2*x) == '2 x'\n    assert latex(2*x**2) == '2 x^{2}'\n    assert latex(x + y) == 'x + y'\n    assert latex(x - y) == 'x - y'\n    assert latex(x * y) == 'x y'\n    assert latex(x / y) == '\\\\frac{x}{y}'\n    assert latex(x**y) == 'x^{y}'\n    assert latex(x**(y*z)) == 'x^{y z}'\n    assert latex(x**(y**z)) == 'x^{y^{z}}'\n    assert latex(x**(y**(z**t))) == 'x^{y^{z^{t}}}'\n\n    # Test latex printing of trigonometric functions\n    assert latex(sin(x)) == '\\\\sin{\\\\left (x \\\\right )}'\n    assert latex(cos(x)) == '\\\\cos{\\\\left (x \\\\right )}'\n    assert latex(tan(x)) == '\\\\tan{\\\\left (x \\\\right )}'\n    assert latex(asin(x)) == '\\\\operatorname{asin}{\\\\left (x \\\\right )}'\n    assert latex(acos(x)) == '\\\\operatorname{acos}{\\\\left (x \\\\right )}'\n    assert latex(atan(x)) == '\\\\operatorname{atan}{\\\\left (x \\\\right )}'\n\n    # Test latex printing of hyperbolic functions\n    assert latex(sinh(x)) == '\\\\sinh{\\\\left (x \\\\right )}'\n    assert latex(cosh(x)) == '\\\\cosh{\\\\left (x \\\\right )}'\n    assert latex(tanh(x)) == '\\\\tanh{\\\\left (x \\\\right )}'\n    assert latex(asinh(x)) == '\\\\operatorname{asinh}{\\\\left (x \\\\right )}'\n    assert latex(acosh(x)) == '\\\\operatorname{acosh}{\\\\left (x \\\\right )}'\n    assert latex(atanh(x)) == '\\\\operatorname{atanh}{\\\\left (x \\\\right )}'\n\n    # Test latex printing of exponential and logarithmic functions\n    assert latex(exp(x)) == 'e^{x}'\n    assert latex(log(x)) == '\\\\log{\\\\left (x \\\\right )}'\n\n    # Test"], "sample_1195": ["def test_kahane_simplify():\n    i0, i1, i2, i3 = tensor_indices('i0:4', LorentzIndex)\n    p = TensorHead('p', [LorentzIndex])\n    t1 = G(i0)*G(-i0)\n    t2 = G(i0)*G(i1)*G(-i0)\n    t3 = G(i0)*G(i1)*G(i2)*G(-i0)\n    t4 = G(i0)*G(i1)*G(i2)*G(i3)*G(-i0)\n    t5 = G(i0)*G(i1)*G(i2)*G(i3)*G(-i1)\n    t6 = G(i0)*G(i1)*G(i2)*G(i3)*G(-i2)\n    t7 = G(i0)*G(i1)*G(i2)*G(i3)*G(-i3)\n    t8 = G(i0)*G(i1)*G(i2)*G(i3)*G(-i0)*G(-i1)\n    t9 = G(i0)*G(i1)*G(i2)*G(i3)*G(-i0)*G(-i2)\n    t10 = G(i0)*G(i1)*G(i2)*G(i3)*G(-i0)*G(-i3)\n    t11 = G(i0)*G(i1)*G(i2)*G(i3)*G(-i1)*G(-i2)\n    t12 = G(i0)*G(i1)*G(i2)*G(i3)*G(-i1)*G(-i3)\n    t13 = G(i0)*G(i1)*G(i2)*G(i3)*G(-i2)*G(-i3)\n    t14 = G(i0)*G(i1)*G(i2)*G(i3)*G(-i0)*G(-i1)*G(-i2)\n    t15 = G(i0)*G(i1)*G(i2)*G(i3)*G(-i0)*G(-i1)*G(-i3)\n    t16 = G(i0)*G(i1)*G(i2)*G(i3)*G(-i0)*G(-i2)*G(-i3)\n    t17 = G(i0)*G(i1)*G(i2)*G(i3)*G(-i1)*"], "sample_49": ["    def test_media_rendering(self):\n        class TestWidget(TextInput):\n            class Media:\n                css = {\n                    'all': ('css/test.css',),\n                }\n                js = ('js/test.js',)\n\n        widget = TestWidget()\n        media = widget.media\n        self.assertEqual(\n            media.render(),\n            '<link href=\"http://media.example.com/static/css/test.css\" type=\"text/css\" media=\"all\" rel=\"stylesheet\">\\n'\n            '<script type=\"text/javascript\" src=\"http://media.example.com/static/js/test.js\"></script>'\n        )\n"], "sample_987": ["def test_evalf_piecewise():\n    x = Symbol('x')\n    f = Piecewise((1, Eq(x, 0)), (0, True))\n    raises(NotImplementedError, lambda: NS(f, 15, subs={x: 0}))\n"], "sample_542": ["def test_text_rotation():\n    fig, ax = plt.subplots()\n    ax.set_xlim(0, 10)\n    ax.set_ylim(0, 10)\n    ax.text(5, 5, 'Hello World', rotation=45, ha='center', va='center')\n    ax.set_aspect('equal')\n"], "sample_334": ["    def test_form_order_fields(self):\n        class OrderedForm(Form):\n            field_order = ['last_name', 'first_name', 'birthday']\n            first_name = CharField()\n            last_name = CharField()\n            birthday = DateField()\n\n        form = OrderedForm()\n        self.assertEqual(list(form.fields.keys()), ['last_name', 'first_name', 'birthday'])\n\n        class UnorderedForm(Form):\n            first_name = CharField()\n            last_name = CharField()\n            birthday = DateField()\n\n        form = UnorderedForm(field_order=['last_name', 'first_name', 'birthday'])\n        self.assertEqual(list(form.fields.keys()), ['last_name', 'first_name', 'birthday'])\n\n        class PartiallyOrderedForm(Form):\n            field_order = ['last_name']\n            first_name = CharField()\n            last_name = CharField()\n            birthday = DateField()\n\n        form = PartiallyOrderedForm()\n        self.assertEqual(list(form.fields.keys()), ['last_name', 'first_name', 'birthday'])\n\n        class FormWithUnknownFieldInOrder(Form):\n            field_order = ['last_name', 'unknown_field', 'first_name', 'birthday']\n            first_name = CharField()\n            last_name = CharField()\n            birthday = DateField()\n\n        form = FormWithUnknownFieldInOrder()\n        self.assertEqual(list(form.fields.keys()), ['last_name', 'first_name', 'birthday'])\n"], "sample_835": ["def test_adaboost_regressor():\n    # Test that AdaBoostRegressor works with different base estimators\n    estimators = [DecisionTreeRegressor(max_depth=3),\n                  DecisionTreeRegressor(max_depth=5),\n                  DecisionTreeRegressor(max_depth=7)]\n\n    for estimator in estimators:\n        clf = AdaBoostRegressor(base_estimator=estimator, n_estimators=10,\n                                random_state=rng)\n        clf.fit(boston.data, boston.target)\n        assert_array_less(clf.feature_importances_, 1.0)\n        assert_array_less(0.0, clf.feature_importances_.sum())\n\n    # Test that AdaBoostRegressor works with different loss functions\n    losses = ['linear', 'square', 'exponential']\n\n    for loss in losses:\n        clf = AdaBoostRegressor(loss=loss, n_estimators=10, random_state=rng)\n        clf.fit(boston.data, boston.target)\n        assert_array_less(clf.feature_importances_, 1.0)\n        assert_array_less(0.0, clf.feature_importances_.sum())\n\n    # Test that AdaBoostRegressor works with different learning rates\n    learning_rates = [0.1, 0.5, 1.0]\n\n    for learning_rate in learning_rates:\n        clf = AdaBoostRegressor(learning_rate=learning_rate, n_estimators=10,\n                                random_state=rng)\n        clf.fit(boston.data, boston.target)\n        assert_array_less(clf.feature_importances_, 1.0)\n        assert_array_less(0.0, clf.feature_importances_.sum())\n\n    # Test that AdaBoostRegressor raises an error when the base estimator\n    # does not support sample weights\n    class DummyEstimator(BaseEstimator):\n            pass\n\n            pass\n\n    clf = AdaBoostRegressor(base_estimator=DummyEstimator(), n_estimators=10,\n                            random_state=rng)\n    assert_raises(ValueError, clf.fit, boston.data, boston.target)\n\n    # Test that AdaBoostRegressor raises an error when the loss is not valid\n    clf = AdaBoostRegressor(loss='invalid_loss', n_estimators=10,\n                            random_state=rng)\n    assert_raises(ValueError, clf.fit, boston.data, boston.target)\n\n    # Test that AdaBoostRegressor raises an error when the learning rate is\n    # not valid\n    clf = AdaBoostRegressor(learning_rate=-1.0,"], "sample_305": ["    def test_lookup_exact(self):\n        # Test exact lookup with string value\n        self.assertQuerysetEqual(\n            Author.objects.filter(name__exact='Adrian Holovaty'),\n            [self.a1],\n            attrgetter('name')\n        )\n\n        # Test exact lookup with integer value\n        self.assertQuerysetEqual(\n            Author.objects.filter(age__exact=34),\n            [self.a1],\n            attrgetter('age')\n        )\n\n        # Test exact lookup with float value\n        self.assertQuerysetEqual(\n            Book.objects.filter(rating__exact=4.5),\n            [self.b1],\n            attrgetter('rating')\n        )\n\n        # Test exact lookup with datetime value\n        self.assertQuerysetEqual(\n            Book.objects.filter(pubdate__exact=datetime.date(2007, 12, 6)),\n            [self.b1],\n            attrgetter('pubdate')\n        )\n\n        # Test exact lookup with Decimal value\n        self.assertQuerysetEqual(\n            Book.objects.filter(price__exact=Decimal('30.00')),\n            [self.b1],\n            attrgetter('price')\n        )\n\n        # Test exact lookup with UUID value\n        self.assertQuerysetEqual(\n            Book.objects.filter(uuid__exact=self.b1.uuid),\n            [self.b1],\n            attrgetter('uuid')\n        )\n\n        # Test exact lookup with Q object\n        self.assertQuerysetEqual(\n            Author.objects.filter(Q(name__exact='Adrian Holovaty') | Q(age__exact=34)),\n            [self.a1],\n            attrgetter('name')\n        )\n\n        # Test exact lookup with F expression\n        self.assertQuerysetEqual(\n            Author.objects.filter(name__exact=F('name')),\n            Author.objects.all(),\n            attrgetter('name')\n        )\n\n        # Test exact lookup with Value expression\n        self.assertQuerysetEqual(\n            Author.objects.filter(name__exact=Value('Adrian Holovaty')),\n            [self.a1],\n            attrgetter('name')\n        )\n"], "sample_964": ["def test_parse_annotation():\n    env = Mock(spec=BuildEnvironment)\n    env.config.python_use_unqualified_type_names = False\n\n    # Test simple type\n    annotation = \"int\"\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'int'\n\n    # Test type with module\n    annotation = \"module.Type\"\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'module.Type'\n\n    # Test type with multiple modules\n    annotation = \"module1.module2.Type\"\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'module1.module2.Type'\n\n    # Test type with generics\n    annotation = \"List[int]\"\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 3\n    assert isinstance(result[0], desc_sig_name)\n    assert result[0].astext() == 'List'\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == '['\n    assert isinstance(result[2], pending_xref)\n    assert result[2].attributes['reftarget'] == 'int'\n\n    # Test type with multiple generics\n    annotation = \"Dict[str, int]\"\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 5\n    assert isinstance(result[0], desc_sig_name)\n    assert result[0].astext() == 'Dict'\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == '['\n    assert isinstance(result[2], pending_xref)\n    assert result[2].attributes['reftarget'] == 'str'\n    assert isinstance(result[3], desc_sig_punctuation)\n    assert result[3].astext() == ','\n    assert isinstance(result[4], pending_xref)\n    assert result[4].attributes['reftarget'] == 'int'\n\n    # Test type with nested generics\n    annotation = \"List[Dict[str, int]]\"\n    result = _parse_annotation"], "sample_741": ["def test_parameter_grid_iter():\n    # Test that iterating over a ParameterGrid object is equivalent to\n    # accessing its elements by index\n    param_grid = {'a': [1, 2], 'b': [True, False]}\n    grid = ParameterGrid(param_grid)\n    assert_grid_iter_equals_getitem(grid)\n\n    param_grid = [{'a': [1, 2]}, {'b': [True, False]}]\n    grid = ParameterGrid(param_grid)\n    assert_grid_iter_equals_getitem(grid)\n\n    param_grid = [{'a': [1, 2], 'b': [True, False]}, {'c': [3, 4]}]\n    grid = ParameterGrid(param_grid)\n    assert_grid_iter_equals_getitem(grid)\n"], "sample_357": ["def test_altered_unique_together(self):\n    before_state = self.make_project_state([\n        self.book_foo_together,\n    ])\n    after_state = self.make_project_state([\n        self.book_foo_together_2,\n    ])\n    changes = self.get_changes(before_state, after_state)\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\"])\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 0, unique_together={(\"title\", \"author\")})\n"], "sample_1033": ["def test_add_primitive():\n    assert (2*x + 4*y).primitive() == (2, x + 2*y)\n    assert (2*x/3 + 4*y/9).primitive() == (Rational(2, 9), 3*x + 2*y)\n    assert (2*x/3 + 4.2*y).primitive() == (Rational(1, 3), 2*x + 12.6*y)\n    assert ((2 + 2*x)*x + 2).primitive() == (1, x*(2*x + 2) + 2)\n    assert ((2 + 2*x)*x + 2).as_content_primitive() == (2, x*(x + 1) + 1)\n    assert (3 + 3*sqrt(2)).as_content_primitive() == (3, 1 + sqrt(2))\n    assert (2*sqrt(2) + 4*sqrt(10)).as_content_primitive(radical=True) == (2, sqrt(2)*(1 + 2*sqrt(5)))\n"], "sample_358": ["    def test_rename_table_references(self):\n        self.reference.rename_table_references('table', 'new_table')\n        self.assertEqual(self.reference.table, 'new_table')\n        self.assertEqual(str(self.reference), 'NEW_TABLE')\n"], "sample_489": ["    def test_bulk_create_with_deferred_fields(self):\n        # Test that bulk_create() works with deferred fields.\n        with connection.cursor() as cursor:\n            cursor.execute(\"TRUNCATE TABLE %s RESTART IDENTITY\" % Country._meta.db_table)\n        countries = [\n            Country(name=\"United States of America\", iso_two_letter=\"US\"),\n            Country(name=\"The Netherlands\", iso_two_letter=\"NL\"),\n            Country(name=\"Germany\", iso_two_letter=\"DE\"),\n            Country(name=\"Czech Republic\", iso_two_letter=\"CZ\"),\n        ]\n        Country.objects.bulk_create(countries, batch_size=2)\n        self.assertEqual(Country.objects.count(), 4)\n        for country in Country.objects.all():\n            self.assertIsNotNone(country.name)\n            self.assertIsNotNone(country.iso_two_letter)\n"], "sample_872": ["def test_ndcg_score():\n    # Test ndcg_score with k\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[.1, .2, .3, 4, 70]])\n    assert_almost_equal(ndcg_score(y_true, y_score, k=2), 0.35, decimal=2)\n\n    # Test ndcg_score with k and ties\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[1, 0, 0, 0, 1]])\n    assert_almost_equal(ndcg_score(y_true, y_score, k=1), 0.75, decimal=2)\n\n    # Test ndcg_score with k and ties and ignore_ties\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[1, 0, 0, 0, 1]])\n    assert_almost_equal(ndcg_score(y_true, y_score, k=1, ignore_ties=True), 0.5, decimal=2)\n\n    # Test ndcg_score with k and sample_weight\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[.1, .2, .3, 4, 70]])\n    sample_weight = np.array([0.5])\n    assert_almost_equal(ndcg_score(y_true, y_score, k=2, sample_weight=sample_weight), 0.175, decimal=3)\n\n    # Test ndcg_score with k and sample_weight and ties\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[1, 0, 0, 0, 1]])\n    sample_weight = np.array([0.5])\n    assert_almost_equal(ndcg_score(y_true, y_score, k=1, sample_weight=sample_weight), 0.375, decimal=3)\n\n    # Test ndcg_score with k and sample_weight and ties and ignore_ties\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[1, 0, 0, 0, 1]])\n   "], "sample_316": ["def test_get_image_dimensions(self):\n    # Create a temporary image file\n    with tempfile.NamedTemporaryFile(suffix='.png') as tmp:\n        # Create a simple image\n        img = Image.new('RGB', (100, 200))\n        img.save(tmp.name)\n        \n        # Test with a file path\n        dimensions = get_image_dimensions(tmp.name)\n        self.assertEqual(dimensions, (100, 200))\n\n        # Test with an open file\n        with open(tmp.name, 'rb') as f:\n            dimensions = get_image_dimensions(f)\n            self.assertEqual(dimensions, (100, 200))\n\n        # Test with a closed file\n        f = open(tmp.name, 'rb')\n        f.close()\n        with self.assertRaises(OSError):\n            get_image_dimensions(f)\n\n        # Test with a non-existent file\n        with self.assertRaises(OSError):\n            get_image_dimensions('non_existent_file.png')\n\n        # Test with a non-image file\n        with open(__file__, 'rb') as f:\n            dimensions = get_image_dimensions(f)\n            self.assertEqual(dimensions, (None, None))\n"], "sample_338": ["def test_altered_unique_together(self):\n    before_state = self.make_project_state([\n        self.book_foo_together,\n    ])\n    after_state = self.make_project_state([\n        self.book_foo_together_2,\n    ])\n    changes = self.get_changes(before_state, after_state)\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\"])\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 0, unique_together={(\"title\", \"author\")})\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 1, index_together={(\"title\", \"author\")})\n"], "sample_248": ["def test_shell_command_with_interface(self):\n    with captured_stdout() as stdout:\n        call_command('shell', interface='python')\n    self.assertIn('>>> ', stdout.getvalue())\n"], "sample_881": ["def test_ndcg_score():\n    # Test ndcg_score with k\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[.1, .2, .3, 4, 70]])\n    assert_almost_equal(ndcg_score(y_true, y_score, k=2), 0.35, decimal=2)\n\n    # Test ndcg_score with k and ties\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[1, 0, 0, 0, 1]])\n    assert_almost_equal(ndcg_score(y_true, y_score, k=1), 0.75, decimal=2)\n\n    # Test ndcg_score with k and ties and ignore_ties\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[1, 0, 0, 0, 1]])\n    assert_almost_equal(ndcg_score(y_true, y_score, k=1, ignore_ties=True), 0.5, decimal=2)\n\n    # Test ndcg_score with k and sample_weight\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[.1, .2, .3, 4, 70]])\n    sample_weight = np.array([0.5])\n    assert_almost_equal(ndcg_score(y_true, y_score, k=2, sample_weight=sample_weight), 0.35, decimal=2)\n\n    # Test ndcg_score with k and sample_weight and ties\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[1, 0, 0, 0, 1]])\n    sample_weight = np.array([0.5])\n    assert_almost_equal(ndcg_score(y_true, y_score, k=1, sample_weight=sample_weight), 0.75, decimal=2)\n\n    # Test ndcg_score with k and sample_weight and ties and ignore_ties\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[1, 0, 0, 0, 1]])\n   "], "sample_86": ["def test_lazy_property(self):\n    class TestClass:\n            self._value = None\n\n        @cached_property\n            self._value = 'computed'\n            return self._value\n\n    obj = TestClass()\n    self.assertIsNone(obj._value)\n    self.assertEqual(obj.value, 'computed')\n    self.assertEqual(obj._value, 'computed')\n    self.assertEqual(obj.value, 'computed')\n"], "sample_3": ["def test_ecsv_read_write_masked_columns():\n    # Create a table with a masked column\n    t = Table({'a': [1, 2, 3], 'b': [4, 5, 6]})\n    t['b'] = MaskedColumn(t['b'], mask=[True, False, True])\n\n    # Write the table to a string in ECSV format\n    with StringIO() as f:\n        ascii.write(t, f, format='ecsv')\n        ecsv_content = f.getvalue()\n\n    # Read the ECSV content back into a table\n    t_read = ascii.read(ecsv_content, format='ecsv')\n\n    # Check that the masked column was read correctly\n    assert np.all(t_read['b'].mask == t['b'].mask)\n    assert np.all(t_read['b'].data[~t_read['b'].mask] == t['b'].data[~t['b'].mask])\n"], "sample_412": ["def test_urlize(self):\n    self.check_output(urlize, \"Hello world!\")\n    self.check_output(urlize, \"http://example.com\", \"<a href='http://example.com'>http://example.com</a>\")\n    self.check_output(urlize, \"https://example.com\", \"<a href='https://example.com'>https://example.com</a>\")\n    self.check_output(urlize, \"www.example.com\", \"<a href='http://www.example.com'>www.example.com</a>\")\n    self.check_output(urlize, \"example@example.com\", \"<a href='mailto:example@example.com'>example@example.com</a>\")\n    self.check_output(urlize, \"example@example.com.\", \"<a href='mailto:example@example.com'>example@example.com</a>.\")\n    self.check_output(urlize, \"(http://example.com)\", \"(<a href='http://example.com'>http://example.com</a>)\")\n    self.check_output(urlize, \"[http://example.com]\", \"[<a href='http://example.com'>http://example.com</a>]\")\n"], "sample_715": ["def test_cross_validate_return_train_score_warn():\n    # Test that return_train_score='warn' raises a warning and returns\n    # the train scores\n    estimator = Ridge()\n    X, y = make_regression(n_samples=10, n_features=1, noise=0.1, random_state=0)\n    with warnings.catch_warnings(record=True) as w:\n        warnings.simplefilter(\"always\")\n        cv_results = cross_validate(estimator, X, y, return_train_score='warn')\n        assert_true(len(w) == 1)\n        assert_true(issubclass(w[0].category, FutureWarning))\n        assert_true('train_score' in cv_results)\n"], "sample_1128": ["def test_partial_velocity():\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    p = Point('p')\n    u1, u2 = dynamicsymbols('u1, u2')\n    p.set_vel(N, u1 * N.x + u2 * A.y)\n    assert p.partial_velocity(N, u1) == N.x\n    assert p.partial_velocity(N, u1, u2) == (N.x, A.y)\n"], "sample_854": ["def test_base_libsvm_fit():\n    # Test BaseLibSVM fit method\n    X = np.array(X)\n    y = np.array(Y)\n    clf = svm.BaseLibSVM(kernel='linear', degree=3, gamma='auto', coef0=0.0,\n                         tol=0.001, C=1.0, nu=0.0, epsilon=0.1, shrinking=True,\n                         probability=False, cache_size=200, class_weight=None,\n                         verbose=False, max_iter=-1, random_state=42)\n    clf.fit(X, y)\n    assert clf.support_.shape[0] == 4\n    assert clf.support_vectors_.shape == (4, 2)\n    assert clf.dual_coef_.shape == (1, 4)\n    assert clf.intercept_.shape == (1,)\n    assert clf.fit_status_ == 0\n"], "sample_474": ["    def test_ord(self):\n        self.assertEqual(Ord(F('name')).resolve_expression(\n            query=None, connection=None, using=None\n        ).as_sql([], None), \"ORD(T1.name)\")\n"], "sample_547": ["def test_paddedbox():\n    fig, ax = plt.subplots()\n    child = mpatches.Circle((0.5, 0.5), 0.2, edgecolor='black', facecolor='blue')\n    box = PaddedBox(child, pad=0.1, draw_frame=True)\n    ax.add_artist(box)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect('equal')\n"], "sample_1177": ["def test_polar_lift():\n    x = Symbol('x')\n    p = Symbol('p', polar=True)\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*p) == 4*p\n"], "sample_999": ["def test_latex():\n    # Test latex printing of various objects\n    assert latex(x) == 'x'\n    assert latex(x**2) == 'x^{2}'\n    assert latex(x**-2) == 'x^{-2}'\n    assert latex(x**Rational(2, 3)) == 'x^{\\frac{2}{3}}'\n    assert latex(x**Rational(2, 3), fold_frac_powers=True) == 'x^{2/3}'\n    assert latex(x**-Rational(2, 3)) == 'x^{-\\frac{2}{3}}'\n    assert latex(x**-Rational(2, 3), fold_frac_powers=True) == 'x^{-2/3}'\n    assert latex(x**-Rational(1, 2)) == 'x^{-\\frac{1}{2}}'\n    assert latex(x**-Rational(1, 2), fold_frac_powers=True) == 'x^{-1/2}'\n    assert latex(x**-Rational(3, 2)) == 'x^{-\\frac{3}{2}}'\n    assert latex(x**-Rational(3, 2), fold_frac_powers=True) == 'x^{-3/2}'\n    assert latex(x**-Rational(1, 3)) == 'x^{-\\frac{1}{3}}'\n    assert latex(x**-Rational(1, 3), fold_frac_powers=True) == 'x^{-1/3}'\n    assert latex(x**-Rational(2, 3)) == 'x^{-\\frac{2}{3}}'\n    assert latex(x**-Rational(2, 3), fold_frac_powers=True) == 'x^{-2/3}'\n    assert latex(x**-Rational(3, 3)) == 'x^{-1}'\n    assert latex(x**-Rational(3, 3), fold_frac_powers=True) == 'x^{-1}'\n    assert latex(x**-Rational(4, 3)) == 'x^{-\\frac{4}{3}}'\n    assert latex(x**-Rational(4, 3), fold_frac_powers=True) == 'x^{-4/3}'\n    assert latex(x**-Rational(5, 3)) == 'x^{-\\frac{5}{3}}'\n    assert latex(x**-Rational(5,"], "sample_31": ["    def test_write_latex(self, cosmo, tmp_path):\n        \"\"\"\n        Test writing a cosmology to a LaTeX file.\n        \"\"\"\n        file = tmp_path / \"cosmology.tex\"\n        write_latex(cosmo, file)\n        assert file.exists()\n"], "sample_497": ["    def test_get_tick_space(self):\n        fig, ax = plt.subplots()\n        ax.set_xlim(0, 10)\n        ax.set_ylim(0, 10)\n        ax.set_xticks([1, 2, 3, 4, 5])\n        ax.set_yticks([1, 2, 3, 4, 5])\n        assert ax.xaxis.get_tick_space() == 5\n        assert ax.yaxis.get_tick_space() == 5\n        plt.close(fig)\n"], "sample_692": ["def test_temp_path_factory_from_config(tmp_path_factory, config):\n    \"\"\"Test that TempPathFactory.from_config creates a factory with the correct basetemp.\"\"\"\n    config.option.basetemp = tmp_path_factory.getbasetemp()\n    factory = TempPathFactory.from_config(config)\n    assert factory.getbasetemp() == tmp_path_factory.getbasetemp()\n\n"], "sample_1156": ["def test_hyperbolic_functions():\n    x = symbols('x')\n    z = symbols('z')\n\n    # Test sinh\n    assert sinh(x).diff(x) == cosh(x)\n    assert sinh(x).diff(z) == 0\n    assert sinh(x).fdiff(2) == ArgumentIndexError(sinh(x), 2)\n    assert sinh(0) == 0\n    assert sinh(pi*I/2) == I\n    assert sinh(pi*I) == 0\n    assert sinh(-pi*I/2) == -I\n    assert sinh(-pi*I) == 0\n    assert sinh(nan) == nan\n    assert sinh(oo) == oo\n    assert sinh(-oo) == -oo\n    assert sinh(zoo) == zoo\n\n    # Test cosh\n    assert cosh(x).diff(x) == sinh(x)\n    assert cosh(x).diff(z) == 0\n    assert cosh(x).fdiff(2) == ArgumentIndexError(cosh(x), 2)\n    assert cosh(0) == 1\n    assert cosh(pi*I/2) == 0\n    assert cosh(pi*I) == -1\n    assert cosh(-pi*I/2) == 0\n    assert cosh(-pi*I) == -1\n    assert cosh(nan) == nan\n    assert cosh(oo) == oo\n    assert cosh(-oo) == oo\n    assert cosh(zoo) == zoo\n\n    # Test tanh\n    assert tanh(x).diff(x) == 1 - tanh(x)**2\n    assert tanh(x).diff(z) == 0\n    assert tanh(x).fdiff(2) == ArgumentIndexError(tanh(x), 2)\n    assert tanh(0) == 0\n    assert tanh(pi*I/4) == I\n    assert tanh(pi*I/2) == -I\n    assert tanh(-pi*I/4) == -I\n    assert tanh(-pi*I/2) == I\n    assert tanh(nan) == nan\n    assert tanh(oo) == 1\n    assert tanh(-oo) == -1\n    assert tanh(zoo) == zoo\n\n    # Test coth\n    assert coth(x).diff(x) == -1/sinh(x)**2\n   "], "sample_1052": ["def test_routine_creation():\n    x, y, z = symbols('x y z')\n    r = make_routine('test', Eq(x, y + z))\n    assert len(r.arguments) == 2\n    assert len(r.results) == 0\n    assert len(r.local_vars) == 0\n    assert len(r.global_vars) == 0\n    assert r.name == 'test'\n    assert r.arguments[0].name == x\n    assert r.arguments[1].name == y\n    assert r.arguments[1].expr == z\n"], "sample_225": ["    def setUpTestData(cls):\n        cls.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n"], "sample_22": ["def test_rotation_matrix():\n    # Test rotation around x, y, z axes\n    for axis in 'xyz':\n        R = rotation_matrix(90 * u.deg, axis=axis)\n        assert_allclose(R, rotation_matrix(np.pi / 2 * u.rad, axis=axis))\n\n    # Test rotation around arbitrary axis\n    axis = np.array([1, 1, 1])\n    R = rotation_matrix(90 * u.deg, axis=axis)\n    assert_allclose(R, rotation_matrix(np.pi / 2 * u.rad, axis=axis))\n\n    # Test rotation with array of angles\n    angles = np.array([90, 180, 270]) * u.deg\n    R = rotation_matrix(angles, axis='x')\n    assert_allclose(R, rotation_matrix(angles.to(u.rad), axis='x'))\n\n    # Test rotation with array of axes\n    axes = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n    R = rotation_matrix(90 * u.deg, axis=axes)\n    assert_allclose(R, rotation_matrix(np.pi / 2 * u.rad, axis=axes))\n"], "sample_1149": ["def test_singleton_registry():\n    class TestSingleton(Basic, metaclass=Singleton):\n        pass\n\n    assert TestSingleton() is TestSingleton()\n    assert S.TestSingleton is TestSingleton()\n"], "sample_307": ["def test_format_a(self):\n    dt = datetime(2003, 10, 7, 11, 39)\n    self.assertEqual(dateformat.format(dt, 'a'), 'a.m.')\n"], "sample_350": ["def test_union_with_empty_querysets(self):\n    qs1 = Number.objects.filter(num__gt=5)\n    qs2 = Number.objects.none()\n    qs3 = Number.objects.none()\n\n    result = qs1.union(qs2, qs3)\n    self.assertEqual(result.count(), 5)\n\n    result = qs2.union(qs1, qs3)\n    self.assertEqual(result.count(), 5)\n\n    result = qs2.union(qs3, qs1)\n    self.assertEqual(result.count(), 5)\n\n    result = qs2.union(qs3)\n    self.assertEqual(result.count(), 0)\n"], "sample_662": ["    def test_collect_report_serialization(self):\n        report = CollectReport(\n            nodeid=\"node1\",\n            outcome=\"failed\",\n            longrepr=\"Error message\",\n            result=[],\n            sections=[(\"section1\", \"content1\"), (\"section2\", \"content2\")],\n        )\n        serialized_report = pytest_report_to_serializable(report)\n        assert serialized_report[\"$report_type\"] == \"CollectReport\"\n        assert serialized_report[\"nodeid\"] == \"node1\"\n        assert serialized_report[\"outcome\"] == \"failed\"\n        assert serialized_report[\"longrepr\"] == \"Error message\"\n        assert serialized_report[\"result\"] is None\n        assert serialized_report[\"sections\"] == [(\"section1\", \"content1\"), (\"section2\", \"content2\")]\n\n        deserialized_report = pytest_report_from_serializable(serialized_report)\n        assert isinstance(deserialized_report, CollectReport)\n        assert deserialized_report.nodeid == \"node1\"\n        assert deserialized_report.outcome == \"failed\"\n        assert deserialized_report.longrepr == \"Error message\"\n        assert deserialized_report.result == []\n        assert deserialized_report.sections == [(\"section1\", \"content1\"), (\"section2\", \"content2\")]\n"], "sample_120": ["    def test_serializer_factory_with_lazy_object(self):\n        lazy_object = SimpleLazyObject(lambda: 'lazy_value')\n        serializer = serializer_factory(lazy_object)\n        self.assertIsInstance(serializer, BaseSimpleSerializer)\n"], "sample_943": ["def test_apidoc_excludes_subdir(apidoc):\n    assert not (apidoc.outdir / 'subdir.rst').exists()\n    assert (apidoc.outdir / 'test_root.rst').exists()\n\n"], "sample_98": ["    def test_wsgi_server_ipv6(self):\n        # Test that the WSGIServer can be created with IPv6\n        server_address = ('::1', 0)\n        httpd = WSGIServer(server_address, QuietWSGIRequestHandler, ipv6=True)\n        self.assertEqual(httpd.address_family, socket.AF_INET6)\n"], "sample_480": ["def test_jsonfield_keytransform_exact_lookup(self):\n    json_data = {\"key\": \"value\"}\n    JSONModel.objects.create(data=json_data)\n\n    # Test exact lookup with string value\n    self.assertEqual(JSONModel.objects.filter(data__key__exact=\"value\").count(), 1)\n    self.assertEqual(JSONModel.objects.filter(data__key__exact=\"other\").count(), 0)\n\n    # Test exact lookup with integer value\n    json_data = {\"key\": 123}\n    JSONModel.objects.create(data=json_data)\n    self.assertEqual(JSONModel.objects.filter(data__key__exact=123).count(), 1)\n    self.assertEqual(JSONModel.objects.filter(data__key__exact=456).count(), 0)\n\n    # Test exact lookup with None value\n    json_data = {\"key\": None}\n    JSONModel.objects.create(data=json_data)\n    self.assertEqual(JSONModel.objects.filter(data__key__exact=None).count(), 1)\n    self.assertEqual(JSONModel.objects.filter(data__key__exact=\"value\").count(), 1)\n\n    # Test exact lookup with nested key\n    json_data = {\"key\": {\"nested_key\": \"value\"}}\n    JSONModel.objects.create(data=json_data)\n    self.assertEqual(JSONModel.objects.filter(data__key__nested_key__exact=\"value\").count(), 1)\n    self.assertEqual(JSONModel.objects.filter(data__key__nested_key__exact=\"other\").count(), 0)\n"], "sample_460": ["def test_admin_site_register_model(self):\n    \"\"\"\n    Test that registering a model with the admin site works correctly.\n    \"\"\"\n    model_admin = ModelAdmin(Actor, site)\n    site.register(Actor, model_admin)\n    self.assertIn(Actor, site._registry)\n    self.assertEqual(site._registry[Actor], model_admin)\n\n    # Test that registering the same model again raises an AlreadyRegistered exception.\n    with self.assertRaises(AlreadyRegistered):\n        site.register(Actor, model_admin)\n\n    # Test that unregistering a model works correctly.\n    site.unregister(Actor)\n    self.assertNotIn(Actor, site._registry)\n\n    # Test that unregistering a model that is not registered raises a NotRegistered exception.\n    with self.assertRaises(NotRegistered):\n        site.unregister(Actor)\n"], "sample_134": ["    def test_serializer_factory_with_lazy_object(self):\n        lazy_object = SimpleLazyObject(lambda: 'lazy_value')\n        serializer = serializer_factory(lazy_object)\n        self.assertIsInstance(serializer, BaseSimpleSerializer)\n        serialized_value, imports = serializer.serialize()\n        self.assertEqual(serialized_value, \"'lazy_value'\")\n        self.assertEqual(imports, set())\n"], "sample_109": ["    def test_autocomplete_select_rendering(self):\n        form = AlbumForm()\n        html = form.as_p()\n        self.assertHTMLEqual(\n            html,\n            '<p><label for=\"id_band\">Band:</label> '\n            '<select name=\"band\" class=\"my-class admin-autocomplete\" '\n            'data-ajax--cache=\"true\" data-ajax--delay=\"250\" data-ajax--type=\"GET\" '\n            'data-ajax--url=\"/admin/albums/autocomplete/\" data-theme=\"admin-autocomplete\" '\n            'data-allow-clear=\"false\" data-placeholder=\"\"><option value=\"\" selected></option></select></p>'\n            '<p><label for=\"id_featuring\">Featuring:</label> '\n            '<select name=\"featuring\" class=\"admin-autocomplete\" '\n            'data-ajax--cache=\"true\" data-ajax--delay=\"250\" data-ajax--type=\"GET\" '\n            'data-ajax--url=\"/admin/albums/autocomplete/\" data-theme=\"admin-autocomplete\" '\n            'data-allow-clear=\"false\" data-placeholder=\"\"><option value=\"\" selected></option></select></p>'\n        )\n"], "sample_487": ["    def test_raw_id_fields_item(self):\n        class TestModelAdmin(ModelAdmin):\n            raw_id_fields = (\"nonexistent_field\",)\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'raw_id_fields[0]' refers to 'nonexistent_field', \"\n            \"which is not a field of 'validationtestmodel'.\",\n            id=\"admin.E002\",\n        )\n"], "sample_640": ["def test_is_builtin(node, expected):\n    assert utils.is_builtin(node.name) == expected\n"], "sample_263": ["    def test_dumpdata_command(self):\n        # Create some test data\n        article = Article.objects.create(title='Test Article')\n        category = Category.objects.create(name='Test Category')\n        tag = Tag.objects.create(name='Test Tag')\n        article.categories.add(category)\n        article.tags.add(tag)\n\n        # Run the dumpdata command\n        out = StringIO()\n        management.call_command('dumpdata', 'dumpdata', stdout=out)\n        output = out.getvalue()\n        self.assertIn('Article', output)\n        self.assertIn('Category', output)\n        self.assertIn('Tag', output)\n"], "sample_609": ["def test_apply_ufunc_with_dask():\n    if not has_dask:\n        pytest.skip(\"dask is not installed or imported\")\n\n    # Create a dask array\n    da = xr.DataArray(np.random.rand(10, 10), dims=[\"x\", \"y\"]).chunk(5)\n\n    # Apply a ufunc with dask='allowed'\n    result = apply_ufunc(np.sin, da, dask=\"allowed\")\n    assert isinstance(result.data, dask.array.core.Array)\n    assert_identical(result, np.sin(da.data))\n\n    # Apply a ufunc with dask='parallelized'\n    result = apply_ufunc(np.sin, da, dask=\"parallelized\")\n    assert isinstance(result.data, dask.array.core.Array)\n    assert_identical(result, np.sin(da.data))\n\n    # Apply a ufunc with dask='forbidden'\n    with pytest.raises(ValueError):\n        apply_ufunc(np.sin, da, dask=\"forbidden\")\n\n    # Apply a ufunc with dask='parallelized' and output_dtypes\n    result = apply_ufunc(np.sin, da, dask=\"parallelized\", output_dtypes=[np.float64])\n    assert isinstance(result.data, dask.array.core.Array)\n    assert_identical(result, np.sin(da.data))\n\n    # Apply a ufunc with dask='parallelized' and dask_gufunc_kwargs\n    result = apply_ufunc(\n        np.sin,\n        da,\n        dask=\"parallelized\",\n        dask_gufunc_kwargs={\"allow_rechunk\": True},\n    )\n    assert isinstance(result.data, dask.array.core.Array)\n    assert_identical(result, np.sin(da.data))\n\n    # Apply a ufunc with dask='parallelized' and meta\n    result = apply_ufunc(\n        np.sin,\n        da,\n        dask=\"parallelized\",\n        dask_gufunc_kwargs={\"meta\": np.array(0, dtype=np.float64)},\n    )\n    assert isinstance(result.data, dask.array.core.Array)\n    assert_identical(result, np.sin(da.data))\n\n    # Apply a ufunc with dask='parallelized' and output_sizes\n    result = apply_ufunc(\n        np.sin,\n        da,\n        dask=\"parallelized\",\n        dask_gufunc_kwargs={\"output_sizes\": {\"x\": 10, \"y\": 10}},\n    )\n    assert isinstance(result.data, dask.array"], "sample_962": ["def test_mock():\n    with mock(['mocked_module']):\n        import mocked_module\n        assert ismock(mocked_module)\n        assert isinstance(mocked_module, mock._MockModule)\n\n        class MockedClass:\n            pass\n\n        mocked_class = mocked_module.MockedClass\n        assert ismock(mocked_class)\n        assert isinstance(mocked_class, mock._MockObject)\n\n        mocked_instance = mocked_class()\n        assert ismock(mocked_instance)\n        assert isinstance(mocked_instance, mock._MockObject)\n\n        assert undecorate(mocked_instance) == mocked_instance\n\n        @mocked_class\n            pass\n\n        assert undecorate(decorated_function) == decorated_function\n\n        with pytest.raises(AttributeError):\n            mocked_instance.__non_existent_attribute__\n"], "sample_17": ["    def test_invariant_a_helper(self):\n            return a\n\n        helper = FUNCTION_HELPERS[test_func]\n        args, kwargs, unit, out = helper(self.q)\n        assert args[0] is self.q.value\n        assert kwargs == {}\n        assert unit == self.q.unit\n        assert out is None\n"], "sample_580": ["def test_variable_type():\n    # Test numeric data\n    assert variable_type(pd.Series([1, 2, 3])) == VarType(\"numeric\")\n    assert variable_type(pd.Series([1.0, 2.0, 3.0])) == VarType(\"numeric\")\n    assert variable_type(pd.Series([np.nan, np.nan, np.nan])) == VarType(\"numeric\")\n\n    # Test categorical data\n    assert variable_type(pd.Series([\"a\", \"b\", \"c\"])) == VarType(\"categorical\")\n    assert variable_type(pd.Series([\"a\", \"b\", \"c\"], dtype=\"category\")) == VarType(\"categorical\")\n\n    # Test datetime data\n    assert variable_type(pd.Series([pd.to_datetime(\"2022-01-01\"), pd.to_datetime(\"2022-01-02\")])) == VarType(\"datetime\")\n\n    # Test boolean data\n    assert variable_type(pd.Series([True, False])) == VarType(\"boolean\")\n    assert variable_type(pd.Series([0, 1])) == VarType(\"boolean\")\n    assert variable_type(pd.Series([0, 1]), boolean_type=\"numeric\") == VarType(\"numeric\")\n    assert variable_type(pd.Series([0, 1]), boolean_type=\"categorical\") == VarType(\"categorical\")\n\n    # Test mixed data\n    assert variable_type(pd.Series([1, \"a\", np.nan])) == VarType(\"categorical\")\n\n    # Test strict boolean\n    assert variable_type(pd.Series([0, 1]), strict_boolean=True) == VarType(\"numeric\")\n    assert variable_type(pd.Series([True, False]), strict_boolean=True) == VarType(\"boolean\")\n"], "sample_766": ["def test_sparse_encode():\n    # Test sparse_encode with different algorithms\n    dictionary = np.random.rand(5, n_features)\n    for algorithm in ['lasso_lars', 'lasso_cd', 'lars', 'omp', 'threshold']:\n        code = sparse_encode(X, dictionary, algorithm=algorithm)\n        assert code.shape == (n_samples, 5)\n\n    # Test sparse_encode with different regularization parameters\n    for alpha in [0.1, 1, 10]:\n        code = sparse_encode(X, dictionary, algorithm='lasso_lars', alpha=alpha)\n        assert code.shape == (n_samples, 5)\n\n    # Test sparse_encode with different number of nonzero coefficients\n    for n_nonzero_coefs in [1, 5, 10]:\n        code = sparse_encode(X, dictionary, algorithm='lars', n_nonzero_coefs=n_nonzero_coefs)\n        assert code.shape == (n_samples, 5)\n\n    # Test sparse_encode with different number of jobs\n    for n_jobs in [1, 2, -1]:\n        code = sparse_encode(X, dictionary, algorithm='lasso_lars', n_jobs=n_jobs)\n        assert code.shape == (n_samples, 5)\n\n    # Test sparse_encode with positive code\n    code = sparse_encode(X, dictionary, algorithm='lasso_lars', positive=True)\n    assert code.shape == (n_samples, 5)\n    assert np.all(code >= 0)\n\n    # Test sparse_encode with invalid algorithm\n    with assert_raises(ValueError):\n        sparse_encode(X, dictionary, algorithm='invalid')\n\n    # Test sparse_encode with invalid regularization parameter\n    with assert_raises(ValueError):\n        sparse_encode(X, dictionary, algorithm='lasso_lars', alpha=-1)\n\n    # Test sparse_encode with invalid number of nonzero coefficients\n    with assert_raises(ValueError):\n        sparse_encode(X, dictionary, algorithm='lars', n_nonzero_coefs=-1)\n\n    # Test sparse_encode with invalid number of jobs\n    with assert_raises(ValueError):\n        sparse_encode(X, dictionary, algorithm='lasso_lars', n_jobs=0)\n"], "sample_230": ["def test_jsonfield_with_encoder(self):\n    class TestForm(Form):\n        json_field = JSONField(encoder=DjangoJSONEncoder)\n\n    form = TestForm(data={'json_field': '{\"key\": \"value\"}'})\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data['json_field'], {'key': 'value'})\n\n    form = TestForm(data={'json_field': '{\"key\": \"value\"}}')\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data['json_field'], {'key': 'value'})\n\n    form = TestForm(data={'json_field': '{\"key\": \"value\"}}')\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data['json_field'], {'key': 'value'})\n\n    form = TestForm(data={'json_field': '{\"key\": \"value\"}}')\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data['json_field'], {'key': 'value'})\n\n    form = TestForm(data={'json_field': '{\"key\": \"value\"}}')\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data['json_field'], {'key': 'value'})\n\n    form = TestForm(data={'json_field': '{\"key\": \"value\"}}')\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data['json_field'], {'key': 'value'})\n\n    form = TestForm(data={'json_field': '{\"key\": \"value\"}}')\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data['json_field'], {'key': 'value'})\n\n    form = TestForm(data={'json_field': '{\"key\": \"value\"}}')\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data['json_field'], {'key': 'value'})\n\n    form = TestForm(data={'json_field': '{\"key\": \"value\"}}')\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data['json_field'], {'key': 'value'})\n\n    form = TestForm(data={'json_field': '{\"key\": \"value\"}}')\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data['json_field'], {'key': 'value'})\n\n    form = TestForm(data={'json_field': '{\"key\": \"value\"}}')\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data['json_field'], {'key': 'value'})\n\n    form = TestForm(data={'json_field': '{\"key\": \"value\"}}')\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data['json_field'], {'key': 'value'})\n\n    form ="], "sample_1133": ["def test_refraction_angle():\n    # Test with a Ray3D and a Plane\n    r1 = Ray3D(Point3D(-1, -1, 1), Point3D(0, 0, 0))\n    P = Plane(Point3D(0, 0, 0), normal_vector=[0, 0, 1])\n    assert refraction_angle(r1, 1, 1, plane=P) == Ray3D(Point3D(0, 0, 0), Point3D(1, 1, -1))\n\n    # Test with a Ray3D and a normal vector\n    n = Matrix([0, 0, 1])\n    assert refraction_angle(r1, 1, 1, n) == Matrix([[1], [1], [-1]])\n\n    # Test with a sequence and a normal vector\n    seq = [1, 1, -1]\n    assert refraction_angle(seq, 1, 1, n) == Matrix([[1], [1], [-1]])\n\n    # Test with an angle of incidence\n    angle = pi/6\n    assert ae(refraction_angle(angle, 1.2, 1.5), 0.41152, 5)\n\n    # Test with a normal vector that is not a unit vector\n    n = Matrix([0, 0, 2])\n    assert refraction_angle(r1, 1, 1, n) == Matrix([[1], [1], [-1]])\n\n    # Test with a normal vector that is not perpendicular to the plane\n    n = Matrix([1, 0, 1])\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, n))\n\n    # Test with a plane that is not perpendicular to the normal vector\n    P = Plane(Point3D(0, 0, 0), normal_vector=[1, 0, 1])\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, plane=P))\n\n    # Test with a normal vector that is not a Ray3D or a Matrix\n    n = [0, 0, 1]\n    raises(TypeError, lambda: refraction_angle(r1, 1, 1, n))\n\n    # Test with a plane that is not a Plane\n    P = [0, 0, 1]\n    raises(TypeError,"], "sample_160": ["def test_format_decimal(self):\n    # Test formatting of Decimal objects\n    number = Decimal('123456.789012')\n    formatted = nformat(number, decimal_sep='.', decimal_pos=3, grouping=3, thousand_sep=',')\n    self.assertEqual(formatted, '123,456.789')\n\n    # Test formatting of Decimal objects with scientific notation\n    number = Decimal('1.23456789012345678901234567890123456789e+200')\n    formatted = nformat(number, decimal_sep='.', decimal_pos=3, grouping=3, thousand_sep=',')\n    self.assertEqual(formatted, '1.235e+200')\n\n    # Test formatting of Decimal objects with very small numbers\n    number = Decimal('0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_433": ["    def test_migration_mutate_state(self):\n        migration = Migration(\"test_migration\", \"testapp\")\n        migration.operations = [\n            migrations.AddField(\n                \"Author\",\n                \"name\",\n                models.CharField(max_length=200),\n            ),\n        ]\n        project_state = self.make_project_state([self.author_empty])\n        new_state = migration.mutate_state(project_state)\n        self.assertEqual(\n            new_state.models[\"testapp\", \"Author\"].fields,\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=200)),\n            ],\n        )\n"], "sample_364": ["def test_path_view_must_be_callable(self):\n    with self.assertRaises(TypeError):\n        path('test/', View())\n"], "sample_729": ["def test_enet_path():\n    # Test enet_path with different parameters\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([5, 6])\n    alphas, coefs, dual_gaps = enet_path(X, y, l1_ratio=0.5, eps=1e-3,\n                                         n_alphas=100, alphas=None,\n                                         precompute='auto', Xy=None,\n                                         copy_X=True, coef_init=None,\n                                         verbose=False, return_n_iter=False,\n                                         positive=False, check_input=True)\n    assert_array_almost_equal(alphas.shape, (100,))\n    assert_array_almost_equal(coefs.shape, (2, 100))\n    assert_array_almost_equal(dual_gaps.shape, (100,))\n\n    # Test enet_path with sparse X\n    X_sparse = sparse.csr_matrix(X)\n    alphas, coefs, dual_gaps = enet_path(X_sparse, y, l1_ratio=0.5, eps=1e-3,\n                                         n_alphas=100, alphas=None,\n                                         precompute='auto', Xy=None,\n                                         copy_X=True, coef_init=None,\n                                         verbose=False, return_n_iter=False,\n                                         positive=False, check_input=True)\n    assert_array_almost_equal(alphas.shape, (100,))\n    assert_array_almost_equal(coefs.shape, (2, 100))\n    assert_array_almost_equal(dual_gaps.shape, (100,))\n\n    # Test enet_path with multi-output y\n    y_multi = np.array([[5, 6], [7, 8]])\n    alphas, coefs, dual_gaps = enet_path(X, y_multi, l1_ratio=0.5, eps=1e-3,\n                                         n_alphas=100, alphas=None,\n                                         precompute='auto', Xy=None,\n                                         copy_X=True, coef_init=None,\n                                         verbose=False, return_n_iter=False,\n                                         positive=False, check_input=True)\n    assert_array_almost_equal(alphas.shape, (100,))\n    assert_array_almost_equal(coefs.shape, (2, 2, 100))\n    assert_array_almost_equal(dual_gaps.shape, (100,))\n\n    # Test enet_path with precomputed Gram matrix\n    X Gram = np.dot(X.T, X)\n    alphas, coefs, dual_gaps = enet_path(X, y, l1_ratio="], "sample_595": ["def test_str_accessor_encode_decode(dtype):\n    data = np.array([\"hello\", \"world\"], dtype=dtype)\n    da = xr.DataArray(data)\n    encoded = da.str.encode(\"utf-8\")\n    decoded = encoded.str.decode(\"utf-8\")\n    assert_equal(decoded, da)\n"], "sample_957": ["def test_restify():\n    assert restify(None) == ':obj:`None`'\n    assert restify(Ellipsis) == '...'\n    assert restify(Struct) == ':class:`struct.Struct`'\n    assert restify(TracebackType) == ':class:`types.TracebackType`'\n    assert restify(MyClass1) == ':class:`test_util_typing.MyClass1`'\n    assert restify(MyClass2) == ':class:`test_util_typing.MyClass2`'\n    assert restify(MyInt) == ':class:`test_util_typing.MyInt`'\n    assert restify(MyList) == ':class:`test_util_typing.MyList`\\\\ [~T]''\n    assert restify(BrokenType) == ':class:`test_util_typing.BrokenType`'\n    assert restify(Union) == ':obj:`~typing.Union`'\n    assert restify(Optional[int]) == ':obj:`~typing.Optional`\\\\ [:obj:`~typing.Union`\\\\ [int, :obj:`None`]]'\n    assert restify(Optional[Union[int, str]]) == ':obj:`~typing.Optional`\\\\ [:obj:`~typing.Union`\\\\ [int, str, :obj:`None`]]'\n    assert restify(Callable[[int, str], bool]) == ':obj:`~typing.Callable`\\\\ [[int, str], bool]'\n    assert restify(Dict[str, int]) == ':class:`~typing.Dict`\\\\ [str, int]'\n    assert restify(List[int]) == ':class:`~typing.List`\\\\ [int]'\n    assert restify(Tuple[int, str]) == ':class:`~typing.Tuple`\\\\ [int, str]'\n    assert restify(Generator[int, str, bool]) == ':class:`~typing.Generator`\\\\ [int, str, bool]'\n\n"], "sample_807": ["def test_calibrated_classifier_cv():\n    # Test that the calibrated classifier is better calibrated than the\n    # original classifier\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=10,\n                               n_redundant=0, n_repeated=0, n_classes=2,\n                               random_state=0)\n\n    clf = LinearSVC(random_state=0)\n    clf.fit(X, y)\n    y_pred = clf.decision_function(X)\n\n    calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='sigmoid')\n    calibrated_clf.fit(X, y)\n    y_pred_calibrated = calibrated_clf.predict_proba(X)[:, 1]\n\n    score_clf = brier_score_loss(y, expit(y_pred), pos_label=1)\n    score_calibrated = brier_score_loss(y, y_pred_calibrated, pos_label=1)\n\n    assert_greater(score_clf, score_calibrated)\n\n    # Test that the calibrated classifier is better calibrated than the\n    # original classifier for multiclass problems\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=10,\n                               n_redundant=0, n_repeated=0, n_classes=3,\n                               random_state=0)\n\n    clf = LinearSVC(random_state=0)\n    clf.fit(X, y)\n    y_pred = clf.decision_function(X)\n\n    calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='sigmoid')\n    calibrated_clf.fit(X, y)\n    y_pred_calibrated = calibrated_clf.predict_proba(X)\n\n    score_clf = log_loss(y, expit(y_pred))\n    score_calibrated = log_loss(y, y_pred_calibrated)\n\n    assert_greater(score_clf, score_calibrated)\n\n    # Test that the calibrated classifier is better calibrated than the\n    # original classifier for multiclass problems with sparse input\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=10,\n                               n_redundant=0, n_repeated=0, n_classes=3,\n                               random_state=0)\n\n    X_sparse = sparse.csr_matrix(X)\n    clf = LinearSVC(random_state=0)\n    clf.fit(X_sparse, y)\n    y_pred = clf.decision_function(X_sparse)\n\n    calibrated_clf = CalibratedClassifierCV(clf"], "sample_711": ["def test_iterparentnodeids_with_colon_in_test_name():\n    nodeid = \"a/b::c/d::e[/test]\"\n    expected = [\"\", \"a\", \"a/b\", \"a/b::c/d\", \"a/b::c/d::e[/test]\"]\n    assert list(nodes.iterparentnodeids(nodeid)) == expected\n"], "sample_559": ["def test_axes_inset_zoom():\n    fig, ax = plt.subplots()\n    ax.plot(range(10))\n    axin = ax.inset_axes([0.5, 0.5, 0.4, 0.4])\n    axin.plot(range(10))\n    ax.indicate_inset_zoom(axin, edgecolor='red')\n    ax.set_xlim(0, 10)\n    ax.set_ylim(0, 10)\n"], "sample_750": ["def test_omp_path_residues():\n    # Test that the residues are correctly computed\n    X_train, y_train = X[:n_samples // 2], y[:n_samples // 2]\n    X_test, y_test = X[n_samples // 2:], y[n_samples // 2:]\n    residues = _omp_path_residues(X_train, y_train, X_test, y_test)\n    assert_equal(residues.shape, (n_samples // 2, n_features))\n    assert_true(np.allclose(residues[:, 0], y_test))\n\n    # Test that the residues are correctly computed when fit_intercept is False\n    residues = _omp_path_residues(X_train, y_train, X_test, y_test,\n                                  fit_intercept=False)\n    assert_equal(residues.shape, (n_samples // 2, n_features))\n    assert_true(np.allclose(residues[:, 0], y_test))\n\n    # Test that the residues are correctly computed when normalize is False\n    residues = _omp_path_residues(X_train, y_train, X_test, y_test,\n                                  normalize=False)\n    assert_equal(residues.shape, (n_samples // 2, n_features))\n    assert_true(np.allclose(residues[:, 0], y_test))\n\n    # Test that the residues are correctly computed when max_iter is small\n    residues = _omp_path_residues(X_train, y_train, X_test, y_test,\n                                  max_iter=5)\n    assert_equal(residues.shape, (n_samples // 2, 5))\n    assert_true(np.allclose(residues[:, 0], y_test))\n"], "sample_321": ["def test_origin_verified(self):\n    # Test that the _origin_verified method correctly verifies the origin\n    # header.\n    middleware = CsrfViewMiddleware()\n    request = TestingHttpRequest()\n    request.META['HTTP_ORIGIN'] = 'https://example.com'\n    request.get_host = lambda: 'example.com'\n    self.assertTrue(middleware._origin_verified(request))\n\n    # Test that the _origin_verified method correctly rejects an invalid\n    # origin header.\n    request.META['HTTP_ORIGIN'] = 'https://example2.com'\n    self.assertFalse(middleware._origin_verified(request))\n\n    # Test that the _origin_verified method correctly verifies an origin\n    # header with a subdomain.\n    request.META['HTTP_ORIGIN'] = 'https://sub.example.com'\n    settings.CSRF_TRUSTED_ORIGINS = ['*.example.com']\n    self.assertTrue(middleware._origin_verified(request))\n\n    # Test that the _origin_verified method correctly rejects an origin\n    # header with a subdomain that is not trusted.\n    request.META['HTTP_ORIGIN'] = 'https://sub.example2.com'\n    self.assertFalse(middleware._origin_verified(request))\n"], "sample_53": ["    def test_select_date_widget(self):\n        class DateForm(forms.Form):\n            date = forms.DateField(widget=SelectDateWidget)\n\n        form = DateForm({'date_year': '2022', 'date_month': '12', 'date_day': '31'})\n        self.assertEqual(form.is_valid(), True)\n        self.assertEqual(form.cleaned_data['date'], datetime.date(2022, 12, 31))\n\n        form = DateForm({'date_year': '', 'date_month': '', 'date_day': ''})\n        self.assertEqual(form.is_valid(), True)\n        self.assertEqual(form.cleaned_data['date'], None)\n\n        form = DateForm({'date_year': '2022', 'date_month': '13', 'date_day': '31'})\n        self.assertEqual(form.is_valid(), False)\n\n        form = DateForm({'date_year': '2022', 'date_month': '12', 'date_day': '32'})\n        self.assertEqual(form.is_valid(), False)\n\n        form = DateForm({'date_year': '2022', 'date_month': '2', 'date_day': '29'})\n        self.assertEqual(form.is_valid(), True)\n        self.assertEqual(form.cleaned_data['date'], datetime.date(2022, 2, 28))\n\n        form = DateForm({'date_year': '2022', 'date_month': '2', 'date_day': '30'})\n        self.assertEqual(form.is_valid(), False)\n\n        form = DateForm({'date_year': '2022', 'date_month': '2', 'date_day': '31'})\n        self.assertEqual(form.is_valid(), False)\n\n        form = DateForm({'date_year': '2022', 'date_month': '4', 'date_day': '31'})\n        self.assertEqual(form.is_valid(), True)\n        self.assertEqual(form.cleaned_data['date'], datetime.date(2022, 4, 30))\n\n        form = DateForm({'date_year': '2022', 'date_month': '6', 'date_day': '31'})\n        self.assertEqual(form.is_valid(), True)\n        self.assertEqual(form.cleaned_data['date'], datetime.date(2022, 6, 30))\n\n        form = DateForm({'date_year': '2022', 'date_month': '9', 'date_day': '31'})\n        self.assertEqual(form.is_valid(), True)\n        self.assertEqual(form.cleaned_data['date'], datetime.date(2022, 9, 30))\n\n        form = DateForm({'date_year': '2022',"], "sample_36": ["def test_biweight_midcorrelation():\n    with catch_warnings() as w:\n        # Test that a warning is raised when the input arrays are not the same shape\n        with pytest.raises(ValueError):\n            biweight_midcorrelation(randn(10), randn(20))\n\n        # Test that a warning is raised when the input arrays are not 1D\n        with pytest.raises(ValueError):\n            biweight_midcorrelation(randn(10, 2), randn(10, 2))\n\n        # Test that a warning is raised when the input arrays are not the same shape\n        with pytest.raises(ValueError):\n            biweight_midcorrelation(randn(10), randn(10, 2))\n\n    # Test the biweight midcorrelation with random data\n    with NumpyRNGContext(12345):\n        x = normal(0, 1, 200)\n        y = normal(0, 3, 200)\n        bicorr = biweight_midcorrelation(x, y)\n        assert_allclose(bicorr, -0.0495780713907, atol=1e-7)\n\n    # Test the biweight midcorrelation with constant data\n    x = np.ones(200)\n    y = np.ones(200)\n    bicorr = biweight_midcorrelation(x, y)\n    assert_allclose(bicorr, 1.0, atol=1e-7)\n\n    # Test the biweight midcorrelation with data that has a single outlier\n    x = normal(0, 1, 200)\n    y = normal(0, 3, 200)\n    x[0] = 30.0\n    bicorr = biweight_midcorrelation(x, y)\n    assert_allclose(bicorr, -0.0495780713907, atol=1e-7)\n\n    # Test the biweight midcorrelation with data that has multiple outliers\n    x = normal(0, 1, 200)\n    y = normal(0, 3, 200)\n    x[0] = 30.0\n    x[1] = 30.0\n    bicorr = biweight_midcorrelation(x, y)\n    assert_allclose(bicorr, -0.0495780713907, atol=1e-7)\n"], "sample_399": ["def test_is_nullable(self):\n    # Test that is_nullable() returns True for fields that are nullable or\n    # have empty_strings_allowed=True and the database backend interprets\n    # empty strings as null.\n    field = IntegerField(null=True)\n    self.assertTrue(Query(None).is_nullable(field))\n\n    field = IntegerField(null=False, empty_strings_allowed=True)\n    self.assertTrue(Query(None).is_nullable(field))\n\n    field = IntegerField(null=False, empty_strings_allowed=False)\n    self.assertFalse(Query(None).is_nullable(field))\n\n    # Test that is_nullable() returns False for fields that are not nullable\n    # and do not have empty_strings_allowed=True, even if the database\n    # backend interprets empty strings as null.\n    field = IntegerField(null=False, empty_strings_allowed=False)\n    with connection.cursor() as cursor:\n        cursor.execute(\"SET EMPTY_STRING_TO_NULL = TRUE\")\n        self.assertFalse(Query(None).is_nullable(field))\n"], "sample_952": ["def test_signature_from_str():\n    sig_str = \"(a: int, b: str, *args, **kwargs) -> None\"\n    sig = inspect.signature_from_str(sig_str)\n    assert len(sig.parameters) == 4\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.parameters['args'].annotation == Parameter.empty\n    assert sig.parameters['kwargs'].annotation == Parameter.empty\n    assert sig.return_annotation == type(None)\n"], "sample_363": ["    def test_filtered_select_multiple(self):\n        widget = widgets.FilteredSelectMultiple('verbose_name', True)\n        context = widget.get_context('name', ['value'], {'class': 'test'})\n        self.assertIn('selectfilter', context['widget']['attrs']['class'])\n        self.assertIn('stacked', context['widget']['attrs']['class'])\n        self.assertEqual(context['widget']['attrs']['data-field-name'], 'verbose_name')\n        self.assertEqual(context['widget']['attrs']['data-is-stacked'], '1')\n"], "sample_299": ["    def test_check_default_cache_is_configured(self):\n        with self.subTest('default cache is configured'):\n            errors = check_default_cache_is_configured([], settings=self.settings)\n            self.assertEqual(errors, [])\n\n        with self.subTest('default cache is not configured'):\n            with override_settings(CACHES=self.INVALID_CACHES_CONFIGURATION):\n                errors = check_default_cache_is_configured([], settings=self.settings)\n                self.assertEqual(len(errors), 1)\n                self.assertEqual(errors[0].id, E001.id)\n"], "sample_201": ["def test_legacy_hash(self):\n    storage = self.storage_class(self.request, self.response)\n    value = 'test_value'\n    legacy_hash = storage._legacy_hash(value)\n    self.assertIsInstance(legacy_hash, str)\n    self.assertEqual(len(legacy_hash), 40)  # SHA1 hash length\n"], "sample_65": ["    def test_set_language_view(self):\n        \"\"\"Test that the set_language view sets the language correctly.\"\"\"\n        lang_code = self._get_inactive_language_code()\n        url = reverse('set_language')\n        data = {LANGUAGE_QUERY_PARAMETER: lang_code}\n        response = self.client.post(url, data)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(get_language(), lang_code)\n"], "sample_660": ["def test_record_testsuite_property(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n            record_testsuite_property(\"ARCH\", \"PPC\")\n            record_testsuite_property(\"STORAGE_TYPE\", \"CEPH\")\n    \"\"\"\n    )\n    result, dom = runandparse(testdir, \"--junit-xml=junit.xml\")\n    assert result.ret == 0\n    properties = dom.find_first_by_tag(\"properties\")\n    assert properties.find_nth_by_tag(\"property\", 0).assert_attr(name=\"ARCH\", value=\"PPC\")\n    assert properties.find_nth_by_tag(\"property\", 1).assert_attr(name=\"STORAGE_TYPE\", value=\"CEPH\")\n"], "sample_1166": ["def test_itermonomials():\n    # Test Case I: max_degrees and min_degrees are both integers\n    assert set(itermonomials([x, y], 2)) == {1, x, y, x**2, x*y, y**2}\n    assert set(itermonomials([x, y], 3)) == {1, x, y, x**2, x*y, y**2, x**3, x**2*y, x*y**2, y**3}\n    assert set(itermonomials([a, b, x], 2)) == {1, a, a**2, b, b**2, x, x**2, a*b, b*a, x*a, x*b}\n    assert set(itermonomials([x, y], 2, 1)) == {x, y, x**2, x*y, y**2}\n\n    # Test Case II: max_degrees and min_degrees are both lists\n    assert set(itermonomials([x, y], [2, 4], [1, 2])) == {x**2*y**4, x**2*y**3, x**2*y**2, x*y**4, x*y**3, x*y**2}\n"], "sample_839": ["def test_hashing_vectorizer():\n    # Test that HashingVectorizer can handle a large number of features\n    # without running out of memory\n    vectorizer = HashingVectorizer(n_features=2**20)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n    assert X.shape == (len(ALL_FOOD_DOCS), 2**20)\n\n    # Test that HashingVectorizer can handle a large number of documents\n    # without running out of memory\n    vectorizer = HashingVectorizer(n_features=100)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 1000)\n    assert X.shape == (len(ALL_FOOD_DOCS) * 1000, 100)\n\n    # Test that HashingVectorizer can handle a large number of features\n    # and a large number of documents without running out of memory\n    vectorizer = HashingVectorizer(n_features=2**20)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 1000)\n    assert X.shape == (len(ALL_FOOD_DOCS) * 1000, 2**20)\n\n    # Test that HashingVectorizer can handle a large number of features\n    # and a large number of documents with a large number of non-zero\n    # elements without running out of memory\n    vectorizer = HashingVectorizer(n_features=2**20, non_negative=True)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 1000)\n    assert X.shape == (len(ALL_FOOD_DOCS) * 1000, 2**20)\n\n    # Test that HashingVectorizer can handle a large number of features\n    # and a large number of documents with a large number of non-zero\n    # elements and alternate_sign=True without running out of memory\n    vectorizer = HashingVectorizer(n_features=2**20, non_negative=False, alternate_sign=True)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 1000)\n    assert X.shape == (len(ALL_FOOD_DOCS) * 1000, 2**20)\n"], "sample_986": ["def test_evalf_piecewise():\n    x = Symbol('x')\n    expr = Piecewise((1, Eq(x, 0)), (0, True))\n    assert NS(expr, 15) == '1.00000000000000'\n    assert NS(expr.subs(x, 1), 15) == '0.00000000000000'\n"], "sample_1135": ["def test_mul():\n    assert (2*x*y).as_two_terms() == (2, x*y)\n    assert (2*x*y*z).as_two_terms() == (2, x*y*z)\n    assert (2*x*y*z).as_coefficients_dict() == {x*y*z: 2}\n    assert (2*x*y*z).as_coeff_Mul() == (2, x*y*z)\n    assert (2*x*y*z).as_coeff_mul() == (2, (x, y, z))\n    assert (2*x*y*z).as_coeff_mul(x) == (2*y*z, (x,))\n    assert (2*x*y*z).as_coeff_mul(x, y) == (2*z, (x, y))\n    assert (2*x*y*z).as_coeff_mul(x, y, z) == (2, (x, y, z))\n    assert (2*x*y*z).as_coeff_mul(x, y, z, clear=False) == (2, (x, y, z))\n    assert (2*x*y*z).as_coeff_mul(x, y, z, rational=False) == (2, (x, y, z))\n    assert (2*x*y*z).as_coeff_mul(x, y, z, rational=False, clear=False) == (2, (x, y, z))\n    assert (2*x*y*z).as_coeff_mul(x, y, z, clear=False, rational=False) == (2, (x, y, z))\n    assert (2*x*y*z).as_coeff_mul(clear=False, rational=False) == (2, (x, y, z))\n    assert (2*x*y*z).as_coeff_mul(clear=False) == (2, (x, y, z))\n    assert (2*x*y*z).as_coeff_mul(rational=False) == (2, (x, y, z))\n    assert (2*x*y*z).as_coeff_mul(rational=False, clear=False) == (2, (x, y, z))\n    assert (2*x*y*z).as_coeff_mul(clear=False, rational=False) == (2, (x, y, z))\n    assert (2*x*y*z).as_coeff_mul() == (2, (x, y, z))\n    assert (2*x*y*z).as_coeff_mul(rational=True) == (2, (x, y, z))\n    assert (2*x*y*z)."], "sample_541": ["def test_rectangle_selector(ax):\n        pass\n\n    rs = widgets.RectangleSelector(ax, onselect, useblit=True,\n                                   props=dict(facecolor='blue', alpha=0.5),\n                                   interactive=True)\n    assert rs.extents == (0, 0, 0, 0)\n    assert rs._visible is False\n\n    # Test that the selector is not visible before the first click.\n    assert not rs._selection_artist.get_visible()\n    assert not rs._edge_handles._artists[0].get_visible()\n    assert not rs._corner_handles._artists[0].get_visible()\n    assert not rs._center_handle._artists[0].get_visible()\n\n    # Test that the selector is visible after the first click.\n    click_and_drag(ax, rs, (0.1, 0.1), (0.2, 0.2))\n    assert rs._selection_artist.get_visible()\n    assert rs._edge_handles._artists[0].get_visible()\n    assert rs._corner_handles._artists[0].get_visible()\n    assert rs._center_handle._artists[0].get_visible()\n\n    # Test that the selector is not visible after a second click.\n    click_and_drag(ax, rs, (0.1, 0.1), (0.1, 0.1))\n    assert not rs._selection_artist.get_visible()\n    assert not rs._edge_handles._artists[0].get_visible()\n    assert not rs._corner_handles._artists[0].get_visible()\n    assert not rs._center_handle._artists[0].get_visible()\n\n    # Test that the selector is visible after a third click.\n    click_and_drag(ax, rs, (0.1, 0.1), (0.2, 0.2))\n    assert rs._selection_artist.get_visible()\n    assert rs._edge_handles._artists[0].get_visible()\n    assert rs._corner_handles._artists[0].get_visible()\n    assert rs._center_handle._artists[0].get_visible()\n\n    # Test that the selector is not visible after a fourth click.\n    click_and_drag(ax, rs, (0.1, 0.1), (0.1, 0.1))\n    assert not rs._selection_artist.get_visible()\n    assert not rs._edge_handles._artists[0].get_visible()\n    assert not rs._corner_handles._artists[0].get"], "sample_795": ["def test_check_fit_score_takes_y():\n    # Test that check_fit_score_takes_y raises an error when the estimator\n    # does not accept an optional y in fit and score\n    class BadEstimator(BaseEstimator):\n            return self\n\n            return 0\n\n    assert_raises_regex(ValueError, \"Expected y or Y as second argument\",\n                       check_fit_score_takes_y, \"BadEstimator\", BadEstimator())\n\n    # Test that check_fit_score_takes_y does not raise an error when the\n    # estimator accepts an optional y in fit and score\n    class GoodEstimator(BaseEstimator):\n            return self\n\n            return 0\n\n    check_fit_score_takes_y(\"GoodEstimator\", GoodEstimator())\n"], "sample_613": ["def test_groupby_quantile():\n    # Create a DataArray with a coordinate that has repeated values\n    da = xr.DataArray(\n        np.random.randn(6),\n        dims=\"x\",\n        coords={\"x\": [\"a\", \"a\", \"b\", \"b\", \"c\", \"c\"]},\n    )\n\n    # Group by the \"x\" coordinate and calculate the quantile\n    result = da.groupby(\"x\").quantile(0.5)\n\n    # Check that the result has the correct shape and values\n    assert result.shape == (3,)\n    assert result.coords[\"x\"].values.tolist() == [\"a\", \"b\", \"c\"]\n    assert result.coords[\"quantile\"].values == 0.5\n\n    # Check that the quantile values are correct\n    for x in [\"a\", \"b\", \"c\"]:\n        group = da.sel(x=x)\n        assert result.sel(x=x).values == np.median(group.values)\n\n"], "sample_482": ["    def test_escapeseq_with_unsafe_strings(self):\n        template = '{{ a|escapeseq|join:\", \" }}'\n        context = {'a': ['<script>alert(\"XSS\")</script>', 'Hello']}\n        rendered = self.render(template, context)\n        self.assertEqual(rendered, mark_safe('&lt;script&gt;alert(&#x22;XSS&#x22;)&lt;/script&gt;, Hello'))\n"], "sample_778": ["def test_non_negative_factorization():\n    # Test non_negative_factorization with different solvers and beta losses\n    X = np.array([[1, 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])\n    W, H, n_iter = non_negative_factorization(X, n_components=2, solver='cd')\n    assert_array_almost_equal(X, np.dot(W, H), decimal=1)\n\n    W, H, n_iter = non_negative_factorization(X, n_components=2, solver='mu')\n    assert_array_almost_equal(X, np.dot(W, H), decimal=1)\n\n    W, H, n_iter = non_negative_factorization(X, n_components=2, solver='mu', beta_loss='kullback-leibler')\n    assert_array_almost_equal(X, np.dot(W, H), decimal=1)\n\n    W, H, n_iter = non_negative_factorization(X, n_components=2, solver='mu', beta_loss='itakura-saito')\n    assert_array_almost_equal(X, np.dot(W, H), decimal=1)\n\n    # Test non_negative_factorization with different initializations\n    W, H, n_iter = non_negative_factorization(X, n_components=2, init='random')\n    assert_array_almost_equal(X, np.dot(W, H), decimal=1)\n\n    W, H, n_iter = non_negative_factorization(X, n_components=2, init='nndsvd')\n    assert_array_almost_equal(X, np.dot(W, H), decimal=1)\n\n    W, H, n_iter = non_negative_factorization(X, n_components=2, init='nndsvda')\n    assert_array_almost_equal(X, np.dot(W, H), decimal=1)\n\n    W, H, n_iter = non_negative_factorization(X, n_components=2, init='nndsvdar')\n    assert_array_almost_equal(X, np.dot(W, H), decimal=1)\n\n    # Test non_negative_factorization with custom initialization\n    W_init = np.array([[1, 0], [0, 1], [1, 1], [0, 1], [1, 0], [1, 1]])\n    H_init = np.array([[1, 1], [1, 0]])\n    W, H, n_iter = non_negative"], "sample_87": ["    def test_watchman_reloader(self):\n        reloader = autoreload.WatchmanReloader()\n        self.assertIsInstance(reloader, autoreload.BaseReloader)\n"], "sample_567": ["def test_annotation_rotation():\n    fig, ax = plt.subplots()\n    ax.set_xlim(0, 10)\n    ax.set_ylim(0, 10)\n    ax.add_patch(mpatches.Rectangle((1, 1), 8, 8, fill=False))\n    ax.add_patch(mpatches.Rectangle((2, 2), 6, 6, fill=False))\n    ax.add_patch(mpatches.Rectangle((3, 3), 4, 4, fill=False))\n    ax.add_patch(mpatches.Rectangle((4, 4), 2, 2, fill=False))\n    ax.add_patch(mpatches.Rectangle((5, 5), 1, 1, fill=False))\n    ax.add_patch(mpatches.Rectangle((6, 6), 1, 1, fill=False))\n    ax.add_patch(mpatches.Rectangle((7, 7), 1, 1, fill=False))\n    ax.add_patch(mpatches.Rectangle((8, 8), 1, 1, fill=False))\n    ax.add_patch(mpatches.Rectangle((9, 9), 1, 1, fill=False))\n\n    ann = ax.annotate('test', xy=(5, 5), xytext=(5, 5),\n                      textcoords='offset points', xycoords='data',\n                      rotation=45, ha='center', va='center')\n    ann = ax.annotate('test', xy=(6, 6), xytext=(6, 6),\n                      textcoords='offset points', xycoords='data',\n                      rotation=90, ha='center', va='center')\n    ann = ax.annotate('test', xy=(7, 7), xytext=(7, 7),\n                      textcoords='offset points', xycoords='data',\n                      rotation=135, ha='center', va='center')\n    ann = ax.annotate('test', xy=(8, 8), xytext=(8, 8),\n                      textcoords='offset points', xycoords='data',\n                      rotation=180, ha='center', va='center')\n    ann = ax.annotate('test', xy=(9, 9), xytext=(9, 9),\n                      textcoords='offset points', xycoords='data',\n                      rotation=225, ha='center', va='center')\n    ann = ax.annotate('test', xy=(5, 6), xytext=(5, 6),\n                      textcoords='"], "sample_115": ["    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        request.user = User()\n        exc_type = Exception\n        exc_value = Exception('Test exception')\n        tb = None\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIn('request', data)\n        self.assertIn('request_meta', data)\n        self.assertIn('user_str', data)\n        self.assertIn('filtered_POST_items', data)\n        self.assertIn('settings', data)\n        self.assertIn('sys_executable', data)\n        self.assertIn('sys_version_info', data)\n        self.assertIn('server_time', data)\n        self.assertIn('django_version_info', data)\n        self.assertIn('sys_path', data)\n        self.assertIn('template_info', data)\n        self.assertIn('template_does_not_exist', data)\n        self.assertIn('postmortem', data)\n        self.assertIn('exception_type', data)\n        self.assertIn('exception_value', data)\n        self.assertIn('lastframe', data)\n"], "sample_1078": ["def test_IndexedBase():\n    i, j = symbols('i j', integer=True)\n    A = IndexedBase('A', shape=(i, j))\n    assert A.shape == (i, j)\n    assert A.label == Symbol('A')\n    assert A.offset == 0\n    assert A.strides is None\n\n    B = IndexedBase('B', shape=(i, j), offset=5)\n    assert B.offset == 5\n\n    C = IndexedBase('C', shape=(i, j), strides=(2, 3))\n    assert C.strides == (2, 3)\n\n    D = IndexedBase('D', shape=(i, j), strides='C')\n    assert D.strides == 'C'\n\n    E = IndexedBase('E', shape=(i, j), strides='F')\n    assert E.strides == 'F'\n\n    F = IndexedBase('F', shape=(i, j), offset=5, strides=(2, 3))\n    assert F.offset == 5\n    assert F.strides == (2, 3)\n\n    G = IndexedBase('G', shape=(i, j), offset=5, strides='C')\n    assert G.offset == 5\n    assert G.strides == 'C'\n\n    H = IndexedBase('H', shape=(i, j), offset=5, strides='F')\n    assert H.offset == 5\n    assert H.strides == 'F'\n\n    I = IndexedBase('I', shape=(i, j), offset=5, strides=(2, 3), foo='bar')\n    assert I.offset == 5\n    assert I.strides == (2, 3)\n    assert I.foo == 'bar'\n\n    J = IndexedBase('J', shape=(i, j), offset=5, strides='C', foo='bar')\n    assert J.offset == 5\n    assert J.strides == 'C'\n    assert J.foo == 'bar'\n\n    K = IndexedBase('K', shape=(i, j), offset=5, strides='F', foo='bar')\n    assert K.offset == 5\n    assert K.strides == 'F'\n    assert K.foo == 'bar'\n"], "sample_1042": ["def test_idx():\n    i = Idx('i')\n    j = Idx('j', 3)\n    k = Idx('k', (1, 3))\n\n    assert i.label == Symbol('i', integer=True)\n    assert j.label == Symbol('j', integer=True)\n    assert k.label == Symbol('k', integer=True)\n\n    assert i.lower is None\n    assert i.upper is None\n    assert j.lower == 0\n    assert j.upper == 2\n    assert k.lower == 1\n    assert k.upper == 3\n\n    assert i.free_symbols == {i}\n    assert j.free_symbols == {j}\n    assert k.free_symbols == {k}\n\n    assert i.name == 'i'\n    assert j.name == 'j'\n    assert k.name == 'k'\n\n    assert i <= j\n    assert j <= k\n    assert i <= k\n\n    assert j >= i\n    assert k >= j\n    assert k >= i\n\n    assert i < j\n    assert j < k\n    assert i < k\n\n    assert j > i\n    assert k > j\n    assert k > i\n"], "sample_429": ["def test_url_validator_with_idn(self):\n    # Test that the URLValidator correctly handles IDN domains.\n    validator = URLValidator()\n    valid_idn_url = \"http://m\u00fcller.example.com\"\n    try:\n        validator(valid_idn_url)\n    except ValidationError:\n        self.fail(\"URLValidator failed to validate a valid IDN URL\")\n\n    invalid_idn_url = \"http://m\u00fcller.example\"\n    with self.assertRaisesMessage(ValidationError, \"Enter a valid URL.\"):\n        validator(invalid_idn_url)\n\n    # Test that the URLValidator correctly handles IDN domains with a port.\n    valid_idn_url_with_port = \"http://m\u00fcller.example.com:8080\"\n    try:\n        validator(valid_idn_url_with_port)\n    except ValidationError:\n        self.fail(\"URLValidator failed to validate a valid IDN URL with a port\")\n\n    # Test that the URLValidator correctly handles IDN domains with a path.\n    valid_idn_url_with_path = \"http://m\u00fcller.example.com/path/to/resource\"\n    try:\n        validator(valid_idn_url_with_path)\n    except ValidationError:\n        self.fail(\"URLValidator failed to validate a valid IDN URL with a path\")\n\n    # Test that the URLValidator correctly handles IDN domains with a query string.\n    valid_idn_url_with_query = \"http://m\u00fcller.example.com/path/to/resource?query=string\"\n    try:\n        validator(valid_idn_url_with_query)\n    except ValidationError:\n        self.fail(\"URLValidator failed to validate a valid IDN URL with a query string\")\n\n    # Test that the URLValidator correctly handles IDN domains with a fragment.\n    valid_idn_url_with_fragment = \"http://m\u00fcller.example.com/path/to/resource#fragment\"\n    try:\n        validator(valid_idn_url_with_fragment)\n    except ValidationError:\n        self.fail(\"URLValidator failed to validate a valid IDN URL with a fragment\")\n"], "sample_894": ["def test_feature_importances(name):\n    \"\"\"Check feature importances on a classification and regression dataset.\"\"\"\n    ForestEstimator = FOREST_ESTIMATORS[name]\n\n    # Classification\n    clf = ForestEstimator(n_estimators=10, random_state=1)\n    clf.fit(X_large, y_large)\n    importances = clf.feature_importances_\n    assert importances.shape == (X_large.shape[1],)\n    assert np.isclose(importances.sum(), 1)\n    assert_array_equal(importances, clf.feature_importances_)\n\n    # Regression\n    reg = ForestEstimator(n_estimators=10, random_state=1)\n    reg.fit(X_reg, y_reg)\n    importances = reg.feature_importances_\n    assert importances.shape == (X_reg.shape[1],)\n    assert np.isclose(importances.sum(), 1)\n    assert_array_equal(importances, reg.feature_importances_)\n"], "sample_871": ["def test_silhouette_reduce():\n    # Test _silhouette_reduce with dense and sparse matrices\n    n_samples = 10\n    n_labels = 3\n    labels = np.random.randint(0, n_labels, size=n_samples)\n    label_freqs = np.bincount(labels)\n    D_chunk = np.random.rand(n_samples, n_samples)\n    D_chunk_sparse = csr_matrix(D_chunk)\n\n    intra_clust_dists, inter_clust_dists = _silhouette_reduce(\n        D_chunk, 0, labels, label_freqs\n    )\n    intra_clust_dists_sparse, inter_clust_dists_sparse = _silhouette_reduce(\n        D_chunk_sparse, 0, labels, label_freqs\n    )\n\n    assert_allclose(intra_clust_dists, intra_clust_dists_sparse)\n    assert_allclose(inter_clust_dists, inter_clust_dists_sparse)\n\n    # Test _silhouette_reduce with non-CSR sparse matrix\n    D_chunk_sparse = csc_matrix(D_chunk)\n    with pytest.raises(TypeError):\n        _silhouette_reduce(D_chunk_sparse, 0, labels, label_freqs)\n\n    # Test _silhouette_reduce with non-square matrix\n    D_chunk = np.random.rand(n_samples, n_samples + 1)\n    with pytest.raises(ValueError):\n        _silhouette_reduce(D_chunk, 0, labels, label_freqs)\n\n    # Test _silhouette_reduce with non-integer labels\n    labels = np.random.rand(n_samples)\n    with pytest.raises(ValueError):\n        _silhouette_reduce(D_chunk, 0, labels, label_freqs)\n"], "sample_500": ["def test_colorbar_extension_length():\n    \"\"\"\n    Test the length of colorbar extensions for uniform and proportional spacing.\n    \"\"\"\n    fig1 = _colorbar_extension_length('uniform')\n    fig2 = _colorbar_extension_length('proportional')\n    return fig1, fig2\n\n"], "sample_233": ["    def test_make_token(self):\n        user = User.objects.create_user('testuser', 'test@example.com', 'password')\n        token_generator = PasswordResetTokenGenerator()\n        token = token_generator.make_token(user)\n        self.assertIsNotNone(token)\n        self.assertIsInstance(token, str)\n        self.assertGreater(len(token), 0)\n"], "sample_627": ["def test_concat_with_fill_value():\n    # Create two datasets with different values for the same variable\n    ds1 = Dataset(\n        data_vars={\"temperature\": ([\"x\", \"y\"], [[1, 2], [3, 4]])},\n        coords={\"x\": [1, 2], \"y\": [3, 4]},\n    )\n    ds2 = Dataset(\n        data_vars={\"temperature\": ([\"x\", \"y\"], [[5, 6], [7, 8]])},\n        coords={\"x\": [1, 2], \"y\": [3, 4]},\n    )\n\n    # Concatenate the datasets with a fill value\n    concatenated = concat([ds1, ds2], dim=\"z\", fill_value=-999)\n\n    # Check that the fill value is used for missing values\n    expected = Dataset(\n        data_vars={\n            \"temperature\": (\n                [\"x\", \"y\", \"z\"],\n                np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]]),\n            )\n        },\n        coords={\"x\": [1, 2], \"y\": [3, 4], \"z\": [0, 1]},\n    )\n    assert_identical(concatenated, expected)\n\n    # Test with a dictionary of fill values\n    fill_values = {\"temperature\": -999}\n    concatenated = concat([ds1, ds2], dim=\"z\", fill_value=fill_values)\n    assert_identical(concatenated, expected)\n\n    # Test with a fill value that is a DataArray\n    fill_value_da = DataArray(-999, dims=(), name=\"temperature\")\n    concatenated = concat([ds1, ds2], dim=\"z\", fill_value=fill_value_da)\n    assert_identical(concatenated, expected)\n"], "sample_853": ["def test_transformed_target_regressor():\n    # Test with a custom transformer\n    transformer = StandardScaler()\n    X, y = friedman\n    regressor = TransformedTargetRegressor(transformer=transformer)\n    regressor.fit(X, y)\n    assert_allclose(regressor.predict(X), regressor.regressor_.predict(X))\n\n    # Test with a custom function and inverse function\n    regressor = TransformedTargetRegressor(func=np.log, inverse_func=np.exp)\n    regressor.fit(X, y)\n    assert_allclose(regressor.predict(X), np.exp(regressor.regressor_.predict(X)))\n\n    # Test with a pipeline\n    pipe = Pipeline([('scaler', StandardScaler()), ('regressor', LinearRegression())])\n    regressor = TransformedTargetRegressor(regressor=pipe)\n    regressor.fit(X, y)\n    assert_allclose(regressor.predict(X), pipe.predict(X))\n\n    # Test with a dummy regressor\n    regressor = TransformedTargetRegressor(regressor=DummyRegressor())\n    regressor.fit(X, y)\n    assert_allclose(regressor.predict(X), regressor.regressor_.predict(X))\n\n    # Test with a Lasso regressor\n    regressor = TransformedTargetRegressor(regressor=Lasso())\n    regressor.fit(X, y)\n    assert_allclose(regressor.predict(X), regressor.regressor_.predict(X))\n\n    # Test that the transformer is cloned\n    transformer = StandardScaler()\n    regressor = TransformedTargetRegressor(transformer=transformer)\n    regressor.fit(X, y)\n    assert id(regressor.transformer_) != id(transformer)\n\n    # Test that the regressor is cloned\n    regressor = LinearRegression()\n    tt_regressor = TransformedTargetRegressor(regressor=regressor)\n    tt_regressor.fit(X, y)\n    assert id(tt_regressor.regressor_) != id(regressor)\n\n    # Test that the inverse function is checked\n        return y\n    regressor = TransformedTargetRegressor(func=np.log, inverse_func=inverse_func)\n    with pytest.raises(ValueError):\n        regressor.fit(X, y)\n\n    # Test that the transformer and functions cannot be set at the same time\n    transformer = StandardScaler()\n    regressor = TransformedTargetRegressor(transformer=transformer, func=np.log)\n    with pytest.raises(ValueError):\n        regressor.fit(X, y)\n\n    # Test that"], "sample_785": ["def test_leave_p_groups_out():\n    # Test LeavePGroupsOut with different values of n_groups\n    for n_groups in range(1, 5):\n        lpgo = LeavePGroupsOut(n_groups=n_groups)\n        X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])\n        y = np.array([1, 2, 1, 2, 1, 2])\n        groups = np.array([1, 2, 3, 4, 5, 6])\n        assert lpgo.get_n_splits(X, y, groups) == comb(len(np.unique(groups)), n_groups, exact=True)\n        for train_index, test_index in lpgo.split(X, y, groups):\n            assert len(train_index) + len(test_index) == len(X)\n            assert len(np.unique(groups[test_index])) == n_groups\n"], "sample_162": ["    def test_preprocess(self):\n        build_file = self.build_file_class(self, 'django', self.translatable_file_class('.', 'test.py', '.'))\n        build_file.preprocess()\n        self.assertTrue(os.path.exists(build_file.work_path))\n"], "sample_915": ["def test_signature_from_str():\n    sig_str = \"(a: int, b: str, *, c: float, d: bool) -> None\"\n    sig = inspect.signature_from_str(sig_str)\n    assert len(sig.parameters) == 4\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.parameters['c'].annotation == float\n    assert sig.parameters['d'].annotation == bool\n    assert sig.return_annotation == type(None)\n\n    sig_str = \"(a: int, b: str, *args: str, **kwargs: int) -> None\"\n    sig = inspect.signature_from_str(sig_str)\n    assert len(sig.parameters) == 4\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.parameters['args'].annotation == str\n    assert sig.parameters['kwargs'].annotation == int\n    assert sig.return_annotation == type(None)\n\n    sig_str = \"(a: int, b: str, *, c: float, d: bool = True) -> None\"\n    sig = inspect.signature_from_str(sig_str)\n    assert len(sig.parameters) == 4\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.parameters['c'].annotation == float\n    assert sig.parameters['d'].annotation == bool\n    assert sig.parameters['d'].default == True\n    assert sig.return_annotation == type(None)\n"], "sample_901": ["def test_kmeans_elkan():\n    # Test that the Elkan algorithm is faster than the full algorithm\n    # for large datasets\n    X, _ = make_blobs(n_samples=10000, centers=10, random_state=42)\n    kmeans_elkan = KMeans(n_clusters=10, algorithm='elkan', random_state=42)\n    kmeans_full = KMeans(n_clusters=10, algorithm='full', random_state=42)\n    start_time = time.time()\n    kmeans_elkan.fit(X)\n    elkan_time = time.time() - start_time\n    start_time = time.time()\n    kmeans_full.fit(X)\n    full_time = time.time() - start_time\n    assert elkan_time < full_time\n\n"], "sample_352": ["    def test_split_having(self):\n        # Test that split_having correctly splits the WhereNode into WHERE and HAVING clauses\n        where_node = WhereNode(children=[Q(id=1), Q(id=2)], connector=AND, negated=False)\n        where_clause, having_clause = where_node.split_having()\n        self.assertEqual(where_clause.children, [Q(id=1), Q(id=2)])\n        self.assertIsNone(having_clause)\n"], "sample_423": ["def test_alter_field_with_deconstructible_default(self):\n    before_state = self.make_project_state(\n        [\n            self.author_name,\n            self.author_name_deconstructible_1,\n        ]\n    )\n    after_state = self.make_project_state(\n        [\n            self.author_name,\n            self.author_name_deconstructible_2,\n        ]\n    )\n    changes = self.get_changes(before_state, after_state)\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationFieldAttributes(\n        changes,\n        \"testapp\",\n        0,\n        0,\n        default=DeconstructibleObject(),\n    )\n"], "sample_983": ["def test_sparse_matrix():\n    # Test SparseMatrix creation\n    M = SparseMatrix(3, 3, {(0, 0): 1, (1, 1): 2, (2, 2): 3})\n    assert M.rows == 3\n    assert M.cols == 3\n    assert M._smat == {(0, 0): 1, (1, 1): 2, (2, 2): 3}\n\n    # Test SparseMatrix equality\n    M1 = SparseMatrix(2, 2, {(0, 0): 1, (1, 1): 2})\n    M2 = SparseMatrix(2, 2, {(0, 0): 1, (1, 1): 2})\n    assert M1 == M2\n\n    # Test SparseMatrix addition\n    M1 = SparseMatrix(2, 2, {(0, 0): 1, (1, 1): 2})\n    M2 = SparseMatrix(2, 2, {(0, 1): 3, (1, 0): 4})\n    M3 = M1 + M2\n    assert M3._smat == {(0, 0): 1, (0, 1): 3, (1, 0): 4, (1, 1): 2}\n\n    # Test SparseMatrix multiplication\n    M1 = SparseMatrix(2, 2, {(0, 0): 1, (1, 1): 2})\n    M2 = SparseMatrix(2, 2, {(0, 1): 3, (1, 0): 4})\n    M3 = M1 * M2\n    assert M3._smat == {(0, 1): 3, (1, 0): 8}\n\n    # Test SparseMatrix transpose\n    M = SparseMatrix(2, 2, {(0, 1): 1, (1, 0): 2})\n    Mt = M.T\n    assert Mt._smat == {(0, 1): 2, (1, 0): 1}\n\n    # Test SparseMatrix LDL decomposition\n    M = SparseMatrix(3, 3, {(0, 0): 4, (1, 1): 5, (2, 2):"], "sample_787": ["def test_multilabel_confusion_matrix():\n    # Test multilabel confusion matrix\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    mcm = multilabel_confusion_matrix(y_true, y_pred)\n    assert_array_almost_equal(mcm, np.array([[[1, 0],\n                                              [0, 1]],\n                                             [[1, 0],\n                                              [0, 1]],\n                                             [[0, 1],\n                                              [1, 0]]]))\n\n    # Test multilabel confusion matrix with sample weights\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    sample_weight = np.array([0.5, 1.5])\n    mcm = multilabel_confusion_matrix(y_true, y_pred, sample_weight=sample_weight)\n    assert_array_almost_equal(mcm, np.array([[[0.5, 0],\n                                              [0, 0.5]],\n                                             [[0.5, 0],\n                                              [0, 0.5]],\n                                             [[0, 1.5],\n                                              [1.5, 0]]]))\n\n    # Test multilabel confusion matrix with labels\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    labels = [0, 2]\n    mcm = multilabel_confusion_matrix(y_true, y_pred, labels=labels)\n    assert_array_almost_equal(mcm, np.array([[[1, 0],\n                                              [0, 1]],\n                                             [[0, 1],\n                                              [1, 0]]]))\n\n    # Test multilabel confusion matrix with samplewise\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    mcm = multilabel_confusion_matrix(y_true, y_pred,"], "sample_1": ["def test_separable_model_with_more_than_two_outputs():\n    class TestModel(Model):\n        n_inputs = 3\n        n_outputs = 3\n        separable = True\n\n            return x, y, z\n\n    model = TestModel()\n    expected_separability_matrix = np.array([[True, False, False],\n                                            [False, True, False],\n                                            [False, False, True]])\n    assert_allclose(separability_matrix(model), expected_separability_matrix)\n\n"], "sample_878": ["def test_make_column_selector():\n    # Test make_column_selector with pattern\n    selector = make_column_selector(pattern=\"city\")\n    df = pd.DataFrame({\"city\": [\"London\", \"London\", \"Paris\", \"Sallisaw\"],\n                       \"rating\": [5, 3, 4, 5]})\n    assert selector(df) == [\"city\"]\n\n    # Test make_column_selector with dtype_include\n    selector = make_column_selector(dtype_include=np.number)\n    df = pd.DataFrame({\"city\": [\"London\", \"London\", \"Paris\", \"Sallisaw\"],\n                       \"rating\": [5, 3, 4, 5]})\n    assert selector(df) == [\"rating\"]\n\n    # Test make_column_selector with dtype_exclude\n    selector = make_column_selector(dtype_exclude=object)\n    df = pd.DataFrame({\"city\": [\"London\", \"London\", \"Paris\", \"Sallisaw\"],\n                       \"rating\": [5, 3, 4, 5]})\n    assert selector(df) == [\"rating\"]\n\n    # Test make_column_selector with pattern and dtype_include\n    selector = make_column_selector(pattern=\"city\", dtype_include=object)\n    df = pd.DataFrame({\"city\": [\"London\", \"London\", \"Paris\", \"Sallisaw\"],\n                       \"rating\": [5, 3, 4, 5]})\n    assert selector(df) == [\"city\"]\n\n    # Test make_column_selector with pattern and dtype_exclude\n    selector = make_column_selector(pattern=\"city\", dtype_exclude=np.number)\n    df = pd.DataFrame({\"city\": [\"London\", \"London\", \"Paris\", \"Sallisaw\"],\n                       \"rating\": [5, 3, 4, 5]})\n    assert selector(df) == [\"city\"]\n\n    # Test make_column_selector with dtype_include and dtype_exclude\n    selector = make_column_selector(dtype_include=np.number, dtype_exclude=int)\n    df = pd.DataFrame({\"city\": [\"London\", \"London\", \"Paris\", \"Sallisaw\"],\n                       \"rating\": [5, 3, 4, 5],\n                       \"float_rating\": [5.0, 3.0, 4.0, 5.0]})\n    assert selector(df) == [\"float_rating\"]\n\n    # Test make_column_selector with all parameters\n    selector = make_column_selector(pattern=\"city\", dtype_include=object, dtype_exclude=None)\n    df = pd.DataFrame({\"city\": [\"London\", \"London\", \"Paris\", \"Sallisaw\"],\n                      "], "sample_922": ["def test_parse_annotation():\n    # Test parsing of type annotations\n    annotation = \"List[int]\"\n    result = _parse_annotation(annotation)\n    assert len(result) == 3\n    assert isinstance(result[0], nodes.Text)\n    assert result[0].astext() == \"List\"\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == \"[\"\n    assert isinstance(result[2], nodes.Text)\n    assert result[2].astext() == \"int\"\n\n    annotation = \"Dict[str, int]\"\n    result = _parse_annotation(annotation)\n    assert len(result) == 5\n    assert isinstance(result[0], nodes.Text)\n    assert result[0].astext() == \"Dict\"\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == \"[\"\n    assert isinstance(result[2], nodes.Text)\n    assert result[2].astext() == \"str\"\n    assert isinstance(result[3], desc_sig_punctuation)\n    assert result[3].astext() == \",\"\n    assert isinstance(result[4], nodes.Text)\n    assert result[4].astext() == \"int\"\n\n    annotation = \"Tuple[int, str]\"\n    result = _parse_annotation(annotation)\n    assert len(result) == 5\n    assert isinstance(result[0], nodes.Text)\n    assert result[0].astext() == \"Tuple\"\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == \"[\"\n    assert isinstance(result[2], nodes.Text)\n    assert result[2].astext() == \"int\"\n    assert isinstance(result[3], desc_sig_punctuation)\n    assert result[3].astext() == \",\"\n    assert isinstance(result[4], nodes.Text)\n    assert result[4].astext() == \"str\"\n\n    annotation = \"Union[int, str]\"\n    result = _parse_annotation(annotation)\n    assert len(result) == 5\n    assert isinstance(result[0], nodes.Text)\n    assert result[0].astext() == \"Union\"\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == \"[\"\n    assert isinstance(result[2], nodes.Text)\n    assert result[2].astext() == \"int\"\n    assert isinstance(result[3], desc_sig_punctuation)\n    assert result[3].astext() =="], "sample_651": ["def test_warnings_recorder_pop() -> None:\n    with WarningsRecorder() as wrec:\n        warnings.warn(\"message1\", UserWarning)\n        warnings.warn(\"message2\", UserWarning)\n        warnings.warn(\"message3\", DeprecationWarning)\n\n    assert len(wrec) == 3\n\n    # Test exact match\n    w = wrec.pop(UserWarning)\n    assert str(w.message) == \"message1\"\n    assert len(wrec) == 2\n\n    # Test match with subclass\n    w = wrec.pop(Warning)\n    assert str(w.message) == \"message2\"\n    assert len(wrec) == 1\n\n    # Test match with non-exact match\n    w = wrec.pop(DeprecationWarning)\n    assert str(w.message) == \"message3\"\n    assert len(wrec) == 0\n\n    # Test no match\n    with pytest.raises(AssertionError):\n        wrec.pop(UserWarning)\n\n    # Test pop with no warnings\n    wrec.clear()\n    with pytest.raises(AssertionError):\n        wrec.pop(UserWarning)\n"], "sample_909": ["    def test_google_docstring(self):\n        config = Config(napoleon_use_param=True, napoleon_use_rtype=True)\n        docstring = cleandoc('''\n            One line summary.\n\n            Extended description.\n\n            Args:\n                arg1 (int): Description of `arg1`\n                arg2 (str): Description of `arg2`\n\n            Returns:\n                str: Description of return value.\n        ''')\n        expected = dedent('''\n            One line summary.\n\n            Extended description.\n\n            :param arg1: Description of `arg1`\n            :type arg1: int\n            :param arg2: Description of `arg2`\n            :type arg2: str\n\n            :returns: Description of return value.\n            :rtype: str\n        ''')\n        self.assertEqual(str(GoogleDocstring(docstring, config)), expected)\n"], "sample_713": ["def test_ridge_regression_sparse_cg():\n    # Test sparse_cg solver with sparse input\n    X = sp.csr_matrix(np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))\n    y = np.array([1, 2, 3])\n    alpha = 1.0\n    coef = ridge_regression(X, y, alpha, solver='sparse_cg')\n    assert_array_almost_equal(coef, np.array([1, 2, 3]))\n\n    # Test sparse_cg solver with sparse input and sample weights\n    X = sp.csr_matrix(np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))\n    y = np.array([1, 2, 3])\n    alpha = 1.0\n    sample_weight = np.array([1, 2, 3])\n    coef = ridge_regression(X, y, alpha, solver='sparse_cg', sample_weight=sample_weight)\n    assert_array_almost_equal(coef, np.array([1, 2, 3]))\n\n    # Test sparse_cg solver with sparse input and multiple targets\n    X = sp.csr_matrix(np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))\n    y = np.array([[1, 2], [2, 3], [3, 4]])\n    alpha = 1.0\n    coef = ridge_regression(X, y, alpha, solver='sparse_cg')\n    assert_array_almost_equal(coef, np.array([[1, 2], [2, 3], [3, 4]]))\n\n    # Test sparse_cg solver with sparse input and multiple targets and sample weights\n    X = sp.csr_matrix(np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))\n    y = np.array([[1, 2], [2, 3], [3, 4]])\n    alpha = 1.0\n    sample_weight = np.array([1, 2, 3])\n    coef = ridge_regression(X, y, alpha, solver='sparse_cg', sample_weight=sample_weight)\n    assert_array_almost_equal(coef, np.array([[1, 2], [2, 3],"], "sample_247": ["def test_query_annotation_select(self):\n    # Test that annotation_select is correctly filtered by annotation_select_mask\n    qs = Book.objects.annotate(avg_price=Avg('price'))\n    self.assertEqual(qs.query.annotation_select, {'avg_price': qs.query.annotations['avg_price']})\n    qs.query.set_annotation_mask(['avg_price'])\n    self.assertEqual(qs.query.annotation_select, {'avg_price': qs.query.annotations['avg_price']})\n    qs.query.set_annotation_mask([])\n    self.assertEqual(qs.query.annotation_select, {})\n"], "sample_718": ["def test_check_estimator_sparse_data():\n    class SparseDataEstimator(BaseEstimator):\n            if sp.issparse(X):\n                raise ValueError(\"Sparse data not supported\")\n            return self\n\n            return np.ones(X.shape[0])\n\n    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):\n        assert_raises_regex(ValueError, \"Sparse data not supported\",\n                            check_estimator_sparse_data, \"SparseDataEstimator\",\n                            SparseDataEstimator())\n"], "sample_997": ["def test_parse_expr():\n    # Test implicit multiplication\n    assert parse_expr('2 x', transformations=(standard_transformations +\n                                             (implicit_multiplication,))) == 2*Symbol('x')\n\n    # Test implicit application\n    assert parse_expr('sin x', transformations=(standard_transformations +\n                                               (implicit_application,))) == sin(Symbol('x'))\n\n    # Test implicit multiplication and application\n    assert parse_expr('2 sin x', transformations=(standard_transformations +\n                                                 (implicit_multiplication,\n                                                  implicit_application))) == 2*sin(Symbol('x'))\n\n    # Test implicit multiplication and application with multiple arguments\n    assert parse_expr('2 sin x y', transformations=(standard_transformations +\n                                                   (implicit_multiplication,\n                                                    implicit_application))) == 2*sin(Symbol('x'), Symbol('y'))\n\n    # Test implicit multiplication and application with multiple arguments and exponentiation\n    assert parse_expr('2 sin^2 x y', transformations=(standard_transformations +\n                                                      (implicit_multiplication,\n                                                       implicit_application,\n                                                       function_exponentiation))) == 2*sin(Symbol('x'), Symbol('y'))**2\n\n    # Test implicit multiplication and application with multiple arguments and exponentiation\n    assert parse_expr('2 sin x^2 y', transformations=(standard_transformations +\n                                                      (implicit_multiplication,\n                                                       implicit_application,\n                                                       function_exponentiation))) == 2*sin(Symbol('x')**2, Symbol('y'))\n\n    # Test implicit multiplication and application with multiple arguments and exponentiation\n    assert parse_expr('2 sin x y^2', transformations=(standard_transformations +\n                                                      (implicit_multiplication,\n                                                       implicit_application,\n                                                       function_exponentiation))) == 2*sin(Symbol('x'), Symbol('y')**2)\n\n    # Test implicit multiplication and application with multiple arguments and exponentiation\n    assert parse_expr('2 sin x^2 y^2', transformations=(standard_transformations +\n                                                        (implicit_multiplication,\n                                                         implicit_application,\n                                                         function_exponentiation))) == 2*sin(Symbol('x')**2, Symbol('y')**2)\n\n    # Test implicit multiplication and application with multiple arguments and exponentiation\n    assert parse_expr('2 sin^2 x^2 y^2', transformations=(standard_transformations +\n                                                          (implicit_multiplication,\n                                                           implicit_application,\n                                                           function_exponentiation))) == 2*sin(Symbol('x')**2, Symbol('y')**2)**2\n\n    # Test implicit multiplication and application with multiple arguments and exponentiation\n    assert parse_expr"], "sample_938": ["def test_manual_page_builder_init():\n    \"\"\"Test the init method of ManualPageBuilder.\"\"\"\n    builder = ManualPageBuilder()\n    config = Config()\n    config.man_pages = []\n    builder.init()\n    assert builder.name == 'man'\n    assert builder.format == 'man'\n\n    config.man_pages = [('docname', 'name', 'description', ['author'], 1)]\n    builder.init()\n    assert builder.name == 'man'\n    assert builder.format == 'man'\n"], "sample_315": ["    def test_language_from_request(self):\n        middleware = LocaleMiddleware()\n        request = RequestFactory().get('/nl/admin/')\n        middleware.process_request(request)\n        self.assertEqual(translation.get_language(), 'nl')\n"], "sample_605": ["def test_groupby_quantile(dataset):\n    expected = dataset.quantile(0.5, dim=\"x\")\n    result = dataset.groupby(\"x\").quantile(0.5)\n    assert_identical(result, expected)\n\n    expected = dataset.quantile(0.5, dim=\"y\")\n    result = dataset.groupby(\"y\").quantile(0.5)\n    assert_identical(result, expected)\n\n    expected = dataset.quantile(0.5, dim=\"z\")\n    result = dataset.groupby(\"z\").quantile(0.5)\n    assert_identical(result, expected)\n\n    expected = dataset.quantile([0.25, 0.5, 0.75], dim=\"x\")\n    result = dataset.groupby(\"x\").quantile([0.25, 0.5, 0.75])\n    assert_identical(result, expected)\n\n    expected = dataset.quantile([0.25, 0.5, 0.75], dim=\"y\")\n    result = dataset.groupby(\"y\").quantile([0.25, 0.5, 0.75])\n    assert_identical(result, expected)\n\n    expected = dataset.quantile([0.25, 0.5, 0.75], dim=\"z\")\n    result = dataset.groupby(\"z\").quantile([0.25, 0.5, 0.75])\n    assert_identical(result, expected)\n"], "sample_600": ["def test_unsigned_integer_coder():\n    # Create a sample variable with unsigned integer data\n    data = np.array([1, 2, 3], dtype=np.uint8)\n    var = xr.Variable((\"x\",), data)\n\n    # Encode the variable\n    coder = variables.UnsignedIntegerCoder()\n    encoded_var = coder.encode(var)\n\n    # Check that the data has been converted to signed integer\n    assert encoded_var.dtype == np.int8\n\n    # Decode the variable\n    decoded_var = coder.decode(encoded_var)\n\n    # Check that the data has been converted back to unsigned integer\n    assert decoded_var.dtype == np.uint8\n\n    # Check that the data values are correct\n    assert_allclose(decoded_var, var)\n\n    # Test with _Unsigned attribute\n    var.attrs[\"_Unsigned\"] = \"true\"\n    encoded_var = coder.encode(var)\n    decoded_var = coder.decode(encoded_var)\n    assert decoded_var.dtype == np.uint8\n    assert_allclose(decoded_var, var)\n\n    # Test with _Unsigned attribute set to \"false\"\n    var.attrs[\"_Unsigned\"] = \"false\"\n    encoded_var = coder.encode(var)\n    decoded_var = coder.decode(encoded_var)\n    assert decoded_var.dtype == np.int8\n    assert_allclose(decoded_var, var)\n\n    # Test with _FillValue\n    var.attrs[\"_FillValue\"] = 255\n    encoded_var = coder.encode(var)\n    decoded_var = coder.decode(encoded_var)\n    assert decoded_var.dtype == np.uint8\n    assert_allclose(decoded_var, var)\n"], "sample_903": ["def test_tsne_fit_transform():\n    # Test that TSNE.fit_transform returns the same result as TSNE.fit followed\n    # by TSNE.embedding_\n    X = np.random.RandomState(0).rand(100, 10)\n    tsne = TSNE(n_components=2, random_state=0)\n    X_embedded_fit_transform = tsne.fit_transform(X)\n    tsne.fit(X)\n    X_embedded_fit = tsne.embedding_\n    assert_array_almost_equal(X_embedded_fit_transform, X_embedded_fit)\n"], "sample_577": ["    def test_init(self):\n\n        p = Plot()\n        assert p._data.frame.empty\n        assert p._layers == []\n        assert p._scales == {}\n        assert p._shares == {}\n        assert p._limits == {}\n        assert p._labels == {}\n        assert p._theme == {}\n        assert p._facet_spec == {}\n        assert p._pair_spec == {}\n        assert p._figure_spec == {}\n        assert p._subplot_spec == {}\n        assert p._layout_spec == {}\n        assert p._target is None\n\n        p = Plot(x=[1, 2, 3], y=[4, 5, 6])\n        assert_frame_equal(p._data.frame, pd.DataFrame({\"x\": [1, 2, 3], \"y\": [4, 5, 6]}))\n\n        p = Plot(data={\"x\": [1, 2, 3], \"y\": [4, 5, 6]})\n        assert_frame_equal(p._data.frame, pd.DataFrame({\"x\": [1, 2, 3], \"y\": [4, 5, 6]}))\n\n        p = Plot(data={\"x\": [1, 2, 3], \"y\": [4, 5, 6]}, x=[7, 8, 9])\n        assert_frame_equal(p._data.frame, pd.DataFrame({\"x\": [7, 8, 9], \"y\": [4, 5, 6]}))\n\n        p = Plot(data={\"x\": [1, 2, 3], \"y\": [4, 5, 6]}, y=[7, 8, 9])\n        assert_frame_equal(p._data.frame, pd.DataFrame({\"x\": [1, 2, 3], \"y\": [7, 8, 9]}))\n\n        p = Plot(data={\"x\": [1, 2, 3], \"y\": [4, 5, 6]}, x=[7, 8, 9], y=[10, 11, 12])\n        assert_frame_equal(p._data.frame, pd.DataFrame({\"x\": [7, 8, 9], \"y\": [10, 11, 12]}))\n\n        p = Plot(data={\"x\": [1, 2, 3], \"y\": [4, 5, 6]}, hue=[7, 8"], "sample_939": ["compilation error"], "sample_836": ["def test_unique_labels():\n    # Test that unique_labels raises an error when given no arguments\n    assert_raises(ValueError, unique_labels)\n\n    # Test that unique_labels raises an error when given arguments of different types\n    assert_raises(ValueError, unique_labels, [1, 2, 3], ['a', 'b', 'c'])\n\n    # Test that unique_labels raises an error when given multilabel-indicator and other types\n    assert_raises(ValueError, unique_labels, csr_matrix(np.array([[0, 1], [1, 0]])), [1, 2, 3])\n\n    # Test that unique_labels raises an error when given multilabel-indicator with different numbers of labels\n    assert_raises(ValueError, unique_labels, csr_matrix(np.array([[0, 1], [1, 0]])), csr_matrix(np.array([[0, 1, 0], [1, 0, 1]])))\n\n    # Test that unique_labels raises an error when given string and integer labels\n    assert_raises(ValueError, unique_labels, [1, 2, 3], ['a', 'b', 'c'])\n\n    # Test that unique_labels returns the correct unique labels for multiclass targets\n    assert_array_equal(unique_labels([1, 2, 3, 2, 1]), np.array([1, 2, 3]))\n\n    # Test that unique_labels returns the correct unique labels for multilabel-indicator targets\n    assert_array_equal(unique_labels(csr_matrix(np.array([[0, 1], [1, 0]]))), np.array([0, 1]))\n\n    # Test that unique_labels returns the correct unique labels for multiple targets\n    assert_array_equal(unique_labels([1, 2, 3], [2, 3, 4]), np.array([1, 2, 3, 4]))\n\n    # Test that unique_labels returns the correct unique labels for multiple multilabel-indicator targets\n    assert_array_equal(unique_labels(csr_matrix(np.array([[0, 1], [1, 0]])), csr_matrix(np.array([[0, 1], [1, 0]]))), np.array([0, 1]))\n"], "sample_468": ["def test_context_pop_exception(self):\n    context = Context()\n    with self.assertRaises(ContextPopException):\n        context.pop()\n    context.push({'a': 1})\n    context.pop()\n    with self.assertRaises(ContextPopException):\n        context.pop()\n"], "sample_815": ["def test_multilabel_confusion_matrix():\n    # Test multilabel confusion matrix\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    mcm = multilabel_confusion_matrix(y_true, y_pred)\n    assert_array_almost_equal(mcm, np.array([[[1, 0],\n                                             [0, 1]],\n                                            [[1, 0],\n                                             [0, 1]],\n                                            [[0, 1],\n                                             [1, 0]]]))\n\n    # Test multilabel confusion matrix with sample weights\n    sample_weight = np.array([0.5, 1.5])\n    mcm = multilabel_confusion_matrix(y_true, y_pred, sample_weight=sample_weight)\n    assert_array_almost_equal(mcm, np.array([[[0.5, 0],\n                                             [0, 1.5]],\n                                            [[1.5, 0],\n                                             [0, 0.5]],\n                                            [[0, 1.5],\n                                             [1.5, 0]]]))\n\n    # Test multilabel confusion matrix with labels\n    labels = [0, 1]\n    mcm = multilabel_confusion_matrix(y_true, y_pred, labels=labels)\n    assert_array_almost_equal(mcm, np.array([[[1, 0],\n                                             [0, 1]],\n                                            [[1, 0],\n                                             [0, 1]]))\n\n    # Test multilabel confusion matrix with samplewise=True\n    mcm = multilabel_confusion_matrix(y_true, y_pred, samplewise=True)\n    assert_array_almost_equal(mcm, np.array([[[1, 0, 0, 1],\n                                             [0, 1, 1, 0]],\n                                            [[1, 0, 0, 1],\n                                             [0, 1, 1, 0]]))\n\n    # Test multilabel confusion matrix with sample weights and samplewise=True\n    mcm = multilabel_confusion_matrix(y_true, y_pred, sample_weight=sample_weight, samplewise=True)\n    assert_array_almost_equal(mcm, np.array([[[0.5, 0, 0, 1.5],\n                                             [0, 1.5, 1.5"], "sample_1204": ["def test_coset():\n    a = Permutation(1, 2)\n    b = Permutation(0, 1)\n    G = PermutationGroup([a, b])\n    H = PermutationGroup([a])\n    cst = Coset(a, H, G, dir=\"-\")\n    assert cst.as_list() == [a, a*b, a*b**2]\n    assert cst.is_left_coset\n    assert not cst.is_right_coset\n    cst = Coset(a, H, G, dir=\"+\")\n    assert cst.as_list() == [a, b*a, b**2*a]\n    assert cst.is_right_coset\n    assert not cst.is_left_coset\n"], "sample_506": ["def test_spine_set_bounds():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3])\n    ax.spines['left'].set_bounds(1, 2)\n    ax.spines['right'].set_bounds(2, 3)\n    ax.spines['top'].set_bounds(1, 2)\n    ax.spines['bottom'].set_bounds(2, 3)\n    return fig\n"], "sample_453": ["    def test_prepopulated_fields_js(self):\n        request = self.request_factory.get(reverse(\"admin:tests_article_changelist\"))\n        request.user = self.superuser\n        context = self.get_context(request, ArticleAdmin(Article, site), Article)\n        prepopulated_fields_js(context)\n        self.assertIn(\"prepopulated_fields\", context)\n        self.assertIn(\"prepopulated_fields_json\", context)\n        self.assertIsInstance(context[\"prepopulated_fields\"], list)\n        self.assertIsInstance(context[\"prepopulated_fields_json\"], str)\n"], "sample_335": ["def test_decimal_field_to_python(self):\n    f = DecimalField(max_digits=5, decimal_places=2)\n    self.assertEqual(f.to_python('123.45'), Decimal('123.45'))\n    self.assertEqual(f.to_python('123'), Decimal('123'))\n    self.assertEqual(f.to_python('123.'), Decimal('123'))\n    self.assertEqual(f.to_python('.45'), Decimal('0.45'))\n    self.assertEqual(f.to_python(''), None)\n    self.assertEqual(f.to_python(None), None)\n    with self.assertRaises(ValidationError):\n        f.to_python('123.456')\n    with self.assertRaises(ValidationError):\n        f.to_python('12345.67')\n    with self.assertRaises(ValidationError):\n        f.to_python('abc')\n"], "sample_629": ["def test_expand_modules_with_file(tmp_path):\n    # Create a temporary directory with a Python file\n    file_path = tmp_path / \"test_file.py\"\n    file_path.write_text(\"\")\n\n    # Create a temporary directory with an __init__.py file\n    package_path = tmp_path / \"test_package\"\n    package_path.mkdir()\n    (package_path / \"__init__.py\").write_text(\"\")\n\n    # Test expand_modules with a file\n    result, errors = expand_modules(\n        [str(file_path)], [], [], []\n    )\n    assert len(result) == 1\n    assert result[0][\"path\"] == str(file_path)\n    assert result[0][\"name\"] == \"test_file\"\n    assert errors == []\n\n    # Test expand_modules with a package\n    result, errors = expand_modules(\n        [str(package_path)], [], [], []\n    )\n    assert len(result) == 1\n    assert result[0][\"path\"] == str(package_path / \"__init__.py\")\n    assert result[0][\"name\"] == \"test_package\"\n    assert errors == []\n"], "sample_281": ["def test_process_request_validates_request_parameters(self):\n    request = self.factory.get(self.url, {'term': 'test', 'app_label': 'nonexistent', 'model_name': 'Model', 'field_name': 'field'})\n    view = AutocompleteJsonView.as_view(**self.as_view_args)\n    with self.assertRaises(PermissionDenied):\n        view(request)\n\n    request = self.factory.get(self.url, {'term': 'test', 'app_label': 'tests', 'model_name': 'NonExistentModel', 'field_name': 'field'})\n    with self.assertRaises(PermissionDenied):\n        view(request)\n\n    request = self.factory.get(self.url, {'term': 'test', 'app_label': 'tests', 'model_name': 'Author', 'field_name': 'nonexistent'})\n    with self.assertRaises(PermissionDenied):\n        view(request)\n\n    request = self.factory.get(self.url, {'term': 'test', 'app_label': 'tests', 'model_name': 'Author', 'field_name': 'id'})\n    with self.assertRaises(Http404):\n        view(request)\n\n    request = self.factory.get(self.url, {'term': 'test', 'app_label': 'tests', 'model_name': 'Author', 'field_name': 'id'})\n    with model_admin(Author, AuthorAdmin(search_fields=[])):\n        with self.assertRaises(Http404):\n            view(request)\n"], "sample_1049": ["def test_plane():\n    x, y, z = symbols('x y z')\n    p1, p2, p3 = Point3D(0, 0, 0), Point3D(1, 0, 0), Point3D(0, 1, 0)\n    p = Plane(p1, p2, p3)\n    assert p.normal_vector == (0, 0, 1)\n    assert p.equation(x, y, z) == z\n    assert p.equation() == z\n    assert p.p1 == p1\n    assert p.is_coplanar(p1)\n    assert p.is_coplanar(p2)\n    assert p.is_coplanar(p3)\n    assert p.is_coplanar(Line3D(p1, p2))\n    assert p.is_coplanar(Line3D(p2, p3))\n    assert p.is_coplanar(Line3D(p3, p1))\n    assert p.is_coplanar(Line3D(p1, p3))\n    assert p.is_coplanar(Line3D(p2, p1))\n    assert p.is_coplanar(Line3D(p3, p2))\n    assert p.is_coplanar(Plane(p1, p2, p3))\n    assert p.is_coplanar(Plane(p1, p2, Point3D(1, 1, 0)))\n    assert p.is_coplanar(Plane(p1, p3, Point3D(1, 1, 0)))\n    assert p.is_coplanar(Plane(p2, p3, Point3D(1, 1, 0)))\n    assert p.is_coplanar(Plane(p1, Point3D(1, 1, 0), p3))\n    assert p.is_coplanar(Plane(p2, Point3D(1, 1, 0), p3))\n    assert p.is_coplanar(Plane(p1, p2, Point3D(2, 2, 0)))\n    assert p.is_coplanar(Plane(p1, p3, Point3D(2, 2, 0)))\n    assert p.is_coplanar(Plane(p2, p3, Point3D(2, 2, 0)))\n    assert p.is_coplanar(Plane(p1, Point3D(2, 2, 0), p3"], "sample_885": ["def test_generate_invalid_param_val_interval():\n    # Test that we can generate an invalid value for an interval constraint\n    interval = Interval(Integral, 0, 10, closed=\"both\")\n    invalid_val = generate_invalid_param_val(interval)\n    assert not interval.is_satisfied_by(invalid_val)\n\n    # Test that we can generate an invalid value for an interval constraint when\n    # there's also a real interval constraint\n    interval = Interval(Integral, 0, 10, closed=\"both\")\n    real_interval = Interval(Real, 0, 10, closed=\"both\")\n    invalid_val = generate_invalid_param_val(interval, [interval, real_interval])\n    assert not interval.is_satisfied_by(invalid_val)\n    assert not real_interval.is_satisfied_by(invalid_val)\n\n    # Test that we can't generate an invalid value for an interval constraint when\n    # there's no invalid value\n    interval = Interval(Integral, None, None, closed=\"both\")\n    with pytest.raises(NotImplementedError):\n        generate_invalid_param_val(interval)\n\n    # Test that we can't generate an invalid value for an interval constraint when\n    # there's also a real interval constraint and no invalid value\n    interval = Interval(Integral, None, None, closed=\"both\")\n    real_interval = Interval(Real, None, None, closed=\"both\")\n    with pytest.raises(NotImplementedError):\n        generate_invalid_param_val(interval, [interval, real_interval])\n"], "sample_858": ["def test_voting_regressor_weights():\n    # Test VotingRegressor with different weights\n    estimators = [('lr', LinearRegression()), ('rf', RandomForestRegressor(n_estimators=10))]\n    X_train, X_test, y_train, y_test = train_test_split(X_r, y_r, test_size=0.2, random_state=42)\n    \n    # Test with uniform weights\n    vr_uniform = VotingRegressor(estimators)\n    vr_uniform.fit(X_train, y_train)\n    y_pred_uniform = vr_uniform.predict(X_test)\n    \n    # Test with custom weights\n    vr_custom = VotingRegressor(estimators, weights=[0.7, 0.3])\n    vr_custom.fit(X_train, y_train)\n    y_pred_custom = vr_custom.predict(X_test)\n    \n    # Check that predictions are different\n    assert not np.array_equal(y_pred_uniform, y_pred_custom)\n    \n    # Check that predictions are not identical to any of the individual estimators\n    lr = LinearRegression()\n    lr.fit(X_train, y_train)\n    y_pred_lr = lr.predict(X_test)\n    rf = RandomForestRegressor(n_estimators=10)\n    rf.fit(X_train, y_train)\n    y_pred_rf = rf.predict(X_test)\n    assert not np.array_equal(y_pred_uniform, y_pred_lr)\n    assert not np.array_equal(y_pred_uniform, y_pred_rf)\n    assert not np.array_equal(y_pred_custom, y_pred_lr)\n    assert not np.array_equal(y_pred_custom, y_pred_rf)\n"], "sample_76": ["def test_check_language_settings_consistent(self):\n    # Test with LANGUAGE_CODE in LANGUAGES\n    with self.settings(LANGUAGE_CODE='en', LANGUAGES=(('en', 'English'),)):\n        self.assertEqual(check_language_settings_consistent(None), [])\n\n    # Test with LANGUAGE_CODE not in LANGUAGES\n    with self.settings(LANGUAGE_CODE='fr', LANGUAGES=(('en', 'English'),)):\n        self.assertEqual(len(check_language_settings_consistent(None)), 1)\n        self.assertEqual(check_language_settings_consistent(None)[0].id, 'translation.E004')\n\n    # Test with LANGUAGE_CODE as 'en-us' (special case)\n    with self.settings(LANGUAGE_CODE='en-us', LANGUAGES=(('en', 'English'),)):\n        self.assertEqual(check_language_settings_consistent(None), [])\n\n    # Test with LANGUAGE_CODE as None\n    with self.settings(LANGUAGE_CODE=None, LANGUAGES=(('en', 'English'),)):\n        self.assertEqual(len(check_language_settings_consistent(None)), 1)\n        self.assertEqual(check_language_settings_consistent(None)[0].id, 'translation.E001')\n\n    # Test with LANGUAGE_CODE as invalid type\n    with self.settings(LANGUAGE_CODE=123, LANGUAGES=(('en', 'English'),)):\n        self.assertEqual(len(check_language_settings_consistent(None)), 1)\n        self.assertEqual(check_language_settings_consistent(None)[0].id, 'translation.E001')\n\n    # Test with LANGUAGE_CODE as invalid tag\n    with self.settings(LANGUAGE_CODE='e\u00fc', LANGUAGES=(('en', 'English'),)):\n        self.assertEqual(len(check_language_settings_consistent(None)), 1)\n        self.assertEqual(check_language_settings_consistent(None)[0].id, 'translation.E001')\n"], "sample_745": ["def test_function_transformer_inverse_transform():\n    # Test that inverse_transform works correctly\n    X = np.array([[1, 2], [3, 4]])\n    transformer = FunctionTransformer(func=np.log, inverse_func=np.exp)\n    X_transformed = transformer.fit_transform(X)\n    X_inv_transformed = transformer.inverse_transform(X_transformed)\n    assert_allclose_dense_sparse(X, X_inv_transformed)\n\n    # Test that inverse_transform raises a warning if func and inverse_func are not inverses\n    transformer = FunctionTransformer(func=np.log, inverse_func=lambda x: x**2)\n    with pytest.warns(UserWarning):\n        transformer.fit(X)\n"], "sample_1164": ["def test_cg_simp():\n    a = symbols('a')\n    alpha = symbols('alpha')\n    b = symbols('b')\n    beta = symbols('beta')\n    c = symbols('c')\n    gamma = symbols('gamma')\n\n    # Test _check_varsh_871_1\n    assert cg_simp(Sum(CG(a, alpha, b, 0, a, alpha), (alpha, -a, a))) == (2*a + 1)*KroneckerDelta(b, 0)\n\n    # Test _check_varsh_871_2\n    assert cg_simp(Sum((-1)**(a - alpha)*CG(a, alpha, a, -alpha, c, 0), (alpha, -a, a))) == sqrt(2*a + 1)*KroneckerDelta(c, 0)\n\n    # Test _check_varsh_872_9\n    assert cg_simp(Sum(CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma), (alpha, -a, a), (beta, -b, b))) == 1\n\n    # Test _check_varsh_sum_871_1\n    assert _check_varsh_sum_871_1(Sum(CG(a, alpha, b, 0, a, alpha), (alpha, -a, a))) == (2*a + 1)*KroneckerDelta(b, 0)\n\n    # Test _check_varsh_sum_871_2\n    assert _check_varsh_sum_871_2(Sum((-1)**(a - alpha)*CG(a, alpha, a, -alpha, c, 0), (alpha, -a, a))) == sqrt(2*a + 1)*KroneckerDelta(c, 0)\n\n    # Test _check_varsh_sum_872_4\n    assert _check_varsh_sum_872_4(Sum(CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma), (alpha, -a, a), (beta, -b, b))) == 1\n"], "sample_691": ["def test_pytest_configure_with_faulthandler_already_enabled(pytester: Pytester) -> None:\n    # Arrange\n    pytester.makeini(\"[pytest]\\nfaulthandler_timeout = 1.0\")\n    import faulthandler\n    faulthandler.enable()\n\n    # Act\n    pytester.runpytest()\n\n    # Assert\n    result = pytester.runpytest(\"-v\")\n    assert \"faulthandler module enabled before pytest configuration step, 'faulthandler_timeout' option ignored\" in result.stdout.str()\n"], "sample_1032": ["def test_real_root():\n    x = Symbol('x')\n    assert real_root(-8, 3) == -2\n    assert real_root(-8, 3) == -2\n    assert real_root(-32, 5) == -2\n    assert real_root(-32, 5) == -2\n    assert real_root(-27, 3) == -3\n    assert real_root(-27, 3) == -3\n    assert real_root(-1, 3) == -1\n    assert real_root(-1, 3) == -1\n    assert real_root(-1, 5) == -1\n    assert real_root(-1, 5) == -1\n    assert real_root(-1, 7) == -1\n    assert real_root(-1, 7) == -1\n    assert real_root(-1, 9) == -1\n    assert real_root(-1, 9) == -1\n    assert real_root(-1, 11) == -1\n    assert real_root(-1, 11) == -1\n    assert real_root(-1, 13) == -1\n    assert real_root(-1, 13) == -1\n    assert real_root(-1, 15) == -1\n    assert real_root(-1, 15) == -1\n    assert real_root(-1, 17) == -1\n    assert real_root(-1, 17) == -1\n    assert real_root(-1, 19) == -1\n    assert real_root(-1, 19) == -1\n    assert real_root(-1, 21) == -1\n    assert real_root(-1, 21) == -1\n    assert real_root(-1, 23) == -1\n    assert real_root(-1, 23) == -1\n    assert real_root(-1, 25) == -1\n    assert real_root(-1, 25) == -1\n    assert real_root(-1, 27) == -1\n    assert real_root(-1, 27) == -1\n    assert real_root(-1, 29) == -1\n    assert real_root(-1, 29) == -1\n    assert real_root(-1, 31) == -1\n    assert real_root(-1,"], "sample_221": ["    def setUpTestData(cls):\n        cls.event1 = Event.objects.create(name='Event 1')\n        cls.event2 = Event.objects.create(name='Event 2')\n        cls.event3 = Event.objects.create(name='Event 3')\n"], "sample_1111": ["def test_textplot_str():\n    x = Symbol('x')\n    expr = sin(x)\n    a = 0\n    b = 10\n    W = 55\n    H = 21\n    lines = list(textplot_str(expr, a, b, W, H))\n    assert len(lines) == H + 1  # +1 for the x values line\n    assert all(len(line) == W + len(str(int(b))) + 3 for line in lines[:-1])  # +3 for the margin and the '|' character\n    assert len(lines[-1]) == W + len(str(int(b))) + 2  # +2 for the margin\n"], "sample_630": ["def test_dot_writer_get_values_with_exception():\n    \"\"\"test get_values method of DotWriter with an exception\"\"\"\n    config = Config()\n    writer = DotWriter(config)\n    obj = astroid.Instance(\"Exception\", lineno=1)\n    values = writer.get_values(obj)\n    assert values[\"fontcolor\"] == \"red\"\n    assert values[\"shape\"] == \"record\"\n\n"], "sample_70": ["    def test_collector_add_field_update(self):\n        collector = Collector(using='default')\n        field = models.ForeignKey(A, on_delete=models.CASCADE)\n        objs = [R(), R()]\n        collector.add_field_update(field, 1, objs)\n        self.assertEqual(len(collector.field_updates), 1)\n        self.assertEqual(len(collector.field_updates[R]), 1)\n        self.assertEqual(len(collector.field_updates[R][(field, 1)]), 2)\n\n        # Test adding the same field update again\n        collector.add_field_update(field, 1, objs)\n        self.assertEqual(len(collector.field_updates), 1)\n        self.assertEqual(len(collector.field_updates[R]), 1)\n        self.assertEqual(len(collector.field_updates[R][(field, 1)]), 2)\n\n        # Test adding a different field update\n        collector.add_field_update(field, 2, objs)\n        self.assertEqual(len(collector.field_updates), 1)\n        self.assertEqual(len(collector.field_updates[R]), 2)\n        self.assertEqual(len(collector.field_updates[R][(field, 1)]), 2)\n        self.assertEqual(len(collector.field_updates[R][(field, 2)]), 2)\n\n        # Test adding a field update for a different model\n        field2 = models.ForeignKey(M, on_delete=models.CASCADE)\n        objs2 = [M(), M()]\n        collector.add_field_update(field2, 1, objs2)\n        self.assertEqual(len(collector.field_updates), 2)\n        self.assertEqual(len(collector.field_updates[R]), 2)\n        self.assertEqual(len(collector.field_updates[M]), 1)\n        self.assertEqual(len(collector.field_updates[M][(field2, 1)]), 2)\n"], "sample_353": ["    def test_create_superuser_with_password_validation_error(self):\n        call_command('createsuperuser', interactive=False, stdin=MockTTY())\n        self.assertEqual(CustomUser.objects.count(), 1)\n        self.assertEqual(CustomUser.objects.first().username, 'alice')\n"], "sample_1205": ["def test_ring():\n    R, x, y, z = ring('x, y, z', ZZ)\n    assert R.symbols == (x, y, z)\n    assert R.ngens == 3\n    assert R.domain == ZZ\n    assert R.order == lex\n    assert R.zero_monom == (0, 0, 0)\n    assert R.gens == (x, y, z)\n    assert R._gens_set == {x, y, z}\n    assert R._one == [(0, 0, 0), 1]\n    assert R.monomial_mul == R._monomial_mul\n    assert R.monomial_pow == R._monomial_pow\n    assert R.monomial_mulpow == R._monomial_mulpow\n    assert R.monomial_ldiv == R._monomial_ldiv\n    assert R.monomial_div == R._monomial_div\n    assert R.monomial_lcm == R._monomial_lcm\n    assert R.monomial_gcd == R._monomial_gcd\n    assert R.leading_expv == max\n\n    R, (x, y, z) = xring('x, y, z', ZZ)\n    assert R.symbols == (x, y, z)\n    assert R.ngens == 3\n    assert R.domain == ZZ\n    assert R.order == lex\n    assert R.zero_monom == (0, 0, 0)\n    assert R.gens == (x, y, z)\n    assert R._gens_set == {x, y, z}\n    assert R._one == [(0, 0, 0), 1]\n    assert R.monomial_mul == R._monomial_mul\n    assert R.monomial_pow == R._monomial_pow\n    assert R.monomial_mulpow == R._monomial_mulpow\n    assert R.monomial_ldiv == R._monomial_ldiv\n    assert R.monomial_div == R._monomial_div\n    assert R.monomial_lcm == R._monomial_lcm\n    assert R.monomial_gcd == R._monomial_gcd\n    assert R.leading_expv == max\n\n    R = vring('x, y, z', ZZ)\n    assert R.symbols == (x, y, z)\n    assert R.ngens == 3\n"], "sample_1094": ["def test_basic():\n    assert b1.args == ()\n    assert b2.args == (b1,)\n    assert b3.args == (b2,)\n    assert b21.args == (b2, b1)\n\n    assert b1._sorted_args == ()\n    assert b2._sorted_args == (b1,)\n    assert b3._sorted_args == (b2,)\n    assert b21._sorted_args == (b1, b2)\n\n    assert b1.func == Basic\n    assert b2.func == Basic\n    assert b3.func == Basic\n    assert b21.func == Basic\n\n    assert b1.copy() == b1\n    assert b2.copy() == b2\n    assert b3.copy() == b3\n    assert b21.copy() == b21\n\n    assert b1.as_content_primitive() == (S.One, b1)\n    assert b2.as_content_primitive() == (S.One, b2)\n    assert b3.as_content_primitive() == (S.One, b3)\n    assert b21.as_content_primitive() == (S.One, b21)\n\n    assert b1.subs({}) == b1\n    assert b2.subs({}) == b2\n    assert b3.subs({}) == b3\n    assert b21.subs({}) == b21\n\n    assert b1.xreplace({}) == b1\n    assert b2.xreplace({}) == b2\n    assert b3.xreplace({}) == b3\n    assert b21.xreplace({}) == b21\n\n    assert b1.has(b1) == True\n    assert b2.has(b1) == True\n    assert b3.has(b1) == True\n    assert b21.has(b1) == True\n\n    assert b1.has(b2) == False\n    assert b2.has(b2) == True\n    assert b3.has(b2) == True\n    assert b21.has(b2) == True\n\n    assert b1.has(b3) == False\n    assert b2.has(b3) == False\n    assert b3.has(b3) == True\n    assert b21.has(b3) == False\n\n    assert b1.has(b21) == False\n    assert b2.has(b21) == False\n    assert b3.has(b21) == False\n    assert b21.has(b21) == True\n\n    assert b1._has(b1)"], "sample_911": ["def test_template_introduction():\n    input = \"concept C<T> { T t; }\"\n    output = \"concept C<T> { T t; }\"\n    idDict = {3: \"3CIXT_E\"}\n    check(\"concept\", input, idDict, output)\n"], "sample_961": ["def test_parse_annotation():\n    env = Mock(spec=['config'])\n    env.config.python_use_unqualified_type_names = False\n\n    # Test simple type\n    annotation = 'int'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'int'\n\n    # Test type with module\n    annotation = 'module.Type'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'module.Type'\n\n    # Test type with multiple modules\n    annotation = 'module1.module2.Type'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'module1.module2.Type'\n\n    # Test type with generic\n    annotation = 'List[int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 3\n    assert isinstance(result[0], nodes.Text)\n    assert result[0].astext() == 'List'\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == '['\n    assert isinstance(result[2], pending_xref)\n    assert result[2].attributes['reftarget'] == 'int'\n\n    # Test type with multiple generics\n    annotation = 'Dict[str, int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 5\n    assert isinstance(result[0], nodes.Text)\n    assert result[0].astext() == 'Dict'\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == '['\n    assert isinstance(result[2], pending_xref)\n    assert result[2].attributes['reftarget'] == 'str'\n    assert isinstance(result[3], desc_sig_punctuation)\n    assert result[3].astext() == ','\n    assert isinstance(result[4], pending_xref)\n    assert result[4].attributes['reftarget'] == 'int'\n\n    # Test type with nested generics\n    annotation = 'List[Dict[str, int]]'\n    result = _parse_annotation(annotation, env"], "sample_340": ["    def test_load_disk(self):\n        \"\"\"\n        Test loading migrations from disk.\n        \"\"\"\n        loader = MigrationLoader(connection=connection)\n        loader.load_disk()\n        self.assertIsNotNone(loader.disk_migrations)\n        self.assertIsNotNone(loader.unmigrated_apps)\n        self.assertIsNotNone(loader.migrated_apps)\n"], "sample_849": ["def test_leave_p_groups_out():\n    # Test LeavePGroupsOut\n    for groups in test_groups:\n        logo = LeavePGroupsOut(n_groups=2)\n        n_splits = logo.get_n_splits(groups=groups)\n        assert n_splits == comb(len(np.unique(groups)), 2, exact=True)\n        for train, test in logo.split(groups=groups):\n            assert len(train) + len(test) == len(groups)\n            assert len(np.unique(groups[test])) == 2\n            assert len(np.unique(groups[train])) == len(np.unique(groups)) - 2\n"], "sample_1175": ["def test_tensor():\n    i = TensorIndex('i', TensorIndexType('contravariant'))\n    j = TensorIndex('j', TensorIndexType('covariant'))\n    k = TensorIndex('k', TensorIndexType('contravariant'))\n    l = TensorIndex('l', TensorIndexType('covariant'))\n    A = TensorHead('A', [i, j])\n    B = TensorHead('B', [k, l])\n    expr = A(i, j) * B(-i, -j)\n    assert pretty(expr) == \"A  B\"\n    assert upretty(expr) == \"A  B\"\n    expr = A(i, j) * B(i, j)\n    assert pretty(expr) == \"A  B\"\n    assert upretty(expr) == \"A  B\"\n    expr = A(i, j) * B(-j, -i)\n    assert pretty(expr) == \"A  B\"\n    assert upretty(expr) == \"A  B\"\n    expr = A(i, j) * B(j, i)\n    assert pretty(expr) == \"A  B\"\n    assert upretty(expr) == \"A  B\"\n    expr = A(i, j) * B(i, -j)\n    assert pretty(expr) == \"A  B\"\n    assert upretty(expr) == \"A  B\"\n    expr = A(i, j) * B(-i, j)\n    assert pretty(expr) == \"A  B\"\n    assert upretty(expr) == \"A  B\"\n    expr = A(i, j) * B(j, -i)\n    assert pretty(expr) == \"A  B\"\n    assert upretty(expr) == \"A  B\"\n    expr = A(i, j) * B(-j, i)\n    assert pretty(expr) == \"A  B\"\n    assert upretty(expr) == \"A  B\"\n    expr = A(i, j) * B(i, j) * B(i, j)\n    assert pretty(expr) == \"A  B  B\"\n    assert upretty(expr) == \"A  B  B\"\n    expr = A(i, j) * B(i, j) * B(j, i)\n    assert pretty(expr) == \"A  B  B\"\n    assert upretty(expr) == \"A  B  B\"\n    expr = A(i, j) * B(i, j) * B(-j,"], "sample_654": ["def test_scopeproperty_decorator():\n    class TestClass:\n            self.request = request\n\n        @fixtures.scopeproperty(\"function\")\n            return \"function\"\n\n        @fixtures.scopeproperty(\"class\")\n            return \"class\"\n\n        @fixtures.scopeproperty(\"module\")\n            return \"module\"\n\n        @fixtures.scopeproperty(\"package\")\n            return \"package\"\n\n        @fixtures.scopeproperty(\"session\")\n            return \"session\"\n\n    request = fixtures.FixtureRequest(None)\n    request.scope = \"function\"\n    test_class = TestClass(request)\n\n    assert test_class.function == \"function\"\n    with pytest.raises(AttributeError):\n        test_class.cls\n    with pytest.raises(AttributeError):\n        test_class.module\n    with pytest.raises(AttributeError):\n        test_class.package\n    with pytest.raises(AttributeError):\n        test_class.session\n\n    request.scope = \"class\"\n    assert test_class.function == \"function\"\n    assert test_class.cls == \"class\"\n    with pytest.raises(AttributeError):\n        test_class.module\n    with pytest.raises(AttributeError):\n        test_class.package\n    with pytest.raises(AttributeError):\n        test_class.session\n\n    request.scope = \"module\"\n    assert test_class.function == \"function\"\n    assert test_class.cls == \"class\"\n    assert test_class.module == \"module\"\n    with pytest.raises(AttributeError):\n        test_class.package\n    with pytest.raises(AttributeError):\n        test_class.session\n\n    request.scope = \"package\"\n    assert test_class.function == \"function\"\n    assert test_class.cls == \"class\"\n    assert test_class.module == \"module\"\n    assert test_class.package == \"package\"\n    with pytest.raises(AttributeError):\n        test_class.session\n\n    request.scope = \"session\"\n    assert test_class.function == \"function\"\n    assert test_class.cls == \"class\"\n    assert test_class.module == \"module\"\n    assert test_class.package == \"package\"\n    assert test_class.session == \"session\"\n"], "sample_857": ["def test_prune_tree():\n    # Test that pruning a tree with a high alpha value results in a tree with\n    # fewer nodes\n    X, y = iris.data, iris.target\n    clf = DecisionTreeClassifier(ccp_alpha=0.1, random_state=0)\n    clf.fit(X, y)\n    n_nodes_before_pruning = clf.tree_.node_count\n\n    # Prune the tree\n    clf.ccp_alpha = 0.5\n    clf._prune_tree()\n    n_nodes_after_pruning = clf.tree_.node_count\n\n    assert n_nodes_after_pruning < n_nodes_before_pruning\n\n    # Test that pruning a tree with a low alpha value does not change the tree\n    clf = DecisionTreeClassifier(ccp_alpha=0.0, random_state=0)\n    clf.fit(X, y)\n    n_nodes_before_pruning = clf.tree_.node_count\n\n    # Prune the tree\n    clf.ccp_alpha = 0.0001\n    clf._prune_tree()\n    n_nodes_after_pruning = clf.tree_.node_count\n\n    assert n_nodes_after_pruning == n_nodes_before_pruning\n\n    # Test that pruning a tree with a negative alpha value raises an error\n    clf = DecisionTreeClassifier(ccp_alpha=-0.1, random_state=0)\n    with pytest.raises(ValueError):\n        clf.fit(X, y)\n"], "sample_639": ["def test_get_message_definition():\n    checker = OtherBasicChecker()\n    message_definition = checker.get_message_definition(\"W0001\")\n    assert message_definition.msgid == \"W0001\"\n    assert message_definition.msg == \"Basic checker has an example.\"\n    assert message_definition.symbol == \"basic-checker-example\"\n    assert message_definition.descr == \"Used nowhere and serves no purpose.\"\n\n    with pytest.raises(InvalidMessageError):\n        checker.get_message_definition(\"W0002\")\n"], "sample_668": ["def test_deprecated_external_plugins():\n    assert isinstance(DEPRECATED_EXTERNAL_PLUGINS, set)\n    assert len(DEPRECATED_EXTERNAL_PLUGINS) == 3\n    assert \"pytest_catchlog\" in DEPRECATED_EXTERNAL_PLUGINS\n    assert \"pytest_capturelog\" in DEPRECATED_EXTERNAL_PLUGINS\n    assert \"pytest_faulthandler\" in DEPRECATED_EXTERNAL_PLUGINS\n"], "sample_764": ["def test_transformer_weights():\n    # test that transformer weights are applied correctly\n    X = np.array([[1, 2, 3], [4, 5, 6]])\n    transformer_weights = {'scaler': 2, 'encoder': 3}\n    ct = ColumnTransformer([\n        ('scaler', StandardScaler(), [0]),\n        ('encoder', OneHotEncoder(), [1])\n    ], transformer_weights=transformer_weights)\n    ct.fit(X)\n    X_t = ct.transform(X)\n    assert_allclose_dense_sparse(X_t[:, :1], 2 * StandardScaler().fit_transform(X[:, :1]))\n    assert_allclose_dense_sparse(X_t[:, 1:], 3 * OneHotEncoder().fit_transform(X[:, 1:]))\n"], "sample_10": ["def test_table_attribute():\n    class MyTable(Table):\n        identifier = TableAttribute(default=1)\n\n    t = MyTable(identifier=10)\n    assert t.identifier == 10\n    assert t.meta == OrderedDict([('__attributes__', {'identifier': 10})])\n\n    t.identifier = 20\n    assert t.identifier == 20\n    assert t.meta == OrderedDict([('__attributes__', {'identifier': 20})])\n\n    t2 = MyTable(t)\n    assert t2.identifier == 20\n    assert t2.meta == OrderedDict([('__attributes__', {'identifier': 20})])\n\n    t3 = MyTable(t, meta={'identifier': 30})\n    assert t3.identifier == 30\n    assert t3.meta == OrderedDict([('__attributes__', {'identifier': 30})])\n"], "sample_897": ["def test_partial_dependence_display_from_estimator(diabetes, clf_diabetes):\n    # Test that the display is created correctly\n    display = PartialDependenceDisplay.from_estimator(\n        clf_diabetes, diabetes.data, [0], n_cols=3, grid_resolution=10\n    )\n    assert display.pd_results[0].average.shape == (1, 10)\n    assert display.pd_results[0].grid_values.shape == (10,)\n\n    # Test that the display is created correctly with categorical features\n    X = np.hstack((diabetes.data, np.random.randint(0, 2, size=(50, 1))))\n    clf = GradientBoostingRegressor(n_estimators=10, random_state=1)\n    clf.fit(X, diabetes.target)\n    display = PartialDependenceDisplay.from_estimator(\n        clf, X, [0, 10], n_cols=3, grid_resolution=10, categorical_features=[10]\n    )\n    assert display.pd_results[0].average.shape == (1, 10)\n    assert display.pd_results[0].grid_values.shape == (10,)\n    assert display.pd_results[1].average.shape == (1, 2)\n    assert display.pd_results[1].grid_values.shape == (2,)\n\n    # Test that the display is created correctly with multiple features\n    display = PartialDependenceDisplay.from_estimator(\n        clf_diabetes, diabetes.data, [(0, 1)], n_cols=3, grid_resolution=10\n    )\n    assert display.pd_results[0].average.shape == (1, 10, 10)\n    assert display.pd_results[0].grid_values.shape == (2, 10)\n\n    # Test that the display is created correctly with multiple features and categorical features\n    display = PartialDependenceDisplay.from_estimator(\n        clf, X, [(0, 10)], n_cols=3, grid_resolution=10, categorical_features=[10]\n    )\n    assert display.pd_results[0].average.shape == (1, 10, 2)\n    assert display.pd_results[0].grid_values.shape == (2, 10)\n\n    # Test that the display is created correctly with multiple features and multiple categorical features\n    X = np.hstack((diabetes.data, np.random.randint(0, 2, size=(50, 2))))\n    clf = GradientBoostingRegressor(n_estimators=10, random_state="], "sample_1081": ["def test_mersenne_prime_exponent():\n    for i in range(1, 52):\n        assert mersenne_prime_exponent(i) in MERSENNE_PRIME_EXPONENTS\n    raises(ValueError, lambda: mersenne_prime_exponent(0))\n    raises(ValueError, lambda: mersenne_prime_exponent(52))\n"], "sample_113": ["def test_replace_named_groups(self):\n    pattern = r'^(?P<a>\\w+)/b/(?P<c>\\w+)/$'\n    expected = r'^<a>/b/<c>/$'\n    self.assertEqual(utils.replace_named_groups(pattern), expected)\n\n    pattern = r'^(?P<a>\\w+)/b/(?P<c>\\w+)$'\n    expected = r'^<a>/b/<c>$'\n    self.assertEqual(utils.replace_named_groups(pattern), expected)\n\n    pattern = r'^(?P<a>\\w+)/b/(\\w+)/$'\n    expected = r'^<a>/b/<var>/$'\n    self.assertEqual(utils.replace_named_groups(pattern), expected)\n\n    pattern = r'^(?P<a>\\w+)/b/(\\w+)$'\n    expected = r'^<a>/b/<var>$'\n    self.assertEqual(utils.replace_named_groups(pattern), expected)\n"], "sample_408": ["def test_altered_indexes(self):\n    before_state = self.make_project_state(\n        [\n            self.book_indexes,\n        ]\n    )\n    after_state = self.make_project_state(\n        [\n            self.book_unordered_indexes,\n        ]\n    )\n    changes = MigrationAutodetector(before_state, after_state)._detect_changes()\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"RemoveIndex\", \"AddIndex\"])\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        0,\n        model_name=\"book\",\n        name=\"book_title_author_idx\",\n    )\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        1,\n        model_name=\"book\",\n        index=models.Index(fields=[\"title\", \"author\"], name=\"book_author_title_idx\"),\n    )\n"], "sample_375": ["def test_project_state_clone(self):\n    project_state = ProjectState()\n    project_state.models = {\n        ('app_label', 'model_name'): ModelState(\n            app_label='app_label',\n            name='ModelName',\n            fields={'field_name': models.Field()},\n            options={'option_name': 'option_value'},\n            bases=(models.Model,),\n            managers=[('manager_name', models.Manager())],\n        )\n    }\n    project_state.real_apps = {'app_label'}\n    project_state.is_delayed = True\n\n    cloned_project_state = project_state.clone()\n\n    self.assertEqual(project_state.models, cloned_project_state.models)\n    self.assertEqual(project_state.real_apps, cloned_project_state.real_apps)\n    self.assertEqual(project_state.is_delayed, cloned_project_state.is_delayed)\n\n    # Check that the cloned project state has its own apps registry\n    self.assertIsNot(project_state.apps, cloned_project_state.apps)\n\n    # Check that the cloned model state has its own fields and options\n    self.assertIsNot(project_state.models[('app_label', 'model_name')].fields, cloned_project_state.models[('app_label', 'model_name')].fields)\n    self.assertIsNot(project_state.models[('app_label', 'model_name')].options, cloned_project_state.models[('app_label', 'model_name')].options)\n"], "sample_1160": ["def test_intersection_sets():\n    # Test intersection of ConditionSet with Set\n    x = symbols('x')\n    cond_set = ConditionSet(x, x**2 + 1 > 0, S.Reals)\n    interval = Interval(0, 1)\n    assert intersection_sets(cond_set, interval) == ConditionSet(x, x**2 + 1 > 0, interval)\n\n    # Test intersection of Naturals with Integers\n    assert intersection_sets(S.Naturals, S.Integers) == S.Naturals\n\n    # Test intersection of Naturals with Naturals\n    assert intersection_sets(S.Naturals, S.Naturals) == S.Naturals\n\n    # Test intersection of Interval with Naturals\n    interval = Interval(1, 10)\n    assert intersection_sets(interval, S.Naturals) == Range(1, 11)\n\n    # Test intersection of ComplexRegion with Set\n    region = ComplexRegion(Interval(0, 1) * Interval(0, 2*pi))\n    interval = Interval(0, 1)\n    assert intersection_sets(region, interval) == ComplexRegion(Interval(0, 1) * Interval(0, 2*pi))\n\n    # Test intersection of Integers with Reals\n    assert intersection_sets(S.Integers, S.Reals) == S.Integers\n\n    # Test intersection of Range with Interval\n    range_set = Range(1, 10)\n    interval = Interval(3, 7)\n    assert intersection_sets(range_set, interval) == Range(3, 8)\n\n    # Test intersection of Range with Naturals\n    range_set = Range(1, 10)\n    assert intersection_sets(range_set, S.Naturals) == range_set\n\n    # Test intersection of Range with Range\n    range_set1 = Range(1, 10)\n    range_set2 = Range(5, 15)\n    assert intersection_sets(range_set1, range_set2) == Range(5, 10)\n\n    # Test intersection of ImageSet with Set\n    lamda = Lambda(x, x**2)\n    image_set = imageset(lamda, S.Integers)\n    interval = Interval(0, 10)\n    assert intersection_sets(image_set, interval) == imageset(lamda, Range(0, 4))\n\n    # Test intersection of ProductSet with ProductSet\n    set1 = ProductSet(Interval(0, 1), Interval"], "sample_484": ["    def test_right_function(self):\n        author = Author.objects.annotate(right_name=Right(\"name\", 5)).get(name=\"John Smith\")\n        self.assertEqual(author.right_name, \"Smith\")\n"], "sample_742": ["def test_logistic_regression_path_multiclass():\n    # Test logistic_regression_path with multiclass classification\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5,\n                               n_redundant=3, n_repeated=2, n_classes=3,\n                               n_clusters_per_class=1, random_state=0)\n    Cs = [0.1, 1, 10]\n    coefs, Cs, n_iter = logistic_regression_path(X, y, Cs=Cs,\n                                                  multi_class='multinomial',\n                                                  solver='lbfgs')\n    assert len(coefs) == len(Cs)\n    assert coefs[0].shape == (3, 10)\n\n    # Test logistic_regression_path with multiclass classification and warm start\n    coefs, Cs, n_iter = logistic_regression_path(X, y, Cs=Cs,\n                                                  multi_class='multinomial',\n                                                  solver='lbfgs',\n                                                  coef=coefs[0])\n    assert len(coefs) == len(Cs)\n    assert coefs[0].shape == (3, 10)\n"], "sample_400": ["def test_altered_indexes(self):\n    before_state = self.make_project_state(\n        [\n            self.book_indexes,\n        ]\n    )\n    after_state = self.make_project_state(\n        [\n            self.book_unordered_indexes,\n        ]\n    )\n    changes = MigrationAutodetector(before_state, after_state)._detect_changes()\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"RemoveIndex\", \"AddIndex\"])\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        0,\n        model_name=\"Book\",\n        name=\"book_title_author_idx\",\n    )\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        1,\n        model_name=\"Book\",\n        index=models.Index(fields=[\"title\", \"author\"], name=\"book_author_title_idx\"),\n    )\n"], "sample_283": ["    def test_runshell_restores_sigint_handler(self, mock_popen):\n        mock_popen.return_value.wait.side_effect = KeyboardInterrupt\n        with self.assertRaises(KeyboardInterrupt):\n            self.settings_to_cmd_args_env({'NAME': 'test_db'})\n            DatabaseClient().runshell([])\n        self.assertEqual(signal.getsignal(signal.SIGINT), signal.default_int_handler)\n"], "sample_735": ["def test_gaussian_mixture_bic_aic():\n    # Test that BIC and AIC scores are computed correctly\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 100, 2\n    n_components = 2\n    X = rng.rand(n_samples, n_features)\n\n    gmm = GaussianMixture(n_components=n_components, random_state=rng)\n    gmm.fit(X)\n\n    bic = gmm.bic(X)\n    aic = gmm.aic(X)\n\n    assert isinstance(bic, float)\n    assert isinstance(aic, float)\n    assert bic > aic\n\n    # Test that BIC and AIC scores are computed correctly for different\n    # covariance types\n    for covariance_type in COVARIANCE_TYPE:\n        gmm = GaussianMixture(n_components=n_components,\n                               covariance_type=covariance_type,\n                               random_state=rng)\n        gmm.fit(X)\n\n        bic = gmm.bic(X)\n        aic = gmm.aic(X)\n\n        assert isinstance(bic, float)\n        assert isinstance(aic, float)\n        assert bic > aic\n"], "sample_501": ["def test_legend_handler_map():\n    # Test that the default handler map is correctly set and updated.\n    default_handler_map = mlegend.Legend.get_default_handler_map()\n    assert isinstance(default_handler_map, dict)\n    assert len(default_handler_map) > 0\n\n    # Test that the default handler map can be updated.\n    new_handler_map = {mlines.Line2D: HandlerTuple()}\n    mlegend.Legend.update_default_handler_map(new_handler_map)\n    updated_handler_map = mlegend.Legend.get_default_handler_map()\n    assert updated_handler_map[mlines.Line2D] == HandlerTuple()\n\n    # Test that the default handler map can be reset.\n    mlegend.Legend.set_default_handler_map({})\n    reset_handler_map = mlegend.Legend.get_default_handler_map()\n    assert len(reset_handler_map) == 0\n\n    # Test that the legend handler map can be set and updated for a Legend instance.\n    legend = mlegend.Legend(None, [], [])\n    assert isinstance(legend.get_legend_handler_map(), dict)\n    assert len(legend.get_legend_handler_map()) > 0\n\n    new_handler_map = {mlines.Line2D: HandlerTuple()}\n    legend._custom_handler_map = new_handler_map\n    updated_handler_map = legend.get_legend_handler_map()\n    assert updated_handler_map[mlines.Line2D] == HandlerTuple()\n"], "sample_64": ["    def test_init(self):\n        response = HttpResponseBase()\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response._headers, {})\n        self.assertEqual(response._closable_objects, [])\n        self.assertEqual(response.cookies, SimpleCookie())\n        self.assertEqual(response.closed, False)\n"], "sample_40": ["def test_pixel_scale():\n    pixscale = 0.1 * u.arcsec / u.pix\n    equiv = u.pixel_scale(pixscale)\n    assert_quantity_allclose(1*u.pix.to(u.arcsec, equivalencies=equiv), 0.1*u.arcsec)\n    assert_quantity_allclose(1*u.arcsec.to(u.pix, equivalencies=equiv), 10*u.pix)\n\n    pixscale = 10 * u.pix / u.arcsec\n    equiv = u.pixel_scale(pixscale)\n    assert_quantity_allclose(1*u.pix.to(u.arcsec, equivalencies=equiv), 0.1*u.arcsec)\n    assert_quantity_allclose(1*u.arcsec.to(u.pix, equivalencies=equiv), 10*u.pix)\n\n    with pytest.raises(u.UnitsError):\n        u.pixel_scale(0.1*u.arcsec)\n\n    with pytest.raises(u.UnitsError):\n        u.pixel_scale(10*u.pix/u.m)\n"], "sample_505": ["def test_date2num():\n    # Test date2num with datetime objects\n    dt = datetime.datetime(2022, 1, 1)\n    assert mdates.date2num(dt) == 737060.0\n\n    # Test date2num with numpy datetime64 objects\n    dt64 = np.datetime64('2022-01-01')\n    assert mdates.date2num(dt64) == 737060.0\n\n    # Test date2num with a list of datetime objects\n    dt_list = [datetime.datetime(2022, 1, 1), datetime.datetime(2022, 1, 2)]\n    assert np.allclose(mdates.date2num(dt_list), [737060.0, 737061.0])\n\n    # Test date2num with a list of numpy datetime64 objects\n    dt64_list = [np.datetime64('2022-01-01'), np.datetime64('2022-01-02')]\n    assert np.allclose(mdates.date2num(dt64_list), [737060.0, 737061.0])\n\n    # Test date2num with a timezone\n    tz = dateutil.tz.tzlocal()\n    dt_tz = datetime.datetime(2022, 1, 1, tzinfo=tz)\n    assert mdates.date2num(dt_tz) == 737060.0\n\n    # Test date2num with a timezone and a list of datetime objects\n    dt_tz_list = [datetime.datetime(2022, 1, 1, tzinfo=tz), datetime.datetime(2022, 1, 2, tzinfo=tz)]\n    assert np.allclose(mdates.date2num(dt_tz_list), [737060.0, 737061.0])\n\n    # Test date2num with a timezone and a list of numpy datetime64 objects\n    dt64_tz_list = [np.datetime64('2022-01-01'), np.datetime64('2022-01-02')]\n    assert np.allclose(mdates.date2num(dt64_tz_list), [737060.0, 737061.0])\n"], "sample_35": ["def test_resolve_name():\n    # Test resolving a module\n    import astropy\n    assert introspection.resolve_name('astropy') is astropy\n\n    # Test resolving a submodule\n    import astropy.utils\n    assert introspection.resolve_name('astropy.utils') is astropy.utils\n\n    # Test resolving a function\n    assert introspection.resolve_name('astropy.utils.introspection.resolve_name') is introspection.resolve_name\n\n    # Test resolving a class\n    assert introspection.resolve_name('astropy.utils.introspection.IntrospectionTestCase') is introspection.IntrospectionTestCase\n\n    # Test resolving a non-existent module\n    with pytest.raises(ImportError):\n        introspection.resolve_name('non_existent_module')\n\n    # Test resolving a non-existent submodule\n    with pytest.raises(ImportError):\n        introspection.resolve_name('astropy.non_existent_submodule')\n\n    # Test resolving a non-existent function\n    with pytest.raises(ImportError):\n        introspection.resolve_name('astropy.utils.introspection.non_existent_function')\n\n    # Test resolving a non-existent class\n    with pytest.raises(ImportError):\n        introspection.resolve_name('astropy.utils.introspection.NonExistentClass')\n\n    # Test resolving with additional parts\n    assert introspection.resolve_name('astropy', 'utils', 'introspection', 'resolve_name') is introspection.resolve_name\n\n    # Test resolving with a single part\n    assert introspection.resolve_name('astropy.utils.introspection.resolve_name') is introspection.resolve_name\n"], "sample_895": ["def test_make_column_selector():\n    # Test that make_column_selector can select columns based on pattern\n    selector = make_column_selector(pattern=\"city\")\n    df = pd.DataFrame({\"city\": [\"London\", \"London\", \"Paris\", \"Sallisaw\"],\n                       \"rating\": [5, 3, 4, 5]})\n    assert selector(df) == [\"city\"]\n\n    # Test that make_column_selector can select columns based on dtype\n    selector = make_column_selector(dtype_include=np.number)\n    df = pd.DataFrame({\"city\": [\"London\", \"London\", \"Paris\", \"Sallisaw\"],\n                       \"rating\": [5, 3, 4, 5]})\n    assert selector(df) == [\"rating\"]\n\n    # Test that make_column_selector can select columns based on both pattern and dtype\n    selector = make_column_selector(pattern=\"city\", dtype_include=np.object)\n    df = pd.DataFrame({\"city\": [\"London\", \"London\", \"Paris\", \"Sallisaw\"],\n                       \"rating\": [5, 3, 4, 5]})\n    assert selector(df) == [\"city\"]\n\n    # Test that make_column_selector can select columns based on excluded dtype\n    selector = make_column_selector(dtype_exclude=np.number)\n    df = pd.DataFrame({\"city\": [\"London\", \"London\", \"Paris\", \"Sallisaw\"],\n                       \"rating\": [5, 3, 4, 5]})\n    assert selector(df) == [\"city\"]\n\n    # Test that make_column_selector raises an error when used with non-pandas data\n    selector = make_column_selector()\n    X = np.array([[1, 2], [3, 4]])\n    with pytest.raises(ValueError):\n        selector(X)\n"], "sample_905": ["def test_signature_from_str():\n    signature_str = \"(a: int, b: str) -> None\"\n    sig = inspect.signature_from_str(signature_str)\n    assert len(sig.parameters) == 2\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.return_annotation == type(None)\n"], "sample_554": ["def test_text_get_window_extent():\n    fig, ax = plt.subplots()\n    text = Text(0.5, 0.5, \"Test\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n    ax.add_artist(text)\n    extent = text.get_window_extent()\n    assert_almost_equal(extent.x0, 0.5 - 0.5 * text.get_window_extent().width)\n    assert_almost_equal(extent.y0, 0.5 - 0.5 * text.get_window_extent().height)\n    assert_almost_equal(extent.x1, 0.5 + 0.5 * text.get_window_extent().width)\n    assert_almost_equal(extent.y1, 0.5 + 0.5 * text.get_window_extent().height)\n"], "sample_540": ["def test_html_writer(tmpdir):\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3])\n    writer = animation.HTMLWriter()\n    ani = animation.FuncAnimation(fig, lambda i: None, frames=5, writer=writer)\n    ani.save(str(tmpdir / 'test.html'))\n    assert (tmpdir / 'test.html').exists()\n    assert (tmpdir / 'test_frames').exists()\n    assert len(list((tmpdir / 'test_frames').glob('*.png'))) == 5\n\n"], "sample_625": ["def test_broadcast_compat_data():\n    dims = (\"x\", \"y\")\n    data = np.arange(6).reshape(2, 3)\n    var = xr.Variable(dims, data)\n\n    # test no change\n    broadcast_dims = ()\n    core_dims = dims\n    result = broadcast_compat_data(var, broadcast_dims, core_dims)\n    assert_identical(result, data)\n\n    # test transpose\n    broadcast_dims = (\"z\",)\n    core_dims = dims\n    result = broadcast_compat_data(var, broadcast_dims, core_dims)\n    assert_identical(result, data)\n\n    # test add new axes\n    broadcast_dims = (\"z\", \"w\")\n    core_dims = dims\n    result = broadcast_compat_data(var, broadcast_dims, core_dims)\n    assert_identical(result, data[np.newaxis, np.newaxis, :, :])\n\n    # test reorder\n    broadcast_dims = (\"z\",)\n    core_dims = (\"y\", \"x\")\n    result = broadcast_compat_data(var, broadcast_dims, core_dims)\n    assert_identical(result, data.T)\n\n    # test reorder and add new axes\n    broadcast_dims = (\"z\", \"w\")\n    core_dims = (\"y\", \"x\")\n    result = broadcast_compat_data(var, broadcast_dims, core_dims)\n    assert_identical(result, data.T[np.newaxis, np.newaxis, :, :])\n"], "sample_286": ["def test_model_instance_creation_with_deferred_fields(self):\n    article = Article.objects.defer('headline').get(id=1)\n    self.assertEqual(article.headline, 'This is a test article')\n    article.refresh_from_db(fields=['headline'])\n    self.assertEqual(article.headline, 'This is a test article')\n    article.refresh_from_db(fields=['headline', 'pub_date'])\n    self.assertEqual(article.pub_date, datetime(2005, 7, 27, 14, 30))\n"], "sample_1040": ["def test_mathml_content_printer():\n    assert mp.doprint(sin(x)) == '<apply><sin/><ci>x</ci></apply>'\n    assert mp.doprint(cos(x)) == '<apply><cos/><ci>x</ci></apply>'\n    assert mp.doprint(tan(x)) == '<apply><tan/><ci>x</ci></apply>'\n    assert mp.doprint(asin(x)) == '<apply><arcsin/><ci>x</ci></apply>'\n    assert mp.doprint(acos(x)) == '<apply><arccos/><ci>x</ci></apply>'\n    assert mp.doprint(atan(x)) == '<apply><arctan/><ci>x</ci></apply>'\n    assert mp.doprint(sinh(x)) == '<apply><sinh/><ci>x</ci></apply>'\n    assert mp.doprint(cosh(x)) == '<apply><cosh/><ci>x</ci></apply>'\n    assert mp.doprint(tanh(x)) == '<apply><tanh/><ci>x</ci></apply>'\n    assert mp.doprint(asinh(x)) == '<apply><arcsinh/><ci>x</ci></apply>'\n    assert mp.doprint(acosh(x)) == '<apply><arccosh/><ci>x</ci></apply>'\n    assert mp.doprint(atanh(x)) == '<apply><arctanh/><ci>x</ci></apply>'\n    assert mp.doprint(E) == '<exponentiale/>'\n    assert mp.doprint(I) == '<imaginaryi/>'\n    assert mp.doprint(oo) == '<infinity/>'\n    assert mp.doprint(-oo) == '<apply><minus/><infinity/></apply>'\n    assert mp.doprint(pi) == '<pi/>'\n    assert mp.doprint(GoldenRatio) == '<cn>&#x3c6;</cn>'\n    assert mp.doprint(EulerGamma) == '<eulergamma/>'\n    assert mp.doprint(Integer(1)) == '<cn>1</cn>'\n    assert mp.doprint(Rational(1, 2)) == '<apply><divide/><cn>1</cn><cn>2</cn></apply>'\n    assert mp.doprint(Float(1.5)) == '<cn>1.5</cn>'\n    assert mp.doprint(Matrix([[1, 2], [3, 4]])) =="], "sample_981": ["def test_cycle():\n    c = Cycle(1, 2, 3)\n    assert c.list() == [0, 2, 3, 1]\n    assert c.list(5) == [0, 2, 3, 1, 4]\n    assert c.list(-1) == [0, 2, 3, 1]\n    c = Cycle(1, 2, 3, 4)\n    assert c.list() == [0, 2, 3, 4, 1]\n    assert c.list(5) == [0, 2, 3, 4, 1]\n    assert c.list(-1) == [0, 2, 3, 4, 1]\n    c = Cycle(1, 2, 3, 4, 5)\n    assert c.list() == [0, 2, 3, 4, 5, 1]\n    assert c.list(6) == [0, 2, 3, 4, 5, 1]\n    assert c.list(-1) == [0, 2, 3, 4, 5, 1]\n    c = Cycle(1, 2, 3, 4, 5, 6)\n    assert c.list() == [0, 2, 3, 4, 5, 6, 1]\n    assert c.list(7) == [0, 2, 3, 4, 5, 6, 1]\n    assert c.list(-1) == [0, 2, 3, 4, 5, 6, 1]\n    c = Cycle(1, 2, 3, 4, 5, 6, 7)\n    assert c.list() == [0, 2, 3, 4, 5, 6, 7, 1]\n    assert c.list(8) == [0, 2, 3, 4, 5, 6, 7, 1]\n    assert c.list(-1) == [0, 2, 3, 4, 5, 6, 7, 1]\n    c = Cycle(1, 2, 3, 4, 5, 6, 7, 8"], "sample_601": ["    def test_timedelta_accessor(self, field):\n        timedelta_data = pd.timedelta_range(start=\"1 day\", freq=\"6H\", periods=20)\n        timedelta_da = xr.DataArray(timedelta_data, dims=(\"time\"))\n        expected = getattr(timedelta_data, field)\n        actual = getattr(timedelta_da.dt, field)\n        assert_array_equal(actual, expected)\n"], "sample_829": ["def test_incremental_pca_partial_fit():\n    # Test partial_fit with multiple calls\n    X = iris.data\n    ipca = IncrementalPCA(n_components=2, batch_size=10)\n    ipca.partial_fit(X[:10])\n    ipca.partial_fit(X[10:20])\n    ipca.partial_fit(X[20:])\n\n    pca = PCA(n_components=2)\n    pca.fit(X)\n\n    assert_array_almost_equal(ipca.components_, pca.components_, decimal=3)\n    assert_array_almost_equal(ipca.explained_variance_ratio_,\n                              pca.explained_variance_ratio_, decimal=3)\n\n    # Test partial_fit with different batch sizes\n    ipca = IncrementalPCA(n_components=2, batch_size=5)\n    ipca.partial_fit(X[:5])\n    ipca.partial_fit(X[5:10])\n    ipca.partial_fit(X[10:15])\n    ipca.partial_fit(X[15:])\n\n    assert_array_almost_equal(ipca.components_, pca.components_, decimal=3)\n    assert_array_almost_equal(ipca.explained_variance_ratio_,\n                              pca.explained_variance_ratio_, decimal=3)\n\n    # Test partial_fit with sparse input\n    X_sparse = sparse.csr_matrix(X)\n    ipca = IncrementalPCA(n_components=2, batch_size=10)\n    ipca.partial_fit(X_sparse[:10].toarray())\n    ipca.partial_fit(X_sparse[10:20].toarray())\n    ipca.partial_fit(X_sparse[20:].toarray())\n\n    assert_array_almost_equal(ipca.components_, pca.components_, decimal=3)\n    assert_array_almost_equal(ipca.explained_variance_ratio_,\n                              pca.explained_variance_ratio_, decimal=3)\n\n    # Test partial_fit with check_input=False\n    ipca = IncrementalPCA(n_components=2, batch_size=10)\n    ipca.partial_fit(X[:10], check_input=False)\n    ipca.partial_fit(X[10:20], check_input=False)\n    ipca.partial_fit(X[20:], check_input=False)\n\n    assert_array_almost_equal(ipca.components_, pca.components_, decimal=3)\n    assert_array_almost_equal(ipca.explained_variance_ratio_,\n                              pca.explained_variance_ratio_, decimal=3)\n\n    # Test partial_fit with n_components=None\n    ipca = IncrementalPCA(batch_size=10)\n    ipca.partial_fit(X[:10])\n    ipca.partial_fit(X[10:20])\n    ipca.partial_fit"], "sample_1044": ["def test_isqrt():\n    assert Pow.isqrt(16) == 4\n    assert Pow.isqrt(26) == 5\n    assert Pow.isqrt(17984395633462800708566937239551) == 134480247\n    assert Pow.isqrt(17984395633462800708566937239552) == 134480247\n    assert Pow.isqrt(17984395633462800708566937239553) == 134480248\n"], "sample_1098": ["def test_hyper():\n    # Test hypergeometric function\n    assert hyper([], [], x).doit() == exp(x)\n    assert hyper([], [S(1)/2], -x**2/4).doit() == cos(x)\n    assert x*hyper([S(1)/2, S(1)/2], [S(3)/2], x**2).doit() == asin(x)\n    assert hyper([-a], [], x).doit() == (1 - x)**a\n\n    # Test convergence\n    assert hyper((1, 2), (3,), z).radius_of_convergence == 1\n    assert hyper((1, 2, 3), (4,), z).radius_of_convergence == 0\n    assert hyper((1, 2), (3, 4), z).radius_of_convergence == oo\n\n    # Test derivative\n    assert hyper((1, 2), (3,), z).fdiff() == (2*z/3)*hyper((2, 3), (4,), z)\n\n    # Test series expansion\n    s = hyper((1, 2), (3,), x).series(x, 0, 4)\n    assert s == 1 + x + 5*x**2/6 + 61*x**3/180 + O(x**4)\n\n    # Test limit\n    assert limit(hyper((1, 2), (3,), x), x, 0) == 1\n\n    # Test numerical evaluation\n    tn(hyper((1, 2), (3,), x), x, 1)\n\n    # Test derivative numerically\n    td(hyper((1, 2), (3,), x), x, 1)\n"], "sample_925": ["def test_mock_object():\n    mock_obj = _MockObject()\n    assert mock_obj.__display_name__ == '_MockObject'\n    assert hasattr(mock_obj, '__sphinx_mock__')\n    assert mock_obj.__sphinx_mock__\n\n    # Test __len__\n    assert len(mock_obj) == 0\n\n    # Test __contains__\n    assert 'test' not in mock_obj\n\n    # Test __iter__\n    assert list(mock_obj) == []\n\n    # Test __mro_entries__\n    assert mock_obj.__mro_entries__(()) == (_MockObject,)\n\n    # Test __getitem__\n    mock_item = mock_obj['test']\n    assert isinstance(mock_item, _MockObject)\n    assert mock_item.__display_name__ == '_MockObject.test'\n\n    # Test __getattr__\n    mock_attr = mock_obj.test\n    assert isinstance(mock_attr, _MockObject)\n    assert mock_attr.__display_name__ == '_MockObject.test'\n\n    # Test __call__\n        pass\n\n    result = mock_obj(test_func)\n    assert result is test_func\n\n    result = mock_obj()\n    assert isinstance(result, _MockObject)\n    assert result.__display_name__ == '_MockObject'\n\n    # Test __repr__\n    assert repr(mock_obj) == '_MockObject'\n\n"], "sample_722": ["def test_kmeans_elkan():\n    # Test that the Elkan algorithm is faster than the full algorithm\n    # for dense data\n    X, _ = make_blobs(n_samples=1000, centers=10, random_state=42)\n    kmeans_elkan = KMeans(n_clusters=10, algorithm='elkan', random_state=42)\n    kmeans_full = KMeans(n_clusters=10, algorithm='full', random_state=42)\n    start_time = time.time()\n    kmeans_elkan.fit(X)\n    elkan_time = time.time() - start_time\n    start_time = time.time()\n    kmeans_full.fit(X)\n    full_time = time.time() - start_time\n    assert_less(elkan_time, full_time)\n\n    # Test that the Elkan algorithm raises an error for sparse data\n    X_csr = sp.csr_matrix(X)\n    kmeans_elkan = KMeans(n_clusters=10, algorithm='elkan', random_state=42)\n    assert_raises(TypeError, kmeans_elkan.fit, X_csr)\n"], "sample_848": ["def test_multioutput_regressor_parallel():\n    # Test parallel fitting of MultiOutputRegressor\n    X, y = make_regression(n_samples=10, n_features=5, n_informative=3,\n                            n_targets=3, random_state=0)\n    regr_multirf = MultiOutputRegressor(Ridge(), n_jobs=cpu_count())\n    regr_multirf.fit(X, y)\n    y_pred = regr_multirf.predict(X)\n    assert y_pred.shape == (10, 3)\n\n    # Test parallel prediction of MultiOutputRegressor\n    regr_multirf = MultiOutputRegressor(Ridge(), n_jobs=cpu_count())\n    regr_multirf.fit(X, y)\n    y_pred = regr_multirf.predict(X)\n    assert y_pred.shape == (10, 3)\n\n    # Test parallel fitting and prediction of MultiOutputRegressor\n    regr_multirf = MultiOutputRegressor(Ridge(), n_jobs=cpu_count())\n    regr_multirf.fit(X, y)\n    y_pred = regr_multirf.predict(X)\n    assert y_pred.shape == (10, 3)\n\n    # Test parallel fitting of MultiOutputClassifier\n    X, y = make_classification(n_samples=10, n_features=5, n_informative=3,\n                               n_classes=3, random_state=0)\n    clf_multirf = MultiOutputClassifier(LogisticRegression(), n_jobs=cpu_count())\n    clf_multirf.fit(X, y)\n    y_pred = clf_multirf.predict(X)\n    assert y_pred.shape == (10, 3)\n\n    # Test parallel prediction of MultiOutputClassifier\n    clf_multirf = MultiOutputClassifier(LogisticRegression(), n_jobs=cpu_count())\n    clf_multirf.fit(X, y)\n    y_pred = clf_multirf.predict(X)\n    assert y_pred.shape == (10, 3)\n\n    # Test parallel fitting and prediction of MultiOutputClassifier\n    clf_multirf = MultiOutputClassifier(LogisticRegression(), n_jobs=cpu_count())\n    clf_multirf.fit(X, y)\n    y_pred = clf_multirf.predict(X)\n    assert y_pred.shape == (10, 3)\n"], "sample_900": ["def test_mlp_regression():\n    # Test that the MLPRegressor can handle sparse input data\n    X_sparse = csr_matrix(Xboston)\n    mlp = MLPRegressor(hidden_layer_sizes=(10,), max_iter=1000)\n    mlp.fit(X_sparse, yboston)\n    assert_array_equal(mlp.predict(X_sparse).shape, (200,))\n\n    # Test that the MLPRegressor can handle sparse input data with multiple outputs\n    X_sparse_multi, y_sparse_multi = make_regression(n_samples=200, n_features=10, n_informative=5, n_targets=3, noise=0.1, random_state=42)\n    X_sparse_multi = csr_matrix(X_sparse_multi)\n    mlp = MLPRegressor(hidden_layer_sizes=(10,), max_iter=1000)\n    mlp.fit(X_sparse_multi, y_sparse_multi)\n    assert_array_equal(mlp.predict(X_sparse_multi).shape, (200, 3))\n\n    # Test that the MLPRegressor can handle sparse input data with multiple outputs and different activation functions\n    for activation in ACTIVATION_TYPES:\n        mlp = MLPRegressor(hidden_layer_sizes=(10,), activation=activation, max_iter=1000)\n        mlp.fit(X_sparse_multi, y_sparse_multi)\n        assert_array_equal(mlp.predict(X_sparse_multi).shape, (200, 3))\n\n    # Test that the MLPRegressor can handle sparse input data with multiple outputs and different solvers\n    for solver in ['lbfgs', 'sgd', 'adam']:\n        mlp = MLPRegressor(hidden_layer_sizes=(10,), solver=solver, max_iter=1000)\n        mlp.fit(X_sparse_multi, y_sparse_multi)\n        assert_array_equal(mlp.predict(X_sparse_multi).shape, (200, 3))\n\n    # Test that the MLPRegressor can handle sparse input data with multiple outputs and different batch sizes\n    for batch_size in [10, 50, 100]:\n        mlp = MLPRegressor(hidden_layer_sizes=(10,), batch_size=batch_size, max_iter=1000)\n        mlp.fit(X_sparse_multi, y_sparse_multi)\n        assert_array_equal(mlp.predict(X_sparse_multi).shape, (200, 3))\n\n    # Test that the MLPRegressor can handle sparse input data with multiple outputs and different learning rates\n    for learning_rate in ['constant', 'invscaling', 'adaptive']:\n        mlp = MLPRegressor(hidden_layer_sizes=(10,), learning_rate=learning_rate, max_iter="], "sample_988": ["def test_comp():\n    assert comp(1, 1) == True\n    assert comp(1, 2) == True\n    assert comp(1, 1.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_219": ["    def test_expression_wrapper(self):\n        expression = ExpressionWrapper(F('num_employees'), output_field=IntegerField())\n        self.assertIsInstance(expression, Expression)\n        self.assertIsInstance(expression, Combinable)\n        self.assertEqual(expression.output_field.get_internal_type(), 'IntegerField')\n        self.assertEqual(expression.expression, F('num_employees'))\n\n        with self.assertRaises(FieldError):\n            ExpressionWrapper(F('num_employees'), output_field=None)\n\n        with self.assertRaises(ValueError):\n            ExpressionWrapper('num_employees', output_field=IntegerField())\n"], "sample_1006": ["def test_binomial():\n    n, k = symbols('n k', integer=True)\n    assert binomial(n, k).fdiff(1) == binomial(n, k)*(polygamma(0, n + 1) - polygamma(0, n - k + 1))\n    assert binomial(n, k).fdiff(2) == binomial(n, k)*(polygamma(0, n - k + 1) - polygamma(0, k + 1))\n\n    assert binomial(15, 8) == 6435\n    assert binomial(n, -1) == 0\n    assert binomial(Rational(5, 4), 3) == -5/128\n    assert binomial(Rational(-5, 4), 3) == -195/128\n\n    assert binomial(n, 3).expand(func=True) == n**3/6 - n**2/2 + n/3\n    assert expand_func(binomial(n, 3)) == n*(n - 2)*(n - 1)/6\n\n    assert binomial(n, 3).rewrite(factorial) == factorial(n)/(factorial(3)*factorial(n - 3))\n    assert binomial(n, 3).rewrite(gamma) == gamma(n + 1)/(gamma(3 + 1)*gamma(n - 3 + 1))\n    assert binomial(n, 3).rewrite(tractable) == gamma(n + 1)/(gamma(3 + 1)*gamma(n - 3 + 1))\n    assert binomial(n, 3).rewrite(FallingFactorial) == ff(n, 3)/factorial(3)\n\n    assert binomial(n, 3).is_integer == True\n    assert binomial(n, 3).is_nonnegative == True\n"], "sample_608": ["def test_format_array_flat():\n    array = np.arange(10)\n    assert formatting.format_array_flat(array, 20) == \"0 1 2 3 4 5 6 7 8 9\"\n    assert formatting.format_array_flat(array, 10) == \"0 9 1 8 2 7 3 6 4 5\"\n    assert formatting.format_array_flat(array, 5) == \"0 9 1 8\"\n    assert formatting.format_array_flat(array, 3) == \"0 9\"\n    assert formatting.format_array_flat(array, 2) == \"0...\"\n"], "sample_950": ["def test_parse_annotation():\n    env = Mock(spec=['config'])\n    env.config.python_use_unqualified_type_names = False\n\n    # Test simple type\n    annotation = 'int'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'int'\n\n    # Test type with module\n    annotation = 'module.Type'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'module.Type'\n\n    # Test type with multiple modules\n    annotation = 'module1.module2.Type'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'module1.module2.Type'\n\n    # Test type with generics\n    annotation = 'List[int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 3\n    assert isinstance(result[0], nodes.Text)\n    assert result[0].astext() == 'List'\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == '['\n    assert isinstance(result[2], pending_xref)\n    assert result[2].attributes['reftarget'] == 'int'\n\n    # Test type with multiple generics\n    annotation = 'Dict[str, int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 5\n    assert isinstance(result[0], nodes.Text)\n    assert result[0].astext() == 'Dict'\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == '['\n    assert isinstance(result[2], pending_xref)\n    assert result[2].attributes['reftarget'] == 'str'\n    assert isinstance(result[3], desc_sig_punctuation)\n    assert result[3].astext() == ', '\n    assert isinstance(result[4], pending_xref)\n    assert result[4].attributes['reftarget'] == 'int'\n\n    # Test type with nested generics\n    annotation = 'List[Dict[str, int]]'\n    result = _parse_annotation(annotation, env"], "sample_165": ["    def test_model_form_save(self):\n        class TestModelForm(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = ('name',)\n\n        form = TestModelForm({'name': 'Test'})\n        self.assertTrue(form.is_valid())\n        instance = form.save()\n        self.assertEqual(instance.name, 'Test')\n"], "sample_289": ["    def test_init(self):\n        ordered_set = OrderedSet([1, 2, 3, 2, 1])\n        self.assertEqual(list(ordered_set), [1, 2, 3])\n"], "sample_773": ["def test_logistic_regression_path():\n    # Test logistic_regression_path with different solvers\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5,\n                               n_redundant=0, n_classes=2, random_state=0)\n    Cs = [1, 10]\n    for solver in ['lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga']:\n        coefs, Cs, n_iter = logistic_regression_path(X, y, Cs=Cs, solver=solver)\n        assert len(coefs) == len(Cs)\n        assert len(n_iter) == len(Cs)\n        assert coefs.shape[1] == X.shape[1] + 1  # +1 for intercept\n\n    # Test logistic_regression_path with different penalties\n    for penalty in ['l1', 'l2', 'elasticnet']:\n        coefs, Cs, n_iter = logistic_regression_path(X, y, Cs=Cs, solver='saga',\n                                                     penalty=penalty)\n        assert len(coefs) == len(Cs)\n        assert len(n_iter) == len(Cs)\n        assert coefs.shape[1] == X.shape[1] + 1  # +1 for intercept\n\n    # Test logistic_regression_path with different multi_class options\n    for multi_class in ['ovr', 'multinomial']:\n        coefs, Cs, n_iter = logistic_regression_path(X, y, Cs=Cs, solver='lbfgs',\n                                                     multi_class=multi_class)\n        assert len(coefs) == len(Cs)\n        assert len(n_iter) == len(Cs)\n        if multi_class == 'ovr':\n            assert coefs.shape[1] == X.shape[1] + 1  # +1 for intercept\n        else:\n            assert coefs.shape[1] == X.shape[1] + 1  # +1 for intercept\n            assert coefs.shape[0] == 2  # 2 classes\n\n    # Test logistic_regression_path with warm_start\n    coefs, Cs, n_iter = logistic_regression_path(X, y, Cs=Cs, solver='lbfgs',\n                                                 warm_start=True)\n    assert len(coefs) == len(Cs)\n    assert len(n_iter) == len(Cs)\n    assert coefs.shape[1] == X.shape[1] + 1  # +1 for intercept\n\n    #"], "sample_274": ["    def test_model_form_save(self):\n        from ..models import Author\n        data = {\n            'name': 'John Doe',\n            'email': 'john@example.com',\n        }\n        form = AuthorForm(data)\n        self.assertTrue(form.is_valid())\n        author = form.save()\n        self.assertEqual(author.name, 'John Doe')\n        self.assertEqual(author.email, 'john@example.com')\n"], "sample_830": ["def test_get_sys_info():\n    sys_info = _get_sys_info()\n    assert isinstance(sys_info, dict)\n    assert 'python' in sys_info\n    assert 'executable' in sys_info\n    assert 'machine' in sys_info\n\n"], "sample_880": ["def test_unique_labels():\n    # Test that unique_labels raises an error when given a mix of label types\n    with pytest.raises(ValueError):\n        unique_labels([1, 2, 3], [\"a\", \"b\", \"c\"])\n\n    # Test that unique_labels raises an error when given a mix of label indicator\n    # matrices of different sizes\n    with pytest.raises(ValueError):\n        unique_labels(np.array([[0, 1], [1, 0]]), np.array([[0, 1, 0], [1, 0, 1]]))\n\n    # Test that unique_labels raises an error when given a mix of string and\n    # integer labels\n    with pytest.raises(ValueError):\n        unique_labels([1, 2, 3], [\"a\", \"b\", \"c\"])\n\n    # Test that unique_labels returns the correct unique labels for a single\n    # array-like input\n    assert_array_equal(unique_labels([1, 2, 2, 3, 3, 3]), np.array([1, 2, 3]))\n\n    # Test that unique_labels returns the correct unique labels for multiple\n    # array-like inputs\n    assert_array_equal(unique_labels([1, 2, 2], [3, 3, 3]), np.array([1, 2, 3]))\n\n    # Test that unique_labels returns the correct unique labels for a sparse\n    # matrix input\n    assert_array_equal(unique_labels(csr_matrix(np.array([[0, 1], [1, 0]]))), np.array([0, 1]))\n\n    # Test that unique_labels returns the correct unique labels for a mix of\n    # dense and sparse matrix inputs\n    assert_array_equal(unique_labels(np.array([1, 2, 2]), csr_matrix(np.array([[0, 1], [1, 0]]))), np.array([0, 1, 2]))\n"], "sample_932": ["def test_template_introduction():\n    input = \"template <typename T> concept C<T> { }\"\n    idDict = {2: \"I0XSt3CIXT_EE\", 3: \"I0XSt3CIXT_EE\", 4: \"I0XSt3CIXT_EE\"}\n    output = \"template <typename T> concept C<T> { }\"\n    check(\"concept\", input, idDict, output)\n"], "sample_652": ["def test_pyobj_property():\n    class TestClass:\n            self.module = \"test_module\"\n            self.cls = \"test_class\"\n            self.instance = \"test_instance\"\n\n    test_obj = PyobjContext()\n    test_obj.module = property(lambda self: \"test_module\")\n    test_obj.cls = property(lambda self: \"test_class\")\n    test_obj.instance = property(lambda self: \"test_instance\")\n\n    assert test_obj.module == \"test_module\"\n    assert test_obj.cls == \"test_class\"\n    assert test_obj.instance == \"test_instance\"\n\n    test_obj = PyobjContext()\n    test_obj._obj = TestClass()\n\n    assert test_obj.module == \"test_module\"\n    assert test_obj.cls == \"test_class\"\n    assert test_obj.instance == \"test_instance\"\n"], "sample_719": ["def test_tfidfvectorizer():\n    # Test that TfidfVectorizer works with a custom preprocessor\n    v = TfidfVectorizer(preprocessor=uppercase)\n    X = v.fit_transform(ALL_FOOD_DOCS)\n    assert_equal(X.shape, (len(ALL_FOOD_DOCS), len(set(uppercase(doc) for doc in ALL_FOOD_DOCS))))\n\n    # Test that TfidfVectorizer works with a custom tokenizer\n    v = TfidfVectorizer(tokenizer=split_tokenize)\n    X = v.fit_transform(ALL_FOOD_DOCS)\n    assert_equal(X.shape, (len(ALL_FOOD_DOCS), len(set(split_tokenize(doc) for doc in ALL_FOOD_DOCS))))\n\n    # Test that TfidfVectorizer works with a custom analyzer\n    v = TfidfVectorizer(analyzer=lazy_analyze)\n    X = v.fit_transform(ALL_FOOD_DOCS)\n    assert_equal(X.shape, (len(ALL_FOOD_DOCS), 1))\n\n    # Test that TfidfVectorizer works with a custom vocabulary\n    vocab = set(uppercase(doc) for doc in ALL_FOOD_DOCS)\n    v = TfidfVectorizer(vocabulary=vocab, preprocessor=uppercase)\n    X = v.fit_transform(ALL_FOOD_DOCS)\n    assert_equal(X.shape, (len(ALL_FOOD_DOCS), len(vocab)))\n\n    # Test that TfidfVectorizer works with a custom stop_words\n    stop_words = set(['the'])\n    v = TfidfVectorizer(stop_words=stop_words)\n    X = v.fit_transform(ALL_FOOD_DOCS)\n    assert_equal(X.shape, (len(ALL_FOOD_DOCS), len(set(doc for doc in ALL_FOOD_DOCS if doc not in stop_words))))\n\n    # Test that TfidfVectorizer works with a custom ngram_range\n    v = TfidfVectorizer(ngram_range=(2, 2))\n    X = v.fit_transform(ALL_FOOD_DOCS)\n    assert_equal(X.shape, (len(ALL_FOOD_DOCS), len(set(doc.split() for doc in ALL_FOOD_DOCS))))\n\n    # Test that TfidfVectorizer works with a custom max_df\n    v = TfidfVectorizer(max_df=0.5)\n    X = v.fit_transform(ALL_FOOD_DOCS)\n    assert_equal(X.shape, (len(ALL_FOOD_DOCS), len(set(doc for doc in ALL_FOOD_DOCS if doc.count(' ') < 0.5 * len("], "sample_164": ["def test_callback_filter(self):\n        return record.levelno == logging.INFO\n\n    filter = CallbackFilter(callback)\n    record = logging.LogRecord('test', logging.INFO, 'path', 1, 'message', None, None)\n    self.assertTrue(filter.filter(record))\n\n    record = logging.LogRecord('test', logging.ERROR, 'path', 1, 'message', None, None)\n    self.assertFalse(filter.filter(record))\n"], "sample_918": ["def test_parse_annotation():\n    # Test parsing of type annotations\n    annotation = \"List[int]\"\n    result = _parse_annotation(annotation)\n    assert len(result) == 3\n    assert isinstance(result[0], desc_sig_name)\n    assert result[0].astext() == \"List\"\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == \"[\"\n    assert isinstance(result[2], desc_sig_name)\n    assert result[2].astext() == \"int\"\n    assert isinstance(result[2][0], pending_xref)\n    assert result[2][0].astext() == \"int\"\n\n    # Test parsing of nested type annotations\n    annotation = \"List[List[int]]\"\n    result = _parse_annotation(annotation)\n    assert len(result) == 5\n    assert isinstance(result[0], desc_sig_name)\n    assert result[0].astext() == \"List\"\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == \"[\"\n    assert isinstance(result[2], desc_sig_name)\n    assert result[2].astext() == \"List\"\n    assert isinstance(result[3], desc_sig_punctuation)\n    assert result[3].astext() == \"[\"\n    assert isinstance(result[4], desc_sig_name)\n    assert result[4].astext() == \"int\"\n    assert isinstance(result[4][0], pending_xref)\n    assert result[4][0].astext() == \"int\"\n\n    # Test parsing of type annotations with multiple arguments\n    annotation = \"Dict[str, int]\"\n    result = _parse_annotation(annotation)\n    assert len(result) == 5\n    assert isinstance(result[0], desc_sig_name)\n    assert result[0].astext() == \"Dict\"\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == \"[\"\n    assert isinstance(result[2], desc_sig_name)\n    assert result[2].astext() == \"str\"\n    assert isinstance(result[2][0], pending_xref)\n    assert result[2][0].astext() == \"str\"\n    assert isinstance(result[3], desc_sig_punctuation)\n    assert result[3].astext() == \", \"\n    assert isinstance(result[4], desc_sig_name)\n    assert result[4].astext() == \"int\"\n    assert isinstance(result"], "sample_407": ["    def test_model_base_subclass_exception(self):\n        class MyModel(models.Model):\n            class Meta:\n                app_label = \"myapp\"\n\n        exception = MyModel.DoesNotExist\n        self.assertEqual(exception.__module__, \"myapp.models\")\n        self.assertEqual(exception.__qualname__, \"MyModel.DoesNotExist\")\n"], "sample_461": ["def test_urlfield_assume_scheme_deprecation_warning(self):\n    with self.assertWarnsMessage(\n        RemovedInDjango60Warning,\n        \"The default scheme will be changed from 'http' to 'https' in Django 6.0. Pass the forms.URLField.assume_scheme argument to silence this warning.\",\n    ):\n        URLField()\n"], "sample_760": ["def test_make_scorer():\n    # Test that make_scorer returns a scorer object\n    scorer = make_scorer(f1_score)\n    assert isinstance(scorer, _PredictScorer)\n\n    # Test that the scorer object can be called\n    X, y = make_classification(n_samples=10, n_features=5, random_state=0)\n    clf = DecisionTreeClassifier(random_state=0)\n    clf.fit(X, y)\n    score = scorer(clf, X, y)\n    assert isinstance(score, numbers.Number)\n\n    # Test that make_scorer raises an error if score_func is not callable\n    with assert_raises(TypeError):\n        make_scorer(\"not callable\")\n\n    # Test that make_scorer raises an error if greater_is_better is not a bool\n    with assert_raises(TypeError):\n        make_scorer(f1_score, greater_is_better=\"not a bool\")\n\n    # Test that make_scorer raises an error if needs_proba and needs_threshold are both True\n    with assert_raises(ValueError):\n        make_scorer(f1_score, needs_proba=True, needs_threshold=True)\n\n    # Test that make_scorer raises an error if needs_proba is True and score_func does not accept y_pred\n    with assert_raises(ValueError):\n        make_scorer(r2_score, needs_proba=True)\n\n    # Test that make_scorer raises an error if needs_threshold is True and score_func does not accept y_pred\n    with assert_raises(ValueError):\n        make_scorer(r2_score, needs_threshold=True)\n"], "sample_345": ["    def test_tick(self):\n        reloader = autoreload.StatReloader()\n        ticker = reloader.tick()\n        next(ticker)\n        self.assertTrue(reloader.should_stop)\n"], "sample_354": ["    def test_create_superuser_with_password_validation_error(self):\n        with mock.patch.object(sys, 'stdin', MockTTY()):\n            call_command('createsuperuser', interactive=True, verbosity=0)\n        self.assertEqual(CustomUser.objects.count(), 1)\n        self.assertEqual(CustomUser.objects.first().username, 'alice')\n"], "sample_966": ["def test_parse_annotation():\n    env = Mock(spec=['config'])\n    env.config.python_use_unqualified_type_names = False\n\n    # Test simple type\n    annotation = 'int'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], addnodes.pending_xref)\n    assert result[0].attributes['reftarget'] == 'int'\n\n    # Test type with module\n    annotation = 'module.Type'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], addnodes.pending_xref)\n    assert result[0].attributes['reftarget'] == 'module.Type'\n\n    # Test type with multiple modules\n    annotation = 'module1.module2.Type'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], addnodes.pending_xref)\n    assert result[0].attributes['reftarget'] == 'module1.module2.Type'\n\n    # Test type with generics\n    annotation = 'List[int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 3\n    assert isinstance(result[0], addnodes.desc_sig_punctuation)\n    assert result[0].astext() == '['\n    assert isinstance(result[1], addnodes.pending_xref)\n    assert result[1].attributes['reftarget'] == 'int'\n    assert isinstance(result[2], addnodes.desc_sig_punctuation)\n    assert result[2].astext() == ']'\n\n    # Test type with multiple generics\n    annotation = 'Dict[str, int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 5\n    assert isinstance(result[0], addnodes.desc_sig_punctuation)\n    assert result[0].astext() == '['\n    assert isinstance(result[1], addnodes.pending_xref)\n    assert result[1].attributes['reftarget'] == 'str'\n    assert isinstance(result[2], addnodes.desc_sig_punctuation)\n    assert result[2].astext() == ','\n    assert isinstance(result[3], addnodes.pending_xref)\n    assert result[3].attributes['reftarget'] == 'int'\n    assert isinstance(result[4], addnodes.desc_sig_punctuation)\n    assert result[4].astext() == ']'\n\n    # Test type with"], "sample_457": ["    def test_base_constraint_repr(self):\n        constraint = BaseConstraint(name='test_constraint')\n        self.assertEqual(repr(constraint), \"<BaseConstraint: name='test_constraint'>\")\n"], "sample_436": ["    def test_runserver_command(self):\n        self.write_settings(\"settings.py\")\n        call_command(\"runserver\", verbosity=0)\n"], "sample_499": ["def test_legend_handler_map():\n    # Test that the default handler map is not modified by the Legend class\n    default_handler_map = mlegend.Legend.get_default_handler_map()\n    original_handler_map = default_handler_map.copy()\n\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], label='Line')\n    legend = ax.legend(handler_map={mlines.Line2D: HandlerTuple()})\n\n    assert default_handler_map == original_handler_map\n\n    # Test that the custom handler map is used by the Legend class\n    custom_handler_map = {mlines.Line2D: HandlerTuple()}\n    legend = ax.legend(handler_map=custom_handler_map)\n    assert legend.get_legend_handler_map() == custom_handler_map\n\n    # Test that the custom handler map is not modified by the Legend class\n    original_custom_handler_map = custom_handler_map.copy()\n    legend = ax.legend(handler_map=custom_handler_map)\n    assert custom_handler_map == original_custom_handler_map\n\n    # Test that the default handler map is updated by the Legend class\n    mlegend.Legend.update_default_handler_map({mcollections.PathCollection: HandlerTuple()})\n    assert mlegend.Legend.get_default_handler_map() != original_handler_map\n\n    # Test that the default handler map is reset by the Legend class\n    mlegend.Legend.set_default_handler_map(original_handler_map)\n    assert mlegend.Legend.get_default_handler_map() == original_handler_map\n"], "sample_768": ["def test_leave_p_groups_out():\n    # Test LeavePGroupsOut with different values of p\n    for p in range(1, 5):\n        lpgo = LeavePGroupsOut(p)\n        groups = np.array([1, 1, 1, 2, 2, 3, 3, 3, 3])\n        X = np.arange(9)\n        y = np.arange(9)\n        train_test_indices = list(lpgo.split(X, y, groups))\n        assert len(train_test_indices) == comb(len(np.unique(groups)), p)\n        for train, test in train_test_indices:\n            assert len(train) + len(test) == len(X)\n            assert len(set(groups[test])) == p\n"], "sample_287": ["    def test_check_dependencies(self):\n        with self.settings(INSTALLED_APPS=[\n            'django.contrib.admin',\n            'django.contrib.contenttypes',\n            'django.contrib.messages',\n            'admin_checks',\n        ]):\n            errors = check_dependencies()\n            self.assertEqual(len(errors), 1)\n            self.assertEqual(errors[0].id, 'admin.E401')\n\n        with self.settings(INSTALLED_APPS=[\n            'django.contrib.admin',\n            'django.contrib.auth',\n            'django.contrib.contenttypes',\n            'admin_checks',\n        ]):\n            errors = check_dependencies()\n            self.assertEqual(len(errors), 1)\n            self.assertEqual(errors[0].id, 'admin.E406')\n\n        with self.settings(INSTALLED_APPS=[\n            'django.contrib.admin',\n            'django.contrib.auth',\n            'django.contrib.contenttypes',\n            'django.contrib.messages',\n            'admin_checks',\n        ], TEMPLATES=[\n            {\n                'BACKEND': 'django.template.backends.django.DjangoTemplates',\n                'DIRS': [],\n                'APP_DIRS': True,\n                'OPTIONS': {\n                    'context_processors': [\n                        'django.contrib.auth.context_processors.auth',\n                        'django.contrib.messages.context_processors.messages',\n                    ],\n                },\n            },\n        ]):\n            errors = check_dependencies()\n            self.assertEqual(len(errors), 0)\n\n        with self.settings(INSTALLED_APPS=[\n            'django.contrib.admin',\n            'django.contrib.auth',\n            'django.contrib.contenttypes',\n            'django.contrib.messages',\n            'admin_checks',\n        ], TEMPLATES=[\n            {\n                'BACKEND': 'django.template.backends.django.DjangoTemplates',\n                'DIRS': [],\n                'APP_DIRS': True,\n                'OPTIONS': {\n                    'context_processors': [\n                        'django.contrib.messages.context_processors.messages',\n                    ],\n                },\n            },\n        ], AUTHENTICATION_BACKENDS=[\n            'django.contrib.auth.backends.ModelBackend',\n        ]):\n            errors = check_dependencies()\n            self.assertEqual(len(errors), 1)\n            self.assertEqual(errors[0].id, 'admin.E402')\n\n        with self.settings(INSTALLED_APPS=[\n            'django.contrib.admin',\n            'django.contrib.auth',\n            'django.contrib.contenttypes',\n            'django.contrib.messages',\n            'admin_checks',\n        ], TEMPLATES=[\n            {\n                'BACKEND': 'django.template.backends.django.DjangoTemplates',\n                'DIRS': [],\n                'APP_DIRS': True,\n                'OPTIONS': {\n                    'context_processors': [\n                       "], "sample_237": ["    def test_check_user_model_required_fields_not_list(self):\n        class CustomUser(AbstractBaseUser):\n            USERNAME_FIELD = 'username'\n            REQUIRED_FIELDS = 'email'\n\n        with self.assertRaisesMessage(checks.Error, \"'REQUIRED_FIELDS' must be a list or tuple.\"):\n            check_user_model(app_configs=[apps.get_app_config('auth_tests')])\n"], "sample_548": ["def test_colorbar_extension_length():\n    \"\"\"\n    Test that colorbar extensions have the correct length for uniform and\n    proportional spacing.\n    \"\"\"\n    _colorbar_extension_length('uniform')\n    _colorbar_extension_length('proportional')\n\n"], "sample_241": ["def test_is_nullable(self):\n    query = Company.objects.all()\n    self.assertTrue(query.is_nullable(Company._meta.get_field('name')))\n    self.assertFalse(query.is_nullable(Company._meta.get_field('num_employees')))\n"], "sample_701": ["def test_check_ispytest_warning():\n    with warnings.catch_warnings(record=True) as w:\n        deprecated.check_ispytest(False)\n        assert len(w) == 1\n        assert w[0].category == PytestDeprecationWarning\n        assert str(w[0].message) == \"A private pytest class or function was used.\"\n"], "sample_920": ["    def test_google_docstring(self):\n        config = Config(napoleon_use_param=True, napoleon_use_rtype=True)\n        docstring = '''One line summary.\n        ...\n        ... Extended description.\n        ...\n        ... Args:\n        ...   arg1(int): Description of `arg1`\n        ...   arg2(str): Description of `arg2`\n        ... Returns:\n        ...   str: Description of return value.\n        ... '''\n        expected = cleandoc('''\n            One line summary.\n\n            Extended description.\n\n            :param arg1: Description of `arg1`\n            :type arg1: int\n            :param arg2: Description of `arg2`\n            :type arg2: str\n\n            :returns: Description of return value.\n            :rtype: str\n        ''')\n        self.assertEqual(str(GoogleDocstring(docstring, config)), expected)\n"], "sample_1208": ["def test_matrix_gamma_distribution():\n    alpha, beta = symbols('alpha beta', positive=True)\n    M = MatrixGamma('M', alpha, beta, [[2, 1], [1, 2]])\n    X = MatrixSymbol('X', 2, 2)\n    assert density(M)(X).doit() == exp(Trace(Matrix([\n        [-2/3,  1/3],\n        [ 1/3, -2/3]])*X)/beta)*Determinant(X)**(alpha - 3/2)/(3**alpha*sqrt(pi)*beta**(2*alpha)*gamma(alpha)*gamma(alpha - 1/2))\n    assert density(M)([[1, 0], [0, 1]]).doit() == exp(-4/(3*beta))/(3**alpha*sqrt(pi)*beta**(2*alpha)*gamma(alpha)*gamma(alpha - 1/2))\n"], "sample_372": ["    def test_urlresolver_match_with_kwargs(self):\n        resolver = get_resolver(urlconf_outer)\n        match = resolver.resolve('/test1/inner/42/37/')\n        self.assertEqual(match.func, views.empty_view)\n        self.assertEqual(match.args, ())\n        self.assertEqual(match.kwargs, {'arg1': '42', 'arg2': '37'})\n        self.assertEqual(match.url_name, 'urlobject-view')\n        self.assertEqual(match.app_names, ['testapp'])\n        self.assertEqual(match.namespaces, ['test-ns1'])\n        self.assertEqual(match.route, 'test1/inner/<arg1>/<arg2>/')\n        self.assertEqual(match.view_name, 'test-ns1:urlobject-view')\n"], "sample_105": ["def test_template_view_context(self):\n    class TestTemplateView(TemplateView):\n        extra_context = {'foo': 'bar'}\n\n            context = super().get_context_data(**kwargs)\n            context['baz'] = 'qux'\n            return context\n\n    view = TestTemplateView()\n    request = self.rf.get('/')\n    view.setup(request)\n    context = view.get_context_data()\n    self.assertEqual(context['foo'], 'bar')\n    self.assertEqual(context['baz'], 'qux')\n    self.assertEqual(context['view'], view)\n"], "sample_1073": ["def test_sqrt_depth():\n    assert sqrtdenest.sqrt_depth(1 + sqrt(2)*(1 + sqrt(3))) == 2\n    assert sqrtdenest.sqrt_depth(1 + sqrt(2)*sqrt(1 + sqrt(3))) == 2\n    assert sqrtdenest.sqrt_depth(sqrt(5 + 2 * sqrt(6))) == 2\n    assert sqrtdenest.sqrt_depth(sqrt(2) + sqrt(3)) == 1\n    assert sqrtdenest.sqrt_depth(sqrt(2)*sqrt(3)) == 1\n    assert sqrtdenest.sqrt_depth(sqrt(2) + sqrt(3) + sqrt(2)*sqrt(3)) == 1\n"], "sample_579": ["def test_heatmap_square_warning():\n    with pytest.warns(UserWarning, match=\"``square=True`` ignored in clustermap\"):\n        mat.clustermap(np.random.rand(10, 12), square=True)\n"], "sample_381": ["def test_altered_indexes(self):\n    before_state = self.make_project_state([\n        self.book_indexes,\n    ])\n    after_state = self.make_project_state([\n        self.book_unordered_indexes,\n    ])\n    changes = MigrationAutodetector(before_state, after_state)._detect_changes()\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"RemoveIndex\", \"AddIndex\"])\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"book_title_author_idx\")\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 1, fields=[\"title\", \"author\"], name=\"book_author_title_idx\")\n"], "sample_710": ["def test_is_skipped(monkeypatch: MonkeyPatch) -> None:\n    class TestClass:\n            pass\n\n    obj = TestClass()\n    assert not _is_skipped(obj)\n\n    monkeypatch.setattr(obj, \"__unittest_skip__\", True)\n    assert _is_skipped(obj)\n\n    monkeypatch.setattr(obj, \"__unittest_skip__\", False)\n    assert not _is_skipped(obj)\n"], "sample_193": ["    def test_related_field(self):\n        class TestModel(models.Model):\n            pass\n\n        class RelatedModel(models.Model):\n            test = models.ForeignKey(TestModel, on_delete=models.CASCADE)\n\n        class AnotherRelatedModel(models.Model):\n            test = models.ForeignKey(TestModel, on_delete=models.CASCADE)\n\n        class ManyToManyModel(models.Model):\n            tests = models.ManyToManyField(TestModel)\n\n        apps = Apps(['tests.test_state'])\n\n        state = ProjectState(\n            apps=apps,\n            models={\n                'tests.test_state.TestModel': ModelState(\n                    'tests.test_state.TestModel',\n                    fields=[],\n                    options={'managed': True},\n                    bases=(models.Model,),\n                ),\n                'tests.test_state.RelatedModel': ModelState(\n                    'tests.test_state.RelatedModel',\n                    fields=[\n                        ('id', models.AutoField(primary_key=True)),\n                        ('test', models.ForeignKey(TestModel, on_delete=models.CASCADE)),\n                    ],\n                    options={'managed': True},\n                    bases=(models.Model,),\n                ),\n                'tests.test_state.AnotherRelatedModel': ModelState(\n                    'tests.test_state.AnotherRelatedModel',\n                    fields=[\n                        ('id', models.AutoField(primary_key=True)),\n                        ('test', models.ForeignKey(TestModel, on_delete=models.CASCADE)),\n                    ],\n                    options={'managed': True},\n                    bases=(models.Model,),\n                ),\n                'tests.test_state.ManyToManyModel': ModelState(\n                    'tests.test_state.ManyToManyModel',\n                    fields=[\n                        ('id', models.AutoField(primary_key=True)),\n                    ],\n                    options={'managed': True},\n                    bases=(models.Model,),\n                ),\n            },\n        )\n\n        # Test that related fields are correctly resolved\n        self.assertEqual(\n            get_related_models_recursive(state, 'tests.test_state.TestModel'),\n            {'tests.test_state.RelatedModel', 'tests.test_state.AnotherRelatedModel'}\n        )\n\n        # Test that many-to-many fields are correctly resolved\n        state.models['tests.test_state.ManyToManyModel'].fields.append(\n            ('tests', models.ManyToManyField(TestModel))\n        )\n        self.assertEqual(\n            get_related_models_recursive(state, 'tests.test_state.TestModel'),\n            {'tests.test_state.RelatedModel', 'tests.test_state.AnotherRelatedModel', 'tests.test_state.ManyToManyModel'}\n        )\n\n        # Test that related fields are correctly resolved when the related model is not in the state\n        state.models['tests.test_state.RelatedModel'].fields[1].remote_field.model = 'tests.test_state.NonExistentModel'\n        with self.assertRaises(InvalidBasesError):\n            get_related_models_recursive(state,"], "sample_636": ["def test_stripped_lines_with_comments_and_docstrings(tmp_path):\n    \"\"\"Test that comments and docstrings are correctly stripped from lines.\"\"\"\n    # Create a test file with comments and docstrings\n    test_file = tmp_path / \"test_file.py\"\n    test_file.write_text(\n        \"\"\"\\"], "sample_23": ["def test_longitude_wrap_at():\n    lon = Longitude([10, 20, 30] * u.deg, wrap_angle=180 * u.deg)\n    assert lon.wrap_angle == 180 * u.deg\n    lon.wrap_at(0 * u.deg)\n    assert lon.wrap_angle == 0 * u.deg\n    assert_allclose(lon.degree, [-170, -160, -150])\n"], "sample_694": ["def test_check_ispytest():\n    with pytest.warns(PytestDeprecationWarning, match=\"A private pytest class or function was used.\"):\n        deprecated.check_ispytest(False)\n\n    with warnings.catch_warnings(record=True) as w:\n        deprecated.check_ispytest(True)\n        assert not w\n"], "sample_737": ["def test_tfidfvectorizer():\n    # Test that TfidfVectorizer produces the same results as CountVectorizer\n    # followed by TfidfTransformer\n    docs = [\"hello world\", \"world world\", \"hello hello\"]\n    v = TfidfVectorizer()\n    X = v.fit_transform(docs)\n\n    v_count = CountVectorizer()\n    X_count = v_count.fit_transform(docs)\n    t = TfidfTransformer()\n    X_tfidf = t.fit_transform(X_count)\n\n    assert_array_almost_equal(X.toarray(), X_tfidf.toarray())\n\n    # Test that TfidfVectorizer produces the same results as CountVectorizer\n    # followed by TfidfTransformer when using a custom vocabulary\n    vocab = [\"hello\", \"world\"]\n    v = TfidfVectorizer(vocabulary=vocab)\n    X = v.fit_transform(docs)\n\n    v_count = CountVectorizer(vocabulary=vocab)\n    X_count = v_count.fit_transform(docs)\n    t = TfidfTransformer()\n    X_tfidf = t.fit_transform(X_count)\n\n    assert_array_almost_equal(X.toarray(), X_tfidf.toarray())\n\n    # Test that TfidfVectorizer produces the same results as CountVectorizer\n    # followed by TfidfTransformer when using a custom vocabulary and\n    # stop_words\n    vocab = [\"hello\", \"world\"]\n    stop_words = [\"hello\"]\n    v = TfidfVectorizer(vocabulary=vocab, stop_words=stop_words)\n    X = v.fit_transform(docs)\n\n    v_count = CountVectorizer(vocabulary=vocab, stop_words=stop_words)\n    X_count = v_count.fit_transform(docs)\n    t = TfidfTransformer()\n    X_tfidf = t.fit_transform(X_count)\n\n    assert_array_almost_equal(X.toarray(), X_tfidf.toarray())\n\n    # Test that TfidfVectorizer produces the same results as CountVectorizer\n    # followed by TfidfTransformer when using a custom vocabulary and\n    # max_df\n    vocab = [\"hello\", \"world\"]\n    max_df = 0.5\n    v = TfidfVectorizer(vocabulary=vocab, max_df=max_df)\n    X = v.fit_transform(docs)\n\n    v_count = CountVectorizer(vocabulary=vocab, max_df=max_df)\n    X_count = v_count.fit_transform(docs)\n    t = TfidfTransformer()\n    X_tfidf = t.fit_transform(X_count)\n\n    assert_array_almost_equal(X.toarray(), X_tfidf.toarray())\n\n    # Test that TfidfVectorizer produces the same results as CountVectorizer\n    # followed by"], "sample_974": ["def test_ccode():\n    # Test _print_Pow\n    assert ccode(x**2) == \"pow(x, 2)\"\n    assert ccode(x**-1) == \"1.0/x\"\n    assert ccode(x**0.5) == \"sqrt(x)\"\n\n    # Test _print_Rational\n    assert ccode(Rational(3, 4)) == \"3.0L/4.0L\"\n\n    # Test _print_Indexed\n    i = Idx('i', 5)\n    A = IndexedBase('A', shape=(5,))\n    assert ccode(A[i]) == \"A[i]\"\n\n    # Test _print_Idx\n    assert ccode(i) == \"i\"\n\n    # Test _print_Exp1\n    assert ccode(exp(1)) == \"M_E\"\n\n    # Test _print_Pi\n    assert ccode(pi) == \"M_PI\"\n\n    # Test _print_Infinity\n    assert ccode(oo) == \"HUGE_VAL\"\n\n    # Test _print_NegativeInfinity\n    assert ccode(-oo) == \"-HUGE_VAL\"\n\n    # Test _print_Piecewise\n    expr = Piecewise((x**2, x > 0), (x, True))\n    assert ccode(expr) == \"((x > 0) ? (pow(x, 2)) : (x))\"\n\n    # Test _print_ITE\n    expr = ITE(x > 0, x**2, x)\n    assert ccode(expr) == \"((x > 0) ? (pow(x, 2)) : (x))\"\n\n    # Test _print_MatrixElement\n    M = Matrix([[1, 2], [3, 4]])\n    assert ccode(M[0, 0]) == \"{0}[0]\"\n\n    # Test _print_Symbol\n    assert ccode(x) == \"x\"\n\n    # Test _print_Relational\n    assert ccode(x > 0) == \"(x > 0)\"\n\n    # Test _print_sinc\n    from sympy.functions.elementary.trigonometric import sin\n    from sympy.core.relational import Ne\n    from sympy.functions import Piecewise\n    expr = sin(x)/x\n    _piecewise = Piecewise((sin(x)/x, Ne(x, 0)), (1, True))\n    assert ccode(expr) == ccode"], "sample_80": ["def test_is_nullable(self):\n    query = Query(Item)\n    self.assertTrue(query.is_nullable(CharField(null=True)))\n    self.assertFalse(query.is_nullable(CharField(null=False)))\n    self.assertTrue(query.is_nullable(CharField(null=False, blank=True)))\n    self.assertFalse(query.is_nullable(CharField(null=False, blank=False)))\n"], "sample_1188": ["def test_pretty_printing():\n    # Test pretty printing of various expressions\n    assert pretty(a + b) == \"a + b\"\n    assert upretty(a + b) == \"a + b\"\n    assert pretty(a * b) == \"a*b\"\n    assert upretty(a * b) == \"a\u22c5b\"\n    assert pretty(a / b) == \"a/b\"\n    assert upretty(a / b) == \"a\u2044b\"\n    assert pretty(a ** b) == \"a**b\"\n    assert upretty(a ** b) == \"a\u1d47\"\n\n    # Test pretty printing of vectors\n    assert pretty(v[0]) == \"0\"\n    assert upretty(v[0]) == \"0\"\n    assert pretty(v[1]) == \"i_N\"\n    assert upretty(v[1]) == \"i_N\"\n    assert pretty(v[2]) == \"-i_N\"\n    assert upretty(v[2]) == \"-i_N\"\n    assert pretty(v[3]) == \"i_N + j_N\"\n    assert upretty(v[3]) == \"i_N + j_N\"\n    assert pretty(v[4]) == \"a*i_N\"\n    assert upretty(v[4]) == \"a\u22c5i_N\"\n    assert pretty(v[5]) == \"a*i_N - b*j_N\"\n    assert upretty(v[5]) == \"a\u22c5i_N - b\u22c5j_N\"\n    assert pretty(v[6]) == \"(a**2 + x_N)*i_N + k_N\"\n    assert upretty(v[6]) == \"(a\u00b2 + x_N)\u22c5i_N + k_N\"\n    assert pretty(v[7]) == \"(a**2 + b)*i_N + 3*(y_C - c)*k_N\"\n    assert upretty(v[7]) == \"(a\u00b2 + b)\u22c5i_N + 3\u22c5(y_C - c)\u22c5k_N\"\n    assert pretty(v[8]) == \"j_N + (-x_C**2 + Integral(f(b), (b,)))*k_N\"\n    assert upretty(v[8]) == upretty_v_8\n    assert pretty(v[8]) == pretty_v_8\n    assert pretty(v[9]) == \"i_N + k_C\"\n    assert upretty(v[9]) == \"i_N +"], "sample_331": ["def test_parse_date(self):\n    # Test valid dates\n    self.assertEqual(parse_date('2022-01-01'), date(2022, 1, 1))\n    self.assertEqual(parse_date('2022-12-31'), date(2022, 12, 31))\n\n    # Test invalid dates\n    with self.assertRaises(ValueError):\n        parse_date('2022-02-30')\n    with self.assertRaises(ValueError):\n        parse_date('2022-13-01')\n\n    # Test invalid formats\n    self.assertIsNone(parse_date('2022/01/01'))\n    self.assertIsNone(parse_date('20220101'))\n\n    # Test edge cases\n    self.assertEqual(parse_date('0001-01-01'), date(1, 1, 1))\n    self.assertEqual(parse_date('9999-12-31'), date(9999, 12, 31))\n"], "sample_933": ["def test_gettext_builder(tmp_path, monkeypatch):\n    # Create a test directory with a simple Sphinx project\n    project_dir = tmp_path / 'project'\n    project_dir.mkdir()\n    (project_dir / 'conf.py').write_text('''\n        project = 'Test Project'\n        copyright = '2023, Test Author'\n        author = 'Test Author'\n        release = '1.0'\n        extensions = ['gettext']\n    ''')\n    (project_dir / 'index.rst').write_text('''\n        .. toctree::\n           :maxdepth: 2\n           :caption: Contents:\n\n           foo\n    ''')\n    (project_dir / 'foo.rst').write_text('''\n        Foo\n        ===\n\n        This is a test page.\n    ''')\n\n    # Run Sphinx with the gettext builder\n    with cd(project_dir):\n        result = subprocess.run(['sphinx-build', '-b', 'gettext', '.', '_build'], stdout=PIPE, stderr=PIPE)\n        assert result.returncode == 0\n\n    # Check the generated POT file\n    pot_file = project_dir / '_build' / 'LC_MESSAGES' / 'sphinx.pot'\n    assert pot_file.exists()\n    with open(pot_file, 'r', encoding='utf-8') as f:\n        pot_content = f.read()\n    assert 'msgid \"\"' in pot_content\n    assert 'msgstr \"\"' in pot_content\n    assert 'Project-Id-Version: Test Project 1.0' in pot_content\n"], "sample_1019": ["def test_factor_nc():\n    A = Symbol('A', commutative=False)\n    B = Symbol('B', commutative=False)\n    C = Symbol('C', commutative=False)\n    assert factor_nc((x**2 + 2*A*x + A**2).expand()) == (x + A)**2\n    assert factor_nc(((x + A)*(x + B)).expand()) == (x + A)*(x + B)\n    assert factor_nc((x + A)*(x + B) + (x + A)*(x + C)) == (x + A)*(x + B + C)\n    assert factor_nc((x + A)*(x + B) + (x + B)*(x + C)) == (x + B)*(x + A + C)\n    assert factor_nc((x + A)*(x + B) + (x + C)*(x + A)) == (x + A)*(x + B + C)\n    assert factor_nc((x + A)*(x + B) + (x + C)*(x + B)) == (x + B)*(x + A + C)\n    assert factor_nc((x + A)*(x + B) + (x + A)*(x + C) + (x + B)*(x + C)) == (x + A)*(x + B)*(x + C)\n"], "sample_390": ["def test_was_modified_since(self):\n    # Test that was_modified_since returns True when the header is None\n    self.assertTrue(was_modified_since())\n\n    # Test that was_modified_since returns True when the header is invalid\n    self.assertTrue(was_modified_since(\"Invalid header\"))\n\n    # Test that was_modified_since returns True when the file has been modified\n    mtime = 1643723400  # Some arbitrary modification time\n    self.assertTrue(was_modified_since(http_date(mtime - 1), mtime))\n\n    # Test that was_modified_since returns False when the file has not been modified\n    self.assertFalse(was_modified_since(http_date(mtime), mtime))\n\n    # Test that was_modified_since returns True when the file size has changed\n    self.assertTrue(was_modified_since(http_date(mtime), mtime, 100, 200))\n\n    # Test that was_modified_since returns False when the file size has not changed\n    self.assertFalse(was_modified_since(http_date(mtime), mtime, 100, 100))\n"], "sample_538": ["def test_transformed_patch_path():\n    fig, ax = plt.subplots()\n    patch = mpatches.Circle((0.5, 0.5), 0.2)\n    ax.add_patch(patch)\n    transform = mtransforms.Affine2D().rotate(np.pi / 2)\n    transformed_patch_path = mtransforms.TransformedPatchPath(patch)\n    transformed_path, affine = transformed_patch_path.get_transformed_path_and_affine()\n    assert_array_almost_equal(transformed_path.vertices,\n                             transform.transform_path(patch.get_path()).vertices)\n    assert_array_almost_equal(affine.get_matrix(), transform.get_matrix())\n"], "sample_774": ["def test_ordinal_encoder():\n    # Test OrdinalEncoder with string categories\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), [[0., 0.], [1., 2.], [1., 1.]])\n\n    # Test OrdinalEncoder with integer categories\n    enc = OrdinalEncoder()\n    X = [[1, 1], [3, 3], [2, 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), [[0., 0.], [2., 2.], [1., 1.]])\n\n    # Test OrdinalEncoder with mixed-type categories\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), [[0., 0.], [1., 2.], [1., 1.]])\n\n    # Test OrdinalEncoder with categories that are not sorted\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), [[0., 0.], [1., 2.], [1., 1.]])\n\n    # Test OrdinalEncoder with categories that contain NaN\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', np.nan], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), [[0., 0.], [1., np.nan], [1., 1.]])\n\n    # Test OrdinalEncoder with categories that contain None\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', None], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), [[0., 0.], [1., np.nan], [1., 1.]])\n\n    # Test OrdinalEncoder with categories that contain None and NaN\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', np.nan], ['Female', None]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), [[0., 0.], [1., np.nan"], "sample_377": ["    def test_get_traceback_data(self):\n        request = HttpRequest()\n        request.user = User()\n        exc_type = Exception\n        exc_value = Exception(\"Test exception\")\n        tb = None\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIn(\"request\", data)\n        self.assertIn(\"request_meta\", data)\n        self.assertIn(\"request_COOKIES_items\", data)\n        self.assertIn(\"user_str\", data)\n        self.assertIn(\"filtered_POST_items\", data)\n        self.assertIn(\"settings\", data)\n        self.assertIn(\"sys_executable\", data)\n        self.assertIn(\"sys_version_info\", data)\n        self.assertIn(\"server_time\", data)\n        self.assertIn(\"django_version_info\", data)\n        self.assertIn(\"sys_path\", data)\n        self.assertIn(\"template_info\", data)\n        self.assertIn(\"template_does_not_exist\", data)\n        self.assertIn(\"postmortem\", data)\n"], "sample_261": ["def test_parse_date(self):\n    # Test valid date\n    self.assertEqual(parse_date('2022-01-01'), date(2022, 1, 1))\n\n    # Test invalid date\n    with self.assertRaises(ValueError):\n        parse_date('2022-02-30')\n\n    # Test invalid format\n    self.assertIsNone(parse_date('2022/01/01'))\n\n    # Test edge cases\n    self.assertEqual(parse_date('0001-01-01'), date(1, 1, 1))\n    self.assertEqual(parse_date('9999-12-31'), date(9999, 12, 31))\n"], "sample_42": ["def test_pixel_scale():\n    pixscale = 0.1 * u.arcsec / u.pix\n    equiv = u.pixel_scale(pixscale)\n    assert_quantity_allclose(1 * u.pix.to(u.arcsec, equivalencies=equiv), 0.1 * u.arcsec)\n    assert_quantity_allclose(1 * u.arcsec.to(u.pix, equivalencies=equiv), 10 * u.pix)\n\n    pixscale = 10 * u.pix / u.arcsec\n    equiv = u.pixel_scale(pixscale)\n    assert_quantity_allclose(1 * u.pix.to(u.arcsec, equivalencies=equiv), 0.1 * u.arcsec)\n    assert_quantity_allclose(1 * u.arcsec.to(u.pix, equivalencies=equiv), 10 * u.pix)\n\n    with pytest.raises(u.UnitsError):\n        u.pixel_scale(0.1 * u.arcsec)\n\n    with pytest.raises(u.UnitsError):\n        u.pixel_scale(10 * u.pix)\n"], "sample_1186": ["def test_ndim_array_creation():\n    # Test creation from a list\n    a = ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    assert a.tolist() == [[1, 2], [3, 4]]\n\n    # Test creation from a nested list\n    b = ImmutableDenseNDimArray([[1, 2], [3, 4]])\n    assert b.tolist() == [[1, 2], [3, 4]]\n\n    # Test creation from a matrix\n    c = ImmutableDenseNDimArray(Matrix([[1, 2], [3, 4]]))\n    assert c.tolist() == [[1, 2], [3, 4]]\n\n    # Test creation with shape\n    d = ImmutableDenseNDimArray([1, 2, 3, 4, 5, 6], (2, 3))\n    assert d.tolist() == [[1, 2, 3], [4, 5, 6]]\n\n    # Test creation with invalid shape\n    raises(ValueError, lambda: ImmutableDenseNDimArray([1, 2, 3, 4, 5, 6], (2, 4)))\n"], "sample_211": ["    def test_template_view(self):\n        request = self.rf.get('/')\n        response = AboutTemplateView.as_view()(request)\n        self.assertEqual(response.status_code, 200)\n"], "sample_47": ["    def test_callable_setting_wrapper_repr(self):\n            pass\n\n        wrapper = CallableSettingWrapper(test_callable)\n        self.assertEqual(repr(wrapper), repr(test_callable))\n"], "sample_427": ["    def test_formset_factory(self):\n        Formset = formset_factory(FavoriteDrinkForm, extra=2)\n        formset = Formset()\n        self.assertEqual(len(formset.forms), 2)\n        self.assertEqual(formset.extra, 2)\n"], "sample_758": ["def test_check_is_fitted():\n    # Test that check_is_fitted raises NotFittedError when attributes are missing\n    class MockEstimator:\n            self.fitted_ = True\n\n    estimator = MockEstimator()\n    assert_raise_message(NotFittedError, \"This MockEstimator instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.\",\n                        check_is_fitted, estimator, attributes='fitted_')\n\n    # Test that check_is_fitted does not raise NotFittedError when attributes are present\n    estimator.fit()\n    check_is_fitted(estimator, attributes='fitted_')\n\n    # Test that check_is_fitted raises NotFittedError when attributes are missing and all_or_any is all\n    class MockEstimator:\n            self.fitted_ = True\n\n    estimator = MockEstimator()\n    assert_raise_message(NotFittedError, \"This MockEstimator instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.\",\n                        check_is_fitted, estimator, attributes=['fitted_', 'other_'], all_or_any=all)\n\n    # Test that check_is_fitted does not raise NotFittedError when attributes are present and all_or_any is all\n    estimator.fit()\n    check_is_fitted(estimator, attributes=['fitted_', 'other_'], all_or_any=all)\n\n    # Test that check_is_fitted raises NotFittedError when attributes are missing and all_or_any is any\n    class MockEstimator:\n            self.fitted_ = True\n\n    estimator = MockEstimator()\n    assert_raise_message(NotFittedError, \"This MockEstimator instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.\",\n                        check_is_fitted, estimator, attributes=['fitted_', 'other_'], all_or_any=any)\n\n    # Test that check_is_fitted does not raise NotFittedError when attributes are present and all_or_any is any\n    estimator.fit()\n    check_is_fitted(estimator, attributes=['fitted_', 'other_'], all_or_any=any)\n\n    # Test that check_is_fitted raises TypeError when estimator is not an estimator instance\n    assert_raise_message(TypeError, \"MockObject is not an estimator instance.\",\n                        check_is_fitted, object(), attributes='fitted_')\n\n    # Test that check_is_fitted raises ValueError"], "sample_60": ["    def setUp(self):\n        self.site = AdminSite()\n        self.model_admin = admin.ModelAdmin(Category, self.site)\n"], "sample_761": ["def test_iterative_imputer():\n    # Test IterativeImputer with a simple case\n    X = np.array([[1, 2], [np.nan, 3], [7, 6]])\n    imputer = IterativeImputer(max_iter=1, random_state=0)\n    Xt = imputer.fit_transform(X)\n    assert_allclose(Xt, np.array([[1., 2.], [4., 3.], [7., 6.]]))\n\n    # Test IterativeImputer with a more complex case\n    X = np.array([[1, 2, np.nan], [np.nan, 3, 4], [7, np.nan, 6]])\n    imputer = IterativeImputer(max_iter=2, random_state=0)\n    Xt = imputer.fit_transform(X)\n    assert_allclose(Xt, np.array([[1., 2., 3.5], [3.5, 3., 4.], [7., 3.5, 6.]]))\n\n    # Test IterativeImputer with a sparse matrix\n    X = sparse.csc_matrix(np.array([[1, 2, np.nan], [np.nan, 3, 4], [7, np.nan, 6]]))\n    imputer = IterativeImputer(max_iter=2, random_state=0)\n    Xt = imputer.fit_transform(X)\n    assert_allclose(Xt.toarray(), np.array([[1., 2., 3.5], [3.5, 3., 4.], [7., 3.5, 6.]]))\n\n    # Test IterativeImputer with a non-default estimator\n    X = np.array([[1, 2, np.nan], [np.nan, 3, 4], [7, np.nan, 6]])\n    imputer = IterativeImputer(estimator=RidgeCV(), max_iter=2, random_state=0)\n    Xt = imputer.fit_transform(X)\n    assert_allclose(Xt, np.array([[1., 2., 3.5], [3.5, 3., 4.], [7., 3.5, 6.]]))\n\n    # Test IterativeImputer with a non-default initial strategy\n    X = np.array([[1, 2, np.nan], [np.nan, 3, 4], [7, np"], "sample_844": ["def test_optics_xi_cluster():\n    # Test that the xi cluster extraction works correctly\n    # with different parameters\n    reachability_plot = np.array([10, 8.9, 8.8, 8.7, 7, 10, np.inf])\n    predecessor_plot = np.array([-1, 0, 1, 2, 3, 4, 5])\n    ordering = np.arange(7)\n    xi = 0.05\n    min_samples = 2\n    min_cluster_size = 2\n    predecessor_correction = True\n\n    clusters = _xi_cluster(reachability_plot, predecessor_plot, ordering, xi,\n                           min_samples, min_cluster_size, predecessor_correction)\n    assert_array_equal(clusters, np.array([[0, 5]]))\n\n    # Test with different xi value\n    xi = 0.1\n    clusters = _xi_cluster(reachability_plot, predecessor_plot, ordering, xi,\n                           min_samples, min_cluster_size, predecessor_correction)\n    assert_array_equal(clusters, np.array([[0, 5]]))\n\n    # Test with different min_samples value\n    min_samples = 3\n    clusters = _xi_cluster(reachability_plot, predecessor_plot, ordering, xi,\n                           min_samples, min_cluster_size, predecessor_correction)\n    assert_array_equal(clusters, np.array([[0, 5]]))\n\n    # Test with different min_cluster_size value\n    min_cluster_size = 3\n    clusters = _xi_cluster(reachability_plot, predecessor_plot, ordering, xi,\n                           min_samples, min_cluster_size, predecessor_correction)\n    assert_array_equal(clusters, np.array([[0, 5]]))\n\n    # Test with predecessor_correction=False\n    predecessor_correction = False\n    clusters = _xi_cluster(reachability_plot, predecessor_plot, ordering, xi,\n                           min_samples, min_cluster_size, predecessor_correction)\n    assert_array_equal(clusters, np.array([[0, 5]]))\n"], "sample_511": ["def test_pyplot_functions():\n    # Test that all pyplot functions are correctly wrapped\n    pyplot_functions = [\n        'acorr', 'angle_spectrum', 'annotate', 'arrow', 'autoscale',\n        'axhline', 'axhspan', 'axis', 'axline', 'axvline', 'axvspan',\n        'bar', 'barbs', 'barh', 'bar_label', 'boxplot', 'broken_barh',\n        'clabel', 'cohere', 'contour', 'contourf', 'csd', 'errorbar',\n        'eventplot', 'fill', 'fill_between', 'fill_betweenx', 'grid',\n        'hexbin', 'hist', 'hist2d', 'hlines', 'imshow', 'legend',\n        'locator_params', 'loglog', 'magnitude_spectrum', 'margins',\n        'minorticks_off', 'minorticks_on', 'pcolor', 'pcolormesh',\n        'phase_spectrum', 'pie', 'plot', 'plot_date', 'psd', 'quiver',\n        'quiverkey', 'scatter', 'semilogx', 'semilogy', 'specgram',\n        'spy', 'stackplot', 'stem', 'step', 'streamplot', 'table',\n        'text', 'tick_params', 'ticklabel_format', 'tricontour',\n        'tricontourf', 'tripcolor', 'triplot', 'violinplot', 'vlines',\n        'xcorr'\n    ]\n\n    for func_name in pyplot_functions:\n        assert hasattr(plt, func_name), f\"Missing function {func_name}\"\n        func = getattr(plt, func_name)\n        assert callable(func), f\"{func_name} is not callable\"\n"], "sample_336": ["    def test_urlresolver_match_with_nested_namespaces(self):\n        resolver = get_resolver(urlconf_outer)\n        match = resolver.resolve('/ns-included1/ns-included4/ns-included2/test3/inner/42/37/')\n        self.assertEqual(match.func, views.empty_view)\n        self.assertEqual(match.args, ())\n        self.assertEqual(match.kwargs, {'arg1': '42', 'arg2': '37'})\n        self.assertEqual(match.url_name, 'urlobject-view')\n        self.assertEqual(match.app_names, ['included_namespace_urls', 'namespace_urls', 'included_namespace_urls', 'testapp'])\n        self.assertEqual(match.namespaces, ['inc-ns1', 'inc-ns4', 'inc-ns2', 'test-ns3'])\n        self.assertEqual(match.route, 'ns-included1/ns-included4/ns-included2/test3/inner/42/37/')\n        self.assertEqual(match.view_name, 'inc-ns1:inc-ns4:inc-ns2:test-ns3:urlobject-view')\n"], "sample_456": ["    def test_management_form(self):\n        formset = ChoiceFormSet()\n        management_form = formset.management_form\n        self.assertIsInstance(management_form, ManagementForm)\n        self.assertEqual(management_form.fields[TOTAL_FORM_COUNT].initial, 1)\n        self.assertEqual(management_form.fields[INITIAL_FORM_COUNT].initial, 0)\n        self.assertEqual(management_form.fields[MIN_NUM_FORM_COUNT].initial, 0)\n        self.assertEqual(management_form.fields[MAX_NUM_FORM_COUNT].initial, 1000)\n"], "sample_606": ["def test_apply_ufunc_with_dask_array():\n    if not has_dask:\n        pytest.skip(\"dask is not installed or imported\")\n\n    # Create a dask array\n    da = xr.DataArray(np.random.rand(100, 100), chunks=(10, 10))\n\n    # Apply a function to the dask array\n    result = apply_ufunc(np.mean, da, dask=\"allowed\")\n\n    # Check that the result is a dask array\n    assert isinstance(result.data, dask.array.core.Array)\n\n    # Check that the result is correct\n    assert_allclose(result.data.compute(), np.mean(da.data))\n\n    # Check that the result has the correct attributes\n    assert result.attrs == da.attrs\n\n    # Check that the result has the correct coordinates\n    assert result.coords == da.coords\n\n    # Check that the result has the correct dimensions\n    assert result.dims == da.dims\n\n    # Check that the result has the correct shape\n    assert result.shape == da.shape\n"], "sample_637": ["    def test_encoding_declaration(self):\n        set_config(self.linter, notes=[\"FIXME\"])\n        code = \"\"\"# -*- coding: utf-8 -*-"], "sample_370": ["    def test_prefetch_related_objects_with_reverse_one_to_one(self):\n        # Create a Bio instance for author1\n        bio = Bio.objects.create(author=self.author1)\n\n        # Prefetch the bio for authors\n        authors = Author.objects.prefetch_related('bio').all()\n\n        # Check that the bio is prefetched\n        with self.assertNumQueries(1):\n            for author in authors:\n                if author == self.author1:\n                    self.assertEqual(author.bio, bio)\n                else:\n                    self.assertIsNone(author.bio)\n\n        # Check that the reverse accessor also works\n        bios = Bio.objects.prefetch_related('author').all()\n\n        # Check that the author is prefetched\n        with self.assertNumQueries(1):\n            for bio in bios:\n                self.assertEqual(bio.author, self.author1)\n"], "sample_137": ["def test_parse_docstring(self):\n    title, body, metadata = parse_docstring(self.docstring)\n    self.assertEqual(title, \"This __doc__ output is required for testing. I copied this example from `admindocs` documentation. (TITLE)\")\n    self.assertIn(\"Display an individual\", body)\n    self.assertIn(\"some_metadata\", metadata)\n    self.assertEqual(metadata[\"some_metadata\"], \"some data\")\n\n    # Test with an empty docstring\n    title, body, metadata = parse_docstring(\"\")\n    self.assertEqual(title, \"\")\n    self.assertEqual(body, \"\")\n    self.assertEqual(metadata, {})\n\n    # Test with a docstring that has no metadata\n    docstring = \"This is a docstring with no metadata.\"\n    title, body, metadata = parse_docstring(docstring)\n    self.assertEqual(title, docstring)\n    self.assertEqual(body, \"\")\n    self.assertEqual(metadata, {})\n\n    # Test with a docstring that has a title and a body but no metadata\n    docstring = \"This is a title.\\n\\nThis is a body.\"\n    title, body, metadata = parse_docstring(docstring)\n    self.assertEqual(title, \"This is a title.\")\n    self.assertEqual(body, \"This is a body.\")\n    self.assertEqual(metadata, {})\n"], "sample_413": ["    def test_check_setting_app_dirs_loaders_error(self):\n        errors = check_setting_app_dirs_loaders(None)\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, E001.id)\n        self.assertEqual(errors[0].msg, E001.msg)\n"], "sample_813": ["def test_bayesian_ridge_predict_variance():\n    # Test that the variance of the predictive distribution is correctly\n    # computed\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([5, 6])\n    br = BayesianRidge()\n    br.fit(X, y)\n    y_mean, y_std = br.predict(X, return_std=True)\n    assert_array_almost_equal(y_std, np.array([0.5, 0.5]))\n"], "sample_620": ["def test_concat_dataset_with_conflicting_attrs():\n    # Create two datasets with conflicting attributes\n    ds1 = create_test_data()\n    ds2 = deepcopy(ds1)\n    ds2.attrs[\"conflicting_attr\"] = \"value2\"\n\n    # Concatenate the datasets with override combine_attrs\n    result = concat([ds1, ds2], dim=\"new_dim\", combine_attrs=\"override\")\n\n    # Check that the resulting dataset has the attributes from the first dataset\n    assert result.attrs == ds1.attrs\n\n    # Check that the resulting dataset does not have the conflicting attribute from the second dataset\n    assert \"conflicting_attr\" not in result.attrs\n\n    # Check that the resulting dataset has the correct data\n    assert_equal(result[\"var1\"], np.concatenate([ds1[\"var1\"], ds2[\"var1\"]]))\n\n"], "sample_291": ["def test_template_response_mixin(self):\n    class TestTemplateResponseMixinView(TemplateResponseMixin, View):\n        template_name = 'test_template.html'\n\n            return self.render_to_response({})\n\n    view = TestTemplateResponseMixinView()\n    request = self.rf.get('/')\n    view.setup(request)\n    response = view.get(request)\n    self.assertEqual(response.status_code, 200)\n"], "sample_661": ["def test_record_testsuite_property(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n            record_testsuite_property(\"ARCH\", \"PPC\")\n            record_testsuite_property(\"STORAGE_TYPE\", \"CEPH\")\n        \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    properties = dom.find_first_by_tag(\"properties\")\n    assert properties.find_nth_by_tag(\"property\", 0).assert_attr(name=\"ARCH\", value=\"PPC\")\n    assert properties.find_nth_by_tag(\"property\", 1).assert_attr(name=\"STORAGE_TYPE\", value=\"CEPH\")\n"], "sample_1162": ["def test_Derivative():\n    # Test that Derivative can handle non-commutative symbols\n    assert Derivative(comm_x, comm_x).doit() == 1\n    assert Derivative(noncomm_x, noncomm_x).doit() == 1\n    assert Derivative(noncomm_x, comm_x).doit() == 0\n    assert Derivative(comm_x, noncomm_x).doit() == 0\n"], "sample_351": ["    def test_modelchoicefield_prepare_value(self):\n        class TestForm(forms.Form):\n            category = forms.ModelChoiceField(Category.objects.all())\n\n        form = TestForm({'category': self.c1.pk})\n        self.assertEqual(form.fields['category'].prepare_value(self.c1.pk), self.c1.pk)\n\n        form = TestForm({'category': self.c1})\n        self.assertEqual(form.fields['category'].prepare_value(self.c1), self.c1.pk)\n\n        form = TestForm({'category': None})\n        self.assertIsNone(form.fields['category'].prepare_value(None))\n\n        form = TestForm({'category': ''})\n        self.assertEqual(form.fields['category'].prepare_value(''), '')\n\n        form = TestForm({'category': 'invalid'})\n        with self.assertRaises(ValidationError):\n            form.fields['category'].prepare_value('invalid')\n"], "sample_721": ["def test_check_symmetric():\n    # test symmetric matrix\n    X = np.array([[1, 2], [2, 1]])\n    assert_array_equal(check_symmetric(X), X)\n\n    # test non-symmetric matrix\n    X = np.array([[1, 2], [3, 1]])\n    X_sym = check_symmetric(X)\n    assert_array_equal(X_sym, np.array([[1, 2.5], [2.5, 1]]))\n\n    # test sparse symmetric matrix\n    X = sp.csr_matrix(np.array([[1, 2], [2, 1]]))\n    assert_array_equal(check_symmetric(X).toarray(), X.toarray())\n\n    # test sparse non-symmetric matrix\n    X = sp.csr_matrix(np.array([[1, 2], [3, 1]]))\n    X_sym = check_symmetric(X)\n    assert_array_equal(X_sym.toarray(), np.array([[1, 2.5], [2.5, 1]]))\n\n    # test non-square matrix\n    X = np.array([[1, 2, 3], [4, 5, 6]])\n    assert_raises(ValueError, check_symmetric, X)\n\n    # test non-2D matrix\n    X = np.array([1, 2, 3])\n    assert_raises(ValueError, check_symmetric, X)\n\n    # test raise_exception=True\n    X = np.array([[1, 2], [3, 1]])\n    assert_raises(ValueError, check_symmetric, X, raise_exception=True)\n\n    # test raise_warning=False\n    X = np.array([[1, 2], [3, 1]])\n    with ignore_warnings(category=UserWarning):\n        X_sym = check_symmetric(X, raise_warning=False)\n        assert_array_equal(X_sym, np.array([[1, 2.5], [2.5, 1]]))\n"], "sample_13": ["def test_longitude_wrap_at():\n    lon = Longitude([10, 20, 30] * u.deg, wrap_angle=180 * u.deg)\n    assert lon.wrap_angle == 180 * u.deg\n    lon.wrap_at(0 * u.deg)\n    assert lon.wrap_angle == 0 * u.deg\n    assert_allclose(lon.degree, [-170, -160, -150])\n"], "sample_1192": ["def test_disambiguate():\n    x = Symbol('x')\n    y = Symbol('y')\n    d1 = Dummy('x')\n    d2 = Dummy('x')\n    d3 = Dummy('y')\n    d4 = Dummy('y')\n\n    assert disambiguate(x, d1, d2, d3, d4) == (x, x_1, x_2, y, y_1)\n\n    assert disambiguate(x, y, d1, d2, d3, d4) == (x, y, x_1, x_2, y_1, y_2)\n\n    assert disambiguate(x, y, d1, d2, d3, d4, x, y) == (x, y, x_1, x_2, y_1, y_2, x_3, y_3)\n\n    assert disambiguate(x, y, d1, d2, d3, d4, x, y, x, y) == (x, y, x_1, x_2, y_1, y_2, x_3, y_3, x_4, y_4)\n\n    assert disambiguate(x, y, d1, d2, d3, d4, x, y, x, y, x, y) == (x, y, x_1, x_2, y_1, y_2, x_3, y_3, x_4, y_4, x_5, y_5)\n\n    assert disambiguate(x, y, d1, d2, d3, d4, x, y, x, y, x, y, x, y) == (x, y, x_1, x_2, y_1, y_2, x_3, y_3, x_4, y_4, x_5, y_5, x_6, y_6)\n\n    assert disambiguate(x, y, d1, d2, d3, d4, x, y, x, y, x, y, x, y, x, y) == (x, y, x_1, x_2, y_1, y_2, x_3, y_3, x_4, y_"], "sample_1039": ["def test_mathml_content_printer():\n    # Test _print_Mul\n    assert mp._print_Mul(2*x) == mp.dom.createElement('apply')\n    assert mp._print_Mul(-2*x) == mp.dom.createElement('apply')\n    assert mp._print_Mul(2*x*y) == mp.dom.createElement('apply')\n    assert mp._print_Mul(1/x) == mp.dom.createElement('apply')\n    assert mp._print_Mul(1/(2*x)) == mp.dom.createElement('apply')\n\n    # Test _print_Add\n    assert mp._print_Add(x + 2) == mp.dom.createElement('apply')\n    assert mp._print_Add(x - 2) == mp.dom.createElement('apply')\n    assert mp._print_Add(x + 2*y) == mp.dom.createElement('apply')\n    assert mp._print_Add(x - 2*y) == mp.dom.createElement('apply')\n\n    # Test _print_MatrixBase\n    M = Matrix([[1, 2], [3, 4]])\n    assert mp._print_MatrixBase(M) == mp.dom.createElement('matrix')\n\n    # Test _print_Rational\n    assert mp._print_Rational(Rational(1, 2)) == mp.dom.createElement('apply')\n    assert mp._print_Rational(Rational(2, 1)) == mp.dom.createElement('cn')\n\n    # Test _print_Limit\n    assert mp._print_Limit(Limit(x, x, 0)) == mp.dom.createElement('apply')\n\n    # Test _print_ImaginaryUnit\n    assert mp._print_ImaginaryUnit(I) == mp.dom.createElement('imaginaryi')\n\n    # Test _print_EulerGamma\n    assert mp._print_EulerGamma(EulerGamma) == mp.dom.createElement('eulergamma')\n\n    # Test _print_GoldenRatio\n    assert mp._print_GoldenRatio(GoldenRatio) == mp.dom.createElement('cn')\n\n    # Test _print_Exp1\n    assert mp._print_Exp1(E) == mp.dom.createElement('exponentiale')\n\n    # Test _print_Pi\n    assert mp._print_Pi(pi) == mp.dom.createElement('pi')\n\n    # Test _print_Infinity\n    assert mp._print_Infinity(oo) == mp.dom.createElement('infinity')\n\n    # Test _print_Negative_Infinity\n    assert mp._print_Negative_Infinity(-oo) == mp.dom.createElement"], "sample_190": ["    def test_lookup_exact_with_float_rhs(self):\n        # Test that IntegerFieldFloatRounding works correctly.\n        self.assertEqual(\n            Article.objects.filter(pub_date__year__exact=2005.5).count(),\n            Article.objects.filter(pub_date__year__exact=6).count()\n        )\n        self.assertEqual(\n            Article.objects.filter(pub_date__year__exact=2005.0).count(),\n            Article.objects.filter(pub_date__year__exact=2005).count()\n        )\n        self.assertEqual(\n            Article.objects.filter(pub_date__year__exact=2004.9).count(),\n            Article.objects.filter(pub_date__year__exact=5).count()\n        )\n        self.assertEqual(\n            Article.objects.filter(pub_date__year__exact=2005.1).count(),\n            Article.objects.filter(pub_date__year__exact=6).count()\n        )\n"], "sample_481": ["    def test_truncatechars(self):\n        output = self.engine.render_to_string(\"truncatechars01\", {\"a\": \"Hello, World!\"})\n        self.assertEqual(output, \"Hello\")\n"], "sample_1209": ["def test_prefix():\n    assert kilo.scale_factor == 1000\n    assert kilo.base == 10\n    assert kilo.name == 'kilo'\n    assert kilo.abbrev == 'k'\n    assert str(kilo) == 'k'\n    assert repr(kilo) == \"Prefix('kilo', 'k', 3)\"\n\n    assert kibi.scale_factor == 1024\n    assert kibi.base == 2\n    assert kibi.name == 'kibi'\n    assert kibi.abbrev == 'Y'\n    assert str(kibi) == 'Y'\n    assert repr(kibi) == \"Prefix('kibi', 'Y', 10, 2)\"\n\n    assert kilo * kilo == 1000000\n    assert kilo / kilo == 1\n    assert kilo * kibi == 1024000\n    assert kilo / kibi == Rational(1000, 1024)\n\n    assert (kilo * meter).scale_factor == 1000\n    assert (kilo * meter).abbrev == 'km'\n    assert (kilo * meter).name == 'kilometer'\n\n    assert prefix_unit(meter, PREFIXES) == [\n        yotta * meter, zetta * meter, exa * meter, peta * meter, tera * meter,\n        giga * meter, mega * meter, kilo * meter, hecto * meter, deca * meter,\n        meter, deci * meter, centi * meter, milli * meter, micro * meter,\n        nano * meter, pico * meter, femto * meter, atto * meter, zepto * meter,\n        yocto * meter\n    ]\n"], "sample_527": ["def test_figure_repr():\n    fig = Figure()\n    fig_repr = repr(fig)\n    assert re.match(r\"<Figure size [0-9\\.]+x[0-9\\.]+ with 0 Axes>\", fig_repr)\n    ax = fig.add_subplot(111)\n    fig_repr = repr(fig)\n    assert re.match(r\"<Figure size [0-9\\.]+x[0-9\\.]+ with 1 Axes>\", fig_repr)\n"], "sample_674": ["def test_splitnode(nodeid, expected):\n    assert nodes._splitnode(nodeid) == expected\n"], "sample_282": ["def test_bound_field(self):\n    form = ComplexFieldForm({'field1': 'John,J,G,2022-01-01 12:00:00'})\n    bound_field = form['field1']\n    self.assertEqual(bound_field.errors, [])\n    self.assertEqual(bound_field.auto_id, 'id_field1')\n    self.assertEqual(bound_field.id_for_label, 'id_field1_0')\n    self.assertEqual(bound_field.initial, None)\n    self.assertEqual(bound_field.is_hidden, False)\n    self.assertEqual(bound_field.value(), 'John,J,G,2022-01-01 12:00:00')\n    self.assertEqual(bound_field.widget_type, 'complexfield')\n    self.assertEqual(str(bound_field), str(form.fields['field1'].widget))\n    self.assertEqual(bound_field.label_tag(), '<label for=\"id_field1_0\">Field1:</label>')\n    self.assertEqual(bound_field.css_classes(), '')\n    self.assertEqual(bound_field.build_widget_attrs({'class': 'test'}), {'class': 'test'})\n    self.assertEqual(bound_field.as_widget(), str(form.fields['field1'].widget))\n    self.assertEqual(bound_field.as_text(), '<input type=\"text\" name=\"field1_0\" value=\"John\">')\n    self.assertEqual(bound_field.as_textarea(), '<textarea name=\"field1_0\" cols=\"40\" rows=\"10\">John</textarea>')\n    self.assertEqual(bound_field.as_hidden(), '<input type=\"hidden\" name=\"field1_0\" value=\"John\">')\n"], "sample_426": ["def test_timesince_future_date(self):\n    # Test that timesince returns \"0 minutes\" for a future date\n    future_date = self.t + self.oneday\n    self.assertEqual(timesince(future_date), \"0 minutes\")\n"], "sample_838": ["def test_transformer_weights():\n    # test that transformer weights are applied correctly\n    X = np.array([[1, 2, 3], [4, 5, 6]])\n    transformer_weights = {'norm1': 2, 'norm2': 3}\n    ct = ColumnTransformer(\n        [('norm1', Normalizer(norm='l1'), [0, 1]),\n         ('norm2', Normalizer(norm='l1'), [2])],\n        transformer_weights=transformer_weights)\n    X_t = ct.fit_transform(X)\n    X_t_expected = np.hstack([\n        2 * Normalizer(norm='l1').fit_transform(X[:, :2]),\n        3 * Normalizer(norm='l1').fit_transform(X[:, 2:])\n    ])\n    assert_allclose_dense_sparse(X_t, X_t_expected)\n\n    # test that transformer weights are applied correctly when using make_column_transformer\n    ct = make_column_transformer(\n        (Normalizer(norm='l1'), [0, 1]),\n        (Normalizer(norm='l1'), [2]),\n        transformer_weights={'normalizer': 2, 'onehotencoder': 3}\n    )\n    with assert_raises(ValueError) as cm:\n        ct.fit_transform(X)\n    assert \"Unknown transformer names in 'transformer_weights'\" in str(cm.exception)\n\n    ct = make_column_transformer(\n        (Normalizer(norm='l1'), [0, 1]),\n        (Normalizer(norm='l1'), [2]),\n        transformer_weights={'standardscaler': 2, 'onehotencoder': 3}\n    )\n    with assert_raises(ValueError) as cm:\n        ct.fit_transform(X)\n    assert \"Unknown transformer names in 'transformer_weights'\" in str(cm.exception)\n\n    ct = make_column_transformer(\n        (Normalizer(norm='l1'), [0, 1]),\n        (Normalizer(norm='l1'), [2]),\n        transformer_weights={'standardscaler': 2}\n    )\n    with assert_raises(ValueError) as cm:\n        ct.fit_transform(X)\n    assert \"Unknown transformer names in 'transformer_weights'\" in str(cm.exception)\n\n    ct = make_column_transformer(\n        (Normalizer(norm='l1'), [0, 1]),\n        (Normalizer(norm='l1'), [2]),\n        transformer_weights={'standardscaler': 2, 'onehotencoder': 3, 'normalizer': 4}\n    )\n    X"], "sample_887": ["def test_calibration_curve():\n    # Test calibration curve with binary classification\n    X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n    clf = LogisticRegression(random_state=42)\n    clf.fit(X_train, y_train)\n    y_prob = clf.predict_proba(X_test)[:, 1]\n    prob_true, prob_pred = calibration_curve(y_test, y_prob, n_bins=5)\n    assert len(prob_true) == len(prob_pred)\n    assert np.allclose(prob_true, prob_pred, atol=0.2)  # tolerance for randomness\n\n    # Test calibration curve with multiclass classification\n    X, y = make_blobs(n_samples=100, n_features=2, centers=3, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n    clf = LogisticRegression(random_state=42, multi_class=\"ovr\")\n    clf.fit(X_train, y_train)\n    y_prob = clf.predict_proba(X_test)\n    for i in range(3):\n        prob_true, prob_pred = calibration_curve(y_test, y_prob[:, i], n_bins=5, pos_label=i)\n        assert len(prob_true) == len(prob_pred)\n        assert np.allclose(prob_true, prob_pred, atol=0.2)  # tolerance for randomness\n\n    # Test calibration curve with non-probabilistic predictions\n    X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n    clf = DecisionTreeClassifier(random_state=42)\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    with pytest.raises(ValueError):\n        calibration_curve(y_test, y_pred, n_bins=5)\n\n    # Test calibration curve with normalize=True\n    X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n    clf = LogisticRegression(random_state"], "sample_479": ["def test_rename_index(self):\n    operations = [\n        migrations.RenameIndex(\n            model_name=\"model\",\n            new_name=\"new_index\",\n            old_name=\"old_index\",\n        ),\n        migrations.RenameIndex(\n            model_name=\"model\",\n            new_name=\"another_index\",\n            old_name=\"new_index\",\n        ),\n    ]\n    expected = [\n        migrations.RenameIndex(\n            model_name=\"model\",\n            new_name=\"another_index\",\n            old_name=\"old_index\",\n        ),\n    ]\n    self.assertOptimizesTo(operations, expected)\n"], "sample_203": ["def test_prohibit_null_characters_validator(self):\n    validator = validators.ProhibitNullCharactersValidator()\n    with self.assertRaisesMessage(ValidationError, _('Null characters are not allowed.')):\n        validator('\\x00')\n    validator('\\x01')  # Should not raise an exception\n"], "sample_117": ["    def test_user_creation_form(self):\n        data = {\n            'username': 'newuser',\n            'password1': 'password',\n            'password2': 'password',\n        }\n        form = UserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        user = form.save()\n        self.assertEqual(user.username, 'newuser')\n        self.assertTrue(user.check_password('password'))\n"], "sample_450": ["def test_get_admin_log_template_tag(self):\n    template_str = \"{% load admin_utils %}{% get_admin_log 10 as admin_log %}{{ admin_log }}{% get_admin_log 10 as admin_log for_user user %}{{ admin_log }}\"\n    template = template.Template(template_str)\n    context = template.Context({\"log_entries\": LogEntry.objects.all(), \"user\": self.user})\n    rendered_template = template.render(context)\n    self.assertIn(\"LogEntry\", rendered_template)\n"], "sample_2": ["def test_ccddata_init():\n    \"\"\"\n    Test the initialization of a CCDData object.\n    \"\"\"\n    data = np.array([1, 2, 3])\n    ccd = CCDData(data, unit=u.adu)\n    assert ccd.data == data\n    assert ccd.unit == u.adu\n    assert ccd.uncertainty is None\n    assert ccd.mask is None\n    assert ccd.flags is None\n    assert ccd.wcs is None\n    assert ccd.meta == {}\n\n    # Test with uncertainty\n    uncertainty = StdDevUncertainty(np.array([0.1, 0.2, 0.3]))\n    ccd = CCDData(data, uncertainty=uncertainty, unit=u.adu)\n    assert ccd.uncertainty == uncertainty\n\n    # Test with mask\n    mask = np.array([False, True, False])\n    ccd = CCDData(data, mask=mask, unit=u.adu)\n    assert np.array_equal(ccd.mask, mask)\n\n    # Test with flags\n    flags = np.array([1, 2, 3])\n    ccd = CCDData(data, flags=flags, unit=u.adu)\n    assert np.array_equal(ccd.flags, flags)\n\n    # Test with WCS\n    wcs = WCS(naxis=1)\n    ccd = CCDData(data, wcs=wcs, unit=u.adu)\n    assert ccd.wcs == wcs\n\n    # Test with meta\n    meta = {'key': 'value'}\n    ccd = CCDData(data, meta=meta, unit=u.adu)\n    assert ccd.meta == meta\n\n    # Test with invalid unit\n    with pytest.raises(ValueError):\n        CCDData(data, unit=None)\n\n    # Test with invalid uncertainty\n    with pytest.raises(TypeError):\n        CCDData(data, uncertainty='invalid', unit=u.adu)\n\n    # Test with invalid mask\n    with pytest.raises(ValueError):\n        CCDData(data, mask='invalid', unit=u.adu)\n\n    # Test with invalid flags\n    with pytest.raises(TypeError):\n        CCDData(data, flags='invalid', unit=u.adu)\n\n    # Test with invalid WCS\n    with pytest.raises(TypeError):\n        CCDData(data, wcs='invalid', unit=u.adu)\n"], "sample_515": ["def test_colorbar_extension_length():\n    \"\"\"\n    Test that colorbar extensions have the correct length for uniform and\n    proportional spacing.\n    \"\"\"\n    _colorbar_extension_length('uniform')\n    _colorbar_extension_length('proportional')\n\n"], "sample_956": ["def test_resolve_reference_detect_inventory_with_qualification(self, mock_read_from_url, mock_InventoryFile):\n    app = mock.Mock()\n    env = mock.Mock()\n    env.domains = {\n        'std': mock.Mock(),\n        'py': mock.Mock(),\n    }\n    env.domains['std'].get_full_qualified_name.return_value = 'std:func'\n    env.domains['py'].get_full_qualified_name.return_value = 'py:func'\n    env.config.intersphinx_disabled_reftypes = []\n    node, contnode = fake_node('std', 'func', 'inv_name:target', 'content')\n    InventoryAdapter(env).named_inventory = {\n        'inv_name': {\n            'std:func': {\n                'target': ('project', 'version', 'uri', 'dispname')\n            }\n        }\n    }\n    result = resolve_reference_detect_inventory(env, node, contnode)\n    self.assertIsNotNone(result)\n    self.assertIsInstance(result, nodes.reference)\n    self.assertEqual(result['refuri'], 'uri')\n    self.assertEqual(result[0].astext(), 'dispname')\n"], "sample_103": ["    def test_aggregate_with_filter(self):\n        # Test that aggregates with filters work correctly\n        query = Book.objects.annotate(avg_price=Avg('price', filter=Q(pages__gt=400)))\n        self.assertEqual(query.count(), 6)\n        self.assertGreater(query[0].avg_price, 0)\n\n        # Test that aggregates with filters and distinct work correctly\n        query = Book.objects.annotate(avg_price=Avg('price', distinct=True, filter=Q(pages__gt=400)))\n        self.assertEqual(query.count(), 6)\n        self.assertGreater(query[0].avg_price, 0)\n\n        # Test that aggregates with filters and distinct raise an error when not allowed\n        with self.assertRaises(TypeError):\n            Avg('price', distinct=True, filter=Q(pages__gt=400), allow_distinct=False)\n\n        # Test that aggregates with filters and sample work correctly\n        query = Book.objects.annotate(std_dev=StdDev('price', sample=True, filter=Q(pages__gt=400)))\n        self.assertEqual(query.count(), 6)\n        self.assertGreater(query[0].std_dev, 0)\n\n        # Test that aggregates with filters and sample raise an error when not allowed\n        with self.assertRaises(TypeError):\n            StdDev('price', sample=True, filter=Q(pages__gt=400), allow_distinct=False)\n\n        # Test that aggregates with filters and distinct raise an error when not allowed\n        with self.assertRaises(TypeError):\n            Sum('price', distinct=True, filter=Q(pages__gt=400), allow_distinct=False)\n"], "sample_1041": ["def test_matrix_element():\n    i, j = symbols('i j', integer=True)\n    assert MatrixElement(A, i, j).parent == A\n    assert MatrixElement(A, i, j).i == i\n    assert MatrixElement(A, i, j).j == j\n    assert MatrixElement(A, i, j).doit() == A[i, j]\n    assert MatrixElement(A, i, j)._diff_wrt\n    assert MatrixElement(A, i, j).is_symbol\n    assert MatrixElement(A, i, j).is_commutative\n    assert MatrixElement(A, i, j).indices == (i, j)\n\n    raises(ValueError, lambda: MatrixElement(A, i, n+1))\n    raises(ValueError, lambda: MatrixElement(A, n+1, j))\n"], "sample_644": ["def test_check_reimport(self) -> None:\n    \"\"\"Test that reimported modules are correctly detected.\"\"\"\n    node = astroid.parse(\n        \"\"\"\n        import os\n        import os\n        \"\"\"\n    )\n    with self.assertAddsMessages(\"W0404\", line=2):\n        self.checker.visit_import(node.body[0])\n        self.checker.visit_import(node.body[1])\n"], "sample_995": ["def test_mod_inverse():\n    assert mod_inverse(2, 3) == 2\n    assert mod_inverse(-2, 3) == -2\n    assert mod_inverse(2, -3) == -2\n    assert mod_inverse(-2, -3) == 2\n    assert mod_inverse(2, 4) == 1\n    assert mod_inverse(2, 5) == 3\n    assert mod_inverse(2, 7) == 4\n    assert mod_inverse(2, 11) == 6\n    assert mod_inverse(2, 13) == 7\n    assert mod_inverse(2, 17) == 9\n    assert mod_inverse(2, 19) == 10\n    assert mod_inverse(2, 23) == 12\n    assert mod_inverse(2, 29) == 15\n    assert mod_inverse(2, 31) == 16\n    assert mod_inverse(2, 37) == 19\n    assert mod_inverse(2, 41) == 21\n    assert mod_inverse(2, 43) == 22\n    assert mod_inverse(2, 47) == 24\n    assert mod_inverse(2, 53) == 27\n    assert mod_inverse(2, 59) == 30\n    assert mod_inverse(2, 61) == 31\n    assert mod_inverse(2, 67) == 34\n    assert mod_inverse(2, 71) == 36\n    assert mod_inverse(2, 73) == 37\n    assert mod_inverse(2, 79) == 40\n    assert mod_inverse(2, 83) == 42\n    assert mod_inverse(2, 89) == 45\n    assert mod_inverse(2, 97) == 49\n    assert mod_inverse(2, 101) == 51\n    assert mod_inverse(2, 103) == 52\n    assert mod_inverse(2, 107) == 54\n    assert mod_inverse(2, 109) == 55\n    assert mod_inverse(2, 113) == 57\n    assert mod_inverse(2, 127) == 64\n    assert mod_inverse(2, 131) == 66\n    assert mod_inverse(2, 137) == 69\n"], "sample_330": ["    def test_typecast_date(self):\n        self.assertEqual(typecast_date('2022-01-01'), datetime.date(2022, 1, 1))\n        self.assertIsNone(typecast_date(''))\n"], "sample_1144": ["def test_split_super_sub():\n    assert split_super_sub('a_x^1') == ('a', ['1'], ['x'])\n    assert split_super_sub('var_sub1__sup_sub2') == ('var', ['sup'], ['sub1', 'sub2'])\n    assert split_super_sub('a') == ('a', [], [])\n    assert split_super_sub('a_1') == ('a', [], ['1'])\n    assert split_super_sub('a^1') == ('a', ['1'], [])\n    assert split_super_sub('a__1') == ('a', ['1'], [])\n    assert split_super_sub('a_b_c') == ('a', [], ['b', 'c'])\n    assert split_super_sub('a_b^c') == ('a', ['c'], ['b'])\n    assert split_super_sub('a^b_c') == ('a', ['b'], ['c'])\n    assert split_super_sub('a_b_c^d') == ('a', ['d'], ['b', 'c'])\n    assert split_super_sub('a_b^c_d') == ('a', ['c'], ['b', 'd'])\n    assert split_super_sub('a^b_c^d') == ('a', ['b', 'd'], ['c'])\n"], "sample_941": ["def test_restify():\n    assert restify(None) == ':obj:`None`'\n    assert restify(Ellipsis) == '...'\n    assert restify(Struct) == ':class:`struct.Struct`'\n    assert restify(MyClass1) == ':class:`test_util_typing.MyClass1`'\n    assert restify(MyClass2) == ':class:`MyClass2`'\n    assert restify(MyInt) == ':class:`MyInt`'\n    assert restify(MyList) == ':class:`MyList`\\\\ [~T]'  # type: ignore\n    assert restify(BrokenType) == ':obj:`test_util_typing.BrokenType`'\n    assert restify(Any) == ':obj:`Any`'\n    assert restify(Callable) == ':class:`Callable`'\n    assert restify(Dict) == ':class:`Dict`'\n    assert restify(Generator) == ':class:`Generator`'\n    assert restify(List) == ':class:`List`'\n    assert restify(Optional) == ':obj:`Optional`'\n    assert restify(Tuple) == ':class:`Tuple`'\n    assert restify(TypeVar) == ':obj:`TypeVar`'\n    assert restify(Union) == ':obj:`Union`'\n    assert restify(Integral) == ':class:`numbers.Integral`'\n    assert restify(List[int]) == ':class:`List`\\\\ [:class:`int`]'  # type: ignore\n    assert restify(Tuple[int, str]) == ':class:`Tuple`\\\\ [:class:`int`, :class:`str`]'  # type: ignore\n    assert restify(Dict[str, int]) == ':class:`Dict`\\\\ [:class:`str`, :class:`int`]'  # type: ignore\n    assert restify(Union[int, str]) == ':obj:`Union`\\\\ [:class:`int`, :class:`str`]'  # type: ignore\n    assert restify(Optional[int]) == ':obj:`Optional`\\\\ [:class:`int`]'  # type: ignore\n    assert restify(Callable[[int, str], int]) == ':class:`Callable`\\\\ [[:class:`int`, :class:`str`], :class:`int`]'  # type: ignore\n    assert restify(Generator[int, str, int]) == ':class:`Generator`\\\\ [:class:`int`, :class:`"], "sample_899": ["    def test_check_estimator_sparse_data(self):\n        class SparseEstimator(BaseEstimator):\n                return self\n\n                return np.ones(X.shape[0])\n\n        sparse_estimator = SparseEstimator()\n        check_estimator_sparse_data('SparseEstimator', sparse_estimator)\n"], "sample_822": ["def test_check_pairwise_arrays():\n    # Test that check_pairwise_arrays raises an error when the input arrays\n    # have different numbers of features.\n    X = np.array([[1, 2], [3, 4]])\n    Y = np.array([[1, 2, 3], [4, 5, 6]])\n    with assert_raises(ValueError):\n        check_pairwise_arrays(X, Y)\n\n    # Test that check_pairwise_arrays raises an error when the input arrays\n    # are not at least two dimensional.\n    X = np.array([1, 2, 3])\n    Y = np.array([4, 5, 6])\n    with assert_raises(ValueError):\n        check_pairwise_arrays(X, Y)\n\n    # Test that check_pairwise_arrays raises an error when the input arrays\n    # are not of the same type.\n    X = np.array([[1, 2], [3, 4]])\n    Y = csr_matrix([[1, 2], [3, 4]])\n    with assert_raises(ValueError):\n        check_pairwise_arrays(X, Y, dtype=np.float32)\n\n    # Test that check_pairwise_arrays returns the correct output when the\n    # input arrays are valid.\n    X = np.array([[1, 2], [3, 4]])\n    Y = np.array([[5, 6], [7, 8]])\n    X_checked, Y_checked = check_pairwise_arrays(X, Y)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(Y_checked, Y)\n\n    # Test that check_pairwise_arrays returns the correct output when the\n    # input arrays are sparse.\n    X = csr_matrix([[1, 2], [3, 4]])\n    Y = csr_matrix([[5, 6], [7, 8]])\n    X_checked, Y_checked = check_pairwise_arrays(X, Y)\n    assert_array_equal(X_checked.toarray(), X.toarray())\n    assert_array_equal(Y_checked.toarray(), Y.toarray())\n\n    # Test that check_pairwise_arrays returns the correct output when Y is None.\n    X = np.array([[1, 2], [3, 4]])\n    X_checked, Y_checked = check_pairwise_arrays(X, None)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(Y_checked, X)\n"], "sample_218": ["    def test_trunc_timezone(self):\n        tz = pytz.timezone('America/Los_Angeles')\n        dt = datetime(2022, 3, 13, 1, 59, tzinfo=tz)\n        self.assertEqual(\n            Trunc(dt, 'hour', tzinfo=tz),\n            truncate_to(dt, 'hour', tzinfo=tz)\n        )\n        self.assertEqual(\n            Trunc(dt, 'day', tzinfo=tz),\n            truncate_to(dt, 'day', tzinfo=tz)\n        )\n        self.assertEqual(\n            Trunc(dt, 'month', tzinfo=tz),\n            truncate_to(dt, 'month', tzinfo=tz)\n        )\n        self.assertEqual(\n            Trunc(dt, 'year', tzinfo=tz),\n            truncate_to(dt, 'year', tzinfo=tz)\n        )\n"], "sample_913": ["def test_parse_annotation():\n    # Test parsing of type annotations\n    annotation = 'List[int]'\n    result = _parse_annotation(annotation)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].astext() == 'List'\n\n    annotation = 'List[int, str]'\n    result = _parse_annotation(annotation)\n    assert len(result) == 3\n    assert isinstance(result[0], pending_xref)\n    assert result[0].astext() == 'List'\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == '['\n    assert isinstance(result[2], desc_sig_punctuation)\n    assert result[2].astext() == ']'\n\n    annotation = 'Dict[str, int]'\n    result = _parse_annotation(annotation)\n    assert len(result) == 3\n    assert isinstance(result[0], pending_xref)\n    assert result[0].astext() == 'Dict'\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == '['\n    assert isinstance(result[2], desc_sig_punctuation)\n    assert result[2].astext() == ']'\n\n    annotation = 'Tuple[int, str, float]'\n    result = _parse_annotation(annotation)\n    assert len(result) == 5\n    assert isinstance(result[0], pending_xref)\n    assert result[0].astext() == 'Tuple'\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == '['\n    assert isinstance(result[2], desc_sig_punctuation)\n    assert result[2].astext() == ', '\n    assert isinstance(result[3], desc_sig_punctuation)\n    assert result[3].astext() == ', '\n    assert isinstance(result[4], desc_sig_punctuation)\n    assert result[4].astext() == ']'\n\n    annotation = 'Union[int, str, float]'\n    result = _parse_annotation(annotation)\n    assert len(result) == 5\n    assert isinstance(result[0], pending_xref)\n    assert result[0].astext() == 'Union'\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == '['\n    assert isinstance(result[2], desc_sig_punctuation)\n    assert result[2].astext() == ', '\n    assert isinstance(result"], "sample_977": ["def test_mathematica_code():\n    assert mcode(x**2) == 'x^2'\n    assert mcode(x**-2) == 'x^(-2)'\n    assert mcode(x**Rational(3, 2)) == 'x^(3/2)'\n    assert mcode(x**Rational(-3, 2)) == 'x^(-3/2)'\n    assert mcode(x**pi) == 'x^Pi'\n    assert mcode(x**oo) == 'x^Infinity'\n    assert mcode(x**(-oo)) == 'x^(-Infinity)'\n    assert mcode(x*y) == 'x*y'\n    assert mcode(x*y*z) == 'x*y*z'\n    assert mcode(x + y + z) == 'x + y + z'\n    assert mcode(x - y - z) == 'x - y - z'\n    assert mcode(x + y*z) == 'x + y*z'\n    assert mcode(x - y*z) == 'x - y*z'\n    assert mcode(x*(y + z)) == 'x*(y + z)'\n    assert mcode(x/(y + z)) == 'x/(y + z)'\n    assert mcode(x + y/(z + 1)) == 'x + y/(1 + z)'\n    assert mcode(x - y/(z + 1)) == 'x - y/(1 + z)'\n    assert mcode(x + y*(z + 1)) == 'x + y*(1 + z)'\n    assert mcode(x - y*(z + 1)) == 'x - y*(1 + z)'\n    assert mcode((x + y)*(z + 1)) == '(x + y)*(1 + z)'\n    assert mcode((x - y)*(z + 1)) == '(x - y)*(1 + z)'\n    assert mcode((x + y)/(z + 1)) == '(x + y)/(1 + z)'\n    assert mcode((x - y)/(z + 1)) == '(x - y)/(1 + z)'\n    assert mcode(exp(x)) == 'Exp[x]'\n    assert mcode(sin(x)) == 'Sin[x]'\n    assert mcode(cos(x)) == 'Cos[x]'\n    assert mcode(Integral(x**2, x)) == 'Hold[Integrate[x^2, x]]'\n    assert mcode(S"], "sample_348": ["    def test_model_form_metaclass(self):\n        class TestModel(Model):\n            name = Field()\n\n        class TestForm(ModelForm):\n            class Meta:\n                model = TestModel\n                fields = ('name',)\n\n        self.assertEqual(TestForm._meta.model, TestModel)\n        self.assertEqual(TestForm._meta.fields, ('name',))\n"], "sample_269": ["    def test_set_language_view_with_invalid_language_code(self):\n        \"\"\"Test the set_language view with an invalid language code.\"\"\"\n        inactive_language_code = self._get_inactive_language_code()\n        response = self.client.post(reverse('set_language'), {\n            LANGUAGE_QUERY_PARAMETER: inactive_language_code,\n            'next': '/',\n        })\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response.url, '/')\n"], "sample_810": ["def test_pipeline_memory_caching():\n    # Test that the memory caching works correctly with a pipeline\n    iris = load_iris()\n    X, y = iris.data, iris.target\n\n    # Create a pipeline with a transformer that stores the timestamp of when it\n    # was fitted\n    pipeline = Pipeline([\n        ('scaler', StandardScaler()),\n        ('dummy', DummyTransf())\n    ])\n\n    # Create a memory object\n    memory = Memory(location=mkdtemp(), verbose=0)\n\n    # Fit the pipeline with caching\n    pipeline_with_cache = clone(pipeline)\n    pipeline_with_cache.memory = memory\n    pipeline_with_cache.fit(X, y)\n\n    # Fit the pipeline without caching\n    pipeline_without_cache = clone(pipeline)\n    pipeline_without_cache.fit(X, y)\n\n    # Check that the transformer was fitted at different times\n    assert pipeline_with_cache.named_steps['dummy'].timestamp_ != \\\n        pipeline_without_cache.named_steps['dummy'].timestamp_\n\n    # Check that the transformer was fitted only once with caching\n    pipeline_with_cache.fit(X, y)\n    assert pipeline_with_cache.named_steps['dummy'].timestamp_ == \\\n        pipeline_with_cache.named_steps['dummy'].timestamp_\n\n    # Clean up the temporary directory\n    shutil.rmtree(memory.location)\n"], "sample_382": ["def test_template_changed_resets_loaders(self):\n    with mock.patch('django.template.autoreload.reset_loaders') as reset_loaders_mock:\n        file_path = EXTRA_TEMPLATES_DIR / 'test_template.html'\n        file_path.touch()\n        autoreload.file_changed(None, file_path)\n        reset_loaders_mock.assert_called_once()\n"], "sample_619": ["def test_decode_cf_datetime(num_dates, units, calendar):\n    dates = decode_cf_datetime(num_dates, units, calendar)\n    assert isinstance(dates, np.ndarray)\n    assert dates.dtype == \"datetime64[ns]\"\n    assert dates.shape == np.asarray(num_dates).shape\n"], "sample_643": ["def test_colorized_text_reporter_handle_message(capsys, reporter):\n    \"\"\"Test ColorizedTextReporter handle_message method.\"\"\"\n    linter = PyLinter()\n    linter.set_reporter(ColorizedTextReporter())\n    linter.set_option(\"exit-zero\", True)\n    checkers.initialize(linter)\n    linter.check([\"-r\", \"n\", \"tests/data/func_with_docstring.py\"])\n    captured = capsys.readouterr()\n    assert \"************* Module tests.data.func_with_docstring\" in captured.out\n    assert \"\\033[31mE0602\\033[0m\" in captured.out  # Red color for error message\n\n"], "sample_864": ["def test_mean_shift_seeding():\n    # Test seeding with bin_seeding=True\n    ms = MeanShift(bandwidth=2, bin_seeding=True)\n    ms.fit(X)\n    assert_array_equal(ms.labels_, np.sort(ms.labels_))\n\n    # Test seeding with bin_seeding=False\n    ms = MeanShift(bandwidth=2, bin_seeding=False)\n    ms.fit(X)\n    assert_array_equal(ms.labels_, np.sort(ms.labels_))\n\n    # Test seeding with custom seeds\n    seeds = np.array([[0, 0], [5, 5]])\n    ms = MeanShift(bandwidth=2, seeds=seeds)\n    ms.fit(X)\n    assert_array_equal(ms.labels_, np.sort(ms.labels_))\n\n    # Test seeding with bin_seeding=True and min_bin_freq > 1\n    ms = MeanShift(bandwidth=2, bin_seeding=True, min_bin_freq=10)\n    ms.fit(X)\n    assert_array_equal(ms.labels_, np.sort(ms.labels_))\n\n    # Test seeding with bin_seeding=False and min_bin_freq > 1\n    ms = MeanShift(bandwidth=2, bin_seeding=False, min_bin_freq=10)\n    with warnings.catch_warnings(record=True) as w:\n        ms.fit(X)\n        assert len(w) == 1\n        assert \"min_bin_freq is ignored\" in str(w[0].message)\n\n    # Test seeding with custom seeds and min_bin_freq > 1\n    seeds = np.array([[0, 0], [5, 5]])\n    ms = MeanShift(bandwidth=2, seeds=seeds, min_bin_freq=10)\n    with warnings.catch_warnings(record=True) as w:\n        ms.fit(X)\n        assert len(w) == 1\n        assert \"min_bin_freq is ignored\" in str(w[0].message)\n"], "sample_633": ["def test_stripped_lines_with_docstrings():\n    lines = [\n        '\"\"\"This is a docstring.\"\"\"',\n        \"def foo():\",\n        '    \"\"\"This is another docstring.\"\"\"',\n        \"    pass\",\n        \"# This is a comment\",\n        \"print('Hello, world!')\",\n    ]\n    stripped = similar.stripped_lines(lines, ignore_comments=True, ignore_docstrings=True, ignore_imports=False, ignore_signatures=False)\n    assert len(stripped) == 2\n    assert stripped[0].text == \"def foo():\"\n    assert stripped[1].text == \"print('Hello, world!')\"\n\n"], "sample_921": ["def test_signature_from_str():\n    sig = inspect.signature_from_str('(a: int, b: str, *args: str, **kwargs: int) -> None')\n    assert len(sig.parameters) == 4\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.parameters['args'].annotation == str\n    assert sig.parameters['kwargs'].annotation == int\n    assert sig.return_annotation == type(None)\n\n    sig = inspect.signature_from_str('(a: int, b: str, *, c: int, d: str) -> None')\n    assert len(sig.parameters) == 4\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.parameters['c'].annotation == int\n    assert sig.parameters['d'].annotation == str\n    assert sig.return_annotation == type(None)\n\n    sig = inspect.signature_from_str('(a: int, b: str, /, c: int, d: str) -> None')\n    assert len(sig.parameters) == 4\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.parameters['c'].annotation == int\n    assert sig.parameters['d'].annotation == str\n    assert sig.return_annotation == type(None)\n\n    with pytest.raises(SyntaxError):\n        inspect.signature_from_str('(a: int, b: str, /, /, c: int, d: str) -> None')\n"], "sample_168": ["    def test_handle_removes_stale_content_types_interactive(self, mock_clear_cache, mock_input):\n        with captured_stdout() as stdout:\n            call_command('remove_stale_content_types', interactive=True, verbosity=2)\n        self.assertIn('Deleting stale content type', stdout.getvalue())\n        self.assertEqual(ContentType.objects.count(), self.before_count - 1)\n        mock_clear_cache.assert_called_once()\n"], "sample_886": ["def test_wrap_in_pandas_container():\n    # Test wrapping a numpy array\n    data_to_wrap = np.array([[1, 2], [3, 4]])\n    columns = ['feature1', 'feature2']\n    result = _wrap_in_pandas_container(data_to_wrap, columns=columns)\n    assert result.shape == (2, 2)\n    assert result.columns.tolist() == columns\n\n    # Test wrapping a pandas DataFrame\n    data_to_wrap = pd.DataFrame([[1, 2], [3, 4]], columns=['old_feature1', 'old_feature2'])\n    columns = ['feature1', 'feature2']\n    result = _wrap_in_pandas_container(data_to_wrap, columns=columns)\n    assert result.shape == (2, 2)\n    assert result.columns.tolist() == columns\n\n    # Test wrapping a numpy array with callable columns\n    data_to_wrap = np.array([[1, 2], [3, 4]])\n    columns = lambda: ['feature1', 'feature2']\n    result = _wrap_in_pandas_container(data_to_wrap, columns=columns)\n    assert result.shape == (2, 2)\n    assert result.columns.tolist() == ['feature1', 'feature2']\n\n    # Test wrapping a numpy array with None columns\n    data_to_wrap = np.array([[1, 2], [3, 4]])\n    columns = None\n    result = _wrap_in_pandas_container(data_to_wrap, columns=columns)\n    assert result.shape == (2, 2)\n    assert result.columns.tolist() == [0, 1]\n\n    # Test wrapping a pandas DataFrame with None columns\n    data_to_wrap = pd.DataFrame([[1, 2], [3, 4]], columns=['old_feature1', 'old_feature2'])\n    columns = None\n    result = _wrap_in_pandas_container(data_to_wrap, columns=columns)\n    assert result.shape == (2, 2)\n    assert result.columns.tolist() == ['old_feature1', 'old_feature2']\n\n    # Test wrapping a sparse matrix\n    data_to_wrap = csr_matrix([[1, 2], [3, 4]])\n    columns = ['feature1', 'feature2']\n    with pytest.raises(ValueError):\n        _wrap_in_pandas_container(data_to_wrap, columns=columns)\n"], "sample_149": ["    def test_check_user_model_is_anonymous_is_method(self):\n        class CustomUser(AbstractBaseUser):\n            USERNAME_FIELD = 'username'\n            REQUIRED_FIELDS = ['email']\n\n                return False\n\n        with self.settings(AUTH_USER_MODEL='auth_tests.CustomUser'):\n            errors = check_user_model()\n            self.assertEqual(len(errors), 1)\n            self.assertEqual(errors[0].id, 'auth.C009')\n"], "sample_526": ["def test_date2num():\n    # Test date2num with datetime objects\n    dt = datetime.datetime(2022, 1, 1, 12, 0, 0)\n    assert mdates.date2num(dt) == 737060.5\n\n    # Test date2num with numpy datetime64 objects\n    dt64 = np.datetime64('2022-01-01T12:00:00')\n    assert mdates.date2num(dt64) == 737060.5\n\n    # Test date2num with a list of datetime objects\n    dt_list = [datetime.datetime(2022, 1, 1, 12, 0, 0),\n               datetime.datetime(2022, 1, 2, 12, 0, 0)]\n    assert np.allclose(mdates.date2num(dt_list), [737060.5, 737061.5])\n\n    # Test date2num with a list of numpy datetime64 objects\n    dt64_list = [np.datetime64('2022-01-01T12:00:00'),\n                 np.datetime64('2022-01-02T12:00:00')]\n    assert np.allclose(mdates.date2num(dt64_list), [737060.5, 737061.5])\n\n    # Test date2num with a timezone\n    tz = dateutil.tz.tzoffset(None, 3600)  # UTC+1\n    dt_tz = datetime.datetime(2022, 1, 1, 12, 0, 0, tzinfo=tz)\n    assert mdates.date2num(dt_tz) == 737060.5\n\n    # Test date2num with a numpy datetime64 object and a timezone\n    dt64_tz = np.datetime64('2022-01-01T12:00:00+01:00')\n    assert mdates.date2num(dt64_tz) == 737060.5\n"], "sample_27": ["def test_table_data_diff(self):\n    # Create two tables with a single column of different data types\n    col1 = Column(name='a', format='I', array=[1, 2, 3])\n    col2 = Column(name='a', format='E', array=[1.1, 2.2, 3.3])\n    hdu1 = BinTableHDU.from_columns([col1])\n    hdu2 = BinTableHDU.from_columns([col2])\n\n    # Create a TableDataDiff object\n    diff = TableDataDiff(hdu1.data, hdu2.data)\n\n    # Check that the diff object has the expected attributes\n    assert diff.diff_column_attributes == [\n        (('A', 'format'), ('I', 'E')),\n    ]\n    assert diff.diff_values == [\n        (('a', 0), (1, 1.1)),\n        (('a', 1), (2, 2.2)),\n        (('a', 2), (3, 3.3)),\n    ]\n    assert diff.diff_total == 3\n    assert diff.diff_ratio == 1.0\n\n    # Check that the report method works correctly\n    report = diff.report()\n    assert 'Column A has different format:' in report\n    assert 'Data differs at row 0:' in report\n    assert 'Data differs at row 1:' in report\n    assert 'Data differs at row 2:' in report\n"], "sample_1190": ["def test_get_dimensional_expr():\n    x = symbols('x')\n    expr = 2*x + 3\n    assert SI.get_dimensional_expr(expr) == S.One\n\n    expr = 2*x**2 + 3*x\n    assert SI.get_dimensional_expr(expr) == S.One\n\n    expr = diff(x**2, x)\n    assert SI.get_dimensional_expr(expr) == S.One\n\n    expr = integrate(x**2, x)\n    assert SI.get_dimensional_expr(expr) == S.One\n\n    expr = sin(x)\n    assert SI.get_dimensional_expr(expr) == S.One\n\n    expr = exp(x)\n    assert SI.get_dimensional_expr(expr) == S.One\n\n    expr = log(x)\n    assert SI.get_dimensional_expr(expr) == S.One\n\n    expr = sqrt(x)\n    assert SI.get_dimensional_expr(expr) == S.One\n\n    expr = Abs(x)\n    assert SI.get_dimensional_expr(expr) == S.One\n\n    expr = 2*kg + 3\n    assert SI.get_dimensional_expr(expr) == mass\n\n    expr = 2*kg + 3*m\n    raises(ValueError, lambda: SI.get_dimensional_expr(expr))\n\n    expr = 2*kg + 3*second\n    raises(ValueError, lambda: SI.get_dimensional_expr(expr))\n"], "sample_929": ["def test_parse_annotation():\n    env = Mock(spec=['ref_context'])\n    env.ref_context = {}\n\n    # Test simple annotation\n    annotation = 'int'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].astext() == 'int'\n\n    # Test annotation with module\n    annotation = 'module.Class'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].astext() == 'module.Class'\n\n    # Test annotation with nested module\n    annotation = 'module.submodule.Class'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].astext() == 'module.submodule.Class'\n\n    # Test annotation with list\n    annotation = '[int, str]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 5\n    assert isinstance(result[0], desc_sig_punctuation)\n    assert result[0].astext() == '['\n    assert isinstance(result[1], pending_xref)\n    assert result[1].astext() == 'int'\n    assert isinstance(result[2], desc_sig_punctuation)\n    assert result[2].astext() == ', '\n    assert isinstance(result[3], pending_xref)\n    assert result[3].astext() == 'str'\n    assert isinstance(result[4], desc_sig_punctuation)\n    assert result[4].astext() == ']'\n\n    # Test annotation with tuple\n    annotation = '(int, str)'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 5\n    assert isinstance(result[0], desc_sig_punctuation)\n    assert result[0].astext() == '('\n    assert isinstance(result[1], pending_xref)\n    assert result[1].astext() == 'int'\n    assert isinstance(result[2], desc_sig_punctuation)\n    assert result[2].astext() == ', '\n    assert isinstance(result[3], pending_xref)\n    assert result[3].astext() == 'str'\n    assert isinstance(result[4], desc_sig_punctuation)\n    assert result[4].astext() == ')'\n\n    # Test annotation with"], "sample_1206": ["def test_comp():\n    assert comp(1.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_823": ["def test_pairwise_distances_chunked():\n    # Test pairwise_distances_chunked with different metrics\n    X = np.random.RandomState(0).rand(10, 5)\n    Y = np.random.RandomState(1).rand(10, 5)\n    for metric in PAIRWISE_DISTANCE_FUNCTIONS:\n        D_chunked = pairwise_distances_chunked(X, Y, metric=metric)\n        assert isinstance(D_chunked, GeneratorType)\n        D = pairwise_distances(X, Y, metric=metric)\n        D_chunked = np.concatenate(list(D_chunked))\n        assert_array_almost_equal(D, D_chunked)\n\n    # Test pairwise_distances_chunked with callable metric\n        return np.sum(x * y)\n    D_chunked = pairwise_distances_chunked(X, Y, metric=custom_metric)\n    assert isinstance(D_chunked, GeneratorType)\n    D = pairwise_distances(X, Y, metric=custom_metric)\n    D_chunked = np.concatenate(list(D_chunked))\n    assert_array_almost_equal(D, D_chunked)\n\n    # Test pairwise_distances_chunked with reduce_func\n        return np.sum(D_chunk, axis=1)\n    D_chunked = pairwise_distances_chunked(X, Y, reduce_func=reduce_func)\n    assert isinstance(D_chunked, GeneratorType)\n    D = pairwise_distances(X, Y)\n    D_reduced = np.sum(D, axis=1)\n    D_chunked = np.concatenate(list(D_chunked))\n    assert_array_almost_equal(D_reduced, D_chunked)\n\n    # Test pairwise_distances_chunked with working_memory\n    D_chunked = pairwise_distances_chunked(X, Y, working_memory=0)\n    assert isinstance(D_chunked, GeneratorType)\n    D = pairwise_distances(X, Y)\n    D_chunked = np.concatenate(list(D_chunked))\n    assert_array_almost_equal(D, D_chunked)\n\n    # Test pairwise_distances_chunked with n_jobs\n    with config_context(working_memory=None):\n        D_chunked = pairwise_distances_chunked(X, Y, n_jobs=2)\n        assert isinstance(D_chunked, GeneratorType)\n        D = pairwise_distances(X, Y)\n        D_chunked = np.concatenate(list(D_chunked))\n        assert_array_almost_equal(D, D_chunked)\n"], "sample_265": ["def test_get_templatetag_libraries(self):\n    # Test that built-in template tag libraries are loaded\n    libraries = get_installed_libraries()\n    self.assertIn('i18n', libraries)\n\n    # Test that custom libraries are added to the built-in libraries\n    custom_libraries = {'custom_tags': 'path.to.custom.tags'}\n    libraries = self.engine_class({'OPTIONS': {'libraries': custom_libraries}}).get_templatetag_libraries(custom_libraries)\n    self.assertIn('i18n', libraries)\n    self.assertIn('custom_tags', libraries)\n\n    # Test that custom libraries override built-in libraries\n    custom_libraries = {'i18n': 'path.to.custom.i18n'}\n    libraries = self.engine_class({'OPTIONS': {'libraries': custom_libraries}}).get_templatetag_libraries(custom_libraries)\n    self.assertNotIn('django.templatetags.i18n', libraries.values())\n    self.assertIn('path.to.custom.i18n', libraries.values())\n"], "sample_349": ["    def test_autocomplete_select_multiple(self):\n        class AlbumForm(forms.ModelForm):\n            class Meta:\n                model = Album\n                fields = ['band', 'featuring']\n                widgets = {\n                    'band': AutocompleteSelectMultiple(\n                        Album._meta.get_field('band'),\n                        admin.site,\n                        attrs={'class': 'my-class'},\n                    ),\n                    'featuring': AutocompleteSelectMultiple(\n                        Album._meta.get_field('featuring'),\n                        admin.site,\n                    )\n                }\n\n        form = AlbumForm()\n        self.assertIn('admin-autocomplete', form.fields['band'].widget.attrs['class'])\n        self.assertIn('admin-autocomplete', form.fields['featuring'].widget.attrs['class'])\n"], "sample_73": ["    def test_hashed_name(self):\n        name = 'path/to/file.css'\n        content = b'body { background-color: #f2f2f2; }'\n        hashed_name = storage.staticfiles_storage.hashed_name(name, content=content)\n        self.assertNotEqual(hashed_name, name)\n        self.assertIn('.css', hashed_name)\n"], "sample_360": ["    def setUp(self):\n        self.factory = RequestFactory()\n        self.middleware = UpdateCacheMiddleware(get_response=lambda request: HttpResponse())\n"], "sample_1167": ["def test_latex():\n    # Test latex printing of various objects\n    assert latex(x) == 'x'\n    assert latex(x**2) == 'x^{2}'\n    assert latex(x**-2) == 'x^{-2}'\n    assert latex(x**Rational(2, 3)) == 'x^{\\frac{2}{3}}'\n    assert latex(x**Rational(2, 3), fold_frac_powers=True) == 'x^{2/3}'\n    assert latex(x**Rational(-2, 3)) == 'x^{-\\frac{2}{3}}'\n    assert latex(x**Rational(-2, 3), fold_frac_powers=True) == 'x^{-2/3}'\n    assert latex(x**Rational(1, 2)) == '\\sqrt{x}'\n    assert latex(x**Rational(1, 2), root_notation=False) == 'x^{\\frac{1}{2}}'\n    assert latex(x**Rational(-1, 2)) == '\\frac{1}{\\sqrt{x}}'\n    assert latex(x**Rational(-1, 2), root_notation=False) == 'x^{-\\frac{1}{2}}'\n    assert latex(x**Rational(3, 2)) == 'x^{\\frac{3}{2}}'\n    assert latex(x**Rational(3, 2), root_notation=False) == 'x^{\\frac{3}{2}}'\n    assert latex(x**Rational(-3, 2)) == '\\frac{1}{x^{\\frac{3}{2}}}'\n    assert latex(x**Rational(-3, 2), root_notation=False) == 'x^{-\\frac{3}{2}}'\n    assert latex(x**2*y) == 'x^{2} y'\n    assert latex(x**2*y, mul_symbol='times') == 'x^{2} \\\\times y'\n    assert latex(x**2*y, mul_symbol='ldot') == 'x^{2} \\\\,\\\\.\\\\, y'\n    assert latex(x**2*y, mul_symbol='dot') == 'x^{2} \\\\cdot y'\n    assert latex(x**2*y, mul_symbol=' ') == 'x^{2}  y'\n    assert latex(x**2*y, mul_symbol='*') == 'x^{2} * y'\n    assert latex(x**2*y"], "sample_421": ["    def test_expression_output_field_resolution(self):\n        # Test that the output field of an expression is resolved correctly.\n        expression = F('integer') + F('integer2')\n        self.assertIsInstance(expression.output_field, IntegerField)\n\n        expression = F('integer') + Value(1.5)\n        self.assertIsInstance(expression.output_field, FloatField)\n\n        expression = F('integer') + Value(Decimal('1.5'))\n        self.assertIsInstance(expression.output_field, DecimalField)\n\n        expression = F('integer') + Value(datetime(2022, 1, 1))\n        self.assertIsInstance(expression.output_field, DateTimeField)\n\n        expression = F('integer') + Value(date(2022, 1, 1))\n        self.assertIsInstance(expression.output_field, DateField)\n\n        expression = F('integer') + Value(time(12, 0, 0))\n        self.assertIsInstance(expression.output_field, TimeField)\n\n        expression = F('integer') + Value(timedelta(days=1))\n        self.assertIsInstance(expression.output_field, DurationField)\n\n        expression = F('integer') + Value(UUID('01234567-89ab-cdef-0123-456789abcdef'))\n        self.assertIsInstance(expression.output_field, UUIDField)\n\n        expression = F('integer') + Value(b'binary data')\n        self.assertIsInstance(expression.output_field, BinaryField)\n\n        expression = F('integer') + Value(True)\n        self.assertIsInstance(expression.output_field, BooleanField)\n\n        expression = F('integer') + Value(None)\n        self.assertIsInstance(expression.output_field, IntegerField)\n"], "sample_846": ["def test_transformer_weights():\n    # Test that transformer weights are applied correctly\n    X = np.array([[1, 2, 3], [4, 5, 6]])\n    transformer_weights = {'scaler': 2, 'encoder': 3}\n    ct = ColumnTransformer(\n        transformers=[\n            ('scaler', StandardScaler(), [0, 1]),\n            ('encoder', OneHotEncoder(), [2])\n        ],\n        transformer_weights=transformer_weights\n    )\n    ct.fit(X)\n    X_t = ct.transform(X)\n    X_t_expected = np.hstack([\n        2 * StandardScaler().fit_transform(X[:, :2]),\n        3 * OneHotEncoder().fit_transform(X[:, 2:]).toarray()\n    ])\n    assert_allclose_dense_sparse(X_t, X_t_expected)\n\n    # Test that transformer weights are applied correctly when using make_column_transformer\n    ct = make_column_transformer(\n        (StandardScaler(), [0, 1]),\n        (OneHotEncoder(), [2]),\n        transformer_weights=transformer_weights\n    )\n    ct.fit(X)\n    X_t = ct.transform(X)\n    assert_allclose_dense_sparse(X_t, X_t_expected)\n\n    # Test that transformer weights are applied correctly when using remainder\n    ct = ColumnTransformer(\n        transformers=[\n            ('scaler', StandardScaler(), [0, 1])\n        ],\n        remainder='passthrough',\n        transformer_weights=transformer_weights\n    )\n    ct.fit(X)\n    X_t = ct.transform(X)\n    X_t_expected = np.hstack([\n        2 * StandardScaler().fit_transform(X[:, :2]),\n        X[:, 2:]\n    ])\n    assert_allclose_dense_sparse(X_t, X_t_expected)\n\n    # Test that transformer weights are applied correctly when using make_column_transformer with remainder\n    ct = make_column_transformer(\n        (StandardScaler(), [0, 1]),\n        remainder='passthrough',\n        transformer_weights=transformer_weights\n    )\n    ct.fit(X)\n    X_t = ct.transform(X)\n    assert_allclose_dense_sparse(X_t, X_t_expected)\n"], "sample_276": ["    def test_view_index_view(self):\n        response = self.client.get(reverse('django-admindocs:view_index'))\n        self.assertEqual(response.status_code, 200)\n        self.assertTemplateUsed(response, 'admin_doc/view_index.html')\n\n        # Test that the view index page contains all views\n        views = response.context['views']\n        self.assertGreater(len(views), 0)\n        for view in views:\n            self.assertIn('full_name', view)\n            self.assertIn('url', view)\n            self.assertIn('url_name', view)\n            self.assertIn('namespace', view)\n            self.assertIn('name', view)\n"], "sample_59": ["    def test_model_check_long_column_names(self):\n        class LongModelName(models.Model):\n            field1 = models.CharField(max_length=255)\n            field2 = models.CharField(max_length=255)\n\n        class LongFieldName(models.Model):\n            very_long_field_name_that_exceeds_max_length = models.CharField(max_length=255)\n\n        with self.assertRaisesMessage(\n            ValidationError,\n            \"Autogenerated column name too long for field \\\"very_long_field_name_that_exceeds_max_length\\\". \"\n            \"Maximum length is \\\"30\\\" for database \\\"default\\\".\"\n        ):\n            LongFieldName.check()\n\n        with self.assertRaisesMessage(\n            ValidationError,\n            \"Autogenerated column name too long for field \\\"longmodelname\\\". \"\n            \"Maximum length is \\\"30\\\" for database \\\"default\\\".\"\n        ):\n            LongModelName.check()\n"], "sample_845": ["def test_hashing_vectorizer():\n    # Test that HashingVectorizer can handle a large number of features\n    vectorizer = HashingVectorizer(n_features=2**20)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n    assert X.shape == (len(ALL_FOOD_DOCS), 2**20)\n\n    # Test that HashingVectorizer can handle a large number of samples\n    vectorizer = HashingVectorizer(n_features=100)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 1000)\n    assert X.shape == (len(ALL_FOOD_DOCS) * 1000, 100)\n\n    # Test that HashingVectorizer can handle a large number of features and samples\n    vectorizer = HashingVectorizer(n_features=2**20)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 1000)\n    assert X.shape == (len(ALL_FOOD_DOCS) * 1000, 2**20)\n\n    # Test that HashingVectorizer can handle a large number of features and samples with alternate_sign=True\n    vectorizer = HashingVectorizer(n_features=2**20, alternate_sign=True)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 1000)\n    assert X.shape == (len(ALL_FOOD_DOCS) * 1000, 2**20)\n\n    # Test that HashingVectorizer can handle a large number of features and samples with alternate_sign=False\n    vectorizer = HashingVectorizer(n_features=2**20, alternate_sign=False)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 1000)\n    assert X.shape == (len(ALL_FOOD_DOCS) * 1000, 2**20)\n\n    # Test that HashingVectorizer can handle a large number of features and samples with binary=True\n    vectorizer = HashingVectorizer(n_features=2**20, binary=True)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 1000)\n    assert X.shape == (len(ALL_FOOD_DOCS) * 1000, 2**20)\n\n    # Test that HashingVectorizer can handle a large number of features and samples with binary=False\n    vectorizer = HashingVectorizer(n_features=2**20, binary=False)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 1000)\n    assert X.shape"], "sample_1043": ["def test_mathematica_code():\n    assert mcode(0) == '0'\n    assert mcode(1) == '1'\n    assert mcode(-1) == '-1'\n    assert mcode(S.Half) == '1/2'\n    assert mcode(S.ImaginaryUnit) == 'I'\n    assert mcode(S.Infinity) == 'Infinity'\n    assert mcode(S.NegativeInfinity) == '-Infinity'\n    assert mcode(S.ComplexInfinity) == 'ComplexInfinity'\n    assert mcode(S.NaN) == 'Indeterminate'\n    assert mcode(S.Exp1) == 'E'\n    assert mcode(S.Pi) == 'Pi'\n    assert mcode(S.GoldenRatio) == 'GoldenRatio'\n    assert mcode(S.EulerGamma) == 'EulerGamma'\n    assert mcode(S.Catalan) == 'Catalan'\n    assert mcode(Tuple(1, 2, 3)) == '{1, 2, 3}'\n    assert mcode((1, 2, 3)) == '{1, 2, 3}'\n    assert mcode([1, 2, 3]) == '{1, 2, 3}'\n    assert mcode(exp(x)) == 'Exp[x]'\n    assert mcode(sin(x)) == 'Sin[x]'\n    assert mcode(cos(x)) == 'Cos[x]'\n    assert mcode(conjugate(x)) == 'Conjugate[x]'\n    assert mcode(Max(x, y)) == 'Max[x, y]'\n    assert mcode(Min(x, y)) == 'Min[x, y]'\n    assert mcode(Integral(x, x)) == 'Hold[Integrate[x, x]]'\n    assert mcode(Sum(x, (x, 1, 10))) == 'Hold[Sum[x, {x, 1, 10}]]'\n    assert mcode(Derivative(x**2, x)) == 'Hold[D[x**2, x]]'\n    assert mcode(f(x, y, z)) == 'f[x, y, z]'\n    assert mcode(Rational(1, 2)) == '1/2'\n    assert mcode(Integer(1)) == '1'\n"], "sample_524": ["def test_colorbar_extension_shape_proportional():\n    fig1 = _colorbar_extension_shape('proportional')\n    fig2 = _colorbar_extension_shape('proportional')\n    return fig1, fig2\n"], "sample_238": ["    def test_trigonometric_functions(self):\n        # Test the trigonometric functions\n        self.assertAlmostEqual(\n            Book.objects.annotate(sin=Sin('rating')).get(isbn='159059725').sin,\n            math.sin(4.5),\n            places=5\n        )\n        self.assertAlmostEqual(\n            Book.objects.annotate(cos=Cos('rating')).get(isbn='159059725').cos,\n            math.cos(4.5),\n            places=5\n        )\n        self.assertAlmostEqual(\n            Book.objects.annotate(tan=Tan('rating')).get(isbn='159059725').tan,\n            math.tan(4.5),\n            places=5\n        )\n        self.assertAlmostEqual(\n            Book.objects.annotate(atan=ATan('rating')).get(isbn='159059725').atan,\n            math.atan(4.5),\n            places=5\n        )\n        self.assertAlmostEqual(\n            Book.objects.annotate(asin=ASin('rating')).get(isbn='159059725').asin,\n            math.asin(4.5),\n            places=5\n        )\n        self.assertAlmostEqual(\n            Book.objects.annotate(acos=ACos('rating')).get(isbn='159059725').acos,\n            math.acos(4.5),\n            places=5\n        )\n        self.assertAlmostEqual(\n            Book.objects.annotate(atan2=ATan2('rating', 'pages')).get(isbn='159059725').atan2,\n            math.atan2(4.5, 447),\n            places=5\n        )\n"], "sample_16": ["    def test_invariant_a_helper(self):\n            return np.copy(a)\n\n        self.check(test_func)\n"], "sample_564": ["def test_3d_quiver():\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.quiver([0, 1, 0], [0, 0, 1], [0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1])\n    ax.set_xlim(-1, 1)\n    ax.set_ylim(-1, 1)\n    ax.set_zlim(-1, 1)\n"], "sample_95": ["def test_patch_cache_control(self):\n    response = HttpResponse()\n    patch_cache_control(response, max_age=3600, public=True)\n    self.assertEqual(response['Cache-Control'], 'max-age=3600, public')\n\n    response = HttpResponse()\n    response['Cache-Control'] = 'max-age=3600, public'\n    patch_cache_control(response, max_age=1800, private=True)\n    self.assertEqual(response['Cache-Control'], 'max-age=1800, private')\n\n    response = HttpResponse()\n    patch_cache_control(response, no_cache=True, no_store=True, must_revalidate=True)\n    self.assertEqual(response['Cache-Control'], 'no-cache, no-store, must-revalidate')\n"], "sample_1145": ["def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n"], "sample_325": ["    def test_bound_field(self):\n        form = Person({'first_name': 'John', 'last_name': 'Doe', 'birthday': '1990-01-01'})\n        bound_field = form['first_name']\n        self.assertEqual(bound_field.name, 'first_name')\n        self.assertEqual(bound_field.html_name, 'first_name')\n        self.assertEqual(bound_field.label, 'First name')\n        self.assertEqual(bound_field.help_text, '')\n        self.assertEqual(str(bound_field), '<input type=\"text\" name=\"first_name\" value=\"John\">')\n\n        form = PersonNew({'first_name': 'John', 'last_name': 'Doe', 'birthday': '1990-01-01'})\n        bound_field = form['first_name']\n        self.assertEqual(bound_field.name, 'first_name')\n        self.assertEqual(bound_field.html_name, 'first_name')\n        self.assertEqual(bound_field.label, 'First name')\n        self.assertEqual(bound_field.help_text, '')\n        self.assertEqual(str(bound_field), '<input type=\"text\" name=\"first_name\" value=\"John\" id=\"first_name_id\">')\n\n        self.assertEqual(bound_field.errors, ErrorList())\n        self.assertEqual(bound_field.as_widget(), '<input type=\"text\" name=\"first_name\" value=\"John\" id=\"first_name_id\">')\n        self.assertEqual(bound_field.as_text(), '<input type=\"text\" name=\"first_name\" value=\"John\" id=\"first_name_id\">')\n        self.assertEqual(bound_field.as_textarea(), '<textarea name=\"first_name\" cols=\"40\" rows=\"10\" id=\"first_name_id\">John</textarea>')\n        self.assertEqual(bound_field.as_hidden(), '<input type=\"hidden\" name=\"first_name\" value=\"John\" id=\"first_name_id\">')\n\n        self.assertEqual(bound_field.data, 'John')\n        self.assertEqual(bound_field.value(), 'John')\n        self.assertFalse(bound_field._has_changed())\n\n        self.assertEqual(bound_field.label_tag(), '<label for=\"first_name_id\">First name:</label>')\n        self.assertEqual(bound_field.css_classes(), '')\n        self.assertFalse(bound_field.is_hidden)\n        self.assertEqual(bound_field.auto_id, 'first_name_id')\n        self.assertEqual(bound_field.id_for_label, 'first_name_id')\n        self.assertEqual(bound_field.initial, 'John')\n        self.assertEqual(bound_field.build_widget_attrs({'class': 'test'}), {'class': 'test', '"], "sample_944": ["def test_restify():\n    assert restify(None) == ':obj:`None`'\n    assert restify(int) == ':class:`int`'\n    assert restify(Struct) == ':class:`struct.Struct`'\n    assert restify(TracebackType) == ':class:`types.TracebackType`'\n    assert restify(MyClass1) == ':class:`test_util_typing.MyClass1`'\n    assert restify(MyClass2) == ':class:`<MyClass2>`'\n    assert restify(MyList[int]) == ':class:`test_util_typing.MyList`\\\\ [int]'\n    assert restify(Union[int, str]) == ':obj:`Union`\\\\ [int, str]'\n    assert restify(Optional[int]) == ':obj:`Optional`\\\\ [int]'\n    assert restify(Callable[[int, str], int]) == ':class:`Callable`\\\\ [[int, str], int]'\n    assert restify(Generator[int, str, int]) == ':class:`Generator`\\\\ [int, str, int]'\n    assert restify(Tuple[int, str]) == ':class:`tuple`\\\\ [int, str]'\n    assert restify(List[int]) == ':class:`list`\\\\ [int]'\n    assert restify(Dict[int, str]) == ':class:`dict`\\\\ [int, str]'\n    assert restify(MyInt) == ':class:`MyInt`'\n    assert restify(BrokenType) == ':obj:`test_util_typing.BrokenType`'\n\n"], "sample_271": ["    def test_tick(self):\n        reloader = autoreload.StatReloader()\n        ticker = reloader.tick()\n        next(ticker)\n        self.assertTrue(reloader.should_stop)\n"], "sample_414": ["    def test_inline_model_admin(self):\n        class CarAdmin(admin.ModelAdmin):\n            inlines = [CarInline]\n\n        class CarInline(admin.TabularInline):\n            model = Car\n            fields = [\"make\", \"model\"]\n\n        admin.site.register(Car, CarAdmin)\n\n        self.client.force_login(self.superuser)\n\n        response = self.client.get(reverse(\"admin:tests_car_changelist\"))\n        self.assertEqual(response.status_code, 200)\n\n        response = self.client.get(reverse(\"admin:tests_car_add\"))\n        self.assertEqual(response.status_code, 200)\n\n        response = self.client.get(reverse(\"admin:tests_car_change\", args=[1]))\n        self.assertEqual(response.status_code, 200)\n\n        admin.site.unregister(Car)\n"], "sample_581": ["def test_blueprint_setup_state():\n    app = flask.Flask(__name__)\n    blueprint = flask.Blueprint(\"test_blueprint\", __name__)\n\n    state = blueprint.make_setup_state(app, {}, first_registration=True)\n\n    assert state.app == app\n    assert state.blueprint == blueprint\n    assert state.options == {}\n    assert state.first_registration is True\n    assert state.subdomain is None\n    assert state.url_prefix is None\n    assert state.name == \"test_blueprint\"\n    assert state.name_prefix == \"\"\n    assert state.url_defaults == {}\n\n    state = blueprint.make_setup_state(app, {\"subdomain\": \"test\"}, first_registration=False)\n\n    assert state.subdomain == \"test\"\n    assert state.url_defaults == {}\n\n    state = blueprint.make_setup_state(app, {\"url_prefix\": \"/test\"}, first_registration=False)\n\n    assert state.url_prefix == \"/test\"\n    assert state.url_defaults == {}\n\n    state = blueprint.make_setup_state(app, {\"url_defaults\": {\"key\": \"value\"}}, first_registration=False)\n\n    assert state.url_defaults == {\"key\": \"value\"}\n\n    with pytest.raises(ValueError):\n        state.add_url_rule(\"/test\", endpoint=\"test.endpoint\")\n\n    with pytest.raises(ValueError):\n        state.add_url_rule(\"/test\", view_func=lambda: None, endpoint=\"test.endpoint\")\n"], "sample_571": ["def test_regplot_scatter_kws():\n    x = np.random.randn(100)\n    y = np.random.randn(100)\n    ax = lm.regplot(x=x, y=y, scatter_kws={\"s\": 100, \"alpha\": 0.5})\n    assert ax.collections[0].get_sizes() == [100]\n    assert ax.collections[0].get_alpha() == 0.5\n"], "sample_347": ["def test_make_aware(self):\n    naive_dt = datetime.datetime(2022, 1, 1, 12, 0, 0)\n    aware_dt = timezone.make_aware(naive_dt)\n    self.assertEqual(aware_dt.tzinfo, timezone.get_current_timezone())\n\n    aware_dt = timezone.make_aware(naive_dt, timezone=UTC)\n    self.assertEqual(aware_dt.tzinfo, UTC)\n\n    aware_dt = timezone.make_aware(naive_dt, timezone=CET)\n    self.assertEqual(aware_dt.tzinfo, CET)\n\n    with self.assertRaises(ValueError):\n        timezone.make_aware(datetime.datetime(2022, 1, 1, 12, 0, 0, tzinfo=UTC))\n\n    # Test with is_dst parameter\n    tz = pytz.timezone('America/New_York')\n    naive_dt = datetime.datetime(2022, 3, 13, 2, 0, 0)\n    aware_dt = timezone.make_aware(naive_dt, timezone=tz, is_dst=True)\n    self.assertEqual(aware_dt.tzinfo, tz)\n    self.assertEqual(aware_dt.dst(), datetime.timedelta(0, 3600))\n\n    aware_dt = timezone.make_aware(naive_dt, timezone=tz, is_dst=False)\n    self.assertEqual(aware_dt.tzinfo, tz)\n    self.assertEqual(aware_dt.dst(), datetime.timedelta(0, 3600))\n"], "sample_4": ["    def test_read_html_table(self, cosmo):\n        # Create a QTable from the cosmology\n        table = to_table(cosmo)\n\n        # Write the table to a temporary HTML file\n        with tempfile.NamedTemporaryFile(suffix='.html') as tmp:\n            table.write(tmp.name, format='ascii.html')\n\n            # Read the cosmology from the HTML file\n            read_cosmo = read_html_table(tmp.name)\n\n            # Check that the read cosmology matches the original\n            assert read_cosmo == cosmo\n"], "sample_1200": ["def test_UnitSystem_get_dimensional_expr():\n    x = symbols('x')\n    expr = 2 * x**2 + 3 * x + 1\n    assert SI.get_dimensional_expr(expr) == 1\n\n    expr = 2 * meter**2 + 3 * meter + 1\n    assert SI.get_dimensional_expr(expr) == length**2\n\n    expr = diff(x**2, x)\n    assert SI.get_dimensional_expr(expr) == 1\n\n    expr = integrate(x**2, x)\n    assert SI.get_dimensional_expr(expr) == 1\n\n    expr = sin(x)\n    assert SI.get_dimensional_expr(expr) == 1\n\n    expr = exp(x)\n    assert SI.get_dimensional_expr(expr) == 1\n\n    expr = log(x)\n    assert SI.get_dimensional_expr(expr) == 1\n\n    expr = sqrt(x)\n    assert SI.get_dimensional_expr(expr) == 1\n\n    expr = Abs(x)\n    assert SI.get_dimensional_expr(expr) == 1\n\n    expr = joule / (kilogram * meter**2 / second**2)\n    assert SI.get_dimensional_expr(expr) == 1\n\n    expr = joule / (kilogram * meter**2 / second**2) * meter\n    assert SI.get_dimensional_expr(expr) == length\n\n    expr = joule / (kilogram * meter**2 / second**2) * meter**2\n    assert SI.get_dimensional_expr(expr) == length**2\n\n    expr = joule / (kilogram * meter**2 / second**2) * meter**2 / second\n    assert SI.get_dimensional_expr(expr) == length**2 / time\n\n    expr = joule / (kilogram * meter**2 / second**2) * meter**2 / second**2\n    assert SI.get_dimensional_expr(expr) == length**2 / time**2\n"], "sample_332": ["    def test_management_form_validation(self):\n        formset = self.make_choiceformset(\n            formset_data=[('choice1', 10), ('choice2', 20)],\n            total_forms=2,\n            initial_forms=1,\n            max_num_forms=1,\n            min_num_forms=1,\n        )\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(len(formset.non_form_errors()), 1)\n        self.assertEqual(formset.non_form_errors()[0].code, 'too_many_forms')\n\n        formset = self.make_choiceformset(\n            formset_data=[('choice1', 10)],\n            total_forms=1,\n            initial_forms=1,\n            max_num_forms=1,\n            min_num_forms=2,\n        )\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(len(formset.non_form_errors()), 1)\n        self.assertEqual(formset.non_form_errors()[0].code, 'too_few_forms')\n\n        formset = self.make_choiceformset(\n            formset_data=[('choice1', 10)],\n            total_forms=1,\n            initial_forms=1,\n            max_num_forms=1,\n            min_num_forms=1,\n        )\n        self.assertTrue(formset.is_valid())\n"], "sample_759": ["def test_ordinal_encoder():\n    # Test OrdinalEncoder with categorical data\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc = OrdinalEncoder()\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 2.], [1., 1.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array(X, dtype=object))\n\n    # Test OrdinalEncoder with numerical data\n    X = [[1, 2], [3, 4], [5, 6]]\n    enc = OrdinalEncoder()\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 1.], [2., 2.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array(X))\n\n    # Test OrdinalEncoder with mixed data\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc = OrdinalEncoder()\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 2.], [1., 1.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array(X, dtype=object))\n\n    # Test OrdinalEncoder with categories\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    categories = [['Male', 'Female'], [1, 2, 3]]\n    enc = OrdinalEncoder(categories=categories)\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 2.], [1., 1.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array(X, dtype=object))\n\n    # Test OrdinalEncoder with unknown categories\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    categories = [['Male', 'Female'], [1, 2]]\n    enc = OrdinalEncoder(categories=categories, handle_unknown='error')\n    with assert_raises(ValueError):\n        enc.fit_transform(X)\n\n    # Test OrdinalEncoder with handle_unknown='ignore'\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    categories = [['Male"], "sample_333": ["    def test_base_form_order_fields(self):\n        class MyForm(BaseForm):\n            field_order = ['field3', 'field1', 'field2']\n            field1 = CharField()\n            field2 = CharField()\n            field3 = CharField()\n\n        form = MyForm()\n        self.assertEqual(list(form.fields.keys()), ['field3', 'field1', 'field2'])\n\n        class MyForm2(BaseForm):\n            field_order = ['field3', 'field1']\n            field1 = CharField()\n            field2 = CharField()\n            field3 = CharField()\n\n        form = MyForm2()\n        self.assertEqual(list(form.fields.keys()), ['field3', 'field1', 'field2'])\n\n        class MyForm3(BaseForm):\n            field_order = None\n            field1 = CharField()\n            field2 = CharField()\n            field3 = CharField()\n\n        form = MyForm3()\n        self.assertEqual(list(form.fields.keys()), ['field1', 'field2', 'field3'])\n\n        class MyForm4(BaseForm):\n            field_order = ['field4', 'field1', 'field2']\n            field1 = CharField()\n            field2 = CharField()\n            field3 = CharField()\n\n        form = MyForm4()\n        self.assertEqual(list(form.fields.keys()), ['field1', 'field2', 'field3'])\n"], "sample_344": ["def test_project_state_resolve_fields_and_relations(self):\n    # Create a ProjectState with a model that has a foreign key to another model.\n    project_state = ProjectState()\n    model_state1 = ModelState(\n        'app_label1',\n        'Model1',\n        [\n            ('id', models.AutoField(primary_key=True)),\n            ('field1', models.CharField(max_length=255)),\n        ],\n    )\n    model_state2 = ModelState(\n        'app_label2',\n        'Model2',\n        [\n            ('id', models.AutoField(primary_key=True)),\n            ('field2', models.CharField(max_length=255)),\n            ('model1', models.ForeignKey('app_label1.Model1', on_delete=models.CASCADE)),\n        ],\n    )\n    project_state.add_model(model_state1)\n    project_state.add_model(model_state2)\n\n    # Resolve fields and relations.\n    project_state.resolve_fields_and_relations()\n\n    # Check that the relations are correctly resolved.\n    self.assertEqual(\n        project_state.relations,\n        {\n            ('app_label1', 'model1'): {\n                ('app_label2', 'model2'): [('model1', model_state2.fields['model1'])],\n            },\n        },\n    )\n"], "sample_1122": ["def test_polar_lift():\n    x = Symbol('x')\n    p = Symbol('p', polar=True)\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*p) == 4*p\n"], "sample_561": ["def test_marker_style_transformations(fig_test, fig_ref):\n    fig_test, ax_test = fig_test\n    fig_ref, ax_ref = fig_ref\n\n    marker = markers.MarkerStyle(\"o\")\n    marker_transformed = marker.transformed(Affine2D().rotate_deg(45).scale(2))\n\n    ax_test.plot([1, 2, 3], marker=marker_transformed, markersize=20)\n    ax_test.set_xlim(0, 4)\n    ax_test.set_ylim(0, 4)\n\n    ax_ref.plot([1, 2, 3], marker=\"o\", markersize=20)\n    ax_ref.set_xlim(0, 4)\n    ax_ref.set_ylim(0, 4)\n\n    ax_ref.plot([1, 2, 3], marker=\"o\", markersize=20, linestyle=\"--\",\n                transform=Affine2D().rotate_deg(45).scale(2) + ax_ref.transData)\n\n    ax_test.set_aspect('equal')\n    ax_ref.set_aspect('equal')\n"], "sample_1010": ["def test_latex():\n    # Test latex printing of latex printer\n    assert latex(x) == 'x'\n    assert latex(x, mode='inline') == '$x$'\n    assert latex(x, mode='equation') == r'\\begin{equation}x\\end{equation}'\n    assert latex(x, mode='equation*', fold_frac_powers=True) == r'\\begin{equation*}x\\end{equation*}'\n    assert latex(x, mode='plain', fold_frac_powers=True) == 'x'\n    assert latex(x, mode='inline', fold_frac_powers=True) == '$x$'\n    assert latex(x, mode='equation', fold_frac_powers=True) == r'\\begin{equation}x\\end{equation}'\n    assert latex(x, mode='equation*', fold_frac_powers=True) == r'\\begin{equation*}x\\end{equation*}'\n\n    # Test latex printing of latex printer with itex\n    assert latex(x, mode='inline', itex=True) == '$$x$$'\n    assert latex(x, mode='equation', itex=True) == '$$x$$'\n    assert latex(x, mode='equation*', itex=True) == '$$x$$'\n    assert latex(x, mode='plain', itex=True) == 'x'\n\n    # Test latex printing of latex printer with itex and fold_frac_powers\n    assert latex(x, mode='inline', itex=True, fold_frac_powers=True) == '$$x$$'\n    assert latex(x, mode='equation', itex=True, fold_frac_powers=True) == '$$x$$'\n    assert latex(x, mode='equation*', itex=True, fold_frac_powers=True) == '$$x$$'\n    assert latex(x, mode='plain', itex=True, fold_frac_powers=True) == 'x'\n\n    # Test latex printing of latex printer with mul_symbol\n    assert latex(x, mode='inline', mul_symbol='ldot') == '$x$'\n    assert latex(x, mode='equation', mul_symbol='ldot') == r'\\begin{equation}x\\end{equation}'\n    assert latex(x, mode='equation*', mul_symbol='ldot') == r'\\begin{equation*}x\\end{equation*}'\n    assert latex(x, mode='plain',"], "sample_562": ["def test_line2d_markevery():\n    fig, ax = plt.subplots()\n    x = np.arange(10)\n    y = np.arange(10)\n    line, = ax.plot(x, y, 'o-')\n\n    # Test markevery with int\n    line.set_markevery(2)\n    assert_array_equal(line.get_markevery(), 2)\n\n    # Test markevery with tuple\n    line.set_markevery((1, 2))\n    assert_array_equal(line.get_markevery(), (1, 2))\n\n    # Test markevery with slice\n    line.set_markevery(slice(1, 5, 2))\n    assert_array_equal(line.get_markevery(), slice(1, 5, 2))\n\n    # Test markevery with list\n    line.set_markevery([1, 3, 5])\n    assert_array_equal(line.get_markevery(), [1, 3, 5])\n\n    # Test markevery with float\n    line.set_markevery(0.5)\n    assert_array_equal(line.get_markevery(), 0.5)\n\n    # Test markevery with tuple of floats\n    line.set_markevery((0.1, 0.5))\n    assert_array_equal(line.get_markevery(), (0.1, 0.5))\n\n    # Test markevery with invalid input\n    with pytest.raises(ValueError):\n        line.set_markevery('invalid')\n\n    plt.close(fig)\n"], "sample_1096": ["def test_IndexedBase():\n    # Test IndexedBase creation\n    A = IndexedBase('A')\n    assert A.name == 'A'\n    assert A.label == 'A'\n    assert A.shape is None\n    assert A.offset == 0\n    assert A.strides is None\n\n    # Test IndexedBase creation with shape\n    A = IndexedBase('A', shape=(3, 4))\n    assert A.name == 'A'\n    assert A.label == 'A'\n    assert A.shape == (3, 4)\n    assert A.offset == 0\n    assert A.strides is None\n\n    # Test IndexedBase creation with strides\n    A = IndexedBase('A', strides=(2, 3))\n    assert A.name == 'A'\n    assert A.label == 'A'\n    assert A.shape is None\n    assert A.offset == 0\n    assert A.strides == (2, 3)\n\n    # Test IndexedBase creation with offset\n    A = IndexedBase('A', offset=5)\n    assert A.name == 'A'\n    assert A.label == 'A'\n    assert A.shape is None\n    assert A.offset == 5\n    assert A.strides is None\n\n    # Test IndexedBase creation with Symbol\n    x = Symbol('x', integer=True)\n    A = IndexedBase(x)\n    assert A.name == 'x'\n    assert A.label == x\n    assert A.shape is None\n    assert A.offset == 0\n    assert A.strides is None\n\n    # Test IndexedBase creation with Symbol and shape\n    x = Symbol('x', integer=True)\n    A = IndexedBase(x, shape=(3, 4))\n    assert A.name == 'x'\n    assert A.label == x\n    assert A.shape == (3, 4)\n    assert A.offset == 0\n    assert A.strides is None\n\n    # Test IndexedBase creation with Symbol and strides\n    x = Symbol('x', integer=True)\n    A = IndexedBase(x, strides=(2, 3))\n    assert A.name == 'x'\n    assert A.label == x\n    assert A.shape is None\n    assert A.offset == 0\n    assert A.strides == (2, 3)\n\n    # Test IndexedBase creation with Symbol and offset\n    x = Symbol('x', integer=True)\n    A = IndexedBase(x, offset=5)\n    assert A.name =="], "sample_607": ["def test_detect_parameters():\n    with pytest.raises(TypeError):\n        detect_parameters(DummyBackendEntrypointArgs.open_dataset)\n\n    with pytest.raises(TypeError):\n        detect_parameters(DummyBackendEntrypointKwargs.open_dataset)\n\n    assert detect_parameters(DummyBackendEntrypoint1.open_dataset) == (\"decoder\",)\n\n"], "sample_1112": ["def test_digits():\n    assert digits(35) == [10, 3, 5]\n    assert digits(-35) == [-10, 3, 5]\n    assert digits(27, b=2) == [2, 1, 1, 0, 1, 1]\n    assert digits(35, digits=4) == [10, 0, 0, 3, 5]\n    raises(ValueError, lambda: digits(35, b=1))\n    raises(ValueError, lambda: digits(35, digits=2))\n"], "sample_592": ["def test_format_array_flat():\n    array = np.arange(100)\n    assert formatting.format_array_flat(array, 80) == \"0 1 2 ... 97 98 99\"\n\n    array = np.arange(1000)\n    assert formatting.format_array_flat(array, 80) == \"0 1 2 ... 997 998 999\"\n\n    array = np.arange(1000000)\n    assert formatting.format_array_flat(array, 80) == \"0 1 2 ... 999997 999998 999999\"\n\n    array = np.array([1, 2, 3])\n    assert formatting.format_array_flat(array, 80) == \"1 2 3\"\n\n    array = np.array([])\n    assert formatting.format_array_flat(array, 80) == \"\"\n"], "sample_1121": ["def test_mul_as_coefficients_dict():\n    expr = 3*a*x*y\n    d = expr.as_coefficients_dict()\n    assert d == {a*x*y: 3}\n    assert d[a] == 0\n    assert d[x] == 0\n    assert d[y] == 0\n"], "sample_97": ["    def test_tick(self):\n        reloader = autoreload.StatReloader()\n        ticker = reloader.tick()\n        next(ticker)\n        self.assertTrue(reloader.should_stop)\n"], "sample_72": ["    def test_serializer_factory_with_lazy_object(self):\n        lazy_object = SimpleLazyObject(lambda: 'lazy_value')\n        serializer = serializer_factory(lazy_object)\n        self.assertIsInstance(serializer, BaseSimpleSerializer)\n"], "sample_574": ["    def x(self):\n        return pd.Series(\n            [\"2022-01-01\", \"2022-01-15\", \"2022-02-01\"],\n            name=\"x\",\n            dtype=\"datetime64[ns]\",\n        )\n"], "sample_617": ["def test_apply_ufunc_with_dask():\n    if not has_dask:\n        pytest.skip(\"dask is not installed or imported\")\n\n    # Test that apply_ufunc works with dask arrays\n    a = xr.DataArray(np.random.rand(10, 10), dims=[\"x\", \"y\"])\n    b = xr.DataArray(np.random.rand(10, 10), dims=[\"x\", \"y\"])\n    a_dask = a.chunk()\n    b_dask = b.chunk()\n\n    result = apply_ufunc(np.add, a_dask, b_dask, dask=\"allowed\")\n    expected = apply_ufunc(np.add, a, b)\n    assert_identical(result, expected)\n\n    # Test that apply_ufunc works with dask arrays and parallelized\n    result = apply_ufunc(np.add, a_dask, b_dask, dask=\"parallelized\")\n    expected = apply_ufunc(np.add, a, b)\n    assert_identical(result, expected)\n\n    # Test that apply_ufunc raises an error when dask arrays are not allowed\n    with pytest.raises(ValueError):\n        apply_ufunc(np.add, a_dask, b_dask, dask=\"forbidden\")\n\n    # Test that apply_ufunc works with dask arrays and output_dtypes\n    result = apply_ufunc(\n        np.add, a_dask, b_dask, dask=\"parallelized\", output_dtypes=[np.float64]\n    )\n    expected = apply_ufunc(np.add, a, b)\n    assert_identical(result, expected)\n\n    # Test that apply_ufunc works with dask arrays and dask_gufunc_kwargs\n    result = apply_ufunc(\n        np.add,\n        a_dask,\n        b_dask,\n        dask=\"parallelized\",\n        dask_gufunc_kwargs={\"allow_rechunk\": True},\n    )\n    expected = apply_ufunc(np.add, a, b)\n    assert_identical(result, expected)\n\n    # Test that apply_ufunc works with dask arrays and meta\n    result = apply_ufunc(\n        np.add,\n        a_dask,\n        b_dask,\n        dask=\"parallelized\",\n        meta=np.ndarray,\n    )\n    expected = apply_ufunc(np.add, a, b)\n    assert_identical(result, expected)\n\n    # Test that apply_ufunc works with dask arrays"], "sample_157": ["def test_test_db_signature(self):\n    test_connection = get_connection_copy()\n    creation = BaseDatabaseCreation(test_connection)\n    signature = creation.test_db_signature()\n    self.assertEqual(len(signature), 4)\n    self.assertEqual(signature[0], test_connection.settings_dict['HOST'])\n    self.assertEqual(signature[1], test_connection.settings_dict['PORT'])\n    self.assertEqual(signature[2], test_connection.settings_dict['ENGINE'])\n    self.assertEqual(signature[3], TEST_DATABASE_PREFIX + test_connection.settings_dict['NAME'])\n"], "sample_56": ["    def test_check_autocomplete_fields(self):\n        class MyAdmin(admin.ModelAdmin):\n            autocomplete_fields = ['author']\n\n        ma = MyAdmin(Album, AdminSite())\n        errors = ma.check()\n        self.assertEqual(len(errors), 0)\n\n        class MyAdmin(admin.ModelAdmin):\n            autocomplete_fields = ['nonexistent']\n\n        ma = MyAdmin(Album, AdminSite())\n        errors = ma.check()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'admin.E037')\n"], "sample_677": ["def test_parse_error():\n    with pytest.raises(ParseError) as exc_info:\n        Expression.compile(\"invalid input\")\n    assert exc_info.value.column == 1\n    assert exc_info.value.message == 'unexpected character \"i\"'\n"], "sample_71": ["def test_format_decimal(self):\n    # Test formatting of Decimal instances\n    self.assertEqual(nformat(Decimal('12345.6789'), decimal_sep='.', decimal_pos=2), '12,345.68')\n    self.assertEqual(nformat(Decimal('-12345.6789'), decimal_sep='.', decimal_pos=2), '-12,345.68')\n    self.assertEqual(nformat(Decimal('12345.6789'), decimal_sep=',', decimal_pos=2), '12.345,68')\n    self.assertEqual(nformat(Decimal('-12345.6789'), decimal_sep=',', decimal_pos=2), '-12.345,68')\n\n    # Test formatting of very small Decimal instances\n    self.assertEqual(nformat(Decimal('0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_833": ["def test_logistic_regression_path_multiclass():\n    # Test logistic_regression_path with multiclass classification\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5,\n                               n_redundant=0, n_repeated=0, n_classes=3,\n                               random_state=1)\n    Cs = [1, 10]\n    fit_intercept = True\n    solver = 'lbfgs'\n    multi_class = 'multinomial'\n    tol = 1e-4\n    max_iter = 100\n    verbose = 0\n    random_state = 1\n    check_input = True\n    max_squared_sum = None\n    sample_weight = None\n    l1_ratio = None\n\n    coefs, Cs, n_iter = _logistic_regression_path(\n        X, y, Cs=Cs, fit_intercept=fit_intercept, solver=solver,\n        max_iter=max_iter, tol=tol, verbose=verbose,\n        multi_class=multi_class, random_state=random_state,\n        check_input=check_input, max_squared_sum=max_squared_sum,\n        sample_weight=sample_weight, l1_ratio=l1_ratio)\n\n    assert coefs.shape == (len(Cs), 3, X.shape[1] + int(fit_intercept))\n    assert len(Cs) == len(n_iter)\n"], "sample_753": ["def test_logistic_regression_path():\n    # Test logistic_regression_path with different solvers\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5,\n                               n_redundant=3, n_classes=2, random_state=0)\n    Cs = [0.1, 1, 10]\n    for solver in ['lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga']:\n        coefs, Cs, n_iter = logistic_regression_path(X, y, Cs=Cs,\n                                                     solver=solver)\n        assert len(coefs) == len(Cs)\n        assert len(n_iter) == len(Cs)\n\n    # Test logistic_regression_path with multinomial solver\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5,\n                               n_redundant=3, n_classes=3, random_state=0)\n    Cs = [0.1, 1, 10]\n    for solver in ['lbfgs', 'newton-cg', 'sag', 'saga']:\n        coefs, Cs, n_iter = logistic_regression_path(X, y, Cs=Cs,\n                                                     solver=solver,\n                                                     multi_class='multinomial')\n        assert len(coefs) == len(Cs)\n        assert len(n_iter) == len(Cs)\n\n    # Test logistic_regression_path with warm start\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5,\n                               n_redundant=3, n_classes=2, random_state=0)\n    Cs = [0.1, 1, 10]\n    coefs, Cs, n_iter = logistic_regression_path(X, y, Cs=Cs,\n                                                 solver='lbfgs')\n    coefs_warm, Cs_warm, n_iter_warm = logistic_regression_path(X, y, Cs=Cs,\n                                                                solver='lbfgs',\n                                                                coef=coefs[0])\n    assert_array_almost_equal(coefs, coefs_warm)\n\n    # Test logistic_regression_path with sample weights\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5,\n                               n_redundant=3, n_classes=2, random_state=0)\n    Cs = [0.1, 1, 10]\n    sample_weight"], "sample_664": ["def test_deprecated_external_plugins():\n    assert isinstance(DEPRECATED_EXTERNAL_PLUGINS, set)\n    assert len(DEPRECATED_EXTERNAL_PLUGINS) == 3\n    assert \"pytest_catchlog\" in DEPRECATED_EXTERNAL_PLUGINS\n    assert \"pytest_capturelog\" in DEPRECATED_EXTERNAL_PLUGINS\n    assert \"pytest_faulthandler\" in DEPRECATED_EXTERNAL_PLUGINS\n"], "sample_968": ["def test_parse_annotation():\n    env = Mock(spec=['config'])\n    env.config.python_use_unqualified_type_names = False\n\n    # Test simple type\n    annotation = 'int'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n\n    # Test type with module\n    annotation = 'module.Type'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n\n    # Test type with module and class\n    annotation = 'module.Class.Type'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n\n    # Test type with nested modules and classes\n    annotation = 'module1.module2.Class1.Class2.Type'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n\n    # Test type with generics\n    annotation = 'List[int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 3\n    assert isinstance(result[0], desc_sig_punctuation)\n    assert isinstance(result[1], pending_xref)\n    assert isinstance(result[2], desc_sig_punctuation)\n\n    # Test type with multiple generics\n    annotation = 'Dict[str, int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 5\n    assert isinstance(result[0], desc_sig_punctuation)\n    assert isinstance(result[1], pending_xref)\n    assert isinstance(result[2], desc_sig_punctuation)\n    assert isinstance(result[3], pending_xref)\n    assert isinstance(result[4], desc_sig_punctuation)\n\n    # Test type with nested generics\n    annotation = 'List[Dict[str, int]]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 7\n    assert isinstance(result[0], desc_sig_punctuation)\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert isinstance(result[2], pending_xref)\n    assert isinstance(result[3], desc_sig_punctuation)\n    assert isinstance(result[4], pending_xref)\n    assert isinstance(result[5], desc_sig_punctuation)\n    assert isinstance(result[6], desc_sig_punctuation)\n\n    # Test type with tuple\n    annotation = '(int, str"], "sample_326": ["def test_urlize(self):\n    self.check_output(urlize, 'Hello world!')\n    self.check_output(urlize, 'Visit https://www.djangoproject.com for more info.')\n    self.check_output(urlize, 'Visit www.djangoproject.com for more info.')\n    self.check_output(urlize, 'Visit http://www.djangoproject.com for more info.')\n    self.check_output(urlize, 'Visit http://example.com/path/to/page for more info.')\n    self.check_output(urlize, 'Visit http://example.com/path/to/page?query=string for more info.')\n    self.check_output(urlize, 'Visit http://example.com/path/to/page#anchor for more info.')\n    self.check_output(urlize, 'Visit http://example.com/path/to/page?query=string#anchor for more info.')\n    self.check_output(urlize, 'Visit http://example.com/path/to/page?query=string&another=query for more info.')\n    self.check_output(urlize, 'Visit http://example.com/path/to/page?query=string&another=query#anchor for more info.')\n    self.check_output(urlize, 'Visit http://example.com/path/to/page?query=string&another=query#anchor with spaces.')\n    self.check_output(urlize, 'Visit http://example.com/path/to/page?query=string&another=query#anchor with spaces.', \n                      'Visit <a href=\"http://example.com/path/to/page?query=string&amp;another=query#anchor\" rel=\"nofollow\">http://example.com/path/to/page?query=string&amp;another=query#anchor</a> with spaces.')\n    self.check_output(urlize, 'Visit http://example.com/path/to/page?query=string&another=query#anchor with spaces.', \n                      'Visit <a href=\"http://example.com/path/to/page?query=string&amp;another=query#anchor\" rel=\"nofollow\">http://example.com/path/to/page?query=string&amp;another=query#anchor</a> with spaces.', \n                      autoescape=True)\n    self.check_output(urlize, 'Visit http://example.com/path/to/page?query=string&another=query#anchor with spaces.', \n                      'Visit <a href=\"http://example.com/path/to/page?query=string&amp;another=query#anchor\" rel=\"nofollow\">http://example.com/path/to/page?query=string&amp;another=query#anchor</a> with spaces.', \n                      trim_url_limit=50)\n    self.check_output(urlize,"], "sample_746": ["def test_hinge_loss_multiclass():\n    # Test multiclass hinge loss\n    X = np.array([[0], [1], [2], [3]])\n    Y = np.array([0, 1, 2, 3])\n    labels = np.array([0, 1, 2, 3])\n    est = svm.LinearSVC()\n    est.fit(X, Y)\n    pred_decision = est.decision_function([[0], [1], [2]])\n    y_true = [0, 1, 2]\n    assert_almost_equal(hinge_loss(y_true, pred_decision, labels), 0.66666667)\n"], "sample_104": ["    def test_hashed_name(self):\n        name = 'path/to/file.css'\n        content = b'body { background-color: #f2f2f2; }'\n        hashed_name = storage.staticfiles_storage.hashed_name(name, content=content)\n        self.assertIn('path/to/file.', hashed_name)\n        self.assertIn('.css', hashed_name)\n"], "sample_91": ["    def test_page_not_found(self):\n        request = self.request_factory.get('/nonexistent_url/')\n        response = page_not_found(request, Http404())\n        self.assertEqual(response.status_code, 404)\n        self.assertTemplateUsed(response, '404.html')\n"], "sample_77": ["def test_avoid_wrapping(self):\n    self.check_output(avoid_wrapping, \"Hello World\", \"Hello\\xa0World\")\n    self.check_output(avoid_wrapping, \"   Hello   World   \", \"\\xa0\\xa0\\xa0Hello\\xa0\\xa0World\\xa0\\xa0\")\n    self.check_output(avoid_wrapping, \"No spaces\", \"No spaces\")\n"], "sample_477": ["    def test_addslashes(self):\n        output = self.engine.render_to_string(\"addslashes01\")\n        self.assertEqual(output, \"Hello \\\\'World\\' Hello \\\\\\\"World\\\\\\\"\")\n"], "sample_301": ["    def test_watchman_reloader(self):\n        reloader = autoreload.WatchmanReloader()\n        self.assertTrue(reloader.check_availability())\n"], "sample_669": ["    def test_suspend_and_resume(self, method):\n        capman = CaptureManager(method)\n        capman.start_global_capturing()\n        capman.suspend_global_capture()\n        assert capman.is_capturing() == \"global\"\n        capman.resume_global_capture()\n        assert capman.is_capturing() == \"global\"\n        capman.stop_global_capturing()\n        assert capman.is_capturing() is False\n"], "sample_991": ["def test_product():\n    assert product(k, (k, 1, n)).doit() == factorial(n)\n    assert product(k**2, (k, 1, n)).doit() == factorial(n)**2\n    assert product(2, (k, 1, n)).doit() == 2**n\n    assert product(2, (k, n, 1)).doit() == 2**(1-n)\n    assert product(1/k, (k, 1, n)).doit() == 1/factorial(n)\n    assert product(1/k, (k, n, 1)).doit() == factorial(n-1)\n    assert product(k, (k, n, n)).doit() == n\n    assert product(k, (k, n, n-1)).doit() == 1\n    assert product(k, (k, n+1, n)).doit() == 1\n    assert product(2*k, (k, 1, n)).doit() == 2**n * factorial(n)\n    assert product(2, (k, 1, n), (n, 1, m)).doit() == 2**(m*n)\n    assert product(k, (k, 1, n), (n, 1, m)).doit() == Product(factorial(n), (n, 1, m))\n    assert product(2, (k, 1, n), (n, 1, m)).doit() == 2**(m*n)\n    assert product(2, (k, 1, n), (n, m, m)).doit() == 2**(n)\n    assert product(2, (k, 1, n), (n, m, m-1)).doit() == 2**(n)\n    assert product(2, (k, 1, n), (n, m+1, m)).doit() == 1\n    assert product(2, (k, 1, n), (n, m, m)).doit() == 2**n\n    assert product(2, (k, 1, n), (n, m, m-1)).doit() == 2**n\n    assert product(2, (k, 1, n), (n, m+1,"], "sample_1198": ["def test_parse_mathematica():\n    parser = MathematicaParser()\n    assert parser.parse(\"x + y\") == x + y\n    assert parser.parse(\"x * y\") == x * y\n    assert parser.parse(\"x / y\") == x / y\n    assert parser.parse(\"x ^ y\") == x ** y\n    assert parser.parse(\"Sin[x]\") == sin(x)\n    assert parser.parse(\"Cos[x]\") == cos(x)\n    assert parser.parse(\"Tan[x]\") == tan(x)\n    assert parser.parse(\"Log[x]\") == log(x)\n    assert parser.parse(\"Exp[x]\") == exp(x)\n    assert parser.parse(\"Sqrt[x]\") == sqrt(x)\n    assert parser.parse(\"Max[x, y]\") == Max(x, y)\n    assert parser.parse(\"Min[x, y]\") == Min(x, y)\n    assert parser.parse(\"Mod[x, y]\") == Mod(x, y)\n    assert parser.parse(\"Pochhammer[x, y]\") == rf(x, y)\n    assert parser.parse(\"ArcTan[x, y]\") == atan2(y, x)\n    assert parser.parse(\"ExpIntegralEi[x]\") == Ei(x)\n    assert parser.parse(\"SinIntegral[x]\") == Si(x)\n    assert parser.parse(\"CosIntegral[x]\") == Ci(x)\n    assert parser.parse(\"AiryAi[x]\") == airyai(x)\n    assert parser.parse(\"AiryAiPrime[x]\") == airyaiprime(x)\n    assert parser.parse(\"AiryBi[x]\") == airybi(x)\n    assert parser.parse(\"AiryBiPrime[x]\") == airybiprime(x)\n    assert parser.parse(\"LogIntegral[x]\") == li(x)\n    assert parser.parse(\"PrimePi[x]\") == primepi(x)\n    assert parser.parse(\"Prime[x]\") == prime(x)\n    assert parser.parse(\"PrimeQ[x]\") == isprime(x)\n"], "sample_51": ["def test_parse_duration(self):\n    # Test standard duration format\n    self.assertEqual(parse_duration('1 02:03:04.123456'), timedelta(days=1, hours=2, minutes=3, seconds=4, microseconds=123456))\n    self.assertEqual(parse_duration('-1 02:03:04.123456'), -timedelta(days=1, hours=2, minutes=3, seconds=4, microseconds=123456))\n\n    # Test ISO 8601 duration format\n    self.assertEqual(parse_duration('P1DT2H3M4S'), timedelta(days=1, hours=2, minutes=3, seconds=4))\n    self.assertEqual(parse_duration('-P1DT2H3M4S'), -timedelta(days=1, hours=2, minutes=3, seconds=4))\n\n    # Test PostgreSQL's day-time interval format\n    self.assertEqual(parse_duration('1 day 02:03:04.123456'), timedelta(days=1, hours=2, minutes=3, seconds=4, microseconds=123456))\n    self.assertEqual(parse_duration('-1 day 02:03:04.123456'), -timedelta(days=1, hours=2, minutes=3, seconds=4, microseconds=123456))\n\n    # Test invalid duration formats\n    self.assertIsNone(parse_duration('invalid'))\n    self.assertIsNone(parse_duration('1 02:03:04:05'))\n"], "sample_449": ["def test_handle_one_request(self):\n    # Create a stub request\n    request = self.request_factory.get(\"/\")\n\n    # Create a stub socket\n    socket = Stub(\n        makefile=lambda mode: UnclosableBytesIO(b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\"),\n        getpeername=lambda: (\"127.0.0.1\", 12345),\n        getsockname=lambda: (\"127.0.0.1\", 80),\n    )\n\n    # Create a WSGIRequestHandler instance\n    handler = WSGIRequestHandler(socket, (\"127.0.0.1\", 80), WSGIServer())\n\n    # Call handle_one_request\n    with captured_stderr() as stderr:\n        handler.handle_one_request()\n\n    # Check that the request was handled correctly\n    self.assertEqual(stderr.getvalue(), \"\")\n\n    # Check that the response was sent correctly\n    self.assertEqual(socket.makefile(\"rb\").read(), b\"HTTP/1.1 200 OK\\r\\n\\r\\n\")\n\n    # Check that the connection was closed\n    self.assertTrue(handler.close_connection)\n"], "sample_355": ["    def setUpTestData(cls):\n        cls.permission = Permission.objects.create(\n            name='Test permission',\n            codename='test_permission',\n            content_type=ContentType.objects.get_for_model(User)\n        )\n"], "sample_963": ["def test_restify():\n    assert restify(None) == ':py:obj:`None`'\n    assert restify(int) == ':py:class:`int`'\n    assert restify(Struct) == ':py:class:`struct.Struct`'\n    assert restify(TracebackType) == ':py:class:`types.TracebackType`'\n    assert restify(MyClass1) == ':py:class:`test_util_typing.MyClass1`'\n    assert restify(MyClass2) == ':py:class:`<MyClass2>`'\n    assert restify(MyInt) == ':py:class:`test_util_typing.MyInt`'\n    assert restify(MyList[int]) == ':py:class:`test_util_typing.MyList`\\\\ [int]'\n    assert restify(Union[int, str]) == ':py:obj:`~typing.Union`\\\\ [int, str]'\n    assert restify(Optional[int]) == ':py:obj:`~typing.Optional`\\\\ [int]'\n    assert restify(Callable[[int], str]) == ':py:obj:`~typing.Callable`\\\\ [[int], str]'\n    assert restify(Dict[str, int]) == ':py:class:`dict`\\\\ [str, int]'\n    assert restify(List[int]) == ':py:class:`list`\\\\ [int]'\n    assert restify(Tuple[int, str]) == ':py:class:`tuple`\\\\ [int, str]'\n    assert restify(Generator[int, str, float]) == ':py:class:`generator`\\\\ [int, str, float]'\n"], "sample_159": ["    def test_check_user_model_is_anonymous_is_method(self):\n        class CustomUser(AbstractBaseUser):\n            is_anonymous = lambda self: True\n\n        with self.settings(AUTH_USER_MODEL='auth_tests.CustomUser'):\n            errors = check_user_model()\n            self.assertEqual(len(errors), 1)\n            self.assertEqual(errors[0].id, 'auth.C009')\n"], "sample_20": ["def test_read_table_fits_with_memmap(self):\n    # Create a FITS file with a table\n    filename = get_pkg_data_filename(\"data/table.fits\")\n    with fits.open(filename) as hdul:\n        table_hdu = hdul[1]\n        table = Table(table_hdu.data)\n\n    # Read the table with memmap=True\n    with fits.open(filename, memmap=True) as hdul:\n        memmap_table = Table(hdul[1].data)\n\n    # Check that the tables are equal\n    assert table == memmap_table\n\n    # Check that the data is not loaded into memory\n    assert memmap_table[\"a\"].data.flags[\"WRITEABLE\"] is False\n    assert memmap_table[\"b\"].data.flags[\"WRITEABLE\"] is False\n    assert memmap_table[\"c\"].data.flags[\"WRITEABLE\"] is False\n\n    # Check that the data is loaded into memory when accessed\n    assert memmap_table[\"a\"].data.flags[\"WRITEABLE\"] is True\n    assert memmap_table[\"b\"].data.flags[\"WRITEABLE\"] is True\n    assert memmap_table[\"c\"].data.flags[\"WRITEABLE\"] is True\n\n    # Check that the table can be written to a new file\n    new_filename = \"test.fits\"\n    memmap_table.write(new_filename, format=\"fits\")\n    with fits.open(new_filename) as hdul:\n        new_table = Table(hdul[1].data)\n    assert table == new_table\n    os.remove(new_filename)\n"], "sample_213": ["    def test_field_file_init(self):\n        instance = object()\n        field = FileField()\n        name = 'test.txt'\n        field_file = FieldFile(instance, field, name)\n        self.assertEqual(field_file.instance, instance)\n        self.assertEqual(field_file.field, field)\n        self.assertEqual(field_file.storage, default_storage)\n        self.assertEqual(field_file.name, name)\n"], "sample_249": ["    def test_test_db_signature(self):\n        test_connection = get_connection_copy()\n        creation = BaseDatabaseCreation(test_connection)\n        signature = creation.test_db_signature()\n        self.assertEqual(len(signature), 4)\n        self.assertEqual(signature[0], test_connection.settings_dict['HOST'])\n        self.assertEqual(signature[1], test_connection.settings_dict['PORT'])\n        self.assertEqual(signature[2], test_connection.settings_dict['ENGINE'])\n        self.assertEqual(signature[3], TEST_DATABASE_PREFIX + test_connection.settings_dict['NAME'])\n"], "sample_389": ["    def test_get_host(self):\n        request = HttpRequest()\n        request.META = {\n            \"HTTP_HOST\": \"example.com\",\n            \"SERVER_NAME\": \"example.com\",\n            \"SERVER_PORT\": \"80\",\n        }\n        self.assertEqual(request.get_host(), \"example.com\")\n"], "sample_658": ["def test_is_mocked():\n    class MockObject:\n        pytest_mock_example_attribute_that_shouldnt_exist = True\n\n    assert _is_mocked(MockObject())\n    assert not _is_mocked(object())\n"], "sample_583": ["    def test_expanded_indexer(self):\n        assert indexing.expanded_indexer(1, 3) == (1, slice(None), slice(None))\n        assert indexing.expanded_indexer(slice(1, 2), 3) == (slice(1, 2), slice(None), slice(None))\n        assert indexing.expanded_indexer((1, slice(1, 2)), 3) == (1, slice(1, 2), slice(None))\n        assert indexing.expanded_indexer((1, slice(1, 2), 3), 3) == (1, slice(1, 2), 3)\n        assert indexing.expanded_indexer((1, slice(1, 2), 3, 4), 3) == (1, slice(1, 2), 3)\n        assert indexing.expanded_indexer(..., 3) == (slice(None), slice(None), slice(None))\n        assert indexing.expanded_indexer((..., 1), 3) == (slice(None), slice(None), 1)\n        assert indexing.expanded_indexer((1, ...), 3) == (1, slice(None), slice(None))\n        assert indexing.expanded_indexer((1, ..., 2), 3) == (1, slice(None), 2)\n        with pytest.raises(IndexError):\n            indexing.expanded_indexer((1, 2, 3, 4), 3)\n"], "sample_131": ["def test_test_db_signature(self):\n    test_connection = self.get_connection_copy()\n    creation = BaseDatabaseCreation(test_connection)\n    signature = creation.test_db_signature()\n    self.assertEqual(len(signature), 4)\n    self.assertEqual(signature[0], test_connection.settings_dict['HOST'])\n    self.assertEqual(signature[1], test_connection.settings_dict['PORT'])\n    self.assertEqual(signature[2], test_connection.settings_dict['ENGINE'])\n    self.assertEqual(signature[3], TEST_DATABASE_PREFIX + test_connection.settings_dict['NAME'])\n"], "sample_1123": ["def test_conditionset():\n    # Test ConditionSet with a condition that is a finite set\n    condition = FiniteSet(1, 2, 3)\n    cs = ConditionSet(x, condition, S.Integers)\n    assert cs == ConditionSet(x, Eq(x, 1) | Eq(x, 2) | Eq(x, 3), S.Integers)\n\n    # Test ConditionSet with a condition that is a finite set and a non-symbol dummy\n    condition = FiniteSet(x + 1, x + 2, x + 3)\n    with raises(ValueError):\n        ConditionSet(x + 1, condition, S.Integers)\n\n    # Test ConditionSet with a condition that is a finite set and a non-symbol dummy\n    condition = FiniteSet(x + 1, x + 2, x + 3)\n    cs = ConditionSet(x, condition, S.Integers)\n    assert cs == ConditionSet(x, Eq(x + 1, 0) | Eq(x + 2, 0) | Eq(x + 3, 0), S.Integers)\n\n    # Test ConditionSet with a condition that is a finite set and a non-symbol dummy\n    condition = FiniteSet(x + 1, x + 2, x + 3)\n    cs = ConditionSet(x + 1, condition, S.Integers)\n    assert cs == ConditionSet(x, Eq(x + 1, 0) | Eq(x + 2, 0) | Eq(x + 3, 0), S.Integers)\n\n    # Test ConditionSet with a condition that is a finite set and a non-symbol dummy\n    condition = FiniteSet(x + 1, x + 2, x + 3)\n    cs = ConditionSet(x + 1, condition, S.Integers)\n    assert cs == ConditionSet(x, Eq(x + 1, 0) | Eq(x + 2, 0) | Eq(x + 3, 0), S.Integers)\n\n    # Test ConditionSet with a condition that is a finite set and a non-symbol dummy\n    condition = FiniteSet(x + 1, x + 2, x + 3)\n    cs = ConditionSet(x + 1, condition, S.Integers)\n    assert cs == ConditionSet(x, Eq(x + 1, 0) | Eq(x + 2, 0) | Eq(x + 3"], "sample_739": ["def test_inverse_binarize_thresholding():\n    # Test binary classification\n    y = np.array([[0.7, 0.3], [0.4, 0.6]])\n    y_binarized = np.array([[1, 0], [0, 1]])\n    assert_array_equal(_inverse_binarize_thresholding(y, \"binary\", [0, 1], 0.5),\n                       y_binarized)\n\n    # Test multiclass classification\n    y = np.array([[0.7, 0.2, 0.1], [0.1, 0.7, 0.2]])\n    y_binarized = np.array([[1, 0, 0], [0, 1, 0]])\n    assert_array_equal(_inverse_binarize_thresholding(y, \"multiclass\", [0, 1, 2], 0.5),\n                       y_binarized)\n\n    # Test multilabel classification\n    y = np.array([[0.7, 0.3], [0.4, 0.6]])\n    y_binarized = np.array([[1, 0], [0, 1]])\n    assert_array_equal(_inverse_binarize_thresholding(y, \"multilabel-indicator\", [0, 1], 0.5),\n                       y_binarized)\n\n    # Test with sparse matrix\n    y = csr_matrix(np.array([[0.7, 0.3], [0.4, 0.6]]))\n    y_binarized = np.array([[1, 0], [0, 1]])\n    assert_array_equal(_inverse_binarize_thresholding(y, \"binary\", [0, 1], 0.5),\n                       y_binarized)\n\n    # Test with threshold other than 0.5\n    y = np.array([[0.7, 0.3], [0.4, 0.6]])\n    y_binarized = np.array([[1, 0], [0, 1]])\n    assert_array_equal(_inverse_binarize_thresholding(y, \"binary\", [0, 1], 0.4),\n                       y_binarized)\n\n    # Test with threshold None\n    y = np.array([[0.7, 0.3], [0.4, 0.6]])\n    y_binarized = np.array([[1,"], "sample_612": ["def test_groupby_quantile():\n    # Create a test dataset\n    np.random.seed(0)\n    data = np.random.randn(3, 4, 2)\n    ds = xr.Dataset({\"foo\": ((\"x\", \"y\", \"z\"), data)}, {\"x\": [\"a\", \"b\", \"c\"], \"y\": [1, 2, 3, 4], \"z\": [1, 2]})\n\n    # Group by dimension 'x' and calculate quantiles\n    grouped = ds.groupby(\"x\")\n    quantiles = grouped.quantile(0.5, dim=\"y\")\n\n    # Check the result\n    expected = np.array([[data[0, 1, 0], data[0, 3, 0]], [data[1, 1, 0], data[1, 3, 0]], [data[2, 1, 0], data[2, 3, 0]]])\n    assert_array_equal(quantiles, expected)\n\n    # Group by dimension 'y' and calculate quantiles\n    grouped = ds.groupby(\"y\")\n    quantiles = grouped.quantile(0.5, dim=\"x\")\n\n    # Check the result\n    expected = np.array([[data[1, 0, 0], data[1, 0, 1]], [data[1, 1, 0], data[1, 1, 1]], [data[1, 2, 0], data[1, 2, 1]], [data[1, 3, 0], data[1, 3, 1]]])\n    assert_array_equal(quantiles, expected)\n\n    # Group by dimension 'z' and calculate quantiles\n    grouped = ds.groupby(\"z\")\n    quantiles = grouped.quantile(0.5, dim=\"x\")\n\n    # Check the result\n    expected = np.array([[data[0, 0, 0], data[0, 1, 0], data[0, 2, 0]], [data[1, 0, 0], data[1, 1, 0], data[1, 2, 0]], [data[2, 0, 0], data[2, 1, 0], data[2, 2, 0]]])\n    assert_array_equal(quantiles, expected)\n"], "sample_1137": ["def test_convert_to():\n    # Test conversion to a single unit\n    assert convert_to(mile, kilometer) == 25146*kilometer/15625\n    assert convert_to(speed_of_light, meter/second) == 299792458*meter/second\n    assert convert_to(day, second) == 86400*second\n    assert convert_to(3*newton, kilogram*meter/second**2) == 3*kilogram*meter/second**2\n    assert convert_to(atomic_mass_constant, gram) == 1.660539060e-24*gram\n\n    # Test conversion to multiple units\n    assert convert_to(speed_of_light, [meter, second]) == 299792458*meter/second\n    assert convert_to(3*newton, [centimeter, gram, second]) == 300000*centimeter*gram/second**2\n\n    # Test conversion to Planck units\n    assert convert_to(atomic_mass_constant, [gravitational_constant, speed_of_light, hbar]).n() == 7.62963085040767e-20*gravitational_constant**(-0.5)*hbar**0.5*speed_of_light**0.5\n\n    # Test conversion with incompatible dimensions\n    raises(ValueError, lambda: convert_to(mile, joule))\n"], "sample_1165": ["def test_quaternion():\n    # Test Quaternion.from_axis_angle\n    q1 = Quaternion.from_axis_angle((1, 0, 0), pi/2)\n    assert q1 == Quaternion(0, 1, 0, 0)\n\n    # Test Quaternion.from_rotation_matrix\n    M = Matrix([[0, 1, 0], [-1, 0, 0], [0, 0, 1]])\n    q2 = Quaternion.from_rotation_matrix(M)\n    assert q2 == Quaternion(0, 1, 0, 0)\n\n    # Test Quaternion.add\n    q3 = Quaternion(1, 2, 3, 4)\n    q4 = Quaternion(5, 6, 7, 8)\n    assert q3.add(q4) == Quaternion(6, 8, 10, 12)\n\n    # Test Quaternion.mul\n    q5 = Quaternion(1, 2, 3, 4)\n    q6 = Quaternion(5, 6, 7, 8)\n    assert q5.mul(q6) == Quaternion(-60, 12, 30, 24)\n\n    # Test Quaternion.pow\n    q7 = Quaternion(1, 2, 3, 4)\n    assert q7.pow(2) == Quaternion(-28, 4, 6, 8)\n\n    # Test Quaternion.exp\n    q8 = Quaternion(1, 2, 3, 4)\n    assert q8.exp() == Quaternion(E*cos(sqrt(29)), 2*sqrt(29)*E*sin(sqrt(29))/29, 3*sqrt(29)*E*sin(sqrt(29))/29, 4*sqrt(29)*E*sin(sqrt(29))/29)\n\n    # Test Quaternion._ln\n    q9 = Quaternion(1, 2, 3, 4)\n    assert q9._ln() == Quaternion(log(sqrt(30)), 2*sqrt(29)*acos(sqrt(30)/30)/29, 3*sqrt(29)*acos(sqrt(30)/30)/29, 4*sqrt(29)*acos(sqrt(30)/30)/29)\n\n    # Test Quaternion.integrate\n    q10 = Quaternion(1, 2, 3, 4)\n    assert q10.integrate(x) == Quaternion(x, 2*x, 3*x, 4*x)\n\n    # Test Quaternion.rotate"], "sample_653": ["def test_get_option_ini():\n    class Config:\n            if name == \"log_print\":\n                return True\n            elif name == \"log_level\":\n                return \"DEBUG\"\n            else:\n                return None\n\n            if name == \"log_print\":\n                return \"true\"\n            elif name == \"log_level\":\n                return \"INFO\"\n            else:\n                return None\n\n    config = Config()\n    assert get_option_ini(config, \"log_print\") is True\n    assert get_option_ini(config, \"log_level\") == \"DEBUG\"\n    assert get_option_ini(config, \"non_existent_option\") is None\n"], "sample_434": ["    def test_view_dispatch(self):\n        class TestView(View):\n                return HttpResponse(\"Get\")\n\n                return HttpResponse(\"Post\")\n\n        view = TestView()\n        request = RequestFactory().get(\"/\")\n        response = view.dispatch(request)\n        self.assertEqual(response.content, b\"Get\")\n\n        request = RequestFactory().post(\"/\")\n        response = view.dispatch(request)\n        self.assertEqual(response.content, b\"Post\")\n\n        request = RequestFactory().put(\"/\")\n        response = view.dispatch(request)\n        self.assertIsInstance(response, HttpResponseNotAllowed)\n"], "sample_517": ["def test_text_rotation():\n    fig, ax = plt.subplots()\n    ax.set_xlim(0, 10)\n    ax.set_ylim(0, 10)\n    ax.text(5, 5, 'Hello world!', rotation=45, ha='center', va='center')\n    ax.text(5, 3, 'Hello world!', rotation=45, ha='left', va='center')\n    ax.text(5, 1, 'Hello world!', rotation=45, ha='right', va='center')\n    ax.text(8, 5, 'Hello world!', rotation=45, ha='center', va='top')\n    ax.text(2, 5, 'Hello world!', rotation=45, ha='center', va='bottom')\n    ax.text(5, 5, 'Hello world!', rotation=45, ha='center', va='baseline')\n    ax.text(5, 5, 'Hello world!', rotation=45, ha='center', va='center_baseline')\n"], "sample_801": ["def test_clone():\n    # Test cloning of estimators with different types of parameters\n    estimators = [\n        LogisticRegression(),\n        StandardScaler(),\n        RFE(estimator=LogisticRegression()),\n        GridSearchCV(estimator=LogisticRegression(), param_grid={}),\n        CountVectorizer(),\n        Pipeline(steps=[('scaler', StandardScaler()), ('clf', LogisticRegression())]),\n        SVC(),\n        PCA(),\n        NMF(),\n        SimpleImputer()\n    ]\n\n    for estimator in estimators:\n        cloned_estimator = clone(estimator)\n        assert type(cloned_estimator) == type(estimator)\n        assert cloned_estimator.get_params() == estimator.get_params()\n\n    # Test cloning of estimators with non-estimator parameters\n    class NonEstimator:\n            self.value = value\n\n    non_estimator = NonEstimator(42)\n    cloned_non_estimator = clone(non_estimator, safe=False)\n    assert cloned_non_estimator.value == non_estimator.value\n\n    # Test cloning of lists and tuples of estimators\n    estimators_list = [LogisticRegression(), StandardScaler()]\n    cloned_estimators_list = clone(estimators_list)\n    assert len(cloned_estimators_list) == len(estimators_list)\n    for estimator, cloned_estimator in zip(estimators_list, cloned_estimators_list):\n        assert type(cloned_estimator) == type(estimator)\n        assert cloned_estimator.get_params() == estimator.get_params()\n\n    estimators_tuple = (LogisticRegression(), StandardScaler())\n    cloned_estimators_tuple = clone(estimators_tuple)\n    assert len(cloned_estimators_tuple) == len(estimators_tuple)\n    for estimator, cloned_estimator in zip(estimators_tuple, cloned_estimators_tuple):\n        assert type(cloned_estimator) == type(estimator)\n        assert cloned_estimator.get_params() == estimator.get_params()\n"], "sample_1199": ["def test_tensor_product_simp():\n    # Test tensor_product_simp with a simple expression\n    expr = TensorProduct(A, B) * TensorProduct(C, D)\n    assert tensor_product_simp(expr) == TensorProduct(A*C, B*D)\n\n    # Test tensor_product_simp with a power\n    expr = (TensorProduct(A, B) * TensorProduct(C, D)) ** 2\n    assert tensor_product_simp(expr) == TensorProduct(A*C, B*D) ** 2\n\n    # Test tensor_product_simp with a commutator\n    expr = Comm(TensorProduct(A, B) * TensorProduct(C, D), TensorProduct(E, F))\n    assert tensor_product_simp(expr) == Comm(TensorProduct(A*C, B*D), TensorProduct(E, F))\n\n    # Test tensor_product_simp with an anticommutator\n    expr = AntiCommutator(TensorProduct(A, B) * TensorProduct(C, D), TensorProduct(E, F))\n    assert tensor_product_simp(expr) == AntiCommutator(TensorProduct(A*C, B*D), TensorProduct(E, F))\n\n    # Test tensor_product_simp with a matrix\n    expr = TensorProduct(mat1, mat2)\n    assert tensor_product_simp(expr) == expr\n\n    # Test tensor_product_simp with a scalar\n    expr = 2 * TensorProduct(A, B)\n    assert tensor_product_simp(expr) == 2 * TensorProduct(A, B)\n\n    # Test tensor_product_simp with a complex expression\n    expr = (TensorProduct(A, B) * TensorProduct(C, D)) ** 2 + 2 * TensorProduct(E, F)\n    assert tensor_product_simp(expr) == TensorProduct(A*C, B*D) ** 2 + 2 * TensorProduct(E, F)\n"], "sample_102": ["def test_union_with_empty_querysets(self):\n    qs1 = Number.objects.filter(num__gt=5)\n    qs2 = Number.objects.none()\n    qs3 = Number.objects.filter(num__lt=5)\n\n    qs = qs1.union(qs2, qs3)\n    self.assertNumbersEqual(qs, [0, 1, 2, 3, 4, 6, 7, 8, 9])\n\n    qs = qs2.union(qs1, qs3)\n    self.assertNumbersEqual(qs, [0, 1, 2, 3, 4, 6, 7, 8, 9])\n\n    qs = qs2.union(qs2, qs3)\n    self.assertNumbersEqual(qs, [0, 1, 2, 3, 4])\n"], "sample_346": ["def test_method_decorator(self):\n            return func(*args, **kwargs)\n        return wrapper\n\n    class MyClass:\n            return \"Hello, World!\"\n\n    decorated_class = method_decorator(my_decorator, name='my_method')(MyClass)\n    self.assertEqual(decorated_class.my_method(None), \"Hello, World!\")\n\n    with self.assertRaises(ValueError):\n        method_decorator(my_decorator, name='non_existent_method')(MyClass)\n\n    with self.assertRaises(TypeError):\n        class MyClass:\n            my_method = \"not a callable\"\n        method_decorator(my_decorator, name='my_method')(MyClass)\n"], "sample_284": ["    def test_hashed_name(self):\n        name = 'path/to/file.css'\n        content = b'body { background-color: #f2f2f2; }'\n        hashed_name = storage.staticfiles_storage.hashed_name(name, content=content)\n        self.assertNotEqual(hashed_name, name)\n        self.assertIn('.css', hashed_name)\n"], "sample_675": ["def test_log_capture_fixture(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logging.warning(\"this is a warning\")\n            logging.error(\"this is an error\")\n            assert \"this is a warning\" in caplog.text\n            assert \"this is an error\" in caplog.text\n            assert len(caplog.records) == 2\n            assert len(caplog.record_tuples) == 2\n            assert len(caplog.messages) == 2\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=1)\n\n"], "sample_672": ["def test_saferepr_with_exception():\n    class FailingRepr:\n            raise Exception(\"Failing repr\")\n\n    obj = FailingRepr()\n    result = saferepr(obj)\n    assert \"Exception\" in result\n    assert \"FailingRepr\" in result\n\n"], "sample_859": ["def test_enet_path():\n    # Test enet_path with a random dataset\n    X = np.random.rand(100, 10)\n    y = np.random.rand(100)\n    alphas, coefs, dual_gaps = enet_path(X, y, l1_ratio=0.5, eps=1e-3,\n                                         n_alphas=100, alphas=None,\n                                         precompute='auto', Xy=None,\n                                         copy_X=True, coef_init=None,\n                                         verbose=False, return_n_iter=False,\n                                         positive=False, check_input=True)\n    assert len(alphas) == 100\n    assert coefs.shape == (10, 100)\n    assert len(dual_gaps) == 100\n\n    # Test enet_path with a sparse dataset\n    X_sparse = sparse.csr_matrix(X)\n    alphas, coefs, dual_gaps = enet_path(X_sparse, y, l1_ratio=0.5, eps=1e-3,\n                                         n_alphas=100, alphas=None,\n                                         precompute='auto', Xy=None,\n                                         copy_X=True, coef_init=None,\n                                         verbose=False, return_n_iter=False,\n                                         positive=False, check_input=True)\n    assert len(alphas) == 100\n    assert coefs.shape == (10, 100)\n    assert len(dual_gaps) == 100\n\n    # Test enet_path with a multi-output dataset\n    y_multi = np.random.rand(100, 3)\n    alphas, coefs, dual_gaps = enet_path(X, y_multi, l1_ratio=0.5, eps=1e-3,\n                                         n_alphas=100, alphas=None,\n                                         precompute='auto', Xy=None,\n                                         copy_X=True, coef_init=None,\n                                         verbose=False, return_n_iter=False,\n                                         positive=False, check_input=True)\n    assert len(alphas) == 100\n    assert coefs.shape == (3, 10, 100)\n    assert len(dual_gaps) == 100\n"], "sample_791": ["def test_ordinal_encoder():\n    # Test OrdinalEncoder with string categories\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 2.], [1., 1.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([['Male', 1], ['Female', 3], ['Female', 2]], dtype=object))\n\n    # Test OrdinalEncoder with integer categories\n    enc = OrdinalEncoder()\n    X = [[1, 2], [3, 4], [3, 5]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 1.], [1., 2.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([[1, 2], [3, 4], [3, 5]], dtype=object))\n\n    # Test OrdinalEncoder with mixed type categories\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc = OrdinalEncoder()\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 2.], [1., 1.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([['Male', 1], ['Female', 3], ['Female', 2]], dtype=object))\n\n    # Test OrdinalEncoder with categories specified\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    categories = [['Male', 'Female'], [1, 2, 3]]\n    enc = OrdinalEncoder(categories=categories)\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 2.], [1., 1.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([['Male', 1], ['Female', 3], ['Female', 2]], dtype=object))\n\n    # Test OrdinalEncoder with unknown categories\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc = OrdinalEncoder(handle"], "sample_763": ["def test_check_non_negative():\n    # Test that check_non_negative raises an error for negative values\n    X = np.array([1, -2, 3])\n    assert_raises(ValueError, check_non_negative, X, \"test\")\n\n    # Test that check_non_negative passes for non-negative values\n    X = np.array([1, 2, 3])\n    check_non_negative(X, \"test\")\n\n    # Test that check_non_negative raises an error for negative values in sparse matrix\n    X = sp.csr_matrix([1, -2, 3])\n    assert_raises(ValueError, check_non_negative, X, \"test\")\n\n    # Test that check_non_negative passes for non-negative values in sparse matrix\n    X = sp.csr_matrix([1, 2, 3])\n    check_non_negative(X, \"test\")\n"], "sample_463": ["def test_altered_indexes(self):\n    before_state = self.make_project_state(\n        [\n            self.book_unique_together,\n            self.author,\n        ]\n    )\n    after_state = self.make_project_state(\n        [\n            self.book_unique_together_2,\n            self.author,\n        ]\n    )\n    changes = self.get_changes(before_state, after_state)\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\"])\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        0,\n        name=\"Book\",\n        unique_together={(\"title\", \"author\")},\n    )\n"], "sample_569": ["def test_lmplot():\n    \"\"\"Test that lmplot produces the correct number of facets.\"\"\"\n    p = lm.lmplot(x=\"x\", y=\"y\", data=df, col=\"d\", palette=\"husl\")\n    assert len(p.axes_dict) == 5\n\n    p = lm.lmplot(x=\"x\", y=\"y\", data=df, row=\"d\", palette=\"husl\")\n    assert len(p.axes_dict) == 5\n\n    p = lm.lmplot(x=\"x\", y=\"y\", data=df, col=\"s\", palette=\"husl\")\n    assert len(p.axes_dict) == 10\n\n    p = lm.lmplot(x=\"x\", y=\"y\", data=df, row=\"s\", palette=\"husl\")\n    assert len(p.axes_dict) == 10\n\n    p = lm.lmplot(x=\"x\", y=\"y\", data=df, col=\"d\", row=\"s\", palette=\"husl\")\n    assert len(p.axes_dict) == 50\n\n    p = lm.lmplot(x=\"x\", y=\"y\", data=df, hue=\"d\", palette=\"husl\")\n    assert len(p.axes_dict) == 1\n\n    p = lm.lmplot(x=\"x\", y=\"y\", data=df, col=\"d\", hue=\"s\", palette=\"husl\")\n    assert len(p.axes_dict) == 5\n\n    p = lm.lmplot(x=\"x\", y=\"y\", data=df, row=\"d\", hue=\"s\", palette=\"husl\")\n    assert len(p.axes_dict) == 5\n\n    p = lm.lmplot(x=\"x\", y=\"y\", data=df, col=\"s\", hue=\"d\", palette=\"husl\")\n    assert len(p.axes_dict) == 10\n\n    p = lm.lmplot(x=\"x\", y=\"y\", data=df, row=\"s\", hue=\"d\", palette=\"husl\")\n    assert len(p.axes_dict) == 10\n\n    p = lm.lmplot(x=\"x\", y=\"y\", data=df, col=\"d\", row=\"s\", hue=\"d\", palette=\"husl\")\n    assert len(p.axes_dict) == 50\n"], "sample_1143": ["def test_comp():\n    assert comp(1, 1)\n    assert comp(1, 1.0)\n    assert comp(1, 1.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_799": ["def test_cross_validate_return_estimator():\n    # Test that cross_validate returns the estimators when return_estimator=True\n    X, y = make_classification(n_samples=10, n_features=2, n_informative=2,\n                               n_redundant=0, n_classes=2, random_state=0)\n    estimator = LogisticRegression()\n    cv_results = cross_validate(estimator, X, y, cv=2, return_estimator=True)\n    assert len(cv_results['estimator']) == 2\n    for est in cv_results['estimator']:\n        assert isinstance(est, LogisticRegression)\n        assert hasattr(est, 'coef_')\n"], "sample_1061": ["def test_integer_nthroot():\n    assert integer_nthroot(16, 2) == (4, True)\n    assert integer_nthroot(26, 2) == (5, False)\n    assert integer_nthroot(27, 3) == (3, True)\n    assert integer_nthroot(28, 3) == (3, False)\n    assert integer_nthroot(0, 2) == (0, True)\n    assert integer_nthroot(1, 2) == (1, True)\n    assert integer_nthroot(-1, 2) == (1, False)\n    assert integer_nthroot(-16, 2) == (4, False)\n    assert integer_nthroot(-27, 3) == (3, False)\n    assert integer_nthroot(-28, 3) == (3, False)\n    assert integer_nthroot(0, 3) == (0, True)\n    assert integer_nthroot(1, 3) == (1, True)\n    assert integer_nthroot(-1, 3) == (1, False)\n    assert integer_nthroot(-16, 4) == (2, False)\n    assert integer_nthroot(-27, 3) == (3, False)\n    assert integer_nthroot(-28, 3) == (3, False)\n    assert integer_nthroot(0, 4) == (0, True)\n    assert integer_nthroot(1, 4) == (1, True)\n    assert integer_nthroot(-1, 4) == (1, False)\n    assert integer_nthroot(16, 4) == (2, True)\n    assert integer_nthroot(17, 4) == (2, False)\n    assert integer_nthroot(81, 4) == (3, True)\n    assert integer_nthroot(82, 4) == (3, False)\n    assert integer_nthroot(625, 4) == (5, True)\n    assert integer_nthroot(626, 4) == (5, False)\n    assert integer_nthroot(2401, 4) == (7, True)\n    assert integer_nthroot(2402, 4) == (7, False)\n    assert integer_nthroot(14641, 4) == (11, True)\n    assert integer_nthroot(14642, 4) == (11, False)\n    assert integer_nthroot("], "sample_328": ["    def setUpTestData(cls):\n        cls.articles = [\n            Article.objects.create(headline='Article %d' % i, pub_date=datetime.date(2005, 7, 15))\n            for i in range(10)\n        ]\n"], "sample_214": ["    def test_jsonfield_encoder_decoder(self):\n        class CustomEncoder(json.JSONEncoder):\n                if isinstance(obj, uuid.UUID):\n                    return str(obj)\n                return super().default(obj)\n\n        class CustomDecoder(json.JSONDecoder):\n                super().__init__(object_hook=self.dict_to_uuid, *args, **kwargs)\n\n                if 'uuid' in d:\n                    d['uuid'] = uuid.UUID(d['uuid'])\n                return d\n\n        json_field = JSONField(encoder=CustomEncoder, decoder=CustomDecoder)\n        obj = {'uuid': uuid.uuid4()}\n        encoded_obj = json_field.get_prep_value(obj)\n        decoded_obj = json_field.from_db_value(encoded_obj, None, connection)\n        self.assertIsInstance(decoded_obj['uuid'], uuid.UUID)\n"], "sample_717": ["def test_fetch_lfw_pairs():\n    # Test that the pairs are correctly loaded\n    pairs = fetch_lfw_pairs(subset='train', data_home=SCIKIT_LEARN_DATA)\n    assert_equal(pairs.target_names.shape[0], 2)\n    assert_equal(pairs.target_names[0], 'Different persons')\n    assert_equal(pairs.target_names[1], 'Same person')\n    assert_equal(pairs.target.shape[0], 10)\n    assert_equal(pairs.pairs.shape[0], 10)\n    assert_equal(pairs.pairs.shape[1], 2)\n    assert_equal(pairs.pairs.shape[2], 250)\n    assert_equal(pairs.pairs.shape[3], 250)\n    assert_equal(pairs.data.shape[0], 10)\n    assert_equal(pairs.data.shape[1], 250 * 250 * 2)\n\n    # Test that the pairs are correctly loaded with a custom slice\n    pairs = fetch_lfw_pairs(subset='train', data_home=SCIKIT_LEARN_DATA,\n                            slice_=(slice(100, 150), slice(100, 150)))\n    assert_equal(pairs.pairs.shape[2], 50)\n    assert_equal(pairs.pairs.shape[3], 50)\n    assert_equal(pairs.data.shape[1], 50 * 50 * 2)\n\n    # Test that the pairs are correctly loaded with a custom resize\n    pairs = fetch_lfw_pairs(subset='train', data_home=SCIKIT_LEARN_DATA,\n                            resize=0.5)\n    assert_equal(pairs.pairs.shape[2], 125)\n    assert_equal(pairs.pairs.shape[3], 125)\n    assert_equal(pairs.data.shape[1], 125 * 125 * 2)\n\n    # Test that the pairs are correctly loaded with color\n    pairs = fetch_lfw_pairs(subset='train', data_home=SCIKIT_LEARN_DATA,\n                            color=True)\n    assert_equal(pairs.pairs.shape[4], 3)\n    assert_equal(pairs.data.shape[1], 250 * 250 * 2 * 3)\n\n    # Test that the pairs are correctly loaded with a custom slice and resize\n    pairs = fetch_lfw_pairs(subset='train', data_home=SCIKIT_LEARN_DATA,\n                            slice_=(slice(100, 150), slice(100, 150)),\n                            resize=0.5"], "sample_955": ["def test_unparse_arguments(source, expected):\n    tree = ast.parse(source)\n    assert unparse(tree.body[0].args) == expected\n"], "sample_119": ["def test_is_nullable(self):\n    query = Query(Item)\n    query.setup_joins(['author'], Item._meta, 'table')\n    self.assertTrue(query.is_nullable(Item._meta.get_field('author')))\n    self.assertFalse(query.is_nullable(Item._meta.get_field('name')))\n\n    query = Query(Author)\n    query.setup_joins(['ranking'], Author._meta, 'table')\n    self.assertTrue(query.is_nullable(Author._meta.get_field('ranking')))\n    self.assertFalse(query.is_nullable(Author._meta.get_field('name')))\n\n    query = Query(ObjectC)\n    query.setup_joins(['ranking'], ObjectC._meta, 'table')\n    self.assertTrue(query.is_nullable(ObjectC._meta.get_field('ranking')))\n    self.assertFalse(query.is_nullable(ObjectC._meta.get_field('name')))\n"], "sample_397": ["def test_engine_init(self):\n    engine = self.engine_class()\n    self.assertEqual(engine.dirs, [])\n    self.assertEqual(engine.app_dirs, False)\n    self.assertEqual(engine.autoescape, True)\n    self.assertEqual(engine.context_processors, [])\n    self.assertEqual(engine.debug, False)\n    self.assertEqual(engine.loaders, [(\"django.template.loaders.cached.Loader\", [\"django.template.loaders.filesystem.Loader\"])])\n    self.assertEqual(engine.string_if_invalid, \"\")\n    self.assertEqual(engine.file_charset, \"utf-8\")\n    self.assertEqual(engine.libraries, {})\n    self.assertEqual(engine.builtins, [])\n\n    engine = self.engine_class(dirs=[\"/path/to/templates\"], app_dirs=True, context_processors=[\"path.to.processor\"], debug=True, loaders=[\"path.to.loader\"], string_if_invalid=\"INVALID\", file_charset=\"latin1\", libraries={\"lib\": \"path.to.lib\"}, builtins=[\"path.to.builtin\"], autoescape=False)\n    self.assertEqual(engine.dirs, [\"/path/to/templates\"])\n    self.assertEqual(engine.app_dirs, True)\n    self.assertEqual(engine.autoescape, False)\n    self.assertEqual(engine.context_processors, [\"path.to.processor\"])\n    self.assertEqual(engine.debug, True)\n    self.assertEqual(engine.loaders, [(\"django.template.loaders.cached.Loader\", [\"path.to.loader\", \"django.template.loaders.app_directories.Loader\"])])\n    self.assertEqual(engine.string_if_invalid, \"INVALID\")\n    self.assertEqual(engine.file_charset, \"latin1\")\n    self.assertEqual(engine.libraries, {\"lib\": \"path.to.lib\"})\n    self.assertEqual(engine.builtins, [\"path.to.builtin\"])\n\n    with self.assertRaises(ImproperlyConfigured):\n        self.engine_class(app_dirs=True, loaders=[\"path.to.loader\"])\n"], "sample_337": ["def test_origin_verified(self):\n    middleware = CsrfViewMiddleware()\n    request = HttpRequest()\n    request.META['HTTP_ORIGIN'] = 'https://example.com'\n    request.get_host = lambda: 'example.com'\n    self.assertTrue(middleware._origin_verified(request))\n\n    request.META['HTTP_ORIGIN'] = 'https://sub.example.com'\n    self.assertTrue(middleware._origin_verified(request))\n\n    request.META['HTTP_ORIGIN'] = 'https://example.net'\n    self.assertFalse(middleware._origin_verified(request))\n\n    request.META['HTTP_ORIGIN'] = 'http://example.com'\n    self.assertFalse(middleware._origin_verified(request))\n\n    request.META['HTTP_ORIGIN'] = 'https://example.com:8080'\n    request.get_port = lambda: '8080'\n    self.assertTrue(middleware._origin_verified(request))\n\n    request.META['HTTP_ORIGIN'] = 'https://example.com:8080'\n    request.get_port = lambda: '80'\n    self.assertFalse(middleware._origin_verified(request))\n\n    request.META['HTTP_ORIGIN'] = 'https://*.example.com'\n    self.assertTrue(middleware._origin_verified(request))\n\n    request.META['HTTP_ORIGIN'] = 'https://*.example.net'\n    self.assertFalse(middleware._origin_verified(request))\n\n    request.META['HTTP_ORIGIN'] = 'https://example.com:8080'\n    request.get_port = lambda: '8080'\n    settings.CSRF_TRUSTED_ORIGINS = ['https://*.example.com:8080']\n    self.assertTrue(middleware._origin_verified(request))\n\n    request.META['HTTP_ORIGIN'] = 'https://example.com:8080'\n    request.get_port = lambda: '8080'\n    settings.CSRF_TRUSTED_ORIGINS = ['https://*.example.com:80']\n    self.assertFalse(middleware._origin_verified(request))\n"], "sample_420": ["    def test_fields_for_model_with_custom_field(self):\n        class CustomField(models.Field):\n                return forms.CharField(**kwargs)\n\n        class CustomModel(models.Model):\n            custom_field = CustomField()\n\n        fields = fields_for_model(CustomModel)\n        self.assertEqual(len(fields), 1)\n        self.assertIsInstance(fields[\"custom_field\"], forms.CharField)\n"], "sample_847": ["def test_enet_path():\n    # Test enet_path with different parameters\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([5, 6])\n    alphas, coefs, dual_gaps = enet_path(X, y, l1_ratio=0.5, eps=1e-3,\n                                         n_alphas=100, alphas=None,\n                                         precompute='auto', Xy=None,\n                                         copy_X=True, coef_init=None,\n                                         verbose=False, return_n_iter=False,\n                                         positive=False, check_input=True)\n    assert_array_almost_equal(alphas.shape, (100,))\n    assert_array_almost_equal(coefs.shape, (2, 100))\n    assert_array_almost_equal(dual_gaps.shape, (100,))\n\n    # Test enet_path with sparse X\n    X_sparse = sparse.csr_matrix(X)\n    alphas, coefs, dual_gaps = enet_path(X_sparse, y, l1_ratio=0.5, eps=1e-3,\n                                         n_alphas=100, alphas=None,\n                                         precompute='auto', Xy=None,\n                                         copy_X=True, coef_init=None,\n                                         verbose=False, return_n_iter=False,\n                                         positive=False, check_input=True)\n    assert_array_almost_equal(alphas.shape, (100,))\n    assert_array_almost_equal(coefs.shape, (2, 100))\n    assert_array_almost_equal(dual_gaps.shape, (100,))\n\n    # Test enet_path with multi-output y\n    y_multi = np.array([[5, 6], [7, 8]])\n    alphas, coefs, dual_gaps = enet_path(X, y_multi, l1_ratio=0.5, eps=1e-3,\n                                         n_alphas=100, alphas=None,\n                                         precompute='auto', Xy=None,\n                                         copy_X=True, coef_init=None,\n                                         verbose=False, return_n_iter=False,\n                                         positive=False, check_input=True)\n    assert_array_almost_equal(alphas.shape, (100,))\n    assert_array_almost_equal(coefs.shape, (2, 2, 100))\n    assert_array_almost_equal(dual_gaps.shape, (100,))\n\n    # Test enet_path with precomputed Gram matrix\n    X Gram = np.dot(X.T, X)\n    alphas, coefs, dual_gaps = enet_path(X, y, l1_ratio="], "sample_451": ["def test_parse_docstring(self):\n    title, body, metadata = parse_docstring(self.docstring)\n    self.assertEqual(title, \"(TITLE)\")\n    self.assertIn(\"Display an individual\", body)\n    self.assertIn(\"myapp.MyModel\", body)\n    self.assertIn(\"RequestContext\", body)\n    self.assertIn(\"myapp/my_template.html\", body)\n    self.assertIn(\"some_metadata\", metadata)\n    self.assertEqual(metadata[\"some_metadata\"], \"some data\")\n"], "sample_442": ["def test_signer_unsign_object_with_max_age(self):\n    signer = signing.TimestampSigner()\n    obj = {'foo': 'bar'}\n    signed_obj = signer.sign_object(obj)\n    with freeze_time(datetime.datetime.now() + datetime.timedelta(seconds=10)):\n        with self.assertRaises(signing.SignatureExpired):\n            signer.unsign_object(signed_obj, max_age=5)\n    with self.assertRaises(signing.BadSignature):\n        signer.unsign_object(signed_obj, max_age='invalid')\n"], "sample_462": ["def test_choicefield_valid_value(self):\n    field = ChoiceField(choices=[(1, 'one'), (2, 'two')])\n    self.assertTrue(field.valid_value(1))\n    self.assertTrue(field.valid_value('1'))\n    self.assertFalse(field.valid_value(3))\n    self.assertFalse(field.valid_value('three'))\n\n    field = ChoiceField(choices=[('a', 'one'), ('b', 'two')])\n    self.assertTrue(field.valid_value('a'))\n    self.assertTrue(field.valid_value('b'))\n    self.assertFalse(field.valid_value('c'))\n    self.assertFalse(field.valid_value(1))\n\n    field = ChoiceField(choices=[(1, [(2, 'two'), (3, 'three')])])\n    self.assertTrue(field.valid_value(2))\n    self.assertTrue(field.valid_value('2'))\n    self.assertFalse(field.valid_value(1))\n    self.assertFalse(field.valid_value('one'))\n"], "sample_417": ["    def test_floatformat_with_decimal(self):\n        with translation.override('en'):\n            with localcontext() as ctx:\n                ctx.prec = 10\n                a = Decimal('34.23234')\n                b = Decimal('34.00000')\n                c = Decimal('34.26000')\n                self.assertEqual(\n                    floatformat(a, -1),\n                    mark_safe('34.2')\n                )\n                self.assertEqual(\n                    floatformat(b, -1),\n                    mark_safe('34')\n                )\n                self.assertEqual(\n                    floatformat(c, -1),\n                    mark_safe('34.3')\n                )\n                self.assertEqual(\n                    floatformat(a, 3),\n                    mark_safe('34.232')\n                )\n                self.assertEqual(\n                    floatformat(b, 3),\n                    mark_safe('34.000')\n                )\n                self.assertEqual(\n                    floatformat(c, 3),\n                    mark_safe('34.260')\n                )\n                self.assertEqual(\n                    floatformat(a, '-3'),\n                    mark_safe('34.232')\n                )\n                self.assertEqual(\n                    floatformat(b, '-3'),\n                    mark_safe('34')\n                )\n                self.assertEqual(\n                    floatformat(c, '-3'),\n                    mark_safe('34.260')\n                )\n"], "sample_747": ["def test_power_transformer():\n    # Test that the power transformer works correctly\n    pt = PowerTransformer()\n    X = np.array([[1, 2], [3, 2], [4, 5]])\n    X_trans = pt.fit_transform(X)\n    assert_array_almost_equal(X_trans, [[-1.332, -0.707], [0.256, -0.707],\n                                     [1.076, 1.414]])\n\n    # Test that the inverse transform works correctly\n    X_inv = pt.inverse_transform(X_trans)\n    assert_array_almost_equal(X_inv, X)\n\n    # Test that the power transformer works with a single feature\n    X = np.array([[1], [2], [3]])\n    pt = PowerTransformer()\n    X_trans = pt.fit_transform(X)\n    assert_array_almost_equal(X_trans, [[-1.5], [0.0], [1.5]])\n\n    # Test that the power transformer raises an error for non-positive data\n    X = np.array([[-1, 2], [3, 2], [4, 5]])\n    pt = PowerTransformer()\n    assert_raises(ValueError, pt.fit, X)\n\n    # Test that the power transformer raises an error for non-numeric data\n    X = np.array([['a', 2], [3, 2], [4, 5]])\n    pt = PowerTransformer()\n    assert_raises(ValueError, pt.fit, X)\n"], "sample_1203": ["def test_group_homomorphism():\n    # Test the GroupHomomorphism class\n    G = PermutationGroup([Permutation(0, 1), Permutation(0, 2)])\n    H = PermutationGroup([Permutation(0, 1)])\n    images = {G.generators[0]: H.generators[0], G.generators[1]: H.identity}\n    phi = GroupHomomorphism(G, H, images)\n    assert phi.domain == G\n    assert phi.codomain == H\n    assert phi.images == images\n    assert phi.kernel() == PermutationGroup([Permutation(0, 2)])\n    assert phi.image() == H\n    assert phi.is_injective() == False\n    assert phi.is_surjective() == True\n    assert phi.is_isomorphism() == False\n    assert phi.is_trivial() == False\n    assert phi.compose(phi) == phi\n    assert phi.restrict_to(G) == phi\n    assert phi.invert_subgroup(H) == G\n"], "sample_513": ["def test_legend_title_fontsize():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], label='Line 1')\n    ax.plot([3, 2, 1], label='Line 2')\n    ax.legend(title='Legend Title', title_fontsize=20)\n    return fig\n"], "sample_369": ["def test_rename_model_with_custom_manager(self):\n    before_state = self.make_project_state([\n        self.author_empty,\n        self.publisher,\n        self.contract,\n    ])\n    after_state = self.make_project_state([\n        self.author_empty,\n        self.publisher,\n        self.contract_renamed,\n    ])\n    changes = self.get_changes(before_state, after_state)\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"RenameModel\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, old_name=\"Contract\", new_name=\"Deal\")\n"], "sample_470": ["def test_lazy_property(self):\n    class TestClass:\n            self._value = None\n\n        @cached_property\n            self._value = 'computed'\n            return self._value\n\n    obj = TestClass()\n    self.assertIsNone(obj._value)\n    self.assertEqual(obj.value, 'computed')\n    self.assertEqual(obj._value, 'computed')\n    self.assertEqual(obj.value, 'computed')  # cached value is returned\n"], "sample_94": ["    def test_create_superuser_with_password_validation_error(self):\n        with mock.patch.object(createsuperuser, 'getpass', return_value='password123'):\n            with mock.patch.object(sys, 'stdin', MockTTY()):\n                call_command('createsuperuser', interactive=True, verbosity=0)\n                self.assertEqual(CustomUser.objects.count(), 1)\n"], "sample_736": ["def test_logistic_regression_path():\n    # Test logistic_regression_path with a simple dataset\n    X = np.array([[-1, 0], [0, 1], [1, 1]])\n    y = np.array([0, 1, 1])\n    Cs = [1]\n    coefs, Cs, n_iter = logistic_regression_path(X, y, Cs=Cs)\n    assert_equal(len(coefs), 1)\n    assert_equal(len(Cs), 1)\n    assert_equal(len(n_iter), 1)\n\n    # Test logistic_regression_path with a sparse dataset\n    X_sp = sp.csr_matrix(X)\n    coefs_sp, Cs_sp, n_iter_sp = logistic_regression_path(X_sp, y, Cs=Cs)\n    assert_equal(len(coefs_sp), 1)\n    assert_equal(len(Cs_sp), 1)\n    assert_equal(len(n_iter_sp), 1)\n\n    # Test logistic_regression_path with a multi-class dataset\n    y_multi = np.array([0, 1, 2])\n    coefs_multi, Cs_multi, n_iter_multi = logistic_regression_path(X, y_multi, Cs=Cs, multi_class='multinomial')\n    assert_equal(len(coefs_multi), 1)\n    assert_equal(len(Cs_multi), 1)\n    assert_equal(len(n_iter_multi), 1)\n\n    # Test logistic_regression_path with a dataset that has a large number of features\n    X_large = np.random.rand(100, 1000)\n    y_large = np.random.randint(0, 2, 100)\n    coefs_large, Cs_large, n_iter_large = logistic_regression_path(X_large, y_large, Cs=Cs)\n    assert_equal(len(coefs_large), 1)\n    assert_equal(len(Cs_large), 1)\n    assert_equal(len(n_iter_large), 1)\n"], "sample_821": ["def test_affinity_propagation_precomputed():\n    # Test affinity propagation with precomputed affinity matrix\n    X = np.array([[1, 2], [1, 4], [1, 0],\n                  [4, 2], [4, 4], [4, 0]])\n    S = -euclidean_distances(X, squared=True)\n    cluster_centers_indices, labels = affinity_propagation(S, copy=False)\n    assert_array_equal(cluster_centers_indices, np.array([0, 3]))\n    assert_array_equal(labels, np.array([0, 0, 0, 1, 1, 1]))\n\n    # Test affinity propagation with precomputed affinity matrix and preference\n    cluster_centers_indices, labels = affinity_propagation(S, preference=-0.5, copy=False)\n    assert_array_equal(cluster_centers_indices, np.array([0, 3]))\n    assert_array_equal(labels, np.array([0, 0, 0, 1, 1, 1]))\n\n    # Test affinity propagation with precomputed affinity matrix and damping\n    cluster_centers_indices, labels = affinity_propagation(S, damping=0.8, copy=False)\n    assert_array_equal(cluster_centers_indices, np.array([0, 3]))\n    assert_array_equal(labels, np.array([0, 0, 0, 1, 1, 1]))\n\n    # Test affinity propagation with precomputed affinity matrix and max_iter\n    cluster_centers_indices, labels = affinity_propagation(S, max_iter=100, copy=False)\n    assert_array_equal(cluster_centers_indices, np.array([0, 3]))\n    assert_array_equal(labels, np.array([0, 0, 0, 1, 1, 1]))\n\n    # Test affinity propagation with precomputed affinity matrix and convergence_iter\n    cluster_centers_indices, labels = affinity_propagation(S, convergence_iter=10, copy=False)\n    assert_array_equal(cluster_centers_indices, np.array([0, 3]))\n    assert_array_equal(labels, np.array([0, 0, 0, 1, 1, 1]))\n\n    # Test affinity propagation with precomputed affinity matrix and return_n_iter\n    cluster_centers_indices, labels, n_iter = affinity_propagation(S, return_n_iter=True, copy=False)\n    assert_array_equal(cluster_centers_indices, np.array([0, 3]))\n    assert_array_equal(labels, np.array([0, 0, 0, 1,"], "sample_591": ["    def test_merge_indexes(self):\n        data_vars = {\"x\": (\"x\", [1, 2, 3]), \"y\": (\"y\", [4, 5, 6])}\n        coords = {\"x\": [1, 2, 3], \"y\": [4, 5, 6]}\n        ds = xr.Dataset(data_vars, coords)\n        indexes = {\"x\": [\"a\", \"b\", \"c\"]}\n        new_vars, new_coord_names = merge_indexes(indexes, ds._variables, ds._coord_names)\n        expected_vars = {\n            \"x\": xr.IndexVariable(\"x\", pd.Index([\"a\", \"b\", \"c\"], name=\"x\")),\n            \"y\": xr.Variable((\"y\",), [4, 5, 6]),\n        }\n        assert new_coord_names == {\"x\"}\n        assert_identical(new_vars, expected_vars)\n"], "sample_476": ["    def test_file_descriptor(self):\n        \"\"\"\n        Tests the FileDescriptor class.\n        \"\"\"\n        person = self.PersonModel()\n        person.mugshot = self.file1\n        self.assertEqual(person.mugshot.name, \"4x8.png\")\n        self.assertEqual(person.mugshot.width, 4)\n        self.assertEqual(person.mugshot.height, 8)\n\n        # Test that assigning a string to the descriptor works.\n        person.mugshot = \"4x8.png\"\n        self.assertEqual(person.mugshot.name, \"4x8.png\")\n        self.assertEqual(person.mugshot.width, 4)\n        self.assertEqual(person.mugshot.height, 8)\n\n        # Test that assigning None to the descriptor works.\n        person.mugshot = None\n        self.assertIsNone(person.mugshot)\n\n        # Test that assigning a File object to the descriptor works.\n        person.mugshot = self.file2\n        self.assertEqual(person.mugshot.name, \"8x4.png\")\n        self.assertEqual(person.mugshot.width, 8)\n        self.assertEqual(person.mugshot.height, 4)\n\n        # Test that the descriptor's __set__ method is called when assigning a value.\n        person.mugshot = self.file1\n        self.assertEqual(person.mugshot.name, \"4x8.png\")\n        self.assertEqual(person.mugshot.width, 4)\n        self.assertEqual(person.mugshot.height, 8)\n\n        # Test that the descriptor's __get__ method is called when getting a value.\n        self.assertEqual(person.mugshot.name, \"4x8.png\")\n        self.assertEqual(person.mugshot.width, 4)\n        self.assertEqual(person.mugshot.height, 8)\n"], "sample_954": ["def test_manual_page_writer(tmp_path, monkeypatch):\n    from sphinx.builders import Builder\n    from sphinx.writers.manpage import ManualPageWriter\n\n    class MockBuilder(Builder):\n            return ManualPageTranslator(document, builder)\n\n        return MockBuilder(app)\n\n    monkeypatch.setattr('sphinx.writers.manpage.Builder', MockBuilder)\n    monkeypatch.setattr('sphinx.writers.manpage.get_builder', mock_get_builder)\n\n    writer = ManualPageWriter(MockBuilder(None))\n    writer.translate()\n\n    assert writer.output.startswith('.TH ')\n"], "sample_438": ["    def test_model_base_subclass_exception(self):\n        class TestModel(models.Model):\n            class Meta:\n                app_label = \"tests\"\n\n        exception = TestModel.DoesNotExist\n        self.assertEqual(exception.__module__, \"tests.models\")\n        self.assertEqual(exception.__qualname__, \"TestModel.DoesNotExist\")\n        self.assertEqual(exception.__name__, \"DoesNotExist\")\n"], "sample_30": ["def test_votable_file_to_xml():\n    votable_file = tree.VOTableFile()\n    resource = tree.Resource()\n    table = tree.Table(votable_file, ID=\"test_table\")\n    field = tree.Field(votable_file, ID=\"test_field\")\n    table.fields.append(field)\n    resource.tables.append(table)\n    votable_file.resources.append(resource)\n\n    with io.BytesIO() as fd:\n        votable_file.to_xml(fd)\n        fd.seek(0)\n        new_votable_file = parse(fd)\n\n    assert len(new_votable_file.resources) == 1\n    assert len(new_votable_file.resources[0].tables) == 1\n    assert len(new_votable_file.resources[0].tables[0].fields) == 1\n    assert new_votable_file.resources[0].tables[0].fields[0].ID == \"test_field\"\n"], "sample_578": ["    def test_bar_properties(self):\n\n        variables = {\"x\": [1, 2, 3], \"y\": [1, 2, 3]}\n        mark_kws = {\"color\": \"red\", \"alpha\": 0.5, \"fill\": True, \"edgecolor\": \"black\", \"edgewidth\": 2}\n        layer_kws = {}\n\n        bars = self.plot_bars(variables, mark_kws, layer_kws)\n\n        for bar in bars:\n            assert bar.get_facecolor() == to_rgba(\"red\", 0.5)\n            assert bar.get_edgecolor() == to_rgba(\"black\", 1)\n            assert bar.get_linewidth() == 2\n            assert bar.get_linestyle() == \"-\"\n"], "sample_293": ["    def test_urlresolver_match_with_nested_namespaces(self):\n        resolver = get_resolver(urlconf_outer)\n        match = resolver.resolve('/ns-included1/ns-included4/ns-included2/test3/inner/42/37/')\n        self.assertEqual(match.func, views.empty_view)\n        self.assertEqual(match.args, ())\n        self.assertEqual(match.kwargs, {'arg1': '42', 'arg2': '37'})\n        self.assertEqual(match.url_name, 'urlobject-view')\n        self.assertEqual(match.app_names, ['included_namespace_urls', 'namespace_urls', 'included_namespace_urls', 'testapp'])\n        self.assertEqual(match.namespaces, ['inc-ns1', 'inc-ns4', 'inc-ns2', 'test-ns3'])\n        self.assertEqual(match.route, 'ns-included1/ns-included4/ns-included2/test3/inner/42/37/')\n        self.assertEqual(match.view_name, 'inc-ns1:inc-ns4:inc-ns2:test-ns3:urlobject-view')\n"], "sample_151": ["def test_altered_unique_together(self):\n    before_state = self.make_project_state([self.author_with_book])\n    after_state = self.make_project_state([self.book_foo_together])\n    changes = self.get_changes(before_state, after_state)\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\"])\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 0, unique_together={(\"author\", \"title\")})\n"], "sample_1179": ["def test_strprinter():\n    p = StrPrinter()\n    assert p._print_Str(\"Hello\") == \"Str('Hello')\"\n    assert p._print_str(\"Hello\") == \"Hello\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert p._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert"], "sample_6": ["def test_latitude_validation():\n    # Test that Latitude raises an error when initialized with an invalid angle\n    with pytest.raises(ValueError):\n        Latitude(100 * u.deg)\n\n    # Test that Latitude raises an error when an invalid angle is assigned\n    lat = Latitude(0 * u.deg)\n    with pytest.raises(ValueError):\n        lat[0] = 100 * u.deg\n\n    # Test that Latitude raises an error when initialized with a Longitude\n    with pytest.raises(TypeError):\n        Latitude(Longitude(10 * u.deg))\n\n    # Test that Latitude raises an error when a Longitude is assigned\n    lat = Latitude(0 * u.deg)\n    with pytest.raises(TypeError):\n        lat[0] = Longitude(10 * u.deg)\n"], "sample_980": ["def test_permutation():\n    # Test the Permutation class\n    p = Permutation([1, 0, 2, 3])\n    assert p.array_form == [1, 0, 2, 3]\n    assert p.cyclic_form == [[0, 1]]\n    assert p.size == 4\n    assert p.rank() == 1\n    assert p.cardinality == 24\n    assert p.parity() == 1\n    assert p.is_even == False\n    assert p.is_odd == True\n    assert p.is_Singleton == False\n    assert p.is_Empty == False\n    assert p.is_Identity == False\n    assert p.ascents() == [1]\n    assert p.descents() == [0]\n    assert p.max() == 1\n    assert p.min() == 0\n    assert p.inversions() == 1\n    assert p.commutes_with(Permutation([0, 1, 2, 3])) == True\n    assert p.commutes_with(Permutation([1, 0, 2, 3])) == False\n    assert p.transpositions() == [(0, 1)]\n    assert p.signature() == -1\n    assert p.order() == 2\n    assert p.length() == 2\n    assert p.cycle_structure == {2: 1}\n    assert p.cycles == 2\n    assert p.index() == 1\n    assert p.runs() == [[0, 1], [2, 3]]\n    assert p.inversion_vector() == [1, 0]\n    assert p.rank_trotterjohnson() == 1\n    assert p.get_precedence_matrix() == [[0, 0, 0, 0], [1, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n    assert p.get_adjacency_matrix() == [[0, 1, 0, 0], [0, 0, 0, 0], [0, 0, 0, 1], [0, 0, 0, 0]]\n    assert p.get_precedence_distance(Permutation([0, 1, 2, 3])) == 0\n    assert p.get_adjacency_distance(Permutation([0, "], "sample_765": ["def test_multilabel_confusion_matrix():\n    # Test multilabel confusion matrix\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    mcm = multilabel_confusion_matrix(y_true, y_pred)\n    assert_array_almost_equal(mcm, np.array([[[1, 0],\n                                              [0, 1]],\n                                             [[1, 0],\n                                              [0, 1]],\n                                             [[0, 1],\n                                              [1, 0]]]))\n\n    # Test multilabel confusion matrix with sample_weight\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    sample_weight = np.array([0.5, 1.0])\n    mcm = multilabel_confusion_matrix(y_true, y_pred, sample_weight=sample_weight)\n    assert_array_almost_equal(mcm, np.array([[[0.5, 0],\n                                              [0, 0.5]],\n                                             [[0.5, 0],\n                                              [0, 0.5]],\n                                             [[0, 0.5],\n                                              [0.5, 0]]))\n\n    # Test multilabel confusion matrix with labels\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    labels = [0, 1]\n    mcm = multilabel_confusion_matrix(y_true, y_pred, labels=labels)\n    assert_array_almost_equal(mcm, np.array([[[1, 0],\n                                              [0, 1]],\n                                             [[1, 0],\n                                              [0, 1]]]))\n\n    # Test multilabel confusion matrix with samplewise\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    mcm = multilabel_confusion_matrix(y_true, y_pred,"], "sample_812": ["def test_changed_params():\n    # Test that _changed_params returns the correct parameters\n    estimator = LogisticRegression(penalty='l1', C=0.5)\n    changed_params = _changed_params(estimator)\n    assert changed_params == {'penalty': 'l1', 'C': 0.5}\n\n    # Test that _changed_params ignores default parameters\n    estimator = LogisticRegression()\n    changed_params = _changed_params(estimator)\n    assert changed_params == {}\n\n    # Test that _changed_params handles NaN values correctly\n    estimator = LogisticRegression(tol=np.nan)\n    changed_params = _changed_params(estimator)\n    assert changed_params == {}\n\n    # Test that _changed_params handles non-estimator objects correctly\n    class NotAnEstimator:\n            self.param1 = param1\n            self.param2 = param2\n\n            return {'param1': self.param1, 'param2': self.param2}\n\n    obj = NotAnEstimator('value1', 'value2')\n    with pytest.raises(AttributeError):\n        _changed_params(obj)\n"], "sample_676": ["def test_build_summary_stats_line():\n    stats = {\"failed\": [1, 2, 3], \"passed\": [4, 5, 6]}\n    line, color = build_summary_stats_line(stats)\n    assert line == \"3 failed, 3 passed\"\n    assert color == \"red\"\n\n    stats = {\"passed\": [1, 2, 3]}\n    line, color = build_summary_stats_line(stats)\n    assert line == \"3 passed\"\n    assert color == \"green\"\n\n    stats = {\"warnings\": [1, 2, 3]}\n    line, color = build_summary_stats_line(stats)\n    assert line == \"3 warnings\"\n    assert color == \"yellow\"\n\n    stats = {\"unknown\": [1, 2, 3]}\n    line, color = build_summary_stats_line(stats)\n    assert line == \"3 unknown\"\n    assert color == \"yellow\"\n\n    stats = {}\n    line, color = build_summary_stats_line(stats)\n    assert line == \"no tests ran\"\n    assert color == \"yellow\"\n"], "sample_681": ["def test_catching_logs_context_manager(tmp_path, caplog):\n    log_file = tmp_path / \"test.log\"\n    handler = logging.FileHandler(log_file)\n    formatter = logging.Formatter(\"%(levelname)s:%(message)s\")\n    handler.setFormatter(formatter)\n\n    with catching_logs(handler, level=logging.INFO) as h:\n        logging.info(\"Test message\")\n\n    assert log_file.read_text() == \"INFO:Test message\\n\"\n    assert h.stream.getvalue() == \"INFO:Test message\\n\"\n\n    with catching_logs(handler, level=logging.DEBUG) as h:\n        logging.debug(\"Debug message\")\n\n    assert log_file.read_text() == \"INFO:Test message\\nDEBUG:Debug message\\n\"\n    assert h.stream.getvalue() == \"DEBUG:Debug message\\n\"\n\n    with catching_logs(handler, level=logging.ERROR) as h:\n        logging.error(\"Error message\")\n\n    assert log_file.read_text() == \"INFO:Test message\\nDEBUG:Debug message\\nERROR:Error message\\n\"\n    assert h.stream.getvalue() == \"ERROR:Error message\\n\"\n\n    with pytest.raises(SystemExit):\n        with catching_logs(handler, level=logging.CRITICAL) as h:\n            logging.critical(\"Critical message\")\n            raise SystemExit(1)\n\n    assert log_file.read_text() == \"INFO:Test message\\nDEBUG:Debug message\\nERROR:Error message\\nCRITICAL:Critical message\\n\"\n    assert h.stream.getvalue() == \"CRITICAL:Critical message\\n\"\n"], "sample_252": ["def test_jsonfield_encoder_decoder(self):\n    encoder = mock.Mock()\n    decoder = mock.Mock()\n    field = JSONField(encoder=encoder, decoder=decoder)\n    value = {'key': 'value'}\n    field.get_prep_value(value)\n    encoder.assert_called_once_with(value)\n    field.from_db_value('{\"key\": \"value\"}', None, connection)\n    decoder.assert_called_once_with('{\"key\": \"value\"}')\n"], "sample_930": ["def test_create_index(app, status, warning):\n    \"\"\"Test the create_index method of IndexEntries.\"\"\"\n    app.builder.env.domains['index'].entries['test'] = [\n        ('single', 'test', 'test_id', 'Test', None),\n        ('pair', 'test1,test2', 'test_id1', 'Test1', None),\n        ('triple', 'test1,test2,test3', 'test_id2', 'Test2', None),\n        ('see', 'test,see', 'test_id3', 'Test3', None),\n        ('seealso', 'test,seealso', 'test_id4', 'Test4', None),\n    ]\n    index_entries = IndexEntries(app.builder.env)\n    result = index_entries.create_index(app.builder)\n    assert len(result) > 0\n    assert all(isinstance(item, tuple) and len(item) == 2 for item in result)\n\n    # Test with group_entries=False\n    result = index_entries.create_index(app.builder, group_entries=False)\n    assert len(result) > 0\n    assert all(isinstance(item, tuple) and len(item) == 2 for item in result)\n\n    # Test with unknown index entry type\n    app.builder.env.domains['index'].entries['test'] = [\n        ('unknown', 'test', 'test_id', 'Test', None),\n    ]\n    with pytest.warns(UserWarning, match='unknown index entry type'):\n        index_entries.create_index(app.builder)\n"], "sample_1001": ["def test_latex():\n    # Test latex printing of various objects\n    assert latex(x) == 'x'\n    assert latex(x**2) == 'x^{2}'\n    assert latex(x**-2) == 'x^{-2}'\n    assert latex(x**Rational(1, 2)) == '\\sqrt{x}'\n    assert latex(x**Rational(1, 3)) == '\\sqrt[3]{x}'\n    assert latex(x**Rational(2, 3)) == 'x^{\\frac{2}{3}}'\n    assert latex(x**Rational(-1, 3)) == 'x^{-\\frac{1}{3}}'\n    assert latex(x**Rational(-2, 3)) == 'x^{-\\frac{2}{3}}'\n    assert latex(x**Rational(-3, 2)) == 'x^{-\\frac{3}{2}}'\n    assert latex(x**Rational(-3, 4)) == 'x^{-\\frac{3}{4}}'\n    assert latex(x**Rational(-5, 4)) == 'x^{-\\frac{5}{4}}'\n    assert latex(x**Rational(-7, 4)) == 'x^{-\\frac{7}{4}}'\n    assert latex(x**Rational(-9, 4)) == 'x^{-\\frac{9}{4}}'\n    assert latex(x**Rational(-11, 4)) == 'x^{-\\frac{11}{4}}'\n    assert latex(x**Rational(-13, 4)) == 'x^{-\\frac{13}{4}}'\n    assert latex(x**Rational(-15, 4)) == 'x^{-\\frac{15}{4}}'\n    assert latex(x**Rational(-17, 4)) == 'x^{-\\frac{17}{4}}'\n    assert latex(x**Rational(-19, 4)) == 'x^{-\\frac{19}{4}}'\n    assert latex(x**Rational(-21, 4)) == 'x^{-\\frac{21}{4}}'\n    assert latex(x**Rational(-23, 4)) == 'x^{-\\frac{23}{4}}'\n    assert latex(x**Rational(-25, 4)) == 'x^{-\\frac{25}{4}}'\n    assert latex(x**Rational(-27, 4)) == 'x^{-\\frac{"], "sample_696": ["def test_check_ispytest_warning():\n    with warnings.catch_warnings(record=True) as w:\n        deprecated.check_ispytest(False)\n        assert len(w) == 1\n        assert w[0].category == PytestDeprecationWarning\n        assert str(w[0].message) == \"A private pytest class or function was used.\"\n"], "sample_21": ["def test_read_table_qdp():\n    # Test reading a QDP file with multiple tables\n    qdp_file = \"\"\"\n    ! Initial comment line 1\n    ! Initial comment line 2\n    READ TERR 1\n    READ SERR 3\n    ! Table 0 comment\n    !a a(pos) a(neg) b be c d\n    53000.5   0.25  -0.5   1  1.5  3.5 2\n    54000.5   1.25  -1.5   2  2.5  4.5 3\n    NO NO NO NO NO\n    ! Table 1 comment\n    !a a(pos) a(neg) b be c d\n    54000.5   2.25  -2.5   NO  3.5  5.5 5\n    55000.5   3.25  -3.5   4  4.5  6.5 nan\n    \"\"\"\n    tables = _read_table_qdp(qdp_file)\n    assert len(tables) == 2\n    assert len(tables[0].columns) == 7\n    assert len(tables[1].columns) == 7\n\n    # Test reading a QDP file with a single table\n    qdp_file = \"\"\"\n    ! Initial comment line 1\n    ! Initial comment line 2\n    READ TERR 1\n    READ SERR 3\n    ! Table 0 comment\n    !a a(pos) a(neg) b be c d\n    53000.5   0.25  -0.5   1  1.5  3.5 2\n    54000.5   1.25  -1.5   2  2.5  4.5 3\n    \"\"\"\n    tables = _read_table_qdp(qdp_file)\n    assert len(tables) == 1\n    assert len(tables[0].columns) == 7\n\n    # Test reading a QDP file with custom column names\n    qdp_file = \"\"\"\n    ! Initial comment line 1\n    ! Initial comment line 2\n    READ TERR 1\n    READ SERR 3\n    ! Table"], "sample_518": ["def test_patch_update_from():\n    patch1 = Patch(facecolor='red', edgecolor='blue')\n    patch2 = Patch(facecolor='green', edgecolor='yellow')\n    patch1.update_from(patch2)\n    assert patch1.get_facecolor() == (0.0, 1.0, 0.0, 1.0)\n    assert patch1.get_edgecolor() == (1.0, 1.0, 0.0, 1.0)\n"], "sample_179": ["    def test_check_long_column_names(self):\n        # Create a model with a field that has an auto-generated column name\n        # longer than the maximum allowed length for the database.\n        class LongNameModel(models.Model):\n            long_field_name = models.CharField(max_length=255)\n\n        # Get the maximum allowed column name length and the database alias.\n        max_length, db_alias = get_max_column_name_length()\n\n        # If no database has a maximum column name length, skip the test.\n        if max_length is None:\n            self.skipTest(\"No database has a maximum column name length.\")\n\n        # Create a model with a field that has an auto-generated column name\n        # longer than the maximum allowed length for the database.\n        class LongNameModel(models.Model):\n            long_field_name = models.CharField(max_length=max_length + 1)\n\n        # Check the model for errors.\n        errors = LongNameModel.check(databases=[db_alias])\n\n        # Check that an error was raised.\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, 'models.E018')\n"], "sample_771": ["def test_power_transformer():\n    # Test that the PowerTransformer works as expected\n    X = np.array([[1, 2], [3, 2], [4, 5]])\n    pt = PowerTransformer(method='yeo-johnson', standardize=True)\n    X_trans = pt.fit_transform(X)\n    assert_allclose(X_trans.mean(axis=0), np.zeros(X.shape[1]))\n    assert_allclose(X_trans.std(axis=0), np.ones(X.shape[1]))\n\n    # Test that the PowerTransformer works with NaNs\n    X = np.array([[1, 2], [3, np.nan], [4, 5]])\n    pt = PowerTransformer(method='yeo-johnson', standardize=True)\n    X_trans = pt.fit_transform(X)\n    assert_allclose(X_trans.mean(axis=0), np.zeros(X.shape[1]))\n    assert_allclose(X_trans.std(axis=0), np.ones(X.shape[1]))\n\n    # Test that the PowerTransformer works with negative values\n    X = np.array([[-1, 2], [3, -2], [4, 5]])\n    pt = PowerTransformer(method='yeo-johnson', standardize=True)\n    X_trans = pt.fit_transform(X)\n    assert_allclose(X_trans.mean(axis=0), np.zeros(X.shape[1]))\n    assert_allclose(X_trans.std(axis=0), np.ones(X.shape[1]))\n\n    # Test that the PowerTransformer raises an error with invalid method\n    with assert_raises_regex(ValueError, \"'method' must be one of\"):\n        PowerTransformer(method='invalid_method')\n\n    # Test that the PowerTransformer raises an error with non-positive data\n    X = np.array([[0, 2], [3, 2], [4, 5]])\n    with assert_raises_regex(ValueError, \"The Box-Cox transformation can only\"):\n        PowerTransformer(method='box-cox').fit(X)\n\n    # Test that the PowerTransformer works with sparse data\n    X = sparse.csr_matrix(np.array([[1, 2], [3, 2], [4, 5]]))\n    pt = PowerTransformer(method='yeo-johnson', standardize=True)\n    X_trans = pt.fit_transform(X)\n    assert_allclose(X_trans.toarray().mean(axis=0), np.zeros(X.shape[1]))\n    assert_allclose(X_trans.toarray().std(axis=0), np.ones(X.shape[1]))\n\n   "], "sample_37": ["def test_wcs_footprint_to_file(self):\n    filename = get_pkg_data_filename('wcs/92bs_c_g_v7p.fits')\n    with fits.open(filename) as hdul:\n        w = wcs.WCS(hdul[0].header)\n        w.footprint_to_file('footprint.reg')\n        assert os.path.exists('footprint.reg')\n        os.remove('footprint.reg')\n"], "sample_384": ["    def setUpTestData(cls):\n        cls.article1 = Article.objects.create(headline=\"Article 1\")\n        cls.article2 = Article.objects.create(headline=\"Article 2\")\n        cls.article3 = Article.objects.create(headline=\"Article 3\")\n"], "sample_394": ["    def test_inline_formset_validation(self):\n        # Test that inline formset validation works correctly.\n        url = reverse(\"admin:admin_views_section_change\", args=(self.s1.pk,))\n        response = self.client.post(url, self.inline_post_data)\n        self.assertEqual(response.status_code, 200)\n        self.assertFormsetError(\n            response,\n            \"article_set\",\n            0,\n            \"title\",\n            [\"This field cannot be blank.\"],\n        )\n        self.assertFormsetError(\n            response,\n            \"article_set\",\n            1,\n            \"title\",\n            [\"This field cannot be blank.\"],\n        )\n        self.assertFormsetError(\n            response,\n            \"article_set\",\n            2,\n            \"title\",\n            [\"This field cannot be blank.\"],\n        )\n"], "sample_44": ["    def test_init(self):\n        with pytest.raises(ValueError):\n            u.FunctionUnitBase(physical_unit='m')\n\n        with pytest.raises(ValueError):\n            u.FunctionUnitBase(function_unit='m')\n\n        with pytest.raises(ValueError):\n            u.FunctionUnitBase(physical_unit='m', function_unit='s')\n"], "sample_471": ["def test_jsonfield(self):\n    f = JSONField()\n    self.assertWidgetRendersTo(f, '<textarea name=\"field\" cols=\"40\" rows=\"10\"></textarea>')\n    self.assertWidgetRendersTo(f, '<textarea name=\"field\" cols=\"40\" rows=\"10\"></textarea>', 'value')\n\n    # Test to_python method\n    self.assertEqual(f.to_python('{\"key\": \"value\"}'), {\"key\": \"value\"})\n    self.assertEqual(f.to_python('[\"list\", \"of\", \"values\"]'), [\"list\", \"of\", \"values\"])\n    self.assertEqual(f.to_python('123'), 123)\n    self.assertEqual(f.to_python('123.45'), 123.45)\n    self.assertEqual(f.to_python('true'), True)\n    self.assertEqual(f.to_python('false'), False)\n    self.assertEqual(f.to_python('null'), None)\n    self.assertEqual(f.to_python(''), None)\n    self.assertEqual(f.to_python(None), None)\n\n    # Test to_python method with invalid JSON\n    with self.assertRaises(ValidationError):\n        f.to_python('Invalid JSON')\n\n    # Test bound_data method\n    self.assertEqual(f.bound_data('{\"key\": \"value\"}', None), {\"key\": \"value\"})\n    self.assertEqual(f.bound_data(None, '{\"key\": \"value\"}'), '{\"key\": \"value\"}')\n\n    # Test prepare_value method\n    self.assertEqual(f.prepare_value({\"key\": \"value\"}), '{\"key\": \"value\"}')\n    self.assertEqual(f.prepare_value('{\"key\": \"value\"}'), '{\"key\": \"value\"}')\n\n    # Test has_changed method\n    self.assertTrue(f.has_changed('{\"key\": \"value\"}', '{\"key\": \"new_value\"}'))\n    self.assertFalse(f.has_changed('{\"key\": \"value\"}', '{\"key\": \"value\"}'))\n"], "sample_949": ["def test_manual_page_builder_init(app, status, warning):\n    app.builder = 'man'\n    app.config.man_pages = None\n    app.builder.init()\n    assert 'no \"man_pages\" config value found; no manual pages will be written' in warning.getvalue()\n"], "sample_697": ["def test_temp_path_factory_getbasetemp(tmp_path_factory: TempPathFactory) -> None:\n    \"\"\"Test that TempPathFactory.getbasetemp() returns the correct base temporary directory.\"\"\"\n    basetemp = tmp_path_factory.getbasetemp()\n    assert basetemp.exists()\n    assert basetemp.is_dir()\n    assert os.access(str(basetemp), os.W_OK)\n"], "sample_376": ["def test_store_messages_exceeding_max_cookie_size(self):\n    storage = self.get_storage()\n    messages = [Message(constants.DEBUG, f\"Message {i}\") for i in range(100)]\n    response = self.get_response()\n    unstored_messages = storage._store(messages, response)\n    self.assertGreater(len(unstored_messages), 0)\n    self.assertEqual(stored_cookie_messages_count(storage, response), storage.max_cookie_size // 2)\n    self.assertEqual(unstored_messages[0].message, messages[0].message)\n    self.assertEqual(unstored_messages[-1].message, messages[-1].message)\n"], "sample_786": ["def test_inverse_transform():\n    est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n    est.fit(X)\n    Xt = est.transform(X)\n    Xinv = est.inverse_transform(Xt)\n    assert_array_equal(Xinv, [[-1.5, 1.5, -3.5, -0.5],\n                              [-0.5, 2.5, -2.5, -0.5],\n                              [0.5, 3.5, -1.5, 0.5],\n                              [0.5, 3.5, -1.5, 1.5]])\n"], "sample_1197": ["def test_UnitSystem():\n    # Test the UnitSystem class\n    us = UnitSystem((length, time, mass), name=\"SI\", descr=\"International System of Units\")\n    assert us.name == \"SI\"\n    assert us.descr == \"International System of Units\"\n    assert us.dim == 3\n    assert us.is_consistent\n\n    # Test the extend method\n    us2 = us.extend((temperature,))\n    assert us2.name == \"\"\n    assert us2.descr == \"\"\n    assert us2.dim == 4\n    assert us2.is_consistent\n\n    # Test the get_dimension_system method\n    assert us.get_dimension_system() is not None\n\n    # Test the get_quantity_dimension method\n    assert us.get_quantity_dimension(meter) == length\n\n    # Test the get_quantity_scale_factor method\n    assert us.get_quantity_scale_factor(meter) == 1\n\n    # Test the get_unit_system method\n    assert UnitSystem.get_unit_system(\"SI\") is us\n\n    # Test the get_default_unit_system method\n    assert UnitSystem.get_default_unit_system() is us\n\n    # Test the derived_units property\n    assert us.derived_units == {}\n\n    # Test the get_dimensional_expr method\n    x = Symbol('x')\n    assert us.get_dimensional_expr(x) == 1\n    assert us.get_dimensional_expr(meter) == length\n    assert us.get_dimensional_expr(meter / second) == length / time\n\n    # Test the _collect_factor_and_dimension method\n    assert us._collect_factor_and_dimension(meter) == (1, length)\n    assert us._collect_factor_and_dimension(meter / second) == (1, length / time)\n\n    # Test the get_units_non_prefixed method\n    assert us.get_units_non_prefixed() == {meter, second, kilogram}\n"], "sample_539": ["def test_rectangle_selector(ax):\n    rs = widgets.RectangleSelector(ax, noop, useblit=True,\n                                  props=dict(facecolor='blue', alpha=0.5))\n    click_and_drag(ax, (0.2, 0.2), (0.8, 0.8))\n    assert_allclose(rs.extents, (0.2, 0.8, 0.2, 0.8))\n"], "sample_79": ["    def check_values(self, *tests):\n        for value, arg, expected in tests:\n            with self.subTest(value=value, arg=arg):\n                output = self.engine.render_to_string('t', {'value': value, 'arg': arg})\n                self.assertEqual(output, expected)\n"], "sample_379": ["def test_mark_safe_decorator(self):\n    @mark_safe\n        return '<script>alert(\"Hello\")</script>'\n\n    result = my_safe_function()\n    self.assertIsInstance(result, SafeString)\n    self.assertEqual(result, '<script>alert(\"Hello\")</script>')\n\n    @mark_safe\n        return arg\n\n    result = my_safe_function_with_args('<script>alert(\"Hello\")</script>')\n    self.assertIsInstance(result, SafeString)\n    self.assertEqual(result, '<script>alert(\"Hello\")</script>')\n\n    @mark_safe\n        return kwargs['arg']\n\n    result = my_safe_function_with_kwargs(arg='<script>alert(\"Hello\")</script>')\n    self.assertIsInstance(result, SafeString)\n    self.assertEqual(result, '<script>alert(\"Hello\")</script>')\n"], "sample_940": ["def test_signature_from_str():\n    sig = inspect.signature_from_str('(a: int, b: str) -> None')\n    assert len(sig.parameters) == 2\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.return_annotation == type(None)\n"], "sample_69": ["    def test_tick(self):\n        reloader = autoreload.StatReloader()\n        ticker = reloader.tick()\n        next(ticker)  # Advance the ticker to the first sleep call.\n        self.assertTrue(reloader.should_stop is False)\n        reloader.stop()\n        self.assertTrue(reloader.should_stop is True)\n        with self.assertRaises(StopIteration):\n            next(ticker)\n"], "sample_432": ["def test_modeladmin_get_inline_instances(self):\n    request = self.factory.get(\"/admin/\")\n    request.user = self.superuser\n\n    model_admin = ParentAdmin(Parent, admin.site)\n    inline_instances = model_admin.get_inline_instances(request)\n\n    self.assertEqual(len(inline_instances), 1)\n    self.assertIsInstance(inline_instances[0], ChildAdmin)\n\n    # Test that inlines are filtered out if the user doesn't have the necessary permissions.\n    request.user = self._create_superuser(\"noperms\")\n    request.user.is_superuser = False\n    request.user.save()\n\n    model_admin = ParentAdmin(Parent, admin.site)\n    inline_instances = model_admin.get_inline_instances(request)\n\n    self.assertEqual(len(inline_instances), 0)\n"], "sample_122": ["    def test_patch_cache_control(self):\n        response = HttpResponse()\n        patch_cache_control(response, max_age=3600, public=True)\n        self.assertEqual(response['Cache-Control'], 'max-age=3600, public')\n"], "sample_841": ["def test_ridge_regression_solver(solver, X_filter):\n    X = X_filter(X_diabetes)\n    y = y_diabetes\n    alpha = 1.0\n    if solver == \"cholesky\":\n        # cholesky solver does not support sparse input\n        X = X.toarray()\n    ridge = Ridge(alpha=alpha, solver=solver)\n    ridge.fit(X, y)\n    y_pred = ridge.predict(X)\n    assert_almost_equal(mean_squared_error(y, y_pred),\n                        ridge_regression(X, y, alpha, solver=solver),\n                        decimal=5)\n"], "sample_1110": ["def test_printers():\n    # Test PythonCodePrinter\n    printer = PythonCodePrinter()\n    assert printer.doprint(1) == \"1\"\n    assert printer.doprint(x) == \"x\"\n    assert printer.doprint(x + 1) == \"x + 1\"\n    assert printer.doprint(x**2) == \"x**2\"\n    assert printer.doprint(Mod(x, 2)) == \"(x % 2)\"\n    assert printer.doprint(acos(x)) == \"math.acos(x)\"\n    assert printer.doprint(KroneckerDelta(x, y)) == \"(1 if x == y else 0)\"\n    assert printer.doprint(Piecewise((x, Eq(x, 0)), (y, True))) == \"(x if x == 0 else y)\"\n    assert printer.doprint(sign(x)) == \"(0.0 if x == 0 else math.copysign(1, x))\"\n    assert printer.doprint(sqrt(x)) == \"math.sqrt(x)\"\n    assert printer.doprint(zoo) == \"float('inf')\"\n    assert printer.doprint(-oo) == \"float('-inf')\"\n    assert printer.doprint(Rational(1, 2)) == \"1/2\"\n\n    # Test MpmathPrinter\n    printer = MpmathPrinter()\n    assert printer.doprint(1) == \"1\"\n    assert printer.doprint(x) == \"x\"\n    assert printer.doprint(x + 1) == \"x + 1\"\n    assert printer.doprint(x**2) == \"x**2\"\n    assert printer.doprint(Mod(x, 2)) == \"(x % 2)\"\n    assert printer.doprint(acos(x)) == \"mpmath.acos(x)\"\n    assert printer.doprint(KroneckerDelta(x, y)) == \"(1 if x == y else 0)\"\n    assert printer.doprint(Piecewise((x, Eq(x, 0)), (y, True))) == \"(x if x == 0 else y)\"\n    assert printer.doprint(sign(x)) == \"mpmath.sign(x)\"\n    assert printer.doprint(sqrt(x)) == \"mpmath.sqrt(x)\"\n    assert printer.doprint(zoo) == \"mpmath.inf\"\n    assert printer.doprint(-oo) == \"mpmath.ninf\"\n    assert printer.doprint(R"], "sample_1065": ["def test_binomial():\n    x = Symbol('x')\n    n = Symbol('n', integer=True, positive=True)\n    k = Symbol('k', integer=True, positive=True)\n\n    assert binomial(n, k).diff(n) == binomial(n, k)*(polygamma(0, n + 1) - polygamma(0, n - k + 1))\n    assert binomial(n, k).diff(k) == binomial(n, k)*(polygamma(0, n - k + 1) - polygamma(0, k + 1))\n\n    assert binomial(0, 0) == 1\n    assert binomial(1, 0) == 1\n    assert binomial(1, 1) == 1\n    assert binomial(2, 0) == 1\n    assert binomial(2, 1) == 2\n    assert binomial(2, 2) == 1\n    assert binomial(3, 0) == 1\n    assert binomial(3, 1) == 3\n    assert binomial(3, 2) == 3\n    assert binomial(3, 3) == 1\n    assert binomial(4, 0) == 1\n    assert binomial(4, 1) == 4\n    assert binomial(4, 2) == 6\n    assert binomial(4, 3) == 4\n    assert binomial(4, 4) == 1\n    assert binomial(5, 0) == 1\n    assert binomial(5, 1) == 5\n    assert binomial(5, 2) == 10\n    assert binomial(5, 3) == 10\n    assert binomial(5, 4) == 5\n    assert binomial(5, 5) == 1\n    assert binomial(6, 0) == 1\n    assert binomial(6, 1) == 6\n    assert binomial(6, 2) == 15\n    assert binomial(6, 3) == 20\n    assert binomial(6, 4) == 15\n    assert binomial(6, 5) == 6\n    assert binomial(6, 6) =="], "sample_1055": ["def test_elgamal_private_key():\n    p, g, d = elgamal_private_key(5)\n    assert isprime(p)\n    assert is_primitive_root(g, p)\n    assert 2 <= d < p\n"], "sample_311": ["    def test_admin_site_register(self):\n        \"\"\"\n        Test registering a model with the admin site.\n        \"\"\"\n        # Create a test model\n        class TestModel(models.Model):\n            name = models.CharField(max_length=255)\n\n        # Create a test admin class\n        class TestAdmin(admin.ModelAdmin):\n            pass\n\n        # Register the model with the admin site\n        site.register(TestModel, TestAdmin)\n\n        # Check that the model is registered\n        self.assertIn(TestModel, site._registry)\n\n        # Check that the admin class is correct\n        self.assertIsInstance(site._registry[TestModel], TestAdmin)\n\n        # Unregister the model\n        site.unregister(TestModel)\n\n        # Check that the model is no longer registered\n        self.assertNotIn(TestModel, site._registry)\n"], "sample_317": ["    def test_rss_feed(self):\n        \"\"\"\n        Test the RSS feed generation.\n        \"\"\"\n        feed = Rss201rev2Feed(\n            title=\"Test Feed\",\n            link=\"http://example.com\",\n            description=\"Test feed description\",\n            language=\"en\",\n        )\n        feed.add_item(\n            title=\"Test Item\",\n            link=\"http://example.com/item\",\n            description=\"Test item description\",\n            pubdate=datetime.datetime(2022, 1, 1, 12, 0, 0),\n        )\n        xml = feed.writeString('utf-8')\n        doc = minidom.parseString(xml)\n        self.assertChildNodes(doc.documentElement, ['channel'])\n        channel = doc.documentElement.firstChild\n        self.assertChildNodeContent(channel, {\n            'title': 'Test Feed',\n            'link': 'http://example.com',\n            'description': 'Test feed description',\n            'language': 'en',\n            'lastBuildDate': rfc2822_date(datetime.datetime(2022, 1, 1, 12, 0, 0)),\n        })\n        self.assertChildNodes(channel, ['title', 'link', 'description', 'language', 'lastBuildDate', 'item'])\n        item = channel.lastChild\n        self.assertChildNodeContent(item, {\n            'title': 'Test Item',\n            'link': 'http://example.com/item',\n            'description': 'Test item description',\n            'pubDate': rfc2822_date(datetime.datetime(2022, 1, 1, 12, 0, 0)),\n        })\n"], "sample_616": ["def test_broadcast_compat_data():\n    dims = (\"x\", \"y\")\n    data = np.arange(4).reshape(2, 2)\n    var = xr.Variable(dims, data)\n\n    # test no broadcasting\n    broadcast_dims = ()\n    core_dims = dims\n    result = broadcast_compat_data(var, broadcast_dims, core_dims)\n    assert_identical(result, data)\n\n    # test broadcasting\n    broadcast_dims = (\"z\",)\n    core_dims = dims\n    result = broadcast_compat_data(var, broadcast_dims, core_dims)\n    expected = data[np.newaxis, :, :]\n    assert_identical(result, expected)\n\n    # test transposition\n    broadcast_dims = ()\n    core_dims = (\"y\", \"x\")\n    result = broadcast_compat_data(var, broadcast_dims, core_dims)\n    expected = data.T\n    assert_identical(result, expected)\n\n    # test broadcasting and transposition\n    broadcast_dims = (\"z\",)\n    core_dims = (\"y\", \"x\")\n    result = broadcast_compat_data(var, broadcast_dims, core_dims)\n    expected = data.T[np.newaxis, :, :]\n    assert_identical(result, expected)\n\n    # test broadcasting with dask array\n    if has_dask:\n        import dask.array as da\n\n        data = da.from_array(data, chunks=(2, 2))\n        var = xr.Variable(dims, data)\n        broadcast_dims = (\"z\",)\n        core_dims = dims\n        result = broadcast_compat_data(var, broadcast_dims, core_dims)\n        expected = data[np.newaxis, :, :]\n        assert_identical(result, expected)\n"], "sample_28": ["def test_card_fromstring_with_invalid_card_image(fits_file):\n    # Test that a VerifyError is raised when creating a Card from a string\n    # that is not a valid FITS card image\n    with pytest.raises(VerifyError):\n        fits.Card.fromstring(\"Invalid card image\")\n\n    # Test that a VerifyError is raised when creating a Card from a string\n    # that is a valid FITS card image but has an invalid value\n    with pytest.raises(VerifyError):\n        fits.Card.fromstring(\"KEYWORD= invalid value\")\n\n    # Test that a VerifyError is raised when creating a Card from a string\n    # that is a valid FITS card image but has an invalid keyword\n    with pytest.raises(VerifyError):\n        fits.Card.fromstring(\" invalid keyword = value\")\n\n    # Test that a VerifyError is raised when creating a Card from a string\n    # that is a valid FITS card image but has an invalid comment\n    with pytest.raises(VerifyError):\n        fits.Card.fromstring(\"KEYWORD= value / invalid comment\")\n"], "sample_734": ["def test_fowlkes_mallows_score():\n    # Test the Fowlkes-Mallows score with perfect labelings\n    assert_almost_equal(fowlkes_mallows_score([0, 0, 1, 1], [0, 0, 1, 1]), 1.0)\n    assert_almost_equal(fowlkes_mallows_score([0, 0, 1, 1], [1, 1, 0, 0]), 1.0)\n\n    # Test the Fowlkes-Mallows score with random labelings\n    assert_almost_equal(fowlkes_mallows_score([0, 0, 0, 0], [0, 1, 2, 3]), 0.0)\n\n    # Test the Fowlkes-Mallows score with sparse matrix\n    assert_almost_equal(fowlkes_mallows_score([0, 0, 1, 1], [0, 0, 1, 1], sparse=True), 1.0)\n    assert_almost_equal(fowlkes_mallows_score([0, 0, 1, 1], [1, 1, 0, 0], sparse=True), 1.0)\n    assert_almost_equal(fowlkes_mallows_score([0, 0, 0, 0], [0, 1, 2, 3], sparse=True), 0.0)\n\n    # Test the Fowlkes-Mallows score with edge cases\n    assert_almost_equal(fowlkes_mallows_score([], []), 1.0)\n    assert_almost_equal(fowlkes_mallows_score([0], [0]), 1.0)\n    assert_almost_equal(fowlkes_mallows_score([0, 0], [0, 0]), 1.0)\n"], "sample_936": ["def test_stringify():\n    assert stringify(int) == 'int'\n    assert stringify(str) == 'str'\n    assert stringify(List) == 'List'\n    assert stringify(Dict) == 'Dict'\n    assert stringify(Union) == 'Union'\n    assert stringify(Callable) == 'Callable'\n    assert stringify(Tuple) == 'Tuple'\n    assert stringify(Any) == 'Any'\n    assert stringify(None) == 'None'\n    assert stringify(Ellipsis) == '...'\n    assert stringify(MyClass1) == 'MyClass1'\n    assert stringify(MyClass2) == '<MyClass2>'\n    assert stringify(MyList) == 'List[T]'\n    assert stringify(BrokenType) == 'BrokenType'\n    assert stringify(Optional[int]) == 'Optional[int]'\n    assert stringify(Union[int, str]) == 'Union[int, str]'\n    assert stringify(Callable[[int, str], int]) == 'Callable[[int, str], int]'\n    assert stringify(Tuple[int, str]) == 'Tuple[int, str]'\n    assert stringify(Generic) == 'Generic'\n    assert stringify(List[int]) == 'List[int]'\n    assert stringify(Dict[str, int]) == 'Dict[str, int]'\n    assert stringify(Union[int, None]) == 'Optional[int]'\n    assert stringify(Union[int, str, None]) == 'Optional[Union[int, str]]'\n    assert stringify(Callable[..., int]) == 'Callable[..., int]'\n    assert stringify(Tuple[int, ...]) == 'Tuple[int, ...]'\n"], "sample_99": ["    def test_trunc_timezone_aware(self):\n        tz = pytz.timezone('America/New_York')\n        dt = datetime(2022, 3, 13, 1, 59, tzinfo=tz)\n        self.create_model(dt, dt + timedelta(hours=1))\n\n        # Test truncation to hour before and after DST transition\n        self.assertEqual(\n            DTModel.objects.annotate(trunc_hour=Trunc('start_datetime', 'hour', tzinfo=tz)).get().trunc_hour,\n            truncate_to(dt, 'hour', tzinfo=tz)\n        )\n        self.assertEqual(\n            DTModel.objects.annotate(trunc_hour=Trunc('end_datetime', 'hour', tzinfo=tz)).get().trunc_hour,\n            truncate_to(dt + timedelta(hours=1), 'hour', tzinfo=tz)\n        )\n\n        # Test truncation to day before and after DST transition\n        self.assertEqual(\n            DTModel.objects.annotate(trunc_day=Trunc('start_datetime', 'day', tzinfo=tz)).get().trunc_day,\n            truncate_to(dt, 'day', tzinfo=tz)\n        )\n        self.assertEqual(\n            DTModel.objects.annotate(trunc_day=Trunc('end_datetime', 'day', tzinfo=tz)).get().trunc_day,\n            truncate_to(dt + timedelta(hours=1), 'day', tzinfo=tz)\n        )\n"], "sample_67": ["    def test_model_form_metaclass(self):\n        class TestModel(models.Model):\n            pass\n\n        class TestForm(forms.ModelForm):\n            class Meta:\n                model = TestModel\n\n        self.assertEqual(TestForm._meta.model, TestModel)\n"], "sample_140": ["    def test_sensitive_variables_decorator(self):\n        @sensitive_variables('user', 'password')\n            pass\n\n        self.assertEqual(test_function.sensitive_variables, ('user', 'password'))\n"], "sample_125": ["def test_set_cookie_with_expires(self):\n    response = HttpResponse()\n    expires = datetime(2022, 1, 1, tzinfo=utc)\n    response.set_cookie('key', 'value', expires=expires)\n    self.assertEqual(response.cookies['key']['expires'], http_date(expires.timestamp()))\n"], "sample_483": ["    def test_check_dependencies(self):\n        with self.settings(\n            INSTALLED_APPS=[\n                \"django.contrib.admin\",\n                \"django.contrib.auth\",\n                \"django.contrib.contenttypes\",\n                \"django.contrib.messages\",\n                \"admin_checks\",\n            ],\n            TEMPLATES=[\n                {\n                    \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n                    \"DIRS\": [],\n                    \"APP_DIRS\": True,\n                    \"OPTIONS\": {\n                        \"context_processors\": [\n                            \"django.template.context_processors.debug\",\n                            \"django.template.context_processors.request\",\n                            \"django.contrib.auth.context_processors.auth\",\n                            \"django.contrib.messages.context_processors.messages\",\n                        ],\n                    },\n                },\n            ],\n            MIDDLEWARE=[\n                \"django.contrib.sessions.middleware.SessionMiddleware\",\n                \"django.contrib.auth.middleware.AuthenticationMiddleware\",\n                \"django.contrib.messages.middleware.MessageMiddleware\",\n            ],\n            AUTHENTICATION_BACKENDS=[\"django.contrib.auth.backends.ModelBackend\"],\n        ):\n            errors = check_dependencies()\n            self.assertEqual(errors, [])\n"], "sample_169": ["def test_xml_serializer(self):\n    # Create a test model instance\n    json_model = JSONModel.objects.create(data={'key': 'value'})\n\n    # Serialize the model instance to XML\n    serializer = serializers.get_serializer('xml')()\n    xml_data = serializer.serialize([json_model])\n\n    # Deserialize the XML data back to a Python object\n    deserializer = serializers.get_deserializer('xml')()\n    deserialized_objects = list(deserializer.deserialize(xml_data, ignorenonexistent=True))\n\n    # Check that the deserialized object matches the original model instance\n    self.assertEqual(len(deserialized_objects), 1)\n    deserialized_model = deserialized_objects[0].object\n    self.assertEqual(deserialized_model.data, json_model.data)\n"], "sample_458": ["def test_floatformat_decimal_places(self):\n    with translation.override(\"en\"):\n        with localcontext() as ctx:\n            ctx.prec = 10\n            a = Decimal(\"34.23234\")\n            b = Decimal(\"34.00000\")\n            c = Decimal(\"34.26000\")\n            self.assertEqual(\n                floatformat(a, 3),\n                mark_safe(\"34.232\"),\n            )\n            self.assertEqual(\n                floatformat(b, 3),\n                mark_safe(\"34.000\"),\n            )\n            self.assertEqual(\n                floatformat(c, 3),\n                mark_safe(\"34.260\"),\n            )\n            self.assertEqual(\n                floatformat(a, -3),\n                mark_safe(\"34.232\"),\n            )\n            self.assertEqual(\n                floatformat(b, -3),\n                mark_safe(\"34\"),\n            )\n            self.assertEqual(\n                floatformat(c, -3),\n                mark_safe(\"34.260\"),\n            )\n"], "sample_1187": ["def test_polytope_integrate():\n    # Test 2D Polytope\n    polygon = Polygon(Point(0, 0), Point(0, 1), Point(1, 1), Point(1, 0))\n    polys = [1, x, y, x*y, x**2*y, x*y**2]\n    expr = x*y\n    assert polytope_integrate(polygon, expr) == Rational(1, 4)\n    assert polytope_integrate(polygon, polys, max_degree=3) == {1: 1, x: Rational(1, 2), y: Rational(1, 2), x*y: Rational(1, 4), x*y**2: Rational(1, 6), x**2*y: Rational(1, 6)}\n\n    # Test 3D Polytope\n    cube = [[(0, 0, 0), (0, 0, 5), (0, 5, 0), (0, 5, 5), (5, 0, 0), (5, 0, 5), (5, 5, 0), (5, 5, 5)],\n            [2, 6, 7, 3], [3, 7, 5, 1], [7, 6, 4, 5], [1, 5, 4, 0], [3, 1, 0, 2], [0, 4, 6, 2]]\n    vertices = cube[0]\n    faces = cube[1:]\n    hp_params = hyperplane_parameters(faces, vertices)\n    assert main_integrate3d(1, faces, vertices, hp_params) == -125\n\n    # Test clockwise parameter\n    assert polytope_integrate(polygon, expr, clockwise=True) == Rational(1, 4)\n\n    # Test max_degree parameter\n    assert polytope_integrate(polygon, polys, max_degree=3, clockwise=True) == {1: 1, x: Rational(1, 2), y: Rational(1, 2), x*y: Rational(1, 4), x*y**2: Rational(1, 6), x**2*y: Rational(1, 6)}\n\n    # Test invalid input\n    try:\n        polytope"], "sample_808": ["def test_isolation_forest_sparse_input():\n    \"\"\"Test that IsolationForest works with sparse input.\"\"\"\n    X = csc_matrix(iris.data)\n    y = iris.target\n\n    iforest = IsolationForest(n_estimators=10, random_state=rng)\n    iforest.fit(X, y)\n\n    assert_array_almost_equal(iforest.score_samples(X), iforest.score_samples(X.toarray()))\n\n    iforest = IsolationForest(n_estimators=10, random_state=rng)\n    iforest.fit(X.toarray(), y)\n\n    assert_array_almost_equal(iforest.score_samples(X), iforest.score_samples(X.toarray()))\n\n    # Test with csr_matrix\n    X = csr_matrix(iris.data)\n    iforest = IsolationForest(n_estimators=10, random_state=rng)\n    iforest.fit(X, y)\n\n    assert_array_almost_equal(iforest.score_samples(X), iforest.score_samples(X.toarray()))\n\n    iforest = IsolationForest(n_estimators=10, random_state=rng)\n    iforest.fit(X.toarray(), y)\n\n    assert_array_almost_equal(iforest.score_samples(X), iforest.score_samples(X.toarray()))\n"], "sample_867": ["def test_search_cv_refit_callable(klass):\n    # Test that refit can be a callable\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5,\n                               n_redundant=3, n_classes=2, random_state=0)\n    param_grid = {'C': [0.1, 1, 10]}\n        return np.argmax(cv_results['mean_test_score'])\n\n    search = klass(SVC(), param_grid, refit=refit_func, cv=2)\n    search.fit(X, y)\n\n    assert search.best_index_ == refit_func(search.cv_results_)\n    assert search.best_estimator_ is not None\n    assert search.best_params_ == search.cv_results_['params'][search.best_index_]\n"], "sample_519": ["def test_subplots_adjust():\n    fig, axs = plt.subplots(2, 2)\n    axs[0, 0].set_title('Title 1')\n    axs[1, 0].set_title('Title 2')\n    axs[0, 1].set_title('Title 3')\n    axs[1, 1].set_title('Title 4')\n\n    fig.subplots_adjust(top=0.8)\n\n    fig2, axs2 = plt.subplots(2, 2)\n    axs2[0, 0].set_title('Title 1')\n    axs2[1, 0].set_title('Title 2')\n    axs2[0, 1].set_title('Title 3')\n    axs2[1, 1].set_title('Title 4')\n\n    fig2.subplots_adjust(top=0.9)\n\n    assert not check_figures_equal(fig, fig2)\n"], "sample_851": ["def test_mean_tweedie_deviance():\n    # Test mean Tweedie deviance with power=0 (Normal distribution)\n    y_true = np.array([1, 2, 3, 4])\n    y_pred = np.array([1.1, 1.9, 3.2, 3.8])\n    assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, power=0),\n                        mean_squared_error(y_true, y_pred))\n\n    # Test mean Tweedie deviance with power=1 (Poisson distribution)\n    y_true = np.array([1, 2, 3, 4])\n    y_pred = np.array([1.1, 1.9, 3.2, 3.8])\n    assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, power=1),\n                        mean_poisson_deviance(y_true, y_pred))\n\n    # Test mean Tweedie deviance with power=2 (Gamma distribution)\n    y_true = np.array([1, 2, 3, 4])\n    y_pred = np.array([1.1, 1.9, 3.2, 3.8])\n    assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, power=2),\n                        mean_gamma_deviance(y_true, y_pred))\n\n    # Test mean Tweedie deviance with power=3 (Inverse Gaussian distribution)\n    y_true = np.array([1, 2, 3, 4])\n    y_pred = np.array([1.1, 1.9, 3.2, 3.8])\n    assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, power=3),\n                        2 * (np.log(y_pred/y_true) + y_true**3/y_pred**2 - 1))\n\n    # Test mean Tweedie deviance with sample weights\n    y_true = np.array([1, 2, 3, 4])\n    y_pred = np.array([1.1, 1.9, 3.2, 3.8])\n    sample_weight = np.array([0.1, 0.2, 0.3, 0.4])\n    assert_almost_equal(mean_tweedie_deviance(y_true, y_pred, sample_weight, power=0),\n                        np.average((y_true - y"], "sample_32": ["    def test_w(self):\n        \"\"\"Test w0wzCDM.w\"\"\"\n        cosmo = self._cls(**self._cls_kwargs)\n        z = np.linspace(0, 10, 100)\n        w = cosmo.w(z)\n        assert np.allclose(w, cosmo.w0 + cosmo.wz * z)\n"], "sample_945": ["def test_parse_annotation():\n    env = Mock(spec=['config'])\n    env.config.python_use_unqualified_type_names = False\n\n    # Test simple type\n    annotation = 'int'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'int'\n\n    # Test type with module\n    annotation = 'module.Type'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'module.Type'\n\n    # Test type with module and class\n    annotation = 'module.Class.Type'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'module.Class.Type'\n\n    # Test type with nested types\n    annotation = 'List[int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 3\n    assert isinstance(result[0], nodes.Text)\n    assert result[0].astext() == 'List'\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == '['\n    assert isinstance(result[2], pending_xref)\n    assert result[2].attributes['reftarget'] == 'int'\n\n    # Test type with nested types and module\n    annotation = 'module.List[int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 3\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'module.List'\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == '['\n    assert isinstance(result[2], pending_xref)\n    assert result[2].attributes['reftarget'] == 'int'\n\n    # Test type with nested types and module and class\n    annotation = 'module.Class.List[int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 3\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'module.Class.List'\n    assert isinstance(result[1],"], "sample_90": ["    def test_model_form_metaclass(self):\n        class TestModel(models.Model):\n            name = models.CharField(max_length=255)\n\n        class TestForm(forms.ModelForm):\n            class Meta:\n                model = TestModel\n                fields = ('name',)\n\n        self.assertEqual(TestForm._meta.model, TestModel)\n        self.assertEqual(TestForm._meta.fields, ('name',))\n"], "sample_15": ["def test_quantity_subclass():\n    class TestQuantity(SpecificTypeQuantity):\n        _equivalent_unit = u.m\n\n    q = TestQuantity(1, u.m)\n    assert q.__quantity_subclass__(u.m)[0] is TestQuantity\n    assert q.__quantity_subclass__(u.cm)[0] is TestQuantity\n    assert q.__quantity_subclass__(u.s)[0] is Quantity\n"], "sample_1083": ["def test_hyperbolic_functions():\n    x = Symbol('x')\n    y = Symbol('y')\n\n    # Test sinh\n    assert sinh(x).diff(x) == cosh(x)\n    assert sinh(x).diff(y) == 0\n    assert sinh(0) == 0\n    assert sinh(pi*I/2) == I\n    assert sinh(pi*I) == 0\n    assert sinh(-pi*I/2) == -I\n    assert sinh(-pi*I) == 0\n    assert sinh(oo) == oo\n    assert sinh(-oo) == -oo\n    assert sinh(nan) == nan\n    assert sinh(zoo) == zoo\n\n    # Test cosh\n    assert cosh(x).diff(x) == sinh(x)\n    assert cosh(x).diff(y) == 0\n    assert cosh(0) == 1\n    assert cosh(pi*I/2) == 0\n    assert cosh(pi*I) == -1\n    assert cosh(-pi*I/2) == 0\n    assert cosh(-pi*I) == -1\n    assert cosh(oo) == oo\n    assert cosh(-oo) == oo\n    assert cosh(nan) == nan\n    assert cosh(zoo) == zoo\n\n    # Test tanh\n    assert tanh(x).diff(x) == 1 - tanh(x)**2\n    assert tanh(x).diff(y) == 0\n    assert tanh(0) == 0\n    assert tanh(pi*I/4) == I\n    assert tanh(pi*I/2) == -I\n    assert tanh(-pi*I/4) == -I\n    assert tanh(-pi*I/2) == I\n    assert tanh(oo) == 1\n    assert tanh(-oo) == -1\n    assert tanh(nan) == nan\n    assert tanh(zoo) == zoo\n\n    # Test coth\n    assert coth(x).diff(x) == -1/sinh(x)**2\n    assert coth(x).diff(y) == 0\n    assert coth(0) == zoo\n    assert coth(pi*I/2) == 0\n    assert coth(pi*I) == -I\n    assert coth(-pi*I/2) == 0\n    assert coth(-"], "sample_295": ["def test_expression_wrapper(self):\n    expression = F('name')\n    wrapped_expression = ExpressionWrapper(expression, output_field=CharField())\n    self.assertEqual(wrapped_expression.output_field.get_internal_type(), 'CharField')\n    self.assertEqual(wrapped_expression.get_group_by_cols(), [wrapped_expression])\n"], "sample_507": ["    def test_update(self, data, locs):\n        ud = cat.UnitData()\n        ud.update(data)\n        assert list(ud._mapping.keys()) == data\n        assert list(ud._mapping.values()) == locs\n"], "sample_136": ["    def test_get_signed_cookie(self):\n        request = HttpRequest()\n        request.COOKIES = {'signed_cookie': 'signed_value'}\n        with self.settings(SESSION_COOKIE_SALT='test_salt'):\n            self.assertEqual(request.get_signed_cookie('signed_cookie', salt='test_salt'), 'signed_value')\n            self.assertIsNone(request.get_signed_cookie('unsigned_cookie', default=None, salt='test_salt'))\n            with self.assertRaises(signing.BadSignature):\n                request.get_signed_cookie('signed_cookie', salt='wrong_salt')\n"], "sample_25": ["def test_card_fromstring(fits_file):\n    card = fits.Card.fromstring(fits_file[0])\n    assert card.keyword == \"SIMPLE\"\n    assert card.value == True\n    assert card.comment == \"file does conform to FITS standard\"\n\n    card = fits.Card.fromstring(fits_file[1])\n    assert card.keyword == \"BITPIX\"\n    assert card.value == 8\n    assert card.comment == \"number of bits per data pixel\"\n\n    card = fits.Card.fromstring(fits_file[2])\n    assert card.keyword == \"NAXIS\"\n    assert card.value == 0\n    assert card.comment == \"number of data axes\"\n\n    card = fits.Card.fromstring(fits_file[3])\n    assert card.keyword == \"EXTEND\"\n    assert card.value == True\n    assert card.comment == \"FITS dataset may contain extensions\"\n\n    card = fits.Card.fromstring(fits_file[4])\n    assert card.keyword == \"COMMENT\"\n    assert card.value == \"FITS (Flexible Image Transport System) format is defined in 'Astronomy\"\n    assert card.comment == \"\"\n\n    card = fits.Card.fromstring(fits_file[5])\n    assert card.keyword == \"HISTORY\"\n    assert card.value == \"FITS (Flexible Image Transport System) format is defined in 'Astronomy\"\n    assert card.comment == \"\"\n\n    card = fits.Card.fromstring(fits_file[6])\n    assert card.keyword == \"END\"\n    assert card.value == \"\"\n    assert card.comment == \"\"\n"], "sample_684": ["def test_traceback_entry_repr():\n    frame = mock.Mock(spec=FrameType)\n    frame.f_lineno = 10\n    frame.f_code.co_filename = \"test_file.py\"\n    frame.f_code.co_name = \"test_function\"\n    frame.f_locals = {\"var1\": \"value1\", \"var2\": \"value2\"}\n\n    traceback_entry = TracebackEntry(frame)\n    assert repr(traceback_entry) == \"<TracebackEntry test_file.py:10>\"\n\n    assert traceback_entry.lineno == 9\n    assert traceback_entry.frame.code.path == \"test_file.py\"\n    assert traceback_entry.frame.code.name == \"test_function\"\n\n    assert traceback_entry.statement == Source(\"\")\n\n    assert traceback_entry.path == \"test_file.py\"\n    assert traceback_entry.locals == {\"var1\": \"value1\", \"var2\": \"value2\"}\n\n    assert traceback_entry.getfirstlinesource() == 0\n    assert traceback_entry.getsource() is None\n\n    assert traceback_entry.ishidden() is False\n\n    assert str(traceback_entry) == \"  File 'test_file.py':10 in test_function\\n  ???\\n\"\n\n    assert traceback_entry.name == \"test_function\"\n"], "sample_657": ["    def test_mark_decorator(self):\n        @Mark.slowtest\n            pass\n\n        assert len(get_unpacked_marks(test_function)) == 1\n        assert get_unpacked_marks(test_function)[0].name == \"slowtest\"\n\n        @Mark.slowtest(\"reason\")\n            pass\n\n        assert len(get_unpacked_marks(test_function_with_reason)) == 1\n        assert get_unpacked_marks(test_function_with_reason)[0].name == \"slowtest\"\n        assert get_unpacked_marks(test_function_with_reason)[0].args == (\"reason\",)\n\n        @Mark.slowtest(reason=\"slow\")\n            pass\n\n        assert len(get_unpacked_marks(test_function_with_kwarg)) == 1\n        assert get_unpacked_marks(test_function_with_kwarg)[0].name == \"slowtest\"\n        assert get_unpacked_marks(test_function_with_kwarg)[0].kwargs == {\"reason\": \"slow\"}\n\n        @Mark.slowtest(\"reason\", \"another\")\n            pass\n\n        assert len(get_unpacked_marks(test_function_with_multiple_args)) == 1\n        assert get_unpacked_marks(test_function_with_multiple_args)[0].name == \"slowtest\"\n        assert get_unpacked_marks(test_function_with_multiple_args)[0].args == (\"reason\", \"another\")\n\n        @Mark.slowtest(reason=\"slow\", another=\"arg\")\n            pass\n\n        assert len(get_unpacked_marks(test_function_with_multiple_kwargs)) == 1\n        assert get_unpacked_marks(test_function_with_multiple_kwargs)[0].name == \"slowtest\"\n        assert get_unpacked_marks(test_function_with_multiple_kwargs)[0].kwargs == {\"reason\": \"slow\", \"another\": \"arg\"}\n"], "sample_1091": ["def test_relational():\n    # Test Relational class\n    assert Relational.ValidRelationOperator['=='] == Equality\n    assert Relational.ValidRelationOperator['!='] == Unequality\n    assert Relational.ValidRelationOperator['>='] == GreaterThan\n    assert Relational.ValidRelationOperator['<='] == LessThan\n    assert Relational.ValidRelationOperator['>'] == StrictGreaterThan\n    assert Relational.ValidRelationOperator['<'] == StrictLessThan\n\n    # Test Relational properties\n    rel = Relational(x, y)\n    assert rel.lhs == x\n    assert rel.rhs == y\n    assert rel.reversed == Relational(y, x)\n    assert rel.reversedsign == Relational(-x, -y)\n\n    # Test Relational methods\n    assert rel.equals(rel) == True\n    assert rel.equals(Relational(y, x)) == True\n    assert rel.equals(Relational(x, z)) == False\n\n    # Test Relational canonical form\n    rel = Relational(-x, y)\n    assert rel.canonical == Relational(y, -x)\n    rel = Relational(x, -y)\n    assert rel.canonical == Relational(y, -x)\n\n    # Test Relational simplify\n    rel = Relational(x + 1, x)\n    assert rel.simplify() == Relational(1, 0)\n\n    # Test Relational expand\n    rel = Relational(x + 1, x)\n    assert rel.expand() == Relational(x + 1, x)\n\n    # Test Relational as_set\n    rel = Relational(x, 1)\n    assert rel.as_set() == ConditionSet(x, Eq(x, 1), Reals)\n\n    # Test Relational binary_symbols\n    rel = Relational(x, 1)\n    assert rel.binary_symbols == {x}\n"], "sample_789": ["def test_adaboost_regressor():\n    # Test that AdaBoostRegressor works with different base estimators\n    estimators = [DecisionTreeRegressor(max_depth=3),\n                  DecisionTreeRegressor(max_depth=5),\n                  DecisionTreeRegressor(max_depth=10)]\n\n    for estimator in estimators:\n        clf = AdaBoostRegressor(base_estimator=estimator, n_estimators=10,\n                                random_state=rng)\n        clf.fit(boston.data, boston.target)\n        assert_array_less(clf.predict(boston.data), 100)\n        assert_array_less(100, clf.predict(boston.data) * 2)\n\n    # Test that AdaBoostRegressor works with different loss functions\n    losses = ['linear', 'square', 'exponential']\n\n    for loss in losses:\n        clf = AdaBoostRegressor(loss=loss, n_estimators=10, random_state=rng)\n        clf.fit(boston.data, boston.target)\n        assert_array_less(clf.predict(boston.data), 100)\n        assert_array_less(100, clf.predict(boston.data) * 2)\n\n    # Test that AdaBoostRegressor works with different learning rates\n    learning_rates = [0.1, 0.5, 1.0]\n\n    for learning_rate in learning_rates:\n        clf = AdaBoostRegressor(learning_rate=learning_rate, n_estimators=10,\n                                random_state=rng)\n        clf.fit(boston.data, boston.target)\n        assert_array_less(clf.predict(boston.data), 100)\n        assert_array_less(100, clf.predict(boston.data) * 2)\n\n    # Test that AdaBoostRegressor raises an error with invalid loss\n    with assert_raises(ValueError):\n        AdaBoostRegressor(loss='invalid', n_estimators=10, random_state=rng)\n\n    # Test that AdaBoostRegressor raises an error with invalid learning rate\n    with assert_raises(ValueError):\n        AdaBoostRegressor(learning_rate=-1, n_estimators=10, random_state=rng)\n"], "sample_690": ["    def test_evaluate_xfail_marks_with_strict(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            textwrap.dedent(\n                \"\"\"\\\n                import pytest\n\n                @pytest.mark.xfail(strict=True)\n                    assert 1 == 2\n                \"\"\"\n            )\n        )\n        result = pytester.runpytest()\n        result.assert_outcomes(passed=0, failed=1, xfailed=0)\n        result.stdout.fnmatch_lines([\"*XPASS(strict)*\"])\n"], "sample_708": ["def test_getstatementrange_ast():\n    # Test getstatementrange_ast with a simple function\n        a = 1\n        b = 2\n        if a > b:\n            print(\"a is greater than b\")\n        else:\n            print(\"a is less than or equal to b\")\n\n    source = Source(test_func)\n    lineno = 3  # Line number of the if statement\n    astnode, start, end = getstatementrange_ast(lineno, source)\n    assert start == 2\n    assert end == 6\n\n    # Test getstatementrange_ast with a function containing a docstring\n        \"\"\"This is a docstring\"\"\"\n        a = 1\n        b = 2\n        if a > b:\n            print(\"a is greater than b\")\n        else:\n            print(\"a is less than or equal to b\")\n\n    source = Source(test_func_with_docstring)\n    lineno = 4  # Line number of the if statement\n    astnode, start, end = getstatementrange_ast(lineno, source)\n    assert start == 3\n    assert end == 7\n\n    # Test getstatementrange_ast with a function containing a nested function\n            a = 1\n            b = 2\n            if a > b:\n                print(\"a is greater than b\")\n            else:\n                print(\"a is less than or equal to b\")\n\n        nested_func()\n\n    source = Source(test_func_with_nested_func)\n    lineno = 4  # Line number of the if statement in the nested function\n    astnode, start, end = getstatementrange_ast(lineno, source)\n    assert start == 3\n    assert end == 7\n\n    # Test getstatementrange_ast with a function containing a try-except block\n        try:\n            a = 1\n            b = 2\n            if a > b:\n                print(\"a is greater than b\")\n            else:\n                print(\"a is less than or equal to b\")\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n\n    source = Source(test_func_with_try_except)\n    lineno = 4  # Line number of the if statement\n    astnode, start, end = getstatementrange_ast(lineno,"], "sample_856": ["def test_leave_p_groups_out():\n    # Test LeavePGroupsOut with different values of p\n    for p in range(1, 4):\n        logo = LeavePGroupsOut(p)\n        groups = np.array([1, 1, 1, 2, 2, 3, 3, 3, 3, 3])\n        X = np.ones((10, 2))\n        y = np.arange(10)\n        train_test_indices = list(logo.split(X, y, groups))\n        assert len(train_test_indices) == comb(len(np.unique(groups)), p)\n        for train, test in train_test_indices:\n            assert len(train) + len(test) == len(X)\n            assert len(set(groups[test])) == p\n"], "sample_751": ["def test_random_forest_classifier():\n    # Test that the forest correctly classifies the samples\n    clf = RandomForestClassifier(n_estimators=10, random_state=rng)\n    clf.fit(X, y_class)\n    assert_array_equal(clf.predict(X), y_class)\n\n    # Test that the forest correctly classifies the test set\n    clf.fit(X, y_class)\n    assert_array_equal(clf.predict(T), y_t_class)\n\n    # Test that the forest raises an error for an empty forest\n    clf = RandomForestClassifier(n_estimators=0, random_state=rng)\n    assert_raises(ValueError, clf.fit, X, y_class)\n\n    # Test that the forest raises an error for a negative number of estimators\n    clf = RandomForestClassifier(n_estimators=-1, random_state=rng)\n    assert_raises(ValueError, clf.fit, X, y_class)\n\n    # Test that the forest raises an error for a non-integer number of estimators\n    clf = RandomForestClassifier(n_estimators=10.5, random_state=rng)\n    assert_raises(ValueError, clf.fit, X, y_class)\n\n    # Test that the forest raises an error for a non-integer number of jobs\n    clf = RandomForestClassifier(n_estimators=10, n_jobs=1.5, random_state=rng)\n    assert_raises(ValueError, clf.fit, X, y_class)\n\n    # Test that the forest raises an error for a negative number of jobs\n    clf = RandomForestClassifier(n_estimators=10, n_jobs=-1, random_state=rng)\n    assert_raises(ValueError, clf.fit, X, y_class)\n\n    # Test that the forest raises an error for a non-integer number of features\n    clf = RandomForestClassifier(n_estimators=10, max_features=1.5, random_state=rng)\n    assert_raises(ValueError, clf.fit, X, y_class)\n\n    # Test that the forest raises an error for a negative number of features\n    clf = RandomForestClassifier(n_estimators=10, max_features=-1, random_state=rng)\n    assert_raises(ValueError, clf.fit, X, y_class)\n\n    # Test that the forest raises an error for a non-integer number of samples\n    clf = RandomForestClassifier(n_estimators=10, min_samples_split=1.5, random_state=rng)\n    assert_raises(ValueError, clf.fit, X, y_class)\n\n    # Test that the forest raises an error for a negative number of samples\n    clf = RandomForestClassifier(n_estimators=10, min"], "sample_529": ["def test_legend_title():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], label='Line 1')\n    ax.plot([2, 3, 4], label='Line 2')\n    ax.legend(title='Legend Title')\n    ax.set_title('Legend with Title')\n"], "sample_222": ["def test_lock_file(self):\n    with tempfile.NamedTemporaryFile() as f:\n        self.assertTrue(locks.lock(f, locks.LOCK_EX))\n        self.assertFalse(locks.lock(f, locks.LOCK_EX))\n        self.assertTrue(locks.unlock(f))\n        self.assertTrue(locks.lock(f, locks.LOCK_SH))\n        self.assertTrue(locks.unlock(f))\n"], "sample_1053": ["def test_mod_inverse():\n    assert mod_inverse(2, 3) == 2\n    assert mod_inverse(-2, 3) == 1\n    assert mod_inverse(2, 4) == 1\n    assert mod_inverse(2, 5) == 3\n    assert mod_inverse(3, 11) == 4\n    assert mod_inverse(7, 19) == 11\n    assert mod_inverse(42, 55) == 38\n    assert mod_inverse(7, 17) == 5\n    assert mod_inverse(1, 1) == 1\n    assert mod_inverse(1, 2) == 1\n    assert mod_inverse(1, 3) == 1\n    assert mod_inverse(1, 4) == 1\n    assert mod_inverse(1, 5) == 1\n    assert mod_inverse(1, 6) == 1\n    assert mod_inverse(1, 7) == 1\n    assert mod_inverse(1, 8) == 1\n    assert mod_inverse(1, 9) == 1\n    assert mod_inverse(1, 10) == 1\n    assert mod_inverse(1, 11) == 1\n    assert mod_inverse(1, 12) == 1\n    assert mod_inverse(1, 13) == 1\n    assert mod_inverse(1, 14) == 1\n    assert mod_inverse(1, 15) == 1\n    assert mod_inverse(1, 16) == 1\n    assert mod_inverse(1, 17) == 1\n    assert mod_inverse(1, 18) == 1\n    assert mod_inverse(1, 19) == 1\n    assert mod_inverse(1, 20) == 1\n    assert mod_inverse(2, 1) == 0\n    assert mod_inverse(3, 1) == 0\n    assert mod_inverse(4, 1) == 0\n    assert mod_inverse(5, 1) == 0\n    assert mod_inverse(6, 1) == 0\n    assert mod_inverse(7, 1) == 0\n    assert mod_inverse(8, 1) == 0\n    assert mod_inverse(9, 1) == 0\n"], "sample_852": ["def test_make_classification():\n    # Test that the generated data is finite\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=10,\n                               n_redundant=0, n_repeated=0, n_classes=2,\n                               n_clusters_per_class=1, weights=None,\n                               flip_y=0.01, class_sep=1.0, hypercube=True,\n                               shift=0.0, scale=1.0, shuffle=True,\n                               random_state=0)\n    assert_all_finite(X)\n    assert_all_finite(y)\n\n    # Test that the generated data has the correct shape\n    assert X.shape == (100, 20)\n    assert y.shape == (100,)\n\n    # Test that the generated data has the correct number of classes\n    assert len(np.unique(y)) == 2\n\n    # Test that the generated data has the correct number of informative features\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=10,\n                               n_redundant=0, n_repeated=0, n_classes=2,\n                               n_clusters_per_class=1, weights=None,\n                               flip_y=0.01, class_sep=1.0, hypercube=True,\n                               shift=0.0, scale=1.0, shuffle=True,\n                               random_state=0)\n    assert X.shape[1] == 20\n\n    # Test that the generated data has the correct number of redundant features\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=10,\n                               n_redundant=5, n_repeated=0, n_classes=2,\n                               n_clusters_per_class=1, weights=None,\n                               flip_y=0.01, class_sep=1.0, hypercube=True,\n                               shift=0.0, scale=1.0, shuffle=True,\n                               random_state=0)\n    assert X.shape[1] == 20\n\n    # Test that the generated data has the correct number of repeated features\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=10,\n                               n_redundant=0, n_repeated=5, n_classes=2,\n                               n_clusters_per_class=1, weights=None,\n                               flip_y=0.01, class_sep=1."], "sample_971": ["def test_getLogger():\n    logger = logging.getLogger(__name__)\n    assert isinstance(logger, logging.LoggerAdapter)\n    assert logger.name.startswith('sphinx.')\n\n"], "sample_502": ["def test_switch_backend():\n    # Test that switching backend works\n    original_backend = mpl.get_backend()\n    plt.switch_backend('agg')\n    assert mpl.get_backend() == 'agg'\n    plt.switch_backend(original_backend)\n    assert mpl.get_backend() == original_backend\n\n    # Test that switching to an invalid backend raises an ImportError\n    with pytest.raises(ImportError):\n        plt.switch_backend('invalid_backend')\n\n    # Test that switching to a backend that requires an interactive framework\n    # raises an ImportError if no interactive framework is running\n    if not mpl.is_interactive():\n        with pytest.raises(ImportError):\n            plt.switch_backend('qt5agg')\n"], "sample_207": ["def test_jsonfield_encoder_decoder(self):\n    class CustomEncoder(json.JSONEncoder):\n            if isinstance(obj, uuid.UUID):\n                return str(obj)\n            return super().default(obj)\n\n    class CustomDecoder(json.JSONDecoder):\n            super().__init__(object_hook=self.dict_to_uuid, *args, **kwargs)\n\n            if 'uuid' in d:\n                d['uuid'] = uuid.UUID(d['uuid'])\n            return d\n\n    field = JSONField(encoder=CustomEncoder, decoder=CustomDecoder)\n    obj = {'uuid': uuid.uuid4()}\n    encoded = field.get_prep_value(obj)\n    decoded = field.from_db_value(encoded, None, connection)\n    self.assertIsInstance(decoded['uuid'], uuid.UUID)\n"], "sample_250": ["def test_format_date(self):\n    d = date(2003, 10, 7)\n    self.assertEqual(format(d, 'jS F Y'), '7th October 2003')\n    self.assertEqual(format(d, 'l, jS F Y'), 'Tuesday, 7th October 2003')\n    self.assertEqual(format(d, 'jS F Y H:i'), '7th October 2003 00:00')\n    self.assertEqual(format(d, 'jS F Y H:i:s'), '7th October 2003 00:00:00')\n    self.assertEqual(format(d, 'Y-m-d'), '2003-10-07')\n    self.assertEqual(format(d, 'Y-m-d H:i'), '2003-10-07 00:00')\n    self.assertEqual(format(d, 'Y-m-d H:i:s'), '2003-10-07 00:00:00')\n    self.assertEqual(format(d, 'Y/m/d'), '2003/10/07')\n    self.assertEqual(format(d, 'Y/m/d H:i'), '2003/10/07 00:00')\n    self.assertEqual(format(d, 'Y/m/d H:i:s'), '2003/10/07 00:00:00')\n    self.assertEqual(format(d, 'd/m/Y'), '07/10/2003')\n    self.assertEqual(format(d, 'd/m/Y H:i'), '07/10/2003 00:00')\n    self.assertEqual(format(d, 'd/m/Y H:i:s'), '07/10/2003 00:00:00')\n    self.assertEqual(format(d, 'd M Y'), '7 Oct 2003')\n    self.assertEqual(format(d, 'd M Y H:i'), '7 Oct 2003 00:00')\n    self.assertEqual(format(d, 'd M Y H:i:s'), '7 Oct 2003 00:00:00')\n    self.assertEqual(format(d, 'd F Y'), '7 October 2003')\n    self.assertEqual(format(d, 'd F Y H:i'), '7 October 2003 00:00')\n    self.assertEqual(format(d, 'd F Y H:i:s'), '7 October 2003 00:00:00')\n"], "sample_106": ["    def test_patch_cache_control(self):\n        response = HttpResponse()\n        patch_cache_control(response, max_age=3600, public=True)\n        self.assertEqual(response['Cache-Control'], 'max-age=3600, public')\n"], "sample_166": ["def test_salted_hmac(self):\n    key_salt = 'test_key_salt'\n    value = 'test_value'\n    secret = 'test_secret'\n    algorithm = 'sha256'\n\n    # Test with default secret (settings.SECRET_KEY)\n    hmac_obj = salted_hmac(key_salt, value)\n    self.assertIsInstance(hmac_obj, hmac.HMAC)\n\n    # Test with custom secret\n    hmac_obj = salted_hmac(key_salt, value, secret)\n    self.assertIsInstance(hmac_obj, hmac.HMAC)\n\n    # Test with custom algorithm\n    hmac_obj = salted_hmac(key_salt, value, algorithm=algorithm)\n    self.assertIsInstance(hmac_obj, hmac.HMAC)\n\n    # Test with invalid algorithm\n    with self.assertRaises(InvalidAlgorithm):\n        salted_hmac(key_salt, value, algorithm='invalid_algorithm')\n\n    # Test with None value\n    hmac_obj = salted_hmac(key_salt, None)\n    self.assertIsInstance(hmac_obj, hmac.HMAC)\n\n    # Test with empty string value\n    hmac_obj = salted_hmac(key_salt, '')\n    self.assertIsInstance(hmac_obj, hmac.HMAC)\n"], "sample_769": ["def test_multilabel_confusion_matrix():\n    # Test multilabel confusion matrix\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    mcm = multilabel_confusion_matrix(y_true, y_pred)\n    assert_array_almost_equal(mcm, np.array([[[1, 0],\n                                              [0, 1]],\n                                             [[1, 0],\n                                              [0, 1]],\n                                             [[0, 1],\n                                              [1, 0]]]))\n\n    # Test multilabel confusion matrix with sample weights\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    sample_weight = np.array([0.5, 1.5])\n    mcm = multilabel_confusion_matrix(y_true, y_pred, sample_weight=sample_weight)\n    assert_array_almost_equal(mcm, np.array([[[0.5, 0],\n                                              [0, 1.5]],\n                                             [[1.5, 0],\n                                              [0, 0.5]],\n                                             [[0, 1.5],\n                                              [1.5, 0]]]))\n\n    # Test multilabel confusion matrix with labels\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    labels = [0, 1]\n    mcm = multilabel_confusion_matrix(y_true, y_pred, labels=labels)\n    assert_array_almost_equal(mcm, np.array([[[1, 0],\n                                              [0, 1]],\n                                             [[1, 0],\n                                              [0, 1]]]))\n\n    # Test multilabel confusion matrix with samplewise\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    mcm = multilabel_confusion_matrix(y_true, y_pred,"], "sample_1127": ["def test_coset():\n    a = Permutation(1, 2)\n    b = Permutation(0, 1)\n    G = PermutationGroup([a, b])\n    cst = Coset(a, G, dir=\"-\")\n    assert cst.as_list() == [a*b, a, b*a, b]\n    assert cst.is_left_coset\n    assert not cst.is_right_coset\n    cst = Coset(a, G, dir=\"+\")\n    assert cst.as_list() == [a*b, a, b*a, b]\n    assert not cst.is_left_coset\n    assert cst.is_right_coset\n"], "sample_296": ["def test_cookie_storage_max_size(self):\n    storage = self.storage_class(self.request, self.response)\n    messages = [Message(constants.INFO, 'Message %d' % i) for i in range(100)]\n    storage._store(messages, self.response)\n    self.assertLess(stored_cookie_messages_count(storage, self.response), len(messages))\n"], "sample_748": ["def test_parameter_grid():\n    # Test that ParameterGrid works with a single dictionary\n    grid = ParameterGrid({'foo': [1, 2], 'bar': ['a', 'b']})\n    assert_grid_iter_equals_getitem(grid)\n    assert_equal(len(grid), 4)\n\n    # Test that ParameterGrid works with a list of dictionaries\n    grid = ParameterGrid([{'foo': [1, 2]}, {'bar': ['a', 'b']}])\n    assert_grid_iter_equals_getitem(grid)\n    assert_equal(len(grid), 4)\n\n    # Test that ParameterGrid works with an empty dictionary\n    grid = ParameterGrid({})\n    assert_grid_iter_equals_getitem(grid)\n    assert_equal(len(grid), 1)\n\n    # Test that ParameterGrid works with an empty list\n    grid = ParameterGrid([])\n    assert_grid_iter_equals_getitem(grid)\n    assert_equal(len(grid), 1)\n\n    # Test that ParameterGrid raises an error for a non-iterable value\n    with assert_raises(TypeError):\n        ParameterGrid(0)\n\n    # Test that ParameterGrid raises an error for a non-dict value in a list\n    with assert_raises(TypeError):\n        ParameterGrid([{'foo': [1, 2]}, 0])\n\n    # Test that ParameterGrid raises an error for a non-iterable value in a dict\n    with assert_raises(TypeError):\n        ParameterGrid({'foo': 0})\n\n    # Test that ParameterGrid raises an error for an empty iterable value in a dict\n    with assert_raises(ValueError):\n        ParameterGrid({'foo': []})\n"], "sample_439": ["    def test_form_order_fields(self):\n        class MyForm(Form):\n            field1 = CharField()\n            field2 = CharField()\n            field3 = CharField()\n\n        form = MyForm(field_order=[\"field2\", \"field1\"])\n        self.assertEqual(list(form.fields.keys()), [\"field2\", \"field1\", \"field3\"])\n\n        form = MyForm(field_order=[\"field2\", \"field4\"])\n        self.assertEqual(list(form.fields.keys()), [\"field2\", \"field1\", \"field3\"])\n\n        form = MyForm(field_order=None)\n        self.assertEqual(list(form.fields.keys()), [\"field1\", \"field2\", \"field3\"])\n\n        form = MyForm(field_order=[])\n        self.assertEqual(list(form.fields.keys()), [\"field1\", \"field2\", \"field3\"])\n"], "sample_445": ["def test_timesince_future_date(self):\n    future_date = self.t + self.oneday\n    self.assertEqual(timesince(future_date), \"0 minutes\")\n"], "sample_268": ["    def test_watchman_reloader(self):\n        reloader = autoreload.WatchmanReloader()\n        self.assertIsInstance(reloader, autoreload.BaseReloader)\n"], "sample_599": ["def test_unsigned_integer_coder():\n    # Create a sample variable with unsigned integer data\n    data = np.array([1, 2, 3], dtype=np.uint8)\n    var = xr.Variable((\"x\",), data)\n\n    # Encode the variable\n    coder = variables.UnsignedIntegerCoder()\n    encoded_var = coder.encode(var)\n\n    # Check that the data has been converted to signed integer\n    assert encoded_var.dtype == np.int8\n\n    # Decode the variable\n    decoded_var = coder.decode(encoded_var)\n\n    # Check that the data has been converted back to unsigned integer\n    assert decoded_var.dtype == np.uint8\n    assert_allclose(decoded_var.data, data)\n\n    # Test with _Unsigned attribute\n    var.attrs[\"_Unsigned\"] = \"true\"\n    encoded_var = coder.encode(var)\n    decoded_var = coder.decode(encoded_var)\n    assert decoded_var.dtype == np.uint8\n    assert_allclose(decoded_var.data, data)\n\n    # Test with _Unsigned attribute and _FillValue\n    var.attrs[\"_FillValue\"] = 255\n    encoded_var = coder.encode(var)\n    decoded_var = coder.decode(encoded_var)\n    assert decoded_var.dtype == np.uint8\n    assert_allclose(decoded_var.data, data)\n    assert decoded_var.attrs[\"_FillValue\"] == 255\n\n    # Test with non-integer data\n    data = np.array([1.0, 2.0, 3.0], dtype=np.float32)\n    var = xr.Variable((\"x\",), data)\n    var.attrs[\"_Unsigned\"] = \"true\"\n    with pytest.warns(variables.SerializationWarning):\n        decoded_var = coder.decode(var)\n    assert decoded_var.dtype == np.float32\n    assert_allclose(decoded_var.data, data)\n"], "sample_229": ["def test_union_with_empty_querysets(self):\n    qs1 = Number.objects.all()\n    qs2 = Number.objects.none()\n    qs3 = Number.objects.none()\n\n    # Test union of two querysets where one is empty\n    self.assertNumbersEqual(qs1.union(qs2), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n    # Test union of three querysets where two are empty\n    self.assertNumbersEqual(qs1.union(qs2, qs3), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n    # Test union of two empty querysets\n    self.assertNumbersEqual(qs2.union(qs3), [])\n\n    # Test union of three empty querysets\n    self.assertNumbersEqual(qs2.union(qs3, qs1.none()), [])\n"], "sample_1108": ["def test_multiset_partitions():\n    # Test that the multiset_partitions function works correctly\n    # for different inputs\n    assert list(multiset_partitions([1, 1, 2])) == [[[1, 1, 2]], [[1, 1], [2]], [[1, 2], [1]], [[1], [1], [2]]]\n    assert list(multiset_partitions([1]*3)) == [[[1, 1, 1]], [[1], [1, 1]], [[1], [1], [1]]]\n    assert list(multiset_partitions([1, 2, 3], 2)) == [[[1, 2, 3]], [[1, 2], [3]], [[1, 3], [2]], [[2, 3], [1]]]\n    assert list(multiset_partitions([1, 2, 3], 1)) == [[[1, 2, 3]]]\n    assert list(multiset_partitions([1, 2, 3], 3)) == [[[1], [2], [3]]]\n    assert list(multiset_partitions([1, 1, 2, 2], 2)) == [[[1, 1, 2, 2]], [[1, 1, 2], [2]], [[1, 1], [2, 2]], [[1, 2, 2], [1]], [[1, 2], [1, 2]], [[1], [1, 2, 2]]]\n    assert list(multiset_partitions([1, 1, 1, 2, 2], 2)) == [[[1, 1, 1, 2, 2]], [[1, 1, 1, 2], [2]], [[1, 1, 1], [2, 2]], [[1, 1, 2, 2], [1]], [[1, 1, 2], [1, 2]], [[1, 1], [1, 2, 2]], [[1, 2, 2], [1, 1]], [[1, 2], [1, 1, 2]], [[1], [1, 1, 2, 2]]]\n    assert list(multiset_partitions([1, 1, 1"], "sample_946": ["def test_parse_annotation():\n    env = Mock(spec=['config'])\n    env.config.python_use_unqualified_type_names = False\n\n    # Test simple type\n    annotation = 'int'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'int'\n\n    # Test type with module\n    annotation = 'module.Type'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'module.Type'\n\n    # Test type with multiple modules\n    annotation = 'module1.module2.Type'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'module1.module2.Type'\n\n    # Test type with generic\n    annotation = 'List[int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 3\n    assert isinstance(result[0], nodes.Text)\n    assert result[0].astext() == 'List'\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == '['\n    assert isinstance(result[2], pending_xref)\n    assert result[2].attributes['reftarget'] == 'int'\n\n    # Test type with multiple generics\n    annotation = 'Dict[str, int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 5\n    assert isinstance(result[0], nodes.Text)\n    assert result[0].astext() == 'Dict'\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == '['\n    assert isinstance(result[2], pending_xref)\n    assert result[2].attributes['reftarget'] == 'str'\n    assert isinstance(result[3], desc_sig_punctuation)\n    assert result[3].astext() == ', '\n    assert isinstance(result[4], pending_xref)\n    assert result[4].attributes['reftarget'] == 'int'\n\n    # Test type with nested generics\n    annotation = 'List[Dict[str, int]]'\n    result = _parse_annotation(annotation, env"], "sample_1150": ["def test_ComplexRegion():\n    a = Interval(2, 3)\n    b = Interval(4, 5)\n    c = Interval(1, 7)\n    C1 = ComplexRegion(a*b)\n    C2 = ComplexRegion(Union(a*b, b*c))\n    assert C1.sets == ProductSet(a, b)\n    assert C2.sets == Union(ProductSet(a, b), ProductSet(b, c))\n    assert C1.psets == (ProductSet(a, b),)\n    assert C2.psets == (ProductSet(a, b), ProductSet(b, c))\n    assert C1.a_interval == a\n    assert C2.a_interval == Union(a, b)\n    assert C1.b_interval == b\n    assert C2.b_interval == Interval(1, 7)\n    assert C1.measure == 3\n    assert C2.measure == 21\n    assert 2.5 + 4.5*I in C1\n    assert 2.5 + 6.5*I not in C1\n    assert ComplexRegion.from_real(Interval(0,1)) == CartesianComplexRegion(ProductSet(Interval(0, 1), FiniteSet(0)))\n\n    r = Interval(0, 1)\n    theta = Interval(0, 2*pi)\n    C2 = ComplexRegion(r*theta, polar=True)\n    assert C2.sets == ProductSet(r, normalize_theta_set(theta))\n    assert C2.psets == (ProductSet(r, normalize_theta_set(theta)),)\n    assert C2.a_interval == r\n    assert C2.b_interval == normalize_theta_set(theta)\n    assert C2.measure == pi\n    assert 0.5 + 0.5*I in C2\n    assert 1 + 2*I not in C2\n"], "sample_565": ["def test_inset_locator():\n    fig, ax = plt.subplots()\n    ax.set_xlim(0, 10)\n    ax.set_ylim(0, 10)\n    ax.plot([5], [5], 'bo')\n\n    axins = zoomed_inset_axes(ax, zoom=0.5, loc=1)\n    axins.plot([5], [5], 'ro')\n    mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n\n    axins = zoomed_inset_axes(ax, zoom=0.5, loc=2)\n    axins.plot([5], [5], 'ro')\n    mark_inset(ax, axins, loc1=1, loc2=3, fc=\"none\", ec=\"0.5\")\n\n    axins = zoomed_inset_axes(ax, zoom=0.5, loc=3)\n    axins.plot([5], [5], 'ro')\n    mark_inset(ax, axins, loc1=4, loc2=2, fc=\"none\", ec=\"0.5\")\n\n    axins = zoomed_inset_axes(ax, zoom=0.5, loc=4)\n    axins.plot([5], [5], 'ro')\n    mark_inset(ax, axins, loc1=3, loc2=1, fc=\"none\", ec=\"0.5\")\n\n    axins = zoomed_inset_axes(ax, zoom=0.5, loc=1, borderpad=0.1)\n    axins.plot([5], [5], 'ro')\n    mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n\n    axins = zoomed_inset_axes(ax, zoom=0.5, loc=2, borderpad=0.1)\n    axins.plot([5], [5], 'ro')\n    mark_inset(ax, axins, loc1=1, loc2=3, fc=\"none\", ec=\"0.5\")\n\n    axins = zoomed_inset_axes(ax, zoom=0.5, loc=3, borderpad=0.1)\n    axins.plot([5], [5], 'ro')\n    mark_inset(ax, axins, loc1=4, loc"], "sample_910": ["def test_getLogger():\n    logger = logging.getLogger(__name__)\n    assert logger.name.startswith('sphinx.')\n    assert not logger.disabled\n"], "sample_951": ["def test_signature_from_str():\n    signature_str = \"(a: int, b: str) -> None\"\n    sig = inspect.signature_from_str(signature_str)\n    assert len(sig.parameters) == 2\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.return_annotation == type(None)\n"], "sample_783": ["def test_missing_indicator():\n    # Test MissingIndicator with dense and sparse matrices\n    X = np.array([[1, 2, np.nan], [4, np.nan, 6], [7, 8, 9]])\n    X_sparse = sparse.csc_matrix(X)\n\n    indicator = MissingIndicator()\n    Xt = indicator.fit_transform(X)\n    Xt_sparse = indicator.transform(X_sparse)\n\n    assert_array_equal(Xt, np.array([[False, False, True], [False, True, False], [False, False, False]]))\n    assert_array_equal(Xt_sparse.toarray(), Xt)\n\n    # Test MissingIndicator with features='all'\n    indicator = MissingIndicator(features='all')\n    Xt = indicator.fit_transform(X)\n    Xt_sparse = indicator.transform(X_sparse)\n\n    assert_array_equal(Xt, np.array([[False, False, True], [False, True, False], [False, False, False]]))\n    assert_array_equal(Xt_sparse.toarray(), Xt)\n\n    # Test MissingIndicator with sparse='auto'\n    indicator = MissingIndicator(sparse='auto')\n    Xt = indicator.fit_transform(X)\n    Xt_sparse = indicator.transform(X_sparse)\n\n    assert_array_equal(Xt, np.array([[False, False, True], [False, True, False], [False, False, False]]))\n    assert_array_equal(Xt_sparse.toarray(), Xt)\n\n    # Test MissingIndicator with sparse=True\n    indicator = MissingIndicator(sparse=True)\n    Xt = indicator.fit_transform(X)\n    Xt_sparse = indicator.transform(X_sparse)\n\n    assert_array_equal(Xt.toarray(), np.array([[False, False, True], [False, True, False], [False, False, False]]))\n    assert_array_equal(Xt_sparse.toarray(), Xt.toarray())\n\n    # Test MissingIndicator with sparse=False\n    indicator = MissingIndicator(sparse=False)\n    Xt = indicator.fit_transform(X_sparse)\n    Xt_sparse = indicator.transform(X)\n\n    assert_array_equal(Xt, np.array([[False, False, True], [False, True, False], [False, False, False]]))\n    assert_array_equal(Xt_sparse, Xt)\n\n    # Test MissingIndicator with error_on_new=True\n    indicator = MissingIndicator(error_on_new=True)\n    Xt = indicator.fit_transform(X)\n    with pytest.raises(ValueError):\n        indicator.transform(np.array([[1, 2, 3], [4, 5, np.nan], [7, 8, 9]]))\n\n"], "sample_173": ["def test_adapt_decimalfield_value(self):\n    value = decimal.Decimal('123.456')\n    adapted_value = self.ops.adapt_decimalfield_value(value)\n    self.assertEqual(adapted_value, '123.456')\n\n    value = decimal.Decimal('123.456789012345678901234567890')\n    adapted_value = self.ops.adapt_decimalfield_value(value, max_digits=10, decimal_places=2)\n    self.assertEqual(adapted_value, '123.46')\n\n    value = decimal.Decimal('123.456789012345678901234567890')\n    adapted_value = self.ops.adapt_decimalfield_value(value, max_digits=10, decimal_places=5)\n    self.assertEqual(adapted_value, '123.45679')\n"], "sample_475": ["    def test_raw_id_fields_item(self):\n        class MyModelAdmin(ModelAdmin):\n            raw_id_fields = (\"nonexistent_field\",)\n\n        self.assertIsInvalid(\n            MyModelAdmin,\n            ValidationTestModel,\n            \"The value of 'raw_id_fields[0]' refers to 'nonexistent_field', \"\n            \"which is not a field of 'validationtestmodel'.\",\n            id=\"admin.E002\",\n        )\n"], "sample_1051": ["def test_dotprint():\n    expr = x + 2\n    dotprint(expr)\n"], "sample_366": ["def test_parse_date(self):\n    # Test valid date\n    self.assertEqual(parse_date('2022-01-01'), date(2022, 1, 1))\n    self.assertEqual(parse_date('2022-12-31'), date(2022, 12, 31))\n\n    # Test invalid date\n    with self.assertRaises(ValueError):\n        parse_date('2022-02-30')\n\n    # Test invalid format\n    self.assertIsNone(parse_date('2022/01/01'))\n\n    # Test None input\n    self.assertIsNone(parse_date(None))\n"], "sample_163": ["    def test_password_reset_view(self):\n        # Test that the password reset view renders the correct template\n        response = self.client.get(reverse('password_reset'))\n        self.assertEqual(response.status_code, 200)\n        self.assertTemplateUsed(response, 'registration/password_reset_form.html')\n"], "sample_510": ["def test_xkcd_context_manager():\n    with plt.xkcd():\n        fig = plt.figure()\n        assert fig.get_edgecolor() == (0, 0, 0, 1)\n        assert fig.get_facecolor() == (1, 1, 1, 1)\n    assert fig.get_edgecolor() != (0, 0, 0, 1)\n    assert fig.get_facecolor() != (1, 1, 1, 1)\n"], "sample_393": ["    def test_is_templatized(self):\n        command = MakeMessagesCommand()\n        command.domain = \"djangojs\"\n        command.gettext_version = (0, 18, 2)\n        build_file = command.build_file_class(command, command.domain, self.translatable_file_class(\"path\", \"file.js\", \"locale\"))\n        self.assertTrue(build_file.is_templatized)\n\n        command.gettext_version = (0, 18, 3)\n        build_file = command.build_file_class(command, command.domain, self.translatable_file_class(\"path\", \"file.js\", \"locale\"))\n        self.assertFalse(build_file.is_templatized)\n\n        command.domain = \"django\"\n        build_file = command.build_file_class(command, command.domain, self.translatable_file_class(\"path\", \"file.py\", \"locale\"))\n        self.assertFalse(build_file.is_templatized)\n\n        build_file = command.build_file_class(command, command.domain, self.translatable_file_class(\"path\", \"file.html\", \"locale\"))\n        self.assertTrue(build_file.is_templatized)\n"], "sample_386": ["def test_mark_safe_decorator(self):\n    @mark_safe\n        return \"<p>Hello World!</p>\"\n\n    result = my_safe_function()\n    self.assertIsInstance(result, SafeString)\n    self.assertEqual(result, \"<p>Hello World!</p>\")\n\n    @mark_safe\n        return \"<p>Hello %s!</p>\" % name\n\n    result = my_safe_function_with_args(\"John\")\n    self.assertIsInstance(result, SafeString)\n    self.assertEqual(result, \"<p>Hello John!</p>\")\n\n    @mark_safe\n        return \"<p>Hello %s!</p>\" % kwargs[\"name\"]\n\n    result = my_safe_function_with_kwargs(name=\"Jane\")\n    self.assertIsInstance(result, SafeString)\n    self.assertEqual(result, \"<p>Hello Jane!</p>\")\n"], "sample_92": ["    def test_base_backend_has_perm(self):\n        backend = SimpleBackend()\n        self.assertTrue(backend.has_perm(self.user, 'user_perm'))\n        self.assertFalse(backend.has_perm(self.user, 'nonexistent_perm'))\n        self.assertFalse(backend.has_perm(AnonymousUser(), 'user_perm'))\n"], "sample_508": ["def test_artist_set():\n    fig, ax = plt.subplots()\n    line, = ax.plot([1, 2, 3])\n    assert line.get_linestyle() == '-'\n    line.set(linestyle='--')\n    assert line.get_linestyle() == '--'\n    line.set(linestyle='-', color='r')\n    assert line.get_linestyle() == '-' and line.get_color() == 'r'\n    with pytest.raises(AttributeError):\n        line.set(invalid_property='value')\n    with pytest.raises(TypeError):\n        line.set(linestyle='invalid')\n"], "sample_891": ["def test_ndcg_score():\n    # Test NDCG score with k=1\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[.1, .2, .3, 4, 70]])\n    assert_almost_equal(ndcg_score(y_true, y_score, k=1), 0.75)\n\n    # Test NDCG score with k=2\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[.1, .2, .3, 4, 70]])\n    assert_almost_equal(ndcg_score(y_true, y_score, k=2), 0.69)\n\n    # Test NDCG score with k=3\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[.1, .2, .3, 4, 70]])\n    assert_almost_equal(ndcg_score(y_true, y_score, k=3), 0.69)\n\n    # Test NDCG score with k=4\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[.1, .2, .3, 4, 70]])\n    assert_almost_equal(ndcg_score(y_true, y_score, k=4), 0.69)\n\n    # Test NDCG score with k=5\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[.1, .2, .3, 4, 70]])\n    assert_almost_equal(ndcg_score(y_true, y_score, k=5), 0.69)\n\n    # Test NDCG score with k=None\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[.1, .2, .3, 4, 70]])\n    assert_almost_equal(ndcg_score(y_true, y_score), 0.69)\n\n    # Test NDCG score with ties\n    y_true = np.array([[10, 0, 0, 1, 5]])\n    y_score = np.array([[1, 0, 0,"], "sample_1085": ["def test_comp():\n    assert comp(1, 1)\n    assert comp(1, 1.0)\n    assert comp(1, 1.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_185": ["    def test_localize_input(self):\n        with override_settings(USE_L10N=True):\n            activate('de')\n            date = datetime.date(2022, 1, 1)\n            self.assertEqual(localize_input(date), '01.01.2022')\n            deactivate()\n\n            activate('en')\n            self.assertEqual(localize_input(date), '2022-01-01')\n            deactivate()\n\n            time = datetime.time(12, 30)\n            self.assertEqual(localize_input(time), '12:30:00')\n            deactivate()\n\n            datetime_obj = datetime.datetime(2022, 1, 1, 12, 30)\n            self.assertEqual(localize_input(datetime_obj), '2022-01-01 12:30:00')\n            deactivate()\n\n            decimal_value = decimal.Decimal('1234.56')\n            self.assertEqual(localize_input(decimal_value), '1,234.56')\n            deactivate()\n\n            float_value = 1234.56\n            self.assertEqual(localize_input(float_value), '1,234.56')\n            deactivate()\n\n            int_value = 1234\n            self.assertEqual(localize_input(int_value), '1,234')\n            deactivate()\n\n            bool_value = True\n            self.assertEqual(localize_input(bool_value), 'True')\n            deactivate()\n\n            str_value = 'Hello'\n            self.assertEqual(localize_input(str_value), 'Hello')\n            deactivate()\n\n            with self.assertRaises(ValueError):\n                localize_input(object())\n"], "sample_824": ["def test_pairwise_distances_chunked():\n    # Test that pairwise_distances_chunked yields the same result as\n    # pairwise_distances\n    X = np.random.RandomState(0).rand(100, 10)\n    Y = np.random.RandomState(1).rand(50, 10)\n\n    D_chunked = np.concatenate(list(pairwise_distances_chunked(X, Y)))\n    D = pairwise_distances(X, Y)\n\n    assert_array_almost_equal(D_chunked, D)\n\n    # Test that pairwise_distances_chunked yields the same result as\n    # pairwise_distances when reduce_func is used\n        return D_chunk.min(axis=1)\n\n    D_chunked = np.concatenate(list(pairwise_distances_chunked(X, Y,\n                                                              reduce_func)))\n    D = pairwise_distances(X, Y).min(axis=1)\n\n    assert_array_almost_equal(D_chunked, D)\n\n    # Test that pairwise_distances_chunked yields the same result as\n    # pairwise_distances when reduce_func returns a list\n        return [D_chunk.min(axis=1)]\n\n    D_chunked = list(pairwise_distances_chunked(X, Y, reduce_func))\n    D = [pairwise_distances(X, Y).min(axis=1)]\n\n    assert_array_almost_equal(D_chunked[0], D[0])\n\n    # Test that pairwise_distances_chunked yields the same result as\n    # pairwise_distances when reduce_func returns a sparse matrix\n    from scipy.sparse import csr_matrix\n\n        return csr_matrix(D_chunk.min(axis=1)[:, np.newaxis])\n\n    D_chunked = list(pairwise_distances_chunked(X, Y, reduce_func))\n    D = csr_matrix(pairwise_distances(X, Y).min(axis=1)[:, np.newaxis])\n\n    assert_array_almost_equal(D_chunked[0].toarray(), D.toarray())\n\n    # Test that pairwise_distances_chunked yields the same result as\n    # pairwise_distances when reduce_func returns a tuple\n        return (D_chunk.min(axis=1), D_chunk.max(axis=1))\n\n    D_chunked = list(pairwise_distances_chunked(X, Y, reduce_func))\n    D = (pairwise_distances(X, Y).min(axis=1), pairwise_distances(X, Y).max(axis=1))\n\n    assert_array_almost_equal(D_chunked[0][0], D[0])\n    assert"], "sample_0": ["def test_init(UncertClass):\n    # Test that the uncertainty is initialized correctly\n    array = np.array([1, 2, 3])\n    unit = u.m\n    uncertainty = UncertClass(array, unit=unit)\n    assert_array_equal(uncertainty.array, array)\n    assert uncertainty.unit == unit\n\n    # Test that the uncertainty is initialized correctly with a Quantity\n    array = np.array([1, 2, 3]) * u.m\n    uncertainty = UncertClass(array)\n    assert_array_equal(uncertainty.array, array.value)\n    assert uncertainty.unit == array.unit\n\n    # Test that the uncertainty is initialized correctly with another uncertainty\n    array = np.array([1, 2, 3])\n    unit = u.m\n    other_uncertainty = StdDevUncertainty(array, unit=unit)\n    uncertainty = UncertClass(other_uncertainty)\n    assert_array_equal(uncertainty.array, array)\n    assert uncertainty.unit == unit\n\n    # Test that the uncertainty is initialized correctly with no unit\n    array = np.array([1, 2, 3])\n    uncertainty = UncertClass(array)\n    assert_array_equal(uncertainty.array, array)\n    assert uncertainty.unit is None\n\n    # Test that the uncertainty is initialized correctly with a scalar value\n    array = 1\n    uncertainty = UncertClass(array)\n    assert uncertainty.array == array\n    assert uncertainty.unit is None\n\n    # Test that the uncertainty is initialized correctly with a scalar value and unit\n    array = 1\n    unit = u.m\n    uncertainty = UncertClass(array, unit=unit)\n    assert uncertainty.array == array\n    assert uncertainty.unit == unit\n\n    # Test that the uncertainty is initialized correctly with a list\n    array = [1, 2, 3]\n    uncertainty = UncertClass(array)\n    assert_array_equal(uncertainty.array, array)\n    assert uncertainty.unit is None\n\n    # Test that the uncertainty is initialized correctly with a list and unit\n    array = [1, 2, 3]\n    unit = u.m\n    uncertainty = UncertClass(array, unit=unit)\n    assert_array_equal(uncertainty.array, array)\n    assert uncertainty.unit == unit\n\n    # Test that the uncertainty is initialized correctly with None\n    uncertainty = UncertClass()\n    assert uncertainty.array is None\n    assert"], "sample_811": ["def test_pairwise_distances_chunked():\n    # Test that pairwise_distances_chunked yields the same result as\n    # pairwise_distances\n    X = np.random.RandomState(0).rand(100, 10)\n    Y = np.random.RandomState(1).rand(50, 10)\n\n    D_chunked = np.vstack(list(pairwise_distances_chunked(X, Y)))\n    D = pairwise_distances(X, Y)\n\n    assert_array_almost_equal(D_chunked, D)\n\n    # Test that pairwise_distances_chunked yields the same result as\n    # pairwise_distances when reduce_func is used\n        return np.sum(D_chunk, axis=1)\n\n    D_chunked = np.array(list(pairwise_distances_chunked(X, Y,\n                                                         reduce_func=reduce_func)))\n    D = np.sum(pairwise_distances(X, Y), axis=1)\n\n    assert_array_almost_equal(D_chunked, D)\n\n    # Test that pairwise_distances_chunked yields the same result as\n    # pairwise_distances when reduce_func returns a list\n        return [np.sum(d) for d in D_chunk]\n\n    D_chunked = list(pairwise_distances_chunked(X, Y, reduce_func=reduce_func))\n    D = [np.sum(d) for d in pairwise_distances(X, Y)]\n\n    assert_array_almost_equal(D_chunked, D)\n\n    # Test that pairwise_distances_chunked yields the same result as\n    # pairwise_distances when reduce_func returns a sparse matrix\n    from scipy.sparse import csr_matrix\n\n        return csr_matrix(D_chunk)\n\n    D_chunked = list(pairwise_distances_chunked(X, Y, reduce_func=reduce_func))\n    D = csr_matrix(pairwise_distances(X, Y))\n\n    assert_array_almost_equal(D_chunked[0].toarray(), D.toarray())\n\n    # Test that pairwise_distances_chunked yields the same result as\n    # pairwise_distances when reduce_func returns a tuple\n        return (np.sum(D_chunk, axis=1), np.sum(D_chunk, axis=0))\n\n    D_chunked = list(pairwise_distances_chunked(X, Y, reduce_func=reduce_func))\n    D = pairwise_distances(X, Y)\n    D_sum_axis_1 = np.sum(D, axis=1)\n    D_sum_axis_0 = np.sum(D, axis=0)\n\n    assert_array_almost"], "sample_130": ["def test_is_nullable(self):\n    query = Query(Item)\n    self.assertTrue(query.is_nullable(CharField(null=True)))\n    self.assertFalse(query.is_nullable(CharField(null=False)))\n    self.assertTrue(query.is_nullable(CharField(null=False, blank=True)))\n    self.assertFalse(query.is_nullable(CharField(null=False, blank=False)))\n"], "sample_754": ["def test_sparse_pca_transform():\n    # Test that transform returns the correct shape\n    n_components = 3\n    n_samples = 10\n    image_size = (10, 10)\n    Y, _, _ = generate_toy_data(n_components, n_samples, image_size)\n    spca = SparsePCA(n_components=n_components, random_state=0)\n    spca.fit(Y)\n    Y_transformed = spca.transform(Y)\n    assert_equal(Y_transformed.shape, (n_samples, n_components))\n\n    # Test that transform with ridge regression works\n    spca = SparsePCA(n_components=n_components, ridge_alpha=0.1, random_state=0)\n    spca.fit(Y)\n    Y_transformed = spca.transform(Y)\n    assert_equal(Y_transformed.shape, (n_samples, n_components))\n\n    # Test that transform raises an error if not fitted\n    spca = SparsePCA(n_components=n_components, random_state=0)\n    with pytest.raises(NotFittedError):\n        spca.transform(Y)\n\n    # Test that transform with normalize_components=True works\n    spca = SparsePCA(n_components=n_components, normalize_components=True, random_state=0)\n    spca.fit(Y)\n    Y_transformed = spca.transform(Y)\n    assert_equal(Y_transformed.shape, (n_samples, n_components))\n\n    # Test that transform with normalize_components=False works\n    spca = SparsePCA(n_components=n_components, normalize_components=False, random_state=0)\n    spca.fit(Y)\n    Y_transformed = spca.transform(Y)\n    assert_equal(Y_transformed.shape, (n_samples, n_components))\n\n    # Test that MiniBatchSparsePCA transform works\n    mb_spca = MiniBatchSparsePCA(n_components=n_components, random_state=0)\n    mb_spca.fit(Y)\n    Y_transformed = mb_spca.transform(Y)\n    assert_equal(Y_transformed.shape, (n_samples, n_components))\n"], "sample_180": ["    def test_check_long_column_names(self):\n        class Model(models.Model):\n            field1 = models.CharField(max_length=100)\n            field2 = models.CharField(max_length=100)\n\n        max_length, db_alias = get_max_column_name_length()\n        if max_length is None:\n            self.skipTest(\"Database does not enforce column name length limits.\")\n        Model._meta.db_table = 'a' * (max_length + 1)\n        errors = Model.check()\n        self.assertEqual(len(errors), 1)\n        self.assertEqual(errors[0].id, 'models.E018')\n        self.assertEqual(errors[0].msg, \"Autogenerated column name too long for field \\\"field1\\\". Maximum length is %d for database \\\"%s\\\".\" % (max_length, db_alias))\n"], "sample_772": ["def test_forest_oob_score():\n    \"\"\"Check oob score computation on a toy dataset.\"\"\"\n    for name in FOREST_CLASSIFIERS_REGRESSORS:\n        if name in FOREST_CLASSIFIERS:\n            ForestEstimator = FOREST_CLASSIFIERS[name]\n            X, y = iris.data, iris.target\n        else:\n            ForestEstimator = FOREST_REGRESSORS[name]\n            X, y = boston.data, boston.target\n\n        # Test all combinations of bootstrap and oob_score parameters\n        for bootstrap, oob_score in product([True, False], [True, False]):\n            if not bootstrap and oob_score:\n                with assert_raises(ValueError):\n                    ForestEstimator(n_estimators=10, bootstrap=bootstrap,\n                                    oob_score=oob_score, random_state=0)\n            else:\n                clf = ForestEstimator(n_estimators=10, bootstrap=bootstrap,\n                                      oob_score=oob_score, random_state=0)\n                clf.fit(X, y)\n                if oob_score:\n                    assert hasattr(clf, 'oob_score_')\n                    assert hasattr(clf, 'oob_prediction_')\n                else:\n                    assert not hasattr(clf, 'oob_score_')\n                    assert not hasattr(clf, 'oob_prediction_')\n"], "sample_187": ["def test_slugify(self):\n    self.assertEqual(text.slugify('hello world'), 'hello-world')\n    self.assertEqual(text.slugify('hello  world'), 'hello-world')\n    self.assertEqual(text.slugify('hello---world'), 'hello-world')\n    self.assertEqual(text.slugify('hello_world'), 'hello_world')\n    self.assertEqual(text.slugify('hello-world'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'), 'hello-world')\n    self.assertEqual(text.slugify('hello world!'),"], "sample_365": ["    def test_lazy_property(self):\n        class TestClass:\n                self.value = value\n\n            @cached_property\n                return self.value\n\n        obj = TestClass(42)\n        self.assertEqual(obj.cached_value, 42)\n        obj.value = 24\n        self.assertEqual(obj.cached_value, 42)  # cached value is not updated\n"], "sample_1095": ["def test_applied_permutation():\n    x = Symbol('x')\n    p = Permutation([1, 0, 2])\n    ap = AppliedPermutation(p, x)\n    assert ap.subs(x, 1) == 0\n    assert ap.subs(x, 0) == 1\n    assert ap.subs(x, 2) == 2\n    assert ap.subs(x, 3) == 3\n    assert ap.subs(x, -1) == -1\n    assert ap.subs(x, S.Half) == S.Half\n    assert ap.subs(x, 1.5) == 1.5\n    assert ap.subs(x, a) == a\n    assert ap.subs(x, x) == x\n    assert ap.subs(x, p) == p\n    assert ap.subs(x, ap) == ap\n    assert ap.subs(x, Eq(x, 1)) == Eq(x, 1)\n    assert ap.subs(x, [1, 2, 3]) == [1, 2, 3]\n    assert ap.subs(x, (1, 2, 3)) == (1, 2, 3)\n    assert ap.subs(x, {1: 2, 2: 3}) == {1: 2, 2: 3}\n    assert ap.subs(x, S.Half) == S.Half\n    assert ap.subs(x, 1.5) == 1.5\n    assert ap.subs(x, a) == a\n    assert ap.subs(x, x) == x\n    assert ap.subs(x, p) == p\n    assert ap.subs(x, ap) == ap\n    assert ap.subs(x, Eq(x, 1)) == Eq(x, 1)\n    assert ap.subs(x, [1, 2, 3]) == [1, 2, 3]\n    assert ap.subs(x, (1, 2, 3)) == (1, 2, 3)\n    assert ap.subs(x, {1: 2, 2: 3}) == {1: 2, 2: 3}\n    assert ap.subs(x, S.Half) == S.Half\n    assert ap.subs(x, 1.5) =="], "sample_1191": ["def test_invariant_factors():\n    x = Symbol('x')\n    m = DomainMatrix([[ZZ(12), ZZ(6), ZZ(4)],\n                      [ZZ(3), ZZ(9), ZZ(6)],\n                      [ZZ(2), ZZ(16), ZZ(14)]], (3, 3), ZZ)\n    assert invariant_factors(m) == (1, 10, -30)\n"], "sample_1189": ["def test_lambdify_with_unevaluated_expr():\n    x = symbols('x')\n    expr = UnevaluatedExpr(x**2)\n    f = lambdify(x, expr, 'sympy')\n    assert f(2) == 4\n"], "sample_792": ["def test_complement_nb():\n    # Test ComplementNB with a binary classification problem\n    X, y = load_digits(n_class=2, return_X_y=True)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = ComplementNB()\n    clf.fit(X_train, y_train)\n    assert_array_equal(clf.predict(X_test), y_test)\n\n    # Test ComplementNB with a multi-class classification problem\n    X, y = load_iris(return_X_y=True)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n    clf = ComplementNB()\n    clf.fit(X_train, y_train)\n    assert_array_equal(clf.predict(X_test), y_test)\n\n    # Test ComplementNB with sparse data\n    X_sparse = scipy.sparse.csr_matrix(X)\n    clf = ComplementNB()\n    clf.fit(X_sparse, y)\n    assert_array_equal(clf.predict(X_sparse), y)\n\n    # Test ComplementNB with sample weights\n    clf = ComplementNB()\n    clf.fit(X, y, sample_weight=np.ones_like(y))\n    assert_array_equal(clf.predict(X), y)\n\n    # Test ComplementNB with alpha parameter\n    clf = ComplementNB(alpha=0.1)\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(X), y)\n\n    # Test ComplementNB with norm parameter\n    clf = ComplementNB(norm=True)\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(X), y)\n\n    # Test ComplementNB with partial_fit\n    clf = ComplementNB()\n    clf.partial_fit(X, y, classes=np.unique(y))\n    assert_array_equal(clf.predict(X), y)\n\n    # Test ComplementNB with pickle\n    clf = ComplementNB()\n    clf.fit(X, y)\n    with BytesIO() as f:\n        pickle.dump(clf, f)\n        f.seek(0)\n        clf_pickle = pickle.load(f)\n    assert_array_equal(clf_pickle.predict(X), y)\n"], "sample_698": ["def test_colored_level_formatter():\n    # Create a TerminalWriter instance\n    terminal_writer = TerminalWriter()\n\n    # Create a ColoredLevelFormatter instance\n    formatter = ColoredLevelFormatter(terminal_writer, \"%(levelname)s\")\n\n    # Test that the formatter correctly colorizes log levels\n    record = logging.LogRecord(\"test_logger\", logging.CRITICAL, \"\", 1, \"Test message\", None, None)\n    formatted_record = formatter.format(record)\n    assert \"\\x1b[31m\" in formatted_record  # Red color code for CRITICAL level\n\n    record = logging.LogRecord(\"test_logger\", logging.ERROR, \"\", 1, \"Test message\", None, None)\n    formatted_record = formatter.format(record)\n    assert \"\\x1b[31m\" in formatted_record  # Red color code for ERROR level\n\n    record = logging.LogRecord(\"test_logger\", logging.WARNING, \"\", 1, \"Test message\", None, None)\n    formatted_record = formatter.format(record)\n    assert \"\\x1b[33m\" in formatted_record  # Yellow color code for WARNING level\n\n    record = logging.LogRecord(\"test_logger\", logging.INFO, \"\", 1, \"Test message\", None, None)\n    formatted_record = formatter.format(record)\n    assert \"\\x1b[32m\" in formatted_record  # Green color code for INFO level\n\n    record = logging.LogRecord(\"test_logger\", logging.DEBUG, \"\", 1, \"Test message\", None, None)\n    formatted_record = formatter.format(record)\n    assert \"\\x1b[35m\" in formatted_record  # Purple color code for DEBUG level\n\n    record = logging.LogRecord(\"test_logger\", logging.NOTSET, \"\", 1, \"Test message\", None, None)\n    formatted_record = formatter.format(record)\n    assert \"\\x1b[\" not in formatted_record  # No color code for NOTSET level\n"], "sample_1172": ["def test_solve_biquadratic():\n    x, y = symbols('x y')\n    a = Poly(y**2 - 4 + x, y, x, domain='ZZ')\n    b = Poly(y*2 + 3*x - 7, y, x, domain='ZZ')\n    assert solve_biquadratic(a, b, parallel_poly_from_expr([a, b], x, y)[1]) == \\\n        [(1/3, 3), (41/27, 11/9)]\n\n    a = Poly(y + x**2 - 3, y, x, domain='ZZ')\n    b = Poly(-y + x - 4, y, x, domain='ZZ')\n    assert solve_biquadratic(a, b, parallel_poly_from_expr([a, b], x, y)[1]) == \\\n        [(7/2 - sqrt(29)/2, -sqrt(29)/2 - 1/2), (sqrt(29)/2 + 7/2, -1/2 + sqrt(29)/2)]\n\n    # Test that SolveFailed is raised when the system is not zero-dimensional\n    a = Poly(x, x, y, domain='ZZ')\n    b = Poly(y, x, y, domain='ZZ')\n    raises(SolveFailed, lambda: solve_biquadratic(a, b, parallel_poly_from_expr([a, b], x, y)[1]))\n\n    # Test that SolveFailed is raised when the system is not biquadratic\n    a = Poly(x**3, x, y, domain='ZZ')\n    b = Poly(y**2, x, y, domain='ZZ')\n    raises(SolveFailed, lambda: solve_biquadratic(a, b, parallel_poly_from_expr([a, b], x, y)[1]))\n"], "sample_58": ["def test_form_order_fields(self):\n    class MyForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n        field3 = CharField()\n\n    form = MyForm(field_order=['field3', 'field1'])\n    self.assertEqual(list(form.fields.keys()), ['field3', 'field1', 'field2'])\n\n    form = MyForm(field_order=['field3', 'field1', 'field4'])\n    self.assertEqual(list(form.fields.keys()), ['field3', 'field1', 'field2'])\n\n    form = MyForm(field_order=None)\n    self.assertEqual(list(form.fields.keys()), ['field1', 'field2', 'field3'])\n"], "sample_804": ["def test_ordinal_encoder():\n    # Test OrdinalEncoder with categorical features\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 2.], [1., 1.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([['Male', 1], ['Female', 3], ['Female', 2]], dtype=object))\n\n    # Test OrdinalEncoder with numerical features\n    X = [[1, 2], [3, 4], [5, 6]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 1.], [2., 2.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([[1, 2], [3, 4], [5, 6]], dtype=object))\n\n    # Test OrdinalEncoder with mixed-type features\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 2.], [1., 1.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([['Male', 1], ['Female', 3], ['Female', 2]], dtype=object))\n\n    # Test OrdinalEncoder with categories\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc = OrdinalEncoder(categories=[['Male', 'Female'], [1, 2, 3]])\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 2.], [1., 1.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([['Male', 1], ['Female', 3], ['Female', 2]], dtype=object))\n\n    # Test OrdinalEncoder with unknown categories\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc = OrdinalEncoder(categories=[['Male', 'Female'], [1, 2]])\n    with pytest.raises(ValueError):\n       "], "sample_877": ["def test_isotonic_regression_auto_increasing():\n    # Test that isotonic regression with auto increasing works correctly\n    X, y = make_regression(n_samples=100, n_features=1, random_state=42)\n    X, y = shuffle(X, y, random_state=42)\n    iso_reg = IsotonicRegression(increasing=\"auto\")\n    iso_reg.fit(X, y)\n    assert iso_reg.increasing_ == check_increasing(X, y)\n\n    # Test that isotonic regression with auto increasing works correctly\n    # when the relationship is decreasing\n    X, y = make_regression(n_samples=100, n_features=1, random_state=42)\n    y = -y\n    X, y = shuffle(X, y, random_state=42)\n    iso_reg = IsotonicRegression(increasing=\"auto\")\n    iso_reg.fit(X, y)\n    assert not iso_reg.increasing_ == check_increasing(X, y)\n"], "sample_597": ["def test_merge_core_with_conflicting_attrs():\n    # Create two datasets with conflicting attributes\n    attrs1 = {\"attr1\": \"value1\", \"attr2\": \"value2\"}\n    attrs2 = {\"attr1\": \"value1\", \"attr2\": \"different_value\"}\n    ds1 = xr.Dataset(attrs=attrs1)\n    ds2 = xr.Dataset(attrs=attrs2)\n\n    # Merge the datasets with combine_attrs=\"no_conflicts\"\n    with pytest.raises(MergeError):\n        merge_core([ds1, ds2], combine_attrs=\"no_conflicts\")\n\n    # Merge the datasets with combine_attrs=\"identical\"\n    with pytest.raises(MergeError):\n        merge_core([ds1, ds2], combine_attrs=\"identical\")\n\n    # Merge the datasets with combine_attrs=\"override\"\n    result = merge_core([ds1, ds2], combine_attrs=\"override\")\n    assert result.attrs == attrs1\n\n    # Merge the datasets with combine_attrs=\"drop\"\n    result = merge_core([ds1, ds2], combine_attrs=\"drop\")\n    assert result.attrs == {}\n"], "sample_1202": ["def test_comp():\n    assert comp(1.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_866": ["def test_affinity_propagation_precomputed():\n    # Test with precomputed affinity matrix\n    S = euclidean_distances(X, squared=True)\n    S = -S\n    cluster = AffinityPropagation(affinity='precomputed')\n    cluster.fit(S)\n    assert_array_equal(cluster.labels_, np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,"], "sample_678": ["    def test_get_lock_path(self, tmp_path):\n        path = tmp_path / \"test\"\n        lock_path = get_lock_path(path)\n        assert lock_path == path / \".lock\"\n"], "sample_235": ["def test_on_commit_with_nested_transactions(self):\n    \"\"\"\n    Test that on_commit callbacks are executed in the correct order when\n    nested transactions are used.\n    \"\"\"\n    with transaction.atomic():\n        self.do(1)\n        with transaction.atomic():\n            self.do(2)\n            with transaction.atomic():\n                self.do(3)\n        self.do(4)\n    self.assertNotified([1, 2, 3, 4])\n    self.assertDone([1, 2, 3, 4])\n"], "sample_673": ["def test_doctest_item_repr_failure():\n    class FakeException(Exception):\n        pass\n\n    class FakeDocTestFailure:\n            self.test = test\n            self.example = example\n            self.got = got\n\n    class FakeDocTest:\n            self.name = name\n            self.filename = filename\n            self.docstring = docstring\n            self.lineno = lineno\n\n    class FakeExample:\n            self.source = source\n            self.lineno = lineno\n\n    class FakeExcInfo:\n            self.value = value\n\n    class FakeConfig:\n            return \"udiff\"\n\n    class FakeTerminalWriter:\n            pass\n\n    item = DoctestItem(\"test\", None)\n    item.config = FakeConfig()\n    item.dtest = FakeDocTest(\"test\", \"test.py\", \"docstring\", 1)\n    item.dtest.examples = [FakeExample(\"example\", 1)]\n    excinfo = FakeExcInfo(FakeDocTestFailure(item.dtest, item.dtest.examples[0], \"got\"))\n    repr_failure = item.repr_failure(excinfo)\n    assert isinstance(repr_failure, ReprFailDoctest)\n\n    tw = FakeTerminalWriter()\n    repr_failure.toterminal(tw)\n"], "sample_1176": ["def test_comp():\n    assert comp(1.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_820": ["def test_voting_regressor_weights():\n    # Test VotingRegressor with different weights\n    r1 = LinearRegression()\n    r2 = RandomForestRegressor(n_estimators=10, random_state=1)\n    er = VotingRegressor([('lr', r1), ('rf', r2)], weights=[0.7, 0.3])\n    er.fit(X_r, y_r)\n    y_pred = er.predict(X_r)\n    assert_array_almost_equal(y_pred, np.average([r1.fit(X_r, y_r).predict(X_r) * 0.7,\n                                                  r2.fit(X_r, y_r).predict(X_r) * 0.3], axis=0))\n"], "sample_714": ["def test_brier_score_loss():\n    # Test Brier score loss for binary classification\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    score = brier_score_loss(y_true, y_prob)\n    assert_almost_equal(score, 0.037, decimal=3)\n\n    # Test Brier score loss for binary classification with sample weights\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    sample_weight = np.array([0.5, 1.0, 1.0, 0.5])\n    score = brier_score_loss(y_true, y_prob, sample_weight=sample_weight)\n    assert_almost_equal(score, 0.033, decimal=3)\n\n    # Test Brier score loss for binary classification with pos_label\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.9, 0.1, 0.2, 0.7])\n    score = brier_score_loss(y_true, y_prob, pos_label=0)\n    assert_almost_equal(score, 0.037, decimal=3)\n\n    # Test Brier score loss for categorical classification\n    y_true = np.array(['cat', 'dog', 'dog', 'cat'])\n    y_prob = np.array([[0.1, 0.9], [0.9, 0.1], [0.8, 0.2], [0.35, 0.65]])\n    score = brier_score_loss(y_true, y_prob, pos_label='dog')\n    assert_almost_equal(score, 0.037, decimal=3)\n\n    # Test Brier score loss for categorical classification with sample weights\n    y_true = np.array(['cat', 'dog', 'dog', 'cat'])\n    y_prob = np.array([[0.1, 0.9], [0.9, 0.1], [0.8, 0.2], [0.35, 0.65]])\n    sample_weight = np.array([0.5, 1.0, 1.0, 0."], "sample_663": ["    def test_session_repr(self):\n        session = Session(pytest.config)\n        session.exitstatus = ExitCode.OK\n        session.testsfailed = 1\n        session.testscollected = 10\n        expected_repr = \"<Session {} exitstatus=<ExitCode.OK: 0> testsfailed=1 testscollected=10>\".format(session.name)\n        assert repr(session) == expected_repr\n"], "sample_1183": ["def test_frac_field():\n    K, x, y, z = field(\"x,y,z\", ZZ)\n    assert K.domain == ZZ\n    assert K.order == 'lex'\n    assert K.ngens == 3\n    assert K.symbols == (x, y, z)\n    assert K.gens == (x, y, z)\n    assert K.zero == K(0)\n    assert K.one == K(1)\n\n    f = K(x**2 + y)\n    g = K(y**2 + z)\n    assert f + g == K(x**2 + y + y**2 + z)\n    assert f - g == K(x**2 + y - y**2 - z)\n    assert f * g == K(x**2*y**2 + x**2*z + y**3 + y*z)\n    assert f / g == K((x**2 + y) / (y**2 + z))\n\n    assert f.diff(x) == K(2*x)\n    assert f.diff(y) == K(1)\n    assert f.diff(z) == K(0)\n\n    assert f(1, 2, 3) == K(7)\n    assert f.subs(x, 1) == K(1 + y)\n    assert f.subs(y, 2) == K(x**2 + 2)\n    assert f.subs(z, 3) == K(x**2 + y)\n\n    assert f == K(x**2 + y)\n    assert f != K(x**2 + y**2)\n    assert f < K(x**2 + y**2)\n    assert f <= K(x**2 + y)\n    assert f > K(x**2)\n    assert f >= K(x**2 + y)\n\n    assert f**2 == K(x**4 + 2*x**2*y + y**2)\n    assert f**-1 == K(1 / (x**2 + y))\n"], "sample_615": ["def test_broadcast_compat_data():\n    dims = (\"x\", \"y\")\n    data = np.random.rand(2, 3)\n    var = xr.Variable(dims, data)\n    broadcast_dims = (\"z\",)\n    core_dims = dims\n    new_data = broadcast_compat_data(var, broadcast_dims, core_dims)\n    assert new_data.shape == (1, 2, 3)\n    assert new_data[0, :, :].all() == data.all()\n\n    # test with dask array\n    if has_dask:\n        import dask.array as da\n\n        data = da.from_array(data, chunks=(2, 3))\n        var = xr.Variable(dims, data)\n        new_data = broadcast_compat_data(var, broadcast_dims, core_dims)\n        assert new_data.shape == (1, 2, 3)\n        assert new_data[0, :, :].compute().all() == data.compute().all()\n\n    # test with non-trivial order\n    dims = (\"x\", \"y\")\n    data = np.random.rand(2, 3)\n    var = xr.Variable(dims, data)\n    broadcast_dims = (\"z\", \"w\")\n    core_dims = (\"y\", \"x\")\n    new_data = broadcast_compat_data(var, broadcast_dims, core_dims)\n    assert new_data.shape == (1, 1, 3, 2)\n    assert new_data[0, 0, :, :].all() == data.T.all()\n"], "sample_979": ["def test_matrix_element():\n    M = MatrixSymbol('M', 3, 3)\n    ME = MatrixElement(M, 1, 1)\n    assert ME.parent == M\n    assert ME.i == 1\n    assert ME.j == 1\n    assert ME.diff(ME) == KroneckerDelta(1, 1)**2\n    assert ME.diff(MatrixElement(M, 0, 0)) == 0\n    assert ME.diff(x) == 0\n"], "sample_1002": ["def test_mod_inverse():\n    assert mod_inverse(2, 3) == 2\n    assert mod_inverse(-3, 11) == 4\n    assert mod_inverse(7, 19) == 11\n    assert mod_inverse(121, 100) == 21\n    assert mod_inverse(1, 1) == 1\n    assert mod_inverse(1, 2) == 1\n    assert mod_inverse(1, 3) == 1\n    assert mod_inverse(1, 4) == 1\n    assert mod_inverse(1, 5) == 1\n    assert mod_inverse(1, 6) == 1\n    assert mod_inverse(1, 7) == 1\n    assert mod_inverse(1, 8) == 1\n    assert mod_inverse(1, 9) == 1\n    assert mod_inverse(1, 10) == 1\n    assert mod_inverse(1, 11) == 1\n    assert mod_inverse(1, 12) == 1\n    assert mod_inverse(1, 13) == 1\n    assert mod_inverse(1, 14) == 1\n    assert mod_inverse(1, 15) == 1\n    assert mod_inverse(1, 16) == 1\n    assert mod_inverse(1, 17) == 1\n    assert mod_inverse(1, 18) == 1\n    assert mod_inverse(1, 19) == 1\n    assert mod_inverse(1, 20) == 1\n    assert mod_inverse(1, 21) == 1\n    assert mod_inverse(1, 22) == 1\n    assert mod_inverse(1, 23) == 1\n    assert mod_inverse(1, 24) == 1\n    assert mod_inverse(1, 25) == 1\n    assert mod_inverse(1, 26) == 1\n    assert mod_inverse(1, 27) == 1\n    assert mod_inverse(1, 28) == 1\n    assert mod_inverse(1, 29) == 1\n    assert mod_inverse(1, 30) == 1\n    assert mod_inverse(1, 31) == 1\n    assert mod_inverse(1, 32) == 1\n"], "sample_245": ["    def test_preprocess(self):\n        build_file = self.build_file_class(self, 'django', self.translatable_file_class('.', 'test.py', '.'))\n        with mock.patch('builtins.open', mock.mock_open(read_data='test content')):\n            build_file.preprocess()\n            self.assertTrue(os.path.exists(build_file.work_path))\n"], "sample_294": ["def test_origin_verified(self):\n    # Test that the _origin_verified method correctly verifies the origin\n    # of a request.\n\n    # Create a request with a valid origin\n    req = self._get_GET_csrf_cookie_request()\n    req.META['HTTP_ORIGIN'] = 'https://example.com'\n    self.assertTrue(self.middleware._origin_verified(req))\n\n    # Create a request with an invalid origin\n    req = self._get_GET_csrf_cookie_request()\n    req.META['HTTP_ORIGIN'] = 'https://example.net'\n    self.assertFalse(self.middleware._origin_verified(req))\n\n    # Create a request with a valid origin that is a subdomain\n    req = self._get_GET_csrf_cookie_request()\n    req.META['HTTP_ORIGIN'] = 'https://sub.example.com'\n    self.middleware.allowed_origin_subdomains['https'].append('example.com')\n    self.assertTrue(self.middleware._origin_verified(req))\n\n    # Create a request with an invalid origin that is a subdomain\n    req = self._get_GET_csrf_cookie_request()\n    req.META['HTTP_ORIGIN'] = 'https://sub.example.net'\n    self.middleware.allowed_origin_subdomains['https'].append('example.com')\n    self.assertFalse(self.middleware._origin_verified(req))\n\n    # Create a request with a valid origin that is an exact match\n    req = self._get_GET_csrf_cookie_request()\n    req.META['HTTP_ORIGIN'] = 'https://example.com'\n    self.middleware.allowed_origins_exact.add('https://example.com')\n    self.assertTrue(self.middleware._origin_verified(req))\n\n    # Create a request with an invalid origin that is an exact match\n    req = self._get_GET_csrf_cookie_request()\n    req.META['HTTP_ORIGIN'] = 'https://example.net'\n    self.middleware.allowed_origins_exact.add('https://example.com')\n    self.assertFalse(self.middleware._origin_verified(req))\n"], "sample_536": ["def test_rectangle_selector(ax):\n        assert eclick.xdata == 0.5\n        assert eclick.ydata == 0.5\n        assert erelease.xdata == 0.7\n        assert erelease.ydata == 0.7\n\n    rs = widgets.RectangleSelector(ax, onselect, useblit=True,\n                                  props=dict(facecolor='blue', alpha=0.5))\n    click_and_drag(ax, 0.5, 0.5, 0.7, 0.7)\n"], "sample_198": ["def test_window_frame(self):\n    with self.subTest('RowRange'):\n        frame = RowRange(start=5, end=10)\n        self.assertEqual(frame.frame_type, 'ROWS')\n        self.assertEqual(str(frame), 'ROWS BETWEEN 5 PRECEDING AND 10 FOLLOWING')\n\n    with self.subTest('ValueRange'):\n        frame = ValueRange(start=5, end=10)\n        self.assertEqual(frame.frame_type, 'RANGE')\n        self.assertEqual(str(frame), 'RANGE BETWEEN 5 PRECEDING AND 10 FOLLOWING')\n\n    with self.subTest('WindowFrame'):\n        with self.assertRaises(NotImplementedError):\n            frame = WindowFrame(start=5, end=10)\n            str(frame)\n"], "sample_38": ["def test_wcs_to_header(self):\n    filename = get_pkg_data_filename('wcs/2d_fits/1904-66_AIR_flt.fits')\n    with fits.open(filename) as hdul:\n        header = hdul[('sci', 1)].header\n        w = wcs.WCS(header)\n        header2 = w.to_header()\n        w2 = wcs.WCS(header2)\n        assert_array_almost_equal(w.wcs.cd, w2.wcs.cd)\n        assert_array_almost_equal(w.wcs.crval, w2.wcs.crval)\n        assert_array_almost_equal(w.wcs.crpix, w2.wcs.crpix)\n        assert_array_almost_equal(w.wcs.ctype, w2.wcs.ctype)\n"], "sample_139": ["def test_to_field_allowed(self):\n    model_admin = ParentAdmin(Parent, admin.site)\n    request = self.factory.get('/admin/')\n    request.user = self.superuser\n\n    # Test that the primary key is always allowed.\n    self.assertTrue(model_admin.to_field_allowed(request, 'id'))\n\n    # Test that a field that is referenced by another model is allowed.\n    self.assertTrue(model_admin.to_field_allowed(request, 'name'))\n\n    # Test that a field that is not referenced by another model is not allowed.\n    self.assertFalse(model_admin.to_field_allowed(request, 'age'))\n"], "sample_563": ["def test_paddedbox():\n    fig, ax = plt.subplots()\n    child = mpatches.Circle((0.5, 0.5), 0.2, edgecolor='black', facecolor='blue')\n    box = PaddedBox(child, pad=0.1, draw_frame=True)\n    ax.add_artist(box)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect('equal')\n"], "sample_667": ["def test_temp_path_factory_from_config(tmp_path):\n    class Config:\n        option = attr.s\n        option.basetemp = tmp_path\n        trace = attr.s\n        trace.tmpdir = []\n\n    factory = TempPathFactory.from_config(Config())\n    assert factory._given_basetemp == tmp_path\n    assert factory._trace == Config().trace.tmpdir\n\n"], "sample_419": ["    def test_management_form(self):\n        formset = ChoiceFormSet()\n        management_form = formset.management_form\n        self.assertIsInstance(management_form, ManagementForm)\n        self.assertEqual(management_form.prefix, \"form\")\n        self.assertEqual(management_form[\"TOTAL_FORMS\"].value(), 1)\n        self.assertEqual(management_form[\"INITIAL_FORMS\"].value(), 0)\n        self.assertEqual(management_form[\"MIN_NUM_FORMS\"].value(), 0)\n        self.assertEqual(management_form[\"MAX_NUM_FORMS\"].value(), 1000)\n"], "sample_341": ["    def test_management_form_cleaned_data(self):\n        formset = self.make_choiceformset(formset_data=[('A', 1), ('B', 2)])\n        self.assertEqual(formset.management_form.cleaned_data[TOTAL_FORM_COUNT], 2)\n        self.assertEqual(formset.management_form.cleaned_data[INITIAL_FORM_COUNT], 2)\n        self.assertEqual(formset.management_form.cleaned_data[MIN_NUM_FORM_COUNT], 0)\n        self.assertEqual(formset.management_form.cleaned_data[MAX_NUM_FORM_COUNT], 1000)\n"], "sample_1201": ["def test_cgs_gaussian_units():\n    # Test that the cgs_gaussian units are correctly defined\n    assert cgs_gauss.get_quantity_dimension(statcoulomb) == charge\n    assert cgs_gauss.get_quantity_scale_factor(statcoulomb) == centimeter**(S(3)/2)*gram**(S.Half)/second\n\n    assert cgs_gauss.get_quantity_dimension(statampere) == current\n    assert cgs_gauss.get_quantity_scale_factor(statampere) == statcoulomb/second\n\n    assert cgs_gauss.get_quantity_dimension(statvolt) == voltage\n    assert cgs_gauss.get_quantity_scale_factor(statvolt) == erg/statcoulomb\n\n    assert cgs_gauss.get_quantity_dimension(gauss) == magnetic_density\n    assert cgs_gauss.get_quantity_scale_factor(gauss) == sqrt(gram/centimeter)/second\n\n    assert cgs_gauss.get_quantity_dimension(maxwell) == magnetic_flux\n    assert cgs_gauss.get_quantity_scale_factor(maxwell) == sqrt(centimeter**3*gram)/second\n\n    # Test that the SI units are correctly expressed in cgs_gaussian units\n    assert cgs_gauss.get_quantity_scale_factor(coulomb) == 10*speed_of_light*statcoulomb\n    assert cgs_gauss.get_quantity_scale_factor(ampere) == 10*speed_of_light*statcoulomb/second\n    assert cgs_gauss.get_quantity_scale_factor(volt) == 10**6/speed_of_light*statvolt\n    assert cgs_gauss.get_quantity_scale_factor(weber) == 10**8*maxwell\n    assert cgs_gauss.get_quantity_scale_factor(tesla) == 10**4*gauss\n    assert cgs_gauss.get_quantity_scale_factor(debye) == One/10**18*statcoulomb*centimeter\n    assert cgs_gauss.get_quantity_scale_factor(oersted) == sqrt(gram/centimeter)/second\n    assert cgs_gauss.get_quantity_scale_factor(ohm) == 10**5/speed_of_light**2*second/centimeter\n    assert cgs_gauss.get_quantity_scale_factor(farad) == One/10**5*speed_of_light**2*centimeter\n    assert cgs_gauss.get_quantity_scale_factor(henry) == 10**5/speed_of_light**2/"], "sample_655": ["    def test_suspend_global_capture(self, capsys):\n        capman = CaptureManager(\"fd\")\n        capman.start_global_capturing()\n        print(\"Hello\")\n        capman.suspend_global_capture()\n        print(\"World\")\n        capman.resume_global_capture()\n        out, err = capman.read_global_capture()\n        assert out == \"Hello\\n\"\n        assert err == \"\"\n"], "sample_832": ["def test_bayesian_ridge_predict():\n    # Test predict method of BayesianRidge\n    X, y = diabetes.data, diabetes.target\n    clf = BayesianRidge()\n    clf.fit(X, y)\n    y_mean, y_std = clf.predict(X, return_std=True)\n    assert_array_almost_equal(y_mean.shape, y.shape)\n    assert_array_less(y_std, 1000)  # std should not be too large\n    assert_array_less(0, y_std)  # std should be positive\n"], "sample_275": ["    def test_query_set_methods(self):\n        # Create some data\n        person1 = Person.objects.create(name='John')\n        person2 = Person.objects.create(name='Jane')\n        person3 = Person.objects.create(name='Jim')\n\n        # Test filter\n        qs = Person.objects.filter(name='John')\n        self.assertEqual(qs.count(), 1)\n        self.assertEqual(qs[0].name, 'John')\n\n        # Test exclude\n        qs = Person.objects.exclude(name='John')\n        self.assertEqual(qs.count(), 2)\n        self.assertEqual(qs[0].name, 'Jane')\n        self.assertEqual(qs[1].name, 'Jim')\n\n        # Test order_by\n        qs = Person.objects.order_by('name')\n        self.assertEqual(qs[0].name, 'Jane')\n        self.assertEqual(qs[1].name, 'Jim')\n        self.assertEqual(qs[2].name, 'John')\n\n        # Test reverse\n        qs = Person.objects.order_by('name').reverse()\n        self.assertEqual(qs[0].name, 'John')\n        self.assertEqual(qs[1].name, 'Jim')\n        self.assertEqual(qs[2].name, 'Jane')\n\n        # Test values\n        qs = Person.objects.values('name')\n        self.assertEqual(qs[0]['name'], 'John')\n        self.assertEqual(qs[1]['name'], 'Jane')\n        self.assertEqual(qs[2]['name'], 'Jim')\n\n        # Test values_list\n        qs = Person.objects.values_list('name', flat=True)\n        self.assertEqual(qs[0], 'John')\n        self.assertEqual(qs[1], 'Jane')\n        self.assertEqual(qs[2], 'Jim')\n\n        # Test dates\n        person1.date_of_birth = datetime.date(1990, 1, 1)\n        person2.date_of_birth = datetime.date(1991, 1, 1)\n        person3.date_of_birth = datetime.date(1992, 1, 1)\n        person1.save()\n        person2.save()\n        person3.save()\n        qs = Person.objects.dates('date_of_birth', 'year')\n        self.assertEqual(qs[0], datetime.date(1990, 1, 1))\n        self.assertEqual(qs[1], datetime.date(1991, 1, 1))\n        self.assertEqual(qs[2], datetime.date(1992, 1, 1"], "sample_695": ["def test_iterparentnodeids(nodeid, expected):\n    assert list(nodes.iterparentnodeids(nodeid)) == expected\n"], "sample_649": ["def test_logcapture_fixture(caplog, pytestconfig):\n    \"\"\"Test the logcapture fixture.\"\"\"\n    logger = logging.getLogger(\"test_logger\")\n    logger.setLevel(logging.DEBUG)\n\n    logger.debug(\"debug message\")\n    logger.info(\"info message\")\n    logger.warning(\"warning message\")\n    logger.error(\"error message\")\n    logger.critical(\"critical message\")\n\n    assert len(caplog.records) == 5\n    assert caplog.record_tuples == [\n        (\"test_logger\", logging.DEBUG, \"debug message\"),\n        (\"test_logger\", logging.INFO, \"info message\"),\n        (\"test_logger\", logging.WARNING, \"warning message\"),\n        (\"test_logger\", logging.ERROR, \"error message\"),\n        (\"test_logger\", logging.CRITICAL, \"critical message\"),\n    ]\n\n    caplog.clear()\n\n    logger.debug(\"debug message\")\n    logger.info(\"info message\")\n    logger.warning(\"warning message\")\n    logger.error(\"error message\")\n    logger.critical(\"critical message\")\n\n    assert len(caplog.records) == 5\n    assert caplog.record_tuples == [\n        (\"test_logger\", logging.DEBUG, \"debug message\"),\n        (\"test_logger\", logging.INFO, \"info message\"),\n        (\"test_logger\", logging.WARNING, \"warning message\"),\n        (\"test_logger\", logging.ERROR, \"error message\"),\n        (\"test_logger\", logging.CRITICAL, \"critical message\"),\n    ]\n\n    caplog.set_level(logging.INFO)\n\n    logger.debug(\"debug message\")\n    logger.info(\"info message\")\n    logger.warning(\"warning message\")\n    logger.error(\"error message\")\n    logger.critical(\"critical message\")\n\n    assert len(caplog.records) == 4\n    assert caplog.record_tuples == [\n        (\"test_logger\", logging.INFO, \"info message\"),\n        (\"test_logger\", logging.WARNING, \"warning message\"),\n        (\"test_logger\", logging.ERROR, \"error message\"),\n        (\"test_logger\", logging.CRITICAL, \"critical message\"),\n    ]\n\n    with caplog.at_level(logging.DEBUG):\n        logger.debug(\"debug message\")\n        logger.info(\"info message\")\n        logger.warning(\"warning message\")\n        logger.error(\"error message\")\n        logger.critical(\"critical message\")\n\n    assert len(caplog.records) == 9\n    assert caplog.record_tuples == [\n        (\"test_logger\", logging.INFO, \"info message\"),\n        (\"test_logger\", logging.WARNING, \"warning message\"),\n        (\"test_logger\", logging.ERROR, \"error message\"),\n        (\"test_logger\", logging.CRITICAL, \"critical message\"),\n        (\"test_logger\", logging.DEBUG"], "sample_665": ["def test_pyobj_property():\n    class TestClass:\n            self.module = \"test_module\"\n            self.cls = \"test_class\"\n            self.instance = \"test_instance\"\n\n    test_class = TestClass()\n    pyobj_property_instance = PyobjContext()\n    pyobj_property_instance.module = pyobj_property(\"module\")\n    pyobj_property_instance.cls = pyobj_property(\"cls\")\n    pyobj_property_instance.instance = pyobj_property(\"instance\")\n\n    assert pyobj_property_instance.module.fget(test_class) == \"test_module\"\n    assert pyobj_property_instance.cls.fget(test_class) == \"test_class\"\n    assert pyobj_property_instance.instance.fget(test_class) == \"test_instance\"\n"], "sample_1031": ["def test_quantity():\n    q = Quantity(\"test_quantity\")\n    q.set_dimension(length)\n    q.set_scale_factor(meter)\n    assert q.dimensionality == length\n    assert q.scale_factor == meter\n\n    q.set_dimension(mass)\n    q.set_scale_factor(kg)\n    assert q.dimensionality == mass\n    assert q.scale_factor == kg\n\n    q.set_dimension(time)\n    q.set_scale_factor(s)\n    assert q.dimensionality == time\n    assert q.scale_factor == s\n\n    q.set_dimension(velocity)\n    q.set_scale_factor(m/s)\n    assert q.dimensionality == velocity\n    assert q.scale_factor == m/s\n\n    q.set_dimension(action)\n    q.set_scale_factor(m**2*kg/s)\n    assert q.dimensionality == action\n    assert q.scale_factor == m**2*kg/s\n\n    q.set_dimension(current)\n    q.set_scale_factor(A)\n    assert q.dimensionality == current\n    assert q.scale_factor == A\n\n    raises(ValueError, lambda: q.set_dimension(mass))\n    raises(ValueError, lambda: q.set_scale_factor(m**2))\n"], "sample_796": ["def test_huber_regressor():\n    # Test HuberRegressor with outliers\n    X, y = make_regression_with_outliers()\n    huber = HuberRegressor()\n    huber.fit(X, y)\n    assert_greater(huber.score(X, y), -10)\n    assert_array_almost_equal(huber.coef_, huber.coef_, decimal=3)\n    assert_array_almost_equal(huber.intercept_, huber.intercept_, decimal=3)\n    assert_array_almost_equal(huber.scale_, huber.scale_, decimal=3)\n\n    # Test HuberRegressor with sparse data\n    X_sparse = sparse.csr_matrix(X)\n    huber_sparse = HuberRegressor()\n    huber_sparse.fit(X_sparse, y)\n    assert_array_almost_equal(huber_sparse.coef_, huber.coef_, decimal=3)\n    assert_array_almost_equal(huber_sparse.intercept_, huber.intercept_, decimal=3)\n    assert_array_almost_equal(huber_sparse.scale_, huber.scale_, decimal=3)\n\n    # Test HuberRegressor with sample weights\n    sample_weight = np.ones_like(y)\n    sample_weight[:10] = 0.5\n    huber_weighted = HuberRegressor()\n    huber_weighted.fit(X, y, sample_weight=sample_weight)\n    assert_array_almost_equal(huber_weighted.coef_, huber.coef_, decimal=3)\n    assert_array_almost_equal(huber_weighted.intercept_, huber.intercept_, decimal=3)\n    assert_array_almost_equal(huber_weighted.scale_, huber.scale_, decimal=3)\n\n    # Test HuberRegressor with warm start\n    huber_warm_start = HuberRegressor(warm_start=True)\n    huber_warm_start.fit(X, y)\n    assert_array_almost_equal(huber_warm_start.coef_, huber.coef_, decimal=3)\n    assert_array_almost_equal(huber_warm_start.intercept_, huber.intercept_, decimal=3)\n    assert_array_almost_equal(huber_warm_start.scale_, huber.scale_, decimal=3)\n\n    # Test HuberRegressor with different epsilon values\n    epsilon_values = [1.0, 1.1, 1.2, 1.3, 1.4]\n    for epsilon in epsilon_values:\n        huber_epsilon = HuberRegressor(epsilon=epsilon)\n        huber_epsilon.fit(X, y)\n        assert_array_almost_equal(huber_epsilon.coef_, huber.co"], "sample_304": ["def test_url_validator_with_idn(self):\n    validator = URLValidator()\n    with self.assertRaises(ValidationError):\n        validator('http://example.\u00fcser.com')\n    with self.assertRaises(ValidationError):\n        validator('http://example.\u00fcser.com/path')\n    with self.assertRaises(ValidationError):\n        validator('http://example.\u00fcser.com:8080')\n    with self.assertRaises(ValidationError):\n        validator('http://example.\u00fcser.com:8080/path')\n    with self.assertRaises(ValidationError):\n        validator('http://example.\u00fcser.com/path?query')\n    with self.assertRaises(ValidationError):\n        validator('http://example.\u00fcser.com/path?query#fragment')\n    with self.assertRaises(ValidationError):\n        validator('http://example.\u00fcser.com:8080/path?query#fragment')\n\n    validator = URLValidator(schemes=['http', 'https'])\n    with self.assertRaises(ValidationError):\n        validator('ftp://example.com')\n\n    validator = URLValidator(schemes=['http', 'https', 'ftp'])\n    validator('ftp://example.com')\n\n    validator = URLValidator(schemes=['http', 'https', 'ftp', 'ftps'])\n    validator('ftps://example.com')\n\n    validator = URLValidator(schemes=['http', 'https', 'ftp', 'ftps', 'git'])\n    validator('git://example.com')\n\n    validator = URLValidator(schemes=['http', 'https', 'ftp', 'ftps', 'git', 'git+ssh'])\n    validator('git+ssh://example.com')\n\n    validator = URLValidator(schemes=['http', 'https', 'ftp', 'ftps', 'git', 'git+ssh', 'file'])\n    validator('file://example.com')\n\n    validator = URLValidator(schemes=['http', 'https', 'ftp', 'ftps', 'git', 'git+ssh', 'file', 'http+ssh'])\n    with self.assertRaises(ValidationError):\n        validator('http+ssh://example.com')\n"], "sample_192": ["    def test_formset_factory_with_custom_form_init(self):\n        CustomKwargFormSet = formset_factory(CustomKwargForm, extra=1)\n        formset = CustomKwargFormSet(custom_kwarg='test')\n        self.assertEqual(formset.forms[0].custom_kwarg, 'test')\n"], "sample_503": ["def test_line2d_markevery():\n    fig, ax = plt.subplots()\n    x = np.linspace(0, 10, 100)\n    y = np.sin(x)\n    line, = ax.plot(x, y, 'o-', markevery=10)\n    assert_array_equal(line.get_markevery(), 10)\n\n    line.set_markevery(5)\n    assert_array_equal(line.get_markevery(), 5)\n\n    line.set_markevery((0, 5))\n    assert_array_equal(line.get_markevery(), (0, 5))\n\n    line.set_markevery(slice(0, 10, 2))\n    assert_array_equal(line.get_markevery(), slice(0, 10, 2))\n\n    line.set_markevery([1, 3, 5])\n    assert_array_equal(line.get_markevery(), [1, 3, 5])\n\n    line.set_markevery(0.1)\n    assert_array_equal(line.get_markevery(), 0.1)\n\n    line.set_markevery((0.5, 0.1))\n    assert_array_equal(line.get_markevery(), (0.5, 0.1))\n\n    line.set_markevery(None)\n    assert line.get_markevery() is None\n"], "sample_127": ["def test_bulk_create_with_prefetch_related(self):\n    # Create a restaurant with a country\n    country = Country.objects.create(name=\"United States of America\", iso_two_letter=\"US\")\n    restaurant = Restaurant.objects.create(name=\"Pizza Hut\", country=country)\n\n    # Create a list of pizzerias with prefetch_related\n    pizzerias = [\n        Pizzeria(name=\"Pizza Hut 1\", restaurant=restaurant),\n        Pizzeria(name=\"Pizza Hut 2\", restaurant=restaurant),\n        Pizzeria(name=\"Pizza Hut 3\", restaurant=restaurant),\n    ]\n\n    # Use bulk_create with prefetch_related\n    Pizzeria.objects.bulk_create(pizzerias, batch_size=2)\n\n    # Check that the pizzerias were created correctly\n    self.assertEqual(Pizzeria.objects.count(), 3)\n    for pizzeria in Pizzeria.objects.all():\n        self.assertEqual(pizzeria.restaurant, restaurant)\n"], "sample_1009": ["def test_vector_to_matrix():\n    q = symbols('q')\n    N = ReferenceFrame('N')\n    A = N.orientnew('A', 'Axis', [q, N.x])\n    v = 2 * N.x + 3 * N.y + 4 * N.z\n    v_A = v.express(A)\n    assert v.to_matrix(N) == Matrix([2, 3, 4])\n    assert v_A.to_matrix(A) == Matrix([2*cos(q) + 4*sin(q), -2*sin(q) + 4*cos(q), 3])\n"], "sample_469": ["def test_annotation_select_mask(self):\n    # Create a query with annotations\n    query = Book.objects.annotate(avg_price=Avg(\"price\"))\n\n    # Check that the annotation is in the annotation_select\n    self.assertIn(\"avg_price\", query.annotation_select)\n\n    # Set the annotation mask to only include the annotation\n    query.set_annotation_mask([\"avg_price\"])\n\n    # Check that the annotation is still in the annotation_select\n    self.assertIn(\"avg_price\", query.annotation_select)\n\n    # Set the annotation mask to exclude the annotation\n    query.set_annotation_mask([])\n\n    # Check that the annotation is no longer in the annotation_select\n    self.assertNotIn(\"avg_price\", query.annotation_select)\n\n    # Check that the annotation is still in the annotations\n    self.assertIn(\"avg_price\", query.annotations)\n\n    # Set the annotation mask to None\n    query.set_annotation_mask(None)\n\n    # Check that the annotation is back in the annotation_select\n    self.assertIn(\"avg_price\", query.annotation_select)\n"], "sample_123": ["    def test_urlsafe_base64_encode(self):\n        s = b'Hello, World!'\n        encoded = urlsafe_base64_encode(s)\n        self.assertEqual(encoded, 'SGVsbG8sIFdvcmxkIQ')\n"], "sample_1012": ["def test_printing():\n    p = PythonCodePrinter()\n    assert p._print_known_func(Mod(1, 2)) == 'math.fmod(1, 2)'\n    assert p._print_known_const(pi) == 'math.pi'\n    assert p._print_known_func(sign(1)) == 'math.copysign(1, 1)'\n    assert p._print_known_func(acos(1)) == 'math.acos(1)'\n    assert p._print_known_func(Piecewise((1, Eq(x, 0)), (0, True))) == '(1 if Eq(x, 0) else 0)'\n    assert p._print_known_func(And(x, y)) == '(x and y)'\n    assert p._print_known_func(Or(x, y)) == '(x or y)'\n    assert p._print_known_func(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n    assert p._print_known_func(zoo) == 'float(\"inf\")'\n    assert p._print_known_func(oo) == 'float(\"inf\")'\n    assert p._print_known_func(Rational(1, 2)) == '1/2'\n    assert p._print_known_func(none) == 'None'\n"], "sample_220": ["def test_set_cookie_with_expires(self):\n    response = HttpResponse()\n    expires = datetime(2024, 3, 16, 10, 30, tzinfo=utc)\n    response.set_cookie('key', 'value', expires=expires)\n    cookie = cookies.SimpleCookie(response.cookies.output(header=''))\n    self.assertEqual(cookie['key']['expires'], http_date(time.mktime(expires.timetuple())))\n"], "sample_989": ["def test_comp():\n    assert comp(1, 1) == True\n    assert comp(1, 2) == True\n    assert comp(1, 2, 0.5) == False\n    assert comp(1, 2, 1) == True\n    assert comp(1, 2, 2) == True\n    assert comp(1, 1, 0) == True\n    assert comp(1, 1, 1) == False\n    assert comp(1, 1, 0.5) == False\n    assert comp(1, 1, 2) == False\n    assert comp(1, 1, 1e-10) == False\n    assert comp(1, 1, 1e-15) == True\n    assert comp(1, 1, 1e-20) == True\n    assert comp(1, 1, 1e-25) == True\n    assert comp(1, 1, 1e-30) == True\n    assert comp(1, 1, 1e-35) == True\n    assert comp(1, 1, 1e-40) == True\n    assert comp(1, 1, 1e-45) == True\n    assert comp(1, 1, 1e-50) == True\n    assert comp(1, 1, 1e-55) == True\n    assert comp(1, 1, 1e-60) == True\n    assert comp(1, 1, 1e-65) == True\n    assert comp(1, 1, 1e-70) == True\n    assert comp(1, 1, 1e-75) == True\n    assert comp(1, 1, 1e-80) == True\n    assert comp(1, 1, 1e-85) == True\n    assert comp(1, 1, 1e-90) == True\n    assert comp(1, 1, 1e-95) == True\n    assert comp(1, 1, 1e-100) == True\n    assert comp(1, 1, 1e-105) == True\n    assert comp(1, 1, 1e"], "sample_879": ["def test_ordinal_encoder_handle_unknown():\n    # Test that OrdinalEncoder handles unknown categories correctly\n    X = np.array([['a', 'b'], ['b', 'c'], ['a', 'd']])\n    oe = OrdinalEncoder(handle_unknown='error')\n    oe.fit(X)\n    with pytest.raises(ValueError):\n        oe.transform(np.array([['a', 'e']]))\n\n    oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=2)\n    oe.fit(X)\n    assert_array_equal(oe.transform(np.array([['a', 'e']])), np.array([[0, 2]]))\n\n    oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n    oe.fit(X)\n    assert_array_equal(oe.transform(np.array([['a', 'e']])), np.array([[0, np.nan]]))\n"], "sample_776": ["def test_lars_path_residues():\n    # Test that the residues are correctly computed\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n    alphas, active, coefs, residues = _lars_path_residues(X_train, y_train, X_test, y_test)\n    assert_equal(residues.shape, (len(alphas), len(y_test)))\n\n    # Test that the residues are correctly computed with Gram\n    Gram = np.dot(X_train.T, X_train)\n    alphas, active, coefs, residues = _lars_path_residues(X_train, y_train, X_test, y_test, Gram=Gram)\n    assert_equal(residues.shape, (len(alphas), len(y_test)))\n\n    # Test that the residues are correctly computed with precomputed Xy\n    Xy = np.dot(X_train.T, y_train)\n    alphas, active, coefs, residues = _lars_path_residues(X_train, y_train, X_test, y_test, Xy=Xy)\n    assert_equal(residues.shape, (len(alphas), len(y_test)))\n\n    # Test that the residues are correctly computed with copy=False\n    alphas, active, coefs, residues = _lars_path_residues(X_train, y_train, X_test, y_test, copy=False)\n    assert_equal(residues.shape, (len(alphas), len(y_test)))\n\n    # Test that the residues are correctly computed with method='lasso'\n    alphas, active, coefs, residues = _lars_path_residues(X_train, y_train, X_test, y_test, method='lasso')\n    assert_equal(residues.shape, (len(alphas), len(y_test)))\n\n    # Test that the residues are correctly computed with positive=True\n    alphas, active, coefs, residues = _lars_path_residues(X_train, y_train, X_test, y_test, positive=True)\n    assert_equal(residues.shape, (len(alphas), len(y_test)))\n\n    # Test that the residues are correctly computed with normalize=False\n    alphas, active, coefs, residues = _lars_path_residues(X_train, y_train, X_test, y_test, normalize=False)\n    assert_equal(residues.shape, (len(alphas), len(y_test)))\n\n"], "sample_756": ["def test_extract_dbscan():\n    # Test DBSCAN extraction for an arbitrary epsilon\n    optics = OPTICS(min_samples=10, max_eps=3.0)\n    optics.fit(X)\n    eps = 1.5\n    core_sample_indices, labels = optics.extract_dbscan(eps)\n    assert len(core_sample_indices) > 0\n    assert len(labels) == len(X)\n\n    # Test DBSCAN extraction with eps larger than max_eps\n    with assert_raise_message(ValueError, \"Specify an epsilon smaller than\"):\n        optics.extract_dbscan(eps=4.0)\n\n    # Test DBSCAN extraction with eps close to max_eps\n    with assert_warns(RuntimeWarning, \"max_eps .* is close to eps .*\"):\n        optics.extract_dbscan(eps=2.9)\n"], "sample_623": ["def test_to_netcdf_invalid_netcdf():\n    # Create a dataset with a numpy.bool_ attribute\n    ds = xr.Dataset()\n    ds.attrs[\"bool_attr\"] = np.bool_(True)\n\n    # Try to write the dataset to netCDF with invalid_netcdf=True\n    with pytest.raises(ValueError):\n        ds.to_netcdf(\"test.nc\", engine=\"netcdf4\", invalid_netcdf=True)\n\n    # Try to write the dataset to netCDF with invalid_netcdf=True and engine=h5netcdf\n    ds.to_netcdf(\"test.nc\", engine=\"h5netcdf\", invalid_netcdf=True)\n\n    # Try to write the dataset to netCDF with invalid_netcdf=False\n    ds.to_netcdf(\"test.nc\", engine=\"h5netcdf\", invalid_netcdf=False)\n"], "sample_573": ["    def test_polyfit(self, df):\n        \"\"\"Test that PolyFit works as expected.\"\"\"\n        polyfit = PolyFit()\n        result = polyfit(df, GroupBy(\"color\"), \"x\", \"y\")\n        assert isinstance(result, pd.DataFrame)\n        assert result.shape[0] == 3 * polyfit.gridsize\n        assert result[\"x\"].nunique() == polyfit.gridsize\n        assert result[\"color\"].nunique() == 3\n"], "sample_553": ["def test_html_writer(tmpdir):\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3])\n    writer = animation.HTMLWriter()\n    ani = animation.FuncAnimation(fig, lambda i: None, frames=5)\n    ani.save(str(tmpdir / 'test.html'), writer=writer)\n    assert (tmpdir / 'test.html').exists()\n    assert (tmpdir / 'test_frames').exists()\n    assert len(list((tmpdir / 'test_frames').glob('*.png'))) == 5\n"], "sample_1016": ["def test_octave_code():\n    assert octave_code(x**2 + 2*x - 1) == \"(x.^2 + 2.*x - 1)\"\n    assert octave_code(x**2 + 2*x*y - 1) == \"(x.^2 + 2.*x.*y - 1)\"\n    assert octave_code(x**2 + 2*y - 1) == \"(x.^2 + 2.*y - 1)\"\n    assert octave_code(x**2 + 2*x - y) == \"(x.^2 + 2.*x - y)\"\n    assert octave_code(x**2 + 2*x - y, assign_to=\"s\") == \"s = (x.^2 + 2.*x - y);\"\n    assert octave_code(x**2 + 2*x - y, assign_to=\"s\", inline=False) == \"s = x.^2 + 2.*x - y;\"\n    assert octave_code(x**2 + 2*x - y, assign_to=\"s\", inline=False, human=False) == ([], [], \"s = x.^2 + 2.*x - y;\")\n    assert octave_code(x**2 + 2*x - y, assign_to=\"s\", inline=False, human=False, precision=20) == ([], [], \"s = x.^2 + 2.*x - y;\")\n    assert octave_code(x**2 + 2*x - y, assign_to=\"s\", inline=False, human=False, precision=20, user_functions={}) == ([], [], \"s = x.^2 + 2.*x - y;\")\n    assert octave_code(x**2 + 2*x - y, assign_to=\"s\", inline=False, human=False, precision=20, user_functions={}, contract=True) == ([], [], \"s = x.^2 + 2.*x - y;\")\n    assert octave_code(x**2 + 2*x - y, assign_to=\"s\", inline=False, human=False, precision=20, user_functions={}, contract=True, inline=True) == ([], [], \"s = x.^2 + 2.*x - y;\")\n    assert octave_code(x**2 + 2*x - y, assign_to=\"s\", inline=False, human=False, precision=20, user_functions={}, contract=True, inline=True, order=None) == ([], [], \"s = x.^2 + 2.*x - y;\")\n    assert octave_code"], "sample_794": ["def test_ridge_regression_sparse_cg():\n    # Test sparse_cg solver with sparse input\n    X_sparse = sp.csr_matrix(np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))\n    y = np.array([1, 2, 3])\n    alpha = 1.0\n    coef_sparse_cg = ridge_regression(X_sparse, y, alpha, solver='sparse_cg')\n    coef_cholesky = ridge_regression(X_sparse.toarray(), y, alpha, solver='cholesky')\n    assert_allclose(coef_sparse_cg, coef_cholesky, atol=1e-6)\n\n    # Test sparse_cg solver with sparse input and sample weights\n    sample_weight = np.array([1.0, 2.0, 3.0])\n    coef_sparse_cg_sw = ridge_regression(X_sparse, y, alpha, solver='sparse_cg', sample_weight=sample_weight)\n    coef_cholesky_sw = ridge_regression(X_sparse.toarray(), y, alpha, solver='cholesky', sample_weight=sample_weight)\n    assert_allclose(coef_sparse_cg_sw, coef_cholesky_sw, atol=1e-6)\n\n    # Test sparse_cg solver with sparse input and multiple targets\n    y_multi = np.array([[1, 2], [3, 4], [5, 6]])\n    coef_sparse_cg_multi = ridge_regression(X_sparse, y_multi, alpha, solver='sparse_cg')\n    coef_cholesky_multi = ridge_regression(X_sparse.toarray(), y_multi, alpha, solver='cholesky')\n    assert_allclose(coef_sparse_cg_multi, coef_cholesky_multi, atol=1e-6)\n\n    # Test sparse_cg solver with sparse input and multiple targets and sample weights\n    coef_sparse_cg_multi_sw = ridge_regression(X_sparse, y_multi, alpha, solver='sparse_cg', sample_weight=sample_weight)\n    coef_cholesky_multi_sw = ridge_regression(X_sparse.toarray(), y_multi, alpha, solver='cholesky', sample_weight=sample_weight)\n    assert_allclose(coef_sparse_cg_multi_sw, coef_cholesky_multi_sw, atol=1e-6)\n"], "sample_1092": ["def test_cse_separate():\n    eq = Eq(x + 1 + exp((x + 1)/(y + 1)) + cos(y + 1), 0)\n    replacements, reduced_exprs = cse([eq, Eq(x, z + 1), z - 2], postprocess=cse_separate)\n    assert len(replacements) == 3\n    assert len(reduced_exprs) == 2\n    assert all(isinstance(expr, Eq) for expr in reduced_exprs)\n    assert all(isinstance(replacement, tuple) for replacement in replacements)\n    assert all(isinstance(replacement[0], Symbol) and replacement[1].is_expr for replacement in replacements)\n"], "sample_19": ["def test_wcs_to_header(self):\n    # Test that WCS.to_header() returns a header with the correct WCS keywords\n    # and that WCS.to_fits() returns a FITS file with the correct WCS keywords.\n\n    # Create a WCS object\n    w = wcs.WCS(naxis=2)\n\n    # Set some WCS parameters\n    w.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\"]\n    w.wcs.crval = [12.5, 34.2]\n    w.wcs.crpix = [100, 200]\n    w.wcs.cdelt = [0.01, 0.01]\n    w.wcs.cunit = [\"deg\", \"deg\"]\n\n    # Get the header\n    header = w.to_header()\n\n    # Check that the header has the correct WCS keywords\n    assert header[\"CTYPE1\"] == \"RA---TAN\"\n    assert header[\"CTYPE2\"] == \"DEC--TAN\"\n    assert header[\"CRVAL1\"] == 12.5\n    assert header[\"CRVAL2\"] == 34.2\n    assert header[\"CRPIX1\"] == 100\n    assert header[\"CRPIX2\"] == 200\n    assert header[\"CDELT1\"] == 0.01\n    assert header[\"CDELT2\"] == 0.01\n    assert header[\"CUNIT1\"] == \"deg\"\n    assert header[\"CUNIT2\"] == \"deg\"\n\n    # Get the FITS file\n    hdulist = w.to_fits()\n\n    # Check that the FITS file has the correct WCS keywords\n    assert hdulist[0].header[\"CTYPE1\"] == \"RA---TAN\"\n    assert hdulist[0].header[\"CTYPE2\"] == \"DEC--TAN\"\n    assert hdulist[0].header[\"CRVAL1\"] == 12.5\n    assert hdulist[0].header[\"CRVAL2\"] == 34.2\n    assert hdulist[0].header[\"CRPIX1\"] == 100\n    assert hdulist[0].header[\"CRPIX2\"] == 200\n    assert hdulist[0].header[\"CDELT1\"] == 0.01\n    assert hdulist[0].header[\"CDELT2\"] == 0.01\n    assert hdulist[0].header[\"CUNIT1\"] == \"deg\"\n    assert"], "sample_912": ["def test_parse_annotation():\n    annotation = \"List[int]\"\n    result = _parse_annotation(annotation)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].astext() == \"List\"\n    assert result[0].attributes['reftarget'] == \"List\"\n    assert result[0].attributes['refdomain'] == \"py\"\n    assert result[0].attributes['reftype'] == \"class\"\n\n    annotation = \"Union[int, str]\"\n    result = _parse_annotation(annotation)\n    assert len(result) == 5\n    assert isinstance(result[0], desc_sig_punctuation)\n    assert result[0].astext() == \"[\"\n    assert isinstance(result[1], pending_xref)\n    assert result[1].astext() == \"int\"\n    assert result[1].attributes['reftarget'] == \"int\"\n    assert result[1].attributes['refdomain'] == \"py\"\n    assert result[1].attributes['reftype'] == \"class\"\n    assert isinstance(result[2], desc_sig_punctuation)\n    assert result[2].astext() == \", \"\n    assert isinstance(result[3], pending_xref)\n    assert result[3].astext() == \"str\"\n    assert result[3].attributes['reftarget'] == \"str\"\n    assert result[3].attributes['refdomain'] == \"py\"\n    assert result[3].attributes['reftype'] == \"class\"\n    assert isinstance(result[4], desc_sig_punctuation)\n    assert result[4].astext() == \"]\"\n\n    annotation = \"List[Union[int, str]]\"\n    result = _parse_annotation(annotation)\n    assert len(result) == 7\n    assert isinstance(result[0], pending_xref)\n    assert result[0].astext() == \"List\"\n    assert result[0].attributes['reftarget'] == \"List\"\n    assert result[0].attributes['refdomain'] == \"py\"\n    assert result[0].attributes['reftype'] == \"class\"\n    assert isinstance(result[1], desc_sig_punctuation)\n    assert result[1].astext() == \"[\"\n    assert isinstance(result[2], desc_sig_punctuation)\n    assert result[2].astext() == \"[\"\n    assert isinstance(result[3], pending_xref)\n    assert result[3].astext() == \"int\"\n   "], "sample_313": ["    def test_template_changed_resets_loaders(self):\n        # Mock the get_template_directories function to return a directory\n        # that is a parent of the file_path.\n        with mock.patch('template_tests.get_template_directories') as mock_get_template_directories:\n            mock_get_template_directories.return_value = [Path('/path/to/templates')]\n            file_path = '/path/to/templates/subdir/template.html'\n            self.assertTrue(template_changed(None, file_path))\n            self.assertTrue(reset_loaders.called)\n\n        # Mock the get_template_directories function to return a directory\n        # that is not a parent of the file_path.\n        with mock.patch('template_tests.get_template_directories') as mock_get_template_directories:\n            mock_get_template_directories.return_value = [Path('/path/to/other/templates')]\n            file_path = '/path/to/templates/subdir/template.html'\n            self.assertFalse(template_changed(None, file_path))\n            self.assertFalse(reset_loaders.called)\n"], "sample_1104": ["def test_strprinter():\n    printer = StrPrinter()\n    assert printer._print_StrPrinter(StrPrinter()) == \"StrPrinter()\"\n    assert printer._print_StrReprPrinter(StrReprPrinter()) == \"StrReprPrinter()\"\n    assert printer._print_Predicate(S.true) == \"Q.true\"\n    assert printer._print_Predicate(S.false) == \"Q.false\"\n    assert printer._print_Predicate(S.Eq) == \"Q.Eq\"\n    assert printer._print_Predicate(S.Ne) == \"Q.Ne\"\n    assert printer._print_Predicate(S.Gt) == \"Q.Gt\"\n    assert printer._print_Predicate(S.Lt) == \"Q.Lt\"\n    assert printer._print_Predicate(S.Ge) == \"Q.Ge\"\n    assert printer._print_Predicate(S.Le) == \"Q.Le\"\n    assert printer._print_Predicate(S.Eq) == \"Q.Eq\"\n    assert printer._print_Predicate(S.Ne) == \"Q.Ne\"\n    assert printer._print_Predicate(S.Equivalent) == \"Q.Equivalent\"\n    assert printer._print_Predicate(S.Xor) == \"Q.Xor\"\n    assert printer._print_Predicate(S.Complement) == \"Q.Complement\"\n    assert printer._print_Predicate(S.SymmetricDifference) == \"Q.SymmetricDifference\"\n    assert printer._print_Predicate(S.AccumBounds) == \"Q.AccumBounds\"\n    assert printer._print_Predicate(S.UnevaluatedExpr) == \"Q.UnevaluatedExpr\"\n    assert printer._print_Predicate(S.Eq) == \"Q.Eq\"\n    assert printer._print_Predicate(S.Ne) == \"Q.Ne\"\n    assert printer._print_Predicate(S.Gt) == \"Q.Gt\"\n    assert printer._print_Predicate(S.Lt) == \"Q.Lt\"\n    assert printer._print_Predicate(S.Ge) == \"Q.Ge\"\n    assert printer._print_Predicate(S.Le) == \"Q.Le\"\n    assert printer._print_Predicate(S.Eq) == \"Q.Eq\"\n    assert printer._print_Predicate(S.Ne) == \"Q.Ne\"\n    assert printer._print_Predicate(S.Equivalent) == \"Q.Equivalent\"\n    assert printer._print_Predicate(S.Xor) == \"Q.Xor\"\n    assert printer._print_Predicate(S.Complement) == \"Q.Complement\"\n   "], "sample_1014": ["def test_immutable_dense_ndim_array():\n    a = ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    b = a.tomatrix()\n    assert b == Matrix([[1, 2], [3, 4]])\n\n    c = ImmutableDenseNDimArray([1, 2, 3, 4, 5, 6], (2, 3))\n    d = c.reshape(3, 2)\n    assert d.shape == (3, 2)\n    assert d._array == [1, 2, 3, 4, 5, 6]\n\n    e = ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    f = e.as_mutable()\n    assert isinstance(f, MutableDenseNDimArray)\n\n    g = ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    assert g.free_symbols == set()\n\n    h = ImmutableDenseNDimArray([1, Symbol('x'), 3, 4], (2, 2))\n    assert h.free_symbols == {Symbol('x')}\n\n    i = ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    j = copy(i)\n    assert j.shape == i.shape\n    assert j._array == i._array\n\n    with raises(ValueError):\n        ImmutableDenseNDimArray([1, 2, 3, 4], (2, 3))\n\n    with raises(ValueError):\n        ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2)).reshape(3, 3)\n\n    with raises(TypeError):\n        ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2))[0, 0] = 5\n"], "sample_1181": ["def test_NDimArray():\n    A = Array([[1, 2], [3, 4]])\n    p = NumPyPrinter()\n    assert p.doprint(A) == \"numpy.array([[1, 2], [3, 4]])\"\n"], "sample_1196": ["def test_contains_eval():\n    x = Symbol('x')\n    assert Contains(x, S.Integers).func == Contains\n    assert Contains(1, S.Integers).is_true\n    assert Contains(1, S.Naturals).is_true\n    assert Contains(-1, S.Naturals).is_false\n    assert Contains(1, S.EmptySet).is_false\n    assert Contains(1, S.UniversalSet).is_true\n    assert Contains(x, S.EmptySet).is_false\n    assert Contains(x, S.UniversalSet).is_true\n"], "sample_685": ["def test_log_capture_fixture(caplog):\n    logger.info(\"info message\")\n    logger.warning(\"warning message\")\n    sublogger.error(\"error message\")\n\n    assert caplog.records == [\n        logging.makeLogRecord(\n            {\n                \"name\": __name__,\n                \"msg\": \"info message\",\n                \"levelname\": \"INFO\",\n                \"levelno\": logging.INFO,\n            }\n        ),\n        logging.makeLogRecord(\n            {\n                \"name\": __name__,\n                \"msg\": \"warning message\",\n                \"levelname\": \"WARNING\",\n                \"levelno\": logging.WARNING,\n            }\n        ),\n        logging.makeLogRecord(\n            {\n                \"name\": __name__ + \".baz\",\n                \"msg\": \"error message\",\n                \"levelname\": \"ERROR\",\n                \"levelno\": logging.ERROR,\n            }\n        ),\n    ]\n\n    assert caplog.record_tuples == [\n        (__name__, logging.INFO, \"info message\"),\n        (__name__, logging.WARNING, \"warning message\"),\n        (__name__ + \".baz\", logging.ERROR, \"error message\"),\n    ]\n\n    assert caplog.messages == [\"info message\", \"warning message\", \"error message\"]\n\n    assert caplog.text == (\n        \"INFO     {} info message\\n\"\n        \"WARNING  {} warning message\\n\"\n        \"ERROR    {}.baz error message\\n\".format(__name__, __name__, __name__)\n    )\n"], "sample_266": ["    def test_load_disk(self):\n        \"\"\"\n        Test loading migrations from disk.\n        \"\"\"\n        loader = MigrationLoader(connection=connection)\n        loader.load_disk()\n        self.assertIsNotNone(loader.disk_migrations)\n        self.assertIsNotNone(loader.unmigrated_apps)\n        self.assertIsNotNone(loader.migrated_apps)\n"], "sample_728": ["def test_make_classification():\n    # Test that the generated data is finite\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=2,\n                               n_redundant=2, n_repeated=0, n_classes=2,\n                               n_clusters_per_class=2, weights=None, flip_y=0.01,\n                               class_sep=1.0, hypercube=True, shift=0.0, scale=1.0,\n                               shuffle=True, random_state=0)\n    assert_all_finite(X)\n    assert_all_finite(y)\n\n    # Test that the generated data has the correct shape\n    assert_equal(X.shape, (100, 20))\n    assert_equal(y.shape, (100,))\n\n    # Test that the number of classes is correct\n    assert_equal(len(np.unique(y)), 2)\n\n    # Test that the number of informative features is correct\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=5,\n                               n_redundant=2, n_repeated=0, n_classes=2,\n                               n_clusters_per_class=2, weights=None, flip_y=0.01,\n                               class_sep=1.0, hypercube=True, shift=0.0, scale=1.0,\n                               shuffle=True, random_state=0)\n    assert_equal(X.shape, (100, 20))\n\n    # Test that the number of redundant features is correct\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=2,\n                               n_redundant=5, n_repeated=0, n_classes=2,\n                               n_clusters_per_class=2, weights=None, flip_y=0.01,\n                               class_sep=1.0, hypercube=True, shift=0.0, scale=1.0,\n                               shuffle=True, random_state=0)\n    assert_equal(X.shape, (100, 20))\n\n    # Test that the number of repeated features is correct\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=2,\n                               n_redundant=2, n_repeated=5, n_classes=2,\n                               n_clusters_per_class=2, weights=None, flip_y=0.01,\n                               class_sep=1.0, hypercube=True, shift=0.0"], "sample_327": ["def test_jsonfield_prepare_value(self):\n    class TestForm(Form):\n        json_field = JSONField(encoder=DjangoJSONEncoder)\n\n    form = TestForm({'json_field': '{\"key\": \"value\"}'})\n    self.assertEqual(form.fields['json_field'].prepare_value(form.data['json_field']), '{\"key\": \"value\"}')\n\n    form = TestForm({'json_field': json.dumps({'key': 'value'})})\n    self.assertEqual(form.fields['json_field'].prepare_value(form.data['json_field']), '{\"key\": \"value\"}')\n\n    form = TestForm({'json_field': {'key': 'value'}})\n    self.assertEqual(form.fields['json_field'].prepare_value(form.data['json_field']), '{\"key\": \"value\"}')\n\n    form = TestForm({'json_field': 'not a json'})\n    self.assertEqual(form.fields['json_field'].prepare_value(form.data['json_field']), 'not a json')\n\n    form = TestForm({'json_field': None})\n    self.assertEqual(form.fields['json_field'].prepare_value(form.data['json_field']), 'null')\n\n    form = TestForm({'json_field': uuid.uuid4()})\n    self.assertEqual(form.fields['json_field'].prepare_value(form.data['json_field']), str(form.data['json_field']))\n"], "sample_178": ["    def test_management_form_validation(self):\n        formset = self.make_choiceformset(\n            formset_data=[('A', 1), ('B', 2)],\n            total_forms=3,\n            initial_forms=2,\n            max_num_forms=2,\n            min_num_forms=1,\n        )\n        with self.assertRaises(ValidationError) as cm:\n            formset.management_form.is_valid()\n        self.assertEqual(cm.exception.code, 'missing_management_form')\n\n        formset = self.make_choiceformset(\n            formset_data=[('A', 1), ('B', 2)],\n            total_forms=3,\n            initial_forms=2,\n            max_num_forms=2,\n            min_num_forms=1,\n            data={'choices-TOTAL_FORMS': '4', 'choices-INITIAL_FORMS': '2', 'choices-MIN_NUM_FORMS': '1', 'choices-MAX_NUM_FORMS': '2'}\n        )\n        with self.assertRaises(ValidationError) as cm:\n            formset.management_form.is_valid()\n        self.assertEqual(cm.exception.code, 'too_many_forms')\n"], "sample_174": ["def test_adapt_decimalfield_value(self):\n    value = decimal.Decimal('123.456')\n    adapted_value = self.ops.adapt_decimalfield_value(value)\n    self.assertEqual(adapted_value, '123.456')\n\n    value = decimal.Decimal('123.456')\n    adapted_value = self.ops.adapt_decimalfield_value(value, max_digits=10, decimal_places=2)\n    self.assertEqual(adapted_value, '123.46')\n\n    value = None\n    adapted_value = self.ops.adapt_decimalfield_value(value)\n    self.assertIsNone(adapted_value)\n"], "sample_43": ["def test_bayesian_blocks_regular_events():\n    dt = 0.05\n    t = dt * np.arange(1000)\n    x = np.zeros(len(t))\n    x[np.random.randint(0, len(t), len(t) // 10)] = 1\n\n    edges = bayesian_blocks(t, x, fitness='regular_events', dt=dt)\n    assert len(edges) > 2\n\n    # Test that the edges are in ascending order\n    assert np.all(np.diff(edges) > 0)\n\n    # Test that the edges are correctly spaced by dt\n    assert_allclose(np.diff(edges), dt, atol=1e-10)\n"], "sample_262": ["def test_lazy_property(self):\n    class TestClass:\n            self._value = None\n\n        @cached_property\n            self._value = 'computed'\n            return self._value\n\n    obj = TestClass()\n    self.assertIsNone(obj._value)\n    self.assertEqual(obj.value, 'computed')\n    self.assertEqual(obj._value, 'computed')\n    self.assertEqual(obj.value, 'computed')  # cached value is returned\n"], "sample_107": ["    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        exc_type = Exception\n        exc_value = Exception('Test exception')\n        tb = None\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIn('request', data)\n        self.assertIn('settings', data)\n        self.assertIn('sys_executable', data)\n        self.assertIn('sys_version_info', data)\n        self.assertIn('server_time', data)\n        self.assertIn('django_version_info', data)\n        self.assertIn('sys_path', data)\n        self.assertIn('template_info', data)\n        self.assertIn('template_does_not_exist', data)\n        self.assertIn('postmortem', data)\n        self.assertIn('exception_type', data)\n        self.assertIn('exception_value', data)\n        self.assertIn('frames', data)\n        self.assertIn('request_GET_items', data)\n        self.assertIn('request_FILES_items', data)\n        self.assertIn('request_COOKIES_items', data)\n        self.assertIn('filtered_POST_items', data)\n        self.assertIn('lastframe', data)\n"], "sample_63": ["    def test_render_to_string_with_context(self):\n        template_name = 'template.txt'\n        template_path = os.path.join(TEMPLATE_DIR, template_name)\n        with open(template_path, 'w') as f:\n            f.write('Hello {{ name }}!')\n        context = {'name': 'world'}\n        rendered = self.engine.render_to_string(template_name, context)\n        self.assertEqual(rendered, 'Hello world!')\n"], "sample_585": ["def test_consolidate_slices():\n    slices = [slice(0, 3), slice(3, 6), slice(6, 9), slice(9, 12)]\n    expected = [slice(0, 12)]\n    assert _consolidate_slices(slices) == expected\n\n    slices = [slice(0, 3), slice(4, 6), slice(6, 9), slice(9, 12)]\n    expected = [slice(0, 3), slice(4, 12)]\n    assert _consolidate_slices(slices) == expected\n\n    slices = [slice(0, 3), slice(3, 6), slice(7, 9), slice(9, 12)]\n    expected = [slice(0, 6), slice(7, 12)]\n    assert _consolidate_slices(slices) == expected\n\n    slices = [slice(0, 3), slice(3, 6), slice(6, 9), slice(10, 12)]\n    expected = [slice(0, 9), slice(10, 12)]\n    assert _consolidate_slices(slices) == expected\n\n    slices = [slice(0, 3), slice(3, 6), slice(6, 9), slice(12, 15)]\n    expected = [slice(0, 9), slice(12, 15)]\n    assert _consolidate_slices(slices) == expected\n\n    slices = [slice(0, 3), slice(3, 6), slice(6, 9), slice(9, 12), slice(12, 15)]\n    expected = [slice(0, 15)]\n    assert _consolidate_slices(slices) == expected\n\n    slices = [slice(0, 3), slice(3, 6), slice(6, 9), slice(9, 12), slice(15, 18)]\n    expected = [slice(0, 12), slice(15, 18)]\n    assert _consolidate_slices(slices) == expected\n\n    slices = [slice(0, 3), slice(3, 6), slice(6, 9), slice(9, 12), slice(12, 15), slice(15, 18)]\n    expected = [slice(0, 18)]\n    assert _cons"], "sample_96": ["    def test_raw_id_fields_item(self):\n        class MyModelAdmin(ModelAdmin):\n            raw_id_fields = ('nonexistent_field',)\n\n        self.assertIsInvalid(MyModelAdmin, ValidationTestModel, \"The value of 'raw_id_fields[0]' refers to 'nonexistent_field', which is not a field on ValidationTestModel.\", id='admin.E002')\n"], "sample_446": ["def test_floatformat_with_decimal_places(self):\n    with translation.override('en'):\n        with localcontext() as ctx:\n            ctx.prec = 10\n            a = Decimal('34.23234')\n            b = Decimal('34.00000')\n            c = Decimal('34.26000')\n            self.assertEqual(\n                floatformat(a, -1),\n                mark_safe('34.2')\n            )\n            self.assertEqual(\n                floatformat(b, -1),\n                mark_safe('34')\n            )\n            self.assertEqual(\n                floatformat(c, -1),\n                mark_safe('34.3')\n            )\n            self.assertEqual(\n                floatformat(a, 3),\n                mark_safe('34.232')\n            )\n            self.assertEqual(\n                floatformat(b, 3),\n                mark_safe('34.000')\n            )\n            self.assertEqual(\n                floatformat(c, 3),\n                mark_safe('34.260')\n            )\n            self.assertEqual(\n                floatformat(a, '-3'),\n                mark_safe('34.232')\n            )\n            self.assertEqual(\n                floatformat(b, '-3'),\n                mark_safe('34')\n            )\n            self.assertEqual(\n                floatformat(c, '-3'),\n                mark_safe('34.260')\n            )\n"], "sample_177": ["def test_project_state_clone(self):\n    # Create a ProjectState\n    project_state = ProjectState()\n    project_state.add_model(ModelState.from_model(Food))\n\n    # Clone the ProjectState\n    cloned_project_state = project_state.clone()\n\n    # Check that the clone is equal to the original\n    self.assertEqual(project_state, cloned_project_state)\n\n    # Check that the clone's models are equal to the original's models\n    self.assertEqual(project_state.models, cloned_project_state.models)\n\n    # Check that the clone's apps are equal to the original's apps\n    self.assertEqual(project_state.real_apps, cloned_project_state.real_apps)\n\n    # Check that the clone's is_delayed attribute is equal to the original's\n    self.assertEqual(project_state.is_delayed, cloned_project_state.is_delayed)\n\n    # Modify the clone's models and check that the original's models are not affected\n    cloned_project_state.models = {}\n    self.assertNotEqual(project_state.models, cloned_project_state.models)\n\n    # Modify the clone's apps and check that the original's apps are not affected\n    cloned_project_state.real_apps = []\n    self.assertNotEqual(project_state.real_apps, cloned_project_state.real_apps)\n\n    # Modify the clone's is_delayed attribute and check that the original's is_delayed attribute is not affected\n    cloned_project_state.is_delayed = True\n    self.assertNotEqual(project_state.is_delayed, cloned_project_state.is_delayed)\n"], "sample_646": ["def test_is_skipped(monkeypatch: MonkeyPatch) -> None:\n    class TestClass:\n            pass\n\n    obj = TestClass()\n    assert not _is_skipped(obj)\n\n    monkeypatch.setattr(obj, \"__unittest_skip__\", True)\n    assert _is_skipped(obj)\n\n    monkeypatch.setattr(obj, \"__unittest_skip__\", False)\n    assert not _is_skipped(obj)\n"], "sample_621": ["def test_indexes_equal():\n    # Test indexes_equal with different index types\n    idx1 = PandasIndex(np.array([1, 2, 3]), 'x')\n    idx2 = PandasIndex(np.array([1, 2, 3]), 'x')\n    var1 = IndexVariable('x', np.array([1, 2, 3]))\n    var2 = IndexVariable('x', np.array([1, 2, 3]))\n    assert indexes_equal(idx1, idx2, var1, var2)\n\n    idx3 = PandasMultiIndex(pd.MultiIndex.from_product([['a', 'b'], [1, 2]]), 'x')\n    idx4 = PandasMultiIndex(pd.MultiIndex.from_product([['a', 'b'], [1, 2]]), 'x')\n    var3 = IndexVariable('x', np.array([1, 2, 3, 4]))\n    var4 = IndexVariable('x', np.array([1, 2, 3, 4]))\n    assert indexes_equal(idx3, idx4, var3, var4)\n\n    # Test indexes_equal with different index values\n    idx5 = PandasIndex(np.array([1, 2, 3]), 'x')\n    idx6 = PandasIndex(np.array([1, 2, 4]), 'x')\n    var5 = IndexVariable('x', np.array([1, 2, 3]))\n    var6 = IndexVariable('x', np.array([1, 2, 4]))\n    assert not indexes_equal(idx5, idx6, var5, var6)\n\n    # Test indexes_equal with different variable values\n    idx7 = PandasIndex(np.array([1, 2, 3]), 'x')\n    idx8 = PandasIndex(np.array([1, 2, 3]), 'x')\n    var7 = IndexVariable('x', np.array([1, 2, 3]))\n    var8 = IndexVariable('x', np.array([1, 2, 4]))\n    assert not indexes_equal(idx7, idx8, var7, var8)\n\n    # Test indexes_equal with cache\n    cache = {}\n    idx9 = PandasIndex(np.array([1, 2, 3]), 'x')\n    idx10 = PandasIndex(np.array([1, 2, 3]), 'x')\n    var"], "sample_784": ["def test_calibrated_classifier_cv():\n    # Test CalibratedClassifierCV with a classifier that has a decision_function\n    X, y = make_classification(n_samples=100, n_features=4, n_informative=3,\n                               n_redundant=0, n_classes=3, random_state=42)\n    clf = LinearSVC(random_state=42)\n    calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='sigmoid')\n    calibrated_clf.fit(X, y)\n    y_pred = calibrated_clf.predict(X)\n    assert_array_equal(y_pred, clf.fit(X, y).predict(X))\n\n    # Test CalibratedClassifierCV with a classifier that has a predict_proba\n    X, y = make_classification(n_samples=100, n_features=4, n_informative=3,\n                               n_redundant=0, n_classes=3, random_state=42)\n    clf = MultinomialNB()\n    calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='sigmoid')\n    calibrated_clf.fit(X, y)\n    y_pred = calibrated_clf.predict(X)\n    assert_array_equal(y_pred, clf.fit(X, y).predict(X))\n\n    # Test CalibratedClassifierCV with a classifier that has neither\n    # decision_function nor predict_proba\n    X, y = make_classification(n_samples=100, n_features=4, n_informative=3,\n                               n_redundant=0, n_classes=3, random_state=42)\n    clf = RandomForestRegressor(random_state=42)\n    calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='sigmoid')\n    assert_raises(RuntimeError, calibrated_clf.fit, X, y)\n\n    # Test CalibratedClassifierCV with a pipeline\n    X, y = make_classification(n_samples=100, n_features=4, n_informative=3,\n                               n_redundant=0, n_classes=3, random_state=42)\n    clf = Pipeline([('imputer', SimpleImputer()), ('clf', LinearSVC())])\n    calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='sigmoid')\n    calibrated_clf.fit(X, y)\n    y_pred = calibrated_clf.predict(X)\n    assert_array_equal(y_pred, clf.fit(X, y).predict(X))\n\n    # Test CalibratedClassifierCV with a sparse matrix\n    X, y"], "sample_111": ["    def test_get_ordering_field(self):\n        request = self._mocked_authenticated_request(reverse('admin:auth_user_changelist'), self.superuser)\n        cl = ChangeList(request, User, ['username'], ['username'], [], None, [], True, 100, 200, [], BandAdmin, True)\n        self.assertEqual(cl.get_ordering_field('username'), 'username')\n        self.assertIsNone(cl.get_ordering_field('nonexistent_field'))\n\n        # Test with a method that has an admin_order_field attribute\n        class TestAdmin(admin.ModelAdmin):\n                return obj.username\n            test_method.admin_order_field = 'username'\n        cl = ChangeList(request, User, ['test_method'], ['test_method'], [], None, [], True, 100, 200, [], TestAdmin, True)\n        self.assertEqual(cl.get_ordering_field('test_method'), 'username')\n\n        # Test with a property that has an admin_order_field attribute\n        class TestModel(models.Model):\n            @property\n                return self.username\n            test_property.fget.admin_order_field = 'username'\n        cl = ChangeList(request, TestModel, ['test_property'], ['test_property'], [], None, [], True, 100, 200, [], TestAdmin, True)\n        self.assertEqual(cl.get_ordering_field('test_property'), 'username')\n"], "sample_116": ["    def test_make_template_fragment_key(self):\n        fragment_name = 'test_fragment'\n        vary_on = ['arg1', 'arg2']\n        key = make_template_fragment_key(fragment_name, vary_on)\n        self.assertRegex(key, r'^template\\.cache\\.test_fragment\\.[0-9a-f]{32}$')\n"], "sample_635": ["def test_docstringify():\n    docstring = \"This is a docstring.\"\n    assert isinstance(docstringify(docstring), Docstring)\n\n    docstring = \"\"\"\n    This is a Sphinx docstring.\n\n    :param param: This is a parameter.\n    :type param: int\n    :return: This is a return value.\n    :rtype: str\n    \"\"\"\n    assert isinstance(docstringify(docstring), SphinxDocstring)\n\n    docstring = \"\"\"\n    This is an Epytext docstring.\n\n    @param param: This is a parameter.\n    @type param: int\n    @return: This is a return value.\n    @rtype: str\n    \"\"\"\n    assert isinstance(docstringify(docstring), EpytextDocstring)\n\n    docstring = \"\"\"\n    This is a Google docstring.\n\n    Args:\n        param: This is a parameter.\n    Returns:\n        This is a return value.\n    \"\"\"\n    assert isinstance(docstringify(docstring), GoogleDocstring)\n\n    docstring = \"\"\"\n    This is a Numpy docstring.\n\n    Parameters\n    ----------\n    param : int\n        This is a parameter.\n\n    Returns\n    -------\n    str\n        This is a return value.\n    \"\"\"\n    assert isinstance(docstringify(docstring), NumpyDocstring)\n"], "sample_996": ["def test_product():\n    assert product(k, (k, 1, n)).doit() == factorial(n)\n    assert product(k**2, (k, 1, n)).doit() == factorial(n)**2\n    assert product(2, (k, 1, n)).doit() == 2**n\n    assert product(2, (k, n, 1)).doit() == 2**(1-n)\n    assert product(1, (k, 1, n)).doit() == 1\n    assert product(1, (k, n, 1)).doit() == 1\n    assert product(k, (k, n, n)).doit() == n\n    assert product(k, (k, n+1, n)).doit() == 1\n    assert product(k, (k, n, n-1)).doit() == 1/n\n    assert product(k, (k, 1, 0)).doit() == 1\n    assert product(k, (k, 0, 0)).doit() == 1\n    assert product(k, (k, 0, -1)).doit() == 1\n    assert product(k, (k, 1, -1)).doit() == 1\n    assert product(k, (k, 2, 1)).doit() == 1\n    assert product(k, (k, 1, 1)).doit() == 1\n    assert product(k, (k, 0, 1)).doit() == 0\n    assert product(k, (k, -1, 0)).doit() == 0\n    assert product(1/k, (k, 1, n)).doit() == 1/factorial(n)\n    assert product(1/k, (k, n, 1)).doit() == factorial(n-1)\n    assert product(1/k, (k, 1, 0)).doit() == 1\n    assert product(1/k, (k, 0, 0)).doit() == 1\n    assert product(1/k, (k, 0, -1)).doit() == 1\n    assert product(1/k, (k, 1, -1)).doit() == 1\n   "], "sample_770": ["def test_silhouette_score_sparse():\n    # Test silhouette score with sparse matrices\n    iris = datasets.load_iris()\n    X = iris.data\n    labels = iris.target\n    X_sparse = sp.csr_matrix(X)\n    score_dense = silhouette_score(X, labels)\n    score_sparse = silhouette_score(X_sparse, labels)\n    assert_array_equal(score_dense, score_sparse)\n"], "sample_388": ["    def test_unknown_user(self):\n        \"\"\"\n        Test that an unknown user is created when create_unknown_user is True.\n        \"\"\"\n        backend = RemoteUserBackend()\n        backend.create_unknown_user = True\n        user = backend.authenticate(None, self.known_user)\n        self.assertIsNotNone(user)\n        self.assertEqual(user.username, self.known_user)\n"], "sample_1084": ["def test_intersection_sets():\n    # Test intersection of ConditionSet with Set\n    x = symbols('x')\n    cond_set = ConditionSet(x, Eq(x**2, 1), S.Reals)\n    interval = Interval(-1, 1)\n    assert intersection_sets(cond_set, interval) == ConditionSet(x, Eq(x**2, 1), Interval(-1, 1))\n\n    # Test intersection of Naturals with Integers\n    assert intersection_sets(S.Naturals, S.Integers) == S.Naturals\n\n    # Test intersection of Naturals with Naturals\n    assert intersection_sets(S.Naturals, S.Naturals) == S.Naturals\n\n    # Test intersection of Interval with Naturals\n    interval = Interval(1, 10)\n    assert intersection_sets(interval, S.Naturals) == Range(1, 11)\n\n    # Test intersection of ComplexRegion with Set\n    region = ComplexRegion(Interval(1, 2)*Interval(0, pi))\n    interval = Interval(1, 3)\n    assert intersection_sets(region, interval) == ComplexRegion(Interval(1, 2)*Interval(0, pi))\n\n    # Test intersection of Integers with Reals\n    assert intersection_sets(S.Integers, S.Reals) == S.Integers\n\n    # Test intersection of Range with Interval\n    range_set = Range(1, 10)\n    interval = Interval(2, 9)\n    assert intersection_sets(range_set, interval) == Range(2, 10)\n\n    # Test intersection of Range with Naturals\n    range_set = Range(1, 10)\n    assert intersection_sets(range_set, S.Naturals) == Range(1, 10)\n\n    # Test intersection of Range with Range\n    range_set1 = Range(1, 10)\n    range_set2 = Range(5, 15)\n    assert intersection_sets(range_set1, range_set2) == Range(5, 10)\n\n    # Test intersection of Range with Integers\n    range_set = Range(1, 10)\n    assert intersection_sets(range_set, S.Integers) == Range(1, 10)\n\n    # Test intersection of ImageSet with Set\n    lamda = Lambda(x, x**2)\n    image_set = ImageSet(lamda, S.Integers)\n    interval = Interval(1, 10)\n    assert intersection_sets(image_set, interval) =="], "sample_755": ["def test_silhouette_score_precomputed():\n    # Test silhouette score with precomputed distance matrix\n    iris = datasets.load_iris()\n    X = iris.data\n    labels = iris.target\n    distance_matrix = pairwise_distances(X, metric='euclidean')\n    score = silhouette_score(distance_matrix, labels, metric='precomputed')\n    assert score >= -1 and score <= 1\n"], "sample_288": ["def test_jsonfield_encoder_decoder(self):\n    encoder = mock.Mock()\n    decoder = mock.Mock()\n    field = JSONField(encoder=encoder, decoder=decoder)\n\n    # Test encoder\n    value = {'key': 'value'}\n    encoded_value = field.get_prep_value(value)\n    encoder.assert_called_once_with(value)\n    self.assertEqual(encoded_value, encoder.return_value)\n\n    # Test decoder\n    db_value = '{\"key\": \"value\"}'\n    decoded_value = field.from_db_value(db_value, None, connection)\n    decoder.assert_called_once_with(db_value)\n    self.assertEqual(decoded_value, decoder.return_value)\n\n    # Test validation\n    invalid_value = 'not a json'\n    with self.assertRaises(ValidationError):\n        field.validate(invalid_value, None)\n    encoder.assert_called_once_with(invalid_value)\n\n    # Test formfield\n    formfield = field.formfield()\n    self.assertIsInstance(formfield, forms.JSONField)\n    self.assertEqual(formfield.encoder, encoder)\n    self.assertEqual(formfield.decoder, decoder)\n"], "sample_82": ["def test_select_date_widget_rendering(self):\n    widget = self.widget\n    date = date(2009, 9, 1)\n    html = widget.render('date', date)\n    self.assertHTML(\n        html,\n        \"\"\"\n        <select id=\"id_date_year\" name=\"date_year\">\n            <option value=\"2007\">2007</option>\n            <option value=\"2008\">2008</option>\n            <option value=\"2009\" selected>2009</option>\n            <option value=\"2010\">2010</option>\n            <option value=\"2011\">2011</option>\n            <option value=\"2012\">2012</option>\n            <option value=\"2013\">2013</option>\n            <option value=\"2014\">2014</option>\n            <option value=\"2015\">2015</option>\n            <option value=\"2016\">2016</option>\n        </select>\n        <select id=\"id_date_month\" name=\"date_month\">\n            <option value=\"1\">January</option>\n            <option value=\"2\">February</option>\n            <option value=\"3\">March</option>\n            <option value=\"4\">April</option>\n            <option value=\"5\">May</option>\n            <option value=\"6\">June</option>\n            <option value=\"7\">July</option>\n            <option value=\"8\">August</option>\n            <option value=\"9\" selected>September</option>\n            <option value=\"10\">October</option>\n            <option value=\"11\">November</option>\n            <option value=\"12\">December</option>\n        </select>\n        <select id=\"id_date_day\" name=\"date_day\">\n            <option value=\"1\">1</option>\n            <option value=\"2\">2</option>\n            <option value=\"3\">3</option>\n            <option value=\"4\">4</option>\n            <option value=\"5\">5</option>\n            <option value=\"6\">6</option>\n            <option value=\"7\">7</option>\n            <option value=\"8\">8</option>\n            <option value=\"9\">9</option>\n            <option value=\"10\">10</option>\n            <option value=\"11\">11</option>\n            <option value=\"12\">12</option>\n            <option value=\"13\">13</option>\n           "], "sample_1207": ["def test_parse_expr():\n    # Test that parse_expr can handle repeated decimals\n    assert parse_expr('.3', transformations=T[3, 11]) == Rational(3, 10)\n    assert parse_expr('.3[1]', transformations=T[3, 11]) == Rational(3, 10) + Rational(1, 90)\n    assert parse_expr('.3[12]', transformations=T[3, 11]) == Rational(3, 10) + Rational(12, 990)\n    assert parse_expr('.3[123]', transformations=T[3, 11]) == Rational(3, 10) + Rational(123, 9990)\n    assert parse_expr('.3[1234]', transformations=T[3, 11]) == Rational(3, 10) + Rational(1234, 99990)\n    assert parse_expr('.3[12345]', transformations=T[3, 11]) == Rational(3, 10) + Rational(12345, 999990)\n    assert parse_expr('.3[123456]', transformations=T[3, 11]) == Rational(3, 10) + Rational(123456, 9999990)\n    assert parse_expr('.3[1234567]', transformations=T[3, 11]) == Rational(3, 10) + Rational(1234567, 99999990)\n    assert parse_expr('.3[12345678]', transformations=T[3, 11]) == Rational(3, 10) + Rational(12345678, 999999990)\n    assert parse_expr('.3[123456789]', transformations=T[3, 11]) == Rational(3, 10) + Rational(123456789, 9999999990)\n\n    # Test that parse_expr can handle repeated decimals with multiple digits\n    assert parse_expr('.34[12]', transformations=T[3, 11]) == Rational(34, 100) + Rational(12, 9900)\n    assert parse_expr('.345[123]', transformations=T[3, 11]) == Rational(345, 1000) + Rational(123, 99900)\n    assert parse_expr('.3456[1234]', transformations=T[3, 11]) == Rational(3456, 10000) + Rational(1234, 999900)\n    assert parse_expr('.34567[12345]', transformations=T[3, 11]) == Rational"], "sample_1109": ["def test_frac():\n    assert frac(17) == 0\n    assert frac(Rational(23, 10)) == Rational(3, 10)\n    assert frac(2*E) == 2*E - 5\n    assert frac(-Float(0.567)) == Float(0.433)\n    assert frac(-I/2) == -I/2\n    assert frac(S(5)/2 + 5*I/2) == S(1)/2 + S(1)/2*I\n    assert frac(nan) == nan\n    assert frac(oo) == AccumBounds(0, 1)\n    assert frac(-oo) == AccumBounds(0, 1)\n    assert frac(zoo) == nan\n    assert frac(x) == frac(x)\n    assert frac(i) == frac(i)\n    assert frac(y) == frac(y)\n    assert frac(k) == 0\n    assert frac(n) == 0\n    assert frac(sin(x)) == frac(sin(x))\n    assert frac(exp(x)) == frac(exp(x))\n    assert frac(log(x)) == frac(log(x))\n    assert frac(factorial(x)) == frac(factorial(x))\n    assert frac(sqrt(x)) == frac(sqrt(x))\n"], "sample_1027": ["def test_to_rational_coeffs():\n    assert to_rational_coeffs(Poly(((x**2-1)*(x-2)).subs({x:x*(1 + sqrt(2))}, domain='EX')))[0:3] == (7 + 5*sqrt(2), -2*sqrt(2) + 2, None)\n    assert to_rational_coeffs(Poly(((x**2-1)*(x-2)).subs({x:x + sqrt(2)}, domain='EX')))[0:3] == (None, None, sqrt(2))\n    assert to_rational_coeffs(Poly(x**2 + 2*x + 1, domain='EX')) is None\n    assert to_rational_coeffs(Poly(x**2 + 2*x + 1, domain='QQ')) is None\n    assert to_rational_coeffs(Poly(x**2 + 2*x + 1, domain='ZZ')) is None\n"], "sample_216": ["def test_field_references_with_recursive_relationship(self):\n    model_tuple = (\"testapp\", \"Author\")\n    field = models.ForeignKey(\"self\", models.CASCADE)\n    reference_model_tuple = (\"testapp\", \"Author\")\n    reference_field_name = \"id\"\n    reference_field = models.AutoField(primary_key=True)\n\n    result = field_references(model_tuple, field, reference_model_tuple, reference_field_name, reference_field)\n    self.assertIsInstance(result, FieldReference)\n    self.assertEqual(result.to, (field, None))\n    self.assertIsNone(result.through)\n"], "sample_264": ["def test_legacy_decode(self):\n    storage = self.storage_class(self.request, self.response)\n    with ignore_warnings(category=RemovedInDjango40Warning):\n        data = 'hash$value'\n        self.assertIsNone(storage._legacy_decode(data))\n        data = 'hash$' + get_random_string(100)\n        self.assertIsNone(storage._legacy_decode(data))\n        data = storage._legacy_hash('value') + '$value'\n        self.assertEqual(storage._legacy_decode(data), 'value')\n"], "sample_114": ["def test_altered_unique_together(self):\n    # Create initial state\n    before_state = self.make_project_state([\n        self.book_foo_together,\n    ])\n\n    # Create final state\n    after_state = self.make_project_state([\n        self.book_foo_together_2,\n    ])\n\n    # Get changes\n    changes = MigrationAutodetector(before_state, after_state)._detect_changes()\n\n    # Check changes\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\"])\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 0, unique_together={(\"title\", \"author\")})\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 1, index_together={(\"title\", \"author\")})\n"], "sample_622": ["    def test_decode_cf(self):\n        # Create a test dataset\n        time = pd.date_range(\"2000-01-01\", periods=3)\n        ds = Dataset(\n            {\"foo\": (\"time\", [1, 2, 3], {\"units\": \"hours since 2000-01-01\"})},\n            coords={\"time\": time},\n        )\n\n        # Save the dataset to a netCDF file\n        with self.temp_file(\".nc\") as tmp_file:\n            ds.to_netcdf(tmp_file)\n\n            # Load the dataset from the netCDF file\n            with open_dataset(tmp_file) as ds_loaded:\n                # Decode the dataset\n                decoded_ds = decode_cf(ds_loaded)\n\n                # Check that the decoded dataset is identical to the original\n                assert_identical(decoded_ds, ds)\n"], "sample_1132": ["def test_multiset_partitions():\n    # Test multiset_partitions with an integer\n    assert list(multiset_partitions(5)) == [[[0, 1, 2, 3, 4]], [[0, 1, 2, 3], [4]], [[0, 1, 2], [3, 4]], [[0, 1, 2], [3], [4]], [[0, 1], [2, 3, 4]], [[0, 1], [2, 3], [4]], [[0, 1], [2], [3, 4]], [[0, 1], [2], [3], [4]], [[0], [1, 2, 3, 4]], [[0], [1, 2, 3], [4]], [[0], [1, 2], [3, 4]], [[0], [1, 2], [3], [4]], [[0], [1], [2, 3, 4]], [[0], [1], [2, 3], [4]], [[0], [1], [2], [3, 4]], [[0], [1], [2], [3], [4]], [[0], [1, 2], [2, 3], [4]], [[0], [1, 3], [2, 3], [4]], [[0], [1, 2], [2, 4], [3]], [[0], [1, 3], [2, 4], [3]], [[0], [1, 2], [2, 3], [3, 4]], [[0], [1, 3], [2, 3], [3, 4]], [[0], [1, 2], [2, 4], [3, 4]], [[0], [1, 3], [2, 4], [3, 4]], [[0], [1, 2], [2, 3], [3, 4], [4]], [[0], [1, 3], [2, 3], [3, 4], [4]], [[0], [1, 2], [2, 4], [3, 4], [4]], [[0], [1, 3], [2, 4"], "sample_530": ["def test_offsetbox_text_area():\n    fig, ax = plt.subplots()\n    area = TextArea(\"Hello World\")\n    area.set_offset((0.5, 0.5))\n    ab = AnchoredOffsetbox(ax.transData, loc='center', child=area)\n    ax.add_artist(ab)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n"], "sample_270": ["    def test_check_default_pk(self):\n        class AutoModel(models.Model):\n            pass\n\n        class BigAutoModel(models.Model):\n            id = models.BigAutoField(primary_key=True)\n\n        class CustomAutoModel(models.Model):\n            id = models.AutoField(primary_key=True)\n\n        class NonAutoModel(models.Model):\n            id = models.IntegerField(primary_key=True)\n\n        self.assertEqual(AutoModel.check(), [\n            checks.Warning(\n                \"Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'.\",\n                hint=(\n                    \"Configure the DEFAULT_AUTO_FIELD setting or the \"\n                    \"invalid_models_tests.models.AutoModel.default_auto_field attribute to point to a subclass \"\n                    \"of AutoField, e.g. 'django.db.models.BigAutoField'.\"\n                ),\n                obj=AutoModel,\n                id='models.W042',\n            ),\n        ])\n        self.assertEqual(BigAutoModel.check(), [])\n        self.assertEqual(CustomAutoModel.check(), [])\n        self.assertEqual(NonAutoModel.check(), [])\n"], "sample_100": ["    def test_tick(self):\n        reloader = autoreload.StatReloader()\n        ticker = reloader.tick()\n        next(ticker)\n        self.assertTrue(reloader.should_stop)\n"], "sample_650": ["def test_logcapture_fixture(caplog, pytestconfig):\n    \"\"\"Test the LogCaptureFixture class.\"\"\"\n    caplog.set_level(logging.INFO)\n    logging.info(\"info message\")\n    logging.warning(\"warning message\")\n    logging.error(\"error message\")\n    assert len(caplog.records) == 3\n    assert caplog.record_tuples == [\n        (\"root\", logging.INFO, \"info message\"),\n        (\"root\", logging.WARNING, \"warning message\"),\n        (\"root\", logging.ERROR, \"error message\"),\n    ]\n    assert caplog.messages == [\"info message\", \"warning message\", \"error message\"]\n    assert caplog.text == (\n        \"INFO     root:info message\\n\"\n        \"WARNING  root:warning message\\n\"\n        \"ERROR    root:error message\\n\"\n    )\n\n    caplog.clear()\n    assert len(caplog.records) == 0\n    assert caplog.record_tuples == []\n    assert caplog.messages == []\n    assert caplog.text == \"\"\n\n    caplog.set_level(logging.WARNING)\n    logging.info(\"info message\")\n    logging.warning(\"warning message\")\n    logging.error(\"error message\")\n    assert len(caplog.records) == 2\n    assert caplog.record_tuples == [\n        (\"root\", logging.WARNING, \"warning message\"),\n        (\"root\", logging.ERROR, \"error message\"),\n    ]\n    assert caplog.messages == [\"warning message\", \"error message\"]\n    assert caplog.text == (\n        \"WARNING  root:warning message\\n\"\n        \"ERROR    root:error message\\n\"\n    )\n\n    caplog.set_level(logging.ERROR)\n    logging.info(\"info message\")\n    logging.warning(\"warning message\")\n    logging.error(\"error message\")\n    assert len(caplog.records) == 1\n    assert caplog.record_tuples == [(\"root\", logging.ERROR, \"error message\")]\n    assert caplog.messages == [\"error message\"]\n    assert caplog.text == \"ERROR    root:error message\\n\"\n\n    caplog.set_level(logging.CRITICAL)\n    logging.info(\"info message\")\n    logging.warning(\"warning message\")\n    logging.error(\"error message\")\n    assert len(caplog.records) == 0\n    assert caplog.record_tuples == []\n    assert caplog.messages == []\n    assert caplog.text == \"\"\n\n    caplog.set_level(logging.DEBUG)\n    logging.info(\"info message\")\n    logging.warning(\"warning message\")\n    logging.error(\"error message\")\n    assert len(caplog.records) == 3\n    assert caplog.record_tuples == [\n        (\"root\", logging.INFO"], "sample_1015": ["def test_c99_code_printer():\n    printer = C99CodePrinter()\n    assert printer._print_Infinity(S.Infinity) == 'INFINITY'\n    assert printer._print_NegativeInfinity(S.NegativeInfinity) == '-INFINITY'\n    assert printer._print_NaN(S.NaN) == 'NAN'\n    assert printer._print_Max(Max(x, y)) == 'fmax(x, y)'\n    assert printer._print_Min(Min(x, y)) == 'fmin(x, y)'\n    assert printer._print_exp(exp(x)) == 'exp(x)'\n    assert printer._print_exp2(exp2(x)) == 'exp2(x)'\n    assert printer._print_expm1(expm1(x)) == 'expm1(x)'\n    assert printer._print_log(log(x)) == 'log(x)'\n    assert printer._print_log10(log10(x)) == 'log10(x)'\n    assert printer._print_log2(log2(x)) == 'log2(x)'\n    assert printer._print_log1p(log1p(x)) == 'log1p(x)'\n    assert printer._print_sqrt(sqrt(x)) == 'sqrt(x)'\n    assert printer._print_Cbrt(Cbrt(x)) == 'cbrt(x)'\n    assert printer._print_hypot(hypot(x, y)) == 'hypot(x, y)'\n    assert printer._print_fma(fma(x, y, z)) == 'fma(x, y, z)'\n    assert printer._print_loggamma(loggamma(x)) == 'lgamma(x)'\n    assert printer._print_gamma(gamma(x)) == 'tgamma(x)'\n    assert printer._print_erf(erf(x)) == 'erf(x)'\n    assert printer._print_erfc(erfc(x)) == 'erfc(x)'\n    assert printer._print_ceiling(ceiling(x)) == 'ceil(x)'\n    assert printer._print_floor(floor(x)) == 'floor(x)'\n"], "sample_406": ["    def test_manager_creation_counter(self):\n        manager1 = BaseManager()\n        manager2 = BaseManager()\n        self.assertEqual(manager1.creation_counter, 0)\n        self.assertEqual(manager2.creation_counter, 1)\n"], "sample_135": ["    def test_format_date(self):\n        d = date(2003, 10, 7)\n        self.assertEqual(dateformat.format(d, 'jS F Y'), '7th October 2003')\n        self.assertEqual(dateformat.format(d, 'l, F jS, Y'), 'Tuesday, October 7th, 2003')\n        self.assertEqual(dateformat.format(d, 'l, jS F Y'), 'Tuesday, 7th October 2003')\n        self.assertEqual(dateformat.format(d, 'l, j F Y'), 'Tuesday, 7 October 2003')\n        self.assertEqual(dateformat.format(d, 'l, jS F'), 'Tuesday, 7th October')\n        self.assertEqual(dateformat.format(d, 'l, j F'), 'Tuesday, 7 October')\n        self.assertEqual(dateformat.format(d, 'l, F jS'), 'Tuesday, October 7th')\n        self.assertEqual(dateformat.format(d, 'l, F j'), 'Tuesday, October 7')\n        self.assertEqual(dateformat.format(d, 'l, jS'), 'Tuesday, 7th')\n        self.assertEqual(dateformat.format(d, 'l, j'), 'Tuesday, 7')\n        self.assertEqual(dateformat.format(d, 'l'), 'Tuesday')\n        self.assertEqual(dateformat.format(d, 'F jS, Y'), 'October 7th, 2003')\n        self.assertEqual(dateformat.format(d, 'F j, Y'), 'October 7, 2003')\n        self.assertEqual(dateformat.format(d, 'F jS'), 'October 7th')\n        self.assertEqual(dateformat.format(d, 'F j'), 'October 7')\n        self.assertEqual(dateformat.format(d, 'jS F Y'), '7th October 2003')\n        self.assertEqual(dateformat.format(d, 'j F Y'), '7 October 2003')\n        self.assertEqual(dateformat.format(d, 'jS F'), '7th October')\n        self.assertEqual(dateformat.format(d, 'j F'), '7 October')\n        self.assertEqual(dateformat.format(d, 'F Y'), 'October 2003')\n        self.assertEqual(dateformat.format(d, 'F'), 'October')\n        self.assertEqual(dateformat.format(d, 'jS'), '7th')\n        self.assertEqual(dateformat.format(d, 'j'), '7')\n        self.assertEqual(dateformat.format(d, 'Y'), '2003')\n"], "sample_535": ["def test_auto_set_column_width():\n    fig, ax = plt.subplots()\n    data = [['A', 'B', 'C'], [1, 2, 3], [4, 5, 6]]\n    table = ax.table(cellText=data, loc='center')\n    table.auto_set_column_width(0)\n    ax.axis('off')\n    return fig\n"], "sample_11": ["def test_sliced_low_level_wcs():\n    # Test that the SlicedLowLevelWCS class correctly slices the WCS\n    wcs = WCS_SPECTRAL_CUBE\n    sliced_wcs = SlicedLowLevelWCS(wcs, (slice(1, 5), slice(2, 4), 3))\n\n    assert sliced_wcs.pixel_n_dim == 2\n    assert sliced_wcs.world_n_dim == 2\n    assert sliced_wcs.world_axis_names == ['Latitude', 'Longitude']\n    assert sliced_wcs.world_axis_physical_types == ['pos.eq.dec', 'pos.eq.ra']\n    assert sliced_wcs.world_axis_units == ['deg', 'deg']\n    assert sliced_wcs.pixel_axis_names == ['x', 'y']\n    assert sliced_wcs.pixel_bounds == ((1, 5), (2, 4))\n\n    # Test that the pixel_to_world_values method works correctly\n    pixel_coords = [np.array([1, 2, 3, 4]), np.array([2, 3, 4, 5])]\n    world_coords = sliced_wcs.pixel_to_world_values(*pixel_coords)\n    assert len(world_coords) == 2\n    assert world_coords[0].shape == (4,)\n    assert world_coords[1].shape == (4,)\n\n    # Test that the world_to_pixel_values method works correctly\n    world_coords = [np.array([10.1, 10.2, 10.3, 10.4]), np.array([25.1, 25.2, 25.3, 25.4])]\n    pixel_coords = sliced_wcs.world_to_pixel_values(*world_coords)\n    assert len(pixel_coords) == 2\n    assert pixel_coords[0].shape == (4,)\n    assert pixel_coords[1].shape == (4,)\n\n    # Test that the dropped_world_dimensions property works correctly\n    dropped_info = sliced_wcs.dropped_world_dimensions\n    assert dropped_info['value'] == [20]\n    assert dropped_info['world_axis_names'] == ['Frequency']\n    assert dropped_info['world_axis_physical_types'] == ['em.freq']\n    assert dropped_info['world_axis_units'] == ['Hz']\n    assert dropped_info['world_axis_object_components'] == [('em.freq.freq',)]\n    assert dropped_info['world_axis_object_classes'] == {'em.freq': 'SpectralCoord'}\n\n    # Test that the world_axis_object_components and world_axis"], "sample_602": ["def test_open_dataset_with_invalid_netcdf():\n    # Create a test dataset with a numpy.bool_ attribute\n    ds = xr.Dataset()\n    ds.attrs[\"bool_attr\"] = np.bool_(True)\n\n    # Try to open the dataset with the h5netcdf engine and invalid_netcdf=True\n    with xr.open_dataset(ds, engine=\"h5netcdf\", invalid_netcdf=True) as ds:\n        assert ds.attrs[\"bool_attr\"] == np.bool_(True)\n\n    # Try to open the dataset with the h5netcdf engine and invalid_netcdf=False\n    with xr.open_dataset(ds, engine=\"h5netcdf\", invalid_netcdf=False) as ds:\n        assert ds.attrs[\"bool_attr\"] == np.bool_(True)\n\n    # Try to open the dataset with the netcdf4 engine and invalid_netcdf=True\n    with xr.open_dataset(ds, engine=\"netcdf4\", invalid_netcdf=True) as ds:\n        assert ds.attrs[\"bool_attr\"] == np.bool_(True)\n\n    # Try to open the dataset with the netcdf4 engine and invalid_netcdf=False\n    with xr.open_dataset(ds, engine=\"netcdf4\", invalid_netcdf=False) as ds:\n        assert ds.attrs[\"bool_attr\"] == np.bool_(True)\n"], "sample_1066": ["def test_mathml_content_printer():\n    # Test printing of various mathematical expressions in Content MathML\n    assert mp.doprint(sin(x)) == '<apply><sin/><ci>x</ci></apply>'\n    assert mp.doprint(cos(x)) == '<apply><cos/><ci>x</ci></apply>'\n    assert mp.doprint(tan(x)) == '<apply><tan/><ci>x</ci></apply>'\n    assert mp.doprint(asin(x)) == '<apply><arcsin/><ci>x</ci></apply>'\n    assert mp.doprint(acos(x)) == '<apply><arccos/><ci>x</ci></apply>'\n    assert mp.doprint(atan(x)) == '<apply><arctan/><ci>x</ci></apply>'\n    assert mp.doprint(sinh(x)) == '<apply><sinh/><ci>x</ci></apply>'\n    assert mp.doprint(cosh(x)) == '<apply><cosh/><ci>x</ci></apply>'\n    assert mp.doprint(tanh(x)) == '<apply><tanh/><ci>x</ci></apply>'\n    assert mp.doprint(asinh(x)) == '<apply><arcsinh/><ci>x</ci></apply>'\n    assert mp.doprint(acosh(x)) == '<apply><arccosh/><ci>x</ci></apply>'\n    assert mp.doprint(atanh(x)) == '<apply><arctanh/><ci>x</ci></apply>'\n    assert mp.doprint(cot(x)) == '<apply><cot/><ci>x</ci></apply>'\n    assert mp.doprint(coth(x)) == '<apply><coth/><ci>x</ci></apply>'\n    assert mp.doprint(acot(x)) == '<apply><arccot/><ci>x</ci></apply>'\n    assert mp.doprint(acoth(x)) == '<apply><arccoth/><ci>x</ci></apply>'\n    assert mp.doprint(csc(x)) == '<apply><csc/><ci>x</ci></apply>'\n    assert mp.doprint(acsc(x)) == '<apply><arccsc/><ci>x</ci></apply>'\n    assert mp.doprint(csch(x)) == '<apply><csch/><ci>x</ci></apply>'\n    assert mp.doprint(acsch(x)) == '<apply><arccsch/><ci>x</ci></apply>'\n    assert mp"], "sample_12": ["def test_longitude_wrap_angle():\n    lon = Longitude([10, 20, 30] * u.deg, wrap_angle=180 * u.deg)\n    assert lon.wrap_angle == 180 * u.deg\n    assert_allclose(lon.value, [-170, -160, -150])\n\n    lon.wrap_angle = 0 * u.deg\n    assert lon.wrap_angle == 0 * u.deg\n    assert_allclose(lon.value, [10, 20, 30])\n\n    lon.wrap_angle = 360 * u.deg\n    assert lon.wrap_angle == 360 * u.deg\n    assert_allclose(lon.value, [10, 20, 30])\n\n    with pytest.raises(u.UnitsError):\n        lon.wrap_angle = 10 * u.m\n"], "sample_246": ["    def test_preprocess(self):\n        with tempfile.NamedTemporaryFile(suffix='.js') as tmp:\n            tmp.write(b'console.log(gettext(\"Hello, world!\"));')\n            tmp.flush()\n            build_file = self.MakeMessagesCommand.build_file_class(self.MakeMessagesCommand, 'djangojs', self.MakeMessagesCommand.translatable_file_class(tmp.name, 'test.js', '/tmp'))\n            build_file.preprocess()\n            with open(build_file.work_path, 'r') as f:\n                self.assertEqual(f.read(), 'console.log(gettext(\"Hello, world!\"));')\n"], "sample_819": ["def test_voting_regressor_weights():\n    # Test VotingRegressor with weights\n    r1 = LinearRegression()\n    r2 = RandomForestRegressor(n_estimators=10, random_state=1)\n    er = VotingRegressor([('lr', r1), ('rf', r2)], weights=[0.7, 0.3])\n    er.fit(X_r, y_r)\n    y_pred = er.predict(X_r)\n    assert_array_almost_equal(y_pred, np.average([r1.fit(X_r, y_r).predict(X_r) * 0.7,\n                                                  r2.fit(X_r, y_r).predict(X_r) * 0.3], axis=0))\n"], "sample_239": ["    def test_management_form_validation(self):\n        formset = self.make_choiceformset(\n            formset_data=[('choice1', 10), ('choice2', 20)],\n            total_forms=3,\n            initial_forms=2,\n            max_num_forms=2,\n            min_num_forms=1,\n        )\n        with self.assertRaises(ValidationError) as cm:\n            formset.management_form.is_valid()\n        self.assertEqual(cm.exception.code, 'missing_management_form')\n        self.assertEqual(\n            cm.exception.params['field_names'],\n            'choices-TOTAL_FORMS, choices-INITIAL_FORMS, choices-MIN_NUM_FORMS, choices-MAX_NUM_FORMS',\n        )\n"], "sample_904": ["def test_standard_domain_resolve_xref():\n    app = restructuredtext.sphinx_test_tempdir()\n    app.builder.name = 'html'\n    app.env.domaindata['std']['labels'] = {\n        'label1': ('doc1', 'label1-id', 'Section 1'),\n        'label2': ('doc2', 'label2-id', 'Section 2'),\n    }\n    app.env.domaindata['std']['objects'] = {\n        ('term', 'term1'): ('doc1', 'term1-id'),\n        ('token', 'token1'): ('doc2', 'token1-id'),\n    }\n    app.env.domaindata['std']['progoptions'] = {\n        ('program1', 'option1'): ('doc1', 'option1-id'),\n    }\n    app.env.domaindata['std']['anonlabels'] = {\n        'anonlabel1': ('doc1', 'anonlabel1-id'),\n    }\n\n    domain = StandardDomain(app.env)\n\n    # Test ref\n    node = pending_xref('', reftype='ref', refdomain='std', reftarget='label1')\n    result = domain.resolve_xref(app.env, 'doc1', app.builder, 'ref', 'label1', node, None)\n    assert result is not None\n    assert result['refuri'] == '#label1-id'\n    assert result.astext() == 'Section 1'\n\n    # Test numref\n    node = pending_xref('', reftype='numref', refdomain='std', reftarget='label1')\n    result = domain.resolve_xref(app.env, 'doc1', app.builder, 'numref', 'label1', node, None)\n    assert result is not None\n    assert result['refuri'] == '#label1-id'\n    assert result.astext() == 'Section 1'\n\n    # Test keyword\n    node = pending_xref('', reftype='keyword', refdomain='std', reftarget='label1')\n    result = domain.resolve_xref(app.env, 'doc1', app.builder, 'keyword', 'label1', node, None)\n    assert result is not None\n    assert result['refuri'] == '#label1-id'\n    assert result.astext() == 'label1'\n\n    # Test doc\n    node = pending_xref('', reftype='doc', refdomain='std', reftarget='doc1')\n    result = domain.resolve_xref(app.env, '"], "sample_1086": ["def test_strprinter():\n    p = StrPrinter()\n    assert p._print_StrPrinter(p) == \"StrPrinter()\"\n    assert p._print_StrReprPrinter(p) == \"StrReprPrinter()\"\n    assert p._print_Dict(Dict({x: 1, y: 2})) == \"{x: 1, y: 2}\"\n    assert p._print_Tuple(Tuple(x, y, z)) == \"(x, y, z)\"\n    assert p._print_FiniteSet(FiniteSet(x, y, z)) == \"{x, y, z}\"\n    assert p._print_Complement(Complement(S.Reals, S.Integers)) == \"Reals - Integers\"\n    assert p._print_SymmetricDifference(SymmetricDifference(S.Reals, S.Integers)) == \"Reals ^ Integers\"\n    assert p._print_AccumBounds(AccumBounds(1, 2)) == \"AccumBounds(1, 2)\"\n    assert p._print_UnevaluatedExpr(UnevaluatedExpr(x + y)) == \"x + y\"\n    assert p._print_Eq(Eq(x, y)) == \"Eq(x, y)\"\n    assert p._print_Ne(Ne(x, y)) == \"Ne(x, y)\"\n    assert p._print_Quaternion(Quaternion(1, 2, 3, 4)) == \"1 + 2*i + 3*j + 4*k\"\n    assert p._print_Subs(Subs(x + y, x, 2)) == \"Subs(x + y, x, 2)\"\n    assert p._print_log(log(x)) == \"log(x)\"\n    assert p._print_Tr(Tr(Matrix([[1, 2], [3, 4]]))) == \"Tr(Matrix([[1, 2], [3, 4]]))\"\n"], "sample_46": ["    def test_uuid_exact_lookup(self):\n        obj = UUIDModel.objects.create(uuid=uuid.uuid4())\n        uuid_str = str(obj.uuid)\n        self.assertEqual(UUIDModel.objects.get(uuid=uuid_str), obj)\n"], "sample_525": ["def test_subfigure_layout_engine():\n    fig = plt.figure()\n    gs = gridspec.GridSpec(2, 2)\n    sfig1 = fig.add_subfigure(gs[0, 0])\n    sfig2 = fig.add_subfigure(gs[1, 1])\n    sfig1.set_layout_engine('constrained')\n    sfig2.set_layout_engine('tight')\n    assert isinstance(sfig1.get_layout_engine(), ConstrainedLayoutEngine)\n    assert isinstance(sfig2.get_layout_engine(), TightLayoutEngine)\n    assert isinstance(fig.get_layout_engine(), PlaceHolderLayoutEngine)\n"], "sample_537": ["    def test_stride_windows(self):\n        x = np.arange(10)\n        NFFT = 5\n        noverlap = 2\n        axis = 0\n\n        result = mlab.stride_windows(x, NFFT, noverlap, axis)\n        target = self.calc_window_target(x, NFFT, noverlap, axis)\n\n        assert_array_equal(result, target)\n\n        # Test that the returned array is a view of the original array\n        assert self.get_base(result) is x\n\n        # Test that the returned array is not writeable\n        with pytest.raises(ValueError):\n            result[0, 0] = 1\n\n        # Test that the returned array has the correct shape and dtype\n        assert result.shape == (NFFT, 6)\n        assert result.dtype == x.dtype\n\n        # Test that the function raises an error for invalid inputs\n        with pytest.raises(ValueError):\n            mlab.stride_windows(x, NFFT, noverlap, axis=1)\n\n        with pytest.raises(ValueError):\n            mlab.stride_windows(x, NFFT, noverlap=-1, axis=0)\n\n        with pytest.raises(ValueError):\n            mlab.stride_windows(x, NFFT, noverlap=NFFT+1, axis=0)\n\n        with pytest.raises(ValueError):\n            mlab.stride_windows(x, NFFT, noverlap=0, axis=2)\n"], "sample_931": ["def test_parse_annotation():\n    env = Mock(spec=['ref_context'])\n    env.ref_context = {}\n    assert _parse_annotation('int', env) == [nodes.Text('int')]\n    assert _parse_annotation('List[int]', env) == [\n        nodes.Text('List'),\n        desc_sig_punctuation('[', '['),\n        nodes.Text('int'),\n        desc_sig_punctuation(']', ']')\n    ]\n    assert _parse_annotation('List[int, str]', env) == [\n        nodes.Text('List'),\n        desc_sig_punctuation('[', '['),\n        nodes.Text('int'),\n        desc_sig_punctuation(',', ', '),\n        nodes.Text('str'),\n        desc_sig_punctuation(']', ']')\n    ]\n    assert _parse_annotation('Dict[str, int]', env) == [\n        nodes.Text('Dict'),\n        desc_sig_punctuation('[', '['),\n        nodes.Text('str'),\n        desc_sig_punctuation(',', ', '),\n        nodes.Text('int'),\n        desc_sig_punctuation(']', ']')\n    ]\n    assert _parse_annotation('Tuple[int, ...]', env) == [\n        nodes.Text('Tuple'),\n        desc_sig_punctuation('[', '['),\n        nodes.Text('int'),\n        desc_sig_punctuation(',', ', '),\n        desc_sig_punctuation('...', '...')\n        desc_sig_punctuation(']', ']')\n    ]\n    assert _parse_annotation('Union[int, str]', env) == [\n        nodes.Text('Union'),\n        desc_sig_punctuation('[', '['),\n        nodes.Text('int'),\n        desc_sig_punctuation(',', ', '),\n        nodes.Text('str'),\n        desc_sig_punctuation(']', ']')\n    ]\n    assert _parse_annotation('Optional[int]', env) == [\n        nodes.Text('Optional'),\n        desc_sig_punctuation('[', '['),\n        nodes.Text('int'),\n        desc_sig_punctuation(']', ']')\n    ]\n    assert _parse_annotation('Any', env) == [nodes.Text('Any')]\n    assert _parse_annotation('None', env) == [nodes.Text('None')]\n"], "sample_1163": ["def test_polar_lift():\n    x = Symbol('x')\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*polar_lift(x)) == 4*polar_lift(x)\n"], "sample_534": ["def test_contour_labeler_event_handler():\n    fig, ax = plt.subplots()\n    cs = ContourSet(ax, [1, 2, 3], [[[[0, 0], [1, 0], [1, 1], [0, 1]]]])\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 0.5, 0.5)\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 1\n    assert len(cs.labelCValues) == 1\n    assert len(cs.labelXYs) == 1\n\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 0.5, 0.5)\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 2\n    assert len(cs.labelCValues) == 2\n    assert len(cs.labelXYs) == 2\n\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 0.5, 0.5, button=MouseButton.RIGHT)\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 1\n    assert len(cs.labelCValues) == 1\n    assert len(cs.labelXYs) == 1\n\n    event = mpl.backend_bases.LocationEvent('key_press_event', fig.canvas, 0.5, 0.5, key='enter')\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 1\n    assert len(cs.labelCValues) == 1\n    assert len(cs.labelXYs) == 1\n\n    event = mpl.backend_bases.LocationEvent('key_press_event', fig.canvas, 0.5, 0.5, key='backspace')\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 0\n    assert len(cs.labelCValues) == 0\n    assert len(cs.labelXYs) == 0\n"], "sample_410": ["    def test_normalize_email(self):\n        manager = BaseUserManager()\n        email = \"TestEmail@EXAMPLE.com\"\n        self.assertEqual(manager.normalize_email(email), \"TestEmail@example.com\")\n"], "sample_1093": ["def test_printers():\n    expr = x + y + z\n    printers = [MpmathPrinter, NumPyPrinter, PythonCodePrinter, SciPyPrinter, SymPyPrinter]\n    for printer in printers:\n        printer().doprint(expr)\n"], "sample_209": ["    def test_model_base_subclass_exception(self):\n        class MyModel(models.Model):\n            pass\n\n        self.assertEqual(MyModel.DoesNotExist.__qualname__, 'MyModel.DoesNotExist')\n        self.assertEqual(MyModel.MultipleObjectsReturned.__qualname__, 'MyModel.MultipleObjectsReturned')\n"], "sample_145": ["    def test_raw_id_fields_item(self):\n        class MyModelAdmin(ModelAdmin):\n            raw_id_fields = ('nonexistent_field',)\n\n        self.assertIsInvalid(MyModelAdmin, ValidationTestModel, \"'nonexistent_field' is not a field on 'ValidationTestModel'.\", 'admin.E002')\n"], "sample_861": ["def test_grid_search_cv_refit_callable():\n    # Test that refit can be a callable\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5,\n                               n_redundant=3, n_classes=3, random_state=0)\n    param_grid = {'C': [0.1, 1, 10]}\n        # Select the parameter setting with the highest mean fit time\n        return np.argmax(cv_results['mean_fit_time'])\n\n    grid_search = GridSearchCV(SVC(), param_grid, refit=refit_func, cv=3)\n    grid_search.fit(X, y)\n    assert grid_search.best_index_ == np.argmax(grid_search.cv_results_['mean_fit_time'])\n    assert grid_search.best_params_ == grid_search.cv_results_['params'][grid_search.best_index_]\n    assert grid_search.best_estimator_ is not None\n    assert grid_search.best_score_ is None\n"], "sample_596": ["def test_concat_dataset_with_fill_value():\n    # Create test data\n    data = np.random.rand(2, 3)\n    ds1 = Dataset({\"foo\": ([\"x\", \"y\"], data)}, coords={\"x\": [1, 2]})\n    ds2 = Dataset({\"foo\": ([\"x\", \"y\"], data + 1)}, coords={\"x\": [3, 4]})\n\n    # Concatenate with fill value\n    result = concat([ds1, ds2], dim=\"x\", fill_value=-1)\n\n    # Check result\n    expected = Dataset(\n        {\"foo\": ([\"x\", \"y\"], np.array([data, data + 1]))},\n        coords={\"x\": [1, 2, 3, 4]},\n    )\n    assert_equal(result, expected)\n\n    # Test with fill value as a dictionary\n    result = concat([ds1, ds2], dim=\"x\", fill_value={\"foo\": -1})\n    assert_equal(result, expected)\n\n    # Test with fill value as a DataArray\n    fill_value_da = DataArray(-1, dims=[\"x\"], coords={\"x\": [1, 2, 3, 4]})\n    result = concat([ds1, ds2], dim=\"x\", fill_value=fill_value_da)\n    assert_equal(result, expected)\n"], "sample_1182": ["def test_AbstractPythonCodePrinter():\n    printer = AbstractPythonCodePrinter()\n    assert printer._print_known_func(None) is None\n    assert printer._print_known_const(None) is None\n    assert printer._format_code(None) is None\n    assert printer._get_statement(None) == \"{}\"\n    assert printer._get_comment(None) == \"  # \"\n    assert printer._expand_fold_binary_op(None, None) is None\n    assert printer._expand_reduce_binary_op(None, None) is None\n    assert printer._get_einsum_string(None, None) == (\"\", [], [])\n    assert printer._print_NaN(None) == \"float('nan')\"\n    assert printer._print_Infinity(None) == \"float('inf')\"\n    assert printer._print_NegativeInfinity(None) == \"float('-inf')\"\n    assert printer._print_ComplexInfinity(None) == \"float('nan')\"\n    assert printer._print_Mod(None) is None\n    assert printer._print_Piecewise(None) is None\n    assert printer._print_Relational(None) is None\n    assert printer._print_ITE(None) is None\n    assert printer._print_Sum(None) is None\n    assert printer._print_ImaginaryUnit(None) == \"1j\"\n    assert printer._print_KroneckerDelta(None) is None\n    assert printer._print_MatrixBase(None) is None\n    assert printer._print_FunctionDefinition(None) is None\n    assert printer._print_While(None) is None\n    assert printer._print_Declaration(None) is None\n    assert printer._print_Return(None) is None\n    assert printer._print_Print(None) is None\n    assert printer._print_Stream(None) is None\n    assert printer._print_NoneToken(None) == \"None\"\n    assert printer._hprint_Pow(None, rational=False) is None\n    assert printer._print_frac(None) is None\n    assert printer._print_Symbol(None) is None\n    assert printer._print_lowergamma(None) is None\n    assert printer._print_uppergamma(None) is None\n    assert printer._print_fresnelc(None) is None\n    assert printer._print_fresnels(None) is None\n"], "sample_1169": ["def test_substitute_dummies():\n    a, b, c, d = symbols('a b c d', above_fermi=True, cls=Dummy)\n    i, j = symbols('i j', below_fermi=True, cls=Dummy)\n    p, q = symbols('p q', cls=Dummy)\n    f = Function('f')\n    t = Function('t')\n\n    expr = f(a, b) + f(c, d)\n    assert substitute_dummies(expr) == 2*f(a, b)\n\n    expr = f(a, b, i, j) + f(c, d, i, j)\n    assert substitute_dummies(expr) == 2*f(a, b, i, j)\n\n    expr = f(a, b, i, j) + f(c, d, j, i)\n    assert substitute_dummies(expr) == 2*f(a, b, i, j)\n\n    expr = f(a, b, p, q) + f(c, d, q, p)\n    assert substitute_dummies(expr) == 2*f(a, b, p, q)\n\n    expr = f(a, b, p, q) + f(c, d, p, q)\n    assert substitute_dummies(expr) == 2*f(a, b, p, q)\n\n    expr = f(a, b, p, q) + f(c, d, p, q) + f(a, b, p, q)\n    assert substitute_dummies(expr) == 3*f(a, b, p, q)\n\n    expr = f(a, b, p, q) + f(c, d, p, q) + f(a, b, p, q) + f(c, d, p, q)\n    assert substitute_dummies(expr) == 4*f(a, b, p, q)\n\n    expr = f(a, b, p, q) + f(c, d, p, q) + f(a, b, p, q) + f(c, d, p, q) + f(a, b, p, q)\n    assert substitute_dummies(expr) == 5*f(a, b, p, q)\n\n    expr = f(a, b, p, q) + f(c, d, p, q) + f(a, b, p, q) + f(c, d, p, q) + f(a, b, p, q)"], "sample_277": ["def test_q_combine(self):\n    q1 = Q(field1='value1')\n    q2 = Q(field2='value2')\n    q3 = q1 & q2\n    self.assertEqual(q3.connector, Q.AND)\n    self.assertEqual(len(q3.children), 2)\n    self.assertEqual(q3.children[0][0], 'field1')\n    self.assertEqual(q3.children[0][1], 'value1')\n    self.assertEqual(q3.children[1][0], 'field2')\n    self.assertEqual(q3.children[1][1], 'value2')\n\n    q4 = q1 | q2\n    self.assertEqual(q4.connector, Q.OR)\n    self.assertEqual(len(q4.children), 2)\n    self.assertEqual(q4.children[0][0], 'field1')\n    self.assertEqual(q4.children[0][1], 'value1')\n    self.assertEqual(q4.children[1][0], 'field2')\n    self.assertEqual(q4.children[1][1], 'value2')\n\n    q5 = ~q1\n    self.assertTrue(q5.negated)\n    self.assertEqual(len(q5.children), 1)\n    self.assertEqual(q5.children[0][0], 'field1')\n    self.assertEqual(q5.children[0][1], 'value1')\n"], "sample_1185": ["def test_decompogen():\n    assert decompogen(sin(cos(x)), x) == [sin(x), cos(x)]\n    assert decompogen(sin(x)**2 + sin(x) + 1, x) == [x**2 + x + 1, sin(x)]\n    assert decompogen(sqrt(6*x**2 - 5), x) == [sqrt(x), 6*x**2 - 5]\n    assert decompogen(sin(sqrt(cos(x**2 + 1))), x) == [sin(x), sqrt(x), cos(x), x**2 + 1]\n    assert decompogen(x**4 + 2*x**3 - x - 1, x) == [x**2 - x - 1, x**2 + x]\n    assert decompogen(Abs(x), x) == [Abs(x)]\n    assert decompogen(exp(x), x) == [exp(x)]\n    assert decompogen(Max(x, y), x) == [Max(x, y)]\n    assert decompogen(Max(x, y), y) == [Max(x, y)]\n    assert decompogen(Max(x, y), x) == [Max(x, y)]\n    assert decompogen(Max(x, y), y) == [Max(x, y)]\n"], "sample_448": ["    def test_base_constraint_repr(self):\n        constraint = BaseConstraint(name='test_constraint')\n        self.assertEqual(repr(constraint), \"<BaseConstraint: name='test_constraint'>\")\n"], "sample_645": ["def test_log_capture_fixture(caplog):\n    logger.info(\"info message\")\n    sublogger.warning(\"warning message\")\n    assert len(caplog.records) == 2\n    assert caplog.record_tuples == [\n        (__name__, logging.INFO, \"info message\"),\n        (__name__ + \".baz\", logging.WARNING, \"warning message\"),\n    ]\n    assert caplog.messages == [\"info message\", \"warning message\"]\n    assert caplog.text == (\n        \"INFO     {}:{} info message\\n\"\n        \"WARNING  {}.baz:{} warning message\\n\".format(\n            __name__, __file__, __name__, __file__\n        )\n    )\n"], "sample_707": ["def test_iterparentnodeids_with_colon_in_test_name():\n    nodeid = \"a/b::c/d::e[/test]\"\n    expected = [\"\", \"a\", \"a/b\", \"a/b::c/d\", \"a/b::c/d::e[/test]\"]\n    assert list(nodes.iterparentnodeids(nodeid)) == expected\n"], "sample_782": ["def test_transformer_weights():\n    # test that transformer weights are applied correctly\n    X = np.array([[1, 2, 3], [4, 5, 6]])\n    ct = ColumnTransformer(\n        [(\"norm1\", Normalizer(norm='l1'), [0, 1]),\n         (\"norm2\", Normalizer(norm='l1'), [2])],\n        transformer_weights={\"norm1\": 2, \"norm2\": 3}\n    )\n    X_t = ct.fit_transform(X)\n    X_t_expected = np.hstack([\n        2 * Normalizer(norm='l1').fit_transform(X[:, :2]),\n        3 * Normalizer(norm='l1').fit_transform(X[:, 2:])\n    ])\n    assert_allclose_dense_sparse(X_t, X_t_expected)\n\n    # test that transformer weights are applied correctly when using make_column_transformer\n    ct = make_column_transformer(\n        (Normalizer(norm='l1'), [0, 1]),\n        (Normalizer(norm='l1'), [2]),\n        transformer_weights={\"normalizer\": 2}\n    )\n    X_t = ct.fit_transform(X)\n    X_t_expected = np.hstack([\n        2 * Normalizer(norm='l1').fit_transform(X[:, :2]),\n        Normalizer(norm='l1').fit_transform(X[:, 2:])\n    ])\n    assert_allclose_dense_sparse(X_t, X_t_expected)\n\n    # test that transformer weights are applied correctly when using make_column_transformer with multiple transformers of the same type\n    ct = make_column_transformer(\n        (Normalizer(norm='l1'), [0, 1]),\n        (Normalizer(norm='l1'), [2]),\n        transformer_weights={\"normalizer-1\": 2, \"normalizer-2\": 3}\n    )\n    X_t = ct.fit_transform(X)\n    X_t_expected = np.hstack([\n        2 * Normalizer(norm='l1').fit_transform(X[:, :2]),\n        3 * Normalizer(norm='l1').fit_transform(X[:, 2:])\n    ])\n    assert_allclose_dense_sparse(X_t, X_t_expected)\n"], "sample_367": ["def test_cache_control_decorator(self):\n    @cache_control(max_age=3600, public=True)\n        return HttpResponse()\n\n    request = HttpRequest()\n    response = view_func(request)\n    self.assertEqual(response['Cache-Control'], 'max-age=3600, public')\n"], "sample_356": ["def test_altered_unique_together(self):\n    before_state = self.make_project_state([\n        self.book_foo_together,\n    ])\n    after_state = self.make_project_state([\n        self.book_foo_together_2,\n    ])\n    changes = self.get_changes(before_state, after_state)\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\"])\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 0, unique_together={(\"title\", \"author\")})\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 1, index_together={(\"title\", \"author\")})\n"], "sample_202": ["def test_cookie_storage_max_size(self):\n    storage = self.storage_class(self.request, self.response)\n    messages = [Message(constants.INFO, 'Message %d' % i) for i in range(100)]\n    storage._store(messages, self.response)\n    self.assertLess(stored_cookie_messages_count(storage, self.response), len(messages))\n"], "sample_817": ["def test_variance_threshold():\n    X = np.array(data)\n    selector = VarianceThreshold(threshold=0.5)\n    X_selected = selector.fit_transform(X)\n    assert_array_equal(X_selected, [[1, 2, 3, 4],\n                                    [2, 2, 3, 5],\n                                    [1, 2, 4, 0]])\n"], "sample_982": ["def test_smoothness_p():\n    n = 10431\n    assert smoothness_p(n, m=1) == (1, [(3, (2, 2, 4)), (19, (1, 5, 5)), (61, (1, 31, 31))])\n    assert smoothness_p(n) == (-1, [(3, (2, 2, 2)), (19, (1, 3, 9)), (61, (1, 5, 5))])\n    assert smoothness_p(n, power=1) == (-1, [(3, (2, 2, 2)), (61, (1, 5, 5)), (19, (1, 3, 9))])\n    assert smoothness_p(n, visual=True) == \"\"\"p**i=3**2 has p-1 B=2, B-pow=2"], "sample_280": ["    def test_aggregate_with_default(self):\n        # Test that an aggregate with a default value works correctly.\n        aggregate = Avg('age', default=0)\n        result = Author.objects.aggregate(avg_age=aggregate)\n        self.assertEqual(result['avg_age'], Approximate(37.375, places=3))\n\n        # Test that an aggregate with a default value and filter works correctly.\n        aggregate = Avg('age', filter=Q(name__startswith='A'), default=0)\n        result = Author.objects.aggregate(avg_age=aggregate)\n        self.assertEqual(result['avg_age'], Approximate(34.5, places=3))\n\n        # Test that an aggregate with a default value and distinct works correctly.\n        aggregate = Avg('age', distinct=True, default=0)\n        result = Author.objects.aggregate(avg_age=aggregate)\n        self.assertEqual(result['avg_age'], Approximate(36.5, places=3))\n\n        # Test that an aggregate with a default value, filter, and distinct works correctly.\n        aggregate = Avg('age', filter=Q(name__startswith='A'), distinct=True, default=0)\n        result = Author.objects.aggregate(avg_age=aggregate)\n        self.assertEqual(result['avg_age'], Approximate(34.5, places=3))\n"], "sample_183": ["    def test_window_expression(self):\n        qs = CaseTestModel.objects.annotate(\n            window_sum=Window(\n                expression=Sum('integer'),\n                partition_by=F('integer2'),\n                order_by=F('integer').asc(),\n                frame=RowRange(start=-1, end=1),\n            ),\n        )\n        self.assertEqual(qs.count(), 9)\n        self.assertEqual(qs[0].window_sum, 2)\n        self.assertEqual(qs[1].window_sum, 6)\n        self.assertEqual(qs[2].window_sum, 9)\n        self.assertEqual(qs[3].window_sum, 9)\n        self.assertEqual(qs[4].window_sum, 9)\n        self.assertEqual(qs[5].window_sum, 12)\n        self.assertEqual(qs[6].window_sum, 12)\n        self.assertEqual(qs[7].window_sum, 12)\n        self.assertEqual(qs[8].window_sum, 5)\n"], "sample_896": ["def test_non_negative_factorization():\n    # Test that the non_negative_factorization function works correctly\n    X = np.array([[1, 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])\n    W, H, n_iter = non_negative_factorization(X, n_components=2, init='random', random_state=0)\n    assert W.shape == (6, 2)\n    assert H.shape == (2, 2)\n    assert n_iter > 0\n\n    # Test that the non_negative_factorization function raises an error when n_components is too large\n    with pytest.raises(ValueError):\n        non_negative_factorization(X, n_components=3, init='nndsvd', random_state=0)\n\n    # Test that the non_negative_factorization function raises an error when beta_loss is invalid\n    with pytest.raises(ValueError):\n        non_negative_factorization(X, n_components=2, beta_loss='invalid', random_state=0)\n\n    # Test that the non_negative_factorization function raises an error when X contains zeros and beta_loss <= 0\n    X = np.array([[1, 0], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])\n    with pytest.raises(ValueError):\n        non_negative_factorization(X, n_components=2, beta_loss=0, random_state=0)\n"], "sample_121": ["    def test_check_long_column_names(self):\n        # Create a model with a field that has an auto-generated column name\n        # that is too long for the database.\n        class LongColumnNameModel(models.Model):\n            long_column_name = models.CharField(max_length=255)\n\n        # Get the maximum allowed column name length for the database.\n        max_length, db_alias = get_max_column_name_length()\n\n        # If the database does not have a maximum column name length, skip the test.\n        if max_length is None:\n            self.skipTest(\"Database does not have a maximum column name length.\")\n\n        # Check that the model's column name is too long for the database.\n        self.assertGreater(len(LongColumnNameModel._meta.get_field('long_column_name').column), max_length)\n\n        # Check that the model check raises an error.\n        errors = LongColumnNameModel.check()\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, 'models.E018')\n        self.assertIn(\"Autogenerated column name too long for field\", str(errors[0]))\n"], "sample_181": ["def test_filtering_with_aggregates(self):\n    # Test filtering with aggregates\n    books = Book.objects.annotate(avg_rating=Avg('authors__rating')).filter(avg_rating__gt=4.0)\n    self.assertEqual(len(books), 2)\n    self.assertEqual(books[0].isbn, '159059725')\n    self.assertEqual(books[1].isbn, '159059996')\n\n    # Test filtering with aggregates and Q objects\n    books = Book.objects.annotate(avg_rating=Avg('authors__rating')).filter(Q(avg_rating__gt=4.0) | Q(pages__gt=500))\n    self.assertEqual(len(books), 3)\n    self.assertEqual(books[0].isbn, '159059725')\n    self.assertEqual(books[1].isbn, '067232959')\n    self.assertEqual(books[2].isbn, '159059996')\n\n    # Test filtering with aggregates and F expressions\n    books = Book.objects.annotate(avg_rating=Avg('authors__rating')).filter(avg_rating__gt=F('rating'))\n    self.assertEqual(len(books), 1)\n    self.assertEqual(books[0].isbn, '159059996')\n\n    # Test filtering with aggregates and Case expressions\n    books = Book.objects.annotate(avg_rating=Avg('authors__rating')).annotate(\n        rating_label=Case(\n            When(avg_rating__gt=4.0, then='High'),\n            When(avg_rating__gt=3.0, then='Medium'),\n            default='Low',\n        )\n    ).filter(rating_label='High')\n    self.assertEqual(len(books), 2)\n    self.assertEqual(books[0].isbn, '159059725')\n    self.assertEqual(books[1].isbn, '159059996')\n\n    # Test filtering with aggregates and Exists expressions\n    books = Book.objects.annotate(avg_rating=Avg('authors__rating')).annotate(\n        has_high_rating=Exists(Book.objects.filter(authors__rating__gt=4.0))\n    ).filter(has_high_rating=True)\n    self.assertEqual(len(books), 3)\n    self.assertEqual(books[0].isbn, '159059725')\n    self.assertEqual(books[1].isbn, '067232959')\n    self.assertEqual(books[2].isbn, '159059996')\n\n    # Test filtering with aggregates and Subquery expressions\n    subquery = Book.objects.filter(authors__rating__gt=4.0).values('id')\n    books = Book.objects.annotate(avg"], "sample_703": ["def test_parse_error():\n    with pytest.raises(ParseError) as excinfo:\n        Expression.compile(\"invalid input\")\n    assert excinfo.value.column == 1\n    assert \"unexpected character\" in excinfo.value.message\n"], "sample_1097": ["def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert isinstance(B, BlockMatrix)\n    assert ImmutableMatrix(B.blocks[0, 1]) == ImmutableMatrix(1, 3, range(1, 4))\n"], "sample_171": ["    def test_migration_progress_callback(self):\n        \"\"\"\n        Test the migration progress callback.\n        \"\"\"\n        # Mock the stdout and stderr to capture the output\n        stdout = io.StringIO()\n        stderr = io.StringIO()\n        with mock.patch('sys.stdout', stdout):\n            with mock.patch('sys.stderr', stderr):\n                # Create a mock migration\n                migration = mock.Mock()\n                migration.name = 'test_migration'\n                # Call the migration progress callback\n                self.command.migration_progress_callback('apply_start', migration)\n                self.command.migration_progress_callback('apply_success')\n                self.command.migration_progress_callback('unapply_start', migration)\n                self.command.migration_progress_callback('unapply_success')\n                self.command.migration_progress_callback('render_start')\n                self.command.migration_progress_callback('render_success')\n                # Check the output\n                self.assertIn('Applying test_migration...', stdout.getvalue())\n                self.assertIn(' OK', stdout.getvalue())\n                self.assertIn('Unapplying test_migration...', stdout.getvalue())\n                self.assertIn(' OK', stdout.getvalue())\n                self.assertIn('Rendering model states...', stdout.getvalue())\n                self.assertIn(' DONE', stdout.getvalue())\n"], "sample_767": ["def test_column_transformer_remainder():\n    # test that remainder is correctly applied\n    X = np.array([[1, 2, 3], [4, 5, 6]])\n    ct = ColumnTransformer(\n        transformers=[(\"norm1\", Normalizer(norm='l1'), [0, 1])],\n        remainder='passthrough')\n    result = ct.fit_transform(X)\n    assert_array_equal(result, np.array([[1., 1., 3.], [0.70710678, 0.70710678, 6.]]))\n\n    # test that remainder is correctly applied with sparse output\n    X = sparse.csr_matrix([[1, 2, 3], [4, 5, 6]])\n    ct = ColumnTransformer(\n        transformers=[(\"norm1\", Normalizer(norm='l1'), [0, 1])],\n        remainder='passthrough', sparse_threshold=0)\n    result = ct.fit_transform(X)\n    assert_allclose_dense_sparse(result, np.array([[1., 1., 3.], [0.70710678, 0.70710678, 6.]]))\n\n    # test that remainder is correctly applied with a transformer\n    X = np.array([[1, 2, 3], [4, 5, 6]])\n    ct = ColumnTransformer(\n        transformers=[(\"norm1\", Normalizer(norm='l1'), [0, 1])],\n        remainder=DoubleTrans())\n    result = ct.fit_transform(X)\n    assert_array_equal(result, np.array([[1., 1., 6.], [0.70710678, 0.70710678, 12.]]))\n\n    # test that remainder is correctly applied with a transformer and sparse output\n    X = sparse.csr_matrix([[1, 2, 3], [4, 5, 6]])\n    ct = ColumnTransformer(\n        transformers=[(\"norm1\", Normalizer(norm='l1'), [0, 1])],\n        remainder=DoubleTrans(), sparse_threshold=0)\n    result = ct.fit_transform(X)\n    assert_allclose_dense_sparse(result, np.array([[1., 1., 6.], [0.70710678, 0.70710678, 12.]]))\n"], "sample_876": ["def test_mlp_regressor_partial_fit():\n    # Test partial_fit for regression\n    X, y = regression_datasets[0]\n    mlp = MLPRegressor(hidden_layer_sizes=(10,), max_iter=1, warm_start=True)\n    mlp.partial_fit(X[:10], y[:10])\n    assert mlp.n_iter_ == 1\n    assert mlp.loss_curve_[0] > 0\n    assert mlp.t_ == 10\n    mlp.partial_fit(X[10:20], y[10:20])\n    assert mlp.n_iter_ == 2\n    assert mlp.loss_curve_[1] > 0\n    assert mlp.t_ == 20\n"], "sample_803": ["def test_roc_auc_score_multiclass():\n    # Test that roc_auc_score returns error for multiclass indicators\n    y_true = np.array([[0, 1, 0], [0, 0, 1]])\n    y_pred = np.array([[0.1, 0.7, 0.2], [0.1, 0.2, 0.7]])\n    with pytest.raises(ValueError):\n        roc_auc_score(y_true, y_pred, average='macro')\n"], "sample_850": ["def test_nystroem():\n    # Test Nystroem with different kernels\n    for kernel in kernel_metrics:\n        if kernel == 'precomputed':\n            continue\n        nystroem = Nystroem(kernel=kernel, n_components=10, random_state=0)\n        nystroem.fit(X)\n        X_nystroem = nystroem.transform(X)\n        assert X_nystroem.shape == (300, 10)\n\n    # Test Nystroem with callable kernel\n        return polynomial_kernel(X, Y, degree=2, gamma=1, coef0=1)\n    nystroem = Nystroem(kernel=custom_kernel, n_components=10, random_state=0)\n    nystroem.fit(X)\n    X_nystroem = nystroem.transform(X)\n    assert X_nystroem.shape == (300, 10)\n\n    # Test Nystroem with sparse data\n    X_sparse = csr_matrix(X)\n    nystroem = Nystroem(kernel='rbf', n_components=10, random_state=0)\n    nystroem.fit(X_sparse)\n    X_nystroem_sparse = nystroem.transform(X_sparse)\n    assert X_nystroem_sparse.shape == (300, 10)\n\n    # Test Nystroem with n_components > n_samples\n    nystroem = Nystroem(kernel='rbf', n_components=500, random_state=0)\n    with pytest.warns(UserWarning):\n        nystroem.fit(X)\n    X_nystroem = nystroem.transform(X)\n    assert X_nystroem.shape == (300, 300)\n\n    # Test Nystroem with invalid kernel\n    with assert_raises(ValueError):\n        Nystroem(kernel='invalid_kernel', n_components=10, random_state=0)\n\n    # Test Nystroem with invalid n_components\n    with assert_raises(ValueError):\n        Nystroem(kernel='rbf', n_components=-1, random_state=0)\n"], "sample_373": ["def test_simplify_regex(self):\n    self.assertEqual(simplify_regex(r'^(?P<sport_slug>\\w+)/athletes/(?P<athlete_slug>\\w+)/$'), '/<sport_slug>/athletes/<athlete_slug>/')\n    self.assertEqual(simplify_regex(r'^articles/(?P<year>\\d{4})/$'), '/<year>/')\n    self.assertEqual(simplify_regex(r'^articles/(?P<year>\\d{4})/(?P<month>\\d{2})/$'), '/<year>/<month>/')\n    self.assertEqual(simplify_regex(r'^articles/(?P<year>\\d{4})/(?P<month>\\d{2})/(?P<day>\\d{2})/$'), '/<year>/<month>/<day>/')\n    self.assertEqual(simplify_regex(r'^articles/(?P<year>\\d{4})/(?P<month>\\d{2})/(?P<day>\\d{2})/(?P<slug>[-\\w]+)/$'), '/<year>/<month>/<day>/<slug>/')\n    self.assertEqual(simplify_regex(r'^$'), '/')\n"], "sample_253": ["    def test_tick(self):\n        reloader = autoreload.StatReloader()\n        ticker = reloader.tick()\n        next(ticker)\n        self.assertFalse(reloader.should_stop)\n"], "sample_258": ["def test_send_robust_catches_exceptions(self):\n        return 'receiver1'\n\n        raise ValueError('Test exception')\n\n        return 'receiver3'\n\n    a_signal.connect(receiver1)\n    a_signal.connect(receiver2)\n    a_signal.connect(receiver3)\n\n    responses = a_signal.send_robust(None)\n    self.assertEqual(len(responses), 3)\n    self.assertEqual(responses[0][1], 'receiver1')\n    self.assertIsInstance(responses[1][1], ValueError)\n    self.assertEqual(responses[2][1], 'receiver3')\n"], "sample_81": ["def test_regex_pattern_match(self):\n    pattern = RegexPattern(r'^hello/(?P<name>\\w+)/world/$', name='test')\n    match = pattern.match('/hello/John/world/')\n    self.assertEqual(match, ('', ('John',), {'name': 'John'}))\n\n    pattern = RegexPattern(r'^hello/(?P<name>\\w+)/world/$', name='test')\n    match = pattern.match('/hello/John/world/extra/')\n    self.assertIsNone(match)\n\n    pattern = RegexPattern(r'^hello/(?P<name>\\w+)/world/$', name='test')\n    match = pattern.match('/hello/John/world')\n    self.assertIsNone(match)\n"], "sample_1131": ["def test_printers():\n    printers = [MpmathPrinter, NumPyPrinter, PythonCodePrinter, SciPyPrinter, SymPyPrinter]\n    exprs = [\n        x + y,\n        x * y,\n        x / y,\n        x ** y,\n        x ** (y ** z),\n        x ** (1 / 2),\n        x ** (1 / 3),\n        x ** (2 / 3),\n        x ** (3 / 2),\n        x ** (3 / 4),\n        x ** (4 / 3),\n        x ** (5 / 2),\n        x ** (5 / 3),\n        x ** (5 / 4),\n        x ** (6 / 5),\n        x ** (7 / 2),\n        x ** (7 / 3),\n        x ** (7 / 4),\n        x ** (7 / 5),\n        x ** (7 / 6),\n        x ** (8 / 3),\n        x ** (8 / 5),\n        x ** (8 / 7),\n        x ** (9 / 2),\n        x ** (9 / 4),\n        x ** (9 / 5),\n        x ** (9 / 7),\n        x ** (9 / 8),\n        x ** (10 / 3),\n        x ** (10 / 7),\n        x ** (10 / 9),\n        x ** (11 / 2),\n        x ** (11 / 3),\n        x ** (11 / 4),\n        x ** (11 / 5),\n        x ** (11 / 6),\n        x ** (11 / 7),\n        x ** (11 / 8),\n        x ** (11 / 9),\n        x ** (11 / 10),\n        x ** (12 / 5),\n        x ** (12 / 7),\n        x ** (12 / 11),\n        x ** (13 / 2),\n        x ** (13 / 3),\n        x ** (13 / 4),\n        x ** (13 / 5),\n        x ** (13 / 6),\n        x ** (13 / 7),\n        x ** (13 / 8),\n        x ** (13 / 9),\n        x ** (13 / 10),\n        x ** (13 / 11),\n        x ** (13 / 12),\n        x ** (14"], "sample_790": ["def test_kernel_pca_inverse_transform():\n    # Test that the inverse transform is correct\n    X, _ = make_circles(n_samples=100, factor=.2, noise=.05, random_state=0)\n    kpca = KernelPCA(kernel=\"rbf\", gamma=10, n_components=2,\n                     fit_inverse_transform=True, random_state=0)\n    X_kpca = kpca.fit_transform(X)\n    X_inv = kpca.inverse_transform(X_kpca)\n    assert_allclose(X, X_inv, atol=0.1)\n"], "sample_628": ["    def test_spelling_store_unknown_words(self):\n        \"\"\"Test that unknown words are stored in the private dictionary.\"\"\"\n        self.checker.open()\n        self.checker._check_spelling(\n            \"wrong-spelling-in-comment\", \"This is a tset comment\", 1\n        )\n        self.checker.close()\n        with open(self.checker.config.spelling_private_dict_file, \"r\") as f:\n            self.assertEqual(f.read().strip(), \"tset\")\n"], "sample_485": ["def test_json_script(self):\n    data = {\"key\": \"value\"}\n    expected_output = '<script type=\"application/json\">{}</script>'.format(\n        json.dumps(data, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n    )\n    self.check_output(json_script, data, expected_output)\n\n    element_id = \"test-id\"\n    expected_output = '<script id=\"{}\" type=\"application/json\">{}</script>'.format(\n        element_id, json.dumps(data, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n    )\n    self.check_output(json_script, data, element_id=element_id, output=expected_output)\n\n    custom_encoder = lambda x: json.dumps(x).upper()\n    expected_output = '<script type=\"application/json\">{}</script>'.format(\n        custom_encoder(data).translate(_json_script_escapes)\n    )\n    self.check_output(json_script, data, encoder=custom_encoder, output=expected_output)\n"], "sample_743": ["def test_neighbors_base_init():\n    # Test that the NeighborsBase class raises an error when initialized\n    # with an invalid algorithm\n    with assert_raises_regex(ValueError, \"unrecognized algorithm\"):\n        neighbors.NeighborsBase(algorithm='invalid')\n\n    # Test that the NeighborsBase class raises an error when initialized\n    # with an invalid metric\n    with assert_raises_regex(ValueError, \"Metric 'invalid' not valid\"):\n        neighbors.NeighborsBase(metric='invalid')\n\n    # Test that the NeighborsBase class raises an error when initialized\n    # with a callable metric and the KDTree algorithm\n    with assert_raises_regex(ValueError, \"kd_tree algorithm does not support\"):\n        neighbors.NeighborsBase(algorithm='kd_tree', metric=lambda x, y: 0)\n\n    # Test that the NeighborsBase class raises an error when initialized\n    # with a metric that is not valid for the chosen algorithm\n    with assert_raises_regex(ValueError, \"Metric 'minkowski' not valid\"):\n        neighbors.NeighborsBase(algorithm='kd_tree', metric='minkowski')\n\n    # Test that the NeighborsBase class raises an error when initialized\n    # with a p value less than 1 for the minkowski metric\n    with assert_raises_regex(ValueError, \"p must be greater than one\"):\n        neighbors.NeighborsBase(metric='minkowski', p=0)\n\n    # Test that the NeighborsBase class raises an error when initialized\n    # with a p value that is not an integer for the minkowski metric\n    with assert_raises_regex(TypeError, \"n_neighbors does not take\"):\n        neighbors.NeighborsBase(metric='minkowski', p=2.5)\n\n    # Test that the NeighborsBase class raises an error when initialized\n    # with a negative n_neighbors value\n    with assert_raises_regex(ValueError, \"Expected n_neighbors > 0\"):\n        neighbors.NeighborsBase(n_neighbors=-1)\n\n    # Test that the NeighborsBase class raises an error when initialized\n    # with a non-integer n_neighbors value\n    with assert_raises_regex(TypeError, \"n_neighbors does not take\"):\n        neighbors.NeighborsBase(n_neighbors=2.5)\n"], "sample_128": ["    def test_index_deconstruct(self):\n        index = Index(fields=['field1', '-field2'], name='my_index', db_tablespace='my_tablespace')\n        path, args, kwargs = index.deconstruct()\n        self.assertEqual(path, 'django.db.models.Index')\n        self.assertEqual(args, ())\n        self.assertEqual(kwargs, {'fields': ['field1', '-field2'], 'name': 'my_index', 'db_tablespace': 'my_tablespace'})\n\n        index = Index(fields=['field1', '-field2'], name='my_index', opclasses=['opclass1', 'opclass2'])\n        path, args, kwargs = index.deconstruct()\n        self.assertEqual(path, 'django.db.models.Index')\n        self.assertEqual(args, ())\n        self.assertEqual(kwargs, {'fields': ['field1', '-field2'], 'name': 'my_index', 'opclasses': ['opclass1', 'opclass2']})\n\n        index = Index(fields=['field1', '-field2'], name='my_index', condition=Q(field1='value1'))\n        path, args, kwargs = index.deconstruct()\n        self.assertEqual(path, 'django.db.models.Index')\n        self.assertEqual(args, ())\n        self.assertEqual(kwargs, {'fields': ['field1', '-field2'], 'name': 'my_index', 'condition': Q(field1='value1')})\n\n        index = Index(fields=['field1', '-field2'], name='my_index', include=['field3', 'field4'])\n        path, args, kwargs = index.deconstruct()\n        self.assertEqual(path, 'django.db.models.Index')\n        self.assertEqual(args, ())\n        self.assertEqual(kwargs, {'fields': ['field1', '-field2'], 'name': 'my_index', 'include': ['field3', 'field4']})\n"], "sample_7": ["def test_column_insert():\n    # Test that inserting into a Column works as expected\n    col = table.Column(name='test', data=[1, 2, 3])\n    new_col = col.insert(1, [4, 5])\n    assert_array_equal(new_col, [1, 4, 5, 2, 3])\n\n    # Test that inserting into a MaskedColumn works as expected\n    col = table.MaskedColumn(name='test', data=[1, 2, 3], mask=[False, True, False])\n    new_col = col.insert(1, [4, 5], mask=[False, False])\n    assert_array_equal(new_col.data, [1, 4, 5, 2, 3])\n    assert_array_equal(new_col.mask, [False, False, False, True, False])\n\n    # Test that inserting into a Column with a structured dtype works as expected\n    col = table.Column(name='test', data=np.array([(1, 2), (3, 4)], dtype=[('a', int), ('b', int)]))\n    new_col = col.insert(1, [(5, 6)])\n    assert_array_equal(new_col, [(1, 2), (5, 6), (3, 4)])\n\n    # Test that inserting into a MaskedColumn with a structured dtype works as expected\n    col = table.MaskedColumn(name='test', data=np.array([(1, 2), (3, 4)], dtype=[('a', int), ('b', int)]), mask=[(False, True), (False, False)])\n    new_col = col.insert(1, [(5, 6)], mask=[(False, False)])\n    assert_array_equal(new_col.data, [(1, 2), (5, 6), (3, 4)])\n    assert_array_equal(new_col.mask, [(False, True), (False, False), (False, False)])\n"], "sample_670": ["def test_evaluate_simple_match():\n        return ident == \"test\"\n\n    assert evaluate(\"test\", matcher) is True\n    assert evaluate(\"not test\", matcher) is False\n    assert evaluate(\"test and test\", matcher) is True\n    assert evaluate(\"test or test\", matcher) is True\n    assert evaluate(\"not test and test\", matcher) is False\n    assert evaluate(\"not test or test\", matcher) is True\n"], "sample_411": ["    def test_base_command_output_transaction(self):\n        class TestCommand(BaseCommand):\n            output_transaction = True\n\n                return \"SELECT * FROM table;\"\n\n        out = StringIO()\n        cmd = TestCommand(stdout=out)\n        cmd.execute()\n        self.assertEqual(\n            out.getvalue(),\n            \"BEGIN;\\nSELECT * FROM table;\\nCOMMIT;\\n\",\n        )\n"], "sample_1129": ["def test_printing():\n    # Test printing of various expressions\n    exprs = [\n        x + y,\n        x * y,\n        x / y,\n        x ** y,\n        x ** (1/2),\n        x ** (1/3),\n        x ** (2/3),\n        x ** (3/2),\n        x ** (3/4),\n        x ** (4/3),\n        x ** (5/2),\n        x ** (5/3),\n        x ** (5/4),\n        x ** (6/5),\n        x ** (7/2),\n        x ** (7/3),\n        x ** (7/4),\n        x ** (7/5),\n        x ** (7/6),\n        x ** (8/3),\n        x ** (8/5),\n        x ** (8/7),\n        x ** (9/2),\n        x ** (9/4),\n        x ** (9/5),\n        x ** (9/7),\n        x ** (9/8),\n        x ** (10/3),\n        x ** (10/7),\n        x ** (10/9),\n        x ** (11/2),\n        x ** (11/3),\n        x ** (11/4),\n        x ** (11/5),\n        x ** (11/6),\n        x ** (11/7),\n        x ** (11/8),\n        x ** (11/9),\n        x ** (11/10),\n        x ** (12/5),\n        x ** (12/7),\n        x ** (12/11),\n        x ** (13/2),\n        x ** (13/3),\n        x ** (13/4),\n        x ** (13/5),\n        x ** (13/6),\n        x ** (13/7),\n        x ** (13/8),\n        x ** (13/9),\n        x ** (13/10),\n        x ** (13/11),\n        x ** (13/12),\n        x ** (14/3),\n        x ** (14/5),\n        x ** (14/9),\n        x ** (14/11),\n        x ** (14/13),\n        x ** (15/2),\n        x ** (15/4),\n        x ** (15/7),\n        x ** (15/8),\n        x ** (15/11"], "sample_254": ["    def test_inline_change_link(self):\n        request = self.factory.get(reverse('admin:admin_inlines_holder_change', args=(self.holder.pk,)))\n        request.user = self.superuser\n        inline_admin = InnerInline(Inner, admin_site)\n        formset = inline_admin.get_formset(request, self.holder)\n        inline_admin_form = InlineAdminForm(inline_admin, formset, [], {}, [], model_admin=inline_admin)\n        html = inline_admin_form.render()\n        self.assertRegex(html, INLINE_CHANGELINK_HTML)\n"], "sample_546": ["def test_figure_repr():\n    fig = Figure(figsize=(8, 6))\n    assert re.match(r\"<Figure\\(8\\.0x6\\.0\\) with 0 Axes>\", repr(fig))\n    ax = fig.add_subplot(111)\n    assert re.match(r\"<Figure\\(8\\.0x6\\.0\\) with 1 Axes>\", repr(fig))\n"], "sample_459": ["    def test_integer_field_exact_lookup(self):\n        lookup = IntegerFieldExact()\n        self.assertEqual(lookup.lookup_name, \"exact\")\n        self.assertIsInstance(lookup, IntegerFieldOverflow)\n        self.assertIsInstance(lookup, Exact)\n"], "sample_1194": ["def test_julia_code():\n    assert julia_code(x**2 + 2*x - 3) == \"(x ^ 2) + 2 * x - 3\"\n    assert julia_code(x**2 + 2*x - 3, assign_to=\"y\") == \"y = (x ^ 2) + 2 * x - 3\"\n    assert julia_code(x**2 + 2*x - 3, assign_to=\"y\", inline=False) == \"y = x ^ 2 + 2 * x - 3\"\n    assert julia_code(x**2 + 2*x - 3, assign_to=\"y\", inline=False, human=False) == ([], [], \"y = x ^ 2 + 2 * x - 3\")\n\n    assert julia_code(x**2 + 2*x - 3, assign_to=\"y\", precision=20) == \"y = (x ^ 2) + 2 * x - 3\"\n    assert julia_code(x**2 + 2*x - 3, assign_to=\"y\", user_functions={}) == \"y = (x ^ 2) + 2 * x - 3\"\n    assert julia_code(x**2 + 2*x - 3, assign_to=\"y\", contract=True) == \"y = (x ^ 2) + 2 * x - 3\"\n    assert julia_code(x**2 + 2*x - 3, assign_to=\"y\", contract=False) == \"y = (x ^ 2) + 2 * x - 3\"\n\n    assert julia_code(x**2 + 2*x - 3, assign_to=\"y\", inline=True) == \"y = (x ^ 2) + 2 * x - 3\"\n    assert julia_code(x**2 + 2*x - 3, assign_to=\"y\", inline=False) == \"y = x ^ 2 + 2 * x - 3\"\n\n    assert julia_code(x**2 + 2*x - 3, assign_to=\"y\", human=True) == \"y = (x ^ 2) + 2 * x - 3\"\n    assert julia_code(x**2 + 2*x - 3, assign_to=\"y\", human=False) == ([], [], \"y = x ^ 2 + 2 * x - "], "sample_1000": ["def test_octave_code():\n    # Test the _print_Idx method\n    from sympy.tensor import Idx\n    i = Idx('i')\n    assert octave_code(i) == 'i'\n\n    # Test the _print_Indexed method\n    from sympy.tensor import IndexedBase\n    A = IndexedBase('A')\n    assert octave_code(A[i]) == 'A(i)'\n\n    # Test the _print_Assignment method with IndexedBase\n    from sympy import Eq\n    eq = Eq(A[i], x)\n    assert octave_code(eq.rhs, assign_to=eq.lhs) == 'A(i) = x;'\n\n    # Test the _print_Assignment method with MatrixSymbol\n    from sympy import MatrixSymbol\n    M = MatrixSymbol('M', 2, 2)\n    eq = Eq(M, Matrix([[x, y], [z, x]]))\n    assert octave_code(eq.rhs, assign_to=eq.lhs) == 'M = [x y; z x];'\n\n    # Test the _print_Assignment method with Piecewise\n    pw = Piecewise((x, x > 0), (y, True))\n    eq = Eq(x, pw)\n    assert octave_code(eq.rhs, assign_to=eq.lhs) == 'x = ((x > 0).*x + (~(x > 0)).*y);'\n\n    # Test the _print_Assignment method with contract=False\n    from sympy import Indexed\n    i = Idx('i', 3)\n    A = IndexedBase('A')\n    eq = Eq(A[i], x)\n    assert octave_code(eq.rhs, assign_to=eq.lhs, contract=False) == 'A(i) = x;'\n\n    # Test the _print_Assignment method with inline=False\n    pw = Piecewise((x, x > 0), (y, True))\n    eq = Eq(x, pw)\n    assert octave_code(eq.rhs, assign_to=eq.lhs, inline=False) == 'if (x > 0)\\n  x = x;\\nelse\\n  x = y;\\nend\\n'\n\n    # Test the _print_Assignment method with user_functions\n    f = Function('f')\n    custom_functions = {\"f\": \"my_fcn\"}\n    eq = Eq(x, f(x))\n    assert octave_code(eq.rhs, assign_to=eq.lhs, user_functions"], "sample_197": ["def test_timesince_future(self):\n    with translation.override('en'):\n        self.assertEqual(timesince(self.t + self.onemicrosecond), '0 minutes')\n        self.assertEqual(timesince(self.t + self.onesecond), '0 minutes')\n        self.assertEqual(timesince(self.t + self.oneminute), '0 minutes')\n        self.assertEqual(timesince(self.t + self.onehour), '0 minutes')\n        self.assertEqual(timesince(self.t + self.oneday), '0 minutes')\n        self.assertEqual(timesince(self.t + self.oneweek), '0 minutes')\n        self.assertEqual(timesince(self.t + self.onemonth), '0 minutes')\n        self.assertEqual(timesince(self.t + self.oneyear), '0 minutes')\n"], "sample_702": ["def test_pytester_makefile(tmp_path_factory, pytester):\n    pytester.makefile(\".txt\", \"line1\", \"line2\")\n    assert (tmp_path_factory.mktemp(\"test_makefile\", numbered=True) / \"test_makefile.txt\").exists()\n\n    pytester.makefile(\".ini\", pytest=\"[pytest]\\naddopts=-rs\\n\")\n    assert (tmp_path_factory.mktemp(\"test_makefile\", numbered=True) / \"pytest.ini\").exists()\n\n    pytester.makefile(\".txt\", custom=\"line1\", custom2=\"line2\")\n    assert (tmp_path_factory.mktemp(\"test_makefile\", numbered=True) / \"custom.txt\").exists()\n    assert (tmp_path_factory.mktemp(\"test_makefile\", numbered=True) / \"custom2.txt\").exists()\n"], "sample_937": ["compilation error"], "sample_889": ["def test_calibration_curve_multiclass():\n    # Test that calibration_curve raises an error for multiclass problems\n    X, y = make_classification(n_samples=100, n_features=6, n_informative=3, n_redundant=0, random_state=42)\n    y_pred = np.random.rand(100, 3)\n    with pytest.raises(ValueError):\n        calibration_curve(y, y_pred[:, 1])\n"], "sample_306": ["def test_parse_date(self):\n    # Test valid date\n    self.assertEqual(parse_date('2022-01-01'), date(2022, 1, 1))\n\n    # Test invalid date\n    with self.assertRaises(ValueError):\n        parse_date('2022-02-30')\n\n    # Test invalid format\n    self.assertIsNone(parse_date('2022/01/01'))\n\n    # Test edge cases\n    self.assertEqual(parse_date('0001-01-01'), date(1, 1, 1))\n    self.assertEqual(parse_date('9999-12-31'), date(9999, 12, 31))\n"], "sample_1074": ["def test_sylow_subgroup():\n    # Test the sylow_subgroup method\n    S = SymmetricGroup(6)\n    S3 = S.sylow_subgroup(3)\n    assert S3.order() == 9\n    assert S3.is_subgroup(S)\n\n    A = AlternatingGroup(6)\n    A3 = A.sylow_subgroup(3)\n    assert A3.order() == 9\n    assert A3.is_subgroup(A)\n\n    D = DihedralGroup(6)\n    D2 = D.sylow_subgroup(2)\n    assert D2.order() == 4\n    assert D2.is_subgroup(D)\n\n    C = CyclicGroup(6)\n    C2 = C.sylow_subgroup(2)\n    assert C2.order() == 2\n    assert C2.is_subgroup(C)\n\n    C3 = C.sylow_subgroup(3)\n    assert C3.order() == 3\n    assert C3.is_subgroup(C)\n\n    # Test the sylow_subgroup method for a non-prime p\n    G = SymmetricGroup(4)\n    with raises(ValueError):\n        G.sylow_subgroup(6)\n"], "sample_290": ["def test_migration_suggest_name(self):\n    migration = Migration(\"0001_test\", \"testapp\")\n    migration.operations = [\n        migrations.AddField(\n            model_name='author',\n            name='name',\n            field=models.CharField(max_length=200),\n        ),\n        migrations.AddField(\n            model_name='author',\n            name='biography',\n            field=models.TextField(),\n        ),\n    ]\n    self.assertEqual(migration.suggest_name(), 'add_field_name_and_biography')\n\n    migration = Migration(\"0001_test\", \"testapp\")\n    migration.operations = [\n        migrations.AddField(\n            model_name='author',\n            name='name',\n            field=models.CharField(max_length=200),\n        ),\n        migrations.AddField(\n            model_name='author',\n            name='biography',\n            field=models.TextField(),\n        ),\n        migrations.AddField(\n            model_name='author',\n            name='date_of_birth',\n            field=models.DateField(),\n        ),\n    ]\n    self.assertEqual(migration.suggest_name(), 'add_field_name_biography_and_date_of_birth')\n\n    migration = Migration(\"0001_test\", \"testapp\")\n    migration.operations = [\n        migrations.AddField(\n            model_name='author',\n            name='name',\n            field=models.CharField(max_length=200),\n        ),\n        migrations.AddField(\n            model_name='author',\n            name='biography',\n            field=models.TextField(),\n        ),\n        migrations.AddField(\n            model_name='author',\n            name='date_of_birth',\n            field=models.DateField(),\n        ),\n        migrations.AddField(\n            model_name='author',\n            name='date_time_of_birth',\n            field=models.DateTimeField(),\n        ),\n    ]\n    self.assertEqual(migration.suggest_name(), 'add_field_name_biography_date_of_birth_and_date_time_of_birth')\n\n    migration = Migration(\"0001_test\", \"testapp\")\n    migration.operations = [\n        migrations.AddField(\n            model_name='author',\n            name='name',\n            field=models.CharField(max_length=200),\n        ),\n        migrations.AddField(\n            model_name='author',\n            name='biography',\n            field=models.TextField(),\n        ),\n        migrations.AddField(\n            model_name='author',\n            name='date_of_birth',\n            field=models.DateField(),\n        ),\n        migrations.AddField(\n            model_name='author',\n            name='date_time_of_birth',\n            field=models.DateTimeField(),\n        ),\n        migrations.AddField(\n            model_name='author',\n            name='time_of_birth',\n            field=models.TimeField(),\n        ),\n    ]\n    self.assertEqual(migration.suggest_name(), 'add_field_name_biography_date_of"], "sample_680": ["def test_evaluate_xfail_marks_with_strict_and_run_true():\n    class Item:\n            if name == \"xfail\":\n                return [Mark(\"xfail\", args=(), kwargs={\"reason\": \"test reason\", \"strict\": True, \"run\": True})]\n            return []\n\n    item = Item()\n    xfail_marks = evaluate_xfail_marks(item)\n    assert xfail_marks is not None\n    assert xfail_marks.reason == \"test reason\"\n    assert xfail_marks.strict is True\n    assert xfail_marks.run is True\n    assert xfail_marks.raises is None\n"], "sample_809": ["def test_mutual_info_classif():\n    # Test classification with discrete features\n    X = np.array([[1, 2], [1, 3], [2, 2], [2, 3]])\n    y = np.array([0, 0, 1, 1])\n    mi = mutual_info_classif(X, y, discrete_features=True)\n    assert_array_equal(mi, np.array([0.0, 0.0]))\n\n    # Test classification with continuous features\n    X = np.array([[1.0, 2.0], [1.0, 3.0], [2.0, 2.0], [2.0, 3.0]])\n    y = np.array([0, 0, 1, 1])\n    mi = mutual_info_classif(X, y, discrete_features=False)\n    assert_greater(mi[0], 0.0)\n    assert_greater(mi[1], 0.0)\n\n    # Test classification with mixed features\n    X = np.array([[1, 2.0], [1, 3.0], [2, 2.0], [2, 3.0]])\n    y = np.array([0, 0, 1, 1])\n    mi = mutual_info_classif(X, y, discrete_features=[True, False])\n    assert_greater(mi[0], 0.0)\n    assert_greater(mi[1], 0.0)\n\n    # Test classification with sparse features\n    X = csr_matrix(np.array([[1, 2], [1, 3], [2, 2], [2, 3]]))\n    y = np.array([0, 0, 1, 1])\n    mi = mutual_info_classif(X, y, discrete_features=True)\n    assert_array_equal(mi, np.array([0.0, 0.0]))\n\n    # Test classification with random state\n    X = np.array([[1, 2], [1, 3], [2, 2], [2, 3]])\n    y = np.array([0, 0, 1, 1])\n    rng = check_random_state(0)\n    mi1 = mutual_info_classif(X, y, random_state=rng)\n    mi2 = mutual_info_classif(X, y, random_state=rng)\n    assert_array_equal(mi1, mi2)\n\n    # Test classification"], "sample_1046": ["def test_TensorHead():\n    L = TensorIndexType(\"L\")\n    i, j, k = symbols(\"i j k\")\n    A = tensorhead(\"A\", [L, L], [[1], [1]])\n    te = TensorElement(A(i, j), {i: 2})\n    assert te.get_free_indices() == [j]\n    assert te.get_indices() == [2, j]\n    assert te.expr == A(i, j)\n    assert te.index_map == {i: 2}\n    assert te.free == [(j, 1)]\n    assert te.dum == []\n"], "sample_1103": ["def test_isqrt():\n    assert isqrt(0) == 0\n    assert isqrt(1) == 1\n    assert isqrt(2) == 1\n    assert isqrt(3) == 1\n    assert isqrt(4) == 2\n    assert isqrt(5) == 2\n    assert isqrt(8) == 2\n    assert isqrt(9) == 3\n    assert isqrt(16) == 4\n    assert isqrt(25) == 5\n    assert isqrt(36) == 6\n    assert isqrt(49) == 7\n    assert isqrt(64) == 8\n    assert isqrt(81) == 9\n    assert isqrt(100) == 10\n    assert isqrt(121) == 11\n    assert isqrt(144) == 12\n    assert isqrt(169) == 13\n    assert isqrt(196) == 14\n    assert isqrt(225) == 15\n    assert isqrt(256) == 16\n    assert isqrt(289) == 17\n    assert isqrt(324) == 18\n    assert isqrt(361) == 19\n    assert isqrt(400) == 20\n    assert isqrt(441) == 21\n    assert isqrt(484) == 22\n    assert isqrt(529) == 23\n    assert isqrt(576) == 24\n    assert isqrt(625) == 25\n    assert isqrt(676) == 26\n    assert isqrt(729) == 27\n    assert isqrt(784) == 28\n    assert isqrt(841) == 29\n    assert isqrt(900) == 30\n    assert isqrt(961) == 31\n    assert isqrt(1024) == 32\n    assert isqrt(1089) == 33\n    assert isqrt(1156) == 34\n    assert isqrt(1225) == 35\n    assert isqrt(1296) == 36\n    assert isqrt(1369) == 37\n    assert isqrt(1444) == 38\n    assert isqrt(1521) == 39\n    assert isqrt(1600) == 40\n"], "sample_806": ["def test_gradient_boosting_regressor():\n    # Test Gradient Boosting Regressor.\n    X, y = make_regression(n_samples=100, n_features=10, n_informative=5,\n                            random_state=1)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5,\n                                                        random_state=1)\n\n    gbrt = GradientBoostingRegressor(n_estimators=10, random_state=1)\n    gbrt.fit(X_train, y_train)\n    y_pred = gbrt.predict(X_test)\n\n    assert_equal(y_pred.shape, (X_test.shape[0],))\n    assert_greater(mean_squared_error(y_test, y_pred), 0.0)\n\n    # Test with different loss functions\n    for loss in ['ls', 'lad', 'huber', 'quantile']:\n        gbrt = GradientBoostingRegressor(n_estimators=10, loss=loss,\n                                         random_state=1)\n        gbrt.fit(X_train, y_train)\n        y_pred = gbrt.predict(X_test)\n        assert_equal(y_pred.shape, (X_test.shape[0],))\n\n    # Test with different init estimators\n    for init in [None, DummyRegressor(), LinearRegression()]:\n        gbrt = GradientBoostingRegressor(n_estimators=10, init=init,\n                                         random_state=1)\n        gbrt.fit(X_train, y_train)\n        y_pred = gbrt.predict(X_test)\n        assert_equal(y_pred.shape, (X_test.shape[0],))\n\n    # Test with sparse data\n    X_sparse = csr_matrix(X)\n    gbrt = GradientBoostingRegressor(n_estimators=10, random_state=1)\n    gbrt.fit(X_sparse, y)\n    y_pred = gbrt.predict(X_sparse)\n    assert_equal(y_pred.shape, (X.shape[0],))\n\n    # Test with presort\n    gbrt = GradientBoostingRegressor(n_estimators=10, presort=True,\n                                     random_state=1)\n    gbrt.fit(X, y)\n    y_pred = gbrt.predict(X)\n    assert_equal(y_pred.shape, (X.shape[0],))\n\n    # Test with warm_start\n    gbrt = GradientBoostingRegressor(n_estimators=10, warm_start=True,\n                                     random_state=1)\n    gbrt.fit(X_train, y_train)\n    y_pred = gbrt.predict(X"], "sample_240": ["    def test_make_token(self):\n        user = User.objects.create_user('testuser', 'test@example.com', 'password')\n        token_generator = PasswordResetTokenGenerator()\n        token = token_generator.make_token(user)\n        self.assertTrue(token_generator.check_token(user, token))\n"], "sample_1020": ["def test_mcode_printer():\n    assert mcode(x**2) == 'x^2'\n    assert mcode(x**-2) == 'x^(-2)'\n    assert mcode(x**(S(1)/2)) == 'x^(1/2)'\n    assert mcode(x**(S(3)/2)) == 'x^(3/2)'\n    assert mcode(x**2*y**3) == 'x^2*y^3'\n    assert mcode(x**2*y**-3) == 'x^2*y^(-3)'\n    assert mcode(x**2*y**(S(1)/3)) == 'x^2*y^(1/3)'\n    assert mcode(x**2*y**(S(2)/3)) == 'x^2*y^(2/3)'\n    assert mcode(x**2*y**(S(3)/2)) == 'x^2*y^(3/2)'\n    assert mcode(x**2*y**(S(4)/3)) == 'x^2*y^(4/3)'\n    assert mcode(x**2*y**(S(5)/3)) == 'x^2*y^(5/3)'\n    assert mcode(x**2*y**(S(5)/4)) == 'x^2*y^(5/4)'\n    assert mcode(x**2*y**(S(7)/4)) == 'x^2*y^(7/4)'\n    assert mcode(x**2*y**(S(7)/6)) == 'x^2*y^(7/6)'\n    assert mcode(x**2*y**(S(11)/6)) == 'x^2*y^(11/6)'\n    assert mcode(x**2*y**(S(13)/6)) == 'x^2*y^(13/6)'\n    assert mcode(x**2*y**(S(13)/8)) == 'x^2*y^(13/8)'\n    assert mcode(x**2*y**(S(15)/8)) == 'x^2*y^(15/8)'\n    assert mcode(x**2*y**(S(17)/8)) == 'x^2*y^(17/8)'\n    assert mcode(x**2*y**(S(19)/8)) == 'x^2*y^(19/8)'\n    assert mcode(x**2*y**(S(21)/8)) == 'x^2*y^(21/8)'\n   "], "sample_491": ["    def test_bound_field(self):\n        form = FrameworkForm(data={\"name\": \"John\", \"language\": \"P\"})\n        bound_field = form[\"name\"]\n        self.assertEqual(bound_field.name, \"name\")\n        self.assertEqual(bound_field.html_name, \"name\")\n        self.assertEqual(bound_field.html_initial_name, \"name\")\n        self.assertEqual(bound_field.html_initial_id, \"id_name\")\n        self.assertEqual(bound_field.label, \"Name\")\n        self.assertEqual(bound_field.help_text, \"\")\n        self.assertEqual(bound_field.renderer, get_default_renderer())\n\n        self.assertEqual(len(bound_field.subwidgets), 1)\n        self.assertEqual(bound_field.errors, ErrorList())\n        self.assertEqual(bound_field.template_name, \"django/forms/widgets/text.html\")\n        self.assertEqual(bound_field.get_context(), {\"field\": bound_field})\n\n        self.assertEqual(bound_field.as_widget(), '<input type=\"text\" name=\"name\" value=\"John\" id=\"id_name\">')\n        self.assertEqual(bound_field.as_text(), '<input type=\"text\" name=\"name\" value=\"John\" id=\"id_name\">')\n        self.assertEqual(bound_field.as_textarea(), '<textarea name=\"name\" cols=\"40\" rows=\"10\" id=\"id_name\">John</textarea>')\n        self.assertEqual(bound_field.as_hidden(), '<input type=\"hidden\" name=\"name\" value=\"John\" id=\"id_name\">')\n\n        self.assertEqual(bound_field.data, \"John\")\n        self.assertEqual(bound_field.value(), \"John\")\n        self.assertFalse(bound_field._has_changed())\n\n        self.assertEqual(bound_field.label_tag(), '<label for=\"id_name\">Name:</label>')\n        self.assertEqual(bound_field.legend_tag(), '<legend>Name:</legend>')\n        self.assertEqual(bound_field.css_classes(), \"\")\n        self.assertFalse(bound_field.is_hidden)\n        self.assertEqual(bound_field.auto_id, \"name\")\n        self.assertEqual(bound_field.id_for_label, \"id_name\")\n        self.assertEqual(bound_field.initial, \"\")\n        self.assertEqual(bound_field.build_widget_attrs({\"class\": \"test\"}), {\"class\": \"test\"})\n\n        self.assertEqual(bound_field.widget_type, \"char\")\n        self.assertFalse(bound_field.use_fieldset)\n\n        bound_widget = bound_field.subwidgets[0]\n        self.assertEqual(str(bound_widget), '<input type=\"text\" name=\"name\" value=\"John\" id=\"id_name\">')\n        self.assertEqual(bound_widget.tag(), '<input type=\"text"], "sample_869": ["def test_multilabel_confusion_matrix():\n    # Test multilabel-indicator case\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    mcm = multilabel_confusion_matrix(y_true, y_pred)\n    assert_array_almost_equal(mcm, np.array([[[1, 0],\n                                              [0, 1]],\n                                             [[1, 0],\n                                              [0, 1]],\n                                             [[0, 1],\n                                              [1, 0]]]))\n\n    # Test multiclass case\n    y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n    y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n    mcm = multilabel_confusion_matrix(y_true, y_pred,\n                                       labels=[\"ant\", \"bird\", \"cat\"])\n    assert_array_almost_equal(mcm, np.array([[[3, 1],\n                                              [0, 2]],\n                                             [[5, 0],\n                                              [1, 0]],\n                                             [[2, 1],\n                                              [1, 2]]]))\n\n    # Test samplewise case\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    mcm = multilabel_confusion_matrix(y_true, y_pred, samplewise=True)\n    assert_array_almost_equal(mcm, np.array([[[1, 0, 0, 1],\n                                              [0, 1, 1, 0]],\n                                             [[1, 0, 0, 1],\n                                              [0, 1, 1, 0]]]))\n\n    # Test samplewise case with sample weights\n    y_true = np.array([[1, 0, 1],\n                       [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0],\n                       [0, 1, 1]])\n    sample_weight = np.array([0.5, 1.5])\n    mcm = multilabel_confusion_matrix(y_true, y_pred, sample_weight=sample_weight,\n                                       sample"], "sample_883": ["def test_bayesian_ridge_deprecation_warning():\n    # Test that a deprecation warning is raised when using n_iter\n    with pytest.warns(FutureWarning):\n        BayesianRidge(n_iter=100)\n\n    # Test that no warning is raised when using max_iter\n    with pytest.warns(None) as record:\n        BayesianRidge(max_iter=100)\n    assert len(record) == 0\n\n    # Test that a ValueError is raised when using both n_iter and max_iter\n    with pytest.raises(ValueError):\n        BayesianRidge(n_iter=100, max_iter=100)\n"], "sample_1077": ["def test_ComplexRegion():\n    a, b = Interval(2, 5), Interval(4, 8)\n    c = Interval(0, 2*pi)\n    c1 = ComplexRegion(a*b)\n    c2 = ComplexRegion(a*c, polar=True)\n    assert c1.measure == 12\n    assert c2.measure == 6*pi\n    assert ComplexRegion.from_real(Interval(0,1)) == ComplexRegion(ProductSet(Interval(0, 1), FiniteSet(0)), False)\n    assert ComplexRegion.from_real(Interval(0,1)).sets == ProductSet(Interval(0, 1), FiniteSet(0))\n    assert ComplexRegion.from_real(Interval(0,1)).polar == False\n    assert ComplexRegion.from_real(Interval(0,1)).a_interval == Interval(0, 1)\n    assert ComplexRegion.from_real(Interval(0,1)).b_interval == FiniteSet(0)\n    assert ComplexRegion.from_real(Interval(0,1)).variables == (x, y)\n    assert ComplexRegion.from_real(Interval(0,1)).expr == x + I*y\n    assert ComplexRegion.from_real(Interval(0,1)).psets == (ProductSet(Interval(0, 1), FiniteSet(0)),)\n    assert ComplexRegion.from_real(Interval(0,1))._measure == 1\n    assert ComplexRegion.from_real(Interval(0,1))._contains(0.5) == True\n    assert ComplexRegion.from_real(Interval(0,1))._contains(1.5) == False\n    assert ComplexRegion.from_real(Interval(0,1))._contains(0.5 + 0.5*I) == True\n    assert ComplexRegion.from_real(Interval(0,1))._contains(1.5 + 0.5*I) == False\n"], "sample_492": ["def test_operation_writer_serialize(self):\n    class TestOperation(migrations.operations.base.Operation):\n            self.arg1 = arg1\n            self.arg2 = arg2\n\n            return (\"TestOperation\", [self.arg1], {\"arg2\": self.arg2})\n\n    operation = TestOperation(\"arg1_value\", arg2=\"arg2_value\")\n    writer = OperationWriter(operation)\n    serialized, imports = writer.serialize()\n    self.assertEqual(serialized, \"migrations.TestOperation(arg1='arg1_value', arg2='arg2_value'),\")\n    self.assertEqual(imports, set())\n"], "sample_440": ["    def test_bulk_create_with_auto_field(self):\n        # Test that bulk_create() works with auto fields.\n        ids = list(range(1, 11))\n        instances = [SmallAutoFieldModel(id=i) for i in ids]\n        SmallAutoFieldModel.objects.bulk_create(instances)\n        self.assertEqual(list(SmallAutoFieldModel.objects.values_list(\"id\", flat=True)), ids)\n\n        # Test that bulk_create() works with BigAutoField.\n        ids = list(range(1, 11))\n        instances = [BigAutoFieldModel(id=i) for i in ids]\n        BigAutoFieldModel.objects.bulk_create(instances)\n        self.assertEqual(list(BigAutoFieldModel.objects.values_list(\"id\", flat=True)), ids)\n\n        # Test that bulk_create() works with auto fields and other fields.\n        ids = list(range(1, 11))\n        instances = [SmallAutoFieldModel(id=i, name=f\"Name {i}\") for i in ids]\n        SmallAutoFieldModel.objects.bulk_create(instances)\n        self.assertEqual(\n            list(SmallAutoFieldModel.objects.values_list(\"id\", \"name\")),\n            list(zip(ids, [f\"Name {i}\" for i in ids])),\n        )\n\n        # Test that bulk_create() works with BigAutoField and other fields.\n        ids = list(range(1, 11))\n        instances = [BigAutoFieldModel(id=i, name=f\"Name {i}\") for i in ids]\n        BigAutoFieldModel.objects.bulk_create(instances)\n        self.assertEqual(\n            list(BigAutoFieldModel.objects.values_list(\"id\", \"name\")),\n            list(zip(ids, [f\"Name {i}\" for i in ids])),\n        )\n"], "sample_231": ["    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        request.user = User()\n        exc_type = Exception\n        exc_value = Exception('Test exception')\n        tb = None\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIn('request', data)\n        self.assertIn('request_meta', data)\n        self.assertIn('user_str', data)\n        self.assertIn('filtered_POST_items', data)\n        self.assertIn('settings', data)\n        self.assertIn('sys_executable', data)\n        self.assertIn('sys_version_info', data)\n        self.assertIn('server_time', data)\n        self.assertIn('django_version_info', data)\n        self.assertIn('sys_path', data)\n        self.assertIn('template_info', data)\n        self.assertIn('template_does_not_exist', data)\n        self.assertIn('postmortem', data)\n        self.assertIn('exception_type', data)\n        self.assertIn('exception_value', data)\n        self.assertIn('lastframe', data)\n"], "sample_68": ["    def test_sensitive_key(self):\n        key = 'API_KEY'\n        value = 'my_secret_key'\n        self.assertEqual(cleanse_setting(key, value), CLEANSED_SUBSTITUTE)\n"], "sample_158": ["def test_foreign_key_check_unique(self):\n    class Model(models.Model):\n        fk = models.ForeignKey('self', on_delete=models.CASCADE, unique=True)\n\n    with self.assertRaisesMessage(Error, \"Setting unique=True on a ForeignKey has the same effect as using a OneToOneField.\"):\n        Model._meta.get_field('fk').check()\n\n    class Model(models.Model):\n        fk = models.ForeignKey('self', on_delete=models.CASCADE, unique=False)\n\n    self.assertEqual(Model._meta.get_field('fk').check(), [])\n\n    class Model(models.Model):\n        fk = models.OneToOneField('self', on_delete=models.CASCADE)\n\n    self.assertEqual(Model._meta.get_field('fk').check(), [])\n"], "sample_549": ["def test_delete_masked_points():\n    # Test case 1: 1-D masked arrays\n    x = np.ma.array([1, 2, 3, 4, 5], mask=[0, 1, 0, 1, 0])\n    y = np.ma.array([6, 7, 8, 9, 10], mask=[1, 0, 1, 0, 1])\n    x_out, y_out = delete_masked_points(x, y)\n    assert_array_equal(x_out, np.array([1, 3, 5]))\n    assert_array_equal(y_out, np.array([7, 9]))\n\n    # Test case 2: 1-D ndarrays\n    x = np.array([1, 2, 3, 4, 5])\n    y = np.array([6, 7, 8, 9, 10])\n    x_out, y_out = delete_masked_points(x, y)\n    assert_array_equal(x_out, np.array([1, 2, 3, 4, 5]))\n    assert_array_equal(y_out, np.array([6, 7, 8, 9, 10]))\n\n    # Test case 3: ndarrays with more than one dimension\n    x = np.array([[1, 2], [3, 4]])\n    y = np.array([[6, 7], [8, 9]])\n    x_out, y_out = delete_masked_points(x, y)\n    assert_array_equal(x_out, np.array([[1, 2], [3, 4]]))\n    assert_array_equal(y_out, np.array([[6, 7], [8, 9]]))\n\n    # Test case 4: other non-string iterables\n    x = [1, 2, 3, 4, 5]\n    y = [6, 7, 8, 9, 10]\n    x_out, y_out = delete_masked_points(x, y)\n    assert_array_equal(x_out, np.array([1, 2, 3, 4, 5]))\n    assert_array_equal(y_out, np.array([6, 7, 8, 9, 10]))\n\n    # Test case 5: anything else\n    x = 1\n    y = 2\n    x_out, y_out = delete_mask"], "sample_89": ["    def test_tick(self):\n        reloader = autoreload.StatReloader()\n        ticker = reloader.tick()\n        self.assertEqual(next(ticker), None)\n"], "sample_689": ["def test_deprecated_external_plugins():\n    \"\"\"Test that deprecated external plugins are correctly defined.\"\"\"\n    assert isinstance(DEPRECATED_EXTERNAL_PLUGINS, set)\n    assert len(DEPRECATED_EXTERNAL_PLUGINS) == 3\n    assert \"pytest_catchlog\" in DEPRECATED_EXTERNAL_PLUGINS\n    assert \"pytest_capturelog\" in DEPRECATED_EXTERNAL_PLUGINS\n    assert \"pytest_faulthandler\" in DEPRECATED_EXTERNAL_PLUGINS\n"], "sample_671": ["def test_check_strict_xfail_passing_test_with_strict_xfail_marker():\n    class TestClass:\n        @pytest.mark.xfail(strict=True)\n            pass\n\n    item = pytest.Item(\"test_passing_test\", parent=TestClass())\n    item.config = pytest.Config()\n    item.config.getini = lambda x: False\n    item._store[evalxfail_key] = MarkEvaluator(item, \"xfail\")\n    check_strict_xfail(item)\n    assert item._store.get(evalxfail_key) is None\n"], "sample_118": ["    def test_year_lookup(self):\n        # Test year lookups.\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year=2005),\n            [self.a1, self.a2, self.a3, self.a4, self.a7],\n            attrgetter('headline'),\n        )\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gt=2005),\n            [self.a5, self.a6],\n            attrgetter('headline'),\n        )\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gte=2005),\n            [self.a1, self.a2, self.a3, self.a4, self.a5, self.a6, self.a7],\n            attrgetter('headline'),\n        )\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lt=2005),\n            [],\n            attrgetter('headline'),\n        )\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lte=2005),\n            [self.a1, self.a2, self.a3, self.a4, self.a7],\n            attrgetter('headline'),\n        )\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__exact=2005),\n            [self.a1, self.a2, self.a3, self.a4, self.a7],\n            attrgetter('headline'),\n        )\n"], "sample_374": ["def test_prefetch_related_objects_with_nested_prefetch(self):\n    with CaptureQueriesContext(connection) as captured_queries:\n        authors = Author.objects.prefetch_related(\n            Prefetch('book_set', queryset=Book.objects.prefetch_related('authors'))\n        ).all()\n        for author in authors:\n            for book in author.book_set.all():\n                for book_author in book.authors.all():\n                    pass\n    self.assertEqual(len(captured_queries), 3)\n"], "sample_788": ["def test_inverse_transform():\n    est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n    est.fit(X)\n    Xt = est.transform(X)\n    Xinv = est.inverse_transform(Xt)\n    assert_array_almost_equal(Xinv, [[-1.5, 1.5, -3.5, -0.5],\n                                    [-0.5, 2.5, -2.5, -0.5],\n                                    [0.5, 3.5, -1.5, 0.5],\n                                    [0.5, 3.5, -1.5, 1.5]])\n"], "sample_1161": ["def test_strprinter():\n    printer = StrPrinter()\n    assert printer._print_Str(\"Hello\") == \"Str('Hello')\"\n    assert printer._print_str(\"Hello\") == \"Hello\"\n    assert printer._print_StrReprPrinter(\"Hello\") == \"Str('Hello')\"\n    assert sstr(\"Hello\") == \"Hello\"\n    assert sstrrepr(\"Hello\") == \"'Hello'\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\")) == \"Str('Hello')\"\n    assert sstrrepr(Str(\"Hello\"))"], "sample_884": ["def test_deprecated_class_instantiation():\n    with pytest.warns(FutureWarning, match=\"Class MockClass1 is deprecated; qwerty\"):\n        MockClass1()\n\n    with pytest.warns(FutureWarning, match=\"Class MockClass6 is deprecated; a message\"):\n        MockClass6(1)\n\n    with pytest.warns(FutureWarning, match=\"Class MockClass1 is deprecated; qwerty\"):\n        MockClass5(1)\n\n"], "sample_814": ["def test_gradient_boosting_regressor():\n    # Test Gradient Boosting Regressor.\n    X, y = make_regression(n_samples=100, n_features=10, n_informative=5,\n                            random_state=1)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5,\n                                                        random_state=1)\n\n    gbrt = GradientBoostingRegressor(n_estimators=10, random_state=1)\n    gbrt.fit(X_train, y_train)\n    y_pred = gbrt.predict(X_test)\n\n    assert_equal(y_pred.shape, (X_test.shape[0],))\n    assert_greater(mean_squared_error(y_test, y_pred), 0.0)\n\n    # Test with different loss functions\n    for loss in ['ls', 'lad', 'huber', 'quantile']:\n        gbrt = GradientBoostingRegressor(n_estimators=10, loss=loss,\n                                         random_state=1)\n        gbrt.fit(X_train, y_train)\n        y_pred = gbrt.predict(X_test)\n        assert_equal(y_pred.shape, (X_test.shape[0],))\n        assert_greater(mean_squared_error(y_test, y_pred), 0.0)\n\n    # Test with different init estimators\n    for init in [None, DummyRegressor(), LinearRegression()]:\n        gbrt = GradientBoostingRegressor(n_estimators=10, init=init,\n                                         random_state=1)\n        gbrt.fit(X_train, y_train)\n        y_pred = gbrt.predict(X_test)\n        assert_equal(y_pred.shape, (X_test.shape[0],))\n        assert_greater(mean_squared_error(y_test, y_pred), 0.0)\n\n    # Test with sparse data\n    X_sparse = csr_matrix(X_train)\n    gbrt = GradientBoostingRegressor(n_estimators=10, random_state=1)\n    gbrt.fit(X_sparse, y_train)\n    y_pred = gbrt.predict(X_sparse)\n    assert_equal(y_pred.shape, (X_test.shape[0],))\n    assert_greater(mean_squared_error(y_test, y_pred), 0.0)\n\n    # Test with presort\n    gbrt = GradientBoostingRegressor(n_estimators=10, presort=True,\n                                     random_state=1)\n    gbrt.fit(X_train, y_train)\n    y_pred = gbrt.predict(X_test)\n    assert_equal(y_pred.shape, ("], "sample_706": ["def test_parse_error():\n    with pytest.raises(ParseError) as excinfo:\n        Expression.compile(\"invalid input\")\n    assert excinfo.value.column == 1\n    assert \"unexpected character\" in excinfo.value.message\n"], "sample_405": ["    def test_rename_index(self):\n        \"\"\"\n        Tests the RenameIndex operation.\n        \"\"\"\n        # Create a model with an index\n        operation = migrations.CreateModel(\n            \"TestModel\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=255)),\n            ],\n            options={\"indexes\": [models.Index(fields=[\"name\"], name=\"name_index\")]},\n        )\n        self.apply_operations(operation)\n\n        # Rename the index\n        operation = migrations.RenameIndex(\n            \"TestModel\", \"new_name_index\", \"name_index\"\n        )\n        self.apply_operations(operation)\n\n        # Check the index was renamed\n        with connection.cursor() as cursor:\n            cursor.execute(\n                \"SELECT name FROM sqlite_master WHERE type='index' AND name='new_name_index'\"\n            )\n            self.assertEqual(len(cursor.fetchall()), 1)\n\n        # Reverse the operation\n        self.reverse_operations(operation)\n\n        # Check the index was renamed back\n        with connection.cursor() as cursor:\n            cursor.execute(\n                \"SELECT name FROM sqlite_master WHERE type='index' AND name='name_index'\"\n            )\n            self.assertEqual(len(cursor.fetchall()), 1)\n\n        # Rename an unnamed index\n        operation = migrations.CreateModel(\n            \"TestModel\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=255)),\n            ],\n            options={\"indexes\": [models.Index(fields=[\"name\"])]},\n        )\n        self.apply_operations(operation)\n\n        # Rename the index\n        operation = migrations.RenameIndex(\n            \"TestModel\", \"new_name_index\", old_fields=[\"name\"]\n        )\n        self.apply_operations(operation)\n\n        # Check the index was renamed\n        with connection.cursor() as cursor:\n            cursor.execute(\n                \"SELECT name FROM sqlite_master WHERE type='index' AND name='new_name_index'\"\n            )\n            self.assertEqual(len(cursor.fetchall()), 1)\n\n        # Reverse the operation\n        self.reverse_operations(operation)\n\n        # Check the index was renamed back\n        with connection.cursor() as cursor:\n            cursor.execute(\n                \"SELECT name FROM sqlite_master WHERE type='index' AND name='new_name_index'\"\n            )\n            self.assertEqual(len(cursor.fetchall()), 0)\n"], "sample_570": ["    def test_define_support_univariate(self, x):\n        kde = KDE()\n        support = kde.define_support(x)\n        assert len(support) == kde.gridsize\n        assert support.min() < x.min()\n        assert support.max() > x.max()\n"], "sample_1072": ["def test_frac():\n    assert frac(17) == 0\n    assert frac(Rational(23, 10)) == Rational(3, 10)\n    assert frac(2*E) == 2*E - 5\n    assert frac(-Float(0.567)) == Float(0.433)\n    assert frac(-I/2) == -I/2\n    assert frac(S(5)/2 + 5*I/2) == S(1)/2 + S(1)/2*I\n\n    assert frac(n) == 0\n    assert frac(x).rewrite(floor) == x - floor(x)\n    assert frac(t + I*r) == I*frac(r) + frac(t)\n\n    assert frac(oo) == AccumBounds(0, 1)\n    assert frac(-oo) == AccumBounds(0, 1)\n    assert frac(nan) == nan\n    assert frac(zoo) == nan\n\n    assert frac(sin(x)) == frac(sin(x))\n    assert frac(exp(x)) == frac(exp(x))\n    assert frac(log(x)) == frac(log(x))\n    assert frac(factorial(x)) == frac(factorial(x))\n    assert frac(sqrt(x)) == frac(sqrt(x))\n\n    assert frac(x).is_real == y.is_real\n    assert frac(i).is_imaginary == True\n    assert frac(x).is_integer == x.is_integer\n    assert frac(x).is_zero == (x.is_zero | x.is_integer)\n\n    assert frac(x) >= 0\n    assert frac(x) < 1\n\n    assert Eq(frac(x), 0) == Eq(x, floor(x))\n    assert Eq(frac(x), 0) == Eq(x, ceiling(x))\n\n    assert frac(x) >= -1 == False\n    assert frac(x) >= 1 == False\n    assert frac(x) > -1 == True\n    assert frac(x) > 1 == False\n    assert frac(x) <= 1 == True\n    assert frac(x) <= 0 == False\n    assert frac(x) < 1 == True\n    assert frac(x) < 0 == False\n"], "sample_560": ["def test_legend_draggable():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], label='Line 1')\n    ax.plot([2, 3, 4], label='Line 2')\n    legend = ax.legend(loc='upper right', draggable=True)\n    assert legend.get_draggable()\n    assert isinstance(legend._draggable, mlegend.DraggableLegend)\n    assert legend._draggable.legend is legend\n    assert legend._draggable.use_blit is False\n    assert legend._draggable._update == 'loc'\n"], "sample_557": ["def test_subfigure_layout_engine():\n    fig = plt.figure()\n    sfigs = fig.subfigures(1, 2, width_ratios=[1, 2])\n    ax1 = sfigs[0].subplots()\n    ax2 = sfigs[1].subplots()\n    ax1.plot([1, 2, 3])\n    ax2.plot([1, 2, 3])\n    sfigs[0].set_layout_engine('constrained')\n    sfigs[1].set_layout_engine('tight')\n    fig.tight_layout()\n    assert isinstance(sfigs[0].get_layout_engine(), ConstrainedLayoutEngine)\n    assert isinstance(sfigs[1].get_layout_engine(), TightLayoutEngine)\n    assert isinstance(fig.get_layout_engine(), PlaceHolderLayoutEngine)\n"], "sample_75": ["    def test_foreign_key_to_self(self):\n        # Test that a ForeignKey to self works correctly\n        author = Author.objects.create(name='Test Author')\n        book = Book.objects.create(title='Test Book', author=author)\n        self.assertEqual(book.author, author)\n"], "sample_1168": ["def test_multiset_partitions():\n    # Test multiset_partitions with a multiset\n    multiset = [1, 1, 2, 2, 3]\n    expected_partitions = [\n        [[1, 1, 2, 2, 3]],\n        [[1, 1, 2, 2], [3]],\n        [[1, 1, 2], [2, 3]],\n        [[1, 1, 2], [3], [2]],\n        [[1, 1], [2, 2, 3]],\n        [[1, 1], [2, 2], [3]],\n        [[1, 1], [2], [2, 3]],\n        [[1, 1], [2], [3], [2]],\n        [[1], [1, 2, 2, 3]],\n        [[1], [1, 2, 2], [3]],\n        [[1], [1, 2], [2, 3]],\n        [[1], [1, 2], [3], [2]],\n        [[1], [1], [2, 2, 3]],\n        [[1], [1], [2, 2], [3]],\n        [[1], [1], [2], [2, 3]],\n        [[1], [1], [2], [3], [2]],\n        [[1], [1], [1], [2, 2, 3]],\n        [[1], [1], [1], [2, 2], [3]],\n        [[1], [1], [1], [2], [2, 3]],\n        [[1], [1], [1], [2], [3], [2]],\n        [[1], [1], [1], [1], [2, 2, 3]],\n        [[1], [1], [1], [1], [2, 2], [3]],\n        [[1], [1], [1], [1], [2], [2, 3]],\n        [[1], [1], [1], [1], [2], [3], [2]],\n        [[1], [1], [1], [1], [1], [2, 2, 3]],\n        [[1], [1], [1], [1], [1], [2, 2], ["], "sample_62": ["    def test_register_model(self):\n        self.site.register(Location, NameAdmin)\n        self.assertIn(Location, self.site._registry)\n        self.assertIsInstance(self.site._registry[Location], NameAdmin)\n"], "sample_1048": ["def test_parabola():\n    p1 = Parabola(Point(0, 0), Line(Point(5, 8), Point(7, 8)))\n    assert p1.focus == Point2D(0, 0)\n    assert p1.directrix == Line2D(Point2D(5, 8), Point2D(7, 8))\n    assert p1.axis_of_symmetry == Line2D(Point2D(0, 0), Point2D(0, 1))\n    assert p1.eccentricity == 1\n    assert p1.equation() == -p1.x**2 - 16*p1.y + 64\n    assert p1.focal_length == 4\n    assert p1.p_parameter == -4\n    assert p1.vertex == Point2D(0, 4)\n\n    p2 = Parabola(Point(0, 0), Line(Point(5, 8), Point(5, 10)))\n    assert p2.focus == Point2D(0, 0)\n    assert p2.directrix == Line2D(Point2D(5, 8), Point2D(5, 10))\n    assert p2.axis_of_symmetry == Line2D(Point2D(0, 0), Point2D(1, 0))\n    assert p2.eccentricity == 1\n    assert p2.equation() == -16*p2.x + p2.y**2 - 64\n    assert p2.focal_length == 4\n    assert p2.p_parameter == 4\n    assert p2.vertex == Point2D(4, 0)\n\n    raises(NotImplementedError, lambda: Parabola(Point(0, 0), Line(Point(5, 8), Point(7, 9))))\n    raises(ValueError, lambda: Parabola(Point(5, 8), Line(Point(5, 8), Point(7, 8))))\n\n    p3 = Parabola()\n    assert p3.focus == Point2D(0, 0)\n    assert p3.directrix == Line2D(Point2D(0, 1), Point2D(1, 1))\n    assert p3.axis_of_symmetry == Line2D(Point2D(0, 0), Point2D(0, 1))\n    assert p3.eccentricity == "], "sample_1013": ["def test_lambdify_with_implemented_function():\n    f = implemented_function('f', lambda x: x**2)\n    g = implemented_function('g', lambda x: x + 1)\n    expr = f(g(x))\n    func = lambdify(x, expr)\n    assert func(2) == 9\n"], "sample_1146": ["def test_latex():\n    # Test latex printing of various objects\n    assert latex(x) == 'x'\n    assert latex(1) == '1'\n    assert latex(x**2) == 'x^{2}'\n    assert latex(x**-2) == 'x^{-2}'\n    assert latex(x**Rational(1, 2)) == '\\sqrt{x}'\n    assert latex(x**Rational(1, 3)) == '\\sqrt[3]{x}'\n    assert latex(x**Rational(2, 3)) == '\\sqrt[3]{x^{2}}'\n    assert latex(x**Rational(-1, 3)) == '\\frac{1}{\\sqrt[3]{x}}'\n    assert latex(x**Rational(-2, 3)) == '\\frac{1}{\\sqrt[3]{x^{2}}}'\n\n    assert latex(x + y) == 'x + y'\n    assert latex(x - y) == 'x - y'\n    assert latex(x * y) == 'x y'\n    assert latex(x / y) == '\\frac{x}{y}'\n\n    assert latex(x + 1) == 'x + 1'\n    assert latex(x - 1) == 'x - 1'\n    assert latex(x * 2) == '2 x'\n    assert latex(x / 2) == '\\frac{x}{2}'\n\n    assert latex(2 * x) == '2 x'\n    assert latex(2 + x) == 'x + 2'\n    assert latex(2 - x) == '2 - x'\n    assert latex(2 / x) == '\\frac{2}{x}'\n\n    assert latex(x**2 + y**2) == 'x^{2} + y^{2}'\n    assert latex(x**2 - y**2) == 'x^{2} - y^{2}'\n    assert latex(x**2 * y**2) == 'x^{2} y^{2}'\n    assert latex(x**2 / y**2) == '\\frac{x^{2}}{y^{2}}'\n\n    assert latex((x + y)**2) == '\\left(x + y\\right)^{2}'\n    assert latex((x - y)**2) == '\\left(x - y\\right)^{2}'\n    assert latex((x * y)**2) == '\\left(x y\\right)^{2}'\n    assert latex((x"], "sample_594": ["def test_format_array_flat():\n    array = np.arange(100)\n    assert formatting.format_array_flat(array, 20) == \"0 1 2 ... 97 98 99\"\n    assert formatting.format_array_flat(array, 10) == \"0 ... 99\"\n    assert formatting.format_array_flat(array, 5) == \"...\"\n\n    array = np.arange(100).reshape(10, 10)\n    assert formatting.format_array_flat(array, 20) == \"0 1 2 ... 97 98 99\"\n    assert formatting.format_array_flat(array, 10) == \"0 ... 99\"\n    assert formatting.format_array_flat(array, 5) == \"...\"\n\n    array = np.arange(100).reshape(10, 10, 1)\n    assert formatting.format_array_flat(array, 20) == \"0 1 2 ... 97 98 99\"\n    assert formatting.format_array_flat(array, 10) == \"0 ... 99\"\n    assert formatting.format_array_flat(array, 5) == \"...\"\n"], "sample_1147": ["def test_latex():\n    # Test latex printing of various objects\n    assert latex(x) == 'x'\n    assert latex(x**2) == 'x^{2}'\n    assert latex(x**-2) == 'x^{-2}'\n    assert latex(x**Rational(1, 2)) == '\\sqrt{x}'\n    assert latex(x**Rational(1, 3)) == '\\sqrt[3]{x}'\n    assert latex(x**Rational(2, 3)) == '\\sqrt[3]{x^{2}}'\n    assert latex(x**Rational(-1, 3)) == '\\frac{1}{\\sqrt[3]{x}}'\n    assert latex(x**Rational(-2, 3)) == '\\frac{1}{\\sqrt[3]{x^{2}}}'\n    assert latex(x**Rational(-3, 2)) == 'x^{-\\frac{3}{2}}'\n    assert latex(x**Rational(-3, 4)) == 'x^{-\\frac{3}{4}}'\n    assert latex(x**Rational(3, 4)) == 'x^{\\frac{3}{4}}'\n    assert latex(x**Rational(-5, 4)) == 'x^{-\\frac{5}{4}}'\n    assert latex(x**Rational(5, 4)) == 'x^{\\frac{5}{4}}'\n    assert latex(x**Rational(-7, 4)) == 'x^{-\\frac{7}{4}}'\n    assert latex(x**Rational(7, 4)) == 'x^{\\frac{7}{4}}'\n    assert latex(x**Rational(-9, 4)) == 'x^{-\\frac{9}{4}}'\n    assert latex(x**Rational(9, 4)) == 'x^{\\frac{9}{4}}'\n    assert latex(x**Rational(-11, 4)) == 'x^{-\\frac{11}{4}}'\n    assert latex(x**Rational(11, 4)) == 'x^{\\frac{11}{4}}'\n    assert latex(x**Rational(-13, 4)) == 'x^{-\\frac{13}{4}}'\n    assert latex(x**Rational(13, 4)) == 'x^{\\frac{13}{4}}'\n    assert latex(x**Rational(-15, 4)) == '"], "sample_404": ["    def test_tokenize(self):\n        lexer = Lexer(\"Hello, {{ world }}!\")\n        tokens = lexer.tokenize()\n        self.assertEqual(len(tokens), 3)\n        self.assertEqual(tokens[0].token_type, TokenType.TEXT)\n        self.assertEqual(tokens[0].contents, \"Hello, \")\n        self.assertEqual(tokens[1].token_type, TokenType.VAR)\n        self.assertEqual(tokens[1].contents, \" world \")\n        self.assertEqual(tokens[2].token_type, TokenType.TEXT)\n        self.assertEqual(tokens[2].contents, \"!\")\n"], "sample_57": ["    def test_user_creation(self):\n        data = {\n            'username': 'testuser',\n            'password1': 'testpassword',\n            'password2': 'testpassword',\n        }\n        form = UserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        user = form.save()\n        self.assertEqual(user.username, 'testuser')\n        self.assertTrue(user.check_password('testpassword'))\n"], "sample_992": ["def test_print_known_func():\n    printer = PythonCodePrinter()\n    expr = acos(x)\n    assert printer._print_known_func(expr) == 'acos(x)'\n"], "sample_840": ["def test_pls_svd():\n    # Test that PLSSVD is equivalent to PLS with algorithm=\"svd\"\n    X, Y = load_linnerud(return_X_y=True)\n    pls_svd = PLSSVD(n_components=2)\n    pls_svd.fit(X, Y)\n    pls_svd_x_scores = pls_svd.x_scores_\n    pls_svd_y_scores = pls_svd.y_scores_\n\n    pls = pls_.PLS(n_components=2, algorithm=\"svd\")\n    pls.fit(X, Y)\n    pls_x_scores = pls.x_scores_\n    pls_y_scores = pls.y_scores_\n\n    assert_array_almost_equal(pls_svd_x_scores, pls_x_scores)\n    assert_array_almost_equal(pls_svd_y_scores, pls_y_scores)\n"], "sample_267": ["    def test_database_wrapper_get_connection_params(self):\n        with self.settings(DATABASES={\n            'default': {\n                'ENGINE': 'django.db.backends.sqlite3',\n                'NAME': ':memory:',\n                'OPTIONS': {\n                    'check_same_thread': True,\n                },\n            },\n        }):\n            wrapper = connection.vendor\n            params = wrapper.get_connection_params()\n            self.assertIn('check_same_thread', params)\n            self.assertFalse(params['check_same_thread'])\n            self.assertIn('uri', params)\n            self.assertTrue(params['uri'])\n"], "sample_993": ["def test_free_group():\n    assert F.is_FreeGroup\n    assert F.is_group\n    assert F.is_associative\n    assert not F.is_PermutationGroup\n    assert F.rank == 3\n    assert F.order() == oo\n    assert F.identity == F.dtype(())\n    assert F.generators == (x, y, z)\n    assert F.symbols == (x, y, z)\n    assert F.elements == {F.identity}\n    assert F.is_abelian == False\n    assert F.center() == {F.identity}\n    assert F.relators == ()\n    assert F == F\n    assert F != free_group(\"x, y\")\n    assert F != free_group(\"x, y, z, w\")\n    assert F != free_group(\"\")\n    assert F != free_group(\"x, y, z, w, v\")\n    assert F != free_group(\"x, y, z, w, v, u\")\n    assert F != free_group(\"x, y, z, w, v, u, t\")\n    assert F != free_group(\"x, y, z, w, v, u, t, s\")\n    assert F != free_group(\"x, y, z, w, v, u, t, s, r\")\n    assert F != free_group(\"x, y, z, w, v, u, t, s, r, q\")\n    assert F != free_group(\"x, y, z, w, v, u, t, s, r, q, p\")\n    assert F != free_group(\"x, y, z, w, v, u, t, s, r, q, p, o\")\n    assert F != free_group(\"x, y, z, w, v, u, t, s, r, q, p, o, n\")\n    assert F != free_group(\"x, y, z, w, v, u, t, s, r, q, p, o, n, m\")\n    assert F != free_group(\"x, y, z, w, v, u, t, s, r, q, p, o, n, m, l\")\n    assert F != free_group(\"x, y, z, w, v, u, t, s, r, q, p, o, n, m, l, k\")\n    assert F != free_group(\"x, y, z,"], "sample_1017": ["def test_as_Boolean():\n    assert as_Boolean(True) is true\n    assert as_Boolean(False) is false\n    assert as_Boolean(1) is true\n    assert as_Boolean(0) is false\n    raises(TypeError, lambda: as_Boolean(2))\n"], "sample_395": ["    def test_template_changed_resets_loaders(self, reset_loaders):\n        file_path = EXTRA_TEMPLATES_DIR / \"test_template.html\"\n        file_path.touch()\n        sender = mock.Mock()\n        template_changed(sender, file_path)\n        reset_loaders.assert_called_once()\n"], "sample_182": ["def test_union_with_empty_querysets(self):\n    qs1 = Number.objects.all()\n    qs2 = Number.objects.none()\n    qs3 = Number.objects.none()\n\n    qs = qs1.union(qs2, qs3)\n    self.assertEqual(qs.count(), 10)\n\n    qs = qs2.union(qs1, qs3)\n    self.assertEqual(qs.count(), 10)\n\n    qs = qs2.union(qs3, qs1)\n    self.assertEqual(qs.count(), 10)\n\n    qs = qs2.union(qs3)\n    self.assertEqual(qs.count(), 0)\n"], "sample_1067": ["def test_mul():\n    x, y = symbols('x y')\n    a = Symbol('a', commutative=False)\n    b = Symbol('b', commutative=False)\n\n    assert Mul._matches_noncomm([a, b], [a, b]) == {}\n    assert Mul._matches_noncomm([a, b], [b, a]) == None\n    assert Mul._matches_noncomm([a, b], [a, b, b]) == None\n    assert Mul._matches_noncomm([a, b, b], [a, b]) == None\n    assert Mul._matches_noncomm([a, b, b], [a, b, b]) == {}\n    assert Mul._matches_noncomm([a, b, b], [a, b, b, b]) == None\n    assert Mul._matches_noncomm([a, b, b, b], [a, b, b]) == None\n    assert Mul._matches_noncomm([a, b, b, b], [a, b, b, b]) == {}\n    assert Mul._matches_noncomm([a, b, b, b], [a, b, b, b, b]) == None\n    assert Mul._matches_noncomm([a, b, b, b, b], [a, b, b, b]) == None\n    assert Mul._matches_noncomm([a, b, b, b, b], [a, b, b, b, b]) == {}\n    assert Mul._matches_noncomm([a, b, b, b, b], [a, b, b, b, b, b]) == None\n    assert Mul._matches_noncomm([a, b, b, b, b, b], [a, b, b, b, b]) == None\n    assert Mul._matches_noncomm([a, b, b, b, b, b], [a, b, b, b, b, b]) == {}\n    assert Mul._matches_noncomm([a, b, b, b, b, b], [a, b, b, b, b, b, b]) == None\n    assert Mul._matches_noncomm([a, b, b, b, b, b, b], [a, b, b, b, b, b]) == None\n    assert Mul._matches_noncomm([a, b, b, b,"], "sample_1018": ["def test_fcode():\n    x, y, z = symbols('x y z')\n    f = Function('f')\n    A = MatrixSymbol('A', 3, 3)\n    B = MatrixSymbol('B', 3, 3)\n    C = MatrixSymbol('C', 3, 3)\n\n    # Test printing of complex numbers\n    assert fcode(1 + 2*I) == \"      cmplx(1,2)\"\n\n    # Test printing of complex numbers in Add\n    assert fcode(1 + 2*I + 3) == \"      cmplx(4,2)\"\n\n    # Test printing of complex numbers in Mul\n    assert fcode((1 + 2*I)*3) == \"      cmplx(3,6)\"\n\n    # Test printing of complex numbers in Pow\n    assert fcode((1 + 2*I)**2) == \"      cmplx(-3,4)\"\n\n    # Test printing of complex numbers in Matrix\n    assert fcode(Matrix([1 + 2*I, 3])) == \"      A(1, 1) = cmplx(1,2)\\n      A(2, 1) = 3\"\n\n    # Test printing of complex numbers in Matrix with multiple columns\n    assert fcode(Matrix([[1 + 2*I, 3], [4, 5]])) == \"      A(1, 1) = cmplx(1,2)\\n      A(1, 2) = 3\\n      A(2, 1) = 4\\n      A(2, 2) = 5\"\n\n    # Test printing of complex numbers in Matrix with multiple rows and columns\n    assert fcode(Matrix([[1 + 2*I, 3, 4], [5, 6, 7], [8, 9, 10]])) == \"      A(1, 1) = cmplx(1,2)\\n      A(1, 2) = 3\\n      A(1, 3) = 4\\n      A(2, 1) = 5\\n      A(2, 2) = 6\\n      A(2, 3) = 7\\n      A(3, 1) = 8\\n      A(3, 2) = 9\\n      A(3, 3) = 10\"\n\n"], "sample_1024": ["def test_comp():\n    assert comp(1, 1) == True\n    assert comp(1, 2) == True\n    assert comp(1, 2, 0.5) == False\n    assert comp(1, 2, 1) == True\n    assert comp(1, 2, 2) == True\n    assert comp(1, 1.0000000000000001) == True\n    assert comp(1, 1.0000000000000001, 1e-15) == False\n    assert comp(1, 1.0000000000000001, 1e-16) == True\n    assert comp(1, 1.0000000000000001, 1e-17) == True\n    assert comp(1, 1.0000000000000001, 1e-18) == True\n    assert comp(1, 1.0000000000000001, 1e-19) == True\n    assert comp(1, 1.0000000000000001, 1e-20) == True\n    assert comp(1, 1.0000000000000001, 1e-21) == True\n    assert comp(1, 1.0000000000000001, 1e-22) == True\n    assert comp(1, 1.0000000000000001, 1e-23) == True\n    assert comp(1, 1.0000000000000001, 1e-24) == True\n    assert comp(1, 1.0000000000000001, 1e-25) == True\n    assert comp(1, 1.0000000000000001, 1e-26) == True\n    assert comp(1, 1.0000000000000001, 1e-27) == True\n    assert comp(1, 1.0000000000000001, 1e-28) == True\n    assert comp(1, 1.0000000000000001, 1e-29) == True\n    assert comp(1, 1.0000000000000001, 1e-30) == True\n    assert comp(1, 1.0000000000000001"], "sample_401": ["    def test_management_form(self):\n        formset = ChoiceFormSet()\n        management_form = formset.management_form\n        self.assertIsInstance(management_form, ManagementForm)\n        self.assertEqual(management_form.prefix, \"form\")\n        self.assertEqual(management_form.initial[TOTAL_FORM_COUNT], 1)\n        self.assertEqual(management_form.initial[INITIAL_FORM_COUNT], 0)\n        self.assertEqual(management_form.initial[MIN_NUM_FORM_COUNT], 0)\n        self.assertEqual(management_form.initial[MAX_NUM_FORM_COUNT], 1000)\n"], "sample_1079": ["def test_point():\n    p1 = Point(1, 2)\n    p2 = Point(3, 4)\n    p3 = Point(5, 6)\n    p4 = Point(7, 8)\n    p5 = Point(9, 10)\n    p6 = Point(11, 12)\n\n    # Test Point.affine_rank\n    assert Point.affine_rank(p1, p2, p3) == 2\n    assert Point.affine_rank(p1, p2, p3, p4) == 2\n    assert Point.affine_rank(p1, p2, p3, p4, p5) == 2\n    assert Point.affine_rank(p1, p2, p3, p4, p5, p6) == 2\n\n    # Test Point.are_coplanar\n    assert Point.are_coplanar(p1, p2, p3, p4)\n    assert Point.are_coplanar(p1, p2, p3, p4, p5)\n    assert Point.are_coplanar(p1, p2, p3, p4, p5, p6)\n\n    # Test Point.is_collinear\n    assert Point.is_collinear(p1, p2, p3)\n    assert Point.is_collinear(p1, p2, p3, p4)\n    assert Point.is_collinear(p1, p2, p3, p4, p5)\n    assert Point.is_collinear(p1, p2, p3, p4, p5, p6)\n\n    # Test Point.is_concyclic\n    assert Point.is_concyclic(p1, p2, p3, p4)\n    assert Point.is_concyclic(p1, p2, p3, p4, p5)\n    assert Point.is_concyclic(p1, p2, p3, p4, p5, p6)\n\n    # Test Point.distance\n    assert p1.distance(p2) == 5\n    assert p1.distance(p3) == 5 * sqrt(2)\n    assert p1.distance(p4) == 10\n    assert p1.distance(p5) == 10 * sqrt(2)\n    assert p1.distance(p6) == 15\n\n    # Test Point.dot\n    assert p1.dot(p2) == 11\n    assert p1"], "sample_342": ["def test_process_request_validates_request_parameters(self):\n    request = self.factory.get(self.url, {'term': 'test', 'app_label': 'tests', 'model_name': 'author', 'field_name': 'id'})\n    request.user = self.user\n    view = AutocompleteJsonView.as_view(**self.as_view_args)\n    with model_admin(Author, AuthorAdmin):\n        response = view(request)\n        self.assertEqual(response.status_code, 200)\n\n    # Test missing 'term' parameter\n    request = self.factory.get(self.url, {'app_label': 'tests', 'model_name': 'author', 'field_name': 'id'})\n    request.user = self.user\n    with self.assertRaises(PermissionDenied):\n        view(request)\n\n    # Test missing 'app_label' parameter\n    request = self.factory.get(self.url, {'term': 'test', 'model_name': 'author', 'field_name': 'id'})\n    request.user = self.user\n    with self.assertRaises(PermissionDenied):\n        view(request)\n\n    # Test missing 'model_name' parameter\n    request = self.factory.get(self.url, {'term': 'test', 'app_label': 'tests', 'field_name': 'id'})\n    request.user = self.user\n    with self.assertRaises(PermissionDenied):\n        view(request)\n\n    # Test missing 'field_name' parameter\n    request = self.factory.get(self.url, {'term': 'test', 'app_label': 'tests', 'model_name': 'author'})\n    request.user = self.user\n    with self.assertRaises(PermissionDenied):\n        view(request)\n"], "sample_398": ["    def test_password_reset_view(self):\n        # Test that a valid password reset request is handled correctly\n        response = self.client.post(\n            reverse(\"password_reset\"),\n            {\n                \"email\": self.u1.email,\n            },\n        )\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(len(mail.outbox), 1)\n"], "sample_1107": ["def test_multiset_partitions():\n    # Test multiset_partitions with a multiset\n    multiset = [1, 2, 2, 3, 3, 3]\n    expected_partitions = [\n        [[1, 2, 2, 3, 3, 3]],\n        [[1, 2, 2, 3, 3], [3]],\n        [[1, 2, 2, 3], [3, 3]],\n        [[1, 2, 2], [3, 3, 3]],\n        [[1, 2, 3, 3], [2, 3]],\n        [[1, 2, 3, 3], [3, 2]],\n        [[1, 2, 3], [2, 3, 3]],\n        [[1, 3, 3], [2, 2, 3]],\n        [[1, 3, 3], [2, 3, 2]],\n        [[1, 3], [2, 2, 3, 3]],\n        [[1], [2, 2, 3, 3, 3]],\n        [[2, 2, 3, 3], [1, 3]],\n        [[2, 2, 3], [1, 3, 3]],\n        [[2, 2], [1, 3, 3, 3]],\n        [[2, 3, 3], [1, 2, 3]],\n        [[2, 3], [1, 2, 3, 3]],\n        [[2], [1, 2, 3, 3, 3]],\n        [[3, 3, 3], [1, 2, 2]],\n        [[3, 3], [1, 2, 2, 3]],\n        [[3], [1, 2, 2, 3, 3]],\n        [[], [1, 2, 2, 3, 3, 3]]\n    ]\n    assert sorted(multiset_partitions(multiset)) == expected_partitions\n\n    # Test multiset_partitions with an integer\n    expected_partitions = [\n        [[1, 1, 1, 1, 1, 1]],\n        [[1, 1, 1, 1],"], "sample_383": ["    def test_related_exact_lookup(self):\n        # Test that RelatedExact lookup works correctly\n        self.assertEqual(\n            Item.objects.filter(tags__name__exact=\"t1\").count(),\n            2,\n        )\n"], "sample_444": ["    def test_manifest_version(self):\n        storage = ManifestStaticFilesStorage()\n        self.assertEqual(storage.manifest_version, \"1.1\")\n"], "sample_496": ["    def test_base_command(self):\n        class TestCommand(BaseCommand):\n            help = 'Test command'\n\n                return 'Test output'\n\n        command = TestCommand()\n        output = StringIO()\n        command.execute(stdout=output)\n        self.assertEqual(output.getvalue().strip(), 'Test output')\n"], "sample_126": ["def test_altered_unique_together(self):\n    before_state = self.make_project_state([\n        self.book_foo_together,\n    ])\n    after_state = self.make_project_state([\n        self.book_foo_together_2,\n    ])\n    changes = MigrationAutodetector(before_state, after_state)._detect_changes()\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\"])\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 0, unique_together={(\"title\", \"author\")})\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 1, index_together={(\"title\", \"author\")})\n"], "sample_50": ["    def test_runshell_db_with_sigint_handler(self):\n        \"\"\"\n        Test that the original SIGINT handler is restored after running the shell.\n        \"\"\"\n            raise KeyboardInterrupt\n        with mock.patch('subprocess.run', new=_mock_subprocess_run):\n            with self.assertRaises(KeyboardInterrupt):\n                DatabaseClient.runshell_db({'host': 'localhost', 'database': 'test'})\n        self.assertEqual(signal.getsignal(signal.SIGINT), signal.default_int_handler)\n"], "sample_749": ["def test_transformer_weights():\n    # Test that transformer weights are applied correctly\n    X = np.array([[1, 2, 3], [4, 5, 6]])\n    transformer_weights = {'norm1': 2, 'norm2': 3}\n    ct = ColumnTransformer(\n        [(\"norm1\", Normalizer(norm='l1'), [0, 1]),\n         (\"norm2\", Normalizer(norm='l1'), [2])],\n        transformer_weights=transformer_weights\n    )\n    X_t = ct.fit_transform(X)\n    X_t_expected = np.hstack([\n        2 * Normalizer(norm='l1').fit_transform(X[:, :2]),\n        3 * Normalizer(norm='l1').fit_transform(X[:, 2:])\n    ])\n    assert_allclose_dense_sparse(X_t, X_t_expected)\n\n    # Test that transformer weights are applied correctly when using make_column_transformer\n    ct = make_column_transformer(\n        (['col1', 'col2'], Normalizer(norm='l1')),\n        (['col3'], Normalizer(norm='l1')),\n        transformer_weights={'normalizer': 2}\n    )\n    X = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4], 'col3': [5, 6]})\n    X_t = ct.fit_transform(X)\n    X_t_expected = np.hstack([\n        2 * Normalizer(norm='l1').fit_transform(X[['col1', 'col2']]),\n        Normalizer(norm='l1').fit_transform(X['col3'])\n    ])\n    assert_allclose_dense_sparse(X_t, X_t_expected)\n\n    # Test that transformer weights are applied correctly when using remainder\n    ct = ColumnTransformer(\n        [(\"norm1\", Normalizer(norm='l1'), [0, 1])],\n        remainder='passthrough',\n        transformer_weights={'norm1': 2}\n    )\n    X = np.array([[1, 2, 3], [4, 5, 6]])\n    X_t = ct.fit_transform(X)\n    X_t_expected = np.hstack([\n        2 * Normalizer(norm='l1').fit_transform(X[:, :2]),\n        X[:, 2:]\n    ])\n    assert_allclose_dense_sparse(X_t, X_t_expected)\n"], "sample_402": ["    def test_append_slash_redirect(self):\n        request = self.rf.get(\"/foo\")\n        response = CommonMiddleware().process_request(request)\n        self.assertIsInstance(response, HttpResponsePermanentRedirect)\n        self.assertEqual(response.url, \"http://testserver/foo/\")\n"], "sample_568": ["def test_art3d_text_2d_to_3d():\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    text = Text(0.5, 0.5, 'Hello, world!')\n    art3d.text_2d_to_3d(text, z=0.5, zdir='z')\n    ax.add_artist(text)\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_zlim(0, 1)\n"], "sample_882": ["def test_mlp_regressor_partial_fit():\n    # Test partial_fit for MLPRegressor\n    X, y = make_regression(n_samples=100, n_features=10, random_state=42)\n    regr = MLPRegressor(hidden_layer_sizes=(10,), max_iter=1, warm_start=True)\n    regr.partial_fit(X[:50], y[:50])\n    regr.partial_fit(X[50:], y[50:])\n    assert regr.n_iter_ == 2\n    assert regr.loss_curve_ == [regr.loss_]\n\n    # Test partial_fit with multiple outputs\n    X, y = make_regression(n_samples=100, n_features=10, n_targets=2, random_state=42)\n    regr = MLPRegressor(hidden_layer_sizes=(10,), max_iter=1, warm_start=True)\n    regr.partial_fit(X[:50], y[:50])\n    regr.partial_fit(X[50:], y[50:])\n    assert regr.n_iter_ == 2\n    assert regr.loss_curve_ == [regr.loss_]\n\n    # Test partial_fit with sparse input\n    X, y = make_regression(n_samples=100, n_features=10, random_state=42)\n    X_sparse = csr_matrix(X)\n    regr = MLPRegressor(hidden_layer_sizes=(10,), max_iter=1, warm_start=True)\n    regr.partial_fit(X_sparse[:50], y[:50])\n    regr.partial_fit(X_sparse[50:], y[50:])\n    assert regr.n_iter_ == 2\n    assert regr.loss_curve_ == [regr.loss_]\n\n    # Test partial_fit with early stopping\n    X, y = make_regression(n_samples=100, n_features=10, random_state=42)\n    regr = MLPRegressor(\n        hidden_layer_sizes=(10,),\n        max_iter=100,\n        early_stopping=True,\n        validation_fraction=0.2,\n        n_iter_no_change=5,\n    )\n    regr.partial_fit(X[:50], y[:50])\n    regr.partial_fit(X[50:], y[50:])\n    assert regr.n_iter_ <= 100\n    assert regr.loss_curve_ == [regr.loss_]\n"], "sample_418": ["    def test_truncate_chars(self):\n        output = self.engine.render_to_string(\"truncate_chars01\")\n        self.assertEqual(output, \"This is a \")\n"], "sample_224": ["def test_values_list_with_flat_and_named(self):\n    with self.assertRaises(TypeError):\n        Book.objects.values_list(flat=True, named=True)\n\n    with self.assertRaises(TypeError):\n        Book.objects.values_list('name', flat=True, named=True)\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', flat=True).filter(name='test')\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', named=True).filter(name='test')\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', flat=True).order_by('name')\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', named=True).order_by('name')\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', flat=True).distinct()\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', named=True).distinct()\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', flat=True).reverse()\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', named=True).reverse()\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', flat=True).defer('name')\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', named=True).defer('name')\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', flat=True).only('name')\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', named=True).only('name')\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', flat=True).select_related()\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', named=True).select_related()\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', flat=True).prefetch_related()\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', named=True).prefetch_related()\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', flat=True).annotate()\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', named=True).annotate()\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', flat=True).alias()\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', named=True).alias()\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', flat=True).extra()\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', named=True).extra()\n\n    with self.assertRaises(ValueError):\n        Book.objects.values_list('name', flat=True)."], "sample_683": ["def test_capturemanager_suspend_resume(capsys):\n    capman = capsys.request.config.pluginmanager.getplugin(\"capturemanager\")\n    assert capman.is_capturing() == \"global\"\n    with capman.global_and_fixture_disabled():\n        assert capman.is_capturing() is False\n    assert capman.is_capturing() == \"global\"\n    capman.suspend()\n    assert capman.is_capturing() is False\n    capman.resume()\n    assert capman.is_capturing() == \"global\"\n"], "sample_191": ["    def test_tick(self):\n        reloader = autoreload.StatReloader()\n        ticker = reloader.tick()\n        next(ticker)  # Advance the ticker to the first sleep call.\n        self.assertTrue(reloader.should_stop is False)\n        reloader.stop()\n        self.assertTrue(reloader.should_stop is True)\n"], "sample_285": ["    def test_get_finder(self):\n        finder = get_finder('django.contrib.staticfiles.finders.FileSystemFinder')\n        self.assertIsInstance(finder, BaseFinder)\n"], "sample_512": ["def test_xkcd_context_manager():\n    with plt.xkcd():\n        fig = plt.figure()\n        assert fig.get_label() == ''\n        assert rcParams['font.family'] == ['xkcd', 'xkcd Script', 'Humor Sans', 'Comic Neue', 'Comic Sans MS']\n        assert rcParams['font.size'] == 14.0\n        assert rcParams['path.sketch'] == (1, 100, 2)\n        assert rcParams['path.effects'] == [mpl.patheffects.withStroke(linewidth=4, foreground=\"w\")]\n        assert rcParams['axes.linewidth'] == 1.5\n        assert rcParams['lines.linewidth'] == 2.0\n        assert rcParams['figure.facecolor'] == 'white'\n        assert rcParams['grid.linewidth'] == 0.0\n        assert rcParams['axes.grid'] == False\n        assert rcParams['axes.unicode_minus'] == False\n        assert rcParams['axes.edgecolor'] == 'black'\n        assert rcParams['xtick.major.size'] == 8\n        assert rcParams['xtick.major.width'] == 3\n        assert rcParams['ytick.major.size'] == 8\n        assert rcParams['ytick.major.width'] == 3\n    assert rcParams['font.family'] == mpl.rcParamsDefault['font.family']\n    assert rcParams['font.size'] == mpl.rcParamsDefault['font.size']\n    assert rcParams['path.sketch'] == mpl.rcParamsDefault['path.sketch']\n    assert rcParams['path.effects'] == mpl.rcParamsDefault['path.effects']\n    assert rcParams['axes.linewidth'] == mpl.rcParamsDefault['axes.linewidth']\n    assert rcParams['lines.linewidth'] == mpl.rcParamsDefault['lines.linewidth']\n    assert rcParams['figure.facecolor'] == mpl.rcParamsDefault['figure.facecolor']\n    assert rcParams['grid.linewidth'] == mpl.rcParamsDefault['grid.linewidth']\n    assert rcParams['axes.grid'] == mpl.rcParamsDefault['axes.grid']\n    assert rcParams['axes.unicode_minus'] == mpl.rcParamsDefault['axes.unicode_minus']\n    assert rcParams['axes.edgecolor'] == mpl.rcParamsDefault['axes.edgecolor']\n    assert rcParams['xtick.major.size'] == mpl.rcParamsDefault['xtick.major.size']\n    assert rcParams['xtick.major.width'] == mpl.rcParamsDefault['xtick.major.width']\n    assert rcParams"], "sample_387": ["    def test_get_inline_instances(self):\n        class MyInline(admin.StackedInline):\n            model = Car\n\n        class MyAdmin(admin.ModelAdmin):\n            inlines = [MyInline]\n\n        ma = MyAdmin(Car, admin.site)\n        inline_instances = ma.get_inline_instances(self.client.force_login(self.superuser).get(reverse(\"admin:tests_car_changelist\")).wsgi_request)\n        self.assertEqual(len(inline_instances), 1)\n        self.assertIsInstance(inline_instances[0], MyInline)\n"], "sample_83": ["    def test_filter_registration(self):\n            return value.upper()\n\n        self.library.filter('my_filter', my_filter)\n        self.assertIn('my_filter', self.library.filters)\n        self.assertEqual(self.library.filters['my_filter'], my_filter)\n\n        @self.library.filter('decorated_filter')\n            return value.lower()\n\n        self.assertIn('decorated_filter', self.library.filters)\n        self.assertEqual(self.library.filters['decorated_filter'], decorated_filter)\n\n        @self.library.filter\n            return value.title()\n\n        self.assertIn('another_decorated_filter', self.library.filters)\n        self.assertEqual(self.library.filters['another_decorated_filter'], another_decorated_filter)\n"], "sample_522": ["def test_colorbar_extension_length():\n    fig1 = _colorbar_extension_length('uniform')\n    fig2 = _colorbar_extension_length('proportional')\n    return fig1, fig2\n"], "sample_1030": ["def test_idiff():\n    x = Symbol('x')\n    y = Symbol('y')\n    a = Symbol('a')\n    eq = x**2 + y**2 - 4\n    assert idiff(eq, y, x) == -x/y\n    assert idiff(eq, y, x, 2).simplify() == -(x**2 + y**2)/y**3\n    assert idiff(x + a + y, y, x) == -1\n    assert idiff(x + a + y, [y, a], x) == -Derivative(a, x) - 1\n    assert idiff(x + y, y, x) == -1\n    assert idiff(x + y, y, x, 2) == 0\n    assert idiff(x + y, y, x, 3) == 0\n    assert idiff(x + y, y, x, 4) == 0\n    assert idiff(x + y, y, x, 5) == 0\n    assert idiff(x + y, y, x, 6) == 0\n    assert idiff(x + y, y, x, 7) == 0\n    assert idiff(x + y, y, x, 8) == 0\n    assert idiff(x + y, y, x, 9) == 0\n    assert idiff(x + y, y, x, 10) == 0\n    assert idiff(x + y, y, x, 11) == 0\n    assert idiff(x + y, y, x, 12) == 0\n    assert idiff(x + y, y, x, 13) == 0\n    assert idiff(x + y, y, x, 14) == 0\n    assert idiff(x + y, y, x, 15) == 0\n    assert idiff(x + y, y, x, 16) == 0\n    assert idiff(x + y, y, x, 17) == 0\n    assert idiff(x + y, y, x, 18) == 0\n    assert idiff(x + y, y, x, 19) == 0\n    assert idiff(x + y, y, x, 20) == 0\n"], "sample_143": ["def test_slugify(self):\n    self.assertEqual(text.slugify('Hello World'), 'hello-world')\n    self.assertEqual(text.slugify('\u00a1Hola Mundo!'), 'hola-mundo')\n    self.assertEqual(text.slugify('\u00a1Hola Mundo!', allow_unicode=True), '\u00a1hola-mundo!')\n    self.assertEqual(text.slugify(' foo bar '), 'foo-bar')\n    self.assertEqual(text.slugify('foo@bar.com'), 'foobarcom')\n    self.assertEqual(text.slugify('foo!bar.com'), 'foobarcom')\n    self.assertEqual(text.slugify('foo-bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo_bar.com'), 'foobarcom')\n    self.assertEqual(text.slugify('foo bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo-bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo_bar.com'), 'foobarcom')\n    self.assertEqual(text.slugify('foo bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo-bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo_bar.com'), 'foobarcom')\n    self.assertEqual(text.slugify('foo bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo-bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo_bar.com'), 'foobarcom')\n    self.assertEqual(text.slugify('foo bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo-bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo_bar.com'), 'foobarcom')\n    self.assertEqual(text.slugify('foo bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo-bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo_bar.com'), 'foobarcom')\n    self.assertEqual(text.slugify('foo bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo-bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo_bar.com'), 'foobarcom')\n    self.assertEqual(text.slugify('foo bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo-bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo_bar.com'), 'foobarcom')\n    self.assertEqual(text.slugify('foo bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo-bar.com'), 'foo-barcom')\n    self.assertEqual(text.slugify('foo_bar.com'),"], "sample_893": ["def test_export_text():\n    # Test export_text with a decision tree classifier\n    clf = DecisionTreeClassifier(random_state=0, max_depth=2)\n    clf.fit(X, y)\n    report = export_text(clf, feature_names=[\"feature_0\", \"feature_1\"])\n    assert \"class: 1\" in report\n    assert \"class: -1\" in report\n\n    # Test export_text with a decision tree regressor\n    reg = DecisionTreeRegressor(random_state=0, max_depth=2)\n    reg.fit(X, y)\n    report = export_text(reg, feature_names=[\"feature_0\", \"feature_1\"])\n    assert \"value: [\" in report\n\n    # Test export_text with a multi-output decision tree regressor\n    reg = DecisionTreeRegressor(random_state=0, max_depth=2)\n    reg.fit(X, y2)\n    report = export_text(reg, feature_names=[\"feature_0\", \"feature_1\"])\n    assert \"value: [\" in report\n\n    # Test export_text with a decision tree classifier and class names\n    clf = DecisionTreeClassifier(random_state=0, max_depth=2)\n    clf.fit(X, y)\n    report = export_text(clf, feature_names=[\"feature_0\", \"feature_1\"], class_names=[\"class_0\", \"class_1\"])\n    assert \"class: class_1\" in report\n    assert \"class: class_0\" in report\n\n    # Test export_text with a decision tree classifier and show_weights\n    clf = DecisionTreeClassifier(random_state=0, max_depth=2)\n    clf.fit(X, y, sample_weight=w)\n    report = export_text(clf, feature_names=[\"feature_0\", \"feature_1\"], show_weights=True)\n    assert \"weights: [\" in report\n\n    # Test export_text with a decision tree classifier and max_depth\n    clf = DecisionTreeClassifier(random_state=0, max_depth=2)\n    clf.fit(X, y)\n    report = export_text(clf, feature_names=[\"feature_0\", \"feature_1\"], max_depth=1)\n    assert \"truncated branch of depth\" in report\n\n    # Test export_text with a decision tree classifier and decimals\n    clf = DecisionTreeClassifier(random_state=0, max_depth=2)\n    clf.fit(X, y)\n    report = export_text(clf, feature_names=[\"feature_0\", \"feature_1\"], decimals="], "sample_902": ["def test_pipeline_inverse_transform():\n    # Test that inverse_transform works correctly in a pipeline\n    X = np.array([[1, 2], [3, 4]])\n    pipeline = Pipeline([('mult', Mult(mult=2)), ('mult2', Mult(mult=3))])\n    Xt = pipeline.fit_transform(X)\n    X_inv = pipeline.inverse_transform(Xt)\n    assert_array_almost_equal(X_inv, X)\n"], "sample_641": ["def test_load_results(tmp_path):\n    # Create a temporary file with a valid LinterStats object\n    data_file = tmp_path / \"test.stats\"\n    results = LinterStats()\n    results.error = 1\n    results.warning = 2\n    with open(data_file, \"wb\") as stream:\n        pickle.dump(results, stream)\n\n    # Test loading the results\n    loaded_results = load_results(data_file, tmp_path)\n    assert loaded_results.error == 1\n    assert loaded_results.warning == 2\n\n    # Test loading a non-existent file\n    assert load_results(tmp_path / \"non_existent_file\", tmp_path) is None\n\n    # Test loading a file with invalid data\n    with open(data_file, \"wb\") as stream:\n        pickle.dump(\"Invalid data\", stream)\n    with pytest.warns(UserWarning):\n        assert load_results(data_file, tmp_path) is None\n\n    # Test loading a file with an exception\n    with open(data_file, \"wb\") as stream:\n        pickle.dump(b\"Invalid data\", stream)\n    assert load_results(data_file, tmp_path) is None\n"], "sample_29": ["def test_write_latex_parameter_units(tmp_path):\n    \"\"\"\n    Test that the units of the cosmology parameters are correctly written to LaTeX.\n    \"\"\"\n    from astropy.cosmology import FlatLambdaCDM\n    from astropy import units as u\n\n    # Create a cosmology instance with a non-standard unit for H0\n    cosmo = FlatLambdaCDM(H0=70 * u.km / (u.s * u.Mpc), Om0=0.3)\n\n    # Write the cosmology to a LaTeX file\n    file = tmp_path / \"cosmology.tex\"\n    write_latex(cosmo, file)\n\n    # Check that the unit of H0 is correctly written to the LaTeX file\n    with open(file, \"r\") as f:\n        latex = f.read()\n    assert r\"$\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$\" in latex\n"], "sample_544": ["def test_nonuniform_image():\n    fig, ax = plt.subplots()\n    x = np.linspace(0, 10, 10)\n    y = np.linspace(0, 10, 20)\n    A = np.random.rand(20, 10)\n    im = NonUniformImage(ax, x, y, A, cmap='viridis')\n    ax.add_image(im)\n    ax.set_xlim(0, 10)\n    ax.set_ylim(0, 10)\n    ax.set_aspect('auto')\n"], "sample_638": ["def test_run_with_invalid_output_format(mock_graphviz, capsys):\n    \"\"\"Test that an error message is printed when the output format is not supported.\"\"\"\n    with pytest.raises(SystemExit) as exit_info:\n        main.Run([\"-o\", \"invalid_format\", \"test_module\"])\n    assert exit_info.value == 1\n    captured = capsys.readouterr()\n    assert \"Format invalid_format is not supported natively. Pyreverse will try to generate it using Graphviz...\" in captured.out\n\n"], "sample_210": ["    def test_template_view_context(self):\n        class TestTemplateView(TemplateView):\n            extra_context = {'foo': 'bar'}\n\n                kwargs['baz'] = 'qux'\n                return super().get_context_data(**kwargs)\n\n        view = TestTemplateView()\n        request = self.rf.get('/')\n        view.setup(request)\n        context = view.get_context_data()\n        self.assertEqual(context, {'foo': 'bar', 'baz': 'qux', 'view': view})\n"], "sample_478": ["    def test_raw_id_fields_item(self):\n        class MyModelAdmin(admin.ModelAdmin):\n            raw_id_fields = [\"nonexistent_field\"]\n\n        self.assertIsInvalid(\n            MyModelAdmin,\n            ValidationTestModel,\n            \"The value of 'raw_id_fields[0]' refers to 'nonexistent_field', \"\n            \"which is not a field of 'validationtestmodel'.\",\n            id=\"admin.E002\",\n        )\n"], "sample_428": ["def test_format_decimal(self):\n    # Test formatting of Decimal instances\n    number = Decimal('123456.789012')\n    self.assertEqual(nformat(number, decimal_sep='.', decimal_pos=2), '123,456.79')\n    self.assertEqual(nformat(number, decimal_sep=',', decimal_pos=2), '123.456,79')\n    self.assertEqual(nformat(number, decimal_sep='.', decimal_pos=4), '123,456.7890')\n    self.assertEqual(nformat(number, decimal_sep=',', decimal_pos=4), '123.456,7890')\n\n    # Test formatting of very large/small Decimal instances\n    number = Decimal('1.23456789012345678901234567890123456789')\n    self.assertEqual(nformat(number, decimal_sep='.', decimal_pos=2), '1.23e+29')\n    number = Decimal('0.0000000000000000000000000000000000000123456789')\n    self.assertEqual(nformat(number, decimal_sep='.', decimal_pos=2), '1.23e-29')\n\n    # Test formatting of Decimal instances with scientific notation\n    number = Decimal('1.23456789e+30')\n    self.assertEqual(nformat(number, decimal_sep='.', decimal_pos=2), '1.23e+30')\n    number = Decimal('1.23456789e-30')\n    self.assertEqual(nformat(number, decimal_sep='.', decimal_pos=2), '1.23e-30')\n"], "sample_805": ["def test_mean_squared_log_error():\n    y_true = np.array([1, 2, 3, 4])\n    y_pred = np.array([1, 2, 3, 4])\n    assert_almost_equal(mean_squared_log_error(y_true, y_pred), 0.0)\n\n    y_true = np.array([1, 2, 3, 4])\n    y_pred = np.array([2, 3, 4, 5])\n    assert_almost_equal(mean_squared_log_error(y_true, y_pred), 0.0198, decimal=3)\n\n    y_true = np.array([1, 2, 3, 4])\n    y_pred = np.array([0.5, 1, 1.5, 2])\n    assert_almost_equal(mean_squared_log_error(y_true, y_pred), 0.0198, decimal=3)\n\n    y_true = np.array([[1, 2], [3, 4]])\n    y_pred = np.array([[1, 2], [3, 4]])\n    assert_array_almost_equal(mean_squared_log_error(y_true, y_pred, multioutput='raw_values'), np.array([0.0, 0.0]))\n\n    y_true = np.array([[1, 2], [3, 4]])\n    y_pred = np.array([[2, 3], [4, 5]])\n    assert_almost_equal(mean_squared_log_error(y_true, y_pred), 0.0198, decimal=3)\n\n    y_true = np.array([[1, 2], [3, 4]])\n    y_pred = np.array([[0.5, 1], [1.5, 2]])\n    assert_almost_equal(mean_squared_log_error(y_true, y_pred), 0.0198, decimal=3)\n\n    # Test with sample weights\n    y_true = np.array([1, 2, 3, 4])\n    y_pred = np.array([2, 3, 4, 5])\n    sample_weight = np.array([0.1, 0.2, 0.3, 0.4])\n    assert_almost_equal(mean_squared_log_error(y_true, y_pred, sample_weight=sample_weight), 0.0249, decimal=3)\n\n    # Test with multioutput and sample weights\n    y_true = np.array([[1, 2], [3, 4]])\n    y_pred"], "sample_700": ["def test_parametrize_id_generation_with_custom_id_function(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n            return f\"custom_id_{value}\"\n\n        @pytest.mark.parametrize(\"x\", [1, 2, 3], ids=id_function)\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-v\")\n    result.assert_outcomes(passed=3)\n    result.stdout.fnmatch_lines([\"*test_parametrized[custom_id_1]*\", \"*test_parametrized[custom_id_2]*\", \"*test_parametrized[custom_id_3]*\"])\n"], "sample_278": ["    def test_filtered_relation_init(self):\n        relation_name = 'test_relation'\n        condition = Q()\n        fr = FilteredRelation(relation_name, condition=condition)\n        self.assertEqual(fr.relation_name, relation_name)\n        self.assertEqual(fr.condition, condition)\n        self.assertIsNone(fr.alias)\n        self.assertEqual(fr.path, [])\n"], "sample_147": ["    def test_union_with_empty_querysets(self):\n        qs1 = Number.objects.all()\n        qs2 = Number.objects.none()\n        qs3 = Number.objects.none()\n\n        # Test union of two empty querysets\n        self.assertNumbersEqual(qs2.union(qs3), [])\n\n        # Test union of a non-empty queryset with an empty queryset\n        self.assertNumbersEqual(qs1.union(qs2), list(range(10)))\n\n        # Test union of an empty queryset with a non-empty queryset\n        self.assertNumbersEqual(qs2.union(qs1), list(range(10)))\n\n        # Test union of three querysets, two of which are empty\n        self.assertNumbersEqual(qs1.union(qs2, qs3), list(range(10)))\n"], "sample_865": ["def test_prune_tree():\n    # Test pruning of decision tree\n    X, y = iris.data, iris.target\n    clf = DecisionTreeClassifier(random_state=0)\n    clf.fit(X, y)\n\n    # Prune the tree\n    ccp_alpha = 0.01\n    clf_pruned = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n    clf_pruned.fit(X, y)\n\n    # Check that the pruned tree has fewer nodes\n    assert clf_pruned.tree_.node_count < clf.tree_.node_count\n\n    # Check that the pruned tree has the same feature importances\n    assert_array_almost_equal(clf_pruned.feature_importances_, clf.feature_importances_)\n\n    # Check that the pruned tree has the same classes\n    assert_array_equal(clf_pruned.classes_, clf.classes_)\n\n    # Check that the pruned tree has the same n_classes\n    assert_array_equal(clf_pruned.n_classes_, clf.n_classes_)\n\n    # Check that the pruned tree has the same n_features\n    assert clf_pruned.n_features_ == clf.n_features_\n\n    # Check that the pruned tree has the same n_outputs\n    assert clf_pruned.n_outputs_ == clf.n_outputs_\n\n    # Check that the pruned tree has the same tree structure\n    assert_tree_equal(clf_pruned.tree_, clf.tree_, \"Pruned tree structure\")\n\n    # Test pruning of decision tree regressor\n    X, y = boston.data, boston.target\n    reg = DecisionTreeRegressor(random_state=0)\n    reg.fit(X, y)\n\n    # Prune the tree\n    ccp_alpha = 0.01\n    reg_pruned = DecisionTreeRegressor(random_state=0, ccp_alpha=ccp_alpha)\n    reg_pruned.fit(X, y)\n\n    # Check that the pruned tree has fewer nodes\n    assert reg_pruned.tree_.node_count < reg.tree_.node_count\n\n    # Check that the pruned tree has the same feature importances\n    assert_array_almost_equal(reg_pruned.feature_importances_, reg.feature_importances_)\n\n    # Check that the pruned tree has the same n_features\n    assert reg_pruned.n_features_ == reg.n_features_\n\n    # Check that the pruned tree has the same n_outputs\n    assert reg_pruned.n_outputs_ == reg.n_outputs_\n\n    # Check that the pruned tree has the same tree structure\n"], "sample_205": ["def test_validation_error_init_with_dict(self):\n    error_dict = {\n        'field1': ['error1', 'error2'],\n        'field2': ValidationError(['error3', 'error4'])\n    }\n    validation_error = ValidationError(error_dict)\n    self.assertEqual(len(validation_error.error_dict), 2)\n    self.assertEqual(len(validation_error.error_dict['field1']), 2)\n    self.assertEqual(len(validation_error.error_dict['field2']), 2)\n    self.assertIsInstance(validation_error.error_dict['field1'][0], ValidationError)\n    self.assertIsInstance(validation_error.error_dict['field2'][0], ValidationError)\n"], "sample_733": ["def test_tfidfvectorizer():\n    # Test that TfidfVectorizer produces the same output as CountVectorizer\n    # followed by TfidfTransformer\n    vectorizer = TfidfVectorizer()\n    transformer = TfidfTransformer()\n    count_vectorizer = CountVectorizer()\n\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n    X_count = count_vectorizer.fit_transform(ALL_FOOD_DOCS)\n    X_count_tfidf = transformer.fit_transform(X_count)\n\n    assert_array_almost_equal(X.toarray(), X_count_tfidf.toarray())\n\n    # Test that TfidfVectorizer produces the same output as CountVectorizer\n    # followed by TfidfTransformer when using a custom vocabulary\n    vocab = ['pizza', 'burger', 'beer', 'salad', 'water']\n    vectorizer = TfidfVectorizer(vocabulary=vocab)\n    transformer = TfidfTransformer()\n    count_vectorizer = CountVectorizer(vocabulary=vocab)\n\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n    X_count = count_vectorizer.fit_transform(ALL_FOOD_DOCS)\n    X_count_tfidf = transformer.fit_transform(X_count)\n\n    assert_array_almost_equal(X.toarray(), X_count_tfidf.toarray())\n\n    # Test that TfidfVectorizer produces the same output as CountVectorizer\n    # followed by TfidfTransformer when using a custom analyzer\n    vectorizer = TfidfVectorizer(analyzer=split_tokenize)\n    transformer = TfidfTransformer()\n    count_vectorizer = CountVectorizer(analyzer=split_tokenize)\n\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n    X_count = count_vectorizer.fit_transform(ALL_FOOD_DOCS)\n    X_count_tfidf = transformer.fit_transform(X_count)\n\n    assert_array_almost_equal(X.toarray(), X_count_tfidf.toarray())\n\n    # Test that TfidfVectorizer produces the same output as CountVectorizer\n    # followed by TfidfTransformer when using a custom preprocessor\n    vectorizer = TfidfVectorizer(preprocessor=uppercase)\n    transformer = TfidfTransformer()\n    count_vectorizer = CountVectorizer(preprocessor=uppercase)\n\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n    X_count = count_vectorizer.fit_transform(ALL_FOOD_DOCS)\n    X_count_tfidf = transformer.fit_transform(X_count)\n\n    assert_array_almost_equal(X.toarray(), X_count_tfidf.toarray())\n\n    # Test that TfidfVectorizer produces the same output as CountVectorizer\n    # followed by TfidfTransformer when using a"], "sample_172": ["    def test_get_field_queryset_with_ordering(self):\n        class MyModelAdmin(admin.ModelAdmin):\n            ordering = ['name']\n\n        ma = MyModelAdmin(Band, admin.site)\n        queryset = ma.get_field_queryset(None, Band._meta.get_field('members'), None)\n        self.assertEqual(queryset.query.order_by, ['name'])\n"], "sample_66": ["def test_get_signed_cookie(self):\n    request = HttpRequest()\n    request.COOKIES = {'test_cookie': 'test_value'}\n    with self.settings(SESSION_COOKIE_SALT='test_salt'):\n        self.assertEqual(request.get_signed_cookie('test_cookie', salt='test_salt'), 'test_value')\n        self.assertIsNone(request.get_signed_cookie('nonexistent_cookie', default=None, salt='test_salt'))\n        with self.assertRaises(signing.BadSignature):\n            request.get_signed_cookie('test_cookie', salt='wrong_salt')\n"], "sample_642": ["def test_preprocess_options() -> None:\n    \"\"\"Test the _preprocess_options function.\"\"\"\n    run = mock.Mock(spec=Run)\n    args = [\"--init-hook=print('Hello World')\", \"--rcfile=pylintrc\", \"--output=output.txt\", \"--load-plugins=plugin1,plugin2\", \"--verbose\", \"-v\", \"--enable-all-extensions\"]\n\n    processed_args = config._preprocess_options(run, args)\n\n    assert processed_args == []\n    assert run._rcfile == \"pylintrc\"\n    assert run._output == \"output.txt\"\n    assert run._plugins == [\"plugin1\", \"plugin2\"]\n    assert run.verbose is True\n\n    with pytest.raises(config.ArgumentPreprocessingError):\n        config._preprocess_options(run, [\"--init-hook\"])\n\n    with pytest.raises(config.ArgumentPreprocessingError):\n        config._preprocess_options(run, [\"--rcfile\"])\n\n    with pytest.raises(config.ArgumentPreprocessingError):\n        config._preprocess_options(run, [\"--output\"])\n\n    with pytest.raises(config.ArgumentPreprocessingError):\n        config._preprocess_options(run, [\"--load-plugins\"])\n\n    with pytest.raises(config.ArgumentPreprocessingError):\n        config._preprocess_options(run, [\"--verbose=value\"])\n\n    with pytest.raises(config.ArgumentPreprocessingError):\n        config._preprocess_options(run, [\"-v=value\"])\n\n    with pytest.raises(config.ArgumentPreprocessingError):\n        config._preprocess_options(run, [\"--enable-all-extensions=value\"])\n"], "sample_558": ["def test_imagegrid_cbar_mode():\n    fig = plt.figure(figsize=(8, 6))\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode=\"each\", cbar_location=\"right\")\n    for ax in grid:\n        ax.imshow(np.random.rand(10, 10), cmap=\"viridis\")\n    for ax, cax in zip(grid.axes_all, grid.cbar_axes):\n        fig.colorbar(ax.images[0], cax=cax)\n    assert len(grid.cbar_axes) == 4\n\n    fig = plt.figure(figsize=(8, 6))\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode=\"single\", cbar_location=\"right\")\n    for ax in grid:\n        ax.imshow(np.random.rand(10, 10), cmap=\"viridis\")\n    fig.colorbar(grid.axes_all[0].images[0], cax=grid.cbar_axes[0])\n    assert len(grid.cbar_axes) == 1\n\n    fig = plt.figure(figsize=(8, 6))\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode=\"edge\", cbar_location=\"right\")\n    for ax in grid:\n        ax.imshow(np.random.rand(10, 10), cmap=\"viridis\")\n    for ax, cax in zip(grid.axes_all, grid.cbar_axes):\n        fig.colorbar(ax.images[0], cax=cax)\n    assert len(grid.cbar_axes) == 2\n\n    fig = plt.figure(figsize=(8, 6))\n    grid = ImageGrid(fig, 111, (2, 2), cbar_mode=None, cbar_location=\"right\")\n    for ax in grid:\n        ax.imshow(np.random.rand(10, 10), cmap=\"viridis\")\n    assert len(grid.cbar_axes) == 4\n    for cax in grid.cbar_axes:\n        assert not cax.get_visible()\n"], "sample_259": ["    def test_prefetch_related_objects_with_prefetch(self):\n        prefetch = Prefetch('books_read', queryset=Book.objects.all())\n        prefetch_related_objects([self.reader1, self.reader2], prefetch)\n        self.assertEqual(len(self.reader1.books_read.all()), 2)\n        self.assertEqual(len(self.reader2.books_read.all()), 2)\n        self.assertEqual(self.reader1.books_read.all()[0].title, 'Poems')\n        self.assertEqual(self.reader1.books_read.all()[1].title, 'Sense and Sensibility')\n        self.assertEqual(self.reader2.books_read.all()[0].title, 'Jane Eyre')\n        self.assertEqual(self.reader2.books_read.all()[1].title, 'Sense and Sensibility')\n"], "sample_634": ["    def test_expand_modules_with_files(self) -> None:\n        files_or_modules = [\"file1.py\", \"file2.py\", \"file3.py\"]\n        ignore_list_re = [re.compile(r\"^file1\\.py$\")]\n        ignore_list_paths_re = [re.compile(r\"^/path/to/file2\\.py$\")]\n        result, errors = expand_modules(\n            files_or_modules, get_global_option(\"ignore\"), ignore_list_re, ignore_list_paths_re\n        )\n        assert len(result) == 1\n        assert result[0][\"name\"] == \"file3\"\n        assert len(errors) == 0\n"], "sample_152": ["def test_collector_add_dependency(self):\n    collector = Collector(using='default')\n    model1 = A\n    model2 = B\n    collector.add_dependency(model1, model2)\n    self.assertIn(model1._meta.concrete_model, collector.dependencies)\n    self.assertIn(model2._meta.concrete_model, collector.dependencies[model1._meta.concrete_model])\n\n    collector.add_dependency(model2, model1, reverse_dependency=True)\n    self.assertIn(model2._meta.concrete_model, collector.dependencies)\n    self.assertIn(model1._meta.concrete_model, collector.dependencies[model2._meta.concrete_model])\n"], "sample_323": ["    def test_migration_plan_with_clean_start(self):\n        \"\"\"\n        Test that migration_plan with clean_start=True returns the correct plan.\n        \"\"\"\n        # Create a test migration graph\n        graph = MigrationGraph()\n        graph.add_node((\"app1\", \"0001_initial\"), dependencies=[])\n        graph.add_node((\"app1\", \"0002_add_field\"), dependencies=[(\"app1\", \"0001_initial\")])\n        graph.add_node((\"app2\", \"0001_initial\"), dependencies=[])\n        graph.add_node((\"app2\", \"0002_add_field\"), dependencies=[(\"app2\", \"0001_initial\")])\n\n        # Create a MigrationLoader with the test migration graph\n        loader = MigrationLoader(connection)\n        loader.graph = graph\n\n        # Create a MigrationExecutor with the test MigrationLoader\n        executor = MigrationExecutor(connection)\n        executor.loader = loader\n\n        # Test that migration_plan with clean_start=True returns the correct plan\n        targets = [(\"app1\", \"0002_add_field\"), (\"app2\", \"0002_add_field\")]\n        plan = executor.migration_plan(targets, clean_start=True)\n        self.assertEqual(len(plan), 4)\n        self.assertEqual(plan[0][0].app_label, \"app1\")\n        self.assertEqual(plan[0][0].name, \"0001_initial\")\n        self.assertEqual(plan[1][0].app_label, \"app1\")\n        self.assertEqual(plan[1][0].name, \"0002_add_field\")\n        self.assertEqual(plan[2][0].app_label, \"app2\")\n        self.assertEqual(plan[2][0].name, \"0001_initial\")\n        self.assertEqual(plan[3][0].app_label, \"app2\")\n        self.assertEqual(plan[3][0].name, \"0002_add_field\")\n"], "sample_292": ["def test_origin_verified(self):\n    # Test that the origin is verified correctly\n    middleware = CsrfViewMiddleware()\n    request = self._get_GET_csrf_cookie_request()\n    request.META['HTTP_ORIGIN'] = 'https://example.com'\n    self.assertTrue(middleware._origin_verified(request))\n\n    # Test that the origin is not verified when it's not in the trusted origins\n    request.META['HTTP_ORIGIN'] = 'https://other.com'\n    self.assertFalse(middleware._origin_verified(request))\n\n    # Test that the origin is verified when it's a subdomain of a trusted origin\n    request.META['HTTP_ORIGIN'] = 'https://sub.example.com'\n    middleware.csrf_trusted_origins_hosts = ['example.com']\n    self.assertTrue(middleware._origin_verified(request))\n\n    # Test that the origin is not verified when it's not a subdomain of a trusted origin\n    request.META['HTTP_ORIGIN'] = 'https://sub.other.com'\n    self.assertFalse(middleware._origin_verified(request))\n\n    # Test that the origin is verified when it's an exact match of a trusted origin\n    request.META['HTTP_ORIGIN'] = 'https://example.com'\n    middleware.allowed_origins_exact = {'https://example.com'}\n    self.assertTrue(middleware._origin_verified(request))\n\n    # Test that the origin is not verified when it's not an exact match of a trusted origin\n    request.META['HTTP_ORIGIN'] = 'https://other.com'\n    self.assertFalse(middleware._origin_verified(request))\n"], "sample_167": ["def test_naturaltime_filter(self):\n    with override_settings(USE_TZ=True):\n        with translation.override('en'):\n            # Test past dates\n            past_date = datetime.date(2022, 3, 8)\n            self.assertEqual(humanize.naturaltime(past_date), '1 day ago')\n            past_date = datetime.date(2022, 3, 7)\n            self.assertEqual(humanize.naturaltime(past_date), '2 days ago')\n            past_date = datetime.date(2022, 3, 1)\n            self.assertEqual(humanize.naturaltime(past_date), '8 days ago')\n            past_date = datetime.date(2022, 2, 28)\n            self.assertEqual(humanize.naturaltime(past_date), '9 days ago')\n            past_date = datetime.date(2022, 2, 27)\n            self.assertEqual(humanize.naturaltime(past_date), '10 days ago')\n            past_date = datetime.date(2022, 2, 26)\n            self.assertEqual(humanize.naturaltime(past_date), '11 days ago')\n            past_date = datetime.date(2022, 2, 25)\n            self.assertEqual(humanize.naturaltime(past_date), '12 days ago')\n            past_date = datetime.date(2022, 2, 24)\n            self.assertEqual(humanize.naturaltime(past_date), '13 days ago')\n            past_date = datetime.date(2022, 2, 23)\n            self.assertEqual(humanize.naturaltime(past_date), '14 days ago')\n            past_date = datetime.date(2022, 2, 22)\n            self.assertEqual(humanize.naturaltime(past_date), '15 days ago')\n            past_date = datetime.date(2022, 2, 21)\n            self.assertEqual(humanize.naturaltime(past_date), '16 days ago')\n            past_date = datetime.date(2022, 2, 20)\n            self.assertEqual(humanize.naturaltime(past_date), '17 days ago')\n            past_date = datetime.date(2022, 2, 19)\n            self.assertEqual(humanize.naturaltime(past_date), '18 days ago')\n            past_date = datetime.date(2022, 2, 18)\n            self.assertEqual(humanize.naturaltime(past_date), '19 days ago')\n            past"], "sample_447": ["def test_expression_wrapper(self):\n    expr = ExpressionWrapper(F('name'), output_field=CharField())\n    self.assertIsInstance(expr, Expression)\n    self.assertIsInstance(expr, SQLiteNumericMixin)\n    self.assertEqual(expr.output_field.get_internal_type(), 'CharField')\n\n    expr = ExpressionWrapper(Func(F('name'), function='UPPER'), output_field=CharField())\n    self.assertIsInstance(expr, Expression)\n    self.assertIsInstance(expr, SQLiteNumericMixin)\n    self.assertEqual(expr.output_field.get_internal_type(), 'CharField')\n\n    with self.assertRaises(FieldError):\n        ExpressionWrapper(Func(F('name'), function='UPPER'), output_field=IntegerField())\n"], "sample_890": ["def test_sequential_feature_selector_backward_selection():\n    # Test backward selection with a classifier\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5, n_redundant=3, random_state=42)\n    estimator = KNeighborsClassifier()\n    sfs = SequentialFeatureSelector(estimator, n_features_to_select=5, direction=\"backward\")\n    sfs.fit(X, y)\n    assert sfs.n_features_to_select_ == 5\n    assert_array_equal(sfs.support_.sum(), 5)\n\n    # Test backward selection with a regressor\n    X, y = make_regression(n_samples=100, n_features=10, n_informative=5, random_state=42)\n    estimator = LinearRegression()\n    sfs = SequentialFeatureSelector(estimator, n_features_to_select=5, direction=\"backward\")\n    sfs.fit(X, y)\n    assert sfs.n_features_to_select_ == 5\n    assert_array_equal(sfs.support_.sum(), 5)\n\n    # Test backward selection with a clusterer\n    X, _ = make_blobs(n_samples=100, n_features=10, centers=3, random_state=42)\n    estimator = KMeans(n_clusters=3)\n    sfs = SequentialFeatureSelector(estimator, n_features_to_select=5, direction=\"backward\")\n    sfs.fit(X)\n    assert sfs.n_features_to_select_ == 5\n    assert_array_equal(sfs.support_.sum(), 5)\n"], "sample_378": ["    def test_bulk_update_with_aggregate(self):\n        self.create_tags()\n        for note in self.notes:\n            note.tags.add(self.tags[0])\n        Note.objects.bulk_update(self.notes, fields=['note'], updates=[F('note').lower()])\n        self.notes = list(Note.objects.all())\n        for note in self.notes:\n            self.assertEqual(note.note, note.note.lower())\n"], "sample_175": ["def test_collector_add_dependency(self):\n    collector = Collector(using='default')\n    model1 = A\n    model2 = B\n    collector.add_dependency(model1, model2)\n    self.assertIn(model2._meta.concrete_model, collector.dependencies[model1._meta.concrete_model])\n    self.assertIn(model2, collector.data)\n\n    collector = Collector(using='default')\n    model1 = A\n    model2 = B\n    collector.add_dependency(model1, model2, reverse_dependency=True)\n    self.assertIn(model1._meta.concrete_model, collector.dependencies[model2._meta.concrete_model])\n    self.assertIn(model1, collector.data)\n"], "sample_493": ["def test_query_set_annotation_mask(self):\n    # Create a query with annotations\n    query = Book.objects.annotate(avg_rating=Avg(\"rating\"))\n\n    # Test that the annotation is included in the annotation mask\n    self.assertIn(\"avg_rating\", query.annotation_select)\n\n    # Test that the annotation is not included in the annotation mask when masked\n    query.set_annotation_mask(())\n    self.assertNotIn(\"avg_rating\", query.annotation_select)\n\n    # Test that the annotation is included in the annotation mask when unmasked\n    query.set_annotation_mask([\"avg_rating\"])\n    self.assertIn(\"avg_rating\", query.annotation_select)\n\n    # Test that multiple annotations are included in the annotation mask\n    query = Book.objects.annotate(avg_rating=Avg(\"rating\"), max_pages=Max(\"pages\"))\n    query.set_annotation_mask([\"avg_rating\", \"max_pages\"])\n    self.assertIn(\"avg_rating\", query.annotation_select)\n    self.assertIn(\"max_pages\", query.annotation_select)\n\n    # Test that annotations are not included in the annotation mask when not specified\n    query = Book.objects.annotate(avg_rating=Avg(\"rating\"), max_pages=Max(\"pages\"))\n    query.set_annotation_mask([\"avg_rating\"])\n    self.assertIn(\"avg_rating\", query.annotation_select)\n    self.assertNotIn(\"max_pages\", query.annotation_select)\n"], "sample_960": ["def test_parse_annotation():\n    env = Mock(spec=['config'])\n    env.config.python_use_unqualified_type_names = False\n\n    # Test simple type\n    annotation = 'int'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'int'\n\n    # Test type with module\n    annotation = 'module.Type'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 1\n    assert isinstance(result[0], pending_xref)\n    assert result[0].attributes['reftarget'] == 'module.Type'\n\n    # Test type with module and unqualified type names\n    env.config.python_use_unqualified_type_names = True\n    annotation = 'module.Type'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 2\n    assert isinstance(result[0], pending_xref_condition)\n    assert result[0].attributes['condition'] == 'resolved'\n    assert isinstance(result[1], pending_xref_condition)\n    assert result[1].attributes['condition'] == '*'\n\n    # Test nested type\n    annotation = 'List[int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 3\n    assert isinstance(result[0], desc_sig_punctuation)\n    assert result[0].astext() == '['\n    assert isinstance(result[1], pending_xref)\n    assert result[1].attributes['reftarget'] == 'int'\n    assert isinstance(result[2], desc_sig_punctuation)\n    assert result[2].astext() == ']'\n\n    # Test type with multiple arguments\n    annotation = 'Dict[str, int]'\n    result = _parse_annotation(annotation, env)\n    assert len(result) == 5\n    assert isinstance(result[0], desc_sig_punctuation)\n    assert result[0].astext() == '['\n    assert isinstance(result[1], pending_xref)\n    assert result[1].attributes['reftarget'] == 'str'\n    assert isinstance(result[2], desc_sig_punctuation)\n    assert result[2].astext() == ', '\n    assert isinstance(result[3], pending_xref)\n    assert result[3].attributes['reftarget'] == 'int'\n    assert isinstance(result[4], desc_sig_punctuation)\n    assert result[4].ast"], "sample_892": ["def test_adaboost_regressor_loss():\n    # Test that the loss parameter is validated correctly\n    with pytest.raises(ValueError, match=\"loss must be one of\"):\n        AdaBoostRegressor(loss=\"invalid_loss\")\n\n    # Test that the loss parameter is used correctly\n    X, y = diabetes.data, diabetes.target\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.5, random_state=rng\n    )\n\n    for loss in [\"linear\", \"square\", \"exponential\"]:\n        regr = AdaBoostRegressor(loss=loss, random_state=rng)\n        regr.fit(X_train, y_train)\n        assert regr.score(X_test, y_test) > 0\n\n    # Test that the loss parameter is used correctly with a custom estimator\n    for loss in [\"linear\", \"square\", \"exponential\"]:\n        regr = AdaBoostRegressor(\n            estimator=DecisionTreeRegressor(max_depth=3), loss=loss, random_state=rng\n        )\n        regr.fit(X_train, y_train)\n        assert regr.score(X_test, y_test) > 0\n"], "sample_1023": ["def test_cycle_length():\n        return (x**2 + 1) % 51\n\n    assert next(cycle_length(f, 4)) == (6, 2)\n    assert list(ni for ni in cycle_length(f, 4, values=True)) == \\\n        [17, 35, 2, 5, 26, 14, 44, 50, 2, 5, 26, 14]\n    assert next(cycle_length(f, 4, nmax=4)) == (4, None)\n    assert [ni for ni in cycle_length(f, 4, nmax=4, values=True)] == \\\n        [17, 35, 2, 5]\n\n    raises(ValueError, lambda: cycle_length(f, 4, nmax=-1))\n    raises(ValueError, lambda: cycle_length(f, 4, nmax=0))\n"], "sample_800": ["def test_check_fit_score_takes_y():\n    # Test that check_fit_score_takes_y raises an error when the estimator\n    # does not accept an optional y in fit and score.\n    class BadEstimator(BaseEstimator):\n            return self\n\n            return 0\n\n    assert_raises_regex(ValueError, \"Expected y or Y as second argument\",\n                       check_fit_score_takes_y, \"BadEstimator\", BadEstimator())\n"], "sample_632": ["def test_similar_checker_with_ignore_signatures(capsys):\n    \"\"\"Test that SimilarChecker ignores function signatures when computing similarities.\"\"\"\n    linter = PyLinter()\n    linter.set_option(\"ignore-signatures\", True)\n    reporter = Reporter()\n    linter.set_reporter(reporter)\n    linter.register_checker(similar.SimilarChecker(linter))\n    linter.check([EMPTY_FUNCTION_1, EMPTY_FUNCTION_2])\n    captured = capsys.readouterr()\n    assert \"R0801\" not in captured.out\n"], "sample_464": ["def test_file_response_with_unseekable_file(self):\n    file = UnseekableBytesIO(b\"Hello, world!\")\n    response = FileResponse(file)\n    self.assertEqual(response[\"Content-Type\"], \"application/octet-stream\")\n    self.assertNotIn(\"Content-Length\", response)\n    self.assertEqual(response.streaming_content, [b\"Hello, world!\"])\n"], "sample_138": ["    def test_hashed_name(self):\n        storage = storage.StaticFilesStorage()\n        mixin = storage.HashedFilesMixin()\n        mixin.__init__()\n        name = 'path/to/file.css'\n        content = b'body { background-color: #f2f2f2; }'\n        hashed_name = mixin.hashed_name(name, content=StringIO(content))\n        self.assertIn('path/to/file.', hashed_name)\n        self.assertIn('.css', hashed_name)\n"], "sample_716": ["def test_ridge_regression_sparse_cg():\n    # Test sparse_cg solver with sparse data\n    X = sp.csr_matrix(np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))\n    y = np.array([1, 2, 3])\n    alpha = 1.0\n    coef = ridge_regression(X, y, alpha, solver='sparse_cg')\n    assert_array_almost_equal(coef, np.array([1, 2, 3]))\n"], "sample_215": ["    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        request.user = User()\n        exc_type = Exception\n        exc_value = Exception('Test exception')\n        tb = None\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIn('request', data)\n        self.assertIn('request_meta', data)\n        self.assertIn('user_str', data)\n        self.assertIn('filtered_POST_items', data)\n        self.assertIn('settings', data)\n        self.assertIn('sys_executable', data)\n        self.assertIn('sys_version_info', data)\n        self.assertIn('server_time', data)\n        self.assertIn('django_version_info', data)\n        self.assertIn('sys_path', data)\n        self.assertIn('template_info', data)\n        self.assertIn('template_does_not_exist', data)\n        self.assertIn('postmortem', data)\n        self.assertIn('exception_type', data)\n        self.assertIn('exception_value', data)\n        self.assertIn('lastframe', data)\n"], "sample_725": ["def test_check_symmetric():\n    # Test symmetric matrix\n    X = np.array([[1, 2], [2, 1]])\n    X_sym = check_symmetric(X)\n    assert_array_equal(X, X_sym)\n\n    # Test non-symmetric matrix\n    X = np.array([[1, 2], [3, 1]])\n    X_sym = check_symmetric(X)\n    assert_array_equal(X_sym, np.array([[2, 2.5], [2.5, 1]]))\n\n    # Test sparse symmetric matrix\n    X = sp.csr_matrix(np.array([[1, 2], [2, 1]]))\n    X_sym = check_symmetric(X)\n    assert_allclose_dense_sparse(X, X_sym)\n\n    # Test sparse non-symmetric matrix\n    X = sp.csr_matrix(np.array([[1, 2], [3, 1]]))\n    X_sym = check_symmetric(X)\n    assert_allclose_dense_sparse(X_sym, np.array([[2, 2.5], [2.5, 1]]))\n\n    # Test non-square matrix\n    X = np.array([[1, 2, 3], [4, 5, 6]])\n    assert_raises(ValueError, check_symmetric, X)\n\n    # Test non-2D matrix\n    X = np.array([1, 2, 3])\n    assert_raises(ValueError, check_symmetric, X)\n\n    # Test with tol\n    X = np.array([[1, 2], [2.000001, 1]])\n    X_sym = check_symmetric(X, tol=1E-6)\n    assert_array_equal(X, X_sym)\n\n    # Test with raise_exception\n    X = np.array([[1, 2], [3, 1]])\n    assert_raises(ValueError, check_symmetric, X, raise_exception=True)\n\n    # Test with raise_warning\n    with warnings.catch_warnings(record=True) as w:\n        X = np.array([[1, 2], [3, 1]])\n        check_symmetric(X, raise_warning=False)\n        assert len(w) == 0\n"], "sample_314": ["    def test_clean_password2(self):\n        form_data = {'username': 'testuser', 'password1': 'password', 'password2': 'different'}\n        form = UserCreationForm(data=form_data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors['password2'], [_('The two password fields didn\u2019t match.')])\n"], "sample_61": ["    def test_ascii_username_validator(self):\n        validator = ASCIIUsernameValidator()\n        self.assertIsNone(validator('test_user'))\n        self.assertIsNone(validator('test_user123'))\n        self.assertIsNone(validator('test_user@domain'))\n        self.assertIsNone(validator('test_user.test@domain'))\n        self.assertIsNone(validator('test_user+test@domain'))\n        self.assertIsNone(validator('test_user-test@domain'))\n        self.assertIsNone(validator('test_user_test@domain'))\n\n        with self.assertRaises(ValidationError):\n            validator('test_user\u00a3')\n"], "sample_112": ["    def test_prepopulated_fields_js(self):\n        # Create a mock context\n        context = {\n            'adminform': Mock(prepopulated_fields=[{'field': Mock(auto_id='id_field'), 'dependencies': [Mock(auto_id='id_dependency')]}]),\n            'inline_admin_formsets': [[Mock(original=None, prepopulated_fields=[{'field': Mock(auto_id='id_inline_field'), 'dependencies': [Mock(auto_id='id_inline_dependency')]}])]],\n        }\n\n        # Call the function\n        result = prepopulated_fields_js(context)\n\n        # Check the result\n        self.assertIn('prepopulated_fields', result)\n        self.assertIn('prepopulated_fields_json', result)\n        self.assertEqual(len(result['prepopulated_fields']), 2)\n        self.assertEqual(len(json.loads(result['prepopulated_fields_json'])), 2)\n"], "sample_1101": ["def test_schur_number():\n    assert SchurNumber(1) == 1\n    assert SchurNumber(2) == 4\n    assert SchurNumber(3) == 13\n    assert SchurNumber(4) == 44\n    assert SchurNumber(5).lower_bound() == 364\n    assert SchurNumber(6).lower_bound() == 1093\n    assert SchurNumber(S.Infinity) == S.Infinity\n    raises(ValueError, lambda: SchurNumber(0))\n    raises(ValueError, lambda: SchurNumber(-1))\n    raises(ValueError, lambda: SchurNumber(Rational(1, 2)))\n    raises(ValueError, lambda: SchurNumber(S(1)/2))\n"], "sample_85": ["    def test_foreign_key_on_delete_set_null(self):\n        r = R.objects.create()\n        mr = MR.objects.create(r=r)\n        r.delete()\n        self.assertIsNone(MR.objects.get().r_id)\n"], "sample_26": ["    def test_section_getitem(self, indices):\n        # Create a 3D array\n        data = np.arange(27).reshape(3, 3, 3)\n        hdu = fits.PrimaryHDU(data)\n        section = hdu.section\n\n        # Test that slicing the section returns the same data as slicing the\n        # original array\n        sliced_section = section[indices]\n        sliced_data = data[indices]\n\n        if isinstance(sliced_section, np.ndarray):\n            assert_equal(sliced_section, sliced_data)\n        else:\n            assert sliced_section == sliced_data\n"], "sample_324": ["    def test_origin_verified(self):\n        # Test that the _origin_verified method correctly verifies the Origin\n        # header against the CSRF_TRUSTED_ORIGINS setting.\n        with override_settings(CSRF_TRUSTED_ORIGINS=['http://example.com']):\n            middleware = CsrfViewMiddleware()\n            request = self._get_GET_csrf_cookie_request()\n            request.META['HTTP_ORIGIN'] = 'http://example.com'\n            self.assertTrue(middleware._origin_verified(request))\n\n        with override_settings(CSRF_TRUSTED_ORIGINS=['http://*.example.com']):\n            middleware = CsrfViewMiddleware()\n            request = self._get_GET_csrf_cookie_request()\n            request.META['HTTP_ORIGIN'] = 'http://subdomain.example.com'\n            self.assertTrue(middleware._origin_verified(request))\n\n        with override_settings(CSRF_TRUSTED_ORIGINS=['http://example.com']):\n            middleware = CsrfViewMiddleware()\n            request = self._get_GET_csrf_cookie_request()\n            request.META['HTTP_ORIGIN'] = 'http://other.com'\n            self.assertFalse(middleware._origin_verified(request))\n\n        with override_settings(CSRF_TRUSTED_ORIGINS=['http://example.com']):\n            middleware = CsrfViewMiddleware()\n            request = self._get_GET_csrf_cookie_request()\n            request.META['HTTP_ORIGIN'] = 'https://example.com'\n            self.assertFalse(middleware._origin_verified(request))\n\n        with override_settings(CSRF_TRUSTED_ORIGINS=['http://example.com']):\n            middleware = CsrfViewMiddleware()\n            request = self._get_GET_csrf_cookie_request()\n            request.META['HTTP_ORIGIN'] = 'http://example.com:8080'\n            self.assertFalse(middleware._origin_verified(request))\n\n        with override_settings(CSRF_TRUSTED_ORIGINS=['http://example.com:8080']):\n            middleware = CsrfViewMiddleware()\n            request = self._get_GET_csrf_cookie_request()\n            request.META['HTTP_ORIGIN'] = 'http://example.com:8080'\n            self.assertTrue(middleware._origin_verified(request))\n"], "sample_777": ["def test_gradient_boosting_regressor():\n    # Test Gradient Boosting Regressor.\n    X, y = make_regression(n_samples=100, n_features=10, n_informative=5,\n                            noise=0.1, random_state=0)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5,\n                                                        random_state=0)\n\n    gbrt = GradientBoostingRegressor(n_estimators=10, random_state=0)\n    gbrt.fit(X_train, y_train)\n    y_pred = gbrt.predict(X_test)\n\n    assert_equal(y_pred.shape, (X_test.shape[0],))\n    assert_greater(mean_squared_error(y_test, y_pred), 0.0)\n\n    # Test with presort\n    gbrt_presort = GradientBoostingRegressor(n_estimators=10, presort=True,\n                                             random_state=0)\n    gbrt_presort.fit(X_train, y_train)\n    y_pred_presort = gbrt_presort.predict(X_test)\n\n    assert_array_almost_equal(y_pred, y_pred_presort)\n\n    # Test with warm start\n    gbrt_warm_start = GradientBoostingRegressor(n_estimators=5, warm_start=True,\n                                                random_state=0)\n    gbrt_warm_start.fit(X_train, y_train)\n    y_pred_warm_start = gbrt_warm_start.predict(X_test)\n\n    gbrt_warm_start.n_estimators = 10\n    gbrt_warm_start.fit(X_train, y_train)\n    y_pred_warm_start_2 = gbrt_warm_start.predict(X_test)\n\n    assert_array_almost_equal(y_pred, y_pred_warm_start_2)\n\n    # Test with init\n    gbrt_init = GradientBoostingRegressor(n_estimators=10, init=DummyRegressor(),\n                                          random_state=0)\n    gbrt_init.fit(X_train, y_train)\n    y_pred_init = gbrt_init.predict(X_test)\n\n    assert_array_almost_equal(y_pred, y_pred_init)\n\n    # Test with max_features\n    gbrt_max_features = GradientBoostingRegressor(n_estimators=10,\n                                                  max_features='sqrt',\n                                                  random_state=0)\n    gbrt_max_features.fit(X_train, y_train)\n    y_pred_max_features = gbrt_max_features.predict(X_test)\n\n    assert_array_almost_equal(y_pred, y_pred_max_features)\n\n    # Test"], "sample_965": ["def test_signature_from_str():\n    signature_str = \"(a: int, b: str, *args, **kwargs) -> None\"\n    sig = inspect.signature_from_str(signature_str)\n    assert len(sig.parameters) == 4\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.parameters['args'].kind == Parameter.VAR_POSITIONAL\n    assert sig.parameters['kwargs'].kind == Parameter.VAR_KEYWORD\n    assert sig.return_annotation == type(None)\n"], "sample_189": ["    def test_make_key(self):\n        cache = caches['default']\n        key = 'test_key'\n        version = 1\n        expected_key = f'{cache.key_prefix}:{version}:{key}'\n        self.assertEqual(cache.make_key(key, version), expected_key)\n"], "sample_752": ["def test_isolation_forest_sparse_input():\n    \"\"\"Test that Isolation Forest works with sparse input.\"\"\"\n    X = csc_matrix(np.random.rand(100, 10))\n    y = np.random.randint(0, 2, 100)\n    iforest = IsolationForest(n_estimators=10, random_state=rng)\n    iforest.fit(X, y)\n    assert_array_almost_equal(iforest.predict(X), np.ones(100))\n"], "sample_543": ["def test_rectangle_selector():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], [10, 50, 100])\n        pass\n    rectprops = dict(facecolor='blue', alpha=0.5)\n    rect = widgets.RectangleSelector(ax, onselect, interactive=True,\n                                    props=rectprops)\n    click_and_drag(ax, rect, 0.1, 0.1, 0.8, 0.8)\n    assert rect.extents == (0.1, 0.8, 0.1, 0.8)\n"], "sample_528": ["def test_update_nested_dict():\n    main_dict = {'style1': {'param1': 'value1', 'param2': 'value2'}}\n    new_dict = {'style1': {'param2': 'new_value2', 'param3': 'value3'},\n                'style2': {'param1': 'value1'}}\n    expected_dict = {'style1': {'param1': 'value1', 'param2': 'new_value2', 'param3': 'value3'},\n                     'style2': {'param1': 'value1'}}\n    style.update_nested_dict(main_dict, new_dict)\n    assert main_dict == expected_dict\n\n"], "sample_260": ["def test_rename_model_references(self):\n    operations = [\n        migrations.CreateModel(\n            name='ModelA',\n            fields=[\n                ('id', models.AutoField(primary_key=True)),\n                ('modelb', models.ForeignKey('ModelB', on_delete=models.CASCADE)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='ModelB',\n            fields=[\n                ('id', models.AutoField(primary_key=True)),\n            ],\n        ),\n        migrations.RenameModel(\n            old_name='ModelB',\n            new_name='ModelC',\n        ),\n    ]\n    expected = [\n        migrations.CreateModel(\n            name='ModelA',\n            fields=[\n                ('id', models.AutoField(primary_key=True)),\n                ('modelc', models.ForeignKey('ModelC', on_delete=models.CASCADE)),\n            ],\n        ),\n        migrations.CreateModel(\n            name='ModelC',\n            fields=[\n                ('id', models.AutoField(primary_key=True)),\n            ],\n        ),\n    ]\n    self.assertOptimizesTo(operations, expected)\n"], "sample_860": ["def test_check_scalar():\n    # Test that check_scalar raises an error when the input is not of the correct type\n    with assert_raises(TypeError):\n        check_scalar(\"a\", \"test\", int)\n\n    # Test that check_scalar raises an error when the input is out of bounds\n    with assert_raises(ValueError):\n        check_scalar(-1, \"test\", int, min_val=0)\n\n    with assert_raises(ValueError):\n        check_scalar(2, \"test\", int, max_val=1)\n\n    # Test that check_scalar does not raise an error when the input is of the correct type and within bounds\n    check_scalar(1, \"test\", int)\n    check_scalar(1, \"test\", (int, float))\n    check_scalar(1.0, \"test\", (int, float))\n    check_scalar(1, \"test\", int, min_val=0, max_val=2)\n"], "sample_1124": ["def test_field():\n    x, y = symbols('x y')\n    F, x, y = field((x, y), ZZ)\n    assert F.domain == ZZ\n    assert F.order == lex\n    assert F.symbols == (x, y)\n    assert F.gens == (x, y)\n    assert F.ngens == 2\n    assert F.zero == F(0)\n    assert F.one == F(1)\n"], "sample_93": ["    def test_expression_wrapper(self):\n        expression = ExpressionWrapper(F('age'), output_field=IntegerField())\n        self.assertIsInstance(expression, Expression)\n        self.assertIsInstance(expression, BaseExpression)\n        self.assertEqual(expression.output_field.get_internal_type(), 'IntegerField')\n\n        with self.assertRaises(FieldError):\n            ExpressionWrapper(F('age'), output_field=None)\n\n        expression = ExpressionWrapper(F('age'), output_field=IntegerField())\n        self.assertEqual(expression.as_sql(None, connection), ('\"age\"', []))\n\n        expression = ExpressionWrapper(F('age'), output_field=FloatField())\n        self.assertEqual(expression.as_sql(None, connection), ('\"age\"', []))\n\n        expression = ExpressionWrapper(F('age'), output_field=DecimalField())\n        self.assertEqual(expression.as_sql(None, connection), ('\"age\"', []))\n"], "sample_509": ["def test_date2num():\n    # Test date2num with datetime objects\n    dt = datetime.datetime(2022, 1, 1)\n    assert mdates.date2num(dt) == 737060.0\n\n    # Test date2num with numpy datetime64 objects\n    dt64 = np.datetime64('2022-01-01')\n    assert mdates.date2num(dt64) == 737060.0\n\n    # Test date2num with a list of datetime objects\n    dt_list = [datetime.datetime(2022, 1, 1), datetime.datetime(2022, 1, 2)]\n    assert np.allclose(mdates.date2num(dt_list), [737060.0, 737061.0])\n\n    # Test date2num with a list of numpy datetime64 objects\n    dt64_list = [np.datetime64('2022-01-01'), np.datetime64('2022-01-02')]\n    assert np.allclose(mdates.date2num(dt64_list), [737060.0, 737061.0])\n\n    # Test date2num with timezone-aware datetime objects\n    dt_tz = datetime.datetime(2022, 1, 1, tzinfo=dateutil.tz.tzutc())\n    assert mdates.date2num(dt_tz) == 737060.0\n\n    # Test date2num with timezone-aware numpy datetime64 objects\n    dt64_tz = np.datetime64('2022-01-01', 'ns', 'UTC')\n    assert mdates.date2num(dt64_tz) == 737060.0\n"], "sample_687": ["def test_log_capture_fixture(caplog):\n    logger.info(\"info message\")\n    sublogger.warning(\"warning message\")\n    assert len(caplog.records) == 2\n    assert caplog.record_tuples == [\n        (__name__, logging.INFO, \"info message\"),\n        (__name__ + \".baz\", logging.WARNING, \"warning message\"),\n    ]\n    assert caplog.messages == [\"info message\", \"warning message\"]\n    assert caplog.text == (\n        \"INFO     {} info message\\n\"\n        \"WARNING  {}.baz warning message\\n\".format(__name__, __name__)\n    )\n"], "sample_494": ["    def test_serializer_factory_with_lazy_object(self):\n        lazy_object = SimpleLazyObject(lambda: \"lazy_value\")\n        serializer = serializer_factory(lazy_object)\n        self.assertIsInstance(serializer, BaseSimpleSerializer)\n        serialized_value, imports = serializer.serialize()\n        self.assertEqual(serialized_value, \"'lazy_value'\")\n        self.assertEqual(imports, set())\n"], "sample_699": ["def test_doctest_item_repr_failure_with_multiple_failures():\n    \"\"\"Test that DoctestItem.repr_failure() handles multiple failures.\"\"\"\n    doctest_item = DoctestItem(\"test\", None)\n    failures = [\n        doctest.DocTestFailure(None, None, \"got\"),\n        doctest.DocTestFailure(None, None, \"got2\"),\n    ]\n    excinfo = ExceptionInfo(MultipleDoctestFailures(failures), None)\n    result = doctest_item.repr_failure(excinfo)\n    assert isinstance(result, DoctestItem.ReprFailDoctest)\n    assert len(result.reprlocation_lines) == 2\n"], "sample_110": ["    def test_expression_pickleability(self):\n        expression = F('name')\n        pickled_expression = pickle.loads(pickle.dumps(expression))\n        self.assertEqual(expression.name, pickled_expression.name)\n"], "sample_834": ["def test_nca_init():\n    # Test that the initialization methods produce the correct shape\n    n_samples, n_features = 100, 5\n    X = rng.rand(n_samples, n_features)\n    y = rng.randint(0, 2, n_samples)\n\n    nca = NeighborhoodComponentsAnalysis(n_components=3, init='auto')\n    transformation = nca._initialize(X, y, 'auto')\n    assert transformation.shape == (3, n_features)\n\n    nca = NeighborhoodComponentsAnalysis(n_components=3, init='pca')\n    transformation = nca._initialize(X, y, 'pca')\n    assert transformation.shape == (3, n_features)\n\n    nca = NeighborhoodComponentsAnalysis(n_components=3, init='lda')\n    transformation = nca._initialize(X, y, 'lda')\n    assert transformation.shape == (3, n_features)\n\n    nca = NeighborhoodComponentsAnalysis(n_components=3, init='identity')\n    transformation = nca._initialize(X, y, 'identity')\n    assert transformation.shape == (3, n_features)\n\n    nca = NeighborhoodComponentsAnalysis(n_components=3, init='random')\n    transformation = nca._initialize(X, y, 'random')\n    assert transformation.shape == (3, n_features)\n\n    # Test that a custom initialization produces the correct shape\n    custom_init = rng.rand(3, n_features)\n    nca = NeighborhoodComponentsAnalysis(n_components=3, init=custom_init)\n    transformation = nca._initialize(X, y, custom_init)\n    assert transformation.shape == (3, n_features)\n\n    # Test that an invalid initialization raises an error\n    nca = NeighborhoodComponentsAnalysis(n_components=3, init='invalid')\n    with pytest.raises(ValueError):\n        nca._initialize(X, y, 'invalid')\n"], "sample_256": ["    def test_clean_password2(self):\n        form_data = {\n            'username': 'testuser',\n            'password1': 'password',\n            'password2': 'password',\n        }\n        form = UserCreationForm(data=form_data)\n        self.assertTrue(form.is_valid())\n"], "sample_1178": ["def test_Type():\n    assert Type.from_expr(1) == integer\n    assert Type.from_expr(1.0) == real\n    assert Type.from_expr(True) == bool_\n    assert Type.from_expr(1+2j) == complex_\n\n    assert int8.min == -2**7\n    assert int8.max == 2**7 - 1\n    assert uint8.min == 0\n    assert uint8.max == 2**8 - 1\n\n    assert f16.min == -2**15\n    assert f16.max == 2**15 - 2**10\n    assert f16.tiny == 2**-14\n    assert f16.eps == 2**-10\n    assert f16.dig == 3\n    assert f16.decimal_dig == 5\n\n    assert f32.min == -2**127\n    assert f32.max == 2**127 - 2**23\n    assert f32.tiny == 2**-126\n    assert f32.eps == 2**-23\n    assert f32.dig == 6\n    assert f32.decimal_dig == 7\n\n    assert f64.min == -2**1023\n    assert f64.max == 2**1023 - 2**52\n    assert f64.tiny == 2**-1022\n    assert f64.eps == 2**-52\n    assert f64.dig == 15\n    assert f64.decimal_dig == 17\n\n    assert f80.min == -2**16383\n    assert f80.max == 2**16383 - 2**63\n    assert f80.tiny == 2**-16382\n    assert f80.eps == 2**-63\n    assert f80.dig == 18\n    assert f80.decimal_dig == 21\n\n    assert f128.min == -2**32767\n    assert f128.max == 2**32767 - 2**112\n    assert f128.tiny == 2**-32766\n    assert f128.eps == 2**-112\n    assert f128.dig == 33\n    assert f128.decimal_dig == 36\n\n    assert c64.min == -2**127\n    assert c64.max == 2**127 - 2**23\n    assert c"], "sample_473": ["    def test_asgi_request_creation(self):\n        scope = {\n            \"type\": \"http\",\n            \"method\": \"GET\",\n            \"path\": \"/path/to/resource\",\n            \"headers\": [(b\"host\", b\"example.com\")],\n            \"query_string\": b\"a=1&b=2\",\n            \"client\": [\"192.168.1.1\", 12345],\n            \"server\": [\"example.com\", 80],\n        }\n        body_file = tempfile.SpooledTemporaryFile(max_size=1024, mode=\"w+b\")\n        request = ASGIRequest(scope, body_file)\n        self.assertEqual(request.method, \"GET\")\n        self.assertEqual(request.path, \"/path/to/resource\")\n        self.assertEqual(request.META[\"HTTP_HOST\"], \"example.com\")\n        self.assertEqual(request.GET, {\"a\": [\"1\"], \"b\": [\"2\"]})\n        self.assertEqual(request.COOKIES, {})\n        body_file.close()\n"], "sample_33": ["def test_check_broadcast():\n    # Test that a single shape is passed through unmodified\n    assert misc.check_broadcast((1, 2, 3)) == (1, 2, 3)\n\n    # Test that no shapes returns an empty tuple\n    assert misc.check_broadcast() == ()\n\n    # Test that two shapes can be broadcast\n    assert misc.check_broadcast((1, 2, 3), (4, 2, 3)) == (4, 2, 3)\n\n    # Test that two shapes cannot be broadcast\n    with pytest.raises(misc.IncompatibleShapeError):\n        misc.check_broadcast((1, 2, 3), (4, 5, 3))\n\n    # Test that three shapes can be broadcast\n    assert misc.check_broadcast((1, 2, 3), (4, 2, 3), (4, 2, 1)) == (4, 2, 3)\n\n    # Test that three shapes cannot be broadcast\n    with pytest.raises(misc.IncompatibleShapeError):\n        misc.check_broadcast((1, 2, 3), (4, 5, 3), (4, 2, 1))\n"], "sample_361": ["def test_urlizer(self):\n    urlizer = Urlizer()\n    self.check_output(urlizer, 'http://example.com', '<a href=\"http://example.com\">http://example.com</a>')\n    self.check_output(urlizer, 'www.example.com', '<a href=\"http://www.example.com\">www.example.com</a>')\n    self.check_output(urlizer, 'example@example.com', 'mailto:example@example.com')\n    self.check_output(urlizer, 'example@example.com.', 'mailto:example@example.com.')\n    self.check_output(urlizer, '(http://example.com)', '<a href=\"http://example.com\">http://example.com</a>')\n    self.check_output(urlizer, '[http://example.com]', '<a href=\"http://example.com\">http://example.com</a>')\n    self.check_output(urlizer, 'http://example.com.', '<a href=\"http://example.com\">http://example.com</a>.')\n\n    # Test nofollow\n    self.check_output(urlizer, 'http://example.com', '<a href=\"http://example.com\" rel=\"nofollow\">http://example.com</a>', nofollow=True)\n\n    # Test autoescape\n    self.check_output(urlizer, '<script>alert(\"XSS\")</script>', '&lt;script&gt;alert(&quot;XSS&quot;)&lt;/script&gt;', autoescape=True)\n\n    # Test trim_url_limit\n    self.check_output(urlizer, 'http://example.com/very/long/url', '<a href=\"http://example.com/very/long/url\">http://example.com/very/long/url</a>')\n    self.check_output(urlizer, 'http://example.com/very/long/url', '<a href=\"http://example.com/very/long/url\">http://example.com/very/long/\u2026</a>', trim_url_limit=20)\n"], "sample_837": ["def test_get_sys_info():\n    sys_info = _get_sys_info()\n    assert isinstance(sys_info, dict)\n    assert 'python' in sys_info\n    assert 'executable' in sys_info\n    assert 'machine' in sys_info\n\n"], "sample_392": ["    def test_jsonfield_encoder_decoder(self):\n        # Test that the encoder and decoder are used correctly\n        json_data = {'key': 'value'}\n        json_model = JSONModel.objects.create(data=json_data)\n\n        # Test that the encoder is used when saving the model\n        self.assertEqual(json_model.data, json_data)\n\n        # Test that the decoder is used when retrieving the model\n        retrieved_model = JSONModel.objects.get(id=json_model.id)\n        self.assertEqual(retrieved_model.data, json_data)\n\n        # Test that a custom encoder and decoder can be used\n        custom_encoder = mock.Mock(return_value='custom_encoded_data')\n        custom_decoder = mock.Mock(return_value='custom_decoded_data')\n        custom_json_model = JSONModel.objects.create(data=json_data, encoder=custom_encoder, decoder=custom_decoder)\n\n        # Test that the custom encoder is used when saving the model\n        custom_encoder.assert_called_once_with(json_data)\n        self.assertEqual(custom_json_model.data, 'custom_encoded_data')\n\n        # Test that the custom decoder is used when retrieving the model\n        retrieved_custom_model = JSONModel.objects.get(id=custom_json_model.id)\n        custom_decoder.assert_called_once_with('custom_encoded_data')\n        self.assertEqual(retrieved_custom_model.data, 'custom_decoded_data')\n\n        # Test that a ValueError is raised if the encoder or decoder is not callable\n        with self.assertRaises(ValueError):\n            JSONModel.objects.create(data=json_data, encoder='not_callable')\n\n        with self.assertRaises(ValueError):\n            JSONModel.objects.create(data=json_data, decoder='not_callable')\n"], "sample_54": ["def test_file_response_with_filelike_object(self):\n    with tempfile.NamedTemporaryFile() as tmp:\n        tmp.write(b'Hello, world!')\n        tmp.flush()\n        response = FileResponse(tmp)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response['Content-Type'], 'application/octet-stream')\n        self.assertEqual(response['Content-Disposition'], 'attachment; filename=\"{}\"'.format(os.path.basename(tmp.name)))\n        self.assertEqual(response.streaming_content, [b'Hello, world!'])\n"], "sample_552": ["def test_subfigure_layout_engine():\n    fig = plt.figure()\n    gs = gridspec.GridSpec(2, 2)\n    sfig1 = fig.add_subfigure(gs[0, 0])\n    sfig2 = fig.add_subfigure(gs[1, 1])\n    sfig1.set_layout_engine('constrained')\n    sfig2.set_layout_engine('tight')\n    assert isinstance(sfig1.get_layout_engine(), ConstrainedLayoutEngine)\n    assert isinstance(sfig2.get_layout_engine(), TightLayoutEngine)\n    assert isinstance(fig.get_layout_engine(), PlaceHolderLayoutEngine)\n"], "sample_1139": ["def test_ComplexRegion():\n    a = Interval(2, 3)\n    b = Interval(4, 5)\n    c = Interval(1, 7)\n    C1 = ComplexRegion(a*b)\n    C2 = ComplexRegion(Union(a*b, b*c))\n    assert C1.sets == ProductSet(Interval(2, 3), Interval(4, 5))\n    assert C2.sets == Union(ProductSet(Interval(2, 3), Interval(4, 5)), ProductSet(Interval(4, 5), Interval(1, 7)))\n    assert C1.psets == (ProductSet(Interval(2, 3), Interval(4, 5)),)\n    assert C2.psets == (ProductSet(Interval(2, 3), Interval(4, 5)), ProductSet(Interval(4, 5), Interval(1, 7)))\n    assert C1.a_interval == Interval(2, 3)\n    assert C2.a_interval == Union(Interval(2, 3), Interval(4, 5))\n    assert C1.b_interval == Interval(4, 5)\n    assert C2.b_interval == Interval(1, 7)\n    assert C1._measure == 3\n    assert C2._measure == 21\n\n    r = Interval(0, 1)\n    theta = Interval(0, 2*S.Pi)\n    c2 = ComplexRegion(r*theta, polar=True)\n    assert c2.sets == ProductSet(Interval(0, 1), Interval.Ropen(0, 2*pi))\n    assert c2.psets == (ProductSet(Interval(0, 1), Interval.Ropen(0, 2*pi)),)\n    assert c2.a_interval == Interval(0, 1)\n    assert c2.b_interval == Interval.Ropen(0, 2*pi)\n    assert c2._measure == pi\n\n    assert 2.5 + 4.5*I in C1\n    assert 2.5 + 6.5*I not in C1\n    assert 0.5 + 0.5*I in c2\n    assert 1 + 2*I not in c2\n\n    unit_disk = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)\n    upper_half_unit_disk = ComplexRegion(Interval"], "sample_870": ["def test_sample_y():\n    # Test that sample_y returns the correct shape\n    gpr = GaussianProcessRegressor(kernel=RBF(length_scale=1.0))\n    gpr.fit(X, y)\n    y_samples = gpr.sample_y(X2, n_samples=10)\n    assert y_samples.shape == (X2.shape[0], 10)\n\n    # Test that sample_y returns the correct shape for multi-output\n    y_multi = np.column_stack((y, y))\n    gpr.fit(X, y_multi)\n    y_samples_multi = gpr.sample_y(X2, n_samples=10)\n    assert y_samples_multi.shape == (X2.shape[0], 2, 10)\n\n    # Test that sample_y raises an error for unfitted model\n    gpr = GaussianProcessRegressor(kernel=RBF(length_scale=1.0))\n    with pytest.raises(AttributeError):\n        gpr.sample_y(X2)\n\n    # Test that sample_y raises an error for non-positive n_samples\n    gpr.fit(X, y)\n    with pytest.raises(ValueError):\n        gpr.sample_y(X2, n_samples=0)\n\n    # Test that sample_y raises an error for non-integer n_samples\n    with pytest.raises(ValueError):\n        gpr.sample_y(X2, n_samples=1.5)\n"], "sample_1021": ["def test_to_axis_angle():\n    q = Quaternion(1, 1, 1, 1)\n    axis, angle = q.to_axis_angle()\n    assert axis == (sqrt(3)/3, sqrt(3)/3, sqrt(3)/3)\n    assert angle == 2*pi/3\n\n    q = Quaternion(-1, -1, -1, -1)\n    axis, angle = q.to_axis_angle()\n    assert axis == (sqrt(3)/3, sqrt(3)/3, sqrt(3)/3)\n    assert angle == 2*pi/3\n\n    q = Quaternion(1, 0, 0, 0)\n    axis, angle = q.to_axis_angle()\n    assert axis == (0, 0, 0)\n    assert angle == 0\n\n    q = Quaternion(0, 1, 0, 0)\n    axis, angle = q.to_axis_angle()\n    assert axis == (1, 0, 0)\n    assert angle == pi\n\n    q = Quaternion(0, 0, 1, 0)\n    axis, angle = q.to_axis_angle()\n    assert axis == (0, 1, 0)\n    assert angle == pi\n\n    q = Quaternion(0, 0, 0, 1)\n    axis, angle = q.to_axis_angle()\n    assert axis == (0, 0, 1)\n    assert angle == pi\n\n    q = Quaternion(1, 1, 1, 1)/sqrt(4)\n    axis, angle = q.to_axis_angle()\n    assert axis == (sqrt(3)/3, sqrt(3)/3, sqrt(3)/3)\n    assert angle == pi/3\n\n    q = Quaternion(1, 1, 1, 1)/sqrt(4)\n    axis, angle = q.to_axis_angle()\n    assert axis == (sqrt(3)/3, sqrt(3)/3, sqrt(3)/3)\n    assert angle == pi/3\n\n    q = Quaternion(1, 0, 0, 0)\n    axis, angle = q.to_axis_angle()\n    assert axis == (0, 0, 0)\n    assert angle == 0\n\n    q = Quaternion(0, 1, 0, 0)\n    axis, angle = q.to_axis_angle()\n    assert axis == (1, 0,"], "sample_862": ["def test_hashing_vectorizer():\n    # Test that HashingVectorizer can handle a large number of features\n    vectorizer = HashingVectorizer(n_features=2**20)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n    assert X.shape == (len(ALL_FOOD_DOCS), 2**20)\n\n    # Test that HashingVectorizer can handle a large number of samples\n    vectorizer = HashingVectorizer(n_features=100)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 100)\n    assert X.shape == (len(ALL_FOOD_DOCS) * 100, 100)\n\n    # Test that HashingVectorizer can handle a large number of features and samples\n    vectorizer = HashingVectorizer(n_features=2**20)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 100)\n    assert X.shape == (len(ALL_FOOD_DOCS) * 100, 2**20)\n\n    # Test that HashingVectorizer can handle a large number of features and samples with alternate_sign=True\n    vectorizer = HashingVectorizer(n_features=2**20, alternate_sign=True)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 100)\n    assert X.shape == (len(ALL_FOOD_DOCS) * 100, 2**20)\n\n    # Test that HashingVectorizer can handle a large number of features and samples with alternate_sign=False\n    vectorizer = HashingVectorizer(n_features=2**20, alternate_sign=False)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 100)\n    assert X.shape == (len(ALL_FOOD_DOCS) * 100, 2**20)\n\n    # Test that HashingVectorizer can handle a large number of features and samples with binary=True\n    vectorizer = HashingVectorizer(n_features=2**20, binary=True)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 100)\n    assert X.shape == (len(ALL_FOOD_DOCS) * 100, 2**20)\n\n    # Test that HashingVectorizer can handle a large number of features and samples with binary=False\n    vectorizer = HashingVectorizer(n_features=2**20, binary=False)\n    X = vectorizer.fit_transform(ALL_FOOD_DOCS * 100)\n    assert X.shape == (len(ALL_FOOD_DOCS) *"], "sample_1080": ["def test_refine_abs():\n    assert refine(Abs(x), Q.real(x)) == Abs(x)\n    assert refine(Abs(x), Q.positive(x)) == x\n    assert refine(Abs(x), Q.negative(x)) == -x\n    assert refine(Abs(x**2), Q.real(x)) == x**2\n    assert refine(Abs(x**2), Q.positive(x)) == x**2\n    assert refine(Abs(x**2), Q.negative(x)) == x**2\n"], "sample_868": ["def test_contingency_matrix():\n    # Test contingency matrix with sparse and dense output\n    labels_true = np.array([0, 0, 1, 1])\n    labels_pred = np.array([0, 1, 0, 1])\n    contingency_sparse = contingency_matrix(labels_true, labels_pred, sparse=True)\n    contingency_dense = contingency_matrix(labels_true, labels_pred, sparse=False)\n    assert_allclose(contingency_sparse.toarray(), contingency_dense)\n\n    # Test contingency matrix with eps\n    contingency_eps = contingency_matrix(labels_true, labels_pred, eps=1e-10)\n    assert_allclose(contingency_eps, contingency_dense + 1e-10)\n\n    # Test contingency matrix with invalid input\n    with pytest.raises(ValueError):\n        contingency_matrix(labels_true, labels_pred, eps=1e-10, sparse=True)\n\n    # Test contingency matrix with non-integer labels\n    labels_true = np.array([0.5, 0.5, 1.5, 1.5])\n    labels_pred = np.array([0.5, 1.5, 0.5, 1.5])\n    with pytest.raises(ValueError):\n        contingency_matrix(labels_true, labels_pred)\n\n    # Test contingency matrix with non-1D labels\n    labels_true = np.array([[0, 0], [1, 1]])\n    labels_pred = np.array([[0, 1], [0, 1]])\n    with pytest.raises(ValueError):\n        contingency_matrix(labels_true, labels_pred)\n"], "sample_516": ["def test_pdf_embed_ttf():\n    # Test embedding of TrueType fonts in PDFs\n    fig, ax = plt.subplots()\n    font = findfont(FontProperties(family='serif'))\n    font = FT2Font(font)\n    ax.text(0.5, 0.5, 'Hello, world!', fontproperties=FontProperties(fname=font.fname))\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    fig.savefig('test.pdf')\n    assert get_glyphs_subset('test.pdf', 'Hello, world!') == b'Hello, world!'\n    os.remove('test.pdf')\n"], "sample_757": ["def test_ordinal_encoder():\n    # Test OrdinalEncoder with categorical features\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 2.], [1., 1.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([['Male', 1], ['Female', 3], ['Female', 2]], dtype=object))\n\n    # Test OrdinalEncoder with numerical features\n    X = [[1, 2], [3, 4], [5, 6]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 1.], [2., 2.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([[1, 2], [3, 4], [5, 6]], dtype=object))\n\n    # Test OrdinalEncoder with mixed-type features\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 2.], [1., 1.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([['Male', 1], ['Female', 3], ['Female', 2]], dtype=object))\n\n    # Test OrdinalEncoder with unknown categories\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    X_new = [['Male', 1], ['Female', 3], ['Female', 4]]\n    assert_array_equal(enc.transform(X_new), np.array([[0., 0.], [1., 2.], [1., 3.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X_new)), np.array([['Male', 1], ['Female', 3], ['Female', 4]], dtype=object))\n\n    # Test OrdinalEncoder with categories specified\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc = OrdinalEncoder(categories=[['Male', 'Female'], [1, 2, 3]])\n    enc"], "sample_816": ["def test_hashing_vectorizer():\n    # Test that HashingVectorizer works with a custom analyzer\n    hv = HashingVectorizer(analyzer=lazy_analyze)\n    X = hv.fit_transform(ALL_FOOD_DOCS)\n    assert X.shape == (10, 2 ** 20)\n\n    # Test that HashingVectorizer works with a custom tokenizer\n    hv = HashingVectorizer(tokenizer=split_tokenize)\n    X = hv.fit_transform(ALL_FOOD_DOCS)\n    assert X.shape == (10, 2 ** 20)\n\n    # Test that HashingVectorizer works with a custom preprocessor\n    hv = HashingVectorizer(preprocessor=uppercase)\n    X = hv.fit_transform(ALL_FOOD_DOCS)\n    assert X.shape == (10, 2 ** 20)\n\n    # Test that HashingVectorizer works with a custom analyzer and alternate_sign=False\n    hv = HashingVectorizer(analyzer=lazy_analyze, alternate_sign=False)\n    X = hv.fit_transform(ALL_FOOD_DOCS)\n    assert X.shape == (10, 2 ** 20)\n\n    # Test that HashingVectorizer works with a custom analyzer and binary=True\n    hv = HashingVectorizer(analyzer=lazy_analyze, binary=True)\n    X = hv.fit_transform(ALL_FOOD_DOCS)\n    assert X.shape == (10, 2 ** 20)\n\n    # Test that HashingVectorizer works with a custom analyzer and norm='l1'\n    hv = HashingVectorizer(analyzer=lazy_analyze, norm='l1')\n    X = hv.fit_transform(ALL_FOOD_DOCS)\n    assert X.shape == (10, 2 ** 20)\n\n    # Test that HashingVectorizer works with a custom analyzer and dtype=np.float32\n    hv = HashingVectorizer(analyzer=lazy_analyze, dtype=np.float32)\n    X = hv.fit_transform(ALL_FOOD_DOCS)\n    assert X.shape == (10, 2 ** 20)\n\n    # Test that HashingVectorizer raises an error when input is a string\n    hv = HashingVectorizer()\n    with pytest.raises(ValueError):\n        hv.fit_transform(\"This is a string\")\n\n    # Test that HashingVectorizer raises an error when input is a list of strings\n    hv = HashingVectorizer()\n    with pytest.raises(ValueError):\n        hv.fit_transform([\"This is a string\", \"This is another string\"])\n\n    # Test that HashingVectorizer raises an error when input is"], "sample_1008": ["def test_reference_frame_orient():\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    q1, q2, q3 = dynamicsymbols('q1 q2 q3')\n    A.orient(N, 'Body', [q1, q2, q3], '123')\n    assert A.dcm(N) == Matrix([\n        [cos(q1)*cos(q2), -cos(q1)*sin(q2)*sin(q3) + sin(q1)*cos(q3), sin(q1)*sin(q2) + cos(q1)*cos(q2)*sin(q3)],\n        [sin(q1)*cos(q2), cos(q1)*cos(q3) + sin(q1)*sin(q2)*sin(q3), -cos(q1)*sin(q2) + sin(q1)*cos(q2)*sin(q3)],\n        [-sin(q2), cos(q2)*sin(q3), cos(q2)*cos(q3)]\n    ])\n"], "sample_84": ["    def test_base36_to_int(self):\n        self.assertEqual(base36_to_int('0'), 0)\n        self.assertEqual(base36_to_int('10'), 10)\n        self.assertEqual(base36_to_int('z'), 35)\n        self.assertEqual(base36_to_int('10z'), 370)\n"], "sample_1134": ["def test_latex():\n    # Test latex printing of various objects\n    assert latex(x) == 'x'\n    assert latex(x**2) == 'x^{2}'\n    assert latex(x**-2) == 'x^{-2}'\n    assert latex(x**Rational(1, 2)) == '\\sqrt{x}'\n    assert latex(x**Rational(1, 3)) == '\\sqrt[3]{x}'\n    assert latex(x**Rational(2, 3)) == '\\sqrt[3]{x^{2}}'\n    assert latex(x**Rational(-1, 3)) == '\\frac{1}{\\sqrt[3]{x}}'\n    assert latex(x**Rational(-2, 3)) == '\\frac{1}{\\sqrt[3]{x^{2}}}'\n    assert latex(x**Rational(-1, 2)) == '\\frac{1}{\\sqrt{x}}'\n    assert latex(x**Rational(-3, 2)) == '\\frac{1}{x \\sqrt{x}}'\n    assert latex(x**Rational(3, 2)) == 'x \\sqrt{x}'\n    assert latex(x**Rational(-3, 4)) == '\\frac{1}{x^{3/4}}'\n    assert latex(x**Rational(3, 4)) == 'x^{3/4}'\n    assert latex(x**Rational(-5, 4)) == '\\frac{1}{x^{5/4}}'\n    assert latex(x**Rational(5, 4)) == 'x^{5/4}'\n    assert latex(x**Rational(-7, 4)) == '\\frac{1}{x^{7/4}}'\n    assert latex(x**Rational(7, 4)) == 'x^{7/4}'\n    assert latex(x**Rational(-9, 4)) == '\\frac{1}{x^{9/4}}'\n    assert latex(x**Rational(9, 4)) == 'x^{9/4}'\n    assert latex(x**Rational(-11, 4)) == '\\frac{1}{x^{11/4}}'\n    assert latex(x**Rational(11, 4)) == 'x^{11/4}'\n    assert latex(x**Rational(-13, 4)) == '\\frac{1}{x^{13/4}}'\n    assert latex(x**Rational(13,"], "sample_720": ["def test_power_transformer():\n    # Test that the power transformer is correctly applied\n    pt = PowerTransformer()\n    X = np.array([[1, 2], [3, 2], [4, 5]])\n    X_trans = pt.fit_transform(X)\n    assert_array_almost_equal(X_trans, [[-1.332, -0.707], [0.256, -0.707],\n                                     [1.076, 1.414]])\n\n    # Test that the inverse power transformer is correctly applied\n    X_inv = pt.inverse_transform(X_trans)\n    assert_array_almost_equal(X_inv, X)\n\n    # Test that the power transformer works with a single feature\n    X = np.array([[1], [2], [3]])\n    pt = PowerTransformer()\n    X_trans = pt.fit_transform(X)\n    assert_array_almost_equal(X_trans, [[-1.5], [0.0], [1.5]])\n\n    # Test that the power transformer raises an error for non-positive data\n    X = np.array([[-1, 2], [3, 2], [4, 5]])\n    pt = PowerTransformer()\n    assert_raises(ValueError, pt.fit, X)\n\n    # Test that the power transformer raises an error for non-numeric data\n    X = np.array([['a', 2], [3, 2], [4, 5]])\n    pt = PowerTransformer()\n    assert_raises(ValueError, pt.fit, X)\n"], "sample_255": ["def test_handle_one_request(self):\n    # Create a mock request\n    request = self.request_factory.get('/')\n\n    # Create a mock socket\n    sock = Stub()\n    sock.makefile = lambda mode: BytesIO()\n\n    # Create a WSGIRequestHandler instance\n    handler = WSGIRequestHandler(sock, ('localhost', 8000), WSGIServer(('localhost', 8000), WSGIRequestHandler))\n\n    # Set the request handler's rfile to the mock request\n    handler.rfile = BytesIO(b'GET / HTTP/1.1\\r\\nHost: localhost:8000\\r\\n\\r\\n')\n\n    # Call the handle_one_request method\n    handler.handle_one_request()\n\n    # Check that the request was handled correctly\n    self.assertEqual(handler.raw_requestline, b'GET / HTTP/1.1\\r\\n')\n    self.assertEqual(handler.requestline, 'GET / HTTP/1.1')\n    self.assertEqual(handler.request_version, 'HTTP/1.1')\n    self.assertEqual(handler.command, 'GET')\n"], "sample_730": ["def test_enet_path():\n    # Test enet_path with a random dataset\n    X = np.random.rand(100, 10)\n    y = np.random.rand(100)\n    alphas, coefs, dual_gaps = enet_path(X, y, l1_ratio=0.5, eps=1e-3,\n                                         n_alphas=10, alphas=None,\n                                         precompute='auto', Xy=None,\n                                         copy_X=True, coef_init=None,\n                                         verbose=False, return_n_iter=False,\n                                         positive=False, check_input=True)\n    assert len(alphas) == 10\n    assert coefs.shape == (10, 10)\n    assert len(dual_gaps) == 10\n\n    # Test enet_path with a sparse dataset\n    X_sparse = sparse.csr_matrix(X)\n    alphas, coefs, dual_gaps = enet_path(X_sparse, y, l1_ratio=0.5, eps=1e-3,\n                                         n_alphas=10, alphas=None,\n                                         precompute='auto', Xy=None,\n                                         copy_X=True, coef_init=None,\n                                         verbose=False, return_n_iter=False,\n                                         positive=False, check_input=True)\n    assert len(alphas) == 10\n    assert coefs.shape == (10, 10)\n    assert len(dual_gaps) == 10\n\n    # Test enet_path with a multi-output dataset\n    y_multi = np.random.rand(100, 3)\n    alphas, coefs, dual_gaps = enet_path(X, y_multi, l1_ratio=0.5, eps=1e-3,\n                                         n_alphas=10, alphas=None,\n                                         precompute='auto', Xy=None,\n                                         copy_X=True, coef_init=None,\n                                         verbose=False, return_n_iter=False,\n                                         positive=False, check_input=True)\n    assert len(alphas) == 10\n    assert coefs.shape == (3, 10, 10)\n    assert len(dual_gaps) == 10\n\n    # Test enet_path with a precomputed Gram matrix\n    X Gram = np.dot(X.T, X)\n    alphas, coefs, dual_gaps = enet_path(X, y, l1_ratio=0.5, eps=1e-3,\n                                         n_alphas=10, alphas=None,\n                                         precompute=X Gram, Xy=None,\n"], "sample_24": ["    def test_inv(self):\n        self.check(np.linalg.inv)\n"], "sample_704": ["def test_iterparentnodeids_with_colon_in_test_name():\n    nodeid = \"a/b::c/d::e[/test]\"\n    expected = [\"\", \"a\", \"a/b\", \"a/b::c/d\", \"a/b::c/d::e[/test]\"]\n    assert list(nodes.iterparentnodeids(nodeid)) == expected\n"], "sample_1070": ["def test_exp_polar():\n    assert exp_polar(0) == 1\n    assert exp_polar(2*pi*I) == exp_polar(2*pi*I)\n    assert exp_polar(2)*exp_polar(3) == exp_polar(5)\n    assert exp_polar(2*pi*I).is_polar\n    assert not exp_polar(2*pi*I).is_comparable\n    assert exp_polar(2*pi*I)._eval_evalf(10) == exp(2*pi*I)._eval_evalf(10)\n    assert exp_polar(2*pi*I)._eval_evalf(10) != exp_polar(2*pi*I + pi*I)._eval_evalf(10)\n    assert exp_polar(2*pi*I)._eval_evalf(10) == exp_polar(2*pi*I - pi*I)._eval_evalf(10)\n    assert exp_polar(2*pi*I)._eval_evalf(10) != exp_polar(2*pi*I + 2*pi*I)._eval_evalf(10)\n    assert exp_polar(2*pi*I)._eval_evalf(10) == exp_polar(2*pi*I - 2*pi*I)._eval_evalf(10)\n    assert exp_polar(2*pi*I)._eval_evalf(10) != exp_polar(2*pi*I + 3*pi*I)._eval_evalf(10)\n    assert exp_polar(2*pi*I)._eval_evalf(10) == exp_polar(2*pi*I - 3*pi*I)._eval_evalf(10)\n    assert exp_polar(2*pi*I)._eval_evalf(10) != exp_polar(2*pi*I + 4*pi*I)._eval_evalf(10)\n    assert exp_polar(2*pi*I)._eval_evalf(10) == exp_polar(2*pi*I - 4*pi*I)._eval_evalf(10)\n    assert exp_polar(2*pi*I)._eval_evalf(10) != exp_polar(2*pi*I + 5*pi*I)._eval_evalf(10)\n    assert exp_polar(2*pi*I)._eval_evalf(10) == exp_polar(2*pi*I - 5*pi*I)._eval_evalf(10)\n    assert exp_polar(2*pi*I)._eval_evalf(10) != exp_polar(2*pi*I + 6*pi*I)._eval_evalf(10)\n   "], "sample_257": ["    def test_jsonfield_encoder_decoder(self):\n        class CustomEncoder(json.JSONEncoder):\n                if isinstance(obj, uuid.UUID):\n                    return str(obj)\n                return super().default(obj)\n\n        class CustomDecoder(json.JSONDecoder):\n                super().__init__(object_hook=self.dict_to_uuid, *args, **kwargs)\n\n                if 'uuid' in d:\n                    d['uuid'] = uuid.UUID(d['uuid'])\n                return d\n\n        json_field = JSONField(encoder=CustomEncoder, decoder=CustomDecoder)\n        obj = {'uuid': uuid.uuid4()}\n        encoded_obj = json_field.get_prep_value(obj)\n        decoded_obj = json_field.from_db_value(encoded_obj, None, connection)\n        self.assertIsInstance(decoded_obj['uuid'], uuid.UUID)\n"], "sample_41": ["def test_composite_unit_repr():\n    assert repr(u.m / u.s) == \"Unit('m / s')\"\n    assert repr(u.m / (u.s**2)) == \"Unit('m / s2')\"\n    assert repr(u.m**2 / (u.s**2)) == \"Unit('m2 / s2')\"\n    assert repr(u.m**2 / (u.s**-2)) == \"Unit('m2 s2')\"\n    assert repr(u.m**-2 / (u.s**-2)) == \"Unit('1 / (m2 s2)')\"\n    assert repr(u.m**-2 / (u.s**-2)) == \"Unit('1 / (m2 s2)')\"\n    assert repr(u.m**-2 / (u.s**-2)) == \"Unit('1 / (m2 s2)')\"\n    assert repr(u.m**-2 / (u.s**-2)) == \"Unit('1 / (m2 s2)')\"\n    assert repr(u.m**-2 / (u.s**-2)) == \"Unit('1 / (m2 s2)')\"\n    assert repr(u.m**-2 / (u.s**-2)) == \"Unit('1 / (m2 s2)')\"\n    assert repr(u.m**-2 / (u.s**-2)) == \"Unit('1 / (m2 s2)')\"\n    assert repr(u.m**-2 / (u.s**-2)) == \"Unit('1 / (m2 s2)')\"\n    assert repr(u.m**-2 / (u.s**-2)) == \"Unit('1 / (m2 s2)')\"\n    assert repr(u.m**-2 / (u.s**-2)) == \"Unit('1 / (m2 s2)')\"\n    assert repr(u.m**-2 / (u.s**-2)) == \"Unit('1 / (m2 s2)')\"\n    assert repr(u.m**-2 / (u.s**-2)) == \"Unit('1 / (m2 s2)')\"\n    assert repr(u.m**-2 / (u.s**-2)) == \"Unit('1 / (m2 s2)')\"\n    assert repr(u.m**-2 / (u.s**-2)) == \"Unit('1 / (m2 s2)')\"\n    assert repr(u.m**-2 / ("], "sample_129": ["    def test_floatformat_with_decimal(self):\n        with localcontext() as ctx:\n            ctx.prec = 10\n            a = Decimal('34.23234')\n            b = Decimal('34.00000')\n            c = Decimal('34.26000')\n            self.assertEqual(floatformat(a), mark_safe('34.2'))\n            self.assertEqual(floatformat(b), mark_safe('34'))\n            self.assertEqual(floatformat(c), mark_safe('34.3'))\n            self.assertEqual(floatformat(a, 3), mark_safe('34.232'))\n            self.assertEqual(floatformat(b, 3), mark_safe('34.000'))\n            self.assertEqual(floatformat(c, 3), mark_safe('34.260'))\n            self.assertEqual(floatformat(a, -3), mark_safe('34.232'))\n            self.assertEqual(floatformat(b, -3), mark_safe('34'))\n            self.assertEqual(floatformat(c, -3), mark_safe('34.260'))\n"], "sample_244": ["    def test_formset_factory_with_custom_form_kwargs(self):\n        # Test that formset_factory correctly passes custom kwargs to the form\n        # when instantiating it.\n        formset = formset_factory(CustomKwargForm, extra=1, form_kwargs={'custom_kwarg': 'custom_value'})\n        self.assertEqual(formset.empty_form.custom_kwarg, 'custom_value')\n        self.assertEqual(formset.forms[0].custom_kwarg, 'custom_value')\n"], "sample_48": ["    def test_aggregate_stddev_pop_and_var_pop(self):\n        # Test StdDev and Variance with population parameters\n        stddev = Book.objects.aggregate(stddev=StdDev('price', sample=False))['stddev']\n        variance = Book.objects.aggregate(variance=Variance('price', sample=False))['variance']\n        self.assertIsInstance(stddev, float)\n        self.assertIsInstance(variance, float)\n        self.assertGreaterEqual(variance, 0)\n\n        # Test StdDev and Variance with sample parameters\n        stddev = Book.objects.aggregate(stddev=StdDev('price', sample=True))['stddev']\n        variance = Book.objects.aggregate(variance=Variance('price', sample=True))['variance']\n        self.assertIsInstance(stddev, float)\n        self.assertIsInstance(variance, float)\n        self.assertGreaterEqual(variance, 0)\n\n        # Test StdDev and Variance with no rows\n        stddev = Book.objects.none().aggregate(stddev=StdDev('price', sample=False))['stddev']\n        variance = Book.objects.none().aggregate(variance=Variance('price', sample=False))['variance']\n        self.assertIsNone(stddev)\n        self.assertIsNone(variance)\n"], "sample_371": ["    def test_get_traceback_data(self):\n        request = HttpRequest()\n        request.user = User()\n        exc_type = Exception\n        exc_value = Exception('Test exception')\n        tb = None\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIn('request', data)\n        self.assertIn('request_meta', data)\n        self.assertIn('user_str', data)\n        self.assertIn('filtered_POST_items', data)\n        self.assertIn('settings', data)\n        self.assertIn('sys_executable', data)\n        self.assertIn('sys_version_info', data)\n        self.assertIn('server_time', data)\n        self.assertIn('django_version_info', data)\n        self.assertIn('sys_path', data)\n        self.assertIn('template_info', data)\n        self.assertIn('template_does_not_exist', data)\n        self.assertIn('postmortem', data)\n"], "sample_1113": ["def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert type(B).__name__ == 'BlockMatrix'\n    assert ImmutableMatrix(B.blocks[0, 1]) == ImmutableMatrix([[1, 2, 3]])\n"], "sample_624": ["    def test_inline_index_repr(self):\n        index = pd.Index([1, 2, 3])\n        assert formatting.inline_index_repr(index) == repr(index)\n\n        index = pd.MultiIndex.from_tuples([(1, 2), (3, 4)])\n        assert formatting.inline_index_repr(index) == repr(index)\n\n        class CustomIndex:\n                return \"CustomIndex\"\n\n        index = CustomIndex()\n        assert formatting.inline_index_repr(index) == \"CustomIndex\"\n"], "sample_9": ["def test_html_multicol():\n    # Test that HTML output handles multidimensional columns correctly\n    table = Table([[1, 2], [3, 4]], names=['a', 'b'])\n    table['a'] = np.array([[1, 2], [3, 4]])\n\n    htmldict = {'multicol': True}\n    html_writer = html.HTML(htmldict)\n    output = html_writer.write(table)\n\n    # Check that the output HTML contains the correct colspan attribute\n    soup = BeautifulSoup(output[0], 'html.parser')\n    th_tags = soup.find_all('th')\n    assert th_tags[0]['colspan'] == '2'\n\n    # Check that the output HTML contains the correct data\n    td_tags = soup.find_all('td')\n    assert td_tags[0].text.strip() == '(1, 2)'\n    assert td_tags[1].text.strip() == '(3, 4)'\n"], "sample_217": ["    def test_media_rendering(self):\n        class TestWidget(TextInput):\n            class Media:\n                css = {'all': ['test.css']}\n                js = ['test.js']\n\n        widget = TestWidget()\n        media = widget.media\n        self.assertEqual(\n            media.render(),\n            '<link href=\"http://media.example.com/static/test.css\" type=\"text/css\" media=\"all\" rel=\"stylesheet\">\\n'\n            '<script src=\"http://media.example.com/static/test.js\"></script>'\n        )\n"], "sample_176": ["def test_altered_unique_together(self):\n    before_state = self.make_project_state([\n        self.book_foo_together,\n    ])\n    after_state = self.make_project_state([\n        self.book_foo_together_2,\n    ])\n    changes = MigrationAutodetector(before_state, after_state)._detect_changes()\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\"])\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 0, unique_together={(\"title\", \"author\")})\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 1, index_together={(\"title\", \"author\")})\n"], "sample_380": ["    def test_aggregate_with_filter(self):\n        # Test that aggregates with filters work correctly\n        query = Book.objects.annotate(avg_price=Avg('price', filter=Q(pages__gt=400)))\n        self.assertEqual(query.count(), 6)\n        self.assertAlmostEqual(query[0].avg_price, Decimal('30.00'))\n        self.assertAlmostEqual(query[1].avg_price, Decimal('23.09'))\n        self.assertAlmostEqual(query[2].avg_price, Decimal('29.69'))\n        self.assertAlmostEqual(query[3].avg_price, Decimal('29.69'))\n        self.assertAlmostEqual(query[4].avg_price, Decimal('82.80'))\n        self.assertAlmostEqual(query[5].avg_price, Decimal('75.00'))\n\n        # Test that aggregates with filters and distinct work correctly\n        query = Book.objects.annotate(avg_price=Avg('price', distinct=True, filter=Q(pages__gt=400)))\n        self.assertEqual(query.count(), 6)\n        self.assertAlmostEqual(query[0].avg_price, Decimal('30.00'))\n        self.assertAlmostEqual(query[1].avg_price, Decimal('23.09'))\n        self.assertAlmostEqual(query[2].avg_price, Decimal('29.69'))\n        self.assertAlmostEqual(query[3].avg_price, Decimal('29.69'))\n        self.assertAlmostEqual(query[4].avg_price, Decimal('82.80'))\n        self.assertAlmostEqual(query[5].avg_price, Decimal('75.00'))\n\n        # Test that aggregates with filters and default work correctly\n        query = Book.objects.annotate(avg_price=Avg('price', filter=Q(pages__gt=400), default=0))\n        self.assertEqual(query.count(), 6)\n        self.assertAlmostEqual(query[0].avg_price, Decimal('30.00'))\n        self.assertAlmostEqual(query[1].avg_price, Decimal('23.09'))\n        self.assertAlmostEqual(query[2].avg_price, Decimal('29.69'))\n        self.assertAlmostEqual(query[3].avg_price, Decimal('29.69'))\n        self.assertAlmostEqual(query[4].avg_price, Decimal('82.80'))\n        self.assertAlmostEqual(query[5].avg_price, Decimal('75.00'))\n\n        # Test that aggregates with filters and distinct and default work correctly\n        query = Book.objects.annotate(avg_price=Avg('price', distinct=True, filter=Q(pages__gt=400), default=0))\n        self.assertEqual(query.count(), 6)\n        self.assertAlmostEqual(query[0].avg_price, Decimal('30.00'))\n        self.assertAlmostEqual(query[1].avg_price,"], "sample_551": ["def test_3d_text():\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.set_xlim(-1, 1)\n    ax.set_ylim(-1, 1)\n    ax.set_zlim(-1, 1)\n    ax.text(0, 0, 0, 'Hello, world!', zdir='y')\n    ax.text(0, 0, 0, 'Hello, world!', zdir='x')\n    ax.text(0, 0, 0, 'Hello, world!', zdir='z')\n    ax.text(0, 0, 0, 'Hello, world!', zdir=(1, 1, 1))\n    ax.text(0, 0, 0, 'Hello, world!', zdir=(-1, -1, -1))\n"], "sample_223": ["    def test_pickling(self):\n        qs = Item.objects.all()\n        pickled_qs = pickle.dumps(qs)\n        unpickled_qs = pickle.loads(pickled_qs)\n        self.assertEqual(list(qs), list(unpickled_qs))\n"], "sample_155": ["def test_file_response_with_filelike_object(self):\n    with tempfile.NamedTemporaryFile() as tmp:\n        tmp.write(b'Hello, world!')\n        tmp.flush()\n        response = FileResponse(tmp)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response['Content-Type'], 'application/octet-stream')\n        self.assertEqual(response['Content-Length'], str(os.path.getsize(tmp.name)))\n        self.assertEqual(response['Content-Disposition'], 'attachment; filename=\"{}\"'.format(os.path.basename(tmp.name)))\n        self.assertEqual(response.streaming_content, [b'Hello, world!'])\n"], "sample_545": ["def test_subplots_adjust():\n    fig, axs = plt.subplots(2, 2, figsize=(8, 6))\n    axs[0, 0].plot([1, 2, 3])\n    axs[0, 1].plot([1, 2, 3])\n    axs[1, 0].plot([1, 2, 3])\n    axs[1, 1].plot([1, 2, 3])\n    fig.subplots_adjust(left=0.2, bottom=0.2, right=0.8, top=0.8)\n    fig.tight_layout()\n"], "sample_199": ["    def test_window_function(self):\n        authors = Author.objects.annotate(\n            rank=Window(\n                expression=Rank(),\n                order_by=F('age').desc(),\n            )\n        )\n        self.assertEqual(authors[0].rank, 1)\n        self.assertEqual(authors[1].rank, 2)\n        self.assertEqual(authors[2].rank, 3)\n        self.assertEqual(authors[3].rank, 4)\n        self.assertEqual(authors[4].rank, 5)\n        self.assertEqual(authors[5].rank, 6)\n        self.assertEqual(authors[6].rank, 7)\n        self.assertEqual(authors[7].rank, 8)\n        self.assertEqual(authors[8].rank, 9)\n"], "sample_740": ["def test_check_is_fitted():\n    # Test that check_is_fitted raises NotFittedError when attributes are not\n    # present\n    class MockEstimator:\n            self.fitted_ = True\n\n    estimator = MockEstimator()\n    assert_raise_message(NotFittedError, \"This MockEstimator instance is not \"\n                                        \"fitted yet. Call 'fit' with \"\n                                        \"appropriate arguments before using \"\n                                        \"this method.\",\n                         check_is_fitted, estimator, attributes='fitted_')\n\n    # Test that check_is_fitted does not raise NotFittedError when attributes\n    # are present\n    estimator.fit()\n    check_is_fitted(estimator, attributes='fitted_')\n\n    # Test that check_is_fitted raises NotFittedError when attributes are not\n    # present and all_or_any is all\n    estimator = MockEstimator()\n    assert_raise_message(NotFittedError, \"This MockEstimator instance is not \"\n                                        \"fitted yet. Call 'fit' with \"\n                                        \"appropriate arguments before using \"\n                                        \"this method.\",\n                         check_is_fitted, estimator, attributes=['fitted_',\n                                                                'other_'],\n                         all_or_any=all)\n\n    # Test that check_is_fitted does not raise NotFittedError when attributes\n    # are present and all_or_any is all\n    estimator.fit()\n    check_is_fitted(estimator, attributes=['fitted_', 'other_'], all_or_any=all)\n\n    # Test that check_is_fitted raises NotFittedError when attributes are not\n    # present and all_or_any is any\n    estimator = MockEstimator()\n    assert_raise_message(NotFittedError, \"This MockEstimator instance is not \"\n                                        \"fitted yet. Call 'fit' with \"\n                                        \"appropriate arguments before using \"\n                                        \"this method.\",\n                         check_is_fitted, estimator, attributes=['fitted_',\n                                                                'other_'],\n                         all_or_any=any)\n\n    # Test that check_is_fitted does not raise NotFittedError when attributes\n    # are present and all_or_any is any\n    estimator.fit()\n    check_is_fitted(estimator, attributes=['fitted_', 'other_'], all_or_any=any)\n\n    # Test that check_is_fitted raises TypeError when estimator is not an\n    # estimator instance\n    assert_raise_message(TypeError, \" is not an estimator instance.\",\n                         check_is_f"], "sample_424": ["    def test_rename_index(self):\n        # Create a model with an index\n        operation = migrations.CreateModel(\n            \"TestModel\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=255)),\n            ],\n            options={\"indexes\": [models.Index(fields=[\"name\"], name=\"name_index\")]},\n        )\n        state = ProjectState()\n        operation.state_forwards(\"app\", state)\n        self.assertEqual(\n            state.models[\"app\", \"testmodel\"].options[\"indexes\"],\n            [models.Index(fields=[\"name\"], name=\"name_index\")],\n        )\n\n        # Rename the index\n        rename_operation = migrations.RenameIndex(\n            \"TestModel\", \"new_name_index\", \"name_index\"\n        )\n        rename_operation.state_forwards(\"app\", state)\n        self.assertEqual(\n            state.models[\"app\", \"testmodel\"].options[\"indexes\"],\n            [models.Index(fields=[\"name\"], name=\"new_name_index\")],\n        )\n\n        # Reverse the rename operation\n        rename_operation.database_backwards(\"app\", connection.schema_editor, state, state)\n        self.assertEqual(\n            state.models[\"app\", \"testmodel\"].options[\"indexes\"],\n            [models.Index(fields=[\"name\"], name=\"name_index\")],\n        )\n\n        # Test renaming an unnamed index\n        operation = migrations.CreateModel(\n            \"TestModel\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=255)),\n            ],\n            options={\"indexes\": [models.Index(fields=[\"name\"])]},\n        )\n        state = ProjectState()\n        operation.state_forwards(\"app\", state)\n        self.assertEqual(\n            state.models[\"app\", \"testmodel\"].options[\"indexes\"],\n            [models.Index(fields=[\"name\"])],\n        )\n\n        # Rename the unnamed index\n        rename_operation = migrations.RenameIndex(\n            \"TestModel\", \"new_name_index\", old_fields=[\"name\"]\n        )\n        rename_operation.state_forwards(\"app\", state)\n        self.assertEqual(\n            state.models[\"app\", \"testmodel\"].options[\"indexes\"],\n            [models.Index(fields=[\"name\"], name=\"new_name_index\")],\n        )\n\n        # Reverse the rename operation\n        rename_operation.database_backwards(\"app\", connection.schema_editor, state, state)\n        self.assertEqual(\n            state.models[\"app\", \"testmodel\"].options[\"indexes\"],\n            [models.Index(fields=[\"name\"])],\n        )\n"], "sample_875": ["def test_multilabel_confusion_matrix():\n    # Test multilabel-indicator case\n    y_true = np.array([[1, 0, 1], [0, 1, 0]])\n    y_pred = np.array([[1, 0, 0], [0, 1, 1]])\n    mcm = multilabel_confusion_matrix(y_true, y_pred)\n    assert_array_almost_equal(mcm, np.array([[[1, 0], [0, 1]], [[1, 0], [0, 1]], [[0, 1], [1, 0]]]))\n\n    # Test multiclass case\n    y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n    y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n    mcm = multilabel_confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n    assert_array_almost_equal(mcm, np.array([[[3, 1], [0, 2]], [[5, 0], [1, 0]], [[2, 1], [1, 2]]]))\n\n    # Test samplewise case\n    y_true = np.array([[0, 1, 1], [1, 1, 0]])\n    y_pred = np.array([[1, 1, 1], [1, 0, 0]])\n    mcm = multilabel_confusion_matrix(y_true, y_pred, samplewise=True)\n    assert_array_almost_equal(mcm, np.array([[[1, 0], [0, 1]], [[0, 1], [1, 0]]))\n\n    # Test with sample weights\n    y_true = np.array([[0, 1, 1], [1, 1, 0]])\n    y_pred = np.array([[1, 1, 1], [1, 0, 0]])\n    sample_weight = np.array([0.5, 1.5])\n    mcm = multilabel_confusion_matrix(y_true, y_pred, sample_weight=sample_weight)\n    assert_array_almost_equal(mcm, np.array([[[1.5, 0], [0, 1.5]], [[1.5, 0], [0, 1.5]], [[0, 1."], "sample_1054": ["def test_ComplexRegion():\n    a = Interval(2, 3)\n    b = Interval(4, 5)\n    c = Interval(1, 7)\n    C1 = ComplexRegion(a*b)\n    C2 = ComplexRegion(Union(a*b, b*c))\n    assert C1.sets == a*b\n    assert C2.sets == Union(a*b, b*c)\n    assert C1.psets == (a*b,)\n    assert C2.psets == (a*b, b*c)\n    assert C1.a_interval == a\n    assert C2.a_interval == Union(a, b)\n    assert C1.b_interval == b\n    assert C2.b_interval == c\n    assert C1.polar == False\n    assert C1.measure == 3\n    assert C1._contains(2 + 4*I) == True\n    assert C1._contains(2 + 6*I) == False\n    assert C1._contains(Tuple(2, 4)) == True\n    assert C1._contains(Tuple(2, 6)) == False\n\n    r = Interval(0, 1)\n    theta = Interval(0, 2*pi)\n    C2 = ComplexRegion(r*theta, polar=True)\n    assert C2.sets == r*normalize_theta_set(theta)\n    assert C2.psets == (r*normalize_theta_set(theta),)\n    assert C2.a_interval == r\n    assert C2.b_interval == normalize_theta_set(theta)\n    assert C2.polar == True\n    assert C2.measure == pi\n    assert C2._contains(0.5 + 0.5*I) == True\n    assert C2._contains(1 + 2*I) == False\n    assert C2._contains(Tuple(0.5, pi/4)) == True\n    assert C2._contains(Tuple(1, pi/4)) == False\n\n    unit_disk = ComplexRegion(Interval(0, 1)*Interval(0, 2*pi), polar=True)\n    upper_half_unit_disk = ComplexRegion(Interval(0, 1)*Interval(0, pi), polar=True)\n    intersection = unit_disk.intersect(upper_half_unit_disk)\n    assert intersection == upper_half_unit_disk\n\n    assert ComplexRegion.from_real(Interval(0,1)) == ComplexRegion(Interval(0,1)*FiniteSet(0))\n"], "sample_208": ["def test_altered_unique_together(self):\n    before_states = [\n        self.book_foo_together,\n    ]\n    after_states = [\n        self.book_foo_together_2,\n    ]\n    changes = self.get_changes(before_states, after_states)\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\"])\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 0, unique_together={(\"title\", \"author\")})\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 1, index_together={(\"title\", \"author\")})\n"], "sample_1022": ["def test_parse_expr():\n    # Test implicit multiplication\n    assert parse_expr('2x', transformations=standard_transformations + (implicit_multiplication,)) == 2*sympy.Symbol('x')\n\n    # Test implicit application\n    assert parse_expr('sin x', transformations=standard_transformations + (implicit_application,)) == sympy.sin(sympy.Symbol('x'))\n\n    # Test implicit multiplication and application\n    assert parse_expr('2 sin x', transformations=standard_transformations + (implicit_multiplication_application,)) == 2*sympy.sin(sympy.Symbol('x'))\n\n    # Test function exponentiation\n    assert parse_expr('sin^2 x', transformations=standard_transformations + (function_exponentiation,)) == sympy.sin(sympy.Symbol('x'))**2\n\n    # Test split symbols\n    assert parse_expr('xyz', transformations=standard_transformations + (split_symbols,)) == sympy.Symbol('x')*sympy.Symbol('y')*sympy.Symbol('z')\n\n    # Test custom split symbols\n        if symbol not in ('list', 'of', 'unsplittable', 'names'):\n            return _token_splittable(symbol)\n        return False\n    transformation = split_symbols_custom(can_split)\n    assert parse_expr('unsplittable', transformations=standard_transformations + (transformation, implicit_multiplication)) == sympy.Symbol('unsplittable')\n\n    # Test convert xor\n    assert parse_expr('2^3', transformations=standard_transformations + (convert_xor,)) == 2**3\n\n    # Test repeated decimals\n    assert parse_expr('0.2[1]', transformations=standard_transformations + (repeated_decimals,)) == sympy.Rational(19, 90)\n\n    # Test auto number\n    assert parse_expr('2', transformations=standard_transformations + (auto_number,)) == sympy.Integer(2)\n\n    # Test rationalize\n    assert parse_expr('0.5', transformations=standard_transformations + (auto_number, rationalize)) == sympy.Rational(1, 2)\n\n    # Test convert equals signs\n    assert parse_expr('1=2', transformations=standard_transformations + (convert_equals_signs,)) == sympy.Eq(1, 2)\n\n    # Test evaluate False\n    assert parse_expr('2+3', evaluate=False) =="], "sample_101": ["def test_wsgi_request(self):\n    environ = {\n        'REQUEST_METHOD': 'GET',\n        'SCRIPT_NAME': '/myapp',\n        'PATH_INFO': '/path/to/resource',\n        'QUERY_STRING': 'key=value',\n        'HTTP_COOKIE': 'sessionid=1234567890',\n        'CONTENT_LENGTH': '0',\n        'wsgi.input': BytesIO(),\n    }\n    request = WSGIRequest(environ)\n    self.assertEqual(request.path, '/myapp/path/to/resource')\n    self.assertEqual(request.method, 'GET')\n    self.assertEqual(request.GET, {'key': ['value']})\n    self.assertEqual(request.COOKIES, {'sessionid': '1234567890'})\n    self.assertEqual(request.META['PATH_INFO'], '/path/to/resource')\n    self.assertEqual(request.META['SCRIPT_NAME'], '/myapp')\n"], "sample_775": ["def test_estimator_pretty_printer():\n    # Test that the EstimatorPrettyPrinter correctly handles estimators\n    set_config(print_changed_only=True)\n    pp = _EstimatorPrettyPrinter(indent=1, width=80, depth=None, stream=None,\n                                 compact=False, indent_at_name=True,\n                                 n_max_elements_to_show=5)\n\n    # Test with a simple estimator\n    estimator = LogisticRegression()\n    estimator_str = pp.pformat(estimator)\n    assert \"LogisticRegression\" in estimator_str\n    assert \"penalty='l2'\" in estimator_str\n    assert \"dual=False\" in estimator_str\n\n    # Test with a pipeline\n    pipeline = make_pipeline(StandardScaler(), LogisticRegression())\n    pipeline_str = pp.pformat(pipeline)\n    assert \"Pipeline\" in pipeline_str\n    assert \"StandardScaler\" in pipeline_str\n    assert \"LogisticRegression\" in pipeline_str\n\n    # Test with a grid search\n    param_grid = {'C': [0.1, 1, 10]}\n    grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n    grid_search_str = pp.pformat(grid_search)\n    assert \"GridSearchCV\" in grid_search_str\n    assert \"LogisticRegression\" in grid_search_str\n    assert \"param_grid={'C': [0.1, 1, 10]}\" in grid_search_str\n\n    # Test with a feature selector\n    selector = SelectKBest(chi2, k=5)\n    selector_str = pp.pformat(selector)\n    assert \"SelectKBest\" in selector_str\n    assert \"score_func=<function chi2\" in selector_str\n    assert \"k=5\" in selector_str\n\n    # Test with a feature selector in a pipeline\n    pipeline = make_pipeline(StandardScaler(), selector, LogisticRegression())\n    pipeline_str = pp.pformat(pipeline)\n    assert \"Pipeline\" in pipeline_str\n    assert \"StandardScaler\" in pipeline_str\n    assert \"SelectKBest\" in pipeline_str\n    assert \"LogisticRegression\" in pipeline_str\n\n    # Test with a recursive feature eliminator\n    rfe = RFE(estimator=LogisticRegression(), n_features_to_select=5)\n    rfe_str = pp.pformat(rfe)\n    assert \"RFE\" in rfe_str\n    assert \"estimator=LogisticRegression\" in rfe_str\n    assert \"n_features_to_select=5"], "sample_144": ["def test_model_inheritance_check_constraints(self):\n    class ModelWithCheckConstraint(models.Model):\n        field = models.IntegerField()\n        class Meta:\n            constraints = [\n                models.CheckConstraint(check=models.Q(field__gt=0), name='field_gt_0'),\n            ]\n\n    class ModelWithUnsupportedCheckConstraint(ModelWithCheckConstraint):\n        class Meta:\n            constraints = [\n                models.CheckConstraint(check=models.Q(field__gt=0), name='field_gt_0'),\n            ]\n            required_db_features = ['supports_table_check_constraints']\n\n    with self.assertRaisesMessage(\n        checks.Error,\n        \"The database backend 'default' does not support check constraints.\"\n    ):\n        ModelWithUnsupportedCheckConstraint.check()\n\n    with self.assertNumQueries(0):\n        ModelWithCheckConstraint.check()\n"], "sample_188": ["    def test_window_frame(self):\n        # Test the WindowFrame class\n        frame = WindowFrame(start=5, end=10)\n        self.assertEqual(frame.start.value, 5)\n        self.assertEqual(frame.end.value, 10)\n\n        # Test the RowRange class\n        row_range = RowRange(start=5, end=10)\n        self.assertEqual(row_range.frame_type, 'ROWS')\n\n        # Test the ValueRange class\n        value_range = ValueRange(start=5, end=10)\n        self.assertEqual(value_range.frame_type, 'RANGE')\n\n        # Test the window_frame_start_end method\n        with mock.patch.object(connection.ops, 'window_frame_rows_start_end') as mock_method:\n            row_range.window_frame_start_end(connection, 5, 10)\n            mock_method.assert_called_once_with(5, 10)\n\n        with mock.patch.object(connection.ops, 'window_frame_range_start_end') as mock_method:\n            value_range.window_frame_start_end(connection, 5, 10)\n            mock_method.assert_called_once_with(5, 10)\n"], "sample_322": ["    def test_migration_plan_with_replaced_migration(self):\n        \"\"\"\n        Test that migration plan correctly handles replaced migrations.\n        \"\"\"\n        # Create a migration graph with a replaced migration\n        graph = MigrationGraph()\n        app_label = 'migrations'\n        migration_name = '0001_initial'\n        migration = migrations.Migration(app_label, migration_name)\n        migration.replaces = [('migrations', '0001_replaced')]\n        graph.add_migration(app_label, migration)\n        graph.add_dependency(app_label, migration_name, ('migrations', '0001_replaced'))\n\n        # Create a migration loader with the migration graph\n        loader = mock.Mock()\n        loader.graph = graph\n        loader.applied_migrations = {('migrations', '0001_replaced')}\n\n        # Create a migration executor with the migration loader\n        executor = MigrationExecutor(connection)\n        executor.loader = loader\n\n        # Test that the migration plan correctly handles the replaced migration\n        targets = [(app_label, migration_name)]\n        plan = executor.migration_plan(targets)\n        self.assertEqual(len(plan), 1)\n        self.assertEqual(plan[0][0].app_label, app_label)\n        self.assertEqual(plan[0][0].name, migration_name)\n        self.assertFalse(plan[0][1])  # Should be a forwards migration\n"], "sample_1003": ["def test_domain():\n    assert Options._init_dependencies_order() is None\n\n    assert Domain.preprocess('ZZ') == ZZ\n    assert Domain.preprocess('QQ') == QQ\n    assert Domain.preprocess('RR') == RR\n    assert Domain.preprocess('CC') == CC\n    assert Domain.preprocess('EX') == EX\n\n    assert Domain.preprocess('R_100') == RR(100)\n    assert Domain.preprocess('C_100') == CC(100)\n\n    assert Domain.preprocess('FF(5)') == FF(5)\n    assert Domain.preprocess('GF(5)') == GF(5)\n\n    assert Domain.preprocess('ZZ[x,y,z]') == ZZ.poly_ring(x, y, z)\n    assert Domain.preprocess('QQ[x,y,z]') == QQ.poly_ring(x, y, z)\n    assert Domain.preprocess('RR[x,y,z]') == RR.poly_ring(x, y, z)\n    assert Domain.preprocess('CC[x,y,z]') == CC.poly_ring(x, y, z)\n\n    assert Domain.preprocess('ZZ[x,y,z]/(x**2 + y**2 + z**2)') == ZZ.frac_field(x, y, z)\n    assert Domain.preprocess('QQ[x,y,z]/(x**2 + y**2 + z**2)') == QQ.frac_field(x, y, z)\n\n    assert Domain.preprocess('QQ<sqrt(2)>') == QQ.algebraic_field(sqrt(2))\n\n    raises(OptionError, lambda: Domain.preprocess('InvalidDomain'))\n\n    raises(GeneratorsError, lambda: Domain.postprocess({'gens': (x, y, z), 'domain': ZZ.poly_ring(x, y, z)}))\n\n    raises(GeneratorsError, lambda: Domain.postprocess({'domain': EX}))\n"], "sample_762": ["def test_clone():\n    # test cloning of a simple estimator\n    est = MyEstimator(l1=1)\n    est_clone = clone(est)\n    assert_true(est_clone.l1 == 1)\n    assert_true(est_clone.empty is None)\n\n    # test cloning of a pipeline\n    pipeline = Pipeline([('est', MyEstimator(l1=1))])\n    pipeline_clone = clone(pipeline)\n    assert_true(pipeline_clone.steps[0][1].l1 == 1)\n    assert_true(pipeline_clone.steps[0][1].empty is None)\n\n    # test cloning of a grid search\n    param_grid = {'est__l1': [1, 2]}\n    grid_search = GridSearchCV(MyEstimator(), param_grid, cv=2)\n    grid_search_clone = clone(grid_search)\n    assert_true(grid_search_clone.param_grid == param_grid)\n    assert_true(grid_search_clone.cv == 2)\n\n    # test cloning of a list of estimators\n    estimators = [MyEstimator(l1=1), MyEstimator(l1=2)]\n    estimators_clone = clone(estimators)\n    assert_true(len(estimators_clone) == 2)\n    assert_true(estimators_clone[0].l1 == 1)\n    assert_true(estimators_clone[1].l1 == 2)\n\n    # test cloning of a tuple of estimators\n    estimators = (MyEstimator(l1=1), MyEstimator(l1=2))\n    estimators_clone = clone(estimators)\n    assert_true(len(estimators_clone) == 2)\n    assert_true(estimators_clone[0].l1 == 1)\n    assert_true(estimators_clone[1].l1 == 2)\n\n    # test cloning of a set of estimators\n    estimators = {MyEstimator(l1=1), MyEstimator(l1=2)}\n    estimators_clone = clone(estimators)\n    assert_true(len(estimators_clone) == 2)\n    assert_true(set([est.l1 for est in estimators_clone]) == {1, 2})\n\n    # test cloning of a frozenset of estimators\n    estimators = frozenset({MyEstimator(l1=1), MyEstimator(l1=2)})\n    estimators_clone = clone(estimators)\n    assert_true(len(estimators_clone) == 2)\n    assert_true(set([est.l1 for est in estimators_clone]) == {1"], "sample_618": ["def test_broadcast_compat_data():\n    # Test that broadcast_compat_data correctly handles core dimensions\n    # that are not at the end of the input variable\n    var = xr.Variable((\"x\", \"y\"), np.random.rand(2, 3))\n    broadcast_dims = (\"z\",)\n    core_dims = (\"y\",)\n    data = broadcast_compat_data(var, broadcast_dims, core_dims)\n    assert data.shape == (1, 2, 3)\n    assert data[0, :, :].shape == var.data.shape\n\n    # Test that broadcast_compat_data correctly handles core dimensions\n    # that are not present on the input variable\n    var = xr.Variable((\"x\",), np.random.rand(2))\n    broadcast_dims = (\"y\", \"z\")\n    core_dims = (\"x\", \"y\")\n    with pytest.raises(ValueError):\n        broadcast_compat_data(var, broadcast_dims, core_dims)\n\n    # Test that broadcast_compat_data correctly handles unexpected dimensions\n    # on the input variable\n    var = xr.Variable((\"x\", \"y\", \"z\"), np.random.rand(2, 3, 4))\n    broadcast_dims = (\"w\",)\n    core_dims = (\"x\", \"y\")\n    with pytest.raises(ValueError):\n        broadcast_compat_data(var, broadcast_dims, core_dims)\n"], "sample_495": ["def test_paginator_validate_number(self):\n    paginator = Paginator([1, 2, 3, 4, 5], 2)\n    self.assertEqual(paginator.validate_number(1), 1)\n    self.assertEqual(paginator.validate_number(2), 2)\n    self.assertEqual(paginator.validate_number(3), 3)\n\n    with self.assertRaises(PageNotAnInteger):\n        paginator.validate_number('a')\n\n    with self.assertRaises(PageNotAnInteger):\n        paginator.validate_number(1.5)\n\n    with self.assertRaises(EmptyPage):\n        paginator.validate_number(0)\n\n    with self.assertRaises(EmptyPage):\n        paginator.validate_number(4)\n"], "sample_1184": ["def test_gaussian_conj():\n    s_in, z_r_in, f = symbols('s_in z_r_in f')\n    s_out, z_r_out, m = gaussian_conj(s_in, z_r_in, f)\n    assert streq(s_out, '1/(-1/(s_in + z_r_in**2/(-f + s_in)) + 1/f)')\n    assert streq(z_r_out, 'z_r_in/(1 - s_in**2/f**2 + z_r_in**2/f**2)')\n    assert streq(m, '1/sqrt(1 - s_in**2/f**2 + z_r_in**2/f**2)')\n"], "sample_582": ["def test_find_best_app(runner):\n    app = Flask(__name__)\n\n    with runner.isolated_filesystem():\n        with open(\"app.py\", \"w\") as f:\n            f.write(\"from flask import Flask\\napp = Flask(__name__)\\n\")\n\n        module = import_string(\"app\")\n        assert find_best_app(module) is module.app\n\n    with runner.isolated_filesystem():\n        with open(\"app.py\", \"w\") as f:\n            f.write(\"from flask import Flask\\napplication = Flask(__name__)\\n\")\n\n        module = import_string(\"app\")\n        assert find_best_app(module) is module.application\n\n    with runner.isolated_filesystem():\n        with open(\"app.py\", \"w\") as f:\n            f.write(\n                \"from flask import Flask\\ndef create_app():\\n  return Flask(__name__)\\n\"\n            )\n\n        module = import_string(\"app\")\n        assert find_best_app(module) is module.create_app()\n\n    with runner.isolated_filesystem():\n        with open(\"app.py\", \"w\") as f:\n            f.write(\n                \"from flask import Flask\\ndef make_app():\\n  return Flask(__name__)\\n\"\n            )\n\n        module = import_string(\"app\")\n        assert find_best_app(module) is module.make_app()\n\n    with runner.isolated_filesystem():\n        with open(\"app.py\", \"w\") as f:\n            f.write(\"from flask import Flask\\napp1 = Flask(__name__)\\napp2 = Flask(__name__)\\n\")\n\n        module = import_string(\"app\")\n        with pytest.raises(NoAppException):\n            find_best_app(module)\n\n    with runner.isolated_filesystem():\n        with open(\"app.py\", \"w\") as f:\n            f.write(\"from flask import Flask\\ndef create_app(arg):\\n  return Flask(__name__)\\n\")\n\n        module = import_string(\"app\")\n        with pytest.raises(NoAppException):\n            find_best_app(module)\n\n    with runner.isolated_filesystem():\n        with open(\"app.py\", \"w\") as f:\n            f.write(\"from flask import Flask\\ndef create_app():\\n  raise Exception()\\n\")\n\n        module = import_string(\"app\")\n        with pytest.raises(NoAppException):\n            find_best_app(module)\n\n    with runner.isolated_filesystem():\n        with open(\"app.py\", \"w\") as f:\n            f.write(\"from flask import Flask\\ndef create_app():\\"], "sample_520": ["def test_text_2d_to_3d():\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    text = Text(0, 0, 'Hello')\n    art3d.text_2d_to_3d(text, z=1, zdir='x')\n    ax.add_artist(text)\n    ax.set_xlim(-1, 1)\n    ax.set_ylim(-1, 1)\n    ax.set_zlim(-1, 1)\n"], "sample_589": ["def test_interp_na_with_max_gap(da):\n    # Test with max_gap as a scalar\n    result = da.interp_na(dim=\"time\", max_gap=2)\n    expected = xr.DataArray(\n        [0.0, 0.5, 1.0, 2.0, 2.5, 3.0, 4.0, 5.0, 5.5, 6.0, 7.0], dims=\"time\"\n    )\n    assert_array_equal(result, expected)\n\n    # Test with max_gap as a timedelta\n    result = da.interp_na(dim=\"time\", max_gap=\"2D\")\n    expected = xr.DataArray(\n        [0.0, 0.5, 1.0, 2.0, 2.5, 3.0, 4.0, 5.0, 5.5, 6.0, 7.0], dims=\"time\"\n    )\n    assert_array_equal(result, expected)\n\n    # Test with max_gap as a numpy timedelta64\n    result = da.interp_na(dim=\"time\", max_gap=np.timedelta64(2, \"D\"))\n    expected = xr.DataArray(\n        [0.0, 0.5, 1.0, 2.0, 2.5, 3.0, 4.0, 5.0, 5.5, 6.0, 7.0], dims=\"time\"\n    )\n    assert_array_equal(result, expected)\n\n    # Test with max_gap as a pandas Timedelta\n    result = da.interp_na(dim=\"time\", max_gap=pd.Timedelta(days=2))\n    expected = xr.DataArray(\n        [0.0, 0.5, 1.0, 2.0, 2.5, 3.0, 4.0, 5.0, 5.5, 6.0, 7.0], dims=\"time\"\n    )\n    assert_array_equal(result, expected)\n\n    # Test with max_gap that is too small\n    result = da.interp_na(dim=\"time\", max_gap=1)\n    expected = xr.DataArray(\n        [0.0, np.nan, 1.0, 2.0, np.nan, 3.0, 4.0, "], "sample_146": ["    def test_check_language_settings_consistent(self):\n        # Test with LANGUAGE_CODE that is in LANGUAGES\n        with override_settings(LANGUAGE_CODE='en', LANGUAGES=(('en', 'English'),)):\n            self.assertEqual(check_language_settings_consistent(None, None), [])\n\n        # Test with LANGUAGE_CODE that is not in LANGUAGES\n        with override_settings(LANGUAGE_CODE='fr', LANGUAGES=(('en', 'English'),)):\n            self.assertEqual(len(check_language_settings_consistent(None, None)), 1)\n            self.assertEqual(check_language_settings_consistent(None, None)[0].id, 'translation.E004')\n\n        # Test with LANGUAGE_CODE that is None\n        with override_settings(LANGUAGE_CODE=None, LANGUAGES=(('en', 'English'),)):\n            self.assertEqual(len(check_language_settings_consistent(None, None)), 1)\n            self.assertEqual(check_language_settings_consistent(None, None)[0].id, 'translation.E001')\n\n        # Test with LANGUAGE_CODE that is not a string\n        with override_settings(LANGUAGE_CODE=123, LANGUAGES=(('en', 'English'),)):\n            self.assertEqual(len(check_language_settings_consistent(None, None)), 1)\n            self.assertEqual(check_language_settings_consistent(None, None)[0].id, 'translation.E001')\n\n        # Test with LANGUAGE_CODE that is an invalid language code\n        with override_settings(LANGUAGE_CODE='en_US', LANGUAGES=(('en', 'English'),)):\n            self.assertEqual(len(check_language_settings_consistent(None, None)), 1)\n            self.assertEqual(check_language_settings_consistent(None, None)[0].id, 'translation.E001')\n"], "sample_1130": ["def test_partial_velocity():\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    p = Point('p')\n    u1, u2 = dynamicsymbols('u1, u2')\n    p.set_vel(N, u1 * N.x + u2 * A.y)\n    assert p.partial_velocity(N, u1) == N.x\n    assert p.partial_velocity(N, u1, u2) == (N.x, A.y)\n    with raises(ValueError):\n        p.partial_velocity(N, u1, u2, u1)\n"], "sample_533": ["def test_contour_labeler_event_handler():\n    fig, ax = plt.subplots()\n    cs = ContourSet(ax, [1, 2, 3], [[[0, 0], [1, 0], [1, 1], [0, 1]]])\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 0.5, 0.5)\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 1\n    assert len(cs.labelCValues) == 1\n    assert len(cs.labelXYs) == 1\n\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 0.5, 0.5)\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 2\n    assert len(cs.labelCValues) == 2\n    assert len(cs.labelXYs) == 2\n\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 0.5, 0.5, button=MouseButton.RIGHT)\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 1\n    assert len(cs.labelCValues) == 1\n    assert len(cs.labelXYs) == 1\n\n    event = mpl.backend_bases.LocationEvent('key_press_event', fig.canvas, 0.5, 0.5, key='enter')\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 1\n    assert len(cs.labelCValues) == 1\n    assert len(cs.labelXYs) == 1\n\n    event = mpl.backend_bases.LocationEvent('key_press_event', fig.canvas, 0.5, 0.5, key='backspace')\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 0\n    assert len(cs.labelCValues) == 0\n    assert len(cs.labelXYs) == 0\n"], "sample_556": ["def test_subfigure_layout_engine():\n    fig = plt.figure()\n    gs = gridspec.GridSpec(2, 2)\n    sfig1 = fig.add_subfigure(gs[0, 0])\n    sfig2 = fig.add_subfigure(gs[1, 1])\n    sfig1.set_layout_engine('constrained')\n    sfig2.set_layout_engine('tight')\n    assert isinstance(sfig1.get_layout_engine(), ConstrainedLayoutEngine)\n    assert isinstance(sfig2.get_layout_engine(), TightLayoutEngine)\n    assert isinstance(fig.get_layout_engine(), PlaceHolderLayoutEngine)\n"], "sample_1090": ["def test_comp():\n    assert S.comp(S.pi.n(4), 3.142)\n    assert not S.comp(S.pi.n(4), 3.141)\n    assert not S.comp(S.pi.n(4), 3.143)\n    assert S.comp(S.pi.n(4), 3.1415)\n    assert not S.comp(S.pi.n(4), 3.1415, '')\n    assert S.comp(S.pi.n(4), 3.14, .001)\n    assert not S.comp(S.pi.n(4), 3.14, .0005)\n    assert S.comp(1/S.pi.n(4), 0.3183, 1e-5)\n    assert not S.comp(1/S.pi.n(4), 0.3183, 9.78393554684764e-6)\n    assert S.comp(S.pi.n(4) - 3.14, 0, .002)\n    assert not S.comp(S.pi.n(4) - 3.14, 0, .001)\n"], "sample_498": ["def test_legend_get_legend_handler():\n    # Test that Legend.get_legend_handler returns the correct handler\n    # for different types of artists.\n    legend = mlegend.Legend(None, [], [])\n\n    # Test that a Line2D artist returns a HandlerLine2D handler.\n    line = mlines.Line2D([0], [0])\n    handler = legend.get_legend_handler(mlegend.Legend.get_default_handler_map(), line)\n    assert isinstance(handler, mlegend.legend_handler.HandlerLine2D)\n\n    # Test that a Patch artist returns a HandlerPatch handler.\n    patch = mpatches.Patch([])\n    handler = legend.get_legend_handler(mlegend.Legend.get_default_handler_map(), patch)\n    assert isinstance(handler, mlegend.legend_handler.HandlerPatch)\n\n    # Test that a tuple of artists returns a HandlerTuple handler.\n    tuple_artist = (line, patch)\n    handler = legend.get_legend_handler(mlegend.Legend.get_default_handler_map(), tuple_artist)\n    assert isinstance(handler, HandlerTuple)\n\n    # Test that an unknown artist type returns None.\n    unknown_artist = object()\n    handler = legend.get_legend_handler(mlegend.Legend.get_default_handler_map(), unknown_artist)\n    assert handler is None\n"], "sample_648": ["    def test_get_empty_parameterset_mark(self, pytestconfig):\n        pytestconfig.setini(\"markers\", [\"skipif(condition): skip the given test if...\"])\n        pytestconfig.setini(EMPTY_PARAMETERSET_OPTION, \"skip\")\n        mark = get_empty_parameterset_mark(pytestconfig, [\"arg1\", \"arg2\"], lambda x, y: None)\n        assert mark.name == \"skip\"\n        assert mark.args == ()\n        assert mark.kwargs == {\"reason\": \"got empty parameter set ('arg1', 'arg2'), function <lambda> at ?:?\"}\n\n        pytestconfig.setini(EMPTY_PARAMETERSET_OPTION, \"xfail\")\n        mark = get_empty_parameterset_mark(pytestconfig, [\"arg1\", \"arg2\"], lambda x, y: None)\n        assert mark.name == \"xfail\"\n        assert mark.args == ()\n        assert mark.kwargs == {\"reason\": \"got empty parameter set ('arg1', 'arg2'), function <lambda> at ?:?\", \"run\": False}\n\n        pytestconfig.setini(EMPTY_PARAMETERSET_OPTION, \"fail_at_collect\")\n        with pytest.raises(Collector.CollectError):\n            get_empty_parameterset_mark(pytestconfig, [\"arg1\", \"arg2\"], lambda x, y: None)\n\n        pytestconfig.setini(EMPTY_PARAMETERSET_OPTION, \"unknown\")\n        with pytest.raises(LookupError):\n            get_empty_parameterset_mark(pytestconfig, [\"arg1\", \"arg2\"], lambda x, y: None)\n"], "sample_614": ["    def test_diff_array_repr(self):\n        a = xr.DataArray([1, 2, 3], dims='x')\n        b = xr.DataArray([1, 2, 4], dims='x')\n        expected = dedent(\n            \"\"\"\\\n            Left and right DataArray objects are not equal\n            Differing values:\n            L\n            array([1, 2, 3])\n            R\n            array([1, 2, 4])\"\"\"\n        )\n        assert formatting.diff_array_repr(a, b, 'equals') == expected\n\n        a = xr.DataArray([1, 2, 3], dims='x', attrs={'foo': 'bar'})\n        b = xr.DataArray([1, 2, 3], dims='x', attrs={'foo': 'baz'})\n        expected = dedent(\n            \"\"\"\\\n            Left and right DataArray objects are not identical\n            Differing attributes:\n            L\n                foo: 'bar'\n            R\n                foo: 'baz'\"\"\"\n        )\n        assert formatting.diff_array_repr(a, b, 'identical') == expected\n"], "sample_88": ["def test_email_message_with_attachment(self):\n    subject = 'Test email with attachment'\n    body = 'This is a test email with an attachment.'\n    from_email = 'from@example.com'\n    to = ['to@example.com']\n    attachment_filename = 'test.txt'\n    attachment_content = b'Hello, world!'\n    attachment_mimetype = 'text/plain'\n\n    email = EmailMessage(subject, body, from_email, to)\n    email.attach(attachment_filename, attachment_content, attachment_mimetype)\n\n    self.assertEqual(email.subject, subject)\n    self.assertEqual(email.body, body)\n    self.assertEqual(email.from_email, from_email)\n    self.assertEqual(email.to, to)\n    self.assertEqual(email.attachments, [(attachment_filename, attachment_content, attachment_mimetype)])\n\n    decoded_attachments = self.get_decoded_attachments(email)\n    self.assertEqual(len(decoded_attachments), 1)\n    filename, content, mimetype = decoded_attachments[0]\n    self.assertEqual(filename, attachment_filename)\n    self.assertEqual(content, attachment_content)\n    self.assertEqual(mimetype, attachment_mimetype)\n\n    # Test that the attachment is correctly encoded in the email message\n    msg_bytes = email.message().as_bytes()\n    email_message = message_from_bytes(msg_bytes)\n    self.assertEqual(email_message['Subject'], subject)\n    self.assertEqual(email_message['From'], from_email)\n    self.assertEqual(email_message['To'], ', '.join(to))\n    self.assertEqual(email_message.get_content_type(), 'multipart/mixed')\n\n    # Test that the attachment is correctly decoded from the email message\n    attachment_part = None\n    for part in email_message.walk():\n        if part.get_content_disposition() == 'attachment':\n            attachment_part = part\n            break\n    self.assertIsNotNone(attachment_part)\n    self.assertEqual(attachment_part.get_filename(), attachment_filename)\n    self.assertEqual(attachment_part.get_payload(decode=True), attachment_content)\n    self.assertEqual(attachment_part.get_content_type(), attachment_mimetype)\n"], "sample_1102": ["def test_to_rational_coeffs():\n    assert to_rational_coeffs(Poly(((x**2-1)*(x-2)).subs({x:x*(1 + sqrt(2))}, domain='EX')))[0:3] == (7 + 5*sqrt(2), 2 - 2*sqrt(2), None)\n    assert to_rational_coeffs(Poly(((x**2-1)*(x-2)).subs({x:x + sqrt(2)}, domain='EX')))[0:3] == (None, None, -sqrt(2))\n    assert to_rational_coeffs(Poly(x**2 + 2*x + 1, domain='EX')) is None\n"], "sample_514": ["def test_colorbar_extension_length():\n    \"\"\"\n    Test that colorbar extensions have the correct length for uniform and\n    proportional spacing.\n    \"\"\"\n    _colorbar_extension_length('uniform')\n    _colorbar_extension_length('proportional')\n\n"], "sample_1082": ["def test_hyperbolic_functions():\n    x = symbols('x')\n    z = symbols('z')\n\n    # Test sinh\n    assert sinh(x).diff(x) == cosh(x)\n    assert sinh(x).inverse() == asinh\n    assert sinh(0) == 0\n    assert sinh(pi*I/2) == I\n    assert sinh(-pi*I/2) == -I\n    assert sinh(pi*I) == 0\n    assert sinh(-pi*I) == 0\n    assert sinh(oo) == oo\n    assert sinh(-oo) == -oo\n    assert sinh(zoo) == zoo\n    assert sinh(nan) == nan\n\n    # Test cosh\n    assert cosh(x).diff(x) == sinh(x)\n    assert cosh(x).inverse() == acosh\n    assert cosh(0) == 1\n    assert cosh(pi*I/2) == 0\n    assert cosh(-pi*I/2) == 0\n    assert cosh(pi*I) == -1\n    assert cosh(-pi*I) == -1\n    assert cosh(oo) == oo\n    assert cosh(-oo) == oo\n    assert cosh(zoo) == zoo\n    assert cosh(nan) == nan\n\n    # Test tanh\n    assert tanh(x).diff(x) == 1 - tanh(x)**2\n    assert tanh(x).inverse() == atanh\n    assert tanh(0) == 0\n    assert tanh(pi*I/4) == I\n    assert tanh(-pi*I/4) == -I\n    assert tanh(pi*I/2) == zoo\n    assert tanh(-pi*I/2) == zoo\n    assert tanh(oo) == 1\n    assert tanh(-oo) == -1\n    assert tanh(zoo) == zoo\n    assert tanh(nan) == nan\n\n    # Test coth\n    assert coth(x).diff(x) == -1/sinh(x)**2\n    assert coth(x).inverse() == acoth\n    assert coth(0) == zoo\n    assert coth(pi*I/2) == 0\n    assert coth(-pi*I/2) == 0\n    assert coth(pi*I) == -1\n    assert coth(-pi*I) =="], "sample_310": ["    def test_view_index_view(self):\n        response = self.client.get(reverse('django-admindocs:django.views.generic.base.ViewIndexView'))\n        self.assertEqual(response.status_code, 200)\n        self.assertTemplateUsed(response, 'admin_doc/view_index.html')\n"], "sample_251": ["def test_expression_wrapper(self):\n    expr = F('name')\n    wrapped_expr = ExpressionWrapper(expr, output_field=CharField())\n    self.assertIsInstance(wrapped_expr, ExpressionWrapper)\n    self.assertEqual(wrapped_expr.expression, expr)\n    self.assertEqual(wrapped_expr.output_field, CharField())\n\n    # Test that ExpressionWrapper can be used in a query\n    authors = Author.objects.annotate(wrapped_name=wrapped_expr)\n    self.assertEqual(authors[0].wrapped_name, 'Adrian Holovaty')\n\n    # Test that ExpressionWrapper can be used in a filter\n    authors = Author.objects.filter(wrapped_name='Adrian Holovaty')\n    self.assertEqual(authors[0].name, 'Adrian Holovaty')\n\n    # Test that ExpressionWrapper can be used in an order_by\n    authors = Author.objects.order_by(wrapped_expr)\n    self.assertEqual(authors[0].name, 'Adrian Holovaty')\n\n    # Test that ExpressionWrapper can be used in an aggregate\n    authors = Author.objects.annotate(count=Count(wrapped_expr))\n    self.assertEqual(authors[0].count, 1)\n\n    # Test that ExpressionWrapper can be used in a subquery\n    subquery = Author.objects.filter(wrapped_name='Adrian Holovaty').values('id')\n    authors = Author.objects.filter(id__in=subquery)\n    self.assertEqual(authors[0].name, 'Adrian Holovaty')\n"], "sample_797": ["def test_power_transformer():\n    # Test that the power transformer works correctly\n    X = np.array([[1, 2], [3, 2], [4, 5]])\n    pt = PowerTransformer(method='yeo-johnson', standardize=True)\n    X_trans = pt.fit_transform(X)\n    assert_allclose(X_trans.mean(axis=0), np.zeros(X.shape[1]))\n    assert_allclose(X_trans.std(axis=0), np.ones(X.shape[1]))\n\n    # Test that the power transformer works correctly with NaNs\n    X = np.array([[1, 2], [3, np.nan], [4, 5]])\n    pt = PowerTransformer(method='yeo-johnson', standardize=True)\n    X_trans = pt.fit_transform(X)\n    assert_allclose(X_trans.mean(axis=0), np.zeros(X.shape[1]))\n    assert_allclose(X_trans.std(axis=0), np.ones(X.shape[1]))\n\n    # Test that the power transformer works correctly with negative values\n    X = np.array([[-1, 2], [3, -2], [4, 5]])\n    pt = PowerTransformer(method='yeo-johnson', standardize=True)\n    X_trans = pt.fit_transform(X)\n    assert_allclose(X_trans.mean(axis=0), np.zeros(X.shape[1]))\n    assert_allclose(X_trans.std(axis=0), np.ones(X.shape[1]))\n\n    # Test that the power transformer raises an error with invalid method\n    with assert_raises_regex(ValueError, \"'method' must be one of\"):\n        PowerTransformer(method='invalid')\n\n    # Test that the power transformer raises an error with non-positive data\n    X = np.array([[0, 2], [3, 2], [4, 5]])\n    with assert_raises_regex(ValueError, \"The Box-Cox transformation can only\"):\n        PowerTransformer(method='box-cox').fit(X)\n\n    # Test that the power transformer works correctly with a pipeline\n    X = np.array([[1, 2], [3, 2], [4, 5]])\n    pipeline = Pipeline([('pt', PowerTransformer(method='yeo-johnson'))])\n    X_trans = pipeline.fit_transform(X)\n    assert_allclose(X_trans.mean(axis=0), np.zeros(X.shape[1]))\n    assert_allclose(X_trans.std(axis=0), np.ones(X.shape[1]))\n\n    # Test that the power transformer works correctly with"], "sample_227": ["    def test_generic_foreign_key(self):\n        bookmark = Bookmark.objects.create(url='https://www.example.com')\n        tag = TaggedItem.objects.create(tag='example', content_object=bookmark)\n        self.assertEqual(tag.content_object, bookmark)\n"], "sample_148": ["    def test_quote(self):\n        self.assertEqual(quote('hello'), 'hello')\n        self.assertEqual(quote('hello/world'), 'hello_world')\n        self.assertEqual(quote('hello:world'), 'hello_world')\n"], "sample_228": ["    def test_management_form(self):\n        management_form = ManagementForm(auto_id='id_%s', prefix='my_prefix')\n        self.assertEqual(management_form.fields[TOTAL_FORM_COUNT].widget, HiddenInput())\n        self.assertEqual(management_form.fields[INITIAL_FORM_COUNT].widget, HiddenInput())\n        self.assertEqual(management_form.fields[MIN_NUM_FORM_COUNT].widget, HiddenInput())\n        self.assertEqual(management_form.fields[MAX_NUM_FORM_COUNT].widget, HiddenInput())\n"], "sample_798": ["def test_ridge_regression_sparse():\n    # Test that Ridge regression works with sparse matrices\n    X = sp.csr_matrix(np.array([[1, 0, 0], [0, 0, 0], [0, 0, 1]]))\n    y = np.array([1, 0, 1])\n    alpha = 1.0\n    solver = \"sparse_cg\"\n\n    ridge = Ridge(alpha=alpha, solver=solver)\n    ridge.fit(X, y)\n\n    assert_array_almost_equal(ridge.coef_, np.array([1., 0., 1.]))\n\n    # Test that Ridge regression works with sparse matrices and sample weights\n    sample_weight = np.array([1, 2, 3])\n    ridge.fit(X, y, sample_weight=sample_weight)\n\n    assert_array_almost_equal(ridge.coef_, np.array([1., 0., 1.]))\n\n    # Test that Ridge regression works with sparse matrices and multiple targets\n    y = np.array([[1, 2], [0, 0], [1, 2]])\n    ridge.fit(X, y)\n\n    assert_array_almost_equal(ridge.coef_, np.array([[1., 0., 1.], [2., 0., 2.]]))\n\n    # Test that Ridge regression works with sparse matrices and multiple targets and sample weights\n    ridge.fit(X, y, sample_weight=sample_weight)\n\n    assert_array_almost_equal(ridge.coef_, np.array([[1., 0., 1.], [2., 0., 2.]]))\n"], "sample_425": ["    def test_serializer_factory_with_lazy_object(self):\n        lazy_object = SimpleLazyObject(lambda: \"lazy_value\")\n        serializer = serializer_factory(lazy_object)\n        self.assertIsInstance(serializer, BaseSimpleSerializer)\n        serialized_value, imports = serializer.serialize()\n        self.assertEqual(serialized_value, \"'lazy_value'\")\n        self.assertEqual(imports, set())\n"], "sample_298": ["def test_make_token_with_timestamp(self):\n    user = User.objects.create_user('testuser', 'test@example.com', 'password')\n    token_generator = PasswordResetTokenGenerator()\n    token = token_generator.make_token(user)\n    self.assertIsNotNone(token)\n    self.assertIsInstance(token, str)\n    self.assertGreater(len(token), 0)\n"], "sample_978": ["def test_bspline_basis():\n    # Test degree 0\n    b = bspline_basis(0, [0, 1, 2, 3], 0, x)\n    assert b == Piecewise((1, (x >= 0) & (x <= 1)), (0, True))\n    b = bspline_basis(0, [0, 1, 2, 3], 1, x)\n    assert b == Piecewise((1, (x >= 1) & (x <= 2)), (0, True))\n    b = bspline_basis(0, [0, 1, 2, 3], 2, x)\n    assert b == Piecewise((1, (x >= 2) & (x <= 3)), (0, True))\n\n    # Test degree 1\n    b = bspline_basis(1, [0, 1, 2, 3], 0, x)\n    assert b == Piecewise((x, (x >= 0) & (x <= 1)), (-x + 2, (x >= 1) & (x <= 2)), (0, True))\n    b = bspline_basis(1, [0, 1, 2, 3], 1, x)\n    assert b == Piecewise((-x + 1, (x >= 1) & (x <= 2)), (x - 2, (x >= 2) & (x <= 3)), (0, True))\n\n    # Test degree 2\n    b = bspline_basis(2, [0, 1, 2, 3, 4], 0, x)\n    assert b == Piecewise((x**2/2, (x >= 0) & (x <= 1)), (-x**2 + 3*x - 3/2, (x >= 1) & (x <= 2)), (x**2/2 - 3*x + 9/2, (x >= 2) & (x <= 3)), (0, True))\n    b = bspline_basis(2, [0, 1, 2, 3, 4], 1, x)\n    assert b == Piecewise((x**2/2 - x + 1/2, (x >= 1) & (x <= "], "sample_170": ["    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        request.user = User()\n        exc_type = Exception\n        exc_value = Exception('Test exception')\n        tb = None\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIn('request', data)\n        self.assertIn('request_meta', data)\n        self.assertIn('user_str', data)\n        self.assertIn('filtered_POST_items', data)\n        self.assertIn('settings', data)\n        self.assertIn('sys_executable', data)\n        self.assertIn('sys_version_info', data)\n        self.assertIn('server_time', data)\n        self.assertIn('django_version_info', data)\n        self.assertIn('sys_path', data)\n        self.assertIn('template_info', data)\n        self.assertIn('template_does_not_exist', data)\n        self.assertIn('postmortem', data)\n        self.assertIn('exception_type', data)\n        self.assertIn('exception_value', data)\n        self.assertIn('lastframe', data)\n"], "sample_78": ["    def test_handle_default_options(self):\n        with mock.patch.dict(os.environ, {}):\n            options = mock.Mock(settings='my_settings', pythonpath='my_path')\n            handle_default_options(options)\n            self.assertEqual(os.environ['DJANGO_SETTINGS_MODULE'], 'my_settings')\n            self.assertIn('my_path', sys.path)\n\n        with mock.patch.dict(os.environ, {'DJANGO_SETTINGS_MODULE': 'old_settings'}):\n            options = mock.Mock(settings='new_settings')\n            handle_default_options(options)\n            self.assertEqual(os.environ['DJANGO_SETTINGS_MODULE'], 'new_settings')\n\n        options = mock.Mock(settings=None, pythonpath=None)\n        handle_default_options(options)\n        self.assertNotIn('DJANGO_SETTINGS_MODULE', os.environ)\n        self.assertNotIn('my_path', sys.path)\n"], "sample_656": ["def test_capture_manager_suspend_resume(capsys):\n    capman = capture.CaptureManager(\"fd\")\n    capman.start_global_capturing()\n    capman.suspend_global_capture()\n    assert capman.is_globally_capturing() is True\n    capman.resume_global_capture()\n    assert capman.is_globally_capturing() is True\n    capman.stop_global_capturing()\n    assert capman.is_globally_capturing() is False\n"], "sample_523": ["def test_legend_draggable():\n    fig, ax = plt.subplots()\n    line1, = ax.plot([1, 2, 3], label='Line 1')\n    line2, = ax.plot([2, 3, 4], label='Line 2')\n    ax.legend(handler_map={Line2D: HandlerTuple(ndivide=None)},\n              loc='upper right', bbox_to_anchor=(1.05, 1),\n              borderaxespad=0., frameon=False, draggable=True)\n    return fig\n"], "sample_587": ["def test_merge_variables():\n    # Create two variables with the same name but different values\n    var1 = xr.Variable((\"x\",), [1, 2, 3])\n    var2 = xr.Variable((\"x\",), [4, 5, 6])\n\n    # Test that merge_variables raises a MergeError when compat is 'identical'\n    with pytest.raises(merge.MergeError):\n        merge.unique_variable(\"x\", [var1, var2], compat=\"identical\")\n\n    # Test that merge_variables returns the first variable when compat is 'override'\n    result = merge.unique_variable(\"x\", [var1, var2], compat=\"override\")\n    assert result.equals(var1)\n\n    # Test that merge_variables returns the first variable when compat is 'broadcast_equals'\n    result = merge.unique_variable(\"x\", [var1, var2], compat=\"broadcast_equals\")\n    assert result.equals(var1)\n\n    # Test that merge_variables returns the first variable when compat is 'equals'\n    result = merge.unique_variable(\"x\", [var1, var2], compat=\"equals\")\n    assert result.equals(var1)\n\n    # Test that merge_variables returns the first variable when compat is 'no_conflicts'\n    result = merge.unique_variable(\"x\", [var1, var2], compat=\"no_conflicts\")\n    assert result.equals(var1)\n\n    # Test that merge_variables returns the first variable when compat is 'minimal'\n    result = merge.unique_variable(\"x\", [var1, var2], compat=\"minimal\")\n    assert result.equals(var1)\n"], "sample_969": ["def test_restify():\n    assert restify(None) == ':py:obj:`None`'\n    assert restify(Ellipsis) == '...'\n    assert restify(str) == ':py:class:`str`'\n    assert restify(Struct) == ':py:class:`struct.Struct`'\n    assert restify(TracebackType) == ':py:class:`types.TracebackType`'\n    assert restify(MyClass1) == ':py:class:`test_util_typing.MyClass1`'\n    assert restify(MyClass2) == ':py:class:`MyClass2`'\n    assert restify(MyInt) == ':py:class:`test_util_typing.MyInt`'\n    assert restify(MyList) == ':py:class:`test_util_typing.MyList`\\\\ [~typing.Any]'\n    assert restify(List) == ':py:class:`list`'\n    assert restify(List[int]) == ':py:class:`list`\\\\ [int]'\n    assert restify(List[Tuple[int, str]]) == ':py:class:`list`\\\\ [~typing.Tuple\\\\ [int, str]]'\n    assert restify(Union[int, str]) == ':py:obj:`~typing.Union`\\\\ [int, str]'\n    assert restify(Optional[int]) == ':py:obj:`~typing.Optional`\\\\ [int]'\n    assert restify(Callable[[int, str], bool]) == ':py:obj:`~typing.Callable`\\\\ [[int, str], bool]'\n    assert restify(Generator[int, str, bool]) == ':py:obj:`~typing.Generator`\\\\ [int, str, bool]'\n    assert restify(Dict[str, int]) == ':py:class:`dict`\\\\ [str, int]'\n    assert restify(BrokenType) == ':py:class:`test_util_typing.BrokenType`'\n"], "sample_150": ["    def test_handle_default_options(self):\n        options = mock.Mock()\n        options.settings = 'my_settings'\n        options.pythonpath = '/path/to/python'\n        handle_default_options(options)\n        self.assertEqual(os.environ['DJANGO_SETTINGS_MODULE'], 'my_settings')\n        self.assertIn('/path/to/python', sys.path)\n"], "sample_970": ["def test_signature_from_str():\n    sig = inspect.signature_from_str('(a: int, b: str) -> None')\n    assert len(sig.parameters) == 2\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.return_annotation == type(None)\n"], "sample_1088": ["def test_symmetrize():\n    assert symmetrize(x**2 + y**2) == (-2*x*y + (x + y)**2, 0)\n    assert symmetrize(x**2 + y**2, formal=True) == ((S(1)**2 - 2*S(2), 0), [(S(1), x + y), (S(2), x*y)])\n    assert symmetrize(x**2 - y**2) == (-2*x*y + (x + y)**2, -2*y**2)\n    assert symmetrize(x**2 - y**2, formal=True) == ((S(1)**2 - 2*S(2), -2*y**2), [(S(1), x + y), (S(2), x*y)])\n"], "sample_907": ["def test_template_introduction():\n    input = \"template <typename T> concept C<T> { T t; }\"\n    idDict = {2: \"I0T_E\", 3: \"I0T_E\", 4: \"I0T_E\"}\n    output = \"template <typename T> concept C<T> { T t; }\"\n    check(\"concept\", input, idDict, output)\n"], "sample_320": ["    def test_rename_index(self):\n        # Create a model with an index\n        operation = migrations.CreateModel(\n            \"TestModel\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=255)),\n            ],\n            options={\"indexes\": [models.Index(fields=[\"name\"])]},\n        )\n        project_state = ProjectState()\n        operation.state_forwards(\"app\", project_state)\n        self.assertIndexExists(project_state, \"app\", \"testmodel\", \"testmodel_name\")\n\n        # Rename the index\n        rename_operation = migrations.RenameIndex(\n            \"TestModel\", \"new_name\", \"testmodel_name\"\n        )\n        rename_operation.state_forwards(\"app\", project_state)\n        self.assertIndexExists(project_state, \"app\", \"testmodel\", \"new_name\")\n\n        # Reverse the rename operation\n        rename_operation.database_backwards(\n            \"app\", self.schema_editor, project_state, project_state.clone()\n        )\n        self.assertIndexExists(project_state, \"app\", \"testmodel\", \"testmodel_name\")\n"], "sample_1157": ["def test_parse_expr():\n    # Test implicit multiplication\n    assert parse_expr('2 x', transformations=(standard_transformations +\n                                             (implicit_multiplication,))) == 2*Symbol('x')\n\n    # Test implicit application\n    assert parse_expr('sin x', transformations=(standard_transformations +\n                                               (implicit_application,))) == sin(Symbol('x'))\n\n    # Test implicit multiplication and application\n    assert parse_expr('2 sin x', transformations=(standard_transformations +\n                                                 (implicit_multiplication_application,))) == 2*sin(Symbol('x'))\n\n    # Test function exponentiation\n    assert parse_expr('sin**2 x', transformations=(standard_transformations +\n                                                  (function_exponentiation,))) == sin(Symbol('x'))**2\n\n    # Test implicit multiplication and function exponentiation\n    assert parse_expr('2 sin**2 x', transformations=(standard_transformations +\n                                                    (implicit_multiplication, function_exponentiation))) == 2*sin(Symbol('x'))**2\n\n    # Test implicit application and function exponentiation\n    assert parse_expr('sin**2 x', transformations=(standard_transformations +\n                                                  (implicit_application, function_exponentiation))) == sin(Symbol('x'))**2\n\n    # Test implicit multiplication, application, and function exponentiation\n    assert parse_expr('2 sin**2 x', transformations=(standard_transformations +\n                                                    (implicit_multiplication_application, function_exponentiation))) == 2*sin(Symbol('x'))**2\n\n    # Test convert equals signs\n    assert parse_expr('2 = 3', transformations=(standard_transformations +\n                                                (convert_equals_signs,))) == Eq(2, 3)\n\n    # Test convert equals signs with implicit multiplication\n    assert parse_expr('2 x = 3', transformations=(standard_transformations +\n                                                  (implicit_multiplication, convert_equals_signs))) == Eq(2*Symbol('x'), 3)\n\n    # Test convert equals signs with implicit application\n    assert parse_expr('sin x = 3', transformations=(standard_transformations +\n                                                    (implicit_application, convert_equals_signs))) == Eq(sin(Symbol('x')), 3)\n\n    # Test convert equals signs with implicit multiplication and application\n    assert parse_expr('2 sin x = 3', transformations=(standard_transformations +\n                                                      (implicit_multiplication_application, convert_equals_signs))) == Eq(2*sin(Symbol('x')), 3)\n\n    # Test convert equals signs with function exponentiation\n    assert parse_expr('sin**2 x ="], "sample_935": ["def test_template_introduction():\n    input = \"template <typename T> concept C<T> { }\"\n    idDict = {2: \"I0X3CIXE\", 3: \"I0X3CIXE\", 4: \"I0X3CIXE\"}\n    output = \"template <typename T> concept C<T> { }\"\n    check(\"concept\", input, idDict, output)\n"], "sample_873": ["def test_inverse_transform_sparse():\n    # Test that inverse_transform works with sparse matrices\n    selector = StepSelector(step=2)\n    selector.fit(X)\n    Xt_sparse = selector.transform(sp.csc_matrix(X))\n    Xinv_sparse = selector.inverse_transform(Xt_sparse)\n    assert_array_equal(Xinv_sparse.toarray(), Xinv)\n\n"], "sample_1004": ["def test_conditionset():\n    # Test ConditionSet with a non-symbol dummy\n    raises(ValueError, lambda: ConditionSet(x + 1, x < 1, S.Integers))\n\n    # Test ConditionSet with a condition that is always False\n    assert ConditionSet(x, x < x, S.Integers) == EmptySet()\n\n    # Test ConditionSet with a condition that is always True\n    assert ConditionSet(x, x < oo, S.Integers) == S.Integers\n\n    # Test ConditionSet with a base set that is an Interval\n    assert ConditionSet(x, x < 1, Interval(0, 2)) == Interval(0, 1)\n\n    # Test ConditionSet with a base set that is a Union\n    assert ConditionSet(x, x < 1, Union(Interval(0, 2), Interval(3, 4))) == Interval(0, 1)\n\n    # Test ConditionSet with a base set that is an Intersection\n    assert ConditionSet(x, x < 1, Intersection(Interval(0, 2), Interval(1, 3))) == Interval(1, 2)\n\n    # Test ConditionSet with a condition that involves a function\n    assert ConditionSet(x, f(x) < 1, S.Reals) == ConditionSet(x, f(x) < 1, S.Reals)\n\n    # Test ConditionSet with a condition that involves a Lambda function\n    assert ConditionSet(x, Lambda(x, x < 1)(x), S.Reals) == ConditionSet(x, x < 1, S.Reals)\n\n    # Test ConditionSet with a condition that involves a Mod\n    assert ConditionSet(x, Mod(x, 2) < 1, S.Integers) == ConditionSet(x, Mod(x, 2) < 1, S.Integers)\n\n    # Test ConditionSet with a condition that involves an Abs\n    assert ConditionSet(x, Abs(x) < 1, S.Reals) == Interval(-1, 1)\n\n    # Test ConditionSet with a condition that involves a sin\n    assert ConditionSet(x, sin(x) < 1, Interval(0, 2*pi)) == ConditionSet(x, sin(x) < 1, Interval(0, 2*pi))\n\n    # Test ConditionSet with a condition that involves an And\n    assert ConditionSet(x, And(x < 1, x > 0), S.Re"], "sample_1153": ["def test_polar_lift():\n    x = Symbol('x')\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*polar_lift(x)) == 4*polar_lift(x)\n"], "sample_923": ["def test_parse_nested_name():\n    parser = DefinitionParser(\"a::b::c\", location=None, config=None)\n    ast = parser._parse_nested_name()\n    assert str(ast) == \"a::b::c\"\n\n    parser = DefinitionParser(\"a::b::c::\", location=None, config=None)\n    with pytest.raises(DefinitionError):\n        parser._parse_nested_name()\n\n    parser = DefinitionParser(\"a::b::c::d\", location=None, config=None)\n    ast = parser._parse_nested_name()\n    assert str(ast) == \"a::b::c::d\"\n\n    parser = DefinitionParser(\"a::b::c::d::\", location=None, config=None)\n    with pytest.raises(DefinitionError):\n        parser._parse_nested_name()\n\n    parser = DefinitionParser(\"::a::b::c\", location=None, config=None)\n    ast = parser._parse_nested_name()\n    assert str(ast) == \"::a::b::c\"\n\n    parser = DefinitionParser(\"::a::b::c::\", location=None, config=None)\n    with pytest.raises(DefinitionError):\n        parser._parse_nested_name()\n\n    parser = DefinitionParser(\"::a::b::c::d\", location=None, config=None)\n    ast = parser._parse_nested_name()\n    assert str(ast) == \"::a::b::c::d\"\n\n    parser = DefinitionParser(\"::a::b::c::d::\", location=None, config=None)\n    with pytest.raises(DefinitionError):\n        parser._parse_nested_name()\n\n    parser = DefinitionParser(\"a::b::c::d::e::\", location=None, config=None)\n    with pytest.raises(DefinitionError):\n        parser._parse_nested_name()\n\n    parser = DefinitionParser(\"a::b::c::d::e::f\", location=None, config=None)\n    ast = parser._parse_nested_name()\n    assert str(ast) == \"a::b::c::d::e::f\"\n\n    parser = DefinitionParser(\"a::b::c::d::e::f::\", location=None, config=None)\n    with pytest.raises(DefinitionError):\n        parser._parse_nested_name()\n"], "sample_308": ["    def test_format_date(self):\n        d = date(2003, 10, 7)\n        self.assertEqual(format(d, 'jS F Y'), '7th October 2003')\n        self.assertEqual(format(d, 'l, jS F Y'), 'Tuesday, 7th October 2003')\n        self.assertEqual(format(d, 'l, jS F Y H:i'), 'Tuesday, 7th October 2003 00:00')\n        self.assertEqual(format(d, 'l, jS F Y H:i:s'), 'Tuesday, 7th October 2003 00:00:00')\n        self.assertEqual(format(d, 'l, jS F Y H:i:s.u'), 'Tuesday, 7th October 2003 00:00:00.000000')\n"], "sample_232": ["def test_jsonfield_encoder_decoder(self):\n    encoder = mock.Mock()\n    decoder = mock.Mock()\n    field = JSONField(encoder=encoder, decoder=decoder)\n    value = {'key': 'value'}\n    self.assertEqual(field.get_prep_value(value), encoder.return_value)\n    encoder.assert_called_once_with(value)\n    self.assertEqual(field.from_db_value('{\"key\": \"value\"}'), decoder.return_value)\n    decoder.assert_called_once_with('{\"key\": \"value\"}', cls=None)\n\n    with self.assertRaises(ValueError):\n        JSONField(encoder='not callable')\n\n    with self.assertRaises(ValueError):\n        JSONField(decoder='not callable')\n"], "sample_610": ["compilation error"], "sample_455": ["    def test_base_constraint_repr(self):\n        constraint = BaseConstraint(name='test_constraint')\n        self.assertEqual(repr(constraint), \"<BaseConstraint: name='test_constraint'>\")\n"], "sample_576": ["    def test_init(self):\n\n        p = Plot()\n        assert p._data.frame.empty\n        assert p._layers == []\n        assert p._scales == {}\n        assert p._shares == {}\n        assert p._limits == {}\n        assert p._labels == {}\n        assert p._theme == {}\n        assert p._facet_spec == {}\n        assert p._pair_spec == {}\n        assert p._figure_spec == {}\n        assert p._subplot_spec == {}\n        assert p._layout_spec == {}\n        assert p._target is None\n"], "sample_724": ["def test_imputer_most_frequent_ties():\n    \"\"\"Test most frequent strategy when there are ties.\"\"\"\n    X = np.array([[1, 2, np.nan], [np.nan, 2, 3], [1, 2, 3]])\n    X_true = np.array([[1, 2, 3], [1, 2, 3], [1, 2, 3]])\n    statistics = np.array([1, 2, 3])\n\n    _check_statistics(X, X_true, \"most_frequent\", statistics, np.nan)\n\n    X = np.array([[1, 2, np.nan], [np.nan, 2, 3], [1, 2, 3]])\n    X_true = np.array([[1, 2, 3], [1, 2, 3], [1, 2, 3]])\n    statistics = np.array([1, 2, 3])\n\n    _check_statistics(X, X_true, \"most_frequent\", statistics, np.nan)\n\n    X = np.array([[1, 2, np.nan], [np.nan, 2, 3], [1, 2, 3]])\n    X_true = np.array([[1, 2, 3], [1, 2, 3], [1, 2, 3]])\n    statistics = np.array([1, 2, 3])\n\n    _check_statistics(X, X_true, \"most_frequent\", statistics, np.nan)\n\n    # Test with sparse matrix\n    X = sparse.csc_matrix(np.array([[1, 2, np.nan], [np.nan, 2, 3], [1, 2, 3]]))\n    X_true = np.array([[1, 2, 3], [1, 2, 3], [1, 2, 3]])\n    statistics = np.array([1, 2, 3])\n\n    _check_statistics(X, X_true, \"most_frequent\", statistics, np.nan)\n"], "sample_242": ["def test_lookup_identity(self):\n    lookup1 = CustomLookup(DateTimeField(), Value(datetime(2022, 1, 1)))\n    lookup2 = CustomLookup(DateTimeField(), Value(datetime(2022, 1, 1)))\n    lookup3 = CustomLookup(DateTimeField(), Value(datetime(2022, 1, 2)))\n\n    self.assertEqual(lookup1.identity, lookup2.identity)\n    self.assertNotEqual(lookup1.identity, lookup3.identity)\n"], "sample_842": ["def test_clone():\n    # Test cloning of a single estimator\n    kernel = RBF(length_scale=2.0)\n    cloned_kernel = clone(kernel)\n    assert kernel != cloned_kernel\n    assert kernel.get_params() == cloned_kernel.get_params()\n\n    # Test cloning of a list of estimators\n    kernels = [RBF(length_scale=2.0), Matern(length_scale=0.5)]\n    cloned_kernels = clone(kernels)\n    assert kernels != cloned_kernels\n    for kernel, cloned_kernel in zip(kernels, cloned_kernels):\n        assert kernel.get_params() == cloned_kernel.get_params()\n\n    # Test cloning of a tuple of estimators\n    kernels = (RBF(length_scale=2.0), Matern(length_scale=0.5))\n    cloned_kernels = clone(kernels)\n    assert kernels != cloned_kernels\n    for kernel, cloned_kernel in zip(kernels, cloned_kernels):\n        assert kernel.get_params() == cloned_kernel.get_params()\n\n    # Test cloning of a set of estimators\n    kernels = {RBF(length_scale=2.0), Matern(length_scale=0.5)}\n    cloned_kernels = clone(kernels)\n    assert kernels != cloned_kernels\n    for kernel, cloned_kernel in zip(kernels, cloned_kernels):\n        assert kernel.get_params() == cloned_kernel.get_params()\n\n    # Test cloning of a non-estimator object\n    obj = object()\n    cloned_obj = clone(obj, safe=False)\n    assert obj is cloned_obj\n\n    # Test cloning of a non-estimator object with safe=True\n    with pytest.raises(TypeError):\n        clone(obj, safe=True)\n"], "sample_1025": ["def test_printers():\n    p = PythonCodePrinter()\n    assert p._print_known_func(Mod) == 'math.fmod'\n    assert p._print_known_const(pi) == 'math.pi'\n\n    mp = MpmathPrinter()\n    assert mp._print_known_func(Mod) == 'mpmath.fmod'\n    assert mp._print_known_const(pi) == 'mpmath.pi'\n\n    np = NumPyPrinter()\n    assert np._print_known_func(Mod) == 'numpy.mod'\n    assert np._print_known_const(pi) == 'numpy.pi'\n\n    sp = SciPyPrinter()\n    assert sp._print_known_func(Mod) == 'numpy.mod'\n    assert sp._print_known_const(pi) == 'scipy.constants.pi'\n\n    sp = SymPyPrinter()\n    assert sp._print_known_func(Mod) == 'sympy.Mod'\n    assert sp._print_known_const(pi) == 'sympy.pi'\n"], "sample_153": ["    def test_model_check_long_column_names(self):\n        # Create a model with a field that has an auto-generated column name\n        # that is too long for the database.\n        class LongColumnNameModel(models.Model):\n            very_long_field_name = models.CharField(max_length=255)\n\n        # Mock the database connection to return a max name length of 50.\n        with mock.patch.object(connection.ops, 'max_name_length', return_value=50):\n            errors = LongColumnNameModel.check()\n            self.assertEqual(len(errors), 1)\n            self.assertEqual(errors[0].id, 'models.E018')\n"], "sample_1038": ["def test_matrix_element():\n    i, j = symbols('i j')\n    M = MatrixSymbol('M', n, m)\n    ME = MatrixElement(M, i, j)\n    assert ME.parent == M\n    assert ME.i == i\n    assert ME.j == j\n    assert ME.indices == (i, j)\n    assert ME.doit() == M[i, j]\n    assert ME.diff(M) == KroneckerDelta(i, i)*KroneckerDelta(j, j)\n    assert ME.diff(M[1, 2]) == S.Zero\n"], "sample_1075": ["def test_beta():\n    x, y = symbols('x y')\n    assert beta(x, y).diff(x) == (digamma(x) - digamma(x + y))*beta(x, y)\n    assert beta(x, y).diff(y) == (digamma(y) - digamma(x + y))*beta(x, y)\n\n    assert beta(1, y).simplify() == 1/y\n    assert beta(x, 1).simplify() == 1/x\n\n    assert beta(x, y).conjugate() == beta(conjugate(x), conjugate(y))\n\n    assert beta(x, y).is_real == (x.is_real and y.is_real)\n\n    raises(ArgumentIndexError, lambda: beta(x, y).fdiff(3))\n\n    assert expand_func(beta(x, y)) == gamma(x)*gamma(y)/gamma(x + y)\n"], "sample_1056": ["def test_lambdarepr():\n    assert lambdarepr(x + y) == \"(x + y)\"\n    assert lambdarepr(sin(x)) == \"sin(x)\"\n    assert lambdarepr(Piecewise((x, x < 1), (x**2, True))) == \"((x if (x < 1) else (x**2)))\"\n    assert lambdarepr(Sum(x, (i, 1, 10))) == \"sum([x for i in range(1, 11)])\"\n"], "sample_196": ["def test_adapt_decimalfield_value(self):\n    value = decimal.Decimal('123.456')\n    self.assertEqual(self.ops.adapt_decimalfield_value(value), '123.456')\n\n    value = decimal.Decimal('123.456789012345678901234567890')\n    self.assertEqual(self.ops.adapt_decimalfield_value(value), '123.456789012345678901234567890')\n\n    value = decimal.Decimal('12345678901234567890.12345678901234567890')\n    self.assertEqual(self.ops.adapt_decimalfield_value(value), '12345678901234567890.12345678901234567890')\n\n    value = decimal.Decimal('12345678901234567890.123456789012345678901234567890')\n    self.assertEqual(self.ops.adapt_decimalfield_value(value), '12345678901234567890.123456789012345678901234567890')\n\n    value = decimal.Decimal('12345678901234567890.1234567890123456789012345678901234567890')\n    self.assertEqual(self.ops.adapt_decimalfield_value(value), '12345678901234567890.1234567890123456789012345678901234567890')\n\n    value = decimal.Decimal('12345678901234567890.12345678901234567890123456789012345678901234567890')\n    self.assertEqual(self.ops.adapt_decimalfield_value(value), '12345678901234567890.12345678901234567890123456789012345678901234567890')\n\n    value = decimal.Decimal('12345678901234567890.12345678901234567890123456789012345678901234567890123456789')\n    self.assertEqual(self.ops.adapt_decimalfield_value(value), '12345678901234567890.12345678901234567890123456789012345678901234567890123456789')\n\n    value = decimal.Decimal('12345678901234567890.123456789012345678901234567890123456789012345678901234567890')\n    self.assertEqual(self.ops.adapt_decimalfield_value(value), '12345678901234567890.123456789012345678901234567890123456789012345678901234567890')\n\n    value = decimal.Decimal('12345678901234567890.123456789012345678901234567890123456789012345678901234"], "sample_1105": ["def test_refine_MatMul():\n    X = MatrixSymbol('X', 2, 2)\n    expr = X * X.T\n    assert refine(expr, Q.orthogonal(X)) == Identity(2)\n\n    Y = MatrixSymbol('Y', 2, 2)\n    expr = Y * Y.conjugate()\n    assert refine(expr, Q.unitary(Y)) == Identity(2)\n\n    Z = MatrixSymbol('Z', 2, 2)\n    expr = Z * Z.conjugate()\n    assert refine(expr, Q.orthogonal(Z)) != Identity(2)\n"], "sample_1087": ["def test_swinnerton_dyer_poly():\n    assert swinnerton_dyer_poly(1) == x**2 - 2\n    assert swinnerton_dyer_poly(2) == x**4 - 10*x**2 + 1\n    assert swinnerton_dyer_poly(3) == x**8 - 40*x**6 + 352*x**4 - 960*x**2 + 576\n    assert swinnerton_dyer_poly(4, polys=True).as_expr() == swinnerton_dyer_poly(4)\n"], "sample_1064": ["def test_tensorflow_code_derivative():\n    x = symbols('x')\n    f = Function('f')\n    expr = Derivative(f(x), x)\n    tensorflow_expr = tensorflow_code(expr)\n    assert tensorflow_expr == \"tensorflow.gradients(f(x), x)[0]\"\n\n"], "sample_972": ["def test_restify():\n    assert restify(None) == ':py:obj:`None`'\n    assert restify(Ellipsis) == '...'\n    assert restify(str) == ':py:class:`str`'\n    assert restify(Struct) == ':py:class:`struct.Struct`'\n    assert restify(TracebackType) == ':py:class:`types.TracebackType`'\n    assert restify(MyClass1) == ':py:class:`test_util_typing.MyClass1`'\n    assert restify(MyClass2) == ':py:class:`MyClass2`'\n    assert restify(MyInt) == ':py:class:`MyInt`'\n    assert restify(MyList[int]) == ':py:class:`test_util_typing.MyList`\\\\ [int]'\n    assert restify(Union[int, str]) == ':py:obj:`~typing.Union`\\\\ [int, str]'\n    assert restify(Optional[int]) == ':py:obj:`~typing.Optional`\\\\ [int]'\n    assert restify(Callable[[int, str], bool]) == ':py:obj:`~typing.Callable`\\\\ [[int, str], bool]'\n\n"], "sample_1154": ["def test_linsolve_underdetermined():\n    # Test underdetermined system\n    eqs = [Eq(x + y, 0)]\n    syms = [x, y]\n    sol = _linsolve(eqs, syms)\n    assert sol == {x: -y, y: y}\n"], "sample_1119": ["def test_non_square_matrix_error():\n    raises(NonSquareMatrixError, lambda: eye(3).inv())\n    raises(NonSquareMatrixError, lambda: eye(3).exp())\n    raises(NonSquareMatrixError, lambda: eye(3).log())\n    raises(NonSquareMatrixError, lambda: eye(3).is_nilpotent())\n    raises(NonSquareMatrixError, lambda: eye(3).analytic_func(symbols('x'), symbols('x')))\n"], "sample_1035": ["def test_measure_all():\n    from sympy.physics.quantum.qubit import measure_all, Qubit\n    from sympy.physics.quantum.gate import H\n    from sympy.physics.quantum.qapply import qapply\n\n    c = H(0)*H(1)*Qubit('00')\n    q = qapply(c)\n    result = measure_all(q)\n    assert len(result) == 4\n    for state, prob in result:\n        assert isinstance(state, Qubit)\n        assert prob == 1/4\n\n"], "sample_926": ["def test_macro():\n    input = \"MACRO(a, b, c)\"\n    idDict = {1: \"MACRO\", 2: \"MACRO(a, b, c)\"}\n    output = \"MACRO(a, b, c)\"\n    check(\"macro\", input, idDict, output)\n"], "sample_588": ["    def test_combine_nd(self):\n        # Create a 2D grid of datasets\n        datasets = [\n            [create_test_data(x, y) for y in range(2)]\n            for x in range(2)\n        ]\n\n        # Define the concat dimensions\n        concat_dims = ['x', 'y']\n\n        # Combine the datasets\n        combined_ids = _infer_concat_order_from_positions(datasets)\n        combined = _combine_nd(\n            combined_ids,\n            concat_dims=concat_dims,\n            data_vars='all',\n            coords='different',\n            compat='no_conflicts',\n            fill_value=dtypes.NA,\n            join='outer',\n        )\n\n        # Check the result\n        expected = create_test_data(2, 2)\n        assert_identical(combined, expected)\n"], "sample_430": ["def test_altered_indexes(self):\n    before_state = [\n        self.book_indexes,\n    ]\n    after_state = [\n        self.book_unordered_indexes,\n    ]\n    changes = self.get_changes(before_state, after_state)\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"RemoveIndex\", \"AddIndex\"])\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        0,\n        name=\"book_title_author_idx\",\n    )\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        1,\n        name=\"book_author_title_idx\",\n    )\n"], "sample_958": ["def test_alias():\n    # Test that aliasing works\n    rootSymbol = Symbol(None, None, None, None, None)\n    symbol = rootSymbol.add_declaration(parse(\"function\", \"void f()\"), docname=\"TestDoc\", line=42)\n    alias = rootSymbol.add_declaration(parse(\"function\", \"void f()\"), docname=\"TestDoc\", line=43)\n    alias.isRedeclaration = True\n    assert symbol.declaration.get_newest_id() == alias.declaration.get_newest_id()\n    assert symbol.declaration.get_id(1) == alias.declaration.get_id(1)\n    assert symbol.declaration.get_id(2) == alias.declaration.get_id(2)\n"], "sample_1118": ["def test_matpow():\n    assert MatPow(A, 0).doit() == Identity(n)\n    assert MatPow(ZeroMatrix(n, n), -1) == ZeroMatrix(n, n)\n    assert MatPow(Identity(n), -1) == Identity(n)\n    assert MatPow(Identity(n), 1) == Identity(n)\n    assert MatPow(Identity(n), 2) == Identity(n)\n\n    raises(NonSquareMatrixError, lambda: MatPow(A, 2).doit())\n    raises(NonInvertibleMatrixError, lambda: MatPow(ZeroMatrix(n, n), -1).doit())\n\n    assert MatPow(C, 1).doit() == C\n    assert MatPow(C, 2).doit() == C*C\n    assert MatPow(C, -1).doit() == Inverse(C).doit()\n    assert MatPow(C, -2).doit() == Inverse(C).doit()*Inverse(C).doit()\n\n    assert MatPow(MatPow(C, 2), 3).doit() == C**6\n    assert MatPow(MatPow(C, -2), 3).doit() == Inverse(C)**6\n"], "sample_959": ["def test_template_introduction():\n    input = \"template<typename T> concept C<T> { T t; }\"\n    idDict = {2: \"I0T_E\", 3: \"I0T_E\", 4: \"I0T_E\"}\n    output = \"template <typename T> concept C<T> { T t; }\"\n    check(\"concept\", input, idDict, output)\n"], "sample_1141": ["def test_expr_free_symbols():\n    x = Symbol('x')\n    expr = x + 1\n    assert expr.expr_free_symbols == {x}\n    assert expr.as_independent(x)[0].expr_free_symbols == set()\n    assert expr.as_independent(x)[1].expr_free_symbols == {x}\n    assert (expr**2).expr_free_symbols == {x}\n    assert (expr**2).as_independent(x)[0].expr_free_symbols == set()\n    assert (expr**2).as_independent(x)[1].expr_free_symbols == {x}\n"], "sample_1174": ["def test_polar_lift():\n    x = Symbol('x')\n    assert polar_lift(4) == 4*exp_polar(0)\n    assert polar_lift(-4) == 4*exp_polar(I*pi)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(I + 2) == polar_lift(2 + I)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(4*polar_lift(x)) == 4*polar_lift(x)\n"], "sample_133": ["    def test_set_language_view(self):\n        \"\"\"Test the set_language view.\"\"\"\n        # Create a request with a POST method\n        request_factory = RequestFactory()\n        request = request_factory.post('/i18n/setlang/', {'language': 'fr'})\n\n        # Test that the view redirects to the next URL\n        response = set_language(request)\n        self.assertEqual(response.status_code, 302)\n\n        # Test that the view sets the language in the session\n        self.assertEqual(request.session[LANGUAGE_SESSION_KEY], 'fr')\n\n        # Test that the view sets the language cookie\n        self.assertEqual(response.cookies[settings.LANGUAGE_COOKIE_NAME].value, 'fr')\n\n        # Test that the view handles invalid language codes\n        request = request_factory.post('/i18n/setlang/', {'language': 'invalid'})\n        response = set_language(request)\n        self.assertEqual(response.status_code, 204)\n\n        # Test that the view handles missing language parameter\n        request = request_factory.post('/i18n/setlang/')\n        response = set_language(request)\n        self.assertEqual(response.status_code, 204)\n\n        # Test that the view handles GET requests\n        request = request_factory.get('/i18n/setlang/', {'language': 'fr'})\n        response = set_language(request)\n        self.assertEqual(response.status_code, 302)\n"], "sample_1057": ["def test_render_as_module():\n    content = Print('Hello, world!')\n    result = render_as_module(content)\n    assert 'import sympy' in result\n    assert 'print(\"Hello, world!\")' in result\n"], "sample_828": ["def test_check_pairwise_arrays():\n    # Test that check_pairwise_arrays raises an error when the input arrays\n    # have different numbers of features\n    X = np.array([[1, 2], [3, 4]])\n    Y = np.array([[5, 6, 7], [8, 9, 10]])\n    with assert_raises(ValueError):\n        check_pairwise_arrays(X, Y)\n\n    # Test that check_pairwise_arrays raises an error when the input arrays\n    # are not at least 2D\n    X = np.array([1, 2, 3])\n    Y = np.array([4, 5, 6])\n    with assert_raises(ValueError):\n        check_pairwise_arrays(X, Y)\n\n    # Test that check_pairwise_arrays raises an error when the input arrays\n    # are not of the same type\n    X = np.array([[1, 2], [3, 4]])\n    Y = csr_matrix([[5, 6], [7, 8]])\n    with assert_raises(ValueError):\n        check_pairwise_arrays(X, Y, dtype=np.float32)\n\n    # Test that check_pairwise_arrays returns the correct arrays when the\n    # input arrays are valid\n    X = np.array([[1, 2], [3, 4]])\n    Y = np.array([[5, 6], [7, 8]])\n    X_checked, Y_checked = check_pairwise_arrays(X, Y)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(Y_checked, Y)\n\n    # Test that check_pairwise_arrays returns the correct arrays when the\n    # input arrays are sparse\n    X = csr_matrix([[1, 2], [3, 4]])\n    Y = csr_matrix([[5, 6], [7, 8]])\n    X_checked, Y_checked = check_pairwise_arrays(X, Y)\n    assert_array_equal(X_checked.toarray(), X.toarray())\n    assert_array_equal(Y_checked.toarray(), Y.toarray())\n\n    # Test that check_pairwise_arrays returns the correct arrays when the\n    # input arrays are of type float32\n    X = np.array([[1, 2], [3, 4]], dtype=np.float32)\n    Y = np.array([[5, 6], [7, 8]], dtype=np.float32)\n    X_checked, Y_checked, dtype = _return_float_dtype(X, Y)\n    assert_array"], "sample_827": ["def test_inplace_swap_row_csc():\n    # Test swapping rows in a CSC matrix\n    X = sp.csc_matrix(np.array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]))\n    inplace_swap_row_csc(X, 0, 1)\n    assert_array_equal(X.toarray(), np.array([[0, 2, 0], [1, 0, 0], [0, 0, 3]]))\n\n    # Test swapping rows with negative indices\n    X = sp.csc_matrix(np.array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]))\n    inplace_swap_row_csc(X, -1, -2)\n    assert_array_equal(X.toarray(), np.array([[0, 2, 0], [1, 0, 0], [0, 0, 3]]))\n\n    # Test swapping rows with non-integer indices\n    X = sp.csc_matrix(np.array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]))\n    with assert_raises(TypeError):\n        inplace_swap_row_csc(X, 0.5, 1)\n\n    # Test swapping rows with out-of-bounds indices\n    X = sp.csc_matrix(np.array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]))\n    with assert_raises(ValueError):\n        inplace_swap_row_csc(X, 3, 1)\n"], "sample_154": ["    def test_check_database_backends_calls_check_on_each_database(self, mock_check):\n        mock_check.return_value = []\n        check_database_backends(databases=self.databases)\n        for alias in self.databases:\n            mock_check.assert_any_call()\n        self.assertEqual(mock_check.call_count, len(self.databases))\n"], "sample_319": ["def test_altered_indexes(self):\n    before_state = self.make_project_state(\n        [\n            self.book_indexes,\n        ]\n    )\n    after_state = self.make_project_state(\n        [\n            self.book_unordered_indexes,\n        ]\n    )\n    changes = self.get_changes(before_state, after_state)\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"RemoveIndex\", \"AddIndex\"])\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        0,\n        name=\"book_title_author_idx\",\n    )\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        1,\n        name=\"book_author_title_idx\",\n    )\n"], "sample_415": ["    def test_check_constraint(self):\n        constraint = BaseConstraint(\"test_constraint\")\n        with self.assertRaises(NotImplementedError):\n            constraint.constraint_sql(None, None)\n"], "sample_826": ["def test_ordinal_encoder():\n    enc = OrdinalEncoder()\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 2.], [1., 0.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([['Male', 1], ['Female', 2]], dtype=object))\n\n    # Test with categorical features\n    enc = OrdinalEncoder(categories=[['Male', 'Female'], [1, 2, 3]])\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform(X), np.array([[0., 0.], [1., 2.], [1., 1.]]))\n    assert_array_equal(enc.inverse_transform(enc.transform(X)), np.array([['Male', 1], ['Female', 3], ['Female', 2]], dtype=object))\n\n    # Test with unknown categories\n    enc = OrdinalEncoder(handle_unknown='error')\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    with assert_raises(ValueError):\n        enc.transform([['Unknown', 1]])\n\n    enc = OrdinalEncoder(handle_unknown='ignore')\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc.fit(X)\n    assert_array_equal(enc.transform([['Unknown', 1]]), np.array([[np.nan, 0.]]))\n"], "sample_781": ["def test_forest_oob_score():\n    \"\"\"Check oob score computation on a toy dataset.\"\"\"\n    for name, ForestClassifier in FOREST_CLASSIFIERS.items():\n        clf = ForestClassifier(n_estimators=10, oob_score=True, random_state=1)\n        clf.fit(X, y)\n        assert clf.oob_score_ > 0.0\n\n    for name, ForestRegressor in FOREST_REGRESSORS.items():\n        reg = ForestRegressor(n_estimators=10, oob_score=True, random_state=1)\n        reg.fit(X, y)\n        assert reg.oob_score_ > 0.0\n"], "sample_195": ["    def test_bulk_batch_size(self):\n        ops = DatabaseOperations(connection=connection)\n        fields = ['field1', 'field2', 'field3']\n        objs = [1, 2, 3]\n        self.assertEqual(ops.bulk_batch_size(fields, objs), 333)\n\n        fields = ['field1']\n        objs = [1, 2, 3]\n        self.assertEqual(ops.bulk_batch_size(fields, objs), 500)\n\n        fields = []\n        objs = [1, 2, 3]\n        self.assertEqual(ops.bulk_batch_size(fields, objs), 3)\n"], "sample_1152": ["def test_powsimp():\n    # Test powsimp with deep=True and combine='all'\n    assert powsimp(x**y*x**z*y**z, deep=True, combine='all') == x**(y + z)*y**z\n\n    # Test powsimp with deep=True and combine='exp'\n    assert powsimp(x**y*x**z*y**z, deep=True, combine='exp') == x**(y + z)*y**z\n\n    # Test powsimp with deep=True and combine='base'\n    assert powsimp(x**y*x**z*y**z, deep=True, combine='base') == x**y*(x*y)**z\n\n    # Test powsimp with deep=False and combine='all'\n    assert powsimp(x**y*x**z*y**z, deep=False, combine='all') == x**y*x**z*y**z\n\n    # Test powsimp with deep=False and combine='exp'\n    assert powsimp(x**y*x**z*y**z, deep=False, combine='exp') == x**y*x**z*y**z\n\n    # Test powsimp with deep=False and combine='base'\n    assert powsimp(x**y*x**z*y**z, deep=False, combine='base') == x**y*x**z*y**z\n\n    # Test powsimp with force=True\n    assert powsimp(x**y*x**z*y**z, deep=True, combine='all', force=True) == (x*y)**(y + z)\n\n    # Test powsimp with a non-commutative base\n    A = MatrixSymbol('A', 2, 2)\n    assert powsimp(A**x*A**y, deep=True, combine='all') == A**(x + y)\n\n    # Test powsimp with a non-commutative base and force=True\n    assert powsimp(A**x*A**y, deep=True, combine='all', force=True) == A**(x + y)\n\n    # Test powsimp with a non-commutative base and deep=False\n    assert powsimp(A**x*A**y, deep=False, combine='all') == A**x*A**y\n\n    # Test powsimp with a non-commutative base and deep=False and force=True\n    assert powsimp(A**x*A**y, deep"], "sample_927": ["def test_template_introduction():\n    input = \"template<concept C> C\"\n    output = \"template<concept C> C\"\n    idDict = {2: \"I0E\", 3: \"I0E\", 4: \"I0E\"}\n    check(\"concept\", input, idDict, output)\n"], "sample_132": ["    def test_get_traceback_data(self):\n        request = RequestFactory().get('/')\n        request.user = User()\n        exc_type = Exception\n        exc_value = Exception('Test exception')\n        tb = None\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIn('request', data)\n        self.assertIn('request_meta', data)\n        self.assertIn('user_str', data)\n        self.assertIn('filtered_POST_items', data)\n        self.assertIn('settings', data)\n        self.assertIn('sys_executable', data)\n        self.assertIn('sys_version_info', data)\n        self.assertIn('server_time', data)\n        self.assertIn('django_version_info', data)\n        self.assertIn('sys_path', data)\n        self.assertIn('template_info', data)\n        self.assertIn('template_does_not_exist', data)\n        self.assertIn('postmortem', data)\n        self.assertIn('exception_type', data)\n        self.assertIn('exception_value', data)\n        self.assertIn('lastframe', data)\n"], "sample_731": ["def test_fetch_california_housing():\n    \"\"\"Test the california_housing loader.\"\"\"\n    try:\n        data = fetch()\n    except IOError:\n        raise SkipTest(\"Dataset not found\")\n\n    assert data.data.shape == (20640, 8)\n    assert data.target.shape == (20640,)\n    assert len(data.feature_names) == 8\n    assert data.DESCR == fetch_california_housing.__doc__\n\n    # Test return_X_y\n    X, y = fetch(return_X_y=True)\n    assert X.shape == (20640, 8)\n    assert y.shape == (20640,)\n\n    # Test data_home\n    import tempfile\n    temp_dir = tempfile.mkdtemp()\n    try:\n        data = fetch(data_home=temp_dir)\n    finally:\n        import shutil\n        shutil.rmtree(temp_dir)\n\n    # Test download_if_missing=False\n    try:\n        fetch(download_if_missing=False, data_home=temp_dir)\n    except IOError:\n        pass\n    else:\n        raise AssertionError(\"Expected IOError\")\n\n    # Test download_if_missing=True\n    data = fetch(download_if_missing=True, data_home=temp_dir)\n    assert data.data.shape == (20640, 8)\n    assert data.target.shape == (20640,)\n\n    # Test data loading from cache\n    data_cached = fetch(data_home=temp_dir)\n    assert data_cached.data.shape == (20640, 8)\n    assert data_cached.target.shape == (20640,)\n"], "sample_603": ["def test_collapsible_section():\n    name = \"Test Section\"\n    inline_details = \"Inline details\"\n    details = \"Detailed information\"\n    n_items = 10\n    enabled = True\n    collapsed = False\n\n    result = fh.collapsible_section(\n        name, inline_details, details, n_items, enabled, collapsed\n    )\n    assert name in result\n    assert inline_details in result\n    assert details in result\n    assert str(n_items) in result\n    assert \"disabled\" not in result\n    assert \"checked\" not in result\n\n    result = fh.collapsible_section(\n        name, inline_details, details, n_items, enabled=False, collapsed=True\n    )\n    assert \"disabled\" in result\n    assert \"checked\" in result\n\n    result = fh.collapsible_section(\n        name, inline_details, details, n_items=None, enabled=True, collapsed=False\n    )\n    assert str(n_items) not in result\n"], "sample_934": ["def test_macro():\n    input = \"MACRO(a, b, c)\"\n    idDict = {1: \"MACRO\", 2: \"MACRO(a, b, c)\"}\n    output = \"MACRO(a, b, c)\"\n    check(\"macro\", input, idDict, output)\n\n    input = \"MACRO(a, b, c...)\"\n\n    idDict = {1: \"MACRO\", 2: \"MACRO(a, b, c...)\"}\n    output = \"MACRO(a, b, c...)\"\n    check(\"macro\", input, idDict, output)\n\n    input = \"MACRO(a, b, c...)\"\n\n    idDict = {1: \"MACRO\", 2: \"MACRO(a, b, c...)\"}\n    output = \"MACRO(a, b, c...)\"\n    check(\"macro\", input, idDict, output)\n\n    input = \"MACRO(a, b, c...)\"\n\n    idDict = {1: \"MACRO\", 2: \"MACRO(a, b, c...)\"}\n    output = \"MACRO(a, b, c...)\"\n    check(\"macro\", input, idDict, output)\n\n    input = \"MACRO(a, b, c...)\"\n\n    idDict = {1: \"MACRO\", 2: \"MACRO(a, b, c...)\"}\n    output = \"MACRO(a, b, c...)\"\n    check(\"macro\", input, idDict, output)\n\n    input = \"MACRO(a, b, c...)\"\n\n    idDict = {1: \"MACRO\", 2: \"MACRO(a, b, c...)\"}\n    output = \"MACRO(a, b, c...)\"\n    check(\"macro\", input, idDict, output)\n\n    input = \"MACRO(a, b, c...)\"\n\n    idDict = {1: \"MACRO\", 2: \"MACRO(a, b, c...)\"}\n    output = \"MACRO(a, b, c...)\"\n    check(\"macro\", input, idDict, output)\n\n    input = \"MACRO(a, b, c...)\"\n\n    idDict = {1: \"MACRO\", 2: \"MACRO(a, b, c...)\"}\n    output = \"MACRO(a, b, c...)\"\n    check(\"macro\", input, idDict, output)\n\n    input = \""], "sample_917": ["def test_template_introduction():\n    input = \"concept C { T }\"\n    idDict = {2: \"I0X3CIZliE0E\", 3: \"I0X3CIZliE0E\", 4: \"I0X3CIZliE0E\"}\n    check(\"concept\", input, idDict)\n"], "sample_302": ["    def test_runshell_restores_sigint_handler(self, mock_signal, mock_runshell):\n        self.client = DatabaseClient(connection=connection)\n        parameters = ['--some-parameter']\n        self.client.runshell(parameters)\n        mock_signal.assert_called_with(signal.SIGINT, signal.SIG_IGN)\n        mock_signal.assert_called_with(signal.SIGINT, mock_signal.return_value)\n        mock_runshell.assert_called_once_with(parameters)\n"], "sample_732": ["def test_fetch_kddcup99():\n    # Test that the data is correctly loaded\n    data = fetch_kddcup99()\n    assert_equal(data.data.shape, (494021, 41))\n    assert_equal(len(data.target), 494021)\n\n    # Test that the data is correctly shuffled\n    data_shuffled = fetch_kddcup99(shuffle=True, random_state=0)\n    assert_equal(data_shuffled.data.shape, (494021, 41))\n    assert_equal(len(data_shuffled.target), 494021)\n    assert not np.array_equal(data.data, data_shuffled.data)\n\n    # Test that the data is correctly subsetted\n    data_sa = fetch_kddcup99(subset='SA')\n    assert_equal(data_sa.data.shape, (976158, 41))\n    assert_equal(len(data_sa.target), 976158)\n\n    data_sf = fetch_kddcup99(subset='SF')\n    assert_equal(data_sf.data.shape, (699691, 4))\n    assert_equal(len(data_sf.target), 699691)\n\n    data_http = fetch_kddcup99(subset='http')\n    assert_equal(data_http.data.shape, (619052, 3))\n    assert_equal(len(data_http.target), 619052)\n\n    data_smtp = fetch_kddcup99(subset='smtp')\n    assert_equal(data_smtp.data.shape, (95373, 3))\n    assert_equal(len(data_smtp.target), 95373)\n\n    # Test that the data is correctly returned as X, y\n    X, y = fetch_kddcup99(return_X_y=True)\n    assert_equal(X.shape, (494021, 41))\n    assert_equal(len(y), 494021)\n"], "sample_575": ["    def x(self):\n        return pd.Series([\"a\", \"b\", \"c\"], name=\"x\", dtype=object)\n"], "sample_924": ["def test_template_introduction():\n    input = \"template<concept C> C\"\n    output = \"template<concept C> C\"\n    idDict = {2: \"I0C0E\", 3: \"I0C0E\", 4: \"I0C0E\"}\n    check(\"concept\", input, idDict, output)\n"], "sample_279": ["    def test_check_constraint_creation(self):\n        with self.assertRaises(IntegrityError):\n            Product.objects.create(price=-1)\n"], "sample_611": ["def test_to_offset(freq, expected_offset):\n    offset = to_offset(freq)\n    assert isinstance(offset, expected_offset)\n    assert offset.n == 1\n"], "sample_1063": ["def test_lambdify_with_implemented_function():\n    f = implemented_function('f', lambda x: x**2)\n    g = implemented_function('g', lambda x: x + 1)\n    expr = f(g(x))\n    func = lambdify(x, expr)\n    assert func(2) == 9\n"], "sample_947": ["def test_alias():\n    app = restructuredtext.sphinx_test(\n        testroot='test-alias',\n        confoverrides={\n            'c_id_attributes': ['id_attr'],\n            'c_paren_attributes': ['paren_attr'],\n        },\n    )\n    app.builder.build_all()\n\n    # Check that the alias is rendered correctly\n    assert_node(app, \"\"\"\n        <desc>\n            <desc_signature>\n                <desc_name>alias</desc_name>\n            </desc_signature>\n            <desc_content>\n                <desc>\n                    <desc_signature>\n                        <desc_name>original</desc_name>\n                    </desc_signature>\n                </desc>\n            </desc_content>\n        </desc>\n    \"\"\", 'c-domain-alias')\n\n    # Check that the alias is rendered correctly with noroot\n    assert_node(app, \"\"\"\n        <desc>\n            <desc_signature>\n                <desc_name>alias</desc_name>\n            </desc_signature>\n            <desc_content>\n                <desc>\n                    <desc_signature>\n                        <desc_name>original</desc_name>\n                    </desc_signature>\n                </desc>\n            </desc_content>\n        </desc>\n    \"\"\", 'c-domain-alias-noroot')\n\n    # Check that the alias is rendered correctly with maxdepth\n    assert_node(app, \"\"\"\n        <desc>\n            <desc_signature>\n                <desc_name>alias</desc_name>\n            </desc_signature>\n            <desc_content>\n                <desc>\n                    <desc_signature>\n                        <desc_name>original</desc_name>\n                    </desc_signature>\n                </desc>\n                <desc>\n                    <desc_signature>\n                        <desc_name>original2</desc_name>\n                    </desc_signature>\n                </desc>\n            </desc_content>\n        </desc>\n    \"\"\", 'c-domain-alias-maxdepth')\n\n    # Check that the alias is rendered correctly with noroot and maxdepth\n    assert_node(app, \"\"\"\n        <desc>\n            <desc_signature>\n                <desc_name>alias</desc_name>\n            </desc_signature>\n            <desc_content>\n                <desc>\n                    <desc_signature>\n                        <desc_name>original</desc_name>\n                    </desc_signature>\n                </desc>\n                <desc>\n                    <desc_signature>\n                        <desc_name>original2</desc_name>\n                    </desc_signature>\n                </desc>\n            </desc_content>\n        </desc>\n    \"\"\", 'c-domain-alias-noroot-maxdepth')\n"], "sample_1068": ["def test_octave_code():\n    # Test that the OctaveCodePrinter can handle a variety of expressions\n    assert octave_code(x**2 + 2*x + 1) == \"(x.^2 + 2.*x + 1)\"\n    assert octave_code(sin(x)) == \"sin(x)\"\n    assert octave_code(cos(x)) == \"cos(x)\"\n    assert octave_code(tan(x)) == \"tan(x)\"\n    assert octave_code(cot(x)) == \"cot(x)\"\n    assert octave_code(sec(x)) == \"sec(x)\"\n    assert octave_code(csc(x)) == \"csc(x)\"\n    assert octave_code(asec(x)) == \"asec(x)\"\n    assert octave_code(acsc(x)) == \"acsc(x)\"\n    assert octave_code(asin(x)) == \"asin(x)\"\n    assert octave_code(acos(x)) == \"acos(x)\"\n    assert octave_code(acot(x)) == \"acot(x)\"\n    assert octave_code(atan(x)) == \"atan(x)\"\n    assert octave_code(atan2(x, y)) == \"atan2(x, y)\"\n    assert octave_code(sinh(x)) == \"sinh(x)\"\n    assert octave_code(cosh(x)) == \"cosh(x)\"\n    assert octave_code(tanh(x)) == \"tanh(x)\"\n    assert octave_code(coth(x)) == \"coth(x)\"\n    assert octave_code(csch(x)) == \"csch(x)\"\n    assert octave_code(sech(x)) == \"sech(x)\"\n    assert octave_code(asinh(x)) == \"asinh(x)\"\n    assert octave_code(acosh(x)) == \"acosh(x)\"\n    assert octave_code(atanh(x)) == \"atanh(x)\"\n    assert octave_code(acoth(x)) == \"acoth(x)\"\n    assert octave_code(asech(x)) == \"asech(x)\"\n    assert octave_code(acsch(x)) == \"acsch(x)\"\n    assert octave_code(exp(x)) == \"exp(x)\"\n    assert octave_code(log(x)) == \"log(x)\"\n    assert octave_code(factorial(x)) == \"factorial(x)\"\n    assert octave_code(floor(x)) == \"floor(x)\"\n    assert octave_code(ceiling(x)) == \"ceil(x)\"\n    assert octave_code(arg(x)) == \"angle(x)\"\n    assert octave_code(conjugate(x)) == \"conj(x)\"\n    assert octave_code(im(x)) == \"imag(x)\"\n    assert octave_code(re(x)) =="], "sample_1117": ["def test_AskSquareHandler():\n    assert ask(Q.square(X), Q.square(X)) is True\n    assert ask(Q.square(Y), Q.square(Y)) is False\n    assert ask(Q.square(Z), Q.square(Z)) is True\n    assert ask(Q.square(A1x1), Q.square(A1x1)) is True\n    assert ask(Q.square(B1x1), Q.square(B1x1)) is True\n    assert ask(Q.square(C0x0), Q.square(C0x0)) is True\n    assert ask(Q.square(V1), Q.square(V1)) is False\n    assert ask(Q.square(V2), Q.square(V2)) is False\n"], "sample_723": ["def test_imputer_with_pipeline():\n    # Test that the imputer can be used in a pipeline\n    X = np.array([[1, 2], [np.nan, 3], [7, 6]])\n    y = np.array([0, 0, 1])\n\n    imputer = SimpleImputer(strategy=\"mean\")\n    clf = tree.DecisionTreeClassifier(random_state=0)\n    pipeline = Pipeline([(\"imputer\", imputer), (\"clf\", clf)])\n\n    pipeline.fit(X, y)\n\n    assert_equal(pipeline.predict(X), [0, 0, 1])\n\n"], "sample_1125": ["def test_Operator():\n    A = Operator('A')\n    assert A.is_commutative is False\n    assert A.hilbert_space == 'H'\n    assert A.label == ('A',)\n    assert A * A == A**2\n    assert A.inv() == A**(-1)\n    assert A * A.inv() == 1\n"], "sample_309": ["    def test_http_date(self):\n        dt = datetime(2022, 1, 1, 12, 0, 0, tzinfo=timezone.utc)\n        self.assertEqual(http_date(dt.timestamp()), 'Sat, 01 Jan 2022 12:00:00 GMT')\n"], "sample_1037": ["def test_MatMul():\n    # Test MatMul constructor\n    assert MatMul(A, B, C).shape == (n, l)\n    assert MatMul(A, B, C).is_MatMul\n\n    # Test MatMul with non-matrix arguments\n    assert MatMul(2, A, B).shape == (n, l)\n    assert MatMul(2, A, B).is_MatMul\n\n    # Test MatMul with zero matrix\n    assert MatMul(A, ZeroMatrix(m, l), C).shape == (n, n)\n    assert MatMul(A, ZeroMatrix(m, l), C).is_MatMul\n\n    # Test MatMul with identity matrix\n    assert MatMul(A, Identity(m), C).shape == (n, n)\n    assert MatMul(A, Identity(m), C).is_MatMul\n\n    # Test MatMul with transpose\n    assert MatMul(A, B.T, C).shape == (n, n)\n    assert MatMul(A, B.T, C).is_MatMul\n\n    # Test MatMul with adjoint\n    assert MatMul(A, B.conjugate().T, C).shape == (n, n)\n    assert MatMul(A, B.conjugate().T, C).is_MatMul\n\n    # Test MatMul with inverse\n    assert MatMul(A, B.inv(), C).shape == (n, n)\n    assert MatMul(A, B.inv(), C).is_MatMul\n\n    # Test MatMul with matrix power\n    assert MatMul(A, B**2, C).shape == (n, n)\n    assert MatMul(A, B**2, C).is_MatMul\n\n    # Test MatMul with matrix addition\n    assert MatMul(A, B + C, D).shape == (n, n)\n    assert MatMul(A, B + C, D).is_MatMul\n\n    # Test MatMul with matrix multiplication\n    assert MatMul(A, B * C, D).shape == (n, n)\n    assert MatMul(A, B * C, D).is_MatMul\n\n    # Test MatMul with scalar multiplication\n    assert MatMul(2 * A, B, C).shape == (n, l)\n    assert MatMul(2 * A, B, C).is_MatMul\n\n    # Test MatMul with matrix element\n   "], "sample_431": ["    def test_model_instance_creation_with_deferred_fields(self):\n        article = Article.objects.defer('headline').get(id=1)\n        self.assertEqual(article.headline, 'This is a test')\n        article = Article.objects.defer('headline').get(id=1)\n        with self.assertRaises(AttributeError):\n            article.headline\n        article.refresh_from_db(fields=['headline'])\n        self.assertEqual(article.headline, 'This is a test')\n"], "sample_604": ["    def test_diff_array_repr(self):\n        a = xr.DataArray([1, 2, 3])\n        b = xr.DataArray([1, 2, 4])\n        expected = dedent(\n            \"\"\"\\\n            Left and right DataArray objects are not equal\n            Differing values:\n            L\n            array([1, 2, 3])\n            R\n            array([1, 2, 4])\"\"\"\n        )\n        assert formatting.diff_array_repr(a, b, \"equals\") == expected\n\n        a = xr.DataArray([1, 2, 3], dims=[\"x\"], coords={\"x\": [1, 2, 3]})\n        b = xr.DataArray([1, 2, 4], dims=[\"x\"], coords={\"x\": [1, 2, 3]})\n        expected = dedent(\n            \"\"\"\\\n            Left and right DataArray objects are not equal\n            Differing values:\n            L\n            array([1, 2, 3])\n            R\n            array([1, 2, 4])\"\"\"\n        )\n        assert formatting.diff_array_repr(a, b, \"equals\") == expected\n\n        a = xr.DataArray([1, 2, 3], dims=[\"x\"], coords={\"x\": [1, 2, 3]}, attrs={\"foo\": \"bar\"})\n        b = xr.DataArray([1, 2, 4], dims=[\"x\"], coords={\"x\": [1, 2, 3]}, attrs={\"foo\": \"baz\"})\n        expected = dedent(\n            \"\"\"\\\n            Left and right DataArray objects are not identical\n            Differing values:\n            L\n            array([1, 2, 3])\n            R\n            array([1, 2, 4])\n            Differing attributes:\n            L\n                foo: 'bar'\n            R\n                foo: 'baz'\"\"\"\n        )\n        assert formatting.diff_array_repr(a, b, \"identical\") == expected\n"], "sample_916": ["def test_parse_nested_name():\n    parser = DefinitionParser(\"a::b::c\", location=None, config=None)\n    name = parser.parse_nested_name()\n    assert str(name) == \"a::b::c\"\n\n    parser = DefinitionParser(\"a::b::c::\", location=None, config=None)\n    with pytest.raises(DefinitionError):\n        parser.parse_nested_name()\n\n    parser = DefinitionParser(\"a::b::c::d\", location=None, config=None)\n    with pytest.raises(DefinitionError):\n        parser.parse_nested_name()\n"], "sample_1159": ["def test_failing_assumptions():\n    x = Symbol('x', real=True, positive=True)\n    y = Symbol('y')\n    assert failing_assumptions(6*x + y, real=True, positive=True) == {'positive': None, 'real': None}\n    assert failing_assumptions(x**2 - 1, positive=True) == {'positive': None}\n    assert failing_assumptions(x**2, positive=True) == {}\n    assert failing_assumptions(oo, finite=True) == {'finite': False}\n    assert failing_assumptions(-oo, positive=True) == {'positive': False}\n    assert failing_assumptions(I, real=True) == {'real': False}\n    assert failing_assumptions(sqrt(2), rational=True) == {'rational': False}\n    assert failing_assumptions(log(2), rational=True) == {'rational': False}\n    assert failing_assumptions(exp(1), rational=True) == {'rational': False}\n    assert failing_assumptions(sin(1), rational=True) == {'rational': False}\n    assert failing_assumptions(asin(1), rational=True) == {'rational': False}\n    assert failing_assumptions(factorial(3), rational=True) == {'rational': True}\n    assert failing_assumptions(Mod(3, 4), rational=True) == {'rational': True}\n    assert failing_assumptions(pi, rational=True) == {'rational': False}\n    assert failing_assumptions(oo, rational=True) == {'rational': False}\n"], "sample_1173": ["def test_parse_expr():\n    # Test implicit multiplication\n    assert parse_expr('2 x', transformations=(standard_transformations +\n                                             (implicit_multiplication,))) == 2*Symbol('x')\n\n    # Test implicit application\n    assert parse_expr('sin x', transformations=(standard_transformations +\n                                               (implicit_application,))) == sin(Symbol('x'))\n\n    # Test implicit multiplication and application\n    assert parse_expr('2 sin x', transformations=(standard_transformations +\n                                                 (implicit_multiplication_application,))) == 2*sin(Symbol('x'))\n\n    # Test implicit multiplication and application with multiple arguments\n    assert parse_expr('2 sin x y', transformations=(standard_transformations +\n                                                   (implicit_multiplication_application,))) == 2*sin(Symbol('x'), Symbol('y'))\n\n    # Test implicit multiplication and application with multiple arguments and exponentiation\n    assert parse_expr('2 sin x y**2', transformations=(standard_transformations +\n                                                      (implicit_multiplication_application,))) == 2*sin(Symbol('x'), Symbol('y')**2)\n\n    # Test implicit multiplication and application with multiple arguments and exponentiation and factorial\n    assert parse_expr('2 sin x y**2 z!', transformations=(standard_transformations +\n                                                         (implicit_multiplication_application,))) == 2*sin(Symbol('x'), Symbol('y')**2)*factorial(Symbol('z'))\n\n    # Test implicit multiplication and application with multiple arguments and exponentiation and factorial and equals\n    assert parse_expr('2 sin x y**2 z! = 1', transformations=(standard_transformations +\n                                                             (implicit_multiplication_application, convert_equals_signs))) == Eq(2*sin(Symbol('x'), Symbol('y')**2)*factorial(Symbol('z')), 1)\n\n    # Test implicit multiplication and application with multiple arguments and exponentiation and factorial and equals and xor\n    assert parse_expr('2 sin x y**2 z! = 1 ^ 2', transformations=(standard_transformations +\n                                                                 (implicit_multiplication_application, convert_equals_signs, convert_xor))) == Eq(2*sin(Symbol('x'), Symbol('y')**2)*factorial(Symbol('z')), Pow(1, 2))\n\n    # Test implicit multiplication and application with multiple arguments and exponentiation and factorial and equals and xor and function exponentiation\n    assert parse_expr('2 sin**2 x y**2 z! = 1 ^ 2', transformations=(standard_transformations +\n                                                                     (implicit_multiplication_application, convert_equals_signs,"], "sample_1026": ["def test_lambdify_with_implemented_function():\n    f = implemented_function('f', lambda x: x**2)\n    g = implemented_function('g', lambda x: x + 1)\n    expr = f(g(x))\n    func = lambdify(x, expr)\n    assert func(2) == 9\n"], "sample_437": ["    def test_savepoint(self):\n        with transaction.atomic():\n            sid = connection.savepoint()\n            self.assertIsNotNone(sid)\n            connection.savepoint_commit(sid)\n            connection.savepoint_rollback(sid)\n            connection.savepoint_commit(sid)\n\n        with self.assertRaises(TransactionManagementError):\n            connection.savepoint()\n\n        with transaction.atomic():\n            sid = connection.savepoint()\n            try:\n                with self.assertRaises(DatabaseError):\n                    with connection.cursor() as cursor:\n                        cursor.execute(\"SELECT * FROM invalid_table\")\n            except DatabaseError:\n                connection.savepoint_rollback(sid)\n            else:\n                self.fail(\"DatabaseError not raised\")\n\n        with transaction.atomic():\n            sid = connection.savepoint()\n            connection.savepoint_commit(sid)\n            connection.savepoint_commit(sid)\n\n        with transaction.atomic():\n            sid = connection.savepoint()\n            connection.savepoint_rollback(sid)\n            connection.savepoint_rollback(sid)\n"], "sample_1155": ["def test_construct_domain():\n    # Test constructing a domain for a list of expressions\n    domain, elements = construct_domain([S(1), S(2), S(3)])\n    assert domain == ZZ\n    assert elements == [1, 2, 3]\n\n    # Test constructing a domain for a dictionary of expressions\n    domain, elements = construct_domain({x: S(1), y: S(2)})\n    assert domain == ZZ\n    assert elements == {x: 1, y: 2}\n\n    # Test constructing a domain for a single expression\n    domain, element = construct_domain(S(1))\n    assert domain == ZZ\n    assert element == 1\n\n    # Test constructing a domain for a list of rational expressions\n    domain, elements = construct_domain([S(1)/2, S(3)/4])\n    assert domain == QQ\n    assert elements == [S(1)/2, S(3)/4]\n\n    # Test constructing a domain for a list of expressions with symbols\n    domain, elements = construct_domain([2*x + 1, S(3)/4])\n    assert domain == QQ.poly_ring(x)\n    assert elements == [2*x + 1, S(3)/4]\n\n    # Test constructing a domain for a list of expressions with symbols and negative powers\n    domain, elements = construct_domain([y/x, x/(1 - y)])\n    assert domain == ZZ.frac_field(x, y)\n    assert elements == [y/x, -x/(y - 1)]\n\n    # Test constructing a domain for a list of expressions with irrational algebraic numbers\n    domain, elements = construct_domain([sqrt(2)])\n    assert domain == EX\n    assert elements == [EX(sqrt(2))]\n\n    # Test constructing a domain for a list of expressions with irrational algebraic numbers and extension=True\n    domain, elements = construct_domain([sqrt(2)], extension=True)\n    assert domain == QQ.algebraic_field((sqrt(2),))\n    assert elements == [domain.dtype.from_list([1, 0], domain.gen, QQ)]\n\n    # Test constructing a domain for a list of expressions with complex numbers\n    domain, elements = construct_domain([1 + 2*I])\n    assert domain == ZZ_I\n    assert elements == [1 + 2*I]\n\n    # Test constructing a domain for a list of expressions with complex numbers and extension=True\n    domain, elements = construct"], "sample_1036": ["def test_mul_as_coeff_mul():\n    x, y = symbols('x y')\n    assert (2*x*y).as_coeff_mul() == (2, (x, y))\n    assert (2*x*y).as_coeff_mul(x) == (2*y, (x,))\n    assert (2*x*y).as_coeff_mul(x, y) == (2, (x, y))\n    assert (2*x*y).as_coeff_mul(rational=False) == (2, (x, y))\n    assert (-2*x*y).as_coeff_mul(rational=False) == (-1, (2, x, y))\n"], "sample_1058": ["def test_printers():\n    expr = Piecewise((x**2, Eq(x, 0)), (x, True))\n    printers = [MpmathPrinter, NumPyPrinter, PythonCodePrinter, SciPyPrinter, SymPyPrinter]\n    for printer in printers:\n        assert printer().doprint(expr) == printer().doprint(expr)\n\n    expr = And(x > 0, y < 0)\n    printers = [MpmathPrinter, NumPyPrinter, PythonCodePrinter, SciPyPrinter, SymPyPrinter]\n    for printer in printers:\n        assert printer().doprint(expr) == printer().doprint(expr)\n\n    expr = Or(x > 0, y < 0)\n    printers = [MpmathPrinter, NumPyPrinter, PythonCodePrinter, SciPyPrinter, SymPyPrinter]\n    for printer in printers:\n        assert printer().doprint(expr) == printer().doprint(expr)\n\n    expr = sign(x)\n    printers = [MpmathPrinter, NumPyPrinter, PythonCodePrinter, SciPyPrinter, SymPyPrinter]\n    for printer in printers:\n        assert printer().doprint(expr) == printer().doprint(expr)\n\n    expr = sqrt(x)\n    printers = [MpmathPrinter, NumPyPrinter, PythonCodePrinter, SciPyPrinter, SymPyPrinter]\n    for printer in printers:\n        assert printer().doprint(expr) == printer().doprint(expr)\n\n    expr = acos(x)\n    printers = [MpmathPrinter, NumPyPrinter, PythonCodePrinter, SciPyPrinter, SymPyPrinter]\n    for printer in printers:\n        assert printer().doprint(expr) == printer().doprint(expr)\n\n    expr = Mod(x, y)\n    printers = [MpmathPrinter, NumPyPrinter, PythonCodePrinter, SciPyPrinter, SymPyPrinter]\n    for printer in printers:\n        assert printer().doprint(expr) == printer().doprint(expr)\n\n    expr = zoo\n    printers = [MpmathPrinter, NumPyPrinter, PythonCodePrinter, SciPyPrinter, SymPyPrinter]\n    for printer in printers:\n        assert printer().doprint(expr) == printer().doprint(expr)\n\n    expr = oo\n    printers = [MpmathPrinter, NumPyPrinter, PythonCodePrinter, SciPyPrinter, SymPyPrinter]\n    for printer in printers:\n        assert printer()."], "sample_586": ["def test_concat_dataset_with_fill_value():\n    # Create test data\n    data = create_test_data()\n    ds1 = data[0]\n    ds2 = data[1]\n\n    # Create a new dataset with a different value for a variable\n    ds2['var1'] = ds2['var1'] + 1\n\n    # Concatenate the datasets with a fill value\n    concatenated = concat([ds1, ds2], dim='dim1', fill_value=-999)\n\n    # Check that the fill value is used for missing values\n    assert concatenated['var1'].isel(dim1=-1).values == -999\n\n    # Check that the data is concatenated correctly\n    assert concatenated['var1'].shape == (10, 10)\n    assert concatenated['var2'].shape == (10, 10)\n\n    # Check that the attributes are preserved\n    assert concatenated.attrs == ds1.attrs\n\n    # Check that the encoding is preserved\n    assert concatenated.encoding == ds1.encoding\n"], "sample_780": ["def test_latent_dirichlet_allocation_init():\n    # Test initialization with different parameters\n    lda = LatentDirichletAllocation(n_components=5, doc_topic_prior=0.5,\n                                    topic_word_prior=0.1, learning_method='online',\n                                    learning_decay=0.8, learning_offset=15.,\n                                    max_iter=20, batch_size=256,\n                                    evaluate_every=5, total_samples=1000000,\n                                    perp_tol=1e-2, mean_change_tol=1e-4,\n                                    max_doc_update_iter=150, n_jobs=2,\n                                    verbose=1, random_state=42)\n    assert lda.n_components == 5\n    assert lda.doc_topic_prior == 0.5\n    assert lda.topic_word_prior == 0.1\n    assert lda.learning_method == 'online'\n    assert lda.learning_decay == 0.8\n    assert lda.learning_offset == 15.\n    assert lda.max_iter == 20\n    assert lda.batch_size == 256\n    assert lda.evaluate_every == 5\n    assert lda.total_samples == 1000000\n    assert lda.perp_tol == 1e-2\n    assert lda.mean_change_tol == 1e-4\n    assert lda.max_doc_update_iter == 150\n    assert lda.n_jobs == 2\n    assert lda.verbose == 1\n    assert lda.random_state == 42\n\n    # Test initialization with default parameters\n    lda = LatentDirichletAllocation()\n    assert lda.n_components == 10\n    assert lda.doc_topic_prior is None\n    assert lda.topic_word_prior is None\n    assert lda.learning_method == 'batch'\n    assert lda.learning_decay == 0.7\n    assert lda.learning_offset == 10.\n    assert lda.max_iter == 10\n    assert lda.batch_size == 128\n    assert lda.evaluate_every == 0\n    assert lda.total_samples == 1000000\n    assert lda.perp_tol == 1e-1\n    assert lda.mean_change_tol == 1e-3\n    assert lda.max_doc_update_iter == 100\n    assert lda.n_jobs is None\n    assert lda.verbose == 0\n    assert lda.random_state is None\n"], "sample_1069": ["def test_glsl_code():\n    # Test printing of GLSL code\n    expr = x**2 + y**2\n    glsl_expr = glsl_code(expr)\n    assert glsl_expr == \"add(pow(x, 2.0), pow(y, 2.0))\"\n\n    # Test printing of GLSL code with assign_to\n    glsl_expr = glsl_code(expr, assign_to=\"float result\")\n    assert glsl_expr == \"float result = add(pow(x, 2.0), pow(y, 2.0));\"\n\n    # Test printing of GLSL code with use_operators=False\n    glsl_expr = glsl_code(expr, use_operators=False)\n    assert glsl_expr == \"add(pow(x, 2.0), pow(y, 2.0))\"\n\n    # Test printing of GLSL code with user_functions\n    custom_functions = {\n        \"pow\": \"my_pow\"\n    }\n    glsl_expr = glsl_code(expr, user_functions=custom_functions)\n    assert glsl_expr == \"add(my_pow(x, 2.0), my_pow(y, 2.0))\"\n\n    # Test printing of GLSL code with Piecewise\n    expr = Piecewise((x + 1, x > 0), (x, True))\n    glsl_expr = glsl_code(expr, assign_to=\"float result\")\n    assert glsl_expr == \"if (x > 0) {\\n   result = x + 1;\\n}\\nelse {\\n   result = x;\\n}\"\n\n    # Test printing of GLSL code with Indexed\n    from sympy import IndexedBase, Idx\n    y = IndexedBase('y', shape=(5,))\n    i = Idx('i', 5)\n    expr = y[i]\n    glsl_expr = glsl_code(expr, assign_to=\"float result\", contract=False)\n    assert glsl_expr == \"result = y[i];\"\n\n    # Test printing of GLSL code with Matrix\n    from sympy import Matrix\n    expr = Matrix([x, y, z])\n    glsl_expr = glsl_code(expr)\n    assert glsl_expr == \"vec3(x, y, z)\"\n\n    # Test printing of GLSL code with Matrix and assign_to\n    expr = Matrix([x, y, z])\n    glsl_expr = glsl_code(expr, assign_to=\"vec3 result\")\n    assert gl"], "sample_874": ["def test_get_feature_names_out():\n    selector = StepSelector(step=2)\n    selector.fit(X, y)\n    assert_array_equal(selector.get_feature_names_out(), feature_names_t)\n    assert_array_equal(selector.get_feature_names_out(input_features=feature_names), feature_names_t)\n    assert_array_equal(selector.get_feature_names_out(input_features=feature_names_inv), feature_names_t)\n    with pytest.raises(ValueError, match=\"feature names mismatch\"):\n        selector.get_feature_names_out(input_features=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n"], "sample_1142": ["def test_matrix_element():\n    i, j = symbols('i j', integer=True)\n    assert MatrixElement(A, i, j).parent == A\n    assert MatrixElement(A, i, j).i == i\n    assert MatrixElement(A, i, j).j == j\n    assert MatrixElement(A, i, j).doit() == A[i, j]\n    raises(SympifyError, lambda: MatrixElement(1, i, j))\n    raises(TypeError, lambda: MatrixElement('A', i, j))\n    raises(TypeError, lambda: MatrixElement(A, i, 'j'))\n    raises(TypeError, lambda: MatrixElement(A, 'i', j))\n"], "sample_825": ["def test_pls_svd():\n    # Test that PLSSVD is equivalent to PLS with algorithm=\"svd\"\n    X, Y = load_linnerud(return_X_y=True)\n    pls_svd = PLSSVD(n_components=2)\n    pls_svd.fit(X, Y)\n    pls_svd_x_scores = pls_svd.x_scores_\n    pls_svd_y_scores = pls_svd.y_scores_\n\n    pls = PLSRegression(n_components=2, algorithm=\"svd\")\n    pls.fit(X, Y)\n    pls_x_scores = pls.x_scores_\n    pls_y_scores = pls.y_scores_\n\n    assert_array_almost_equal(pls_svd_x_scores, pls_x_scores)\n    assert_array_almost_equal(pls_svd_y_scores, pls_y_scores)\n"], "sample_976": ["def test_symbols():\n    # Test that symbols function returns a single symbol when given a single name\n    x = symbols('x')\n    assert isinstance(x, Symbol)\n    assert x.name == 'x'\n\n    # Test that symbols function returns a tuple of symbols when given multiple names\n    x, y, z = symbols('x,y,z')\n    assert isinstance(x, Symbol)\n    assert x.name == 'x'\n    assert isinstance(y, Symbol)\n    assert y.name == 'y'\n    assert isinstance(z, Symbol)\n    assert z.name == 'z'\n\n    # Test that symbols function returns a list of symbols when given a list of names\n    x, y, z = symbols(['x', 'y', 'z'])\n    assert isinstance(x, Symbol)\n    assert x.name == 'x'\n    assert isinstance(y, Symbol)\n    assert y.name == 'y'\n    assert isinstance(z, Symbol)\n    assert z.name == 'z'\n\n    # Test that symbols function returns a set of symbols when given a set of names\n    x, y, z = symbols({'x', 'y', 'z'})\n    assert isinstance(x, Symbol)\n    assert x.name == 'x'\n    assert isinstance(y, Symbol)\n    assert y.name == 'y'\n    assert isinstance(z, Symbol)\n    assert z.name == 'z'\n\n    # Test that symbols function raises an error when given an empty string\n    raises(ValueError, lambda: symbols(''))\n\n    # Test that symbols function raises an error when given a string with only commas\n    raises(ValueError, lambda: symbols(','))\n\n    # Test that symbols function raises an error when given a string with only spaces\n    raises(ValueError, lambda: symbols('   '))\n\n    # Test that symbols function raises an error when given a string with a range that is missing an end\n    raises(ValueError, lambda: symbols('x:'))\n\n    # Test that symbols function raises an error when given a string with a range that has a non-integer start or end\n    raises(ValueError, lambda: symbols('x:a'))\n    raises(ValueError, lambda: symbols('a:x'))\n\n    # Test that symbols function raises an error when given a string with a range that has a start greater than the end\n    raises(ValueError, lambda: symbols('x:0'))\n\n    # Test that symbols function raises an error when given a string with a range that has a start equal to the end\n    raises(ValueError, lambda: symbols('x:x'))\n\n   "], "sample_948": ["def test_template_introduction():\n    input = \"template<typename T> concept C<T> { T t; }\"\n    idDict = {2: \"I0T_E\", 3: \"I0T_E\", 4: \"I0T_E\"}\n    output = \"template <typename T> concept C<T> { T t; }\"\n    check(\"concept\", input, idDict, output)\n"], "sample_303": ["def test_runshell_raises_not_implemented_error(self):\n    with self.assertRaises(NotImplementedError):\n        self.client.runshell(parameters={})\n"], "sample_1126": ["def test_dagger():\n    # Test Dagger with Operator\n    A = Operator('A')\n    B = Operator('B')\n    assert Dagger(A*B) == Dagger(B)*Dagger(A)\n    assert Dagger(A+B) == Dagger(A) + Dagger(B)\n    assert Dagger(A**2) == Dagger(A)**2\n\n    # Test Dagger with Matrix\n    m = Matrix([[1,I],[2,I]])\n    assert Dagger(m) == Matrix([[1, 2], [-I, -I]])\n\n    # Test Dagger with complex numbers\n    z = 1 + 2*I\n    assert Dagger(z) == conjugate(z)\n\n    # Test Dagger with IdentityOperator\n    I = IdentityOperator()\n    assert Dagger(I) == I\n\n    # Test Dagger with nested expressions\n    expr = A * (B + I)\n    assert Dagger(expr) == Dagger(I) + Dagger(B)*Dagger(A)\n\n    # Test Dagger with non-Expr objects\n    assert Dagger(Integer(1)) == Integer(1)\n"], "sample_1116": ["def test_Inverse():\n    assert Inverse(A) == A**(-1)\n    assert A.inverse() == Inverse(A)\n    assert (A*B).inverse() == B**(-1)*A**(-1)\n    assert Inverse(A*B) == (A*B)**(-1)\n\n    raises(NonSquareMatrixError, lambda: Inverse(A))\n    raises(NonSquareMatrixError, lambda: Inverse(B))\n\n    assert Inverse(C).shape == C.shape\n    assert Inverse(D).shape == D.shape\n\n    assert Inverse(C)._eval_inverse() == C\n    assert Inverse(D)._eval_inverse() == D\n\n    assert Inverse(C)._eval_determinant() == 1/C.det()\n    assert Inverse(D)._eval_determinant() == 1/D.det()\n\n    assert Inverse(C).doit() == C.inv()\n    assert Inverse(D).doit() == D.inv()\n\n    assert refine(Inverse(C), Q.orthogonal(C)) == C.T\n    assert refine(Inverse(D), Q.unitary(D)) == D.conjugate()\n\n    raises(ValueError, lambda: refine(Inverse(C), Q.singular(C)))\n    raises(ValueError, lambda: refine(Inverse(D), Q.singular(D)))\n"], "sample_1034": ["def test_superposition_basis():\n    nqubits = 3\n    basis_states = superposition_basis(nqubits)\n    assert len(basis_states.args) == 2**nqubits\n    for i in range(2**nqubits):\n        assert IntQubit(i, nqubits=nqubits) in basis_states.args\n\n"], "sample_1106": ["def test_matadd():\n    # Test MatAdd with MatrixSymbols\n    X = MatAdd(A, B)\n    assert X.shape == (n, l)\n    assert X._entry(1, 1) == A._entry(1, 1) + B._entry(1, 1)\n\n    # Test MatAdd with Matrix\n    M = Matrix([[1, 2], [3, 4]])\n    X = MatAdd(A, M)\n    assert X.shape == (n, m)\n    assert X._entry(1, 1) == A._entry(1, 1) + M[1, 1]\n\n    # Test MatAdd with ZeroMatrix\n    Z = ZeroMatrix(n, m)\n    X = MatAdd(A, Z)\n    assert X.shape == (n, m)\n    assert X._entry(1, 1) == A._entry(1, 1)\n\n    # Test MatAdd with GenericZeroMatrix\n    X = MatAdd(A, GenericZeroMatrix())\n    assert X.shape == (n, m)\n    assert X._entry(1, 1) == A._entry(1, 1)\n\n    # Test MatAdd with multiple arguments\n    X = MatAdd(A, B, C)\n    assert X.shape == (n, l)\n    assert X._entry(1, 1) == A._entry(1, 1) + B._entry(1, 1) + C._entry(1, 1)\n\n    # Test MatAdd with transpose\n    X = MatAdd(transpose(A), transpose(B))\n    assert X.shape == (m, n)\n    assert X._entry(1, 1) == transpose(A)._entry(1, 1) + transpose(B)._entry(1, 1)\n\n    # Test MatAdd with adjoint\n    X = MatAdd(adjoint(A), adjoint(B))\n    assert X.shape == (m, n)\n    assert X._entry(1, 1) == adjoint(A)._entry(1, 1) + adjoint(B)._entry(1, 1)\n\n    # Test MatAdd with doit\n    X = MatAdd(A, B).doit()\n    assert X.shape == (n, l)\n    assert X._entry(1, 1) == A.doit()._entry(1, 1) + B.doit()._entry(1,"], "sample_779": ["def test_check_fit_score_takes_y():\n    # Test that check_fit_score_takes_y raises an error when the estimator\n    # does not accept an optional y in fit and score\n    class BadEstimator(BaseEstimator):\n            return self\n\n            return 0\n\n    assert_raises_regex(ValueError, \"Expected y or Y as second argument\",\n                       check_fit_score_takes_y, \"BadEstimator\", BadEstimator())\n\n    # Test that check_fit_score_takes_y does not raise an error when the\n    # estimator accepts an optional y in fit and score\n    class GoodEstimator(BaseEstimator):\n            return self\n\n            return 0\n\n    check_fit_score_takes_y(\"GoodEstimator\", GoodEstimator())\n"], "sample_454": ["    def test_exclusion_constraint_creation(self):\n        # Create a model with an exclusion constraint\n        class Model(models.Model):\n            field1 = models.IntegerField()\n            field2 = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    ExclusionConstraint(\n                        name=\"exclusion_constraint\",\n                        expressions=[(\"field1\", \"&&\"), (\"field2\", \"&&\")],\n                    )\n                ]\n\n        # Create the model's table\n        with connection.schema_editor(atomic=True) as schema_editor:\n            schema_editor.create_model(Model)\n\n        # Check that the exclusion constraint was created\n        constraints = get_constraints(Model._meta.db_table)\n        self.assertEqual(len(constraints), 1)\n        self.assertEqual(constraints[0][\"type\"], \"EXCLUSION\")\n"], "sample_1076": ["def test_printers():\n    expr = x + y + z\n    printers = [PythonCodePrinter, NumPyPrinter, SciPyPrinter, MpmathPrinter, SymPyPrinter]\n    for printer in printers:\n        assert pycode(expr, printer=printer) == pycode(expr, printer=printer())\n\n    assert pycode(expr, printer=PythonCodePrinter) == pycode(expr, printer=PythonCodePrinter({}))\n"], "sample_243": ["def test_is_nullable(self):\n    query = Query(Item)\n    query.setup_joins(['author'], Item._meta, 'table')\n    self.assertTrue(query.is_nullable(Col(Item._meta.get_field('author'))))\n    self.assertFalse(query.is_nullable(Col(Item._meta.get_field('name'))))\n"], "sample_1158": ["def test_sympify_numpy_array():\n    if numpy:\n        a = numpy.array([1, 2, 3])\n        assert sympify(a).shape == (3,)\n        assert sympify(a).dtype == int\n\n        a = numpy.array([[1, 2], [3, 4]])\n        assert sympify(a).shape == (2, 2)\n        assert sympify(a).dtype == int\n\n        a = numpy.array([1, 2, 3], dtype=numpy.float64)\n        assert sympify(a).shape == (3,)\n        assert sympify(a).dtype == float\n\n        a = numpy.array([1, 2, 3], dtype=numpy.complex128)\n        assert sympify(a).shape == (3,)\n        assert sympify(a).dtype == complex\n\n        a = numpy.array([1, 2, 3], dtype=object)\n        assert sympify(a).shape == (3,)\n        assert sympify(a).dtype == object\n\n        a = numpy.array([1, 2, 3], dtype=numpy.int8)\n        assert sympify(a).shape == (3,)\n        assert sympify(a).dtype == int\n\n        a = numpy.array([1, 2, 3], dtype=numpy.uint8)\n        assert sympify(a).shape == (3,)\n        assert sympify(a).dtype == int\n\n        a = numpy.array([1, 2, 3], dtype=numpy.int16)\n        assert sympify(a).shape == (3,)\n        assert sympify(a).dtype == int\n\n        a = numpy.array([1, 2, 3], dtype=numpy.uint16)\n        assert sympify(a).shape == (3,)\n        assert sympify(a).dtype == int\n\n        a = numpy.array([1, 2, 3], dtype=numpy.int32)\n        assert sympify(a).shape == (3,)\n        assert sympify(a).dtype == int\n\n        a = numpy.array([1, 2, 3], dtype=numpy.uint32)\n        assert sympify(a).shape == (3,)\n        assert sympify(a).dtype == int\n\n        a = numpy.array([1, 2, 3], dtype=numpy.int64)\n        assert sympify(a).shape == (3,)\n        assert sympify(a).dtype == int\n\n        a = numpy.array([1, 2, "], "sample_1005": ["def test_latex():\n    # Test latex printing of various objects\n    assert latex(x) == 'x'\n    assert latex(x**2) == 'x^{2}'\n    assert latex(2*x) == '2 x'\n    assert latex(2*x**2) == '2 x^{2}'\n    assert latex(x + 2) == 'x + 2'\n    assert latex(x + 2*x) == '3 x'\n    assert latex(x + 2*x**2) == 'x + 2 x^{2}'\n    assert latex(x + 2*x**2 + 3*x**3) == 'x + 2 x^{2} + 3 x^{3}'\n    assert latex(x**2 + 2*x + 3) == 'x^{2} + 2 x + 3'\n    assert latex(x**2 + 2*x + 3*x**3) == 'x^{2} + 2 x + 3 x^{3}'\n    assert latex(x**2 + 2*x + 3*x**3 + 4*x**4) == 'x^{2} + 2 x + 3 x^{3} + 4 x^{4}'\n    assert latex(x**2 + 2*x + 3*x**3 + 4*x**4 + 5*x**5) == 'x^{2} + 2 x + 3 x^{3} + 4 x^{4} + 5 x^{5}'\n    assert latex(x**2 + 2*x + 3*x**3 + 4*x**4 + 5*x**5 + 6*x**6) == 'x^{2} + 2 x + 3 x^{3} + 4 x^{4} + 5 x^{5} + 6 x^{6}'\n    assert latex(x**2 + 2*x + 3*x**3 + 4*x**4 + 5*x**5 + 6*x**6 + 7*x**7) == 'x^{2} + 2 x + 3 x^{3} + 4 x^{4} + 5 x^{5} + 6 x^{6} + 7 x^{7}'\n    assert latex(x**2 + 2*x + 3*x**3 + 4*x**4 + 5*x**5 + 6*x**"], "sample_973": ["def test_signature_from_str():\n    signature_str = \"(a: int, b: str) -> None\"\n    sig = inspect.signature_from_str(signature_str)\n    assert len(sig.parameters) == 2\n    assert sig.parameters['a'].annotation == int\n    assert sig.parameters['b'].annotation == str\n    assert sig.return_annotation == type(None)\n"], "sample_906": ["def test_alias():\n    # Test alias with noroot and maxdepth\n    rootSymbol = Symbol(None, None, None, None, None)\n    symbol = rootSymbol.add_declaration(parse(\"function\", \"void f(int a, int b)\"), docname=\"TestDoc\", line=42)\n    symbol2 = rootSymbol.add_declaration(parse(\"function\", \"void f(int a, int b)\"), docname=\"TestDoc2\", line=42)\n    symbol3 = symbol.add_declaration(parse(\"function\", \"void f(int a, int b)\"), docname=\"TestDoc\", line=42)\n    symbol4 = symbol.add_declaration(parse(\"function\", \"void f(int a, int b)\"), docname=\"TestDoc2\", line=42)\n    symbol5 = symbol.add_declaration(parse(\"function\", \"void f(int a, int b)\"), docname=\"TestDoc\", line=42)\n    symbol6 = symbol.add_declaration(parse(\"function\", \"void f(int a, int b)\"), docname=\"TestDoc2\", line=42)\n\n    # Test alias with noroot and maxdepth\n    node = addnodes.desc()\n    node.document = \"TestDoc\"\n    node['domain'] = 'c'\n    node['objtype'] = 'alias'\n    node['noindex'] = True\n    aliasOptions = {\n        'maxdepth': 1,\n        'noroot': True,\n    }\n    aliasNode = addnodes.AliasNode(\"f\", aliasOptions, \"TestDoc\", env=None, parentKey=rootSymbol.get_lookup_key())\n    node.append(aliasNode)\n\n    # Test alias with noroot and maxdepth\n    aliasOptions = {\n        'maxdepth': 2,\n        'noroot': True,\n    }\n    aliasNode = addnodes.AliasNode(\"f\", aliasOptions, \"TestDoc\", env=None, parentKey=rootSymbol.get_lookup_key())\n    node.append(aliasNode)\n\n    # Test alias with noroot and maxdepth\n    aliasOptions = {\n        'maxdepth': 3,\n        'noroot': True,\n    }\n    aliasNode = addnodes.AliasNode(\"f\", aliasOptions, \"TestDoc\", env=None, parentKey=rootSymbol.get_lookup_key())\n    node.append(aliasNode)\n\n    # Test alias with noroot and maxdepth\n    aliasOptions = {\n        'maxdepth': 0,\n        'noroot': True,\n    }\n    aliasNode = addnodes"], "sample_843": ["def test_kernel_clone():\n    # Test that cloning a kernel returns a deep copy\n    kernel = RBF(length_scale=2.0)\n    kernel_clone = clone(kernel)\n    kernel_clone.length_scale = 3.0\n    assert kernel.length_scale != kernel_clone.length_scale\n\n    # Test that cloning a kernel with hyperparameters returns a deep copy\n    kernel = RBF(length_scale=2.0, length_scale_bounds=(1e-5, 1e5))\n    kernel_clone = clone(kernel)\n    kernel_clone.length_scale_bounds = (1e-6, 1e6)\n    assert kernel.length_scale_bounds != kernel_clone.length_scale_bounds\n\n    # Test that cloning a kernel with a custom hyperparameter returns a deep copy\n    kernel = RBF(length_scale=2.0)\n    kernel.hyperparameter_length_scale = Hyperparameter(\n        \"length_scale\", \"numeric\", (1e-5, 1e5), fixed=False)\n    kernel_clone = clone(kernel)\n    kernel_clone.hyperparameter_length_scale.bounds = (1e-6, 1e6)\n    assert kernel.hyperparameter_length_scale.bounds != kernel_clone.hyperparameter_length_scale.bounds\n"]}, "raw_scored_generations": {"sample_0": [false], "sample_3": [true], "sample_1": [false], "sample_2": [false], "sample_4": [true], "sample_5": [false], "sample_6": [false], "sample_7": [false], "sample_8": [false], "sample_9": [true], "sample_10": [false], "sample_11": [false], "sample_12": [false], "sample_13": [false], "sample_14": [false], "sample_15": [true], "sample_16": [false], "sample_17": [false], "sample_18": [false], "sample_19": [false], "sample_20": [false], "sample_21": [false], "sample_22": [true], "sample_23": [false], "sample_24": [false], "sample_25": [false], "sample_26": [false], "sample_27": [false], "sample_28": [false], "sample_29": [false], "sample_30": [false], "sample_31": [false], "sample_32": [true], "sample_33": [true], "sample_34": [false], "sample_35": [false], "sample_36": [false], "sample_37": [false], "sample_38": [false], "sample_39": [false], "sample_40": [false], "sample_41": [false], "sample_42": [false], "sample_43": [false], "sample_44": [false], "sample_45": [false], "sample_46": [false], "sample_47": [false], "sample_48": [false], "sample_49": [true], "sample_50": [false], "sample_51": [false], "sample_52": [true], "sample_54": [false], "sample_53": [false], "sample_55": [false], "sample_58": [false], "sample_56": [false], "sample_57": [true], "sample_59": [false], "sample_60": [false], "sample_61": [false], "sample_62": [false], "sample_63": [true], "sample_64": [false], "sample_65": [false], "sample_67": [false], "sample_66": [false], "sample_68": [true], "sample_69": [false], "sample_70": [false], "sample_71": [false], "sample_72": [false], "sample_73": [true], "sample_75": [false], "sample_74": [true], "sample_76": [true], "sample_77": [false], "sample_78": [false], "sample_79": [true], "sample_80": [false], "sample_82": [false], "sample_81": [false], "sample_83": [false], "sample_85": [false], "sample_84": [false], "sample_86": [false], "sample_88": [true], "sample_87": [true], "sample_89": [true], "sample_90": [true], "sample_91": [false], "sample_92": [false], "sample_93": [false], "sample_94": [false], "sample_95": [false], "sample_98": [true], "sample_96": [false], "sample_99": [false], "sample_97": [false], "sample_100": [false], "sample_102": [true], "sample_101": [true], "sample_103": [false], "sample_104": [true], "sample_107": [false], "sample_106": [true], "sample_105": [false], "sample_108": [false], "sample_109": [false], "sample_111": [false], "sample_110": [false], "sample_112": [false], "sample_113": [true], "sample_114": [true], "sample_115": [false], "sample_116": [true], "sample_117": [true], "sample_118": [false], "sample_119": [false], "sample_120": [false], "sample_121": [true], "sample_122": [true], "sample_123": [true], "sample_124": [false], "sample_125": [false], "sample_126": [true], "sample_127": [true], "sample_128": [false], "sample_129": [true], "sample_130": [false], "sample_131": [true], "sample_132": [false], "sample_133": [false], "sample_135": [true], "sample_134": [false], "sample_136": [false], "sample_139": [true], "sample_137": [true], "sample_138": [true], "sample_140": [false], "sample_141": [true], "sample_142": [false], "sample_143": [false], "sample_144": [false], "sample_145": [false], "sample_146": [false], "sample_147": [false], "sample_148": [false], "sample_151": [true], "sample_149": [false], "sample_152": [true], "sample_150": [false], "sample_153": [false], "sample_154": [true], "sample_155": [false], "sample_156": [false], "sample_157": [false], "sample_158": [false], "sample_159": [false], "sample_160": [false], "sample_161": [false], "sample_162": [true], "sample_163": [true], "sample_164": [false], "sample_165": [false], "sample_166": [false], "sample_167": [false], "sample_168": [false], "sample_169": [false], "sample_171": [false], "sample_170": [false], "sample_172": [false], "sample_173": [true], "sample_174": [true], "sample_175": [true], "sample_176": [true], "sample_177": [true], "sample_178": [false], "sample_180": [true], "sample_179": [true], "sample_182": [true], "sample_181": [false], "sample_183": [false], "sample_184": [true], "sample_185": [false], "sample_186": [false], "sample_187": [false], "sample_188": [false], "sample_189": [true], "sample_190": [false], "sample_191": [true], "sample_192": [false], "sample_193": [false], "sample_194": [false], "sample_195": [false], "sample_196": [false], "sample_198": [true], "sample_197": [true], "sample_199": [false], "sample_200": [true], "sample_201": [false], "sample_202": [false], "sample_203": [false], "sample_204": [true], "sample_205": [false], "sample_206": [false], "sample_207": [false], "sample_208": [true], "sample_209": [false], "sample_210": [false], "sample_211": [true], "sample_213": [false], "sample_212": [true], "sample_214": [false], "sample_215": [false], "sample_216": [true], "sample_217": [true], "sample_218": [false], "sample_219": [false], "sample_220": [false], "sample_221": [false], "sample_222": [false], "sample_223": [true], "sample_224": [false], "sample_225": [false], "sample_226": [false], "sample_227": [true], "sample_228": [false], "sample_229": [true], "sample_230": [false], "sample_231": [false], "sample_232": [false], "sample_233": [true], "sample_234": [true], "sample_235": [true], "sample_236": [true], "sample_237": [false], "sample_238": [false], "sample_239": [false], "sample_240": [true], "sample_241": [true], "sample_242": [false], "sample_243": [false], "sample_244": [false], "sample_245": [true], "sample_246": [true], "sample_247": [true], "sample_248": [true], "sample_249": [true], "sample_250": [true], "sample_251": [true], "sample_252": [false], "sample_253": [true], "sample_254": [false], "sample_256": [true], "sample_255": [true], "sample_257": [false], "sample_258": [false], "sample_259": [true], "sample_260": [true], "sample_261": [false], "sample_262": [false], "sample_263": [false], "sample_264": [false], "sample_265": [true], "sample_266": [true], "sample_267": [false], "sample_268": [true], "sample_269": [false], "sample_270": [false], "sample_271": [false], "sample_272": [false], "sample_273": [false], "sample_274": [false], "sample_275": [false], "sample_276": [false], "sample_277": [false], "sample_278": [false], "sample_279": [false], "sample_280": [false], "sample_281": [true], "sample_282": [true], "sample_283": [false], "sample_284": [true], "sample_285": [true], "sample_286": [false], "sample_287": [false], "sample_288": [false], "sample_289": [true], "sample_290": [false], "sample_291": [false], "sample_292": [true], "sample_293": [false], "sample_294": [true], "sample_295": [true], "sample_296": [false], "sample_297": [false], "sample_298": [false], "sample_299": [true], "sample_300": [false], "sample_301": [false], "sample_302": [false], "sample_303": [true], "sample_304": [false], "sample_305": [false], "sample_306": [false], "sample_307": [true], "sample_308": [false], "sample_309": [true], "sample_310": [false], "sample_312": [true], "sample_311": [false], "sample_313": [false], "sample_314": [true], "sample_315": [false], "sample_316": [false], "sample_317": [true], "sample_318": [false], "sample_319": [true], "sample_320": [false], "sample_321": [true], "sample_322": [false], "sample_323": [false], "sample_324": [true], "sample_325": [false], "sample_326": [false], "sample_327": [false], "sample_328": [false], "sample_329": [false], "sample_330": [false], "sample_331": [false], "sample_332": [false], "sample_333": [false], "sample_334": [true], "sample_335": [false], "sample_336": [false], "sample_337": [false], "sample_338": [true], "sample_339": [true], "sample_340": [true], "sample_341": [false], "sample_342": [true], "sample_343": [false], "sample_344": [true], "sample_345": [false], "sample_346": [false], "sample_347": [false], "sample_348": [false], "sample_349": [false], "sample_350": [true], "sample_351": [false], "sample_352": [false], "sample_353": [false], "sample_354": [false], "sample_355": [false], "sample_356": [true], "sample_357": [true], "sample_358": [true], "sample_359": [false], "sample_360": [false], "sample_361": [false], "sample_362": [true], "sample_363": [false], "sample_364": [false], "sample_365": [false], "sample_366": [false], "sample_367": [false], "sample_368": [false], "sample_369": [true], "sample_370": [false], "sample_371": [false], "sample_372": [false], "sample_373": [true], "sample_374": [true], "sample_375": [true], "sample_376": [false], "sample_377": [false], "sample_378": [false], "sample_379": [false], "sample_380": [false], "sample_381": [true], "sample_382": [false], "sample_383": [true], "sample_384": [false], "sample_385": [false], "sample_386": [false], "sample_387": [false], "sample_388": [true], "sample_389": [false], "sample_390": [true], "sample_391": [true], "sample_392": [false], "sample_393": [true], "sample_394": [false], "sample_395": [false], "sample_396": [false], "sample_397": [true], "sample_398": [true], "sample_399": [true], "sample_400": [true], "sample_401": [true], "sample_402": [false], "sample_403": [false], "sample_404": [true], "sample_405": [false], "sample_406": [false], "sample_407": [false], "sample_408": [true], "sample_409": [false], "sample_410": [false], "sample_411": [false], "sample_412": [false], "sample_413": [true], "sample_414": [false], "sample_415": [true], "sample_416": [true], "sample_417": [true], "sample_418": [false], "sample_419": [true], "sample_420": [false], "sample_421": [false], "sample_422": [false], "sample_423": [true], "sample_424": [false], "sample_425": [false], "sample_426": [true], "sample_427": [true], "sample_428": [false], "sample_429": [false], "sample_430": [true], "sample_431": [false], "sample_432": [true], "sample_433": [false], "sample_434": [false], "sample_435": [true], "sample_436": [false], "sample_437": [false], "sample_438": [false], "sample_439": [true], "sample_440": [false], "sample_441": [false], "sample_442": [false], "sample_443": [false], "sample_444": [true], "sample_445": [true], "sample_446": [false], "sample_447": [true], "sample_448": [false], "sample_449": [true], "sample_450": [true], "sample_451": [true], "sample_453": [false], "sample_452": [false], "sample_454": [false], "sample_455": [false], "sample_456": [false], "sample_457": [false], "sample_458": [false], "sample_459": [false], "sample_460": [false], "sample_461": [false], "sample_462": [false], "sample_463": [true], "sample_464": [false], "sample_465": [true], "sample_466": [false], "sample_467": [true], "sample_469": [true], "sample_468": [false], "sample_470": [false], "sample_471": [false], "sample_472": [false], "sample_473": [false], "sample_474": [false], "sample_475": [false], "sample_476": [false], "sample_477": [false], "sample_478": [false], "sample_479": [true], "sample_480": [false], "sample_481": [false], "sample_482": [false], "sample_483": [false], "sample_484": [true], "sample_485": [false], "sample_486": [false], "sample_487": [false], "sample_488": [false], "sample_489": [false], "sample_490": [false], "sample_491": [false], "sample_492": [false], "sample_493": [true], "sample_494": [false], "sample_495": [true], "sample_496": [false], "sample_497": [false], "sample_498": [false], "sample_499": [false], "sample_500": [false], "sample_501": [false], "sample_502": [true], "sample_503": [true], "sample_504": [false], "sample_505": [false], "sample_506": [false], "sample_507": [true], "sample_508": [false], "sample_509": [false], "sample_510": [false], "sample_511": [true], "sample_512": [false], "sample_513": [false], "sample_514": [false], "sample_515": [false], "sample_516": [false], "sample_517": [false], "sample_518": [false], "sample_519": [false], "sample_520": [false], "sample_521": [false], "sample_522": [false], "sample_523": [false], "sample_524": [false], "sample_525": [false], "sample_526": [false], "sample_527": [true], "sample_528": [false], "sample_529": [false], "sample_530": [false], "sample_531": [false], "sample_532": [false], "sample_533": [false], "sample_534": [false], "sample_535": [false], "sample_536": [false], "sample_537": [false], "sample_538": [false], "sample_539": [false], "sample_540": [false], "sample_541": [false], "sample_542": [false], "sample_543": [false], "sample_544": [false], "sample_545": [false], "sample_546": [false], "sample_547": [false], "sample_548": [false], "sample_549": [false], "sample_550": [false], "sample_551": [false], "sample_552": [false], "sample_553": [false], "sample_554": [false], "sample_555": [false], "sample_556": [false], "sample_557": [false], "sample_558": [false], "sample_559": [false], "sample_560": [false], "sample_561": [false], "sample_562": [false], "sample_563": [false], "sample_564": [false], "sample_565": [false], "sample_566": [false], "sample_567": [false], "sample_568": [false], "sample_569": [false], "sample_570": [false], "sample_571": [true], "sample_572": [false], "sample_573": [false], "sample_574": [false], "sample_575": [false], "sample_576": [true], "sample_577": [false], "sample_578": [false], "sample_579": [false], "sample_580": [false], "sample_581": [false], "sample_582": [false], "sample_583": [false], "sample_584": [false], "sample_585": [false], "sample_586": [false], "sample_587": [false], "sample_588": [false], "sample_589": [false], "sample_590": [false], "sample_591": [false], "sample_592": [false], "sample_593": [true], "sample_594": [false], "sample_595": [false], "sample_596": [false], "sample_597": [false], "sample_598": [false], "sample_599": [false], "sample_600": [false], "sample_601": [false], "sample_602": [false], "sample_603": [false], "sample_604": [false], "sample_605": [false], "sample_606": [false], "sample_607": [false], "sample_608": [false], "sample_609": [false], "sample_610": [false], "sample_611": [false], "sample_612": [false], "sample_613": [false], "sample_614": [false], "sample_615": [false], "sample_616": [false], "sample_617": [false], "sample_618": [false], "sample_619": [false], "sample_620": [false], "sample_621": [false], "sample_622": [false], "sample_623": [false], "sample_624": [false], "sample_625": [false], "sample_626": [false], "sample_627": [false], "sample_628": [true], "sample_629": [true], "sample_630": [false], "sample_631": [false], "sample_632": [false], "sample_633": [false], "sample_634": [false], "sample_635": [false], "sample_636": [false], "sample_637": [false], "sample_638": [false], "sample_639": [false], "sample_640": [false], "sample_641": [false], "sample_642": [false], "sample_643": [false], "sample_644": [false], "sample_645": [false], "sample_646": [false], "sample_647": [false], "sample_648": [false], "sample_649": [false], "sample_650": [false], "sample_651": [false], "sample_652": [false], "sample_653": [false], "sample_654": [false], "sample_655": [true], "sample_656": [false], "sample_657": [false], "sample_658": [false], "sample_659": [false], "sample_660": [false], "sample_661": [false], "sample_662": [false], "sample_663": [false], "sample_664": [false], "sample_665": [false], "sample_666": [false], "sample_667": [false], "sample_668": [false], "sample_669": [false], "sample_670": [false], "sample_671": [false], "sample_672": [false], "sample_673": [false], "sample_674": [false], "sample_675": [false], "sample_676": [false], "sample_677": [false], "sample_678": [false], "sample_679": [false], "sample_680": [false], "sample_681": [false], "sample_682": [false], "sample_683": [false], "sample_684": [false], "sample_685": [false], "sample_686": [false], "sample_687": [false], "sample_688": [false], "sample_689": [false], "sample_690": [false], "sample_691": [true], "sample_692": [false], "sample_693": [false], "sample_694": [false], "sample_695": [true], "sample_696": [false], "sample_697": [true], "sample_698": [false], "sample_699": [false], "sample_700": [false], "sample_701": [false], "sample_702": [false], "sample_703": [false], "sample_704": [false], "sample_705": [false], "sample_706": [false], "sample_707": [false], "sample_708": [false], "sample_709": [false], "sample_710": [false], "sample_711": [false], "sample_712": [false], "sample_713": [false], "sample_714": [false], "sample_715": [false], "sample_716": [false], "sample_717": [false], "sample_718": [false], "sample_719": [false], "sample_720": [false], "sample_721": [true], "sample_722": [false], "sample_723": [false], "sample_724": [false], "sample_725": [false], "sample_726": [false], "sample_727": [false], "sample_728": [false], "sample_729": [false], "sample_730": [false], "sample_731": [true], "sample_732": [false], "sample_733": [true], "sample_734": [false], "sample_735": [true], "sample_736": [true], "sample_737": [true], "sample_738": [false], "sample_739": [false], "sample_740": [false], "sample_741": [true], "sample_742": [false], "sample_743": [false], "sample_744": [false], "sample_745": [true], "sample_746": [false], "sample_747": [false], "sample_748": [false], "sample_749": [false], "sample_750": [false], "sample_751": [false], "sample_752": [false], "sample_753": [false], "sample_754": [false], "sample_755": [true], "sample_756": [false], "sample_757": [false], "sample_758": [false], "sample_759": [false], "sample_760": [false], "sample_761": [false], "sample_762": [false], "sample_763": [true], "sample_764": [false], "sample_765": [false], "sample_766": [false], "sample_767": [false], "sample_768": [false], "sample_769": [false], "sample_770": [false], "sample_771": [false], "sample_772": [false], "sample_773": [false], "sample_774": [false], "sample_775": [false], "sample_776": [false], "sample_777": [false], "sample_778": [false], "sample_779": [false], "sample_780": [false], "sample_781": [false], "sample_782": [false], "sample_783": [false], "sample_784": [false], "sample_785": [true], "sample_786": [false], "sample_787": [false], "sample_788": [false], "sample_789": [false], "sample_790": [false], "sample_791": [false], "sample_792": [false], "sample_793": [true], "sample_794": [false], "sample_795": [false], "sample_796": [false], "sample_797": [false], "sample_798": [false], "sample_799": [true], "sample_800": [false], "sample_801": [false], "sample_802": [false], "sample_803": [false], "sample_804": [false], "sample_805": [false], "sample_806": [false], "sample_807": [false], "sample_808": [true], "sample_809": [false], "sample_810": [true], "sample_811": [false], "sample_812": [false], "sample_813": [false], "sample_814": [false], "sample_815": [false], "sample_816": [false], "sample_817": [false], "sample_818": [false], "sample_819": [false], "sample_820": [false], "sample_821": [false], "sample_822": [false], "sample_823": [false], "sample_824": [false], "sample_825": [false], "sample_826": [false], "sample_827": [false], "sample_828": [false], "sample_829": [true], "sample_830": [true], "sample_831": [false], "sample_832": [true], "sample_833": [true], "sample_834": [false], "sample_835": [false], "sample_836": [true], "sample_837": [true], "sample_838": [false], "sample_839": [false], "sample_840": [false], "sample_841": [false], "sample_842": [false], "sample_843": [false], "sample_844": [false], "sample_845": [true], "sample_846": [false], "sample_847": [false], "sample_848": [false], "sample_849": [false], "sample_850": [false], "sample_851": [false], "sample_852": [false], "sample_853": [false], "sample_854": [false], "sample_855": [false], "sample_856": [false], "sample_857": [true], "sample_858": [true], "sample_859": [true], "sample_860": [true], "sample_861": [false], "sample_862": [false], "sample_863": [false], "sample_864": [false], "sample_865": [false], "sample_866": [false], "sample_867": [false], "sample_868": [false], "sample_869": [false], "sample_870": [false], "sample_871": [false], "sample_872": [false], "sample_873": [true], "sample_874": [false], "sample_875": [false], "sample_876": [false], "sample_877": [false], "sample_878": [false], "sample_879": [false], "sample_880": [false], "sample_881": [false], "sample_882": [false], "sample_883": [false], "sample_884": [false], "sample_885": [false], "sample_886": [false], "sample_887": [false], "sample_888": [false], "sample_889": [false], "sample_890": [false], "sample_891": [false], "sample_892": [false], "sample_893": [false], "sample_894": [false], "sample_895": [false], "sample_896": [false], "sample_897": [false], "sample_898": [false], "sample_899": [false], "sample_900": [false], "sample_901": [false], "sample_902": [true], "sample_903": [true], "sample_904": [false], "sample_905": [false], "sample_906": [false], "sample_907": [false], "sample_908": [false], "sample_909": [false], "sample_910": [false], "sample_911": [false], "sample_912": [false], "sample_913": [false], "sample_914": [false], "sample_915": [false], "sample_916": [false], "sample_917": [false], "sample_918": [false], "sample_919": [false], "sample_920": [false], "sample_921": [false], "sample_922": [false], "sample_923": [true], "sample_924": [false], "sample_925": [false], "sample_926": [false], "sample_927": [false], "sample_928": [false], "sample_929": [false], "sample_930": [false], "sample_931": [false], "sample_932": [false], "sample_933": [false], "sample_934": [false], "sample_935": [false], "sample_936": [false], "sample_937": [false], "sample_938": [false], "sample_939": [false], "sample_940": [false], "sample_941": [false], "sample_942": [false], "sample_943": [false], "sample_944": [false], "sample_945": [false], "sample_946": [false], "sample_947": [false], "sample_948": [false], "sample_949": [false], "sample_950": [false], "sample_951": [false], "sample_952": [false], "sample_953": [false], "sample_954": [false], "sample_955": [false], "sample_956": [false], "sample_957": [false], "sample_958": [false], "sample_959": [false], "sample_960": [false], "sample_961": [false], "sample_962": [false], "sample_963": [false], "sample_964": [false], "sample_965": [false], "sample_966": [false], "sample_967": [true], "sample_968": [false], "sample_969": [false], "sample_970": [false], "sample_971": [false], "sample_972": [false], "sample_973": [false], "sample_974": [false], "sample_975": [false], "sample_976": [false], "sample_977": [false], "sample_978": [false], "sample_979": [true], "sample_980": [false], "sample_981": [false], "sample_982": [false], "sample_983": [false], "sample_984": [false], "sample_985": [false], "sample_986": [false], "sample_987": [false], "sample_988": [false], "sample_989": [false], "sample_990": [false], "sample_991": [false], "sample_992": [false], "sample_993": [false], "sample_994": [false], "sample_995": [false], "sample_996": [false], "sample_997": [false], "sample_998": [false], "sample_999": [false], "sample_1000": [false], "sample_1001": [false], "sample_1002": [false], "sample_1003": [false], "sample_1004": [false], "sample_1005": [false], "sample_1006": [false], "sample_1007": [false], "sample_1008": [false], "sample_1009": [false], "sample_1010": [false], "sample_1011": [false], "sample_1012": [false], "sample_1013": [true], "sample_1014": [false], "sample_1015": [false], "sample_1016": [false], "sample_1017": [true], "sample_1018": [false], "sample_1019": [false], "sample_1020": [false], "sample_1021": [false], "sample_1022": [false], "sample_1023": [false], "sample_1024": [false], "sample_1025": [false], "sample_1026": [true], "sample_1027": [false], "sample_1028": [false], "sample_1029": [false], "sample_1030": [false], "sample_1031": [false], "sample_1032": [false], "sample_1033": [false], "sample_1034": [false], "sample_1035": [true], "sample_1036": [false], "sample_1037": [false], "sample_1038": [false], "sample_1039": [false], "sample_1040": [false], "sample_1041": [false], "sample_1042": [false], "sample_1043": [false], "sample_1044": [false], "sample_1045": [false], "sample_1046": [false], "sample_1047": [false], "sample_1048": [false], "sample_1049": [false], "sample_1050": [false], "sample_1051": [false], "sample_1052": [false], "sample_1053": [false], "sample_1054": [false], "sample_1055": [true], "sample_1056": [false], "sample_1057": [false], "sample_1058": [false], "sample_1059": [false], "sample_1060": [false], "sample_1061": [false], "sample_1062": [false], "sample_1063": [true], "sample_1064": [false], "sample_1065": [false], "sample_1066": [true], "sample_1067": [false], "sample_1068": [false], "sample_1069": [false], "sample_1070": [false], "sample_1071": [false], "sample_1072": [false], "sample_1073": [false], "sample_1074": [true], "sample_1075": [false], "sample_1076": [false], "sample_1077": [false], "sample_1078": [false], "sample_1079": [false], "sample_1080": [true], "sample_1081": [false], "sample_1082": [false], "sample_1083": [false], "sample_1084": [false], "sample_1085": [false], "sample_1086": [false], "sample_1087": [false], "sample_1088": [false], "sample_1089": [false], "sample_1090": [false], "sample_1091": [false], "sample_1092": [false], "sample_1093": [false], "sample_1094": [false], "sample_1095": [false], "sample_1096": [false], "sample_1097": [true], "sample_1098": [false], "sample_1099": [false], "sample_1100": [false], "sample_1101": [false], "sample_1102": [false], "sample_1103": [false], "sample_1104": [false], "sample_1105": [false], "sample_1106": [false], "sample_1107": [false], "sample_1108": [false], "sample_1109": [false], "sample_1110": [false], "sample_1111": [false], "sample_1112": [false], "sample_1113": [false], "sample_1114": [false], "sample_1115": [false], "sample_1116": [false], "sample_1117": [false], "sample_1118": [false], "sample_1119": [false], "sample_1120": [false], "sample_1121": [true], "sample_1122": [false], "sample_1123": [false], "sample_1124": [false], "sample_1125": [false], "sample_1126": [false], "sample_1127": [false], "sample_1128": [true], "sample_1129": [false], "sample_1130": [false], "sample_1131": [false], "sample_1132": [false], "sample_1133": [false], "sample_1134": [false], "sample_1135": [false], "sample_1136": [false], "sample_1137": [false], "sample_1138": [false], "sample_1139": [false], "sample_1140": [false], "sample_1141": [false], "sample_1142": [false], "sample_1143": [false], "sample_1144": [true], "sample_1145": [true], "sample_1146": [false], "sample_1147": [false], "sample_1148": [true], "sample_1149": [true], "sample_1150": [false], "sample_1151": [false], "sample_1152": [false], "sample_1153": [false], "sample_1154": [true], "sample_1155": [false], "sample_1156": [false], "sample_1157": [false], "sample_1158": [false], "sample_1159": [false], "sample_1160": [false], "sample_1161": [false], "sample_1162": [true], "sample_1163": [false], "sample_1164": [false], "sample_1165": [false], "sample_1166": [true], "sample_1167": [false], "sample_1168": [false], "sample_1169": [true], "sample_1170": [false], "sample_1171": [false], "sample_1172": [false], "sample_1173": [false], "sample_1174": [false], "sample_1175": [false], "sample_1176": [false], "sample_1177": [false], "sample_1178": [false], "sample_1179": [false], "sample_1180": [false], "sample_1181": [true], "sample_1182": [false], "sample_1183": [false], "sample_1184": [true], "sample_1185": [true], "sample_1186": [false], "sample_1187": [false], "sample_1188": [false], "sample_1189": [true], "sample_1190": [false], "sample_1191": [true], "sample_1192": [false], "sample_1193": [false], "sample_1194": [false], "sample_1195": [false], "sample_1196": [false], "sample_1197": [false], "sample_1198": [false], "sample_1199": [false], "sample_1200": [false], "sample_1201": [false], "sample_1202": [false], "sample_1203": [false], "sample_1204": [false], "sample_1205": [false], "sample_1206": [false], "sample_1207": [false], "sample_1208": [false], "sample_1209": [false]}}