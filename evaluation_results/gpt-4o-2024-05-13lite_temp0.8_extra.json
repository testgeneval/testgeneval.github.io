{"raw_generations": {"sample_67": ["    def test_serialize_regex_with_flags(self):\n        regex = re.compile(r\"^\\w+$\", re.IGNORECASE | re.MULTILINE)\n        self.assertSerializedEqual(regex)\n        string, imports = MigrationWriter.serialize(regex)\n        self.assertEqual(\n            string,\n            \"re.compile('^\\\\\\\\w+$', flags=re.RegexFlag['IGNORECASE']|re.RegexFlag['MULTILINE'])\"\n        )\n        self.assertEqual(imports, {\"import re\"})\n", "    def test_serialize_compiled_regex_flags(self):\n        regex = re.compile(r\"^[a-zA-Z]+$\", re.IGNORECASE | re.MULTILINE)\n        string, imports = MigrationWriter.serialize(regex)\n        self.assertEqual(\n            string,\n            \"re.compile('^[a-zA-Z]+$', re.RegexFlag['IGNORECASE'] | re.RegexFlag['MULTILINE'])\",\n        )\n        self.assertIn(\"import re\", imports)\n        self.serialize_round_trip(regex)\n", "    def test_serialize_datetime_with_timezone(self):\n        dt = datetime.datetime(2023, 10, 7, 12, 30, 45, tzinfo=datetime.timezone.utc)\n        self.assertSerializedEqual(dt)\n        self.assertSerializedResultEqual(\n            dt,\n            (\n                \"datetime.datetime(2023, 10, 7, 12, 30, 45, tzinfo=datetime.timezone.utc)\",\n                {\"import datetime\"},\n            ),\n        )\n", "def test_serialize_deconstructable_instance(self):\n        instance = DeconstructibleInstances()\n        self.assertSerializedResultEqual(\n            instance,\n            (\"migrations.test_writer.DeconstructibleInstances()\", {\"import migrations.test_writer\"}),\n        )\n", "    def test_serialize_datetime_with_tzinfo(self):\n        dt_with_tz = datetime.datetime(2022, 5, 17, 15, 30, tzinfo=datetime.timezone(datetime.timedelta(hours=2)))\n        self.assertSerializedResultEqual(\n            dt_with_tz,\n            (\n                \"datetime.datetime(2022, 5, 17, 13, 30, tzinfo=datetime.timezone.utc)\",\n                {\"import datetime\"},\n            ),\n        )\n"], "sample_97": ["def test_label_encoder_non_comparable_labels():\n    # Test LabelEncoder with non-comparable labels\n    le = LabelEncoder()\n    non_comparable_labels = [3, 'a', (1, 2), 5]\n    assert_raises(TypeError, le.fit, non_comparable_labels)\n    assert_raises(TypeError, le.fit_transform, non_comparable_labels)\n", "def test_label_encoder_multitype():\n    # Test LabelEncoder with mixed types\n    le = LabelEncoder()\n    mixed_labels = [1, \"two\", 3, \"four\", 5]\n    le.fit(mixed_labels)\n    assert_array_equal(le.classes_, [1, 3, 5, \"four\", \"two\"])\n    assert_array_equal(le.transform([1, \"two\", 3, 3, \"four\", 5]),\n                       [0, 4, 1, 1, 3, 2])\n    assert_array_equal(le.inverse_transform([0, 4, 1, 1, 3, 2]),\n                       [1, \"two\", 3, 3, \"four\", 5])\n    assert_raises(ValueError, le.transform, [1, \"six\"])\n\n    # Test empty fit and transform\n    le = LabelEncoder()\n    le.fit([])\n    assert_array_equal(le.classes_, [])\n    assert_array_equal(le.transform([]), [])\n    assert_array_equal(le.inverse_transform([]), [])\n", "def test_label_encoder_strings():\n    # Test LabelEncoder with string labels\n    le = LabelEncoder()\n    le.fit([\"dog\", \"cat\", \"mouse\", \"dog\", \"dog\", \"cat\"])\n    assert_array_equal(le.classes_, [\"cat\", \"dog\", \"mouse\"])\n    assert_array_equal(le.transform([\"cat\", \"dog\", \"mouse\", \"dog\"]),\n                       [0, 1, 2, 1])\n    assert_array_equal(le.inverse_transform([0, 1, 2, 1]),\n                       [\"cat\", \"dog\", \"mouse\", \"dog\"])\n    assert_raises(ValueError, le.transform, [\"elephant\"])\n\n    # Edge case with empty string and whitespace string\n    le.fit([\"\", \" \", \"a\", \"b\"])\n    assert_array_equal(le.classes_, [\"\", \" \", \"a\", \"b\"])\n    assert_array_equal(le.transform([\"\", \" \", \"a\", \"b\"]),\n                       [0, 1, 2, 3])\n    assert_array_equal(le.inverse_transform([0, 1, 2, 3]),\n                       [\"\", \" \", \"a\", \"b\"])\n", "def test_label_encoder_with_strings():\n    le = LabelEncoder()\n    le.fit([\"dog\", \"cat\", \"fish\", \"dog\"])\n    assert_array_equal(le.classes_, [\"cat\", \"dog\", \"fish\"])\n    assert_array_equal(le.transform([\"fish\", \"cat\", \"cat\", \"dog\"]),\n                       [2, 0, 0, 1])\n    assert_array_equal(le.inverse_transform([2, 0, 0, 1]),\n                       [\"fish\", \"cat\", \"cat\", \"dog\"])\n    assert_raises(ValueError, le.transform, [\"bird\"])\n\n    # Test with unseen labels\n    msg = \"y contains previously unseen labels: 'bird'\"\n    assert_raise_message(ValueError, msg, le.transform, [\"bird\"])\n", "def test_multilabel_binarizer_with_empty_classes():\n    # Ensure MultiLabelBinarizer handles case with empty classes correctly\n    mlb = MultiLabelBinarizer(classes=[])\n    y = [[1, 2], [1], [2]]\n    expected = np.zeros((3, 0), dtype=int)\n    transformed = mlb.fit_transform(y)\n    assert_array_equal(transformed, expected)\n    assert_array_equal(mlb.inverse_transform(transformed), [tuple()] * 3)\n"], "sample_37": ["    def test_register_and_unregister_lookup(self):\n        class CustomLookup:\n            lookup_name = 'custom'\n\n        class TestModel(RegisterLookupMixin):\n            pass\n\n        # Test register_lookup\n        TestModel.register_lookup(CustomLookup)\n        self.assertIn('custom', TestModel.class_lookups)\n        self.assertIs(TestModel.class_lookups['custom'], CustomLookup)\n\n        # Test unregister_lookup\n        TestModel._unregister_lookup(CustomLookup)\n        self.assertNotIn('custom', TestModel.class_lookups)\n", "    def test_filtered_relation_initialization(self):\n        \"\"\"Test initialization of FilteredRelation with valid and invalid arguments.\"\"\"\n        valid_relation = FilteredRelation('test_relation', condition=Q(test_field=1))\n        self.assertEqual(valid_relation.relation_name, 'test_relation')\n        self.assertEqual(valid_relation.condition, Q(test_field=1))\n\n        with self.assertRaises(ValueError):\n            FilteredRelation('', condition=Q(test_field=1))\n\n        with self.assertRaises(ValueError):\n            FilteredRelation('test_relation', condition='invalid_condition')\n", "    def setUp(self):\n        self.company = Company.objects.create(\n            name=\"TechCorp\", num_employees=500, num_chairs=200,\n            ceo=Employee.objects.create(firstname=\"Alice\", lastname=\"Johnson\", salary=100)\n        )\n        self.employee1 = Employee.objects.create(firstname=\"John\", lastname=\"Doe\", salary=50, company=self.company)\n        self.employee2 = Employee.objects.create(firstname=\"Jane\", lastname=\"Smith\", salary=60, company=self.company)\n", "    def setUp(self):\n        self.company_a = Company.objects.create(\n            name=\"Company A\", num_employees=100, num_chairs=50,\n            ceo=Employee.objects.create(firstname=\"Alice\", lastname=\"Smith\", salary=100)\n        )\n        self.company_b = Company.objects.create(\n            name=\"Company B\", num_employees=200, num_chairs=100,\n            ceo=Employee.objects.create(firstname=\"Bob\", lastname=\"Johnson\", salary=200)\n        )\n", "    def setUpTestData(cls):\n        cls.company = Company.objects.create(name=\"Test Company\", num_employees=50, num_chairs=20)\n        cls.employee1 = Employee.objects.create(firstname=\"John\", lastname=\"Doe\", salary=100, company=cls.company)\n        cls.employee2 = Employee.objects.create(firstname=\"Jane\", lastname=\"Smith\", salary=150, company=cls.company)\n        cls.employee3 = Employee.objects.create(firstname=\"Jim\", lastname=\"Beam\", salary=200, company=cls.company)\n"], "sample_7": ["    def test_ensure_echo_on(self, mocked_tcsetattr, mocked_tcgetattr, mocked_stdin):\n        mocked_stdin.isatty.return_value = True\n        attrs = [0, 0, 0, 0]\n        mocked_tcgetattr.return_value = attrs\n        attrs[3] = attrs[3] & ~termios.ECHO\n        autoreload.ensure_echo_on()\n        mocked_tcgetattr.assert_called_once_with(mocked_stdin)\n        mocked_tcsetattr.assert_called_once_with(mocked_stdin, termios.TCSANOW, attrs)\n", "    def test_ensure_echo_on_with_echo_disabled(self, mock_isatty, mock_termios):\n        # Mock termios.tcgetattr to return attributes with ECHO off\n        attrs = [0, 0, 0, 0, 0]\n        attrs[3] = 0  # ECHO off\n        mock_termios.tcgetattr.return_value = attrs\n\n        autoreload.ensure_echo_on()\n\n        # ECHO should be enabled\n        attrs[3] |= mock_termios.ECHO\n        mock_termios.tcsetattr.assert_called_once_with(sys.stdin, mock_termios.TCSANOW, attrs)\n", "    def test_ensure_echo_on_with_echo_disabled(self, mock_tcsetattr, mock_tcgetattr, mock_isatty):\n        attrs = [0, 0, 0, 0]\n        attrs[3] = 0  # ECHO is off\n        mock_tcgetattr.return_value = attrs\n\n        autoreload.ensure_echo_on()\n\n        self.assertTrue(mock_tcsetattr.called)\n", "    def test_ensure_echo_on_enabled(self, mocked_tcsetattr, mocked_tcgetattr, mocked_isatty):\n        mocked_tcgetattr.return_value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n        autoreload.ensure_echo_on()\n        self.assertEqual(mocked_tcsetattr.call_count, 1)\n", "    def test_notify_file_changed_triggers_reload(self):\n        reloader = autoreload.BaseReloader()\n        reloader.stop = mock.MagicMock()\n        \n        with mock.patch('django.utils.autoreload.trigger_reload') as mocked_trigger_reload:\n            reloader.notify_file_changed(Path('/some/file/path'))\n            mocked_trigger_reload.assert_called_once_with(Path('/some/file/path'))\n"], "sample_129": ["def test_latex_evalf():\n    # Test for latex representation of evaluated expressions\n    expr = sin(x) + cos(x)\n    assert latex(expr.evalf(subs={x: pi/4})) == r'\\sin{\\left(\\frac{\\pi}{4}\\right)} + \\cos{\\left(\\frac{\\pi}{4}\\right)}'\n    expr = Integral(exp(-x**2), (x, -oo, oo))\n    assert latex(expr.evalf()) == r'\\int_{-\\infty}^{\\infty} e^{- x^{2}}\\, dx'\n    expr = Sum(1/n**2, (n, 1, oo))\n    assert latex(expr.evalf()) == r'\\sum_{n=1}^{\\infty} \\frac{1}{n^{2}}'\n", "def test_latex_custom_functions():\n    # Custom function names with LaTeX-compatible symbols and special characters\n    hbar = Function('hbar')\n    assert latex(hbar(x)) == r'\\hbar{\\left (x \\right )}'\n    assert latex(hbar(x)**2) == r'\\hbar^{2}{\\left (x \\right )}'\n    \n    myfunc = Function('my_func')\n    assert latex(myfunc(x)) == r'\\operatorname{my\\_func}{\\left (x \\right )}'\n    \n    specialfunc = Function('special_func!')\n    assert latex(specialfunc(x)) == r'\\operatorname{special\\_func!}{\\left (x \\right )}'\n\n    underscores = Function('func_with_underscores')\n    assert latex(underscores(x)) == r'\\operatorname{func\\_with\\_underscores}{\\left (x \\right )}'\n    \n    greek_func = Function('Gamma_func')\n    assert latex(greek_func(x)) == r'\\Gamma_{\\text{func}}{\\left (x \\right )}'\n", "def test_latex_mixed_expressions():\n    from sympy import Derivative, Integral, Function, Sum, Product, Eq, Rational\n    f = Function('f')\n    g = Function('g')\n    \n    # Testing Derivative with Integral and Sum\n    expr = Derivative(Integral(f(x), (x, 0, 1)) + Sum(g(x), (x, 1, 10)), x)\n    assert latex(expr) == r\"\\frac{d}{d x} \\left(\\int_{0}^{1} f{\\left (x \\right )}\\, dx + \\sum_{x=1}^{10} g{\\left (x \\right )}\\right)\"\n    \n    # Testing Product with Rational exponents and integrals\n    expr = Product((x + y)**Rational(3, 4), (x, 1, 5)) * Integral(g(x), (x, 0, y))\n    assert latex(expr) == r\"\\prod_{x=1}^{5} \\left(x + y\\right)^{\\frac{3}{4}} \\int_{0}^{y} g{\\left (x \\right )}\\, dx\"\n    \n    # Testing equations with derivatives and sums\n    expr = Eq(Derivative(f(x), x) + Sum(g(x), (x, 1, 5)), 0)\n    assert latex(expr) == r\"\\frac{d}{d x} f{\\left (x \\right )} + \\sum_{x=1}^{5} g{\\left (x \\right )} = 0\"\n\n    # Testing nested integrals\n    expr = Integral(Integral(f(x, y), (x, 0, 1)), (y, 0, 1))\n    assert latex(expr) == r\"\\int_{0}^{1} \\int_{0}^{1} f{\\left (x,y \\right )}\\, dx\\, dy\"\n\n    # Testing nested sums\n    expr = Sum(Sum(f(x, y), (x, 1, 5)), (y, 1, 5))\n    assert latex(expr) == r\"\\sum_{y=1}^{5} \\sum_{x=1}^{5} f{\\left (x, y \\right )}\"\n", "def test_latex_QuotientModuleElement():\n    from sympy.polys.agca import quotient_module\n    from sympy.polys.domains import QQ\n\n    R = QQ.old_poly_ring(x, y)\n    F = R.free_module(2)\n    M = F.submodule([x, y], [1, x**2])\n    Q = F / M\n\n    qme = Q.convert([x**2, y**2])\n    assert latex(qme) == r\"{\\left[\\begin{matrix}x^{2}\\\\y^{2}\\end{matrix}\\right]} + {\\left< {\\left[ {x},{y} \\right]},{\\left[ {1},{x^{2}} \\right]} \\right>}\"\n\n    qme2 = Q.convert([1, x*y + y])\n    assert latex(qme2) == r\"{\\left[\\begin{matrix}1\\\\x y + y\\end{matrix}\\right]} + {\\left< {\\left[ {x},{y} \\right]},{\\left[ {1},{x^{2}} \\right]} \\right>}\"\n", "def test_latex_integral_with_trigonometric_functions():\n    assert latex(Integral(sin(x), x)) == r\"\\int \\sin{\\left (x \\right )}\\, dx\"\n    assert latex(Integral(cos(x), (x, 0, pi))) == r\"\\int_{0}^{\\pi} \\cos{\\left (x \\right )}\\, dx\"\n    assert latex(Integral(tan(x), (x, -pi/2, pi/2))) == r\"\\int_{-\\frac{\\pi}{2}}^{\\frac{\\pi}{2}} \\tan{\\left (x \\right )}\\, dx\"\n    assert latex(Integral(cot(x), (x, 0, pi))) == r\"\\int_{0}^{\\pi} \\cot{\\left (x \\right )}\\, dx\"\n    assert latex(Integral(sec(x), (x, 0, pi/3))) == r\"\\int_{0}^{\\frac{\\pi}{3}} \\sec{\\left (x \\right )}\\, dx\"\n    assert latex(Integral(csc(x), (x, pi/6, pi/2))) == r\"\\int_{\\frac{\\pi}{6}}^{\\frac{\\pi}{2}} \\csc{\\left (x \\right )}\\, dx\"\n"], "sample_44": ["def test_apply_limit_choices_to_to_formfield(self):\n    \"\"\"Test apply_limit_choices_to_to_formfield function.\"\"\"\n    from django.db import models\n    from django.forms.models import apply_limit_choices_to_to_formfield\n    \n    class TestModel(models.Model):\n        name = models.CharField(max_length=100)\n        category = models.ForeignKey(Category, on_delete=models.CASCADE, limit_choices_to={'name__icontains': 'test'})\n    \n    field = forms.ModelChoiceField(Category.objects.all())\n    formfield = TestModel._meta.get_field('category').formfield()\n    apply_limit_choices_to_to_formfield(formfield)\n    \n    self.assertEqual(list(formfield.queryset), [self.c2, self.c3])\n", "    def test_model_to_dict(self):\n        author = Author.objects.create(name='Author 1')\n        book = Book.objects.create(author=author, title='Book 1')\n        expected_dict = {\n            'author': author.pk,\n            'title': 'Book 1',\n            'id': book.pk\n        }\n        self.assertEqual(model_to_dict(book), expected_dict)\n", "    def setUpTestData(cls):\n        cls.author1 = Author.objects.create(name='Author 1')\n        cls.author2 = Author.objects.create(name='Author 2')\n        cls.author3 = Author.objects.create(name='Author 3')\n        ", "def test_modelchoicefield_custom_widget_attrs(self):\n    class CustomWidget(forms.Select):\n            option = super().create_option(name, value, label, selected, index, subindex, attrs)\n            option['attrs']['data-custom'] = 'custom-attr'\n            return option\n\n    field = forms.ModelChoiceField(Category.objects.all(), widget=CustomWidget)\n    self.assertHTMLEqual(\n        field.widget.render('name', ''),\n        '<select name=\"name\" required id=\"id_name\">'\n        '<option value=\"\" data-custom=\"custom-attr\">---------</option>'\n        '<option value=\"%d\" data-custom=\"custom-attr\">Entertainment</option>'\n        '<option value=\"%d\" data-custom=\"custom-attr\">A test</option>'\n        '<option value=\"%d\" data-custom=\"custom-attr\">Third</option>'\n        '</select>' % (self.c1.pk, self.c2.pk, self.c3.pk)\n    )\n", "    def test_custom_modelchoicefield_with_limit_choices_to(self):\n        writer1 = Writer.objects.create(name=\"Writer 1\")\n        writer2 = Writer.objects.create(name=\"Writer 2\")\n        article1 = Article.objects.create(title=\"Article 1\", writer=writer1, pub_date=datetime.date(2023, 1, 1))\n        article2 = Article.objects.create(title=\"Article 2\", writer=writer2, pub_date=datetime.date(2023, 1, 2))\n\n        class CustomModelChoiceField(forms.ModelChoiceField):\n                return {'writer': writer1}\n\n        f = CustomModelChoiceField(Article.objects.all())\n        self.assertEqual(list(f.choices), [\n            ('', '---------'),\n            (article1.pk, 'Article 1'),\n        ])\n        with self.assertRaises(ValidationError):\n            f.clean(article2.pk)\n\n        self.assertEqual(f.clean(article1.pk).title, 'Article 1')\n"], "sample_150": ["def test_solve_generic():\n    from sympy.polys import Options\n\n    gens = (x, y)\n    NewOption = Options(gens, {'domain': 'ZZ'})\n\n    # Testing simple polynomial equations\n    a = Poly(x - y + 5, x, y, domain='ZZ')\n    b = Poly(x + y - 3, x, y, domain='ZZ')\n    assert solve_generic([a, b], NewOption) == [(-1, 4)]\n\n    # Testing with more complex polynomial equations\n    a = Poly(x - 2*y + 5, x, y, domain='ZZ')\n    b = Poly(2*x - y - 3, x, y, domain='ZZ')\n    assert solve_generic([a, b], NewOption) == [(11/3, 13/3)]\n\n    # Testing polynomial equations with no real solutions\n    a = Poly(x**2 + y + 1, x, y, domain='ZZ')\n    b = Poly(x + y*4, x, y, domain='ZZ')\n    assert solve_generic([a, b], NewOption) == []\n\n    # Testing polynomial equations with multiple solutions\n    a = Poly(x**2 + y, x, y, domain='ZZ')\n    b = Poly(x + y*4, x, y, domain='ZZ')\n    assert solve_generic([a, b], NewOption) == [(0, 0), (1/4, -1/16)]\n\n    # Testing polynomial equations with a single solution\n    a = Poly(x**2 - 4*x + 4, x, y, domain='ZZ')\n    b = Poly(y - x, x, y, domain='ZZ')\n    assert solve_generic([a, b], NewOption) == [(2, 2)]\n\n    # Testing NotImplementedError for non-zero-dimensional systems\n    c = Poly(x**2 + y**2 - 1, x, y, domain='ZZ')\n    d = Poly(x + y, x, y, domain='ZZ')\n    raises(NotImplementedError, lambda: solve_generic([c, d], NewOption))\n", "def test_solve_generic():\n    a = Poly(x**2 + y**2 - 1, x, y, domain='ZZ')\n    b = Poly(x**2 - y**2 - 1, x, y, domain='ZZ')\n    assert solve_generic([a, b], parallel_poly_from_expr([a, b], x, y)[1]) == [\n        (-sqrt(2)/2, -sqrt(2)/2), (-sqrt(2)/2, sqrt(2)/2),\n        (sqrt(2)/2, -sqrt(2)/2), (sqrt(2)/2, sqrt(2)/2)\n    ]\n\n    a = Poly(x**2 + y**2 - 1, x, y, domain='ZZ')\n    b = Poly(x**2 + y**2 - 2, x, y, domain='ZZ')\n    assert solve_generic([a, b], parallel_poly_from_expr([a, b], x, y)[1]) == []\n\n    a = Poly(x**2 - y**2, x, y, domain='ZZ')\n    b = Poly(x + y - 1, x, y, domain='ZZ')\n    assert solve_generic([a, b], parallel_poly_from_expr([a, b], x, y)[1]) == [\n        (0, 1), (1, 0)\n    ]\n\n    raises(NotImplementedError, lambda: solve_generic(\n        [Poly(x**3 + y**3 - 1, x, y, domain='ZZ')], parallel_poly_from_expr(\n            [Poly(x**3 + y**3 - 1, x, y, domain='ZZ')], x, y)[1]))\n", "def test_solve_generic():\n    from sympy.polys import Options\n\n    NewOption = Options((x, y), {'domain': 'ZZ'})\n\n    a = Poly(x - y + 5, x, y, domain='ZZ')\n    b = Poly(x + y - 3, x, y, domain='ZZ')\n    assert solve_generic([a, b], NewOption) == [(-1, 4)]\n\n    a = Poly(x - 2*y + 5, x, y, domain='ZZ')\n    b = Poly(2*x - y - 3, x, y, domain='ZZ')\n    assert solve_generic([a, b], NewOption) == [(11/3, 13/3)]\n\n    a = Poly(x**2 + y, x, y, domain='ZZ')\n    b = Poly(x + y*4, x, y, domain='ZZ')\n    assert solve_generic([a, b], NewOption) == [(0, 0), (1/4, -1/16)]\n\n    c = Poly(x**2 + y**2 - 1, x, y, domain='ZZ')\n    d = Poly(x**2 - y**2 - 1, x, y, domain='ZZ')\n    assert solve_generic([c, d], NewOption) == [(-1, 0), (1, 0), (0, -1), (0, 1)]\n", "def test_solve_generic():\n    from sympy.polys.polytools import parallel_poly_from_expr\n    from sympy.polys import Options\n\n    gens = (x, y)\n    seq = [x**2 + y - 1, y**2 - x + 1]\n    (polys, opt) = parallel_poly_from_expr(seq, *gens)\n    opt = Options(gens, opt)\n    assert solve_generic(polys, opt) == [(-1, 2), (Rational(1, 2), Rational(1, 4))]\n\n    seq = [x**3 - y**3, x - y]\n    (polys, opt) = parallel_poly_from_expr(seq, *gens)\n    opt = Options(gens, opt)\n    raises(NotImplementedError, lambda: solve_generic(polys, opt))\n\n    seq = [x**2 + y**2 - 1, x**2 - y**2 - 0.5]\n    (polys, opt) = parallel_poly_from_expr(seq, *gens)\n    opt = Options(gens, opt)\n    assert solve_generic(polys, opt) == [(-sqrt(0.75), -0.5), (-sqrt(0.75), 0.5), (sqrt(0.75), -0.5), (sqrt(0.75), 0.5)]\n\n    seq = [x**2 + y**2 - 4, x**2 - y**2 - 1]\n    (polys, opt) = parallel_poly_from_expr(seq, *gens)\n    opt = Options(gens, opt)\n    assert solve_generic(polys, opt) == [(-sqrt(5)/2, -sqrt(5)/2), (-sqrt(5)/2, sqrt(5)/2), (sqrt(5)/2, -sqrt(5)/2), (sqrt(5)/2, sqrt(5)/2)]\n", "def test_solve_generic():\n    from sympy.polys.polytools import Options\n\n    opt = Options((x, y), {'domain': 'ZZ'})\n\n    # Simple case\n    a = Poly(x - y + 5, x, y, domain='ZZ')\n    b = Poly(x + y - 3, x, y, domain='ZZ')\n    assert solve_generic([a, b], opt) == [(-1, 4)]\n\n    # Slightly more complex case\n    a = Poly(x - 2*y + 5, x, y, domain='ZZ')\n    b = Poly(2*x - y - 3, x, y, domain='ZZ')\n    assert solve_generic([a, b], opt) == [(11/3, 13/3)]\n\n    # Case with zero-dimensional system\n    a = Poly(x**2 + y, x, y, domain='ZZ')\n    b = Poly(x + y*4, x, y, domain='ZZ')\n    assert solve_generic([a, b], opt) == [(0, 0), (1/4, -1/16)]\n\n    # Testing failure due to non-zero-dimensional system\n    a = Poly(x**2 + y, x, y, domain='ZZ')\n    b = Poly(x**2 + y**2 - 1, x, y, domain='ZZ')\n    raises(NotImplementedError, lambda: solve_generic([a, b], opt))\n\n    # Testing CoercionFailed exception handling\n    a = Poly(x - y + 5, x, y, domain='ZZ')\n    b = Poly(x + y - 3, x, y, domain='QQ')  # Different domain\n    raises(NotImplementedError, lambda: solve_generic([a, b], opt))\n"], "sample_84": ["def test_pyobj_property():\n    import pytest\n\n    class DummyNode:\n            self.name = name\n\n            if self.name == parent_type:\n                return self\n            return None\n\n    class DummyParent:\n        obj = \"parent object\"\n\n    @pytest.fixture\n        class Dummy:\n                self.name = name\n                self._parent = DummyNode(name)\n\n                return self._parent.getparent(parent_type)\n\n        return Dummy\n\n    parent_type = \"Parent\"\n    dummy = dummy_class()(parent_type)\n    pyobj_prop = pyobj_property(parent_type.capitalize())\n    assert pyobj_prop.fget(dummy) == \"parent object\"\n", "def test_path_matches_patterns():\n    from _pytest.pathlib import Path\n\n    # Create a dummy path object\n    path = Path(\"test_sample.py\")\n\n    # Test with a pattern that should match\n    assert path_matches_patterns(path, [\"test_*.py\"])\n\n    # Test with a pattern that should not match\n    assert not path_matches_patterns(path, [\"example_*.py\"])\n\n    # Test with multiple patterns, one of which should match\n    assert path_matches_patterns(path, [\"example_*.py\", \"test_*.py\"])\n\n    # Test with multiple patterns, none of which should match\n    assert not path_matches_patterns(path, [\"example_*.py\", \"example_2*.py\"])\n", "def test_path_matches_patterns():\n    from _pytest.pathlib import Path\n    \n    path = Path(\"tests/test_example.py\")\n    patterns = [\"test_*.py\", \"*.py\"]\n    \n    assert path_matches_patterns(path, patterns) == True\n\n    path = Path(\"tests/example_test.py\")\n    assert path_matches_patterns(path, patterns) == True\n    \n    path = Path(\"tests/example.py\")\n    assert path_matches_patterns(path, patterns) == True\n    \n    path = Path(\"tests/example_test.txt\")\n    assert path_matches_patterns(path, patterns) == False\n", "def test_pyobj_property():\n    import pytest\n\n    class MockNode:\n            self.obj = obj\n\n            return self\n\n    class MockModule:\n        pass\n\n    module = MockModule()\n    module.obj = \"test_module_obj\"\n\n    node = MockNode(module)\n\n    pyobj_prop = pyobj_property(\"Module\")\n    assert pyobj_prop.__doc__ == \"python module object this node was collected from (can be None).\"\n    assert pyobj_prop.fget(node) == \"test_module_obj\"\n", "def test_pyobj_property():\n    class MockNode:\n            return self\n\n    mock_node = MockNode()\n    mock_node.obj = \"mock_obj\"\n    property_func = pyobj_property(\"Test\")\n    assert property_func.fget(mock_node) == \"mock_obj\"\n"], "sample_134": ["def test_codegen_array_contraction():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    A = MatrixSymbol(\"A\", 2, 2)\n    B = MatrixSymbol(\"B\", 2, 2)\n    C = MatrixSymbol(\"C\", 2, 2)\n    \n    cg = CodegenArrayContraction(CodegenArrayTensorProduct(A, B, C), (1, 2), (3, 4))\n    f = lambdify((A, B, C), cg, 'numpy')\n    \n    a = np.array([[1, 2], [3, 4]])\n    b = np.array([[2, 0], [1, 2]])\n    c = np.array([[1, 1], [0, 2]])\n    \n    expected_result = np.einsum('ij,jk,kl->il', a, b, c)\n    assert np.allclose(f(a, b, c), expected_result)\n", "def test_codegen_array_diagonal():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    M = MatrixSymbol(\"M\", 3, 3)\n    N = MatrixSymbol(\"N\", 3, 3)\n    ma = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    mb = np.array([[9, 8, 7], [6, 5, 4], [3, 2, 1]])\n\n    cg = CodegenArrayDiagonal(CodegenArrayTensorProduct(M, N), (1, 2))\n    f = lambdify((M, N), cg, 'numpy')\n    assert np.array_equal(f(ma, mb), np.diagonal(np.einsum('ij,jk->ijk', ma, mb), axis1=1, axis2=2))\n", "def test_abs_function():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    from sympy import Abs\n\n    f = lambdify((a,), Abs(a), 'numpy')\n    \n    assert np.array_equal(f(np.array([-1, 0, 1, -2, 2])), np.array([1, 0, 1, 2, 2]))\n", "def test_sign_function():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    from sympy.functions.elementary.complexes import sign\n    e = sign(x)\n    f = lambdify((x,), e, 'numpy')\n\n    x_ = np.array([-2, -1, 0, 1, 2])\n    expected = np.sign(x_)\n    assert np.array_equal(f(x_), expected)\n", "def test_relational_operators():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    e = (x == 1)\n\n    f = lambdify((x,), e, 'numpy')\n    x_ = np.array([0, 1, 2])\n    assert np.array_equal(f(x_), [False, True, False])\n\n    e = (x != 1)\n\n    f = lambdify((x,), e, 'numpy')\n    x_ = np.array([0, 1, 2])\n    assert np.array_equal(f(x_), [True, False, True])\n\n    e = (x < 1)\n\n    f = lambdify((x,), e, 'numpy')\n    x_ = np.array([0, 1, 2])\n    assert np.array_equal(f(x_), [True, False, False])\n\n    e = (x <= 1)\n\n    f = lambdify((x,), e, 'numpy')\n    x_ = np.array([0, 1, 2])\n    assert np.array_equal(f(x_), [True, True, False])\n\n    e = (x > 1)\n\n    f = lambdify((x,), e, 'numpy')\n    x_ = np.array([0, 1, 2])\n    assert np.array_equal(f(x_), [False, False, True])\n\n    e = (x >= 1)\n\n    f = lambdify((x,), e, 'numpy')\n    x_ = np.array([0, 1, 2])\n    assert np.array_equal(f(x_), [False, True, True])\n"], "sample_60": ["    def test_serialize_function_type_bound_method(self):\n        \"\"\"\n        Test serialization of a bound method.\n        \"\"\"\n        instance = TestModel1()\n        bound_method = instance.upload_to\n        with self.assertRaisesMessage(ValueError, \"Could not find function upload_to in\"):\n            self.serialize_round_trip(bound_method)\n", "    def test_serialize_function_type_serializer(self):\n            pass\n\n        module_name = sample_function.__module__\n\n        # Test with regular function\n        result = serializer_factory(sample_function).serialize()\n        self.assertEqual(\n            result,\n            (\"%s.sample_function\" % module_name, {\"import %s\" % module_name}),\n        )\n\n        # Test with method of a class\n        class TestClass:\n                pass\n\n        method_result = serializer_factory(TestClass.method).serialize()\n        self.assertEqual(\n            method_result,\n            (\"%s.TestClass.method\" % module_name, {\"import %s\" % module_name}),\n        )\n\n        # Test with lambda (should raise ValueError)\n        with self.assertRaisesMessage(ValueError, \"Cannot serialize function: lambda\"):\n            serializer_factory(lambda x: x).serialize()\n\n        # Test with function with no module (should raise ValueError)\n        sample_function.__module__ = None\n        with self.assertRaisesMessage(\n            ValueError, \"Cannot serialize function %r: No module\" % sample_function\n        ):\n            serializer_factory(sample_function).serialize()\n        sample_function.__module__ = module_name  # Restore module name\n", "    def test_serialize_dictionary(self):\n        value = {\"a\": 1, \"b\": 2.3, \"c\": [1, 2, 3], \"d\": {\"nested\": \"dict\"}}\n        self.assertSerializedEqual(value)\n        self.assertSerializedResultEqual(\n            value,\n            (\n                \"{'a': 1, 'b': 2.3, 'c': [1, 2, 3], 'd': {'nested': 'dict'}}\",\n                set(),\n            ),\n        )\n", "    def test_serialize_model_field(self):\n        field = models.IntegerField(default=0, null=False, blank=True)\n        string = MigrationWriter.serialize(field)[0]\n        self.assertEqual(\n            string,\n            \"models.IntegerField(blank=True, default=0)\",\n        )\n        self.serialize_round_trip(field)\n", "    def test_serialize_functools_partial_with_kwargs(self):\n        value = functools.partial(int, base=2)\n        result = self.serialize_round_trip(value)\n        self.assertEqual(result.func, value.func)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n"], "sample_145": ["def test_latex_symbols_with_subs_and_supers():\n    assert latex(Symbol('alpha_1^2')) == r'\\alpha_{1}^{2}'\n    assert latex(Symbol('beta_a_b_c')) == r'\\beta_{a b c}'\n    assert latex(Symbol('gamma^i_j')) == r'\\gamma^{i}_{j}'\n    assert latex(Symbol('delta__1__2')) == r'\\delta^{2}_{1}'\n    assert latex(Symbol('epsilon_xyz_123')) == r'\\epsilon_{xyz 123}'\n    assert latex(Symbol('theta_i__j^k')) == r'\\theta_{i j}^{k}'\n", "def test_latex_escape_special_characters():\n    assert latex_escape(r'3&4%5$6#7_8{9}0~^') == r'3\\&4\\%5\\$6\\#7\\_8\\{9\\}0\\textasciitilde\\textasciicircum'\n    assert latex_escape('text_normal') == r'text\\_normal'\n    assert latex_escape('text$money') == r'text\\$money'\n    assert latex_escape(r'\\backslash') == r'\\textbackslashbackslash'\n", "def test_LatexPrinter_invalid_mode():\n    with raises(ValueError):\n        LatexPrinter({'mode': 'invalid_mode'})\n", "def test_latex_LatexPrinter():\n    # Test initialization of LatexPrinter with various settings\n    settings = {\n        \"fold_func_brackets\": True,\n        \"fold_frac_powers\": True,\n        \"itex\": True,\n        \"mul_symbol\": \"times\",\n        \"ln_notation\": True,\n        \"long_frac_ratio\": 1.5,\n        \"symbol_names\": {x: \"x_i\", y: \"y_j\"},\n        \"mode\": \"equation*\",\n        \"gothic_re_im\": True,\n    }\n    lp = LatexPrinter(settings)\n    assert lp._settings[\"fold_func_brackets\"] is True\n    assert lp._settings[\"fold_frac_powers\"] is True\n    assert lp._settings[\"itex\"] is True\n    assert lp._settings[\"mul_symbol\"] == \"times\"\n    assert lp._settings[\"ln_notation\"] is True\n    assert lp._settings[\"long_frac_ratio\"] == 1.5\n    assert lp._settings[\"symbol_names\"] == {x: \"x_i\", y: \"y_j\"}\n    assert lp._settings[\"mode\"] == \"equation*\"\n    assert lp._settings[\"gothic_re_im\"] is True\n\n    # Test initialization with invalid settings\n    with raises(ValueError):\n        LatexPrinter({\"mode\": \"invalid_mode\"})\n    with raises(KeyError):\n        LatexPrinter({\"mul_symbol\": \"invalid_symbol\"})\n\n    # Test handling of different modes\n    expr = x + y\n    assert lp.doprint(expr) == r\"\\begin{equation*}x_i + y_j\\end{equation*}\"\n    lp._settings[\"mode\"] = \"inline\"\n    assert lp.doprint(expr) == r\"$x_i + y_j$\"\n    lp._settings[\"mode\"] = \"plain\"\n    assert lp.doprint(expr) == r\"x_i + y_j\"\n\n    # Test handling of different multiplication symbols\n    lp._settings[\"mul_symbol\"] = \"ldot\"\n    assert lp.doprint(x * y) == r\"x_i \\,.\\, y_j\"\n    lp._settings[\"mul_symbol\"] = \"dot\"\n    assert lp.doprint(x * y) == r\"x_i \\cdot y_j\"\n    lp._settings[\"mul_symbol\"] = \"times\"\n    assert lp.doprint(x * y) == r\"x_i \\times y_j\"\n\n    # Test handling of different", "def test_latex_CustomFunctions():\n    class MyFunc(Function):\n            return r'\\operatorname{MyFunc}{\\left(%s\\right)}' % printer._print(self.args[0])\n    \n    f = MyFunc(x)\n    assert latex(f) == r'\\operatorname{MyFunc}{\\left(x\\right)}'\n    assert latex(f**2) == r'\\left(\\operatorname{MyFunc}{\\left(x\\right)}\\right)^{2}'\n    assert latex(f + MyFunc(y)) == r'\\operatorname{MyFunc}{\\left(x\\right)} + \\operatorname{MyFunc}{\\left(y\\right)}'\n"], "sample_10": ["    def test_year_lookup(self):\n        # Test YearExact lookup\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__exact=2005),\n            [\n                '<Article: Article 1>',\n                '<Article: Article 2>',\n                '<Article: Article 3>',\n                '<Article: Article 4>',\n                '<Article: Article 6>',\n                '<Article: Article 7>',\n                '<Article: Article 5>',\n            ],\n            ordered=False\n        )\n        \n        # Test YearGt lookup\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gt=2004),\n            [\n                '<Article: Article 1>',\n                '<Article: Article 2>',\n                '<Article: Article 3>',\n                '<Article: Article 4>',\n                '<Article: Article 6>',\n                '<Article: Article 7>',\n                '<Article: Article 5>',\n            ],\n            ordered=False\n        )\n        \n        # Test YearGte lookup\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gte=2005),\n            [\n                '<Article: Article 1>',\n                '<Article: Article 2>',\n                '<Article: Article 3>',\n                '<Article: Article 4>',\n                '<Article: Article 6>',\n                '<Article: Article 7>',\n                '<Article: Article 5>',\n            ],\n            ordered=False\n        )\n        \n        # Test YearLt lookup\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lt=2006),\n            [\n                '<Article: Article 1>',\n                '<Article: Article 2>',\n                '<Article: Article 3>',\n                '<Article: Article 4>',\n                '<Article: Article 6>',\n                '<Article: Article 7>',\n                '<Article: Article 5>',\n            ],\n            ordered=False\n        )\n        \n        # Test YearLte lookup\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lte=2005),\n            [\n                '<Article: Article 1>',\n                '<Article: Article 2>',\n                '<Article: Article 3>',\n                '<Article: Article 4>',\n                '<Article: Article 6>',\n                '<Article: Article 7>',\n                '<Article: Article 5>',\n            ],\n            ordered=False\n        )\n", "    def test_year_lookup(self):\n        # Test Year lookup operations on DateTimeField\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year=2005),\n            [\n                '<Article: Article 1>',\n                '<Article: Article 2>',\n                '<Article: Article 3>',\n                '<Article: Article 4>',\n                '<Article: Article 5>',\n                '<Article: Article 6>',\n                '<Article: Article 7>',\n            ],\n            ordered=False\n        )\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__exact=2005),\n            [\n                '<Article: Article 1>',\n                '<Article: Article 2>',\n                '<Article: Article 3>',\n                '<Article: Article 4>',\n                '<Article: Article 5>',\n                '<Article: Article 6>',\n                '<Article: Article 7>',\n            ],\n            ordered=False\n        )\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gt=2004),\n            [\n                '<Article: Article 1>',\n                '<Article: Article 2>',\n                '<Article: Article 3>',\n                '<Article: Article 4>',\n                '<Article: Article 5>',\n                '<Article: Article 6>',\n                '<Article: Article 7>',\n            ],\n            ordered=False\n        )\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gte=2005),\n            [\n                '<Article: Article 1>',\n                '<Article: Article 2>',\n                '<Article: Article 3>',\n                '<Article: Article 4>',\n                '<Article: Article 5>',\n                '<Article: Article 6>',\n                '<Article: Article 7>',\n            ],\n            ordered=False\n        )\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lt=2006),\n            [\n                '<Article: Article 1>',\n                '<Article: Article 2>',\n                '<Article: Article 3>',\n                '<Article: Article 4>',\n                '<Article: Article 5>',\n                '<Article: Article 6>',\n                '<Article: Article 7>',\n            ],\n            ordered=False\n        )\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lte=2005),\n            [\n                '<Article: Article 1>',\n                '<Article: Article 2>',\n                '<Article: Article 3>',\n                '<Article: Article 4>',\n                '<Article", "    def test_year_lookups(self):\n        # Create some articles with specific pub_dates for testing year lookups\n        now = datetime.now()\n        articles = [\n            Article.objects.create(headline=f'Article {i}', pub_date=datetime(2010 + i, 1, 1))\n            for i in range(5)\n        ]\n        \n        # Test YearExact lookup\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year=2012),\n            [f'<Article: Article 2>']\n        )\n\n        # Test YearGt lookup\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gt=2012),\n            [f'<Article: Article 3>', f'<Article: Article 4>'],\n            ordered=False\n        )\n\n        # Test YearGte lookup\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gte=2012),\n            [f'<Article: Article 2>', f'<Article: Article 3>', f'<Article: Article 4>'],\n            ordered=False\n        )\n\n        # Test YearLt lookup\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lt=2012),\n            [f'<Article: Article 0>', f'<Article: Article 1>'],\n            ordered=False\n        )\n\n        # Test YearLte lookup\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lte=2012),\n            [f'<Article: Article 0>', f'<Article: Article 1>', f'<Article: Article 2>'],\n            ordered=False\n        )\n", "    def test_year_lookup(self):\n        # Ensure YearLookup based queries work as expected.\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year=2005),\n            [\n                '<Article: Article 1>',\n                '<Article: Article 2>',\n                '<Article: Article 3>',\n                '<Article: Article 4>',\n                '<Article: Article 5>',\n                '<Article: Article 6>',\n                '<Article: Article 7>',\n            ],\n            ordered=False\n        )\n\n        # Test YearGt (greater than)\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gt=2005),\n            [],\n            ordered=False\n        )\n\n        # Test YearGte (greater than or equal)\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gte=2005),\n            [\n                '<Article: Article 1>',\n                '<Article: Article 2>',\n                '<Article: Article 3>',\n                '<Article: Article 4>',\n                '<Article: Article 5>',\n                '<Article: Article 6>',\n                '<Article: Article 7>',\n            ],\n            ordered=False\n        )\n\n        # Test YearLt (less than)\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lt=2005),\n            [],\n            ordered=False\n        )\n\n        # Test YearLte (less than or equal)\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lte=2005),\n            [\n                '<Article: Article 1>',\n                '<Article: Article 2>',\n                '<Article: Article 3>',\n                '<Article: Article 4>',\n                '<Article: Article 5>',\n                '<Article: Article 6>',\n                '<Article: Article 7>',\n            ],\n            ordered=False\n        )\n\n        # Test YearExact\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__exact=2005),\n            [\n                '<Article: Article 1>',\n                '<Article: Article 2>',\n                '<Article: Article 3>',\n                '<Article: Article 4>',\n                '<Article: Article 5>',\n                '<Article: Article 6>',\n                '<Article: Article 7>',\n            ],\n            ordered=False\n        )\n", "    def test_year_lookups(self):\n        # Create some articles with specific publish dates to test year lookups.\n        Article.objects.create(headline='Article 8', pub_date=datetime(2008, 1, 15), author=self.au1, slug='a8')\n        Article.objects.create(headline='Article 9', pub_date=datetime(2009, 2, 20), author=self.au1, slug='a9')\n        Article.objects.create(headline='Article 10', pub_date=datetime(2010, 3, 25), author=self.au1, slug='a10')\n\n        # Test YearExact lookup.\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__exact=2009),\n            ['<Article: Article 9>']\n        )\n\n        # Test YearGt lookup.\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gt=2008),\n            ['<Article: Article 9>', '<Article: Article 10>'],\n            ordered=False\n        )\n\n        # Test YearGte lookup.\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gte=2009),\n            ['<Article: Article 9>', '<Article: Article 10>'],\n            ordered=False\n        )\n\n        # Test YearLt lookup.\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lt=2010),\n            ['<Article: Article 8>', '<Article: Article 9>'],\n            ordered=False\n        )\n\n        # Test YearLte lookup.\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lte=2009),\n            ['<Article: Article 8>', '<Article: Article 9>'],\n            ordered=False\n        )\n"], "sample_9": ["    def test_enable_echo(self, mock_tcsetattr, mock_tcgetattr, mock_isatty):\n        # Setup termios to return attributes without ECHO enabled\n        attrs = [0, 0, 0, 0]\n        mock_tcgetattr.return_value = attrs\n\n        autoreload.ensure_echo_on()\n\n        self.assertTrue(attrs[3] & autoreload.termios.ECHO)\n        mock_tcsetattr.assert_called_once_with(sys.stdin, autoreload.termios.TCSANOW, attrs)\n", "    def test_ensure_echo_on_termios_not_imported(self, mocked_stdin, mocked_termios):\n        mocked_termios.return_value = None\n        autoreload.ensure_echo_on()\n        mocked_stdin.isatty.assert_not_called()\n", "    def test_ensure_echo_on_no_termios(self, mock_stdin, mock_termios):\n        mock_termios = None\n        autoreload.ensure_echo_on()\n        mock_stdin.isatty.assert_not_called()\n", "    def setUp(self):\n        self._tempdir = tempfile.TemporaryDirectory()\n        self.tempdir = Path(self._tempdir.name).resolve().absolute()\n", "    def test_trigger_reload(self, mock_exit, mock_logger_info):\n        filename = 'changed_file.py'\n        autoreload.trigger_reload(filename)\n        mock_logger_info.assert_called_once_with('%s changed, reloading.', filename)\n        mock_exit.assert_called_once_with(3)\n"], "sample_53": ["def test_rename_index_together_to_index_with_deps(self):\n    \"\"\"\n    Test renaming index_together to index with dependencies on other apps.\n    \"\"\"\n    before = [\n        self.author_empty,\n        self.book_foo_together,\n        ModelState(\n            \"anotherapp\",\n            \"Store\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"book\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n            ],\n        ),\n    ]\n    after = [\n        self.author_empty,\n        self.book_indexes,\n        ModelState(\n            \"anotherapp\",\n            \"Store\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"book\", models.ForeignKey(\"otherapp.Book\", models.CASCADE)),\n            ],\n        ),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(\n        changes, \"otherapp\", 0, [\"RenameIndex\", \"AlterUniqueTogether\"]\n    )\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        0,\n        model_name=\"book\",\n        new_name=\"book_title_author_idx\",\n        old_fields=(\"author\", \"title\"),\n    )\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        1,\n        name=\"book\",\n        unique_together=set(),\n    )\n    # Ensure anotherapp migration is not affected\n    self.assertNumberMigrations(changes, \"anotherapp\", 0)\n", "    def test_generate_removed_fields(self):\n        \"\"\"Tests the generation of RemoveField operations.\"\"\"\n        # Test removing a single field\n        changes = self.get_changes([self.author_name], [self.author_empty])\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertOperationTypes(changes, \"testapp\", 0, [\"RemoveField\"])\n        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n\n        # Test removing multiple fields\n        before_state = ModelState(\n            \"testapp\",\n            \"Author\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=200)),\n                (\"age\", models.IntegerField()),\n            ],\n        )\n        after_state = ModelState(\n            \"testapp\",\n            \"Author\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n            ],\n        )\n        changes = self.get_changes([before_state], [after_state])\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertOperationTypes(changes, \"testapp\", 0, [\"RemoveField\", \"RemoveField\"])\n        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n        self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"age\")\n", "def test_alter_field_and_constraint_together(self):\n    \"\"\"\n    Test that altering a field and adding/removing a constraint together\n    creates the operations in the correct order.\n    \"\"\"\n    before = [\n        ModelState(\n            \"testapp\",\n            \"Author\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=200)),\n            ],\n        )\n    ]\n    after = [\n        ModelState(\n            \"testapp\",\n            \"Author\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=300)),\n            ],\n            {\n                \"constraints\": [\n                    models.CheckConstraint(\n                        check=models.Q(name__contains=\"Ada\"), name=\"name_contains_ada\"\n                    )\n                ]\n            },\n        )\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(\n        changes, \"testapp\", 0, [\"AlterField\", \"AddConstraint\"]\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, name=\"name\"\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 1, model_name=\"author\", constraint=models.CheckConstraint(\n            check=models.Q(name__contains=\"Ada\"), name=\"name_contains_ada\"\n        )\n    )\n", "    def test_deep_deconstruct_model_field(self):\n        \"\"\"\n        Tests deep deconstruction of model fields with nested deconstructible objects.\n        \"\"\"\n        class CustomObject:\n                self.value = value\n\n                return (self.__module__ + \".\" + self.__class__.__name__, [self.value], {})\n\n        initial_state = ModelState(\n            \"testapp\",\n            \"Author\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=200, default=CustomObject(1))),\n            ],\n        )\n        changed_state = ModelState(\n            \"testapp\",\n            \"Author\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=200, default=CustomObject(2))),\n            ],\n        )\n        changes = self.get_changes([initial_state], [changed_state])\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n", "    def test_foreignkey_to_self(self):\n        \"\"\"\n        Tests autodetection of models with ForeignKey to self.\n        \"\"\"\n        before = [\n            ModelState(\n                \"testapp\",\n                \"Category\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\"parent\", models.ForeignKey(\"self\", models.CASCADE, null=True, blank=True)),\n                ],\n            ),\n        ]\n        after = [\n            ModelState(\n                \"testapp\",\n                \"Category\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\"parent\", models.ForeignKey(\"self\", models.CASCADE, null=True, blank=True)),\n                    (\"name\", models.CharField(max_length=200)),\n                ],\n            ),\n        ]\n        changes = self.get_changes(before, after)\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertOperationTypes(changes, \"testapp\", 0, [\"AddField\"])\n        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n"], "sample_146": ["def test_Predicate():\n    p = Predicate('is_prime')\n    assert str(p) == 'Q.is_prime'\n", "def test_Complexes():\n    assert str(S.Complexes) == \"Complexes\"\n    assert str(S.Reals) == \"Reals\"\n    assert str(S.Rationals) == \"Rationals\"\n    assert str(S.Integers) == \"Integers\"\n    assert str(S.Naturals) == \"Naturals\"\n    assert str(S.Naturals0) == \"Naturals0\"\n", "def test_Exp_printing():\n    assert str(exp(x + y)) == \"exp(x + y)\"\n    assert str(exp(x * y)) == \"exp(x*y)\"\n    assert str(exp(-x)) == \"exp(-x)\"\n    assert str(exp(x / y)) == \"exp(x/y)\"\n    assert str(exp(sin(x))) == \"exp(sin(x))\"\n", "def test_BlockMatrix():\n    from sympy import BlockMatrix, Matrix\n    A = Matrix([[1, 2], [3, 4]])\n    B = Matrix([[5, 6], [7, 8]])\n    C = Matrix([[9, 10], [11, 12]])\n    D = Matrix([[13, 14], [15, 16]])\n    BM = BlockMatrix([[A, B], [C, D]])\n    assert str(BM) == \"Matrix([[1, 2, 5, 6], [3, 4, 7, 8], [9, 10, 13, 14], [11, 12, 15, 16]])\"\n", "def test_BlockMatrix():\n    from sympy.matrices.expressions.blockmatrix import BlockMatrix, BlockDiagMatrix, MatrixSymbol\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    D = MatrixSymbol('D', 2, 2)\n    BM = BlockMatrix([[A, B], [C, D]])\n    assert str(BM) == 'Matrix([[A, B], [C, D]])'\n    \n    BDM = BlockDiagMatrix(A, B)\n    assert str(BDM) == 'Matrix([[A, 0], [0, B]])'\n"], "sample_8": ["    def test_cleanse_setting_callable(self):\n            return \"Sensitive Data\"\n\n        cleansed = cleanse_setting('API_KEY', sensitive_callable)\n        self.assertIsInstance(cleansed, CallableSettingWrapper)\n        self.assertEqual(repr(cleansed), repr(sensitive_callable))\n", "    def setUp(self):\n        self.rf = RequestFactory()\n", "    def test_sensitive_variables_in_traceback(self):\n        \"\"\"\n        Sensitive variables should not be shown in the traceback frame variables.\n        \"\"\"\n        try:\n            request = self.rf.get('/test_view/')\n            request.user = User()\n            sensitive_value = 'super_secret'\n            raise ValueError(\"Sensitive error\")\n        except ValueError:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        html = reporter.get_traceback_html()\n        self.assertNotIn(sensitive_value, html)\n        self.assertIn('super_secret', CLEANSED_SUBSTITUTE)\n", "    def setUp(self):\n        self.filter = SafeExceptionReporterFilter()\n        self.request = RequestFactory().post('/some_url/', data={\n            'non_sensitive_key': 'non_sensitive_value',\n            'sensitive_key': 'sensitive_value',\n        })\n        self.request.sensitive_post_parameters = ['sensitive_key']\n", "    def test_get_post_parameters_cleanse_all(self):\n        \"\"\"\n        Test that all POST parameters are cleansed when `sensitive_post_parameters`\n        is set to '__ALL__' and the filter is active.\n        \"\"\"\n        request = RequestFactory().post('/some_url/', data={\n            'username': 'admin',\n            'password': 'super_secret',\n        })\n        request.sensitive_post_parameters = '__ALL__'\n        filter = SafeExceptionReporterFilter()\n        cleansed_params = filter.get_post_parameters(request)\n        self.assertEqual(cleansed_params['username'], CLEANSED_SUBSTITUTE)\n        self.assertEqual(cleansed_params['password'], CLEANSED_SUBSTITUTE)\n"], "sample_133": ["def test_rust_codegen():\n    x, y, z = symbols('x,y,z')\n    expr = (x + y)*z\n    routine = make_routine(\"test_rust\", expr)\n    code_gen = RustCodeGen()\n    source = get_string(code_gen.dump_rs, [routine])\n    expected = (\n        \"fn test_rust(x: f64, y: f64, z: f64) -> f64 {\\n\"\n        \"    let test_rust_result = (x + y) * z;\\n\"\n        \"    test_rust_result\\n\"\n        \"}\\n\"\n    )\n    assert source == expected\n", "def test_simple_rust_code():\n    x, y, z = symbols('x,y,z')\n    expr = (x + y)*z\n    routine = make_routine(\"test\", expr)\n    code_gen = RustCodeGen()\n    source = get_string(code_gen.dump_rs, [routine])\n    expected = (\n        \"fn test(x: f64, y: f64, z: f64) -> f64 {\\n\"\n        \"   let test_result = z*(x + y);\\n\"\n        \"   test_result\\n\"\n        \"}\\n\"\n    )\n    assert source == expected\n", "def test_rust_simple_code():\n    x, y, z = symbols('x,y,z')\n    expr = (x + y)*z\n    routine = make_routine(\"test\", expr)\n    code_gen = RustCodeGen()\n    source = get_string(code_gen.dump_rs, [routine])\n    expected = (\n        \"fn test(x: f64, y: f64, z: f64) -> f64 {\\n\"\n        \"   let test_result = z * (x + y);\\n\"\n        \"   test_result\\n\"\n        \"}\\n\"\n    )\n    assert source == expected\n", "def test_julia_codegen():\n    x, y, z = symbols('x,y,z')\n    expr = (x + y) * z\n    expected = [\n        (\"file.jl\",\n        \"#   Code generated with sympy %s\\n\"\n        \"#\\n\"\n        \"#   See http://www.sympy.org/ for more information.\\n\"\n        \"#\\n\"\n        \"#   This file is part of 'project'\\n\"\n        \"#\\n\"\n        \"function test(x, y, z)\\n\"\n        \"    test_result = z * (x + y)\\n\"\n        \"    return test_result\\n\"\n        \"end\\n\" % sympy_version)\n    ]\n    result = codegen((\"test\", expr), \"julia\", \"file\", header=True, empty=True)\n    assert result == expected\n", "def test_rust_codegen():\n    x, y, z = symbols('x y z')\n    expr = (x + y)*z\n    routine = make_routine(\"test\", expr)\n    code_gen = RustCodeGen()\n    source = get_string(code_gen.dump_rs, [routine])\n    expected = (\n        \"fn test(x: f64, y: f64, z: f64) -> f64 {\\n\"\n        \"    let test_result;\\n\"\n        \"    test_result = z * (x + y);\\n\"\n        \"    test_result\\n\"\n        \"}\\n\"\n    )\n    assert source == expected\n"], "sample_105": ["def test_predict_with_empty_estimators():\n    \"\"\"Test VotingClassifier with empty estimators list.\"\"\"\n    eclf = VotingClassifier(estimators=[])\n    with pytest.raises(AttributeError, match='Invalid `estimators` attribute'):\n        eclf.fit(X, y)\n", "def test_voting_regressor_predict():\n    \"\"\"Test the predict function of VotingRegressor.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(n_estimators=10, random_state=1)\n    reg3 = DummyRegressor(strategy='mean')\n    \n    X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n    y = np.array([2, 3, 4, 5])\n    \n    ereg = VotingRegressor(estimators=[('lr', reg1), ('rf', reg2), ('dr', reg3)])\n    ereg.fit(X, y)\n    pred = ereg.predict(X)\n    \n    # Check if the shape of prediction is correct\n    assert pred.shape == y.shape\n    \n    # Check if the prediction is close to the expected output\n    expected_pred = np.array([2.17617417, 3.14637061, 4.11656706, 5.08676350])\n    assert_almost_equal(pred, expected_pred, decimal=2)\n", "compilation error", "def test_voting_regressor_transform():\n    \"\"\"Check transform method of VotingRegressor on toy dataset.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(n_estimators=5, random_state=123)\n    X = np.array([[1, 1], [2, 4], [3, 9], [4, 16], [5, 25], [6, 36]])\n    y = np.array([2, 6, 12, 20, 30, 42])\n\n    ereg = VotingRegressor(estimators=[('lr', reg1), ('rf', reg2)])\n    ereg.fit(X, y)\n\n    transform_output = ereg.transform(X)\n    assert transform_output.shape == (6, 2)\n    assert_array_almost_equal(transform_output[:, 0], reg1.predict(X), decimal=2)\n    assert_array_almost_equal(transform_output[:, 1], reg2.predict(X), decimal=2)\n", "def test_voting_regressor_predict():\n    \"\"\"Check predictions of VotingRegressor on toy dataset.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(n_estimators=10, random_state=1)\n    reg3 = DummyRegressor(strategy='mean')\n\n    X = np.array([[1, 1], [2, 2], [3, 3], [4, 4], [5, 5]])\n    y = np.array([1, 2, 3, 4, 5])\n\n    ereg = VotingRegressor(estimators=[('lr', reg1), ('rf', reg2), ('dummy', reg3)])\n    ereg.fit(X, y)\n    y_pred = ereg.predict(X)\n\n    reg1_pred = reg1.predict(X)\n    reg2_pred = reg2.predict(X)\n    reg3_pred = reg3.predict(X)\n    avg_pred = np.mean(np.vstack([reg1_pred, reg2_pred, reg3_pred]), axis=0)\n\n    assert_array_almost_equal(y_pred, avg_pred, decimal=2)\n\n    # Check with non-uniform weights\n    ereg = VotingRegressor(estimators=[('lr', reg1), ('rf', reg2), ('dummy', reg3)],\n                           weights=[1, 2, 0.5])\n    ereg.fit(X, y)\n    y_pred_weighted = ereg.predict(X)\n\n    avg_pred_weighted = np.average(np.vstack([reg1_pred, reg2_pred, reg3_pred]),\n                                   axis=0, weights=[1, 2, 0.5])\n\n    assert_array_almost_equal(y_pred_weighted, avg_pred_weighted, decimal=2)\n"], "sample_59": ["    def test_management_form_clean_defaults(self):\n        \"\"\"\n        Test that the ManagementForm.clean() method sets default values for\n        TOTAL_FORMS and INITIAL_FORMS when they are missing or invalid.\n        \"\"\"\n        class CustomManagementForm(ManagementForm):\n                cleaned_data = super().clean()\n                # Custom logic can be added here\n                return cleaned_data\n\n        form = CustomManagementForm(\n            data={\n                \"TOTAL_FORMS\": \"invalid\",\n                \"INITIAL_FORMS\": \"invalid\",\n            }\n        )\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.cleaned_data[TOTAL_FORM_COUNT], 0)\n        self.assertEqual(form.cleaned_data[INITIAL_FORM_COUNT], 0)\n", "    def test_management_form_clean_default_values(self):\n        \"\"\"\n        Test if ManagementForm's clean method sets default values for\n        TOTAL_FORMS and INITIAL_FORMS correctly when they are missing in the cleaned_data.\n        \"\"\"\n        form = ManagementForm()\n        cleaned_data = form.clean()\n        self.assertEqual(cleaned_data[TOTAL_FORM_COUNT], 0)\n        self.assertEqual(cleaned_data[INITIAL_FORM_COUNT], 0)\n", "    def test_validate_max_with_deleted_forms(self):\n        \"\"\"\n        validate_max correctly handles forms marked for deletion.\n        \"\"\"\n        data = {\n            \"choices-TOTAL_FORMS\": \"3\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-MAX_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Choice 1\",\n            \"choices-0-votes\": \"10\",\n            \"choices-0-DELETE\": \"\",\n            \"choices-1-choice\": \"Choice 2\",\n            \"choices-1-votes\": \"20\",\n            \"choices-1-DELETE\": \"on\",\n            \"choices-2-choice\": \"Choice 3\",\n            \"choices-2-votes\": \"30\",\n            \"choices-2-DELETE\": \"\",\n        }\n        ChoiceFormSet = formset_factory(Choice, extra=2, max_num=2, validate_max=True, can_delete=True)\n        formset = ChoiceFormSet(data, prefix=\"choices\")\n        self.assertTrue(formset.is_valid())\n        self.assertEqual(\n            [form.cleaned_data for form in formset.deleted_forms],\n            [{\"votes\": 20, \"DELETE\": True, \"choice\": \"Choice 2\"}],\n        )\n        self.assertEqual(\n            [form.cleaned_data for form in formset.forms if not form.cleaned_data.get(\"DELETE\", False)],\n            [{\"votes\": 10, \"DELETE\": False, \"choice\": \"Choice 1\"}, {\"votes\": 30, \"DELETE\": False, \"choice\": \"Choice 3\"}],\n        )\n", "    def test_custom_clean_method(self):\n        \"\"\"\n        A FormSet with a custom clean method should raise errors defined in that method.\n        \"\"\"\n\n        class CustomCleanForm(Form):\n            field = CharField()\n\n        class CustomCleanFormSet(BaseFormSet):\n                super().clean()\n                if any(form.cleaned_data.get('field') == 'invalid' for form in self.forms):\n                    raise ValidationError(\"Custom clean method error\")\n\n        CustomCleanFormSet = formset_factory(CustomCleanForm, formset=CustomCleanFormSet)\n        data = {\n            \"form-TOTAL_FORMS\": \"2\",\n            \"form-INITIAL_FORMS\": \"0\",\n            \"form-MIN_NUM_FORMS\": \"0\",\n            \"form-0-field\": \"valid\",\n            \"form-1-field\": \"invalid\",\n        }\n        formset = CustomCleanFormSet(data, auto_id=False, prefix=\"form\")\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(formset.non_form_errors(), [\"Custom clean method error\"])\n\n        # Valid case\n        data[\"form-1-field\"] = \"valid\"\n        formset = CustomCleanFormSet(data, auto_id=False, prefix=\"form\")\n        self.assertTrue(formset.is_valid())\n        self.assertEqual(formset.non_form_errors(), [])\n", "    def test_formset_with_custom_deletion_widget(self):\n        \"\"\"Test formset with custom deletion widget rendering.\"\"\"\n\n        class CustomDeletionWidgetFormSet(BaseFormSet):\n                return HiddenInput(attrs={\"class\": \"custom-deletion\"})\n\n        CustomFormSet = formset_factory(Choice, formset=CustomDeletionWidgetFormSet, can_delete=True)\n        \n        formset = CustomFormSet(auto_id=False, prefix=\"choices\")\n        self.assertHTMLEqual(\n            \"\\n\".join(form.as_ul() for form in formset.forms),\n            \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\"></li>"], "sample_123": ["def test_mpf_norm_zero():\n    assert mpf_norm((1, 0, 0, 0), 10) == mpf('0')._mpf_\n    assert Float._new((1, 0, 0, 0), 10)._mpf_ == mpf('0')._mpf_\n", "def test_mpf_norm_exceptions():\n    from mpmath.libmp.backend import MPZ\n    from mpmath.libmp.libmpf import fnan, finf, fninf\n\n    # Test with mantissa as zero and bc as non-zero\n    assert mpf_norm((0, 0, 0, 1), 10) == (0, 0, 0, 0)  # zero case\n\n    # Test with mantissa as non-zero\n    assert mpf_norm((0, 12345, 0, 5), 10) == (0, MPZ(12345), 0, 5)\n\n    # Test with mantissa zero but bc non-zero to ensure non-zero preservation\n    assert mpf_norm((0, 0, 0, 3), 10) == (0, 0, 0, 3)\n\n    # Test with special values (inf, -inf, nan)\n    assert mpf_norm(finf, 10) == finf\n    assert mpf_norm(fninf, 10) == fninf\n    assert mpf_norm(fnan, 10) == fnan\n\n    # Test normalizing tuple with negative exponent and large mantissa\n    assert mpf_norm((0, 56789, -3, 10), 10) == (0, MPZ(56789), -3, 10)\n\n    # Test with other edge cases\n    assert mpf_norm((1, 0, 0, 0), 10) == (0, 0, 0, 0)\n    assert mpf_norm((0, 0, -9999, 0), 10) == (0, 0, 0, 0)\n", "def test_mod_inverse_errors():\n    # Test invalid inputs for mod_inverse\n    raises(ValueError, lambda: mod_inverse(2, 0))  # modulus cannot be zero\n    raises(ValueError, lambda: mod_inverse(2, 4))  # 2 and 4 are not coprime, so no inverse exists\n    raises(ValueError, lambda: mod_inverse(1, 1))  # gcd(1, 1) != 1, so no inverse exists\n    raises(TypeError, lambda: mod_inverse(1.5, 5))  # non-integer inputs should raise TypeError\n    raises(ValueError, lambda: mod_inverse(5, 1.5))  # non-integer modulus should raise ValueError\n", "def test_mpf_to_float():\n    # Test conversion of mpmath mpf to Float\n    assert Float(mpf('3.141592653589793')) == Float(pi)\n    assert Float(mpf('2.718281828459045')) == Float(E)\n    assert Float(mpf('-1.618033988749895')) == Float(-GoldenRatio)\n\n    # Test conversion with specified precision\n    assert Float(mpf('1.4142135623730951'), precision=30) == Float(sqrt(2), precision=30)\n    assert Float(mpf('0.5772156649015329'), precision=20) == Float(EulerGamma, precision=20)\n    assert Float(mpf('0.915965594177219'), precision=15) == Float(Catalan, precision=15)\n\n    # Test conversion of irrational numbers\n    assert Float(mpf('3.14159265358979323846264338327950288419716939937510'), precision=50) == Float(pi, precision=50)\n    assert Float(mpf('2.71828182845904523536028747135266249775724709369995'), precision=50) == Float(E, precision=50)\n    assert Float(mpf('-1.61803398874989484820458683436563811772030917980576'), precision=50) == Float(-GoldenRatio, precision=50)\n", "def test_mpf_norm_issue_6639():\n    # Test mpf_norm for mantissa zero but non-zero bc\n    from mpmath.libmp import finf as _mpf_inf, fninf as _mpf_ninf, fnan as _mpf_nan\n\n    # mantissa zero but bc is non-zero\n    assert mpf_norm((0, 0, 1, 1), 10) == (0, 0, 1, 1)\n    assert mpf_norm((1, 0, 1, 1), 10) == (1, 0, 1, 1)\n    assert mpf_norm(_mpf_inf, 10) == _mpf_inf\n    assert mpf_norm(_mpf_ninf, 10) == _mpf_ninf\n    assert mpf_norm(_mpf_nan, 10) == _mpf_nan\n\n    # mantissa zero and bc is zero\n    assert mpf_norm((0, 0, 1, 0), 10) == (0, 0, 0, 0)\n    assert mpf_norm((1, 0, 1, 0), 10) == (0, 0, 0, 0)\n"], "sample_141": ["def test_quantity_simplify():\n    from sympy.physics.units import kilo\n    from sympy.physics.units.definitions import foot, inch\n\n    # Test simplification of expressions with prefixes\n    assert quantity_simplify(kilo*foot*inch) == 250*foot**2/3\n\n    # Test simplification of expressions with multiple units of the same dimension\n    assert quantity_simplify(foot - 6*inch) == foot/2\n\n    # Test simplification of complex expressions\n    expr = kilo*foot*inch + inch\n    simplified_expr = quantity_simplify(expr)\n    expected_expr = 250*foot**2/3 + inch\n    assert simplified_expr == expected_expr\n", "def test_quantity_simplify():\n    from sympy.physics.units import joule, meter, second, kilogram\n    from sympy.physics.units.prefixes import kilo\n\n    # Simplify an expression with prefixes and quantities\n    expr = kilo*meter*meter\n    assert quantity_simplify(expr) == 1000*meter**2\n\n    expr = kilo*joule*second\n    assert quantity_simplify(expr) == 1000*joule*second\n\n    # Simplify an expression with different units of the same dimension\n    from sympy.physics.units import foot, inch\n    expr = foot + 6*inch\n    assert quantity_simplify(expr) == 1.5*foot\n\n    expr = kilo*foot*inch\n    assert quantity_simplify(expr) == 250*kilo*foot**2/3\n\n    # Simplify an expression with quantities that should be unified\n    from sympy.physics.units import centimeter, gram\n    expr = 100*centimeter + 1*meter\n    assert quantity_simplify(expr) == 2*meter\n\n    expr = 500*gram + 0.5*kilo*gram\n    assert quantity_simplify(expr) == 1*kilogram\n\n    # Simplify an expression with nested quantities\n    expr = 2*(10*meter + 100*centimeter)\n    assert quantity_simplify(expr) == 2*11*meter\n", "def test_quantity_simplify():\n    from sympy.physics.units import kilo, foot, inch, meter, second, minute, gram\n    from sympy import Symbol\n    expr1 = kilo * foot * inch\n    expr2 = foot - 6 * inch\n    expr3 = kilo * meter / second + meter / second\n    expr4 = 5000 * gram\n    simplified_expr1 = quantity_simplify(expr1)\n    simplified_expr2 = quantity_simplify(expr2)\n    simplified_expr3 = quantity_simplify(expr3)\n    simplified_expr4 = quantity_simplify(expr4)\n\n    assert simplified_expr1 == 250 * foot**2 / 3\n    assert simplified_expr2 == foot / 2\n    assert simplified_expr3 == 1001 * meter / second\n    assert simplified_expr4 == 5 * kilo * gram\n", "def test_quantity_simplify():\n    from sympy.physics.units import kilo, foot, inch, gram\n    from sympy.physics.units.util import quantity_simplify\n\n    expr1 = kilo * foot * inch\n    simplified_expr1 = quantity_simplify(expr1)\n    assert simplified_expr1 == 250 * foot**2 / 3\n\n    expr2 = foot - 6 * inch\n    simplified_expr2 = quantity_simplify(expr2)\n    assert simplified_expr2 == foot / 2\n\n    expr3 = 3 * kilo * gram\n    simplified_expr3 = quantity_simplify(expr3)\n    assert simplified_expr3 == 3000 * gram\n", "def test_quantity_simplify():\n    from sympy.physics.units.prefixes import kilo\n    from sympy.physics.units import foot, inch\n    \n    expr1 = kilo * foot * inch\n    simplified_expr1 = quantity_simplify(expr1)\n    assert simplified_expr1 == 250 * foot**2 / 3\n    \n    expr2 = foot - 6 * inch\n    simplified_expr2 = quantity_simplify(expr2)\n    assert simplified_expr2 == foot / 2\n\n    # Additional cases to improve coverage\n    expr3 = 2 * kilo * meter + 300 * centimeter\n    simplified_expr3 = quantity_simplify(expr3)\n    assert simplified_expr3 == 2300 * meter\n    \n    expr4 = 5 * kilo * joule + 2000 * joule\n    simplified_expr4 = quantity_simplify(expr4)\n    assert simplified_expr4 == 7 * kilo * joule\n    \n    expr5 = 1 * kilogram * meter / second**2 + 1000 * gram * meter / second**2\n    simplified_expr5 = quantity_simplify(expr5)\n    assert simplified_expr5 == 2 * kilogram * meter / second**2\n"], "sample_140": ["def test_point_set_pos_exceptions():\n    N = ReferenceFrame('N')\n    p1 = Point('p1')\n    p2 = Point('p2')\n\n    # Test with invalid name type\n    with raises(TypeError):\n        p1.locatenew(123, 10 * N.x)\n\n    # Test with invalid vector type\n    with raises(TypeError):\n        p1.set_pos(p2, 'invalid_vector')\n\n    # Test with invalid point type\n    with raises(TypeError):\n        p1.set_pos('invalid_point', 10 * N.x)\n", "def test_point_acc():\n    q = dynamicsymbols('q')\n    qd = dynamicsymbols('q', 1)\n    qdd = dynamicsymbols('q', 2)\n    N = ReferenceFrame('N')\n    O = Point('O')\n    P = O.locatenew('P', q * N.x)\n    P.set_vel(N, qd * N.x)\n    O.set_acc(N, 0)\n    assert P.acc(N) == qdd * N.x  # Testing automatically calculated acceleration\n    O.set_acc(N, N.y)\n    assert P.acc(N) == qdd * N.x + N.y  # Testing with non-zero acceleration of the reference point\n    raises(ValueError, lambda: O.acc(ReferenceFrame('B')))  # Testing frame not in dictionary\n", "def test_point_set_pos_exceptions():\n    N = ReferenceFrame('N')\n    p1 = Point('p1')\n    p2 = Point('p2')\n    raises(TypeError, lambda: p1.set_pos(p2, 'not_a_vector'))  # Invalid vector\n    raises(TypeError, lambda: p1.set_pos('not_a_point', N.x))  # Invalid point\n", "def test_point_set_acc():\n    q1, q2 = dynamicsymbols('q1 q2')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    P = Point('P')\n    P.set_acc(N, q1 * N.x)\n    assert P.acc(N) == q1 * N.x\n    raises(ValueError, lambda: P.acc(B))  # Acceleration of P not defined in B\n    P.set_acc(N, q2 * N.y)\n    assert P.acc(N) == q2 * N.y\n    raises(ValueError, lambda: P.set_acc(B, q2 * N.y))  # Invalid frame for acceleration\n", "def test_point_set_and_get_acc():\n    q = dynamicsymbols('q')\n    qd = dynamicsymbols('q', 1)\n    N = ReferenceFrame('N')\n    P = Point('P')\n    P.set_acc(N, qd * N.x)\n    assert P.acc(N) == qd * N.x\n    P.set_acc(N, 0)\n    assert P.acc(N) == 0\n"], "sample_38": ["    def test_unicode_ci_compare_case_insensitive(self):\n        self.assertTrue(_unicode_ci_compare('A', 'a'))\n        self.assertTrue(_unicode_ci_compare('\u00df', 'ss'))  # '\u00df' normalizes to 'ss'\n        self.assertTrue(_unicode_ci_compare('\u212a', 'K'))   # '\u212a' (Kelvin sign) normalizes to 'K'\n        self.assertFalse(_unicode_ci_compare('A', 'b'))\n", "    def test_to_python_normalizes_unicode(self):\n        field = UsernameField()\n        value = 'test\u2126'  # U+2126 OHM SIGN\n        normalized_value = field.to_python(value)\n        self.assertEqual(normalized_value, 'test\u03a9')  # U+03A9 GREEK CAPITAL LETTER OMEGA\n", "    def test_case_insensitive_match(self):\n        self.assertTrue(_unicode_ci_compare('Test', 'test'))\n        self.assertTrue(_unicode_ci_compare('\u00df', 'ss'))  # German sharp S to lowercase 'ss'\n        self.assertTrue(_unicode_ci_compare('\u2126', '\u03a9'))  # Ohm symbol to Greek Omega\n", "    def test_case_insensitive_comparison(self):\n        self.assertTrue(_unicode_ci_compare('Test', 'test'))\n        self.assertTrue(_unicode_ci_compare('Stra\u00dfe', 'strasse'))  # German sharp S vs. ss\n        self.assertTrue(_unicode_ci_compare('Test\u03a3', 'Test\u03c3'))  # Greek capital sigma vs. small sigma\n        self.assertFalse(_unicode_ci_compare('Test', 'TesT1'))\n", "    def test_to_python_normalization(self):\n        field = UsernameField()\n        # Ensure that to_python normalizes the input using NFKC normalization.\n        self.assertEqual(field.to_python('test\\u2126'), 'test\u03a9')\n        self.assertEqual(field.to_python('test\\u00A0'), 'test ')\n"], "sample_28": ["    def setUp(self):\n        self.site = admin.AdminSite()\n", "    def setUp(self):\n        self.site = admin.AdminSite()\n", "    def setUp(self):\n        self.site = admin.AdminSite()\n", "    def setUp(self):\n        self.site = admin.AdminSite()\n", "    def setUp(self):\n        self.site = admin.AdminSite()\n"], "sample_20": ["    def test_unique_constraint_on_single_field(self):\n        class Model(models.Model):\n            field = models.CharField(max_length=100, unique=True)\n\n        self.assertEqual(Model.check(), [])\n", "    def test_proxy_model_with_fields(self):\n        class Parent(models.Model):\n            name = models.CharField(max_length=100)\n\n        class ProxyModel(Parent):\n            class Meta:\n                proxy = True\n\n        self.assertEqual(ProxyModel.check(), [])\n", "    def test_meta_options_ordering(self):\n        class Model(models.Model):\n            field = models.CharField(max_length=255)\n\n            class Meta:\n                ordering = ['field']\n\n        self.assertEqual(Model._meta.ordering, ['field'])\n", "    def test_proxy_model_with_fields(self):\n        class BaseModel(models.Model):\n            field1 = models.IntegerField()\n\n        class ProxyModel(BaseModel):\n            class Meta:\n                proxy = True\n\n        self.assertEqual(ProxyModel.check(), [\n            Error(\n                \"Proxy model 'ProxyModel' contains model fields.\",\n                obj=ProxyModel,\n                id='models.E017',\n            ),\n        ])\n", "    def test_get_deferred_fields(self):\n        class TestModel(models.Model):\n            field1 = models.CharField(max_length=100)\n            field2 = models.IntegerField()\n        \n        obj = TestModel(field1='value1')\n        obj._deferred = True\n        self.assertEqual(obj.get_deferred_fields(), {'field2'})\n    "], "sample_98": ["def test_check_is_fitted_custom_message():\n    class MockEstimator:\n            self.fitted = fitted\n            if fitted:\n                self.some_attribute_ = \"I am fitted!\"\n\n    est = MockEstimator(fitted=True)\n    assert_equal(check_is_fitted(est, \"some_attribute_\"), None)\n\n    est = MockEstimator(fitted=False)\n    custom_msg = \"Custom error message for not fitted estimator: %(name)s\"\n    with pytest.raises(NotFittedError, match=custom_msg % {\"name\": \"MockEstimator\"}):\n        check_is_fitted(est, \"some_attribute_\", msg=custom_msg)\n", "def test_check_random_state():\n    # Test check_random_state with various inputs\n    rng = np.random.RandomState(42)\n    \n    # When seed is None, it should return the singleton RandomState used by np.random\n    assert check_random_state(None) is np.random.mtrand._rand\n\n    # When seed is an integer, it should return a new RandomState instance seeded with seed\n    assert isinstance(check_random_state(42), np.random.RandomState)\n\n    # When seed is already a RandomState instance, it should return that instance\n    assert check_random_state(rng) is rng\n\n    # Check that an invalid seed raises a ValueError\n    assert_raises(ValueError, check_random_state, \"invalid_seed\")\n    \n    # Check that the returned RandomState instance generates reproducible results\n    rng1 = check_random_state(42)\n    rng2 = check_random_state(42)\n    assert_array_equal(rng1.randint(0, 100, 10), rng2.randint(0, 100, 10))\n", "def test_check_non_negative():\n    # Test the check_non_negative function\n\n    # Test with dense array containing negative values\n    X = np.array([1, 2, -3, 4])\n    with pytest.raises(ValueError, match=\"Negative values in data passed to test\"):\n        check_non_negative(X, \"test\")\n\n    # Test with dense array containing no negative values\n    X = np.array([1, 2, 3, 4])\n    assert check_non_negative(X, \"test\") is None\n\n    # Test with sparse matrix containing negative values\n    X = sp.csr_matrix([[0, 1], [2, -3]])\n    with pytest.raises(ValueError, match=\"Negative values in data passed to test\"):\n        check_non_negative(X, \"test\")\n\n    # Test with sparse matrix containing no negative values\n    X = sp.csr_matrix([[0, 1], [2, 3]])\n    assert check_non_negative(X, \"test\") is None\n", "def test_check_no_nan_inf():\n    # Test check_array with no NaNs or Infs\n    X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    X_checked = check_array(X, force_all_finite=True)\n    assert_array_equal(X, X_checked)\n\n    # Test with a sparse matrix\n    X_sparse = sp.csr_matrix(X)\n    X_sparse_checked = check_array(X_sparse, accept_sparse=True, force_all_finite=True)\n    assert_array_equal(X_sparse.toarray(), X_sparse_checked.toarray())\n\n    # Test with a DataFrame\n    pd = importorskip(\"pandas\")\n    df = pd.DataFrame(X)\n    df_checked = check_array(df, force_all_finite=True)\n    assert_array_equal(X, df_checked)\n", "def test_check_symmetric_sparse():\n    # Test check_symmetric with different sparse formats\n    arr_sym = np.array([[0, 1], [1, 2]])\n    arr_asym = np.array([[0, 2], [0, 2]])\n\n    test_arrays = {'dok': sp.dok_matrix(arr_asym),\n                   'csr': sp.csr_matrix(arr_asym),\n                   'csc': sp.csc_matrix(arr_asym),\n                   'coo': sp.coo_matrix(arr_asym),\n                   'lil': sp.lil_matrix(arr_asym),\n                   'bsr': sp.bsr_matrix(arr_asym)}\n\n    for arr_format, arr in test_arrays.items():\n        output = check_symmetric(arr, raise_warning=False)\n        assert sp.issparse(output)\n        assert_equal(output.format, arr_format)\n        assert_array_equal(output.toarray(), arr_sym)\n"], "sample_45": ["    def test_decorator_from_middleware(self):\n        class TestMiddleware:\n                self.get_response = get_response\n\n                response = self.get_response(request)\n                response[\"X-Test\"] = \"TestMiddleware\"\n                return response\n\n        @decorator_from_middleware(TestMiddleware)\n            return HttpResponse()\n\n        request = HttpRequest()\n        response = a_view(request)\n        self.assertEqual(response[\"X-Test\"], \"TestMiddleware\")\n", "    def test_classonlymethod_access_from_instance(self):\n        \"\"\"\n        Accessing a classonlymethod from an instance raises AttributeError.\n        \"\"\"\n        class MyClass:\n            @classonlymethod\n                return \"class method called\"\n\n        instance = MyClass()\n        with self.assertRaisesMessage(AttributeError, \"This method is available only on the class, not on instances.\"):\n            instance.my_class_method()\n", "    def test_decorator_from_middleware(self):\n        class MyMiddleware:\n                self.get_response = get_response\n\n                response = self.get_response(request)\n                response['X-Test'] = 'middleware-applied'\n                return response\n\n        @decorator_from_middleware(MyMiddleware)\n            return HttpResponse(\"OK\")\n\n        request = HttpRequest()\n        response = my_view(request)\n        self.assertEqual(response['X-Test'], 'middleware-applied')\n        self.assertEqual(response.content, b\"OK\")\n", "    def test_classonlymethod(self):\n        class MyClass:\n            @classonlymethod\n                return \"class method\"\n\n        self.assertEqual(MyClass.my_class_method(), \"class method\")\n        instance = MyClass()\n        with self.assertRaisesMessage(AttributeError, \"This method is available only on the class, not on instances.\"):\n            instance.my_class_method()\n", "    def test_classonlymethod_on_instance(self):\n        class MyClass:\n            @classonlymethod\n                return \"class method\"\n\n        instance = MyClass()\n        with self.assertRaisesMessage(AttributeError, \"This method is available only on the class, not on instances.\"):\n            instance.my_class_method()\n"], "sample_11": ["    def test_serialize_lazy_objects_string(self):\n        lazy_string = SimpleLazyObject(lambda: \"lazy_string\")\n        self.assertSerializedEqual(lazy_string)\n", "    def test_serialize_custom_deconstructable(self):\n        @deconstructible\n        class CustomDeconstructable:\n                self.arg1 = arg1\n                self.arg2 = arg2\n\n                path = 'migrations.test_writer.CustomDeconstructable'\n                return (path, [self.arg1, self.arg2], {})\n\n        obj = CustomDeconstructable(1, 'test')\n        string, imports = MigrationWriter.serialize(obj)\n        self.assertEqual(\n            string,\n            \"migrations.test_writer.CustomDeconstructable(1, 'test')\"\n        )\n        self.assertEqual(imports, {'import migrations.test_writer'})\n        result = self.safe_exec(f\"from migrations.test_writer import CustomDeconstructable\\n{string}\")\n        self.assertEqual(result['CustomDeconstructable'](1, 'test').arg1, 1)\n        self.assertEqual(result['CustomDeconstructable'](1, 'test').arg2, 'test')\n", "    def test_serialize_function_type(self):\n            return \"sample function\"\n        \n        self.assertSerializedResultEqual(\n            sample_function,\n            (\"migrations.test_writer.sample_function\", {'import migrations.test_writer'})\n        )\n        \n        class SampleClass:\n            @staticmethod\n                return \"static method\"\n            \n            @classmethod\n                return \"class method\"\n        \n        self.assertSerializedResultEqual(\n            SampleClass.static_method,\n            (\"migrations.test_writer.SampleClass.static_method\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedResultEqual(\n            SampleClass.class_method,\n            (\"migrations.test_writer.SampleClass.class_method\", {'import migrations.test_writer'})\n        )\n", "    def test_serialize_iterable(self):\n        self.assertSerializedEqual(iter([1, 2, 3]))\n        self.assertSerializedResultEqual(\n            iter([1, 2, 3]),\n            (\"(1, 2, 3)\", set())\n        )\n        self.assertSerializedEqual(iter([\"a\", \"b\", \"c\"]))\n        self.assertSerializedResultEqual(\n            iter([\"a\", \"b\", \"c\"]),\n            (\"('a', 'b', 'c')\", set())\n        )\n        self.assertSerializedEqual(iter([]))\n        self.assertSerializedResultEqual(\n            iter([]),\n            (\"()\", set())\n        )\n", "    def test_serialize_iterable(self):\n        self.assertSerializedEqual(iter([1, 2, 3]))\n        self.assertSerializedEqual(iter(\"abc\"))\n        self.assertSerializedResultEqual(\n            iter([1, 2, 3]),\n            (\"(1, 2, 3)\", set())\n        )\n        self.assertSerializedResultEqual(\n            iter(\"abc\"),\n            (\"('a', 'b', 'c')\", set())\n        )\n"], "sample_104": ["def test_custom_repr_with_large_parameters():\n    # Test custom repr with a large number of parameters\n    class CustomEstimator(BaseEstimator):\n            self.params = params\n\n            return self.params\n\n    # Generate a large number of parameters\n    large_params = {f'param_{i}': i for i in range(100)}\n\n    est = CustomEstimator(**large_params)\n    pp = _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=True)\n\n    expected = (\n        \"CustomEstimator(param_0=0, param_1=1, param_2=2, param_3=3, param_4=4, param_5=5, param_6=6, param_7=7, \"\n        \"param_8=8, param_9=9, param_10=10, param_11=11, param_12=12, param_13=13, param_14=14, param_15=15, \"\n        \"param_16=16, param_17=17, param_18=18, param_19=19, param_20=20, param_21=21, param_22=22, param_23=23, \"\n        \"param_24=24, param_25=25, param_26=26, param_27=27, param_28=28, param_29=29, param_30=30, param_31=31, \"\n        \"param_32=32, param_33=33, param_34=34, param_35=35, param_36=36, param_37=37, param_38=38, param_39=39, \"\n        \"param_40=40, param_41=41, param_42=42, param_43=43, param_44=44, param_45=45, param_46=46, param_47=47, \"\n        \"param_48=48, param_49=49, param_50=50, param_51=51, param_52=52, param_53=53, param_54=54, param_55=55, \"\n        \"param_56=56, param_57=57, param_58=58, param_59=59, param_60=60", "def test_nested_pipeline():\n    # Test nested pipelines to ensure proper pretty-printing\n    pipeline = Pipeline([\n        ('scaler', StandardScaler()),\n        ('classifier', Pipeline([\n            ('selector', SelectKBest(chi2)),\n            ('clf', LogisticRegression())\n        ]))\n    ])\n    expected = \"\"\"", "def test_custom_keyvaltuple():\n    # Test custom KeyValTuple and KeyValTupleParam rendering\n    pp = _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=True)\n\n    custom_dict = KeyValTuple((('key1', 'value1'), ('key2', 'value2')))\n    expected = \"('key1', 'value1'), ('key2', 'value2')\"\n    assert pp.pformat(custom_dict) == expected\n\n    custom_param = KeyValTupleParam((('param1', 'value1'), ('param2', 'value2')))\n    expected = \"param1='value1', param2='value2'\"\n    assert pp.pformat(custom_param) == expected\n", "def test_custom_indentation():\n    # Test _EstimatorPrettyPrinter with custom indentation and width\n    pp = _EstimatorPrettyPrinter(indent=4, width=100, compact=True, indent_at_name=False)\n\n    lr = LogisticRegression(C=999, penalty='l1')\n    expected = \"\"\"", "def test_dict_compact():\n    # Test the compact representation for dictionaries\n    pp = _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=True)\n    \n    params = {'penalty': 'l2', 'dual': False, 'tol': 1e-4, 'C': 1.0}\n    expected = r\"{'C': 1.0, 'dual': False, 'penalty': 'l2', 'tol': 0.0001}\"\n    \n    assert pp.pformat(params) == expected\n\n    params = {i: i for i in range(20)}\n    expected = r\"{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19}\"\n    \n    assert pp.pformat(params) == expected\n\n    params = {i: i for i in range(21)}\n    expected = r\"{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19, ...}\"\n    \n    assert pp.pformat(params) == expected\n"], "sample_49": ["    def test_template_changed_no_dirs(self, mock_reset, mock_get_dirs):\n        template_path = Path(__file__).parent / 'templates' / 'index.html'\n        self.assertFalse(autoreload.template_changed(None, template_path))\n        mock_reset.assert_not_called()\n", "    def test_reset_cached_loader(self, mock_reset):\n        autoreload.reset_loaders()\n        mock_reset.assert_called_once()\n", "    def test_get_template_directories_with_cached_loader(self):\n        # Cached loader should traverse its loaders to find directories\n        self.assertSetEqual(\n            autoreload.get_template_directories(),\n            {\n                ROOT / 'templates',\n                ROOT / 'templates_extra',\n            }\n        )\n", "    def test_template_changed_with_cached_loader(self, mock_reset):\n        template_path = Path(__file__).parent / 'templates' / 'index.html'\n        self.assertTrue(autoreload.template_changed(None, template_path))\n        mock_reset.assert_called_once()\n", "    def test_reset_cached_loader(self, mock_reset):\n        autoreload.reset_loaders()\n        mock_reset.assert_called_once()\n"], "sample_5": ["    def test_set_callable(self):\n        \"\"\"\n        Test the SET callable on_delete handler to ensure it sets the field correctly.\n        \"\"\"\n        default_value = lambda: R.objects.create()\n        a = create_a('set_callable')\n        set_callable_handler = SET(default_value)\n\n        # Apply the callable handler\n        set_callable_handler(Collector(using='default'), a._meta.get_field('set_callable'), [a], using='default')\n\n        a = A.objects.get(pk=a.pk)\n        self.assertEqual(a.set_callable, default_value())\n", "    def test_delete_with_reverse_dependency(self):\n        \"\"\"\n        Test delete with reverse dependency where the source model should be deleted\n        before the current model.\n        \"\"\"\n        parent = R.objects.create()\n        child = S.objects.create(r=parent)\n        grandchild = T.objects.create(s=child)\n        \n        collector = Collector(using='default')\n        collector.collect([grandchild], source=child, reverse_dependency=True)\n        deleted_count, deleted_objs = collector.delete()\n        \n        self.assertEqual(deleted_count, 3)\n        self.assertFalse(T.objects.filter(pk=grandchild.pk).exists())\n        self.assertFalse(S.objects.filter(pk=child.pk).exists())\n        self.assertFalse(R.objects.filter(pk=parent.pk).exists())\n", "    def test_set_callable(self):\n        \"\"\"\n        Test the SET function where the value is a callable.\n        \"\"\"\n            return self.DEFAULT\n\n        a = create_a('set_callable')\n        a.set_callable = dynamic_value\n        a.set_callable.delete()\n        a = A.objects.get(pk=a.pk)\n        self.assertEqual(self.DEFAULT, a.set_callable.pk)\n", "def test_protected_error_initialization():\n    protected_objects = ['obj1', 'obj2']\n    msg = \"Test Protected Error\"\n    error = ProtectedError(msg, protected_objects)\n    self.assertEqual(error.protected_objects, protected_objects)\n    self.assertEqual(str(error), msg)\n", "def test_collect_related_objects(self):\n    \"\"\"\n    Test that collect() correctly gathers related objects for deletion\n    based on various on_delete behaviors.\n    \"\"\"\n    # Create objects with different on_delete behaviors\n    r = R.objects.create()\n    a_cascade = A.objects.create(name='cascade', cascade=r)\n    a_protect = A.objects.create(name='protect', protect=r)\n    a_setnull = A.objects.create(name='setnull', setnull=r)\n\n    collector = Collector(using='default')\n    collector.collect([r])\n\n    # The collector should collect the related objects based on their on_delete behavior\n    self.assertIn(r, collector.data[R])\n    self.assertIn(a_cascade, collector.data[A])\n    self.assertIn(a_setnull, collector.data[A])\n    \n    # Ensure that objects with PROTECT are not collected\n    self.assertNotIn(a_protect, collector.data[A])\n\n    # Test deletion order\n    collector.sort()\n    collected_models = list(collector.data.keys())\n    self.assertTrue(collected_models.index(R) < collected_models.index(A))\n"], "sample_156": ["def test_parser_mathematica_nested_functions():\n    parser = MathematicaParser()\n\n    # Chaining multiple functions together\n    nested_expr = \"Sin[Cos[Tan[x]]]\"\n    assert parse_mathematica(nested_expr) == sin(cos(tan(x)))\n\n    # More complex nested functions\n    nested_expr_complex = \"Exp[Log[Sqrt[Sin[x]^2 + Cos[y]^2]]]\"\n    assert parse_mathematica(nested_expr_complex) == exp(log(sqrt(sin(x)**2 + cos(y)**2)))\n\n    # Function within function with arguments\n    nested_expr_args = \"Max[Min[3, 5], Mod[7, 2]]\"\n    assert parse_mathematica(nested_expr_args) == Max(Min(3, 5), Mod(7, 2))\n\n    # Nested function with trigonometric functions\n    nested_trig_expr = \"Cos[ArcSin[Sin[Pi/4]]]\"\n    assert parse_mathematica(nested_trig_expr) == cos(asin(sin(pi/4)))\n\n    # Multiple nested trigonometric functions\n    nested_trig_expr_complex = \"Sin[Cos[ArcTan[3, 4]]]\"\n    assert parse_mathematica(nested_trig_expr_complex) == sin(cos(atan2(4, 3)))\n", "def test_mathematica_complex_patterns():\n    d = {\n        'Sin[Pi x] + Cos[2 Pi y]': 'sin(pi*x) + cos(2*pi*y)',\n        'E^(I Pi) + 1': 'exp(I*pi) + 1',\n        'Gamma[5]': 'gamma(5)',\n        'Sum[k^2, {k, 1, 10}]': 'Sum(k**2, (k, 1, 10))',\n        'Integrate[Sin[x], {x, 0, Pi}]': 'Integral(sin(x), (x, 0, pi))',\n        'D[Sin[x], x]': 'Derivative(x)(sin(x))',\n        'Sqrt[2] + 3/Sqrt[5]': 'sqrt(2) + 3/sqrt(5)',\n        'Abs[x - y]': 'Abs(x - y)',\n        'Ceiling[2.5]': 'ceiling(2.5)',\n        'Floor[2.5]': 'floor(2.5)',\n        'Max[1, 2, 3] + Min[1, 2, 3]': 'Max(1, 2, 3) + Min(1, 2, 3)',\n        '2^(3/2)': '2**(3/2)',\n        'Sign[x - y]': 'sign(x - y)',\n    }\n\n    for e in d:\n        assert parse_mathematica(e) == sympify(d[e])\n", "def test_mathematica_special_cases():\n    # Test edge cases and special characters\n    assert parse_mathematica('Pi') == pi\n    assert parse_mathematica('E') == sympify('E')\n    assert parse_mathematica('I') == I\n    assert parse_mathematica('Infinity') == sympify('oo')\n    assert parse_mathematica('Undefined') == sympify('zoo')\n    assert parse_mathematica('NaN') == sympify('nan')\n\n    # Test compound expressions with special characters\n    assert parse_mathematica('Pi + I') == pi + I\n    assert parse_mathematica('E * Pi') == sympify('E') * pi\n    assert parse_mathematica('Infinity - I') == sympify('oo') - I\n\n    # Test nested functions\n    assert parse_mathematica('Sin[Cos[Tan[x]]]') == sin(cos(tan(x)))\n    assert parse_mathematica('Exp[Log[Sin[x] + Cos[y]]]') == exp(log(sin(x) + cos(y)))\n\n    # Test function with multiple arguments and special characters\n    assert parse_mathematica('Max[Pi, E, I]') == Max(pi, sympify('E'), I)\n    assert parse_mathematica('Min[Infinity, Undefined, NaN]') == Min(sympify('oo'), sympify('zoo'), sympify('nan'))\n\n    # Test list and matrix handling\n    m = parse_mathematica('{{a, b}, {c, d}}')\n    from sympy import Matrix\n    assert Matrix(m) == Matrix([[symbols('a'), symbols('b')], [symbols('c'), symbols('d')]])\n\n    # Test invalid and edge cases\n    raises(SyntaxError, lambda: parse_mathematica('Sin['))\n    raises(SyntaxError, lambda: parse_mathematica('Sin[x'))\n    raises(SyntaxError, lambda: parse_mathematica('Sin[x] Cos[y]'))  # Missing operator\n    raises(ValueError, lambda: MathematicaParser._check_input('Missing closing bracket]'))\n", "def test_mathematica_custom_translations():\n    custom_translations = {\n        'CustomFunc[x,y]': 'custom_func(x,y)',\n        'AnotherFunc[x]': 'another_func(x)',\n        'NestedFunc[x,y,z]': 'nested_func(x,y,z)'\n    }\n    \n    parser = MathematicaParser(additional_translations=custom_translations)\n    \n    assert parser._parse_old('CustomFunc[a, b]') == 'custom_func(a,b)'\n    assert parser._parse_old('AnotherFunc[Sin[x]]') == 'another_func(sin(x))'\n    assert parser._parse_old('NestedFunc[x, y, CustomFunc[z, w]]') == 'nested_func(x,y,custom_func(z,w))'\n", "def test_additional_correspondences():\n    d = {\n        'ArcCos[0.5]': 'acos(0.5)',\n        'ArcSin[1]': 'asin(1)',\n        'ArcTan[1,1]': 'atan2(1,1)',\n        'ArcCot[1]': 'acot(1)',\n        'ArcSec[2]': 'asec(2)',\n        'ArcCsc[2]': 'acsc(2)',\n        'Sinh[1]': 'sinh(1)',\n        'Cosh[1]': 'cosh(1)',\n        'Tanh[1]': 'tanh(1)',\n        'Coth[1]': 'coth(1)',\n        'Sech[1]': 'sech(1)',\n        'Csch[1]': 'csch(1)',\n        'ArcSinh[1]': 'asinh(1)',\n        'ArcCosh[1]': 'acosh(1)',\n        'ArcTanh[1]': 'atanh(1)',\n        'ArcCoth[1]': 'acoth(1)',\n        'ArcSech[1]': 'asech(1)',\n        'ArcCsch[1]': 'acsch(1)',\n        'Exp[1]': 'exp(1)',\n        'Sqrt[4]': 'sqrt(4)',\n        'Log[10]': 'log(10)',\n        'Log[2,8]': 'log(8,2)',\n        'Log2[32]': 'log(32,2)',\n        'Log10[1000]': 'log(1000,10)',\n        'Mod[10,3]': 'Mod(10,3)',\n        'Max[1,2,3]': 'Max(1,2,3)',\n        'Min[1,2,3]': 'Min(1,2,3)',\n        'Pochhammer[2,3]': 'rf(2,3)',\n        'AiryAi[1]': 'airyai(1)',\n        'AiryAiPrime[1]': 'airyaiprime(1)',\n        'AiryBi[1]': 'airybi(1)',\n        'AiryBiPrime[1]': 'airybiprime(1)',\n        'LogIntegral[2]': '"], "sample_158": ["def test_unit_system_extension():\n    base_units = (meter, second)\n    additional_units = (kilogram, joule)\n    new_system_name = \"ExtendedSystem\"\n    unit_system = UnitSystem(base_units, name=\"BaseSystem\")\n    extended_system = unit_system.extend(additional_units, name=new_system_name)\n    \n    assert extended_system.name == new_system_name\n    assert set(extended_system._base_units) == set(base_units + additional_units)\n    assert set(extended_system._units) == set(base_units + additional_units)\n    assert extended_system._dimension_system == unit_system._dimension_system\n    assert extended_system._derived_units == unit_system._derived_units\n", "def test_unit_system():\n    base_units = (meter, second)\n    units = (kilogram, joule, volt)\n    name = \"TestUnitSystem\"\n    description = \"A test unit system\"\n    dimension_system = SI.get_dimension_system()\n    derived_units = {length: meter, time: second}\n\n    us = UnitSystem(base_units, units, name, description, dimension_system, derived_units)\n\n    assert us.name == name\n    assert us.descr == description\n    assert us._base_units == base_units\n    assert us._dimension_system == dimension_system\n    assert us._units == (meter, second, kilogram, joule, volt)\n    assert us._derived_units == derived_units\n\n    assert str(us) == name\n    assert repr(us) == f'<UnitSystem: {(meter, second)}>'\n\n    extended_us = us.extend((kilogram,), (joule,), \"ExtendedUnitSystem\", \"An extended test unit system\")\n    assert extended_us.name == \"ExtendedUnitSystem\"\n    assert extended_us.descr == \"An extended test unit system\"\n    assert extended_us._base_units == (meter, second, kilogram)\n    assert extended_us._units == (meter, second, kilogram, joule, volt, joule)\n    assert extended_us._derived_units == derived_units\n\n    assert us.get_dimension_system() == dimension_system\n    assert us.get_quantity_dimension(meter) == length\n    assert us.get_quantity_scale_factor(meter) == 1\n\n    assert UnitSystem.get_unit_system(us) == us\n    assert UnitSystem.get_unit_system(\"TestUnitSystem\") == us\n    with raises(ValueError):\n        UnitSystem.get_unit_system(\"NonExistentUnitSystem\")\n\n    assert us.dim == 2\n    assert us.is_consistent\n    assert us.derived_units == derived_units\n\n    expr = 2 * meter + 3 * meter\n    assert us.get_dimensional_expr(expr) == length.name\n\n    factor, dimension = us._collect_factor_and_dimension(2 * meter + 3 * meter)\n    assert factor == 5\n    assert dimension == length\n\n    units_non_prefixed = us.get_units_non_prefixed()\n    assert units_non_prefixed == {meter, second, kilogram, joule, volt}\n", "def test_extend_unitsystem():\n    base_units = (meter, second)\n    additional_units = (centimeter, millimeter, kilometer)\n    derived_units = {length: kilometer, time: second}\n    us = UnitSystem(base_units, additional_units, name=\"Custom\", derived_units=derived_units)\n\n    extended_us = us.extend(base=(kilogram,), units=(joule,), name=\"Extended\", description=\"Extended Unit System\")\n\n    assert extended_us.name == \"Extended\"\n    assert extended_us.descr == \"Extended Unit System\"\n    assert set(extended_us._base_units) == {meter, second, kilogram}\n    assert set(extended_us._units) == {meter, second, centimeter, millimeter, kilometer, kilogram, joule}\n    assert extended_us.derived_units[length] == kilometer\n    assert extended_us.derived_units[time] == second\n", "def test_get_units_non_prefixed():\n    u1 = Quantity(\"u1\")\n    u2 = Quantity(\"u2\")\n    u3 = Quantity(\"u3\")\n    u4 = kilo * u1\n    u5 = Quantity(\"u5\")\n\n    u1.set_global_relative_scale_factor(S.One, meter)\n    u2.set_global_relative_scale_factor(S.One, second)\n    u3.set_global_relative_scale_factor(S.One, joule)\n    u5.set_global_relative_scale_factor(S.One, elementary_charge)\n\n    us = UnitSystem((u1, u2), (u3, u4, u5))\n\n    non_prefixed_units = us.get_units_non_prefixed()\n\n    assert u1 in non_prefixed_units\n    assert u2 in non_prefixed_units\n    assert u3 in non_prefixed_units\n    assert u4 not in non_prefixed_units  # prefixed unit\n    assert u5 in non_prefixed_units  # physical constant should be excluded\n", "def test_unit_system_str_repr():\n    base_units = (meter, second)\n    us = UnitSystem(base_units, name=\"TestSystem\", descr=\"A test unit system\")\n    \n    assert str(us) == \"TestSystem\"\n    assert repr(us) == \"<UnitSystem: (meter, second)>\"\n\n    us_no_name = UnitSystem(base_units)\n    assert str(us_no_name) == \"UnitSystem((meter, second))\"\n    assert repr(us_no_name) == \"<UnitSystem: (meter, second)>\"\n"], "sample_55": ["def test_command_error_returncode(self):\n        \"\"\"Test that CommandError correctly sets the returncode attribute.\"\"\"\n        with self.assertRaises(CommandError) as cm:\n            raise CommandError(\"An error occurred\", returncode=2)\n        self.assertEqual(cm.exception.returncode, 2)\n", "    def test_command_error_returncode(self):\n        \"\"\"Test that CommandError sets the return code correctly.\"\"\"\n        with self.assertRaises(CommandError) as cm:\n            raise CommandError(\"Error occurred\", returncode=5)\n        self.assertEqual(cm.exception.returncode, 5)\n", "def test_command_error_returncode(self):\n    \"\"\"Test that CommandError correctly sets the returncode attribute.\"\"\"\n    with self.assertRaises(CommandError) as cm:\n        raise CommandError(\"Test error\", returncode=5)\n    self.assertEqual(cm.exception.returncode, 5)\n", "def test_command_parser_error_handling(self):\n    \"\"\"\n    Test that CommandParser handles errors correctly when called from command line\n    and when called programmatically.\n    \"\"\"\n    # Case 1: Called from command line, should raise SystemExit\n    parser = CommandParser(\n        prog=\"testprog\",\n        called_from_command_line=True,\n        description=\"Test command parser error handling\",\n    )\n    parser.add_argument(\"--testarg\", required=True)\n    with self.assertRaises(SystemExit):\n        parser.parse_args([])\n\n    # Case 2: Called programmatically, should raise CommandError\n    parser = CommandParser(\n        prog=\"testprog\",\n        called_from_command_line=False,\n        description=\"Test command parser error handling\",\n    )\n    parser.add_argument(\"--testarg\", required=True)\n    with self.assertRaises(CommandError):\n        parser.parse_args([])\n", "    def test_command_error_returncode(self):\n        \"\"\"Test that CommandError correctly sets returncode.\"\"\"\n        with self.assertRaises(CommandError) as cm:\n            raise CommandError(\"Test error\", returncode=5)\n        self.assertEqual(cm.exception.returncode, 5)\n"], "sample_95": ["    def test_pytest_addoption(self, pytester: Pytester) -> None:\n        pytester.makeconftest(\n            \"\"\"\n                parser.addoption(\"--foo\", action=\"store\", default=\"bar\", help=\"foo option\")\n            \"\"\"\n        )\n        pytester.makepyfile(\n            test_pytest_addoption=\"\"\"\n            import pytest\n\n                assert pytestconfig.getoption(\"foo\") == \"bar\"\n            \"\"\"\n        )\n        result = pytester.runpytest(\"test_pytest_addoption.py\")\n        result.assert_outcomes(passed=1)\n", "def test_pytest_addoption(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n            parser.addoption(\"--custom\", action=\"store_true\", help=\"custom option\")\n        \"\"\"\n    )\n    pytester.makepyfile(\n        test_addoption=\"\"\"\n        import pytest\n\n            assert pytestconfig.getoption(\"--custom\") is False\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n", "def test_pytest_addoption_options(pytester: Pytester) -> None:\n    result = pytester.runpytest(\"--help\")\n    result.stdout.fnmatch_lines([\n        \"*--fixtures*\",\n        \"*show available fixtures*\",\n        \"*--fixtures-per-test*\",\n        \"*show fixtures per test*\"\n    ])\n", "def test_pytest_cmdline_main_showfixtures(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n            group = parser.getgroup(\"general\")\n            group.addoption(\n                \"--fixtures\",\n                action=\"store_true\",\n                dest=\"showfixtures\",\n                default=False,\n                help=\"show available fixtures\",\n            )\n        \"\"\"\n    )\n    result = pytester.runpytest(\"--fixtures\")\n    result.stdout.fnmatch_lines([\"*fixtures defined from*\"])\n", "def test_pytest_collect_file_with_non_python_extension(self, pytester: Pytester) -> None:\n    dummy_file = pytester.makefile(ext=\".txt\", content=\"dummy content\")\n    parent = pytester.getmodulecol()\n    \n    collected = pytest_collect_file(Path(dummy_file), parent)\n    assert collected is None, \"Non-Python files should not be collected\"\n"], "sample_34": ["    def test_invalid_ordering_field(self):\n        class Model(models.Model):\n            class Meta:\n                ordering = ['nonexistent_field']\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"'ordering' refers to the nonexistent field, related field, or lookup 'nonexistent_field'.\",\n                obj=Model,\n                id='models.E015',\n            ),\n        ])\n", "    def test_multiple_primary_keys(self):\n        with self.assertRaisesMessage(checks.Error, \"The model cannot have more than one field with 'primary_key=True'.\"):\n            class ModelWithMultiplePKs(models.Model):\n                id1 = models.AutoField(primary_key=True)\n                id2 = models.IntegerField(primary_key=True)\n", "    def test_proxy_model_with_fields(self):\n        class BaseModel(models.Model):\n            name = models.CharField(max_length=20)\n\n        class ProxyModel(BaseModel):\n            age = models.IntegerField()\n\n            class Meta:\n                proxy = True\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"Proxy model 'ProxyModel' contains model fields.\",\n                id='models.E017',\n            ),\n        ])\n", "    def test_field_name_clash_with_parent(self):\n        class Parent(models.Model):\n            common_field = models.CharField(max_length=20)\n\n        class Child(Parent):\n            common_field = models.IntegerField()\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"The field 'common_field' from parent model 'check_framework.Parent' clashes with the field 'common_field' from parent model 'check_framework.Parent'.\",\n                obj=Child,\n                id='models.E005',\n            )\n        ])\n", "    def test_field_name_clash_with_parent(self):\n        class ParentModel(models.Model):\n            field1 = models.CharField(max_length=20)\n\n        class ChildModel(ParentModel):\n            field1 = models.IntegerField()\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"The field 'field1' from parent model 'check_framework.ParentModel' clashes with the field 'field1' from model 'check_framework.ChildModel'.\",\n                obj=ChildModel._meta.get_field('field1'),\n                id='models.E005',\n            ),\n        ])\n    "], "sample_106": ["def test_transform_not_fitted_error():\n    \"\"\"Test that transform raises an error if fit has not been called.\"\"\"\n    X, y = iris_data, iris_target\n\n    nca = NeighborhoodComponentsAnalysis(n_components=2, init='identity', random_state=42)\n    with pytest.raises(ValueError, match=\"This NeighborhoodComponentsAnalysis instance is not fitted yet\"):\n        nca.transform(X)\n", "def test_fit_transform_equivalence():\n    \"\"\"Test that fit_transform gives the same result as calling fit followed by transform.\"\"\"\n    X, y = make_classification(n_samples=50, n_features=10, n_informative=8, n_classes=3, random_state=42)\n    \n    nca = NeighborhoodComponentsAnalysis(n_components=5, init='pca', random_state=42)\n    \n    # Fit and transform separately\n    nca.fit(X, y)\n    X_transformed = nca.transform(X)\n    \n    # Fit and transform together\n    X_fit_transformed = nca.fit_transform(X, y)\n    \n    assert_array_almost_equal(X_transformed, X_fit_transformed)\n", "def test_transform_before_fit():\n    \"\"\"Test that calling transform before fit raises a NotFittedError.\"\"\"\n    X = iris_data\n    nca = NeighborhoodComponentsAnalysis()\n    with pytest.raises(AttributeError):\n        nca.transform(X)\n", "def test_transform_before_fit():\n    \"\"\"Test that calling transform before fit raises NotFittedError\"\"\"\n    X = np.arange(12).reshape(4, 3)\n    nca = NeighborhoodComponentsAnalysis()\n    with pytest.raises(RuntimeError, match=\"This NeighborhoodComponentsAnalysis instance is not fitted yet.\"):\n        nca.transform(X)\n", "def test_random_state():\n    \"\"\"Test that the random_state parameter controls the randomness in the initialization.\"\"\"\n    X, y = make_classification(n_samples=50, n_features=5, n_classes=3,\n                               n_informative=3, n_redundant=0, random_state=0)\n\n    # Check that two runs with the same random_state produce the same result\n    nca_1 = NeighborhoodComponentsAnalysis(init='random', random_state=42)\n    nca_1.fit(X, y)\n    components_1 = nca_1.components_\n\n    nca_2 = NeighborhoodComponentsAnalysis(init='random', random_state=42)\n    nca_2.fit(X, y)\n    components_2 = nca_2.components_\n\n    assert_array_almost_equal(components_1, components_2)\n\n    # Check that two runs with different random_state produce different results\n    nca_3 = NeighborhoodComponentsAnalysis(init='random', random_state=24)\n    nca_3.fit(X, y)\n    components_3 = nca_3.components_\n\n    with pytest.raises(AssertionError):\n        assert_array_almost_equal(components_1, components_3)\n"], "sample_90": ["def test_mark_evaluator_istrue():\n    from _pytest.nodes import Item\n    from _pytest.mark.structures import Mark\n\n    class MockItem(Item):\n            self.marks = []\n\n            if name:\n                return [mark for mark in self.marks if mark.name == name]\n            return self.marks\n\n    item = MockItem()\n    item.marks.append(Mark(name=\"condition\", args=(\"True\",), kwargs={}))\n\n    evaluator = MarkEvaluator(item, \"condition\")\n    assert evaluator.istrue() is True\n\n    item.marks.append(Mark(name=\"condition\", args=(\"False\",), kwargs={\"reason\": \"example reason\"}))\n    evaluator = MarkEvaluator(item, \"condition\")\n    assert evaluator.istrue() is True  # because the first condition is True\n\n    item.marks = [Mark(name=\"condition\", args=(\"False\",), kwargs={\"reason\": \"example reason\"})]\n    evaluator = MarkEvaluator(item, \"condition\")\n    assert evaluator.istrue() is False\n", "def test_mark_evaluator_istrue():\n    from _pytest.mark import Mark\n    from _pytest.nodes import Item\n    from _pytest.outcomes import TEST_OUTCOME\n\n    item = mock.Mock(spec=Item)\n    item.iter_markers.return_value = [Mark(\"test\", (\"True\",), {})]\n    evaluator = MarkEvaluator(item, \"test\")\n    assert evaluator.istrue()\n\n    item.iter_markers.return_value = [Mark(\"test\", (\"False\",), {})]\n    evaluator = MarkEvaluator(item, \"test\")\n    assert not evaluator.istrue()\n\n    item.iter_markers.return_value = [Mark(\"test\", (), {\"condition\": \"True\"})]\n    evaluator = MarkEvaluator(item, \"test\")\n    assert evaluator.istrue()\n\n    item.iter_markers.return_value = [Mark(\"test\", (), {\"condition\": \"False\"})]\n    evaluator = MarkEvaluator(item, \"test\")\n    assert not evaluator.istrue()\n\n    item.iter_markers.return_value = [Mark(\"test\", (), {\"condition\": True, \"reason\": \"just a test\"})]\n    evaluator = MarkEvaluator(item, \"test\")\n    assert evaluator.istrue()\n", "def test_mark_evaluator_istrue():\n    from _pytest.nodes import Item\n    from _pytest.mark.structures import Mark\n\n    class MockItem(Item):\n            super().__init__(name, parent=None, config=config, session=None, nodeid=name)\n            self._markers = markers\n\n            for marker in self._markers:\n                if name is None or marker.name == name:\n                    yield marker\n\n    class MockConfig:\n        pass\n\n    config = MockConfig()\n    mock_item = MockItem(\"test_item\", config, [Mark(name=\"custom_mark\", args=(), kwargs={\"condition\": \"2 + 2 == 4\", \"reason\": \"test reason\"})])\n    evaluator = MarkEvaluator(mock_item, \"custom_mark\")\n\n    assert evaluator.istrue() is True\n    assert evaluator.getexplanation() == \"test reason\"\n", "def test_mark_evaluator_istrue_with_condition():\n    from _pytest.nodes import Item\n    from _pytest.mark.structures import Mark\n\n    class MockItem(Item):\n            super().__init__(name, None)\n            self.config = config\n            self.obj = obj\n\n            if name == \"mock_mark\":\n                return [Mark(name, (), {\"condition\": \"3 > 2\", \"reason\": \"Test reason\"})]\n            return []\n\n    mock_item = MockItem(\"mock_item\", None)\n    evaluator = MarkEvaluator(mock_item, \"mock_mark\")\n    \n    assert evaluator.istrue() is True\n    assert evaluator.getexplanation() == \"Test reason\"\n", "def test_mark_evaluator_istrue():\n    from _pytest.mark.structures import Mark\n    from _pytest.nodes import Item\n\n    class MockItem:\n            self.config = mock.Mock()\n            self.obj = mock.Mock()\n            self.obj.__globals__ = {}\n\n            if name == \"test_mark\":\n                return [Mark(name=\"test_mark\", args=(\"True\",), kwargs={})]\n            return []\n\n    item = MockItem()\n    evaluator = MarkEvaluator(item, \"test_mark\")\n    assert evaluator.istrue() is True\n\n    item2 = MockItem()\n    evaluator2 = MarkEvaluator(item2, \"test_mark\")\n    item2.iter_markers = lambda name: [Mark(name=\"test_mark\", args=(\"False\",), kwargs={})]\n    assert evaluator2.istrue() is False\n"], "sample_74": ["def test_colorbar_alpha_array():\n    # Test that colorbar can handle mappables with 2D alpha arrays properly.\n    fig, ax = plt.subplots()\n    data = np.random.rand(10, 10)\n    alpha = np.linspace(0.1, 1.0, 100).reshape(10, 10)\n    im = ax.imshow(data, alpha=alpha)\n    cbar = fig.colorbar(im, ax=ax)\n    \n    # The colorbar's alpha should be None since it should handle 2D alpha arrays internally\n    assert cbar.alpha is None\n    \n    # Ensure the figure renders without errors\n    fig.canvas.draw()\n", "def test_colorbar_remove_disconnect():\n    \"\"\"\n    Test that the colorbar disconnects the callbacks from its mappable\n    when it is removed.\n    \"\"\"\n    fig, ax = plt.subplots()\n    data = np.random.rand(10, 10)\n    im = ax.imshow(data)\n    cbar = fig.colorbar(im)\n\n    # Check that the colorbar is connected to the mappable\n    assert im.callbacks.callbacks.get('changed')\n\n    cbar.remove()\n\n    # Check that the colorbar is disconnected from the mappable\n    assert not im.callbacks.callbacks.get('changed')\n\n    # Check that the colorbar reference is removed\n    assert im.colorbar is None\n    assert im.colorbar_cid is None\n", "def test_colorbar_alpha_array_handling():\n    # Test that setting alpha to an array in Colorbar works correctly.\n    fig, ax = plt.subplots()\n    data = np.random.rand(10, 10)\n    alpha = np.linspace(0, 1, 10)\n    pc = ax.pcolormesh(data, alpha=alpha)\n    cbar = fig.colorbar(pc, ax=ax)\n\n    assert cbar.alpha is None  # Colorbar should not use a single alpha value\n    np.testing.assert_array_equal(pc.get_alpha(), alpha)  # Check original alpha array is preserved\n", "def test_colorbar_set_alpha():\n    \"\"\"\n    Test the set_alpha method of the Colorbar class to ensure that it correctly\n    sets the transparency of the colorbar.\n    \"\"\"\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cbar = fig.colorbar(im)\n    \n    # Test setting alpha to a scalar value\n    cbar.set_alpha(0.5)\n    assert cbar.alpha == 0.5\n    assert all(patch.get_alpha() == 0.5 for patch in cbar.ax.patches)\n\n    # Test setting alpha to None\n    cbar.set_alpha(None)\n    assert cbar.alpha is None\n    # Alpha should remain the same for individual patches\n    assert all(patch.get_alpha() == 0.5 for patch in cbar.ax.patches)\n\n    # Test setting alpha to an array\n    alpha_array = np.array([0.1, 0.2, 0.3, 0.4])\n    cbar.set_alpha(alpha_array)\n    assert cbar.alpha is None\n    assert all(patch.get_alpha() is None for patch in cbar.ax.patches)\n", "def test_colorbar_set_ticks():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cbar = fig.colorbar(im)\n    \n    # Test setting major ticks\n    cbar.set_ticks([0.5, 1.5, 2.5])\n    assert cbar.get_ticks().tolist() == [0.5, 1.5, 2.5]\n    \n    # Test setting minor ticks\n    cbar.set_ticks([0.75, 1.25, 2.25], minor=True)\n    assert cbar.get_ticks(minor=True).tolist() == [0.75, 1.25, 2.25]\n    \n    # Test setting tick labels\n    cbar.set_ticklabels(['A', 'B', 'C'])\n    assert [label.get_text() for label in cbar.ax.get_yticklabels()] == ['A', 'B', 'C']\n\n    # Test setting tick labels with minor ticks\n    cbar.set_ticklabels(['X', 'Y', 'Z'], minor=True)\n    assert [label.get_text() for label in cbar.ax.get_yticklabels(minor=True)] == ['X', 'Y', 'Z']\n\n    # Test setting tick labels without specifying minor\n    cbar.set_ticks([1, 2])\n    cbar.set_ticklabels(['One', 'Two'])\n    assert [label.get_text() for label in cbar.ax.get_yticklabels()] == ['One', 'Two']\n"], "sample_132": ["def test_are_coplanar():\n    from sympy import Point3D, Line3D, Plane\n    from sympy.geometry.util import are_coplanar\n\n    # Test cases for are_coplanar\n    a = Line3D(Point3D(5, 0, 0), Point3D(1, -1, 1))\n    b = Line3D(Point3D(0, -2, 0), Point3D(3, 1, 1))\n    c = Line3D(Point3D(0, -1, 0), Point3D(5, -1, 9))\n    d = Plane(Point3D(0, 0, 0), Point3D(1, 0, 0), Point3D(0, 1, 0))\n    e = Line3D(Point3D(1, 1, 1), Point3D(2, 2, 2))\n    f = Point3D(3, 3, 3)\n\n    assert are_coplanar(a, b, c) == False\n    assert are_coplanar(a, b, d) == True\n    assert are_coplanar(a, b, e) == False\n    assert are_coplanar(d, e, f) == True\n    assert are_coplanar(a, d, f) == False\n", "def test_are_coplanar():\n    from sympy.geometry.point import Point3D\n    from sympy.geometry.line import Line3D\n    from sympy.geometry.plane import Plane\n    p1 = Point3D(0, 0, 0)\n    p2 = Point3D(1, 1, 1)\n    p3 = Point3D(2, 2, 2)\n    p4 = Point3D(0, 1, 2)\n    l1 = Line3D(p1, p2)\n    l2 = Line3D(p1, p3)\n    pl1 = Plane(p1, p2, p4)\n    \n    assert not are_coplanar(p1, p2, p3)\n    assert are_coplanar(p1, p2, p4)\n    assert are_coplanar(l1, l2)\n    assert not are_coplanar(l1, p4)\n    assert are_coplanar(l1, pl1)\n", "def test_are_coplanar():\n    from sympy import Point3D, Line3D, Plane\n\n    # Test with Plane and points\n    p1, p2, p3 = Point3D(0, 0, 0), Point3D(1, 1, 1), Point3D(2, 2, 2)\n    plane = Plane(p1, p2, p3)\n    assert are_coplanar(plane, p1, p2, p3) == True\n\n    # Test with all points coplanar\n    p4 = Point3D(3, 3, 3)\n    assert are_coplanar(p1, p2, p3, p4) == True\n\n    # Test with non-coplanar points\n    p5 = Point3D(1, 1, 0)\n    assert are_coplanar(p1, p2, p3, p5) == False\n\n    # Test with lines\n    l1 = Line3D(p1, p2)\n    l2 = Line3D(p3, Point3D(3, 3, 3))\n    assert are_coplanar(l1, l2) == True\n\n    # Test with mixed GeometryEntities\n    l3 = Line3D(Point3D(0, 0, 1), Point3D(1, 1, 2))\n    assert are_coplanar(l1, l3) == False\n\n    # Test with insufficient points\n    assert are_coplanar(p1) == False\n    assert are_coplanar(p1, p2) == False\n", "def test_are_coplanar():\n    from sympy.geometry import Point3D, Line3D, Plane\n    # Test with lines\n    a = Line3D(Point3D(5, 0, 0), Point3D(1, -1, 1))\n    b = Line3D(Point3D(0, -2, 0), Point3D(3, 1, 1))\n    c = Line3D(Point3D(0, -1, 0), Point3D(5, -1, 9))\n    assert are_coplanar(a, b, c) is False\n\n    # Test with points\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(4, 5, 6)\n    p3 = Point3D(7, 8, 9)\n    assert are_coplanar(p1, p2, p3) is False\n\n    # Test with a mix of lines and points\n    p4 = Point3D(10, 11, 12)\n    assert are_coplanar(a, p1, p4) is False\n    \n    # Test with a plane\n    pl = Plane(Point3D(1, 1, 1), normal_vector=(1, -1, 1))\n    assert are_coplanar(pl, p1, p2, p3) is True\n    assert are_coplanar(pl, a, b) is False\n", "def test_are_coplanar():\n    from sympy import Point3D, Line3D, Plane\n    # Test with 3D points\n    p1 = Point3D(1, 0, 0)\n    p2 = Point3D(0, 1, 0)\n    p3 = Point3D(0, 0, 1)\n    p4 = Point3D(1, 1, 1)\n    assert are_coplanar(p1, p2, p3) == False\n    assert are_coplanar(p1, p2, p3, p4) == False\n    # Test with 3D lines\n    l1 = Line3D(p1, p2)\n    l2 = Line3D(p3, p4)\n    assert are_coplanar(l1, l2) == False\n    # Test with a Plane\n    pl = Plane(p1, p2, p3)\n    assert are_coplanar(pl, p1, p2, p3) == True\n    assert are_coplanar(pl, p1, p4) == False\n    # Test with mixed entities\n    assert are_coplanar(pl, l1, p4) == False\n"], "sample_27": ["    def test_token_with_changed_password(self):\n        \"\"\"Changing the user's password invalidates the token.\"\"\"\n        user = User.objects.create_user('changepassworduser', 'test5@example.com', 'oldpassword')\n        p0 = PasswordResetTokenGenerator()\n        tk1 = p0.make_token(user)\n        self.assertIs(p0.check_token(user, tk1), True)\n        user.set_password('newpassword')\n        user.save()\n        self.assertIs(p0.check_token(user, tk1), False)\n", "    def test_token_with_changed_password(self):\n        \"\"\"Changing the user password invalidates the token.\"\"\"\n        user = User.objects.create_user('changepassworduser', 'test5@example.com', 'testpw')\n        p0 = PasswordResetTokenGenerator()\n        tk1 = p0.make_token(user)\n        self.assertIs(p0.check_token(user, tk1), True)\n        user.set_password('newtestpw')\n        user.save()\n        self.assertIs(p0.check_token(user, tk1), False)\n", "    def test_make_token_with_different_timestamps(self):\n        \"\"\"Tokens generated at different timestamps should not match.\"\"\"\n        user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n        now = datetime.now()\n        p0 = MockedPasswordResetTokenGenerator(now)\n        tk1 = p0.make_token(user)\n        \n        later = now + timedelta(seconds=10)\n        p1 = MockedPasswordResetTokenGenerator(later)\n        tk2 = p1.make_token(user)\n        \n        self.assertNotEqual(tk1, tk2)\n", "    def test_token_with_changed_password(self):\n        \"\"\"Changing the user password invalidates the token.\"\"\"\n        user = User.objects.create_user('changepassworduser', 'test5@example.com', 'oldpassword')\n        p0 = PasswordResetTokenGenerator()\n        tk1 = p0.make_token(user)\n        self.assertIs(p0.check_token(user, tk1), True)\n        user.set_password('newpassword')\n        user.save()\n        self.assertIs(p0.check_token(user, tk1), False)\n", "    def test_make_hash_value(self):\n        \"\"\"\n        Verify that _make_hash_value generates a consistent hash value based on\n        user's primary key, password, last_login, timestamp, and email.\n        \"\"\"\n        user = User.objects.create_user('hashvaluetestuser', 'test5@example.com', 'testpw')\n        user.last_login = datetime.now() - timedelta(days=1)\n        user.save()\n        timestamp = int((datetime.now() - datetime(2001, 1, 1)).total_seconds())\n        generator = PasswordResetTokenGenerator()\n        expected_hash = f'{user.pk}{user.password}{user.last_login.replace(microsecond=0, tzinfo=None)}{timestamp}{user.email}'\n        self.assertEqual(generator._make_hash_value(user, timestamp), expected_hash)\n"], "sample_39": ["    def test_compile_valid_regex(self):\n        pattern = RegexPattern(r'^valid-regex/$')\n        compiled_regex = pattern._compile(pattern._regex)\n        self.assertTrue(re.match(compiled_regex, 'valid-regex/'))\n", "    def test_check_pattern_startswith_slash(self):\n        \"\"\"\n        Test that a warning is issued if a pattern starts with a slash.\n        \"\"\"\n        with override_settings(APPEND_SLASH=True):\n            pattern = RegexPattern(r'^/example/$')\n            warnings = pattern.check()\n            self.assertEqual(len(warnings), 1)\n            self.assertEqual(warnings[0].id, 'urls.W002')\n            self.assertIn(\"has a route beginning with a '/'\", warnings[0].msg)\n", "    def test_regex_pattern_match(self):\n        pattern = RegexPattern(r'^places/(?P<id>[0-9]+)/$')\n        match = pattern.match('/places/3/')\n        self.assertIsNotNone(match)\n        self.assertEqual(match[1], ())  # no positional args\n        self.assertEqual(match[2], {'id': '3'})  # kwargs\n", "    def test_invalid_regex_in_resolve(self):\n        \"\"\"\n        Ensure resolving a URL with an invalid regex pattern raises the appropriate error.\n        \"\"\"\n        resolver = URLResolver(RegexPattern(r'(regex_error/$'), settings.ROOT_URLCONF)\n        with self.assertRaises(ImproperlyConfigured):\n            resolver.resolve('/regex_error/')\n", "    def test_compile_valid_regex(self):\n        pattern = RegexPattern(r'^valid/$')\n        compiled_regex = pattern._compile(pattern._regex)\n        self.assertIsNotNone(compiled_regex)\n"], "sample_35": ["    def test_modelform_initialization(self):\n        form = self.TestModelForm()\n        self.assertEqual(form.fields['name'].label, 'Name')\n", "    def test_modelform_defines_fields(self):\n        class ModelFormWithoutFields(ModelForm):\n            class Meta:\n                model = ChoiceModel\n\n        class ModelFormWithFields(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = ['name']\n\n        class ModelFormWithExclude(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                exclude = ['name']\n\n        self.assertFalse(modelform_defines_fields(ModelFormWithoutFields))\n        self.assertTrue(modelform_defines_fields(ModelFormWithFields))\n        self.assertTrue(modelform_defines_fields(ModelFormWithExclude))\n", "    def test_invalid_string_in_meta_fields(self):\n        class InvalidMetaFieldsForm(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = 'name'\n\n        with self.assertRaises(TypeError) as cm:\n            InvalidMetaFieldsForm()\n        self.assertEqual(\n            str(cm.exception),\n            \"InvalidMetaFieldsForm.Meta.fields cannot be a string. Did you mean to type: ('name',)?\"\n        )\n", "    def test_modelform_factory(self):\n        class TestModelForm(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = ['name']\n\n        form = modelform_factory(ChoiceModel, form=TestModelForm, fields=['name'])\n        self.assertEqual(form.__name__, 'ChoiceModelForm')\n        self.assertIn('name', form.base_fields)\n", "    def test_inline_foreign_key_field(self):\n        parent_instance = ChoiceModel.objects.create(name='parent')\n        e = {\n            'invalid_choice': 'INVALID CHOICE',\n        }\n        f = InlineForeignKeyField(parent_instance, error_messages=e)\n\n        # Test initial value\n        self.assertEqual(f.clean(None), parent_instance)\n\n        # Test valid value\n        self.assertEqual(f.clean(parent_instance.pk), parent_instance)\n\n        # Test invalid value\n        with self.assertRaises(ValidationError) as cm:\n            f.clean(parent_instance.pk + 1)\n        self.assertEqual(cm.exception.message, 'INVALID CHOICE')\n"], "sample_144": ["def test_refine_arg():\n    assert refine(arg(x), Q.positive(x)) == S.Zero\n    assert refine(arg(x), Q.negative(x)) == S.Pi\n    assert refine(arg(x), Q.zero(x)) is None\n    assert refine(arg(x + I*y), Q.real(x) & Q.zero(y)) == arg(x)\n    assert refine(arg(x + I*y), Q.positive(x) & Q.positive(y)) == arg(x + I*y)\n    assert refine(arg(x + I*y), Q.negative(x) & Q.negative(y)) == arg(x + I*y)\n", "def test_refine_edge_cases():\n    assert refine(Abs(x), None) == Abs(x)\n    assert refine(Abs(x), False) == Abs(x)\n    assert refine(Abs(x), True) == Abs(x)\n    assert refine((-1)**x, None) == (-1)**x\n    assert refine((-1)**x, False) == (-1)**x\n    assert refine((-1)**x, True) == (-1)**x\n    assert refine(atan2(y, x), None) == atan2(y, x)\n    assert refine(atan2(y, x), False) == atan2(y, x)\n    assert refine(atan2(y, x), True) == atan2(y, x)\n    assert refine(re(x), None) == re(x)\n    assert refine(re(x), False) == re(x)\n    assert refine(re(x), True) == re(x)\n    assert refine(im(x), None) == im(x)\n    assert refine(im(x), False) == im(x)\n    assert refine(im(x), True) == im(x)\n    assert refine(sign(x), None) == sign(x)\n    assert refine(sign(x), False) == sign(x)\n    assert refine(sign(x), True) == sign(x)\n    assert refine(arg(x), None) == arg(x)\n    assert refine(arg(x), False) == arg(x)\n    assert refine(arg(x), True) == arg(x)\n", "def test_refine_arg():\n    assert refine(arg(x), Q.positive(x)) == 0\n    assert refine(arg(x), Q.negative(x)) == pi\n    assert refine(arg(x), Q.zero(x)) == 0\n    y = Symbol('y', real=True)\n    assert refine(arg(y), Q.positive(y)) == 0\n    assert refine(arg(y), Q.negative(y)) == pi\n    assert refine(arg(y), Q.zero(y)) == 0\n    z = Symbol('z', imaginary=True)\n    assert refine(arg(z), Q.positive(im(z))) == pi/2\n    assert refine(arg(z), Q.negative(im(z))) == -pi/2\n", "def test_refine_arg():\n    x = Symbol('x', real=True)\n    assert refine(arg(x), Q.positive(x)) == 0\n    assert refine(arg(x), Q.negative(x)) == pi\n    assert refine(arg(x), Q.nonzero(x)) == Piecewise((0, Q.positive(x)), (pi, Q.negative(x)))\n", "def test_refine_abs_with_mul():\n    expr = Abs(x * y)\n    assert refine(expr, Q.positive(x) & Q.positive(y)) == x * y\n    assert refine(expr, Q.positive(x) & Q.negative(y)) == x * (-y)\n    assert refine(expr, Q.negative(x) & Q.positive(y)) == (-x) * y\n    assert refine(expr, Q.negative(x) & Q.negative(y)) == (-x) * (-y)\n"], "sample_31": ["    def test_shell_with_plain_python_no_startup(self, select):\n        select.return_value = ([], [], [])\n        with mock.patch('code.interact') as mock_interact:\n            call_command('shell', interface='python', no_startup=True)\n        mock_interact.assert_called_once()\n", "    def test_shell_with_ipython_installed(self, select):\n        select.return_value = ([], [], [])\n        with captured_stdout() as stdout:\n            call_command('shell', interface='ipython')\n        self.assertIn('IPython', stdout.getvalue())\n", "    def test_shell_with_plain_python(self, select):\n        select.return_value = ([], [], [])\n        with captured_stdout() as stdout, mock.patch('code.interact') as mock_interact:\n            call_command('shell', interface='python')\n            mock_interact.assert_called_once()\n", "    def test_python_startup_script_execution(self, mock_isfile, mock_open):\n        with captured_stdout() as stdout:\n            call_command('shell', interface='python')\n        self.assertIn('startup script executed', stdout.getvalue().strip())\n", "    def test_shell_with_plain_python(self, select):\n        select.return_value = ([], [], [])\n        with captured_stdout() as stdout, mock.patch('code.interact') as interact:\n            call_command('shell', interface='python')\n            interact.assert_called_once()\n"], "sample_64": ["    def test_prepopulated_fields_js_tag(self):\n        \"\"\"\n        prepopulated_fields_js_tag should render the correct context with JavaScript for prepopulated fields.\n        \"\"\"\n        request = self.request_factory.get(\n            reverse(\"admin:auth_user_add\")\n        )\n        request.user = self.superuser\n        admin = UserAdmin(User, site)\n        response = admin.add_view(request)\n        template_context = prepopulated_fields_js(response.context_data)\n        \n        self.assertIn(\"prepopulated_fields\", template_context)\n        self.assertIn(\"prepopulated_fields_json\", template_context)\n        self.assertIsInstance(template_context[\"prepopulated_fields_json\"], str)\n        self.assertTrue(template_context[\"prepopulated_fields_json\"].startswith('['))\n        self.assertTrue(template_context[\"prepopulated_fields_json\"].endswith(']'))\n", "    def test_prepopulated_fields_js(self):\n        \"\"\"\n        prepopulated_fields_js should correctly generate JSON for prepopulated fields.\n        \"\"\"\n        request = self.request_factory.get(\n            reverse(\"admin:auth_user_change\", args=[self.superuser.pk]),\n        )\n        request.user = self.superuser\n        admin = UserAdmin(User, site)\n        form = admin.get_form(request)()\n        form.prepopulated_fields = [\n            {\n                \"field\": form.fields[\"username\"],\n                \"dependencies\": [form.fields[\"first_name\"], form.fields[\"last_name\"]],\n            }\n        ]\n        context = {\n            \"adminform\": form,\n            \"inline_admin_formsets\": [],\n        }\n        template_context = prepopulated_fields_js(context)\n        prepopulated_fields_json = json.loads(template_context[\"prepopulated_fields_json\"])\n\n        self.assertEqual(len(prepopulated_fields_json), 1)\n        self.assertEqual(\n            prepopulated_fields_json[0][\"id\"], \"#id_username\"\n        )\n        self.assertEqual(\n            prepopulated_fields_json[0][\"dependency_ids\"], [\"#id_first_name\", \"#id_last_name\"]\n        )\n        self.assertEqual(\n            prepopulated_fields_json[0][\"dependency_list\"], [\"first_name\", \"last_name\"]\n        )\n        self.assertEqual(\n            prepopulated_fields_json[0][\"maxLength\"], 150\n        )\n        self.assertFalse(\n            prepopulated_fields_json[0][\"allowUnicode\"]\n        )\n", "    def test_prepopulated_fields_js(self):\n        \"\"\"\n        prepopulated_fields_js should correctly create JSON data for prepopulated fields.\n        \"\"\"\n        request = self.request_factory.get(\n            reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n        )\n        request.user = self.superuser\n        admin = UserAdmin(User, site)\n        extra_context = {\n            \"adminform\": type('AdminForm', (object,), {\n                \"prepopulated_fields\": [\n                    {\n                        \"field\": type('Field', (object,), {\n                            \"auto_id\": \"id_username\",\n                            \"name\": \"username\",\n                            \"field\": type('Field', (object,), {\"max_length\": 150, \"allow_unicode\": False})\n                        })(),\n                        \"dependencies\": [\n                            type('Field', (object,), {\"auto_id\": \"id_first_name\", \"name\": \"first_name\"}),\n                            type('Field', (object,), {\"auto_id\": \"id_last_name\", \"name\": \"last_name\"}),\n                        ],\n                    },\n                ]\n            })(),\n            \"inline_admin_formsets\": []\n        }\n        context = prepopulated_fields_js(extra_context)\n        self.assertIn(\"prepopulated_fields_json\", context)\n        prepopulated_fields_json = json.loads(context[\"prepopulated_fields_json\"])\n        self.assertEqual(len(prepopulated_fields_json), 1)\n        self.assertEqual(prepopulated_fields_json[0][\"id\"], \"#id_username\")\n        self.assertEqual(prepopulated_fields_json[0][\"name\"], \"username\")\n        self.assertEqual(prepopulated_fields_json[0][\"dependency_ids\"], [\"#id_first_name\", \"#id_last_name\"])\n        self.assertEqual(prepopulated_fields_json[0][\"dependency_list\"], [\"first_name\", \"last_name\"])\n        self.assertEqual(prepopulated_fields_json[0][\"maxLength\"], 150)\n        self.assertEqual(prepopulated_fields_json[0][\"allowUnicode\"], False)\n", "    def test_prepopulated_fields_js(self):\n        \"\"\"\n        prepopulated_fields_js should correctly build context with\n        prepopulated fields and their dependencies.\n        \"\"\"\n        class MockField:\n                self.auto_id = auto_id\n                self.name = name\n                self.field = self\n                self.max_length = max_length\n                self.allow_unicode = allow_unicode\n\n        class MockAdminForm:\n                self.prepopulated_fields = prepopulated_fields\n\n        admin_form = MockAdminForm([\n            {\n                \"field\": MockField(\"id_title\", \"title\"),\n                \"dependencies\": [MockField(\"id_slug\", \"slug\")]\n            }\n        ])\n\n        context = {\n            \"adminform\": admin_form,\n            \"inline_admin_formsets\": []\n        }\n\n        updated_context = prepopulated_fields_js(context)\n\n        self.assertIn(\"prepopulated_fields_json\", updated_context)\n        prepopulated_fields_json = json.loads(updated_context[\"prepopulated_fields_json\"])\n        self.assertEqual(len(prepopulated_fields_json), 1)\n        self.assertEqual(prepopulated_fields_json[0][\"id\"], \"#id_title\")\n        self.assertEqual(prepopulated_fields_json[0][\"name\"], \"title\")\n        self.assertEqual(prepopulated_fields_json[0][\"dependency_ids\"], [\"#id_slug\"])\n        self.assertEqual(prepopulated_fields_json[0][\"dependency_list\"], [\"slug\"])\n        self.assertEqual(prepopulated_fields_json[0][\"maxLength\"], 50)\n        self.assertEqual(prepopulated_fields_json[0][\"allowUnicode\"], False)\n", "    def test_prepopulated_fields_js(self):\n        \"\"\"\n        prepopulated_fields_js should properly format and return JSON for prepopulated fields.\n        \"\"\"\n        class MockField:\n                self.auto_id = auto_id\n                self.name = name\n                self.field = self\n                self.max_length = max_length\n                self.allow_unicode = allow_unicode\n\n        class MockAdminForm:\n                self.prepopulated_fields = prepopulated_fields\n\n        class MockInlineAdminForm:\n                self.original = original\n                self.prepopulated_fields = prepopulated_fields\n\n        class MockInlineAdminFormset:\n                self.forms = forms\n\n        context = {\n            \"adminform\": MockAdminForm(\n                [\n                    {\"field\": MockField(\"id_title\", \"title\"), \"dependencies\": [MockField(\"id_slug\", \"slug\")]}\n                ]\n            ),\n            \"inline_admin_formsets\": [\n                MockInlineAdminFormset(\n                    [\n                        MockInlineAdminForm(\n                            None,  # original is None for new inline\n                            [\n                                {\"field\": MockField(\"id_description\", \"description\"), \"dependencies\": [MockField(\"id_title\", \"title\")]}\n                            ]\n                        ),\n                        MockInlineAdminForm(\n                            True,  # existing inline, should be ignored\n                            [\n                                {\"field\": MockField(\"id_summary\", \"summary\"), \"dependencies\": [MockField(\"id_title\", \"title\")]}\n                            ]\n                        ),\n                    ]\n                )\n            ],\n        }\n\n        expected_json = json.dumps([\n            {\n                \"id\": \"#id_title\",\n                \"name\": \"title\",\n                \"dependency_ids\": [\"#id_slug\"],\n                \"dependency_list\": [\"slug\"],\n                \"maxLength\": 50,\n                \"allowUnicode\": False,\n            },\n            {\n                \"id\": \"#id_description\",\n                \"name\": \"description\",\n                \"dependency_ids\": [\"#id_title\"],\n                \"dependency_list\": [\"title\"],\n                \"maxLength\": 50,\n                \"allowUnicode\": False,\n            }\n        ])\n\n        template_context = prepopulated_fields_js(context)\n        self.assertEqual(template_context[\"prepopulated_fields_json\"], expected_json)\n"], "sample_86": ["def test_record_property_with_special_chars(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_property(\"special_key\", \"<&'\\\">\")\n    \"\"\"\n    )\n    result, dom = runandparse(testdir, \"-rw\")\n    node = dom.find_first_by_tag(\"testsuite\")\n    tnode = node.find_first_by_tag(\"testcase\")\n    psnode = tnode.find_first_by_tag(\"properties\")\n    pnode = psnode.find_first_by_tag(\"property\")\n    pnode.assert_attr(name=\"special_key\", value=\"<&'\\\">\")\n", "def test_bin_xml_escape():\n    from _pytest.junitxml import bin_xml_escape\n    # Test escaping of invalid XML characters\n    invalid_chars = \"\\x00\\x01\\x02\\x0B\\x0C\\x0E\\x19\\xD800\\xDFFF\\xFFFE\\x0FFFF\"\n    escaped = bin_xml_escape(invalid_chars)\n    assert \"#x00\" in escaped\n    assert \"#x01\" in escaped\n    assert \"#x02\" in escaped\n    assert \"#x0B\" in escaped\n    assert \"#x0C\" in escaped\n    assert \"#x0E\" in escaped\n    assert \"#x19\" in escaped\n    assert \"#xD800\" in escaped\n    assert \"#xDFFF\" in escaped\n    assert \"#xFFFE\" in escaped\n    assert \"#x0FFFF\" in escaped\n\n    # Test valid XML characters remain unchanged\n    valid_chars = \"\\x09\\x0A\\x20\\xD7FF\\xE000\\xFFFD\\x10000\\x10FFFF\"\n    escaped_valid = bin_xml_escape(valid_chars)\n    assert escaped_valid == valid_chars\n", "    def test_add_global_property(self, testdir):\n        path = testdir.tmpdir.join(\"test_add_global_property.xml\")\n        log = LogXML(str(path), None)\n\n        class Report(BaseReport):\n            sections = []\n            nodeid = \"test_node_id\"\n\n        log.pytest_sessionstart()\n        log.add_global_property(\"key\", \"value\")\n        log.pytest_sessionfinish()\n\n        dom = minidom.parse(str(path))\n        properties = dom.getElementsByTagName(\"properties\")\n        assert properties.length == 1, \"There must be one <properties> node\"\n\n        property_list = dom.getElementsByTagName(\"property\")\n        assert property_list.length == 1, \"There must be one property node\"\n        property_node = property_list[0]\n        assert property_node.getAttribute(\"name\") == \"key\", \"Property name should be 'key'\"\n        assert property_node.getAttribute(\"value\") == \"value\", \"Property value should be 'value'\"\n", "def test_multiple_testcases_with_same_name(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            assert 0\n        class TestClass(object):\n                assert 1\n        \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 1\n    nodes = dom.find_by_tag(\"testcase\")\n    assert len(nodes) == 2\n    nodes[0].assert_attr(classname=\"test_multiple_testcases_with_same_name\", name=\"test_func\")\n    nodes[1].assert_attr(classname=\"test_multiple_testcases_with_same_name.TestClass\", name=\"test_func\")\n", "def test_bin_xml_escape():\n    from _pytest.junitxml import bin_xml_escape\n    invalid_str = \"invalid\\x00string\"\n    escaped_str = bin_xml_escape(invalid_str).uniobj\n    assert \"#x00\" in escaped_str\n    assert \"invalid\" in escaped_str\n    assert \"string\" in escaped_str\n"], "sample_76": ["def test_polynomial_order(self, df):\n\n    groupby = GroupBy([\"group\"])\n    res = PolyFit(order=3)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n\n    assert_array_equal(res.columns, [\"x\", \"y\"])\n\n    grid = np.linspace(df[\"x\"].min(), df[\"x\"].max(), 100)\n    assert_array_equal(res[\"x\"], grid)\n    # For a cubic polynomial, the fourth derivative should be zero\n    assert_array_almost_equal(\n        res[\"y\"].diff().diff().diff().diff().dropna(), np.zeros(grid.size - 4)\n    )\n", "def test_different_orders(self, df):\n\n    groupby = GroupBy([\"group\"])\n    orders = [1, 2, 3, 4]\n    gridsize = 100\n    \n    for order in orders:\n        res = PolyFit(order=order, gridsize=gridsize)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n        \n        assert res.columns.to_list() == [\"x\", \"y\"]\n        \n        grid = np.linspace(df[\"x\"].min(), df[\"x\"].max(), gridsize)\n        assert_array_equal(res[\"x\"], grid)\n        if order == 1:\n            assert_array_almost_equal(\n                res[\"y\"].diff().diff().dropna(), np.zeros(grid.size - 2)\n            )\n        else:\n            assert res[\"y\"].diff().diff().dropna().abs().gt(0).all()\n", "    def test_high_order_polynomial(self, df):\n        groupby = GroupBy([\"group\"])\n        high_order = 10\n        res = PolyFit(order=high_order, gridsize=100)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n\n        assert_array_equal(res.columns, [\"x\", \"y\"])\n\n        grid = np.linspace(df[\"x\"].min(), df[\"x\"].max(), 100)\n        assert_array_equal(res[\"x\"], grid)\n        \n        # Check if polynomial curve is correctly fitted by examining the residuals\n        fit_y = np.polyval(np.polyfit(df[\"x\"], df[\"y\"], high_order), res[\"x\"])\n        residuals = res[\"y\"] - fit_y\n        assert np.all(np.abs(residuals) < 1e-1)\n", "def test_varying_order(self, df):\n    \n    groupby = GroupBy([\"group\"])\n    for order in [1, 2, 3]:\n        res = PolyFit(order=order, gridsize=100)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n        \n        assert_array_equal(res.columns, [\"x\", \"y\"])\n        \n        grid = np.linspace(df[\"x\"].min(), df[\"x\"].max(), 100)\n        assert_array_equal(res[\"x\"], grid)\n        assert res[\"y\"].diff().diff().dropna().abs().gt(0).all()\n", "def test_high_order_polynomial(self, df):\n\n    groupby = GroupBy([\"group\"])\n    high_order = 10\n    res = PolyFit(order=high_order, gridsize=100)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n\n    assert_array_equal(res.columns, [\"x\", \"y\"])\n\n    grid = np.linspace(df[\"x\"].min(), df[\"x\"].max(), 100)\n    assert_array_equal(res[\"x\"], grid)\n\n    # Check that the polynomial fit has the expected number of coefficients\n    for part in res.groupby(\"group\"):\n        p = np.polyfit(part[1][\"x\"], part[1][\"y\"], high_order)\n        assert len(p) == high_order + 1\n"], "sample_19": ["    def test_get_safe_settings_filters_sensitive_data(self):\n        \"\"\"\n        Ensure that get_safe_settings filters out sensitive settings.\n        \"\"\"\n        with self.settings(API_KEY='should not be displayed', NORMAL_SETTING='displayed'):\n            reporter_filter = SafeExceptionReporterFilter()\n            safe_settings = reporter_filter.get_safe_settings()\n            self.assertEqual(safe_settings['NORMAL_SETTING'], 'displayed')\n            self.assertEqual(safe_settings['API_KEY'], reporter_filter.cleansed_substitute)\n", "    def test_cleanse_setting_callable(self):\n        \"\"\"\n        Ensure that callable settings are wrapped with CallableSettingWrapper.\n        \"\"\"\n            return \"This should be wrapped\"\n        reporter_filter = SafeExceptionReporterFilter()\n        cleansed = reporter_filter.cleanse_setting('CALLABLE_SETTING', callable_setting)\n        self.assertIsInstance(cleansed, CallableSettingWrapper)\n        self.assertEqual(repr(cleansed), repr(callable_setting))\n", "    def test_cleanse_setting_nested_dict(self):\n        \"\"\"Test cleansing sensitive keys within a nested dictionary\"\"\"\n        reporter_filter = SafeExceptionReporterFilter()\n        nested_dict = {\n            'outer': {\n                'inner_password': 'super_secret',\n                'inner_key': 'value'\n            },\n            'password': 'outer_secret'\n        }\n        cleansed = reporter_filter.cleanse_setting('SETTING_NAME', nested_dict)\n        expected = {\n            'outer': {\n                'inner_password': reporter_filter.cleansed_substitute,\n                'inner_key': 'value'\n            },\n            'password': reporter_filter.cleansed_substitute\n        }\n        self.assertEqual(cleansed, expected)\n", "    def setUp(self):\n        self.filter = SafeExceptionReporterFilter()\n", "    def setUp(self):\n        self.filter = SafeExceptionReporterFilter()\n"], "sample_118": ["def test_ccode_reserved_function_names():\n    func_names = symbols('sin cos tan', cls=Dummy)\n    expr = func_names[0](x) + func_names[1](x) + func_names[2](x)\n    assert ccode(expr) == 'sin_(x) + cos_(x) + tan_(x)'\n    assert ccode(expr, reserved_word_suffix='_unreserved') == 'sin_unreserved(x) + cos_unreserved(x) + tan_unreserved(x)'\n    with raises(ValueError):\n        ccode(expr, error_on_reserved=True)\n", "def test_ccode_AugmentedAssignment():\n    expr = aug_assign(x, '+', y * z)\n    assert ccode(expr) == 'x += y*z;'\n    expr = aug_assign(x, '-', y / z)\n    assert ccode(expr) == 'x -= y/z;'\n    expr = aug_assign(x, '*', y + z)\n    assert ccode(expr) == 'x *= y + z;'\n    expr = aug_assign(x, '/', y - z)\n    assert ccode(expr) == 'x /= y - z;'\n", "def test_ccode_TensorSymbol():\n    from sympy.tensor import tensorcontraction, tensorsymmetry\n    from sympy import TensorType, TensorIndexType\n\n    # Define tensor type and symmetry\n    T = TensorType([TensorIndexType('T')]*4, tensorsymmetry([2, 2]))\n    A = T('A')\n\n    # Define tensor expression\n    expr = tensorcontraction(A, (0, 1))\n\n    # Verify the generated C code for tensor contraction\n    assert ccode(expr) == \"A[T__contraction_0]\"\n\n    # Ensure proper handling of tensor contraction in loops\n    assert ccode(expr, assign_to='B') == (\n        \"for (int T__contraction_0=0; T__contraction_0<4; T__contraction_0++){\\n\"\n        \"   B = A[T__contraction_0];\\n\"\n        \"}\"\n    )\n", "def test_ccode_AugmentedAssignment():\n    assert ccode(aug_assign(x, '*', y)) == 'x *= y;'\n    assert ccode(aug_assign(z, '-', x + y)) == 'z -= x + y;'\n    assert ccode(aug_assign(x, '/', 2)) == 'x /= 2;'\n    assert ccode(aug_assign(z, '%', y)) == 'z %= y;'\n", "def test_ccode_MatrixElement():\n    A = MatrixSymbol('A', 3, 3)\n    assert ccode(A[1, 2]) == 'A[5]'\n    assert ccode(A[0, 0]) == 'A[0]'\n    assert ccode(A[2, 1]) == 'A[7]'\n"], "sample_152": ["def test_array_arithmetic_operations():\n    for ArrayType in array_types:\n        a = ArrayType([1, 2, 3, 4], (2, 2))\n        b = ArrayType([4, 3, 2, 1], (2, 2))\n\n        # Test addition\n        c = a + b\n        assert c.tolist() == [[5, 5], [5, 5]]\n\n        # Test subtraction\n        d = a - b\n        assert d.tolist() == [[-3, -1], [1, 3]]\n\n        # Test scalar multiplication\n        e = a * 2\n        assert e.tolist() == [[2, 4], [6, 8]]\n\n        # Test scalar division\n        f = a / 2\n        assert f.tolist() == [[0.5, 1], [1.5, 2]]\n\n        # Test negation\n        g = -a\n        assert g.tolist() == [[-1, -2], [-3, -4]]\n\n        # Test equality\n        h = ArrayType([1, 2, 3, 4], (2, 2))\n        assert a == h\n        assert a != b\n", "def test_array_creation_and_properties():\n    # Test creating arrays with different shapes and properties\n    a = MutableDenseNDimArray.zeros(2, 3, 4)\n    assert a.shape == (2, 3, 4)\n    assert len(a) == 24\n    assert a.tolist() == [[[0]*4]*3]*2\n\n    b = MutableDenseNDimArray([1, 2, 3, 4, 5, 6], (2, 3))\n    assert b.shape == (2, 3)\n    assert len(b) == 6\n    assert b.tolist() == [[1, 2, 3], [4, 5, 6]]\n\n    c = MutableDenseNDimArray(Matrix([[1, 2], [3, 4]]))\n    assert c.shape == (2, 2)\n    assert len(c) == 4\n    assert c.tolist() == [[1, 2], [3, 4]]\n\n    d = MutableDenseNDimArray([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n    assert d.shape == (2, 2, 2)\n    assert len(d) == 8\n    assert d.tolist() == [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n\n    e = ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    assert e.shape == (2, 2)\n    assert len(e) == 4\n    assert e.tolist() == [[1, 2], [3, 4]]\n\n    f = MutableSparseNDimArray([1, 2, 3, 4], (2, 2))\n    assert f.shape == (2, 2)\n    assert len(f) == 4\n    assert f.tolist() == [[1, 2], [3, 4]]\n\n    g = ImmutableSparseNDimArray([1, 2, 3, 4], (2, 2))\n    assert g.shape == (2, 2)\n    assert len(g) == 4\n    assert g.tolist() == [[1, 2], [3, 4]]\n", "def test_ndim_array_creation():\n    for ArrayType in array_types:\n        # Create an N-dim array from a list\n        a = ArrayType([[1, 2], [3, 4]])\n        assert a.shape == (2, 2)\n        assert a.tolist() == [[1, 2], [3, 4]]\n\n        # Create an N-dim array from a flat list with dimension shape\n        b = ArrayType([1, 2, 3, 4, 5, 6], (2, 3))\n        assert b.shape == (2, 3)\n        assert b.tolist() == [[1, 2, 3], [4, 5, 6]]\n\n        # Create an N-dim array from a matrix\n        c = Matrix([[1, 2], [3, 4]])\n        d = ArrayType(c)\n        assert d.shape == (2, 2)\n        assert d.tolist() == [[1, 2], [3, 4]]\n", "def test_ndimarray_addition():\n    a = MutableDenseNDimArray([1, 2], (2,))\n    b = MutableDenseNDimArray([3, 4], (2,))\n    c = a + b\n    assert c == MutableDenseNDimArray([4, 6], (2,))\n\n    a = MutableDenseNDimArray([[1, 2], [3, 4]])\n    b = MutableDenseNDimArray([[5, 6], [7, 8]])\n    c = a + b\n    assert c == MutableDenseNDimArray([[6, 8], [10, 12]])\n\n    a = ImmutableDenseNDimArray([1, 2], (2,))\n    b = ImmutableDenseNDimArray([3, 4], (2,))\n    c = a + b\n    assert c == ImmutableDenseNDimArray([4, 6], (2,))\n\n    a = ImmutableDenseNDimArray([[1, 2], [3, 4]])\n    b = ImmutableDenseNDimArray([[5, 6], [7, 8]])\n    c = a + b\n    assert c == ImmutableDenseNDimArray([[6, 8], [10, 12]])\n", "def test_array_creation_and_shape():\n    for ArrayType in array_types:\n        # Test creation from list\n        a = ArrayType([1, 2, 3, 4])\n        assert a.shape == (4,)\n        assert a.tolist() == [1, 2, 3, 4]\n\n        # Test creation from nested list\n        a = ArrayType([[1, 2], [3, 4]])\n        assert a.shape == (2, 2)\n        assert a.tolist() == [[1, 2], [3, 4]]\n\n        # Test creation from tuple\n        a = ArrayType((1, 2, 3, 4))\n        assert a.shape == (4,)\n        assert a.tolist() == [1, 2, 3, 4]\n\n        # Test creation from nested tuple\n        a = ArrayType(((1, 2), (3, 4)))\n        assert a.shape == (2, 2)\n        assert a.tolist() == [[1, 2], [3, 4]]\n\n        # Test creation with specified shape\n        a = ArrayType([1, 2, 3, 4], shape=(2, 2))\n        assert a.shape == (2, 2)\n        assert a.tolist() == [[1, 2], [3, 4]]\n\n        # Test creation from another NDimArray\n        b = ArrayType(a)\n        assert b.shape == (2, 2)\n        assert b.tolist() == [[1, 2], [3, 4]]\n\n        # Test creation from an empty list\n        a = ArrayType([])\n        assert a.shape == (0,)\n        assert a.tolist() == []\n"], "sample_143": ["def test_pretty_imaginary_unit_settings():\n    # Test imaginary_unit setting for PrettyPrinter\n    assert upretty(I, imaginary_unit='j') == '\u2149'\n    assert upretty(I, imaginary_unit='i') == '\u2148'\n    assert pretty(I, use_unicode=False, imaginary_unit='j') == 'I'\n    assert pretty(I, use_unicode=False, imaginary_unit='i') == 'I'\n    raises(TypeError, lambda: pretty(I, imaginary_unit=1))\n    raises(ValueError, lambda: pretty(I, imaginary_unit='k'))\n", "def test_prettyprinter_imaginary_unit_validation():\n    # Test validation for imaginary_unit setting\n    with raises(TypeError):\n        PrettyPrinter({\"imaginary_unit\": 1})  # Should raise TypeError\n    with raises(ValueError):\n        PrettyPrinter({\"imaginary_unit\": \"k\"})  # Should raise ValueError\n", "def test_prettyImaginaryUnitOption():\n    # Test imaginary_unit setting in doprint method of PrettyPrinter\n    expr = 1 + I\n    assert upretty(expr) == \"1 + \u2148\"\n    assert upretty(expr, imaginary_unit='j') == \"1 + \u2149\"\n    assert pretty(expr) == \"1 + I\"\n    assert pretty(expr, imaginary_unit='j') == \"1 + j\"\n\n    expr = I\n    assert upretty(expr) == \"\u2148\"\n    assert upretty(expr, imaginary_unit='j') == \"\u2149\"\n    assert pretty(expr) == \"I\"\n    assert pretty(expr, imaginary_unit='j') == \"j\"\n", "def test_pretty_symbols_different_styles():\n    # Tests for different symbol styles\n\n    # Regular symbols\n    alpha = Symbol('alpha')\n    beta = Symbol('beta')\n    gamma = Symbol('gamma')\n\n    assert pretty(alpha) == 'alpha'\n    assert pretty(beta) == 'beta'\n    assert pretty(gamma) == 'gamma'\n\n    assert upretty(alpha) == '\u03b1'\n    assert upretty(beta) == '\u03b2'\n    assert upretty(gamma) == '\u03b3'\n\n    # Subscript and superscript symbols\n    subscripted = Symbol('alpha_beta')\n    superscripted = Symbol('beta^gamma')\n\n    assert pretty(subscripted) == 'alpha_beta'\n    assert pretty(superscripted) == 'beta^gamma'\n\n    assert upretty(subscripted) == '\u03b1\u1d66'\n    assert upretty(superscripted) == '\u03b2\u1d5e'\n\n    # Symbols with accents\n    dotted = Symbol('alpha_dot')\n    double_dotted = Symbol('beta_ddot')\n\n    assert pretty(dotted) == 'alpha_dot'\n    assert pretty(double_dotted) == 'beta_ddot'\n\n    assert upretty(dotted) == '\u03b1\u0307'\n    assert upretty(double_dotted) == '\u03b2\u0308'\n\n    # Complex symbols with multiple subscripts and superscripts\n    complex_symbol = Symbol('alpha^beta_gamma')\n\n    assert pretty(complex_symbol) == 'alpha^beta_gamma'\n    assert upretty(complex_symbol) == '\u03b1\u1d5d\u1d67'\n\n    # Greek symbols with subscripts and superscripts\n    greek_sub_sup = Symbol('gamma_delta^epsilon')\n\n    assert pretty(greek_sub_sup) == 'gamma_delta^epsilon'\n    assert upretty(greek_sub_sup) == '\u03b3\u1d5f\u1d49'\n\n    # Symbols with modifiers\n    mathring = Symbol('alpha_mathring')\n    check = Symbol('beta_check')\n\n    assert pretty(mathring) == 'alpha_mathring'\n    assert pretty(check) == 'beta_check'\n\n    assert upretty(mathring) == '\u03b1\u030a'\n    assert upretty(check) == '\u03b2\u030c'\n", "def test_pretty_Printer():\n    printer = PrettyPrinter()\n\n    class TestClass:\n            return \"TestClass\"\n\n    obj = TestClass()\n    \n    # Test emptyPrinter method\n    assert printer.emptyPrinter(obj) == prettyForm(\"TestClass\")\n\n    # Test _use_unicode property\n    assert printer._use_unicode is False  # Default settings should use ASCII\n\n    # Test _print_stringPict method\n    assert printer._print_stringPict(\"test\") == \"test\"\n\n    # Test _print_basestring method\n    assert printer._print_basestring(\"test\") == prettyForm(\"test\")\n\n    # Test _print_Symbol method\n    sym = Symbol(\"alpha\")\n    assert printer._print_Symbol(sym) == prettyForm(\"alpha\")\n\n    # Test _print_Float method\n    fl = Float(\"1.234567890123456789\")\n    assert printer._print_Float(fl) == prettyForm(\"1.23456789012346\")\n\n    # Test doprint method\n    assert printer.doprint(sym) == \"alpha\"\n\n    # Test doprint with a different settings for use_unicode\n    printer._settings[\"use_unicode\"] = True\n    assert printer.doprint(sym) == \"\u03b1\"\n"], "sample_154": ["def test_issue_additional_math():\n    # Test additional mathematical functions for coverage\n    f_exp = lambdify(x, exp(x), modules=\"math\")\n    f_ln = lambdify(x, sympy.ln(x), modules=\"math\")\n    f_sqrt = lambdify(x, sqrt(x), modules=\"math\")\n    assert f_exp(1) == math.exp(1)\n    assert f_ln(math.e) == 1\n    assert f_sqrt(4) == 2\n\n    if numpy:\n        f_exp_numpy = lambdify(x, exp(x), modules=\"numpy\")\n        f_ln_numpy = lambdify(x, sympy.ln(x), modules=\"numpy\")\n        f_sqrt_numpy = lambdify(x, sqrt(x), modules=\"numpy\")\n        assert f_exp_numpy(1) == numpy.exp(1)\n        assert f_ln_numpy(numpy.e) == 1\n        assert f_sqrt_numpy(4) == 2\n", "def test_implemented_function_errors():\n        raise RuntimeError(\"This function always fails.\")\n\n    f = implemented_function('faulty_func', faulty_func)\n    g = lambdify(x, f(x))\n\n    with raises(RuntimeError, match=\"This function always fails.\"):\n        g(42)\n", "def test_custom_namespace():\n    custom_sqrt = lambda x: \"custom_sqrt\"\n    custom_sin = lambda x: \"custom_sin\"\n    custom_cos = lambda x: \"custom_cos\"\n\n    custom_namespace = {\n        'sqrt': custom_sqrt,\n        'sin': custom_sin,\n        'cos': custom_cos\n    }\n\n    f_sqrt = lambdify(x, sqrt(x), custom_namespace)\n    f_sin = lambdify(x, sin(x), custom_namespace)\n    f_cos = lambdify(x, cos(x), custom_namespace)\n\n    assert f_sqrt(4) == \"custom_sqrt\"\n    assert f_sin(1) == \"custom_sin\"\n    assert f_cos(1) == \"custom_cos\"\n\n    # Ensure default behavior is not altered\n    default_f_sqrt = lambdify(x, sqrt(x), \"math\")\n    default_f_sin = lambdify(x, sin(x), \"math\")\n    default_f_cos = lambdify(x, cos(x), \"math\")\n\n    assert default_f_sqrt(4) == 2.0\n    assert default_f_sin(math.pi / 2) == 1.0\n    assert default_f_cos(math.pi) == -1.0\n", "def test_lambda_with_list_of_expressions():\n    f = lambdify([x, y], [x + y, x * y, x - y, x / y])\n    result = f(4, 2)\n    assert result == [6, 8, 2, 2]\n", "def test_lambdify_with_import_module():\n    from sympy import sin, symbols\n    x = symbols('x')\n    \n    # Test with `import_module` usage\n    expr = sin(x)\n    modules = [{'sin': sin}, 'numpy', 'math', 'mpmath', 'scipy', 'import_module(\"numpy\")']\n    f = lambdify(x, expr, modules=modules)\n    \n    # Check if the function evaluates correctly using different modules\n    assert abs(f(0.5) - sin(0.5)) < 1e-10\n\n    # Ensure the function handles the 'import_module' usage\n    assert 'numpy' in f.__globals__\n    assert f.__globals__['sin'] == sin\n"], "sample_51": ["    def test_directory_index_custom_template_not_found(self):\n        \"\"\"\n        Test that if custom template is not found, the default directory index template is used.\n        \"\"\"\n        with override_settings(TEMPLATES=[\n            {\n                \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n                \"OPTIONS\": {\n                    \"loaders\": [\n                        (\n                            \"django.template.loaders.locmem.Loader\",\n                            {},\n                        ),\n                    ],\n                },\n            }\n        ]):\n            response = self.client.get(\"/%s/\" % self.prefix)\n            self.assertContains(response, \"Index of ./\")\n            # Directories have a trailing slash.\n            self.assertIn(\"subdir/\", response.context[\"file_list\"])\n", "    def test_directory_without_index_and_no_show_indexes(self):\n        \"\"\"Test accessing a directory without an index when show_indexes is False.\"\"\"\n        response = self.client.get(\"/%s/subdir_no_index/\" % self.prefix)\n        self.assertEqual(response.status_code, 404)\n", "def test_directory_index_template_does_not_exist(self):\n        \"\"\"Test the fallback to the default template when the template does not exist.\"\"\"\n        with self.settings(\n            TEMPLATES=[\n                {\n                    \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n                    \"OPTIONS\": {\n                        \"loaders\": [\n                            (\n                                \"django.template.loaders.locmem.Loader\",\n                                {},\n                            ),\n                        ],\n                    },\n                }\n            ]\n        ):\n            response = self.client.get(\"/%s/\" % self.prefix)\n            self.assertContains(response, \"Index of ./\")\n            self.assertIn(\"subdir/\", response.context[\"file_list\"])\n", "    def test_directory_not_allowed(self):\n        \"\"\"\n        The static view should raise a 404 error if a directory is requested and show_indexes is False.\n        \"\"\"\n        response = self.client.get(\"/%s/subdir/\" % self.prefix, {'show_indexes': False})\n        self.assertEqual(response.status_code, 404)\n        self.assertContains(response, \"Directory indexes are not allowed here.\", status_code=404)\n", "    def test_directory_index_template_does_not_exist(self):\n        \"\"\"Test that the default directory index template is used when the custom template does not exist.\"\"\"\n        with override_settings(\n            TEMPLATES=[\n                {\n                    \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n                    \"OPTIONS\": {\n                        \"loaders\": [\n                            (\n                                \"django.template.loaders.locmem.Loader\",\n                                {},\n                            ),\n                        ],\n                    },\n                }\n            ]\n        ):\n            response = self.client.get(\"/%s/\" % self.prefix)\n            self.assertContains(response, \"Index of ./\")\n            self.assertIn(\"subdir/\", response.context[\"file_list\"])\n"], "sample_17": ["    def test_create_test_db_verbosity_zero(self):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = False\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        with mock.patch.object(creation, '_create_test_db') as mock_create_test_db, \\\n             mock.patch.object(creation, 'log') as mock_log:\n            creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n            mock_create_test_db.assert_called_once_with(verbosity=0, autoclobber=True, keepdb=False)\n            mock_log.assert_not_called()\n        with mock.patch.object(creation, '_destroy_test_db'):\n            creation.destroy_test_db(old_database_name, verbosity=0)\n", "    def test_create_test_db(self, mocked_call_command):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                test_db_name = creation.create_test_db(verbosity=1, autoclobber=True, serialize=True, keepdb=False)\n            self.assertEqual(test_db_name, TEST_DATABASE_PREFIX + old_database_name)\n            self.assertEqual(\n                settings.DATABASES[test_connection.alias][\"NAME\"],\n                TEST_DATABASE_PREFIX + old_database_name\n            )\n            self.assertEqual(\n                test_connection.settings_dict[\"NAME\"],\n                TEST_DATABASE_PREFIX + old_database_name\n            )\n            mocked_call_command.assert_any_call(\n                'migrate',\n                verbosity=0,\n                interactive=False,\n                database=test_connection.alias,\n                run_syncdb=True,\n            )\n            mocked_call_command.assert_any_call('createcachetable', database=test_connection.alias)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=1)\n", "    def test_create_test_db(self, mocked_close, mocked_call_command):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        test_database_name = creation._get_test_db_name()\n\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                with mock.patch.object(creation, 'serialize_db_to_string', return_value='{}'):\n                    created_db_name = creation.create_test_db(verbosity=1, autoclobber=True, serialize=True)\n                    self.assertEqual(created_db_name, test_database_name)\n                    self.assertEqual(test_connection.settings_dict['NAME'], test_database_name)\n                    mocked_close.assert_called_once()\n                    mocked_call_command.assert_any_call('migrate', verbosity=0, interactive=False, database=test_connection.alias, run_syncdb=True)\n                    mocked_call_command.assert_any_call('createcachetable', database=test_connection.alias)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n", "    def test_clone_test_db(self, mocked_clone_test_db):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        try:\n            creation.clone_test_db(suffix='clone_suffix', verbosity=0, keepdb=True)\n            mocked_clone_test_db.assert_called_once_with('clone_suffix', verbosity=0, keepdb=True)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(verbosity=0, keepdb=True, suffix='clone_suffix')\n", "    def test_create_test_db_with_serialization(self, mocked_call_command):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                with mock.patch.object(creation, 'serialize_db_to_string', return_value=\"{}\") as mock_serialize:\n                    creation.create_test_db(verbosity=0, autoclobber=True, serialize=True)\n                    mock_serialize.assert_called_once()\n            mocked_call_command.assert_any_call('migrate', verbosity=0, interactive=False, database=test_connection.alias, run_syncdb=True)\n            mocked_call_command.assert_any_call('createcachetable', database=test_connection.alias)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_48": ["    def test_model_operation_init(self):\n        \"\"\"\n        Tests the initialization of a ModelOperation.\n        \"\"\"\n        operation = ModelOperation(name=\"TestModel\")\n        self.assertEqual(operation.name, \"TestModel\")\n", "    def test_create_model_with_options(self):\n        \"\"\"\n        Tests the CreateModel operation with various model options.\n        \"\"\"\n        # Define the operation with additional options\n        operation = migrations.CreateModel(\n            \"Pony\",\n            fields=[\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"pink\", models.IntegerField(default=1)),\n            ],\n            options={\n                \"verbose_name\": \"My Pony\",\n                \"verbose_name_plural\": \"My Ponies\",\n                \"permissions\": [(\"can_groom\", \"Can groom\")],\n                \"ordering\": [\"pink\"],\n            },\n        )\n        self.assertEqual(operation.describe(), \"Create model Pony\")\n        self.assertEqual(operation.migration_name_fragment, 'pony')\n        # Test the state alteration\n        project_state = ProjectState()\n        new_state = project_state.clone()\n        operation.state_forwards(\"test_crmo\", new_state)\n        self.assertEqual(new_state.models[\"test_crmo\", \"pony\"].name, \"Pony\")\n        self.assertEqual(len(new_state.models[\"test_crmo\", \"pony\"].fields), 2)\n        self.assertEqual(new_state.models[\"test_crmo\", \"pony\"].options[\"verbose_name\"], \"My Pony\")\n        self.assertEqual(new_state.models[\"test_crmo\", \"pony\"].options[\"verbose_name_plural\"], \"My Ponies\")\n        self.assertEqual(new_state.models[\"test_crmo\", \"pony\"].options[\"permissions\"], [(\"can_groom\", \"Can groom\")])\n        self.assertEqual(new_state.models[\"test_crmo\", \"pony\"].options[\"ordering\"], [\"pink\"])\n        # Test the database alteration\n        self.assertTableNotExists(\"test_crmo_pony\")\n        with connection.schema_editor() as editor:\n            operation.database_forwards(\"test_crmo\", editor, project_state, new_state)\n        self.assertTableExists(\"test_crmo_pony\")\n        # And test reversal\n        with connection.schema_editor() as editor:\n            operation.database_backwards(\"test_crmo\", editor, new_state, project_state)\n        self.assertTableNotExists(\"test_crmo_pony\")\n        # And deconstruction\n        definition = operation.deconstruct()\n        self.assertEqual(definition[0], \"CreateModel\")\n        self.assertEqual(definition[1], [])\n        self.assertEqual(sorted(definition[2].keys()), [\"fields\", \"name\", \"options\"])\n        self.assertEqual(definition[2][\"options\"][\"verbose_name\"], \"My Pony\")\n        self.assertEqual", "    def test_create_model_with_options(self):\n        \"\"\"\n        Tests the CreateModel operation with additional options.\n        \"\"\"\n        operation = migrations.CreateModel(\n            \"FancyPony\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"color\", models.CharField(max_length=20)),\n            ],\n            options={\n                \"ordering\": [\"color\"],\n                \"verbose_name\": \"Fancy Pony\",\n                \"permissions\": [(\"can_ride\", \"Can ride the pony\")],\n            },\n        )\n        self.assertEqual(operation.describe(), \"Create model FancyPony\")\n        self.assertEqual(operation.migration_name_fragment, 'fancypony')\n        # Test the state alteration\n        project_state = ProjectState()\n        new_state = project_state.clone()\n        operation.state_forwards(\"test_crmo_opt\", new_state)\n        self.assertEqual(new_state.models[\"test_crmo_opt\", \"fancypony\"].name, \"FancyPony\")\n        self.assertEqual(len(new_state.models[\"test_crmo_opt\", \"fancypony\"].fields), 2)\n        self.assertEqual(new_state.models[\"test_crmo_opt\", \"fancypony\"].options[\"ordering\"], [\"color\"])\n        self.assertEqual(new_state.models[\"test_crmo_opt\", \"fancypony\"].options[\"verbose_name\"], \"Fancy Pony\")\n        self.assertEqual(new_state.models[\"test_crmo_opt\", \"fancypony\"].options[\"permissions\"], [(\"can_ride\", \"Can ride the pony\")])\n        # Test the database alteration\n        self.assertTableNotExists(\"test_crmo_opt_fancypony\")\n        with connection.schema_editor() as editor:\n            operation.database_forwards(\"test_crmo_opt\", editor, project_state, new_state)\n        self.assertTableExists(\"test_crmo_opt_fancypony\")\n        # And test reversal\n        with connection.schema_editor() as editor:\n            operation.database_backwards(\"test_crmo_opt\", editor, new_state, project_state)\n        self.assertTableNotExists(\"test_crmo_opt_fancypony\")\n        # And deconstruction\n        definition = operation.deconstruct()\n        self.assertEqual(definition[0], \"CreateModel\")\n        self.assertEqual(definition[1], [])\n        self.assertEqual(sorted(definition[2]), [\"fields\", \"name\", \"options\"])\n", "    def test_create_model_with_options(self):\n        \"\"\"\n        Tests the CreateModel operation with custom options.\n        \"\"\"\n        operation = migrations.CreateModel(\n            \"Pony\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"pink\", models.IntegerField(default=1)),\n            ],\n            options={\n                \"verbose_name\": \"My Pony\",\n                \"permissions\": [(\"can_ride\", \"Can ride Pony\")],\n                \"db_table\": \"custom_pony_table\",\n            },\n        )\n        self.assertEqual(operation.describe(), \"Create model Pony\")\n        self.assertEqual(operation.migration_name_fragment, 'pony')\n        # Test the state alteration\n        project_state = ProjectState()\n        new_state = project_state.clone()\n        operation.state_forwards(\"test_crmo\", new_state)\n        self.assertEqual(new_state.models[\"test_crmo\", \"pony\"].name, \"Pony\")\n        self.assertEqual(len(new_state.models[\"test_crmo\", \"pony\"].fields), 2)\n        self.assertEqual(new_state.models[\"test_crmo\", \"pony\"].options[\"verbose_name\"], \"My Pony\")\n        self.assertEqual(new_state.models[\"test_crmo\", \"pony\"].options[\"permissions\"], [(\"can_ride\", \"Can ride Pony\")])\n        self.assertEqual(new_state.models[\"test_crmo\", \"pony\"].options[\"db_table\"], \"custom_pony_table\")\n        # Test the database alteration\n        self.assertTableNotExists(\"custom_pony_table\")\n        with connection.schema_editor() as editor:\n            operation.database_forwards(\"test_crmo\", editor, project_state, new_state)\n        self.assertTableExists(\"custom_pony_table\")\n        # And test reversal\n        with connection.schema_editor() as editor:\n            operation.database_backwards(\"test_crmo\", editor, new_state, project_state)\n        self.assertTableNotExists(\"custom_pony_table\")\n        # And deconstruction\n        definition = operation.deconstruct()\n        self.assertEqual(definition[0], \"CreateModel\")\n        self.assertEqual(definition[1], [])\n        self.assertEqual(sorted(definition[2]), [\"fields\", \"name\", \"options\"])\n", "    def test_create_model_with_duplicate_field_name_case_insensitive(self):\n        with self.assertRaisesMessage(ValueError, 'Found duplicate value PiNk in CreateModel fields argument.'):\n            migrations.CreateModel(\n                \"Pony\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\"pink\", models.TextField()),\n                    (\"PiNk\", models.IntegerField(default=1)),\n                ],\n            )\n"], "sample_124": ["def test_sinh_eval():\n    x = Symbol('x')\n    assert sinh(asinh(x)) == x\n    assert sinh(acosh(x)) == sqrt(x - 1) * sqrt(x + 1)\n    assert sinh(atanh(x)) == x / sqrt(1 - x**2)\n    assert sinh(acoth(x)) == 1 / (sqrt(x - 1) * sqrt(x + 1))\n", "def test_asech_infinities():\n    assert asech(oo) == I*pi/2\n    assert asech(-oo) == I*pi/2\n    assert asech(zoo) == nan\n", "def test_sech_expansion():\n    x, y = symbols('x,y')\n    assert sech(x+y).expand(trig=True) == sech(x) * sech(y) * (1 - tanh(x) * tanh(y))\n    assert sech(2*x).expand(trig=True) == sech(x)**2 * (1 - tanh(x)**2)\n    assert sech(3*x).expand(trig=True).expand() == sech(x)**3 * (1 - 3*tanh(x)**2 + tanh(x)**4)\n", "def test_rewrite_hyperbolics_as_exp():\n    x = Symbol('x')\n    expr = sinh(x) + cosh(x) + tanh(x) + coth(x)\n    rewritten_expr = _rewrite_hyperbolics_as_exp(expr)\n    assert rewritten_expr == sinh(x).rewrite(exp) + cosh(x).rewrite(exp) + tanh(x).rewrite(exp) + coth(x).rewrite(exp)\n", "def test_asech_infinities():\n    assert asech(oo) == I*pi/2\n    assert asech(-oo) == I*pi/2\n    assert asech(zoo) == nan\n"], "sample_149": ["def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n    assert monomial_ldiv((0, 0, 0), (0, 0, 0)) == (0, 0, 0)\n    assert monomial_ldiv((5, 5, 5), (5, 5, 5)) == (0, 0, 0)\n", "def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n", "def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n", "def test_term_div():\n    from sympy.polys.monomials import term_div\n    from sympy.polys.domains import ZZ, QQ\n\n    assert term_div(((3, 4, 1), 6), ((1, 2, 0), 2), ZZ) == ((2, 2, 1), 3)\n    assert term_div(((3, 4, 1), 6), ((1, 2, 0), 2), QQ) == ((2, 2, 1), QQ(3, 1))\n    assert term_div(((3, 4, 1), 6), ((1, 2, 0), 4), ZZ) is None\n    assert term_div(((3, 4, 1), 6), ((1, 2, 2), 2), ZZ) is None\n", "def test_monomial_deg():\n    assert monomial_deg((3, 4, 1)) == 8\n    assert monomial_deg((0, 0, 0)) == 0\n    assert monomial_deg((1, 1, 1)) == 3\n"], "sample_130": ["def test_lambdastr_function():\n    # Test the lambdastr function for different cases\n    from sympy.abc import x, y, z\n\n    # Single variable\n    result = lambdastr(x, x**2)\n    assert result == 'lambda x: (x**2)'\n\n    # Multiple variables\n    result = lambdastr((x, y, z), [z, y, x])\n    assert result == 'lambda x,y,z: ([z, y, x])'\n\n    # Nested arguments\n    result = lambdastr((x, (y, z)), x + y)\n    expected_result = 'lambda _0,_1: (lambda x,y,z: (x + y))(_0,_1[0],_1[1])'\n    assert result == expected_result\n\n    # Custom printer\n    class CustomPrinter:\n            return f\"custom_repr({expr})\"\n\n    result = lambdastr(x, x**2, printer=CustomPrinter())\n    assert result == 'lambda x: (custom_repr(x**2))'\n\n    # Ensure non-dummy variables are preserved\n    result = lambdastr((x, y), x + y, dummify=False)\n    assert result == 'lambda x,y: (x + y)'\n", "def test_mult_args_custom_function():\n    # Ensure that lambdify can handle multiple arguments with custom functions\n        return x + y - z\n\n    expr = custom_func(x, y, z)\n    f = lambdify((x, y, z), expr, {'custom_func': custom_func})\n    \n    assert f(1, 2, 3) == 0\n    assert f(3, 2, 1) == 4\n    assert f(-1, -2, -3) == 0\n", "def test_import_reload():\n    # Test that _import function properly reloads the module\n    from sympy.utilities.lambdify import _import, MODULES\n\n    # Backup original namespaces\n    original_math = MODULES[\"math\"][0].copy()\n\n    # Modify the math namespace\n    MODULES[\"math\"][0][\"dummy_key\"] = \"dummy_value\"\n    assert \"dummy_key\" in MODULES[\"math\"][0]\n\n    # Reload the math module\n    _import(\"math\", reload=True)\n\n    # Check that the namespace has been reset to its original state\n    assert \"dummy_key\" not in MODULES[\"math\"][0]\n\n    # Check that the reloaded namespace matches the original\n    assert MODULES[\"math\"][0] == original_math\n", "def test_custom_translations():\n    from sympy import gamma\n    custom_translations = {\n        \"gamma\": lambda x: x + 10  # Custom translation for testing\n    }\n    f = lambdify(x, gamma(x), modules=[custom_translations, \"sympy\"])\n    assert f(5) == 15  # Custom translation should add 10 to the input value\n", "def test_custom_function_with_unusual_symbols():\n    alpha_beta = symbols(r'\\alpha \\beta')\n    gamma_delta = symbols(r'\\gamma \\delta')\n    custom_func = implemented_function('custom_func', lambda x, y: x**2 + y**2)\n    expr = custom_func(alpha_beta, gamma_delta)\n    f = lambdify((alpha_beta, gamma_delta), expr)\n    assert f(2, 3) == 13\n"], "sample_113": ["def test_column_transformer_with_callable_remainder():\n    # test case where remainder is a callable that returns an estimator\n    X_array = np.array([[0, 1, 2], [2, 4, 6], [8, 6, 4]]).T\n\n        return DoubleTrans()\n\n    ct = ColumnTransformer(\n        [(\"trans\", Trans(), [0])], remainder=remainder_fn\n    )\n    \n    X_res_both = X_array.copy()\n    X_res_both[:, 1:3] *= 2\n\n    assert_array_equal(ct.fit_transform(X_array), X_res_both)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_both)\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == \"remainder\"\n    assert isinstance(ct.transformers_[-1][1], DoubleTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n", "def test_column_transformer_all_passthrough():\n    # Test the case where all transformers are 'passthrough'\n    X_array = np.array([[0, 1, 2], [2, 4, 6], [8, 6, 4]]).T\n\n    ct = ColumnTransformer(\n        [(\"trans1\", \"passthrough\", [0]), (\"trans2\", \"passthrough\", [1]), (\"trans3\", \"passthrough\", [2])]\n    )\n\n    assert_array_equal(ct.fit_transform(X_array), X_array)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_array)\n    assert len(ct.transformers_) == 3\n    assert ct.transformers_[-1][0] != \"remainder\"\n\n    # Test with remainder='passthrough'\n    ct = ColumnTransformer(\n        [(\"trans1\", \"passthrough\", [0]), (\"trans2\", \"passthrough\", [1])], remainder=\"passthrough\"\n    )\n\n    assert_array_equal(ct.fit_transform(X_array), X_array)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_array)\n    assert len(ct.transformers_) == 3\n    assert ct.transformers_[-1][0] == \"remainder\"\n    assert ct.transformers_[-1][1] == \"passthrough\"\n    assert_array_equal(ct.transformers_[-1][2], [2])\n", "def test_column_transformer_with_callable_remainder():\n    # Test that callable remainder can be used and applied correctly\n    X_array = np.array([[1, 2, 3], [4, 5, 6]]).T\n    X_res_both = np.array([[2, 3, 4], [5, 6, 7], [8, 9, 10]]).T\n\n        return X * 2\n\n    ct = ColumnTransformer(\n        [(\"trans1\", Trans(), [0])],\n        remainder=double_transformer\n    )\n    \n    assert_array_equal(ct.fit_transform(X_array), X_res_both)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_both)\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == \"remainder\"\n    assert callable(ct.transformers_[-1][1])\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n", "def test_column_transformer_with_callable_remainder():\n    # Test if ColumnTransformer works correctly with a callable for remainder\n    X = np.array([[0, 1, 2], [2, 4, 6]]).T\n\n        return StandardScaler().fit(X).transform(X)\n\n    ct = ColumnTransformer([(\"trans1\", Trans(), [0])], remainder=remainder_transformer)\n    transformed_X = ct.fit_transform(X)\n    expected_remainder = StandardScaler().fit(X[:, 1:]).transform(X[:, 1:])\n    expected_result = np.hstack([X[:, [0]], expected_remainder])\n\n    assert_array_equal(transformed_X, expected_result)\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == \"remainder\"\n    assert callable(ct.transformers_[-1][1])\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n", "def test_column_transformer_remainder_sparse_threshold():\n    X_array = np.array([[0, 1, 2], [2, 4, 6], [8, 6, 4]]).T\n\n    # Setting sparse_threshold to 1.0, the output should be sparse if any part is sparse\n    ct = ColumnTransformer(\n        [(\"trans1\", Trans(), [0])], remainder=SparseMatrixTrans(), sparse_threshold=1.0\n    )\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n    assert X_trans.shape == (3, 4)\n    assert_array_equal(X_trans.toarray(), np.hstack((X_array[:, :1], np.eye(3))))\n\n    # Setting sparse_threshold to 0.0, the output should not be sparse\n    ct = ColumnTransformer(\n        [(\"trans1\", Trans(), [0])], remainder=SparseMatrixTrans(), sparse_threshold=0.0\n    )\n\n    X_trans = ct.fit_transform(X_array)\n    assert not sparse.issparse(X_trans)\n    assert X_trans.shape == (3, 4)\n    assert_array_equal(X_trans, np.hstack((X_array[:, :1], np.eye(3))))\n"], "sample_116": ["def test_create_index_with_subwords(app):\n    text = (\".. index:: single: foo; bar\\n\"\n            \".. index:: single: foo; baz\\n\"\n            \".. index:: single: qux; quux\\n\"\n            \".. index:: single: quux; corge\\n\"\n            \".. index:: single: corge\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 2\n    assert index[0] == ('C', [('corge', [[('', '#index-4')], [], None])])\n    assert index[1] == ('F', [('foo', [[], \n                                       ('bar', [('', '#index-0')]), \n                                       ('baz', [('', '#index-1')])], None),\n                              ('quux', [[], [('corge', [('', '#index-3')])], None]),\n                              ('qux', [[], [('quux', [('', '#index-2')])], None])])\n", "def test_create_index_with_subitems(app):\n    text = (\".. index:: single: Python\\n\"\n            \".. index:: single: Python (programming language)\\n\"\n            \".. index:: single: Python (snake)\\n\"\n            \".. index:: single: Sphinx\\n\"\n            \".. index:: single: Sphinx (tool)\\n\"\n            \".. index:: single: Sphinx (mythological creature)\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    \n    assert len(index) == 2\n    assert index[0] == ('P', [('Python', [[('', '#index-0')], \n                                          {'(programming language)': [('', '#index-1')],\n                                           '(snake)': [('', '#index-2')]}, \n                                           None])])\n    assert index[1] == ('S', [('Sphinx', [[('', '#index-3')], \n                                          {'(tool)': [('', '#index-4')],\n                                           '(mythological creature)': [('', '#index-5')]}, \n                                           None])])\n", "def test_create_index_with_invalid_entry_type(app):\n    text = (\".. index:: invalidtype: docutils\\n\")\n    restructuredtext.parse(app, text)\n    with pytest.warns(UserWarning, match=\"unknown index entry type 'invalidtype'\"):\n        index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 0\n", "def test_create_index_with_incorrect_format(app):\n    text = (\".. index:: incorrect\\n\"\n            \".. index:: triple: foo; bar\\n\"  # Incorrect triple format\n            \".. index:: pair: only_one_value\\n\")  # Incorrect pair format\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n\n    # check index is created, but with warnings logged\n    assert len(index) == 1\n    assert index[0] == ('I', [('incorrect', [[('', '#index-0')], [], None])])\n\n    # Capture and check the warnings\n    log = app._warning.getvalue()\n    assert \"ValueError: not enough values to unpack (expected 3, got 2)\" in log\n    assert \"ValueError: not enough values to unpack (expected 2, got 1)\" in log\n", "def test_create_index_with_unknown_type(app, caplog):\n    text = (\".. index:: unknown: entry\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    \n    # check index is empty since the entry type is unknown\n    assert len(index) == 0\n    \n    # check that a warning is logged for the unknown index entry type\n    assert len(caplog.records) == 1\n    assert caplog.records[0].levelname == 'WARNING'\n    assert 'unknown index entry type' in caplog.records[0].message\n"], "sample_109": ["def test_kfold_more_folds_than_samples():\n    # Test to ensure KFold raises an error when the number of folds is greater than the number of samples.\n    X_small = np.array([[1, 2], [3, 4]])\n    y_small = np.array([0, 1])\n    kf = KFold(n_splits=3)\n    with pytest.raises(ValueError, match=\"Cannot have number of splits n_splits=3 greater than the number of samples: 2.\"):\n        next(kf.split(X_small, y_small))\n", "def test_leave_one_out_single_sample():\n    # Check LeaveOneOut raises error when there is only one sample\n    loo = LeaveOneOut()\n    X, y = [[1]], [0]  # 1 sample\n    with pytest.raises(ValueError, match='Cannot perform LeaveOneOut with n_samples=1'):\n        next(loo.split(X, y))\n", "def test_leave_one_out():\n    X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n    y = np.array([1, 2, 1, 2])\n    \n    loo = LeaveOneOut()\n    splits = list(loo.split(X, y))\n    \n    expected_splits = [\n        (np.array([1, 2, 3]), np.array([0])),\n        (np.array([0, 2, 3]), np.array([1])),\n        (np.array([0, 1, 3]), np.array([2])),\n        (np.array([0, 1, 2]), np.array([3]))\n    ]\n    \n    for split, expected in zip(splits, expected_splits):\n        assert_array_equal(split[0], expected[0])\n        assert_array_equal(split[1], expected[1])\n        \n    # Test get_n_splits method\n    assert loo.get_n_splits(X) == 4\n\n    # Ensure that split throws an error when there are fewer than 2 samples\n    with pytest.raises(ValueError, match='Cannot perform LeaveOneOut with n_samples=1'):\n        next(LeaveOneOut().split(np.array([[1]])))\n", "def test_stratified_shuffle_split_maintains_stratification():\n    # Check that StratifiedShuffleSplit maintains stratification\n    X = np.ones(100)\n    y = np.hstack((np.zeros(95), np.ones(5)))\n    sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n\n    for train_idx, test_idx in sss.split(X, y):\n        assert np.sum(y[train_idx]) / len(y[train_idx]) == pytest.approx(0.05, rel=1e-2)\n        assert np.sum(y[test_idx]) / len(y[test_idx]) == pytest.approx(0.05, rel=1e-2)\n", "def test_leave_one_out_raises_error_for_one_sample():\n    # Test that LeaveOneOut raises an error when given a single sample\n    X = np.array([[1, 2]])\n    y = np.array([1])\n    \n    loo = LeaveOneOut()\n    \n    with pytest.raises(ValueError, match=\"Cannot perform LeaveOneOut with n_samples=1\"):\n        next(loo.split(X, y))\n"], "sample_40": ["def test_boundfield_as_textarea(self):\n    class SampleForm(Form):\n        description = CharField(widget=Textarea)\n\n    form = SampleForm(initial={'description': 'Initial text'})\n    self.assertHTMLEqual(\n        form['description'].as_textarea(),\n        '<textarea name=\"description\" rows=\"10\" cols=\"40\" required>Initial text</textarea>',\n    )\n    form = SampleForm(data={'description': 'Updated text'})\n    self.assertHTMLEqual(\n        form['description'].as_textarea(),\n        '<textarea name=\"description\" rows=\"10\" cols=\"40\" required>Updated text</textarea>',\n    )\n", "    def test_boundfield_as_hidden(self):\n        # Verify BoundField's as_hidden method renders the hidden widget correctly.\n        class HiddenFieldForm(Form):\n            hidden_field = CharField(widget=HiddenInput)\n\n        f = HiddenFieldForm()\n        self.assertHTMLEqual(\n            f['hidden_field'].as_hidden(),\n            '<input type=\"hidden\" name=\"hidden_field\" id=\"id_hidden_field\">'\n        )\n\n        f = HiddenFieldForm({'hidden_field': 'secret'})\n        self.assertHTMLEqual(\n            f['hidden_field'].as_hidden(),\n            '<input type=\"hidden\" name=\"hidden_field\" value=\"secret\" id=\"id_hidden_field\">'\n        )\n", "    def test_boundfield_as_widget_with_attrs(self):\n        class CustomForm(Form):\n            text = CharField(widget=TextInput(attrs={'placeholder': 'Enter text'}))\n            textarea = CharField(widget=Textarea(attrs={'rows': 4, 'cols': 15}))\n\n        form = CustomForm()\n        text_field = form['text']\n        textarea_field = form['textarea']\n        self.assertHTMLEqual(\n            text_field.as_widget(attrs={'class': 'text-class'}),\n            '<input type=\"text\" name=\"text\" placeholder=\"Enter text\" class=\"text-class\" required>'\n        )\n        self.assertHTMLEqual(\n            textarea_field.as_widget(attrs={'class': 'textarea-class'}),\n            '<textarea name=\"textarea\" rows=\"4\" cols=\"15\" class=\"textarea-class\" required></textarea>'\n        )\n", "    def test_boundfield_css_classes_with_errors(self):\n        # Test to ensure css_classes method works correctly when there are errors\n        class SimpleForm(Form):\n            name = CharField()\n\n        data = {'name': ''}\n        form = SimpleForm(data)\n        form.is_valid()  # Trigger validation\n\n        field = form['name']\n        form.required_css_class = 'required'\n        form.error_css_class = 'error'\n        self.assertEqual(field.css_classes(), 'error required')\n        self.assertEqual(field.css_classes(extra_classes='extra'), 'extra error required')\n", "def test_boundfield_as_textarea(self):\n    class TextAreaForm(Form):\n        description = CharField(widget=Textarea, initial='Initial description')\n\n    form = TextAreaForm()\n    self.assertHTMLEqual(\n        form['description'].as_textarea(),\n        '<textarea name=\"description\" rows=\"10\" cols=\"40\" required>Initial description</textarea>'\n    )\n    form = TextAreaForm({'description': 'Updated description'})\n    self.assertHTMLEqual(\n        form['description'].as_textarea(),\n        '<textarea name=\"description\" rows=\"10\" cols=\"40\" required>Updated description</textarea>'\n    )\n"], "sample_128": ["def test_Options_init():\n    opt = Options((x, y, z), {'domain': 'ZZ'})\n\n    assert opt.gens == (x, y, z)\n    assert opt.domain == ZZ\n    assert opt['gens'] == (x, y, z)\n    assert opt['domain'] == ZZ\n\n    raises(OptionError, lambda: Options((x, y, z), {'gens': (x, y), 'domain': 'ZZ'}))\n\n    opt = Options(None, {'domain': 'ZZ'})\n    assert opt.gens == ()\n    assert opt.domain == ZZ\n\n    raises(OptionError, lambda: Options((x, y, z), {'invalid_option': 'ZZ'}))\n", "def test_build_options():\n    assert build_options((x, y, z), {'domain': 'ZZ'}) == Options((x, y, z), {'domain': 'ZZ'})\n    assert build_options(None, {'opt': Options((x, y), {'domain': 'QQ'})}) == Options((x, y), {'domain': 'QQ'})\n    \n    raises(OptionError, lambda: build_options((x, y, z), {'opt': Options((x, y), {'domain': 'QQ'})}))\n", "def test_Strict_default():\n    assert Strict.default() is True\n", "def test_Options_init():\n    # Testing initialization of Options with various parameters\n    opt = Options((x, y, z), {'domain': 'ZZ', 'expand': True, 'split': False})\n    assert opt.gens == (x, y, z)\n    assert opt.domain == ZZ\n    assert opt.expand is True\n    assert opt.split is False\n\n    raises(OptionError, lambda: Options((x, y), {'gens': (x, y), 'domain': 'ZZ'}))  # gens conflict\n    raises(OptionError, lambda: Options((x, y), {'domain': 'invalid_domain'}))  # invalid domain\n    raises(OptionError, lambda: Options((x, y), {'field': True, 'domain': 'ZZ'}))  # field and domain conflict\n", "def test_Options_init():\n    # Test normal initialization\n    opt = Options((x, y, z), {'domain': 'ZZ'})\n    assert opt.gens == (x, y, z)\n    assert opt.domain == ZZ\n    assert opt['domain'] == ZZ\n\n    # Test initialization with defaults\n    opt = Options((x, y, z), {}, defaults={'domain': 'QQ'})\n    assert opt.gens == (x, y, z)\n    assert opt.domain == QQ\n    assert opt['domain'] == QQ\n\n    # Test invalid option\n    raises(OptionError, lambda: Options((x, y, z), {'invalid_option': 'ZZ'}))\n\n    # Test invalid flag in strict mode\n    raises(OptionError, lambda: Options((x, y, z), {'domain': 'ZZ', 'frac': True}, strict=True))\n\n    # Test valid flag in strict mode\n    opt = Options((x, y, z), {'domain': 'ZZ', 'frac': True}, strict=False, flags=['frac'])\n    assert opt.domain == ZZ\n    assert opt.frac == True\n\n    # Test option dependencies\n    raises(OptionError, lambda: Options((x, y, z), {'field': True, 'domain': 'ZZ'}))\n    raises(OptionError, lambda: Options((x, y, z), {'field': True, 'greedy': True}))\n\n    # Test option exclusions\n    raises(OptionError, lambda: Options((x, y, z), {'domain': 'ZZ', 'field': True}))\n    raises(OptionError, lambda: Options((x, y, z), {'split': True, 'field': True}))\n\n    # Test option requirements\n    raises(OptionError, lambda: Options((x, y, z), {'symmetric': True}))\n"], "sample_73": ["def test_offsetbox_set_get_offset():\n    fig, ax = plt.subplots()\n    size = 50\n    da = DrawingArea(size, size)\n    anchored_box = AnchoredOffsetbox(\n        loc='center',\n        child=da,\n        pad=0.,\n        frameon=False,\n        bbox_to_anchor=(.5, .5),\n        bbox_transform=ax.transAxes,\n        borderpad=0.)\n\n    da.set_offset((10, 20))\n    assert da.get_offset() == (10, 20)\n\n        return (width * 0.1, height * 0.2)\n\n    da.set_offset(dynamic_offset)\n    assert da.get_offset(Bbox.from_bounds(0, 0, size, size), None) == (5, 10)\n", "def test_offsetbox_get_set_offset():\n    # Test the get_offset and set_offset methods of OffsetBox\n    fig, ax = plt.subplots()\n    ob = OffsetBox()\n\n    # Set an explicit offset and check if it is correctly returned\n    ob.set_offset((10, 20))\n    assert ob.get_offset(Bbox.from_bounds(0, 0, 1, 1), None) == (10, 20)\n\n    # Set a callable offset and check if it is correctly calculated and returned\n        return (width + xdescent, height + ydescent)\n\n    ob.set_offset(offset_func)\n    bbox = Bbox.from_bounds(2, 3, 4, 5)\n    assert ob.get_offset(bbox, None) == (6, 8)\n", "def test_offsetbox_get_visible_children():\n    # Test to check the get_visible_children method of OffsetBox\n    fig, ax = plt.subplots()\n    ob = OffsetBox()\n    child1 = DrawingArea(10, 10)\n    child2 = DrawingArea(20, 20)\n    child3 = DrawingArea(30, 30)\n    ob._children.extend([child1, child2, child3])\n\n    # Initially all children are visible\n    assert ob.get_visible_children() == [child1, child2, child3]\n\n    # Hide one child and check\n    child2.set_visible(False)\n    assert ob.get_visible_children() == [child1, child3]\n\n    # Hide all children and check\n    child1.set_visible(False)\n    child3.set_visible(False)\n    assert ob.get_visible_children() == []\n\n    # Make children visible again and check\n    child1.set_visible(True)\n    child2.set_visible(True)\n    child3.set_visible(True)\n    assert ob.get_visible_children() == [child1, child2, child3]\n", "def test_offsetbox_set_get_offset():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100)\n    anchored_box = AnchoredOffsetbox(loc='center', child=da)\n    ax.add_artist(anchored_box)\n\n    # Set a static offset\n    anchored_box.set_offset((10, 20))\n    assert anchored_box.get_offset(anchored_box.get_bbox(ax.figure._get_renderer()), ax.figure._get_renderer()) == (10, 20)\n\n    # Set an offset using a callable\n        return width/2, height/2\n\n    anchored_box.set_offset(offset_fn)\n    bbox = anchored_box.get_bbox(ax.figure._get_renderer())\n    assert anchored_box.get_offset(bbox, ax.figure._get_renderer()) == (bbox.width/2, bbox.height/2)\n", "def test_offsetbox_contains():\n    fig, ax = plt.subplots()\n    size = 100\n    da = DrawingArea(size, size, clip=True)\n    bg = mpatches.Rectangle((0, 0), size, size,\n                            facecolor='#CCCCCC',\n                            edgecolor='None',\n                            linewidth=0)\n    line = mlines.Line2D([-size*.5, size*1.5], [size/2, size/2],\n                         color='black',\n                         linewidth=10)\n    anchored_box = AnchoredOffsetbox(\n        loc='center',\n        child=da,\n        pad=0.,\n        frameon=False,\n        bbox_to_anchor=(.5, .5),\n        bbox_transform=ax.transAxes,\n        borderpad=0.)\n\n    da.add_artist(bg)\n    da.add_artist(line)\n    ax.add_artist(anchored_box)\n    fig.canvas.draw()\n\n    # Check contains method of OffsetBox\n    event_inside = MouseEvent(\"button_press_event\", fig.canvas, 0.5, 0.5, MouseButton.LEFT)\n    event_outside = MouseEvent(\"button_press_event\", fig.canvas, 0, 0, MouseButton.LEFT)\n    assert anchored_box.contains(event_inside)[0] is True\n    assert anchored_box.contains(event_outside)[0] is False\n"], "sample_111": ["def test_empty_labels(metric):\n    with pytest.raises(ValueError, match=\"labels_true must be 1D: shape is ()\"):\n        metric([], [])\n", "def test_homogeneity_completeness_v_measure():\n    labels_true = [0, 0, 1, 1, 2, 2]\n    labels_pred = [0, 0, 1, 1, 2, 2]\n    homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(labels_true, labels_pred)\n    assert_allclose(homogeneity, 1.0)\n    assert_allclose(completeness, 1.0)\n    assert_allclose(v_measure, 1.0)\n\n    labels_pred = [0, 1, 2, 0, 1, 2]\n    homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(labels_true, labels_pred)\n    assert homogeneity > 0\n    assert completeness > 0\n    assert v_measure > 0\n\n    labels_true = []\n    labels_pred = []\n    homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(labels_true, labels_pred)\n    assert_allclose(homogeneity, 1.0)\n    assert_allclose(completeness, 1.0)\n    assert_allclose(v_measure, 1.0)\n\n    labels_true = [0]\n    labels_pred = [1]\n    homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(labels_true, labels_pred)\n    assert_allclose(homogeneity, 1.0)\n    assert_allclose(completeness, 1.0)\n    assert_allclose(v_measure, 1.0)\n", "def test_contingency_matrix(labels_true, labels_pred, eps, sparse, expected):\n    result = contingency_matrix(labels_true, labels_pred, eps=eps, sparse=sparse)\n    if sparse:\n        assert (result != expected).nnz == 0  # Sparse matrices should be identical\n    else:\n        assert np.array_equal(result, expected)\n", "def test_adjusted_rand_score(labels_true, labels_pred, expected):\n    assert_allclose(adjusted_rand_score(labels_true, labels_pred), expected, atol=1e-2)\n", "def test_empty_input(metric_name):\n    # Test that supervised metrics handle empty inputs correctly\n    metric = SUPERVISED_METRICS[metric_name]\n    assert metric([], []) == 1.0\n"], "sample_151": ["def test_canberra_distance():\n    # Test Canberra Distance for 2D points\n    p1 = Point2D(1, 2)\n    p2 = Point2D(3, 4)\n    p3 = Point2D(1, 2)\n    assert p1.canberra_distance(p2) == Rational(1, 2)\n    assert p1.canberra_distance(p3) == 0\n    raises(ValueError, lambda: p1.canberra_distance(Point2D(0, 0)))\n\n    # Test Canberra Distance for 3D points\n    p4 = Point3D(1, 2, 3)\n    p5 = Point3D(4, 5, 6)\n    p6 = Point3D(1, 2, 3)\n    assert p4.canberra_distance(p5) == Rational(1, 3)\n    assert p4.canberra_distance(p6) == 0\n    raises(ValueError, lambda: p4.canberra_distance(Point3D(0, 0, 0)))\n\n    # Test Canberra Distance for higher dimension points\n    p7 = Point(1, 2, 3, 4)\n    p8 = Point(5, 6, 7, 8)\n    p9 = Point(1, 2, 3, 4)\n    assert p7.canberra_distance(p8) == Rational(1, 4)\n    assert p7.canberra_distance(p9) == 0\n    raises(ValueError, lambda: p7.canberra_distance(Point(0, 0, 0, 0)))\n", "def test_canberra_distance():\n    p1 = Point(2, 4)\n    p2 = Point(5, 1)\n    assert p1.canberra_distance(p2) == Rational(3, 5) + Rational(3, 5)\n    p3 = Point3D(1, 0, 2)\n    p4 = Point3D(3, 2, 6)\n    assert p3.canberra_distance(p4) == Rational(2, 4) + Rational(2, 2) + Rational(4, 8)\n    raises(ValueError, lambda: Point(0, 0).canberra_distance((0, 0)))\n", "def test_Point3D_rotate():\n    # Test rotation around the origin\n    p = Point3D(1, 1, 1)\n    assert p.rotate(pi, (0, 0, 0)) == Point3D(-1, -1, -1)\n    \n    # Test rotation around another point\n    assert p.rotate(pi, (1, 1, 0)) == Point3D(1, 1, -1)\n    assert p.rotate(pi/2, (0, 0, 0)) == Point3D(1, -1, 1)\n    assert p.rotate(pi/2, (1, 1, 1)) == Point3D(1, 1, 1)\n\n    # Test rotation around a point with z not equal to 0\n    assert p.rotate(pi/2, (1, 1, 2)) == Point3D(1, 1, 1)\n    assert p.rotate(-pi/2, (1, 1, 2)) == Point3D(1, 1, 1)\n\n    # Test invalid input for rotate\n    raises(ValueError, lambda: p.rotate('invalid'))\n    raises(ValueError, lambda: p.rotate(pi, 'invalid'))\n", "def test_is_concyclic_cases():\n    # Test concyclic points in 2D\n    p1 = Point2D(0, 0)\n    p2 = Point2D(1, 0)\n    p3 = Point2D(0, 1)\n    p4 = Point2D(1, 1)\n    assert Point2D.is_concyclic(p1, p2, p3, p4) is False\n\n    # Test concyclic points in 3D\n    p5 = Point3D(1, 0, 0)\n    p6 = Point3D(0, 1, 0)\n    p7 = Point3D(0, 0, 1)\n    p8 = Point3D(1, 1, 1)\n    assert Point3D.is_concyclic(p5, p6, p7, p8) is False\n\n    # Special case where only two points are given\n    assert Point2D.is_concyclic(p1, p2) is True\n    assert Point3D.is_concyclic(p5, p6) is True\n\n    # Points that lie on a circle in 2D\n    p9 = Point2D(0, 1)\n    p10 = Point2D(1, 0)\n    p11 = Point2D(0, -1)\n    p12 = Point2D(-1, 0)\n    assert Point2D.is_concyclic(p9, p10, p11, p12) is True\n\n    # Points that lie on a sphere in 3D\n    p13 = Point3D(0, 1, 0)\n    p14 = Point3D(1, 0, 0)\n    p15 = Point3D(0, -1, 0)\n    p16 = Point3D(-1, 0, 0)\n    assert Point3D.is_concyclic(p13, p14, p15, p16) is True\n", "def test_canberra_distance():\n    p1 = Point2D(2, 3)\n    p2 = Point2D(5, 9)\n    p3 = Point2D(0, 0)\n    p4 = Point2D(-1, -1)\n    \n    assert p1.canberra_distance(p2) == Rational(7, 17)\n    assert p2.canberra_distance(p3) == Rational(5, 5) + Rational(9, 9)\n    assert p3.canberra_distance(p4) == 1\n    assert p4.canberra_distance(p1) == Rational(1, 3) + Rational(4, 4)\n    \n    # Ensure ValueError is raised for zero vectors\n    raises(ValueError, lambda: p3.canberra_distance(p3))\n\n    # Test with mixed positive and negative coordinates\n    p5 = Point2D(-2, 3)\n    assert p1.canberra_distance(p5) == Rational(4, 4) + Rational(0, 6)\n    \n    p6 = Point2D(-2, -3)\n    assert p2.canberra_distance(p6) == Rational(7, 7) + Rational(12, 12)\n"], "sample_148": ["def test_periodic_argument_eval():\n    from sympy import polar_lift, periodic_argument, exp_polar\n    x = Symbol('x', polar=True)\n    y = Symbol('y')\n\n    # Testing periodic_argument with exp_polar\n    assert periodic_argument(exp_polar(2*I*pi), 2*pi) == 0\n    assert periodic_argument(exp_polar(3*I*pi), 2*pi) == pi\n    assert periodic_argument(exp_polar(5*I*pi), 3*pi) == -pi\n\n    # Testing periodic_argument with polar_lift\n    assert periodic_argument(polar_lift(1), 2*pi) == 0\n    assert periodic_argument(polar_lift(I), 2*pi) == pi/2\n    assert periodic_argument(polar_lift(-1), 2*pi) == pi\n    assert periodic_argument(polar_lift(-I), 2*pi) == -pi/2\n\n    # Testing periodic_argument with non-polar symbols\n    assert periodic_argument(y, 2*pi).func == periodic_argument\n\n    # Testing periodic_argument with additions and multiplications\n    assert periodic_argument(exp_polar(3*I*pi) * exp_polar(2*I*pi), 2*pi) == pi\n    assert periodic_argument(exp_polar(5*I*pi) + exp_polar(I*pi), 2*pi).func == periodic_argument\n", "def test_periodic_argument_properties():\n    from sympy import periodic_argument, unbranched_argument, principal_branch, oo, pi\n    from sympy.abc import z\n\n    p = Symbol('p', positive=True, real=True)\n    n = Symbol('n', negative=True, real=True)\n\n    # Check properties of periodic_argument\n    assert periodic_argument(p, 2*pi).is_real is True\n    assert periodic_argument(p, oo).is_real is True\n    assert periodic_argument(n, 2*pi).is_real is True\n    assert periodic_argument(n, oo).is_real is True\n\n    # Check properties of unbranched_argument\n    assert unbranched_argument(p).is_real is True\n    assert unbranched_argument(n).is_real is True\n\n    # Check properties of principal_branch\n    assert principal_branch(p, 2*pi).is_real is True\n    assert principal_branch(n, 2*pi).is_real is True\n\n    # Test periodic_argument with complex numbers\n    assert periodic_argument(3 + 4*I, 2*pi).is_real is True\n    assert periodic_argument(3 + 4*I, oo).is_real is True\n\n    # Test unbranched_argument with complex numbers\n    assert unbranched_argument(3 + 4*I).is_real is True\n\n    # Test principal_branch with complex numbers\n    assert principal_branch(3 + 4*I, 2*pi).is_real is True\n\n    # Ensure periodic_argument of polar_lift is periodic_argument\n    assert periodic_argument(polar_lift(z), 2*pi) == periodic_argument(z, 2*pi)\n    assert periodic_argument(polar_lift(z), oo) == periodic_argument(z, oo)\n\n    # Ensure unbranched_argument of polar_lift is unbranched_argument\n    assert unbranched_argument(polar_lift(z)) == unbranched_argument(z)\n", "def test_conjugate_transpose_properties():\n    M = Matrix([[1 + 2*I, 3 - I], [2*I, 1 - 3*I]])\n    assert conjugate(transpose(M)) == Matrix([[1 - 2*I, -2*I], [3 + I, 1 + 3*I]])\n    assert transpose(conjugate(M)) == Matrix([[1 - 2*I, -2*I], [3 + I, 1 + 3*I]])\n    assert adjoint(M) == Matrix([[1 - 2*I, -2*I], [3 + I, 1 + 3*I]])\n\n    x, y = symbols('x y', commutative=False)\n    N = Matrix([[x, y], [y, x]])\n    assert conjugate(transpose(N)) == Matrix([[adjoint(x), adjoint(y)], [adjoint(y), adjoint(x)]])\n    assert transpose(conjugate(N)) == Matrix([[adjoint(x), adjoint(y)], [adjoint(y), adjoint(x)]])\n    assert adjoint(N) == Matrix([[adjoint(x), adjoint(y)], [adjoint(y), adjoint(x)]])\n", "def test_polar_lift():\n    from sympy import polar_lift, exp_polar, pi, sqrt\n\n    # Test basic polar lifting\n    assert polar_lift(1) == exp_polar(0)\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(I*pi/2)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    \n    # Test polar lifting with a complex number\n    assert polar_lift(1 + I) == (1 + I) * exp_polar(0)\n    assert polar_lift(-1 + I) == (1 + I) * exp_polar(I*pi)\n\n    # Test polar lifting with a product of numbers\n    assert polar_lift(2*I) == 2 * exp_polar(I*pi/2)\n    assert polar_lift(-2*I) == 2 * exp_polar(-I*pi/2)\n\n    # Test polar lifting of expressions involving symbols\n    x = Symbol('x')\n    assert polar_lift(x) == x * exp_polar(0)\n    assert polar_lift(-x) == x * exp_polar(I*pi)\n\n    # Test polar lifting with more complex expressions\n    assert polar_lift(sqrt(2) + I*sqrt(2)) == sqrt(2) * (1 + I) * exp_polar(0)\n    assert polar_lift(-sqrt(2) + I*sqrt(2)) == sqrt(2) * (1 + I) * exp_polar(I*pi)\n", "def test_imaginary_matrix_operations():\n    A = Matrix([[1 + 2*I, 2 - 3*I], [-I, -2 + I]])\n    B = Matrix([[2 - I, I], [1 + I, 3 - I]])\n\n    # Testing re and im on a matrix\n    assert re(A) == Matrix([[1, 2], [0, -2]])\n    assert im(A) == Matrix([[2, -3], [-1, 1]])\n    assert re(B) == Matrix([[2, 0], [1, 3]])\n    assert im(B) == Matrix([[-1, 1], [1, -1]])\n\n    # Testing conjugate on a matrix\n    assert conjugate(A) == Matrix([[1 - 2*I, 2 + 3*I], [I, -2 - I]])\n    assert conjugate(B) == Matrix([[2 + I, -I], [1 - I, 3 + I]])\n\n    # Testing adjoint on a matrix\n    assert adjoint(A) == Matrix([[1 - 2*I, I], [2 + 3*I, -2 - I]])\n    assert adjoint(B) == Matrix([[2 + I, 1 - I], [-I, 3 + I]])\n\n    # Testing transpose on a matrix\n    assert transpose(A) == Matrix([[1 + 2*I, -I], [2 - 3*I, -2 + I]])\n    assert transpose(B) == Matrix([[2 - I, 1 + I], [I, 3 - I]])\n\n    # Testing Abs on a matrix\n    assert Abs(A) == Matrix([[sqrt(5), sqrt(13)], [1, sqrt(5)]])\n    assert Abs(B) == Matrix([[sqrt(5), 1], [sqrt(2), sqrt(10)]])\n\n    # Testing sign on a matrix\n    assert sign(A) == Matrix([[sign(1 + 2*I), sign(2 - 3*I)], [sign(-I), sign(-2 + I)]])\n    assert sign(B) == Matrix([[sign(2 - I), sign(I)], [sign(1 + I), sign(3 - I)]])\n"], "sample_155": ["def test_get_units_non_prefixed():\n    m = Quantity('m')\n    m.set_global_relative_scale_factor(1, meter)\n    cm = Quantity('cm')\n    cm.set_global_relative_scale_factor(1, centimeter)\n    km = Quantity('km')\n    km.set_global_relative_scale_factor(1, kilometer)\n    g = Quantity('g')\n    g.set_global_relative_scale_factor(1, gram)\n    kg = Quantity('kg')\n    kg.set_global_relative_scale_factor(1, kilogram)\n\n    # Define a unit system with both prefixed and non-prefixed units\n    us = UnitSystem(base_units=(m,), units=(m, cm, km, g, kg))\n\n    non_prefixed_units = us.get_units_non_prefixed()\n    \n    # Only m and g should be non-prefixed\n    assert m in non_prefixed_units\n    assert g in non_prefixed_units\n    assert cm not in non_prefixed_units\n    assert km not in non_prefixed_units\n    assert kg not in non_prefixed_units\n", "def test_extend_unit_system():\n    base_units = (meter, second)\n    derived_units = {length: meter, time: second}\n    us = UnitSystem(base_units, derived_units=derived_units, name=\"BaseSystem\")\n\n    extended_base_units = (kilogram,)\n    extended_units = (joule, coulomb)\n    extended_derived_units = {mass: kilogram, energy: joule}\n\n    new_us = us.extend(extended_base_units, extended_units, \"ExtendedSystem\", \"Extended description\", derived_units=extended_derived_units)\n\n    assert new_us.name == \"ExtendedSystem\"\n    assert new_us.descr == \"Extended description\"\n    assert new_us._base_units == (meter, second, kilogram)\n    assert new_us._units == (meter, second, joule, coulomb)\n    assert new_us._derived_units == {**derived_units, **extended_derived_units}\n", "def test_unit_system():\n    # Create a dimension and some quantities\n    length_dim = Dimension('length')\n    mass_dim = Dimension('mass')\n    time_dim = Dimension('time')\n\n    meter = Quantity(\"meter\")\n    meter.set_global_relative_scale_factor(1, meter)\n    kilogram = Quantity(\"kilogram\")\n    kilogram.set_global_relative_scale_factor(1, kilogram)\n    second = Quantity(\"second\")\n    second.set_global_relative_scale_factor(1, second)\n\n    # Initialize a UnitSystem with base units\n    unit_system = UnitSystem(base_units=[meter, kilogram, second], name=\"TestSystem\", descr=\"Test Description\")\n\n    assert unit_system.name == \"TestSystem\"\n    assert unit_system.descr == \"Test Description\"\n    assert unit_system.dim == 3\n\n    # Test string representations\n    assert str(unit_system) == \"TestSystem\"\n    assert repr(unit_system) == \"<UnitSystem: ('meter', 'kilogram', 'second')>\"\n\n    # Test extend method\n    new_unit = Quantity(\"new_unit\")\n    new_unit.set_global_relative_scale_factor(1, meter)\n    extended_system = unit_system.extend([new_unit], name=\"ExtendedSystem\")\n    \n    assert extended_system.name == \"ExtendedSystem\"\n    assert extended_system.dim == 4\n\n    # Test get_units_non_prefixed\n    assert meter in unit_system.get_units_non_prefixed()\n    assert kilogram in unit_system.get_units_non_prefixed()\n    assert second in unit_system.get_units_non_prefixed()\n\n    # Test get_unit_system static method\n    assert UnitSystem.get_unit_system(\"TestSystem\") == unit_system\n    assert UnitSystem.get_unit_system(unit_system) == unit_system\n    raises(ValueError, lambda: UnitSystem.get_unit_system(\"NonExistent\"))\n\n    # Test default unit system method\n    UnitSystem._unit_systems[\"SI\"] = unit_system\n    assert UnitSystem.get_default_unit_system() == unit_system\n\n    # Test get_quantity_dimension and get_quantity_scale_factor methods\n    assert unit_system.get_quantity_dimension(meter) == length_dim\n    assert unit_system.get_quantity_scale_factor(meter) == 1\n\n    # Test dimensional expression methods\n    assert unit_system.get_dimensional_expr(meter) == length_dim.name\n    assert unit_system._collect_factor_and_dimension(meter) == (1, length_dim)\n", "def test_unit_system_initialization():\n    from sympy.physics.units.systems.si import dimsys_SI\n\n    # Define a mock dimension and quantity for testing\n    mock_dimension = Dimension(\"mock_dimension\")\n    mock_quantity = Quantity(\"mock_quantity\")\n\n    # Create a UnitSystem instance with base units, additional units, and derived units\n    base_units = [meter, second]\n    units = [kilometer, hour]\n    derived_units = {mock_dimension: mock_quantity}\n    unit_system = UnitSystem(base_units, units, name=\"MockSystem\", descr=\"A mock unit system for testing\", dimension_system=dimsys_SI, derived_units=derived_units)\n\n    # Check if the UnitSystem instance is initialized correctly\n    assert unit_system.name == \"MockSystem\"\n    assert unit_system.descr == \"A mock unit system for testing\"\n    assert set(unit_system._base_units) == {meter, second}\n    assert set(unit_system._units) == {meter, second, kilometer, hour}\n    assert unit_system._derived_units == derived_units\n    assert unit_system.get_dimension_system() == dimsys_SI\n    assert unit_system.is_consistent\n", "def test_get_units_non_prefixed():\n    # Create some units with and without prefixes\n    base_unit1 = Quantity(\"meter\")\n    base_unit2 = Quantity(\"second\")\n    prefixed_unit = Quantity(\"kilometer\")\n    constant = Quantity(\"speed_of_light\")\n\n    # Set scale factors and dimensions\n    base_unit1.set_global_relative_scale_factor(1, meter)\n    base_unit2.set_global_relative_scale_factor(1, second)\n    prefixed_unit.set_global_relative_scale_factor(1000, meter)\n    constant.set_global_relative_scale_factor(299792458, meter / second)\n\n    # Create a UnitSystem\n    unit_system = UnitSystem([base_unit1, base_unit2], [prefixed_unit, constant])\n\n    # Get non-prefixed units\n    non_prefixed_units = unit_system.get_units_non_prefixed()\n\n    # Check that non-prefixed units are correctly identified\n    assert base_unit1 in non_prefixed_units\n    assert base_unit2 in non_prefixed_units\n    assert prefixed_unit not in non_prefixed_units\n    assert constant not in non_prefixed_units\n"], "sample_83": ["def test_colorized_text_reporter() -> None:\n    \"\"\"Test the ColorizedTextReporter for correct ANSI color and style application.\"\"\"\n    output = StringIO()\n    reporter = ColorizedTextReporter(output=output)\n    \n    # Create a sample message\n    message = Message(\n        symbol=\"line-too-long\",\n        msg_id=\"C0301\",\n        location=MessageLocationTuple(\"abspath\", \"path\", \"module\", \"obj\", 1, 0, 1, 10),\n        msg=\"Line too long\",\n        confidence=HIGH,\n    )\n    \n    # Handle the message using the ColorizedTextReporter\n    reporter.handle_message(message)\n    \n    # Capture the output and verify that ANSI codes are applied correctly\n    output_value = output.getvalue()\n    assert \"\\033[35mLine too long\\033[0m\" in output_value\n    assert \"\\033[35mline-too-long\\033[0m\" in output_value\n    assert \"\\033[35mconvention\\033[0m\" in output_value\n    assert \"\\033[35mC\\033[0m\" in output_value\n", "def test_colorize_ansi():\n    \"\"\"Test colorize_ansi function with various MessageStyle inputs.\"\"\"\n\n    # Test with no color or style\n    assert colorize_ansi(\"test message\", MessageStyle(None, ())) == \"test message\"\n\n    # Test with a single style\n    assert (\n        colorize_ansi(\"test message\", MessageStyle(None, (\"bold\",)))\n        == \"\\033[1mtest message\\033[0m\"\n    )\n\n    # Test with a single color\n    assert (\n        colorize_ansi(\"test message\", MessageStyle(\"red\", ()))\n        == \"\\033[31mtest message\\033[0m\"\n    )\n\n    # Test with a combination of color and style\n    assert (\n        colorize_ansi(\"test message\", MessageStyle(\"red\", (\"bold\",)))\n        == \"\\033[1;31mtest message\\033[0m\"\n    )\n\n    # Test with 256 color code\n    assert (\n        colorize_ansi(\"test message\", MessageStyle(\"196\", (\"bold\",)))\n        == \"\\033[1;38;5;196mtest message\\033[0m\"\n    )\n\n    # Test with deprecated typing\n    with warnings.catch_warnings(record=True) as cm:\n        warnings.simplefilter(\"always\")\n        assert (\n            colorize_ansi(\"test message\", \"red\", \"bold\", color=\"31\")\n            == \"\\033[1;31mtest message\\033[0m\"\n        )\n        assert len(cm) == 1\n        assert issubclass(cm[0].category, DeprecationWarning)\n", "def test_colorize_ansi_deprecated_warning() -> None:\n    with warnings.catch_warnings(record=True) as w:\n        warnings.simplefilter(\"always\")\n        msg = \"Test message\"\n        colorize_ansi(msg, \"red\", style=\"bold\")\n        \n        assert len(w) == 1\n        assert issubclass(w[-1].category, DeprecationWarning)\n        assert \"In pylint 3.0, the colorize_ansi function of Text reporters will only accept a MessageStyle parameter\" in str(w[-1].message)\n", "def test_colorize_ansi():\n    \"\"\"Test the colorize_ansi function with different styles and colors.\"\"\"\n    msg = \"Sample message\"\n    \n    # Test with no color and no style\n    assert colorize_ansi(msg) == msg\n\n    # Test with only color\n    colored_msg = colorize_ansi(msg, msg_style=MessageStyle(\"red\"))\n    assert colored_msg == f\"{ANSI_PREFIX}31{ANSI_END}{msg}{ANSI_RESET}\"\n\n    # Test with only style\n    styled_msg = colorize_ansi(msg, msg_style=MessageStyle(None, (\"bold\",)))\n    assert styled_msg == f\"{ANSI_PREFIX}1{ANSI_END}{msg}{ANSI_RESET}\"\n\n    # Test with both color and style\n    styled_colored_msg = colorize_ansi(msg, msg_style=MessageStyle(\"blue\", (\"underline\", \"italic\")))\n    assert styled_colored_msg == f\"{ANSI_PREFIX}4;3;34{ANSI_END}{msg}{ANSI_RESET}\"\n\n    # Test deprecated usage with color and style as strings\n    with pytest.warns(DeprecationWarning):\n        deprecated_msg = colorize_ansi(msg, msg_style=\"green\", style=\"bold\")\n    assert deprecated_msg == f\"{ANSI_PREFIX}1;32{ANSI_END}{msg}{ANSI_RESET}\"\n\n    # Test with invalid style and color\n    with pytest.raises(KeyError):\n        colorize_ansi(msg, msg_style=MessageStyle(\"invalid_color\", (\"invalid_style\",)))\n", "def test_colorize_ansi() -> None:\n    \"\"\"Test the colorize_ansi function with different styles and colors.\"\"\"\n    message = \"Test message\"\n    \n    # Test with MessageStyle\n    style = MessageStyle(\"red\", (\"bold\", \"underline\"))\n    colored_message = colorize_ansi(message, style)\n    expected_escape_code = f\"{ANSI_PREFIX}31;1;4{ANSI_END}\"\n    assert colored_message == f\"{expected_escape_code}Test message{ANSI_RESET}\"\n    \n    # Test with deprecated color and style arguments\n    colored_message = colorize_ansi(message, \"red\", \"bold, underline\")\n    assert colored_message == f\"{expected_escape_code}Test message{ANSI_RESET}\"\n    \n    # Test with no style and color\n    plain_message = colorize_ansi(message)\n    assert plain_message == message\n    \n    # Test with invalid color\n    style = MessageStyle(\"invalid_color\", (\"bold\",))\n    invalid_colored_message = colorize_ansi(message, style)\n    assert invalid_colored_message == message\n"], "sample_43": ["    def test_invalid_app_label(self):\n        request = self.factory.get(self.url, {'term': 'is', 'app_label': 'invalid_app', **self.opts})\n        request.user = self.superuser\n        with self.assertRaises(PermissionDenied):\n            AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "def test_permission_denied_on_malformed_request(self):\n        \"\"\"\n        Test that a malformed request raises PermissionDenied.\n        \"\"\"\n        request = self.factory.get(self.url, {'term': 'is'})\n        request.user = self.superuser\n        with self.assertRaises(PermissionDenied):\n            AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "    def test_permission_denied_invalid_app_label(self):\n        request = self.factory.get(self.url, {'term': 'is', 'app_label': 'invalid', 'model_name': 'question', 'field_name': 'question'})\n        request.user = self.superuser\n        with self.assertRaises(PermissionDenied):\n            AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "    def test_invalid_app_label(self):\n        request = self.factory.get(self.url, {'term': 'is', 'app_label': 'invalid', 'model_name': 'answer', 'field_name': 'question'})\n        request.user = self.superuser\n        with self.assertRaises(PermissionDenied):\n            AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "def test_invalid_app_label(self):\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'invalid_app', **self.opts})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n"], "sample_137": ["def test_interactive_traversal():\n    from sympy import Add, Mul, Symbol\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z')\n    \n    expr = Add(x, Mul(y, z))\n    \n    # Capture the traversal process.\n        responses = {\n            \"Your choice [0,f,l,r,d,?]: \": \"0\",  # Choosing the first subexpression initially\n            \"Your choice [0,f,l,r,d,?]: \": \"d\",  # Done\n        }\n        print(prompt, responses[prompt])\n        return responses[prompt]\n    \n    import builtins\n    original_input = builtins.input\n    builtins.input = mock_input\n    \n    try:\n        result = interactive_traversal(expr)\n        assert result == x  # We chose the first subexpression, which is x\n    finally:\n        builtins.input = original_input\n", "def test_interactive_traversal():\n    from sympy import sin, cos, exp\n    from sympy.abc import a, b, c, d, e\n\n    expr = a + b*sin(c + d*exp(e))\n\n    # Capture the output of interactive_traversal to verify traversal steps\n        if \"Your choice\" in prompt:\n            # Simulate user's choices in the traversal\n            return '0'  # Always select the first subexpression for simplicity\n        return ''  # Default return for any other input prompts\n\n    import builtins\n    original_input = builtins.input\n    builtins.input = mock_input\n\n    try:\n        result = capture(lambda: interactive_traversal(expr))\n        expected_output = (\n            \"Current expression (stage  0):\\n\" +\n            \"a + b*sin(c + d*exp(e))\\n\\n\" +\n            \"Current expression (stage  1):\\n\" +\n            \"a\\n\"\n        )\n        assert expected_output in result\n    finally:\n        builtins.input = original_input\n", "def test_filter_symbols():\n    symbols_set = symbols(\"a b c d e f g h i j k l m n o p q r s t u v w x y z\")\n    filtered = filter_symbols(symbols_set, symbols(\"a e i o u\"))\n    assert take(filtered, 5) == list(symbols(\"b c d f g\"))\n\n    numbered = numbered_symbols(start=0)\n    filtered_numbered = filter_symbols(numbered, [symbols(\"x1\"), symbols(\"x3\")])\n    assert take(filtered_numbered, 5) == list(symbols(\"x0 x2 x4 x5 x6\"))\n", "def test_common_prefix_suffix_more_cases():\n    assert common_prefix([1, 2, 3], [1, 2, 3, 4, 5]) == [1, 2, 3]\n    assert common_suffix([1, 2, 3, 4, 5], [0, 2, 3, 4, 5]) == [2, 3, 4, 5]\n    assert common_prefix([1, 2, 3], [1, 2, 4]) == [1, 2]\n    assert common_suffix([1, 2, 3], [0, 2, 3]) == [2, 3]\n    assert common_suffix([1, 2, 3], [1, 2]) == []\n    assert common_prefix(['abc', 'def', 'ghi'], ['abc', 'xyz']) == ['abc']\n    assert common_suffix(['abc', 'def', 'ghi'], ['xyz', 'def', 'ghi']) == ['def', 'ghi']\n", "def test_iproduct_with_large_inputs():\n    # Large inputs test for iproduct\n    large_input = list(range(100))\n    large_product = list(iproduct(large_input, repeat=2))\n    assert len(large_product) == 10000\n    for i in range(100):\n        for j in range(100):\n            assert (i, j) in large_product\n\n    # Test for infinite iterables\n    infinite_product = iproduct(S.Integers, [0, 1])\n    for i, val in enumerate(infinite_product):\n        assert val in [(i, 0), (i, 1)]\n        if i >= 9:\n            break\n\n    # Mixed finite and infinite\n    mixed_product = iproduct([0, 1], S.Integers)\n    for i, val in enumerate(mixed_product):\n        assert val[0] in [0, 1]\n        assert isinstance(val[1], Integer)\n        if i >= 9:\n            break\n"], "sample_68": ["    def setUp(self):\n        self.data = [\n            Country(name=\"Country A\", iso_two_letter=\"CA\"),\n            Country(name=\"Country B\", iso_two_letter=\"CB\"),\n            Country(name=\"Country C\", iso_two_letter=\"CC\"),\n            Country(name=\"Country D\", iso_two_letter=\"CD\"),\n        ]\n        Country.objects.bulk_create(self.data)\n", "    def setUp(self):\n        self.country_data = [\n            Country(name=\"Canada\", iso_two_letter=\"CA\"),\n            Country(name=\"Mexico\", iso_two_letter=\"MX\"),\n            Country(name=\"Spain\", iso_two_letter=\"ES\"),\n        ]\n        self.state_data = [\n            State(two_letter_code=\"TX\"),\n            State(two_letter_code=\"FL\"),\n            State(two_letter_code=\"NY\"),\n        ]\n", "    def test_queryset_bool(self):\n        \"\"\"\n        Test the __bool__ method of QuerySet to ensure it correctly evaluates\n        the truthiness based on the presence of results.\n        \"\"\"\n        # Initially, the QuerySet should be empty and evaluate to False.\n        qs = Country.objects.all()\n        self.assertFalse(bool(qs))\n\n        # Add a Country object and the QuerySet should evaluate to True.\n        Country.objects.create(name=\"Japan\", iso_two_letter=\"JP\")\n        self.assertTrue(bool(qs))\n", "    def test_bulk_create_with_deferred_models(self):\n        class DeferredModel(Country):\n            class Meta:\n                proxy = True\n\n                super().save(*args, **kwargs)\n\n        deferred_countries = [\n            DeferredModel(name=\"Deferred Country 1\", iso_two_letter=\"D1\"),\n            DeferredModel(name=\"Deferred Country 2\", iso_two_letter=\"D2\"),\n        ]\n        DeferredModel.objects.bulk_create(deferred_countries)\n        self.assertEqual(DeferredModel.objects.count(), 2)\n        self.assertQuerySetEqual(\n            DeferredModel.objects.order_by(\"name\"),\n            [\"Deferred Country 1\", \"Deferred Country 2\"],\n            attrgetter(\"name\"),\n        )\n", "    def setUp(self):\n        self.raw_query = \"SELECT * FROM test_table\"\n        self.model = Country\n        self.params = ()\n        self.translations = {\"iso_two_letter\": \"iso\"}\n        self.using = \"default\"\n        self.queryset = RawQuerySet(\n            raw_query=self.raw_query,\n            model=self.model,\n            params=self.params,\n            translations=self.translations,\n            using=self.using,\n        )\n"], "sample_119": ["def test_custom_user_function():\n    custom_func = Function('custom_func')\n    settings = {'user_functions': {'custom_func': 'CustomFunc'}}\n    assert mcode(custom_func(x, y), **settings) == \"CustomFunc[x, y]\"\n", "def test_known_functions():\n    assert mcode(sin(x)) == \"Sin[x]\"\n    assert mcode(cos(x)) == \"Cos[x]\"\n    assert mcode(tan(x)) == \"Tan[x]\"\n    assert mcode(cot(x)) == \"Cot[x]\"\n    assert mcode(asin(x)) == \"ArcSin[x]\"\n    assert mcode(acos(x)) == \"ArcCos[x]\"\n    assert mcode(atan(x)) == \"ArcTan[x]\"\n    assert mcode(sinh(x)) == \"Sinh[x]\"\n    assert mcode(cosh(x)) == \"Cosh[x]\"\n    assert mcode(tanh(x)) == \"Tanh[x]\"\n    assert mcode(coth(x)) == \"Coth[x]\"\n    assert mcode(asech(x)) == \"ArcSech[x]\"\n    assert mcode(acsch(x)) == \"ArcCsch[x]\"\n", "def test_user_defined_functions():\n    user_functions = {'custom_func': 'CustomFunc'}\n    assert mcode(Function('custom_func')(x), user_functions=user_functions) == \"CustomFunc[x]\"\n    user_functions = {'custom_func': [(lambda x: x > 0, 'PositiveFunc'), (lambda x: x <= 0, 'NonPositiveFunc')]}\n    assert mcode(Function('custom_func')(x), user_functions=user_functions) == \"PositiveFunc[x]\"\n    assert mcode(Function('custom_func')(-x), user_functions=user_functions) == \"NonPositiveFunc[-x]\"\n", "def test_user_defined_functions():\n    assert mcode(Function('myfunc')(x, y)) == \"myfunc[x, y]\"\n    assert mcode(Function('customFunc')(sin(x), cos(y))) == \"customFunc[Sin[x], Cos[y]]\"\n", "def test_custom_user_functions():\n    custom_funcs = {'custom_func': 'CustomFunction'}\n    expr = Function('custom_func')(x, y)\n    assert mcode(expr, user_functions=custom_funcs) == \"CustomFunction[x, y]\"\n    expr_with_cond = Function('custom_func')(sin(x))\n    assert mcode(expr_with_cond, user_functions={'custom_func': [(lambda x: isinstance(x, Function), 'CustomFuncIfFunc')]}) == \"CustomFuncIfFunc[Sin[x]]\"\n"], "sample_79": ["def test_concat_with_scalar_coords():\n    ds1 = Dataset(\n        {\n            \"var1\": ((\"x\", \"y\"), [[1, 2], [3, 4]]),\n        },\n        coords={\"scalar_coord\": 1}\n    )\n    ds2 = Dataset(\n        {\n            \"var1\": ((\"x\", \"y\"), [[5, 6], [7, 8]]),\n        },\n        coords={\"scalar_coord\": 2}\n    )\n    \n    with raises_regex(ValueError, \"some variables in coords are not coordinates on the first dataset\"):\n        concat([ds1, ds2], dim=\"x\", coords=[\"scalar_coord\"])\n    \n    ds2.coords[\"scalar_coord\"] = 1\n    expected = Dataset(\n        {\n            \"var1\": ((\"x\", \"y\"), [[1, 2], [3, 4], [5, 6], [7, 8]]),\n        },\n        coords={\"scalar_coord\": 1}\n    )\n    actual = concat([ds1, ds2], dim=\"x\")\n    assert_identical(expected, actual)\n", "def test_concat_with_new_dimension():\n    ds1 = Dataset({\"a\": (\"x\", [1, 2]), \"b\": (\"x\", [3, 4])}, coords={\"x\": [0, 1]})\n    ds2 = Dataset({\"a\": (\"x\", [5, 6]), \"b\": (\"x\", [7, 8])}, coords={\"x\": [2, 3]})\n    dim_coord = DataArray([10, 20], dims=\"new_dim\")\n\n    expected = Dataset(\n        {\"a\": ((\"new_dim\", \"x\"), [[1, 2], [5, 6]]), \"b\": ((\"new_dim\", \"x\"), [[3, 4], [7, 8]])},\n        coords={\"x\": [0, 1], \"new_dim\": [10, 20]}\n    )\n    \n    actual = concat([ds1, ds2], dim=dim_coord)\n    assert_identical(expected, actual)\n\n    # Test with positions argument\n    positions = [np.array([0, 1]), np.array([2, 3])]\n    actual_with_positions = concat([ds1, ds2], dim=dim_coord, positions=positions)\n    assert_identical(expected, actual_with_positions)\n", "def test_concat_empty_datasets():\n    ds1 = Dataset({\"x\": [], \"y\": []})\n    ds2 = Dataset({\"x\": [], \"y\": []})\n    \n    result = concat([ds1, ds2], dim=\"z\")\n    \n    expected = Dataset({\"x\": (\"z\", [[], []]), \"y\": (\"z\", [[], []])})\n    assert_identical(result, expected)\n", "    def test_concat_with_new_dimension(self):\n        # Test concatenation along a new dimension not present in the datasets\n        ds1 = Dataset({\"foo\": (\"x\", [1, 2, 3])}, coords={\"x\": [0, 1, 2]})\n        ds2 = Dataset({\"foo\": (\"x\", [4, 5, 6])}, coords={\"x\": [0, 1, 2]})\n        \n        result = concat([ds1, ds2], dim=\"new_dim\")\n        expected = Dataset({\"foo\": ((\"new_dim\", \"x\"), [[1, 2, 3], [4, 5, 6]])}, coords={\"x\": [0, 1, 2]})\n        \n        assert_identical(result, expected)\n        \n        # Test with DataArray objects\n        da1 = DataArray([1, 2, 3], dims=\"x\", coords={\"x\": [0, 1, 2]})\n        da2 = DataArray([4, 5, 6], dims=\"x\", coords={\"x\": [0, 1, 2]})\n        \n        result = concat([da1, da2], dim=\"new_dim\")\n        expected = DataArray([[1, 2, 3], [4, 5, 6]], dims=[\"new_dim\", \"x\"], coords={\"x\": [0, 1, 2]})\n        \n        assert_identical(result, expected)\n", "def test_concat_with_positions():\n    data1 = Dataset({\"a\": (\"x\", [1, 2, 3]), \"b\": (\"x\", [4, 5, 6])})\n    data2 = Dataset({\"a\": (\"x\", [7, 8]), \"b\": (\"x\", [9, 10])})\n    positions = [np.array([0, 2, 4]), np.array([1, 3])]\n    \n    actual = concat([data1, data2], dim=\"x\", positions=positions)\n    expected = Dataset({\"a\": (\"x\", [1, 7, 2, 8, 3]), \"b\": (\"x\", [4, 9, 5, 10, 6])})\n    \n    assert_identical(actual, expected)\n"], "sample_77": ["    def x(self):\n        return pd.Series([\"a\", \"b\", \"c\", \"a\"], name=\"x\")\n    ", "def test_nominal_tick(self, x):\n\n    locator = mpl.ticker.FixedLocator([0, 1, 2])\n    s = Nominal().tick(locator)._setup(x, Coordinate())\n    assert_series_equal(s(x), pd.Series([0, 1, 2, 1], name=\"x\", dtype=float))\n", "def test_label_concise_with_custom_formatter(self, t, x):\n\n    ax = mpl.figure.Figure().subplots()\n    custom_formatter = mpl.dates.DateFormatter(\"%b %d, %Y\")\n    Temporal().label(formatter=custom_formatter, concise=True)._setup(t, Coordinate(), ax.xaxis)\n    formatter = ax.xaxis.get_major_formatter()\n    assert isinstance(formatter, mpl.dates.DateFormatter)\n    assert formatter.fmt == \"%b %d, %Y\"\n", "    def test_temporal_tick_upto(self, t):\n\n        n = 5\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n", "def test_nominal_tick_defaults(self, x):\n    ax = mpl.figure.Figure().subplots()\n    s = Nominal().tick()._setup(x, Coordinate(), ax.xaxis)\n    assert_array_equal(ax.xaxis.get_ticklocs(), [0, 1, 2])\n    f = ax.xaxis.get_major_formatter()\n    assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n"], "sample_88": ["def test_safeformat():\n    class BrokenRepr:\n            raise ValueError(\"broken repr\")\n\n    class BrokenStr:\n            raise ValueError(\"broken str\")\n\n    assert \"ValueError\" in safeformat(BrokenRepr())\n    assert \"ValueError\" in safeformat(BrokenStr())\n\n    nested_structure = {\n        \"key1\": [1, 2, 3],\n        \"key2\": {\n            \"nested_key\": BrokenRepr(),\n        },\n        \"key3\": (4, 5, BrokenStr()),\n    }\n    formatted = safeformat(nested_structure)\n    assert \"ValueError\" in formatted\n    assert \"broken repr\" in formatted\n    assert \"broken str\" in formatted\n", "def test_nested_structure():\n    nested_dict = {\n        'a': [1, 2, 3],\n        'b': {'x': 10, 'y': 20, 'z': [100, 200, 300]},\n        'c': (4, 5, 6)\n    }\n    nested_repr = saferepr(nested_dict, maxsize=100)\n    assert \"...\" in nested_repr or len(nested_repr) <= 100\n\n    nested_list = [nested_dict] * 10\n    nested_list_repr = saferepr(nested_list, maxsize=100)\n    assert \"...\" in nested_list_repr or len(nested_list_repr) <= 100\n", "def test_safeformat():\n    class BrokenReprClass:\n            raise ValueError(\"broken repr\")\n\n    class NormalClass:\n            return \"normal repr\"\n\n    assert \"broken repr\" in safeformat(BrokenReprClass())\n    assert \"normal repr\" in safeformat(NormalClass())\n    assert \"None\" in safeformat(None)\n    assert \"[1, 2, 3]\" in safeformat([1, 2, 3])\n", "def test_safeformat():\n    class BrokenRepr:\n            raise ValueError(\"Broken repr!\")\n\n    class CustomClass:\n            self.attr = \"value\"\n\n            return \"<CustomClass>\"\n\n    assert \"Broken repr!\" in safeformat(BrokenRepr())\n    obj = CustomClass()\n    formatted_obj = safeformat(obj)\n    assert \"CustomClass\" in formatted_obj\n    assert \"attr\" in formatted_obj\n", "def test_nested_objects():\n    \"\"\"Test saferepr with nested objects to ensure it handles depth correctly.\"\"\"\n    \n    class NestedRepr:\n            self.level = level\n            if level > 0:\n                self.child = NestedRepr(level - 1)\n            else:\n                self.child = \"Leaf\"\n\n            return f\"<Nested level={self.level} child={repr(self.child)}>\"\n\n    nested_obj = NestedRepr(10)\n    s = saferepr(nested_obj, maxsize=100)\n    assert s.startswith(\"<Nested level=10 child=<Nested level=9 child=<Nested level=8 child=<Nested level=7 child=<Nested level=6 child=<Nested level=5 child=<Nested level=4 child=<Nested level=3 child=<Nested level=2 child=<Nested level=1 child='Leaf'>\")\n    assert len(s) <= 100\n"], "sample_21": ["    def test_protect_error_message(self):\n        \"\"\"\n        Ensure the ProtectedError exception message is formatted correctly.\n        \"\"\"\n        msg = \"Cannot delete some instances of model 'TestModel' because they are referenced through a protected foreign key: 'RelatedModel.related_field'.\"\n        protected_objects = ['obj1', 'obj2']\n        error = ProtectedError(msg, protected_objects)\n        self.assertEqual(str(error), msg)\n        self.assertEqual(error.protected_objects, protected_objects)\n", "    def test_protected_error_initialization(self):\n        protected_objects = [A(), A()]\n        error = ProtectedError(\"Test message\", protected_objects)\n        self.assertEqual(error.protected_objects, protected_objects)\n        self.assertEqual(str(error), \"Test message\")\n", "    def test_set_callable(self):\n            return self.DEFAULT\n\n        a = create_a('set_callable')\n        set_function = models.SET(value_callable)\n        collector = Collector(using='default')\n        a.set_callable_field.on_delete = set_function\n        a.set_callable_field.on_delete(collector, a._meta.get_field('set_callable_field'), [a], 'default')\n        collector.delete()\n        a.refresh_from_db()\n        self.assertEqual(a.set_callable_field, self.DEFAULT)\n", "    def test_set_callable(self):\n        a = create_a('set_callable')\n            return self.DEFAULT\n        a.set_callable = SET(callable_func)\n        a.set_callable.delete()\n        a = A.objects.get(pk=a.pk)\n        self.assertEqual(self.DEFAULT, a.set_callable)\n", "def test_cascade_delete_with_multiple_related_objects(self):\n        r = R.objects.create()\n        s1 = S.objects.create(r=r)\n        s2 = S.objects.create(r=r)\n        t1 = T.objects.create(s=s1)\n        t2 = T.objects.create(s=s1)\n        t3 = T.objects.create(s=s2)\n        t4 = T.objects.create(s=s2)\n        self.assertEqual(S.objects.count(), 2)\n        self.assertEqual(T.objects.count(), 4)\n        r.delete()\n        self.assertEqual(S.objects.count(), 0)\n        self.assertEqual(T.objects.count(), 0)\n"], "sample_52": ["    def test_create_model_with_invalid_field(self):\n        \"\"\"\n        Tests the CreateModel operation with an invalid field type.\n        \"\"\"\n        with self.assertRaisesMessage(TypeError, \"Invalid field type specified\"):\n            migrations.CreateModel(\n                \"Pony\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\"invalid_field\", \"This is not a valid field type\"),\n                ],\n            )\n", "    def test_create_model_with_options(self):\n        \"\"\"\n        Tests the CreateModel operation with additional options like\n        unique_together, index_together, and other Meta options.\n        \"\"\"\n        operation = migrations.CreateModel(\n            \"Pony\",\n            fields=[\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=255)),\n                (\"age\", models.IntegerField()),\n            ],\n            options={\n                \"unique_together\": {(\"name\", \"age\")},\n                \"index_together\": {(\"name\", \"age\")},\n                \"verbose_name\": \"Pony\",\n                \"verbose_name_plural\": \"Ponies\",\n            },\n        )\n        self.assertEqual(operation.describe(), \"Create model Pony\")\n        self.assertEqual(operation.migration_name_fragment, \"pony\")\n        # Test the state alteration\n        project_state = ProjectState()\n        new_state = project_state.clone()\n        operation.state_forwards(\"test_crmo\", new_state)\n        self.assertEqual(new_state.models[\"test_crmo\", \"pony\"].name, \"Pony\")\n        self.assertEqual(len(new_state.models[\"test_crmo\", \"pony\"].fields), 3)\n        self.assertEqual(\n            new_state.models[\"test_crmo\", \"pony\"].options[\"unique_together\"],\n            {(\"name\", \"age\")},\n        )\n        self.assertEqual(\n            new_state.models[\"test_crmo\", \"pony\"].options[\"index_together\"],\n            {(\"name\", \"age\")},\n        )\n        self.assertEqual(\n            new_state.models[\"test_crmo\", \"pony\"].options[\"verbose_name\"], \"Pony\"\n        )\n        self.assertEqual(\n            new_state.models[\"test_crmo\", \"pony\"].options[\"verbose_name_plural\"],\n            \"Ponies\",\n        )\n        # Test the database alteration\n        self.assertTableNotExists(\"test_crmo_pony\")\n        with connection.schema_editor() as editor:\n            operation.database_forwards(\"test_crmo\", editor, project_state, new_state)\n        self.assertTableExists(\"test_crmo_pony\")\n        # Check unique constraint\n        with connection.cursor() as cursor:\n            cursor.execute(\n                \"INSERT INTO test_crmo_pony (name, age) VALUES ('Twilight', 5)\"\n            )\n            with self.assertRaises(IntegrityError):\n                with atomic():\n                    cursor.execute(\n                        \"INSERT INTO test_crmo_pony (name, age) VALUES ('Twilight', 5)\"\n                    )\n        # Check", "def test_create_model_with_custom_base(self):\n    \"\"\"\n    Tests the CreateModel operation with a custom base class.\n    \"\"\"\n    class CustomBase(models.Model):\n        custom_field = models.CharField(max_length=255)\n\n        class Meta:\n            abstract = True\n\n    operation = migrations.CreateModel(\n        \"CustomModel\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"custom_field\", models.CharField(max_length=255)),\n        ],\n        bases=(CustomBase,),\n    )\n    self.assertEqual(operation.describe(), \"Create model CustomModel\")\n    self.assertEqual(operation.migration_name_fragment, \"custommodel\")\n    # Test the state alteration\n    project_state = ProjectState()\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_cmcb\", new_state)\n    self.assertEqual(new_state.models[\"test_cmcb\", \"custommodel\"].name, \"CustomModel\")\n    self.assertEqual(len(new_state.models[\"test_cmcb\", \"custommodel\"].fields), 2)\n    # Test the database alteration\n    self.assertTableNotExists(\"test_cmcb_custommodel\")\n    with connection.schema_editor() as editor:\n        operation.database_forwards(\"test_cmcb\", editor, project_state, new_state)\n    self.assertTableExists(\"test_cmcb_custommodel\")\n    # And test reversal\n    with connection.schema_editor() as editor:\n        operation.database_backwards(\"test_cmcb\", editor, new_state, project_state)\n    self.assertTableNotExists(\"test_cmcb_custommodel\")\n    # And deconstruction\n    definition = operation.deconstruct()\n    self.assertEqual(definition[0], \"CreateModel\")\n    self.assertEqual(definition[1], [])\n    self.assertEqual(sorted(definition[2]), [\"bases\", \"fields\", \"name\"])\n", "    def test_references_model_with_bases(self):\n        \"\"\"\n        Tests that references_model correctly identifies models that inherit\n        from the given model.\n        \"\"\"\n        class BaseModel(models.Model):\n            class Meta:\n                app_label = 'test_app'\n\n        operation = migrations.CreateModel(\n            \"InheritedModel\",\n            fields=[\n                (\"id\", models.AutoField(primary_key=True)),\n            ],\n            bases=(BaseModel,),\n        )\n        self.assertTrue(operation.references_model(\"BaseModel\", \"test_app\"))\n        self.assertFalse(operation.references_model(\"UnrelatedModel\", \"test_app\"))\n\n        operation = migrations.CreateModel(\n            \"InheritedModel\",\n            fields=[\n                (\"id\", models.AutoField(primary_key=True)),\n            ],\n            bases=(\"test_app.BaseModel\",),\n        )\n        self.assertTrue(operation.references_model(\"BaseModel\", \"test_app\"))\n        self.assertFalse(operation.references_model(\"UnrelatedModel\", \"test_app\"))\n", "    def test_create_model_with_bases(self):\n        \"\"\"\n        Tests the CreateModel operation with various bases.\n        \"\"\"\n        project_state = self.set_up_test_model(\"test_crmo_bas\")\n        operation = migrations.CreateModel(\n            \"WingedPony\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"wing_length\", models.FloatField(default=1.5)),\n            ],\n            bases=(\"test_crmo_bas.Pony\",),\n        )\n        new_state = project_state.clone()\n        operation.state_forwards(\"test_crmo_bas\", new_state)\n        self.assertIn((\"test_crmo_bas\", \"wingedpony\"), new_state.models)\n        self.assertEqual(len(new_state.models[\"test_crmo_bas\", \"wingedpony\"].fields), 2)\n        self.assertTableNotExists(\"test_crmo_bas_wingedpony\")\n        with connection.schema_editor() as editor:\n            operation.database_forwards(\"test_crmo_bas\", editor, project_state, new_state)\n        self.assertTableExists(\"test_crmo_bas_wingedpony\")\n        with connection.schema_editor() as editor:\n            operation.database_backwards(\"test_crmo_bas\", editor, new_state, project_state)\n        self.assertTableNotExists(\"test_crmo_bas_wingedpony\")\n"], "sample_69": ["def test_stale_callback():\n    # Test setting stale via axes property\n    fig, ax = plt.subplots()\n    art = martist.Artist()\n    assert art.stale, \"New artist should be stale\"\n\n        stale_callback.called = True\n\n    stale_callback.called = False\n    art.stale_callback = stale_callback\n\n    ax.add_artist(art)\n    assert not art.stale, \"Artist should not be stale after being added to Axes\"\n    assert not stale_callback.called, \"Callback should not be called yet\"\n\n    art.stale = True\n    assert stale_callback.called, \"Callback should be called when stale is set to True\"\n    assert ax.stale, \"Axes should be stale when artist is stale\"\n\n    # Test setting stale directly\n    stale_callback.called = False\n    art.stale = False\n    assert not art.stale, \"Artist should not be stale after being set to False\"\n    assert not stale_callback.called, \"Callback should not be called when setting stale to False\"\n", "def test_set_visible():\n    art = martist.Artist()\n    assert art.get_visible() == True\n    art.set_visible(False)\n    assert art.get_visible() == False\n    art.set_visible(True)\n    assert art.get_visible() == True\n", "def test_artist_remove_callback():\n    # Test that remove_callback correctly removes the callback.\n        func.counter += 1\n\n    func.counter = 0\n\n    art = martist.Artist()\n    oid = art.add_callback(func)\n    assert func.counter == 0\n    art.pchanged()  # must call the callback\n    assert func.counter == 1\n    art.set_zorder(10)  # setting a property must also call the callback\n    assert func.counter == 2\n    art.remove_callback(oid)\n    art.pchanged()  # must not call the callback anymore\n    assert func.counter == 2\n", "def test_set_sketch_params():\n    art = martist.Artist()\n    art.set_sketch_params(scale=1.0, length=2.0, randomness=3.0)\n    assert art.get_sketch_params() == (1.0, 2.0, 3.0)\n\n    art.set_sketch_params(scale=None)\n    assert art.get_sketch_params() is None\n\n    art.set_sketch_params(scale=4.0)\n    assert art.get_sketch_params() == (4.0, 128.0, 16.0)\n", "def test_set_clip_on():\n    art = martist.Artist()\n    assert art.get_clip_on()  # Default should be True\n\n    art.set_clip_on(False)\n    assert not art.get_clip_on()\n\n    art.set_clip_on(True)\n    assert art.get_clip_on()\n"], "sample_121": ["def test_af_functions():\n    # Test _af_invert\n    a = [3, 2, 1, 0]\n    assert _af_invert(a) == [3, 2, 1, 0]\n    b = [1, 0, 3, 2]\n    assert _af_invert(b) == [1, 0, 3, 2]\n    c = [2, 3, 0, 1]\n    assert _af_invert(c) == [2, 3, 0, 1]\n\n    # Test _af_pow\n    a = [2, 0, 1]\n    assert _af_pow(a, 0) == [0, 1, 2]\n    assert _af_pow(a, 1) == [2, 0, 1]\n    assert _af_pow(a, 2) == [1, 2, 0]\n    assert _af_pow(a, 3) == [0, 1, 2]\n    assert _af_pow(a, -1) == [1, 2, 0]\n\n    # Test _af_commutes_with\n    a = [0, 1, 2, 3]\n    b = [0, 2, 1, 3]\n    assert _af_commutes_with(a, b) == False\n    a = [1, 0, 2, 3]\n    b = [1, 0, 2, 3]\n    assert _af_commutes_with(a, b) == True\n\n    # Test _af_rmul\n    a = [1, 0, 2]\n    b = [0, 2, 1]\n    assert _af_rmul(a, b) == [1, 2, 0]\n    a = [3, 1, 2, 0]\n    b = [2, 3, 0, 1]\n    assert _af_rmul(a, b) == [2, 0, 3, 1]\n", "def test_af_pow():\n    # Test _af_pow function\n    assert _af_pow([0, 1, 2, 3], 0) == [0, 1, 2, 3]\n    assert _af_pow([0, 1, 2, 3], 1) == [0, 1, 2, 3]\n    assert _af_pow([2, 0, 3, 1], 2) == [3, 2, 1, 0]\n    assert _af_pow([2, 0, 3, 1], 3) == [1, 3, 0, 2]\n    assert _af_pow([2, 0, 3, 1], 4) == [0, 1, 2, 3]\n    assert _af_pow([2, 0, 3, 1], -1) == [1, 3, 0, 2]\n    assert _af_pow([2, 0, 3, 1], -2) == [3, 2, 1, 0]\n    # Testing a higher power to trigger binary multiplication\n    assert _af_pow([2, 0, 3, 1], 8) == [0, 1, 2, 3]\n", "def test_af_functions():\n    # Test _af_rmul\n    a, b = [1, 0, 2], [0, 2, 1]\n    assert _af_rmul(a, b) == [1, 2, 0]\n    assert _af_rmul([3, 2, 1, 0], [0, 2, 1, 3]) == [3, 1, 2, 0]\n\n    # Test _af_rmuln with various lengths\n    assert _af_rmuln([1, 0, 2], [0, 2, 1], [2, 1, 0]) == [0, 2, 1]\n    assert _af_rmuln([1, 0, 2], [0, 2, 1], [2, 1, 0], [0, 1, 2]) == [0, 1, 2]\n    assert _af_rmuln([1, 0, 2], [0, 2, 1], [2, 1, 0], [0, 1, 2], [1, 2, 0]) == [1, 2, 0]\n\n    # Test _af_parity\n    assert _af_parity([0, 1, 2, 3]) == 0\n    assert _af_parity([3, 2, 0, 1]) == 1\n\n    # Test _af_invert\n    assert _af_invert([1, 2, 0, 3]) == [2, 0, 1, 3]\n    assert _af_invert([3, 1, 2, 0]) == [3, 1, 2, 0]\n\n    # Test _af_pow with various powers\n    assert _af_pow([2, 0, 3, 1], 4) == [0, 1, 2, 3]\n    assert _af_pow([2, 0, 3, 1], 2) == [3, 2, 1, 0]\n    assert _af_pow([2, 0, 3, 1], 3) == [1, 3, 2, 0]\n\n    # Test _af_commutes_with", "def test_af_functions():\n    # Testing _af_rmul\n    a = [1, 0, 2]\n    b = [0, 2, 1]\n    assert _af_rmul(a, b) == [1, 2, 0]\n\n    # Testing _af_rmuln\n    c = [2, 1, 0]\n    d = [1, 0, 2]\n    e = [0, 1, 2]\n    assert _af_rmuln(a, b, c, d, e) == [0, 2, 1]\n    assert _af_rmuln(a) == [1, 0, 2]\n    assert _af_rmuln(a, b) == [1, 2, 0]\n    assert _af_rmuln() == ValueError(\"String must not be empty\")\n\n    # Testing _af_parity\n    assert _af_parity([0, 1, 2, 3]) == 0\n    assert _af_parity([3, 2, 0, 1]) == 1\n\n    # Testing _af_invert\n    A = [1, 2, 0, 3]\n    assert _af_invert(A) == [2, 0, 1, 3]\n    assert _af_rmul(_af_invert(A), A) == [0, 1, 2, 3]\n\n    # Testing _af_pow\n    p = [2, 0, 3, 1]\n    assert _af_pow(p, 0) == [0, 1, 2, 3]\n    assert _af_pow(p, 1) == [2, 0, 3, 1]\n    assert _af_pow(p, 2) == [3, 2, 0, 1]\n    assert _af_pow(p, 3) == [1, 3, 2, 0]\n    assert _af_pow(p, 4) == [0, 1, 2, 3]\n    assert _af_pow(p, -1) == _af_invert(p)\n\n    # Testing _af_commutes_with\n    assert _af_commutes_with([1, 2, 0], [0, 2, 1]) == False\n    assert _af_commutes_with([", "def test__af_rmul():\n    a = [1, 0, 2]\n    b = [0, 2, 1]\n    assert _af_rmul(a, b) == [1, 2, 0]\n    assert _af_rmul(b, a) == [0, 1, 2]\n    assert _af_rmul([0, 1, 2], [2, 1, 0]) == [2, 1, 0]\n    assert _af_rmul([2, 1, 0], [0, 1, 2]) == [2, 1, 0]\n    assert _af_rmul([1, 2, 0], [2, 0, 1]) == [0, 1, 2]\n"], "sample_58": ["def test_no_dbname_or_service(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env(\n            {\n                \"USER\": \"someuser\",\n                \"PASSWORD\": \"somepassword\",\n                \"HOST\": \"somehost\",\n                \"PORT\": \"444\",\n            }\n        ),\n        (\n            [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"],\n            {\"PGPASSWORD\": \"somepassword\"},\n        ),\n    )\n", "    def test_default_dbname(self):\n        self.assertEqual(\n            self.settings_to_cmd_args_env(\n                {\n                    \"USER\": \"someuser\",\n                    \"HOST\": \"somehost\",\n                    \"PORT\": \"444\",\n                }\n            ),\n            (\n                [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"],\n                None,\n            ),\n        )\n", "    def test_no_dbname_or_service(self):\n        self.assertEqual(\n            self.settings_to_cmd_args_env(\n                {\n                    \"USER\": \"someuser\",\n                    \"HOST\": \"somehost\",\n                    \"PORT\": \"444\",\n                }\n            ),\n            (\n                [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"],\n                None,\n            ),\n        )\n", "    def test_default_dbname_when_not_provided(self):\n        self.assertEqual(\n            self.settings_to_cmd_args_env(\n                {\n                    \"USER\": \"someuser\",\n                    \"HOST\": \"somehost\",\n                    \"PORT\": \"444\",\n                }\n            ),\n            (\n                [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"],\n                None,\n            ),\n        )\n", "    def test_no_name_or_service_defaults_to_postgres(self):\n        self.assertEqual(\n            self.settings_to_cmd_args_env(\n                {\n                    \"USER\": \"someuser\",\n                    \"HOST\": \"somehost\",\n                    \"PORT\": \"444\",\n                }\n            ),\n            (\n                [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"],\n                None,\n            ),\n        )\n"], "sample_126": ["def test_mpf_norm_inf_nan():\n    from mpmath.libmp.libmpf import finf, fninf, fnan\n    assert mpf_norm(finf, 10) == finf\n    assert mpf_norm(fninf, 10) == fninf\n    assert mpf_norm(fnan, 10) == fnan\n\n    assert Float._new(finf, 10)._mpf_ == finf\n    assert Float._new(fninf, 10)._mpf_ == fninf\n    assert Float._new(fnan, 10)._mpf_ == fnan\n", "def test_mpf_norm_with_custom_mpf_tuples():\n    # Testing the mpf_norm function directly with different custom mpf tuples\n    # These custom tuples are to test edge cases in normalization logic\n\n    # Case with zero mantissa\n    assert mpf_norm((0, 0, 0, 0), 53) == (0, 0, 0, 0)\n\n    # Case with a positive normalized number\n    assert mpf_norm((0, 12345, 20, 14), 53) == (0, 12345, 20, 14)\n\n    # Case with a negative normalized number\n    assert mpf_norm((1, 12345, 20, 14), 53) == (1, 12345, 20, 14)\n\n    # Case with a large exponent\n    assert mpf_norm((0, 12345, 10000, 14), 53) == (0, 12345, 10000, 14)\n\n    # Case with a small exponent\n    assert mpf_norm((0, 12345, -10000, 14), 53) == (0, 12345, -10000, 14)\n\n    # Case with a small precision\n    assert mpf_norm((0, 12345, 20, 2), 53) == (0, 12345, 20, 2)\n\n    # Case with inf mantissa\n    assert mpf_norm((0, 0, 0, 0), 53) == (0, 0, 0, 0)\n\n    # Case with nan mantissa\n    assert mpf_norm((0, 0, 0, 0), 53) == (0, 0, 0, 0)\n", "def test_mpf_norm():\n    assert mpf_norm((0, 0, 0, 0), 10) == (0, 0, 0, 0)\n    assert mpf_norm((1, 2, 3, 4), 10) == (1, 2, 3, 4)\n    assert mpf_norm((0, 123456789, -5, 10), 10) == (0, 123456789, -5, 10)\n    assert mpf_norm((1, 123456789, -5, 10), 10) == (1, 123456789, -5, 10)\n    assert mpf_norm((1, 0, 3, 0), 10) == (0, 0, 0, 0)\n    assert mpf_norm((0, 0, 0, 10), 10) == (0, 0, 0, 0)\n    assert mpf_norm((1, 0, 0, 0), 10) == (0, 0, 0, 0)\n    assert mpf_norm((0, 0, 1, 0), 10) == (0, 0, 0, 0)\n    assert mpf_norm((1, 0, 1, 0), 10) == (0, 0, 0, 0)\n    assert mpf_norm((0, 1, 0, 0), 10) == (0, 1, 0, 0)\n", "def test_mpf_norm():\n    # Testing mpf_norm function for various edge cases\n    assert mpf_norm((1, 0, 1, 0), 10) == mlib.fzero  # Should be zero\n    assert mpf_norm((0, 1, 1, 0), 10) == (0, 1, 1, 0)  # Should be unchanged\n    assert mpf_norm((1, 1, 1, 0), 10) == (1, 1, 1, 0)  # Should be unchanged\n    assert mpf_norm((0, 1, 1, 2), 10) == (0, 1, 1, 2)  # Should be unchanged\n    assert mpf_norm((1, 0, 1, 2), 10) == mlib.fzero  # Should be zero\n\n    # Testing with infinities and NaN\n    assert mpf_norm(mlib.finf, 10) == mlib.finf\n    assert mpf_norm(mlib.fninf, 10) == mlib.fninf\n    assert mpf_norm(mlib.fnan, 10) == mlib.fnan\n\n    # Test with very large numbers\n    large_number = (0, 1 << 100, 100, 100)\n    assert mpf_norm(large_number, 200) == large_number\n\n    # Test with very small numbers\n    small_number = (0, 1, -100, 100)\n    assert mpf_norm(small_number, 200) == small_number\n", "def test_mpf_norm_edge_cases():\n    # Check if mpf_norm handles edge cases correctly\n    # Edge case: Very small exponent, mantissa and zero bits\n    assert mpf_norm((0, 0, -1000000, 0), 53) == (0, 0, 0, 0)\n\n    # Edge case: Large exponent with a small mantissa\n    assert mpf_norm((0, 1, 1000000, 1), 53) == (0, 1, 1000000, 1)\n\n    # Edge case: Zero mantissa\n    assert mpf_norm((0, 0, 1, 1), 53) == (0, 0, 0, 0)\n\n    # Edge case: Infinity and negative infinity\n    from mpmath.libmp.libmpf import finf, fninf\n    assert mpf_norm(finf, 53) == finf\n    assert mpf_norm(fninf, 53) == fninf\n\n    # Edge case: NaN\n    from mpmath.libmp.libmpf import fnan\n    assert mpf_norm(fnan, 53) == fnan\n\n    # Edge case: Very large exponent with non-zero mantissa\n    assert mpf_norm((0, 1, 10**6, 53), 53) == (0, 1, 10**6, 53)\n"], "sample_41": ["    def test_management_form_clean_default_values(self):\n        \"\"\"\n        Verify that ManagementForm.clean() method sets default values for\n        TOTAL_FORM_COUNT and INITIAL_FORM_COUNT when they are missing.\n        \"\"\"\n        data = {\n            'choices-TOTAL_FORMS': '',\n            'choices-INITIAL_FORMS': '',\n        }\n        form = ManagementForm(data)\n        cleaned_data = form.clean()\n        self.assertEqual(cleaned_data[TOTAL_FORM_COUNT], 0)\n        self.assertEqual(cleaned_data[INITIAL_FORM_COUNT], 0)\n", "def test_management_form_cleaning(self):\n    \"\"\"Test the cleaning of ManagementForm in isolation.\"\"\"\n    data = {\n        'choices-TOTAL_FORMS': '2',\n        'choices-INITIAL_FORMS': '1',\n        'choices-MIN_NUM_FORMS': '0',\n        'choices-MAX_NUM_FORMS': '0',\n    }\n    form = ManagementForm(data)\n    self.assertTrue(form.is_valid())\n    cleaned_data = form.clean()\n    self.assertEqual(cleaned_data[TOTAL_FORM_COUNT], 2)\n    self.assertEqual(cleaned_data[INITIAL_FORM_COUNT], 1)\n    self.assertEqual(cleaned_data[MIN_NUM_FORM_COUNT], 0)\n    self.assertEqual(cleaned_data[MAX_NUM_FORM_COUNT], 0)\n", "    def test_management_form_missing_fields(self):\n        \"\"\"Test missing management form fields in the formset.\"\"\"\n        data = {\n            'choices-TOTAL_FORMS': '1',\n            # 'choices-INITIAL_FORMS': '0',  # This field is missing\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-MAX_NUM_FORMS': '1000',\n            'choices-0-choice': 'Calexico',\n            'choices-0-votes': '100',\n        }\n        formset = self.make_choiceformset(data=data)\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(\n            formset.non_form_errors(),\n            ['ManagementForm data is missing or has been tampered with. Missing fields: choices-INITIAL_FORMS. You may need to file a bug report if the issue persists.']\n        )\n", "    def test_initial_form_data_overrides_management_form_fields(self):\n        \"\"\"\n        Test that initial form data overrides management form fields if present.\n        \"\"\"\n        initial = [{'choice': 'Calexico', 'votes': 100}]\n        formset = self.make_choiceformset(initial=initial)\n        self.assertEqual(formset.management_form.initial[TOTAL_FORM_COUNT], 1)\n        self.assertEqual(formset.management_form.initial[INITIAL_FORM_COUNT], 1)\n        self.assertEqual(formset.management_form.initial[MIN_NUM_FORM_COUNT], 0)\n        self.assertEqual(formset.management_form.initial[MAX_NUM_FORM_COUNT], 1000)\n        form = formset[0]\n        self.assertEqual(form.initial['choice'], 'Calexico')\n        self.assertEqual(form.initial['votes'], 100)\n", "    def test_prefilled_data_with_deletion_and_ordering(self):\n        \"\"\"\n        Test a formset with both prefilled data, deletion and ordering enabled.\n        \"\"\"\n        initial = [\n            {'choice': 'Calexico', 'votes': 100},\n            {'choice': 'Fergie', 'votes': 900},\n            {'choice': 'The Decemberists', 'votes': 500}\n        ]\n        data = {\n            'choices-TOTAL_FORMS': '3',\n            'choices-INITIAL_FORMS': '3',\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-MAX_NUM_FORMS': '3',\n            'choices-0-choice': 'Calexico',\n            'choices-0-votes': '100',\n            'choices-0-ORDER': '2',\n            'choices-0-DELETE': 'on',\n            'choices-1-choice': 'Fergie',\n            'choices-1-votes': '900',\n            'choices-1-ORDER': '1',\n            'choices-1-DELETE': '',\n            'choices-2-choice': 'The Decemberists',\n            'choices-2-votes': '500',\n            'choices-2-ORDER': '0',\n            'choices-2-DELETE': '',\n        }\n        ChoiceFormSet = formset_factory(Choice, can_delete=True, can_order=True)\n        formset = ChoiceFormSet(data, auto_id=False, prefix='choices', initial=initial)\n        self.assertTrue(formset.is_valid())\n        self.assertEqual(\n            [form.cleaned_data for form in formset.ordered_forms],\n            [\n                {'votes': 500, 'ORDER': 0, 'choice': 'The Decemberists', 'DELETE': False},\n                {'votes': 900, 'ORDER': 1, 'choice': 'Fergie', 'DELETE': False},\n            ],\n        )\n        self.assertEqual(\n            [form.cleaned_data for form in formset.deleted_forms],\n            [{'votes': 100, 'ORDER': 2, 'choice': 'Calexico', 'DELETE': True}]\n        )\n"], "sample_94": ["def test_source_from_string_with_blank_lines() -> None:\n    source = Source(\n        \"\"\"\n        \n            pass\n        \n        \n        \"\"\"\n    )\n    assert source.lines == [\"\", \"def f():\", \"    pass\", \"\"]\n", "def test_source_from_multiline_string() -> None:\n    multiline_string = \"\"\"\\\n        x = 1\n        y = 2\n        return x + y\n    \"\"\"\n    source = Source(multiline_string)\n    assert str(source) == \"def foo():\\n    x = 1\\n    y = 2\\n    return x + y\"\n", "def test_source_indent() -> None:\n    source = Source(\"def func():\\n    pass\")\n    indented_source = source.indent(\"    \")\n    expected = Source(\"    def func():\\n        pass\")\n    assert indented_source == expected\n", "def test_source_indent() -> None:\n    source = Source(\"def func():\\n    pass\")\n    indented_source = source.indent(\"  \")\n    assert str(indented_source) == \"  def func():\\n    pass\"\n", "def test_source_indent() -> None:\n    source = Source(\n        \"\"\"\\"], "sample_65": ["    def test_join09(self):\n        output = self.engine.render_to_string(\"join09\", {\"a\": [\"alpha\", \"beta & me\"]})\n        self.assertEqual(output, \"ALPHA, BETA &AMP; ME\")\n", "    def test_join09(self):\n        output = self.engine.render_to_string(\n            \"join09\", {\"a\": [\"alpha\", \"beta & me\"], \"var\": \" & \"}\n        )\n        self.assertEqual(output, \"ALPHA &AMP; BETA &AMP; ME\")\n", "    def test_join09(self):\n        output = self.engine.render_to_string(\"join09\", {\"a\": [\"alpha\", None, \"beta\"]})\n        self.assertEqual(output, \"alpha  beta\")\n", "    def test_join09(self):\n        output = self.engine.render_to_string(\n            \"join09\", {\"a\": [\"alpha\", \"beta & me\"], \"var\": \" & \"}\n        )\n        self.assertEqual(output, \"ALPHA &AMP; BETA &AMP; ME\")\n", "    def test_join09(self):\n        output = self.engine.render_to_string(\n            \"join09\", {\"a\": [\"alpha\", None, \"beta & me\"], \"var\": \" & \"}\n        )\n        self.assertEqual(output, \"alpha &  &amp; beta &amp; me\")\n"], "sample_72": ["def test_suptitle():\n    fig = plt.figure()\n    title = \"Super Title\"\n    suptitle = fig.suptitle(title)\n    assert suptitle.get_text() == title\n    assert suptitle.get_position() == (0.5, 0.98)\n    assert suptitle.get_horizontalalignment() == 'center'\n    assert suptitle.get_verticalalignment() == 'top'\n", "def test_update_subplot_params():\n    fig = plt.figure()\n    assert fig.subplotpars.left == mpl.rcParams[\"figure.subplot.left\"]\n    assert fig.subplotpars.right == mpl.rcParams[\"figure.subplot.right\"]\n\n    fig.subplotpars.update(left=0.2, right=0.8)\n    assert fig.subplotpars.left == 0.2\n    assert fig.subplotpars.right == 0.8\n\n    with pytest.raises(ValueError, match=\"left cannot be >= right\"):\n        fig.subplotpars.update(left=0.9, right=0.8)\n        \n    with pytest.raises(ValueError, match=\"bottom cannot be >= top\"):\n        fig.subplotpars.update(bottom=0.8, top=0.7)\n", "def test_subplot_mosaic():\n    fig = plt.figure()\n    mosaic = \"\"\"\n    AB\n    CD\n    \"\"\"\n    axs = fig.subplot_mosaic(mosaic)\n    assert len(axs) == 4\n    assert axs['A']._subplotspec.rowspan == (0, 1)\n    assert axs['A']._subplotspec.colspan == (0, 1)\n    assert axs['B']._subplotspec.rowspan == (0, 1)\n    assert axs['B']._subplotspec.colspan == (1, 2)\n    assert axs['C']._subplotspec.rowspan == (1, 2)\n    assert axs['C']._subplotspec.colspan == (0, 1)\n    assert axs['D']._subplotspec.rowspan == (1, 2)\n    assert axs['D']._subplotspec.colspan == (1, 2)\n", "def test_figure_add_artist():\n    fig = plt.figure()\n    artist = fig.text(0.5, 0.5, \"test\")\n    \n    fig.add_artist(artist)\n    assert artist in fig.artists\n    assert artist.get_figure() == fig\n", "def test_subplotparams_update():\n    # Create a SubplotParams instance with default parameters\n    sp = Figure().subplotpars\n\n    # Update the parameters\n    sp.update(left=0.1, bottom=0.2, right=0.9, top=0.8, wspace=0.5, hspace=0.6)\n\n    # Verify the updates\n    assert sp.left == 0.1\n    assert sp.bottom == 0.2\n    assert sp.right == 0.9\n    assert sp.top == 0.8\n    assert sp.wspace == 0.5\n    assert sp.hspace == 0.6\n\n    # Verify that an invalid update raises a ValueError\n    with pytest.raises(ValueError):\n        sp.update(left=0.9, right=0.1)\n    with pytest.raises(ValueError):\n        sp.update(bottom=0.8, top=0.2)\n"], "sample_122": ["def test_matrix_extraction():\n    # Test the extract method for submatrix extraction\n    a = SparseMatrix([\n        [1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]\n    ])\n    sub_a = a.extract([0, 1], [1, 2])\n    assert sub_a == SparseMatrix([\n        [2, 3],\n        [5, 6]\n    ])\n\n    sub_a = a.extract([2], [0, 2])\n    assert sub_a == SparseMatrix([\n        [7, 9]\n    ])\n\n    sub_a = a.extract([0, 1, 2], [0, 2])\n    assert sub_a == SparseMatrix([\n        [1, 3],\n        [4, 6],\n        [7, 9]\n    ])\n\n    # Test extraction with repetition of rows and columns\n    sub_a = a.extract([0, 1, 1], [1, 2, 2])\n    assert sub_a == SparseMatrix([\n        [2, 3, 3],\n        [5, 6, 6],\n        [5, 6, 6]\n    ])\n\n    # Test extraction with unsorted and duplicate indices\n    sub_a = a.extract([2, 0, 2], [2, 0, 1])\n    assert sub_a == SparseMatrix([\n        [9, 7, 8],\n        [3, 1, 2],\n        [9, 7, 8]\n    ])\n", "def test_matrix_extraction():\n    a = SparseMatrix([\n        [1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9],\n        [10, 11, 12]\n    ])\n    assert a.extract([0, 2], [1, 2]) == SparseMatrix([\n        [2, 3],\n        [8, 9]\n    ])\n    assert a.extract([1, 3], [0, 1, 2]) == SparseMatrix([\n        [4, 5, 6],\n        [10, 11, 12]\n    ])\n    assert a.extract([0, 1, 2, 3], [1]) == SparseMatrix([\n        [2],\n        [5],\n        [8],\n        [11]\n    ])\n", "def test_matrix_division():\n    from sympy import symbols\n    x, y = symbols('x y')\n    A = SparseMatrix([[x, y], [2, 3]])\n    B = SparseMatrix([[1, 0], [0, 1]])\n    assert A / B == A\n    assert A / 1 == A\n    C = SparseMatrix([[x, y], [0, 3]])\n    D = SparseMatrix([[1, 0], [0, y]])\n    assert (C / D).applyfunc(lambda i: i.simplify()) == SparseMatrix([[x, 1], [0, 3/y]])\n", "def test_scalar_multiply():\n    a = SparseMatrix([\n        [1, 0],\n        [0, 1]\n    ])\n    b = a.scalar_multiply(5)\n    assert b == SparseMatrix([\n        [5, 0],\n        [0, 5]\n    ])\n\n    c = SparseMatrix([\n        [2, -3],\n        [0, 4]\n    ])\n    d = c.scalar_multiply(-2)\n    assert d == SparseMatrix([\n        [-4, 6],\n        [0, -8]\n    ])\n\n    e = SparseMatrix(2, 2, {})\n    f = e.scalar_multiply(7)\n    assert f == SparseMatrix(2, 2, {})\n", "def test_applyfunc_exceptions():\n    # Ensure applyfunc raises TypeError with non-callable argument\n    a = SparseMatrix(2, 2, [1, 2, 3, 4])\n    raises(TypeError, lambda: a.applyfunc(42))\n    raises(TypeError, lambda: a.applyfunc(\"not_callable\"))\n\n    # Ensure applyfunc works with a valid callable\n    result = a.applyfunc(lambda x: x**2)\n    assert result == SparseMatrix(2, 2, [1, 4, 9, 16])\n"], "sample_91": ["def test_evaluate_condition_syntax_error(self, testdir):\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.skipif(\"invalid syntax\", reason=\"syntax error\")\n            pass\n        \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_skip_marks(item)\n    assert excinfo.value.msg is not None\n    assert \"SyntaxError: invalid syntax\" in excinfo.value.msg\n", "def test_xfail_with_invalid_syntax_in_condition(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(\"invalid syntax\")\n            pass\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\n        \"*ERROR*test_func*\",\n        \"*evaluating*xfail*condition*\",\n        \"    invalid syntax\",\n        \"              ^\",\n        \"SyntaxError: invalid syntax\",\n        \"*1 error*\"\n    ])\n", "def test_marked_xfail_with_raises(self, testdir):\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(raises=ZeroDivisionError, reason=\"Expected zero division error\")\n            1 / 0\n    \"\"\"\n    )\n    xfailed = evaluate_xfail_marks(item)\n    assert xfailed\n    assert xfailed.reason == \"Expected zero division error\"\n    assert xfailed.raises == (ZeroDivisionError,)\n    reports = runtestprotocol(item, log=False)\n    assert len(reports) == 3\n    callreport = reports[1]\n    assert callreport.skipped\n    assert callreport.wasxfail == \"Expected zero division error\"\n", "def test_dynamic_xfail_run_false_with_reason(self, testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            request.node.add_marker(pytest.mark.xfail(run=False, reason=\"fixture xfail\"))\n\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxX\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_func*\",\n            \"*NOTRUN*fixture xfail*\"\n        ]\n    )\n", "def test_skip_with_custom_message_in_eval_condition(testdir):\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.skipif(\"3 > 2\", reason=\"custom reason\")\n            pass\n    \"\"\"\n    )\n    skipped = evaluate_skip_marks(item)\n    assert skipped\n    assert skipped.reason == \"custom reason\"\n"], "sample_115": ["def test_wrap_method_output_tuple():\n    \"\"\"Check that _wrap_method_output correctly wraps methods returning tuples.\"\"\"\n\n    class EstimatorWithTupleOutput(_SetOutputMixin):\n            self.n_features_in_ = X.shape[1]\n            return self\n\n            return (X, X + 1)\n\n            return np.asarray([f\"X{i}\" for i in range(self.n_features_in_)], dtype=object)\n\n    pd = pytest.importorskip(\"pandas\")\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    est = EstimatorWithTupleOutput().fit(X)\n\n    est.set_output(transform=\"pandas\")\n    X_trans_tuple = est.transform(X)\n    \n    assert isinstance(X_trans_tuple, tuple)\n    assert isinstance(X_trans_tuple[0], pd.DataFrame)\n    assert isinstance(X_trans_tuple[1], np.ndarray)\n    assert_array_equal(X_trans_tuple[0].columns, est.get_feature_names_out())\n    assert_array_equal(X_trans_tuple[1], X + 1)\n", "def test__wrap_data_with_container_default():\n    \"\"\"Check _wrap_data_with_container for default output.\"\"\"\n    X = np.asarray([[1, 2, 3], [4, 5, 6]])\n    est = EstimatorWithSetOutput().fit(X)\n    \n    # Ensure that when the config is set to \"default\", the output is unchanged\n    est.set_output(transform=\"default\")\n    wrapped_data = _wrap_data_with_container(\"transform\", X, X, est)\n    assert isinstance(wrapped_data, np.ndarray)\n    assert_array_equal(wrapped_data, X)\n", "def test_set_output_mixin_inheritance():\n    \"\"\"Check that _SetOutputMixin works correctly with multiple inheritance.\"\"\"\n\n    class BaseEstimator:\n            self.n_features_in_ = X.shape[1]\n            return self\n\n            return X\n\n    class CombinedEstimator(BaseEstimator, _SetOutputMixin):\n            return np.asarray([f\"X{i}\" for i in range(self.n_features_in_)], dtype=object)\n\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    est = CombinedEstimator().fit(X)\n\n    # Check without setting output\n    X_trans = est.transform(X)\n    assert isinstance(X_trans, np.ndarray)\n\n    # Check with pandas output\n    est.set_output(transform=\"pandas\")\n    X_trans_pd = est.transform(X)\n    pd = pytest.importorskip(\"pandas\")\n    assert isinstance(X_trans_pd, pd.DataFrame)\n    assert_array_equal(X_trans_pd.columns, est.get_feature_names_out())\n", "def test__wrap_data_with_container():\n    \"\"\"Check _wrap_data_with_container works as expected.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    original_input = pd.DataFrame(X, columns=[\"a\", \"b\", \"c\"])\n\n    est = EstimatorWithSetOutput().fit(X)\n\n    # Default output config should return numpy array\n    est.set_output(transform=\"default\")\n    X_trans = _wrap_data_with_container(\"transform\", X, original_input, est)\n    assert isinstance(X_trans, np.ndarray)\n\n    # Pandas output config should return pandas DataFrame\n    est.set_output(transform=\"pandas\")\n    X_trans = _wrap_data_with_container(\"transform\", X, original_input, est)\n    assert isinstance(X_trans, pd.DataFrame)\n    assert_array_equal(X_trans.columns, est.get_feature_names_out())\n    assert_array_equal(X_trans.index, original_input.index)\n", "def test_wrap_method_output_multiple_outputs():\n    \"\"\"Check _wrap_method_output handles multiple outputs correctly.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    class EstimatorWithMultipleOutputs(_SetOutputMixin):\n            self.n_features_in_ = X.shape[1]\n            return self\n\n            return X, X + 1\n\n            return np.asarray([f\"X{i}\" for i in range(self.n_features_in_)], dtype=object)\n\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    est = EstimatorWithMultipleOutputs().fit(X)\n    est.set_output(transform=\"pandas\")\n\n    X_trans_1, X_trans_2 = est.transform(X)\n    assert isinstance(X_trans_1, pd.DataFrame)\n    assert isinstance(X_trans_2, np.ndarray)\n"], "sample_15": ["    def test_supported_language_variant(self):\n        \"\"\"Test if LANGUAGE_CODE is correctly identified as a supported variant.\"\"\"\n        # This should not raise an error because 'fr' is in LANGUAGES.\n        self.assertEqual(check_language_settings_consistent(None), [])\n", "def test_invalid_variant_inconsistent_language_settings(self):\n    msg = (\n        'You have provided a value for the LANGUAGE_CODE setting that is '\n        'not in the LANGUAGES setting.'\n    )\n    for tag in ['zh-Hant', 'es-XYZ', 'en-GB-oed']:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [\n                Error(msg, id='translation.E004'),\n            ])\n", "    def test_invalid_variant_inconsistent_language_settings(self):\n        msg = (\n            'You have provided a value for the LANGUAGE_CODE setting that is '\n            'not in the LANGUAGES setting.'\n        )\n        for tag in ['fr-CA-variant', 'es-419-variant']:\n            with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n                self.assertEqual(check_language_settings_consistent(None), [\n                    Error(msg, id='translation.E004'),\n                ])\n", "    def test_inconsistent_language_settings_bidi(self):\n        msg = (\n            'You have provided a value for the LANGUAGE_CODE setting that is '\n            'not in the LANGUAGES setting.'\n        )\n        # Test a valid LANGUAGE_CODE but not in LANGUAGES_BIDI\n        with self.settings(LANGUAGE_CODE='en'):\n            self.assertEqual(check_language_settings_consistent(None), [])\n\n        # Test a LANGUAGE_CODE that is in LANGUAGES_BIDI but not in LANGUAGES\n        with self.settings(LANGUAGE_CODE='sgn-ase'):\n            self.assertEqual(check_language_settings_consistent(None), [\n                Error(msg, id='translation.E004'),\n            ])\n", "def test_mixed_valid_invalid_language_settings(self):\n    valid_tags = ['en', 'zh-Hans', 'pt-BR', 'sr-Latn']\n    invalid_tags = ['fr-xx', 'es-XX', 'de-INVALID']\n    \n    for tag in valid_tags:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [])\n\n    for tag in invalid_tags:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [\n                Error(\n                    'You have provided a value for the LANGUAGE_CODE setting that is not in the LANGUAGES setting.',\n                    id='translation.E004',\n                ),\n            ])\n"], "sample_12": ["def test_alter_field_with_default(self):\n    \"\"\"\n    Test that altering a field's default value is detected and the correct migration is generated.\n    \"\"\"\n    before = ModelState('testapp', 'Author', [\n        ('id', models.AutoField(primary_key=True)),\n        ('name', models.CharField(max_length=200)),\n    ])\n    after = ModelState('testapp', 'Author', [\n        ('id', models.AutoField(primary_key=True)),\n        ('name', models.CharField(max_length=200, default='Jane Doe')),\n    ])\n    changes = self.get_changes([before], [after])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, ['AlterField'])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name', preserve_default=True)\n    self.assertOperationFieldAttributes(changes, 'testapp', 0, 0, default='Jane Doe')\n", "    def test_deep_deconstruct_with_partial(self):\n        \"\"\"\n        Tests the deep deconstruction of a model with a field using functools.partial.\n        \"\"\"\n            return f\"{instance}/{filename}\"\n\n        partial_func = functools.partial(sample_function)\n\n        before = ModelState(\"testapp\", \"Author\", [\n            (\"id\", models.AutoField(primary_key=True)),\n        ])\n\n        after = ModelState(\"testapp\", \"Author\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"file\", models.FileField(upload_to=partial_func)),\n        ])\n\n        changes = self.get_changes([before], [after])\n\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n        self.assertOperationFieldAttributes(\n            changes, \"testapp\", 0, 0, upload_to=partial_func\n        )\n", "    def test_alter_field_with_check_constraint(self):\n        \"\"\"Test change detection of altering a field with a check constraint.\"\"\"\n        changes = self.get_changes([self.author_name_check_constraint], [self.author_name_longer])\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['AlterField', 'RemoveConstraint'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name')\n        self.assertOperationAttributes(changes, 'testapp', 0, 1, model_name='author', name='name_contains_bob')\n", "    def test_remove_foo_together_and_add_indexes(self):\n        \"\"\"\n        Removing unique_together/index_together and adding new indexes should generate the correct operations.\n        \"\"\"\n        changes = self.get_changes(\n            [self.author_empty, self.book_foo_together],\n            [self.author_empty, self.book_indexes]\n        )\n        self.assertNumberMigrations(changes, 'otherapp', 1)\n        self.assertOperationTypes(changes, 'otherapp', 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\", \"AddIndex\"])\n        self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"book\", unique_together=set())\n        self.assertOperationAttributes(changes, \"otherapp\", 0, 1, name=\"book\", index_together=set())\n        added_index = models.Index(fields=[\"author\", \"title\"], name=\"book_title_author_idx\")\n        self.assertOperationAttributes(changes, \"otherapp\", 0, 2, model_name=\"book\", index=added_index)\n", "    def test_alter_model_managers_removal(self):\n        \"\"\"\n        Test that removing a model manager is detected correctly.\n        \"\"\"\n        changes = self.get_changes([self.other_pony_food], [self.other_pony])\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, 'otherapp', 1)\n        self.assertOperationTypes(changes, 'otherapp', 0, [\"AlterModelManagers\"])\n        self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"pony\")\n        self.assertEqual([name for name, mgr in changes['otherapp'][0].operations[0].managers], [])\n"], "sample_81": ["    def setUp(self):\n        super().setUp()\n        self.linter._by_id_managed_msgs = []\n", "    def test_non_ascii_without_encoding_declaration(self) -> None:\n        code = \"\"\"# non-ASCII character: \u00f1\n                a = 1\n                \"\"\"\n        node = self.checker.linter.current_name_scope().lookup(\"module\")\n        node.file_encoding = None\n        with self.assertNoMessages():\n            self.checker.process_module(node)\n", "    def test_message_disabled_by_id(self) -> None:\n        code = \"\"\"a = 1\n                # pylint: disable=I0011\n                \"\"\"\n        self.checker.linter._by_id_managed_msgs = [\n            (\"test_module\", \"I0011\", \"some-symbol\", 2, True)\n        ]\n        with self.assertAddsMessages(\n            MessageTest(\n                msg_id=\"use-symbolic-message-instead\",\n                line=2,\n                args=\"'I0011' is cryptic: use '# pylint: disable=some-symbol' instead\"\n            )\n        ):\n            self.checker.process_module(self.create_node(\"test_module\", code))\n", "    def test_non_ascii_without_encoding_declaration(self) -> None:\n        code = 'a = \"\u03b1\u03b2\u03b3\"\\n'\n        node = self.checker.linter.make_file_node(code)\n        with self.assertNoMessages():\n            self.checker.process_module(node)\n    ", "    def test_invalid_utf8_encoding(self) -> None:\n        code = b\"\"\"# coding: utf-8\\n\\x80\\x81\\x82\"\"\"\n        with self.assertAddsMessages(\n            MessageTest(\n                msg_id=\"syntax-error\",\n                line=2,\n                args=\"Cannot decode using encoding 'utf-8', bad encoding\",\n            )\n        ):\n            module_node = self.create_module_node_from_bytes(code)\n            self.checker.process_module(module_node)\n"], "sample_4": ["    def test_charset_extraction_from_content_type(self):\n        response = HttpResponse(content_type='text/html; charset=iso-8859-1')\n        self.assertEqual(response.charset, 'iso-8859-1')\n\n        response = HttpResponse(content_type='text/html; charset=\"utf-8\"')\n        self.assertEqual(response.charset, 'utf-8')\n\n        response = HttpResponse(content_type='text/html')\n        self.assertEqual(response.charset, settings.DEFAULT_CHARSET)\n\n        response = HttpResponse()\n        self.assertEqual(response.charset, settings.DEFAULT_CHARSET)\n\n        response = HttpResponse(content_type='text/plain; charset=windows-1252')\n        self.assertEqual(response.charset, 'windows-1252')\n\n        response = HttpResponse(content_type='application/json; charset=utf-8')\n        self.assertEqual(response.charset, 'utf-8')\n", "    def test_http_response_delete_cookie(self):\n        response = HttpResponse()\n        response.set_cookie('my_cookie', 'value')\n        self.assertIn('my_cookie', response.cookies)\n\n        response.delete_cookie('my_cookie')\n        self.assertIn('Set-Cookie', response.serialize_headers().decode())\n        self.assertIn('my_cookie=; Max-Age=0;', response.serialize_headers().decode())\n", "    def test_gone_response(self):\n        response = HttpResponseGone()\n        self.assertEqual(response.status_code, 410)\n        self.assertContains(response, '', status_code=410)\n        self.assertEqual(response['Content-Type'], 'text/html; charset=utf-8')\n", "    def test_file_response(self):\n        file_content = b'This is a test file content'\n        filename = 'testfile.txt'\n        filelike = io.BytesIO(file_content)\n        filelike.name = filename\n\n        response = FileResponse(filelike, as_attachment=True, filename=filename)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response['Content-Disposition'], f'attachment; filename=\"{filename}\"')\n        self.assertEqual(response['Content-Length'], str(len(file_content)))\n        self.assertEqual(response['Content-Type'], 'text/plain')\n        self.assertEqual(b''.join(response), file_content)\n", "    def test_file_response_as_attachment(self):\n        file_path = os.path.join(os.path.dirname(__file__), 'testfile.txt')\n        with open(file_path, 'w') as f:\n            f.write('This is a test file.')\n\n        with open(file_path, 'rb') as f:\n            response = FileResponse(f, as_attachment=True, filename='testfile.txt')\n            self.assertEqual(response['Content-Disposition'], 'attachment; filename=\"testfile.txt\"')\n            self.assertEqual(response.status_code, 200)\n\n        os.remove(file_path)\n"], "sample_1": ["def test_get_type_from_list_of_lines():\n    lines = [\n        \"! A comment\",\n        \"543 12 456.0\",\n        \"READ SERR 1\",\n        \"NO NO NO\"\n    ]\n    types, ncol = _get_type_from_list_of_lines(lines)\n    assert types == [\"comment\", \"data,3\", \"command\", \"new\"]\n    assert ncol == 3\n\n    lines_inconsistent = [\n        \"! Another comment\",\n        \"123 456\",\n        \"789 012 345\"\n    ]\n    with pytest.raises(ValueError, match=\"Inconsistent number of columns\"):\n        _get_type_from_list_of_lines(lines_inconsistent)\n", "def test_interpret_err_lines():\n    # Case 1: No error specifications, default column names\n    colnames = _interpret_err_lines(None, 3)\n    assert colnames == [\"col1\", \"col2\", \"col3\"]\n\n    # Case 2: With symmetric and two-sided error specifications\n    err_specs = {\"serr\": [2], \"terr\": [1]}\n    colnames = _interpret_err_lines(err_specs, 5, names=[\"MJD\", \"Rate\"])\n    assert colnames == [\"MJD\", \"MJD_perr\", \"MJD_nerr\", \"Rate\", \"Rate_err\"]\n\n    # Case 3: Inconsistent number of input colnames\n    with pytest.raises(ValueError, match=\"Inconsistent number of input colnames\"):\n        _interpret_err_lines(err_specs, 6, names=[\"MJD\", \"Rate\"])\n\n    # Case 4: Only symmetric error specifications\n    err_specs = {\"serr\": [2]}\n    colnames = _interpret_err_lines(err_specs, 3, names=[\"MJD\", \"Rate\"])\n    assert colnames == [\"MJD\", \"Rate\", \"Rate_err\"]\n\n    # Case 5: Only two-sided error specifications\n    err_specs = {\"terr\": [1]}\n    colnames = _interpret_err_lines(err_specs, 4, names=[\"MJD\", \"Rate\"])\n    assert colnames == [\"MJD\", \"MJD_perr\", \"MJD_nerr\", \"Rate\"]\n", "def test_interpret_err_lines():\n    err_specs = {\"serr\": [1], \"terr\": [2, 3]}\n    colnames = _interpret_err_lines(err_specs, 5, names=[\"a\", \"b\", \"c\"])\n    assert colnames == [\"a\", \"b_perr\", \"b_nerr\", \"c\", \"c_err\"]\n\n    err_specs = {\"serr\": [2], \"terr\": [1]}\n    colnames = _interpret_err_lines(err_specs, 5, names=[\"a\", \"b\", \"c\"])\n    assert colnames == [\"a\", \"a_perr\", \"a_nerr\", \"b\", \"b_err\"]\n\n    err_specs = {}\n    colnames = _interpret_err_lines(err_specs, 3, names=[\"a\", \"b\", \"c\"])\n    assert colnames == [\"a\", \"b\", \"c\"]\n\n    with pytest.raises(ValueError, match=\"Inconsistent number of input colnames\"):\n        _interpret_err_lines({\"serr\": [1], \"terr\": [2]}, 4, names=[\"a\", \"b\"])\n\n    with pytest.raises(ValueError, match=\"Inconsistent number of input colnames\"):\n        _interpret_err_lines({\"serr\": [1]}, 3, names=[\"a\", \"b\"])\n", "def test_inconsistent_columns_error():\n    example_qdp = \"\"\"\n    ! Initial comment line 1\n    ! Initial comment line 2\n    READ SERR 2\n    ! Table 0 comment\n    !a b c\n    53000.5 1.0\n    54000.5 2.0 3.0 4.0\n    \"\"\"\n    \n    with pytest.raises(ValueError, match=\"Inconsistent number of columns\"):\n        ascii.read(example_qdp, format=\"qdp\", table_id=0, names=[\"a\", \"b\", \"c\"])\n", "def test_interpret_err_lines():\n    # Test without error specifications\n    colnames = _interpret_err_lines(None, 3, names=['col1', 'col2', 'col3'])\n    assert colnames == ['col1', 'col2', 'col3']\n\n    # Test with symmetric and two-sided error specifications\n    err_specs = {'serr': [2], 'terr': [1]}\n    colnames = _interpret_err_lines(err_specs, 5, names=['MJD', 'Rate'])\n    assert colnames == ['MJD', 'MJD_perr', 'MJD_nerr', 'Rate', 'Rate_err']\n\n    # Test inconsistent number of input colnames\n    with pytest.raises(ValueError, match=\"Inconsistent number of input colnames\"):\n        _interpret_err_lines(err_specs, 6, names=['MJD', 'Rate'])\n"], "sample_102": ["def test_iforest_random_state():\n    \"\"\"Test Isolation Forest with different random states to ensure reproducibility.\"\"\"\n    X_train, X_test, y_train, y_test = train_test_split(boston.data,\n                                                        boston.target,\n                                                        random_state=42)\n    clf1 = IsolationForest(random_state=42).fit(X_train)\n    y_pred1 = clf1.predict(X_test)\n    clf2 = IsolationForest(random_state=42).fit(X_train)\n    y_pred2 = clf2.predict(X_test)\n    assert_array_equal(y_pred1, y_pred2)\n\n    clf3 = IsolationForest(random_state=1).fit(X_train)\n    y_pred3 = clf3.predict(X_test)\n    with pytest.raises(AssertionError):\n        assert_array_equal(y_pred1, y_pred3)\n", "def test_iforest_fit_predict_consistency():\n    \"\"\"Test consistency between fit and predict.\"\"\"\n    rng = check_random_state(42)\n    X = rng.randn(100, 2)\n\n    clf = IsolationForest(n_estimators=10, max_samples=50, random_state=rng)\n    clf.fit(X)\n\n    # Test predict output shape\n    y_pred = clf.predict(X)\n    assert_equal(y_pred.shape, (100,))\n\n    # Test fit consistency by refitting the same data and checking predictions\n    clf.fit(X)\n    y_pred_refit = clf.predict(X)\n    assert_array_equal(y_pred, y_pred_refit)\n\n    # Test decision_function output shape and consistency\n    decision_scores = clf.decision_function(X)\n    assert_equal(decision_scores.shape, (100,))\n    decision_scores_refit = clf.decision_function(X)\n    assert_array_equal(decision_scores, decision_scores_refit)\n\n    # Ensure predict output matches decision_function output threshold\n    assert_array_equal(y_pred, decision_scores >= 0)\n", "def test_iforest_random_state():\n    \"\"\"Test IsolationForest with various random_state values.\"\"\"\n    X = iris.data\n\n    clf1 = IsolationForest(random_state=42).fit(X)\n    clf2 = IsolationForest(random_state=42).fit(X)\n    assert_array_equal(clf1.predict(X), clf2.predict(X))\n    assert_array_almost_equal(clf1.score_samples(X), clf2.score_samples(X))\n\n    clf3 = IsolationForest(random_state=0).fit(X)\n    clf4 = IsolationForest(random_state=np.random.RandomState(0)).fit(X)\n    assert_array_equal(clf3.predict(X), clf4.predict(X))\n    assert_array_almost_equal(clf3.score_samples(X), clf4.score_samples(X))\n\n    clf5 = IsolationForest(random_state=None).fit(X)\n    clf6 = IsolationForest(random_state=None).fit(X)\n    assert_raises(AssertionError, assert_array_equal, clf5.predict(X), clf6.predict(X))\n", "def test_iforest_random_state_consistency():\n    \"\"\"Check that IsolationForest gives the same results with the same random_state.\"\"\"\n    X = iris.data\n    rng = check_random_state(42)\n    \n    clf1 = IsolationForest(random_state=rng).fit(X)\n    clf2 = IsolationForest(random_state=rng).fit(X)\n    \n    # Ensure the predict results are the same\n    assert_array_equal(clf1.predict(X), clf2.predict(X))\n    \n    # Ensure the score_samples results are the same\n    assert_array_equal(clf1.score_samples(X), clf2.score_samples(X))\n    \n    # Ensure the decision_function results are the same\n    assert_array_equal(clf1.decision_function(X), clf2.decision_function(X))\n", "def test_iforest_predict():\n    \"\"\"Test the predict method of IsolationForest\"\"\"\n    X_train = [[1, 1], [1, 2], [2, 1]]\n    X_test = [[1.5, 1.5], [3, 3], [0, 0]]\n    clf = IsolationForest(contamination=0.1, random_state=0).fit(X_train)\n    \n    # Test prediction with known data\n    predictions = clf.predict(X_test)\n    \n    # Check the output shape\n    assert_equal(predictions.shape, (3,))\n    \n    # Check if predictions are either -1 or 1\n    assert all(pred in [-1, 1] for pred in predictions)\n    \n    # Check if the decision_function and score_samples give consistent results\n    decision_func = clf.decision_function(X_test)\n    score_samples = clf.score_samples(X_test)\n    assert_array_equal(decision_func, score_samples + clf.offset_)\n"], "sample_139": ["def test_issue_16133():\n    x, y = symbols('x y', extended_real=True)\n    assert re(Piecewise((1, x < 0), (2, True))) == Piecewise((1, x < 0), (2, True))\n    assert re(Piecewise((1, y < 0), (2, True))) == Piecewise((1, y < 0), (2, True))\n    assert im(Piecewise((1, x < 0), (2, True))) == 0\n    assert im(Piecewise((1, y < 0), (2, True))) == 0\n", "def test_polar_lift():\n    assert polar_lift(1) == exp_polar(0)\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(I*pi/2)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(2 + 3*I) == polar_lift(2 + 3*I)\n    assert polar_lift(exp_polar(2*I*pi)) == exp_polar(2*I*pi)\n    assert polar_lift(3*exp_polar(2*I*pi)) == 3*exp_polar(2*I*pi)\n\n    x = Symbol('x')\n    assert polar_lift(x) == polar_lift(x)\n    assert polar_lift(x + 1) == polar_lift(x + 1)\n    assert polar_lift(exp(x)) == exp(x)\n    assert polar_lift(exp_polar(x)) == exp_polar(x)\n\n    p = Symbol('p', polar=True)\n    assert polar_lift(3*p) == 3*p\n\n    y = Symbol('y', positive=True)\n    assert polar_lift(y) == y*exp_polar(0)\n    assert polar_lift(y*I) == y*exp_polar(I*pi/2)\n", "def test_polar_lift():\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z', polar=True)\n    \n    assert polar_lift(1) == 1 * exp_polar(0)\n    assert polar_lift(-1) == 1 * exp_polar(I * pi)\n    assert polar_lift(I) == exp_polar(I * pi / 2)\n    assert polar_lift(-I) == exp_polar(-I * pi / 2)\n    assert polar_lift(2) == 2 * exp_polar(0)\n    assert polar_lift(2 * I) == 2 * exp_polar(I * pi / 2)\n    assert polar_lift(-2 * I) == 2 * exp_polar(-I * pi / 2)\n    assert polar_lift(x) == polar_lift(x)\n    assert polar_lift(x * y) == polar_lift(x) * polar_lift(y)\n    \n    assert polar_lift(2 * z) == 2 * z\n    assert polar_lift(2 * x * y) == 2 * polar_lift(x * y)\n    \n    assert polar_lift(exp_polar(I * pi) * x) == exp_polar(I * pi) * polar_lift(x)\n    assert polar_lift(exp_polar(I * pi) * z) == exp_polar(I * pi) * z\n\n    # Test with expressions\n    assert polar_lift(2 + I) == polar_lift(2 + I)\n    assert polar_lift(-2 + I) == polar_lift(-2 + I)\n    assert polar_lift(x + I * y) == polar_lift(x + I * y)\n    assert polar_lift(exp(x + I * y)) == exp(polar_lift(x + I * y))\n\n    # Testing with rational numbers\n    assert polar_lift(Rational(1, 2)) == Rational(1, 2) * exp_polar(0)\n    assert polar_lift(-Rational(1, 2)) == Rational(1, 2) * exp_polar(I * pi)\n\n    # Testing with complex numbers\n    assert polar_lift(1 + I) == polar_lift(1 + I)\n    assert polar_lift(1 - I) == polar_lift(1 - I)\n    assert polar_lift(-", "def test_issue_17000():\n    a, b = symbols('a b', real=True)\n    c = Symbol('c', complex=True)\n    expr = (a + b*I)**2 / c\n\n    assert re(expr) == (a**2 - b**2) / re(c) - 2*a*b*im(c) / Abs(c)**2\n    assert im(expr) == (2*a*b) / re(c) + (a**2 - b**2)*im(c) / Abs(c)**2\n\n    expr_conjugate = conjugate(expr)\n    assert re(expr_conjugate) == re(expr)\n    assert im(expr_conjugate) == -im(expr)\n", "def test_polar_lift():\n    assert polar_lift(5) == 5 * exp_polar(0)\n    assert polar_lift(-3) == 3 * exp_polar(I * pi)\n    assert polar_lift(I) == exp_polar(I * pi / 2)\n    assert polar_lift(-I) == exp_polar(-I * pi / 2)\n    assert polar_lift(2 + 3*I) == polar_lift(2 + 3*I)\n    assert polar_lift(2 * (3 + 4*I)) == 2 * polar_lift(3 + 4*I)\n\n    x = Symbol('x')\n    assert polar_lift(4*x) == 4 * polar_lift(x)\n\n    p = Symbol('p', polar=True)\n    assert polar_lift(4*p) == 4 * p\n\n    assert polar_lift(exp(I*pi/3)) == exp_polar(I*pi/3)\n    assert polar_lift(exp(-I*pi/3)) == exp_polar(-I*pi/3)\n"], "sample_125": ["def test_mpf_norm_cases():\n    # Test cases with more edge cases for mpf_norm\n    assert mpf_norm((0, 0, 0, 0), 10) == (0, 0, 0, 0)  # Zero case\n    assert mpf_norm((1, 1, 0, 1), 10) == (1, 1, 0, 1)  # Normalized already\n    assert mpf_norm((0, 1, 10, 1), 10) == (0, 1, 10, 1)  # Positive power of 2\n    assert mpf_norm((0, 1, -10, 1), 10) == (0, 1, -10, 1)  # Negative power of 2\n    assert mpf_norm((1, 0, 1, 0), 10) == (0, 0, 0, 0)  # Special zero case handling\n    assert mpf_norm((1, 10**20, -20, 20), 10) == (1, 10**20, -20, 20)  # Large positive number\n    assert mpf_norm((1, 10**20, -40, 20), 10) == (1, 10**20, -40, 20)  # Large negative exponent\n    assert mpf_norm((1, 10**-20, 40, 20), 10) == (1, 10**-20, 40, 20)  # Small positive number\n    assert mpf_norm((1, 0, -123, -1), 10) == (0, 0, 0, 0)  # Normalize inf to 0\n    assert mpf_norm((1, 0, -456, -2), 10) == (0, 0, 0, 0)  # Normalize +inf to 0\n    assert mpf_norm((1, 0, -789, -3), 10) == (0, 0, 0, 0)  # Normalize -inf to 0\n", "def test_mpf_norm_special_cases():\n    # Test special cases for mpf_norm\n    assert mpf_norm(_mpf_zero, 10) == _mpf_zero\n    assert mpf_norm(_mpf_inf, 10) == _mpf_inf\n    assert mpf_norm(_mpf_ninf, 10) == _mpf_ninf\n    assert mpf_norm(_mpf_nan, 10) == _mpf_nan\n\n    # Test normalized mpf values\n    assert mpf_norm((0, 1, -1, 1), 10) == (0, MPZ(1), -1, 1)\n    assert mpf_norm((1, 123456789, 5, 10), 10) == (1, MPZ(123456789), 5, 10)\n    assert mpf_norm((0, 123456789, 5, 10), 10) == (0, MPZ(123456789), 5, 10)\n\n    # Test zero mantissa with non-zero exponent and bc\n    assert mpf_norm((0, 0, 5, 10), 10) == _mpf_zero\n    assert mpf_norm((1, 0, 5, 10), 10) == _mpf_zero\n    assert mpf_norm((0, 0, -5, 10), 10) == _mpf_zero\n    assert mpf_norm((1, 0, -5, 10), 10) == _mpf_zero\n", "def test_mpf_norm_special_cases():\n    assert mpf_norm((0, 0, 0, 0), 10) == _mpf_zero\n    assert mpf_norm((0, 0, 0, 0), 10) == (0, MPZ(0), 0, 0)\n    assert mpf_norm(_mpf_nan, 10) == _mpf_nan\n    assert mpf_norm(_mpf_inf, 10) == _mpf_inf\n    assert mpf_norm(_mpf_ninf, 10) == _mpf_ninf\n", "def test_mpf_norm():\n    assert mpf_norm((0, 0, 0, 0), 10) == _mpf_zero\n    assert mpf_norm((1, 0, 1, 1), 10) == _mpf_inf\n    assert mpf_norm((1, 0, -1, 1), 10) == _mpf_ninf\n    assert mpf_norm((0, 0, 0, 1), 10) == _mpf_nan\n    assert mpf_norm((0, 1, 0, 1), 10) == (0, 1, 0, 1)\n    assert mpf_norm((1, 1, 1, 1), 10) == (1, 1, 1, 1)\n", "def test_mpf_norm():\n    assert mpf_norm((1, 0, 1, 0), 10) == mpf('0')._mpf_\n    assert mpf_norm((0, 1, 1, 1), 10) == mpf('1')._mpf_\n    assert mpf_norm((0, 2, 1, 1), 10) == mpf('2')._mpf_\n    assert mpf_norm((0, 0, 0, 0), 10) == mpf('0')._mpf_\n    assert mpf_norm((-1, 1, 1, 1), 10) == mpf('-1')._mpf_\n\n    # Ensure that numbers are normalized correctly\n    assert mpf_norm((0, 123456789012345678901234567890, 15, 54), 10) == (0, 123456789012345678901234567890, 15, 54)\n    assert mpf_norm((0, 12345678901234567890, 30, 54), 10) == (0, 12345678901234567890, 30, 54)\n    assert mpf_norm((0, 12345678901234567890, -30, 54), 10) == (0, 12345678901234567890, -30, 54)\n    assert mpf_norm((0, 1, -123, -1), 10) == (0, 1, -123, -1)\n    assert mpf_norm((0, 1, 456, 2), 10) == (0, 1, 456, 2)\n"], "sample_131": ["def test_user_defined_function():\n    settings = {'user_functions': {'myfunc': 'MyFunc'}}\n    assert mcode(Function('myfunc')(x, y, z), **settings) == \"MyFunc[x, y, z]\"\n", "def test_user_defined_functions():\n    settings = {'user_functions': {'foo': 'Foo', 'bar': 'Bar'}}\n    assert mcode(Function('foo')(x, y), **settings) == \"Foo[x, y]\"\n    assert mcode(Function('bar')(x), **settings) == \"Bar[x]\"\n    assert mcode(Function('baz')(x), **settings) == \"baz[x]\"\n", "def test_user_defined_functions():\n    custom_functions = {\n        'myfunc': 'MyFunc',\n        'anotherfunc': 'AnotherFunc'\n    }\n    expr = Function('myfunc')(x) + Function('anotherfunc')(y)\n    assert mcode(expr, user_functions=custom_functions) == \"MyFunc[x] + AnotherFunc[y]\"\n\n    expr = Function('myfunc')(x, y) * Function('anotherfunc')(z)\n    assert mcode(expr, user_functions=custom_functions) == \"MyFunc[x, y]*AnotherFunc[z]\"\n", "def test_user_defined_functions():\n    user_defined_code = mathematica_code(sin(x) + cos(x), user_functions={\"sin\": \"CustomSin\", \"cos\": \"CustomCos\"})\n    assert user_defined_code == \"CustomSin[x] + CustomCos[x]\"\n\n    user_defined_code_nested = mathematica_code(sin(x + cos(x)), user_functions={\"sin\": \"CustomSin\", \"cos\": \"CustomCos\"})\n    assert user_defined_code_nested == \"CustomSin[x + CustomCos[x]]\"\n\n    user_defined_code_with_lambda = mathematica_code(sin(x) + cos(x), user_functions={\"sin\": [(lambda x: True, \"LambdaSin\")], \"cos\": [(lambda x: True, \"LambdaCos\")]})\n    assert user_defined_code_with_lambda == \"LambdaSin[x] + LambdaCos[x]\"\n", "def test_user_defined_function():\n    user_functions = {'myfunc': 'MyFunc', 'anotherfunc': 'AnotherFunc'}\n    expr1 = Function('myfunc')(x, y)\n    expr2 = Function('anotherfunc')(x, y, z)\n    assert mcode(expr1, user_functions=user_functions) == \"MyFunc[x, y]\"\n    assert mcode(expr2, user_functions=user_functions) == \"AnotherFunc[x, y, z]\"\n"], "sample_32": ["    def test_key_transform_preprocess_lhs(self):\n        transform = KeyTransform('key_name', 'lhs')\n        mock_compiler = mock.MagicMock()\n        mock_connection = mock.MagicMock()\n        result = transform.preprocess_lhs(mock_compiler, mock_connection)\n        self.assertIsInstance(result, tuple)\n        self.assertEqual(len(result), 3)\n        self.assertIsInstance(result[0], str)\n        self.assertIsInstance(result[1], list)\n        self.assertIsInstance(result[2], list)\n", "    def test_empty_json(self):\n        field = models.JSONField()\n        value = {}\n        cleaned_value = field.clean(value, None)\n        self.assertEqual(cleaned_value, value)\n", "    def test_compile_json_path_with_root(self):\n        key_transforms = ['a', 'b', 1]\n        expected_path = '$.a.b[1]'\n        self.assertEqual(compile_json_path(key_transforms), expected_path)\n", "    def test_contains_lookup_in_jsonfield(self):\n        instance = JSONModel(value={\"nested\": {\"key\": \"value\"}})\n        instance.save()\n        self.assertTrue(JSONModel.objects.filter(value__contains={\"nested\": {\"key\": \"value\"}}).exists())\n        self.assertFalse(JSONModel.objects.filter(value__contains={\"nested\": {\"key\": \"different_value\"}}).exists())\n", "    def test_get_internal_type(self):\n        field = models.JSONField()\n        self.assertEqual(field.get_internal_type(), 'JSONField')\n"], "sample_62": ["    def setUp(self):\n        self.cache = caches[\"default\"]\n", "    def test_touch_updates_expiry(self):\n        # Set a cache entry with a short timeout\n        cache.set(\"touch_key\", \"touch_value\", timeout=1)\n        time.sleep(2)\n        # The key should be expired now\n        self.assertIsNone(cache.get(\"touch_key\"))\n\n        # Set the key again with a short timeout\n        cache.set(\"touch_key\", \"touch_value\", timeout=1)\n        # Touch the key to extend its timeout\n        self.assertIs(cache.touch(\"touch_key\", timeout=5), True)\n        time.sleep(2)\n        # The key should still exist\n        self.assertEqual(cache.get(\"touch_key\"), \"touch_value\")\n        time.sleep(4)\n        # The key should be expired now\n        self.assertIsNone(cache.get(\"touch_key\"))\n", "    def setUp(self):\n        super().setUp()\n        self.dirname = tempfile.mkdtemp()\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n", "    def setUp(self):\n        super().setUp()\n        self.dirname = tempfile.mkdtemp()\n        self.cache = FileBasedCache(self.dirname, params={})\n", "    def setUp(self):\n        super().setUp()\n        self.dirname = tempfile.mkdtemp()\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n"], "sample_33": ["    def test_connect_with_dispatch_uid(self):\n        receiver_1 = Callable()\n        a_signal.connect(receiver_1, dispatch_uid=\"unique_id_1\")\n        # Connect another receiver with the same dispatch_uid, it should not get added.\n        a_signal.connect(receiver_1.a, dispatch_uid=\"unique_id_1\")\n        self.assertEqual(len(a_signal.receivers), 1)\n        # Now disconnect the receiver using the dispatch_uid.\n        a_signal.disconnect(dispatch_uid=\"unique_id_1\")\n        self.assertTestIsClean(a_signal)\n", "    def test_connect_with_dispatch_uid(self):\n            return val\n\n        dispatch_uid = \"unique_id\"\n        a_signal.connect(receiver_with_uid, dispatch_uid=dispatch_uid)\n        result = a_signal.send(sender=self, val='test')\n        self.assertEqual(result, [(receiver_with_uid, 'test')])\n\n        # Try connecting another receiver with the same dispatch_uid\n            return f\"another_{val}\"\n\n        a_signal.connect(another_receiver_with_uid, dispatch_uid=dispatch_uid)\n        result = a_signal.send(sender=self, val='test')\n        self.assertEqual(result, [(receiver_with_uid, 'test')])  # Should not change\n\n        a_signal.disconnect(dispatch_uid=dispatch_uid)\n        self.assertTestIsClean(a_signal)\n", "    def test_disconnect_by_dispatch_uid(self):\n            pass\n\n        a_signal.connect(receiver_func, dispatch_uid=\"unique_id\")\n        self.assertTrue(a_signal.disconnect(dispatch_uid=\"unique_id\"))\n        self.assertTestIsClean(a_signal)\n", "    def test_connect_with_dispatch_uid(self):\n            return val\n\n        dispatch_uid = 'unique-id'\n        a_signal.connect(test_receiver, dispatch_uid=dispatch_uid)\n        result = a_signal.send(sender=self, val='test')\n        self.assertEqual(result, [(test_receiver, 'test')])\n        \n        # Connect another receiver with the same dispatch_uid\n            return val\n\n        a_signal.connect(another_receiver, dispatch_uid=dispatch_uid)\n        result = a_signal.send(sender=self, val='test')\n        self.assertEqual(result, [(test_receiver, 'test')])  # Should still call the first receiver\n\n        a_signal.disconnect(dispatch_uid=dispatch_uid)\n        self.assertTestIsClean(a_signal)\n", "    def test_disconnect_with_dispatch_uid(self):\n            return val\n\n        dispatch_uid = \"unique_id\"\n        a_signal.connect(receiver_with_uid, dispatch_uid=dispatch_uid)\n        self.assertTrue(a_signal.has_listeners())\n        self.assertTrue(a_signal.disconnect(dispatch_uid=dispatch_uid))\n        self.assertFalse(a_signal.has_listeners())\n        self.assertTestIsClean(a_signal)\n"], "sample_93": ["def test_mktemp_raises_valueerror_for_invalid_basename(tmp_path_factory: TempPathFactory) -> None:\n    invalid_basename = \"../../invalid_path\"\n    with pytest.raises(ValueError, match=\"is not a normalized and relative path\"):\n        tmp_path_factory.mktemp(invalid_basename)\n", "def test_get_user_with_env_variable(monkeypatch):\n    \"\"\"Test that get_user() function returns the correct username when environment variable is present.\"\"\"\n    monkeypatch.setenv(\"USER\", \"testuser\")\n    assert get_user() == \"testuser\"\n", "def test_temp_path_factory_from_config(pytester: Pytester) -> None:\n    \"\"\"Test TempPathFactory initialization from Config.\"\"\"\n    mytemp = pytester.mkdir(\"mytemp\")\n    config_file = pytester.makeconftest(\n        \"\"\"\n            config.option.basetemp = '{}'\n        \"\"\".format(mytemp)\n    )\n    pytester.syspathinsert(config_file.parent)\n    config = pytester.parseconfig()\n    temp_path_factory = TempPathFactory.from_config(config, _ispytest=True)\n    assert temp_path_factory.getbasetemp() == mytemp\n", "def test_ensure_relative_to_basetemp(tmp_path_factory: TempPathFactory) -> None:\n    base_temp = tmp_path_factory.getbasetemp()\n    relative_path = \"relative/path\"\n    absolute_path = \"/absolute/path\"\n    \n    # Test with a valid relative path\n    assert tmp_path_factory._ensure_relative_to_basetemp(relative_path) == relative_path\n\n    # Test with an absolute path (should raise ValueError)\n    with pytest.raises(ValueError):\n        tmp_path_factory._ensure_relative_to_basetemp(absolute_path)\n\n    # Test with a relative path that resolves outside basetemp (should raise ValueError)\n    invalid_relative_path = \"../outside_basetemp\"\n    with pytest.raises(ValueError):\n        tmp_path_factory._ensure_relative_to_basetemp(invalid_relative_path)\n", "def test_temp_path_factory_from_config(pytester: Pytester) -> None:\n    \"\"\"Test the TempPathFactory.from_config method with different basetemp values.\"\"\"\n    config_with_basetemp = cast(Config, FakeConfig(pytester.path / \"base_temp\"))\n    config_without_basetemp = cast(Config, FakeConfig(None))\n    \n    factory_with_basetemp = TempPathFactory.from_config(config_with_basetemp, _ispytest=True)\n    assert factory_with_basetemp._given_basetemp == pytester.path / \"base_temp\"\n    \n    factory_without_basetemp = TempPathFactory.from_config(config_without_basetemp, _ispytest=True)\n    assert factory_without_basetemp._given_basetemp is None\n"], "sample_142": ["def test_is_sequence():\n    assert is_sequence([1, 2, 3])\n    assert is_sequence((1, 2, 3))\n    assert not is_sequence(123)\n    assert not is_sequence('123')\n    assert is_sequence({1, 2, 3})\n    assert not is_sequence(None)\n    assert is_sequence([1, [2, 3]])\n    assert not is_sequence(Basic(1, 2, 3))\n", "def test_unflatten_exceptions():\n    raises(ValueError, lambda: unflatten(list(range(10)), 3))\n    raises(ValueError, lambda: unflatten(list(range(10)), -2))\n", "def test_interactive_traversal():\n    expr = x + y * z\n    # We cannot test interactive functions directly since they expect user input.\n    # Instead, we test that the function can be called without error for a simple case.\n    result = interactive_traversal(expr)\n    assert result == expr\n", "def test_reshape_exceptions():\n    raises(ValueError, lambda: reshape([1, 2, 3], [4]))\n    raises(ValueError, lambda: reshape([1, 2, 3], -1))\n    raises(ValueError, lambda: reshape([1, 2, 3, 4], [2, [3]]))\n", "def test_interactive_traversal():\n    from sympy.abc import a, b, c\n    from sympy import Add\n\n    expr = Add(a, b, c)\n\n    # Mock input to simulate interactive traversal\n    input_values = iter(['0', 'f', 'd'])\n\n        return next(input_values)\n\n    import builtins\n    original_input = builtins.input\n    builtins.input = mock_input\n\n    result = interactive_traversal(expr)\n    \n    # restore original input function\n    builtins.input = original_input\n    \n    # Check if the result is the expression itself (as 'd' was input to finish traversal)\n    assert result == expr\n"], "sample_120": ["def test_MatrixExpr_properties():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, n)\n\n    assert A.is_Matrix\n    assert A.is_MatrixExpr\n    assert not A.is_Identity\n    assert not A.is_Inverse\n    assert not A.is_Transpose\n    assert not A.is_ZeroMatrix\n    assert not A.is_MatAdd\n    assert not A.is_MatMul\n    assert not A.is_commutative\n\n    C = MatrixSymbol('C', n, n)\n    D = ZeroMatrix(n, n)\n\n    assert not C.is_Identity\n    assert D.is_ZeroMatrix\n    assert isinstance(D.inverse(), Identity)\n", "def test_as_explicit():\n    A = MatrixSymbol('A', 2, 2)\n    explicit_A = A.as_explicit()\n    assert explicit_A.shape == (2, 2)\n    assert explicit_A[0, 0] == A[0, 0]\n    assert explicit_A[0, 1] == A[0, 1]\n    assert explicit_A[1, 0] == A[1, 0]\n    assert explicit_A[1, 1] == A[1, 1]\n", "def test_MatrixExpr_operations():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    \n    expr = A + B\n    assert expr == MatAdd(A, B)\n    assert expr.shape == (2, 2)\n    \n    expr = A * B\n    assert expr == MatMul(A, B)\n    assert expr.shape == (2, 2)\n    \n    expr = A - B\n    assert expr == MatAdd(A, MatMul(S.NegativeOne, B))\n    assert expr.shape == (2, 2)\n    \n    expr = A ** 2\n    assert expr == MatPow(A, 2)\n    assert expr.shape == (2, 2)\n    \n    expr = -A\n    assert expr == MatMul(S.NegativeOne, A)\n    assert expr.shape == (2, 2)\n    \n    expr = A / 2\n    assert expr == MatMul(A, S.Half)\n    assert expr.shape == (2, 2)\n    \n    raises(NotImplementedError, lambda: 2 / A)\n", "def test_as_explicit():\n    A = MatrixSymbol('A', 2, 2)\n    explicit_matrix = A.as_explicit()\n    assert explicit_matrix == Matrix([[A[0, 0], A[0, 1]], [A[1, 0], A[1, 1]]])\n", "def test_matrixexpr_as_explicit():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    Z = ZeroMatrix(2, 2)\n    I = Identity(2)\n\n    # Testing explicit conversion\n    explicit_A = A.as_explicit()\n    assert explicit_A.shape == (2, 2)\n    assert explicit_A[0, 0] == A[0, 0]\n    assert explicit_A[1, 1] == A[1, 1]\n\n    # Testing with Identity matrix\n    explicit_I = I.as_explicit()\n    assert explicit_I.shape == (2, 2)\n    assert explicit_I == Matrix([[1, 0], [0, 1]])\n\n    # Testing with Zero matrix\n    explicit_Z = Z.as_explicit()\n    assert explicit_Z.shape == (2, 2)\n    assert explicit_Z == Matrix([[0, 0], [0, 0]])\n\n    # Combined matrix expressions\n    expr = A + B - I\n    explicit_expr = expr.as_explicit()\n    assert explicit_expr.shape == (2, 2)\n    assert explicit_expr[0, 0] == A[0, 0] + B[0, 0] - 1\n    assert explicit_expr[1, 1] == A[1, 1] + B[1, 1] - 1\n"], "sample_14": ["    def test_serialize_custom_object(self):\n        class CustomObject:\n                self.data = data\n\n                return (\n                    'migrations.test_writer.CustomObject',\n                    [self.data],\n                    {}\n                )\n\n        custom_obj = CustomObject('test_data')\n        self.assertSerializedEqual(custom_obj)\n        self.assertSerializedResultEqual(\n            custom_obj,\n            (\"migrations.test_writer.CustomObject('test_data')\", {'import migrations.test_writer'})\n        )\n", "    def test_serialize_regex_flags(self):\n        \"\"\"\n        Test serialization of regex with flags.\n        \"\"\"\n        regex = re.compile(r'^[0-9]+$', re.IGNORECASE | re.MULTILINE)\n        self.assertSerializedResultEqual(\n            regex,\n            (\n                \"re.compile('^[0-9]+$', re.RegexFlag['IGNORECASE']|re.RegexFlag['MULTILINE'])\",\n                {'import re'},\n            )\n        )\n        self.assertSerializedEqual(regex)\n", "    def test_serialize_deconstructable_instance(self):\n        instance = DeconstructibleInstances()\n        self.assertSerializedResultEqual(\n            instance,\n            (\"migrations.test_writer.DeconstructibleInstances()\", {'import migrations.test_writer'})\n        )\n        self.assertSerializedEqual(instance)\n", "    def test_serialize_functools_partialmethod_bound_method(self):\n            return x + y\n        \n        class SampleClass:\n                return a + b\n\n        instance = SampleClass()\n        value = functools.partialmethod(instance.method, 1, b=2)\n        result = self.serialize_round_trip(value)\n        self.assertIsInstance(result, functools.partialmethod)\n        self.assertEqual(result.args, value.args)\n        self.assertEqual(result.keywords, value.keywords)\n", "    def test_serialize_function_type(self):\n            pass\n\n        string, imports = MigrationWriter.serialize(example_function)\n        self.assertEqual(string, 'migrations.test_writer.example_function')\n        self.assertEqual(imports, {'import migrations.test_writer'})\n\n        class ExampleClass:\n                pass\n\n            @staticmethod\n                pass\n\n            @classmethod\n                pass\n\n        string, imports = MigrationWriter.serialize(ExampleClass.method)\n        self.assertEqual(string, 'migrations.test_writer.WriterTests.test_serialize_function_type.<locals>.ExampleClass.method')\n        self.assertEqual(imports, {'import migrations.test_writer'})\n\n        string, imports = MigrationWriter.serialize(ExampleClass.static_method)\n        self.assertEqual(string, 'migrations.test_writer.WriterTests.test_serialize_function_type.<locals>.ExampleClass.static_method')\n        self.assertEqual(imports, {'import migrations.test_writer'})\n\n        string, imports = MigrationWriter.serialize(ExampleClass.class_method)\n        self.assertEqual(string, 'migrations.test_writer.WriterTests.test_serialize_function_type.<locals>.ExampleClass.class_method')\n        self.assertEqual(imports, {'import migrations.test_writer'})\n"], "sample_157": ["def test_tensor_product_latex():\n    from sympy.printing.latex import latex\n    tp = TensorProduct(A, B)\n    assert latex(tp) == r'{A}\\otimes {B}'\n    tp = TensorProduct(A + B, C + D)\n    assert latex(tp) == r'{\\left(A + B\\right)}\\otimes {\\left(C + D\\right)}'\n    tp = TensorProduct(A * B, C ** 2)\n    assert latex(tp) == r'{A B}\\otimes {C^{2}}'\n", "def test_tensor_product_combinations():\n    # Mixed tensor products with matrices and symbols\n    assert TensorProduct(mat1, A) * TensorProduct(mat2, B) == \\\n        TensorProduct(mat1 * mat2, A * B)\n    assert TensorProduct(A, mat1) * TensorProduct(B, mat2) == \\\n        TensorProduct(A * B, mat1 * mat2)\n    # Tensor product with scalars\n    assert TensorProduct(2, A) * TensorProduct(3, B) == 6 * TensorProduct(A, B)\n    # Tensor product with identity matrices\n    I2 = Matrix.eye(2)\n    assert TensorProduct(I2, A) * TensorProduct(I2, B) == TensorProduct(I2 * I2, A * B)\n", "def test_combined_tensor_printing():\n    combined_tensor_printing(True)\n    ket = Qubit('10')\n    bra = QubitBra('10')\n    assert str(TP(ket, ket)) == '|10, 10>'\n    assert str(TP(bra, bra)) == '<10, 10|'\n\n    combined_tensor_printing(False)\n    assert str(TP(ket, ket)) == '|10>x|10>'\n    assert str(TP(bra, bra)) == '<10|x<10|'\n", "def test_combined_tensor_printing():\n    from sympy.physics.quantum.state import Ket\n    combined_tensor_printing(True)\n    k1 = Ket('0')\n    k2 = Ket('1')\n    tp = TensorProduct(k1, k2)\n    assert tp._pretty(printer=None) == '{0, 1}'\n    assert tp._latex(printer=None) == r'{\\left|0, 1\\right\\rangle}'\n\n    combined_tensor_printing(False)\n    assert tp._pretty(printer=None) == '0x1'\n    assert tp._latex(printer=None) == r'{\\left|0\\right\\rangle}\\otimes {\\left|1\\right\\rangle}'\n", "def test_tensor_product_sympystr():\n    assert str(TensorProduct(A + B, C + D)) == \"(A + B)x(C + D)\"\n    assert str(TensorProduct(A * B, C ** 2)) == \"AxBx(C**2)\"\n    assert str(TensorProduct(A, B, C)) == \"AxBxC\"\n    assert str(TensorProduct(A + B, C * D, E ** 2)) == \"(A + B)x(C*D)x(E**2)\"\n"], "sample_110": ["def test_affinity_propagation_damping_out_of_bounds():\n    # Test AffinityPropagation with damping factor out of bounds\n    S = -euclidean_distances(X, squared=True)\n    preference = np.median(S) * 10\n\n    with pytest.raises(ValueError, match='damping must be >= 0.5 and < 1'):\n        affinity_propagation(S, preference=preference, damping=0.4)\n    \n    with pytest.raises(ValueError, match='damping must be >= 0.5 and < 1'):\n        affinity_propagation(S, preference=preference, damping=1)\n", "def test_affinity_propagation_sparse_input():\n    # Test AffinityPropagation with sparse input\n    X_sparse = csr_matrix(X)\n    af = AffinityPropagation(affinity=\"euclidean\")\n    labels_sparse = af.fit_predict(X_sparse)\n    labels_dense = af.fit_predict(X)\n    \n    # Ensure that sparse and dense inputs result in the same output\n    assert_array_equal(labels_sparse, labels_dense)\n    \n    # Ensure that no warnings are raised when fitting sparse input\n    with pytest.warns(None) as record:\n        af.fit(X_sparse)\n    assert len(record) == 0\n", "def test_affinity_propagation_invalid_affinity():\n    # Test invalid affinity input\n    X = np.array([[0, 0], [1, 1], [-2, -2]])\n    af = AffinityPropagation(affinity='invalid_affinity')\n    with pytest.raises(ValueError, match=\"Affinity must be 'precomputed' or 'euclidean'. Got invalid_affinity instead\"):\n        af.fit(X)\n", "def test_affinity_propagation_single_sample():\n    # Test affinity propagation with a single sample\n    X = np.array([[1, 1]])\n    S = -euclidean_distances(X, squared=True)\n    preference = np.median(S)\n\n    # Test with the function directly\n    cluster_centers_indices, labels = affinity_propagation(S, preference=preference)\n    assert_array_equal(cluster_centers_indices, [0])\n    assert_array_equal(labels, [0])\n\n    # Test with the class\n    af = AffinityPropagation(preference=preference, affinity=\"precomputed\")\n    af.fit(S)\n    assert_array_equal(af.cluster_centers_indices_, [0])\n    assert_array_equal(af.labels_, [0])\n", "def test_affinity_propagation_damping_values():\n    # Test AffinityPropagation with various valid and invalid damping values\n    S = -euclidean_distances(X, squared=True)\n    preference = np.median(S) * 10\n\n    # Valid damping value\n    af = AffinityPropagation(preference=preference, damping=0.6)\n    labels = af.fit(X).labels_\n    assert len(np.unique(labels)) > 0  # Ensure some clusters are formed\n\n    # Invalid damping values\n    with pytest.raises(ValueError, match=\"damping must be >= 0.5 and < 1\"):\n        af = AffinityPropagation(preference=preference, damping=0.4)\n        af.fit(X)\n    \n    with pytest.raises(ValueError, match=\"damping must be >= 0.5 and < 1\"):\n        af = AffinityPropagation(preference=preference, damping=1.0)\n        af.fit(X)\n"], "sample_136": ["def test_BlockMatrix_is_Identity():\n    A = Identity(n)\n    B = ZeroMatrix(n, m)\n    C = ZeroMatrix(m, n)\n    D = Identity(m)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    assert X.is_Identity\n\n    E = MatrixSymbol('E', n, n)\n    F = ZeroMatrix(n, m)\n    G = ZeroMatrix(m, n)\n    H = Identity(m)\n    Y = BlockMatrix([[E, F], [G, H]])\n\n    assert not Y.is_Identity\n", "def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', n, n)\n    Z = BlockMatrix([[A, B], [C, D]])\n    \n    real_Z, imag_Z = Z.as_real_imag()\n    \n    assert isinstance(real_Z, Matrix)\n    assert isinstance(imag_Z, Matrix)\n    assert real_Z.shape == Z.blockshape\n    assert imag_Z.shape == Z.blockshape\n    assert real_Z == Matrix([[re(A), re(B)], [re(C), re(D)]])\n    assert imag_Z == Matrix([[im(A), im(B)], [im(C), im(D)]])\n", "def test_BlockMatrix_properties():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', m, m)\n    C = MatrixSymbol('C', n, m)\n    D = MatrixSymbol('D', m, n)\n    Z = ZeroMatrix(n, m)\n    block_matrix = BlockMatrix([[A, C], [D, B]])\n\n    assert block_matrix.shape == (n + m, n + m)\n    assert block_matrix.blockshape == (2, 2)\n    assert block_matrix.rowblocksizes == [n, m]\n    assert block_matrix.colblocksizes == [n, m]\n    assert block_matrix.structurally_equal(BlockMatrix([[A, C], [D, B]]))\n    assert not block_matrix.structurally_equal(BlockMatrix([[A, Z], [Z, B]]))\n    assert block_matrix.equals(BlockMatrix([[A, C], [D, B]]))\n    assert block_matrix.equals(BlockMatrix([[A, Z], [Z, B]])) == False\n\n    block_diag_matrix = BlockDiagMatrix(A, B)\n    assert block_diag_matrix.shape == (n + m, n + m)\n    assert block_diag_matrix.blockshape == (2, 2)\n    assert block_diag_matrix.rowblocksizes == [n, m]\n    assert block_diag_matrix.colblocksizes == [n, m]\n    assert block_diag_matrix.equals(BlockDiagMatrix(A, B))\n    assert block_diag_matrix.equals(BlockDiagMatrix(A, C)) == False\n", "def test_BlockMatrix_as_real_imag():\n    A = Matrix([[1 + 2j, 3 + 4j], [5 + 6j, 7 + 8j]])\n    B = Matrix([[9 + 10j, 11 + 12j], [13 + 14j, 15 + 16j]])\n    block_matrix = BlockMatrix([[A, B]])\n\n    real_part, imag_part = block_matrix.as_real_imag()\n\n    expected_real = Matrix([[1, 3, 9, 11], [5, 7, 13, 15]])\n    expected_imag = Matrix([[2, 4, 10, 12], [6, 8, 14, 16]])\n\n    assert real_part == expected_real\n    assert imag_part == expected_imag\n", "def test_blockmatrix_as_real_imag():\n    from sympy import I, re, im\n\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', n, n)\n\n    X = BlockMatrix([[A + B*I, C - D*I], [B - A*I, D + C*I]])\n    real, imag = X.as_real_imag()\n\n    expected_real = BlockMatrix([[re(A + B*I), re(C - D*I)], [re(B - A*I), re(D + C*I)]])\n    expected_imag = BlockMatrix([[im(A + B*I), im(C - D*I)], [im(B - A*I), im(D + C*I)]])\n\n    assert real == expected_real.blocks\n    assert imag == expected_imag.blocks\n"], "sample_80": ["def test_wrap_indent():\n    cases = [\n        (\"This is a test string\", \"\", 4, \"This is a test string\"),\n        (\n            \"This is a test string with\\nmultiple lines\",\n            \"> \",\n            2,\n            \"> This is a test string with\\n  multiple lines\"\n        ),\n        (\n            \"Short text\",\n            \">>> \",\n            5,\n            \">>> Short text\"\n        ),\n    ]\n    for text, start, length, expected in cases:\n        actual = formatting.wrap_indent(text, start=start, length=length)\n        assert actual == expected\n", "def test_inline_dask_repr():\n    import dask.array as da\n\n    array = da.from_array(np.arange(100).reshape(10, 10), chunks=(5, 5))\n    expected_chunksize = \"(5, 5)\"\n    expected_meta = \"np.ndarray\"\n\n    actual = formatting.inline_dask_repr(array)\n    assert expected_chunksize in actual\n    assert expected_meta in actual\n", "def test_wrap_indent():\n    text = \"This is a test string\\nthat spans multiple lines\\nfor testing wrap_indent.\"\n    start = \"Prefix: \"\n    length = 10\n\n    actual = formatting.wrap_indent(text, start, length)\n    expected = \"Prefix: This is a test string\\n          that spans multiple lines\\n          for testing wrap_indent.\"\n    assert actual == expected\n\n    # Test with default length (None)\n    actual = formatting.wrap_indent(text, start)\n    expected = \"Prefix: This is a test string\\n          that spans multiple lines\\n          for testing wrap_indent.\"\n    assert actual == expected\n\n    # Test with no start string\n    actual = formatting.wrap_indent(text)\n    expected = \"This is a test string\\nthat spans multiple lines\\nfor testing wrap_indent.\"\n    assert actual == expected\n", "def test_wrap_indent():\n    text = \"line1\\nline2\\nline3\"\n    start = \"Start: \"\n    length = 7\n    actual = formatting.wrap_indent(text, start=start, length=length)\n    expected = \"Start: line1\\n       line2\\n       line3\"\n    assert actual == expected\n\n    # Test without start and length\n    actual = formatting.wrap_indent(text)\n    expected = \"line1\\nline2\\nline3\"\n    assert actual == expected\n", "def test_inline_sparse_repr():\n    sparse = pytest.importorskip(\"sparse\")\n    array = sparse.COO(coords=[[0, 1], [2, 3]], data=[4, 5], shape=(4, 4), fill_value=0)\n\n    expected = \"<sparse.COO: nnz=2, fill_value=0>\"\n    actual = formatting.inline_sparse_repr(array)\n\n    assert actual == expected\n"], "sample_99": ["def test_check_weights():\n    # Test the _check_weights function.\n    assert_equal(_check_weights(None), None)\n    assert_equal(_check_weights('uniform'), 'uniform')\n    assert_equal(_check_weights('distance'), 'distance')\n\n        return dist ** -2\n\n    assert_equal(_check_weights(custom_weights), custom_weights)\n\n    invalid_weights = ['invalid', 5, {}, []]\n    for weight in invalid_weights:\n        assert_raises_regex(ValueError, \"weights not recognized\", _check_weights, weight)\n", "def test_weights_function():\n    # Test custom weights function\n        return np.exp(-dist)\n\n    X = np.array([[0, 1], [1, 1], [2, 2], [3, 3]])\n    y = np.array([0, 0, 1, 1])\n    n_neighbors = 2\n\n    knn = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, weights=custom_weights)\n    knn.fit(X, y)\n    \n    test_points = np.array([[1, 1], [2, 2]])\n    y_pred = knn.predict(test_points)\n    \n    expected_pred = np.array([0, 1])\n    assert_array_equal(y_pred, expected_pred)\n\n    knn_reg = neighbors.KNeighborsRegressor(n_neighbors=n_neighbors, weights=custom_weights)\n    knn_reg.fit(X, y)\n    \n    y_pred_reg = knn_reg.predict(test_points)\n    expected_pred_reg = np.array([0, 1])\n    assert_array_almost_equal(y_pred_reg, expected_pred_reg, decimal=1)\n", "def test_check_weights():\n    # Test _check_weights function for valid and invalid inputs\n    assert_equal(_check_weights(None), None)\n    assert_equal(_check_weights('uniform'), 'uniform')\n    assert_equal(_check_weights('distance'), 'distance')\n    assert_equal(_check_weights(lambda x: x), lambda x: x)\n    \n    invalid_weights = ['invalid', 0, 1.5, {}, [], set()]\n    for weights in invalid_weights:\n        assert_raises(ValueError, _check_weights, weights)\n", "def test_neighbors_unsupervised_with_callable_weights():\n    # Test KNeighbors with callable weights\n        return np.exp(-dist)\n\n    X = np.random.RandomState(42).rand(20, 3)\n    test_points = np.random.RandomState(42).rand(5, 3)\n\n    neigh = neighbors.NearestNeighbors(n_neighbors=5, algorithm='auto')\n    neigh.fit(X)\n\n    # Get the distances and indices without custom weights\n    dist, ind = neigh.kneighbors(test_points)\n\n    # Apply custom weights to distances\n    weights = custom_weights(dist)\n\n    # Check that custom weights are applied correctly\n    expected_weights = np.exp(-dist)\n    assert_array_almost_equal(weights, expected_weights)\n", "def test_check_weights():\n    # Test the _check_weights function with various inputs\n    assert_equal(_check_weights(None), None)\n    assert_equal(_check_weights('uniform'), 'uniform')\n    assert_equal(_check_weights('distance'), 'distance')\n    \n        return 1.0 / (dist + 1e-5)\n    \n    assert_equal(_check_weights(custom_weight_func), custom_weight_func)\n    \n    with assert_raises(ValueError, match=\"weights not recognized\"):\n        _check_weights('invalid_weight')\n"], "sample_6": ["    def setUp(self):\n        self.validator = validators.ASCIIUsernameValidator()\n", "    def test_ascii_validator_message(self):\n        v = validators.ASCIIUsernameValidator()\n        invalid_username = \"\u00c9ric\"\n        expected_message = (\n            'Enter a valid username. This value may contain only English letters, '\n            'numbers, and @/./+/-/_ characters.'\n        )\n        with self.assertRaises(ValidationError) as cm:\n            v(invalid_username)\n        self.assertEqual(cm.exception.message, expected_message)\n", "    def test_ascii_validator_flags(self):\n        v = validators.ASCIIUsernameValidator()\n        self.assertEqual(v.flags, re.ASCII)\n", "    def test_ascii_unicode_validator_messages(self):\n        ascii_validator = validators.ASCIIUsernameValidator()\n        unicode_validator = validators.UnicodeUsernameValidator()\n        \n        with self.assertRaises(ValidationError) as cm:\n            ascii_validator(\"\u00c9ric\")\n        self.assertEqual(cm.exception.messages, [\n            'Enter a valid username. This value may contain only English letters, numbers, and @/./+/-/_ characters.'\n        ])\n        \n        with self.assertRaises(ValidationError) as cm:\n            unicode_validator(\"o'connell\")\n        self.assertEqual(cm.exception.messages, [\n            'Enter a valid username. This value may contain only letters, numbers, and @/./+/-/_ characters.'\n        ])\n", "    def test_unicode_validator_edge_cases(self):\n        edge_case_usernames = [\n            \"leading space\", \n            \" trailing space\",\n            \"\",  # Empty username\n            \" \" * 10,  # Only spaces\n            \"user@domain.com\",  # Email-like username\n            \"user+name\",  # Plus sign in username\n            \"user-name\",  # Hyphen in username\n            \"user_name\",  # Underscore in username\n            \"user.name\",  # Dot in username\n        ]\n        v = validators.UnicodeUsernameValidator()\n        for edge_case in edge_case_usernames:\n            with self.subTest(edge_case=edge_case):\n                if edge_case.strip():  # Only valid if not only spaces\n                    v(edge_case)\n                else:\n                    with self.assertRaises(ValidationError):\n                        v(edge_case)\n"], "sample_66": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = \"name\"\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n", "    def test_readonly_fields_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n", "    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = \"name\"\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n", "    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n", "    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n"], "sample_25": ["def test_deep_deconstruct_partial_function(self):\n    \"\"\"\n    Test that deep_deconstruct can handle functools.partial objects.\n    \"\"\"\n        return x + y\n\n    partial_obj = functools.partial(sample_function, x=1)\n    autodetector = MigrationAutodetector(None, None)\n    deconstructed = autodetector.deep_deconstruct(partial_obj)\n    self.assertEqual(deconstructed, (sample_function, (1,), {}))\n", "    def test_remove_and_add_constraints(self):\n        \"\"\"Test detection of removed and added constraints together.\"\"\"\n        before = [\n            ModelState(\"testapp\", \"Author\", [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=200)),\n            ], {'constraints': [models.CheckConstraint(check=models.Q(name__contains='Bob'), name='name_contains_bob')]}),\n        ]\n        after = [\n            ModelState(\"testapp\", \"Author\", [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=200)),\n            ], {'constraints': [models.CheckConstraint(check=models.Q(name__contains='Alice'), name='name_contains_alice')]}),\n        ]\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RemoveConstraint', 'AddConstraint'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name='author', name='name_contains_bob')\n        added_constraint = models.CheckConstraint(check=models.Q(name__contains='Alice'), name='name_contains_alice')\n        self.assertOperationAttributes(changes, 'testapp', 0, 1, model_name='author', constraint=added_constraint)\n", "    def test_create_and_delete_model_with_constraints(self):\n        \"\"\"Test creation and deletion of a model with constraints.\"\"\"\n        book_with_constraints = ModelState('otherapp', 'BookWithConstraints', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ], {\n            'constraints': [models.CheckConstraint(check=models.Q(title__contains='Test'), name='title_contains_test')]\n        })\n        changes_create = self.get_changes([], [book_with_constraints])\n        # Right number/type of migrations for creation?\n        self.assertNumberMigrations(changes_create, 'otherapp', 1)\n        self.assertOperationTypes(changes_create, 'otherapp', 0, [\"CreateModel\", \"AddConstraint\"])\n        created_constraint = models.CheckConstraint(check=models.Q(title__contains='Test'), name='title_contains_test')\n        self.assertOperationAttributes(changes_create, 'otherapp', 0, 1, model_name='bookwithconstraints', constraint=created_constraint)\n        \n        changes_delete = self.get_changes([book_with_constraints], [])\n        # Right number/type of migrations for deletion?\n        self.assertNumberMigrations(changes_delete, 'otherapp', 1)\n        self.assertOperationTypes(changes_delete, 'otherapp', 0, [\"RemoveConstraint\", \"DeleteModel\"])\n        self.assertOperationAttributes(changes_delete, 'otherapp', 0, 0, model_name='bookwithconstraints', name='title_contains_test')\n        self.assertOperationAttributes(changes_delete, 'otherapp', 0, 1, name='BookWithConstraints')\n", "    def test_add_model_with_order_with_respect_to_and_unique_constraint(self):\n        \"\"\"\n        Adding a new model with 'order_with_respect_to' and 'unique' constraint\n        should generate the appropriate operations in the correct order.\n        \"\"\"\n        author = ModelState('testapp', 'Author', [\n            ('id', models.AutoField(primary_key=True)),\n            ('name', models.CharField(max_length=200)),\n            ('book', models.ForeignKey('otherapp.Book', models.CASCADE)),\n        ], options={\n            'order_with_respect_to': 'book',\n            'unique_together': {('id', '_order')},\n        })\n        book = ModelState('otherapp', 'Book', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ])\n        changes = self.get_changes([], [author, book])\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['CreateModel', 'AlterUniqueTogether'])\n        self.assertOperationAttributes(\n            changes,\n            'testapp',\n            0,\n            0,\n            name='Author',\n            options={'order_with_respect_to': 'book'}\n        )\n        self.assertOperationAttributes(\n            changes,\n            'testapp',\n            0,\n            1,\n            name='author',\n            unique_together={('id', '_order')}\n        )\n", "    def test_create_and_remove_index(self):\n        \"\"\"\n        Tests creating and then removing an index within a single migration.\n        \"\"\"\n        # Create an initial state with no indexes\n        initial_state = ModelState('testapp', 'Author', [\n            ('id', models.AutoField(primary_key=True)),\n            ('name', models.CharField(max_length=200)),\n        ])\n        # Create a state with an added index\n        with_index_state = ModelState('testapp', 'Author', [\n            ('id', models.AutoField(primary_key=True)),\n            ('name', models.CharField(max_length=200)),\n        ], {'indexes': [models.Index(fields=['name'], name='author_name_idx')]})\n        # Transition from initial state to state with index\n        changes = self.get_changes([initial_state], [with_index_state])\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['AddIndex'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name='author', name='author_name_idx')\n\n        # Now remove the index\n        changes = self.get_changes([with_index_state], [initial_state])\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RemoveIndex'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name='author', name='author_name_idx')\n"], "sample_63": ["    def test_to_python_normalization(self):\n        field = UsernameField()\n        self.assertEqual(field.to_python(\"test\u2126\"), \"test\u03a9\")\n        self.assertEqual(field.to_python(\"test\u2126\"), \"test\u03a9\")\n        self.assertEqual(field.to_python(\"\u03a9\"), \"\u03a9\")\n        self.assertEqual(field.to_python(\"\u2126\"), \"\u03a9\")\n", "    def test_get_context_no_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        context = widget.get_context('password', None, {})\n        self.assertIn('summary', context)\n        self.assertEqual(context['summary'], [{'label': gettext(\"No password set.\")}])\n", "    def test_get_context_no_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        context = widget.get_context(\"password\", None, {})\n        self.assertIn(\"summary\", context)\n        self.assertEqual(context[\"summary\"], [{\"label\": gettext(\"No password set.\")}])\n", "    def test_get_context_no_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        context = widget.get_context(\"password\", None, {})\n        self.assertIn(\"summary\", context)\n        self.assertEqual(context[\"summary\"], [{\"label\": gettext(\"No password set.\")}])\n", "    def test_unicode_ci_compare_identical(self):\n        self.assertTrue(_unicode_ci_compare(\"test\", \"test\"))\n"], "sample_96": ["def test_ridge_regression_auto_solver():\n    # Test that ridge_regression selects the appropriate solver when solver='auto'\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 6, 5\n    y = rng.randn(n_samples)\n    X = rng.randn(n_samples, n_features)\n    sample_weight = 1.0 + rng.rand(n_samples)\n\n    # Test with dense input\n    coef_auto = ridge_regression(X, y, alpha=1.0, solver='auto')\n    coef_cholesky = ridge_regression(X, y, alpha=1.0, solver='cholesky')\n    assert_array_almost_equal(coef_auto, coef_cholesky)\n\n    # Test with sparse input\n    X_sparse = sp.csr_matrix(X)\n    coef_auto_sparse = ridge_regression(X_sparse, y, alpha=1.0, solver='auto')\n    coef_sparse_cg = ridge_regression(X_sparse, y, alpha=1.0, solver='sparse_cg')\n    assert_array_almost_equal(coef_auto_sparse, coef_sparse_cg)\n\n    # Test with sample weights\n    coef_auto_sw = ridge_regression(X, y, alpha=1.0, solver='auto', sample_weight=sample_weight)\n    coef_cholesky_sw = ridge_regression(X, y, alpha=1.0, solver='cholesky', sample_weight=sample_weight)\n    assert_array_almost_equal(coef_auto_sw, coef_cholesky_sw)\n", "def test_ridge_intercept_sparse():\n    # Test that Ridge can correctly handle fitting intercepts with sparse input data\n    X, y = make_regression(n_samples=100, n_features=5, n_informative=3, random_state=42)\n    X_sparse = sp.csr_matrix(X)\n    \n    ridge_dense = Ridge(alpha=1.0, fit_intercept=True)\n    ridge_sparse = Ridge(alpha=1.0, fit_intercept=True, solver='sag')\n\n    # Fit on dense data and sparse data\n    ridge_dense.fit(X, y)\n    ridge_sparse.fit(X_sparse, y)\n\n    # Check if intercepts are the same\n    assert_almost_equal(ridge_dense.intercept_, ridge_sparse.intercept_, decimal=5)\n    # Check if coefficients are the same\n    assert_array_almost_equal(ridge_dense.coef_, ridge_sparse.coef_, decimal=5)\n", "def test_ridge_solver_auto_selection():\n    # Test that 'auto' solver selects appropriate solvers based on input conditions\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 6, 5\n    X = rng.randn(n_samples, n_features)\n    y = rng.randn(n_samples)\n    sample_weight = 1.0 + rng.rand(n_samples)\n\n    # Test auto selection with dense data and no sample weights\n    ridge = Ridge(alpha=1.0, solver='auto')\n    ridge.fit(X, y)\n    assert_equal(ridge.solver, 'cholesky')\n\n    # Test auto selection with sparse data and no sample weights\n    X_sparse = sp.csr_matrix(X)\n    ridge.fit(X_sparse, y)\n    assert_equal(ridge.solver, 'sparse_cg')\n\n    # Test auto selection with dense data and sample weights\n    ridge.fit(X, y, sample_weight=sample_weight)\n    assert_equal(ridge.solver, 'cholesky')\n\n    # Test auto selection with sparse data and sample weights\n    ridge.fit(X_sparse, y, sample_weight=sample_weight)\n    assert_equal(ridge.solver, 'cholesky')\n", "def test_ridge_alpha_array():\n    # Test Ridge with array-like alpha input for multi-target regression.\n    rng = np.random.RandomState(42)\n    n_samples, n_features, n_targets = 20, 10, 5\n    X = rng.randn(n_samples, n_features)\n    y = rng.randn(n_samples, n_targets)\n    alpha = np.array([1.0, 0.1, 10.0, 0.01, 0.5])\n\n    for solver in ['svd', 'sparse_cg', 'lsqr', 'cholesky', 'sag', 'saga']:\n        ridge = Ridge(alpha=alpha, solver=solver)\n        ridge.fit(X, y)\n        coefs = ridge.coef_\n\n        # Check the shape of coefficients\n        assert_equal(coefs.shape, (n_targets, n_features))\n\n        # Check that coefficients are consistent with individual alpha\n        for i in range(n_targets):\n            ridge_indiv = Ridge(alpha=alpha[i], solver=solver)\n            ridge_indiv.fit(X, y[:, i])\n            assert_array_almost_equal(coefs[i], ridge_indiv.coef_, decimal=5)\n\n    # Test error is raised when number of targets and penalties do not match\n    alpha_mismatch = np.array([1.0, 0.1, 10.0])\n    ridge = Ridge(alpha=alpha_mismatch)\n    assert_raises(ValueError, ridge.fit, X, y)\n", "def test_ridge_solver_auto():\n    # Test the 'auto' solver choice based on input data type and sample weights\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 6, 5\n    y = rng.randn(n_samples)\n    X_dense = rng.randn(n_samples, n_features)\n    X_sparse = sp.csr_matrix(X_dense)\n    sample_weight = 1.0 + rng.rand(n_samples)\n\n    # Dense data without sample weights should use 'cholesky'\n    ridge = Ridge(alpha=1.0, solver='auto')\n    ridge.fit(X_dense, y)\n    assert_equal(ridge.solver, 'cholesky')\n\n    # Dense data with sample weights should use 'cholesky'\n    ridge.fit(X_dense, y, sample_weight=sample_weight)\n    assert_equal(ridge.solver, 'cholesky')\n\n    # Sparse data without sample weights should use 'sparse_cg'\n    ridge.fit(X_sparse, y)\n    assert_equal(ridge.solver, 'sparse_cg')\n\n    # Sparse data with sample weights should use 'cholesky' due to rescaling\n    ridge.fit(X_sparse, y, sample_weight=sample_weight)\n    assert_equal(ridge.solver, 'cholesky')\n"], "sample_36": ["    def test_invert(self):\n        q = Q(price__gt=F('discounted_price'))\n        inverted_q = ~q\n        self.assertTrue(inverted_q.negated)\n        self.assertEqual(inverted_q.connector, Q.AND)\n        self.assertEqual(inverted_q.children, [q])\n", "def test_invert(self):\n    q = Q(price__gt=F('discounted_price'))\n    inverted_q = ~q\n    path, args, kwargs = inverted_q.deconstruct()\n    self.assertEqual(args, (Q(price__gt=F('discounted_price')),))\n    self.assertEqual(kwargs, {'_negated': True})\n", "    def test_invert(self):\n        q = Q(price__gt=F('discounted_price'))\n        inverted_q = ~q\n        self.assertTrue(inverted_q.negated)\n        self.assertEqual(inverted_q.children, [q])\n", "    def test_invert(self):\n        q = Q(price__gt=F('discounted_price'))\n        inverted_q = ~q\n        self.assertTrue(inverted_q.negated)\n        self.assertEqual(inverted_q.connector, Q.AND)\n        self.assertEqual(len(inverted_q.children), 1)\n        self.assertEqual(inverted_q.children[0], q)\n", "    def test_invert_q_object(self):\n        q = Q(price__gt=F('discounted_price'))\n        inverted_q = ~q\n        self.assertTrue(inverted_q.negated)\n        self.assertEqual(inverted_q.connector, Q.AND)\n        self.assertEqual(len(inverted_q.children), 1)\n        self.assertEqual(inverted_q.children[0], q)\n"], "sample_78": ["def test_find_app_by_string():\n    class Module:\n        myapp = Flask(\"myapp\")\n\n        @staticmethod\n            return Flask(\"created_app\")\n\n        @staticmethod\n            return Flask(f\"app_{arg1}_{arg2}\")\n\n    # Test finding app by attribute name\n    app = find_app_by_string(Module, \"myapp\")\n    assert app.name == \"myapp\"\n\n    # Test finding app by factory function without args\n    app = find_app_by_string(Module, \"create_app\")\n    assert app.name == \"created_app\"\n\n    # Test finding app by factory function with args\n    app = find_app_by_string(Module, 'create_app_with_args(\"foo\", \"bar\")')\n    assert app.name == \"app_foo_bar\"\n\n    # Test parsing invalid attribute name\n    with pytest.raises(NoAppException):\n        find_app_by_string(Module, \"invalid_attribute\")\n\n    # Test parsing invalid function call\n    with pytest.raises(NoAppException):\n        find_app_by_string(Module, \"create_app_invalid()\")\n", "def test_scriptinfo_no_app_found(monkeypatch):\n    # Mock to simulate no app found in current directory\n    monkeypatch.setattr(sys, 'path', [])\n    monkeypatch.setattr(os.path, 'exists', lambda x: False)\n    monkeypatch.setattr(os, 'getcwd', lambda: \"/nonexistent\")\n\n    obj = ScriptInfo()\n    with pytest.raises(NoAppException, match=\"Could not locate a Flask application.\"):\n        obj.load_app()\n", "def test_find_app_by_string():\n    class Module:\n        app = Flask(\"appname\")\n        \n        @staticmethod\n            return Flask(\"appname\")\n\n        @staticmethod\n            return Flask(f\"app_{arg1}_{arg2}\")\n\n    # Test direct app name\n    app = find_app_by_string(Module, \"app\")\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    # Test factory function without args\n    app = find_app_by_string(Module, \"create_app\")\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    # Test factory function with args\n    app = find_app_by_string(Module, 'create_app_with_args(\"foo\", \"bar\")')\n    assert isinstance(app, Flask)\n    assert app.name == \"app_foo_bar\"\n\n    # Test invalid attribute name\n    with pytest.raises(NoAppException):\n        find_app_by_string(Module, \"non_existent\")\n\n    # Test invalid function call\n    with pytest.raises(NoAppException):\n        find_app_by_string(Module, 'non_existent()')\n\n    # Test invalid argument parsing\n    with pytest.raises(NoAppException):\n        find_app_by_string(Module, 'create_app_with_args(\"foo\", bar)')\n", "def test_find_app_by_string():\n    class Module:\n        app = Flask(\"appname\")\n            return Flask(\"created_app\")\n\n    module = Module()\n\n    # Test finding an app by variable name\n    app = find_app_by_string(module, \"app\")\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    # Test finding an app by function name\n    app = find_app_by_string(module, \"create_app\")\n    assert isinstance(app, Flask)\n    assert app.name == \"created_app\"\n\n    # Test finding an app by function name with parentheses\n    app = find_app_by_string(module, \"create_app()\")\n    assert isinstance(app, Flask)\n    assert app.name == \"created_app\"\n\n    # Test invalid attribute name\n    with pytest.raises(NoAppException):\n        find_app_by_string(module, \"non_existent_app\")\n\n    # Test invalid function call with arguments\n    with pytest.raises(NoAppException):\n        find_app_by_string(module, \"create_app(foo)\")\n", "def test_find_app_by_string():\n    class Module:\n        app = Flask(\"appname\")\n        create_app = staticmethod(lambda: Flask(\"created_appname\"))\n        make_app = staticmethod(lambda: Flask(\"made_appname\"))\n\n    app = find_app_by_string(Module, \"app\")\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    app = find_app_by_string(Module, \"create_app()\")\n    assert isinstance(app, Flask)\n    assert app.name == \"created_appname\"\n\n    app = find_app_by_string(Module, \"make_app()\")\n    assert isinstance(app, Flask)\n    assert app.name == \"made_appname\"\n\n    with pytest.raises(NoAppException):\n        find_app_by_string(Module, \"non_existent\")\n\n    with pytest.raises(NoAppException):\n        find_app_by_string(Module, \"create_app(foo, bar)\")\n"], "sample_2": ["def test_wcs_invalid_keywords():\n    \"\"\"\n    Test invalid WCS keywords in the header\n    \"\"\"\n    header = fits.Header()\n    header['CTYPE1'] = 'INVALID'\n    header['CTYPE2'] = 'INVALID'\n    header['CRPIX1'] = 0.0\n    header['CRPIX2'] = 0.0\n    header['CRVAL1'] = 0.0\n    header['CRVAL2'] = 0.0\n    header['CDELT1'] = 1.0\n    header['CDELT2'] = 1.0\n\n    with pytest.raises(wcs.InvalidTransformError) as excinfo:\n        wcs.WCS(header)\n    assert \"Invalid parameter value\" in str(excinfo.value)\n", "def test_wcs_sub():\n    \"\"\"\n    Test the sub method of the WCS class to extract a subset of axes.\n    \"\"\"\n    w = wcs.WCS(naxis=3)\n    w.wcs.crval = [1, 2, 3]\n    w.wcs.cdelt = [0.1, 0.1, 0.1]\n    w.wcs.crpix = [1, 1, 1]\n    w.wcs.ctype = ['RA---TAN', 'DEC--TAN', 'FREQ']\n    \n    # Subset for celestial axes (RA, DEC)\n    sub_w = w.sub([wcs.WCSSUB_CELESTIAL])\n    assert sub_w.naxis == 2\n    assert sub_w.wcs.ctype.tolist() == ['RA---TAN', 'DEC--TAN']\n    \n    # Subset for spectral axis (FREQ)\n    sub_w = w.sub([wcs.WCSSUB_SPECTRAL])\n    assert sub_w.naxis == 1\n    assert sub_w.wcs.ctype.tolist() == ['FREQ']\n    \n    # Subset with no axes (Invalid, should return all axes as per WCSLIB behavior)\n    sub_w = w.sub([])\n    assert sub_w.naxis == 3\n    assert sub_w.wcs.ctype.tolist() == ['RA---TAN', 'DEC--TAN', 'FREQ']\n", "def test_wcs_init_with_header_and_fobj():\n    \"\"\"\n    Test initializing WCS with a header and an fobj to ensure distortion\n    lookup tables are correctly handled.\n    \"\"\"\n    fits_name = get_pkg_data_filename('data/dist_lookup.fits.gz')\n    with fits.open(fits_name) as hdulist:\n        header = hdulist[1].header\n        w = wcs.WCS(header, fobj=hdulist)\n\n    # Check that the WCS object has been initialized correctly\n    assert w.det2im1 is not None\n    assert w.det2im2 is not None\n    assert isinstance(w.det2im1, wcs.DistortionLookupTable)\n    assert isinstance(w.det2im2, wcs.DistortionLookupTable)\n\n    # Check that the distortion correction can be applied without error\n    x, y = w.det2im([100, 200], [100, 200], 1)\n    assert x is not None\n    assert y is not None\n", "def test_wcs_copy():\n    \"\"\"\n    Test that copying WCS objects works correctly for both shallow and deep copies.\n    \"\"\"\n    fits_name = get_pkg_data_filename('data/sip.fits')\n    w = wcs.WCS(fits_name)\n    \n    # Test shallow copy\n    w_shallow_copy = w.copy()\n    assert w.wcs.compare(w_shallow_copy.wcs)\n    assert w.sip == w_shallow_copy.sip\n    assert w.cpdis1 == w_shallow_copy.cpdis1\n    assert w.cpdis2 == w_shallow_copy.cpdis2\n    assert w.det2im1 == w_shallow_copy.det2im1\n    assert w.det2im2 == w_shallow_copy.det2im2\n    \n    # Test deep copy\n    w_deep_copy = w.deepcopy()\n    assert w.wcs.compare(w_deep_copy.wcs)\n    assert w.sip == w_deep_copy.sip\n    assert w.cpdis1 == w_deep_copy.cpdis1\n    assert w.cpdis2 == w_deep_copy.cpdis2\n    assert w.det2im1 == w_deep_copy.det2im1\n    assert w.det2im2 == w_deep_copy.det2im2\n\n    # Ensure deep copy is independent\n    w.wcs.crval[0] = 100.0\n    assert w.wcs.crval[0] != w_deep_copy.wcs.crval[0]\n", "def test_deepcopy():\n    \"\"\"\n    Test that deepcopy works as expected for WCS objects.\n    \"\"\"\n    fits_name = get_pkg_data_filename('data/sip.fits')\n    w1 = wcs.WCS(fits_name)\n    \n    w2 = w1.deepcopy()\n    \n    assert w1.wcs.compare(w2.wcs)\n    assert (w1.sip.a == w2.sip.a).all()\n    assert (w1.sip.b == w2.sip.b).all()\n    assert (w1.sip.ap == w2.sip.ap).all()\n    assert (w1.sip.bp == w2.sip.bp).all()\n    assert (w1.sip.crpix == w2.sip.crpix).all()\n    assert w1.naxis == w2.naxis\n    assert w1.wcs.naxis == w2.wcs.naxis\n    \n    # Ensure that modifying w2 does not affect w1\n    w2.wcs.crval = [0, 0]\n    assert not np.array_equal(w1.wcs.crval, w2.wcs.crval)\n"], "sample_71": ["def test_apply_style_with_blacklisted_params():\n    # Test applying a style with blacklisted parameters.\n    blacklisted_params = {param: VALUE for param in mpl.style.core.STYLE_BLACKLIST}\n    non_blacklisted_params = {'axes.labelsize': 'large', 'figure.figsize': [10, 5]}\n    combined_params = {**blacklisted_params, **non_blacklisted_params}\n    \n    with temp_style('test_blacklist', combined_params):\n        with style.context('test_blacklist'):\n            for param in blacklisted_params:\n                assert mpl.rcParams[param] != blacklisted_params[param]\n            for param, value in non_blacklisted_params.items():\n                assert mpl.rcParams[param] == value\n", "def test_remove_blacklisted_style_params():\n    original_dict = {\n        'backend': 'TkAgg',\n        'figure.facecolor': 'white',\n        'interactive': True\n    }\n    filtered_dict = mpl.style.core._remove_blacklisted_style_params(original_dict)\n    assert 'backend' not in filtered_dict\n    assert 'interactive' not in filtered_dict\n    assert 'figure.facecolor' in filtered_dict\n    assert filtered_dict['figure.facecolor'] == 'white'\n", "def test_apply_style_with_blacklisted_params():\n    original_value = mpl.rcParams[PARAM]\n    blacklisted_param = 'backend'\n    blacklisted_value = 'agg'\n    style_dict = {PARAM: VALUE, blacklisted_param: blacklisted_value}\n    \n    with pytest.warns(UserWarning, match=f\".*{blacklisted_param}.*\"):\n        mpl.style.core._apply_style(style_dict)\n    \n    assert mpl.rcParams[PARAM] == VALUE\n    assert mpl.rcParams[blacklisted_param] != blacklisted_value\n    mpl.rcParams[PARAM] = original_value  # Reset to original value\n", "def test_remove_blacklisted_style_params():\n    style_dict = {\n        'interactive': True,\n        'backend': 'Agg',\n        'figure.figsize': [10.0, 5.0],\n        'savefig.directory': '/tmp'\n    }\n    filtered_style = style._remove_blacklisted_style_params(style_dict)\n    # Check that blacklisted params are removed\n    assert 'interactive' not in filtered_style\n    assert 'backend' not in filtered_style\n    assert 'savefig.directory' not in filtered_style\n    # Check that non-blacklisted params are still present\n    assert 'figure.figsize' in filtered_style\n    assert filtered_style['figure.figsize'] == [10.0, 5.0]\n", "def test_remove_blacklisted_style_params():\n    settings = {PARAM: VALUE, 'backend': 'Agg'}\n    expected_output = {PARAM: VALUE}\n    output = style.core._remove_blacklisted_style_params(settings)\n    assert output == expected_output\n"], "sample_26": ["    def test_serialize_empty_db(self):\n        # Test serializing an empty database.\n        test_connection = get_connection_copy()\n        creation = BaseDatabaseCreation(test_connection)\n        with mock.patch('django.db.migrations.loader.MigrationLoader') as loader:\n            loader_instance = loader.return_value\n            loader_instance.migrated_apps = {'backends'}\n            data = creation.serialize_db_to_string()\n        self.assertEqual(data, '[]')\n", "    def test_create_test_db(self, mocked_call_command):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = BaseDatabaseCreation(test_connection)\n        with mock.patch.object(creation, '_create_test_db'), \\\n             mock.patch.object(creation, '_nodb_cursor', return_value=mock.MagicMock()), \\\n             mock.patch.object(creation, 'serialize_db_to_string', return_value='{}'):\n            test_db_name = creation.create_test_db(verbosity=1, autoclobber=True, serialize=True, keepdb=False)\n        \n        self.assertEqual(test_db_name, TEST_DATABASE_PREFIX + test_connection.settings_dict['NAME'])\n        mocked_call_command.assert_any_call('migrate', verbosity=0, interactive=False, database=test_connection.alias, run_syncdb=True)\n        mocked_call_command.assert_any_call('createcachetable', database=test_connection.alias)\n", "    def test_create_test_db(self, mock_create_test_db, mock_get_test_db_name, mock_call_command):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST'] = {'NAME': None, 'MIGRATE': True}\n        creation = BaseDatabaseCreation(test_connection)\n        \n        test_database_name = creation.create_test_db(verbosity=2, autoclobber=True, serialize=True, keepdb=False)\n        \n        self.assertEqual(test_database_name, 'test_hodor')\n        mock_create_test_db.assert_called_once()\n        mock_call_command.assert_any_call('migrate', verbosity=1, interactive=False, database=test_connection.alias, run_syncdb=True)\n        mock_call_command.assert_any_call('createcachetable', database=test_connection.alias)\n        self.assertTrue(hasattr(test_connection, '_test_serialized_contents'))\n", "    def test_clone_test_db(self):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_clone_test_db') as mocked_clone_test_db:\n                creation.clone_test_db(suffix='clone', verbosity=1, autoclobber=True, keepdb=True)\n                mocked_clone_test_db.assert_called_once_with('clone', 1, True)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n", "    def test_create_test_db_with_migration_disabled(self, mock_get_test_db_name, mock_call_command):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = False\n        test_connection.settings_dict['NAME'] = 'original_db'\n        creation = BaseDatabaseCreation(test_connection)\n        if connection.vendor == 'oracle':\n            # Don't close connection on Oracle.\n            creation.connection.close = mock.Mock()\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                test_db_name = creation.create_test_db(verbosity=1, autoclobber=True, serialize=False, keepdb=True)\n            self.assertEqual(test_db_name, 'test_db')\n            mock_get_test_db_name.assert_called()\n            mock_call_command.assert_any_call(\n                'migrate',\n                verbosity=0,\n                interactive=False,\n                database=test_connection.alias,\n                run_syncdb=True,\n            )\n            mock_call_command.assert_any_call('createcachetable', database=test_connection.alias)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(test_db_name, verbosity=1, keepdb=True)\n"], "sample_23": ["    def test_combining_with_annotate(self):\n        qs1 = Number.objects.filter(num=1).annotate(is_even=Value(0, IntegerField()))\n        qs2 = Number.objects.filter(num=2).annotate(is_even=Value(1, IntegerField()))\n        combined_qs = qs1.union(qs2)\n        results = list(combined_qs.order_by('num'))\n        self.assertEqual(results[0].is_even, 0)\n        self.assertEqual(results[1].is_even, 1)\n", "    def test_raw_query_set(self):\n        raw_query = \"SELECT num, other_num FROM app_number WHERE num < %s\"\n        params = [5]\n        qs = Number.objects.raw(raw_query, params=params)\n        results = list(qs)\n        self.assertEqual(len(results), 5)\n        self.assertEqual(results[0].num, 0)\n        self.assertEqual(results[1].num, 1)\n        self.assertEqual(results[2].num, 2)\n        self.assertEqual(results[3].num, 3)\n        self.assertEqual(results[4].num, 4)\n", "    def test_empty_qs_in_bulk(self):\n        qs = Number.objects.none()\n        self.assertEqual(qs.in_bulk(), {})\n        self.assertEqual(qs.in_bulk([1, 2, 3]), {})\n", "    def test_create(self):\n        obj = Number.objects.create(num=11, other_num=5)\n        self.assertEqual(obj.num, 11)\n        self.assertEqual(obj.other_num, 5)\n        self.assertTrue(Number.objects.filter(num=11).exists())\n", "    def test_union_with_qs_with_aggregates(self):\n        qs1 = Number.objects.filter(num__lte=1).annotate(total=F('num') + F('other_num'))\n        qs2 = Number.objects.filter(num__gte=8).annotate(total=F('num') - F('other_num'))\n        result = qs1.union(qs2).order_by('num')\n        expected_totals = [1 + 9, 0 + 10, 8 - 2, 9 - 1]\n        for obj, total in zip(result, expected_totals):\n            self.assertEqual(obj.total, total)\n"], "sample_117": ["def test_restify_forward_reference():\n    forward_ref = ForwardRef(\"MyClass1\")\n    assert restify(forward_ref) == \":class:`MyClass1`\"\n", "def test_get_type_hints():\n        pass\n\n    class SampleClass:\n        attr: int\n\n            return y\n\n    assert get_type_hints(sample_function) == {'a': int, 'b': str, 'return': None}\n    assert get_type_hints(SampleClass) == {'attr': int}\n    assert get_type_hints(SampleClass.method) == {'x': int, 'y': str, 'return': str}\n", "def test_restify_type_hints_forwardref_evaluation():\n    if sys.version_info < (3, 7):\n        from sphinx.util.typing import ForwardRef\n        globalns = {'MyClass1': MyClass1}\n        localns = {}\n        forward_ref = ForwardRef('MyClass1')\n        evaluated = forward_ref._evaluate(globalns, localns)\n        assert evaluated == MyClass1\n", "def test_restify_forward_reference():\n    if sys.version_info >= (3, 7):\n        ref = ForwardRef('MyClass1')\n    else:\n        ref = ForwardRef('MyClass1')\n        assert restify(ref) == \":class:`MyClass1`\"\n    \n    assert restify(ref) == \":class:`MyClass1`\"\n", "def test_restify_forward_reference():\n    ForwardRefType = ForwardRef(\"MyClass1\")\n    assert restify(ForwardRefType) == \":class:`MyClass1`\"\n"], "sample_127": ["def test_latex_matrix_operations():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    assert latex(A + B) == r\"A + B\"\n    assert latex(A - B) == r\"A - B\"\n    assert latex(A * B) == r\"A B\"\n    assert latex(A**2) == r\"A^{2}\"\n    assert latex(A**-1) == r\"A^{-1}\"\n    assert latex(Transpose(A)) == r\"A^T\"\n    assert latex(Adjoint(A)) == r\"A^\\dagger\"\n", "def test_latex_Limit():\n    # Test for the latex representation of the Limit class\n    expr = Limit(sin(x)/x, x, 0)\n    assert latex(expr) == r\"\\lim_{x \\to 0} \\frac{\\sin{\\left (x \\right )}}{x}\"\n    expr = Limit(1/x, x, 0, dir='-')\n    assert latex(expr) == r\"\\lim_{x \\to 0^-} \\frac{1}{x}\"\n    expr = Limit(1/x, x, 0, dir='+')\n    assert latex(expr) == r\"\\lim_{x \\to 0^+} \\frac{1}{x}\"\n    expr = Limit(1/x, x, 0, dir='+-')\n    assert latex(expr) == r\"\\lim_{x \\to 0} \\frac{1}{x}\"\n    expr = Limit((x + 1)**(1/x), x, 0)\n    assert latex(expr) == r\"\\lim_{x \\to 0} \\left(x + 1\\right)^{\\frac{1}{x}}\"\n\n    expr = Limit(f(x) + g(x), x, 0)\n    assert latex(expr) == r\"\\lim_{x \\to 0} \\left(f{\\left (x \\right )} + g{\\left (x \\right )}\\right)\"\n    expr = Limit(f(x)*g(x), x, 0)\n    assert latex(expr) == r\"\\lim_{x \\to 0} f{\\left (x \\right )} g{\\left (x \\right )}\"\n    expr = Limit(f(x)/g(x), x, 0)\n    assert latex(expr) == r\"\\lim_{x \\to 0} \\frac{f{\\left (x \\right )}}{g{\\left (x \\right )}}\"\n", "def test_latex_Piecewise_with_multiple_conditions():\n    p = Piecewise((x, x < 1), (x**2, x <= 2), (sin(x), x < 3), (cos(x), True))\n    expected_latex = r\"\\begin{cases} x & \\text{for}\\: x < 1 \\\\\\\\x^{2} & \\text{for}\\: x \\leq 2 \\\\\\\\sin{\\left (x \\right )} & \\text{for}\\: x < 3 \\\\\\\\cos{\\left (x \\right )} & \\text{otherwise} \\end{cases}\"\n    assert latex(p) == expected_latex\n\n    p = Piecewise((x + 1, x > 2), (x**2, x >= 1), (tan(x), x < 0), (sec(x), True))\n    expected_latex = r\"\\begin{cases} x + 1 & \\text{for}\\: x > 2 \\\\\\\\x^{2} & \\text{for}\\: x \\geq 1 \\\\\\\\tan{\\left (x \\right )} & \\text{for}\\: x < 0 \\\\\\\\sec{\\left (x \\right )} & \\text{otherwise} \\end{cases}\"\n    assert latex(p) == expected_latex\n", "def test_latex_matrix_function():\n    from sympy import Function, MatrixSymbol, Matrix\n    f = Function('f')\n    X = MatrixSymbol('X', 3, 3)\n    assert latex(f(X)) == r'f{\\left (X \\right )}'\n    assert latex(f(X) + X) == r'f{\\left (X \\right )} + X'\n    assert latex(f(X + X)) == r'f{\\left (X + X \\right )}'\n    assert latex(f(X).diff(X)) == r\"\\frac{\\partial}{\\partial X} f{\\left (X \\right )}\"\n    M = Matrix([[f(x), f(y)], [f(z), f(t)]])\n    assert latex(M) == r'\\left[\\begin{matrix}f{\\left (x \\right )} & f{\\left (y \\right )}\\\\f{\\left (z \\right )} & f{\\left (t \\right )}\\end{matrix}\\right]'\n", "def test_latex_IndexedBase_additional_cases():\n    # Testing for more cases involving IndexedBase and Indexed\n    A = IndexedBase('A')\n    B = IndexedBase('B')\n    i, j = symbols('i j')\n    \n    # Single index\n    assert latex(A[i]) == r'A_{i}'\n    assert latex(B[j]) == r'B_{j}'\n    \n    # Multiple indices\n    assert latex(A[i, j]) == r'A_{i, j}'\n    assert latex(B[j, i]) == r'B_{j, i}'\n    \n    # Using Indexed in expressions\n    expr = A[i] + B[j]\n    assert latex(expr) == r'A_{i} + B_{j}'\n    \n    expr = A[i] * B[j]\n    assert latex(expr) == r'A_{i} B_{j}'\n    \n    expr = A[i] / B[j]\n    assert latex(expr) == r'\\frac{A_{i}}{B_{j}}'\n    \n    expr = A[i]**2 + B[j]**3\n    assert latex(expr) == r'A_{i}^{2} + B_{j}^{3}'\n"], "sample_87": ["def test_pytest_ignore_collect_with_multiple_patterns(testdir):\n    testdir.makeconftest(\n        \"\"\"\n            return path.basename.startswith(\"ignore_\") or path.basename.endswith(\"_ignore.py\")\n    \"\"\"\n    )\n    testdir.makepyfile(\n        ignore_test_1=\"def test_ignored(): pass\",\n        test_ignore_2=\"def test_ignored(): pass\",\n        test_valid=\"def test_valid(): pass\"\n    )\n\n    result = testdir.runpytest(\"--collect-only\")\n    result.stdout.fnmatch_lines(\n        [\n            \"collected 1 item\",\n            \"<Module test_valid.py>\",\n            \"  <Function test_valid>\",\n        ]\n    )\n    result.stdout.no_fnmatch_line(\"*test_ignored*\")\n", "def test_wrap_session_exit_status(testdir):\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n        from _pytest.main import wrap_session, ExitCode\n        from _pytest.config import Config\n\n        @pytest.fixture\n            return Config.fromdictargs({}, [])\n\n                raise pytest.UsageError(\"usage error\")\n\n            exitstatus = wrap_session(config, doit)\n            assert exitstatus == ExitCode.USAGE_ERROR\n\n                raise KeyboardInterrupt\n\n            exitstatus = wrap_session(config, doit)\n            assert exitstatus == ExitCode.INTERRUPTED\n\n                raise Exception(\"internal error\")\n\n            exitstatus = wrap_session(config, doit)\n            assert exitstatus == ExitCode.INTERNAL_ERROR\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*3 passed*\"])\n", "def test_pytest_addoption():\n    from _pytest.config import Config, OptionGroup\n    \n    class Parser:\n            self.inis = {}\n            self.options = {}\n            self.groups = {}\n            \n            self.inis[name] = (help, type, default)\n            \n            if name not in self.groups:\n                self.groups[name] = OptionGroup(name, description)\n            return self.groups[name]\n        \n            for opt in opts:\n                self.options[opt] = attrs\n                \n    parser = Parser()\n    pytest_addoption(parser)\n    \n    # Check ini options\n    assert \"norecursedirs\" in parser.inis\n    assert parser.inis[\"norecursedirs\"] == (\"directory patterns to avoid for recursion\", \"args\", [\".*\", \"build\", \"dist\", \"CVS\", \"_darcs\", \"{arch}\", \"*.egg\", \"venv\"])\n    \n    assert \"testpaths\" in parser.inis\n    assert parser.inis[\"testpaths\"] == (\"directories to search for tests when no files or directories are given in the command line.\", \"args\", [])\n    \n    # Check general options\n    general_group = parser.getgroup(\"general\", \"running and selection options\")\n    assert \"-x\" in parser.options\n    assert \"--exitfirst\" in parser.options\n    assert parser.options[\"-x\"]['action'] == \"store_const\"\n    \n    assert \"--maxfail\" in parser.options\n    assert parser.options[\"--maxfail\"]['type'] == int\n    \n    assert \"--strict-markers\" in parser.options\n    assert parser.options[\"--strict-markers\"]['action'] == \"store_true\"\n    \n    assert \"-c\" in parser.options\n    assert parser.options[\"-c\"]['type'] == str\n    \n    assert \"--continue-on-collection-errors\" in parser.options\n    assert parser.options[\"--continue-on-collection-errors\"]['action'] == \"store_true\"\n    \n    assert \"--rootdir\" in parser.options\n    assert parser.options[\"--rootdir\"]['type'] == str\n    \n    # Check collect options\n    collect_group = parser.getgroup(\"collect\", \"collection\")\n    assert \"--collectonly\" in parser.options\n    assert parser.options[\"--collectonly\"]['action'] == \"store", "def test_collect_ignore_glob(testdir):\n    testdir.makeconftest(\n        \"\"\"\n        collect_ignore_glob = ['*.ignore']\n        \"\"\"\n    )\n    testdir.makepyfile(\n        test_ignore=\"\"\"\n            assert False\n        \"\"\",\n        test_ok=\"\"\"\n            assert True\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.no_fnmatch_line(\"*test_ignore*\")\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n", "def test_pytest_ignore_collect_handles_vcs(testdir):\n    \"\"\"Check if pytest_ignore_collect correctly ignores version control system directories.\"\"\"\n    testdir.makeconftest(\n        \"\"\"\n            if path.basename.startswith(\".git\"):\n                return True\n        \"\"\"\n    )\n    tmpdir = testdir.tmpdir\n    tmpdir.ensure(\".git\", \"test_ignored.py\").write(\"def test_ignored(): assert False\")\n    tmpdir.ensure(\"test_collected.py\").write(\"def test_collected(): assert True\")\n\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n    result.stdout.no_fnmatch_line(\"*2 items*\")\n"], "sample_153": ["def test_pretty_printer_exceptions():\n    # Test TypeError when imaginary_unit is not a string\n    try:\n        PrettyPrinter(settings={\"imaginary_unit\": 1})\n    except TypeError as e:\n        assert str(e) == \"'imaginary_unit' must a string, not 1\"\n    \n    # Test ValueError when imaginary_unit is not 'i' or 'j'\n    try:\n        PrettyPrinter(settings={\"imaginary_unit\": \"k\"})\n    except ValueError as e:\n        assert str(e) == \"'imaginary_unit' must be either 'i' or 'j', not 'k'\"\n\n    # Test with correct imaginary_unit\n    pp = PrettyPrinter(settings={\"imaginary_unit\": \"i\"})\n    assert pp._settings[\"imaginary_unit\"] == \"i\"\n", "def test_pretty_printer_initialization():\n    from sympy.printing.pretty.pretty import PrettyPrinter\n\n    # Test default settings\n    pp = PrettyPrinter()\n    assert pp._settings[\"order\"] is None\n    assert pp._settings[\"full_prec\"] == \"auto\"\n    assert pp._settings[\"use_unicode\"] is None\n    assert pp._settings[\"wrap_line\"] is True\n    assert pp._settings[\"num_columns\"] is None\n    assert pp._settings[\"use_unicode_sqrt_char\"] is True\n    assert pp._settings[\"root_notation\"] is True\n    assert pp._settings[\"mat_symbol_style\"] == \"plain\"\n    assert pp._settings[\"imaginary_unit\"] == \"i\"\n    assert pp._settings[\"perm_cyclic\"] is True\n\n    # Test invalid imaginary_unit type\n    try:\n        PrettyPrinter({\"imaginary_unit\": 1})\n    except TypeError as e:\n        assert str(e) == \"'imaginary_unit' must a string, not 1\"\n\n    # Test invalid imaginary_unit value\n    try:\n        PrettyPrinter({\"imaginary_unit\": \"k\"})\n    except ValueError as e:\n        assert str(e) == \"'imaginary_unit' must be either 'i' or 'j', not 'k'\"\n", "def test_pretty_printer_settings():\n    from sympy import Symbol\n\n    # Testing the imaginary_unit setting\n    assert pretty(Symbol('i'), imaginary_unit='j') == 'j'\n    assert upretty(Symbol('i'), imaginary_unit='j') == 'j'\n\n    # Testing the root_notation setting\n    assert pretty((a**(1/3)), root_notation=False) == 'a**(1/3)'\n    assert upretty((a**(1/3)), root_notation=False) == 'a**(1/3)'\n\n    # Testing the mat_symbol_style setting\n    from sympy.matrices import MatrixSymbol\n    X = MatrixSymbol('X', 2, 2)\n    assert pretty(X, mat_symbol_style='bold') == '\\033[1mX\\033[0m'\n\n    # Testing the use_unicode_sqrt_char setting\n    assert pretty(a**0.5, use_unicode_sqrt_char=False) == 'sqrt(a)'\n\n    # Testing the full_prec setting\n    from sympy import Float\n    assert pretty(Float('0.3333333333333333'), full_prec=True) == '0.3333333333333333'\n    assert pretty(Float('0.3333333333333333'), full_prec=False) == '0.333333'\n", "def test_pretty_printer_settings():\n    from sympy import I, sqrt, Matrix, symbols\n\n    # Testing PrettyPrinter settings\n    x, y = symbols('x y')\n\n    # Test imaginary_unit setting\n    assert upretty(I, imaginary_unit=\"i\") == \"i\"\n    assert upretty(I, imaginary_unit=\"j\") == \"j\"\n\n    # Test use_unicode_sqrt_char setting\n    assert upretty(sqrt(2), use_unicode_sqrt_char=True) == \"\u221a2\"\n    assert upretty(sqrt(2), use_unicode_sqrt_char=False) == \"2**(1/2)\"\n\n    # Test root_notation setting\n    assert upretty(x**(1/3), root_notation=True) == \"\u221bx\"\n    assert upretty(x**(1/3), root_notation=False) == \"x**(1/3)\"\n\n    # Test full_prec setting\n    from sympy import Float\n    f = Float(\"1.234567890123456789\")\n    assert upretty(f, full_prec=\"auto\") == \"1.23456789012346\"\n    assert upretty(f, full_prec=True) == \"1.234567890123456789\"\n\n    # Test wrap_line setting\n    expr = Matrix([[x**2 + y**2, x*y], [y*x, y**2 - x**2]])\n    wrapped = upretty(expr, wrap_line=True, num_columns=5)\n    unwrapped = upretty(expr, wrap_line=False)\n    assert \"\\n\" in wrapped\n    assert \"\\n\" not in unwrapped\n\n    # Test num_columns setting\n    from sympy import pi\n    long_expr = pi**100\n    assert \"\\n\" in upretty(long_expr, wrap_line=True, num_columns=20)\n    assert \"\\n\" not in upretty(long_expr, wrap_line=True, num_columns=200)\n", "def test_pretty_printing_expressions():\n    from sympy import Symbol, sqrt, pi, Integral, cos\n    from sympy.vector import CoordSys3D\n    \n    x = Symbol('x')\n    y = Symbol('y')\n    sqrt_expr = sqrt(x + y)\n    pi_expr = pi * x**2\n    integral_expr = Integral(cos(x), x)\n    \n    # Expected pretty print outputs\n    expected_sqrt_pretty = \"  _______\\n\u221ax + y  \"\n    expected_pi_pretty = \"\u03c0\u22c5x\u00b2\"\n    expected_integral_pretty = \"\u2320 \\n\u23ae cos(x) dx\\n\u2321 \"\n    \n    # Actual pretty print outputs\n    actual_sqrt_pretty = pretty(sqrt_expr)\n    actual_pi_pretty = pretty(pi_expr)\n    actual_integral_pretty = pretty(integral_expr)\n    \n    assert actual_sqrt_pretty == expected_sqrt_pretty\n    assert actual_pi_pretty == expected_pi_pretty\n    assert actual_integral_pretty == expected_integral_pretty\n    \n    # Unicode pretty print outputs\n    expected_sqrt_upretty = \"\u221ax + y\"\n    expected_pi_upretty = \"\u03c0\u22c5x\u00b2\"\n    expected_integral_upretty = \"\u2320\\n\u23ae cos(x) dx\\n\u2321\"\n    \n    actual_sqrt_upretty = upretty(sqrt_expr)\n    actual_pi_upretty = upretty(pi_expr)\n    actual_integral_upretty = upretty(integral_expr)\n    \n    assert actual_sqrt_upretty == expected_sqrt_upretty\n    assert actual_pi_upretty == expected_pi_upretty\n    assert actual_integral_upretty == expected_integral_upretty\n"], "sample_82": ["def test_groupby_fillna():\n    # Create a dataset with NaN values\n    ds = xr.Dataset(\n        {\"foo\": (\"x\", [1, np.nan, 3, np.nan, 5, 6])},\n        coords={\"x\": [1, 1, 1, 2, 2, 2]},\n    )\n\n    # Fill NaN values with 0 and group by 'x'\n    expected = xr.Dataset(\n        {\"foo\": (\"x\", [1, 0, 3, 0, 5, 6])},\n        coords={\"x\": [1, 1, 1, 2, 2, 2]},\n    )\n    actual = ds.groupby(\"x\").fillna(0)\n    assert_identical(expected, actual)\n\n    # Fill NaN values with the group mean\n    expected = xr.Dataset(\n        {\"foo\": (\"x\", [1, 2, 3, 5.5, 5, 6])},\n        coords={\"x\": [1, 1, 1, 2, 2, 2]},\n    )\n    actual = ds.groupby(\"x\").map(lambda x: x.fillna(x.mean()))\n    assert_identical(expected, actual)\n", "def test_groupby_apply():\n    # Test the apply method for GroupBy objects\n    dataset = xr.Dataset(\n        {\"foo\": (\"x\", [1, 2, 3, 4, 5, 6])}, {\"x\": [1, 1, 1, 2, 2, 2]}\n    )\n    expected = dataset.copy()\n    actual = dataset.groupby(\"x\").apply(lambda ds: ds)\n    assert_identical(expected, actual)\n\n    # Test with function altering dataset\n    expected = xr.Dataset(\n        {\"foo\": (\"x\", [2, 4, 6, 8, 10, 12])}, {\"x\": [1, 1, 1, 2, 2, 2]}\n    )\n    actual = dataset.groupby(\"x\").apply(lambda ds: ds * 2)\n    assert_identical(expected, actual)\n\n    # Test with DataArray\n    array = xr.DataArray([1, 2, 3, 4, 5, 6], [(\"x\", [1, 1, 1, 2, 2, 2])])\n    expected = array.copy()\n    actual = array.groupby(\"x\").apply(lambda da: da)\n    assert_identical(expected, actual)\n\n    expected = xr.DataArray([2, 4, 6, 8, 10, 12], [(\"x\", [1, 1, 1, 2, 2, 2])])\n    actual = array.groupby(\"x\").apply(lambda da: da * 2)\n    assert_identical(expected, actual)\n", "def test_groupby_arithmetic_operations():\n    array = xr.DataArray([1, 2, 3, 4, 5, 6], coords={\"x\": [1, 1, 1, 2, 2, 2]}, dims=\"x\")\n\n    # Test addition\n    expected = xr.DataArray([3, 6, 9, 8, 10, 12], coords={\"x\": [1, 1, 1, 2, 2, 2]}, dims=\"x\")\n    actual = array.groupby(\"x\") + 2\n    assert_identical(expected, actual)\n\n    # Test subtraction\n    expected = xr.DataArray([-1, 0, 1, 2, 3, 4], coords={\"x\": [1, 1, 1, 2, 2, 2]}, dims=\"x\")\n    actual = array.groupby(\"x\") - 2\n    assert_identical(expected, actual)\n\n    # Test multiplication\n    expected = xr.DataArray([2, 4, 6, 8, 10, 12], coords={\"x\": [1, 1, 1, 2, 2, 2]}, dims=\"x\")\n    actual = array.groupby(\"x\") * 2\n    assert_identical(expected, actual)\n\n    # Test division\n    expected = xr.DataArray([0.5, 1, 1.5, 2, 2.5, 3], coords={\"x\": [1, 1, 1, 2, 2, 2]}, dims=\"x\")\n    actual = array.groupby(\"x\") / 2\n    assert_identical(expected, actual)\n", "def test_groupby_fillna():\n    array = xr.DataArray(\n        [1, np.nan, 3, np.nan, 5, 6], coords={\"x\": [1, 1, 1, 2, 2, 2]}, dims=\"x\"\n    )\n\n    # Fill NaN with a scalar value\n    expected = xr.DataArray(\n        [1, 0, 3, 0, 5, 6], coords={\"x\": [1, 1, 1, 2, 2, 2]}, dims=\"x\"\n    )\n    actual = array.groupby(\"x\").fillna(0)\n    assert_identical(expected, actual)\n\n    # Fill NaN with a DataArray\n    fill_value = xr.DataArray([7, 8], coords={\"x\": [1, 2]}, dims=\"x\")\n    expected = xr.DataArray(\n        [1, 7, 3, 8, 5, 6], coords={\"x\": [1, 1, 1, 2, 2, 2]}, dims=\"x\"\n    )\n    actual = array.groupby(\"x\").fillna(fill_value)\n    assert_identical(expected, actual)\n\n    # Fill NaN with a Dataset\n    ds = xr.Dataset({\"a\": array})\n    fill_value_ds = xr.Dataset({\"a\": (\"x\", [7, 8])}, coords={\"x\": [1, 2]})\n    expected_ds = xr.Dataset(\n        {\"a\": (\"x\", [1, 7, 3, 8, 5, 6])}, coords={\"x\": [1, 1, 1, 2, 2, 2]}\n    )\n    actual_ds = ds.groupby(\"x\").fillna(fill_value_ds)\n    assert_identical(expected_ds, actual_ds)\n", "def test_dummy_copy():\n    from xarray.core.dataarray import DataArray\n    from xarray.core.dataset import Dataset\n\n    # Test with DataArray\n    array = xr.DataArray([1, 2, 3], dims=\"x\", name=\"test_array\")\n    dummy_array = _dummy_copy(array)\n    expected_array = DataArray(\n        dtypes.get_fill_value(array.dtype),\n        dims=[],\n        name=\"test_array\",\n        attrs=array.attrs,\n    )\n    assert_identical(dummy_array, expected_array)\n\n    # Test with Dataset\n    ds = xr.Dataset(\n        {\n            \"var1\": (\"x\", [1, 2, 3]),\n            \"var2\": (\"x\", [4, 5, 6]),\n        },\n        coords={\"x\": [0, 1, 2]},\n        attrs={\"test_attr\": \"value\"},\n    )\n    dummy_ds = _dummy_copy(ds)\n    expected_ds = Dataset(\n        {\n            \"var1\": dtypes.get_fill_value(ds[\"var1\"].dtype),\n            \"var2\": dtypes.get_fill_value(ds[\"var2\"].dtype),\n        },\n        coords={\"x\": [0, 1, 2]},\n        attrs={\"test_attr\": \"value\"},\n    )\n    assert_identical(dummy_ds, expected_ds)\n"], "sample_0": ["def test_media_merge():\n        media1 = Media(css={'all': ['styles.css']}, js=['script1.js'])\n        media2 = Media(css={'print': ['print.css']}, js=['script2.js'])\n        combined_media = media1 + media2\n        self.assertEqual(\n            combined_media._css,\n            {'all': [['styles.css']], 'print': [['print.css']]}\n        )\n        self.assertEqual(\n            combined_media._js,\n            ['script1.js', 'script2.js']\n        )\n", "def test_media_render_js(self):\n    css_files = {\n        'screen': ['styles.css'],\n        'print': ['print.css']\n    }\n    js_files = ['scripts.js', 'extra.js']\n    media = Media(css=css_files, js=js_files)\n    \n    rendered_js = media.render_js()\n    self.assertIn('<script type=\"text/javascript\" src=\"scripts.js\"></script>', rendered_js[0])\n    self.assertIn('<script type=\"text/javascript\" src=\"extra.js\"></script>', rendered_js[1])\n", "    def test_media_initialization(self):\n        media = Media(css={'all': ['styles.css']}, js=['scripts.js'])\n        self.assertEqual(media._css, {'all': ['styles.css']})\n        self.assertEqual(media._js, ['scripts.js'])\n        self.assertIn('<link href=\"styles.css\" type=\"text/css\" media=\"all\" rel=\"stylesheet\">', media.render_css())\n        self.assertIn('<script type=\"text/javascript\" src=\"scripts.js\"></script>', media.render_js())\n", "    def test_checkbox_input_format_value(self):\n        widget = CheckboxInput()\n        self.assertIsNone(widget.format_value(''))\n        self.assertIsNone(widget.format_value(None))\n        self.assertIsNone(widget.format_value(False))\n        self.assertEqual(widget.format_value('some-value'), 'some-value')\n        self.assertEqual(widget.format_value(True), None)\n", "    def test_media_repr(self):\n        media = Media(css={'all': ['style.css']}, js=['script.js'])\n        self.assertEqual(repr(media), \"Media(css={'all': ['style.css']}, js=['script.js'])\")\n"], "sample_70": ["def test_legend_set_loc():\n    \"\"\"Test setting the location of the legend manually.\"\"\"\n    fig, ax = plt.subplots()\n    lines = ax.plot(range(10), label='Data')\n    leg = ax.legend(loc='upper left')\n    assert leg._loc == 2  # 'upper left' corresponds to code 2\n    leg.set_loc('lower right')\n    assert leg._loc == 4  # 'lower right' corresponds to code 4\n", "def test_draggable_legend_update_loc():\n    fig, ax = plt.subplots()\n    line, = ax.plot([0, 1], [0, 1], label='line')\n    leg = ax.legend()\n    draggable = leg.set_draggable(True, update='loc')\n    assert isinstance(draggable, DraggableLegend)\n    draggable.finalize_offset()\n    assert leg._loc == draggable.get_loc_in_canvas()\n", "def test_draggable_legend_update_loc():\n    fig, ax = plt.subplots()\n    line, = ax.plot([0, 1], label='line')\n    leg = ax.legend(draggable=True, update='loc')\n    assert leg._update == 'loc'\n    assert isinstance(leg._draggable, mlegend.DraggableLegend)\n    \n    # Simulate dragging the legend\n    leg._draggable.finalize_offset()\n    assert leg._loc == leg._draggable.get_loc_in_canvas()\n", "def test_legend_box_and_alignment():\n    fig, ax = plt.subplots()\n    lines = ax.plot(range(10), label='test')\n    leg = ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), \n                    ncol=2, mode='expand', borderpad=2, labelspacing=1.5, \n                    handlelength=2, handleheight=1, handletextpad=1, \n                    borderaxespad=0.5, columnspacing=1.0, alignment='left')\n    \n    assert leg._legend_box.align == 'left'\n    assert leg._legend_box.get_children()[0]._text.get_text() == 'test'\n    assert leg._legend_box.get_children()[0]._text.get_fontproperties().get_size_in_points() == mpl.rcParams[\"legend.fontsize\"]\n    \n    # Checking custom properties\n    assert leg.borderpad == 2\n    assert leg.labelspacing == 1.5\n    assert leg.handlelength == 2\n    assert leg.handleheight == 1\n    assert leg.handletextpad == 1\n    assert leg.borderaxespad == 0.5\n    assert leg.columnspacing == 1.0\n", "def test_draggable_legend():\n    fig, ax = plt.subplots()\n    x = np.arange(10)\n    y = np.sin(x)\n    line, = ax.plot(x, y, label='Sine Wave')\n\n    # Create a draggable legend\n    leg = ax.legend(draggable=True)\n    assert leg.get_draggable() is True\n\n    # Simulate dragging the legend to a new location\n    old_loc = leg._get_loc()\n    leg._update_loc((0.5, 0.5))\n\n    # Check if the location has been updated\n    new_loc = leg._get_loc()\n    assert old_loc != new_loc\n    assert new_loc == (0.5, 0.5)\n\n    # Test finalizing the offset updates the location correctly\n    leg.finalize_offset()\n    assert leg._get_loc() == new_loc\n\n    # Disable draggable and check\n    leg.set_draggable(False)\n    assert leg.get_draggable() is False\n"], "sample_18": ["    def test_foreign_key_with_unique_field(self):\n        class Target(models.Model):\n            unique_field = models.IntegerField(unique=True)\n\n        class Model(models.Model):\n            foreign_key = models.ForeignKey(Target, models.CASCADE, to_field='unique_field')\n\n        field = Model._meta.get_field('foreign_key')\n        self.assertEqual(field.check(), [])\n", "    def test_foreign_key_to_missing_model_with_swapped_out_model(self):\n        class SwappedModel(models.Model):\n            class Meta:\n                swappable = 'TEST_SWAPPABLE_MODEL'\n\n        class Model(models.Model):\n            foreign_key = models.ForeignKey('InvalidModel', models.CASCADE)\n\n        field = Model._meta.get_field('foreign_key')\n        self.assertEqual(field.check(), [\n            Error(\n                \"Field defines a relation with model 'InvalidModel', \"\n                \"which is either not installed, or is abstract.\",\n                obj=field,\n                id='fields.E300',\n            ),\n        ])\n", "    def test_foreign_key_unique_constraint(self):\n        class Target(models.Model):\n            unique_field = models.IntegerField(unique=True)\n\n        class Model(models.Model):\n            field = models.ForeignKey(Target, models.CASCADE, to_field='unique_field')\n\n        field = Model._meta.get_field('field')\n        self.assertEqual(field.check(), [])\n", "    def test_many_to_many_with_custom_through_model(self):\n        class CustomThroughModel(models.Model):\n            person = models.ForeignKey('Person', models.CASCADE)\n            group = models.ForeignKey('Group', models.CASCADE)\n            extra_field = models.CharField(max_length=20)\n\n        class Person(models.Model):\n            pass\n\n        class Group(models.Model):\n            members = models.ManyToManyField('Person', through='CustomThroughModel')\n\n        field = Group._meta.get_field('members')\n        self.assertEqual(field.check(from_model=Group), [])\n", "    def test_resolve_relation_with_recursive_relationship(self):\n        \"\"\"\n        Test resolve_relation with RECURSIVE_RELATIONSHIP_CONSTANT.\n        \"\"\"\n\n        class ScopeModel(models.Model):\n            class Meta:\n                app_label = 'test_app'\n\n        self.assertEqual(resolve_relation(ScopeModel, 'self'), ScopeModel)\n"], "sample_75": ["def test_grid_set_axes_pad():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 2), axes_pad=0.1)\n    assert grid.get_axes_pad() == (0.1, 0.1)\n    grid.set_axes_pad((0.2, 0.3))\n    assert grid.get_axes_pad() == (0.2, 0.3)\n", "def test_grid_set_axes_pad():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 2), axes_pad=(0.5, 0.7))\n    assert grid.get_axes_pad() == (0.5, 0.7)\n    grid.set_axes_pad((0.2, 0.3))\n    assert grid.get_axes_pad() == (0.2, 0.3)\n", "def test_grid_set_get_axes_pad():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 2), axes_pad=(0.1, 0.2))\n    \n    # Check initial pad values\n    assert grid.get_axes_pad() == (0.1, 0.2)\n    \n    # Set new pad values\n    grid.set_axes_pad((0.3, 0.4))\n    \n    # Check updated pad values\n    assert grid.get_axes_pad() == (0.3, 0.4)\n", "def test_grid_set_label_mode():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 2))\n    \n    # Check the initial label mode\n    assert grid.get_geometry() == (2, 2)\n    \n    # Test setting label mode to 'all'\n    grid.set_label_mode('all')\n    for ax in grid:\n        assert ax.xaxis.get_visible() is True\n        assert ax.yaxis.get_visible() is True\n    \n    # Test setting label mode to 'L'\n    grid.set_label_mode('L')\n    for i, ax in enumerate(grid):\n        if i % 2 == 0:\n            assert ax.yaxis.get_visible() is True\n        else:\n            assert ax.yaxis.get_visible() is False\n        \n        if i >= 2:\n            assert ax.xaxis.get_visible() is True\n        else:\n            assert ax.xaxis.get_visible() is False\n    \n    # Test setting label mode to '1'\n    grid.set_label_mode('1')\n    for i, ax in enumerate(grid):\n        if i == 0:\n            assert ax.xaxis.get_visible() is True\n            assert ax.yaxis.get_visible() is True\n        else:\n            assert ax.xaxis.get_visible() is False\n            assert ax.yaxis.get_visible() is False\n    \n    # Test setting label mode to 'keep'\n    grid.set_label_mode('keep')\n    # No change expected, so just check a few axes\n    assert grid[0].xaxis.get_visible() is True\n    assert grid[1].xaxis.get_visible() is False\n    assert grid[2].yaxis.get_visible() is True\n    assert grid[3].yaxis.get_visible() is False\n", "def test_cbaraxesbase_colorbar():\n    fig, ax = plt.subplots()\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    cbar_axes = CbarAxesBase(fig, ax.get_position(), orientation=\"right\")\n    fig.add_axes(cbar_axes)\n    im = ax.imshow(np.random.random((10, 10)))\n    cbar = cbar_axes.colorbar(im)\n    assert cbar.ax is cbar_axes\n"], "sample_114": ["def test_check_partial_fit_first_call():\n    class MockClassifier:\n            self.classes_ = None\n\n    clf = MockClassifier()\n\n    # Test first call without classes\n    with pytest.raises(ValueError, match=\"classes must be passed on the first call to partial_fit.\"):\n        _check_partial_fit_first_call(clf)\n\n    # Test first call with classes\n    classes = [0, 1, 2]\n    assert _check_partial_fit_first_call(clf, classes) == True\n    assert_array_equal(clf.classes_, classes)\n\n    # Test subsequent call with same classes\n    assert _check_partial_fit_first_call(clf, classes) == False\n\n    # Test subsequent call with different classes\n    new_classes = [0, 1]\n    with pytest.raises(ValueError, match=\"`classes=%r` is not the same as on last call to partial_fit, was: %r\" % (new_classes, classes)):\n        _check_partial_fit_first_call(clf, new_classes)\n", "def test_check_classification_targets_exceptions():\n    # Test that check_classification_targets raises appropriate exceptions\n\n    # Continuous target\n    y_continuous = [0.5, 2.3, 1.9]\n    with pytest.raises(ValueError, match=\"Unknown label type: 'continuous'\"):\n        check_classification_targets(y_continuous)\n\n    # Continuous multioutput target\n    y_continuous_multioutput = np.array([[0.5, 2.3], [1.9, 3.4]])\n    with pytest.raises(ValueError, match=\"Unknown label type: 'continuous-multioutput'\"):\n        check_classification_targets(y_continuous_multioutput)\n\n    # Unknown target with 3D array\n    y_unknown = np.array([[[0, 1], [1, 0]], [[1, 1], [0, 0]]])\n    with pytest.raises(ValueError, match=\"Unknown label type: 'unknown'\"):\n        check_classification_targets(y_unknown)\n\n    # Multiclass multioutput target\n    y_multiclass_multioutput = np.array([[1, 2], [3, 4]])\n    try:\n        check_classification_targets(y_multiclass_multioutput)\n    except ValueError as e:\n        assert False, f\"check_classification_targets raised an exception {e} unexpectedly\"\n\n    # Multilabel indicator target\n    y_multilabel_indicator = np.array([[0, 1], [1, 0]])\n    try:\n        check_classification_targets(y_multilabel_indicator)\n    except ValueError as e:\n        assert False, f\"check_classification_targets raised an exception {e} unexpectedly\"\n\n    # Binary target\n    y_binary = [0, 1, 0, 1]\n    try:\n        check_classification_targets(y_binary)\n    except ValueError as e:\n        assert False, f\"check_classification_targets raised an exception {e} unexpectedly\"\n\n    # Multiclass target\n    y_multiclass = [0, 1, 2, 1]\n    try:\n        check_classification_targets(y_multiclass)\n    except ValueError as e:\n        assert False, f\"check_classification_targets raised an exception {e} unexpectedly\"\n", "def test_multilabel_mixed_array_types():\n    # Test that multilabel-indicator mixed with other array types raise error\n    y_multilabel = csr_matrix(np.random.RandomState(42).randint(2, size=(10, 10)))\n    y_binary = [0, 1, 1, 0]\n    y_multiclass = [0, 1, 2, 1]\n    \n    with pytest.raises(ValueError, match=\"Mix type of y not allowed\"):\n        unique_labels(y_multilabel, y_binary)\n    \n    with pytest.raises(ValueError, match=\"Mix type of y not allowed\"):\n        unique_labels(y_multilabel, y_multiclass)\n", "def test_unique_labels_multiclass_multioutput():\n    # Test unique_labels with multiclass-multioutput format\n\n    # Example with integers\n    y1 = np.array([[1, 0, 2], [2, 1, 0], [1, 2, 0]])\n    y2 = np.array([[3, 1, 0], [0, 2, 3], [1, 3, 2]])\n    expected_labels = np.array([0, 1, 2, 3])\n    assert_array_equal(unique_labels(y1, y2), expected_labels)\n\n    # Example with strings\n    y3 = np.array([[\"a\", \"b\", \"c\"], [\"c\", \"a\", \"b\"]])\n    y4 = np.array([[\"d\", \"a\", \"c\"], [\"b\", \"d\", \"a\"]])\n    expected_labels = np.array([\"a\", \"b\", \"c\", \"d\"])\n    assert_array_equal(unique_labels(y3, y4), expected_labels)\n\n    # Example with mixed types should raise ValueError\n    y5 = np.array([[1, \"a\", 2], [2, 1, \"b\"]])\n    with pytest.raises(ValueError):\n        unique_labels(y5, y1)\n", "def test_is_integral_float():\n    assert not _is_integral_float(np.array([1.1, 2.2, 3.3]))\n    assert _is_integral_float(np.array([1.0, 2.0, 3.0]))\n    assert _is_integral_float(np.array([1.0, 2.0, 3.0, 4.0]))\n    assert not _is_integral_float(np.array([1.0, 2.0, 3.5]))\n    assert not _is_integral_float(np.array([0.1, 0.2, 0.3]))\n    assert _is_integral_float(np.array([1.0, 0.0, -1.0]))\n"], "sample_112": ["def test_check_increasing_with_identical_values():\n    # Test check_increasing with x and y having identical values\n    x = [1, 1, 1, 1, 1]\n    y = [1, 1, 1, 1, 1]\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\", UserWarning)\n        is_increasing = check_increasing(x, y)\n\n    assert is_increasing\n", "def test_isotonic_regression_ymin_ymax_with_extreme_values():\n    # Test isotonic regression with extreme y_min and y_max values\n\n    x = np.array([0, 1, 2, 3, 4, 5])\n    y = np.array([10, 20, 30, 40, 50, 60])\n\n    # Test with very high y_min and y_max\n    y_min = 100\n    y_max = 200\n    y_expected = np.full_like(y, y_min)\n    ir = IsotonicRegression(y_min=y_min, y_max=y_max)\n    y_transformed = ir.fit_transform(x, y)\n    assert_array_equal(y_transformed, y_expected)\n\n    # Test with very low y_min and y_max\n    y_min = -100\n    y_max = -50\n    y_expected = np.full_like(y, y_max)\n    ir = IsotonicRegression(y_min=y_min, y_max=y_max)\n    y_transformed = ir.fit_transform(x, y)\n    assert_array_equal(y_transformed, y_expected)\n", "def test_isotonic_regression_check_out_of_bounds():\n    \"\"\"Test IsotonicRegression's behavior with 'clip' and 'nan' for out_of_bounds.\"\"\"\n\n    # Test data\n    x = np.array([1, 2, 3, 4, 5])\n    y = np.array([2, 1, 4, 3, 5])\n\n    # Test with out_of_bounds=\"clip\"\n    ir_clip = IsotonicRegression(out_of_bounds=\"clip\")\n    ir_clip.fit(x, y)\n    y_clip_pred = ir_clip.predict([0, 6])\n    assert y_clip_pred[0] == y.min()\n    assert y_clip_pred[1] == y.max()\n\n    # Test with out_of_bounds=\"nan\"\n    ir_nan = IsotonicRegression(out_of_bounds=\"nan\")\n    ir_nan.fit(x, y)\n    y_nan_pred = ir_nan.predict([0, 6])\n    assert np.isnan(y_nan_pred[0])\n    assert np.isnan(y_nan_pred[1])\n", "def test_check_increasing_with_nan_values():\n    # Test check_increasing function with NaN values in the input.\n    x = [0, 1, 2, 3, 4, 5]\n    y = [0, np.nan, 2.77, 8.99, np.nan, 50]\n\n    # Expect that check_increasing can handle NaN values without raising an error\n    # and correctly identifies the increasing trend.\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\", UserWarning)\n        is_increasing = check_increasing(x, y)\n\n    assert is_increasing\n", "def test_isotonic_regression_out_of_bounds_behavior():\n    # Check the behavior of IsotonicRegression for different out_of_bounds values\n\n    # Set y and x\n    y = np.array([3, 7, 5, 9, 8, 7, 10])\n    x = np.arange(len(y))\n\n    # Model with out_of_bounds=\"raise\"\n    ir_raise = IsotonicRegression(increasing=True, out_of_bounds=\"raise\")\n    ir_raise.fit(x, y)\n    with pytest.raises(ValueError, match=\"in x_new is below the interpolation range\"):\n        ir_raise.predict([min(x) - 1])\n    with pytest.raises(ValueError, match=\"in x_new is above the interpolation range\"):\n        ir_raise.predict([max(x) + 1])\n\n    # Model with out_of_bounds=\"clip\"\n    ir_clip = IsotonicRegression(increasing=True, out_of_bounds=\"clip\")\n    ir_clip.fit(x, y)\n    y_clip_pred = ir_clip.predict([min(x) - 1, max(x) + 1])\n    assert y_clip_pred[0] == y[0]  # Clipped to min y value\n    assert y_clip_pred[1] == y[-1]  # Clipped to max y value\n\n    # Model with out_of_bounds=\"nan\"\n    ir_nan = IsotonicRegression(increasing=True, out_of_bounds=\"nan\")\n    ir_nan.fit(x, y)\n    y_nan_pred = ir_nan.predict([min(x) - 1, max(x) + 1])\n    assert np.isnan(y_nan_pred).all()  # Both predictions should be NaN\n"], "sample_138": ["def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, k)\n    C = MatrixSymbol('C', l, m)\n    D = MatrixSymbol('D', l, k)\n    X = BlockMatrix(Matrix([[A, B], [C, D]]))\n\n    real_X, imag_X = X.as_real_imag()\n\n    assert real_X.blocks[0, 0] == re(A)\n    assert real_X.blocks[0, 1] == re(B)\n    assert real_X.blocks[1, 0] == re(C)\n    assert real_X.blocks[1, 1] == re(D)\n\n    assert imag_X.blocks[0, 0] == im(A)\n    assert imag_X.blocks[0, 1] == im(B)\n    assert imag_X.blocks[1, 0] == im(C)\n    assert imag_X.blocks[1, 1] == im(D)\n", "def test_BlockMatrix_equality():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', n, n)\n    E = MatrixSymbol('E', n, n)\n    F = MatrixSymbol('F', n, n)\n\n    X = BlockMatrix([[A, B], [C, D]])\n    Y = BlockMatrix([[A, B], [C, D]])\n    Z = BlockMatrix([[E, F], [C, D]])\n\n    assert X.equals(Y)\n    assert not X.equals(Z)\n", "def test_BlockMatrix_as_real_imag():\n    from sympy import I\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', n, n)\n    X = BlockMatrix([[A + I*B, C], [D, A - I*B]])\n\n    real_part, imag_part = X.as_real_imag()\n    expected_real = BlockMatrix([[A, C], [D, A]])\n    expected_imag = BlockMatrix([[B, ZeroMatrix(n, n)], [ZeroMatrix(n, n), -B]])\n\n    assert real_part == expected_real\n    assert imag_part == expected_imag\n", "def test_BlockMatrix_structurally_equal():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n    Y = BlockMatrix([[A, B], [C, D]])\n    Z = BlockMatrix([[A, ZeroMatrix(n, m)], [ZeroMatrix(m, n), D]])\n\n    assert X.structurally_equal(Y)\n    assert not X.structurally_equal(Z)\n\n    W = BlockMatrix([[A, B], [C, ZeroMatrix(m, m)]])\n    assert not X.structurally_equal(W)\n", "def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', m, m)\n    C = MatrixSymbol('C', n, m)\n    D = MatrixSymbol('D', m, n)\n    E = MatrixSymbol('E', n, m)\n    F = MatrixSymbol('F', m, m)\n    Z = ZeroMatrix(n, m)\n    X = BlockMatrix([[A, C], [D, B]])\n    Y = BlockMatrix([[E, Z], [Z, F]])\n\n    real_X, imag_X = X.as_real_imag()\n    real_Y, imag_Y = Y.as_real_imag()\n\n    assert isinstance(real_X, Matrix)\n    assert isinstance(imag_X, Matrix)\n    assert isinstance(real_Y, Matrix)\n    assert isinstance(imag_Y, Matrix)\n\n    assert real_X.shape == X.blockshape\n    assert imag_X.shape == X.blockshape\n    assert real_Y.shape == Y.blockshape\n    assert imag_Y.shape == Y.blockshape\n\n    assert real_X == Matrix([[re(A), re(C)], [re(D), re(B)]])\n    assert imag_X == Matrix([[im(A), im(C)], [im(D), im(B)]])\n    assert real_Y == Matrix([[re(E), re(Z)], [re(Z), re(F)]])\n    assert imag_Y == Matrix([[im(E), im(Z)], [im(Z), im(F)]])\n"], "sample_16": ["    def test_unquote(self):\n        self.assertEqual(unquote('something_0Aor_0Aother'), 'something\\nor\\nother')\n        self.assertEqual(unquote('nothing_to_unquote'), 'nothing_to_unquote')\n        self.assertEqual(unquote('mixed_5Bcase_5Dhere'), 'mixed[case]here')\n", "    def test_prepare_lookup_value(self):\n        \"\"\"\n        Test prepare_lookup_value function.\n        \"\"\"\n        self.assertEqual(prepare_lookup_value('key__in', 'value1,value2'), ['value1', 'value2'])\n        self.assertTrue(prepare_lookup_value('key__isnull', ''))\n        self.assertTrue(prepare_lookup_value('key__isnull', 'false'))\n        self.assertTrue(prepare_lookup_value('key__isnull', '0'))\n        self.assertFalse(prepare_lookup_value('key__isnull', 'true'))\n        self.assertEqual(prepare_lookup_value('key', 'value'), 'value')\n", "    def test_reverse_field_path(self):\n        class User(models.Model):\n            name = models.CharField(max_length=100)\n\n        class Group(models.Model):\n            name = models.CharField(max_length=100)\n            user = models.ForeignKey(User, on_delete=models.CASCADE, related_name='groups')\n\n        class Order(models.Model):\n            user = models.ForeignKey(User, on_delete=models.CASCADE)\n\n        self.assertEqual(reverse_field_path(Order, \"user__groups\"), (Group, \"user__order\"))\n        self.assertEqual(reverse_field_path(Group, \"user__order\"), (Order, \"user__groups\"))\n", "    def test_prepare_lookup_value(self):\n        \"\"\"\n        Test `prepare_lookup_value` function.\n        \"\"\"\n        self.assertEqual(prepare_lookup_value('field__in', '1,2,3'), ['1', '2', '3'])\n        self.assertTrue(prepare_lookup_value('field__isnull', 'false') is False)\n        self.assertTrue(prepare_lookup_value('field__isnull', '0') is False)\n        self.assertTrue(prepare_lookup_value('field__isnull', 'True') is True)\n        self.assertEqual(prepare_lookup_value('field', 'value'), 'value')\n", "    def test_prepare_lookup_value(self):\n        \"\"\"\n        Test the behavior of prepare_lookup_value with different types of lookup keys.\n        \"\"\"\n        # Test '__in' lookup\n        self.assertEqual(prepare_lookup_value('field__in', '1,2,3'), ['1', '2', '3'])\n\n        # Test '__isnull' lookup with different values\n        self.assertTrue(prepare_lookup_value('field__isnull', 'true'))\n        self.assertTrue(prepare_lookup_value('field__isnull', 'True'))\n        self.assertTrue(prepare_lookup_value('field__isnull', '1'))\n        self.assertFalse(prepare_lookup_value('field__isnull', 'false'))\n        self.assertFalse(prepare_lookup_value('field__isnull', 'False'))\n        self.assertFalse(prepare_lookup_value('field__isnull', '0'))\n        self.assertFalse(prepare_lookup_value('field__isnull', ''))\n\n        # Test other lookup types (should remain unchanged)\n        self.assertEqual(prepare_lookup_value('field__exact', 'value'), 'value')\n        self.assertEqual(prepare_lookup_value('field__icontains', 'value'), 'value')\n"], "sample_89": ["def test_node_add_marker():\n    node = nodes.Node(name=\"test_node\", parent=None, config=pytest.Config(), session=pytest.Session(py.path.local()))\n    node.add_marker(\"test_marker\")\n    assert \"test_marker\" in node.keywords\n    assert node.own_markers[0].name == \"test_marker\"\n\n    node.add_marker(\"another_marker\", append=False)\n    assert \"another_marker\" in node.keywords\n    assert node.own_markers[0].name == \"another_marker\"\n", "def test_node_id_generation():\n    parent = nodes.Node(name=\"parent\", nodeid=\"parent\")\n    child = nodes.Node(name=\"child\", parent=parent)\n    assert child.nodeid == \"parent::child\"\n", "def test_node_repr():\n    node = nodes.Node(name=\"test_node\", parent=None, config=pytest.Config.fromdictargs({}), session=pytest.Session(py.path.local(), pytest.Config.fromdictargs({})))\n    assert repr(node) == \"<Node test_node>\"\n", "def test_get_closest_marker():\n    class FakeNode(nodes.Node):\n            super().__init__(name, parent)\n            self.own_markers = [\n                pytest.mark.foo,\n                pytest.mark.bar,\n                pytest.mark.baz,\n            ]\n\n    parent_node = FakeNode(\"parent\")\n    child_node = FakeNode(\"child\", parent=parent_node)\n\n    assert child_node.get_closest_marker(\"foo\") == pytest.mark.foo\n    assert child_node.get_closest_marker(\"bar\") == pytest.mark.bar\n    assert child_node.get_closest_marker(\"baz\") == pytest.mark.baz\n    assert child_node.get_closest_marker(\"nonexistent\") is None\n", "def test_node_add_marker():\n    node = nodes.Node(name=\"test_node\", parent=None, config=pytest.Config(), session=pytest.Session(config=pytest.Config()))\n    assert len(node.own_markers) == 0\n    node.add_marker(\"marker1\")\n    assert len(node.own_markers) == 1\n    assert node.own_markers[0].name == \"marker1\"\n\n    node.add_marker(pytest.mark.example)\n    assert len(node.own_markers) == 2\n    assert node.own_markers[1].name == \"example\"\n\n    with pytest.raises(ValueError, match=\"is not a string or pytest.mark.* Marker\"):\n        node.add_marker(123)\n"], "sample_13": ["    def test_fields_limit(self):\n        with self.assertRaisesMessage(TooManyFieldsSent, 'The number of GET/POST parameters exceeded settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'):\n            limited_parse_qsl('a=1&b=2&c=3', fields_limit=2)\n", "    def test_unquote(self):\n        self.assertEqual(urlunquote('http%3A%2F%2Fexample.com'), 'http://example.com')\n        self.assertEqual(urlunquote('https%3A%2F%2Fexample.com'), 'https://example.com')\n        self.assertEqual(urlunquote('%2Fpath%2Fto%2Fresource'), '/path/to/resource')\n        self.assertEqual(urlunquote('plain%20text'), 'plain text')\n        self.assertEqual(urlunquote('already_unquoted'), 'already_unquoted')\n", "    def test_urlparse(self):\n        url = 'http://www.example.com/path;params?query#fragment'\n        result = _urlparse(url)\n        self.assertEqual(result.scheme, 'http')\n        self.assertEqual(result.netloc, 'www.example.com')\n        self.assertEqual(result.path, '/path')\n        self.assertEqual(result.params, 'params')\n        self.assertEqual(result.query, 'query')\n        self.assertEqual(result.fragment, 'fragment')\n", "    def test_valid_dates(self):\n        valid_dates = [\n            'Sun, 06 Nov 1994 08:49:37 GMT',\n            'Sunday, 06-Nov-94 08:49:37 GMT',\n            'Sun Nov  6 08:49:37 1994',\n        ]\n        expected_timestamp = 784111777\n        for date in valid_dates:\n            with self.subTest(date=date):\n                self.assertEqual(parse_http_date_safe(date), expected_timestamp)\n", "    def test_limit_exceeded(self):\n        with self.assertRaisesMessage(TooManyFieldsSent, 'The number of GET/POST parameters exceeded settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'):\n            limited_parse_qsl('a=1&b=2&c=3&d=4&e=5', fields_limit=4)\n"], "sample_50": ["    def test_not_finished_sentinel(self):\n        \"\"\"\n        The not_finished sentinel value is correctly handled when retrieving\n        messages from the cookie storage.\n        \"\"\"\n        storage = self.get_storage()\n        response = self.get_response()\n        \n        # Add messages to storage\n        messages = ['msg1', 'msg2', 'msg3', CookieStorage.not_finished]\n        set_cookie_data(storage, messages)\n        \n        # Retrieve messages from storage and ensure the sentinel value is handled correctly\n        retrieved_messages, all_retrieved = storage._get()\n        self.assertFalse(all_retrieved)\n        self.assertEqual(retrieved_messages, ['msg1', 'msg2', 'msg3'])\n\n        # Test the behavior when there is no sentinel value\n        messages = ['msg1', 'msg2', 'msg3']\n        set_cookie_data(storage, messages)\n        retrieved_messages, all_retrieved = storage._get()\n        self.assertTrue(all_retrieved)\n        self.assertEqual(retrieved_messages, ['msg1', 'msg2', 'msg3'])\n", "    def test_invalid_json_decoder(self):\n        \"\"\"\n        Test that the MessageDecoder properly handles and raises an error\n        when encountering invalid JSON data.\n        \"\"\"\n        invalid_json = '{\"__json_message\": 1, \"invalid_message_data\"}'\n        with self.assertRaises(json.JSONDecodeError):\n            json.loads(invalid_json, cls=MessageDecoder)\n", "    def test_not_finished_sentinal(self):\n        \"\"\"\n        Ensure that the not_finished sentinel value is correctly handled.\n        \"\"\"\n        storage = self.get_storage()\n        response = self.get_response()\n\n        # Create more messages than max_cookie_size can handle.\n        msg_size = int((CookieStorage.max_cookie_size - 54) / 4.5 - 37)\n        messages = [Message(constants.INFO, get_random_string(msg_size)) for _ in range(10)]\n        storage.add(constants.INFO, 'initial message')\n        set_cookie_data(storage, messages)\n\n        # Check that messages include the not_finished sentinel when they don't fit in the cookie.\n        storage.update(response)\n        cookie_messages = storage._decode(response.cookies[storage.cookie_name].value)\n        self.assertEqual(cookie_messages[-1], CookieStorage.not_finished)\n", "    def test_not_finished_sentinal(self):\n        \"\"\"\n        Test that the not_finished sentinel value is correctly handled when\n        messages exceed the maximum cookie size.\n        \"\"\"\n        storage = self.get_storage()\n        response = self.get_response()\n\n        # Create messages that will exceed the max_cookie_size.\n        large_message = 'A' * CookieStorage.max_cookie_size\n        storage.add(constants.INFO, large_message)\n        \n        # Store the messages in response and verify the not_finished sentinel is added\n        storage.update(response)\n        cookie_data = response.cookies['messages'].value\n        messages = storage._decode(cookie_data)\n        \n        # Check that the sentinel is added to indicate not all messages were stored\n        self.assertIn(CookieStorage.not_finished, messages)\n", "    def test_message_serializer(self):\n        \"\"\"\n        Test that the MessageSerializer correctly serializes and deserializes\n        a list of Message objects.\n        \"\"\"\n        messages = [\n            Message(constants.INFO, 'info message', extra_tags='tag1'),\n            Message(constants.WARNING, 'warning message', extra_tags='tag2'),\n            Message(constants.ERROR, 'error message', extra_tags='tag3'),\n        ]\n        serializer = MessageSerializer()\n        serialized = serializer.dumps(messages)\n        deserialized = serializer.loads(serialized)\n        self.assertEqual(messages, deserialized)\n"], "sample_92": ["def test_evaluate_skip_marks_with_multiple_conditions(testdir):\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.skipif(\"False\", reason=\"first condition\")\n        @pytest.mark.skipif(\"True\", reason=\"second condition\")\n            pass\n    \"\"\"\n    )\n    skipped = evaluate_skip_marks(item)\n    assert skipped\n    assert skipped.reason == \"second condition\"\n", "def test_xfail_mark_without_reason(testdir):\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail()\n            assert 0\n    \"\"\"\n    )\n    xfailed = evaluate_xfail_marks(item)\n    assert xfailed\n    assert xfailed.reason == \"\"\n", "def test_xfail_with_raises_and_strict(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(raises=ValueError, strict=True, reason=\"Expected ValueError\")\n            raise ValueError(\"This is a ValueError\")\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*XPASS(strict)*Expected ValueError*\"])\n    assert result.ret == 1  # Ensure test fails due to strict xfail\n", "def test_xfail_strict_from_ini(testdir):\n    # Test xfail's strict option using xfail_strict from ini file\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = true\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xfail(reason='strict from ini')\n            assert 1\n\n        @pytest.mark.xfail(reason='strict from ini')\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxX\")\n    result.stdout.fnmatch_lines([\n        \"*XPASS(strict)*strict from ini*\",\n        \"*1 failed*1 xfailed*\"\n    ])\n    assert result.ret == 1\n", "def test_evaluate_condition_with_syntax_error(testdir):\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.skipif(\"invalid syntax\", reason=\"should fail\")\n            pass\n    \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_skip_marks(item)\n    assert excinfo.value.msg is not None\n    assert \"SyntaxError: invalid syntax\" in excinfo.value.msg\n"], "sample_135": ["def test_class_key():\n    class SubBasic(Basic):\n        pass\n\n    class SubAtom(Atom):\n        pass\n\n    assert Basic.class_key() == (5, 0, 'Basic')\n    assert Atom.class_key() == (2, 0, 'Atom')\n    assert SubBasic.class_key() == (5, 0, 'SubBasic')\n    assert SubAtom.class_key() == (2, 0, 'SubAtom')\n\n    assert Basic().class_key() == (5, 0, 'Basic')\n    assert Atom().class_key() == (2, 0, 'Atom')\n    assert SubBasic().class_key() == (5, 0, 'SubBasic')\n    assert SubAtom().class_key() == (2, 0, 'SubAtom')\n", "def test_compare():\n    # Test compare function\n    x, y = symbols('x y')\n    assert Basic(x).compare(Basic(x)) == 0\n    assert Basic(x).compare(Basic(y)) < 0\n    assert Basic(y).compare(Basic(x)) > 0\n\n    # Complex comparison\n    assert Basic(x, y).compare(Basic(y, x)) < 0\n    assert Basic(y, x).compare(Basic(x, y)) > 0\n    assert Basic(x, x).compare(Basic(y, y)) < 0\n\n    # Check self comparison\n    assert Basic(x).compare(Basic(x)) == 0\n\n    # Check different lengths\n    assert Basic(x, y).compare(Basic(x)) > 0\n    assert Basic(x).compare(Basic(x, y)) < 0\n\n    # Check mixed types\n    assert Basic(x).compare(Basic(x, y)) < 0\n    assert Basic(x, y).compare(Basic(x)) > 0\n", "def test_args_property():\n    a = Basic(1, 2, 3)\n    assert a.args == (1, 2, 3)\n    b = Basic(a, 4)\n    assert b.args == (a, 4)\n    assert b.func(*b.args) == b\n    assert b.args[0].args == (1, 2, 3)\n", "def test_constructor_postprocessors():\n    from sympy.core.basic import Basic\n    from sympy import Symbol\n\n    # Define a postprocessor that replaces a symbol with another symbol\n        return expr.subs(Symbol('x'), Symbol('y'))\n\n    # Add the postprocessor to Basic\n    Basic._constructor_postprocessor_mapping[Symbol] = {'Basic': [replace_symbol]}\n\n    # Create an instance of Basic containing the symbol 'x'\n    expr = Basic(Symbol('x'))\n\n    # Apply the constructor postprocessors\n    processed_expr = Basic._exec_constructor_postprocessors(expr)\n\n    # Check that the symbol 'x' has been replaced with 'y'\n    assert processed_expr == Basic(Symbol('y'))\n\n    # Clean up the postprocessor mapping\n    del Basic._constructor_postprocessor_mapping[Symbol]\n", "def test_copy():\n    x, y = symbols('x y')\n    expr = Basic(x, y)\n    copied_expr = expr.copy()\n    assert copied_expr == expr\n    assert copied_expr.args == expr.args\n    assert copied_expr is not expr  # Ensure a new instance is created\n"], "sample_159": ["def test_prefix_properties():\n    y = PREFIXES['Y']\n    assert y.name == 'yotta'\n    assert y.abbrev == 'Y'\n    assert y.scale_factor == 10**24\n\n    micro = PREFIXES['mu']\n    assert micro.name == 'micro'\n    assert micro.abbrev == 'mu'\n    assert micro.scale_factor == 10**(-6)\n    assert micro._latex(None) == r\"\\mu\"\n\n    giga = PREFIXES['G']\n    assert giga.name == 'giga'\n    assert giga.abbrev == 'G'\n    assert giga.scale_factor == 10**9\n\n    kibi = BIN_PREFIXES['Ki']\n    assert kibi.name == 'kibi'\n    assert kibi.abbrev == 'Y'\n    assert kibi.scale_factor == 2**10\n", "def test_latex_representation():\n    assert kilo._latex(None) == r'\\text{k}'\n    assert milli._latex(None) == r'\\text{m}'\n    assert micro._latex(None) == r'\\mu'\n    custom_prefix = Prefix('custom', 'cu', 2, latex_repr=r\"\\text{custom}\")\n    assert custom_prefix._latex(None) == r'\\text{custom}'\n", "def test_prefix_initialization():\n    name = \"test\"\n    abbrev = \"t\"\n    exponent = 5\n    base = 2\n    latex_repr = r\"\\text{t}\"\n\n    p = Prefix(name, abbrev, exponent, base, latex_repr)\n\n    assert p.name == name\n    assert p.abbrev == abbrev\n    assert p.scale_factor == base ** exponent\n    assert p._exponent == exponent\n    assert p.base == base\n    assert p._latex_repr == latex_repr\n    assert p._latex(None) == latex_repr\n", "def test_prefix_properties():\n    y = PREFIXES['Y']\n    assert y.name == 'yotta'\n    assert y.abbrev == 'Y'\n    assert y.scale_factor == 10**24\n\n    mu = PREFIXES['mu']\n    assert mu.name == 'micro'\n    assert mu.abbrev == 'mu'\n    assert mu.scale_factor == 10**-6\n\n    kibi = BIN_PREFIXES['Ki']\n    assert kibi.name == 'kibi'\n    assert kibi.abbrev == 'Y'\n    assert kibi.scale_factor == 2**10\n", "def test_prefix_properties():\n    milli = PREFIXES['m']\n    assert milli.name == 'milli'\n    assert milli.abbrev == 'm'\n    assert milli.scale_factor == 10**-3\n\n    assert milli._latex(None) == r'\\text{m}'\n\n    micro = PREFIXES['mu']\n    assert micro.name == 'micro'\n    assert micro.abbrev == 'mu'\n    assert micro.scale_factor == 10**-6\n    assert micro._latex(None) == r'\\mu'\n\n    assert kilo.name == 'kilo'\n    assert kilo.abbrev == 'k'\n    assert kilo.scale_factor == 10**3\n"], "sample_147": ["def test_Function_kind():\n    from sympy import Function, symbols\n    f = Function('f')\n    x, y = symbols('x y')\n    assert f(x).kind is UndefinedKind\n    assert f(x + y).kind is UndefinedKind\n    assert f(x*y).kind is UndefinedKind\n", "def test_Function_kind():\n    from sympy import Function\n\n    # Define undefined functions\n    f = Function('f')\n    g = Function('g')\n\n    assert f(comm_x).kind is NumberKind\n    assert f(noncomm_x).kind is UndefinedKind\n    assert g(comm_x, noncomm_x).kind is UndefinedKind\n\n    # Test derivatives of functions\n    assert f(comm_x).diff(comm_x).kind is NumberKind\n    assert g(noncomm_x).diff(noncomm_x).kind is UndefinedKind\n\n    # Test nested functions\n    h = Function('h')(comm_x) + Function('i')(noncomm_x)\n    assert h.kind is UndefinedKind\n\n    # Test function application\n    assert f(x).applyfunc(lambda x: x**2).kind is NumberKind\n", "def test_Function_nargs():\n    from sympy import Function, Symbol\n    x, y, z = Symbol('x'), Symbol('y'), Symbol('z')\n    \n    # Test undefined functions\n    f = Function('f')\n    assert f.nargs == S.Naturals0  # Can take any number of arguments\n    \n    # Test defined functions\n    class my_func(Function):\n        nargs = (1, 2)\n    \n    assert my_func.nargs == FiniteSet(1, 2)\n    assert my_func(x).nargs == FiniteSet(1)\n    assert my_func(x, y).nargs == FiniteSet(2)\n    raises(TypeError, lambda: my_func(x, y, z))  # Should raise an error for invalid number of arguments\n", "def test_Function_kind():\n    from sympy import Function\n    f = Function('f')\n    g = Function('g')\n    h = Function('h', nargs=2)\n    A = MatrixSymbol('A', 2, 2)\n    \n    assert f(comm_x).kind is NumberKind\n    assert f(noncomm_x).kind is UndefinedKind\n    assert g(A).kind is MatrixKind(NumberKind)\n    assert h(comm_x, A).kind is MatrixKind(NumberKind)\n    assert h(noncomm_x, A).kind is UndefinedKind\n", "def test_Function_kind():\n    from sympy import Function\n    f = Function('f')\n    assert f.kind is UndefinedKind\n    assert f(comm_x).kind is UndefinedKind\n    assert f(2).kind is NumberKind\n\n    g = Function('g', nargs=1)\n    assert g.kind is UndefinedKind\n    assert g(comm_x).kind is UndefinedKind\n    assert g(2).kind is NumberKind\n"], "sample_57": ["    def test_management_form_initial_data(self):\n        \"\"\"\n        Test that the management form is correctly initialized with the total,\n        initial, min, and max form counts.\n        \"\"\"\n        formset = formset_factory(Choice, extra=2, min_num=1, max_num=3)\n        formset_instance = formset()\n        management_form = formset_instance.management_form\n        self.assertEqual(management_form.initial[TOTAL_FORM_COUNT], 2)\n        self.assertEqual(management_form.initial[INITIAL_FORM_COUNT], 0)\n        self.assertEqual(management_form.initial[MIN_NUM_FORM_COUNT], 1)\n        self.assertEqual(management_form.initial[MAX_NUM_FORM_COUNT], 3)\n", "    def test_clean_method_called_on_formset(self):\n        \"\"\"\n        The clean method on the formset should be called during validation.\n        \"\"\"\n        class CleanMethodFormSet(BaseFormSet):\n                raise ValidationError(\"Formset clean method called\")\n\n        CleanMethodFormSetFactory = formset_factory(FavoriteDrinkForm, formset=CleanMethodFormSet)\n        data = {\n            \"form-TOTAL_FORMS\": \"1\",\n            \"form-INITIAL_FORMS\": \"0\",\n            \"form-0-name\": \"Mojito\",\n        }\n        formset = CleanMethodFormSetFactory(data)\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(formset.non_form_errors(), [\"Formset clean method called\"])\n\n", "    def test_formset_initial_and_extra_forms(self):\n        \"\"\"\n        A FormSet can be prefilled with initial data and have extra empty forms \n        rendered. Extra forms should not be bound and should be empty.\n        \"\"\"\n        initial = [{\"choice\": \"Calexico\", \"votes\": 100}, {\"choice\": \"Fergie\", \"votes\": 900}]\n        formset = self.make_choiceformset(initial=initial, total_forms=5, extra=3)\n\n        # Check if initial forms are correctly prefilled.\n        self.assertEqual(\n            [form.initial for form in formset.forms[:2]], \n            [{\"choice\": \"Calexico\", \"votes\": 100}, {\"choice\": \"Fergie\", \"votes\": 900}]\n        )\n        \n        # Check if extra forms are empty.\n        for form in formset.forms[2:]:\n            self.assertFalse(form.is_bound)\n            self.assertEqual(form.initial, {})\n            self.assertEqual(form.cleaned_data, {})\n\n        # Check HTML rendering\n        self.assertHTMLEqual(\n            \"\\n\".join(form.as_ul() for form in formset.forms),\n            '<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>'\n            '<li>Votes: <input type=\"number\" name=\"choices-0-votes\" value=\"100\"></li>'\n            '<li>Choice: <input type=\"text\" name=\"choices-1-choice\" value=\"Fergie\"></li>'\n            '<li>Votes: <input type=\"number\" name=\"choices-1-votes\" value=\"900\"></li>'\n            '<li>Choice: <input type=\"text\" name=\"choices-2-choice\"></li>'\n            '<li>Votes: <input type=\"number\" name=\"choices-2-votes\"></li>'\n            '<li>Choice: <input type=\"text\" name=\"choices-3-choice\"></li>'\n            '<li>Votes: <input type=\"number\" name=\"choices-3-votes\"></li>'\n            '<li>Choice: <input type=\"text\" name=\"choices-4-choice\"></li>'\n            '<li>Votes: <input type=\"number\" name=\"choices-4-votes\"></li>'\n        )\n", "def test_max_num_with_initial_and_extra(self):\n    \"\"\"\n    Ensure that initial forms combined with extra forms respect the max_num\n    constraint.\n    \"\"\"\n    initial = [\n        {\"choice\": \"Gin Tonic\"},\n        {\"choice\": \"Bloody Mary\"},\n    ]\n    LimitedFavoriteDrinkFormSet = formset_factory(\n        FavoriteDrinkForm, extra=2, max_num=3\n    )\n    formset = LimitedFavoriteDrinkFormSet(initial=initial)\n    self.assertHTMLEqual(\n        \"\\n\".join(str(form) for form in formset.forms),\n        \"\"\"\n        <div><label for=\"id_form-0-name\">Name:</label>\n        <input type=\"text\" name=\"form-0-name\" value=\"Gin Tonic\" id=\"id_form-0-name\"></div>\n        <div><label for=\"id_form-1-name\">Name:</label>\n        <input type=\"text\" name=\"form-1-name\" value=\"Bloody Mary\" id=\"id_form-1-name\"></div>\n        <div><label for=\"id_form-2-name\">Name:</label>\n        <input type=\"text\" name=\"form-2-name\" id=\"id_form-2-name\"></div>\"\"\",\n    )\n", "def test_management_form_clean_sets_defaults(self):\n        \"\"\"ManagementForm.clean() should set defaults for missing data.\"\"\"\n        class ManagementFormWithValidation(ManagementForm):\n                cleaned_data = super().clean()\n                cleaned_data.setdefault('additional_field', 'default_value')\n                return cleaned_data\n\n        form = ManagementFormWithValidation(\n            data={\n                TOTAL_FORM_COUNT: '1',\n                INITIAL_FORM_COUNT: '0',\n            }\n        )\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data.get('additional_field'), 'default_value')\n"], "sample_103": ["def test_estimate_mi_continuous_discrete():\n    # Generate a random dataset with mixed continuous and discrete features\n    rng = check_random_state(42)\n    X = rng.rand(1000, 5)\n    X[:, 0] = (X[:, 0] * 10).astype(int)  # Make the first feature discrete\n    X[:, 3] = (X[:, 3] * 10).astype(int)  # Make the fourth feature discrete\n    y = rng.rand(1000) * 2  # Continuous target variable\n\n    # Compute mutual information\n    mi = _estimate_mi(X, y, discrete_features=[0, 3], discrete_target=False, n_neighbors=3, random_state=42)\n\n    # Assert that mutual information values are non-negative\n    assert np.all(mi >= 0), \"Mutual information should be non-negative\"\n\n    # Check for different number of neighbors\n    for n_neighbors in [5, 7, 9]:\n        mi_nn = _estimate_mi(X, y, discrete_features=[0, 3], discrete_target=False, n_neighbors=n_neighbors, random_state=42)\n        assert np.all(mi_nn >= 0), \"Mutual information should be non-negative\"\n\n        # Check that increasing neighbors doesn't drastically decrease MI for continuous features\n        for i, is_discrete in enumerate([True, False, False, True, False]):\n            if not is_discrete:\n                assert_greater(mi_nn[i], mi[i] * 0.5), f\"MI for continuous feature {i} should not decrease drastically\"\n", "def test_mutual_info_regression_mixed():\n    # Here the target is continuous and there are two continuous and one\n    # discrete feature. The idea of this test is clear from the code.\n    rng = check_random_state(0)\n    X = rng.rand(1000, 3)\n    X[:, 1] += X[:, 0]\n    y = 0.5 * X[:, 0] + X[:, 2]\n    X[:, 2] = X[:, 2] > 0.5\n\n    mi = mutual_info_regression(X, y, discrete_features=[2], n_neighbors=3,\n                                random_state=0)\n    assert_array_equal(np.argsort(-mi), [0, 2, 1])\n    for n_neighbors in [5, 7, 9]:\n        mi_nn = mutual_info_regression(X, y, discrete_features=[2],\n                                       n_neighbors=n_neighbors, random_state=0)\n        # Check that the continuous values have an higher MI with greater\n        # n_neighbors\n        assert_greater(mi_nn[0], mi[0])\n        assert_greater(mi_nn[1], mi[1])\n        # The n_neighbors should not have any effect on the discrete value\n        # The MI should be the same\n        assert_equal(mi_nn[2], mi[2])\n", "def test_iterate_columns():\n    # Test _iterate_columns with dense array\n    X_dense = np.array([[1, 2, 3],\n                        [4, 5, 6],\n                        [7, 8, 9]])\n    columns = [0, 2]\n    expected = [np.array([1, 4, 7]), np.array([3, 6, 9])]\n    \n    for i, x in enumerate(_iterate_columns(X_dense, columns)):\n        assert_array_equal(x, expected[i])\n\n    # Test _iterate_columns with sparse matrix\n    X_sparse = csr_matrix(X_dense)\n    for i, x in enumerate(_iterate_columns(X_sparse, columns)):\n        assert_array_equal(x, expected[i])\n\n    # Test _iterate_columns with default columns (None)\n    expected_all = [np.array([1, 4, 7]), np.array([2, 5, 8]), np.array([3, 6, 9])]\n    for i, x in enumerate(_iterate_columns(X_dense)):\n        assert_array_equal(x, expected_all[i])\n\n    for i, x in enumerate(_iterate_columns(X_sparse)):\n        assert_array_equal(x, expected_all[i])\n", "def test_estimate_mi_with_sparse_input():\n    # Test mutual information estimation with sparse matrix input\n    rng = check_random_state(0)\n    X_dense = rng.rand(100, 5)\n    X_sparse = csr_matrix(X_dense)\n    y = (X_dense[:, 0] + X_dense[:, 1] > 1).astype(int)\n\n    mi_dense = mutual_info_classif(X_dense, y, discrete_features='auto', random_state=0)\n    mi_sparse = mutual_info_classif(X_sparse, y, discrete_features='auto', random_state=0)\n\n    assert_array_equal(mi_dense, mi_sparse)\n", "def test_iterate_columns():\n    # Test _iterate_columns function for both dense and sparse matrices.\n    \n    X_dense = np.array([[1, 2, 3],\n                        [4, 5, 6],\n                        [7, 8, 9]])\n    \n    X_sparse = csr_matrix(X_dense)\n    \n    columns = [0, 2]\n    \n    # Test dense matrix\n    dense_columns = list(_iterate_columns(X_dense, columns=columns))\n    assert_array_equal(dense_columns[0], X_dense[:, 0])\n    assert_array_equal(dense_columns[1], X_dense[:, 2])\n    \n    # Test sparse matrix\n    sparse_columns = list(_iterate_columns(X_sparse, columns=columns))\n    assert_array_equal(sparse_columns[0], X_dense[:, 0])\n    assert_array_equal(sparse_columns[1], X_dense[:, 2])\n\n    # Test dense matrix without specifying columns\n    dense_columns_all = list(_iterate_columns(X_dense))\n    for i in range(X_dense.shape[1]):\n        assert_array_equal(dense_columns_all[i], X_dense[:, i])\n    \n    # Test sparse matrix without specifying columns\n    sparse_columns_all = list(_iterate_columns(X_sparse))\n    for i in range(X_sparse.shape[1]):\n        assert_array_equal(sparse_columns_all[i], X_dense[:, i])\n"], "sample_101": ["def test_pipeline_with_none_step():\n    # Test that a pipeline can handle None steps\n    X = np.array([[1, 2]])\n    y = np.array([1])\n    mult2 = Mult(mult=2)\n    mult3 = Mult(mult=3)\n    \n    pipeline = Pipeline([('m2', mult2), ('none_step', None), ('m3', mult3)])\n    \n    exp = 2 * 3\n    assert_array_equal([[exp]], pipeline.fit_transform(X, y))\n    assert_array_equal([exp], pipeline.fit(X).predict(X))\n    assert_array_equal(X, pipeline.inverse_transform([[exp]]))\n\n    # Check that None step can be replaced with another step\n    pipeline.set_params(none_step=mult3)\n    exp = 2 * 3 * 3\n    assert_array_equal([[exp]], pipeline.fit_transform(X, y))\n    assert_array_equal([exp], pipeline.fit(X).predict(X))\n    assert_array_equal(X, pipeline.inverse_transform([[exp]]))\n\n    # Check that setting a step to None works\n    pipeline.set_params(m3=None)\n    exp = 2\n    assert_array_equal([[exp]], pipeline.fit_transform(X, y))\n    assert_array_equal([exp], pipeline.fit(X).predict(X))\n    assert_array_equal(X, pipeline.inverse_transform([[exp]]))\n", "def test_pipeline_memory_with_intermediate_step():\n    # Test that caching works with intermediate transformers\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        if LooseVersion(joblib_version) < LooseVersion('0.12'):\n            memory = Memory(cachedir=cachedir, verbose=10)\n        else:\n            memory = Memory(location=cachedir, verbose=10)\n        \n        # Transformer + Transformer + SVC\n        transf1 = DummyTransf()\n        transf2 = StandardScaler()\n        clf = SVC(gamma='scale', probability=True, random_state=0)\n        pipe = Pipeline([('transf1', transf1), ('transf2', transf2), ('svc', clf)])\n        cached_pipe = Pipeline([('transf1', transf1), ('transf2', transf2), ('svc', clf)], memory=memory)\n        \n        # First fit\n        cached_pipe.fit(X, y)\n        pipe.fit(X, y)\n        \n        # Check that both pipelines yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X), cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        \n        # Get the time stamp of the transformer in the cached pipeline\n        ts = cached_pipe.named_steps['transf1'].timestamp_\n        \n        # Check that we are reading the cache while fitting a second time\n        cached_pipe.fit(X, y)\n        \n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X), cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_equal(ts, cached_pipe.named_steps['transf1'].timestamp_)\n        \n        # Create a new pipeline with cloned estimators and modified step names\n        transf1_2 = DummyTransf()\n        transf2_2 = StandardScaler()\n        clf_2 = SVC(gamma='scale', probability=True, random_state=0)\n        cached_pipe_2 = Pipeline([('transf1", "def test_pipeline_partial_fit():\n    # Test partial_fit method of pipeline\n    class IncrementalDummyClassifier(BaseEstimator):\n            self.partial_fit_calls = 0\n\n            self.partial_fit_calls += 1\n            return self\n\n            return np.zeros(X.shape[0])\n\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n\n    clf = IncrementalDummyClassifier()\n    pipe = Pipeline([('clf', clf)])\n    \n    for _ in range(3):\n        pipe.partial_fit(X, y, classes=np.unique(y))\n    \n    assert_equal(clf.partial_fit_calls, 3)\n", "def test_pipeline_transform_with_passthrough():\n    # Test whether pipeline handles 'passthrough' correctly in transform\n    iris = load_iris()\n    X = iris.data\n    pca = PCA(n_components=2, svd_solver='full')\n    transformer = Pipeline([('pca', pca), ('passthrough', 'passthrough')])\n\n    # test transform and fit_transform:\n    X_trans = transformer.fit(X).transform(X)\n    X_trans2 = transformer.fit_transform(X)\n    X_trans3 = pca.fit_transform(X)\n    assert_array_almost_equal(X_trans, X_trans2)\n    assert_array_almost_equal(X_trans, X_trans3)\n\n    X_back = transformer.inverse_transform(X_trans)\n    X_back2 = pca.inverse_transform(X_trans)\n    assert_array_almost_equal(X_back, X_back2)\n", "def test_pipeline_with_passthrough():\n    # Test the behavior of 'passthrough' in various positions\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n\n    # Pipeline with passthrough in the middle\n    pipe = Pipeline([\n        ('scaler', StandardScaler()),\n        ('passthrough', 'passthrough'),\n        ('svc', SVC(gamma='scale'))\n    ])\n\n    # Fit and test predict\n    pipe.fit(X, y)\n    predictions = pipe.predict(X)\n    assert predictions.shape == y.shape\n\n    # Pipeline with passthrough at the end\n    pipe = Pipeline([\n        ('scaler', StandardScaler()),\n        ('passthrough', 'passthrough')\n    ])\n\n    # Fit and test transform\n    transformed = pipe.fit_transform(X)\n    assert transformed.shape == X.shape\n\n    # Pipeline with passthrough at the beginning\n    pipe = Pipeline([\n        ('passthrough', 'passthrough'),\n        ('svc', SVC(gamma='scale'))\n    ])\n\n    # Fit and test predict\n    pipe.fit(X, y)\n    predictions = pipe.predict(X)\n    assert predictions.shape == y.shape\n\n    # Check behavior of slice with passthrough\n    pipe = Pipeline([\n        ('scaler', StandardScaler()),\n        ('passthrough', 'passthrough'),\n        ('svc', SVC(gamma='scale'))\n    ])\n    sub_pipe = pipe[:-1]\n    assert len(sub_pipe) == 2\n    assert sub_pipe.steps == [\n        ('scaler', StandardScaler()),\n        ('passthrough', 'passthrough')\n    ]\n"], "sample_108": ["def test_fit_invalid_gamma_value():\n    # Test fitting SVM with an invalid gamma value string\n    clf = svm.SVC(gamma='invalid_string')\n    with pytest.raises(ValueError, match=\"When 'gamma' is a string, it should be either 'scale' or 'auto'. Got 'invalid_string' instead.\"):\n        clf.fit(X, Y)\n\n    clf = svm.SVR(gamma='invalid_string')\n    with pytest.raises(ValueError, match=\"When 'gamma' is a string, it should be either 'scale' or 'auto'. Got 'invalid_string' instead.\"):\n        clf.fit(X, Y)\n", "def test_liblinear_solver_type():\n    # Test _get_liblinear_solver_type function\n\n    # Test logistic regression solvers\n    assert _get_liblinear_solver_type('ovr', 'l1', 'logistic_regression', False) == 6\n    assert _get_liblinear_solver_type('ovr', 'l2', 'logistic_regression', False) == 0\n    assert _get_liblinear_solver_type('ovr', 'l2', 'logistic_regression', True) == 7\n\n    # Test hinge loss solvers\n    assert _get_liblinear_solver_type('ovr', 'l2', 'hinge', True) == 3\n\n    # Test squared hinge loss solvers\n    assert _get_liblinear_solver_type('ovr', 'l1', 'squared_hinge', False) == 5\n    assert _get_liblinear_solver_type('ovr', 'l2', 'squared_hinge', False) == 2\n    assert _get_liblinear_solver_type('ovr', 'l2', 'squared_hinge', True) == 1\n\n    # Test epsilon insensitive loss solvers\n    assert _get_liblinear_solver_type('ovr', 'l2', 'epsilon_insensitive', True) == 13\n\n    # Test squared epsilon insensitive loss solvers\n    assert _get_liblinear_solver_type('ovr', 'l2', 'squared_epsilon_insensitive', False) == 11\n    assert _get_liblinear_solver_type('ovr', 'l2', 'squared_epsilon_insensitive', True) == 12\n\n    # Test crammer singer\n    assert _get_liblinear_solver_type('crammer_singer', 'l2', 'hinge', False) == 4\n\n    # Test invalid configurations\n    with pytest.raises(ValueError, match=\"`multi_class` must be one of `ovr`, `crammer_singer`, got 'invalid_class'\"):\n        _get_liblinear_solver_type('invalid_class', 'l2', 'hinge', False)\n    \n    with pytest.raises(ValueError, match=\"loss='invalid_loss' is not supported\"):\n        _get_liblinear_solver_type('ovr', 'l2', 'invalid_loss', False)\n    \n    with pytest.raises(ValueError, match=\"The combination of penalty='invalid_penalty' and loss='logistic_regression' is not supported\"):\n", "def test_svm_sparse_input():\n    # Test SVM with sparse input\n    X_sparse = sparse.csr_matrix(X)\n    T_sparse = sparse.csr_matrix(T)\n    clf = svm.SVC(kernel='linear').fit(X_sparse, Y)\n    pred = clf.predict(T_sparse)\n    assert_array_equal(pred, true_result)\n    assert sp.issparse(clf.support_vectors_)\n\n    # Test with dense input after fitting with sparse input\n    pred_dense = clf.predict(T)\n    assert_array_equal(pred_dense, true_result)\n\n    # Test with precomputed kernel\n    K_sparse = X_sparse.dot(X_sparse.T)\n    clf = svm.SVC(kernel='precomputed')\n    clf.fit(K_sparse, Y)\n    KT_sparse = T_sparse.dot(X_sparse.T)\n    pred_precomputed = clf.predict(KT_sparse)\n    assert_array_equal(pred_precomputed, true_result)\n", "def test_libsvm_fit_invalid_gamma():\n    # Test that a ValueError is raised if gamma is set to 0\n    with pytest.raises(ValueError, match=\"The gamma value of 0.0 is invalid. Use 'auto' to set gamma to a value of 1 / n_features.\"):\n        clf = svm.SVC(gamma=0)\n        clf.fit(X, Y)\n", "def test_svm_sparse_input():\n    # Test if SVMs can handle sparse input\n    X_sparse = sparse.csr_matrix(X)\n    Y_sparse = np.array(Y)\n\n    # Test sparse input for SVC\n    clf = svm.SVC(kernel='linear').fit(X_sparse, Y_sparse)\n    assert_array_equal(clf.predict(X_sparse), Y_sparse)\n\n    # Test sparse input for NuSVC\n    clf = svm.NuSVC(kernel='linear', nu=0.5).fit(X_sparse, Y_sparse)\n    assert_array_equal(clf.predict(X_sparse), Y_sparse)\n\n    # Test sparse input for SVR\n    clf = svm.SVR(kernel='linear').fit(X_sparse, Y_sparse)\n    assert_array_almost_equal(clf.predict(X_sparse), Y_sparse, decimal=1)\n\n    # Test sparse input for NuSVR\n    clf = svm.NuSVR(kernel='linear', nu=0.5).fit(X_sparse, Y_sparse)\n    assert_array_almost_equal(clf.predict(X_sparse), Y_sparse, decimal=1)\n\n    # Test sparse input for OneClassSVM\n    clf = svm.OneClassSVM(kernel='linear').fit(X_sparse)\n    pred = clf.predict(X_sparse)\n    assert pred.dtype == np.dtype('intp')\n\n    # Regression test for the error raised when using sparse input in precomputed kernel\n    clf = svm.SVC(kernel='precomputed')\n    with pytest.raises(TypeError, match=\"Sparse precomputed kernels are not supported.\"):\n        clf.fit(X_sparse, Y_sparse)\n"], "sample_22": ["    def test_camel_case_to_spaces(self):\n        self.assertEqual(text.camel_case_to_spaces('CamelCase'), 'camel case')\n        self.assertEqual(text.camel_case_to_spaces('camelCaseToSpaces'), 'camel case to spaces')\n        self.assertEqual(text.camel_case_to_spaces('Camel2Case3Test'), 'camel2 case3 test')\n        self.assertEqual(text.camel_case_to_spaces('camel'), 'camel')\n        self.assertEqual(text.camel_case_to_spaces('Camel'), 'camel')\n", "    def test_camel_case_to_spaces(self):\n        self.assertEqual(text.camel_case_to_spaces('CamelCaseString'), 'camel case string')\n        self.assertEqual(text.camel_case_to_spaces('camelCaseString'), 'camel case string')\n        self.assertEqual(text.camel_case_to_spaces('camel'), 'camel')\n        self.assertEqual(text.camel_case_to_spaces('Camel2Case'), 'camel2 case')\n        self.assertEqual(text.camel_case_to_spaces('CamelCaseToSpaces'), 'camel case to spaces')\n        self.assertEqual(text.camel_case_to_spaces(lazystr('LazyCamelCaseString')), 'lazy camel case string')\n", "    def test_capfirst(self):\n        self.assertEqual(text.capfirst('hello'), 'Hello')\n        self.assertEqual(text.capfirst('Hello'), 'Hello')\n        self.assertEqual(text.capfirst(''), '')\n        self.assertEqual(text.capfirst('h'), 'H')\n        self.assertEqual(text.capfirst(lazystr('hello')), 'Hello')\n", "    def test_camel_case_to_spaces(self):\n        self.assertEqual(text.camel_case_to_spaces('CamelCaseTest'), 'camel case test')\n        self.assertEqual(text.camel_case_to_spaces('camelCaseTest'), 'camel case test')\n        self.assertEqual(text.camel_case_to_spaces('CamelcaseTestExample'), 'camelcase test example')\n        self.assertEqual(text.camel_case_to_spaces('CamelCase'), 'camel case')\n        self.assertEqual(text.camel_case_to_spaces('Camel'), 'camel')\n        self.assertEqual(text.camel_case_to_spaces(''), '')\n", "    def test_camel_case_to_spaces(self):\n        self.assertEqual(text.camel_case_to_spaces('CamelCaseExample'), 'camel case example')\n        self.assertEqual(text.camel_case_to_spaces('camelCaseExample'), 'camel case example')\n        self.assertEqual(text.camel_case_to_spaces('CamelCase'), 'camel case')\n        self.assertEqual(text.camel_case_to_spaces('Camel'), 'camel')\n        self.assertEqual(text.camel_case_to_spaces('camel'), 'camel')\n        self.assertEqual(text.camel_case_to_spaces(''), '')\n"], "sample_47": ["    def test_reapply_replacement_migration(self):\n        \"\"\"\n        Tests reapplying a replacement migration to ensure it handles\n        the case where the original migrations were applied, the replacement\n        migration is unapplied, and then reapplied.\n        \"\"\"\n        recorder = MigrationRecorder(connection)\n        # Apply the replaced migrations and the squashed replacement.\n        recorder.record_applied(\"migrations\", \"0001_initial\")\n        recorder.record_applied(\"migrations\", \"0002_second\")\n        recorder.record_applied(\"migrations\", \"0001_squashed_0002\")\n        executor = MigrationExecutor(connection)\n        # Unapply the squashed migration.\n        executor.migrate([(\"migrations\", None)])\n        self.assertNotIn(\n            (\"migrations\", \"0001_squashed_0002\"),\n            recorder.applied_migrations(),\n        )\n        # Reapply the squashed migration.\n        executor.migrate([(\"migrations\", \"0001_squashed_0002\")])\n        self.assertIn(\n            (\"migrations\", \"0001_squashed_0002\"),\n            recorder.applied_migrations(),\n        )\n        # Cleanup\n        executor.migrate([(\"migrations\", None)])\n        self.assertNotIn(\n            (\"migrations\", \"0001_squashed_0002\"),\n            recorder.applied_migrations(),\n        )\n", "    def test_detect_soft_applied_create_model(self):\n        \"\"\"\n        Tests detection of initial migrations already having been applied for CreateModel operations.\n        \"\"\"\n        executor = MigrationExecutor(connection)\n        migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n        # Apply the migration to create the model table\n        executor.migrate([(\"migrations\", \"0001_initial\")], fake=True)\n        self.assertTableExists(\"migrations_author\")\n        # Detect if the migration is considered implicitly applied\n        self.assertIs(executor.detect_soft_applied(None, migration)[0], True)\n        # Cleanup\n        executor.migrate([(\"migrations\", None)], fake=True)\n        self.assertTableNotExists(\"migrations_author\")\n", "    def test_migrate_with_no_operations(self):\n        \"\"\"\n        Tests the behavior when a migration has no operations.\n        \"\"\"\n        executor = MigrationExecutor(connection)\n        # Define a migration with no operations\n        class NoOpMigration(migrations.Migration):\n            operations = []\n\n        # Fake apply the no-op migration\n        executor.loader.graph.add_node((\"migrations\", \"0003_noop\"), NoOpMigration(\"0003_noop\", \"migrations\"))\n        executor.recorder.record_applied(\"migrations\", \"0003_noop\")\n\n        # Verify the migration has been applied\n        applied_migrations = executor.recorder.applied_migrations()\n        self.assertIn((\"migrations\", \"0003_noop\"), applied_migrations)\n\n        # Undo the no-op migration\n        executor.migrate([(\"migrations\", None)])\n\n        # Verify the migration has been unapplied\n        applied_migrations = executor.recorder.applied_migrations()\n        self.assertNotIn((\"migrations\", \"0003_noop\"), applied_migrations)\n", "    def test_apply_migration_exception_handling(self):\n        \"\"\"\n        Tests that an exception during the migration process does not leave the migration partially applied.\n        \"\"\"\n        executor = MigrationExecutor(connection)\n        self.assertTableNotExists(\"migrations_author\")\n        self.assertTableNotExists(\"migrations_book\")\n\n        # Mock the apply_migration method to raise an exception during migration\n        with mock.patch.object(executor, 'apply_migration', side_effect=RuntimeError(\"Failed during migration\")):\n            with self.assertRaises(RuntimeError):\n                executor.migrate([(\"migrations\", \"0001_initial\")])\n        \n        # Ensure that no tables were created due to the exception\n        self.assertTableNotExists(\"migrations_author\")\n        self.assertTableNotExists(\"migrations_book\")\n", "    def test_empty_project_state(self):\n        \"\"\"\n        Test the creation of a project state with and without applied migrations.\n        \"\"\"\n        executor = MigrationExecutor(connection)\n        # Test project state without applied migrations\n        state = executor._create_project_state(with_applied_migrations=False)\n        self.assertEqual(state.real_apps, executor.loader.unmigrated_apps)\n        self.assertNotIn(\"migrations\", state.models)\n\n        # Fake-apply a migration to test project state with applied migrations\n        executor.migrate([(\"migrations\", \"0001_initial\")], fake=True)\n        state_with_migrations = executor._create_project_state(with_applied_migrations=True)\n        self.assertIn(\"migrations\", state_with_migrations.real_apps)\n        self.assertIn((\"migrations\", \"author\"), state_with_migrations.models)\n\n        # Clean up by removing the fake-applied migration\n        executor.migrate([(\"migrations\", None)], fake=True)\n"], "sample_61": ["    def test_format_edge_cases(self):\n        # Test very small positive float number\n        self.assertEqual(nformat(1e-50, \".\", decimal_pos=50), \"0.00000000000000000000000000000000000000000000000000\")\n        \n        # Test very large integer\n        self.assertEqual(nformat(10**100, \".\"), \"10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\")\n        \n        # Test Decimal with high precision\n        self.assertEqual(nformat(Decimal(\"1.2345678901234567890123456789\"), \".\", decimal_pos=28), \"1.2345678901234567890123456789\")\n        \n        # Test float with scientific notation and grouping\n        self.assertEqual(\n            nformat(1.23e20, \".\", grouping=3, thousand_sep=\",\", force_grouping=True),\n            \"1,23e+20\"\n        )\n        \n        # Test negative float with scientific notation\n        self.assertEqual(nformat(-1.23e-20, \".\", decimal_pos=22), \"-0.0000000000000000000123\")\n", "    def test_non_numeric_string(self):\n        self.assertEqual(nformat(\"abcd\", \".\"), \"abcd\")\n        self.assertEqual(nformat(\"1234abcd\", \".\"), \"1234abcd\")\n        self.assertEqual(nformat(\"abcd1234\", \".\", decimal_pos=2), \"abcd1234\")\n        self.assertEqual(nformat(\"1234abcd\", \".\", grouping=2, thousand_sep=\",\"), \"1234abcd\")\n        self.assertEqual(\n            nformat(\"1234abcd\", \".\", grouping=2, thousand_sep=\",\", force_grouping=True),\n            \"12,34abcd\",\n        )\n", "    def test_non_standard_grouping(self):\n        # Test non-standard grouping sequence\n        self.assertEqual(\n            nformat(1234567, \".\", grouping=(3, 2, 0), thousand_sep=\",\", force_grouping=True),\n            \"12,34,567\"\n        )\n        self.assertEqual(\n            nformat(12345678, \".\", grouping=(4, 3, 2), thousand_sep=\".\", force_grouping=True),\n            \"1.234.567.8\"\n        )\n", "    def test_edge_cases(self):\n        # Test a number with more than 200 digits to ensure scientific notation is used.\n        large_number = Decimal('1' + '0' * 201)\n        self.assertEqual(\n            nformat(large_number, \".\", decimal_pos=3),\n            \"1.000e+201\"\n        )\n        \n        # Test grouping with non-uniform intervals\n        self.assertEqual(\n            nformat(1234567890, \".\", grouping=(3, 2, 1), thousand_sep=\",\", force_grouping=True),\n            \"1,23,45,67,890\"\n        )\n        \n        # Test number with no decimal part but with decimal_pos specified\n        self.assertEqual(\n            nformat(1234.0, \".\", decimal_pos=5),\n            \"1234.00000\"\n        )\n\n        # Test number with decimal part shorter than decimal_pos\n        self.assertEqual(\n            nformat(1234.56, \".\", decimal_pos=5),\n            \"1234.56000\"\n        )\n\n        # Test a negative number with more than 200 digits to ensure scientific notation is used.\n        large_negative_number = Decimal('-1' + '0' * 201)\n        self.assertEqual(\n            nformat(large_negative_number, \".\", decimal_pos=3),\n            \"-1.000e+201\"\n        )\n        \n        # Test non-integer grouping\n        self.assertEqual(\n            nformat(Decimal(\"1234567.89\"), \".\", grouping=3.5, thousand_sep=\",\", force_grouping=True),\n            \"1,234,567.89\"\n        )\n        \n        # Test a float with 'e' in the string representation\n        self.assertEqual(\n            nformat(1e20, \".\", decimal_pos=2),\n            \"1.00e+20\"\n        )\n        \n        # Test a negative float with 'e' in the string representation\n        self.assertEqual(\n            nformat(-1e20, \".\", decimal_pos=2),\n            \"-1.00e+20\"\n        )\n", "    def test_invalid_input(self):\n        with self.assertRaises(TypeError):\n            nformat([], \".\")\n        with self.assertRaises(TypeError):\n            nformat({}, \".\")\n        with self.assertRaises(TypeError):\n            nformat(set(), \".\")\n        with self.assertRaises(ValueError):\n            nformat(\"invalid\", \".\")\n"], "sample_3": ["def test_separability_matrix_edge_cases():\n    # Test with single input and multiple outputs\n    @custom_model\n        return x, x**2\n\n    assert_allclose(separability_matrix(model_1toN()), np.array([[True], [True]]))\n\n    # Test with multiple inputs and single output\n    @custom_model\n        return x + y\n\n    assert_allclose(separability_matrix(model_Nto1()), np.array([[True, True]]))\n\n    # Test with model having no inputs and outputs\n    @custom_model\n        return np.array([])\n\n    assert_allclose(separability_matrix(model_empty()), np.array([[]], dtype=bool))\n", "def test_compute_n_outputs():\n    # Models as inputs\n    result = _compute_n_outputs(sh1, scl1)\n    assert result == 2\n\n    result = _compute_n_outputs(rot, p2)\n    assert result == 2\n\n    # ndarray as inputs\n    left = np.array([[1, 0], [0, 1]])\n    right = np.array([[1, 1], [1, 0]])\n    result = _compute_n_outputs(left, right)\n    assert result == 4\n\n    # Mixed inputs\n    result = _compute_n_outputs(sh1, right)\n    assert result == 3\n\n    result = _compute_n_outputs(left, rot)\n    assert result == 4\n", "def test_separability_matrix():\n    # Test with simple models\n    result = separability_matrix(sh1)\n    assert_allclose(result, np.array([[True]]))\n\n    result = separability_matrix(rot)\n    assert_allclose(result, np.array([[True, True], [True, True]]))\n\n    result = separability_matrix(map3)\n    assert_allclose(result, np.array([[True], [True]]))\n\n    # Test with compound models\n    result = separability_matrix(sh1 & sh2 | scl1 & scl2)\n    assert_allclose(result, np.array([[True, False], [False, True]]))\n\n    result = separability_matrix(rot | sh1 & sh2)\n    assert_allclose(result, np.array([[True, True], [True, True]]))\n\n    result = separability_matrix(map2 | rot & scl1)\n    assert_allclose(result, np.array([[True, False], [True, False], [False, True]]))\n\n    # Test with a more complex compound model\n    result = separability_matrix(sh1 & sh2 | map2 | rot & scl1)\n    assert_allclose(result, np.array([[True, False], [True, False], [False, True]]))\n\n    # Test edge case with n_inputs == 1 and n_outputs > 1\n    simple_model = models.Identity(2)\n    result = separability_matrix(simple_model)\n    assert_allclose(result, np.array([[True], [True]]))\n", "def test_separability_matrix():\n    result = separability_matrix(sh1 & sh2 | scl1 & scl2)\n    expected = np.array([[True, False], [False, True]])\n    assert_allclose(result, expected)\n\n    result = separability_matrix(sh1 & sh2 | rot)\n    expected = np.array([[True, True], [True, True]])\n    assert_allclose(result, expected)\n\n    result = separability_matrix(sh1 & sh2 | Mapping([0, 1, 0, 1]) | p2 & p22)\n    expected = np.array([[True, True], [True, True]])\n    assert_allclose(result, expected)\n\n    result = separability_matrix(sh1 & sh2 | Mapping([0, 1, 0, 1]))\n    expected = np.array([[True, False], [False, True], [True, False], [False, True]])\n    assert_allclose(result, expected)\n\n    result = separability_matrix(Mapping([0, 1]) & Mapping([1, 0]))\n    expected = np.array([[True, False], [False, True]])\n    assert_allclose(result, expected)\n", "def test_separability_matrix():\n    result = separability_matrix(sh1 & sh2 | rot | scl1 & scl2)\n    expected = np.array([[True, True, False, False],\n                         [True, True, False, False],\n                         [False, False, True, False],\n                         [False, False, False, True]])\n    assert_allclose(result, expected)\n\n    result = separability_matrix(p1 & p2)\n    expected = np.array([[True, False], [False, True]])\n    assert_allclose(result, expected)\n\n    result = separability_matrix(map1 | p1 & p2)\n    expected = np.array([[True, True], [True, True], [False, False]])\n    assert_allclose(result, expected)\n\n    with pytest.raises(ModelDefinitionError, match=r\"Models cannot be combined with the \\\"|\\\" operator; .*\"):\n        separability_matrix(sh1 | map1)\n"], "sample_107": ["def test_logistic_loss_multinomial():\n    # Test the calculation of the multinomial logistic loss.\n    X, y = make_classification(n_samples=100, n_features=10, n_classes=3, random_state=42)\n    Y = LabelBinarizer().fit_transform(y)\n    w = np.random.randn(3 * 10)\n    alpha = 1.0\n    sample_weight = np.ones(X.shape[0])\n\n    loss, _, _ = _multinomial_loss(w, X, Y, alpha, sample_weight)\n    expected_loss = log_loss(y, np.exp(_multinomial_loss(w, X, Y, alpha, sample_weight)[1]))\n\n    assert_almost_equal(loss, expected_loss, decimal=5)\n", "def test_logistic_loss():\n    X_ref, y = make_classification(n_samples=20, random_state=0)\n    n_features = X_ref.shape[1]\n\n    X_sp = X_ref.copy()\n    X_sp[X_sp < .1] = 0\n    X_sp = sp.csr_matrix(X_sp)\n    for X in (X_ref, X_sp):\n        w = np.zeros(n_features)\n\n        # Compute logistic loss without regularization\n        loss = _logistic_loss(w, X, y, alpha=0.)\n        expected_loss = log_loss(y, expit(np.dot(X.toarray() if sparse.issparse(X) else X, w)))\n        assert_almost_equal(loss, expected_loss, decimal=6)\n\n        # Compute logistic loss with regularization\n        alpha = 1.0\n        loss_reg = _logistic_loss(w, X, y, alpha=alpha)\n        expected_loss_reg = expected_loss + 0.5 * alpha * np.dot(w, w)\n        assert_almost_equal(loss_reg, expected_loss_reg, decimal=6)\n", "def test_multinomial_loss_and_grad():\n    # Test the _multinomial_loss_grad function\n    rng = np.random.RandomState(0)\n    n_samples, n_features, n_classes = 100, 5, 3\n    X = rng.randn(n_samples, n_features)\n    w = rng.rand(n_classes, n_features)\n    Y = np.zeros((n_samples, n_classes))\n    ind = np.argmax(np.dot(X, w.T), axis=1)\n    Y[range(0, n_samples), ind] = 1\n    w = w.ravel()\n    sample_weight = np.ones(n_samples)\n    \n    # Check the loss and gradient calculation\n    loss, grad, p = _multinomial_loss_grad(w, X, Y, alpha=1., sample_weight=sample_weight)\n    expected_loss, expected_probabilities, _ = _multinomial_loss(w, X, Y, alpha=1., sample_weight=sample_weight)\n\n    assert_almost_equal(loss, expected_loss, decimal=5)\n    assert_array_almost_equal(p, expected_probabilities, decimal=5)\n\n    # Check the gradient with finite differences\n    approx_grad = optimize.approx_fprime(\n        w, lambda w: _multinomial_loss(w, X, Y, alpha=1., sample_weight=sample_weight)[0], 1e-5\n    )\n    assert_array_almost_equal(grad, approx_grad, decimal=2)\n", "def test_logistic_loss():\n    # Test logistic loss function with and without sample weights\n    X, y = make_classification(n_samples=20, n_features=10, random_state=0)\n    w = np.zeros(X.shape[1])\n    alpha = 1.0\n\n    # Compute logistic loss without sample weights\n    loss_no_weights = _logistic_loss(w, X, y, alpha)\n\n    # Compute logistic loss with sample weights\n    sample_weight = np.random.rand(X.shape[0])\n    loss_with_weights = _logistic_loss(w, X, y, alpha, sample_weight=sample_weight)\n\n    # Ensure that loss with weights is different from loss without weights\n    assert loss_no_weights != loss_with_weights, \\\n        \"Loss should be different when using sample weights\"\n\n    # Test to ensure _logistic_loss function behaves as expected\n    assert loss_no_weights > 0, \"Loss should be positive\"\n    assert loss_with_weights > 0, \"Loss should be positive\"\n\n    # Also check that loss with unit weights is same as without weights\n    unit_weight_loss = _logistic_loss(w, X, y, alpha, sample_weight=np.ones(X.shape[0]))\n    assert_almost_equal(loss_no_weights, unit_weight_loss, decimal=6,\n                        err_msg=\"Loss with unit weights should be equal to loss without weights\")\n", "def test_logistic_regression_path_intercept():\n    # Test that the logistic_regression_path function correctly handles the intercept\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = [1] * 100 + [-1] * 100\n    Cs = np.logspace(-4, 4, 10)\n\n    coefs, _, _ = _logistic_regression_path(\n        X, y, Cs=Cs, fit_intercept=True, tol=1e-5, solver='lbfgs', max_iter=1000, multi_class='ovr', random_state=0)\n    \n    for i, C in enumerate(Cs):\n        lr = LogisticRegression(C=C, fit_intercept=True, tol=1e-5, solver='lbfgs', multi_class='ovr', random_state=0, max_iter=1000)\n        lr.fit(X, y)\n        lr_coef = np.concatenate([lr.coef_.ravel(), lr.intercept_])\n        assert_array_almost_equal(lr_coef, coefs[i], decimal=4)\n"], "sample_30": ["    def test_change_model_permission(self):\n        \"\"\"\n        Test that a user with only change permission on the model can still change the model.\n        \"\"\"\n        user = User.objects.create_user('change_user', password='password', is_staff=True)\n        permission = Permission.objects.get(codename='change_holder2', content_type=ContentType.objects.get_for_model(Holder2))\n        user.user_permissions.add(permission)\n        self.client.force_login(user)\n\n        holder = Holder2.objects.create(dummy=13)\n        response = self.client.get(reverse('admin:admin_inlines_holder2_change', args=(holder.id,)))\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, 'Change Holder2')\n        self.assertNotContains(response, 'Add another Inner2')\n\n        response = self.client.post(reverse('admin:admin_inlines_holder2_change', args=(holder.id,)), {\n            'dummy': 42,\n        })\n        self.assertEqual(response.status_code, 302)\n        holder.refresh_from_db()\n        self.assertEqual(holder.dummy, 42)\n", "    def test_inline_foreignkey_widget_wrapper(self):\n        \"\"\"\n        Ensure that RelatedFieldWidgetWrapper is correctly applied to ForeignKey fields\n        in inlines.\n        \"\"\"\n        holder = Holder.objects.create(dummy=42)\n        response = self.client.get(reverse('admin:admin_inlines_holder_change', args=(holder.pk,)))\n        inline_admin_formset = response.context['inline_admin_formsets'][0]\n\n        # Ensure formfield widget is wrapped with RelatedFieldWidgetWrapper\n        for inline_admin_form in inline_admin_formset:\n            for fieldset in inline_admin_form:\n                for line in fieldset:\n                    field = line.field['field']\n                    if isinstance(field, forms.ModelChoiceField):\n                        self.assertIsInstance(field.widget, widgets.RelatedFieldWidgetWrapper)\n                        \n        # Ensure the correct attributes are passed to the widget wrapper\n        expected_html = (\n            '<a href=\"/admin/admin_inlines/inner/add/\" class=\"add-another\" id=\"add_id_inner_set-0-holder\">'\n            '<img src=\"/static/admin/img/icon-addlink.svg\" width=\"10\" height=\"10\" alt=\"Add another\"/></a>'\n        )\n        self.assertContains(response, expected_html)\n", "    def test_formfield_for_dbfield(self):\n        \"\"\"\n        Test formfield_for_dbfield to ensure it returns the correct form field\n        instance for various database field types.\n        \"\"\"\n        class TestModel(models.Model):\n            char_field = models.CharField(max_length=100)\n            int_field = models.IntegerField()\n            foreign_key_field = models.ForeignKey(Author, on_delete=models.CASCADE)\n            many_to_many_field = models.ManyToManyField(Book)\n            choice_field = models.CharField(max_length=100, choices=(('1', 'One'), ('2', 'Two')))\n\n        model_admin = ModelAdmin(TestModel, admin_site)\n        request = self.factory.get(reverse('admin:index'))\n\n        # Test CharField\n        form_field = model_admin.formfield_for_dbfield(TestModel._meta.get_field('char_field'), request)\n        self.assertIsInstance(form_field, forms.CharField)\n\n        # Test IntegerField\n        form_field = model_admin.formfield_for_dbfield(TestModel._meta.get_field('int_field'), request)\n        self.assertIsInstance(form_field, forms.IntegerField)\n\n        # Test ForeignKey\n        form_field = model_admin.formfield_for_dbfield(TestModel._meta.get_field('foreign_key_field'), request)\n        self.assertIsInstance(form_field, forms.ModelChoiceField)\n\n        # Test ManyToManyField\n        form_field = model_admin.formfield_for_dbfield(TestModel._meta.get_field('many_to_many_field'), request)\n        self.assertIsInstance(form_field, forms.ModelMultipleChoiceField)\n\n        # Test ChoiceField with RadioSelect widget\n        model_admin.radio_fields = {'choice_field': HORIZONTAL}\n        form_field = model_admin.formfield_for_dbfield(TestModel._meta.get_field('choice_field'), request)\n        self.assertIsInstance(form_field.widget, widgets.AdminRadioSelect)\n", "    def test_model_admin_get_actions(self):\n        \"\"\"\n        Test ModelAdmin get_actions method.\n        \"\"\"\n        class TestModelAdmin(ModelAdmin):\n            model = Book\n            actions = ['test_action']\n\n                pass\n\n        modeladmin = TestModelAdmin(Book, admin_site)\n        request = self.factory.get(reverse('admin:admin_inlines_book_changelist'))\n        request.user = self.superuser\n\n        actions = modeladmin.get_actions(request)\n        self.assertIn('test_action', actions)\n", "    def test_custom_formfield_overrides(self):\n        \"\"\"\n        Ensure that formfield_overrides in ModelAdmin works correctly.\n        \"\"\"\n        class CustomModelAdmin(ModelAdmin):\n            formfield_overrides = {\n                models.CharField: {'widget': forms.Textarea(attrs={'rows': 2, 'cols': 20})}\n            }\n\n        site = admin_site\n        model_admin = CustomModelAdmin(Author, site)\n        request = self.factory.get(reverse('admin:admin_inlines_author_add'))\n        request.user = self.superuser\n        Form = model_admin.get_form(request)\n        form = Form()\n        self.assertIsInstance(form.fields['name'].widget, forms.Textarea)\n        self.assertEqual(form.fields['name'].widget.attrs, {'rows': 2, 'cols': 20})\n"], "sample_85": ["def test_colored_level_formatter(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        from _pytest.logging import ColoredLevelFormatter\n        from _pytest.config import create_terminal_writer\n\n            terminal_writer = create_terminal_writer(None)\n            formatter = ColoredLevelFormatter(terminal_writer, '%(levelname)s: %(message)s')\n            handler = logging.StreamHandler()\n            handler.setFormatter(formatter)\n            logger = logging.getLogger(__name__)\n            logger.addHandler(handler)\n            logger.setLevel(logging.DEBUG)\n\n            logger.debug('debug message')\n            logger.info('info message')\n            logger.warning('warning message')\n            logger.error('error message')\n            logger.critical('critical message')\n\n            log_output = handler.stream.getvalue()\n            assert 'DEBUG: debug message' in log_output\n            assert 'INFO: info message' in log_output\n            assert 'WARNING: warning message' in log_output\n            assert 'ERROR: error message' in log_output\n            assert 'CRITICAL: critical message' in log_output\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"* 1 passed in *\"])\n", "def test_colored_level_formatter(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        from _pytest.logging import ColoredLevelFormatter\n        from _pytest.config import create_terminal_writer\n\n            terminal_writer = create_terminal_writer(request.config)\n            formatter = ColoredLevelFormatter(terminal_writer, \"%(levelname)s: %(message)s\")\n            logger = logging.getLogger(\"test_logger\")\n            handler = logging.StreamHandler()\n            handler.setFormatter(formatter)\n            logger.addHandler(handler)\n            logger.setLevel(logging.DEBUG)\n            logger.debug(\"debug message\")\n            logger.info(\"info message\")\n            logger.warning(\"warning message\")\n            logger.error(\"error message\")\n            logger.critical(\"critical message\")\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\n        \"*DEBUG: debug message*\",\n        \"*INFO: info message*\",\n        \"*WARNING: warning message*\",\n        \"*ERROR: error message*\",\n        \"*CRITICAL: critical message*\",\n    ])\n", "def test_catching_logs_context_manager(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        from _pytest.logging import catching_logs\n\n            logger = logging.getLogger(\"test\")\n            stream_handler = logging.StreamHandler()\n            stream_handler.setLevel(logging.DEBUG)\n            with catching_logs(stream_handler) as handler:\n                logger.debug(\"debug log\")\n                logger.info(\"info log\")\n                logger.warning(\"warning log\")\n                logger.error(\"error log\")\n            assert len(handler.stream.getvalue().splitlines()) == 4\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*test_catching_logs*\"])\n", "def test_colored_level_formatter(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        from _pytest.logging import ColoredLevelFormatter\n        from _pytest.config import create_terminal_writer\n\n            terminal_writer = create_terminal_writer()\n            formatter = ColoredLevelFormatter(\n                terminal_writer,\n                \"%(levelname)s %(message)s\",\n                datefmt=None\n            )\n            handler = logging.StreamHandler()\n            handler.setFormatter(formatter)\n            logger = logging.getLogger(\"testlogger\")\n            logger.addHandler(handler)\n\n            with caplog.at_level(logging.INFO):\n                logger.info(\"info message\")\n                logger.error(\"error message\")\n                logger.warning(\"warning message\")\n\n            test_colored_formatter()\n            assert len(caplog.records) == 3\n            assert caplog.records[0].levelname == \"INFO\"\n            assert caplog.records[1].levelname == \"ERROR\"\n            assert caplog.records[2].levelname == \"WARNING\"\n            assert caplog.text.endswith(\"INFO info message\\nERROR error message\\nWARNING warning message\\n\")\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"* 2 passed in *\"])\n", "def test_custom_formatter(testdir):\n    testdir.makeconftest(\n        \"\"\"\n        import logging\n        class CustomFormatter(logging.Formatter):\n                return \"CUSTOM: \" + super(CustomFormatter, self).format(record)\n\n            logging_plugin = config.pluginmanager.get_plugin(\"logging-plugin\")\n            custom_formatter = CustomFormatter('%(asctime)s - %(levelname)s - %(message)s')\n            logging_plugin.log_cli_handler.setFormatter(custom_formatter)\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n        logger = logging.getLogger(__name__)\n\n            logger.info('custom format test')\n            assert True\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--log-cli-level=INFO\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*-- live log call --*\",\n            \"CUSTOM: *INFO*custom format test*\"\n        ]\n    )\n    assert result.ret == 0\n"], "sample_54": ["    def test_avoid_wrapping(self):\n        tests = (\n            (\"Hello world\", \"Hello\\xa0world\"),\n            (\"No wrapping allowed\", \"No\\xa0wrapping\\xa0allowed\"),\n            (\"This is a test\", \"This\\xa0is\\xa0a\\xa0test\"),\n            (\"Django utils\", \"Django\\xa0utils\"),\n            (\"Keep spaces\", \"Keep\\xa0spaces\"),\n        )\n        for value, output in tests:\n            with self.subTest(value=value):\n                self.assertEqual(avoid_wrapping(value), output)\n", "    def test_avoid_wrapping(self):\n        tests = (\n            (\"This is a test\", \"This\\xa0is\\xa0a\\xa0test\"),\n            (\"No wrapping here\", \"No\\xa0wrapping\\xa0here\"),\n            (\"Another example\", \"Another\\xa0example\"),\n            (lazystr(\"Lazy evaluation\"), \"Lazy\\xa0evaluation\"),\n        )\n        for value, output in tests:\n            with self.subTest(value=value):\n                self.assertEqual(avoid_wrapping(value), output)\n", "    def test_avoid_wrapping(self):\n        items = (\n            (\"hello world\", \"hello\\xa0world\"),\n            (\"a b c\", \"a\\xa0b\\xa0c\"),\n            (\"multiple  spaces\", \"multiple\\xa0\\xa0spaces\"),\n            (\"  leading and trailing  \", \"\\xa0\\xa0leading\\xa0and\\xa0trailing\\xa0\\xa0\"),\n        )\n        for value, output in items:\n            with self.subTest(value=value, output=output):\n                self.check_output(avoid_wrapping, value, output)\n                self.check_output(avoid_wrapping, lazystr(value), output)\n", "    def test_avoid_wrapping(self):\n        tests = (\n            (\"This is a test\", \"This\\xa0is\\xa0a\\xa0test\"),\n            (\"Avoid text wrapping\", \"Avoid\\xa0text\\xa0wrapping\"),\n            (\"Non-breaking space\", \"Non-breaking\\xa0space\"),\n            (\"Another test case\", \"Another\\xa0test\\xa0case\"),\n        )\n        for value, output in tests:\n            with self.subTest(value=value):\n                self.check_output(avoid_wrapping, value, output)\n", "    def test_avoid_wrapping(self):\n        tests = (\n            (\"Hello world\", \"Hello\\xa0world\"),\n            (\"This is a test\", \"This\\xa0is\\xa0a\\xa0test\"),\n            (\"Django utils\", \"Django\\xa0utils\"),\n        )\n        for value, output in tests:\n            with self.subTest(value=value):\n                self.assertEqual(avoid_wrapping(value), output)\n"], "sample_100": ["def test_ordinal_encoder_handle_unknown():\n    X = np.array([['a', 'b'], ['c', 'd']])\n    X2 = np.array([['e', 'f'], ['a', 'b']])\n\n    # Test that ordinal encoder raises error for unknown categories\n    enc = OrdinalEncoder()\n    enc.fit(X)\n    with pytest.raises(ValueError, match=\"Found unknown categories\"):\n        enc.transform(X2)\n\n    # Test the ignore option, unknown categories should be set to -1\n    class OrdinalEncoderIgnore(OrdinalEncoder):\n            X_int, X_mask = super()._transform(X, handle_unknown='ignore')\n            X_int[~X_mask] = -1\n            return X_int, X_mask\n\n    enc = OrdinalEncoderIgnore(categories='auto')\n    enc.fit(X)\n    X_trans = enc.transform(X2)\n    assert_array_equal(X_trans, [[-1, -1], [0, 0]])\n", "def test_ordinal_encoder_handle_unknown():\n    X = np.array([['cat1', 'cat2'], ['cat3', 'cat1']], dtype=object)\n    X2 = np.array([['cat1', 'cat4'], ['cat2', 'cat1']], dtype=object)\n\n    # Test that ordinal encoder raises error for unknown features present during transform\n    enc = OrdinalEncoder()\n    enc.fit(X)\n    with pytest.raises(ValueError, match=\"Found unknown categories\"):\n        enc.transform(X2)\n\n    # Test the ignore option, ignores unknown features\n    enc = OrdinalEncoder(categories=[['cat1', 'cat2', 'cat3']], dtype=np.float64)\n    enc.fit(X)\n    enc.transform(X2)  # should not raise\n\n    # Raise error if handle_unknown is neither 'error' nor 'ignore'\n    enc = OrdinalEncoder(categories=[['cat1', 'cat2', 'cat3']], dtype=np.float64)\n    with pytest.raises(ValueError, match=\"Found unknown categories\"):\n        enc.transform(X2)\n", "def test_one_hot_encoder_inverse_mixed():\n    # Test inverse_transform with mixed data types\n    X = [['abc', 2, 55.0], ['def', 1, 44.1], ['ghi', 3, 33.3]]\n    enc = OneHotEncoder(sparse=False)\n    X_tr = enc.fit_transform(X)\n    exp = np.array(X, dtype=object)\n    assert_array_equal(enc.inverse_transform(X_tr), exp)\n\n    # Test inverse_transform with specified categories and mixed data types\n    enc = OneHotEncoder(sparse=False, categories=[['abc', 'def', 'ghi'], [1, 2, 3], [33.3, 44.1, 55.0]])\n    X_tr = enc.fit_transform(X)\n    assert_array_equal(enc.inverse_transform(X_tr), exp)\n    \n    # Test inverse_transform with unknown categories and mixed data types\n    X_unknown = [['xyz', 4, 66.6], ['abc', 1, 55.0]]\n    enc = OneHotEncoder(sparse=False, handle_unknown='ignore', categories=[['abc', 'def', 'ghi'], [1, 2, 3], [33.3, 44.1, 55.0]])\n    X_tr = enc.fit_transform(X)\n    exp = np.array([['xyz', None, None], ['abc', 1, 55.0]], dtype=object)\n    assert_array_equal(enc.inverse_transform(enc.transform(X_unknown)), exp)\n", "def test_one_hot_encoder_fit_transform_array():\n    # Test OneHotEncoder fit_transform with a plain list of categories\n    X = [['Male', 'Tall'], ['Female', 'Short'], ['Male', 'Short']]\n    enc = OneHotEncoder()\n    X_trans = enc.fit_transform(X).toarray()\n    \n    # Expected transformation\n    expected = np.array([[0., 1., 1., 0.],\n                         [1., 0., 0., 1.],\n                         [0., 1., 0., 1.]])\n    \n    assert_equal(X_trans.shape, (3, 4))\n    assert_array_equal(X_trans, expected)\n    assert_array_equal(enc.categories_, [np.array(['Female', 'Male'], dtype=object),\n                                         np.array(['Short', 'Tall'], dtype=object)])\n", "def test_one_hot_encoder_inverse_with_unknown():\n    # Test the inverse_transform method when handle_unknown='ignore'\n    X = [['apple', 1], ['banana', 2], ['apple', 3]]\n    enc = OneHotEncoder(handle_unknown='ignore')\n    enc.fit(X)\n    \n    # Transform with an unknown category\n    X_transformed = enc.transform([['apple', 1], ['banana', 4], ['cherry', 2]]).toarray()\n    expected_transformed = np.array([\n        [1., 0., 1., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 0., 1., 0.]\n    ])\n    \n    # Verify the transformation result\n    assert_array_equal(X_transformed, expected_transformed)\n    \n    # Perform inverse transform and verify the result\n    X_inversed = enc.inverse_transform(X_transformed)\n    expected_inversed = np.array([\n        ['apple', 1],\n        ['banana', None],\n        [None, 2]\n    ], dtype=object)\n    \n    assert_array_equal(X_inversed, expected_inversed)\n"], "sample_29": ["    def test_query_get_compiler(self):\n        query = Query(Company)\n        compiler = query.get_compiler(using='default')\n        self.assertEqual(compiler.using, 'default')\n        self.assertEqual(compiler.query, query)\n        self.assertEqual(compiler.connection, connections['default'])\n", "    def setUp(self):\n        self.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        self.example_inc = Company.objects.create(\n            name=\"Example Inc.\", num_employees=2300, num_chairs=5, ceo=self.max\n        )\n", "    def setUpTestData(cls):\n        cls.example_inc = Company.objects.create(\n            name=\"Example Inc.\", num_employees=2300, num_chairs=5,\n            ceo=Employee.objects.create(firstname=\"Joe\", lastname=\"Smith\", salary=10)\n        )\n        cls.foobar_ltd = Company.objects.create(\n            name=\"Foobar Ltd.\", num_employees=3, num_chairs=4, based_in_eu=True,\n            ceo=Employee.objects.create(firstname=\"Frank\", lastname=\"Meyer\", salary=20)\n        )\n        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.gmbh = Company.objects.create(name='Test GmbH', num_employees=32, num_chairs=1, ceo=cls.max)\n", "    def setUpTestData(cls):\n        cls.employee_joe = Employee.objects.create(firstname=\"Joe\", lastname=\"Smith\", salary=10)\n        cls.employee_frank = Employee.objects.create(firstname=\"Frank\", lastname=\"Meyer\", salary=20)\n        cls.company_example_inc = Company.objects.create(\n            name=\"Example Inc.\", num_employees=2300, num_chairs=5, ceo=cls.employee_joe\n        )\n        cls.company_foobar_ltd = Company.objects.create(\n            name=\"Foobar Ltd.\", num_employees=3, num_chairs=4, based_in_eu=True, ceo=cls.employee_frank\n        )\n", "    def setUpTestData(cls):\n        cls.example_inc = Company.objects.create(\n            name=\"Example Inc.\", num_employees=2300, num_chairs=5,\n            ceo=Employee.objects.create(firstname=\"Joe\", lastname=\"Smith\", salary=10)\n        )\n        cls.raw_query = RawQuery(\"SELECT * FROM expressions_company WHERE name = %s\", 'default', params=(\"Example Inc.\",))\n"], "sample_42": ["    def test_serialize_functools_lru_cache(self):\n            return x + 1\n\n        cached_function = functools.lru_cache(maxsize=32)(sample_function)\n\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize function'):\n            self.serialize_round_trip(cached_function)\n\n        cached_function_with_name = functools.update_wrapper(\n            functools.lru_cache(maxsize=32)(sample_function),\n            sample_function,\n        )\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize function'):\n            self.serialize_round_trip(cached_function_with_name)\n", "    def test_serialize_function_type(self):\n        # Test serializing a function type (non lambda)\n            return \"test\"\n\n        self.assertSerializedResultEqual(\n            test_func,\n            (\"migrations.test_writer.test_func\", {'import migrations.test_writer'}),\n        )\n        self.serialize_round_trip(test_func)\n\n        # Test serializing a lambda (should raise ValueError)\n        with self.assertRaisesMessage(ValueError, 'Cannot serialize function: lambda'):\n            self.assertSerializedEqual(lambda x: x + 1)\n", "    def test_serialize_deconstructable_object(self):\n        class CustomDeconstructable:\n                return (\n                    'migrations.test_writer.CustomDeconstructable',\n                    [],\n                    {'arg1': 'value1', 'arg2': 2},\n                )\n\n        obj = CustomDeconstructable()\n        self.assertSerializedResultEqual(\n            obj,\n            (\n                \"migrations.test_writer.CustomDeconstructable(arg1='value1', arg2=2)\",\n                {'import migrations.test_writer'},\n            )\n        )\n        self.serialize_round_trip(obj)\n", "    def test_serialize_deconstructable(self):\n        instance = DeconstructibleInstances()\n        self.assertSerializedResultEqual(\n            instance,\n            (\n                \"migrations.test_writer.DeconstructibleInstances()\",\n                {'import migrations.test_writer'},\n            )\n        )\n", "    def test_serialize_dictionary(self):\n        value = {\"key1\": \"value1\", \"key2\": 2, \"key3\": [1, 2, 3], \"key4\": {\"nested_key\": \"nested_value\"}}\n        self.assertSerializedEqual(value)\n        expected = (\n            \"{'key1': 'value1', 'key2': 2, 'key3': [1, 2, 3], 'key4': {'nested_key': 'nested_value'}}\",\n            set()\n        )\n        self.assertSerializedResultEqual(value, expected)\n"], "sample_56": ["    def test_template_tags_same_library_in_multiple_templates(self):\n        with self.settings(\n            TEMPLATES=[\n                self.get_settings(\n                    \"same_tags\", \"same_tags_app_1.templatetags.same_tags\"\n                ),\n                self.get_settings(\n                    \"same_tags\", \"same_tags_app_1.templatetags.same_tags\"\n                ),\n                self.get_settings(\n                    \"other_tags\", \"same_tags_app_2.templatetags.other_tags\"\n                ),\n            ]\n        ):\n            self.assertEqual(\n                check_for_template_tags_with_the_same_name(None),\n                [\n                    Error(\n                        E003.msg.format(\n                            \"'same_tags'\",\n                            \"'check_framework.template_test_apps.same_tags_app_1.\"\n                            \"templatetags.same_tags'\",\n                        ),\n                        id=E003.id,\n                    )\n                ],\n            )\n", "    def test_no_options_key_in_template(self):\n        TEMPLATES = [\n            {\n                \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n                \"APP_DIRS\": True,\n                # No OPTIONS key provided\n            },\n        ]\n        with self.settings(TEMPLATES=TEMPLATES):\n            self.assertEqual(check_setting_app_dirs_loaders(None), [])\n", "    def test_string_if_invalid_is_empty_string(self):\n        TEMPLATES = deepcopy(self.TEMPLATES_STRING_IF_INVALID)\n        TEMPLATES[0][\"OPTIONS\"][\"string_if_invalid\"] = \"\"\n        TEMPLATES[1][\"OPTIONS\"][\"string_if_invalid\"] = \"valid_string\"\n        with self.settings(TEMPLATES=TEMPLATES):\n            self.assertEqual(check_string_if_invalid_is_string(None), [])\n", "def test_template_tags_no_libraries_defined(self):\n    TEMPLATES = [\n        {\n            \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n            \"OPTIONS\": {},\n        },\n    ]\n    with self.settings(TEMPLATES=TEMPLATES):\n        self.assertEqual(check_for_template_tags_with_the_same_name(None), [])\n", "    def test_template_tags_with_no_libraries(self):\n        with self.settings(\n            TEMPLATES=[\n                {\n                    \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n                    \"OPTIONS\": {},\n                },\n            ]\n        ):\n            self.assertEqual(check_for_template_tags_with_the_same_name(None), [])\n"], "sample_46": ["    def setUp(self):\n        self.reference = IndexColumns(\n            'table', \n            ['first_column', 'second_column'], \n            lambda column: column.upper(), \n            col_suffixes=['ASC', 'DESC'], \n            opclasses=['text_ops', 'int_ops']\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(), opclasses=['opclass1', 'opclass2']\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(), opclasses=['opclass1', 'opclass2']\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(), opclasses=['opclass1', 'opclass2']\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(), opclasses=['opclass1', 'opclass2']\n        )\n"], "sample_24": ["def test_message_dict(self):\n    error_dict = {\n        'field1': ['error1', 'error2'],\n        'field2': 'error3',\n    }\n    error = ValidationError(error_dict)\n    self.assertEqual(error.message_dict, {\n        'field1': ['error1', 'error2'],\n        'field2': ['error3'],\n    })\n\n    nested_error_dict = {\n        'field1': ValidationError(\n            'error %(parm1)s %(parm2)s',\n            code='my_code',\n            params={'parm2': 'val2', 'parm1': 'val1'},\n        ),\n        'field2': 'other',\n    }\n    nested_error = ValidationError(nested_error_dict)\n    self.assertEqual(nested_error.message_dict, {\n        'field1': ['error val1 val2'],\n        'field2': ['other'],\n    })\n", "    def test_iter(self):\n        error_list = [\n            ValidationError('message1'),\n            ValidationError('message2', code='code2'),\n            ValidationError('error %(param)s', code='code3', params={'param': 'value'}),\n        ]\n        exception = ValidationError(error_list)\n        self.assertEqual(\n            list(exception),\n            ['message1', 'message2', 'error value']\n        )\n\n        error_dict = {\n            'field1': ['error1', 'error2'],\n            'field2': ValidationError('error3'),\n        }\n        exception = ValidationError(error_dict)\n        self.assertEqual(\n            list(exception),\n            [('field1', ['error1', 'error2']), ('field2', ['error3'])]\n        )\n", "    def test_validation_error_single_message(self):\n        error = ValidationError('single error message')\n        self.assertEqual(error.message, 'single error message')\n        self.assertEqual(error.code, None)\n        self.assertEqual(error.params, None)\n        self.assertEqual(len(error.error_list), 1)\n        self.assertEqual(error.error_list[0].message, 'single error message')\n        self.assertEqual(str(error), \"['single error message']\")\n", "compilation error", "    def test_update_error_dict(self):\n        error1 = ValidationError('message1')\n        error2 = ValidationError({'field1': 'message2'})\n        error3 = ValidationError(['message3', 'message4'])\n\n        error_dict = {}\n        updated_dict = error1.update_error_dict(error_dict)\n        self.assertEqual(updated_dict, {NON_FIELD_ERRORS: ['message1']})\n\n        error_dict = {'field1': ['existing']}\n        updated_dict = error2.update_error_dict(error_dict)\n        self.assertEqual(updated_dict, {'field1': ['existing', 'message2']})\n\n        error_dict = {}\n        updated_dict = error3.update_error_dict(error_dict)\n        self.assertEqual(updated_dict, {NON_FIELD_ERRORS: ['message3', 'message4']})\n\n        nested_error = ValidationError({'field2': error1, 'field3': error3})\n        error_dict = {'field2': ['existing_field2']}\n        updated_dict = nested_error.update_error_dict(error_dict)\n        self.assertEqual(updated_dict, {\n            'field2': ['existing_field2', 'message1'],\n            NON_FIELD_ERRORS: ['message3', 'message4']\n        })\n"]}, "raw_scored_generations": {"sample_0": [true, true, false, false, false], "sample_3": [false, false, false, false, false], "sample_6": [false, true, false, true, false], "sample_1": [false, false, false, true, false], "sample_2": [false, false, false, false, true], "sample_4": [false, false, false, false, false], "sample_5": [false, false, false, true, true], "sample_7": [false, false, false, false, true], "sample_9": [false, false, false, false, false], "sample_8": [false, false, false, false, false], "sample_10": [true, false, false, true, false], "sample_11": [true, false, false, false, false], "sample_12": [true, false, false, true, true], "sample_13": [false, false, false, false, false], "sample_14": [false, false, false, false, false], "sample_15": [true, true, false, true, true], "sample_16": [false, false, false, false, false], "sample_17": [false, false, false, false, false], "sample_18": [true, true, true, true, false], "sample_19": [true, false, false, false, false], "sample_21": [false, false, false, false, true], "sample_20": [true, true, true, false, false], "sample_23": [true, false, true, true, true], "sample_22": [true, false, true, true, true], "sample_24": [true, true, true, false, false], "sample_25": [false, false, false, false, false], "sample_28": [false, false, false, false, false], "sample_26": [true, false, false, true, false], "sample_27": [true, true, true, true, true], "sample_29": [false, false, false, false, false], "sample_31": [false, false, false, false, false], "sample_30": [true, true, true, false, true], "sample_32": [false, false, false, false, true], "sample_33": [false, false, false, false, false], "sample_34": [false, false, false, false, false], "sample_35": [false, false, false, false, false], "sample_36": [false, true, false, false, false], "sample_37": [false, false, false, false, false], "sample_39": [false, false, false, true, true], "sample_38": [false, false, false, false, false], "sample_40": [true, true, false, false, true], "sample_42": [false, false, false, false, true], "sample_41": [false, true, false, false, true], "sample_43": [true, true, true, true, true], "sample_45": [false, false, false, false, false], "sample_46": [false, false, false, false, false], "sample_44": [true, false, false, false, false], "sample_48": [false, false, false, false, false], "sample_47": [false, false, false, false, false], "sample_50": [true, true, true, false, false], "sample_49": [false, false, false, false, false], "sample_51": [false, false, true, false, false], "sample_52": [false, false, true, true, false], "sample_53": [true, false, true, false, false], "sample_55": [true, true, true, true, true], "sample_54": [false, false, false, false, false], "sample_56": [false, true, false, true, true], "sample_58": [true, true, true, true, true], "sample_57": [false, false, false, true, false], "sample_60": [false, false, true, true, true], "sample_59": [false, false, true, false, false], "sample_61": [false, false, false, false, false], "sample_63": [false, false, false, false, false], "sample_62": [false, true, false, false, false], "sample_64": [false, false, false, false, false], "sample_66": [true, true, true, true, true], "sample_65": [false, false, false, false, false], "sample_68": [false, false, false, false, false], "sample_67": [false, false, true, true, true], "sample_69": [false, true, false, true, true], "sample_70": [false, false, false, false, false], "sample_71": [false, false, false, false, false], "sample_72": [true, false, false, true, true], "sample_73": [false, false, true, false, false], "sample_74": [true, true, true, true, true], "sample_75": [true, true, true, false, false], "sample_76": [false, false, true, false, false], "sample_77": [false, false, false, true, false], "sample_78": [false, false, false, false, false], "sample_79": [false, false, false, true, true], "sample_80": [true, true, false, true, false], "sample_82": [true, true, false, true, false], "sample_81": [false, false, false, false, false], "sample_83": [false, false, false, false, false], "sample_84": [false, false, false, false, false], "sample_85": [false, false, false, false, false], "sample_86": [false, false, true, false, true], "sample_87": [false, false, false, false, false], "sample_88": [false, true, false, false, false], "sample_89": [false, false, false, false, false], "sample_90": [false, false, false, false, false], "sample_91": [false, false, false, false, false], "sample_92": [false, false, false, false, false], "sample_93": [true, true, false, false, true], "sample_95": [true, false, false, false, false], "sample_94": [false, false, false, false, false], "sample_96": [true, false, false, false, false], "sample_97": [true, true, true, false, false], "sample_98": [false, false, false, true, true], "sample_99": [false, false, false, false, false], "sample_100": [false, false, false, false, true], "sample_101": [false, false, false, true, false], "sample_102": [true, false, false, false, false], "sample_103": [false, false, false, false, false], "sample_104": [false, false, false, false, false], "sample_105": [true, false, false, false, false], "sample_107": [false, false, false, true, true], "sample_106": [true, true, true, false, true], "sample_108": [true, false, false, true, true], "sample_109": [false, true, true, false, true], "sample_110": [true, true, true, true, true], "sample_111": [false, false, false, false, false], "sample_112": [false, true, false, false, true], "sample_113": [false, true, false, false, true], "sample_114": [false, true, true, false, false], "sample_115": [false, false, false, false, false], "sample_116": [false, false, false, false, false], "sample_117": [false, false, true, false, false], "sample_118": [false, true, false, true, true], "sample_119": [true, false, false, true, false], "sample_120": [false, true, false, true, true], "sample_121": [false, false, false, false, false], "sample_122": [true, true, false, true, true], "sample_123": [true, false, false, false, true], "sample_124": [true, true, false, false, true], "sample_125": [false, false, false, false, false], "sample_126": [false, true, false, false, false], "sample_127": [false, false, false, false, false], "sample_128": [true, false, true, false, false], "sample_129": [false, false, false, false, false], "sample_130": [false, false, true, true, false], "sample_131": [true, false, false, false, false], "sample_132": [false, false, false, false, false], "sample_133": [false, false, false, false, false], "sample_134": [true, true, true, true, true], "sample_135": [true, true, true, false, true], "sample_136": [true, false, false, false, true], "sample_137": [false, false, true, true, false], "sample_138": [false, false, false, false, false], "sample_139": [true, false, false, false, false], "sample_140": [true, false, true, false, true], "sample_142": [false, true, false, false, false], "sample_141": [false, false, false, true, false], "sample_143": [false, false, false, false, false], "sample_144": [false, false, false, false, true], "sample_145": [false, true, true, false, false], "sample_146": [false, false, true, false, false], "sample_147": [true, false, false, false, false], "sample_148": [false, false, false, false, false], "sample_149": [false, false, false, true, false], "sample_150": [false, false, false, false, false], "sample_151": [false, false, false, false, false], "sample_152": [true, true, true, true, true], "sample_153": [false, true, false, false, false], "sample_154": [true, false, true, true, false], "sample_155": [false, false, false, false, false], "sample_156": [false, false, false, true, false], "sample_157": [false, false, false, false, false], "sample_158": [false, false, false, false, false], "sample_159": [false, false, false, false, false]}}