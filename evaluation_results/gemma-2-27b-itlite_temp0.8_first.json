{"raw_generations": {"sample_121": ["def test_unrank_trotterjohnson():\n    p = Permutation.unrank_trotterjohnson(5, 10)\n    assert p.rank_trotterjohnson() == 10\n    assert p == Permutation([0, 3, 1, 2, 4])\n\n", "def test_unrank_lex():\n    p = Permutation.unrank_lex(4, 10)\n    assert p.rank() == 10\n    assert Permutation.unrank_lex(4, 0) == Permutation([0, 1, 2, 3])\n    assert Permutation.unrank_lex(4, 23) == Permutation([3, 2, 1, 0])\n\n", "def test_from_inversion_vector():\n    p1 = Permutation.from_inversion_vector([3, 2, 1, 0, 0])\n    assert p1 == Permutation([3, 2, 1, 0, 4, 5])\n\n    p2 = Permutation.from_inversion_vector([1, 0, 0])\n    assert p2 == Permutation([2, 1, 0])\n", "def test_unrank_trotterjohnson():\n    p = Permutation.unrank_trotterjohnson(5, 10)\n    assert p.rank_trotterjohnson() == 10\n    assert list(p.array_form) == [0, 3, 1, 2, 4]\n", "def test_from_inversion_vector():\n    p = Permutation.from_inversion_vector([0, 1, 0, 2])\n    assert p.array_form == [0, 2, 1, 3]\n\n\n\n"], "sample_94": ["    def test_getstatementrange_ast_blockfinder_empty(self, tmpdir: Path):\n        f = tmpdir.join(\"test.py\")\n        f.write_text(\"\"\"\n            pass\n\n        \"\"\")\n        code = compile(f.read_text(), \"test.py\", \"exec\")\n        astnode = ast.parse(f.read_text(), \"test.py\", \"exec\")\n        source = Source(code)\n        _, _, end = getstatementrange_ast(1, source, astnode=astnode)\n        assert end == 3\n", "    def test_multiple_statements_in_same_line():\n        s = Source(\n            \"\"\"\n            x = 1; y = 2\n            print(x, y)\n        \"\"\"\n        )\n        statement1 = s.getstatement(0)\n        statement2 = s.getstatement(1)\n        assert statement1.lines == [\"x = 1; y = 2\"]\n        assert statement2.lines == [\"print(x, y)\"]\n\n", "def test_source_getstatement_with_empty_lines():\n    src = Source(\n        \"\"\"\n        pass\n\n    # comment\n\n        pass\n    \"\"\"\n    )\n    stmt = src.getstatement(3)\n    assert stmt == Source(\n        \"\"\"\n    # comment\n    \"\"\"\n    )\n\n", "    def test_getstatementrange_trailing_empty_lines():\n        source = Source(\n            \"\"\"", "def test_getstatementrange_empty():\n    source = Source()\n    source.lines = []\n    with pytest.raises(IndexError):\n        getstatementrange_ast(0, source)\n\n"], "sample_143": ["    def test_print_Matrix_with_free_symbols():\n        A = MatrixSymbol('A', 2, 2)\n        assert pretty(A) == \"A\\n\"\\\n                           \"___\\n\"\\\n                           \"[] []\\n\"\\\n                           \"[] []\"\n", "    def test_pretty_print_MatrixSymbol(self):\n        A = MatrixSymbol('A', 2, 3)\n        self.assertEqual(pretty(A), 'A')\n\n", "def test_pretty_groebner_basis():\n    x = Symbol('x')\n    y = Symbol('y')\n    f = x**2 + y*x\n    g = x + y**2\n    I = S.GroebnerBasis([f, g], x, y)\n    assert pretty(I) == \"GroebnerBasis(x**2 + x*y, x + y**2, x, y)\"\n", "def test_pretty_MatrixSlice():\n    A = MatrixSymbol('A', 3, 3)\n    assert pretty(A[0, :]) == \"A[0, :]\"\n    assert pretty(A[:, 1]) == \"A[:, 1]\"\n    assert pretty(A[1:3, 0:2]) == \"A[1:3, 0:2]\"\n", "def test_pretty_MatrixSlice():\n    M = Matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    assert pretty(M[1, :]) == '\u23a14  5  6\u23a4'\n"], "sample_59": ["    def test_formset_factory_with_custom_kwargs(self):\n        formset = formset_factory(CustomKwargForm, extra=1, custom_kwarg=\"custom_value\")\n        instance = formset(data={})\n        self.assertEqual(instance.forms[0].custom_kwarg, \"custom_value\")\n", "    def test_formset_factory_with_custom_kwargs(self):\n        formset_class = formset_factory(CustomKwargForm, extra=1)\n        formset = formset_class(\n            {\"custom_kwarg\": \"hello\"}, prefix=\"custom_formset\"\n        )\n        self.assertEqual(formset[0].custom_kwarg, \"hello\")\n", "    def test_formset_factory_sets_absolute_max(self):\n        # This test exercises the 'absolute_max' parameter to formset_factory\n\n        # Set a lower absolute_max than the default max_num\n        CustomFormSet = formset_factory(Choice, absolute_max=5)\n        formset = CustomFormSet({'choices-TOTAL_FORMS': '6'})\n\n        self.assertEqual(formset.absolute_max, 5)\n\n        # The total_forms should be capped at the absolute_max\n        self.assertEqual(formset.total_form_count(), 5)\n\n        # Ensure the rest of the formset functionality still works\n        self.assertEqual(\n            formset.management_form.cleaned_data[TOTAL_FORM_COUNT], 5\n        )\n", "    def test_formset_factory_absolute_max(self):\n        formset_class = formset_factory(\n            Choice, max_num=5, absolute_max=3, validate_max=True\n        )\n\n        formset = formset_class({'choices-0-choice': 'Choice 1',\n                                           'choices-0-votes': '1',\n                                           'choices-1-choice': 'Choice 2',\n                                           'choices-1-votes': '2',\n                                           'choices-2-choice': 'Choice 3',\n                                           'choices-2-votes': '3',\n                                           'choices-3-choice': 'Choice 4',\n                                           'choices-3-votes': '4',\n                                           'choices-TOTAL_FORMS': '5'})\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(\n            formset.errors.as_data(),\n            {\n                \"nonform\": [\n                    {\n                        'code': 'too_many_forms',\n                        'message': 'Please submit at most 3 forms.'\n                    }\n                ]\n            }\n        )\n", "    def test_formset_factory_absolute_max(self):\n        # Test absolute_max limit.\n        formset_data = [(\"Choice 1\", 1)]\n        formset_class = formset_factory(Choice, absolute_max=1, max_num=2)\n        formset = self.make_choiceformset(formset_data, formset_class)\n\n        self.assertEqual(formset.total_form_count(), 1)  # Should respect absolute_max\n"], "sample_11": ["    def test_serialize_lazy_object(self):\n        class LazyValue:\n                self._value = value\n                return self._value\n        lazy_obj = LazyObject(LazyValue('test'))\n\n        serialized_value, imports = serializer_factory(lazy_obj).serialize()\n        self.assertEqual(serialized_value, \"'test'\")\n        self.assertEqual(imports, set())\n\n\n\n", "    def test_operation_writer_custom_operation(self):\n        class CustomOperation(migrations.Migration):\n                super().__init__(*args, **kwargs)\n                self.name = 'CustomOperation'\n\n        operation = CustomOperation()\n        writer = OperationWriter(operation)\n        self.assertEqual(writer.serialize(), (\"Operation(name='CustomOperation')\", set()))\n\n", "    def test_serialize_lazy_object_wrapped_value(self):\n        class MyLazyObject(SimpleLazyObject):\n                self._wrapped = value\n\n                return self._wrapped\n\n        lazy_value = MyLazyObject(3)\n\n        serializer = serializer_factory(lazy_value)\n        serialized, _ = serializer.serialize()\n\n        self.assertEqual(serialized, '3')\n", "    def test_serialize_deconstructable_with_lazy_object(self):\n        class LazyValue:\n                self.value = SimpleLazyObject(lambda: \"hello\")\n\n                return (\n                    '%s.%s' % (self.__class__.__module__, self.__class__.__name__),\n                    [],\n                    {},\n                )\n\n        lazy_obj = LazyValue()\n        serialized = MigrationWriter.serialize(migrations.CreateModel(\n            name='TestModel',\n            fields=[\n                ('id', models.AutoField(primary_key=True)),\n                ('value', models.CharField(default=lazy_obj)),\n            ],\n        ))\n        self.assertIn('value=models.CharField(default=\"hello\")', serialized)\n\n", "    def test_serialize_lazy_string(self):\n        lazy_string = SimpleLazyObject(lambda: 'Hello, world!')\n        serializer = serializer_factory(lazy_string)\n        string, imports = serializer.serialize()\n        self.assertEqual(string, \"'Hello, world!'\")\n        self.assertEqual(imports, set())\n"], "sample_10": ["    def test_range_lookup(self):\n\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__range=(datetime(2005, 7, 26), datetime(2005, 7, 27))),\n            [self.a1, self.a2, self.a3]\n        )\n\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__range=(datetime(2005, 7, 27), datetime(2005, 8, 1))),\n            [self.a3, self.a4, self.a5, self.a6, self.a7]\n        )\n", "    def test_in_lookup_with_subquery(self):\n        # Test IN lookup with a subquery.\n        subquery = Article.objects.filter(headline__startswith='Article 1').values_list('id', flat=True)\n        articles = Article.objects.filter(id__in=subquery)\n        self.assertQuerysetEqual(articles, [self.a1], attrgetter('id'))\n\n", "    def test_year_exact_lookup_with_subquery(self):\n        # Test YearExact lookup with a subquery as the rhs value\n        subquery = Article.objects.filter(author=self.au1).values('pub_date__year').distinct()\n        lookup = YearExact('pub_date', subquery)\n        articles = Article.objects.filter(lookup)\n\n        self.assertQuerysetEqual(articles, [self.a1, self.a2, self.a3, self.a4])\n\n", "    def test_year_lookups(self):\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__exact=2005),\n            [\n                'Article 1',\n                'Article 2',\n                'Article 3',\n                'Article 4',\n                'Article 5',\n                'Article 6',\n                'Article 7',\n            ],\n            transform=attrgetter('headline'),\n        )\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gt=2004),\n            [\n                'Article 1',\n                'Article 2',\n                'Article 3',\n                'Article 4',\n                'Article 5',\n                'Article 6',\n                'Article 7',\n            ],\n            transform=attrgetter('headline'),\n        )\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__gte=2005),\n            [\n                'Article 1',\n                'Article 2',\n                'Article 3',\n                'Article 4',\n                'Article 5',\n                'Article 6',\n                'Article 7',\n            ],\n            transform=attrgetter('headline'),\n        )\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lt=2006),\n            [\n                'Article 1',\n                'Article 2',\n                'Article 3',\n                'Article 4',\n                'Article 5',\n                'Article 6',\n                'Article 7',\n            ],\n            transform=attrgetter('headline'),\n        )\n        self.assertQuerysetEqual(\n            Article.objects.filter(pub_date__year__lte=2005),\n            [\n                'Article 1',\n                'Article 2',\n                'Article 3',\n                'Article 4',\n                'Article 5',\n                'Article 6',\n                'Article 7',\n            ],\n            transform=attrgetter('headline'),\n        )\n", "    def test_year_gte_with_direct_value(self):\n        qs = Article.objects.filter(pub_date__year__gte=2005)\n        self.assertQuerysetEqual(qs, [self.a1, self.a2, self.a3, self.a4, self.a5, self.a6, self.a7])\n\n"], "sample_153": ["def test_pretty_vector_dyadic_product():\n    assert pretty(d[7]) == pretty_d_7\n    assert upretty(d[7]) == upretty_d_7\n\n", "def test_pretty_del():\n    assert pretty(Del) == '\u2207'\n    assert upretty(Del) == '\u2207'\n\n", "def test_pretty_del_operator():\n    assert pretty(Del) == '\u2207'\n    assert upretty(Del) == '\u2207'\n\n", "def test_pretty_vector_scalar_product():\n    assert pretty(v[7] | N.k) == pretty_d_7\n    assert upretty(v[7] | N.k) == upretty_d_7\n", "def test_pretty_del():\n    assert pretty(Del) == '\u2207'\n    assert upretty(Del) == '\u2207'\n"], "sample_41": ["    def test_formset_factory_absolute_max(self):\n        formset = formset_factory(Choice, max_num=5, absolute_max=3)\n        formset.management_form.cleaned_data = {\n            TOTAL_FORM_COUNT: 4,\n            INITIAL_FORM_COUNT: 0,\n            MIN_NUM_FORMS: 0,\n            MAX_NUM_FORMS: 5,\n        }\n        with self.assertRaises(ValidationError) as cm:\n            formset.full_clean()\n\n        self.assertEqual(\n            str(cm.exception),\n            'Please submit at most 3 forms.',\n        )\n\n", "    def test_formset_factory_absolute_max(self):\n        formset_class = formset_factory(FavoriteDrinkForm, max_num=5, absolute_max=3)\n        formset = formset_class({'form-0-name': 'Soda'})\n\n        self.assertEqual(formset.errors, [])\n        self.assertEqual(formset.cleaned_data, [{'name': 'Soda'}])\n\n        formset = formset_class({'form-0-name': 'Soda', 'form-1-name': 'Water', 'form-2-name': 'Juice'})\n\n        self.assertEqual(formset.errors, [])\n        self.assertEqual(formset.cleaned_data, [\n            {'name': 'Soda'}, {'name': 'Water'}, {'name': 'Juice'}\n        ])\n\n        formset = formset_class({'form-0-name': 'Soda', 'form-1-name': 'Water', 'form-2-name': 'Juice',\n                                'form-3-name': 'Tea', 'form-4-name': 'Coffee'})\n        self.assertRaises(ValidationError, formset.full_clean)\n", "    def test_formset_factory_absolute_max(self):\n        class TestForm(Form):\n            field = CharField()\n\n        FormSet = formset_factory(TestForm, absolute_max=5)\n\n        # Create a formset with 5 forms.\n        formset = FormSet(data={'form-0-field': ['a'],\n                               'form-1-field': ['b'],\n                               'form-2-field': ['c'],\n                               'form-3-field': ['d'],\n                               'form-4-field': ['e'],\n                               'form-TOTAL_FORMS': '5',\n                               'form-INITIAL_FORMS': '0'})\n        self.assertTrue(formset.is_valid())\n\n        # Try to create a formset with 6 forms (exceeding absolute_max).\n        with self.assertRaises(ValidationError):\n            formset = FormSet(data={'form-0-field': ['a'],\n                                   'form-1-field': ['b'],\n                                   'form-2-field': ['c'],\n                                   'form-3-field': ['d'],\n                                   'form-4-field': ['e'],\n                                   'form-5-field': ['f'],\n                                   'form-TOTAL_FORMS': '6',\n                                   'form-INITIAL_FORMS': '0'})\n", "    def test_formset_factory_absolute_max(self):\n        formset_class = formset_factory(Choice, max_num=10, absolute_max=5)\n        formset = formset_class({'choices-TOTAL_FORMS': '6'})\n        self.assertEqual(formset.errors, [ErrorList([ValidationError('Please submit at most 5 forms.')])])\n", "    def test_formset_factory_can_delete_extra(self):\n        formset = formset_factory(\n            FavoriteDrinkForm,\n            extra=2,\n            can_delete=True,\n            can_delete_extra=False\n\n        )\n\n        formset_data = {\n            'form-0-name': 'Coke',\n        }\n\n        formset_instance = formset(formset_data, prefix='form')\n\n        self.assertEqual(formset_instance.is_valid(), False)\n        self.assertEqual(len(formset_instance.errors), 1)\n\n        self.assertEqual(formset_instance.errors[0].__class__, ErrorList)\n        self.assertIn(\n            'This field is required.',\n            formset_instance.errors[0]\n        )\n\n"], "sample_84": ["    def test_setup_method_invocaton(self):\n        class MyClass:\n                assert method == 'test_something'\n                self.setup_called = True\n\n                assert self.setup_called\n        self.runpytest(\n            \"-v\",\n            \"--fixtures\",\n            \"-s\",\n            *get_public_names(MyClass),\n        )\n\n", "    def test_FunctionDefinition_setup(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n                pass\n            \"\"\"\n        )\n        funcdef = FunctionDefinition(\n            name=\"test_func\",\n            parent=testdir.getpathnode(\"test_module.py\"),\n            obj=test_func,\n            config=testdir.config,\n        )\n        with pytest.raises(RuntimeError):\n            funcdef.setup()\n", "    def test_getting_fixture_request_from_function_definition(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n                config.addinivalue_line(\"markers\", \"needs_fixture: mark a test which requires the fixture\")\n\n            @pytest.fixture\n                return 'fixture1'\n        \"\"\"\n        )\n        testdir.create_test_file(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.needs_fixture\n                assert fixture1 == 'fixture1'\n                \n                assert isinstance(request, FixtureRequest)\n                \n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.assert_outcomes(passed=1)\n\n        def_node = next(x for x in result.session.items if isinstance(x, FunctionDefinition))\n        assert isinstance(def_node._request, FixtureRequest)\n\n", "    def test_fixture_missing(self, testdir):\n        testdir.create_test(\"\"\"\n                pass\n        \"\"\")\n        result = testdir.runpytest()\n        assert result.ret == 1\n        result.stdout.fnmatch_lines([\n            \"*fixture 'nonexistent' not found*\",\n        ])\n\n", "    def test_non_existing_fixture(self):\n            pass\n        with pytest.raises(FixtureLookupError):\n            self._fixturemanager.getfixtureinfo(\n                Function(\"test_func\", self, obj=test_func), test_func\n            )\n        self._fixturemanager.register(\n            \"fixture\", lambda: 1, scope=\"session\"\n        )\n"], "sample_157": ["def test_tensorproduct_simp_Add():\n    A = symbols('A', commutative=False)\n    B = symbols('B', commutative=False)\n    C = symbols('C', commutative=False)\n    D = symbols('D', commutative=False)\n    tp1 = TensorProduct(A, B)\n    tp2 = TensorProduct(C, D)\n    assert tensor_product_simp(tp1 + tp2) == tp1 + tp2\n", "def test_tensorproduct_simp_matrix():\n    m1 = Matrix([[1, 2*I], [1 + I, 3]])\n    m2 = Matrix([[2*I, 3], [4*I, 2]])\n    tp = TensorProduct(m1, m2)\n    assert tensor_product_simp(tp) == tp\n", "    def test_trace_indices(self):\n        tp = TP(A, B)\n        self.assertEqual(Tr(tp), Tr(A)*Tr(B))\n        self.assertEqual(Tr(tp, indices=[0]), Tr(A))\n        self.assertEqual(Tr(tp, indices=[1]), Tr(B))\n        self.assertEqual(Tr(tp, indices=[0, 1]), Tr(A)*Tr(B))\n\n", "    def test_tensorproduct_simp_density(self):\n        d1 = Density(QubitBra(0))\n        d2 = Density(QubitBra(1))\n        tp = TensorProduct(d1, d2)\n        self.assertEqual(tp.doit(), TensorProduct(d1,d2))\n\n", "def test_tensorproduct_simp_with_density():\n    ket1 = Qubit('0')\n    ket2 = Qubit('1')\n    rho = Density(ket1*ket1.dagger + 0.5*ket2*ket2.dagger)\n    tp = TensorProduct(rho, A)\n    assert tensor_product_simp(tp) == TensorProduct(rho, A)\n\n"], "sample_139": ["    def test_principal_branch_evalf_inf():\n        from sympy.functions.elementary.complexes import principal_branch\n        assert principal_branch(exp(I*pi), oo)._evalf(2).is_real\n        assert (principal_branch(exp(I*pi/2), oo)\n                ._evalf(2) == sqrt(0.5 + 0.5j)).is_real == False\n", "def test_periodic_argument_evalf_period():\n    from sympy import periodic_argument\n    z = Symbol('z')\n    assert periodic_argument(z, 2 * pi).evalf(subs={z: 1 + I}, n=2) == N_equals(\n        (atan2(1, 1)).evalf(n=2), (periodic_argument(1 + I, 2 * pi)).evalf(n=2)\n    )\n\n", "def test_unbranched_argument():\n    x = Symbol('x', real=True)\n    y = Symbol('y', real=True)\n    assert unbranched_argument(exp(2*pi*I*x)) == 2*pi*x\n    assert unbranched_argument(exp(2*pi*I*(x + y))) == 2*pi*(x + y)\n    assert unbranched_argument(exp(2*pi*I*x)*exp(2*pi*I*y)) == 2*pi*(x + y)\n    assert unbranched_argument(exp(2*pi*I*x)*exp(pi*I)) == 2*pi*x + pi\n    assert unbranched_argument(exp(pi*I)) == pi\n    assert unbranched_argument(exp(2*pi*I*x + pi*I)) == 2*pi*x + pi\n    assert unbranched_argument(exp(2*pi*I*(x + y) + pi*I)) == 2*pi*(x + y) + pi\n\n", "def test_unbranched_argument():\n    x = Symbol('x')\n    assert unbranched_argument(exp(2*pi*I*x)) == 2*pi*x\n    assert unbranched_argument(exp(2*pi*I*x + pi*I)) == 2*pi*x + pi\n    assert unbranched_argument(exp(4*pi*I*x)) == 0\n    assert unbranched_argument(exp(pi*I)) == pi\n\n", "    def test_principal_branch_evalf_issue_3228():\n        z = Symbol('z', real=True)\n        pb = principal_branch(exp(I*pi*z), 2*pi)\n        assert pb.evalf(subs={z: 1.5}) == 1\n"], "sample_88": ["def test_saferepr_with_recursive_object():\n    class Recursive:\n            self.self = self\n\n    obj = Recursive()\n    result = saferepr(obj)\n    assert \"<[RecursionError raised in repr()] Recursive object at 0x\" in result\n\n", "    def test_saferepr_maxsize():\n        class BrokenRepr:\n                raise ValueError(\"Intentional error\")\n\n        assert len(saferepr(BrokenRepr(), maxsize=10)) <= 10\n", "    def test_saferepr_maxsize():\n        assert len(saferepr(list(range(1000)), maxsize=100)) < 100\n", "    def test_saferepr_exception_in_repr():\n        class BrokenRepr:\n                raise ValueError(\"Broken Repr\")\n        obj = BrokenRepr()\n        s = saferepr(obj)\n        assert s.startswith(\"<[ValueError raised in repr()] BrokenRepr object at 0x\")\n", "    def test_pformat_dispatch_basic():\n        class Foo:\n                return \"Foo()\"\n        assert _pformat_dispatch(Foo()) == \"Foo()\"\n"], "sample_28": ["    def test_each_context_available_apps(self):\n        self.assertIn('available_apps', self.ctx)\n        for app in self.ctx['available_apps']:\n            self.assertIn('name', app)\n            self.assertIn('app_label', app)\n            self.assertIn('app_url', app)\n            self.assertIn('has_module_perms', app)\n            self.assertIn('models', app)\n            for model in app['models']:\n                self.assertIn('model', model)\n                self.assertIn('name', model)\n                self.assertIn('object_name', model)\n                self.assertIn('perms', model)\n                self.assertIn('admin_url', model)\n                self.assertIn('add_url', model)\n", "    def test_each_context_available_apps(self):\n        self.assertIn('available_apps', self.ctx)\n        self.assertIsInstance(self.ctx['available_apps'], list)\n        for app in self.ctx['available_apps']:\n            self.assertIn('name', app)\n            self.assertIn('app_label', app)\n            self.assertIn('app_url', app)\n            self.assertIn('has_module_perms', app)\n            self.assertIn('models', app)\n            self.assertIsInstance(app['models'], list)\n            for model in app['models']:\n                self.assertIn('model', model)\n                self.assertIn('name', model)\n                self.assertIn('object_name', model)\n                self.assertIn('perms', model)\n                self.assertIn('admin_url', model)\n                self.assertIn('add_url', model)\n                self.assertIn('view_only', model, msg=f'Missing view_only for model {model[\"name\"]}')\n", "    def test_each_context_available_apps(self):\n        expected_apps = [\n            {\n                'name': 'Auth',\n                'app_label': 'auth',\n                'app_url': '/test_admin/admin/auth/',\n                'has_module_perms': True,\n                'models': [\n                    {\n                        'model': User,\n                        'name': 'Users',\n                        'object_name': 'user',\n                        'perms': {\n                            'add': True,\n                            'change': True,\n                            'delete': True,\n                            'view': True\n                        },\n                        'admin_url': '/test_admin/admin/auth/user/',\n                        'add_url': '/test_admin/admin/auth/user/add/'\n                    }\n                ]\n            },\n            {\n                'name': 'Test app',\n                'app_label': 'admin_views',\n                'app_url': '/test_admin/admin/admin_views/',\n                'has_module_perms': True,\n                'models': [\n                    {\n                        'model': Article,\n                        'name': 'Articles',\n                        'object_name': 'article',\n                        'perms': {\n                            'add': True,\n                            'change': True,\n                            'delete': True,\n                            'view': True\n                        },\n                        'admin_url': '/test_admin/admin/admin_views/article/',\n                        'add_url': '/test_admin/admin/admin_views/article/add/'\n\n                    }\n                ]\n            }\n        ]\n\n        self.assertEqual(self.ctx['available_apps'], expected_apps)\n\n", "    def test_available_apps_context_variable(self):\n        self.assertIn('available_apps', self.ctx)\n        available_apps = self.ctx['available_apps']\n        self.assertIsInstance(available_apps, list)\n        for app in available_apps:\n            self.assertIsInstance(app, dict)\n            self.assertIn('name', app)\n            self.assertIn('app_label', app)\n            self.assertIn('app_url', app)\n            self.assertIn('has_module_perms', app)\n            self.assertIn('models', app)\n            for model in app['models']:\n                self.assertIn('name', model)\n                self.assertIn('object_name', model)\n                self.assertIn('perms', model)\n                self.assertIn('admin_url', model)\n                self.assertIn('add_url', model)\n                self.assertIn('view_only', model)\n\n", "    def test_each_context_available_apps(self):\n        self.assertIsInstance(self.ctx['available_apps'], list)\n        for app in self.ctx['available_apps']:\n            self.assertIn('name', app)\n            self.assertIn('app_label', app)\n            self.assertIn('app_url', app)\n            self.assertIn('has_module_perms', app)\n            self.assertIn('models', app)\n            for model in app['models']:\n                self.assertIn('model', model)\n                self.assertIn('name', model)\n                self.assertIn('object_name', model)\n                self.assertIn('perms', model)\n\n"], "sample_148": ["    def test_polarify_subs_and_lift():\n        x, y = symbols('x y', polar=True)\n        eq = x + y\n        result, _ = polarify(eq, subs=True)\n        assert result == _x + _y\n\n", "def test_polar_lift_inverse():\n    x = Symbol('x')\n    y = Symbol('y')\n    assert unpolarify(polar_lift(x)) == x\n    assert unpolarify(polar_lift(x*y)) == x*y\n    assert unpolarify(polar_lift(2 + I)) == 2 + I\n    assert unpolarify(polar_lift(-1)) == -1\n    assert unpolarify(polar_lift(exp(I*pi/3))) == exp(I*pi/3)\n    assert unpolarify(polar_lift(exp(I*pi))) == -1\n    assert unpolarify(polar_lift(exp(2*I*pi))) == 1\n", "def test_principal_branch_issue_18677():\n    z = Symbol('z', polar=True)\n    assert principal_branch(z, oo) == z\n", "def test_principal_branch_evalf():\n    z = Symbol('z', polar=True)\n    assert principal_branch(z, 2*pi)._eval_evalf(10).equals(\n        principal_branch(z, 2*pi))\n    assert principal_branch(exp_polar(3*pi*I), 2*pi)._eval_evalf(\n        10).equals(exp_polar(pi*I))\n", "    def test_unpolarify_exp_polar():\n        x = Symbol('x')\n        assert unpolarify(exp_polar(x)) == exp(x)\n        assert unpolarify(exp_polar(x)*x) == exp(x)*x\n        assert unpolarify(exp_polar(I*x)) == exp(I*x)\n        assert unpolarify(exp_polar(I*x)*x) == exp(I*x)*x\n        assert unpolarify(exp_polar(x + I*pi/2)) == I*exp(x)\n        assert unpolarify(exp_polar(x + I*pi)) == -exp(x)\n"], "sample_37": ["    def test_select_related_descend(self):\n        emp = Employee.objects.get(pk=self.example_inc.ceo.pk)\n        # Check if select_related() correctly traverses the foreign key\n        # relationship.\n\n        # Check the base case\n        with CaptureQueriesContext(connection) as context:\n            emp.company\n        self.assertEqual(len(context.captured_queries), 1)\n\n        # Now check with select_related()\n        with CaptureQueriesContext(connection) as context:\n            emp = Employee.objects.select_related('company').get(pk=self.example_inc.ceo.pk)\n        self.assertEqual(len(context.captured_queries), 1)\n\n", "    def test_lookup_on_filtered_relation(self):\n        with CaptureQueriesContext(connection) as queries:\n            Employee.objects.filter(company__name='Example Inc.', salary__gt=F('company__ceo__salary')).first()\n        self.assertEqual(len(queries), 1)\n        self.assertIn('SELECT \"app_employee\".\"id\" FROM \"app_employee\" INNER JOIN \"app_company\" ON (\"app_employee\".\"company_id\" = \"app_company\".\"id\") WHERE (\"app_company\".\"name\" = %s AND \"app_employee\".\"salary\" > \"app_company\".\"ceo__salary\")', queries[0]['sql'])\n\n", "    def test_select_related(self):\n        queries = list(\n            Company.objects.filter(num_employees__gt=2).select_related(\"ceo\")\n        )\n        self.assertEqual(len(queries), 2)\n\n", "    def test_filtered_relation_as_sql(self):\n        with CaptureQueriesContext(connection) as queries:\n            Manager.objects.filter(\n                employee__in=Employee.objects.filter(\n                    filtered_relation=FilteredRelation(\n                        'company', condition=Q(num_employees__gt=10)\n                    )\n                )\n            )\n        self.assertEqual(len(queries), 2)\n        # First query should fetch all employees belonging to companies with\n        # more than 10 employees.\n        self.assertIn(\n            \"SELECT \\\"auth_user\\\".* FROM \\\"auth_user\\\" WHERE \\\"auth_user\\\".\\\"company_id\\\" IN (SELECT id FROM \\\"company\\\" WHERE \\\"company\\\".\\\"num_employees\\\" > 10)\",\n            queries[0]['sql']\n        )\n        # Second query should fetch the managers from the filtered set of employees.\n        self.assertIn(\n            \"SELECT \\\"auth_user\\\".* FROM \\\"auth_user\\\" WHERE \\\"auth_user\\\".\\\"id\\\" IN (SELECT employee_id FROM \\\"manager\\\" WHERE \\\"manager\\\".\\\"employee_id\\\" IN (SELECT \\\"auth_user\\\".\\\"id\\\" FROM \\\"auth_user\\\" WHERE \\\"auth_user\\\".\\\"company_id\\\" IN (SELECT id FROM \\\"company\\\" WHERE \\\"company\\\".\\\"num_employees\\\" > 10)))\",\n            queries[1]['sql']\n        )\n\n", "    def test_select_related_descend_with_null_fk(self):\n        # Test select_related_descend with a nullable ForeignKey.\n        self.assertFalse(\n            select_related_descend(\n                Manager.objects.get(pk=self.example_inc.ceo_id).objects,\n                restricted=False,\n                requested={},\n                load_fields=None,\n            )\n        )\n\n"], "sample_98": ["    def test_check_symmetric_sparse_tolerance():\n        # Tests the check_symmetric function on sparse matrices with a tolerance.\n        X = sp.csr_matrix([[1, 2], [2.01, 4]])\n        with assert_warns(UserWarning,\n                          match=\"Array is not symmetric\"):\n            check_symmetric(X, tol=0)\n        X = sp.csr_matrix([[1, 2], [2.01, 4]])\n        check_symmetric(X, tol=0.1)\n\n", "    def test_check_consistent_length_sparse_matrices(self):\n        X = sparse_random_matrix(10, 5, density=0.5)\n        y = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n        assert_raises(ValueError, check_consistent_length, X, y)\n", "    def test_check_consistent_length_sparse_y():\n        X = np.array([[1], [2], [3]])\n        y = sp.csr_matrix([[1], [2]])\n\n        with pytest.raises(ValueError):\n            check_consistent_length(X, y)\n", "    def test_check_consistent_length_sparse_matrix():\n        X = sparse_random_matrix(10, 5, density=0.5).tocsr()\n        y = np.arange(9)\n\n        with pytest.raises(ValueError):\n            check_consistent_length(X, y)\n\n", "    def test_check_symmetric_with_sparse_matrix():\n        # Check if check_symmetric works with sparse matrices\n        sparse_matrix = sparse_random_matrix(10, 10, density=0.5)\n        sym_sparse_matrix = check_symmetric(sparse_matrix)\n        assert_allclose_dense_sparse(sym_sparse_matrix,\n                                     sym_sparse_matrix.transpose())\n"], "sample_5": ["    def test_delete_with_deferrable_uniques(self):\n        # Create two A objects with the same value for a unique field, but deferrability.\n        A.objects.create(name='same-name')\n        A.objects.create(name='same-name')\n\n        with transaction.atomic():\n            # Attempt to delete one instance. This should fail with an IntegrityError due\n            # to the unique constraint.\n            try:\n                A.objects.get(name='same-name').delete()\n            except IntegrityError:\n                pass\n            else:\n                self.fail(\"Expected IntegrityError\")\n\n            # Now, try with deferrable uniqueness. The deletion should succeed because the\n            # constraint check is deferred.\n            A.objects.filter(name='same-name').delete()\n", "    def test_set_null_on_delete_during_cascade_delete_with_m2m(self):\n        \"\"\"\n        Regression test for #23461, verifying that setting a foreign key to NULL\n        during a cascade delete doesn't lead to inconsistencies with existing m2m\n        relations.\n\n        Specifically, this tests a scenario where a parent model has a\n        one-to-many relation to a child model with on_delete=SET_NULL. The child\n        model also has an m2m relation to another model.\n        When deleting parent instances in a cascading way, we need to ensure that\n        the m2m table isn't left with orphaned entries pointing to NULL foreign keys.\n        \"\"\"\n        m2m_to_count = M2MTo.objects.count()\n        m2m_from_count = M2MFrom.objects.count()\n\n        parent1 = Parent.objects.create()\n        child1 = Child.objects.create(parent=parent1)\n        m2m_to = M2MTo.objects.create()\n        child1.m2m.add(m2m_to)\n\n        parent2 = Parent.objects.create()\n        child2 = Child.objects.create(parent=parent2)\n        m2m_to2 = M2MTo.objects.create()\n        child2.m2m.add(m2m_to2)\n\n        # Delete the parent instances which should cascade to the child and\n        # consequently delete the m2m relations as well.\n        Parent.objects.filter(pk__in=[parent1.pk, parent2.pk]).delete()\n\n        # Ensure that all m2m relations have been properly deleted.\n        self.assertEqual(M2MTo.objects.count(), m2m_to_count)\n        self.assertEqual(M2MFrom.objects.count(), m2m_from_count)\n", "compilation error", "    def test_cascade_delete_with_transaction_rollback(self):\n        \"\"\"\n        Test that cascading deletes are rolled back when a transaction is\n        rolled back.\n\n        Specifically, we want to ensure that related objects are not deleted\n        when a parent object is deleted and the transaction is rolled back.\n        \"\"\"\n        with transaction.atomic():\n            parent = Parent.objects.create()\n            child1 = Child.objects.create(parent=parent)\n            child2 = Child.objects.create(parent=parent)\n\n            # Simulate an error that would normally cause a transaction rollback.\n            raise IntegrityError(\"Rollback this transaction!\")\n        self.assertEqual(Child.objects.count(), 2)\n        self.assertEqual(Parent.objects.count(), 1)\n", "    def test_cascade_through_proxy_model(self):\n        r = create_a()\n        r.s_set.create(name='S1')\n        r.s_set.create(name='S2')\n        r_child = RChild.objects.create(parent=r)\n        r_child.s_set.create(name='S3')\n        with transaction.atomic():\n            r.delete()\n        self.assertFalse(R.objects.exists())\n        self.assertFalse(S.objects.exists())\n        self.assertFalse(RChild.objects.exists())\n\n"], "sample_34": ["    def test_duplicate_table_name(self):\n        class DuplicateTable(models.Model):\n            name = models.CharField(max_length=100)\n\n        @override_settings(DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3'}})\n        with self.assertRaises(checks.Error):\n            checks.run_checks([DuplicateTable])\n", "    def test_duplicate_db_table(self):\n        with mock.patch('django.db.connections.router.allow_migrate', return_value=True):\n            with self.settings(DATABASE_ROUTERS=[('check_framework.routers.EmptyRouter',)]) as settings:\n\n                class Meta(object):\n                    app_label = 'check_framework'\n\n                class DuplicateModel(models.Model):\n                    name = models.CharField(max_length=100)\n\n                    class Meta:\n                        db_table = 'duplicate_table'\n\n                class AnotherDuplicateModel(models.Model):\n                    name = models.CharField(max_length=100)\n\n                    class Meta:\n                        db_table = 'duplicate_table'\n\n                self.assertNumQueries(0)\n                with self.assertRaises(RuntimeError):\n                    DuplicateModel.objects.create(name='foo')\n", "    def test_duplicate_table_name_different_apps(self):\n        with mock.patch('django.apps.apps', EmptyRouter()):\n            with self.assertRaises(models.base.OperationError) as e:\n                with override_settings(DATABASE_APPS_MAPPING={\n                    'default': ['check_framework']\n                }):\n                    with self.settings(INSTALLED_APPS=['check_framework.duplicate_tables']):\n                        class DuplicateModel(models.Model):\n                            pass\n            self.assertIn(\"The model 'DuplicateModel' is trying to create a table name that already exists\", str(e.exception))\n\n", "    def test_duplicate_db_table_name(self, mock_AppConfigReady):\n        class Meta:\n            app_label = 'check_framework'\n            labels = ['test_model_a', 'test_model_b']\n        \n\n        class TestModelA(models.Model):\n            name = models.CharField(max_length=100)\n\n            class Meta(Meta):\n                db_table = 'duplicate_table'\n\n        class TestModelB(models.Model):\n            name = models.CharField(max_length=100)\n\n            class Meta(Meta):\n                db_table = 'duplicate_table'\n\n        with self.assertRaisesMessage(\n            RuntimeError, 'Duplicate db_table name \"duplicate_table\" '\n            'in app \"check_framework\".'\n        ):\n            apps.populate(TestModelA, TestModelB)\n\n", "    def test_duplicate_table_name(self):\n        with self.assertRaises(Error):\n            class DuplicateModel(models.Model):\n                pass\n\n        with self.assertRaises(Error):\n            class AnotherDuplicateModel(models.Model):\n                objects = models.Manager()\n\n\n\n"], "sample_100": ["    def test_onehot_unknown_handle_error(self):\n        enc = OneHotEncoder(handle_unknown='error')\n        X = np.array([[0, 1], [1, 2], [3, 2]]).reshape(3, 2)\n        enc.fit(X)\n        with pytest.raises(ValueError) as exc:\n            enc.transform([[0, 4]])\n            \n        assert \"unknown categorical feature present\" in str(exc.value)\n", "    def test_onehotencoder_inverse_transform_ignore_unknown(self):\n        enc = OneHotEncoder(handle_unknown='ignore')\n        X = [['Male', 1], ['Female', 3], ['Female', 2], ['Male', 4]]\n\n        enc.fit(X)\n        X_transformed = enc.transform(X)\n\n        # check that unknown categories are handled correctly\n        X_inverse = enc.inverse_transform(X_transformed)\n\n        assert_equal(X_inverse[0], ['Male', 1])\n        assert_equal(X_inverse[1], ['Female', 3])\n        assert_equal(X_inverse[2], ['Female', 2])\n        assert_equal(X_inverse[3], ['Male', None])\n", "    def test_inverse_transform_with_unknown_categories():\n        est = OneHotEncoder(handle_unknown='ignore')\n        X = np.array([[0, 1], [1, 2], [0, 3]]).astype(object)\n        est.fit(X)\n        X_transformed = est.transform(X)\n        # introduce a new category during inverse transform\n        X_new = np.array([[0, 4]]).astype(object)\n\n        with assert_warns(UserWarning):\n            X_back = est.inverse_transform(X_transformed)\n        # check if inverse transform handles the unknown category correctly\n\n        assert_array_equal(X_back[:3], X[:3])\n        assert_array_equal(X_back[3], [0, None])\n\n", "def test_one_hot_encoder_fit_transform_sparse():\n    X = np.array([[0, 1], [1, 0]])\n    enc = OneHotEncoder(sparse=True, handle_unknown='ignore')\n    out = enc.fit_transform(X)\n    assert out.shape == (2, 2)\n    assert isinstance(out, sparse.csr_matrix)\n", "    def test_transform_unknown(self, sparse):\n        enc = OneHotEncoder(handle_unknown='ignore', sparse=sparse)\n        X = [['Male', 1], ['Female', 3], ['Female', 2]]\n        enc.fit(X)\n        X_test = [['Male', 4], ['Female', 2]]\n        X_out = enc.transform(X_test)\n        expected_indices = [\n            [0, 1, 0, 0, 0],\n            [0, 0, 0, 1, 0],\n        ]\n        assert_array_equal(toarray(X_out), expected_indices)\n"], "sample_107": ["def test_logistic_regression_cv_refit_off():\n    \"\"\"Test that LogisticRegressionCV works with refit=False.\"\"\"\n    X, y = make_classification(n_samples=50, n_features=10, random_state=0)\n    clf = LogisticRegressionCV(Cs=10, refit=False, cv=5)\n    clf.fit(X, y)\n    assert 'C_' in clf.get_params()\n\n    # Check that predict works\n    clf.predict(X[:2])\n\n    # Check that coef_ is not None\n    assert clf.coef_ is not None\n\n    # Check that the score is available even without refitting\n    clf.score(X, y)\n", "def test_logistic_regression_cv_l1_ratios():\n    X, y = make_classification(n_samples=50, n_features=20, random_state=0)\n    \n    # Test that LogisticRegressionCV works with l1_ratios and elasticnet\n    clf = LogisticRegressionCV(Cs=10, penalty='elasticnet',\n                                l1_ratios=[.1, .5, .9], cv=3,\n                                random_state=0)\n    clf.fit(X, y)\n    assert len(clf.coefs_paths_) == 1\n    assert clf.l1_ratios_.shape == (1,)\n", "    def test_logistic_regression_cv_l1_ratio_gridsearch(self):\n        # Check that LogisticRegressionCV works with l1_ratios as a grid\n        # parameter in GridSearchCV\n        X, y = make_classification(n_samples=100, n_features=10,\n                                   random_state=42)\n        param_grid = {'l1_ratios': [0, 0.5, 1], 'C': [1, 10]}\n        clf = LogisticRegressionCV(Cs=5, penalty='elasticnet', solver='saga',\n                                    scoring='accuracy', cv=3)\n        grid = GridSearchCV(clf, param_grid=param_grid, cv=3)\n        grid.fit(X, y)\n\n        assert grid.best_params_['l1_ratios'] in [0, 0.5, 1]\n", "    def test_logistic_regression_cv_multiclass_fit_intercept_false():\n        X, y = make_classification(n_samples=100, n_features=20,\n                                   random_state=42, n_classes=3,\n                                   n_informative=10)\n\n        # Test with fit_intercept=False and multi_class='multinomial'\n        clf = LogisticRegressionCV(fit_intercept=False,\n                                   multi_class='multinomial',\n                                   cv=5, random_state=42).fit(X, y)\n\n        assert_equal(clf.coef_.shape, (3, X.shape[1]))\n        assert_equal(clf.intercept_.shape, (3,))\n\n", "    def test_logistic_regression_cv_l1_ratio_parameter(self):\n        # Test that LogisticRegressionCV handles l1_ratio parameter correctly\n        # for elasticnet penalty\n        X, y = make_classification(n_samples=100, n_features=10, random_state=42)\n        clf = LogisticRegressionCV(Cs=10, penalty='elasticnet',\n                                   l1_ratios=[.1, .5, .9],\n                                   solver='saga', max_iter=1000)\n        clf.fit(X, y)\n\n        assert clf.l1_ratio_.shape == (1,)\n        assert_almost_equal(clf.l1_ratio_[0], 0.5, decimal=1)\n\n"], "sample_135": ["def test_Basic_args():\n    assert b1.args == ()\n    assert b2.args == (b1,)\n    assert b3.args == (b2,)\n    assert b21.args == (b2, b1)\n\n", "def test_eval_rewrite():\n    x = Symbol('x')\n    f = Function('f')\n    assert f(x).rewrite(exp) == f(x)\n    assert sin(x).rewrite(exp) == -I*(exp(I*x) - exp(-I*x))/2\n    assert (sin(x)).rewrite(exp) == -I*(exp(I*x) - exp(-I*x))/2\n\n\n", "def test_sort_key():\n    assert b1.sort_key() < b2.sort_key()\n    assert b2.sort_key() < b3.sort_key()\n    assert b2.sort_key() == b21.sort_key()\n\n    # check that default_sort_key is used for args\n    a, b = symbols('a b')\n    assert Basic(a, b).sort_key() != Basic(b, a).sort_key()\n\n", "def test_as_Basic():\n    assert as_Basic(S.Pi) is S.Pi\n    assert as_Basic(pi) is S.Pi\n    assert as_Basic(1) == S.One\n    assert as_Basic(1.0) == S.One\n    assert as_Basic(True) is S.True\n    assert as_Basic(False) is S.False\n\n", "def test_basic_slicing():\n    assert b1[:1] == (b1)\n    assert b2[:2] == (b2, b1)\n    assert b21[:1] == (b2,)\n    assert b21[1:] == (b1,)\n"], "sample_99": ["    def test_kneighbors_graph_distances(self):\n        # Check that kneighbors_graph returns the correct distances\n        for algorithm, metric in product(ALGORITHMS, VALID_METRICS):\n            neigh = neighbors.KNeighborsClassifier(n_neighbors=5,\n                                                algorithm=algorithm,\n                                                metric=metric)\n            neigh.fit(iris.data)\n            graph = neigh.kneighbors_graph(mode='distance')\n            distances, _ = neigh.kneighbors(iris.data)\n            for i in range(iris.data.shape[0]):\n                assert_array_almost_equal(graph[i].toarray().flatten(),\n                                          distances[i])\n\n\n", "def test_radius_neighbors_graph_weighted_sparse():\n    # Test radius_neighbors_graph with sparse input and weighted mode\n    # For sparse matrices, only 'connectivity' mode is supported\n    X = csr_matrix([[0, 1], [1, 0]])\n    neigh = neighbors.NearestNeighbors(radius=1.5,\n                                       metric='euclidean',\n                                       mode='distance',\n                                       algorithm='brute')\n    neigh.fit(X)\n\n    with assert_raises(ValueError):\n        neigh.radius_neighbors_graph(X, mode='distance')\n\n    # Test 'connectivity' mode\n    A = neigh.radius_neighbors_graph(X, mode='connectivity')\n    assert_true(issparse(A))\n    assert_array_equal(A.toarray(),\n                       [[1., 1.],\n                        [1., 1.]])\n\n", "    def test_radius_neighbors_graph_sparse_input_metric_precomputed(self):\n        # Test radius_neighbors_graph with sparse input and metric='precomputed'\n        X = csr_matrix(np.eye(5))\n        neigh = neighbors.NearestNeighbors(radius=2, metric='precomputed')\n        neigh.fit(X)\n        graph = neigh.radius_neighbors_graph(X)\n        assert_equal(graph.format, 'csr')\n        assert_array_equal(graph.toarray(), np.eye(5))\n", "    def test_kneighbors_graph_sparse(self):\n        X = csr_matrix(rng.rand(10, 5))\n        knn = neighbors.KNeighborsClassifier(n_neighbors=3,\n                                            algorithm='brute')\n        A = knn.kneighbors_graph(X).toarray()\n        assert_equal(A.shape, (10, 10))\n        assert_true(np.all(A == A.T))\n\n", "    def test_radius_neighbors_graph_sparse(self):\n        for sparse_type in SPARSE_TYPES:\n            X = sparse_type(iris.data)\n            for radius in [0.5, 1.0, 2.0]:\n                neigh = neighbors.RadiusNeighbors(radius=radius)\n                neigh.fit(X)\n                graph = neigh.radius_neighbors_graph(X)\n                assert_equal(graph.shape[0], X.shape[0])\n                assert_equal(graph.shape[1], X.shape[0])\n"], "sample_71": ["def test_reload_library_user_style():\n    with temp_style('test_style'):\n        style.use('test_style')\n        assert mpl.rcParams[PARAM] == VALUE\n\n        # Reloading should not remove the style.\n        style.reload_library()\n        assert mpl.rcParams[PARAM] == VALUE\n", "def test_context_style_after_reset():\n    with temp_style('test_style'):\n        original_cmap = plt.rcParams[PARAM]\n        with style.context('test_style', after_reset=True):\n            assert plt.rcParams[PARAM] == VALUE\n        assert plt.rcParams[PARAM] == original_cmap\n\n", "def test_style_context_manager_after_reset():\n    with temp_style('test_style'):\n        with style.context('test_style', after_reset=True):\n            assert plt.rcParams[PARAM] == VALUE\n        assert plt.rcParams[PARAM] != VALUE\n\n\n", "def test_use_style_from_file_with_invalid_path():\n    with pytest.raises(IOError):\n        with temp_style('invalid_style'):\n            style.use('invalid_style')\n", "def test_context_after_reset():\n    with temp_style('test_style'):\n        original_cmap = plt.rcParams[PARAM]\n        with style.context('test_style', after_reset=True):\n            assert plt.rcParams[PARAM] == VALUE\n        assert plt.rcParams[PARAM] == original_cmap\n"], "sample_81": ["    def test_fixme_with_special_characters(self):\n        stmts = _tokenize_str(\n            r\"\"\"\n            # TODO: handle special characters like & \u20ac \u2122\n            print(\"Some code\")\n            \"\"\"\n        )\n        with self.assertAddsMessages(\n            MessageTest(msg_id=\"fixme\", line=2, col_offset=1, args=\"TODO: handle special characters like & \u20ac \u2122\"),\n        ):\n            self.checker.process_tokens(stmts)\n\n", "    def test_fixme_ignores_pragma_disable(self):\n        code = \"\"\"", "    def test_fixme_with_pragma(self):\n        stmts = _tokenize_str(\n            \"\"\"", "    def test_fixme_in_docstring(self):\n        self.set_input(\n            \"\"\"\n                \\\"\\\"\\\"\n                FIXME: This function needs more documentation.\n                \\\"\\\"\\\"\n                pass\n            \"\"\"\n        )\n        msgs = self.linter.run()\n        self.assertEqual(\n            msgs,\n            [\n                MessageTest(\"fixme\", line=3, col_offset=4, args=(\"FIXME: This function needs more documentation.\",)),\n            ],\n        )\n", "    def test_fixme_with_bad_encoding(self):\n        \"\"\"Test that we handle FIXMEs with bad encoding properly.\"\"\"\n        self.checker._fixme_pattern = re.compile(r\"#\\s*(FIXME)(?=(:|\\s|\\Z))\", re.I)\n        error_line = b\" # FIXM\\xc3\\xa9: this is a bad encoding.\"\n\n        with set_config(self.linter, notes=['FIXME']):\n            node = _tokenize_str(error_line)\n            tokens = list(node.tokens)\n\n        self.checker.process_tokens(tokens)\n        expected = []\n        messages = self.linter.reporter.messages\n        self.assertEqual(messages, expected)\n"], "sample_50": ["    def test_message_storage_max_size(self):\n        storage = self.get_storage()\n        messages = [Message(constants.DEBUG, get_random_string(100)) for _ in range(20)]\n        response = self.request\n\n        # Store messages, ensuring some are truncated\n        truncated_messages = storage._store(messages, response)\n        self.assertGreater(len(messages), len(truncated_messages))\n\n        # Check that the cookie contains some messages, but not all\n        self.assertTrue(self.stored_messages_count(storage, response) < len(messages))\n\n", "    def test_cookie_size_limit(self):\n        storage = self.get_storage()\n        storage.max_cookie_size = 100\n\n        messages = [Message(level, f'Message {i}') for i, level in enumerate(\n            constants.LEVEL_TAGS.values()\n        )]\n\n        # Add enough messages to exceed the cookie size limit.\n        while len(storage._encode(messages)) > storage.max_cookie_size:\n            messages.append(Message(constants.DEBUG, 'Extra message'))\n\n        response = self.get_response(storage=storage)\n\n        unstored_messages = storage._store(messages, response)\n\n        self.assertGreater(len(messages), len(unstored_messages))\n\n        # Ensure the cookie contains all but the last message\n        self.assertEqual(stored_cookie_messages_count(storage, response), len(messages) - len(unstored_messages))\n", "    def test_cookie_overflow_and_partial_retrieval(self):\n        storage = self.get_storage()\n        messages = [\n            Message(constants.DEBUG, 'Message 1'),\n            Message(constants.INFO, 'Message 2'),\n        ]\n        response = self.client.response\n        set_cookie_data(storage, messages)\n        unstored_messages = storage._store(messages, response)\n        self.assertEqual(unstored_messages, [])\n        self.assertEqual(self.stored_messages_count(storage, response), 2)\n\n        # Simulate adding too many messages to the cookie.\n\n        for _ in range(100):\n            messages.append(Message(constants.WARNING, get_random_string(10)))\n        unstored_messages = storage._store(messages, response)\n        self.assertEqual(len(unstored_messages), 98)\n        self.assertEqual(self.stored_messages_count(storage, response), 2)\n\n        messages, all_retrieved = storage._get()\n        self.assertFalse(all_retrieved)\n        self.assertEqual(len(messages), 2)\n", "    def test_max_cookie_size_exceeded(self):\n        storage = self.get_storage()\n        messages = [Message(constants.DEBUG, get_random_string(100)) for _ in range(50)]\n        set_cookie_data(storage, messages)\n\n        response = self.get_empty_response()\n        storage.store(messages, response)\n        self.assertLess(stored_cookie_messages_count(storage, response), len(messages))\n", "    def test_cookie_max_size_limit(self):\n        storage = self.get_storage()\n        original_max_cookie_size = storage.max_cookie_size\n        storage.max_cookie_size = 100  # Set a small size limit\n\n        original_messages = [Message(constants.DEBUG, 'message ' + str(i)) for i in range(20)]\n        set_cookie_data(storage, original_messages)\n        response = self.client.get('/')\n\n        self.assertEqual(stored_cookie_messages_count(storage, response),\n                         original_storage.max_cookie_size // \n                         len(json.dumps(original_messages[0])))\n\n        storage.max_cookie_size = original_max_cookie_size\n\n"], "sample_40": ["    def test_boundfield_widget_type(self):\n        form = PersonNew({'first_name': 'John', 'last_name': 'Doe'})\n        self.assertEqual(form['first_name'].widget_type, 'text')\n        \n", "    def test_boundfield_label_tag_with_label_suffix(self):\n        form = PersonNew({'first_name': 'John', 'last_name': 'Doe'})\n        bound_field = form['first_name']\n        # Test with default label suffix\n        expected_label = '<label for=\"first_name_id\">First Name:</label>'\n        self.assertEqual(bound_field.label_tag(), mark_safe(expected_label))\n        # Test with a custom label suffix\n        form.label_suffix = ' *'\n        expected_label = '<label for=\"first_name_id\">First Name *</label>'\n        self.assertEqual(bound_field.label_tag(), mark_safe(expected_label))\n\n", "    def test_boundfield_template_name(self):\n        form = PersonNew({'first_name': 'John'})\n        bound_field = form['first_name']\n        self.assertEqual(bound_field.widget_type, 'textinput')\n        self.assertEqual(bound_field.template_name, 'django/forms/widgets/textinput.html')\n", "    def test_bound_field_as_text_input(self):\n        form = PersonNew({'first_name': 'John'})\n        bound_field = form['first_name']\n        html_output = bound_field.as_text()\n        self.assertEqual(html_output, '<input type=\"text\" name=\"first_name\" id=\"first_name_id\" value=\"John\">')\n", "    def test_boundfield_id_for_label(self):\n        form = PersonNew({'first_name': 'John', 'last_name': 'Doe'})\n\n        bound_field = form['first_name']\n        self.assertEqual(bound_field.id_for_label, 'first_name_id')\n"], "sample_145": ["    def test_latex_print_lowergamma(self):\n        assert latex(lowergamma(z, a)) == r'\\operatorname{\\gamma}(z, a)'\n", "def test_latex_cross():\n    C = CoordSys3D('C')\n    v1 = C.i + 2*C.j\n    v2 = 3*C.i - C.j + C.k\n    assert latex(Cross(v1, v2)) == r'\\begin{pmatrix}2 \\\\ 7 \\\\ -5 \\end{pmatrix}'\n\n\n", "    def test_latex_SingularityFunction(self):\n        assert latex(SingularityFunction(x, 1)) == '\\\\text{SingularityFunction}\\\\left(x, 1\\\\right)'\n", "    def test_print_indexed_base(self):\n        i = IndexedBase('i')\n        expr = i[x]\n        self.assertEqual(latex(expr), 'i_{x}')\n        \n", "def test_latex_MatrixSymbol():\n    A = MatrixSymbol('A', 2, 3)\n    assert latex(A) == r'\\mathbf{A}'\n\n\n"], "sample_116": ["def test_indexentries_sort(app, status, warning):\n    app.env.get_domain('index').entries = {\n        'index.rst': [\n            ('single', 'apple', 'apple', 'apple', None),\n            ('single', 'Banana', 'banana', 'Banana', None),\n            ('single', 'Cherry', 'cherry', 'Cherry', None),\n        ]\n    }\n    indexentries = IndexEntries(app.env)\n    result = indexentries.create_index(app.builder)\n\n    assert result[0][0] == 'apple'\n    assert result[0][1][0][0] == ('apple', None)\n\n    assert result[1][0] == 'Banana'\n    assert result[1][1][0][0] == ('Banana', None)\n\n    assert result[2][0] == 'Cherry'\n    assert result[2][1][0][0] == ('Cherry', None)\n", "    def test_index_entries_see(self, app, status, warning) -> None:\n        app.builder.build_all()\n        indexentries = IndexEntries(app.env)\n        entries = indexentries.create_index(app.builder)\n        entries = [entry for entry in entries if entry[0].startswith('see')]\n        assert len(entries) == 1\n        entry = entries[0]\n        assert entry[0] == 'see'\n        assert len(entry[1]) == 1\n        assert entry[1][0][0] == ('see other', None)\n", "    def test_index_entries_fixup(self, app, status, warning):\n        app.builder.build_all()\n        index_entries_data = app.env.get_domain('index').entries\n        \n        # Add an example 'see' and 'seealso' entry\n        app.env.domaindata['index']['entries']['example.rst'] = [\n            ('see', 'entry1 entry2', 'id1', 'main', None),\n            ('seealso', 'entry3 entry4', 'id2', 'main', None)\n        ]\n        \n        # Add a 'single' entry with sub entry example\n        app.env.domaindata['index']['entries']['example2.rst'] = [\n            ('single', 'main entry (subentry)', 'id3', 'main', None)\n        ]\n\n        index_entries = IndexEntries(app.env).create_index(app.builder)\n\n        # Check if the entries are grouped correctly\n        assert len(index_entries) == 2  # Two groups, one for letters and one for Symbols\n        assert len(index_entries[0][1]) == 1  \n        assert index_entries[0][1][0][0] == 'entry1 entry2'\n\n        assert len(index_entries[1][1]) == 1\n        assert index_entries[1][1][0][0] == 'main entry'\n", "def test_see_entry(app, env):\n    env.get_domain('index').entries = {\n        'file.rst': [\n            ('see', 'entry', 'id', 'main', None),\n        ]\n    }\n    indexentries = IndexEntries(env)\n    index = indexentries.create_index(app.builder)\n    assert index[0][1][0][0] == ('main', 'see entry')\n", "    def test_index_entries_with_categories(self, app, status, warning):\n        app.config.index_output = 'genindex'\n        app.builder.build()\n\n        # Test index entries with categories\n\n        index_content = open(app.outdir / 'genindex.html').read()\n\n        assert _('Symbols') in index_content\n        assert 'aaa' in index_content\n        assert 'bbb' in index_content\n        assert 'ccc' in index_content\n        assert 'ddd' in index_content\n\n        # Test that entries with categories are grouped correctly\n        assert \"Category1\" in index_content\n        assert \"Category2\" in index_content\n\n        \n\n"], "sample_119": ["    def test_derivative(self):\n        self.assertEqual(mcode(Derivative(sin(x), x)), \"Hold[D[Sin[x],x]]\")\n", "    def test_derivative(self):\n        self.assertEqual( mcode(Derivative(sin(x), x)),\n                         \"Hold[D[Sin[x], x]]\")\n\n", "    def test_derivative(self):\n        assert mcode(Derivative(sin(x), x)) == 'Hold[D[Sin[x], x]]'\n", "def test_print_derivative():\n    assert mcode(Derivative(f(x), x)) == 'Hold[D[f[x], x]]'\n", "    def test_mcode_derivative(self):\n        assert mcode(Derivative(f(x), x)) == 'Hold[D[f[x], x]]'\n"], "sample_146": ["    def test_MatrixSymbol_printing():\n        A = MatrixSymbol('A', 2, 3)\n        assert sstr(A) == 'A'\n", "    def test_printmethod_str(self):\n        p = StrPrinter(printmethod='_str')\n        assert p.doprint(x) == 'x'\n        assert p.doprint(x + y) == 'x + y'\n", "def test_print_TransferFunction():\n    s = TransferFunction(1, [1, 2, 1])\n    assert sstr(s) == 'TransferFunction(1, [1, 2, 1])'\n\n\n\n", "def test_printmethod():\n    f = Function('f')\n\n    assert sstr(f(x)) == 'f(x)'\n\n    class MyFunction(Function):\n            return 'MyFunction({})'.format(', '.join(str(arg) for arg in args))\n    g = MyFunction('g')\n    assert sstr(g(x)) == 'MyFunction(x)'\n\n\n\n", "def test_print_NDimArray():\n\n    a = NDimArray([1, 2, 3])\n\n    assert sstr(a) == 'NDimArray([1, 2, 3])'\n"], "sample_149": ["def test_monomial_divides():\n    assert monomial_divides((1, 2), (3, 4))\n    assert not monomial_divides((1, 2), (0, 2))\n", "    def test_monomial_divides(self):\n        assert monomial_divides((1, 2), (3, 4))\n        assert not monomial_divides((1, 2), (0, 2))\n", "def test_Monomial_as_expr():\n    M = Monomial((1, 2, 3), gens=[x, y, z])\n    assert M.as_expr() == x*y**2*z**3\n    assert M.as_expr(x, y, z) == x*y**2*z**3\n    assert M.as_expr(a, b, c) == a*b**2*c**3\n", "    def test_monomial_pow(self):\n        assert monomial_pow((1, 2), 2) == (2, 4)\n        assert monomial_pow((1, 0, 3), 2) == (2, 0, 6)\n        assert monomial_pow((0, 0, 0), 5) == (0, 0, 0)\n", "def test_Monomial_as_expr():\n    M = Monomial((1, 2, 3), gens=[x, y, z])\n    assert M.as_expr() == x*y**2*z**3\n    assert M.as_expr(x, z, y) == x*y**2*z**3\n    raises(ValueError, lambda: M.as_expr())\n"], "sample_131": ["    def test_derivative():\n        assert mcode(Derivative(f(x), x)) == 'Hold[D[f[x], x]]'\n        assert mcode(Derivative(f(x, y), x, 2)) == 'Hold[D[f[x, y], {x, 2}]]'\n", "    def test_print_Derivative(self):\n        self.assertEqual(mcode(Derivative(sin(x), x)),\n                        \"Hold[D[Sin[x], x]]\")\n        self.assertEqual(mcode(Derivative(sin(x), (x, 2))),\n                        \"Hold[D[Sin[x], {x, 2}]]\")\n        self.assertEqual(mcode(Derivative(sin(x*y), x, 2)),\n                        \"Hold[D[Sin[x*y], {x, 2}]]\")\n        self.assertEqual(mcode(Derivative(sin(x), x) + Derivative(sin(y), y)),\n                        \"Hold[D[Sin[x], x]] + Hold[D[Sin[y], y]]\")\n\n", "    def test_print_Sum():\n        assert mcode(Sum(x**2, (x, 1, 5))) == \"Hold[Sum[x^2, {x, 1, 5}]]\"\n", "    def test_print_minmax(self):\n        assert mcode(Max(x, y)) == 'Max[x, y]'\n        assert mcode(Min(x, y)) == 'Min[x, y]'\n", "    def test_mcode_Sum():\n        assert mcode(Sum(x**2, (x, 1, 3))) == \"Hold[Sum[{x^2, {x, 1, 3}}]]\"\n"], "sample_87": ["    def test_in_venv(self, tmpdir):\n        env = tmpdir.mkdir(\"venv\")\n        env.join(\"bin\").mkdir()\n        assert _in_venv(env)\n\n        outside = tmpdir.mkdir(\"outside\")\n        assert not _in_venv(outside)\n", "    def test_in_venv(self, tmpdir):\n        venv = tmpdir.mkdir(\"venv\")\n        venv.join(\"bin\", \"activate\").ensure()\n        assert _in_venv(venv)\n        assert not _in_venv(tmpdir)\n", "    def test_in_venv(self, tmpdir):\n        venv = tmpdir.mkdir(\"venv\").ensure_dir()\n        bindir = venv.join('Scripts' if sys.platform.startswith('win') else 'bin')\n        bindir.mkdir()\n        (bindir / 'activate').ensure()\n\n        assert _in_venv(venv)\n        assert not _in_venv(tmpdir)\n", "    def test_in_venv_true(self, monkeypatch):\n        monkeypatch.setattr(os, \"listdir\", lambda x: [\"Scripts\", \"bin\"])\n        assert _in_venv(py.path.local(\"somepath\"))\n", "    def test_in_virtualenv(self, tmpdir):\n        p = tmpdir.join(\"venv\").ensure(dir=True)\n        p.join(\"bin\").ensure(dir=True)\n        p.join(\"Scripts\").ensure(dir=True)\n        p.join(\"activate\").touch()\n        assert _in_venv(p)\n        assert not _in_venv(tmpdir)\n"], "sample_12": ["    def test_field_renames_with_default_value(self):\n        # Test renaming a field with a default value\n\n        self.assertOperationAttributes(\n            self.get_changes(\n                [self.author_name],\n                [self.author_name_renamed],\n            ),\n            \"testapp\",\n            0,\n            0,\n            name=\"RenameField\",\n            # TODO: Figure out why this doesn't match and fix it.\n            # new_name='name_new',\n            old_name='name',\n            model_name=\"Author\",\n        )\n", "    def test_multiple_fields_same_name_same_app(self):\n        states = [\n            self.make_project_state([self.author_name, self.book]),\n            self.make_project_state([self.author_name_same_field, self.book]),\n        ]\n        changes = self.get_changes(*states)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['AddField'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name', field_type='CharField')\n", "    def test_renamed_field_through_m2m(self):\n        changes = self.get_changes(\n            [self.author_with_m2m, self.publisher],\n            [self.author_with_renamed_m2m_through, self.publisher],\n        )\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, [\n            'RenameField',\n        ])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='publishers',\n                                       field_name='new_publishers')\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, model_name='author',\n                                       reverse_name='author_set')\n\n", "    def test_custom_user_no_inherit(self):\n        before = [\n            self.custom_user,\n        ]\n        after = [\n            self.custom_user_no_inherit,\n        ]\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'thirdapp', 1)\n        self.assertOperationTypes(changes, 'thirdapp', 0, ['CreateModel'])\n\n", "    def test_circular_foreign_key_dependencies(self):\n        before = [\n            self.author,\n            self.knight,\n        ]\n        after = [\n            self.author,\n            self.knight,\n            self.rabbit,\n        ]\n        changes = self.get_changes(before, after)\n\n        self.assertNumberMigrations(changes, \"eggs\", 1)\n\n        self.assertOperationAttributes(changes, \"eggs\", 0, 0, name=\"0001_initial\")\n        self.assertOperationTypes(changes, \"eggs\", 0, [\"CreateModel\"])\n\n        self.assertOperationAttributes(changes, \"eggs\", 0, 0, name=\"0001_initial\")\n        self.assertOperationAttributes(changes, \"eggs\", 0, 0, app_label=\"eggs\")\n        self.assertOperationAttributes(changes, \"eggs\", 0, 0, initial=True)\n        self.assertOperationFieldAttributes(changes, \"eggs\", 0, 0, name=\"knight\", db_column=\"knight_id\", default=None,\n                                            null=True)\n"], "sample_58": ["    def test_runshell_sigint(self):\n        with mock.patch('django.db.backends.postgresql.client.signal.signal') as mock_signal:\n            with mock.patch('django.db.backends.postgresql.client.subprocess.Popen') as mock_popen:\n                mock_popen.return_value.wait.return_value = 0\n                DatabaseClient().runshell([])\n                mock_signal.assert_any_call(signal.SIGINT, signal.SIG_IGN)\n                mock_signal.assert_any_call(signal.SIGINT, mock.ANY)\n", "    def test_runshell_pass_sigint(self):\n        with mock.patch('subprocess.Popen') as mock_popen:\n            mock_popen.return_value.returncode = 0\n            DatabaseClient().runshell([])\n            mock_popen.assert_called_once_with(\n                ['psql'],\n                stdin=subprocess.PIPE,\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                env=None,\n            )\n            # Check that SIGINT is ignored within the runshell method\n            self.assertEqual(signal.getsignal(signal.SIGINT), signal.SIG_IGN)\n", "    def test_runshell_with_signal(self):\n        with mock.patch('subprocess.Popen') as mock_popen:\n            mock_popen.return_value.communicate.return_value = (b'output', b'error')\n            with mock.patch('signal.signal') as mock_signal:\n                DatabaseClient().runshell(['p', 'sql', 'command'])\n                mock_signal.assert_has_calls([\n                    mock.call(signal.SIGINT, signal.SIG_IGN),\n                    mock.call(signal.SIGINT, mock.ANY),\n                ])\n", "    def test_settings_to_cmd_args_env_with_all_options(self):\n        settings = {\n            \"OPTIONS\": {\n                \"passfile\": \"/path/to/passfile\",\n                \"service\": \"my_service\",\n                \"sslmode\": \"require\",\n                \"sslrootcert\": \"/path/to/rootcert\",\n                \"sslcert\": \"/path/to/cert\",\n                \"sslkey\": \"/path/to/key\",\n            },\n            \"HOST\": \"my_host\",\n            \"PORT\": 5432,\n            \"NAME\": \"my_database\",\n            \"USER\": \"my_user\",\n            \"PASSWORD\": \"my_password\",\n        }\n        args, env = self.settings_to_cmd_args_env(settings)\n        expected_args = [\n            \"psql\",\n            \"-U\",\n            \"my_user\",\n            \"-h\",\n            \"my_host\",\n            \"-p\",\n            \"5432\",\n            \"my_database\",\n        ]\n        expected_env = {\n            \"PGPASSWORD\": \"my_password\",\n            \"PGSERVICE\": \"my_service\",\n            \"PGSSLMODE\": \"require\",\n            \"PGSSLROOTCERT\": \"/path/to/rootcert\",\n            \"PGSSLCERT\": \"/path/to/cert\",\n            \"PGSSLKEY\": \"/path/to/key\",\n            \"PGPASSFILE\": \"/path/to/passfile\",\n        }\n        self.assertEqual(args, expected_args)\n        self.assertEqual(env, expected_env)\n", "    def test_runshell_sigint(self):\n        with mock.patch('django.db.backends.postgresql.client.subprocess.Popen') as mock_popen:\n            mock_popen.return_value.communicate.return_value = (b'', b'')\n            with mock.patch('django.db.backends.postgresql.client.signal.signal') as mock_signal:\n                db_client = DatabaseClient(None)\n                db_client.runshell([])\n                mock_signal.assert_called_with(signal.SIGINT, signal.SIG_IGN)\n                mock_signal.assert_called_with(signal.SIGINT, mock.ANY)\n"], "sample_95": ["    def test_skip_on_condition_evaluates_correctly(self, testdir):\n        testdir.create_testfile(\n            \"\"\"\n            import pytest\n\n                pytest.skipif(True, reason=\"skip condition is true\")\n                assert False\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.assert_outcomes(skipped=1)\n", "    def test_evaluate_skip_with_condition(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n                if True:\n                    pytest.skip(\"condition\")\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        assert result.ret == 0\n        result.stdout.fnmatch_lines([\"*SKIP*func*condition*\"])\n\n", "    def test_run_test_with_xfail(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n        import pytest\n\n        @pytest.mark.xfail\n            assert 0 == 1\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        assert result.ret == pytest.ExitCode.XFAIL\n        result.stdout.fnmatch_lines([\"*XFAIL*test_func*\"])\n", "    def test_skip_by_mark_on_function(self, testdir):\n        testdir.create_test_file(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skip\n                assert False\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.assert_outcomes(skipped=1)\n", "    def test_skip_condition_is_evaluated_within_the_scope_of_the_fixture_setup(\n        self, testdir, monkeypatch"], "sample_133": ["def test_codegen_IndexedBase():\n    x, y = symbols('x y')\n    A = IndexedBase('A')\n    expr = A[x] + y\n    routine = make_routine('test', expr)\n\n    # OutputArgument requires an indexed object to be properly defined.\n\n    with raises(CodeGenError):\n        codegen([('test', expr)], 'C', header=False, empty=False)\n\n\n", "def test_codegen_matrix_indexedbase():\n    from sympy.utilities.codegen import CodeGenError\n    x, y = symbols('x y')\n    A = MatrixSymbol('A', 3, 3)\n    expr = A[x, y]\n    # Test that an error is raised when trying to generate code for\n    # a MatrixSymbol with indices that are symbols\n    raises(CodeGenError, lambda: codegen(\n        (str(expr), expr), 'f95'))\n", "def test_codegen_with_indexed_base():\n    x, y = symbols('x y')\n    A = IndexedBase('A')\n    expr = Eq(A[x], x*y)\n\n    routine = make_routine(\"test\", expr)\n\n    code = get_string(CCodeGen().dump_m, [routine])\n    assert \"void test(double *A, double x, double y)\" in code\n    assert \"A[(int)x] = x*y;\" in code\n\n", "def test_codegen_multipleoutputs():\n    x, y = symbols('x y')\n    r1 = make_routine('test', [x*y, x + y], language='F95')\n\n    code = get_string(CCodeGen().dump_c, [r1], 'test', header=False, empty=False).strip()\n    assert code == '#include \"test.h\"\\n' \\\n                   'double test(double x, double y, double *out1, double *out2) {\\n' \\\n                   '  (*out1) = x*y;\\n' \\\n                   '  (*out2) = x + y;\\n' \\\n                   '  return 0;\\n' \\\n                   '}'\n\n", "    def test_codegen_indexed():\n        x, y = symbols('x y')\n        A = MatrixSymbol('A', 3, 3)\n        exprs = [Eq(A[0,0], x*y)]\n        name_expr = [('fcn', exprs)]\n\n        routine = make_routine('fcn', exprs)\n        code = get_string(CCodeGen.dump_c, [routine], header=False, empty=False)\n        assert 'A[0][0] = x*y;' in code\n\n\n\n"], "sample_22": ["    def test_smart_split(self):\n        self.assertEqual(list(text.smart_split(r'This is \"a person\\'s\" test.')),\n                         ['This', 'is', '\"a person\\\\\\'s\"', 'test.'])\n        self.assertEqual(list(text.smart_split(r\"Another 'person\\'s' test.\")),\n                         ['Another', \"'person\\\\'s'\", 'test.'])\n        self.assertEqual(list(text.smart_split(r'A \"\\\"funky\\\" style\" test.')),\n                         ['A', '\"\\\\\"funky\\\\\" style\"', 'test.'])\n", "    def test_slugify_unicode(self):\n        self.assertEqual(text.slugify('Django'), 'django')\n        self.assertEqual(text.slugify('Django Reinhardt'), 'django-reinhardt')\n        self.assertEqual(text.slugify(u'S\u00e3o Paulo'), 'sao-paulo')\n        self.assertEqual(text.slugify(u'Caf\u00e9'), 'cafe')\n        self.assertEqual(text.slugify('\u4f60\u597d\u4e16\u754c'), 'ni-hao-shi-jie')\n", "    def test_slugify_unicode(self):\n        self.assertEqual(text.slugify('Django'), 'django')\n        self.assertEqual(text.slugify('Django Reinhardt'), 'django-reinhardt')\n        self.assertEqual(text.slugify('Caf\u00e9'), 'cafe')\n        self.assertEqual(text.slugify('\u4f60\u597d'), 'ni-hao')\n", "    def test_get_text_list_empty(self):\n        self.assertEqual(text.get_text_list([]), '')\n", "    def test_unescape_entities(self):\n        with ignore_warnings(category=RemovedInDjango40Warning):\n            self.assertEqual(text.unescape_entities('&amp;'), '&')\n            self.assertEqual(text.unescape_entities('&lt;'), '<')\n            self.assertEqual(text.unescape_entities('&gt;'), '>')\n            self.assertEqual(text.unescape_entities('&quot;'), '\"')\n            self.assertEqual(text.unescape_entities('&#39;'), \"'\")\n            self.assertEqual(text.unescape_entities('&#x27;'), \"'\")\n            self.assertEqual(text.unescape_entities('&nbsp;'), ' ')\n            self.assertEqual(text.unescape_entities('&#160;'), ' ')\n            self.assertEqual(text.unescape_entities('&some;'), '&some;')\n"], "sample_129": ["    def test_latex_MatrixSymbol_with_shape(self):\n        A = MatrixSymbol('A', 2, 3)\n        assert latex(A) == r'A_{2\\times3}'\n        assert latex(A[:, 0]) == r'A_{:,0}'\n", "def test_latex_SetExpr():\n    # Testing SetExpr LaTeX printing for intersection, union, and complement\n    A = SetExpr('A')\n    B = SetExpr('B')\n    assert latex(A.intersect(B)) == '\\\\left(A \\\\cap B\\\\right)'\n    assert latex(A.union(B)) == '\\\\left(A \\\\cup B\\\\right)'\n    assert latex(A.complement()) == '\\\\left(\\\\complement A\\\\right)'\n\n", "def test_latex_tensorproduct():\n    A = ImmutableDenseNDimArray([1, 2, 3])\n    B = ImmutableDenseNDimArray([4, 5, 6])\n    C = tensorproduct(A, B)\n    assert latex(C) == r\"\\begin{pmatrix}4 & 5 & 6 \\\\ 8 & 10 & 12 \\\\ 12 & 15 & 18\\end{pmatrix}\"\n", "def test_latex_SetExpr():\n    A = SetExpr(x)\n    assert latex(A) == r\"\\left\\{x\\right\\}\"\n    B = SetExpr(x, y)\n    assert latex(B) == r\"\\left\\{x, y\\right\\}\"\n    C = SetExpr(x, y, z)\n    assert latex(C) == r\"\\left\\{x, y, z\\right\\}\"\n    D = SetExpr(x | y)\n    assert latex(D) == r\"\\left\\{x \\mid y\\right\\}\"\n", "def test_latex_SingularityFunction():\n    assert latex(SingularityFunction(x, 1, 0)) == '\\\\delta(x)'\n    assert latex(SingularityFunction(x, 2, 1)) == '\\\\delta^{(1)}(x)'\n    assert latex(SingularityFunction(x, 3, 2)) == '\\\\delta^{(2)}(x)'\n    assert latex(SingularityFunction(x, 1, 0, 0)) == '\\\\delta(x - 0)'\n    assert latex(SingularityFunction(x, 2, 1, 1)) == '\\\\delta^{(1)}(x - 1)'\n    assert latex(SingularityFunction(x, 3, 2, 2)) == '\\\\delta^{(2)}(x - 2)'\n\n\n"], "sample_83": ["    def test_textreporter_module_separator(\n        reporter: TextReporter, disable: list[str]", "def test_write_message(reporter: TextReporter):\n    \"\"\"Test the write_message method.\"\"\"\n    msg = Message(\n        \"test\",\n        \"C0001\",\n        \"Test message\",\n        (\"my_module.py\", 1, 0, \"MyFunction\", \"funcname\"),\n    )\n    with StringIO() as output:\n        reporter.out = output\n        reporter.write_message(msg)\n        assert output.getvalue() == \"my_module.py:1:0: C0001: Test message (C)\\n\"\n", "    def test_issue_2564(self, reporter: TextReporter, disable: list[str]\n                        ) -> None:\n        # Test the handling of messages with no module\n        with redirect_stdout(StringIO()) as stdout:\n            linter = PyLinter()\n            linter.set_reporter(reporter)\n            linter.disable(disable)\n            checkers.BaseChecker.msg_store = []\n\n            linter.msg.append(Message(\n                'test',\n                'message without module',\n                'C0001',\n                1,\n                1,\n                None,\n                'test.py',\n            ))\n\n            linter.process([None])\n\n        output = stdout.getvalue()\n        assert \"************* \" in output\n        assert \"message without module\" in output\n\n", "def test_colorized_text_reporter_with_color_mapping(reporter: TextReporter, disable: list[str]) -> None:\n    linter = PyLinter()\n    linter.disable(disable)\n    linter.set_reporter(ColorizedTextReporter)\n\n    output = StringIO()\n    with redirect_stdout(output):\n        linter.process_module(\"test_file.py\", \"\")\n\n    messages = [\n        Message(\n            \"test_file.py\", 1, 0, \"C0001\", \"test_message\", \"info\", HIGH, \"test_message\",\n        ),\n        Message(\n            \"test_file.py\", 2, 0, \"W0702\", \"test_message\", \"warning\", HIGH, \"test_message\",\n        ),\n        Message(\n            \"test_file.py\", 3, 0, \"E1101\", \"test_message\", \"error\", HIGH, \"test_message\",\n        ),\n    ]\n\n    for msg in messages:\n        linter.add_message(msg)\n\n    output_value = output.getvalue()\n\n    assert \"test_message\" in output_value\n    assert \"test_message\" in output_value\n    assert \"test_message\" in output_value\n", "def test_colorized_reporter_handles_unknown_symbol(reporter, disable):\n    \"\"\"Test colorized reporter with unknown symbol.\"\"\"\n    linter = PyLinter()\n    linter.set_reporter(reporter)\n    linter.disable(*disable)\n    output = StringIO()\n    linter.set_output(output)\n    msg = Message(\n        msg_id=\"unknown\", Symbol=\"?\",\n        line=1, column=1, path=\"test.py\",\n        obj=[\n            FileItem(name=\"test.py\",\n                     module=\"test\", path=\"test.py\")\n        ]\n    )\n    linter.add_message(msg)\n    linter.reporter.handle_message(msg)\n    output.seek(0)\n    output_str = output.read()\n    assert \"?\" in output_str\n"], "sample_122": ["    def test_sparse_row_swap():\n        M = SparseMatrix([[1, 2], [3, 4]])\n        M.row_swap(0, 1)\n        assert M == SparseMatrix([[3, 4], [1, 2]])\n\n", "def test_SparseMatrix_row_swap():\n    M = SparseMatrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    M.row_swap(0, 1)\n    assert M == SparseMatrix([[4, 5, 6], [1, 2, 3], [7, 8, 9]])\n", "def test_SparseMatrix_row_op():\n    M = SparseMatrix([[1, 2], [3, 4]])\n    M.row_op(0, lambda v, j: v + 1)\n    assert M == SparseMatrix([[2, 3], [3, 4]])\n", "def test_SparseMatrix_row_swap():\n    S = SparseMatrix.eye(3)\n    S[2, 1] = 2\n    S.row_swap(1, 0)\n    assert S == Matrix([[0, 1, 0], [1, 0, 0], [0, 2, 1]])\n", "def test_row_op_sparse():\n    M = SparseMatrix.eye(3)\n    M[0, 1] = -1\n    M.row_op(1, lambda v, j: v + 2*M[0, j])\n    assert M == Matrix([\n        [1, -1, 0],\n        [2, 0, 0],\n        [0, 0, 1]])\n"], "sample_85": ["def test_log_records_include_levelname(caplog):\n    caplog.set_level(logging.DEBUG)\n    logging.debug(\"this is a debug message\")\n    logging.info(\"this is an info message\")\n    assert caplog.record_tuples == [\n        (\"root\", logging.DEBUG, \"this is a debug message\"),\n        (\"root\", logging.INFO, \"this is an info message\"),\n    ]\n", "    def test_log_capture_at_level(\n        testdir, capsys", "    def test_log_capture_with_log_file(testdir, caplog):\n        testdir.makefile('.py', \"\"\"\n            import logging\n            import pytest\n\n            log = logging.getLogger(__name__)\n\n                log.info('hello from test_foo')\n        \"\"\")\n        result = testdir.runpytest('--log-file=test.log')\n        assert result.ret == 0\n        assert os.path.exists('test.log')\n        with open('test.log', 'r', encoding='utf-8') as f:\n            lines = f.readlines()\n        assert len(lines) == 1\n        assert 'hello from test_foo' in lines[0]\n", "    def test_log_record_tuples(caplog):\n        caplog.set_level(logging.DEBUG)\n        logging.debug(\"This is a debug message\")\n        logging.info(\"This is an info message\")\n        logging.warning(\"This is a warning message\")\n        assert caplog.record_tuples == [\n            ('root', logging.DEBUG, 'This is a debug message'),\n            ('root', logging.INFO, 'This is an info message'),\n            ('root', logging.WARNING, 'This is a warning message')\n        ]\n", "    def test_log_capture_with_different_levels(\n        caplog, tmpdir, monkeypatch"], "sample_127": ["def test_latex_tensor_product():\n    A = ImmutableDenseNDimArray([1, 2, 3], (3,))\n    B = ImmutableDenseNDimArray([4, 5, 6], (3,))\n    C = tensorproduct(A, B)\n    assert latex(C) == r'\\begin{bmatrix}4 & 5 & 6 \\\\ 8 & 10 & 12 \\\\ 12 & 15 & 18 \\end{bmatrix}'\n\n", "def test_latex_Heaviside():\n    assert latex(Heaviside(x)) == '\\\\operatorname{H}\\\\left(x \\\\right)'\n\n\n", "def test_latex_tensor_product():\n    A = ImmutableDenseNDimArray([[1, 2], [3, 4]])\n    B = ImmutableDenseNDimArray([[5, 6], [7, 8]])\n    C = tensorproduct(A, B)\n    assert latex(C) == r'\\begin{bmatrix} 5 & 6 & 10 & 12 \\\\ 7 & 8 & 14 & 16 \\\\ 15 & 18 & 30 & 36 \\\\ 21 & 24 & 42 & 48 \\end{bmatrix}'\n\n", "def test_MatrixSymbol():\n    A = MatrixSymbol('A', 2, 3)\n    assert latex(A) == r'A'\n    assert latex(A[0, 1]) == r'A_{0,1}'\n    assert latex(A[:, 1]) == r'A_{:,1}'\n\n", "def test_latex_MatrixSymbol():\n    A = MatrixSymbol('A', 2, 3)\n    assert latex(A) == r'A_{2 \\times 3}'\n\n"], "sample_48": ["    def test_add_expression_index(self):\n        # Create a model with a CharField\n        with atomic():\n            class Food(models.Model):\n                name = models.CharField(max_length=50)\n            \n        # Create a migration to add an index on the length of the name field\n        new_state = self._get_state()\n        with connection.cursor() as cursor:\n            AddIndex(\n                'food',\n                models.Index(\n                    expressions=[Abs(models.F('name'))],\n                    name='food_name_length_idx'\n                ),\n            )\n        # Apply the migration\n        self.migrate_and_assert_state(new_state)\n        \n        # Check for the index creation in the database\n        cursor.execute(\n            \"\"\"\n            SELECT name FROM sqlite_master WHERE type='index' AND tbl_name='food';\n            \"\"\"\n        )\n        self.assertIn(('food_name_length_idx',), cursor.fetchall())\n\n", "    def test_add_index(self):\n        with atomic(using=self.connection.alias), connection.cursor() as cursor:\n            # Check initial state\n            cursor.execute(\"SELECT COUNT(*) FROM sqlite_master WHERE type='index' AND tbl_name='test_unicodemodel'\")\n            self.assertEqual(cursor.fetchone()[0], 0)\n\n            # Run operation\n            migration = Migration(\n                'test',\n                [AddIndex('UnicodeModel', models.Index(fields=['name']))]\n            )\n            self.apply_migration(migration)\n\n            # Check index is created\n            cursor.execute(\"SELECT COUNT(*) FROM sqlite_master WHERE type='index' AND tbl_name='test_unicodemodel'\")\n            self.assertEqual(cursor.fetchone()[0], 1)\n\n            # Run backwards operation\n            self.migrate_backwards(migration)\n\n            # Check index is gone\n            cursor.execute(\"SELECT COUNT(*) FROM sqlite_master WHERE type='index' AND tbl_name='test_unicodemodel'\")\n            self.assertEqual(cursor.fetchone()[0], 0)\n", "    def test_alter_unique_together(self):\n        \"\"\"\n        Tests altering unique_together\n        \"\"\"\n        with connection.cursor() as cursor:\n            cursor.execute(\"CREATE TABLE \" + self.table_name + \" (id INTEGER PRIMARY KEY, name VARCHAR(100), ingredient TEXT)\")\n\n        class Migration(migrations.Migration):\n            dependencies = []\n            operations = [\n                migrations.CreateModel(\n                    name='Food',\n                    fields=[\n                        ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                        ('name', models.CharField(max_length=100)),\n                        ('ingredient', models.TextField()),\n                    ],\n                ),\n            ]\n\n        run_migrations(Migration, self.database)\n\n        class Food(models.Model):\n            name = models.CharField(max_length=100)\n            ingredient = models.TextField()\n\n        with transaction.atomic():\n            Food.objects.create(name='Pizza', ingredient='Cheese')\n            Food.objects.create(name='Burger', ingredient='Beef')\n\n            with self.assertRaises(IntegrityError):\n                Food.objects.create(name='Pizza', ingredient='Beef')\n\n        class Migration(migrations.Migration):\n            dependencies = [\n                ('test_app', '0001_initial'),\n            ]\n            operations = [\n                migrations.AlterUniqueTogether(\n                    name='food',\n                    unique_together={('name', 'ingredient')},\n                ),\n            ]\n\n        run_migrations(Migration, self.database)\n\n        with transaction.atomic():\n            with self.assertRaises(IntegrityError):\n                Food.objects.create(name='Pizza', ingredient='Cheese')\n", "    def test_add_unique_constraint_deferrable_initially_immediate(self):\n        # Tests that adding a unique constraint with deferrable and\n        # initially immediate behaves correctly.\n        operation = AddConstraint(\n            'UnicodeModel',\n            models.UniqueConstraint(\n                fields=['name'],\n                name='unique_name',\n                deferrable=models.Deferrable.DEFERRED,\n                immediate=True,\n            )\n        )\n        with atomic(using=self.connection.alias):\n            with CaptureQueriesContext(connection) as captured_queries:\n                self.apply_operation(operation)\n        self.assertQuerySetEqual(captured_queries, [\n            'ALTER TABLE \"%s\".\"unicodemodel\" ADD CONSTRAINT \"unique_name\" UNIQUE DEFERRABLE INITIALLY IMMEDIATE (\"name\")' % self.quote_name,\n        ])\n\n", "    def test_alter_unique_together(self):\n        with atomic(using=self.test_db_name), transaction.atomic():\n            with CaptureQueriesContext(connection) as queries:\n                # Create a model with unique_together\n                self.create_model(\n                    'test_app.Book',\n                    fields=[\n                        ('name', models.CharField(max_length=100)),\n                        ('author', models.CharField(max_length=100)),\n                    ],\n                    options={'unique_together': [('name', 'author')]},\n                )\n\n                # Apply the migration\n                self.migrate('test_app')\n\n                # Check the database state\n                self.assertModelFields('test_app.Book', ['name', 'author'])\n                self.assertConstraintType(\n                    'test_app_book', 'name', 'author', 'UNIQUE',\n                )\n                # Make sure we only executed one SQL statement.\n                self.assertEqual(len(queries), 1)\n\n                # Alter the unique_together\n\n                operation = AlterUniqueTogether('Book', unique_together=[\n                    ('name', 'author', 'genre'),\n                ])\n\n                operation.state_forwards(self.test_app_label, self.project_state)\n                operation.database_forwards(self.test_app_label, self.schema_editor, self.project_state, ProjectState.from_apps(self.app_registry))\n\n                self.assertConstraintType(\n                    'test_app_book', 'name', 'author', 'genre', 'UNIQUE',\n                )\n"], "sample_65": ["    def test_join_empty(self):\n        template = '{{ a|join:\", \" }}'\n        with self.assertTemplateResult(template, ''):\n            pass\n\n", "    def test_join_with_empty_list(self):\n        self.assertEqual(render_template('join01', {'a': []}), '')\n\n", "    def test_join_empty_list(self):\n        output = self.engine.render_to_string('join01', {'a': []})\n        self.assertEqual(output, '')\n", "    def test_join_with_safe(self):\n        output = self.engine.render_to_string('join01', {'a': mark_safe('<b>a</b>, <b>b</b>')})\n        self.assertEqual(output, '<b>a</b>, <b>b</b>')\n", "    def test_join_empty_list(self):\n        self.assertEqual(\n            self.engine.render_to_string(\"join01\", {\"a\": []}),\n            \"\",\n        )\n"], "sample_101": ["    def test_pipeline_memory_with_transformers_that_dont_implement_inverse():\n        # Test that Pipeline works with transformers that don't implement\n        # inverse_transform, but still have fit and transform methods.\n\n        X = np.array([[1, 2], [3, 4]])\n        pipeline = Pipeline([('trans', NoInvTransf()), ('clf', LogisticRegression())])\n        pipeline.fit(X, [0, 1])\n        # Should not raise an error, even though inverse_transform is not\n        # implemented\n        pipeline.predict(X)\n\n", "    def test_pipeline_with_memory_and_fit_params(self):\n        # Test that fit_params are correctly passed to transformers in a pipeline\n        # with memory\n\n        memory = Memory(location=mkdtemp())\n        X = np.array([[1, 2], [2, 3], [3, 4]])\n        y = np.array([0, 1, 0])\n\n        # Create a Pipeline with a transformer that takes fit_params\n        pipeline = Pipeline(\n            memory=memory,\n            steps=[\n                ('transformer', TransfFitParams()),\n                ('classifier', LogisticRegression())\n            ]\n        )\n\n        # Fit the pipeline and check that fit_params are stored\n        pipeline.fit(X, y, transformer__fit_params={'sample_weight': np.array([1, 2, 3])})\n        assert_equal(pipeline.named_steps.transformer.fit_params, {'sample_weight': np.array([1, 2, 3])})\n\n        # Check that fit_params are used when loading from cache\n        pipeline.fit(X, y)\n        assert_equal(pipeline.named_steps.transformer.fit_params, {'sample_weight': np.array([1, 2, 3])})\n\n\n", "def test_pipeline_with_transformer_that_returns_none():\n    \"\"\"Test pipeline with transformer returning None.\"\"\"\n    # Regression test for issue #11723\n    pipe = Pipeline([('a', DummyTransf()), ('b', LogisticRegression())])\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n\n    with pytest.raises(TypeError):\n        pipe.fit(X, y)\n\n\n", "    def test_pipeline_with_passthrough_estimator_and_memory(self):\n        # Test pipeline containing a PassThrough estimator and caching\n\n        # Create a pipeline with a PassThrough estimator\n        passthrough = 'passthrough'\n        pipeline = Pipeline([\n            ('scaler', StandardScaler()),\n            (passthrough, 'passthrough'),\n            ('classifier', LogisticRegression())\n        ])\n\n        # Create a memory cache\n        memory = Memory(location=\".\", verbose=0)\n\n        # Fit the pipeline with caching\n        pipeline.fit(X, y, memory=memory)\n\n        # Second fit should use the cached result\n        start_time = time.time()\n        pipeline.fit(X, y, memory=memory)\n        end_time = time.time()\n\n        # Assert that the second fit is significantly faster than the first\n        assert end_time - start_time < 0.1\n\n", "    def test_pipeline_with_memory_cached_transformed_data():\n        # Test that when a pipeline is fitted with memory caching enabled,\n        # the transformed data is cached and reused on subsequent calls to\n        # fit.\n\n        # Create a pipeline with a transformer that stores the column means\n        pipe = Pipeline([\n            ('transformer', DummyTransf()),\n            ('classifier', SVC())\n        ], memory=Memory(location=mkdtemp()))\n\n        # Generate some random data\n        X = np.random.rand(100, 10)\n        y = np.random.randint(0, 2, size=100)\n\n        # Fit the pipeline for the first time\n        pipe.fit(X, y)\n\n        # Store the initial timestamp from the transformer\n        initial_timestamp = pipe.named_steps['transformer'].timestamp_\n\n        # Fit the pipeline again\n        pipe.fit(X, y)\n\n        # The timestamp should not have changed, indicating cached data\n        assert pipe.named_steps['transformer'].timestamp_ == initial_timestamp\n\n        # Clean up the temporary directory\n        shutil.rmtree(pipe.memory.location)\n\n"], "sample_51": ["    def test_serve_with_if_modified_since(self):\n        test_file = path.join(media_dir, \"test.txt\")\n        with open(test_file, \"w\") as f:\n            f.write(\"Test file contents\")\n        response = self.client.get(f\"/{self.prefix}/test.txt\")\n        self.assertEqual(response.status_code, 200)\n        last_modified = response[\"Last-Modified\"]\n        # Request the file again with If-Modified-Since header\n        response = self.client.get(\n            f\"/{self.prefix}/test.txt\",\n            HTTP_IF_MODIFIED_SINCE=last_modified,\n        )\n        self.assertEqual(response.status_code, 304)\n\n\n", "    def test_serve_not_modified(self):\n        response = self.client.get(\n            f\"/{self.prefix}/example.txt\",\n            HTTP_IF_MODIFIED_SINCE=http_date(\n                path.getmtime(path.join(media_dir, \"example.txt\"))\n            ),\n        )\n        self.assertEqual(response.status_code, 304)\n        self.assertEqual(response.__class__, HttpResponseNotModified)\n", "    def test_serve_not_modified(self):\n        # Simulate a request with If-Modified-Since header\n        request = self.client.get(\n            \"/media/test.txt\",\n            HTTP_IF_MODIFIED_SINCE=http_date(path.getmtime(media_dir / \"test.txt\")),\n        )\n        self.assertEqual(request.status_code, 304)\n        self.assertIsInstance(request, HttpResponseNotModified)\n", "    def test_serve_with_if_modified_since(self):\n        response = self.client.get(\n            f\"/{self.prefix}/test.txt\",\n            HTTP_IF_MODIFIED_SINCE=http_date(\n                path.getmtime(path.join(media_dir, \"test.txt\"))\n            ),\n        )\n        self.assertEqual(response.status_code, 304)\n", "    def test_directory_index_with_template(self):\n        response = self.client.get(\"/\" + self.prefix + \"/test_directory/\")\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(\n            response.content.decode(\"utf-8\").strip(),\n            \"\"\"\n            <!DOCTYPE html>\n            <html lang=\"en\">\n              <head>\n                <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\">\n                <meta http-equiv=\"Content-Language\" content=\"en-us\">\n                <meta name=\"robots\" content=\"NONE,NOARCHIVE\">\n                <title>Index of /test_directory/</title>\n              </head>\n              <body>\n                <h1>Index of /test_directory/</h1>\n                <ul>\n                  <li><a href=\"../\">../</a></li>\n                  <li><a href=\"file.txt\">file.txt</a></li>\n                </ul>\n              </body>\n            </html>\n            \"\"\".strip(),\n        )\n\n\n\n"], "sample_86": ["    def test_junitxml_failure_with_teardown(testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n                assert False\n                assert False\n\n            @pytest.fixture(scope='function', autouse=True)\n                assert False\n\n                pass\n        \"\"\"\n        )\n        result, dom = runandparse(testdir)\n        assert result.ret == 1\n\n        testsuite = dom.find_first_by_tag(\"testsuite\")\n        assert testsuite[\"name\"] == \"pytest\"\n        assert int(testsuite[\"failures\"]) == 3\n        assert int(testsuite[\"errors\"]) == 0\n        assert int(testsuite[\"skipped\"]) == 0\n\n        # check for the failing testcases\n\n        testcases = testsuite.find_by_tag(\"testcase\")\n\n        assert len(testcases) == 3\n\n        test1 = testcases[0]\n        assert test1[\"classname\"] == \"test_failing\"\n\n        assert test1.find_first_by_tag(\"failure\").text.startswith(\n            \"assert False\"\n        )\n        test2 = testcases[1]\n        assert test2[\"classname\"] == \"test_teardown_failing\"\n        assert test2.find_first_by_tag(\"failure\").text.startswith(\n            \"assert False\"\n        )\n\n        test3 = testcases[2]\n        assert test3[\"classname\"] == \"test_passing\"\n        assert test3.find_first_by_tag(\"failure\") is None\n", "    def test_junitxml_properties(testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"a, b\", [(1, 2), (3, 4)])\n                record_property(\"sum\", a + b)\n        \"\"\"\n        )\n        result, dom = runandparse(testdir)\n        testcase = dom.find_first_by_tag(\"testcase\")\n        properties = testcase.find_by_tag(\"property\")\n        assert len(properties) == 1\n        assert properties[0][\"name\"] == \"sum\"\n        assert properties[0].text == \"3\"\n\n", "    def test_junit_multiple_reports_same_nodeid_with_teardown_failure(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"i\", range(2))\n                if i == 0:\n                    assert 0\n                assert 1\n        \"\"\"\n        )\n        result, xmldoc = runandparse(testdir)\n        assert result.ret == 1\n        test_case = xmldoc.find_first_by_tag(\"testcase\")\n        assert_attr(test_case, classname=\"test_func\", name=\"test_func[0]\")\n        failure = test_case.find_first_by_tag(\"failure\")\n        assert failure is not None\n        failure = test_case.find_first_by_tag(\"error\")\n        assert failure is not None\n", "    def test_xml_escaping(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n                print(\"<hello&world>\")\n        \"\"\"\n        )\n        result, dom = runandparse(testdir)\n        assert dom.find_first_by_tag(\"testcase\").text == \"<hello&world>\"\n", "    def test_junit_capture_stderr(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import sys\n\n                print(\"stderr output\", file=sys.stderr)\n                assert 0\n        \"\"\"\n        )\n        result, dom = runandparse(testdir, p)\n        assert result.ret == 1\n        testcase = dom.find_first_by_tag(\"testcase\")\n        failure = testcase.find_first_by_tag(\"failure\")\n        system_err = failure.find_first_by_tag(\"system-err\")\n        assert system_err.text == \"stderr output\\n\"\n"], "sample_158": ["    def test_units_non_prefixed():\n        assert SI.get_units_non_prefixed() == {meter, kilogram, second, ampere, kelvin, mole, candela}\n", "def test_quantity_scale_factor():\n    x = Quantity(\"x\", \"m\")\n    assert SI.get_quantity_scale_factor(x) == 1\n    assert SI.get_quantity_scale_factor(x*2) == 2\n    assert SI.get_quantity_scale_factor(x/2) == 0.5\n    assert SI.get_quantity_scale_factor(x**2) == 1\n    assert SI.get_quantity_scale_factor(2*x) == 2\n\n", "def test_UnitSystem_get_dimensional_expr():\n    x = Symbol('x')\n    t = Symbol('t')\n    v = Quantity('v', SI.velocity)\n    u = SI.velocity\n\n    assert SI.get_dimensional_expr(v) == SI.velocity\n\n    assert SI.get_dimensional_expr(x*v*t) == SI.velocity\n\n    assert SI.get_dimensional_expr(v**2) == SI.acceleration\n\n    assert SI.get_dimensional_expr(Add(v, v)) == SI.velocity\n\n    assert SI.get_dimensional_expr(diff(x*v, t)) == SI.acceleration\n\n    assert SI.get_dimensional_expr(sin(v)) == S.One\n", "    def test_derived_units(self):\n        m = meter\n        kg = SI.kilogram\n        s = second\n        A = ampere\n        K = kelvin\n        mol = mole\n        cd = candela\n        joule = kg*m**2/s**2\n        watt = joule/s\n        newton = kg*m/s**2\n\n        assert SI.get_quantity_dimension(joule) == energy\n        assert SI.get_quantity_dimension(watt) == energy/time\n        assert SI.get_quantity_dimension(newton) == force\n\n\n\n", "def test_unit_system_get_dimensional_expr():\n    t = SI.get_quantity_dimension(meter)\n    assert t == Dimension(length)\n\n    q = Quantity(1, meter)\n    assert SI.get_dimensional_expr(q) == Dimension(length)\n\n    assert SI.get_dimensional_expr( meter * meter * second) == Dimension(length ** 2 * time)\n\n    assert SI.get_dimensional_expr(q * q) == Dimension(length**2)\n\n    assert SI.get_dimensional_expr(q + q) == Dimension(length)\n\n"], "sample_36": ["    def test_q_negation(self):\n        q = Q(field1=1)\n        self.assertEqual(str(q), 'field1 = 1')\n        q = ~q\n        self.assertEqual(str(q), 'NOT (field1 = 1)')\n        q = Q(field1=1) & Q(field2=2)\n        self.assertEqual(str(q), '(field1 = 1 AND field2 = 2)')\n        q = ~q\n        self.assertEqual(str(q), 'NOT (field1 = 1 AND field2 = 2)')\n        q = Q(field1=1) | Q(field2=2)\n        self.assertEqual(str(q), '(field1 = 1 OR field2 = 2)')\n        q = ~q\n        self.assertEqual(str(q), 'NOT (field1 = 1 OR field2 = 2)')\n\n", "    def test_q_default_connector(self):\n        q = Q(field1=1) | Q(field2=2)\n        self.assertEqual(q.connector, Q.OR)\n", "    def test_q_and_parenthesis(self):\n        q = (Q(a=1) & Q(b=2)) | Q(c=3)\n        self.assertEqual(q.deconstruct()[2], {'_connector': Q.OR})\n", "    def test_q_and_or_empty(self):\n        q1 = Q()\n        q2 = Q(pk=1)\n        self.assertEqual(q1 & q2, q2)\n        self.assertEqual(q2 & q1, q2)\n        self.assertEqual(q1 | q2, q2)\n        self.assertEqual(q2 | q1, q2)\n", "    def test_q_not(self):\n        q = Q(name='test')\n        self.assertEqual(str(Q(~q)), 'NOT (name = test)')\n"], "sample_17": ["    def test_test_db_signature_with_different_host(self):\n        connection = get_connection_copy()\n        connection.settings_dict['HOST'] = 'different_host'\n        creation = BaseDatabaseCreation(connection)\n        self.assertEqual(\n            creation.test_db_signature(),\n            (\n                'different_host',\n                connection.settings_dict['PORT'],\n                connection.settings_dict['ENGINE'],\n                TEST_DATABASE_PREFIX + connection.settings_dict['NAME'],\n            ),\n        )\n\n", "    def test_test_db_signature(self):\n        test_connection = get_connection_copy()\n        creation = BaseDatabaseCreation(test_connection)\n\n        original_settings = copy.deepcopy(test_connection.settings_dict)\n        creation.test_db_signature()  # Ensure it doesn't raise\n\n        # Check that the signature includes relevant database details\n        self.assertIn(original_settings['HOST'], creation.test_db_signature())\n        self.assertIn(original_settings['PORT'], creation.test_db_signature())\n        self.assertIn(original_settings['ENGINE'], creation.test_db_signature())\n        self.assertIn(\n            TEST_DATABASE_PREFIX + original_settings['NAME'],\n            creation.test_db_signature(),\n        )\n", "    def test_test_db_signature(self):\n        # Make sure test_db_signature returns a tuple.\n        connection = get_connection_copy()\n        creation = BaseDatabaseCreation(connection)\n        signature = creation.test_db_signature()\n        self.assertIsInstance(signature, tuple)\n\n        # Make sure the tuple contains the expected elements.\n        self.assertEqual(len(signature), 4)\n        self.assertIn(connection.settings_dict['HOST'], signature)\n        self.assertIn(connection.settings_dict['PORT'], signature)\n        self.assertIn(connection.settings_dict['ENGINE'], signature)\n        self.assertIn(TEST_DATABASE_PREFIX + connection.settings_dict['NAME'], signature)\n", "    def test_test_db_signature(self):\n        connection = get_connection_copy()\n        original_settings = connection.settings_dict.copy()\n        creation = BaseDatabaseCreation(connection)\n\n        signature = creation.test_db_signature()\n\n        # Modify a database setting and check if the signature changes.\n        connection.settings_dict['NAME'] = 'modified_name'\n        self.assertNotEqual(creation.test_db_signature(), signature)\n\n        # Restore the original settings.\n        connection.settings_dict = original_settings\n        self.assertEqual(creation.test_db_signature(), signature)\n", "    def test_test_db_signature(self):\n        connection = get_connection_copy()\n        creation = BaseDatabaseCreation(connection)\n        original_settings = connection.settings_dict.copy()\n        test_db_alias = connection.alias\n        signature = creation.test_db_signature()\n        self.assertEqual(signature, (\n            original_settings['HOST'],\n            original_settings['PORT'],\n            original_settings['ENGINE'],\n            f'{TEST_DATABASE_PREFIX}{original_settings[\"NAME\"]}',\n        ))\n\n        # Change some settings and ensure the signature is recomputed\n        original_settings['HOST'] = 'new_host'\n        connection.settings_dict = original_settings\n        new_signature = creation.test_db_signature()\n        self.assertEqual(new_signature, (\n            'new_host',\n            original_settings['PORT'],\n            original_settings['ENGINE'],\n            f'{TEST_DATABASE_PREFIX}{original_settings[\"NAME\"]}',\n        ))\n\n        # Reset settings\n        connection.settings_dict = original_settings\n        self.assertEqual(creation.test_db_signature(), signature)"], "sample_43": ["    def test_autocomplete_view_permission_denied_no_search_fields(self):\n        with model_admin(\n            Answer,\n            admin.ModelAdmin\n        ):\n            response = self.client.get(self.url, {\n                'app_label': Answer._meta.app_label,\n                'model_name': Answer._meta.model_name,\n                'field_name': 'question',\n                'term': 'test',\n            })\n            self.assertEqual(response.status_code, 404)\n", "    def test_autocomplete_permission_denied_invalid_field(self):\n        with override_settings(ROOT_URLCONF='tests.urls'):\n            with model_admin(Answer, AnswerAdmin, admin_site):\n                response = self.client.get(\n                    self.url,\n                    {'app_label': Answer._meta.app_label,\n                     'model_name': Answer._meta.model_name,\n                     'field_name': 'nonexistent_field',\n                     'term': 'test',\n                     },\n                    HTTP_AUTHORIZATION=self.get_auth_header(self.user),\n                )\n            self.assertEqual(response.status_code, 403)\n", "    def test_permission_denied_for_nonexistent_model(self):\n        with model_admin(\n            Toy,\n            ToyAdmin,\n        ):\n            with self.assertRaises(Http404):\n                self.client.get(self.url, {'term': 'foo', **self.opts})\n", "    def test_invalid_related_field(self):\n        with model_admin(\n            Answer,\n            AnswerAdmin,\n            admin_site=admin.AdminSite(name='invalid_admin'),\n        ):\n            response = self.client.get(self.url, data={\n                'app_label': Answer._meta.app_label,\n                'model_name': Answer._meta.model_name,\n                'field_name': 'invalid_field',\n                'term': 'foo',\n            })\n            self.assertEqual(response.status_code, 403)\n", "    def test_permission_denied_on_unregistered_model(self):\n        with model_admin(\n            Employee,\n            admin.ModelAdmin,\n            admin_site=site,\n        ):\n            request = self.factory.get(\n                self.url,\n                data={\n                    'app_label': Employee._meta.app_label,\n                    'model_name': Employee._meta.model_name,\n                    'field_name': 'name',\n                    'term': 'foo',\n                },\n            )\n            request.user = self.user\n\n            with self.assertRaises(PermissionDenied):\n                AutocompleteJsonView.as_view(**self.as_view_args)(request)\n"], "sample_53": ["    def test_circular_fk_migration_creation(self):\n        \"\"\"\n        Checks that a migration is created correctly when there's a circular\n        foreign key relationship.\n        \"\"\"\n        before = self.make_project_state(\n            [\n                self.knight,\n                self.rabbit,\n            ]\n        )\n\n        # No initial migrations exist\n        self.assertNumberMigrations(self.get_changes(before, before), \"eggs\", 0)\n\n        after = self.make_project_state(\n            [\n                self.knight,\n                self.rabbit,\n            ]\n        )\n        # Add a new rabbit, creating a circular dependency\n        after.models[\"eggs\"].append(\n            ModelState(\n                \"eggs\",\n                \"Rabbit\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\"knight\", models.ForeignKey(\"eggs.Knight\", models.CASCADE)),\n                    (\"parent\", models.ForeignKey(\"eggs.Rabbit\", models.CASCADE)),\n                ],\n                {\n                    \"unique_together\": {(\"parent\", \"knight\")},\n                    \"indexes\": [\n                        models.Index(\n                            fields=[\"parent\", \"knight\"],\n                            name=\"rabbit_circular_fk_index\",\n                        )\n                    ],\n                },\n            )\n        )\n\n        changes = self.get_changes(before, after)\n\n        self.assertNumberMigrations(changes, \"eggs\", 1)\n        self.assertOperationTypes(changes, \"eggs\", 0, [\"CreateModel\"])\n\n", "    def test_remove_field_with_default(self):\n        before = [\n            self.author_with_field_default,\n        ]\n        after = [\n            self.author_with_field_removed,\n        ]\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertOperationTypes(changes, \"testapp\", 0, [\"RemoveField\"])\n        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n\n", "    def test_rename_fields_with_different_default(self):\n        before = [\n            self.author_with_name,\n            self.book,\n        ]\n        after = [\n            self.ModelState(\n                \"testapp\",\n                \"Author\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\n                        \"renamed_name\",\n                        models.CharField(max_length=200, default=\"John Doe\"),\n                    ),\n                ],\n            ),\n            self.book,\n        ]\n\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertOperationTypes(changes, \"testapp\", 0, [\"RenameField\"])\n        self.assertOperationAttributes(\n            changes, \"testapp\", 0, 0, name=\"name\", renamed_name=\"renamed_name\"\n        )\n\n\n\n", "    def test_remove_empty_migration_with_dependency(self):\n        before = [self.author, self.book_with_author_renamed]\n        after = [\n            self.author_renamed,\n            self.book_with_author_renamed.clone(\n                dependencies=[(\"testapp\", \"RenameAuthor\")]\n            ),\n        ]\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, \"testapp\", 2)\n        self.assertMigrationDependencies(\n            changes, \"testapp\", 1, [(\"testapp\", \"RenameAuthor\")]\n        )\n        self.assertOperationTypes(changes, \"testapp\", 1, [\"RenameModel\"])\n\n\n\n", "    def test_alter_unique_together(self):\n        before = self.make_project_state(\n            [self.book_unique_together, self.author_with_pk]\n        )\n        after = self.make_project_state(\n            [self.book_unique_together_changed, self.author_with_pk]\n        )\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, \"otherapp\", 1)\n        self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterUniqueTogether\"])\n        self.assertOperationAttributes(\n            changes, \"otherapp\", 0, 0, name=\"0002_alter_book_unique_together\"\n        )\n"], "sample_105": ["    def test_voting_regressor_with_sample_weight(self):\n        # Check that sample_weight is passed to base estimators\n        clf1 = LinearRegression()\n        clf2 = DummyRegressor(strategy=\"mean\")\n        vr = VotingRegressor([('lr', clf1), ('dr', clf2)])\n\n        sample_weight = np.ones(len(y_r))\n        sample_weight[0] = 2\n        vr.fit(X_r, y_r, sample_weight=sample_weight)\n        # Check if estimators were fitted with sample_weight\n        assert hasattr(clf1, 'sample_weight_')\n\n        # Check if prediction is correct with sample_weight\n        vr_pred = vr.predict(X_r)\n        # Compare with prediction without sample_weight\n        vr_no_weight = VotingRegressor([('lr', clf1), ('dr', clf2)])\n        vr_no_weight.fit(X_r, y_r)\n        vr_no_weight_pred = vr_no_weight.predict(X_r)\n        assert not np.array_equal(vr_pred, vr_no_weight_pred)\n", "    def test_voting_regressor_gridsearchcv():\n        clf1 = LinearRegression()\n        clf2 = RandomForestRegressor(n_estimators=10, random_state=1)\n        ereg = VotingRegressor([('lr', clf1), ('rf', clf2)])\n        param_grid = {'lr__fit_intercept': [True, False],\n                      'rf__max_depth': [2, 3]}\n        grid = GridSearchCV(ereg, param_grid, cv=3)\n        grid.fit(X_r, y_r)\n\n", "    def test_voting_regressor_with_sample_weights():\n        # Check if sample_weight works correctly with VotingRegressor\n\n        rf = RandomForestRegressor(random_state=0, n_estimators=100)\n        lr = LinearRegression()\n        vr = VotingRegressor([('rf', rf), ('lr', lr)])\n        sample_weight = np.random.rand(len(y_r))\n\n        vr.fit(X_r, y_r, sample_weight=sample_weight)\n        y_pred = vr.predict(X_r)\n        assert y_pred.shape == y_r.shape\n", "    def test_voting_regressor_empty():\n        # Test with empty list of estimators\n        clf1 = RandomForestRegressor()\n        eclf = VotingRegressor(estimators=[('empty', None)])\n        X_train, X_test, y_train, y_test = train_test_split(X_r, y_r,\n                                                            test_size=0.2)\n        with pytest.raises(ValueError):\n             eclf.fit(X_train, y_train)\n", "    def test_voting_classifier_predict_proba_not_fitted(self):\n        clf1 = LogisticRegression()\n        clf2 = RandomForestClassifier()\n        eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)])\n        with pytest.raises(NotFittedError):\n            eclf.predict_proba(X)\n"], "sample_102": ["    def test_average_path_length(self):\n        # Check that _average_path_length function performs correctly on\n        # boundary cases and with random data\n        assert_allclose(_average_path_length(np.array([1])), 0.0)\n        assert_allclose(_average_path_length(np.array([2])), 1.0)\n        n_samples_leaf = np.array([3, 4, 5, 6, 7, 8, 9, 10])\n        expected = np.array([2.0 * (np.log(2.0) + np.euler_gamma) -\n                             2.0 * 2.0 / 3.0,\n                            2.0 * (np.log(3.0) + np.euler_gamma) -\n                            2.0 * 3.0 / 4.0,\n                            2.0 * (np.log(4.0) + np.euler_gamma) -\n                            2.0 * 4.0 / 5.0,\n                            2.0 * (np.log(5.0) + np.euler_gamma) -\n                            2.0 * 5.0 / 6.0,\n                            2.0 * (np.log(6.0) + np.euler_gamma) -\n                            2.0 * 6.0 / 7.0,\n                            2.0 * (np.log(7.0) + np.euler_gamma) -\n                            2.0 * 7.0 / 8.0,\n                            2.0 * (np.log(8.0) + np.euler_gamma) -\n                            2.0 * 8.0 / 9.0,\n                            2.0 * (np.log(9.0) + np.euler_gamma) -\n                            2.0 * 9.0 / 10.0])\n        assert_allclose(_average_path_length(n_samples_leaf), expected)\n\n", "    def test_sparse_matrix_input(self):\n        # Test IsolationForest with sparse matrices\n        X_train = csr_matrix(boston.data)\n        y_train = boston.target\n\n        clf = IsolationForest(random_state=0)\n        clf.fit(X_train, y_train)\n\n        # Test predict with a sparse matrix\n        X_test = csc_matrix(boston.data[:50])\n        predictions = clf.predict(X_test)\n\n        assert_equal(predictions.shape, (50,))\n\n        # Test score_samples with a sparse matrix\n        scores = clf.score_samples(X_test)\n        assert_equal(scores.shape, (50,))\n", "def test_iforest_sparse_csc():\n    \"\"\"Check that IsolationForest works with sparse data (csc format).\"\"\"\n    X = csc_matrix(boston.data)\n    y = boston.target\n\n    clf = IsolationForest(random_state=0).fit(X, y)\n    X_transformed = clf.decision_function(X)\n    assert_equal(X_transformed.shape[0], boston.data.shape[0])\n\n", "    def test_sparse_input(self):\n        X_train, X_test, y_train, y_test = train_test_split(\n            iris.data, iris.target, test_size=0.2, random_state=rng\n        )\n        # convert to sparse matrix\n        X_train_sparse = csc_matrix(X_train)\n        clf = IsolationForest(random_state=rng).fit(X_train_sparse)\n        assert_raises(ValueError, clf.predict, X_test)\n", "    def test_sparse_input(self):\n        X = csc_matrix(boston.data[:100])\n        clf = IsolationForest(random_state=rng)\n        clf.fit(X)\n        # Check if prediction works\n        clf.predict(X)\n"], "sample_124": ["    def test_acsch_rewrite():\n        x = Symbol('x')\n        assert acsch(x)._eval_rewrite_as_log() == log(1/x + sqrt(1/x**2 + 1))\n", "def test_acsch_rewrite():\n    x = Symbol('x')\n    assert acsch(x).rewrite(log) == log(1/x + sqrt(1/x**2 + 1))\n", "    def test_asech_eval(self):\n        assert asech(1).evalf() == 0\n        assert asech(S(2)).evalf() == 0.481211825061145\n        assert asech(-sqrt(2)).evalf() == 2.3094010767585\n        assert asech((sqrt(6) - sqrt(2))).evalf() == 0.261799387799149\n        assert asech(S.Infinity) == S.Pi*S.ImaginaryUnit / 2\n", "def test_acsch_rewrite():\n    x = Symbol('x')\n    assert acsch(x)._eval_rewrite_as_log() == log(1/x + sqrt(1/x**2 + 1))\n\n", "def test_acosh_rewrite():\n    x = Symbol('x')\n    assert acosh(x).rewrite(log) == log(x + sqrt(x - 1) * sqrt(x + 1))\n"], "sample_142": ["def test_generate_involutions_empty():\n    assert list(generate_involutions([])) == [[]]\n", "    def test_is_palindromic():\n        assert is_palindromic('racecar')\n        assert is_palindromic([])\n        assert is_palindromic('')\n        assert not is_palindromic('hello')\n        assert not is_palindromic([1, 2, 3])\n        assert is_palindromic([1, 2, 1])\n\n", "def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((1, 2, 3))) == [(1, 2, 3), (-1, 2, 3), (1, -2, 3),\n", "def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((1, -1, 2))) == [(1, -1, 2), (-1, 1, 2), (1, 1, -2), (-1, -1, -2)]\n\n", "    def test_permute_signs():\n        assert list(permute_signs((0, 1, 2))) == [\n        (0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n        assert list(permute_signs((1, 2, 3))) == [\n        (1, 2, 3), (-1, 2, 3), (1, -2, 3), (1, 2, -3),\n        (-1, -2, 3), (-1, 2, -3), (1, -2, -3), (-1, -2, -3)]\n\n"], "sample_112": ["    def test_isotonic_regression_out_of_bounds():\n        # Test out_of_bounds handling on IsotonicRegression\n        X = np.array([1, 2, 3, 4, 5])\n        y = np.array([1, 3, 2, 5, 4])\n\n        iso_reg_nan = IsotonicRegression(out_of_bounds=\"nan\")\n        iso_reg_clip = IsotonicRegression(out_of_bounds=\"clip\")\n\n        iso_reg_nan.fit(X, y)\n        iso_reg_clip.fit(X, y)\n\n        # Test out-of-bounds predictions\n        X_test_below = np.array([0])\n        X_test_above = np.array([6])\n\n        # NaN behavior\n        assert np.isnan(iso_reg_nan.predict(X_test_below)[0])\n        assert np.isnan(iso_reg_nan.predict(X_test_above)[0])\n\n        # Clip behavior\n        assert_allclose(iso_reg_clip.predict(X_test_below),\n                        iso_reg_clip.predict(np.array([1])))\n        assert_allclose(iso_reg_clip.predict(X_test_above),\n                        iso_reg_clip.predict(np.array([5])))\n", "    def test_isotonic_regression_with_sample_weight_increasing_decreasing():\n        # Test isotonic regression with sample weights for both increasing and\n        # decreasing relationships\n        rng = np.random.RandomState(0)\n\n        # Increasing case\n        X = np.sort(rng.rand(10))\n        y = 2 * X + 1 + rng.randn(10) * 0.1\n        sample_weight = np.ones(10)\n        sample_weight[2:5] = 2  # Increase weight for middle values\n        y_pred = isotonic_regression(y, sample_weight=sample_weight, increasing=True)\n        assert_allclose(\n            y_pred,\n            isotonic_regression(y, increasing=True),\n            err_msg=\"isotonic_regression with weights should be the same as \"\n                   \"without weights for increasing case\",\n        )\n\n        # Decreasing case\n        y = -2 * X + 1 + rng.randn(10) * 0.1\n        y_pred = isotonic_regression(y, sample_weight=sample_weight, increasing=False)\n        assert_allclose(\n            y_pred,\n            isotonic_regression(y, increasing=False),\n            err_msg=\"isotonic_regression with weights should be the same as \"\n                   \"without weights for decreasing case\",\n        )\n", "    def test_increasing_default(self):\n        X = np.sort(np.random.rand(100))\n        y = X + 2 * np.random.randn(100)\n        iso_reg = IsotonicRegression()\n        iso_reg.fit(X, y)\n        assert iso_reg.increasing_\n\n\n\n", "    def test_out_of_bounds_clip():\n        # Test that a model configured to clip out-of-bounds values\n        # handles this correctly.\n        \n        X = np.array([0, 1, 2, 3])\n        y = np.array([0, 1, 2, 3])\n        iso = IsotonicRegression(out_of_bounds=\"clip\").fit(X, y)\n        assert_array_equal(iso.predict([-1, 4]), [0, 3])\n\n", "    def test_isotonic_regression_increasing_decreasing(self):\n        X, y = make_regression(n_samples=20, n_features=1, random_state=0)\n        X = X[:, 0]\n        y = expit(X)  # Monotonically increasing\n        y_iso_inc = isotonic_regression(y, increasing=True)\n        assert_array_almost_equal(y_iso_inc, np.sort(y))\n        y_iso_dec = isotonic_regression(y, increasing=False)\n        assert_array_almost_equal(y_iso_dec, np.sort(y)[::-1])\n\n"], "sample_26": ["    def test_test_db_signature_includes_database_name(self):\n        connection = get_connection_copy()\n        creation = BaseDatabaseCreation(connection)\n\n        original_name = connection.settings_dict['NAME']\n        try:\n            connection.settings_dict['NAME'] = 'test_database'\n            self.assertEqual(\n                creation.test_db_signature()[3], 'test_database'\n            )\n        finally:\n            connection.settings_dict['NAME'] = original_name\n", "    def test_test_db_signature(self):\n        test_connection = get_connection_copy()\n        creation = BaseDatabaseCreation(test_connection)\n        # Test the default test db signature\n        original_signature = creation.test_db_signature()\n        settings_dict_copy = copy.deepcopy(test_connection.settings_dict)\n        # Modify some settings\n        settings_dict_copy['NAME'] = 'new_test_name'\n        test_connection.settings_dict = settings_dict_copy\n        creation = BaseDatabaseCreation(test_connection)\n        new_signature = creation.test_db_signature()\n        self.assertNotEqual(original_signature, new_signature)\n\n        # Test the signature with suffix\n        settings_dict_copy['NAME'] = 'original_name'\n        test_connection.settings_dict = settings_dict_copy\n        creation = BaseDatabaseCreation(test_connection)\n        suffix = 'clone_suffix'\n        test_signature = creation.test_db_signature()\n        self.assertNotEqual(test_signature, original_signature)\n\n", "    def test_test_db_signature(self):\n        # Check that test_db_signature returns a tuple.\n        connection = get_connection_copy()\n        creation = BaseDatabaseCreation(connection)\n        signature = creation.test_db_signature()\n        self.assertIsInstance(signature, tuple)\n", "    def test_test_db_signature_includes_database_name(self):\n        connection = get_connection_copy()\n        dbc = BaseDatabaseCreation(connection)\n\n        connection.settings_dict['NAME'] = 'my_database'\n        signature = dbc.test_db_signature()\n        self.assertIn('my_database', signature)\n", "    def test_test_db_signature(self):\n        self.assertEqual(\n            BaseDatabaseCreation(get_connection_copy()).test_db_signature(),\n            (\n                connection.settings_dict['HOST'],\n                connection.settings_dict['PORT'],\n                connection.settings_dict['ENGINE'],\n                TEST_DATABASE_PREFIX + connection.settings_dict['NAME'],\n            ),\n        )\n"], "sample_123": ["def test_GoldenRatio_rewrite():\n    assert S.GoldenRatio.expand(func=True) == Rational(1, 2) + sqrt(5)/2\n    assert simplify(S.GoldenRatio**2) == S.GoldenRatio + 1\n\n\n\n", "def test_factorial():\n    assert factorial(0) == S.One\n    assert factorial(1) == S.One\n    assert factorial(5) == 120\n    assert factorial(S.Half) == sqrt(pi) / 2\n\n    assert factorial(S.Infinity) == S.Infinity\n    assert factorial(-S.Infinity) == S.NaN\n    raises(ValueError, lambda: factorial(S.ComplexInfinity))\n    raises(ValueError, lambda: factorial(-2))\n\n", "def test_sympify_mod():\n    assert sympify(Mod(5, 3)) == Mod(5, 3)\n    assert sympify('5 mod 3') == Mod(5, 3)\n", "def test_igcd2():\n    assert igcd2(12, 18) == 6\n    assert igcd2(18, 12) == 6\n    assert igcd2(24, 36) == 12\n    assert igcd2(36, 24) == 12\n    assert igcd2(18, 27) == 9\n    assert igcd2(27, 18) == 9\n    assert igcd2(1, 2) == 1\n    assert igcd2(2, 1) == 1\n    assert igcd2(-1, -2) == 1\n    assert igcd2(-2, -1) == 1\n", "def test_NumberSymbol_rewrite():\n    assert S.Pi.rewrite('sin') == sin(S.Pi*I/2)\n\n    assert S.EulerGamma.rewrite('sqrt') == S.EulerGamma\n\n"], "sample_97": ["    def test_label_binarize_multiclass_sparse_thresholding(self):\n        y = np.array([[1, 2], [0, 2], [1, 0]])\n        classes = np.array([0, 1, 2])\n        lb = LabelBinarizer()\n        y_bin = lb.fit_transform(y)\n\n        # Test thresholding for multiclass\n        y_thresh = _inverse_binarize_thresholding(y_bin, \"multiclass\", classes,\n                                                   threshold=0.5)\n        assert_array_equal(y_thresh, y)\n\n        y_bin_sparse = coo_matrix(y_bin)\n        y_thresh_sparse = _inverse_binarize_thresholding(y_bin_sparse,\n                                                      \"multiclass\", classes,\n                                                      threshold=0.5)\n        assert_array_equal(y_thresh_sparse, y)\n", "    def test_inverse_transform_multilabel_thresholding(self):\n        # Test inverse transformation with thresholding for multilabel\n        lb = LabelBinarizer()\n        y_bin = lb.fit_transform(np.array([\n            [1, 0, 2],\n            [0, 1, 1],\n            [2, 0, 0]]))\n\n        y_inv = _inverse_binarize_thresholding(y_bin, \"multilabel-indicator\",\n                                               lb.classes_, threshold=0.5)\n        assert_array_equal(y_inv, np.array([[1, 2], [1, 2], [2]]))\n", "    def test_label_binarizer_sparse_output_multilabel(self):\n\n        lb = LabelBinarizer(sparse_output=True)\n        y = [[1, 2], [3], [1, 2, 3]]\n        lb.fit(y)\n        yt = lb.transform(y)\n        assert_true(issparse(yt))\n\n        yt = toarray(yt)\n\n        assert_equal(yt.shape, (3, 4))\n        assert_array_equal(yt[0], [1, 1, 0, 0])\n        assert_array_equal(yt[1], [0, 0, 1, 0])\n        assert_array_equal(yt[2], [1, 1, 1, 0])\n\n\n\n", "    def test_multilabelbinarizer_sparse_output_binary(self):\n        mlb = MultiLabelBinarizer(sparse_output=True)\n        mlb.fit([[1, 2], [3]])\n        X = mlb.transform([[1, 3], [2], [1, 2, 3]])\n        assert_true(issparse(X))\n        expected = coo_matrix([[1, 0, 1],\n                              [0, 1, 0],\n                              [1, 1, 1]])\n        assert_array_equal(toarray(X), toarray(expected))\n", "    def test_binarize_multilabel_indicator(self):\n        y = [[1, 2], [3], []]\n        classes = [1, 2, 3]\n        y_binarized = label_binarize(y, classes=classes, sparse_output=True,\n                                    output_format='csc')\n        assert_equal(y_binarized.shape, (3, 3))\n        assert_true(issparse(y_binarized))\n        assert_(isinstance(y_binarized, csc_matrix))\n        y_binarized = toarray(y_binarized)\n        assert_array_equal(y_binarized,\n                           [[1, 1, 0],\n                            [0, 0, 1],\n                            [0, 0, 0]])\n\n"], "sample_134": ["    def test_print_CodegenArrayDiagonal(self):\n        A = MatrixSymbol('A', 3, 3)\n        expr = CodegenArrayDiagonal(A, diagonal_indices=[(0, 0)])\n        p = NumPyPrinter()\n        code = p.doprint(expr)\n        assert code == 'numpy.diagonal(A, 0, axis1=0, axis2=0)'\n", "    def test_codegen_array_diagonal(self):\n        # Test simple diagonal extraction\n        with warns_deprecated_sympy():\n            a = MatrixSymbol('a', 3, 3)\n            expr = CodegenArrayDiagonal(a, (0, 1))\n            printer = NumPyPrinter()\n            code = printer.doprint(expr)\n            assert code == 'numpy.diagonal(a, 0, axis1=0, axis2=1)'\n\n        # Test diagonal extraction with offsets\n\n", "    def test_codegen_array_diagonal_nested(self):\n        A = MatrixSymbol('A', 3, 3)\n        B = MatrixSymbol('B', 3, 3)\n        expr = CodegenArrayDiagonal(CodegenArrayTensorProduct(A, B), [0, 0], [1, 1])\n        printer = NumPyPrinter()\n        code = printer.doprint(expr)\n        assert code == 'numpy.einsum(\"ij,kl->il\", A, B)'\n", "    def test_numpy_codegen_diagonal(self):\n        # Diagonal\n        with warns_deprecated_sympy():\n            expr = CodegenArrayDiagonal(eye(3), [0])\n            func = lambdify((), expr, 'numpy')\n            assert (func() == np.eye(3)).all()\n\n", "    def test_numpy_codegen_array(self):\n        A = MatrixSymbol('A', 2, 2)\n        B = MatrixSymbol('B', 2, 2)\n        expr = CodegenArrayTensorProduct(A, B)\n        numpy_code = NumPyPrinter().doprint(expr)\n        assert numpy_code == 'numpy.einsum(\\'ij,kl->ijkl\\', A, B)'\n"], "sample_27": ["    def test_token_expired(self):\n        generator = MockedPasswordResetTokenGenerator(now=datetime(2023, 1, 1))\n        user = User.objects.create_user(username='testuser')\n        token = generator.make_token(user)\n        settings.PASSWORD_RESET_TIMEOUT = timedelta(seconds=1)\n        self.assertFalse(generator.check_token(user, token))\n", "    def test_token_expires(self):\n        user = User.objects.create_user(username='testuser', email='test@example.com', password='password')\n        generator = MockedPasswordResetTokenGenerator(now=datetime.now())\n        token = generator.make_token(user)\n\n        # Advance time beyond the expiry limit\n        generator._now_val += timedelta(days=settings.PASSWORD_RESET_TIMEOUT.days + 1)\n\n        self.assertFalse(generator.check_token(user, token))\n", "    def test_check_token_legacy_algorithm(self):\n        user = User.objects.create_user(username='testuser', password='password')\n        generator = MockedPasswordResetTokenGenerator(\n            now=datetime(2040, 1, 1)\n        )\n        token = generator.make_token(user)\n\n        # Simulate using a legacy (sha1) algorithm\n        settings.DEFAULT_HASHING_ALGORITHM = 'sha1'\n        self.assertTrue(generator.check_token(user, token))\n\n        settings.DEFAULT_HASHING_ALGORITHM = 'sha256'\n", "    def test_check_token_expiry(self):\n        user = User.objects.create_user(username='testuser', password='password')\n        generator = MockedPasswordResetTokenGenerator(now=datetime(2038, 1, 1))\n        token = generator.make_token(user)\n\n        # Set timeout to 1 second\n        settings.PASSWORD_RESET_TIMEOUT = 1\n\n        # Simulate token being generated 1 second ago\n        generator = MockedPasswordResetTokenGenerator(\n            now=datetime(2038, 1, 1) + timedelta(seconds=1)\n        )\n        self.assertFalse(generator.check_token(user, token))\n", "    def test_password_reset_token_expired(self):\n        user = User.objects.create_user(username='testuser', password='password')\n        generator = MockedPasswordResetTokenGenerator(now=datetime.now() - timedelta(days=settings.PASSWORD_RESET_TIMEOUT + 1))\n        token = generator.make_token(user)\n        self.assertFalse(generator.check_token(user, token))\n"], "sample_23": ["    def test_union_with_different_select_clause(self):\n        queryset1 = Number.objects.values('num').filter(num__gt=5)\n        queryset2 = Number.objects.values('other_num').filter(other_num__lt=5)\n        combined = queryset1.union(queryset2)\n        self.assertCountEqual(combined, [\n            {'num': 6},\n            {'num': 7},\n            {'num': 8},\n            {'num': 9},\n            {'other_num': 4},\n            {'other_num': 3},\n            {'other_num': 2},\n            {'other_num': 1},\n            {'other_num': 0},\n        ])\n", "    def test_select_related_with_union(self):\n        numbers1 = Number.objects.filter(num__lt=5).select_related('other_number')\n        numbers2 = Number.objects.filter(num__gte=5).select_related('other_number')\n        union_qs = numbers1.union(numbers2)\n        self.assertNumbersEqual(union_qs, Number.objects.all().select_related('other_number'))\n", "    def test_empty_union(self):\n        empty_qs = Number.objects.none()\n        self.assertNumbersEqual(empty_qs.union(Number.objects.all()), Number.objects.all().order_by(\n            'pk'))\n        self.assertNumbersEqual(Number.objects.all().union(empty_qs), Number.objects.all().order_by(\n            'pk'))\n        self.assertNumbersEqual(empty_qs | empty_qs, empty_qs)\n", "    def test_union_with_subquery(self):\n        # Test union with a subquery that uses a WHERE clause.\n        subquery = Number.objects.filter(num__gt=5).values('num')\n        queryset = Number.objects.all().values('num').union(subquery)\n        expected_numbers = list(Number.objects.filter(Q(num__gt=5) | Q(num__lte=5)).values_list('num', flat=True))\n        self.assertNumbersEqual(queryset, expected_numbers)\n", "    def test_union_with_empty(self):\n        empty = Number.objects.none()\n        self.assertNumbersEqual(Number.objects.all().union(empty), Number.objects.all())\n        self.assertNumbersEqual(empty.union(Number.objects.all()), Number.objects.all())\n"], "sample_39": ["compilation error", "compilation error", "compilation error", "compilation error", "def test_resolve_urlconf_exception(self):\n    with self.assertRaises(ImproperlyConfigured):\n        resolve('/foo/')\n"], "sample_55": ["    def test_no_translations(self):\n        with translation.override('fr'):\n            with captured_stderr() as stderr:\n                management.call_command('dance')\n            self.assertEqual(stderr.getvalue(), '')\n", "    def test_command_help(self):\n        out = StringIO()\n        with captured_stderr(out):\n            management.call_command('dance', '--help')\n        self.assertIn('This command does a little dance.', out.getvalue())\n\n\n\n", "    def test_no_translations(self):\n        with translation.override(\"fr\"):\n            self.assertEqual(dance.dance(), \"Dancing!\")\n\n\n\n", "    def test_no_translations_decorator(self):\n        with translation.override('fr'):\n            @no_translations\n                return translation.get_language()\n\n            self.assertIsNone(my_func())\n", "    def test_no_color(self):\n        with captured_stderr() as stderr, override_settings(SILENCED_SYSTEM_CHECKS=['django.core.checks.AdminSiteCheck']):\n            management.call_command('dance', no_color=True)\n        self.assertEqual(stderr.getvalue(), '')\n"], "sample_111": ["def test_v_measure_score_invariance():\n    for metric_name in [\"v_measure_score\"]:\n        metric = SUPERVISED_METRICS[metric_name]\n\n        for labels_true, labels_pred in [\n            (y1, y2),\n            (y2, y1),\n            (y1.tolist(), y2.tolist()),\n            (y2.tolist(), y1.tolist()),\n        ]:\n            assert_allclose(\n                metric(labels_true, labels_pred),\n                metric(labels_pred, labels_true),\n                err_msg=\"{} should be symmetric\".format(metric_name),\n            )\n", "def test_silhouette_score_empty_labels():\n    assert silhouette_score([]) == 0\n    assert silhouette_score(rng.randint(5, size=100), []) == 0\n", "    def test_silhouette_score_empty(self):\n        with pytest.raises(ValueError):\n            silhouette_score([[0, 1], [1, 0]], [0, 0])\n", "    def test_silhouette_score_empty_clusters():\n        # Test silhouette_score with empty clusters\n\n        labels = np.array([0, 0, 1, 1, -1, -1])\n        X = np.array([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5]])\n        with pytest.raises(ValueError):\n            silhouette_score(X, labels)\n", "    def test_mutual_info_score_contingency(self):\n        \"\"\"Test mutual_info_score with a manually given contingency matrix.\"\"\"\n\n        labels_true = np.array([0, 0, 1, 1, 2, 2])\n        labels_pred = np.array([0, 1, 0, 1, 2, 2])\n\n        # Manually calculate contingency matrix\n        contingency = np.array([[2, 1, 0],\n                               [1, 1, 0],\n                               [0, 0, 2]])\n        score = mutual_info_score(labels_true, labels_pred, contingency=contingency)\n        assert_allclose(score, 0.72192809, rtol=1e-7)\n\n"], "sample_147": ["def test_nfloat_matrix_symbol():\n    x = MatrixSymbol('x', 2, 2)\n    assert nfloat(x) == x\n    assert nfloat(x, exponent=True) == x\n    assert nfloat(x, dkeys=True) == x\n\n", "def test_expand_power_base_complex():\n    assert expand_power_base((\n        2*I**3 )**n) == 2**n * I**(3*n)\n", "    def test_expand_mul_MatMul():\n        x, y, z = symbols('x y z', commutative=False)\n        a = MatrixSymbol('a', 2, 2)\n        b = MatrixSymbol('b', 2, 2)\n        c = MatrixSymbol('c', 2, 2)\n        assert expand_mul(x*a*y) == x*a*y\n        assert expand_mul(x*(a*b)*y) == x*a*b*y\n        assert expand_mul(x*(a*b*c)*y) == x*a*b*c*y\n        assert expand_mul(x*a*y*b) == x*a*y*b\n        assert expand_mul(x*(a*b)*y*c) == x*a*b*y*c\n\n\n\n", "def test_nfloat_matrix():\n    x = MatrixSymbol('x', 2, 2)\n    assert nfloat(x) == x\n    m = Matrix(\n        [\n            [1, 2],\n            [pi, S.Half]\n        ]\n    )\n    assert nfloat(m) == Matrix(\n        [\n            [1, 2],\n            [pi.n(15), S.Half.n(15)]\n        ]\n    )\n\n", "    def test_nfloat_matrix(self):\n        m = Matrix([[1, 2], [3, 4]])\n        m_nfloat = nfloat(m)\n        assert isinstance(m_nfloat, Matrix)\n        assert all(isinstance(e, float) for e in m_nfloat.flat)\n\n"], "sample_31": ["    def test_python_command_with_command_option(self):\n        with captured_stdout() as stdout, captured_stdin():\n            call_command('shell', command=self.script_globals)\n            self.assertEqual(stdout.getvalue(), 'True\\n')\n", "    def test_command_execution(self):\n        with captured_stdout() as stdout, captured_stdin() as stdin:\n            stdin.write(self.script_globals)\n            stdin.seek(0)\n            call_command('shell', command=self.script_globals)\n        self.assertEqual(stdout.get_value(), 'True\\n')\n\n", "    def test_python_startup_files(self):\n        with captured_stdout() as stdout, captured_stdin() as stdin, mock.patch.dict(os.environ, {'PYTHONSTARTUP': 'print(\"HELLO\")'}):\n            call_command('shell', interface='python', no_startup=False)\n            self.assertEqual(stdout.getvalue().strip(), 'HELLO')\n\n", "    def test_no_startup_option(self):\n        with captured_stdout() as stdout, captured_stdin() as stdin:\n            stdin.write(self.script_globals)\n            call_command('shell', no_startup=True)\n            self.assertEqual(stdout.getvalue().strip(), 'True')\n\n", "    def test_stdin_execution(self):\n        with captured_stdin() as stdin, captured_stdout() as stdout:\n            stdin.write(self.script_globals)\n            stdin.seek(0)\n            call_command('shell', '-c', self.script_globals)\n        self.assertEqual(stdout.getvalue(), 'True\\n')\n\n"], "sample_80": ["    def test_summarize_attr(self):\n        ds = xr.Dataset({\"foo\": (\"x\", np.arange(5))})\n        ds.attrs[\"bar\"] = {\"a\": 1, \"b\": 2}\n        ds.attrs[\"baz\"] = \"quux\"\n\n        expected = dedent(\n            \"\"\"\n            Attributes:\n              bar: {'a': 1, 'b': 2}\n              baz: 'quux'\n            \"\"\"\n        ).strip()\n        actual = formatting.attrs_repr(ds.attrs)\n        assert actual == expected\n\n        ds.attrs[\"bar\"] = np.arange(10)\n        expected = dedent(\n            \"\"\"\n            Attributes:\n              bar: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n              baz: 'quux'\n            \"\"\"\n        ).strip()\n        actual = formatting.attrs_repr(ds.attrs)\n        assert actual == expected\n", "    def test_inline_sparse_repr(self):\n        # Test for correct formatting of sparse arrays\n        data = np.array([[0, 1, 0], [2, 0, 3], [0, 0, 0]])\n        sparse_array = sparse.COO(data)\n\n        # Test for correct string representation\n        assert formatting.inline_sparse_repr(sparse_array) == \"<COO: nnz=4, fill_value=0>\"\n\n", "    def test_summarize_variable_dask_array(self) -> None:\n        import dask.array as da\n\n        data = da.random.random((10, 20), chunks=(5, 5))\n        var = xr.Variable((\"x\", \"y\"), data)\n        ds = xr.Dataset({\"foo\": var})\n\n        expected = dedent(\n            \"\"\"\n            <xarray.Variable (x: 10, y: 20)>\n            dask.array<chunksize=(5, 5), shape=(10, 20), dtype=float64>\n            Attributes:\n                *empty*\n        \"\"\"\n        )\n\n        actual = formatting.summarize_variable(\"foo\", var, col_width = 20)\n        assert actual == expected\n\n", "    def test_inline_sparse_repr(self):\n        arr = sparse.COO([1, 2, 3], ([0, 1, 2], [0, 1, 2]), shape=(3, 3))\n        expected = \"<sparse.COO: nnz=3, fill_value=0>\"\n        assert formatting.inline_sparse_repr(arr) == expected\n", "    def test_array_repr(self, da, expected):\n        assert repr(da) == expected\n\n"], "sample_132": ["def test_farthest_points_on_a_line():\n    # Test farthest points on a line should be the endpoints\n    p1 = Point(0, 0)\n    p2 = Point(10, 0)\n    p3 = Point(5, 0)\n    assert farthest_points(p1, p2, p3) == {(p1, p2)}\n", "    def test_closest_points_non_rational():\n        P = [(1, 1), (1, 2), (3, 4), (5, 5)]\n        c = closest_points(*P)\n        assert len(c) == 1\n        assert list(c)[0] == tuple(sorted([(Point2D(1, 1), Point2D(1, 2))]))\n\n", "    def test_are_coplanar_mixed():\n        # Ensure are_coplanar handles mixed Point2D/Point3D correctly\n        p1 = Point(0, 0, 0)\n        p2 = Point2D(1, 0)\n        p3 = Point3D(0, 1, 0)\n        assert are_coplanar(p1, p2, p3)\n", "def test_farthest_points():\n    p1 = Point(0, 0)\n    p2 = Point(1, 0)\n    p3 = Point(0, 1)\n    assert farthest_points(p1, p2, p3) == {(Point(0, 0), Point(0, 1))}\n    assert farthest_points(p1, p2) == {(Point(0, 0), Point(1, 0))}\n", "def test_convex_hull_points_on_line():\n    p1 = Point2D(1, 1)\n    p2 = Point2D(2, 2)\n    p3 = Point2D(3, 3)\n    ch = convex_hull(p1, p2, p3)\n    assert isinstance(ch, Segment)\n    assert ch.points == [p1, p3]\n\n"], "sample_154": ["    def test_lambdify_tensorflow_scalar():\n        if not tensorflow:\n            skip(\"TensorFlow is not installed.\")\n\n        expr = x**2 + y\n        f = lambdify(x, expr, \"tensorflow\")\n        result = f(tensorflow.constant(2))\n        assert result.numpy() == 4\n\n", "    def test_lambdify_tensorflow_array():\n        if not tensorflow:\n            skip(\"TensorFlow not installed\")\n        x = tf.Variable(2)\n        f = lambdify(x, x**2, 'tensorflow')\n        assert f(x).numpy() == 4\n", "def test_lambdify_tensorflow_scalar():\n    if not tensorflow:\n        skip(\"TensorFlow not installed\")\n\n    expr = sin(x)**2 + cos(y)**2\n    f = lambdify(x, expr, 'tensorflow')\n    result = f(tensorflow.constant(1.0))\n    assert numpy.allclose(result.numpy(), expr.subs({x: 1.0}).evalf())\n\n", "def test_lambdify_tensorflow_sparse():\n    if not tensorflow:\n        skip(\"Tensorflow not installed.\")\n    A = sympy.SparseMatrix([[1, 2], [3, 4]])\n    x = sympy.MatrixSymbol('x', 2, 1)\n    expr = A @ x\n    f = lambdify(x, expr, 'tensorflow')\n    result = f(tensorflow.constant([5, 6]))\n    assert (result.numpy() == numpy.array([17, 39])).all()\n", "def test_lambdify_tensorflow_array():\n    from sympy.tensor.array import Array, tensorproduct\n    from sympy import sin, sqrt\n    x = Array(\"x\", (2, 3))\n    expr = sin(sqrt(tensorproduct(x, x)))\n    f = lambdify(x, expr, 'tensorflow')\n    tf_x = tensorflow.constant([[1, 2, 3], [4, 5, 6]])\n    res = f(tf_x)\n\n"], "sample_138": ["    def test_blockinverse_2x2_invertible(self):\n        X = MatrixSymbol('X', 2, 2)\n        Y = MatrixSymbol('Y', 2, 2)\n        Z = MatrixSymbol('Z', 2, 2)\n        B = BlockMatrix([[X, Y], [Z, MatrixSymbol('A', 2, 2)]])\n        B_inv = block_collapse(Inverse(B))\n        # TODO: This should be checked for equality, but that requires\n        #       a more sophisticated comparison of MatrixExpressions.\n        self.assertTrue(isinstance(B_inv, BlockMatrix))\n\n", "def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert isinstance(B, BlockMatrix)\n    assert ImmutableMatrix(B.blocks[0, 1]) == ImmutableMatrix([[1, 2, 3]])\n", "    def test_blockcut():\n        M = ImmutableMatrix(4, 4, range(16))\n        B = blockcut(M, (1, 3), (1, 3))\n        assert isinstance(B, BlockMatrix)\n        assert ImmutableMatrix(B.blocks[0, 1]) == ImmutableMatrix([[1, 2, 3]])\n", "    def test_block_inverse_general_2x2():\n        x, y, z, w = symbols('x y z w')\n        M = Matrix([[x, y], [z, w]])\n        BM = BlockMatrix([[M]])\n        iBM = Inverse(BM)\n        assert isinstance(iBM, BlockMatrix)\n        assert iBM.blocks[0, 0] == M.inv()\n\n\n\n", "def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert B.blocks[0, 0] == Matrix([[0]])\n    assert B.blocks[0, 1] == Matrix([[1, 2, 3]])\n    assert isinstance(B, BlockMatrix)\n"], "sample_152": ["    def test_array_add_scalar(self):\n        a = ImmutableDenseNDimArray([1, 2, 3], (3,))\n        b = a + 2\n        assert b.equals(ImmutableDenseNDimArray([3, 4, 5], (3,)))\n        b = 2 + a\n        assert b.equals(ImmutableDenseNDimArray([3, 4, 5], (3,)))\n", "def test_diff_scalar():\n    from sympy import ImmutableDenseNDimArray\n    from sympy.abc import x  \n\n    a = ImmutableDenseNDimArray([x, 1, x**2, 3], (2, 2))\n    diffa = a.diff(x)\n    assert diffa == ImmutableDenseNDimArray([1, 0, 2*x, 0], (2, 2))\n\n", "def test_array_diff():\n    M = ImmutableDenseNDimArray([[x, y], [1, x*y]])\n    assert M.diff(x) == ImmutableDenseNDimArray([[1, 0], [0, y]])\n    assert M.diff(y) == ImmutableDenseNDimArray([[0, 1], [0, x]])\n\n", "def test_array_scalar_op():\n    a = ImmutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    assert (a + 1).tolist() == [[2, 3], [4, 5]]\n    assert (a - 1).tolist() == [[0, 1], [2, 3]]\n    assert (a * 2).tolist() == [[2, 4], [6, 8]]\n    assert (a / 2).tolist() == [[0.5, 1], [1.5, 2]]\n\n", "def test_array_diff():\n    A = ImmutableDenseNDimArray([[x, y], [1, x*y]])\n    assert A.diff(x) == ImmutableDenseNDimArray([[1, y], [0, y]])\n    assert A.diff(y) == ImmutableDenseNDimArray([[0, 1], [0, x]])\n\n"], "sample_103": ["    def test_mutual_info_regression_sparse_discrete(self):\n        X = csr_matrix([[0, 1], [1, 0], [0, 1]])\n        y = np.array([0, 1, 0])\n        mi = mutual_info_regression(X, y, discrete_features='auto')\n        assert_array_equal(mi, [0, 0])\n", "    def test_mutual_info_classif_sparse_input():\n        rng = check_random_state(0)\n        X = csr_matrix(rng.randint(0, 2, size=(100, 10)))\n        y = rng.randint(0, 2, size=100)\n\n        mi = mutual_info_classif(X, y)\n        assert_equal(mi.shape[0], X.shape[1])\n        assert_greater(mi.min(), -1e-10)\n", "    def test_mutual_info_regression_sparse_data():\n        rng = check_random_state(0)\n        n_samples = 100\n        n_features = 5\n        X = csr_matrix(rng.randn(n_samples, n_features))\n        y = rng.randn(n_samples)\n        mi = mutual_info_regression(X, y)\n        assert_equal(mi.shape[0], n_features)\n", "    def test_mutual_info_regression_discrete_features():\n        random_state = check_random_state(0)\n        X = random_state.randn(100, 5)\n        y = X[:, 0] + X[:, 1]\n\n        # Test with all discrete features\n        mi = mutual_info_regression(X, y, discrete_features=True)\n        assert_array_equal(mi.shape, (5,))\n        assert_greater(mi[0], 0)\n        assert_greater(mi[1], 0)\n\n        # Test with some discrete features\n        discrete_features = [True, False, True, False, True]\n        mi = mutual_info_regression(X, y, discrete_features=discrete_features)\n        assert_array_equal(mi.shape, (5,))\n        assert_greater(mi[0], 0)\n        assert_almost_equal(mi[1], 0, 5)\n        assert_greater(mi[2], 0)\n", "    def test_mutual_info_classif_sparse_discrete(self):\n        n_samples = 100\n        n_features = 5\n        rng = check_random_state(42)\n\n        X = csr_matrix(rng.randint(0, 2, size=(n_samples, n_features)))\n        y = rng.randint(0, 2, size=(n_samples,))\n\n        mi = mutual_info_classif(X, y)\n        assert_greater(np.sum(mi), 0)\n\n"], "sample_6": ["    def test_ascii_username_validator(self):\n        validator = validators.ASCIIUsernameValidator()\n        self.assertIsNone(validator('testuser123'))\n        with self.assertRaises(ValidationError):\n            validator('test user')\n        with self.assertRaises(ValidationError):\n            validator('\ud14c\uc2a4\ud2b8\uc0ac\uc6a9\uc790')\n\n", "    def test_unicode_username_validator(self):\n        \"\"\"\n        Test the UnicodeUsernameValidator\n        \"\"\"\n        validator = validators.UnicodeUsernameValidator()\n        self.assertTrue(validator('username123'))\n        with self.assertRaisesMessage(ValidationError, 'Enter a valid username. This value may contain only letters, numbers, and @/./+/-/_ characters.'):\n            validator('user name')\n", "    def test_ascii_username_validator(self):\n        validator = validators.ASCIIUsernameValidator()\n        valid_usernames = ['john_doe', 'jane.doe', 'jDoe123', 'j_doe-123']\n        invalid_usernames = ['john doe', 'j@doe.com', 'jDoe!123']\n        for username in valid_usernames:\n            validator(username)\n        for username in invalid_usernames:\n            with self.assertRaises(ValidationError):\n                validator(username)\n", "    def test_username_validators(self):\n        \"\"\"\n        Tests ASCIIUsernameValidator and UnicodeUsernameValidator.\n        \"\"\"\n        # Test ASCIIUsernameValidator\n        validator = validators.ASCIIUsernameValidator()\n        self.assertTrue(validator(\n            'john.doe123'))\n        with self.assertRaises(ValidationError):\n            validator('j\u00f6hn.doe')\n        # Test UnicodeUsernameValidator\n        validator = validators.UnicodeUsernameValidator()\n        self.assertTrue(validator(\n            'j\u00f6hn.doe123'))\n        self.assertTrue(validator('john.doe123'))\n", "    def test_ascii_username_validator(self):\n        validator = validators.ASCIIUsernameValidator()\n        valid_username = 'john_doe'\n        invalid_username = 'j\u00f5hn_d\u00f5e'\n\n        self.assertIsNone(validator(valid_username))\n        with self.assertRaises(ValidationError):\n            validator(invalid_username)\n\n"], "sample_137": ["    def test_rotations():\n        assert list(rotations([1,2,3])) == [[1, 2, 3], [2, 3, 1], [3, 1, 2]]\n        assert list(rotations([1,2,3], -1)) == [[1, 2, 3], [3, 1, 2], [2, 3, 1]]\n", "def test_is_palindromic():\n    assert is_palindromic('racecar') is True\n    assert is_palindromic('level') is True\n    assert is_palindromic('madam') is True\n    assert is_palindromic('rotor') is True\n    assert is_palindromic('stats') is True\n    assert is_palindromic('deified') is True\n\n    assert is_palindromic('apple') is False\n    assert is_palindromic('banana') is False\n    assert is_palindromic('house') is False\n\n\n\n", "def test_is_palindromic():\n    assert is_palindromic('') is True\n    assert is_palindromic('a') is True\n    assert is_palindromic('aa') is True\n    assert is_palindromic('aba') is True\n    assert is_palindromic('abba') is True\n    assert is_palindromic('abcba') is True\n    assert is_palindromic('racecar') is True\n\n    assert is_palindromic('ab') is False\n    assert is_palindromic('abc') is False\n    assert is_palindromic('abca') is False\n    assert is_palindromic('hello') is False\n", "    def test_rotations():\n        assert list(rotations([1,2,3])) == [[1, 2, 3], [2, 3, 1], [3, 1, 2]]\n        assert list(rotations([1,2,3], -1)) == [[1, 2, 3], [3, 1, 2], [2, 3, 1]]\n\n", "def test_ordered_partitions():\n    assert list(ordered_partitions(4, 2)) == [\n        [[0], [1, 2, 3]],\n        [[0, 1], [2, 3]],\n        [[0, 1, 2], [3]],\n        [[0, 1, 3], [2]],\n        [[0, 2, 3], [1]],\n        [[0, 1, 2, 3], []]\n    ]\n"], "sample_0": ["def test_required_autocomplete_widget_renders_empty_option(self):\n        form = RequiredBandForm()\n        response = self.client.get('/form/')\n        self.assertContains(response, self.empty_option)\n", "    def test_required_field(self):\n        form = RequiredBandForm(data={'band': ''})\n        self.assertFalse(form.is_valid())\n\n        expected_error = {'band': ['This field is required.']}\n        self.assertEqual(form.errors, expected_error)\n", "    def test_required_field_initial_value(self):\n        form = RequiredBandForm(initial={'band': Band.objects.first().id})\n        self.assertEqual(\n            form.as_p(),\n            '<p><label for=\"id_band\">Band:</label> <select id=\"id_band\" name=\"band\" required><option value=\"%s\" selected>%s</option>%s</select></p>' % (\n                Band.objects.first().id,\n                Band.objects.first().name,\n                self.empty_option\n            )\n        )\n", "    def test_autocomplete_select_required_empty(self):\n        form = RequiredBandForm()\n        html = form.as_p()\n        self.assertIn(self.empty_option, html)\n        self.assertIn('required', html)\n", "    def test_autocomplete_widget_required(self):\n        form = RequiredBandForm(data={'band': ''})\n        self.assertFalse(form.is_valid())\n        self.assertIn('band', form.errors)\n        self.assertEqual(\n            form.errors['band'][0],\n            'This field is required.',\n        )\n"], "sample_67": ["    def test_serialize_operation_with_custom_operation(self):\n        with mock.patch(\"django.db.migrations.writer.OperationWriter.serialize\") as mock_serialize:\n            operation = custom_migration_operations.more_operations.MoreOperation(\n                'some_name', 'some_argument',\n            )\n            MigrationWriter(\n                [operation], indentation=0\n            ).serialize()\n\n            mock_serialize.assert_called_once()\n            serialized_operation, _ = mock_serialize.call_args[0]\n            self.assertEqual(serialized_operation.name, operation.name)\n            self.assertEqual(serialized_operation.kwargs, operation.kwargs)\n\n", "    def test_serialize_integer_flag_enum(self):\n        op = migrations.AlterField(\n            model_name=\"testmodel\",\n            name=\"enum_field\",\n            field=models.IntegerField(\n                choices=[(IntFlagEnum.A, IntFlagEnum.A.name), (IntFlagEnum.B, IntFlagEnum.B.name)],  # noqa: E501\n            ),\n        )\n        writer = OperationWriter(op, indentation=0)\n\n        expected = (\n            \"AlterField(model_name='testmodel', name='enum_field', field=models.IntegerField(\"\n            \"choices=[(IntFlagEnum.A, '1'), (IntFlagEnum.B, '2')]))\"\n        )\n        self.assertEqual(writer.serialize(), expected)\n\n", "    def test_serialize_int_flag_enum(self):\n        from django.db.migrations.serializer import serializer_factory\n\n        enum_value = IntFlagEnum.A | IntFlagEnum.B\n\n        serialized, imports = serializer_factory(enum_value).serialize()\n\n        self.assertEqual(serialized, \"IntFlagEnum.A | IntFlagEnum.B\")\n        self.assertEqual(imports, {\"import enum\"})\n", "    def test_uuid_serializer(self):\n        serializer = serializer_factory(uuid.uuid4())\n        self.assertEqual(serializer.serialize(), ('uuid.%s' % repr(serializer.value), {'import uuid'}))\n", "    def test_serialize_int_flag_enum(self):\n        operation = migrations.RunPython(\n            lambda apps: apps.get_model('test_migrations', 'TestModel').objects.create(\n                name='test',\n                price=IntFlagEnum.A | IntFlagEnum.B,\n            )\n        )\n\n        writer = OperationWriter(operation, indentation=0)\n        serialized, _ = writer.serialize()\n        self.assertIn(\n            'models.SET_DEFAULT', serialized\n        )\n        self.assertIn(\n            f'IntFlagEnum.A | IntFlagEnum.B', serialized\n        )\n"], "sample_76": ["    def test_same_length_unique_x(self, df):\n        df['x'] = np.repeat(df['x'].unique(), 10)\n        df['y'] = np.repeat(df['y'].unique(), 10)\n        GroupBy(df, 'group').apply(\n            PolyFit(order=2),\n            groupby='group',\n            orient='x',\n            scales=None,\n        )\n", "    def test_fit_predict(self, df):\n\n        data = df.query(\"group == 'x'\")\n\n        stat = PolyFit(order=2, gridsize=50)\n        result = stat._fit_predict(data)\n\n        assert isinstance(result, pd.DataFrame)\n        assert \"x\" in result.columns\n        assert \"y\" in result.columns\n        assert len(result) == 50\n\n", "    def test_polyfit_groupby(self, df, rng):\n\n        df[\"x\"] = rng.normal(0, 1, 100)\n        df[\"y\"] = df[\"x\"]**2 + rng.normal(0, 0.5, 100)\n        df[\"group\"] = np.repeat([1, 2], 50)\n\n        groupby = GroupBy(df, 'group')\n        stat = PolyFit(order=2, gridsize=5)\n        result = stat(df, groupby, \"vertical\", {})\n        assert isinstance(result, pd.DataFrame)\n", "    def test_fit_predict(self, df):\n        # Test the _fit_predict method\n        data = df.query(\"group == 'x'\")\n\n        result = PolyFit()._fit_predict(data)\n        assert isinstance(result, pd.DataFrame)\n\n        assert_array_equal(result.columns, [\"x\", \"y\"])\n        assert len(result) == 100\n", "    def test_fit_predict(self, df):\n        x = np.linspace(-3, 3, 100)\n        y = 2 * x + 1 + np.random.normal(0, 0.5, 100)\n        data = pd.DataFrame(dict(x=x, y=y))\n\n        expected = pd.DataFrame(dict(\n            x=np.linspace(-3, 3, 100),\n            y=2 * np.linspace(-3, 3, 100) + 1\n        ))\n\n        actual = PolyFit(order=1)(data, GroupBy([\"__\"]), orient=None, scales=None)\n        assert_frame_equal(actual, expected)\n"], "sample_78": ["def test_with_appcontext(runner, tmpdir):\n    class MyBlueprint(Blueprint):\n            super().__init__(name, import_name)\n            self.called = False\n\n        @app.route('/test')\n            self.called = True\n            return 'OK'\n\n    app = Flask(__name__)\n    b = MyBlueprint('my_blueprint', __name__)\n    app.register_blueprint(b)\n\n    with tmpdir.as_cwd():\n\n        with open('app.py', 'w') as f:\n            f.write(\n                f\"from flask import Flask\\n\"\n                f\"from flask import Blueprint\\n\"\n                f\"app = Flask(__name__)\\n\"\n                f\"{b.__class__.__name__}('my_blueprint', __name__)\\n\"\n                f\"app.register_blueprint({b.__class__.__name__})\\n\"\n            )\n        result = runner.invoke(run_command, ['--app', 'app:app'])\n        assert result.exit_code == 0\n\n        import requests\n        assert requests.get('http://localhost:5000/test').text == 'OK'\n        assert b.called\n", "def test_load_dotenv_multiple_files(tmpdir):\n    (tmpdir / \".env\").write_text(\"FOO=bar\\n\")\n    (tmpdir / \".flaskenv\").write_text(\"BAR=baz\\n\")\n    os.chdir(tmpdir)\n\n    # Mock os.environ to avoid interference from existing environment\n    with pytest.MonkeyPatch.context() as m:\n        m.setattr(os, \"environ\", {})\n        load_dotenv()\n\n    assert os.environ.get(\"FOO\") == \"bar\"\n    assert os.environ.get(\"BAR\") == \"baz\"\n", "def test_load_dotenv_with_custom_path(runner):\n    \"\"\"Test loading a `.env` file from a custom path.\"\"\"\n    with tempfile.TemporaryDirectory() as tempdir:\n        env_path = Path(tempdir) / \".env\"\n        env_path.touch()\n        with open(env_path, \"w\") as f:\n            f.write(\"TEST_VAR=custom_value\\n\")\n        os.environ[\"FLASK_APP\"] = \"test_apps.app\"\n        result = runner.invoke(\n            cli.commands[\"run\"],\n            [\"--env-file\", str(env_path)],\n            catch_exceptions=False,\n        )\n        assert result.exit_code == 0\n        assert \"TEST_VAR=custom_value\" in os.environ\n", "    def test_run_command_with_cert(runner, tmpdir):\n        \"\"\"Test running the server with a certificate file.\"\"\"\n        app = Flask(__name__)\n\n        cert_file = tmpdir / \"cert.pem\"\n        cert_file.write_text(\"some cert\")\n\n        with app.app_context():\n            with runner.isolated_filesystem():\n\n                result = runner.invoke(\n                    run_command,\n                    [\"--host\", \"localhost\", \"--port\", \"5001\", \"--cert\", str(cert_file)],\n                )\n\n                assert result.exit_code == 0\n\n", "def test_run_command_with_cert(runner):\n    with runner.isolated_filesystem():\n        os.mkdir(\"test_app\")\n        (Path(\"test_app\") / \"app.py\").write_text(\n            \"\"\"\n            from flask import Flask\n\n            app = Flask(__name__)\n\n            @app.route('/')\n                return 'Hello, World!'\n        \"\"\"\n        )\n        (Path(\"test_app\") / \"cert.pem\").write_text(\n            \"\"\"-----BEGIN CERTIFICATE-----\n\n            [REPLACE WITH CERTIFICATE DATA]\n\n            -----END CERTIFICATE-----\n            \"\"\"\n        )\n        result = runner.invoke(\n            click.command()(\n                \"flask\", \"run\", \"--cert\", \"cert.pem\", \"--host\", \"localhost\", \"--port\", \"5000\"\n            ),\n            cwd=\"test_app\",\n        )\n        assert result.exit_code == 0\n\n"], "sample_44": ["    def test_to_python_with_to_field_name(self):\n        field = ModelChoiceField(queryset=Category.objects.all(), to_field_name='slug')\n        self.assertEqual(field.to_python('entertainment'), Category.objects.get(slug='entertainment'))\n        with self.assertRaises(Category.DoesNotExist):\n            field.to_python('unknown')\n", "    def test_modelchoicefield_empty_label(self):\n        class CategoryForm(forms.Form):\n            category = forms.ModelChoiceField(queryset=Category.objects.all(), empty_label=\"Select a category\")\n        f = CategoryForm()\n        self.assertEqual(f.fields['category'].choices[0], (\"\", \"Select a category\"))\n", "    def test_modelchoicefield_prepare_value(self):\n        form = ArticleForm()\n        self.assertIsNone(form.fields['category'].prepare_value(None))\n        self.assertEqual(form.fields['category'].prepare_value(self.c1), self.c1.pk)\n        self.assertEqual(form.fields['category'].prepare_value(self.c1.pk), self.c1.pk)\n\n", "    def test_modelchoicefield_empty_label(self):\n        class ArticleForm(forms.ModelForm):\n            category = forms.ModelChoiceField(queryset=Category.objects.all(), empty_label='---------')\n\n            class Meta:\n                model = Article\n                fields = ['category']\n\n        form = ArticleForm()\n        self.assertIn('---------', form.as_p())\n", "    def test_modelchoicefield_empty_label_and_choices(self):\n        class CategoryForm(forms.Form):\n            category = forms.ModelChoiceField(Category.objects.all())\n        form = CategoryForm()\n\n        self.assertEqual(form.fields['category'].choices[0], ('', '---------'))\n        self.assertEqual(len(form.fields['category'].choices), len(Category.objects.all()) + 1)\n"], "sample_79": ["    def test_concat_override():\n        ds1 = create_test_data(2)\n        ds2 = create_test_data(2).rename({'dim1': 'dim2'})\n        ds3 = create_test_data(2).rename({'dim1': 'dim3'})\n        expected = concat([ds1, ds2, ds3], dim='dim1', compat='override')\n        actual = concat([ds1, ds2, ds3], dim='dim1', compat='override', join='exact')\n        assert_identical(expected, actual)\n", "    def test_concat_compat(self, compat):\n        data = create_test_data()\n        ds1 = data[\"ds1\"]\n        ds2 = data[\"ds2\"].assign_coords({\"dim2\": [\"b\", \"c\"]})\n\n        if compat == \"identical\":\n            with pytest.raises(ValueError):\n                concat([ds1, ds2], dim=\"dim2\", compat=compat)\n        else:\n            expected = concat([ds1, ds2], dim=\"dim2\", compat=compat)\n            actual = concat([ds2, ds1], dim=\"dim2\", compat=compat)\n            assert_identical(expected, actual)\n\n", "    def test_concat_different_coords():\n        ds1 = Dataset({'foo': (('x', 'y'), np.arange(6).reshape(2, 3))},\n                      coords={'x': np.array([0, 1]), 'y': np.arange(3)})\n        ds2 = Dataset({'foo': (('x', 'y'), np.arange(6).reshape(2, 3) + 6)},\n                      coords={'x': np.array([2, 3]), 'y': np.arange(3)})\n        expected = Dataset({'foo': (('x', 'y'), np.arange(12).reshape(4, 3)),\n                           'x': np.array([0, 1, 2, 3]), 'y': np.arange(3)})\n        actual = concat([ds1, ds2], dim='x')\n        assert_identical(actual, expected)\n", "    def test_concat_different_index_types():\n        # Regression test for issue #1663\n        a = DataArray(np.arange(3), dims=['x'], coords=[pd.date_range('2000-01-01', periods=3)])\n        b = DataArray(np.arange(3), dims=['x'], coords=[\n            pd.DatetimeIndex(['2000-01-02', '2000-01-03', '2000-01-04'])\n        ])\n        expected = DataArray(np.arange(6), dims=['x'], coords=[\n            pd.DatetimeIndex(['2000-01-01','2000-01-02', '2000-01-03', '2000-01-04'])\n        ])\n        actual = concat([a, b], dim='x')\n        assert_identical(actual, expected)\n\n", "    def test_concat_identical_coords():\n        a = Dataset({'foo': ('x', [1, 2, 3])}, coords={'x': [0, 1, 2]})\n        b = Dataset({'foo': ('x', [4, 5, 6])}, coords={'x': [0, 1, 2]})\n        actual = concat([a, b], dim='x')\n        expected = Dataset({'foo': ('x', [1, 2, 3, 4, 5, 6])}, coords={'x': [0, 1, 2, 0, 1, 2]})\n        assert_identical(actual, expected)\n"], "sample_47": ["    def test_migrate_multiple_targets(self):\n        \"\"\"\n        Test migrating to multiple targets at once.\n        \"\"\"\n        with self.assertRaises(InvalidMigrationPlan):\n            with connection.schema_editor() as editor:\n                executor = MigrationExecutor(connection)\n                executor.migrate(\n                    targets=[\n                        ('migrations2', '0002_auto_20221012_1457'),\n                        ('migrations2', '0001_initial'),\n                    ],\n                )\n\n", "    def test_unapply_migration_with_replacements(self):\n        \"\"\"\n        Test unapplying a migration that replaces others.\n        \"\"\"\n        # Create a migration for app 'migrations2' that replaces two migrations\n        with self.connection.cursor() as cursor:\n            self.run_migration_plan('migrations2', '0001_initial', cursor=cursor)\n        with self.connection.cursor() as cursor:\n            self.run_migration_plan('migrations2', '0002_replace_initial', cursor=cursor)\n        \n        # Check that the replaced migrations are marked as unapplied\n        recorder = MigrationRecorder(self.connection)\n        self.assertEqual(recorder.applied_migrations(), {('migrations2', '0002_replace_initial')})\n\n        # Unapply the replacing migration\n        with self.connection.cursor() as cursor:\n            self.run_migration_plan('migrations2', '0002_replace_initial', reverse=True, cursor=cursor)\n\n        # Check that the replaced migrations are marked as unapplied\n        self.assertEqual(recorder.applied_migrations(), set())\n", "    def test_migrate_unapplied_initial_migration(self):\n        \"\"\"\n        Test that an unapplied initial migration is detected and applied correctly\n        when using 'migrate' with no target specified.\n\n        Requires a database that:\n            * Supports introspection of table names\n            * Allows migration creation for the 'migrations2' app\n        \"\"\"\n        with self.connection.cursor() as cursor:\n            with mock.patch('django.db.migrations.executor.MigrationExecutor.detect_soft_applied',\n                            return_value=(True, ProjectState(real_apps=self.loader.unmigrated_apps))):\n                executor = MigrationExecutor(self.connection)\n                executor.migrate(\n                    targets=[('migrations2', None)],\n                    fake_initial=True,\n                )\n                self.assertTableExists('migrations2_testmodel', using=self.connection.alias)\n                self.assertColumnExists('migrations2_testmodel', 'name', using=self.connection.alias)\n", "    def test_migrate_replacements(self):\n        # Test that replacement migrations are correctly applied and unapplied.\n        with self.connection.cursor() as cursor:\n            self.connection.introspection.table_names(cursor)\n        self.migrate(\"migrations2\")\n        with self.connection.cursor() as cursor:\n            self.connection.introspection.table_names(cursor)\n        self.migrate(\"migrations2\", [\"0002_replace_model\"], fake=True)\n        with self.connection.cursor() as cursor:\n            self.connection.introspection.table_names(cursor)\n        self.migrate(\"migrations2\", [\"0002_replace_model\"])\n        with self.connection.cursor() as cursor:\n            self.connection.introspection.table_names(cursor)\n        self.migrate(\"migrations2\", [\"0003_other_model\"], fake=True)\n        with self.connection.cursor() as cursor:\n            self.connection.introspection.table_names(cursor)\n        self.migrate(\"migrations2\", [\"0003_other_model\"])\n        with self.connection.cursor() as cursor:\n            self.connection.introspection.table_names(cursor)\n", "    def test_migrate_forwards_then_backwards(self):\n        \"\"\"\n        Test forward and backward migration within the same transaction.\n        \"\"\"\n        with self.assertRaises(InvalidMigrationPlan):\n            with self.connection.atomic():\n                executor = MigrationExecutor(self.connection)\n                executor.migrate(\n                    targets=[('migrations2', '0002_secondmodel')],\n                    fake=True,\n                )\n                executor.migrate(\n                    targets=[('migrations2', None)],\n                    fake=True,\n                )\n"], "sample_33": ["    def test_receiver_disconnect(self):\n            pass\n\n        a_signal.connect(receiver_func)\n        self.assertTrue(a_signal.has_listeners())\n        a_signal.disconnect(receiver_func)\n        self.assertFalse(a_signal.has_listeners())\n        # Test that disconnecting a non-existent receiver doesn't raise an error\n        a_signal.disconnect(receiver_func)\n        self.assertFalse(a_signal.has_listeners())\n", "    def test_signal_weak_receiver_garbage_collected(self):\n        class WeakReceiver:\n                self.signal = signal\n\n                pass\n\n        receiver_inst = WeakReceiver(a_signal)\n        weak_ref = weakref.ref(receiver_inst)\n        a_signal.connect(receiver_inst, weak=True)\n\n        del receiver_inst\n        garbage_collect()\n        self.assertIsNone(weak_ref())\n        self.assertTestIsClean(a_signal)\n", "    def test_receiver_disconnect_weakref(self):\n            pass\n\n        receiver_instance = Callable()\n        a_signal.connect(receiver_func, weak=True)\n        del receiver_instance\n        garbage_collect()\n        self.assertTestIsClean(a_signal)\n", "    def test_signal_disconnect_weakref_gc(self):\n            pass\n        # Create a weakref to the receiver\n        receiver_ref = weakref.ref(receiver_func)\n        a_signal.connect(receiver_ref(), sender=None)\n        self.assertTrue(a_signal.has_listeners())\n        # Delete the strong reference\n        del receiver_func\n        # Force garbage collection\n        garbage_collect()\n        # Assert that receiver is disconnected\n        self.assertFalse(a_signal.has_listeners())\n", "    def test_receiver_disconnect_on_garbage_collection(self):\n            pass\n\n        weak_ref = weakref.ref(receiver_func)\n        a_signal.connect(receiver_func, weak=True)\n\n        # Garbage collect to remove receiver_func\n        del receiver_func\n        garbage_collect()\n\n        # Check that receiver_func is no longer connected\n        self.assertFalse(a_signal._live_receivers(None))\n        self.assertFalse(a_signal.has_listeners())\n"], "sample_140": ["def test_point_set_pos():\n    N = ReferenceFrame('N')\n    p1 = Point('p1')\n    p2 = Point('p2')\n    p1.set_pos(p2, 10*N.x)\n    assert p1.pos_from(p2) == 10*N.x\n    p2.set_pos(p1, 5*N.y)\n    assert p2.pos_from(p1) == 5*N.y\n", "def test_locatenew():\n    N = ReferenceFrame('N')\n    p1 = Point('p1')\n    p2 = p1.locatenew('p2', 10*N.x)\n    assert p2.pos_from(p1) == 10*N.x\n    assert p1.pos_from(p2) == -10*N.x\n", "    def test_pos_from_multipoint(self):\n        N = ReferenceFrame('N')\n        O = Point('O')\n        P = Point('P')\n        Q = Point('Q')\n        O.set_pos(N, 10* N.x)\n        P.set_pos(O, 5*N.y)\n        Q.set_pos(P, 2*N.z)\n        assert Q.pos_from(N) == 10*N.x + 5*N.y + 2*N.z\n", "    def test_set_acc(self):\n        N = ReferenceFrame('N')\n        p1 = Point('p1')\n        p1.set_acc(N, 10 * N.x)\n        assert p1.acc(N) == 10 * N.x\n", "    def test_locatenew_with_vector_input(self):\n        N = ReferenceFrame('N')\n        p1 = Point('p1')\n        v = 10*N.x\n        p2 = p1.locatenew('p2', v)\n        assert p2.pos_from(p1) == v\n"], "sample_9": ["    def test_iter_modules_and_files_zipfile(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_path = Path(tempdir) / 'my_package.zip'\n            with zipfile.ZipFile(zip_path, 'w') as zf:\n                zf.writestr('my_package/__init__.py', '')\n            self.import_and_cleanup('my_package')\n            self.assertFileFound(zip_path)\n", "    def test_watchman_error_handling(self):\n        with mock.patch('django.utils.autoreload.pywatchman.client', side_effect=pywatchman.WatchmanError):\n            reloader = autoreload.WatchmanReloader()\n            with self.assertRaises(autoreload.WatchmanUnavailable):\n                reloader.check_availability()\n\n", "    def test_watch_files_inside_zip(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_filename = Path(tempdir) / 'archive.zip'\n\n            with zipfile.ZipFile(zip_filename, 'w') as zipf:\n                zipf.writestr('module.py', 'print(\"Hello!\")')\n\n            sys.path.append(tempdir)\n            self.import_and_cleanup('archive.module')\n            zip_file = Path(zip_filename)\n            self.assertFileFound(zip_file)\n", "    def test_watchman_globs_resolve_to_correct_paths(self):\n        with extend_sys_path(self.temporary_file('tempdir')):\n            self.temporary_file('tempdir/app').touch()\n            reloader = autoreload.WatchmanReloader()\n            reloader.watch_glob(self.temporary_file('tempdir'), ['*.py'])\n            self.assertSetEqual(\n                set(reloader.watched_files(include_globs=True)),\n                {self.temporary_file('tempdir/app')},\n            )\n", "    def test_iter_modules_and_files_zip_import(self):\n        zip_filename = self.temporary_file('test.zip')\n        with zipfile.ZipFile(zip_filename, 'w') as zf:\n            zf.writestr('test_module.py', 'pass')\n        sys.path.append(str(zip_filename.parent))\n        self.import_and_cleanup('test_module')\n        self.assertFileFound(zip_filename)\n\n"], "sample_110": ["    def test_affinity_propagation_empty_preference():\n        \"\"\"Test affinity propagation with empty preference array.\"\"\"\n\n        # Create a similarity matrix with all equal values\n        S = np.ones((10, 10))\n\n        # Set preference to an empty array\n        preference = np.array([])\n\n        with pytest.warns(ConvergenceWarning):\n            cluster_centers_indices, labels = affinity_propagation(\n                S, preference=preference, damping=0.5, max_iter=100,\n                convergence_iter=10\n            )\n\n        assert_array_equal(cluster_centers_indices, [])\n        assert_array_equal(labels, [-1] * 10)\n\n", "def test_affinity_propagation_empty_array():\n    # Test affinity propagation when all input data is equal\n    X = np.zeros((5, 2))\n    model = AffinityPropagation(preference=-1).fit(X)\n    assert_array_equal(model.labels_, np.array([-1, -1, -1, -1, -1]))\n", "    def test_affinity_propagation_all_equal_similarities():\n        \"\"\" Test affinity propagation with all equal similarities and preferences\"\"\"\n        X = np.ones((10, 10))\n        with assert_warns(UserWarning) as w:\n            ap = AffinityPropagation(preference=0.1).fit(X)\n        assert \"All samples have mutually equal similarities\" in str(w.warning)\n        assert_array_equal(ap.labels_, np.zeros(10))\n        with assert_warns(UserWarning) as w:\n            ap = AffinityPropagation(preference=10).fit(X)\n        assert \"All samples have mutually equal similarities\" in str(w.warning)\n        assert_array_equal(ap.labels_, np.arange(10))\n\n", "    def test_equal_similarities_and_preferences():\n        S = np.ones((5, 5))\n        preference = np.ones(5)\n        assert _equal_similarities_and_preferences(S, preference)\n        preference = np.array([1, 2, 3, 4, 5])\n        assert not _equal_similarities_and_preferences(S, preference)\n        S = np.array([[1, 2, 3, 4, 5],\n                      [2, 1, 3, 4, 5],\n                      [3, 3, 1, 4, 5],\n                      [4, 4, 4, 1, 5],\n                      [5, 5, 5, 5, 1]])\n        preference = np.ones(5)\n        assert not _equal_similarities_and_preferences(S, preference)\n\n\n\n", "    def test_affinity_propagation_empty_input():\n        # Check behavior when input is empty\n        with pytest.raises(ValueError):\n            affinity_propagation(np.array([]))\n\n        # Check behavior with empty preference array\n        with pytest.raises(ValueError):\n            affinity_propagation(X, preference=np.array([]))\n"], "sample_120": ["def test_MatrixElement_subs():\n    i, j = symbols('i j', integer=True)\n    A = MatrixSymbol('A', 3, 3)\n    e = MatrixElement(A, i, j)\n    assert e.subs(i, 1) == MatrixElement(A, 1, j)\n    assert e.subs(j, 2) == MatrixElement(A, i, 2)\n    assert e.subs(A, B) == MatrixElement(B, i, j)\n", "def test_MatAdd_commutative():\n    assert (A + B).is_commutative == False\n", "def test_Identity_determinant():\n    assert Identity(3).determinant() == 1\n", "def test_zero_matrix_power():\n    Z = ZeroMatrix(3, 3)\n    assert Z**0 == Identity(3)\n    assert Z**1 == Z\n    raises(ValueError, lambda: Z**(-1))\n", "def test_MatrixElement_doit():\n    # Test doit method for MatrixElement\n    i, j = symbols('i j', integer=True)\n    M = MatrixSymbol('M', 3, 3)\n    M_ij = MatrixElement(M, i, j)\n    assert M_ij.doit() == M[i, j]\n\n    # Test doit with symbolic indices\n    M_12 = MatrixElement(M, 1, 2)\n    assert M_12.doit() == M[1, 2]\n"], "sample_2": ["    def test_projection_preservation(self):\n        \"\"\"\n        Test that the projection type is preserved when a WCS object is re-\n        created from a header.\n        \"\"\"\n\n        for filename in self._file_list:\n            with open(filename, \"r\") as f:\n                header = fits.Header.fromstring(f.read())\n            \n            w = wcs.WCS(header)\n            with pytest.raises(ValueError):\n                w.sub([[1,2]])\n            \n\n\n\n", "    def test_maps_fits(self):\n        \"\"\"Test reading and parsing of FITS headers for maps.\"\"\"\n        for filename in self._file_list:\n            with fits.open(filename) as hdul:\n                wcs_obj = wcs.WCS(hdul[0].header)\n                assert isinstance(wcs_obj, wcs.WCS)\n", "    def test_wcs_slicing(self):\n        # Test slicing of WCS objects\n\n        with catch_warnings() as w:\n            warnings.simplefilter(\"ignore\", AstropyUserWarning)\n            for filename in self._file_list:\n                # skip test if the file doesn't exist\n                if not os.path.exists(filename):\n                    continue\n\n                hdulist = fits.open(filename)\n\n                wcs_obj = wcs.WCS(hdulist[0].header)\n                new_wcs = wcs_obj.slice(\n                    (slice(None), slice(None)), numpy_order=True)\n                assert new_wcs.naxis == wcs_obj.naxis\n                assert new_wcs.wcs.crpix == wcs_obj.wcs.crpix\n", "    def test_wcs_to_header(self):\n        \"\"\"Test conversion of WCS to FITS header.\"\"\"\n\n        with catch_warnings(AstropyUserWarning):\n            for f in self._file_list:\n                with fits.open(f) as hdul:\n                    header = hdul[0].header\n\n                    # Read the WCS from the header\n                    wcs_obj = wcs.WCS(header)\n\n                    # Convert the WCS object back to a header\n                    new_header = wcs_obj.to_header()\n\n                    # Compare the original and new headers (ignoring history)\n                    for key in header:\n                        if key.startswith(\"HISTORY\"):\n                            continue\n                        assert header[key] == new_header.get(key)\n", "    def test_reorient_celestial_first(self):\n        \"\"\"\n        Test reorient_celestial_first method.\n        \"\"\"\n        with catch_warnings() as w:\n            # Ignore the warning for non-standard WCS keywords\n            warnings.simplefilter(\"ignore\", AstropyUserWarning)\n            for filename in self._file_list:\n                with open(filename, 'r') as f:\n                    header_str = f.read()\n\n                hdulist = fits.fromstring(header_str)\n                w = wcs.WCS(hdulist[0].header)\n                if len(w.wcs.axis_types) >= 2:\n                    w_reoriented = w.reorient_celestial_first()\n                    assert w_reoriented.wcs.axis_types[:2] == [\n                        2, 2\n                    ], f\"Axis types for {filename} are incorrect after reorientation\"\n\n"], "sample_20": ["    def test_index_together_empty_name(self):\n        class MyModel(models.Model):\n            name = models.CharField(max_length=100)\n            class Meta:\n                index_together = []\n\n        with self.assertRaisesMessage(\n            ValueError, \"index_together must be a list or tuple\"\n        ):\n            MyModel.check()\n", "    def test_index_together_invalid_field(self):\n        with self.assertRaisesMessage(ValueError, 'The field \"fake_field\" does not exist in the model \"TestModel\".'):\n            class TestModel(models.Model):\n                name = models.CharField(max_length=100)\n\n                class Meta:\n                    index_together = [\n                        ('name', 'fake_field'),\n                    ]\n\n", "    def test_check_indexes_with_conditions(self):\n        allowed_len, db_alias = get_max_column_name_length()\n        with override_settings(DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3'}}):\n            class MyModel(models.Model):\n                name = models.CharField(max_length=100)\n                value = models.IntegerField()\n\n                class Meta:\n                    indexes = [\n                        models.Index(fields=['name', 'value'], condition=models.Q(value__gt=10)),\n                    ]\n            errors = MyModel._meta.check(databases=['default'])\n            if allowed_len:\n                self.assertEqual(len(errors), 1)\n                self.assertIsInstance(errors[0], Warning)\n                self.assertEqual(errors[0].id, 'models.W037')\n            else:\n                self.assertEqual(len(errors), 0)\n\n\n", "    def test_index_together_on_different_databases(self):\n        with override_settings(DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3'},\n                                        'other': {'ENGINE': 'django.db.backends.postgresql'}}):\n            class MyModel(models.Model):\n                name = models.CharField(max_length=10)\n                data = models.TextField()\n\n            MyModel._meta.index_together = [('name', 'data')]\n            router = EmptyRouter()\n            router._databases = {'default': 'default', 'other': 'other'}\n            MyModel._meta.router = router\n            with connections['default'].cursor() as cursor:\n                cursor.execute(\"SELECT * FROM invalid_models_tests_mymodel\")\n                cursor.fetchone()\n            with connections['other'].cursor() as cursor:\n                cursor.execute(\"SELECT * FROM invalid_models_tests_mymodel\")\n                cursor.fetchone()\n\n", "    def test_check_index_together_invalid_type(self):\n        with self.assertRaisesMessage(TypeError, \"'index_together' must be a list or tuple.\"):\n            class MyModel(models.Model):\n                name = models.CharField(max_length=100)\n                \n                class Meta:\n                    index_together = 'name'\n"], "sample_130": ["def test_lambdify_matrix_with_scalar():\n    x = Symbol('x')\n    M = Matrix([[1, x], [x, x**2]])\n    lam_M = lambdify(x, M)\n    assert lam_M(2) == Matrix([[1, 2], [2, 4]])\n", "def test_lambdify_piecewise():\n    f = Piecewise((0, x < 0), (x, x >= 0))\n    f_ = lambdify(x, f)\n    assert f_(-1) == 0\n    assert f_(1) == 1\n\n    g = Piecewise((x, x < 0), (0, x >= 0))\n    g_ = lambdify(x, g)\n    assert g_(-1) == -1\n    assert g_(1) == 0\n", "def test_lambdify_integral():\n    f = Integral(x**2, x)\n    assert lambdify(x, f)(2) == 8/3\n", "def test_lambdify_nested_lists():\n    # Test lambdifying an expression with nested lists as arguments\n    expr = [ [x*y**2], [sin(x)] ]\n    f = lambdify((x, y), expr, 'numpy')\n    res = f(2, 3)\n    assert isinstance(res, list)\n    assert isinstance(res[0], list)\n    assert res == [[18], [ 0.9092974268256817]]\n\n", "def test_lambdify_piecewise():\n    f = Piecewise((x, x < 1), (2*x, x >= 1))\n    g = lambdify(x, f)\n    assert g(0) == 0\n    assert g(1) == 2\n    assert g(2) == 4\n\n"], "sample_8": ["    def test_callable_setting_wrapper_repr(self):\n        class MyCallable:\n                return 'MyCallable'\n\n        wrapped = CallableSettingWrapper(MyCallable())\n        self.assertEqual(repr(wrapped), repr(MyCallable()))\n", "    def test_callable_setting_wrapper_repr(self):\n        wrapper = CallableSettingWrapper(lambda: 'a_callable')\n        self.assertEqual(repr(wrapper), '<bound method lambda of <object object at ...>>')\n", "    def test_callable_setting_wrapper_repr(self):\n        class MyCallable:\n                return 'MyCallable()'\n\n        wrapped_callable = CallableSettingWrapper(MyCallable())\n        self.assertEqual(repr(wrapped_callable), 'MyCallable()')\n", "    def test_callable_setting_wrapper(self):\n        wrapper = CallableSettingWrapper(lambda: 'sensitive data')\n        self.assertEqual(repr(wrapper), '<bound method CallableSettingWrapper.<lambda> at ...>')\n", "    def test_sensitive_variables_wrapper_clears_sensitive_variables(self):\n        request = RequestFactory().get('/')\n        request.user = User()\n\n            return func(*args, **kwargs)\n\n        with mock.patch('django.views.debug.get_default_exception_reporter_filter') as mock_filter:\n            mock_filter.return_value.get_traceback_frame_variables.return_value = [('sensitive_var', CLEANSED_SUBSTITUTE)]\n            response = sensitive_variables_wrapper(sensitive_view, request=request)\n            self.assertIn(CLEANSED_SUBSTITUTE, response.content.decode())\n"], "sample_15": ["    def test_check_setting_language_code_invalid(self):\n        with override_settings(LANGUAGE_CODE='e\u00fc'):\n            errors = check_setting_language_code(None, **{})\n            self.assertEqual(len(errors), 1)\n            self.assertIsInstance(errors[0], Error)\n", "    def test_check_setting_language_code(self):\n        for tag in self.valid_tags:\n            with override_settings(LANGUAGE_CODE=tag):\n                self.assertEqual(check_setting_language_code(None), [])\n\n        for tag in self.invalid_tags:\n            with override_settings(LANGUAGE_CODE=tag):\n                self.assertEqual(check_setting_language_code(None), [Error(\n                    'You have provided an invalid value for the LANGUAGE_CODE setting: {!r}.'.format(tag),\n                    id='translation.E001',\n                )])\n", "    def test_check_setting_languages(self):\n        with override_settings(LANGUAGES=[('en', 'English'), (123, 'Some language')]):\n            errors = check_setting_languages(None, **{})\n            self.assertEqual(len(errors), 1)\n            self.assertIsInstance(errors[0], Error)\n        with override_settings(LANGUAGES=[('en', 'English'), ('e\u00fc', 'Some language')]):\n            errors = check_setting_languages(None, **{})\n            self.assertEqual(len(errors), 1)\n            self.assertIsInstance(errors[0], Error)\n\n", "    def test_check_setting_languages_bidi(self):\n        for tag in self.valid_tags:\n            settings.LANGUAGES_BIDI = [tag]\n            errors = check_setting_languages_bidi(None, **{})\n            self.assertEqual(errors, [])\n\n        for tag in self.invalid_tags:\n            settings.LANGUAGES_BIDI = [tag]\n            errors = check_setting_languages_bidi(None, **{})\n            self.assertEqual(len(errors), 1, errors)\n            self.assertIsInstance(errors[0], Error)\n", "    def test_check_setting_language_code_valid(self):\n        errors = check_setting_language_code(None, **{})\n        self.assertEqual(errors, [])\n\n"], "sample_4": ["    def test_set_cookie_samesite(self):\n        response = HttpResponse()\n        response.set_cookie('mycookie', 'value', samesite='strict')\n        self.assertEqual(response.cookies['mycookie']['samesite'], 'strict')\n\n        with self.assertRaises(ValueError):\n            response.set_cookie('mycookie', 'value', samesite='invalid')\n\n", "    def test_copy(self):\n        qd = QueryDict('a=1&b=2&c=3&a=4', mutable=True)\n        copy_qd = copy.copy(qd)\n        self.assertEqual(qd, copy_qd)\n        copy_qd['a'] = '5'\n        self.assertEqual(qd['a'], '1')\n        self.assertEqual(copy_qd['a'], '5')\n", "    def test_cookie_parsing(self):\n        cookie_str = 'user=foo; sessionid=bar; key=value; path=/; HttpOnly; SameSite=Strict'\n        cookies = parse_cookie(cookie_str)\n        self.assertEqual(cookies['user'].value, 'foo')\n        self.assertEqual(cookies['sessionid'].value, 'bar')\n        self.assertEqual(cookies['key'].value, 'value')\n        self.assertEqual(cookies['user'].path, '/')\n        self.assertTrue(cookies['user'].httponly)\n        self.assertEqual(cookies['user'].samesite, 'Strict')\n", "    def test_getlist_with_no_key(self):\n        qd = QueryDict('')\n        self.assertEqual(qd.getlist('foo'), [])\n", "    def test_getlist(self):\n        qd = QueryDict('a=1&a=2&b=3')\n        self.assertEqual(qd.getlist('a'), ['1', '2'])\n        self.assertEqual(qd.getlist('b'), ['3'])\n        self.assertEqual(qd.getlist('c'), [])\n"], "sample_69": ["    def test_ArtistInspector_get_valid_values(self):\n        fig, ax = plt.subplots()\n        line, = ax.plot([1, 2], [1, 2])\n\n        ai = martist.ArtistInspector(line)\n        assert ai.get_valid_values('color') == 'color: color, None'\n        assert ai.get_valid_values('linestyle') == (\n            'linestyle: {\"-\", \"--\", \"-.\", \":\", \"\", (offset, on-off-seq), '\n            '..., \"solid\", \"dashed\", \"dashdot\", \"dotted\"'\n        )\n        assert ai.get_valid_values('linewidth') == 'linewidth: float or None'\n\n        # Test for alias\n        assert ai.get_valid_values('lw') == 'linewidth: float or None'\n\n        # Test for property with no docstring\n        assert ai.get_valid_values('zorder') == 'unknown'\n\n        # Test for property with no 'ACCEPTS:' line in docstring\n        assert ai.get_valid_values('set_picker') == 'unknown'\n", "def test_artistinspector_transform():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], [1, 2, 3])\n    ai = martist.ArtistInspector(ax.lines[0])\n    assert ai.get_valid_values('transform') == 'matplotlib.transforms.Transform or None'\n", "    def test_setp_keyword_alias(self):\n        fig, ax = plt.subplots()\n        line, = ax.plot([1, 2, 3], [4, 5, 6])\n\n        # set with keyword arguments\n        setp(line, linewidth=2, color='r')\n        assert line.get_linewidth() == 2\n        assert line.get_color() == 'r'\n\n        # set with alias\n        setp(line, lw=3, c='b')\n        assert line.get_linewidth() == 3\n        assert line.get_color() == 'b'\n", "    def test_setp_with_aliases():\n        fig, ax = plt.subplots()\n        line, = ax.plot(range(5))\n        \n        # Using aliases\n        setp(line, lw=3, c='r')\n        assert line.get_linewidth() == 3\n        assert line.get_color() == 'r'\n        \n        setp(line, 'linewidth', 2, 'color', 'b')\n        assert line.get_linewidth() == 2\n        assert line.get_color() == 'b'\n", "    def test_getp_setp(self):\n        fig, ax = plt.subplots()\n        line, = ax.plot([1, 2, 3], [4, 5, 6])\n        assert getp(line, 'color') == line.get_color()\n\n        setp(line, color='r', linewidth=5)\n        assert getp(line, 'color') == 'r'\n        assert getp(line, 'linewidth') == 5\n\n        # Test setting multiple properties at once\n        setp(line, linestyle='--', marker='o')\n        assert getp(line, 'linestyle') == '--'\n        assert getp(line, 'marker') == 'o'\n\n        # Test setting using MATLAB style string/value pairs\n        setp(line, 'linewidth', 2, 'color', 'g')\n        assert getp(line, 'linewidth') == 2\n        assert getp(line, 'color') == 'g'\n"], "sample_57": ["    def test_formset_factory_absolute_max(self):\n        formset = formset_factory(\n            FavoriteDrinkForm,\n            max_num=10,\n            absolute_max=5,\n        )\n        formset = formset(data={\n            \"choices-TOTAL_FORMS\": \"6\",\n            \"choices-0-name\": \"a\",\n            \"choices-1-name\": \"b\",\n            \"choices-2-name\": \"c\",\n            \"choices-3-name\": \"d\",\n            \"choices-4-name\": \"e\",\n            \"choices-5-name\": \"f\",\n        })\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(\n            formset.errors,\n            [{'name': ['Ensure this value is less than or equal to 5.']}],\n        )\n", "    def test_formset_widget_passing(self):\n        class MyForm(Form):\n            field = CharField(widget=HiddenInput())\n        # Ensure that the widget specified in the form is used in the formset\n        MyFormSet = formset_factory(MyForm)\n        formset = MyFormSet()\n        self.assertEqual(type(formset.forms[0].fields[\"field\"].widget), HiddenInput)\n", "    def test_formset_factory_absolute_max(self):\n        formset_class = formset_factory(\n            Choice,\n            max_num=2,\n            absolute_max=3,\n        )\n        formset = formset_class(data={'choices-0-choice': 'a', 'choices-0-votes': '1',\n                                      'choices-1-choice': 'b', 'choices-1-votes': '2',\n                                      'choices-2-choice': 'c', 'choices-2-votes': '3',\n                                      'choices-TOTAL_FORMS': '3',\n                                      'choices-INITIAL_FORMS': '0',\n                                      'choices-MAX_NUM_FORMS': '2',\n                                      'choices-MIN_NUM_FORMS': '0'})\n        self.assertTrue(formset.is_valid())\n        self.assertEqual(len(formset.cleaned_data), 3)\n\n        formset = formset_class(data={'choices-0-choice': 'a', 'choices-0-votes': '1',\n                                      'choices-1-choice': 'b', 'choices-1-votes': '2',\n                                      'choices-2-choice': 'c', 'choices-2-votes': '3',\n                                      'choices-3-choice': 'd', 'choices-3-votes': '4',\n                                      'choices-TOTAL_FORMS': '4',\n                                      'choices-INITIAL_FORMS': '0',\n                                      'choices-MAX_NUM_FORMS': '2',\n                                      'choices-MIN_NUM_FORMS': '0'})\n        self.assertFalse(formset.is_valid())\n", "    def test_formset_factory_min_num(self):\n        formset = self.make_choiceformset(\n            formset_data=[(\"Pizza\", 10), (\"Tacos\", 5)],\n            min_num=3,\n        )\n        self.assertFalse(formset.is_valid())\n        self.assertEqual(len(formset.errors), 1)\n        self.assertEqual(\n            formset.errors[0].code, \"too_few_forms\"\n        )\n\n", "    def test_formset_factory_with_custom_kwargs(self):\n        formset = formset_factory(CustomKwargForm, extra=1)\n\n        formset_instance = formset(\n            {\"form-0-custom_kwarg\": \"test_value\"}, prefix=\"form\", auto_id=False\n        )\n        self.assertEqual(formset_instance.forms[0].custom_kwarg, \"test_value\")\n"], "sample_32": ["    def test_key_transform_isnull_with_multiple_keys(self):\n        model = JSONModel.objects.create(data={'a': {'b': 5}})\n        with self.assertRaisesMessage(\n            JSONField.DoesNotExist, \"JSONField has no keys matching: 'a__c'\",\n        ):\n            model.data__a__c__isnull = False\n        self.assertTrue(model.data__a__b__isnull is False)\n        self.assertTrue(JSONModel.objects.filter(data__a__b__isnull=False).exists())\n        self.assertFalse(\n            JSONModel.objects.filter(data__a__c__isnull=False).exists()\n        )\n", "    def test_key_transform_isnull_with_lhs_expression(self):\n        JSONModel.objects.create(data={'key': 'value'})\n        obj = JSONModel.objects.annotate(\n            key_isnull=Cast(\n                ExpressionWrapper(KeyTransform('key'), output_field=models.BooleanField()),\n                output_field=models.BooleanField(),\n            )\n        ).filter(key_isnull=False).first()\n        self.assertIsNotNone(obj)\n", "    def test_key_transform_in_lookup_with_null(self):\n        model = JSONModel.objects.create(data={'key': 'value'})\n        with self.assertRaises(IntegrityError):\n            JSONModel.objects.create(data={'key': None})\n\n        qs = JSONModel.objects.filter(data__key__in=[None, 'value'])\n        self.assertQuerysetEqual(qs, [model])\n\n        qs = JSONModel.objects.filter(data__key__in=['value'])\n        self.assertQuerysetEqual(qs, [model])\n", "    def test_key_transform_transform_expression_with_subquery(self):\n        # Ensure KeyTransform works with subquery expressions.\n        related_instances = RelatedJSONModel.objects.create(\n            data_json={'key1': 1, 'key2': 2},\n        )\n        with connection.cursor() as cursor:\n            cursor.execute(\n                \"SELECT COUNT(*) FROM jsonfield_relatedjsonmodel WHERE json_data->>'key1' = %s\",\n                [str(related_instances.data_json['key1'])],\n            )\n            count = cursor.fetchone()[0]\n        self.assertEqual(count, 1)\n\n", "    def test_key_transform_isnull_false(self):\n        model = JSONModel.objects.create(\n            data={'key': 'value'},\n        )\n        self.assertEqual(JSONModel.objects.filter(data__key__isnull=False).count(), 1)\n        self.assertEqual(JSONModel.objects.filter(data__key__isnull=True).count(), 0)\n"], "sample_73": ["def test_draggable_annotation():\n    fig, ax = plt.subplots()\n    text = ax.text(0.5, 0.5, \"Draggable Text\", ha=\"center\", va=\"center\")\n    ann = AnnotationBbox(text, (0.5, 0.9), xycoords=\"axes fraction\",\n                         boxcoords=\"axes fraction\",\n                         box_alignment=(0.5, 0.5),\n                         draggable=True)\n    ax.add_artist(ann)\n    ax.set_xlim([0, 1])\n    ax.set_ylim([0, 1])\n    ax.set_aspect(\"equal\")\n    plt.draw()\n    # Dragging isn't testable in an automated fashion, but we can\n    # at least validate that draggable=True doesn't raise an error.\n", "def test_draggable_annotation():\n    fig, ax = plt.subplots()\n\n    # Create a simple annotation\n    txt = ax.annotate(\"Annotation\", (0.5, 0.5), xycoords='data',\n                      ha='center', va='center')\n    draggable_annotation = DraggableAnnotation(txt)\n\n    # Trigger the on_pick event\n    event = MouseEvent('pick_event', xdata=0.5, ydata=0.5, button=MouseButton.LEFT,\n                       inaxes=ax, artist=txt)\n    draggable_annotation.on_pick(event)\n\n    # Simulate a drag motion\n    event = MouseEvent('motion_notify_event', xdata=0.6, ydata=0.6,\n                       inaxes=ax)\n    draggable_annotation.on_motion(event)\n\n    # Simulate release\n    event = MouseEvent('button_release_event', xdata=0.6, ydata=0.6,\n                       inaxes=ax, button=MouseButton.LEFT)\n    draggable_annotation.on_release(event)\n\n    # Assert that the annotation's position has changed\n    assert_allclose(txt.xyann, (0.6, 0.6))\n", "    def test_AnnotationBbox_annotation_clip_false(self):\n        fig, ax = plt.subplots()\n        xy = (1.5, 1.5)\n        ann = AnnotationBbox(\n            TextArea(\"Test\"), xy, clip_on=False,\n            xybox=(1.2, 1.2),\n            boxcoords=\"axes fraction\",\n            box_alignment=(0.5, 0.5),\n            bboxprops=dict(boxstyle=\"round,pad=0.2\", facecolor=\"w\"),\n            arrowprops=dict(arrowstyle=\"->\"))\n        ax.add_artist(ann)\n        ax.set_xlim(0, 2)\n        ax.set_ylim(0, 2)\n        fig.canvas.draw()\n        # Make sure the annotation is fully drawn even though xy is outside\n        # the axes limits.\n        assert len(ax.images) == 0\n", "def test_draggable_annotation():\n    fig, ax = plt.subplots()\n\n    # Create a simple annotation\n    ann = ax.annotate(\"Annotation\", xy=(0.5, 0.5), xycoords=\"data\")\n\n    # Make it draggable\n    draggable_ann = DraggableAnnotation(ann)\n\n    # Simulate a mouse click and drag\n    event1 = MouseEvent('button_press_event', fig.canvas, \n                        x=50, y=50, button=MouseButton.LEFT)\n    event2 = MouseEvent('motion_notify_event', fig.canvas, \n                        x=100, y=100)\n    event3 = MouseEvent('button_release_event', fig.canvas, \n                        x=100, y=100, button=MouseButton.LEFT)\n\n    draggable_ann.on_pick(event1)\n    draggable_ann.on_motion(event2)\n    draggable_ann.on_release(event3)\n\n    # Check if the annotation's position has changed\n    assert ann.xyann != (0.5, 0.5) \n\n    plt.close(fig)\n", "    def test_offsetbox_arrow(self):\n        fig, ax = plt.subplots()\n        bbox = OffsetBox(\n            TextArea(\"Test\"),\n            bbox=dict(facecolor=\"w\", pad=5)\n        )\n        ab = AnnotationBbox(\n            bbox, (0.5, 0.5),\n            xybox=(0.7, 0.8),\n            arrowprops=dict(arrowstyle=\"->\"),\n            boxcoords='axes fraction',\n            frameon=True\n        )\n        ax.add_artist(ab)\n        ax.set_xlim([0, 1])\n        ax.set_ylim([0, 1])\n"], "sample_113": ["    def test_sparse_output(self):\n        X = np.array([[1, 2], [3, 4]])\n        ct = ColumnTransformer(\n            transformers=[\n                ('trans1', Trans(), [0]),\n                ('trans2', Trans(), [1]),\n            ],\n            sparse_threshold=0.5,\n        )\n        X_trans = ct.fit_transform(X)\n        assert isinstance(X_trans, sparse.csr_matrix)\n        assert_allclose(X_trans.toarray(), [[1, 2], [3, 4]])\n\n        ct = ColumnTransformer(\n            transformers=[\n                ('trans1', Trans(), [0]),\n                ('trans2', Trans(), [1]),\n            ],\n            sparse_threshold=0,\n        )\n        X_trans = ct.fit_transform(X)\n        assert isinstance(X_trans, np.ndarray)\n        assert_allclose(X_trans, [[1, 2], [3, 4]])\n\n        X_sparse = sparse.csr_matrix(X)\n        ct = ColumnTransformer(\n            transformers=[\n                ('trans1', Trans(), [0]),\n                ('trans2', Trans(), [1]),\n            ],\n            sparse_threshold=0.5,\n        )\n        X_trans = ct.fit_transform(X_sparse)\n        assert isinstance(X_trans, sparse.csr_matrix)\n        assert_allclose(X_trans.toarray(), [[1, 2], [3, 4]])\n", "    def test_make_column_transformer_remainder_callable(self):\n        # Test remainder as callable for ColumnTransformer\n\n            return X + 1\n\n        ct = make_column_transformer(\n            (StandardScaler(), ['a']), remainder=add_one\n        )\n        X = np.array([[1, 2], [3, 4]])\n        ct.fit(X)\n        Xt = ct.transform(X)\n        assert_allclose_dense_sparse(\n            Xt, np.array([[0, 2], [0, 4]]), rtol=1e-6\n        )\n\n", "    def test_sparse_output_transform():\n        X = sparse.csr_matrix([[1, 2], [3, 4], [5, 6]])\n        ct = ColumnTransformer(\n            [(\"scaler\", StandardScaler(), [0]), (\"encoder\", OneHotEncoder(), [1])],\n            sparse_threshold=0.5,\n        )\n        X_transformed = ct.fit_transform(X)\n        assert isinstance(X_transformed, sparse.csr_matrix)\n\n        ct = ColumnTransformer(\n            [(\"scaler\", StandardScaler(), [0]), (\"encoder\", OneHotEncoder(), [1])],\n            sparse_threshold=0.0,\n        )\n        X_transformed = ct.fit_transform(X)\n        assert isinstance(X_transformed, np.ndarray)\n\n", "    def test_sparse_output(self):\n        X = np.array([[1, 2], [3, 4]])\n        sparse_X = sparse.csr_matrix(X)\n\n        transformer = ColumnTransformer(\n            transformers=[\n                ('scale', StandardScaler(), [0]),\n                ('passthrough', 'passthrough', [1]),\n            ],\n            sparse_threshold=0.5,\n        )\n\n        assert_array_equal(transformer.fit_transform(sparse_X).toarray(),\n                           transformer.fit_transform(X))\n\n        transformer = ColumnTransformer(\n            transformers=[('scale', StandardScaler(), [0])],\n            sparse_threshold=0.5,\n        )\n\n        assert isinstance(transformer.fit_transform(sparse_X), sparse.csr_matrix)\n\n        transformer = ColumnTransformer(\n            transformers=[('scale', StandardScaler(), [0])],\n            sparse_threshold=0.1,\n        )\n\n        assert_array_equal(transformer.fit_transform(sparse_X),\n                           transformer.fit_transform(X))\n\n", "    def test_column_transformer_passthrough_sparse_output(self):\n        X = sparse.csr_matrix([[1, 2], [3, 4]])\n        transformer = ColumnTransformer(\n            transformers=[\n                (\"drop\", \"drop\", 0),\n                (\"passthrough\", \"passthrough\", 1),\n            ],\n            sparse_threshold=0.0,\n        )\n        Xt = transformer.fit_transform(X)\n        assert isinstance(Xt, sparse.csr_matrix)\n        assert_allclose(Xt.toarray(), X[:, 1].toarray())\n"], "sample_90": ["    def test_mark_evaluator_istrue_with_invalid_syntax(self, tmpdir):\n        class Example:\n                pass\n\n        item = Collector.from_pytest_function(\n            None, \"test_method\", module=Example(), config=None\n        )\n        mark_evaluator = MarkEvaluator(item, \"mark\")\n        mark_evaluator._marks = [Mark(\"mark\", {\"condition\": \"invalid syntax\"})]\n        with pytest.raises(SyntaxError) as excinfo:\n            mark_evaluator.istrue()\n        assert \"invalid syntax\" in str(excinfo.value)\n", "    def test_mark_evaluator_get_mark_with_condition_string(\n        self,\n        mocker: mock.Mock,", "    def test_mark_evaluator_invalidraise_raises(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"a\", [1, 2])\n                assert a > 3\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        assert result.ret == 1\n        result.stdout.fnmatch_lines(\n            [\n                \"*test_func*\",\n                \"*ValueError: assert 1 > 3*\",\n                \"*test_func*\",\n                \"*ValueError: assert 2 > 3*\",\n            ]\n        )\n", "    def test_mark_eval_raises_type(self):\n            pass\n        item = Node(fun, None, None)\n        mark = Mark(\"raises\", raises=ValueError)\n        item._markers.append(mark)\n        ev = MarkEvaluator(item, \"raises\")\n        with pytest.raises(ValueError):\n            ev._istrue()\n", "    def test_mark_evaluator_istrue_empty_marks(self):\n        item = Collector(parent=None, name=\"test_func\")\n        mark_evaluator = MarkEvaluator(item, \"mark\")\n        assert not mark_evaluator.istrue()\n"], "sample_75": ["    def test_imagegrid_colorbar_mode_edge(self):\n        fig, axs = plt.subplots(2, 2)\n        grid = ImageGrid(fig, 111, (2, 2),\n                         axes_pad=0.1,\n                         cbar_mode=\"edge\",\n                         cbar_location=\"right\",\n                         cbar_pad=\"2%\")\n        for ax in grid:\n            ax.imshow(np.random.rand(10, 10))\n        fig.canvas.draw()\n        # Check if colorbars are correctly positioned\n        for i in range(grid.ngrids):\n            col, row = grid._get_col_row(i)\n            if col == 0:\n                assert grid.cbar_axes[row].get_position().bounds[0] < \\\n                       grid.axes_all[i].get_position().bounds[2]\n\n", "    def test_ImageGrid_cbar_location_edge(self):\n        fig, axs = plt.subplots(2, 2, figsize=(6, 6))\n        imgrid = ImageGrid(fig, 111,\n                         nrows_ncols=(2, 2),\n                         cbar_mode=\"edge\",\n                         cbar_location=\"left\",\n                         axes_pad=0.1,\n                         share_all=True,\n                         aspect=True,\n                         label_mode=\"L\")\n        for ax in imgrid.axes_all:\n            ax.imshow(np.random.rand(10, 10))\n        fig.colorbar(axs[0, 0].images[0], cax=imgrid.cbar_axes[0])\n        fig.colorbar(axs[0, 1].images[0], cax=imgrid.cbar_axes[1])\n        fig.colorbar(axs[1, 0].images[0], cax=imgrid.cbar_axes[2])\n        fig.colorbar(axs[1, 1].images[0], cax=imgrid.cbar_axes[3])\n\n        for cax in imgrid.cbar_axes:\n            cax.set_aspect(20)\n", "def test_colorbar_each():\n    fig, axs = plt.subplots(2, 2, figsize=(6, 6))\n    grid = ImageGrid(\n        fig, 111, (2, 2),\n        axes_pad=0.1,  # This is the padding between subplots\n        share_all=True,\n        cbar_mode=\"each\",\n        cbar_pad=0.05\n    )\n    for i, ax in enumerate(grid):\n\n        img = np.random.rand(10, 10)\n        im = ax.imshow(img, cmap='viridis')\n        cbar_ax = grid.cbar_axes[i]\n        fig.colorbar(im, cax=cbar_ax)\n\n    plt.tight_layout()\n", "    def test_grid_label_mode(self, nrows_ncols, ngrids, direction, label_mode):\n        fig, axs = plt.subplots(*nrows_ncols, num='test')\n        grid = Grid(fig, 111, nrows_ncols=nrows_ncols, ngrids=ngrids,\n                    direction=direction)\n        grid.set_label_mode(label_mode)\n        for ax in grid.axes_all:\n            for tick in ax.xaxis.get_major_ticks() + ax.yaxis.get_major_ticks():\n                if tick.label1 is not None:\n                    tick.label1.set_visible(True)\n                if tick.label2 is not None:\n                    tick.label2.set_visible(True)\n\n        plt.draw()\n        assert_array_equal(\n            [tick.label1.get_visible() for tick in ax.xaxis.get_major_ticks()],\n            [True if (label_mode == 'all'\n                     or (label_mode == 'L' and i == 1 and j == 0)\n                     or (label_mode == '1' and i == 1 and j == 0))\n                 else False for i in range(nrows_ncols[0])\n                 for j in range(nrows_ncols[1])\n                 for ax in grid.axes_all\n                 ])\n        assert_array_equal(\n            [tick.label1.get_visible() for tick in ax.yaxis.get_major_ticks()],\n            [True if (label_mode == 'all'\n                     or (label_mode == 'L' and i == 0 and j == 0)\n                     or (label_mode == '1' and i == 0 and j == 0))\n                 else False for i in range(nrows_ncols", "    def test_grid_label_mode(self, direction):\n        fig, axs = plt.subplots(2, 2, gridspec_kw={'direction': direction})\n\n        grid = Grid(fig, (0, 0, 1, 1), (2, 2),\n                    axes_pad=0.2, direction=direction,\n                    label_mode=\"L\")\n        grid.axes_all = axs.ravel()\n\n        for ax in grid.axes_all:\n            ax.set_xticks([0, 1])\n            ax.set_yticks([0, 1])\n\n        for i, ax in enumerate(grid.axes_all):\n            # Check for tick labels based on label_mode\n            if (direction == \"row\" and i >= 2) or (direction == \"column\"\n                                                  and i % 2 == 0):\n                assert ax.xaxis.get_ticklabels()\n            else:\n                assert not ax.xaxis.get_ticklabels()\n\n            if (direction == \"column\" and i % 2 == 1) or (direction == \"row\"\n                                                        and i < 2):\n                assert ax.yaxis.get_ticklabels()\n            else:\n                assert not ax.yaxis.get_ticklabels()\n\n\n\n"], "sample_117": ["    def test_restify_broken_type():\n        assert restify(BrokenType) == ':obj:`BrokenType`'\n", "    def test_restify_special_form(self):\n        assert restify(MyInt) == ':obj:`MyInt`'\n        assert restify(MyList) == ':class:`MyList`'\n\n", "    def test_restify_union_complex():\n        assert restify(Union[MyInt, MyClass1, Optional[MyClass2], List[int]]) == (\n            ':obj:`Union`\\\\ [:obj:`MyInt`\\\\ , :class:`MyClass1`\\\\ , :obj:`Optional`\\\\ [:class:`MyClass2`\\\\ ], '\n            ':class:`list`\\\\ [:obj:`int`\\\\ ]]'\n        )\n\n\n", "    def test_restify_forwardref():\n        from sphinx.util.typing import ForwardRef  # lazy loading\n\n        class MyClass:\n            pass\n        ref = ForwardRef('MyClass')\n        assert restify(ref) == ':class:`MyClass`'\n", "    def test_restify_forwardref():\n        from sphinx.util.typing import ForwardRef\n\n        class MyClass:\n            pass\n\n        @ForwardRef('MyClass')\n            return MyClass\n\n        assert restify(my_forward_ref) == ':class:`MyClass`'\n\n"], "sample_21": ["    def test_collect_related_objects_with_null_fk(self):\n        # Test that null foreign keys don't raise errors when collecting objects\n\n        a1 = create_a()\n        b1 = B.objects.create(a=a1)\n        b2 = B.objects.create(a=None)\n        c1 = Child.objects.create(parent=b1)\n\n        collector = Collector(using='default')\n        collector.collect([a1], collect_related=True)\n        self.assertCountEqual(collector.data[A], [a1])\n        self.assertCountEqual(collector.data[B], [b1, b2])\n        self.assertCountEqual(collector.data[Child], [c1])\n", "    def test_cascade_with_deferrable_unique_constraint(self):\n        with transaction.atomic():\n            p = Parent.objects.create(name='p')\n            c1 = Child.objects.create(parent=p, name='c1')\n            c2 = Child.objects.create(parent=p, name='c2')\n            # This will fail with a UniqueViolation if the constraint\n            # cannot be deferred\n            Child.objects.create(parent=p, name='c1', unique_field='duplicate')\n\n", "    def test_cascade_with_deferrable_constraints(self):\n        # Create a cascade relationship between models with deferrable constraints.\n        A.objects.create()\n        a = A.objects.get()\n        create_a(a, RChildChild)\n\n        # Delete the parent object.\n        A.objects.filter(pk=a.pk).delete()\n\n        # Ensure that the child object is deleted as well, due to the cascade.\n        self.assertFalse(RChildChild.objects.exists())\n", "    def test_restricted_objects_cascade_many(self):\n        with transaction.atomic():\n            # Create a parent with children, grandchild, and related object\n            parent = P.objects.create()\n            child1 = Child.objects.create(parent=parent, val='c1')\n            child2 = Child.objects.create(parent=parent, val='c2')\n            grandchild = RChildChild.objects.create(rchild=RChild.objects.create(\n                r=R.objects.create(parent=parent)\n            ))\n            # Create a related object\n            ref = Referrer.objects.create(child=child1)\n\n        # This should succeed because the related object is deleted\n        # after cascade deletes the parent\n        with self.assertNumQueries(14):\n            Collector.collect([parent])\n\n        # Now create a restricted object referencing child2\n        Restricted.objects.create(child=child2)\n\n        # This should trigger a RestrictedError because child2\n        # is referenced by a restricted object\n        with self.assertRaises(RestrictedError):\n            Collector.collect([parent])", "    def test_delete_with_m2m_on_delete_cascade(self):\n        a = create_a(name='a')\n        m2m_to_1 = M2MTo.objects.create(name='m2m_to_1')\n        m2m_to_2 = M2MTo.objects.create(name='m2m_to_2')\n        a.m2m_to.add(m2m_to_1, m2m_to_2)\n\n        # Use a transaction to ensure that the m2m relations are consistent\n        with self.atomic():\n            a.delete()\n\n        self.assertFalse(M2MFrom.objects.filter(pk=a.pk).exists())\n        self.assertFalse(M2MTo.objects.filter(pk=m2m_to_1.pk).exists())\n        self.assertFalse(M2MTo.objects.filter(pk=m2m_to_2.pk).exists())\n"], "sample_104": ["    def test_estimator_pretty_printer_compact_dict():\n        with set_config(print_changed_only=True):\n            estimator = LogisticRegressionCV(Cs=[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100],\n                                            cv=3,\n                                            penalty='l2',\n                                            scoring='auc',\n                                            random_state=42)\n            expected_output = (\n                'LogisticRegressionCV(Cs=[0.00001, 0.0001, 0.001, 0.01, 0.1, 1, '\n                '10, 100], cv=3, penalty='l2', scoring='auc', random_state=42)'\n            )\n            assert repr(estimator) == expected_output\n\n", "    def test_estimator_pretty_printer_n_max_elements_to_show(self):\n        set_config(print_changed_only=False)\n        lr = LogisticRegression(penalty='l2', dual=False, tol=1e-4, C=1.0,\n                   fit_intercept=True, intercept_scaling=1,\n                   class_weight=None, random_state=None, solver='warn',\n                   max_iter=100, multi_class='warn', verbose=0,\n                   warm_start=False, n_jobs=None, l1_ratio=None)\n        pipe = make_pipeline(StandardScaler(), lr)\n        pp = _EstimatorPrettyPrinter(n_max_elements_to_show=2)\n        expected = (\n            \"Pipeline(steps=[('standardscaler', StandardScaler(copy=True, \"\n            \"with_mean=True, with_std=True)), ('logisticregression',\"\n            \" LogisticRegression(C=1.0, class_weight=None, \"\n            \"dual=False, fit_intercept=True, intercept_scaling=1, \"\n            \"l1_ratio=None, max_iter=100, multi_class='warn', \"\n            \"n_jobs=None, penalty='l2', random_state=None, \"\n            \"solver='warn', tol=0.0001, verbose=0, warm_start=False))])\"\n        )\n\n        self.assertEqual(pp.pformat(pipe), expected)\n\n", "    def test_pprint_estimator_with_long_arguments():\n        # Test estimator with long arguments to check ellipsis behavior\n        pipe = make_pipeline(\n            SelectKBest(chi2, k=10),\n            StandardScaler(),\n            LogisticRegressionCV(\n                Cs=np.logspace(-4, 4, 20),\n                scoring='accuracy',\n                cv=5,\n                penalty='l2',\n                random_state=0,\n                n_jobs=-1,\n                verbose=1\n            )\n        )\n        pp = _EstimatorPrettyPrinter(compact=True, n_max_elements_to_show=3)\n        expected = (\n            'make_pipeline(SelectKBest(chi2, k=10), StandardScaler(), '\n            'LogisticRegressionCV(Cs=array([  1.0000e-04,   1.0000e-03, '\n            '   1.0000e-02,   1.0000e-01,   1.0000e+00,   1.0000e+01, '\n            '   1.0000e+02,   1.0000e+03,   1.0000e+04]), '\n            'scoring=\\'accuracy\\', cv=5, penalty=\\'l2\\', '\n            'random_state=0, n_jobs=-1, verbose=1))'\n        )\n\n        assert re.sub(r'\\s+', ' ', pp.pformat(pipe)) == expected\n\n", "    def test_estimator_with_deep_copy_params(self):\n        n_components = 10\n        pca = PCA(n_components=n_components,\n                  random_state=42)\n        set_config(print_changed_only=True)\n        expected = (\n            'PCA(n_components=10, random_state=42)'\n        )\n        result = _EstimatorPrettyPrinter().pformat(pca)\n        assert result == expected\n        \n", "    def test_estimator_with_changed_only_false(self):\n       set_config(print_changed_only=False)\n       estimator = LogisticRegressionCV(\n           Cs=[1, 10], cv=5, scoring='accuracy',\n           penalty='l2', solver='lbfgs', max_iter=1000, random_state=42\n       )\n\n       # No changes to these params\n       expected = (\n           \"LogisticRegressionCV(Cs=[1, 10], cv=5, max_iter=1000, \"\n           \"penalty='l2', random_state=42, scoring='accuracy', \"\n           \"solver='lbfgs')\"\n       )\n       result = pprint.pformat(estimator)\n       self.assertEqual(result, expected)\n\n       # Now change some params\n       estimator.Cs = [15, 20]\n       estimator.max_iter = 2000\n       \n       expected = (\n           \"LogisticRegressionCV(Cs=[15, 20], cv=5, max_iter=2000, \"\n           \"penalty='l2', random_state=42, scoring='accuracy', \"\n           \"solver='lbfgs')\"\n       )\n       result = pprint.pformat(estimator)\n       self.assertEqual(result, expected)\n\n"], "sample_18": ["    def test_many_to_many_check_relationship_model_invalid_through_fields(self):\n        class MyModel(models.Model):\n            pass\n\n        class AnotherModel(models.Model):\n            pass\n\n        with mock.patch.object(connection, 'ops', mock.MagicMock() ):\n            with self.assertRaisesMessage(\n                checks.Error,\n                \"The model is used as an intermediate model by 'MyModel.related_m2m', but it does not have a foreign key to 'MyModel' or 'AnotherModel'.\"\n            ):\n                MyModel.objects.create(\n                    related_m2m=AnotherModel.objects.create()\n                )\n\n", "    def test_many_to_many_field_with_through_model_auto_created(self):\n        class Author(models.Model):\n            name = models.CharField(max_length=100)\n\n        class Book(models.Model):\n            title = models.CharField(max_length=200)\n\n        class AuthorBook(models.Model):\n            author = models.ForeignKey(Author, on_delete=models.CASCADE)\n            book = models.ForeignKey(Book, on_delete=models.CASCADE)\n\n        class MyModel(models.Model):\n            authors = models.ManyToManyField(Author, through=AuthorBook)\n\n        # Make sure the through model is auto-created\n        self.assertEqual(MyModel._meta.get_field('authors').remote_field.through._meta.models, (AuthorBook,))\n\n        # Check tables are created correctly\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT * FROM django_migrations\")\n            migrations = cursor.fetchall()\n            self.assertEqual(len(migrations), 1)\n", "    def test_check_table_uniqueness_with_router(self):\n        class ThroughModel(models.Model):\n            source = models.ForeignKey('Person', on_delete=models.CASCADE)\n            target = models.ForeignKey('Person', on_delete=models.CASCADE)\n\n        class Person(models.Model):\n            name = models.CharField(max_length=100)\n            friends = models.ManyToManyField(\n                'self',\n                through=ThroughModel,\n                symmetrical=False,\n            )\n\n        with connection.cursor() as cursor:\n            cursor.execute(\"CREATE TABLE test.person (id SERIAL PRIMARY KEY, name VARCHAR(100))\")\n            cursor.execute(\"CREATE TABLE test.through_model (id SERIAL PRIMARY KEY, source_id INTEGER REFERENCES test.person(id), \"\n                           \"target_id INTEGER REFERENCES test.person(id), UNIQUE (source_id, target_id))\")\n            cursor.execute(\"CREATE TABLE other.person (id SERIAL PRIMARY KEY, name VARCHAR(100))\")\n            cursor.execute(\"CREATE TABLE other.through_model (id SERIAL PRIMARY KEY, source_id INTEGER REFERENCES other.person(id), \"\n                           \"target_id INTEGER REFERENCES other.person(id))\")\n        errors = Person._meta.get_field('friends').check(**{'from_model': Person})\n        self.assertEqual(errors, [])\n\n", "    def test_custom_through_model_with_non_autocreated_fields(self):\n        class MyModel(models.Model):\n            pass\n        class YourModel(models.Model):\n            pass\n\n        class CustomThroughModel(models.Model):\n            my_model = models.ForeignKey(MyModel, on_delete=models.CASCADE)\n            your_model = models.ForeignKey(YourModel, on_delete=models.CASCADE)\n\n        class MyModelWithCustomThrough(models.Model):\n            my_field = models.ManyToManyField(YourModel, through=CustomThroughModel,\n                                           through_fields=('my_model', 'your_model'))\n\n        # Make sure that the through_fields argument is correctly interpreted.\n        self.assertEqual(MyModelWithCustomThrough._meta.get_field('my_field').remote_field.through, CustomThroughModel)\n        self.assertEqual(MyModelWithCustomThrough._meta.get_field('my_field').remote_field.through_fields, ('my_model', 'your_model'))\n\n        # Test that the generated descriptor correctly sets up the relation.\n\n        MyModel.objects.create()\n        YourModel.objects.create()\n        my_instance = MyModel.objects.first()\n        your_instance = YourModel.objects.first()\n\n        my_instance.my_field.add(your_instance)\n\n        # Verify the intermediate table entry was created correctly\n        self.assertEqual(CustomThroughModel.objects.count(), 1)\n        custom_through_instance = CustomThroughModel.objects.first()\n\n        self.assertEqual(custom_through_instance.my_model, my_instance)\n        self.assertEqual(custom_through_instance.your_model, your_instance)\n\n", "    def test_m2m_through_fields_required_for_recursive_relation(self):\n        with override_settings(INSTALLED_APPS=['invalid_models_tests']):\n            class MyModel(models.Model):\n                friends = models.ManyToManyField('self')\n\n            with self.assertRaisesMessage(ValueError, \"Field specifies 'through_fields' but does not provide the names of the two link fields that should be used for the relation through model 'MyModel'.\"):\n                MyModel.objects.create()\n\n"], "sample_25": ["    def test_many_to_many_through_rename_model(self):\n        \"\"\"\n        Tests renaming model involved in a many-to-many through relationship\n        \"\"\"\n\n        before = [\n            self.contract,\n            self.author_with_publisher_string,\n            self.publisher,\n        ]\n        after = [\n            self.contract_renamed,\n            self.author_with_publisher_string,\n            self.publisher,\n        ]\n\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, ['RenameModel'])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, old_name='Contract', new_name='Deal')\n\n", "    def test_rename_with_m2m_through_model(self):\n        # Rename a model involved in a M2M relationship through another model\n        before = [\n            self.book,\n            self.author,\n            self.contract,\n        ]\n        after = [\n            self.book_renamed,\n            self.author,\n            self.contract_renamed,\n        ]\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, [\n            'RenameModel',\n            'AlterField',\n        ])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Book', old_name='Book')\n\n", "    def test_remove_unique_together(self):\n        changes = self.get_changes(\n            [self.book_foo_together],\n            [self.book],\n        )\n        self.assertNumberMigrations(changes, 'otherapp', 1)\n        self.assertOperationTypes(changes, 'otherapp', 0, ['RemoveUniqueConstraint'])\n", "    def test_delete_field_with_default(self):\n        before = self.make_project_state([\n            self.author_name_char,\n            self.book_with_no_author,\n        ])\n        after = self.make_project_state([\n            self.author_name_char_default_null,\n            self.book_with_no_author,\n        ])\n        changes = self.get_changes(before.models, after.models)\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertOperationTypes(changes, 'testapp', 0, [\n            'AlterField',\n        ])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='name',\n                                       field_type='CharField', null=True)\n        \n\n", "    def test_circular_fk_dependency_detection(self):\n        before = [\n            self.knight,\n            self.rabbit\n        ]\n        after = [\n            self.knight,\n            self.rabbit.clone(name='rabbit_updated'),\n        ]\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'eggs', 1)\n        self.assertOperationTypes(changes, 'eggs', 0, ['AlterField'])\n        self.assertOperationAttributes(changes, 'eggs', 0, 0, field='parent', name='parent')\n"], "sample_128": ["    def test_Modulus_negative():\n        raises(OptionError, lambda: Options((x, y, z), {'modulus': -1}))\n", "def test_Options_clone():\n    opts = Options((x, y), {'domain': ZZ})\n    opts2 = opts.clone({'domain': QQ})\n    assert opts2['domain'] == QQ\n    assert opts['domain'] == ZZ\n", "def test_options_symbols():\n    opt = Options((x, y, z), {'symbols': ['a', 'b']})\n    assert opt.symbols == ['a', 'b']\n\n    opt = Options((x, y, z), {'symbols': ['a', 'b', 'c']})\n    assert opt.symbols == ['a', 'b', 'c']\n", "def test_option_preprocess_symbols():\n    opt = Options((x, y, z), {'symbols': 3})\n    assert opt.symbols == (Symbol('s1'), Symbol('s2'), Symbol('s3'))\n\n    opt = Options((x, y, z), {'symbols': ['a', 'b']})\n    assert opt.symbols == [Symbol('a'), Symbol('b')]\n\n    with raises(OptionError):\n        Options((x, y, z), {'symbols': 'a'})\n\n", "def test_Options_auto():\n    opt = Options((x, y, z), {'auto': True})\n    assert opt.domain == ZZ\n    assert opt.auto is True\n\n    opt = Options((x, y, z), {'domain': QQ})\n    assert opt.domain == QQ\n    assert opt.auto is False\n"], "sample_151": ["def test_point3d_direction_cosine():\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(2, 3, 5)\n    assert p1.direction_cosine(p2) == [sqrt(6)/6, sqrt(6)/6, sqrt(6)/3]\n", "    def test_point3d_rotate():\n        p = Point3D(1, 0, 0)\n        p_rot = p.rotate(pi / 2, Point3D(0, 0, 0))\n        assert p_rot == Point3D(0, 1, 0)\n\n        p_rot = p.rotate(pi, Point3D(0, 0, 0))\n        assert p_rot == Point3D(-1, 0, 0)\n", "def test_Point3D_rotate():\n    p = Point3D(1, 0, 0)\n    q = p.rotate(pi/2, Point3D(0, 0, 0))\n    assert q == Point3D(0, 1, 0)\n\n", "    def test_point3d_distance_to_line3d():\n        p1 = Point3D(1, 1, 1)\n        l1 = Line3D(Point3D(0, 0, 0), Point3D(1, 1, 1))\n\n        assert p1.distance(l1) == sqrt(3)/3\n\n\n", "def test_point3d_direction_cosine():\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(2, 3, 5)\n    assert p1.direction_cosine(p2) == [sqrt(6)/6, sqrt(6)/6, sqrt(6)/3]\n"], "sample_72": ["    def test_savefig(self):\n        fig, ax = plt.subplots()\n        fig.savefig(self.temp('fig.png'))\n        assert os.path.exists(self.temp('fig.png'))\n", "def test_figure_savefig_format(tmpdir):\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], [4, 5, 6])\n\n    # Test saving with explicit format\n    fname = str(tmpdir.join('test.png'))\n    fig.savefig(fname, format='png')\n    assert os.path.isfile(fname)\n\n    # Test saving without format, using extension\n    fname = str(tmpdir.join('test.pdf'))\n    fig.savefig(fname)\n    assert os.path.isfile(fname)\n\n    # Test saving with invalid format\n    with pytest.raises(ValueError):\n        fig.savefig(str(tmpdir.join('test.xyz')))\n", "def test_tight_layout_rect():\n    fig, ax = plt.subplots()\n    ax.set_xlabel('X-axis')\n    ax.set_ylabel('Y-axis')\n    ax.set_title('Test Title')\n\n    fig.tight_layout(rect=(0.1, 0.1, 0.9, 0.9))\n\n    # Check if bounding box is inside the specified rect\n    bbox = fig.bbox\n    assert bbox.xmin >= 0.1 * fig.bbox_inches.width\n    assert bbox.ymin >= 0.1 * fig.bbox_inches.height\n    assert bbox.xmax <= 0.9 * fig.bbox_inches.width\n    assert bbox.ymax <= 0.9 * fig.bbox_inches.height\n\n", "def test_figaspect_array():\n    A = np.arange(12).reshape((3, 4))\n    w, h = Figure.figaspect(A)\n    assert w == 4\n    assert h == 3\n\n", "    def test_figaspect_array(self):\n        A = np.random.rand(5, 3)\n        w, h = Figure.figaspect(A)\n        assert np.isclose(w / h, A.shape[0] / A.shape[1])\n\n"], "sample_7": ["    def test_iter_modules_and_files_zipfile(self):\n        with tempfile.NamedTemporaryFile(delete=False) as zip_file:\n            zip_filename = zip_file.name\n        with zipfile.ZipFile(zip_filename, 'w') as zipf:\n            zipf.writestr('module.py', 'print(\"Hello\")')\n\n        self.import_and_cleanup('zipfile_module')\n        sys_path = sys.path.copy()\n        try:\n            sys.path.append(os.path.dirname(zip_filename))\n            self.assertFileFound(Path(zip_filename))\n        finally:\n            sys.path = sys_path\n            os.remove(zip_filename)\n\n", "    def test_iter_modules_and_files_removes_missing_files(self):\n        filename = self.temporary_file('test.py')\n        self.assertFileFound(filename)\n        os.remove(filename)\n        self.assertFileNotFound(filename)\n", "    def test_iter_modules_and_files_with_zipfile(self):\n        with tempfile.NamedTemporaryFile(suffix=\".zip\") as zipfile_file:\n            zipfile_path = Path(zipfile_file.name)\n            with zipfile.ZipFile(zipfile_path, \"w\") as zipf:\n                zipf.writestr(\"module.py\", \"print('hello')\")\n            sys.path.append(zipfile_path.parent)\n            self.addCleanup(sys.path.remove, zipfile_path.parent)\n            self.addCleanup(lambda: sys.path_importer_cache.clear())\n            self.import_and_cleanup(\"module\")\n            self.assertFileFound(zipfile_path / 'module.py')\n", "    def test_zipfile_module(self):\n        # Ensure the module is in sys.modules\n        zip_file_path = self.temporary_file('test.zip')\n        with zipfile.ZipFile(zip_file_path, 'w') as zf:\n            zf.writestr('test_module.py', 'pass')\n        with extend_sys_path(str(zip_file_path.parent)):\n            self.import_and_cleanup('test_module')\n            self.assertFileFound(zip_file_path / 'test_module.py')\n            # Now remove the file, the module should still be in sys.modules\n            zip_file_path.unlink()\n            self.assertFileNotFound(zip_file_path / 'test_module.py')\n", "    def test_iter_modules_and_files_zipfile(self):\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            zip_filename = Path(tmpdirname) / 'test.zip'\n            with zipfile.ZipFile(zip_filename, 'w') as zipf:\n                zipf.writestr('my_module.py', 'print(\"hello\")')\n\n            sys.path.append(tmpdirname)\n            self.addCleanup(sys.path.remove, tmpdirname)\n            self.import_and_cleanup('my_module')\n            self.assertFileFound(zip_filename)\n"], "sample_62": ["    def test_file_cache_cull(self):\n        # Test culling behavior in FileBasedCache\n        cache_dir = tempfile.mkdtemp()\n        try:\n            with self.settings(CACHES={\"default\": {\"BACKEND\": \"django.core.cache.backends.filebased.FileBasedCache\", \"LOCATION\": cache_dir, \"MAX_ENTRIES\": 5, \"CULL_FREQUENCY\": 2}}):\n                cache = cache.cache\n                for i in range(10):\n                    cache.set(f\"key_{i}\", i, timeout=60)\n                self.assertEqual(len(os.listdir(cache_dir)), 5)\n        finally:\n            shutil.rmtree(cache_dir)\n", "    def test_file_cache_cull_frequency(self):\n        cache_file = FileBasedCache\n        self._test_cull(cache_file)\n\n", "    def test_file_cache_cull(self):\n        # Test file-based cache culling\n        settings.CACHES['default']['BACKEND'] = 'django.core.cache.backends.filebased.FileBasedCache'\n        settings.CACHES['default']['LOCATION'] = tempfile.mkdtemp()\n        settings.CACHES['default']['MAX_ENTRIES'] = 2\n        settings.CACHES['default']['CULL_FREQUENCY'] = 2\n\n        cache.clear()\n        cache.set('key1', 1)\n        cache.set('key2', 2)\n        cache.set('key3', 3)\n\n        self.assertEqual(len(os.listdir(settings.CACHES['default']['LOCATION'])), 3)\n        cache.get('key1')  # Touch key1 to prevent its deletion\n        cache._cull()\n        self.assertEqual(len(os.listdir(settings.CACHES['default']['LOCATION'])), 2)\n        self.assertTrue('key1' in os.listdir(settings.CACHES['default']['LOCATION']))\n        self.assertTrue('key2' in os.listdir(settings.CACHES['default']['LOCATION']))\n", "    def test_file_cache_cull(self):\n        self.cache = caches[\"default\"]\n        self.cache._max_entries = 10\n        self.cache._cull_frequency = 2\n        for i in range(20):\n            self.cache.set(f\"key_{i}\", i)\n        self.assertEqual(len(self.cache._list_cache_files()), 10)\n", "    def test_file_based_cache_cull(self):\n        # Ensure files are actually deleted when _cull() is called.\n        with tempfile.TemporaryDirectory() as tmpdir:\n            cache_path = os.path.join(tmpdir, 'cache')\n            cache = FileBasedCache(cache_path, {})\n            # Create some dummy cache files\n            for i in range(10):\n                with open(cache._key_to_file(str(i)), 'wb') as f:\n                    f.write(b'some data')\n            cache._max_entries = 5\n            cache._cull_frequency = 2\n            cache._cull()\n            # Assert that some files were deleted\n            self.assertLess(len(os.listdir(cache_path)), 10)\n"], "sample_49": ["    def test_template_changed_resets_loaders_for_file_change_in_extra_templates_dir(self):\n        file_path = EXTRA_TEMPLATES_DIR / 'test.html'\n        with mock.patch('django.template.autoreload.file_changed') as mock_file_changed:\n            mock_file_changed.dispatch(sender=None, file_path=file_path)\n\n        self.assertTrue(autoreload.reset_loaders.called)\n", "    def test_watch_for_template_changes(self):\n        with mock.patch('django.template.autoreload.get_template_directories') as get_template_directories_mock:\n            get_template_directories_mock.return_value = {EXTRA_TEMPLATES_DIR}\n\n            autoreload.autoreload_started(None, None)\n            get_template_directories_mock.assert_called_once()\n            self.assertEqual(autoreload.watchers_for_changes.get(str(EXTRA_TEMPLATES_DIR))._paths, {'**/*'})\n", "    def test_template_changed_triggers_reset_loaders(self):\n        reset_loaders_mock = mock.patch('django.template.autoreload.reset_loaders')\n        with reset_loaders_mock as mock_reset_loaders:\n            file_path = EXTRA_TEMPLATES_DIR / 'test.html'\n            autoreload.file_changed(file_path)\n        mock_reset_loaders.assert_called_once()\n", "    def test_template_changed_triggers_reload(self):\n        reset_loaders_mock = self.mock_patching(autoreload, 'reset_loaders')\n        autoreload.watch_for_template_changes(None, **{})\n\n        path = EXTRA_TEMPLATES_DIR / \"test.html\"\n        autoreload.template_changed(None, str(path), **{})\n        self.assertTrue(reset_loaders_mock.called)\n", "    def test_watch_for_template_changes(self):\n        autoreload.reset_loaders.reset_mock()\n        watch_for_template_changes(self, **{'sender': mock.Mock()})\n        autoreload.reset_loaders.assert_called()\n"], "sample_106": ["def test_nca_warm_start():\n    # Test warm start functionality\n\n    nca = NeighborhoodComponentsAnalysis(n_components=2,\n                                       warm_start=True, random_state=0)\n    nca.fit(iris_data[:100], iris_target[:100])\n    nca.fit(iris_data, iris_target)\n\n    # Check that the transformation from the second fit is closer to the\n    # transformation of the first fit than a new fit\n    nca_new = NeighborhoodComponentsAnalysis(n_components=2, random_state=0)\n    nca_new.fit(iris_data, iris_target)\n\n    assert_array_almost_equal(nca.components_, nca._last_transformation,\n                              decimal=5)\n    assert not np.allclose(nca.components_, nca_new.components_)\n\n\n", "    def test_nca_pca_init(iris_data, iris_target):\n        \"\"\"Test if PCA initialization works as expected.\"\"\"\n        nca = NeighborhoodComponentsAnalysis(n_components=2, init='pca')\n        nca.fit(iris_data, iris_target)\n        assert nca.components_.shape == (2, iris_data.shape[1])\n\n", "def test_transform_different_n_components():\n    # Test if the transform method works with a different number of\n    # components than the fitted model.\n    n_components = 2\n    n_samples = 50\n    n_features = 10\n    X = rng.randn(n_samples, n_features)\n    nca = NeighborhoodComponentsAnalysis(n_components=n_components)\n    nca.fit(X, rng.randint(0, 2, n_samples))\n    # Transforming with the same number of components should work\n    X_transformed = nca.transform(X)\n    assert X_transformed.shape == (n_samples, n_components)\n\n    # Try transforming with a different number of components\n    new_n_components = 3\n    with pytest.raises(ValueError):\n        nca.transform(X, n_components=new_n_components)\n", "    def test_warm_start(self):\n        # test that warm_start uses the previous solution\n        nca = NeighborhoodComponentsAnalysis(n_components=2, init='pca',\n                                            max_iter=1)\n        nca.fit(iris_data, iris_target)\n        initial_components = nca.components_.copy()\n        nca.fit(iris_data, iris_target)\n        assert_array_almost_equal(nca.components_, initial_components)\n", "    def test_nca_callback(self):\n        nca = NeighborhoodComponentsAnalysis(random_state=0, n_components=2,\n                                             callback=lambda x, n_iter: None)\n        nca.fit(iris_data[:100], iris_target[:100])\n        assert nca.n_iter_ > 0\n\n"], "sample_68": ["    def test_bulk_create_model_with_custom_pk(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT MAX(id) FROM django_app_country\")\n            max_id = cursor.fetchone()[0]\n\n        for obj in self.data:\n            obj.id = max_id + obj.id\n        \n        Country.objects.bulk_create(self.data)\n\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT id FROM django_app_country ORDER BY id DESC LIMIT 4\")\n            results = cursor.fetchall()\n\n        self.assertEqual([result[0] for result in results], [c.id for c in reversed(self.data)])\n\n", "def test_bulk_create_with_database_error(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\"ALTER TABLE django_migrations ADD CONSTRAINT \"\n                           \"dummy_constraint UNIQUE (app, name);\")\n        try:\n            with self.assertRaises(IntegrityError):\n                Country.objects.bulk_create(self.data)\n        finally:\n            cursor.execute(\"ALTER TABLE django_migrations DROP CONSTRAINT \"\n                           \"dummy_constraint;\")\n", "    def test_bulk_create_with_related_objects(self):\n        pizzeria = Pizzeria(name='Pizza Place')\n        pizzeria.save()\n        restaurants = [\n            Restaurant(name='Restaurant 1', pizzeria=pizzeria),\n            Restaurant(name='Restaurant 2', pizzeria=pizzeria),\n        ]\n        Restaurant.objects.bulk_create(restaurants)\n        self.assertEqual(Restaurant.objects.count(), 2)\n        self.assertEqual(Restaurant.objects.filter(pizzeria=pizzeria).count(), 2)\n", "    def test_bulk_create_with_auto_increment_pk(self):\n        with transaction.atomic():\n            created_objects = Country.objects.bulk_create(\n                [\n                    Country(name=\"Canada\", iso_two_letter=\"CA\"),\n                    Country(name=\"Australia\", iso_two_letter=\"AU\"),\n                ],\n                batch_size=1,\n            )\n        self.assertEqual(len(created_objects), 2)\n        for obj in created_objects:\n            self.assertIsNotNone(obj.id)\n\n", "    def test_bulk_create_model_without_pk(self):\n        with transaction.atomic():\n            UpsertConflict.objects.bulk_create(\n                [\n                    UpsertConflict(name=\"Apple\"),\n                    UpsertConflict(name=\"Banana\"),\n                    UpsertConflict(name=\"Cherry\"),\n                ],\n                ignore_conflicts=True,\n            )\n        self.assertEqual(UpsertConflict.objects.count(), 3)\n\n"], "sample_63": ["    def test_create_user_with_existing_username(self):\n        data = {\"username\": self.u1.username, \"password1\": \"password\", \"password2\": \"password\"}\n        form = UserCreationForm(data=data)\n        self.assertFalse(form.is_valid())\n        self.assertIn(\"This username is already taken.\", form.errors[\"username\"])\n\n\n", "    def test_create_user_with_custom_email_field(self):\n        # Create a user with a custom email field\n        data = {'username': 'custom_email_user', 'password1': 'password', 'password2': 'password'}\n        form = UserCreationForm(data=data)\n        self.assertTrue(form.is_valid())\n        user = form.save()\n        self.assertEqual(user.username, 'custom_email_user')\n        self.assertEqual(user.email, 'custom_email_user@example.com')\n", "    def test_creation_form_with_custom_user_model(self):\n        class CustomUserCreationForm(UserCreationForm):\n            class Meta:\n                model = CustomUser\n\n        with override_settings(AUTH_USER_MODEL=\"auth_tests.CustomUser\"):\n            form = CustomUserCreationForm()\n            self.assertEqual(form.fields[\"username\"].widget.attrs[\"autofocus\"], True)\n\n", "    def test_user_creation_form_with_custom_user_model(self):\n        with override_settings(AUTH_USER_MODEL='tests.models.custom_user.CustomUser'):\n            data = {'username': 'newuser', 'password1': 'password', 'password2': 'password'}\n            form = UserCreationForm(data=data)\n            self.assertTrue(form.is_valid())\n            user = form.save()\n            self.assertIsInstance(user, CustomUser)\n            self.assertEqual(user.username, 'newuser')\n", "    def test_creation_with_custom_user_model(self):\n        with override_settings(AUTH_USER_MODEL=CustomUser._meta.label):\n            form = UserCreationForm()\n            self.assertTrue(form.fields[\"username\"].widget.attrs.get(\"autofocus\"))\n            form.data = {\"username\": \"customuser\", \"password\": \"password\"}\n            self.assertTrue(form.is_valid())\n            user = form.save()\n            self.assertEqual(user.username, \"customuser\")\n"], "sample_92": ["    def test_skip_condition_string_eval_error(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n                pytest.skip(condition=\"1/0\")\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.assert_outcomes(skipped=1)\n        assert \"Error evaluating 'skip' condition\" in result.stdout.str()\n", "    def test_evaluate_skip_marks_conditional_skipif(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(\"sys.platform == 'win32'\")\n                assert 1 == 1\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        result.assert_outcomes(skipped=1)\n", "    def test_evaluate_skipif_boolean_condition_with_reason(self):\n        item = Testdir.getitem(\"def test_func(): pass\")\n        mark = attr.ib(type=str, default=\"skipif(True, reason='my reason')\")\n        result, reason = evaluate_skip_marks(item, mark)\n        assert result is True\n        assert reason == \"my reason\"\n", "    def test_evaluate_skip_marks_multiple_conditions(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(\"sys.platform == 'win32'\", reason=\"skip on windows\")\n            @pytest.mark.skipif(\"1 == 1\", reason=\"always skip\")\n                pass\n            \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"*SKIPPED*reason=always skip*\"])\n", "    def test_evaluate_skip_marks_multiple_skipif(self, testdir):\n        testdir.makepyfile(\n            '''\n            import pytest\n\n            @pytest.mark.skipif(\"sys.platform == 'win32'\")\n            @pytest.mark.skipif(\"1 == 1\")\n                pass\n            '''\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"*1 skipped*\"])\n        assert \"sys.platform == 'win32'\" in result.stdout.str()\n\n"], "sample_144": ["    def test_refine_im_complex():\n        x = Symbol('x', real=True)\n        y = Symbol('y', real=True)\n        assert refine(im(x + S.ImaginaryUnit*y), Q.real(x) & Q.real(y)) == S.ImaginaryUnit*y\n        # Test complex expansion\n        z = Symbol('z', real=True)\n        expr = im((x+S.I*y)*(z+S.I*w))\n        expected = refine(expr, Q.real(x) & Q.real(y) & Q.real(z) & Q.real(w))\n        assert expected == y*z - x*w\n", "    def test_refine_atan2_complex():\n        x = Symbol('x', real=True)\n        y = Symbol('y', real=True)\n        assert refine(atan2(y, x), Q.positive(x) & Q.positive(y)) == atan(y/x)\n        assert refine(atan2(y, x), Q.positive(x) & Q.negative(y)) == atan(y/x) + pi\n        assert refine(atan2(y, x), Q.negative(x) & Q.positive(y)) == atan(y/x) + pi\n        assert refine(atan2(y, x), Q.negative(x) & Q.negative(y)) == atan(y/x) - pi\n        assert refine(atan2(y, x), Q.positive(y) & Q.zero(x)) == pi/2\n        assert refine(atan2(y, x), Q.positive(x) & Q.zero(y) ) == 0\n        assert refine(atan2(y, x), Q.negative(y) & Q.zero(x)) == -pi/2\n\n", "    def test_refine_sign_complex():\n        x = Symbol('x', complex=True)\n        assert refine(sign(x), Q.positive(re(x))) == S.One\n        assert refine(sign(x), Q.negative(re(x))) == S.NegativeOne\n        assert refine(sign(x), Q.positive(im(x))) == S.ImaginaryUnit\n        assert refine(sign(x), Q.negative(im(x))) == -S.ImaginaryUnit\n", "    def test_refine_sign_complex(self):\n        x = Symbol('x', complex=True)\n        expr = sign(x)\n        self.assertEqual(refine(expr, Q.positive(re(x)) & Q.positive(im(x))), S.One + S.ImaginaryUnit)\n        self.assertEqual(refine(expr, Q.positive(re(x)) & Q.negative(im(x))), S.One - S.ImaginaryUnit)\n        self.assertEqual(refine(expr, Q.negative(re(x)) & Q.positive(im(x))), -S.One + S.ImaginaryUnit)\n        self.assertEqual(refine(expr, Q.negative(re(x)) & Q.negative(im(x))), -S.One - S.ImaginaryUnit)\n", "    def test_refine_re_im_complex_expression():\n        x = Symbol('x', real=True)\n        y = Symbol('y', real=True)\n        z = Symbol('z', imaginary=True)\n        expr = re(x*y + I*z) + im(x*y + I*z)\n        assert refine(expr, Q.real(x) & Q.real(y)) == x*y\n        assert refine(expr, Q.imaginary(z)) == -S.ImaginaryUnit*z + I*z\n"], "sample_24": ["    def test_validationerror_empty(self):\n        error = ValidationError('')\n        self.assertEqual(error.messages, [])\n        self.assertEqual(error.error_dict, {})\n", "    def test_validation_error_with_dict(self):\n        error_dict = {'field1': ['error1', 'error2'], 'field2': ['error3']}\n        validation_error = ValidationError(error_dict)\n        self.assertEqual(validation_error.error_dict, error_dict)\n", "    def test_validation_error_with_mixed_errors(self):\n        error_dict = {\n            'field1': 'This field is required.',\n            'field2': ValidationError(['This field must be unique.']),\n        }\n        ve = ValidationError(error_dict)\n        self.assertEqual(ve.error_dict, error_dict)\n        self.assertEqual(list(ve), [\n            'This field is required.',\n            'This field must be unique.',\n        ])\n", "    def test_validationerror_with_empty_message(self):\n        error = ValidationError('')\n        self.assertEqual(error.messages, [''])\n", "    def test_validationerror_update_error_dict(self):\n        error_dict = {}\n        validation_error = ValidationError({'field1': ['Error 1', 'Error 2']})\n        validation_error.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {'field1': ['Error 1', 'Error 2']})\n\n        error_dict = {}\n        validation_error = ValidationError(['Error 1', 'Error 2'])\n        validation_error.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {ValidationError.NON_FIELD_ERRORS: ['Error 1', 'Error 2']})\n"], "sample_126": ["    def test_Integer_nthroot():\n        assert integer_nthroot(16, 4) == 2\n        assert integer_nthroot(-16, 4) == -2\n        assert integer_nthroot(16, 2) == 4\n        assert integer_nthroot(125, 3) == 5\n        assert integer_nthroot(8, 3) == 2\n        assert integer_nthroot(256, 4) == 4\n\n        raises(ValueError, lambda: integer_nthroot(16, 0))\n        raises(ValueError, lambda: integer_nthroot(16, -1))\n        raises(ValueError, lambda: integer_nthroot(-16, 2))\n        raises(ValueError, lambda: integer_nthroot(16, 1.5))\n", "def test_GoldenRatio_approximation_interval():\n    assert S.GoldenRatio.approximation_interval(Integer) == (Integer(1), Integer(2))\n    assert S.GoldenRatio.approximation_interval(Rational) == (Rational(3,2), Rational(2,1))\n\n", "    def test_GoldenRatio():\n        assert GoldenRatio == S.GoldenRatio\n        assert latex(GoldenRatio) == r'\\phi'\n\n        assert GoldenRatio > 1\n        assert GoldenRatio.is_irrational\n\n        assert GoldenRatio.expand(func=True) == 1/2 + sqrt(5)/2\n\n        assert (GoldenRatio**2).n() == (1 + 5**0.5)/2\n", "def test_Mod_noncommutative():\n    x = Symbol('x')\n    y = Symbol('y')\n    assert (x%y).is_commutative==False\n\n", "def test_gcd_lehmer():\n    assert igcd_lehmer(12, 8) == 4\n    assert igcd_lehmer(12, 1) == 1\n    assert igcd_lehmer(1, 12) == 1\n    assert igcd_lehmer(0, 12) == 12\n    assert igcd_lehmer(12, 0) == 12\n\n    assert igcd_lehmer(12345678901234567890, 98765432109876543210) == 1\n\n    # Test gcd of negative integers\n    assert igcd_lehmer(-12, -8) == 4\n    assert igcd_lehmer(-12, 8) == 4\n    assert igcd_lehmer(12, -8) == 4\n\n"], "sample_141": ["    def test_convert_to_dimensionless():\n        x = Symbol(\"x\")\n        assert convert_to(x*meter, Dimension(1)) == x*1\n        assert convert_to(x*meter, Dimension(1)).free_symbols == {x}\n        assert convert_to(Quantity(x, meter), Dimension(1)) == Quantity(x, 1)\n        assert convert_to(Quantity(x, meter), Dimension(1)).free_symbols == {x}\n\n", "    def test_convert_to_multiple_units_with_symbols():\n        x = Symbol('x')\n        expr = x*meter + 2*kilometer\n        res = convert_to(expr, [meter, kilometer])\n        assert res == x*meter + 2000*meter\n", "def test_convert_to_different_units():\n    x = Quantity(1, kilometer)\n    y = convert_to(x, meter)\n\n    assert y == 1000*meter\n\n", "def test_convert_to_constant():\n    assert convert_to(speed_of_light, meter/second) == 299792458*meter/second\n", "    def test_convert_to_symbolic_dimensions():\n        x = Symbol('x')\n        Q = Quantity(x, dimension=length)\n        assert convert_to(Q, meter).free_symbols == {x}\n        assert convert_to(Q, kilometer).free_symbols == {x}\n"], "sample_70": ["    def test_legend_loc(self, loc):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], label='Line')\n        ax.legend(loc=loc)\n        fig.canvas.draw()\n\n        # Check that legend is at the expected location.\n        bbox = ax.get_legend().get_window_extent()\n        \n        if loc in ['upper left', 'upper right', 'lower left', 'lower right']:\n            assert bbox.x0 <= ax.bbox.x0 + ax.bbox.width\n            assert bbox.x1 >= ax.bbox.x0\n            assert bbox.y0 <= ax.bbox.y0 + ax.bbox.height\n            assert bbox.y1 >= ax.bbox.y0\n        elif loc in ['right', 'left', 'center']:\n            assert bbox.x0 <= ax.bbox.x1\n            assert bbox.x1 >= ax.bbox.x0\n            assert bbox.y0 <= ax.bbox.y0 + ax.bbox.height\n            assert bbox.y1 >= ax.bbox.y0\n\n", "    def test_legend_bbox_to_anchor(self):\n        fig, ax = plt.subplots()\n        x = np.arange(0, 10, 0.1)\n        ax.plot(x, np.sin(x), label='sin')\n        ax.plot(x, np.cos(x), label='cos')\n        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left',\n                  borderaxespad=0.)\n        ax.set_xlabel('x')\n        ax.set_ylabel('y')\n\n", "    def test_legend_with_empty_label():\n        fig, ax = plt.subplots()\n        line, = ax.plot([1, 2, 3], label='')\n        with pytest.warns(UserWarning, match='empty label'):\n            ax.legend()\n\n", "    def test_legend_with_handler_map(self):\n        fig, ax = plt.subplots()\n        line1, = ax.plot([1, 2, 3], [1, 2, 3], label='Line 1')\n        point1, = ax.plot([1, 2, 3], [1, 2, 3], 'o', label='Point 1')\n        plt.legend(handler_map={type(line1): mlegend.HandlerLine2D(),\n                                type(point1): HandlerTuple()})\n\n", "    def test_legend_handler_tuple(self):\n        fig, ax = plt.subplots()\n        x = np.arange(0, 10, 0.1)\n        line1, = ax.plot(x, np.sin(x), label='sin')\n        line2, = ax.plot(x, np.cos(x), label='cos')\n        tuple_data = (line1, line2)\n        ax.legend(handles=[tuple_data],\n                  handler_map={tuple: HandlerTuple(marker_pad=0.5)})\n"], "sample_125": ["def test_issue_15020():\n    # See issue https://github.com/sympy/sympy/issues/15020\n    x = Symbol('x')\n    a = x**2\n    assert a.is_real is None\n    a = a.subs(x, 2)\n    assert a.is_real is True\n\n", "def test_Integer_mod():\n    assert Integer(5) % Integer(2) == Integer(1)\n    assert Integer(-5) % Integer(2) == Integer(1)\n    assert Integer(5) % Integer(-2) == Integer(1)\n    assert Integer(-5) % Integer(-2) == Integer(1)\n\n\n", "def test_complex_abs():\n    assert abs(1 + 2*I) == sqrt(5)\n    assert abs(-2 - 3*I) == sqrt(13)\n    assert abs(2*I) == 2\n    assert abs(-3) == 3\n", "def test_Catalan():\n    assert Catalan.is_Irrational is None\n    assert Catalan > 0\n    assert Catalan < 1\n    assert float(Catalan) == pytest.approx(0.91596559417721901505460351493238462643383279, rel=1e-15)\n", "    def test_GoldenRatio_rewrite_as_sqrt():\n        assert S.GoldenRatio._eval_rewrite_as_sqrt() == 1/2 + sqrt(5)/2\n"], "sample_19": ["    def test_callable_setting_wrapper_repr(self):\n            pass\n\n        wrapped_callable = CallableSettingWrapper(my_callable)\n        self.assertEqual(repr(wrapped_callable), repr(my_callable))\n", "    def test_callable_setting_wrapper(self):\n        class MockCallable:\n                return 'Called!'\n\n        mock = MockCallable()\n        wrapper = CallableSettingWrapper(mock)\n\n        self.assertEqual(repr(wrapper), repr(mock))\n\n        # Ensure that calling the wrapper doesn't execute the callable itself\n        self.assertEqual(wrapper(), 'Called!')\n        self.assertEqual(wrapper.__call__(), 'Called!')\n", "    def test_callable_setting_wrapper(self):\n         wrapped = CallableSettingWrapper(lambda: 1)\n         self.assertEqual(repr(wrapped), '<lambda>')\n", "    def test_callable_setting_wrapper_does_not_break_debug_page(self):\n        # Regression test for #31779. Ensure that wrapped callables don't break\n        # the debug page.\n        with override_settings(DEBUG=True, ALLOWED_HOSTS=['*']):\n            request = RequestFactory().get('/')\n            request.user = User()\n            settings.DEFAULT_EXCEPTION_REPORTER = 'django.views.debug.SafeExceptionReporterFilter'\n            try:\n                technical_500_response(request, Exception, Exception('test'), sys.exc_info()[2])\n            except Exception as e:\n                self.fail(f\"CallableSettingWrapper caused an error: {e}\")", "    def test_call_setting(self):\n            return 'Hello'\n        wrapper = CallableSettingWrapper(callable_setting)\n        self.assertEqual(wrapper(), 'Hello')\n"], "sample_66": ["    def test_raw_id_fields_check(self):\n        class MyAdmin(ModelAdmin):\n            list_display = ['raw_id_field']\n            raw_id_fields = ['nonexistent_field']\n\n        self.assertIsInvalid(\n            MyAdmin,\n            ValidationTestModel,\n            r\"The value of 'raw_id_fields' refers to 'nonexistent_field', which is not a field of 'ValidationTestModel'.\",\n            id=\"admin.E121\",\n        )\n", "    def test_raw_id_fields_without_model(self):\n        class TestAdmin(ModelAdmin):\n            raw_id_fields = ['nonexistent_field']\n        self.assertIsInvalid(\n            TestAdmin,\n            Band,\n            r\"The value of 'raw_id_fields' refers to 'nonexistent_field', which is not a field of 'Band'.\",\n        )\n", "    def test_raw_id_fields_with_empty_string(self):\n        class MyModelAdmin(ModelAdmin):\n            raw_id_fields = [\"name\"]\n\n        class MyModel(models.Model):\n            name = models.CharField(max_length=100)\n\n        self.assertIsInvalid(\n            MyModelAdmin,\n            MyModel,\n            r\"The value of 'raw_id_fields' refers to 'name', which is not a ForeignKey or OneToOneField\\. \"\n            r\"Did you mean to use 'related_field_name' instead\\?\",\n            id=\"admin.E023\",\n        )\n\n", "    def test_raw_id_fields_validation(self):\n        class MyModelAdmin(ModelAdmin):\n            raw_id_fields = ['does_not_exist']\n\n        self.assertIsInvalid(\n            MyModelAdmin,\n            ValidationTestModel,\n            r\"The value of 'raw_id_fields' refers to 'does_not_exist', which is not a field of 'ValidationTestModel'.\",\n            id=\"admin.E026\",\n        )\n", "    def test_rawid_field_no_name(self):\n        class MyModelAdmin(ModelAdmin):\n            raw_id_fields = ['invalid_field']\n\n        self.assertIsInvalid(\n            MyModelAdmin, ValidationTestModel, r\"The value of 'raw_id_fields' refers to 'invalid_field', which is not a field of 'ValidationTestModel'.\"\n        )\n\n"], "sample_30": ["    def test_inline_formset_extra(self):\n        response = self.client.get(reverse('admin:admin_inlines_holder_change', args=(self.holder.id,)))\n        self.assertContains(response, INLINE_CHANGELINK_HTML)\n        formset = response.context['adminform'].formsets['inner']\n        self.assertEqual(formset.total_form_count(), 1)\n        self.assertEqual(formset.extra, 3)\n\n", "    def test_inline_formset_extra(self):\n        url = reverse('admin:admin_site_holder_change', args=[self.holder.id])\n        response = self.client.get(url)\n        self.assertLess(len(response.context['adminform'].formset.forms), 3)\n", "    def test_inline_change_link(self):\n        response = self.client.get(reverse('admin:admin_inlines_holder_change', args=[self.holder.id]))\n        self.assertContains(response, INLINE_CHANGELINK_HTML)\n", "    def test_can_delete_related_inline(self):\n        url = reverse('admin:admin_site_holder_change', args=(self.holder.pk,))\n        response = self.client.get(url)\n        self.assertContains(response, INLINE_CHANGELINK_HTML)\n        inner_id = Inner.objects.get(holder=self.holder).pk\n        # Delete the related inline object\n        data = {\n            f'inline-group-{InnerInline.model._meta.model_name}-0-DELETE': 'on',\n            f'inline-group-{InnerInline.model._meta.model_name}-0-{InnerInline.model._meta.pk.name}': inner_id,\n        }\n        post_response = self.client.post(url, data, follow=True)\n        self.assertRedirects(post_response, url)\n        self.assertContains(post_response, 'The %s has been deleted.' % Inner.objects.model_name)\n        self.assertFalse(Inner.objects.exists())\n\n", "    def test_inline_model_with_custom_pk(self):\n        response = self.client.get(reverse('admin:admin_inlines_parentmodelwithcustompk_changelist'))\n        self.assertEqual(response.status_code, 200)\n        # Check if the inline form for ChildModel1 has the correct primary key field\n        self.assertIn('<input type=\"hidden\" name=\"form-0-id\" id=\"id_form-0-id\">', response.content.decode())\n"], "sample_42": ["    def test_serialize_lazy_object(self):\n        lazy_obj = SimpleLazyObject(lambda: 'lazy')\n        serializer = serializer_factory(lazy_obj)\n        self.assertEqual(serializer.serialize(), ('\\'lazy\\'', set()))\n", "    def test_serialize_uuid(self):\n        with mock.patch('uuid.UUID', autospec=True) as MockUUID:\n            MockUUID.return_value = uuid.UUID('a1b2c3d4-e5f6-7890-1234-567890abcdef')\n            serializer = serializer_factory(MockUUID.return_value)\n            serialized, imports = serializer.serialize()\n            self.assertEqual(serialized, 'uuid.UUID(\\'a1b2c3d4-e5f6-7890-1234-567890abcdef\\')')\n            self.assertEqual(imports, {'import uuid'})\n", "    def test_serialize_lazy_object(self):\n        lazy_value = SimpleLazyObject(lambda: \"lazy\")\n        serializer = serializer_factory(lazy_value)\n        self.assertEqual(serializer.serialize(), ('\"lazy\"', set()))\n", "    def test_serialize_function_with_self(self):\n            return self.value * arg\n\n        class MyClass:\n                self.value = value\n\n        MyClass.my_func = my_func\n        obj = MyClass(5)\n\n        writer = OperationWriter(\n            migrations.AddField(\n                model_name='testmodel',\n                name='calculated',\n                field=models.IntegerField(default=obj.my_func, blank=True),\n            ),\n            indentation=0,\n        )\n        serialized = writer.serialize()\n\n        self.assertIn(\"MyClass\", serialized[0])\n        self.assertIn('\"my_func\"', serialized[0])\n\n", "    def test_serialize_settings_reference(self):\n        ref = SettingsReference('DATABASE_ENGINE')\n        serializer = migrations.serializer.SettingsReferenceSerializer(ref)\n        serialized, imports = serializer.serialize()\n        self.assertEqual(serialized, 'settings.DATABASE_ENGINE')\n        self.assertEqual(imports, {'from django.conf import settings'})\n"], "sample_136": ["    def test_blockcut_empty():\n        M = ImmutableMatrix.zeros(0, 0)\n        B = blockcut(M, (0,), (0,))\n        assert isinstance(B, BlockMatrix)\n        assert B.shape == (0, 0)\n", "def test_deblock_2x2_not_blockmatrix():\n    M = Matrix([[1, 2], [3, 4]])\n    assert deblock(M) == M\n", "def test_deblock():\n    M = ImmutableMatrix([[1, 2], [3, 4]])\n    B = BlockMatrix([[M]])\n    assert B.blocks == M\n\n    N = MatrixSymbol('N', 2, 2)\n    BN = BlockMatrix([[N]])\n    assert deblock(BN) == BN\n\n    B2 = BlockMatrix([[A, B], [C, D]])\n    assert isinstance(deblock(B2), BlockMatrix)\n    assert deblock(B2).blocks.shape == (4, 4)\n\n\n", "    def test_blockcut():\n        A = ImmutableMatrix(4, 4, range(16))\n        B = blockcut(A, (1, 3), (1, 3))\n        assert type(B).__name__ == 'BlockMatrix'\n        assert ImmutableMatrix(B.blocks[0, 1]) == ImmutableMatrix([[1, 2, 3]])\n\n", "def test_blockcut():\n    M = ImmutableMatrix(4, 4, range(16))\n    B = blockcut(M, (1, 3), (1, 3))\n    assert type(B).__name__ == 'BlockMatrix'\n    assert ImmutableMatrix(B.blocks[0, 1]) == ImmutableMatrix([[1, 2, 3]])\n    assert block_collapse(B) == M\n"], "sample_35": ["    def test_modelmultiplechoicefield_required_empty(self):\n        class MyForm(Form):\n            choices = ModelMultipleChoiceField(queryset=ChoiceModel.objects.all(), required=True)\n        form = MyForm()\n        self.assertFormErrors(\n            [{'choices': ['This field is required.']}],\n            form.save,\n            )\n", "    def test_modelformset_factory_fk_name(self):\n        class ParentModel(models.Model):\n            name = models.CharField(max_length=100)\n\n        class ChildModelA(models.Model):\n            parent = models.ForeignKey(ParentModel, on_delete=models.CASCADE)\n            name = models.CharField(max_length=100)\n\n        class ChildModelB(models.Model):\n            parent = models.ForeignKey(ParentModel, on_delete=models.CASCADE)\n            name = models.CharField(max_length=100)\n\n\n\n        formset_a = inlineformset_factory(ParentModel, ChildModelA, fk_name='parent')\n        formset_b = inlineformset_factory(ParentModel, ChildModelB, fk_name='parent')\n        self.assertEqual(formset_a.fk.name, 'parent')\n        self.assertEqual(formset_b.fk.name, 'parent')\n\n", "    def test_modelmultiplechoicefield_invalid_choice(self):\n        ChoiceModel.objects.create(name='Choice 1', value=1)\n        ChoiceModel.objects.create(name='Choice 2', value=2)\n\n        form = Form({\n            'choices': [1, 3],\n        }, ModelMultipleChoiceForm(queryset=ChoiceModel.objects.all()))\n\n        self.assertFormErrors(\n            [\n                '\u201c3\u201d is not a valid value.',\n            ], form.save\n        )\n", "    def test_modelformset_get_unique_error_message(self):\n        formset = modelformset_factory(ChoiceModel, fields=('name', 'description'))\n        formset.initial = [\n            {'name': 'Foo', 'description': 'bar'},\n            {'name': 'Foo', 'description': 'baz'},\n        ]\n        formset.is_valid()\n\n        expected_error = [\n            ValidationError(\n                'Please correct the duplicate data for name.',\n                code='unique',\n                params={'field_name': 'name'},\n            ),\n        ]\n\n        self.assertEqual(formset.errors, expected_error)\n\n", "    def test_modelmultiplechoicefield_invalid_pk_value(self):\n        ChoiceModel.objects.create(name='Choice 1', value='A')\n        ChoiceModel.objects.create(name='Choice 2', value='B')\n\n        form = Form({\n            'choices': ['invalid', 'C']\n        }, )\n\n        self.assertFormErrors(\n            [\n                ValidationError(\n                    '\u201cinvalid\u201d is not a valid value.',\n                    code='invalid_pk_value',\n                    params={'pk': 'invalid'}\n                )\n            ],\n            form.is_valid\n        )\n\n"], "sample_156": ["    def test_parse_function_with_args():\n        m_expr = \"f[x, g[y]]\"\n        expected = Function('f')(x, Function('g')(y))\n        assert parse_mathematica(m_expr) == expected\n", "    def test_parse_mathematica_function_with_arguments_and_optional_arguments():\n        expr_str = \"Sin[x_, y_?NumericQ]\"\n        expr = parse_mathematica(expr_str)\n        x = symbols('x')\n        y = symbols('y')\n        assert expr == sin(x, y)\n\n", "    def test_parse_mathematica_function_with_underscore(self):\n        expr = parse_mathematica(\"f_[x_] := x^2\")\n        f = Function('f')\n        assert expr == f(x)\n\n", "def test_compound_expression():\n    parser = MathematicaParser()\n    expr = \"x + y * z\"\n    expected = parse_mathematica(expr, parser)\n    assert expr == str(expected)\n", "    def test_parse_nested_functions():\n        expr = \"Sin[Cos[x]]\"\n        expected = sin(cos(x))\n        assert parse_mathematica(expr) == expected\n"], "sample_91": ["    def test_evaluate_skip_marks_skip(self):\n        item = pytest.Item.from_parent(None, fspath=None, func=lambda x: 0)\n        item._store[skipped_by_mark_key] = False\n        for mark_name in [\"skipif\", \"skip\"]:\n            item.add_marker(mark_name, reason=\"some reason\")\n            skip_reason = evaluate_skip_marks(item)\n            assert skip_reason is not None\n            assert skip_reason.reason == \"some reason\"\n            item.marks = []\n", "    def test_evaluate_skip_marks_multiple_conditions(self):\n        item = _pytest.Item(\n            \"hello\", config=pytest.Config(option=pytest.Option({\"runxfail\": False}))\n        )\n        item._markernames = {\"skipif\"}\n        item._config.option.xfail_strict = False\n        mark = _pytest.mark.Mark(\n            name=\"skipif\", args=(\"condition1\", \"condition2\"), kwargs={\"reason\": \"multiple reasons\"}\n        )\n        item._markers = [mark]\n        with pytest.raises(Exception):\n            evaluate_skip_marks(item)\n", "    def test_evaluate_skipif_condition_false(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n                pytest.skipif(False, reason=\"condition should be False\")\n                assert False, \"This should not be reached\"\n            \"\"\"\n        )\n        result = testdir.runpytest()\n        result.assert_outcomes(passed=1)\n", "    def test_evaluate_skip_marks_conditional_skipif_with_reason(self):\n        item = self.create_item_with_marks(\n            \"skipif(sys.platform == 'win32', reason='Skipping on Windows')\",\n        )\n        skip_info = evaluate_skip_marks(\n            item\n        )\n        assert skip_info is not None\n        assert skip_info.reason == \"Skipping on Windows\" \n", "    def test_evaluate_skip_marks_condition_string(self):\n        item = runtestprotocol.Item(\n            name=\"test_func\",\n            function=lambda: None,\n            nodeid=\"test_func\",\n            parent=None,\n            config=None,\n        )\n        item._store = {}\n        item.iter_markers = lambda name: [pytest.mark.skipif(\"sys.platform == 'win32'\", reason=\"skip on windows\")]\n        skip = evaluate_skip_marks(item)\n        assert skip.reason == \"skip on windows\"\n"], "sample_16": ["    def test_nested_objects_many_to_many(self):\n        car1 = Car.objects.create(make='Toyota', model='Corolla')\n        car2 = Car.objects.create(make='Honda', model='Civic')\n        event1 = Event.objects.create(name='Car Show')\n        event2 = Event.objects.create(name='Race Day')\n\n        event1.cars.add(car1, car2)\n        event2.cars.add(car2)\n\n        self.n.collect([event1, event2])\n        self.assertEqual(self.n.nested(lambda obj: str(obj)), [[str(event1), [str(car1), str(car2)]], [str(event2), [str(car2)]]])\n\n", "    def test_nested_deletion_with_circular_reference(self):\n        self._connect(0, 1)\n        self._connect(1, 2)\n        self._connect(2, 0)\n\n        self._collect(0, 1, 2)\n        target = [[self.objs[0].num], [self.objs[1].num], [self.objs[2].num]]\n        self._check(target)\n", "    def test_nested_objects_with_circular_references(self):\n        self._connect(1, 0)  # 1 -> 0\n        self._connect(2, 1)  # 2 -> 1\n        self._connect(3, 2)  # 3 -> 2\n        self._connect(4, 3)  # 4 -> 3\n\n        self._collect(0, 1, 2, 3, 4)\n        target = [\n            [self.objs[0].num, [self.objs[1].num, [self.objs[2].num, [self.objs[3].num, [self.objs[4].num]]]]],\n        ]\n        self._check(target)\n", "    def test_nested_objects_with_circular_references(self):\n        self._connect(1, 0)\n        self._connect(2, 1)\n        self._connect(3, 2)\n        self._collect(0, 1, 2, 3)\n        target = [\n            [0],\n            [1, [2, [3]]],\n        ]\n        self._check(target)\n", "    def test_nested_objects_with_circular_relation(self):\n        self._connect(1, 0)\n        self._connect(2, 1)\n        self._connect(3, 2)\n        self._collect(1, 2, 3)\n\n        target = [\n            [self.objs[1].num, [self.objs[2].num]],\n            [self.objs[2].num, [self.objs[3].num]],\n            [self.objs[3].num],\n        ]\n        self._check(target)\n\n"], "sample_56": ["    def test_app_dirs_and_loaders(self):\n        errors = check_setting_app_dirs_loaders(None, **{})\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, E001.id)\n", "    def test_app_dirs_and_loaders(self):\n        errors = check_setting_app_dirs_loaders(None, **{})\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, E001.id)\n", "    def test_app_dirs_and_loaders(self):\n        errors = check_setting_app_dirs_loaders(None, **{})\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, E001.id)\n", "    def test_app_dirs_and_loaders(self):\n        self.assertEqual(\n            check_setting_app_dirs_loaders(None, **{}),\n            [E001],\n        )\n", "    def test_check_setting_app_dirs_loaders(self):\n        errors = check_setting_app_dirs_loaders(None, **{})\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Error)\n        self.assertEqual(errors[0].id, E001.id)\n"], "sample_114": ["    def test_class_distribution_empty_sparse(self):\n        X = sp.csr_matrix((2, 3))\n\n        classes, _, _ = class_distribution(X)\n        assert classes == [np.array([0, 1, 2])]\n", "    def test_unique_labels_multilabel_sequences(self):\n        for seq in MULTILABEL_SEQUENCES:\n            with pytest.raises(ValueError, match=\"Multilabel format\"):\n                unique_labels(seq)\n", "    def test_type_of_target_multilabel_sequences_deprecation(self):\n        with pytest.warns(FutureWarning, match=\"Sequence of sequences\"):\n            type_of_target(MULTILABEL_SEQUENCES[0])\n\n", "def test_multiclass_sparse_matrix_types():\n    for target_type, examples in EXAMPLES.items():\n        for example in examples:\n\n            if isinstance(example, _NotAnArray):\n                with pytest.raises(TypeError):\n                    type_of_target(example)\n            elif target_type == \"multilabel-indicator\" and issparse(\n                example\n            ):\n                assert (\n                    type_of_target(example) == \"multilabel-indicator\"\n                )\n            elif target_type != \"unknown\" and isinstance(example, np.ndarray):\n                if example.ndim > 2:\n                    assert type_of_target(example) == \"unknown\"\n                else:\n                    assert type_of_target(example) == target_type\n\n", "    def test_type_of_target_multilabel_with_empty_rows():\n        # Check that empty rows can be handled in multilabel-indicator input\n        y = np.array([[1, 0], [0, 1], [], [1, 0]])\n        assert type_of_target(y) == \"multilabel-indicator\"\n\n"], "sample_14": ["    def test_serialize_lazy_object(self):\n        lazy_object = SimpleLazyObject(lambda: 'foo')\n        serialized = serializer_factory(lazy_object)\n        self.assertEqual(serialized.serialize(), (\"'foo'\", set()))\n", "    def test_serialize_lazy_object(self):\n        lazy_obj = SimpleLazyObject(lambda: 'test')\n        serialized, imports = serializer_factory(lazy_obj).serialize()\n        self.assertEqual(serialized, \"'test'\")\n        self.assertEqual(imports, set())\n", "    def test_serialize_model_field_with_choices(self):\n        field = models.CharField(max_length=10, choices=[('a', 'A'), ('b', 'B')])\n        serialized = serializer_factory(field).serialize()\n        self.assertEqual(\n            serialized,\n            (\n                \"django.db.models.CharField(max_length=10, choices=[('a', 'A'), ('b', 'B')])\",\n                {'from django.db import models'},\n            ),\n        )\n\n", "    def test_serialize_date(self):\n        date = datetime.date(2023, 10, 26)\n        serialized, imports = serializer_factory(date).serialize()\n        self.assertEqual(serialized, 'datetime.date(2023, 10, 26)')\n        self.assertEqual(imports, {'import datetime'})\n\n", "    def test_serialize_lazy_object(self):\n        lazy_value = SimpleLazyObject(lambda: 'lazy')\n        serializer = serializer_factory(lazy_value)\n        self.assertEqual(serializer.serialize(), (\"'lazy'\", set()))\n"], "sample_77": ["    def test_label_concise(self, x):\n        a, locs = self.setup_labels(x, concise=True)\n        fmt = a.major.formatter\n        assert isinstance(fmt, mpl.dates.ConciseDateFormatter)\n        # TODO: Add more assertive checks about the formatter output\n", "    def test_label_concise(self, x):\n        a, locs = self.setup_labels(x, concise=True)\n        formatter = a.major.formatter\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n        assert len(formatter.formatters) == len(locs)  \n", "    def test_label_concise(self, x):\n\n        a, locs = self.setup_labels(x, concise=True)\n        formatter = a.major.formatter\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n        # TODO add more specific assertions about formatter output\n", "    def test_label_concise_date(self, x):\n        s = Temporal().label(concise=True)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, len(x) - 1)\n        assert isinstance(a.major.formatter, mpl.dates.ConciseDateFormatter)\n\n", "    def test_label_like_format(self, x):\n        a, locs = self.setup_labels(x, like=\".2f\")\n        labels = a.major.formatter.format_ticks(locs)\n        expected = [f\"{v:.2f}\" for v in locs]\n        assert_array_equal(labels, expected)\n"], "sample_45": ["    def test_method_decorator_with_name(self):\n            return 'decorated'\n\n        class MyClass:\n            pass\n\n        MyClass.my_method = method_decorator(full_decorator, name='my_method')(my_decorated_method)\n\n        instance = MyClass()\n        response = instance.my_method()\n        self.assertIsInstance(response, HttpResponse)\n        self.assertEqual(response.content, b'<html><body>dummy</body></html>')\n", "    def test_method_decorator_with_class(self):\n        class MyClass:\n            @method_decorator(staff_member_required, name='my_method')\n                return HttpResponse(\"OK\")\n\n        instance = MyClass()\n        response = instance.my_method(HttpRequest())\n        self.assertEqual(response.status_code, 200)\n", "    def test_method_decorator_classonlymethod(self):\n        class MyClass:\n            @method_decorator(classonlymethod)\n                return 'Hello'\n\n        # Calling on the class should work\n        self.assertEqual(MyClass.my_method(), 'Hello')\n        # Calling on an instance should raise AttributeError\n        instance = MyClass()\n        with self.assertRaises(AttributeError) as cm:\n            instance.my_method()\n        self.assertEqual(str(cm.exception), \"This method is available only on the class, not on instances.\")\n\n", "    def test_method_decorator_with_class(self):\n        class MyClass:\n            @method_decorator(login_required, 'my_method')\n                return HttpResponse('OK')\n        mc = MyClass()\n        response = mc.my_method(HttpRequest())\n        self.assertEqual(response.status_code, 302)\n        self.assertIsNone(response.content)\n\n", "    def test_method_decorator_with_class(self):\n        class MyClass:\n            @method_decorator(staff_member_required)\n                return HttpResponse(mark_safe('OK'))\n\n        response = MyClass().my_method(HttpRequest())\n        self.assertEqual(response.status_code, 403)\n"], "sample_150": ["    def test_solve_biquadratic_complex():\n        a = Poly(y**2 + 2*x*y + x**2 - 4, y, x, domain='ZZ')\n        b = Poly(y - x + 2, y, x, domain='ZZ')\n        NewOption = Options((x, y), {'domain': 'ZZ'})\n        sol = solve_biquadratic(a, b, NewOption)\n        assert set(sol) == {((1 + I*sqrt(3)), 3 + I*sqrt(3)),\n                           (1 - I*sqrt(3), 3 - I*sqrt(3)),\n                           ((-1 + I*sqrt(3)), (-1 + I*sqrt(3))),\n                           ((-1 - I*sqrt(3)), (-1 - I*sqrt(3)))}\n\n", "def test_solve_poly_system_biquadratic_complex():\n    p = Poly(x**2 + y**2 - 4, x, y)\n    q = Poly(x*y - 1, x, y)\n    sol = solve_poly_system([p, q], x, y)\n    assert set(sol) == {(sqrt(5)/2, 2/sqrt(5)), (-sqrt(5)/2, -2/sqrt(5)),\n                       (sqrt(5)/2, -2/sqrt(5)), (-sqrt(5)/2, 2/sqrt(5))}\n", "def test_solve_poly_system_biquadratic_complex():\n    a = Poly(x**2 + y**2 - 1, x, y)\n    b = Poly(x*y - 1, x, y)\n    sol = solve_poly_system([a, b], x, y)\n    assert set(sol) == {(1/sqrt(2), sqrt(2)), (1/sqrt(2), -sqrt(2)), (-1/sqrt(2), sqrt(2)), (-1/sqrt(2), -sqrt(2))}\n", "def test_solve_poly_system_biquadratic_non_solvable():\n    a = Poly(x**2 + y**2 - 1, x, y)\n    b = Poly(x**2 - y**2 - 1, x, y)\n\n    with raises(SolveFailed):\n        solve_poly_system([a, b], x, y)\n", "    def test_solve_biquadratic_complex_roots():\n        a = Poly(y**2 + x**2 - 4, y, x)\n        b = Poly(y - x + 2, y, x)\n        sol = solve_biquadratic(a, b, Options((x, y), {'domain': 'ZZ'}))\n        assert len(sol) == 2\n        assert all(isinstance(r, tuple) for r in sol)\n\n"], "sample_96": ["    def test_ridgecv_sparse_cv(self):\n        # Check that RidgeCV works with sparse data and cross-validation\n\n        X = sp.csr_matrix([[1, 2], [3, 4], [5, 6]])\n        y = np.array([1, 2, 3])\n        clf = RidgeCV(alphas=[1, 10], cv=KFold(2), fit_intercept=False)\n        clf.fit(X, y)\n        assert_true(clf.coef_.shape == (2,))\n\n", "    def test_ridgecv_sparse_scoring(self):\n        X = SPARSE_FILTER(X_diabetes)\n        y = y_diabetes\n        # Test RidgeCV with a custom scoring function\n        scorer = make_scorer(mean_squared_error, squared=False)\n        ridgecv = RidgeCV(alphas=[1e-3, 1e-2, 1e-1], scoring=scorer)\n        ridgecv.fit(X, y)\n        assert_true(ridgecv.best_score_ < 10)\n", "    def test_ridgecv_sparse_data_gcv(self):\n        rng = np.random.RandomState(0)\n        n_samples = 20\n        n_features = 10\n        X = rng.rand(n_samples, n_features)\n        X = sp.csr_matrix(X)\n        y = rng.rand(n_samples)\n\n        # Test with various gcv_modes\n        for gcv_mode in ['auto', 'svd', 'eigen']:\n            ridgecv = RidgeCV(alphas=(0.1, 1.0, 10.0), gcv_mode=gcv_mode,\n                              fit_intercept=False, normalize=False)\n            ridgecv.fit(X, y)\n            y_pred = ridgecv.predict(X)\n            score = mean_squared_error(y, y_pred)\n            assert_greater(score, 0.0)\n\n            # Check that the best alpha is one of the provided values\n            assert_true(ridgecv.alpha_ in ridgecv.alphas)\n", "    def test_ridge_classifier_cv_sparse_input(self):\n        # Test that RidgeClassifierCV works with sparse input\n\n        X = sp.csc_matrix(make_regression(n_samples=100, n_features=10,\n                                       random_state=0, noise=10)[0])\n        y = make_regression(n_samples=100, n_features=10,\n                             random_state=0, noise=10)[1]\n\n        clf = RidgeClassifierCV(alphas=[0.1, 1.0, 10.0])\n        clf.fit(X, y)\n", "    def test_ridge_cv_sparse_fit_intercept(self):\n        sparse_X = sp.csr_matrix(X_diabetes)\n        ridgecv = RidgeCV(alphas=[1e-4, 1e-2, 1], fit_intercept=True)\n        ridgecv.fit(sparse_X, y_diabetes)\n        \n        # Check if the results are the same as those from a dense array\n        ridgecv_dense = RidgeCV(alphas=[1e-4, 1e-2, 1], fit_intercept=True)\n        ridgecv_dense.fit(X_diabetes, y_diabetes)\n\n        assert_array_almost_equal(ridgecv.coef_, ridgecv_dense.coef_)\n        assert_equal(ridgecv.alpha_, ridgecv_dense.alpha_)\n"], "sample_61": ["    def test_format_large_decimal_scientific_notation(self):\n        result = nformat(\n            Decimal(\"123456789012345678901234567890.1234567890123456789\"),\n            decimal_sep=\",\",\n            decimal_pos=5,\n            grouping=3,\n            thousand_sep=\".\",\n        )\n        self.assertEqual(\n            result, \"12.345.678.901.234.567.890.123,45679\"\n        )\n", "    def test_format_large_decimal(self):\n        value = Decimal(\"123456789012345678901234567890.1234567890\")\n        formatted = nformat(\n            value, decimal_sep=\",\", decimal_pos=5, grouping=3, thousand_sep=\".\"\n        )\n        self.assertEqual(\n            formatted, \"12.345.678.901.234.567.890.123.456\"\n        )\n", "    def test_format_large_decimal(self):\n        number = Decimal(\"123456789012345678901234567890.12345678901234567890\")\n        formatted = nformat(number, decimal_sep=\",\", decimal_pos=4, grouping=3)\n        self.assertEqual(formatted, \"12.345.678.901.234.567.890,1235\")\n", "    def test_format_decimal_with_scientific_notation(self):\n        self.assertEqual(\n            nformat(Decimal(\"1.234567890123456789e+100\"), decimal_sep=\",\", decimal_pos=2),\n            \"12.35e+100\",\n        )\n", "    def test_scientific_notation(self):\n        self.assertEqual(\n            nformat(\n                Decimal(\"1.2345678901234567890e+100\"),\n                decimal_sep=\".\",\n                decimal_pos=2,\n            ),\n            \"1.23e+100\",\n        )\n"], "sample_60": ["    def test_serialize_enum_flag(self):\n        operation = migrations.RunPython(\n            lambda apps: None,\n            reverse_code=lambda apps: None,\n            elide_operations=True\n        )\n        operation.state = {\"value\": IntFlagEnum.A | IntFlagEnum.B}\n        writer = OperationWriter(operation)\n        self.assertEqual(\n            writer.serialize()[0],\n            'migrations.RunPython(lambda apps: None, reverse_code=lambda apps: None, elide_operations=True, state={\"value\": IntFlagEnum.A | IntFlagEnum.B})',\n        )\n", "    def test_serialize_enum_translated(self):\n        with self.assertRaises(ValueError):\n            serializer_factory(TextTranslatedEnum.A)\n", "    def test_serialize_enum_class_with_module(self):\n        class MyEnum(enum.Enum):\n            ONE = 1\n            TWO = 2\n\n        operation = migrations.RunPython(\n            lambda apps, schema_editor: None,\n            reverse_code=lambda apps, schema_editor: None,\n        )\n        operation.state = {\n            \"enum_val\": MyEnum.ONE,\n        }\n        writer = OperationWriter(operation)\n        expected_output = (\n            \"migrations.RunPython(lambda apps, schema_editor: None, reverse_code=lambda \"\n            \"apps, schema_editor: None, state={'enum_val': enums.MyEnum.ONE}),\"\n        )\n        self.assertEqual(writer.serialize().strip(), expected_output)\n", "    def test_serialize_float_nan(self):\n        writer = OperationWriter(\n            migrations.AlterField(model_name='TestModel1', name='thing', field=models.FloatField(null=True))\n        )\n        expected = (\n            'migrations.AlterField(\\n'\n            '    model_name=\\'TestModel1\\',\\n'\n            '    name=\\'thing\\',\\n'\n            '    field=models.FloatField(null=True),\\n'\n            ')'\n        )\n        self.assertEqual(str(writer), expected)\n", "    def test_serialize_uuid(self):\n        operation = migrations.RunPython(lambda apps: None)\n        operation.kwargs[\"uuid_value\"] = uuid.uuid4()\n\n        writer = OperationWriter(operation)\n        serialized = writer.serialize()\n        self.assertIn(f\"uuid='{operation.kwargs['uuid_value']}'\", serialized)\n"], "sample_108": ["    def test_svc_decision_function_ovr():\n        # Test that decision_function works correctly for OVR\n        X = np.array([[1, 2], [2, 1], [-1, -1]])\n        y = np.array([0, 1, 0])\n        clf = svm.SVC(decision_function_shape='ovr').fit(X, y)\n        dec = clf.decision_function(X)\n        assert dec.shape == (3, 2)\n\n        # test against known values\n        assert_almost_equal(dec[0, 0], -1.485442)\n        assert_almost_equal(dec[0, 1], 1.485442)\n        assert_almost_equal(dec[1, 0], 0.514558)\n        assert_almost_equal(dec[1, 1], -0.514558)\n\n", "compilation error", "def test_svc_decision_function_shape_ovo():\n    \"\"\"Check that decision_function output shape is correct for ovo.\n\n    Non-regression test for #14398.\n    \"\"\"\n    X, y = make_classification(n_samples=100, n_features=20,\n                               n_classes=3, random_state=42)\n    clf = svm.SVC(decision_function_shape='ovo', kernel='linear')\n    clf.fit(X, y)\n\n    # Check shape for decision_function\n    dec_func = clf.decision_function(X)\n    assert dec_func.shape == (100, 3)\n", "    def test_svc_decision_function_shape_ovo():\n        # Check the decision function shape for ovo is correct\n        X_train, X_test, y_train, y_test = train_test_split(\n            iris.data, iris.target, test_size=0.2, random_state=42)\n        clf = svm.SVC(decision_function_shape='ovo')\n        clf.fit(X_train, y_train)\n        dec = clf.decision_function(X_test)\n\n        assert dec.shape[0] == len(X_test)\n        assert dec.shape[1] == 3 * 2 // 2\n", "compilation error"], "sample_54": ["    def test_json_script(self):\n        d = {\"key1\": \"value1\", \"key2\": \"value2\"}\n        script = json_script(d, element_id=\"my-script\")\n        self.assertIn('<script id=\"my-script\" type=\"application/json\">', script)\n        self.assertIn(\n            json.dumps(d, cls=DjangoJSONEncoder).replace('\"', '\\\\\"'), script\n        )\n", "    def test_urlize_nofollow(self):\n        self.check_output(\n            lambda: urlize(\"http://example.com\", nofollow=True),\n            '<a href=\"http://example.com\" rel=\"nofollow\">http://example.com</a>',\n        )\n", "    def test_smart_urlquote(self):\n        self.assertEqual(smart_urlquote(\"http://example.com\"), \"http://example.com\")\n        self.assertEqual(smart_urlquote(\"https://example.com\"), \"https://example.com\")\n        self.assertEqual(\n            smart_urlquote(\"https://www.example.com/path?query=value\"),\n            \"https://www.example.com/path?query=value\",\n        )\n        self.assertEqual(\n            smart_urlquote(\"http://user:pass@example.com\"), \"http://user:pass@example.com\"\n        )\n        self.assertEqual(smart_urlquote(\"example.com\"), \"http://example.com\")\n        self.assertEqual(smart_urlquote(\"www.example.com\"), \"http://www.example.com\")\n        self.assertEqual(\n            smart_urlquote(\"www.example.com/path?query=value\"),\n            \"http://www.example.com/path?query=value\",\n        )\n        self.assertEqual(smart_urlquote(\"example.net\"), \"http://example.net\")\n        self.assertEqual(smart_urlquote(\"invalid:url\"), \"invalid:url\")\n        self.assertEqual(smart_urlquote(\"invalid[url]\"), \"invalid[url]\")\n", "    def test_smart_urlquote(self):\n        self.assertEqual(smart_urlquote('https://www.example.com'), 'https://www.example.com')\n        self.assertEqual(smart_urlquote('http://www.example.com'), 'http://www.example.com')\n        self.assertEqual(smart_urlquote('www.example.com'), 'http://www.example.com')\n        self.assertEqual(smart_urlquote('example.com'), 'http://example.com')\n        self.assertEqual(smart_urlquote('ftp://ftp.example.com'), 'ftp://ftp.example.com')\n        self.assertEqual(smart_urlquote('example.com/path'), 'http://example.com/path')\n        self.assertEqual(smart_urlquote('example.com?query'), 'http://example.com?query')\n        self.assertEqual(smart_urlquote('example.com#fragment'), 'http://example.com#fragment')\n        self.assertEqual(smart_urlquote('https://user:password@example.com'),\n                         'https://user:password@example.com')\n        self.assertEqual(smart_urlquote('http://[::1]'), 'http://[::1]')\n        self.assertEqual(smart_urlquote('http://localhost'), 'http://localhost')\n\n\n\n", "    def test_json_script(self):\n        self.assertEqual(\n            json_script({'key': 'value', 'list': [1, 2, 3]}),\n            '<script type=\"application/json\">{&quot;key&quot;: &quot;value&quot;, &quot;list&quot;: [1, 2, 3]}</script>'\n        )\n        self.assertEqual(\n            json_script({'key': 'value', 'list': [1, 2, 3]}, element_id='my-script'),\n            '<script id=\"my-script\" type=\"application/json\">{&quot;key&quot;: &quot;value&quot;, &quot;list&quot;: [1, 2, 3]}</script>'\n        )\n"], "sample_29": ["    def test_related_field_references(self):\n        # Test that we can access related field values in expressions.\n        query = Company.objects.annotate(\n            ceo_full_name=F('ceo__firstname') + ' ' + F('ceo__lastname')\n        ).values('name', 'ceo_full_name')\n        self.assertQuerysetEqual(\n            query, [\n                {'name': 'Example Inc.', 'ceo_full_name': 'Joe Smith'},\n                {'name': 'Foobar Ltd.', 'ceo_full_name': 'Frank Meyer'},\n                {'name': 'Test GmbH', 'ceo_full_name': 'Max Mustermann'},\n            ],\n            ordered=False\n        )\n", "    def test_when_expressions(self):\n        self.assertQuerysetEqual(\n            Company.objects.annotate(\n                chair_number=Case(\n                    When(num_chairs__gt=3, then=Value(\"Many\")),\n                    When(num_chairs__gt=1, then=Value(\"Few\")),\n                    default=Value(\"None\"),\n                    output_field=CharField(),\n                )\n            ).order_by(\"name\"),\n            [\n                {\n                    \"name\": \"Example Inc.\",\n                    \"num_employees\": 2300,\n                    \"num_chairs\": 5,\n                    \"chair_number\": \"Many\",\n                },\n                {\n                    \"name\": \"Foobar Ltd.\",\n                    \"num_employees\": 3,\n                    \"num_chairs\": 4,\n                    \"chair_number\": \"Many\",\n                },\n                {\n                    \"name\": \"Test GmbH\",\n                    \"num_employees\": 32,\n                    \"num_chairs\": 1,\n                    \"chair_number\": \"Few\",\n                },\n            ],\n        )\n\n", "    def test_combined_expression_with_aggregate(self):\n        result = self.company_query.annotate(\n            employees_per_chair=Sum('num_employees') / F('num_chairs')\n        ).values_list('employees_per_chair', flat=True)\n        self.assertEqual(\n            list(result),\n            [\n                Approximate(460, places=1),\n                Approximate(750, places=1),\n                32,\n            ],\n        )\n\n", "    def test_subquery_in_expression(self):\n        # Test using a subquery in an expression within a where clause\n        subquery = Employee.objects.filter(salary__gt=15).values('id')\n        result = Company.objects.filter(ceo__in=subquery).get()\n        self.assertEqual(result, self.foobar_ltd)\n\n", "    def test_order_by_and_values(self):\n        ordered = list(self.company_query.order_by('-num_chairs'))\n        self.assertEqual(\n            ordered[0]['name'],\n            'Test GmbH',\n        )\n\n"], "sample_74": ["    def test_colorbar_extension_length_vertical(self):\n        fig, axs = plt.subplots(4, 3, figsize=(8, 10))\n        cmap, norms = _get_cmap_norms()\n        for i, extension_type in enumerate(('neither', 'min', 'max', 'both')):\n            norm = norms[extension_type]\n            boundaries = values = norm.boundaries\n            values = values[:-1]\n            for j, extendfrac in enumerate((None, 'auto', 0.1)):\n                ax = axs[i, j]\n                Colorbar(ax, cmap=cmap, norm=norm,\n                         boundaries=boundaries, values=values,\n                         extend=extension_type, extendfrac=extendfrac,\n                         orientation='vertical')\n                ax.tick_params(left=False, labelleft=False,\n                               bottom=False, labelbottom=False)\n        fig.tight_layout()\n\n", "    def test_colorbar_no_norm(self):\n        fig, ax = plt.subplots()\n        # Create some data.\n        data = np.arange(100).reshape(10, 10)\n        # Create an image from the data.\n        img = ax.imshow(data, cmap='viridis')\n        # Create a colorbar without specifying a norm.\n        fig.colorbar(img)\n        # Assert that the colorbar is created without errors.\n\n\n\n", "def test_colorbar_ticks_formatters():\n    fig, ax = plt.subplots()\n    im = ax.imshow(np.arange(100).reshape(10, 10), cmap='viridis')\n    cbar = fig.colorbar(im, ax=ax)\n\n    # Test default tick formatter\n    assert isinstance(cbar.ax.yaxis.get_major_formatter(),\n                      mticker.ScalarFormatter)\n\n    # Test setting a custom tick formatter\n    cbar.ax.yaxis.set_major_formatter(\n        mticker.FormatStrFormatter('%d items'))\n    for label in cbar.ax.yaxis.get_ticklabels():\n        assert label.get_text().endswith(' items')\n\n", "def test_colorbar_extension_length_log():\n    \"\"\"\n    Test colorbar extensions with logarithmic spacing.\n\n    This test checks the behavior of colorbar extensions when the colormap\n    is logarithmic. It ensures that the extensions are correctly sized\n    and positioned.\n    \"\"\"\n    cmap = mpl.colormaps[\"viridis\"].resampled(5)\n    norm = LogNorm(vmin=1, vmax=1000)\n    clevs = norm.boundaries\n\n    fig, ax = plt.subplots()\n    cb = Colorbar(ax, cmap=cmap, norm=norm,\n                  boundaries=clevs,\n                  extend=\"both\",\n                  extendfrac='auto',\n                  orientation='vertical')\n    fig.canvas.draw()\n    # Check that the extension triangles are the right size.\n    # This test may need to be adjusted based on changes in\n    # how the extensions are rendered.\n\n    bbox = cb.ax.bbox.transformed(fig.transFigure)\n    upper_triangle_height = bbox.ymax - cb.ax.get_ylim()[1]\n    lower_triangle_height = cb.ax.get_ylim()[0] - bbox.ymin\n\n", "    def _colorbar_extension_location(self):\n        \"\"\"Test that colorbar extensions are correctly positioned\n        for different locations.\"\"\"\n        cmap = mpl.colormaps[\"viridis\"]\n        norm = Normalize(vmin=0, vmax=100)\n        fig, axs = plt.subplots(2, 2)\n\n        for i, loc in enumerate(('left', 'right', 'top', 'bottom')):\n            ax = axs.flat[i]\n            cb = Colorbar(ax, cmap=cmap, norm=norm,\n                          orientation='vertical' if loc in ('left', 'right')\n                          else 'horizontal',\n                          location=loc, extend='both')\n            ax.set_title(f\"Location: {loc}\")\n\n        return fig\n"], "sample_1": ["def test_read_multi_table():\n    qdp_text = \"\"\"\n    ! Initial comment line 1\n    ! Initial comment line 2\n    READ TERR 1\n    READ SERR 3\n    ! Table 0 comment\n    !a a(pos) a(neg) b be c d\n    53000.5   0.25  -0.5   1  1.5  3.5 2\n    54000.5   1.25  -1.5   2  2.5  4.5 3\n    NO NO NO NO NO\n    ! Table 1 comment\n    !a a(pos) a(neg) b be c d\n    54000.5   2.25  -2.5   NO  3.5  5.5 5\n    55000.5   3.25  -3.5   4  4.5  6.5 nan\n    \"\"\"\n    table_list = ascii.read(qdp_text, format=\"ascii.qdp\")\n    assert len(table_list) == 2\n    # Check the first table\n    assert table_list[0]['a'][0] == 53000.5\n    assert table_list[0]['a_perr'][0] == 0.25\n    assert table_list[0]['c'][0] == 3.5\n    # Check the second table\n    assert table_list[1]['a'][0] == 54000.5\n    assert table_list[1]['a_nerr'][0] == -2.5\n    assert table_list[1]['c'][0] == 5.5\n", "def test_read_qdp_masked_values():\n    data = \"\"\"\n    ! Initial comment\n    READ SERR 1\n    ! Table 1\n    a a(err) b\n    1.1 0.1 2\n    1.2 0.2 3\n    NO NO NO\n    \"\"\"\n    table = ascii.read(data, format='ascii.qdp', names=['a', 'b'])\n    assert np.isnan(table['a'][2])\n    assert np.isnan(table['b'][2])\n    assert table['a'].mask[2]\n    assert table['b'].mask[2]\n", "def test_write_table_qdp_comments():\n    table = Table(\n        {\n            \"col1\": [1.0, 2.0],\n            \"col2\": [3.0, 4.0],\n            \"col3\": [5.0, 6.0],\n        },\n        meta={\"comments\": [\"Comment 1\", \"Comment 2\"], \"initial_comments\": [\"Initial comment 1\"]},\n    )\n\n    lines = _write_table_qdp(table)\n\n    assert lines[0] == \"Initial comment 1\"\n    assert lines[1] == \"! Comment 1\"\n    assert lines[2] == \"! Comment 2\"\n    assert lines[3] == \"col1 col2 col3\"\n    assert lines[4] == \"1.0 3.0 5.0\"\n    assert lines[5] == \"2.0 4.0 6.0\"\n", "def test_read_write_table_err():\n    \"\"\"Test reading and writing a table with error columns.\"\"\"\n\n    table = Table()\n    table['a'] = [1, 2, 3]\n    table['b_perr'] = [0.1, 0.2, 0.3]\n    table['b_nerr'] = [-0.1, -0.2, -0.3]\n    table['c_err'] = [0.05, 0.1, 0.15]\n    table['d'] = [10, 20, 30]\n\n    # Write the table to a temporary file\n    with tempfile.NamedTemporaryFile(delete=False) as tmpfile:\n        filename = tmpfile.name\n        _write_table_qdp(table, filename)\n\n    # Read the table back\n    read_table = ascii.read(filename, format='qdp')\n\n    # Assert that the table structure is preserved\n    assert read_table.colnames == ['a', 'b_perr', 'b_nerr', 'c_err', 'd']\n    assert np.allclose(read_table['a'], table['a'])\n    assert np.allclose(read_table['b_perr'], table['b_perr'])\n    assert np.allclose(read_table['b_nerr'], table['b_nerr'])\n    assert np.allclose(read_table['c_err'], table['c_err'])\n    assert np.allclose(read_table['d'], table['d'])\n\n    # Clean up the temporary file\n    os.remove(filename)\n", "def test_read_missing_value():\n    # Test reading a file with a missing value represented by \"NO\"\n    data = \"\"\"\n    a b c\n    1 2 3\n    4 5 NO\n    7 8 9\n    \"\"\"\n    table = ascii.read(data, format=\"qdp\")\n    assert table[\"a\"][1] == 4\n    assert table[\"b\"][1] == 5\n    assert np.ma.is_masked(table[\"c\"][1])\n"], "sample_115": ["    def test_safe_set_output_errors():\n        class MockEstimator:\n            pass\n\n        estimator = MockEstimator()\n\n        with pytest.raises(ValueError, match=\"Unable to configure output\"):\n            _safe_set_output(estimator, transform=\"pandas\")\n", "def test_wrap_in_pandas_container_sparse_input():\n    \"\"\"Check if the function raises ValueError for sparse input.\"\"\"\n    data = csr_matrix([[1, 2], [3, 4]])\n    with pytest.raises(ValueError, match=\"Pandas output does not support sparse data\"):\n        _wrap_in_pandas_container(data, columns=[1, 2])\n", "    def test_set_output_transform_pandas():\n        class DummyEstimator(_SetOutputMixin):\n                return X\n\n        est = DummyEstimator()\n        with config_context(output_transform=\"pandas\"):\n            est.set_output(transform=\"pandas\")\n\n            df = pd.DataFrame(np.arange(10).reshape(5, 2))\n            result = est.transform(df)\n            assert isinstance(result, pd.DataFrame)\n            assert_array_equal(result.values, df.values)\n\n", "def test_safe_set_output_when_method_not_available():\n    class DummyEstimator:\n        pass\n\n    with pytest.raises(ValueError, match=\"Unable to configure output\"):\n        _safe_set_output(DummyEstimator(), transform=\"pandas\")\n", "    def test_wrap_in_pandas_container_sparse_error():\n        with pytest.raises(ValueError, match=\"Pandas output does not support sparse data.\"):\n            _wrap_in_pandas_container(csr_matrix((2, 2)), columns=[0, 1])\n"], "sample_118": ["    def test_IndexedBase_assign(self):\n        len_y = 5\n        y = IndexedBase('y', shape=(len_y,))\n        t = IndexedBase('t', shape=(len_y,))\n        Dy = IndexedBase('Dy', shape=(len_y-1,))\n        i = Idx('i', len_y-1)\n        e=Eq(Dy[i], (y[i+1]-y[i])/(t[i+1]-t[i]))\n        code = ccode(e.rhs, assign_to='Dy[i]', contract=False)\n        self.assertEqual(code, 'Dy[i] = (y[i + 1] - y[i])/(t[i + 1] - t[i]);')\n", "    def test_ccode_IndexedBase_matrix(self):\n        i, j = symbols('i j')\n        A = MatrixSymbol('A', 2, 2)\n        expr = A[i, j]\n        code = ccode(expr, assign_to='B')\n        expected = \"B = A[{0},{1}];\".format(i, j)\n        self.assertEqual(code, expected)\n", "    def test_ccode_for_loop_with_indexed_assignment():\n        i = Idx('i', range(5))\n        A = IndexedBase('A', shape=(5,))\n        expr = For(i, Range(5), Assignment(A[i], i**2))\n        expected = ('for (int i = 0; i < 5; i++){\\n'\n                    'A[i] = pow(i, 2);\\n'\n                    '}')\n        assert ccode(expr) == expected\n\n", "    def test_indexed_base_printing():\n        i, j = symbols('i j')\n        A = IndexedBase('A', shape=(3, 3))\n        assert ccode(A[i, j]) == 'A[i][j]'\n        assert ccode(A[i, i]) == 'A[i][i]'\n", "    def test_indexed_symbol_matrix_printing(self):\n        x = IndexedBase('x', shape=(3, 3))\n        y = MatrixSymbol('y', 3, 3)\n\n        ccode = ccode(Eq(x[0, 0], y[0, 0]))\n        self.assertEqual(ccode, \"y[0] = x[0];\")\n\n        ccode = ccode(Eq(x[1,1], y[1,1] + y[0,0]))\n        self.assertEqual(ccode, \"y[3 + 1] = y[3 + 1] + x[3];\")\n\n        \n\n\n"], "sample_3": ["def test_separability_matrix_with_custom_model():\n    \"\"\"Test separability matrix with a custom model.\"\"\"\n\n    class MyModel(models.Model):\n        n_inputs = 1\n        n_outputs = 1\n\n            super().__init__()\n            self.factor = factor\n\n            return self.factor * x\n\n    model = MyModel(2) | map1\n    assert_allclose(separability_matrix(model), np.array([[True, False],\n                                                        [False, True]]))\n\n", "    def test_separability_complex_mapping():\n        model = map1 & sh1 | map2 & sh2 | p2 & p1\n        is_sep, sep_mat = is_separable(model), separability_matrix(model)\n        assert_allclose(is_sep, [False, False, False, False, False])\n        assert_allclose(sep_mat,\n                        np.array([[True, False,  False, False, False],\n                                  [False, True,  False, False, False],\n                                  [False, False, True,  False, False],\n                                  [False, False, False, True, False],\n                                  [False, False, False, False, True]]))\n", "    def test_compound_model_12(self):\n        \"\"\"Test separability of a compound model.\"\"\"\n        cm = models.Shift(1) & models.Scale(2) | map3 & rot\n        is_sep, sep_mat = is_separable(cm), separability_matrix(cm)\n        assert_allclose(is_sep, np.array([False, False, True]))\n        assert_allclose(sep_mat, np.array([[True, False], [True, False], [False, True]]))\n\n", "    def test_separability_compound_model_12():\n        transform = ((rot & sh1) | map2)\n        separable = is_separable(transform)\n        expected_separability_array = np.array([False, False])\n        assert_allclose(separable, expected_separability_array)\n\n        separability_matrix_ = separability_matrix(transform)\n        expected_separability_matrix = np.array([[True, True], [True, True]])\n        assert_allclose(separability_matrix_, expected_separability_matrix)\n", "    def test_separable_compound8():\n        model = compound_models['cm8'][0]\n        assert_allclose(is_separable(model), compound_models['cm8'][1][0])\n        assert_allclose(separability_matrix(model), compound_models['cm8'][1][1])\n"], "sample_64": ["    def test_submit_row_tag(self):\n        request = self.request_factory.get(reverse('admin:article_article_change', args=(1,)))\n        request.user = User.objects.create_user('testuser', 'test@example.com', 'password')\n        request.user.is_staff = True\n        request.user.save()\n\n        context = {'add': True, 'change': False, 'is_popup': False, 'save_as': False,\n                   'has_add_permission': True, 'has_change_permission': True,\n                   'has_view_permission': True,\n                   'has_editable_inline_admin_formsets': False, 'show_delete': True}\n\n        rendered = submit_row(context)\n\n        self.assertIn('can_change', rendered)\n        self.assertIn('show_delete_link', rendered)\n        self.assertIn('show_save_as_new', rendered)\n        self.assertIn('show_save_and_add_another', rendered)\n        self.assertIn('show_save_and_continue', rendered)\n        self.assertIn('show_save', rendered)\n        self.assertIn('show_close', rendered)\n\n", "    def test_submit_row_tag(self):\n        request = self.request_factory.get(reverse(\"admin:myapp_article_change\", args=(1,)))\n        request.user = self.user\n        request.GET = {\"_popup\": 1}\n        request.session = {}\n        context = {\n            \"add\": False,\n            \"change\": True,\n            \"is_popup\": True,\n            \"save_as\": False,\n            \"has_add_permission\": True,\n            \"has_change_permission\": True,\n            \"has_view_permission\": True,\n            \"has_delete_permission\": True,\n            \"has_editable_inline_admin_formsets\": False,\n            \"show_save\": True,\n            \"show_save_and_add_another\": True,\n            \"show_save_and_continue\": True,\n            \"show_delete\": True,\n        }\n        ctx = submit_row(context)\n        self.assertTrue(ctx[\"show_save\"])\n        self.assertFalse(ctx[\"show_save_and_add_another\"])\n        self.assertFalse(ctx[\"show_save_and_continue\"])\n        self.assertTrue(ctx[\"show_close\"])\n        self.assertTrue(ctx[\"show_delete_link\"])\n", "    def test_cell_count(self):\n        request = self.request_factory.get(reverse(\"admin:articles_article_changelist\"))\n        request.user = self.user\n        ctx = {\n            \"inline_admin_form\": ArticleAdmin(Article, site).get_inline_formset(\n                request, None, Article\n            ).forms[0],\n        }\n\n        self.assertEqual(cell_count(ctx[\"inline_admin_form\"]), 7)\n", "    def test_submit_row_tag_display_save_and_add_another(self):\n        request = self.request_factory.get(reverse('admin:myapp_article_add'))\n        request.user = self.user\n        request.META['HTTP_REFERER'] = \"/admin/myapp/article/\"\n        context = {\n            \"add\": True,\n            \"change\": False,\n            \"is_popup\": False,\n            \"save_as\": False,\n            \"has_add_permission\": True,\n            \"has_change_permission\": True,\n            \"has_view_permission\": True,\n            \"has_editable_inline_admin_formsets\": False,\n        }\n        template_context = submit_row(Context(context)).dicts\n        self.assertTrue(template_context['show_save_and_add_another'])\n", "    def test_submit_row(self):\n        request = self.request_factory.get('/admin/blog/article/')\n        request.user = User.objects.create_user('testuser', 'test@example.com', 'password')\n        get_perm(request.user, 'blog.add_article')\n        admin_site = site\n\n        # Create an ArticleAdmin instance\n        article_admin = ArticleAdmin(Article, admin_site)\n        # Create Article instance\n        article = Article(title=\"Test Article\", slug=\"test-article\")\n        article.save()\n\n        # Mock the context data for the template\n        context = {\n            'adminform': article_admin.form(request, article),\n            'add': True,\n            'change': False,\n            'is_popup': False,\n            'save_as': False,\n            'show_save': True,\n            'show_save_and_add_another': True,\n            'show_save_and_continue': True,\n            'has_add_permission': True,\n            'has_change_permission': True,\n            'has_view_permission': True,\n            'has_editable_inline_admin_formsets': False,\n        }\n\n        # Render the submit_row template tag\n        rendered_html = submit_row(context).render()\n\n        # Assert that the rendered HTML contains expected elements\n        self.assertIn('<button type=\"submit\" name=\"_save\"', rendered_html)\n        self.assertIn('<button type=\"submit\" name=\"_saveandaddanother\"', rendered_html)\n        self.assertIn('<button type=\"submit\" name=\"_saveandcontinue\"', rendered_html)\n        self.assertIn('<button type=\"submit\" name=\"_delete\"', rendered_html)\n"], "sample_89": ["compilation error", "compilation error", "compilation error", "compilation error", "compilation error"], "sample_13": ["    def test_urlencode_multivaluedict(self):\n        q = MultiValueDict({'a': ['1', '2']})\n        self.assertEqual(urlencode(q), 'a=1&a=2')\n\n", "    def test_urlencode_multivaluedict(self):\n        data = MultiValueDict({'a': ['1', '2'], 'b': ['3', '4']})\n        self.assertEqual(urlencode(data), 'a=1&a=2&b=3&b=4')\n\n", "    def test_urlencode_multivaluedict(self):\n        d = MultiValueDict({'a': ['1', '2'], 'b': ['3']})\n        self.assertEqual(urlencode(d), 'a=1&a=2&b=3')\n\n", "    def test_urlencode_with_multivaluedict(self):\n        query = MultiValueDict({'a': ['1', '2'], 'b': ['3']})\n        self.assertEqual(urlencode(query), 'a=1&a=2&b=3')\n", "    def test_urlencode_multivaluedict(self):\n        data = MultiValueDict({'a': ['1', '2'], 'b': ['3']})\n        self.assertEqual(urlencode(data), 'a=1&a=2&b=3')\n"], "sample_159": ["    def test_prefix_unit():\n        km = Prefix('kilo', 'k', 3) * meter\n        assert km == kilo*meter\n        assert km == Quantity('kilometer', abbrev='km')\n\n        prefixes = {'k': kilo, 'c': Prefix('centi', 'c', -2)}\n        prefixed_units = prefix_unit(meter, prefixes)\n        assert len(prefixed_units) == 2\n        assert prefixed_units[0] == kilo*meter\n        assert prefixed_units[1] == Prefix('centi', 'c', -2)*meter\n\n        assert SI.get_quantity_dimension_map(prefixed_units[0]) == SI.get_quantity_dimension_map(km)\n", "def test_prefix_unit_custom_prefixes():\n    pref = {\"k\": PREFIXES[\"k\"], \"M\": PREFIXES[\"M\"]}\n    kilometers = prefix_unit(meter, pref)[0]\n    assert kilometers.name == kilo*meter.name\n    assert kilometers.abbrev == kilo.abbrev + meter.abbrev\n    assert kilometers.scale_factor == kilo.scale_factor*meter.scale_factor\n", "    def test_prefix_unit():\n        m = meter\n        pref = {\"m\": PREFIXES[\"m\"], \"c\": PREFIXES[\"c\"], \"d\": PREFIXES[\"d\"]}\n        prefixed_units = prefix_unit(m, pref)\n        assert prefixed_units[0] == PREFIXES[\"m\"]*m\n        assert prefixed_units[1] == PREFIXES[\"c\"]*m\n        assert prefixed_units[2] == PREFIXES[\"d\"]*m\n\n", "def test_prefix_unit():\n    from sympy.physics.units.quantities import Quantity\n    m = Quantity('meter', length, abbrev='m')\n    pref = {'k': PREFIXES['k'], 'M': PREFIXES['M']}\n    prefixed_units = prefix_unit(m, pref)\n\n    assert prefixed_units[0].name == 'kilometer'\n    assert prefixed_units[0].abbrev == 'km'\n    assert prefixed_units[0].scale_factor == kilo.scale_factor * meter.scale_factor\n    assert prefixed_units[1].name == 'megameter'\n    assert prefixed_units[1].abbrev == 'Mm'\n    assert prefixed_units[1].scale_factor == mega.scale_factor * meter.scale_factor\n", "    def test_prefix_unit():\n        prefixed_units = prefix_unit(meter, PREFIXES)\n        assert len(prefixed_units) == len(PREFIXES)\n        assert prefixed_units[0].name == 'yottameter'\n        assert prefixed_units[-1].abbrev == 'ym'\n        assert prefixed_units[5].scale_factor == 1000\n\n"], "sample_93": ["def test_get_user_no_user(monkeypatch):\n    with monkeypatch.context() as m:\n        m.setattr(getpass, \"getuser\", lambda: None)\n        assert pathlib.get_user() is None\n", "def test_get_user_raises_if_getuser_fails(monkeypatch: MonkeyPatch) -> None:\n    monkeypatch.setattr(getpass, \"getuser\", lambda: (yield OSError()))\n    with pytest.raises(RuntimeError):\n        get_user()\n", "    def test_tmpdir_factory_getbasetemp_with_given_basetemp(self, pytester: Pytester) -> None:\n        config = pytester.parseconfig([], {'basetemp': 'some/base/temp'})\n        factory = TempPathFactory.from_config(config, _ispytest=True)\n        basetemp = factory.getbasetemp()\n        assert str(basetemp) == 'some/base/temp'\n        assert basetemp.exists()\n", "def test_tmpdirhandler_getbasetemp_from_env(pytester: Pytester) -> None:\n    pytester.makeconfig(\n        {\n            \"pytest_debug_temproot\": \"/some/path\",\n        }\n    )\n\n    with pytester.monkeypatch_config(\n        {\n            \"pytest_debug_temproot\": \"/some/path\",\n        }\n    ) as config:\n        tmpdir_factory = TempdirFactory.from_config(config)\n        assert tmpdir_factory.getbasetemp() == Path(\"/some/path\").resolve()\n", "    def test_tmpdir_factory_getbasetemp_from_config(self, pytester: Pytester) -> None:"], "sample_46": ["    def test_references_table(self):\n        self.assertTrue(self.reference.references_table('TABLE'))\n        self.assertFalse(self.reference.references_table('other_table'))\n", "    def test_table_rename_references(self):\n        self.reference.rename_table_references('table', 'new_table')\n        self.assertEqual(str(self.reference), 'NEW_TABLE')\n", "    def test_table_rename(self):\n        self.reference.rename_table_references('table', 'new_table')\n        self.assertEqual(str(self.reference), 'NEW_TABLE')\n", "    def test_table_references_table(self):\n        self.assertTrue(self.reference.references_table('table'))\n        self.assertFalse(self.reference.references_table('other_table'))\n", "    def test_table_references_table(self):\n        self.assertTrue(self.reference.references_table('TABLE'))\n        self.assertFalse(self.reference.references_table('another_table'))\n"], "sample_38": ["    def test_create_user_with_invalid_password(self):\n        form_data = {\n            'username': 'newuser',\n            'password1': 'short',\n            'password2': 'short',\n        }\n        form = UserCreationForm(form_data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors['password1'], [\n            _(\"Ensure this field has at least 8 characters.\"),\n        ])\n", "    def test_password_validation_with_custom_validators(self):\n        with override_settings(PASSWORD_HASHERS=['django.contrib.auth.hashers.BCryptSHA256PasswordHasher']):\n            form_data = {'username': 'newuser', 'password1': 'short', 'password2': 'short'}\n            form = UserCreationForm(form_data)\n            self.assertFalse(form.is_valid())\n            self.assertEqual(form.errors['password2'], [\n                _('Ensure this value has at least 8 characters.')\n            ])\n        \n", "    def test_create_user_with_custom_email_field(self):\n        data = {\n            'username': 'testuser',\n            'password1': 'password',\n            'password2': 'password',\n            'email': 'user@example.com',\n        }\n        form = UserCreationForm(data=data)\n        self.assertTrue(form.is_valid())\n        user = form.save()\n        self.assertEqual(user.username, 'testuser')\n        self.assertEqual(user.email, 'user@example.com')\n", "    def test_creation_form_with_custom_email_field(self):\n        user = CustomEmailField.objects.create_user(\n            username='testclient', password='password', email='testclient@example.com'\n        )\n        self.assertEqual(user.email, 'testclient@example.com')\n", "    def test_creation_form_password_validation(self):\n        form_data = {\n            'username': 'testuser',\n            'password1': 'p@sswOrd!1',\n            'password2': 'p@sswOrd!2',\n        }\n        form = UserCreationForm(form_data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors['password2'], [\n            _('The two password fields didn\u2019t match.')\n        ])\n"], "sample_52": ["    def test_add_field_with_default_from_related_model(self):\n        class RelatedModel(models.Model):\n            name = models.CharField(max_length=10)\n\n        class MyModel(models.Model):\n            related = models.ForeignKey(RelatedModel, on_delete=models.CASCADE)\n\n        with atomic(using=self.connection.alias):\n            # Create the related model\n            RelatedModel.objects.create(name='Foo')\n\n            # Create a migration to add a field\n            with self.migration_recorder() as recorder:\n                AddField(\n                    model_name='mymodel',\n                    name='related_name',\n                    field=models.CharField(max_length=20, default='bar'),\n                ).database_forwards(\n                    self.app_label,\n                    recorder.schema_editor(),\n                    ProjectState.from_apps(recorder.apps),\n                )\n\n                # Assert the field was added to MyModel\n                self.assertEqual(MyModel._meta.get_field('related_name').default, 'bar')\n", "    def test_alter_unique_together(self):\n        with atomic(savepoint=False):\n            with connection.cursor() as cursor:\n                cursor.execute(\n                    \"CREATE TABLE test_model (id SERIAL PRIMARY KEY, name VARCHAR(100), \"\n                    \"flavor VARCHAR(100), spiciness INTEGER)\"\n                )\n                cursor.execute(\n                    \"ALTER TABLE test_model ADD CONSTRAINT unique_flavor_spiciness UNIQUE (\"\n                    \"flavor, spiciness)\"\n                )\n\n            class TestModel(models.Model):\n                name = models.CharField(max_length=100)\n                flavor = models.CharField(max_length=100)\n                spiciness = models.IntegerField()\n\n                class Meta:\n                    unique_together = ('flavor', 'spiciness')\n\n            initial_state = ProjectState.from_apps(self.apps)\n            operation = migrations.Migrate(\n                initial_state,\n                initial_state.clone(app_label='tests', model_state=ModelState.from_models(\n                    TestModel)),\n            )\n\n            self.assertEqual(operation.operations[0].__class__, migrations.schema.AlterUniqueTogether)\n            self.assertEqual(\n                operation.operations[0].model_name,\n                'tests.testmodel',\n            )\n            self.assertEqual(\n                operation.operations[0].unique_together,\n                (\n                    'flavor',\n                    'spiciness',\n                ),\n            )\n", "    def test_rename_index_unnamed(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\n                \"CREATE TABLE test_rename_index_unnamed (id INTEGER PRIMARY KEY, \"\n                \"value TEXT)\"\n            )\n        with atomic():\n            class MyModel(models.Model):\n                value = models.CharField(max_length=100)\n\n                class Meta:\n                    db_table = \"test_rename_index_unnamed\"\n\n            with CaptureQueriesContext(connection) as queries:\n                operation = RenameIndex(\n                    model_name=\"test_rename_index_unnamed\",\n                    new_name=\"my_index_name\",\n                    old_fields=[\"value\"],\n                )\n                database_schema_editor = self.get_schema_editor(connection)\n                operation.database_forwards(\n                    'default', database_schema_editor, self.before_state, self.after_state\n                )\n                self.assertEqual(\n                    queries.captured_queries[1],\n                    [\n                        \"CREATE INDEX my_index_name ON test_rename_index_unnamed (value)\"\n                    ],\n                )\n\n", "    def test_add_constraint_unique_together(self):\n        class Food(models.Model):\n            name = models.CharField(max_length=10)\n            calories = models.IntegerField()\n\n        with CaptureQueriesContext(connection) as captured_queries:\n            # Create initial migration\n            migration = migrations.Migration(\n                \"initial\", (\"\", []),\n                operations=[migrations.CreateModel(\n                    name='Food',\n                    fields=[\n                        ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n                        ('name', models.CharField(max_length=10)),\n                        ('calories', models.IntegerField()),\n                    ],\n                    options={'db_table': 'food',\n                            'managed': True,\n                            'unique_together': ('name', 'calories')},\n                )],\n            )\n\n            # State before applying migration\n            state = ProjectState.from_migration(migration)\n            self.assertEqual(state.models[('app', 'food')].options['unique_together'],\n                             (('name', 'calories'),))\n\n            # Apply migration\n            with self.atomically():\n                migration.apply(connection)\n\n            \n            # Check database constraints\n            self.assertEqual(\n                captured_queries[0].get('sql')[0],\n                'CREATE UNIQUE INDEX ON \"food\" (\"name\", \"calories\")'\n            )\n\n", "    def test_alter_jsonfield(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\"CREATE TABLE test_jsonfield (id SERIAL PRIMARY KEY, data JSONB)\")\n        app_label = \"test_migrations\"\n        model_name = \"UnicodeModel\"\n        model = UnicodeModel\n        state = ProjectState.from_apps([])\n        state.models[app_label, model_name] = ModelState.from_model(model)\n        operation = AlterField(\n            model_name=model_name,\n            name=\"data\",\n            field=models.JSONField(default=dict),\n        )\n        migration = Migration(\n            \"test\",\n            [operation],\n            dependencies=[],\n        )\n\n        # Forwards\n        with atomic(using=connection.alias), capture_queries_context as queries:\n            migration.apply(state, schema_editor=connection.schema_editor())\n        self.assertEqual(len(queries.captured_queries), 1)\n        self.assertEqual(\n            queries.captured_queries[0]['sql'],\n            \"ALTER TABLE test_unicodemodel ALTER COLUMN data TYPE JSONB USING data::JSONB\",\n        )\n\n        # Backwards\n        with atomic(using=connection.alias), capture_queries_context as queries:\n            migration.unapply(state, schema_editor=connection.schema_editor())\n        self.assertEqual(len(queries.captured_queries), 1)\n        self.assertEqual(\n            queries.captured_queries[0]['sql'],\n            \"ALTER TABLE test_unicodemodel ALTER COLUMN data TYPE TEXT\",\n        )\n"], "sample_82": ["def test_groupby_apply_args(array):\n    \"\"\"Test that groupby.apply passes arguments correctly.\"\"\"\n\n        return x + a + b\n\n    result = array.groupby(\"x\").apply(myfunc, args=(10, 20))\n    expected = array.groupby(\"x\").map(lambda x: x + 10 + 20)\n\n    assert_identical(result, expected)\n", "def test_groupby_assign_coords(dataset):\n    grouped = dataset.groupby(\"x\").assign(baz=(\"y\", lambda ds: ds.y + 10))\n    expected = dataset.copy()\n    expected[\"baz\"] = ((\"y\"), expected.y + 10)\n    assert_identical(grouped, expected)\n", "    def test_groupby_slice_with_empty_groups(dataset):\n        # Regression test for https://github.com/pydata/xarray/issues/3264\n        expected = dataset.sel(x=[\"a\", \"b\"])\n        grouped = dataset.groupby(\"x\")\n        actual = grouped.nth(0)\n        assert_identical(expected, actual)\n", "    def test_groupby_empty(self):\n        ds = xr.Dataset({\"a\": (\"x\", [1, 2, 3])}, {\"x\": [0, 1, 2]})\n        empty_ds = ds.where(ds[\"a\"] > 5)\n        grouped = empty_ds.groupby(\"x\")\n        assert len(list(grouped)) == 3\n        for group in grouped:\n            assert group[1].size == 0\n", "    def test_groupby_reduce_empty_groups(array):\n        # create empty groups\n        g = array.groupby(array.coords[\"x\"], squeeze=False).mean()\n\n        # Check that the resulting array has the correct shape\n        assert g.shape == (0,) + array.shape[1:]\n\n"], "sample_155": ["    def test_get_dimensional_expr(self):\n        x, y = symbols('x y')\n        v = meter / second\n        a = meter / second**2\n        t = second\n        F = kilogram * meter / second**2\n\n        assert SI.get_dimensional_expr(x * v) == length / time\n        assert SI.get_dimensional_expr(x * a * t**2) == length\n        assert SI.get_dimensional_expr(0.5 * F * v**2) == energy\n        assert SI.get_dimensional_expr(sin(x)) == 1\n        assert SI.get_dimensional_expr(exp(x)*volt) ==  voltage\n        assert SI.get_dimensional_expr(x**2) == 1\n        assert SI.get_dimensional_expr(Add(x, y)) == 1\n", "def test_get_quantity_dimension():\n    assert SI.get_quantity_dimension(meter) == Dimension(length)\n    assert SI.get_quantity_dimension(second) == Dimension(time)\n    assert SI.get_quantity_dimension(kilogram) == Dimension(mass)\n    assert SI.get_quantity_dimension(joule) == Dimension(energy)\n    assert SI.get_quantity_dimension(volt) == Dimension(energy / charge)\n", "    def test_UnitSystem_is_consistent():\n        assert SI.is_consistent is True\n        assert SI.extend(base=(joule,), name=\"SI_extended\").is_consistent is True\n\n\n", "def test_get_dimensional_expr_derived():\n    x = symbols('x')\n    v = meter / second\n    a = meter / second**2\n    \n    expr = v**2 / a\n    assert SI.get_dimensional_expr(expr) == length**1 / time**2\n", "def test_get_dimensional_expr_with_functions():\n    x = symbols('x')\n    expr = sin(x*meter)\n    assert SI.get_dimensional_expr(expr) == Dimension(1)\n\n"], "sample_109": ["    def test_shuffle_split_with_sparse_input(self):\n        # Test ShuffleSplit and StratifiedShuffleSplit with sparse input\n        X = coo_matrix([[1, 2], [3, 4]])\n        y = np.array([0, 1])\n        n_splits = 5\n\n        for cv_class in [ShuffleSplit, StratifiedShuffleSplit]:\n            cv = cv_class(test_size=0.3, random_state=42)\n\n            for train_index, test_index in cv.split(X, y):\n                X_train = X[train_index]\n                X_test = X[test_index]\n\n                assert isinstance(X_train, csc_matrix)\n                assert isinstance(X_test, csc_matrix)\n\n", "    def test_stratified_kfold_multilabel(self):\n        X = np.array([[1, 2], [1, 1], [2, 1], [2, 2], [1, 3], [2, 3]])\n        y = np.array([[1, 0], [0, 1], [1, 0], [1, 1], [0, 1], [1, 1]])\n        skf = StratifiedKFold(n_splits=3)\n        for train, test in skf.split(X, y):\n            assert len(train) + len(test) == X.shape[0]\n            train_y = y[train]\n            test_y = y[test]\n\n            # Check if the distribution of classes in each fold is balanced\n            for col in range(y.shape[1]):\n                train_counts = np.bincount(train_y[:, col])\n                test_counts = np.bincount(test_y[:, col])\n                assert np.allclose(train_counts / len(train),\n                                   test_counts / len(test),\n                                   rtol=0.2)\n", "    def test_stratifiedkfold_multiclass(self):\n        X, y = make_classification(n_samples=100, n_features=10,\n                                  n_informative=5, n_classes=3, random_state=0)\n        skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n        for train_index, test_index in skf.split(X, y):\n            X_train, X_test = X[train_index], X[test_index]\n            y_train, y_test = y[train_index], y[test_index]\n            assert len(np.unique(y_train)) == 3\n", "def test_cross_val_score_fit_params():\n    \"\"\"Test that fit_params are correctly passed to the estimator.\"\"\"\n    X = np.ones((10, 1))\n    y = np.arange(10)\n\n    clf = MockClassifier(allow_nd=True)\n    scoring = 'accuracy'\n\n    # Test with sample_weight\n    sample_weight = np.random.rand(10)\n    scores = cross_val_score(clf, X, y, scoring=scoring,\n                             fit_params={'sample_weight': sample_weight})\n    assert clf.dummy_int is None\n    assert clf.dummy_str is None\n    assert clf.dummy_obj is None\n\n    # Test with class_prior\n    class_prior = np.array([0.1, 0.2, 0.3, 0.4])\n    scores = cross_val_score(clf, X, y, scoring=scoring,\n                             fit_params={'class_prior': class_prior})\n    assert clf.dummy_int is None\n    assert clf.dummy_str is None\n    assert clf.dummy_obj is None\n\n    # Test with sparse_sample_weight\n    sparse_sample_weight = csc_matrix(sample_weight)\n    scores = cross_val_score(clf, X, y, scoring=scoring,\n                             fit_params={'sparse_sample_weight':\n                             sparse_sample_weight})\n    assert clf.dummy_int is None\n    assert clf.dummy_str is None\n    assert clf.dummy_obj is None\n\n    # Test with sparse_param\n    sparse_param = P_sparse\n    scores = cross_val_score(clf, X, y, scoring=scoring,\n                             fit_params={'sparse_param': sparse_param})\n    assert clf.dummy_int is None\n    assert clf.dummy_str is None\n    assert clf.dummy_obj is None\n\n", "    def test_shuffle_split_random_state(self):\n        # Test reproducibility with random_state\n        X = np.arange(10)\n        y = np.array([0, 0, 1, 1, 0, 1, 1, 0, 0, 1])\n        cv = ShuffleSplit(test_size=0.25, random_state=42)\n        train_indices = []\n        test_indices = []\n\n        for train_index, test_index in cv.split(X, y):\n            train_indices.append(train_index)\n            test_indices.append(test_index)\n\n        cv = ShuffleSplit(test_size=0.25, random_state=42)\n        train_indices2 = []\n        test_indices2 = []\n\n        for train_index, test_index in cv.split(X, y):\n            train_indices2.append(train_index)\n            test_indices2.append(test_index)\n\n        assert_array_equal(train_indices, train_indices2)\n        assert_array_equal(test_indices, test_indices2)\n"]}, "raw_scored_generations": {"sample_1": [false, false, false, false, false], "sample_0": [true, true, false, false, true], "sample_3": [false, false, false, false, false], "sample_2": [false, false, false, false, false], "sample_6": [true, false, false, false, true], "sample_4": [true, false, false, true, true], "sample_5": [false, false, false, false, false], "sample_7": [false, false, false, false, false], "sample_9": [false, false, false, false, false], "sample_8": [false, false, false, false, false], "sample_10": [false, false, false, false, false], "sample_11": [false, false, false, false, false], "sample_13": [false, false, false, false, false], "sample_12": [false, false, false, false, false], "sample_14": [false, false, false, false, false], "sample_15": [true, true, true, false, true], "sample_16": [false, false, false, false, false], "sample_17": [true, true, true, true, false], "sample_18": [false, false, false, false, false], "sample_19": [false, false, false, false, false], "sample_21": [false, false, false, false, false], "sample_20": [false, false, false, false, false], "sample_23": [false, false, false, false, false], "sample_22": [true, false, false, true, false], "sample_24": [false, false, false, true, false], "sample_25": [false, false, false, false, false], "sample_28": [true, true, false, true, true], "sample_26": [false, true, true, false, true], "sample_27": [false, false, true, false, false], "sample_29": [false, false, false, false, false], "sample_31": [true, false, false, false, true], "sample_30": [false, false, false, false, false], "sample_32": [false, false, false, false, false], "sample_33": [false, false, false, false, false], "sample_34": [false, false, false, false, false], "sample_35": [false, false, false, false, false], "sample_36": [false, true, true, true, false], "sample_37": [false, false, false, false, false], "sample_39": [false, false, false, false, false], "sample_38": [false, false, false, false, true], "sample_40": [true, false, false, false, true], "sample_42": [false, false, false, false, false], "sample_41": [false, false, false, false, false], "sample_43": [false, false, false, true, true], "sample_45": [false, false, false, false, false], "sample_44": [false, false, false, true, false], "sample_46": [false, true, true, true, false], "sample_48": [false, false, false, false, false], "sample_47": [false, false, false, false, false], "sample_50": [false, false, false, false, false], "sample_49": [false, false, false, false, false], "sample_51": [true, false, false, true, false], "sample_52": [false, false, false, false, false], "sample_53": [false, false, false, false, false], "sample_55": [true, false, false, false, true], "sample_54": [false, false, false, false, false], "sample_56": [true, true, true, true, true], "sample_58": [false, false, false, true, false], "sample_57": [false, true, false, false, false], "sample_60": [false, false, false, false, false], "sample_59": [false, false, false, false, false], "sample_61": [false, false, false, false, false], "sample_63": [false, false, false, false, false], "sample_62": [false, false, false, false, false], "sample_64": [false, false, false, false, false], "sample_66": [false, false, false, false, false], "sample_65": [false, false, true, false, true], "sample_68": [false, true, false, false, false], "sample_67": [false, false, false, false, false], "sample_69": [false, false, false, false, false], "sample_70": [false, false, false, false, false], "sample_71": [true, true, true, false, true], "sample_72": [false, false, false, false, false], "sample_73": [false, false, false, false, false], "sample_74": [false, false, false, false, false], "sample_75": [false, false, false, false, false], "sample_76": [false, true, false, true, false], "sample_77": [false, false, false, true, true], "sample_78": [false, false, false, false, false], "sample_79": [false, false, false, false, false], "sample_80": [false, false, false, false, false], "sample_82": [false, false, false, false, false], "sample_81": [false, false, false, false, false], "sample_83": [false, false, false, false, false], "sample_84": [false, false, false, false, false], "sample_85": [false, false, false, false, false], "sample_86": [false, false, false, false, false], "sample_87": [false, true, true, false, false], "sample_88": [false, false, false, false, false], "sample_89": [false, false, false, false, false], "sample_90": [false, false, false, false, false], "sample_91": [false, false, false, false, false], "sample_92": [false, false, false, false, false], "sample_93": [false, false, false, false, false], "sample_95": [false, false, false, false, false], "sample_94": [false, false, false, false, false], "sample_96": [false, false, false, false, false], "sample_97": [false, false, false, false, false], "sample_98": [false, false, false, false, false], "sample_99": [false, false, false, false, false], "sample_100": [false, false, false, false, false], "sample_101": [false, false, false, false, false], "sample_102": [false, false, true, false, false], "sample_103": [false, false, false, false, false], "sample_104": [false, false, false, false, false], "sample_105": [false, false, false, false, false], "sample_107": [false, false, false, false, false], "sample_106": [false, false, false, false, false], "sample_108": [false, false, false, false, false], "sample_109": [false, false, false, false, false], "sample_110": [false, false, false, false, false], "sample_111": [true, false, false, false, false], "sample_112": [false, false, false, false, false], "sample_113": [false, false, false, false, false], "sample_114": [false, false, false, false, false], "sample_115": [false, true, false, false, false], "sample_116": [false, false, false, false, false], "sample_117": [false, false, false, false, false], "sample_118": [false, false, false, false, false], "sample_119": [false, false, false, true, false], "sample_120": [true, false, false, true, true], "sample_121": [true, true, false, true, false], "sample_122": [false, true, true, true, false], "sample_123": [false, false, false, true, false], "sample_124": [false, true, false, false, true], "sample_125": [true, false, true, false, true], "sample_126": [true, false, true, false, false], "sample_127": [false, false, false, false, false], "sample_128": [false, true, false, false, false], "sample_129": [false, false, false, false, false], "sample_130": [false, true, false, false, true], "sample_131": [false, false, false, false, false], "sample_132": [true, false, false, false, false], "sample_133": [false, false, false, false, true], "sample_134": [false, false, false, false, false], "sample_135": [true, true, false, false, false], "sample_136": [false, true, false, false, false], "sample_137": [false, true, true, false, false], "sample_138": [false, true, false, false, false], "sample_139": [true, false, false, false, true], "sample_140": [true, true, false, false, false], "sample_142": [false, false, false, false, false], "sample_141": [false, false, false, true, false], "sample_143": [true, true, false, false, false], "sample_144": [false, false, false, false, false], "sample_145": [false, false, false, false, false], "sample_146": [false, false, false, false, false], "sample_147": [false, false, false, false, false], "sample_148": [true, false, false, false, true], "sample_149": [true, false, true, false, false], "sample_150": [false, false, false, false, false], "sample_151": [true, false, false, false, true], "sample_152": [false, true, true, false, false], "sample_153": [false, false, false, false, false], "sample_154": [false, false, true, true, false], "sample_155": [false, false, false, false, false], "sample_156": [false, false, false, false, false], "sample_157": [true, true, false, false, false], "sample_158": [false, false, false, false, false], "sample_159": [false, false, false, false, false]}}