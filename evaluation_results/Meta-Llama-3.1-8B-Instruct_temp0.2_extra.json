{"raw_generations": {"sample_200": ["    def test_attachments_with_same_filename(self):\n        \"\"\"\n        Regression test for #14964\n        \"\"\"\n        msg = EmailMessage('subject', 'body', 'from@example.com', ['to@example.com'])\n        msg.attach('example.txt', 'content1', 'text/plain')\n        msg.attach('example.txt', 'content2', 'text/plain')\n        sent_num = msg.send()\n        self.assertEqual(sent_num, 1)\n        filename, content, mimetype = self.get_decoded_attachments(msg)[0]\n        self.assertEqual(filename, 'example.txt')\n        self.assertEqual(content, b'content1')\n        self.assertEqual(mimetype, 'text/plain')\n        self.assertEqual(len(msg.attachments), 2)\n"], "sample_1007": ["def test_subfactorial_diff():\n    x = Symbol('x')\n    n = Symbol('n', integer=True)\n\n    assert subfactorial(x).diff(x) == \\\n        -subfactorial(x - 1) - subfactorial(x - 2)\n    assert subfactorial(n).diff(n) == \\\n        -subfactorial(n - 1) - subfactorial(n - 2)\n"], "sample_55": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n        cls.s1 = State.objects.create(name='New York')\n        cls.s2 = State.objects.create(name='Illinois')\n        cls.s3 = State.objects.create(name='California')\n        cls.c1 = City.objects.create(state=cls.s1, name='New York')\n        cls.c2 = City.objects.create(state=cls.s2, name='Chicago')\n        cls.c3 = City.objects.create(state=cls.s3, name='San Francisco')\n        cls.r1 = Restaurant.objects.create(city=cls.c1, name='Italian Pizza')\n        cls.r2 = Restaurant.objects.create(city=cls.c1, name='Boulevard')\n        cls.r3 = Restaurant.objects.create(city=cls.c2, name='Chinese Dinner')\n        cls.r4 = Restaurant.objects.create(city=cls.c2, name='Angels')\n        cls.r5 = Restaurant.objects.create(city=cls.c2, name='Take Away')\n        cls.r6 = Restaurant.objects.create(city=cls.c3, name='The Unknown Restaurant')\n        cls.w1 = Worker.objects.create(work_at=cls.r1, name='Mario', surname='Rossi')\n        cls.w2 = Worker.objects.create(work_at=cls.r1, name='Antonio', surname='Bianchi')\n        cls.w3 = Worker.objects.create(work_at=cls.r1, name='John', surname='Doe')\n"], "sample_744": ["def test_power_transformer_axis1():\n    # Test that PowerTransformer can transform along axis=1\n    X = np.abs(X_2d)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method='box-cox', standardize=standardize)\n\n        X_trans_class = pt.fit_transform(X.T).T\n        X_trans_func = power_transform(X.T, standardize=standardize).T\n\n        for X_trans in [X_trans_class, X_trans_func]:\n            for i in range(X_trans.shape[1]):\n                X_expected, lmbda = stats.boxcox(X[:, i].flatten())\n\n                if standardize:\n                    X_expected = scale(X_expected)\n\n                assert_almost_equal(X_trans[:, i], X_expected)\n                assert_almost_equal(lmbda, pt.lambdas_[i])\n\n            # Test inverse transformation\n            X_inv = pt.inverse_transform(X_trans)\n            assert_array_almost_equal(X_inv, X)\n\n        assert len(pt.lambdas_) == X.shape[1]\n        assert isinstance(pt.lambdas_, np.ndarray)\n"], "sample_908": ["def test_unparse_arguments():\n    source = \"def func(a, b, c, *, d, e, f, *, g, h, i, *, j, k, *, l, m, n, *, o, p, q, *, r, s, t, *, u, v, w, *, x, y, z): pass\"\n    expected = \"a, b, c, *, d, e, f, *, g, h, i, *, j, k, *, l, m, n, *, o, p, q, *, r, s, t, *, u, v, w, *, x, y, z\"\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].args) == expected\n"], "sample_1060": ["def test_SciPyPrinter_print_SparseMatrix():\n    p = SciPyPrinter()\n    smat = SparseMatrix(2, 5, {(0, 1): 3})\n    assert p.doprint(smat) == 'scipy.sparse.coo_matrix([3], ([0], [1]), shape=(2, 5))'\n    assert 'scipy.sparse' in p.module_imports\n"], "sample_693": ["def test_teardown_class_failure_is_shown(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n        class MyTestCase(unittest.TestCase):\n                assert 0, \"down1\"\n            @classmethod\n                assert 0, \"down2\"\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-s\")\n    assert result.ret == 1\n    result.stdout.fnmatch_lines([\"*tearDownClass*\", \"*assert 0*down2*\", \"*1 failed*\"])\n    result.stdout.no_fnmatch_line(\"*down1*\")\n"], "sample_488": ["    def test_lazy_model_operation(self):\n        \"\"\"\n        Tests apps.lazy_model_operation().\n        \"\"\"\n        model_classes = []\n        initial_pending = set(apps._pending_operations)\n\n            model_classes[:] = models\n\n        class LazyA(models.Model):\n            pass\n\n        # Test models appearing twice, and models appearing consecutively\n        model_keys = [\n            (\"apps\", model_name)\n            for model_name in [\"lazya\", \"lazyb\", \"lazyb\", \"lazyc\", \"lazya\"]\n        ]\n        apps.lazy_model_operation(test_func, *model_keys)\n\n        # LazyModelA shouldn't be waited on since it's already registered,\n        # and LazyModelC shouldn't be waited on until LazyModelB exists.\n        self.assertEqual(\n            set(apps._pending_operations) - initial_pending, {(\"apps\", \"lazyb\")}\n        )\n\n        # Multiple operations can wait on the same model\n        apps.lazy_model_operation(test_func, (\"apps\", \"lazyb\"))\n\n        class LazyB(models.Model):\n            pass\n\n        self.assertEqual(model_classes, [LazyB])\n\n        # Now we are just waiting on LazyModelC.\n        self.assertEqual(\n            set(apps._pending_operations) - initial_pending, {(\"apps\", \"lazyc\")}\n        )\n\n        class LazyC(models.Model):\n            pass\n\n        # Everything should be loaded - make sure the callback was executed properly.\n        self.assertEqual(model_classes, [LazyA, LazyB, LazyB, LazyC, LazyA])\n\n        # Test that lazy_model_operation raises an exception if the model is not found\n        with self.assertRaises(LookupError):\n            apps.lazy_model_operation(test_func, (\"apps\", \"non_existent_model\"))\n"], "sample_572": ["    def test_pi_errorbars_with_weights(self, long_df):\n\n        agg = EstimateAggregator(\"mean\", \"pi\")\n        out = agg(long_df, \"y\", weights=long_df[\"x\"])\n        assert out[\"ymin\"] == np.percentile(long_df[\"y\"], 2.5, weights=long_df[\"x\"])\n        assert out[\"ymax\"] == np.percentile(long_df[\"y\"], 97.5, weights=long_df[\"x\"])\n\n        agg = EstimateAggregator(\"mean\", (\"pi\", 50))\n        out = agg(long_df, \"y\", weights=long_df[\"x\"])\n        assert out[\"ymin\"] == np.percentile(long_df[\"y\"], 25, weights=long_df[\"x\"])\n        assert out[\"ymax\"] == np.percentile(long_df[\"y\"], 75, weights=long_df[\"x\"])\n"], "sample_416": ["def test_default_database(self):\n    \"\"\"Test default database connection.\"\"\"\n    self.assertEqual(\n        self.settings_to_cmd_args_env({\"NAME\": \"\"}),\n        ([\"psql\"], None),\n    )\n\n    self.assertEqual(\n        self.settings_to_cmd_args_env({\"NAME\": None}),\n        ([\"psql\"], None),\n    )\n\n    self.assertEqual(\n        self.settings_to_cmd_args_env({\"OPTIONS\": {\"service\": \"django_test\"}, \"NAME\": \"\"}),\n        ([\"psql\"], {\"PGSERVICE\": \"django_test\"}),\n    )\n\n    self.assertEqual(\n        self.settings_to_cmd_args_env({\"OPTIONS\": {\"service\": \"django_test\"}, \"NAME\": None}),\n        ([\"psql\"], {\"PGSERVICE\": \"django_test\"}),\n    )\n"], "sample_1114": ["def test_ImageSet_iterable():\n    from sympy.abc import n\n    from sympy import Rational\n    assert imageset(n, n + 1, S.Naturals) == Range(1, oo, 1)\n    assert imageset(n, n + 1, S.Naturals0) == Range(0, oo, 1)\n    assert imageset(n, n + 1, S.Integers) == Range(-oo, oo, 1)\n    assert imageset(n, n + Rational(1, 2), S.Naturals) == Range(1, oo, 1)\n    assert imageset(n, n + Rational(1, 2), S.Naturals0) == Range(0, oo, 1)\n    assert imageset(n, n + Rational(1, 2), S.Integers) == Range(-oo, oo, 1)\n    assert imageset(n, n + 1, S.Naturals).is_iterable\n    assert imageset(n, n + 1, S.Naturals0).is_iterable\n    assert imageset(n, n + 1, S.Integers).is_iterable\n    assert imageset(n, n + Rational(1, 2), S.Naturals).is_iterable\n    assert imageset(n, n + Rational(1, 2), S.Naturals0).is_iterable\n    assert imageset(n, n + Rational(1, 2), S.Integers).is_iterable\n"], "sample_5": ["def test_models_repr(model):\n    if not HAS_SCIPY and model['class'] in SCIPY_MODELS:\n        pytest.skip()\n\n    m = model['class'](**model['parameters'])\n    assert_quantity_allclose(m.__repr__(), param_repr_oneline(m))\n"], "sample_1029": ["def test_MonogenicFiniteExtension():\n    assert srepr(FiniteExtension(Poly(x**2 + 1, x, domain='ZZ'))) == \\\n        \"FiniteExtension(Poly(x**2 + 1, x, domain='ZZ'))\"\n    assert srepr(FiniteExtension(Poly(x**2 + 1, x, domain='QQ'))) == \\\n        \"FiniteExtension(Poly(x**2 + 1, x, domain='QQ'))\"\n"], "sample_738": ["def test_hashingvectorizer_dtype():\n    # Non-regression test: HashingVectorizer used to ignore its \"dtype\" param.\n    v = HashingVectorizer(dtype=np.float32)\n    assert_equal(v.dtype, np.float32)\n\n    X = v.fit_transform(['hello world', 'hello hello']).toarray()\n    assert_equal(X.dtype, np.float32)\n    X2 = v.transform(['hello world', 'hello hello']).toarray()\n    assert_equal(X2.dtype, np.float32)\n"], "sample_272": ["def test_migrate_with_multiple_targets(self):\n    \"\"\"\n    Test migrating to multiple targets.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Were the tables there before?\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_book\")\n    # Alright, let's try running it\n    executor.migrate([(\"migrations\", \"0002_second\"), (\"migrations\", \"0001_initial\")])\n    # Are the tables there now?\n    self.assertTableExists(\"migrations_author\")\n    self.assertTableExists(\"migrations_book\")\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Alright, let's undo what we did\n    executor.migrate([(\"migrations\", None), (\"migrations\", None)])\n    # Are the tables gone?\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_book\")\n"], "sample_234": ["def test_difference_with_distinct(self):\n    qs1 = Number.objects.filter(num__lt=10).distinct()\n    qs2 = Number.objects.filter(num__lt=9).distinct()\n    self.assertNumbersEqual(qs1.difference(qs2), [9], ordered=False)\n"], "sample_312": ["def test_add_squash(self):\n    # start with the same children of node1 then add an item that can be squashed\n    node3 = Node(self.node1_children)\n    node3_added_child = Node([('d', 4)])\n    # add() returns the added data\n    self.assertEqual(node3.add(node3_added_child, Node.default, squash=True),\n                     node3)\n    # we added exactly one item, len() should reflect that\n    self.assertEqual(len(self.node1) + 1, len(node3))\n    self.assertEqual(str(node3), \"(DEFAULT: ('a', 1), ('b', 2), (DEFAULT: ('d', 4)))\")\n"], "sample_584": ["    def test_auto_combine_with_coords_and_concat_dim(self):\n        objs = [Dataset({'x': [0]}), Dataset({'x': [1]})]\n        with pytest.warns(FutureWarning, match=\"supplied have global\"):\n            auto_combine(objs, concat_dim='x')\n"], "sample_1138": ["def test_TR22():\n    assert TR22(1 + tan(x)**2) == sec(x)**2\n    assert TR22(1 + cot(x)**2) == csc(x)**2\n    assert TR22(tan(x)**2) == sec(x)**2 - 1\n    assert TR22(cot(x)**2) == csc(x)**2 - 1\n    assert TR22(1 + tan(x)**3) == sec(x)**3\n    assert TR22(1 + cot(x)**3) == csc(x)**3\n    assert TR22(tan(x)**3) == sec(x)**3 - 3*sec(x)\n    assert TR22(cot(x)**3) == csc(x)**3 - 3*csc(x)\n    assert TR22(tan(x)**4) == sec(x)**4 - 4*sec(x)**2 + 3\n    assert TR22(cot(x)**4) == csc(x)**4 - 4*csc(x)**2 + 3\n"], "sample_329": ["    def test_serialize_deconstructable_class(self):\n        \"\"\"\n        Test serialization of a deconstructable class.\n        \"\"\"\n        class DeconstructableClass:\n                return ('DeconstructableClass', [], {})\n\n        self.assertSerializedResultEqual(\n            DeconstructableClass(),\n            (\"migrations.test_writer.DeconstructableClass\", {'import migrations.test_writer'})\n        )\n"], "sample_1170": ["def test_Dict_printing():\n    d = Dict({1: 1 + x, 2: y*x})\n    assert str(d) == \"{1: x + 1, 2: x*y}\"\n    assert sstr(d) == \"{1: x + 1, 2: x*y}\"\n"], "sample_18": ["    def setup_class(self):\n        self.q = u.Quantity(np.arange(1.0, 5.0), \"m/s\")\n        self.q.info.name = \"v\"\n        self.q.info.description = \"air speed of a african swallow\"\n"], "sample_184": ["    def test_index_with_condition_and_include(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                indexes = [\n                    models.Index(\n                        fields=['age'],\n                        name='index_age_gte_10',\n                        condition=models.Q(age__gte=10),\n                        include=['id'],\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_partial_indexes else [\n            Warning(\n                '%s does not support indexes with conditions.' % connection.display_name,\n                hint=(\n                    \"Conditions will be ignored. Silence this warning if you \"\n                    \"don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W037',\n            )\n        ]\n        expected += [] if connection.features.supports_covering_indexes else [\n            Warning(\n                '%s does not support indexes with non-key columns.' % connection.display_name,\n                hint=(\n                    \"Non-key columns will be ignored. Silence this warning if \"\n                    \"you don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W040',\n            ),\n        ]\n        self.assertEqual(errors, expected)\n"], "sample_39": ["def test_sub():\n    \"\"\"\n    Test sub method\n    \"\"\"\n    header = get_pkg_data_contents('data/sip.fits', encoding='binary')\n    w = wcs.WCS(header)\n    w2 = w.sub([1])\n    assert w2.naxis == 1\n    assert w2.wcs.naxis == 1\n    assert w2.wcs.ctype[0] == w.wcs.ctype[1]\n    assert w2.wcs.crval[0] == w.wcs.crval[1]\n    assert w2.wcs.crpix[0] == w.wcs.crpix[1]\n    assert w2.wcs.cdelt[0] == w.wcs.cdelt[1]\n    assert w2.wcs.pc[0][0] == w.wcs.pc[1][0]\n    assert w2.wcs.pc[0][1] == w.wcs.pc[1][1]\n\n    w3 = w.sub([1, 2])\n    assert w3.naxis == 0\n    assert w3.wcs.naxis == 0\n\n    w4 = w.sub([0, 1])\n    assert w4.naxis == 2\n    assert w4.wcs.naxis == 2\n    assert w4.wcs.ctype[0] == w.wcs.ctype[0]\n    assert w4.wcs.crval[0] == w.wcs.crval[0]\n    assert w4.wcs.crpix[0] == w.wcs.crpix[0]\n    assert w4.wcs.cdelt[0] == w.wcs.cdelt[0]\n    assert w4.wcs.pc[0][0] == w.wcs.pc[0][0]\n    assert w4.wcs.pc[0][1] == w.wcs.pc[0][1]\n\n    w5 = w.sub([0, 1, 2])\n    assert w5.naxis == 0\n    assert w5.wcs.naxis == 0\n\n    w6 = w.sub([0, 1, 3])\n    assert w6.naxis == 2\n    assert w6.wcs.naxis == 2\n    assert w6.wcs.ctype[0] == w.wcs.ctype[0]\n    assert w6.wcs.crval[0] == w.wcs.crval[0]\n    assert w6.wcs"], "sample_45": ["def test_trunc_func_with_timezone_priority(self):\n    start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n    end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n    if settings.USE_TZ:\n        start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n        end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n    self.create_model(end_datetime, start_datetime)\n\n    melb = pytz.timezone('Australia/Melbourne')\n    pacific = pytz.timezone('US/Pacific')\n\n    model = DTModel.objects.annotate(\n        melb_year=TruncYear('start_datetime', tzinfo=melb),\n        pacific_year=TruncYear('start_datetime', output_field=DateTimeField(), tzinfo=pacific),\n    ).order_by('start_datetime').get()\n\n    self.assertEqual(model.start_datetime, start_datetime)\n    self.assertEqual(model.melb_year, truncate_to(start_datetime, 'year', melb))\n    self.assertEqual(model.pacific_year, truncate_to(start_datetime, 'year', pacific))\n    self.assertEqual(model.start_datetime.year, 2015)\n    self.assertEqual(model.melb_year.year, 2015)\n    self.assertEqual(model.pacific_year.year, 2015)\n"], "sample_686": ["def test_pytest_collect_module_deprecated_attribute_name(testdir: Testdir) -> None:\n    \"\"\"Check that pytest.collect.{name} was moved to pytest.{name}\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    with pytest.warns(pytest.PytestDeprecationWarning, match=\"pytest.collect.{name} was moved to pytest.{name}\"):\n        pytest.collect.module\n    with pytest.warns(pytest.PytestDeprecationWarning, match=\"pytest.collect.{name} was moved to pytest.{name}\"):\n        pytest.collect.module.__name__\n"], "sample_391": ["def test_create_model_add_constraint(self):\n    \"\"\"\n    AddConstraint should optimize into CreateModel.\n    \"\"\"\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                \"Foo\", [(\"name\", models.CharField(max_length=255))]\n            ),\n            migrations.AddConstraint(\"Foo\", models.CheckConstraint(check=models.Q(name=\"test\"))),\n        ],\n        [\n            migrations.CreateModel(\n                \"Foo\",\n                [(\"name\", models.CharField(max_length=255))],\n                options={\"constraints\": [models.CheckConstraint(check=models.Q(name=\"test\"))]},\n            ),\n        ],\n    )\n"], "sample_688": ["    def test_resolve_package_path(self, testdir):\n        \"\"\"Verify resolve_package_path() returns the correct package path.\"\"\"\n        tmpdir = testdir.tmpdir\n        subdir = tmpdir.join(\"subdir\")\n        subdir.ensure(\"__init__.py\")\n        x = subdir.ensure(\"x.py\")\n        with subdir.as_cwd():\n            config = testdir.parseconfigure(x)\n        col = testdir.getnode(config, x)\n        assert isinstance(col, pytest.Module)\n        assert isinstance(col.parent, pytest.Package)\n        assert isinstance(col.parent.parent, pytest.Session)\n        # session is batman (has no parents)\n        assert col.parent.parent.parent is None\n        package_path = resolve_package_path(col.fspath)\n        assert package_path == subdir\n        # Test that resolve_package_path() returns None when the path is not a package.\n        assert resolve_package_path(testdir.tmpdir.join(\"test_file.py\")) is None\n"], "sample_888": ["def test_iforest_offset():\n    \"\"\"Test that the offset is correctly computed when contamination is not 'auto'.\"\"\"\n    X_train = [[1, 1], [1, 2], [2, 1]]\n    clf = IsolationForest(contamination=0.1).fit(X_train)\n    assert clf.offset_ == np.percentile(clf._score_samples(X_train), 10.0)\n"], "sample_1148": ["def test_matrixsymbol_transpose():\n    A = MatrixSymbol('A', 2, 2)\n    assert A.T == Transpose(A)\n    assert A.T.shape == A.shape\n    assert (A.T).T == A\n    assert (A.T).T.T == A\n    assert (A.T).T.T.T == A\n    assert (A.T).T.T.T.T == A\n    assert (A.T).T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T"], "sample_802": ["def test_pipeline_fit_transform_with_intermediate_fit_params_and_transform():\n    # tests that Pipeline passes fit_params to intermediate steps\n    # when fit_transform is invoked\n    pipe = Pipeline([('transf', TransfFitParams()), ('clf', FitParamT())])\n    pipe.fit_transform(X=None,\n                      y=None,\n                      transf__should_get_this=True,\n                      clf__should_succeed=True)\n    assert pipe.named_steps['transf'].fit_params['should_get_this']\n    assert pipe.named_steps['clf'].successful\n    assert 'should_succeed' not in pipe.named_steps['transf'].fit_params\n"], "sample_1089": ["def test_issue_17256():\n    from sympy import Symbol, Range, Sum\n    x = Symbol('x')\n    s1 = Sum(x + 1, (x, 1, 9))\n    s2 = Sum(x + 1, (x, Range(1, 10)))\n    a = Symbol('a')\n    r1 = s1.xreplace({x:a})\n    r2 = s2.xreplace({x:a})\n\n    r1.doit() == r2.doit()\n    s1 = Sum(x + 1, (x, 0, 9))\n    s2 = Sum(x + 1, (x, Range(10)))\n    a = Symbol('a')\n    r1 = s1.xreplace({x:a})\n    r2 = s2.xreplace({x:a})\n    assert r1 == r2\n"], "sample_647": ["def test_unformatted_warning_formatting() -> None:\n    \"\"\"Test that UnformattedWarning formats correctly.\"\"\"\n    warning = warning_types.UnformattedWarning(\n        category=warning_types.PytestWarning, template=\"This is a warning: {message}\"\n    )\n    formatted_warning = warning.format(message=\"some message\")\n    assert isinstance(formatted_warning, warning_types.PytestWarning)\n    assert str(formatted_warning) == \"PytestWarning: This is a warning: some message\"\n"], "sample_359": ["def test_alter_field_with_db_column_and_index(self):\n    \"\"\"\n    AlterField operation with an index to ensure indexes created via Meta.indexes don't get dropped with sqlite3 remake.\n    \"\"\"\n    project_state = self.set_up_test_model(\"test_alflin\", index=True)\n    operation = migrations.AlterField(\"Pony\", \"pink\", models.IntegerField(null=True))\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_alflin\", new_state)\n    # Test the database alteration\n    self.assertColumnNotNull(\"test_alflin_pony\", \"pink\")\n    with connection.schema_editor() as editor:\n        operation.database_forwards(\"test_alflin\", editor, project_state, new_state)\n    # Index hasn't been dropped\n    self.assertIndexExists(\"test_alflin_pony\", [\"pink\"])\n    # And test reversal\n    with connection.schema_editor() as editor:\n        operation.database_backwards(\"test_alflin\", editor, new_state, project_state)\n    # Ensure the index is still there\n    self.assertIndexExists(\"test_alflin_pony\", [\"pink\"])\n"], "sample_14": ["def test_angle_pickle():\n    \"\"\"\n    Ensure that after pickling we can still do operations on hourangle.\n    \"\"\"\n    angle = Angle(0.25 * u.hourangle)\n    expected = angle + 0.5 * u.hourangle\n    via_pickle = pickle.loads(pickle.dumps(angle))\n    via_pickle_copy = via_pickle.copy()\n    via_pickle_copy += 0.5 * u.hourangle\n    assert_allclose(via_pickle_copy.value, expected.value)\n"], "sample_465": ["    def setUpTestData(cls):\n        cls.band = Band.objects.create(\n            name=\"The Doors\",\n            bio=\"\",\n            sign_date=date(1965, 1, 1),\n        )\n"], "sample_273": ["    def test_collision_in_same_model(self):\n        class Model(models.Model):\n            class Meta:\n                unique_together = [('id', 'name')]\n\n            id = models.AutoField(primary_key=True)\n            name = models.CharField(max_length=20)\n\n            class Meta:\n                unique_together = [('id', 'name')]\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"unique_together 'id, name' is not unique for model \"\n                \"check_framework.Model.\",\n                id='models.E010',\n            ),\n        ])\n"], "sample_1050": ["def test_SciPyPrinter_print_SparseMatrix():\n    p = SciPyPrinter()\n    smat = SparseMatrix(2, 5, {(0, 1): 3})\n    assert p.doprint(smat) == 'scipy.sparse.coo_matrix([3], ([0], [1]), shape=(2, 5))'\n    assert 'scipy.sparse' in p.module_imports\n"], "sample_793": ["def test_iforest_max_features():\n    \"\"\"Check Isolation Forest for various max_features settings.\"\"\"\n    X_train = np.array([[0, 1], [1, 2]])\n    X_test = np.array([[2, 1], [1, 1]])\n\n    grid = ParameterGrid({\"max_features\": [1.0, 2.0, 3.0]})\n\n    with ignore_warnings():\n        for params in grid:\n            IsolationForest(random_state=rng, **params).fit(X_train).predict(X_test)\n"], "sample_52": ["def test_choices_with_limit_choices_to(self):\n    class ModelChoiceForm(forms.Form):\n        category = forms.ModelChoiceField(Category.objects.all(), limit_choices_to={'name__startswith': 'A'})\n\n    self.assertEqual(list(ModelChoiceForm().fields['category'].choices), [\n        ('', '---------'),\n        (self.c2.pk, 'A test'),\n    ])\n    self.assertEqual(ModelChoiceForm({'category': self.c2.pk}).is_valid(), True)\n    self.assertEqual(ModelChoiceForm({'category': self.c3.pk}).is_valid(), False)\n\n    class ModelChoiceFormWithCallableLimitChoicesTo(forms.Form):\n        category = forms.ModelChoiceField(Category.objects.all(), limit_choices_to=lambda: {'name__startswith': 'A'})\n\n    self.assertEqual(list(ModelChoiceFormWithCallableLimitChoicesTo().fields['category'].choices), [\n        ('', '---------'),\n        (self.c2.pk, 'A test'),\n    ])\n    self.assertEqual(ModelChoiceFormWithCallableLimitChoicesTo({'category': self.c2.pk}).is_valid(), True)\n    self.assertEqual(ModelChoiceFormWithCallableLimitChoicesTo({'category': self.c3.pk}).is_valid(), False)\n"], "sample_726": ["def test_label_binarizer_sparse_output_binary():\n    # Test sparse output for binary case\n    lb = LabelBinarizer(sparse_output=True)\n    inp = [\"neg\", \"pos\", \"pos\", \"neg\"]\n    expected = csr_matrix([[0, 1, 1, 0]])\n    got = lb.fit_transform(inp)\n    assert_array_equal(got.toarray(), expected.toarray())\n    assert_array_equal(lb.inverse_transform(got.toarray()), inp)\n\n    # Test sparse output for binary case with pos_label=0\n    lb = LabelBinarizer(neg_label=-2, pos_label=0, sparse_output=True)\n    inp = np.array([0, 1, 1, 0])\n    expected = csr_matrix([[-2, 0, 0, -2]])\n    got = lb.fit_transform(inp)\n    assert_array_equal(got.toarray(), expected.toarray())\n    assert_array_equal(lb.inverse_transform(got.toarray()), inp)\n\n    # Test sparse output for binary case with neg_label=0\n    lb = LabelBinarizer(neg_label=0, pos_label=2, sparse_output=True)\n    inp = np.array([3, 2, 1, 2, 0])\n    expected = csr_matrix([[-2, -2, -2, +2],\n                          [-2, -2, +2, -2],\n                          [-2, +2, -2, -2],\n                          [-2, -2, +2, -2],\n                          [+2, -2, -2, -2]])\n    got = lb.fit_transform(inp)\n    assert_array_equal(got.toarray(), expected.toarray())\n    assert_array_equal(lb.inverse_transform(got.toarray()), inp)\n"], "sample_1028": ["def test_Mod_is_zero():\n    x, y = symbols('x y', zero=True)\n    assert (x % y).is_zero\n    assert (y % x).is_zero\n    assert (x % x).is_zero\n    assert (y % y).is_zero\n    assert (x % 0).is_zero\n    assert (0 % x).is_zero\n    assert (0 % y).is_zero\n    assert (0 % 0).is_zero\n"], "sample_441": ["    def test_render_with_invalid_password(self):\n        # Rendering the widget with an invalid password\n        # mustn't raise an exception.\n        widget = ReadOnlyPasswordHashWidget()\n        value = \"invalid_password\"\n        self.assertHTMLEqual(\n            widget.render(\"name\", value, {\"id\": \"id_password\"}),\n            '<div id=\"id_password\">'\n            \"    <strong>No password set.</strong>\"\n            \"</div>\",\n        )\n"], "sample_521": ["def test_surface3d_masked_strides():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n\n    x, y = np.mgrid[-6:6.1:1, -6:6.1:1]\n    z = np.ma.masked_less(x * y, 2)\n\n    ax.plot_surface(x, y, z, rstride=4, cstride=4)\n    ax.view_init(60, -45, 0)\n\n"], "sample_490": ["    def test_deconstruction_with_expressions_and_fields(self):\n        fields = [\"foo\", \"bar\"]\n        name = \"unique_fields\"\n        constraint = models.UniqueConstraint(fields=fields, name=name, expressions=[F(\"baz\")])\n        path, args, kwargs = constraint.deconstruct()\n        self.assertEqual(path, \"django.db.models.UniqueConstraint\")\n        self.assertEqual(args, (F(\"baz\"),))\n        self.assertEqual(kwargs, {\"fields\": tuple(fields), \"name\": name})\n"], "sample_141": ["    def _validate_output(serial_str):\n        try:\n            json.loads(serial_str)\n        except Exception:\n            return False\n        else:\n            return True\n"], "sample_626": ["    def test_init(self) -> None:\n        indexer = BasicIndexer((1, 2, 3))\n        assert indexer.tuple == (1, 2, 3)\n"], "sample_204": ["def test_loading_squashed_ref_squashed_multiple_replacements(self):\n    \"\"\"\n    Tests loading a squashed migration with multiple replacements.\n    \"\"\"\n    r\"\"\"\n    The sample migrations are structured like this:\n\n    app_1       1 --> 2 ---------------------*--> 3        *--> 4\n                     \\                          /             /\n                      *-------------------*----/--> 2_sq_3 --*\n                       \\                 /    /\n        =============== \\ ============= / == / ======================\n        app_2            *--> 1_sq_2 --*    /\n                          \\                /\n                           *--> 1 --> 2 --*\n                           \\        /\n                            *--> 5 --> 6 --*\n\n    Where 2_sq_3 is a replacing migration for 2 and 3 in app_1,\n    as 1_sq_2 is a replacing migration for 1 and 2 in app_2.\n    And 5_sq_6 is a replacing migration for 5 and 6 in app_2.\n    \"\"\"\n\n    loader = MigrationLoader(connection)\n    recorder = MigrationRecorder(connection)\n    self.addCleanup(recorder.flush)\n\n    # Load with nothing applied: both migrations squashed.\n    loader.build_graph()\n    plan = set(loader.graph.forwards_plan(('app1', '4_auto')))\n    plan = plan - loader.applied_migrations.keys()\n    expected_plan = {\n        ('app1', '1_auto'),\n        ('app2', '1_squashed_2'),\n        ('app1', '2_squashed_3'),\n        ('app1', '4_auto'),\n        ('app2', '5_squashed_6'),\n    }\n    self.assertEqual(plan, expected_plan)\n\n    # Fake-apply a few from app1: unsquashes migration in app1.\n    recorder.record_applied('app1', '1_auto')\n    recorder.record_applied('app1', '2_auto')\n    loader.build_graph()\n    plan = set(loader.graph.forwards"], "sample_984": ["def test_MatPow():\n    from sympy import MatrixSymbol\n    M = MatrixSymbol('M', 2, 2)\n    assert str(M**2) == \"M**2\"\n    assert str(M**-1) == \"M**(-1)\"\n    assert str(M**2 + M**-1) == \"M**2 + M**(-1)\"\n"], "sample_422": ["    def test_m2m_prefetch_limit(self):\n        authors = Author.objects.all()[:2]\n        with self.assertNumQueries(3):\n            books = list(\n                Book.objects.prefetch_related(\n                    Prefetch(\"authors\", authors),\n                    Prefetch(\"authors\", authors[1:], to_attr=\"authors_sliced\"),\n                )\n            )\n        for book in books:\n            with self.subTest(book=book):\n                self.assertEqual(book.authors_sliced, list(book.authors.all())[1:])\n"], "sample_1100": ["def test_Pow_is_zero_2():\n    z = Symbol('z', zero=True)\n    e = z**2\n    assert e.is_zero\n    assert e.is_positive is False\n    assert e.is_negative is False\n\n    assert Pow(0, 0, evaluate=False).is_zero is False\n    assert Pow(0, 3, evaluate=False).is_zero\n    assert Pow(0, oo, evaluate=False).is_zero\n    assert Pow(0, -3, evaluate=False).is_zero is False\n    assert Pow(0, -oo, evaluate=False).is_zero is False\n    assert Pow(2, 2, evaluate=False).is_zero is False\n\n    a = Symbol('a', zero=False)\n    assert Pow(a, 3).is_zero is False  # issue 7965\n\n    assert Pow(2, oo, evaluate=False).is_zero is False\n    assert Pow(2, -oo, evaluate=False).is_zero\n    assert Pow(S.Half, oo, evaluate=False).is_zero\n    assert Pow(S.Half, -oo, evaluate=False).is_zero is False\n"], "sample_226": ["    def test_serialize_db_to_string(self):\n        # serialize_db_to_string() handles large amounts of data.\n        obj_1 = Object.objects.create()\n        obj_2 = Object.objects.create()\n        obj_3 = Object.objects.create()\n        obj_4 = Object.objects.create()\n        obj_5 = Object.objects.create()\n        obj_6 = Object.objects.create()\n        obj_7 = Object.objects.create()\n        obj_8 = Object.objects.create()\n        obj_9 = Object.objects.create()\n        obj_10 = Object.objects.create()\n        obj_11 = Object.objects.create()\n        obj_12 = Object.objects.create()\n        obj_13 = Object.objects.create()\n        obj_14 = Object.objects.create()\n        obj_15 = Object.objects.create()\n        obj_16 = Object.objects.create()\n        obj_17 = Object.objects.create()\n        obj_18 = Object.objects.create()\n        obj_19 = Object.objects.create()\n        obj_20 = Object.objects.create()\n        obj_21 = Object.objects.create()\n        obj_22 = Object.objects.create()\n        obj_23 = Object.objects.create()\n        obj_24 = Object.objects.create()\n        obj_25 = Object.objects.create()\n        obj_26 = Object.objects.create()\n        obj_27 = Object.objects.create()\n        obj_28 = Object.objects.create()\n        obj_29 = Object.objects.create()\n        obj_30 = Object.objects.create()\n        obj_31 = Object.objects.create()\n        obj_32 = Object.objects.create()\n        obj_33 = Object.objects.create()\n        obj_34 = Object.objects.create()\n        obj_35 = Object.objects.create()\n        obj_36 = Object.objects.create()\n        obj_37 = Object.objects.create()\n        obj_38 = Object.objects.create()\n        obj_39 = Object.objects.create()\n        obj_40 = Object.objects.create()\n        obj_41 = Object.objects.create()\n        obj_42 = Object.objects.create()\n        obj_43 = Object.objects.create()\n        obj_44 = Object.objects.create()\n        obj_45 = Object.objects.create()\n        obj_46 = Object.objects.create()\n        obj_47 = Object.objects.create()\n        obj_48 = Object.objects.create()\n        obj_49 = Object.objects.create()\n        obj_50 = Object.objects.create()\n        obj_51 = Object.objects.create()\n        obj_52 = Object.objects.create()\n        obj_"], "sample_727": ["def test_imputation_copy_sparse_csc_axis_0():\n    # Test imputation with copy, sparse csc, axis=0\n    X_orig = sparse_random_matrix(5, 5, density=0.75, random_state=0)\n\n    # copy=True\n    X = X_orig.copy().tocsc()\n    imputer = Imputer(missing_values=X.data[0], strategy=\"mean\", copy=True)\n    Xt = imputer.fit(X).transform(X)\n    Xt.data[0] = -1\n    assert_false(np.all(X.data == Xt.data))\n\n    # copy=False\n    X = X_orig.copy().tocsc()\n    imputer = Imputer(missing_values=X.data[0], strategy=\"mean\", copy=False)\n    Xt = imputer.fit(X).transform(X)\n    Xt.data[0] = -1\n    assert_array_almost_equal(X.data, Xt.data)\n"], "sample_855": ["def test_constant_strategy_regressor_multioutput():\n    random_state = np.random.RandomState(seed=1)\n\n    X_learn = random_state.randn(10, 10)\n    y_learn = random_state.randn(10, 5)\n\n    # test with 2d array\n    constants = random_state.randn(5)\n\n    X_test = random_state.randn(20, 10)\n    y_test = random_state.randn(20, 5)\n\n    # Correctness oracle\n    est = DummyRegressor(strategy=\"constant\", constant=constants)\n    est.fit(X_learn, y_learn)\n    y_pred_learn = est.predict(X_learn)\n    y_pred_test = est.predict(X_test)\n\n    _check_equality_regressor(\n        constants, y_learn, y_pred_learn, y_test, y_pred_test)\n    _check_behavior_2d_for_constant(est)\n\n    # test with 1d array\n    constants = random_state.randn(1)\n    est = DummyRegressor(strategy=\"constant\", constant=constants)\n    est.fit(X_learn, y_learn[:, 0])\n    y_pred_learn = est.predict(X_learn)\n    y_pred_test = est.predict(X_test)\n\n    _check_equality_regressor(\n        constants, y_learn[:, 0], y_pred_learn, y_test[:, 0], y_pred_test)\n    _check_behavior_2d_for_constant(est)\n"], "sample_953": ["def test_quickstart_makefile_and_batchfile(tempdir):\n    answers = {\n        'Root path': tempdir,\n        'Project name': 'Sphinx Test',\n        'Author name': 'Georg Brandl',\n        'Project version': '0.1',\n        'Create Makefile': 'y',\n        'Create Windows command file': 'y',\n    }\n    qs.term_input = mock_input(answers)\n    d = {}\n    qs.ask_user(d)\n    qs.generate(d)\n\n    makefile = tempdir / 'Makefile'\n    assert makefile.isfile()\n    batchfile = tempdir / 'make.bat'\n    assert batchfile.isfile()\n\n    conffile = tempdir / 'conf.py'\n    assert conffile.isfile()\n    ns = {}\n    exec(conffile.read_text(), ns)\n    assert ns['extensions'] == []\n    assert ns['templates_path'] == ['_templates']\n    assert ns['project'] == 'Sphinx Test'\n    assert ns['copyright'] == '%s, Georg Brandl' % time.strftime('%Y')\n    assert ns['version'] == '0.1'\n    assert ns['release'] == '0.1'\n    assert ns['html_static_path'] == ['_static']\n\n    assert (tempdir / '_static').isdir()\n    assert (tempdir / '_templates').isdir()\n    assert (tempdir / 'index.rst').isfile()\n"], "sample_1062": ["def test_TR22():\n    assert TR22(1 + tan(x)**2) == sec(x)**2\n    assert TR22(1 + cot(x)**2) == csc(x)**2\n    assert TR22(1 + tan(x)**4) == sec(x)**4\n    assert TR22(1 + cot(x)**4) == csc(x)**4\n    assert TR22(1 + tan(x)**6) == sec(x)**6\n    assert TR22(1 + cot(x)**6) == csc(x)**6\n    assert TR22(1 + tan(x)**8) == sec(x)**8\n    assert TR22(1 + cot(x)**8) == csc(x)**8\n    assert TR22(1 + tan(x)**10) == sec(x)**10\n    assert TR22(1 + cot(x)**10) == csc(x)**10\n    assert TR22(1 + tan(x)**12) == sec(x)**12\n    assert TR22(1 + cot(x)**12) == csc(x)**12\n    assert TR22(1 + tan(x)**14) == sec(x)**14\n    assert TR22(1 + cot(x)**14) == csc(x)**14\n    assert TR22(1 + tan(x)**16) == sec(x)**16\n    assert TR22(1 + cot(x)**16) == csc(x)**16\n    assert TR22(1 + tan(x)**18) == sec(x)**18\n    assert TR22(1 + cot(x)**18) == csc(x)**18\n    assert TR22(1 + tan(x)**20) == sec(x)**20\n    assert TR22(1 + cot(x)**20) == csc(x)**20\n    assert TR22(1 + tan(x)**22) == sec(x)**22\n    assert TR22(1 + cot(x)**22) == csc(x)**22\n    assert TR22(1 + tan(x)**24) == sec(x)**24\n    assert TR22(1 + cot(x)**24) == csc(x)**24\n    assert TR22(1 + tan(x)**26) == sec(x)**26\n    assert TR22(1 + cot(x)**26) == csc(x)**26\n    assert TR22(1 + tan(x)**28) == sec(x)**28\n    assert TR22("], "sample_300": ["def test_filter_conditional_subquery(self):\n    query = Query(Item)\n    filter_expr = Q(note__note__gt=F('id'))\n    msg = 'Cannot filter against a non-conditional expression.'\n    with self.assertRaisesMessage(TypeError, msg):\n        query.build_where(filter_expr)\n"], "sample_1045": ["def test_issue_10368():\n    a = S(32442016954)/78058255275\n    assert type(int(a)) is type(int(-a)) is int\n    assert int(a) == 41\n    assert int(-a) == -41\n"], "sample_1071": ["def test_quantity_simplify_prefixes():\n    from sympy.physics.units.util import quantity_simple\n    from sympy.physics.units import kilo, mega, giga, foot, inch\n\n    assert quantity_simplify(kilo*foot*inch) == 250*foot**2/3\n    assert quantity_simplify(mega*foot*inch) == 250000*foot**2/3\n    assert quantity_simplify(giga*foot*inch) == 250000000*foot**2/3\n    assert quantity_simplify(foot - 6*inch) == foot/2\n    assert quantity_simplify(foot - 6*kilo*inch) == foot/2\n    assert quantity_simplify(foot - 6*mega*inch) == foot/2\n    assert quantity_simplify(foot - 6*giga*inch) == foot/2\n"], "sample_467": ["    def test_render_custom_years(self):\n        self.check_html(\n            self.widget,\n            \"mydate\",\n            \"\",\n            html=(\n                \"\"\"\n            <select name=\"mydate_month\" id=\"id_mydate_month\">\n                <option selected value=\"\">---</option>\n                <option value=\"1\">January</option>\n                <option value=\"2\">February</option>\n                <option value=\"3\">March</option>\n                <option value=\"4\">April</option>\n                <option value=\"5\">May</option>\n                <option value=\"6\">June</option>\n                <option value=\"7\">July</option>\n                <option value=\"8\">August</option>\n                <option value=\"9\">September</option>\n                <option value=\"10\">October</option>\n                <option value=\"11\">November</option>\n                <option value=\"12\">December</option>\n            </select>\n\n            <select name=\"mydate_day\" id=\"id_mydate_day\">\n                <option selected value=\"\">---</option>\n                <option value=\"1\">1</option>\n                <option value=\"2\">2</option>\n                <option value=\"3\">3</option>\n                <option value=\"4\">4</option>\n                <option value=\"5\">5</option>\n                <option value=\"6\">6</option>\n                <option value=\"7\">7</option>\n                <option value=\"8\">8</option>\n                <option value=\"9\">9</option>\n                <option value=\"10\">10</option>\n                <option value=\"11\">11</option>\n                <option value=\"12\">12</option>\n                <option value=\"13\">13</option>\n                <option value=\"14\">14</option>\n                <option value=\"15\">15</option>\n                <option value=\"16\">16</option>\n                <option value=\"17\">17</option>\n                <option value=\"18\">18</option>\n                <option value=\"19\">19</option>\n                <option value=\"20\">20</option>\n                <option value=\"21\">21</option>\n                <option value=\"22\">22</option>\n                <option value=\"23\">23</option>\n                <option value=\""], "sample_593": ["def test_repr_of_variable():\n    v = xr.Variable([\"time\", \"x\"], [[1, 2, 3], [4, 5, 6]], {\"foo\": \"bar\"})\n    formatted = fh.summarize_variable(\"foo\", v)\n    assert \"<div class='xr-var-name'><span class='xr-has-index'>foo</span></div>\" in formatted\n    assert \"<dt><span>foo :</span></dt>\" in formatted\n    assert \"<dd>bar</dd>\" in formatted\n    assert \"<div class='xr-var-dims'>(time, x)</div>\" in formatted\n    assert \"<div class='xr-var-dtype'>object</div>\" in formatted\n    assert \"<div class='xr-var-preview xr-preview'>\" in formatted\n    assert \"<div class='xr-var-attrs'>\" in formatted\n    assert \"<div class='xr-var-data'>\" in formatted\n"], "sample_712": ["def test_one_hot_encoder_sparse_output():\n    X = np.array([[3, 2, 1], [0, 1, 1]])\n    enc = OneHotEncoder(sparse=True)\n    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):\n        X_trans = enc.fit_transform(X)\n        assert sparse.isspmatrix_csr(X_trans)\n        assert_array_equal(X_trans.toarray(), [[0., 1., 0., 1., 1.],\n                                              [1., 0., 1., 0., 1.]])\n"], "sample_108": ["    def test_resolver404_with_tried(self):\n        url = '/articles/2003/'\n        with self.assertRaises(Resolver404) as cm:\n            resolve('/articles/2003/extra/')\n        self.assertEqual(cm.exception.args[0]['tried'], [path('articles/<str:year>/', lambda r: None)])\n"], "sample_531": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect((1, 2, 3))\n    ax2.set_box_aspect((2, 1, 1))\n"], "sample_928": ["def test_heading_with_empty_string():\n    env = Environment()\n    env.extend(language=None)\n\n    assert heading(env, '') == ''\n    assert heading(env, '', 1) == ''\n    assert heading(env, '', 2) == ''\n    assert heading(env, '', 3) == ''\n\n    # language=ja: ambiguous\n    env.language = 'ja'\n    assert heading(env, '', 1) == ''\n    assert heading(env, '', 2) == ''\n    assert heading(env, '', 3) == ''\n"], "sample_590": ["    def test_concat_fill_value_coord(self, data):\n        # GH438\n        ds1 = Dataset({\"y\": (\"t\", [1])}, {\"x\": 1, \"t\": [0]})\n        ds2 = Dataset({\"y\": (\"t\", [2])}, {\"x\": 1, \"t\": [0]})\n        expected = Dataset({\"y\": (\"t\", [1, 2]), \"x\": 1, \"t\": [0, 0]})\n        actual = concat([ds1, ds2], \"t\", fill_value=1)\n        assert_identical(expected, actual)\n\n        ds1 = Dataset({\"y\": (\"t\", [1])}, {\"x\": 1, \"t\": [0]})\n        ds2 = Dataset({\"y\": (\"t\", [2])}, {\"x\": 2, \"t\": [0]})\n        with pytest.raises(ValueError):\n            concat([ds1, ds2], \"t\", coords=\"minimal\", fill_value=1)\n"], "sample_550": ["def test_axis_method_wrapper():\n    class TestAxis(maxis.Axis):\n            super().__init__(*args, **kwargs)\n            self._axis_method_wrapper = _axis_method_wrapper(\n                \"xaxis\", \"get_bar\")\n\n            return \"bar\"\n\n    ax = TestAxis()\n    assert ax.get_foo() == \"bar\"\n    assert ax.get_foo.__doc__ == \"get_bar\"\n    assert ax.get_foo.__signature__ == inspect.signature(ax.get_bar)\n    assert ax.get_foo.__name__ == \"get_foo\"\n    assert ax.get_foo.__qualname__ == \"TestAxis.get_foo\"\n\n    with pytest.raises(ValueError):\n        class TestAxis(maxis.Axis):\n                super().__init__(*args, **kwargs)\n                self._axis_method_wrapper = _axis_method_wrapper(\n                    \"xaxis\", \"get_bar\")\n                self._axis_method_wrapper._missing_subs = [\"this Axis\"]\n\n                return \"bar\"\n\n        ax = TestAxis()\n        ax.get_foo()\n"], "sample_1151": ["def test_Mod_is_zero():\n    x, y = symbols('x y', zero=True)\n    assert (x % y).is_zero\n\n    # Issue 15873\n    e = -2*I + (1 + I)**2\n    assert (e % y).is_zero is None\n"], "sample_1099": ["def test_eval_partial_derivative_single_2nd_rank_tensors_by_2nd_rank_tensor():\n    tau, mu = symbols(\"tau mu\")\n\n    expr1 = PartialDerivative(H(i, j), H(k, m))\n    assert expr1._perform_derivative() - L.delta(i, -k) * L.delta(j, -m) == 0\n\n    expr2 = PartialDerivative(H(i, j), H(-k, m))\n    assert expr2._perform_derivative() - L.metric(i, L_0) * L.delta(-L_0, k) * L.delta(j, -m) == 0\n\n    expr3 = PartialDerivative(H(i, j), H(k, -m))\n    assert expr3._perform_derivative() - L.delta(i, -k) * L.metric(j, L_0) * L.delta(-L_0, m) == 0\n\n    expr4 = PartialDerivative(H(i, j), H(-k, -m))\n    assert expr4._perform_derivative() - L.metric(i, L_0) * L.delta(-L_0, k) * L.metric(j, L_1) * L.delta(-L_1, m) == 0\n\n    expr5 = PartialDerivative(H(i, j), H(k, i))\n    assert expr5._perform_derivative() - L.delta(j, -i) == 0\n\n    expr6 = PartialDerivative(H(i, j), H(k, -i))\n    assert expr6._perform_derivative() - L.metric(j, L_0) * L.delta(-L_0, k) == 0\n\n    expr7 = PartialDerivative(H(i, j), H(-k, i))\n    assert expr7._perform_derivative() - L.delta(j, -k) == 0\n\n    expr8 = PartialDerivative(H(i, j), H(-k, -i))\n    assert expr8._perform_derivative() - L.metric(j, L_0) * L.delta(-L_0, k) == 0\n"], "sample_863": ["def test_pipeline_fit_transform_with_intermediate_fit_params():\n    # tests that Pipeline passes fit_params to intermediate steps\n    # when fit_transform is invoked\n    pipe = Pipeline([('transf', TransfFitParams()), ('clf', FitParamT())])\n    pipe.fit_transform(X=None,\n                       y=None,\n                       transf__should_get_this=True,\n                       clf__should_succeed=True)\n    assert pipe.named_steps['transf'].fit_params['should_get_this']\n    assert pipe.named_steps['clf'].successful\n    assert 'should_succeed' not in pipe.named_steps['transf'].fit_params\n"], "sample_206": ["def test_fieldfile_pickle(self):\n    \"\"\"\n    FieldFile instances can be pickled and unpickled without losing their\n    state.\n    \"\"\"\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        with override_settings(MEDIA_ROOT=Path(tmp_dir)):\n            with open(__file__, 'rb') as fp:\n                file1 = File(fp, name='test_file.py')\n                document = Document(myfile='test_file.py')\n                document.myfile.save('test_file.py', file1)\n                try:\n                    dump = pickle.dumps(document.myfile)\n                    loaded_myfile = pickle.loads(dump)\n                    self.assertEqual(document.myfile, loaded_myfile)\n                    self.assertEqual(document.myfile.url, loaded_myfile.url)\n                    self.assertEqual(document.myfile.storage, loaded_myfile.storage)\n                    self.assertEqual(document.myfile.instance, loaded_myfile.instance)\n                    self.assertEqual(document.myfile.field, loaded_myfile.field)\n                finally:\n                    document.myfile.delete()\n"], "sample_532": ["def test_contour_label_fontsize():\n    x, y = np.meshgrid(np.arange(0, 10), np.arange(0, 10))\n    z = np.max(np.dstack([abs(x), abs(y)]), 2)\n\n    fig, ax = plt.subplots()\n    cs = ax.contour(x, y, z)\n    cs.clabel(fontsize='xx-large')\n    assert [t.get_fontproperties().get_size() for t in cs.labelTexts] == [24]\n"], "sample_566": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect((1, 2, 3))\n    ax2.set_box_aspect((2, 1, 1))\n"], "sample_990": ["def test_acsch_expansion():\n    x, y = symbols('x,y')\n    assert acsch(x+y).expand(trig=True) == acsch(x)*acsch(y) + csch(x)*csch(y)\n    assert acsch(2*x).expand(trig=True) == 2*acsch(x)*csch(x)\n    assert acsch(3*x).expand(trig=True).expand() == \\\n        acsch(x)**3 + 3*acsch(x)*csch(x)**2\n"], "sample_831": ["def test_export_text_multi_output():\n    clf = DecisionTreeClassifier(max_depth=2, random_state=0)\n    clf.fit(X, y2)\n\n    expected_report = dedent(\"\"\"\n    |--- feature_1 <= 0.00\n    |   |--- class: [0, 1]\n    |--- feature_1 >  0.00\n    |   |--- class: [1, 2]\n    \"\"\").lstrip()\n    assert export_text(clf) == expected_report\n    # testing that leaves at level 1 are not truncated\n    assert export_text(clf, max_depth=0) == expected_report\n    # testing that the rest of the tree is truncated\n    assert export_text(clf, max_depth=10) == expected_report\n\n    expected_report = dedent(\"\"\"\n    |--- b <= 0.00\n    |   |--- class: [0, 1]\n    |--- b >  0.00\n    |   |--- class: [1, 2]\n    \"\"\").lstrip()\n    assert export_text(clf, feature_names=['a', 'b']) == expected_report\n\n    expected_report = dedent(\"\"\"\n    |--- feature_1 <= 0.00\n    |   |--- weights: [3.0, 1.5, 0.0] class: [0, 1]\n    |--- feature_1 >  0.00\n    |   |--- weights: [0.0, 1.0, 2.0] class: [1, 2]\n    \"\"\").lstrip()\n    assert export_text(clf, show_weights=True) == expected_report\n\n    expected_report = dedent(\"\"\"\n    |- feature_1 <= 0.00\n    | |- class: [0, 1]\n    |- feature_1 >  0.00\n    | |- class: [1, 2]\n    \"\"\").lstrip()\n    assert export_text(clf, spacing=1) == expected_report\n\n    X_l = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1], [-1, 1]]\n    y_l = [-1, -1, -1, 1, 1, 1, 2]\n    clf = DecisionTreeClassifier(max_depth="], "sample_8": ["    def test_indexing(self):\n        ma_index = self.ma[[0, 2]]\n        expected_data = self.a[[0, 2]]\n        expected_mask = self.mask_a[[0, 2]]\n        assert_array_equal(ma_index.unmasked, expected_data)\n        assert_array_equal(ma_index.mask, expected_mask)\n"], "sample_914": ["def test_unparse_arguments():\n    source = \"def func(a, b, c=1, *, d, e=2, f, **kwargs): pass\"\n    expected = \"a, b, c=1, *, d, e=2, f, **kwargs\"\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].args) == expected\n"], "sample_161": ["    def test_through_fields_with_unique_constraint(self):\n        class Parent(models.Model):\n            a = models.PositiveIntegerField()\n            b = models.PositiveIntegerField()\n            c = models.PositiveIntegerField()\n\n            class Meta:\n                unique_together = (('a', 'b'),)\n\n        class Child(models.Model):\n            a = models.PositiveIntegerField()\n            b = models.PositiveIntegerField()\n            value = models.CharField(max_length=255)\n            parent = models.ForeignObject(\n                Parent,\n                on_delete=models.SET_NULL,\n                from_fields=('a', 'b'),\n                to_fields=('a', 'b'),\n                related_name='children',\n            )\n\n        field = Child._meta.get_field('parent')\n        self.assertEqual(field.check(from_model=Child), [])\n"], "sample_504": ["def test_colorbar_alpha():\n    fig, ax = plt.subplots()\n    sm = cm.ScalarMappable(norm=mcolors.Normalize(), cmap='viridis')\n    fig.colorbar(sm)\n    sm.set_cmap('plasma')\n    sm.set_array(np.array([0.5]))\n    plt.draw()\n    assert sm.colorbar.alpha is None\n    assert sm.get_alpha() == 0.5\n"], "sample_1171": ["def test_ImageSet_simplification_with_rational():\n    from sympy.abc import n, m\n    assert imageset(Lambda(n, n/2), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/2), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/3), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/4), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/5), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/6), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/7), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/8), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/9), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/10), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/11), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/12), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/13), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/14), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/15), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/16), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/17), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/18), S.Integers) == S.Integers\n"], "sample_472": ["    def test_get_elided_page_range_with_zero_pages(self):\n        paginator = Paginator([], 10)\n        with self.assertRaises(EmptyPage):\n            list(paginator.get_elided_page_range(1))\n"], "sample_898": ["def test_coverage_error_multilabel():\n    # Test the coverage error metric\n    random_state = check_random_state(0)\n    y_true = random_state.randint(0, 2, size=(20, 5))\n    y_score = random_state.uniform(size=y_true.shape)\n\n    for name in THRESHOLDED_MULTILABEL_METRICS:\n        metric = ALL_METRICS[name]\n        assert_almost_equal(metric(y_true, y_score), metric(y_true, y_score,\n                                                          sample_weight=None))\n"], "sample_985": ["def test_is_positive_is_nonnegative_is_negative():\n    x, y = symbols('x y')\n    assert Min(x, y).is_positive is False\n    assert Min(x, y).is_nonnegative is True\n    assert Min(x, y).is_negative is False\n    assert Max(x, y).is_positive is True\n    assert Max(x, y).is_nonnegative is True\n    assert Max(x, y).is_negative is False\n    assert Min(x, -x).is_positive is False\n    assert Min(x, -x).is_nonnegative is True\n    assert Min(x, -x).is_negative is False\n    assert Max(x, -x).is_positive is True\n    assert Max(x, -x).is_nonnegative is True\n    assert Max(x, -x).is_negative is False\n    assert Min(-x, x).is_positive is False\n    assert Min(-x, x).is_nonnegative is True\n    assert Min(-x, x).is_negative is False\n    assert Max(-x, x).is_positive is True\n    assert Max(-x, x).is_nonnegative is True\n    assert Max(-x, x).is_negative is False\n    assert Min(-x, -x).is_positive is False\n    assert Min(-x, -x).is_nonnegative is True\n    assert Min(-x, -x).is_negative is True\n    assert Max(-x, -x).is_positive is False\n    assert Max(-x, -x).is_nonnegative is True\n    assert Max(-x, -x).is_negative is True\n"], "sample_942": ["def test_pyvariable_signature(app):\n    text = (\".. py:data:: var\\n\"\n            \"   :type: int\\n\"\n            \"   :value: 1\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"var\"],\n                                                    [desc_annotation, (\": \",\n                                                                       [pending_xref, \"int\"])],\n                                                    [desc_annotation, \" = 1\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n    assert_node(doctree[1][0][1],\n                ([desc_annotation, \"int\"],\n                 [desc_annotation, \" = 1\"]))\n\n    assert 'var' in app.env.domains['py'].objects\n    assert app.env.domains['py'].objects['var'] == ('index', 'var', 'data', False)\n"], "sample_818": ["def test_spectral_clustering_with_kmeans_init():\n    # Test that spectral_clustering is the same with kmeans initialization\n    # Based on toy example from plot_segmentation_toy.py\n\n    # a small two coin image\n    x, y = np.indices((40, 40))\n\n    center1, center2 = (14, 12), (20, 25)\n    radius1, radius2 = 8, 7\n\n    circle1 = (x - center1[0]) ** 2 + (y - center1[1]) ** 2 < radius1 ** 2\n    circle2 = (x - center2[0]) ** 2 + (y - center2[1]) ** 2 < radius2 ** 2\n\n    circles = circle1 | circle2\n    mask = circles.copy()\n    img = circles.astype(float)\n\n    graph = img_to_graph(img, mask=mask)\n    graph.data = np.exp(-graph.data / graph.data.std())\n\n    labels_kmeans = spectral_clustering(\n        graph, n_clusters=2, eigen_solver='arpack', random_state=0,\n        assign_labels='kmeans')\n\n    labels_discretize = spectral_clustering(\n        graph, n_clusters=2, eigen_solver='arpack', random_state=0,\n        assign_labels='discretize')\n\n    assert adjusted_rand_score(labels_kmeans, labels_discretize) == 1\n"], "sample_435": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = UNUSABLE_PASSWORD_PREFIX + \"123456\"\n        self.assertHTMLEqual(\n            widget.render(\"name\", value, {\"id\": \"id_password\"}),\n            '<div id=\"id_password\">'\n            \"    <strong>No password set.</strong>\"\n            \"</div>\",\n        )\n"], "sample_1136": ["def test_Poly_unify():\n    F3 = FF(3)\n    F5 = FF(5)\n\n    assert Poly(x, x, modulus=3)._unify(Poly(y, y, modulus=5))[2:] == (\n        DMP([[F5(1)], []], F5), DMP([[F5(1), F5(0)]], F5))\n\n    assert Poly(x, x, modulus=3)._unify(Poly(y, y, modulus=5))[2:] == (\n        DMP([[F5(1)], []], F5), DMP([[F5(1), F5(0)]], F5))\n\n    assert Poly(y, x, y)._unify(Poly(x, x, modulus=3))[2:] == (DMP([[F3(1), F3(0)]], F3), DMP([[F3(1)], []], F3))\n    assert Poly(x, x, modulus=3)._unify(Poly(y, x, y))[2:] == (DMP([[F3(1)], []], F3), DMP([[F3(1), F3(0)]], F3))\n\n    assert Poly(x + 1, x)._unify(Poly(x + 2, x))[2:] == (DMP([1, 1], ZZ), DMP([1, 2], ZZ))\n    assert Poly(x + 1, x, domain='QQ')._unify(Poly(x + 2, x))[2:] == (DMP([1, 1], QQ), DMP([1, 2], QQ))\n    assert Poly(x + 1, x)._unify(Poly(x + 2, x, domain='QQ'))[2:] == (DMP([1, 1], QQ), DMP([1, 2], QQ))\n\n    assert Poly(x + 1, x)._unify(Poly(x + 2, x, y))[2:] == (DMP([[1], [1]], ZZ), DMP([[1], [2]], ZZ))\n    assert Poly(x + 1, x, domain='QQ')._unify(Poly(x + 2, x, y))[2:] == (DMP([[1], [1]], QQ), DMP([[1], [2]], QQ))\n    assert Poly(x + 1, x)._unify(Poly(x +"], "sample_705": ["def test_pytester_syspathinsert(pytester: Pytester) -> None:\n    pytester.syspathinsert()\n    assert pytester.path in sys.path\n    pytester.syspathinsert(\"/tmp\")\n    assert \"/tmp\" in sys.path\n    pytester.syspathinsert()\n    assert pytester.path not in sys.path\n"], "sample_1047": ["def test_issue_10303():\n    x = Symbol('x')\n    r = Symbol('r', real=True)\n    u = -(3*2**pi)**(1/pi) + 2*3**(1/pi)\n    i = u + u*I\n    assert (u + i).is_real is None  # w/o simplification this should fail\n    assert (u + i).is_zero is None\n    assert (1 + i).is_zero is False\n    a = Dummy('a', zero=True)\n    assert (a + I).is_zero is False\n    assert (a + r*I).is_zero is None\n    assert (a + I).is_imaginary\n    assert (a + x + I).is_imaginary is None\n    assert (a + r*I + I).is_imaginary is None\n    assert (a + r*I + x).is_imaginary is None\n"], "sample_1193": ["def test_closest_points_farthest_points_empty():\n    assert closest_points() == []\n    assert farthest_points() == []\n    assert closest_points(Point2D(0, 0)) == []\n    assert farthest_points(Point2D(0, 0)) == []\n    assert closest_points(Point2D(0, 0), Point2D(0, 0)) == set([(Point2D(0, 0), Point2D(0, 0))])\n    assert farthest_points(Point2D(0, 0), Point2D(0, 0)) == set([(Point2D(0, 0), Point2D(0, 0))])\n    assert closest_points(Point2D(0, 0), Point2D(1, 0)) == set([(Point2D(0, 0), Point2D(1, 0))])\n    assert farthest_points(Point2D(0, 0), Point2D(1, 0)) == set([(Point2D(0, 0), Point2D(1, 0))])\n    assert closest_points(Point2D(0, 0), Point2D(1, 0), Point2D(2, 0)) == set([(Point2D(0, 0), Point2D(1, 0))])\n    assert farthest_points(Point2D(0, 0), Point2D(1, 0), Point2D(2, 0)) == set([(Point2D(0, 0), Point2D(2, 0))])\n    assert closest_points(Point2D(0, 0), Point2D(1, 0), Point2D(2, 0), Point2D(3, 0)) == set([(Point2D(0, 0), Point2D(1, 0))])\n    assert farthest_points(Point2D(0, 0), Point2D(1, 0), Point2D(2, 0), Point2D(3, 0)) == set([(Point2D(0, 0), Point2D(3, 0))])\n"], "sample_666": ["    def test_live_logging(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import logging\n            import sys\n            import pytest\n\n            logger = logging.getLogger(__name__)\n\n                print(\"hello\")\n                sys.stderr.write(\"world\\\\n\")\n                captured = sys.stderr.read()\n                assert captured == \"world\\\\n\"\n\n                logging.info(\"something\")\n                print(\"next\")\n                logging.info(\"something\")\n\n                captured = sys.stderr.read()\n                assert captured == \"next\\\\n\"\n        \"\"\"\n        )\n\n        result = testdir.runpytest_subprocess(\"--log-cli-level=INFO\")\n        assert result.ret == 0\n"], "sample_1115": ["def test_TensorIndexType_data():\n    Lorentz = TensorIndexType('Lorentz', dim=4, dummy_name='L')\n    Lorentz.data = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\n    Lorentz.metric = Lorentz\n    Lorentz.data = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\n    Lorentz.metric = Lorentz\n    Lorentz.data = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\n    Lorentz.metric = Lorentz\n    Lorentz.data = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\n    Lorentz.metric = Lorentz\n    Lorentz.data = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\n    Lorentz.metric = Lorentz\n    Lorentz.data = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\n    Lorentz.metric = Lorentz\n    Lorentz.data = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\n    Lorentz.metric = Lorentz\n    Lorentz.data = [[1, 0, 0, 0], [0, 1, 0, 0], ["], "sample_466": ["def test_serialize_datetime_tzinfo(self):\n    \"\"\"\n    Test serialization of datetime objects with timezone info.\n    \"\"\"\n    self.assertSerializedResultEqual(\n        datetime.datetime(2014, 1, 1, 1, 1, tzinfo=datetime.timezone.utc),\n        (\n            \"datetime.datetime(2014, 1, 1, 1, 1, tzinfo=datetime.timezone.utc)\",\n            {\"import datetime\"},\n        ),\n    )\n    self.assertSerializedResultEqual(\n        datetime.datetime(2012, 1, 1, 1, 1, tzinfo=zoneinfo.ZoneInfo(\"Europe/Paris\")),\n        (\n            \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc)\",\n            {\"import datetime\"},\n        ),\n    )\n"], "sample_486": ["def test_inlineformset_factory_nulls_default_pks_auto_parent_uuid_parent(self):\n    \"\"\"\n    #24958 - Variant of test_inlineformset_factory_nulls_default_pks for\n    the case of a parent object with an AutoField primary key and a parent\n    object with a UUID primary key.\n    \"\"\"\n    FormSet = inlineformset_factory(\n        AutoPKParent, UUIDPKParent, fields=\"__all__\"\n    )\n    formset = FormSet()\n    self.assertIsNone(formset.forms[0].fields[\"parent\"].initial)\n"], "sample_403": ["def test_rename_field_with_db_column_and_index(self):\n    \"\"\"\n    Tests the RenameField operation with a field that has a db_column and an index.\n    \"\"\"\n    project_state = self.set_up_test_model(\n        \"test_rfwdbci\",\n        fields=[\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"field\", models.IntegerField(db_column=\"db_field\")),\n            (\n                \"fk_field\",\n                models.ForeignKey(\n                    \"Pony\",\n                    models.CASCADE,\n                    db_column=\"db_fk_field\",\n                ),\n            ),\n        ],\n        indexes=[models.Index(\"field\")],\n    )\n    new_state = project_state.clone()\n    operation = migrations.RenameField(\"Pony\", \"field\", \"renamed_field\")\n    operation.state_forwards(\"test_rfwdbci\", new_state)\n    self.assertIn(\"renamed_field\", new_state.models[\"test_rfwdbci\", \"pony\"].fields)\n    self.assertNotIn(\"field\", new_state.models[\"test_rfwdbci\", \"pony\"].fields)\n    self.assertColumnExists(\"test_rfwdbci_pony\", \"db_field\")\n    with connection.schema_editor() as editor:\n        with self.assertNumQueries(0):\n            operation.database_forwards(\n                \"test_rfwdbci\", editor, project_state, new_state\n            )\n    self.assertColumnExists(\"test_rfwdbci_pony\", \"db_field\")\n    with connection.schema_editor() as editor:\n        with self.assertNumQueries(0):\n            operation.database_backwards(\n                \"test_rfwdbci\", editor, new_state, project_state\n            )\n    self.assertColumnExists(\"test_rfwdbci_pony\", \"db_field\")\n\n    new_state = project_state.clone()\n    operation = migrations.RenameField(\"Pony\", \"fk_field\", \"renamed_fk_field\")\n    operation.state_forwards(\"test_rfwdbci\", new_state)\n    self.assertIn(\n        \"renamed_fk_field\", new_state.models[\"test_rfwdbci\", \"pony\"].fields\n    )\n    self.assertNotIn(\"fk_field\", new_state.models[\"test_rfwdbci\", \"pony\"].fields)\n    self.assertColumnExists(\"test_rfwdbci_pony\", \"db_fk_field\")\n    with connection.schema_editor() as editor:\n        with self.assertNumQueries(0):\n            operation.database_forwards(\n                \"test_rfwdbci\", editor, project_state, new_state\n           "], "sample_1140": ["def test_pretty_ConditionSet():\n    from sympy import ConditionSet\n    ascii_str = '{x | x in (-oo, oo) and sin(x) = 0}'\n    ucode_str = '{x | x \u220a \u211d \u2227 (sin(x) = 0)}'\n    assert pretty(ConditionSet(x, Eq(sin(x), 0), S.Reals)) == ascii_str\n    assert upretty(ConditionSet(x, Eq(sin(x), 0), S.Reals)) == ucode_str\n\n    assert pretty(ConditionSet(x, Contains(x, S.Reals, evaluate=False), FiniteSet(1))) == '{1}'\n    assert upretty(ConditionSet(x, Contains(x, S.Reals, evaluate=False), FiniteSet(1))) == '{1}'\n\n    assert pretty(ConditionSet(x, And(x > 1, x < -1), FiniteSet(1, 2, 3))) == \"EmptySet\"\n    assert upretty(ConditionSet(x, And(x > 1, x < -1), FiniteSet(1, 2, 3))) == \"\u2205\"\n\n    assert pretty(ConditionSet(x, Or(x > 1, x < -1), FiniteSet(1, 2))) == '{2}'\n    assert upretty(ConditionSet(x, Or(x > 1, x < -1), FiniteSet(1, 2))) == '{2}'\n"], "sample_682": ["    def test_xfail_raises_with_multiple_exceptions(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(raises=(TypeError, ValueError))\n                raise TypeError()\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n"], "sample_679": ["def test_mark_eval_invalid_syntax(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xyz\n            pass\n    \"\"\"\n    )\n    expr = \"xyz invalid syntax\"\n    reprec = testdir.inline_run(\"-m\", expr)\n    err = reprec.getfailure()\n    assert err.longreprtext.startswith(\"ERROR: Wrong expression passed to '-m':\")\n    assert \"invalid syntax\" in err.longreprtext\n"], "sample_343": ["    def test_check_content_type_field(self):\n        class Model(models.Model):\n            content_type = models.ForeignKey(ContentType, on_delete=models.CASCADE)\n            object_id = models.IntegerField()\n            generic_field = GenericForeignKey(ct_field='content_type', fk_field='object_id')\n        self.assertEqual(Model._meta.get_field('generic_field').check(), [])\n"], "sample_1059": ["def test_hermite_normalized():\n    n = Symbol(\"n\")\n    X = hermite(n, x)\n    assert isinstance(X, hermite)\n    assert unchanged(hermite, n, x)\n    assert hermite(n, -x) == (-1)**n*hermite(n, x)\n    assert unchanged(hermite, -n, x)\n\n    assert hermite(n, 0) == 2**n*sqrt(pi)/gamma(S(1)/2 - n/2)\n    assert hermite(n, oo) == oo\n\n    assert conjugate(hermite(n, x)) == hermite(n, conjugate(x))\n\n    _k = Dummy('k')\n    assert hermite(n, x).rewrite(\"polynomial\").dummy_eq(factorial(n)*Sum((-1)**_k*(2*x)**(-2*_k + n)/(factorial(_k)*factorial(-2*_k + n)), (_k, 0, floor(n/2))))\n\n    assert diff(hermite(n, x), x) == 2*n*hermite(n - 1, x)\n    assert diff(hermite(n, x), n) == Derivative(hermite(n, x), n)\n\n    assert hermite_normalized(n, x) == \\\n        hermite(n, x)/sqrt(2**n*factorial(n)*gamma(n + S(1)/2)*gamma(n + S(1)/2))\n\n    raises(ValueError, lambda: hermite(-2.1, x))\n    raises(ValueError, lambda: hermite(Rational(5, 2), x))\n    raises(ArgumentIndexError, lambda: hermite(n, x).fdiff(3))\n"], "sample_142": ["def test_inline_formset_factory(self):\n    class SongInline(admin.TabularInline):\n        model = Song\n\n    class AlbumAdmin(admin.ModelAdmin):\n        inlines = [SongInline]\n\n    errors = AlbumAdmin(Album, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongInlineWithFkName(admin.TabularInline):\n        model = Song\n        fk_name = \"album\"\n\n    class AlbumAdminWithFkName(admin.ModelAdmin):\n        inlines = [SongInlineWithFkName]\n\n    errors = AlbumAdminWithFkName(Album, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongInlineWithFkNameMissing(admin.TabularInline):\n        model = Song\n        fk_name = \"nonexistent\"\n\n    class AlbumAdminWithFkNameMissing(admin.ModelAdmin):\n        inlines = [SongInlineWithFkNameMissing]\n\n    errors = AlbumAdminWithFkNameMissing(Album, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"'admin_checks.Song' has no ForeignKey named 'nonexistent'.\",\n            obj=SongInlineWithFkNameMissing,\n            id='admin.E203',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_124": ["def test_boundfield_value_disabled_callable_initial_with_microseconds(self):\n    class DateTimeForm(forms.Form):\n        dt = DateTimeField(initial=lambda: datetime.datetime(2006, 10, 25, 14, 30, 45, 123456), disabled=True)\n\n    form = DateTimeForm({'dt': '2006-10-25 14:30:45'})\n    self.assertEqual(form.changed_data, [])\n"], "sample_1011": ["def test_MatrixSlice():\n    A = Matrix([[1, 2, 3], [4, 5, 6]])\n    assert mcode(A[1, :]) == \"[4 5 6]\"\n    assert mcode(A[:, 1]) == \"[2; 5]\"\n    assert mcode(A[1, 1:3]) == \"[5 6]\"\n    assert mcode(A[:, 1:3]) == \"[2 5; 5 6]\"\n    assert mcode(A[1, 1:3:2]) == \"[5]\"\n    assert mcode(A[:, 1:3:2]) == \"[2; 5]\"\n    assert mcode(A[1, 1:3:-1]) == \"[6]\"\n    assert mcode(A[:, 1:3:-1]) == \"[5; 2]\"\n    assert mcode(A[1, 1:3:2:-1]) == \"[6]\"\n    assert mcode(A[:, 1:3:2:-1]) == \"[5; 2]\"\n"], "sample_186": ["def test_prepopulated_fields(self):\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title', 'nonexistent')}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'prepopulated_fields[slug][1]' refers to 'nonexistent', \"\n            \"which is not an attribute of 'admin_checks.Song'.\",\n            obj=SongAdmin,\n            id='admin.E027',\n        )\n    ]\n    self.assertEqual(errors, expected)\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors,"], "sample_409": ["    def test_contextual_translation_with_filter(self):\n        t = Template(\n            \"{% load i18n %}{% blocktranslate context message_context|lower %}May{% endblocktranslate %}\"\n        )\n        with translation.override(\"de\"):\n            rendered = t.render(Context({\"message_context\": \"MONTH NAME\"}))\n            self.assertEqual(rendered, \"Mai\")\n            rendered = t.render(Context({\"message_context\": \"verb\"}))\n            self.assertEqual(rendered, \"Kann\")\n"], "sample_709": ["def test_pytester_syspathinsert(pytester: Pytester) -> None:\n    pytester.syspathinsert()\n    assert pytester.path in sys.path\n    pytester.syspathinsert(None)\n    assert pytester.path not in sys.path\n"], "sample_362": ["def test_alter_field_with_default(self):\n    \"\"\"Tests autodetection of altered fields with a default.\"\"\"\n    changes = self.get_changes([self.author_name], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, 'testapp', 0, 0, default='Ada Lovelace')\n"], "sample_659": ["    def test_raises_with_custom_exception_info(self):\n        class CustomException(Exception):\n            pass\n\n        with pytest.raises(CustomException, excinfo=ExceptionInfo((CustomException, CustomException(), None))):\n            raise CustomException()\n"], "sample_74": ["def test_empty_connection_params(self):\n    with self.assertRaises(KeyError):\n        DatabaseClient.runshell_db({})\n"], "sample_1180": ["def test_canberra_distance():\n    p1 = Point(1, 1)\n    p2 = Point(3, 3)\n    assert p1.canberra_distance(p2) == 1\n    p3 = Point(0, 0)\n    assert p1.canberra_distance(p3) == 2\n    p4 = Point(0, 1)\n    assert p1.canberra_distance(p4) == 1\n    p5 = Point(0, 0, 0)\n    assert p1.canberra_distance(p5) == 2\n    p6 = Point(0, 0, 0, 0)\n    with warns(UserWarning):\n        assert p1.canberra_distance(p6) == 3\n    p7 = Point(0, 0, 0, 0, 0)\n    with warns(UserWarning):\n        assert p1.canberra_distance(p7) == 4\n    p8 = Point(0, 0, 0, 0, 0, 0)\n    with warns(UserWarning):\n        assert p1.canberra_distance(p8) == 5\n    p9 = Point(0, 0, 0, 0, 0, 0, 0)\n    with warns(UserWarning):\n        assert p1.canberra_distance(p9) == 6\n    p10 = Point(0, 0, 0, 0, 0, 0, 0, 0)\n    with warns(UserWarning):\n        assert p1.canberra_distance(p10) == 7\n    p11 = Point(0, 0, 0, 0, 0, 0, 0, 0, 0)\n    with warns(UserWarning):\n        assert p1.canberra_distance(p11) == 8\n    p12 = Point(0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n    with warns(UserWarning):\n        assert p1.canberra_distance(p12) == 9\n    p13 = Point(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n    with warns(UserWarning):\n        assert p1.canberra_distance(p13) == 10\n    p14 = Point(0, "], "sample_385": ["    def test_build_attrs_i18n_language_not_supported(self):\n        \"\"\"Test that the language code is not supported.\"\"\"\n        rel = Album._meta.get_field(\"band\")\n        w = AutocompleteSelect(rel, admin.site)\n        with translation.override(\"zh-hant-tw\"):\n            attrs = w.build_attrs({})\n            self.assertNotIn(\"lang\", attrs)\n            self.assertNotIn(\"data-lang\", attrs)\n"], "sample_631": ["    def setup_method(self):\n        super().setup_method()\n        self._to_consume_backup = self.checker._to_consume\n        self.checker._to_consume = []\n"], "sample_919": ["def test_enum_definitions():\n    check('enum', '{key}A', {2: \"1A\"})\n    check('enum', '{key}A : std::underlying_type<B>::type', {2: \"1A\"})\n    check('enum', '{key}A : unsigned int', {2: \"1A\"})\n    check('enum', 'public A', {2: \"1A\"}, output='{key}A')\n    check('enum', 'private {key}A', {2: \"1A\"})\n\n    check('enumerator', '{key}A', {2: \"1A\"})\n    check('enumerator', '{key}A = std::numeric_limits<unsigned long>::max()', {2: \"1A\"})\n"], "sample_967": ["def test_mathjax_path(app, status, warning):\n    app.builder.build_all()\n\n    content = (app.outdir / 'index.html').read_text()\n    assert 'https://example.com/mathjax.js' in content\n"], "sample_318": ["    def test_include_urls_with_default_namespace(self):\n        self.assertEqual(include(self.url_patterns, namespace='default'), (self.url_patterns, None, 'default'))\n"], "sample_555": ["def test_patch_alpha_coloring():\n    \"\"\"\n    Test checks that the patch and collection are rendered with the specified\n    alpha values in their facecolor and edgecolor.\n    \"\"\"\n    star = mpath.Path.unit_regular_star(6)\n    circle = mpath.Path.unit_circle()\n    # concatenate the star with an internal cutout of the circle\n    verts = np.concatenate([circle.vertices, star.vertices[::-1]])\n    codes = np.concatenate([circle.codes, star.codes])\n    cut_star1 = mpath.Path(verts, codes)\n    cut_star2 = mpath.Path(verts + 1, codes)\n\n    ax = plt.axes()\n    col = mcollections.PathCollection([cut_star2],\n                                      linewidth=5, linestyles='dashdot',\n                                      facecolor=(1, 0, 0, 0.5),\n                                      edgecolor=(0, 0, 1, 0.75))\n    ax.add_collection(col)\n\n    patch = mpatches.PathPatch(cut_star1,\n                               linewidth=5, linestyle='dashdot',\n                               facecolor=(1, 0, 0, 0.5),\n                               edgecolor=(0, 0, 1, 0.75))\n    ax.add_patch(patch)\n\n    ax.set_xlim([-1, 2])\n    ax.set_ylim([-1, 2])\n"], "sample_975": ["def test_nsolve_univariate():\n    x = Symbol('x')\n    assert nsolve(x**2 - 4, x, 2) == 2.0\n    assert nsolve(x**2 - 4, x, 1) == 2.0\n    assert nsolve(x**2 - 4, x, 3) == 2.0\n    assert nsolve(x**2 - 4, x, 0) == 2.0\n    assert nsolve(x**2 - 4, x, -1) == 2.0\n    assert nsolve(x**2 - 4, x, -2) == 2.0\n    assert nsolve(x**2 - 4, x, -3) == 2.0\n    assert nsolve(x**2 - 4, x, -4) == 2.0\n    assert nsolve(x**2 - 4, x, -5) == 2.0\n    assert nsolve(x**2 - 4, x, -6) == 2.0\n    assert nsolve(x**2 - 4, x, -7) == 2.0\n    assert nsolve(x**2 - 4, x, -8) == 2.0\n    assert nsolve(x**2 - 4, x, -9) == 2.0\n    assert nsolve(x**2 - 4, x, -10) == 2.0\n    assert nsolve(x**2 - 4, x, -11) == 2.0\n    assert nsolve(x**2 - 4, x, -12) == 2.0\n    assert nsolve(x**2 - 4, x, -13) == 2.0\n    assert nsolve(x**2 - 4, x, -14) == 2.0\n    assert nsolve(x**2 - 4, x, -15) == 2.0\n    assert nsolve(x**2 - 4, x, -16) == 2.0\n    assert nsolve(x**2 - 4, x, -17) == 2.0\n    assert nsolve(x**2 - 4, x, -18) == 2.0\n    assert nsolve(x**2 - 4,"], "sample_194": ["    def setUpTestData(cls):\n        cls.p1, cls.p2 = UniqueConstraintProduct.objects.bulk_create([\n            UniqueConstraintProduct(name='p1', color='red'),\n            UniqueConstraintProduct(name='p2'),\n        ])\n"], "sample_236": ["    def test_delete_with_keeping_parents_multiple(self):\n        child = RChild.objects.create()\n        parent_id = child.r_ptr_id\n        child.delete(keep_parents=True)\n        self.assertFalse(RChild.objects.filter(id=child.id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n\n        childchild = RChildChild.objects.create()\n        parent_id = childchild.rchild_ptr.r_ptr_id\n        child_id = childchild.rchild_ptr_id\n        parent_referent_id = S.objects.create(r=childchild.rchild_ptr.r_ptr).pk\n        childchild.delete(keep_parents=True)\n        self.assertFalse(RChildChild.objects.filter(id=childchild.id).exists())\n        self.assertTrue(RChild.objects.filter(id=child_id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n\n        childgrandchild = RChildChildChild.objects.create()\n        grandparent_id = childgrandchild.rchildchild_ptr.r_ptr_id\n        child_id = childgrandchild.rchildchild_ptr_id\n        parent_referent_id = S.objects.create(r=childgrandchild.rchildchild_ptr.r_ptr).pk\n        childgrandchild.delete(keep_parents=True)\n        self.assertFalse(RChildChildChild.objects.filter(id=childgrandchild.id).exists())\n        self.assertTrue(RChildChild.objects.filter(id=child_id).exists())\n        self.assertTrue(R.objects.filter(id=grandparent_id).exists())\n        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n"], "sample_443": ["    def setUp(self):\n        super().setUp()\n        self.dirname = self.mkdtemp()\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n"], "sample_212": ["def test_session_save_error(self):\n    \"\"\"\n    Test that an UpdateError is raised when the session save fails.\n    \"\"\"\n    class SimpleMiddleWare(MiddlewareMixin):\n            request.session = self.SessionStore('session_key')\n\n            try:\n                request.session.save()\n                raise Exception('Simulate save error')\n            except Exception as e:\n                raise UpdateError(str(e))\n\n    request = HttpRequest()\n    response = SimpleMiddleWare(None)(request)\n    self.assertIsInstance(response, HttpResponse)\n    self.assertEqual(response.status_code, 500)\n    self.assertIn('The request\\'s session was deleted before the request completed.', response.content.decode())\n"], "sample_297": ["    def setUpTestData(cls):\n        cls.a1 = Author.objects.create(name='a1', num=1001, extra=ExtraInfo.objects.create(info='e1', note=Note.objects.create(note='n1', misc='foo', id=1)))\n        cls.a2 = Author.objects.create(name='a2', num=2002, extra=ExtraInfo.objects.create(info='e2', note=Note.objects.create(note='n2', misc='bar', id=2)))\n        cls.a3 = Author.objects.create(name='a3', num=3003, extra=ExtraInfo.objects.create(info='e3', note=Note.objects.create(note='n3', misc='foo', id=3)))\n"], "sample_156": ["def test_boundfield_value_disabled_callable_initial_with_form_data(self):\n    class PersonForm(Form):\n        name = CharField(initial=lambda: 'John Doe', disabled=True)\n\n    # With form data. As the field is disabled, the value should not be\n    # affected by the form data.\n    form = PersonForm({'name': 'Jane Doe'})\n    self.assertEqual(form['name'].value(), 'John Doe')\n"], "sample_452": ["def test_rename_field_with_unique_together(self):\n    \"\"\"\n    Tests the RenameField operation with unique_together.\n    \"\"\"\n    project_state = self.set_up_test_model(\"test_rnflut\", unique_together=True)\n    operation = migrations.RenameField(\"Pony\", \"pink\", \"blue\")\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_rnflut\", new_state)\n    # unique_together has the renamed column.\n    self.assertIn(\n        \"blue\",\n        new_state.models[\"test_rnflut\", \"pony\"].options[\"unique_together\"][0],\n    )\n    self.assertNotIn(\n        \"pink\",\n        new_state.models[\"test_rnflut\", \"pony\"].options[\"unique_together\"][0],\n    )\n    # Rename field.\n    self.assertColumnExists(\"test_rnflut_pony\", \"pink\")\n    self.assertColumnNotExists(\"test_rnflut_pony\", \"blue\")\n    with connection.schema_editor() as editor:\n        operation.database_forwards(\"test_rnflut\", editor, project_state, new_state)\n    self.assertColumnExists(\"test_rnflut_pony\", \"blue\")\n    self.assertColumnNotExists(\"test_rnflut_pony\", \"pink\")\n    # The unique constraint has been ported over.\n    with connection.cursor() as cursor:\n        cursor.execute(\"INSERT INTO test_rnflut_pony (blue, weight) VALUES (1, 1)\")\n        with self.assertRaises(IntegrityError):\n            with atomic():\n                cursor.execute(\n                    \"INSERT INTO test_rnflut_pony (blue, weight) VALUES (1, 1)\"\n                )\n        cursor.execute(\"DELETE FROM test_rnflut_pony\")\n    # Reversal.\n    with connection.schema_editor() as editor:\n        operation.database_backwards(\n            \"test_rnflut\", editor, new_state, project_state\n        )\n    self.assertColumnExists(\"test_rnflut_pony\", \"pink\")\n    self.assertColumnNotExists(\"test_rnflut_pony\", \"blue\")\n"], "sample_1120": ["def test_matrix_symbol_subs():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = MatrixSymbol('C', m, l)\n\n    assert A.subs(n, m) == MatrixSymbol('A', m, m)\n    assert A.subs(n, m).subs(m, l) == MatrixSymbol('A', l, l)\n    assert A.subs(n, m).subs(m, l).subs(l, n) == MatrixSymbol('A', n, n)\n\n    assert (A*B).subs(B, C) == A*C\n    assert (A*B).subs(B, C).subs(C, A) == A**2\n\n    assert (A*B).subs(l, n) == A*B\n    assert (A*B).subs(l, n).subs(n, m) == A*B\n\n    assert (A*B).subs(n, m).subs(m, l) == A*C\n    assert (A*B).subs(n, m).subs(m, l).subs(l, n) == A**2\n\n    assert (A*B).subs(n, m).subs(m, l).subs(l, n).subs(n, m) == A**2\n"], "sample_34": ["def test_compose_with_invalid_units():\n    unit = u.m\n    with pytest.raises(u.UnitsError):\n        unit.compose(units=[u.kg, u.s])\n"], "sample_368": ["def test_migrate_with_replaced_migration(self):\n    \"\"\"\n    Test migrating with a replaced migration.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Were the tables there before?\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_tribble\")\n    # Run it normally\n    self.assertEqual(\n        executor.migration_plan([(\"migrations\", \"0001_initial\")]),\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n        ],\n    )\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n    # Are the tables there now?\n    self.assertTableExists(\"migrations_author\")\n    self.assertTableExists(\"migrations_tribble\")\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Replace the migration\n    executor.loader.replace_migrations = True\n    executor.loader.build_graph()\n    # Migrate to the replaced migration\n    executor.migrate([(\"migrations\", \"0001_replaced\")])\n    # Are the tables still there?\n    self.assertTableExists(\"migrations_author\")\n    self.assertTableExists(\"migrations_tribble\")\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Migrate back to clean up the database\n    executor.migrate([(\"migrations\", None)])\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_tribble\")\n"], "sample_994": ["def test_issue_10368():\n    a = S(32442016954)/78058255275\n    assert type(int(a)) is type(int(-a)) is int\n    assert int(a) == 41\n    assert int(-a) == -41\n"], "sample_339": ["    def test_modelformset_factory_with_custom_save_method_related_instance(self):\n        \"\"\"\n        The ModelForm.save() method should be able to access the related object\n        if it exists in the database (#24395).\n        \"\"\"\n        class PoemForm2(forms.ModelForm):\n                poem = super().save(commit=False)\n                poem.name = \"%s by %s\" % (poem.name, poem.poet.name)\n                if commit:\n                    poem.save()\n                return poem\n\n        PoemFormSet = inlineformset_factory(Poet, Poem, form=PoemForm2, fields=\"__all__\")\n        data = {\n            'poem_set-TOTAL_FORMS': '1',\n            'poem_set-INITIAL_FORMS': '0',\n            'poem_set-MAX_NUM_FORMS': '',\n            'poem_set-0-name': 'Le Lac',\n        }\n        poet = Poet()\n        formset = PoemFormSet(data=data, instance=poet)\n        self.assertTrue(formset.is_valid())\n\n        # The Poet instance is saved after the formset instantiation. This\n        # happens in admin's changeform_view() when adding a new object and\n        # some inlines in the same request.\n        poet.name = 'Lamartine'\n        poet.save()\n        poem = formset.save()[0]\n        self.assertEqual(poem.name, 'Le Lac by Lamartine')\n"], "sample_598": ["def test_inline_dask_repr():\n    da = xr.DataArray(np.random.randn(10, 10), dims=[\"x\", \"y\"], chunks=(5, 5))\n    actual = formatting.inline_dask_repr(da)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(5, 5)>\"\"\"\n    )\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 10), dims=[\"x\", \"y\"], chunks=(5, 5))\n    actual = formatting.inline_dask_repr(da)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(5, 5)>\"\"\"\n    )\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 10), dims=[\"x\", \"y\"], chunks=(5, 5))\n    actual = formatting.inline_dask_repr(da)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(5, 5)>\"\"\"\n    )\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 10), dims=[\"x\", \"y\"], chunks=(5, 5))\n    actual = formatting.inline_dask_repr(da)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(5, 5)>\"\"\"\n    )\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 10), dims=[\"x\", \"y\"], chunks=(5, 5))\n    actual = formatting.inline_dask_repr(da)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(5, 5)>\"\"\"\n    )\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 10), dims=[\"x\", \"y\"], chunks=(5, 5))\n    actual = formatting.inline_dask_repr(da)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(5, 5)>\"\"\"\n    )\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 10), dims=[\"x\", \"y\"], chunks=(5, 5))\n    actual = formatting.inline_dask_repr(da)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(5, 5)>\"\"\"\n    )\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10,"], "sample_396": ["    def setUpTestData(cls):\n        cls.a1 = Author.objects.create(name=\"a1\", num=1001)\n        cls.a2 = Author.objects.create(name=\"a2\", num=2002)\n        cls.a3 = Author.objects.create(name=\"a3\", num=3003)\n        cls.a4 = Author.objects.create(name=\"a4\", num=4004)\n        cls.r1 = Report.objects.create(name=\"r1\", creator=cls.a1)\n        cls.r2 = Report.objects.create(name=\"r2\", creator=cls.a3)\n        cls.r3 = Report.objects.create(name=\"r3\")\n"], "sample_998": ["def test_latex_Morphism():\n    from sympy.categories import (Object, IdentityMorphism,\n        NamedMorphism, Category, Diagram, DiagramGrid)\n\n    A1 = Object(\"A1\")\n    A2 = Object(\"A2\")\n    A3 = Object(\"A3\")\n\n    f1 = NamedMorphism(A1, A2, \"f1\")\n    f2 = NamedMorphism(A2, A3, \"f2\")\n    id_A1 = IdentityMorphism(A1)\n\n    K1 = Category(\"K1\")\n\n    assert latex(f1) == \"f_{1}:A_{1}\\\\rightarrow A_{2}\"\n    assert latex(id_A1) == \"id:A_{1}\\\\rightarrow A_{1}\"\n    assert latex(f2*f1) == \"f_{2}\\\\circ f_{1}:A_{1}\\\\rightarrow A_{3}\"\n    assert latex(NamedMorphism(A1, A2, \"f\")) == \"f:A_{1}\\\\rightarrow A_{2}\"\n    assert latex(IdentityMorphism(A1)) == \"id:A_{1}\\\\rightarrow A_{1}\"\n    assert latex(Category(\"K\")) == r\"\\mathbf{K}\"\n"], "sample_1195": ["def test_kahane_simplify2():\n    i0,i1,i2,i3,i4,i5,i6,i7,i8,i9,i10,i11,i12,i13,i14,i15 = tensor_indices('i0:16', LorentzIndex)\n    mu, nu, rho, sigma = tensor_indices(\"mu, nu, rho, sigma\", LorentzIndex)\n    D = 4\n    t = G(i0)*G(i1)*G(i2)*G(-i0)*G(-i1)*G(-i2)\n    r = kahane_simplify(t)\n    assert r.equals(-2*G(i2)*G(i1)*G(i0))\n\n    t = G(i0)*G(i1)*G(i2)*G(i3)*G(-i0)*G(-i1)*G(-i2)*G(-i3)\n    r = kahane_simplify(t)\n    assert r.equals((2*D - D**2)*eye(4))\n\n    t = G(i0)*G(i1)*G(i2)*G(i3)*G(i4)*G(-i0)*G(-i1)*G(-i2)*G(-i3)*G(-i4)\n    r = kahane_simplify(t)\n    assert r.equals((2*D - D**2)*(2*D - D**2)*eye(4))\n\n    t = G(i0)*G(i1)*G(i2)*G(i3)*G(i4)*G(i5)*G(-i0)*G(-i1)*G(-i2)*G(-i3)*G(-i4)*G(-i5)\n    r = kahane_simplify(t)\n    assert r.equals((2*D - D**2)*(2*D - D**2)*(2*D - D**2)*eye(4))\n\n    t = G(i0)*G(i1)*G(i2)*G(i3)*G(i4)*G(i5)*G(i6)*G(-i0)*G(-i1)*G(-i2)*G(-i3)*G(-i4)*G(-i5)*G(-i6)\n    r = kahane_simplify(t)\n    assert r.equals((2*D - D**2)*(2*D - D**2)*(2*D - D**2)*(2*D - D**2)*eye(4))\n\n    t = G(i0)*G(i1)*G"], "sample_49": ["def test_media_property_overrides(self):\n    # Media properties can override the media of their parents\n    class MyWidget1(TextInput):\n        class Media:\n            css = {\n                'all': ('path/to/css1', '/path/to/css2')\n            }\n            js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')\n\n    class MyWidget2(MyWidget1):\n            return Media(css={'all': ('/some/path',)}, js=('/some/js',))\n        media = property(_media)\n\n    w2 = MyWidget2()\n    self.assertEqual(\n        str(w2.media),\n        \"\"\"<link href=\"/some/path\" type=\"text/css\" media=\"all\" rel=\"stylesheet\">"], "sample_987": ["def test_evalf_piecewise():\n    assert NS(Piecewise((1, x>0), (0, x<=0)), 15) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)), 10) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)), 1) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)), 0) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)), -1) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)), -10) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)), -100) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)), -1000) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)), -10000) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)), -100000) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)), -1000000) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)), -10000000) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)), -100000000) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)), -1000000000) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)), -10000000000) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)), -100000000000) == '1.0'\n    assert NS(Piecewise((1, x>0), (0, x<=0)),"], "sample_542": ["def test_wrap_width():\n    fig, ax = plt.subplots()\n    text = fig.text(0.5, 0.5, 'This is a very long text that should be wrapped multiple times.', wrap=True)\n    fig.canvas.draw()\n    assert text._get_wrap_line_width() == 2.0\n"], "sample_334": ["def test_boundfield_iterable(self):\n    class BeatleForm(Form):\n        name = ChoiceField(\n            choices=[('john', 'John'), ('paul', 'Paul'), ('george', 'George'), ('ringo', 'Ringo')],\n            widget=RadioSelect,\n        )\n\n    f = BeatleForm(auto_id=False)\n    self.assertEqual(len(list(f['name'])), 4)\n    self.assertEqual(len(list(f['name'][1:])), 3)\n    self.assertEqual(len(list(f['name'][1:2]), 1)\n    self.assertEqual(len(list(f['name'][1:3]), 2)\n    self.assertEqual(len(list(f['name'][1:4]), 3)\n    self.assertEqual(len(list(f['name'][1:5]), 4)\n    self.assertEqual(len(list(f['name'][1:6]), 5)\n    self.assertEqual(len(list(f['name'][1:7]), 6)\n    self.assertEqual(len(list(f['name'][1:8]), 7)\n    self.assertEqual(len(list(f['name'][1:9]), 8)\n    self.assertEqual(len(list(f['name'][1:10]), 9)\n    self.assertEqual(len(list(f['name'][1:11]), 10)\n    self.assertEqual(len(list(f['name'][1:12]), 11)\n    self.assertEqual(len(list(f['name'][1:13]), 12)\n    self.assertEqual(len(list(f['name'][1:14]), 13)\n    self.assertEqual(len(list(f['name'][1:15]), 14)\n    self.assertEqual(len(list(f['name'][1:16]), 15)\n    self.assertEqual(len(list(f['name'][1:17]), 16)\n    self.assertEqual(len(list(f['name'][1:18]), 17)\n    self.assertEqual(len(list(f['name'][1:19]), 18)\n    self.assertEqual(len(list(f['name'][1:20]), 19)\n    self.assertEqual(len(list(f['name'][1:21]), 20)\n    self.assertEqual(len(list(f['name'][1:22]), 21)\n    self.assertEqual(len(list(f['name'][1:23]), 22)\n    self.assertEqual(len(list(f['name'][1:24]), 23)\n    self.assertEqual(len(list(f['name'][1:25]), 24)\n    self.assertEqual(len(list(f['name'][1:26]), 25)\n    self.assertEqual(len(list"], "sample_835": ["def test_adaboost_consistent_staged_predict():\n    # check that staged_predict and predict give consistent results\n    # regression test for:\n    # https://github.com/scikit-learn/scikit-learn/issues/14084\n    X_train, X_test, y_train, y_test = train_test_split(\n        *datasets.load_digits(return_X_y=True), random_state=42\n    )\n    model = AdaBoostClassifier(random_state=42)\n    model.fit(X_train, y_train)\n\n    assert_array_equal(\n        np.argmax([p for p in model.staged_predict(X_test)], axis=1),\n        model.predict(X_test)\n    )\n"], "sample_305": ["    def test_aggregate_with_subquery(self):\n        # Regression test for #12822: DatabaseError: aggregates not allowed in\n        # WHERE clause\n\n        # The subselect works and returns results equivalent to a\n        # query with the IDs listed.\n        qs = Book.objects.values('contact').annotate(Max('id'))\n        qs = qs.order_by('contact').values_list('id__max', flat=True)\n        # don't do anything with the queryset (qs) before including it as a\n        # subquery\n        books = Book.objects.order_by('id')\n        qs1 = books.filter(id__in=qs)\n        qs2 = books.filter(id__in=list(qs))\n        self.assertEqual(list(qs1), list(qs2))\n\n        # The subselect works and returns results equivalent to a\n        # query with the IDs listed.\n        qs = Book.objects.values('contact').annotate(Max('id'))\n        qs = qs.order_by('contact').values_list('id__max', flat=True)\n        # force the queryset (qs) for the subquery to be evaluated in its\n        # current state\n        list(qs)\n        books = Book.objects.order_by('id')\n        qs1 = books.filter(id__in=qs)\n        qs2 = books.filter(id__in=list(qs))\n        self.assertEqual(list(qs1), list(qs2))\n\n        # Regression test for #12822: DatabaseError: aggregates not allowed in\n        # WHERE clause\n\n        # The subselect works and returns results equivalent to a\n        # query with the IDs listed.\n        qs = Book.objects.values('contact').annotate(Max('id'))\n        qs = qs.order_by('contact').values_list('id__max', flat=True)\n        # don't do anything with the queryset (qs) before including it as a\n        # subquery\n        books = Book.objects.order_by('id')\n        qs1 = books.filter(id__in=qs)\n        qs2 = books.filter(id__in=list(qs))\n        self.assertEqual(list(qs1), list(qs2))\n\n        # The subselect works and returns results equivalent to a\n        # query with the IDs listed.\n        qs = Book.objects.values('contact').annotate(Max('id'))\n        qs = qs.order_by('contact').values_list('id__max', flat=True)\n        # force the queryset (qs) for the subquery to be evaluated in"], "sample_964": ["def test_pydata_with_union_type_operator_old(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :annotation: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0],\n                ([desc_name, \"version\"],\n                 [desc_annotation, ([desc_sig_punctuation, ':'],\n                                    desc_sig_space,\n                                    [pending_xref, \"int\"],\n                                    desc_sig_space,\n                                    [desc_sig_punctuation, \"|\"],\n                                    desc_sig_space,\n                                    [pending_xref, \"str\"])]))\n"], "sample_774": ["def test_one_hot_encoder_sparse_output():\n    X = np.array([[3, 2, 1], [0, 1, 1]])\n    enc = OneHotEncoder(sparse=True)\n    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):\n        X_trans = enc.fit_transform(X)\n        assert sparse.isspmatrix_csr(X_trans)\n        assert_array_equal(X_trans.toarray(), [[0., 1., 0., 1., 1.],\n                                              [1., 0., 1., 0., 1.]])\n"], "sample_946": ["def test_pydata_with_union_type_operator_old(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :annotation: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0],\n                ([desc_name, \"version\"],\n                 [desc_annotation, (\": \",\n                                    [pending_xref, \"int\"],\n                                    \" \",\n                                    [desc_sig_punctuation, \"|\"],\n                                    \" \",\n                                    [pending_xref, \"str\"])]))\n"], "sample_962": ["def test_stringify_type_hints_ForwardRef():\n    from typing import ForwardRef  # type: ignore\n    assert stringify(ForwardRef(\"myint\")) == \"myint\"\n"], "sample_1013": ["def test_lambdify_with_numexpr_and_numpy():\n    if not numexpr:\n        skip(\"numexpr not installed.\")\n    if not numpy:\n        skip(\"numpy not installed.\")\n    a, b = numpy.random.randn(2, 10)\n    uf = type('uf', (Function, ),\n              {'eval' : classmethod(lambda x, y : y**2+1)})\n    func = lambdify(x, 1-uf(x), modules=['numexpr', 'numpy'])\n    assert numpy.allclose(func(a), -(a**2))\n"], "sample_459": ["    def test_integer_field_exact_lookup(self):\n        \"\"\"\n        Test that the exact lookup works correctly.\n        \"\"\"\n        instance = self.model.objects.create(value=1)\n        self.assertEqual(self.model.objects.get(value__exact=1), instance)\n"], "sample_527": ["def test_figure_subplot_mosaic():\n    fig, axs = plt.subplots(2, 2)\n    fig.subplot_mosaic(\n        [['A', 'B'],\n         ['C', 'D']],\n        sharex=True,\n        sharey=True,\n        subplot_kw={'title': 'Title'},\n        gridspec_kw={'hspace': 0.3, 'wspace': 0.4}\n    )\n    assert len(fig.axes) == 4\n    assert fig.axes[0].get_title() == 'Title'\n    assert fig.axes[1].get_title() == 'Title'\n    assert fig.axes[2].get_title() == 'Title'\n    assert fig.axes[3].get_title() == 'Title'\n    assert fig.subplotpars.hspace == 0.3\n    assert fig.subplotpars.wspace == 0.4\n"], "sample_786": ["def test_fit_transform_sparse():\n    X = sp.csr_matrix([[1, 2, 3], [4, 5, 6]])\n    est = KBinsDiscretizer(n_bins=3, encode='ordinal')\n    assert_raises(ValueError, est.fit_transform, X)\n"], "sample_387": ["    def test_inline_formset(self):\n        class MyModelAdmin(admin.ModelAdmin):\n            inlines = [InlineModelAdmin]\n\n        class MyInline(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline2(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline3(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline4(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline5(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline6(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline7(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline8(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline9(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline10(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline11(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline12(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline13(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline14(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline15(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline16(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline17(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline18(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline19(admin.StackedInline):\n            model = MyModel\n            extra = 2\n\n        class MyModelInline20(admin.StackedInline):\n            model = MyModel\n"], "sample_669": ["    def test_global_capture_is_disabled(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n                print(\"hello\")\n            \"\"\"\n        )\n        result = testdir.runpytest_subprocess(\"--capture=no\")\n        result.stdout.fnmatch_lines([\"*hello*\"])\n        assert result.ret == 0\n"], "sample_27": ["def test_headerdiff_comments_with_rtol_and_atol(self):\n    \"\"\"\n    Test that comments are compared correctly when rtol and atol are specified.\n    \"\"\"\n\n    ha = Header([(\"A\", 1, \"A\"), (\"B\", 2, \"B\"), (\"C\", 3, \"C\")])\n    hb = ha.copy()\n    hb.comments[\"B\"] = \"D\"\n    hb.comments[\"C\"] = \"E\"\n    diff = HeaderDiff(ha, hb, rtol=1e-6, atol=1e-6)\n    assert not diff.identical\n    assert diff.diff_keyword_comments == {\"B\": [(\"B\", \"D\")]}\n\n    diff = HeaderDiff(ha, hb, rtol=1e-5, atol=1e-5)\n    assert diff.identical\n\n    diff = HeaderDiff(ha, hb, rtol=1e-6, atol=1e-5)\n    assert not diff.identical\n    assert diff.diff_keyword_comments == {\"B\": [(\"B\", \"D\")]}\n\n    diff = HeaderDiff(ha, hb, rtol=1e-5, atol=1e-6)\n    assert not diff.identical\n    assert diff.diff_keyword_comments == {\"B\": [(\"B\", \"D\")]}\n\n    diff = HeaderDiff(ha, hb, rtol=1e-6, atol=1e-6)\n    assert not diff.identical\n    assert diff.diff_keyword_comments == {\"B\": [(\"B\", \"D\")]}\n\n    diff = HeaderDiff(ha, hb, rtol=1e-5, atol=1e-5)\n    assert diff.identical\n"], "sample_673": ["    def test_allow_unicode(self, testdir):\n        testdir.maketxtfile(\n            test_doc=\"\"\"\n            >>> b'12'.decode('ascii')\n            '12'\n        \"\"\"\n        )\n        reprec = testdir.inline_run()\n        reprec.assertoutcome(passed=1)\n"], "sample_710": ["def test_setup_teardown_failure_is_shown(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n        class MyTestCase(unittest.TestCase):\n                assert 0, \"down1\"\n                assert 0, \"down2\"\n                pass\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-s\")\n    assert result.ret == 1\n    result.stdout.fnmatch_lines([\"*setUp*\", \"*assert 0*down1*\", \"*tearDown*\", \"*assert 0*down2*\", \"*1 failed*\"])\n    result.stdout.no_fnmatch_line(\"*down1*\")\n"], "sample_834": ["def test_callback_with_args():\n    \"\"\"Test that the callback function is called with the correct arguments.\n\n    The callback function should be called with the current solution (flattened\n    transformation matrix) and the number of iterations.\n    \"\"\"\n    X = iris_data\n    y = iris_target\n\n        assert transformation.shape == (iris_data.shape[1]**2,)\n        assert isinstance(n_iter, int)\n\n    # assert that my_cb is called\n    nca = NeighborhoodComponentsAnalysis(max_iter=10,\n                                         callback=my_cb, verbose=1)\n    nca.fit(iris_data, iris_target)\n"], "sample_678": ["def test_symlink_or_skip(tmp_path):\n    \"\"\"Ensure that symlink_or_skip works correctly.\"\"\"\n    src = tmp_path / \"src\"\n    src.mkdir()\n    dst = tmp_path / \"dst\"\n    assert not dst.exists()\n    symlink_or_skip(src, dst)\n    assert dst.is_symlink()\n    assert dst.resolve() == src\n    dst.symlink_to(tmp_path / \"other\")\n    with pytest.raises(OSError):\n        symlink_or_skip(src, dst)\n    assert not dst.is_symlink()\n"], "sample_635": ["def test_finds_multiple_types_numpy_with_xref(self) -> None:\n    \"\"\"Example of a function with multiple types in a numpy style docstring with xref\"\"\"\n    node = astroid.extract_node(\n        f'''\n            \"\"\"The docstring\n\n            Args\n            ----\n            named_arg : {r\"`int or str`\"}: Returned\n            '''\n            return named_arg\n        '''\n    )\n    with self.assertNoMessages():\n        self.checker.visit_functiondef(node)\n"], "sample_1156": ["def test_acsch_expansion():\n    x, y = symbols('x,y')\n    assert acsch(x+y).expand(trig=True) == acsch(x)*acsch(y) + 1/(x*y*(x + y))\n    assert acsch(2*x).expand(trig=True) == acsch(x)/x**2 + 1/(2*x*(x**2 + 1))\n    assert acsch(3*x).expand(trig=True).expand() == acsch(x)**3/x**6 + 3*acsch(x)/x**4 + 1/(3*x*(x**2 + 1)**2)\n"], "sample_741": ["def test_grid_search_with_sparse_target():\n    # Test that grid search works with sparse target\n    X, y = make_blobs(n_samples=200, n_features=100, random_state=0)\n    y = sp.csr_matrix(y)\n    clf = LinearSVC()\n    cv = GridSearchCV(clf, {'C': [0.1, 1.0]})\n    cv.fit(X, y)\n    y_pred = cv.predict(X)\n    C = cv.best_estimator_.C\n\n    assert_true(np.mean(y_pred == y.toarray()) >= .9)\n    assert_equal(C, cv.best_estimator_.C)\n"], "sample_434": ["    def test_template_view_responds_correctly(self):\n        request_factory = RequestFactory()\n        view = TemplateView(template_name=\"test_template.html\")\n        response = view.get(request_factory.get(\"/\"))\n        self.assertIsInstance(response, TemplateResponse)\n"], "sample_529": ["def test_legend_framealpha():\n    fig, ax = plt.subplots()\n    ax.plot(range(100), label=\"test\")\n    leg = ax.legend(framealpha=0.5)\n    assert leg.get_frame().get_alpha() == 0.5\n"], "sample_1145": ["def test_refine_Pow_issue():\n    x = Symbol('x', real = True)\n    y = Symbol('y', real = True)\n    assert refine((-1)**(x + y), Q.even(x) & Q.even(y)) == 1\n    assert refine((-1)**(x + y), Q.even(x) & Q.odd(y)) == (-1)**y\n    assert refine((-1)**(x + y), Q.odd(x) & Q.even(y)) == (-1)**x\n    assert refine((-1)**(x + y), Q.odd(x) & Q.odd(y)) == (-1)**(x + y)\n\n    assert refine((-1)**(x + y + 1), Q.even(x) & Q.even(y)) == (-1)**(y + 1)\n    assert refine((-1)**(x + y + 1), Q.even(x) & Q.odd(y)) == (-1)**(x + 1)\n    assert refine((-1)**(x + y + 1), Q.odd(x) & Q.even(y)) == (-1)**(y + 1)\n    assert refine((-1)**(x + y + 1), Q.odd(x) & Q.odd(y)) == (-1)**(x + y + 1)\n\n    assert refine((-1)**(x + y + 2), Q.even(x) & Q.even(y)) == (-1)**(y + 1)\n    assert refine((-1)**(x + y + 2), Q.even(x) & Q.odd(y)) == (-1)**(x + 1)\n    assert refine((-1)**(x + y + 2), Q.odd(x) & Q.even(y)) == (-1)**(y + 1)\n    assert refine((-1)**(x + y + 2), Q.odd(x) & Q.odd(y)) == (-1)**(x + y + 1)\n\n    assert refine((-1)**(x + y + 3), Q.even(x) & Q.even(y)) == (-1)**(y + 2)\n    assert refine((-1)**(x + y + 3), Q.even(x) & Q.odd(y)) == (-1)**(x + 2)\n    assert refine((-1)**(x + y + "], "sample_602": ["def test_open_dataset_with_chunks():\n    ds = xr.Dataset(\n        dict(a=2 * np.arange(5)), coords=dict(x=(\"x\", np.arange(5), dict(units=\"s\")))\n    )\n\n    chunks = {\"x\": 2}\n    actual = xr.open_dataset(\"fake_filename\", engine=\"netcdf4\", chunks=chunks)\n    expected = xr.Dataset(\n        dict(a=2 * np.arange(5)), coords=dict(x=(\"x\", np.arange(5), dict(units=\"s\")))\n    )\n    expected = expected.chunk(chunks)\n    assert_identical(expected, actual)\n\n    chunks = {\"x\": 3}\n    actual = xr.open_dataset(\"fake_filename\", engine=\"netcdf4\", chunks=chunks)\n    expected = xr.Dataset(\n        dict(a=2 * np.arange(5)), coords=dict(x=(\"x\", np.arange(5), dict(units=\"s\")))\n    )\n    expected = expected.chunk(chunks)\n    assert_identical(expected, actual)\n\n    chunks = {\"x\": 1}\n    actual = xr.open_dataset(\"fake_filename\", engine=\"netcdf4\", chunks=chunks)\n    expected = xr.Dataset(\n        dict(a=2 * np.arange(5)), coords=dict(x=(\"x\", np.arange(5), dict(units=\"s\")))\n    )\n    expected = expected.chunk(chunks)\n    assert_identical(expected, actual)\n\n    chunks = {\"x\": -1}\n    actual = xr.open_dataset(\"fake_filename\", engine=\"netcdf4\", chunks=chunks)\n    expected = xr.Dataset(\n        dict(a=2 * np.arange(5)), coords=dict(x=(\"x\", np.arange(5), dict(units=\"s\")))\n    )\n    expected = expected.chunk(chunks)\n    assert_identical(expected, actual)\n\n    chunks = {\"x\": \"auto\"}\n    actual = xr.open_dataset(\"fake_filename\", engine=\"netcdf4\", chunks=chunks)\n    expected = xr.Dataset(\n        dict(a=2 * np.arange(5)), coords=dict(x=(\"x\", np.arange(5), dict(units=\"s\")))\n    )\n    expected = expected.chunk(chunks)\n    assert_identical(expected, actual)\n"], "sample_1161": ["def test_Dict_printing():\n    d = Dict({1: 1 + x, 2: y*x})\n    assert str(d) == \"{1: x + 1, 2: x*y}\"\n    assert sstr(d) == \"{1: x + 1, 2: x*y}\"\n"], "sample_70": ["    def test_delete_with_keeping_parents_and_related_objects(self):\n        child = RChild.objects.create()\n        parent_id = child.r_ptr_id\n        parent_referent_id = S.objects.create(r=child.r_ptr).pk\n        related_child = RChild.objects.create(r_ptr=child.r_ptr)\n        child.delete(keep_parents=True)\n        self.assertFalse(RChild.objects.filter(id=child.id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n        self.assertTrue(RChild.objects.filter(id=related_child.id).exists())\n"], "sample_811": ["def test_pairwise_distances_chunked_sparse():\n    # Test the pairwise_distance helper function.\n    rng = np.random.RandomState(0)\n    # Euclidean distance should be equivalent to calling the function.\n    X = rng.random_sample((400, 4))\n    X_sparse = csr_matrix(X)\n    check_pairwise_distances_chunked(X_sparse, None, working_memory=1,\n                                     metric='euclidean')\n    # Test small amounts of memory\n    for power in range(-16, 0):\n        check_pairwise_distances_chunked(X_sparse, None, working_memory=2 ** power,\n                                         metric='euclidean')\n    # X as list\n    check_pairwise_distances_chunked(X_sparse.todense().tolist(), None,\n                                     working_memory=1, metric='euclidean')\n    # Euclidean distance, with Y != X.\n    Y = rng.random_sample((200, 4))\n    Y_sparse = csr_matrix(Y)\n    check_pairwise_distances_chunked(X_sparse, Y_sparse, working_memory=1,\n                                     metric='euclidean')\n    check_pairwise_distances_chunked(X_sparse.todense().tolist(),\n                                     Y_sparse.todense().tolist(), working_memory=1,\n                                     metric='euclidean')\n    # absurdly large working_memory\n    check_pairwise_distances_chunked(X_sparse, Y_sparse, working_memory=10000,\n                                     metric='euclidean')\n    # \"cityblock\" uses scikit-learn metric, cityblock (function) is\n    # scipy.spatial.\n    check_pairwise_distances_chunked(X_sparse, Y_sparse, working_memory=1,\n                                     metric='cityblock')\n    # Test that a value error is raised if the metric is unknown\n    assert_raises(ValueError, next,\n                  pairwise_distances_chunked(X_sparse, Y_sparse, metric=\"blah\"))\n\n    # Test precomputed returns all at once\n    D = pairwise_distances(X_sparse)\n    gen = pairwise_distances_chunked(D,\n                                     working_memory=2 ** -16,\n                                     metric='precomputed')\n    assert isinstance(gen, GeneratorType)\n    assert next(gen) is D\n    assert_raises(StopIteration, next, gen)\n"], "sample_1073": ["def test_sqrtdenest5():\n    z = sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2))))\n    assert sqrtdenest(z) == z\n    z = sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2))))\n    assert sqrtdenest(z) == z\n    z = sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2)))))\n    assert sqrtdenest(z) == z\n    z = sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2))))))\n    assert sqrtdenest(z) == z\n    z = sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2 + sqrt(2)))))))\n    assert sqrtdenest(z) == z\n"], "sample_716": ["def test_ridge_solver_switch():\n    # Test that solver switch works correctly\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([1, 2])\n    alpha = 1.0\n\n    # Test that solver switch works correctly\n    ridge = Ridge(solver='cholesky')\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape, (X.shape[1], ))\n\n    # Test that solver switch works correctly\n    ridge = Ridge(solver='svd')\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape, (X.shape[1], ))\n\n    # Test that solver switch works correctly\n    ridge = Ridge(solver='sparse_cg')\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape, (X.shape[1], ))\n\n    # Test that solver switch works correctly\n    ridge = Ridge(solver='lsqr')\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape, (X.shape[1], ))\n\n    # Test that solver switch works correctly\n    ridge = Ridge(solver='sag')\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape, (X.shape[1], ))\n\n    # Test that solver switch works correctly\n    ridge = Ridge(solver='saga')\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape, (X.shape[1], ))\n\n    # Test that solver switch works correctly\n    ridge = Ridge(solver='auto')\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape, (X.shape[1], ))\n"], "sample_347": ["def test_make_naive_pytz_fold(self):\n    self.assertEqual(\n        timezone.make_naive(CET.localize(datetime.datetime(2011, 9, 1, 12, 20, 30, fold=0)), CET),\n        datetime.datetime(2011, 9, 1, 12, 20, 30)\n    )\n    self.assertEqual(\n        timezone.make_naive(CET.localize(datetime.datetime(2011, 9, 1, 12, 20, 30, fold=1)), CET),\n        datetime.datetime(2011, 9, 1, 12, 20, 30, fold=1)\n    )\n"], "sample_414": ["    def test_inline_formset_formfield_callback(self):\n        class MyInline(admin.StackedInline):\n            model = Member\n            formfield_overrides = {\n                models.CharField: {\"widget\": forms.TextInput(attrs={\"size\": 10})}\n            }\n\n        ma = MyInline(Member, admin.site)\n        ff = ma.formfield_for_dbfield(Member._meta.get_field(\"name\"), request=None)\n        self.assertIsInstance(ff.widget, forms.TextInput)\n        self.assertEqual(ff.widget.attrs[\"size\"], 10)\n"], "sample_671": ["    def test_xfail_raises(self, raises, expected, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(raises=%s)\n                raise %s()\n        \"\"\"\n            % (raises, raises)\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([f\"*{expected}*\"])\n"], "sample_992": ["def test_PythonCodePrinter_precision():\n    prntr = PythonCodePrinter(settings={'precision': 3})\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n    assert not prntr.module_imports\n    assert prntr.doprint(pi) == 'math.pi'\n    assert prntr.module_imports == {'math': {'pi'}}\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(2.12345678901234567890) == '2.123'\n"], "sample_32": ["    def test_Omega0(self, cosmo, z):\n        \"\"\"Test :meth:`astropy.cosmology.w0wzCDM.Omega0`.\n\n        This is tested in the base class, but we need to override it here because\n        this class is quite unstable.\n        \"\"\"\n        super().test_Omega0(cosmo, z)\n"], "sample_268": ["    def setUp(self):\n        self._tempdir = tempfile.TemporaryDirectory()\n        self.tempdir = Path(self._tempdir.name).resolve(strict=True).absolute()\n        self.existing_file = self.ensure_file(self.tempdir / 'test.py')\n        self.nonexistent_file = (self.tempdir / 'does_not_exist.py').absolute()\n        self.reloader = autoreload.StatReloader()\n"], "sample_355": ["    def create_users(self):\n        self.user = CustomUser._default_manager.create_user(\n            email='test@example.com',\n            password='test',\n            date_of_birth=date(2006, 4, 25)\n        )\n        self.superuser = CustomUser._default_manager.create_superuser(\n            email='test2@example.com',\n            password='test',\n            date_of_birth=date(1976, 11, 8)\n        )\n"], "sample_615": ["def test_unify_chunks() -> None:\n    array = np.arange(10)\n    variable = xr.Variable(\"x\", array)\n    data_array = xr.DataArray(variable, dims=[\"x\"], coords={\"x\": np.arange(10)})\n    dataset = xr.Dataset({\"y\": variable}, {\"x\": np.arange(10)})\n\n    unified_array, unified_variable, unified_data_array, unified_dataset = unify_chunks(\n        array, variable, data_array, dataset\n    )\n\n    assert unified_array.shape == (10,)\n    assert unified_variable.shape == (10,)\n    assert unified_data_array.shape == (10,)\n    assert unified_dataset.dims == (\"x\",)\n\n    assert unified_array.chunks == (10,)\n    assert unified_variable.chunks == (10,)\n    assert unified_data_array.chunks == (10,)\n    assert unified_dataset[\"y\"].chunks == (10,)\n\n    assert unified_array.dtype == array.dtype\n    assert unified_variable.dtype == variable.dtype\n    assert unified_data_array.dtype == data_array.dtype\n    assert unified_dataset[\"y\"].dtype == dataset[\"y\"].dtype\n\n    assert unified_array.name == \"x\"\n    assert unified_variable.name == \"x\"\n    assert unified_data_array.name == \"x\"\n    assert unified_dataset[\"y\"].name == \"y\"\n\n    assert unified_array.attrs == {}\n    assert unified_variable.attrs == {}\n    assert unified_data_array.attrs == {}\n    assert unified_dataset.attrs == {}\n\n    assert unified_array.coords == {\"x\": np.arange(10)}\n    assert unified_variable.coords == {\"x\": np.arange(10)}\n    assert unified_data_array.coords == {\"x\": np.arange(10)}\n    assert unified_dataset.coords == {\"x\": np.arange(10)}\n\n    assert unified_array.dims == (\"x\",)\n    assert unified_variable.dims == (\"x\",)\n    assert unified_data_array.dims == (\"x\",)\n    assert unified_dataset.dims == (\"x\",)\n\n    assert unified_array.sizes == {\"x\": 10}\n    assert unified_variable.sizes == {\"x\": 10}\n    assert unified_data_array.sizes == {\"x\": 10}\n    assert unified_dataset.sizes == {\"x\": 10}\n\n    assert unified_array.name == \"x\"\n    assert unified_variable.name == \"x\"\n    assert unified_data_array.name == \"x\"\n    assert unified_dataset[\"y\"].name == \"y\"\n\n    assert unified_array.attrs == {}\n    assert unified_variable.attrs == {}\n    assert unified_data_array.attrs =="], "sample_1192": ["def test_Str_vs_Symbol():\n    S = sympify\n    x = Symbol('x')\n    xu = Str('x')\n    assert x != xu\n    assert xu.is_Symbol is False\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n    assert xu.is_Symbol is False\n    assert xu.is_str is True\n"], "sample_278": ["    def setUpTestData(cls):\n        cls.example_inc = Company.objects.create(\n            name=\"Example Inc.\", num_employees=2300, num_chairs=5,\n            ceo=Employee.objects.create(firstname=\"Joe\", lastname=\"Smith\", salary=10)\n        )\n        cls.foobar_ltd = Company.objects.create(\n            name=\"Foobar Ltd.\", num_employees=3, num_chairs=4, based_in_eu=True,\n            ceo=Employee.objects.create(firstname=\"Frank\", lastname=\"Meyer\", salary=20)\n        )\n        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.gmbh = Company.objects.create(name='Test GmbH', num_employees=32, num_chairs=1, ceo=cls.max)\n"], "sample_67": ["    def test_save_m2m(self):\n        class ArticleForm(forms.ModelForm):\n            class Meta:\n                model = Article\n                fields = '__all__'\n\n        form = ArticleForm({'headline': 'Test headline', 'slug': 'test-headline', 'pub_date': '1984-02-06', 'writer': str(Writer.objects.create(name='Test writer').pk), 'article': 'Hello.', 'categories': [str(Category.objects.create(name='Test category').pk)]})\n        self.assertTrue(form.is_valid())\n        article = form.save()\n        self.assertEqual(article.headline, 'Test headline')\n        self.assertEqual(article.writer.name, 'Test writer')\n        self.assertEqual(article.categories.count(), 1)\n        self.assertEqual(article.categories.first().name, 'Test category')\n\n        # Test that save_m2m() is called on the form\n        self.assertTrue(hasattr(form, 'save_m2m'))\n\n        # Test that save_m2m() is called on the form when commit=False\n        form = ArticleForm({'headline': 'Test headline', 'slug': 'test-headline', 'pub_date': '1984-02-06', 'writer': str(Writer.objects.create(name='Test writer').pk), 'article': 'Hello.', 'categories': [str(Category.objects.create(name='Test category').pk)}, commit=False)\n        self.assertTrue(hasattr(form, 'save_m2m'))\n\n        # Test that save_m2m() is not called on the form when commit=True\n        form = ArticleForm({'headline': 'Test headline', 'slug': 'test-headline', 'pub_date': '1984-02-06', 'writer': str(Writer.objects.create(name='Test writer').pk), 'article': 'Hello.', 'categories': [str(Category.objects.create(name='Test category').pk)}, commit=True)\n        self.assertFalse(hasattr(form, 'save_m2m'))\n"], "sample_753": ["def test_logistic_regression_path_convergence():\n    # Test that the path algorithm converges\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = [1] * 100 + [-1] * 100\n    Cs = [1e3]\n    assert_warns(ConvergenceWarning, logistic_regression_path,\n                 X, y, Cs=Cs, tol=0., max_iter=1, random_state=0, verbose=1)\n"], "sample_203": ["    def test_value_placeholder_with_ipv4_address_field(self):\n        cases = [\n            ('256.1.1.1', 'invalid'),\n            ('256.1.1.256', 'invalid'),\n            ('256.1.1', 'invalid'),\n            ('256.1.1.1.1', 'invalid'),\n        ]\n        for value, code in cases:\n            with self.subTest(value=value):\n                class MyForm(forms.Form):\n                    field = forms.IPAddressField(\n                        protocol='ipv4',\n                        error_messages={code: '%(value)s'},\n                    )\n\n                form = MyForm({'field': value})\n                self.assertIs(form.is_valid(), False)\n                self.assertEqual(form.errors, {'field': [value]})\n"], "sample_17": ["    def setup_method(self):\n        self.q = np.array([1.0, 2.0, 3.0]) * u.m\n"], "sample_90": ["    def test_save_m2m(self):\n        class ArticleForm(forms.ModelForm):\n            class Meta:\n                model = Article\n                fields = '__all__'\n\n        form = ArticleForm({'headline': 'Test headline', 'slug': 'test-headline', 'pub_date': '1984-02-06', 'writer': str(Writer.objects.create(name='Test writer').pk), 'article': 'Hello.', 'categories': [str(Category.objects.create(name='Test category').pk)}})\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.save().id, Article.objects.get(headline='Test headline').id)\n        self.assertEqual(form.save().slug, 'test-headline')\n        self.assertEqual(form.save().pub_date, datetime.date(1984, 2, 6))\n        self.assertEqual(form.save().writer.name, 'Test writer')\n        self.assertEqual(form.save().article, 'Hello.')\n        self.assertEqual(form.save().categories.count(), 1)\n        self.assertEqual(form.save().categories.first().name, 'Test category')\n"], "sample_37": ["def test_sip_foc2pix():\n    \"\"\"\n    Test that sip_foc2pix() returns the correct result.\n    \"\"\"\n    header = get_pkg_data_contents('data/sip.fits', encoding='binary')\n    w = wcs.WCS(header)\n    x, y = w.sip_foc2pix(72, 72, 0)\n    assert_array_almost_equal(x, 200, decimal=1)\n    assert_array_almost_equal(y, 200, decimal=1)\n"], "sample_568": ["def test_surface3d_zsort_nan():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n\n    x, y = np.mgrid[-2:2:0.1, -2:2:0.1]\n    z = np.sin(x)**2 + np.cos(y)**2\n    z[x.shape[0] // 2:, x.shape[1] // 2:] = np.nan\n\n    ax.plot_surface(x, y, z, cmap='jet')\n    ax.view_init(elev=45, azim=145)\n"], "sample_360": ["    def tearDown(self):\n        cache.clear()\n"], "sample_361": ["def test_avoid_wrapping(self):\n    items = (\n        ('Hello, world!', 'Hello, world!'),\n        ('Hello, world!  Hello, world!', 'Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello,"], "sample_1112": ["def test_digits_negative_base():\n    assert raises(ValueError, lambda: digits(35, 1))\n    assert raises(ValueError, lambda: digits(35, 1, 3))\n    assert raises(ValueError, lambda: digits(-35, 1))\n    assert raises(ValueError, lambda: digits(-35, 1, 3))\n"], "sample_932": ["def test_enum_definitions():\n    check('enum', '{key}A', {2: \"1A\"})\n    check('enum', '{key}A : std::underlying_type<B>::type', {2: \"1A\"})\n    check('enum', '{key}A : unsigned int', {2: \"1A\"})\n    check('enum', 'public A', {2: \"1A\"}, output='{key}A')\n    check('enum', 'private {key}A', {2: \"1A\"})\n\n    check('enumerator', '{key}A', {2: \"1A\"})\n    check('enumerator', '{key}A = std::numeric_limits<unsigned long>::max()', {2: \"1A\"})\n"], "sample_58": ["def test_boundfield_html_output(self):\n    class SomeForm(Form):\n        field = CharField()\n\n            return self._html_output(\n                normal_row='<p>%(field)s %(field_name)s</p>',\n                error_row='%s',\n                row_ender='</p>',\n                help_text_html=' %s',\n                errors_on_separate_row=True,\n            )\n\n    form = SomeForm()\n    self.assertHTMLEqual(form.as_p(), '<p>Field: Field</p>')\n\n    class SomeForm(Form):\n        field = CharField()\n\n            return self._html_output(\n                normal_row='<p>%(field)s %(field_name)s</p>',\n                error_row='<p>%(errors)s</p>',\n                row_ender='</p>',\n                help_text_html=' %s',\n                errors_on_separate_row=False,\n            )\n\n    form = SomeForm()\n    self.assertHTMLEqual(form.as_p(), '<p>Field: Field</p>')\n\n    class SomeForm(Form):\n        field = CharField()\n\n            return self._html_output(\n                normal_row='<p>%(field)s %(field_name)s</p>',\n                error_row='<p>%(errors)s</p>',\n                row_ender='</p>',\n                help_text_html=' %s',\n                errors_on_separate_row=True,\n            )\n\n    form = SomeForm()\n    self.assertHTMLEqual(form.as_p(), '<p>Field: Field</p>')\n\n    class SomeForm(Form):\n        field = CharField()\n\n            return self._html_output(\n                normal_row='<p>%(field)s %(field_name)s</p>',\n                error_row='<p>%(errors)s</p>',\n                row_ender='</p>',\n                help_text_html=' %s',\n                errors_on_separate_row=False,\n            )\n\n    form = SomeForm({'field': 'value'})\n    self.assertHTMLEqual(form.as_p(), '<p>value: Field</p>')\n\n    class SomeForm(Form):\n        field = CharField()\n\n            return self._html_output(\n                normal_row='<p>%(field)s %(field_name)s</p>',\n                error_row='<p>%(errors)s</p>',\n                row_ender='</p>',\n                help_text_html=' %s',\n                errors_on_separate_row=True,\n            )\n\n    form ="], "sample_117": ["    def test_render_with_unusable_password(self):\n        # Rendering the widget with an unusable password\n        # mustn't raise an exception.\n        widget = ReadOnlyPasswordHashWidget()\n        value = 'pbkdf2_sha256$100000$a6Pucb1qSFcD$WmCkn9Hqidj48NVe5x0FEM6A9YiOqQcl/83m2Z5udm0='\n        widget.value = value\n        widget.render('name', value, {'id': 'id_password'})\n        self.assertIn(_(\"No password set.\"), widget.render('name', value, {'id': 'id_password'}))\n"], "sample_865": ["def test_min_impurity_split_warning():\n    # Test if min_impurity_split raises warning when expected.\n    X = np.arange(100)[:, np.newaxis]\n    y = np.ones(100)\n    y[:50] = 0.0\n\n    clf = DecisionTreeClassifier(random_state=0)\n    with pytest.warns(FutureWarning, match=\"The parameter 'min_impurity_split'\"):\n        clf.fit(X, y, min_impurity_split=0.5)\n"], "sample_3": ["def test_ecsv_round_trip_masked_table_serialize_null(tmpdir):\n    \"\"\"Test (mostly) round-trip of MaskedColumn through ECSV using null value\n    serialization.  Note:\n\n    >>> simple_table(masked=True)\n    <Table masked=True length=3>\n      a      b     c\n    int64 float64 str1\n    ----- ------- ----\n       --     1.0    c\n        2     2.0   --\n        3      --    e\n    \"\"\"\n    filename = str(tmpdir.join('test.ecsv'))\n\n    t = simple_table(masked=True)  # int, float, and str cols with one masked element\n    t.write(filename, serialize_method='null_value')\n\n    t2 = Table.read(filename)\n    assert t2.masked is False\n    assert t2.colnames == t.colnames\n    for name in t2.colnames:\n        # From formal perspective the round-trip columns are the \"same\"\n        assert np.all(t2[name].mask == t[name].mask)\n        assert np.all(t2[name] == t[name])\n\n        # But peeking under the mask shows that the underlying data are changed\n        # because by default ECSV uses \"\" to represent masked elements.\n        t[name].mask = False\n        t2[name].mask = False\n        assert not np.all(t2[name] == t[name])  # Expected diff\n"], "sample_911": ["def test_template_specialization():\n    check('class', 'template<int T> A', {2: 'I_iE1A'})\n    check('class', 'template<int T> A<int>', {2: 'I_iE1A'})\n    check('class', 'template<int T> A<int, int>', {2: 'I_iE1A'})\n    check('class', 'template<int T> A<int, int, int>', {2: 'I_iE1A'})\n    check('class', 'template<int T> A<int, int, int, int>', {2: 'I_iE1A'})\n    check('class', 'template<int T> A<int, int, int, int, int>', {2: 'I_iE1A'})\n    check('class', 'template<int T> A<int, int, int, int, int, int>', {2: 'I_iE1A'})\n    check('class', 'template<int T> A<int, int, int, int, int, int, int>', {2: 'I_iE1A'})\n    check('class', 'template<int T> A<int, int, int, int, int, int, int, int>', {2: 'I_iE1A'})\n    check('class', 'template<int T> A<int, int, int, int, int, int, int, int, int>', {2: 'I_iE1A'})\n    check('class', 'template<int T> A<int, int, int, int, int, int, int, int, int, int>', {2: 'I_iE1A'})\n    check('class', 'template<int T> A<int, int, int, int, int, int, int, int, int, int, int>', {2: 'I_iE1A'})\n    check('class', 'template<int T> A<int, int, int, int, int, int, int, int, int, int, int, int>', {2: 'I_iE1A'})\n    check('class', 'template<int T> A<int, int, int, int, int, int, int, int, int, int, int, int, int>', {2: 'I_iE1A'})\n    check('class', 'template<int T> A<int, int, int, int, int"], "sample_846": ["def test_column_transformer_sparse_output():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    X_res_first = np.array([[0], [1]])\n    X_res_both = X_array\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           sparse_threshold=0.8)\n    assert sparse.issparse(ct.fit_transform(X_array))\n    assert_array_equal(ct.fit_transform(X_array), X_res_first)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_first)\n\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', Trans(), [1])],\n                           sparse_threshold=0.8)\n    assert sparse.issparse(ct.fit_transform(X_array))\n    assert_array_equal(ct.fit_transform(X_array), X_res_both)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_both)\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           sparse_threshold=0.2)\n    assert not sparse.issparse(ct.fit_transform(X_array))\n    assert_array_equal(ct.fit_transform(X_array), X_res_first)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_first)\n\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', Trans(), [1])],\n                           sparse_threshold=0.2)\n    assert not sparse.issparse(ct.fit_transform(X_array))\n    assert_array_equal(ct.fit_transform(X_array), X_res_both)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_both)\n"], "sample_895": ["def test_column_transformer_set_output_after_fitting_transform():\n    \"\"\"Check column transformer behavior with set_output after fitting and transforming.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame([[1, 2, 3, 4]], columns=[\"a\", \"b\", \"c\", \"d\"], index=[10])\n    ct = ColumnTransformer(\n        [(\"first\", TransWithNames(), [\"a\", \"c\"]), (\"second\", TransWithNames(), [\"d\"])],\n        remainder=\"passthrough\",\n        verbose_feature_names_out=False,\n    )\n    X_trans = ct.fit_transform(df)\n    assert isinstance(X_trans, np.ndarray)\n\n    ct.set_output(transform=\"pandas\")\n\n    df_test = pd.DataFrame([[1, 2, 3, 4]], columns=df.columns, index=[20])\n    X_trans = ct.transform(df_test)\n    assert isinstance(X_trans, pd.DataFrame)\n    assert_array_equal(X_trans.columns, ct.get_feature_names_out())\n    assert_array_equal(X_trans.index, df_test.index)\n"], "sample_530": ["def test_packer_mode_equal():\n    fig, ax = plt.subplots()\n    r1 = DrawingArea(10, 10)\n    r2 = DrawingArea(20, 20)\n    r3 = DrawingArea(30, 30)\n    hpacker = HPacker(children=[r1, r2, r3], pad=0, sep=0, align=\"center\", mode=\"equal\")\n    renderer = fig.canvas.get_renderer()\n    *extents, offset_pairs = hpacker.get_extent_offsets(renderer)\n    assert_allclose((60, 30, 0, 0), extents)\n    assert_allclose([(15, 0), (30, 0), (45, 0)], offset_pairs)\n\n    vpacker = VPacker(children=[r1, r2, r3], pad=0, sep=0, align=\"center\", mode=\"equal\")\n    *extents, offset_pairs = vpacker.get_extent_offsets(renderer)\n    assert_allclose([30, 60, 0, 60], extents)\n    assert_allclose([(0, 15), (0, 30), (0, 45)], offset_pairs)\n"], "sample_538": ["def test_transformed_bbox():\n    t = mtransforms.Affine2D()\n    bbox = mtransforms.Bbox([[0, 0], [1, 1]])\n    trans_bbox = mtransforms.TransformedBbox(bbox, t)\n    assert_array_equal(trans_bbox.get_points(), t.transform(bbox.get_points()))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([[0, 0], [1, 1]]))\n    assert_array_equal(trans_bbox.get_points(), t.transform([["], "sample_941": ["def test_stringify_type_hints_NewType():\n    MyInt = NewType('MyInt', int)\n    assert stringify(MyInt) == \"MyInt\"\n"], "sample_426": ["def test_time_strings_override(self):\n    \"\"\"\n    Test that time_strings parameter is used correctly.\n    \"\"\"\n    time_strings = {\n        \"minute\": npgettext_lazy(\n            \"naturaltime-future\",\n            \"%(num)d minute\",\n            \"%(num)d minutes\",\n            \"num\",\n        ),\n        \"hour\": npgettext_lazy(\n            \"naturaltime-future\",\n            \"%(num)d hour\",\n            \"%(num)d hours\",\n            \"num\",\n        ),\n    }\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneminute, time_strings=time_strings),\n        \"1\\xa0minute\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.onehour, time_strings=time_strings),\n        \"1\\xa0hour\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneday, time_strings=time_strings),\n        \"1\\xa0day\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneweek, time_strings=time_strings),\n        \"1\\xa0week\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.onemonth, time_strings=time_strings),\n        \"1\\xa0month\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneyear, time_strings=time_strings),\n        \"1\\xa0year\",\n    )\n"], "sample_1103": ["def test_Pow_is_nonzero():\n    z = Symbol('z', zero=True)\n    e = z**2\n    assert e.is_zero\n    assert e.is_nonzero is False\n\n    assert Pow(0, 0, evaluate=False).is_nonzero is False\n    assert Pow(0, 3, evaluate=False).is_nonzero is False\n    assert Pow(0, oo, evaluate=False).is_nonzero is False\n    assert Pow(0, -3, evaluate=False).is_nonzero is True\n    assert Pow(0, -oo, evaluate=False).is_nonzero is True\n    assert Pow(2, 2, evaluate=False).is_nonzero is True\n\n    a = Symbol('a', zero=False)\n    assert Pow(a, 3).is_nonzero is True  # issue 7965\n\n    assert Pow(2, oo, evaluate=False).is_nonzero is True\n    assert Pow(2, -oo, evaluate=False).is_nonzero is False\n    assert Pow(S.Half, oo, evaluate=False).is_nonzero is False\n    assert Pow(S.Half, -oo, evaluate=False).is_nonzero is True\n\n    # All combinations of real/complex base/exponent\n    h = S.Half\n    T = True\n    F = False\n    N = None\n\n    pow_isnonzero = [\n        ['**',  0,  h,  1,  2, -h, -1,-2,-2*I,-I/2,I/2,1+I,oo,-oo,zoo],\n        [   0,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  N],\n        [   h,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  N],\n        [   1,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  N],\n        [   2,  F,  F,  F,  F,  F,  F,  F,  F"], "sample_310": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n        with captured_stderr() as self.docutils_stderr:\n            self.response = self.client.get(reverse('django-admindocs-models-detail', args=['admin_docs', 'Person']))\n"], "sample_267": ["    def test_database_features(self):\n        features = connection.features\n        self.assertTrue(features.supports_pragma_foreign_key_check)\n        self.assertTrue(features.supports_pragma_foreign_keys)\n        self.assertTrue(features.supports_savepoints)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions_with_savepoints)\n        self.assertTrue(features.supports_transactions_with_savepoints_and_foreign_keys)\n        self.assertTrue(features.supports_transactions_with_savepoints_and_foreign_keys_and_pragma_foreign_keys)\n        self.assertTrue(features.supports_transactions_with_savepoints_and_foreign_keys_and_pragma_foreign_keys_and_pragma_foreign_key_check)\n        self.assertTrue(features.supports_transactions_with_savepoints_and_foreign_keys_and_pragma_foreign_keys_and_pragma_foreign_key_check_and_pragma_foreign_keys)\n        self.assertTrue(features.supports_transactions_with_savepoints_and_foreign_keys_and_pragma_foreign_keys_and_pragma_foreign_key_check_and_pragma_foreign_keys_and_pragma_foreign_key_check)\n        self.assertTrue(features.supports_transactions_with_savepoints_and_foreign_keys_and_pragma_foreign_keys_and_pragma_foreign_key_check_and_pragma_foreign_keys_and_pragma_foreign_key_check_and_pragma_foreign_keys)\n        self.assertTrue(features.supports_transactions_with_savepoints_and_foreign_keys_and_pragma_foreign_keys_and_pragma_foreign_key_check_and_pragma_foreign_keys_and_pragma_foreign_key_check_and_pragma_foreign_keys_and_pragma_foreign_key_check)\n        self.assertTrue(features.supports_transactions_with_savepoints_and_foreign_keys_and_pragma_foreign_keys_and_pragma_foreign_key_check_and_pragma_foreign_keys_and_pragma_foreign_key_check_and_pragma_foreign_keys_and_pragma_foreign_key_check_and_pragma_foreign_keys)\n        self.assertTrue(features.supports_transactions_with_savepoints_and_foreign_keys_and_pragma_foreign_keys_and_pragma_foreign_key_check_and_pragma_foreign_keys_and_pragma_foreign_key_check_and_pragma_foreign_keys_and_pragma_foreign_key_check_and_pragma_foreign_keys_and_pragma_foreign_key_check)\n        self.assertTrue(features.supports_transactions_with_savepoints_and_foreign_keys_and_pragma_foreign_keys_and_pragma_foreign_key_check_and_pragma_foreign_keys_and_pragma_foreign_key_check_and_pragma_foreign_keys_and_pragma_foreign_key_check_and_pragma_foreign_keys_and_pragma_foreign_key_check"], "sample_1206": ["def test_issue_10368():\n    a = Rational(32442016954, 78058255275)\n    assert int(a) == int(-a) == 0\n"], "sample_623": ["    def create_dataset(self, shape, chunks):\n        \"\"\"Return a dataset with a variable with the given shape and chunks.\"\"\"\n        dims = tuple(f\"dim_{idx}\" for idx in range(len(shape)))\n        return xr.Dataset(\n            {\n                self.var_name: xr.Variable(\n                    dims,\n                    np.empty(shape, dtype=np.dtype(\"V1\")),\n                    encoding={\"chunks\": dict(zip(dims, chunks))},\n                )\n            }\n        )\n"], "sample_832": ["def test_bayesian_ridge_fit_intercept():\n    # Test BayesianRidge with fit_intercept=False\n    X = np.array([[1, 1], [3, 4], [5, 7], [4, 1], [2, 6], [3, 10], [3, 2]])\n    y = np.array([1, 2, 3, 2, 0, 4, 5]).T\n\n    # A Ridge regression model using an alpha value equal to the ratio of\n    # lambda_ and alpha_ from the Bayesian Ridge model must be identical\n    br_model = BayesianRidge(fit_intercept=False, compute_score=True).fit(X, y)\n    rr_model = Ridge(alpha=br_model.lambda_ / br_model.alpha_).fit(X, y)\n    assert_array_almost_equal(rr_model.coef_, br_model.coef_)\n    assert_almost_equal(rr_model.intercept_, br_model.intercept_)\n"], "sample_289": ["    def test_dictwrapper_with_none_value(self):\n            return \"*%s\" % x\n        d = DictWrapper({'a': None}, f, 'xx_')\n        self.assertIsNone(d['a'])\n"], "sample_815": ["def test_multilabel_precision_recall_fscore_support_multiclass():\n    # Test precision_recall_fscore_support on a crafted multilabel example\n    # First crafted example\n\n    y_true = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 1]])\n    y_pred = np.array([[0, 1, 0, 0], [0, 1, 0, 0], [1, 0, 1, 0]])\n\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average=None)\n\n    # tp = [0, 1, 1, 0]\n    # fn = [1, 0, 0, 1]\n    # fp = [1, 1, 0, 0]\n    # Check per class\n\n    assert_array_almost_equal(p, [0.0, 0.5, 1.0, 0.0], 2)\n    assert_array_almost_equal(r, [0.0, 1.0, 1.0, 0.0], 2)\n    assert_array_almost_equal(f, [0.0, 1 / 1.5, 1, 0.0], 2)\n    assert_array_almost_equal(s, [1, 1, 1, 1], 2)\n\n    f2 = fbeta_score(y_true, y_pred, beta=2, average=None)\n    support = s\n    assert_array_almost_equal(f2, [0, 0.83, 1, 0], 2)\n\n    # Check macro\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred,\n                                                 average=\"macro\")\n    assert_almost_equal(p, 1.5 / 4)\n    assert_almost_equal(r, 0.5)\n    assert_almost_equal(f, 2.5 / 1.5 * 0.25)\n    assert_equal(s, None)\n    assert_almost_equal(fbeta_score(y_true, y_pred, beta=2, average=\"macro\"),\n                        np.mean(f2))\n\n    # Check micro\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred,\n                                                 average=\"micro\")\n    assert_almost_equal"], "sample_163": ["    def test_password_change_fails_with_old_password_not_provided(self):\n        self.login()\n        response = self.client.post(\n            \"/password_change/\",\n            {\n                \"new_password1\": \"password1\",\n                \"new_password2\": \"password1\",\n            },\n        )\n        self.assertFormError(\n            response, PasswordChangeForm.error_messages[\"old_password_incorrect\"]\n        )\n"], "sample_367": ["    def test_cache_page_decorator_http_request(self):\n        class MyClass:\n            @cache_page(123)\n                return HttpResponse()\n\n        msg = (\n            \"cache_page didn't receive an HttpRequest. If you are decorating \"\n            \"a classmethod, be sure to use @method_decorator.\"\n        )\n        request = HttpRequest()\n        with self.assertRaisesMessage(TypeError, msg):\n            MyClass().a_view(request)\n        with self.assertRaisesMessage(TypeError, msg):\n            MyClass().a_view(HttpRequestProxy(request))\n"], "sample_567": ["def test_wrap():\n    fig = plt.figure(figsize=(6, 4))\n    s = 'This is a very long text that should be wrapped multiple times.'\n    text = fig.text(0.1, 0.7, s, wrap=True)\n    fig.canvas.draw()\n    assert text._get_wrapped_text() == ('This is a very long\\n'\n                                        'text that should be\\n'\n                                        'wrapped multiple\\n'\n                                        'times.')\n"], "sample_383": ["    def setUpTestData(cls):\n        cls.num1 = Number.objects.create(num=1)\n        cls.num2 = Number.objects.create(num=2)\n        cls.num3 = Number.objects.create(num=3)\n"], "sample_344": ["    def test_bound_field_sanity_check(self):\n        field = models.CharField(max_length=1)\n        field.model = models.Model\n        with self.assertRaisesMessage(ValueError, 'ModelState.fields cannot be bound to a model - \"field\" is.'):\n            ModelState('app', 'Model', [('field', field)])\n"], "sample_510": ["def test_matshow():\n    fig, ax = plt.subplots()\n    matshow(np.arange(9).reshape(3, 3))\n    assert ax.get_images()[0].get_array().shape == (3, 3)\n    assert ax.get_images()[0].get_array().dtype == np.int64\n    plt.close()\n"], "sample_1027": ["def test_Poly_lift():\n    assert Poly(x**4 - I*x + 17*I, x, gaussian=True).lift() == \\\n        Poly(x**16 + 2*x**10 + 578*x**8 + x**4 - 578*x**2 + 83521,\n             x, domain='QQ')\n\n    assert Poly(x**4 - I*x + 17*I, x, gaussian=True).lift(field=True) == \\\n        Poly(x**16 + 2*x**10 + 578*x**8 + x**4 - 578*x**2 + 83521,\n             x, domain='QQ')\n\n    assert Poly(x**4 - I*x + 17*I, x, gaussian=True).lift(auto=True) == \\\n        Poly(x**16 + 2*x**10 + 578*x**8 + x**4 - 578*x**2 + 83521,\n             x, domain='QQ')\n\n    assert Poly(x**4 - I*x + 17*I, x, gaussian=True).lift(auto=False) == \\\n        Poly(x**16 + 2*x**10 + 578*x**8 + x**4 - 578*x**2 + 83521,\n             x, domain='QQ')\n\n    assert Poly(x**4 - I*x + 17*I, x, gaussian=True).lift(domain='QQ') == \\\n        Poly(x**16 + 2*x**10 + 578*x**8 + x**4 - 578*x**2 + 83521,\n             x, domain='QQ')\n\n    assert Poly(x**4 - I*x + 17*I, x, gaussian=True).lift(domain='QQ', auto=True) == \\\n        Poly(x**16 + 2*x**10 + 578*x**8 + x**4 - 578*x**2 + 83521,\n             x, domain='QQ')\n\n    assert Poly(x**4 - I*x + 17*I, x, gaussian=True).lift(domain='QQ', auto=False) == \\\n        Poly(x**16 + 2*x**10 + 578*x**8 + x**4 - 578*x**2 + 83521,\n             x, domain='QQ')\n\n    assert Poly(x**4 - I*x + 17*I, x, gaussian=True).lift(domain='QQ', field=True) == \\\n        Poly(x**16 + 2*x**10 + "], "sample_433": ["def test_add_field_with_default_and_not_null(self):\n    \"\"\"\n    #23609 - Adding a field with a default and NOT NULL should work.\n    \"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=\"Ada Lovelace\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, null=False)\n"], "sample_316": ["    def test_image_dimensions_cache(self):\n        \"\"\"\n        The _get_image_dimensions() method should cache the image dimensions.\n        \"\"\"\n        img_path = os.path.join(os.path.dirname(__file__), \"test.png\")\n        with open(img_path, 'rb') as fh:\n            image = images.ImageFile(fh)\n            self.assertEqual(image.width, 540)\n            self.assertEqual(image.height, 405)\n            self.assertEqual(image.width, 540)\n            self.assertEqual(image.height, 405)\n"], "sample_314": ["    def test_render_with_unusable_password(self):\n        # Rendering the widget with an unusable password\n        # mustn't raise an exception.\n        widget = ReadOnlyPasswordHashWidget()\n        value = 'pbkdf2_sha256$100000$a6Pucb1qSFcD$WmCkn9Hqidj48NVe5x0FEM6A9YiOqQcl/83m2Z5udm0='\n        widget.value = UNUSABLE_PASSWORD_PREFIX + 'abc'\n        self.assertHTMLEqual(\n            widget.render('name', value, {'id': 'id_password'}),\n            \"\"\"\n            <div id=\"id_password\">\n                <strong>No password set.</strong>\n            </div>\n            \"\"\"\n        )\n"], "sample_591": ["    def test_merge_broadcast_equals(self):\n        ds1 = xr.Dataset({\"x\": 0})\n        ds2 = xr.Dataset({\"x\": (\"y\", [0, 0])})\n        actual = ds1.merge(ds2, compat=\"broadcast_equals\")\n        assert ds2.identical(actual)\n\n        actual = ds2.merge(ds1, compat=\"broadcast_equals\")\n        assert ds2.identical(actual)\n\n        actual = ds1.copy()\n        actual.update(ds2)\n        assert ds2.identical(actual)\n\n        ds1 = xr.Dataset({\"x\": np.nan})\n        ds2 = xr.Dataset({\"x\": (\"y\", [np.nan, np.nan])})\n        actual = ds1.merge(ds2, compat=\"broadcast_equals\")\n        assert ds2.identical(actual)\n\n        ds1 = xr.Dataset({\"x\": 0})\n        ds2 = xr.Dataset({\"x\": (\"y\", [0, 1])})\n        actual = ds1.merge(ds2, compat=\"broadcast_equals\")\n        expected = xr.Dataset({\"x\": (\"y\", [0, 1])})\n        assert expected.identical(actual)\n\n        ds1 = xr.Dataset({\"x\": 0})\n        ds2 = xr.Dataset({\"x\": (\"y\", [1, 0])})\n        actual = ds1.merge(ds2, compat=\"broadcast_equals\")\n        expected = xr.Dataset({\"x\": (\"y\", [1, 0])})\n        assert expected.identical(actual)\n\n        ds1 = xr.Dataset({\"x\": 0})\n        ds2 = xr.Dataset({\"x\": (\"y\", [0, 1])})\n        actual = ds1.merge(ds2, compat=\"broadcast_equals\", join=\"left\")\n        expected = xr.Dataset({\"x\": (\"y\", [0, 1])})\n        assert expected.identical(actual)\n\n        ds1 = xr.Dataset({\"x\": 0})\n        ds2 = xr.Dataset({\"x\": (\"y\", [1, 0])})\n        actual = ds1.merge(ds2, compat=\"broadcast_equals\", join=\"right\")\n        expected = xr.Dataset({\"x\": (\"y\", [1, 0])})\n        assert expected.identical(actual)\n\n        ds1 = xr.Dataset({\"x\": 0})\n        ds2 = xr.Dataset({\"x\": (\"y\", [0, 1])})\n        actual = ds1.merge(ds2, compat=\"broadcast_equals\", join=\"inner\")\n        expected ="], "sample_371": ["    def test_non_sensitive_request(self):\n        \"\"\"\n        Request info can bee seen in the default error reports for\n        non-sensitive requests.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n\n        with self.settings(DEBUG=False):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n"], "sample_654": ["    def test_getfixturedefs(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n                return 1\n\n            @pytest.fixture\n                return 2\n        \"\"\"\n        )\n        testdir.makepyfile(\n            \"\"\"\n                assert arg1 == 1\n                assert arg2 == 2\n        \"\"\"\n        )\n        reprec = testdir.inline_run()\n        reprec.assertoutcome(passed=1)\n        fm = reprec.getcalls(\"pytest_runtest_call\")[0].item.session._fixturemanager\n        fixturedefs = fm.getfixturedefs(\"arg1\", \"test_getfixturedefs.py::test_getfixturedefs\")\n        assert len(fixturedefs) == 1\n        assert fixturedefs[0].argname == \"arg1\"\n        fixturedefs = fm.getfixturedefs(\"arg2\", \"test_getfixturedefs.py::test_getfixturedefs\")\n        assert len(fixturedefs) == 1\n        assert fixturedefs[0].argname == \"arg2\"\n        fixturedefs = fm.getfixturedefs(\"arg1\", \"test_getfixturedefs.py::test_getfixturedefs\")\n        assert len(fixturedefs) == 1\n        assert fixturedefs[0].argname == \"arg1\"\n        fixturedefs = fm.getfixturedefs(\"arg2\", \"test_getfixturedefs.py::test_getfixturedefs\")\n        assert len(fixturedefs) == 1\n        assert fixturedefs[0].argname == \"arg2\"\n"], "sample_1190": ["def test_get_dimension_system():\n    u = Quantity(\"u\")\n    u.set_global_relative_scale_factor(S(10), meter)\n    assert u.get_dimension_system() == SI.get_dimension_system()\n    assert u.get_dimension_system() is u.get_dimension_system()\n    assert u.get_dimension_system() is not None\n    assert isinstance(u.get_dimension_system(), UnitSystem)\n"], "sample_164": ["    def test_uses_server_time(self):\n        server_time = '2016-09-25 10:20:30'\n        log_msg = 'log message'\n        logger = logging.getLogger('django.server')\n\n        @contextmanager\n            old_stream = logger.handlers[0].stream\n            new_stream = StringIO()\n            logger.handlers[0].stream = new_stream\n            yield new_stream\n            logger.handlers[0].stream = old_stream\n\n        with patch_django_server_logger() as logger_output:\n            logger.info(log_msg, extra={'server_time': server_time})\n            self.assertEqual('[%s] %s\\n' % (server_time, log_msg), logger_output.getvalue())\n\n        with patch_django_server_logger() as logger_output:\n            logger.info(log_msg)\n            self.assertNotRegex(logger_output.getvalue(), r'^\\[[/:,\\w\\s\\d]+\\] %s\\n' % log_msg)\n"], "sample_237": ["    def test_builtin_permission_name_max_length(self):\n        class Checked(models.Model):\n            class Meta:\n                permissions = [\n                    ('my_builtin_permission', 'Some permission'),\n                ]\n        errors = checks.run_checks(self.apps.get_app_configs())\n        # The max length of builtin permission name is the max length of all builtin permission names\n        # which is 15 in this case\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most 240 \"\n                \"characters for its builtin permission names to be at most 255 characters.\",\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n"], "sample_938": ["def test_definition_list(app, status, warning):\n    app.build()\n    content = (app.outdir / 'python.1').read_text()\n    assert r'\\fBterm1\\fP' in content\n    assert r'\\fBterm2\\fP' in content\n    assert r'\\fBterm3\\fP' in content\n    assert r'\\fBterm4\\fP' in content\n    assert r'\\fBterm5\\fP' in content\n    assert r'\\fBterm6\\fP' in content\n    assert r'\\fBterm7\\fP' in content\n    assert r'\\fBterm8\\fP' in content\n    assert r'\\fBterm9\\fP' in content\n    assert r'\\fBterm10\\fP' in content\n    assert r'\\fBterm11\\fP' in content\n    assert r'\\fBterm12\\fP' in content\n    assert r'\\fBterm13\\fP' in content\n    assert r'\\fBterm14\\fP' in content\n    assert r'\\fBterm15\\fP' in content\n    assert r'\\fBterm16\\fP' in content\n    assert r'\\fBterm17\\fP' in content\n    assert r'\\fBterm18\\fP' in content\n    assert r'\\fBterm19\\fP' in content\n    assert r'\\fBterm20\\fP' in content\n    assert r'\\fBterm21\\fP' in content\n    assert r'\\fBterm22\\fP' in content\n    assert r'\\fBterm23\\fP' in content\n    assert r'\\fBterm24\\fP' in content\n    assert r'\\fBterm25\\fP' in content\n    assert r'\\fBterm26\\fP' in content\n    assert r'\\fBterm27\\fP' in content\n    assert r'\\fBterm28\\fP' in content\n    assert r'\\fBterm29\\fP' in content\n    assert r'\\fBterm30\\fP' in content\n    assert r'\\fBterm31\\fP' in content\n    assert r'\\fBterm32\\fP' in content\n    assert r'\\fBterm33\\fP' in content\n    assert r'\\"], "sample_228": ["def test_formset_can_order_with_initial_data(self):\n    \"\"\"\n    Formsets with ordering + initial data.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_order=True)\n    initial = [\n        {'choice': 'Calexico', 'votes': 100},\n        {'choice': 'Fergie', 'votes': 900},\n        {'choice': 'The Decemberists', 'votes': 500},\n    ]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_304": ["    def test_decimal_validator_max_digits(self):\n        validator = DecimalValidator(max_digits=5, decimal_places=2)\n        with self.assertRaisesMessage(ValidationError, 'Ensure that there are no more than 5 digits in total.'):\n            validator(Decimal('742403889818000000'))\n"], "sample_627": ["def test_concat_fill_value_dict() -> None:\n    datasets = create_typed_datasets(2, seed=123)\n    expected1 = concat(datasets, dim=\"day\", fill_value={\"float\": 2, \"string\": \"foo\"})\n    expected2 = concat(datasets[::-1], dim=\"day\", fill_value={\"float\": 2, \"string\": \"foo\"})\n    vars = [\"float\", \"float2\", \"string\", \"int\", \"datetime64\", \"timedelta64\"]\n    expected = [expected2, expected1]\n    for i, exp in enumerate(expected):\n        sl = slice(i * 2, (i + 1) * 2)\n        exp[\"float2\"][..., sl] = np.nan\n        exp[\"datetime64\"][..., sl] = np.nan\n        exp[\"timedelta64\"][..., sl] = np.nan\n        var = exp[\"int\"] * 1.0\n        var[..., sl] = np.nan\n        exp[\"int\"] = var\n        var = exp[\"string\"].astype(object)\n        var[..., sl] = np.nan\n        exp[\"string\"] = var\n\n    # set up the test data\n    datasets[1] = datasets[1].drop_vars(vars[1:])\n\n    actual = concat(datasets, dim=\"day\", fill_value={\"float\": 2, \"string\": \"foo\"})\n\n    assert_identical(actual, expected[1])\n\n    # reversed\n    actual = concat(datasets[::-1], dim=\"day\", fill_value={\"float\": 2, \"string\": \"foo\"})\n\n    assert_identical(actual, expected[0])\n"], "sample_290": ["def test_alter_field_to_not_null_with_default(self):\n    \"\"\"\n    #23609 - Tests autodetection of nullable to non-nullable alterations.\n    \"\"\"\n    changes = self.get_changes([self.author_name], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True)\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default='Ada Lovelace')\n"], "sample_681": ["def test_log_cli_level_not_set_by_default(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_handler.level == logging.NOTSET\n            logging.getLogger('catchlog').info(\"This log message won't be shown\")\n            logging.getLogger('catchlog').warning(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n    \"\"\"\n    )\n\n    result = testdir.runpytest(\"-s\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_log_cli_level_not_set_by_default.py*This log message will be shown\",\n            \"PASSED\",  # 'PASSED' on its own line because the log message prints a new line\n        ]\n    )\n    result.stdout.no_fnmatch_line(\"*This log message won't be shown*\")\n\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n"], "sample_463": ["def test_alter_field_to_foreign_key(self):\n    \"\"\"Tests autodetection of field type changes from a concrete field to a ForeignKey.\"\"\"\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author],\n        [self.author_empty, self.book_with_author_renamed],\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(\n        changes, \"otherapp\", 0, 0, model_name=\"book\", name=\"author\"\n    )\n    self.assertEqual(\n        changes[\"otherapp\"][0].operations[0].field.deconstruct(),\n        (\n            \"author\",\n            \"django.db.models.ForeignKey\",\n            [],\n            {\"to\": \"testapp.Writer\", \"on_delete\": models.CASCADE},\n        ),\n    )\n"], "sample_348": ["    def test_invalid_expression_with_f(self):\n        class TestModelAdmin(ModelAdmin):\n            ordering = (F('nonexistent'), )\n\n        self.assertIsInvalid(\n            TestModelAdmin, ValidationTestModel,\n            \"The value of 'ordering[0]' refers to 'nonexistent', which is not \"\n            \"a field of 'modeladmin.ValidationTestModel'.\",\n            'admin.E033'\n        )\n"], "sample_1066": ["def test_print_Cross():\n    ACS = CoordSys3D('A')\n    assert mathml(Cross(ACS.i, ACS.j), printer='presentation') == \\\n        '<mrow><msub><mover><mi mathvariant=\"bold\">i</mi><mo>^</mo></mover>'\\\n        '<mi mathvariant=\"bold\">A</mi></msub><mo>&#xD7;</mo><msub><mover>'\\\n        '<mi mathvariant=\"bold\">j</mi><mo>^</mo></mover><mi mathvariant=\"bold\">'\\\n        'A</mi></msub></mrow>'\n    assert mathml(Cross(ACS.i, ACS.j*ACS.x*3+ACS.k), printer='presentation') == \\\n        '<mrow><msub><mover><mi mathvariant=\"bold\">i</mi><mo>^</mo></mover>'\\\n        '<mi mathvariant=\"bold\">A</mi></msub><mo>&#xD7;</mo><mfenced><mrow>'\\\n        '<mfenced><mrow><mn>3</mn><mo>&InvisibleTimes;</mo><msub>'\\\n        '<mi mathvariant=\"bold\">x</mi><mi mathvariant=\"bold\">A</mi></msub>'\\\n        '</mrow></mfenced><mo>&InvisibleTimes;</mo><msub><mover>'\\\n        '<mi mathvariant=\"bold\">j</mi><mo>^</mo></mover><mi mathvariant=\"bold\">'\\\n        'A</mi></msub><mo>+</mo><msub><mover><mi mathvariant=\"bold\">k</mi>'\\\n        '<mo>^</mo></mover><mi mathvariant=\"bold\">A</mi></msub></mrow></mfenced></mrow>'\n    assert mathml(x*Cross(ACS.i, ACS.j), printer='presentation') == \\\n        '<mrow><mi>x</mi><mo>&InvisibleTimes;</mo><mfenced><mrow><msub><mover>'\\\n        '<mi mathvariant=\"bold\">i</mi><mo>^</mo></mover>'\\\n        '<mi mathvariant=\"bold\">A</mi></msub><mo>&#xD7;</mo><msub><mover>'\\\n        '<mi mathvariant=\"bold\">j</mi><mo>^"], "sample_285": ["    def test_finders_list(self):\n        \"\"\"Test finders list method.\"\"\"\n        class Finder1(BaseFinder):\n                return [(1, 'storage1'), (2, 'storage2')]\n\n        class Finder2(BaseFinder):\n                return [(3, 'storage3'), (4, 'storage4')]\n\n            return [Finder1(), Finder2()]\n\n        with mock.patch('django.contrib.staticfiles.checks.get_finders', get_finders):\n            finder = get_finders()[0]\n            self.assertEqual(list(finder.list(None)), [(1, 'storage1'), (2, 'storage2')])\n            self.assertEqual(list(finder.list(['**/*.txt'])), [(1, 'storage1')])\n\n        with mock.patch('django.contrib.staticfiles.checks.get_finders', get_finders):\n            finder = get_finders()[1]\n            self.assertEqual(list(finder.list(None)), [(3, 'storage3'), (4, 'storage4')])\n            self.assertEqual(list(finder.list(['**/*.txt'])), [(3, 'storage3')])\n"], "sample_456": ["    def test_custom_renderer(self):\n        \"\"\"\n        A custom renderer passed to a formset_factory() is passed to all forms\n        and ErrorList.\n        \"\"\"\n        from django.forms.renderers import Jinja2\n\n        renderer = Jinja2()\n        data = {\n            \"choices-TOTAL_FORMS\": \"2\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Zero\",\n            \"choices-0-votes\": \"\",\n            \"choices-1-choice\": \"One\",\n            \"choices-1-votes\": \"\",\n        }\n        ChoiceFormSet = formset_factory(Choice, renderer=renderer)\n        formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertEqual(formset.renderer, renderer)\n        self.assertEqual(formset.forms[0].renderer, renderer)\n        self.assertEqual(formset.management_form.renderer, renderer)\n        self.assertEqual(formset.non_form_errors().renderer, renderer)\n        self.assertEqual(formset.empty_form.renderer, renderer)\n"], "sample_940": ["def test_isabstractmethod():\n    class Foo:\n        @abstractmethod\n            pass\n\n    class Bar(Foo):\n            pass\n\n    assert inspect.isabstractmethod(Foo.meth) is True\n    assert inspect.isabstractmethod(Bar.meth) is False\n    assert inspect.isabstractmethod(Foo().meth) is False\n    assert inspect.isabstractmethod(Bar().meth) is False\n\n    class AbstractClass(metaclass=abc.ABCMeta):\n        @abc.abstractmethod\n            pass\n\n    class ConcreteClass(AbstractClass):\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.meth) is True\n    assert inspect.isabstractmethod(ConcreteClass.meth) is False\n    assert inspect.isabstractmethod(AbstractClass().meth) is False\n    assert inspect.isabstractmethod(ConcreteClass().meth) is False\n"], "sample_1048": ["def test_parabola_equation():\n    a, b = symbols('a b')\n    p1 = Point(0, 0)\n    p2 = Point(3, 7)\n    p3 = Point(0, 4)\n    p4 = Point(6, 0)\n    p5 = Point(a, a)\n    d1 = Line(Point(4, 0), Point(4, 9))\n    d2 = Line(Point(7, 6), Point(3, 6))\n    d3 = Line(Point(4, 0), slope=oo)\n    d4 = Line(Point(7, 6), slope=0)\n    d5 = Line(Point(b, a), slope=oo)\n    d6 = Line(Point(a, b), slope=0)\n\n    pa1 = Parabola(None, d2)\n    pa2 = Parabola(directrix=d1)\n    pa3 = Parabola(p1, d1)\n    pa4 = Parabola(p2, d2)\n    pa5 = Parabola(p2, d4)\n    pa6 = Parabola(p3, d2)\n    pa7 = Parabola(p2, d1)\n    pa8 = Parabola(p4, d1)\n    pa9 = Parabola(p4, d3)\n    pa10 = Parabola(p5, d5)\n    pa11 = Parabola(p5, d6)\n\n    # equation\n    assert pa1.equation() == -x**2 - 16*y + 64\n    assert pa2.equation() == -x**2 - 16*y + 64\n    assert pa3.equation() == -x**2 - 16*y + 64\n    assert pa4.equation() == -x**2 - 16*y + 64\n    assert pa5.equation() == -y**2 - 16*x + 64\n    assert pa6.equation() == -x**2 - 16*y + 64\n    assert pa7.equation() == -y**2 - 16*x + 64\n    assert pa8.equation() == -x**2 + 16*y + 64\n    assert pa9.equation() == -y**2 + 16*x + 64\n    assert pa10.equation() == -y**2 - "], "sample_548": ["def test_colorbar_single_scatter():\n    # Issue #2642: if a path collection has only one entry,\n    # the norm scaling within the colorbar must ensure a\n    # finite range, otherwise a zero denominator will occur in _locate.\n    plt.figure()\n    x = y = [0]\n    z = [50]\n    cmap = mpl.colormaps['jet'].resampled(16)\n    cs = plt.scatter(x, y, z, c=z, cmap=cmap)\n    plt.colorbar(cs)\n"], "sample_714": ["def test_fbeta_score_multiclass():\n    # Test fbeta_score function for multiclass classification task\n    y_true, y_pred, _ = make_prediction(binary=False)\n\n    # compute scores with default labels introspection\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average=None)\n    assert_array_almost_equal(p, [0.83, 0.33, 0.42], 2)\n    assert_array_almost_equal(r, [0.79, 0.09, 0.90], 2)\n    assert_array_almost_equal(f, [0.81, 0.15, 0.57], 2)\n    assert_array_equal(s, [24, 31, 20])\n\n    # averaging tests\n    fs = fbeta_score(y_true, y_pred, average='micro')\n    assert_array_almost_equal(fs, 0.53, 2)\n\n    fs = fbeta_score(y_true, y_pred, average='macro')\n    assert_array_almost_equal(fs, 0.51, 2)\n\n    fs = fbeta_score(y_true, y_pred, average='weighted')\n    assert_array_almost_equal(fs, 0.47, 2)\n\n    assert_raises(ValueError, fbeta_score, y_true, y_pred, average=\"samples\")\n\n    # same prediction but with and explicit label ordering\n    p, r, f, s = precision_recall_fscore_support(\n        y_true, y_pred, labels=[0, 2, 1], average=None)\n    assert_array_almost_equal(p, [0.83, 0.41, 0.33], 2)\n    assert_array_almost_equal(r, [0.79, 0.90, 0.10], 2)\n    assert_array_almost_equal(f, [0.81, 0.57, 0.15], 2)\n    assert_array_equal(s, [24, 20, 31])\n\n    # check that fbeta_score behaves correctly when beta is 1\n    fs = fbeta_score(y_true, y_pred, average='micro', beta=1)\n    assert_array_almost_equal(fs, 0.53, 2)\n\n    fs = fbeta_score(y_true, y_pred, average='macro', beta=1)\n    assert_array_almost_equal(fs, 0.51, 2)\n\n    fs = fbeta_score(y_true, y_pred, average"], "sample_775": ["def test_nmf():\n    # Render a NMF object\n    nmf = NMF(n_components=5, init='random', random_state=42, tol=0.0001,\n              max_iter=200, alpha=0.0, l1_ratio=0.0, shuffle=True, solver='cd',\n              verbose=0)\n    expected = \"\"\""], "sample_301": ["    def test_iter_modules_and_files_with_zip_import(self):\n        \"\"\"\n        Modules imported from zipped files have their archive location included\n        in the result.\n        \"\"\"\n        zip_file = self.temporary_file('zip_import.zip')\n        with zipfile.ZipFile(str(zip_file), 'w', zipfile.ZIP_DEFLATED) as zipf:\n            zipf.writestr('test_zipped_file.py', '')\n\n        with extend_sys_path(str(zip_file)):\n            self.import_and_cleanup('test_zipped_file')\n        self.assertFileFound(zip_file)\n"], "sample_539": ["def test_Cursor(ax):\n    cursor = widgets.Cursor(ax, horizOn=True, vertOn=True)\n    assert cursor.visible\n    assert cursor.horizOn\n    assert cursor.vertOn\n    assert cursor.useblit is False\n\n    cursor.visible = False\n    assert not cursor.visible\n\n    cursor.visible = True\n    assert cursor.visible\n\n    cursor.horizOn = False\n    assert not cursor.horizOn\n    cursor.horizOn = True\n    assert cursor.horizOn\n\n    cursor.vertOn = False\n    assert not cursor.vertOn\n    cursor.vertOn = True\n    assert cursor.vertOn\n\n    cursor.useblit = True\n    assert cursor.useblit\n    cursor.useblit = False\n    assert not cursor.useblit\n\n    cursor.lineh.set_visible(False)\n    assert not cursor.lineh.get_visible()\n    cursor.lineh.set_visible(True)\n    assert cursor.lineh.get_visible()\n\n    cursor.linev.set_visible(False)\n    assert not cursor.linev.get_visible()\n    cursor.linev.set_visible(True)\n    assert cursor.linev.get_visible()\n\n    cursor._update()\n    assert cursor.lineh.get_xdata() == (0, 0)\n    assert cursor.linev.get_ydata() == (0, 0)\n\n    cursor.lineh.set_xdata((10, 10))\n    cursor.linev.set_ydata((10, 10))\n    cursor._update()\n    assert cursor.lineh.get_xdata() == (10, 10)\n    assert cursor.linev.get_ydata() == (10, 10)\n\n    cursor.visible = False\n    cursor._update()\n    assert not cursor.lineh.get_visible()\n    assert not cursor.linev.get_visible()\n"], "sample_1044": ["def test_Pow_is_transcendental():\n    from sympy import Pow, exp, log, sin, cos, tan, sqrt, atan, asin, acos, atan2, asin, acosl, asinl, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, asin, acosl, as"], "sample_1092": ["def test_issue_12345():\n    # Test that cse can handle a large number of expressions\n    nexprs, nterms = 100, 20\n    x = symbols('x:%d' % nterms)\n    exprs = [\n        reduce(add, [x[j]*(-1)**(i+j) for j in range(nterms)])\n        for i in range(nexprs)\n    ]\n    assert (exprs[0] + exprs[1]).simplify() == 0\n    subst, red = cse(exprs)\n    assert len(subst) > 0, \"exprs[0] == -exprs[2], i.e. a CSE\"\n    for i, e in enumerate(red):\n        assert (e.subs(reversed(subst)) - exprs[i]).simplify() == 0\n"], "sample_951": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n        pass\n\n    @singledispatch\n        pass\n\n    @dispatch.register\n        pass\n\n    @dispatch.register\n        pass\n\n    assert inspect.is_singledispatch_function(func) is False\n    assert inspect.is_singledispatch_function(dispatch) is True\n    assert inspect.is_singledispatch_function(dispatch.register) is False\n"], "sample_822": ["def test_pairwise_distances_chunked_sparse():\n    # Test the pairwise_distance helper function.\n    rng = np.random.RandomState(0)\n    # Euclidean distance should be equivalent to calling the function.\n    X = rng.random_sample((400, 4))\n    X_sparse = csr_matrix(X)\n    check_pairwise_distances_chunked(X_sparse, None, working_memory=1,\n                                     metric='euclidean')\n    # Test small amounts of memory\n    for power in range(-16, 0):\n        check_pairwise_distances_chunked(X_sparse, None, working_memory=2 ** power,\n                                         metric='euclidean')\n    # X as list\n    check_pairwise_distances_chunked(X_sparse.todense().tolist(), None,\n                                     working_memory=1, metric='euclidean')\n    # Euclidean distance, with Y != X.\n    Y = rng.random_sample((200, 4))\n    Y_sparse = csr_matrix(Y)\n    check_pairwise_distances_chunked(X_sparse, Y_sparse, working_memory=1,\n                                     metric='euclidean')\n    check_pairwise_distances_chunked(X_sparse.todense().tolist(),\n                                     Y_sparse.todense().tolist(), working_memory=1,\n                                     metric='euclidean')\n    # absurdly large working_memory\n    check_pairwise_distances_chunked(X_sparse, Y_sparse, working_memory=10000,\n                                     metric='euclidean')\n    # \"cityblock\" uses scikit-learn metric, cityblock (function) is\n    # scipy.spatial.\n    check_pairwise_distances_chunked(X_sparse, Y_sparse, working_memory=1,\n                                     metric='cityblock')\n    # Test that a value error is raised if the metric is unknown\n    assert_raises(ValueError, next,\n                  pairwise_distances_chunked(X_sparse, Y_sparse, metric=\"blah\"))\n\n    # Test precomputed returns all at once\n    D = pairwise_distances(X_sparse)\n    gen = pairwise_distances_chunked(D,\n                                     working_memory=2 ** -16,\n                                     metric='precomputed')\n    assert isinstance(gen, GeneratorType)\n    assert next(gen) is D\n    assert_raises(StopIteration, next, gen)\n"], "sample_275": ["    def test_delete_with_select_related(self):\n        \"\"\"\n        Deleting a queryset with select_related() should work correctly.\n        \"\"\"\n        h = House.objects.create(address='Foo')\n        OrderedPerson.objects.create(name='Jack', lives_in=h)\n        OrderedPerson.objects.create(name='Bob', lives_in=h)\n        OrderedPerson.objects.select_related('lives_in').filter(lives_in__address='Foo').delete()\n        self.assertEqual(OrderedPerson.objects.count(), 0)\n"], "sample_715": ["def test_cross_validate_sparse_input():\n    # Check that cross_validate allows sparse input\n    X = np.arange(200, dtype=np.float64).reshape(10, -1)\n    X[2, :] = np.nan\n    X_sparse = coo_matrix(X)\n    y = np.repeat([0, 1], X.shape[0] / 2)\n    p = Pipeline([\n        ('imputer', Imputer(strategy='mean', missing_values='NaN')),\n        ('classifier', MockClassifier()),\n    ])\n    result = cross_validate(p, X_sparse, y, cv=5)\n    assert_array_almost_equal(result['test_score'], [1.0, 1.0, 1.0, 1.0, 1.0])\n"], "sample_420": ["    def test_save_m2m(self):\n        # Test that save_m2m() is called when commit=False.\n        class TestModel(models.Model):\n            pass\n\n        class TestForm(forms.ModelForm):\n            class Meta:\n                model = TestModel\n                fields = \"__all__\"\n\n        form = TestForm({\"name\": \"Test\"}, instance=TestModel())\n        self.assertTrue(form.is_valid())\n        form.save(commit=False)\n        self.assertTrue(hasattr(form, \"save_m2m\"))\n        form.save_m2m()\n"], "sample_1111": ["def test_zero_function():\n    x = Symbol('x')\n    lines = [\n        '      0 |                                                     ...',\n        '        |                                                   ...  ',\n        '        |                                                ...    ',\n        '        |                                              ...      ',\n        '        |                                            ...        ',\n        '        |                                          ...          ',\n        '        |                                        ...            ',\n        '        |                                      ...              ',\n        '        |                                    ...                ',\n        '        |                                   ...                 ',\n        '      0 |-----------------------------------------------...-----',\n        '        |                                ...                     ',\n        '        |                               ...                      ',\n        '        |                              ...                       ',\n        '        |                             ...                        ',\n        '        |                            ...                         ',\n        '        |                           ...                          ',\n        '        |                          ...                           ',\n        '        |                         ...                            ',\n        '        |                        ...                             ',\n        '        |                       ...                              ',\n        '        |                      ...                               ',\n        '        |                     ...                                ',\n        '        |                    ...                                 ',\n        '        |                   ...                                  ',\n        '        |                  ...                                   ',\n        '        |                 ...                                    ',\n        '        |                ...                                     ',\n        '        |               ...                                      ',\n        '        |              ...                                       ',\n        '        |             ...                                        ',\n        '        |            ...                                         ',\n        '        |           ...                                          ',\n        '        |          ...                                           ',\n        '        |         ...                                            ',\n        '        |        ...                                             ',\n        '        |       ...                                              ',\n        '        |      ...                                               ',\n        '        |     ...                                                ',\n        '        |    ...                                                 ',\n        '        |   ...                                                  ',\n        '        |  ...                                                   ',\n        '        | ...                                                    ',\n        '        |...                                                     ',\n        '     -1 |_______________________________________________________',\n        '         -1                         0                          1'\n    ]\n    assert list(textplot_str(0, -1, 1)) == lines\n"], "sample_607": ["def test_sort_backends():\n    dummy_pkg_entrypoints = [\n        pkg_resources.EntryPoint.parse(\n            \"dummy2 = xarray.tests.test_plugins:backend_1\",\n        ),\n        pkg_resources.EntryPoint.parse(\n            \"dummy1 = xarray.tests.test_plugins:backend_1\",\n        ),\n        pkg_resources.EntryPoint.parse(\n            \"dummy3 = xarray.tests.test_plugins:backend_2\",\n        ),\n    ]\n    backend_entrypoints = plugins.backends_dict_from_pkg(dummy_pkg_entrypoints)\n    sorted_backends = plugins.sort_backends(backend_entrypoints)\n    assert list(sorted_backends.keys()) == [\"dummy1\", \"dummy2\", \"dummy3\"]\n"], "sample_582": ["def test_app_group_context(runner):\n    @click.group(cls=AppGroup)\n        pass\n\n    @cli.command()\n    @with_appcontext\n        click.echo(current_app.name)\n\n    @cli.group()\n        pass\n\n    @subgroup.command()\n    @with_appcontext\n        click.echo(current_app.name)\n\n    obj = ScriptInfo(create_app=lambda: Flask(\"testappgroup\"))\n\n    result = runner.invoke(cli, [\"test\"], obj=obj)\n    assert result.exit_code == 0\n    assert result.output == \"testappgroup\\n\"\n\n    result = runner.invoke(cli, [\"subgroup\", \"test2\"], obj=obj)\n    assert result.exit_code == 0\n    assert result.output == \"testappgroup\\n\"\n"], "sample_324": ["    def _get_GET_csrf_cookie_request(self, cookie=None):\n        \"\"\"The cookie argument defaults to the valid test cookie.\"\"\"\n        if cookie is None:\n            cookie = self._csrf_id_cookie\n        req = TestingHttpRequest()\n        req.COOKIES[settings.CSRF_COOKIE_NAME] = cookie\n        return req\n"], "sample_758": ["def test_check_array_large_sparse():\n    # Test that check_array raises a ValueError when a large sparse matrix\n    # is not accepted.\n    X = sp.rand(20, 10, format='csr')\n    for attr in ['indices', 'indptr', 'row', 'col']:\n        if hasattr(X, attr):\n            setattr(X, attr, getattr(X, attr).astype('int64'))\n    assert_raises_regex(ValueError, \"Only sparse matrices with 32-bit integer\"\n                        \" indices are accepted. Got int64 indices.\",\n                        check_array, X, accept_sparse=True,\n                        accept_large_sparse=False)\n"], "sample_573": ["def test_order_change(self, df):\n\n    groupby = GroupBy([\"group\"])\n    res = PolyFit(order=3, gridsize=100)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n\n    assert_array_equal(res.columns, [\"x\", \"y\"])\n\n    grid = np.linspace(df[\"x\"].min(), df[\"x\"].max(), 100)\n    assert_array_almost_equal(\n        res[\"y\"], np.polyval(np.polyfit(df[\"x\"], df[\"y\"], 3), grid)\n    )\n"], "sample_1091": ["def test_issue_17329():\n    from sympy import symbols, sin, cos, Eq, trigsimp\n    x = symbols('x')\n    s, c = sin(x), cos(x)\n    eq = Eq(s, c)\n    assert trigsimp(eq) == eq  # no rearrangement of sides\n    # simplification of sides might result in\n    # an unevaluated Eq\n    changed = trigsimp(Eq(s + c, sqrt(2)))\n    assert isinstance(changed, Eq)\n    assert changed.subs(x, pi/8) is S.true\n    # or an evaluated one\n    assert trigsimp(Eq(cos(x)**2 + sin(x)**2, 1)) is S.true\n"], "sample_122": ["    def tearDown(self):\n        cache.clear()\n"], "sample_580": ["def test_variable_type_datetime_with_object_dtype():\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=object)\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"object\")\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"string\")\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"string\")\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"string\")\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"string\")\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"string\")\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"string\")\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"string\")\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"string\")\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"string\")\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"string\")\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"string\")\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"string\")\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"string\")\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"string\")\n    assert variable_type(s) == \"datetime\"\n\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)], dtype=\"string\")\n"], "sample_978": ["def test_repeated_degree_3():\n    d = 3\n    knots = [0, 0, 1, 2, 2, 3, 4, 4]\n    splines = bspline_basis_set(d, knots, x)\n    b0 = Piecewise(\n        (x**3/6, And(x <= 1, x >= 0)),\n        (Rational(2, 3) - 2*x + 2*x**2 - x**3/2, And(x <= 2, x >= 1)),\n        (Rational(-22, 3) + 10*x - 4*x**2 + x**3/2, And(x <= 3, x >= 2)),\n        (Rational(32, 3) - 8*x + 2*x**2 - x**3/6, And(x <= 4, x >= 3)),\n        (0, True)\n    )\n    b1 = Piecewise(\n        (x**3/2 - 4*x**2 + 10*x - 22/3, And(x <= 1, x >= 0)),\n        (Rational(2, 3) - 2*x + 2*x**2 - x**3/2, And(x <= 2, x >= 1)),\n        (Rational(-22, 3) + 10*x - 4*x**2 + x**3/2, And(x <= 3, x >= 2)),\n        (Rational(32, 3) - 8*x + 2*x**2 - x**3/6, And(x <= 4, x >= 3)),\n        (0, True)\n    )\n    b2 = Piecewise(\n        (x**3/2 - 4*x**2 + 10*x - 22/3, And(x <= 2, x >= 1)),\n        (Rational(-22, 3) + 10*x - 4*x**2 + x**3/2, And(x <= 3, x >= 2)),\n        (Rational(32, 3) - 8*x + 2*x**2 - x**3/6, And(x <= 4, x >= 3)),\n        (0, True)\n    )\n    b3 = Piecewise(\n        (x**3/2 - 4*x"], "sample_929": ["def test_pydata_annotation(app):\n    text = (\".. py:data:: var\\n\"\n            \"   :type: int\\n\"\n            \"   :value: 1\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"var\"],\n                                                    [desc_annotation, (\": \",\n                                                                       [pending_xref, \"int\"])],\n                                                    [desc_annotation, \" = 1\"])],\n                                  [desc_content, ()])]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_annotation, \" = 1\"])\n    assert 'var' in app.env.domains['py'].objects\n    assert app.env.domains['py'].objects['var'] == ('index', 'var', 'data')\n"], "sample_78": ["    def test_command_error_message(self):\n        \"\"\"CommandError should have a sensible error message.\"\"\"\n        e = CommandError(\"Something went wrong\")\n        self.assertIn(\"Error: Something went wrong\", str(e))\n"], "sample_369": ["def test_alter_field_to_fk_dependency_other_app_with_unique_together(self):\n    \"\"\"\n    #23100 - ForeignKeys correctly depend on other apps' models.\n    \"\"\"\n    changes = self.get_changes([self.author_empty, self.book], [self.author_empty, self.book_with_no_author_fk])\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '__first__')])\n"], "sample_792": ["def test_multinomialnb_alpha_vector():\n    # Test MultinomialNB with alpha as a vector\n    X = np.array([[1, 2], [1, 2], [1, 0]])\n    y = np.array([0, 0, 1])\n    alpha = np.array([1, 2])\n    clf = MultinomialNB(alpha=alpha)\n    clf.fit(X, y)\n    assert_array_almost_equal(clf.feature_log_prob_, np.log(np.array([[1 / 2, 1 / 2], [2 / 5, 3 / 5]])))\n    prob = np.array([[5 / 9, 4 / 9], [25 / 49, 24 / 49]])\n    assert_array_almost_equal(clf.predict_proba(X), prob)\n\n    # Test alpha non-negative\n    alpha = np.array([1., -0.1])\n    expected_msg = ('Smoothing parameter alpha = -1.0e-01. '\n                    'alpha should be > 0.')\n    m_nb = MultinomialNB(alpha=alpha)\n    assert_raise_message(ValueError, expected_msg, m_nb.fit, X, y)\n\n    # Test that too small pseudo-counts are replaced\n    ALPHA_MIN = 1e-10\n    alpha = np.array([ALPHA_MIN / 2, 0.5])\n    m_nb = MultinomialNB(alpha=alpha)\n    m_nb.partial_fit(X, y)\n    assert_array_almost_equal(m_nb._check_alpha(),\n                              [ALPHA_MIN, 0.5],\n                              decimal=12)\n\n    # Test correct dimensions\n    alpha = np.array([1., 2., 3.])\n    m_nb = MultinomialNB(alpha=alpha)\n    expected_msg = ('alpha should be a scalar or a numpy array '\n                    'with shape [n_features]')\n    assert_raise_message(ValueError, expected_msg, m_nb.fit, X, y)\n"], "sample_889": ["def test_calibration_with_non_fitted_base_estimator():\n    \"\"\"Check that we raise an error if the base estimator is not fitted.\"\"\"\n    X, y = load_iris(return_X_y=True)\n    clf = LogisticRegression()\n    calib_clf = CalibratedClassifierCV(clf, cv=\"prefit\")\n    with pytest.raises(NotFittedError):\n        calib_clf.fit(X, y)\n"], "sample_864": ["def test_mean_shift_seeds():\n    # Test MeanShift algorithm with custom seeds\n    ms = MeanShift(seeds=[[1, 1], [-1, -1], [1, -1]])\n    labels = ms.fit(X).labels_\n    labels_unique = np.unique(labels)\n    n_clusters_ = len(labels_unique)\n    assert n_clusters_ == 3\n    assert labels_unique[0] == 0\n    assert labels_unique[1] == 1\n    assert labels_unique[2] == 2\n\n    cluster_centers, labels_mean_shift = mean_shift(X, seeds=[[1, 1], [-1, -1], [1, -1]])\n    labels_mean_shift_unique = np.unique(labels_mean_shift)\n    n_clusters_mean_shift = len(labels_mean_shift_unique)\n    assert n_clusters_mean_shift == 3\n    assert labels_mean_shift_unique[0] == 0\n    assert labels_mean_shift_unique[1] == 1\n    assert labels_mean_shift_unique[2] == 2\n"], "sample_894": ["def check_max_depth(name):\n    # Test that max_depth is respected.\n    X, y = hastie_X, hastie_y\n    ForestEstimator = FOREST_ESTIMATORS[name]\n    est = ForestEstimator(max_depth=1, n_estimators=1, random_state=0)\n    est.fit(X, y)\n    assert est.estimators_[0].get_depth() == 1\n\n"], "sample_251": ["    def setUpTestData(cls):\n        cls.a1 = Author.objects.create(name='Adrian Holovaty', age=34)\n        cls.a2 = Author.objects.create(name='Jacob Kaplan-Moss', age=35)\n        cls.a3 = Author.objects.create(name='Brad Dayley', age=45)\n        cls.a4 = Author.objects.create(name='James Bennett', age=29)\n        cls.a5 = Author.objects.create(name='Jeffrey Forcier', age=37)\n        cls.a6 = Author.objects.create(name='Paul Bissex', age=29)\n        cls.a7 = Author.objects.create(name='Wesley J. Chun', age=25)\n        cls.a8 = Author.objects.create(name='Peter Norvig', age=57)\n        cls.a9 = Author.objects.create(name='Stuart Russell', age=46)\n        cls.a1.friends.add(cls.a2, cls.a4)\n        cls.a2.friends.add(cls.a1, cls.a7)\n        cls.a4.friends.add(cls.a1)\n        cls.a5.friends.add(cls.a6, cls.a7)\n        cls.a6.friends.add(cls.a5, cls.a7)\n        cls.a7.friends.add(cls.a2, cls.a5, cls.a6)\n        cls.a8.friends.add(cls.a9)\n        cls.a9.friends.add(cls.a8)\n\n        cls.p1 = Publisher.objects.create(name='Apress', num_awards=3)\n        cls.p2 = Publisher.objects.create(name='Sams', num_awards=1)\n        cls.p3 = Publisher.objects.create(name='Prentice Hall', num_awards=7)\n        cls.p4 = Publisher.objects.create(name='Morgan Kaufmann', num_awards=9)\n        cls.p5 = Publisher.objects.create(name=\"Jonno's House of Books\", num_awards=0)\n\n        cls.b1 = Book.objects.create(\n            isbn='159059725', name='The Definitive Guide to Django: Web Development Done Right',\n            pages=447, rating=4.5, price=Decimal('30.00'), contact=cls.a1, publisher=cls.p1,\n            pubdate=datetime.date(2007, 12, 6)\n        )\n        cls.b2 = Book.objects.create(\n            isbn='067232959', name='Sams Teach Yourself Django in 24 Hours',\n            pages=528, rating=3.0,"], "sample_110": ["    def setUpTestData(cls):\n        cls.h1 = Happening.objects.create(when=datetime.datetime(2022, 1, 1))\n        cls.h2 = Happening.objects.create(when=datetime.datetime(2022, 1, 2))\n        cls.h3 = Happening.objects.create(when=datetime.datetime(2022, 1, 3))\n"], "sample_691": ["def test_timeout_config_value_invalid_input(pytester: Pytester) -> None:\n    \"\"\"Test that get_timeout_config_value returns 0.0 when invalid input is provided.\"\"\"\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        faulthandler_timeout = invalid\n        \"\"\"\n    )\n    assert FaultHandlerHooks.get_timeout_config_value(pytester.config) == 0.0\n"], "sample_711": ["def test_repr_failure_py() -> None:\n    \"\"\"Test that repr_failure_py() returns a TerminalRepr instance.\"\"\"\n    node = nodes.Item(\"test_func\")\n    excinfo = nodes.ExceptionInfo(Exception(\"test exception\"))\n    result = node._repr_failure_py(excinfo)\n    assert isinstance(result, nodes.TerminalRepr)\n"], "sample_293": ["    def test_include_urls(self):\n        self.assertEqual(include(self.url_patterns), (self.url_patterns, None, None))\n"], "sample_453": ["    def test_prepopulated_fields_js(self):\n        \"\"\"\n        prepopulated_fields_js template tag should pass whole context.\n        \"\"\"\n        article = Article.objects.all()[0]\n        request = self.request_factory.get(\n            reverse(\"admin:admin_views_article_change\", args=[article.pk])\n        )\n        request.user = self.superuser\n        admin = ArticleAdmin(Article, site)\n        extra_context = {\"extra\": True}\n        response = admin.change_view(\n            request, str(article.pk), extra_context=extra_context\n        )\n        template_context = prepopulated_fields_js(response.context_data)\n        self.assertIs(template_context[\"extra\"], True)\n        self.assertIn(\"prepopulated_fields\", template_context)\n        self.assertIn(\"prepopulated_fields_json\", template_context)\n"], "sample_877": ["def test_isotonic_regression_out_of_bounds_clip_with_ties():\n    # Setup examples with ties on minimum and maximum\n    x = [1, 1, 2, 2, 3, 3, 4, 4, 5, 5]\n    y = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n    y_true = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n    # Check that we get identical results for fit/transform and fit_transform\n    ir = IsotonicRegression(increasing=True, out_of_bounds=\"clip\")\n    ir.fit(x, y)\n    assert_array_equal(ir.fit(x, y).transform(x), ir.fit_transform(x, y))\n    assert_array_equal(y_true, ir.fit_transform(x, y))\n"], "sample_450": ["def test_get_admin_log(self):\n    \"\"\"\n    Test the get_admin_log template tag.\n    \"\"\"\n    # Test with limit and varname\n    response = self.client.get(reverse(\"admin:index\"))\n    self.assertContains(response, \"get_admin_log 10 as admin_log\")\n    self.assertContains(response, \"get_admin_log 10 as admin_log for_user user\")\n    self.assertContains(response, \"get_admin_log 10 as admin_log for_user 23\")\n\n    # Test with limit only\n    response = self.client.get(reverse(\"admin:index\"))\n    self.assertContains(response, \"get_admin_log 10\")\n\n    # Test with invalid limit\n    response = self.client.get(reverse(\"admin:index\"))\n    self.assertContains(response, \"get_admin_log invalid_limit as admin_log\")\n    self.assertContains(response, \"get_admin_log invalid_limit as admin_log for_user user\")\n    self.assertContains(response, \"get_admin_log invalid_limit as admin_log for_user 23\")\n\n    # Test with invalid varname\n    response = self.client.get(reverse(\"admin:index\"))\n    self.assertContains(response, \"get_admin_log 10 as invalid_varname\")\n    self.assertContains(response, \"get_admin_log 10 as invalid_varname for_user user\")\n    self.assertContains(response, \"get_admin_log 10 as invalid_varname for_user 23\")\n\n    # Test with invalid for_user\n    response = self.client.get(reverse(\"admin:index\"))\n    self.assertContains(response, \"get_admin_log 10 as admin_log for_user invalid_user\")\n    self.assertContains(response, \"get_admin_log 10 as admin_log for_user invalid_user for_user user\")\n    self.assertContains(response, \"get_admin_log 10 as admin_log for_user invalid_user for_user 23\")\n\n    # Test with invalid syntax\n    response = self.client.get(reverse(\"admin:index\"))\n    self.assertContains(response, \"{% get_admin_log %}\")\n    self.assertContains(response, \"{% get_admin_log 10 %}\")\n    self.assertContains(response, \"{% get_admin_log 10 as %}\")\n    self.assertContains(response, \"{% get_admin_log 10 as admin_log for_user %}\")\n    self.assertContains(response, \"{% get_admin_log 10 as admin_log for_user 23 %}\")\n    self.assertContains(response, \"{% get_admin_log 10 as admin_log for_user user %}\")\n"], "sample_1198": ["def test_parser_mathematica_exp():\n    parser = MathematicaParser()\n\n    convert_chain = lambda expr: parser._from_fullformlist_to_fullformsympy(parser._from_mathematica_to_tokens(expr))\n    convert_chain2 = lambda expr: parser._from_fullformsympy_to_sympy(convert_chain(expr))\n\n    # Test cases for _from_mathematica_to_tokens\n    assert convert_chain(\"x + y\") == x + y\n    assert convert_chain(\"x - y\") == x - y\n    assert convert_chain(\"x * y\") == x * y\n    assert convert_chain(\"x / y\") == x / y\n    assert convert_chain(\"x ^ y\") == x ** y\n    assert convert_chain(\"x ** y\") == x ** y\n    assert convert_chain(\"x + 3\") == x + 3\n    assert convert_chain(\"x - 3\") == x - 3\n    assert convert_chain(\"x * 3\") == x * 3\n    assert convert_chain(\"x / 3\") == x / 3\n    assert convert_chain(\"x ^ 3\") == x ** 3\n    assert convert_chain(\"x ** 3\") == x ** 3\n    assert convert_chain(\"x + y + z\") == x + y + z\n    assert convert_chain(\"x - y - z\") == x - y - z\n    assert convert_chain(\"x * y * z\") == x * y * z\n    assert convert_chain(\"x / y / z\") == x / y / z\n    assert convert_chain(\"x ^ y ^ z\") == x ** y ** z\n    assert convert_chain(\"x ** y ** z\") == x ** y ** z\n\n    # Test cases for _from_fullformlist_to_fullformsympy\n    assert convert_chain2(\"x + y\") == x + y\n    assert convert_chain2(\"x - y\") == x - y\n    assert convert_chain2(\"x * y\") == x * y\n    assert convert_chain2(\"x / y\") == x / y\n    assert convert_chain2(\"x ^ y\") == x ** y\n    assert convert_chain2(\"x ** y\") == x ** y\n    assert convert_chain2(\"x + 3\") == x + 3\n    assert convert_chain2(\"x - 3\") == x - 3"], "sample_1096": ["def test_IndexedBase_shape_precedence():\n    i, j = symbols('i j', integer=True)\n    o, p = symbols('o p', integer=True)\n    n, m = symbols('n m', integer=True)\n    a = IndexedBase('a', shape=(o, p))\n    assert a.shape == Tuple(o, p)\n    assert Indexed(\n        a, Idx(i, m), Idx(j, n)).ranges == [Tuple(0, m - 1), Tuple(0, n - 1)]\n    assert Indexed(a, Idx(i, m), Idx(j, n)).shape == Tuple(o, p)\n    assert Indexed(\n        a, Idx(i, m), Idx(j)).ranges == [Tuple(0, m - 1), Tuple(None, None)]\n    assert Indexed(a, Idx(i, m), Idx(j)).shape == Tuple(o, p)\n"], "sample_956": ["def test_load_mappings_cache(tempdir, app, status, warning):\n    \"\"\"\n    load_mappings issues a warning if new-style mapping identifiers are not string\n    \"\"\"\n    inv_file = tempdir / 'inventory'\n    inv_file.write_bytes(inventory_v2)\n    set_config(app, {\n        'https://docs.python.org/': inv_file,\n        'py3k': ('https://docs.python.org/py3k/', inv_file),\n        'repoze.workflow': ('http://docs.repoze.org/workflow/', inv_file),\n        'django-taggit': ('http://django-taggit.readthedocs.org/en/latest/',\n                          inv_file),\n        12345: ('http://www.sphinx-doc.org/en/stable/', inv_file),\n    })\n\n    # load the inventory and check if it's done correctly\n    normalize_intersphinx_mapping(app, app.config)\n    load_mappings(app)\n    assert warning.getvalue().count('\\n') == 1\n\n    # clear messages\n    status.truncate(0)\n    warning.truncate(0)\n\n    # add cache limit\n    app.config.intersphinx_cache_limit = 1\n    load_mappings(app)\n    assert \"failed to reach any of the inventories\" in status.getvalue()\n\n    # clear messages\n    status.truncate(0)\n    warning.truncate(0)\n\n    # add cache limit and cache\n    app.config.intersphinx_cache_limit = 1\n    app.env.intersphinx_cache = {'https://docs.python.org/': (None, 0, None)}\n    load_mappings(app)\n    assert \"encountered some issues with some of the inventories\" in status.getvalue()\n    assert \"\" == warning.getvalue()\n\n    rn = reference_check(app, 'py', 'func', 'module1.func', 'foo')\n    assert isinstance(rn, nodes.reference)\n"], "sample_1085": ["def test_Float_floor_ceiling():\n    a = Float(4.7)\n    assert a.floor() == 4\n    assert a.ceiling() == 5\n    assert a.__floor__() == 4\n    assert a.__ceil__() == 5\n"], "sample_139": ["def test_distinct_for_m2m_in_list_filter_with_params(self):\n    \"\"\"\n    If a ManyToManyField is in list_filter and is in any lookup params,\n    the changelist's query should have distinct.\n    \"\"\"\n    m = BandAdmin(Band, custom_site)\n    for lookup_params in ({'genres': '0'}, {'name': 'test', 'genres': '0'}):\n        request = self.factory.get('/band/', lookup_params)\n        request.user = self.superuser\n        cl = m.get_changelist_instance(request)\n        self.assertTrue(cl.queryset.query.distinct)\n\n    # A ManyToManyField in params does have distinct applied.\n    request = self.factory.get('/band/', {'genres': '0'})\n    request.user = self.superuser\n    cl = m.get_changelist_instance(request)\n    self.assertTrue(cl.queryset.query.distinct)\n"], "sample_905": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n        pass\n\n    func.register(int, lambda x: x + 1)\n    func.register(str, lambda x: x.upper())\n\n    assert inspect.is_singledispatch_function(func) is True\n\n        pass\n\n    assert inspect.is_singledispatch_function(func2) is False\n\n        pass\n\n    assert inspect.is_singledispatch_function(func3) is False\n\n        pass\n\n    func4.register(int, lambda x: x + 1)\n    func4.register(str, lambda x: x.upper())\n\n    assert inspect.is_singledispatch_function(func4) is True\n"], "sample_72": ["def test_serialize_datetime_tzinfo(self):\n    \"\"\"\n    Test serialization of datetime with tzinfo.\n    \"\"\"\n    self.assertSerializedResultEqual(\n        datetime.datetime(2014, 1, 1, 1, 1, tzinfo=get_default_timezone()),\n        (\"datetime.datetime(2014, 1, 1, 1, 1, tzinfo=get_default_timezone())\", {'import datetime'})\n    )\n    self.assertSerializedResultEqual(\n        datetime.datetime(2013, 12, 31, 22, 1, tzinfo=get_fixed_timezone(180)),\n        (\n            \"datetime.datetime(2013, 12, 31, 22, 1, tzinfo=get_fixed_timezone(180))\",\n            {'import datetime', 'from django.utils.timezone import get_fixed_timezone'}\n        )\n    )\n"], "sample_1077": ["def test_ImageSet_simplification():\n    from sympy.abc import n, m\n    assert imageset(Lambda(n, n), S.Integers) == S.Integers\n    assert imageset(Lambda(n, sin(n)),\n                    imageset(Lambda(m, tan(m)), S.Integers)) == \\\n            imageset(Lambda(m, sin(tan(m))), S.Integers)\n    assert imageset(n, 1 + 2*n, S.Naturals) == Range(3, oo, 2)\n    assert imageset(n, 1 + 2*n, S.Naturals0) == Range(1, oo, 2)\n    assert imageset(n, 1 - 2*n, S.Naturals) == Range(-1, -oo, -2)\n    assert imageset(Lambda(n, n**2), S.Integers) == FiniteSet(0, 1)\n    assert imageset(Lambda(n, n**2), S.Naturals) == FiniteSet(1)\n    assert imageset(Lambda(n, n**2), S.Naturals0) == FiniteSet(0, 1)\n    assert imageset(Lambda(n, n**2), S.Integers) == FiniteSet(0, 1)\n    assert imageset(Lambda(n, n**2), S.Integers) == FiniteSet(0, 1)\n    assert imageset(Lambda(n, n**2), S.Integers) == FiniteSet(0, 1)\n    assert imageset(Lambda(n, n**2), S.Integers) == FiniteSet(0, 1)\n    assert imageset(Lambda(n, n**2), S.Integers) == FiniteSet(0, 1)\n    assert imageset(Lambda(n, n**2), S.Integers) == FiniteSet(0, 1)\n    assert imageset(Lambda(n, n**2), S.Integers) == FiniteSet(0, 1)\n    assert imageset(Lambda(n, n**2), S.Integers) == FiniteSet(0, 1)\n    assert imageset(Lambda(n, n**2), S.Integers) == FiniteSet(0, 1)\n    assert imageset(Lambda(n, n**2), S.Integers) == FiniteSet(0, 1)\n    assert imageset(Lambda(n, n**2), S.Integers) =="], "sample_740": ["def test_check_X_y():\n    # Test check_X_y with different types of inputs\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # Test check_X_y with sparse matrix\n    X_sparse = sp.csr_matrix([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X_sparse, y)\n    assert_array_equal(X_checked.toarray(), X_sparse.toarray())\n    assert_array_equal(y_checked, y)\n\n    # Test check_X_y with multi-output\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([[0, 1], [1, 0]])\n    X_checked, y_checked = check_X_y(X, y, multi_output=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # Test check_X_y with invalid input\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1, 2])\n    with pytest.raises(ValueError):\n        check_X_y(X, y)\n\n    # Test check_X_y with complex data\n    X = np.array([[1 + 2j, 3 + 4j], [5 + 6j, 7 + 8j]])\n    with pytest.raises(ValueError):\n        check_X_y(X, y)\n\n    # Test check_X_y with non-numeric y\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array(['a', 'b'])\n    with pytest.raises(ValueError):\n        check_X_y(X, y)\n\n    # Test check_X_y with y that has np.nan or np.inf values\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([np.nan, 1])\n    with pytest.raises(ValueError):\n        check_X_y(X, y)\n"], "sample_328": ["    def test_update_with_related_objects(self):\n        note = Note.objects.create(note='test-note', misc='test')\n        tag = Tag.objects.create(name='test-tag')\n        note.tag = tag\n        with self.assertNumQueries(1):\n            Note.objects.bulk_update([note], ['tag'])\n        self.assertEqual(note.tag, tag)\n        self.assertEqual(Note.objects.filter(tag__isnull=False).count(), 1)\n"], "sample_1131": ["def test_SymPyPrinter():\n    p = SymPyPrinter()\n    assert p.doprint(S.Pi) == 'sympy.pi'\n    assert p.doprint(S.Exp1) == 'sympy.E'\n    assert p.doprint(S.GoldenRatio) == 'sympy.GoldenRatio'\n    assert p.doprint(S.EulerGamma) == 'sympy.EulerGamma'\n    assert p.doprint(S.NaN) == 'sympy.nan'\n    assert p.doprint(S.Infinity) == 'sympy.oo'\n    assert p.doprint(S.NegativeInfinity) == 'sympy.NegativeInfinity'\n    assert p.doprint(loggamma(x)) == 'sympy.loggamma(x)'\n"], "sample_1043": ["def test_TribonacciConstant():\n    assert mcode(S.TribonacciConstant) == \"1/3 + (1/3)*(19 - 3*33^(1/2))^(1/3) + \" \\\n        \"(1/3)*(3*33^(1/2) + 19)^(1/3)\"\n    assert mcode(x**S.TribonacciConstant) == \"x^(1/3 + (1/3)*(19 - 3*33^(1/2))^(1/3) + \" \\\n        \"(1/3)*(3*33^(1/2) + 19)^(1/3))\"\n    assert mcode(S.TribonacciConstant + S.TribonacciConstant) == \\\n        \"1/3 + (1/3)*(19 - 3*33^(1/2))^(1/3) + (1/3)*(3*33^(1/2) + 19)^(1/3) + \" \\\n        \"1/3 + (1/3)*(19 - 3*33^(1/2))^(1/3) + (1/3)*(3*33^(1/2) + 19)^(1/3)\"\n"], "sample_750": ["def test_omp_path_with_tol():\n    path = orthogonal_mp(X, y, tol=1., n_nonzero_coefs=5, return_path=True)\n    last = orthogonal_mp(X, y, tol=1., n_nonzero_coefs=5, return_path=False)\n    assert_equal(path.shape, (n_features, n_targets, 5))\n    assert_array_almost_equal(path[:, :, -1], last)\n"], "sample_474": ["    def setUpTestData(cls):\n        cls.john = Author.objects.create(name=\"John Smith\", alias=\"smithj\")\n        cls.elena = Author.objects.create(name=\"\u00c9lena Jordan\", alias=\"elena\")\n        cls.rhonda = Author.objects.create(name=\"Rhonda\")\n"], "sample_849": ["def test_predefinedsplit():\n    # Check that PredefinedSplit can reproduce a split generated by Kfold.\n    folds = np.full(10, -1.)\n    kf_train = []\n    kf_test = []\n    for i, (train_ind, test_ind) in enumerate(KFold(5, shuffle=True).split(X)):\n        kf_train.append(train_ind)\n        kf_test.append(test_ind)\n        folds[test_ind] = i\n    ps = PredefinedSplit(folds)\n    # n_splits is simply the no of unique folds\n    assert len(np.unique(folds)) == ps.get_n_splits()\n    ps_train, ps_test = zip(*ps.split())\n    assert_array_equal(ps_train, kf_train)\n    assert_array_equal(ps_test, kf_test)\n\n    # Check that PredefinedSplit can reproduce a split generated by StratifiedKFold.\n    y = np.array([0, 1, 0, 1, 0, 0, 1, 1, 1])\n    X = np.ones_like(y)\n    skf_train = []\n    skf_test = []\n    for i, (train_ind, test_ind) in enumerate(StratifiedKFold(3).split(X, y)):\n        skf_train.append(train_ind)\n        skf_test.append(test_ind)\n        folds[test_ind] = i\n    ps = PredefinedSplit(folds)\n    # n_splits is simply the no of unique folds\n    assert len(np.unique(folds)) == ps.get_n_splits()\n    ps_train, ps_test = zip(*ps.split())\n    assert_array_equal(ps_train, skf_train)\n    assert_array_equal(ps_test, skf_test)\n\n    # Check that PredefinedSplit can reproduce a split generated by GroupKFold.\n    groups = np.array([1, 1, 1, 2, 2])\n    X = y = np.ones(len(groups))\n    gkf_train = []\n    gkf_test = []\n    for i, (train_ind, test_ind) in enumerate(GroupKFold(3).split(X, y, groups)):\n        gkf_train.append(train_ind)\n        gkf_test.append(test_ind)\n        folds[test_ind] = i\n    ps = PredefinedSplit(folds)\n    # n_splits is simply the no of unique folds\n    assert len(np.unique(folds)) == ps.get_n_splits()\n    ps_train, ps_test = zip(*ps.split())\n    assert_array_equal(ps_train, g"], "sample_537": ["    def test_stride_windows_stride_tricks(self):\n        x = np.arange(10)\n        y = mlab.stride_windows(x, 3, noverlap=1)\n        yt = self.calc_window_target(x, 3, noverlap=1)\n        assert_array_equal(y, yt)\n"], "sample_448": ["    def test_deconstruction_with_expressions_and_fields(self):\n        fields = [\"foo\", \"bar\"]\n        name = \"unique_fields\"\n        constraint = models.UniqueConstraint(fields=fields, name=name, expressions=[Lower(\"title\")])\n        path, args, kwargs = constraint.deconstruct()\n        self.assertEqual(path, \"django.db.models.UniqueConstraint\")\n        self.assertEqual(args, (Lower(\"title\"),))\n        self.assertEqual(kwargs, {\"fields\": tuple(fields), \"name\": name})\n"], "sample_363": ["    def test_render(self):\n        # Backslash in verbose_name to ensure it is JavaScript escaped.\n        w = widgets.AutocompleteSelect('test\\\\', False)\n        self.assertHTMLEqual(\n            w.render('test', 'test'),\n            '<select name=\"test\" class=\"admin-autocomplete\" '\n            'data-ajax--cache=\"true\" data-ajax--delay=\"250\" '\n            'data-ajax--type=\"GET\" data-ajax--url=\"/admin_widgets/autocomplete/test/\" '\n            'data-app-label=\"admin_widgets\" data-model-name=\"test\" '\n            'data-field-name=\"test\\\\\" data-theme=\"admin-autocomplete\" '\n            'data-allow-clear=\"true\" data-placeholder=\"\" lang=\"en\">'\n            '<option value=\"test\"></option></select>'\n        )\n"], "sample_10": ["    def test_1(self, table_types):\n        self._setup(table_types)\n        t = self.t\n        t2 = table_types.Table(t, copy=False)\n        assert t.groups == t2.groups\n"], "sample_624": ["def test_inline_dask_repr(self) -> None:\n    import dask.array as da\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(2, 3)>\"\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]), chunks=(1, 3))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(1, 3)>\"\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]), chunks=(2, 1))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(2, 1)>\"\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]), chunks=(2, 2))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(2, 2)>\"\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]), chunks=(1, 1))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(1, 1)>\"\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]), chunks=(3, 3))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(3, 3)>\"\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]), chunks=(4, 4))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(4, 4)>\"\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]), chunks=(5, 5))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(5, 5)>\"\n\n    da_array = da.from_array(np.array([[1"], "sample_968": ["def test_pydata_with_union_type_operator_old(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :annotation: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0],\n                ([desc_name, \"version\"],\n                 [desc_annotation, ([desc_sig_punctuation, ':'],\n                                    desc_sig_space,\n                                    [pending_xref, \"int\"],\n                                    desc_sig_space,\n                                    [desc_sig_punctuation, \"|\"],\n                                    desc_sig_space,\n                                    [pending_xref, \"str\"])]))\n"], "sample_115": ["    def test_sensitive_variables_decorator(self):\n        \"\"\"\n        The sensitive_variables decorator works with function calls.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(sensitive_variables_wrapper)\n            self.verify_unsafe_email(sensitive_variables_wrapper)\n\n        with self.settings(DEBUG=False):\n            self.verify_safe_response(sensitive_variables_wrapper)\n            self.verify_safe_email(sensitive_variables_wrapper)\n"], "sample_578": ["    def test_mapped_color(self, x, y, color):\n\n        p = Plot(x, y, color=color).add(Bars()).plot()\n        ax = p._figure.axes[0]\n        fcs = ax.collections[0].get_facecolors()\n        C0, C1, C2, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        expected = to_rgba_array([C0, C1, C2, C0, C2])\n        assert_array_equal(fcs, expected)\n"], "sample_684": ["def test_ExceptionChainRepr_reprcrash() -> None:\n    \"\"\"Test ExceptionChainRepr._getreprcrash() method.\"\"\"\n    try:\n        raise ValueError()\n    except ValueError:\n        excinfo = ExceptionInfo.from_current()\n        repr = excinfo.getrepr()\n        assert isinstance(repr, ExceptionChainRepr)\n        assert repr.reprcrash is not None\n        assert repr.reprcrash.path == \"test_ExceptionChainRepr_reprcrash.py\"\n        assert repr.reprcrash.lineno == 1\n        assert repr.reprcrash.message == \"ValueError\"\n"], "sample_287": ["def test_prepopulated_fields(self):\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title', 'nonexistent')}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'prepopulated_fields['slug']' refers to 'nonexistent', \"\n            \"which is not a field of 'admin_checks.Song'.\",\n            obj=SongAdmin,\n            id='admin.E027',\n        )\n    ]\n    self.assertEqual(errors, expected)\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin"], "sample_323": ["def test_detect_soft_applied_add_field(self):\n    \"\"\"\n    executor.detect_soft_applied() detects AddField operations.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Create the tables for 0001 but make it look like the migration hasn't\n    # been applied.\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n    executor.migrate([(\"migrations\", None)], fake=True)\n    # Create the tables for 0002 but make it look like the migration hasn't\n    # been applied.\n    executor.migrate([(\"migrations\", \"0002_initial\")])\n    executor.migrate([(\"migrations\", None)], fake=True)\n    # Table detection sees 0001 is applied but not 0002.\n    migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], True)\n    migration = executor.loader.get_migration(\"migrations\", \"0002_initial\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], False)\n\n    # Create the tables for both migrations but make it look like neither\n    # has been applied.\n    executor.loader.build_graph()\n    executor.migrate([(\"migrations\", \"0001_initial\")], fake=True)\n    executor.migrate([(\"migrations\", \"0002_initial\")])\n    executor.loader.build_graph()\n    executor.migrate([(\"migrations\", None)], fake=True)\n    # Table detection sees 0002 is applied.\n    migration = executor.loader.get_migration(\"migrations\", \"0002_initial\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], True)\n\n    # Leave the tables for 0001 except the field. That missing field should\n    # cause detect_soft_applied() to return False.\n    with connection.schema_editor() as editor:\n        editor.execute(editor.sql_delete_table % {\"table\": \"migrations_book\"})\n    migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], False)\n\n    # Cleanup by removing the remaining tables.\n    with connection.schema_editor() as editor:\n        editor.execute(editor.sql_delete_table % {\"table\": \"migrations_author\"})\n    for table in [\"migrations_book\", \"migrations_author\"]:\n        self.assertTableNotExists(table)\n"], "sample_764": ["def test_column_transformer_sparse_remainder_transformer_sparse_output():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           sparse_threshold=0.8)\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n    # SparseMatrixTrans creates 3 features for each column. There is\n    # one column in ``transformers``, thus:\n    assert X_trans.shape == (3, 3 + 1)\n\n    exp_array = np.hstack(\n        (X_array[:, 0].reshape(-1, 1), np.eye(3)))\n    assert_array_equal(X_trans.toarray(), exp_array)\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], SparseMatrixTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n\n    # test that sparse_output_ is set to True\n    assert ct.sparse_output_\n\n    # test that transform also returns a sparse matrix\n    X_trans = ct.transform(X_array)\n    assert sparse.issparse(X_trans)\n    assert_array_equal(X_trans.toarray(), exp_array)\n"], "sample_451": ["def test_replace_metacharacters(self):\n    \"\"\"\n    Test that replace_metacharacters() correctly removes unescaped metacharacters.\n    \"\"\"\n    pattern = r\"\\(\\\\?P<name>\\w+\\)\"\n    expected_output = r\"\\(?P<name>\\w+\\)\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\(\\\\?P<name>\\w+\\)\"\n    expected_output = r\"\\(?P<name>\\w+\\)\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\(P<name>\\w+\\)\"\n    expected_output = r\"\\(P<name>\\w+\\)\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\(P<name>\\w+\\)\"\n    expected_output = r\"\\(P<name>\\w+\\)\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\(P<name>\\w+\\)\"\n    expected_output = r\"\\(P<name>\\w+\\)\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\(P<name>\\w+\\)\"\n    expected_output = r\"\\(P<name>\\w+\\)\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\(P<name>\\w+\\)\"\n    expected_output = r\"\\(P<name>\\w+\\)\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\(P<name>\\w+\\)\"\n    expected_output = r\"\\(P<name>\\w+\\)\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\(P<name>\\w+\\)\"\n    expected_output = r\"\\(P<name>\\w+\\)\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\(P<name>\\w+\\)\"\n    expected_output = r\"\\(P<name>\\w+\\)\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\(P<name>\\w+\\)\"\n    expected_output = r\"\\(P<name>\\w+\\)\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\(P<name>\\w+\\)\"\n    expected_output = r\"\\(P<name"], "sample_903": ["def test_tsne_with_sparse_input():\n    # Test that TSNE can handle sparse input.\n    random_state = check_random_state(0)\n    X = random_state.randn(100, 2)\n    X[(np.random.randint(0, 100, 50), np.random.randint(0, 2, 50))] = 0.0\n    X_csr = sp.csr_matrix(X)\n    tsne = TSNE(n_components=2, perplexity=10, learning_rate=100.0,\n                random_state=0, method='exact')\n    X_embedded = tsne.fit_transform(X_csr)\n    assert_almost_equal(trustworthiness(X_csr, X_embedded, n_neighbors=1), 1.0,\n                        decimal=1)\n"], "sample_65": ["    def test_json_catalog(self):\n        \"\"\"The json_catalog returns the language catalog and settings as JSON.\"\"\"\n        with override('de'):\n            response = self.client.get('/jsoni18n/')\n            data = json.loads(response.content.decode())\n            self.assertIn('catalog', data)\n            self.assertIn('formats', data)\n            self.assertEqual(data['formats']['TIME_INPUT_FORMATS'], ['%H:%M:%S', '%H:%M:%S.%f', '%H:%M'])\n            self.assertEqual(data['formats']['FIRST_DAY_OF_WEEK'], 0)\n            self.assertIn('plural', data)\n            self.assertEqual(data['plural'], '(n != 1)')\n            self.assertIn('DATETIME_FORMAT', data['formats'])\n            self.assertEqual(data['catalog']['month name\\x04May'], 'Mai')\n"], "sample_41": ["def test_prefix_unit():\n    \"\"\"\n    Test that prefix units are correctly created and used.\n    \"\"\"\n    assert u.mm.is_equivalent(u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m * u.m"], "sample_315": ["    def test_language_prefix_added(self):\n        response = self.client.get('/account/register/', HTTP_ACCEPT_LANGUAGE='en')\n        self.assertRedirects(response, '/en/account/register/')\n\n        response = self.client.get(response.headers['location'])\n        self.assertEqual(response.status_code, 200)\n"], "sample_36": ["def test_biweight_midcorrelation_axis():\n    \"\"\"\n    Test that biweight_midcorrelation raises error when axis is not None.\n    \"\"\"\n\n    rng = np.random.RandomState(1)\n    d = rng.normal(0, 2, size=(3, 500))\n    with pytest.raises(ValueError) as e:\n        biweight_midcorrelation(d[0], d[1], axis=0)\n    assert 'axis must be None' in str(e.value)\n\n    with pytest.raises(ValueError) as e:\n        biweight_midcorrelation(d[0], d[1], axis=1)\n    assert 'axis must be None' in str(e.value)\n"], "sample_446": ["    def test_floatformat03(self):\n        output = self.engine.render_to_string(\n            \"floatformat03\", {\"a\": \"66666.666\", \"b\": mark_safe(\"66666.666\")}\n        )\n        self.assertEqual(output, \"66,667.00 66,667.67\")\n"], "sample_896": ["def test_nmf_solver_cd_convergence():\n    # Test that the Coordinate Descent solver converges\n    n_samples = 20\n    n_features = 15\n    n_components = 10\n    alpha = 0.1\n    l1_ratio = 0.5\n    tol = 1e-6\n\n    # initialization\n    rng = np.random.mtrand.RandomState(42)\n    X = rng.randn(n_samples, n_features)\n    np.abs(X, X)\n    W0, H0 = nmf._initialize_nmf(X, n_components, init=\"random\", random_state=42)\n\n    W, H = W0.copy(), H0.copy()\n    previous_loss = None\n    for _ in range(30):\n        # one more iteration starting from the previous results\n        W, H, _ = non_negative_factorization(\n            X,\n            W,\n            H,\n            beta_loss=2,\n            init=\"custom\",\n            n_components=n_components,\n            max_iter=1,\n            alpha_W=alpha,\n            solver=\"cd\",\n            tol=tol,\n            l1_ratio=l1_ratio,\n            verbose=0,\n            random_state=0,\n            update_H=True,\n        )\n\n        loss = (\n            nmf._beta_divergence(X, W, H, beta_loss=2)\n            + alpha * l1_ratio * n_features * W.sum()\n            + alpha * l1_ratio * n_samples * H.sum()\n            + alpha * (1 - l1_ratio) * n_features * (W**2).sum()\n            + alpha * (1 - l1_ratio) * n_samples * (H**2).sum()\n        )\n        if previous_loss is not None:\n            assert previous_loss > loss\n        previous_loss = loss\n"], "sample_876": ["def test_mlp_regressor_max_iter():\n    # Test max_iter.\n    # It should force the solver to exit the loop when it reaches max_iter.\n    X = [[3, 2], [1, 6]]\n    y = [1, 0]\n    clf = MLPRegressor(max_iter=2, solver=\"sgd\")\n    clf.fit(X, y)\n    assert clf.max_iter > clf.n_iter_\n"], "sample_860": ["def test_check_array_sparse_conversion():\n    # Test that check_array converts sparse matrices to the correct format\n    X = sp.csr_matrix(np.arange(4).reshape(2, 2))\n    X_coo = X.tocoo()\n    X_dok = X.todok()\n    X_csc = X.tocsc()\n    X_bsr = sp.bsr_matrix(np.arange(4).reshape(2, 2))\n    X_bsr_coo = X_bsr.tocoo()\n    X_bsr_dok = X_bsr.todok()\n    X_bsr_csc = X_bsr.tocsc()\n\n    # Test that check_array converts to the first format in the list\n    assert check_array(X, accept_sparse=['csr', 'csc']).format == 'csr'\n    assert check_array(X, accept_sparse=['csr', 'csc']).format == 'csr'\n    assert check_array(X, accept_sparse=['csr', 'csc']).format == 'csr'\n\n    # Test that check_array converts to the correct format when the input is in the list\n    assert check_array(X_coo, accept_sparse=['csr', 'csc']).format == 'coo'\n    assert check_array(X_dok, accept_sparse=['csr', 'csc']).format == 'dok'\n    assert check_array(X_csc, accept_sparse=['csr', 'csc']).format == 'csc'\n    assert check_array(X_bsr, accept_sparse=['csr', 'csc']).format == 'bsr'\n    assert check_array(X_bsr_coo, accept_sparse=['csr', 'csc']).format == 'coo'\n    assert check_array(X_bsr_dok, accept_sparse=['csr', 'csc']).format == 'dok'\n    assert check_array(X_bsr_csc, accept_sparse=['csr', 'csc']).format == 'csc'\n\n    # Test that check_array raises an error when the input is not in the list\n    msg = (\"A sparse matrix was passed, but dense data is required. \"\n           \"Use X.toarray() to convert to a dense numpy array.\")\n    assert_raise_message(TypeError, msg, check_array, X, accept_sparse=False)\n\n    # Test that check_array raises an error when the input is not a sparse matrix\n    msg = (\"Parameter 'accept_sparse' should be a string, \"\n           \"boolean or list of strings. You provided 'accept_sparse={}'."], "sample_594": ["def test_inline_dask_repr():\n    da = xr.DataArray(np.random.randn(10), dims=\"x\", coords={\"x\": np.arange(10)})\n    actual = formatting.inline_dask_repr(da)\n    expected = f\"dask.array<chunksize={(10,)}>\"\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 10), dims=(\"x\", \"y\"), coords={\"x\": np.arange(10), \"y\": np.arange(10)})\n    actual = formatting.inline_dask_repr(da)\n    expected = f\"dask.array<chunksize={(10, 10)}>\"\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 10, 10), dims=(\"x\", \"y\", \"z\"), coords={\"x\": np.arange(10), \"y\": np.arange(10), \"z\": np.arange(10)})\n    actual = formatting.inline_dask_repr(da)\n    expected = f\"dask.array<chunksize={(10, 10, 10)}>\"\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 10, 10, 10), dims=(\"x\", \"y\", \"z\", \"w\"), coords={\"x\": np.arange(10), \"y\": np.arange(10), \"z\": np.arange(10), \"w\": np.arange(10)})\n    actual = formatting.inline_dask_repr(da)\n    expected = f\"dask.array<chunksize={(10, 10, 10, 10)}>\"\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 10, 10, 10, 10), dims=(\"x\", \"y\", \"z\", \"w\", \"v\"), coords={\"x\": np.arange(10), \"y\": np.arange(10), \"z\": np.arange(10), \"w\": np.arange(10), \"v\": np.arange(10)})\n    actual = formatting.inline_dask_repr(da)\n    expected = f\"dask.array<chunksize={(10, 10, 10, 10, 10)}>\"\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 10, 10, 10, 10, 10), dims=(\"x\", \"y\", \"z\", \"w\", \"v\", \"u\"), coords={\"x\": np.arange(10), \""], "sample_421": ["    def test_expression_hash(self):\n        expression_1 = F(\"integer\")\n        expression_2 = F(\"integer\")\n        self.assertEqual(hash(expression_1), hash(expression_2))\n        expression_3 = F(\"integer2\")\n        self.assertNotEqual(hash(expression_1), hash(expression_3))\n        expression_4 = F(\"fk_rel__integer\")\n        self.assertNotEqual(hash(expression_1), hash(expression_4))\n"], "sample_570": ["    def test_binwidth_roundoff(self, rng):\n\n        x = np.array([2.4, 2.5, 2.6])\n        h = Histogram(binwidth=0.01)\n        bin_kws = h.define_bin_params(x)\n        assert h.sum() == 3\n"], "sample_687": ["def test_log_cli_level(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_level == logging.INFO\n            logger = logging.getLogger('catchlog')\n            logger.warning(\"WARNING message won't be shown\")\n            logger.error(\"ERROR message will be shown\")\n            assert 'WARNING' not in caplog.text\n            assert 'ERROR' in caplog.text\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_cli_level=INFO\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n"], "sample_963": ["def test_restify_type_hints_NewType():\n    MyInt = NewType('MyInt', int)\n    assert restify(MyInt) == \":py:class:`tests.test_util_typing.MyInt`\"\n"], "sample_1051": ["def test_dotprint_styles():\n    styles = [(Basic, {'color': 'blue', 'shape': 'ellipse'}),\n              (Expr,  {'color': 'black', 'fontname': 'Arial'})]\n    text = dotprint(x+2, styles=styles)\n    assert all(e in text for e in dotedges(x+2, repeat=False))\n    assert all(n in text for n in [dotnode(expr, styles=styles, repeat=False) for expr in (x, Integer(2), x+2)])\n    assert 'digraph' in text\n    assert 'fontname' in text\n"], "sample_1031": ["def test_get_dimensional_expr():\n    # test that get_dimensional_expr returns the correct dimensional expression\n    dimsys = UnitSystem((m, kg, s), (c,))\n    assert dimsys.get_dimensional_expr(m) == m\n    assert dimsys.get_dimensional_expr(kg) == kg\n    assert dimsys.get_dimensional_expr(s) == s\n    assert dimsys.get_dimensional_expr(c) == c\n\n    # test that get_dimensional_expr returns the correct dimensional expression for derived units\n    N = Quantity(\"N\")\n    N.set_dimension(force)\n    N.set_scale_factor(kg*m/s**2)\n    dimsys = UnitSystem((m, kg, s), (c, N))\n    assert dimsys.get_dimensional_expr(N) == kg*m/s**2\n\n    # test that get_dimensional_expr returns the correct dimensional expression for units with scale factors\n    dm = Quantity(\"dm\")\n    dm.set_dimension(length)\n    dm.set_scale_factor(Rational(1, 10))\n    dimsys = UnitSystem((m, s), (c, dm))\n    assert dimsys.get_dimensional_expr(dm) == m/10\n\n    # test that get_dimensional_expr raises an error for invalid units\n    raises(ValueError, lambda: dimsys.get_dimensional_expr(Quantity(\"invalid_unit\")))\n"], "sample_511": ["def test_rgrids():\n    fig, ax = plt.subplots()\n    ax.set_rgrids([0.5, 1.0, 1.5])\n    assert len(ax.yaxis.get_gridlines()) == 3\n    assert len(ax.yaxis.get_ticklabels()) == 3\n    assert ax.yaxis.get_ticklabels()[0].get_text() == '0.5'\n    assert ax.yaxis.get_ticklabels()[1].get_text() == '1.0'\n    assert ax.yaxis.get_ticklabels()[2].get_text() == '1.5'\n\n    ax.set_rgrids([0.5, 1.0, 1.5], labels=['a', 'b', 'c'])\n    assert len(ax.yaxis.get_gridlines()) == 3\n    assert len(ax.yaxis.get_ticklabels()) == 3\n    assert ax.yaxis.get_ticklabels()[0].get_text() == 'a'\n    assert ax.yaxis.get_ticklabels()[1].get_text() == 'b'\n    assert ax.yaxis.get_ticklabels()[2].get_text() == 'c'\n\n    ax.set_rgrids([0.5, 1.0, 1.5], labels=['a', 'b', 'c'], angle=45)\n    assert len(ax.yaxis.get_gridlines()) == 3\n    assert len(ax.yaxis.get_ticklabels()) == 3\n    assert ax.yaxis.get_ticklabels()[0].get_text() == 'a'\n    assert ax.yaxis.get_ticklabels()[1].get_text() == 'b'\n    assert ax.yaxis.get_ticklabels()[2].get_text() == 'c'\n\n    ax.set_rgrids([0.5, 1.0, 1.5], labels=['a', 'b', 'c'], fmt='%f')\n    assert len(ax.yaxis.get_gridlines()) == 3\n    assert len(ax.yaxis.get_ticklabels()) == 3\n    assert ax.yaxis.get_ticklabels()[0].get_text() == '0.500000'\n    assert ax.yaxis.get_ticklabels()[1].get_text() == '1.000000'\n    assert ax.yaxis.get_ticklabels()[2].get_text() == '1.500000'\n\n    ax.set_rgrids([])\n    assert len(ax.yaxis.get_gridlines()) == 0\n    assert len"], "sample_1181": ["def test_issue_17007():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    M = MatrixSymbol(\"M\", 2, 2)\n\n    f = lambdify(M, M**2)\n    ma = np.array([[1, 2], [3, 4]])\n    mr = np.array([[1, 4, 4], [9, 16, 8], [6, 8, 16]])\n\n    assert (f(ma) == mr).all()\n\n    from sympy.core.symbol import symbols\n    n = symbols('n', integer=True)\n    N = MatrixSymbol(\"M\", n, n)\n    raises(NotImplementedError, lambda: lambdify(N, N**2))\n"], "sample_372": ["    def test_include_namespace_with_app_name(self):\n        url_patterns = [\n            path('inner/', views.empty_view, name='urlobject-view', app_name='app_name'),\n            re_path(r'^inner/(?P<arg1>[0-9]+)/(?P<arg2>[0-9]+)/$', views.empty_view, name='urlobject-view', app_name='app_name'),\n            re_path(r'^inner/\\+\\\\\\$\\*/$', views.empty_view, name='urlobject-special-view', app_name='app_name'),\n        ]\n        self.assertEqual(include(url_patterns, namespace='namespace'), (url_patterns, 'app_name', 'namespace'))\n"], "sample_410": ["    def test_get_session_auth_hash(self):\n        user = AbstractBaseUser(password=\"some-gibbberish\")\n        self.assertIsInstance(user.get_session_auth_hash(), str)\n        self.assertEqual(len(user.get_session_auth_hash()), 64)\n"], "sample_495": ["    def test_get_page_with_invalid_page_number(self):\n        \"\"\"\n        Paginator.get_page() raises InvalidPage with invalid page number.\n        \"\"\"\n        paginator = Paginator([1, 2, 3], 2)\n        with self.assertRaises(InvalidPage):\n            paginator.get_page('a')\n"], "sample_1139": ["def test_ImageSet_simplification_with_rational():\n    from sympy.abc import n, m\n    assert imageset(Lambda(n, Rational(1, 2) + n), S.Integers) == S.Integers\n    assert imageset(Lambda(n, Rational(1, 2) + n), S.Naturals) == Range(1, oo, 1)\n    assert imageset(Lambda(n, Rational(1, 2) + n), S.Naturals0) == Range(0, oo, 1)\n    assert imageset(Lambda(n, Rational(1, 2) - n), S.Naturals) == Range(-oo, 0, -1)\n    assert imageset(Lambda(n, Rational(1, 2) - n), S.Naturals0) == Range(0, 1, -1)\n"], "sample_1162": ["def test_WildFunction_kind():\n    F = WildFunction('F')\n    assert F.kind is UndefinedKind\n    assert F(1).kind is UndefinedKind\n    assert F(comm_x).kind is UndefinedKind\n    assert F(noncomm_x).kind is UndefinedKind\n"], "sample_167": ["def test_intword_l10n(self):\n    # Positive integers.\n    test_list_positive = (\n        '100', '1000000', '1200000', '1290000', '1000000000', '2000000000',\n        '6000000000000',\n    )\n    result_list_positive = (\n        '100', '1,0 Millionen', '1,2 Millionen', '1,3 Millionen',\n        '1,0 Milliarde', '2,0 Milliarden', '6,0 Billionen',\n    )\n    # Negative integers.\n    test_list_negative = ('-' + test for test in test_list_positive)\n    result_list_negative = ('-' + result for result in result_list_positive)\n    with self.settings(USE_L10N=True, USE_THOUSAND_SEPARATOR=True):\n        with translation.override('de'):\n            self.humanize_tester(\n                (*test_list_positive, *test_list_negative),\n                (*result_list_positive, *result_list_negative),\n                'intword',\n            )\n"], "sample_982": ["def test_primefactors():\n    assert primefactors(0) == []\n    assert primefactors(1) == []\n    assert primefactors(-1) == []\n    assert primefactors(-2) == [-2]\n    assert primefactors(2) == [2]\n    assert primefactors(3) == [3]\n    assert primefactors(17) == [17]\n    assert primefactors(10) == [2, 5]\n    assert primefactors(100) == [2, 5, 5]\n    assert primefactors(101) == [101]\n    assert primefactors(123456) == [2, 2, 2, 2, 2, 2, 3, 643]\n    assert primefactors(5951757) == [3, 7, 29, 29, 337]\n    assert primefactors(64015937) == [7993, 8009]\n    assert primefactors(2**(2**6) + 1) == [274177, 67280421310721]\n    assert primefactors(2**64 + 1) == [274177]\n    assert primefactors(19) == [19]\n    assert primefactors(2*3*5) == [2, 3, 5]\n    assert primefactors(2*3*5*7) == [2, 3, 5, 7]\n    assert primefactors(2*3*5*7*11) == [2, 3, 5, 7, 11]\n    assert primefactors(2*3*5*7*11*13) == [2, 3, 5, 7, 11, 13]\n    assert primefactors(2*3*5*7*11*13*17) == [2, 3, 5, 7, 11, 13, 17]\n    assert primefactors(2*3*5*7*11*13*17*19) == [2, 3, 5, 7, 11, 13, 17, 19]\n    assert primefactors(2*3*5*7*11*13*17*19*23) == [2, 3, 5, 7"], "sample_425": ["def test_serialize_pathlib_posix_path(self):\n    \"\"\"Test serialization of pathlib.PosixPath.\"\"\"\n    path = pathlib.PosixPath(\"/path/file.txt\")\n    expected = (\"pathlib.PurePosixPath('/path/file.txt')\", {\"import pathlib\"})\n    self.assertSerializedResultEqual(path, expected)\n\n    field = models.FilePathField(path=pathlib.PosixPath(\"/home/user\"))\n    string, imports = MigrationWriter.serialize(field)\n    self.assertEqual(\n        string,\n        \"models.FilePathField(path=pathlib.PurePosixPath('/home/user'))\",\n    )\n    self.assertIn(\"import pathlib\", imports)\n"], "sample_704": ["def test_repr_failure_py() -> None:\n    \"\"\"Test that repr_failure_py() returns a TerminalRepr instance.\"\"\"\n    node = nodes.Node(\"test_node\")\n    excinfo = pytest.raises(Exception, lambda: None)\n    result = node._repr_failure_py(excinfo)\n    assert isinstance(result, pytest._code.TerminalRepr)\n"], "sample_768": ["def test_train_test_split_with_sparse_input():\n    # Check that train_test_split converts scipy sparse matrices\n    # to csr, as stated in the documentation\n    X = np.arange(100).reshape((10, 10))\n    sparse_types = [csr_matrix, csc_matrix, coo_matrix]\n    for InputFeatureType in sparse_types:\n        X_s = InputFeatureType(X)\n        X_train, X_test = train_test_split(X_s)\n        assert isinstance(X_train, csr_matrix)\n        assert isinstance(X_test, csr_matrix)\n"], "sample_1168": ["def test_signed_permutations():\n    assert list(signed_permutations((0, 1, 2))) == [\n        (0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2),\n        (0, 2, 1), (0, -2, 1), (0, 2, -1), (0, -2, -1),\n        (1, 0, 2), (-1, 0, 2), (1, 0, -2), (-1, 0, -2),\n        (1, 2, 0), (-1, 2, 0), (1, -2, 0), (-1, -2, 0),\n        (2, 0, 1), (-2, 0, 1), (2, 0, -1), (-2, 0, -1),\n        (2, 1, 0), (-2, 1, 0), (2, -1, 0), (-2, -1, 0)]\n    assert list(signed_permutations((0, 1, 1))) == [\n        (0, 1, 1), (0, -1, 1), (0, 1, -1), (0, -1, -1),\n        (1, 0, 1), (-1, 0, 1), (1, 0, -1), (-1, 0, -1),\n        (1, 1, 0), (-1, 1, 0), (1, -1, 0), (-1, -1, 0)]\n    assert list(signed_permutations((0, 0, 1))) == [\n        (0, 0, 1), (0, 0, -1), (0, -0, 1), (0, -0, -1),\n        (0, 1, 0), (0, -1, 0), (0, 1, 0), (0, -1, 0),\n        (1, 0, 0), (-1, 0, 0), (1, 0, 0), (-1, 0, 0)]\n    assert list(signed"], "sample_166": ["    def test_force_bytes(self):\n        self.assertIsInstance(force_bytes('hello'), bytes)\n        self.assertIsInstance(force_bytes(123), bytes)\n        self.assertIsInstance(force_bytes(None), bytes)\n        self.assertIsInstance(force_bytes(True), bytes)\n        self.assertIsInstance(force_bytes(False), bytes)\n        self.assertIsInstance(force_bytes(1.23), bytes)\n        self.assertIsInstance(force_bytes([1, 2, 3]), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.keys()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.values()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.items()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.keys()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.values()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.items()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.keys()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.values()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.items()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.keys()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.values()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.items()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.keys()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.values()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.items()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.keys()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.values()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.items()), bytes)\n        self.assertIsInstance(force_bytes({'a': 1, 'b': 2}.keys()), bytes)\n        self"], "sample_561": ["def test_marker_scaled_invalid():\n    marker = markers.MarkerStyle(\"o\")\n    with pytest.raises(ValueError):\n        new_marker = marker.scaled(2, 3, 4)\n    with pytest.raises(ValueError):\n        new_marker = marker.scaled(2, 3, 4, 5)\n"], "sample_930": ["def test_create_triple_index_with_name(app):\n    text = (\".. index:: triple: foo; bar; baz\\n\"\n            \"   :name: ref1\\n\"\n            \".. index:: triple: Python; Sphinx; reST\\n\"\n            \"   :name: ref2\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 5\n    assert index[0] == ('B', [('bar', [[], [('baz, foo', [('', '#index-0')])], None),\n                              ('baz', [[], [('foo bar', [('', '#index-0')])], None])])\n    assert index[1] == ('F', [('foo', [[], [('bar baz', [('', '#index-0')])], None)])\n    assert index[2] == ('P', [('Python', [[], [('Sphinx reST', [('', '#index-1')])], None)])\n    assert index[3] == ('R', [('reST', [[], [('Python Sphinx', [('', '#index-1')])], None)])\n    assert index[4] == ('S', [('Sphinx', [[], [('reST, Python', [('', '#index-1')])], None]])\n\n    # check the reference labels are created correctly\n    std = app.env.get_domain('std')\n    assert std.anonlabels['ref1'] == ('index', 'ref1')\n    assert std.anonlabels['ref2'] == ('index', 'ref2')\n"], "sample_366": ["    def test_parse_postgres_interval_with_seconds(self):\n        self.assertEqual(parse_duration('1 day 00:00:01'), timedelta(days=1, seconds=1))\n        self.assertEqual(parse_duration('1 day -00:00:01'), timedelta(days=1, seconds=-1))\n        self.assertEqual(parse_duration('-1 day -00:00:01'), timedelta(days=-1, seconds=-1))\n        self.assertEqual(parse_duration('-1 day +00:00:01'), timedelta(days=-1, seconds=1))\n        self.assertEqual(parse_duration('4 days 00:15:30.1'), timedelta(days=4, minutes=15, seconds=30, milliseconds=100))\n        self.assertEqual(parse_duration('4 days 00:15:30.0001'), timedelta(days=4, minutes=15, seconds=30, microseconds=100))\n        self.assertEqual(parse_duration('-4 days -15:00:30'), timedelta(days=-4, hours=-15, seconds=-30))\n"], "sample_1199": ["def test_tensor_product_simp_with_Pow_and_Add():\n    A, B, C, D = symbols('A,B,C,D', commutative=False)\n    assert tensor_product_simp(TP(A, B)*TP(C, D) + TP(A, B)*TP(C, D)) == \\\n        2*TP(A, B)*TP(C, D)\n    assert tensor_product_simp(TP(A, B)*TP(C, D) - TP(A, B)*TP(C, D)) == \\\n        0\n    assert tensor_product_simp(TP(A, B)*TP(C, D) + TP(A, B)*TP(C, D) + TP(A, B)*TP(C, D)) == \\\n        3*TP(A, B)*TP(C, D)\n    assert tensor_product_simp(TP(A, B)*TP(C, D) - TP(A, B)*TP(C, D) + TP(A, B)*TP(C, D)) == \\\n        2*TP(A, B)*TP(C, D)\n"], "sample_641": ["def test_save_results_invalid_pylint_home() -> None:\n    \"\"\"Test that save_results raises an OSError when the pylint_home directory cannot be created.\"\"\"\n    linter_stats = LinterStats(\n        bad_names=BadNames(\n            argument=1,\n            attr=2,\n            klass=3,\n            class_attribute=4,\n            class_const=5,\n            const=6,\n            inlinevar=7,\n            function=8,\n            method=9,\n            module=10,\n            variable=11,\n            typevar=12,\n        )\n    )\n    with pytest.raises(OSError):\n        save_results(linter_stats, \".tests\", \"/non/existent/directory\")\n"], "sample_1072": ["def test_frac_real_imaginary():\n    r = Symbol('r', real=True)\n    i = Symbol('i', imaginary=True)\n    assert frac(r + i) == I*frac(r) + frac(r)\n    assert frac(r - i) == I*frac(r) + frac(r)\n    assert frac(r + i).rewrite(floor) == I*floor(r) + (r - floor(r))\n    assert frac(r - i).rewrite(floor) == I*floor(r) + (r - floor(r))\n    assert frac(r + i).rewrite(ceiling) == I*ceiling(r) + (r + ceiling(-r))\n    assert frac(r - i).rewrite(ceiling) == I*ceiling(r) + (r + ceiling(-r))\n"], "sample_569": ["    def test_regress_out(self):\n\n        x = np.array([1, 2, 3, 4, 5])\n        y = np.array([2, 4, 6, 8, 10])\n        z = np.array([1, 1, 1, 1, 1])\n\n        p = lm._RegressionPlotter(x, y, x_partial=z)\n        p.regress_out(x, z)\n\n        npt.assert_array_equal(p.x, np.array([0, 0, 0, 0, 0]))\n\n        p = lm._RegressionPlotter(x, y, y_partial=z)\n        p.regress_out(y, z)\n\n        npt.assert_array_equal(p.y, np.array([1, 3, 5, 7, 9]))\n\n        p = lm._RegressionPlotter(x, y, x_partial=z, y_partial=z)\n        p.regress_out(x, z)\n        p.regress_out(y, z)\n\n        npt.assert_array_equal(p.x, np.array([0, 0, 0, 0, 0]))\n        npt.assert_array_equal(p.y, np.array([1, 3, 5, 7, 9]))\n\n        x = pd.Series(x)\n        y = pd.Series(y)\n        z = pd.Series(z)\n\n        p = lm._RegressionPlotter(x, y, x_partial=z)\n        p.regress_out(x, z)\n\n        npt.assert_array_equal(p.x, np.array([0, 0, 0, 0, 0]))\n\n        p = lm._RegressionPlotter(x, y, y_partial=z)\n        p.regress_out(y, z)\n\n        npt.assert_array_equal(p.y, np.array([1, 3, 5, 7, 9]))\n\n        p = lm._RegressionPlotter(x, y, x_partial=z, y_partial=z)\n        p.regress_out(x, z)\n        p.regress_out(y, z)\n\n        npt.assert_array_equal(p.x, np.array([0, 0, 0, 0, 0]))\n        npt.assert_array_equal(p.y, np.array([1, 3, 5, 7, 9]))\n"], "sample_239": ["def test_formset_can_order_with_initial_data(self):\n    \"\"\"\n    Formsets with ordering + initial data.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_order=True)\n    initial = [{'choice': 'Calexico', 'votes': 100}, {'choice': 'Fergie', 'votes': 900}]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_995": ["def test_Float_precision():\n    # Make sure Float inputs for keyword args work\n    assert Float('1.0', dps=Float(15))._prec == 53\n    assert Float('1.0', precision=Float(15))._prec == 15\n    assert type(Float('1.0', precision=Float(15))._prec) == int\n    assert sympify(srepr(Float('1.0', precision=15))) == Float('1.0', precision=15)\n"], "sample_820": ["def test_transform_proba():\n    \"\"\"Check transform method of VotingClassifier on toy dataset.\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    X = np.array([[-1.1, -1.5], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n    y = np.array([1, 1, 2, 2])\n\n    eclf1 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft',\n        flatten_transform=False).fit(X, y)\n    eclf2 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft',\n        flatten_transform=True).fit(X, y)\n\n    probas1 = eclf1._collect_probas(X)\n    probas2 = eclf2._collect_probas(X)\n\n    assert_array_almost_equal(eclf1.transform(X), probas1)\n    assert_array_almost_equal(eclf2.transform(X), probas2.reshape((4, 6)))\n"], "sample_1143": ["def test_Float_as_coeff_Mul():\n    a = Float(2)\n    assert a.as_coeff_Mul() == (S.One, a)\n    assert a.as_coeff_Mul(rational=True) == (a, S.One)\n    assert a.as_coeff_Mul(rational=False) == (a, S.One)\n    assert a.as_coeff_Mul(rational=True) == (a, S.One)\n    assert a.as_coeff_Mul(rational=False) == (a, S.One)\n\n    a = Float(2.5)\n    assert a.as_coeff_Mul() == (S.One, a)\n    assert a.as_coeff_Mul(rational=True) == (a, S.One)\n    assert a.as_coeff_Mul(rational=False) == (a, S.One)\n    assert a.as_coeff_Mul(rational=True) == (a, S.One)\n    assert a.as_coeff_Mul(rational=False) == (a, S.One)\n\n    a = Float(2.5)\n    assert a.as_coeff_Mul() == (S.One, a)\n    assert a.as_coeff_Mul(rational=True) == (a, S.One)\n    assert a.as_coeff_Mul(rational=False) == (a, S.One)\n    assert a.as_coeff_Mul(rational=True) == (a, S.One)\n    assert a.as_coeff_Mul(rational=False) == (a, S.One)\n\n    a = Float(2.5)\n    assert a.as_coeff_Mul() == (S.One, a)\n    assert a.as_coeff_Mul(rational=True) == (a, S.One)\n    assert a.as_coeff_Mul(rational=False) == (a, S.One)\n    assert a.as_coeff_Mul(rational=True) == (a, S.One)\n    assert a.as_coeff_Mul(rational=False) == (a, S.One)\n\n    a = Float(2.5)\n    assert a.as_coeff_Mul() == (S.One, a)\n    assert a.as_coeff_Mul(rational=True) == (a, S.One)\n    assert a.as_coeff_Mul(rational=False) == (a, S.One)\n    assert a.as_coeff_Mul(rational=True) == (a, S.One)\n    assert a.as_coeff_Mul(rational=False) == (a, S.One)\n\n    a = Float(2.5)\n    assert a.as_coeff_Mul() == (S.One, a"], "sample_6": ["def test_angle_wrap():\n    \"\"\"\n    Test wrapping of Angle objects.\n    \"\"\"\n    a1 = Angle([0, 45, 90, 180, 270, 360, 720.], unit=u.degree)\n    a2 = a1.wrap_at(180 * u.deg)\n    npt.assert_almost_equal(a2.value, [-180, -135, 90, 0, 90, 180, 180])\n\n    a3 = Angle([0, 45, 90, 180, 270, 360, 720.], unit=u.degree)\n    a4 = a3.wrap_at(360 * u.deg)\n    npt.assert_almost_equal(a4.value, [0, 45, 90, 180, 270, 360, 0])\n\n    a5 = Angle([-180, -135, 90, 0, 90, 180, 180], unit=u.degree)\n    a6 = a5.wrap_at(180 * u.deg)\n    npt.assert_almost_equal(a6.value, [0, -135, 90, 0, 90, 0, 0])\n\n    a7 = Angle([0, 45, 90, 180, 270, 360, 720.], unit=u.degree)\n    a8 = a7.wrap_at(360 * u.deg, inplace=True)\n    npt.assert_almost_equal(a8.value, [0, 45, 90, 180, 270, 360, 0])\n\n    a9 = Angle([-180, -135, 90, 0, 90, 180, 180], unit=u.degree)\n    a10 = a9.wrap_at(180 * u.deg, inplace=True)\n    npt.assert_almost_equal(a10.value, [0, -135, 90, 0, 90, 0, 0])\n\n    a11 = Angle([0, 45, 90, 180, 270, 360, 720.], unit=u.degree)\n    a12 = a11.wrap_at(180 * u.deg, inplace=False)\n    npt.assert_almost_equal(a12.value, [-180, -135, 90, 0, 90, 180, 180])\n\n    a13 = Angle([-180, -135, 90, 0, 90, 180, 180], unit=u.degree)\n"], "sample_1134": ["def test_latex_RandomDomain():\n    from sympy.stats import Normal, Die, Exponential, pspace, where\n    from sympy.stats.rv import RandomDomain\n\n    X = Normal('x1', 0, 1)\n    assert latex(where(X > 0)) == r\"\\text{Domain: }0 < x_{1} \\wedge x_{1} < \\infty\"\n\n    D = Die('d1', 6)\n    assert latex(where(D > 4)) == r\"\\text{Domain: }d_{1} = 5 \\vee d_{1} = 6\"\n\n    A = Exponential('a', 1)\n    B = Exponential('b', 1)\n    assert latex(\n        pspace(Tuple(A, B)).domain) == \\\n        r\"\\text{Domain: }0 \\leq a \\wedge 0 \\leq b \\wedge a < \\infty \\wedge b < \\infty\"\n\n    assert latex(RandomDomain(FiniteSet(x), FiniteSet(1, 2))) == \\\n        r'\\text{Domain: }\\left\\{x\\right\\}\\text{ in }\\left\\{1, 2\\right\\}'\n"], "sample_806": ["def test_gradient_boosting_init_with_pipeline_with_sample_weight():\n    # Check that the init estimator can be a pipeline with sample_weight\n    X, y = make_regression(random_state=0)\n    init = make_pipeline(LinearRegression())\n    gb = GradientBoostingRegressor(init=init)\n    gb.fit(X, y, sample_weight=np.ones(X.shape[0]))\n"], "sample_859": ["def test_enet_path_return_models():\n    # Test that lasso_path with lars_path style output gives the\n    # same result\n\n    # Some toy data\n    X = np.array([[1, 2, 3.1], [2.3, 5.4, 4.3]]).T\n    y = np.array([1, 2, 3.1])\n    alphas = [5., 1., .5]\n\n    # Use lars_path and lasso_path(new output) with 1D linear interpolation\n    # to compute the same path\n    alphas_lars, _, coef_path_lars = lars_path(X, y, method='lasso')\n    coef_path_cont_lars = interpolate.interp1d(alphas_lars[::-1],\n                                               coef_path_lars[:, ::-1])\n    alphas_lasso2, coef_path_lasso2, _ = lasso_path(X, y, alphas=alphas,\n                                                    return_models=False)\n    coef_path_cont_lasso = interpolate.interp1d(alphas_lasso2[::-1],\n                                                coef_path_lasso2[:, ::-1])\n\n    assert_array_almost_equal(\n        coef_path_cont_lasso(alphas), coef_path_cont_lars(alphas),\n        decimal=1)\n"], "sample_252": ["    def test_json_field_on_non_json_model(self):\n        with self.assertRaisesMessage(TypeError, 'JSONField is not supported on this model'):\n            models.JSONField()\n"], "sample_773": ["def test_logistic_regression_path_multinomial():\n    # Test that the path algorithm is consistent for the multinomial case\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = [1] * 100 + [-1] * 100\n    Cs = np.logspace(0, 4, 10)\n\n    for solver in ['sag', 'saga']:\n        coefs, Cs, _ = _logistic_regression_path(\n            X, y, Cs=Cs, fit_intercept=False, tol=1e-5, solver=solver,\n            max_iter=1000, multi_class='multinomial', random_state=0)\n        for i, C in enumerate(Cs):\n            lr = LogisticRegression(C=C, fit_intercept=False, tol=1e-5,\n                                    solver=solver, multi_class='multinomial',\n                                    random_state=0, max_iter=1000)\n            lr.fit(X, y)\n            lr_coef = lr.coef_.ravel()\n            assert_array_almost_equal(lr_coef, coefs[i], decimal=4,\n                                      err_msg=\"with solver = %s\" % solver)\n\n    # test for fit_intercept=True\n    for solver in ('lbfgs', 'newton-cg'):\n        Cs = [1e3]\n        coefs, Cs, _ = _logistic_regression_path(\n            X, y, Cs=Cs, fit_intercept=True, tol=1e-6, solver=solver,\n            intercept_scaling=10000., random_state=0, multi_class='multinomial')\n        lr = LogisticRegression(C=Cs[0], fit_intercept=True, tol=1e-4,\n                                intercept_scaling=10000., random_state=0,\n                                multi_class='multinomial', solver=solver)\n        lr.fit(X, y)\n        lr_coef = np.concatenate([lr.coef_.ravel(), lr.intercept_])\n        assert_array_almost_equal(lr_coef, coefs[0], decimal=4,\n                                  err_msg=\"with solver = %s\" % solver)\n"], "sample_172": ["    def test_inline_formset_formfield_callback(self):\n        class MyInline(admin.StackedInline):\n            model = Member\n            formfield_overrides = {\n                CharField: {'widget': forms.TextInput(attrs={'size': '10'})}\n            }\n\n        ma = MyInline(Member, admin.site)\n        ff = ma.formfield_for_dbfield(Member._meta.get_field('name'), request=None)\n        self.assertIsInstance(ff.widget, forms.TextInput)\n        self.assertEqual(ff.widget.attrs['maxlength'], 100)\n        self.assertEqual(ff.widget.attrs['size'], 10)\n"], "sample_398": ["    def test_password_change_fails_with_old_password_not_provided(self):\n        self.login()\n        response = self.client.post(\n            \"/password_change/\",\n            {\n                \"new_password1\": \"password1\",\n                \"new_password2\": \"password1\",\n            },\n        )\n        self.assertFormError(\n            response, PasswordChangeForm.error_messages[\"old_password_incorrect\"]\n        )\n"], "sample_547": ["def test_offsetbox_set_width_height():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100)\n    da.set_width(50)\n    da.set_height(50)\n    assert da.width == 50\n    assert da.height == 50\n    assert da.get_bbox(ax.figure._get_renderer()).bounds == (0, 0, 50, 50)\n"], "sample_470": ["def test_lazy_classproperty_reuse_same_name(self):\n    \"\"\"\n    Reusing a classproperty on different classes under the same name is allowed.\n    \"\"\"\n    counter = 0\n\n    @classproperty\n        nonlocal counter\n        counter += 1\n        return counter\n\n    class A:\n        cp = _cp\n\n    class B:\n        cp = _cp\n\n    self.assertEqual(A.cp, 1)\n    self.assertEqual(B.cp, 1)\n    self.assertEqual(A.cp, 1)\n    self.assertEqual(B.cp, 2)\n"], "sample_1101": ["def test_schur_number_lower_bound():\n    # Test lower bound for known values\n    first_known_schur_numbers = {1: 1, 2: 4, 3: 13, 4: 44}\n    for k in first_known_schur_numbers:\n        assert SchurNumber(k).lower_bound() == first_known_schur_numbers[k]\n\n    # Test lower bound for values greater than 4\n    assert SchurNumber(5).lower_bound() == 121\n    assert SchurNumber(6).lower_bound() == 364\n    assert SchurNumber(7).lower_bound() == 1093\n\n    # Test lower bound for infinity\n    assert SchurNumber(S.Infinity).lower_bound() == S.Infinity\n\n    # Test lower bound for non-integer values\n    raises(ValueError, lambda: SchurNumber(0.5).lower_bound())\n    raises(ValueError, lambda: SchurNumber(-1).lower_bound())\n\n    # Test lower bound for non-positive integer values\n    raises(ValueError, lambda: SchurNumber(0).lower_bound())\n\n    # Test lower bound for non-integer arguments\n    n = symbols(\"n\")\n    assert SchurNumber(n).lower_bound() == 3**n/2 - Rational(1, 2)\n"], "sample_971": ["def test_warning_location_with_node(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    node = nodes.Node()\n    node.source, node.line = ('index.txt', 10)\n    logger.warning('message1', location=node)\n    assert 'index.txt:10: WARNING: message1' in warning.getvalue()\n\n    node.source, node.line = ('index.txt', None)\n    logger.warning('message2', location=node)\n    assert 'index.txt:: WARNING: message2' in warning.getvalue()\n\n    node.source, node.line = (None, 10)\n    logger.warning('message3', location=node)\n    assert '<unknown>:10: WARNING: message3' in warning.getvalue()\n\n    node.source, node.line = (None, None)\n    logger.warning('message4', location=node)\n    assert 'WARNING: message4' in warning.getvalue()\n\n    node.source, node.line = ('index.txt', 10)\n    logger.warning('message5', location=node, nonl=True)\n    assert 'index.txt:10: WARNING: message5' in warning.getvalue()\n\n    node.source, node.line = ('index.txt', None)\n    logger.warning('message6', location=node, nonl=True)\n    assert 'index.txt:: WARNING: message6' in warning.getvalue()\n\n    node.source, node.line = (None, 10)\n    logger.warning('message7', location=node, nonl=True)\n    assert '<unknown>:10: WARNING: message7' in warning.getvalue()\n\n    node.source, node.line = (None, None)\n    logger.warning('message8', location=node, nonl=True)\n    assert 'WARNING: message8' in warning.getvalue()\n"], "sample_829": ["def test_incremental_pca_batch_size_none():\n    # Test that batch_size=None is handled correctly.\n    rng = np.random.RandomState(1999)\n    n_samples = 100\n    n_features = 20\n    X = rng.randn(n_samples, n_features)\n    ipca = IncrementalPCA(n_components=None, batch_size=None)\n    ipca.fit(X)\n    assert ipca.batch_size_ == 100\n    ipca.batch_size = 50\n    ipca.fit(X)\n    assert ipca.batch_size_ == 50\n"], "sample_484": ["    def setUpTestData(cls):\n        Author.objects.create(name=\"John Smith\", alias=\"smithj\")\n        Author.objects.create(name=\"Rhonda\")\n"], "sample_609": ["def test_unify_chunks() -> None:\n    array = np.arange(10)\n    variable = xr.Variable(\"x\", array)\n    data_array = xr.DataArray(variable, [(\"x\", -array)])\n    dataset = xr.Dataset({\"y\": variable}, {\"x\": -array})\n\n    unified = unify_chunks(array, variable, data_array, dataset)\n    assert_identical(array, unified[0])\n    assert_identical(variable, unified[1])\n    assert_identical(data_array, unified[2])\n    assert_identical(dataset, unified[3])\n\n    array = np.arange(10).reshape(2, 5)\n    variable = xr.Variable([\"x\", \"y\"], array)\n    data_array = xr.DataArray(variable, {\"x\": [\"a\", \"b\"], \"y\": [-1, -2]})\n    dataset = xr.Dataset({\"data\": data_array})\n\n    unified = unify_chunks(array, variable, data_array, dataset)\n    assert_identical(array, unified[0])\n    assert_identical(variable, unified[1])\n    assert_identical(data_array, unified[2])\n    assert_identical(dataset, unified[3])\n\n    array = np.arange(10).reshape(2, 5)\n    variable = xr.Variable([\"x\", \"y\"], array)\n    data_array = xr.DataArray(variable, {\"x\": [\"a\", \"b\"], \"y\": [-1, -2]})\n    dataset = xr.Dataset({\"data\": data_array})\n\n    unified = unify_chunks(array, variable, data_array, dataset, chunks={\"x\": 1})\n    assert unified[0].chunks == {\"x\": 1, \"y\": 5}\n    assert unified[1].chunks == {\"x\": 1, \"y\": 5}\n    assert unified[2].chunks == {\"x\": 1, \"y\": 5}\n    assert unified[3].chunks == {\"x\": 1, \"y\": 5}\n\n    array = np.arange(10).reshape(2, 5)\n    variable = xr.Variable([\"x\", \"y\"], array)\n    data_array = xr.DataArray(variable, {\"x\": [\"a\", \"b\"], \"y\": [-1, -2]})\n    dataset = xr.Dataset({\"data\": data_array})\n\n    unified = unify_chunks(array, variable, data_array, dataset, chunks={\"y\": 1})\n    assert unified[0].chunks == {\"x\": 2, \"y\": 1}\n   "], "sample_613": ["def test_groupby_dataset_reduce_keepdims() -> None:\n    data = Dataset(\n        {\n            \"xy\": ([\"x\", \"y\"], np.random.randn(3, 4)),\n            \"xonly\": (\"x\", np.random.randn(3)),\n            \"yonly\": (\"y\", np.random.randn(4)),\n            \"letters\": (\"y\", [\"a\", \"a\", \"b\", \"b\"]),\n        }\n    )\n\n    expected = data.mean(\"y\", keepdims=True)\n    expected[\"yonly\"] = expected[\"yonly\"].variable.set_dims({\"x\": 3})\n    actual = data.groupby(\"x\").mean(\"y\", keepdims=True)\n    assert_allclose(expected, actual)\n\n    actual = data.groupby(\"x\").mean(\"y\", keepdims=True)\n    assert_allclose(expected, actual)\n\n    letters = data[\"letters\"]\n    expected = Dataset(\n        {\n            \"xy\": data[\"xy\"].groupby(letters).mean(\"y\", keepdims=True),\n            \"xonly\": (data[\"xonly\"].mean().variable.set_dims({\"letters\": 2})),\n            \"yonly\": data[\"yonly\"].groupby(letters).mean(\"y\", keepdims=True),\n        }\n    )\n    actual = data.groupby(\"letters\").mean(\"y\", keepdims=True)\n    assert_allclose(expected, actual)\n"], "sample_1061": ["def test_Pow_eval():\n    assert Pow(2, 3).evalf() == 8\n    assert Pow(2, 3).evalf(5) == 8\n    assert Pow(2, 3).evalf(10) == 8\n    assert Pow(2, 3).evalf(15) == 8\n    assert Pow(2, 3).evalf(20) == 8\n    assert Pow(2, 3).evalf(25) == 8\n    assert Pow(2, 3).evalf(30) == 8\n    assert Pow(2, 3).evalf(35) == 8\n    assert Pow(2, 3).evalf(40) == 8\n    assert Pow(2, 3).evalf(45) == 8\n    assert Pow(2, 3).evalf(50) == 8\n    assert Pow(2, 3).evalf(55) == 8\n    assert Pow(2, 3).evalf(60) == 8\n    assert Pow(2, 3).evalf(65) == 8\n    assert Pow(2, 3).evalf(70) == 8\n    assert Pow(2, 3).evalf(75) == 8\n    assert Pow(2, 3).evalf(80) == 8\n    assert Pow(2, 3).evalf(85) == 8\n    assert Pow(2, 3).evalf(90) == 8\n    assert Pow(2, 3).evalf(95) == 8\n    assert Pow(2, 3).evalf(100) == 8\n    assert Pow(2, 3).evalf(105) == 8\n    assert Pow(2, 3).evalf(110) == 8\n    assert Pow(2, 3).evalf(115) == 8\n    assert Pow(2, 3).evalf(120) == 8\n    assert Pow(2, 3).evalf(125) == 8\n    assert Pow(2, 3).evalf(130) == 8\n    assert Pow(2, 3).evalf(135) == 8\n   "], "sample_128": ["    def test_partial_index_condition_with_multiple_conditions(self):\n        with connection.schema_editor() as editor:\n            index = Index(\n                name='recent_article_idx',\n                fields=['pub_date', 'headline'],\n                condition=(\n                    Q(pub_date__gt=datetime.datetime(\n                        year=2015,\n                        month=1,\n                        day=1,\n                        tzinfo=timezone.get_current_timezone(),\n                    )) & Q(headline__contains='China') & Q(published=True)\n                ),\n            )\n            sql = str(index.create_sql(Article, schema_editor=editor))\n            where = sql.find('WHERE')\n            self.assertIn(\n                'WHERE (%s' % editor.quote_name('pub_date'),\n                sql\n            )\n            # Because each backend has different syntax for the operators,\n            # check ONLY the occurrence of headline in the SQL.\n            self.assertGreater(sql.rfind('headline'), where)\n            editor.add_index(index=index, model=Article)\n            with connection.cursor() as cursor:\n                self.assertIn(index.name, connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                ))\n            editor.remove_index(index=index, model=Article)\n"], "sample_725": ["def test_check_X_y():\n    # Test check_X_y function\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # Test check_X_y with multi_output=True\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([[0, 1], [1, 0]])\n    X_checked, y_checked = check_X_y(X, y, multi_output=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # Test check_X_y with multi_output=False\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([[0, 1, 2], [1, 0, 1]])\n    with pytest.raises(ValueError):\n        check_X_y(X, y, multi_output=False)\n\n    # Test check_X_y with multi_output=True and sparse y\n    X = np.array([[1, 2], [3, 4]])\n    y = sp.csr_matrix([[0, 1], [1, 0]])\n    X_checked, y_checked = check_X_y(X, y, multi_output=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # Test check_X_y with multi_output=False and sparse y\n    X = np.array([[1, 2], [3, 4]])\n    y = sp.csr_matrix([[0, 1, 2], [1, 0, 1]])\n    with pytest.raises(ValueError):\n        check_X_y(X, y, multi_output=False)\n\n    # Test check_X_y with y_numeric=True\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y, y_numeric=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # Test check_X_y with y_numeric=False\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X"], "sample_44": ["    def test_hashable(self):\n        lq1 = u.Magnitude(np.arange(1., 10.)*u.Jy)\n        lq2 = u.Magnitude(np.arange(1., 10.)*u.Jy)\n        lq3 = u.Magnitude(np.arange(1., 10.)*u.m)\n        lq4 = u.Magnitude(np.arange(1., 10.)*u.m)\n        assert hash(lq1) != hash(lq2)\n        assert hash(lq1) == hash(lq3)\n        assert hash(lq3) == hash(lq4)\n        lqset = {lq1, lq2, lq3}\n        assert len(lqset) == 2\n"], "sample_812": ["def test_n_max_elements_to_show_dict():\n    # Test that n_max_elements_to_show works for dictionaries\n    n_max_elements_to_show = 30\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=n_max_elements_to_show\n    )\n\n    # No ellipsis\n    param_grid = {'C': {i: i for i in range(n_max_elements_to_show)}}\n    gs = GridSearchCV(SVC(), param_grid)\n    expected = \"\"\""], "sample_408": ["def test_alter_field_with_default(self):\n    \"\"\"\n    #23609 - Altering a field with a default should work.\n    \"\"\"\n    changes = self.get_changes([self.author_name], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=\"Ada Lovelace\")\n"], "sample_179": ["    def test_index_with_condition_and_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_partial_indexes'}\n                indexes = [\n                    models.Index(\n                        fields=['age'],\n                        name='index_age_gte_10',\n                        condition=models.Q(age__gte=10),\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_partial_indexes else [\n            Warning(\n                '%s does not support indexes with conditions.'\n                % connection.display_name,\n                hint=(\n                    \"Conditions will be ignored. Silence this warning if you \"\n                    \"don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W037',\n            )\n        ]\n        self.assertEqual(errors, expected)\n"], "sample_176": ["def test_alter_field_with_default(self):\n    \"\"\"#23609 - Altering a field with a default should work.\"\"\"\n    changes = self.get_changes([self.author_name], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, 'testapp', 0, 0, default='Ada Lovelace')\n"], "sample_48": ["def test_aggregate_with_subquery(self):\n    \"\"\"\n    Test that aggregate functions work with subqueries.\n    \"\"\"\n    vals = Book.objects.filter(\n        rating__gt=Book.objects.filter(authors__name__contains=\"Norvig\").aggregate(Avg(\"rating\"))['rating__avg']\n    ).aggregate(Avg(\"rating\"))\n    self.assertEqual(vals, {'rating__avg': Approximate(4.5, places=2)})\n"], "sample_481": ["    def test_stringformat01(self):\n        output = self.engine.render_to_string(\"stringformat01\")\n        self.assertEqual(output, \"hello world\")\n"], "sample_633": ["def test_ignore_signatures_multiline_fail() -> None:\n    output = StringIO()\n    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n        similar.Run([\"--ignore-signatures\", SIMILAR5, SIMILAR6])\n    assert ex.value.code == 0\n    assert (\n        output.getvalue().strip()\n        == (\n            f'''"], "sample_1021": ["def test_quaternion_from_axis_angle():\n    q1 = Quaternion.from_axis_angle((1, 0, 0), pi/2)\n    assert q1 == Quaternion(0, 1, 0, 0)\n\n    q2 = Quaternion.from_axis_angle((0, 1, 0), pi/2)\n    assert q2 == Quaternion(0, 0, 1, 0)\n\n    q3 = Quaternion.from_axis_angle((0, 0, 1), pi/2)\n    assert q3 == Quaternion(0, 0, 0, 1)\n\n    q4 = Quaternion.from_axis_angle((1, 0, 0), 0)\n    assert q4 == Quaternion(1, 0, 0, 0)\n\n    q5 = Quaternion.from_axis_angle((0, 1, 0), 0)\n    assert q5 == Quaternion(1, 0, 0, 0)\n\n    q6 = Quaternion.from_axis_angle((0, 0, 1), 0)\n    assert q6 == Quaternion(1, 0, 0, 0)\n\n    q7 = Quaternion.from_axis_angle((1, 0, 0), pi)\n    assert q7 == Quaternion(-1, 0, 0, 0)\n\n    q8 = Quaternion.from_axis_angle((0, 1, 0), pi)\n    assert q8 == Quaternion(0, -1, 0, 0)\n\n    q9 = Quaternion.from_axis_angle((0, 0, 1), pi)\n    assert q9 == Quaternion(0, 0, -1, 0)\n\n    q10 = Quaternion.from_axis_angle((1, 0, 0), 2*pi)\n    assert q10 == Quaternion(1, 0, 0, 0)\n\n    q11 = Quaternion.from_axis_angle((0, 1, 0), 2*pi)\n    assert q11 == Quaternion(1, 0, 0, 0)\n\n    q12 = Quaternion.from_axis_angle((0, 0, 1), 2*pi)\n    assert q12 == Quaternion(1, 0, 0, 0)\n\n    q13 = Quaternion.from_axis_angle((1, 0, 0), -pi/2)\n    assert q13 == Quaternion(0, -1, 0, 0)\n\n    q"], "sample_912": ["def test_pydata_signature_with_type_and_value(app):\n    text = (\".. py:data:: var\\n\"\n            \"   :type: int\\n\"\n            \"   :value: 1\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"var\"],\n                                                    [desc_annotation, \": int\"],\n                                                    [desc_annotation, \" = 1\"])],\n                                  [desc_content, ()])]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n    assert 'var' in domain.objects\n    assert domain.objects['var'] == ('index', 'var', 'data')\n"], "sample_307": ["def test_dateformat_with_timezone_name(self):\n    my_birthday = datetime(1979, 7, 8, 22, 00)\n    summertime = datetime(2005, 10, 30, 1, 00)\n    wintertime = datetime(2005, 10, 30, 4, 00)\n    timestamp = datetime(2008, 5, 19, 11, 45, 23, 123456)\n\n    # 3h30m to the west of UTC\n    tz = get_fixed_timezone(-210)\n    aware_dt = datetime(2009, 5, 16, 5, 30, 30, tzinfo=tz)\n\n    if TZ_SUPPORT:\n        self.assertEqual(dateformat.format(my_birthday, 'e'), '')\n        self.assertEqual(dateformat.format(aware_dt, 'e'), '-0330')\n        self.assertEqual(dateformat.format(summertime, 'e'), '')\n        self.assertEqual(dateformat.format(wintertime, 'e'), '')\n"], "sample_480": ["    def test_key_transform_gt(self):\n        self.assertCountEqual(\n            NullableJSONModel.objects.filter(value__c__gt=2),\n            [self.objs[3], self.objs[4]],\n        )\n        self.assertCountEqual(\n            NullableJSONModel.objects.filter(value__c__gt=2.33),\n            [self.objs[3], self.objs[4]],\n        )\n        self.assertIs(NullableJSONModel.objects.filter(value__c__lt=5).exists(), False)\n"], "sample_342": ["def test_limit_choices_to_with_related_field(self):\n    # Answer.question_with_to_field defines limit_choices_to to \"those not\n    # starting with 'not'\".\n    q = Question.objects.create(question='Is this a question?')\n    Question.objects.create(question='Not a question.')\n    request = self.factory.get(self.url, {'term': 'is', **self.opts, 'field_name': 'question_with_to_field'})\n    request.user = self.superuser\n    response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    self.assertEqual(response.status_code, 200)\n    data = json.loads(response.content.decode('utf-8'))\n    self.assertEqual(data, {\n        'results': [{'id': str(q.uuid), 'text': q.question}],\n        'pagination': {'more': False},\n    })\n"], "sample_788": ["def test_encode_option_sparse():\n    est = KBinsDiscretizer(n_bins=[2, 3, 3, 3], encode='onehot-dense')\n    Xt = est.fit_transform(X)\n    assert not sp.issparse(Xt)\n    est = KBinsDiscretizer(n_bins=[2, 3, 3, 3], encode='onehot')\n    Xt = est.fit_transform(X)\n    assert sp.issparse(Xt)\n    assert_array_equal(OneHotEncoder(\n                           categories=[np.arange(i) for i in [2, 3, 3, 3]],\n                           sparse=True)\n                       .fit_transform(Xt).toarray(),\n                       Xt.toarray())\n"], "sample_617": ["def test_cross_broadcast_compat_data() -> None:\n    a = xr.DataArray(\n        np.array([1, 2, 0]),\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    b = xr.DataArray(\n        np.array([4, 5, 6]),\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n\n    # a has zeros at the last axis, so it should be treated like a 2D array\n    expected = np.cross(a.data[:, :2], b.data)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n\n    # b has zeros at the last axis, so it should be treated like a 2D array\n    expected = np.cross(a.data, b.data[:, :2])\n    actual = xr.cross(b, a, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n\n    # a and b have different sizes, so they should be padded with zeros\n    expected = np.cross(a.data[:, :2], b.data)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n\n    # a and b have different sizes, so they should be padded with zeros\n    expected = np.cross(a.data, b.data[:, :2])\n    actual = xr.cross(b, a, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n\n    # a has coords in different positions, so it should be treated like a 2D array\n    a = xr.DataArray(\n        np.array([1, 2]),\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"z\"])),\n    )\n    expected = np.cross(a.data, b.data)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n\n    # b has coords in different positions, so it should be treated like a 2D array\n    b = xr.DataArray(\n        np.array([4, 5, 6]),\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \""], "sample_22": ["def test_matrix_transpose():\n    \"\"\"Test the matrix transpose function.\"\"\"\n    m1 = rotation_matrix(35 * u.deg, \"x\")\n    m2 = matrix_transpose(m1)\n    assert_array_equal(m2, m1.T)\n\n    m3 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    m4 = matrix_transpose(m3)\n    assert_array_equal(m4, m3.T)\n\n    # Test broadcasting\n    m5 = np.tile(m1, (2, 1, 1))\n    m6 = matrix_transpose(m5)\n    assert_array_equal(m6, m5.swapaxes(-2, -1))\n\n    # Test with a stack of matrices\n    m7 = np.stack((m1, m3))\n    m8 = matrix_transpose(m7)\n    assert_array_equal(m8, m7.swapaxes(-2, -1))\n"], "sample_554": ["def test_wrap_rotation():\n    fig, ax = plt.subplots()\n    s = 'This is a very long text that should be wrapped multiple times.'\n    text = ax.text(0.1, 0.5, s, wrap=True, rotation=30)\n    fig.canvas.draw()\n    assert text._get_wrapped_text() == ('This is a very long\\n'\n                                        'text that should be\\n'\n                                        'wrapped multiple\\n'\n                                        'times.')\n"], "sample_622": ["    def test_decode_cf_variable_with_unsigned_integer(self) -> None:\n        v = Variable([\"t\"], [1, 2, 3], {\"units\": \"m\", \"Unsigned\": True})\n        v_decoded = conventions.decode_cf_variable(\"test2\", v)\n        assert_identical(v, v_decoded)\n"], "sample_357": ["def test_alter_field_to_foreign_key(self):\n    \"\"\"Tests autodetection of field type changes from non-foreign key to foreign key.\"\"\"\n    changes = self.get_changes([self.author_empty, self.book_with_no_author], [self.author_empty, self.book])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, model_name=\"book\", name=\"author\")\n    self.assertEqual(changes['otherapp'][0].operations[0].field.remote_field.model, 'testapp.Author')\n"], "sample_1187": ["def test_hyperplane_parameters():\n    #  Test cases for 2D polytopes\n    triangle = Polygon(Point(0, 3), Point(5, 3), Point(1, 1))\n    assert hyperplane_parameters(triangle) == [((0, 1), 3), ((1, -2), -1), ((-2, -1), -3)]\n\n    hexagon = Polygon(Point(0, 0), Point(-sqrt(3) / 2, S.Half), Point(-sqrt(3) / 2, S(3) / 2), Point(0, 2), Point(sqrt(3) / 2, S(3) / 2), Point(sqrt(3) / 2, S.Half))\n    assert hyperplane_parameters(hexagon) == [((-1, 0), -sqrt(3) / 2), ((0, -1), -3), ((0, 1), 3), ((1, 0), sqrt(3) / 2), ((-1, 0), sqrt(3) / 2), ((0, -1), -sqrt(3) / 2)]\n\n    #  Test cases for 3D polytopes\n    cube = [[(0, 0, 0), (0, 0, 5), (0, 5, 0), (0, 5, 5), (5, 0, 0), (5, 0, 5), (5, 5, 0), (5, 5, 5)],\n            [2, 6, 7, 3], [3, 7, 5, 1], [7, 6, 4, 5], [1, 5, 4, 0], [3, 1, 0, 2], [0, 4, 6, 2]]\n    assert hyperplane_parameters(cube[1:], cube[0]) == [([0, -1, 0], -5), ([0, 0, -1], -5), ([-1, 0, 0], -5), ([0, 1, 0], 0), ([1, 0, 0], 0), ([0, 0, 1], 0)]\n\n    octahedron = [[(0"], "sample_524": ["def test_colorbar_orientation():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc, orientation='horizontal')\n    assert cb.ax.get_orientation() == 'horizontal'\n    cb = fig.colorbar(pc, orientation='vertical')\n    assert cb.ax.get_orientation() == 'vertical'\n"], "sample_75": ["    def test_prefetch_related_with_limit(self):\n        with self.assertNumQueries(2):\n            qs = Book.objects.prefetch_related('authors').limit(1)\n            lists = [list(b.authors.all()) for b in qs]\n\n        normal_lists = [list(b.authors.all()) for b in Book.objects.all()]\n        self.assertEqual(lists, normal_lists[:1])\n"], "sample_92": ["    def setUpTestData(cls):\n        cls.user = User.objects.create_user('test', 'test@example.com', 'test')\n"], "sample_807": ["def test_calibration_class_weight():\n    \"\"\"Test calibration with class weights\"\"\"\n    n_samples = 100\n    X, y = make_classification(n_samples=2 * n_samples, n_features=6,\n                               random_state=42)\n    sample_weight = np.random.RandomState(seed=42).uniform(size=y.size)\n\n    X -= X.min()  # MultinomialNB only allows positive X\n\n    # split train and test\n    X_train, y_train, sw_train = \\\n        X[:n_samples], y[:n_samples], sample_weight[:n_samples]\n    X_test, y_test = X[n_samples:], y[n_samples:]\n\n    # Naive-Bayes\n    clf = MultinomialNB()\n    clf.fit(X_train, y_train, sample_weight=sw_train)\n    prob_pos_clf = clf.predict_proba(X_test)[:, 1]\n\n    # Naive Bayes with calibration\n    for this_X_train, this_X_test in [(X_train, X_test),\n                                      (sparse.csr_matrix(X_train),\n                                       sparse.csr_matrix(X_test))]:\n        for method in ['isotonic', 'sigmoid']:\n            pc_clf = CalibratedClassifierCV(clf, method=method, cv=2)\n            # Note that this fit overwrites the fit on the entire training\n            # set\n            pc_clf.fit(this_X_train, y_train, sample_weight=sw_train)\n            prob_pos_pc_clf = pc_clf.predict_proba(this_X_test)[:, 1]\n\n            # Check that brier score has improved after calibration\n            assert_greater(brier_score_loss(y_test, prob_pos_clf),\n                           brier_score_loss(y_test, prob_pos_pc_clf))\n\n            # Check invariance against relabeling [0, 1] -> [1, 2]\n            pc_clf.fit(this_X_train, y_train + 1, sample_weight=sw_train)\n            prob_pos_pc_clf_relabeled = pc_clf.predict_proba(this_X_test)[:, 1]\n            assert_array_almost_equal(prob_pos_pc_clf,\n                                      prob_pos_pc_clf_relabeled)\n\n            # Check invariance against relabeling [0, 1] -> [-1, 1]\n            pc_clf.fit(this_X_train, 2 * y_train - 1, sample_weight=sw_train)\n            prob_pos_pc_clf_relabeled = pc_clf.predict_proba(this_X_test)[:, 1]\n            assert"], "sample_224": ["def test_aggregate_annotation_with_subquery(self):\n    \"\"\"\n    Test that aggregate annotations with subqueries are correctly handled.\n    \"\"\"\n    subquery = Book.objects.filter(publisher=OuterRef('pk')).values('rating')[:1]\n    vals = Publisher.objects.annotate(avg_rating=Subquery(subquery)).aggregate(avg_rating=Avg('avg_rating'))\n    self.assertEqual(vals['avg_rating'], 4.0)\n"], "sample_915": ["def test_isabstractmethod():\n    class Foo:\n        @abstractmethod\n            pass\n\n    class Bar(Foo):\n            pass\n\n    assert inspect.isabstractmethod(Foo.meth) is True\n    assert inspect.isabstractmethod(Bar.meth) is False\n"], "sample_211": ["    def _assert_about(self, response):\n        response.render()\n        self.assertContains(response, '<h1>About</h1>')\n"], "sample_1203": ["def test_kernel():\n    F, a, b = free_group(\"a, b\")\n    G = FpGroup(F, [a**3, b**3, (a*b)**2])\n    T = homomorphism(G, AlternatingGroup(4), G.generators)\n    assert T.kernel().order() == 6\n    assert T.kernel().is_subgroup(G)\n\n    E, e = free_group(\"e\")\n    G = FpGroup(E, [e**8])\n    P = PermutationGroup([Permutation(0, 1, 2, 3), Permutation(0, 2)])\n    T = homomorphism(G, P, [e], [Permutation(0, 1, 2, 3)])\n    assert T.kernel().order() == 8\n    assert T.kernel().is_subgroup(G)\n\n    F, a, b = free_group(\"a, b\")\n    G = FpGroup(F, [a**3, b**3, (a*b)**2])\n    T = homomorphism(G, AlternatingGroup(4), G.generators, [a, b])\n    assert T.kernel().order() == 6\n    assert T.kernel().is_subgroup(G)\n\n    # Test that kernel computation is not implemented for infinite groups\n    G = FpGroup(F, [a**2, b**3])\n    raises(NotImplementedError, lambda: T = homomorphism(G, AlternatingGroup(4), G.generators))\n\n    # Test that kernel computation is not implemented for infinite groups\n    G = FpGroup(F, [a**2, b**3])\n    raises(NotImplementedError, lambda: T.kernel())\n"], "sample_689": ["def test_pytest_warning_captured_is_deprecated(testdir: Testdir) -> None:\n    \"\"\"pytest_warning_captured is deprecated and will be removed in a future release.\"\"\"\n    threepass = testdir.makepyfile(\n        test_threepass=\"\"\"\n    \"\"\"\n    )\n    result = testdir.runpytest(\n        \"-k\", \"test_two\", \"--warning-record\", threepass\n    )\n    result.stdout.fnmatch_lines([\"*The pytest_warning_captured is deprecated*\"])\n"], "sample_233": ["def test_token_with_different_password(self):\n    \"\"\"\n    A valid token can be created with a password other than the one used to\n    create the user.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    user.set_password('newpw')\n    user.save()\n    self.assertIs(p0.check_token(user, tk1), False)\n"], "sample_1090": ["def test_complex():\n    with evaluate(False):\n        assert (x + S.ImaginaryUnit*x).args == (x, S.ImaginaryUnit*x)\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n\n        assert (x + S.ImaginaryUnit*x).args_cse() == (x, S.ImaginaryUnit*x)\n        assert (x + S.ImaginaryUnit*x).args_cse() =="], "sample_1201": ["def test_cgs_gauss_convert_units():\n    # Test conversion of units from cgs_gauss to other systems\n    assert convert_to(centimeter, meter, cgs_gauss) == meter/100\n    assert convert_to(gram, kilogram, cgs_gauss) == kilogram/1000\n    assert convert_to(second, second, cgs_gauss) == second\n    assert convert_to(erg, joule, cgs_gauss) == joule/10**7\n    assert convert_to(erg, joule, SI) == joule/10**7\n    assert convert_to(joule, erg, cgs_gauss) == 10**7*erg\n    assert convert_to(joule, erg, SI) == 10**7*erg\n\n    # Test conversion of units from other systems to cgs_gauss\n    assert convert_to(meter, centimeter, SI) == 100*centimeter\n    assert convert_to(kilogram, gram, SI) == 1000*gram\n    assert convert_to(second, second, SI) == second\n    assert convert_to(joule, erg, SI) == 10**7*erg\n    assert convert_to(joule, erg, cgs_gauss) == 10**7*erg\n\n    # Test conversion of units between different systems\n    assert convert_to(centimeter, meter, SI) == meter/100\n    assert convert_to(gram, kilogram, cgs_gauss) == kilogram/1000\n    assert convert_to(second, second, SI) == second\n    assert convert_to(erg, joule, cgs_gauss) == joule/10**7\n    assert convert_to(erg, joule, SI) == joule/10**7\n    assert convert_to(joule, erg, cgs_gauss) == 10**7*erg\n    assert convert_to(joule, erg, SI) == 10**7*erg\n"], "sample_847": ["def test_enet_path_return_models():\n    # Test that lasso_path with lars_path style output gives the\n    # same result\n\n    # Some toy data\n    X = np.array([[1, 2, 3.1], [2.3, 5.4, 4.3]]).T\n    y = np.array([1, 2, 3.1])\n    alphas = [5., 1., .5]\n\n    # Use lars_path and lasso_path(new output) with 1D linear interpolation\n    # to compute the same path\n    alphas_lars, _, coef_path_lars = lars_path(X, y, method='lasso')\n    coef_path_cont_lars = interpolate.interp1d(alphas_lars[::-1],\n                                               coef_path_lars[:, ::-1])\n    alphas_lasso2, coef_path_lasso2, _ = lasso_path(X, y, alphas=alphas,\n                                                    return_models=True)\n    coef_path_cont_lasso = interpolate.interp1d(alphas_lasso2[::-1],\n                                                coef_path_lasso2[:, ::-1])\n\n    assert_array_almost_equal(\n        coef_path_cont_lasso(alphas), coef_path_cont_lars(alphas),\n        decimal=1)\n"], "sample_478": ["    def test_prepopulated_fields_value_item_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            prepopulated_fields = {\"slug\": \"test\"}\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'prepopulated_fields[\\\"slug\\\"]' must be a list or tuple.\",\n            \"admin.E029\",\n        )\n"], "sample_1": ["def test_separability_matrix_custom_model():\n    @custom_model\n        return x\n\n    assert np.all(separability_matrix(model_a()) == [[True]])\n\n    @custom_model\n        return x + y\n\n    assert np.all(separability_matrix(model_b()) == [[True, True]])\n\n    @custom_model\n        return x + y + z\n\n    assert np.all(separability_matrix(model_c()) == [[True, True, True]])\n\n    @custom_model\n        return x * y\n\n    assert np.all(separability_matrix(model_d()) == [[False]])\n\n    @custom_model\n        return x / y\n\n    assert np.all(separability_matrix(model_e()) == [[False]])\n\n    @custom_model\n        return x ** y\n\n    assert np.all(separability_matrix(model_f()) == [[False]])\n"], "sample_798": ["def test_ridge_regression_sample_weights_sparse():\n    # Test that sample weights work with sparse matrices\n    rng = np.random.RandomState(0)\n\n    for solver in (\"cholesky\", ):\n        for n_samples, n_features in ((6, 5), (5, 10)):\n            for alpha in (1.0, 1e-2):\n                y = rng.randn(n_samples)\n                X = rng.randn(n_samples, n_features)\n                X_sparse = sp.csr_matrix(X)\n                sample_weight = 1.0 + rng.rand(n_samples)\n\n                coefs = ridge_regression(X_sparse, y,\n                                         alpha=alpha,\n                                         sample_weight=sample_weight,\n                                         solver=solver)\n\n                # Sample weight can be implemented via a simple rescaling\n                # for the square loss.\n                coefs2 = ridge_regression(\n                    X_sparse * np.sqrt(sample_weight)[:, np.newaxis],\n                    y * np.sqrt(sample_weight),\n                    alpha=alpha, solver=solver)\n                assert_array_almost_equal(coefs, coefs2)\n"], "sample_519": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect((1, 2, 3))\n    ax2.set_box_aspect((2, 1, 1))\n"], "sample_291": ["    def _assert_about(self, response):\n        response.render()\n        self.assertContains(response, '<h1>About</h1>')\n"], "sample_680": ["    def test_xfail_raises_with_multiple_exceptions(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(raises=(TypeError, ValueError))\n                raise TypeError()\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n"], "sample_99": ["def test_trunc_func_with_timezone(self):\n    \"\"\"\n    If the truncated datetime transitions to a different offset (daylight\n    saving) then the returned value will have that new timezone/offset.\n    \"\"\"\n    start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n    end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n    if settings.USE_TZ:\n        start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n        end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n    self.create_model(end_datetime, start_datetime)\n\n    melb = pytz.timezone('Australia/Melbourne')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=DateTimeField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(melb), kind, melb)),\n                (end_datetime, truncate_to(end_datetime.astimezone(melb), kind, melb))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_date', kind, output_field=DateField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.date(), kind)),\n                (end_datetime, truncate_to(end_datetime.date(), kind))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_time', kind, output_field=TimeField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.time(), kind)),\n                (end_datetime, truncate_to(end_datetime.time(), kind))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_date_kind('year')\n    test_date_kind('quarter')\n    test_date_kind('month')\n    test_date_kind('week')\n    test_date_kind('day')\n    test_time"], "sample_516": ["def test_alpha_state():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3])\n    ax.set_title('Axes Title', fontproperties=FontProperties(alpha=0.5))\n    pdf = PdfPages(io.BytesIO())\n    pdf.savefig(fig)\n    pdf.close()\n    with open(pdf._file.fh.name, 'rb') as f:\n        pdf_data = f.read()\n    assert b'A1' in pdf_data\n"], "sample_87": ["    def test_iter_modules_and_files_cache(self):\n        filename = self.temporary_file('test_module.py')\n        filename.write_text('import os')\n        with extend_sys_path(str(filename.parent)):\n            self.import_and_cleanup('test_module')\n\n        self.clear_autoreload_caches()\n        self.assertFileFound(filename)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().hits, 1)\n\n        self.clear_autoreload_caches()\n        self.assertFileFound(filename)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().hits, 2)\n\n        self.clear_autoreload_caches()\n        self.assertFileNotFound(filename)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().hits, 3)\n"], "sample_996": ["def test_issue_12345():\n    n = Symbol('n', integer=True)\n    p = Product(1 + 1/n, (n, 1, oo))\n    assert p.is_convergent() is S.false\n    assert product(1 + 1/n, (n, 1, oo)) == p.doit()\n"], "sample_549": ["def test_safe_masked_invalid():\n    a = np.ma.array([1, 2, 3, np.nan, np.nan, 6])\n    a = cbook.safe_masked_invalid(a)\n    assert_array_equal(a.data, np.array([1, 2, 3, np.nan, np.nan, 6]))\n    assert_array_equal(a.mask, np.array([False, False, False, True, True, False]))\n\n    a = np.ma.array([1, 2, 3, np.nan, np.nan, 6], dtype=np.float32)\n    a = cbook.safe_masked_invalid(a)\n    assert_array_equal(a.data, np.array([1, 2, 3, np.nan, np.nan, 6], dtype=np.float32))\n    assert_array_equal(a.mask, np.array([False, False, False, True, True, False]))\n\n    a = np.ma.array([1, 2, 3, np.nan, np.nan, 6], dtype=np.float64)\n    a = cbook.safe_masked_invalid(a)\n    assert_array_equal(a.data, np.array([1, 2, 3, np.nan, np.nan, 6], dtype=np.float64))\n    assert_array_equal(a.mask, np.array([False, False, False, True, True, False]))\n\n    a = np.ma.array([1, 2, 3, np.nan, np.nan, 6], dtype=np.int32)\n    a = cbook.safe_masked_invalid(a)\n    assert_array_equal(a.data, np.array([1, 2, 3, np.nan, np.nan, 6], dtype=np.int32))\n    assert_array_equal(a.mask, np.array([False, False, False, True, True, False]))\n\n    a = np.ma.array([1, 2, 3, np.nan, np.nan, 6], dtype=np.int64)\n    a = cbook.safe_masked_invalid(a)\n    assert_array_equal(a.data, np.array([1, 2, 3, np.nan, np.nan, 6], dtype=np.int64))\n    assert_array_equal(a.mask, np.array([False, False, False, True, True, False]))\n\n    a = np.ma.array([1, 2, 3, np.nan, np.nan, 6], dtype=np.complex64)\n    a = cbook.safe_masked_invalid(a)\n   "], "sample_46": ["    def setUpTestData(cls):\n        cls.objs = [\n            UUIDModel.objects.create(field=uuid.uuid4()),\n            UUIDModel.objects.create(field='2020-01-01'),\n            UUIDModel.objects.create(field='2020-01-02'),\n        ]\n"], "sample_1137": ["def test_quantity_simplify_with_prefixes():\n    u = Quantity(\"u\")\n    u.set_global_relative_scale_factor(kilo, meter)\n\n    assert quantity_simplify(u) == meter\n    assert quantity_simplify(kilo*u) == kilo*meter\n    assert quantity_simplify(kilo*u**2) == kilo*meter**2\n    assert quantity_simplify(kilo*u**-1) == 1/meter\n    assert quantity_simplify(kilo*u**-2) == 1/meter**2\n\n    v = Quantity(\"v\")\n    v.set_global_relative_scale_factor(micro, meter)\n\n    assert quantity_simplify(v) == meter\n    assert quantity_simplify(micro*v) == micro*meter\n    assert quantity_simplify(micro*v**2) == micro*meter**2\n    assert quantity_simplify(micro*v**-1) == 1/meter\n    assert quantity_simplify(micro*v**-2) == 1/meter**2\n\n    w = Quantity(\"w\")\n    w.set_global_relative_scale_factor(milli, meter)\n\n    assert quantity_simplify(w) == meter\n    assert quantity_simplify(milli*w) == milli*meter\n    assert quantity_simplify(milli*w**2) == milli*meter**2\n    assert quantity_simplify(milli*w**-1) == 1/meter\n    assert quantity_simplify(milli*w**-2) == 1/meter**2\n\n    with warns_deprecated_sympy():\n        Quantity('invalid', 'dimension', 1)\n    with warns_deprecated_sympy():\n        Quantity('mismatch', dimension=length, scale_factor=kg)\n"], "sample_900": ["def test_max_iter():\n    # Test max_iter.\n    # It should force the solver to exit the loop when it reaches max_iter.\n    X = [[3, 2], [1, 6]]\n    y = [1, 0]\n    clf = MLPClassifier(max_iter=2, solver='sgd')\n    with ignore_warnings(category=ConvergenceWarning):\n        clf.fit(X, y)\n    assert clf.n_iter_ == clf.max_iter\n"], "sample_1097": ["def test_BlockMatrix_inverse():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n    assert block_collapse(X.I) == BlockMatrix([\n        [(-B*D.I*C + A).I, -A.I*B*(D + -C*A.I*B).I],\n        [-(D - C*A.I*B).I*C*A.I, (D - C*A.I*B).I]])\n\n    assert isinstance(X.I, Inverse)\n\n    assert not X.is_Identity\n\n    Z = BlockMatrix([[Identity(n), B], [C, D]])\n    assert not Z.is_Identity\n\n    assert X.is_square\n\n    Q = X + Identity(m + n)\n    assert (block_collapse(Q) ==\n        BlockMatrix([[A + Identity(n), B], [C, D + Identity(m)]]))\n\n    assert (X + MatrixSymbol('Q', n + m, n + m)).is_MatAdd\n    assert (X * MatrixSymbol('Q', n + m, n + m)).is_MatMul\n\n    assert block_collapse(Y.I) == A.I\n    Y = BlockMatrix([[A]])\n    assert block_collapse(Y.I) == A.I\n\n    assert isinstance(X.inverse(), Inverse)\n\n    assert not X.is_Identity\n\n    Z = BlockMatrix([[Identity(n), B], [C, D]])\n    assert not Z.is_Identity\n"], "sample_162": ["    def setUp(self):\n        super().setUp()\n        self.symlinked_dir = os.path.join(self.test_dir, 'templates_symlinked')\n"], "sample_974": ["compilation error"], "sample_719": ["def test_hashingvectorizer_dtype():\n    # Non-regression test: HashingVectorizer used to ignore its \"dtype\" param.\n    v = HashingVectorizer(dtype=np.float32)\n    assert_equal(v.dtype, np.float32)\n\n    X = v.fit_transform(['hello world', 'hello hello']).toarray()\n    assert_equal(X.dtype, np.float32)\n    X2 = v.transform(['hello world', 'hello hello']).toarray()\n    assert_equal(X2.dtype, np.float32)\n"], "sample_1183": ["def test_Domain_unify_with_FiniteExtension():\n    KxZZ = FiniteExtension(Poly(x**2 - 2, x, domain=ZZ))\n    KxQQ = FiniteExtension(Poly(x**2 - 2, x, domain=QQ))\n    KxZZy = FiniteExtension(Poly(x**2 - 2, x, domain=ZZ[y]))\n    KxQQy = FiniteExtension(Poly(x**2 - 2, x, domain=QQ[y]))\n\n    assert KxZZ.unify(KxZZ) == KxZZ\n    assert KxQQ.unify(KxQQ) == KxQQ\n    assert KxZZy.unify(KxZZy) == KxZZy\n    assert KxQQy.unify(KxQQy) == KxQQy\n\n    assert KxZZ.unify(ZZ) == KxZZ\n    assert KxZZ.unify(QQ) == KxQQ\n    assert KxQQ.unify(ZZ) == KxQQ\n    assert KxQQ.unify(QQ) == KxQQ\n\n    assert KxZZ.unify(ZZ[y]) == KxZZy\n    assert KxZZ.unify(QQ[y]) == KxQQy\n    assert KxQQ.unify(ZZ[y]) == KxQQy\n    assert KxQQ.unify(QQ[y]) == KxQQy\n\n    assert KxZZy.unify(ZZ) == KxZZy\n    assert KxZZy.unify(QQ) == KxQQy\n    assert KxQQy.unify(ZZ) == KxQQy\n    assert KxQQy.unify(QQ) == KxQQy\n\n    K = FiniteExtension(Poly(x**2 - 2, x, domain=ZZ[y]))\n    assert K.unify(ZZ) == K\n    assert K.unify(ZZ[x]) == K\n    assert K.unify(ZZ[y]) == K\n    assert K.unify(ZZ[x, y]) == K\n\n    Kz = FiniteExtension(Poly(x**2 - 2, x, domain=ZZ[y, z]))\n    assert K.unify(ZZ[z]) == Kz\n    assert K.unify(ZZ[x, z]) == Kz\n    assert K.unify(ZZ[y, z]) == Kz\n    assert K"], "sample_579": ["    def test_heatmap_annotation_with_mask_and_limited_ticklabels(self):\n\n        df = pd.DataFrame(data={'a': [1, 1, 1],\n                                'b': [2, np.nan, 2],\n                                'c': [3, 3, np.nan]})\n\n        kws = self.default_kws.copy()\n        kws[\"mask\"] = np.isnan(df.values)\n        kws[\"xticklabels\"] = False\n        kws[\"yticklabels\"] = False\n\n        ax = mat.heatmap(df, annot=True, fmt=\".1f\", **kws)\n        for val, text in zip(df.compressed(), ax.texts):\n            assert text.get_text() == f\"{val:.1f}\"\n"], "sample_493": ["def test_aggregate_subquery_annotation_values_list(self):\n    \"\"\"\n    Subquery annotations and external aliases are excluded from the GROUP BY if\n    they are not selected.\n    \"\"\"\n    books_qs = (\n        Book.objects.annotate(\n            first_author_the_same_age=Subquery(\n                Author.objects.filter(\n                    age=OuterRef(\"contact__friends__age\"),\n                )\n                .order_by(\"age\")\n                .values(\"id\")[:1],\n            )\n        )\n        .filter(\n            publisher=self.p1,\n            first_author_the_same_age__isnull=False,\n        )\n        .annotate(\n            min_age=Min(\"contact__friends__age\"),\n        )\n        .values(\"name\", \"min_age\")\n        .order_by(\"name\")\n    )\n    self.assertEqual(\n        list(books_qs),\n        [\n            {\"name\": \"Practical Django Projects\", \"min_age\": 34},\n            {\n                \"name\": (\n                    \"The Definitive Guide to Django: Web Development Done Right\"\n                ),\n                \"min_age\": 29,\n            },\n        ],\n    )\n\n    books_qs = (\n        Book.objects.annotate(\n            first_author_the_same_age=Subquery(\n                Author.objects.filter(\n                    age=OuterRef(\"contact__friends__age\"),\n                )\n                .order_by(\"age\")\n                .values(\"id\")[:1],\n            )\n        )\n        .filter(\n            publisher=self.p1,\n            first_author_the_same_age__isnull=False,\n        )\n        .annotate(\n            min_age=Min(\"contact__friends__age\"),\n        )\n        .values_list(\"name\", \"min_age\")\n        .order_by(\"name\")\n    )\n    self.assertEqual(\n        list(books_qs),\n        [\n            (\"Practical Django Projects\", 34),\n            (\n                \"The Definitive Guide to Django: Web Development Done Right\",\n                29,\n            ),\n        ],\n    )\n\n    books_qs = (\n        Book.objects.annotate(\n            first_author_the_same_age=Subquery(\n                Author.objects.filter(\n                    age=OuterRef(\"contact__friends__age\"),\n                )\n                .order_by(\"age\")\n                .values(\"id\")[:1],\n            )\n        )\n        .filter(\n            publisher=self.p1,\n            first_author_the_same_age__isnull=False,\n        )\n        .annotate(\n            min_age=Min(\"contact__friends__age\"),\n        )\n        .values_list(\"name\", flat=True)\n        .order_by(\"name\")\n   "], "sample_1208": ["def test_MatrixStudentT_sample():\n    M = MatrixStudentT('M', 2, [[5, 6]], [[2, 1], [1, 2]], [4])\n    size = 5\n    scipy = import_module('scipy')\n    if scipy:\n        samps = sample(M, size=size, library='scipy')\n        for sam in samps:\n            assert Matrix(sam) in M.pspace.distribution.set\n    pymc = import_module('pymc')\n    if pymc:\n        samps = sample(M, size=size, library='pymc')\n        for sam in samps:\n            assert Matrix(sam) in M.pspace.distribution.set\n    numpy = import_module('numpy')\n    if numpy:\n        samps = sample(M, size=size, library='numpy')\n        for sam in samps:\n            assert Matrix(sam) in M.pspace.distribution.set\n    raises(NotImplementedError, lambda: sample(M, size=3, library='scipy'))\n    raises(NotImplementedError, lambda: sample(M, size=3, library='numpy'))\n    raises(NotImplementedError, lambda: sample(M, size=3, library='pymc'))\n"], "sample_61": ["    def test_unicode_validator_flags(self):\n        valid_usernames = ['joe', 'Ren\u00e9', '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f']\n        invalid_usernames = [\n            \"o'connell\", \"\u0639\u0628\u062f \u0627\u0644\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.UnicodeUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n"], "sample_185": ["    def setUp(self):\n        super().setUp()\n        self.n = decimal.Decimal('66666.666')\n        self.f = 99999.999\n        self.d = datetime.date(2009, 12, 31)\n        self.dt = datetime.datetime(2009, 12, 31, 20, 50)\n        self.t = datetime.time(10, 15, 48)\n        self.long = 10000\n        self.ctxt = Context({\n            'n': self.n,\n            't': self.t,\n            'd': self.d,\n            'dt': self.dt,\n            'f': self.f,\n            'l': self.long,\n        })\n"], "sample_703": ["def test_matcher_function() -> None:\n        return ident.startswith(\"a\")\n\n    assert evaluate(\"true\", matcher)\n    assert not evaluate(\"false\", matcher)\n    assert not evaluate(\"not true\", matcher)\n    assert not evaluate(\"not false\", matcher)\n    assert not evaluate(\"true and true\", matcher)\n    assert not evaluate(\"true and false\", matcher)\n    assert not evaluate(\"false and true\", matcher)\n    assert not evaluate(\"true and true and true\", matcher)\n    assert not evaluate(\"true and true and false\", matcher)\n    assert not evaluate(\"true and true and not true\", matcher)\n    assert not evaluate(\"false or false\", matcher)\n    assert not evaluate(\"false or true\", matcher)\n    assert not evaluate(\"true or true\", matcher)\n    assert not evaluate(\"true or true or false\", matcher)\n    assert not evaluate(\"true and true or false\", matcher)\n    assert not evaluate(\"not true or true\", matcher)\n    assert not evaluate(\"(not true) or true\", matcher)\n    assert not evaluate(\"not (true or true)\", matcher)\n    assert not evaluate(\"true and true or false and false\", matcher)\n    assert not evaluate(\"true and (true or false) and false\", matcher)\n    assert not evaluate(\"true and (true or (not (not false))) and false\", matcher)\n\n    assert evaluate(\"a\", matcher)\n    assert not evaluate(\"b\", matcher)\n    assert not evaluate(\"not a\", matcher)\n    assert evaluate(\"not not a\", matcher)\n    assert not evaluate(\"not not not a\", matcher)\n    assert not evaluate(\"not not not not a\", matcher)\n\n    assert evaluate(\"a and a\", matcher)\n    assert not evaluate(\"a and b\", matcher)\n    assert not evaluate(\"b and a\", matcher)\n    assert not evaluate(\"a and a and a\", matcher)\n    assert not evaluate(\"a and a and b\", matcher)\n    assert not evaluate(\"a and a and not a\", matcher)\n\n    assert not evaluate(\"a or b\", matcher)\n    assert evaluate(\"a or a\", matcher)\n    assert evaluate(\"a or true\", matcher)\n    assert evaluate(\"a or false\", matcher)\n    assert evaluate(\"a or a or b\", matcher)\n    assert evaluate(\"a and a or b\", matcher)\n    assert evaluate(\"not a or a\", matcher)\n    assert evaluate(\"(not a) or a\", matcher)\n   "], "sample_772": ["def check_min_impurity_decrease(name):\n    # Test if min_impurity_decrease of base estimators is set\n    # Regression test for #8006\n    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)\n    all_estimators = [RandomForestClassifier, RandomForestRegressor,\n                      ExtraTreesClassifier, ExtraTreesRegressor]\n\n    for Estimator in all_estimators:\n        est = Estimator(min_impurity_decrease=0.1)\n        est = assert_warns_message(DeprecationWarning, \"min_impurity_split\",\n                                   est.fit, X, y)\n        for tree in est.estimators_:\n            assert_equal(tree.min_impurity_decrease, 0.1)\n\n"], "sample_619": ["def test_decode_cf_datetime_uint64_with_cftime_out_of_range() -> None:\n    units = \"days since 1700-01-01\"\n    calendar = \"360_day\"\n    num_dates = np.uint64(182621)\n    with pytest.raises(OutOfBoundsDatetime):\n        decode_cf_datetime(num_dates, units, calendar)\n"], "sample_966": ["def test_pydata_with_union_type_operator(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :type: int | str\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0],\n                ([desc_name, \"version\"],\n                 [desc_annotation, ([desc_sig_punctuation, ':'],\n                                    desc_sig_space,\n                                    [pending_xref, \"int\"],\n                                    desc_sig_space,\n                                    [desc_sig_punctuation, \"|\"],\n                                    desc_sig_space,\n                                    [pending_xref, \"str\"])]))\n    assert_node(doctree[1][0][0][1][2], pending_xref,\n                refdomain=\"py\", reftype=\"class\", reftarget=\"int\",\n                **{\"py:module\": \"example\", \"py:class\": \"Class\"})\n    assert_node(doctree[1][0][0][1][4], pending_xref,\n                refdomain=\"py\", reftype=\"class\", reftarget=\"str\",\n                **{\"py:module\": \"example\", \"py:class\": \"Class\"})\n"], "sample_199": ["def test_combined_expression_annotation_with_subquery(self):\n    \"\"\"\n    Test that a combined expression annotation with a subquery works correctly.\n    \"\"\"\n    long_books_qs = Book.objects.filter(\n        publisher=OuterRef('pk'),\n        pages__gt=400,\n    ).values('publisher').annotate(count=Count('pk')).values('count')\n    publisher_books_qs = Publisher.objects.annotate(\n        total_books=Count('book'),\n        combined=ExpressionWrapper(F('num_awards') + Subquery(long_books_qs, output_field=IntegerField()), output_field=IntegerField()),\n    ).filter(\n        total_books=Subquery(long_books_qs, output_field=IntegerField()),\n    ).values('name')\n    self.assertCountEqual(publisher_books_qs, [{'name': 'Sams'}, {'name': 'Morgan Kaufmann'}])\n"], "sample_783": ["def test_imputation_constant_fill_value():\n    # Test imputation using the constant strategy with a fill_value.\n    X = np.array([\n        [-1, 2, 3, -1],\n        [4, -1, 5, -1],\n        [6, 7, -1, -1],\n        [8, 9, 0, -1]\n    ])\n\n    X_true = np.array([\n        [5, 2, 3, 5],\n        [4, 5, 5, 5],\n        [6, 7, 5, 5],\n        [8, 9, 0, 5]\n    ])\n\n    imputer = SimpleImputer(missing_values=-1, strategy=\"constant\",\n                            fill_value=5)\n    X_trans = imputer.fit_transform(X)\n\n    assert_array_equal(X_trans, X_true)\n"], "sample_382": ["def test_template_changed_with_filesystem_loader(self):\n    template_path = Path(__file__).parent / 'templates' / 'index.html'\n    self.assertTrue(autoreload.template_changed(None, template_path))\n    mock_reset = mock.patch('django.template.autoreload.reset_loaders')\n    mock_reset.assert_called_once()\n"], "sample_983": ["def test_diagonal_solve():\n    A = SparseMatrix([[2, 0, 0], [0, 3, 0], [0, 0, 4]])\n    b = SparseMatrix([[1], [2], [3]])\n    assert A._diagonal_solve(b) == SparseMatrix([[1/2], [2/3], [3/4]])\n    A = SparseMatrix([[2, 1, 0], [0, 3, 0], [0, 0, 4]])\n    b = SparseMatrix([[1], [2], [3]])\n    assert A._diagonal_solve(b) == SparseMatrix([[1/2], [2/3], [3/4]])\n"], "sample_1022": ["def test_repeated_decimals():\n    cases = {\n        '0.2[1]': '19/90',\n        '0.2[1][1]': '19/90',\n        '0.2[1][1][1]': '19/90',\n        '0.2[1][1][1][1]': '19/90',\n        '0.2[1][1][1][1][1]': '19/90',\n        '0.2[1][1][1][1][1][1]': '19/90',\n        '0.2[1][1][1][1][1][1][1]': '19/90',\n        '0.2[1][1][1][1][1][1][1][1]': '19/90',\n        '0.2[1][1][1][1][1][1][1][1][1]': '19/90',\n        '0.2[1][1][1][1][1][1][1][1][1][1]': '19/90',\n        '0.2[1][1][1][1][1][1][1][1][1][1][1]': '19/90',\n        '0.2[1][1][1][1][1][1][1][1][1][1][1][1]': '19/90',\n        '0.2[1][1][1][1][1][1][1][1][1][1][1][1][1]': '19/90',\n        '0.2[1][1][1][1][1][1][1][1][1][1][1][1][1][1]': '19/90',\n        '0.2[1][1][1][1][1][1][1][1][1][1][1][1][1][1][1]': '19/90',\n        '0.2[1][1][1][1][1][1][1][1][1][1][1][1][1][1][1][1]': '19/90',\n        '0.2[1][1][1][1][1][1][1][1][1][1][1][1][1][1]["], "sample_47": ["    def test_sensitive_kwargs_method(self):\n        \"\"\"\n        The sensitive_variables decorator works with object methods.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(sensitive_kwargs_method_view, check_for_POST_params=False)\n            self.verify_unsafe_email(sensitive_kwargs_method_view, check_for_POST_params=False)\n\n        with self.settings(DEBUG=False):\n            self.verify_safe_response(sensitive_kwargs_method_view, check_for_POST_params=False)\n            self.verify_safe_email(sensitive_kwargs_method_view, check_for_POST_params=False)\n"], "sample_662": ["    def test_repr_locals_serialization(self, testdir):\n        \"\"\"Check serialization/deserialization of report objects containing locals.\"\"\"\n        reprec = testdir.inline_runsource(\n            \"\"\"\n                x = 0\n                assert x\n            \"\"\",\n            \"--showlocals\",\n        )\n        reports = reprec.getreports(\"pytest_runtest_logreport\")\n        assert len(reports) == 3\n        rep = reports[1]\n        d = rep._to_json()\n        a = TestReport._from_json(d)\n\n        rep_entries = rep.longrepr.reprtraceback.reprentries\n        a_entries = a.longrepr.reprtraceback.reprentries\n        for i in range(len(a_entries)):\n            assert isinstance(rep_entries[i], ReprEntry)\n            assert rep_entries[i].lines == a_entries[i].lines\n            assert rep_entries[i].reprfileloc.lineno == a_entries[i].reprfileloc.lineno\n            assert (\n                rep_entries[i].reprfileloc.message == a_entries[i].reprfileloc.message\n            )\n            assert rep_entries[i].reprfileloc.path == a_entries[i].reprfileloc.path\n            assert rep_entries[i].reprfuncargs.args == a_entries[i].reprfuncargs.args\n            assert rep_entries[i].reprlocals.lines == a_entries[i].reprlocals.lines\n            assert rep_entries[i].style == a_entries[i].style\n            assert rep_entries[i].reprlocals.locals == a_entries[i].reprlocals.locals\n"], "sample_444": ["    def test_manifest_hash(self):\n        # Collect the additional file.\n        self.run_collectstatic()\n\n        _, manifest_hash_orig = storage.staticfiles_storage.load_manifest()\n        self.assertEqual(manifest_hash_orig, \"\")\n\n        # Saving doesn't change the hash.\n        storage.staticfiles_storage.save_manifest()\n        self.assertEqual(storage.staticfiles_storage.manifest_hash, \"\")\n\n        # Delete the original file from the app, collect with clear.\n        os.unlink(self._clear_filename)\n        self.run_collectstatic(clear=True)\n\n        # Hash is not changed.\n        _, manifest_hash = storage.staticfiles_storage.load_manifest()\n        self.assertEqual(manifest_hash, \"\")\n"], "sample_178": ["    def test_formset_with_ordering_and_deletion_and_min_num(self):\n        \"\"\"\n        FormSets with ordering + deletion + min_num.\n        \"\"\"\n        ChoiceFormSet = formset_factory(Choice, can_order=True, can_delete=True, min_num=2)\n        initial = [\n            {'choice': 'Calexico', 'votes': 100},\n            {'choice': 'Fergie', 'votes': 900},\n        ]\n        formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n        self.assertHTMLEqual(\n            '\\n'.join(form.as_ul() for form in formset.forms),\n            \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_259": ["def test_prefetch_queryset_to_attr(self):\n    book1 = Book.objects.get(id=self.book1.id)\n    with self.assertNumQueries(1):\n        prefetch_related_objects(\n            [book1],\n            Prefetch('authors', queryset=Author.objects.filter(id__in=[self.author1.id, self.author2.id]), to_attr='the_authors')\n        )\n\n    with self.assertNumQueries(0):\n        self.assertCountEqual(book1.the_authors, [self.author1, self.author2])\n"], "sample_761": ["def test_iterative_imputer_no_missing_at_fit():\n    rng = np.random.RandomState(0)\n    X = rng.rand(100, 100)\n    X[:, 0] = np.nan\n    imputer = IterativeImputer(max_iter=10, random_state=rng)\n    imputer.fit(X)\n    # if there were no missing values at time of fit, then imputer will\n    # only use the initial imputer for that feature at transform\n    assert_allclose(imputer.transform(X)[:, 0],\n                    imputer.initial_imputer_.transform(X)[:, 0])\n"], "sample_247": ["    def setUpTestData(cls):\n        cls.a1 = Author.objects.create(name='Adrian Holovaty', age=34)\n        cls.a2 = Author.objects.create(name='Jacob Kaplan-Moss', age=35)\n        cls.a3 = Author.objects.create(name='Brad Dayley', age=45)\n        cls.a4 = Author.objects.create(name='James Bennett', age=29)\n        cls.a5 = Author.objects.create(name='Jeffrey Forcier', age=37)\n        cls.a6 = Author.objects.create(name='Paul Bissex', age=29)\n        cls.a7 = Author.objects.create(name='Wesley J. Chun', age=25)\n        cls.a8 = Author.objects.create(name='Peter Norvig', age=57)\n        cls.a9 = Author.objects.create(name='Stuart Russell', age=46)\n        cls.a1.friends.add(cls.a2, cls.a4)\n        cls.a2.friends.add(cls.a1, cls.a7)\n        cls.a4.friends.add(cls.a1)\n        cls.a5.friends.add(cls.a6, cls.a7)\n        cls.a6.friends.add(cls.a5, cls.a7)\n        cls.a7.friends.add(cls.a2, cls.a5, cls.a6)\n        cls.a8.friends.add(cls.a9)\n        cls.a9.friends.add(cls.a8)\n\n        cls.p1 = Publisher.objects.create(name='Apress', num_awards=3)\n        cls.p2 = Publisher.objects.create(name='Sams', num_awards=1)\n        cls.p3 = Publisher.objects.create(name='Prentice Hall', num_awards=7)\n        cls.p4 = Publisher.objects.create(name='Morgan Kaufmann', num_awards=9)\n        cls.p5 = Publisher.objects.create(name=\"Jonno's House of Books\", num_awards=0)\n\n        cls.b1 = Book.objects.create(\n            isbn='159059725', name='The Definitive Guide to Django: Web Development Done Right',\n            pages=447, rating=4.5, price=Decimal('30.00'), contact=cls.a1, publisher=cls.p1,\n            pubdate=datetime.date(2007, 12, 6)\n        )\n        cls.b2 = Book.objects.create(\n            isbn='067232959', name='Sams Teach Yourself Django in 24 Hours',\n            pages=528, rating=3.0"], "sample_884": ["def test_deprecated_class_inheritance():\n    # Test if the deprecation warning is propagated when a deprecated class is inherited\n    with pytest.warns(FutureWarning, match=\"qwerty\"):\n        MockClass5(42)\n    # Test if the deprecation warning is not propagated when a non-deprecated class is inherited\n    with pytest.warns(None):\n        MockClass4()\n"], "sample_1165": ["def test_quaternion_addition():\n    q1 = Quaternion(1, 2, 3, 4)\n    q2 = Quaternion(5, 6, 7, 8)\n    q3 = Quaternion(9, 10, 11, 12)\n\n    assert q1 + q2 == Quaternion(6, 8, 10, 12)\n    assert q1 + q3 == Quaternion(10, 12, 14, 16)\n    assert q1 + q2 + q3 == Quaternion(15, 20, 25, 30)\n\n    q4 = Quaternion(0, 0, 0, 0)\n    assert q1 + q4 == q1\n    assert q4 + q1 == q1\n\n    q5 = Quaternion(1, 2, 3, 4, real_field=False)\n    q6 = Quaternion(5, 6, 7, 8, real_field=False)\n    assert q5 + q6 == Quaternion(6 + 5*I, 8 + 6*I, 3 + 7*I, 4 + 8*I)\n\n    q7 = Quaternion(1, 2, 3, 4)\n    q8 = Quaternion(5, 6, 7, 8)\n    assert q7 + q8 == Quaternion(6, 8, 10, 12)\n\n    q9 = Quaternion(1, 2, 3, 4)\n    q10 = Quaternion(5, 6, 7, 8)\n    assert q9 + q10 == Quaternion(6, 8, 10, 12)\n\n    q11 = Quaternion(1, 2, 3, 4)\n    q12 = Quaternion(5, 6, 7, 8)\n    assert q11 + q12 == Quaternion(6, 8, 10, 12)\n\n    q13 = Quaternion(1, 2, 3, 4)\n    q14 = Quaternion(5, 6, 7, 8)\n    assert q13 + q14 == Quaternion(6, 8, 10, 12)\n\n    q15 = Quaternion(1, 2, 3, 4)\n    q16 = Quaternion(5, 6, 7, 8)\n    assert q15 + q16 == Quaternion(6, "], "sample_836": ["def test_class_distribution_sparse_matrix():\n    y = sp.csc_matrix(np.array([[1, 0, 0, 1],\n                                [2, 2, 0, 1],\n                                [1, 3, 0, 1],\n                                [4, 2, 0, 1],\n                                [2, 0, 0, 1],\n                                [1, 3, 0, 1]]), shape=(6, 4))\n    # Define the sparse matrix with a mix of implicit and explicit zeros\n    data = np.array([1, 2, 1, 4, 2, 1, 0, 2, 3, 2, 3, 1, 1, 1, 1, 1, 1])\n    indices = np.array([0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 5, 0, 1, 2, 3, 4, 5])\n    indptr = np.array([0, 6, 11, 11, 17])\n    y_sp = sp.csc_matrix((data, indices, indptr), shape=(6, 4))\n\n    classes, n_classes, class_prior = class_distribution(y)\n    classes_sp, n_classes_sp, class_prior_sp = class_distribution(y_sp)\n    classes_expected = [[1, 2, 4],\n                        [0, 2, 3],\n                        [0],\n                        [1]]\n    n_classes_expected = [3, 3, 1, 1]\n    class_prior_expected = [[3/6, 2/6, 1/6],\n                            [1/3, 1/3, 1/3],\n                            [1.0],\n                            [1.0]]\n\n    for k in range(y.shape[1]):\n        assert_array_almost_equal(classes[k], classes_expected[k])\n        assert_array_almost_equal(n_classes[k], n_classes_expected[k])\n        assert_array_almost_equal(class_prior[k], class_prior_expected[k])\n\n        assert_array_almost_equal(classes_sp[k], classes_expected[k])\n        assert_array_almost_equal(n_classes_sp[k], n_classes_expected[k])\n        assert_array_almost_equal(class_prior_sp[k], class_prior_expected[k])\n\n    # Test again with explicit sample weights\n    (classes,\n     n_classes,\n    "], "sample_755": ["def test_calinski_harabasz_score_non_numpy_labels():\n    # Assert the value is 1. when all samples are equals\n    assert 1. == calinski_harabasz_score([[0, 0], [1, 1]] * 5,\n                                         [0] * 5 + [1] * 5)\n\n    # Assert the value is 0. when all the mean cluster are equal\n    assert 0. == calinski_harabasz_score([[[-1, -1], [1, 1]] * 5 +\n                                          [[3, 3], [4, 4]] * 5 +\n                                          [[0, 4], [1, 3]] * 5 +\n                                          [[3, 1], [4, 0]] * 5,\n                                         [0] * 10 + [1] * 10 + [2] * 10 + [3] * 10)\n\n    # General case (with non numpy arrays)\n    X = [[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5 + \\\n        [[0, 4], [1, 3]] * 5 + [[3, 1], [4, 0]] * 5\n    labels = [0] * 10 + [1] * 10 + [2] * 10 + [3] * 10\n    pytest.approx(calinski_harabasz_score(X, labels),\n                  45 * (40 - 4) / (5 * (4 - 1)))\n\n    # Test with non-numpy arrays\n    X = [[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5 + \\\n        [[0, 4], [1, 3]] * 5 + [[3, 1], [4, 0]] * 5\n    labels = [0] * 10 + [1] * 10 + [2] * 10 + [3] * 10\n    pytest.approx(calinski_harabasz_score(list(map(list, X)), labels),\n                  45 * (40 - 4) / (5 * (4 - 1)))\n\n    # Test with non-encoded labels\n    X = [[0, 0],"], "sample_219": ["    def setUpTestData(cls):\n        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max2 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max3 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max4 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max5 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max6 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max7 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max8 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max9 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max10 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max11 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max12 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max13 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max14 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max15 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max16 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max17 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max18 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max19 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max20 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max21 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max22 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max23 = Employee.objects.create(firstname='"], "sample_1023": ["def test_totient():\n    from sympy.ntheory.generate import sieve\n    sieve._reset()\n    assert totient(1) == 1\n    assert totient(2) == 1\n    assert totient(3) == 2\n    assert totient(4) == 2\n    assert totient(5) == 4\n    assert totient(6) == 2\n    assert totient(7) == 6\n    assert totient(8) == 4\n    assert totient(9) == 6\n    assert totient(10) == 4\n    assert totient(11) == 10\n    assert totient(12) == 4\n    assert totient(13) == 12\n    assert totient(14) == 6\n    assert totient(15) == 8\n    assert totient(16) == 8\n    assert totient(17) == 16\n    assert totient(18) == 6\n    assert totient(19) == 18\n    assert totient(20) == 8\n    assert totient(21) == 12\n    assert totient(22) == 10\n    assert totient(23) == 22\n    assert totient(24) == 8\n    assert totient(25) == 20\n    assert totient(26) == 12\n    assert totient(27) == 18\n    assert totient(28) == 12\n    assert totient(29) == 28\n    assert totient(30) == 8\n    assert totient(31) == 30\n    assert totient(32) == 16\n    assert totient(33) == 20\n    assert totient(34) == 12\n    assert totient(35) == 24\n    assert totient(36) == 12\n    assert totient(37) == 36\n    assert totient(38) == 18\n    assert totient(39) == 24\n    assert totient(40) == 16\n    assert totient(41) == 40\n    assert totient(42) == 12\n    assert totient(43) == 42\n    assert totient(44) == 20\n    assert totient("], "sample_991": ["def test_issue_13547():\n    n = Symbol('n')\n    k = Symbol('k')\n    p = Product(n + 1 / 2**k, (k, 0, n)).doit()\n    assert p.subs(n, 2).doit() == S(15)/2\n"], "sample_589": ["def test_interpolate_na_max_gap_time_specifier():\n    da = xr.DataArray(\n        [np.nan, 1, 2, np.nan, np.nan, 5, np.nan, np.nan, np.nan, np.nan, 10],\n        dims=[\"t\"],\n    )\n    da[\"t\"] = pd.date_range(\"2001-01-01\", freq=\"H\", periods=11)\n    actual = da.interpolate_na(\"t\", max_gap=\"3H\")\n    expected = da.copy(data=[np.nan, 1, 2, 3, 4, 5, np.nan, np.nan, np.nan, np.nan, 10])\n    assert_equal(actual, expected)\n"], "sample_56": ["def test_prepopulated_fields(self):\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title', 'nonexistent')}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'prepopulated_fields[\\\"slug\\\"]' refers to 'nonexistent', \"\n            \"which is not an attribute of 'admin_checks.Song'.\",\n            obj=SongAdmin,\n            id='admin.E027',\n        )\n    ]\n    self.assertEqual(errors, expected)\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin"], "sample_393": ["    def setUp(self):\n        super().setUp()\n        self.symlinked_dir = os.path.join(self.test_dir, \"templates_symlinked\")\n"], "sample_1196": ["def test_contains_eval():\n    x = Symbol('x')\n    s = FiniteSet(1, 2, 3)\n    assert Contains(x, s).eval(x, s) == Contains(x, s)\n    assert Contains(1, s).eval(1, s) == S.true\n    assert Contains(4, s).eval(4, s) == S.false\n"], "sample_170": ["    def test_non_sensitive_request(self):\n        \"\"\"\n        Request info can bee seen in the default error reports for\n        non-sensitive requests.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n\n        with self.settings(DEBUG=False):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n"], "sample_893": ["def test_export_text_class_names_bool_support():\n    # Check that export_text treats class_names correctly and supports bool\n    clf = DecisionTreeClassifier(max_depth=2, random_state=0)\n    clf.fit(X, y)\n\n    expected_report = dedent(\"\"\"\n    |--- feature_1 <= 0.00\n    |   |--- class: -1\n    |--- feature_1 >  0.00\n    |   |--- class: 1\n    \"\"\").lstrip()\n    assert export_text(clf, class_names=True) == expected_report\n\n    expected_report = dedent(\"\"\"\n    |--- feature_1 <= 0.00\n    |   |--- class: -1\n    |--- feature_1 >  0.00\n    |   |--- class: 1\n    \"\"\").lstrip()\n    assert export_text(clf, class_names=False) == expected_report\n\n    expected_report = dedent(\"\"\"\n    |--- feature_1 <= 0.00\n    |   |--- class: -1\n    |--- feature_1 >  0.00\n    |   |--- class: 1\n    \"\"\").lstrip()\n    assert export_text(clf, class_names=True, show_weights=True) == expected_report\n\n    expected_report = dedent(\"\"\"\n    |--- feature_1 <= 0.00\n    |   |--- weights: [3.00, 0.00] class: -1\n    |--- feature_1 >  0.00\n    |   |--- weights: [0.00, 3.00] class: 1\n    \"\"\").lstrip()\n    assert export_text(clf, class_names=False, show_weights=True) == expected_report\n"], "sample_24": ["    def setup_class(self):\n        self.a = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n        self.mask_a = np.array([True, False, False, False, True])\n        self.ma = Masked(self.a, mask=self.mask_a)\n        self.xp = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n        self.fp = np.array([1.0, 5.0, 6.0, 19.0, 20.0])\n        self.mask_fp = np.array([False, False, False, True, False])\n        self.mfp = Masked(self.fp, mask=self.mask_fp)\n        self.x = np.array([1.5, 17.0])\n        self.mask_x = np.array([False, True])\n        self.mx = Masked(self.x, mask=self.mask_x)\n"], "sample_1095": ["def test_inversion_vector():\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    assert p.inversion_vector() == [0, 0, 0, 0, 0, 0]\n    p = Permutation([3, 2, 1, 0])\n    assert p.inversion_vector() == [3, 2, 1]\n    p = Permutation([4, 8, 0, 7, 1, 5, 3, 6, 2])\n    assert p.inversion_vector() == [4, 7, 0, 5, 0, 2, 1, 1]\n    p = Permutation([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    assert p.inversion_vector() == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n    p = Permutation([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])\n    assert p.inversion_vector() == [9, 8, 7, 6, 5, 4, 3, 2, 1]\n    p = Permutation([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n    assert p.inversion_vector() == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n    p = Permutation([10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0])\n    assert p.inversion_vector() == [10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n    p = Permutation([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n    assert p.inversion_vector() == [0, 0, 0,"], "sample_306": ["    def test_parse_iso_8601_with_fractional_seconds(self):\n        test_values = (\n            ('PT1H2M3.4S', timedelta(hours=1, minutes=2, seconds=3, milliseconds=400)),\n            ('PT1H2M3.40S', timedelta(hours=1, minutes=2, seconds=3, milliseconds=400)),\n            ('PT1H2M3.400S', timedelta(hours=1, minutes=2, seconds=3, milliseconds=400)),\n            ('PT1H2M3.4000S', timedelta(hours=1, minutes=2, seconds=3, milliseconds=4000)),\n            ('PT1H2M3.40000S', timedelta(hours=1, minutes=2, seconds=3, milliseconds=40000)),\n            ('PT1H2M3.400000S', timedelta(hours=1, minutes=2, seconds=3, milliseconds=400000)),\n            ('PT1H2M3,4S', timedelta(hours=1, minutes=2, seconds=3, milliseconds=400)),\n            ('PT1H2M3,40S', timedelta(hours=1, minutes=2, seconds=3, milliseconds=400)),\n            ('PT1H2M3,400S', timedelta(hours=1, minutes=2, seconds=3, milliseconds=400)),\n            ('PT1H2M3,4000S', timedelta(hours=1, minutes=2, seconds=3, milliseconds=4000)),\n            ('PT1H2M3,40000S', timedelta(hours=1, minutes=2, seconds=3, milliseconds=40000)),\n            ('PT1H2M3,400000S', timedelta(hours=1, minutes=2, seconds=3, milliseconds=400000)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_706": ["def test_matcher_function() -> None:\n        return ident.startswith(\"a\")\n\n    assert evaluate(\"a\", matcher)\n    assert not evaluate(\"b\", matcher)\n    assert evaluate(\"ab\", matcher)\n    assert not evaluate(\"ba\", matcher)\n\n        return ident.endswith(\"c\")\n\n    assert evaluate(\"c\", matcher2)\n    assert not evaluate(\"a\", matcher2)\n    assert evaluate(\"ac\", matcher2)\n    assert not evaluate(\"ca\", matcher2)\n\n        return len(ident) > 3\n\n    assert evaluate(\"abcd\", matcher3)\n    assert not evaluate(\"abc\", matcher3)\n    assert evaluate(\"abcd123\", matcher3)\n    assert not evaluate(\"ab\", matcher3)\n\n        return ident == \"true\"\n\n    assert evaluate(\"true\", matcher4)\n    assert not evaluate(\"false\", matcher4)\n    assert not evaluate(\"True\", matcher4)\n    assert not evaluate(\"TRUE\", matcher4)\n\n        return ident == \"false\"\n\n    assert not evaluate(\"false\", matcher5)\n    assert evaluate(\"true\", matcher5)\n    assert not evaluate(\"False\", matcher5)\n    assert not evaluate(\"FALSE\", matcher5)\n"], "sample_769": ["def test_precision_recall_fscore_support_multilabel():\n    # Test precision_recall_fscore_support on a crafted multilabel example\n    # First crafted example\n\n    y_true = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 1]])\n    y_pred = np.array([[0, 1, 0, 0], [0, 1, 0, 0], [1, 0, 1, 0]])\n\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average=None)\n\n    # tp = [0, 1, 1, 0]\n    # fn = [1, 0, 0, 1]\n    # fp = [1, 1, 0, 0]\n    # Check per class\n\n    assert_array_almost_equal(p, [0.0, 0.5, 1.0, 0.0], 2)\n    assert_array_almost_equal(r, [0.0, 1.0, 1.0, 0.0], 2)\n    assert_array_almost_equal(f, [0.0, 1 / 1.5, 1, 0.0], 2)\n    assert_array_almost_equal(s, [1, 1, 1, 1], 2)\n\n    f2 = fbeta_score(y_true, y_pred, beta=2, average=None)\n    support = s\n    assert_array_almost_equal(f2, [0, 0.83, 1, 0], 2)\n\n    # Check macro\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred,\n                                                 average=\"macro\")\n    assert_almost_equal(p, 1.5 / 4)\n    assert_almost_equal(r, 0.5)\n    assert_almost_equal(f, 2.5 / 1.5 * 0.25)\n    assert_equal(s, None)\n    assert_almost_equal(fbeta_score(y_true, y_pred, beta=2, average=\"macro\"),\n                        np.mean(f2))\n\n    # Check micro\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred,\n                                                 average=\"micro\")\n    assert_almost_equal(p, 0.5)\n   "], "sample_187": ["def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123'), 'hello world123')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123!'), 'hello world123!')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123!@#'), 'hello world123!@#')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123!@#abc'), 'hello world123!@#abc')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123!@#abc123'), 'hello world123!@#abc123')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123!@#abc123!@#'), 'hello world123!@#abc123!@#')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123!@#abc123!@#def'), 'hello world123!@#abc123!@#def')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123!@#abc123!@#def456'), 'hello world123!@#abc123!@#def456')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123!@#abc123!@#def456!@#'), 'hello world123!@#abc123!@#def456!@#')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123!@#abc123!@#def456!@#ghi'), 'hello world123!@#abc123!@#def456!@#ghi')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123!@#abc123!@#def456!@#ghi789'), 'hello world123!@#abc123!@#def456!@#ghi789')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123!@#abc123!@#def456!@#ghi789!@#'), 'hello world123!@#abc123!@#def456!@#ghi789!@#')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123!@#abc123!@#def456!@#ghi789!@#jkl'), 'hello world123!@#abc123!@#def456!@#ghi789!"], "sample_2": ["def test_arithmetic_overload_ccddata_operand_with_uncertainty():\n    ccd_data = create_ccd_data()\n    ccd_data.uncertainty = StdDevUncertainty(np.ones_like(ccd_data))\n    operand = ccd_data.copy()\n    operand.uncertainty = StdDevUncertainty(np.ones_like(ccd_data) * 2)\n    result = ccd_data.add(operand)\n    assert len(result.meta) == 0\n    np.testing.assert_array_equal(result.data,\n                                  2 * ccd_data.data)\n    np.testing.assert_array_almost_equal_nulp(\n        result.uncertainty.array,\n        np.sqrt(2) * ccd_data.uncertainty.array\n    )\n\n    result = ccd_data.subtract(operand)\n    assert len(result.meta) == 0\n    np.testing.assert_array_equal(result.data,\n                                  0 * ccd_data.data)\n    np.testing.assert_array_almost_equal_nulp(\n        result.uncertainty.array,\n        np.sqrt(2) * ccd_data.uncertainty.array\n    )\n\n    result = ccd_data.multiply(operand)\n    assert len(result.meta) == 0\n    np.testing.assert_array_equal(result.data,\n                                  ccd_data.data ** 2)\n    expected_uncertainty = (np.sqrt(2) * np.abs(ccd_data.data) *\n                            ccd_data.uncertainty.array)\n    np.testing.assert_allclose(result.uncertainty.array,\n                               expected_uncertainty)\n\n    result = ccd_data.divide(operand)\n    assert len(result.meta) == 0\n    np.testing.assert_array_equal(result.data,\n                                  np.ones_like(ccd_data.data))\n    expected_uncertainty = (np.sqrt(2) / np.abs(ccd_data.data) *\n                            ccd_data.uncertainty.array)\n    np.testing.assert_allclose(result.uncertainty.array,\n                               expected_uncertainty)\n"], "sample_676": ["    def test_summary_stats_color(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n                pass\n                assert 0\n                raise ValueError()\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-rF\")\n        result.stdout.fnmatch_lines([\"*1 failed, 1 passed in*\"])\n        assert result.stdout.str().count(\"red\") == 1\n        result = testdir.runpytest(\"-rF\", \"--color=no\")\n        result.stdout.fnmatch_lines([\"*1 failed, 1 passed in*\"])\n        assert result.stdout.str().count(\"red\") == 0\n"], "sample_1030": ["def test_are_coplanar():\n    from sympy.geometry import Point3D, Line3D, Plane\n    a = Line3D(Point3D(5, 0, 0), Point3D(1, -1, 1))\n    b = Line3D(Point3D(0, -2, 0), Point3D(3, 1, 1))\n    c = Line3D(Point3D(0, -1, 0), Point3D(5, -1, 9))\n    assert are_coplanar(a, b, c) == False\n    assert are_coplanar(a, b, Plane((0, 0, 0), (1, 1, 1))) == True\n    assert are_coplanar(a, b, Plane((0, 0, 0), (1, 1, 1), (2, 2, 2))) == True\n    assert are_coplanar(a, b, Plane((0, 0, 0), (1, 1, 1), (2, 2, 2), (3, 3, 3))) == True\n    assert are_coplanar(a, b, Plane((0, 0, 0), (1, 1, 1), (2, 2, 2), (3, 3, 3), (4, 4, 4))) == True\n    assert are_coplanar(a, b, Plane((0, 0, 0), (1, 1, 1), (2, 2, 2), (3, 3, 3), (4, 4, 4), (5, 5, 5))) == True\n    assert are_coplanar(a, b, Plane((0, 0, 0), (1, 1, 1), (2, 2, 2), (3, 3, 3), (4, 4, 4), (5, 5, 5), (6, 6, 6))) == True\n    assert are_coplanar(a, b, Plane((0, 0, 0), (1, 1, 1), (2, 2, 2), (3, 3, 3), (4, 4, "], "sample_692": ["def test_tmp_path_factory_handles_invalid_basetemp_characters(tmp_path_factory: TempPathFactory, monkeypatch: MonkeyPatch) -> None:\n    \"\"\"Test that TempPathFactory handles invalid characters in the basetemp directory name.\"\"\"\n    # _basetemp / _given_basetemp are cached / set in parallel runs, patch them\n    monkeypatch.setattr(tmp_path_factory, \"_basetemp\", None)\n    monkeypatch.setattr(tmp_path_factory, \"_given_basetemp\", None)\n    # Create a basetemp directory with invalid characters\n    invalid_basetemp = Path(\"/tmp/pytest-of-<:;*?/tmp\")\n    invalid_basetemp.mkdir()\n    tmp_path_factory._given_basetemp = invalid_basetemp\n    p = tmp_path_factory.getbasetemp()\n    assert \"pytest-of-unknown\" in str(p)\n"], "sample_1178": ["def test_Element():\n    e = Element('x', 'i')\n    assert e.symbol == Symbol('x')\n    assert e.indices == (Symbol('i'),)\n    assert e.strides == none\n    assert e.offset == none\n    assert e.func(*e.args) == e\n\n    e2 = Element('x', 'ij')\n    assert e2.symbol == Symbol('x')\n    assert e2.indices == (Symbol('i'), Symbol('j'))\n    assert e2.strides == none\n    assert e2.offset == none\n    assert e2.func(*e2.args) == e2\n\n    e3 = Element('x', 'ij', strides='lmn')\n    assert e3.symbol == Symbol('x')\n    assert e3.indices == (Symbol('i'), Symbol('j'))\n    assert e3.strides == Tuple(Symbol('l'), Symbol('m'), Symbol('n'))\n    assert e3.offset == none\n    assert e3.func(*e3.args) == e3\n\n    e4 = Element('x', 'ij', offset='o')\n    assert e4.symbol == Symbol('x')\n    assert e4.indices == (Symbol('i'), Symbol('j'))\n    assert e4.strides == none\n    assert e4.offset == Symbol('o')\n    assert e4.func(*e4.args) == e4\n\n    e5 = Element('x', 'ij', strides='lmn', offset='o')\n    assert e5.symbol == Symbol('x')\n    assert e5.indices == (Symbol('i'), Symbol('j'))\n    assert e5.strides == Tuple(Symbol('l'), Symbol('m'), Symbol('n'))\n    assert e5.offset == Symbol('o')\n    assert e5.func(*e5.args) == e5\n\n    raises(TypeError, lambda: Element('x', 'ij', strides='lmn', offset='o', invalid='arg'))\n"], "sample_698": ["def test_coloredlogformatter_with_custom_color() -> None:\n    logfmt = \"%(levelname)-8s %(message)s\"\n\n    record = logging.LogRecord(\n        name=\"dummy\",\n        level=logging.INFO,\n        pathname=\"dummypath\",\n        lineno=10,\n        msg=\"Test Message\",\n        args=(),\n        exc_info=None,\n    )\n\n    tw = TerminalWriter()\n    tw.hasmarkup = True\n    formatter = ColoredLevelFormatter(tw, logfmt)\n    output = formatter.format(record)\n    assert output == (\n        \"INFO    \\x1b[32mTest Message\\x1b[0m\"\n    )\n\n    tw.hasmarkup = False\n    formatter = ColoredLevelFormatter(tw, logfmt)\n    output = formatter.format(record)\n    assert output == \"INFO     Test Message\"\n"], "sample_871": ["def test_calinski_harabasz_score_sparse():\n    \"\"\"Check that calinski_harabasz_score works for sparse matrices correctly.\"\"\"\n    X = np.array([[0.2, 0.1, 0.1, 0.2, 0.1, 1.6, 0.2, 0.1]], dtype=np.float32).T\n    y = [0, 0, 0, 0, 1, 1, 1, 1]\n    pdist_dense = pairwise_distances(X)\n    pdist_sparse = csr_matrix(pdist_dense)\n    assert issparse(pdist_sparse)\n    pytest.approx(calinski_harabasz_score(X, y), calinski_harabasz_score(pdist_sparse, y, metric=\"precomputed\"))\n    pytest.approx(calinski_harabasz_score(X, y), calinski_harabasz_score(pdist_dense, y))\n"], "sample_581": ["def test_blueprint_static_folder(app, client):\n    bp = flask.Blueprint(\"bp\", __name__, static_folder=\"static\")\n\n    @bp.route(\"/static/<filename>\")\n        return bp.send_static_file(filename)\n\n    app.register_blueprint(bp)\n\n    assert client.get(\"/static/test.txt\").data == b\"Admin File\"\n    assert client.get(\"/static/css/test.css\").data == b\"/* nested file */\"\n"], "sample_551": ["def test_patch_collection_3d_properties():\n    fig, ax = plt.subplots(subplot_kw=dict(projection='3d'))\n    patch = art3d.Patch3D([(-1, -1, 0), (1, -1, 0), (1, 1, 0), (-1, 1, 0)],\n                          label='patch')\n    ax.add_collection3d(patch)\n    leg = ax.legend()\n    assert (leg.legend_handles[0].get_facecolor()\n            == patch.get_facecolor()).all()\n    assert (leg.legend_handles[0].get_edgecolor()\n            == patch.get_edgecolor()).all()\n"], "sample_649": ["def test_log_cli_level_config_overrides_pytest_config(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n        log_cli_level=DEBUG\n        \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_handler.level == logging.INFO\n            logging.getLogger('catchlog').debug(\"This log message won't be shown\")\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n\n    result = pytester.runpytest(\"-s\", \"--log-cli-level=INFO\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_log_cli_level_config_overrides_pytest_config.py*This log message will be shown\",\n            \"PASSED\",  # 'PASSED' on its own line because the log message prints a new line\n        ]\n    )\n    result.stdout.no_fnmatch_line(\"*This log message won't be shown*\")\n\n    # make sure that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n"], "sample_116": ["    def test_get_or_set_version(self):\n        cache.set('answer', 42, version=2)\n        self.assertIsNone(cache.get('answer'))\n        self.assertIsNone(cache.get('answer', version=1))\n        self.assertEqual(cache.get('answer', version=2), 42)\n        self.assertIsNone(cache.get('answer', version=3))\n\n        self.assertEqual(cache.get_or_set('answer', 43, version=2), 43)\n        self.assertIsNone(cache.get('answer'))\n        self.assertIsNone(cache.get('answer', version=1))\n        self.assertEqual(cache.get('answer', version=2), 43)\n        self.assertIsNone(cache.get('answer', version=3))\n\n        self.assertEqual(cache.get_or_set('answer', 44, version=1), 44)\n        self.assertEqual(cache.get('answer'), 44)\n        self.assertEqual(cache.get('answer', version=1), 44)\n        self.assertIsNone(cache.get('answer', version=2))\n        self.assertIsNone(cache.get('answer', version=3))\n\n        self.assertEqual(cache.get_or_set('answer', 45, version=3), 45)\n        self.assertIsNone(cache.get('answer'))\n        self.assertIsNone(cache.get('answer', version=1))\n        self.assertIsNone(cache.get('answer', version=2))\n        self.assertEqual(cache.get('answer', version=3), 45)\n"], "sample_552": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect(.5)\n    ax2.set_box_aspect((2, 1, 1))\n    fig.tight_layout()\n    fig.canvas.draw()\n    assert ax1.get_tightbbox(fig.canvas.get_renderer()).x1 == 7.333\n    assert ax2.get_tightbbox(fig.canvas.get_renderer()).x1 == 7.333\n"], "sample_841": ["def test_ridge_sparse_cg_with_X_fortran():\n    # check that Fortran array are converted when using sparse_cg solver\n    X, y = make_regression(random_state=42)\n    # for the order of X and y to not be C-ordered arrays\n    X = np.asfortranarray(X)\n    X = X[::2, :]\n    y = y[::2]\n    Ridge(solver='sparse_cg').fit(X, y)\n"], "sample_981": ["def test_inversion_vector():\n    # test inversion vector\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    assert p.inversion_vector() == [0, 0, 0, 0, 0, 0]\n    p = Permutation([3, 2, 1, 0, 4, 5])\n    assert p.inversion_vector() == [3, 2, 1, 0, 0, 0]\n    p = Permutation([4, 3, 2, 1, 0, 5])\n    assert p.inversion_vector() == [4, 3, 2, 1, 0, 0]\n    p = Permutation([5, 4, 3, 2, 1, 0])\n    assert p.inversion_vector() == [5, 4, 3, 2, 1, 0]\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([3, 2, 1, 0, 4, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([4, 3, 2, 1, 0, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([5, 4, 3, 2, 1, 0])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    # test invalid inversion vector\n    raises(ValueError, lambda: Permutation.from_inversion_vector([0, 1, 2, 3, 4, 5]))\n    raises(ValueError, lambda: Permutation.from_inversion_vector([5, 4, 3, 2, 1, 6]))\n"], "sample_882": ["def test_mlp_regressor_batch_size():\n    # Test that batch_size affects the training process (it should)\n    X, y = make_regression(n_samples=50, n_features=5, n_targets=1, random_state=0)\n\n    # The coefficients will be identical if both do or do not use batch_size\n    for batch_size in [1, 200]:\n        mlp1 = MLPRegressor(\n            hidden_layer_sizes=1,\n            max_iter=1,\n            batch_size=batch_size,\n            random_state=0,\n        )\n        mlp2 = MLPRegressor(\n            hidden_layer_sizes=1,\n            max_iter=1,\n            batch_size=batch_size,\n            random_state=0,\n        )\n        mlp1.fit(X, y)\n        mlp2.fit(X, y)\n\n        assert np.array_equal(mlp1.coefs_[0], mlp2.coefs_[0])\n\n    # The coefficients will be slightly different if batch_size=1\n    mlp1 = MLPRegressor(\n        hidden_layer_sizes=1, max_iter=1, batch_size=1, random_state=0\n    )\n    mlp2 = MLPRegressor(\n        hidden_layer_sizes=1, max_iter=1, batch_size=200, random_state=0\n    )\n    mlp1.fit(X, y)\n    mlp2.fit(X, y)\n\n    assert not np.array_equal(mlp1.coefs_[0], mlp2.coefs_[0])\n"], "sample_852": ["def test_make_gaussian_quantiles():\n    X, y = make_gaussian_quantiles(n_samples=100, n_features=2,\n                                   n_classes=3, random_state=0)\n\n    assert X.shape == (100, 2), \"X shape mismatch\"\n    assert y.shape == (100,), \"y shape mismatch\"\n    assert np.unique(y).shape == (3,), \"Unexpected number of classes\"\n\n    # Check that roughly equal numbers of samples are in each class\n    assert np.allclose(np.bincount(y) / len(y), [1.0 / 3] * 3, atol=0.1)\n"], "sample_462": ["    def test_typedchoicefield_1(self):\n        f = TypedChoiceField(choices=[(\"1\", \"One\"), (\"2\", \"Two\")], coerce=int)\n        with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):\n            f.clean(\"\")\n        with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):\n            f.clean(None)\n        self.assertEqual(1, f.clean(1))\n        self.assertEqual(1, f.clean(\"1\"))\n        msg = \"'Select a valid choice. 3 is not one of the available choices.'\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            f.clean(\"3\")\n"], "sample_749": ["def test_column_transformer_transformer_weights():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n\n    # test with transformer_weights\n    transformer_weights = {'trans1': .1, 'trans2': 10}\n    both = ColumnTransformer([('trans1', Trans(), [0]),\n                              ('trans2', Trans(), [1])],\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * X_array[:, 0].reshape(-1, 1),\n                     transformer_weights['trans2'] * X_array[:, 1].reshape(-1, 1)]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    both = ColumnTransformer([('trans', Trans(), [0, 1])],\n                             transformer_weights={'trans': .1})\n    assert_array_equal(both.fit_transform(X_array), 0.1 * X_array)\n    assert_array_equal(both.fit(X_array).transform(X_array), 0.1 * X_array)\n    assert len(both.transformers_) == 1\n\n    # test with transformer_weights and remainder='drop'\n    both = ColumnTransformer([('trans1', Trans(), [0]),\n                              ('trans2', Trans(), [1])],\n                             transformer_weights={'trans1': .1, 'trans2': 10},\n                             remainder='drop')\n    res = np.vstack([transformer_weights['trans1'] * X_array[:, 0].reshape(-1, 1),\n                     transformer_weights['trans2'] * X_array[:, 1].reshape(-1, 1)]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and remainder='passthrough'\n    both = ColumnTransformer([('trans1', Trans(), [0]),\n                              ('trans2', Trans(), [1])],\n                             transformer_weights={'trans1': .1, 'trans2': 10},\n                             remainder='passthrough')\n    res = np.hstack([X_array, transformer_weights['trans1'] * X_array[:, 0].reshape(-1, 1),\n                     transformer_weights['trans"], "sample_276": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n        with captured_stderr() as self.docutils_stderr:\n            self.response = self.client.get(reverse('django-admindocs-models-detail', args=['admin_docs', 'Company']))\n"], "sample_605": ["def test_groupby_quantile_empty():\n    array = xr.DataArray([1, 2, 3], [(\"x\", [1, 2, 2])])\n    with pytest.raises(ValueError):\n        array.groupby(\"x\").quantile(0.5)\n"], "sample_950": ["def test_pydata_with_union_type_operator_and_value(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :type: int | str\\n\"\n            \"   :value: 1\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"version\"],\n                                                    [desc_annotation, (\": \",\n                                                                       [pending_xref, \"int\"],\n                                                                       \" \",\n                                                                       [desc_sig_punctuation, \"|\"],\n                                                                       \" \",\n                                                                       [pending_xref, \"str\"])],\n                                                    [desc_annotation, \" = 1\"])],\n                                  [desc_content, ()])])\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n    assert_node(doctree[1][0][1],\n                ([desc_name, \"version\"],\n                 [desc_annotation, (\": \",\n                                    [pending_xref, \"int\"],\n                                    \" \",\n                                    [desc_sig_punctuation, \"|\"],\n                                    \" \",\n                                    [pending_xref, \"str\"])]))\n    assert_node(doctree[1][0][1][0][1][3], pending_xref,\n                refdomain=\"py\", reftype=\"class\", reftarget=\"int\",\n                **{\"py:module\": \"example\", \"py:class\": \"Class\"})\n    assert_node(doctree[1][0][1][0][1][5], pending_xref,\n                refdomain=\"py\", reftype=\"class\", reftarget=\"str\",\n                **{\"py:module\": \"example\", \"py:class\": \"Class\"})\n    assert_node(doctree[1][0][1][2], nodes.inline, \"1\", support_smartquotes=False)\n"], "sample_130": ["def test_annotation(self):\n    query = Query(Author)\n    where = query.build_where(Q(num=F('id')))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, Exact)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.rhs, lookup.lhs)\n\n    query = Query(Author)\n    where = query.build_where(Q(num=F('id') + 1))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, Exact)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.rhs, lookup.lhs + 1)\n\n    query = Query(Author)\n    where = query.build_where(Q(num=F('id') - 1))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, Exact)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.rhs, lookup.lhs - 1)\n\n    query = Query(Author)\n    where = query.build_where(Q(num=F('id') * 2))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, Exact)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.rhs, lookup.lhs * 2)\n\n    query = Query(Author)\n    where = query.build_where(Q(num=F('id') / 2))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, Exact)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.rhs, lookup.lhs / 2)\n\n    query = Query(Author)\n    where = query.build_where(Q(num=F('id') % 2))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, Exact)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.rhs, lookup.lhs % 2)\n\n    query = Query(Author)\n    where = query.build_where(Q(num=F('id')"], "sample_1065": ["def test_subfactorial_rewrite():\n    n = Symbol('n', integer=True)\n    tt = Symbol('tt', integer=True, nonnegative=True)\n    tf = Symbol('tf', integer=True, nonnegative=False)\n    tn = Symbol('tf', integer=True)\n    ft = Symbol('ft', integer=False, nonnegative=True)\n    ff = Symbol('ff', integer=False, nonnegative=False)\n    fn = Symbol('ff', integer=False)\n    nt = Symbol('nt', nonnegative=True)\n    nf = Symbol('nf', nonnegative=False)\n    nn = Symbol('nf')\n    te = Symbol('te', even=True, nonnegative=True)\n    to = Symbol('to', odd=True, nonnegative=True)\n\n    assert subfactorial(n).rewrite(factorial) == factorial(n)\n    assert subfactorial(tt).rewrite(factorial) == factorial(tt)\n    assert subfactorial(tf).rewrite(factorial) == factorial(tf)\n    assert subfactorial(tn).rewrite(factorial) == factorial(tn)\n    assert subfactorial(ft).rewrite(factorial) == factorial(ft)\n    assert subfactorial(ff).rewrite(factorial) == factorial(ff)\n    assert subfactorial(fn).rewrite(factorial) == factorial(fn)\n    assert subfactorial(nt).rewrite(factorial) == factorial(nt)\n    assert subfactorial(nf).rewrite(factorial) == factorial(nf)\n    assert subfactorial(nn).rewrite(factorial) == factorial(nn)\n    assert subfactorial(te).rewrite(factorial) == factorial(te)\n    assert subfactorial(to).rewrite(factorial) == factorial(to)\n\n    assert subfactorial(n).rewrite(ff) == ff(n)\n    assert subfactorial(tt).rewrite(ff) == ff(tt)\n    assert subfactorial(tf).rewrite(ff) == ff(tf)\n    assert subfactorial(tn).rewrite(ff) == ff(tn)\n    assert subfactorial(ft).rewrite(ff) == ff(ft)\n    assert subfactorial(ff).rewrite(ff) == ff(ff)\n    assert subfactorial(fn).rewrite(ff) == ff(fn)\n    assert subfactorial(nt).rewrite(ff) == ff(nt)\n    assert subfactorial(nf).rewrite(ff) == ff(nf)\n    assert subfactorial(nn).rewrite(ff) == ff(nn)\n    assert subfactorial(te).rewrite(ff) == ff(te)\n    assert subfactorial(to).rewrite(ff) == ff(to)\n\n    assert sub"], "sample_757": ["def test_one_hot_encoder_sparse_output():\n    # Test OneHotEncoder's fit and transform with sparse output.\n    X = [[3, 2, 1], [0, 1, 1]]\n    enc = OneHotEncoder(sparse=True)\n    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):\n        # discover max values automatically\n        X_trans = enc.fit_transform(X)\n        assert_equal(X_trans.shape, (2, 5))\n        assert_array_equal(enc.active_features_,\n                           np.where([1, 0, 0, 1, 0, 1, 1, 0, 1])[0])\n        assert_array_equal(enc.feature_indices_, [0, 4, 7, 9])\n\n        # check outcome\n        assert_array_equal(X_trans.toarray(),\n                           [[0., 1., 0., 1., 1.],\n                            [1., 0., 1., 0., 1.]])\n"], "sample_106": ["    def tearDown(self):\n        cache.clear()\n"], "sample_1204": ["def test_coset_table():\n    G = PermutationGroup(Permutation(0,1,2,3), Permutation(0,1,2),\n         Permutation(0,4,2,7), Permutation(5,6), Permutation(0,7));\n    H = PermutationGroup(Permutation(0,1,2,3), Permutation(0,7))\n    assert G.coset_table(H) == \\\n        [[0, 0, 0, 0, 1, 2, 3, 3, 0, 0], [4, 5, 2, 5, 6, 0, 7, 7, 1, 1],\n         [5, 4, 5, 1, 0, 6, 8, 8, 6, 6], [3, 3, 3, 3, 7, 8, 0, 0, 3, 3],\n         [2, 1, 4, 4, 4, 4, 9, 9, 4, 4], [1, 2, 1, 2, 5, 5, 10, 10, 5, 5],\n         [6, 6, 6, 6, 2, 1, 11, 11, 2, 2], [9, 10, 8, 10, 11, 3, 1, 1, 7, 7],\n         [10, 9, 10, 7, 3, 11, 2, 2, 11, 11], [8, 7, 9, 9, 9, 9, 4, 4, 9, 9],\n         [7, 8, 7, 8, 10, 10, 5, 5, 10, 10], [11, 11, 11, 11, 8, 7, 6, 6, 8, 8]]\n"], "sample_400": ["def test_add_field_with_default_and_deconstructible(self):\n    \"\"\"\n    #22030 - Adding a field with a default should work.\n    \"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_name_deconstructible_1])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n\n    changes = self.get_changes([self.author_empty], [self.author_name_deconstructible_2])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n\n    changes = self.get_changes([self.author_empty], [self.author_name_deconstructible_3])\n    self.assertEqual(changes, {})\n\n    changes = self.get_changes([self.author_empty], [self.author_name_deconstructible_4])\n    self.assertEqual(changes, {})\n"], "sample_660": ["def test_record_testsuite_property_multiple_calls(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", \"all good\")\n            record_testsuite_property(\"stats\", 10)\n            record_testsuite_property(\"stats\", \"all good\")\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p2_node = properties_node.find_nth_by_tag(\"property\", 1)\n    p3_node = properties_node.find_nth_by_tag(\"property\", 2)\n    p1_node.assert_attr(name=\"stats\", value=\"all good\")\n    p2_node.assert_attr(name=\"stats\", value=\"10\")\n    p3_node.assert_attr(name=\"stats\", value=\"all good\")\n"], "sample_535": ["def test_table_fontsize():\n    fig = plt.figure()\n\n    # iterable list input\n    ax1 = fig.add_subplot(4, 1, 1)\n    ax1.axis('off')\n    tb1 = ax1.table(\n        cellText=[['Fit Text', 2],\n                  ['very long long text, Longer text than default', 1]],\n        rowLabels=[\"A\", \"B\"],\n        colLabels=[\"Col1\", \"Col2\"],\n        loc=\"center\")\n    tb1.auto_set_font_size(False)\n    tb1.set_fontsize(12)\n    tb1.auto_set_column_width([-1, 0, 1])\n\n    # iterable tuple input\n    ax2 = fig.add_subplot(4, 1, 2)\n    ax2.axis('off')\n    tb2 = ax2.table(\n        cellText=[['Fit Text', 2],\n                  ['very long long text, Longer text than default', 1]],\n        rowLabels=[\"A\", \"B\"],\n        colLabels=[\"Col1\", \"Col2\"],\n        loc=\"center\")\n    tb2.auto_set_font_size(False)\n    tb2.set_fontsize(12)\n    tb2.auto_set_column_width((-1, 0, 1))\n\n    # 3 single inputs\n    ax3 = fig.add_subplot(4, 1, 3)\n    ax3.axis('off')\n    tb3 = ax3.table(\n        cellText=[['Fit Text', 2],\n                  ['very long long text, Longer text than default', 1]],\n        rowLabels=[\"A\", \"B\"],\n        colLabels=[\"Col1\", \"Col2\"],\n        loc=\"center\")\n    tb3.auto_set_font_size(False)\n    tb3.set_fontsize(12)\n    tb3.auto_set_column_width(-1)\n    tb3.auto_set_column_width(0)\n    tb3.auto_set_column_width(1)\n\n    # 4 non integer iterable input\n    ax4 = fig.add_subplot(4, 1, 4)\n    ax4.axis('off')\n    tb4 = ax4.table(\n        cellText=[['Fit Text', 2],\n                  ['very long long text, Longer text than default', 1]],\n        rowLabels=[\"A\", \"B\"],\n        colLabels=[\"Col1\", \"Col2\"],\n        loc=\"center\")\n    tb4.auto_set_font_size(False)\n   "], "sample_152": ["    def test_delete_with_keeping_parents_reverse_relationships(self):\n        child = RChild.objects.create()\n        parent_id = child.r_ptr_id\n        child.delete(keep_parents=True)\n        self.assertFalse(RChild.objects.filter(id=child.id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(S.objects.filter(r=parent_id).exists())\n\n        childchild = RChildChild.objects.create()\n        parent_id = childchild.rchild_ptr.r_ptr_id\n        child_id = childchild.rchild_ptr_id\n        parent_referent_id = S.objects.create(r=childchild.rchild_ptr.r_ptr).pk\n        childchild.delete(keep_parents=True)\n        self.assertFalse(RChildChild.objects.filter(id=childchild.id).exists())\n        self.assertTrue(RChild.objects.filter(id=child_id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(S.objects.filter(r=parent_id).exists())\n"], "sample_15": ["    def test_power_invalid_units(self):\n        with pytest.raises(TypeError, match=\"raise something to a dimensionless\"):\n            np.power(3.0, 4.0 * u.m)\n"], "sample_121": ["    def test_field_name_starting_with_underscore(self):\n        class Model(models.Model):\n            _field = models.CharField(max_length=10)\n\n        self.assertEqual(Model.check(), [\n            Error(\n                'Field names must not start with an underscore.',\n                obj=Model._meta.get_field('_field'),\n                id='fields.E001',\n            ),\n        ])\n"], "sample_536": ["def test_Cursor(ax):\n    cursor = widgets.Cursor(ax, useblit=False)\n    assert cursor.visible\n    cursor.visible = False\n    assert not cursor.visible\n    cursor.visible = True\n    assert cursor.visible\n    cursor.set_visible(False)\n    assert not cursor.visible\n    cursor.set_visible(True)\n    assert cursor.visible\n\n    cursor.horizOn = False\n    cursor.vertOn = False\n    cursor.update()\n    assert not cursor.visible\n\n    cursor.horizOn = True\n    cursor.vertOn = True\n    cursor.update()\n    assert cursor.visible\n\n    cursor.horizOn = False\n    cursor.vertOn = True\n    cursor.update()\n    assert cursor.visible\n\n    cursor.horizOn = True\n    cursor.vertOn = False\n    cursor.update()\n    assert cursor.visible\n\n    cursor.horizOn = False\n    cursor.vertOn = False\n    cursor.update()\n    assert not cursor.visible\n\n    cursor.horizOn = True\n    cursor.vertOn = True\n    cursor.update()\n    assert cursor.visible\n\n    cursor.horizOn = False\n    cursor.vertOn = True\n    cursor.update()\n    assert cursor.visible\n\n    cursor.horizOn = True\n    cursor.vertOn = False\n    cursor.update()\n    assert cursor.visible\n\n    cursor.horizOn = False\n    cursor.vertOn = False\n    cursor.update()\n    assert not cursor.visible\n\n    cursor.horizOn = True\n    cursor.vertOn = True\n    cursor.update()\n    assert cursor.visible\n\n    cursor.horizOn = False\n    cursor.vertOn = True\n    cursor.update()\n    assert cursor.visible\n\n    cursor.horizOn = True\n    cursor.vertOn = False\n    cursor.update()\n    assert cursor.visible\n\n    cursor.horizOn = False\n    cursor.vertOn = False\n    cursor.update()\n    assert not cursor.visible\n\n    cursor.horizOn = True\n    cursor.vertOn = True\n    cursor.update()\n    assert cursor.visible\n\n    cursor.horizOn = False\n    cursor.vertOn = True\n    cursor.update()\n    assert cursor.visible\n\n    cursor.horizOn = True\n    cursor.vertOn = False\n    cursor.update()\n    assert cursor.visible\n\n    cursor.horizOn = False\n    cursor.vertOn = False\n    cursor.update()\n    assert not cursor.visible\n\n    cursor.hor"], "sample_389": ["    def test_get_signed_cookie(self):\n        req = HttpRequest()\n        req.COOKIES[\"test_cookie\"] = \"signed_value\"\n        with self.assertRaises(RawPostDataException):\n            req.get_signed_cookie(\"test_cookie\")\n        req.COOKIES[\"test_cookie\"] = \"signed_value; expires=Fri, 01-Jan-2038 00:00:00 GMT\"\n        self.assertEqual(req.get_signed_cookie(\"test_cookie\"), \"signed_value\")\n        req.COOKIES[\"test_cookie\"] = \"signed_value; expires=Fri, 01-Jan-2038 00:00:00 GMT; max-age=3600\"\n        self.assertEqual(req.get_signed_cookie(\"test_cookie\", max_age=3600), \"signed_value\")\n        req.COOKIES[\"test_cookie\"] = \"signed_value; expires=Fri, 01-Jan-2038 00:00:00 GMT; max-age=3600\"\n        self.assertEqual(req.get_signed_cookie(\"test_cookie\", max_age=7200), \"signed_value\")\n        req.COOKIES[\"test_cookie\"] = \"signed_value; expires=Fri, 01-Jan-2038 00:00:00 GMT; max-age=3600\"\n        self.assertEqual(req.get_signed_cookie(\"test_cookie\", max_age=3600, salt=\"salt\"), \"signed_value\")\n        req.COOKIES[\"test_cookie\"] = \"signed_value; expires=Fri, 01-Jan-2038 00:00:00 GMT; max-age=3600\"\n        self.assertEqual(req.get_signed_cookie(\"test_cookie\", default=\"default_value\"), \"signed_value\")\n        req.COOKIES[\"test_cookie\"] = \"signed_value; expires=Fri, 01-Jan-2038 00:00:00 GMT; max-age=3600\"\n        self.assertEqual(req.get_signed_cookie(\"test_cookie\", default=\"default_value\", max_age=3600), \"signed_value\")\n        req.COOKIES[\"test_cookie\"] = \"signed_value; expires=Fri, 01-Jan-2038 00:00:00 GMT; max-age=3600\"\n        self.assertEqual(req.get_signed_cookie(\"test_cookie\", default=\"default_value\", salt=\"salt\"), \"signed_value\")\n        req.COOKIES[\"test_cookie\"] = \"signed_value; expires=Fri, 01-Jan-2038 00:00:00 GMT; max-age=3600\"\n        self.assertEqual(req.get_signed"], "sample_1024": ["def test_issue_10020():\n    assert oo**I is S.NaN\n    assert oo**(1 + I) is S.ComplexInfinity\n    assert oo**(-1 + I) is S.Zero\n    assert (-oo)**I is S.NaN\n    assert (-oo)**(-1 + I) is S.Zero\n    assert oo**t == Pow(oo, t, evaluate=False)\n    assert (-oo)**t == Pow(-oo, t, evaluate=False)\n"], "sample_85": ["    def test_delete_with_keeping_parents_through(self):\n        child = RChildChild.objects.create()\n        parent_id = child.rchild_ptr_id\n        parent_referent_id = S.objects.create(r=child.rchild_ptr.r_ptr).pk\n        child.delete(keep_parents=True)\n        self.assertFalse(RChildChild.objects.filter(id=child.id).exists())\n        self.assertTrue(RChild.objects.filter(id=parent_id).exists())\n        self.assertTrue(R.objects.filter(id=parent_referent_id).exists())\n        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n"], "sample_1121": ["def test_Mul_as_two_terms():\n    x, y = symbols('x y')\n    assert Mul(x, y).as_two_terms() == (x, y)\n    assert Mul(x, y, z).as_two_terms() == (x, y*z)\n    assert Mul(x, y, z, w).as_two_terms() == (x, y*z*w)\n    assert Mul(x, y, z, w, v).as_two_terms() == (x, y*z*w*v)\n    assert Mul(x, y, z, w, v, u).as_two_terms() == (x, y*z*w*v*u)\n    assert Mul(x, y, z, w, v, u, t).as_two_terms() == (x, y*z*w*v*u*t)\n    assert Mul(x, y, z, w, v, u, t, s).as_two_terms() == (x, y*z*w*v*u*t*s)\n    assert Mul(x, y, z, w, v, u, t, s, r).as_two_terms() == (x, y*z*w*v*u*t*s*r)\n    assert Mul(x, y, z, w, v, u, t, s, r, q).as_two_terms() == (x, y*z*w*v*u*t*s*r*q)\n    assert Mul(x, y, z, w, v, u, t, s, r, q, p).as_two_terms() == (x, y*z*w*v*u*t*s*r*q*p)\n    assert Mul(x, y, z, w, v, u, t, s, r, q, p, o).as_two_terms() == (x, y*z*w*v*u*t*s*r*q*p*o)\n    assert Mul(x, y, z, w, v, u, t, s, r, q, p, o, n).as_two_terms() == (x, y*z*w*v*u*t*s*r*q*p*o*n)\n    assert Mul(x, y, z, w, v, u, t, s, r, q, p, o, n, m).as_two_terms() == (x, y*z*w*v*u*t*s*r*q*p*o*n*m)\n    assert Mul(x, y, z, w, v, u, t, s, r, q, p, o, n, m, l)."], "sample_1009": ["def test_vector_cross_product():\n    q1, q2, q3 = dynamicsymbols('q1 q2 q3')\n    N = ReferenceFrame('N')\n    A = N.orientnew('A', 'Axis', [q1, N.y])\n    B = A.orientnew('B', 'Axis', [q2, A.x])\n    v1 = q1 * N.x + q2 * N.y\n    v2 = q3 * A.x + q1 * A.y\n\n    assert v1 ^ v2 == -q1*q3*A.z\n    assert v2 ^ v1 == q1*q3*A.z\n\n    v3 = v1 ^ v2\n    assert v3 & N.x == 0\n    assert v3 & N.y == 0\n    assert v3 & N.z == -q1*q3\n\n    v4 = v2 ^ v1\n    assert v4 & N.x == 0\n    assert v4 & N.y == 0\n    assert v4 & N.z == q1*q3\n\n    v5 = v1 ^ v1\n    assert v5 == Vector(0)\n\n    v6 = v2 ^ v2\n    assert v6 == Vector(0)\n\n    v7 = v1 ^ v3\n    assert v7 == Vector(0)\n\n    v8 = v2 ^ v4\n    assert v8 == Vector(0)\n\n    v9 = v1 ^ v5\n    assert v9 == v1\n\n    v10 = v2 ^ v6\n    assert v10 == v2\n\n    v11 = v3 ^ v5\n    assert v11 == -v3\n\n    v12 = v4 ^ v6\n    assert v12 == -v4\n\n    v13 = v1 ^ v7\n    assert v13 == v1\n\n    v14 = v2 ^ v8\n    assert v14 == v2\n\n    v15 = v3 ^ v9\n    assert v15 == -v3\n\n    v16 = v4 ^ v10\n    assert v16 == -v4\n\n    v17 = v1 ^ v11\n    assert v17 == v1\n\n    v18 = v2 ^ v12\n    assert v18 == v2\n\n    v19 = v3 ^ v13\n    assert v19 == -v3\n\n    v"], "sample_335": ["    def test_decimalfield_7(self):\n        f = DecimalField(max_digits=4, decimal_places=2, max_value=decimal.Decimal('1.5'), min_value=decimal.Decimal('0.5'))\n        with self.assertRaisesMessage(ValidationError, \"'Ensure this value is less than or equal to 1.5.'\"):\n            f.clean(decimal.Decimal('1.6'))\n        with self.assertRaisesMessage(ValidationError, \"'Ensure this value is greater than or equal to 0.5.'\"):\n            f.clean(decimal.Decimal('0.4'))\n        with self.assertRaisesMessage(ValidationError, \"'Ensure this value is less than or equal to 1.5.'\"):\n            f.clean(decimal.Decimal('1.6'))\n        with self.assertRaisesMessage(ValidationError, \"'Ensure this value is greater than or equal to 0.5.'\"):\n            f.clean(decimal.Decimal('0.4'))\n        self.assertEqual(f.clean(decimal.Decimal('1.5')), decimal.Decimal(\"1.5\"))\n        self.assertEqual(f.clean(decimal.Decimal('0.5')), decimal.Decimal(\"0.5\"))\n        self.assertEqual(f.max_digits, 4)\n        self.assertEqual(f.decimal_places, 2)\n        self.assertEqual(f.max_value, decimal.Decimal('1.5'))\n        self.assertEqual(f.min_value, decimal.Decimal('0.5'))\n"], "sample_1172": ["def test_solve_generic():\n    x, y, z = symbols('x y z')\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    assert solve_generic([f_1, f_2, f_3], (x, y, z)) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0), (sqrt(2) - 1, sqrt(2) - 1, sqrt(2) - 1), \n         (-sqrt(2) - 1, -sqrt(2) - 1, -sqrt(2) - 1)]\n\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    dom = QQ.algebraic_field(sqrt(2))\n\n    assert solve_generic([f_1, f_2, f_3], (x, y, z), domain=dom) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0), (sqrt(2) - 1, sqrt(2) - 1, sqrt(2) - 1), \n         (-sqrt(2) - 1, -sqrt(2) - 1, -sqrt(2) - 1)]\n\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    assert solve_generic([f_1, f_2, f_3], (x, y)) is None\n\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    assert solve_generic([f_1, f_2, f_3], (x,)) is None\n\n    f_1 = x**2 + y + z - 1\n    f"], "sample_747": ["def test_power_transformer_axis1():\n    X = np.abs(X_2d)[:, 0:1]\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method='box-cox', standardize=standardize)\n\n        X_trans_class = pt.fit_transform(X)\n        X_trans_func = power_transform(X, standardize=standardize)\n\n        for X_trans in [X_trans_class, X_trans_func]:\n            X_expected, lmbda = stats.boxcox(X.flatten())\n\n            if standardize:\n                X_expected = scale(X_expected)\n\n            assert_almost_equal(X_trans, X_expected)\n            assert_almost_equal(lmbda, pt.lambdas_[0])\n\n            # Test inverse transformation\n            X_inv = pt.inverse_transform(X_trans)\n            assert_array_almost_equal(X_inv, X)\n\n        assert len(pt.lambdas_) == X.shape[1]\n        assert isinstance(pt.lambdas_, np.ndarray)\n"], "sample_1093": ["def test_SymPyPrinter_print_Function():\n    p = SymPyPrinter()\n    assert p.doprint(Function('f', x)) == 'sympy.Function(f)(x)'\n    assert p.doprint(Function('f', x, y)) == 'sympy.Function(f)(x, y)'\n    assert p.doprint(Function('f', x, y, z)) == 'sympy.Function(f)(x, y, z)'\n"], "sample_870": ["def test_gpr_predict_input_not_modified_with_cov():\n    \"\"\"\n    Check that the input X is not modified by the predict method of the\n    GaussianProcessRegressor when setting return_cov=True.\n\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/24340\n    \"\"\"\n    gpr = GaussianProcessRegressor(kernel=CustomKernel()).fit(X, y)\n\n    X2_copy = np.copy(X2)\n    _, _ = gpr.predict(X2, return_cov=True)\n\n    assert_allclose(X2, X2_copy)\n"], "sample_920": ["    def test_custom_sections(self):\n        docstring = \"\"\"\\"], "sample_401": ["    def test_custom_renderer(self):\n        \"\"\"\n        A custom renderer passed to a formset_factory() is passed to all forms\n        and ErrorList.\n        \"\"\"\n        from django.forms.renderers import Jinja2\n\n        renderer = Jinja2()\n        data = {\n            \"choices-TOTAL_FORMS\": \"2\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Zero\",\n            \"choices-0-votes\": \"\",\n            \"choices-1-choice\": \"One\",\n            \"choices-1-votes\": \"\",\n        }\n        ChoiceFormSet = formset_factory(Choice, renderer=renderer)\n        formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertEqual(formset.renderer, renderer)\n        self.assertEqual(formset.forms[0].renderer, renderer)\n        self.assertEqual(formset.management_form.renderer, renderer)\n        self.assertEqual(formset.non_form_errors().renderer, renderer)\n        self.assertEqual(formset.empty_form.renderer, renderer)\n"], "sample_19": ["def test_subaxis():\n    \"\"\"\n    Test that WCS.subaxis works correctly.\n    \"\"\"\n    w = wcs.WCS(naxis=3)\n    w.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\", \"FREQ\"]\n    w.wcs.crpix = [32.5, 16.5, 1.0]\n    w.wcs.crval = [5.63, -72.05, 1.0]\n    w.wcs.pc = [[5.9e-06, 1.3e-05, 0.0], [-1.2e-05, 5.0e-06, 0.0], [0.0, 0.0, 1.0]]\n    w.wcs.cdelt = [1.0, 1.0, 1.0]\n    w.wcs.set()\n\n    # Test that subaxis returns a WCS with the correct number of axes\n    w_sub = w.subaxis(1)\n    assert w_sub.naxis == 2\n\n    # Test that subaxis returns a WCS with the correct ctype\n    assert list(w_sub.wcs.ctype) == [\"RA---TAN\", \"DEC--TAN\"]\n\n    # Test that subaxis returns a WCS with the correct crpix\n    assert np.allclose(w_sub.wcs.crpix, [32.5, 16.5])\n\n    # Test that subaxis returns a WCS with the correct crval\n    assert np.allclose(w_sub.wcs.crval, [5.63, -72.05])\n\n    # Test that subaxis returns a WCS with the correct pc\n    assert np.allclose(w_sub.wcs.pc, [[5.9e-06, 1.3e-05], [-1.2e-05, 5.0e-06]])\n\n    # Test that subaxis returns a WCS with the correct cdelt\n    assert np.allclose(w_sub.wcs.cdelt, [1.0, 1.0])\n\n    # Test that subaxis returns a WCS with the correct bounds\n    w_sub.bounds_check(False, False)\n    ra, dec = w_sub.wcs_pix2world(300, 0, 0)\n    assert_allclose(ra, -180)\n    assert_allclose(dec, -30)\n\n    # Test that subaxis returns a WCS with the"], "sample_933": ["def test_gettext_template_msgid_order_in_sphinxpot_compact(app):\n    app.builder.build_all()\n    assert (app.outdir / 'sphinx.pot').isfile()\n\n    result = (app.outdir / 'sphinx.pot').read_text()\n    assert re.search(\n        ('msgid \"Template 1\".*'\n         'msgid \"This is Template 1\\\\.\".*'\n         'msgid \"Template 2\".*'\n         'msgid \"This is Template 2\\\\.\".*'),\n        result,\n        flags=re.S)\n\n    # Test with compact mode\n    app.builder.config.gettext_compact = True\n    app.builder.build_all()\n    assert (app.outdir / 'sphinx.pot').isfile()\n\n    result = (app.outdir / 'sphinx.pot').read_text()\n    assert re.search(\n        ('msgid \"Template 1\".*'\n         'msgid \"This is Template 1\\\\.\".*'\n         'msgid \"Template 2\".*'\n         'msgid \"This is Template 2\\\\.\".*'),\n        result,\n        flags=re.S)\n"], "sample_1200": ["def test_dimensional_dependencies():\n    u = Quantity('u')\n    v = Quantity('v')\n    w = Quantity('w')\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    assert SI.get_dimension_system().get_dimensional_dependencies(u) == {\n        length: 1,\n        time: 0\n    }\n    assert SI.get_dimension_system().get_dimensional_dependencies(v) == {\n        length: 1,\n        time: 0\n    }\n    assert SI.get_dimension_system().get_dimensional_dependencies(w) == {\n        length: 0,\n        time: 1\n    }\n\n    expr = u + v\n    Dq = Dimension(SI.get_dimensional_expr(expr))\n    assert SI.get_dimension_system().get_dimensional_dependencies(Dq) == {\n        length: 1,\n        time: 0\n    }\n\n    expr = u * w\n    Dq = Dimension(SI.get_dimensional_expr(expr))\n    assert SI.get_dimension_system().get_dimensional_dependencies(Dq) == {\n        length: 1,\n        time: 1\n    }\n\n    expr = u / w\n    Dq = Dimension(SI.get_dimensional_expr(expr))\n    assert SI.get_dimension_system().get_dimensional_dependencies(Dq) == {\n        length: 1,\n        time: -1\n    }\n\n    expr = u ** 2\n    Dq = Dimension(SI.get_dimensional_expr(expr))\n    assert SI.get_dimension_system().get_dimensional_dependencies(Dq) == {\n        length: 2,\n        time: 0\n    }\n\n    expr = u ** -1\n    Dq = Dimension(SI.get_dimensional_expr(expr))\n    assert SI.get_dimension_system().get_dimensional_dependencies(Dq) == {\n        length: -1,\n        time: 0\n    }\n"], "sample_850": ["def test_nystroem_kernel_params():\n    # Non-regression: Nystroem should pass other parameters beside gamma.\n    rnd = np.random.RandomState(37)\n    X = rnd.uniform(size=(10, 4))\n\n    K = rbf_kernel(X, gamma=10, coef0=0.1)\n    nystroem = Nystroem(kernel=\"rbf\", n_components=X.shape[0],\n                        gamma=10, coef0=0.1)\n    X_transformed = nystroem.fit_transform(X)\n    assert_array_almost_equal(np.dot(X_transformed, X_transformed.T), K)\n\n    # test that available kernels fit and transform\n    kernels_available = kernel_metrics()\n    for kern in kernels_available:\n        nystroem = Nystroem(kernel=kern, n_components=X.shape[0],\n                            gamma=10, coef0=0.1)\n        X_transformed = nystroem.fit(X).transform(X)\n        assert X_transformed.shape == (X.shape[0], 2)\n\n    # test that available kernels fit and transform with default parameters\n    kernels_available = kernel_metrics()\n    for kern in kernels_available:\n        nystroem = Nystroem(kernel=kern, n_components=X.shape[0])\n        X_transformed = nystroem.fit(X).transform(X)\n        assert X_transformed.shape == (X.shape[0], 2)\n"], "sample_1130": ["def test_auto_point_vel_multiple_path_warning_msg():\n    N = ReferenceFrame('N')\n    O = Point('O')\n    P = Point('P')\n    Q = Point('Q')\n    R = Point('R')\n    P.set_vel(N, N.x)\n    Q.set_vel(N, N.y)\n    R.set_vel(N, N.z)\n    O.set_pos(P, N.z)\n    O.set_pos(Q, N.y)\n    O.set_pos(R, N.x)\n    with warnings.catch_warnings(record = True) as w: #There are two possible paths in this point tree, thus a warning is raised\n        warnings.simplefilter(\"always\")\n        O.vel(N)\n        assert issubclass(w[-1].category, UserWarning)\n        assert 'Velocity automatically calculated based on point' in str(w[-1].message)\n        assert 'Velocities from these points are not necessarily the same. This may cause errors in your calculations.' in str(w[-1].message)\n"], "sample_909": ["    def test_custom_sections(self):\n        docstring = \"\"\"\\"], "sample_766": ["def test_dict_learning_online_partial_fit_convergence():\n    n_components = 12\n    rng = np.random.RandomState(0)\n    V = rng.randn(n_components, n_features)  # random init\n    V /= np.sum(V ** 2, axis=1)[:, np.newaxis]\n    dict1 = MiniBatchDictionaryLearning(n_components, n_iter=10 * len(X),\n                                        batch_size=1,\n                                        alpha=1, shuffle=False, dict_init=V,\n                                        random_state=0).fit(X)\n    dict2 = MiniBatchDictionaryLearning(n_components, alpha=1,\n                                        n_iter=1, dict_init=V,\n                                        random_state=0)\n    for i in range(10):\n        for sample in X:\n            dict2.partial_fit(sample[np.newaxis, :])\n\n    # Check that the two dictionaries are close after partial fit\n    assert_array_almost_equal(dict1.components_, dict2.components_, decimal=2)\n"], "sample_418": ["    def test_length_is12(self):\n        output = self.engine.render_to_string(\n            \"length_is12\", {\"some_list\": [\"4\", None, True, {}]}\n        )\n        self.assertEqual(output, \"\")\n"], "sample_1124": ["def test_FracElement___pos__():\n    F, x,y = field(\"x,y\", QQ)\n\n    f = (7*x - 9)/y\n    g = (9 - 7*x)/y\n\n    assert +f == g\n    assert +g == f\n"], "sample_507": ["    def test_StrCategoryFormatterUpdate(self, ydata):\n        unit = cat.UnitData(ydata)\n        labels = cat.StrCategoryFormatter(unit._mapping)\n        unit.update(['d', 'e'])\n        new_labels = cat.StrCategoryFormatter(unit._mapping)\n        for i, d in enumerate(ydata):\n            assert labels(i, i) == d\n            assert labels(i, None) == d\n        for i, d in enumerate(['d', 'e']):\n            assert new_labels(i, i) == d\n            assert new_labels(i, None) == d\n        assert new_labels(i+2, i+2) == \"\"\n"], "sample_260": ["def test_create_model_add_index(self):\n    \"\"\"\n    AddIndex should optimize into CreateModel.\n    \"\"\"\n    managers = [('objects', EmptyManager())]\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n                options={'verbose_name': 'Foo'},\n                bases=(UnicodeModel,),\n                managers=managers,\n            ),\n            migrations.AddIndex(\"Foo\", models.Index(fields=[\"name\"])),\n        ],\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[\n                    (\"name\", models.CharField(max_length=255)),\n                ],\n                options={'verbose_name': 'Foo'},\n                bases=(UnicodeModel,),\n                managers=managers,\n                indexes=[\n                    models.Index(fields=[\"name\"]),\n                ],\n            ),\n        ],\n    )\n"], "sample_663": ["    def test_collect_with_conftest(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n                return path.basename == \"test_one.py\"\n        \"\"\"\n        )\n        testdir.makepyfile(\"def test_hello(): pass\")\n        testdir.makepyfile(test_one=\"syntax error\")\n        result = testdir.runpytest()\n        assert result.ret == ExitCode.NO_TESTS_COLLECTED\n        result.stdout.fnmatch_lines([\"*collected 0 items*\"])\n"], "sample_734": ["def test_homogeneity_completeness_v_measure():\n    # Test homogeneity, completeness and V-measure for a variety of cases\n    h, c, v = homogeneity_completeness_v_measure([0, 0, 1, 1, 2, 2],\n                                                  [0, 0, 1, 1, 2, 2])\n    assert_almost_equal(h, 1.00, 2)\n    assert_almost_equal(c, 1.00, 2)\n    assert_almost_equal(v, 1.00, 2)\n\n    h, c, v = homogeneity_completeness_v_measure([0, 0, 1, 1, 2, 2],\n                                                  [0, 1, 0, 1, 2, 2])\n    assert_almost_equal(h, 0.67, 2)\n    assert_almost_equal(c, 0.42, 2)\n    assert_almost_equal(v, 0.52, 2)\n\n    h, c, v = homogeneity_completeness_v_measure([0, 0, 0, 1, 1, 1],\n                                                  [0, 1, 0, 1, 2, 2])\n    assert_almost_equal(h, 1.00, 2)\n    assert_almost_equal(c, 0.69, 2)\n    assert_almost_equal(v, 0.81, 2)\n\n    h, c, v = homogeneity_completeness_v_measure([0, 0, 1, 1, 2, 2],\n                                                  [0, 0, 1, 1, 1, 1])\n    assert_almost_equal(h, 0.58, 2)\n    assert_almost_equal(c, 1.00, 2)\n    assert_almost_equal(v, 0.73, 2)\n\n    h, c, v = homogeneity_completeness_v_measure([0, 0, 0, 1, 1, 1],\n                                                  [0, 1, 0, 1, 2, 2])\n    assert_almost_equal(h, 0.67, 2)\n    assert_almost_equal(c, 0.42, 2)\n    assert_almost_equal(v, 0.52, 2)\n\n    h, c, v = homogeneity_completeness_v_measure([0,"], "sample_240": ["def test_token_with_different_password(self):\n    \"\"\"\n    A valid token can be created with a password other than the one used to\n    create the user.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    user.set_password('newpw')\n    user.save()\n    self.assertIs(p0.check_token(user, tk1), False)\n"], "sample_1169": ["def test_FockStateFermionKet():\n    i, j, k, l = symbols('i,j,k,l', below_fermi=True)\n    a, b, c, d = symbols('a,b,c,d', above_fermi=True)\n    p, q, r, s = symbols('p,q,r,s')\n    assert FKet([]) == FKet([])\n    assert FKet([i]) == FKet([i])\n    assert FKet([i, j]) == FKet([i, j])\n    assert FKet([i, j, k]) == FKet([i, j, k])\n    assert FKet([i, j, k, l]) == FKet([i, j, k, l])\n    assert FKet([i, j, k, l, a]) == FKet([i, j, k, l, a])\n    assert FKet([i, j, k, l, a, b]) == FKet([i, j, k, l, a, b])\n    assert FKet([i, j, k, l, a, b, c]) == FKet([i, j, k, l, a, b, c])\n    assert FKet([i, j, k, l, a, b, c, d]) == FKet([i, j, k, l, a, b, c, d])\n    assert FKet([i, j, k, l, a, b, c, d, p]) == FKet([i, j, k, l, a, b, c, d, p])\n    assert FKet([i, j, k, l, a, b, c, d, p, q]) == FKet([i, j, k, l, a, b, c, d, p, q])\n    assert FKet([i, j, k, l, a, b, c, d, p, q, r]) == FKet([i, j, k, l, a, b, c, d, p, q, r])\n    assert FKet([i, j, k, l, a, b, c, d, p, q, r, s]) == FKet([i, j, k, l, a, b, c, d, p, q, r, s])\n    assert FKet([i, j"], "sample_370": ["    def test_prefetch_related_with_to_attr(self):\n        with self.assertNumQueries(2):\n            lists = [list(b.authors.all()) for b in Book.objects.prefetch_related('authors', to_attr='authors_list')]\n        normal_lists = [list(b.authors.all()) for b in Book.objects.all()]\n        self.assertEqual(lists, normal_lists)\n"], "sample_1079": ["def test_project():\n    p1 = Point(1, 2)\n    p2 = Point(3, 4)\n    assert Point.project(p1, p2) == Point(7/5, 6/5)\n    p3 = Point(0, 0)\n    assert Point.project(p1, p3) == p1\n    p4 = Point(0, 0)\n    assert Point.project(p4, p4) == p4\n    raises(ValueError, lambda: Point.project(p1, p4))\n"], "sample_338": ["def test_alter_field_with_default(self):\n    \"\"\"#23609 - Altering a field with a default should work.\"\"\"\n    changes = self.get_changes([self.author_name_default], [self.author_name])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\", default=models.NOT_PROVIDED)\n"], "sample_866": ["def test_affinity_propagation_fit_predict_precomputed():\n    # Test AffinityPropagation.fit_predict with precomputed affinity matrix\n    X = np.array([[1, 2], [1, 4], [1, 0],\n                  [4, 2], [4, 4], [4, 0]])\n    S = np.dot(X, X.T)\n    af = AffinityPropagation(affinity=\"precomputed\")\n    labels = af.fit_predict(S)\n    assert_array_equal(labels, np.array([0, 0, 0, 1, 1, 1]))\n"], "sample_64": ["    def test_content_type(self):\n        r = HttpResponse()\n        self.assertEqual(r['Content-Type'], 'text/html; charset=utf-8')\n        r['Content-Type'] = 'text/plain'\n        self.assertEqual(r['Content-Type'], 'text/plain')\n        self.assertEqual(r.charset, 'utf-8')\n        r.charset = 'latin-1'\n        self.assertEqual(r.charset, 'latin-1')\n        self.assertEqual(r['Content-Type'], 'text/plain; charset=latin-1')\n"], "sample_241": ["    def setUpTestData(cls):\n        cls.example_inc = Company.objects.create(\n            name=\"Example Inc.\", num_employees=2300, num_chairs=5,\n            ceo=Employee.objects.create(firstname=\"Joe\", lastname=\"Smith\", salary=10)\n        )\n        cls.foobar_ltd = Company.objects.create(\n            name=\"Foobar Ltd.\", num_employees=3, num_chairs=4, based_in_eu=True,\n            ceo=Employee.objects.create(firstname=\"Frank\", lastname=\"Meyer\", salary=20)\n        )\n        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.gmbh = Company.objects.create(name='Test GmbH', num_employees=32, num_chairs=1, ceo=cls.max)\n"], "sample_81": ["    def test_resolve(self):\n        resolver = get_resolver()\n        self.assertEqual(resolver.resolve('/').func, resolver.urlconf_module.handler404)\n        self.assertEqual(resolver.resolve('/').args, ())\n        self.assertEqual(resolver.resolve('/').kwargs, {})\n        self.assertEqual(resolver.resolve('/').url_name, None)\n        self.assertEqual(resolver.resolve('/').app_names, ['path_urls'])\n        self.assertEqual(resolver.resolve('/').namespaces, [''])\n        self.assertEqual(resolver.resolve('/').route, '')\n\n        self.assertEqual(resolver.resolve('/path/').func, resolver.urlconf_module.handler404)\n        self.assertEqual(resolver.resolve('/path/').args, ())\n        self.assertEqual(resolver.resolve('/path/').kwargs, {})\n        self.assertEqual(resolver.resolve('/path/').url_name, None)\n        self.assertEqual(resolver.resolve('/path/').app_names, ['path_urls'])\n        self.assertEqual(resolver.resolve('/path/').namespaces, [''])\n        self.assertEqual(resolver.resolve('/path/').route, '')\n\n        self.assertEqual(resolver.resolve('/path/<int:pk>/').func, resolver.urlconf_module.handler404)\n        self.assertEqual(resolver.resolve('/path/<int:pk>/').args, ())\n        self.assertEqual(resolver.resolve('/path/<int:pk>/').kwargs, {})\n        self.assertEqual(resolver.resolve('/path/<int:pk>/').url_name, None)\n        self.assertEqual(resolver.resolve('/path/<int:pk>/').app_names, ['path_urls'])\n        self.assertEqual(resolver.resolve('/path/<int:pk>/').namespaces, [''])\n        self.assertEqual(resolver.resolve('/path/<int:pk>/').route, '')\n\n        self.assertEqual(resolver.resolve('/path/<int:pk>/').func, resolver.urlconf_module.handler404)\n        self.assertEqual(resolver.resolve('/path/<int:pk>/').args, ())\n        self.assertEqual(resolver.resolve('/path/<int:pk>/').kwargs, {})\n        self.assertEqual(resolver.resolve('/path/<int:pk>/').url_name, None)\n        self.assertEqual(resolver.resolve('/path/<int:pk>/').app_names, ['path_urls'])\n        self.assertEqual(resolver.resolve('/path/<int:pk>/').namespaces, [''])\n        self.assertEqual(resolver.resolve('/path/<int:pk>/').route, '')\n\n        self.assertEqual(resolver.resolve('/path/<int:pk>/').func, resolver.urlconf_module.handler404)\n        self.assertEqual(resolver.resolve('/"], "sample_1082": ["def test_acsch_expansion():\n    x, y = symbols('x,y')\n    assert acsch(x+y).expand(trig=True) == acsch(x)*acsch(y) + acsch(x)*csch(y)\n    assert acsch(2*x).expand(trig=True) == 2*acsch(x)*csch(x)\n    assert acsch(3*x).expand(trig=True).expand() == \\\n        acsch(x)**3 + 3*acsch(x)*csch(x)**2\n"], "sample_438": ["    def test_get_content_type_arguments(self):\n        class Model(models.Model):\n            field = GenericForeignKey()\n\n        with self.assertRaisesMessage(\n            Exception, \"Impossible arguments to GFK.get_content_type!\"\n        ):\n            Model.field.get_content_type()\n"], "sample_897": ["def test_plot_partial_dependence_kind_centered_subsample(\n    pyplot,\n    kind,\n    centered,\n    subsample,\n    shape,\n    clf_diabetes,\n    diabetes,"], "sample_118": ["def test_year_lookup(self):\n    # Year lookup can be performed using the year attribute of a DateField or DateTimeField.\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 7>',\n        ]\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__exact=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 7>',\n        ]\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gt=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 7>',\n        ]\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gte=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 7>',\n        ]\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lt=2005),\n        []\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lte=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n        ]\n    )\n"], "sample_101": ["    def test_get(self):\n        \"\"\"\n        GET property returns a QueryDict instance.\n        \"\"\"\n        environ = self.request_factory._base_environ(\n            PATH_INFO=\"/\",\n            CONTENT_TYPE=\"text/html; charset=utf-8\",\n            REQUEST_METHOD=\"GET\",\n            QUERY_STRING=\"a=1&b=2\"\n        )\n\n        request = WSGIRequest(environ)\n\n        self.assertIsInstance(request.GET, QueryDict)\n        self.assertEqual(request.GET['a'], ['1'])\n        self.assertEqual(request.GET['b'], ['2'])\n"], "sample_86": ["def test_lazy_object_copying(self):\n    \"\"\"\n    Test that lazy objects are copied correctly when using copy.copy() or copy.deepcopy().\n    \"\"\"\n    class Klazz:\n            self.value = value\n\n            return self.value == other.value\n\n    lazy_klazz = lazy(lambda: Klazz(1), Klazz)\n\n    # Test copy.copy()\n    copied_lazy_klazz = copy.copy(lazy_klazz())\n    self.assertEqual(copied_lazy_klazz.value, 1)\n    self.assertEqual(lazy_klazz().value, 1)\n\n    # Test copy.deepcopy()\n    copied_lazy_klazz_deep = copy.deepcopy(lazy_klazz())\n    self.assertEqual(copied_lazy_klazz_deep.value, 1)\n    self.assertEqual(lazy_klazz().value, 1)\n\n    # Test that the original and copied objects are not the same instance\n    self.assertIsNot(copied_lazy_klazz, lazy_klazz())\n    self.assertIsNot(copied_lazy_klazz_deep, lazy_klazz())\n\n    # Test that the original and copied objects have the same class\n    self.assertEqual(type(copied_lazy_klazz), type(lazy_klazz()))\n    self.assertEqual(type(copied_lazy_klazz_deep), type(lazy_klazz()))\n"], "sample_595": ["def test_isnumeric():\n    # 0x00bc: \u00bc VULGAR FRACTION ONE QUARTER\n    # 0x2605: \u2605 not number\n    # 0x1378: \u1378 ETHIOPIC NUMBER SEVENTY\n    # 0xFF13: \uff13 Em 3\n    values = [\"A\", \"3\", \"\u00bc\", \"\u2605\", \"\u1378\", \"\uff13\", \"four\"]\n    s = xr.DataArray(values)\n    numeric_e = [False, True, True, False, True, True, False]\n    decimal_e = [False, True, False, False, False, True, False]\n    assert_equal(s.str.isnumeric(), xr.DataArray(numeric_e))\n    assert_equal(s.str.isdecimal(), xr.DataArray(decimal_e))\n"], "sample_771": ["def test_power_transformer_inverse_transform_shape_exception():\n    # Exceptions should be raised for arrays with different num_columns\n    # than during fitting\n    pt = PowerTransformer(method='yeo-johnson')\n    X = np.abs(X_2d)\n    pt.fit(X)\n\n    # Exceptions should be raised for arrays with different num_columns\n    # than during fitting\n    wrong_shape_message = 'Input data has a different number of features'\n\n    assert_raise_message(ValueError, wrong_shape_message,\n                         pt.inverse_transform, X[:, 0:1])\n"], "sample_513": ["def test_legend_title_fontsize():\n    fig, ax = plt.subplots()\n    ax.plot(range(10))\n    leg = ax.legend(title='Aardvark', title_fontsize=22)\n    assert leg.get_title().get_fontsize() == 22\n"], "sample_664": ["def test_funcargnames_deprecation(testdir):\n    \"\"\"Check that funcargnames is deprecated and raises a warning\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    with pytest.warns(PytestDeprecationWarning):\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"*The `funcargnames` attribute was an alias for `fixturenames`, *\"])\n"], "sample_823": ["def test_pairwise_distances_chunked_sparse():\n    # Test the pairwise_distance helper function.\n    rng = np.random.RandomState(0)\n    # Euclidean distance should be equivalent to calling the function.\n    X = rng.random_sample((400, 4))\n    X_sparse = csr_matrix(X)\n    check_pairwise_distances_chunked(X_sparse, None, working_memory=1,\n                                     metric='euclidean')\n    # Test small amounts of memory\n    for power in range(-16, 0):\n        check_pairwise_distances_chunked(X_sparse, None, working_memory=2 ** power,\n                                         metric='euclidean')\n    # X as list\n    check_pairwise_distances_chunked(X_sparse.todense().tolist(), None,\n                                     working_memory=1, metric='euclidean')\n    # Euclidean distance, with Y != X.\n    Y = rng.random_sample((200, 4))\n    Y_sparse = csr_matrix(Y)\n    check_pairwise_distances_chunked(X_sparse, Y_sparse, working_memory=1,\n                                     metric='euclidean')\n    check_pairwise_distances_chunked(X_sparse.todense().tolist(),\n                                     Y_sparse.todense().tolist(), working_memory=1,\n                                     metric='euclidean')\n    # absurdly large working_memory\n    check_pairwise_distances_chunked(X_sparse, Y_sparse, working_memory=10000,\n                                     metric='euclidean')\n    # \"cityblock\" uses scikit-learn metric, cityblock (function) is\n    # scipy.spatial.\n    check_pairwise_distances_chunked(X_sparse, Y_sparse, working_memory=1,\n                                     metric='cityblock')\n    # Test that a value error is raised if the metric is unknown\n    assert_raises(ValueError, next,\n                  pairwise_distances_chunked(X_sparse, Y_sparse, metric=\"blah\"))\n\n    # Test precomputed returns all at once\n    D = pairwise_distances(X_sparse)\n    gen = pairwise_distances_chunked(D,\n                                     working_memory=2 ** -16,\n                                     metric='precomputed')\n    assert isinstance(gen, GeneratorType)\n    assert next(gen) is D\n    assert_raises(StopIteration, next, gen)\n"], "sample_824": ["def test_pairwise_distances_argmin_min_callable():\n    # Check pairwise minimum distances computation for any metric\n    X = [[0], [1]]\n    Y = [[-2], [3]]\n\n    Xsp = dok_matrix(X)\n    Ysp = csr_matrix(Y, dtype=np.float32)\n\n    expected_idx = [0, 1]\n    expected_vals = [2, 2]\n    expected_vals_sq = [4, 4]\n\n    # euclidean metric\n    idx, vals = pairwise_distances_argmin_min(X, Y, metric=\"euclidean\")\n    idx2 = pairwise_distances_argmin(X, Y, metric=\"euclidean\")\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(idx2, expected_idx)\n    assert_array_almost_equal(vals, expected_vals)\n    # sparse matrix case\n    idxsp, valssp = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"euclidean\")\n    assert_array_almost_equal(idxsp, expected_idx)\n    assert_array_almost_equal(valssp, expected_vals)\n    # We don't want np.matrix here\n    assert_equal(type(idxsp), np.ndarray)\n    assert_equal(type(valssp), np.ndarray)\n\n    # euclidean metric squared\n    idx, vals = pairwise_distances_argmin_min(X, Y, metric=\"euclidean\",\n                                              metric_kwargs={\"squared\": True})\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(vals, expected_vals_sq)\n\n    # Non-euclidean scikit-learn metric\n    idx, vals = pairwise_distances_argmin_min(X, Y, metric=\"manhattan\")\n    idx2 = pairwise_distances_argmin(X, Y, metric=\"manhattan\")\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(idx2, expected_idx)\n    assert_array_almost_equal(vals, expected_vals)\n    # sparse matrix case\n    idxsp, valssp = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"manhattan\")\n    assert_array_almost_equal(idxsp, expected_idx)\n    assert_array_almost_equal(valssp, expected_vals)\n\n    # Non-euclidean Scipy distance (callable)\n    idx, vals = pairwise_distances_argmin_min(X, Y, metric=minkowski,\n                                              metric_kwargs={\"p\": 2})\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(vals, expected_vals)\n\n    # Non-euclidean Scipy distance (string"], "sample_352": ["        def as_sql(self, compiler, connection):\n            return 'dummy', []\n"], "sample_574": ["    def x(self):\n        return pd.Series([1, 10, 100], name=\"x\", dtype=float)\n"], "sample_492": ["def test_serialize_datetime_tzinfo(self):\n    \"\"\"\n    Test serialization of timezone-aware datetime objects.\n    \"\"\"\n    self.assertSerializedResultEqual(\n        datetime.datetime(2014, 1, 1, 1, 1, tzinfo=datetime.timezone.utc),\n        (\n            \"datetime.datetime(2014, 1, 1, 1, 1, tzinfo=datetime.timezone.utc)\",\n            {\"import datetime\"},\n        ),\n    )\n    self.assertSerializedResultEqual(\n        datetime.datetime(2012, 1, 1, 1, 1, tzinfo=zoneinfo.ZoneInfo(\"Europe/Paris\")),\n        (\n            \"datetime.datetime(2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc)\",\n            {\"import datetime\"},\n        ),\n    )\n"], "sample_599": ["def test_CFScaleOffsetCoder_encode_scale_factor():\n    original = xr.Variable((\"x\",), np.arange(10.0), encoding={\"scale_factor\": 10})\n    expected = xr.Variable((\"x\",), np.arange(1.0))\n    coder = variables.CFScaleOffsetCoder()\n    encoded = coder.encode(original)\n    assert_identical(expected, encoded)\n"], "sample_1094": ["def test_replace():\n    x, y = symbols('x y')\n    e = (x + y)\n    a, b = symbols('a b')\n    assert e.replace(x, a) == a + y\n    assert e.replace(x, a, map=True) == ({x: a}, a + y)\n    assert e.replace(x, a, map=True, simultaneous=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=True) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x, a, map=True, simultaneous=False, exact=False) == a + y\n    assert e.replace(x,"], "sample_1197": ["def test_get_dimension_system():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    w = Quantity(\"w\")\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    assert isinstance(u.get_dimension_system(), UnitSystem)\n    assert isinstance(v.get_dimension_system(), UnitSystem)\n    assert isinstance(w.get_dimension_system(), UnitSystem)\n\n    assert u.get_dimension_system() == v.get_dimension_system()\n    assert u.get_dimension_system() == w.get_dimension_system()\n\n    assert u.get_dimension_system() is SI.get_dimension_system()\n\n    # Test with a custom unit system\n    us = UnitSystem((\"m\", \"s\"), (\"kg\",), \"CustomSystem\")\n    assert us.get_dimension_system() is us\n\n    # Test with a non-existent unit system\n    with raises(ValueError):\n        UnitSystem.get_unit_system(\"NonExistentSystem\")\n"], "sample_428": ["def test_decimal_pos_zero(self):\n    self.assertEqual(nformat(1234, \".\", decimal_pos=0), \"1234\")\n    self.assertEqual(nformat(1234.2, \".\", decimal_pos=0), \"1234\")\n    self.assertEqual(nformat(1234, \".\", decimal_pos=0, decimal_sep=\",\"), \"1234\")\n    self.assertEqual(\n        nformat(1234, \".\", decimal_pos=0, grouping=2, thousand_sep=\",\"), \"1234\"\n    )\n    self.assertEqual(\n        nformat(1234, \".\", decimal_pos=0, grouping=2, thousand_sep=\",\", force_grouping=True),\n        \"12,34\",\n    )\n    self.assertEqual(nformat(-1234.33, \".\", decimal_pos=0), \"-1234\")\n    self.assertEqual(nformat(Decimal(\"1234\"), \".\", decimal_pos=0), \"1234\")\n    self.assertEqual(nformat(Decimal(\"1234.2\"), \".\", decimal_pos=0), \"1234\")\n    self.assertEqual(nformat(Decimal(\"1234\"), \".\", decimal_pos=0, decimal_sep=\",\"), \"1234\")\n    self.assertEqual(\n        nformat(Decimal(\"1234\"), \".\", decimal_pos=0, grouping=2, thousand_sep=\",\"), \"1234\"\n    )\n    self.assertEqual(\n        nformat(\n            Decimal(\"1234\"), \".\", decimal_pos=0, grouping=2, thousand_sep=\",\", force_grouping=True\n        ),\n        \"12,34\",\n    )\n    self.assertEqual(nformat(Decimal(\"-1234.33\"), \".\", decimal_pos=0), \"-1234\")\n    self.assertEqual(nformat(Decimal(\"0.00000001\"), \".\", decimal_pos=0), \"0\")\n    self.assertEqual(nformat(Decimal(\"9e-19\"), \".\", decimal_pos=0), \"0\")\n    self.assertEqual(nformat(Decimal(\".00000000000099\"), \".\", decimal_pos=0), \"0\")\n    self.assertEqual(nformat(Decimal(\"3.\"), \".\", decimal_pos=0), \"3\")\n    self.assertEqual(nformat(Decimal(\"3.0\"), \".\", decimal_pos=0), \"3\")\n"], "sample_1113": ["def test_block_inverse_index():\n    k, l, m, n = symbols('k l m n', integer=True)\n    i, j = symbols('i j', integer=True)\n    A1 = MatrixSymbol('A1', n, n)\n    A2 = MatrixSymbol('A2', n, l)\n    A3 = MatrixSymbol('A3', m, n)\n    A4 = MatrixSymbol('A4', m, m)\n    A = BlockMatrix([[A1, A2], [A3, A4]])\n    assert A.inv()[0, 0] == MatrixElement(A.inv(), 0, 0)\n    assert A.inv()[n - 1, n - 1] == MatrixElement(A.inv(), n - 1, n - 1)\n    assert A.inv()[n, n] == MatrixElement(A.inv(), n, n)\n    assert A.inv()[n + m - 1, n + m - 1] == MatrixElement(A.inv(), n + m - 1, n + m - 1)\n    assert A.inv()[n + m - 1, 0] == MatrixElement(A.inv(), n + m - 1, 0)\n    assert A.inv()[0, n + m - 1] == MatrixElement(A.inv(), 0, n + m - 1)\n    assert A.inv()[n + m - 1, n + m] == MatrixElement(A.inv(), n + m - 1, n + m)\n"], "sample_402": ["def test_prepend_www_append_slash_slashless_custom_urlconf(self):\n    \"\"\"\n    APPEND_SLASH and PREPEND_WWW should work together when a custom URLconf is used.\n    \"\"\"\n    request = self.rf.get(\"/customurlconf/slash\")\n    request.urlconf = \"middleware.extra_urls\"\n    r = CommonMiddleware(get_response_empty).process_request(request)\n    self.assertEqual(r.status_code, 301)\n    self.assertEqual(r.url, \"http://www.testserver/customurlconf/slash/\")\n"], "sample_29": ["def test_write_latex_overwrite_true(self, write, tmp_path):\n    \"\"\"Test to write a LaTeX file overwriting an existing file\"\"\"\n    # Test that passing an invalid path to write_latex() raises a IOError\n    fp = tmp_path / \"test_write_latex_overwrite_true.tex\"\n    write(fp, format=\"latex\")\n    write(fp, format=\"latex\", overwrite=True)\n"], "sample_833": ["def test_logistic_regression_path_multinomial():\n    # Test that the path algorithm is consistent for the multinomial case.\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = np.array([1] * 100 + [-1] * 100)\n    Cs = np.logspace(0, 4, 10)\n\n    for solver in ['lbfgs', 'newton-cg', 'sag', 'saga']:\n        coefs, Cs, _ = _logistic_regression_path(\n            X, y, Cs=Cs, fit_intercept=False, tol=1e-5, solver=solver,\n            multi_class='multinomial', random_state=0)\n        for i, C in enumerate(Cs):\n            lr = LogisticRegression(C=C, fit_intercept=False, tol=1e-5,\n                                    solver=solver, multi_class='multinomial',\n                                    random_state=0, max_iter=1000)\n            lr.fit(X, y)\n            lr_coef = lr.coef_.ravel()\n            assert_array_almost_equal(lr_coef, coefs[i], decimal=4,\n                                      err_msg=\"with solver = %s\" % solver)\n\n    # test for fit_intercept=True\n    for solver in ('lbfgs', 'newton-cg', 'sag', 'saga'):\n        Cs = [1e3]\n        coefs, Cs, _ = _logistic_regression_path(\n            X, y, Cs=Cs, fit_intercept=True, tol=1e-6, solver=solver,\n            intercept_scaling=10000., random_state=0, multi_class='multinomial')\n        lr = LogisticRegression(C=Cs[0], fit_intercept=True, tol=1e-4,\n                                intercept_scaling=10000., random_state=0,\n                                multi_class='multinomial', solver=solver)\n        lr.fit(X, y)\n        lr_coef = np.concatenate([lr.coef_.ravel(), lr.intercept_])\n        assert_array_almost_equal(lr_coef, coefs[0], decimal=4,\n                                  err_msg=\"with solver = %s\" % solver)\n"], "sample_384": ["    def test_update_with_update_conflicts(self):\n        self.create_tags()\n        for note in self.notes:\n            note.tag = self.tags[0]\n        Note.objects.bulk_update(self.notes, [\"tag\"], update_conflicts=True)\n        self.assertCountEqual(Note.objects.filter(tag__isnull=False), self.notes)\n"], "sample_91": ["def test_csrf_token_in_403(self):\n    \"\"\"\n    The 403 page should have the csrf_token available in the context\n    \"\"\"\n    # See ticket #14565\n    request = self.request_factory.get('/technical403/')\n    response = permission_denied(request, Exception())\n    self.assertNotEqual(response.content, b'NOTPROVIDED')\n    self.assertNotEqual(response.content, b'')\n"], "sample_83": ["    def setUp(self):\n        self.library = Library()\n"], "sample_512": ["def test_matshow():\n    A = np.array([[1, 2], [3, 4]])\n    fig, ax = plt.subplots()\n    im = plt.matshow(A)\n    assert isinstance(im, mpl.image.AxesImage)\n    plt.close()\n"], "sample_821": ["def test_affinity_propagation_fit_predict_precomputed():\n    # Test AffinityPropagation.fit_predict with precomputed affinity matrix\n    S = np.dot(X, X.T)\n    af = AffinityPropagation(affinity=\"precomputed\")\n    af.fit(S)\n    labels = af.fit_predict(X)\n    assert_array_equal(labels, af.labels_)\n"], "sample_69": ["    def test_iter_modules_and_files_cache(self):\n        \"\"\"\n        iter_modules_and_files() uses functools.lru_cache, so it should return\n        the same result when called multiple times with the same arguments.\n        \"\"\"\n        filename = self.temporary_file('test_module.py')\n        filename.write_text('def test(): pass')\n        with extend_sys_path(str(filename.parent)):\n            self.import_and_cleanup('test_module')\n        self.assertEqual(autoreload.iter_modules_and_files((sys.modules['test_module'],), frozenset()).pop(), filename)\n        self.assertEqual(autoreload.iter_modules_and_files((sys.modules['test_module'],), frozenset()).pop(), filename)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().hits, 1)\n"], "sample_1191": ["def test_hermite_normal_form_modulo_D():\n    m = DM([[2, 7, 17, 29, 41], [3, 11, 19, 31, 43], [5, 13, 23, 37, 47]], ZZ)\n    hnf = DM([[1, 0, 0], [0, 2, 1], [0, 0, 1]], ZZ)\n    assert _hermite_normal_form_modulo_D(m, ZZ(2)) == hnf\n\n    m = m.transpose()\n    hnf = DM([[37, 0, 19], [222, -6, 113], [48, 0, 25], [0, 2, 1], [0, 0, 1]], ZZ)\n    raises(DMShapeError, lambda: _hermite_normal_form_modulo_D(m, ZZ(96)))\n\n    m = DM([[8, 28, 68, 116, 164], [3, 11, 19, 31, 43], [5, 13, 23, 37, 47]], ZZ)\n    hnf = DM([[4, 0, 0], [0, 2, 1], [0, 0, 1]], ZZ)\n    assert _hermite_normal_form_modulo_D(m, ZZ(8)) == hnf\n\n    m = DM([[10, 8, 6, 30, 2], [45, 36, 27, 18, 9], [5, 4, 3, 2, 1]], ZZ)\n    hnf = DM([[26, 2], [0, 9], [0, 1]], ZZ)\n    raises(DMDomainError, lambda: _hermite_normal_form_modulo_D(m, ZZ(1)))\n\n    m = DM([[2, 7], [0, 0], [0, 0]], ZZ)\n    hnf = DM([[1], [0], [0]], ZZ)\n    raises(DMDomainError, lambda: _hermite_normal_form_modulo_D(m, ZZ(1)))\n\n    m = DM([[-2, 1], [0, 1]], ZZ)\n    hnf = DM([[2, 1], [0, 1]], ZZ)\n    raises(DMDomainError,"], "sample_885": ["def test_interval_real_not_int():\n    \"\"\"Check that the \"real_not_int\" type in the Interval constraint does not allow\n    integers.\"\"\"\n    constraint = Interval(\"real_not_int\", 0, 1, closed=\"both\")\n    assert not constraint.is_satisfied_by(1)\n    assert constraint.is_satisfied_by(1.0)\n"], "sample_954": ["def test_seealso(app, status, warning):\n    app.build()\n    content = (app.outdir / 'python.1').read_text()\n    assert 'SEE ALSO\\n' in content\n    assert 'This is a seealso\\n' in content\n"], "sample_321": ["    def _get_GET_csrf_cookie_request(self, cookie=None):\n        \"\"\"The cookie argument defaults to the valid test cookie.\"\"\"\n        if cookie is None:\n            cookie = self._csrf_id_cookie\n        req = TestingHttpRequest()\n        req.COOKIES[settings.CSRF_COOKIE_NAME] = cookie\n        return req\n"], "sample_796": ["def test_huber_alpha():\n    # Test that the alpha parameter affects the coefficients\n    X, y = make_regression_with_outliers()\n    huber_alpha_0 = HuberRegressor(fit_intercept=True, alpha=0.0)\n    huber_alpha_0.fit(X, y)\n    huber_alpha_1 = HuberRegressor(fit_intercept=True, alpha=0.1)\n    huber_alpha_1.fit(X, y)\n    assert_array_almost_equal(huber_alpha_0.coef_, huber_alpha_1.coef_, 1)\n\n    # Test that the alpha parameter affects the coefficients when fit_intercept is False\n    huber_alpha_0 = HuberRegressor(fit_intercept=False, alpha=0.0)\n    huber_alpha_0.fit(X, y)\n    huber_alpha_1 = HuberRegressor(fit_intercept=False, alpha=0.1)\n    huber_alpha_1.fit(X, y)\n    assert_array_almost_equal(huber_alpha_0.coef_, huber_alpha_1.coef_, 1)\n\n    # Test that the alpha parameter affects the coefficients when epsilon is large\n    huber_alpha_0 = HuberRegressor(fit_intercept=True, epsilon=1e3, alpha=0.0)\n    huber_alpha_0.fit(X, y)\n    huber_alpha_1 = HuberRegressor(fit_intercept=True, epsilon=1e3, alpha=0.1)\n    huber_alpha_1.fit(X, y)\n    assert_array_almost_equal(huber_alpha_0.coef_, huber_alpha_1.coef_, 1)\n"], "sample_217": ["def test_media_property_overriding(self):\n    # A widget can override the media property of its parent\n    class MyWidget1(TextInput):\n        class Media:\n            css = {\n                'all': ('path/to/css1', '/path/to/css2')\n            }\n            js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')\n\n    class MyWidget4(TextInput):\n            return Media(css={'all': ('/some/path',)}, js=('/some/js',))\n        media = property(_media)\n\n    class MyWidget5(MyWidget4):\n            return Media(css={'all': ('/other/path',)}, js=('/other/js',))\n        media = property(_media)\n\n    w5 = MyWidget5()\n    self.assertEqual(\n        str(w5.media),\n        \"\"\"<link href=\"/other/path\" type=\"text/css\" media=\"all\" rel=\"stylesheet\">"], "sample_28": ["def test_card_list_slice_assignment(self):\n    \"\"\"\n    Assigning to a slice of a CardList should just assign new values to the\n    cards included in the slice.\n    \"\"\"\n\n    header = fits.Header([(\"A\", \"B\"), (\"C\", \"D\"), (\"E\", \"F\")])\n    cl = header.cards\n    cl[1:] = 1\n    assert cl[1] == 1\n    assert cl[2] == 1\n\n    # Though strings are iterable they should be treated as a scalar value\n    cl[1:] = \"GH\"\n    assert cl[1] == \"GH\"\n    assert cl[2] == \"GH\"\n\n    # Now assign via an iterable\n    cl[1:] = [\"H\", \"I\"]\n    assert cl[1] == \"H\"\n    assert cl[2] == \"I\"\n\n    cl = header.cards[\"A*\"]\n    cl[1:] = 1\n    assert cl[1] == 1\n    assert cl[2] == 1\n\n    # Though strings are iterable they should be treated as a scalar value\n    cl[1:] = \"GH\"\n    assert cl[1] == \"GH\"\n    assert cl[2] == \"GH\"\n\n    # Now assign via an iterable\n    cl[1:] = [\"H\", \"I\"]\n    assert cl[1] == \"H\"\n    assert cl[2] == \"I\"\n"], "sample_373": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n        with captured_stderr() as self.docutils_stderr:\n            self.response = self.client.get(reverse('django-admindocs-models-detail', args=['admin_docs', 'Person']))\n"], "sample_583": ["    def test_setitem(self):\n        original = np.arange(10)\n        wrapped = indexing.NumpyIndexingAdapter(original)\n        wrapped[B[:]] = 0\n        assert_array_equal(original, np.arange(10))\n        assert_array_equal(wrapped, np.zeros(10))\n"], "sample_762": ["def test_clone_transformer():\n    # Test that clone works for transformers\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.pipeline import Pipeline\n\n    scaler = StandardScaler()\n    new_scaler = clone(scaler)\n    assert scaler is not new_scaler\n    assert_equal(scaler.get_params(), new_scaler.get_params())\n\n    # Test that clone works for transformers with fit_transform\n    transformer = StandardScaler()\n    new_transformer = clone(transformer)\n    assert transformer is not new_transformer\n    assert_equal(transformer.get_params(), new_transformer.get_params())\n\n    # Test that clone works for transformers in a pipeline\n    pipeline = Pipeline([('scaler', StandardScaler())])\n    new_pipeline = clone(pipeline)\n    assert pipeline is not new_pipeline\n    assert_equal(pipeline.get_params(), new_pipeline.get_params())\n"], "sample_296": ["def test_max_cookie_length_with_empty_messages(self):\n    \"\"\"\n    If the data exceeds what is allowed in a cookie, empty messages are removed before saving (and returned by the ``update`` method).\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # When storing as a cookie, the cookie has constant overhead of approx\n    # 54 chars, and each message has a constant overhead of about 37 chars\n    # and a variable overhead of zero in the best case. We aim for a message\n    # size which will fit 4 messages into the cookie, but not 5.\n    # See also FallbackTest.test_session_fallback\n    msg_size = int((CookieStorage.max_cookie_size - 54) / 4.5 - 37)\n    first_msg = None\n    # Generate the same (tested) content every time that does not get run\n    # through zlib compression.\n    random.seed(42)\n    for i in range(5):\n        msg = get_random_string(msg_size)\n        storage.add(constants.INFO, msg)\n        if i == 0:\n            first_msg = msg\n    # Add some empty messages\n    for _ in range(5):\n        storage.add(constants.INFO, '')\n    unstored_messages = storage.update(response)\n\n    cookie_storing = self.stored_messages_count(storage, response)\n    self.assertEqual(cookie_storing, 4)\n\n    self.assertEqual(len(unstored_messages), 1)\n    self.assertEqual(unstored_messages[0].message, first_msg)\n"], "sample_265": ["def test_templatetag_libraries_priority(self):\n    \"\"\"\n    Libraries passed in OPTIONS take precedence over discovered ones.\n    \"\"\"\n    engine = DjangoTemplates({\n        'DIRS': [],\n        'APP_DIRS': False,\n        'NAME': 'django',\n        'OPTIONS': {\n            'libraries': {\n                'alternate': 'django.templatetags.static',\n            },\n        },\n    })\n\n    self.assertEqual(\n        engine.engine.libraries['alternate'],\n        'django.templatetags.static',\n    )\n    self.assertEqual(\n        engine.engine.libraries['static'],\n        'django.templatetags.static',\n    )\n"], "sample_399": ["def test_aggregate_subquery_annotation_values_list(self):\n    \"\"\"\n    Subquery annotations and external aliases are excluded from the GROUP BY if\n    they are not selected.\n    \"\"\"\n    books_qs = (\n        Book.objects.annotate(\n            first_author_the_same_age=Subquery(\n                Author.objects.filter(\n                    age=OuterRef(\"contact__friends__age\"),\n                )\n                .order_by(\"age\")\n                .values(\"id\")[:1],\n            )\n        )\n        .filter(\n            publisher=self.p1,\n            first_author_the_same_age__isnull=False,\n        )\n        .annotate(\n            min_age=Min(\"contact__friends__age\"),\n        )\n        .values(\"name\", \"min_age\")\n        .order_by(\"name\")\n    )\n    self.assertEqual(\n        list(books_qs),\n        [\n            {\"name\": \"Practical Django Projects\", \"min_age\": 34},\n            {\n                \"name\": (\n                    \"The Definitive Guide to Django: Web Development Done Right\"\n                ),\n                \"min_age\": 29,\n            },\n        ],\n    )\n\n    books_qs = (\n        Book.objects.annotate(\n            first_author_the_same_age=Subquery(\n                Author.objects.filter(\n                    age=OuterRef(\"contact__friends__age\"),\n                )\n                .order_by(\"age\")\n                .values(\"id\")[:1],\n            )\n        )\n        .filter(\n            publisher=self.p1,\n            first_author_the_same_age__isnull=False,\n        )\n        .annotate(\n            min_age=Min(\"contact__friends__age\"),\n        )\n        .values_list(\"name\", \"min_age\")\n        .order_by(\"name\")\n    )\n    self.assertEqual(\n        list(books_qs),\n        [\n            (\"Practical Django Projects\", 34),\n            (\n                \"The Definitive Guide to Django: Web Development Done Right\",\n                29,\n            ),\n        ],\n    )\n\n    books_qs = (\n        Book.objects.annotate(\n            first_author_the_same_age=Subquery(\n                Author.objects.filter(\n                    age=OuterRef(\"contact__friends__age\"),\n                )\n                .order_by(\"age\")\n                .values(\"id\")[:1],\n            )\n        )\n        .filter(\n            publisher=self.p1,\n            first_author_the_same_age__isnull=False,\n        )\n        .annotate(\n            min_age=Min(\"contact__friends__age\"),\n        )\n        .values_list(\"name\", flat=True)\n        .order_by(\"name\")\n   "], "sample_515": ["def test_colorbar_alpha_array():\n    fig, ax = plt.subplots()\n    x = np.arange(1, 5).reshape(2, 2)/4\n    pc = ax.pcolormesh(x, alpha=x)\n    cb = fig.colorbar(pc, ax=ax)\n    assert cb.alpha is None\n    assert pc.get_alpha() is x\n    fig.draw_without_rendering()\n"], "sample_215": ["    def test_non_sensitive_request(self):\n        \"\"\"\n        Request info can bee seen in the default error reports for\n        non-sensitive requests.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n\n        with self.settings(DEBUG=False):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n"], "sample_79": ["    def test_invalid_arguments(self):\n        with self.assertRaises(ValueError):\n            pluralize('a')\n        with self.assertRaises(ValueError):\n            pluralize(1, 'a,b')\n        with self.assertRaises(ValueError):\n            pluralize(1, 'a,b,c')\n"], "sample_559": ["def test_secondary_axis():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], [1, 2, 3])\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.secondary_xaxis('top').set_xlabel('x2')\n    ax.secondary_yaxis('right').set_ylabel('y2')\n"], "sample_100": ["    def test_iter_modules_and_files_with_extra_files(self):\n        \"\"\"\n        When extra files are provided, they are included in the result.\n        \"\"\"\n        filename = self.temporary_file('test_file.py')\n        filename.touch()\n        extra_files = [str(filename)]\n        self.clear_autoreload_caches()\n        self.assertIn(filename, list(autoreload.iter_modules_and_files((), frozenset(extra_files))))\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().hits, 1)\n"], "sample_733": ["def test_hashingvectorizer_dtype():\n    # Non-regression test: HashingVectorizer used to ignore its \"dtype\" param.\n    v = HashingVectorizer(dtype=np.float32)\n    assert_equal(v.dtype, np.float32)\n\n    X = v.fit_transform(['hello world', 'hello hello']).toarray()\n    assert_equal(X.dtype, np.float32)\n    X2 = v.transform(['hello world', 'hello hello']).toarray()\n    assert_equal(X2.dtype, np.float32)\n"], "sample_937": ["def test_unparse_Starred():\n    source = \"a, *b, c\"\n    expected = \"a, *b, c\"\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].value) == expected\n"], "sample_340": ["def test_loading_squashed_multiple_replacements(self):\n    \"\"\"\n    Tests loading a squashed migration with multiple replacements.\n    \"\"\"\n    loader = MigrationLoader(connection)\n    recorder = MigrationRecorder(connection)\n    self.addCleanup(recorder.flush)\n\n    # Load with nothing applied: both migrations squashed.\n    loader.build_graph()\n    plan = set(loader.graph.forwards_plan(('migrations', '3_auto')))\n    plan = plan - loader.applied_migrations.keys()\n    expected_plan = {\n        ('migrations', '1_auto'),\n        ('migrations', '2_auto'),\n        ('migrations', '3_auto'),\n    }\n    self.assertEqual(plan, expected_plan)\n\n    # Fake-apply a few from migrations: unsquashes migration in migrations.\n    self.record_applied(recorder, 'migrations', '1_auto')\n    loader.build_graph()\n    plan = set(loader.graph.forwards_plan(('migrations', '3_auto')))\n    plan = plan - loader.applied_migrations.keys()\n    expected_plan = {\n        ('migrations', '2_auto'),\n        ('migrations', '3_auto'),\n    }\n    self.assertEqual(plan, expected_plan)\n\n    # Fake-apply one from migrations: unsquashes migration in migrations too.\n    self.record_applied(recorder, 'migrations', '2_auto')\n    loader.build_graph()\n    plan = set(loader.graph.forwards_plan(('migrations', '3_auto')))\n    plan = plan - loader.applied_migrations.keys()\n    expected_plan = {\n        ('migrations', '3_auto'),\n    }\n    self.assertEqual(plan, expected_plan)\n"], "sample_1098": ["def test_hyper_nseries():\n    from sympy import unpolarify\n    a1, a2, b1, b2 = symbols('a1 a2 b1 b2')\n    assert hyper((1,2), (1,2,3), x**2)._eval_nseries(x, 7, None) == 1 + x**2/3 + x**4/24 + x**6/360 + O(x**7)\n    assert hyper((a1, a2), (b1, b2), x)._eval_nseries(z, 7, None) == hyper((a1, a2), (b1, b2), x) + O(z**7)\n    assert hyper((1,2), (1,2,3), unpolarify(x**2))._eval_nseries(x, 7, None) == 1 + x**2/3 + x**4/24 + x**6/360 + O(x**7)\n    assert hyper((a1, a2), (b1, b2), unpolarify(x))._eval_nseries(z, 7, None) == hyper((a1, a2), (b1, b2), x) + O(z**7)\n"], "sample_801": ["def test_repr_with_custom_tags():\n    # Test that the repr of an estimator with custom tags is correctly rendered\n    class CustomEstimator(BaseEstimator):\n            return {'multioutput': True, 'poor_score': True}\n\n    estimator = CustomEstimator()\n    expected = \"\"\""], "sample_192": ["    def test_clean_method_called(self):\n        \"\"\"FormSets have a clean() hook for doing extra validation that isn't tied\n        to any form. It follows the same pattern as the clean() hook on Forms.\n        \"\"\"\n        # Start out with a some duplicate data.\n        data = {\n            'drinks-TOTAL_FORMS': '2',  # the number of forms rendered\n            'drinks-INITIAL_FORMS': '0',  # the number of forms with initial data\n            'drinks-MIN_NUM_FORMS': '0',  # min number of forms\n            'drinks-MAX_NUM_FORMS': '0',  # max number of forms\n            'drinks-0-name': 'Gin and Tonic',\n            'drinks-1-name': 'Gin and Tonic',\n        }\n        formset = FavoriteDrinksFormSet(data, prefix='drinks')\n        self.assertFalse(formset.is_valid())\n        # Any errors raised by formset.clean() are available via the\n        # formset.non_form_errors() method.\n        self.assertEqual(len(formset.non_form_errors()), 1)\n        # The valid case still works.\n        data['drinks-1-name'] = 'Bloody Mary'\n        formset = FavoriteDrinksFormSet(data, prefix='drinks')\n        self.assertTrue(formset.is_valid())\n        self.assertEqual(formset.non_form_errors(), [])\n"], "sample_878": ["def test_column_transformer_sparse_output():\n    \"\"\"Check that sparse_output_ is correctly set when the output of a\n    transformer is sparse.\"\"\"\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    col_trans = ColumnTransformer(\n        [(\"trans1\", Trans(), [0]), (\"trans2\", SparseMatrixTrans(), 1)],\n        sparse_threshold=0.8,\n    )\n    col_trans.fit(X_array)\n    X_trans = col_trans.transform(X_array)\n    assert sparse.issparse(X_trans)\n    assert col_trans.sparse_output_\n\n    col_trans = ColumnTransformer(\n        [(\"trans1\", Trans(), [0]), (\"trans2\", SparseMatrixTrans(), 1)],\n        sparse_threshold=0.1,\n    )\n    col_trans.fit(X_array)\n    X_trans = col_trans.transform(X_array)\n    assert not sparse.issparse(X_trans)\n    assert not col_trans.sparse_output_\n\n    col_trans = ColumnTransformer(\n        [(\"trans1\", Trans(), [0]), (\"trans2\", SparseMatrixTrans(), 1)],\n        sparse_threshold=0.8,\n    )\n    col_trans.fit(X_array)\n    X_trans = col_trans.transform(X_array)\n    assert sparse.issparse(X_trans)\n    assert col_trans.sparse_output_\n\n    col_trans = ColumnTransformer(\n        [(\"trans1\", Trans(), [0]), (\"trans2\", SparseMatrixTrans(), 1)],\n        sparse_threshold=0.1,\n    )\n    col_trans.fit(X_array)\n    X_trans = col_trans.transform(X_array)\n    assert not sparse.issparse(X_trans)\n    assert not col_trans.sparse_output_\n\n    col_trans = ColumnTransformer(\n        [(\"trans1\", Trans(), [0]), (\"trans2\", SparseMatrixTrans(), 1)],\n        sparse_threshold=0.8,\n    )\n    col_trans.fit(X_array)\n    X_trans = col_trans.transform(X_array)\n    assert sparse.issparse(X_trans)\n    assert col_trans.sparse_output_\n\n    col_trans = ColumnTransformer(\n        [(\"trans1\", Trans(), [0]), (\"trans2\", SparseMatrixTrans(), 1)],\n        sparse_threshold=0.1,\n    )\n    col_trans.fit(X_array)\n    X_trans = col_trans.transform(X_array)\n    assert not sparse.issparse(X_trans)\n    assert not col_trans.sparse_output_\n"], "sample_33": ["def test_ordered_descriptor_container():\n    class TestDescriptor(OrderedDescriptor):\n        _class_attribute_ = '_test_descriptors'\n\n    class TestClass(metaclass=OrderedDescriptorContainer):\n        a = TestDescriptor()\n        b = TestDescriptor()\n\n    assert TestClass._test_descriptors == OrderedDict([('a', TestDescriptor()), ('b', TestDescriptor())])\n\n    class SubClass(TestClass):\n        c = TestDescriptor()\n\n    assert SubClass._test_descriptors == OrderedDict([('c', TestDescriptor())])\n\n    class SubSubClass(SubClass):\n        _inherit_descriptors_ = (TestDescriptor,)\n        d = TestDescriptor()\n\n    assert SubSubClass._test_descriptors == OrderedDict([('a', TestDescriptor()), ('b', TestDescriptor()), ('d', TestDescriptor())])\n"], "sample_787": ["def test_precision_recall_f1_score_multilabel_3():\n    # Test precision_recall_f1_score on a crafted multilabel example 3\n    # Third crafted example\n    y_true = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 1]])\n    y_pred = np.array([[0, 1, 0, 0], [0, 0, 0, 1], [1, 0, 1, 0]])\n\n    # tp = [ 0.  1.  0.  0.]\n    # fp = [ 1.  0.  0.  2.]\n    # fn = [ 1.  1.  1.  0.]\n\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred,\n                                                 average=None)\n    assert_array_almost_equal(p, [0.0, 1.0, 0.0, 0.0], 2)\n    assert_array_almost_equal(r, [0.0, 0.5, 0.0, 0.0], 2)\n    assert_array_almost_equal(f, [0.0, 0.66, 0.0, 0.0], 2)\n    assert_array_almost_equal(s, [1, 2, 1, 0], 2)\n\n    f2 = fbeta_score(y_true, y_pred, beta=2, average=None)\n    support = s\n    assert_array_almost_equal(f2, [0, 0.55, 0, 0], 2)\n\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred,\n                                                 average=\"micro\")\n    assert_almost_equal(p, 0.25)\n    assert_almost_equal(r, 0.25)\n    assert_almost_equal(f, 2 * 0.25 * 0.25 / 0.5)\n    assert_equal(s, None)\n    assert_almost_equal(fbeta_score(y_true, y_pred, beta=2,\n                                    average=\"micro\"),\n                        (1 + 4) * p * r / (4 * p + r))\n\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred,\n                                                "], "sample_881": ["def test_top_k_accuracy_score_multiclass():\n    # Test top-k accuracy score for multiclass classification\n    y_true = np.array([0, 1, 2, 2])\n    y_score = np.array(\n        [\n            [0.4, 0.3, 0.2, 0.1],\n            [0.1, 0.4, 0.3, 0.2],\n            [0.2, 0.1, 0.4, 0.3],\n            [0.3, 0.2, 0.1, 0.4],\n        ]\n    )\n    score = top_k_accuracy_score(y_true, y_score, k=2)\n    assert score == pytest.approx(0.75)\n\n    y_true = np.array([0, 1, 2, 2])\n    y_score = np.array(\n        [\n            [0.4, 0.3, 0.2, 0.1],\n            [0.1, 0.4, 0.3, 0.2],\n            [0.2, 0.1, 0.4, 0.3],\n            [0.3, 0.2, 0.1, 0.4],\n        ]\n    )\n    score = top_k_accuracy_score(y_true, y_score, k=3)\n    assert score == pytest.approx(1.0)\n\n    y_true = np.array([0, 1, 2, 2])\n    y_score = np.array(\n        [\n            [0.4, 0.3, 0.2, 0.1],\n            [0.1, 0.4, 0.3, 0.2],\n            [0.2, 0.1, 0.4, 0.3],\n            [0.3, 0.2, 0.1, 0.4],\n        ]\n    )\n    score = top_k_accuracy_score(y_true, y_score, k=4)\n    assert score == pytest.approx(1.0)\n\n    y_true = np.array([0, 1, 2, 2])\n    y_score = np.array(\n        [\n            [0.4, 0.3, 0.2, 0.1],\n            ["], "sample_62": ["    def setUp(self):\n        self.site = admin.AdminSite()\n"], "sample_667": ["def test_getbasetemp_custom_removes_old_symlink(testdir):\n    \"\"\"Test that getbasetemp removes old symlinked basetemp directory\"\"\"\n    mytemp = testdir.tmpdir.join(\"xyz\")\n    p = testdir.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    testdir.runpytest(p, \"--basetemp=%s\" % mytemp)\n    mytemp.check()\n    mytemp.ensure(\"hello\")\n\n    # create a symlink to the basetemp directory\n    linktemp = testdir.tmpdir.join(\"symlinktemp\")\n    attempt_symlink_to(linktemp, str(mytemp))\n\n    testdir.runpytest(p, \"--basetemp=%s\" % linktemp)\n    mytemp.check()\n    assert not mytemp.join(\"hello\").check()\n"], "sample_427": ["    def test_custom_renderer(self):\n        \"\"\"\n        A custom renderer passed to a formset_factory() is passed to all forms\n        and ErrorList.\n        \"\"\"\n        from django.forms.renderers import Jinja2\n\n        renderer = Jinja2()\n        data = {\n            \"choices-TOTAL_FORMS\": \"2\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Zero\",\n            \"choices-0-votes\": \"\",\n            \"choices-1-choice\": \"One\",\n            \"choices-1-votes\": \"\",\n        }\n        ChoiceFormSet = formset_factory(Choice, renderer=renderer)\n        formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertEqual(formset.renderer, renderer)\n        self.assertEqual(formset.forms[0].renderer, renderer)\n        self.assertEqual(formset.management_form.renderer, renderer)\n        self.assertEqual(formset.non_form_errors().renderer, renderer)\n        self.assertEqual(formset.empty_form.renderer, renderer)\n"], "sample_119": ["def test_annotation(self):\n    query = Query(Author)\n    where = query.build_where(Q(num__gt=F('id')))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertIsInstance(lookup.rhs, SimpleCol)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertEqual(lookup.rhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('num'))\n\n    query = Query(Author)\n    where = query.build_where(Q(num__gt=F('id') + 1))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertIsInstance(lookup.rhs, SimpleCol)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertEqual(lookup.rhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n\n    query = Query(Author)\n    where = query.build_where(Q(num__gt=F('id') + F('id')))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertIsInstance(lookup.rhs, SimpleCol)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertEqual(lookup.rhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n\n    query = Query(Author)\n    where = query.build_where(Q(num__gt=F('id') + F('id') + 1))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertIsInstance(lookup.rhs, SimpleCol)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertEqual(lookup.rhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n"], "sample_379": ["def test_mark_safe_mark_safe_twice(self):\n    \"\"\"\n    mark_safe can be called multiple times on the same string.\n    \"\"\"\n    s = mark_safe('a&b')\n    s = mark_safe(s)\n    self.assertIsInstance(s, SafeData)\n    self.assertRenderEqual('{{ s }}', 'a&b', s=s)\n"], "sample_901": ["def test_k_means_init_callable():\n    # Test that a callable init function is properly called\n        return np.array([[0, 0], [1, 1]])\n\n    km = KMeans(init=test_init, n_clusters=2, random_state=42)\n    km.fit(X)\n    _check_fitted_model(km)\n"], "sample_557": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect((1, 2, 3))\n    ax2.set_box_aspect((2, 1, 1))\n"], "sample_412": ["def test_avoid_wrapping(self):\n    items = (\n        (\"Hello, world!\", \"Hello, world!\"),\n        (\"Hello,\\nworld!\", \"Hello,\\nworld!\"),\n        (\"Hello,\\r\\nworld!\", \"Hello,\\r\\nworld!\"),\n        (\"Hello,\\tworld!\", \"Hello,\\tworld!\"),\n        (\"Hello,\\vworld!\", \"Hello,\\vworld!\"),\n        (\"Hello,\\fworld!\", \"Hello,\\fworld!\"),\n        (\"Hello,\\bworld!\", \"Hello,\\bworld!\"),\n        (\"Hello,\\fworld!\", \"Hello,\\fworld!\"),\n        (\"Hello, world!\\nHello, world!\", \"Hello, world!\\nHello, world!\"),\n        (\"Hello, world!\\r\\nHello, world!\", \"Hello, world!\\r\\nHello, world!\"),\n        (\"Hello, world!\\tHello, world!\", \"Hello, world!\\tHello, world!\"),\n        (\"Hello, world!\\vHello, world!\", \"Hello, world!\\vHello, world!\"),\n        (\"Hello, world!\\fwHello, world!\", \"Hello, world!\\fwHello, world!\"),\n        (\"Hello, world!\\bHello, world!\", \"Hello, world!\\bHello, world!\"),\n        (\"Hello, world!\\fHello, world!\", \"Hello, world!\\fHello, world!\"),\n    )\n    for value, output in items:\n        with self.subTest(value=value, output=output):\n            self.check_output(avoid_wrapping, value, output)\n            self.check_output(avoid_wrapping, lazystr(value), output)\n"], "sample_151": ["def test_rename_field_with_db_column(self):\n    \"\"\"\n    RenameField is used if a field is renamed and db_column equal to the\n    old field's column is added.\n    \"\"\"\n    before = [\n        ModelState('app', 'Foo', [\n            ('id', models.AutoField(primary_key=True)),\n            ('field', models.IntegerField()),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'Foo', [\n            ('id', models.AutoField(primary_key=True)),\n            ('renamed_field', models.IntegerField(db_column='field')),\n        ]),\n    ]\n    changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename': True}))\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RenameField', 'AlterField'])\n    self.assertOperationAttributes(\n        changes, 'app', 0, 0, model_name='foo', old_name='field', new_name='renamed_field',\n    )\n    self.assertOperationAttributes(changes, 'app', 0, 1, model_name='foo', name='renamed_field')\n    self.assertEqual(changes['app'][0].operations[-1].field.deconstruct(), (\n        'renamed_field', 'django.db.models.IntegerField', [], {'db_column': 'field'},\n    ))\n"], "sample_496": ["    def tearDown(self):\n        self.remove_settings('settings.py')\n"], "sample_284": ["    def setUp(self):\n        super().setUp()\n        self._temp_dir = temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, 'test'))\n        self.addCleanup(shutil.rmtree, temp_dir)\n"], "sample_789": ["def test_multiclass_adaboost_proba():\n    # Test predict_proba robustness for multi-class input.\n    # In response to issue #7501\n    # https://github.com/scikit-learn/scikit-learn/issues/7501\n    y_t = np.array([0, 1, 2, 0, 1, 2])\n    clf = AdaBoostClassifier().fit(X, y_t)\n    assert_array_almost_equal(clf.predict_proba(X), np.ones((len(X), 3)))\n"], "sample_249": ["    def test_serialize_db_to_string_large_data(self):\n        # serialize_db_to_string() handles large amounts of data.\n        for i in range(1000):\n            Object.objects.create(obj_ref=ObjectReference.objects.create(obj=Object.objects.create()))\n        with mock.patch('django.db.migrations.loader.MigrationLoader') as loader:\n            # serialize_db_to_string() serializes only migrated apps, so mark\n            # the backends app as migrated.\n            loader_instance = loader.return_value\n            loader_instance.migrated_apps = {'backends'}\n            data = connection.creation.serialize_db_to_string()\n        self.assertGreater(len(data), 1000)\n"], "sample_809": ["def test_mutual_info_regression_sparse():\n    # We generate sample from multivariate normal distribution, using\n    # transformation from initially uncorrelated variables. The zero\n    # variables after transformation is selected as the target vector,\n    # it has the strongest correlation with the variable 2, and\n    # the weakest correlation with the variable 1.\n    T = np.array([\n        [1, 0.5, 2, 1],\n        [0, 1, 0.1, 0.0],\n        [0, 0.1, 1, 0.1],\n        [0, 0.1, 0.1, 1]\n    ])\n    cov = T.dot(T.T)\n    mean = np.zeros(4)\n\n    rng = check_random_state(0)\n    Z = rng.multivariate_normal(mean, cov, size=1000)\n    X = Z[:, 1:]\n    y = Z[:, 0]\n\n    X_csr = csr_matrix(X)\n    mi = mutual_info_regression(X_csr, y, random_state=0)\n    mi_sparse = mutual_info_regression(X_csr, y, copy=False, random_state=0)\n\n    assert_array_equal(np.argsort(-mi), np.array([1, 2, 0]))\n    assert_array_equal(np.argsort(-mi_sparse), np.array([1, 2, 0]))\n    assert_array_equal(mi, mi_sparse)\n"], "sample_718": ["def test_check_estimators_pickle_sparse():\n    # check that estimators can be pickled, and once pickled give the same answer as before.\n    # Test that estimators can handle sparse data.\n    X, y = make_blobs(n_samples=30, centers=[[0, 0, 0], [1, 1, 1]],\n                      random_state=0, n_features=2, cluster_std=0.1)\n    X -= X.min()\n    if 'PowerTransformer' in type(LinearRegression).__name__:\n        # Box-Cox requires positive, non-zero data\n        X += 1\n    X = pairwise_estimator_convert_X(X, LinearRegression())\n    y = multioutput_estimator_convert_y_2d(LinearRegression(), y)\n    set_random_state(LinearRegression())\n    LinearRegression().fit(X, y)\n\n    result = dict()\n    for method in [\"predict\", \"transform\", \"decision_function\", \"predict_proba\"]:\n        if hasattr(LinearRegression(), method):\n            result[method] = getattr(LinearRegression(), method)(X)\n\n    # pickle and unpickle!\n    pickled_estimator = pickle.dumps(LinearRegression())\n    if LinearRegression().__module__.startswith('sklearn.'):\n        assert_true(b\"version\" in pickled_estimator)\n    unpickled_estimator = pickle.loads(pickled_estimator)\n\n    for method in result:\n        unpickled_result = getattr(unpickled_estimator, method)(X)\n        assert_allclose_dense_sparse(result[method], unpickled_result)\n\n    # Test that estimators can handle sparse data.\n    X_sparse = sparse.csr_matrix(X)\n    y_sparse = sparse.csr_matrix(y)\n    set_random_state(LinearRegression())\n    LinearRegression().fit(X_sparse, y_sparse)\n\n    result = dict()\n    for method in [\"predict\", \"transform\", \"decision_function\", \"predict_proba\"]:\n        if hasattr(LinearRegression(), method):\n            result[method] = getattr(LinearRegression(), method)(X_sparse)\n\n    # pickle and unpickle!\n    pickled_estimator = pickle.dumps(LinearRegression())\n    if LinearRegression().__module__.startswith('sklearn.'):\n        assert_true(b\"version\" in pickled_estimator)\n    unpickled_estimator = pickle.loads(pickled_estimator)\n\n    for method in result:\n        unpickled_result = getattr(unpickled_estimator, method)(X_sparse)\n        assert_allclose_dense_sparse(result[method], unpickled_result)\n"], "sample_477": ["def test_floatformat01(self):\n    output = self.engine.render_to_string(\"floatformat01\", {\"num\": 34.23234})\n    self.assertEqual(output, \"34.2\")\n"], "sample_745": ["def test_function_transformer_sparse_input():\n    X = sparse.csr_matrix(np.arange(10).reshape((5, 2)))\n    F = FunctionTransformer(np.log1p, accept_sparse=True)\n    assert_array_equal(F.transform(X), np.log1p(X.toarray()))\n"], "sample_1209": ["def test_prefix_latex():\n    assert kilo._latex(None) == r'\\text{k}'\n    assert kibi._latex(None) == r'\\text{Y}'\n    assert kibi._latex_repr == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\mathrm{Yi}'\n    assert kibi._latex(None) == r'\\"], "sample_374": ["    def setUpTestData(cls):\n        cls.author1 = Author.objects.create(name='Jane')\n        cls.author2 = Author.objects.create(name='Tom')\n        cls.author3 = Author.objects.create(name='Robert')\n        cls.book1 = Book.objects.create(title='Poems')\n        cls.book2 = Book.objects.create(title='Jane Eyre')\n        cls.book3 = Book.objects.create(title='Wuthering Heights')\n        cls.book4 = Book.objects.create(title='Sense and Sensibility')\n        cls.book1.authors.add(cls.author1, cls.author2, cls.author3)\n        cls.book2.authors.add(cls.author1)\n        cls.book3.authors.add(cls.author3)\n        cls.book4.authors.add(cls.author4)\n"], "sample_254": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n"], "sample_479": ["def test_create_model_add_constraint(self):\n    \"\"\"\n    AddConstraint should optimize into CreateModel.\n    \"\"\"\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                \"Foo\", [(\"name\", models.CharField(max_length=255))]\n            ),\n            migrations.AddConstraint(\"Foo\", models.CheckConstraint(check=models.Q(name=\"test\"))),\n        ],\n        [\n            migrations.CreateModel(\n                \"Foo\",\n                [(\"name\", models.CharField(max_length=255))],\n                options={\"constraints\": [models.CheckConstraint(check=models.Q(name=\"test\"))]},\n            ),\n        ],\n    )\n"], "sample_60": ["    def setUp(self):\n        self.site = AdminSite()\n"], "sample_837": ["def test_get_deps_info_with_import_error():\n    # Simulate an import error for a dependency\n    sys.modules['sklearn'] = None\n    deps_info = _get_deps_info()\n\n    assert 'sklearn' not in deps_info\n    assert deps_info['sklearn'] is None\n\n    # Restore the original state\n    del sys.modules['sklearn']\n"], "sample_868": ["def test_empty_input(metric_name):\n    # All clustering metrics should raise an error when given an empty input\n    if metric_name in SUPERVISED_METRICS:\n        metric = SUPERVISED_METRICS[metric_name]\n        with pytest.raises(ValueError):\n            metric([], [])\n        with pytest.raises(ValueError):\n            metric([0, 1], [])\n        with pytest.raises(ValueError):\n            metric([], [0, 1])\n    else:\n        metric = UNSUPERVISED_METRICS[metric_name]\n        X = np.random.randint(10, size=(0, 10))\n        with pytest.raises(ValueError):\n            metric(X, [])\n        with pytest.raises(ValueError):\n            metric([], [0, 1])\n"], "sample_728": ["def test_make_gaussian_quantiles():\n    X, y = make_gaussian_quantiles(n_samples=100, n_features=2,\n                                   n_classes=3, random_state=0)\n\n    assert_equal(X.shape, (100, 2), \"X shape mismatch\")\n    assert_equal(y.shape, (100,), \"y shape mismatch\")\n    assert_equal(np.unique(y).shape, (3,), \"Unexpected number of classes\")\n\n    # Check that roughly equal numbers of samples are in each class\n    assert_array_almost_equal(np.bincount(y) / len(y), [1.0 / 3] * 3,\n                             decimal=1, err_msg=\"Wrong number of samples \"\n                                                 \"per class\")\n\n    # Check that the classes are separated by nested concentric spheres\n    for i in range(3):\n        for j in range(i + 1, 3):\n            dist = np.linalg.norm(X[y == i] - X[y == j], axis=1)\n            assert_less(dist.min(), 1.0, \"Classes are not separated by \"\n                                          \"nested concentric spheres\")\n"], "sample_238": ["def test_aggregate_over_subquery_annotation(self):\n    \"\"\"\n    Subquery annotations are included in the GROUP BY if they are grouped against.\n    \"\"\"\n    subquery_qs = Book.objects.filter(\n        rating=OuterRef('rating')\n    ).values('rating')\n    book_qs = Book.objects.annotate(\n        subquery_rating=Subquery(subquery_qs),\n    ).annotate(count=Count('rating'))\n    self.assertEqual(book_qs.count(), Book.objects.count())\n"], "sample_799": ["def test_cross_validate_return_estimator():\n    X, y = make_classification(n_samples=30, random_state=0)\n    clf = SVC(kernel=\"linear\", random_state=0)\n    cv = KFold(n_splits=5)\n    scores = cross_validate(clf, X, y, cv=cv, return_estimator=True)\n    assert isinstance(scores['estimator'], list)\n    assert len(scores['estimator']) == 5\n    for est in scores['estimator']:\n        assert isinstance(est, SVC)\n"], "sample_436": ["    def test_suppressed_options(self):\n        \"\"\"runserver doesn't support --verbosity and --trackback options.\"\"\"\n        out, err = self.run_manage([\"runserver\", \"--help\"])\n        self.assertNotInOutput(out, \"--verbosity\")\n        self.assertNotInOutput(out, \"--trackback\")\n        self.assertOutput(out, \"--settings\")\n\n"], "sample_634": ["def test_expand_modules_single_file(self, files_or_modules, expected):\n    \"\"\"Test expand_modules with a single file\"\"\"\n    ignore_list, ignore_list_re = [], []\n    modules, errors = expand_modules(\n        files_or_modules,\n        ignore_list,\n        ignore_list_re,\n        get_global_option(self, \"ignore-paths\"),\n    )\n    modules.sort(key=lambda d: d[\"name\"])\n    assert modules == expected\n    assert not errors\n"], "sample_803": ["def test_coverage_error_multilabel():\n    # Test coverage error measure for multilabel classification task\n    y_true = np.array([[0, 1], [0, 1]])\n    y_score = np.array([[0, 1], [0, 1]])\n    assert_almost_equal(coverage_error(y_true, y_score), 1.)\n\n    y_true = np.array([[0, 1], [0, 1]])\n    y_score = np.array([[0, 1], [1, 0]])\n    assert_almost_equal(coverage_error(y_true, y_score), 1.)\n\n    y_true = np.array([[1, 0], [0, 1]])\n    y_score = np.array([[0, 1], [1, 0]])\n    assert_almost_equal(coverage_error(y_true, y_score), 1.)\n\n    y_true = np.array([[1, 0], [0, 1]])\n    y_score = np.array([[0.5, 0.5], [0.5, 0.5]])\n    assert_almost_equal(coverage_error(y_true, y_score), 1.)\n\n    # Test that coverage error is 1 when all labels are relevant\n    y_true = np.array([[1, 1, 1], [1, 1, 1]])\n    y_score = np.array([[0.5, 0.5, 0.5], [0.5, 0.5, 0.5]])\n    assert_almost_equal(coverage_error(y_true, y_score), 1.)\n\n    # Test that coverage error is 1 when all labels are irrelevant\n    y_true = np.array([[0, 0, 0], [0, 0, 0]])\n    y_score = np.array([[0.5, 0.5, 0.5], [0.5, 0.5, 0.5]])\n    assert_almost_equal(coverage_error(y_true, y_score), 1.)\n\n    # Test that coverage error is 0 when no labels are relevant\n    y_true = np.array([[0, 0, 0], [0, 0, 0]])\n    y_score = np.array([[0.5, 0.5, 0.5], [0.5, 0.5, 0.5]])\n    assert_almost_equal(coverage_error(y_true, y_score), 0"], "sample_867": ["def test_grid_search_pre_dispatch():\n    # Test that pre_dispatch is respected\n    X, y = make_classification(n_samples=100, n_features=4, random_state=0)\n    clf = LinearSVC(random_state=0)\n    param_grid = {'C': [0.1, 1.0]}\n    cv = KFold(n_splits=3)\n    grid_search = GridSearchCV(clf, param_grid, cv=cv, pre_dispatch=1)\n    grid_search.fit(X, y)\n    assert len(grid_search.cv_results_) == 2\n    assert len(grid_search.cv_results_['params']) == 2\n\n    grid_search = GridSearchCV(clf, param_grid, cv=cv, pre_dispatch=2)\n    grid_search.fit(X, y)\n    assert len(grid_search.cv_results_) == 2\n    assert len(grid_search.cv_results_['params']) == 2\n\n    grid_search = GridSearchCV(clf, param_grid, cv=cv, pre_dispatch='2*n_jobs')\n    grid_search.fit(X, y)\n    assert len(grid_search.cv_results_) == 2\n    assert len(grid_search.cv_results_['params']) == 2\n\n    grid_search = GridSearchCV(clf, param_grid, cv=cv, pre_dispatch='2*n_jobs')\n    grid_search.fit(X, y)\n    assert len(grid_search.cv_results_) == 2\n    assert len(grid_search.cv_results_['params']) == 2\n\n    grid_search = GridSearchCV(clf, param_grid, cv=cv, pre_dispatch='2*n_jobs')\n    grid_search.fit(X, y)\n    assert len(grid_search.cv_results_) == 2\n    assert len(grid_search.cv_results_['params']) == 2\n"], "sample_21": ["def test_read_write_err_specs(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3]))\n    t1.add_column(Column(name=\"b\", data=[4.0, 5.0, 6.0]))\n    t1.add_column(Column(name=\"c\", data=[7.0, 8.0, 9.0]))\n    t1.add_column(Column(name=\"d\", data=[10.0, 11.0, 12.0]))\n    t1.add_column(Column(name=\"e\", data=[13.0, 14.0, 15.0]))\n    t1.add_column(Column(name=\"f\", data=[16.0, 17.0, 18.0]))\n    t1.add_column(Column(name=\"g\", data=[19.0, 20.0, 21.0]))\n    t1.add_column(Column(name=\"h\", data=[22.0, 23.0, 24.0]))\n    t1.add_column(Column(name=\"i\", data=[25.0, 26.0, 27.0]))\n    t1.add_column(Column(name=\"j\", data=[28.0, 29.0, 30.0]))\n    t1.add_column(Column(name=\"k\", data=[31.0, 32.0, 33.0]))\n    t1.add_column(Column(name=\"l\", data=[34.0, 35.0, 36.0]))\n    t1.add_column(Column(name=\"m\", data=[37.0, 38.0, 39.0]))\n    t1.add_column(Column(name=\"n\", data=[40.0, 41.0, 42.0]))\n    t1.add_column(Column(name=\"o\", data=[43.0, 44.0, 45.0]))\n    t1.add_column(Column(name=\"p\", data=[46.0, 47.0, 48.0]))\n    t1.add_column(Column(name=\"q\", data=[49.0, 50.0, 51.0]))\n    t1.add_column(Column(name=\"r\", data=[52.0, 53.0, 54.0]))\n    t1.add_column(Column(name=\"s\", data=[55.0, 56.0"], "sample_248": ["def test_shell_with_ipython_installed(self, select):\n    select.return_value = ([sys.stdin], [], [])\n    with captured_stdout() as stdout:\n        call_command('shell', interface='ipython')\n    self.assertIn('IPython', stdout.getvalue())\n"], "sample_333": ["def test_boundfield_disabled(self):\n    class Person(Form):\n        first_name = CharField(initial='John', disabled=True)\n\n    form = Person()\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data, {'first_name': 'John'})\n\n    form = Person({'first_name': 'Jane'})\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data, {'first_name': 'John'})\n\n    form = Person({'first_name': 'Jane', 'initial-first_name': 'John'})\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data, {'first_name': 'John'})\n\n    form = Person({'first_name': 'Jane', 'initial-first_name': 'Jane'})\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data, {'first_name': 'Jane'})\n\n    form = Person({'first_name': 'Jane', 'initial-first_name': 'Jane', 'first_name': 'John'})\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data, {'first_name': 'John'})\n\n    form = Person({'first_name': 'Jane', 'initial-first_name': 'Jane', 'first_name': 'Jane'})\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data, {'first_name': 'Jane'})\n\n    form = Person({'first_name': 'Jane', 'initial-first_name': 'Jane', 'first_name': 'Jane', 'initial-first_name': 'John'})\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data, {'first_name': 'Jane'})\n\n    form = Person({'first_name': 'Jane', 'initial-first_name': 'Jane', 'first_name': 'Jane', 'initial-first_name': 'Jane'})\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data, {'first_name': 'Jane'})\n\n    form = Person({'first_name': 'Jane', 'initial-first_name': 'Jane', 'first_name': 'Jane', 'initial-first_name': 'Jane', 'first_name': 'John'})\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data, {'first_name': 'John'})\n\n    form = Person({'first_name': 'Jane', 'initial-first_name': 'Jane', 'first_name': 'Jane', 'initial-first_name': 'Jane', 'first_name': 'Jane'})\n    self.assertTrue(form.is_valid())\n    self.assertEqual(form.cleaned_data, {'first_name': 'Jane'})\n\n    form = Person({'first_name': 'Jane', 'initial-first_name': 'Jane"], "sample_390": ["def test_directory_index_template_translatable(self):\n    \"\"\"Test that the directory index template is translatable\"\"\"\n    response = self.client.get(\"/%s/\" % self.prefix)\n    self.assertIn(template_translatable, response.context)\n    self.assertEqual(response.context[template_translatable], \"Index of ./\")\n"], "sample_810": ["def test_pipeline_fit_transform_with_intermediate_fit_params_and_transform():\n    # tests that Pipeline passes fit_params to intermediate steps\n    # when fit_transform is invoked\n    pipe = Pipeline([('transf', TransfFitParams()), ('clf', FitParamT())])\n    pipe.fit_transform(X=None,\n                       y=None,\n                       transf__should_get_this=True,\n                       clf__should_succeed=True)\n    assert pipe.named_steps['transf'].fit_params['should_get_this']\n    assert pipe.named_steps['clf'].successful\n    assert 'should_succeed' not in pipe.named_steps['transf'].fit_params\n"], "sample_1122": ["def test_issue_15894():\n    f = Function('f', real=True)\n    x = Symbol('x', real=True)\n    eq = Derivative(Abs(f(x)), x)\n    assert eq.doit() == f(x).diff(x)*sign(f(x))\n"], "sample_245": ["    def test_no_default_ignore_enabled(self):\n        management.call_command('makemessages', locale=[LOCALE], verbosity=0, use_default_ignore_patterns=False)\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertMsgId('This literal should be included.', po_contents)\n            self.assertMsgId('This should be ignored.', po_contents)\n"], "sample_541": ["def test_Cursor(ax):\n    cursor = widgets.Cursor(ax, horizOn=True, vertOn=True)\n    assert cursor.visible\n    assert cursor.horizOn\n    assert cursor.vertOn\n    assert cursor.useblit is False\n\n    cursor.clear(mock_event(ax.figure.canvas, x=0, y=0))\n    assert cursor.background is None\n    cursor.update()\n    assert cursor.background is None\n\n    cursor.clear(mock_event(ax.figure.canvas, x=0, y=0))\n    cursor.background = ax.figure.canvas.copy_from_bbox(ax.bbox)\n    assert cursor.background is not None\n    cursor.update()\n    assert cursor.background is not None\n\n    cursor.clear(mock_event(ax.figure.canvas, x=0, y=0))\n    cursor.background = None\n    cursor.update()\n    assert cursor.background is None\n\n    cursor.clear(mock_event(ax.figure.canvas, x=0, y=0))\n    cursor.background = ax.figure.canvas.copy_from_bbox(ax.bbox)\n    cursor.lineh.set_visible(True)\n    cursor.linev.set_visible(True)\n    cursor.update()\n    assert cursor.background is not None\n    assert cursor.lineh.get_visible()\n    assert cursor.linev.get_visible()\n\n    cursor.clear(mock_event(ax.figure.canvas, x=0, y=0))\n    cursor.background = None\n    cursor.lineh.set_visible(False)\n    cursor.linev.set_visible(False)\n    cursor.update()\n    assert cursor.background is None\n    assert not cursor.lineh.get_visible()\n    assert not cursor.linev.get_visible()\n\n    cursor.clear(mock_event(ax.figure.canvas, x=0, y=0))\n    cursor.background = ax.figure.canvas.copy_from_bbox(ax.bbox)\n    cursor.lineh.set_visible(True)\n    cursor.linev.set_visible(False)\n    cursor.update()\n    assert cursor.background is not None\n    assert cursor.lineh.get_visible()\n    assert not cursor.linev.get_visible()\n\n    cursor.clear(mock_event(ax.figure.canvas, x=0, y=0))\n    cursor.background = None\n    cursor.lineh.set_visible(False)\n    cursor.linev.set_visible(True)\n    cursor.update()\n    assert cursor.background is None\n    assert not cursor.lineh.get_visible()\n    assert cursor.linev.get_visible()\n\n    cursor.clear(mock_event(ax.figure.canvas, x=0, y=0))\n    cursor.background = ax.figure.canvas.copy_from_bbox(ax.bbox)\n    cursor.lineh.set_visible(False)\n    cursor.linev.set_visible(False)\n"], "sample_181": ["def test_filtered_aggregate_on_related_field(self):\n    agg = Sum('book__pages', filter=Q(book__rating__gt=3))\n    qs = Author.objects.annotate(pages=agg).order_by('pk')\n    self.assertSequenceEqual([a.pages for a in qs], [447, None, 1047])\n"], "sample_564": ["def test_plot_surface_masked():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    x, y = np.meshgrid(np.arange(-2, 2, 0.25), np.arange(-2, 2, 0.25))\n    Z = np.ma.masked_less(x * y, 2)\n    ax.plot_surface(x, y, Z, cmap='viridis')\n    ax.set_xlim(-2, 2)\n    ax.set_ylim(-2, 2)\n    ax.set_zlim(-1, 1)\n"], "sample_643": ["def test_colorized_output_deprecated():\n    \"\"\"TODO remove in 3.0.\"\"\"\n    reporter = ColorizedTextReporter()\n    with warnings.catch_warnings(record=True) as cm:\n        warnings.simplefilter(\"always\")\n        reporter._get_decoration(\"C\")\n\n    assert len(cm) == 1\n    assert isinstance(cm[0].message, DeprecationWarning)\n\n"], "sample_1055": ["def test_encipher_decipher_atbash():\n    assert encipher_atbash(\"ABC\") == \"ZYX\"\n    assert encipher_atbash(\"ZYX\") == \"ABC\"\n    assert decipher_atbash(\"ABC\") == \"ZYX\"\n    assert decipher_atbash(\"ZYX\") == \"ABC\"\n    assert encipher_atbash(\"Hello, World!\") == \"Svool, Dliow!\"\n    assert decipher_atbash(\"Svool, Dliow!\") == \"Hello, World!\"\n"], "sample_1109": ["def test_issue_12345():\n    x, y = symbols('x,y')\n    assert floor(x).series(x, 0, 10) == floor(0)\n    assert ceiling(x).series(x, 0, 10) == ceiling(0)\n    assert floor(x).series(x, pi, 10) == 3\n    assert ceiling(x).series(x, pi, 10) == 4\n    assert floor(-x).series(x, 0, 10) == -1\n    assert ceiling(-x).series(x, 0, 10) == 0\n"], "sample_38": ["def test_sip_foc2pix():\n    \"\"\"\n    Test that sip_foc2pix returns the correct result when the input is a scalar.\n    \"\"\"\n    w = wcs.WCS(naxis=2)\n    w.sip = wcs.Sip(np.zeros((2, 2)), np.zeros((2, 2)), None, None, [1, 1])\n    result = w.sip_foc2pix(1, 1, 0)\n    assert_array_equal(result, [1, 1])\n    result = w.sip_foc2pix([1], [1], 0)\n    assert_array_equal(result, [[1, 1]])\n    result = w.sip_foc2pix([1, 2], [1, 2], 0)\n    assert_array_equal(result, [[1, 1], [2, 2]])\n"], "sample_708": ["def test_getstatementrange_with_syntaxerror_issue7_in_source() -> None:\n    source = Source(\"def x():\\n    pass\")\n    pytest.raises(SyntaxError, lambda: source.getstatementrange(1))\n"], "sample_1179": ["def test_Dict_printing():\n    d = Dict({1: 1 + x, 2: y*x})\n    assert str(d) == \"{1: x + 1, 2: x*y}\"\n    assert sstr(d) == \"{1: x + 1, 2: x*y}\"\n"], "sample_336": ["    def test_resolve_error_handler(self):\n        \"\"\"\n        Test that resolve_error_handler() returns the correct view for a given\n        status code.\n        \"\"\"\n        resolver = get_resolver('urlpatterns_reverse.urls')\n        self.assertEqual(resolver.resolve_error_handler(400), empty_view)\n        self.assertEqual(resolver.resolve_error_handler(403), empty_view)\n        self.assertEqual(resolver.resolve_error_handler(404), empty_view)\n        self.assertEqual(resolver.resolve_error_handler(500), empty_view)\n"], "sample_325": ["def test_boundfield_subwidgets(self):\n    class SomeForm(Form):\n        field = MultipleChoiceField(\n            choices=[('a', 'A'), ('b', 'B')],\n            widget=CheckboxSelectMultiple,\n        )\n\n    form = SomeForm(auto_id=False)\n    self.assertEqual(len(form['field'].subwidgets), 2)\n    self.assertEqual(form['field'].subwidgets[0].data['value'], 'a')\n    self.assertEqual(form['field'].subwidgets[0].data['label'], 'A')\n    self.assertEqual(form['field'].subwidgets[1].data['value'], 'b')\n    self.assertEqual(form['field'].subwidgets[1].data['label'], 'B')\n\n    form = SomeForm(auto_id='id_%s')\n    self.assertEqual(len(form['field'].subwidgets), 2)\n    self.assertEqual(form['field'].subwidgets[0].data['value'], 'a')\n    self.assertEqual(form['field'].subwidgets[0].data['label'], 'A')\n    self.assertEqual(form['field'].subwidgets[0].id_for_label, 'id_field_0')\n    self.assertEqual(form['field'].subwidgets[1].data['value'], 'b')\n    self.assertEqual(form['field'].subwidgets[1].data['label'], 'B')\n    self.assertEqual(form['field'].subwidgets[1].id_for_label, 'id_field_1')\n"], "sample_533": ["def test_contour_label_fontsize():\n    x, y = np.meshgrid(np.arange(0, 10), np.arange(0, 10))\n    z = np.max(np.dstack([abs(x), abs(y)]), 2)\n\n    fig, (ax1, ax2) = plt.subplots(ncols=2)\n    cs = ax1.contour(x, y, z)\n    cs_filled = ax2.contourf(x, y, z)\n    cs.clabel(fontsize='xx-large')\n    cs_filled.clabel(fontsize='xx-large')\n\n    for ax in fig.get_axes():\n        for label in ax.get_xticklabels():\n            label.set_ha('right')\n            label.set_rotation(30)\n\n    # Check that the font size of the labels is correct\n    assert all(label.get_fontsize() == 24 for label in cs.labelTexts)\n    assert all(label.get_fontsize() == 24 for label in cs_filled.labelTexts)\n"], "sample_558": ["def test_axesgrid_colorbar_log_smoketest_with_label_mode():\n    fig = plt.figure()\n    grid = AxesGrid(fig, 111,  # modified to be only subplot\n                    nrows_ncols=(1, 1),\n                    ngrids=1,\n                    label_mode=\"all\",\n                    cbar_location=\"top\",\n                    cbar_mode=\"single\",\n                    )\n\n    Z = 10000 * np.random.rand(10, 10)\n    im = grid[0].imshow(Z, interpolation=\"nearest\", norm=LogNorm())\n\n    grid.cbar_axes[0].colorbar(im)\n"], "sample_904": ["def test_productionlist_with_brackets(app):\n    text = (\".. productionlist:: P1\\n\"\n            \"   A: `A` [B]\\n\"\n            \"   B: `P1:B` [~P1:B]\\n\")\n    doctree = restructuredtext.parse(app, text)\n    refnodes = list(doctree.findall(pending_xref))\n    assert_node(refnodes[0], pending_xref, reftarget=\"A\")\n    assert_node(refnodes[1], pending_xref, reftarget=\"P1:A\")\n    assert_node(refnodes[2], pending_xref, reftarget=\"P1:B\")\n    assert_node(refnodes[3], pending_xref, reftarget=\"P1:B\")\n    assert_node(refnodes[0], [pending_xref, nodes.literal, \"A\"])\n    assert_node(refnodes[1], [pending_xref, nodes.literal, \"A\"])\n    assert_node(refnodes[2], [pending_xref, nodes.literal, \"P1:B\"])\n    assert_node(refnodes[3], [pending_xref, nodes.literal, \"B\"])\n\n    domain = app.env.get_domain(\"std\")\n    objects = list(domain.get_objects())\n    assert (\"A\", \"A\", \"token\", \"index\", \"grammar-token-P1-A\", -1) in objects\n    assert (\"B\", \"B\", \"token\", \"index\", \"grammar-token-P1-B\", -1) in objects\n    assert (\"P1:A\", \"P1:A\", \"token\", \"index\", \"grammar-token-P1-A\", -1) in objects\n    assert (\"P1:B\", \"P1:B\", \"token\", \"index\", \"grammar-token-P1-B\", -1) in objects\n"], "sample_651": ["    def test_matches(self) -> None:\n        rec = WarningsRecorder(_ispytest=True)\n        with rec:\n            warnings.warn(\"hello\", UserWarning)\n            assert rec.matches(rec[0])\n\n        with pytest.raises(AssertionError):\n            rec.matches(rec[0], match=\"world\")\n\n        rec.clear()\n        with pytest.raises(AssertionError):\n            rec.matches(rec[0])\n\n        rec.clear()\n        with pytest.raises(AssertionError):\n            rec.matches(rec[0], match=None)\n"], "sample_364": ["    def test_path_lookup_with_namespace(self):\n        match = resolve('/namespaced/extra/something/')\n        self.assertEqual(match.url_name, 'inner-extra')\n        self.assertEqual(match.route, 'namespaced/extra/<extra>/')\n        self.assertEqual(match.app_name, 'namespaced')\n"], "sample_743": ["def test_radius_neighbors_regressor_sparse():\n    # Test radius-based regression on sparse matrices\n    # Like the above, but with various types of sparse matrices\n    rng = np.random.RandomState(0)\n    X = 2 * rng.rand(40, 5) - 1\n    y = np.sqrt((X ** 2).sum(1))\n    y /= y.max()\n    y = np.vstack([y, y]).T\n\n    for sparsemat in SPARSE_TYPES:\n        knn = neighbors.RadiusNeighborsRegressor(n_neighbors=3,\n                                                 algorithm='auto')\n        knn.fit(sparsemat(X), y)\n\n        knn_pre = neighbors.RadiusNeighborsRegressor(n_neighbors=3,\n                                                     metric='precomputed')\n        knn_pre.fit(pairwise_distances(X, metric='euclidean'), y)\n\n        for sparsev in SPARSE_OR_DENSE:\n            X2 = sparsev(X)\n            assert_true(np.mean(knn.predict(X2).round() == y) > 0.95)\n\n            X2_pre = sparsev(pairwise_distances(X, metric='euclidean'))\n            if issparse(sparsev(X2_pre)):\n                assert_raises(ValueError, knn_pre.predict, X2_pre)\n            else:\n                assert_true(\n                    np.mean(knn_pre.predict(X2_pre).round() == y) > 0.95)\n"], "sample_1133": ["def test_hyperfocal_distance_invalid_input():\n    f, N, c = symbols('f, N, c')\n    raises(ValueError, lambda: hyperfocal_distance(f=-1, N=N, c=c))\n    raises(ValueError, lambda: hyperfocal_distance(f=f, N=-1, c=c))\n    raises(ValueError, lambda: hyperfocal_distance(f=f, N=N, c=-1))\n    raises(TypeError, lambda: hyperfocal_distance(f='a', N=N, c=c))\n    raises(TypeError, lambda: hyperfocal_distance(f=f, N='b', c=c))\n    raises(TypeError, lambda: hyperfocal_distance(f=f, N=N, c='d'))\n"], "sample_805": ["def test_mean_squared_log_error_at_zero():\n    assert_almost_equal(mean_squared_log_error([0.], [0.]), 0.00, 2)\n    assert_almost_equal(mean_squared_log_error([0.], [0.], squared=False), 0.00, 2)\n    assert_raises_regex(ValueError, \"Mean Squared Logarithmic Error cannot be \"\n                        \"used when targets contain negative values.\",\n                        mean_squared_log_error, [-1.], [-1.])\n    assert_raises_regex(ValueError, \"Mean Squared Logarithmic Error cannot be \"\n                        \"used when targets contain negative values.\",\n                        mean_squared_log_error, [1., 2., 3.], [1., -2., 3.])\n    assert_raises_regex(ValueError, \"Mean Squared Logarithmic Error cannot be \"\n                        \"used when targets contain negative values.\",\n                        mean_squared_log_error, [1., -2., 3.], [1., 2., 3.])\n"], "sample_326": ["def test_avoid_wrapping(self):\n    items = (\n        ('Hello, world!', 'Hello, world!'),\n        ('Hello, world!  Hello, world!', 'Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n    )\n    for value, output in items:\n        with self.subTest(value=value, output=output):\n            self.check_output(avoid_wrapping"], "sample_93": ["def test_window_expression(self):\n    vals = Publisher.objects.annotate(\n        avg_duration=Window(\n            Avg('duration'),\n            partition_by=Publisher.objects.values('name'),\n            order_by=Publisher.objects.values('name')\n        )\n    ).values('name', 'avg_duration')\n    self.assertEqual(\n        list(vals), [\n            {\n                'name': 'Apress',\n                'avg_duration': datetime.timedelta(days=1, hours=12)\n            },\n            {\n                'name': 'Morgan Kaufmann',\n                'avg_duration': datetime.timedelta(days=1, hours=12)\n            },\n            {\n                'name': 'Prentice Hall',\n                'avg_duration': datetime.timedelta(days=1, hours=12)\n            },\n            {\n                'name': 'Sams',\n                'avg_duration': datetime.timedelta(days=2)\n            },\n            {\n                'name': 'Jonno\\'s House of Books',\n                'avg_duration': None\n            }\n        ]\n    )\n\n    vals = Publisher.objects.annotate(\n        avg_duration=Window(\n            Avg('duration'),\n            partition_by=Publisher.objects.values('name'),\n            order_by=Publisher.objects.values('name')\n        )\n    ).values('avg_duration')\n    self.assertEqual(\n        list(vals), [\n            datetime.timedelta(days=1, hours=12),\n            datetime.timedelta(days=1, hours=12),\n            datetime.timedelta(days=1, hours=12),\n            datetime.timedelta(days=2),\n            None\n        ]\n    )\n\n    vals = Publisher.objects.annotate(\n        avg_duration=Window(\n            Avg('duration'),\n            partition_by=Publisher.objects.values('name'),\n            order_by=Publisher.objects.values('name')\n        )\n    ).values('name', 'avg_duration').order_by('avg_duration')\n    self.assertEqual(\n        list(vals), [\n            {\n                'name': 'Jonno\\'s House of Books',\n                'avg_duration': None\n            },\n            {\n                'name': 'Sams',\n                'avg_duration': datetime.timedelta(days=2)\n            },\n            {\n                'name': 'Apress',\n                'avg_duration': datetime.timedelta(days=1, hours=12)\n            },\n            {\n                'name': 'Morgan Kaufmann',\n                'avg_duration': datetime.timedelta(days=1, hours=12)\n            },\n            {\n                'name': 'Prentice Hall',\n                'avg_duration': datetime.timedelta(days=1, hours=12)\n            }\n        ]\n    )\n\n    vals = Publisher"], "sample_460": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(\n            username=\"super\", password=\"secret\", email=\"super@example.com\"\n        )\n        cls.s1 = Section.objects.create(name=\"Test section\")\n        cls.a1 = Article.objects.create(\n            content=\"<p>Middle content</p>\",\n            date=datetime.datetime(2008, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.a2 = Article.objects.create(\n            content=\"<p>Oldest content</p>\",\n            date=datetime.datetime(2000, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.a3 = Article.objects.create(\n            content=\"<p>Newest content</p>\",\n            date=datetime.datetime(2009, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.p1 = PrePopulatedPost.objects.create(\n            title=\"A Long Title\", published=True, slug=\"a-long-title\"\n        )\n"], "sample_844": ["def test_min_eps():\n    # Test that we check a minimum epsilon\n    msg = \"Specify an epsilon smaller than 0.15. Got 0.3.\"\n    centers = [[1, 1], [-1, -1], [1, -1]]\n    X, labels_true = make_blobs(n_samples=750, centers=centers,\n                                cluster_std=0.4, random_state=0)\n\n    # Compute OPTICS\n    clust = OPTICS(max_eps=5.0 * 0.03,\n                   cluster_method='dbscan',\n                   eps=0.3, min_samples=10)\n    assert_raise_message(ValueError, msg, clust.fit, X)\n\n    # Test that we check a minimum epsilon when cluster_method is 'xi'\n    msg = \"Specify an epsilon smaller than 0.15. Got 0.3.\"\n    clust = OPTICS(max_eps=5.0 * 0.03,\n                   cluster_method='xi',\n                   eps=0.3, min_samples=10)\n    assert_raise_message(ValueError, msg, clust.fit, X)\n"], "sample_528": ["def test_context_with_multiple_styles():\n    original_value = 'gray'\n    other_value = 'blue'\n    mpl.rcParams[PARAM] = original_value\n    with temp_style('test', DUMMY_SETTINGS):\n        with style.context(['test', 'default', {PARAM: other_value}]):\n            assert mpl.rcParams[PARAM] == other_value\n    assert mpl.rcParams[PARAM] == original_value\n"], "sample_216": ["def test_add_field_with_default_value(self):\n    \"\"\"#22030 - Adding a field with a default value should work.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, 'testapp', 0, 0, default='Ada Lovelace')\n"], "sample_104": ["    def setUp(self):\n        super().setUp()\n\n        temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, 'test'))\n        self._clear_filename = os.path.join(temp_dir, 'test', 'cleared.txt')\n        with open(self._clear_filename, 'w') as f:\n            f.write('to be deleted in one test')\n\n        self.patched_settings = self.settings(\n            STATICFILES_DIRS=settings.STATICFILES_DIRS + [temp_dir],\n        )\n        self.patched_settings.enable()\n        self.addCleanup(shutil.rmtree, temp_dir)\n        self._manifest_strict = storage.staticfiles_storage.manifest_strict\n"], "sample_1041": ["def test_matrix_derivative():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', n, n)\n    E = MatrixSymbol('E', m, n)\n    w = MatrixSymbol('w', n, 1)\n\n    dexpr = diff((D*w).T, w[p,0])\n\n    assert w[k, p].diff(w[k, p]) == 1\n    assert w[k, p].diff(w[0, 0]) == KroneckerDelta(0, k)*KroneckerDelta(0, p)\n    assert str(dexpr) == \"Sum(KroneckerDelta(_i_1, p)*D[k, _i_1].T, (_i_1, 0, n - 1))\"\n    assert str(dexpr.doit()) == 'Piecewise((D[k, p].T, (p >= 0) & (p <= n - 1)), (0, True))'\n    # TODO: bug with .dummy_eq( ), the previous 2 lines should be replaced by:\n    return  # stop eval\n    _i_1 = Dummy(\"_i_1\")\n    assert dexpr.dummy_eq(Sum(KroneckerDelta(_i_1, p)*D[k, _i_1].T, (_i_1, 0, n - 1)))\n    assert dexpr.doit().dummy_eq(Piecewise((D[k, p].T, (p >= 0) & (p <= n - 1)), (0, True)))\n\n    dexpr = diff((D*w).T, w[k,0])\n\n    assert w[k, p].diff(w[k, p]) == 1\n    assert w[k, p].diff(w[0, 0]) == KroneckerDelta(0, k)*KroneckerDelta(0, p)\n    assert str(dexpr) == \"Sum(KroneckerDelta(_i_1, k)*D[p, _i_1].T, (_i_1, 0, n - 1))\"\n    assert str(dexpr.doit()) == 'Piecewise((D[p, k].T, (k >= 0) & (k <= n - 1)), (0, True))'\n    # TODO: bug with"], "sample_54": ["    def test_file_from_buffer_with_content_type(self):\n        response = FileResponse(io.BytesIO(b'binary content'), content_type='text/plain')\n        self.assertEqual(response['Content-Type'], 'text/plain')\n        self.assertEqual(response['Content-Length'], '14')\n        self.assertFalse(response.has_header('Content-Disposition'))\n        self.assertEqual(list(response), [b'binary content'])\n"], "sample_845": ["def test_hashingvectorizer_dtype():\n    # Non-regression test: HashingVectorizer used to ignore its \"dtype\" param.\n    v = HashingVectorizer(dtype=np.float32)\n    assert v.dtype == np.float32\n\n    X = v.transform(['hello world', 'hello hello']).toarray()\n    assert X.dtype == np.float32\n\n    # check the ability to change the dtype\n    v = HashingVectorizer(dtype=np.float64)\n    X = v.transform(['hello world', 'hello hello']).toarray()\n    assert X.dtype == np.float64\n"], "sample_193": ["    def test_custom_manager_swappable(self):\n        \"\"\"\n        Tests making a ProjectState from unused models with custom managers\n        \"\"\"\n        new_apps = Apps(['migrations'])\n\n        class Food(models.Model):\n\n            food_mgr = FoodManager('a', 'b')\n            food_qs = FoodQuerySet.as_manager()\n            food_no_mgr = NoMigrationFoodManager('x', 'y')\n\n            class Meta:\n                app_label = \"migrations\"\n                apps = new_apps\n                swappable = 'TEST_SWAPPABLE_MODEL'\n\n        food_state = ModelState.from_model(Food)\n\n        # The default manager is used in migrations\n        self.assertEqual([name for name, mgr in food_state.managers], ['food_mgr'])\n        self.assertEqual(food_state.managers[0][1].args, ('a', 'b', 1, 2))\n"], "sample_517": ["def test_wrap_line_width():\n    fig, ax = plt.subplots()\n    text = fig.text(0.5, 0.5, 'This is a very long text that should be wrapped multiple times.', wrap=True)\n    fig.canvas.draw()\n    assert text._get_wrap_line_width() == 2.0\n"], "sample_1015": ["def test_ccode_PreIncrement_PostIncrement():\n    x = symbols('x')\n    assert ccode(x + 1) == 'x + 1'\n    assert ccode(x + 1) == 'x + 1'\n    assert ccode(x + 1 + 2) == 'x + 1 + 2'\n    assert ccode(x + 1 + 2 + 3) == 'x + 1 + 2 + 3'\n    assert ccode(x + 1 + 2 + 3 + 4) == 'x + 1 + 2 + 3 + 4'\n    assert ccode(x + 1 + 2 + 3 + 4 + 5) == 'x + 1 + 2 + 3 + 4 + 5'\n    assert ccode(x + 1 + 2 + 3 + 4 + 5 + 6) == 'x + 1 + 2 + 3 + 4 + 5 + 6'\n    assert ccode(x + 1 + 2 + 3 + 4 + 5 + 6 + 7) == 'x + 1 + 2 + 3 + 4 + 5 + 6 + 7'\n    assert ccode(x + 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8) == 'x + 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8'\n    assert ccode(x + 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9) == 'x + 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9'\n    assert ccode(x + 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10) == 'x + 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10'\n    assert ccode(x + 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 + 11) == 'x + 1 + "], "sample_231": ["    def test_non_sensitive_request(self):\n        \"\"\"\n        Request info can bee seen in the default error reports for non-sensitive requests.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n\n        with self.settings(DEBUG=False):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n"], "sample_256": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = '!' + UNUSABLE_PASSWORD_PREFIX + '!'\n        self.assertHTMLEqual(\n            widget.render('name', value, {'id': 'id_password'}),\n            \"\"\"\n            <div id=\"id_password\">\n                <strong>No password set.</strong>\n            </div>\n            \"\"\"\n        )\n"], "sample_417": ["    def test_floatformat03(self):\n        output = self.engine.render_to_string(\n            \"floatformat03\", {\"a\": 66666.666, \"b\": 66666.666}\n        )\n        self.assertEqual(output, \"66,667.00 66,667.67\")\n"], "sample_858": ["def test_transform_proba():\n    \"\"\"Check transform method of VotingClassifier on toy dataset.\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    X = np.array([[-1.1, -1.5], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n    y = np.array([1, 1, 2, 2])\n\n    eclf1 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft',\n        flatten_transform=False).fit(X, y)\n    eclf2 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft',\n        flatten_transform=True).fit(X, y)\n\n    probas1 = eclf1.transform(X)\n    probas2 = eclf2.transform(X)\n\n    assert_array_almost_equal(probas1, probas2)\n    assert_array_almost_equal(probas1,\n                              np.array([[[0.59790391, 0.40209609],\n                                         [0.57622162, 0.42377838],\n                                         [0.50728456, 0.49271544],\n                                         [0.40241774, 0.59758226]],\n                                        [[0.8, 0.2],\n                                         [0.8, 0.2],\n                                         [0.2, 0.8],\n                                         [0.3, 0.7]],\n                                        [[0.9985082, 0.0014918],\n                                         [0.99845843, 0.00154157],\n                                         [0., 1.],\n                                         [0., 1.]]]))\n"], "sample_1185": ["def test_decompogen_fails():\n    A = lambda x: x**2 + 2*x + 3\n    B = lambda x: 4*x**2 + 5*x + 6\n    assert decompogen(A(x*exp(x)), x) == [x**2 + 2*x + 3, x*exp(x)]\n    assert decompogen(A(B(x)), x) == [x**2 + 2*x + 3, 4*x**2 + 5*x + 6]\n    assert decompogen(A(1/x + 1/x**2), x) == [x**2 + 2*x + 3, 1/x + 1/x**2]\n    assert decompogen(A(1/x + 2/(x + 1)), x) == [x**2 + 2*x + 3, 1/x + 2/(x + 1)]\n"], "sample_699": ["    def test_allow_unicode(self, pytester: Pytester):\n        pytester.maketxtfile(\n            test_doc=\"\"\"\n            >>> b'12'.decode('ascii')\n            '12'\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n"], "sample_1081": ["def test_issue_17676():\n    assert factorint(2063**2 * 4127**1 * 4129**1) == {2063: 2, 4127: 1, 4129: 1}\n    assert factorint(2347**2 * 7039**1 * 7043**1) == {2347: 2, 7039: 1, 7043: 1}\n    assert factorint(2347**2 * 7039**1 * 7043**1, limit=2347) == {2347: 2, 7039: 1, 7043: 1}\n    assert factorint(2347**2 * 7039**1 * 7043**1, limit=2347, use_trial=False) == {2347: 2, 7039: 1, 7043: 1}\n    assert factorint(2347**2 * 7039**1 * 7043**1, limit=2347, use_rho=False) == {2347: 2, 7039: 1, 7043: 1}\n    assert factorint(2347**2 * 7039**1 * 7043**1, limit=2347, use_pm1=False) == {2347: 2, 7039: 1, 7043: 1}\n"], "sample_800": ["def test_check_estimators_pickle():\n    # check that we can pickle all estimators\n    check_estimators_pickle(\"estimator\", LogisticRegression())\n"], "sample_525": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect(.5)\n    ax2.set_box_aspect((2, 1, 1))\n    fig.tight_layout()\n    fig.draw_without_rendering()\n    xn = np.zeros(4)\n    yn = np.zeros(4)\n    for nn, ax in enumerate([ax1, ax2]):\n        yn[nn] = ax.xaxis.label.get_position()[1]\n        xn[nn] = ax.yaxis.label.get_position()[0]\n    np.testing.assert_allclose(xn[:2], xn[2:])\n    np.testing.assert_allclose(yn[::2], yn[1::2])\n"], "sample_729": ["def test_enet_path_return_models():\n    # Test that lasso_path with models output gives the same result\n\n    # Some toy data\n    X = np.array([[1, 2, 3.1], [2.3, 5.4, 4.3]]).T\n    y = np.array([1, 2, 3.1])\n    alphas = [5., 1., .5]\n\n    # Use lars_path and lasso_path(models output) to compute the same path\n    alphas_lars, active, coef_path_lars = lars_path(X, y, method='lasso')\n    coef_path_cont_lars = interpolate.interp1d(alphas_lars[::-1],\n                                               coef_path_lars[:, ::-1])\n    alphas_lasso2, coefs_lasso2, _ = lasso_path(X, y, alphas=alphas,\n                                                 return_models=True)\n    coef_path_cont_lasso = interpolate.interp1d(alphas_lasso2[::-1],\n                                                coefs_lasso2[:, ::-1])\n\n    assert_array_almost_equal(\n        coef_path_cont_lasso(alphas), coef_path_cont_lars(alphas),\n        decimal=1)\n"], "sample_107": ["    def test_sensitive_variables_decorator(self):\n        \"\"\"\n        The sensitive_variables decorator works with function calls.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(sensitive_variables_function_caller)\n            self.verify_unsafe_email(sensitive_variables_function_caller)\n\n        with self.settings(DEBUG=False):\n            self.verify_safe_response(sensitive_variables_function_caller, check_for_POST_params=False)\n            self.verify_safe_email(sensitive_variables_function_caller, check_for_POST_params=False)\n"], "sample_949": ["def test_definition_list(app, status, warning):\n    app.build()\n    content = (app.outdir / 'python.1').read_text()\n    assert ('.TP\\n'\n            'term1\\n'\n            '.TP\\n'\n            'term2 (\\\\fBstronged partially\\\\fP)\\n' in content)\n    assert 'Footnotes' not in content\n"], "sample_497": ["    def test_get_remove_overlapping_locs(self):\n        fig, ax = plt.subplots()\n        ax.xaxis.remove_overlapping_locs = True\n        assert ax.xaxis.get_remove_overlapping_locs() is True\n        ax.xaxis.remove_overlapping_locs = False\n        assert ax.xaxis.get_remove_overlapping_locs() is False\n        ax.xaxis.remove_overlapping_locs = None\n        assert ax.xaxis.get_remove_overlapping_locs() is None\n"], "sample_157": ["    def test_serialize_db_to_string(self):\n        # serialize_db_to_string() serializes all data in the database into a JSON string.\n        data = \"\"\"\n        [\n            {\n                \"model\": \"backends.object\",\n                \"pk\": 1,\n                \"fields\": {\"obj_ref\": 1, \"related_objects\": []}\n            },\n            {\n                \"model\": \"backends.objectreference\",\n                \"pk\": 1,\n                \"fields\": {\"obj\": 1}\n            }\n        ]\n        \"\"\"\n        connection.creation.serialize_db_to_string()\n        self.assertIn(data, connection.creation._test_serialized_contents)\n"], "sample_4": ["def test_read_html_table_cosmology_class(self, cosmo_cls, cosmo, read, tmp_path):\n    \"\"\"Test reading from a class.\"\"\"\n    fp = tmp_path / \"test_read_html_table_cosmology_class.html\"\n\n    # test write\n    write(fp, format=\"ascii.html\", cosmology=cosmo_cls)\n\n    # read with the class\n    got = cosmo_cls.read(fp, format=\"ascii.html\")\n    assert got == cosmo\n\n    # read with the class name\n    got = cosmo_cls.read(fp, format=\"ascii.html\", cosmology=cosmo_cls.__qualname__)\n    assert got == cosmo\n\n    # read with the class name and index\n    got = cosmo_cls.read(fp, index=cosmo.name, format=\"ascii.html\")\n    assert got == cosmo\n"], "sample_476": ["    def test_formfield(self):\n        \"\"\"\n        Test that the formfield method returns an ImageField.\n        \"\"\"\n        formfield = self.PersonModel._meta.get_field(\"mugshot\").formfield()\n        self.assertIsInstance(formfield, forms.ImageField)\n"], "sample_736": ["def test_logistic_regression_path_convergence():\n    # Test that the path algorithm converges\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = [1] * 100 + [-1] * 100\n    Cs = np.logspace(0, 4, 10)\n\n    f = ignore_warnings\n    # can't test with fit_intercept=True since LIBLINEAR\n    # penalizes the intercept\n    for solver in ['sag', 'saga']:\n        coefs, Cs, _ = f(logistic_regression_path)(\n            X, y, Cs=Cs, fit_intercept=False, tol=1e-5, solver=solver,\n            max_iter=1000,\n            random_state=0)\n        for i, C in enumerate(Cs):\n            lr = LogisticRegression(C=C, fit_intercept=False, tol=1e-5,\n                                    solver=solver,\n                                    random_state=0)\n            lr.fit(X, y)\n            lr_coef = lr.coef_.ravel()\n            assert_array_almost_equal(lr_coef, coefs[i], decimal=4,\n                                      err_msg=\"with solver = %s\" % solver)\n\n    # test for fit_intercept=True\n    for solver in ('lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'):\n        Cs = [1e3]\n        coefs, Cs, _ = f(logistic_regression_path)(\n            X, y, Cs=Cs, fit_intercept=True, tol=1e-6, solver=solver,\n            intercept_scaling=10000., random_state=0)\n        lr = LogisticRegression(C=Cs[0], fit_intercept=True, tol=1e-4,\n                                intercept_scaling=10000., random_state=0)\n        lr.fit(X, y)\n        lr_coef = np.concatenate([lr.coef_.ravel(), lr.intercept_])\n        assert_array_almost_equal(lr_coef, coefs[0], decimal=4,\n                                  err_msg=\"with solver = %s\" % solver)\n"], "sample_999": ["def test_latex_Dict():\n    d = {Rational(1): 1, x**2: 2, x: 3, x**3: 4}\n    assert latex(d) == r'\\left \\{ 1 : 1, \\quad x : 3, \\quad x^{2} : 2, \\quad x^{3} : 4\\right \\}'\n    D = Dict(d)\n    assert latex(D) == r'\\left \\{ 1 : 1, \\quad x : 3, \\quad x^{2} : 2, \\quad x^{3} : 4\\right \\}'\n"], "sample_207": ["    def test_key_transform_lookup(self):\n        field = models.JSONField()\n        transform = KeyTransform('foo', field)\n        self.assertIsInstance(transform, KeyTransform)\n        self.assertEqual(transform.key_name, 'foo')\n        self.assertEqual(transform.lhs, field)\n"], "sample_838": ["def test_column_transformer_sparse_output():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    col_trans = ColumnTransformer([('trans1', Trans(), [0]),\n                                   ('trans2', SparseMatrixTrans(), 1)],\n                                  sparse_threshold=0.8)\n    col_trans.fit(X_array)\n    X_trans = col_trans.transform(X_array)\n    assert sparse.issparse(X_trans)\n    assert X_trans.shape == (X_trans.shape[0], X_trans.shape[0] + 1)\n    assert_array_equal(X_trans.toarray()[:, 1:], np.eye(X_trans.shape[0]))\n    assert len(col_trans.transformers_) == 2\n    assert col_trans.transformers_[-1][0] != 'remainder'\n\n    col_trans = ColumnTransformer([('trans1', Trans(), [0]),\n                                   ('trans2', SparseMatrixTrans(), 1)],\n                                  sparse_threshold=0.1)\n    col_trans.fit(X_array)\n    X_trans = col_trans.transform(X_array)\n    assert not sparse.issparse(X_trans)\n    assert X_trans.shape == (X_trans.shape[0], X_trans.shape[0] + 1)\n    assert_array_equal(X_trans[:, 1:], np.eye(X_trans.shape[0]))\n\n    col_trans = ColumnTransformer([('trans1', Trans(), [0]),\n                                   ('trans2', SparseMatrixTrans(), 1)],\n                                  sparse_threshold=0.8)\n    col_trans.fit_transform(X_array)\n    assert sparse.issparse(col_trans.sparse_output_)\n    assert col_trans.sparse_output_\n\n    col_trans = ColumnTransformer([('trans1', Trans(), [0]),\n                                   ('trans2', SparseMatrixTrans(), 1)],\n                                  sparse_threshold=0.1)\n    col_trans.fit_transform(X_array)\n    assert not col_trans.sparse_output_\n"], "sample_358": ["    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(), col_suffixes=['_suffix'], opclasses=['opclass']\n        )\n"], "sample_777": ["def test_gradient_boosting_init_zero():\n    # Test if init='zero' works for both regression and classification.\n    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)\n\n    est = GradientBoostingRegressor(n_estimators=20, max_depth=1,\n                                    random_state=1, init='zero')\n    est.fit(X, y)\n    y_pred = est.predict(X)\n    mse = mean_squared_error(y, y_pred)\n    assert_almost_equal(mse, 0.0, decimal=0)\n\n    est = GradientBoostingClassifier(n_estimators=20, max_depth=1,\n                                     random_state=1, init='zero')\n    est.fit(X, y)\n    assert_greater(est.score(X, y), 0.96)\n\n    # binary clf\n    mask = y != 0\n    y[mask] = 1\n    y[~mask] = 0\n    est = GradientBoostingClassifier(n_estimators=20, max_depth=1,\n                                     random_state=1, init='zero')\n    est.fit(X, y)\n    assert_greater(est.score(X, y), 0.96)\n\n    est = GradientBoostingRegressor(n_estimators=20, max_depth=1,\n                                    random_state=1, init='foobar')\n    assert_raises(ValueError, est.fit, X, y)\n\n    est = GradientBoostingClassifier(n_estimators=20, max_depth=1,\n                                     random_state=1, init='foobar')\n    assert_raises(ValueError, est.fit, X, y)\n"], "sample_292": ["def test_good_origin_wildcard_csrf_trusted_origin_allowed_with_subdomain(self):\n    \"\"\"\n    A POST request with an origin that matches a CSRF_TRUSTED_ORIGINS wildcard\n    and a subdomain is accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_HOST'] = 'subdomain.example.com'\n    req.META['HTTP_REFERER'] = 'https://foo.example.com'\n    mw = CsrfViewMiddleware(post_form_view)\n    self.assertIs(mw._origin_verified(req), True)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n    self.assertEqual(mw.allowed_origins_exact, set())\n    self.assertEqual(mw.allowed_origin_subdomains, {'https': ['.example.com']})\n"], "sample_266": ["def test_loading_squashed_ref_squashed_multiple_replacements(self):\n    \"\"\"\n    Tests loading a squashed migration with multiple replacements.\n    \"\"\"\n    r\"\"\"\n    The sample migrations are structured like this:\n\n    app_1       1 --> 2 ---------------------*--> 3        *--> 4\n                     \\                          /             /\n                      *-------------------*----/--> 2_sq_3 --*\n                       \\                 /    /\n        =============== \\ ============= / == / ======================\n        app_2            *--> 1_sq_2 --*    /\n                          \\                /\n                           *--> 1 --> 2 --*\n                           \\    /\n                            *--> 5 --> 6 --*\n\n    Where 2_sq_3 is a replacing migration for 2 and 3 in app_1,\n    as 1_sq_2 is a replacing migration for 1 and 2 in app_2.\n    And 5_sq_6 is a replacing migration for 5 and 6 in app_2.\n    \"\"\"\n\n    loader = MigrationLoader(connection)\n    recorder = MigrationRecorder(connection)\n    self.addCleanup(recorder.flush)\n\n    # Load with nothing applied: both migrations squashed.\n    loader.build_graph()\n    plan = set(loader.graph.forwards_plan(('app1', '4_auto')))\n    plan = plan - loader.applied_migrations.keys()\n    expected_plan = {\n        ('app1', '1_auto'),\n        ('app2', '1_squashed_2'),\n        ('app1', '2_squashed_3'),\n        ('app1', '4_auto'),\n    }\n    self.assertEqual(plan, expected_plan)\n\n    # Fake-apply a few from app1: unsquashes migration in app1.\n    recorder.record_applied('app1', '1_auto')\n    recorder.record_applied('app1', '2_auto')\n    loader.build_graph()\n    plan = set(loader.graph.forwards_plan(('app1', '4_auto')))\n    plan = plan"], "sample_30": ["def test_get_group_by_id():\n    votable = parse(get_pkg_data_filename(\"data/regression.xml\"))\n    group = votable.get_group_by_id(\"g1\")\n    assert isinstance(group, tree.Group)\n    assert group.name == \"group1\"\n    assert group.ID == \"g1\"\n    assert len(group.entries) == 2\n    assert isinstance(group.entries[0], tree.FieldRef)\n    assert isinstance(group.entries[1], tree.ParamRef)\n"], "sample_739": ["def test_inverse_binarize_thresholding():\n    # Test inverse_binarize_thresholding with binary output\n    y = np.array([[0.5, 0.5], [0.5, 0.5]])\n    classes = [0, 1]\n    threshold = 0.5\n    expected = np.array([0, 1])\n    got = _inverse_binarize_thresholding(y, output_type=\"binary\", classes=classes, threshold=threshold)\n    assert_array_equal(got, expected)\n\n    # Test inverse_binarize_thresholding with multilabel-indicator output\n    y = np.array([[0, 1, 0], [1, 0, 1]])\n    classes = [0, 1, 2]\n    threshold = 0.5\n    expected = y\n    got = _inverse_binarize_thresholding(y, output_type=\"multilabel-indicator\", classes=classes, threshold=threshold)\n    assert_array_equal(got, expected)\n\n    # Test inverse_binarize_thresholding with invalid output type\n    y = np.array([[0.5, 0.5], [0.5, 0.5]])\n    classes = [0, 1]\n    threshold = 0.5\n    assert_raises(ValueError, _inverse_binarize_thresholding, y, output_type=\"foo\", classes=classes, threshold=threshold)\n\n    # Test inverse_binarize_thresholding with invalid threshold\n    y = np.array([[0.5, 0.5], [0.5, 0.5]])\n    classes = [0, 1]\n    threshold = 1.5\n    assert_raises(ValueError, _inverse_binarize_thresholding, y, output_type=\"binary\", classes=classes, threshold=threshold)\n\n    # Test inverse_binarize_thresholding with invalid classes\n    y = np.array([[0.5, 0.5], [0.5, 0.5]])\n    classes = [0, 1, 2]\n    threshold = 0.5\n    assert_raises(ValueError, _inverse_binarize_thresholding, y, output_type=\"binary\", classes=classes, threshold=threshold)\n\n    # Test inverse_binarize_thresholding with invalid y shape\n    y = np.array([[0.5, 0.5]])\n    classes = [0, 1]\n    threshold = 0."], "sample_375": ["    def test_custom_manager_swappable(self):\n        \"\"\"\n        Tests making a ProjectState from unused models with custom managers\n        \"\"\"\n        new_apps = Apps(['migrations'])\n\n        class Food(models.Model):\n\n            food_mgr = FoodManager('a', 'b')\n            food_qs = FoodQuerySet.as_manager()\n            food_no_mgr = NoMigrationFoodManager('x', 'y')\n\n            class Meta:\n                app_label = \"migrations\"\n                apps = new_apps\n                swappable = 'TEST_SWAPPABLE_MODEL'\n\n        food_state = ModelState.from_model(Food)\n\n        # The default manager is used in migrations\n        self.assertEqual([name for name, mgr in food_state.managers], ['food_mgr'])\n        self.assertEqual(food_state.managers[0][1].args, ('a', 'b', 1, 2))\n"], "sample_500": ["def test_colorbar_alpha():\n    \"\"\"\n    Test the alpha parameter of the Colorbar class.\n    \"\"\"\n    fig, ax = plt.subplots()\n    x = np.arange(1, 5).reshape(2, 2)/4\n    pc = ax.pcolormesh(x, alpha=0.5)\n    cb = fig.colorbar(pc, ax=ax)\n    assert cb.alpha == 0.5\n    cb.set_alpha(0.8)\n    assert cb.alpha == 0.8\n    cb.set_alpha(None)\n    assert cb.alpha is None\n    fig.draw_no_output()\n"], "sample_776": ["def test_lars_path_early_stopping():\n    # Test that lars_path stops early when the alpha is too small\n    X = np.array([[1, 0], [0, 1]])\n    y = np.array([1, 1])\n    alphas, active, coef_path = linear_model.lars_path(X, y, method='lar',\n                                                      alpha_min=1e-10)\n    assert len(alphas) == 2\n    assert len(active) == 2\n    assert_array_almost_equal(coef_path.T, [[1, 0], [0, 1]])\n"], "sample_159": ["    def test_builtin_permission_name_max_length(self):\n        class Checked(models.Model):\n            class Meta:\n                permissions = [\n                    ('my_builtin_permission', 'Some permission'),\n                ]\n        errors = checks.run_checks(self.apps.get_app_configs())\n        # The max length of builtin permission names is 255, so we should not get any errors\n        self.assertEqual(errors, [])\n"], "sample_632": ["def test_ignore_signatures_multiline():\n    output = StringIO()\n    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n        similar.Run([\"--ignore-signatures\", SIMILAR5, SIMILAR6])\n    assert ex.value.code == 0\n    assert (\n        output.getvalue().strip()\n        == \"\"\""], "sample_892": ["def test_adaboost_regressor_staged_predict():\n    # Check staged predictions for regression.\n    rng = np.random.RandomState(0)\n    iris_weights = rng.randint(10, size=iris.target.size)\n    diabetes_weights = rng.randint(10, size=diabetes.target.size)\n\n    clf = AdaBoostRegressor(random_state=0)\n    clf.fit(iris.data, iris.target, sample_weight=iris_weights)\n\n    predictions = clf.predict(iris.data)\n    staged_predictions = [p for p in clf.staged_predict(iris.data)]\n    score = clf.score(iris.data, iris.target, sample_weight=iris_weights)\n    staged_scores = [\n        s for s in clf.staged_score(iris.data, iris.target, sample_weight=iris_weights)\n    ]\n\n    assert len(staged_predictions) == len(clf.estimators_)\n    assert_array_almost_equal(predictions, staged_predictions[-1])\n    assert len(staged_scores) == len(clf.estimators_)\n    assert_array_almost_equal(score, staged_scores[-1])\n\n    # AdaBoost regression\n    clf = AdaBoostRegressor(n_estimators=10, random_state=0)\n    clf.fit(diabetes.data, diabetes.target, sample_weight=diabetes_weights)\n\n    predictions = clf.predict(diabetes.data)\n    staged_predictions = [p for p in clf.staged_predict(diabetes.data)]\n    score = clf.score(diabetes.data, diabetes.target, sample_weight=diabetes_weights)\n    staged_scores = [\n        s\n        for s in clf.staged_score(\n            diabetes.data, diabetes.target, sample_weight=diabetes_weights\n        )\n    ]\n\n    assert len(staged_predictions) == len(clf.estimators_)\n    assert_array_almost_equal(predictions, staged_predictions[-1])\n    assert len(staged_scores) == len(clf.estimators_)\n    assert_array_almost_equal(score, staged_scores[-1])\n"], "sample_1010": ["def test_latex_Choose():\n    from sympy.functions.special.combinatorial_functions import Choose\n    from sympy.abc import n, k\n    assert latex(Choose(n, k)) == r\"{\\binom{n}{k}}\"\n"], "sample_674": ["def test_repr_failure_py():\n    class FakeItem(Node):\n            super().__init__(name, parent, config, session, nodeid=nodeid)\n            self._repr_failure_py_called = False\n\n            self._repr_failure_py_called = True\n            return \"repr_failure_py called\"\n\n    item = FakeItem(\"test_name\")\n    excinfo = ExceptionInfo(Exception())\n    result = item._repr_failure_py(excinfo, style=\"long\")\n    assert result == \"repr_failure_py called\"\n    assert item._repr_failure_py_called\n\n    result = item._repr_failure_py(excinfo, style=\"short\")\n    assert result == \"repr_failure_py called\"\n    assert item._repr_failure_py_called\n\n    result = item._repr_failure_py(excinfo, style=\"auto\")\n    assert result == \"repr_failure_py called\"\n    assert item._repr_failure_py_called\n\n    result = item._repr_failure_py(excinfo, style=None)\n    assert result == \"repr_failure_py called\"\n    assert item._repr_failure_py_called\n"], "sample_432": ["def test_get_search_results_with_custom_lookup(self):\n    \"\"\"\n    Regression tests for #13902: When using a ManyToMany in search_fields,\n    results shouldn't appear more than once. With a custom lookup.\n    \"\"\"\n    lead = Musician.objects.create(name=\"Vox\")\n    band = Group.objects.create(name=\"The Hype\")\n    Concert.objects.create(name=\"Woodstock\", group=band)\n    Membership.objects.create(group=band, music=lead, role=\"lead voice\")\n    Membership.objects.create(group=band, music=lead, role=\"bass player\")\n\n    m = ConcertAdmin(Concert, custom_site)\n    m.search_fields = [\"group__members__name__cc\"]\n    with register_lookup(Field, Contains, lookup_name=\"cc\"):\n        request = self.factory.get(\"/\", data={SEARCH_VAR: \"Vox\"})\n        request.user = self.superuser\n        cl = m.get_changelist_instance(request)\n        self.assertEqual(cl.queryset.count(), 1)\n        # Queryset must be deletable.\n        self.assertIs(cl.queryset.query.distinct, False)\n        cl.queryset.delete()\n        self.assertEqual(cl.queryset.count(), 0)\n\n    # A ManyToManyField in params does have Exists() applied.\n    request = self.factory.get(\"/concert/\", data={\"group__members\": \"0\"})\n    request.user = self.superuser\n    cl = m.get_changelist_instance(request)\n    self.assertIn(\" EXISTS\", str(cl.queryset.query))\n"], "sample_25": ["def test_rvkc_keyword_update(self):\n    \"\"\"\n    Regression test for https://github.com/astropy/astropy/issues/2363\n\n    Tests updating the keyword of a record-valued keyword card.\n    \"\"\"\n\n    h = fits.Header()\n    h[\"DP1.AXIS.1\"] = 1.0\n    h[\"DP1.AXIS.2\"] = 2.0\n    h[\"DP1.AXIS.3\"] = 3.0\n    assert h[\"DP1.AXIS.1\"] == 1.0\n    assert h[\"DP1.AXIS.2\"] == 2.0\n    assert h[\"DP1.AXIS.3\"] == 3.0\n\n    h[\"DP1.AXIS.1\"] = \"new value\"\n    assert h[\"DP1.AXIS.1\"] == \"new value\"\n    assert h[\"DP1.AXIS.2\"] == 2.0\n    assert h[\"DP1.AXIS.3\"] == 3.0\n\n    h[\"DP1.AXIS.1\"] = \"new value 2\"\n    assert h[\"DP1.AXIS.1\"] == \"new value 2\"\n    assert h[\"DP1.AXIS.2\"] == 2.0\n    assert h[\"DP1.AXIS.3\"] == 3.0\n\n    h[\"DP1.AXIS.1\"] = \"new value 3\"\n    assert h[\"DP1.AXIS.1\"] == \"new value 3\"\n    assert h[\"DP1.AXIS.2\"] == 2.0\n    assert h[\"DP1.AXIS.3\"] == 3.0\n\n    h[\"DP1.AXIS.1\"] = \"new value 4\"\n    assert h[\"DP1.AXIS.1\"] == \"new value 4\"\n    assert h[\"DP1.AXIS.2\"] == 2.0\n    assert h[\"DP1.AXIS.3\"] == 3.0\n\n    h[\"DP1.AXIS.1\"] = \"new value 5\"\n    assert h[\"DP1.AXIS.1\"] == \"new value 5\"\n    assert h[\"DP1.AXIS.2\"] == 2.0\n    assert h[\""], "sample_1135": ["def test_Mul_is_extended_real():\n    x = Symbol('x', extended_real=True)\n    y = Symbol('y', extended_real=True)\n    z = Symbol('z', extended_real=False)\n    assert (x*y).is_extended_real is True\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n    assert (x*y*z).is_extended_real is None\n   "], "sample_621": ["    def indexes(self) -> tuple[PandasIndex, PandasIndex, Variable, Variable]:\n        index1 = PandasIndex(pd.Index([1, 2, 3]), \"x\")\n        index2 = PandasIndex(pd.Index([1, 2, 3]), \"x\")\n        var1 = xr.Variable(\"x\", [1, 2, 3])\n        var2 = xr.Variable(\"x\", [1, 2, 3])\n\n        return index1, index2, var1, var2\n"], "sample_155": ["    def test_file_from_buffer_with_custom_content_type(self):\n        response = FileResponse(io.BytesIO(b'binary content'), content_type='text/plain')\n        self.assertEqual(response['Content-Type'], 'text/plain')\n        self.assertEqual(response['Content-Length'], '14')\n        self.assertFalse(response.has_header('Content-Disposition'))\n        self.assertEqual(list(response), [b'binary content'])\n"], "sample_286": ["    def test_state_is_not_written_to_database_until_save_was_called(self):\n        a = Article(\n            id=None,\n            headline='Parrot programs in Python',\n            pub_date=datetime(2005, 7, 28),\n        )\n        self.assertIsNone(a.id)\n        self.assertEqual(Article.objects.all().count(), 0)\n        self.assertFalse(a._state.adding)\n        self.assertIsNone(a._state.db)\n\n        # Save it into the database. You have to call save() explicitly.\n        a.save()\n        self.assertIsNotNone(a.id)\n        self.assertEqual(Article.objects.all().count(), 1)\n        self.assertFalse(a._state.adding)\n        self.assertEqual(a._state.db, \"default\")\n"], "sample_137": ["def test_replace_named_groups(self):\n    \"\"\"\n    Test that replace_named_groups() correctly replaces named groups in a pattern.\n    \"\"\"\n    pattern = r'^(?P<a>\\w+)/b/(?P<c>\\w+)/$'\n    expected = r'^<a>/b/<c>/$'\n    self.assertEqual(replace_named_groups(pattern), expected)\n"], "sample_767": ["def test_column_transformer_sparse_output():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    X_sparse = sparse.csr_matrix(X_array)\n\n    # test that sparse output is correctly set\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           sparse_threshold=0.8)\n    assert not ct.sparse_output_\n    ct.fit(X_sparse)\n    assert ct.sparse_output_\n\n    # test that sparse output is correctly set when all transformers are sparse\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', SparseMatrixTrans(), 1)],\n                           sparse_threshold=0.8)\n    assert not ct.sparse_output_\n    ct.fit(X_sparse)\n    assert ct.sparse_output_\n\n    # test that sparse output is correctly set when all transformers are dense\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', TransNo2D(), 1)],\n                           sparse_threshold=0.8)\n    assert not ct.sparse_output_\n    ct.fit(X_sparse)\n    assert not ct.sparse_output_\n\n    # test that sparse output is correctly set when some transformers are sparse\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', SparseMatrixTrans(), 1)],\n                           sparse_threshold=0.2)\n    assert not ct.sparse_output_\n    ct.fit(X_sparse)\n    assert ct.sparse_output_\n\n    # test that sparse output is correctly set when some transformers are dense\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', TransNo2D(), 1)],\n                           sparse_threshold=0.8)\n    assert not ct.sparse_output_\n    ct.fit(X_sparse)\n    assert not ct.sparse_output_\n\n    # test that sparse output is correctly set when all transformers are sparse and\n    # the sparse threshold is 0\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', SparseMatrixTrans(), 1)],\n                           sparse_threshold=0)\n    assert not ct.sparse_output_\n    ct.fit(X_sparse)\n    assert ct.sparse_output_\n\n    # test that sparse output is correctly set when all transformers are dense and\n    # the sparse threshold is 0\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', TransNo2D(), 1)],\n                          "], "sample_377": ["    def test_non_sensitive_request(self):\n        \"\"\"\n        Everything (request info and frame variables) can bee seen\n        in the default error reports for non-sensitive requests.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(non_sensitive_view)\n            self.verify_unsafe_email(non_sensitive_view)\n\n        with self.settings(DEBUG=False):\n            self.verify_unsafe_response(non_sensitive_view)\n            self.verify_unsafe_email(non_sensitive_view)\n"], "sample_830": ["def test_get_deps_info_with_import_error():\n    # Simulate an import error for a dependency\n    sys.modules['Cython'] = None\n    deps_info = _get_deps_info()\n\n    assert 'Cython' in deps_info\n    assert deps_info['Cython'] is None\n\n    # Restore the original module\n    sys.modules['Cython'] = importlib.import_module('Cython')\n"], "sample_606": ["def test_cross_broadcast_compat_data() -> None:\n    a = xr.DataArray([1, 2, 0], dims=[\"dim_0\"])\n    b = xr.DataArray([4, 5, 6], dims=[\"dim_0\"])\n\n    with pytest.raises(ValueError):\n        xr.cross(a, b, dim=\"dim_0\")\n\n    a = xr.DataArray([1, 2], dims=[\"dim_0\"])\n    b = xr.DataArray([4, 5, 6, 0], dims=[\"dim_0\"])\n\n    with pytest.raises(ValueError):\n        xr.cross(a, b, dim=\"dim_0\")\n\n    a = xr.DataArray([1, 2, 0], dims=[\"dim_0\"])\n    b = xr.DataArray([4, 5, 6], dims=[\"dim_0\"])\n\n    c = xr.cross(a, b, dim=\"dim_0\")\n    expected = np.array([-3, 6, 0])\n    xr.testing.assert_duckarray_allclose(expected, c)\n\n    a = xr.DataArray([1, 2], dims=[\"dim_0\"])\n    b = xr.DataArray([4, 5, 6], dims=[\"dim_0\"])\n\n    c = xr.cross(a, b, dim=\"dim_0\")\n    expected = np.array([-3])\n    xr.testing.assert_duckarray_allclose(expected, c)\n\n    a = xr.DataArray([1, 2, 0], dims=[\"dim_0\"])\n    b = xr.DataArray([4, 5, 6], dims=[\"dim_0\"])\n\n    c = xr.cross(a, b, dim=\"dim_0\")\n    expected = np.array([-3, 6, 0])\n    xr.testing.assert_duckarray_allclose(expected, c)\n\n    a = xr.DataArray([1, 2], dims=[\"dim_0\"])\n    b = xr.DataArray([4, 5, 6], dims=[\"dim_0\"])\n\n    c = xr.cross(a, b, dim=\"dim_0\")\n    expected = np.array([-3])\n    xr.testing.assert_duckarray_allclose(expected, c)\n\n    a = xr.DataArray([1, 2, 0], dims=[\"dim_0\"])\n    b = xr.DataArray([4, 5, 6], dims=[\"dim_0\"])\n\n    c = xr.cross(a, b, dim=\"dim_0\")\n    expected"], "sample_202": ["def test_max_cookie_length_empty(self):\n    \"\"\"\n    If the data exceeds what is allowed in a cookie, empty messages are\n    removed before saving (and returned by the ``update`` method).\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # When storing as a cookie, the cookie has constant overhead of approx\n    # 54 chars, and each message has a constant overhead of about 37 chars\n    # and a variable overhead of zero in the best case. We aim for a message\n    # size which will fit 4 messages into the cookie, but not 5.\n    # See also FallbackTest.test_session_fallback\n    msg_size = int((CookieStorage.max_cookie_size - 54) / 4.5 - 37)\n    for i in range(5):\n        storage.add(constants.INFO, str(i) * msg_size)\n    unstored_messages = storage.update(response)\n\n    cookie_storing = self.stored_messages_count(storage, response)\n    self.assertEqual(cookie_storing, 4)\n\n    self.assertEqual(len(unstored_messages), 1)\n    self.assertEqual(unstored_messages[0].message, '')\n"], "sample_1184": ["def test_gaussian_conjugation():\n    # Test gaussian_conj function\n    s_in, z_r_in, f = symbols('s_in z_r_in f')\n    s_out, z_r_out, m = gaussian_conj(s_in, z_r_in, f)\n    assert s_out == 1/(-1/(s_in + z_r_in**2/(-f + s_in)) + 1/f)\n    assert z_r_out == z_r_in/(1 - s_in**2/f**2 + z_r_in**2/f**2)\n    assert m == 1/sqrt(1 - s_in**2/f**2 + z_r_in**2/f**2)\n\n    # Test conjugate_gauss_beams function\n    l, w_i, w_o, f = symbols('l w_i w_o f')\n    s_in, s_out, f_out = conjugate_gauss_beams(l, w_i, w_o, f=f)\n    assert s_in == f*(1 - sqrt(w_i**2/w_o**2 - pi**2*w_i**4/(f**2*l**2)))\n    assert s_out == f*w_o**2*(w_i**2/w_o**2 - sqrt(w_i**2/w_o**2 - pi**2*w_i**4/(f**2*l**2)))/w_i**2\n    assert f_out == f\n\n    # Test BeamParameter class\n    z, l, w_0 = symbols('z l w_0', positive=True)\n    p = BeamParameter(l, z, w=w_0)\n    assert p.radius == z*(pi**2*w_0**4/(l**2*z**2) + 1)\n    assert p.w == w_0*sqrt(l**2*z**2/(pi**2*w_0**4) + 1)\n    assert p.w_0 == w_0\n    assert p.divergence == l/(pi*w_0)\n    assert p.gouy == atan2(z, pi*w_0**2/l)\n    assert p.waist_approximation_limit == 2*l/pi\n\n    # Test BeamParameter class with n != 1\n    p = BeamParameter(530e-9, 1, w=1e-3, n=2)\n    assert p.q == 1 + 3.77358490566038*I*pi\n   "], "sample_658": ["    def test_doctest_report_choice(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n                '''\n                >>> foo()\n                   a  b\n                0  1  4\n                1  2  5\n                2  3  6\n                '''\n                print('   a  b\\\\n'\n                      '0  1  4\\\\n'\n                      '1  2  5\\\\n'\n                      '2  3  6')\n            \"\"\"\n        )\n        result = testdir.runpytest(\"--doctest-modules\", \"--doctest-report\", \"cdiff\")\n        result.stdout.fnmatch_lines(\n            [\n                \"         a  b\",\n                \"      0  1  4\",\n                \"    ! 1  2  4\",\n                \"      2  3  6\",\n                \"    --- 1,4 ----\",\n                \"         a  b\",\n                \"      0  1  4\",\n                \"    ! 1  2  5\",\n                \"      2  3  6\",\n            ]\n        )\n        result = testdir.runpytest(\"--doctest-modules\", \"--doctest-report\", \"ndiff\")\n        result.stdout.fnmatch_lines(\n            [\n                \"         a  b\",\n                \"      0  1  4\",\n                \"    - 1  2  4\",\n                \"    ?       ^\",\n                \"    + 1  2  5\",\n                \"    ?       ^\",\n                \"      2  3  6\",\n            ]\n        )\n"], "sample_672": ["def test_repr_on_newstyle_with_maxsize():\n    class Function:\n            return \"<%s>\" % (self.name)\n\n    assert saferepr(Function(), maxsize=10) == \"<Function object at 0x{:x}>\".format(id(Function()))\n"], "sample_520": ["def test_line_collection_sorting(fig_test, fig_ref):\n    \"\"\"Test that marker properties are correctly sorted.\"\"\"\n    y, x = np.mgrid[:10, :10]\n    z = np.arange(x.size).reshape(x.shape)\n\n    sizes = np.full(z.shape, 25)\n    sizes[0::2, 0::2] = 100\n    sizes[1::2, 1::2] = 100\n\n    facecolors = np.full(z.shape, 'C0')\n    facecolors[:5, :5] = 'C1'\n    facecolors[6:, :4] = 'C2'\n    facecolors[6:, 6:] = 'C3'\n\n    edgecolors = np.full(z.shape, 'C4')\n    edgecolors[1:5, 1:5] = 'C5'\n    edgecolors[5:9, 1:5] = 'C6'\n    edgecolors[5:9, 5:9] = 'C7'\n\n    linewidths = np.full(z.shape, 2)\n    linewidths[0::2, 0::2] = 5\n    linewidths[1::2, 1::2] = 5\n\n    x, y, z, sizes, facecolors, edgecolors, linewidths = [\n        a.flatten()\n        for a in [x, y, z, sizes, facecolors, edgecolors, linewidths]\n    ]\n\n    ax_ref = fig_ref.add_subplot(projection='3d')\n    sets = (np.unique(a) for a in [sizes, facecolors, edgecolors, linewidths])\n    for s, fc, ec, lw in itertools.product(*sets):\n        subset = (\n            (sizes != s) |\n            (facecolors != fc) |\n            (edgecolors != ec) |\n            (linewidths != lw)\n        )\n        subset = np.ma.masked_array(z, subset, dtype=float)\n\n        # When depth shading is disabled, the colors are passed through as\n        # single-item lists; this triggers single path optimization. The\n        # following reshaping is a hack to disable that, since the optimization\n        # would not occur for the full scatter which has multiple colors.\n        fc = np.repeat(fc, sum(~subset.mask))\n\n        ax_ref.scatter(x, y, subset, s=s, fc=fc, ec="], "sample_1149": ["def test_singleton_redefinition_with_different_metaclass():\n    class TestSingleton(Basic, metaclass=type):\n        pass\n\n    assert TestSingleton() is not S.TestSingleton\n\n    class TestSingleton(Basic, metaclass=Singleton):\n        pass\n\n    assert TestSingleton() is S.TestSingleton\n"], "sample_491": ["def test_boundfield_render_template(self):\n    class MyForm(Form):\n        first_name = CharField()\n\n    f = MyForm()\n    self.assertHTMLEqual(\n        f[\"first_name\"].render(template_name=\"forms_tests/custom_field.html\"),\n        '<label for=\"id_first_name\">First name:</label><p>Custom Field<p>'\n        '<input type=\"text\" name=\"first_name\" required id=\"id_first_name\">',\n    )\n"], "sample_746": ["def test_fbeta_score_multiclass():\n    # Test fbeta_score function for multiclass classification task\n    y_true, y_pred, _ = make_prediction(binary=False)\n\n    # compute scores with default labels introspection\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average=None)\n    assert_array_almost_equal(p, [0.83, 0.33, 0.42], 2)\n    assert_array_almost_equal(r, [0.79, 0.09, 0.90], 2)\n    assert_array_almost_equal(f, [0.81, 0.15, 0.57], 2)\n    assert_array_equal(s, [24, 31, 20])\n\n    # averaging tests\n    fs = fbeta_score(y_true, y_pred, average='micro')\n    assert_array_almost_equal(fs, 0.53, 2)\n\n    fs = fbeta_score(y_true, y_pred, average='macro')\n    assert_array_almost_equal(fs, 0.51, 2)\n\n    fs = fbeta_score(y_true, y_pred, average='weighted')\n    assert_array_almost_equal(fs, 0.47, 2)\n\n    assert_raises(ValueError, fbeta_score, y_true, y_pred, average=\"samples\")\n\n    # same prediction but with and explicit label ordering\n    p, r, f, s = precision_recall_fscore_support(\n        y_true, y_pred, labels=[0, 2, 1], average=None)\n    assert_array_almost_equal(p, [0.83, 0.41, 0.33], 2)\n    assert_array_almost_equal(r, [0.79, 0.90, 0.10], 2)\n    assert_array_almost_equal(f, [0.81, 0.57, 0.15], 2)\n    assert_array_equal(s, [24, 20, 31])\n\n    # Check that fbeta_score behaves correctly when beta is 1\n    assert_array_almost_equal(fbeta_score(y_true, y_pred, beta=1, average=None),\n                            f, 2)\n    assert_array_almost_equal(fbeta_score(y_true, y_pred, beta=1, average='micro'),\n                            fs, 2)\n    assert_array_almost_equal(fbeta_score(y_true, y_pred, beta=1, average='macro'),\n                            fs, 2)\n"], "sample_737": ["def test_countvectorizer_fit_transform_twice():\n    # raw documents\n    data = ALL_FOOD_DOCS\n    cv = CountVectorizer()\n    X1 = cv.fit_transform(data)\n    X2 = cv.fit_transform(data)\n    assert_array_equal(X1.toarray(), X2.toarray())\n"], "sample_1002": ["def test_issue_10020():\n    assert oo**I is S.NaN\n    assert oo**(1 + I) is S.ComplexInfinity\n    assert oo**(-1 + I) is S.Zero\n    assert (-oo)**I is S.NaN\n    assert (-oo)**(-1 + I) is S.Zero\n    assert oo**t == Pow(oo, t, evaluate=False)\n    assert (-oo)**t == Pow(-oo, t, evaluate=False)\n"], "sample_331": ["    def test_parse_postgresql_interval_with_seconds(self):\n        self.assertEqual(parse_duration('1 day 00:00:01'), timedelta(days=1, seconds=1))\n        self.assertEqual(parse_duration('-1 day 00:00:01'), timedelta(days=-1, seconds=-1))\n        self.assertEqual(parse_duration('4 days 00:15:30'), timedelta(days=4, minutes=15, seconds=30))\n        self.assertEqual(parse_duration('-4 days 00:15:30'), timedelta(days=-4, minutes=-15, seconds=-30))\n        self.assertEqual(parse_duration('4 days 00:15:30.1'), timedelta(days=4, minutes=15, seconds=30, milliseconds=100))\n        self.assertEqual(parse_duration('-4 days 00:15:30.1'), timedelta(days=-4, minutes=-15, seconds=-30, milliseconds=-100))\n"], "sample_790": ["def test_kernel_pca_copy_X():\n    rng = np.random.RandomState(0)\n    X_fit = rng.random_sample((5, 4))\n    X_pred = rng.random_sample((2, 4))\n\n    kpca = KernelPCA(n_components=2, copy_X=False)\n    kpca.fit(X_fit)\n    X_fit_transformed = kpca.transform(X_fit)\n\n    # modify the original data\n    X_fit[0, 0] = 666\n\n    # check that the transformed data is not affected\n    assert_array_almost_equal(np.abs(X_fit_transformed),\n                             np.abs(kpca.transform(X_fit)))\n\n    # check that the copy_X attribute is correctly set\n    assert_equal(kpca.copy_X, False)\n"], "sample_123": ["    def test_invalid_input(self):\n        with self.assertRaises(ValueError):\n            urlsafe_base64_decode('invalid input')\n"], "sample_494": ["    def test_serialize_deconstructable(self):\n        class DeconstructableClass:\n                return (\"path.to.DeconstructableClass\", [], {})\n\n        self.assertSerializedResultEqual(\n            DeconstructableClass(),\n            (\"path.to.DeconstructableClass\", {\"import path.to\"}),\n        )\n"], "sample_945": ["def test_pydata_with_union_type_operator_old(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :annotation: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0],\n                ([desc_name, \"version\"],\n                 [desc_annotation, (\": \",\n                                    [pending_xref, \"int\"],\n                                    \" \",\n                                    [desc_sig_punctuation, \"|\"],\n                                    \" \",\n                                    [pending_xref, \"str\"])]))\n    assert_node(doctree[1][0][1], pending_xref, refdomain=\"py\", reftype=\"class\", reftarget=\"int\",\n                **{\"py:module\": \"example\", \"py:class\": \"Class\"})\n    assert_node(doctree[1][0][1][1], pending_xref, refdomain=\"py\", reftype=\"class\", reftarget=\"str\",\n                **{\"py:module\": \"example\", \"py:class\": \"Class\"})\n"], "sample_875": ["def test_precision_recall_fscore_support_multilabel_unordered_labels():\n    # test that labels need not be sorted in the multilabel case\n    y_true = np.array([[1, 1, 0, 0]])\n    y_pred = np.array([[0, 0, 1, 1]])\n    p, r, f, s = precision_recall_fscore_support(\n        y_true, y_pred, labels=[3, 0, 1, 2], warn_for=[], average=None\n    )\n    assert_array_equal(p, 0)\n    assert_array_equal(r, 0)\n    assert_array_equal(f, 0)\n    if p is not None:\n        assert_array_equal(s, [0, 1, 1, 0])\n"], "sample_445": ["def test_time_strings_override(self):\n    \"\"\"Test that time_strings can be overridden.\"\"\"\n    time_strings = {\n        \"minute\": ngettext_lazy(\"%(num)d minute\", \"%(num)d minutes\", \"num\"),\n        \"hour\": ngettext_lazy(\"%(num)d hour\", \"%(num)d hours\", \"num\"),\n    }\n    self.assertEqual(timesince(self.t, self.t + self.oneminute, time_strings=time_strings), \"0\\xa0minutes\")\n    self.assertEqual(timeuntil(self.t + self.oneminute, self.t, time_strings=time_strings), \"1\\xa0minute\")\n    self.assertEqual(timesince(self.t, self.t + self.onehour, time_strings=time_strings), \"0\\xa0minutes\")\n    self.assertEqual(timeuntil(self.t + self.onehour, self.t, time_strings=time_strings), \"1\\xa0hour\")\n"], "sample_386": ["def test_mark_safe_marking_lazy_string_twice(self):\n    \"\"\"\n    mark_safe can be called multiple times on a single string.\n    \"\"\"\n    s = mark_safe(mark_safe(\"a&b\"))\n    self.assertIsInstance(s, SafeString)\n    self.assertRenderEqual(\"{{ s }}\", \"a&b\", s=s)\n"], "sample_856": ["def test_train_test_split_sparse_input():\n    # Check that train_test_split converts scipy sparse matrices\n    # to csr, as stated in the documentation\n    X = np.arange(100).reshape((10, 10))\n    sparse_types = [csr_matrix, csc_matrix, coo_matrix]\n    for InputFeatureType in sparse_types:\n        X_s = InputFeatureType(X)\n        X_train, X_test = train_test_split(X_s)\n        assert isinstance(X_train, csr_matrix)\n        assert isinstance(X_test, csr_matrix)\n"], "sample_126": ["def test_alter_field_to_foreign_key(self):\n    \"\"\"Tests autodetection of field alterations to ForeignKey.\"\"\"\n    changes = self.get_changes([self.author_empty, self.book], [self.author_empty, self.book_with_author_renamed])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, model_name=\"book\", name=\"author\")\n    self.assertEqual(changes['otherapp'][0].operations[0].field.remote_field.model._meta.app_label, 'testapp')\n    self.assertEqual(changes['otherapp'][0].operations[0].field.remote_field.model._meta.object_name, 'Writer')\n"], "sample_1046": ["def test_TensorIndexType_data():\n    Lorentz = TensorIndexType('Lorentz', dim=4)\n    Lorentz.data = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\n    m0, m1, m2, m3 = tensor_indices('m0:4', Lorentz)\n    assert Lorentz.data == Lorentz.metric.tomatrix()\n    Lorentz.data = [[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, -1]]\n    assert Lorentz.data == Lorentz.metric.tomatrix()\n    Lorentz.data = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\n    Lorentz.data = [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]\n    raises(ValueError, lambda: Lorentz.data)\n    Lorentz.data = [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]\n    Lorentz.data = [[1, 2], [3, 4]]\n    raises(ValueError, lambda: Lorentz.data)\n"], "sample_469": ["    def setUpTestData(cls):\n        cls.a1 = Author.objects.create(name=\"Adrian Holovaty\", age=34)\n        cls.a2 = Author.objects.create(name=\"Jacob Kaplan-Moss\", age=35)\n        cls.a3 = Author.objects.create(name=\"Brad Dayley\", age=45)\n        cls.a4 = Author.objects.create(name=\"James Bennett\", age=29)\n        cls.a5 = Author.objects.create(name=\"Jeffrey Forcier\", age=37)\n        cls.a6 = Author.objects.create(name=\"Paul Bissex\", age=29)\n        cls.a7 = Author.objects.create(name=\"Wesley J. Chun\", age=25)\n        cls.a8 = Author.objects.create(name=\"Peter Norvig\", age=57)\n        cls.a9 = Author.objects.create(name=\"Stuart Russell\", age=46)\n        cls.a1.friends.add(cls.a2, cls.a4)\n        cls.a2.friends.add(cls.a1, cls.a7)\n        cls.a4.friends.add(cls.a1)\n        cls.a5.friends.add(cls.a6, cls.a7)\n        cls.a6.friends.add(cls.a5, cls.a7)\n        cls.a7.friends.add(cls.a2, cls.a5, cls.a6)\n        cls.a8.friends.add(cls.a9)\n        cls.a9.friends.add(cls.a8)\n\n        cls.p1 = Publisher.objects.create(name=\"Apress\", num_awards=3)\n        cls.p2 = Publisher.objects.create(name=\"Sams\", num_awards=1)\n        cls.p3 = Publisher.objects.create(name=\"Prentice Hall\", num_awards=7)\n        cls.p4 = Publisher.objects.create(name=\"Morgan Kaufmann\", num_awards=9)\n        cls.p5 = Publisher.objects.create(name=\"Jonno's House of Books\", num_awards=0)\n\n        cls.b1 = Book.objects.create(\n            isbn=\"159059725\",\n            name=\"The Definitive Guide to Django: Web Development Done Right\",\n            pages=447,\n            rating=4.5,\n            price=Decimal(\"30.00\"),\n            contact=cls.a1,\n            publisher=cls.p1,\n            pubdate=datetime.date(2007, 12, 6),\n        )\n        cls.b2 = Book.objects.create(\n            isbn=\"067232959\",\n            name=\"Sams Teach Yourself Django in 24 Hours\",\n            pages=528"], "sample_214": ["    def test_json_field_with_nested_null(self):\n        obj = JSONModel(value={'a': {'b': None}})\n        obj.save()\n        obj.refresh_from_db()\n        self.assertEqual(obj.value, {'a': {'b': None}})\n"], "sample_759": ["def test_one_hot_encoder_sparse_dtype():\n    X = np.array([[3, 2, 1], [0, 1, 1]], dtype=np.float32)\n    enc = OneHotEncoder(sparse=True, dtype=np.float32)\n    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):\n        X_trans = enc.fit_transform(X)\n        assert_equal(X_trans.dtype, np.float32)\n        assert_equal(X_trans.shape, (2, 5))\n        assert_array_equal(enc.active_features_,\n                           np.where([1, 0, 0, 1, 0, 1, 1, 0, 1])[0])\n        assert_array_equal(enc.feature_indices_, [0, 4, 7, 9])\n\n    # check outcome\n    assert_array_equal(X_trans.toarray(),\n                       np.array([[0., 1., 0., 1., 1.],\n                                 [1., 0., 1., 0., 1.]], dtype=np.float32))\n"], "sample_146": ["def test_valid_language_code_in_languages(self):\n    \"\"\"Test that LANGUAGE_CODE is valid when it's also in LANGUAGES.\"\"\"\n    for tag in ['de', 'es', 'fr', 'ca']:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag, LANGUAGES=[(tag, tag)]):\n            self.assertEqual(check_setting_language_code(None), [])\n"], "sample_1147": ["def test_latex_RandomDomain():\n    from sympy.stats import Normal, Die, Exponential, pspace, where\n    from sympy.stats.rv import RandomDomain\n\n    X = Normal('x1', 0, 1)\n    assert latex(where(X > 0)) == r\"\\text{Domain: }0 < x_{1} \\wedge x_{1} < \\infty\"\n\n    D = Die('d1', 6)\n    assert latex(where(D > 4)) == r\"\\text{Domain: }d_{1} = 5 \\vee d_{1} = 6\"\n\n    A = Exponential('a', 1)\n    B = Exponential('b', 1)\n    assert latex(\n        pspace(Tuple(A, B)).domain) == \\\n        r\"\\text{Domain: }0 \\leq a \\wedge 0 \\leq b \\wedge a < \\infty \\wedge b < \\infty\"\n\n    assert latex(RandomDomain(FiniteSet(x), FiniteSet(1, 2))) == \\\n        r'\\text{Domain: }\\left\\{x\\right\\}\\text{ in }\\left\\{1, 2\\right\\}'\n"], "sample_13": ["def test_longitude_wrap_at_zero():\n    \"\"\"\n    Test that Longitude objects wrap at zero correctly\n    \"\"\"\n    lon = Longitude([0, 360, 720] * u.deg)\n    assert np.all(lon == Longitude([0, 0, 0] * u.deg))\n    assert np.all(lon == Angle([0, 0, 0] * u.deg))\n\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='180d')\n    assert np.all(lon == Longitude([-180, -180, -180] * u.deg))\n    assert np.all(lon == Angle([-180, -180, -180] * u.deg))\n\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle=180 * u.deg)\n    assert np.all(lon == Longitude([-180, -180, -180] * u.deg))\n    assert np.all(lon == Angle([-180, -180, -180] * u.deg))\n\n    # Test wrapping a scalar Longitude\n    lon = Longitude('0d')\n    assert lon.wrap_at('180d') == Longitude('-180d')\n\n    lon = Longitude('360d')\n    assert lon.wrap_at('180d') == Longitude('-180d')\n"], "sample_980": ["def test_inversion_vector():\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    assert p.inversion_vector() == [0, 0, 0, 0, 0, 0]\n    p = Permutation([3, 2, 1, 0, 4, 5])\n    assert p.inversion_vector() == [3, 2, 1, 0, 0, 0]\n    p = Permutation([4, 3, 2, 1, 0, 5])\n    assert p.inversion_vector() == [4, 3, 2, 1, 0, 0]\n    p = Permutation([5, 4, 3, 2, 1, 0])\n    assert p.inversion_vector() == [5, 4, 3, 2, 1, 0]\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([3, 2, 1, 0, 4, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([4, 3, 2, 1, 0, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([5, 4, 3, 2, 1, 0])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()).array_form == p.array_form\n    p = Permutation([3, 2, 1, 0, 4, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()).array_form == p.array_form\n    p = Permutation([4, 3, 2, 1, 0, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()).array_form == p.array_form\n    p = Permutation([5, 4, 3, 2, 1, 0"], "sample_223": ["    def setUpTestData(cls):\n        cls.a1 = Author.objects.create(name='a1', num=1001)\n        cls.a2 = Author.objects.create(name='a2', num=2002)\n        cls.a3 = Author.objects.create(name='a3', num=3003)\n        cls.a4 = Author.objects.create(name='a4', num=4004)\n        cls.r1 = Report.objects.create(name='r1', creator=cls.a1)\n        cls.r2 = Report.objects.create(name='r2', creator=cls.a3)\n        cls.r3 = Report.objects.create(name='r3')\n"], "sample_522": ["def test_colorbar_extension_shape_proportional():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    # Create figures for uniform and proportionally spaced colorbars.\n    _colorbar_extension_shape('proportional')\n"], "sample_670": ["def test_not_parentheses(expr: str, expected: bool) -> None:\n    matcher = {\"true\": True, \"false\": False}.__getitem__\n    assert evaluate(expr, matcher) is expected\n"], "sample_327": ["def test_invalid_json_with_custom_decoder(self):\n    class CustomDecoder(json.JSONDecoder):\n            return super().__init__(object_hook=self.as_uuid, *args, **kwargs)\n\n            if 'uuid' in dct:\n                dct['uuid'] = uuid.UUID(dct['uuid'])\n            return dct\n\n    value = {'uuid': 'c141e152-6550-4172-a784-05448d98204b'}\n    encoded_value = '{\"uuid\": \"c141e152-6550-4172-a784-05448d98204b\"}'\n    field = JSONField(decoder=CustomDecoder)\n    with self.assertRaisesMessage(ValidationError, 'Enter a valid JSON.'):\n        field.clean(encoded_value)\n"], "sample_625": ["def test_cross_broadcasting() -> None:\n    # Test broadcasting of cross product with arrays of different sizes\n    a = xr.DataArray([1, 2, 0], dims=[\"cartesian\"])\n    b = xr.DataArray([4, 5, 6, 7], dims=[\"cartesian\"])\n\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    expected = np.cross([1, 2, 0], [4, 5, 6, 7])\n    xr.testing.assert_duckarray_allclose(expected, actual)\n\n    # Test broadcasting of cross product with arrays of different sizes and coords\n    a = xr.DataArray(\n        [1, 2, 0],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    b = xr.DataArray(\n        [4, 5, 6, 7],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\", \"w\"])),\n    )\n\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    expected = np.cross([1, 2, 0], [4, 5, 6, 7])\n    xr.testing.assert_duckarray_allclose(expected, actual)\n\n    # Test broadcasting of cross product with arrays of different sizes and coords in different positions\n    a = xr.DataArray(\n        [1, 2],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"z\"])),\n    )\n    b = xr.DataArray(\n        [4, 5, 6, 7],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\", \"w\"])),\n    )\n\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    expected = np.cross([1, 2], [4, 5, 6, 7])\n    xr.testing.assert_duckarray_allclose(expected, actual)\n\n    # Test broadcasting of cross product with arrays of different sizes and coords in different positions and with missing values\n    a = xr.DataArray(\n        [1, 2, np.nan],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"z\"])),\n    )\n    b = xr.Data"], "sample_16": ["    def setup_method(self):\n        self.q = np.array([1.0, 2.0, 3.0]) * u.m\n"], "sample_277": ["def test_combine_and_non_q_object(self):\n    q = Q(x=1)\n    with self.assertRaisesMessage(TypeError, str(2)):\n        q & 2\n    with self.assertRaisesMessage(TypeError, str(2)):\n        2 & q\n\n    q = Q(x__in={}.keys())\n    with self.assertRaisesMessage(TypeError, str(2)):\n        q & 2\n    with self.assertRaisesMessage(TypeError, str(2)):\n        2 & q\n"], "sample_20": ["def test_read_with_unit_parse_strict(tmp_path):\n    filename = tmp_path / \"test_read_with_unit_parse_strict.fits\"\n    hdu = BinTableHDU(self.data)\n    hdu.columns[0].unit = \"RADIANS\"\n    hdu.columns[1].unit = \"spam\"\n    hdu.columns[2].unit = \"millieggs\"\n    with pytest.warns(u.UnitsWarning, match=\"did not parse as fits unit\"):\n        t = Table.read(hdu, unit_parse_strict=\"raise\")\n    assert equal_data(t, self.data)\n    with pytest.raises(u.UnitsWarning, match=\"did not parse as fits unit\"):\n        Table.read(hdu, unit_parse_strict=\"raise\")\n    with pytest.warns(u.UnitsWarning, match=\"did not parse as fits unit\"):\n        Table.read(hdu, unit_parse_strict=\"warn\")\n    with pytest.warns(u.UnitsWarning, match=\"did not parse as fits unit\") as w:\n        Table.read(hdu, unit_parse_strict=\"silent\")\n    assert len(w) == 1\n"], "sample_1123": ["def test_CondSet_base_set():\n    c = ConditionSet(x, x < 1, S.UniversalSet)\n    assert c.base_set == S.UniversalSet\n    assert c == ConditionSet(x, x < 1, S.UniversalSet)\n    assert c.subs(x, y) == ConditionSet(y, y < 1, S.UniversalSet)\n    assert c.dummy_eq(ConditionSet(y, y < 1, S.UniversalSet))\n    assert c.contains(0) == And(Contains(0, S.UniversalSet), x < 1)\n    assert c.contains(1) == And(Contains(1, S.UniversalSet), x < 1)\n    assert c.contains(2) == And(Contains(2, S.UniversalSet), x < 1)\n    assert c.contains(3) == And(Contains(3, S.UniversalSet), x < 1)\n    assert c.contains(4) == And(Contains(4, S.UniversalSet), x < 1)\n    assert c.contains(5) == And(Contains(5, S.UniversalSet), x < 1)\n    assert c.contains(6) == And(Contains(6, S.UniversalSet), x < 1)\n    assert c.contains(7) == And(Contains(7, S.UniversalSet), x < 1)\n    assert c.contains(8) == And(Contains(8, S.UniversalSet), x < 1)\n    assert c.contains(9) == And(Contains(9, S.UniversalSet), x < 1)\n    assert c.contains(10) == And(Contains(10, S.UniversalSet), x < 1)\n    assert c.contains(11) == And(Contains(11, S.UniversalSet), x < 1)\n    assert c.contains(12) == And(Contains(12, S.UniversalSet), x < 1)\n    assert c.contains(13) == And(Contains(13, S.UniversalSet), x < 1)\n    assert c.contains(14) == And(Contains(14, S.UniversalSet), x < 1)\n    assert c.contains(15) == And(Contains(15, S.UniversalSet), x < 1)\n    assert c.contains(16) == And(Contains(16, S.UniversalSet), x < 1)\n    assert"], "sample_1019": ["def test_issue_7915():\n    from sympy import sqrt, sin, cos, tan, atan2, pi\n    from sympy.abc import x, y\n    from sympy.core.exprtools import factor_nc\n\n    # issue 7915\n    assert factor_nc(sin(x + y)) == sin(x + y)\n    assert factor_nc(sin(x + y + pi/2)) == sin(x + y + pi/2)\n    assert factor_nc(sin(x + y + pi)) == sin(x + y + pi)\n    assert factor_nc(sin(x + y + pi/2 + pi)) == sin(x + y + pi)\n    assert factor_nc(sin(x + y + pi/2 + pi/2)) == sin(x + y + pi)\n    assert factor_nc(sin(x + y + pi/2 + pi/2 + pi)) == sin(x + y + pi)\n    assert factor_nc(sin(x + y + pi/2 + pi/2 + pi/2)) == sin(x + y + pi)\n    assert factor_nc(sin(x + y + pi/2 + pi/2 + pi/2 + pi)) == sin(x + y + pi)\n    assert factor_nc(sin(x + y + pi/2 + pi/2 + pi/2 + pi/2)) == sin(x + y + pi)\n    assert factor_nc(sin(x + y + pi/2 + pi/2 + pi/2 + pi/2 + pi)) == sin(x + y + pi)\n    assert factor_nc(sin(x + y + pi/2 + pi/2 + pi/2 + pi/2 + pi/2)) == sin(x + y + pi)\n    assert factor_nc(sin(x + y + pi/2 + pi/2 + pi/2 + pi/2 + pi/2 + pi)) == sin(x + y + pi)\n    assert factor_nc(sin(x + y + pi/2 + pi/2 + pi/2 + pi/2 + pi/2 + pi/2)) == sin(x + y + pi)\n    assert factor_nc(sin(x + y + pi/2 + pi/2 + pi/2 + pi/2 + pi/2 + pi/2 + pi)) == sin(x + y + pi)\n    assert factor_nc(sin(x + y + pi/2 + pi/2 + pi/2 + pi/2 + pi/2 + pi/2 + pi/"], "sample_861": ["def test_grid_search_with_sparse_target():\n    # Test that grid search works with sparse targets\n    X = np.arange(100).reshape(10, 10)\n    y = sp.csr_matrix(np.array([0] * 5 + [1] * 5))\n    Cs = [.1, 1, 10]\n\n    grid_search = GridSearchCV(LinearSVC(random_state=0), {'C': Cs})\n    grid_search.fit(X, y)\n    assert grid_search.best_score_ >= 0\n\n    y_pred = grid_search.predict(X)\n    assert np.mean(y_pred == y) >= 0.9\n\n    # test error is raised when the target is not array-like or sparse\n    assert_raises(ValueError, grid_search.fit, X, y.tolist())\n"], "sample_644": ["    def test_multiple_imports(self) -> None:\n        module = astroid.MANAGER.ast_from_module_name(\"multiple_imports\", REGR_DATA)\n        import_from = module.body[0]\n\n        msg = MessageTest(\n            msg_id=\"multiple-imports\",\n            node=import_from,\n            args=\"a, b\",\n            confidence=UNDEFINED,\n            line=1,\n            col_offset=0,\n            end_line=1,\n            end_col_offset=19,\n        )\n        with self.assertAddsMessages(msg):\n            self.checker.visit_importfrom(import_from)\n"], "sample_471": ["    def test_decimalfield_1(self):\n        f = DecimalField()\n        self.assertWidgetRendersTo(\n            f, '<input id=\"id_f\" name=\"f\" type=\"number\" required>'\n        )\n        with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):\n            f.clean(\"\")\n        with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):\n            f.clean(None)\n        self.assertEqual(1, f.clean(\"1\"))\n        self.assertIsInstance(f.clean(\"1\"), Decimal)\n        self.assertEqual(23, f.clean(\"23\"))\n        with self.assertRaisesMessage(ValidationError, \"'Enter a number.'\"):\n            f.clean(\"a\")\n        self.assertEqual(42, f.clean(42))\n        with self.assertRaisesMessage(ValidationError, \"'Enter a number.'\"):\n            f.clean(3.14)\n        self.assertEqual(1, f.clean(\"1 \"))\n        self.assertEqual(1, f.clean(\" 1\"))\n        self.assertEqual(1, f.clean(\" 1 \"))\n        with self.assertRaisesMessage(ValidationError, \"'Enter a number.'\"):\n            f.clean(\"1a\")\n        self.assertIsNone(f.max_value)\n        self.assertIsNone(f.min_value)\n        self.assertEqual(f.decimal_places, None)\n"], "sample_407": ["def test_save_related_object(self):\n    # Regression for #12190 -- Should be able to save a related object\n    # without having to save the parent object first.\n    parent = Parent.objects.create(name=\"Parent\")\n    child = Child.objects.create(name=\"Child\", parent=parent)\n    child.save()\n    self.assertEqual(child.parent, parent)\n    self.assertEqual(child.parent_id, parent.id)\n"], "sample_1017": ["def test_issue_10240():\n    assert Not(And(x > 2, x < 3)).as_set() == Union(Interval(-oo,2),Interval(3,oo))\n"], "sample_111": ["def test_distinct_for_m2m_in_list_filter_with_params(self):\n    \"\"\"\n    If a ManyToManyField is in list_filter and is in lookup params, the\n    changelist's query should have distinct.\n    \"\"\"\n    m = BandAdmin(Band, custom_site)\n    request = self.factory.get('/band/', data={'name': 'test', 'genres': '0'})\n    request.user = self.superuser\n    cl = m.get_changelist_instance(request)\n    self.assertTrue(cl.queryset.query.distinct)\n"], "sample_270": ["    def test_index_with_condition_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_partial_indexes'}\n                indexes = [\n                    models.Index(\n                        fields=['age'],\n                        name='index_age_gte_10',\n                        condition=models.Q(age__gte=10),\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n"], "sample_840": ["def test_pls_transform_copy():\n    # check that the \"copy\" keyword works\n    d = load_linnerud()\n    X = d.data\n    Y = d.target\n    clf = pls_.PLSCanonical()\n    X_copy = X.copy()\n    Y_copy = Y.copy()\n    clf.fit(X, Y)\n    # check that results are identical with copy\n    assert_array_almost_equal(clf.transform(X, Y), clf.transform(X.copy(), Y.copy(), copy=False))\n    # check that copy doesn't destroy\n    # we do want to check exact equality here\n    assert_array_equal(X_copy, X)\n    assert_array_equal(Y_copy, Y)\n    # also check that mean wasn't zero before (to make sure we didn't touch it)\n    assert np.all(X.mean(axis=0) != 0)\n"], "sample_986": ["def test_evalf_piecewise():\n    assert NS(Piecewise((1, x > 0), (0, x < 0)), 15) == '0.00000000000000'\n    assert NS(Piecewise((1, x > 0), (0, x < 0)), 20) == '0.00000000000000'\n    assert NS(Piecewise((1, x > 0), (0, x < 0)), 25) == '0.00000000000000'\n    assert NS(Piecewise((1, x > 0), (0, x < 0)), 30) == '0.00000000000000'\n    assert NS(Piecewise((1, x > 0), (0, x < 0)), 35) == '0.00000000000000'\n    assert NS(Piecewise((1, x > 0), (0, x < 0)), 40) == '0.00000000000000'\n    assert NS(Piecewise((1, x > 0), (0, x < 0)), 45) == '0.00000000000000'\n    assert NS(Piecewise((1, x > 0), (0, x < 0)), 50) == '0.00000000000000'\n    assert NS(Piecewise((1, x > 0), (0, x < 0)), 55) == '0.00000000000000'\n    assert NS(Piecewise((1, x > 0), (0, x < 0)), 60) == '0.00000000000000'\n    assert NS(Piecewise((1, x > 0), (0, x < 0)), 65) == '0.00000000000000'\n    assert NS(Piecewise((1, x > 0), (0, x < 0)), 70) == '0.00000000000000'\n    assert NS(Piecewise((1, x > 0), (0, x < 0)), 75) == '0.00000000000000'\n    assert NS(Piecewise((1, x > 0), (0, x < 0)), 80) == '0.00000000000000'\n    assert NS(Piecewise((1, x > "], "sample_526": ["def test_DateFormatter_usetex():\n    style.use(\"default\")\n    d1 = datetime.datetime(1997, 1, 1)\n    d2 = d1 + datetime.timedelta(days=40)\n    locator = mdates.AutoDateLocator(interval_multiples=True)\n    locator.create_dummy_axis()\n    locator.axis.set_view_interval(mdates.date2num(d1), mdates.date2num(d2))\n    formatter = mdates.DateFormatter('%Y-%m-%d', usetex=True)\n    assert formatter(d1) == r'$\\mathdefault{1997-01-01}$'\n    assert formatter(d2) == r'$\\mathdefault{1997-02-10}$'\n"], "sample_131": ["    def get_connection_copy(self):\n        # Get a copy of the default connection. (Can't use django.db.connection\n        # because it'll modify the default connection itself.)\n        test_connection = copy.copy(connections[DEFAULT_DB_ALIAS])\n        test_connection.settings_dict = copy.copy(connections[DEFAULT_DB_ALIAS].settings_dict)\n        return test_connection\n"], "sample_957": ["def test_stringify_type_hints_Annotated():\n    from typing import Annotated  # type: ignore\n    assert stringify(Annotated[int, \"foo\", \"bar\"]) == \"int\"  # NOQA\n"], "sample_910": ["def test_message_prefix_filter(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    logger.warning('message1')\n    with prefixed_warnings('PREFIX:'):\n        logger.warning('message2')\n        with prefixed_warnings('Another PREFIX:'):\n            logger.warning('message3')\n        logger.warning('message4')\n    logger.warning('message5')\n\n    assert 'WARNING: message1' in warning.getvalue()\n    assert 'WARNING: PREFIX: message2' in warning.getvalue()\n    assert 'WARNING: Another PREFIX: message3' in warning.getvalue()\n    assert 'WARNING: PREFIX: message4' in warning.getvalue()\n    assert 'WARNING: message5' in warning.getvalue()\n\n    # test reset prefix\n    logger.warning('message6')\n    with prefixed_warnings('PREFIX:'):\n        logger.warning('message7')\n    assert 'WARNING: message6' in warning.getvalue()\n    assert 'WARNING: PREFIX: message7' in warning.getvalue()\n\n    # test prefix filter with info log\n    logger.info('message8')\n    with prefixed_warnings('PREFIX:'):\n        logger.info('message9')\n    assert 'message8' in status.getvalue()\n    assert 'PREFIX: message9' in status.getvalue()\n\n    # test prefix filter with debug log\n    logger.debug('message10')\n    with prefixed_warnings('PREFIX:'):\n        logger.debug('message11')\n    assert 'message10' in status.getvalue()\n    assert 'PREFIX: message11' in status.getvalue()\n\n    # test prefix filter with critical log\n    logger.critical('message12')\n    with prefixed_warnings('PREFIX:'):\n        logger.critical('message13')\n    assert 'message12' in status.getvalue()\n    assert 'PREFIX: message13' in status.getvalue()\n\n    # test prefix filter with error log\n    logger.error('message14')\n    with prefixed_warnings('PREFIX:'):\n        logger.error('message15')\n    assert 'message14' in status.getvalue()\n    assert 'PREFIX: message15' in status.getvalue()\n"], "sample_979": ["def test_matrix_element_subs():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', n, n)\n    E = MatrixSymbol('E', m, n)\n    w = MatrixSymbol('w', n, 1)\n\n    assert (A[0, 0]).subs(n, m) == A[m, 0]\n    assert (A[0, 0]).subs(m, l) == A[0, l]\n    assert (A[0, 0]).subs(A, B) == B[0, 0]\n\n    assert (A[0, 0]).subs(n, m).subs(m, l) == A[l, l]\n    assert (A[0, 0]).subs(n, m).subs(A, B) == B[m, 0]\n\n    assert (A[0, 0]).subs(n, m).subs(m, l).subs(A, B) == B[l, 0]\n\n    assert (A[0, 0]).subs(n, m).subs(m, l).subs(B, C) == C[l, 0]\n\n    assert (A[0, 0]).subs(n, m).subs(m, l).subs(A, B).subs(B, C) == C[l, 0]\n\n    assert (A[0, 0]).subs(n, m).subs(m, l).subs(A, B).subs(B, C).subs(C, D) == D[l, 0]\n\n    assert (A[0, 0]).subs(n, m).subs(m, l).subs(A, B).subs(B, C).subs(C, D).subs(D, E) == E[l, 0]\n\n    assert (A[0, 0]).subs(n, m).subs(m, l).subs(A, B).subs(B, C).subs(C, D).subs(D, E).subs(E, w) == w[l, 0]\n"], "sample_506": ["def test_spine_bounds():\n    fig, ax = plt.subplots()\n    ax.spines.left.set_bounds(0, 1)\n    assert ax.spines.left.get_bounds() == (0, 1)\n    ax.spines.left.set_bounds(1, 2)\n    assert ax.spines.left.get_bounds() == (1, 2)\n    ax.spines.left.set_bounds(0, 0)\n    assert ax.spines.left.get_bounds() == (0, 1)\n\n    ax.spines.right.set_bounds(0, 1)\n    assert ax.spines.right.get_bounds() == (0, 1)\n    ax.spines.right.set_bounds(1, 2)\n    assert ax.spines.right.get_bounds() == (1, 2)\n    ax.spines.right.set_bounds(0, 0)\n    assert ax.spines.right.get_bounds() == (0, 1)\n\n    ax.spines.top.set_bounds(0, 1)\n    assert ax.spines.top.get_bounds() == (0, 1)\n    ax.spines.top.set_bounds(1, 2)\n    assert ax.spines.top.get_bounds() == (1, 2)\n    ax.spines.top.set_bounds(0, 0)\n    assert ax.spines.top.get_bounds() == (0, 1)\n\n    ax.spines.bottom.set_bounds(0, 1)\n    assert ax.spines.bottom.get_bounds() == (0, 1)\n    ax.spines.bottom.set_bounds(1, 2)\n    assert ax.spines.bottom.get_bounds() == (1, 2)\n    ax.spines.bottom.set_bounds(0, 0)\n    assert ax.spines.bottom.get_bounds() == (0, 1)\n\n    ax.spines.left.set_bounds(None, 1)\n    assert ax.spines.left.get_bounds() == (0, 1)\n    ax.spines.left.set_bounds(1, None)\n    assert ax.spines.left.get_bounds() == (1, 2)\n    ax.spines.left.set_bounds(None, None)\n    assert ax.spines.left.get_bounds() == (0, 1)\n\n    ax.spines.right.set_bounds(None, 1)\n    assert ax.spines.right.get_bounds() == (0, 1)\n    ax.spines.right.set_bounds(1, None)\n    assert ax.spines.right.get_bounds() == (1, 2)\n    ax.spines.right.set_bounds(None"], "sample_665": ["    def test_collecting_function_definition(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n                pass\n        \"\"\"\n        )\n        items, reprec = testdir.inline_genitems(p)\n        assert len(items) == 1\n        item, = items\n        assert item.name == \"test_func\"\n        assert item.originalname == \"test_func\"\n"], "sample_125": ["    def test_set_cookie_with_domain(self):\n        \"\"\"set_cookie() accepts a domain for the cookie.\"\"\"\n        response = HttpResponse()\n        response.set_cookie('example', domain='example.com')\n        example_cookie = response.cookies['example']\n        self.assertEqual(example_cookie['domain'], 'example.com')\n"], "sample_656": ["    def test_capture_is_represented_on_failure_issue128(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\\\n                print(\"xxx42xxx\")\n                assert 0\n            \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"xxx42xxx\"])\n"], "sample_1182": ["def test_issue_12345():\n    from sympy.functions.elementary.integers import floor\n    from sympy.functions.elementary.exponential import exp\n\n    expr = floor(exp(x))\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr) == 'numpy.floor(numpy.exp(x))'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr) == 'numpy.floor(numpy.exp(x))'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr) == 'math.floor(math.exp(x))'\n\n    prntr = MpmathPrinter()\n    assert prntr.doprint(expr) == 'mpmath.floor(mpmath.exp(x))'\n\n    prntr = SymPyPrinter()\n    assert prntr.doprint(expr) == 'sympy.floor(sympy.exp(x))'\n"], "sample_1104": ["def test_Derivative_with_multiple_variables():\n    from sympy import symbols, sin, cos, Derivative\n    x, y = symbols('x y')\n    assert str(Derivative(sin(x + y), (x, y))) == \"Derivative(sin(x + y), (x, y))\"\n"], "sample_1102": ["def test_Poly__new__():\n    raises(GeneratorsError, lambda: Poly(x + y, x, y, z))\n    raises(GeneratorsError, lambda: Poly(x + y, x, y, domain=ZZ[y]))\n    raises(GeneratorsError, lambda: Poly(x + y, y, x, domain=ZZ[y]))\n\n    raises(OptionError, lambda: Poly(x + 2, x, symmetric=True))\n    raises(OptionError, lambda: Poly(x + 2, x, modulus=3, domain=QQ))\n\n    raises(OptionError, lambda: Poly(x + 2, x, domain=ZZ, gaussian=True))\n    raises(OptionError, lambda: Poly(x + 2, x, modulus=3, gaussian=True))\n\n    raises(OptionError, lambda: Poly(x + 2, x, domain=ZZ, extension=[sqrt(3)]))\n    raises(OptionError, lambda: Poly(x + 2, x, modulus=3, extension=[sqrt(3)]))\n\n    raises(OptionError, lambda: Poly(x + 2, x, domain=ZZ, extension=True))\n    raises(OptionError, lambda: Poly(x + 2, x, modulus=3, extension=True))\n\n    raises(OptionError, lambda: Poly(x + 2, x, domain=ZZ, greedy=True))\n    raises(OptionError, lambda: Poly(x + 2, x, domain=QQ, field=True))\n\n    raises(OptionError, lambda: Poly(x + 2, x, domain=ZZ, greedy=False))\n    raises(OptionError, lambda: Poly(x + 2, x, domain=QQ, field=False))\n\n    raises(NotImplementedError, lambda: Poly(x + 1, x, modulus=3, order='grlex'))\n    raises(NotImplementedError, lambda: Poly(x + 1, x, order='grlex'))\n\n    raises(GeneratorsNeeded, lambda: Poly({1: 2, 0: 1}))\n    raises(GeneratorsNeeded, lambda: Poly([2, 1]))\n    raises(GeneratorsNeeded, lambda: Poly((2, 1)))\n\n    raises(GeneratorsNeeded, lambda: Poly(1))\n\n    f = a*x**2 + b*x + c\n\n    assert Poly({2: a, 1: b, 0: c}, x)"], "sample_1084": ["def test_ProductSet():\n    from sympy.sets.fancysets import ProductSet\n    from sympy.sets.sets import FiniteSet\n    from sympy import symbols\n\n    a, b, c = symbols('a b c')\n    assert ProductSet(FiniteSet(1, 2), FiniteSet(3, 4)) == \\\n        FiniteSet((1, 3), (1, 4), (2, 3), (2, 4))\n    assert ProductSet(FiniteSet(1, 2), FiniteSet(3, 4, 5)) == \\\n        FiniteSet((1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5))\n    assert ProductSet(FiniteSet(1, 2), FiniteSet(3, 4, 5, 6)) == \\\n        FiniteSet((1, 3), (1, 4), (1, 5), (1, 6), (2, 3), (2, 4), (2, 5), (2, 6))\n    assert ProductSet(FiniteSet(1, 2), FiniteSet(3, 4, 5, 6, 7)) == \\\n        FiniteSet((1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7))\n    assert ProductSet(FiniteSet(1, 2), FiniteSet(3, 4, 5, 6, 7, 8)) == \\\n        FiniteSet((1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8))\n    assert ProductSet(FiniteSet(1, 2), FiniteSet(3, 4, 5, 6, 7, 8, 9)) == \\\n        FiniteSet((1, 3), (1, 4), (1, 5),"], "sample_405": ["def test_rename_field_with_unique_together(self):\n    \"\"\"\n    Tests the RenameField operation with a unique_together constraint.\n    \"\"\"\n    project_state = self.set_up_test_model(\"test_rnflut\", unique_together=True)\n    operation = migrations.RenameField(\"Pony\", \"pink\", \"blue\")\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_rnflut\", new_state)\n    # unique_together has the renamed column.\n    self.assertIn(\n        \"blue\",\n        new_state.models[\"test_rnflut\", \"pony\"].options[\"unique_together\"][0],\n    )\n    self.assertNotIn(\n        \"pink\",\n        new_state.models[\"test_rnflut\", \"pony\"].options[\"unique_together\"][0],\n    )\n    # Rename field.\n    self.assertColumnExists(\"test_rnflut_pony\", \"pink\")\n    self.assertColumnNotExists(\"test_rnflut_pony\", \"blue\")\n    with connection.schema_editor() as editor:\n        operation.database_forwards(\"test_rnflut\", editor, project_state, new_state)\n    self.assertColumnExists(\"test_rnflut_pony\", \"blue\")\n    self.assertColumnNotExists(\"test_rnflut_pony\", \"pink\")\n    # The unique constraint has been ported over.\n    with connection.cursor() as cursor:\n        cursor.execute(\"INSERT INTO test_rnflut_pony (blue, weight) VALUES (1, 1)\")\n        with self.assertRaises(IntegrityError):\n            with atomic():\n                cursor.execute(\n                    \"INSERT INTO test_rnflut_pony (blue, weight) VALUES (1, 1)\"\n                )\n        cursor.execute(\"DELETE FROM test_rnflut_pony\")\n    # Reversal.\n    with connection.schema_editor() as editor:\n        operation.database_backwards(\n            \"test_rnflut\", editor, new_state, project_state\n        )\n    self.assertColumnExists(\"test_rnflut_pony\", \"pink\")\n    self.assertColumnNotExists(\"test_rnflut_pony\", \"blue\")\n    # And deconstruction.\n    definition = operation.deconstruct()\n    self.assertEqual(definition[0], \"RenameField\")\n    self.assertEqual(definition[1], [])\n    self.assertEqual(\n        definition[2],\n        {\"model_name\": \"Pony\", \"old_name\": \"pink"], "sample_424": ["def test_rename_field_with_unique_together(self):\n    \"\"\"\n    Tests the RenameField operation with a unique_together constraint.\n    \"\"\"\n    project_state = self.set_up_test_model(\"test_rnflut\", unique_together=True)\n    operation = migrations.RenameField(\"Pony\", \"pink\", \"blue\")\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_rnflut\", new_state)\n    # unique_together has the renamed column.\n    self.assertIn(\n        \"blue\",\n        new_state.models[\"test_rnflut\", \"pony\"].options[\"unique_together\"][0],\n    )\n    self.assertNotIn(\n        \"pink\",\n        new_state.models[\"test_rnflut\", \"pony\"].options[\"unique_together\"][0],\n    )\n    # Rename field.\n    self.assertColumnExists(\"test_rnflut_pony\", \"pink\")\n    self.assertColumnNotExists(\"test_rnflut_pony\", \"blue\")\n    with connection.schema_editor() as editor:\n        operation.database_forwards(\"test_rnflut\", editor, project_state, new_state)\n    self.assertColumnExists(\"test_rnflut_pony\", \"blue\")\n    self.assertColumnNotExists(\"test_rnflut_pony\", \"pink\")\n    # The unique constraint has been ported over.\n    with connection.cursor() as cursor:\n        cursor.execute(\"INSERT INTO test_rnflut_pony (blue, weight) VALUES (1, 1)\")\n        with self.assertRaises(IntegrityError):\n            with atomic():\n                cursor.execute(\n                    \"INSERT INTO test_rnflut_pony (blue, weight) VALUES (1, 1)\"\n                )\n        cursor.execute(\"DELETE FROM test_rnflut_pony\")\n    # Reversal.\n    with connection.schema_editor() as editor:\n        operation.database_backwards(\n            \"test_rnflut\", editor, new_state, project_state\n        )\n    self.assertColumnExists(\"test_rnflut_pony\", \"pink\")\n    self.assertColumnNotExists(\"test_rnflut_pony\", \"blue\")\n    # And deconstruction.\n    definition = operation.deconstruct()\n    self.assertEqual(definition[0], \"RenameField\")\n    self.assertEqual(definition[1], [])\n    self.assertEqual(\n        definition[2],\n        {\"model_name\": \"Pony\", \"old_name\": \"pink"], "sample_114": ["def test_alter_field_to_fk_dependency_other_app(self):\n    \"\"\"\n    #23100 - ForeignKeys correctly depend on other apps' models.\n    \"\"\"\n    changes = self.get_changes([self.author_empty, self.book], [self.author_with_book, self.book])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"book\")\n    self.assertMigrationDependencies(changes, 'testapp', 0, [(\"otherapp\", \"__first__\")])\n"], "sample_149": ["    def test_builtin_permission_name_max_length(self):\n        class Checked(models.Model):\n            class Meta:\n                permissions = [\n                    ('my_builtin_permission', 'Some permission'),\n                ]\n        errors = checks.run_checks(self.apps.get_app_configs())\n        max_builtin_permission_name_length = (\n            max(len(name) for name in _get_builtin_permissions(Checked._meta).values())\n            if _get_builtin_permissions(Checked._meta) else 0\n        )\n        self.assertEqual(max_builtin_permission_name_length, 255)\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most 255 - %d characters \"\n                \"for its builtin permission names to be at most 255 characters.\" % max_builtin_permission_name_length,\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n"], "sample_66": ["    def test_querydict_fromkeys(self):\n        q = QueryDict.fromkeys(['a', 'b', 'c'], 'value', mutable=True)\n        self.assertEqual(q, {'a': ['value'], 'b': ['value'], 'c': ['value']})\n"], "sample_1177": ["def test_issue_19627():\n    x = Symbol('x')\n    assert Abs(im(acos(-I + acosh(-x + I))).doit()) == 1\n"], "sample_11": ["def test_dropped_dimensions_2d():\n    wcs = WCS_SPECTRAL_CUBE\n\n    sub = SlicedLowLevelWCS(wcs, np.s_[0, :])\n\n    dwd = sub.dropped_world_dimensions\n    wao_classes = dwd.pop(\"world_axis_object_classes\")\n    validate_info_dict(dwd, {\n        \"value\": [12.86995801],\n        \"world_axis_physical_types\": [\"pos.galactic.lat\"],\n        \"world_axis_names\": [\"Latitude\"],\n        \"world_axis_units\": [\"deg\"],\n        \"serialized_classes\": False,\n        \"world_axis_object_components\": [('celestial', 1, 'spherical.lat.degree')],\n        })\n\n    assert wao_classes['celestial'][0] is SkyCoord\n    assert wao_classes['celestial'][1] == ()\n    assert isinstance(wao_classes['celestial'][2]['frame'], Galactic)\n    assert wao_classes['celestial'][2]['unit'] is u.deg\n\n    sub = SlicedLowLevelWCS(wcs, np.s_[5, :])\n\n    dwd = sub.dropped_world_dimensions\n    wao_classes = dwd.pop(\"world_axis_object_classes\")\n    validate_info_dict(dwd, {\n        \"value\": [11.67648267],\n        \"world_axis_physical_types\": [\"pos.galactic.lat\"],\n        \"world_axis_names\": [\"Latitude\"],\n        \"world_axis_units\": [\"deg\"],\n        \"serialized_classes\": False,\n        \"world_axis_object_components\": [('celestial', 1, 'spherical.lat.degree')],\n        })\n\n    assert wao_classes['celestial'][0] is SkyCoord\n    assert wao_classes['celestial'][1] == ()\n    assert isinstance(wao_classes['celestial'][2]['frame'], Galactic)\n    assert wao_classes['celestial'][2]['unit'] is u.deg\n\n    sub = SlicedLowLevelWCS(wcs, np.s_[0, 0])\n\n    dwd = sub.dropped_world_dimensions\n    wao_classes = dwd.pop(\"world_axis_object_classes\")\n    validate_info_dict(dwd, {\n        \"value\": [12.86995801],\n        \"world_axis_physical_types\": [\"pos.galactic.lat\"],\n        \"world_axis_names\": [\"Latitude\"],\n        \"world_axis_units\": [\"deg\"],\n        \"serialized_classes\": False,\n        \"world_axis_object_components\": [('celestial', 1, 'spherical.lat.degree')],\n       "], "sample_717": ["def test_load_lfw_people_with_resize():\n    lfw_people = fetch_lfw_people(data_home=SCIKIT_LEARN_DATA,\n                                  resize=0.25,\n                                  download_if_missing=False)\n\n    # The data is croped around the center as a rectangular bounding box\n    # around the face. Colors are converted to gray levels:\n    assert_equal(lfw_people.images.shape, (10, 31, 23))\n    assert_equal(lfw_people.data.shape, (10, 1081))\n\n    # the target is array of person integer ids\n    assert_array_equal(lfw_people.target, [2, 0, 1, 0, 2, 0, 2, 1, 1, 2])\n\n    # names of the persons can be found using the target_names array\n    expected_classes = ['Abdelatif Smith', 'Abhati Kepler', 'Onur Lopez']\n    assert_array_equal(lfw_people.target_names, expected_classes)\n\n    # It is possible to ask for the original data without any croping or color\n    # conversion and not limit on the number of picture per person\n    lfw_people = fetch_lfw_people(data_home=SCIKIT_LEARN_DATA, resize=0.25,\n                                  slice_=None, color=True,\n                                  download_if_missing=False)\n    assert_equal(lfw_people.images.shape, (17, 250, 250, 3))\n\n    # the ids and class names are the same as previously\n    assert_array_equal(lfw_people.target,\n                       [0, 0, 1, 6, 5, 6, 3, 6, 0, 3, 6, 1, 2, 4, 5, 1, 2])\n    assert_array_equal(lfw_people.target_names,\n                       ['Abdelatif Smith', 'Abhati Kepler', 'Camara Alvaro',\n                        'Chen Dupont', 'John Lee', 'Lin Bauman', 'Onur Lopez'])\n"], "sample_31": ["def test_write_latex_cosmology_in_meta(self, write, tmp_path, format):\n    \"\"\"Test that cosmology_in_meta is False.\"\"\"\n    fp = tmp_path / \"test_write_latex_cosmology_in_meta.tex\"\n    write(fp, format=format, cosmology_in_meta=True)\n    tbl = QTable.read(fp)\n    assert not tbl.meta.get(\"cosmology_in_meta\")\n"], "sample_160": ["def test_format_large_decimal(self):\n    # Test large decimal numbers.\n    large_decimal = Decimal('1.234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012"], "sample_848": ["def test_multioutput_regressor_sample_weights():\n    # weighted regressor\n    Xw = [[1, 2, 3], [4, 5, 6]]\n    yw = [[3.141, 2.718], [2.718, 3.141]]\n    w = np.asarray([2., 1.])\n    rgr_w = MultiOutputRegressor(GradientBoostingRegressor(random_state=0))\n    rgr_w.fit(Xw, yw, w)\n\n    # unweighted, but with repeated samples\n    X = [[1, 2, 3], [1, 2, 3], [4, 5, 6]]\n    y = [[3.141, 2.718], [3.141, 2.718], [2.718, 3.141]]\n    rgr = MultiOutputRegressor(GradientBoostingRegressor(random_state=0))\n    rgr.fit(X, y)\n\n    X_test = [[1.5, 2.5, 3.5], [3.5, 4.5, 5.5]]\n    assert_almost_equal(rgr.predict(X_test), rgr_w.predict(X_test))\n"], "sample_140": ["    def test_sensitive_variables_decorator_preserves_function_signature(self):\n        \"\"\"\n        The sensitive_variables decorator should preserve the function signature.\n        \"\"\"\n        @sensitive_variables('password')\n            pass\n\n        self.assertEqual(inspect.signature(test_func), inspect.signature(lambda password: None))\n"], "sample_675": ["def test_log_cli_format(testdir):\n    # Default log file level\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_handler.level == logging.INFO\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            logging.getLogger('catchlog').warning(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n        log_cli_format = %(asctime)s - %(levelname)s - %(message)s\n    \"\"\"\n    )\n\n    result = testdir.runpytest(\"-s\", \"--log-cli-level=INFO\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_log_cli_format.py*2024-07-26 14:30:00,000 - INFO - This log message will be shown\",\n            \"PASSED\",  # 'PASSED' on its own line because the log message prints a new line\n        ]\n    )\n    result.stdout.no_fnmatch_line(\"*This log message won't be shown*\")\n\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n"], "sample_661": ["def test_record_testsuite_property_multiple_calls(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", \"all good\")\n\n            record_testsuite_property(\"stats\", 10)\n            record_testsuite_property(\"stats\", 20)\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p2_node = properties_node.find_nth_by_tag(\"property\", 1)\n    p3_node = properties_node.find_nth_by_tag(\"property\", 2)\n    p1_node.assert_attr(name=\"stats\", value=\"all good\")\n    p2_node.assert_attr(name=\"stats\", value=\"10\")\n    p3_node.assert_attr(name=\"stats\", value=\"20\")\n"], "sample_468": ["def test_context_processors(self):\n    \"\"\"\n    Test that context processors are called with the correct request object.\n    \"\"\"\n    request = self.request_factory.get(\"/\")\n    context = RequestContext(request, {})\n    context._processors = (context_process_returning_none,)\n\n    with self.assertRaises(TypeError):\n        with context.bind_template(Template(\"\")):\n            pass\n\n    # Test that context processors are called with the correct request object\n    with self.assertRaises(TypeError):\n        with context.bind_template(Template(\"\")):\n            pass\n\n    # Test that context processors are called with the correct request object\n    # when using the 'processors' keyword argument\n    context = RequestContext(request, processors=(context_process_returning_none,))\n    with self.assertRaises(TypeError):\n        with context.bind_template(Template(\"\")):\n            pass\n"], "sample_816": ["def test_hashingvectorizer_dtype():\n    # Non-regression test: HashingVectorizer used to ignore its \"dtype\" param.\n    v = HashingVectorizer(dtype=np.float32)\n    assert v.dtype == np.float32\n\n    X = v.transform(['hello world', 'hello hello']).toarray()\n    assert X.dtype == np.float32\n\n    # Check that the ability to change the dtype\n    v = HashingVectorizer(dtype=np.float64)\n    X = v.transform(['hello world', 'hello hello']).toarray()\n    assert X.dtype == np.float64\n"], "sample_261": ["    def test_parse_iso_8601_with_decimal_seconds(self):\n        test_values = (\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n            ('P4D', timedelta(days=4)),\n"], "sample_257": ["    def test_nested_key_transform_annotation_expression_with_subquery(self):\n        obj = NullableJSONModel.objects.create(value={'d': ['e', {'f': 'g'}, {'f': 'g'}]})\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__d__0__isnull=False).annotate(\n                subquery_value=Subquery(\n                    NullableJSONModel.objects.filter(pk=OuterRef('pk')).values('value')\n                ),\n                key=F('subquery_value__d'),\n                chain=F('key__1__f'),\n                expr=Cast('key', models.JSONField()),\n            ).filter(chain=F('expr__2__f')),\n            [obj],\n        )\n"], "sample_1144": ["def test_requires_partial_multiple_derivatives():\n    x, y, z = symbols('x y z')\n    f = x * y * z\n    assert requires_partial(Derivative(Derivative(f, x), y)) is True\n    assert requires_partial(Derivative(Derivative(f, y), x)) is True\n    assert requires_partial(Derivative(Derivative(f, z), x)) is True\n    assert requires_partial(Derivative(Derivative(f, z), y)) is True\n    assert requires_partial(Derivative(Derivative(f, z), z)) is False\n\n    f = x ** 2 * y ** 3 * z ** 4\n    assert requires_partial(Derivative(Derivative(f, x), y)) is True\n    assert requires_partial(Derivative(Derivative(f, y), x)) is True\n    assert requires_partial(Derivative(Derivative(f, z), x)) is True\n    assert requires_partial(Derivative(Derivative(f, z), y)) is True\n    assert requires_partial(Derivative(Derivative(f, z), z)) is False\n\n    f = x * y * z * exp(x * y * z)\n    assert requires_partial(Derivative(Derivative(f, x), y)) is True\n    assert requires_partial(Derivative(Derivative(f, y), x)) is True\n    assert requires_partial(Derivative(Derivative(f, z), x)) is True\n    assert requires_partial(Derivative(Derivative(f, z), y)) is True\n    assert requires_partial(Derivative(Derivative(f, z), z)) is False\n"], "sample_198": ["    def setUpTestData(cls):\n        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.gmbh = Company.objects.create(name='Test GmbH', num_employees=32, num_chairs=1, ceo=cls.max)\n"], "sample_720": ["def test_power_transformer_axis1():\n    X = np.abs(X_2d)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method='box-cox', standardize=standardize)\n\n        X_trans_class = pt.fit_transform(X.T)\n        X_trans_func = power_transform(X.T, standardize=standardize)\n\n        for X_trans in [X_trans_class, X_trans_func]:\n            for i in range(X_trans.shape[1]):\n                X_expected, lmbda = stats.boxcox(X[:, i].flatten())\n\n                if standardize:\n                    X_expected = scale(X_expected)\n\n                assert_almost_equal(X_trans[:, i], X_expected)\n                assert_almost_equal(lmbda, pt.lambdas_[i])\n\n            # Test inverse transformation\n            X_inv = pt.inverse_transform(X_trans)\n            assert_array_almost_equal(X_inv, X.T)\n\n        assert len(pt.lambdas_) == X.shape[1]\n        assert isinstance(pt.lambdas_, np.ndarray)\n"], "sample_404": ["    def test_render_variable_error(self):\n        \"\"\"\n        # 16770 -- The template system doesn't wrap exceptions, but annotates\n        them.\n        \"\"\"\n        engine = self._engine()\n        c = Context({\"coconuts\": lambda: 42 / 0})\n        t = engine.from_string(\"{{ coconuts }}\")\n\n        with self.assertRaises(ZeroDivisionError) as e:\n            t.render(c)\n\n        if self.debug_engine:\n            debug = e.exception.template_debug\n            self.assertEqual(debug[\"start\"], 0)\n            self.assertEqual(debug[\"end\"], 14)\n"], "sample_677": ["def test_not_precedence(expr: str, expected: bool) -> None:\n    matcher = {\"true\": True, \"false\": False}.__getitem__\n    assert evaluate(expr, matcher) is expected\n"], "sample_397": ["def test_libraries_pathlib(self):\n    engine = DjangoTemplates(\n        {\n            \"DIRS\": [],\n            \"APP_DIRS\": False,\n            \"NAME\": \"django\",\n            \"OPTIONS\": {\n                \"libraries\": {\n                    \"alternate\": (\n                        Path(__file__).parent / \"template_backends\" / \"templatetags\" / \"good_tags.py\"\n                    ),\n                },\n            },\n        }\n    )\n\n    self.assertEqual(\n        engine.engine.libraries[\"good_tags\"],\n        Path(__file__).parent / \"template_backends\" / \"templatetags\" / \"good_tags.py\",\n    )\n"], "sample_406": ["    def test_manager_method_signature_with_defaults(self):\n        self.assertEqual(\n            str(inspect.signature(Article.objects.bulk_create)),\n            \"(objs, batch_size=None, ignore_conflicts=False, update_conflicts=False, \"\n            \"update_fields=None, unique_fields=None)\",\n        )\n        self.assertEqual(\n            str(inspect.signature(Article.objects.bulk_update)),\n            \"(queryset, fields=None, update_fields=None, batch_size=None)\",\n        )\n        self.assertEqual(\n            str(inspect.signature(Article.objects.update_or_create)),\n            \"(lookup, defaults=None, update_fields=None, batch_size=None)\",\n        )\n        self.assertEqual(\n            str(inspect.signature(Article.objects.get_or_create)),\n            \"(lookup, defaults=None, create=False, update_fields=None, batch_size=None)\",\n        )\n"], "sample_785": ["def test_train_test_split_with_sparse_input():\n    # Check that train_test_split converts scipy sparse matrices\n    # to csr, as stated in the documentation\n    X = np.arange(100).reshape((10, 10))\n    sparse_types = [csr_matrix, csc_matrix, coo_matrix]\n    for InputFeatureType in sparse_types:\n        X_s = InputFeatureType(X)\n        X_train, X_test = train_test_split(X_s)\n        assert isinstance(X_train, csr_matrix)\n        assert isinstance(X_test, csr_matrix)\n"], "sample_1207": ["def test_lambda_notation():\n    x = Symbol('x')\n    assert parse_expr('lambda x: x') == Lambda(x, x)\n    assert parse_expr('lambda x: x + 1') == Lambda(x, x + 1)\n    assert parse_expr('lambda x, y: x + y') == Lambda(x, Lambda(y, x + y))\n    assert parse_expr('lambda x: x + lambda y: y') == Lambda(x, x + Lambda(y, y))\n    assert parse_expr('lambda x: x + lambda y: y + lambda z: z') == Lambda(x, x + Lambda(y, y + Lambda(z, z)))\n    assert parse_expr('lambda x: x + lambda y: y + lambda z: z + lambda w: w') == Lambda(x, x + Lambda(y, y + Lambda(z, z + Lambda(w, w))))\n    assert parse_expr('lambda x: x + lambda y: y + lambda z: z + lambda w: w + lambda v: v') == Lambda(x, x + Lambda(y, y + Lambda(z, z + Lambda(w, w + Lambda(v, v)))))\n    assert parse_expr('lambda x: x + lambda y: y + lambda z: z + lambda w: w + lambda v: v + lambda u: u') == Lambda(x, x + Lambda(y, y + Lambda(z, z + Lambda(w, w + Lambda(v, v + Lambda(u, u))))))\n"], "sample_760": ["def test_make_scorer_needs_proba():\n    # Test that make_scorer raises an error when both needs_proba and\n    # needs_threshold are set to True.\n    scorer = make_scorer(roc_auc_score, needs_proba=True, needs_threshold=True)\n    assert_raises(ValueError, scorer, LogisticRegression(), [[1]], [1])\n"], "sample_652": ["    def test_getfixturevalue(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n                return 1\n\n                assert arg1 == 1\n        \"\"\"\n        )\n        reprec = testdir.inline_run()\n        reprec.assertoutcome(passed=1)\n"], "sample_1074": ["def test_is_abelian():\n    # the center of an abelian group is the group itself\n    for i in (1, 2, 3):\n        for j in (1, 5, 7):\n            for k in (1, 1, 11):\n                G = AbelianGroup(i, j, k)\n                assert G.center().is_subgroup(G)\n    # the center of a nonabelian simple group is trivial\n    for i in(1, 5, 9):\n        A = AlternatingGroup(i)\n        assert (A.center()).order() == 1\n    # brute-force verifications\n    D = DihedralGroup(5)\n    A = AlternatingGroup(3)\n    C = CyclicGroup(4)\n    G.is_subgroup(D*A*C)\n    assert _verify_centralizer(G, G)\n"], "sample_113": ["    def test_field_description(self):\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.EmailField()),\n            'Email address'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.URLField()),\n            'URL'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.IPAddressField()),\n            'IP address'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.GenericIPAddressField()),\n            'IP address'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.FileField()),\n            'File'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.ImageField()),\n            'Image'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.BinaryField()),\n            'Binary data'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.TextField()),\n            'Text'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.CharField()),\n            'Text'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.SmallIntegerField()),\n            'Small integer'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.IntegerField()),\n            'Integer'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.BigIntegerField()),\n            'Large integer'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.FloatField()),\n            'Float'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.DecimalField()),\n            'Decimal'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.DateTimeField()),\n            'Date and time'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.DateField()),\n            'Date'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.TimeField()),\n            'Time'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.DurationField()),\n            'Duration'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.SlugField()),\n            'Slug'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.UUIDField()),\n            'UUID'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.BooleanField()),\n            'Boolean (Either True or False)'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.NullBooleanField()),\n            'Boolean (Either True or False)'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.CommaSeparatedIntegerField()),\n            '"], "sample_1003": ["def test_BuildOptions():\n    opt = Options((x, y, z), {'domain': 'ZZ'})\n\n    assert opt.gens == (x, y, z)\n    assert opt.domain == ZZ\n    assert ('order' in opt) is False\n\n    new_opt = build_options((x, y, z), {'domain': 'ZZ'})\n\n    assert new_opt.gens == (x, y, z)\n    assert new_opt.domain == ZZ\n    assert ('order' in new_opt) is False\n\n    assert new_opt is not opt\n\n    assert build_options((x, y, z), {'domain': 'ZZ', 'order': 'lex'}) == \\\n        Options((x, y, z), {'domain': 'ZZ', 'order': 'lex'})\n\n    assert build_options((x, y, z), {'opt': {'domain': 'ZZ', 'order': 'lex'}}) == \\\n        Options((x, y, z), {'domain': 'ZZ', 'order': 'lex'})\n\n    raises(OptionError, lambda: build_options((x, y, z), {'gens': (x, y, z)}))\n    raises(OptionError, lambda: build_options((x, y, z), {'gens': (x, y, z), 'opt': {'domain': 'ZZ'}}))\n"], "sample_629": ["def test_expand_modules_empty_input():\n    ignore_list, ignore_list_re, ignore_list_paths_re = [], [], []\n    modules, errors = expand_modules(files_or_modules=[], ignore_list=ignore_list, ignore_list_re=ignore_list_re, ignore_list_paths_re=ignore_list_paths_re)\n    assert modules == []\n    assert not errors\n"], "sample_89": ["    def test_module_with_spec_has_location(self):\n        module = types.ModuleType('test_module')\n        module.__spec__ = importlib.util.spec_from_file_location('test_module', 'test_module.py')\n        module.__spec__.loader = importlib.machinery.SourceFileLoader('test_module', 'test_module.py')\n        module.__spec__.has_location = True\n        self.assertIn('test_module.py', list(autoreload.iter_modules_and_files((module,), frozenset())))\n"], "sample_59": ["    def test_related_gt_lookup(self):\n        \"\"\"\n        Regression test for #10153: foreign key __gt lookups.\n        \"\"\"\n        Worker.objects.filter(department__gt=0)\n"], "sample_411": ["def test_handle_default_options(self):\n    \"\"\"\n    handle_default_options() should set DJANGO_SETTINGS_MODULE and sys.path\n    correctly.\n    \"\"\"\n    with mock.patch.dict(\"os.environ\", {\"DJANGO_SETTINGS_MODULE\": None}):\n        with mock.patch(\"sys.path\", [\"old_path\"]):\n            handle_default_options(options={\"settings\": \"new_settings\", \"pythonpath\": \"new_path\"})\n            self.assertEqual(os.environ[\"DJANGO_SETTINGS_MODULE\"], \"new_settings\")\n            self.assertEqual(sys.path, [\"new_path\", \"old_path\"])\n"], "sample_221": ["def test_pickle_values_list_flat(self):\n    qs = Happening.objects.values_list('name', flat=True)\n    reloaded = Happening.objects.all()\n    reloaded.query = pickle.loads(pickle.dumps(qs.query))\n    self.assertEqual(reloaded.get(), 'test')\n"], "sample_813": ["def test_bayesian_ridge_fit_intercept():\n    # Test BayesianRidge with fit_intercept=False\n    X = np.array([[1, 1], [2, 2], [3, 3]])\n    y = np.array([1, 2, 3])\n    clf = BayesianRidge(fit_intercept=False)\n    clf.fit(X, y)\n\n    # Check that the model could approximately learn the identity function\n    test = [[1], [2], [3]]\n    assert_array_almost_equal(clf.predict(test), [1, 2, 3], 2)\n\n    # Check that the intercept is not set\n    assert_equal(clf.intercept_, 0.0)\n"], "sample_188": ["    def setUpTestData(cls):\n        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max2 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max3 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max4 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max5 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max6 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max7 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max8 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max9 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max10 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max11 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max12 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max13 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max14 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max15 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max16 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max17 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max18 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max19 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max20 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max21 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max22 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max23 = Employee.objects.create(firstname='"], "sample_177": ["    def test_custom_manager_swappable(self):\n        \"\"\"\n        Tests making a ProjectState from unused models with custom managers\n        \"\"\"\n        new_apps = Apps(['migrations'])\n\n        class Food(models.Model):\n\n            food_mgr = FoodManager('a', 'b')\n            food_qs = FoodQuerySet.as_manager()\n            food_no_mgr = NoMigrationFoodManager('x', 'y')\n\n            class Meta:\n                app_label = \"migrations\"\n                apps = new_apps\n                swappable = 'TEST_SWAPPABLE_MODEL'\n\n        food_state = ModelState.from_model(Food)\n\n        # The default manager is used in migrations\n        self.assertEqual([name for name, mgr in food_state.managers], ['food_mgr'])\n        self.assertEqual(food_state.managers[0][1].args, ('a', 'b', 1, 2))\n"], "sample_168": ["def test_interactive_false_without_stale_content_types(self):\n    \"\"\"\n    non-interactive mode does nothing if there are no stale content types.\n    \"\"\"\n    with captured_stdout() as stdout:\n        call_command('remove_stale_contenttypes', interactive=False, verbosity=2)\n    self.assertNotIn('Deleting stale content type', stdout.getvalue())\n    self.assertEqual(ContentType.objects.count(), self.before_count)\n"], "sample_345": ["    def test_iter_modules_and_files_with_zip_import(self):\n        \"\"\"\n        Modules imported from zipped files have their archive location included\n        in the result.\n        \"\"\"\n        zip_file = self.temporary_file('zip_import.zip')\n        with zipfile.ZipFile(str(zip_file), 'w', zipfile.ZIP_DEFLATED) as zipf:\n            zipf.writestr('test_zipped_file.py', '')\n\n        with extend_sys_path(str(zip_file)):\n            self.import_and_cleanup('test_zipped_file')\n        self.assertFileFound(zip_file)\n"], "sample_169": ["    def setUpTestData(cls):\n        cls.primitives = [True, False, 'yes', 7, 9.6]\n        values = [\n            None,\n            [],\n            {},\n            {'a': 'b', 'c': 14},\n            {\n                'a': 'b',\n                'c': 14,\n                'd': ['e', {'f': 'g'}],\n                'h': True,\n                'i': False,\n                'j': None,\n                'k': {'l': 'm'},\n                'n': [None],\n            },\n            [1, [2]],\n            {'k': True, 'l': False},\n            {\n                'foo': 'bar',\n                'baz': {'a': 'b', 'c': 'd'},\n                'bar': ['foo', 'bar'],\n                'bax': {'foo': 'bar'},\n            },\n        ]\n        cls.objs = [\n            NullableJSONModel.objects.create(value=value)\n            for value in values\n        ]\n        if connection.features.supports_primitives_in_json_field:\n            cls.objs.extend([\n                NullableJSONModel.objects.create(value=value)\n                for value in cls.primitives\n            ])\n        cls.raw_sql = '%s::jsonb' if connection.vendor == 'postgresql' else '%s'\n"], "sample_283": ["def test_empty_settings(self):\n    \"\"\"Empty settings should raise a KeyError.\"\"\"\n    with self.assertRaises(KeyError):\n        self.settings_to_cmd_args_env({})\n"], "sample_696": ["def test_argument_percent_default_is_deprecated() -> None:\n    with pytest.warns(\n        pytest.PytestDeprecationWarning,\n        match=re.escape(\n            \"'%default' should be changed to '%(default)s'\",\n        ),\n    ):\n        pytest.main([\"-h\"])\n"], "sample_637": ["    def test_encoding_ascii(self) -> None:\n        code = \"\"\"a = 1\n                # FIXME message\n                \"\"\"\n        with self.assertNoMessages():\n            self.checker.process_module(_tokenize_str(code))\n"], "sample_701": ["def test_argument_percent_default_is_deprecated() -> None:\n    with pytest.warns(\n        pytest.PytestDeprecationWarning,\n        match=re.escape(\n            \"'%default' should be changed to '%(default)s'\",\n        ),\n    ):\n        pytest.main([\"-h\"])\n"], "sample_76": ["def test_valid_languages_bidi_empty(self):\n    with self.settings(LANGUAGES_BIDI=[]):\n        self.assertEqual(check_setting_languages_bidi(None), [])\n"], "sample_936": ["def test_stringify_type_hints_Generic():\n    T = TypeVar('T')\n    MyGeneric = Generic[T]\n    assert stringify(MyGeneric) == \"Generic[T]\"\n    assert stringify(Generic[T]) == \"Generic[T]\"\n\n    MyDict = Dict[str, T]\n    assert stringify(MyDict) == \"Dict[str, T]\"\n    assert stringify(Dict[str, T]) == \"Dict[str, T]\"\n\n    MyCallable = Callable[[str], T]\n    assert stringify(MyCallable) == \"Callable[[str], T]\"\n    assert stringify(Callable[[str], T]) == \"Callable[[str], T]\"\n"], "sample_255": ["    def test_ipv6(self):\n        \"\"\"WSGIServer handles IPv6 addresses.\"\"\"\n        request = WSGIRequest(self.request_factory.get('/').environ)\n        client_address = ('2001:0db8:85a3:0000:0000:8a2e:0370:7334', 8080)\n        server = WSGIServer(('::1', 0), WSGIRequestHandler, ipv6=True)\n        with captured_stderr() as err:\n            server.handle_error(request, client_address)\n        self.assertEqual(err.getvalue(), '')\n        self.assertEqual(server.address_family, socket.AF_INET6)\n"], "sample_857": ["def test_min_impurity_split_deprecated():\n    # Test if min_impurity_split raises DeprecationWarning when expected.\n    TreeEstimator = ALL_TREES[\"DecisionTreeClassifier\"]\n    X = np.asfortranarray(iris.data, dtype=tree._tree.DTYPE)\n    y = iris.target\n\n    # test both DepthFirstTreeBuilder and BestFirstTreeBuilder\n    # by setting max_leaf_nodes\n    for max_leaf_nodes, name in product((None, 1000), ALL_TREES.keys()):\n        TreeEstimator = ALL_TREES[name]\n        min_impurity_split = .5\n\n        # verify leaf nodes without min_impurity_split less than\n        # impurity 1e-7\n        est = TreeEstimator(max_leaf_nodes=max_leaf_nodes,\n                            random_state=0)\n        assert est.min_impurity_split is None, (\n            \"Failed, min_impurity_split = {0} > 1e-7\".format(\n                est.min_impurity_split))\n        try:\n            assert_warns(DeprecationWarning, est.fit, X, y)\n        except AssertionError:\n            pass\n        for node in range(est.tree_.node_count):\n            if (est.tree_.children_left[node] == TREE_LEAF or\n                    est.tree_.children_right[node] == TREE_LEAF):\n                assert est.tree_.impurity[node] == 0., (\n                    \"Failed with {0} min_impurity_split={1}\".format(\n                        est.tree_.impurity[node],\n                        est.min_impurity_split))\n\n        # verify leaf nodes have impurity [0,min_impurity_split] when using\n        # min_impurity_split\n        est = TreeEstimator(max_leaf_nodes=max_leaf_nodes,\n                            min_impurity_split=min_impurity_split,\n                            random_state=0)\n        assert_warns_message(DeprecationWarning,\n                             \"Use the min_impurity_decrease\",\n                             est.fit, X, y)\n        for node in range(est.tree_.node_count):\n            if (est.tree_.children_left[node] == TREE_LEAF or\n                    est.tree_.children_right[node] == TREE_LEAF):\n                assert est.tree_.impurity[node] >= 0, (\n                    \"Failed with {0}, min_impurity_split={1}\".format(\n                        est.tree_.impurity[node],\n                        est.min_impurity_split))\n                assert est.tree_.impurity[node] <= min_impurity_split, (\n                    \"Failed"], "sample_702": ["def test_pytester_syspathinsert(pytester: Pytester) -> None:\n    pytester.syspathinsert()\n    assert pytester.path in sys.path\n    pytester.syspathinsert(\"/tmp\")\n    assert \"/tmp\" in sys.path\n    pytester.syspathinsert(None)\n    assert pytester.path in sys.path\n    pytester.syspathinsert(\"/tmp\")\n    pytester._finalize()\n    assert pytester.path not in sys.path\n"], "sample_337": ["def test_https_good_referer_matches_cookie_domain_with_different_port_and_trusted_origin(self):\n    \"\"\"\n    A POST HTTPS request with a good referer should be accepted from a\n    subdomain that's allowed by SESSION_COOKIE_DOMAIN and a non-443 port,\n    and also from a trusted origin.\n    \"\"\"\n    self._test_https_good_referer_matches_cookie_domain_with_different_port()\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['HTTP_REFERER'] = 'https://dashboard.example.com'\n    req.META['SERVER_PORT'] = '4443'\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.process_request(req)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n    self.assertEqual(mw.allowed_origins_exact, {'https://dashboard.example.com'})\n    self.assertEqual(mw.allowed_origin_subdomains, {})\n"], "sample_354": ["    def test_validate_fk_via_environment_variable(self):\n        email = Email.objects.create(email='mymail@gmail.com')\n        Group.objects.all().delete()\n        nonexistent_group_id = 1\n        msg = f'group instance with id {nonexistent_group_id} does not exist.'\n\n        with mock.patch.dict(\n            os.environ,\n            {'DJANGO_SUPERUSER_GROUP': str(nonexistent_group_id)},\n        ):\n            with self.assertRaisesMessage(CommandError, msg):\n                call_command(\n                    'createsuperuser',\n                    interactive=False,\n                    username=email.pk,\n                    email=email.email,\n                    verbosity=0,\n                )\n"], "sample_288": ["    def setUpTestData(cls):\n        cls.primitives = [True, False, 'yes', 7, 9.6]\n        values = [\n            None,\n            [],\n            {},\n            {'a': 'b', 'c': 14},\n            {\n                'a': 'b',\n                'c': 14,\n                'd': ['e', {'f': 'g'}],\n                'h': True,\n                'i': False,\n                'j': None,\n                'k': {'l': 'm'},\n                'n': [None, True, False],\n                'o': '\"quoted\"',\n                'p': 4.2,\n                'r': {'s': True, 't': False},\n            },\n            [1, [2]],\n            {'k': True, 'l': False, 'foo': 'bax'},\n            {\n                'foo': 'bar',\n                'baz': {'a': 'b', 'c': 'd'},\n                'bar': ['foo', 'bar'],\n                'bax': {'foo': 'bar'},\n            },\n        ]\n        cls.objs = [\n            NullableJSONModel.objects.create(value=value)\n            for value in values\n        ]\n        if connection.features.supports_primitives_in_json_field:\n            cls.objs.extend([\n                NullableJSONModel.objects.create(value=value)\n                for value in cls.primitives\n            ])\n        cls.raw_sql = '%s::jsonb' if connection.vendor == 'postgresql' else '%s'\n"], "sample_902": ["def test_pipeline_memory_cache_hit():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        memory = Memory(cachedir=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', clone(transf)), ('svc', clf)])\n        cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n                               memory=memory)\n\n        # Memoize the transformer at the first fit\n        cached_pipe.fit(X, y)\n        # Check that we are reading the cache while fitting\n        # a second time\n        cached_pipe.fit(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert_equal(time.time(), cached_pipe.named_steps['transf'].timestamp_)\n    finally:\n        shutil.rmtree(cachedir)\n"], "sample_648": ["def test_parametrize_with_empty_list(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"arg\", [])\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"collected 0 items / 1 error\",\n            \"* ERROR collecting test_parametrize_with_empty_list.py *\",\n            \"Empty parameter set in 'test_func' at line 3\",\n            \"*= 1 error in *\",\n        ]\n    )\n    assert result.ret == ExitCode.INTERRUPTED\n"], "sample_1188": ["def test_issue_12345():\n    from sympy import symbols, sin, cos, pi, UnevaluatedExpr\n\n    delop = Del()\n    CC_   = CoordSys3D(\"C\")\n    y     = CC_.y\n    xhat  = CC_.i\n\n    t = symbols(\"t\")\n    ten = symbols(\"10\", positive=True)\n    eps, mu = 4*pi*ten**(-11), ten**(-5)\n\n    Bx = 2 * ten**(-4) * cos(ten**5 * t) * sin(ten**(-3) * y)\n    vecB = Bx * xhat\n    vecE = (1/eps) * Integral(delop.cross(vecB/mu).doit(), t)\n    vecE = vecE.doit()\n\n    vecB_str = \"\"\"\\"], "sample_722": ["def test_k_means_callable_init():\n    # Small test to check that giving the wrong number of centers\n    # raises a meaningful error\n        return np.array([[0, 0], [0, 1]])\n\n    msg = \"does not match the number of clusters\"\n    assert_raises_regex(ValueError, msg, KMeans(init=test_init, n_clusters=3,\n                                               random_state=42).fit, X)\n\n    # Now check that the fit actually works\n    km = KMeans(init=test_init, n_clusters=3, random_state=42).fit(X)\n    _check_fitted_model(km)\n"], "sample_553": ["def test_movie_writer_invalid_dpi(anim):\n    class DummyMovieWriter(animation.MovieWriter):\n            pass\n\n    # Test setting up movie writer with invalid dpi.\n    fig = plt.figure()\n\n    filename = \"unused.null\"\n    fps = 5\n    codec = \"unused\"\n    bitrate = 1\n    extra_args = [\"unused\"]\n\n    writer = DummyMovieWriter(fps, codec, bitrate, extra_args)\n    with pytest.raises(ValueError):\n        writer.setup(fig, filename, dpi=-1)\n    with pytest.raises(ValueError):\n        writer.setup(fig, filename, dpi=0)\n    with pytest.raises(ValueError):\n        writer.setup(fig, filename, dpi=1.5)\n"], "sample_993": ["def test_FreeGroupElm_cyclic_reduction():\n    w = x**2*y**2*x**-1\n    assert w.cyclic_reduction() == x*y**2\n    assert w.cyclic_reduction(removed=True) == (x*y**2, x**-1)\n\n    w = x**-3*y**-1*x**5\n    assert w.cyclic_reduction() == y**-1*x**2\n    assert w.cyclic_reduction(removed=True) == (y**-1*x**2, x**-3)\n\n    w = x**-3*y**-1*x**5*y**-1\n    assert w.cyclic_reduction() == y**-1*x**2*y**-1\n    assert w.cyclic_reduction(removed=True) == (y**-1*x**2*y**-1, x**-3)\n\n    w = x**-3*y**-1*x**5*y**-1*x**-2\n    assert w.cyclic_reduction() == y**-1*x**2*y**-1*x**-2\n    assert w.cyclic_reduction(removed=True) == (y**-1*x**2*y**-1*x**-2, x**-3)\n\n    w = x**-3*y**-1*x**5*y**-1*x**-2*y**-1\n    assert w.cyclic_reduction() == y**-1*x**2*y**-2\n    assert w.cyclic_reduction(removed=True) == (y**-1*x**2*y**-2, x**-3)\n\n    w = x**-3*y**-1*x**5*y**-1*x**-2*y**-1*x**-1\n    assert w.cyclic_reduction() == y**-1*x**2*y**-2*x**-1\n    assert w.cyclic_reduction(removed=True) == (y**-1*x**2*y**-2*x**-1, x**-3)\n\n    w = x**-3*y**-1*x**5*y**-1*x**-2*y**-1*x**-1*y**-1\n    assert w.cyclic_reduction() == y**-1*x**2*y**-3\n    assert w.cyclic_reduction(removed=True) == (y**-1*x**2*y**-3, x**-"], "sample_35": ["def test_isinstancemethod():\n    class MyClass:\n            pass\n\n        @classmethod\n            pass\n\n        @staticmethod\n            pass\n\n    assert isinstancemethod(MyClass, MyClass.an_instancemethod)\n    assert not isinstancemethod(MyClass, MyClass.a_classmethod)\n    assert not isinstancemethod(MyClass, MyClass.a_staticmethod)\n\n    class MySubClass(MyClass):\n        pass\n\n    assert isinstancemethod(MyClass, MySubClass.an_instancemethod)\n    assert not isinstancemethod(MyClass, MySubClass.a_classmethod)\n    assert not isinstancemethod(MyClass, MySubClass.a_staticmethod)\n\n    class MySubSubClass(MySubClass):\n            pass\n\n    assert isinstancemethod(MyClass, MySubSubClass.an_instancemethod)\n    assert not isinstancemethod(MyClass, MySubSubClass.a_classmethod)\n    assert not isinstancemethod(MyClass, MySubSubClass.a_staticmethod)\n\n    # Test with a static method\n    class MyStaticClass:\n        @staticmethod\n            pass\n\n    assert not isinstancemethod(MyStaticClass, MyStaticClass.a_staticmethod)\n\n    # Test with a class method\n    class MyClassMethodClass:\n        @classmethod\n            pass\n\n    assert not isinstancemethod(MyClassMethodClass, MyClassMethodClass.a_classmethod)\n"], "sample_189": ["    def test_cache_versioning_touch(self):\n        cache.set('answer', 42, version=2)\n        self.assertIsNone(cache.get('answer'))\n        self.assertIsNone(cache.get('answer', version=1))\n        self.assertEqual(cache.get('answer', version=2), 42)\n        self.assertIs(cache.touch('answer', version=2), True)\n        self.assertEqual(cache.get('answer', version=2), 42)\n        self.assertIsNone(cache.get('answer', version=3))\n\n        caches['v2'].set('answer2', 42)\n        self.assertEqual(caches['v2'].get('answer2'), 42)\n        self.assertIsNone(caches['v2'].get('answer2', version=1))\n        self.assertEqual(caches['v2'].get('answer2', version=2), 42)\n        self.assertIs(caches['v2'].touch('answer2', version=2), True)\n        self.assertEqual(caches['v2'].get('answer2', version=2), 42)\n        self.assertIsNone(caches['v2'].get('answer2', version=3))\n\n        with self.assertRaises(ValueError):\n            cache.touch('does_not_exist', version=2)\n\n        with self.assertRaises(ValueError):\n            caches['v2'].touch('does_not_exist', version=2)\n"], "sample_791": ["def test_one_hot_encoder_handle_unknown_strings_pandas():\n    pd = pytest.importorskip('pandas')\n\n    X = pd.DataFrame({'A': ['11111111', '22', '333', '4444']})\n    X2 = pd.DataFrame({'A': ['55555', '22']})\n\n    # Non Regression test for the issue #12470\n    # Test the ignore option, when categories are numpy string dtype\n    # particularly when the known category strings are larger\n    # than the unknown category strings\n    oh = OneHotEncoder(handle_unknown='ignore')\n    oh.fit(X)\n    X2_passed = X2.copy()\n    assert_array_equal(\n        oh.transform(X2_passed).toarray(),\n        np.array([[0.,  0.,  0.,  0.], [0.,  1.,  0.,  0.]]))\n    # ensure transformed data was not modified in place\n    assert_array_equal(X2, X2_passed)\n"], "sample_784": ["def test_calibration_brier_score():\n    \"\"\"Test that Brier score is improved after calibration\"\"\"\n    n_samples = 100\n    X, y = make_classification(n_samples=2 * n_samples, n_features=6,\n                               random_state=42)\n    sample_weight = np.random.RandomState(seed=42).uniform(size=y.size)\n\n    X -= X.min()  # MultinomialNB only allows positive X\n\n    # split train and test\n    X_train, y_train, sw_train = \\\n        X[:n_samples], y[:n_samples], sample_weight[:n_samples]\n    X_test, y_test = X[n_samples:], y[n_samples:]\n\n    # Naive-Bayes\n    clf = MultinomialNB().fit(X_train, y_train, sample_weight=sw_train)\n    prob_pos_clf = clf.predict_proba(X_test)[:, 1]\n\n    pc_clf = CalibratedClassifierCV(clf, cv=2)\n    pc_clf.fit(X_train, y_train, sample_weight=sw_train)\n    prob_pos_pc_clf = pc_clf.predict_proba(X_test)[:, 1]\n\n    # Check that Brier score has improved after calibration\n    assert_greater(brier_score_loss(y_test, prob_pos_clf),\n                   brier_score_loss(y_test, prob_pos_pc_clf))\n\n    # Check that Brier score is improved for all classes\n    prob_pos_pc_clf_all_classes = pc_clf.predict_proba(X_test)\n    for i in range(prob_pos_pc_clf_all_classes.shape[1]):\n        assert_greater(brier_score_loss(y_test, prob_pos_pc_clf_all_classes[:, i]),\n                       brier_score_loss(y_test, prob_pos_clf[:, i]))\n"], "sample_851": ["def test_mean_squared_log_error_negative_values():\n    y_true = [1, 2, 3]\n    y_pred = [1, 2, 3]\n    with pytest.raises(ValueError, match=\"Mean Squared Logarithmic Error cannot be used when targets contain negative values.\"):\n        mean_squared_log_error(y_true, y_pred)\n\n    y_true = [1, 2, 3]\n    y_pred = [1, 2, -3]\n    with pytest.raises(ValueError, match=\"Mean Squared Logarithmic Error cannot be used when targets contain negative values.\"):\n        mean_squared_log_error(y_true, y_pred)\n\n    y_true = [-1, 2, 3]\n    y_pred = [1, 2, 3]\n    with pytest.raises(ValueError, match=\"Mean Squared Logarithmic Error cannot be used when targets contain negative values.\"):\n        mean_squared_log_error(y_true, y_pred)\n\n    y_true = [-1, 2, -3]\n    y_pred = [1, 2, 3]\n    with pytest.raises(ValueError, match=\"Mean Squared Logarithmic Error cannot be used when targets contain negative values.\"):\n        mean_squared_log_error(y_true, y_pred)\n\n    y_true = [-1, 2, -3]\n    y_pred = [-1, 2, 3]\n    with pytest.raises(ValueError, match=\"Mean Squared Logarithmic Error cannot be used when targets contain negative values.\"):\n        mean_squared_log_error(y_true, y_pred)\n"], "sample_218": ["def test_trunc_func_with_timezone_and_dst(self):\n    \"\"\"\n    If the truncated datetime transitions to a different offset (daylight\n    saving) then the returned value will have that new timezone/offset.\n    \"\"\"\n    start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n    end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n    self.create_model(end_datetime, start_datetime)\n\n    melb = pytz.timezone('Australia/Melbourne')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=DateTimeField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(melb), kind, melb)),\n                (end_datetime, truncate_to(end_datetime.astimezone(melb), kind, melb))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_date', kind, output_field=DateField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.date(), kind)),\n                (end_datetime, truncate_to(end_datetime.date(), kind))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_time', kind, output_field=TimeField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.time(), kind)),\n                (end_datetime, truncate_to(end_datetime.time(), kind))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_date_kind('year')\n    test_date_kind('quarter')\n    test_date_kind('month')\n    test_date_kind('week')\n    test_date_kind('day')\n    test_time_kind('hour')\n    test"], "sample_175": ["    def test_delete_with_keeping_parents_multiple_levels(self):\n        child = RChild.objects.create()\n        grandchild = RChildChild.objects.create(rchild_ptr=child)\n        parent_id = child.r_ptr_id\n        grandparent_id = child.r_ptr_id\n        child.delete(keep_parents=True)\n        self.assertFalse(RChild.objects.filter(id=child.id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(RChildChild.objects.filter(id=grandchild.id).exists())\n        self.assertTrue(R.objects.filter(id=grandparent_id).exists())\n\n        childchild = RChildChild.objects.create()\n        parent_id = childchild.rchild_ptr.r_ptr_id\n        child_id = childchild.rchild_ptr_id\n        grandparent_id = childchild.rchild_ptr.r_ptr_id\n        childchild.delete(keep_parents=True)\n        self.assertFalse(RChildChild.objects.filter(id=childchild.id).exists())\n        self.assertTrue(RChild.objects.filter(id=child_id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(R.objects.filter(id=grandparent_id).exists())\n"], "sample_281": ["def test_to_field_resolution_with_fk(self):\n    \"\"\"\n    to_field resolution should correctly resolve for target models using FK.\n    \"\"\"\n    tests = [\n        (Author, Authorship, 'author'),\n        (Book, Authorship, 'author'),\n    ]\n    for Target, Remote, related_name in tests:\n        with self.subTest(target_model=Target, remote_model=Remote, related_name=related_name):\n            o = Target.objects.create(name=\"Frida Kahlo\", gender=2, code=\"painter\", alive=False)\n            opts = {\n                'app_label': Remote._meta.app_label,\n                'model_name': Remote._meta.model_name,\n                'field_name': related_name,\n            }\n            request = self.factory.get(self.url, {'term': 'frida', **opts})\n            request.user = self.superuser\n            response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n            self.assertEqual(response.status_code, 200)\n            data = json.loads(response.content.decode('utf-8'))\n            self.assertEqual(data, {\n                'results': [{'id': str(o.pk), 'text': o.name}],\n                'pagination': {'more': False},\n            })\n"], "sample_395": ["    def test_template_changed_with_multiple_backends(self):\n        template_path = Path(__file__).parent / \"templates\" / \"index.html\"\n        self.assertTrue(autoreload.template_changed(None, template_path))\n        mock_reset = mock.patch(\"django.template.autoreload.reset_loaders\")\n        mock_reset.assert_called_once()\n"], "sample_171": ["def test_migrate_plan_unapplied(self):\n    \"\"\"\n    Tests migrate --plan output when there are unapplied migrations.\n    \"\"\"\n    recorder = MigrationRecorder(connection)\n    recorder.record_applied(\"migrations\", \"0001_initial\")\n    out = io.StringIO()\n    with self.assertRaises(SystemExit):\n        call_command('migrate', 'migrations', '0002', check_unapplied=True, plan=True, stdout=out)\n    self.assertEqual(\n        'Planned operations:\\n'\n        'migrations.0002_second\\n'\n        '    Create model Book\\n'\n        \"    Raw SQL operation -> ['SELECT * FROM migrations_book']\\n\"\n        'migrations.0003_third\\n'\n        '    Create model Author\\n'\n        \"    Raw SQL operation -> ['SELECT * FROM migrations_author']\\n\",\n        out.getvalue()\n    )\n"], "sample_332": ["    def test_min_num_with_initial_data(self):\n        \"\"\"\n        min_num validation doesn't consider unchanged forms with initial data\n        as \"empty\".\n        \"\"\"\n        initial = [\n            {'choice': 'Zero', 'votes': 0},\n            {'choice': 'One', 'votes': 0},\n        ]\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '2',\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-MAX_NUM_FORMS': '2',\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': '0',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',  # changed from initial\n        }\n        ChoiceFormSet = formset_factory(Choice, min_num=2)\n        formset = ChoiceFormSet(data, auto_id=False, prefix='choices', initial=initial)\n        self.assertTrue(formset.is_valid())\n"], "sample_457": ["    def setUpTestData(cls):\n        cls.p1 = UniqueConstraintProduct.objects.create(name=\"p1\", color=\"red\")\n        cls.p2 = UniqueConstraintProduct.objects.create(name=\"p2\")\n"], "sample_638": ["def test_graphviz_unsupported_image_format_with_no_graphviz(mock_writer, capsys):\n    \"\"\"Test that Graphviz is used if the image format is supported.\"\"\"\n    mock_subprocess.run.side_effect = FileNotFoundError\n    with pytest.raises(SystemExit) as wrapped_sysexit:\n        # we have to catch the SystemExit so the test execution does not stop\n        main.Run([\"-o\", \"png\", TEST_DATA_DIR])\n    # Check that the right info message is shown to the user\n    assert (\n        \"Format png is not supported natively. Pyreverse will try to generate it using Graphviz...\"\n        in capsys.readouterr().out\n    )\n    assert (\n        \"Unable to determine Graphviz supported output formats.\"\n        in capsys.readouterr().out\n    )\n    # Check that pyreverse actually made the call to create the diagram and we exit cleanly\n    mock_writer.DiagramWriter().write.assert_not_called()\n    assert wrapped_sysexit.value.code == 1\n"], "sample_563": ["def test_offsetbox_set_width_height():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100)\n    da.set_width(50)\n    da.set_height(50)\n    assert da.width == 50\n    assert da.height == 50\n    assert da.get_bbox(ax.figure._get_renderer()).bounds == (0, 0, 50, 50)\n"], "sample_298": ["def test_token_with_different_algorithm(self):\n    \"\"\"\n    A valid token can be created with a different algorithm by using the\n    PasswordResetTokenGenerator.algorithm attribute.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    new_algorithm = 'sha1'\n    # Create and check a token with a different algorithm.\n    p0 = PasswordResetTokenGenerator()\n    p0.algorithm = new_algorithm\n    tk0 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk0), True)\n    # Create and check a token with the default algorithm.\n    p1 = PasswordResetTokenGenerator()\n    self.assertEqual(p1.algorithm, 'sha256')\n    self.assertNotEqual(p1.algorithm, new_algorithm)\n    tk1 = p1.make_token(user)\n    # Tokens created with a different algorithm don't validate.\n    self.assertIs(p0.check_token(user, tk1), False)\n    self.assertIs(p1.check_token(user, tk0), False)\n"], "sample_614": ["def test_dim_summary_limited(self) -> None:\n    ds = xr.Dataset(coords={\"foo\": [1, 2, 3], \"bar\": [1, 2, 3]})\n    expected = \"foo: 1 2 3, bar: 1 2 3\"\n    actual = formatting.dim_summary_limited(ds, col_width=10)\n    assert expected == actual\n\n    ds = xr.Dataset(coords={\"foo\": [1, 2, 3], \"bar\": [1, 2, 3]})\n    expected = \"foo: 1 2 3\"\n    actual = formatting.dim_summary_limited(ds, col_width=10, max_rows=1)\n    assert expected == actual\n\n    ds = xr.Dataset(coords={\"foo\": [1, 2, 3], \"bar\": [1, 2, 3]})\n    expected = \"bar: 1 2 3\"\n    actual = formatting.dim_summary_limited(ds, col_width=10, max_rows=1)\n    assert expected == actual\n\n    ds = xr.Dataset(coords={\"foo\": [1, 2, 3], \"bar\": [1, 2, 3]})\n    expected = \"foo: 1 2 3, bar: 1 2 3\"\n    actual = formatting.dim_summary_limited(ds, col_width=10, max_rows=2)\n    assert expected == actual\n\n    ds = xr.Dataset(coords={\"foo\": [1, 2, 3], \"bar\": [1, 2, 3]})\n    expected = \"foo: 1 2 3, bar: 1 2 3\"\n    actual = formatting.dim_summary_limited(ds, col_width=10, max_rows=3)\n    assert expected == actual\n\n    ds = xr.Dataset(coords={\"foo\": [1, 2, 3], \"bar\": [1, 2, 3]})\n    expected = \"foo: 1 2 3, bar: 1 2 3\"\n    actual = formatting.dim_summary_limited(ds, col_width=10, max_rows=4)\n    assert expected == actual\n\n    ds = xr.Dataset(coords={\"foo\": [1, 2, 3], \"bar\": [1, 2, 3]})\n    expected = \"foo: 1 2 3, bar: 1 2 3\"\n   "], "sample_183": ["    def setUpTestData(cls):\n        o = CaseTestModel.objects.create(integer=1, integer2=1, string='1')\n        FKCaseTestModel.objects.create(fk=o, integer=1)\n        FKCaseTestModel.objects.create(fk=o, integer=2)\n        FKCaseTestModel.objects.create(fk=o, integer=3)\n"], "sample_351": ["def test_choice_iterator_passes_model_to_widget_with_to_field_name(self):\n    class CustomCheckboxSelectMultiple(CheckboxSelectMultiple):\n            option = super().create_option(name, value, label, selected, index, subindex, attrs)\n            # Modify the HTML based on the object being rendered.\n            c = value.instance\n            option['attrs']['data-slug'] = getattr(c, self.choices.choice_value_to_field_name)\n            return option\n\n    class CustomModelMultipleChoiceField(forms.ModelMultipleChoiceField):\n        widget = CustomCheckboxSelectMultiple\n        to_field_name = 'slug'\n\n    field = CustomModelMultipleChoiceField(Category.objects.all())\n    self.assertHTMLEqual(\n        field.widget.render('name', []),\n        \"\"\"<div>"], "sample_1166": ["def test_MonomialOps():\n    ops = MonomialOps(3)\n\n    assert ops.mul() == Monomial((4, 6, 1))\n    assert ops.pow() == Monomial((3, 6, 3))\n    assert ops.mulpow() == Monomial((4, 6, 4))\n    assert ops.ldiv() == Monomial((2, 2, 1))\n    assert ops.div() == Monomial((2, 2, 1))\n    assert ops.lcm() == Monomial((3, 4, 1))\n    assert ops.gcd() == Monomial((1, 2, 0))\n\n    raises(NotImplementedError, lambda: ops.mul()(1, 2))\n    raises(NotImplementedError, lambda: ops.pow()(1, 2))\n    raises(NotImplementedError, lambda: ops.mulpow()(1, 2, 3))\n    raises(NotImplementedError, lambda: ops.ldiv()(1, 2))\n    raises(NotImplementedError, lambda: ops.div()(1, 2))\n    raises(NotImplementedError, lambda: ops.lcm()(1, 2))\n    raises(NotImplementedError, lambda: ops.gcd()(1, 2))\n"], "sample_1032": ["def test_issue_12345():\n    from sympy.abc import x, y, z\n    n = Symbol('n', negative=True)\n    n_ = Symbol('n_', negative=True)\n    nn = Symbol('nn', nonnegative=True)\n    nn_ = Symbol('nn_', nonnegative=True)\n    p = Symbol('p', positive=True)\n    p_ = Symbol('p_', positive=True)\n    np = Symbol('np', nonpositive=True)\n    np_ = Symbol('np_', nonpositive=True)\n    r = Symbol('r', real=True)\n\n    # test that Min and Max handle non-comparable arguments correctly\n    assert Min(x, y) == Min(y, x)\n    assert Max(x, y) == Max(y, x)\n    assert Min(x, y, z) == Min(z, y, x)\n    assert Max(x, y, z) == Max(z, y, x)\n\n    # test that Min and Max handle non-real arguments correctly\n    assert Min(x, y).is_real\n    assert Max(x, y).is_real\n    assert Min(x, y, z).is_real\n    assert Max(x, y, z).is_real\n\n    # test that Min and Max handle real and non-real arguments correctly\n    assert Min(x, y, I).is_real\n    assert Max(x, y, I).is_real\n    assert Min(x, y, z, I).is_real\n    assert Max(x, y, z, I).is_real\n\n    # test that Min and Max handle non-comparable real and non-real arguments correctly\n    assert Min(x, y, I) == Min(I, y, x)\n    assert Max(x, y, I) == Max(I, y, x)\n    assert Min(x, y, z, I) == Min(I, z, y, x)\n    assert Max(x, y, z, I) == Max(I, z, y, x)\n\n    # test that Min and Max handle non-comparable real and non-real arguments correctly\n    assert Min(x, y, I, z) == Min(I, z, y, x)\n    assert Max(x, y, I, z) == Max(I, z, y, x)\n    assert Min(x, y, z, I, w) == Min(I, w, z, y, x)\n    assert Max(x, y, z, I, w) =="], "sample_210": ["    def _assert_about(self, response):\n        response.render()\n        self.assertContains(response, '<h1>About</h1>')\n"], "sample_429": ["    def test_decimal_validator_max_digits(self):\n        validator = DecimalValidator(max_digits=5, decimal_places=2)\n        with self.assertRaisesMessage(\n            ValidationError,\n            \"Ensure that there are no more than 5 digits in total.\",\n        ):\n            validator(Decimal(\"7424742403889818000000\"))\n"], "sample_77": ["def test_avoid_wrapping(self):\n    items = (\n        ('Hello, world!', 'Hello, world!'),\n        ('Hello, world!  Hello, world!', 'Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello,"], "sample_439": ["def test_boundfield_subwidgets(self):\n    class SomeForm(Form):\n        field = MultipleChoiceField(\n            choices=[(\"a\", \"A\"), (\"b\", \"B\")],\n            widget=CheckboxSelectMultiple,\n        )\n\n    form = SomeForm(auto_id=False)\n    self.assertEqual(len(form[\"field\"].subwidgets), 2)\n    self.assertIsInstance(form[\"field\"].subwidgets[0], CheckboxInput)\n    self.assertIsInstance(form[\"field\"].subwidgets[1], CheckboxInput)\n    self.assertEqual(form[\"field\"].subwidgets[0].value(), \"a\")\n    self.assertEqual(form[\"field\"].subwidgets[1].value(), \"b\")\n    self.assertEqual(form[\"field\"].subwidgets[0].label(), \"A\")\n    self.assertEqual(form[\"field\"].subwidgets[1].label(), \"B\")\n    self.assertEqual(form[\"field\"].subwidgets[0].id_for_label, None)\n    self.assertEqual(form[\"field\"].subwidgets[1].id_for_label, None)\n    self.assertEqual(form[\"field\"].subwidgets[0].tag(), '<input type=\"checkbox\" name=\"field\" value=\"a\">')\n    self.assertEqual(form[\"field\"].subwidgets[1].tag(), '<input type=\"checkbox\" name=\"field\" value=\"b\">')\n    self.assertEqual(\n        str(form[\"field\"]),\n        '<div><div><label><input type=\"checkbox\" name=\"field\" value=\"a\"> A</label></div>'\n        '<div><label><input type=\"checkbox\" name=\"field\" value=\"b\"> B</label></div></div>',\n    )\n    self.assertEqual(\n        str(form[\"field\"]),\n        '<div><div><label><input type=\"checkbox\" name=\"field\" value=\"a\"> A</label></div>'\n        '<div><label><input type=\"checkbox\" name=\"field\" value=\"b\"> B</label></div></div>',\n    )\n    form = SomeForm(auto_id=\"id_%s\")\n    self.assertEqual(form[\"field\"].subwidgets[0].id_for_label, \"id_field_0\")\n    self.assertEqual(form[\"field\"].subwidgets[1].id_for_label, \"id_field_1\")\n    self.assertEqual(\n        str(form[\"field\"]),\n        '<div id=\"id_field\"><div><label for=\"id_field_0\"><input type=\"checkbox\" '\n        'name=\"field\" value=\"a\" id=\"id_field_0\"> A</label"], "sample_883": ["def test_bayesian_ridge_fit_intercept():\n    # Test correctness of fit_intercept parameter\n    X = np.array([[1, 1], [3, 4], [5, 7], [4, 1], [2, 6], [3, 10], [3, 2]])\n    y = np.array([1, 2, 3, 2, 0, 4, 5]).T\n\n    # A Ridge regression model using an alpha value equal to the ratio of\n    # lambda_ and alpha_ from the Bayesian Ridge model must be identical\n    br_model = BayesianRidge(fit_intercept=False).fit(X, y)\n    rr_model = Ridge(alpha=br_model.lambda_ / br_model.alpha_).fit(X, y)\n    assert_array_almost_equal(rr_model.coef_, br_model.coef_)\n    assert_almost_equal(rr_model.intercept_, br_model.intercept_)\n\n    br_model = BayesianRidge(fit_intercept=True).fit(X, y)\n    rr_model = Ridge(alpha=br_model.lambda_ / br_model.alpha_).fit(X, y)\n    assert_array_almost_equal(rr_model.coef_, br_model.coef_)\n    assert_almost_equal(rr_model.intercept_, br_model.intercept_)\n"], "sample_147": ["def test_difference_with_distinct(self):\n    qs1 = Number.objects.filter(num__lt=10).distinct()\n    qs2 = Number.objects.filter(num__lt=9)\n    self.assertNumbersEqual(qs1.difference(qs2), [9], ordered=False)\n"], "sample_487": ["    def test_prepopulated_fields_value_item_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            prepopulated_fields = {\"slug\": (\"name\",)}\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'prepopulated_fields[\\\"slug\\\"]' must be a list or tuple.\",\n            \"admin.E029\",\n        )\n"], "sample_997": ["def test_function_exponentiation():\n    transformations = standard_transformations + (function_exponentiation,)\n    x = Symbol('x')\n    assert parse_expr(\"sin**2(x)\", transformations=transformations) == sin(x)**2\n    assert parse_expr(\"sin**2(x)**3\", transformations=transformations) == (sin(x)**2)**3\n    assert parse_expr(\"sin**2(x)**3 + cos**2(x)**2\", transformations=transformations) == (sin(x)**2)**3 + (cos(x)**2)**2\n"], "sample_707": ["def test_repr_failure_py_style() -> None:\n    \"\"\"Test that repr_failure_py() respects the tbstyle option.\"\"\"\n    class FakeSession:\n            if name == \"tbstyle\":\n                return \"short\"\n            return default\n\n    session = FakeSession()\n    node = nodes.Node(\"test\", session=session)\n    excinfo = ExceptionInfo(Exception(\"test\"))\n    result = node._repr_failure_py(excinfo, style=\"long\")\n    assert isinstance(result, TerminalRepr)\n    assert result.style == \"long\"\n    result = node._repr_failure_py(excinfo, style=\"short\")\n    assert isinstance(result, TerminalRepr)\n    assert result.style == \"short\"\n"], "sample_508": ["def test_set_rasterized():\n    art = martist.Artist()\n    with pytest.raises(TypeError, match='^Rasterization of'):\n        art.set_rasterized('string')\n    with pytest.raises(TypeError, match='^Rasterization of'):\n        art.set_rasterized([1, 2, 3])\n    with pytest.raises(ValueError, match=\"will be ignored\"):\n        art.set_rasterized(True)\n    art.set_rasterized(False)\n    assert not art.get_rasterized()\n    art.set_rasterized(True)\n    assert art.get_rasterized()\n"], "sample_282": ["def test_render_disabled_attributes(self):\n    form = PartiallyRequiredForm({'f_0': 'Hello', 'f_1': ''})\n    self.assertTrue(form.is_valid())\n    self.assertInHTML('<input type=\"text\" name=\"f_0\" value=\"Hello\" required id=\"id_f_0\">', form.as_p())\n    self.assertInHTML('<input type=\"text\" name=\"f_1\" id=\"id_f_1\" disabled>', form.as_p())\n    form = PartiallyRequiredForm({'f_0': '', 'f_1': ''})\n    self.assertFalse(form.is_valid())\n"], "sample_80": ["def test_annotation(self):\n    query = Query(Author)\n    where = query.build_where(Q(num__gt=F('id')))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertIsInstance(lookup.rhs, SimpleCol)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertEqual(lookup.rhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('num'))\n\n    query = Query(Author)\n    where = query.build_where(Q(num__gt=F('id') + 1))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertIsInstance(lookup.rhs, SimpleCol)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertEqual(lookup.rhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n\n    query = Query(Author)\n    where = query.build_where(Q(num__gt=F('id') + F('id')))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertIsInstance(lookup.rhs, SimpleCol)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertEqual(lookup.rhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n\n    query = Query(Author)\n    where = query.build_where(Q(num__gt=F('id') + F('id') + 1))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertIsInstance(lookup.rhs, SimpleCol)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertEqual(lookup.rhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n"], "sample_1164": ["def test_cg_simp():\n    a, b, c, d = symbols('a,b,c,d')\n    cg1 = CG(a, b, c, d, c, d)\n    cg2 = CG(a, b, c, d, c, d)\n    cg3 = CG(a, b, c, d, c, d)\n    cg4 = CG(a, b, c, d, c, d)\n    cg5 = CG(a, b, c, d, c, d)\n    cg6 = CG(a, b, c, d, c, d)\n    cg7 = CG(a, b, c, d, c, d)\n    cg8 = CG(a, b, c, d, c, d)\n    cg9 = CG(a, b, c, d, c, d)\n    cg10 = CG(a, b, c, d, c, d)\n    cg11 = CG(a, b, c, d, c, d)\n    cg12 = CG(a, b, c, d, c, d)\n    cg13 = CG(a, b, c, d, c, d)\n    cg14 = CG(a, b, c, d, c, d)\n    cg15 = CG(a, b, c, d, c, d)\n    cg16 = CG(a, b, c, d, c, d)\n    cg17 = CG(a, b, c, d, c, d)\n    cg18 = CG(a, b, c, d, c, d)\n    cg19 = CG(a, b, c, d, c, d)\n    cg20 = CG(a, b, c, d, c, d)\n    cg21 = CG(a, b, c, d, c, d)\n    cg22 = CG(a, b, c, d, c, d)\n    cg23 = CG(a, b, c, d, c, d)\n    cg24 = CG(a, b, c, d, c, d)\n    cg25 = CG(a, b, c, d, c, d)\n    cg26 = CG(a, b, c, d, c, d)\n    cg27 = CG(a, b, c, d, c, d)\n    cg28 = CG(a, b, c, d, c, d)\n    cg29 = CG(a, b, c,"], "sample_1040": ["def test_print_assoc_op():\n    mml = mpp._print(x + y)\n    assert mml.childNodes[0].nodeName == 'mi'\n    assert mml.childNodes[0].childNodes[0].nodeValue == '+'\n    assert mml.childNodes[1].nodeName == 'mi'\n    assert mml.childNodes[1].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[2].nodeName == 'mi'\n    assert mml.childNodes[2].childNodes[0].nodeValue == 'y'\n\n    mml = mpp._print(x - y)\n    assert mml.childNodes[0].nodeName == 'mi'\n    assert mml.childNodes[0].childNodes[0].nodeValue == '-'\n    assert mml.childNodes[1].nodeName == 'mi'\n    assert mml.childNodes[1].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[2].nodeName == 'mi'\n    assert mml.childNodes[2].childNodes[0].nodeValue == 'y'\n\n    mml = mpp._print(x * y)\n    assert mml.childNodes[0].nodeName == 'mi'\n    assert mml.childNodes[0].childNodes[0].nodeValue == '&InvisibleTimes;'\n    assert mml.childNodes[1].nodeName == 'mi'\n    assert mml.childNodes[1].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[2].nodeName == 'mi'\n    assert mml.childNodes[2].childNodes[0].nodeValue == 'y'\n\n    mml = mpp._print(x / y)\n    assert mml.childNodes[0].nodeName == 'mfrac'\n    assert mml.childNodes[0].childNodes[0].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[0].childNodes[1].childNodes[0].nodeValue == 'y'\n"], "sample_440": ["def test_update_conflicts_unique_fields_pk_and_update_fields(self):\n    TwoFields.objects.bulk_create(\n        [\n            TwoFields(f1=1, f2=1, name=\"a\"),\n            TwoFields(f1=2, f2=2, name=\"b\"),\n        ]\n    )\n    self.assertEqual(TwoFields.objects.count(), 2)\n\n    obj1 = TwoFields.objects.get(f1=1)\n    obj2 = TwoFields.objects.get(f1=2)\n    conflicting_objects = [\n        TwoFields(pk=obj1.pk, f1=3, f2=3, name=\"c\"),\n        TwoFields(pk=obj2.pk, f1=4, f2=4, name=\"d\"),\n    ]\n    TwoFields.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        unique_fields=[\"pk\"],\n        update_fields=[\"name\", \"f2\"],\n    )\n    self.assertEqual(TwoFields.objects.count(), 2)\n    self.assertCountEqual(\n        TwoFields.objects.values(\"f1\", \"f2\", \"name\"),\n        [\n            {\"f1\": 1, \"f2\": 3, \"name\": \"c\"},\n            {\"f1\": 2, \"f2\": 4, \"name\": \"d\"},\n        ],\n    )\n"], "sample_839": ["def test_hashingvectorizer_dtype():\n    # Non-regression test: HashingVectorizer used to ignore its \"dtype\" param.\n    v = HashingVectorizer(dtype=np.float32)\n    assert v.dtype == np.float32\n\n    X = v.transform(['hello world', 'hello hello']).toarray()\n    assert X.dtype == np.float32\n\n    # Check that the ability to change the dtype\n    v = HashingVectorizer(dtype=np.float64)\n    X = v.transform(['hello world', 'hello hello']).toarray()\n    assert X.dtype == np.float64\n"], "sample_190": ["def test_year_lookup(self):\n    # Year lookup can be performed using a year value\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n        ]\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__exact=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n        ]\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gt=2005),\n        []\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gte=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n        ]\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lt=2005),\n        []\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lte=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n        ]\n    )\n"], "sample_721": ["def test_check_X_y():\n    # Test check_X_y with various inputs\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # Test check_X_y with sparse inputs\n    X_sparse = sp.csr_matrix([[1, 2], [3, 4]])\n    y_sparse = sp.csr_matrix([0, 1])\n    X_checked, y_checked = check_X_y(X_sparse, y_sparse)\n    assert_array_equal(X_checked.toarray(), X_sparse.toarray())\n    assert_array_equal(y_checked.toarray(), y_sparse.toarray())\n\n    # Test check_X_y with multi-output y\n    y_multi = np.array([[0, 1], [1, 0]])\n    X_checked, y_checked = check_X_y(X, y_multi, multi_output=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y_multi)\n\n    # Test check_X_y with non-numeric y\n    y_non_numeric = ['a', 'b']\n    with pytest.raises(ValueError):\n        check_X_y(X, y_non_numeric)\n\n    # Test check_X_y with y that has np.nan or np.inf values\n    y_nan_inf = np.array([np.nan, np.inf])\n    with pytest.raises(ValueError):\n        check_X_y(X, y_nan_inf)\n\n    # Test check_X_y with X that has np.nan or np.inf values\n    X_nan_inf = np.array([[np.nan, np.inf], [np.inf, np.nan]])\n    with pytest.raises(ValueError):\n        check_X_y(X_nan_inf, y)\n\n    # Test check_X_y with X that has complex values\n    X_complex = np.array([[1 + 2j, 3 + 4j], [5 + 6j, 7 + 8j]])\n    with pytest.raises(ValueError):\n        check_X_y(X_complex, y)\n\n    # Test check_X_y with y that has complex values\n    y_complex = np.array([1 + 2j, 3 + 4j])\n    with pytest.raises(ValueError):\n        check_X_y(X, y_complex)\n\n    # Test check_X_y with X that has a different number of samples than y\n    X_diff_samples = np.array([[1,"], "sample_51": ["    def test_iso_8601_with_fractional_seconds(self):\n        test_values = (\n            ('PT5H30M30.1S', timedelta(hours=5, minutes=30, seconds=30, milliseconds=100)),\n            ('PT5H30M30.01S', timedelta(hours=5, minutes=30, seconds=30, milliseconds=10)),\n            ('PT5H30M30.001S', timedelta(hours=5, minutes=30, seconds=30, milliseconds=1)),\n            ('PT5H30M30.0001S', timedelta(hours=5, minutes=30, seconds=30, microseconds=100)),\n            ('PT5H30M30.00001S', timedelta(hours=5, minutes=30, seconds=30, microseconds=10)),\n            ('PT5H30M30.000001S', timedelta(hours=5, minutes=30, seconds=30, microseconds=1)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_1033": ["def test_Mul_is_irrational():\n    x = Symbol('x', real=True, irrational=True)\n    y = Symbol('y', real=True, irrational=True)\n    assert (x*y).is_irrational is True\n    assert (x*y).is_rational is False\n    assert (x*y).is_integer is None\n    assert (x*y).is_even is None\n    assert (x*y).is_odd is None\n    assert (x*y).is_positive is None\n    assert (x*y).is_nonpositive is None\n    assert (x*y).is_nonnegative is None\n    assert (x*y).is_negative is None\n    assert (x*y).is_zero is None\n    assert (x*y).is_finite is None\n    assert (x*y).is_real is None\n    assert (x*y).is_imaginary is None\n    assert (x*y).is_complex is None\n    assert (x*y).is_hermitian is None\n    assert (x*y).is_antihermitian is None\n"], "sample_814": ["def test_gradient_boosting_init_estimator_supports_sample_weight():\n    # Check that the init estimator supports sample weights.\n    X, y = make_classification(n_samples=100, random_state=0)\n    init = DummyClassifier(strategy='constant', constant=0)\n    gb = GradientBoostingClassifier(init=init)\n    gb.fit(X, y, sample_weight=np.ones(X.shape[0]))\n\n    init = DummyRegressor(strategy='constant', constant=0)\n    gb = GradientBoostingRegressor(init=init)\n    gb.fit(X, y, sample_weight=np.ones(X.shape[0]))\n\n    init = LinearRegression()\n    gb = GradientBoostingRegressor(init=init)\n    gb.fit(X, y, sample_weight=np.ones(X.shape[0]))\n\n    init = LinearSVC()\n    gb = GradientBoostingClassifier(init=init)\n    gb.fit(X, y, sample_weight=np.ones(X.shape[0]))\n\n    init = OneHotEncoder()\n    gb = GradientBoostingRegressor(init=init)\n    gb.fit(X, y, sample_weight=np.ones(X.shape[0]))\n\n    init = NuSVR(gamma='auto', nu=0.5)\n    gb = GradientBoostingRegressor(init=init)\n    gb.fit(X, y, sample_weight=np.ones(X.shape[0]))\n"], "sample_1083": ["def test_acsch_series():\n    x = Symbol('x')\n    t6 = acsch(x).expansion_term(6, x)\n    assert t6 == -5*x**6/96\n    assert acsch(x).expansion_term(8, x, t6, 0) == -35*x**8/1024\n"], "sample_1132": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((0, 1, 2, 3))) == [(0, 1, 2, 3), (0, -1, 2, 3), (0, 1, -2, 3), (0, -1, -2, 3), (0, 1, 2, -3), (0, -1, 2, -3), (0, 1, -2, -3), (0, -1, -2, -3), (1, 0, 2, 3), (-1, 0, 2, 3), (1, 0, -2, 3), (-1, 0, -2, 3), (1, 0, 2, -3), (-1, 0, 2, -3), (1, 0, -2, -3), (-1, 0, -2, -3), (2, 0, 1, 3), (-2, 0, 1, 3), (2, 0, -1, 3), (-2, 0, -1, 3), (2, 0, 1, -3), (-2, 0, 1, -3), (2, 0, -1, -3), (-2, 0, -1, -3), (2, 1, 0, 3), (-2, 1, 0, 3), (2, -1, 0, 3), (-2, -1, 0, 3), (2, 1, 0, -3), (-2, 1, 0, -3), (2, -1, 0, -3), (-2, -1, 0, -3), (1, 2, 0, 3), (-1, 2, 0, 3), (1, -2, 0, 3), (-1, -2, "], "sample_68": ["    def test_sensitive_kwargs_decorator_with_frame_variables(self):\n        \"\"\"\n        The sensitive_variables decorator works with object methods and frame variables.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(sensitive_kwargs_function_caller)\n            self.verify_unsafe_email(sensitive_kwargs_function_caller)\n\n        with self.settings(DEBUG=False):\n            self.verify_safe_response(sensitive_kwargs_function_caller, check_for_POST_params=False)\n            self.verify_safe_email(sensitive_kwargs_function_caller, check_for_POST_params=False)\n"], "sample_540": ["def test_movie_writer_invalid_codec(anim):\n    class DummyMovieWriter(animation.MovieWriter):\n            pass\n\n    # Test setting up movie writer with invalid codec.\n    fig = plt.figure()\n\n    filename = \"unused.null\"\n    fps = 5\n    codec = \"invalid\"\n    bitrate = 1\n    extra_args = [\"unused\"]\n\n    writer = DummyMovieWriter(fps, codec, bitrate, extra_args)\n    with pytest.raises(RuntimeError):\n        writer.setup(fig, filename)\n"], "sample_365": ["def test_lazy_class_preparation_caching_multiple_result_classes(self):\n    # lazy() should prepare the proxy class only once i.e. the first time\n    # it's used, even if multiple result classes are specified.\n    lazified = lazy(lambda: 0, int, list, tuple)\n    __proxy__ = lazified().__class__\n    with mock.patch.object(__proxy__, '__prepare_class__') as mocked:\n        lazified()\n        mocked.assert_called_once()\n"], "sample_449": ["    def test_close_connections(self):\n        \"\"\"WSGIServer closes all connections when a request is closed.\"\"\"\n        request = WSGIRequest(self.request_factory.get(\"/\").environ)\n        client_address = (\"192.168.2.0\", 8080)\n        server = WSGIServer((\"localhost\", 0), WSGIRequestHandler)\n        server.connections_override = {\"default\": \"connection1\"}\n        server.close_request(request)\n        self.assertEqual(connections[\"default\"], \"connection1\")\n        server._close_connections()\n        self.assertNotEqual(connections[\"default\"], \"connection1\")\n"], "sample_695": ["def test_repr_failure_py_with_fulltrace(pytester: Pytester) -> None:\n    \"\"\"Ensure that repr_failure_py() uses the full traceback when fulltrace is enabled.\"\"\"\n    items = pytester.getitems(\n        \"\"\"\n            raise Exception()\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--fulltrace\")\n    result.stdout.fnmatch_lines([\"*Exception*\"])\n"], "sample_646": ["def test_teardown_class_failure_is_shown(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n        class MyTestCase(unittest.TestCase):\n                assert 0, \"down1\"\n            @classmethod\n                assert 0, \"down2\"\n                pass\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-s\")\n    assert result.ret == 1\n    result.stdout.fnmatch_lines([\"*tearDownClass*\", \"*assert 0*down2*\", \"*1 failed*\"])\n    result.stdout.no_fnmatch_line(\"*down1*\")\n"], "sample_447": ["    def setUpTestData(cls):\n        cls.a1 = Author.objects.create(name=\"Adrian Holovaty\", age=34)\n        cls.a2 = Author.objects.create(name=\"Jacob Kaplan-Moss\", age=35)\n        cls.a3 = Author.objects.create(name=\"Brad Dayley\", age=45)\n        cls.a4 = Author.objects.create(name=\"James Bennett\", age=29)\n        cls.a5 = Author.objects.create(name=\"Jeffrey Forcier\", age=37)\n        cls.a6 = Author.objects.create(name=\"Paul Bissex\", age=29)\n        cls.a7 = Author.objects.create(name=\"Wesley J. Chun\", age=25)\n        cls.a8 = Author.objects.create(name=\"Peter Norvig\", age=57)\n        cls.a9 = Author.objects.create(name=\"Stuart Russell\", age=46)\n        cls.a1.friends.add(cls.a2, cls.a4)\n        cls.a2.friends.add(cls.a1, cls.a7)\n        cls.a4.friends.add(cls.a1)\n        cls.a5.friends.add(cls.a6, cls.a7)\n        cls.a6.friends.add(cls.a5, cls.a7)\n        cls.a7.friends.add(cls.a2, cls.a5, cls.a6)\n        cls.a8.friends.add(cls.a9)\n        cls.a9.friends.add(cls.a8)\n\n        cls.p1 = Publisher.objects.create(name=\"Apress\", num_awards=3)\n        cls.p2 = Publisher.objects.create(name=\"Sams\", num_awards=1)\n        cls.p3 = Publisher.objects.create(name=\"Prentice Hall\", num_awards=7)\n        cls.p4 = Publisher.objects.create(name=\"Morgan Kaufmann\", num_awards=9)\n        cls.p5 = Publisher.objects.create(name=\"Jonno's House of Books\", num_awards=0)\n\n        cls.b1 = Book.objects.create(\n            isbn=\"159059725\",\n            name=\"The Definitive Guide to Django: Web Development Done Right\",\n            pages=447,\n            rating=4.5,\n            price=Decimal(\"30.00\"),\n            contact=cls.a1,\n            publisher=cls.p1,\n            pubdate=datetime.date(2007, 12, 6),\n        )\n        cls.b2 = Book.objects.create(\n            isbn=\"067232959\",\n            name=\"Sams Teach Yourself Django in 24 Hours\",\n            pages=528,\n"], "sample_597": ["    def test_merge_fill_value_dict(self):\n        ds1 = xr.Dataset({\"a\": (\"x\", [1, 2]), \"x\": [0, 1]})\n        ds2 = xr.Dataset({\"b\": (\"x\", [3, 4]), \"x\": [1, 2]})\n        fill_value = {\"a\": 2, \"b\": 3}\n        expected = xr.Dataset(\n            {\"a\": (\"x\", [1, 2, 2]), \"b\": (\"x\", [3, 4, 3])}, {\"x\": [0, 1, 2]}\n        )\n        assert expected.identical(ds1.merge(ds2, fill_value=fill_value))\n        assert expected.identical(ds2.merge(ds1, fill_value=fill_value))\n        assert expected.identical(xr.merge([ds1, ds2], fill_value=fill_value))\n"], "sample_899": ["def test_check_estimators_pickle_sparse():\n    # Test that we can pickle all estimators with sparse data\n    X = np.array([[1, 2], [3, 4]])\n    X = sp.csr_matrix(X)\n    y = np.array([1, 2])\n    est = clone(SGDClassifier())\n    set_random_state(est)\n    est.fit(X, y)\n    pickled_estimator = pickle.dumps(est)\n    unpickled_estimator = pickle.loads(pickled_estimator)\n    assert_true(sparse.issparse(unpickled_estimator.coef_))\n    assert_allclose(est.coef_, unpickled_estimator.coef_)\n"], "sample_872": ["def test_coverage_error_toydata():\n    # Test Coverage error measure\n    assert_almost_equal(coverage_error([[0, 1]], [[0.25, 0.75]]), 1)\n    assert_almost_equal(coverage_error([[0, 1]], [[0.75, 0.25]]), 2)\n    assert_almost_equal(coverage_error([[1, 1]], [[0.75, 0.25]]), 2)\n    assert_almost_equal(coverage_error([[0, 0]], [[0.75, 0.25]]), 0)\n\n    assert_almost_equal(coverage_error([[0, 0, 0]], [[0.25, 0.5, 0.75]]), 0)\n    assert_almost_equal(coverage_error([[0, 0, 1]], [[0.25, 0.5, 0.75]]), 1)\n    assert_almost_equal(coverage_error([[0, 1, 0]], [[0.25, 0.5, 0.75]]), 2)\n    assert_almost_equal(coverage_error([[0, 1, 1]], [[0.25, 0.5, 0.75]]), 2)\n    assert_almost_equal(coverage_error([[1, 0, 0]], [[0.25, 0.5, 0.75]]), 3)\n    assert_almost_equal(coverage_error([[1, 0, 1]], [[0.25, 0.5, 0.75]]), 3)\n    assert_almost_equal(coverage_error([[1, 1, 0]], [[0.25, 0.5, 0.75]]), 3)\n    assert_almost_equal(coverage_error([[1, 1, 1]], [[0.25, 0.5, 0.75]]), 3)\n\n    assert_almost_equal(coverage_error([[0, 0, 0]], [[0.75, 0.5, 0.25]]), 0)\n    assert_almost_equal(coverage_error([[0, 0, 1]], [[0.75, 0.5, 0.25]]), 3)\n    assert_almost_equal(coverage_error([[0, 1, 0]], [[0.75, 0.5, 0.25"], "sample_890": ["def test_n_jobs_support():\n    # Make sure that n_jobs is supported\n\n    X, y = make_regression(n_features=10)\n    sfs = SequentialFeatureSelector(\n        LinearRegression(), n_features_to_select=\"auto\", cv=2, n_jobs=-1\n    )\n    sfs.fit(X, y)\n    sfs.transform(X)\n\n    sfs = SequentialFeatureSelector(\n        LinearRegression(), n_features_to_select=\"auto\", cv=2, n_jobs=2\n    )\n    sfs.fit(X, y)\n    sfs.transform(X)\n\n    sfs = SequentialFeatureSelector(\n        LinearRegression(), n_features_to_select=\"auto\", cv=2, n_jobs=1\n    )\n    sfs.fit(X, y)\n    sfs.transform(X)\n\n    with pytest.raises(ValueError, match=\"n_jobs must be an integer\"):\n        SequentialFeatureSelector(\n            LinearRegression(), n_features_to_select=\"auto\", cv=2, n_jobs=\"auto\"\n        ).fit(X, y)\n\n    with pytest.raises(ValueError, match=\"n_jobs must be an integer\"):\n        SequentialFeatureSelector(\n            LinearRegression(), n_features_to_select=\"auto\", cv=2, n_jobs=None\n        ).fit(X, y)\n"], "sample_961": ["def test_pydata_with_union_type_operator_old(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :annotation: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0],\n                ([desc_name, \"version\"],\n                 [desc_annotation, (\": \",\n                                    [pending_xref, \"int\"],\n                                    \" \",\n                                    [desc_sig_punctuation, \"|\"],\n                                    \" \",\n                                    [pending_xref, \"str\"])]))\n"], "sample_921": ["def test_isabstractmethod():\n    class Foo:\n        @abstractmethod\n            pass\n\n    class Bar(Foo):\n            pass\n\n    assert inspect.isabstractmethod(Foo.meth) is True\n    assert inspect.isabstractmethod(Bar.meth) is False\n    assert inspect.isabstractmethod(Foo()) is False\n    assert inspect.isabstractmethod(Bar()) is False\n\n    class AbstractClass:\n        @classmethod\n        @abstractmethod\n            pass\n\n    class ConcreteClass(AbstractClass):\n        @classmethod\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.classmeth) is True\n    assert inspect.isabstractmethod(ConcreteClass.classmeth) is False\n\n    class AbstractClass:\n        @staticmethod\n        @abstractmethod\n            pass\n\n    class ConcreteClass(AbstractClass):\n        @staticmethod\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.staticmeth) is True\n    assert inspect.isabstractmethod(ConcreteClass.staticmeth) is False\n"], "sample_227": ["def test_emptylistfieldfilter_choices_with_choices(self):\n    \"\"\"\n    Ensure choices are set the selected class when using choices with\n    EmptyFieldListFilter (#19318).\n    \"\"\"\n    modeladmin = BookAdminWithEmptyFieldListFilter(Book, site)\n    request = self.request_factory.get('/')\n    request.user = self.alfred\n    changelist = modeladmin.get_changelist_instance(request)\n    filterspec = changelist.get_filters(request)[0][0]\n    self.assertEqual(filterspec.title, 'Verbose Author')\n    choices = list(filterspec.choices(changelist))\n    self.assertEqual(len(choices), 3)\n\n    self.assertEqual(choices[0]['display'], 'All')\n    self.assertIs(choices[0]['selected'], True)\n    self.assertEqual(choices[0]['query_string'], '?')\n\n    self.assertEqual(choices[1]['display'], 'Empty')\n    self.assertIs(choices[1]['selected'], False)\n    self.assertEqual(choices[1]['query_string'], '?author__isempty=1')\n\n    self.assertEqual(choices[2]['display'], 'Not empty')\n    self.assertIs(choices[2]['selected'], False)\n    self.assertEqual(choices[2]['query_string'], '?author__isempty=0')\n\n    # Test choices\n    choices = [\n        ('Empty', 'Empty'),\n        ('Not empty', 'Not empty'),\n        ('All', 'All'),\n    ]\n    filterspec = changelist.get_filters(request)[0][0]\n    self.assertEqual(filterspec.title, 'Verbose Author')\n    self.assertEqual(filterspec.choices(changelist), choices)\n"], "sample_7": ["def test_insert_string_type_error_masked(self, Column):\n    \"\"\"\n    Test that inserting a non-string value into a string masked column raises a TypeError.\n    \"\"\"\n    c = table.MaskedColumn(['a', 'b'])\n    with pytest.raises(TypeError, match='string operation on non-string array'):\n        c.insert(0, 1)\n"], "sample_545": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect((1, 1, 0.5))\n    ax2.set_box_aspect((2, 1, 1))\n    fig.draw_without_rendering()\n    assert np.allclose(ax1.get_tightbbox(fig.canvas.get_renderer()).x1, 7.333)\n    assert np.allclose(ax2.get_tightbbox(fig.canvas.get_renderer()).x1, 7.333)\n    assert np.allclose(fig.get_tightbbox(fig.canvas.get_renderer()).x1, 7.333)\n"], "sample_40": ["def test_with_h0():\n    H0_70 = 70*u.km/u.s/u.Mpc\n    h100dist = 100 * u.Mpc/u.littleh\n    h100dist_with_h0 = h100dist.to(u.Mpc, u.with_H0(H0_70))\n    assert_quantity_allclose(h100dist_with_h0, 70*u.Mpc)\n\n    # make sure using the default cosmology works\n    H0_default_cosmo = cosmology.default_cosmology.get().H0\n    h100dist_with_default_h0 = h100dist.to(u.Mpc, u.with_H0())\n    assert_quantity_allclose(h100dist_with_default_h0, H0_default_cosmo.value*u.Mpc)\n\n    # Now try a luminosity scaling\n    h1lum = 1 * u.Lsun * u.littleh**-2\n    h1lum_with_h0 = h1lum.to(u.Lsun, u.with_H0(H0_70))\n    assert_quantity_allclose(h1lum_with_h0, .49*u.Lsun)\n\n    # And the trickiest one: magnitudes.  Using H0=10 here for the round numbers\n    H0_10 = 10*u.km/u.s/u.Mpc\n    # assume the \"true\" magnitude M = 12.\n    # Then M - 5*log_10(h)  = M + 5 = 17\n    withlittlehmag = 17 * (u.mag + u.MagUnit(u.littleh**2))\n    withlittlehmag_with_h0 = withlittlehmag.to(u.mag, u.with_H0(H0_10))\n    assert_quantity_allclose(withlittlehmag_with_h0, 12*u.mag)\n"], "sample_989": ["def test_Float_issue_10368():\n    a = S(32442016954)/78058255275\n    assert type(int(a)) is type(int(-a)) is int\n    assert int(a) == 41\n    assert int(-a) == -41\n"], "sample_735": ["def test_gaussian_mixture_lower_bound():\n    # Test that the lower bound is correctly computed\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng, scale=7)\n    n_components = rand_data.n_components\n\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        gmm = GaussianMixture(n_components=n_components,\n                              covariance_type=covar_type, random_state=rng,\n                              n_init=5)\n        gmm.fit(X)\n        log_prob_norm = gmm._estimate_log_prob(X)\n        lower_bound = gmm._compute_lower_bound(X, log_prob_norm)\n        assert_greater_equal(lower_bound, 0)\n"], "sample_1078": ["def test_IndexedBase_shape_precedence():\n    i, j = symbols('i j', integer=True)\n    o, p = symbols('o p', integer=True)\n    n, m = symbols('n m', integer=True)\n    a = IndexedBase('a', shape=(o, p))\n    assert Indexed(a, Idx(i, m), Idx(j, n)).ranges == [Tuple(0, m - 1), Tuple(0, n - 1)]\n    assert Indexed(a, Idx(i, m), Idx(j, n)).shape == Tuple(o, p)\n    assert Indexed(a, Idx(i, m), Idx(j)).ranges == [Tuple(0, m - 1), Tuple(None, None)]\n    assert Indexed(a, Idx(i, m), Idx(j)).shape == Tuple(o, p)\n"], "sample_1006": ["def test_subfactorial_diff():\n    x = Symbol('x')\n    n = Symbol('n', integer=True)\n\n    assert subfactorial(n).diff(n) == \\\n        (-subfactorial(n - 1) - subfactorial(n - 2))\n    assert subfactorial(x).diff(x) == \\\n        -subfactorial(x - 1) - subfactorial(x - 2)\n    assert subfactorial(n**2).diff(n) == \\\n        -2*n*subfactorial(n**2 - 1) - subfactorial(n**2 - 2)\n"], "sample_378": ["    def test_update_with_update_conflicts(self):\n        self.create_tags()\n        for note in self.notes:\n            note.tag = self.tags[0]\n        Note.objects.bulk_update(self.notes, ['tag'], update_conflicts=True)\n        self.assertCountEqual(Note.objects.filter(tag__isnull=False), self.notes)\n"], "sample_765": ["def test_precision_recall_fscore_support_multilabel_3():\n    # Test precision_recall_fscore_support on a crafted multilabel example 3\n    # Third crafted example\n    y_true = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 1, 1, 0]])\n    y_pred = np.array([[0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 0, 0]])\n\n    # tp = [ 0.  1.  0.  0.]\n    # fp = [ 1.  0.  0.  2.]\n    # fn = [ 1.  1.  1.  0.]\n\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred,\n                                                 average=None)\n    assert_array_almost_equal(p, [0.0, 1.0, 0.0, 0.0], 2)\n    assert_array_almost_equal(r, [0.0, 0.5, 0.0, 0.0], 2)\n    assert_array_almost_equal(f, [0.0, 0.66, 0.0, 0.0], 2)\n    assert_array_almost_equal(s, [1, 2, 1, 0], 2)\n\n    f2 = fbeta_score(y_true, y_pred, beta=2, average=None)\n    support = s\n    assert_array_almost_equal(f2, [0, 0.55, 0, 0], 2)\n\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred,\n                                                 average=\"micro\")\n    assert_almost_equal(p, 0.25)\n    assert_almost_equal(r, 0.25)\n    assert_almost_equal(f, 2 * 0.25 * 0.25 / 0.5)\n    assert_equal(s, None)\n    assert_almost_equal(fbeta_score(y_true, y_pred, beta=2,\n                                    average=\"micro\"),\n                        (1 + 4) * p * r / (4 * p + r))\n\n    p, r, f, s = precision_recall_fscore_support(y"], "sample_939": ["compilation error"], "sample_763": ["def test_check_array_large_sparse():\n    # Test that check_array raises an error when a large sparse matrix is not\n    # accepted\n    X = sp.rand(20, 10, format='csr')\n    for attr in ['indices', 'indptr', 'row', 'col']:\n        if hasattr(X, attr):\n            setattr(X, attr, getattr(X, attr).astype('int64'))\n    assert_raises_regex(ValueError, \"Only sparse matrices with 32-bit integer \"\n                                  \"indices are accepted. Got int64 indices.\",\n                        check_array, X, accept_sparse=True,\n                        accept_large_sparse=False)\n"], "sample_482": ["    def test_basic(self):\n        output = self.engine.render_to_string(\n            \"truncatechars_basic\", {\"a\": \"Hello, World!\", \"b\": \"Hello, World!\"}\n        )\n        self.assertEqual(output, \"Hello... -- Hello...\")\n"], "sample_26": ["    def test_scale_with_explicit_bscale(self):\n        \"\"\"\n        Regression test for https://github.com/astropy/astropy/issues/6399\n        \"\"\"\n        hdu2 = fits.ImageHDU(np.random.rand(100, 100))\n        # The line below raised an exception in astropy 2.0, so if it does not\n        # raise an error here, that is progress.\n        hdu2.scale(type=\"uint8\", bscale=1.0)\n"], "sample_103": ["def test_aggregate_with_subquery(self):\n    \"\"\"\n    Test that aggregate functions work with subquery annotations.\n    \"\"\"\n    long_books_count_qs = Book.objects.filter(\n        publisher=OuterRef('pk'),\n        pages__gt=400,\n    ).values(\n        'publisher'\n    ).annotate(count=Count('pk')).values('count')\n    vals = Publisher.objects.annotate(\n        long_books_count=Subquery(long_books_count_qs, output_field=IntegerField())\n    ).aggregate(Avg('long_books_count'))\n    self.assertEqual(vals, {'long_books_count__avg': Approximate(2.0, places=0)})\n"], "sample_931": ["def test_pydecorator_options(app):\n    text = (\".. py:decorator:: deco\\n\"\n            \"   :final:\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_addname, \"@\"],\n                                                    [desc_name, \"deco\"])],\n                                  [desc_content, ()])]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n\n    assert 'deco' in domain.objects\n    assert domain.objects['deco'] == ('index', 'deco', 'function')\n\n    text = (\".. py:decorator:: deco\\n\"\n            \"   :abstractmethod:\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_addname, \"@\"],\n                                                    [desc_name, \"deco\"])],\n                                  [desc_content, ()])]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n\n    assert 'deco' in domain.objects\n    assert domain.objects['deco'] == ('index', 'deco', 'function')\n\n    text = (\".. py:decorator:: deco\\n\"\n            \"   :async:\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_addname, \"@\"],\n                                                    [desc_name, \"deco\"])],\n                                  [desc_content, ()])]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n\n    assert 'deco' in domain.objects\n    assert domain.objects['deco'] == ('index', 'deco', 'function')\n\n    text = (\".. py:decorator:: deco\\n\"\n            \"   :classmethod:\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree,"], "sample_105": ["    def _assert_about(self, response):\n        response.render()\n        self.assertContains(response, '<h1>About</h1>')\n"], "sample_503": ["def test_set_markerfacecolor_fillstyle_none():\n    \"\"\"Test that markerfacecolor does not override fillstyle='none'.\"\"\"\n    l, = plt.plot([1, 3, 2], marker=MarkerStyle('o', fillstyle='none'),\n                  markerfacecolor='red')\n    assert l.get_fillstyle() == 'none'\n    assert l.get_markerfacecolor() == 'none'\n"], "sample_271": ["    def test_iter_modules_and_files_cache(self):\n        \"\"\"\n        iter_modules_and_files() is cached, so subsequent calls with the same\n        arguments should return the same result.\n        \"\"\"\n        self.clear_autoreload_caches()\n        self.assertEqual(autoreload.iter_modules_and_files((), frozenset()), frozenset())\n        self.assertEqual(autoreload.iter_modules_and_files((), frozenset()), frozenset())\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().hits, 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().misses, 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().maxsize, 1)\n"], "sample_244": ["    def test_clean_hook_called(self):\n        \"\"\"FormSets have a clean() hook for doing extra validation that isn't tied\n        to any form. It follows the same pattern as the clean() hook on Forms.\n        \"\"\"\n        # Start out with a some duplicate data.\n        data = {\n            'drinks-TOTAL_FORMS': '2',  # the number of forms rendered\n            'drinks-INITIAL_FORMS': '0',  # the number of forms with initial data\n            'drinks-MIN_NUM_FORMS': '0',  # min number of forms\n            'drinks-MAX_NUM_FORMS': '0',  # max number of forms\n            'drinks-0-name': 'Gin and Tonic',\n            'drinks-1-name': 'Gin and Tonic',\n        }\n        formset = FavoriteDrinksFormSet(data, prefix='drinks')\n        self.assertFalse(formset.is_valid())\n        # Any errors raised by formset.clean() are available via the\n        # formset.non_form_errors() method.\n        for error in formset.non_form_errors():\n            self.assertEqual(str(error), 'You may only specify a drink once.')\n        # The valid case still works.\n        data['drinks-1-name'] = 'Bloody Mary'\n        formset = FavoriteDrinksFormSet(data, prefix='drinks')\n        self.assertTrue(formset.is_valid())\n        self.assertEqual(formset.non_form_errors(), [])\n"], "sample_1049": ["def test_parameter_value_on_circle():\n    t, u, v = symbols(\"t, u v\")\n    p = Plane((0, 0, 0), (0, 0, 1), (0, 1, 0))\n    assert p.parameter_value(p.arbitrary_point(t)) == {t: 0}\n    assert p.parameter_value(p.arbitrary_point(u, v)) == {u: 0, v: 0}\n    assert p.parameter_value(p.arbitrary_point(u, v).subs(u, pi/2)) == {u: pi/2, v: 0}\n    assert p.parameter_value(p.arbitrary_point(u, v).subs(v, pi/2)) == {u: 0, v: pi/2}\n    assert p.parameter_value(p.arbitrary_point(u, v).subs(u, pi/2).subs(v, pi/2)) == {u: pi/2, v: pi/2}\n    raises(ValueError, lambda: p.parameter_value(p.arbitrary_point(u)))\n"], "sample_794": ["def test_ridge_regression_dtype_stability_sparse():\n    random_state = np.random.RandomState(0)\n    n_samples, n_features = 6, 5\n    X = random_state.randn(n_samples, n_features)\n    coef = random_state.randn(n_features)\n    y = np.dot(X, coef) + 0.01 * random_state.randn(n_samples)\n    alpha = 1.0\n    rtol = 1e-2 if os.name == 'nt' and _IS_32BIT else 1e-5\n\n    results = dict()\n    for current_dtype in (np.float32, np.float64):\n        X_sparse = sp.csr_matrix(X.astype(current_dtype))\n        results[current_dtype] = ridge_regression(X_sparse,\n                                                  y.astype(current_dtype),\n                                                  alpha=alpha,\n                                                  solver='cholesky',\n                                                  random_state=random_state,\n                                                  sample_weight=None,\n                                                  max_iter=500,\n                                                  tol=1e-10,\n                                                  return_n_iter=False,\n                                                  return_intercept=False)\n\n    assert results[np.float32].dtype == np.float32\n    assert results[np.float64].dtype == np.float64\n    assert_allclose(results[np.float32], results[np.float64], rtol=rtol)\n"], "sample_1176": ["def test_issue_10368():\n    a = Rational(32442016954, 78058255275)\n    assert a.as_coeff_Mul()[0] == 1\n    assert a.as_coeff_Mul()[1] == (a,)\n    assert a.as_coeff_Add()[0] == 0\n    assert a.as_coeff_Add()[1] == (a,)\n    assert a.as_coeff_Mul(rational=True) == (1, a)\n    assert a.as_coeff_Add(rational=True) == (0, a)\n    assert a.as_coeff_Mul()[0] == 1\n    assert a.as_coeff_Mul()[1] == (a,)\n    assert a.as_coeff_Add()[0] == 0\n    assert a.as_coeff_Add()[1] == (a,)\n    assert a.as_coeff_Mul(rational=True) == (1, a)\n    assert a.as_coeff_Add(rational=True) == (0, a)\n"], "sample_556": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect(.5)\n    ax2.set_box_aspect((2, 1, 1))\n    fig.tight_layout()\n    fig.draw_without_rendering()\n"], "sample_498": ["def test_legend_title_fontsize():\n    # test the title_fontsize kwarg\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontsize=22)\n    assert leg.get_title().get_fontsize() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontsize() == 20\n"], "sample_311": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.s1 = Section.objects.create(name='Test section')\n        cls.a1 = Article.objects.create(\n            content='<p>Middle content</p>', date=datetime.datetime(2008, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a2 = Article.objects.create(\n            content='<p>Oldest content</p>', date=datetime.datetime(2000, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a3 = Article.objects.create(\n            content='<p>Newest content</p>', date=datetime.datetime(2009, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n"], "sample_143": ["def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123'), 'hello world123')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc'), 'hello world123abc')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456'), 'hello world123abc456')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456def'), 'hello world123abc456def')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghi'), 'hello world123abc456defghi')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghij'), 'hello world123abc456defghij')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijk'), 'hello world123abc456defghijk')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijkl'), 'hello world123abc456defghijkl')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklm'), 'hello world123abc456defghijklm')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmn'), 'hello world123abc456defghijklmn')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmno'), 'hello world123abc456defghijklmno')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnop'), 'hello world123abc456defghijklmnop')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnoP'), 'hello world123abc456defghijklmno p')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnopqrstuvwxyz'), 'hello world123abc456defghijklmnopqrstuvwxyz')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnopqrstuvwxyzA'), 'hello world123abc456defghijklmnopqrstuvwxyz a')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnopqrstuvwxyzAB'), 'hello world123abc456defghijklmnopqrstuvwxyz ab')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnop"], "sample_925": ["def test_mock_invalid_module():\n    with pytest.raises(ValueError):\n        with mock(['non.existent.module']):\n            import_module('non.existent.module')\n\n    with pytest.raises(ValueError):\n        with mock(['non.existent.module']):\n            import_module('non.existent.module.submodule')\n\n    with pytest.raises(ValueError):\n        with mock(['non.existent.module']):\n            import_module('non.existent.module.submodule.subsubmodule')\n\n    with pytest.raises(ValueError):\n        with mock(['non.existent.module']):\n            import_module('non.existent.module.submodule.subsubmodule.subsubsubmodule')\n\n    with pytest.raises(ValueError):\n        with mock(['non.existent.module']):\n            import_module('non.existent.module.submodule.subsubmodule.subsubsubmodule.subsubsubmodule')\n\n    with pytest.raises(ValueError):\n        with mock(['non.existent.module']):\n            import_module('non.existent.module.submodule.subsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule')\n\n    with pytest.raises(ValueError):\n        with mock(['non.existent.module']):\n            import_module('non.existent.module.submodule.subsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule')\n\n    with pytest.raises(ValueError):\n        with mock(['non.existent.module']):\n            import_module('non.existent.module.submodule.subsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule')\n\n    with pytest.raises(ValueError):\n        with mock(['non.existent.module']):\n            import_module('non.existent.module.submodule.subsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule')\n\n    with pytest.raises(ValueError):\n        with mock(['non.existent.module']):\n            import_module('non.existent.module.submodule.subsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule')\n\n    with pytest.raises(ValueError):\n        with mock(['non.existent.module']):\n            import_module('non.existent.module.submodule.subsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule')\n\n    with pytest.raises(ValueError):\n        with mock(['non.existent.module']):\n            import_module('non.existent.module.submodule.subsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule.subsubsubmodule"], "sample_543": ["def test_cursor(ax):\n    cursor = widgets.Cursor(ax, horizOn=True, vertOn=True)\n    assert cursor.visible\n    assert cursor.horizOn\n    assert cursor.vertOn\n    assert cursor.useblit is False\n\n    cursor.clear(mock_event(ax.figure.canvas, 'draw_event'))\n    assert cursor.background is None\n\n    cursor.onmove(mock_event(ax.figure.canvas, 'motion_notify_event',\n                            xdata=100, ydata=100))\n    assert cursor.linev.get_xdata() == (100, 100)\n    assert cursor.linev.get_visible()\n    assert cursor.lineh.get_ydata() == (100, 100)\n    assert cursor.lineh.get_visible()\n\n    cursor.onmove(mock_event(ax.figure.canvas, 'motion_notify_event',\n                            xdata=100, ydata=200))\n    assert cursor.linev.get_xdata() == (100, 100)\n    assert cursor.linev.get_visible()\n    assert cursor.lineh.get_ydata() == (200, 200)\n    assert cursor.lineh.get_visible()\n\n    cursor.onmove(mock_event(ax.figure.canvas, 'motion_notify_event',\n                            xdata=200, ydata=200))\n    assert cursor.linev.get_xdata() == (200, 200)\n    assert cursor.linev.get_visible()\n    assert cursor.lineh.get_ydata() == (200, 200)\n    assert cursor.lineh.get_visible()\n\n    cursor.onmove(mock_event(ax.figure.canvas, 'motion_notify_event',\n                            xdata=200, ydata=100))\n    assert cursor.linev.get_xdata() == (200, 200)\n    assert cursor.linev.get_visible()\n    assert cursor.lineh.get_ydata() == (100, 100)\n    assert cursor.lineh.get_visible()\n\n    cursor.onmove(mock_event(ax.figure.canvas, 'motion_notify_event',\n                            xdata=100, ydata=100))\n    assert cursor.linev.get_xdata() == (100, 100)\n    assert cursor.linev.get_visible()\n    assert cursor.lineh.get_ydata() == (100, 100)\n    assert cursor.lineh.get_visible()\n\n    cursor.onmove(mock_event(ax.figure.canvas, 'motion_notify_event',\n                            xdata=100, ydata=100, button=2))\n    assert not cursor.linev.get_visible()\n    assert not cursor.lineh.get_visible()\n\n    cursor.onmove(mock_event(ax.figure.canvas, 'motion_notify_event',\n                           "], "sample_209": ["    def test_state_adding_attribute(self):\n        \"\"\"\n        Regression test for #12345: ModelState._state.adding attribute is not reset\n        \"\"\"\n        obj = Model()\n        self.assertTrue(obj._state.adding)\n        obj.save()\n        self.assertFalse(obj._state.adding)\n"], "sample_413": ["    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n"], "sample_1146": ["def test_latex_Dict():\n    from sympy import Dict\n    d = Dict({1: 1, 2: 2, 3: 3})\n    assert latex(d) == r'\\left\\{ 1 : 1, \\  2 : 2, \\  3 : 3\\right\\}'\n"], "sample_608": ["def test_inline_dask_repr(self) -> None:\n    da = xr.DataArray(np.arange(100), dims=\"test\", chunks=(10,))\n\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10,)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.arange(100), dims=\"test\", chunks=(10, 10))\n\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.arange(100), dims=\"test\", chunks=(10, 10, 10))\n\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10, 10)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.arange(100), dims=\"test\", chunks=(10, 10, 10, 10))\n\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10, 10, 10)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.arange(100), dims=\"test\", chunks=(10, 10, 10, 10, 10))\n\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10, 10, 10, 10)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.arange(100), dims=\"test\", chunks=(10, 10, 10, 10, 10, 10))\n\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10, 10, 10, 10, 10)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.arange(100), dims=\"test\", chunks=(10, 10, 10, 10, 10, 10, 10))\n\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10, 10, 10,"], "sample_499": ["def test_legend_title_fontprop_fontsize():\n    # test the title_fontsize kwarg\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontproperties=FontProperties(\n                                       family='serif', size=22))\n    assert leg.get_title().get_size() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontsize() == 20\n"], "sample_98": ["    def test_server_handler_close_connection(self):\n        \"\"\"\n        Test that ServerHandler.close() closes the connection.\n        \"\"\"\n        conn = HTTPConnection(LiveServerServerHandlerTests.server_thread.host, LiveServerServerHandlerTests.server_thread.port)\n        try:\n            conn.request('GET', '/example_view/', headers={'Connection': 'close'})\n            response = conn.getresponse()\n            self.assertTrue(response.will_close)\n            self.assertEqual(response.read(), b'example view')\n            self.assertEqual(response.status, 200)\n            self.assertEqual(response.getheader('Connection'), 'close')\n            # Test that close() closes the connection\n            response.close()\n            self.assertEqual(conn.sock.recv(1024), b'')\n        finally:\n            conn.close()\n"], "sample_742": ["def test_logistic_regressioncv_class_weight_multinomial():\n    # Test that passing class_weight as [1,2] is the same as\n    # passing class weight = [1,1] but adjusting sample weights\n    # to be 2 for all instances of class 2\n    X, y = make_classification(n_samples=30, n_features=3,\n                               n_repeated=0,\n                               n_informative=3, n_redundant=0,\n                               n_classes=2, random_state=0)\n\n    for solver in ['lbfgs', 'newton-cg']:\n        clf1 = LogisticRegressionCV(solver=solver, multi_class=\"multinomial\",\n                                   class_weight={0: 1, 1: 2})\n        clf2 = LogisticRegressionCV(solver=solver, multi_class=\"multinomial\")\n        clf2.fit(X, y, sample_weight=y + 1)\n        clf1.fit(X, y)\n        assert_array_almost_equal(clf1.coef_, clf2.coef_, decimal=4)\n"], "sample_955": ["compilation error"], "sample_94": ["    def test_password_validation_minimum_length(self):\n        \"\"\"\n        Creation should fail if the password is too short.\n        \"\"\"\n        new_io = StringIO()\n\n        # The first two passwords are too short, but the second two are valid.\n        entered_passwords = [\"a\", \"a\", \"password2\", \"password2\"]\n\n            return entered_passwords.pop(0)\n\n        @mock_inputs({\n            'password': short_passwords_then_valid,\n            'username': 'joe1234567890',\n            'email': '',\n        })\n            call_command(\n                \"createsuperuser\",\n                interactive=True,\n                stdin=MockTTY(),\n                stdout=new_io,\n                stderr=new_io,\n            )\n            self.assertEqual(\n                new_io.getvalue().strip(),\n                \"This password is too short. It must contain at least 8 characters.\\n\"\n                \"Superuser created successfully.\"\n            )\n\n        test(self)\n"], "sample_685": ["def test_log_cli_level(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_level == logging.INFO\n            logger = logging.getLogger('catchlog')\n            logger.warning(\"WARNING message won't be shown\")\n            logger.error(\"ERROR message will be shown\")\n            assert 'WARNING' not in caplog.text\n            assert 'ERROR' in caplog.text\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_cli_level=INFO\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n"], "sample_518": ["def test_fancyarrow_patch_units():\n    \"\"\"\n    Test that FancyArrowPatch works with units.\n    \"\"\"\n    from datetime import datetime\n    # Smoke test to check that FancyArrowPatch works with units\n    dtime = datetime(2000, 1, 1)\n    fig, ax = plt.subplots()\n    arrow = FancyArrowPatch((0, dtime), (0.01, dtime))\n    assert arrow.get_path().vertices[0] == (0, dtime)\n    assert arrow.get_path().vertices[1] == (0.01, dtime)\n"], "sample_571": ["    def test_regress_out(self):\n\n        x = np.array([1, 2, 3, 4, 5])\n        y = np.array([2, 4, 6, 8, 10])\n        z = np.array([1, 1, 1, 1, 1])\n\n        p = lm._RegressionPlotter(x, y, x_partial=z)\n        p.regress_out(x, z)\n        npt.assert_array_equal(p.x, np.array([0, 0, 0, 0, 0]))\n\n        p = lm._RegressionPlotter(x, y, y_partial=z)\n        p.regress_out(y, z)\n        npt.assert_array_equal(p.y, np.array([1, 3, 5, 7, 9]))\n\n        p = lm._RegressionPlotter(x, y, x_partial=z, y_partial=z)\n        p.regress_out(x, z)\n        npt.assert_array_equal(p.x, np.array([0, 0, 0, 0, 0]))\n        p.regress_out(y, z)\n        npt.assert_array_equal(p.y, np.array([1, 3, 5, 7, 9]))\n\n        x = pd.Series(x)\n        y = pd.Series(y)\n        z = pd.Series(z)\n        p = lm._RegressionPlotter(x, y, x_partial=z)\n        p.regress_out(x, z)\n        npt.assert_array_equal(p.x, pd.Series([0, 0, 0, 0, 0]))\n\n        p = lm._RegressionPlotter(x, y, y_partial=z)\n        p.regress_out(y, z)\n        npt.assert_array_equal(p.y, pd.Series([1, 3, 5, 7, 9]))\n\n        p = lm._RegressionPlotter(x, y, x_partial=z, y_partial=z)\n        p.regress_out(x, z)\n        npt.assert_array_equal(p.x, pd.Series([0, 0, 0, 0, 0]))\n        p.regress_out(y, z)\n        npt.assert_array_equal(p.y, pd.Series([1, 3, 5, 7, 9]))\n"], "sample_419": ["    def test_custom_renderer(self):\n        \"\"\"\n        A custom renderer passed to a formset_factory() is passed to all forms\n        and ErrorList.\n        \"\"\"\n        from django.forms.renderers import Jinja2\n\n        renderer = Jinja2()\n        data = {\n            \"choices-TOTAL_FORMS\": \"2\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Zero\",\n            \"choices-0-votes\": \"\",\n            \"choices-1-choice\": \"One\",\n            \"choices-1-votes\": \"\",\n        }\n        ChoiceFormSet = formset_factory(Choice, renderer=renderer)\n        formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertEqual(formset.renderer, renderer)\n        self.assertEqual(formset.forms[0].renderer, renderer)\n        self.assertEqual(formset.management_form.renderer, renderer)\n        self.assertEqual(formset.non_form_errors().renderer, renderer)\n        self.assertEqual(formset.empty_form.renderer, renderer)\n"], "sample_645": ["def test_log_cli_level(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            logger = logging.getLogger('catchlog')\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_level == logging.INFO\n\n            logger.debug(\"DEBUG message won't be shown\")\n\n            with caplog.at_level(logging.DEBUG, logger.name):\n                logger.debug(\"DEBUG message will be shown\")\n\n            logger.debug(\"DEBUG message won't be shown\")\n\n            assert \"message won't be shown\" not in caplog.text\n    \"\"\"\n    )\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_cli_level=INFO\n    \"\"\"\n    )\n\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*DEBUG message will be shown*\"])\n    result.stdout.no_fnmatch_line(\"*DEBUG message won't be shown*\")\n    assert result.ret == 0\n"], "sample_523": ["def test_legend_title_fontprop_fontsize():\n    # test the title_fontsize kwarg\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontproperties=FontProperties(\n                                       family='serif', size=22))\n    assert leg.get_title().get_size() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontsize() == 20\n"], "sample_730": ["def test_enet_path_return_models():\n    # Test that lasso_path with models=True gives the same result\n\n    # Some toy data\n    X = np.array([[1, 2, 3.1], [2.3, 5.4, 4.3]]).T\n    y = np.array([1, 2, 3.1])\n    alphas = [5., 1., .5]\n\n    # Use lars_path and lasso_path(models=True) to compute the same path\n    alphas_lars, active, coef_path_lars = lars_path(X, y, method='lasso',\n                                                    models=True)\n    coef_path_cont_lars = interpolate.interp1d(alphas_lars[::-1],\n                                               coef_path_lars[:, ::-1])\n    alphas_lasso2, coef_path_lasso2, _ = lasso_path(X, y, alphas=alphas,\n                                                    return_models=True)\n    coef_path_cont_lasso = interpolate.interp1d(alphas_lasso2[::-1],\n                                                coef_path_lasso2[:, ::-1])\n\n    assert_array_almost_equal(\n        coef_path_cont_lasso(alphas), coef_path_cont_lars(alphas),\n        decimal=1)\n"], "sample_754": ["def test_mini_batch_fit_transform_parallel(norm_comp):\n    raise SkipTest(\"skipping mini_batch_fit_transform.\")\n    alpha = 1\n    rng = np.random.RandomState(0)\n    Y, _, _ = generate_toy_data(3, 10, (8, 8), random_state=rng)  # wide array\n    spca_lars = MiniBatchSparsePCA(n_components=3, random_state=0,\n                                   alpha=alpha,\n                                   normalize_components=norm_comp).fit(Y)\n    U1 = spca_lars.transform(Y)\n    # Test multiple CPUs\n    if sys.platform == 'win32':  # fake parallelism for win32\n        import sklearn.externals.joblib.parallel as joblib_par\n        _mp = joblib_par.multiprocessing\n        joblib_par.multiprocessing = None\n        try:\n            spca = MiniBatchSparsePCA(n_components=3, n_jobs=2, alpha=alpha,\n                                      random_state=0,\n                                      normalize_components=norm_comp)\n            U2 = spca.fit(Y).transform(Y)\n        finally:\n            joblib_par.multiprocessing = _mp\n    else:  # we can efficiently use parallelism\n        spca = MiniBatchSparsePCA(n_components=3, n_jobs=2, alpha=alpha,\n                                  random_state=0,\n                                  normalize_components=norm_comp)\n        U2 = spca.fit(Y).transform(Y)\n    assert_true(not np.all(spca_lars.components_ == 0))\n    assert_array_almost_equal(U1, U2)\n    # Test that CD gives similar results\n    spca_lasso = MiniBatchSparsePCA(n_components=3, method='cd', alpha=alpha,\n                                    random_state=0,\n                                    normalize_components=norm_comp).fit(Y)\n    assert_array_almost_equal(spca_lasso.components_, spca_lars.components_)\n"], "sample_109": ["def test_build_attrs_multiple_selected(self):\n    form = AlbumForm()\n    attrs = form['featuring'].field.widget.build_attrs({})\n    self.assertJSONEqual(attrs['data-allow-clear'], False)\n"], "sample_683": ["    def test_capture_manager_repr(self):\n        capman = CaptureManager(\"fd\")\n        assert repr(capman) == \"<CaptureManager _method='fd' _global_capturing=None _capture_fixture=None>\"\n"], "sample_943": ["def test_maxdepth(make_app, apidoc):\n    outdir = apidoc.outdir\n    assert (outdir / 'conf.py').isfile()\n    assert (outdir / 'a.rst').isfile()\n    assert (outdir / 'a.b.rst').isfile()\n    assert not (outdir / 'a.b.c.rst').isfile()\n\n    app = make_app('text', srcdir=outdir)\n    app.build()\n    print(app._status.getvalue())\n    print(app._warning.getvalue())\n\n    builddir = outdir / '_build' / 'text'\n    assert (builddir / 'a.txt').isfile()\n    assert (builddir / 'a.b.txt').isfile()\n    assert not (builddir / 'a.b.c.txt').isfile()\n\n    with open(builddir / 'a.txt') as f:\n        txt = f.read()\n        assert \"a package\\n\" in txt\n\n    with open(builddir / 'a.b.txt') as f:\n        txt = f.read()\n        assert \"a.b package\\n\" in txt\n"], "sample_694": ["def test_argparse_percent_default_is_deprecated():\n    with pytest.warns(\n        pytest.PytestRemovedIn8Warning,\n        match=re.escape(\n            \"pytest now uses argparse. '%default' should be changed to '%(default)s'\"\n        ),\n    ):\n        pytest.main([\"--help\"])\n"], "sample_690": ["    def test_xfail_raises(self, pytester: Pytester, raises, expected) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(raises=%s)\n                raise %s()\n        \"\"\"\n            % (raises, raises)\n        )\n        result = pytester.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 failed*\"])\n        assert expected in result.stdout.str()\n"], "sample_138": ["    def test_manifest(self):\n        self.assertIsNone(storage.staticfiles_storage.read_manifest())\n        self.assertEqual(storage.staticfiles_storage.hashed_files, {})\n        self.run_collectstatic()\n        self.assertIsNone(storage.staticfiles_storage.read_manifest())\n        self.assertEqual(storage.staticfiles_storage.hashed_files, {})\n"], "sample_1194": ["def test_HadamardPower():\n    A = MatrixSymbol('A', 3, 3)\n    B = MatrixSymbol('B', 3, 3)\n    assert julia_code(A**B) == \"A .^ B\"\n    assert julia_code(B**A) == \"B .^ A\"\n    assert julia_code(2*A**B) == \"2 * A .^ B\"\n    assert julia_code(B*2*A**B) == \"2 * B * A .^ B\"\n"], "sample_388": ["    def test_last_login(self):\n        \"\"\"\n        A user's last_login is set the first time they make a\n        request but not updated in subsequent requests with the same session.\n        \"\"\"\n        user = User.objects.create(username=\"knownuser\")\n        # Set last_login to something so we can determine if it changes.\n        default_login = datetime(2000, 1, 1)\n        if settings.USE_TZ:\n            default_login = default_login.replace(tzinfo=timezone.utc)\n        user.last_login = default_login\n        user.save()\n\n        response = self.client.get(\"/remote_user/\", **{self.header: self.known_user})\n        self.assertNotEqual(default_login, response.context[\"user\"].last_login)\n\n        user = User.objects.get(username=\"knownuser\")\n        user.last_login = default_login\n        user.save()\n        response = self.client.get(\"/remote_user/\", **{self.header: self.known_user})\n        self.assertEqual(default_login, response.context[\"user\"].last_login)\n"], "sample_262": ["def test_lazy_class_preparation_caching_with_multiple_result_classes(self):\n    # lazy() should prepare the proxy class only once i.e. the first time\n    # it's used, even if multiple result classes are specified.\n    lazified = lazy(lambda: 0, int, str)\n    __proxy__ = lazified().__class__\n    with mock.patch.object(__proxy__, '__prepare_class__') as mocked:\n        lazified()\n        mocked.assert_called_once()\n"], "sample_322": ["def test_migrate_with_replaced_migration(self):\n    \"\"\"\n    Test migrating with a replaced migration.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Prepare for migration\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n    executor.migrate([(\"migrations2\", \"0001_initial\")])\n    executor.loader.build_graph()\n    # Create a replaced migration\n    migration = executor.loader.get_migration(\"migrations\", \"0002_second\")\n    migration.replaces = [(\"migrations2\", \"0001_initial\")]\n    # Migrate with the replaced migration\n    executor.migrate([(\"migrations\", \"0002_second\")])\n    # Check that the replaced migration is marked as applied\n    self.assertIn((\"migrations2\", \"0001_initial\"), executor.recorder.applied_migrations())\n    # Check that the replaced migration is not marked as unapplied\n    self.assertNotIn((\"migrations2\", \"0001_initial\"), executor.recorder.unapplied_migrations())\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Migrate backwards\n    executor.migrate([(\"migrations\", None)])\n    # Check that the replaced migration is marked as unapplied\n    self.assertIn((\"migrations2\", \"0001_initial\"), executor.recorder.unapplied_migrations())\n    # Check that the replaced migration is not marked as applied\n    self.assertNotIn((\"migrations2\", \"0001_initial\"), executor.recorder.applied_migrations())\n"], "sample_514": ["def test_colorbar_orientation():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc, orientation='vertical')\n    assert cb.orientation == 'vertical'\n    cb = fig.colorbar(pc, orientation='horizontal')\n    assert cb.orientation == 'horizontal'\n    cb = fig.colorbar(pc, orientation='invalid')\n    with pytest.raises(TypeError):\n        cb.orientation\n"], "sample_751": ["def test_forest_classifier():\n    # Check consistency on dataset iris.\n    classes = np.unique(iris.target)\n    clf_samme = prob_samme = None\n\n    for alg in ['SAMME', 'SAMME.R']:\n        clf = RandomForestClassifier(algorithm=alg)\n        clf.fit(iris.data, iris.target)\n\n        assert_array_equal(classes, clf.classes_)\n        proba = clf.predict_proba(iris.data)\n        if alg == \"SAMME\":\n            clf_samme = clf\n            prob_samme = proba\n        assert_equal(proba.shape[1], len(classes))\n        assert_equal(clf.decision_function(iris.data).shape[1], len(classes))\n\n        score = clf.score(iris.data, iris.target)\n        assert score > 0.9, \"Failed with algorithm %s and score = %f\" % \\\n            (alg, score)\n\n        # Check we used multiple estimators\n        assert_greater(len(clf.estimators_), 1)\n        # Check for distinct random states (see issue #7408)\n        assert_equal(len(set(est.random_state for est in clf.estimators_)),\n                     len(clf.estimators_))\n\n    # Somewhat hacky regression test: prior to\n    # ae7adc880d624615a34bafdb1d75ef67051b8200,\n    # predict_proba returned SAMME.R values for SAMME.\n    clf_samme.algorithm = \"SAMME.R\"\n    assert_array_less(0,\n                      np.abs(clf_samme.predict_proba(iris.data) - prob_samme))\n"], "sample_1175": ["compilation error"], "sample_71": ["def test_decimal_pos_with_zero(self):\n    self.assertEqual(nformat(Decimal('0.00000001'), '.', decimal_pos=8), '0.00000001')\n    self.assertEqual(nformat(Decimal('0.00000001'), '.', decimal_pos=0), '0')\n    self.assertEqual(nformat(Decimal('0.00000001'), '.', decimal_pos=1), '0.0')\n    self.assertEqual(nformat(Decimal('0.00000001'), '.', decimal_pos=2), '0.00')\n    self.assertEqual(nformat(Decimal('0.00000001'), '.', decimal_pos=3), '0.000')\n    self.assertEqual(nformat(Decimal('0.00000001'), '.', decimal_pos=4), '0.0000')\n    self.assertEqual(nformat(Decimal('0.00000001'), '.', decimal_pos=5), '0.00000')\n    self.assertEqual(nformat(Decimal('0.00000001'), '.', decimal_pos=6), '0.000000')\n    self.assertEqual(nformat(Decimal('0.00000001'), '.', decimal_pos=7), '0.0000000')\n    self.assertEqual(nformat(Decimal('0.00000001'), '.', decimal_pos=8), '0.00000001')\n    self.assertEqual(nformat(Decimal('0.00000001'), '.', decimal_pos=9), '0.000000010')\n    self.assertEqual(nformat(Decimal('0.00000001'), '.', decimal_pos=10), '0.0000000100')\n"], "sample_1086": ["def test_Dict_printing():\n    d = Dict({1: 1 + x, 2: y*x})\n    assert str(d) == \"{1: x + 1, 2: x*y}\"\n    assert sstr(d) == \"{1: x + 1, 2: x*y}\"\n"], "sample_222": ["    def test_locking_file_with_non_existent_path(self):\n        with self.assertRaises(FileNotFoundError):\n            locks.lock('non_existent_file.txt', locks.LOCK_EX)\n"], "sample_612": ["def test_groupby_dataset_reduce_axis_error() -> None:\n    data = Dataset({\"foo\": (\"x\", [1, 2, 3, 4])}, {\"x\": [1, 2, 3]})\n    with pytest.raises(ValueError, match=r\"only one of the 'dimension' and 'axis' arguments can be supplied\"):\n        data.groupby(\"x\").reduce(np.mean, dim=\"x\", axis=1)\n"], "sample_205": ["def test_update_error_dict(self):\n    error1 = ValidationError('message')\n    error2 = ValidationError('message', code='my_code1')\n    error3 = ValidationError('message', code='my_code2')\n    error4 = ValidationError(\n        'error %(parm1)s %(parm2)s',\n        code='my_code1',\n        params={'parm1': 'val1', 'parm2': 'val2'},\n    )\n    error5 = ValidationError({'field1': 'message', 'field2': 'other'})\n    error6 = ValidationError({'field1': 'message'})\n    error7 = ValidationError([\n        ValidationError({'field1': 'field error', 'field2': 'other'}),\n        'message',\n    ])\n\n    error_dict = {}\n    error1.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['message']})\n\n    error2.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['message', 'my_code1']})\n\n    error3.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['message', 'my_code1', 'my_code2']})\n\n    error4.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {\n        '__all__': ['message', 'my_code1', 'my_code2', 'error val1 val2'],\n    })\n\n    error5.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {\n        'field1': ['message'],\n        'field2': ['other'],\n        '__all__': ['message', 'my_code1', 'my_code2', 'error val1 val2'],\n    })\n\n    error6.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {\n        'field1': ['message'],\n        'field2': [],\n        '__all__': ['message', 'my_code1', 'my_code2', 'error val1 val2'],\n    })\n\n    error7.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {\n        'field1': ['field error', 'message'],\n        'field2': ['other'],\n        '__all__': ['message', 'my_code1', 'my_code2', 'error val1 val2'],\n    })\n\n    error_dict = {}\n    error1.update_error_dict(error_dict, 'field1')\n    self.assertEqual(error_dict, {'field1': ['message']})\n\n    error2.update_error_dict(error_dict, 'field1')\n    self"], "sample_668": ["def test_funcargnames_deprecation():\n    \"\"\"Check that funcargnames is deprecated and raises a PytestDeprecationWarning\"\"\"\n    with pytest.warns(PytestDeprecationWarning, match=\"The `funcargnames` attribute was an alias for `fixturenames`\"):\n        class TestClass:\n                pass\n\n    with pytest.raises(AttributeError):\n        class TestClass:\n                pass\n"], "sample_1000": ["def test_LambertW_piecewise():\n    pw = Piecewise((LambertW(x), x > 0), (LambertW(x, 2), True))\n    assert mcode(pw) == \"((x > 0).*(lambertw(x)) + (~(x > 0)).*(lambertw(2, x)))\"\n    assert mcode(pw, assign_to=\"r\") == (\n        \"r = ((x > 0).*(lambertw(x)) + (~(x > 0)).*(lambertw(2, x)));\")\n    assert mcode(pw, assign_to=\"r\", inline=False) == (\n        \"if (x > 0)\\n\"\n        \"  r = lambertw(x);\\n\"\n        \"else\\n\"\n        \"  r = lambertw(2, x);\\n\"\n        \"end\")\n"], "sample_1160": ["def test_imageset_intersection_interval():\n    from sympy.abc import n\n    f1 = ImageSet(Lambda(n, n*pi), S.Integers)\n    f2 = ImageSet(Lambda(n, 2*n), Interval(0, pi))\n    f3 = ImageSet(Lambda(n, 2*n*pi + pi/2), S.Integers)\n    # complex expressions\n    f4 = ImageSet(Lambda(n, n*I*pi), S.Integers)\n    f5 = ImageSet(Lambda(n, 2*I*n*pi + pi/2), S.Integers)\n    # non-linear expressions\n    f6 = ImageSet(Lambda(n, log(n)), S.Integers)\n    f7 = ImageSet(Lambda(n, n**2), S.Integers)\n    f8 = ImageSet(Lambda(n, Abs(n)), S.Integers)\n    f9 = ImageSet(Lambda(n, exp(n)), S.Naturals0)\n\n    assert f1.intersect(Interval(-1, 1)) == FiniteSet(0)\n    assert f1.intersect(Interval(0, 2*pi, False, True)) == FiniteSet(0, pi)\n    assert f2.intersect(Interval(1, 2)) == Interval(1, 2)\n    assert f3.intersect(Interval(-1, 1)) == S.EmptySet\n    assert f3.intersect(Interval(-5, 5)) == FiniteSet(pi*Rational(-3, 2), pi/2)\n    assert f4.intersect(Interval(-1, 1)) == FiniteSet(0)\n    assert f4.intersect(Interval(1, 2)) == S.EmptySet\n    assert f5.intersect(Interval(0, 1)) == S.EmptySet\n    assert f6.intersect(Interval(0, 1)) == FiniteSet(S.Zero, log(2))\n    assert f7.intersect(Interval(0, 10)) == Intersection(f7, Interval(0, 10))\n    assert f8.intersect(Interval(0, 2)) == Intersection(f8, Interval(0, 2))\n    assert f9.intersect(Interval(1, 2)) == Intersection(f9, Interval(1, 2))\n"], "sample_1067": ["def test_issue_5718():\n    x, y = symbols('x y')\n    a, b, c = symbols('a b c', cls=Wild, exclude=(x, y))\n    e = (x + y)**2\n    assert e.match(a*x + b*y + c) == {a: 2, b: 2, c: 0}\n    assert e.match(a*x + b*y + c + 1) == {a: 2, b: 2, c: 1}\n    assert e.match(a*x + b*y + c + x*y) == {a: 1, b: 1, c: x*y}\n    assert e.match(a*x + b*y + c + x*y + 1) == {a: 1, b: 1, c: x*y + 1}\n"], "sample_501": ["def test_legend_title_fontprop_fontsize():\n    # test the title_fontsize kwarg\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontproperties=FontProperties(\n                                       family='serif', size=22))\n    assert leg.get_title().get_size() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontsize() == 20\n"], "sample_752": ["def test_iforest_offset():\n    \"\"\"Check that the offset is correctly set when contamination is not 'auto'.\"\"\"\n    X_train = [[1, 1], [1, 2], [2, 1]]\n    clf = IsolationForest(contamination=0.1).fit(X_train)\n    assert_almost_equal(clf.offset_, sp.stats.scoreatpercentile(\n        clf.score_samples(X_train), 100. * 0.1))\n    clf = IsolationForest(contamination=0.5).fit(X_train)\n    assert_almost_equal(clf.offset_, sp.stats.scoreatpercentile(\n        clf.score_samples(X_train), 100. * 0.5))\n"], "sample_502": ["def test_matshow():\n    fig, ax = plt.subplots()\n    matshow(np.array([[1, 2], [3, 4]]))\n    assert ax.get_title() == 'matshow'\n    assert ax.get_xlabel() == '1'\n    assert ax.get_ylabel() == '0'\n    assert ax.get_xlim() == (0, 2)\n    assert ax.get_ylim() == (0, 1)\n    assert ax.get_aspect() == 'auto'\n    plt.close()\n"], "sample_230": ["def test_invalid_json_with_custom_decoder(self):\n    class CustomDecoder(json.JSONDecoder):\n            return super().__init__(object_hook=self.as_uuid, *args, **kwargs)\n\n            if 'uuid' in dct:\n                dct['uuid'] = uuid.UUID(dct['uuid'])\n            return dct\n\n    field = JSONField(decoder=CustomDecoder)\n    with self.assertRaisesMessage(ValidationError, 'Enter a valid JSON.'):\n        field.clean('{some badly formed: json}')\n"], "sample_1202": ["def test_issue_10368():\n    from sympy import Rational\n    a = Rational(32442016954, 78058255275)\n    assert int(a) == 41\n    assert int(-a) == -41\n"], "sample_349": ["    def test_build_attrs_i18n(self):\n        \"\"\"Test that the language code is correctly set in the data-lang attribute.\"\"\"\n        rel = Album._meta.get_field('band')\n        w = AutocompleteSelect(rel, admin.site)\n        with translation.override('fr'):\n            attrs = w.build_attrs({}, extra_attrs={'data-lang': 'fr'})\n            self.assertEqual(attrs['lang'], 'fr')\n"], "sample_636": ["def test_duplicate_code_raw_strings_disable_scope_function_double(self) -> None:\n    \"\"\"Tests disabling duplicate-code at an inner scope level with another scope with similarity in two files.\"\"\"\n    path = join(DATA, \"raw_strings_disable_scope_function_double\")\n    self._runtest([path, \"--disable=all\", \"--enable=duplicate-code\"], code=0)\n"], "sample_1129": ["def test_SymPyPrinter():\n    p = SymPyPrinter()\n    assert p.doprint(S.Pi) == 'sympy.pi'\n    assert p.doprint(S.Exp1) == 'sympy.E'\n    assert p.doprint(S.GoldenRatio) == 'sympy.GoldenRatio'\n    assert p.doprint(S.EulerGamma) == 'sympy.EulerGamma'\n    assert p.doprint(S.NaN) == 'sympy.nan'\n    assert p.doprint(S.Infinity) == 'sympy.oo'\n    assert p.doprint(S.NegativeInfinity) == 'sympy.NegativeInfinity'\n    assert p.doprint(loggamma(x)) == 'sympy.loggamma(x)'\n"], "sample_317": ["def test_rss2_feed_enclosures(self):\n    \"\"\"\n    Test the structure and content of enclosures in RSS feeds generated by Rss201rev2Feed.\n    \"\"\"\n    response = self.client.get('/syndication/rss2/enclosures/')\n    doc = minidom.parseString(response.content)\n    chan = doc.getElementsByTagName('rss')[0].getElementsByTagName('channel')[0]\n    items = chan.getElementsByTagName('item')\n    for item in items:\n        enclosures = item.getElementsByTagName('enclosure')\n        self.assertEqual(len(enclosures), 1)\n        enclosure = enclosures[0]\n        self.assertEqual(enclosure.getAttribute('url'), 'http://example.com/enclosure.mp3')\n        self.assertEqual(enclosure.getAttribute('length'), '123456')\n        self.assertEqual(enclosure.getAttribute('type'), 'audio/mpeg')\n"], "sample_464": ["def test_content_disposition_buffer_filename(self):\n    response = FileResponse(io.BytesIO(b\"binary content\"), filename=\"custom_name.py\")\n    self.assertEqual(response.headers[\"Content-Disposition\"], \"inline; filename=custom_name.py\")\n"], "sample_489": ["def test_update_conflicts_unique_fields_update_fields_db_column(self):\n    FieldsWithDbColumns.objects.bulk_create(\n        [\n            FieldsWithDbColumns(rank=1, name=\"a\"),\n            FieldsWithDbColumns(rank=2, name=\"b\"),\n        ]\n    )\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n\n    conflicting_objects = [\n        FieldsWithDbColumns(rank=1, name=\"c\"),\n        FieldsWithDbColumns(rank=2, name=\"d\"),\n    ]\n    results = FieldsWithDbColumns.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        unique_fields=[\"rank\"],\n        update_fields=[\"name\", \"db_column\"],\n    )\n    self.assertEqual(len(results), len(conflicting_objects))\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n    self.assertCountEqual(\n        FieldsWithDbColumns.objects.values(\"rank\", \"name\", \"db_column\"),\n        [\n            {\"rank\": 1, \"name\": \"c\", \"db_column\": \"c\"},\n            {\"rank\": 2, \"name\": \"d\", \"db_column\": \"d\"},\n        ],\n    )\n"], "sample_475": ["    def test_prepopulated_fields_with_choices(self):\n        class TestModelAdmin(ModelAdmin):\n            prepopulated_fields = {\"choices\": (\"name\",)}\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'prepopulated_fields' refers to 'choices', which must \"\n            \"not be a DateTimeField, a ForeignKey, a OneToOneField, or a \"\n            \"ManyToManyField.\",\n            \"admin.E028\",\n        )\n"], "sample_63": ["    def test_template_library(self):\n        engine = Engine(dirs=[TEMPLATE_DIR], libraries={'lib': 'django.template.library'})\n        template = engine.get_template('test_library.html')\n        self.assertEqual(template.render(Context()), 'lib: test\\n')\n"], "sample_700": ["    def test_parametrize_with_indirect(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture\n                return request.param\n            @pytest.mark.parametrize(\"arg\", [1, 2], indirect=True)\n                assert arg == 1\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n"], "sample_213": ["    def setUp(self):\n        self.storage = FileSystemStorage(location=tempfile.mkdtemp())\n"], "sample_313": ["    def test_template_dirs_normalized_to_paths(self):\n        self.assertSetEqual(\n            autoreload.get_template_directories(),\n            {\n                Path(ROOT, 'absolute_str'),\n                Path('template_tests', 'relative_str'),\n            }\n        )\n"], "sample_952": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n        pass\n\n    @singledispatch\n        pass\n\n    assert inspect.is_singledispatch_function(func) is False\n    assert inspect.is_singledispatch_function(singledispatch_func) is True\n\n        pass\n\n    class Foo:\n        @singledispatch\n            pass\n\n    assert inspect.is_singledispatch_method(singledispatch_method) is False\n    assert inspect.is_singledispatch_method(singledispatch_method()) is False\n    assert inspect.is_singledispatch_method(Foo().singledispatch_meth) is True\n"], "sample_756": ["def test_max_eps_check():\n    # Test that we check a maximum epsilon\n    msg = (\"Specify an epsilon smaller than 0.15. Got 0.3.\")\n    centers = [[1, 1], [-1, -1], [1, -1]]\n    X, labels_true = make_blobs(n_samples=750, centers=centers,\n                                cluster_std=0.4, random_state=0)\n\n    clust = OPTICS(max_eps=0.3, min_samples=10)\n    assert_raise_message(ValueError, msg, clust.extract_dbscan, 0.3)\n"], "sample_423": ["    def test_add_field_with_default_callable(self):\n        \"\"\"#23609 - Adding a field with a callable default should work.\"\"\"\n        changes = self.get_changes([self.author_empty], [self.author_name_default])\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertOperationTypes(changes, \"testapp\", 0, [\"AddField\"])\n        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n        self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=\"Ada Lovelace\")\n"], "sample_808": ["def test_iforest_max_features():\n    \"\"\"Check Isolation Forest for various max_features settings.\"\"\"\n    X_train = np.array([[0, 1], [1, 2]])\n    X_test = np.array([[2, 1], [1, 1]])\n\n    grid = ParameterGrid({\"max_features\": [1.0, 2, 0.5]})\n\n    with ignore_warnings():\n        for params in grid:\n            IsolationForest(random_state=rng, **params).fit(X_train).predict(X_test)\n"], "sample_23": ["def test_angle_pickle():\n    \"\"\"\n    Ensure that after pickling we can still do to_value on hourangle.\n    \"\"\"\n    angle = Angle(0.25 * u.hourangle)\n    expected = angle.to_value()\n    via_pickle = pickle.loads(pickle.dumps(angle))\n    via_pickle_value = via_pickle.to_value()\n    assert np.allclose(via_pickle_value, expected)\n"], "sample_269": ["    def test_json_catalog(self):\n        \"\"\"\n        The json_catalog view returns the language catalog and settings as JSON.\n        \"\"\"\n        with override('de'):\n            response = self.client.get('/jsoni18n/')\n            data = json.loads(response.content.decode())\n            self.assertIn('catalog', data)\n            self.assertIn('formats', data)\n            self.assertEqual(data['formats']['TIME_INPUT_FORMATS'], ['%H:%M:%S', '%H:%M:%S.%f', '%H:%M'])\n            self.assertEqual(data['formats']['FIRST_DAY_OF_WEEK'], 0)\n            self.assertIn('plural', data)\n            self.assertEqual(data['plural'], '(n != 1)')\n            self.assertIn('DATETIME_FORMAT', data['formats'])\n"], "sample_1008": ["def test_orientnew_respects_input_latexs_and_variables():\n    N = ReferenceFrame('N')\n    q1 = dynamicsymbols('q1')\n    A = N.orientnew('a', 'Axis', [q1, N.z])\n\n    #build default and alternate latex_vecs and variables:\n    def_latex_vecs = [(r\"\\mathbf{\\hat{%s}_%s}\" % (A.name.lower(),\n                      A.indices[0])), (r\"\\mathbf{\\hat{%s}_%s}\" %\n                      (A.name.lower(), A.indices[1])),\n                      (r\"\\mathbf{\\hat{%s}_%s}\" % (A.name.lower(),\n                      A.indices[2]))]\n\n    name = 'b'\n    indices = [x+'1' for x in N.indices]\n    new_latex_vecs = [(r\"\\mathbf{\\hat{%s}_{%s}}\" % (name.lower(),\n                      indices[0])), (r\"\\mathbf{\\hat{%s}_{%s}}\" %\n                      (name.lower(), indices[1])),\n                      (r\"\\mathbf{\\hat{%s}_{%s}}\" % (name.lower(),\n                      indices[2]))]\n\n    new_variables = ['notb_'+x+'1' for x in N.indices]\n    B = N.orientnew(name, 'Axis', [q1, N.z], latexs=new_latex_vecs,\n                    variables=new_variables)\n\n    assert A.latex_vecs == def_latex_vecs\n    assert B.latex_vecs == new_latex_vecs\n    assert B.indices != indices\n    for j,var in enumerate(A.varlist):\n        assert var.name == A.name + '_' + A.indices[j]\n    for j,var in enumerate(B.varlist):\n        assert var.name == new_variables[j]\n"], "sample_180": ["    def test_unique_constraint_pointing_to_non_local_field_in_parent(self):\n        class Parent(models.Model):\n            field1 = models.IntegerField()\n\n        class Child(Parent):\n            field2 = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(fields=['field2', 'field1'], name='name'),\n                ]\n\n        self.assertEqual(Child.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to field 'field1' which is not local to \"\n                \"model 'Child'.\",\n                hint='This issue may be caused by multi-table inheritance.',\n                obj=Child,\n                id='models.E016',\n            ),\n        ])\n"], "sample_191": ["    def setUp(self):\n        self._tempdir = tempfile.TemporaryDirectory()\n        self.tempdir = Path(self._tempdir.name).resolve(strict=True).absolute()\n        self.existing_file = self.ensure_file(self.tempdir / 'test.py')\n        self.nonexistent_file = (self.tempdir / 'does_not_exist.py').absolute()\n        self.reloader = autoreload.StatReloader()\n"], "sample_922": ["def test_pydata_signature_with_type_and_value(app):\n    text = (\".. py:data:: var\\n\"\n            \"   :type: int\\n\"\n            \"   :value: 1\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"var\"],\n                                                    [desc_annotation, (\": \",\n                                                                       [pending_xref, \"int\"])],\n                                                    [desc_annotation, \" = 1\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n    assert 'var' in domain.objects\n    assert domain.objects['var'] == ('index', 'var', 'data')\n"], "sample_620": ["def test_concat_fill_value_dict_with_variable_name() -> None:\n    da1 = DataArray([1, 2], coords=[(\"x\", [1, 2])])\n    da2 = DataArray([1, 2], coords=[(\"x\", [1, 3])])\n    expected = DataArray(\n        [[1, 2, np.nan], [1, np.nan, 2]],\n        dims=[\"y\", \"x\"],\n        coords={\"x\": [1, 2, 3]},\n    )\n    actual = concat((da1, da2), dim=\"y\", fill_value={\"x\": 0})\n    assert_identical(actual, expected)\n"], "sample_483": ["def test_prepopulated_fields(self):\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\", \"nonexistent\")}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'prepopulated_fields[\\\"slug\\\"]' refers to 'nonexistent', \"\n            \"which is not a field of 'admin_checks.Song'.\",\n            obj=SongAdmin,\n            id=\"admin.E030\",\n        )\n    ]\n    self.assertEqual(errors, expected)\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin"], "sample_655": ["    def test_capture_manager_repr(self):\n        capman = CaptureManager(\"fd\")\n        assert repr(capman) == \"<CaptureManager _method='fd' _global_capturing=None _current_item=None>\"\n        capman.start_global_capturing()\n        assert repr(capman) == \"<CaptureManager _method='fd' _global_capturing=<MultiCapture out=True err=True in_=False _state='started' _in_suspended=False> _current_item=None>\"\n        capman.stop_global_capturing()\n        assert repr(capman) == \"<CaptureManager _method='fd' _global_capturing=None _current_item=None>\"\n"], "sample_886": ["def test__wrap_in_pandas_container_sparse():\n    \"\"\"Check _wrap_in_pandas_container for sparse data.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X = csr_matrix([[1, 0, 3], [0, 0, 1]])\n    columns = np.asarray([\"f0\", \"f1\", \"f2\"], dtype=object)\n    index = np.asarray([0, 1])\n\n    with pytest.raises(ValueError, match=\"Pandas output does not support sparse data\"):\n        _wrap_in_pandas_container(X, columns=columns, index=index)\n"], "sample_795": ["def test_check_estimators_pickle_sparse():\n    # Test that we can pickle all estimators with sparse coefficients\n    check_methods = [\"predict\", \"transform\", \"decision_function\",\n                     \"predict_proba\"]\n\n    X, y = make_blobs(n_samples=30, centers=[[0, 0, 0], [1, 1, 1]],\n                      random_state=0, n_features=2, cluster_std=0.1)\n\n    # some estimators only take multioutputs\n    y = multioutput_estimator_convert_y_2d(SGDClassifier(), y)\n\n    # some estimators only take multioutputs\n    y = multioutput_estimator_convert_y_2d(SGDRegressor(), y)\n\n    # some estimators only take multioutputs\n    y = multioutput_estimator_convert_y_2d(LinearRegression(), y)\n\n    # some estimators only take multioutputs\n    y = multioutput_estimator_convert_y_2d(LinearDiscriminantAnalysis(), y)\n\n    # some estimators only take multioutputs\n    y = multioutput_estimator_convert_y_2d(PCA(), y)\n\n    # some estimators only take multioutputs\n    y = multioutput_estimator_convert_y_2d(TruncatedSVD(), y)\n\n    # some estimators only take multioutputs\n    y = multioutput_estimator_convert_y_2d(NMF(), y)\n\n    # some estimators only take multioutputs\n    y = multioutput_estimator_convert_y_2d(SelectKBest(), y)\n\n    # some estimators only take multioutputs\n    y = multioutput_estimator_convert_y_2d(SelectFdr(), y)\n\n    # some estimators only take multioutputs\n    y = multioutput_estimator_convert_y_2d(SelectFwe(), y)\n\n    # some estimators only take multioutputs\n    y = multioutput_estimator_convert_y_2d(SelectPercentile(), y)\n\n    # some estimators only take multioutputs\n    y = multioutput_estimator_convert_y_2d(SelectFpr(), y)\n\n    # some estimators only take multioutputs\n    y = multioutput_estimator_convert_y_2d(SelectFdr(), y)\n\n    # some estimators only take multioutputs\n    y = multioutput_estimator_convert_y_2d(SelectFwe(), y)\n\n    # some estimators only take multioutputs\n    y = multioutput_estimator_convert_y_2d(SelectPercentile(), y)\n\n    # some"], "sample_1128": ["def test_auto_point_vel_disconnected_frames():\n    t = dynamicsymbols._t\n    q, q1, q2, u = dynamicsymbols('q q1 q2 u')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    O = Point('O')\n    O.set_vel(N, u * N.x)\n    P = Point('P')\n    P.set_pos(O, q1 * N.x + q2 * B.y)\n    raises(ValueError, lambda: P.vel(B))\n    N.orient(B, 'Axis', (q, B.x))\n    raises(ValueError, lambda: P.vel(B))\n"], "sample_129": ["    def test_floatformat03(self):\n        output = self.engine.render_to_string('floatformat03', {\"a\": \"1.42\", \"b\": mark_safe(\"1.42\")})\n        self.assertEqual(output, \"1 1\")\n"], "sample_330": ["    def test_typecast_date(self):\n        \"\"\"\n        Test the custom typecast_date function.\n        \"\"\"\n        self.assertEqual(typecast_date('2022-01-01'), datetime.date(2022, 1, 1))\n        self.assertIsNone(typecast_date(None))\n        self.assertIsNone(typecast_date(''))\n"], "sample_53": ["    def test_build_attrs_with_custom_attrs(self):\n        form = AlbumForm()\n        attrs = form['band'].field.widget.get_context(name='my_field', value=None, attrs={'class': 'custom-class', 'data-foo': 'bar'})['widget']['attrs']\n        self.assertEqual(attrs, {\n            'class': 'custom-class my-class admin-autocomplete',\n            'data-ajax--cache': 'true',\n            'data-ajax--type': 'GET',\n            'data-ajax--url': '/admin_widgets/band/autocomplete/',\n            'data-theme': 'admin-autocomplete',\n            'data-allow-clear': 'false',\n            'data-placeholder': '',\n            'data-foo': 'bar'\n        })\n"], "sample_299": ["    def test_absolute_path_with_prefix(self):\n        with self.settings(CACHES={\n            'default': {\n                'BACKEND': 'django.core.cache.backends.filebased.FileBasedCache',\n                'LOCATION': pathlib.Path.cwd() / 'cache' / 'prefix',\n            },\n        }):\n            self.assertEqual(check_file_based_cache_is_absolute(None), [])\n"], "sample_880": ["def test_class_distribution_sparse_explicit_zero():\n    y = np.array([[0, 1], [1, 0]])\n    y_sp = csc_matrix(y)\n\n    classes, n_classes, class_prior = class_distribution(y)\n    classes_sp, n_classes_sp, class_prior_sp = class_distribution(y_sp)\n\n    classes_expected = [[0, 1]]\n    n_classes_expected = [2]\n    class_prior_expected = [0.5, 0.5]\n\n    for k in range(y.shape[1]):\n        assert_array_almost_equal(classes[k], classes_expected[k])\n        assert_array_almost_equal(n_classes[k], n_classes_expected[k])\n        assert_array_almost_equal(class_prior[k], class_prior_expected[k])\n\n        assert_array_almost_equal(classes_sp[k], classes_expected[k])\n        assert_array_almost_equal(n_classes_sp[k], n_classes_expected[k])\n        assert_array_almost_equal(class_prior_sp[k], class_prior_expected[k])\n"], "sample_12": ["def test_longitude_wrap_at_zero():\n    \"\"\"\n    Test that Longitude objects wrap at 0 degrees when the wrap_angle is 360 degrees.\n    \"\"\"\n    lon = Longitude([0, 360, 720] * u.deg)\n    assert np.all(lon.wrap_at(360 * u.deg).degree == np.array([0, 0, 0]))\n    assert np.all(lon.wrap_at('360d').degree == np.array([0, 0, 0]))\n    assert np.all(lon.wrap_at(np.pi * u.rad).degree == np.array([0, 0, 0]))\n\n    # Test wrapping a scalar Longitude\n    lon = Longitude('360d')\n    assert lon.wrap_at('360d') == Longitude('0d')\n\n    lon = Longitude([0, 360, 720] * u.deg)\n    assert np.all(lon.wrap_at(0 * u.deg).degree == np.array([0, 360, 720]))\n    assert np.all(lon.wrap_at('0d').degree == np.array([0, 360, 720]))\n    assert np.all(lon.wrap_at(0 * u.rad).degree == np.array([0, 360, 720]))\n"], "sample_748": ["def test_grid_search_with_sparse_target():\n    # Test that grid search works with sparse target\n    X, y = make_classification(n_samples=200, n_features=100, random_state=0)\n    y = sp.csr_matrix(y)\n    Cs = [.1, 1, 10]\n    clf = LinearSVC()\n    cv = GridSearchCV(clf, {'C': Cs})\n    cv.fit(X, y)\n    y_pred = cv.predict(X)\n    C = cv.best_estimator_.C\n\n    assert_true(np.mean(y_pred == y) >= .9)\n    assert_equal(C, cv.best_estimator_.C)\n"], "sample_376": ["def test_max_cookie_size_empty(self):\n    \"\"\"\n    If the data is empty, it should be stored as an empty cookie.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n    storage.update(response)\n    self.assertEqual(response.cookies['messages'].value, '')\n    self.assertEqual(response.cookies['messages']['max-age'], 0)\n"], "sample_84": ["    def test_valid_date(self):\n        self.assertEqual(parse_http_date_safe('Sun, 06 Nov 1994 08:49:37 GMT'), 822783377)\n"], "sample_96": ["    def test_one_to_one_field(self):\n        class TestModelAdmin(ModelAdmin):\n            prepopulated_fields = {'best_friend': ('name',)}\n\n        self.assertIsInvalid(\n            TestModelAdmin, ValidationTestModel,\n            \"The value of 'prepopulated_fields' refers to 'best_friend', which must not be \"\n            \"a DateTimeField, a ForeignKey, a OneToOneField, or a ManyToManyField.\",\n            'admin.E028'\n        )\n"], "sample_220": ["    def test_max_age_zero(self):\n        \"\"\"Cookie will expire immediately when max_age is 0.\"\"\"\n        response = HttpResponse()\n        response.set_cookie('max_age', max_age=0)\n        max_age_cookie = response.cookies['max_age']\n        self.assertEqual(max_age_cookie['max-age'], 0)\n        self.assertEqual(max_age_cookie['expires'], 'Thu, 01 Jan 1970 00:00:00 GMT')\n"], "sample_601": ["def test_cftime_strftime_accessor(cftime_rounding_dataarray, cftime_date_type, use_dask):\n    import dask.array as da\n\n    date_format = \"%Y%m%d\"\n    expected = xr.DataArray(\n        [\n            [cftime_date_type(1, 1, 1, 1).strftime(date_format), cftime_date_type(1, 1, 1, 15).strftime(date_format)],\n            [cftime_date_type(1, 1, 1, 23).strftime(date_format), cftime_date_type(1, 1, 2, 1).strftime(date_format)],\n        ],\n        name=\"strftime\",\n    )\n\n    if use_dask:\n        chunks = {\"dim_0\": 1}\n        # Currently a compute is done to inspect a single value of the array\n        # if it is of object dtype to check if it is a cftime.datetime (if not\n        # we raise an error when using the dt accessor).\n        with raise_if_dask_computes(max_computes=1):\n            result = cftime_rounding_dataarray.chunk(chunks).dt.strftime(date_format)\n        expected = expected.chunk(chunks)\n        assert isinstance(result.data, da.Array)\n        assert result.chunks == expected.chunks\n    else:\n        result = cftime_rounding_dataarray.dt.strftime(date_format)\n\n    assert_identical(result, expected)\n"], "sample_592": ["def test_inline_dask_repr():\n    da = xr.DataArray(np.random.randn(10, 10), dims=(\"x\", \"y\"))\n    da = da.chunk({\"x\": 5, \"y\": 5})\n    expected = f\"dask.array<chunksize={(5, 5)}>\"\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.random.randn(10, 10), dims=(\"x\", \"y\"))\n    da = da.chunk({\"x\": 5, \"y\": 5})\n    da._meta = np.random.randn(10, 10)\n    expected = f\"dask.array<chunksize={(5, 5)}, meta=np.ndarray>\"\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.random.randn(10, 10), dims=(\"x\", \"y\"))\n    da = da.chunk({\"x\": 5, \"y\": 5})\n    da._meta = np.random.randn(10, 10)\n    type(da._meta).__name__ = \"MyArray\"\n    expected = f\"dask.array<chunksize={(5, 5)}, meta=MyArray>\"\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.random.randn(10, 10), dims=(\"x\", \"y\"))\n    da = da.chunk({\"x\": 5, \"y\": 5})\n    da._meta = None\n    with pytest.raises(AssertionError):\n        formatting.inline_dask_repr(da)\n\n    da = xr.DataArray(np.random.randn(10, 10), dims=(\"x\", \"y\"))\n    da = da.chunk({\"x\": 5, \"y\": 5})\n    da._meta = np.random.randn(10, 10)\n    type(da._meta) = object\n    with pytest.raises(AssertionError):\n        formatting.inline_dask_repr(da)\n\n    da = xr.DataArray(np.random.randn(10, 10), dims=(\"x\", \"y\"))\n    da = da.chunk({\"x\": 5, \"y\": 5})\n    da._meta = np.random.randn(10, 10)\n    type(da._meta).__name__ = \"MyArray\"\n    with pytest.raises(AssertionError):\n        formatting.inline_dask_repr(da)\n"], "sample_1110": ["def test_issue_12345():\n    from sympy import LambertW\n    from sympy.printing.pycode import SciPyPrinter\n\n    p = SciPyPrinter()\n    expr = LambertW(x)\n    assert p.doprint(expr) == 'scipy.special.lambertw(x)'\n"], "sample_862": ["def test_hashingvectorizer_dtype():\n    # Non-regression test: HashingVectorizer used to ignore its \"dtype\" param.\n    v = HashingVectorizer(dtype=np.float32)\n    assert v.dtype == np.float32\n\n    X = v.transform(['hello world', 'hello hello']).toarray()\n    assert X.dtype == np.float32\n\n    # check the ability to change the dtype\n    v = HashingVectorizer(dtype=np.float64)\n    X = v.transform(['hello world', 'hello hello']).toarray()\n    assert X.dtype == np.float64\n"], "sample_797": ["def test_power_transformer_inverse_transform_shape_exception():\n    # Exceptions should be raised for arrays with different num_columns\n    # than during fitting\n    pt = PowerTransformer(method='yeo-johnson')\n    X = np.abs(X_2d)\n    pt.fit(X)\n\n    # Exceptions should be raised for arrays with different num_columns\n    # than during fitting\n    wrong_shape_message = 'Input data has a different number of features'\n    assert_raise_message(ValueError, wrong_shape_message,\n                         pt.inverse_transform, X[:, 0:1])\n"], "sample_73": ["    def setUp(self):\n        super().setUp()\n\n        temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, 'test'))\n        self._clear_filename = os.path.join(temp_dir, 'test', 'cleared.txt')\n        with open(self._clear_filename, 'w') as f:\n            f.write('to be deleted in one test')\n\n        self.patched_settings = self.settings(\n            STATICFILES_DIRS=settings.STATICFILES_DIRS + [temp_dir],\n        )\n        self.patched_settings.enable()\n        self.addCleanup(shutil.rmtree, temp_dir)\n        self._manifest_strict = storage.staticfiles_storage.manifest_strict\n"], "sample_1012": ["def test_PythonCodePrinter_precision():\n    prntr = PythonCodePrinter(settings={'precision': 5})\n    assert prntr.doprint(pi) == 'math.pi'\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n    assert prntr.doprint(zoo) == \"float('nan')\"\n    assert prntr.doprint(-oo) == \"float('-inf')\"\n"], "sample_1016": ["def test_MatrixSlice():\n    A = Matrix([[1, 2, 3], [4, 5, 6]])\n    assert mcode(A[1:2, 1:3]) == \"[4 5]\"\n    assert mcode(A[:, 1:3]) == \"[2 3; 5 6]\"\n    assert mcode(A[1:, 1:]) == \"[4 5; 5 6]\"\n    assert mcode(A[1:2, 1]) == \"[5]\"\n    assert mcode(A[1, 1:]) == \"[5 6]\"\n    assert mcode(A[1:2, 1:2]) == \"[5]\"\n    assert mcode(A[1:2, 1:2, 1]) == \"[5]\"\n    assert mcode(A[1:2, 1:2, 1:2]) == \"[5]\"\n    assert mcode(A[1:2, 1:2, 1:2, 1]) == \"[5]\"\n    assert mcode(A[1:2, 1:2, 1:2, 1:2]) == \"[5]\"\n"], "sample_577": ["    def test_move_group_by_orient(self, long_df):\n\n        class MoveWithOrient(Move):\n            group_by_orient = True\n\n                self.orient = orient\n                return data\n\n        m = MoveWithOrient()\n        Plot(long_df, x=\"a\", y=\"z\").add(m).plot()\n        assert m.orient == \"x\"\n"], "sample_1053": ["def test_issue_10368():\n    a = S(32442016954)/78058255275\n    assert int(a) == 41\n    assert int(-a) == -41\n    assert int(a) == int(-a)\n    assert type(int(a)) is type(int(-a)) is int\n"], "sample_225": ["    def setUp(self):\n        self.site = admin.AdminSite()\n"], "sample_158": ["    def test_unique_constraint_clash(self):\n        class Target(models.Model):\n            source = models.IntegerField()\n            target = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['source', 'target'],\n                        name='tfktuc_clash',\n                    ),\n                ]\n\n        class Model(models.Model):\n            field = models.ForeignKey(Target, models.CASCADE, to_field='source')\n\n        field = Model._meta.get_field('field')\n        self.assertEqual(field.check(), [\n            Error(\n                \"'Target.source' must be unique because it is referenced by a foreign key.\",\n                hint=(\n                    'Add unique=True to this field or add a UniqueConstraint '\n                    '(without condition) in the model Meta.constraints.'\n                ),\n                obj=field,\n                id='fields.E311',\n            ),\n        ])\n"], "sample_9": ["def test_htmloutputter():\n    \"\"\"\n    Test to make sure that the HTMLOutputter correctly converts\n    a Table object into HTML.\n    \"\"\"\n\n    table = Table([['1', 'a', '1.05'], ['2', 'b', '2.75'], ['3', 'c', '-1.25']],\n                  names=('C1', 'C2', 'C3'))\n    expected = \"\"\"\\"], "sample_50": ["def test_empty_conn_params(self):\n    \"\"\"Test that runshell_db raises an error when conn_params is empty.\"\"\"\n    with self.assertRaises(KeyError):\n        DatabaseClient.runshell_db({})\n"], "sample_294": ["def test_csrf_trusted_origin_subdomain_allowed(self):\n    \"\"\"\n    A POST request with an origin that matches a CSRF_TRUSTED_ORIGINS wildcard\n    and a subdomain is accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_HOST'] = 'subdomain.example.com'\n    req.META['HTTP_REFERER'] = 'https://subdomain.example.com'\n    mw = CsrfViewMiddleware(post_form_view)\n    self.assertIs(mw._origin_verified(req), True)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n    self.assertEqual(mw.allowed_origins_exact, set())\n    self.assertEqual(mw.allowed_origin_subdomains, {'https': ['.example.com']})\n"], "sample_853": ["def test_transform_target_regressor_clone_regressor():\n    # regression test for gh-issue #11618\n    # check that we clone the regressor\n    X, y = friedman\n    ttr = TransformedTargetRegressor(\n        regressor=DummyRegressorWithExtraFitParams(),\n        check_inverse=False\n    )\n    ttr.fit(X, y)\n    assert ttr.regressor_.fit_counter == 1\n    assert ttr.regressor_.check_input == False\n    ttr.fit(X, y)\n    assert ttr.regressor_.fit_counter == 2\n    assert ttr.regressor_.check_input == False\n"], "sample_246": ["    def test_no_default_ignore(self):\n        cmd = MakeMessagesCommand()\n        cmd.use_default_ignore_patterns = False\n        cmd.ignore_patterns = ['CVS', '.*', '*~', '*.pyc']\n        cmd.symlinks = False\n        cmd.domain = 'django'\n        cmd.extensions = ['html', 'txt', 'py']\n        cmd.verbosity = 0\n        cmd.locale_paths = []\n        cmd.default_locale_path = os.path.join(self.test_dir, 'locale')\n        found_files = cmd.find_files(self.test_dir)\n        found_exts = {os.path.splitext(tfile.file)[1] for tfile in found_files}\n        self.assertEqual(found_exts.difference({'.py', '.html', '.txt'}), set())\n\n        cmd.ignore_patterns = ['CVS', '.*', '*~', '*.pyc', 'ignore_dir/*']\n        found_files = cmd.find_files(self.test_dir)\n        found_exts = {os.path.splitext(tfile.file)[1] for tfile in found_files}\n        self.assertEqual(found_exts.difference({'.py', '.html', '.txt'}), set())\n"], "sample_43": ["def test_events_fitness_homoscedastic():\n    \"\"\"Test results for events fitness function with homoscedastic data\"\"\"\n    rng = np.random.RandomState(0)\n    t = np.concatenate([rng.randn(100), rng.randn(100) + 1])\n    edges = bayesian_blocks(t, fitness='events')\n\n    assert_allclose(edges, [0.0, 0.5, 1.0])\n"], "sample_112": ["    def test_prepopulated_fields_js(self):\n        \"\"\"\n        prepopulated_fields_js template tag should pass whole context.\n        \"\"\"\n        article = Article.objects.all()[0]\n        request = self.request_factory.get(reverse('admin:admin_views_article_change', args=[article.pk]))\n        request.user = self.superuser\n        admin = ArticleAdmin(Article, site)\n        extra_context = {'extra': True}\n        response = admin.change_view(request, str(article.pk), extra_context=extra_context)\n        template_context = prepopulated_fields_js(response.context_data)\n        self.assertIs(template_context['extra'], True)\n        self.assertIsInstance(template_context['prepopulated_fields'], list)\n        self.assertIsInstance(template_context['prepopulated_fields_json'], str)\n"], "sample_1150": ["def test_ImageSet_iter():\n    from sympy.abc import x\n    from sympy import sin, pi\n    L = Lambda(x, sin(x))\n    evens = ImageSet(L, S.Naturals)\n    i = iter(evens)\n    # No repeats here\n    assert (next(i), next(i), next(i), next(i)) == (0, sin(pi), sin(2*pi), sin(3*pi))\n"], "sample_174": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_135": ["def test_date_format_with_leap_year(self):\n    my_birthday = datetime(2000, 2, 29, 22, 00)\n    self.assertEqual(dateformat.format(my_birthday, 'L'), 'True')\n"], "sample_57": ["    def test_render_with_usable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = 'pbkdf2_sha256$100000$a6Pucb1qSFcD$WmCkn9Hqidj48NVe5x0FEM6A9YiOqQcl/83m2Z5udm0='\n        self.assertHTMLEqual(\n            widget.render('name', value, {'id': 'id_password'}),\n            \"\"\"\n            <div id=\"id_password\">\n                <strong>algorithm</strong>: pbkdf2_sha256\n                <strong>iterations</strong>: 100000\n                <strong>salt</strong>: a6Pucb******\n                <strong>hash</strong>: WmCkn9**************************************\n            </div>\n            \"\"\"\n        )\n"], "sample_485": ["def test_avoid_wrapping(self):\n    items = (\n        (\"Hello, world!\", \"Hello, world!\"),\n        (\"Hello,\\nworld!\", \"Hello,\\nworld!\"),\n        (\"Hello,\\r\\nworld!\", \"Hello,\\r\\nworld!\"),\n        (\"Hello,\\tworld!\", \"Hello,\\tworld!\"),\n        (\"Hello,\\vworld!\", \"Hello,\\vworld!\"),\n        (\"Hello,\\fworld!\", \"Hello,\\fworld!\"),\n        (\"Hello,\\bworld!\", \"Hello,\\bworld!\"),\n        (\"Hello,\\fworld!\", \"Hello,\\fworld!\"),\n        (\"Hello,\\u2028world!\", \"Hello,\\u2028world!\"),\n        (\"Hello,\\u2029world!\", \"Hello,\\u2029world!\"),\n        (\"Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!\"),\n        (\"Hello, world!\\nHello, world!\", \"Hello, world!\\nHello, world!\"),\n        (\"Hello, world!\\r\\nHello, world!\", \"Hello, world!\\r\\nHello, world!\"),\n        (\"Hello, world!\\tHello, world!\", \"Hello, world!\\tHello, world!\"),\n        (\"Hello, world!\\vHello, world!\", \"Hello, world!\\vHello, world!\"),\n        (\"Hello, world!\\fwHello, world!\", \"Hello, world!\\fwHello, world!\"),\n        (\"Hello, world!\\bHello, world!\", \"Hello, world!\\bHello, world!\"),\n        (\"Hello, world!\\fHello, world!\", \"Hello, world!\\fHello, world!\"),\n        (\"Hello, world!\\u2028Hello, world!\", \"Hello, world!\\u2028Hello, world!\"),\n        (\"Hello, world!\\u2029Hello, world!\", \"Hello, world!\\u2029Hello, world!\"),\n    )\n    for value, output in items:\n        with self.subTest(value=value, output=output):\n            self.check_output(avoid_wrapping, value, output)\n            self.check_output(avoid_wrapping, lazystr(value), output)\n"], "sample_148": ["def test_quote_with_non_string_value(self):\n    \"\"\"\n    Regression test for #12345: quote() should handle non-string values.\n    \"\"\"\n    self.assertEqual(quote(12345), '12345')\n    self.assertEqual(quote(12345.6789), '12345.6789')\n    self.assertEqual(quote(True), 'True')\n    self.assertEqual(quote(False), 'False')\n    self.assertEqual(quote(None), 'None')\n    self.assertEqual(quote(datetime.date(2022, 1, 1)), '2022-01-01')\n    self.assertEqual(quote(datetime.time(12, 30, 0)), '12:30:00')\n    self.assertEqual(quote(datetime.datetime(2022, 1, 1, 12, 30, 0)), '2022-01-01 12:30:00')\n    self.assertEqual(quote(decimal.Decimal('12345.6789')), '12345.6789')\n    self.assertEqual(quote([1, 2, 3]), '[1, 2, 3]')\n    self.assertEqual(quote({'a': 1, 'b': 2}), '{\"a\": 1, \"b\": 2}')\n"], "sample_653": ["def test_log_cli_level_overridden_by_log_level(testdir):\n    # Default log file level\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_handler.level == logging.INFO\n            logging.getLogger('catchlog').debug(\"This log message won't be shown\")\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n        log_level=DEBUG\n        \"\"\"\n    )\n\n    result = testdir.runpytest(\"-s\", \"--log-cli-level=INFO\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_log_cli_level_overridden_by_log_level.py*This log message will be shown\",\n            \"PASSED\",  # 'PASSED' on its own line because the log message prints a new line\n        ]\n    )\n    assert \"This log message won't be shown\" not in result.stdout.str()\n\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n"], "sample_1167": ["def test_latex_Dict():\n    d = {Rational(1): 1, x**2: 2, x: 3, x**3: 4}\n    assert latex(d) == \\\n        r'\\left\\{ 1 : 1, \\  x : 3, \\  x^{2} : 2, \\  x^{3} : 4\\right\\}'\n    D = Dict(d)\n    assert latex(D) == \\\n        r'\\left\\{ 1 : 1, \\  x : 3, \\  x^{2} : 2, \\  x^{3} : 4\\right\\}'\n"], "sample_913": ["def test_pydata_signature_old_type(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :type: int\\n\"\n            \"   :value: 1\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"version\"],\n                                                    [desc_annotation, \": int\"],\n                                                    [desc_annotation, \" = 1\"])],\n                                  [desc_content, ()])]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n    assert 'version' in domain.objects\n    assert domain.objects['version'] == ('index', 'version', 'data')\n"], "sample_1020": ["def test_Pi():\n    assert mcode(pi**2) == \"Pi^2\"\n    assert mcode(pi**Rational(3, 2)) == \"Pi^(3/2)\"\n    assert mcode(2*pi) == \"2*Pi\"\n    assert mcode(pi + 2) == \"Pi + 2\"\n    assert mcode(2 + pi) == \"2 + Pi\"\n"], "sample_1186": ["def test_issue_20223():\n    A = ImmutableDenseNDimArray([[1, 2], [3, 4]])\n    B = ImmutableDenseNDimArray([[5, 6], [7, 8]])\n    assert A + B == ImmutableDenseNDimArray([[6, 8], [10, 12]])\n    assert A - B == ImmutableDenseNDimArray([[-4, -4], [-4, -4]])\n    assert A * 2 == ImmutableDenseNDimArray([[2, 4], [6, 8]])\n    assert 2 * A == ImmutableDenseNDimArray([[2, 4], [6, 8]])\n    assert A / 2 == ImmutableDenseNDimArray([[0.5, 1], [1.5, 2]])\n    assert -A == ImmutableDenseNDimArray([[-1, -2], [-3, -4]])\n\n    raises(ValueError, lambda: A + ImmutableSparseNDimArray([[1, 2], [3, 4]]))\n    raises(ValueError, lambda: A - ImmutableSparseNDimArray([[1, 2], [3, 4]]))\n    raises(ValueError, lambda: A * ImmutableSparseNDimArray([[1, 2], [3, 4]]))\n    raises(ValueError, lambda: A / ImmutableSparseNDimArray([[1, 2], [3, 4]]))\n    raises(ValueError, lambda: -ImmutableSparseNDimArray([[1, 2], [3, 4]]))\n"], "sample_356": ["def test_alter_field_to_unique(self):\n    \"\"\"Tests autodetection of unique field alterations.\"\"\"\n    changes = self.get_changes([self.author_name], [self.author_name_check_constraint])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, 'testapp', 0, 0, unique=True)\n    self.assertEqual(changes['testapp'][0].operations[0].field.check, models.Q(name__contains='Bob'))\n"], "sample_697": ["def test_tmp_path_factory_getbasetemp_custom(tmp_path_factory: TempPathFactory) -> None:\n    \"\"\"Test that getbasetemp() returns the custom basetemp when given.\"\"\"\n    custom_basetemp = tmp_path_factory.getbasetemp()\n    assert custom_basetemp == tmp_path_factory._given_basetemp\n"], "sample_887": ["def test_calibration_with_non_fitted_base_estimator():\n    \"\"\"Check that we raise an error if the base estimator is not fitted.\"\"\"\n    X, y = make_classification(n_samples=10, n_features=5, n_classes=2, random_state=7)\n    clf = LinearSVC(C=1)\n    calib_clf = CalibratedClassifierCV(clf, cv=\"prefit\")\n    with pytest.raises(NotFittedError):\n        calib_clf.fit(X, y)\n"], "sample_182": ["def test_difference_with_distinct(self):\n    qs1 = Number.objects.filter(num__lt=10).distinct()\n    qs2 = Number.objects.filter(num__lt=9)\n    self.assertNumbersEqual(qs1.difference(qs2), [9], ordered=False)\n"], "sample_1070": ["def test_log_period():\n    assert log(9*I*pi/4) == log(I*pi/4) + I*pi\n    assert log(46*I*pi/18) == log(5*I*pi/9) + I*pi\n    assert log(25*I*pi/7) == log(-3*I*pi/7) + I*pi\n    assert log(-19*I*pi/3) == log(-I*pi/3) + I*pi\n    assert log(37*I*pi/8) - log(-11*I*pi/8) == 0\n    assert log(-5*I*pi/3) / log(11*I*pi/5) * log(148*I*pi/15) == I*pi\n\n    assert log(2 - 17*I*pi/5) == log(2 + 3*I*pi/5) + I*pi\n    assert log(log(3) + 29*I*pi/9) == log(3) + log(-7*I*pi/9) + I*pi\n\n    n = Symbol('n', integer=True)\n    e = Symbol('e', even=True)\n    assert log(exp(e*I*pi)) == I*pi\n    assert log(exp((e + 1)*I*pi)) == I*pi\n    assert log(exp((1 + 4*n)*I*pi/2)) == I*pi\n    assert log(exp((-1 + 4*n)*I*pi/2)) == I*pi\n"], "sample_392": ["    def setUpTestData(cls):\n        cls.primitives = [True, False, \"yes\", 7, 9.6]\n        values = [\n            None,\n            [],\n            {},\n            {\"a\": \"b\", \"c\": 14},\n            {\n                \"a\": \"b\",\n                \"c\": 14,\n                \"d\": [\"e\", {\"f\": \"g\"}],\n                \"h\": True,\n                \"i\": False,\n                \"j\": None,\n                \"k\": {\"l\": \"m\"},\n                \"n\": [None, True, False],\n                \"o\": '\"quoted\"',\n                \"p\": 4.2,\n                \"r\": {\"s\": True, \"t\": False},\n            },\n            [1, [2]],\n            {\"k\": True, \"l\": False, \"foo\": \"bax\"},\n            {\n                \"foo\": \"bar\",\n                \"baz\": {\"a\": \"b\", \"c\": \"d\"},\n                \"bar\": [\"foo\", \"bar\"],\n                \"bax\": {\"foo\": \"bar\"},\n            },\n        ]\n        cls.objs = [NullableJSONModel.objects.create(value=value) for value in values]\n        if connection.features.supports_primitives_in_json_field:\n            cls.objs.extend(\n                [\n                    NullableJSONModel.objects.create(value=value)\n                    for value in cls.primitives\n                ]\n            )\n        cls.raw_sql = \"%s::jsonb\" if connection.vendor == \"postgresql\" else \"%s\"\n"], "sample_600": ["def test_CFScaleOffsetCoder_encode_scale_factor():\n    original = xr.Variable((\"x\",), np.arange(10.0), encoding=dict(scale_factor=10))\n    coder = variables.CFScaleOffsetCoder()\n    encoded = coder.encode(original)\n    assert encoded.dtype == np.float32\n    roundtripped = coder.decode(encoded)\n    assert_identical(original, roundtripped)\n    assert roundtripped.dtype == np.float32\n"], "sample_82": ["def test_selectdate_years_rendered_without_separator(self):\n    widget = SelectDateWidget(years=(2007,))\n    self.check_html(widget, 'mydate', '', html=(\n        \"\"\"\n        <select name=\"mydate_month\" id=\"id_mydate_month\">\n            <option selected value=\"\">---</option>\n            <option value=\"1\">January</option>\n            <option value=\"2\">February</option>\n            <option value=\"3\">March</option>\n            <option value=\"4\">April</option>\n            <option value=\"5\">May</option>\n            <option value=\"6\">June</option>\n            <option value=\"7\">July</option>\n            <option value=\"8\">August</option>\n            <option value=\"9\">September</option>\n            <option value=\"10\">October</option>\n            <option value=\"11\">November</option>\n            <option value=\"12\">December</option>\n        </select>\n\n        <select name=\"mydate_day\" id=\"id_mydate_day\">\n            <option selected value=\"\">---</option>\n            <option value=\"1\">1</option>\n            <option value=\"2\">2</option>\n            <option value=\"3\">3</option>\n            <option value=\"4\">4</option>\n            <option value=\"5\">5</option>\n            <option value=\"6\">6</option>\n            <option value=\"7\">7</option>\n            <option value=\"8\">8</option>\n            <option value=\"9\">9</option>\n            <option value=\"10\">10</option>\n            <option value=\"11\">11</option>\n            <option value=\"12\">12</option>\n            <option value=\"13\">13</option>\n            <option value=\"14\">14</option>\n            <option value=\"15\">15</option>\n            <option value=\"16\">16</option>\n            <option value=\"17\">17</option>\n            <option value=\"18\">18</option>\n            <option value=\"19\">19</option>\n            <option value=\"20\">20</option>\n            <option value=\"21\">21</option>\n            <option value=\"22\">22</option>\n            <option value=\"23\">23</option>\n            <option value=\"24\">24</option>\n            <option value=\"25\">25</option>\n            <option value=\"26\">26</option"], "sample_136": ["    def test_querydict_fromkeys(self):\n        q = QueryDict.fromkeys(['key1', 'key2'], 'value')\n        self.assertEqual(q, {'key1': ['value'], 'key2': ['value']})\n"], "sample_0": ["def test_repr():\n    fake_uncert = FakeUncertainty([10, 2])\n    assert fake_uncert.__repr__() == 'FakeUncertainty([10 2])'\n    std_uncert = StdDevUncertainty([10, 2])\n    assert std_uncert.__repr__() == 'StdDevUncertainty([10 2])'\n    var_uncert = VarianceUncertainty([10, 2])\n    assert var_uncert.__repr__() == 'VarianceUncertainty([10 2])'\n    ivar_uncert = InverseVariance([10, 2])\n    assert ivar_uncert.__repr__() == 'InverseVariance([10 2])'\n"], "sample_639": ["def test_base_checker_hash() -> None:\n    \"\"\"Test hashability of checkers.\"\"\"\n    basic = OtherBasicChecker()\n    less_basic = LessBasicChecker()\n    different = DifferentBasicChecker()\n    assert hash(basic) != hash(less_basic)\n    assert hash(basic) != hash(different)\n    assert hash(less_basic) != hash(different)\n"], "sample_1001": ["def test_latex_Morphism():\n    from sympy.categories import Object, NamedMorphism, IdentityMorphism, CompositeMorphism\n    from sympy.categories import Category, Diagram, DiagramGrid\n\n    A = Object(\"A\")\n    B = Object(\"B\")\n    C = Object(\"C\")\n    D = Object(\"D\")\n\n    f1 = NamedMorphism(A, B, \"f1\")\n    f2 = NamedMorphism(B, C, \"f2\")\n    f3 = NamedMorphism(C, D, \"f3\")\n    id_A = IdentityMorphism(A)\n    id_B = IdentityMorphism(B)\n    id_C = IdentityMorphism(C)\n    id_D = IdentityMorphism(D)\n\n    K1 = Category(\"K1\")\n    K2 = Category(\"K2\")\n\n    assert latex(f1) == \"f_{1}:A\\\\rightarrow B\"\n    assert latex(id_A) == \"id:A\\\\rightarrow A\"\n    assert latex(id_B) == \"id:B\\\\rightarrow B\"\n    assert latex(id_C) == \"id:C\\\\rightarrow C\"\n    assert latex(id_D) == \"id:D\\\\rightarrow D\"\n\n    assert latex(f2*f1) == \"f_{2}\\\\circ f_{1}:A\\\\rightarrow C\"\n    assert latex(f3*f2*f1) == \"f_{3}\\\\circ f_{2}\\\\circ f_{1}:A\\\\rightarrow D\"\n\n    assert latex(NamedMorphism(f1, \"g1\")) == \"g_{1}:A\\\\rightarrow B\"\n    assert latex(CompositeMorphism(f1, f2)) == \"f_{2}\\\\circ f_{1}:A\\\\rightarrow C\"\n\n    assert latex(Category(\"K\")) == r\"\\mathbf{K}\"\n    assert latex(Category(\"K1\", \"K2\")) == r\"\\mathbf{K_{1} \\circ K_{2}}\"\n\n    d = Diagram()\n    assert latex(d) == r\"\\emptyset\"\n\n    d = Diagram({f1: \"unique\", f2: S.EmptySet})\n    assert latex(d) == r\"\\left \\{ f_{2}\\circ f_{1}:A\" \\\n        r\"\\rightarrow C : \\emptyset, \\quad id:A\\rightarrow \" \\\n        r\"A : \\emptyset, \\quad id:B\\rightarrow B : \" \\\n        r\"\\emptyset, \\quad id:C\\rightarrow C : \\emptyset, \" \\\n        r\"\\"], "sample_274": ["    def test_modelchoicefield_value_placeholder(self):\n        # Create choices for the model choice field tests below.\n        ChoiceModel.objects.create(pk=1, name='a')\n        ChoiceModel.objects.create(pk=2, name='b')\n        ChoiceModel.objects.create(pk=3, name='c')\n\n        # ModelChoiceField\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': '\"%(value)s\" is not one of the available choices.',\n        }\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['\"invalid\" is not one of the available choices.'], f.clean, 'invalid')\n\n        # ModelMultipleChoiceField\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': '\"%(value)s\" is not one of the available choices.',\n            'invalid_list': 'NOT A LIST OF VALUES',\n        }\n        f = ModelMultipleChoiceField(queryset=ChoiceModel.objects.all(), error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['NOT A LIST OF VALUES'], f.clean, '3')\n        self.assertFormErrors(['\"4\" is not one of the available choices.'], f.clean, ['4'])\n"], "sample_562": ["def test_set_markerfacecolor_fillstyle():\n    \"\"\"Test that markerfacecolor does not override fillstyle='none'.\"\"\"\n    l, = plt.plot([1, 3, 2], marker=MarkerStyle('o', fillstyle='none'),\n                  markerfacecolor='red')\n    assert l.get_fillstyle() == 'none'\n    assert l.get_markerfacecolor() == 'none'\n"], "sample_817": ["def test_variance_threshold_non_zero_threshold():\n    # Test VarianceThreshold with custom variance threshold.\n    for X in [data, csr_matrix(data)]:\n        for threshold in [0.1, 0.5, 0.9]:\n            sel = VarianceThreshold(threshold=threshold).fit(X)\n            support = sel.get_support(indices=True)\n            assert_equal(len(support), len(X[0]))\n            assert_equal(np.sum(sel.variances_ > threshold), len(support))\n            assert_equal(np.sum(sel.variances_ <= threshold), len(X[0]) - len(support))\n"], "sample_263": ["    def test_dumpdata_with_natural_primary_keys_and_foreign_keys(self):\n        management.call_command('loaddata', 'fixture1.json', verbosity=0)\n        self._dumpdata_assert(\n            ['fixtures'],\n            '[{\"model\": \"fixtures.category\", \"fields\": {\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '\n            '{\"model\": \"fixtures.article\", \"fields\": {\"headline\": \"Poker on TV is great!\", \"pub_date\": \"2006-06-16T11:00:00\"}}, '\n            '{\"model\": \"fixtures.article\", \"fields\": {\"headline\": \"Copyright is fine the way it is\", \"pub_date\": \"2006-06-16T14:00:00\"}}, '\n            '{\"model\": \"fixtures.article\", \"fields\": {\"headline\": \"Django conquers world!\", \"pub_date\": \"2006-06-16T15:00:00\"}}, '\n            '{\"model\": \"fixtures.article\", \"fields\": {\"headline\": \"XML identified as leading cause of cancer\", \"pub_date\": \"2006-06-16T16:00:00\"}}, '\n            '{\"model\": \"fixtures.tag\", \"fields\": {\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"copyright\", \"tagged_id\": 3}}, '\n            '{\"model\": \"fixtures.tag\", \"fields\": {\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"legal\", \"tagged_id\": 3}}, '\n            '{\"model\": \"fixtures.tag\", \"fields\": {\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"django\", \"tagged_id\": 4}}, '\n            '{\"model\": \"fixtures.tag\", \"fields\": {\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"world domination\", \"tagged_id\": 4}}, '\n            '{\"model\": \"fixtures.person\", \"fields\": {\"name\": \"Django Reinhardt\"}}, '\n            '{\"model\": \"fixtures.person\", \"fields\": {\"name\": \"Stephane Grappelli\"}}, '\n            '{\"model\": \"fixtures.person\", \"fields\": {\"name\": \"Artist formerly known as \\\"Prince\\\"\"}}, '\n            '{\"model\": \"fixtures.visa\", \"fields\": {\"person\": [\"Django Reinhardt\"], \"permissions\": [[\"add_user\", \"auth\", \"user\"], '\n"], "sample_1107": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((0, 1, 2, 3))) == [\n        (0, 1, 2, 3), (0, 1, -2, 3), (0, 1, 2, -3), (0, 1, -2, -3),\n        (0, -1, 2, 3), (0, -1, -2, 3), (0, -1, 2, -3), (0, -1, -2, -3),\n        (0, 2, 1, 3), (0, 2, -1, 3), (0, 2, 1, -3), (0, 2, -1, -3),\n        (0, -2, 1, 3), (0, -2, -1, 3), (0, -2, 1, -3), (0, -2, -1, -3),\n        (0, 2, 1, -3), (0, 2, -1, -3), (0, -2, 1, -3), (0, -2, -1, -3),\n        (0, -1, -2, 3), (0, -1, 2, 3), (0, -1, -2, -3), (0, -1, 2, -3),\n        (0, 1, -2, -3), (0, 1, 2, -3), (0, -1, -2, -3), (0, -1, 2, -3),\n        (0, 2, -1, -3), (0, 2, 1, -3), (0, -2, -1, -3), (0, -2, 1, -3),\n        (0, -2, 1, 3), (0, -2, -1, 3), (0, -2, 1,"], "sample_264": ["def test_max_cookie_length_with_empty_messages(self):\n    \"\"\"\n    If the data exceeds what is allowed in a cookie, empty messages are removed\n    before saving (and returned by the ``update`` method).\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # When storing as a cookie, the cookie has constant overhead of approx\n    # 54 chars, and each message has a constant overhead of about 37 chars\n    # and a variable overhead of zero in the best case. We aim for a message\n    # size which will fit 4 messages into the cookie, but not 5.\n    # See also FallbackTest.test_session_fallback\n    msg_size = int((CookieStorage.max_cookie_size - 54) / 4.5 - 37)\n    first_msg = None\n    # Generate the same (tested) content every time that does not get run\n    # through zlib compression.\n    random.seed(42)\n    for i in range(5):\n        msg = get_random_string(msg_size)\n        if msg:\n            storage.add(constants.INFO, msg)\n        else:\n            storage.add(constants.INFO, '')\n        if i == 0:\n            first_msg = msg\n    unstored_messages = storage.update(response)\n\n    cookie_storing = self.stored_messages_count(storage, response)\n    self.assertEqual(cookie_storing, 4)\n\n    self.assertEqual(len(unstored_messages), 1)\n    self.assertEqual(unstored_messages[0].message, first_msg)\n"], "sample_1039": ["def test_print_assoc_op():\n    mml = mpp._print(x + y)\n    assert mml.nodeName == 'mrow'\n    assert mml.childNodes[0].nodeName == 'mi'\n    assert mml.childNodes[0].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[1].nodeName == 'mo'\n    assert mml.childNodes[1].childNodes[0].nodeValue == '+'\n    assert mml.childNodes[2].nodeName == 'mi'\n    assert mml.childNodes[2].childNodes[0].nodeValue == 'y'\n\n    mml = mpp._print(x - y)\n    assert mml.nodeName == 'mrow'\n    assert mml.childNodes[0].nodeName == 'mi'\n    assert mml.childNodes[0].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[1].nodeName == 'mo'\n    assert mml.childNodes[1].childNodes[0].nodeValue == '-'\n    assert mml.childNodes[2].nodeName == 'mi'\n    assert mml.childNodes[2].childNodes[0].nodeValue == 'y'\n\n    mml = mpp._print(x * y)\n    assert mml.nodeName == 'mrow'\n    assert mml.childNodes[0].nodeName == 'mi'\n    assert mml.childNodes[0].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[1].nodeName == 'mo'\n    assert mml.childNodes[1].childNodes[0].nodeValue == '&InvisibleTimes;'\n    assert mml.childNodes[2].nodeName == 'mi'\n    assert mml.childNodes[2].childNodes[0].nodeValue == 'y'\n\n    mml = mpp._print(x / y)\n    assert mml.nodeName == 'mfrac'\n    assert mml.childNodes[0].nodeName == 'mi'\n    assert mml.childNodes[0].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[1].nodeName == 'mi'\n    assert mml.childNodes[1].childNodes[0].nodeValue == 'y'\n\n    mml = mpp._print(x ** y)\n    assert mml.nodeName == 'msup'\n    assert mml.childNodes[0].nodeName == 'mi'\n    assert mml.childNodes[0].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[1].nodeName == 'mi'\n    assert mml.childNodes[1].childNodes[0].nodeValue == 'y'\n\n    mml"], "sample_534": ["def test_corner_mask_False_no_mask():\n    n = 60\n    mask_level = 0.95\n    noise_amp = 1.0\n    np.random.seed([1])\n    x, y = np.meshgrid(np.linspace(0, 2.0, n), np.linspace(0, 2.0, n))\n    z = np.cos(7*x)*np.sin(8*y) + noise_amp*np.random.rand(n, n)\n    plt.figure()\n    plt.contourf(z, corner_mask=False)\n"], "sample_197": ["def test_time_strings(self):\n    \"\"\" Test time_strings parameter. \"\"\"\n    time_strings = {\n        'year': ngettext_lazy('%d year', '%d years'),\n        'month': ngettext_lazy('%d month', '%d months'),\n        'week': ngettext_lazy('%d week', '%d weeks'),\n        'day': ngettext_lazy('%d day', '%d days'),\n        'hour': ngettext_lazy('%d hour', '%d hours'),\n        'minute': ngettext_lazy('%d minute', '%d minutes'),\n    }\n    self.assertEqual(timesince(self.t, self.t + self.oneminute, time_strings=time_strings), '1 minute')\n    self.assertEqual(timeuntil(self.t, self.t + self.oneminute, time_strings=time_strings), '1 minute')\n    self.assertEqual(timesince(self.t, self.t + self.oneday, time_strings=time_strings), '1 day')\n    self.assertEqual(timeuntil(self.t, self.t + self.oneday, time_strings=time_strings), '1 day')\n    self.assertEqual(timesince(self.t, self.t + self.oneweek, time_strings=time_strings), '1 week')\n    self.assertEqual(timeuntil(self.t, self.t + self.oneweek, time_strings=time_strings), '1 week')\n    self.assertEqual(timesince(self.t, self.t + self.onemonth, time_strings=time_strings), '1 month')\n    self.assertEqual(timeuntil(self.t, self.t + self.onemonth, time_strings=time_strings), '1 month')\n    self.assertEqual(timesince(self.t, self.t + self.oneyear, time_strings=time_strings), '1 year')\n    self.assertEqual(timeuntil(self.t, self.t + self.oneyear, time_strings=time_strings), '1 year')\n"], "sample_145": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin, ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            'admin.E034'\n        )\n"], "sample_650": ["def test_log_cli_level_change(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n\n        logger = logging.getLogger(__name__)\n\n            logger.info('text going to logger from call')\n            assert False\n        \"\"\"\n    )\n    result = pytester.runpytest(\"--log-cli-level=INFO\")\n    assert result.ret == 1\n    result.stdout.fnmatch_lines(\n        [\n            \"*-- live log call --*\",\n            \"*INFO*text going to logger from call*\",\n        ]\n    )\n    result = pytester.runpytest(\"--log-cli-level=DEBUG\")\n    assert result.ret == 1\n    result.stdout.fnmatch_lines(\n        [\n            \"*-- live log call --*\",\n            \"*DEBUG*text going to logger from call*\",\n        ]\n    )\n"], "sample_713": ["def test_ridge_solver_switch():\n    # Test that solver switch works correctly\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 5, 10\n    X = rng.randn(n_samples, n_features)\n    y = rng.randn(n_samples)\n\n    ridge = Ridge(solver='cholesky')\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape, (n_features,))\n\n    ridge = Ridge(solver='cholesky')\n    ridge.fit(X, y, sample_weight=np.ones(n_samples))\n    assert_equal(ridge.coef_.shape, (n_features,))\n\n    ridge = Ridge(solver='cholesky')\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape, (n_features,))\n\n    ridge = Ridge(solver='cholesky')\n    ridge.fit(X, y, sample_weight=np.ones(n_samples))\n    assert_equal(ridge.coef_.shape, (n_features,))\n\n    # Test that solver switch works correctly when fit_intercept is False\n    ridge = Ridge(solver='cholesky', fit_intercept=False)\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape, (n_features,))\n\n    ridge = Ridge(solver='cholesky', fit_intercept=False)\n    ridge.fit(X, y, sample_weight=np.ones(n_samples))\n    assert_equal(ridge.coef_.shape, (n_features,))\n\n    # Test that solver switch works correctly when normalize is True\n    ridge = Ridge(solver='cholesky', normalize=True)\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape, (n_features,))\n\n    ridge = Ridge(solver='cholesky', normalize=True)\n    ridge.fit(X, y, sample_weight=np.ones(n_samples))\n    assert_equal(ridge.coef_.shape, (n_features,))\n\n    # Test that solver switch works correctly when max_iter is specified\n    ridge = Ridge(solver='cholesky', max_iter=10)\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape, (n_features,))\n\n    ridge = Ridge(solver='cholesky', max_iter=10)\n    ridge.fit(X, y, sample_weight=np.ones(n_samples))\n    assert_equal(ridge.coef_.shape, (n_features,))\n\n    # Test that solver switch works correctly when tol is specified\n    ridge = Ridge(s"], "sample_461": ["    def test_urlfield_clean_empty_scheme(self):\n        f = URLField()\n        self.assertEqual(f.clean(\"example.com\"), \"http://example.com\")\n        self.assertEqual(f.clean(\"example.com:80\"), \"http://example.com:80\")\n        self.assertEqual(f.clean(\"example.com:80/path\"), \"http://example.com:80/path\")\n        self.assertEqual(f.clean(\"example.com/path\"), \"http://example.com/path\")\n        self.assertEqual(f.clean(\"example.com/path?query\"), \"http://example.com/path?query\")\n        self.assertEqual(f.clean(\"example.com/path?query#fragment\"), \"http://example.com/path?query#fragment\")\n        self.assertEqual(f.clean(\"example.com/path?query#fragment/path\"), \"http://example.com/path?query#fragment/path\")\n        self.assertEqual(f.clean(\"example.com/path?query#fragment/path?query\"), \"http://example.com/path?query#fragment/path?query\")\n        self.assertEqual(f.clean(\"example.com/path?query#fragment/path?query#fragment\"), \"http://example.com/path?query#fragment/path?query#fragment\")\n        self.assertEqual(f.clean(\"example.com/path?query#fragment/path?query#fragment/path\"), \"http://example.com/path?query#fragment/path?query#fragment/path\")\n        self.assertEqual(f.clean(\"example.com/path?query#fragment/path?query#fragment/path?query\"), \"http://example.com/path?query#fragment/path?query#fragment/path?query\")\n        self.assertEqual(f.clean(\"example.com/path?query#fragment/path?query#fragment/path?query#fragment\"), \"http://example.com/path?query#fragment/path?query#fragment/path?query#fragment\")\n        self.assertEqual(f.clean(\"example.com/path?query#fragment/path?query#fragment/path?query#fragment/path\"), \"http://example.com/path?query#fragment/path?query#fragment/path?query#fragment/path\")\n        self.assertEqual(f.clean(\"example.com/path?query#fragment/path?query#fragment/path?query#fragment/path?query\"), \"http://example.com/path?query#fragment/path?query#fragment/path?query#fragment/path?query\")\n        self.assertEqual(f.clean(\"example.com/path?query#fragment/path?query#fragment/path?query#fragment/path?query#fragment\"), \"http://example.com/path?query#fragment/path?query#fragment/path?query#fragment"], "sample_442": ["    def test_timestamp_signer_max_age(self):\n        value = \"hello\"\n        with freeze_time(123456789):\n            signer = signing.TimestampSigner(key=\"predictable-key\")\n            ts = signer.sign(value)\n            self.assertNotEqual(ts, signing.Signer(key=\"predictable-key\").sign(value))\n            self.assertEqual(signer.unsign(ts), value)\n\n        with freeze_time(123456800):\n            with self.assertRaises(signing.SignatureExpired):\n                signer.unsign(ts, max_age=10)\n            # max_age parameter can also accept a datetime.timedelta object\n            with self.assertRaises(signing.SignatureExpired):\n                signer.unsign(ts, max_age=datetime.timedelta(seconds=10))\n"], "sample_565": ["def test_inset_axes_invalid_bbox_to_anchor():\n    fig, ax = plt.subplots(figsize=[5, 4])\n\n    # prepare the demo image\n    # Z is a 15x15 array\n    Z = cbook.get_sample_data(\"axes_grid/bivariate_normal.npy\")\n    extent = (-3, 4, -4, 3)\n    Z2 = np.zeros((150, 150))\n    ny, nx = Z.shape\n    Z2[30:30+ny, 30:30+nx] = Z\n\n    ax.imshow(Z2, extent=extent, interpolation=\"nearest\",\n              origin=\"lower\")\n\n    # creating our inset axes with a bbox_transform parameter\n    with pytest.raises(ValueError):\n        inset_axes(ax, width=1., height=1.2, bbox_to_anchor=(200, 100),\n                   loc=3, borderpad=0, bbox_transform=ax.transAxes)\n\n    with pytest.raises(ValueError):\n        inset_axes(ax, width=1., height=1.2, bbox_to_anchor=(200, 100),\n                   loc=3, borderpad=0, bbox_transform=ax.transAxes,\n                   width=\"40%\")\n\n    with pytest.raises(ValueError):\n        inset_axes(ax, width=1., height=1.2, bbox_to_anchor=(200, 100),\n                   loc=3, borderpad=0, bbox_transform=ax.transAxes,\n                   height=\"30%\")\n"], "sample_394": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(\n            username=\"super\", password=\"secret\", email=\"super@example.com\"\n        )\n        cls.s1 = Section.objects.create(name=\"Test section\")\n        cls.a1 = Article.objects.create(\n            content=\"<p>Middle content</p>\",\n            date=datetime.datetime(2008, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.a2 = Article.objects.create(\n            content=\"<p>Oldest content</p>\",\n            date=datetime.datetime(2000, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.a3 = Article.objects.create(\n            content=\"<p>Newest content</p>\",\n            date=datetime.datetime(2009, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.p1 = PrePopulatedPost.objects.create(\n            title=\"A Long Title\", published=True, slug=\"a-long-title\"\n        )\n        cls.per1 = Person.objects.create(name=\"John Mauchly\", gender=1, alive=True)\n        cls.per2 = Person.objects.create(name=\"Grace Hopper\", gender=1, alive=False)\n        cls.per3 = Person.objects.create(name=\"Guido van Rossum\", gender=1, alive=True)\n"], "sample_1205": ["def test_PolyElement_mul_ground():\n    R, x = ring(\"x\", ZZ)\n\n    assert R(1).mul_ground(2) == 2\n    assert R(2).mul_ground(2) == 4\n\n    assert R(1).mul_ground(0) == 0\n    assert R(2).mul_ground(0) == 0\n\n    assert R(1).mul_ground(-2) == -2\n    assert R(2).mul_ground(-2) == -4\n\n    R, x, y = ring(\"x,y\", ZZ)\n\n    assert R(1).mul_ground(2) == 2\n    assert R(2).mul_ground(2) == 4\n\n    assert R(1).mul_ground(0) == 0\n    assert R(2).mul_ground(0) == 0\n\n    assert R(1).mul_ground(-2) == -2\n    assert R(2).mul_ground(-2) == -4\n\n    assert (x + 1).mul_ground(2) == 2*x + 2\n    assert (x + 1).mul_ground(0) == 0\n    assert (x + 1).mul_ground(-2) == -2*x - 2\n\n    R, x, y, z = ring(\"x,y,z\", ZZ)\n\n    assert R(1).mul_ground(2) == 2\n    assert R(2).mul_ground(2) == 4\n\n    assert R(1).mul_ground(0) == 0\n    assert R(2).mul_ground(0) == 0\n\n    assert R(1).mul_ground(-2) == -2\n    assert R(2).mul_ground(-2) == -4\n\n    assert (x + 1).mul_ground(2) == 2*x + 2\n    assert (x + 1).mul_ground(0) == 0\n    assert (x + 1).mul_ground(-2) == -2*x - 2\n\n    assert (x*y + 1).mul_ground(2) == 2*x*y + 2\n    assert (x*y + 1).mul_ground(0) == 0\n    assert (x*y + 1).mul_ground(-2) == -2*x*y - 2\n\n    assert (x*y*z +"], "sample_854": ["def test_libsvm_sparse_predict_proba():\n    # Test libsvm_sparse_predict_proba\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    clf = svm.SVC(kernel='linear')\n    clf.fit(X, y)\n    assert_array_almost_equal(clf.predict_proba(X), clf._sparse_predict_proba(X))\n"], "sample_642": ["def test_init_hook(capsys: CaptureFixture) -> None:\n    \"\"\"Test that the init hook is executed.\"\"\"\n    with tempdir() as chroot:\n        with fake_home():\n            chroot_path = Path(chroot)\n            testutils.create_files([\"a/b/c/d/__init__.py\"])\n            os.chdir(chroot_path / \"a/b/c\")\n            init_hook = \"import sys; sys.path.append('/tmp')\"\n            with pytest.raises(SystemExit):\n                Run([\"--init-hook\", init_hook])\n            out = capsys.readouterr()\n            assert \"/tmp\" in out.out\n"], "sample_235": ["    def setUp(self):\n        self.notified = []\n"], "sample_353": ["    def test_fields_with_fk_and_password_validation(self):\n        \"\"\"\n        A CommandError should be raised if the user enters in passwords which\n        fail validation when creating a superuser with a foreign key field.\n        \"\"\"\n        new_io = StringIO()\n        group = Group.objects.create(name='mygroup')\n        email = Email.objects.create(email='mymail@gmail.com')\n\n        @mock_inputs({\n            'password': '1234567890',\n            'username': email.pk,\n            'email': email.email,\n            'Group (Group.id): ': group.pk,\n            'bypass': 'n',\n        })\n            call_command(\n                'createsuperuser',\n                interactive=True,\n                stdout=new_io,\n                stdin=MockTTY(),\n            )\n            self.assertEqual(\n                new_io.getvalue().strip(),\n                \"This password is entirely numeric.\\n\"\n                \"Superuser created successfully.\"\n            )\n\n        test(self)\n"], "sample_1014": ["def test_indexed_base():\n    from sympy.abc import x, y, z\n    M = ImmutableDenseNDimArray([[x, y], [z, x*y]])\n    A = IndexedBase(\"A\", (2, 2))\n    assert A[0, 0].subs(A, M) == x\n    assert A[0, 1].subs(A, M) == y\n    assert A[1, 0].subs(A, M) == z\n    assert A[1, 1].subs(A, M) == x*y\n    assert A[0, 0].subs({A[0, 0]: 1}) == 1\n    assert A[0, 0].subs({A[0, 0]: 1, A[0, 1]: 2}) == 1\n    assert A[0, 0].subs({A[0, 0]: 1, A[1, 0]: 2}) == 1\n    assert A[0, 0].subs({A[0, 0]: 1, A[1, 1]: 2}) == 1\n    assert A[0, 0].subs({A[0, 0]: 1, A[1, 0]: 2, A[1, 1]: 3}) == 1\n    assert A[0, 0].subs({A[0, 0]: 1, A[0, 1]: 2, A[1, 0]: 3, A[1, 1]: 4}) == 1\n    assert A[0, 0].subs({A[0, 0]: 1, A[0, 1]: 2, A[1, 0]: 3, A[1, 1]: 4, A[2, 0]: 5, A[2, 1]: 6}) == 1\n    assert A[0, 0].subs({A[0, 0]: 1, A[0, 1]: 2, A[1, 0]: 3, A[1, 1]: 4, A[2, 0]: 5, A[2, 1]: 6, A[3, 0]: 7, A"], "sample_1189": ["def test_lambdify_with_numpy_array_arg():\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    f = lambdify([[x, y]], x*x + y, 'numpy')\n    assert f(numpy.array([2.0, 1.0])) == 5\n    assert \"numpy\" in str(type(f(numpy.array([2.0, 1.0]))))\n"], "sample_258": ["def test_disconnect_multiple_receivers(self):\n    receiver_1 = Callable()\n    receiver_2 = Callable()\n    receiver_3 = Callable()\n    a_signal.connect(receiver_1)\n    a_signal.connect(receiver_2)\n    a_signal.connect(receiver_3)\n    a_signal.disconnect(receiver_1)\n    a_signal.disconnect(receiver_2)\n    a_signal.disconnect(receiver_3)\n    self.assertTestIsClean(a_signal)\n"], "sample_229": ["def test_difference_with_distinct(self):\n    qs1 = Number.objects.filter(num__lt=10).distinct()\n    qs2 = Number.objects.filter(num__lt=9).distinct()\n    self.assertNumbersEqual(qs1.difference(qs2), [9], ordered=False)\n"], "sample_879": ["def test_one_hot_encoder_handle_unknown_strings_sparse():\n    \"\"\"Check the ignore option, when categories are numpy string dtype\n    particularly when the known category strings are larger than the unknown\n    category strings.\"\"\"\n    X = np.array([\"11111111\", \"22\", \"333\", \"4444\"]).reshape((-1, 1))\n    X2 = np.array([\"55555\", \"22\"]).reshape((-1, 1))\n    # Non Regression test for the issue #12470\n    # Test the ignore option, when categories are numpy string dtype\n    # particularly when the known category strings are larger than the unknown\n    # category strings\n    oh = OneHotEncoder(handle_unknown=\"ignore\")\n    oh.fit(X)\n    X2_passed = X2.copy()\n    assert_array_equal(\n        oh.transform(X2_passed).toarray(),\n        np.array([[0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]]),\n    )\n    # ensure transformed data was not modified in place\n    assert_array_equal(X2, X2_passed)\n"], "sample_350": ["def test_difference_with_values_list_and_order_by_alias(self):\n    ReservedName.objects.create(name='rn1', order=2)\n    qs1 = Number.objects.annotate(\n        alias=F('num'),\n    ).filter(num__gte=6)\n    qs2 = Number.objects.annotate(\n        alias=F('num'),\n    ).filter(num__lte=5)\n    self.assertCountEqual(\n        qs1.difference(qs2).values_list('alias', flat=True),\n        [6, 7, 8, 9],\n    )\n    self.assertQuerysetEqual(\n        qs1.difference(qs2).values_list('alias', flat=True).order_by('alias'),\n        [6, 7, 8, 9],\n        operator.itemgetter('alias'),\n    )\n"], "sample_977": ["def test_Parenthesize():\n    assert mcode((x + y)) == \"(x + y)\"\n    assert mcode((x + y) * (x + y)) == \"((x + y)*(x + y))\"\n    assert mcode((x + y) * (x + y) * (x + y)) == \"(((x + y)*(x + y))*(x + y))\"\n    assert mcode((x + y) * (x + y) * (x + y) * (x + y)) == \"((((x + y)*(x + y))*(x + y))*(x + y))\"\n    assert mcode((x + y) * (x + y) * (x + y) * (x + y) * (x + y)) == \"(((((x + y)*(x + y))*(x + y))*(x + y))*(x + y))\"\n    assert mcode((x + y) * (x + y) * (x + y) * (x + y) * (x + y) * (x + y)) == \"((((((x + y)*(x + y))*(x + y))*(x + y))*(x + y))*(x + y))\"\n"], "sample_173": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_819": ["def test_transform_proba():\n    \"\"\"Check transform method of VotingClassifier on toy dataset.\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    X = np.array([[-1.1, -1.5], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n    y = np.array([1, 1, 2, 2])\n\n    eclf1 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft',\n        flatten_transform=False).fit(X, y)\n    eclf2 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft',\n        flatten_transform=True).fit(X, y)\n\n    proba1 = eclf1._collect_probas(X)\n    proba2 = eclf2._collect_probas(X)\n\n    assert_array_almost_equal(eclf1.transform(X), proba1)\n    assert_array_almost_equal(eclf2.transform(X), proba2)\n"], "sample_1052": ["def test_fcode_matrixsymbol_slice_autoname():\n    # see issue #8093\n    A = MatrixSymbol('A', 2, 3)\n    name_expr = (\"test\", A[:, 1])\n    result = codegen(name_expr, \"f95\", \"test\", header=False, empty=False)\n    source = result[0][1]\n    expected = (\n        \"subroutine test(A, out_%(hash)s)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in), dimension(1:2, 1:3) :: A\\n\"\n        \"REAL*8, intent(out), dimension(1:2, 1:1) :: out_%(hash)s\\n\"\n        \"out_%(hash)s(1, 1) = A(1, 2)\\n\"\n        \"out_%(hash)s(2, 1) = A(2, 2)\\n\"\n        \"end subroutine\\n\"\n    )\n    # look for the magic number\n    a = source.splitlines()[3]\n    b = a.split('_')\n    out = b[1]\n    expected = expected % {'hash': out}\n    assert source == expected\n"], "sample_134": ["def test_serialize_deconstructable_instances(self):\n    \"\"\"\n    Test serialization of deconstructable instances.\n    \"\"\"\n    self.assertSerializedEqual(DeconstructibleInstances())\n    self.assertSerializedResultEqual(\n        DeconstructibleInstances(),\n        (\"migrations.test_writer.DeconstructibleInstances()\", {'import migrations.test_writer'})\n    )\n"], "sample_295": ["    def setUpTestData(cls):\n        cls.e1 = Experiment.objects.create(\n            name='e1', assigned=datetime.date(2010, 6, 25), start=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000),\n            end=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000), completed=datetime.date(2010, 6, 25),\n            estimated_time=datetime.timedelta(0)\n        )\n        cls.e2 = Experiment.objects.create(\n            name='e2', assigned=datetime.date(2010, 6, 25), start=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000),\n            end=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000), completed=datetime.date(2010, 6, 25),\n            estimated_time=datetime.timedelta(0)\n        )\n        cls.e3 = Experiment.objects.create(\n            name='e3', assigned=datetime.date(2010, 6, 25), start=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000),\n            end=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000), completed=datetime.date(2010, 6, 25),\n            estimated_time=datetime.timedelta(0)\n        )\n        cls.e4 = Experiment.objects.create(\n            name='e4', assigned=datetime.date(2010, 6, 25), start=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000),\n            end=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000), completed=datetime.date(2010, 6, 25),\n            estimated_time=datetime.timedelta(0)\n        )\n        cls.e5 = Experiment.objects.create(\n            name='e5', assigned=datetime.date(2010, 6, 25), start=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000),\n            end=datetime.datetime(2010, 6, 25, 12, 15, 30, "], "sample_891": ["def test_average_precision_score_multiclass():\n    # Test average precision score for multiclass classification\n    y_true = np.array([0, 1, 2])\n    y_score = np.array([[0.1, 0.8, 0.1], [0.3, 0.4, 0.3], [0.35, 0.5, 0.15]])\n    assert_almost_equal(average_precision_score(y_true, y_score), 0.5)\n    assert_almost_equal(average_precision_score(y_true, y_score, average=\"macro\"), 0.5)\n    assert_almost_equal(average_precision_score(y_true, y_score, average=\"weighted\"), 0.5)\n    assert_almost_equal(average_precision_score(y_true, y_score, average=\"samples\"), 0.5)\n    assert_almost_equal(average_precision_score(y_true, y_score, average=\"micro\"), 0.5)\n\n    y_true = np.array([0, 1, 2, 2])\n    y_score = np.array([[0.1, 0.8, 0.1], [0.3, 0.4, 0.3], [0.35, 0.5, 0.15], [0, 0.2, 0.8]])\n    assert_almost_equal(average_precision_score(y_true, y_score), 0.5)\n    assert_almost_equal(average_precision_score(y_true, y_score, average=\"macro\"), 0.5)\n    assert_almost_equal(average_precision_score(y_true, y_score, average=\"weighted\"), 0.5)\n    assert_almost_equal(average_precision_score(y_true, y_score, average=\"samples\"), 0.5)\n    assert_almost_equal(average_precision_score(y_true, y_score, average=\"micro\"), 0.5)\n\n    y_true = np.array([0, 1, 2, 2])\n    y_score = np.array([[0.1, 0.8, 0.1], [0.3, 0.4, 0.3], [0.35, 0.5, 0.15], [0.4, 0.3, 0.3]])\n    assert_almost_equal(average_precision_score(y_true, y_score), 0.5)\n    assert_almost_equal(average_precision_score(y_true, y_score, average=\"macro"], "sample_1042": ["def test_IndexedBase_shape_precedence():\n    i, j = symbols('i j', integer=True)\n    o, p = symbols('o p', integer=True)\n    n, m = symbols('n m', integer=True)\n    a = IndexedBase('a', shape=(o, p))\n    assert Indexed(a, Idx(i, m), Idx(j, n)).ranges == [Tuple(0, m - 1), Tuple(0, n - 1)]\n    assert Indexed(a, Idx(i, m), Idx(j, n)).shape == Tuple(o, p)\n    assert Indexed(a, Idx(i, m), Idx(j)).ranges == [Tuple(0, m - 1), Tuple(None, None)]\n    assert Indexed(a, Idx(i, m), Idx(j)).shape == Tuple(o, p)\n"], "sample_120": ["def test_serialize_deconstructable_class(self):\n    \"\"\"\n    Test serialization of a deconstructable class.\n    \"\"\"\n    class DeconstructableClass:\n            return ('DeconstructableClass', [], {})\n\n    class DeconstructableSerializer(BaseSerializer):\n            return 'deconstructable_class(%r)' % self.value, {}\n\n    MigrationWriter.register_serializer(DeconstructableClass, DeconstructableSerializer)\n    self.assertSerializedEqual(DeconstructableClass())\n    MigrationWriter.unregister_serializer(DeconstructableClass)\n    with self.assertRaisesMessage(ValueError, 'Cannot serialize: DeconstructableClass'):\n        self.assertSerializedEqual(DeconstructableClass())\n"], "sample_165": ["    def test_modelform(self):\n        # Create a model instance for the model form tests below.\n        ChoiceModel.objects.create(pk=1, name='a')\n        ChoiceModel.objects.create(pk=2, name='b')\n        ChoiceModel.objects.create(pk=3, name='c')\n\n        # ModelForm\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': 'INVALID CHOICE',\n        }\n        f = ModelForm(ChoiceModel, error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID CHOICE'], f.clean, '4')\n\n        # ModelForm with fields\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': 'INVALID CHOICE',\n        }\n        f = ModelForm(ChoiceModel, fields=['name'], error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID CHOICE'], f.clean, '4')\n\n        # ModelForm with exclude\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': 'INVALID CHOICE',\n        }\n        f = ModelForm(ChoiceModel, exclude=['name'], error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID CHOICE'], f.clean, '4')\n\n        # ModelForm with formfield_callback\n            if f.name == 'name':\n                return CharField(error_messages=e)\n            return f.formfield()\n\n        f = ModelForm(ChoiceModel, formfield_callback=formfield_callback)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID CHOICE'], f.clean, '4')\n\n        # ModelForm with widgets\n        f = ModelForm(ChoiceModel, widgets={'name': CharField(widget=HiddenInput)})\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID CHOICE'], f.clean, '4')\n\n        # ModelForm with localized_fields\n        f = ModelForm(ChoiceModel, localized_fields=['name'])\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID CHOICE'], f.clean, '4')\n\n        # ModelForm with labels\n        f = ModelForm(ChoiceModel, labels={'name': 'Name'})\n        self.assertFormErrors(['REQUIRED'], f"], "sample_1018": ["def test_fcode_Lambda():\n    x = symbols('x')\n    g = Lambda(x, 2*x)\n    assert fcode(g(x)) == \"      2*x\"\n    g = Lambda(x, 2*pi/x)\n    assert fcode(g(x)) == (\n        \"      parameter (pi = %sd0)\\n\"\n        \"      2*pi/x\"\n    ) % pi.evalf(17)\n    A = IndexedBase('A')\n    i = Idx('i', symbols('n', integer=True))\n    g = Lambda(x, x*(1 + x)*(2 + x))\n    assert fcode(g(A[i]), assign_to=A[i]) == (\n        \"      do i = 1, n\\n\"\n        \"         A(i) = (A(i) + 1)*(A(i) + 2)*A(i)\\n\"\n        \"      end do\"\n    )\n"], "sample_381": ["def test_alter_field_with_renamed_model(self):\n    \"\"\"\n    #24537 - The order of fields in a model does not influence the RenameModel detection.\n    \"\"\"\n    before = [\n        ModelState(\"testapp\", \"EntityA\", [\n            (\"id\", models.AutoField(primary_key=True)),\n        ]),\n        ModelState(\"testapp\", \"EntityB\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"some_label\", models.CharField(max_length=255)),\n            (\"entity_a\", models.ForeignKey(\"testapp.EntityA\", models.CASCADE)),\n        ]),\n    ]\n    after = [\n        ModelState(\"testapp\", \"EntityA\", [\n            (\"id\", models.AutoField(primary_key=True)),\n        ]),\n        ModelState(\"testapp\", \"RenamedEntityB\", [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"entity_a\", models.ForeignKey(\"testapp.EntityA\", models.CASCADE)),\n            (\"some_label\", models.CharField(max_length=255)),\n        ]),\n    ]\n    changes = self.get_changes(before, after, MigrationQuestioner({\"ask_rename_model\": True}))\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"RenameModel\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, old_name=\"EntityB\", new_name=\"RenamedEntityB\")\n"], "sample_965": ["def test_getmro():\n    class Foo:\n        pass\n\n    class Bar(Foo):\n        pass\n\n    class Baz(Bar):\n        pass\n\n    assert inspect.getmro(Foo) == (Foo,)\n    assert inspect.getmro(Bar) == (Bar, Foo)\n    assert inspect.getmro(Baz) == (Baz, Bar, Foo)\n\n    class Qux:\n        pass\n\n    assert inspect.getmro(Qux) == (Qux,)\n\n    class Qux(Foo):\n        pass\n\n    assert inspect.getmro(Qux) == (Qux, Foo)\n\n    class Qux(Foo, Bar):\n        pass\n\n    assert inspect.getmro(Qux) == (Qux, Foo, Bar)\n\n    class Qux(Foo, Bar, Baz):\n        pass\n\n    assert inspect.getmro(Qux) == (Qux, Foo, Bar, Baz)\n\n    class Qux(Foo, Bar, Baz, object):\n        pass\n\n    assert inspect.getmro(Qux) == (Qux, Foo, Bar, Baz, object)\n\n    class Qux(object):\n        pass\n\n    assert inspect.getmro(Qux) == (Qux, object)\n\n    class Qux(object, Foo):\n        pass\n\n    assert inspect.getmro(Qux) == (Qux, object, Foo)\n\n    class Qux(object, Foo, Bar):\n        pass\n\n    assert inspect.getmro(Qux) == (Qux, object, Foo, Bar)\n\n    class Qux(object, Foo, Bar, Baz):\n        pass\n\n    assert inspect.getmro(Qux) == (Qux, object, Foo, Bar, Baz)\n\n    class Qux(object, Foo, Bar, Baz, object):\n        pass\n\n    assert inspect.getmro(Qux) == (Qux, object, Foo, Bar, Baz)\n\n    class Qux(object, object):\n        pass\n\n    assert inspect.getmro(Qux) == (Qux, object)\n\n    class Qux(object, object, Foo):\n        pass\n\n    assert inspect.getmro(Qux) == (Qux, object, Foo)\n\n    class Qux(object, object, Foo, Bar):\n        pass\n\n    assert inspect.getmro(Qux) == (Qux, object, Foo, Bar)\n\n    class Qux(object, object, Foo, Bar,"], "sample_95": ["    def test_cache_control_decorator(self):\n        \"\"\"\n        Test the cache_control decorator.\n        \"\"\"\n            return HttpResponse()\n\n        my_view_cached = cache_control(private=True, max_age=123)(my_view)\n        response = my_view_cached(HttpRequest())\n        self.assertEqual(response['Cache-Control'], 'private, max-age=123')\n\n        my_view_cached2 = cache_control(private=False, max_age=456)(my_view)\n        response = my_view_cached2(HttpRequest())\n        self.assertEqual(response['Cache-Control'], 'max-age=456')\n\n        my_view_cached3 = cache_control(private=True, max_age=0)(my_view)\n        response = my_view_cached3(HttpRequest())\n        self.assertEqual(response['Cache-Control'], 'private, max-age=0')\n\n        my_view_cached4 = cache_control(private=True, no_cache=True)(my_view)\n        response = my_view_cached4(HttpRequest())\n        self.assertEqual(response['Cache-Control'], 'private, max-age=0, no-cache')\n\n        my_view_cached5 = cache_control(private=True, no_store=True)(my_view)\n        response = my_view_cached5(HttpRequest())\n        self.assertEqual(response['Cache-Control'], 'private, max-age=0, no-store')\n\n        my_view_cached6 = cache_control(private=True, must_revalidate=True)(my_view)\n        response = my_view_cached6(HttpRequest())\n        self.assertEqual(response['Cache-Control'], 'private, max-age=0, must-revalidate')\n"], "sample_585": ["def test_da_groupby_fillna():\n    array = xr.DataArray([1, 2, np.nan, 4, 5, np.nan],\n                         [('x', [1, 1, 1, 2, 2, 2])])\n\n    expected = xr.DataArray([1, 2, 2, 4, 5, 5],\n                            [('x', [1, 1, 1, 2, 2, 2)])\n                            ]\n                           )\n    actual = array.groupby('x').fillna(2)\n    assert_identical(expected, actual)\n\n    array = xr.DataArray([1, 2, np.nan, 4, 5, np.nan],\n                         [('x', [1, 1, 1, 2, 2, 2]),\n                          ('y', [0, 0, 1])])\n\n    expected = xr.DataArray([1, 2, 2, 4, 5, 5],\n                            [('x', [1, 1, 1, 2, 2, 2]),\n                             ('y', [0, 0, 1])\n                            ]\n                           )\n    actual = array.groupby('x').fillna(2)\n    assert_identical(expected, actual)\n\n    array = xr.DataArray([1, 2, np.nan, 4, 5, np.nan],\n                         [('x', [1, 1, 1, 2, 2, 2])])\n\n    expected = xr.DataArray([1, 2, 2, 4, 5, 5],\n                            [('x', [1, 1, 1, 2, 2, 2])\n                            ]\n                           )\n    actual = array.groupby('x').fillna(2, keep_attrs=False)\n    assert_identical(expected, actual)\n"], "sample_505": ["def test_date2num_tz():\n    # Test for github issue #3896, but in date2num with a timezone-aware datetime object.\n    BRUSSELS = dateutil.tz.gettz('Europe/Brussels')\n    dt = datetime.datetime(2014, 3, 30, 0, 0, tzinfo=BRUSSELS)\n    t = mdates.date2num(dt)\n    assert np.isnan(t)\n"], "sample_473": ["    def test_request_aborted(self):\n        \"\"\"Test RequestAborted exception is raised when client disconnects.\"\"\"\n        async def receive():\n            await asyncio.sleep(0)\n            raise asyncio.IncompleteRead(b\"partial body\", 10)\n\n        handler = ASGIHandler()\n        with self.assertRaises(RequestAborted):\n            handler({\"type\": \"http.request\"}, receive, lambda *a, **k: None)\n"], "sample_782": ["def test_column_transformer_sparse_output():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    X_sparse = sparse.csr_matrix(X_array)\n\n    # no distinction between 1D and 2D\n    X_res_first = X_sparse[:, 0]\n    X_res_both = X_sparse\n\n    for col in [0, [0], slice(0, 1)]:\n        for remainder, res in [('drop', X_res_first),\n                               ('passthrough', X_res_both)]:\n            ct = ColumnTransformer([('trans', Trans(), col)],\n                                   remainder=remainder,\n                                   sparse_threshold=0.8)\n            assert sparse.issparse(ct.fit_transform(X_sparse))\n            assert_allclose_dense_sparse(ct.fit_transform(X_sparse), res)\n            assert_allclose_dense_sparse(ct.fit(X_sparse).transform(X_sparse),\n                                         res)\n\n    for col in [[0, 1], slice(0, 2)]:\n        ct = ColumnTransformer([('trans', Trans(), col)],\n                               sparse_threshold=0.8)\n        assert sparse.issparse(ct.fit_transform(X_sparse))\n        assert_allclose_dense_sparse(ct.fit_transform(X_sparse), X_res_both)\n        assert_allclose_dense_sparse(ct.fit(X_sparse).transform(X_sparse),\n                                     X_res_both)\n"], "sample_640": ["def test_is_subscriptable_pep585() -> None:\n    code = astroid.extract_node(\n        \"\"\"\n    from typing import List\n    class C(List): #@\n        pass\n    \"\"\"\n    )\n    assert utils.is_class_subscriptable_pep585_with_postponed_evaluation_enabled(code, None)\n\n    code = astroid.extract_node(\n        \"\"\"\n    from typing import List\n    class C: #@\n        pass\n    \"\"\"\n    )\n    assert not utils.is_class_subscriptable_pep585_with_postponed_evaluation_enabled(code, None)\n\n    code = astroid.extract_node(\n        \"\"\"\n    from typing import List\n    class C(List): #@\n        pass\n    \"\"\"\n    )\n    assert utils.is_class_subscriptable_pep585_with_postponed_evaluation_enabled(code, None)\n\n    code = astroid.extract_node(\n        \"\"\"\n    from typing import List\n    class C: #@\n        pass\n    \"\"\"\n    )\n    assert not utils.is_class_subscriptable_pep585_with_postponed_evaluation_enabled(code, None)\n"], "sample_97": ["    def test_iter_modules_and_files_with_zip_importer(self):\n        \"\"\"\n        Modules imported from zipped files have their archive location included\n        in the result.\n        \"\"\"\n        zip_file = self.temporary_file('zip_import.zip')\n        with zipfile.ZipFile(str(zip_file), 'w', zipfile.ZIP_DEFLATED) as zipf:\n            zipf.writestr('test_zipped_file.py', '')\n\n        with extend_sys_path(str(zip_file)):\n            self.import_and_cleanup('test_zipped_file')\n        self.assertFileFound(zip_file)\n"], "sample_102": ["def test_difference_with_distinct(self):\n    qs1 = Number.objects.filter(num__lt=10).distinct()\n    qs2 = Number.objects.filter(num__lt=9)\n    self.assertNumbersEqual(qs1.difference(qs2), [9], ordered=False)\n"], "sample_380": ["def test_aggregate_subquery_annotation_values_list(self):\n    \"\"\"\n    Subquery annotations and external aliases are excluded from the GROUP BY if they are not selected.\n    \"\"\"\n    books_qs = Book.objects.annotate(\n        first_author_the_same_age=Subquery(\n            Author.objects.filter(\n                age=OuterRef('contact__friends__age'),\n            ).order_by('age').values('id')[:1],\n        )\n    ).filter(\n        publisher=self.p1,\n        first_author_the_same_age__isnull=False,\n    ).annotate(\n        min_age=Min('contact__friends__age'),\n    ).values_list('name', 'min_age').order_by('name')\n    self.assertEqual(list(books_qs), [\n        {'name': 'Practical Django Projects', 'min_age': 34},\n        {\n            'name': 'The Definitive Guide to Django: Web Development Done Right',\n            'min_age': 29,\n        },\n    ])\n\n    books_qs = Book.objects.annotate(\n        first_author_the_same_age=Subquery(\n            Author.objects.filter(\n                age=OuterRef('contact__friends__age'),\n            ).order_by('age').values('id')[:1],\n        )\n    ).filter(\n        publisher=self.p1,\n        first_author_the_same_age__isnull=False,\n    ).annotate(\n        min_age=Min('contact__friends__age'),\n    ).values('name', 'min_age').order_by('name')\n    self.assertEqual(list(books_qs), [\n        {'name': 'Practical Django Projects', 'min_age': 34},\n        {\n            'name': 'The Definitive Guide to Django: Web Development Done Right',\n            'min_age': 29,\n        },\n    ])\n\n    books_qs = Book.objects.annotate(\n        first_author_the_same_age=Subquery(\n            Author.objects.filter(\n                age=OuterRef('contact__friends__age'),\n            ).order_by('age').values('id')[:1],\n        )\n    ).filter(\n        publisher=self.p1,\n        first_author_the_same_age__isnull=False,\n    ).annotate(\n        min_age=Min('contact__friends__age'),\n    ).values_list('name', flat=True).order_by('name')\n    self.assertEqual(list(books_qs), [\n        'Practical Django Projects',\n        'The Definitive Guide to Django: Web Development Done Right',\n    ])\n\n    books_qs = Book.objects.annotate(\n        first_author_the_same_age=Sub"], "sample_596": ["def test_concat_fill_value_dict():\n    ds1 = Dataset({\"foo\": (\"x\", [1, 2])}, {\"x\": [0, 1]})\n    ds2 = Dataset({\"foo\": (\"x\", [3, 4])}, {\"x\": [0, 1]})\n    expected = Dataset({\"foo\": (\"x\", [1, 2, 3, 4])}, {\"x\": [0, 1, 0, 1]})\n    actual = concat([ds1, ds2], \"x\", fill_value={\"foo\": 0})\n    assert_identical(expected, actual)\n"], "sample_1127": ["def test_coset_rank_coset_unrank():\n    a = Permutation([1, 0, 2, 3, 4, 5])\n    b = Permutation([2, 1, 3, 4, 5, 0])\n    G = PermutationGroup([a, b])\n    assert G.coset_rank(G[0]) == 0\n    assert G.coset_unrank(0) == G[0]\n    assert G.coset_rank(G[1]) == 1\n    assert G.coset_unrank(1) == G[1]\n    assert G.coset_rank(G[2]) == 2\n    assert G.coset_unrank(2) == G[2]\n    assert G.coset_rank(G[3]) == 3\n    assert G.coset_unrank(3) == G[3]\n    assert G.coset_rank(G[4]) == 4\n    assert G.coset_unrank(4) == G[4]\n    assert G.coset_rank(G[5]) == 5\n    assert G.coset_unrank(5) == G[5]\n    assert G.coset_rank(G[6]) == 6\n    assert G.coset_unrank(6) == G[6]\n    assert G.coset_rank(G[7]) == 7\n    assert G.coset_unrank(7) == G[7]\n    assert G.coset_rank(G[8]) == 8\n    assert G.coset_unrank(8) == G[8]\n    assert G.coset_rank(G[9]) == 9\n    assert G.coset_unrank(9) == G[9]\n    assert G.coset_rank(G[10]) == 10\n    assert G.coset_unrank(10) == G[10]\n    assert G.coset_rank(G[11]) == 11\n    assert G.coset_unrank(11) == G[11]\n    assert G.coset_rank(G[12]) == 12\n    assert G.coset_unrank(12) == G[12]\n    assert G.coset_rank(G[13]) == 13\n    assert G.coset_unrank(13) == G[13]\n    assert G.coset_rank(G[14]) == 14\n    assert G.coset_unrank(14) == G[14]\n    assert G.coset_rank(G"], "sample_960": ["def test_pydata_with_union_type_operator_old(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :annotation: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0],\n                ([desc_name, \"version\"],\n                 [desc_annotation, (\": \",\n                                    [pending_xref, \"int\"],\n                                    \" \",\n                                    [desc_sig_punctuation, \"|\"],\n                                    \" \",\n                                    [pending_xref, \"str\"])]))\n"], "sample_1080": ["def test_refine_issue_12724_2():\n    expr1 = refine(Abs(x * y**2), Q.positive(x))\n    expr2 = refine(Abs(x * y**2 * z), Q.positive(x))\n    assert expr1 == x * Abs(y**2)\n    assert expr2 == x * Abs(y**2 * z)\n    y2 = Symbol('y2', real = True)\n    expr3 = refine(Abs(x * y2**2 * z), Q.positive(x))\n    assert expr3 == x * y2**2 * Abs(z)\n\n    expr4 = refine(Abs(x * y**2), Q.real(x))\n    expr5 = refine(Abs(x * y**2 * z), Q.real(x))\n    assert expr4 == x**2 * Abs(y**2)\n    assert expr5 == x**2 * Abs(y**2 * z)\n    y3 = Symbol('y3', real = True)\n    expr6 = refine(Abs(x * y3**2 * z), Q.real(x))\n    assert expr6 == x**2 * y3**2 * Abs(z)\n"], "sample_458": ["    def test_floatformat03(self):\n        output = self.engine.render_to_string(\n            \"floatformat03\", {\"a\": \"66666.666\", \"b\": \"66666.666\"}\n        )\n        self.assertEqual(output, \"66666.67 66,666.7\")\n"], "sample_944": ["def test_restify_type_hints_Annotated():\n    from typing import Annotated  # type: ignore\n    assert restify(Annotated[int, \"foo\", \"bar\"]) == \":class:`int`\"  # NOQA\n"], "sample_1108": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(signed_permutations((0, 1, 2))) == [\n        (0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2),\n        (0, 2, 1), (0, -2, 1), (0, 2, -1), (0, -2, -1),\n        (1, 0, 2), (-1, 0, 2), (1, 0, -2), (-1, 0, -2),\n        (1, 2, 0), (-1, 2, 0), (1, -2, 0), (-1, -2, 0),\n        (2, 0, 1), (-2, 0, 1), (2, 0, -1), (-2, 0, -1),\n        (2, 1, 0), (-2, 1, 0), (2, -1, 0), (-2, -1, 0)]\n"], "sample_560": ["def test_legend_title_fontprop_fontsize():\n    # test the title_fontsize kwarg\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontproperties=FontProperties(\n                                       family='serif', size=22))\n    assert leg.get_title().get_size() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontsize() == 20\n"], "sample_280": ["def test_aggregation_default_using_duration_field(self):\n    result = Publisher.objects.filter(num_awards__gt=3).aggregate(\n        value=Sum('duration', default=datetime.timedelta(days=0)),\n    )\n    self.assertEqual(result['value'], datetime.timedelta(days=0))\n\n    result = Publisher.objects.filter(num_awards__gt=3).aggregate(\n        value=Sum('duration', default=DurationField().from_pytimespan(datetime.timedelta(0))),\n    )\n    self.assertEqual(result['value'], datetime.timedelta(days=0))\n"], "sample_630": ["def test_get_annotation_annassign_listassign(assign, label):\n    \"\"\"AnnAssign\"\"\"\n    node = astroid.extract_node(assign)\n    got = get_annotation(node.value).name\n    assert isinstance(node, astroid.AnnAssign)\n    assert got == label, f\"got {got} instead of {label} for value {node}\"\n\n"], "sample_778": ["def test_nmf_solver_choice():\n    # Test that the solver choice affects the results\n    n_samples = 20\n    n_features = 10\n    n_components = 5\n    rng = np.random.mtrand.RandomState(42)\n    X = np.abs(rng.randn(n_samples, n_features))\n\n    # initialization\n    W0, H0 = nmf._initialize_nmf(X, n_components, init='random', random_state=42)\n\n    # Compare the results of the two solvers\n    W_cd, H_cd, _ = non_negative_factorization(\n        X, W=W0, H=H0, n_components=n_components, init='custom',\n        update_H=True, solver='cd', random_state=42)\n    W_mu, H_mu, _ = non_negative_factorization(\n        X, W=W0, H=H0, n_components=n_components, init='custom',\n        update_H=True, solver='mu', random_state=42)\n\n    assert_array_almost_equal(W_cd, W_mu, decimal=7)\n    assert_array_almost_equal(H_cd, H_mu, decimal=7)\n\n    # Test that the solvers behave differently when the input contains zeros\n    X_zeros = X.copy()\n    X_zeros[0, 0] = 0\n    W_cd_zeros, H_cd_zeros, _ = non_negative_factorization(\n        X_zeros, W=W0, H=H0, n_components=n_components, init='custom',\n        update_H=True, solver='cd', random_state=42)\n    W_mu_zeros, H_mu_zeros, _ = non_negative_factorization(\n        X_zeros, W=W0, H=H0, n_components=n_components, init='custom',\n        update_H=True, solver='mu', random_state=42)\n\n    assert_array_almost_equal(W_cd_zeros, W_mu_zeros, decimal=7)\n    assert_array_almost_equal(H_cd_zeros, H_mu_zeros, decimal=7)\n"], "sample_341": ["def test_formset_can_order_with_initial_data(self):\n    \"\"\"\n    Formsets with ordering + initial data.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_order=True)\n    initial = [{'choice': 'Calexico', 'votes': 100}, {'choice': 'Fergie', 'votes': 900}]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_869": ["def test_precision_recall_fscore_support_multilabel_3():\n    # Test precision_recall_fscore_support on a crafted multilabel example 3\n    # Third crafted example\n    y_true = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 1, 1, 0]])\n    y_pred = np.array([[0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 0, 0]])\n\n    # tp = [ 0.  1.  0.  0.]\n    # fp = [ 1.  0.  0.  2.]\n    # fn = [ 1.  1.  1.  0.]\n\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred,\n                                                 average=None)\n    assert_array_almost_equal(p, [0.0, 1.0, 0.0, 0.0], 2)\n    assert_array_almost_equal(r, [0.0, 0.5, 0.0, 0.0], 2)\n    assert_array_almost_equal(f, [0.0, 0.66, 0.0, 0.0], 2)\n    assert_array_almost_equal(s, [1, 2, 1, 0], 2)\n\n    f2 = fbeta_score(y_true, y_pred, beta=2, average=None)\n    support = s\n    assert_array_almost_equal(f2, [0, 0.55, 0, 0], 2)\n\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred,\n                                                 average=\"micro\")\n    assert_almost_equal(p, 0.25)\n    assert_almost_equal(r, 0.25)\n    assert_almost_equal(f, 2 * 0.25 * 0.25 / 0.5)\n    assert s is None\n    assert_almost_equal(fbeta_score(y_true, y_pred, beta=2,\n                                    average=\"micro\"),\n                        (1 + 4) * p * r / (4 * p + r))\n\n    p, r, f, s = precision_recall_fscore_support(y_true"], "sample_208": ["def test_alter_field_to_foreign_key(self):\n    \"\"\"Tests autodetection of field type changes from a concrete field to a ForeignKey.\"\"\"\n    changes = self.get_changes([self.author_empty, self.book_with_field_and_author_renamed], [self.author_empty, self.book])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, [\"RemoveField\", \"AddField\"])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"writer\")\n    self.assertOperationAttributes(changes, 'otherapp', 0, 1, name=\"author\")\n"], "sample_88": ["    def test_attachments_with_same_filename(self):\n        \"\"\"\n        Regression test for #14964\n        \"\"\"\n        msg = EmailMessage('Subject', 'Content', 'from@example.com', ['to@example.com'])\n        msg.attach('example.txt', 'Text file content', 'text/plain')\n        msg.attach('example.txt', 'Another text file content', 'text/plain')\n        self.assertEqual(len(msg.attachments), 2)\n        self.assertEqual(msg.attachments[0][0], 'example.txt')\n        self.assertEqual(msg.attachments[1][0], 'example.txt')\n        self.assertEqual(msg.attachments[0][1], b'Text file content')\n        self.assertEqual(msg.attachments[1][1], b'Another text file content')\n        self.assertEqual(msg.attachments[0][2], 'text/plain')\n        self.assertEqual(msg.attachments[1][2], 'text/plain')\n"], "sample_509": ["def test_date_formatter_usetex():\n    style.use(\"default\")\n    d1 = datetime.datetime(1997, 1, 1)\n    d2 = d1 + datetime.timedelta(weeks=520)\n    locator = mdates.AutoDateLocator()\n    formatter = mdates.DateFormatter('%d/%m\\n%Y', usetex=True)\n    ax = plt.subplots()\n    ax.xaxis.set_major_locator(locator)\n    ax.xaxis.set_major_formatter(formatter)\n    ax.plot([d1, d2], [0, 0])\n    fig = ax.figure\n    fig.canvas.draw()\n    assert formatter(19000.0) == r'{\\fontfamily{\\familydefault}\\selectfont 01/01\\n1997}'\n"], "sample_546": ["def test_figure_subplot_mosaic():\n    fig, axs = plt.subplots(2, 2)\n    fig.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n    fig.subplotpars.update(left=0.1, right=0.9, top=0.9, bottom=0.1)\n    fig.align_labels(axs=axs)\n    fig.subplot_mosaic([[1, 2], [3, 4]], sharex=True, sharey=True)\n    assert len(fig.axes) == 4\n    assert fig.axes[0].get_shared_x_axes()[0] is fig.axes[1]\n    assert fig.axes[0].get_shared_x_axes()[0] is fig.axes[2]\n    assert fig.axes[0].get_shared_x_axes()[0] is fig.axes[3]\n    assert fig.axes[0].get_shared_y_axes()[0] is fig.axes[1]\n    assert fig.axes[0].get_shared_y_axes()[0] is fig.axes[2]\n    assert fig.axes[0].get_shared_y_axes()[0] is fig.axes[3]\n    assert fig.subplotpars.left == 0.1\n    assert fig.subplotpars.right == 0.9\n    assert fig.subplotpars.top == 0.9\n    assert fig.subplotpars.bottom == 0.1\n"], "sample_1163": ["def test_issue_19627():\n    from sympy import Function, Abs, sin, cos, sqrt\n    f = Function('f', positive=True)\n    x = Symbol('x')\n    assert Abs(f(x)**2) == f(x)**2\n    assert Abs(f(x)*f(x)) == f(x)**2\n    assert Abs(f(x)*sin(x)) == f(x)*sin(x)\n    assert Abs(f(x)*cos(x)) == f(x)*cos(x)\n    assert Abs(f(x)*sqrt(x)) == f(x)*sqrt(x)\n"], "sample_127": ["    def setUp(self):\n        self.data = [\n            TwoFields(f1=1, f2=2),\n            TwoFields(f1=3, f2=4),\n            TwoFields(f1=5, f2=6),\n            TwoFields(f1=7, f2=8),\n        ]\n"], "sample_618": ["def test_cross_broadcast_compat_data() -> None:\n    a = xr.DataArray([1, 2, 0], dims=[\"cartesian\"])\n    b = xr.DataArray([4, 5, 6], dims=[\"cartesian\"])\n\n    # a has a dimension of size 3, b has a dimension of size 3\n    expected = np.cross(a.data, b.data)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n\n    # a has a dimension of size 2, b has a dimension of size 3\n    expected = np.cross(a.data, b.data)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n\n    # a has a dimension of size 3, b has a dimension of size 2\n    expected = np.cross(a.data, b.data)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n\n    # a has a dimension of size 1, b has a dimension of size 3\n    expected = np.cross(a.data, b.data)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n\n    # a has a dimension of size 3, b has a dimension of size 1\n    expected = np.cross(a.data, b.data)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n\n    # a has a dimension of size 2, b has a dimension of size 1\n    expected = np.cross(a.data, b.data)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n\n    # a has a dimension of size 1, b has a dimension of size 2\n    expected = np.cross(a.data, b.data)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n\n    # a has a dimension of size 1, b has a dimension of size 1\n    expected = np.cross(a.data, b.data)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_all"], "sample_1054": ["def test_ImageSet_simplification():\n    from sympy.abc import n, m\n    assert imageset(Lambda(n, n**2), S.Integers) == ImageSet(Lambda(n, n**2), S.Integers)\n    assert imageset(Lambda(n, sin(n)), S.Integers) == ImageSet(Lambda(n, sin(n)), S.Integers)\n    assert imageset(Lambda(n, sin(n**2)), S.Integers) == ImageSet(Lambda(n, sin(n**2)), S.Integers)\n    assert imageset(Lambda(n, sin(n**2 + 1)), S.Integers) == ImageSet(Lambda(n, sin(n**2 + 1)), S.Integers)\n    assert imageset(Lambda(n, sin(n**2 + n)), S.Integers) == ImageSet(Lambda(n, sin(n**2 + n)), S.Integers)\n"], "sample_253": ["    def test_iter_modules_and_files_with_zip_import(self):\n        \"\"\"\n        Modules imported from zipped files have their archive location included\n        in the result.\n        \"\"\"\n        zip_file = self.temporary_file('zip_import.zip')\n        with zipfile.ZipFile(str(zip_file), 'w', zipfile.ZIP_DEFLATED) as zipf:\n            zipf.writestr('test_zipped_file.py', '')\n\n        with extend_sys_path(str(zip_file)):\n            self.import_and_cleanup('test_zipped_file')\n        self.assertFileFound(zip_file)\n"], "sample_201": ["def test_max_cookie_length_empty(self):\n    \"\"\"\n    If the data exceeds what is allowed in a cookie, an empty list is returned\n    by the ``update`` method.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # When storing as a cookie, the cookie has constant overhead of approx\n    # 54 chars, and each message has a constant overhead of about 37 chars\n    # and a variable overhead of zero in the best case. We aim for a message\n    # size which will fit 0 messages into the cookie, but not 1.\n    msg_size = int((CookieStorage.max_cookie_size - 54) / 37)\n    for i in range(1):\n        storage.add(constants.INFO, str(i) * msg_size)\n    unstored_messages = storage.update(response)\n\n    self.assertEqual(self.stored_messages_count(storage, response), 0)\n    self.assertEqual(unstored_messages, [])\n"], "sample_250": ["def test_date_format_with_leap_year(self):\n    my_birthday = datetime(2000, 2, 29, 22, 00)\n    self.assertEqual(dateformat.format(my_birthday, 'L'), 'True')\n    self.assertEqual(dateformat.format(my_birthday, 'L'), 'True')\n    self.assertEqual(dateformat.format(datetime(2001, 2, 28, 22, 00), 'L'), 'False')\n"], "sample_988": ["def test_issue_13348():\n    assert Eq(True, 1) is S.false\n    assert Eq(False, 0) is S.false\n    assert Eq(True, 0) is S.false\n    assert Eq(False, 1) is S.false\n    assert Eq(True, True) is S.true\n    assert Eq(False, False) is S.true\n    assert Eq(True, False) is S.false\n    assert Eq(False, True) is S.false\n"], "sample_770": ["def test_silhouette_score_deprecation():\n    # Assert that silhouette_score is not deprecated\n    assert_warns_message(UserWarning, \"silhouette_score is deprecated\",\n                         silhouette_score, np.ones((10, 2)), [0] * 5 + [1] * 5))\n\n    # Assert that silhouette_samples is not deprecated\n    assert_warns_message(UserWarning, \"silhouette_samples is deprecated\",\n                         silhouette_samples, np.ones((10, 2)), [0] * 5 + [1] * 5))\n\n    # Assert that calinski_harabasz_score is not deprecated\n    assert_warns_message(UserWarning, \"calinski_harabasz_score is deprecated\",\n                         calinski_harabasz_score, np.ones((10, 2)), [0] * 5 + [1] * 5))\n\n    # Assert that davies_bouldin_score is not deprecated\n    assert_warns_message(UserWarning, \"davies_bouldin_score is deprecated\",\n                         davies_bouldin_score, np.ones((10, 2)), [0] * 5 + [1] * 5))\n\n    # Assert that calinski_harabaz_score is deprecated\n    depr_message = (\"Function 'calinski_harabaz_score' has been renamed \"\n                    \"to 'calinski_harabasz_score' \"\n                    \"and will be removed in version 0.23.\")\n    assert_warns_message(DeprecationWarning, depr_message,\n                         calinski_harabaz_score,\n                         np.ones((10, 2)), [0] * 5 + [1] * 5))\n"], "sample_918": ["def test_pydata_signature_with_type_and_value(app):\n    text = (\".. py:data:: var\\n\"\n            \"   :type: int\\n\"\n            \"   :value: 1\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"var\"],\n                                                    [desc_annotation, (\": \",\n                                                                       [pending_xref, \"int\"])],\n                                                    [desc_annotation, \" = 1\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n    assert 'var' in domain.objects\n    assert domain.objects['var'] == ('index', 'var', 'data')\n"], "sample_657": ["def test_parametrize_empty_parameterset_mark_name(testdir):\n    testdir.makeini(\n        \"\"\"\n    [pytest]\n    {}=fail_at_collect\n    \"\"\".format(\n            EMPTY_PARAMETERSET_OPTION\n        )\n    )\n\n    config = testdir.parseconfig()\n    from _pytest.mark import pytest_configure, get_empty_parameterset_mark\n\n    pytest_configure(config)\n\n    p1 = testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"empty\", [])\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest(str(p1))\n    result.stdout.fnmatch_lines(\n        [\n            \"collected 0 items / 1 errors\",\n            \"* ERROR collecting test_parametrize_empty_parameterset_mark_name.py *\",\n            \"Empty parameter set in 'test' at line 3\",\n            \"*= 1 error in *\",\n        ]\n    )\n    assert result.ret == EXIT_INTERRUPTED\n"], "sample_42": ["def test_doppler_relativistic():\n    rest = 105.01 * u.GHz\n    velo = 30 * u.km/u.s\n    shifted = velo.to(u.GHz, equivalencies=u.doppler_relativistic(rest))\n    np.testing.assert_almost_equal(shifted.value, 999.899940784289, decimal=7)\n"], "sample_628": ["def test_docstring_lines_that_look_like_comments_7(self):\n    stmt = astroid.extract_node(\n        '''def f():\n    \"\"\"\n    cat"], "sample_804": ["def test_one_hot_encoder_handle_unknown_strings_pandas():\n    pd = pytest.importorskip('pandas')\n    X = pd.DataFrame({'A': ['11111111', '22', '333', '4444']})\n    X2 = pd.DataFrame({'A': ['55555', '22']})\n\n    # Non Regression test for the issue #12470\n    # Test the ignore option, when categories are numpy string dtype\n    # particularly when the known category strings are larger\n    # than the unknown category strings\n    oh = OneHotEncoder(handle_unknown='ignore')\n    oh.fit(X)\n    X2_passed = X2.copy()\n    assert_array_equal(\n        oh.transform(X2_passed).toarray(),\n        np.array([[0.,  0.,  0.,  0.], [0.,  1.,  0.,  0.]]))\n    # ensure transformed data was not modified in place\n    assert_array_equal(X2, X2_passed)\n"], "sample_616": ["def test_cross_broadcast_compat_data() -> None:\n    # GH 3694\n\n    a = np.array([1, 2, 0])\n    b = np.array([4, 5, 0])\n    var_a = xr.Variable(\"cartesian\", a)\n    var_b = xr.Variable(\"cartesian\", b)\n\n    # use partially overlapping coords\n    coords_a = {\"cartesian\": (\"cartesian\", [\"x\", \"y\", \"z\"])}\n    coords_b = {\"cartesian\": (\"cartesian\", [\"x\", \"y\", \"z\"])}\n\n    da_a = xr.DataArray(a, dims=[\"cartesian\"], coords=coords_a)\n    da_b = xr.DataArray(b, dims=[\"cartesian\"], coords=coords_b)\n\n    # join=\"inner\" is the default\n    actual = xr.cross(da_a, da_b)\n    # `cross` sums over the common dimensions of the arguments\n    expected = (da_a * da_b).sum([\"cartesian\"])\n    xr.testing.assert_allclose(expected, actual)\n\n    actual = xr.cross(da_a, da_b, dim=\"cartesian\")\n    expected = (da_a * da_b).sum([\"cartesian\"])\n    xr.testing.assert_allclose(expected, actual)\n\n    with xr.set_options(arithmetic_join=\"exact\"):\n        with pytest.raises(ValueError, match=r\"cannot align.*join.*exact.*not equal.*\"):\n            xr.cross(da_a, da_b)\n\n    # NOTE: cross always uses `join=\"inner\"` because `(a * b).sum()` yields the same for all\n    # join method (except \"exact\")\n    with xr.set_options(arithmetic_join=\"left\"):\n        actual = xr.cross(da_a, da_b)\n        expected = (da_a * da_b).sum([\"cartesian\"])\n        xr.testing.assert_allclose(expected, actual)\n\n    with xr.set_options(arithmetic_join=\"right\"):\n        actual = xr.cross(da_a, da_b)\n        expected = (da_a * da_b).sum([\"cartesian\"])\n        xr.testing.assert_allclose(expected, actual)\n\n    with xr.set_options(arithmetic_join=\"outer\"):\n        actual = xr.cross(da_a, da_b)\n        expected = (da_a * da_b).sum([\"cartesian\"])\n        xr.testing.assert_allclose(expected, actual)\n\n    # test for variable\n    actual = xr.cross(var_a, var_b)\n    expected = (var_a * var_b).sum([\"cartesian\"])\n    xr"], "sample_346": ["    def test_cache_page_decorator_http_request(self):\n        class MyClass:\n            @cache_page(60 * 15)\n                return HttpResponse()\n\n        msg = (\n            \"cache_page didn't receive an HttpRequest. If you are decorating \"\n            \"a classmethod, be sure to use @method_decorator.\"\n        )\n        with self.assertRaisesMessage(TypeError, msg):\n            MyClass().a_view(HttpRequest())\n"], "sample_144": ["def test_inheritance_get_next_previous_by_foreign_key(self):\n    \"\"\"\n    Regression tests for #8076\n    get_(next/previous)_by_foreign_key should work\n    \"\"\"\n    c1 = ArticleWithAuthor(\n        headline='ArticleWithAuthor 1',\n        author=\"Person 1\",\n        pub_date=datetime.datetime(2005, 8, 1, 3, 0),\n        author_ptr_id=1,\n    )\n    c1.save()\n    c2 = ArticleWithAuthor(\n        headline='ArticleWithAuthor 2',\n        author=\"Person 2\",\n        pub_date=datetime.datetime(2005, 8, 1, 10, 0),\n        author_ptr_id=2,\n    )\n    c2.save()\n    c3 = ArticleWithAuthor(\n        headline='ArticleWithAuthor 3',\n        author=\"Person 3\",\n        pub_date=datetime.datetime(2005, 8, 2),\n        author_ptr_id=3,\n    )\n    c3.save()\n\n    self.assertEqual(c1.get_next_by_author(), c2)\n    self.assertEqual(c2.get_next_by_author(), c3)\n    with self.assertRaises(ArticleWithAuthor.DoesNotExist):\n        c3.get_next_by_author()\n    self.assertEqual(c3.get_previous_by_author(), c2)\n    self.assertEqual(c2.get_previous_by_author(), c1)\n    with self.assertRaises(ArticleWithAuthor.DoesNotExist):\n        c1.get_previous_by_author()\n"], "sample_544": ["def test_image_cliprect():\n    fig, ax = plt.subplots()\n    d = [[1, 2], [3, 4]]\n\n    im = ax.imshow(d, extent=(0, 5, 0, 5))\n\n    rect = patches.Rectangle(\n        xy=(1, 1), width=2, height=2, transform=im.axes.transData)\n    im.set_clip_path(rect)\n\n    # Test that the image is clipped correctly\n    assert im.get_extent() == (1, 3, 1, 3)\n"], "sample_843": ["def test_kernel_exponentiation():\n    # Test that exponentiation of a kernel is correctly implemented.\n    kernel = RBF(length_scale=2.0)\n    exp_kernel = kernel ** 2.0\n    K = exp_kernel(X)\n    K_exact = kernel(X) ** 2.0\n    assert_array_almost_equal(K, K_exact, 5)\n"], "sample_1158": ["def test_sympify_complex():\n    assert sympify(1 + 2j) == 1.0 + I*2.0\n    assert sympify(1.0 + 2.0j) == 1.0 + I*2.0\n    assert sympify('1 + 2*I') == 1.0 + I*2.0\n    assert sympify('1.0 + 2.0*I') == 1.0 + I*2.0\n    assert sympify('1 + 2j') == 1.0 + I*2.0\n    assert sympify('1.0 + 2j') == 1.0 + I*2.0\n    assert sympify('1 + 2*I', rational=True) == Rational(1, 1) + I*Rational(2, 1)\n    assert sympify('1.0 + 2.0*I', rational=True) == Rational(1, 1) + I*Rational(2, 1)\n    assert sympify('1 + 2j', rational=True) == Rational(1, 1) + I*Rational(2, 1)\n    assert sympify('1.0 + 2j', rational=True) == Rational(1, 1) + I*Rational(2, 1)\n    assert sympify('1 + 2*I', evaluate=False) == 1.0 + I*2.0\n    assert sympify('1.0 + 2.0*I', evaluate=False) == 1.0 + I*2.0\n    assert sympify('1 + 2j', evaluate=False) == 1.0 + I*2.0\n    assert sympify('1.0 + 2j', evaluate=False) == 1.0 + I*2.0\n"], "sample_587": ["    def test_merge_fill_value(self):\n        ds1 = xr.Dataset({\"x\": 0})\n        ds2 = xr.Dataset({\"x\": (\"y\", [0, 0])})\n        actual = ds1.merge(ds2, fill_value=1)\n        expected = xr.Dataset({\"x\": (\"y\", [0, 0])})\n        assert expected.identical(actual)\n\n        ds1 = xr.Dataset({\"x\": np.nan})\n        ds2 = xr.Dataset({\"x\": (\"y\", [np.nan, np.nan])})\n        actual = ds1.merge(ds2, fill_value=1)\n        expected = xr.Dataset({\"x\": (\"y\", [1, 1])})\n        assert expected.identical(actual)\n\n        ds1 = xr.Dataset({\"x\": 0})\n        ds2 = xr.Dataset({\"x\": (\"y\", [np.nan, np.nan])})\n        actual = ds1.merge(ds2, fill_value=1)\n        expected = xr.Dataset({\"x\": (\"y\", [0, 1])})\n        assert expected.identical(actual)\n\n        ds1 = xr.Dataset({\"x\": np.nan})\n        ds2 = xr.Dataset({\"x\": 0})\n        actual = ds1.merge(ds2, fill_value=1)\n        expected = xr.Dataset({\"x\": (\"y\", [1, 0])})\n        assert expected.identical(actual)\n"], "sample_970": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n        pass\n\n    func.register(int, lambda x: x + 1)\n    func.register(str, lambda x: x.upper())\n\n    assert inspect.is_singledispatch_function(func) is True\n    assert inspect.is_singledispatch_method(func) is False\n\n        pass\n\n    class MyClass:\n        @singledispatch\n            pass\n\n        @method.register\n            return x + 1\n\n        @method.register\n            return x.upper()\n\n    assert inspect.is_singledispatch_function(func) is True\n    assert inspect.is_singledispatch_method(method) is True\n    assert inspect.is_singledispatch_method(MyClass().method) is True\n"], "sample_150": ["    def test_base_command_init(self):\n        cmd = BaseCommand()\n        self.assertEqual(cmd.help, '')\n        self.assertFalse(cmd.output_transaction)\n        self.assertFalse(cmd.requires_migrations_checks)\n        self.assertTrue(cmd.requires_system_checks)\n        self.assertEqual(cmd.base_stealth_options, ('stderr', 'stdout'))\n        self.assertEqual(cmd.stealth_options, ())\n"], "sample_972": ["def test_stringify_type_hints_NewType():\n    MyInt = NewType('MyInt', int)\n    assert stringify(MyInt) == \"MyInt\"\n    assert stringify(MyInt, \"fully-qualified\") == \"MyInt\"\n    assert stringify(MyInt, \"smart\") == \"MyInt\"\n\n    assert stringify(NewType('MyInt', int)) == \"MyInt\"\n    assert stringify(NewType('MyInt', int), \"fully-qualified\") == \"MyInt\"\n    assert stringify(NewType('MyInt', int), \"smart\") == \"MyInt\"\n"], "sample_1105": ["def test_shape():\n    assert MatMul(A, B).shape == (n, l)\n    assert MatMul(C, D).shape == (n, n)\n    assert MatMul(C, A, B).shape == (n, l)\n    assert MatMul(C, A, D).shape == (n, n)\n    assert MatMul(C, A, B, D).shape == (n, l)\n"], "sample_916": ["def test_template_specialization():\n    check('function', 'template<> void f()', {2: 'IE1fv', 4: 'IE1fvv'})\n    check('function', 'template<> void f(int)', {2: 'IE1fv', 4: 'IE1fvv'})\n    check('function', 'template<> void f(int, int)', {2: 'IE1fv', 4: 'IE1fvv'})\n    check('function', 'template<> void f(int, int, int)', {2: 'IE1fv', 4: 'IE1fvv'})\n    check('function', 'template<> void f(int, int, int, int)', {2: 'IE1fv', 4: 'IE1fvv'})\n    check('function', 'template<> void f(int, int, int, int, int)', {2: 'IE1fv', 4: 'IE1fvv'})\n    check('function', 'template<> void f(int, int, int, int, int, int)', {2: 'IE1fv', 4: 'IE1fvv'})\n    check('function', 'template<> void f(int, int, int, int, int, int, int)', {2: 'IE1fv', 4: 'IE1fvv'})\n    check('function', 'template<> void f(int, int, int, int, int, int, int, int)', {2: 'IE1fv', 4: 'IE1fvv'})\n    check('function', 'template<> void f(int, int, int, int, int, int, int, int, int)', {2: 'IE1fv', 4: 'IE1fvv'})\n    check('function', 'template<> void f(int, int, int, int, int, int, int, int, int, int)', {2: 'IE1fv', 4: 'IE1fvv'})\n    check('function', 'template<> void f(int, int, int, int, int, int, int, int, int, int, int)', {2: 'IE1fv', 4: 'IE1fvv'})\n    check('function', 'template<> void f(int, int, int, int, int, int, int, int, int, int, int, int)', {2: 'IE1fv', 4: '"], "sample_320": ["def test_rename_field_with_unique_together(self):\n    \"\"\"\n    Tests the RenameField operation with a unique_together constraint.\n    \"\"\"\n    project_state = self.set_up_test_model(\"test_rnflut\", unique_together=True)\n    # Test the state alteration\n    operation = migrations.RenameField(\"Pony\", \"pink\", \"blue\")\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_rnflut\", new_state)\n    self.assertEqual(\n        len(\n            new_state.models[\"test_rnflut\", \"pony\"].options.get(\n                \"unique_together\", set()\n            )\n        ),\n        1,\n    )\n    # Make sure we can insert duplicate rows\n    with connection.cursor() as cursor:\n        cursor.execute(\"INSERT INTO test_rnflut_pony (pink, weight) VALUES (1, 1)\")\n        cursor.execute(\"INSERT INTO test_rnflut_pony (pink, weight) VALUES (1, 1)\")\n        cursor.execute(\"DELETE FROM test_rnflut_pony\")\n        # Test the database alteration\n        with connection.schema_editor() as editor:\n            operation.database_forwards(\n                \"test_rnflut\", editor, project_state, new_state\n            )\n        cursor.execute(\"INSERT INTO test_rnflut_pony (pink, weight) VALUES (1, 1)\")\n        with self.assertRaises(IntegrityError):\n            with atomic():\n                cursor.execute(\n                    \"INSERT INTO test_rnflut_pony (pink, weight) VALUES (1, 1)\"\n                )\n        cursor.execute(\"DELETE FROM test_rnflut_pony\")\n        # And test reversal\n        with connection.schema_editor() as editor:\n            operation.database_backwards(\n                \"test_rnflut\", editor, new_state, project_state\n            )\n        cursor.execute(\"INSERT INTO test_rnflut_pony (pink, weight) VALUES (1, 1)\")\n        cursor.execute(\"INSERT INTO test_rnflut_pony (pink, weight) VALUES (1, 1)\")\n        cursor.execute(\"DELETE FROM test_rnflut_pony\")\n"], "sample_1157": ["def test_issue_19502():\n    x = Symbol('x')\n    eq = parse_expr('E**(1+x)', local_dict={'x': x}, transformations=(\n        standard_transformations +\n        (implicit_multiplication_application,)))\n    assert eq.free_symbols == {x}\n"], "sample_947": ["def test_macro_definitions_with_args():\n    check('macro', 'M(a, b)', {1: 'M'})\n    check('macro', 'M(a, b, c)', {1: 'M'})\n    check('macro', 'M(a, b, c, d)', {1: 'M'})\n    check('macro', 'M(a, b, c, d, e)', {1: 'M'})\n    check('macro', 'M(a, b, c, d, e, f)', {1: 'M'})\n    check('macro', 'M(a, b, c, d, e, f, g)', {1: 'M'})\n    check('macro', 'M(a, b, c, d, e, f, g, h)', {1: 'M'})\n    check('macro', 'M(a, b, c, d, e, f, g, h, i)', {1: 'M'})\n    check('macro', 'M(a, b, c, d, e, f, g, h, i, j)', {1: 'M'})\n    check('macro', 'M(a, b, c, d, e, f, g, h, i, j, k)', {1: 'M'})\n    check('macro', 'M(a, b, c, d, e, f, g, h, i, j, k, l)', {1: 'M'})\n    check('macro', 'M(a, b, c, d, e, f, g, h, i, j, k, l, m)', {1: 'M'})\n    check('macro', 'M(a, b, c, d, e, f, g, h, i, j, k, l, m, n)', {1: 'M'})\n    check('macro', 'M(a, b, c, d, e, f, g, h, i, j, k, l, m, n, o)', {1: 'M'})\n    check('macro', 'M(a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p)', {1: 'M'})\n    check('macro', 'M(a, b, c, d, e, f, g, h, i, j, k, l, m, n, o,"], "sample_874": ["def test_clone():\n    \"\"\"Test that clone() returns a deep copy of the estimator.\"\"\"\n    sel = StepSelector(step=2)\n    sel_clone = clone(sel)\n    assert sel is not sel_clone\n    assert sel.get_params() == sel_clone.get_params()\n    assert sel_clone.get_params(deep=True) == sel.get_params(deep=True)\n    assert sel_clone._validate_data(X=np.array([[1, 2], [3, 4]])) is None\n    assert sel_clone._validate_data(X=np.array([[1, 2], [3, 4]]), y=np.array([0, 1])) is None\n    assert sel_clone._validate_params() is None\n    assert sel_clone._more_tags() == sel._more_tags()\n    assert sel_clone._get_tags() == sel._get_tags()\n    assert sel_clone._check_n_features(np.array([[1, 2], [3, 4]]), reset=True) is None\n    assert sel_clone._check_feature_names(np.array([[1, 2], [3, 4]]), reset=True) is None\n    assert sel_clone._validate_data(X=np.array([[1, 2], [3, 4]]), y=np.array([0, 1]), reset=False) is None\n    assert sel_clone._validate_params() is None\n    assert sel_clone._more_tags() == sel._more_tags()\n    assert sel_clone._get_tags() == sel._get_tags()\n    assert sel_clone._check_n_features(np.array([[1, 2], [3, 4]]), reset=False) is None\n    assert sel_clone._check_feature_names(np.array([[1, 2], [3, 4]]), reset=False) is None\n"], "sample_1005": ["def test_latex_Dict():\n    d = {x: 1, y: 2, z: 3}\n    assert latex(d) == r'\\left \\{ x : 1, \\quad y : 2, \\quad z : 3\\right \\}'\n    D = Dict(d)\n    assert latex(D) == r'\\left \\{ x : 1, \\quad y : 2, \\quad z : 3\\right \\}'\n"], "sample_1153": ["def test_issue_19627():\n    from sympy import Abs, Function\n    f = Function('f', positive=True)\n    assert Abs(f(x)**2) == f(x)**2\n"], "sample_924": ["def test_enum_definitions():\n    check('enum', '{key}A', {2: \"1A\"})\n    check('enum', '{key}A : std::underlying_type<B>::type', {2: \"1A\"})\n    check('enum', '{key}A : unsigned int', {2: \"1A\"})\n    check('enum', 'public A', {2: \"1A\"}, output='{key}A')\n    check('enum', 'private {key}A', {2: \"1A\"})\n\n    check('enumerator', '{key}A', {2: \"1A\"})\n    check('enumerator', '{key}A = std::numeric_limits<unsigned long>::max()', {2: \"1A\"})\n"], "sample_308": ["def test_dateformat_with_leap_year(self):\n    self.assertEqual(dateformat.format(datetime(2000, 2, 29), 'jS F Y'), '29th February 2000')\n"], "sample_232": ["    def test_key_transform_gt(self):\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__c__gt=2),\n            [self.objs[3], self.objs[4]],\n        )\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__c__gt=2.33),\n            [self.objs[3], self.objs[4]],\n        )\n        self.assertIs(NullableJSONModel.objects.filter(value__c__lt=5).exists(), False)\n"], "sample_610": ["def test_cftimeindex_shift_invalid_freq_type():\n    index = xr.cftime_range(\"2000\", periods=3)\n    with pytest.raises(TypeError):\n        index.shift(1, \"a\")\n"], "sample_455": ["    def setUpTestData(cls):\n        cls.p1 = UniqueConstraintProduct.objects.create(name=\"p1\", color=\"red\")\n        cls.p2 = UniqueConstraintProduct.objects.create(name=\"p2\")\n"], "sample_576": ["    def test_move_group_by_orient(self, long_df):\n\n        class MoveWithGroupByOrient(Move):\n            group_by_orient = True\n\n                self.orient_at_call = orient\n                return data\n\n        m = MockMark()\n        Plot(long_df, x=\"a\", y=\"z\").add(m, MoveWithGroupByOrient()).plot()\n\n        assert m.passed_orient == \"x\"\n        assert m.passed_data[0][\"x\"] == long_df[\"a\"]\n"], "sample_724": ["def test_imputation_axis_error():\n    # Test that an error is raised when axis is not 0 or 1.\n    imputer = Imputer(strategy=\"mean\")\n    assert_raises(ValueError, imputer.fit, np.array([[1, 2], [3, 4]]), axis=2)\n"], "sample_242": ["    def test_get_bound_params_subclasses(self):\n        year_exact = YearExact(\n            lhs=Value(datetime(2010, 1, 1, 0, 0, 0), output_field=DateTimeField()),\n            rhs=Value(datetime(2010, 1, 1, 23, 59, 59), output_field=DateTimeField()),\n        )\n        year_gt = YearGt(\n            lhs=Value(datetime(2010, 1, 1, 0, 0, 0), output_field=DateTimeField()),\n            rhs=Value(datetime(2010, 1, 1, 23, 59, 59), output_field=DateTimeField()),\n        )\n        year_gte = YearGte(\n            lhs=Value(datetime(2010, 1, 1, 0, 0, 0), output_field=DateTimeField()),\n            rhs=Value(datetime(2010, 1, 1, 23, 59, 59), output_field=DateTimeField()),\n        )\n        year_lt = YearLt(\n            lhs=Value(datetime(2010, 1, 1, 0, 0, 0), output_field=DateTimeField()),\n            rhs=Value(datetime(2010, 1, 1, 23, 59, 59), output_field=DateTimeField()),\n        )\n        year_lte = YearLte(\n            lhs=Value(datetime(2010, 1, 1, 0, 0, 0), output_field=DateTimeField()),\n            rhs=Value(datetime(2010, 1, 1, 23, 59, 59), output_field=DateTimeField()),\n        )\n\n        self.assertEqual(year_exact.get_bound_params(datetime(2010, 1, 1, 0, 0, 0), datetime(2010, 1, 1, 23, 59, 59)), (datetime(2010, 1, 1, 0, 0, 0), datetime(2010, 1, 1, 23, 59, 59)))\n        self.assertEqual(year_gt.get_bound_params(datetime(2010, 1, 1, 0, 0, 0), datetime(2010, 1, 1, 23, 59, 59)), (datetime(2010, 1, 1, 23"], "sample_842": ["def test_kernel_clone_after_set_params_with_nested_kernel():\n    # This test is to verify that using set_params does not\n    # break clone on kernels with nested kernels.\n    # This used to break because in kernels such as the RBF, non-trivial\n    # logic that modified the length scale used to be in the constructor\n    # See https://github.com/scikit-learn/scikit-learn/issues/6961\n    # for more details.\n    kernel = 2.0 * RBF(0.5) + 3.0 * RBF(2.0)\n    kernel_cloned = clone(kernel)\n    params = kernel.get_params()\n    kernel_cloned.set_params(**params)\n    kernel_cloned_clone = clone(kernel_cloned)\n    assert (kernel_cloned_clone.get_params() ==\n                     kernel_cloned.get_params())\n    assert id(kernel_cloned_clone) != id(kernel_cloned)\n    check_hyperparameters_equal(kernel_cloned, kernel_cloned_clone)\n"], "sample_1026": ["def test_lambdify_DotProduct():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    A = Matrix([x, y, z])\n    f = lambdify([x, y, z], DotProduct(A, A), modules='numpy')\n    assert f(1, 2, 3) == numpy.array([14])\n    f = lambdify([x, y, z], DotProduct(A, A.T), modules='numpy')\n    assert f(1, 2, 3) == numpy.array([14])\n    f = lambdify([x, y, z], DotProduct(A.T, A), modules='numpy')\n    assert f(1, 2, 3) == numpy.array([14])\n"], "sample_153": ["    def test_check_swappable(self):\n        class SwappableModel(Model):\n            class Meta:\n                swappable = 'app_label.app_name'\n\n        with self.assertRaises(ValueError):\n            check_database_backends(databases=self.databases)\n\n        class ValidSwappableModel(Model):\n            class Meta:\n                swappable = 'app_label.app_name'\n\n        check_database_backends(databases=self.databases)\n\n        class InvalidSwappableModel(Model):\n            class Meta:\n                swappable = 'invalid_swappable'\n\n        with self.assertRaises(LookupError):\n            check_database_backends(databases=self.databases)\n\n        class NonExistentModel(Model):\n            class Meta:\n                swappable = 'non_existent_app_label.non_existent_app_name'\n\n        with self.assertRaises(LookupError):\n            check_database_backends(databases=self.databases)\n"], "sample_1056": ["def test_complex():\n    # In each case, test eval() the lambdarepr() to make sure there are a\n    # correct number of parentheses. It will give a SyntaxError if there aren't.\n\n    h = \"lambda x: \"\n\n    z = 2 + 3j\n    l = lambdarepr(z)\n    eval(h + l)\n    assert l == \"(2 + 3j)\"\n\n    z = 2 - 3j\n    l = lambdarepr(z)\n    eval(h + l)\n    assert l == \"(2 - 3j)\"\n\n    z = 2 + 3j\n    l = lambdarepr(z)\n    eval(h + l)\n    assert l == \"(2 + 3j)\"\n\n    z = 2 - 3j\n    l = lambdarepr(z)\n    eval(h + l)\n    assert l == \"(2 - 3j)\"\n\n    z = 2 + 3j\n    l = lambdarepr(z)\n    eval(h + l)\n    assert l == \"(2 + 3j)\"\n\n    z = 2 - 3j\n    l = lambdarepr(z)\n    eval(h + l)\n    assert l == \"(2 - 3j)\"\n\n    z = 2 + 3j\n    l = lambdarepr(z)\n    eval(h + l)\n    assert l == \"(2 + 3j)\"\n\n    z = 2 - 3j\n    l = lambdarepr(z)\n    eval(h + l)\n    assert l == \"(2 - 3j)\"\n\n    z = 2 + 3j\n    l = lambdarepr(z)\n    eval(h + l)\n    assert l == \"(2 + 3j)\"\n\n    z = 2 - 3j\n    l = lambdarepr(z)\n    eval(h + l)\n    assert l == \"(2 - 3j)\"\n\n    z = 2 + 3j\n    l = lambdarepr(z)\n    eval(h + l)\n    assert l == \"(2 + 3j)\"\n\n    z = 2 - 3j\n    l = lambdarepr(z)\n    eval(h + l)\n    assert l == \"(2 - 3j)\"\n\n    z = 2 + 3j\n    l = lambdarepr(z)\n    eval(h + l)\n"], "sample_1076": ["def test_SymPyPrinter():\n    p = SymPyPrinter()\n    assert p.doprint(acos(x)) == 'sympy.acos(x)'\n    assert p.doprint(Assignment(x, 2)) == 'x = 2'\n    assert p.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert p.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert p.doprint(sign(x)) == '(0.0 if x == 0 else sympy.copysign(1, x))'\n    assert p.doprint(p[0, 1]) == 'p[0, 1]'\n"], "sample_1057": ["def test_render_as_module_with_imports():\n    ast = Print('x y'.split(), \"coordinate: %12.5g %12.5g\")\n    assert render_as_module(ast, standard='python3') == \\\n        '\\n\\nimport sympy\\n\\nprint(\"coordinate: %12.5g %12.5g\" % (x, y))'\n    assert render_as_module(ast, standard='python2') == \\\n        '\\n\\nimport sympy\\n\\nprint \"coordinate: %12.5g %12.5g\" % (x, y)'\n"], "sample_196": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_1106": ["def test_matadd_scalar_Matrix_doit():\n    # Issue 9053\n    X = Matrix([[1, 2], [3, 4]])\n    assert MatAdd(2, X).doit() == 2 + X\n"], "sample_1088": ["def test_symmetrize_formal():\n    x, y, z = symbols('x,y,z')\n    U = [u0, u1, u2, u3] = symbols('u:4')\n\n    assert symmetrize(x + y + z, x, y, z, formal=True, symbols=U) == \\\n        (u0, -y - z, [(u0, x + y + z), (u1, x*y + x*z + y*z), (u2, x*y*z), (u3, 0)])\n\n    assert symmetrize(x + y + z, x, y, z, formal=True, symbols=U, symbols=['a', 'b', 'c']) == \\\n        (u0, -y - z, [(u0, x + y + z), (u1, x*y + x*z + y*z), (u2, x*y*z), (u3, 0)])\n\n    assert symmetrize(x + y + z, x, y, z, formal=True, symbols=['a', 'b', 'c']) == \\\n        (u0, -y - z, [(u0, x + y + z), (u1, x*y + x*z + y*z), (u2, x*y*z), (u3, 0)])\n\n    assert symmetrize(x + y + z, x, y, z, formal=True, symbols=['a', 'b', 'c'], symbols=['d', 'e', 'f']) == \\\n        (u0, -y - z, [(u0, x + y + z), (u1, x*y + x*z + y*z), (u2, x*y*z), (u3, 0)])\n\n    assert symmetrize(x + y + z, x, y, z, formal=True, symbols=['a', 'b', 'c'], symbols=['d', 'e', 'f'], symbols=['g', 'h', 'i']) == \\\n        (u0, -y - z, [(u0, x + y + z), (u1, x*y + x*z + y*z), (u2, x*y*z), (u3, 0)])\n\n    assert symmetrize(x + y + z, x, y, z, formal=True, symbols=['a', 'b', 'c'],"], "sample_1068": ["def test_MatrixSlice():\n    A = Matrix([[1, 2, 3], [4, 5, 6]])\n    assert mcode(A[1:2, 1:3]) == \"[4 5]\"\n    assert mcode(A[:, 1:3]) == \"[2 3; 5 6]\"\n    assert mcode(A[1:, 1:]) == \"[4 5; 5 6]\"\n    assert mcode(A[1:2, 1]) == \"[5]\"\n    assert mcode(A[1, 1:]) == \"[5 6]\"\n    assert mcode(A[1:2, 1:2]) == \"[5]\"\n    assert mcode(A[1:2, 1:2, 1]) == \"[5]\"\n    assert mcode(A[1:2, 1:2, 1:2]) == \"[5]\"\n    assert mcode(A[1:2, 1:2, 1:2, 1]) == \"[5]\"\n    assert mcode(A[1:2, 1:2, 1:2, 1:2]) == \"[5]\"\n    assert mcode(A[1:2, 1:2, 1:2, 1:2, 1]) == \"[5]\"\n    assert mcode(A[1:2, 1:2, 1:2, 1:2, 1:2]) == \"[5]\"\n    assert mcode(A[1:2, 1:2, 1:2, 1:2, 1:2, 1]) == \"[5]\"\n    assert mcode(A[1:2, 1:2, 1:2, 1:2, 1:2, 1:2]) == \"[5]\"\n    assert mcode(A[1:2, 1:2, 1:2, 1:2, 1:2, 1:2, 1]) == \"[5]\"\n    assert mcode(A[1:2, 1:2, 1:2, 1:2, 1:2, 1:2, 1:2]) == \"[5]\"\n"], "sample_973": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n        pass\n\n    singledispatch(func)(int)(lambda x: x)\n\n    assert inspect.is_singledispatch_function(func)\n    assert not inspect.is_singledispatch_function(singledispatch(func))\n"], "sample_1154": ["def test__linsolve_complex():\n    # Test with complex coefficients\n    eqs = [\n        Eq(x + 2*I*y, 1),\n        Eq(x - 2*I*y, 2)\n    ]\n    sol = {x: 3/2, y: -1/2}\n    assert _linsolve(eqs, [x, y]) == sol\n\n    # Test with complex coefficients and complex solutions\n    eqs = [\n        Eq(x + 2*I*y, 1 + 2*I),\n        Eq(x - 2*I*y, 2 - 2*I)\n    ]\n    sol = {x: 3/2 + I, y: -1/2 - I}\n    assert _linsolve(eqs, [x, y]) == sol\n\n    # Test with complex coefficients and real solutions\n    eqs = [\n        Eq(x + 2*I*y, 1),\n        Eq(x - 2*I*y, 2)\n    ]\n    sol = {x: 3/2, y: -1/2}\n    assert _linsolve(eqs, [x, y]) == sol\n\n    # Test with complex coefficients and no solution\n    eqs = [\n        Eq(x + 2*I*y, 1),\n        Eq(x + 2*I*y, 2)\n    ]\n    assert _linsolve(eqs, [x, y]) is None\n\n    # Test with complex coefficients and underdetermined system\n    eqs = [\n        Eq(x + 2*I*y, 0)\n    ]\n    sol = {x: -2*I*y}\n    assert _linsolve(eqs, [x, y]) == sol\n\n    # Test with complex coefficients and nonlinear terms\n    eqs = [\n        Eq(x**2 + 2*I*y, 1),\n        Eq(x + 2*I*y, 2)\n    ]\n    raises(PolyNonlinearError, lambda: _linsolve(eqs, [x, y]))\n"], "sample_1119": ["def test_inverse_block_diagonal():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    D = MatrixSymbol('D', 2, 2)\n    E = MatrixSymbol('E', 2, 2)\n    F = MatrixSymbol('F', 2, 2)\n    G = MatrixSymbol('G', 2, 2)\n    H = MatrixSymbol('H', 2, 2)\n\n    assert Inverse(BlockMatrix([[A, B], [C, D])).args == (BlockMatrix([[A, B], [C, D]]), S.NegativeOne)\n    assert Inverse(BlockMatrix([[A, B], [C, D]])).shape == (4, 4)\n    assert Inverse(BlockMatrix([[A, B], [C, D]])).inverse() == BlockMatrix([[A, B], [C, D]])\n    assert Inverse(BlockMatrix([[A, B], [C, D]])).doit(inv_expand=False) == BlockMatrix([[A, B], [C, D]])\n\n    assert Inverse(BlockMatrix([[A, B, C], [D, E, F], [G, H, ZeroMatrix(2, 2)])).args == (BlockMatrix([[A, B, C], [D, E, F], [G, H, ZeroMatrix(2, 2)]), S.NegativeOne)\n    assert Inverse(BlockMatrix([[A, B, C], [D, E, F], [G, H, ZeroMatrix(2, 2)])).shape == (4, 4)\n    assert Inverse(BlockMatrix([[A, B, C], [D, E, F], [G, H, ZeroMatrix(2, 2)])).inverse() == BlockMatrix([[A, B, C], [D, E, F], [G, H, ZeroMatrix(2, 2)])\n    assert Inverse(BlockMatrix([[A, B, C], [D, E, F], [G, H, ZeroMatrix(2, 2)])).doit(inv_expand=False) == BlockMatrix([[A, B, C], [D, E, F], [G, H, ZeroMatrix(2, 2)])\n\n    assert Inverse(BlockMatrix([[A, B"], "sample_1036": ["def test_as_two_terms():\n    assert Mul(2, 3, 4).as_two_terms() == (12, 4)\n    assert Mul(2, 3, 4, 5).as_two_terms() == (60, 4*5)\n    assert Mul(2, 3, 4, 5, 6).as_two_terms() == (360, 4*5*6)\n    assert Mul(2, 3, 4, 5, 6, 7).as_two_terms() == (2520, 4*5*6*7)\n    assert Mul(2, 3, 4, 5, 6, 7, 8).as_two_terms() == (20160, 4*5*6*7*8)\n    assert Mul(2, 3, 4, 5, 6, 7, 8, 9).as_two_terms() == (181440, 4*5*6*7*8*9)\n"], "sample_927": ["def test_enum_definitions():\n    check('enum', '{key}A', {2: \"1A\"})\n    check('enum', '{key}A : std::underlying_type<B>::type', {2: \"1A\"})\n    check('enum', '{key}A : unsigned int', {2: \"1A\"})\n    check('enum', 'public A', {2: \"1A\"}, output='{key}A')\n    check('enum', 'private {key}A', {2: \"1A\"})\n\n    check('enumerator', '{key}A', {2: \"1A\"})\n    check('enumerator', '{key}A = std::numeric_limits<unsigned long>::max()', {2: \"1A\"})\n"], "sample_588": ["    def test_concat_dims_not_in_order(self, create_combined_ids):\n        shape = (2, 3)\n        combined_ids = create_combined_ids(shape)\n        result = _combine_nd(combined_ids, concat_dims=[\"dim2\", \"dim1\"])\n\n        ds = create_test_data\n        partway1 = concat([ds(0), ds(3)], dim=\"dim1\")\n        partway2 = concat([ds(1), ds(4)], dim=\"dim1\")\n        partway3 = concat([ds(2), ds(5)], dim=\"dim1\")\n        expected_datasets = [partway1, partway2, partway3]\n        expected = concat([partway1, partway2, partway3], dim=\"dim2\")\n\n        assert_equal(result, expected)\n"], "sample_430": ["def test_add_field_with_default_and_db_default(self):\n    \"\"\"#22030 - Adding a field with a default and a db_default should work.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_name_db_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=\"Ada Lovelace\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, db_default=models.Value(\"Ada Lovelace\"))\n"], "sample_959": ["def test_domain_cpp_ast_enum_definitions():\n    check('enum', '{key}A', {2: \"1A\"})\n    check('enum', '{key}A : std::underlying_type<B>::type', {2: \"1A\"})\n    check('enum', '{key}A : unsigned int', {2: \"1A\"})\n    check('enum', 'public A', {2: \"1A\"}, output='{key}A')\n    check('enum', 'private {key}A', {2: \"1A\"})\n\n    check('enumerator', '{key}A', {2: \"1A\"})\n    check('enumerator', '{key}A = std::numeric_limits<unsigned long>::max()', {2: \"1A\"})\n"], "sample_1118": ["def test_matpow():\n    A = MatrixSymbol('A', 3, 3)\n    B = MatrixSymbol('B', 3, 3)\n    assert MatPow(A, 0).shape == (3, 3)\n    assert MatPow(A, 1).shape == (3, 3)\n    assert MatPow(A, -1).shape == (3, 3)\n    assert MatPow(A, S.Half).shape == (3, 3)\n    assert MatPow(A, S.Half).args == (A, S.Half)\n    assert MatPow(A, S.Half).doit() == MatMul(*[A for i in range(2)])\n    assert MatPow(A, -S.Half).args == (A, -S.Half)\n    assert MatPow(A, -S.Half).doit() == MatMul(*[Inverse(A) for i in range(2)])\n    assert MatPow(A, 0).doit() == Identity(3)\n    assert MatPow(A, 1).doit() == A\n    assert MatPow(A, -1).doit() == Inverse(A)\n    assert MatPow(A, S.Half).doit() == MatMul(*[A for i in range(2)])\n    assert MatPow(A, -S.Half).doit() == MatMul(*[Inverse(A) for i in range(2)])\n    assert MatPow(A, S.Half).doit(deep=False) == MatPow(A, S.Half)\n    assert MatPow(A, -S.Half).doit(deep=False) == MatPow(A, -S.Half)\n    assert MatPow(A, 0).doit(deep=False) == MatPow(A, 0)\n    assert MatPow(A, 1).doit(deep=False) == MatPow(A, 1)\n    assert MatPow(A, -1).doit(deep=False) == MatPow(A, -1)\n    assert MatPow(A, S.Half).doit(inv_expand=False) == MatPow(A, S.Half)\n    assert MatPow(A, -S.Half).doit(inv_expand=False) == MatPow(A, -S.Half)\n    assert MatPow(A, 0).doit(inv_expand=False) == MatPow(A, 0)\n    assert MatPow(A, 1).doit(inv"], "sample_969": ["def test_stringify_type_hints_Callable_with_defaults():\n    assert stringify(Callable[[str], int, dict], False) == \"Callable[[str], int, dict]\"\n    assert stringify(Callable[[str], int, dict], True) == \"~typing.Callable[[str], int, dict]\"\n\n    if sys.version_info >= (3, 7):\n        assert stringify(Callable[..., int, dict], False) == \"Callable[[...], int, dict]\"\n        assert stringify(Callable[..., int, dict], True) == \"~typing.Callable[[...], int, dict]\"\n    else:\n        assert stringify(Callable[..., int, dict], False) == \"Callable[..., int, dict]\"\n        assert stringify(Callable[..., int, dict], True) == \"~typing.Callable[..., int, dict]\"\n"], "sample_1141": ["def test_issue_21196():\n    t = symbols('t')\n    x = Function('x')(t)\n    dx = x.diff(t)\n    exp1 = cos(x) + cos(x)*dx\n    exp2 = sin(x) + tan(x)*(dx.diff(t))\n    exp3 = sin(x)*sin(t)*(dx.diff(t)).diff(t)\n    A = Matrix([[exp1], [exp2], [exp3]])\n    B = Matrix([[exp1.diff(x)], [exp2.diff(x)], [exp3.diff(x)]])\n    assert A.diff(x) == B\n"], "sample_1174": ["def test_issue_19627():\n    from sympy import Abs, Function\n    f = Function('f', positive=True)\n    assert Abs(f(x)) == f(x)\n    assert Abs(f(x)**2) == f(x)**2\n    assert Abs(f(x)*f(x)) == f(x)*f(x)\n    assert Abs(f(x)/f(x)) == 1\n    assert Abs(f(x) + f(x)) == f(x) + f(x)\n    assert Abs(f(x) - f(x)) == 0\n    assert Abs(f(x) + 1) == f(x) + 1\n    assert Abs(f(x) - 1) == f(x) - 1\n    assert Abs(f(x) + f(x) + 1) == f(x) + f(x) + 1\n    assert Abs(f(x) - f(x) + 1) == 1\n    assert Abs(f(x) + f(x) - 1) == f(x) + f(x) - 1\n    assert Abs(f(x) - f(x) - 1) == f(x) - f(x) - 1\n"], "sample_133": ["    def test_json_catalog(self):\n        \"\"\"The json_catalog returns the language catalog and settings as JSON.\"\"\"\n        with override('de'):\n            response = self.client.get('/jsoni18n/')\n            data = json.loads(response.content.decode())\n            self.assertIn('catalog', data)\n            self.assertIn('formats', data)\n            self.assertEqual(data['formats']['TIME_INPUT_FORMATS'], ['%H:%M:%S', '%H:%M:%S.%f', '%H:%M'])\n            self.assertEqual(data['formats']['FIRST_DAY_OF_WEEK'], 0)\n            self.assertIn('plural', data)\n            self.assertEqual(data['catalog']['month name\\x04May'], 'Mai')\n            self.assertIn('DATETIME_FORMAT', data['formats'])\n            self.assertEqual(data['plural'], '(n != 1)')\n"], "sample_1058": ["def test_SciPyPrinter_print_SparseMatrix():\n    p = SciPyPrinter()\n    smat = SparseMatrix(2, 5, {(0, 1): 3})\n    assert p.doprint(smat) == 'scipy.sparse.coo_matrix([3], ([0], [1]), shape=(2, 5))'\n    assert 'scipy.sparse' in p.module_imports\n"], "sample_828": ["def test_pairwise_distances_argmin_min_callable():\n    # Check pairwise minimum distances computation for any metric\n    X = [[0], [1]]\n    Y = [[-2], [3]]\n\n    Xsp = dok_matrix(X)\n    Ysp = csr_matrix(Y, dtype=np.float32)\n\n    expected_idx = [0, 1]\n    expected_vals = [2, 2]\n    expected_vals_sq = [4, 4]\n\n    # euclidean metric\n    idx, vals = pairwise_distances_argmin_min(X, Y, metric=\"euclidean\")\n    idx2 = pairwise_distances_argmin(X, Y, metric=\"euclidean\")\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(idx2, expected_idx)\n    assert_array_almost_equal(vals, expected_vals)\n    # sparse matrix case\n    idxsp, valssp = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"euclidean\")\n    assert_array_almost_equal(idxsp, expected_idx)\n    assert_array_almost_equal(valssp, expected_vals)\n    # We don't want np.matrix here\n    assert_equal(type(idxsp), np.ndarray)\n    assert_equal(type(valssp), np.ndarray)\n\n    # euclidean metric squared\n    idx, vals = pairwise_distances_argmin_min(X, Y, metric=\"euclidean\",\n                                              metric_kwargs={\"squared\": True})\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(vals, expected_vals_sq)\n\n    # Non-euclidean scikit-learn metric\n    idx, vals = pairwise_distances_argmin_min(X, Y, metric=\"manhattan\")\n    idx2 = pairwise_distances_argmin(X, Y, metric=\"manhattan\")\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(idx2, expected_idx)\n    assert_array_almost_equal(vals, expected_vals)\n    # sparse matrix case\n    idxsp, valssp = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"manhattan\")\n    assert_array_almost_equal(idxsp, expected_idx)\n    assert_array_almost_equal(valssp, expected_vals)\n\n    # Non-euclidean Scipy distance (callable)\n    idx, vals = pairwise_distances_argmin_min(X, Y, metric=minkowski,\n                                              metric_kwargs={\"p\": 2})\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(vals, expected_vals)\n\n    # Non-euclidean Scipy distance (string"], "sample_827": ["def test_incr_mean_variance_axis_ignore_nan():\n    for axis in [0, 1]:\n        rng = np.random.RandomState(0)\n        n_features = 50\n        n_samples = 10\n        data_chunks = [rng.randint(0, 2, size=n_features)\n                       for i in range(n_samples)]\n\n        # default params for incr_mean_variance\n        last_mean = np.zeros(n_features)\n        last_var = np.zeros_like(last_mean)\n        last_n = np.zeros_like(last_mean, dtype=np.int64)\n\n        # Test errors\n        X = np.array(data_chunks[0])\n        X = np.atleast_2d(X)\n        X_lil = sp.lil_matrix(X)\n        X_csr = sp.csr_matrix(X_lil)\n        assert_raises(TypeError, incr_mean_variance_axis, axis,\n                      last_mean, last_var, last_n)\n        assert_raises(TypeError, incr_mean_variance_axis, axis,\n                      last_mean, last_var, last_n)\n        assert_raises(TypeError, incr_mean_variance_axis, X_lil, axis,\n                      last_mean, last_var, last_n)\n\n        # Test _incr_mean_and_var with a 1 row input\n        X_means, X_vars = mean_variance_axis(X_csr, axis)\n        X_means_incr, X_vars_incr, n_incr = \\\n            incr_mean_variance_axis(X_csr, axis, last_mean, last_var, last_n,\n                                   ignore_nan=True)\n        assert_array_almost_equal(X_means, X_means_incr)\n        assert_array_almost_equal(X_vars, X_vars_incr)\n        assert_equal(X.shape[axis], n_incr)  # X.shape[axis] picks # samples\n\n        X_csc = sp.csc_matrix(X_lil)\n        X_means, X_vars = mean_variance_axis(X_csc, axis)\n        assert_array_almost_equal(X_means, X_means_incr)\n        assert_array_almost_equal(X_vars, X_vars_incr)\n        assert_equal(X.shape[axis], n_incr)\n\n        # Test _incremental_mean_and_var with whole data\n        X = np.vstack(data_chunks)\n        X_lil = sp.lil_matrix(X)\n        X_csr = sp.csr_matrix(X_lil)\n        X_csc = sp.csc_matrix(X_lil)\n\n        expected_dtypes = [(np.float32, np.float32),\n                           (np.float64, np.float64),\n                           (np.int"], "sample_154": ["def test_database_checks_called_with_kwargs(self, mocked_check):\n    check_database_backends(databases=self.databases, enforce_no_triggers=True)\n    self.assertTrue(mocked_check.called)\n    self.assertEqual(mocked_check.call_args_list, [\n        mock.call(enforce_no_triggers=True)\n    ])\n"], "sample_319": ["def test_alter_field_to_foreign_key(self):\n    \"\"\"Tests autodetection of field type changes from a concrete field to a ForeignKey.\"\"\"\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author],\n        [self.author_empty, self.book_with_author],\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(\n        changes, \"otherapp\", 0, 0, model_name=\"book\", name=\"author\"\n    )\n    self.assertEqual(\n        changes[\"otherapp\"][0].operations[0].field.deconstruct(),\n        (\n            \"author\",\n            \"django.db.models.ForeignKey\",\n            [],\n            {\"to\": \"testapp.Author\", \"on_delete\": models.CASCADE},\n        ),\n    )\n"], "sample_415": ["    def setUpTestData(cls):\n        cls.p1 = UniqueConstraintProduct.objects.create(name=\"p1\", color=\"red\")\n        cls.p2 = UniqueConstraintProduct.objects.create(name=\"p2\")\n"], "sample_826": ["def test_one_hot_encoder_handle_unknown_strings_dtype():\n    X = np.array(['11111111', '22', '333', '4444']).reshape((-1, 1))\n    X2 = np.array(['55555', '22']).reshape((-1, 1))\n    # Non Regression test for the issue #12470\n    # Test the ignore option, when categories are numpy string dtype\n    # particularly when the known category strings are larger\n    # than the unknown category strings\n    oh = OneHotEncoder(handle_unknown='ignore')\n    oh.fit(X)\n    X2_passed = X2.copy()\n    assert_array_equal(\n        oh.transform(X2_passed).toarray(),\n        np.array([[0.,  0.,  0.,  0.], [0.,  1.,  0.,  0.]]))\n    # ensure transformed data was not modified in place\n    assert_array_equal(X2, X2_passed)\n    # check that the dtype of the categories is preserved\n    assert oh.categories_[0].dtype == np.dtype('S5')\n"], "sample_781": ["def check_min_impurity_decrease(name):\n    # Test if min_impurity_decrease of base estimators is set\n    # Regression test for #8006\n    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)\n    all_estimators = [RandomForestClassifier, RandomForestRegressor,\n                      ExtraTreesClassifier, ExtraTreesRegressor]\n\n    for Estimator in all_estimators:\n        est = Estimator(min_impurity_decrease=0.1)\n        est = assert_warns_message(DeprecationWarning, \"min_impurity_split\",\n                                   est.fit, X, y)\n        for tree in est.estimators_:\n            assert_equal(tree.min_impurity_decrease, 0.1)\n\n"], "sample_195": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_1152": ["def test_powsimp_issue_12345():\n    x, y, z = symbols('x y z')\n    assert powsimp((x**y)**z) == x**(y*z)\n    assert powsimp((x**y)**z, combine='exp') == x**(y*z)\n    assert powsimp((x**y)**z, combine='base') == (x**y)**z\n    assert powsimp((x**y)**z, deep=True) == x**(y*z)\n    assert powsimp((x**y)**z, deep=True, combine='exp') == x**(y*z)\n    assert powsimp((x**y)**z, deep=True, combine='base') == (x**y)**z\n    assert powsimp((x**y)**z, deep=True, force=True) == x**(y*z)\n    assert powsimp((x**y)**z, deep=True, combine='exp', force=True) == x**(y*z)\n    assert powsimp((x**y)**z, deep=True, combine='base', force=True) == (x**y)**z\n"], "sample_934": ["def test_macro_definitions():\n    check('macro', 'void f()', {1: \"f\", 2: \"1f\"})\n    check('macro', 'void f(int)', {1: \"f__i\", 2: \"1fKj\"})\n    check('macro', 'void f(int, int)', {1: \"f__i.i\", 2: \"1fKjKj\"})\n    check('macro', 'void f(int, int, int)', {1: \"f__i.i.i\", 2: \"1fKjKjKj\"})\n    check('macro', 'void f(int, int, int, int)', {1: \"f__i.i.i.i\", 2: \"1fKjKjKjKj\"})\n    check('macro', 'void f(int, int, int, int, int)', {1: \"f__i.i.i.i.i\", 2: \"1fKjKjKjKjKj\"})\n    check('macro', 'void f(int, int, int, int, int, int)', {1: \"f__i.i.i.i.i.i\", 2: \"1fKjKjKjKjKjKj\"})\n    check('macro', 'void f(int, int, int, int, int, int, int)', {1: \"f__i.i.i.i.i.i.i\", 2: \"1fKjKjKjKjKjKjKj\"})\n    check('macro', 'void f(int, int, int, int, int, int, int, int)', {1: \"f__i.i.i.i.i.i.i.i\", 2: \"1fKjKjKjKjKjKjKjKj\"})\n    check('macro', 'void f(int, int, int, int, int, int, int, int, int)', {1: \"f__i.i.i.i.i.i.i.i.i\", 2: \"1fKjKjKjKjKjKjKjKjKj\"})\n    check('macro', 'void f(int, int, int, int, int, int, int, int, int, int)', {1: \"f__i.i.i.i.i.i.i.i.i.i\", 2: \"1fKjKjKjKj"], "sample_132": ["    def test_non_sensitive_request(self):\n        \"\"\"\n        Request info can bee seen in the default error reports for non-sensitive requests.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n\n        with self.settings(DEBUG=False):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n"], "sample_731": ["def test_fetch_california_housing_data_home():\n    data_home = 'test_data_home'\n    try:\n        fetch_california_housing(data_home=data_home)\n    except IOError:\n        raise SkipTest(\"California housing dataset can not be loaded to custom data_home.\")\n    assert exists(data_home)\n    assert exists(_pkl_filepath(data_home, 'cal_housing.pkz'))\n"], "sample_603": ["def test_repr_of_dataset_with_attrs():\n    ds = xr.Dataset({\"x\": (\"y\", [1, 2, 3])}, attrs={\"foo\": \"bar\"})\n    formatted = fh.dataset_repr(ds)\n    assert \"foo\" in formatted\n    assert \"bar\" in formatted\n    assert \"<dt><span>foo :</span></dt>\" in formatted\n    assert \"<dd>bar</dd>\" in formatted\n\n    with xr.set_options(display_expand_attrs=False):\n        formatted = fh.dataset_repr(ds)\n        assert \"foo\" not in formatted\n        assert \"bar\" not in formatted\n        assert \"<dt><span>foo :</span></dt>\" not in formatted\n        assert \"<dd>bar</dd>\" not in formatted\n"], "sample_935": ["def test_enum_definitions():\n    check('enum', '{key}A', {2: \"1A\"})\n    check('enum', '{key}A : std::underlying_type<B>::type', {2: \"1A\"})\n    check('enum', '{key}A : unsigned int', {2: \"1A\"})\n    check('enum', 'public A', {2: \"1A\"}, output='{key}A')\n    check('enum', 'private {key}A', {2: \"1A\"})\n\n    check('enumerator', '{key}A', {2: \"1A\"})\n    check('enumerator', '{key}A = std::numeric_limits<unsigned long>::max()', {2: \"1A\"})\n"], "sample_923": ["def test_attribute_parsing():\n    check('member', 'int [[attr1]] f', {1: 'f__i', 2: '1f'})\n    check('member', 'int [[attr1, attr2]] f', {1: 'f__i', 2: '1f'})\n    check('member', 'int [[attr1, attr2, attr3]] f', {1: 'f__i', 2: '1f'})\n    check('member', 'int [[attr1, attr2, attr3, attr4]] f', {1: 'f__i', 2: '1f'})\n    check('member', 'int [[attr1, attr2, attr3, attr4, attr5]] f', {1: 'f__i', 2: '1f'})\n    check('member', 'int [[attr1, attr2, attr3, attr4, attr5, attr6]] f', {1: 'f__i', 2: '1f'})\n    check('member', 'int [[attr1, attr2, attr3, attr4, attr5, attr6, attr7]] f', {1: 'f__i', 2: '1f'})\n    check('member', 'int [[attr1, attr2, attr3, attr4, attr5, attr6, attr7, attr8]] f', {1: 'f__i', 2: '1f'})\n    check('member', 'int [[attr1, attr2, attr3, attr4, attr5, attr6, attr7, attr8, attr9]] f', {1: 'f__i', 2: '1f'})\n    check('member', 'int [[attr1, attr2, attr3, attr4, attr5, attr6, attr7, attr8, attr9, attr10]] f', {1: 'f__i', 2: '1f'})\n    check('member', 'int [[attr1, attr2, attr3, attr4, attr5, attr6, attr7, attr8, attr9, attr10, attr11]] f', {1: 'f__i', 2: '1f'})\n    check('member', 'int [[attr1, attr2, attr3, attr4, attr5, attr6, attr7, attr"], "sample_302": ["def test_settings_to_cmd_args_env_with_options(self):\n    settings_dict = {\n        'OPTIONS': {\n            'host': 'localhost',\n            'port': 5432,\n            'sslmode': 'require',\n            'sslrootcert': '/path/to/sslrootcert',\n            'sslcert': '/path/to/sslcert',\n            'sslkey': '/path/to/sslkey',\n            'passfile': '/path/to/passfile',\n            'service': 'my_service',\n        },\n        'NAME': 'my_database',\n        'USER': 'my_user',\n        'PASSWORD': 'my_password',\n        'HOST': 'localhost',\n        'PORT': 5432,\n    }\n    parameters = ['--option1', '--option2']\n    expected_args = [\n        'psql',\n        '-h', 'localhost',\n        '-p', '5432',\n        '-U', 'my_user',\n        '-d', 'my_database',\n        '--option1',\n        '--option2',\n    ]\n    expected_env = {\n        'PGPASSWORD': 'my_password',\n        'PGSERVICE': 'my_service',\n        'PGSSLMODE': 'require',\n        'PGSSLROOTCERT': '/path/to/sslrootcert',\n        'PGSSLCERT': '/path/to/sslcert',\n        'PGSSLKEY': '/path/to/sslkey',\n        'PGPASSFILE': '/path/to/passfile',\n    }\n    with self.subTest(settings=settings_dict):\n        args, env = self.client.settings_to_cmd_args_env(settings_dict, parameters)\n        self.assertEqual(args, expected_args)\n        self.assertEqual(env, expected_env)\n"], "sample_732": ["def test_percent10_return_X_y():\n    try:\n        data = fetch_kddcup99(download_if_missing=False, return_X_y=True)\n    except IOError:\n        raise SkipTest(\"kddcup99 dataset can not be loaded.\")\n\n    assert_equal(data[0].shape, (494021, 41))\n    assert_equal(data[1].shape, (494021,))\n\n    data_shuffled = fetch_kddcup99(shuffle=True, random_state=0, return_X_y=True)\n    assert_equal(data[0].shape, data_shuffled[0].shape)\n    assert_equal(data[1].shape, data_shuffled[1].shape)\n\n    data = fetch_kddcup99('SA', return_X_y=True)\n    assert_equal(data[0].shape, (100655, 41))\n    assert_equal(data[1].shape, (100655,))\n\n    data = fetch_kddcup99('SF', return_X_y=True)\n    assert_equal(data[0].shape, (73237, 4))\n    assert_equal(data[1].shape, (73237,))\n\n    data = fetch_kddcup99('http', return_X_y=True)\n    assert_equal(data[0].shape, (58725, 3))\n    assert_equal(data[1].shape, (58725,))\n\n    data = fetch_kddcup99('smtp', return_X_y=True)\n    assert_equal(data[0].shape, (9571, 3))\n    assert_equal(data[1].shape, (9571,))\n"], "sample_575": ["    def x(self):\n        return pd.Series([1, 10, 100], name=\"x\", dtype=float)\n"], "sample_926": ["def test_enum_definitions():\n    check('enum', '{key}A', {2: \"1A\"})\n    check('enum', '{key}A : std::underlying_type<B>::type', {2: \"1A\"})\n    check('enum', '{key}A : unsigned int', {2: \"1A\"})\n    check('enum', 'public A', {2: \"1A\"}, output='{key}A')\n    check('enum', 'private {key}A', {2: \"1A\"})\n\n    check('enumerator', '{key}A', {2: \"1A\"})\n    check('enumerator', '{key}A = std::numeric_limits<unsigned long>::max()', {2: \"1A\"})\n\n    # from #4094\n    check('class', 'template<class, class = std::void_t<>> {key}has_var', {2: 'I00E7has_var'})\n    check('class', 'template<class T> {key}has_var<T, std::void_t<decltype(&T::var)>>',\n          {2: 'I0E7has_varI1TNSt6void_tIDTadN1T3varEEEEE'})\n\n    check('class', 'template<typename ...Ts> {key}T<int (*)(Ts)...>',\n          {2: 'IDpE1TIJPFi2TsEEE'})\n    check('class', 'template<int... Is> {key}T<(Is)...>',\n          {2: 'I_DpiE1TIJX(Is)EEE', 3: 'I_DpiE1TIJX2IsEEE'})\n\n    check('class', 'template<typename T> {key}A', {2: \"I0E1A\"})\n    check('class', 'template<class T> {key}A', {2: \"I0E1A\"})\n    check('class', 'template<typename ...T> {key}A', {2: \"IDpE1A\"})\n    check('class', 'template<typename...> {key}A', {2: \"IDpE1A\"})\n    check('class', 'template<typename = Test> {key}A', {2: \"I0E1A\"})\n    check('class', 'template<typename T = Test> {key}A', {2: \"I0E1A\"})\n\n    check('class', 'template<template<typename> typename T"], "sample_279": ["    def setUpTestData(cls):\n        cls.p1, cls.p2 = UniqueConstraintProduct.objects.bulk_create([\n            UniqueConstraintProduct(name='p1', color='red'),\n            UniqueConstraintProduct(name='p2'),\n        ])\n"], "sample_611": ["compilation error"], "sample_1064": ["def test_tensorflow_Piecewise():\n    if not tf:\n        skip(\"TensorFlow not installed\")\n\n    expr = Piecewise((x, x > 0), (y, x < 0))\n    assert tensorflow_code(expr) == \"tensorflow.where(x > 0, x, y)\"\n    _compare_tensorflow_scalar((x, y), expr)\n\n    expr = Piecewise((x, x > 0), (y, x < 0), (z, x == 0))\n    assert tensorflow_code(expr) == \"tensorflow.where(x > 0, x, tensorflow.where(x < 0, y, z))\"\n    _compare_tensorflow_scalar((x, y, z), expr)\n\n    expr = Piecewise((x, x > 0), (y, x < 0), (z, x == 0), (w, x == 1))\n    assert tensorflow_code(expr) == \"tensorflow.where(x > 0, x, tensorflow.where(x < 0, tensorflow.where(x == 0, z, w), y))\"\n    _compare_tensorflow_scalar((x, y, z, w), expr)\n\n    expr = Piecewise((x, x > 0), (y, x < 0), (z, x == 0), (w, x == 1), (v, x == 2))\n    assert tensorflow_code(expr) == \"tensorflow.where(x > 0, x, tensorflow.where(x < 0, tensorflow.where(x == 0, tensorflow.where(x == 1, w, z), tensorflow.where(x == 2, v, y))))\"\n    _compare_tensorflow_scalar((x, y, z, w, v), expr)\n"], "sample_948": ["def test_enum_definitions():\n    check('enum', '{key}A', {2: \"1A\"})\n    check('enum', '{key}A : std::underlying_type<B>::type', {2: \"1A\"})\n    check('enum', '{key}A : unsigned int', {2: \"1A\"})\n    check('enum', 'public A', {2: \"1A\"}, output='{key}A')\n    check('enum', 'private {key}A', {2: \"1A\"})\n\n    check('enumerator', '{key}A', {2: \"1A\"})\n    check('enumerator', '{key}A = std::numeric_limits<unsigned long>::max()', {2: \"1A\"})\n"], "sample_1069": ["def test_MatrixSolve_assign_to():\n    n = Symbol('n', integer=True)\n    A = MatrixSymbol('A', n, n)\n    x = MatrixSymbol('x', n, 1)\n    assert mcode(MatrixSolve(A, x), assign_to='X') == \"X = A \\\\ x;\"\n"], "sample_1125": ["def test_differential_operator():\n    x = symbols('x')\n    f = Function('f')\n    d = DifferentialOperator(Derivative(f(x), x), f(x))\n    w = Wavefunction(x**2, x)\n    assert d.function == f(x)\n    assert d.variables == (x,)\n    assert d.expr == Derivative(f(x), x)\n    assert d._apply_operator_Wavefunction(w) == Wavefunction(2*x, x)\n\n    d = DifferentialOperator(Derivative(f(x, y), x) + Derivative(f(x, y), y), f(x, y))\n    assert d.function == f(x, y)\n    assert d.variables == (x, y)\n    assert d.expr == Derivative(f(x, y), x) + Derivative(f(x, y), y)\n    assert d._apply_operator_Wavefunction(w) == Wavefunction(2*f(x, y), x, y)\n\n    d = DifferentialOperator(Derivative(f(x), x), f(x))\n    assert d._eval_derivative(x) == DifferentialOperator(Derivative(Derivative(f(x), x), x), f(x))\n    assert d._eval_derivative(y) == DifferentialOperator(Derivative(f(x), y), f(x))\n"], "sample_723": ["def test_imputation_axis_error():\n    # Test imputation with invalid axis.\n    X = np.array([\n        [np.nan, 0, 0, 0, 5],\n        [np.nan, 1, 0, np.nan, 3],\n        [np.nan, 2, 0, 0, 0],\n        [np.nan, 6, 0, 5, 13],\n    ])\n\n    imputer = SimpleImputer(strategy=\"mean\", axis=2)\n    assert_raises(ValueError, imputer.fit, X)\n    assert_raises(ValueError, imputer.transform, X)\n\n    imputer = SimpleImputer(strategy=\"median\", axis=3)\n    assert_raises(ValueError, imputer.fit, X)\n    assert_raises(ValueError, imputer.transform, X)\n\n    imputer = SimpleImputer(strategy=\"most_frequent\", axis=4)\n    assert_raises(ValueError, imputer.fit, X)\n    assert_raises(ValueError, imputer.transform, X)\n"], "sample_1142": ["def test_matrixsymbol_transpose():\n    A = MatrixSymbol('A', 2, 2)\n    assert A.T == Transpose(A)\n    assert A.T.shape == A.shape\n    assert (A.T).T == A\n    assert (A.T).T.T == A\n    assert (A.T).T.T.T == A\n    assert (A.T).T.T.T.T == A\n    assert (A.T).T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T.T == A\n    assert (A.T).T.T.T.T.T.T.T.T.T.T.T.T.T"], "sample_309": ["    def test_valid_date(self):\n        self.assertEqual(parse_http_date_safe('Sun, 06 Nov 1994 08:49:37 GMT'), 822783577)\n"], "sample_1038": ["def test_matrix_derivative():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', n, n)\n    E = MatrixSymbol('E', n, n)\n    F = MatrixSymbol('F', n, n)\n    G = MatrixSymbol('G', n, n)\n    H = MatrixSymbol('H', n, n)\n    I = MatrixSymbol('I', n, n)\n    J = MatrixSymbol('J', n, n)\n    K = MatrixSymbol('K', n, n)\n    L = MatrixSymbol('L', n, n)\n    M = MatrixSymbol('M', n, n)\n    N = MatrixSymbol('N', n, n)\n    O = MatrixSymbol('O', n, n)\n    P = MatrixSymbol('P', n, n)\n    Q = MatrixSymbol('Q', n, n)\n    R = MatrixSymbol('R', n, n)\n    S = MatrixSymbol('S', n, n)\n    T = MatrixSymbol('T', n, n)\n    U = MatrixSymbol('U', n, n)\n    V = MatrixSymbol('V', n, n)\n    W = MatrixSymbol('W', n, n)\n    X = MatrixSymbol('X', n, n)\n    Y = MatrixSymbol('Y', n, n)\n    Z = MatrixSymbol('Z', n, n)\n\n    assert (A.diff(A)).shape == (n, n)\n    assert (A.diff(B)).shape == (n, n)\n    assert (B.diff(A)).shape == (n, n)\n    assert (C.diff(D)).shape == (n, n)\n    assert (D.diff(C)).shape == (n, n)\n    assert (E.diff(F)).shape == (n, n)\n    assert (F.diff(E)).shape == (n, n)\n    assert (G.diff(H)).shape == (n, n)\n    assert (H.diff(G)).shape == (n, n)\n    assert (I.diff(J)).shape == (n, n)\n    assert (J.diff(I)).shape == (n, n)\n    assert (K.diff(L)).shape == (n, n)\n    assert (L.diff(K)).shape == (n, n)\n    assert (M.diff(N)).shape == ("], "sample_431": ["    def test_state_attributes(self):\n        a = Article.objects.create(headline=\"foo\", pub_date=datetime.now())\n        self.assertEqual(a._state.db, \"default\")\n        self.assertTrue(a._state.adding)\n        self.assertEqual(a._state.fields_cache, {})\n"], "sample_604": ["def test_inline_dask_repr():\n    da = xr.DataArray(np.random.randn(10, 5), dims=[\"x\", \"y\"], chunks=(2, 5))\n    actual = formatting.inline_dask_repr(da)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(2, 5)>\"\"\"\n    )\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 5), dims=[\"x\", \"y\"], chunks=(2, 5))\n    actual = formatting.inline_dask_repr(da)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(2, 5)>\"\"\"\n    )\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 5), dims=[\"x\", \"y\"], chunks=(2, 5))\n    actual = formatting.inline_dask_repr(da)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(2, 5)>\"\"\"\n    )\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 5), dims=[\"x\", \"y\"], chunks=(2, 5))\n    actual = formatting.inline_dask_repr(da)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(2, 5)>\"\"\"\n    )\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 5), dims=[\"x\", \"y\"], chunks=(2, 5))\n    actual = formatting.inline_dask_repr(da)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(2, 5)>\"\"\"\n    )\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 5), dims=[\"x\", \"y\"], chunks=(2, 5))\n    actual = formatting.inline_dask_repr(da)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(2, 5)>\"\"\"\n    )\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10, 5), dims=[\"x\", \"y\"], chunks=(2, 5))\n    actual = formatting.inline_dask_repr(da)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(2, 5)>\"\"\"\n    )\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10,"], "sample_917": ["def test_template_specialization():\n    check('class', 'template<> A<int>', {2: 'IE1A'})\n    check('class', 'template<> A<int, int>', {2: 'IE1A'})\n    check('class', 'template<> A<int, int, int>', {2: 'IE1A'})\n    check('class', 'template<> A<int, int, int, int>', {2: 'IE1A'})\n    check('class', 'template<> A<int, int, int, int, int>', {2: 'IE1A'})\n    check('class', 'template<> A<int, int, int, int, int, int>', {2: 'IE1A'})\n    check('class', 'template<> A<int, int, int, int, int, int, int>', {2: 'IE1A'})\n    check('class', 'template<> A<int, int, int, int, int, int, int, int>', {2: 'IE1A'})\n    check('class', 'template<> A<int, int, int, int, int, int, int, int, int>', {2: 'IE1A'})\n    check('class', 'template<> A<int, int, int, int, int, int, int, int, int, int>', {2: 'IE1A'})\n    check('class', 'template<> A<int, int, int, int, int, int, int, int, int, int, int>', {2: 'IE1A'})\n    check('class', 'template<> A<int, int, int, int, int, int, int, int, int, int, int, int>', {2: 'IE1A'})\n    check('class', 'template<> A<int, int, int, int, int, int, int, int, int, int, int, int, int>', {2: 'IE1A'})\n    check('class', 'template<> A<int, int, int, int, int, int, int, int, int, int, int, int, int, int>', {2: 'IE1A'})\n    check('class', 'template<> A<int, int, int, int, int, int, int, int, int, int, int, int, int, int, int>', {2: 'IE1A'})\n    check"], "sample_1159": ["def test_issue_17723():\n    x = Symbol('x', extended_real=True)\n    assert x.is_finite is None\n    assert x.is_infinite is None\n    assert x.is_extended_real is True\n    assert x.is_real is None\n    assert x.is_complex is None\n    assert x.is_noninteger is None\n    assert x.is_irrational is None\n    assert x.is_imaginary is None\n    assert x.is_positive is None\n    assert x.is_negative is None\n    assert x.is_nonpositive is None\n    assert x.is_nonnegative is None\n    assert x.is_even is None\n    assert x.is_odd is None\n    assert x.is_finite is None\n    assert x.is_infinite is None\n    assert x.is_comparable is None\n    assert x.is_prime is None\n    assert x.is_composite is None\n    assert x.is_number is None\n"], "sample_1173": ["def test_function_exponentiation_application():\n    t = standard_transformations + (function_exponentiation, implicit_multiplication_application)\n    x = Symbol('x')\n    y = Symbol('y')\n    a = Symbol('a')\n    yfcn = Function('y')\n    assert parse_expr(\"sin**2(x)\", transformations=t) == (sin(x))**2\n    assert parse_expr(\"sin**y(x)\", transformations=t) == (sin(x))**y\n    assert parse_expr(\"exp**y(x)\", transformations=t) == (exp(x))**y\n    assert parse_expr(\"E**y(x)\", transformations=t) == exp(yfcn(x))\n    assert parse_expr(\"a**y(x)\", transformations=t) == a**(yfcn(x))\n"], "sample_1034": ["def test_grover_iteration_3():\n    numqubits = 3\n    basis_states = superposition_basis(numqubits)\n    v = OracleGate(numqubits, return_one_on_two)\n    iterated = grover_iteration(basis_states, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated ="], "sample_437": ["    def test_prepare_database(self):\n        with patch.object(connection, \"prepare_database\", side_effect=Exception):\n            with self.assertRaises(Exception):\n                connection.prepare_database()\n"], "sample_1155": ["def test_construct_domain_with_multiple_irrational_numbers():\n    result = construct_domain([sqrt(2), sqrt(3), sqrt(5)])\n    assert isinstance(result[0], RealField)\n    assert result[1] == [RR(sqrt(2)), RR(sqrt(3)), RR(sqrt(5))]\n\n    result = construct_domain([sqrt(2), sqrt(3), sqrt(5)], extension=True)\n    alg = QQ.algebraic_field(sqrt(2) + sqrt(3) + sqrt(5))\n    assert result[0] == alg\n    assert result[1] == [alg.convert(sqrt(2)), alg.convert(sqrt(3)), alg.convert(sqrt(5))]\n\n    result = construct_domain([sqrt(2), sqrt(3), sqrt(5), sqrt(7)], extension=True)\n    alg = QQ.algebraic_field(sqrt(2) + sqrt(3) + sqrt(5) + sqrt(7))\n    assert result[0] == alg\n    assert result[1] == [alg.convert(sqrt(2)), alg.convert(sqrt(3)), alg.convert(sqrt(5)), alg.convert(sqrt(7))]\n\n    result = construct_domain([sqrt(2), sqrt(3), sqrt(5), sqrt(7), sqrt(11)], extension=True)\n    alg = QQ.algebraic_field(sqrt(2) + sqrt(3) + sqrt(5) + sqrt(7) + sqrt(11))\n    assert result[0] == alg\n    assert result[1] == [alg.convert(sqrt(2)), alg.convert(sqrt(3)), alg.convert(sqrt(5)), alg.convert(sqrt(7)), alg.convert(sqrt(11))]\n"], "sample_1037": ["def test_MatMul_refine():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    with assuming(Q.orthogonal(A)):\n        assert refine_MatMul(A*B).doit() == Identity(2)\n    with assuming(Q.orthogonal(B)):\n        assert refine_MatMul(A*B).doit() == Identity(2)\n    with assuming(Q.orthogonal(A), Q.orthogonal(B)):\n        assert refine_MatMul(A*B).doit() == Identity(2)\n    with assuming(Q.orthogonal(A), Q.unitary(B)):\n        assert refine_MatMul(A*B).doit() == Identity(2)\n    with assuming(Q.unitary(A), Q.orthogonal(B)):\n        assert refine_MatMul(A*B).doit() == Identity(2)\n    with assuming(Q.unitary(A), Q.unitary(B)):\n        assert refine_MatMul(A*B).doit() == Identity(2)\n"], "sample_1063": ["def test_lambdify_with_tensorflow_and_numpy():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    if not numpy:\n        skip(\"numpy not installed.\")\n    expr = Max(sin(x), Abs(1/(x+2)))\n    func = lambdify(x, expr, modules=[\"tensorflow\", \"numpy\"])\n    with tensorflow.compat.v1.Session() as s:\n        a = tensorflow.constant(0, dtype=tensorflow.float32)\n        assert func(a).eval(session=s) == 0.5\n"], "sample_586": ["    def test_concat_fill_value_coord(self):\n        data = Dataset({\"foo\": (\"x\", np.random.randn(10))})\n        expected = data.assign_coords(c=(\"x\", [0] * 5 + [1] * 5))\n        objs = [\n            data.isel(x=slice(5)).assign_coords(c=0),\n            data.isel(x=slice(5, None)).assign_coords(c=1),\n        ]\n        for fill_value in [dtypes.NA, 2, 2.0]:\n            if fill_value == dtypes.NA:\n                # if we supply the default, we expect the missing value for a\n                # float array\n                fill_value = np.nan\n            actual = concat(objs, \"x\", coords=\"different\", fill_value=fill_value)\n            assert_identical(expected, actual)\n"], "sample_780": ["def test_lda_learning_decay():\n    # Test LDA learning decay\n    # learning decay should be between (0.5, 1.0] to guarantee asymptotic convergence\n    n_components, X = _build_sparse_mtx()\n    lda_1 = LatentDirichletAllocation(n_components=n_components,\n                                      learning_decay=0.5, random_state=0)\n    lda_2 = LatentDirichletAllocation(n_components=n_components,\n                                      learning_decay=1.0, random_state=0)\n    lda_3 = LatentDirichletAllocation(n_components=n_components,\n                                      learning_decay=1.1, random_state=0)\n    lda_4 = LatentDirichletAllocation(n_components=n_components,\n                                      learning_decay=-0.5, random_state=0)\n\n    lda_1.fit(X)\n    lda_2.fit(X)\n    lda_3.fit(X)\n    lda_4.fit(X)\n\n    assert_greater_equal(lda_1.n_batch_iter_, lda_2.n_batch_iter_)\n    assert_greater_equal(lda_2.n_batch_iter_, lda_3.n_batch_iter_)\n    assert_raises_regexp(ValueError, r\"Invalid 'learning_decay' parameter\",\n                         lda_4.fit, X)\n"], "sample_1075": ["def test_beta_numerical_evaluation():\n    x, y = Symbol('x'), Symbol('y')\n    assert beta(x, y).evalf(10) == (gamma(x).evalf(10) * gamma(y).evalf(10)) / gamma(x + y).evalf(10)\n    assert beta(1, 2).evalf(10) == 0.3333333333\n    assert beta(2, 2).evalf(10) == 0.1666666667\n    assert beta(1 + I, 1 + I).evalf(10) == -0.2112723729 - 0.7655283165*I\n    assert beta(pi, pi).evalf(10) == 0.026718489\n"], "sample_906": ["def test_domain_cpp_ast_macros():\n    check('macro', 'void f()', {1: 'f', 2: '1fv'})\n    check('macro', 'void f(int)', {1: 'f__i', 2: '1f1i'})\n    check('macro', 'void f(int, int)', {1: 'f__i.i', 2: '1f2i'})\n    check('macro', 'void f(int, int, int)', {1: 'f__i.i.i', 2: '1f3i'})\n    check('macro', 'void f(int, int, int, int)', {1: 'f__i.i.i.i', 2: '1f4i'})\n    check('macro', 'void f(int, int, int, int, int)', {1: 'f__i.i.i.i.i', 2: '1f5i'})\n    check('macro', 'void f(int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i', 2: '1f6i'})\n    check('macro', 'void f(int, int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i.i', 2: '1f7i'})\n    check('macro', 'void f(int, int, int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i.i.i', 2: '1f8i'})\n    check('macro', 'void f(int, int, int, int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i.i.i.i', 2: '1f9i'})\n    check('macro', 'void f(int, int, int, int, int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i.i.i.i.i', 2: '1f10i'})\n    check('macro', 'void f(int, int, int, int, int, int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i.i.i.i.i.i', 2: '1f11i'})\n    check('macro', 'void f(int, int, int, int, int,"], "sample_825": ["def test_pls_transform_copy():\n    # check that the \"copy\" keyword works\n    d = load_linnerud()\n    X = d.data\n    Y = d.target\n    clf = pls_.PLSCanonical()\n    X_copy = X.copy()\n    Y_copy = Y.copy()\n    clf.fit(X, Y)\n    # check that results are identical with copy\n    assert_array_almost_equal(clf.transform(X, Y),\n                              clf.transform(X.copy(), Y.copy(), copy=False))\n    # check that copy doesn't destroy\n    # we do want to check exact equality here\n    assert_array_equal(X_copy, X)\n    assert_array_equal(Y_copy, Y)\n    # also check that mean wasn't zero before (to make sure we didn't touch it)\n    assert np.all(X.mean(axis=0) != 0)\n"], "sample_1004": ["def test_CondSet_subs_with_non_symbol():\n    c = ConditionSet(x, x < 2, FiniteSet(z, y))\n    assert c.subs(x, 1) == c\n    assert c.subs(x, y) == ConditionSet(y, y < 2, FiniteSet(z, y))\n    assert c.subs(x, z) == ConditionSet(z, z < 2, FiniteSet(z, y))\n    assert c.subs(x, y + 1) == c\n    assert c.subs(x, y + z) == c\n    assert c.subs(x, y + z + 1) == c\n    assert c.subs(x, y + z + 1 + y) == c\n    assert c.subs(x, y + z + 1 + y + z) == c\n    assert c.subs(x, y + z + 1 + y + z + y) == c\n    assert c.subs(x, y + z + 1 + y + z + y + z) == c\n    assert c.subs(x, y + z + 1 + y + z + y + z + y) == c\n    assert c.subs(x, y + z + 1 + y + z + y + z + y + z) == c\n    assert c.subs(x, y + z + 1 + y + z + y + z + y + z + y) == c\n    assert c.subs(x, y + z + 1 + y + z + y + z + y + z + y + z) == c\n    assert c.subs(x, y + z + 1 + y + z + y + z + y + z + y + z + y) == c\n    assert c.subs(x, y + z + 1 + y + z + y + z + y + z + y + z + y + z) == c\n    assert c.subs(x, y + z + 1 + y + z + y + z + y + z + y + z + y + z + y) == c\n    assert c.subs(x, y + z + 1 + y + z + y + z + y + z + y + z + y + z + y + z) == c\n    assert c.subs(x, y + z + "], "sample_958": ["def test_domain_cpp_ast_template_shorthand():\n    check('class', \"template<> {key}A\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int>\", {2: \"IE1AI1TE\"})\n    check('class', \"template<> {key}A<int, int>\", {2: \"IE1AI1TE1TE\"})\n    check('class', \"template<> {key}A<int, int, int>\", {2: \"IE1AI1TE1TE1TE\"})\n    check('class', \"template<> {key}A<int, int, int, int>\", {2: \"IE1AI1TE1TE1TE1TE\"})\n    check('class', \"template<> {key}A<int, int, int, int, int>\", {2: \"IE1AI1TE1TE1TE1TE1TE\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int>\", {2: \"IE1AI1TE1TE1TE1TE1TE1TE\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int>\", {2: \"IE1AI1TE1TE1TE1TE1TE1TE1TE\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int, int>\", {2: \"IE1AI1TE1TE1TE1TE1TE1TE1TE1TE\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int, int, int>\", {2: \"IE1AI1TE1TE1TE1TE1TE1TE1TE1TE1TE\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int, int, int, int>\", {2: \"IE1AI1TE1TE1TE1TE1TE1TE1TE1TE1TE1TE\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int, int, int, int, int>\", {2: \"IE1AI1TE1TE1TE1TE1TE1TE1TE1TE1TE"], "sample_303": ["def test_runshell_check(self):\n    with self.assertRaises(subprocess.SubprocessError):\n        with mock.patch('subprocess.run') as run:\n            with mock.patch.object(\n                BaseDatabaseClient,\n                'settings_to_cmd_args_env',\n                return_value=([], None),\n            ):\n                self.client.runshell(None)\n                run.assert_called_once_with([], env=None, check=True)\n"], "sample_1126": ["def test_dagger_expr():\n    x = symbols('x')\n    y = symbols('y')\n    assert Dagger(x + y) == Dagger(x) + Dagger(y)\n    assert Dagger(x*y) == Dagger(y)*Dagger(x)\n    assert Dagger(x/y) == Dagger(y)/Dagger(x)\n    assert Dagger(x**2) == Dagger(x)**2\n    assert Dagger(x**y) == Dagger(x)**Dagger(y)\n"], "sample_1117": ["def test_matrix_element_sets_matrix_slice():\n    X = MatrixSymbol('X', 4, 4)\n    B = MatrixSlice(X, (1, 3), (1, 3))\n    assert ask(Q.real(B[1, 1]), Q.real_elements(X))\n    assert ask(Q.integer(B[1, 1]), Q.integer_elements(X))\n    assert ask(Q.complex(B[1, 1]), Q.complex_elements(X))\n    assert ask(Q.real_elements(B), Q.real_elements(X))\n    assert ask(Q.integer_elements(B), Q.integer_elements(X))\n    assert ask(Q.complex_elements(B), Q.complex_elements(X))\n"], "sample_1035": ["def test_measure_all():\n    nqubits = 2\n    basis_states = superposition_basis(nqubits)\n    assert measure_all(basis_states) == [\n        (basis_states, 1/4),\n        (IntQubit(1, nqubits=nqubits), 1/4),\n        (IntQubit(2, nqubits=nqubits), 1/4),\n        (IntQubit(3, nqubits=nqubits), 1/4)\n    ]\n\n    nqubits = 3\n    basis_states = superposition_basis(nqubits)\n    assert measure_all(basis_states) == [\n        (basis_states, 1/8),\n        (IntQubit(1, nqubits=nqubits), 1/8),\n        (IntQubit(2, nqubits=nqubits), 1/8),\n        (IntQubit(3, nqubits=nqubits), 1/8),\n        (IntQubit(4, nqubits=nqubits), 1/8),\n        (IntQubit(5, nqubits=nqubits), 1/8),\n        (IntQubit(6, nqubits=nqubits), 1/8),\n        (IntQubit(7, nqubits=nqubits), 1/8)\n    ]\n\n    nqubits = 2\n    basis_states = superposition_basis(nqubits)\n    assert measure_all(basis_states, normalize=False) == [\n        (basis_states, 1/4),\n        (IntQubit(1, nqubits=nqubits), 1/4),\n        (IntQubit(2, nqubits=nqubits), 1/4),\n        (IntQubit(3, nqubits=nqubits), 1/4)\n    ]\n\n    nqubits = 3\n    basis_states = superposition_basis(nqubits)\n    assert measure_all(basis_states, normalize=False) == [\n        (basis_states, 1/8),\n        (IntQubit(1, nqubits=nqubits), 1/8),\n        (IntQubit(2, nqubits=nqubits), 1/8),\n        (IntQubit(3, nqubits=nqubits), 1/8),\n        (IntQubit(4, nqubits=nqubits), "], "sample_1116": ["def test_inverse_conjugate():\n    from sympy import conjugate\n    A = MatrixSymbol('A', 3, 3)\n    assert refine(Inverse(A), Q.unitary(A)) == conjugate(A).I\n    assert refine(Inverse(A), Q.orthogonal(A)) == A.T\n    assert refine(Inverse(A), Q.singular(A)) == A\n"], "sample_779": ["def test_check_estimators_pickle_works_on_deprecated_fit():\n    # Tests that check_estimators_pickle works on a class with a deprecated fit method\n\n    class TestEstimatorWithDeprecatedFitMethod(BaseEstimator):\n        @deprecated(\"Deprecated for the purpose of testing check_estimators_pickle\")\n            return self\n\n    check_estimators_pickle(\"test\", TestEstimatorWithDeprecatedFitMethod())\n"], "sample_454": ["    def test_eq(self):\n        constraint1 = models.ExclusionConstraint(\n            expressions=[(\"field1\", \"GT\"), (\"field2\", \"LT\")],\n            name=\"exclusion\",\n        )\n        constraint2 = models.ExclusionConstraint(\n            expressions=[(\"field1\", \"GT\"), (\"field2\", \"LT\")],\n            name=\"exclusion\",\n        )\n        self.assertEqual(constraint1, constraint1)\n        self.assertEqual(constraint1, mock.ANY)\n        self.assertNotEqual(constraint1, constraint2)\n        self.assertNotEqual(constraint1, constraint2)\n        self.assertNotEqual(constraint1, 1)\n        self.assertNotEqual(\n            constraint1,\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"GT\"), (\"field2\", \"LT\")],\n                name=\"exclusion\",\n                violation_error_message=\"custom error\",\n            ),\n        )\n        self.assertNotEqual(\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"GT\"), (\"field2\", \"LT\")],\n                name=\"exclusion\",\n                violation_error_message=\"custom error\",\n            ),\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"GT\"), (\"field2\", \"LT\")],\n                name=\"exclusion\",\n                violation_error_message=\"other custom error\",\n            ),\n        )\n        self.assertEqual(\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"GT\"), (\"field2\", \"LT\")],\n                name=\"exclusion\",\n                violation_error_message=\"custom error\",\n            ),\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"GT\"), (\"field2\", \"LT\")],\n                name=\"exclusion\",\n                violation_error_message=\"custom error\",\n            ),\n        )\n        self.assertNotEqual(\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"GT\"), (\"field2\", \"LT\")],\n                name=\"exclusion\",\n                violation_error_code=\"custom_error\",\n            ),\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"GT\"), (\"field2\", \"LT\")],\n                name=\"exclusion\",\n                violation_error_code=\"other_custom_error\",\n            ),\n        )\n        self.assertEqual(\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"GT\"), (\"field2\", \"LT\")],\n                name=\"exclusion\",\n                violation_error_code=\"custom_error\",\n            ),\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"GT"], "sample_1087": ["def test_fateman_poly_F_4():\n    f, g, h = fateman_poly_F_4(1)\n    F, G, H = dmp_fateman_poly_F_4(1, ZZ)\n\n    assert [ t.rep.rep for t in [f, g, h] ] == [F, G, H]\n\n    f, g, h = fateman_poly_F_4(3)\n    F, G, H = dmp_fateman_poly_F_4(3, ZZ)\n\n    assert [ t.rep.rep for t in [f, g, h] ] == [F, G, H]\n\n"], "sample_243": ["def test_transform_with_lookup(self):\n    query = Query(Author, alias_cols=False)\n    with register_lookup(CharField, Lower):\n        where = query.build_where(Q(name__lower__exact='foo'))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, Exact)\n    self.assertIsInstance(lookup.lhs, Lower)\n    self.assertIsInstance(lookup.lhs.lhs, Col)\n    self.assertIsNone(lookup.lhs.lhs.alias)\n    self.assertEqual(lookup.lhs.lhs.target, Author._meta.get_field('name'))\n    self.assertEqual(lookup.rhs, 'foo')\n"], "sample_1025": ["def test_SymPyPrinter():\n    p = SymPyPrinter()\n    assert p.doprint(x**y) == 'sympy.Symbol(\"x\")**sympy.Symbol(\"y\")'\n    assert p.doprint(Mod(x, 2)) == 'sympy.Mod(sympy.Symbol(\"x\"), 2)'\n    assert p.doprint(And(x, y)) == 'sympy.And(sympy.Symbol(\"x\"), sympy.Symbol(\"y\"))'\n    assert p.doprint(Or(x, y)) == 'sympy.Or(sympy.Symbol(\"x\"), sympy.Symbol(\"y\"))'\n    assert p.doprint(acos(x)) == 'sympy.acos(sympy.Symbol(\"x\"))'\n    assert p.doprint(Assignment(x, 2)) == 'sympy.Symbol(\"x\") = 2'\n    assert p.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert p.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        '(3) if (x > 0) else None)'\n    assert p.doprint(sign(x)) == 'sympy.copysign(1, sympy.Symbol(\"x\"))'\n"], "sample_976": ["def test_Dummy_hash():\n    d1 = Dummy('d')\n    d2 = Dummy('d')\n    d3 = Dummy('e')\n    d4 = Dummy('d', dummy_index=2)\n\n    assert hash(d1) != hash(d2)\n    assert hash(d1) != hash(d3)\n    assert hash(d2) != hash(d3)\n    assert hash(d1) != hash(d4)\n    assert hash(d2) != hash(d4)\n    assert hash(d3) != hash(d4)\n\n    assert d1 != d2\n    assert d1 != d3\n    assert d2 != d3\n    assert d1 != d4\n    assert d2 != d4\n    assert d3 != d4\n"], "sample_907": ["def test_domain_cpp_ast_enum_definitions():\n    check('enum', '{key}A', {2: \"1A\"})\n    check('enum', '{key}A : std::underlying_type<B>::type', {2: \"1A\"})\n    check('enum', '{key}A : unsigned int', {2: \"1A\"})\n    check('enum', 'public A', {2: \"1A\"}, output='{key}A')\n    check('enum', 'private {key}A', {2: \"1A\"})\n\n    check('enumerator', '{key}A', {2: \"1A\"})\n    check('enumerator', '{key}A = std::numeric_limits<unsigned long>::max()', {2: \"1A\"})\n"], "sample_873": ["def test_get_feature_names_out():\n    \"\"\"Check get_feature_names_out method.\"\"\"\n    sel = StepSelector()\n    sel.fit(X, y)\n    assert_array_equal(feature_names_t, sel.get_feature_names_out())\n    assert_array_equal(feature_names_t, sel.get_feature_names_out(input_features=feature_names))\n    assert_array_equal(feature_names_inv, sel.get_feature_names_out(input_features=feature_names_inv))\n    with pytest.raises(ValueError):\n        sel.get_feature_names_out(input_features=[\"a\", \"b\", \"c\"])\n"]}, "raw_scored_generations": {"sample_0": [false], "sample_3": [true], "sample_2": [false], "sample_1": [false], "sample_4": [false], "sample_5": [false], "sample_6": [false], "sample_7": [false], "sample_8": [false], "sample_9": [false], "sample_10": [true], "sample_11": [false], "sample_12": [false], "sample_13": [false], "sample_14": [true], "sample_15": [true], "sample_16": [false], "sample_17": [false], "sample_18": [false], "sample_19": [false], "sample_20": [false], "sample_21": [false], "sample_22": [false], "sample_23": [true], "sample_24": [false], "sample_25": [false], "sample_26": [false], "sample_27": [false], "sample_28": [false], "sample_29": [false], "sample_30": [false], "sample_31": [false], "sample_32": [false], "sample_33": [false], "sample_34": [true], "sample_35": [false], "sample_36": [false], "sample_37": [true], "sample_38": [false], "sample_39": [false], "sample_40": [true], "sample_41": [false], "sample_42": [false], "sample_43": [false], "sample_44": [false], "sample_45": [true], "sample_46": [false], "sample_47": [false], "sample_48": [true], "sample_49": [false], "sample_50": [true], "sample_51": [true], "sample_52": [true], "sample_54": [true], "sample_53": [false], "sample_55": [false], "sample_58": [false], "sample_56": [false], "sample_57": [false], "sample_59": [false], "sample_60": [false], "sample_61": [true], "sample_62": [false], "sample_63": [false], "sample_64": [false], "sample_65": [true], "sample_67": [false], "sample_66": [false], "sample_68": [false], "sample_69": [false], "sample_70": [false], "sample_71": [true], "sample_72": [true], "sample_73": [false], "sample_75": [false], "sample_74": [true], "sample_76": [true], "sample_77": [false], "sample_78": [false], "sample_79": [false], "sample_80": [true], "sample_82": [false], "sample_81": [false], "sample_83": [false], "sample_85": [true], "sample_84": [false], "sample_86": [false], "sample_88": [false], "sample_87": [false], "sample_89": [false], "sample_90": [false], "sample_91": [true], "sample_92": [false], "sample_93": [true], "sample_94": [false], "sample_95": [false], "sample_98": [false], "sample_96": [true], "sample_99": [false], "sample_97": [false], "sample_100": [false], "sample_102": [true], "sample_101": [false], "sample_103": [true], "sample_104": [false], "sample_107": [false], "sample_106": [false], "sample_105": [true], "sample_108": [false], "sample_109": [true], "sample_111": [true], "sample_110": [false], "sample_112": [false], "sample_113": [false], "sample_114": [true], "sample_115": [false], "sample_116": [false], "sample_117": [false], "sample_118": [true], "sample_119": [true], "sample_120": [false], "sample_121": [false], "sample_122": [false], "sample_123": [false], "sample_124": [true], "sample_125": [true], "sample_126": [true], "sample_127": [false], "sample_128": [false], "sample_129": [false], "sample_130": [false], "sample_131": [false], "sample_132": [false], "sample_133": [true], "sample_135": [true], "sample_134": [true], "sample_136": [false], "sample_139": [true], "sample_137": [true], "sample_138": [false], "sample_140": [false], "sample_141": [false], "sample_142": [true], "sample_143": [false], "sample_144": [true], "sample_145": [true], "sample_146": [true], "sample_147": [true], "sample_148": [true], "sample_151": [true], "sample_149": [false], "sample_152": [false], "sample_150": [false], "sample_153": [false], "sample_154": [true], "sample_155": [true], "sample_156": [true], "sample_157": [false], "sample_158": [true], "sample_159": [true], "sample_160": [false], "sample_161": [true], "sample_162": [false], "sample_163": [false], "sample_164": [false], "sample_165": [false], "sample_166": [false], "sample_167": [false], "sample_168": [true], "sample_169": [false], "sample_171": [true], "sample_170": [false], "sample_172": [true], "sample_173": [false], "sample_174": [false], "sample_175": [false], "sample_176": [true], "sample_177": [true], "sample_178": [false], "sample_180": [true], "sample_179": [true], "sample_182": [true], "sample_181": [true], "sample_183": [false], "sample_184": [true], "sample_185": [false], "sample_186": [false], "sample_187": [false], "sample_188": [false], "sample_189": [false], "sample_190": [true], "sample_191": [false], "sample_192": [true], "sample_193": [true], "sample_194": [false], "sample_195": [false], "sample_196": [false], "sample_198": [false], "sample_197": [true], "sample_199": [true], "sample_200": [false], "sample_201": [true], "sample_202": [true], "sample_203": [false], "sample_204": [false], "sample_205": [true], "sample_206": [true], "sample_207": [false], "sample_208": [true], "sample_209": [false], "sample_210": [true], "sample_211": [true], "sample_213": [false], "sample_212": [true], "sample_214": [true], "sample_215": [false], "sample_216": [true], "sample_217": [false], "sample_218": [false], "sample_219": [false], "sample_220": [false], "sample_221": [true], "sample_222": [false], "sample_223": [false], "sample_224": [true], "sample_225": [false], "sample_226": [false], "sample_227": [true], "sample_228": [false], "sample_229": [true], "sample_230": [false], "sample_231": [false], "sample_232": [true], "sample_233": [true], "sample_234": [true], "sample_235": [false], "sample_236": [false], "sample_237": [false], "sample_238": [true], "sample_239": [false], "sample_240": [true], "sample_241": [false], "sample_242": [false], "sample_243": [true], "sample_244": [true], "sample_245": [true], "sample_246": [true], "sample_247": [false], "sample_248": [true], "sample_249": [true], "sample_250": [true], "sample_251": [false], "sample_252": [false], "sample_253": [false], "sample_254": [false], "sample_256": [false], "sample_255": [false], "sample_257": [true], "sample_258": [true], "sample_259": [true], "sample_260": [true], "sample_261": [false], "sample_262": [true], "sample_263": [false], "sample_264": [true], "sample_265": [true], "sample_266": [true], "sample_267": [false], "sample_268": [false], "sample_269": [true], "sample_270": [true], "sample_271": [false], "sample_272": [true], "sample_273": [false], "sample_274": [true], "sample_275": [false], "sample_276": [false], "sample_277": [true], "sample_278": [false], "sample_279": [false], "sample_280": [true], "sample_281": [true], "sample_282": [true], "sample_283": [true], "sample_284": [false], "sample_285": [false], "sample_286": [false], "sample_287": [false], "sample_288": [false], "sample_289": [false], "sample_290": [true], "sample_291": [true], "sample_292": [true], "sample_293": [false], "sample_294": [true], "sample_295": [false], "sample_296": [true], "sample_297": [false], "sample_298": [true], "sample_299": [true], "sample_300": [true], "sample_301": [false], "sample_302": [true], "sample_303": [true], "sample_304": [true], "sample_305": [true], "sample_306": [false], "sample_307": [true], "sample_308": [true], "sample_309": [false], "sample_310": [false], "sample_312": [true], "sample_311": [false], "sample_313": [false], "sample_314": [false], "sample_315": [true], "sample_316": [false], "sample_317": [true], "sample_318": [false], "sample_319": [true], "sample_320": [true], "sample_321": [false], "sample_322": [true], "sample_323": [true], "sample_324": [false], "sample_325": [true], "sample_326": [false], "sample_327": [false], "sample_328": [true], "sample_329": [false], "sample_330": [false], "sample_331": [false], "sample_332": [true], "sample_333": [false], "sample_334": [false], "sample_335": [true], "sample_336": [false], "sample_337": [true], "sample_338": [true], "sample_339": [false], "sample_340": [true], "sample_341": [false], "sample_342": [true], "sample_343": [false], "sample_344": [true], "sample_345": [false], "sample_346": [false], "sample_347": [true], "sample_348": [true], "sample_349": [false], "sample_350": [true], "sample_351": [false], "sample_352": [false], "sample_353": [false], "sample_354": [false], "sample_355": [false], "sample_356": [true], "sample_357": [true], "sample_358": [false], "sample_359": [true], "sample_360": [false], "sample_361": [false], "sample_362": [true], "sample_363": [true], "sample_364": [false], "sample_365": [true], "sample_366": [true], "sample_367": [false], "sample_368": [true], "sample_369": [true], "sample_370": [false], "sample_371": [false], "sample_372": [false], "sample_373": [false], "sample_374": [false], "sample_375": [true], "sample_376": [true], "sample_377": [false], "sample_378": [false], "sample_379": [true], "sample_380": [false], "sample_381": [true], "sample_382": [true], "sample_383": [false], "sample_384": [false], "sample_385": [false], "sample_386": [true], "sample_387": [false], "sample_388": [true], "sample_389": [false], "sample_390": [true], "sample_391": [true], "sample_392": [false], "sample_393": [false], "sample_394": [false], "sample_395": [false], "sample_396": [false], "sample_397": [true], "sample_398": [false], "sample_399": [false], "sample_400": [true], "sample_401": [true], "sample_402": [true], "sample_403": [false], "sample_404": [true], "sample_405": [false], "sample_406": [false], "sample_407": [true], "sample_408": [true], "sample_409": [false], "sample_410": [false], "sample_411": [true], "sample_412": [false], "sample_413": [false], "sample_414": [true], "sample_415": [false], "sample_416": [true], "sample_417": [false], "sample_418": [false], "sample_419": [true], "sample_420": [true], "sample_421": [true], "sample_422": [false], "sample_423": [false], "sample_424": [false], "sample_425": [true], "sample_426": [true], "sample_427": [true], "sample_428": [true], "sample_429": [false], "sample_430": [true], "sample_431": [false], "sample_432": [true], "sample_433": [true], "sample_434": [false], "sample_435": [false], "sample_436": [true], "sample_437": [true], "sample_438": [true], "sample_439": [false], "sample_440": [true], "sample_441": [false], "sample_442": [true], "sample_443": [false], "sample_444": [false], "sample_445": [true], "sample_446": [false], "sample_447": [false], "sample_448": [false], "sample_449": [false], "sample_450": [true], "sample_451": [false], "sample_453": [false], "sample_452": [true], "sample_454": [false], "sample_455": [false], "sample_456": [true], "sample_457": [false], "sample_458": [false], "sample_459": [false], "sample_460": [false], "sample_461": [false], "sample_462": [false], "sample_463": [true], "sample_464": [true], "sample_465": [false], "sample_466": [true], "sample_467": [false], "sample_469": [false], "sample_468": [true], "sample_470": [false], "sample_471": [false], "sample_472": [false], "sample_473": [false], "sample_474": [false], "sample_475": [false], "sample_476": [false], "sample_477": [true], "sample_478": [true], "sample_479": [true], "sample_480": [true], "sample_481": [false], "sample_482": [false], "sample_483": [false], "sample_484": [false], "sample_485": [false], "sample_486": [true], "sample_487": [false], "sample_488": [false], "sample_489": [true], "sample_490": [false], "sample_491": [true], "sample_492": [true], "sample_493": [false], "sample_494": [false], "sample_495": [false], "sample_496": [false], "sample_497": [true], "sample_498": [true], "sample_499": [true], "sample_500": [true], "sample_501": [true], "sample_502": [false], "sample_503": [true], "sample_504": [false], "sample_505": [false], "sample_506": [false], "sample_507": [true], "sample_508": [false], "sample_509": [false], "sample_510": [false], "sample_511": [false], "sample_512": [true], "sample_513": [true], "sample_514": [false], "sample_515": [true], "sample_516": [false], "sample_517": [false], "sample_518": [false], "sample_519": [false], "sample_520": [false], "sample_521": [false], "sample_522": [false], "sample_523": [true], "sample_524": [false], "sample_525": [false], "sample_526": [false], "sample_527": [false], "sample_528": [true], "sample_529": [true], "sample_530": [false], "sample_531": [false], "sample_532": [false], "sample_533": [false], "sample_534": [false], "sample_535": [false], "sample_536": [false], "sample_537": [true], "sample_538": [false], "sample_539": [false], "sample_540": [false], "sample_541": [false], "sample_542": [false], "sample_543": [false], "sample_544": [false], "sample_545": [false], "sample_546": [false], "sample_547": [false], "sample_548": [false], "sample_549": [false], "sample_550": [false], "sample_551": [false], "sample_552": [false], "sample_553": [false], "sample_554": [false], "sample_555": [false], "sample_556": [false], "sample_557": [false], "sample_558": [false], "sample_559": [false], "sample_560": [true], "sample_561": [false], "sample_562": [true], "sample_563": [false], "sample_564": [false], "sample_565": [false], "sample_566": [false], "sample_567": [false], "sample_568": [false], "sample_569": [false], "sample_570": [false], "sample_571": [false], "sample_572": [false], "sample_573": [false], "sample_574": [false], "sample_575": [false], "sample_576": [false], "sample_577": [false], "sample_578": [false], "sample_579": [true], "sample_580": [false], "sample_581": [false], "sample_582": [false], "sample_583": [true], "sample_584": [false], "sample_585": [false], "sample_586": [true], "sample_587": [false], "sample_588": [false], "sample_589": [true], "sample_590": [false], "sample_591": [false], "sample_592": [false], "sample_593": [false], "sample_594": [false], "sample_595": [true], "sample_596": [true], "sample_597": [false], "sample_598": [false], "sample_599": [false], "sample_600": [false], "sample_601": [false], "sample_602": [false], "sample_603": [false], "sample_604": [false], "sample_605": [false], "sample_606": [false], "sample_607": [false], "sample_608": [false], "sample_609": [false], "sample_610": [false], "sample_611": [false], "sample_612": [false], "sample_613": [false], "sample_614": [false], "sample_615": [false], "sample_616": [false], "sample_617": [false], "sample_618": [false], "sample_619": [false], "sample_620": [true], "sample_621": [false], "sample_622": [true], "sample_623": [false], "sample_624": [false], "sample_625": [false], "sample_626": [true], "sample_627": [false], "sample_628": [false], "sample_629": [true], "sample_630": [false], "sample_631": [false], "sample_632": [false], "sample_633": [false], "sample_634": [false], "sample_635": [false], "sample_636": [false], "sample_637": [false], "sample_638": [false], "sample_639": [false], "sample_640": [false], "sample_641": [false], "sample_642": [false], "sample_643": [false], "sample_644": [false], "sample_645": [false], "sample_646": [false], "sample_647": [false], "sample_648": [false], "sample_649": [false], "sample_650": [false], "sample_651": [false], "sample_652": [true], "sample_653": [false], "sample_654": [true], "sample_655": [true], "sample_656": [true], "sample_657": [false], "sample_658": [false], "sample_659": [false], "sample_660": [false], "sample_661": [false], "sample_662": [false], "sample_663": [true], "sample_664": [false], "sample_665": [true], "sample_666": [true], "sample_667": [false], "sample_668": [false], "sample_669": [true], "sample_670": [false], "sample_671": [false], "sample_672": [false], "sample_673": [true], "sample_674": [false], "sample_675": [false], "sample_676": [true], "sample_677": [false], "sample_678": [false], "sample_679": [false], "sample_680": [true], "sample_681": [false], "sample_682": [true], "sample_683": [true], "sample_684": [false], "sample_685": [false], "sample_686": [false], "sample_687": [false], "sample_688": [true], "sample_689": [false], "sample_690": [true], "sample_691": [false], "sample_692": [false], "sample_693": [false], "sample_694": [false], "sample_695": [false], "sample_696": [false], "sample_697": [false], "sample_698": [false], "sample_699": [true], "sample_700": [true], "sample_701": [false], "sample_702": [false], "sample_703": [false], "sample_704": [false], "sample_705": [false], "sample_706": [false], "sample_707": [false], "sample_708": [false], "sample_709": [false], "sample_710": [false], "sample_711": [false], "sample_712": [true], "sample_713": [false], "sample_714": [false], "sample_715": [true], "sample_716": [true], "sample_717": [true], "sample_718": [false], "sample_719": [true], "sample_720": [false], "sample_721": [false], "sample_722": [false], "sample_723": [true], "sample_724": [false], "sample_725": [false], "sample_726": [false], "sample_727": [true], "sample_728": [false], "sample_729": [true], "sample_730": [false], "sample_731": [false], "sample_732": [true], "sample_733": [true], "sample_734": [false], "sample_735": [false], "sample_736": [true], "sample_737": [true], "sample_738": [true], "sample_739": [false], "sample_740": [false], "sample_741": [false], "sample_742": [true], "sample_743": [false], "sample_744": [false], "sample_745": [false], "sample_746": [false], "sample_747": [false], "sample_748": [false], "sample_749": [false], "sample_750": [true], "sample_751": [false], "sample_752": [false], "sample_753": [true], "sample_754": [false], "sample_755": [false], "sample_756": [false], "sample_757": [true], "sample_758": [true], "sample_759": [true], "sample_760": [false], "sample_761": [true], "sample_762": [false], "sample_763": [true], "sample_764": [true], "sample_765": [false], "sample_766": [true], "sample_767": [false], "sample_768": [true], "sample_769": [true], "sample_770": [false], "sample_771": [true], "sample_772": [true], "sample_773": [false], "sample_774": [true], "sample_775": [false], "sample_776": [false], "sample_777": [false], "sample_778": [false], "sample_779": [false], "sample_780": [false], "sample_781": [true], "sample_782": [false], "sample_783": [true], "sample_784": [false], "sample_785": [true], "sample_786": [false], "sample_787": [false], "sample_788": [false], "sample_789": [false], "sample_790": [false], "sample_791": [true], "sample_792": [false], "sample_793": [false], "sample_794": [true], "sample_795": [false], "sample_796": [false], "sample_797": [true], "sample_798": [false], "sample_799": [false], "sample_800": [false], "sample_801": [false], "sample_802": [false], "sample_803": [false], "sample_804": [true], "sample_805": [false], "sample_806": [false], "sample_807": [false], "sample_808": [false], "sample_809": [false], "sample_810": [false], "sample_811": [false], "sample_812": [false], "sample_813": [false], "sample_814": [false], "sample_815": [true], "sample_816": [true], "sample_817": [false], "sample_818": [true], "sample_819": [false], "sample_820": [false], "sample_821": [false], "sample_822": [false], "sample_823": [false], "sample_824": [true], "sample_825": [true], "sample_826": [false], "sample_827": [false], "sample_828": [true], "sample_829": [true], "sample_830": [false], "sample_831": [false], "sample_832": [false], "sample_833": [false], "sample_834": [false], "sample_835": [false], "sample_836": [false], "sample_837": [false], "sample_838": [false], "sample_839": [true], "sample_840": [true], "sample_841": [false], "sample_842": [true], "sample_843": [true], "sample_844": [false], "sample_845": [true], "sample_846": [false], "sample_847": [true], "sample_848": [true], "sample_849": [false], "sample_850": [false], "sample_851": [false], "sample_852": [false], "sample_853": [false], "sample_854": [false], "sample_855": [false], "sample_856": [true], "sample_857": [false], "sample_858": [false], "sample_859": [true], "sample_860": [false], "sample_861": [false], "sample_862": [true], "sample_863": [false], "sample_864": [false], "sample_865": [false], "sample_866": [false], "sample_867": [false], "sample_868": [false], "sample_869": [false], "sample_870": [true], "sample_871": [false], "sample_872": [false], "sample_873": [false], "sample_874": [false], "sample_875": [true], "sample_876": [false], "sample_877": [false], "sample_878": [true], "sample_879": [true], "sample_880": [false], "sample_881": [false], "sample_882": [true], "sample_883": [false], "sample_884": [false], "sample_885": [true], "sample_886": [true], "sample_887": [true], "sample_888": [false], "sample_889": [true], "sample_890": [false], "sample_891": [false], "sample_892": [true], "sample_893": [false], "sample_894": [false], "sample_895": [true], "sample_896": [false], "sample_897": [false], "sample_898": [false], "sample_899": [false], "sample_900": [true], "sample_901": [false], "sample_902": [false], "sample_903": [true], "sample_904": [false], "sample_905": [false], "sample_906": [false], "sample_907": [false], "sample_908": [false], "sample_909": [false], "sample_910": [false], "sample_911": [false], "sample_912": [true], "sample_913": [true], "sample_914": [true], "sample_915": [false], "sample_916": [false], "sample_917": [false], "sample_918": [true], "sample_919": [false], "sample_920": [false], "sample_921": [false], "sample_922": [true], "sample_923": [false], "sample_924": [false], "sample_925": [false], "sample_926": [false], "sample_927": [false], "sample_928": [false], "sample_929": [false], "sample_930": [false], "sample_931": [false], "sample_932": [false], "sample_933": [false], "sample_934": [false], "sample_935": [false], "sample_936": [true], "sample_937": [false], "sample_938": [false], "sample_939": [false], "sample_940": [false], "sample_941": [true], "sample_942": [false], "sample_943": [false], "sample_944": [false], "sample_945": [false], "sample_946": [false], "sample_947": [false], "sample_948": [false], "sample_949": [false], "sample_950": [false], "sample_951": [false], "sample_952": [false], "sample_953": [true], "sample_954": [false], "sample_955": [false], "sample_956": [false], "sample_957": [true], "sample_958": [false], "sample_959": [false], "sample_960": [false], "sample_961": [false], "sample_962": [true], "sample_963": [false], "sample_964": [false], "sample_965": [false], "sample_966": [false], "sample_967": [false], "sample_968": [false], "sample_969": [false], "sample_970": [false], "sample_971": [true], "sample_972": [true], "sample_973": [false], "sample_974": [false], "sample_975": [false], "sample_976": [false], "sample_977": [false], "sample_978": [false], "sample_979": [false], "sample_980": [false], "sample_981": [false], "sample_982": [false], "sample_983": [true], "sample_984": [false], "sample_985": [false], "sample_986": [false], "sample_987": [false], "sample_988": [true], "sample_989": [false], "sample_990": [false], "sample_991": [false], "sample_992": [false], "sample_993": [false], "sample_994": [false], "sample_995": [true], "sample_996": [true], "sample_997": [false], "sample_998": [true], "sample_999": [true], "sample_1000": [true], "sample_1001": [false], "sample_1002": [true], "sample_1003": [false], "sample_1004": [false], "sample_1005": [true], "sample_1006": [false], "sample_1007": [false], "sample_1008": [true], "sample_1009": [false], "sample_1010": [false], "sample_1011": [false], "sample_1012": [true], "sample_1013": [true], "sample_1014": [false], "sample_1015": [false], "sample_1016": [false], "sample_1017": [true], "sample_1018": [false], "sample_1019": [false], "sample_1020": [false], "sample_1021": [false], "sample_1022": [false], "sample_1023": [false], "sample_1024": [true], "sample_1025": [false], "sample_1026": [true], "sample_1027": [false], "sample_1028": [false], "sample_1029": [true], "sample_1030": [false], "sample_1031": [false], "sample_1032": [false], "sample_1033": [false], "sample_1034": [false], "sample_1035": [false], "sample_1036": [false], "sample_1037": [false], "sample_1038": [false], "sample_1039": [true], "sample_1040": [false], "sample_1041": [false], "sample_1042": [true], "sample_1043": [false], "sample_1044": [false], "sample_1045": [false], "sample_1046": [false], "sample_1047": [true], "sample_1048": [false], "sample_1049": [false], "sample_1050": [true], "sample_1051": [false], "sample_1052": [true], "sample_1053": [false], "sample_1054": [true], "sample_1055": [false], "sample_1056": [false], "sample_1057": [false], "sample_1058": [true], "sample_1059": [false], "sample_1060": [true], "sample_1061": [true], "sample_1062": [false], "sample_1063": [true], "sample_1064": [true], "sample_1065": [false], "sample_1066": [false], "sample_1067": [false], "sample_1068": [false], "sample_1069": [true], "sample_1070": [false], "sample_1071": [false], "sample_1072": [false], "sample_1073": [false], "sample_1074": [true], "sample_1075": [false], "sample_1076": [false], "sample_1077": [false], "sample_1078": [true], "sample_1079": [false], "sample_1080": [false], "sample_1081": [false], "sample_1082": [false], "sample_1083": [false], "sample_1084": [false], "sample_1085": [true], "sample_1086": [true], "sample_1087": [false], "sample_1088": [false], "sample_1089": [true], "sample_1090": [false], "sample_1091": [false], "sample_1092": [true], "sample_1093": [false], "sample_1094": [false], "sample_1095": [false], "sample_1096": [true], "sample_1097": [false], "sample_1098": [true], "sample_1099": [false], "sample_1100": [true], "sample_1101": [false], "sample_1102": [false], "sample_1103": [false], "sample_1104": [true], "sample_1105": [false], "sample_1106": [false], "sample_1107": [false], "sample_1108": [false], "sample_1109": [false], "sample_1110": [true], "sample_1111": [false], "sample_1112": [false], "sample_1113": [false], "sample_1114": [false], "sample_1115": [false], "sample_1116": [false], "sample_1117": [true], "sample_1118": [false], "sample_1119": [false], "sample_1120": [false], "sample_1121": [false], "sample_1122": [true], "sample_1123": [false], "sample_1124": [false], "sample_1125": [false], "sample_1126": [false], "sample_1127": [false], "sample_1128": [true], "sample_1129": [false], "sample_1130": [true], "sample_1131": [false], "sample_1132": [false], "sample_1133": [false], "sample_1134": [true], "sample_1135": [true], "sample_1136": [false], "sample_1137": [false], "sample_1138": [false], "sample_1139": [false], "sample_1140": [true], "sample_1141": [true], "sample_1142": [false], "sample_1143": [false], "sample_1144": [false], "sample_1145": [false], "sample_1146": [true], "sample_1147": [true], "sample_1148": [false], "sample_1149": [true], "sample_1150": [false], "sample_1151": [false], "sample_1152": [false], "sample_1153": [false], "sample_1154": [false], "sample_1155": [false], "sample_1156": [false], "sample_1157": [true], "sample_1158": [false], "sample_1159": [false], "sample_1160": [true], "sample_1161": [true], "sample_1162": [false], "sample_1163": [false], "sample_1164": [false], "sample_1165": [false], "sample_1166": [false], "sample_1167": [true], "sample_1168": [false], "sample_1169": [false], "sample_1170": [true], "sample_1171": [false], "sample_1172": [false], "sample_1173": [false], "sample_1174": [false], "sample_1175": [false], "sample_1176": [false], "sample_1177": [false], "sample_1178": [false], "sample_1179": [true], "sample_1180": [false], "sample_1181": [true], "sample_1182": [false], "sample_1183": [true], "sample_1184": [false], "sample_1185": [false], "sample_1186": [false], "sample_1187": [false], "sample_1188": [false], "sample_1189": [true], "sample_1190": [false], "sample_1191": [false], "sample_1192": [false], "sample_1193": [false], "sample_1194": [false], "sample_1195": [false], "sample_1196": [false], "sample_1197": [false], "sample_1198": [false], "sample_1199": [false], "sample_1200": [false], "sample_1201": [false], "sample_1202": [false], "sample_1203": [false], "sample_1204": [true], "sample_1205": [false], "sample_1206": [true], "sample_1207": [false], "sample_1208": [false], "sample_1209": [false]}}