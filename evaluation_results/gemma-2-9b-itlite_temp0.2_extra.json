{"raw_generations": {"sample_47": ["    def test_minimize_rollbacks_circular(self):\n        \"\"\"\n        Minimize rollbacks when there are circular dependencies.\n\n        a: 1 <--- 2\n        b:    \\- 1\n        c:     \\- 1\n\n        If a1 is applied already and a2 is not, and we're asked to migrate to\n        a1, don't apply or unapply b1 or c1, regardless of their current state.\n        \"\"\"\n        a1_impl = FakeMigration('a1')\n        a1 = ('a', '1')\n        a2_impl = FakeMigration('a2')\n        a2 = ('a', '2')\n        b1_impl = FakeMigration('b1')\n        b1 = ('b', '1')\n        c1_impl = FakeMigration('c1')\n        c1 = ('c', '1')\n        graph = MigrationGraph()\n        graph.add_node(a1, a1_impl)\n        graph.add_node(a2, a2_impl)\n        graph.add_node(b1, b1_impl)\n        graph.add_node(c1, c1_impl)\n        graph.add_dependency(None, a2, a1)\n        graph.add_dependency(None, b1, a1)\n        graph.add_dependency(None, c1, a1)\n        graph.add_dependency(None, a1, b1)\n        graph.add_dependency(None, a1, c1)\n\n        executor = MigrationExecutor(None)\n        executor.loader = FakeLoader(graph, {\n            a1: a1_impl,\n            b1: b1_impl,\n        })\n\n        plan = executor.migration_plan({a1})\n\n        self.assertEqual(plan, [])\n"], "sample_12": ["    def test_mti_inheritance_model_removal_with_fk(self):\n        \"\"\"\n        #23316 - Removing a model in an MTI hierarchy with FKs\n        should remove the FK from the parent model.\n        \"\"\"\n        Owner = ModelState('app', 'Owner', [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"pet\", models.ForeignKey(\"app.Pet\", models.CASCADE)),\n        ])\n        Pet = ModelState('app', 'Pet', [], bases=('app.Animal',))\n        Animal = ModelState('app', 'Animal', [\n            (\"id\", models.AutoField(primary_key=True)),\n        ])\n        changes = self.get_changes([Owner, Pet, Animal], [Owner, Animal])\n        self.assertNumberMigrations(changes, 'app', 1)\n        self.assertOperationTypes(changes, 'app', 0, ['DeleteModel', 'RemoveField'])\n        self.assertOperationAttributes(changes, 'app', 0, 0, name='Pet')\n        self.assertOperationAttributes(changes, 'app', 0, 1, name='Owner', model_name='Owner', field_name='pet')\n"], "sample_90": ["    def test_parametrize_with_markers_from_fixture(testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n                return pytest.mark.my_fixture_marker\n\n            @pytest.mark.parametrize(\"arg\", [1, 2, 3], ids=[\"one\", \"two\", \"three\"])\n            @pytest.mark.parametrize(\"marker\", [my_marker], indirect=True)\n                assert arg == 1\n                assert marker.name == \"my_fixture_marker\"\n        \"\"\"\n        )\n        reprec = testdir.inline_run()\n        reprec.assertoutcome(passed=3)\n"], "sample_34": ["    def test_app_default_auto_field_override(self, apps):\n        class ModelWithPkViaAppConfig(models.Model):\n            class Meta:\n                app_label = 'check_framework.apps.CheckPKConfig'\n                default_auto_field = 'django.db.models.BigAutoField'\n\n        self.assertEqual(checks.run_checks(app_configs=apps.get_app_configs()), [])\n"], "sample_86": ["compilation error"], "sample_120": ["def test_transpose_simplify():\n    A = MatrixSymbol('A', n, m)\n    assert (A.T).T == A\n    assert (A + B).T == A.T + B.T\n    assert (A*B).T == B.T * A.T\n    assert (MatPow(A, 2)).T == MatPow(A.T, 2)\n    assert (Inverse(A)).T == Inverse(A.T)\n"], "sample_100": ["def test_one_hot_encoder_sparse_output():\n    X = np.array([['abc', 2, 55], ['def', 1, 55]])\n    enc = OneHotEncoder(sparse=True)\n    X_tr = enc.fit_transform(X)\n    assert isinstance(X_tr, sparse.csr_matrix)\n    assert X_tr.shape == (2, 6)\n\n    enc = OneHotEncoder(sparse=True, handle_unknown='ignore')\n    X_tr = enc.fit_transform(X)\n    assert isinstance(X_tr, sparse.csr_matrix)\n    assert X_tr.shape == (2, 6)\n\n    # check that sparse output is consistent with dense output\n    enc = OneHotEncoder()\n    X_tr_dense = enc.fit_transform(X)\n    enc_sparse = OneHotEncoder(sparse=True)\n    X_tr_sparse = enc_sparse.fit_transform(X)\n    assert_array_equal(X_tr_dense.toarray(), X_tr_sparse.toarray())\n\n\n\n"], "sample_146": ["def test_issue_19670():\n    from sympy.tensor import tensor_indices\n    a = tensor_indices('a')\n    b = tensor_indices('b')\n    c = tensor_indices('c')\n    expr = a[b, c]\n    assert str(expr) == 'a[b, c]'\n"], "sample_64": ["    def test_date_hierarchy_with_custom_field(self):\n        class CustomFieldModelAdmin(ModelAdmin):\n            date_hierarchy = \"custom_date\"\n\n        class CustomField(models.Model):\n            custom_date = models.DateField()\n\n        custom_field_admin = CustomFieldModelAdmin(CustomField, site)\n        custom_field = CustomField.objects.create(custom_date=datetime.date(2023, 10, 26))\n        request = self.factory.get(\"/\", {})\n        request.user = self.superuser\n        changelist = custom_field_admin.get_changelist_instance(request)\n        spec = date_hierarchy(changelist)\n        self.assertEqual(spec[\"choices\"], [])\n"], "sample_76": ["    def test_order_too_high(self, df):\n\n        groupby = GroupBy([\"group\"])\n        res = PolyFit(order=df[\"x\"].nunique() + 1)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n        assert res.empty\n"], "sample_74": ["def test_colorbar_fraction():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cb = fig.colorbar(im, fraction=0.2)\n    assert cb.ax.get_position().height == 0.2\n    cb = fig.colorbar(im, fraction=0.5)\n    assert cb.ax.get_position().height == 0.5\n    cb = fig.colorbar(im, fraction=0.8)\n    assert cb.ax.get_position().height == 0.8\n\n\n\n"], "sample_62": ["    def test_cache_handler_with_custom_key_prefix(self):\n        test_caches = CacheHandler(\n            {\n                \"cache_1\": {\n                    \"BACKEND\": \"django.core.cache.backends.dummy.DummyCache\",\n                    \"KEY_PREFIX\": \"custom_prefix_\",\n                },\n                \"cache_2\": {\n                    \"BACKEND\": \"django.core.cache.backends.dummy.DummyCache\",\n                },\n            }\n        )\n        cache_1 = test_caches[\"cache_1\"]\n        cache_2 = test_caches[\"cache_2\"]\n        self.assertEqual(cache_1.key_prefix, \"custom_prefix_\")\n        self.assertEqual(cache_2.key_prefix, \"\")\n\n"], "sample_52": ["    def test_references_field_by_related_name(self):\n        operation = FieldOperation(\n            \"Model\",\n            \"field\",\n            models.ForeignKey(\"Other\", models.CASCADE, related_name=\"related_name\"),\n        )\n        self.assertIs(\n            operation.references_field(\"Other\", \"related_name\", \"migrations\"), True\n        )\n        self.assertIs(\n            operation.references_field(\"Other\", \"whatever\", \"migrations\"), False\n        )\n"], "sample_29": ["    def test_output_field_override(self):\n        expr = ExpressionWrapper(F('name'), output_field=CharField(max_length=10))\n        self.assertEqual(expr.output_field, CharField(max_length=10))\n"], "sample_66": ["    def test_actions_with_custom_permissions_has_method(self):\n        @admin.action(permissions=[\"custom\"])\n            pass\n\n        class BandAdmin(ModelAdmin):\n            actions = (custom_permission_action,)\n\n        class BandAdminWithHasMethod(ModelAdmin):\n                return request.user.is_staff\n\n            actions = (custom_permission_action,)\n\n        self.assertIsValid(BandAdminWithHasMethod, Band)\n"], "sample_51": ["    def test_was_modified_since_future_time(self):\n        mtime = 1343416141\n        header = http_date(mtime + 1)\n        self.assertTrue(was_modified_since(header, mtime))\n"], "sample_59": ["    def test_custom_renderer_with_management_form(self):\n        class CustomRenderer(TemplatesSetting):\n            formset_template_name = \"a/custom/formset/template.html\"\n\n        ChoiceFormSet = formset_factory(Choice, renderer=CustomRenderer)\n        formset = ChoiceFormSet()\n        self.assertEqual(formset.management_form.renderer, CustomRenderer)\n"], "sample_114": ["compilation error"], "sample_9": ["    def test_snapshot_files_with_non_existing_files(self):\n        with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file, self.nonexistent_file]):\n            snapshot = dict(self.reloader.snapshot_files())\n            self.assertIn(self.existing_file, snapshot)\n            self.assertNotIn(self.nonexistent_file, snapshot)\n"], "sample_49": ["    def test_template_directories_order(self):\n        self.assertSetEqual(\n            autoreload.get_template_directories(),\n            {\n                ROOT / 'templates_extra',\n                ROOT / 'templates',\n            }\n        )\n"], "sample_147": ["def test_nfloat_dict():\n    from sympy.core.symbol import Symbol\n    x = Symbol('x')\n    y = Symbol('y')\n    expr = {x: x**2, y: y + 1}\n    nfloat_expr = nfloat(expr, dkeys=True)\n    assert isinstance(nfloat_expr, dict)\n    assert nfloat_expr[x] == x**2\n    assert isinstance(nfloat_expr[y], float)\n    assert nfloat_expr[y] == y + 1\n\n\n\n"], "sample_135": ["def test_rewrite_with_undefined_functions():\n    from sympy.core.function import UndefinedFunction as UndefFunc\n    x = symbols('x')\n    f = UndefFunc('f')\n    g = UndefFunc('g')\n    assert f(x).rewrite(g) == f(x)\n    assert (f(x) + g(x)).rewrite(g) == f(x) + g(x)\n"], "sample_33": ["    def test_receiver_dispatch_uid(self):\n        @receiver(a_signal, dispatch_uid=\"uid\")\n            self.state = val\n        self.state = False\n        a_signal.send(sender=self, val=True)\n        self.assertTrue(self.state)\n\n        @receiver(a_signal, dispatch_uid=\"uid\")\n            self.state = val\n        a_signal.send(sender=self, val=False)\n        self.assertFalse(self.state)\n"], "sample_156": ["def test_parser_mathematica_complex_expressions():\n    parser = MathematicaParser()\n\n    full_form1 = \"Simplify[Log[x^2 + y^2, e]]\"\n    full_form2 = \"Expand[Sin[x + y]^2]\"\n    full_form3 = \"Integrate[x^2*Sin[x], x]\"\n    full_form4 = \"Solve[x^2 + y^2 == 1, {x, y}]\"\n    full_form5 = \"Limit[Sin[x]/x, x->0]\"\n\n    assert parser._from_fullform_to_fullformlist(full_form1) == [\"Simplify\", [\"Log\", [\"Power\", \"x\", \"2\"], [\"Plus\", \"y\", \"2\"], \"e\"]]\n    assert parser._from_fullform_to_fullformlist(full_form2) == [\"Expand\", [\"Sin\", [\"Plus\", \"x\", \"y\"], \"2\"]]\n    assert parser._from_fullform_to_fullformlist(full_form3) == [\"Integrate\", [\"Times\", \"x\", \"2\", \"Sin\", \"x\"], \"x\"]\n    assert parser._from_fullform_to_fullformlist(full_form4) == [\"Solve\", [\"Equals\", [\"Plus\", \"x\", \"2\"], \"y\", \"2\"], {\"x\", \"y\"}]\n    assert parser._from_fullform_to_fullformlist(full_form5) == [\"Limit\", [\"Sin\", \"x\"], \"x\", \"0\"]\n\n\n\n"], "sample_149": ["compilation error"], "sample_151": ["compilation error"], "sample_38": ["    def test_password_complexity_validation(self):\n        user = User.objects.get(username='testclient')\n        data = {'password1': 'test'}\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertIn(\n            'This password is too short. It must contain at least 8 characters.',\n            form.errors['password1']\n        )\n"], "sample_102": ["def test_iforest_sparse_data():\n    \"\"\"Test Isolation Forest with sparse data.\"\"\"\n    from sklearn.datasets import make_sparse_coded_data\n    X, y = make_sparse_coded_data(n_samples=100, n_features=100,\n                                  random_state=0)\n    clf = IsolationForest(random_state=0).fit(X)\n    clf.predict(X)\n"], "sample_5": ["    def test_fast_delete_related_m2m_with_null_related_field(self):\n        m = M.objects.create()\n        r = R.objects.create()\n        MR.objects.create(m=m, r=r)\n        m.m2m.add(r)\n        m.delete(keep_parents=True)\n        self.assertFalse(MR.objects.filter(m_id=m.pk).exists())\n        self.assertTrue(R.objects.filter(pk=r.pk).exists())\n"], "sample_8": ["    def test_cleanse_setting_handles_nested_dictionaries(self):\n        initial = {'user': {'name': 'john', 'password': 'doe'}}\n        expected = {'user': {'name': 'john', 'password': CLEANSED_SUBSTITUTE}}\n        self.assertEqual(cleanse_setting('SETTING_NAME', initial), expected)\n"], "sample_105": ["def test_partial_fit():\n    \"\"\"Check partial_fit functionality of VotingClassifier.\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2),\n                ('gnb', clf3)], voting='soft')\n\n    X_train = X[:5]\n    y_train = y[:5]\n    X_test = X[5:]\n    y_test = y[5:]\n\n    eclf.partial_fit(X_train, y_train)\n    assert_array_almost_equal(eclf.predict(X_test),\n                              eclf.predict(X_test))\n    eclf.partial_fit(X_train[5:], y_train[5:])\n    assert_array_almost_equal(eclf.predict(X_test),\n                              eclf.predict(X_test))\n    eclf.partial_fit(X_train, y_train, classes=np.unique(y))\n    assert_array_almost_equal(eclf.predict(X_test),\n                              eclf.predict(X_test))\n\n\n\n"], "sample_48": ["    def test_references_field_by_related_name(self):\n        operation = FieldOperation('Model', 'field', models.ForeignKey('Other', models.CASCADE, related_name='related_field'))\n        self.assertIs(operation.references_field('Other', 'related_field', 'migrations'), True)\n        self.assertIs(operation.references_field('Other', 'whatever', 'migrations'), False)\n"], "sample_27": ["    def test_token_generation_with_custom_email_field(self):\n        \"\"\"\n        Test token generation with a custom email field.\n        \"\"\"\n        CustomEmailField.objects.create(user=User.objects.create_user('custom_email_user', 'test5@example.com', 'testpw'))\n        p0 = PasswordResetTokenGenerator()\n        tk1 = p0.make_token(User.objects.get(username='custom_email_user'))\n        self.assertIs(p0.check_token(User.objects.get(username='custom_email_user'), tk1), True)\n"], "sample_138": ["def test_block_collapse_with_matrices():\n    A = Matrix([[1, 2], [3, 4]])\n    B = Matrix([[5, 6], [7, 8]])\n    C = BlockMatrix([[A, B]])\n    assert block_collapse(C) == BlockMatrix([[A, B]])\n    assert block_collapse(C + C) == BlockMatrix([[2*A, 2*B]])\n    assert block_collapse(C * C) == BlockMatrix([[A*A + B*B, A*B + B*A]])\n"], "sample_134": ["def test_issue_17006_sparse():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    from sympy.sparse.matrices import SparseMatrix\n    M = SparseMatrix(((1, 0), (0, 1)), shape=(2, 2))\n\n    f = lambdify(M, M + Identity(2))\n    ma = np.array([[1, 2], [3, 4]])\n    mr = np.array([[2, 2], [3, 5]])\n\n    assert (f(M) == mr).all()\n"], "sample_118": ["def test_ccode_complex():\n    from sympy import I, symbols\n    x, y = symbols('x y', complex=True)\n    assert ccode(x + I*y) == 'x + I*y'\n    assert ccode(x*y) == 'x*y'\n    assert ccode(x**2) == 'pow(x, 2)'\n    assert ccode(sqrt(x + I*y)) == 'sqrt(x + I*y)'\n"], "sample_108": ["def test_svc_probability_with_precomputed_kernel():\n    # Test that probability estimates are available when using a precomputed kernel\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([0, 1, 0])\n    kernel = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n    clf = svm.SVC(probability=True, kernel='precomputed').fit(kernel, y)\n    assert hasattr(clf, 'predict_proba')\n    assert_array_almost_equal(clf.predict_proba(kernel), clf.predict_proba(X))\n"], "sample_77": ["    def test_label_format(self, t):\n\n        fmt = \"%b %Y\"\n        s = Temporal().label(fmt)._setup(t, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"Sep 1972\"\n"], "sample_116": ["def test_create_index_with_subentries(app):\n    text = (\".. index:: pair: docutils; reStructuredText\\n\"\n            \".. index:: pair: Python; interpreter\\n\"\n            \".. index:: pair: Sphinx; documentation tool\\n\"\n            \".. index:: pair: Sphinx; :+1:\\n\"\n            \".. index:: pair: Sphinx; \u0415\u043b\u044c\\n\"\n            \".. index:: pair: Sphinx; \u0451\u043b\u043a\u0430\\n\"\n            \".. index:: pair: Sphinx; subentry1\\n\"\n            \".. index:: pair: Sphinx; subentry2\\n\"\n            \".. index:: pair: Sphinx; subentry3\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 7\n    assert index[0] == ('Symbols', [(':+1:', [[], [('Sphinx', [('', '#index-3')])], None])])\n    assert index[1] == ('D',\n                        [('documentation tool', [[], [('Sphinx', [('', '#index-2')])], None]),\n                         ('docutils', [[], [('reStructuredText', [('', '#index-0')])], None])])\n    assert index[2] == ('I', [('interpreter', [[], [('Python', [('', '#index-1')])], None])])\n    assert index[3] == ('P', [('Python', [[], [('interpreter', [('', '#index-1')])], None])])\n    assert index[4] == ('R', [('reStructuredText', [[], [('docutils', [('', '#index-0')])], None])])\n    assert index[5] == ('S',\n                        [('Sphinx', [[],\n                                     [(':+1:', [('', '#index-3')]),\n                                      ('documentation tool', [('', '#index-2')]),\n                                      ('\u0451\u043b\u043a\u0430', [('', '#index-5')]),\n                                      ('\u0415\u043b\u044c', [('', '#index-4')]),\n                                      ('subentry1', [('', '#index-6')]),\n                                      ('subentry2', ["], "sample_83": ["def test_template_option_with_custom_fields(linter: PyLinter) -> None:\n    output = StringIO()\n    linter.reporter.out = output\n    linter.config.msg_template = \"{path}:{line}:{column}:{msg_id} ({symbol}) - {obj}\"\n    linter.open()\n    linter.set_current_module(\"my_mod\")\n\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\n        \"line-too-long\", line=2, end_lineno=2, end_col_offset=4, args=(3, 4)\n    )\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert out_lines[1] == \"my_mod:1:0:C0301 (line-too-long) - \"\n    assert out_lines[2] == \"my_mod:2:0:line-too-long (line-too-long) - \"\n"], "sample_30": ["    def test_inline_formset_error_input_border_with_multiple_errors(self):\n        self.admin_login(username='super', password='secret')\n        self.selenium.get(self.live_server_url + reverse('admin:admin_inlines_holder5_add'))\n        stacked_inline_formset_selector = 'div#inner5stacked_set-group fieldset.module.collapse'\n        tabular_inline_formset_selector = 'div#inner5tabular_set-group fieldset.module.collapse'\n        # Inlines without errors, both inlines collapsed\n        self.selenium.find_element_by_xpath('//input[@value=\"Save\"]').click()\n        self.assertEqual(\n            len(self.selenium.find_elements_by_css_selector(stacked_inline_formset_selector + '.collapsed')), 1\n        )\n        self.assertEqual(\n            len(self.selenium.find_elements_by_css_selector(tabular_inline_formset_selector + '.collapsed')), 1\n        )\n        show_links = self.selenium.find_elements_by_link_text('SHOW')\n        self.assertEqual(len(show_links), 2)\n\n        # Inlines with errors, both inlines expanded\n        test_fields = ['#id_inner5stacked_set-0-dummy', '#id_inner5tabular_set-0-dummy']\n        for show_index, field_name in enumerate(test_fields):\n            show_links[show_index].click()\n            self.wait_until_visible(field_name)\n            self.selenium.find_element_by_id(field_name[1:]).send_keys(1)\n        hide_links = self.selenium.find_elements_by_link_text('HIDE')\n        self.assertEqual(len(hide_links), 2)\n        for hide_index, field_name in enumerate(test_fields):\n            hide_link = hide_links[hide_index]\n            self.selenium.execute_script('window.scrollTo(0, %s);' % hide_link.location['y'])\n            hide_link.click()\n            self.wait_until_invisible("], "sample_37": ["    def test_output_field_from_expression(self):\n        expr = ExpressionWrapper(F('name').lower(), output_field=CharField())\n        self.assertEqual(expr.output_field, CharField())\n"], "sample_94": ["def test_getstatementrange_with_docstring() -> None:\n    source = Source(\n        \"\"\"\n            \"\"\"docstring\n            with\n            multiple\n            lines\"\"\"\n            pass\n        \"\"\"\n    )\n    assert getstatement(0, source).lines == [\"def test_func():\", \"    \"\"\"docstring\\n    with\\n    multiple\\n    lines\"\"\"\",]\n    assert getstatement(2, source).lines == [\"    pass\"]\n"], "sample_17": ["    def test_deserialize_db_from_string_with_foreign_key(self):\n        # deserialize_db_from_string() handles foreign keys.\n        data = \"\"\"\n        [\n            {\n                \"model\": \"backends.objectreference\",\n                \"pk\": 1,\n                \"fields\": {\"obj\": 1}\n            },\n            {\n                \"model\": \"backends.object\",\n                \"pk\": 1,\n                \"fields\": {\"obj_ref\": 1, \"related_objects\": []}\n            }\n        ]\n        \"\"\"\n        connection.creation.deserialize_db_from_string(data)\n        obj_ref = ObjectReference.objects.get()\n        obj = Object.objects.get()\n        self.assertEqual(obj.obj_ref, obj_ref)\n        self.assertEqual(obj_ref.obj, obj)\n"], "sample_54": ["    def test_urlize_trim_url_limit(self):\n        self.assertEqual(\n            urlize(\"This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit\", trim_url_limit=15),\n            \"This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit\",\n        )\n        self.assertEqual(\n            urlize(\"This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit\", trim_url_limit=30),\n            \"This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit\",\n        )\n        self.assertEqual(\n            urlize(\n                \"This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit\",\n                trim_url_limit=10,\n            ),\n            \"This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit\",\n        )\n        self.assertEqual(\n            urlize(\n                \"This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit\",\n                trim_url_limit=20,\n            ),\n            \"This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit\",\n        )\n        self.assertEqual(\n            urlize(\n                \"This is a long URL: http://www.example.com/this-is-a-very-long-url-that-is-longer-than-the-limit\",\n                trim_url_limit=50,\n            ),\n            \"This"], "sample_67": ["    def test_serialize_custom_field(self):\n        class MyCustomField(models.Field):\n                super().__init__(*args, **kwargs)\n\n                return \"MyCustomFieldType\"\n\n                return \"MyCustomFieldType\"\n\n                return super().formfield(**kwargs)\n\n        class MyModel(models.Model):\n            my_field = MyCustomField()\n\n        string, imports = MigrationWriter.serialize(MyModel)\n        self.assertIn(\"MyCustomFieldType\", string)\n        self.assertIn(\"from migrations.test_writer import MyCustomField\", imports)\n"], "sample_152": ["def test_array_shape_mismatch():\n    for ArrayType in array_types:\n        A = ArrayType([[1, 2], [3, 4]])\n        B = ArrayType([[1, 2, 3], [4, 5, 6]])\n        raises(ValueError, lambda: A + B)\n        raises(ValueError, lambda: A - B)\n        raises(ValueError, lambda: A * B)\n        raises(ValueError, lambda: A / B)\n\n\n\n"], "sample_85": ["compilation error"], "sample_68": ["    def test_update_conflicts_no_unique_fields_no_update_fields(self):\n        with self.assertRaises(ValueError):\n            UpsertConflict.objects.bulk_create(\n                [\n                    UpsertConflict(number=1, rank=1, name=\"John\"),\n                    UpsertConflict(number=2, rank=2, name=\"Mary\"),\n                    UpsertConflict(number=3, rank=3, name=\"Hannah\"),\n                ],\n                update_conflicts=True,\n                update_fields=None,\n                unique_fields=[],\n            )\n"], "sample_15": ["    def test_language_code_not_in_languages(self):\n        msg = (\n            'You have provided a value for the LANGUAGE_CODE setting that is '\n            'not in the LANGUAGES setting.'\n        )\n        for tag in ['de', 'es', 'ca']:\n            with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n                self.assertEqual(check_language_settings_consistent(None), [\n                    Error(msg, id='translation.E004'),\n                ])\n"], "sample_126": ["def test_issue_10474():\n    assert Float(1.23456789012345678901234567890123, 100) == Float(1.23456789012345678901234567890123)\n"], "sample_75": ["def test_grid_with_axes_class_not_overriding_axis():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 2), axes_class=mpl.axes.Axes)\n    for ax in grid:\n        ax.plot([1, 2, 3], [4, 5, 6])\n"], "sample_154": ["def test_issue_23343():\n    if not scipy:\n        skip(\"scipy not installed\")\n    x = symbols('x')\n    f = lambdify(x, scipy.special.erf(x), modules='scipy')\n    assert abs(f(0.5) - scipy.special.erf(0.5)) < 1e-10\n"], "sample_111": ["def test_empty_input(metric_name):\n    metric = SUPERVISED_METRICS[metric_name]\n    with pytest.raises(ValueError, match='Input arrays cannot be empty'):\n        metric([], [])\n    with pytest.raises(ValueError, match='Input arrays cannot be empty'):\n        metric([], [0, 1])\n"], "sample_22": ["    def test_camel_case_to_spaces(self):\n        self.assertEqual(text.camel_case_to_spaces('ThisIsACamelCaseString'), 'This Is A Camel Case String')\n        self.assertEqual(text.camel_case_to_spaces('thisIsACamelCaseString'), 'this Is A Camel Case String')\n        self.assertEqual(text.camel_case_to_spaces('this_is_a_camel_case_string'), 'this is a camel case string')\n        self.assertEqual(text.camel_case_to_spaces('snake_case'), 'snake case')\n        self.assertEqual(text.camel_case_to_spaces('PascalCase'), 'Pascal Case')\n        self.assertEqual(text.camel_case_to_spaces('mixedCase'), 'mixed Case')\n        self.assertEqual(text.camel_case_to_spaces(''), '')\n        self.assertEqual(text.camel_case_to_spaces(lazystr('ThisIsACamelCaseString')), 'This Is A Camel Case String')\n"], "sample_87": ["compilation error"], "sample_96": ["def test_ridge_classifier_multiclass():\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5,\n                               n_classes=3, random_state=0)\n    ridge = RidgeClassifier(random_state=0)\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape[0], X.shape[1])\n    assert_equal(ridge.classes_.shape[0], 3)\n\n\n\n"], "sample_82": ["def test_groupby_with_missing_values():\n    # GH2383\n    # test handling of missing values in groupby operations\n    ds = xr.Dataset(\n        {\n            \"foo\": ((\"x\", \"y\"), np.array([[1, 2, np.nan], [3, 4, 5], [np.nan, 6, 7]])),\n            \"bar\": ((\"x\", \"y\"), np.array([[8, 9, 10], [11, 12, np.nan], [13, 14, 15]])),\n        },\n        coords={\"x\": [0, 1, 2], \"y\": [0, 1, 2]},\n    )\n\n    # Test mean with missing values\n    grouped = ds.groupby(\"x\")\n    expected_mean = xr.Dataset(\n        {\n            \"foo\": ((\"y\"), [np.nan, 3.5, 6.5]),\n            \"bar\": ((\"y\"), [9.0, 11.5, 14.5]),\n        },\n        coords={\"x\": [0, 1, 2], \"y\": [0, 1, 2]},\n    )\n    assert_identical(grouped.mean(), expected_mean)\n\n    # Test sum with missing values\n    expected_sum = xr.Dataset(\n        {\n            \"foo\": ((\"y\"), [1, 6, 13]),\n            \"bar\": ((\"y\"), [18, 33, 45]),\n        },\n        coords={\"x\": [0, 1, 2], \"y\": [0, 1, 2]},\n    )\n    assert_identical(grouped.sum(), expected_sum)\n\n    # Test median with missing values\n    expected_median = xr.Dataset(\n        {\n            \"foo\": ((\"y\"), [2.0, 3.5, 6.5]),\n            \"bar\": ((\"y\"), [9.0, 11.5, 14.5]),\n        },\n        coords={\"x\": [0, 1, 2], \"y\": [0, 1, 2]},\n"], "sample_153": ["def test_pretty_print_unicode_v_with_symbols():\n    from sympy.vector import CoordSys3D, Vector\n    from sympy.abc import x, y, z\n\n    N = CoordSys3D('N')\n    v = Vector.zero\n    v = v.subs(N.x, x)\n    v = v.subs(N.y, y)\n    v = v.subs(N.z, z)\n    assert upretty(v) == '0'\n    \n    v = N.i\n    v = v.subs(N.x, x)\n    v = v.subs(N.y, y)\n    v = v.subs(N.z, z)\n    assert upretty(v) == 'i_N'\n"], "sample_26": ["    def test_serialize_deserialize_object_with_large_field(self):\n        # Test serialization and deserialization of an object with a large field.\n        large_text = 'A' * (1024 * 1024)  # 1MB of text\n        obj = Object.objects.create(large_text_field=large_text)\n        data = connection.creation.serialize_db_to_string()\n        Object.objects.all().delete()\n        connection.creation.deserialize_db_from_string(data)\n        deserialized_obj = Object.objects.get()\n        self.assertEqual(deserialized_obj.large_text_field, large_text)\n"], "sample_92": ["    def test_relpath_rootdir_with_relative_import(testdir):\n        testdir.makepyfile(\n            **{\n                \"tests/test_1.py\": \"\"\"\n        import pytest\n        from .submodule import test_sub\n        @pytest.mark.skip()\n            pass\n            \"\"\",\n                \"tests/submodule.py\": \"\"\"\n            pass\n        \"\"\",\n            }\n        )\n        result = testdir.runpytest(\"-rs\", \"tests/test_1.py\", \"--rootdir=tests\")\n        result.stdout.fnmatch_lines(\n            [\"SKIPPED [[]1[]] tests/test_1.py:2: unconditional skip\"]\n        )\n"], "sample_112": ["def test_isotonic_regression_with_missing_values():\n    # Test handling of missing values in input data\n    X = np.array([1, 2, np.nan, 4, 5])\n    y = np.array([2, 4, 1, 6, 7])\n\n    # Check that fit works with missing values\n    ir = IsotonicRegression()\n    with pytest.raises(ValueError, match=\"Input contains missing values\"):\n        ir.fit(X, y)\n\n    # Check that predict works with missing values\n    ir = IsotonicRegression()\n    ir.fit(X, y)\n    with pytest.raises(ValueError, match=\"Input contains missing values\"):\n        ir.predict(np.array([1, 2, np.nan, 4, 5]))\n\n\n\n"], "sample_91": ["    def test_relpath_rootdir_with_relative_path(testdir):\n        testdir.makepyfile(\n            **{\n                \"tests/test_1.py\": \"\"\"\n            import pytest\n            @pytest.mark.skip()\n                pass\n                \"\"\",\n                \"subfolder/test_2.py\": \"\"\"\n            import pytest\n            @pytest.mark.skip()\n                pass\n                \"\"\",\n            }\n        )\n        result = testdir.runpytest(\n            \"-rs\", \"tests/test_1.py\", \"--rootdir=tests\"\n        )\n        result.stdout.fnmatch_lines(\n            [\"SKIPPED [[]1[]] tests/test_1.py:2: unconditional skip\"]\n        )\n        result = testdir.runpytest(\n            \"-rs\", \"subfolder/test_2.py\", \"--rootdir=tests\"\n        )\n        result.stdout.fnmatch_lines(\n            [\"SKIPPED [[]1[]] subfolder/test_2.py:2: unconditional skip\"]\n        )\n"], "sample_10": ["    def test_exact_query_rhs_with_selected_columns_multiple_values(self):\n        newest_author1 = Author.objects.create(name='Author 2')\n        newest_author2 = Author.objects.create(name='Author 3')\n        authors_max_ids = Author.objects.filter(\n            name__in=['Author 2', 'Author 3'],\n        ).values(\n            'name',\n        ).annotate(\n            max_id=Max('id'),\n        ).values('max_id')\n        authors = Author.objects.filter(id__in=authors_max_ids)\n        self.assertCountEqual(authors, [newest_author1, newest_author2])\n"], "sample_31": ["    def test_no_startup_option(self):\n        with captured_stdout() as stdout:\n            call_command('shell', no_startup=True)\n        self.assertEqual(stdout.getvalue().strip(), '')  # No startup files executed\n"], "sample_155": ["def test_issue_25325():\n    from sympy.physics.units import Quantity, meter, second, kilogram, joule\n\n    q1 = Quantity('q1', dimension=meter)\n    q2 = Quantity('q2', dimension=second)\n    q3 = Quantity('q3', dimension=kilogram)\n    q4 = Quantity('q4', dimension=joule)\n\n    assert (q1 + q2).dimension == meter\n    assert (q1 * q2).dimension == meter * second\n    assert (q1 / q2).dimension == meter / second\n    assert (q1 ** 2).dimension == meter**2\n    assert (q1 ** q2).dimension == meter**(second)\n    assert (q1 ** q3).dimension == meter**(kilogram)\n    assert (q1 ** q4).dimension == meter**(joule)\n"], "sample_42": ["    def test_serialize_custom_field(self):\n        class MyCustomField(models.Field):\n                super().__init__(**kwargs)\n\n                return 'MyCustomDbType'\n\n                return value\n\n                return value\n\n        class MyModel(models.Model):\n            my_field = MyCustomField()\n\n        with self.subTest(serialize=True):\n            self.assertSerializedResultEqual(\n                MyModel._meta.get_field('my_field'),\n                (\n                    \"migrations.test_writer.MyCustomField\",\n                    {'import migrations.test_writer'},\n                )\n            )\n\n        with self.subTest(deserialize=True):\n            field = self.serialize_round_trip(MyModel._meta.get_field('my_field'))\n            self.assertIsInstance(field, MyCustomField)\n"], "sample_107": ["def test_LogisticRegression_fit_intercept(penalty):\n    # Test that fit_intercept=False works as expected\n    X, y = make_classification(n_samples=100, random_state=0)\n    lr_fit_intercept = LogisticRegression(penalty=penalty, solver='saga',\n                random_state=0, fit_intercept=True)\n    lr_no_fit_intercept = LogisticRegression(penalty=penalty, solver='saga',\n                random_state=0, fit_intercept=False)\n\n    lr_fit_intercept.fit(X, y)\n    lr_no_fit_intercept.fit(X, y)\n\n    # Check that intercept is None when fit_intercept is False\n    assert lr_no_fit_intercept.intercept_ is None\n\n    # Check that the coefficients are different when fit_intercept is True/False\n    assert not np.allclose(lr_fit_intercept.coef_, lr_no_fit_intercept.coef_)\n\n"], "sample_98": ["compilation error"], "sample_95": ["compilation error"], "sample_142": ["compilation error"], "sample_130": ["def test_issue_15049():\n    # Test for issue 15049: lambdify with complex symbols\n    x = symbols('x', complex=True)\n    f = lambdify(x, x**2)\n    assert f(2 + 3j) == (2 + 3j)**2\n"], "sample_110": ["def test_affinity_propagation_preference_handling():\n    # Test the handling of preference parameter\n    X = np.array([[1, 1], [-1, -1], [1, -1]])\n    S = -euclidean_distances(X, squared=True)\n\n    # Test with preference equal to median similarity\n    preference = np.median(S)\n    cluster_centers_indices, labels = affinity_propagation(S, preference=preference)\n    assert len(cluster_centers_indices) > 0\n\n    # Test with preference smaller than all similarities\n    preference = np.min(S) - 1\n    cluster_centers_indices, labels = affinity_propagation(S, preference=preference)\n    assert len(cluster_centers_indices) == 1\n\n    # Test with preference larger than all similarities\n    preference = np.max(S) + 1\n    cluster_centers_indices, labels = affinity_propagation(S, preference=preference)\n    assert len(cluster_centers_indices) == 3\n\n\n\n"], "sample_136": ["def test_block_collapse_with_matrices():\n    A = Matrix([[1, 2], [3, 4]])\n    B = Matrix([[5, 6], [7, 8]])\n    C = BlockMatrix([[A, B]])\n    assert block_collapse(C) == BlockMatrix([[A, B]])\n    assert block_collapse(C + C) == BlockMatrix([[2*A, 2*B]])\n    assert block_collapse(C * C) == BlockMatrix([[A*A + B*B, A*B + B*A]])\n"], "sample_84": ["compilation error"], "sample_131": ["def test_user_functions():\n        return x**2 + 1\n    \n    settings = {'user_functions': {'my_func': [lambda x: True, 'MyFunc']}}\n    assert mcode(my_func(x), **settings) == \"MyFunc[x]\"\n"], "sample_50": ["    def test_not_finished_sentinel(self):\n        storage = self.get_storage()\n        response = self.get_response()\n\n        # Add a few messages\n        storage.add(constants.INFO, 'message 1')\n        storage.add(constants.INFO, 'message 2')\n        storage.add(constants.INFO, 'message 3')\n\n        # Update the response with the messages\n        storage.update(response)\n\n        # Retrieve the messages from the cookie\n        messages = storage._decode(response.cookies['messages'].value)\n\n        # Check that the sentinel value is present\n        self.assertEqual(messages[-1], CookieStorage.not_finished)\n\n        # Remove the sentinel value\n        messages.pop()\n\n        # Check that the number of messages retrieved is correct\n        self.assertEqual(len(messages), 3)\n"], "sample_127": ["def test_issue_15063():\n    from sympy.physics.quantum import Dagger\n    a = symbols('a')\n    assert latex(Dagger(a)) == r\"{a}^{\\dagger}\"\n    assert latex(Dagger(a*b)) == r\"{a b}^{\\dagger}\"\n"], "sample_61": ["    def test_grouping_with_non_uniform_digits(self):\n        self.assertEqual(\n            nformat(1234567890, \".\", grouping=(3, 2, 0), thousand_sep=\",\"),\n            \"123,456,789,0\",\n        )\n        self.assertEqual(\n            nformat(1234567890, \".\", grouping=(3, 2, 0), force_grouping=True),\n            \"123,456,789,0\",\n        )\n"], "sample_80": ["    def test_format_array_flat_with_large_array(self):\n        da = xr.DataArray(np.random.randn(10000), dims=\"x\")\n        actual = formatting.format_array_flat(da.values, 10)\n        expected = \"0 ... 9999\"\n        assert actual == expected\n"], "sample_71": ["def test_reload_library():\n    original_library = style.library.copy()\n    with temp_style('test', DUMMY_SETTINGS):\n        style.reload_library()\n        assert len(style.library) > len(original_library)\n    style.reload_library()\n    assert len(style.library) == len(original_library)\n"], "sample_35": ["    def test_modelchoicefield_empty_label(self):\n        f = ModelChoiceField(\n            queryset=ChoiceModel.objects.all(),\n            empty_label=None,\n            error_messages={\n                'invalid_choice': '\"%(value)s\" is not one of the available choices.',\n            },\n        )\n        self.assertFormErrors(\n            ['\"invalid\" is not one of the available choices.'],\n            f.clean,\n            'invalid',\n        )\n\n\n\n"], "sample_109": ["def test_time_series_cv_with_groups():\n    X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14]])\n    y = np.array([0, 0, 0, 1, 1, 1, 1])\n    groups = np.array([0, 0, 0, 1, 1, 1, 1])\n\n    tscv = TimeSeriesSplit(n_splits=3)\n    splits = tscv.split(X, y, groups)\n    for train, test in splits:\n        assert_array_equal(sorted(groups[train]), sorted(groups[test]))\n"], "sample_28": ["    def test_register_unregister(self):\n        class TestModel(models.Model):\n            pass\n\n        with self.assertRaises(AlreadyRegistered):\n            site.register(TestModel)\n            site.register(TestModel)\n\n        site.register(TestModel)\n        with self.assertRaises(NotRegistered):\n            site.unregister(TestModel)\n        site.unregister(TestModel)\n        with self.assertRaises(NotRegistered):\n            site.unregister(TestModel)\n"], "sample_16": ["    def test_quote_with_special_characters(self):\n        self.assertEqual(quote('something\"or\\'other'), 'something_22or_27other')\n"], "sample_55": ["    def test_normalize_path_patterns_handles_trailing_slashes(self):\n        expected = [os.path.normcase(p) for p in [\"foo/bar/\", \"bar/\"]]\n        self.assertEqual(normalize_path_patterns([\"foo/bar/*\", \"bar/*\"]), expected)\n"], "sample_119": ["def test_user_functions():\n    known_functions = {\n        'myfunc': [(lambda x: True, 'MyFunc')]\n    }\n    settings = {'user_functions': known_functions}\n    assert mcode(myfunc(x), settings=settings) == \"MyFunc[x]\"\n"], "sample_97": ["def test_label_binarizer_errors():\n    # Check that invalid arguments yield ValueError\n    mlb = MultiLabelBinarizer()\n    assert_raises(ValueError, mlb.transform, [])\n    assert_raises(ValueError, mlb.inverse_transform, [])\n\n    # Fail on unseen labels\n    mlb = MultiLabelBinarizer()\n    mlb.fit([set([1, 2]), set([3]), set([1, 4])])\n    msg = \"contains previously unseen labels\"\n    assert_raise_message(ValueError, msg, mlb.inverse_transform, set([5]))\n    assert_raise_message(ValueError, msg, mlb.inverse_transform, set([5, 6]))\n\n    # Fail on inverse_transform(\"\")\n    msg = \"bad input shape ()\"\n    assert_raise_message(ValueError, msg, mlb.inverse_transform, \"\")\n"], "sample_14": ["    def test_serialize_custom_field(self):\n        class MyCustomField(models.Field):\n                super().__init__(*args, **kwargs)\n\n                return 'MyCustomFieldType'\n\n                return 'MyCustomFieldType'\n\n                return super().formfield(**kwargs)\n\n        class MyModel(models.Model):\n            my_field = MyCustomField()\n\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.CreateModel(\"MyModel\", (\n                    ('id', models.AutoField(primary_key=True)),\n                    ('my_field', MyModel.my_field),\n                ), {})\n            ]\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\"MyCustomFieldType\", output)\n"], "sample_63": ["    def test_password_too_short(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\"password1\": \"a\", \"password2\": \"a\"}\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form.errors[\"password1\"],\n            [\n                \"Password must be at least 8 characters long.\",\n            ],\n        )\n        self.assertEqual(form.errors[\"password2\"], [\n            \"Password must be at least 8 characters long.\"\n        ])\n\n"], "sample_125": ["def test_issue_10457():\n    assert Float(1.0, 100).as_mpf() == mpf('1.0000000000000000000000000000000000000000000000000000000000000000')\n"], "sample_25": ["    def test_rename_field_with_fk_to_different_app(self):\n        \"\"\"\n        #23406 - Renaming a field that's a foreign key to a different app\n        works correctly.\n        \"\"\"\n        before = [\n            ModelState('testapp', 'Author', [\n                ('id', models.AutoField(primary_key=True)),\n                ('book', models.ForeignKey('otherapp.Book', models.CASCADE)),\n            ]),\n        ]\n        after = [\n            ModelState('testapp', 'Author', [\n                ('id', models.AutoField(primary_key=True)),\n                ('publication', models.ForeignKey('otherapp.Book', models.CASCADE)),\n            ]),\n        ]\n        changes = self.get_changes(before, after)\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, [\"RenameField\"])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0, name='book', new_name='publication')\n"], "sample_89": ["def test_prunetraceback_with_fulltrace(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import traceback\n\n            raise ValueError(\"test error\")\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--fulltrace\")\n    result.stdout.fnmatch_lines([str(p) + \":*: ValueError\", \"*1 failed in *\"])\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([str(p) + \":*: ValueError\", \"*1 failed in *\"])\n"], "sample_157": ["def test_tensor_product_mixed_states():\n    A, B, C, D = symbols('A B C D', commutative=False)\n\n    # Test tensor product with mixed states and trace\n    rho1 = Density([TensorProduct(A, B), 0.5], [TensorProduct(C, D), 0.5])\n    rho2 = Density([TensorProduct(A, B), 0.3], [TensorProduct(C, D), 0.7])\n\n    tr_rho1 = Tr(rho1)\n    tr_rho2 = Tr(rho2)\n\n    assert tr_rho1.doit() == 0.5 * Tr(A*Dagger(A))*Tr(B*Dagger(B)) + 0.5 * Tr(C*Dagger(C))*Tr(D*Dagger(D))\n    assert tr_rho2.doit() == 0.3 * Tr(A*Dagger(A))*Tr(B*Dagger(B)) + 0.7 * Tr(C*Dagger(C))*Tr(D*Dagger(D))\n"], "sample_159": ["def test_latex_repr():\n    assert PREFIXES['m']._latex(None) == r'\\text{m}'\n    assert PREFIXES['k']._latex(None) == r'\\text{k}'\n    assert PREFIXES['k']._latex(None) == r'\\text{k}'\n    assert PREFIXES['mu']._latex(None) == r\"\\mu\"\n"], "sample_104": ["def test_custom_repr_with_custom_class():\n    class MyCustomEstimator(BaseEstimator):\n            self.a = a\n            self.b = b\n\n            return f\"MyCustomEstimator(a={self.a}, b={self.b})\"\n\n    estimator = MyCustomEstimator(a=123, b=456)\n    expected = \"MyCustomEstimator(a=123, b=456)\"\n    assert estimator.__repr__() == expected\n    assert _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=True).pformat(estimator) == expected\n"], "sample_150": ["compilation error"], "sample_21": ["    def test_fast_delete_with_signals(self):\n        \"\"\"\n        Fast delete should still work correctly when deletion signals are connected.\n        \"\"\"\n        class DeleteCounter:\n            count = 0\n\n                self.count += 1\n\n        counter = DeleteCounter()\n        models.signals.post_delete.connect(counter, sender=R)\n        r = R.objects.create()\n        r.delete()\n        self.assertEqual(counter.count, 1)\n        self.assertFalse(R.objects.exists())\n\n\n\n"], "sample_144": ["def test_refine_mul():\n    x = Symbol('x', real=True)\n    y = Symbol('y', real=True)\n    z = Symbol('z', real=True)\n    assert refine(x * y, Q.positive(x) & Q.positive(y)) == x * y\n    assert refine(x * y, Q.negative(x) & Q.positive(y)) == -x * y\n    assert refine(x * y, Q.positive(x) & Q.negative(y)) == -x * y\n    assert refine(x * y, Q.negative(x) & Q.negative(y)) == x * y\n    assert refine(x * y * z, Q.positive(x) & Q.positive(y) & Q.positive(z)) == x * y * z\n    assert refine(x * y * z, Q.negative(x) & Q.positive(y) & Q.positive(z)) == -x * y * z\n    assert refine(x * y * z, Q.positive(x) & Q.negative(y) & Q.positive(z)) == -x * y * z\n    assert refine(x * y * z, Q.negative(x) & Q.negative(y) & Q.positive(z)) == x * y * z\n    assert refine(x * y * z, Q.positive(x) & Q.positive(y) & Q.negative(z)) == -x * y * z\n    assert refine(x * y * z, Q.negative(x) & Q.positive(y) & Q.negative(z)) == x * y * z\n    assert refine(x * y * z, Q.positive(x) & Q.negative(y) & Q.negative(z)) == x * y * z\n    assert refine(x * y * z, Q.negative(x) & Q.negative(y) & Q.negative(z)) == -x * y * z\n"], "sample_73": ["def test_offsetbox_clip_children_with_drawingarea():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100)\n    bg = mpatches.Rectangle((0, 0), 100, 100,\n                            facecolor='#CCCCCC',\n                            edgecolor='None',\n                            linewidth=0)\n    line = mlines.Line2D([-50, 50], [0, 0],\n                         color='black',\n                         linewidth=10)\n    anchored_box = AnchoredOffsetbox(\n        loc='center',\n        child=da,\n        pad=0.,\n        frameon=False,\n        bbox_to_anchor=(.5, .5),\n        bbox_transform=ax.transAxes,\n        borderpad=0.)\n\n    da.add_artist(bg)\n    da.add_artist(line)\n    ax.add_artist(anchored_box)\n    fig.canvas.draw()\n"], "sample_121": ["def test_inversion_vector():\n    p = Permutation([1, 5, 2, 0, 3, 6, 4])\n    assert p.inversion_vector() == [2, 4, 1, 3, 1, 0]\n    q = Permutation([[6], [5], [0, 1, 2, 3, 4]])\n    assert q.inversion_vector() == [3, 1, 2, 0, 0, 0]\n    assert Permutation([0, 1, 2, 3]).inversion_vector() == [0, 0, 0, 0]\n    assert Permutation([3, 2, 1, 0]).inversion_vector() == [0, 0, 0, 0]\n    assert Permutation([0, 1, 3, 2]).inversion_vector() == [1, 0, 0, 0]\n    assert Permutation([0, 3, 1, 2]).inversion_vector() == [1, 0, 0, 0]\n    assert Permutation([0, 2, 1, 3]).inversion_vector() == [1, 0, 0, 0]\n    assert Permutation([1, 0, 2, 3]).inversion_vector() == [1, 0, 0, 0]\n    assert Permutation([2, 1, 0, 3]).inversion_vector() == [1, 0, 0, 0]\n    assert Permutation([3, 0, 1, 2]).inversion_vector() == [1, 0, 0, 0]\n    assert Permutation([1, 4, 2, 3, 0]).inversion_vector() == [2, 1, 0, 0, 0]\n    assert Permutation([4, 1, 2, 3, 0]).inversion_vector() == [2, 1, 0, 0, 0]\n    assert Permutation([2, 4, 1, 3, 0]).inversion_vector() == [2, 1, 0, 0, 0]"], "sample_58": ["    def test_empty_settings(self):\n        self.assertEqual(\n            self.settings_to_cmd_args_env({}),\n            ([\"psql\", \"postgres\"], None),\n        )\n"], "sample_106": ["def test_precomputed_init():\n    # Test that precomputed init works as expected\n    rng = np.random.RandomState(42)\n    X, y = make_blobs(n_samples=30, centers=6, n_features=5, random_state=0)\n    init = rng.randn(X.shape[1], X.shape[1])\n    nca = NeighborhoodComponentsAnalysis(init=init)\n    nca.fit(X, y)\n    assert_array_almost_equal(nca.components_, init)\n"], "sample_70": ["def test_legend_title_fontsize_inheritance():\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label='test')\n    leg = ax.legend(title=\"Aardvark\", title_fontsize=12)\n    assert leg.get_title().get_fontsize() == 12\n    assert leg.get_title().get_fontproperties().get_size() == 12\n\n    mpl.rcParams['legend.title_fontsize'] = 14\n    leg = ax.legend(title=\"Aardvark\")\n    assert leg.get_title().get_fontsize() == 14\n    assert leg.get_title().get_fontproperties().get_size() == 14\n"], "sample_129": ["def test_issue_14748():\n    from sympy.tensor.tensor import Tensor\n    T = Tensor('T', (2, 1))\n    assert latex(T) == r'T'\n"], "sample_43": ["    def test_custom_to_field_with_related_model(self):\n        class RelatedModelAdmin(admin.ModelAdmin):\n            search_fields = ['name']\n\n        with model_admin(RelatedModel, RelatedModelAdmin):\n            q = Question.objects.create(question='Is this a question?')\n            opts = {\n                'app_label': Question._meta.app_label,\n                'model_name': Question._meta.model_name,\n                'field_name': 'related_questions',\n            }\n            request = self.factory.get(self.url, {'term': 'is', **opts})\n            request.user = self.superuser\n            response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n            self.assertEqual(response.status_code, 200)\n            data = json.loads(response.content.decode('utf-8'))\n            self.assertEqual(data, {\n                'results': [{'id': str(q.pk), 'text': q.question}],\n                'pagination': {'more': False},\n            })\n"], "sample_81": ["    def test_regex_codetag(self) -> None:\n        code = \"\"\"a = 1\n                # TODO this should trigger\n                # FIXME another one\n                \"\"\"\n        with self.assertAddsMessages(\n            MessageTest(msg_id=\"fixme\", line=2, args=\"TODO this should trigger\", col_offset=17),\n            MessageTest(msg_id=\"fixme\", line=3, args=\"FIXME another one\", col_offset=17),\n        ):\n            self.checker.process_tokens(_tokenize_str(code))\n"], "sample_158": ["def test_issue_24507():\n    from sympy.physics.units import Quantity, meter, second, kilogram\n    from sympy.physics.units.systems.si import dimsys_SI\n\n    q1 = Quantity(\"q1\")\n    q2 = Quantity(\"q2\")\n    SI.set_quantity_dimension(q1, meter)\n    SI.set_quantity_dimension(q2, kilogram)\n    q1.set_global_relative_scale_factor(1, meter)\n    q2.set_global_relative_scale_factor(1, kilogram)\n\n    expr = q1 / q2\n    assert SI._collect_factor_and_dimension(expr) == (1, length/mass)\n    assert dimsys_SI.get_dimensional_dependencies(expr) == {length: 1, mass: -1}\n"], "sample_117": ["def test_stringify_type_hints_ForwardRef():\n    from typing import ForwardRef  # type: ignore\n    assert stringify(ForwardRef(\"myint\")) == \"myint\"\n"], "sample_45": ["    def test_cache_control_decorator(self):\n        @cache_control(max_age=3600, public=True)\n            return HttpResponse()\n        r = a_view(HttpRequest())\n        self.assertEqual(\n            set(r.headers['Cache-Control'].split(', ')),\n            {'max-age=3600', 'public'},\n        )\n"], "sample_79": ["    def test_concat_with_different_dims(self):\n        ds1 = Dataset({\"x\": ((\"y\", \"z\"), np.random.rand(2, 3)), \"y\": (\"y\", [0, 1])})\n        ds2 = Dataset({\"x\": ((\"y\", \"z\"), np.random.rand(3, 2)), \"y\": (\"y\", [2, 3])})\n        with raises_regex(ValueError, \"Dimensions 'x' are not aligned\"):\n            concat([ds1, ds2], dim=\"y\")\n"], "sample_3": ["    def model_d(x, y):\n        return x * y\n"], "sample_57": ["    def test_extra_forms_are_rendered_correctly(self):\n        data = {\n            \"choices-TOTAL_FORMS\": \"2\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Zero\",\n            \"choices-0-votes\": \"0\",\n            \"choices-1-choice\": \"One\",\n            \"choices-1-votes\": \"1\",\n        }\n        ChoiceFormSet = formset_factory(Choice, extra=1)\n        formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertHTMLEqual(\n            str(formset),\n            '<ul class=\"errorlist nonfield\">'\n            '<li>(Hidden field TOTAL_FORMS) This field is required.</li>'\n            '<li>(Hidden field INITIAL_FORMS) This field is required.</li>'\n            '</ul>'\n            '<div>'\n            '<input type=\"hidden\" name=\"choices-TOTAL_FORMS\" value=\"2\">'\n            '<input type=\"hidden\" name=\"choices-INITIAL_FORMS\" value=\"0\">'\n            '<input type=\"hidden\" name=\"choices-MIN_NUM_FORMS\" value=\"0\">'\n            '<input type=\"hidden\" name=\"choices-MAX_NUM_FORMS\" value=\"0\">'\n            '</div>'\n            '<div>'\n            '<tr><th>Choice:</th><td>'\n            '<input type=\"text\" name=\"choices-0-choice\" value=\"Zero\"></td></tr>'\n            '<tr><th>Votes:</th><td>'\n            '<input type=\"number\" name=\"choices-0-votes\" value=\"0\"></td></tr>'\n            '<tr><th>Choice:</th><td>'\n            '<input type=\"text\" name=\"choices-1-choice\" value=\"One\"></td></tr>'\n            '<tr><th>Votes:</th><td>'\n            '<input type=\"number\" name=\"choices-1-votes\" value=\"1\"></td></tr>'\n            '<tr><th>Choice:</th><td>'\n            '<input type=\"text\" name=\"choices-2-choice\"></td></tr>'\n            '<tr><th>Votes:</th><td>'\n            '<input type=\"number\" name=\"choices-2-votes\"></td></tr>'\n            '</div"], "sample_113": ["compilation error"], "sample_139": ["def test_issue_16164():\n    from sympy import Symbol, Abs, re, im, conjugate\n    x = Symbol('x', real=True)\n    y = Symbol('y', imaginary=True)\n    z = Symbol('z', complex=True)\n    assert re(Abs(z)) == Abs(re(z))\n    assert im(Abs(z)) == Abs(im(z))\n    assert Abs(conjugate(z)) == Abs(z)\n    assert Abs(z*conjugate(z)) == Abs(z)**2\n    assert Abs(z/conjugate(z)) == 1\n    assert Abs(z + conjugate(z)) == 2*Abs(re(z))\n    assert Abs(z - conjugate(z)) == 2*Abs(im(z))\n    assert Abs(x + I*y) == sqrt(x**2 + y**2)\n    assert Abs(x + I*y).subs(x, 1).subs(y, 2) == sqrt(5)\n"], "sample_56": ["    def test_template_tags_with_different_name_in_settings(self):\n        self.assertEqual(check_for_template_tags_with_the_same_name(None), [])\n"], "sample_123": ["def test_issue_10601():\n    assert Float(1.23456789012345678901234567890123, 100) == Float(1.23456789012345678901234567890123)\n"], "sample_24": ["    def test_update_error_dict(self):\n        error_dict = {}\n        exception = ValidationError(error_dict)\n        self.assertEqual(error_dict, {})\n        error_dict = exception.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {})\n\n        error_dict = {'field1': ['E1', 'E2']}\n        exception = ValidationError(error_dict)\n        self.assertEqual(error_dict, {'field1': ['E1', 'E2']})\n        error_dict = exception.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {'field1': ['E1', 'E2']})\n\n        error_dict = {'field2': ['E3', 'E4']}\n        exception = ValidationError(error_dict)\n        self.assertEqual(error_dict, {'field1': ['E1', 'E2'], 'field2': ['E3', 'E4']})\n        error_dict = exception.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {'field1': ['E1', 'E2'], 'field2': ['E3', 'E4']})\n\n        error_dict = {}\n        exception = ValidationError(error_dict)\n        self.assertEqual(error_dict, {})\n        error_dict = exception.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {})\n\n        error_dict = {'field1': ValidationError('E1'), 'field2': ValidationError('E2')}\n        exception = ValidationError(error_dict)\n        self.assertEqual(error_dict, {'field1': ['E1'], 'field2': ['E2']})\n        error_dict = exception.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {'field1': ['E1'], 'field2': ['E2']})\n\n        error_dict = {'field1': ValidationError('E1'), 'field2': ValidationError('E2')}\n        exception = ValidationError(error_dict)\n        self.assertEqual(error_dict, {'field1': ['E1'], 'field2': ['E2']})\n        error_dict = exception."], "sample_132": ["def test_intersection_with_circles():\n    c1 = Circle((0, 0), 1)\n    c2 = Circle((2, 0), 1)\n    assert intersection(c1, c2) == [Point2D(1, 0)]\n    assert intersection(c1, c2, pairwise=True) == [Point2D(1, 0), Point2D(1, 0)]\n    c3 = Circle((1, 0), 1)\n    assert intersection(c1, c2, c3) == [Point2D(1, 0)]\n    assert intersection(c1, c2, c3, pairwise=True) == [Point2D(1, 0), Point2D(1, 0)]\n    c4 = Circle((0, 0), 2)\n    assert intersection(c1, c4) == [Point2D(0, 0), Point2D(0, 0)]\n    assert intersection(c1, c4, pairwise=True) == [Point2D(0, 0), Point2D(0, 0)]\n    c5 = Circle((0, 0), 0.5)\n    assert intersection(c1, c5) == []\n    assert intersection(c1, c5, pairwise=True) == []\n"], "sample_23": ["    def test_union_with_different_fields(self):\n        ReservedName.objects.create(name='a', order=2)\n        qs1 = ReservedName.objects.values('name', 'order')\n        qs2 = Number.objects.values('num')\n        self.assertEqual(list(qs1.union(qs2).values_list('name', flat=True)), ['a'])\n        self.assertEqual(list(qs1.union(qs2).values_list('order', flat=True)), [2])\n        self.assertEqual(list(qs1.union(qs2).values_list('num', flat=True)), [1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n"], "sample_4": ["    def test_cookie_with_unicode_value(self):\n        c = SimpleCookie()\n        c['key'] = '\u4f60\u597d\u4e16\u754c'\n        self.assertEqual(c['key'].value, '\u4f60\u597d\u4e16\u754c')\n        self.assertEqual(parse_cookie(c.output()), {'key': '\u4f60\u597d\u4e16\u754c'})\n\n"], "sample_140": ["def test_point_vel_multiple_velocities():\n    q1, q2, u1, u2 = dynamicsymbols('q1 q2 u1 u2')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    O = Point('O')\n    O.set_vel(N, u1 * N.x)\n    P = Point('P')\n    P.set_pos(O, q1 * N.x)\n    P.set_vel(B, u2 * B.y)\n    assert P.vel(N) == u1 * N.x + u2 * B.y - q1 * u1 * B.x\n    \n    \n"], "sample_0": ["    def test_render_options_with_empty_label(self):\n        form = AlbumForm(initial={'band': None})\n        output = form.as_table()\n        self.assertIn('<option value=\"\">---</option>', output)\n"], "sample_44": ["    def test_modelchoicefield_with_empty_label_and_no_choices(self):\n        f = forms.ModelChoiceField(queryset=None, empty_label='---------')\n        self.assertEqual(list(f.choices), [('', '---------')])\n        with self.assertRaises(ValidationError):\n            f.clean('')\n"], "sample_6": ["    def test_username_validator_flags(self):\n        v_ascii = validators.ASCIIUsernameValidator()\n        v_unicode = validators.UnicodeUsernameValidator()\n\n        with self.assertRaises(ValidationError):\n            v_ascii('\u00c9ric')\n        with self.assertRaises(ValidationError):\n            v_unicode('o\\'connell')\n\n        with self.assertRaises(ValidationError):\n            v_unicode('zerowidth\\u200Bspace')\n        with self.assertRaises(ValidationError):\n            v_unicode('nonbreaking\\u00A0space')\n\n        v_ascii('glenn')\n        v_unicode('Ren\u00e9')\n"], "sample_60": ["    def test_serialize_custom_field(self):\n        class CustomField(models.Field):\n                super().__init__(*args, **kwargs)\n\n                return \"CustomField\"\n\n                return value\n\n                return value\n\n        class MyModel(models.Model):\n            my_field = CustomField()\n\n        string, imports = MigrationWriter.serialize(MyModel)\n        self.assertIn(\"CustomField\", string)\n        self.assertIn(\"from migrations.test_writer import CustomField\", imports)\n"], "sample_13": ["    def test_no_change(self):\n        tests = (\n            ('http://example.com', 'http://example.com'),\n            ('https://example.com', 'https://example.com'),\n            ('example.com', 'example.com'),\n        )\n        for url, expected in tests:\n            with self.subTest(url=url):\n                self.assertEqual(escape_leading_slashes(url), expected)\n"], "sample_103": ["def test_mutual_info_sparse():\n    # Test that mutual information computation works correctly with sparse matrices.\n    n_samples = 1000\n    n_features = 5\n    rng = check_random_state(0)\n    X = rng.rand(n_samples, n_features)\n    X_sparse = csr_matrix(X)\n    y = rng.randint(0, 2, size=n_samples)\n\n    mi_dense = mutual_info_classif(X, y, discrete_features=False, random_state=0)\n    mi_sparse = mutual_info_classif(X_sparse, y, discrete_features=False, random_state=0)\n\n    assert_array_almost_equal(mi_dense, mi_sparse)\n"], "sample_145": ["def test_latex_printing_of_matrices_with_symbols():\n    x, y, z = symbols('x y z')\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n\n    assert latex(A + B) == r\"\\mathbf{A} + \\mathbf{B}\"\n    assert latex(A - B) == r\"\\mathbf{A} - \\mathbf{B}\"\n    assert latex(A * B) == r\"\\mathbf{A} \\mathbf{B}\"\n    assert latex(A / B) == r\"\\frac{\\mathbf{A}}{\\mathbf{B}}\"\n    assert latex(A * x) == r\"x \\mathbf{A}\"\n    assert latex(A * Matrix([[x, y], [z, 1]])) == r\"\\mathbf{A} \\begin{bmatrix} x & y \\\\ z & 1 \\end{bmatrix}\"\n    assert latex(A * Matrix([[x, y], [z, 1]]).T) == r\"\\mathbf{A} \\begin{bmatrix} x & z \\\\ y & 1 \\end{bmatrix}\"\n    assert latex(A * C.T) == r\"\\mathbf{A} \\mathbf{C}^{T}\"\n    assert latex(A.T * B) == r\"\\mathbf{A}^{T} \\mathbf{B}\"\n    assert latex(A.T * B.T) == r\"\\mathbf{A}^{T} \\mathbf{B}^{T}\"\n    assert latex(A.T * C) == r\"\\mathbf{A}^{T} \\mathbf{C}\"\n    assert latex(A.T * C.T) == r\"\\mathbf{A}^{T} \\mathbf{C}^{T}\"\n    assert latex(A.T * x) == r\"x \\mathbf{A}^{T}\"\n    assert latex(A.T * Matrix([[x, y], [z, 1]])) == r\"\\mathbf{A}^{T} \\begin{bmatrix} x & y \\\\ z & 1 \\end{bmatrix}\"\n    assert latex(A.T * Matrix([[x, y], [z, 1]]).T) == r\"\\mathbf{A}^{T} \\"], "sample_40": ["    def test_renderer_inheritance(self):\n        class CustomForm(Form):\n            default_renderer = CustomRenderer\n\n        form = CustomForm()\n        self.assertIsInstance(form.renderer, CustomRenderer)\n\n        class SubForm(CustomForm):\n            pass\n\n        subform = SubForm()\n        self.assertIsInstance(subform.renderer, CustomRenderer)\n"], "sample_115": ["def test_set_output_with_sparse_data():\n    \"\"\"Check that set_output works with sparse data.\"\"\"\n    from scipy.sparse import csr_matrix\n\n    X = csr_matrix([[1, 0, 3], [0, 0, 1]])\n    est = EstimatorWithSetOutput().fit(X)\n    est.set_output(transform=\"pandas\")\n\n    with pytest.raises(ValueError, match=\"Pandas output does not support sparse data\"):\n        est.transform(X)\n"], "sample_137": ["def test_nchoosek():\n    assert nchoosek(0, 0) == 1\n    assert nchoosek(1, 0) == 1\n    assert nchoosek(1, 1) == 1\n    assert nchoosek(2, 0) == 1\n    assert nchoosek(2, 1) == 2\n    assert nchoosek(2, 2) == 1\n    assert nchoosek(5, 2) == 10\n    assert nchoosek(5, 3) == 10\n    assert nchoosek(5, 4) == 5\n    assert nchoosek(5, 5) == 1\n    assert nchoosek(10, 5) == 252\n    assert nchoosek(10, 0) == 1\n    assert nchoosek(10, 10) == 1\n    assert nchoosek(10, 1) == 10\n    assert nchoosek(10, 2) == 45\n    assert nchoosek(10, 3) == 120\n    assert nchoosek(10, 4) == 210\n    assert nchoosek(10, 6) == 210\n    assert nchoosek(10, 7) == 120\n    assert nchoosek(10, 8) == 45\n    assert nchoosek(10, 9) == 10\n"], "sample_99": ["compilation error"], "sample_72": ["def test_toolmanager_set_active_tool():\n    with pytest.warns(UserWarning, match=_EXPECTED_WARNING_TOOLMANAGER):\n        plt.rcParams['toolbar'] = 'toolmanager'\n    fig = plt.gcf()\n    initial_tool = fig.canvas.manager.toolmanager.get_active_tool()\n    assert initial_tool is not None\n    fig.canvas.manager.toolmanager.set_active_tool('pan')\n    active_tool = fig.canvas.manager.toolmanager.get_active_tool()\n    assert active_tool.name == 'pan'\n    fig.canvas.manager.toolmanager.set_active_tool(initial_tool)\n    active_tool = fig.canvas.manager.toolmanager.get_active_tool()\n    assert active_tool.name == initial_tool.name\n    with pytest.warns(UserWarning,\n                      match=\"ToolManager does not control tool 'foo'\"):\n        fig.canvas.manager.toolmanager.set_active_tool('foo')\n"], "sample_7": ["    def test_should_stop_returns_false_when_no_changes(self):\n        with mock.patch.object(self.reloader, 'snapshot_files', return_value={self.existing_file: 1}) as mocked_snapshot:\n            self.assertFalse(self.reloader.should_stop())\n            mocked_snapshot.assert_called_once()\n\n"], "sample_20": ["    def test_unique_constraint_with_non_unique_field(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=100)\n            age = models.IntegerField()\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(fields=['name', 'age'], name='name_age_unique'),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n"], "sample_1": ["def test_read_write_masked_values(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3, 4]))\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"b\", mask=[False, True, False, True]\n        )\n    )\n    t1.write(test_file, format=\"ascii.qdp\")\n    t2 = Table.read(test_file, format=\"ascii.qdp\")\n\n    assert np.allclose(t2[\"a\"], t1[\"a\"])\n    assert np.all(t2[\"b\"].mask == t1[\"b\"].mask)\n    assert np.allclose(t2[\"b\"][~t2[\"b\"].mask], t1[\"b\"][~t1[\"b\"].mask])\n\n\n\n"], "sample_143": ["def test_issue_18479():\n    from sympy.tensor import tensor_indices, tensor_heads, TensorHead\n    L = tensor_indices(\"L\")\n    i, j, k = tensor_indices(\"i j k\", L)\n    A, B, C, D = tensor_heads(\"A B C D\", [L])\n\n    expr = A(i) * B(j) * C(-i)\n    ascii_str = \\"], "sample_133": ["def test_fcode_complex_mixed():\n    import sympy.utilities.codegen\n    sympy.utilities.codegen.COMPLEX_ALLOWED = True\n    x = Symbol('x')\n    y = Symbol('y', real=True)\n    z = Symbol('z', real=True)\n    result = codegen(('test', x + y + z), 'f95', 'test', header=False, empty=False)\n    source = (result[0][1])\n    expected = (\n        \"COMPLEX*16 function test(x, y, z)\\n\"\n        \"implicit none\\n\"\n        \"COMPLEX*16, intent(in) :: x\\n\"\n        \"REAL*8, intent(in) :: y\\n\"\n        \"REAL*8, intent(in) :: z\\n\"\n        \"test = x + y + z\\n\"\n        \"end function\\n\"\n        )\n    assert source == expected\n    sympy.utilities.codegen.COMPLEX_ALLOWED = False\n"], "sample_32": ["    def test_key_transform_with_subquery(self):\n        subquery_obj = NullableJSONModel.objects.create(value={'d': ['e', {'f': 'g'}]})\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(\n                value__d__1__f=F('value__d__1__f'),\n                value__d__1__f=subquery_obj.value__d__1__f,\n            ),\n            [subquery_obj],\n        )\n"], "sample_101": ["def test_pipeline_with_invalid_memory():\n    # Test that an error is raised when memory is not a string or a Memory\n    # instance\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    # Define memory as a list\n    memory = [1, 2]\n    cached_pipe = Pipeline([('transf', DummyTransf()),\n                            ('svc', SVC())], memory=memory)\n    assert_raises_regex(ValueError, \"'memory' should be None, a string or\"\n                        \" have the same interface as joblib.Memory.\"\n                        \" Got memory='\\[1, 2\\]' instead.\", cached_pipe.fit, X, y)\n"], "sample_11": ["    def test_serialize_custom_field(self):\n        class CustomField(models.Field):\n                super().__init__(*args, **kwargs)\n\n                return 'CustomField'\n\n                return 'CustomField'\n\n                return super().formfield(**kwargs)\n\n        class MyModel(models.Model):\n            my_field = CustomField()\n\n        migration = type(\"Migration\", (migrations.Migration,), {\n            \"operations\": [\n                migrations.CreateModel(\"MyModel\", ((\"my_field\", CustomField()),), {})\n            ]\n        })\n        writer = MigrationWriter(migration)\n        output = writer.as_string()\n        self.assertIn(\"CustomField\", output)\n"], "sample_53": ["    def test_operation_with_custom_name(self):\n        class Migration(migrations.Migration):\n            operations = [\n                migrations.CreateModel(\n                    \"Person\", fields=[], name=\"my_person_model\"\n                )\n            ]\n\n        migration = Migration(\"some_migration\", \"test_app\")\n        self.assertEqual(migration.suggest_name(), \"my_person_model\")\n"], "sample_39": ["    def test_lookahead_and_lookbehind_together(self):\n        test_urls = [\n            ('/lookahead+/a-city/lookbehind-/b-city/', {'city': 'a-city', 'city2': 'b-city'}),\n            ('/lookbehind-/b-city/lookahead+/a-city/', {'city': 'a-city', 'city2': 'b-city'}),\n        ]\n        for test_url, kwargs in test_urls:\n            with self.subTest(url=test_url):\n                self.assertEqual(resolve(test_url).kwargs, kwargs)\n"], "sample_78": ["def test_cli_duplicate_commands(app):\n    custom = Blueprint(\"custom\", __name__, cli_group=\"customized\")\n    @custom.cli.command(\"duplicate\")\n        click.echo(\"custom_result\")\n\n    app.register_blueprint(custom)\n\n    with pytest.raises(click.exceptions.DuplicateCommandError):\n        app.cli.add_command(duplicate_command, name=\"duplicate\")\n"], "sample_19": ["    def test_sensitive_variables_decorator_with_kwargs(self):\n        @sensitive_variables\n            return password, kwargs\n\n        with self.settings(DEBUG=True):\n            response = self.client.post('/sensitive_view/', data={'password': 'secret', 'other': 'data'})\n            self.assertEqual(response.status_code, 500)\n            self.assertNotIn('secret', response.content)\n            self.assertIn('other', response.content)\n"], "sample_122": ["compilation error"], "sample_65": ["    def test_join09(self):\n        output = self.engine.render_to_string(\n            \"join09\", {\"a\": [\"alpha\", \"beta & me\"], \"var\": mark_safe(\" & \")}\n        )\n        self.assertEqual(output, \"alpha & beta & me\")\n"], "sample_148": ["def test_issue_16020():\n    from sympy import Symbol, Abs, re, im, conjugate\n    x = Symbol('x', real=True)\n    y = Symbol('y', imaginary=True)\n    z = Symbol('z', complex=True)\n    assert Abs(z).subs(z, x + I*y) == sqrt(x**2 + y**2)\n    assert re(z).subs(z, x + I*y) == x\n    assert im(z).subs(z, x + I*y) == y\n    assert conjugate(z).subs(z, x + I*y) == x - I*y\n    assert Abs(conjugate(z)).subs(z, x + I*y) == sqrt(x**2 + y**2)\n"], "sample_46": ["    def test_rename_column_references_with_suffix(self):\n        table = Person._meta.db_table\n        self.expressions = Expressions(\n            table=table,\n            expressions=ExpressionList(\n                IndexExpression(F('first_name').suffix('_suffix')),\n                IndexExpression(F('last_name').suffix('_suffix').desc()),\n                IndexExpression(Upper('last_name').suffix('_suffix')),\n            ).resolve_expression(self.expressions.compiler.query),\n            compiler=self.expressions.compiler,\n            quote_value=self.editor.quote_value,\n        )\n        self.expressions.rename_column_references(table, 'first_name', 'other')\n        self.assertIs(self.expressions.references_column(table, 'other_suffix'), True)\n        self.assertIs(self.expressions.references_column(table, 'first_name'), False)\n        self.assertIn(\n            '%s.%s_suffix' % (self.editor.quote_name(table), self.editor.quote_name('other')),\n            str(self.expressions),\n        )\n"], "sample_124": ["compilation error"], "sample_141": ["def test_issue_15873():\n    from sympy.physics.units import Quantity, meter, second\n    q1 = Quantity('q1')\n    q2 = Quantity('q2')\n    q1.set_global_relative_scale_factor(1, meter)\n    q2.set_global_relative_scale_factor(1, second)\n    expr = q1 + q2\n    assert expr.is_Add and set(expr.args) == {q1, q2}\n    assert expr.dimension == length + time\n"], "sample_2": ["def test_wcs_from_header_with_missing_crval():\n    \"\"\"\n    Test handling of WCS headers with missing CRVAL keywords.\n    \"\"\"\n    header = get_pkg_data_contents(\"data/missing_crval.hdr\")\n    with pytest.raises(wcs.InvalidTransformError):\n        wcs.WCS(header)\n"], "sample_36": ["    def test_resolve_expression(self):\n        q = Q(id=1)\n        clause, joins = q.resolve_expression()\n        self.assertEqual(clause, 'id=1')\n        self.assertEqual(joins, [])\n"], "sample_93": ["compilation error"], "sample_69": ["def test_format_cursor_data_with_nan():\n    X = np.empty((3, 3))\n    X[0, 0] = 0.9\n    X[0, 1] = 0.99\n    X[0, 2] = 0.999\n    X[1, 0] = np.nan\n    X[1, 1] = 0\n    X[1, 2] = 1\n    X[2, 0] = 0.09\n    X[2, 1] = 0.009\n    X[2, 2] = 0.0009\n\n    fig, ax = plt.subplots()\n    fig.suptitle(\"NaN values\")\n    norm = mcolors.BoundaryNorm(np.linspace(0, 1, 20), 256)\n    img = ax.imshow(X, cmap='RdBu_r', norm=norm)\n\n    labels_list = [\n        \"[0.9]\",\n        \"[nan]\",\n        \"[1.]\",\n        \"[-1.0]\",\n        \"[0.0]\",\n        \"[1.0]\",\n        \"[0.09]\",\n        \"[0.009]\",\n        \"[0.0009]\",\n    ]\n    for v, label in zip(X.flat, labels_list):\n        assert img.format_cursor_data(v) == label\n\n    plt.close()\n"], "sample_88": ["def test_circular_references():\n    class A:\n            self.b = b\n\n    class B:\n            self.a = a\n\n    a = A(B(a))\n    assert saferepr(a)\n"], "sample_128": ["def test_allowed_flags():\n    args = {'domain': ZZ, 'field': True}\n    allowed_flags(args, [])\n    raises(FlagError, lambda: allowed_flags(args, ['frac']))\n\n    args = {'domain': ZZ, 'frac': True}\n    allowed_flags(args, ['frac'])\n"], "sample_18": ["    def test_non_unique_parent_fields(self):\n        class Parent(models.Model):\n            a = models.PositiveIntegerField()\n            b = models.PositiveIntegerField()\n\n        class Child(models.Model):\n            a = models.PositiveIntegerField()\n            b = models.PositiveIntegerField()\n            value = models.CharField(max_length=255)\n            parent = models.ForeignObject(\n                Parent,\n                on_delete=models.SET_NULL,\n                from_fields=('a', 'b'),\n                to_fields=('a', 'b'),\n                related_name='children',\n            )\n\n        field = Child._meta.get_field('parent')\n        self.assertEqual(field.check(from_model=Child), [\n            Error(\n                \"No subset of the fields 'a', 'b' on model 'Parent' is unique.\",\n                hint=(\n                    'Mark a single field as unique=True or add a set of '\n                    'fields to a unique constraint (via unique_together or a '\n                    'UniqueConstraint (without condition) in the model '\n                    'Meta.constraints).'\n                ),\n                obj=field,\n                id='fields.E310',\n            ),\n        ])\n"], "sample_41": ["    def test_all_valid_with_non_form_errors(self):\n        data = {\n            'choices-TOTAL_FORMS': '2',\n            'choices-INITIAL_FORMS': '0',\n            'choices-MIN_NUM_FORMS': '0',\n            'choices-0-choice': 'Zero',\n            'choices-0-votes': '0',\n            'choices-1-choice': 'One',\n            'choices-1-votes': '1',\n        }\n        ChoiceFormSet = formset_factory(Choice, validate_max=True)\n        formset1 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        formset2 = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIs(all_valid((formset1, formset2)), False)\n        expected_errors = [\n            {'__all__': ['This is a non-form error']},\n            {'__all__': ['This is a non-form error']}\n        ]\n        formset1._errors = expected_errors\n        formset2._errors = expected_errors\n        self.assertIs(all_valid((formset1, formset2)), False)\n"]}, "raw_scored_generations": {"sample_1": [false], "sample_3": [false], "sample_0": [false], "sample_2": [false], "sample_6": [true], "sample_4": [false], "sample_5": [true], "sample_7": [false], "sample_9": [true], "sample_8": [true], "sample_10": [true], "sample_11": [false], "sample_13": [true], "sample_12": [false], "sample_14": [false], "sample_15": [false], "sample_16": [false], "sample_17": [true], "sample_18": [true], "sample_19": [false], "sample_21": [false], "sample_20": [true], "sample_23": [false], "sample_22": [false], "sample_24": [false], "sample_25": [false], "sample_28": [false], "sample_26": [false], "sample_27": [false], "sample_29": [false], "sample_31": [true], "sample_30": [false], "sample_32": [false], "sample_33": [false], "sample_34": [false], "sample_35": [true], "sample_36": [false], "sample_37": [false], "sample_39": [false], "sample_38": [false], "sample_40": [true], "sample_42": [false], "sample_41": [false], "sample_43": [true], "sample_45": [false], "sample_44": [false], "sample_46": [false], "sample_48": [false], "sample_47": [true], "sample_50": [false], "sample_49": [false], "sample_51": [false], "sample_52": [false], "sample_53": [false], "sample_55": [false], "sample_54": [false], "sample_56": [true], "sample_58": [true], "sample_57": [false], "sample_60": [false], "sample_59": [true], "sample_61": [false], "sample_63": [false], "sample_62": [true], "sample_64": [false], "sample_66": [false], "sample_65": [false], "sample_68": [true], "sample_67": [false], "sample_69": [false], "sample_70": [true], "sample_71": [false], "sample_72": [false], "sample_73": [false], "sample_74": [false], "sample_75": [false], "sample_76": [true], "sample_77": [false], "sample_78": [false], "sample_79": [false], "sample_80": [true], "sample_82": [false], "sample_81": [true], "sample_83": [false], "sample_84": [false], "sample_85": [false], "sample_86": [false], "sample_87": [false], "sample_88": [false], "sample_89": [false], "sample_90": [true], "sample_91": [false], "sample_92": [false], "sample_93": [false], "sample_95": [false], "sample_94": [false], "sample_96": [false], "sample_97": [false], "sample_98": [false], "sample_99": [false], "sample_100": [false], "sample_101": [true], "sample_102": [false], "sample_103": [false], "sample_104": [false], "sample_105": [false], "sample_107": [false], "sample_106": [true], "sample_108": [false], "sample_109": [false], "sample_110": [true], "sample_111": [false], "sample_112": [false], "sample_113": [false], "sample_114": [false], "sample_115": [true], "sample_116": [false], "sample_117": [true], "sample_118": [true], "sample_119": [false], "sample_120": [false], "sample_121": [false], "sample_122": [false], "sample_123": [true], "sample_124": [false], "sample_125": [false], "sample_126": [true], "sample_127": [false], "sample_128": [false], "sample_129": [false], "sample_130": [true], "sample_131": [false], "sample_132": [false], "sample_133": [true], "sample_134": [true], "sample_135": [true], "sample_136": [false], "sample_137": [false], "sample_138": [false], "sample_139": [false], "sample_140": [false], "sample_142": [false], "sample_141": [false], "sample_143": [false], "sample_144": [false], "sample_145": [false], "sample_146": [false], "sample_147": [false], "sample_148": [false], "sample_149": [false], "sample_150": [false], "sample_151": [false], "sample_152": [true], "sample_153": [true], "sample_154": [true], "sample_155": [false], "sample_156": [false], "sample_157": [true], "sample_158": [false], "sample_159": [true]}}