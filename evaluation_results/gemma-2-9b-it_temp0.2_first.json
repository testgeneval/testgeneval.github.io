{"raw_generations": {"sample_108": ["    def test_dynamic_converter(self):\n        url = '/dynamic/123/'\n        view = empty_view\n        pattern = path('dynamic/<int:id>/', view, name='dynamic_view')\n        resolver = URLResolver(pattern, 'urlpatterns.path_urls')\n        match = resolver.resolve(url)\n        self.assertEqual(match.func, view)\n        self.assertEqual(match.kwargs['id'], 123)\n        self.assertEqual(match.url_name, 'dynamic_view')\n\n        reversed_url = reverse('dynamic_view', kwargs={'id': 456})\n        self.assertEqual(reversed_url, '/dynamic/456/')\n\n"], "sample_770": ["compilation error"], "sample_1011": ["    def test_piecewise_inline(self):\n        pw = Piecewise((x + 1, x > 0), (x, True))\n        code = octave_code(pw, assign_to='tau', inline=True)\n        self.assertEqual(code, 'tau = ((x > 0).* (x + 1) + (~ (x > 0)).*(x));')\n"], "sample_740": ["    def test_check_large_sparse_warn(self):\n        X = sp.csr_matrix(np.random.rand(100, 100), dtype=np.int64)\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"always\")\n            check_array(X, accept_large_sparse=False)\n        assert \"Scipy version\" in warnings.messages[0].message\n"], "sample_808": ["    def test_contamination_auto_behaviour_old(self):\n        # test that contamination='auto' raises a ValueError when behaviour='old'\n        with assert_raises_regex(ValueError, \"contamination parameter cannot be set to 'auto'\"):\n            IsolationForest(behaviour='old', contamination='auto')\n"], "sample_156": ["    def test_form_renderer(self):\n        renderer = get_default_renderer()\n        form = Person()\n        html = renderer.render(form)\n        self.assertIn('<label for=\"id_first_name\">First name:</label>', html)\n        self.assertIn('<label for=\"id_last_name\">Last name:</label>', html)\n        self.assertIn('<label for=\"id_birthday\">Birthday:</label>', html)\n\n        form = PersonNew()\n        html = renderer.render(form)\n        self.assertIn('<label for=\"first_name_id\">First name:</label>', html)\n        self.assertIn('<label for=\"id_last_name\">Last name:</label>', html)\n        self.assertIn('<label for=\"id_birthday\">Birthday:</label>', html)\n"], "sample_92": ["    def test_get_all_permissions(self):\n        backend = SimpleBackend()\n        permissions = backend.get_all_permissions(self.user)\n        self.assertEqual(permissions, {'user_perm', 'group_perm'})\n\n"], "sample_411": ["    def test_dance_command(self):\n        with captured_stderr() as stderr:\n            management.call_command(\"dance\", \"--verbosity\", \"2\")\n        self.assertIn(\"Dancing!\", stderr.getvalue())\n"], "sample_699": ["    def test_doctest_ignore_import_errors(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n                pass\n            \"\"\"\n        )\n        pytester.runpytest(\n            \"--doctest-ignore-import-errors\",\n            \"--doctest-modules\",\n            \"test_doctest_ignore_import_errors.py\",\n        )\n        result = pytester.getresults()\n        assert len(result) == 1\n        assert result[0].passed\n\n\n"], "sample_210": ["    def test_redirect_view(self):\n        redirect_view = RedirectView.as_view(url='http://www.example.com')\n        request = self.rf.get('/')\n        response = redirect_view(request)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response['Location'], 'http://www.example.com')\n"], "sample_498": ["    def test_legend_bbox_to_anchor(self):\n        fig, ax = plt.subplots()\n        legend = ax.legend()\n\n        # Test with bbox_to_anchor=None (default)\n        with rc_context({'axes.facecolor': 'lightblue'}):\n            bbox = legend.get_bbox_to_anchor()\n            assert bbox is None\n\n        # Test with bbox_to_anchor=(0, 0)\n        legend.set_bbox_to_anchor((0, 0))\n        with rc_context({'axes.facecolor': 'lightblue'}):\n            bbox = legend.get_bbox_to_anchor()\n            assert bbox.xmin == 0\n            assert bbox.ymin == 0\n\n        # Test with bbox_to_anchor=(0.5, 0.5)\n        legend.set_bbox_to_anchor((0.5, 0.5))\n        with rc_context({'axes.facecolor': 'lightblue'}):\n            bbox = legend.get_bbox_to_anchor()\n            assert bbox.xmin == 0.5\n            assert bbox.ymin == 0.5\n\n        # Test with bbox_to_anchor=(0.5, 0.5, width=0.2, height=0.1)\n        legend.set_bbox_to_anchor((0.5, 0.5, 0.2, 0.1))\n        with rc_context({'axes.facecolor': 'lightblue'}):\n            bbox = legend.get_bbox_to_anchor()\n            assert bbox.width == 0.2\n            assert bbox.height == 0.1\n\n        plt.close(fig)\n\n\n\n"], "sample_120": ["    def test_serialize_custom_operations(self):\n        with mock.patch('custom_migration_operations.more_operations.MoreOperation.deconstruct') as mock_deconstruct:\n            mock_deconstruct.return_value = (\n                'custom_migration_operations.more_operations.MoreOperation',\n                [],\n                {}\n            )\n            operation = custom_migration_operations.more_operations.MoreOperation()\n            writer = OperationWriter(operation, indentation=0)\n            serialized_operation = writer.serialize()\n            self.assertEqual(serialized_operation, 'MoreOperation()')\n"], "sample_718": ["def check_estimator_with_pandas_series_sample_weight(name, estimator_orig):\n    X, y = _boston_subset()\n    estimator = clone(estimator_orig)\n    sample_weight_series = pd.Series(np.random.rand(len(y)))\n    with assert_raises(ValueError,\n                       msg=\"Estimator does not accept 'sample_weight'\"\n                           \"of type pandas.Series\"):\n        estimator.fit(X, y, sample_weight=sample_weight_series)\n"], "sample_897": ["    def test_partial_dependence_display_two_way_categorical(\n        clf_diabetes, diabetes, grid_resolution"], "sample_1185": ["compilation error"], "sample_195": ["    def test_datetime_extract_sql(self):\n        ops = BaseDatabaseOperations(connection=connection)\n        self.assertEqual(ops.datetime_extract_sql('year', 'some_field', None), 'django_datetime_extract(\"year\", some_field, NULL, NULL)')\n        self.assertEqual(ops.datetime_extract_sql('month', 'some_field', 'America/New_York'), 'django_datetime_extract(\"month\", some_field, \\'America/New_York\\', \\'America/New_York\\')')\n        self.assertEqual(ops.datetime_extract_sql('day', 'some_field', 'UTC'), 'django_datetime_extract(\"day\", some_field, \\'UTC\\', \\'UTC\\')')\n\n\n\n"], "sample_641": ["def test_load_results_missing(\n    monkeypatch: pytest.MonkeyPatch,"], "sample_972": ["    def test_restify_newtype(self):\n        from sphinx.util import inspect  # lazy loading\n\n        if sys.version_info >= (3, 10):\n            newtype_class = NewType('MyInt', int)\n            assert restify(newtype_class) == ':py:class:`~typing.NewType`'\n            assert restify(newtype_class.__origin__) == ':py:class:`int`'\n            assert restify(newtype_class.__args__[0]) == ':py:obj:`int`'\n\n            newtype_class = NewType('MyList', List[str])\n            assert restify(newtype_class) == ':py:class:`~typing.NewType`'\n            assert restify(newtype_class.__origin__) == ':py:class:`list`'\n            assert restify(newtype_class.__args__[0]) == ':py:obj:`str`'\n        else:\n            newtype_class = NewType('MyInt', int)\n            assert restify(newtype_class) == ':py:class:`MyInt`'\n            assert restify(newtype_class.__origin__) == ':py:class:`int`'\n            assert restify(newtype_class.__args__[0]) == ':py:obj:`int`'\n\n\n\n"], "sample_540": ["    def test_blitting_with_func_animation(self, anim):\n        # Test blitting with FuncAnimation\n        # Create a NullMovieWriter to capture the frame data\n        writer = NullMovieWriter()\n        anim.save('test.mp4', writer=writer)\n\n        # Check that the correct number of frames were drawn\n        assert writer._count == anim.get_frames()\n\n        # Check that the blitting logic was used\n        for i in range(anim.get_frames()):\n            frame_data = writer.grab_frame()\n            # Check that the frame data is the same as the original\n            check_figures_equal(frame_data, anim.fig)\n\n\n\n"], "sample_579": ["    def test_clustermap_basic(self):\n        # Test basic functionality of clustermap\n        fig, ax = plt.subplots()\n        mat.clustermap(self.df_norm, ax=ax, **self.default_kws)\n        plt.close(fig)\n"], "sample_1068": ["    def test_matrix_element_access():\n        A = MatrixSymbol('A', 2, 2)\n        expr = A[0, 1]\n        code = octave_code(expr)\n        assert code == 'A(1, 2)'\n"], "sample_862": ["    def test_stop_words_with_custom_stop_words(self):\n        # Test with custom stop words\n        custom_stop_words = ['the', 'pizza', 'beer']\n        vectorizer = TfidfVectorizer(stop_words=custom_stop_words)\n        X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n        expected_features = ['salad', 'celeri', 'copyright', 'burger',\n                             'coke', 'tomato', 'water']\n        assert_array_equal(vectorizer.get_feature_names(), expected_features)\n"], "sample_976": ["    def test_symbols_range_with_letters():\n        a, b, c = symbols('a:c')\n        assert a == Symbol('a')\n        assert b == Symbol('b')\n        assert c == Symbol('c')\n"], "sample_624": ["compilation error"], "sample_445": ["    def test_timesince_future_time(self):\n        future_time = self.t + self.oneminute\n        self.assertEqual(timesince(future_time), avoid_wrapping(gettext(\"0 minutes\")))\n"], "sample_995": ["    def test_sympify_mpmath_complex():\n        z = mpmath.mpc(1, 2)\n        assert same_and_same_prec(sympify(z), 1 + 2*I)\n"], "sample_135": ["    def test_format_rfc5322(self):\n        dt = datetime(2000, 12, 21, 16, 1, 7)\n        formatted_dt = format(dt, 'r')\n        expected_dt = 'Thu, 21 Dec 2000 16:01:07 +0200'\n        self.assertEqual(formatted_dt, expected_dt)\n"], "sample_727": ["compilation error"], "sample_481": ["    def test_join01(self):\n        self.assertEqual(join01.render({\"a\": [\"one\", \"two\", \"three\"]}), \"one, two, three\")\n"], "sample_832": ["    def test_ard_threshold(self):\n        X, y = diabetes.data, diabetes.target\n        n_samples, n_features = X.shape\n        # Create an ARDRegression instance with a low threshold\n        ard = ARDRegression(threshold_lambda=1e-6)\n        ard.fit(X, y)\n        # Check that all weights have been kept\n        assert_array_less(ard.lambda_, ard.threshold_lambda)\n        # Create another ARDRegression instance with a high threshold\n        ard = ARDRegression(threshold_lambda=1e10)\n        ard.fit(X, y)\n        # Check that all weights have been kept\n        assert_array_almost_equal(ard.lambda_, np.ones(n_features))\n"], "sample_753": ["    def test_logistic_regression_cv_multiclass_ovr(self):\n        X, y = make_classification(n_samples=100, n_features=10,\n                                   n_classes=3, random_state=42)\n        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n        clf = LogisticRegressionCV(Cs=10, cv=cv, solver='lbfgs',\n                                   multi_class='ovr', random_state=42)\n        clf.fit(X, y)\n        assert_equal(clf.coef_.shape, (2, 10))\n        assert_equal(clf.intercept_.shape, (2,))\n        assert_equal(clf.Cs_.shape, (10,))\n"], "sample_1132": ["    def test_partitions_with_size():\n        for n, k in [(5, 2), (6, 3), (7, 4)]:\n            for got, expected in zip(\n                ordered_partitions(n, k, size=True),\n                partitions(n, k, size=True)):\n                assert got == expected"], "sample_1103": ["    def test_as_content_primitive_sqrt():\n        from sympy import sqrt\n        assert sqrt(4 + 4*sqrt(2)).as_content_primitive() == (2, sqrt(1 + sqrt(2)))\n        assert sqrt(3 + 3*sqrt(2)).as_content_primitive() == (1, sqrt(3)*sqrt(1 + sqrt(2)))\n        assert sqrt(4 + 4*sqrt(3)).as_content_primitive() == (2, sqrt(1 + sqrt(3)))\n        assert sqrt(16 + 8*sqrt(2)).as_content_primitive() == (4, sqrt(1 + sqrt(2)))\n        assert sqrt(16 + 8*sqrt(3)).as_content_primitive() == (4, sqrt(1 + sqrt(3)))\n        assert sqrt(16 + 8*sqrt(5)).as_content_primitive() == (4, sqrt(1 + sqrt(5)))\n        assert sqrt(16 + 8*sqrt(7)).as_content_primitive() == (4, sqrt(1 + sqrt(7)))\n        assert sqrt(16 + 8*sqrt(11)).as_content_primitive() == (4, sqrt(1 + sqrt(11)))\n        assert sqrt(16 + 8*sqrt(13)).as_content_primitive() == (4, sqrt(1 + sqrt(13)))\n        assert sqrt(16 + 8*sqrt(17)).as_content_primitive() == (4, sqrt(1 + sqrt(17)))\n        assert sqrt(16 + 8*sqrt(19)).as_content_primitive() == (4, sqrt(1 + sqrt(19)))\n        assert sqrt(16 + 8*sqrt(23)).as_content_primitive() == (4, sqrt(1 + sqrt(23)))\n        assert sqrt(16 + 8*sqrt(29)).as_content_primitive() == (4, sqrt(1 + sqrt(29)))\n        assert sqrt(16 + 8*sqrt(31)).as_content_primitive() == (4, sqrt(1 + sqrt(31)))\n        assert sqrt(16 + 8*sqrt(3"], "sample_269": ["    def test_set_language_redirects_to_next_url(self):\n        inactive_language = self._get_inactive_language_code()\n        url = reverse('set_language')\n        response = self.client.post(url, data={'language': inactive_language, 'next': '/some/page'})\n        self.assertRedirects(response, '/some/page', status_code=302, target_status_code=200)\n"], "sample_629": ["compilation error"], "sample_581": ["    def test_blueprint_url_prefix(\n        self, client: flask.TestClient,"], "sample_842": ["    def test_kernel_evaluation(kernel):\n        K = kernel(X)\n        assert K.shape == (X.shape[0], X.shape[0])\n        assert_array_almost_equal(K, K.T)\n        if isinstance(kernel, (RBF, Matern, RationalQuadratic,\n                              ExpSineSquared, DotProduct)):\n            # Check that the kernel is positive semi-definite\n            eigenvalues = np.linalg.eigvals(K)\n            assert np.all(eigenvalues >= 0)\n\n        if hasattr(kernel, 'get_params'):\n            # Check that setting parameters and evaluating the kernel\n            # gives the same result\n            new_kernel = clone(kernel)\n            new_kernel.set_params(**kernel.get_params())\n            K_new = new_kernel(X)\n            assert_array_almost_equal(K, K_new)\n\n        # Check that the kernel can be evaluated with a different input\n        X_new = np.random.RandomState(1).normal(0, 1, (3, 2))\n        K_new = kernel(X_new)\n        assert K_new.shape == (X_new.shape[0], X_new.shape[0])\n        assert_array_almost_equal(K_new, K_new.T)\n\n        if hasattr(kernel, 'get_params'):\n            # Check that the kernel can be evaluated with a different input\n            # after setting parameters\n            new_kernel = clone(kernel)\n            new_kernel.set_params(**kernel.get_params())\n            K_new = new_kernel(X_new)\n            assert_array_almost_equal(K_new, K_new.T)\n\n\n\n"], "sample_713": ["    def test_ridge_gcv_sparse(self):\n        X = SPARSE_FILTER(np.random.rand(100, 50))\n        y = np.random.rand(100)\n        estimator = _RidgeGCV(alphas=(0.1, 1.0, 10.0),\n                              gcv_mode='svd')\n        estimator.fit(X, y)\n        assert_array_almost_equal(estimator.cv_values_,\n                                  estimator.cv_values_)\n"], "sample_715": ["    def test_permutation_test_score_with_groups(self):\n        X, y, groups = make_classification(n_samples=100, n_features=20,\n                                           n_informative=10,\n                                           n_redundant=0,\n                                           random_state=42,\n                                           n_clusters_per_class=1)\n        groups = np.array(groups)\n        estimator = KNeighborsClassifier(n_neighbors=3)\n        score, _, _ = permutation_test_score(estimator, X, y, groups,\n                                             n_permutations=100)\n        assert_greater(score, 0.5)\n\n"], "sample_611": ["    def test_to_offset(offset, expected_n):\n        assert to_offset(offset).n == expected_n\n"], "sample_686": ["    def test_deprecated_warnings(testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.parametrize(\"arg\", [\"a\", \"b\", \"c\"])\n                pytest.deprecated_warnings.FUNCARGNAMES\n                pytest.deprecated_warnings.FILLFUNCARGS\n                pytest.deprecated_warnings.RESULT_LOG\n                pytest.deprecated_warnings.FIXTURE_POSITIONAL_ARGUMENTS\n                pytest.deprecated_warnings.NODE_USE_FROM_PARENT\n                pytest.deprecated_warnings.JUNIT_XML_DEFAULT_FAMILY\n                pytest.deprecated_warnings.COLLECT_DIRECTORY_HOOK\n                pytest.deprecated_warnings.PYTEST_COLLECT_MODULE\n                pytest.deprecated_warnings.TERMINALWRITER_WRITER\n                pytest.deprecated_warnings.MINUS_K_DASH\n                pytest.deprecated_warnings.MINUS_K_COLON\n                pytest.deprecated_warnings.WARNING_CAPTURED_HOOK\n                pytest.deprecated_warnings.FSCOLLECTOR_GETHOOKPROXY_ISINITPATH\n            \"\"\"\n        )\n\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"*WARNING* The `funcargnames` attribute was an alias for `fixturenames`, since pytest 2.3 - use the newer attribute instead.*\",\n                \"*WARNING* The `_fillfuncargs` function is deprecated, use function._request._fillfixtures() instead if you cannot avoid reaching into internals.*\",\n                \"*WARNING* --result-log is deprecated, please try the new pytest-reportlog plugin.*\",\n                \"*WARNING* Passing arguments to pytest.fixture() as positional arguments is deprecated - pass them as a keyword argument instead.*\",\n                \"*WARNING* Direct construction of {name} has been deprecated, please use {name}.from_parent.*\",\n                \"*WARNING* The 'junit_family' default value will change to 'xunit2' in pytest 6.0.*\",\n                \"*WARNING* The pytest_collect_directory hook is not working.*\",\n                \"*WARNING* pytest.collect.{name} was moved to pytest.{name}*\",\n                \"*WARNING* The TerminalReporter.writer attribute is deprecated, use TerminalReporter._tw instead at your own risk.*\",\n                \"*WARNING* The"], "sample_1059": ["    def test_laguerre_assoc_laguerre_diff_alpha(self):\n        n = Symbol('n', integer=True)\n        a = Symbol('a')\n        f = assoc_laguerre(n, a, x)\n        df = diff(f, a)\n        expected = Sum(assoc_laguerre(k, a, x) / (n - a), (k, 0, n - 1))\n        self.assertEqual(df, expected)\n"], "sample_469": ["    def test_annotate_with_subquery(self):\n        subquery = Book.objects.filter(rating__gt=4).values('isbn').annotate(\n            count=Count('id')\n        )\n        qs = Book.objects.annotate(\n            popular_count=Subquery(subquery)\n        )\n        result = qs.all()\n        self.assertEqual(len(result), 4)\n        for book in result:\n            self.assertTrue(book.popular_count > 0)\n\n"], "sample_903": ["    def test_trustworthiness(self):\n        X = np.random.rand(100, 3)\n        X_embedded = TSNE(n_components=2).fit_transform(X)\n        trust = trustworthiness(X, X_embedded)\n        assert trust >= 0\n        assert trust <= 1\n\n\n\n"], "sample_73": ["    def test_manifest_strict_mode(self):\n        with override_settings(STATICFILES_STORAGE='django.contrib.staticfiles.storage.ManifestStaticFilesStorage',):\n            self.storage = storage.staticfiles_storage\n            self.storage.manifest_strict = True\n            self.storage.hashed_files = {}\n            self.storage.post_process(\n                {'static/test.css': ContentFile('/* test */')},\n            )\n            with self.assertRaises(ValueError):\n                self.storage.stored_name('static/missing.css')\n"], "sample_1128": ["    def test_partial_velocity_multiple_frames(self):\n        N = ReferenceFrame('N')\n        A = ReferenceFrame('A')\n        B = ReferenceFrame('B')\n        B.orientnew('B', 'Axis', [dynamicsymbols('q'), N.z])\n        p = Point('p')\n        u1, u2, u3 = dynamicsymbols('u1, u2, u3')\n        p.set_vel(N, u1 * N.x + u2 * A.y)\n        p.set_vel(B, u3 * B.x)\n        with raises(ValueError):\n            p.partial_velocity(N, u1, u2, u3)\n"], "sample_1083": ["    def test_asech_complex():\n        from sympy.functions.special.hyperbolic import asech\n        z = asech(S.ImaginaryUnit)\n        assert z == -I*pi/2\n        z = asech(S.ImaginaryUnit*(sqrt(6) - sqrt(2)))\n        assert z == -5*I*pi/12\n        z = asech(S.ImaginaryUnit*2)\n        assert z == -I*pi/3\n        z = asech(-S.ImaginaryUnit*2)\n        assert z == 2*I*pi/3\n        z = asech(S.ImaginaryUnit*sqrt(2))\n        assert z == -3*I*pi/4\n        z = asech(S.ImaginaryUnit*sqrt(2 + sqrt(2)))\n        assert z == -3*I*pi/8\n        z = asech(S.ImaginaryUnit*sqrt(2 - 2/sqrt(5)))\n        assert z == -2*I*pi/5\n        z = asech(S.ImaginaryUnit*(sqrt(5)-1))\n        assert z == -3*I*pi/10\n        z = asech(S.ImaginaryUnit*2/sqrt(3))\n        assert z == -I*pi/3\n        z = asech(S.ImaginaryUnit*2/sqrt(2 + sqrt(2)))\n        assert z == -3*I*pi/8\n        z = asech(S.ImaginaryUnit*(sqrt(6) + sqrt(2)))\n        assert z == 5*I*pi/12\n        z = asech(S.ImaginaryUnit*(-1 - sqrt(5)))\n        assert z == 3*I*pi/5\n        z = asech(S.ImaginaryUnit*(1 + sqrt(5)))\n        assert z == 2*I*pi/5\n        z = asech(S.ImaginaryUnit*2/sqrt(2 - 2/sqrt(5)))\n        assert z == -7*I*pi/10\n        z = asech(S.ImaginaryUnit*sqrt(2 + 2/sqrt(5)))\n        assert z == 3*I*pi/10\n        z = asech(S"], "sample_329": ["    def test_serialize_functools_partial(self):\n            return a + b + kwargs.get('c', 0)\n\n        partial = functools.partial(func, b=10, c=5)\n        serialized = OperationWriter(partial, indentation=0).serialize()\n        self.assertEqual(\n            serialized,\n            'functools.partial(func, b=10, c=5)'\n        )\n\n\n\n"], "sample_483": ["    def test_admin_checks(self):\n        admin_site = AdminSite()\n        admin_site.register(Song, ValidFields)\n        admin_site.register(Album, MyAdmin)\n        admin_site.register(Author, admin.ModelAdmin)\n        admin_site.register(Book, admin.ModelAdmin)\n        admin_site.register(City, admin.ModelAdmin)\n        admin_site.register(State, admin.ModelAdmin)\n        admin_site.register(TwoAlbumFKAndAnE, admin.ModelAdmin)\n        admin_site.register(Influence, admin.ModelAdmin)\n\n        errors = checks.run_checks(\n            [\n                admin_site,\n                AuthenticationMiddlewareSubclass(),\n                MessageMiddlewareSubclass(),\n                ModelBackendSubclass(),\n                SessionMiddlewareSubclass(),\n            ]\n        )\n        self.assertEqual(len(errors), 1)\n        self.assertIn(\n            \"error!\",\n            str(errors[0]),\n        )\n\n\n\n"], "sample_1117": ["    def test_AskDiagonalHandler_MatMul_empty_or_1x1(self):\n        self.assertTrue(AskDiagonalHandler.MatMul(\n            ZeroMatrix(2, 2), []))\n        self.assertTrue(AskDiagonalHandler.MatMul(\n            OneMatrix(2, 2), []))\n        self.assertTrue(AskDiagonalHandler.MatMul(\n            DiagonalMatrix([1, 2], 2), []))\n        self.assertTrue(AskDiagonalHandler.MatMul(\n            DiagonalMatrix([1], 1), []))\n"], "sample_1129": ["    def test_sympy_printing(self):\n        expr = Piecewise((x, x < 0), (x**2, x >= 0))\n        self.assertEqual(pycode(expr, standard='python3'), 'sympy.Piecewise((x, x < 0), (x**2, x >= 0))')\n\n        expr = MatrixSolve(MatrixSymbol('A', 2, 2), MatrixSymbol('B', 2, 1))\n        self.assertEqual(pycode(expr, standard='python3'), 'sympy.MatrixSolve(A, B)')\n\n        expr = SparseMatrix(((1, 0, 2), (0, 1, 3)), (2, 3))\n        self.assertEqual(pycode(expr, standard='python3'), 'sympy.sparse.coo_matrix(((1, 0, 2), (0, 1, 3)), shape=(2, 3))')\n\n        expr = Assignment(p[0], 1)\n        self.assertEqual(pycode(expr, standard='python3'), 'p[0] = 1')\n\n        expr = KroneckerDelta(x, y)\n        self.assertEqual(pycode(expr, standard='python3'), 'sympy.KroneckerDelta(x, y)')\n\n        expr =  Eq(x, y)\n        self.assertEqual(pycode(expr, standard='python3'), 'Eq(x, y)')\n\n        expr = Le(x, y)\n        self.assertEqual(pycode(expr, standard='python3'), 'sympy.Le(x, y)')\n\n        expr = Gt(x, y)\n        self.assertEqual(pycode(expr, standard='python3'), 'sympy.Gt(x, y)')\n\n        expr = Mod(x, 2)\n        self.assertEqual(pycode(expr, standard='python3'), 'sympy.Mod(x, 2)')\n\n        expr =  sqrt(x)\n        self.assertEqual(pycode(expr, standard='python3'), 'sympy.sqrt(x)')\n\n        expr =  acos(x)\n        self.assertEqual(pycode(expr, standard='python3'), 'sympy.acos(x)')\n\n        expr =  sign(x"], "sample_274": ["    def test_modelchoicefield_invalid_choice_error(self):\n        class MyForm(Form):\n            choice = ModelChoiceField(queryset=ChoiceModel.objects.none(), empty_label=None)\n\n        form = MyForm({'choice': 123})\n        self.assertFormErrors(\n            {'choice': ['Select a valid choice. 123 is not one of the available choices.']},\n            form.is_valid,\n        )\n\n\n\n"], "sample_631": ["    def test_unused_arguments_in_method(self):\n        code = \"\"\""], "sample_925": ["    def test_mock_module_attributes(self):\n        with mock(['test.module']):\n            mod = import_module('test.module')\n            assert isinstance(mod, _MockModule)\n            assert mod.__file__ == os.devnull\n            assert mod.__sphinx_mock__ is True\n            assert mod.__all__ == []\n            assert mod.__path__ == []\n            assert isinstance(mod.some_attribute, _MockObject)\n"], "sample_857": ["    def test_sparse_data(self):\n        for name in [\"sparse-pos\", \"sparse-neg\", \"sparse-mix\"]:\n            X = DATASETS[name][\"X\"]\n            y = DATASETS[name][\"y\"]\n            for tree_type in SPARSE_TREES:\n                clf = CLF_TREES[tree_type](random_state=0)\n                reg = REG_TREES[tree_type](random_state=0)\n                clf.fit(X, y)\n                reg.fit(X, y)\n                with pytest.raises(ValueError):\n                    clf.predict(csr_matrix(X))\n                with pytest.raises(ValueError):\n                    reg.predict(csr_matrix(X))\n                with pytest.raises(ValueError):\n                    clf.predict(csc_matrix(X))\n                with pytest.raises(ValueError):\n                    reg.predict(csc_matrix(X))\n                with pytest.raises(ValueError):\n                    clf.predict(coo_matrix(X))\n                with pytest.raises(ValueError):\n                    reg.predict(coo_matrix(X))\n                with pytest.raises(ValueError):\n                    clf.predict(X_sparse_pos)\n                with pytest.raises(ValueError):\n                    reg.predict(X_sparse_pos)\n                with pytest.raises(ValueError):\n                    clf.predict(X_sparse_neg)\n                with pytest.raises(ValueError):\n                    reg.predict(X_sparse_neg)\n                with pytest.raises(ValueError):\n                    clf.predict(X_sparse_mix)\n                with pytest.raises(ValueError):\n                    reg.predict(X_sparse_mix)\n\n\n\n"], "sample_1005": ["    def test_latex_complex_roots(self):\n        expr = RootSum(\n            (x**2 - 1), 1, 2)\n        self.assertEqual(latex(expr), r\"\\mathcal{R}_{1,2}\\left(x^{2} - 1\\right)\")\n"], "sample_356": ["    def test_migration_dependencies_with_circular_fk(self):\n        before_states = self.make_project_state([\n            rabbit,\n        ])\n        after_states = self.make_project_state([\n            rabbit,\n        ], {\n            \"eggs\": [\n                (\"0001_initial\", [\n                    models.CreateModel(\n                        name=\"Rabbit\",\n                        fields=[\n                            models.AutoField(primary_key=True),\n                            models.ForeignKey(\"Knight\", on_delete=models.CASCADE),\n                            models.ForeignKey(\"Rabbit\", on_delete=models.CASCADE, related_name=\"parent\"),\n                        ],\n                        options={\"unique_together\": [(\"parent\", \"knight\")]},\n                        indexes=[models.Index(fields=[\"parent\", \"knight\"], name='rabbit_circular_fk_index')],\n                    ),\n                ]),\n            ],\n        })\n        changes = self.get_changes(before_states, after_states)\n        self.assertMigrationDependencies(changes, \"eggs\", 0, [\"eggs.Knight\"])\n"], "sample_837": ["        def test_show_versions_prints_info(self, mock_blas_info, mock_deps_info, mock_sys_info):\n            mock_sys_info.return_value = {\"python\": \"mock_python\", \"executable\": \"mock_executable\", \"machine\": \"mock_machine\"}\n            mock_deps_info.return_value = {\"pip\": \"mock_pip\", \"setuptools\": \"mock_setuptools\"}\n            mock_blas_info.return_value = {\"macros\": \"mock_macros\", \"lib_dirs\": \"mock_lib_dirs\", \"cblas_libs\": \"mock_cblas_libs\"}\n\n            show_versions()\n\n            self.assertEqual(mock_sys_info.call_count, 1)\n            self.assertEqual(mock_deps_info.call_count, 1)\n            self.assertEqual(mock_blas_info.call_count, 1)\n"], "sample_1038": ["    def test_from_index_summation_trace(self):\n        from sympy.matrices.expressions.index_summation import from_index_summation\n        expr = Sum(A[i, i], (i, 0, n-1))\n        result = from_index_summation(expr)\n        self.assertEqual(result, trace(A))\n"], "sample_987": ["    def test_evalf_bernoulli():\n        from sympy.functions.special.bernoulli import bernoulli\n        for k in range(10):\n            v = bernoulli(k)\n            r = N(v, 10)\n            assert abs(r - bernoulli(k).evalf(10)) < 1e-8\n"], "sample_626": ["compilation error"], "sample_297": ["compilation error"], "sample_722": ["    def test_reassignment_ratio(self):\n        # Test the impact of reassignment_ratio on convergence\n        n_samples = 1000\n        n_clusters = 5\n        X, _ = make_blobs(n_samples=n_samples, centers=n_clusters,\n                          cluster_std=1., random_state=42)\n        \n        # Test with a low reassignment ratio\n        mbkmeans1 = MiniBatchKMeans(n_clusters=n_clusters,\n                                   batch_size=100,\n                                   reassignment_ratio=0.01,\n                                   max_iter=10)\n        mbkmeans1.fit(X)\n        \n        # Test with a high reassignment ratio\n        mbkmeans2 = MiniBatchKMeans(n_clusters=n_clusters,\n                                   batch_size=100,\n                                   reassignment_ratio=0.1,\n                                   max_iter=10)\n        mbkmeans2.fit(X)\n\n        # Check if the inertia is lower with a higher reassignment ratio\n        assert_less(mbkmeans2.inertia_, mbkmeans1.inertia_)\n"], "sample_647": ["    def test_warn_explicit_for(self, warning_class: type[Warning]):\n            pass\n\n        with pytest.warns(warning_class) as w:\n            warn_explicit_for(my_func, warning_class())\n        assert len(w) == 1\n        assert w[0].filename == inspect.getfile(my_func)\n        assert w[0].lineno == my_func.__code__.co_firstlineno\n"], "sample_964": ["    def test_parse_annotation(self):\n        assert _parse_annotation(\"int\") == (\"int\", None)\n        assert _parse_annotation(\"int | str\") == (\"int | str\", None)\n        assert _parse_annotation(\"int: str\") == (\"int: str\", None)\n        assert _parse_annotation(\"int -> str\") == (\"int -> str\", None)\n        assert _parse_annotation(\"int -> None\") == (\"int -> None\", None)\n        assert _parse_annotation(\"int -> Optional[str]\") == (\"int -> Optional[str]\", None)\n        assert _parse_annotation(\"list[int]\") == (\"list[int]\", None)\n        assert _parse_annotation(\"typing.List[int]\") == (\"typing.List[int]\", None)\n        assert _parse_annotation(\"Union[int, str]\") == (\"Union[int, str]\", None)\n        assert _parse_annotation(\"Callable[[int], str]\") == (\"Callable[[int], str]\", None)\n        assert _parse_annotation(\"int, str\") == (\"int, str\", None)\n        assert _parse_annotation(\"int, Optional[str]\") == (\"int, Optional[str]\", None)\n        assert _parse_annotation(\"int, typing.List[str]\") == (\"int, typing.List[str]\", None)\n        assert _parse_annotation(\"int, Union[str, int]\") == (\"int, Union[str, int]\", None)\n\n\n\n"], "sample_823": ["    def test_pairwise_distances_chunked_reduce_func(metric):\n        X = np.random.rand(100, 5)\n        Y = np.random.rand(100, 5)\n\n            return np.mean(D_chunk, axis=1)\n\n        with config_context(working_memory=10):\n            gen = pairwise_distances_chunked(X, Y, metric=metric,\n                                            reduce_func=reduce_func)\n            for i in range(10):\n                chunk = next(gen)\n                assert isinstance(chunk, np.ndarray)\n                assert chunk.shape[0] == X.shape[0] // 10\n"], "sample_200": ["    def test_sanitize_address_invalid_address(self):\n        with self.assertRaises(ValueError):\n            sanitize_address('invalid address')\n"], "sample_346": ["    def test_decorator_from_middleware(self):\n        @decorator_from_middleware(XFrameOptionsMiddleware)\n            return HttpResponse(\"OK\")\n\n        response = view(HttpRequest())\n        self.assertEqual(response['X-Frame-Options'], 'SAMEORIGIN')\n"], "sample_648": ["    def test_empty_parameterset_mark(self, pytester: Pytester):\n            pass\n\n        # Set up a mock config object\n        mock_config = mock.Mock(spec=Config)\n        mock_config.getini.return_value = EMPTY_PARAMETERSET_OPTION\n\n        # Create a mock collector object\n        mock_collector = mock.Mock(spec=Collector)\n        mock_collector.config = mock_config\n\n        # Call get_empty_parameterset_mark with the mock objects\n        mark = get_empty_parameterset_mark(\n            mock_config, [\"arg1\", \"arg2\"], test_function\n        )\n\n        # Assert that the mark is of the expected type\n        assert isinstance(mark, MarkDecorator)\n\n        # Assert that the mark has the expected name and arguments\n        assert mark.name == \"empty_parameterset\"\n        assert mark.args == ()\n        assert mark.kwargs == {\"reason\": \"got empty parameter set %r, function test_function at <unknown>:1\"}\n\n        # Assert that the mark was applied to the test function\n        assert test_function.pytestmark is not None\n        assert isinstance(test_function.pytestmark, list)\n        assert mark in test_function.pytestmark\n\n        # Assert that the collector was not raised\n        assert not mock_collector.exception\n\n\n\n"], "sample_437": ["    def test_atomic_block_rollback(self):\n        with transaction.atomic():\n            Person.objects.create(name=\"Alice\")\n            raise ValueError(\"Intentional error\")\n\n        # Check that the object was not saved\n        with self.assertRaises(ValueError):\n            Person.objects.get(name=\"Alice\")\n\n\n\n"], "sample_938": ["    def test_default_man_pages(app: Sphinx, tmpdir) -> None:\n        config = Config(app)\n        config.project = 'myproject'\n        config.release = '0.1'\n        config.author = 'John Doe'\n        config.master_doc = 'index'\n\n        expected_man_pages = default_man_pages(config)\n        assert expected_man_pages == [\n            ('index', 'myproject', 'myproject 0.1', ['John Doe'], 1)\n        ]\n"], "sample_72": ["    def test_serialize_custom_operation(self):\n        class CustomOperation(custom_migration_operations.more_operations.MoreOperation):\n                self.value = value\n\n                return (\n                    'custom_migration_operations.more_operations.MoreOperation',\n                    [self.value],\n                    {},\n                )\n\n        operation = CustomOperation('test')\n        serializer = OperationSerializer(operation)\n        serialized_operation = serializer.serialize()\n        self.assertEqual(\n            serialized_operation,\n            \"custom_migration_operations.more_operations.MoreOperation(test)\",\n            \"Custom operation serialization failed\"\n        )\n"], "sample_420": ["    def test_custom_error_message(self):\n        form = CustomErrorMessageForm(data={\"name1\": \"invalid\"})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors[\"name1\"], [\"Form custom error message.\"])\n"], "sample_1064": ["    def _compare_tensorflow_derivative(variables, expr):\n        f = lambdify(variables, expr, 'tensorflow')\n        random_matrices = [\n            randMatrix(v.rows, v.cols).evalf() / 100 for v in variables]\n\n        graph = tf.Graph()\n        r = None\n        with graph.as_default():\n            random_variables = [eval(tensorflow_code(i)) for i in random_matrices]\n            session = tf.compat.v1.Session(graph=graph)\n            r = session.run(f(*random_variables))\n\n        e = expr.doit()\n        assert abs(r-e) < 10**-6\n"], "sample_27": ["    def test_diff_nonstandard_extension(self):\n        hdu1 = PrimaryHDU(np.arange(10).reshape((2, 5)).astype(np.float32))\n        hdu2 = DummyNonstandardExtHDU(np.arange(10).reshape((2, 5)).astype(np.float32))\n        hdulist = HDUList([hdu1, hdu2])\n        diff = FITSDiff(hdulist, hdulist)\n\n        # Check that the diff object is created correctly\n        assert isinstance(diff, FITSDiff)\n        assert diff.diff_header_keywords\n\n        # Check that the diff object correctly identifies the non-standard extension\n        assert isinstance(diff.diff_hdu_data[1], RawDataDiff)\n\n\n\n"], "sample_1057": ["compilation error"], "sample_573": ["    def test_polyfit_handles_low_unique_x_values(self, df, rng):\n        df[\"x\"] = df[\"x\"].drop_duplicates()\n        df = df.sort_values(by=\"x\")\n        with pytest.raises(ValueError):\n            PolyFit()(df, GroupBy(df, \"group\"), \"x\", None)\n"], "sample_265": ["    def test_get_templatetag_libraries(self):\n        with override_settings(INSTALLED_APPS=['app1', 'app2']):\n            libraries = self.engine.get_templatetag_libraries({})\n            self.assertIn('app1', libraries)\n            self.assertIn('app2', libraries)\n            self.assertIn('i18n', libraries)\n"], "sample_343": ["    def test_generic_foreign_key_with_m2m_field(self):\n        post = Post.objects.create(title='Post Title')\n        question = Question.objects.create(title='Question Title')\n        answer = Answer.objects.create(question=question, content='Answer Content')\n\n        # Create a GenericForeignKey on Post to Answer\n        class PostAnswer(models.Model):\n            post = models.ForeignKey(Post, on_delete=models.CASCADE)\n            answer = GenericForeignKey(\n                ct_field='content_type',\n                fk_field='object_id',\n                for_concrete_model=True,\n            )\n            content_type = models.ForeignKey(ContentType, on_delete=models.CASCADE)\n            object_id = models.PositiveIntegerField()\n\n        post_answer = PostAnswer.objects.create(post=post, content_type=Answer._meta.model_type, object_id=answer.pk)\n\n        self.assertEqual(post_answer.answer, answer)\n\n        # Check that the related object is still accessible even after deleting the\n        # related object\n        answer.delete()\n        with self.assertRaises(ObjectDoesNotExist):\n            PostAnswer.objects.get(post=post)\n\n        # Check that the related object is still accessible even after deleting the\n        # related object\n        post.delete()\n        with self.assertRaises(ObjectDoesNotExist):\n            PostAnswer.objects.get(post=post)\n\n\n\n"], "sample_147": ["    def test_union_with_distinct(self):\n        numbers = Number.objects.filter(num__gt=5).union(Number.objects.filter(num__lt=5))\n        self.assertNumbersEqual(numbers, list(range(10)))\n\n        numbers = Number.objects.filter(num__gt=5).union(Number.objects.filter(num__lt=5)).distinct()\n        self.assertNumbersEqual(numbers, list(range(10)), ordered=False)\n"], "sample_1152": ["compilation error"], "sample_183": ["    def test_case_expression_with_complex_conditions(self):\n        qs = CaseTestModel.objects.annotate(\n            result=Case(\n                When(integer=1, then=1),\n                When(integer=2, then=2),\n                When(integer=3, then=3),\n                default=0,\n            )\n        )\n        results = qs.values_list('integer', 'result')\n        expected_results = [\n            (1, 1),\n            (2, 2),\n            (3, 3),\n            (4, 0),\n        ]\n        self.assertQuerysetEqual(results, expected_results)\n\n        qs = CaseTestModel.objects.annotate(\n            result=Case(\n                When(integer__gt=2, then=1),\n                When(integer__lte=2, then=0),\n                default=0,\n            )\n        )\n        results = qs.values_list('integer', 'result')\n        expected_results = [\n            (1, 0),\n            (2, 0),\n            (3, 1),\n            (4, 1),\n        ]\n        self.assertQuerysetEqual(results, expected_results)\n\n        qs = CaseTestModel.objects.annotate(\n            result=Case(\n                When(integer2=1, then=1),\n                When(integer2=2, then=2),\n                When(integer2=3, then=3),\n                default=0,\n            )\n        )\n        results = qs.values_list('integer2', 'result')\n        expected_results = [\n            (1, 1),\n            (2, 2),\n            (3, 3),\n            (4, 0),\n        ]\n        self.assertQuerysetEqual(results, expected_results)\n\n        qs = CaseTestModel.objects.annotate(\n            result=Case(\n                When(string='1', then=1),\n                When(string='2', then=2),\n                When(string='3', then=3),\n                default=0,\n            )\n        )\n        results = qs.values_list('string', 'result')\n        "], "sample_1058": ["    def test_sparse_matrix(self):\n        m = SparseMatrix([[1, 2], [3, 4]], (2, 2))\n        code = pycode(m, printer=SciPyPrinter())\n        expected = \"scipy.sparse.coo_matrix([[1, 2], [3, 4]], ((0, 0), (0, 1), (1, 0), (1, 1)), shape=(2, 2))\"\n        assert code == expected\n"], "sample_465": ["    def test_get_actions(self):\n        class MyModelAdmin(ModelAdmin):\n            actions = [\"my_action\"]\n\n        admin_class = MyModelAdmin\n        admin = admin_class(Band, self.site)\n        actions = admin.get_actions(request)\n        self.assertIn(\"my_action\", actions)\n\n"], "sample_406": ["    def test_manager_descriptor(self):\n        class MyModel(models.Model):\n            pass\n\n        manager = BaseManager.from_queryset(QuerySet, 'MyManager')\n        manager.contribute_to_class(MyModel, 'my_manager')\n        self.assertEqual(MyModel.my_manager, manager)\n        self.assertEqual(MyModel._meta.managers_map['my_manager'], manager)\n"], "sample_759": ["    def test_onehotencoder_legacy_fit_transform_with_unknown_categories(self):\n        enc = OneHotEncoder(handle_unknown='ignore', n_values='auto')\n        X = np.array([[1, 2], [3, 4], [5, 6]])\n        enc.fit(X)\n        X_transformed = enc.transform(X)\n        assert X_transformed.shape[1] == 6\n\n        # Check that unknown categories are handled as expected\n        X_new = np.array([[7, 8]])\n        X_transformed_new = enc.transform(X_new)\n        assert (X_transformed_new.toarray() == 0).all()\n"], "sample_948": ["    def test_cpp_domain_enum_scoped(\n        ):\n        _check(\n            'enum',\n            'enum MyEnum { VALUE = 1; }',\n            {'1': 'MyEnum.VALUE'},\n            'MyEnum { VALUE = 1; }',\n            asTextOutput='MyEnum { VALUE = 1; }'\n        )\n"], "sample_756": ["    def test_optics_dbscan_equivalence(self):\n        optics = OPTICS(eps=0.5, min_samples=5)\n        optics.fit(X)\n        dbscan = DBSCAN(eps=0.5, min_samples=5)\n        dbscan.fit(X)\n\n        assert_array_equal(optics.labels_, dbscan.labels_)\n        assert_array_equal(optics.core_sample_indices_, dbscan.core_sample_indices_)\n\n\n\n"], "sample_122": ["    def test_patch_vary_headers(self):\n        response = HttpResponse()\n        patch_vary_headers(response, ['Accept-Language'])\n        self.assertEqual(response['Vary'], 'Accept-Language')\n\n        patch_vary_headers(response, ['Accept-Language', 'User-Agent'])\n        self.assertEqual(response['Vary'], 'Accept-Language, User-Agent')\n\n        patch_vary_headers(response, ['*'])\n        self.assertEqual(response['Vary'], '*')\n\n\n\n"], "sample_782": ["    def test_remainder_estimator(self):\n        X = np.array([[1, 2], [3, 4]])\n        remainder_est = Trans()\n        ct = ColumnTransformer(\n            transformers=[('scaler', StandardScaler(), [0]),\n                          ('remainder', remainder_est, [1])],\n            remainder='remainder'\n        )\n        ct.fit(X)\n        X_transformed = ct.transform(X)\n        expected_X_transformed = np.hstack(\n            (\n                StandardScaler().fit_transform(X[:, 0].reshape(-1, 1)),\n                remainder_est.transform(X[:, 1].reshape(-1, 1))\n            )\n        )\n        assert_allclose_dense_sparse(X_transformed, expected_X_transformed)\n"], "sample_804": ["    def test_onehotencoder_sparse_transform(self):\n        X = np.array([[0, 1], [1, 0], [2, 2]])\n        encoder = OneHotEncoder(sparse=True)\n        encoder.fit(X)\n        X_sparse = encoder.transform(X)\n        X_dense = encoder.transform(X).toarray()\n        assert_array_equal(toarray(X_sparse), X_dense)\n"], "sample_1010": ["    def test_latex_complex_root(self):\n        expr = RootSum(x**2 - 1, 1)\n        expected = r\"\\mathcal{R}_{1}\\left(x^{2} - 1\\right)\"\n        self.assertEqual(latex(expr), expected)\n"], "sample_1048": ["    def test_intersection_ellipse(self):\n        p1 = Point(0, 0)\n        l1 = Line(Point(1, -2), Point(-1, -2))\n        parabola1 = Parabola(p1, l1)\n        ellipse1 = Ellipse(Point(0, 0), 2, 5)\n        intersection = parabola1.intersection(ellipse1)\n        assert len(intersection) == 2\n        assert intersection[0].x == -2\n        assert intersection[0].y == 0\n        assert intersection[1].x == 2\n        assert intersection[1].y == 0\n"], "sample_1079": ["    def test_point_intersection_line(self):\n        p1 = Point2D(1, 1)\n        l = Line(Point2D(0, 0), Point2D(1, 1))\n        self.assertEqual(p1.intersection(l), [p1])\n\n        p2 = Point2D(2, 2)\n        self.assertEqual(p2.intersection(l), [])\n\n        p3 = Point2D(0, 0)\n        self.assertEqual(p3.intersection(l), [p3])\n"], "sample_1044": ["    def test_as_content_primitive_sqrt(self):\n        from sympy import sqrt\n        for i in range(1, 10):\n            a = i\n            b = i + i*sqrt(2)\n            c, r = b.as_content_primitive(radical=True)\n            assert c == a\n            assert r == sqrt(1 + sqrt(2))\n            assert r**2 == 1 + sqrt(2)\n            assert (c*r)**2 == b**2\n            assert r.is_real is True\n            assert r.is_irrational is True\n            assert r.is_number is True\n            assert r.is_positive is True\n\n\n\n"], "sample_805": ["    def test_mean_tweedie_deviance_errors(self):\n        # Test for invalid input values\n        y_true = np.array([1, 2, 3])\n        y_pred = np.array([1.5, 2.5, 3.5])\n\n        with pytest.raises(ValueError, match=\"Tweedie deviance is only defined for p<=0 and p>=1.\"):\n            mean_tweedie_deviance(y_true, y_pred, p=0.5)\n\n        with pytest.raises(ValueError, match=\"strictly positive y_pred.\"):\n            mean_tweedie_deviance(y_true, y_pred, p=-1)\n\n        with pytest.raises(ValueError, match=\"non-negative y_true and strictly positive y_pred.\"):\n            mean_tweedie_deviance(y_true, y_pred, p=1, y_true=np.array([-1, 2, 3]))\n\n        with pytest.raises(ValueError, match=\"strictly positive y_true and y_pred.\"):\n            mean_tweedie_deviance(y_true, y_pred, p=2, y_true=np.array([0, 2, 3]))\n\n\n\n"], "sample_504": ["def test_colorbar_extension_length():\n    \"\"\"\n    Test colorbar extensions with varying lengths for uniform and\n    proportional spacing.\n    \"\"\"\n    with rc_context({'axes.formatter.limits': (-10, 10)}):\n        fig = _colorbar_extension_length('uniform')\n    return fig\n"], "sample_246": ["    def test_no_locale_dir(self):\n        with self.settings(LOCALE_PATHS=[]):\n            with self.assertRaises(CommandError) as cm:\n                execute_from_command_line(['django-admin', 'makemessages', '--domain=django', '--locale=en'])\n            self.assertIn(\n                \"Unable to find a locale path to store translations for\",\n                str(cm.exception),\n            )\n\n\n\n"], "sample_1102": ["    def test_cancel_with_integers(self):\n        from sympy import cancel, S\n\n        self.assertEqual(cancel(2*x**2 - 2*y**2, x**3 - x), (2*x, x**2 - 2*y**2))\n        self.assertEqual(cancel(2*x**2 - 2*y**2, x**3 - x, domain=ZZ), (2*x, x**2 - 2*y**2))\n        self.assertEqual(cancel(2*x**2 - 2*y**2, x**3 - x, auto=False), (2*x**2 - 2*y**2, x**3 - x))\n        self.assertEqual(cancel(S(2)*x**2 - S(2)*y**2, x**3 - x), (2*x, x**2 - 2*y**2))\n        self.assertEqual(cancel(S(2)*x**2 - S(2)*y**2, x**3 - x, domain=ZZ), (2*x, x**2 - 2*y**2))\n"], "sample_443": ["    def test_file_based_cache_touch(self):\n        cache_dir = tempfile.mkdtemp()\n        cache = FileBasedCache(dir=cache_dir, params={})\n        key = \"test_key\"\n        value = \"test_value\"\n\n        cache.set(key, value, timeout=1)\n        self.assertTrue(cache.has_key(key))\n\n        # Touch the key, extending its timeout\n        cache.touch(key)\n        self.assertTrue(cache.has_key(key))\n\n        # Wait for the cache to expire\n        time.sleep(2)\n        self.assertFalse(cache.has_key(key))\n\n        os.rmdir(cache_dir)\n"], "sample_301": ["    def test_iter_modules_and_files_with_zip_files(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_filename = self.temporary_file('my_module.zip')\n            with zipfile.ZipFile(zip_filename, 'w') as zf:\n                zf.write('__init__.py', arcname='my_module')\n                zf.write('module.py', arcname='my_module/module.py')\n            extend_sys_path([tempdir])\n            self.import_and_cleanup('my_module')\n            self.assertFileFound(zip_filename)\n            self.assertFileFound(zip_filename.parent / 'my_module' / '__init__.py')\n            self.assertFileFound(zip_filename.parent / 'my_module' / 'module.py')\n            self.assertFileNotFound(self.temporary_file('non_existent_file.py'))\n"], "sample_868": ["    def test_symmetric_metrics(metric_name):\n        metric_func = SUPERVISED_METRICS[metric_name]\n        score1 = metric_func(y1, y2)\n        score2 = metric_func(y2, y1)\n        assert_allclose(score1, score2, rtol=1e-05)\n\n"], "sample_788": ["def test_inverse_transform_with_onehot():\n    est = KBinsDiscretizer(n_bins=3, encode='onehot', strategy='uniform')\n    est.fit(X)\n    Xt = est.transform(X)\n    Xinv = est.inverse_transform(Xt)\n    assert_array_almost_equal(Xinv, X)\n"], "sample_121": ["    def test_index_together_with_related_fields(self):\n        with override_settings(INSTALLED_APPS=['invalid_models_tests']):\n            from invalid_models_tests import Author, Book\n\n            # Test that index_together works with related fields.\n            errors = _check_lazy_references(Author)\n            self.assertEqual(len(errors), 0)\n\n            errors = _check_lazy_references(Book)\n            self.assertEqual(len(errors), 0)\n\n            # Check that the index is created correctly.\n            with connection.cursor() as cursor:\n                cursor.execute(\"SELECT * FROM django_indexes WHERE table_name = 'invalid_models_tests_book'\")\n                indexes = cursor.fetchall()\n                self.assertEqual(len(indexes), 1)\n                self.assertIn(('author_id',), indexes[0])\n\n\n\n"], "sample_358": ["    def test_table_references(self):\n        self.assertFalse(self.reference.references_table('other_table'))\n        self.assertTrue(self.reference.references_table('TABLE'))\n"], "sample_171": ["    def test_migrate_with_fake_initial(self):\n        with self.settings(DATABASE_ROUTERS={'default': TestRouter()}):\n            self.create_test_database('default')\n            self.create_test_database('other')\n            # Create a migration that creates a table\n            call_command('makemigrations', 'migrations')\n            # Run migrate with fake_initial\n            with self.assertNumQueries(0):\n                call_command('migrate', '--fake-initial', database='default')\n            # Check that the table exists\n            with connections['default'].cursor() as cursor:\n                cursor.execute(\"SELECT COUNT(*) FROM django_migrations\")\n                self.assertEqual(cursor.fetchone()[0], 1)\n            with connections['default'].cursor() as cursor:\n                cursor.execute(\"SELECT COUNT(*) FROM migrations_test_app_unicodemodel\")\n                self.assertEqual(cursor.fetchone()[0], 0)\n            with connections['other'].cursor() as cursor:\n                cursor.execute(\"SELECT COUNT(*) FROM django_migrations\")\n                self.assertEqual(cursor.fetchone()[0], 0)\n            with connections['other'].cursor() as cursor:\n                cursor.execute(\"SELECT COUNT(*) FROM migrations_test_app_unicodemodel\")\n                self.assertEqual(cursor.fetchone()[0], 0)\n"], "sample_435": ["    def test_clean_password2_mismatch(self):\n        form = UserCreationForm(data={\"username\": \"testuser\", \"password1\": \"password\", \"password2\": \"wrongpassword\"})\n        with self.assertRaises(ValidationError) as context:\n            form.clean()\n        self.assertEqual(context.exception.code, \"password_mismatch\")\n"], "sample_674": ["def test_ischildnode(ischildnode):\n    for baseid, nodeid, expected in nodes.ischildnode_test_data:\n        assert ischildnode(baseid, nodeid) == expected\n"], "sample_1141": ["    def test_matrix_element_eval(self):\n        a = Matrix([[1, 2], [3, 4]])\n        e = MatrixElement(a, 0, 1)\n        assert e.evalf() == 2\n        assert e.subs(a, [[5, 6], [7, 8]]) == 6\n"], "sample_967": ["    def test_mathjax_config(app, status, warning):\n        app.config.mathjax_path = MATHJAX_URL\n        app.config.mathjax3_config = {'tex2jax': {\n            'inlineMath': [['$', '$'], ['\\\\(', '\\\\)']],\n            'displayMath': [['$$', '$$'], ['\\\\[', '\\\\]']]\n        }}\n        app.build()\n        with open(app.outdir / 'index.html') as f:\n            html = f.read()\n        assert r'<script>window.MathJax = {\"tex2jax\":{\"inlineMath\": [[\"$\",\"$\"],[\"\\\\(\",\"\\\\)\"]],\"displayMath\": [[\"$$\",\"$$\"],[\"\\\\[\",\"\\\\\\\\]\"]]}' in html\n"], "sample_973": ["    def test_signature_from_str_with_varargs_and_kwargs():\n        signature = 'def func(a, *, b, c, **d): pass'\n        sig = inspect.signature_from_str(signature)\n        assert sig.parameters['a'].kind == inspect.Parameter.POSITIONAL_OR_KEYWORD\n        assert sig.parameters['b'].kind == inspect.Parameter.POSITIONAL_OR_KEYWORD\n        assert sig.parameters['c'].kind == inspect.Parameter.POSITIONAL_OR_KEYWORD\n        assert sig.parameters['d'].kind == inspect.Parameter.VAR_KEYWORD\n\n\n\n"], "sample_531": ["    def test_constrained_layout_engine_execute(self):\n        fig = Figure(figsize=(6, 4))\n        ax1 = fig.add_subplot(211)\n        ax2 = fig.add_subplot(212)\n\n        # Add some content to the axes\n        ax1.plot([1, 2, 3])\n        ax2.scatter([1, 2, 3], [4, 5, 6])\n\n        # Set up the constrained layout engine\n        engine = ConstrainedLayoutEngine()\n        engine.execute(fig)\n\n        # Check that the axes are properly positioned\n        assert ax1.get_position().x0 > 0.1\n        assert ax1.get_position().y0 > 0.1\n        assert ax2.get_position().x0 > 0.1\n        assert ax2.get_position().y0 < 0.9\n\n        # Check that the layout is tight\n        fig.tight_layout()\n        fig.canvas.draw()\n\n        # Save the figure for comparison\n        fig.savefig('constrained_layout_test.png')\n\n\n\n"], "sample_439": ["    def test_order_fields(self):\n        class MyForm(Form):\n            field1 = CharField()\n            field2 = CharField()\n            field3 = CharField()\n\n        form = MyForm()\n        self.assertEqual(list(form.fields), [\"field1\", \"field2\", \"field3\"])\n\n        form = MyForm(field_order=[\"field3\", \"field1\", \"field2\"])\n        self.assertEqual(list(form.fields), [\"field3\", \"field1\", \"field2\"])\n\n        form = MyForm(field_order=[\"field1\", \"field2\", \"field4\"])\n        self.assertEqual(list(form.fields), [\"field1\", \"field2\", \"field3\"])\n"], "sample_958": ["    def test_cpp_enum_declaration(self):\n        idDict = {\n            1: \"enum_1\",\n            2: \"enum_2\",\n            3: \"enum_3\",\n        }\n        check(\n            \"enum\",\n            \"enum MyEnum { VALUE_1 = 1, VALUE_2 = 2, VALUE_3 = 3; }\",\n            idDict,\n            \"enum MyEnum { VALUE_1 = 1, VALUE_2 = 2, VALUE_3 = 3; }\",\n        )\n"], "sample_286": ["    def test_model_instance_creation_with_deferred_fields(self):\n        with self.assertNumQueries(1):\n            article = Article.objects.create(title='New Article', content='Some content')\n        self.assertEqual(article.content, 'Some content')\n        self.assertIsNotNone(article.created_at)\n        self.assertIsNotNone(article.updated_at)\n\n\n\n"], "sample_1053": ["    def test_sympify_mpmath_complex():\n        z = mpmath.complex(1, 2)\n        assert sympify(z) == 1 + 2*I\n"], "sample_289": ["    def test_ordered_set_reversed(self):\n        s = OrderedSet([1, 2, 3])\n        self.assertEqual(list(reversed(s)), [3, 2, 1])\n"], "sample_950": ["    def test_parse_annotation(self):\n        assert _parse_annotation('int') == 'int'\n        assert _parse_annotation('int: int') == 'int'\n        assert _parse_annotation('int, str') == 'int, str'\n        assert _parse_annotation('int -> str') == 'int -> str'\n        assert _parse_annotation('int -> None') == 'int -> None'\n        assert _parse_annotation('int -> list[str]') == 'int -> list[str]'\n        assert _parse_annotation('int -> typing.List[str]') == 'int -> typing.List[str]'\n        assert _parse_annotation('int -> Optional[str]') == 'int -> Optional[str]'\n        assert _parse_annotation('int -> Union[str, int]') == 'int -> Union[str, int]'\n        assert _parse_annotation('int -> Dict[str, int]') == 'int -> Dict[str, int]'\n        assert _parse_annotation('int -> Tuple[str, int]') == 'int -> Tuple[str, int]'\n        assert _parse_annotation('int -> Callable[[str], int]') == 'int -> Callable[[str], int]'\n        assert _parse_annotation('int -> Any') == 'int -> Any'\n        assert _parse_annotation('int -> ...') == 'int -> ...'\n\n\n\n"], "sample_417": ["    def test_floatformat_with_precision(self):\n        self.assertEqual(\n            self.render_template(\"floatformat01\", {\"a\": 123.456789, \"b\": 123.45}),\n            \"123.46 123.45\",\n        )\n"], "sample_399": ["compilation error"], "sample_981": ["    def test_unrank_trotterjohnson_small():\n        for n in range(1, 6):\n            for i in range(factorial(n)):\n                p = Permutation.unrank_trotterjohnson(n, i)\n                assert p.rank_trotterjohnson() == i\n                assert p.unrank_trotterjohnson(n, i) == p\n"], "sample_605": ["    def test_groupby_quantile_with_multiple_quantiles(array, dataset):\n        q = [0.1, 0.5, 0.9]\n        result = array.groupby(\"x\").quantile(q)\n        expected = xr.DataArray(\n            np.array([\n                [0.1, 0.5, 0.9],\n                [0.1, 0.5, 0.9],\n                [0.1, 0.5, 0.9],\n            ]),\n            coords={\"x\": [\"a\", \"b\", \"c\"], \"y\": [1, 2, 3, 4], \"z\": [1, 2]},\n            dims=(\"x\", \"y\", \"z\"),\n        )\n        assert_allclose(result, expected)\n"], "sample_600": ["    def test_cf_scale_offset_coder_roundtrip(self):\n        data = np.array([1, 2, 3], dtype=np.float32)\n        scale_factor = 2.0\n        add_offset = 1.5\n        var = xr.Variable((\"x\",), data, attrs={\"scale_factor\": scale_factor, \"add_offset\": add_offset})\n        coder = CFScaleOffsetCoder()\n        encoded_var = coder.encode(var)\n        decoded_var = coder.decode(encoded_var)\n        assert_allclose(decoded_var.data, data * scale_factor + add_offset)\n        assert_equal(decoded_var.attrs[\"scale_factor\"], scale_factor)\n        assert_equal(decoded_var.attrs[\"add_offset\"], add_offset)\n"], "sample_146": ["    def test_check_setting_languages_bidi(self):\n        with override_settings(LANGUAGES_BIDI=('en', 'fr-CA')):\n            errors = check_setting_languages_bidi(app_configs=None, **{})\n            self.assertEqual(errors, [])\n\n        with override_settings(LANGUAGES_BIDI=(None, 'fr-CA')):\n            errors = check_setting_languages_bidi(app_configs=None, **{})\n            self.assertEqual(len(errors), 1)\n            self.assertEqual(errors[0].id, 'translation.E003')\n\n        with override_settings(LANGUAGES_BIDI=(123, 'fr-CA')):\n            errors = check_setting_languages_bidi(app_configs=None, **{})\n            self.assertEqual(len(errors), 1)\n            self.assertEqual(errors[0].id, 'translation.E003')\n\n        with override_settings(LANGUAGES_BIDI=('en', 'fr-CA@invalid')):\n            errors = check_setting_languages_bidi(app_configs=None, **{})\n            self.assertEqual(len(errors), 1)\n            self.assertEqual(errors[0].id, 'translation.E003')\n"], "sample_1108": ["    def test_kbin_ordered():\n        for k in range(1, 6):\n            for ordered in [None, 0, 1, 10, 11]:\n                for l in range(1, 10):\n                    for p in kbins(list(range(l)), k, ordered=ordered):\n                        if ordered is None:\n                            assert len(p) == l // k\n                        elif ordered == 00:\n                            assert len(p) == l // k\n                        elif ordered == 11:\n                            assert len(p) == l // k\n                        else:\n                            assert len(p) == l // k\n                        assert all(len(pi) == l // k for pi in p)\n                        assert sum(len(pi) for pi in p) == l\n\n\n\n"], "sample_98": ["    def test_broken_pipe_error(self):\n        response = self.urlopen('/test/')\n        response.close()\n        with self.assertRaises(BrokenPipeError):\n            response.read()\n"], "sample_1030": ["    def test_idiff_complex():\n        x, y = Symbol('x'), Symbol('y')\n        eq = x**2 + y**2 - 4\n        with raises(ValueError):\n            idiff(eq, [y, x], x)\n        with raises(ValueError):\n            idiff(eq, 'y', x)\n        with raises(ValueError):\n            idiff(eq, y, 'x')\n        with raises(ValueError):\n            idiff(eq, y, x, n=3)\n        assert idiff(eq, y, x).simplify() == -x/y\n        assert idiff(eq, y, x, 2).simplify() == -(x**2 + y**2)/y**3\n        assert idiff(x + y, y, x) == -1\n        assert idiff(x + y, [y, x], x) == -Derivative(x, x) - 1\n        assert idiff(x + y + exp(x), y, x) == -Derivative(exp(x), x)\n        assert idiff(x + y + exp(x), [y, x], x) == -Derivative(exp(x), x) - 1\n\n\n\n"], "sample_11": ["    def test_sliced_wcs_pixel_to_world_values_single_dimension(self):\n        slices = (slice(1, 5), slice(None), slice(None))\n        sliced_wcs = SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, slices)\n        world_coords = sliced_wcs.pixel_to_world_values(1, 10, 15)\n        expected_world_coords = WCS_SPECTRAL_CUBE.pixel_to_world_values(1, 10, 15)\n        assert_allclose(world_coords, expected_world_coords)\n"], "sample_512": ["compilation error"], "sample_708": ["    def test_getstatementrange_ast_empty(monkeypatch):\n        source = Source()\n        astnode, start, end = getstatementrange_ast(0, source)\n        assert astnode is not None\n        assert start == 0\n        assert end == 0\n"], "sample_339": ["    def test_inlineformset_factory_can_delete_extra(self):\n        class RestaurantForm(forms.ModelForm):\n            class Meta:\n                model = Restaurant\n                fields = ['name', 'cuisine']\n\n        class LocationForm(forms.ModelForm):\n            class Meta:\n                model = Location\n                fields = ['name']\n\n        RestaurantFormSet = inlineformset_factory(\n            MexicanRestaurant, Location, form=LocationForm,\n            can_delete_extra=True\n        )\n\n        mexican_restaurant = MexicanRestaurant.objects.create(name='Test Restaurant')\n        formset = RestaurantFormSet(instance=mexican_restaurant)\n\n        # Add an extra location\n        formset.initial_form_count = 3\n        formset.data = {\n            'Location_set-0-name': 'Location 1',\n            'Location_set-1-name': 'Location 2',\n            'Location_set-2-name': 'Location 3',\n        }\n        formset.is_bound = True\n\n        formset.save()\n\n        self.assertEqual(Location.objects.count(), 3)\n        self.assertEqual(mexican_restaurant.location_set.count(), 3)\n"], "sample_429": ["compilation error"], "sample_1181": ["    def test_array_diagonal(self):\n        a = Array([[1, 2], [3, 4]])\n        diag = ArrayDiagonal(a, diagonal_indices=((0, 1),))\n        result = diag.evalf()\n        expected = np.array([[1, 0], [0, 4]])\n        assert np.allclose(result, expected)\n\n        diag = ArrayDiagonal(a, diagonal_indices=((1, 0),))\n        result = diag.evalf()\n        expected = np.array([[4, 0], [0, 1]])\n        assert np.allclose(result, expected)\n\n        with warns_deprecated_sympy():\n            diag = ArrayDiagonal(a, diagonal_indices=((0, 1), (1, 0)))\n            result = diag.evalf()\n            expected = np.concatenate((np.array([[1, 0], [0, 4]]),\n                                      np.array([[4, 0], [0, 1]])), axis=0)\n            assert np.allclose(result, expected)\n"], "sample_840": ["    def test_pls_regression_with_one_target(self):\n        X, y = load_linnerud(return_X_y=True)\n        X = X[:, :5]\n        y = y[:, 0]\n        pls = PLSRegression(n_components=2)\n        pls.fit(X, y)\n        y_pred = pls.predict(X)\n        assert_array_almost_equal(y_pred, pls.transform(X)[:, 0])\n        assert_array_almost_equal(pls.coef_[:, 0],\n                                  pls.x_weights_ @ pls.y_weights_[0])\n    "], "sample_41": ["compilation error"], "sample_238": ["    def test_random(self):\n        with CaptureQueriesContext() as captured:\n            Random().as_sql(connection)\n        self.assertEqual(captured.captured_queries, ['SELECT RAND()'])\n\n        with CaptureQueriesContext() as captured:\n            Random().as_sql(connection, template='RANDOM()')\n        self.assertEqual(captured.captured_queries, ['SELECT RANDOM()'])\n\n        with CaptureQueriesContext() as captured:\n            Random().as_sql(connection, function='RAND')\n        self.assertEqual(captured.captured_queries, ['SELECT RAND()'])\n\n        with CaptureQueriesContext() as captured:\n            Random().as_sql(connection, function='DBMS_RANDOM.VALUE')\n        self.assertEqual(captured.captured_queries, ['SELECT DBMS_RANDOM.VALUE FROM dual'])\n\n"], "sample_7": ["    def test_masked_column_insert(self):\n        data = np.array([1, 2, 3, 4, 5])\n        mask = np.array([False, True, False, True, False])\n        col = table.MaskedColumn(data=data, mask=mask)\n\n        # Test inserting a single value\n        new_col = col.insert(1, 10)\n        assert_array_equal(new_col.data, np.array([1, 10, 2, 3, 4, 5]))\n        assert_array_equal(new_col.mask, np.array([False, False, True, False, True, False]))\n\n        # Test inserting multiple values\n        new_col = col.insert(2, [6, 7])\n        assert_array_equal(new_col.data, np.array([1, 2, 6, 7, 3, 4, 5]))\n        assert_array_equal(new_col.mask, np.array([False, True, False, False, True, False, False]))\n\n        # Test inserting with a mask\n        new_col = col.insert(1, 10, mask=True)\n        assert_array_equal(new_col.data, np.array([1, 10, 2, 3, 4, 5]))\n        assert_array_equal(new_col.mask, np.array([False, True, False, False, True, False]))\n\n        # Test inserting with axis=1\n        new_col = col.insert(1, [10, 20], axis=1)\n        assert_array_equal(new_col.data, np.array([[1, 10, 2],\n                                                  [2, 20, 3],\n                                                  [4, 5, ]]))\n        assert_array_equal(new_col.mask, np.array([[False, False, False],\n                                                  [True, False, False],\n                                                  [False, False, True]]))\n\n\n\n"], "sample_679": ["    def test_invalidraise(self, attr, modulename):\n        mark = Mark(modulename)\n        mark.add_marker(\"raises\", \"ValueError\")\n        item = Node(\n            name=\"test\",\n            parent=Collector(None),\n            fspath=None,\n            name=\"test\",\n            obj=None,\n            keywords={},\n            callspec=None,\n            markers=[mark],\n        )\n        evaluator = MarkEvaluator(item, \"raises\")\n        with pytest.raises(ValueError):\n            evaluator.istrue()\n        assert evaluator.wasvalid() is False\n        assert evaluator.invalidraise(ValueError) is True\n        with pytest.raises(ValueError):\n            evaluator.istrue()\n        assert evaluator.wasvalid() is False\n        assert evaluator.invalidraise(TypeError) is False\n"], "sample_24": ["    def test_shape_changing_functions(self):\n        for func in [np.reshape, np.transpose]:\n            with pytest.raises(NotImplementedError):\n                func(self.ma, (10,))\n"], "sample_978": ["compilation error"], "sample_226": ["    def test_db_signature(self):\n        with override_settings(DATABASES={\n            DEFAULT_DB_ALIAS: {\n                'ENGINE': 'django.db.backends.sqlite3',\n                'NAME': ':memory:',\n            }\n        }):\n            connection.close()\n            connection.ensure_connection()\n            creation = BaseDatabaseCreation(get_connection_copy())\n            signature1 = creation.test_db_signature()\n            connection.close()\n            connection.ensure_connection()\n            signature2 = creation.test_db_signature()\n            self.assertEqual(signature1, signature2)\n"], "sample_560": ["    def test_bbox_to_anchor(self):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], [4, 5, 6])\n        legend = ax.legend(bbox_to_anchor=(0.5, 0.5))\n        plt.close(fig)\n\n\n\n"], "sample_625": ["    def test_apply_ufunc_scalar_functions(array, func, expected):\n        result = apply_ufunc(func, array, dask=\"allowed\")\n        assert_identical(result, expected)\n\n"], "sample_114": ["    def test_migration_dependencies_circular(self):\n        before_states = [\n            rabbit,\n            knight,\n        ]\n        after_states = [\n            rabbit,\n            knight,\n        ]\n        changes = self.get_changes(before_states, after_states)\n        self.assertMigrationDependencies(changes, \"eggs\", 0, [])\n        self.assertMigrationDependencies(changes, \"eggs\", 1, [])\n\n\n\n"], "sample_1046": ["    def test_riemann_cyclic_replace():\n        from sympy.tensor.tensor import TensorIndexType, tensor_indices, tensorhead\n        Lorentz = TensorIndexType('Lorentz', dummy_fmt='L')\n        i, j, k, l = tensor_indices('i,j,k,l', Lorentz)\n        R = tensorhead('R', [Lorentz]*4, [[2, 2]])\n        t = R(i,j,k,l)*(R(-i,-j,-k,-l) - 2*R(-i,-k,-j,-l))\n        t1 = riemann_cyclic_replace(t)\n        assert _is_equal(t1, 0)\n"], "sample_32": ["    def test_w(self):\n        cosmo = self._cls(**self._cls_args, **self._cls_kwargs)\n        for z in valid_zs:\n            w = cosmo.w(z)\n            assert isinstance(w, (float, np.ndarray))\n            if isinstance(z, np.ndarray):\n                assert np.all(w == cosmo._w0 + cosmo._wz * z)\n            else:\n                assert w == cosmo._w0 + cosmo._wz * z\n\n\n\n"], "sample_962": ["    def test_restify_with_mock(self):\n        with mock(['target.module.name']):\n            class MockClass:\n                    self.value = value\n\n                    return f'MockClass({self.value})'\n\n            mock_instance = MockClass(123)\n            result = restify(mock_instance)\n            assert result == 'MockClass(123)'\n"], "sample_911": ["    def test_template_params(self):\n        check(\"class\", \"template <typename T> class MyClass { };\", {\"1\": \"MyClass_1_T\"})\n        check(\"struct\", \"template <typename T> struct MyStruct { };\", {\"1\": \"MyStruct_1_T\"})\n        check(\"enum\", \"template <typename T> enum MyEnum { VALUE = T(10) };\", {\"1\": \"MyEnum_1_T\"})\n        check(\"function\", \"template <typename T> void myFunc(T t) { }\", {\"1\": \"myFunc_1_T\"})\n"], "sample_206": ["    def test_file_field_save_and_delete(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            filepath = os.path.join(tmpdir, 'test.txt')\n            with open(filepath, 'w') as f:\n                f.write('Hello, world!')\n\n            doc = Document(title='Test Document', file=File(open(filepath, 'rb')))\n            doc.save()\n\n            self.assertEqual(doc.file.name, 'test.txt')\n            self.assertEqual(doc.file.path, os.path.join(self.settings.MEDIA_ROOT, 'documents', 'test.txt'))\n\n            doc.delete()\n\n            with self.assertRaises(FileNotFoundError):\n                doc.file.open('r')\n"], "sample_205": ["    def test_validation_error_update_error_dict(self):\n        error_dict = {}\n        error1 = ValidationError(\"Error 1\")\n        error2 = ValidationError(\"Error 2\")\n        error3 = ValidationError(\"Error 3\")\n        validation_error = ValidationError({\"field1\": [error1, error2], \"field2\": error3})\n\n        updated_error_dict = validation_error.update_error_dict(error_dict)\n        self.assertEqual(updated_error_dict, {\"field1\": [error1, error2], \"field2\": error3})\n"], "sample_694": ["    def test_private_function_access(pytester: Pytester):\n        pytester.makepyfile(\n            \"\"\"\n            import _pytest.deprecated as deprecated\n\n                deprecated.check_ispytest(_ispytest)\n                return \"OK\"\n\n                my_private_function(1, 2, _ispytest=True)\n            \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"*test_something.py::test_something* OK*\",\n            ]\n        )\n"], "sample_1071": ["compilation error"], "sample_1182": ["    def test_piecewise(self):\n        expr = Piecewise((x, x < 0), (x**2, x >= 0))\n        code = pycode(expr)\n        self.assertEqual(code, '(x if x < 0 else x**2)')\n"], "sample_104": ["    def test_manifest_strict_missing_file(self):\n        with self.assertRaises(ValueError):\n            with self.settings(STATICFILES_STORAGE='django.contrib.staticfiles.storage.ManifestStaticFilesStorage'):\n                call_command('collectstatic', verbosity=0, dry_run=True)\n"], "sample_1023": ["    def test_compositepi_edge_cases():\n        assert compositepi(1) == 0\n        assert compositepi(2) == 0\n        assert compositepi(3) == 0\n        assert compositepi(4) == 1\n        assert compositepi(5) == 2\n        assert compositepi(6) == 3\n        assert compositepi(7) == 4\n        assert compositepi(8) == 5\n        assert compositepi(9) == 6\n        assert compositepi(10) == 7\n        assert compositepi(11) == 8\n        assert compositepi(12) == 9\n        assert compositepi(13) == 10\n        assert compositepi(14) == 11\n        assert compositepi(15) == 12\n        assert compositepi(16) == 13\n        assert compositepi(17) == 14\n        assert compositepi(18) == 15\n        assert compositepi(19) == 16\n        assert compositepi(20) == 17\n        assert compositepi(21) == 18\n        assert compositepi(22) == 19\n        assert compositepi(23) == 20\n        assert compositepi(24) == 21\n        assert compositepi(25) == 22\n        assert compositepi(26) == 23\n        assert compositepi(27) == 24\n        assert compositepi(28) == 25\n        assert compositepi(29) == 26\n        assert compositepi(30) == 27\n        assert compositepi(31) == 28\n        assert compositepi(32) == 29\n        assert compositepi(33) == 30\n        assert compositepi(34) == 31\n        assert compositepi(35) == 32\n        assert compositepi(36) == 33\n        assert compositepi(37) == 34\n        assert compositepi(38) == 35\n        assert compositepi(39) == 36\n        assert compositepi(40) == 3"], "sample_336": ["    def test_no_urlconf(self):\n        with self.assertRaises(ImproperlyConfigured):\n            get_urlconf('nonexistent_app')\n"], "sample_244": ["    def test_formset_factory_with_custom_kwargs(self):\n        class CustomFormSet(BaseFormSet):\n                super().__init__(*args, **kwargs)\n                self.custom_kwargs = kwargs\n\n        CustomFormSet = formset_factory(CustomKwargForm, formset=CustomFormSet, extra=1)\n        formset = CustomFormSet(custom_kwarg='test_value')\n        self.assertEqual(formset.custom_kwargs['custom_kwarg'], 'test_value')\n\n\n\n"], "sample_474": ["    def test_chr(self):\n        self.assertEqual(Chr(F('name')).resolve_expression(self.john), ord('J'))\n        self.assertEqual(Chr(F('name')).resolve_expression(self.elena), ord('\u00c9'))\n        self.assertEqual(Chr(F('name')).resolve_expression(self.rhonda), ord('R'))\n"], "sample_655": ["    def test_global_and_fixture_disabled(self, capsys):\n        with capture.CaptureManager().global_and_fixture_disabled():\n            capsys.write(\"hello\\n\")\n            capsys.write(\"world\\n\")\n        out, err = capsys.readouterr()\n        assert out == \"\"\n        assert err == \"\"\n"], "sample_833": ["    def test_logistic_regression_cv_multiclass_multinomial(self):\n        X, y = make_classification(n_samples=100, n_features=10, n_classes=3,\n                                   random_state=42)\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n                                                            random_state=42)\n        clf = LogisticRegressionCV(cv=5, multi_class='multinomial',\n                                   penalty='l2', solver='saga',\n                                   random_state=42)\n        clf.fit(X_train, y_train)\n        y_pred = clf.predict(X_test)\n        assert_array_equal(y_pred.shape, y_test.shape)\n        assert_allclose(clf.coef_.shape, (3, 10))\n        assert_allclose(clf.intercept_.shape, (3,))\n        assert_allclose(clf.C_.shape, (3,))\n        assert_allclose(clf.l1_ratio_.shape, (3,))\n        assert_allclose(clf.n_iter_.shape, (3, 5, 1))\n"], "sample_734": ["    def test_fowlkes_mallows_score_empty_arrays(self):\n        for labels_true in [np.array([]), np.array([1])]:\n            for labels_pred in [np.array([]), np.array([1])]:\n                score = fowlkes_mallows_score(labels_true, labels_pred)\n                assert_equal(score, 0.0)\n"], "sample_320": ["    def test_add_remove_constraint(self):\n        with atomic():\n            # Add a constraint\n            self.add_constraint(\n                \"app1.UnicodeModel\",\n                models.UniqueConstraint(\n                    fields=[\"name\", \"description\"], name=\"unique_name_description\"\n                ),\n            )\n            self.assertEqual(\n                len(UnicodeModel._meta.constraints), 1\n            )\n            self.assertEqual(\n                UnicodeModel._meta.constraints[0].name,\n                \"unique_name_description\",\n            )\n\n            # Remove the constraint\n            self.remove_constraint(\"app1.UnicodeModel\", \"unique_name_description\")\n            self.assertEqual(len(UnicodeModel._meta.constraints), 0)\n\n            # Try to add the constraint again\n            with self.assertRaises(IntegrityError):\n                self.add_constraint(\n                    \"app1.UnicodeModel\",\n                    models.UniqueConstraint(\n                        fields=[\"name\", \"description\"], name=\"unique_name_description\"\n                    ),\n                )\n\n\n\n"], "sample_692": ["    def test_getbasetemp_from_env(tmpdir_factory: TempPathFactory, monkeypatch: MonkeyPatch) -> None:\n        monkeypatch.setenv(\"PYTEST_DEBUG_TEMPROOT\", str(tmpdir_factory.getbasetemp()))\n        factory = TempPathFactory(given_basetemp=None, trace=None, basetemp=None, _ispytest=True)\n        assert factory.getbasetemp() == pathlib.Path(os.environ[\"PYTEST_DEBUG_TEMPROOT\"])\n"], "sample_52": ["    def test_modelchoicefield_with_limit_choices_to(self):\n        class MyForm(forms.Form):\n            category = forms.ModelChoiceField(\n                queryset=Category.objects.all(),\n                limit_choices_to=lambda instance: instance.name == 'Entertainment'\n            )\n\n        form = MyForm()\n        choices = form.fields['category'].choices\n        self.assertEqual(len(choices), 1)\n        self.assertEqual(choices[0][0], self.c1.pk)\n        self.assertEqual(choices[0][1], self.c1.name)\n\n\n\n"], "sample_772": ["    def test_oob_score_classification(name):\n        ForestClassifier = FOREST_CLASSIFIERS[name]\n\n        clf = ForestClassifier(n_estimators=10, oob_score=True, random_state=1)\n        clf.fit(X, y)\n        assert_equal(clf.oob_score_, clf.score(X, y))\n"], "sample_1204": ["    def test_coset_equality(self):\n        G = PermutationGroup([Permutation([1, 2, 0]), Permutation([0, 2, 1])])\n        H = PermutationGroup([Permutation([0, 2, 1])])\n        g = Permutation([1, 2, 0])\n        c1 = Coset(g, H, dir=\"+\")\n        c2 = Coset(g, H, dir=\"+\")\n        assert c1 == c2\n        c3 = Coset(Permutation([0, 2, 1]), H, dir=\"+\")\n        assert c1 != c3\n        c4 = Coset(g, H, dir=\"-\")\n        assert c1 != c4\n"], "sample_196": ["    def test_integer_field_range(self):\n        self.assertEqual(self.ops.integer_field_range('IntegerField'), (-2147483648, 2147483647))\n        self.assertEqual(self.ops.integer_field_range('SmallIntegerField'), (-32768, 32767))\n        self.assertEqual(self.ops.integer_field_range('BigIntegerField'), (-9223372036854775808, 9223372036854775807))\n        self.assertEqual(self.ops.integer_field_range('PositiveIntegerField'), (0, 2147483647))\n        self.assertEqual(self.ops.integer_field_range('PositiveSmallIntegerField'), (0, 32767))\n        self.assertEqual(self.ops.integer_field_range('AutoField'), (-9223372036854775808, 9223372036854775807))\n\n\n\n"], "sample_303": ["    def test_settings_to_cmd_args_env(self):\n        with mock.patch.object(BaseDatabaseClient, 'settings_to_cmd_args_env') as mock_method:\n            self.client.runshell(parameters={'param1': 'value1'})\n            mock_method.assert_called_once_with(self.client.connection.settings_dict, {'param1': 'value1'})\n"], "sample_636": ["    def test_ignore_comments(self):\n        with _patch_streams(StringIO()) as out:\n            Run([\n                \"duplicate_code\",\n                \"-i\",\n                join(DATA, \"test_comments.py\"),\n            ])\n            output = out.getvalue()\n            assert \"duplicate-code\" not in output\n"], "sample_733": ["    def test_stop_words_max_df(self):\n        # Test stop words removal based on max_df\n        vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)\n        X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n        stop_words = vectorizer.stop_words_\n\n        # Assert that stop words are removed\n        assert_equal(len(stop_words), len(ENGLISH_STOP_WORDS))\n\n        # Assert that common words are removed\n        assert_in('the', stop_words)\n        assert_in('and', stop_words)\n\n        # Assert that words with high document frequency are removed\n        assert_in('pizza', stop_words)\n        assert_in('burger', stop_words)\n        assert_in('beer', stop_words)\n        assert_in('copyright', stop_words)\n"], "sample_893": ["    def test_export_text_with_weights(tree_type, show_weights):\n        if tree_type is DecisionTreeRegressor:\n            y = np.array([1, 2, 3, 4, 5, 6])\n        else:\n            y = np.array([0, 0, 0, 1, 1, 1])\n        tree = tree_type()\n        tree.fit(X, y)\n        report = export_text(tree, show_weights=show_weights)\n        if show_weights:\n            assert \"weights\" in report\n        else:\n            assert \"weights\" not in report\n\n"], "sample_892": ["    def test_adaboost_regressor_staged_predict_proba(self):\n        regr = AdaBoostRegressor(n_estimators=3, random_state=0)\n        X, y = make_regression(n_samples=10, n_features=2, random_state=0)\n        regr.fit(X, y)\n\n        with pytest.raises(AttributeError):\n            regr.predict_proba(X)\n\n        for i, proba in enumerate(regr.staged_predict_proba(X)):\n            assert proba.shape == (X.shape[0], 1)\n            assert np.all(proba >= 0)\n            assert np.all(proba <= 1)\n            assert np.allclose(np.sum(proba, axis=1), 1.0)\n            if i == 0:\n                assert np.allclose(proba, np.ones((X.shape[0], 1)))\n            else:\n                assert not np.allclose(proba, np.ones((X.shape[0], 1)))\n\n\n\n"], "sample_1061": ["    def test_as_content_primitive_sqrt():\n        from sympy import sqrt\n        assert sqrt(4 + 4*sqrt(2)).as_content_primitive() == (2, sqrt(1 + sqrt(2)))\n        assert sqrt(3 + 3*sqrt(2)).as_content_primitive() == (1, sqrt(3)*sqrt(1 + sqrt(2)))\n        assert sqrt(4*x + 4).as_content_primitive() == (2, sqrt(x + 1))\n        assert sqrt(4*x**2 + 4*x).as_content_primitive() == (2, sqrt(x**2 + x))\n        assert sqrt(4*x**2 + 4*x + 1).as_content_primitive() == (1, sqrt(x**2 + x + 1/4))\n        assert sqrt(4*x**2 + 4*x + 1).as_content_primitive() == (1, sqrt(x**2 + x + 1/4))\n        assert sqrt(4*x**2 + 4*x + 1).as_content_primitive() == (1, sqrt(x**2 + x + 1/4))\n        assert sqrt(4*x**2 + 4*x + 1).as_content_primitive() == (1, sqrt(x**2 + x + 1/4))\n\n\n\n"], "sample_471": ["    def test_integer_field_validation(self):\n        field = IntegerField()\n        self.assertValidInput(field, \"123\")\n        self.assertValidInput(field, \"-42\")\n        self.assertValidInput(field, \"0\")\n\n        with self.assertRaises(ValidationError):\n            field.clean(\"abc\")\n        with self.assertRaises(ValidationError):\n            field.clean(\"12.3\")\n        with self.assertRaises(ValidationError):\n            field.clean(\"123a\")\n"], "sample_983": ["    def test_row_structure_symbolic_cholesky(self):\n        from sympy.matrices import SparseMatrix\n        S = SparseMatrix([\n            [1, 0, 3, 2],\n            [0, 0, 1, 0],\n            [4, 0, 0, 5],\n            [0, 6, 7, 0]])\n        R = S.row_structure_symbolic_cholesky()\n        assert R == [[0], [], [0], [1, 2]]\n\n"], "sample_767": ["    def test_remainder_estimator(self):\n        X = np.array([[1, 2], [3, 4]])\n        remainder_est = Trans()\n        ct = ColumnTransformer(\n            transformers=[\n                (\"scaler\", StandardScaler(), [0]),\n                (\"remainder\", remainder_est, [1])\n            ],\n            remainder='remainder'\n        )\n        ct.fit(X)\n        X_transformed = ct.transform(X)\n        expected_X_transformed = np.array([\n            [1.0, 2.0],\n            [3.0, 4.0]\n        ])\n        assert_allclose_dense_sparse(X_transformed, expected_X_transformed)\n"], "sample_673": ["    def test_doctest_ignore_import_errors(\n        self, testdir, monkeypatch"], "sample_971": ["    def test_is_suppressed_warning(self):\n        app = self.app\n        app.config.suppress_warnings = []\n        assert not is_suppressed_warning(None, None, app.config.suppress_warnings)\n        app.config.suppress_warnings = ['my_warning']\n        assert not is_suppressed_warning('my_warning', None, app.config.suppress_warnings)\n        assert is_suppressed_warning('my_warning', 'sub', app.config.suppress_warnings)\n        assert is_suppressed_warning('my_warning', '*', app.config.suppress_warnings)\n        assert not is_suppressed_warning('other_warning', None, app.config.suppress_warnings)\n"], "sample_1207": ["    def test_implicit_multiplication_application_complex(self):\n        expr = parse_expr('1j*2*x', transformations=(standard_transformations + (implicit_multiplication_application,)))\n        assert expr == Mul(I, 2, x)\n"], "sample_482": ["    def test_escapeseq_safe(self):\n        self.assertEqual(\n            self.render(\n                '{{ [1, 2, 3]|escapeseq }}',\n                {\"a\": [1, 2, 3], \"b\": [4, 5, 6]},\n            ),\n            mark_safe(\"1, 2, 3\"),\n        )\n"], "sample_812": ["    def test_estimator_repr_with_changed_params(self):\n        set_config(print_changed_only=True)\n        logreg = LogisticRegression(penalty='l1', C=1.0)\n        logreg.fit(np.zeros((10, 2)), np.zeros(10))\n        repr_logreg = _EstimatorPrettyPrinter().format(logreg, {}, 0, 0)\n        self.assertIn(\"LogisticRegression(penalty='l1', C=1.0)\", repr_logreg)\n        self.assertNotIn(\"penalty='l2'\", repr_logreg)\n\n        set_config(print_changed_only=False)\n\n\n\n"], "sample_1120": ["    def test_transpose_identity(self):\n        I = Identity(3)\n        self.assertEqual(I.transpose(), I)\n"], "sample_683": ["    def test_capture_manager_global_capture(self, method: str) -> None:\n        capman = CaptureManager(method)\n        assert not capman.is_globally_capturing()\n        capman.start_global_capturing()\n        assert capman.is_globally_capturing()\n        sys.stdout.write(\"hello\\n\")\n        sys.stderr.write(\"world\\n\")\n        out, err = capman.read_global_capture()\n        assert out == \"hello\\n\"\n        assert err == \"world\\n\"\n        capman.stop_global_capturing()\n        assert not capman.is_globally_capturing()\n"], "sample_580": ["    def test_variable_type_all_datetime():\n        vector = pd.Series([datetime(2023, 1, 1), datetime(2023, 2, 1)])\n        assert variable_type(vector) == VarType(\"datetime\")\n"], "sample_913": ["    def test_parse_annotation(self):\n        assert _parse_annotation('int') == 'int'\n        assert _parse_annotation('int | str') == 'int | str'\n        assert _parse_annotation('List[int]') == 'List[int]'\n        assert _parse_annotation('Optional[str]') == 'Optional[str]'\n        assert _parse_annotation('Union[int, str]') == 'Union[int, str]'\n        assert _parse_annotation('typing.List[int]') == 'typing.List[int]'\n        assert _parse_annotation('typing.Optional[str]') == 'typing.Optional[str]'\n        assert _parse_annotation('typing.Union[int, str]') == 'typing.Union[int, str]'\n\n\n\n"], "sample_136": ["    def test_parse_file_upload_multipart_error(self):\n        request_factory = RequestFactory()\n        request = WSGIRequest(request_factory.get('/'))\n        request.META = {'CONTENT_TYPE': 'multipart/form-data', 'CONTENT_LENGTH': '100'}\n        request._stream = BytesIO(b'---WebKitFormBoundary7MA4YWxkTrZu0g3w\\r\\nContent-Disposition: form-data; name=\"file\"; filename=\"test.txt\"\\r\\nContent-Type: text/plain\\r\\n\\r\\nThis is a test\\r\\n---WebKitFormBoundary7MA4YWxkTrZu0g3w--')\n        with self.assertRaises(MultiPartParserError):\n            request.parse_file_upload(request.META, request._stream)\n"], "sample_366": ["    def test_parse_datetime_with_postgres_interval(self):\n        self.assertEqual(parse_datetime(\"3 days 04:05:06\"), datetime(2023, 10, 27, 4, 5, 6, tzinfo=get_fixed_timezone(0)))\n"], "sample_1169": ["    def test_simplify_index_permutations_multiple_operators():\n        p, q, r, s = symbols('p q r s')\n        f = Function('f')\n        g = Function('g')\n        expr = f(p, r)*g(q, s) - f(q, r)*g(p, s) + f(q, s)*g(p, r) - f(p, s)*g(q, r)\n        PermutList = [PermutationOperator(p,q),PermutationOperator(r,s)]\n        result = simplify_index_permutations(expr, PermutList)\n        expected = f(p, r)*g(q, s)*PermutationOperator(p, q)*PermutationOperator(r, s)\n        assert result == expected\n"], "sample_26": ["    def test_compressed_image_read_write(self, compression):\n        if compression == \"NONE\":\n            return\n\n        # Create a test image with compression\n        data = np.random.rand(10, 10)\n        hdu = fits.ImageHDU(data, header=fits.Header({\"COMPRESSION\": compression}))\n        hdu.writeto(\"test.fits\")\n\n        # Read the compressed image and verify\n        with fits.open(\"test.fits\") as hdul:\n            hdu_read = hdul[0]\n            assert hdu_read.header[\"COMPRESSION\"] == compression\n            assert_equal(hdu_read.data, data)\n\n        os.remove(\"test.fits\")\n"], "sample_706": ["    def test_parens():\n        assert evaluate(\"((True))\", lambda x: True) is True\n        assert evaluate(\"((False))\", lambda x: True) is False\n        assert evaluate(\"(True and False)\", lambda x: True) is False\n        assert evaluate(\"(True or False)\", lambda x: True) is True\n        assert evaluate(\"not (True)\", lambda x: True) is False\n        assert evaluate(\"not (False)\", lambda x: True) is True\n"], "sample_887": ["    def test_calibration_display_from_estimator_with_pipeline(method, ensemble):\n        X, y = data()\n        if ensemble:\n            clf = Pipeline([\n                ('scaler', StandardScaler()),\n                ('clf', RandomForestClassifier(random_state=42))\n            ])\n        else:\n            clf = RandomForestClassifier(random_state=42)\n        clf.fit(X, y)\n\n        disp = CalibrationDisplay.from_estimator(\n            clf, X, y, method=method, name=\"Random Forest\", ref_line=True\n        )\n        disp.plot()\n"], "sample_716": ["    def test_ridge_cv_sparse(self):\n        X = SPARSE_FILTER(np.random.rand(100, 10))\n        y = np.random.rand(100)\n        alphas = np.array([0.1, 1.0, 10.0])\n        ridge_cv = RidgeCV(alphas=alphas, cv=5)\n        ridge_cv.fit(X, y)\n        assert_greater(ridge_cv.alpha_, 0)\n"], "sample_377": ["    def test_callable_setting_wrapper_calls_callable(self):\n            return \"This is a callable setting\"\n\n        wrapper = CallableSettingWrapper(callable_setting)\n        self.assertEqual(wrapper(), \"This is a callable setting\")\n\n\n"], "sample_698": ["    def test_colored_level_formatter(self):\n        formatter = ColoredLevelFormatter(TerminalWriter(), \"%(asctime)s %(levelname)s %(message)s\", \"%Y-%m-%d %H:%M:%S\")\n        self.assertEqual(formatter.format(\n            logging.LogRecord(\n                name=\"test\",\n                level=logging.DEBUG,\n                msg=\"test message\",\n                args=(),\n                exc_info=None,\n                timestamp=None,\n            )\n        ), \"2023-10-27 17:00:00 DEBUG test message\\n\")\n"], "sample_1158": ["    def test_sympify_numpy_array_scalar(self):\n        a = numpy.array(1)\n        self.assertEqual(sympify(a), Integer(1))\n"], "sample_633": ["    def test_ignore_signatures(self):\n        with open(SIMILAR_CLS_A, \"r\", encoding=\"utf-8\") as f:\n            source_a = f.read()\n        with open(SIMILAR_CLS_B, \"r\", encoding=\"utf-8\") as f:\n            source_b = f.read()\n        linter = PyLinter()\n        linter.parse(source_a, filename=SIMILAR_CLS_A)\n        linter.parse(source_b, filename=SIMILAR_CLS_B)\n        with redirect_stdout(StringIO()) as captured_output:\n            similar.register(linter)\n            linter.run()\n        output = captured_output.getvalue()\n        assert \"Duplicate code\" not in output\n"], "sample_550": ["    def test_get_tightbbox_for_layout_only(self, renderer):\n        fig, ax = plt.subplots(1, 1)\n        ax.set_xlim(0, 10)\n        ax.set_ylim(0, 10)\n        ax.set_title(\"Test Title\")\n        ax.set_xlabel(\"X Label\")\n        ax.set_ylabel(\"Y Label\")\n\n        bbox = ax.get_tightbbox(renderer=renderer, for_layout_only=True)\n        assert bbox is not None\n        assert bbox.width > 0\n        assert bbox.height > 0\n\n        # Check that the title and axis labels are not included in the bbox\n        assert bbox.width < ax.get_window_extent(renderer).width\n        assert bbox.height < ax.get_window_extent(renderer).height\n\n        plt.close(fig)\n\n\n\n"], "sample_1040": ["    def test_derivative_with_partial():\n        expr = diff(x**2, x, evaluate=False)\n        xml = mp._print(expr)\n        assert 'partialdiff' in str(xml)\n        xml = mpp._print(expr)\n        assert '&#x2202;' in str(xml)\n"], "sample_1025": ["    def test_sparse_matrix(self):\n        A = SparseMatrix([[1, 2], [3, 4]], shape=(2, 2))\n        s = SciPyPrinter().doprint(A)\n        assert s == \"scipy.sparse.coo_matrix([[1, 2], [3, 4]], shape=(2, 2))\"\n"], "sample_1042": ["    def test_idx_bounds():\n        from sympy.tensor import IndexedBase, Idx\n\n        n = Symbol('n', integer=True)\n        i = Idx('i', n)\n        j = Idx('j', 2)\n        k = Idx('k', (0, n - 1))\n\n        assert i.lower == 0\n        assert i.upper == n - 1\n        assert j.lower == 0\n        assert j.upper == 1\n        assert k.lower == 0\n        assert k.upper == n - 1\n\n        with raises(TypeError):\n            Idx('i', 'n')\n        with raises(TypeError):\n            Idx('i', (1, 2, 3))\n        with raises(TypeError):\n            Idx('i', [1, 2, 3])\n        with raises(TypeError):\n            Idx('i', 1.5)\n"], "sample_109": ["    def test_autocomplete_select_required_field(self):\n        form = RequiredBandForm()\n        rendered_html = form.as_p()\n        self.assertIn(self.empty_option, rendered_html)\n        self.assertIn('<input type=\"hidden\" name=\"band\" value=\"\">', rendered_html)\n"], "sample_924": ["    def test_cpp_enum_scoped("], "sample_1018": ["    def test_piecewise_with_default(self):\n        x = symbols('x')\n        expr = Piecewise((x + 1, x > 0), (x, True))\n        with self.assertRaises(ValueError):\n            fcode(expr)\n"], "sample_213": ["    def test_get_storage_class_from_callable(self):\n        storage_class = get_storage_class(callable_storage)\n        self.assertEqual(storage_class, callable_storage)\n"], "sample_956": ["    def test_fetch_inventory_group(mock_read_from_url, mock_InventoryFile):\n        app = mock.Mock(spec=intersphinx_setup)\n        env = mock.Mock(spec=app.builder.env)\n        mock_read_from_url.return_value = inventory_v2()\n        now = int(time.time())\n        cache = {}\n        with concurrent.futures.ThreadPoolExecutor() as pool:\n            futures = [pool.submit(fetch_inventory_group,\n                                    'test', 'http://example.com',\n                                    ['http://example.com/objects.inv'],\n                                    cache, app, now)\n                       for _ in range(2)]\n            updated = [f.result() for f in concurrent.futures.as_completed(futures)]\n\n        assert updated[0]\n        assert updated[1]\n\n        mock_InventoryFile.assert_called_once_with(\n            mock.ANY, 'http://example.com', posixpath.join\n        )\n        mock_read_from_url.assert_called_once_with('http://example.com/objects.inv', config=mock.ANY)\n\n\n\n"], "sample_44": ["    def test_unit_creation(self, unit, subclass):\n        u = subclass()\n        assert isinstance(u, u.FunctionUnitBase)\n        assert u.physical_unit == unit\n        assert u.function_unit == unit\n        assert u._default_function_unit == unit\n        assert u._quantity_class == subclass\n"], "sample_1105": ["compilation error"], "sample_133": ["    def test_set_language_redirects_to_same_page_if_no_next_url(self):\n        response = self.client.post(reverse('set_language'), {\n            LANGUAGE_QUERY_PARAMETER: self._get_inactive_language_code(),\n        })\n        self.assertEqual(response.status_code, 302)\n        self.assertRedirects(response, '/')\n"], "sample_116": ["    def test_make_template_fragment_key(self):\n        self.assertEqual(make_template_fragment_key('my_fragment'),\n                         'template.cache.my_fragment.f9876543210abcdef')\n        self.assertEqual(make_template_fragment_key('my_fragment', vary_on=['arg1', 'arg2']),\n                         'template.cache.my_fragment.f9876543210abcdef')\n"], "sample_594": ["    def test_short_numpy_repr(self, array, expected):\n        with set_numpy_options(precision=6, linewidth=100, threshold=200):\n            assert formatting.short_numpy_repr(array) == expected\n\n\n\n"], "sample_582": ["    def test_load_dotenv_no_file(runner):\n        os.environ[\"FLASK_SKIP_DOTENV\"] = \"true\"\n        result = runner.invoke(cli, [\"run\", \"--host\", \"127.0.0.1\", \"--port\", \"5000\"])\n        assert result.exit_code == 0\n        assert \".env\" not in current_app.config\n"], "sample_480": ["    def test_json_field_with_custom_decoder(self):\n        with self.assertNumQueries(1):\n            obj = JSONModel.objects.create(json_field={\"a\": 1, \"b\": \"2\"})\n            self.assertEqual(obj.json_field[\"a\"], 1)\n            self.assertEqual(obj.json_field[\"b\"], \"2\")\n\n        with self.assertNumQueries(1):\n            obj = JSONModel.objects.create(json_field={\"a\": 1, \"b\": 2})\n            self.assertEqual(obj.json_field[\"a\"], 1)\n            self.assertEqual(obj.json_field[\"b\"], 2)\n"], "sample_300": ["    def test_trim_joins(self):\n        q = Query(\n            model=Item,\n            alias='i',\n            where=None,\n            order_by=None,\n            values=None,\n            extra=None,\n            params=None,\n            group_by=None,\n            having=None,\n            low_mark=None,\n            high_mark=None,\n            distinct=False,\n            annotations=None,\n            select_related=None,\n            deferred_loading=None,\n            extra_select=None,\n            extra_order_by=None,\n            extra_tables=None,\n            default_cols=None,\n            select=None,\n            use_for_update=False,\n            for_update=None,\n            allow_joins=True,\n            allow_subqueries=True,\n            allow_aggregates=True,\n            allow_filters=True,\n            allow_ordering=True,\n            allow_grouping=True,\n            allow_distinct=True,\n            allow_values=True,\n            allow_subqueries=True,\n            allow_window_functions=True,\n            allow_expressions=True,\n            allow_annotations=True,\n            allow_extra=True,\n            allow_deferred_loading=True,\n            allow_extra_select=True,\n            allow_extra_order_by=True,\n            allow_extra_tables=True,\n            allow_default_cols=True,\n            allow_select=True,\n            allow_for_update=True,\n            allow_use_for_update=True,\n            allow_joins=True,\n            allow_subqueries=True,\n            allow_aggregates=True,\n            allow_filters=True,\n            allow_ordering=True,\n            allow_grouping=True,\n            allow_distinct=True,\n            allow_values=True,\n            allow_subqueries=True,\n            allow_window_functions=True,\n            allow_expressions=True,\n            allow_annotations=True,\n            allow_extra=True,\n            allow_deferred_loading=True,\n            allow_extra_select=True,\n            allow_extra_order_by=True,\n"], "sample_717": ["compilation error"], "sample_980": ["    def test_inversion_vector_roundtrip(self):\n        for size in range(1, 10):\n            perm = Permutation.random(size)\n            inv_vec = perm.inversion_vector()\n            perm2 = Permutation.from_inversion_vector(inv_vec)\n            assert perm == perm2\n"], "sample_1031": ["compilation error"], "sample_497": ["        def test_max_n_locator_basic(vmin, vmax, expected):\n            locator = mticker.MaxNLocator(nbins=5)\n            ticks = locator(np.linspace(vmin, vmax, 100))\n            if expected is not None:\n                assert_array_equal(ticks, expected)\n            else:\n                assert len(ticks) == 5\n\n\n\n"], "sample_963": ["    def test_restify_special_form(self):\n        assert restify(typing.List) == ':py:class:`typing.List`'\n        assert restify(typing.Dict) == ':py:class:`typing.Dict`'\n        assert restify(typing.Tuple) == ':py:class:`typing.Tuple`'\n        assert restify(typing.Callable) == ':py:class:`typing.Callable`'\n        assert restify(typing.Optional) == ':py:class:`typing.Optional`'\n        assert restify(typing.Union) == ':py:class:`typing.Union`'\n        assert restify(typing.Any) == ':py:obj:`typing.Any`'\n        assert restify(typing.Type) == ':py:obj:`typing.Type`'\n        assert restify(typing.Generic) == ':py:class:`typing.Generic`'\n        assert restify(typing.Literal) == ':py:class:`typing.Literal`'\n        assert restify(typing.Annotated) == ':py:class:`typing.Annotated`'\n\n\n\n"], "sample_250": ["    def test_format_rfc5322(self):\n        dt = datetime(2003, 10, 7, 11, 39)\n        formatted_dt = format(dt, 'r')\n        expected_dt = 'Thu, 07 Oct 2003 11:39:00 +0200'\n        self.assertEqual(formatted_dt, expected_dt)\n"], "sample_1016": ["    def test_piecewise_inline(self):\n        pw = Piecewise((x + 1, x > 0), (x, True))\n        code = octave_code(pw, assign_to=tau, inline=True)\n        self.assertEqual(code, 'tau = ((x > 0).* (x + 1) + (~ (x > 0)).*(x));')\n"], "sample_678": ["    def test_fnmatch_ex(self, match):\n        for pattern, path in self.parametrize:\n            assert match(pattern, path) == fnmatch.fnmatch(path, pattern)\n\n\n\n"], "sample_71": ["    def test_format_large_number_scientific_notation(self):\n        number = Decimal('1.2345678901234567890123456789012345678901234567890')\n        formatted_number = nformat(number, decimal_sep='.', decimal_pos=10, use_l10n=False)\n        self.assertEqual(formatted_number, '1.234567890e+20')\n"], "sample_182": ["    def test_union_with_distinct(self):\n        distinct_numbers = Number.objects.filter(num__gt=5).values('num').distinct()\n        union_numbers = Number.objects.filter(num__gt=5).union(distinct_numbers)\n        self.assertNumbersEqual(union_numbers, [6, 7, 8, 9])\n\n"], "sample_1130": ["    def test_partial_velocity_cyclic_dependencies(self):\n        with ignore_warnings(category=UserWarning):\n            N = ReferenceFrame('N')\n            A = ReferenceFrame('A')\n            p1 = Point('p1')\n            p2 = Point('p2')\n            p3 = Point('p3')\n            u1, u2, u3 = dynamicsymbols('u1, u2, u3')\n            p1.set_vel(N, u1 * N.x)\n            p2.set_pos(p1, 2 * N.x)\n            p3.set_pos(p2, u2 * N.y)\n            p3.set_vel(A, u3 * A.z)\n            with raises(ValueError):\n                p1.partial_velocity(N, u2)\n"], "sample_953": ["    def test_quickstart_with_custom_template(capsys):\n        qs.term_input = mock_input({'path': 'test_dir'})\n        qs.do_prompt = lambda x, y, z: y\n        qs.generate({'path': 'test_dir'}, overwrite=True, silent=True, templatedir='test_templates')\n        captured = capsys.readouterr()\n        assert 'Finished: An initial directory structure has been created.' in captured.out\n        assert path.exists(path.join('test_dir', 'conf.py'))\n        assert path.exists(path.join('test_dir', 'source', 'root_doc.rst'))\n        assert path.exists(path.join('test_dir', 'source', 'templates', 'root_doc.rst'))\n\n\n\n"], "sample_327": ["    def test_json_field_invalid_json(self):\n        field = JSONField()\n        with self.assertRaises(ValidationError):\n            field.to_python('invalid json')\n"], "sample_653": ["    def test_set_log_path(self, tmp_path):\n        plugin = LoggingPlugin(self.config)\n        fname = tmp_path / \"test.log\"\n        plugin.set_log_path(fname)\n        assert plugin.log_file_handler.baseFilename == str(fname)\n        assert os.path.exists(fname)\n\n        plugin.set_log_path(None)\n        assert plugin.log_file_handler is None\n        assert not os.path.exists(fname)\n"], "sample_751": ["    def test_weight_boosting_with_sparse_data(self):\n        X = csr_matrix([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n        y = np.array([1, 0, 1])\n        estimator = DecisionTreeClassifier(max_depth=1)\n        weights = np.array([0.5, 1.0, 0.5])\n        boosting = weight_boosting(estimator, weights)\n        boosting.fit(X, y)\n        y_pred = boosting.predict(X)\n        assert_array_equal(y_pred, y)\n"], "sample_974": ["compilation error"], "sample_586": ["    def test_concat_different_coords_compat_override():\n        ds1 = create_test_data(\n            dims=(\"x\", \"y\"),\n            data={\"a\": np.arange(12).reshape((3, 4)), \"b\": np.arange(12).reshape((3, 4))},\n            coords={\"x\": pd.Index(range(3)), \"y\": pd.Index(range(4))},\n        )\n        ds2 = deepcopy(ds1)\n        ds2.coords[\"y\"] = pd.Index(range(5))\n        ds3 = deepcopy(ds1)\n        ds3.coords[\"y\"] = pd.Index(range(6))\n\n        with raises_regex(ValueError, \"indexes to be aligned are not equal\"):\n            concat(\n                [ds1, ds2, ds3],\n                dim=\"y\",\n                coords=\"different\",\n                compat=\"override\",\n                join=\"exact\",\n            )\n"], "sample_507": ["    def test_update_categorical_data(self, data, locs):\n        unit_data = cat.UnitData()\n        unit_data.update(data[0])\n        assert unit_data._mapping == {k: v for k, v in zip(data[0], locs)}\n"], "sample_340": ["    def test_inconsistent_history(self):\n        with override_settings(DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3'}}):\n            connection = connections['default']\n            with connection.cursor() as cursor:\n                cursor.execute(\"CREATE TABLE test_app_migration (id INTEGER PRIMARY KEY)\")\n            loader = MigrationLoader(connection)\n            recorder = MigrationRecorder(connection)\n            recorder.record_migration('test_app', '0001_initial')\n            loader.check_consistent_history(connection)\n            recorder.record_migration('test_app', '0002_second')\n            with self.assertRaises(InconsistentMigrationHistory):\n                loader.check_consistent_history(connection)\n"], "sample_566": ["    def test_constrained_layout_simple(self):\n        fig = Figure(figsize=(6, 4))\n        ax1 = fig.add_subplot(2, 1, 1)\n        ax2 = fig.add_subplot(2, 1, 2)\n        fig.set_layout_engine(ConstrainedLayoutEngine())\n        ax1.set_title('Top')\n        ax2.set_title('Bottom')\n        fig.canvas.draw()\n"], "sample_919": ["    def test_cpp_domain_enum_scoped("], "sample_784": ["    def test_calibration_curve(self):\n        X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n        clf = RandomForestClassifier(random_state=42)\n        clf.fit(X, y)\n        y_prob = clf.predict_proba(X)[:, 1]\n\n        prob_true, prob_pred = calibration_curve(y, y_prob, n_bins=10)\n        assert_array_almost_equal(prob_true, prob_pred)\n\n        # Test normalization\n        prob_true, prob_pred = calibration_curve(y, y_prob, normalize=True, n_bins=10)\n        assert_array_almost_equal(prob_true, prob_pred)\n\n        # Test quantile strategy\n        prob_true, prob_pred = calibration_curve(y, y_prob, strategy='quantile', n_bins=10)\n        assert_array_almost_equal(prob_true, prob_pred)\n\n\n\n"], "sample_858": ["    def test_voting_classifier_predict_proba_with_weights(self, voting):\n        estimators = [\n            ('lr', LogisticRegression(multi_class='multinomial', random_state=1)),\n            ('rf', RandomForestClassifier(n_estimators=50, random_state=1)),\n            ('gnb', GaussianNB())\n        ]\n        clf = VotingClassifier(estimators=estimators, voting=voting,\n                               weights=[2, 1, 1])\n        X, y = make_multilabel_classification(n_samples=100, n_features=10,\n                                              n_classes=3, random_state=42)\n        clf.fit(X, y)\n        y_pred_proba = clf.predict_proba(X)\n        assert y_pred_proba.shape[1] == 3\n        if voting == 'soft':\n            assert np.allclose(np.sum(y_pred_proba, axis=1), 1.0)\n"], "sample_1173": ["    def test_implicit_multiplication_application_complex(self):\n        expr = parse_expr(\"1*2*x*y\", transformations=(implicit_multiplication_application,))\n        self.assertEqual(expr, Mul(1, 2, x, y))\n"], "sample_290": ["    def test_migration_dependencies_with_circular_fk(self):\n        before_states = [\n            rabbit,\n            knight,\n        ]\n        after_states = [\n            rabbit,\n            knight,\n        ]\n        changes = self.get_changes(before_states, after_states)\n        self.assertMigrationDependencies(changes, \"eggs\", 0, [])\n        self.assertMigrationDependencies(changes, \"eggs\", 1, [])\n"], "sample_1161": ["    def test_print_MatrixSymbol(self):\n        self.assertEqual(sstr(MatrixSymbol('A', 2, 3)), 'MatrixSymbol(\"A\", 2, 3)')\n        self.assertEqual(sstr(MatrixSymbol('B', 1, 1)), 'MatrixSymbol(\"B\", 1, 1)')\n"], "sample_69": ["    def test_iter_all_python_module_files_with_zip(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            zip_filename = Path(tmpdir) / 'test.zip'\n            with zipfile.ZipFile(zip_filename, 'w') as zf:\n                zf.write('test_module.py', 'test_module.py')\n            extend_sys_path([tmpdir])\n            self.import_and_cleanup('test_module')\n            self.assertFileFound(zip_filename / 'test_module.py')\n            self.assertFileFound(Path(tmpdir) / 'test_module.py')\n            self.assertFileFound(zip_filename)\n"], "sample_450": ["    def test_get_admin_log_with_user(self):\n        response = self.client.get(reverse(\"admin:index\"))\n        response.render()\n        context = response.context\n        \n        # Assert that the log entries exist in the context\n        self.assertIn(\"log_entries\", context)\n        \n        # Call the template tag with user argument\n        with self.subTest(\"Test with user argument\"):\n            result = get_admin_log(\n                limit=1,\n                varname=\"admin_log\",\n                for_user=self.user.pk,\n            )\n            self.assertEqual(result, \"<GetAdminLog Node>\")\n            \n        # Assert that the log entries are filtered by user\n        self.assertEqual(len(context[\"admin_log\"]), 1)\n        self.assertEqual(context[\"admin_log\"][0].user_id, self.user.pk)\n"], "sample_1096": ["    def test_idx_bounds_error(self):\n        with raises(TypeError):\n            Idx('i', (1, 'a'))\n        with raises(TypeError):\n            Idx('i', (1, S.Infinity + 1))\n        with raises(TypeError):\n            Idx('i', (1, oo + 1))\n        with raises(TypeError):\n            Idx('i', (1, -oo - 1))\n"], "sample_535": ["    def test_auto_set_font_size(self):\n        fig, ax = plt.subplots()\n        table = Table(ax, cellText=[['A', 'B', 'C'], ['D', 'E', 'F']],\n                      auto_set_font_size=True)\n        table.set_fontsize(10)\n        ax.set_xlim(0, 1)\n        ax.set_ylim(0, 1)\n        table.draw()\n        fig.canvas.draw()\n        plt.close(fig)\n\n\n\n"], "sample_252": ["    def test_key_transform_lookup_with_nested_keys(self):\n        with self.assertNumQueries(1):\n            results = JSONModel.objects.filter(\n                data__key1__key2__key3='value'\n            ).values('id')\n        self.assertEqual(len(results), 1)\n\n        with self.assertNumQueries(1):\n            results = JSONModel.objects.filter(\n                data__key1__key2__key3__gt=10\n            ).values('id')\n        self.assertEqual(len(results), 1)\n\n        with self.assertNumQueries(1):\n            results = JSONModel.objects.filter(\n                data__key1__key2__key3__lt=5\n            ).values('id')\n        self.assertEqual(len(results), 1)\n\n        with self.assertNumQueries(1):\n            results = JSONModel.objects.filter(\n                data__key1__key2__key3__isnull=True\n            ).values('id')\n        self.assertEqual(len(results), 1)\n\n        with self.assertNumQueries(1):\n            results = JSONModel.objects.filter(\n                data__key1__key2__key3__in=['value1', 'value2']\n            ).values('id')\n        self.assertEqual(len(results), 1)\n\n        with self.assertNumQueries(1):\n            results = JSONModel.objects.filter(\n                data__key1__key2__key3__startswith='value'\n            ).values('id')\n        self.assertEqual(len(results), 1)\n\n        with self.assertNumQueries(1):\n            results = JSONModel.objects.filter(\n                data__key1__key2__key3__endswith='value'\n            ).values('id')\n        self.assertEqual(len(results), 1)\n\n        with self.assertNumQueries(1):\n            results = JSONModel.objects.filter(\n                data__key1__key2__key3__regex='^value'\n            ).values('id')\n        self.assertEqual(len(results), 1)\n\n\n\n"], "sample_818": ["    def test_spectral_clustering_affinity_matrix(eigen_solver, assign_labels):\n        n_samples = 30\n        n_clusters = 4\n        X, _ = make_blobs(n_samples=n_samples, centers=n_clusters,\n                          cluster_std=0.6, random_state=42)\n        affinity = img_to_graph(X, n_neighbors=5, mode='nearest')\n        sc = SpectralClustering(n_clusters=n_clusters,\n                                eigen_solver=eigen_solver,\n                                assign_labels=assign_labels)\n        sc.fit(X)\n        labels = sc.labels_\n        \n        # Check that the labels are consistent with the ground truth\n        assert adjusted_rand_score(labels, np.array(_)) > 0.7\n"], "sample_30": ["    def test_parse_single_table_with_invalid_schema(self):\n        with pytest.raises(VOTableSpecError) as excinfo:\n            parse_single_table(get_pkg_data_filename(\"votable/invalid_schema.xml\"))\n        assert \"Schema validation failed\" in str(excinfo.value)\n"], "sample_847": ["    def test_multi_task_lasso_cv_with_sparse_data(self):\n        n_samples = 100\n        n_features = 50\n        n_tasks = 3\n        X = sparse.rand(n_samples, n_features, density=0.1)\n        y = np.random.rand(n_samples, n_tasks)\n\n        clf = MultiTaskLassoCV(cv=5, random_state=42)\n        clf.fit(X, y)\n        assert_array_almost_equal(clf.coef_, clf.coef_)\n        assert_array_almost_equal(clf.intercept_, clf.intercept_)\n        assert_array_equal(clf.alphas_, clf.alphas_)\n        assert_array_equal(clf.mse_path_.shape, (clf.n_alphas, 5))\n\n\n\n"], "sample_36": ["compilation error"], "sample_720": ["    def test_power_transform_ordinal(self):\n        X = np.array([\n            [1, 2, 3],\n            [4, 5, 6],\n            [7, 8, 9]\n        ])\n        pt = PowerTransformer(method='ordinal')\n        X_trans = pt.fit_transform(X)\n        assert_array_equal(X_trans, np.array([\n            [0, 1, 2],\n            [3, 4, 5],\n            [6, 7, 8]\n        ]))\n\n        X_back = pt.inverse_transform(X_trans)\n        assert_array_equal(X_back, X)\n"], "sample_1175": ["compilation error"], "sample_335": ["    def test_decimal_field_with_localize(self):\n        with override_settings(USE_L10N=True):\n            field = DecimalField(localize=True)\n            self.assertEqual(field.widget.attrs.get('class'), 'form-control')\n            self.assertEqual(field.widget.attrs.get('type'), 'number')\n            self.assertEqual(field.localize, True)\n\n            # Test with a localized value\n            value = '123,456.78'\n            cleaned_value = field.clean(value)\n            self.assertEqual(cleaned_value, decimal.Decimal('123456.78'))\n\n            # Test with an unlocalized value\n            value = '123456.78'\n            cleaned_value = field.clean(value)\n            self.assertEqual(cleaned_value, decimal.Decimal('123456.78'))\n"], "sample_1180": ["    def test_point_3d_intersection(self):\n        p1 = Point3D(1, 2, 3)\n        p2 = Point3D(4, 5, 6)\n        self.assertEqual(p1.intersection(p2), [])\n        p3 = Point3D(1, 2, 3)\n        self.assertEqual(p3.intersection(p3), [Point3D(1, 2, 3)])\n        l = Line3D(p1, p2)\n        self.assertEqual(p1.intersection(l), [Point3D(1, 2, 3)])\n        self.assertEqual(p2.intersection(l), [Point3D(4, 5, 6)])\n        p4 = Point3D(1, 2, 3)\n        p5 = Point3D(1, 2, 4)\n        self.assertEqual(p4.intersection(p5), [Point3D(1, 2, 3)])\n        plane = Plane(Point3D(0, 0, 0), Point3D(1, 0, 0), Point3D(0, 1, 0))\n        self.assertEqual(p1.intersection(plane), [Point3D(1, 2, 3)])\n\n\n\n"], "sample_885": ["    def test_interval_constraints(self, interval_type):\n        if interval_type is Integral:\n            interval = Interval(interval_type, 1, 5, closed=\"both\")\n        else:\n            interval = Interval(interval_type, 1.0, 5.0, closed=\"both\")\n\n        valid_values = [2, 3, 4, 5]\n        invalid_values = [0, 6, 1.5, -1]\n\n        for value in valid_values:\n            assert interval.is_satisfied_by(value)\n\n        for value in invalid_values:\n            with pytest.raises(InvalidParameterError):\n                interval.is_satisfied_by(value)\n\n        # Test the generation of invalid values\n        invalid_value = generate_invalid_param_val(interval)\n        assert not interval.is_satisfied_by(invalid_value)\n\n        # Test the generation of valid values\n        valid_value = generate_valid_param(interval)\n        assert interval.is_satisfied_by(valid_value)\n"], "sample_170": ["    def test_callable_setting_wrapper_calls_callable(self):\n            return 'callable_setting_value'\n\n        wrapped_callable = CallableSettingWrapper(callable_setting)\n        self.assertEqual(wrapped_callable(), 'callable_setting_value')\n"], "sample_23": ["    def test_wrap_at_inplace(self):\n        a = Angle([10, 20, 30] * u.deg)\n        a_copy = a.copy()\n        a.wrap_at(180 * u.deg, inplace=True)\n        assert_allclose(a.degree, np.array([-10, 20, 30]))\n        assert_allclose(a_copy.degree, np.array([10, 20, 30]))\n"], "sample_209": ["    def test_check_constraints_with_conditions(self):\n        with isolate_apps(apps):\n            class MyModel(models.Model):\n                name = models.CharField(max_length=100)\n                age = models.IntegerField()\n\n                class Meta:\n                    constraints = [\n                        models.CheckConstraint(\n                            check=models.Q(age__gt=18),\n                            name='age_must_be_greater_than_18',\n                        ),\n                    ]\n\n            MyModel.objects.create(name='Alice', age=15)\n            with self.assertRaises(ValidationError):\n                MyModel.objects.create(name='Bob', age=15)\n\n            MyModel.objects.create(name='Charlie', age=20)\n\n\n\n"], "sample_1149": ["    def test_singleton_registry_registration(self):\n        class MySingleton(Basic, metaclass=Singleton):\n            pass\n        self.assertTrue(MySingleton in S._classes_to_install)\n        S.register(MySingleton)\n        self.assertFalse(MySingleton in S._classes_to_install)\n        self.assertTrue(hasattr(S, 'MySingleton'))\n        self.assertIsInstance(S.MySingleton, MySingleton)\n"], "sample_216": ["    def test_migration_dependencies_circular(self):\n        before_states = [\n            rabbit,\n            knight,\n        ]\n        after_states = [\n            rabbit,\n            knight,\n        ]\n        changes = self.get_changes(before_states, after_states)\n        self.assertMigrationDependencies(changes, 'eggs', 0, [])\n        self.assertMigrationDependencies(changes, 'eggs', 1, [])\n\n\n\n"], "sample_1063": ["    def test_lambdify_with_numpy_array():\n        from sympy.matrices import Matrix\n\n        f = lambdify((x, y), x + y, 'numpy')\n        a = numpy.array([1, 2])\n        b = numpy.array([3, 4])\n        assert numpy.array_equal(f(a, b), numpy.array([4, 6]))\n"], "sample_637": ["    def test_disable_pragma(self) -> None:\n        source = \"\"\"\n        # pylint: disable=fixme\n        FIXME: This is a fixme\n        \"\"\"\n        self.assertNoMessages(source)\n"], "sample_688": ["    def test_bestrelpath_absolute_to_relative(self, testdir):\n        p = testdir.mkdir(\"a\") / \"b\" / \"c\"\n        testdir.makepyfile(\n            textwrap.dedent(\n                \"\"\"\n                    pass\n                \"\"\"\n            )\n        )\n        result = bestrelpath(p, testdir.tmpdir / \"d\" / \"e\" / \"c\")\n        assert result == \"a/b/..\" + os.path.sep + \"..\" + os.path.sep + \"e\" + os.path.sep + \"c\"\n"], "sample_499": ["    def test_bbox_to_anchor(self):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], [4, 5, 6])\n        ax.legend(bbox_to_anchor=(0.5, 1.05), loc='upper center')\n        plt.show()\n"], "sample_1092": ["    def test_cse_matrices():\n        m1 = MutableDenseMatrix([[x, y], [z, w]])\n        m2 = MutableDenseMatrix([[x, y], [z, w]])\n        m3 = MutableDenseMatrix([[x + y, z], [w, x]])\n        m4 = MutableDenseMatrix([[x + y, z], [w, x]])\n\n        # Test basic matrix CSE\n        result, _ = cse([m1, m2, m3, m4])\n        assert len(result) == 1\n        assert result[0][0] == x0\n        assert result[0][1] == m1\n\n        # Test matrix with different types of operations\n        m5 = MutableDenseMatrix([[x + y, z], [w, x + y]])\n        m6 = MutableDenseMatrix([[x + y, z], [w, x + y]])\n        result, _ = cse([m1, m2, m5, m6])\n        assert len(result) == 1\n        assert result[0][0] == x1\n        assert result[0][1] == m5\n\n        # Test sparse matrix CSE\n        m7 = MutableSparseMatrix({(0, 0): x, (0, 1): y, (1, 0): z, (1, 1): w})\n        m8 = MutableSparseMatrix({(0, 0): x, (0, 1): y, (1, 0): z, (1, 1): w})\n        result, _ = cse([m7, m8, m3, m4])\n        assert len(result) == 1\n        assert result[0][0] == x2\n        assert result[0][1] == m7\n\n        # Test CSE with immutable matrices\n        m9 = ImmutableDenseMatrix([[x, y], [z, w]])\n        m10 = ImmutableDenseMatrix([[x, y], [z, w]])\n        result, _ = cse([m9, m10, m3, m4])\n        assert len(result) == 1\n        assert result[0][0] == x3\n        assert result[0][1] == m9\n\n        # Test CSE with mixed types of matrices\n        result"], "sample_793": ["    def test_contamination_auto(self):\n        # Test behaviour with contamination='auto'\n        # and behaviour='new'\n        X_train, X_test, y_train, y_test = train_test_split(\n            iris.data, iris.target, test_size=0.2, random_state=42\n        )\n        clf = IsolationForest(contamination='auto', behaviour='new')\n        clf.fit(X_train)\n        y_pred = clf.predict(X_test)\n        assert_allclose(clf.decision_function(X_test),\n                        clf.score_samples(X_test),\n                        rtol=1e-5)\n        assert_equal(np.sum(y_pred == 1), len(y_test) - np.sum(y_test == 0))\n\n        # Test behaviour with contamination='auto'\n        # and behaviour='old'\n        clf = IsolationForest(contamination='auto', behaviour='old')\n        clf.fit(X_train)\n        y_pred = clf.predict(X_test)\n        assert_allclose(clf.decision_function(X_test),\n                        clf.score_samples(X_test),\n                        rtol=1e-5)\n        assert_equal(np.sum(y_pred == 1), len(y_test) - np.sum(y_test == 0))\n\n\n\n"], "sample_729": ["    def test_multi_task_elastic_net_cv_l1_ratio_path(self):\n        X, y = load_boston(return_X_y=True)\n        X = check_array(X, dtype=np.float64, order='F')\n        y = check_array(y, dtype=np.float64)\n        n_tasks = y.shape[1]\n        n_alphas = 100\n        alphas = np.logspace(-4, 0, n_alphas)\n        l1_ratios = np.linspace(0, 1, 10)\n\n        clf = MultiTaskElasticNetCV(\n            l1_ratio=l1_ratios, eps=1e-3, n_alphas=n_alphas,\n            cv=5, random_state=42)\n        clf.fit(X, y)\n\n        # Check that the path is correctly computed\n        for l1_ratio in l1_ratios:\n            for i in range(n_alphas):\n                with ignore_warnings(category=ConvergenceWarning):\n                    alpha = alphas[i]\n                    coefs = clf.coef_\n                    mse = clf.mse_path_\n                    assert_array_almost_equal(\n                        coefs, clf.coef_[l1_ratio, i],\n                        decimal=4)\n                    assert_array_almost_equal(\n                        mse[i, :], clf.mse_path_[l1_ratio, i, :],\n                        decimal=4)\n"], "sample_47": ["    def test_callable_setting_wrapper(self):\n            return 'This is a callable setting'\n\n        wrapped_setting = CallableSettingWrapper(callable_setting)\n        self.assertEqual(wrapped_setting(), 'This is a callable setting')\n        self.assertEqual(repr(wrapped_setting), '<function callable_setting at 0x...>')\n\n\n\n"], "sample_777": ["compilation error"], "sample_436": ["    def test_runserver_with_ipv6(self):\n        self.write_settings(\"settings.py\", use_ipv6=True)\n        with captured_stdout() as stdout:\n            execute_from_command_line([\"django-admin\", \"runserver\", \"0.0.0.0:8000\"])\n        self.assertIn(\"Starting development server at http://[::1]:8000/\", stdout.getvalue())\n"], "sample_19": ["    def test_maps(self):\n        with ctx_for_v71_dateref_warnings():\n            for filename in self._file_list:\n                with pytest.raises(ValueError) as excinfo:\n                    wcs.WCS(get_pkg_data_contents(filename))\n                assert \"Invalid WCS header\" in str(excinfo.value)\n\n"], "sample_332": ["    def test_formset_factory_with_custom_kwargs(self):\n        class CustomForm(Form):\n            custom_field = CharField()\n\n        CustomFormSet = formset_factory(CustomForm, custom_kwarg='test_value')\n\n        formset = CustomFormSet()\n        self.assertEqual(formset.forms[0].custom_kwarg, 'test_value')\n\n\n\n"], "sample_380": ["    def test_aggregate_with_filter(self):\n        with self.subTest('Count'):\n            count = Count('Book', filter=Q(rating__gt=4))\n            self.assertEqual(count.resolve_expression().output_field, IntegerField())\n            self.assertEqual(count.as_sql(connection.cursor()), 'COUNT(DISTINCT \"django_book\".\"id\") FILTER (WHERE \"django_book\".\"rating\" > 4)')\n        with self.subTest('Avg'):\n            avg_rating = Avg('Book__rating', filter=Q(rating__gt=4))\n            self.assertEqual(avg_rating.resolve_expression().output_field, FloatField())\n            self.assertEqual(avg_rating.as_sql(connection.cursor()), 'AVG(\"django_book\".\"rating\") FILTER (WHERE \"django_book\".\"rating\" > 4)')\n        with self.subTest('Max'):\n            max_price = Max('Book__price', filter=Q(rating__gt=4))\n            self.assertEqual(max_price.resolve_expression().output_field, DecimalField())\n            self.assertEqual(max_price.as_sql(connection.cursor()), 'MAX(\"django_book\".\"price\") FILTER (WHERE \"django_book\".\"rating\" > 4)')\n\n\n\n"], "sample_1075": ["    def test_beta_derivative_with_symbols():\n        x, y = Symbol('x'), Symbol('y')\n        assert diff(beta(x, y), x) == beta(x, y) * (digamma(x) - digamma(x + y))\n        assert diff(beta(x, y), y) == beta(x, y) * (digamma(y) - digamma(x + y))\n"], "sample_583": ["    def test_masked_result_drop_slice(self):\n        for i in range(3):\n            for j in range(3):\n                for k in range(3):\n                    indexer = B(slice(None), slice(None), slice(None))\n                    indexer = indexer.replace(i, j, k)\n                    chunks_hint = (10, 10, 10) if i == 1 else None\n                    mask = create_mask(indexer, (10, 10, 10), chunks_hint)\n                    assert mask.shape == (10, 10, 10)\n                    assert np.all(mask) if chunks_hint is None else np.all(mask)\n                    indexer = posify_mask_indexer(indexer)\n                    assert np.all(indexer.tuple == (i, j, k))\n\n                    # Test that masked values are dropped\n                    result = self.set_to_zero(np.arange(1000).reshape((10, 10, 10)),\n                                             indexer.tuple)\n                    assert np.all(result == 0)\n\n\n\n"], "sample_1171": ["    def test_complex_region_from_real(self):\n        from sympy import Interval, ComplexRegion\n        unit = Interval(0,1)\n        region = ComplexRegion.from_real(unit)\n        self.assertEqual(region, CartesianComplexRegion(ProductSet(unit, FiniteSet(0))))\n"], "sample_448": ["    def test_unique_constraint_with_expressions(self):\n        with atomic():\n            Product.objects.create(name=\"Product A\", description=\"Description A\")\n            with self.assertRaises(IntegrityError):\n                Product.objects.create(name=F(\"name\"), description=\"Description B\")\n"], "sample_456": ["    def test_formset_factory_with_renderer(self):\n        with mock.patch(\"django.forms.renderers.get_default_renderer\") as mock_renderer:\n            mock_renderer.return_value = TemplatesSetting(\n                template_name=\"my_template.html\"\n            )\n            formset = formset_factory(\n                Choice, renderer=mock_renderer.return_value\n            )\n            self.assertEqual(formset.template_name, \"my_template.html\")\n\n\n\n"], "sample_3": ["    def test_ecsv_with_masked_values(self):\n        data = np.array([1, 2, None], dtype=float)\n        masked_data = np.ma.masked_array(data, mask=[False, False, True])\n        table = Table([masked_data], names=['a'])\n        table.meta['__serialized_columns__'] = {'a': {'__class__': 'astropy.table.column.MaskedColumn'}}\n        ecsv_str = ascii.to_string(table, format='ascii.ecsv', delimiter=' ')\n        read_table = ascii.read(ecsv_str, format='ascii.ecsv')\n        assert read_table['a'].mask[2] is True\n        assert np.all(read_table['a'].data == data)\n\n\n\n"], "sample_888": ["    def test_contamination_offset(self, contamination, expected_offset):\n        # Test that the offset is correctly set based on contamination\n        X, y = make_classification(n_samples=100, random_state=42)\n        clf = IsolationForest(contamination=contamination)\n        clf.fit(X)\n        assert_allclose(clf.offset_, expected_offset)\n"], "sample_419": ["    def test_formset_factory_with_renderer(self):\n        renderer = TemplatesSetting(\n            \"django/forms/formsets/div.html\"\n        )\n        CustomFormSet = formset_factory(\n            CustomKwargForm, renderer=renderer\n        )\n        formset = CustomFormSet(\n            {\"custom_kwarg\": \"test_value\"}, prefix=\"custom\"\n        )\n        self.assertEqual(formset.renderer, renderer)\n        self.assertEqual(formset.template_name, \"django/forms/formsets/div.html\")\n"], "sample_591": ["    def test_merge_with_different_indexes(self):\n        ds1 = create_test_data(\n            dims=(\"x\", \"y\"),\n            coords={\"x\": [1, 2, 3], \"y\": [4, 5]},\n            data={\"a\": [[1, 2], [3, 4], [5, 6]]},\n        )\n        ds2 = create_test_data(\n            dims=(\"x\", \"y\"),\n            coords={\"x\": [1, 2, 3], \"y\": [4, 6]},\n            data={\"b\": [[7, 8], [9, 10], [11, 12]]},\n        )\n        merged = merge(ds1, ds2, compat=\"override\")\n        assert merged.indexes[\"y\"].values == [4, 5, 6]\n        assert merged.data[\"a\"].values == [[1, 2], [3, 4], [5, 6]]\n        assert merged.data[\"b\"].values == [[7, 8], [9, 10], [11, 12]]\n\n\n\n"], "sample_59": ["    def test_transaction_rollback_with_related_objects(self):\n        with self.assertRaises(ValidationError):\n            with transaction.atomic():\n                article = Article.objects.create(title='Article 1', content='Content 1')\n                department = Department.objects.create(name='Department 1')\n                article.department = department\n                article.save()\n                raise ValueError(\"Something went wrong!\")\n        # Check that the related object was not saved\n        self.assertEqual(Department.objects.count(), 0)\n"], "sample_460": ["    def test_admin_change_view_with_inline_formset(self):\n        response = self.client.get(reverse(\"admin:%s_change\" % Article._meta.app_label, args=(self.s1.pk,)))\n        self.assertContains(response, \"Article 1\")\n        self.assertContains(response, \"Oldest content\")\n        self.assertContains(response, \"Newest content\")\n        self.assertContains(response, \"Add Article\")\n\n        # Submit the form with inline formset data\n        response = self.client.post(\n            reverse(\"admin:%s_change\" % Article._meta.app_label, args=(self.s1.pk,)),\n            self.inline_post_data,\n            follow=True,\n        )\n        self.assertRedirects(response, reverse(\"admin:%s_changelist\" % Article._meta.app_label))\n\n        # Check that the data was saved correctly\n        self.assertEqual(Article.objects.count(), 3)\n        self.assertEqual(Article.objects.get(pk=self.a1.pk).title, \"Norske bostaver \u00e6\u00f8\u00e5 skaper problemer\")\n        self.assertEqual(Article.objects.get(pk=self.a2.pk).title, \"Need a title.\")\n        self.assertEqual(Article.objects.get(pk=self.a3.pk).title, \"Need a title.\")\n\n\n\n"], "sample_830": ["        def test_get_sys_info(self):\n            sys_info = _get_sys_info()\n            self.assertIn(\"python\", sys_info)\n            self.assertIn(\"executable\", sys_info)\n            self.assertIn(\"machine\", sys_info)\n"], "sample_1041": ["    def test_from_index_summation_trace(self):\n        from sympy import trace\n        expr = Sum(A[i, i], (i, 0, n-1))\n        result = MatrixExpr.from_index_summation(expr)\n        self.assertEqual(result, trace(A))\n\n\n\n"], "sample_447": ["    def test_window_functions_with_aggregate_expression(self):\n        # Test window functions with aggregate expressions in the frame clause.\n        # This is a complex scenario that requires careful handling of the\n        # order of operations.\n        result = Book.objects.annotate(\n            avg_price=Avg(\"price\"),\n            rank=Rank()\n        ).filter(\n            price__gt=25\n        ).values(\n            \"name\",\n            \"avg_price\",\n            \"rank\",\n        ).order_by(\"rank\")\n\n        self.assertEqual(result, [\n            {\"name\": \"The Definitive Guide to Django: Web Development Done Right\", \"avg_price\": Decimal(\"30.00\"), \"rank\": 1},\n            {\"name\": \"Artificial Intelligence: A Modern Approach\", \"avg_price\": Decimal(\"75.00\"), \"rank\": 2},\n            {\"name\": \"Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp\", \"avg_price\": Decimal(\"75.00\"), \"rank\": 3},\n        ])\n\n\n\n"], "sample_418": ["    def test_length_is_with_different_length(self):\n        self.assertTemplateUsed(\"length_is02\", \"length_is02\")\n        self.assertContains(self.response, \"Five\", count=1)\n"], "sample_525": ["    def test_constrained_layout_with_subplotspec(self):\n        fig = Figure()\n        gs = gridspec.GridSpec(2, 2)\n        ax1 = fig.add_subplot(gs[0, 0])\n        ax2 = fig.add_subplot(gs[0, 1])\n        ax3 = fig.add_subplot(gs[1, 0])\n        ax4 = fig.add_subplot(gs[1, 1])\n\n        fig.set_layout_engine(ConstrainedLayoutEngine())\n        fig.set_constrained_layout_pads(wspace=0.1, hspace=0.1)\n        fig.tight_layout()\n\n        # Check that the axes are correctly positioned\n        assert ax1.get_position().x0 > 0\n        assert ax1.get_position().y0 > 0\n        assert ax2.get_position().x1 < 1\n        assert ax2.get_position().y1 < 1\n        assert ax3.get_position().x0 > 0\n        assert ax3.get_position().y0 > 0\n        assert ax4.get_position().x1 < 1\n        assert ax4.get_position().y1 < 1\n\n\n\n"], "sample_650": ["    def test_log_file_handler_path(self, testdir: Pytester) -> None:\n        testdir.makepyfile(\n            \"\"\"\n            import logging\n\n                logging.info(\"This is a test\")\n            \"\"\"\n        )\n\n        config = testdir.parse(\n            \"-v --log-file=test.log --log-file-level=DEBUG\"\n        )\n        config.pluginmanager.get_plugin(\"logging-plugin\").set_log_path(\"my_test.log\")\n        config.run()\n        assert os.path.exists(\"my_test.log\")\n        with open(\"my_test.log\", \"r\") as f:\n            assert f.read().strip() == \"DEBUG: This is a test\\n\"\n        os.remove(\"my_test.log\")\n"], "sample_1107": ["    def test_kbin_ordered():\n        for k in range(1, 6):\n            for ordered in [None, 0, 1, 10, 11]:\n                for l in range(k * 2):\n                    for p in kbins(list(range(l)), k, ordered=ordered):\n                        if ordered is not None:\n                            assert len(p) == k\n                        else:\n                            assert all(len(pi) > 0 for pi in p)\n                        assert sum(sum(pi) for pi in p) == l\n\n\n\n"], "sample_603": ["    def test_array_repr_with_attrs(dataarray):\n        html = fh.array_repr(dataarray)\n        assert \"<pre class='xr-text-repr-fallback'>xarray.DataArray(...)</pre>\" in html\n        assert f\"<div class='xr-array-name'>{dataarray.name}</div>\" in html\n        assert f\"<div class='xr-obj-type'>xarray.DataArray</div>\" in html\n        assert \"<ul class='xr-sections'>\" in html\n        assert \"</ul>\" in html\n        assert \"</div>\" in html\n"], "sample_939": ["compilation error"], "sample_29": ["    def test_latex_names(self, cosmo):\n        with pytest.raises(ValueError) as exc:\n            write_latex(cosmo, \"test.tex\", latex_names=False, format=\"latex\")\n        assert \"format must be 'latex'\" in str(exc.value)\n\n\n\n"], "sample_227": ["    def test_list_filter_with_related_object_model(self):\n        self.assertEqual(\n            BookmarkAdminGenericRelation.list_filter,\n            [('tags__tag', 'django.contrib.admin.filters.RelatedOnlyFieldListFilter')]\n        )\n\n"], "sample_996": ["    def test_reverse_order_product():\n        from sympy.abc import x, y, a, b, c, d\n        P = Product(x, (x, a, b))\n        Pr = P.reverse_order(x)\n        assert Pr == Product(1/x, (x, b + 1, a - 1))\n        Pr = Pr.doit()\n        assert Pr == 1/rf(b + 1, a - b - 1)\n        P = P.doit()\n        assert P == rf(a, -a + b + 1)\n        assert simplify(P) == simplify(Pr)\n\n        S = Sum(x*y, (x, a, b), (y, c, d))\n        S0 = S.reverse_order(0)\n        assert S0 == Sum(-x*y, (x, b + 1, a - 1), (y, c, d))\n        S1 = S0.reverse_order(1)\n        assert S1 == Sum(x*y, (x, b + 1, a - 1), (y, d + 1, c - 1))\n\n        S2 = Sum(x*y, (x, a, b), (y, 2, 5)).reverse_order(x, 1)\n        assert S2 == Sum(x*y, (x, b + 1, a - 1), (y, 6, 1))\n        S3 = Sum(x*y, (x, a, b), (y, 2, 5)).reverse_order(y, x)\n        assert S3 == Sum(x*y, (x, b + 1, a - 1), (y, 6, 1))\n"], "sample_304": ["compilation error"], "sample_67": ["    def test_custom_error_message(self):\n        form = CustomErrorMessageForm(data={'name1': 'invalid'})\n        self.assertEqual(form.errors['name1'], ['Form custom error message.'])\n\n\n"], "sample_510": ["compilation error"], "sample_917": ["compilation error"], "sample_307": ["    def test_format_datetime_with_timezone(self):\n        dt = datetime(2023, 10, 26, 10, 30, 0, tzinfo=get_default_timezone())\n        self.assertEqual(format(dt, 'r'), 'Thu, 26 Oct 2023 10:30:00 +0200')\n"], "sample_1153": ["    def test_polar_lift_evalf():\n        from sympy.functions.elementary.complexes import polar_lift\n        z = polar_lift(2 + 3*I)\n        assert N_equals(z._eval_evalf(3), 2 + 3*I)\n        z = polar_lift(2 + 3*I, evaluate=True)\n        assert N_equals(z, 2 + 3*I)\n        z = polar_lift(2 + 3*I, evaluate=False)\n        assert not z.is_number\n        z = polar_lift(2 + 3*I, evaluate=False)._eval_evalf(3)\n        assert N_equals(z, 2 + 3*I)\n        z = polar_lift(2 + 3*I, evaluate=False)._eval_evalf(10)\n        assert N_equals(z, 2 + 3*I)\n\n"], "sample_318": ["compilation error"], "sample_869": ["    def test_brier_score_loss_multiclass():\n        X, y_true, y_prob = make_prediction(dataset=datasets.load_iris(), binary=False)\n        y_true = label_binarize(y_true, classes=range(3))\n        y_prob = np.array([\n            [0.1, 0.2, 0.7],\n            [0.8, 0.1, 0.1],\n            [0.3, 0.5, 0.2],\n        ])\n        with pytest.warns(UndefinedMetricWarning):\n            brier_score = brier_score_loss(y_true, y_prob, pos_label=1)\n        assert np.isfinite(brier_score)\n"], "sample_743": ["def test_radius_neighbors_graph_sparse_data():\n    X = coo_matrix((np.ones(10), (range(10), range(10))), shape=(10, 10))\n    neigh = neighbors.NearestNeighbors(radius=1, algorithm='brute')\n    neigh.fit(X)\n    A = neigh.radius_neighbors_graph(X, mode='connectivity')\n    assert_equal(A.shape, (10, 10))\n    assert_true(np.all(A.toarray() == np.eye(10)))\n\n    neigh = neighbors.NearestNeighbors(radius=1, algorithm='ball_tree')\n    neigh.fit(X)\n    A = neigh.radius_neighbors_graph(X, mode='connectivity')\n    assert_equal(A.shape, (10, 10))\n    assert_true(np.all(A.toarray() == np.eye(10)))\n\n    neigh = neighbors.NearestNeighbors(radius=1, algorithm='kd_tree')\n    neigh.fit(X)\n    A = neigh.radius_neighbors_graph(X, mode='connectivity')\n    assert_equal(A.shape, (10, 10))\n    assert_true(np.all(A.toarray() == np.eye(10)))\n\n\n\n"], "sample_323": ["    def test_migration_plan_with_replacements(self):\n        with self.settings(MIGRATION_MODULES={\"migrations\": \"migrations.test_migrations\"}):\n            executor = MigrationExecutor(connection, progress_callback=mock.Mock())\n            # Create a migration plan with replacements\n            plan = executor.migration_plan(\n                [(\"migrations\", \"0001_initial\")],\n                clean_start=True\n            )\n            # Assert that the plan includes the replacement migration\n            self.assertIn((\"migrations\", \"0002_replace_model\"), plan)\n            # Assert that the replacement migration is applied\n            self.recorder.record_applied(\"migrations\", \"0002_replace_model\")\n            # Assert that the original migration is not applied\n            self.assertNotIn((\"migrations\", \"0001_initial\"), plan)\n"], "sample_952": ["    def test_signature_from_str_with_varargs_and_kwargs():\n        signature = 'def func(a, *b, **c): pass'\n        sig = inspect.signature_from_str(signature)\n        expected_params = [\n            Parameter('a', Parameter.POSITIONAL_ONLY),\n            Parameter('b', Parameter.VAR_POSITIONAL),\n            Parameter('c', Parameter.VAR_KEYWORD),\n        ]\n        assert sig.parameters == expected_params\n"], "sample_558": ["    def test_imagegrid_colorbar_location(self):\n        fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n        grid = ImageGrid(fig, 111, nrows_ncols=(2, 2),\n                         direction=\"row\", axes_pad=0.05,\n                         cbar_location=\"right\", cbar_mode=\"each\")\n\n        for i, ax in enumerate(grid.axes_all):\n            ax.imshow(np.random.rand(10, 10))\n            ax.set_title(f\"Image {i}\")\n\n        plt.show()\n"], "sample_691": ["    def test_faulthandler_timeout_works(self, pytester: Pytester):\n        \"\"\"Test that the faulthandler_timeout option works.\"\"\"\n        # Write a test function that takes a long time to execute\n            import time\n            time.sleep(1)\n\n        # Configure the test to use the faulthandler_timeout option\n        pytester.pytest_cmdline_parse([\"-v\", \"--faulthandler_timeout=0.5\", \"test_faulthandler.py\"])\n\n        # Run the test and assert that the traceback is dumped to stderr\n        result = pytester.runpytest()\n        assert result.retcode == 0\n        assert \"Traceback (most recent call last)\" in result.stdout\n"], "sample_632": ["    def test_ignore_signatures(self):\n        with open(EMPTY_FUNCTION_1, \"r\") as f:\n            code1 = f.read()\n        with open(EMPTY_FUNCTION_2, \"r\") as f:\n            code2 = f.read()\n        linter = PyLinter()\n        linter.set_option(\"ignore-signatures\", True)\n        linter.parse(code1)\n        linter.parse(code2)\n        assert linter.stats[\"nb_duplicated_lines\"] == 0\n"], "sample_313": ["    def test_template_changed_triggers_reset(self, mock_reset_loaders):\n        file_path = EXTRA_TEMPLATES_DIR / \"test.html\"\n        file_path.write_text(\"<h1>Hello, world!</h1>\")\n\n        autoreload.start()\n\n        # Trigger a file change event\n        file_changed.send(sender=autoreload, file_path=file_path)\n\n        mock_reset_loaders.assert_called_once()\n"], "sample_247": ["    def test_non_aggregate_annotation_with_subquery(self):\n        subquery = Book.objects.filter(rating__gt=4).values('isbn')\n        books = Book.objects.annotate(\n            related_book=Subquery(subquery)\n        ).filter(isbn__in=subquery)\n        self.assertEqual(len(books), 3)\n"], "sample_288": ["    def test_json_field_contains_lookup(self):\n        with self.assertNumQueries(1) as queries:\n            results = JSONModel.objects.filter(data__contains={'key': 'value'}).all()\n        self.assertEqual(len(results), 1)\n        self.assertEqual(queries.count(), 1)\n\n        with self.assertNumQueries(1) as queries:\n            results = JSONModel.objects.filter(data__contains={'key': 'value2'}).all()\n        self.assertEqual(len(results), 0)\n        self.assertEqual(queries.count(), 1)\n"], "sample_737": ["    def test_stop_words_max_df(self):\n        # Test stop words removal based on max_df\n        vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n        X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n        feature_names = vectorizer.get_feature_names()\n        stop_words = set(ENGLISH_STOP_WORDS)\n        for term in feature_names:\n            if term in stop_words:\n                assert term not in feature_names, (\n                    f\"Stop word '{term}' should have been removed\"\n                )\n"], "sample_291": ["    def test_redirect_view(self):\n        redirect_view = RedirectView.as_view(url='/about/')\n        response = redirect_view(self.rf.get('/'))\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response['Location'], '/about/')\n\n        redirect_view = RedirectView.as_view(pattern_name='about')\n        response = redirect_view(self.rf.get('/'))\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response['Location'], '/about/')\n\n        redirect_view = RedirectView.as_view(permanent=True)\n        response = redirect_view(self.rf.get('/'))\n        self.assertEqual(response.status_code, 301)\n        self.assertEqual(response['Location'], '/about/')\n\n        redirect_view = RedirectView.as_view(query_string=True)\n        response = redirect_view(self.rf.get('/?foo=bar'))\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response['Location'], '/about/?foo=bar')\n"], "sample_1143": ["    def test_catalan_rewrite_as_sum():\n        from sympy import Sum, Dummy\n        k = Dummy('k', integer=True, nonnegative=True)\n        assert Catalan._eval_rewrite_as_Sum(k_sym=k) == Sum((-1)**k / (2*k+1)**2, (k, 0, S.Infinity))\n"], "sample_191": ["    def test_iter_modules_and_files_with_zip_modules(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_path = Path(tempdir) / 'test.zip'\n            with zipfile.ZipFile(zip_path, 'w') as zf:\n                zf.write('test_module.py', 'test_module.py')\n            extend_sys_path([tempdir])\n            self.import_and_cleanup('test_module')\n            self.assertFileFound(zip_path / 'test_module.py')\n            self.assertFileFound(Path(tempdir) / 'test_module.py')\n            \n            # Test that the zip file is watched even if it's not directly\n            # imported.\n            self.import_and_cleanup('test_module.submodule')\n            self.assertFileFound(zip_path / 'test_module.py')\n\n\n\n"], "sample_173": ["    def test_integer_field_range(self):\n        self.assertEqual(self.ops.integer_field_range('AutoField'), (-2147483648, 2147483647))\n        self.assertEqual(self.ops.integer_field_range('SmallAutoField'), (-32768, 32767))\n        self.assertEqual(self.ops.integer_field_range('BigIntegerField'), (-9223372036854775808, 9223372036854775807))\n        self.assertEqual(self.ops.integer_field_range('PositiveBigIntegerField'), (0, 9223372036854775807))\n        self.assertEqual(self.ops.integer_field_range('PositiveSmallIntegerField'), (0, 32767))\n        self.assertEqual(self.ops.integer_field_range('PositiveIntegerField'), (0, 2147483647))\n"], "sample_431": ["    def test_model_instance_creation_with_default_values(self):\n        with self.subTest(\"default_value_for_field\"):\n            article = Article.objects.create(title=\"Test Article\")\n            self.assertEqual(article.pub_date, datetime.now())\n        with self.subTest(\"default_value_for_field_with_db_default\"):\n            article = PrimaryKeyWithDbDefault.objects.create(title=\"Test Article\")\n            self.assertEqual(article.pk, 1)\n        with self.subTest(\"default_value_for_field_with_default\"):\n            article = PrimaryKeyWithDefault.objects.create(title=\"Test Article\")\n            self.assertEqual(article.pk, 1)\n        with self.subTest(\"default_value_for_field_with_no_default\"):\n            with self.assertRaises(ValueError):\n                Article.objects.create(title=\"Test Article\", pub_date=None)\n\n\n\n"], "sample_955": ["compilation error"], "sample_502": ["compilation error"], "sample_810": ["    def test_pipeline_with_fit_transform(self):\n        X, y = load_iris(return_X_y=True)\n        scaler = StandardScaler()\n        clf = LogisticRegression()\n        pipe = Pipeline([('scaler', scaler), ('clf', clf)])\n\n        X_transformed = pipe.fit_transform(X, y)\n        assert_array_almost_equal(pipe.steps[0][1].transform(X),\n                                  X_transformed[:, :])\n        assert_array_almost_equal(pipe.steps[1][1].predict(X_transformed),\n                                  clf.predict(X_transformed))\n"], "sample_794": ["    def test_ridge_regression_sparse_data(self, X_type, y_type,\n                                         random_state):\n        X = X_type(np.random.randn(100, 50))\n        y = y_type(np.random.randn(100))\n        ridge = Ridge(alpha=0.1, solver='sparse_cg')\n        ridge.fit(X, y)\n        assert isinstance(ridge.coef_, np.ndarray)\n        assert isinstance(ridge.intercept_, float)\n        assert ridge.coef_.shape == (50,)\n        assert ridge.intercept_.shape == ()\n"], "sample_128": ["    def test_index_name_generation(self):\n        model = IndexedArticle2()\n        index = Index(fields=['title', 'pub_date'], name=None)\n        index.set_name_with_model(model)\n        self.assertTrue(index.name.startswith(model._meta.db_table[:11]))\n        self.assertTrue(index.name.endswith(f'{names_digest(*index.fields, length=6)}_{index.suffix}'))\n"], "sample_455": ["    def test_unique_constraint_with_condition(self):\n        with atomic():\n            Product.objects.create(name=\"Test Product 1\", price=10)\n            with self.assertRaises(ValidationError):\n                UniqueConstraintConditionProduct.objects.create(\n                    name=\"Test Product 1\", price=10\n                )\n"], "sample_461": ["    def test_url_field_with_assume_scheme(self):\n        field = URLField(assume_scheme=\"https\")\n        self.assertEqual(field.assume_scheme, \"https\")\n        self.assert_field_validation(field, \"https://www.example.com\", None)\n        self.assert_field_validation(field, \"www.example.com\", None)\n        self.assert_field_validation(field, \"https://www.example.com/path\", None)\n        self.assert_field_validation(field, \"http://www.example.com\", ValidationError)\n        self.assert_field_validation(field, \"ftp://www.example.com\", ValidationError)\n        self.assert_field_validation(field, \"\", ValidationError)\n        self.assert_field_validation(field, \"invalid url\", ValidationError)\n\n\n\n"], "sample_270": ["    def test_index_together_with_expressions(self):\n        with override_settings(DATABASE_ROUTERS={'default': EmptyRouter()}):\n            class MyModel(models.Model):\n                name = models.CharField(max_length=100)\n                value = models.IntegerField()\n\n                class Meta:\n                    indexes = [\n                        models.Index(fields=['name', F('value') * 2], name='my_index'),\n                    ]\n\n            with self.assertRaises(ValueError):\n                MyModel.objects.create(name='test', value=1)\n"], "sample_646": ["compilation error"], "sample_1176": ["    def test_sympify_mpmath_mpq():\n        x = mpmath.rational.mpq(1, 2)\n        assert sympify_mpmath_mpq(x) == Rational(1, 2)\n"], "sample_373": ["    def test_model_detail_view(self):\n        url = reverse('admin:admindocs_model_detail', kwargs={'app_label': 'myapp', 'model_name': 'company'})\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, 'Company')\n        self.assertContains(response, 'name')\n        self.assertContains(response, 'description')\n        self.assertContains(response, 'address')\n"], "sample_296": ["    def test_cookie_storage_max_cookie_size(self):\n        storage = self.storage_class()\n        messages = [\n            Message(constants.INFO, 'Message 1'),\n            Message(constants.INFO, 'Message 2'),\n            Message(constants.INFO, 'Message 3'),\n            Message(constants.INFO, 'Message 4'),\n            Message(constants.INFO, 'Message 5'),\n            Message(constants.INFO, 'Message 6'),\n            Message(constants.INFO, 'Message 7'),\n            Message(constants.INFO, 'Message 8'),\n            Message(constants.INFO, 'Message 9'),\n            Message(constants.INFO, 'Message 10'),\n        ]\n        response = self.get_response()\n\n        # Set the max_cookie_size to a value smaller than the size of all messages\n        with override_settings(COOKIE_MAX_SIZE=1024):\n            storage._store(messages, response, remove_oldest=True)\n\n        self.assertEqual(stored_cookie_messages_count(storage, response), 5)\n\n        # Check that the oldest messages were removed\n        self.assertEqual(storage._decode(response.cookies[storage.cookie_name].value), [\n            Message(constants.INFO, 'Message 6'),\n            Message(constants.INFO, 'Message 7'),\n            Message(constants.INFO, 'Message 8'),\n            Message(constants.INFO, 'Message 9'),\n            Message(constants.INFO, 'Message 10'),\n        ])\n\n        # Check that the sentinel value is present\n        self.assertEqual(storage._decode(response.cookies[storage.cookie_name].value)[-1], CookieStorage.not_finished)\n"], "sample_656": ["    def test_global_and_fixture_disabled(self, capsys):\n        with capture.CaptureManager().global_and_fixture_disabled():\n            capsys.write(\"hello\\n\")\n            capsys.write(\"world\\n\")\n        out, err = capsys.readouterr()\n        assert out == \"\"\n        assert err == \"\"\n"], "sample_703": ["    def test_parens():\n        assert evaluate(\"((True))\", lambda x: True) is True\n        assert evaluate(\"((False))\", lambda x: True) is False\n        assert evaluate(\"(True and False)\", lambda x: True) is False\n        assert evaluate(\"(True or False)\", lambda x: True) is True\n        assert evaluate(\"(True and (False or True))\", lambda x: True) is True\n        assert evaluate(\"(True and (False or False))\", lambda x: True) is False\n        assert evaluate(\"((True) or (False))\", lambda x: True) is True\n        assert evaluate(\"((True) and (False))\", lambda x: True) is False\n"], "sample_197": ["    def test_timesince_future_time(self):\n        future_time = self.t + self.oneday\n        self.assertEqual(timesince(future_time), avoid_wrapping(gettext('0 minutes')))\n"], "sample_161": ["    def test_check_through_fields(self):\n        class MyModel(models.Model):\n            pass\n\n        with override_settings(DATABASE_ROUTERS=['django.db.backends.sqlite3.DatabaseRouter']):\n            with self.subTest('through_fields_are_valid'):\n                class MyManyToManyField(models.ManyToManyField):\n                        super().__init__(to, through=through, **kwargs)\n\n                class MyModelWithManyToMany(models.Model):\n                    my_m2m = MyManyToManyField(MyModel, through='my_through')\n\n                with self.assertRaises(Error) as cm:\n                    MyModelWithManyToMany._meta.get_field('my_m2m').check()\n                self.assertEqual(\n                    str(cm.exception),\n                    \"The intermediary model 'my_through' has no foreign key to '%s'.\" % MyModel._meta.db_table\n                )\n\n            with self.subTest('through_fields_are_not_valid'):\n                class MyModelWithManyToMany(models.Model):\n                    my_m2m = models.ManyToManyField(MyModel, through='my_through', through_fields=('field1', 'field2'))\n\n                with self.assertRaises(Error) as cm:\n                    MyModelWithManyToMany._meta.get_field('my_m2m').check()\n                self.assertEqual(\n                    str(cm.exception),\n                    \"The intermediary model 'my_through' has no field named 'field1'.\"\n                )\n\n\n\n"], "sample_765": ["    def test_hinge_loss_multiclass():\n        X = np.array([[0], [1], [2], [3]])\n        Y = np.array([0, 1, 2, 3])\n        labels = np.array([0, 1, 2, 3])\n        est = svm.LinearSVC()\n        est.fit(X, Y)\n        pred_decision = est.decision_function([[-1], [2], [3]])\n        y_true = [0, 2, 3]\n        hinge_loss_result = hinge_loss(y_true, pred_decision, labels)\n        assert hinge_loss_result > 0\n"], "sample_1032": ["    def test_minmax_rewrite_as_Piecewise_complex(self):\n        x = Symbol('x', complex=True)\n        y = Symbol('y', complex=True)\n        self.assertEqual(Min(x, y).rewrite(Piecewise),\n                         Piecewise((x, x <= y), (y, x > y)))\n        self.assertEqual(Max(x, y).rewrite(Piecewise),\n                         Piecewise((x, x >= y), (y, x < y)))\n"], "sample_81": ["    def test_route_pattern_match(self):\n        pattern = RoutePattern('blog/<int:pk>/', name='blog_detail')\n        match = pattern.match('/blog/123/')\n        self.assertIsNotNone(match)\n        self.assertEqual(match.args, ())\n        self.assertEqual(match.kwargs, {'pk': '123'})\n\n        match = pattern.match('/blog/abc/')\n        self.assertIsNone(match)\n"], "sample_695": ["compilation error"], "sample_1208": ["    def test_matrix_student_t_pdf(self):\n        n, p = 2, 2\n        nu = 3\n        M = MatrixSymbol('M', n, p)\n        Omega = Matrix([[1, 0], [0, 1]])\n        Sigma = Matrix([[2, 0], [0, 3]])\n        M_dist = MatrixStudentT('M', nu, M, Omega, Sigma)\n        x = Matrix([[1, 2], [3, 4]])\n        pdf_value = density(M_dist)(x)\n        expected_value = gamma((nu + n + p - 1)/2, p) * Determinant(Omega)**(-n/2) * Determinant(Sigma)**(-p/2) \\\n            / ((pi)**(n*p/2) * multigamma((nu + p - 1)/2, p)) * (Determinant(eye(n) + Inverse(Sigma)*(x - M)*Inverse(Omega)*Transpose(x - M))) \\\n               **(-(nu + n + p -1)/2)\n        self.assert_almost_equal(pdf_value.doit(), expected_value)\n\n"], "sample_1095": ["    def test_from_inversion_vector_large(self):\n        for i in range(10):\n            perm = Permutation.random(10)\n            inv_vec = perm.inversion_vector()\n            perm2 = Permutation.from_inversion_vector(inv_vec)\n            self.assertEqual(perm, perm2)\n"], "sample_854": ["    def test_predict_proba_ovr_multiclass(self):\n        X, y = make_classification(n_samples=100, n_features=2, n_classes=3,\n                                   random_state=42)\n        clf = svm.SVC(kernel='linear', probability=True, multi_class='ovr')\n        clf.fit(X, y)\n        y_pred_proba = clf.predict_proba(X)\n        assert y_pred_proba.shape[1] == 3\n        assert np.all(np.sum(y_pred_proba, axis=1) == 1)\n"], "sample_817": ["    def test_threshold_zero(self):\n        X = np.array(data)\n        selector = VarianceThreshold(threshold=0.)\n        selector.fit(X)\n        support = selector.get_support()\n        assert_equal(support, [True, True, True, True, False])\n\n        X_sparse = csc_matrix(data)\n        selector = VarianceThreshold(threshold=0.)\n        selector.fit(X_sparse)\n        support = selector.get_support()\n        assert_equal(support, [True, True, True, True, False])\n"], "sample_62": ["    def test_register_model_with_custom_admin_class(self):\n        self.site.register(Person, NameAdmin)\n        self.assertIn(Person, self.site._registry)\n        admin_class = self.site._registry[Person]\n        self.assertIsInstance(admin_class, NameAdmin)\n"], "sample_454": ["    def test_exclusion_constraint_creation(self):\n        with atomic():\n            Product.objects.create(name=\"Product A\", description=\"Description A\")\n            Product.objects.create(name=\"Product B\", description=\"Description B\")\n\n        with self.assertRaises(IntegrityError):\n            Product.objects.create(name=\"Product A\", description=\"Description A\")\n"], "sample_354": ["    def test_createsuperuser_with_password(self):\n        with mock.patch('builtins.input', lambda prompt: None):\n            with mock.patch('django.contrib.auth.management.createsuperuser.getpass', lambda prompt: 'password123'):\n                call_command('createsuperuser')\n        user = User.objects.get(username='alice')\n        self.assertEqual(user.password, 'password123')\n"], "sample_101": ["    def test_wsgi_request_content_length(self):\n        environ = {\n            'REQUEST_METHOD': 'POST',\n            'CONTENT_LENGTH': '100',\n            'wsgi.input': BytesIO(b'some data'),\n        }\n        request = WSGIRequest(environ)\n        self.assertEqual(request._stream.remaining, 100)\n        self.assertEqual(request._stream.read(), b'some data')\n        self.assertEqual(request._stream.remaining, 0)\n\n        # Test empty content length\n        environ = {\n            'REQUEST_METHOD': 'POST',\n            'CONTENT_LENGTH': '0',\n            'wsgi.input': BytesIO(b''),\n        }\n        request = WSGIRequest(environ)\n        self.assertEqual(request._stream.remaining, 0)\n        self.assertEqual(request._stream.read(), b'')\n\n        # Test missing content length\n        environ = {\n            'REQUEST_METHOD': 'POST',\n            'wsgi.input': BytesIO(b'some data'),\n        }\n        request = WSGIRequest(environ)\n        self.assertEqual(request._stream.remaining, float('inf'))\n        self.assertEqual(request._stream.read(), b'some data')\n        self.assertEqual(request._stream.remaining, float('inf'))\n"], "sample_1170": ["    def test_print_MatrixSymbol(self):\n        self.assertEqual(sstr(MatrixSymbol('A', 2, 3)), 'MatrixSymbol(\"A\", 2, 3)')\n        self.assertEqual(sstr(MatrixSymbol('B', 1, 1)), 'MatrixSymbol(\"B\", 1, 1)')\n        self.assertEqual(sstr(MatrixSymbol('C', 3, 2)), 'MatrixSymbol(\"C\", 3, 2)')\n"], "sample_909": ["    def test_namedtuple_subclass(self):\n        docstring = cleandoc(\"\"\"\n        Sample namedtuple subclass\n\n        Attributes\n        ----------\n        attr1 : Arbitrary type\n            Quick description of attr1\n        attr2 : Another arbitrary type\n            Quick description of attr2\n        attr3 : Type\n\n            Adds a newline after the type\n        \"\"\")\n        config = Config(napoleon_use_rtype=True)\n        docstring_obj = NumpyDocstring(docstring, config)\n        expected_output = dedent(\"\"\"\n        Sample namedtuple subclass\n\n        Attributes\n        ----------\n        attr1 : Arbitrary type\n        attr2 : Another arbitrary type\n        attr3 : Type\n\n        \"\"\")\n        self.assertEqual(docstring_obj.__str__(), expected_output)\n"], "sample_1017": ["    def test_bool_map_complex():\n        eq = And(Xor(a, b), c, And(c,d))\n        eq2 = eq.subs(c, x)\n        result, mapping = bool_map(eq, eq2)\n        assert result == eq2\n        assert mapping == {a: a, b: b, c: d, d: x}\n"], "sample_515": ["def test_colorbar_extension_length(tmpdir):\n    \"\"\"\n    Test the length of colorbar extensions for different spacing and\n    extendfrac values.\n    \"\"\"\n    for spacing in ('uniform', 'proportional'):\n        fig = _colorbar_extension_length(spacing)\n        fig.savefig(f'{tmpdir}/colorbar_extension_length_{spacing}.png')\n"], "sample_848": ["    def test_classifier_chain_multiclass_classification(self):\n        X, y = make_classification(n_samples=100, n_features=20, n_classes=3, random_state=42)\n        y = y.astype(int)\n        clf = ClassifierChain(base_estimator=LogisticRegression(random_state=42), cv=5)\n        clf.fit(X, y)\n        y_pred = clf.predict(X)\n        assert_array_equal(y_pred.shape, y.shape)\n        assert_array_almost_equal(jaccard_score(y, y_pred, average='micro'), 1.0)\n"], "sample_776": ["    def test_lars_path_residues(self):\n        X = np.array([[1, 2], [3, 4], [5, 6]])\n        y = np.array([1, 2, 3])\n        alphas, active, coefs, residues = _lars_path_residues(\n            X, y, X, y, Gram=None, copy=False, method='lar',\n            verbose=0, normalize=True, fit_intercept=True,\n            max_iter=100, eps=1e-6, positive=False)\n        assert alphas.shape[0] > 0\n        assert active.shape[0] == X.shape[0]\n        assert coefs.shape[0] == X.shape[1]\n        assert residues.shape == (len(alphas), X.shape[0])\n\n\n\n"], "sample_852": ["    def test_make_sparse_coded_signal():\n        X, _, _ = make_sparse_coded_signal(n_samples=10, n_components=5,\n                                           n_features=10,\n                                           n_nonzero_coefs=3)\n        assert X.shape == (10, 5)\n        assert_all_finite(X)\n\n\n\n"], "sample_386": ["    def test_mark_safe_callable(self):\n            return mark_safe(\"Hello, world!\")\n\n        # Wrap the view with mark_safe\n        wrapped_view = mark_safe(my_view)\n\n        # Assert that the wrapped view returns a SafeString\n        self.assertIsInstance(wrapped_view(), SafeString)\n"], "sample_526": ["    def test_auto_date_locator(self):\n        with rc_context({'date.autoformatter': 'auto',\n                         'date.converter': 'auto'}):\n            fig, ax = plt.subplots()\n            x = np.arange(mdates.date2num(datetime.date(2000, 1, 1)),\n                          mdates.date2num(datetime.date(2005, 1, 1)),\n                          0.1)\n            ax.plot(x, np.sin(x))\n            ax.set_xlabel('Date')\n            ax.set_ylabel('sin(x)')\n            ax.set_title('Auto Date Locator')\n            ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n            ax.xaxis.set_major_formatter(mdates.AutoDateFormatter())\n            plt.show()\n\n\n\n"], "sample_747": ["    def test_power_transform_ordinal(self):\n        X = np.array([\n            [1, 2, 3],\n            [4, 5, 6],\n            [7, 8, 9]\n        ])\n        pt = PowerTransformer(method='ordinal')\n        X_trans = pt.fit_transform(X)\n        assert_array_equal(X_trans, np.array([\n            [0, 1, 2],\n            [3, 4, 5],\n            [6, 7, 8]\n        ]))\n\n        X_back = pt.inverse_transform(X_trans)\n        assert_array_equal(X_back, X)\n\n\n\n"], "sample_444": ["    def test_manifest_strict_mode(self):\n        with override_settings(STATICFILES_STORAGE='django.contrib.staticfiles.storage.ManifestStaticFilesStorage'):\n            self.maxDiff = None\n            self.create_test_files(\n                [\n                    (\"css/style.css\", \"/* some styles */\"),\n                    (\"js/script.js\", \"/* some script */\"),\n                ]\n            )\n            call_command(\"collectstatic\", interactive=False, dry_run=False)\n            self.assertPostCondition()\n            with self.assertRaises(ValueError):\n                self.create_test_files(\n                    [(\"css/style.css\", \"/* some styles */\"), (\"css/style.css\", \"/* some other styles */\")]\n                )\n            self.assertPostCondition()\n\n\n\n"], "sample_1159": ["    def test_failing_assumptions_empty():\n        x = Symbol('x')\n        assert failing_assumptions(x, real=True, integer=True) == {}\n"], "sample_414": ["    def test_formfield_for_dbfield_with_custom_widget(self):\n        class MyModel(models.Model):\n            my_field = models.CharField(max_length=100)\n\n        class MyModelAdmin(admin.ModelAdmin):\n            formfield_overrides = {\n                models.CharField: {\"widget\": forms.TextInput(attrs={\"class\": \"my-custom-class\"})},\n            }\n\n        ff = self.assertFormfield(MyModel, \"my_field\", forms.TextInput, admin_overrides={\"formfield_overrides\": None})\n        self.assertEqual(ff.widget.attrs[\"class\"], \"my-custom-class\")\n\n\n\n"], "sample_664": ["compilation error"], "sample_39": ["    def test_wcs_from_file(self, filename):\n        with catch_warnings(record=True) as w:\n            wcs = wcs.WCS(get_pkg_data_filename(\"maps\", filename))\n        assert len(w) == 0\n        assert wcs.naxis == 2\n        assert wcs.wcs.ctype[0] == 'RA---TAN'\n        assert wcs.wcs.ctype[1] == 'DEC--TAN'\n\n\n\n"], "sample_54": ["    def test_file_response_with_content_length(self):\n        with tempfile.NamedTemporaryFile(delete=False) as f:\n            f.write(b'test content')\n            f.flush()\n            response = FileResponse(f.name, as_attachment=True)\n            self.assertEqual(response['Content-Length'], str(len(f.read())))\n            os.remove(f.name)\n"], "sample_46": ["    def test_uuid_contains_with_hyphen(self):\n        uuid_value = str(uuid.uuid4())\n        with self.subTest(uuid_value=uuid_value):\n            instance = UUIDModel.objects.create(uuid_field=uuid_value)\n            self.assertTrue(UUIDModel.objects.filter(uuid_field__icontains=uuid_value).exists())\n            self.assertTrue(UUIDModel.objects.filter(uuid_field__contains=uuid_value).exists())\n"], "sample_179": ["    def test_index_together_with_condition(self):\n        with override_settings(DATABASE_ROUTERS={'default': EmptyRouter()}):\n            class MyModel(models.Model):\n                name = models.CharField(max_length=100)\n                age = models.IntegerField()\n\n                class Meta:\n                    indexes = [\n                        models.Index(fields=['name'], condition=models.Q(age__gt=18)),\n                    ]\n\n            with self.assertRaises(Warning) as context:\n                _check_lazy_references(MyModel)\n            self.assertIn(\n                'does not support indexes with conditions.', str(context.exception)\n            )\n\n\n\n"], "sample_35": ["    def test_minversion_module_not_found():\n        with pytest.raises(ImportError):\n            minversion('nonexistent_module', '0.1')\n"], "sample_422": ["    def test_prefetch_related_with_related_manager(self):\n        with ignore_warnings(category=RemovedInDjango50Warning):\n            with CaptureQueriesContext(connection) as queries:\n                qs = Book.objects.prefetch_related(\n                    \"authors\", \"authors__name\"\n                ).select_related(\"authors__name\")\n                qs.get(title=\"Jane Eyre\")\n            self.assertEqual(len(queries.captured_queries), 1)\n            self.assertWhereContains(queries.captured_queries[0], \"authors__name\")\n            self.assertWhereContains(queries.captured_queries[0], \"authors\")\n\n            qs = Book.objects.prefetch_related(\"authors\").select_related(\"authors__name\")\n            qs.get(title=\"Jane Eyre\")\n            self.assertEqual(len(queries.captured_queries), 2)\n            self.assertWhereContains(queries.captured_queries[1], \"authors__name\")\n            self.assertWhereContains(queries.captured_queries[1], \"authors\")\n\n            qs = Book.objects.select_related(\"authors\").prefetch_related(\"authors__name\")\n            qs.get(title=\"Jane Eyre\")\n            self.assertEqual(len(queries.captured_queries), 3)\n            self.assertWhereContains(queries.captured_queries[2], \"authors__name\")\n            self.assertWhereContains(queries.captured_queries[2], \"authors\")\n\n\n\n"], "sample_1067": ["    def test_as_content_primitive_issue_6421():\n        from sympy.core.mul import _keep_coeff\n        x = symbols('x')\n        expr = (2*x*I*sqrt(2) * (1 + x))\n        c, p = expr.as_content_primitive(radical=True)\n        assert c == 2*sqrt(2)*I\n        assert p == (1 + x)\n        expr = (2*x*I*sqrt(2) * (1 + x))\n        c, p = expr.as_content_primitive(radical=True, clear=False)\n        assert c == 2*sqrt(2)*I\n        assert p == (1 + x)\n        expr = (2*x*I*sqrt(2) * (1 + x))\n        c, p = expr.as_content_primitive(radical=True, clear=False, sign=True)\n        assert c == -2*sqrt(2)*I\n        assert p == -(1 + x)\n\n\n\n"], "sample_1140": ["compilation error"], "sample_438": ["    def test_generic_foreign_key_with_null_target(self):\n        post = Post.objects.create(title=\"My Post\")\n        answer = Answer.objects.create(question=post, content=\"My Answer\")\n\n        # Delete the related post\n        post.delete()\n\n        # Check that the answer still exists and its content type and object ID are correct\n        answer_from_db = Answer.objects.get(pk=answer.pk)\n        self.assertEqual(answer_from_db.content_type.model, \"post\")\n        self.assertEqual(answer_from_db.object_id, post.pk)\n\n        # Check that the answer's related post is None\n        self.assertIsNone(answer_from_db.question)\n\n        # Try to access the related post through the GenericForeignKey\n        with self.assertRaises(models.ProtectedError):\n            answer_from_db.question\n\n        # Try to update the answer's related post\n        with self.assertRaises(models.ProtectedError):\n            answer_from_db.question = Post.objects.create(title=\"New Post\")\n\n        # Try to delete the answer\n        with self.assertRaises(models.ProtectedError):\n            answer_from_db.delete()\n\n\n\n"], "sample_549": ["    def test_delete_masked_points_empty(self):\n        x = np.array([1, 2, 3])\n        y = np.array([4, 5, 6])\n        mask = np.array([False, False, False])\n        result = delete_masked_points(x, y, mask)\n        assert_array_equal(result[0], x)\n        assert_array_equal(result[1], y)\n"], "sample_262": ["    def test_lazy(self):\n        @lazy\n            return a + b\n\n        result = my_func(1, 2)\n        self.assertEqual(result, 3)\n\n        @lazy(int)\n            return a + b\n\n        result = my_func(1, 2)\n        self.assertEqual(result, 3)\n\n        @lazy(str)\n            return a + b\n\n        result = my_func(\"hello\", \" world\")\n        self.assertEqual(result, \"hello world\")\n"], "sample_912": ["    def test_parse_annotation(self):\n        assert _parse_annotation(\"int\") == \"int\"\n        assert _parse_annotation(\"List[str]\") == \"List[str]\"\n        assert _parse_annotation(\"Optional[int]\") == \"Optional[int]\"\n        assert _parse_annotation(\"Union[int, str]\") == \"Union[int, str]\"\n        assert _parse_annotation(\"typing.List[str]\") == \"List[str]\"\n        assert _parse_annotation(\"typing.Optional[int]\") == \"Optional[int]\"\n        assert _parse_annotation(\"typing.Union[int, str]\") == \"Union[int, str]\"\n        assert _parse_annotation(\"MyClass\") == \"MyClass\"\n        assert _parse_annotation(\"MyClass.NestedClass\") == \"MyClass.NestedClass\"\n        assert _parse_annotation(\"MyClass.NestedClass[int]\") == \"MyClass.NestedClass[int]\"\n\n\n\n"], "sample_902": ["    def test_pipeline_memory(self):\n        X, y = load_iris(return_X_y=True)\n        memory = Memory(cachedir=mkdtemp(), verbose=0)\n\n        # Test with a simple pipeline\n        pipeline = Pipeline([\n            ('scaler', StandardScaler()),\n            ('clf', SVC())\n        ], memory=memory)\n\n        # Fit the pipeline\n        pipeline.fit(X, y)\n\n        # Check if the transformers have been cached\n        with memory.cachedir:\n            # Check if the cache directory contains files\n            assert len(os.listdir(memory.cachedir)) > 0\n\n        # Test with a pipeline with a transformer that doesn't fit\n        pipeline_no_fit = Pipeline([\n            ('scaler', StandardScaler()),\n            ('no_fit', NoFit(a=1, b=2))\n        ], memory=memory)\n\n        # Fit the pipeline\n        pipeline_no_fit.fit(X, y)\n\n        # Check if the transformer that doesn't fit has been cached\n        with memory.cachedir:\n            # Check if the cache directory contains files\n            assert len(os.listdir(memory.cachedir)) > 0\n\n        # Test with a pipeline with a transformer that doesn't transform\n        pipeline_no_trans = Pipeline([\n            ('scaler', StandardScaler()),\n            ('no_trans', NoTrans())\n        ], memory=memory)\n\n        # Fit the pipeline\n        pipeline_no_trans.fit(X, y)\n\n        # Check if the transformer that doesn't transform has been cached\n        with memory.cachedir:\n            # Check if the cache directory contains files\n            assert len(os.listdir(memory.cachedir)) > 0\n\n        # Test with a pipeline with a transformer that doesn't inverse transform\n        pipeline_no_inv_trans = Pipeline([\n            ('scaler', StandardScaler()),\n            ('no_inv_trans', NoInvTransf())\n        ], memory=memory)\n\n        # Fit the pipeline\n        pipeline_no_inv_trans.fit(X, y)\n\n        # Check if the transformer that doesn't inverse transform has been cached\n        with memory.cachedir:\n            # Check if the cache directory contains files\n            assert len(os"], "sample_564": ["    def test_stem3d(self):\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection='3d')\n        X, Y, Z = get_test_data()\n        ax.stem(X, Y, Z, linefmt='r-', markerfmt='bo', label='Stems')\n        ax.set_xlabel('X')\n        ax.set_ylabel('Y')\n        ax.set_zlabel('Z')\n        plt.show()\n"], "sample_1133": ["    def test_refraction_angle_plane():\n        P = Plane(Point3D(0, 0, 0), normal_vector=[0, 0, 1])\n        r1 = Ray3D(Point3D(-1, -1, 1), Point3D(0, 0, 0))\n        with raises(ValueError):\n            refraction_angle(r1, 1, 1, plane=P, normal=Matrix([0, 0, 1]))\n        with raises(ValueError):\n            refraction_angle(r1, 1, 1, normal=Matrix([0, 0, 1]), plane=P)\n        with raises(TypeError):\n            refraction_angle(r1, 1, 1, plane=P, normal=[0, 0, 1])\n        with raises(TypeError):\n            refraction_angle(r1, 1, 1, normal=[0, 0, 1], plane=P)\n        with raises(ValueError):\n            refraction_angle(r1, 1, 1, plane=P, normal=Matrix([1, 0, 0]))\n        with raises(ValueError):\n            refraction_angle(r1, 1, 1, normal=Matrix([1, 0, 0]), plane=P)\n        with raises(TypeError):\n            refraction_angle(r1, 1, 1, plane=P, normal=[1, 0, 0])\n        with raises(TypeError):\n            refraction_angle(r1, 1, 1, normal=[1, 0, 0], plane=P)\n        with raises(ValueError):\n            refraction_angle(r1, 1, 1, plane=P, normal=Matrix([0, 1, 0]))\n        with raises(ValueError):\n            refraction_angle(r1, 1, 1, normal=Matrix([0, 1, 0]), plane=P)\n        with raises(TypeError):\n            refraction_angle(r1, 1, 1, plane=P, normal=[0, 1, 0])\n        with raises(TypeError):\n            refraction_angle(r1"], "sample_1119": ["    def test_connected_components_decomposition():\n        A = Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 0]])\n        B = Matrix([[1, 0, 0], [0, 0, 0], [0, 0, 1]])\n        C = Matrix([[1, 0, 0], [0, 0, 0], [0, 0, 0]])\n        D = Matrix([[1, 0, 0], [0, 1, 1], [0, 1, 1]])\n        E = Matrix([[1, 0, 0], [0, 0, 0], [0, 0, 0]])\n        F = Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n        G = Matrix([[1, 0, 0], [0, 0, 0], [0, 0, 0]])\n        H = Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 0]])\n        I = Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 0]])\n        J = Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 0]])\n\n        assert A.connected_components_decomposition() == [A]\n        assert B.connected_components_decomposition() == [B]\n        assert C.connected_components_decomposition() == [C]\n        assert D.connected_components_decomposition() == [D]\n        assert E.connected_components_decomposition() == [E]\n        assert F.connected_components_decomposition() == [F]\n        assert G.connected_components_decomposition() == [G]\n        assert H.connected_components_decomposition() == [H]\n        assert I.connected_components_decomposition() == [I]\n        assert J.connected_components_decomposition() == [J]\n\n\n\n"], "sample_53": ["    def test_autocomplete_select_required_field(self):\n        form = RequiredBandForm()\n        rendered_html = form.as_p()\n        self.assertIn('<select', rendered_html)\n        self.assertIn('required', rendered_html)\n        self.assertNotIn(self.empty_option, rendered_html)\n"], "sample_477": ["    def test_random_with_list_of_strings(self):\n        self.assertEqual(\n            self.render_template(\"random01\"),\n            mark_safe(\n                f\"{self.random_value} {self.random_value}\"\n            ),\n        )\n"], "sample_325": ["    def test_boundfield_label_tag(self):\n        form = PersonNew()\n        bound_field = form.fields['first_name']\n        self.assertEqual(bound_field.label_tag(), '<label for=\"first_name_id\">First name</label>')\n        self.assertEqual(bound_field.label_tag(contents='Custom Label'), '<label for=\"first_name_id\">Custom Label</label>')\n        self.assertEqual(bound_field.label_tag(attrs={'class': 'custom-label'}), '<label class=\"custom-label\" for=\"first_name_id\">First name</label>')\n        self.assertEqual(bound_field.label_tag(contents='Custom Label', attrs={'class': 'custom-label'}), '<label class=\"custom-label\" for=\"first_name_id\">Custom Label</label>')\n        self.assertEqual(bound_field.label_tag(label_suffix=' *'), '<label for=\"first_name_id\">First name </label>')\n"], "sample_457": ["    def test_unique_constraint_with_expressions(self):\n        with atomic():\n            Product.objects.create(name=\"Product A\", description=\"Description A\")\n            with self.assertRaises(IntegrityError):\n                Product.objects.create(name=\"Product A\", description=\"Description B\")\n"], "sample_463": ["compilation error"], "sample_1116": ["    def test_refine_singular_matrix():\n        X = MatrixSymbol('X', 2, 2)\n        with raises(ValueError):\n            refine(X.I, {})\n"], "sample_644": ["    def test_preferred_modules(self) -> None:\n        \"\"\"Test preferred module handling.\"\"\"\n        source = \"\"\""], "sample_190": ["    def test_year_lookup_exact(self):\n        with self.subTest('exact'):\n            qs = Article.objects.filter(pub_date__year__exact=2005)\n            self.assertQuerysetEqual(qs, [self.a1, self.a2, self.a3, self.a4])\n\n        with self.subTest('not exact'):\n            qs = Article.objects.filter(pub_date__year__exact=2006)\n            self.assertQuerysetEqual(qs, [])\n"], "sample_1094": ["    def test_find_basic():\n        from sympy.core.basic import Basic, preorder_traversal\n        class MyBasic(Basic):\n            pass\n        a = MyBasic(1, 2)\n        b = MyBasic(1, 2)\n        c = MyBasic(3, 4)\n        d = MyBasic(1, 5)\n        e = MyBasic(1, 2, 3)\n        assert a.find(lambda x: x.args[0] == 1) == [a]\n        assert a.find(lambda x: x.args[1] == 2) == [a]\n        assert a.find(lambda x: x.args[0] == 3) == []\n        assert a.find(lambda x: isinstance(x, MyBasic)) == [a]\n        assert a.find(lambda x: x.args[0] == 1 and x.args[1] == 2) == [a]\n        assert a.find(lambda x: x.args[0] == 1 or x.args[1] == 2) == [a, b]\n        assert a.find(lambda x: x.args[0] == 1 or x.args[1] == 3) == [a]\n        assert a.find(lambda x: x.args[0] == 1 and x.args[1] == 3) == []\n        assert a.find(lambda x: x.args[0] == 1 and x.args[1] == 2 and x.args[2] == 3) == [e]\n        assert a.find(lambda x: x.args[0] == 1 and x.args[1] == 2 and x.args[2] == 4) == []\n        assert a.find(lambda x: x.args[0] == 1 and x.args[1] == 2 and x.args[2] == 5) == []\n        assert a.find(lambda x: x.args[0] == 1 and x.args[1] == 2 and x.args[2] == 6) == []\n        assert a.find(lambda x: x.args[0]"], "sample_529": ["    def test_bbox_to_anchor(self):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], [4, 5, 6])\n        legend = ax.legend(bbox_to_anchor=(0.5, 0.9), loc='upper center')\n        plt.show()\n\n\n\n"], "sample_749": ["    def test_remainder_drop(self):\n        X = np.array([[1, 2], [3, 4]])\n        scaler = StandardScaler()\n        ct = make_column_transformer(\n            [(\"scaler\", scaler, [0])], remainder='drop')\n        X_transformed = ct.fit_transform(X)\n        assert X_transformed.shape == (2, 1)\n        assert_allclose_dense_sparse(X_transformed,\n                                     scaler.fit_transform(X[:, [0]]))\n"], "sample_687": ["    def test_log_cli_level(self, testdir: Testdir) -> None:\n        p = testdir.makepyfile(\n            \"\"\"\n            import logging\n\n            logging.basicConfig(level=logging.DEBUG)\n\n                logging.debug(\"This is a debug message\")\n                logging.info(\"This is an info message\")\n                logging.warning(\"This is a warning message\")\n                logging.error(\"This is an error message\")\n                logging.critical(\"This is a critical message\")\n            \"\"\"\n        )\n        result = testdir.runpytest()\n        result.assert_outcomes(passed=1)\n        # Check that the log messages are captured correctly\n        re = result.stdout.re(r\"DEBUG: This is a debug message\")\n        assert re.search(re) is not None\n        re = result.stdout.re(r\"INFO: This is an info message\")\n        assert re.search(re) is not None\n        re = result.stdout.re(r\"WARNING: This is a warning message\")\n        assert re.search(re) is not None\n        re = result.stdout.re(r\"ERROR: This is an error message\")\n        assert re.search(re) is not None\n        re = result.stdout.re(r\"CRITICAL: This is a critical message\")\n        assert re.search(re) is not None\n"], "sample_700": ["    def test_evaluate_skip_marks_with_explicit_reason(self, pytester):\n        \"\"\"Test evaluate_skip_marks with explicit reason.\"\"\"\n        pytester.raises(pytest.skip.Exception,\n                        lambda: evaluate_skip_marks(\n                            [pytest.mark.skip(reason=\"explicit reason\")],\n                            None,\n                        ),\n                        match=\"explicit reason\")\n"], "sample_430": ["compilation error"], "sample_821": ["    def test_affinity_propagation_equal_similarities_and_preferences():\n        # Test case for equal similarities and preferences\n        S = np.ones((3, 3))\n        preference = np.ones(3)\n\n        assert _equal_similarities_and_preferences(S, preference)\n\n        S = np.ones((3, 3))\n        preference = np.zeros(3)\n        assert not _equal_similarities_and_preferences(S, preference)\n\n        S = np.array([[1, 2, 3], [2, 1, 4], [3, 4, 1]])\n        preference = np.array([1, 2, 3])\n        assert not _equal_similarities_and_preferences(S, preference)\n"], "sample_55": ["    def test_admin_form_fields(self):\n        response = self.client.get(reverse('admin:article_changelist'))\n        fields = self.get_admin_form_fields(response)\n        self.assertIn('search', [f.field['name'] for f in fields])\n        self.assertIn('date', [f.field['name'] for f in fields])\n        self.assertIn('section', [f.field['name'] for f in fields])\n        self.assertIn('title', [f.field['name'] for f in fields])\n        self.assertIn('content', [f.field['name'] for f in fields])\n\n\n\n"], "sample_115": ["    def test_callable_setting_wrapper_calls_callable(self):\n            return 'called'\n\n        wrapper = CallableSettingWrapper(callable_setting)\n        self.assertEqual(wrapper(), 'called')\n\n\n\n"], "sample_970": ["    def test_signature_from_str_with_varargs_kwargs():\n        signature = 'def func(a, b, *, c, d=10, *args, **kwargs): pass'\n        sig = inspect.signature_from_str(signature)\n        assert sig.parameters['a'].kind == inspect.Parameter.POSITIONAL_OR_KEYWORD\n        assert sig.parameters['b'].kind == inspect.Parameter.POSITIONAL_OR_KEYWORD\n        assert sig.parameters['c'].kind == inspect.Parameter.KEYWORD_ONLY\n        assert sig.parameters['d'].kind == inspect.Parameter.POSITIONAL_OR_KEYWORD\n        assert sig.parameters['args'].kind == inspect.Parameter.VAR_POSITIONAL\n        assert sig.parameters['kwargs'].kind == inspect.Parameter.VAR_KEYWORD\n"], "sample_211": ["    def test_redirect_view(self):\n        redirect_view = RedirectView.as_view(url='/about/')\n        response = redirect_view(self.rf.get('/'))\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response['Location'], '/about/')\n\n        redirect_view = RedirectView.as_view(pattern_name='about')\n        response = redirect_view(self.rf.get('/'))\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response['Location'], '/about/')\n\n        redirect_view = RedirectView.as_view(permanent=True)\n        response = redirect_view(self.rf.get('/'))\n        self.assertEqual(response.status_code, 301)\n        self.assertEqual(response['Location'], '/about/')\n\n        redirect_view = RedirectView.as_view(query_string=True)\n        response = redirect_view(self.rf.get('/?foo=bar'))\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response['Location'], '/about/?foo=bar')\n"], "sample_760": ["    def test_check_scoring_with_custom_scorer(self):\n        class CustomScorer(object):\n                return np.mean(y)\n\n        scorer = make_scorer(CustomScorer())\n        estimator = EstimatorWithFitAndPredict()\n        scorer_result = scorer(estimator, X_mm, y_mm)\n        assert_almost_equal(scorer_result, np.mean(y_mm))\n"], "sample_742": ["    def test_logistic_regression_cv_multiclass_ovr(self):\n        X, y = make_classification(n_samples=100, n_features=20,\n                                   n_informative=10, n_redundant=5,\n                                   n_classes=3, random_state=42)\n        y = np.array(y)\n        label_encoder = LabelEncoder().fit(y)\n        y = label_encoder.transform(y)\n\n        clf = LogisticRegressionCV(Cs=10, cv=5, penalty='l2',\n                                   solver='lbfgs', multi_class='ovr',\n                                   random_state=42)\n        clf.fit(X, y)\n\n        assert_equal(clf.n_iter_.shape, (3, 5, 10))\n        assert_equal(clf.coef_.shape, (3, 20))\n        assert_equal(clf.intercept_.shape, (3,))\n        assert_equal(clf.Cs_.shape, (10,))\n\n        # Check that the predictions are correct\n        check_predictions(clf, X, y)\n"], "sample_928": ["    def test_default_role(self):\n        with default_role('testdoc.rst', 'myrole'):\n            role_fn = docutils.get_role('')\n            assert role_fn is not None\n            assert role_fn.__name__ == 'myrole'\n\n        with default_role('testdoc.rst', None):\n            role_fn = docutils.get_role('')\n            assert role_fn is None\n\n        with default_role('testdoc.rst', 'nonexistent_role'):\n            role_fn = docutils.get_role('')\n            assert role_fn is None\n            \n"], "sample_936": ["    def test_stringify_callable(self):\n        if sys.version_info >= (3, 7):\n            callable_type = Callable[[T], List[str]]\n            assert stringify(callable_type) == 'Callable[[T], List[str]]'\n        else:\n            callable_type = typing.Callable[[T], List[str]]\n            assert stringify(callable_type) == 'Callable[[T], List[str]]'\n\n\n\n"], "sample_341": ["    def test_formset_factory_with_custom_kwargs(self):\n        class CustomFormSet(formset_factory(CustomKwargForm, extra=1)):\n            pass\n\n        formset = CustomFormSet(custom_kwarg='test_value')\n        self.assertEqual(formset.forms[0].custom_kwarg, 'test_value')\n\n\n\n"], "sample_984": ["    def test_print_MatrixSymbol(self):\n        self.assertEqual(sstr(MatrixSymbol('A', 2, 3)), 'MatrixSymbol(\"A\", 2, 3)')\n        self.assertEqual(sstrrepr(MatrixSymbol('A', 2, 3)), \"MatrixSymbol('A', 2, 3)\")\n"], "sample_230": ["    def test_json_field_with_custom_encoder_decoder(self):\n        class CustomEncoder(DjangoJSONEncoder):\n                if isinstance(obj, datetime.datetime):\n                    return obj.isoformat()\n                return super().default(obj)\n\n        class CustomDecoder(json.JSONDecoder):\n                if isinstance(s, str) and s.endswith(\"Z\"):\n                    return datetime.datetime.fromisoformat(s[:-1]).replace(tzinfo=timezone.utc)\n                return super().decode(s, _)\n\n        class MyForm(Form):\n            my_json = JSONField(encoder=CustomEncoder, decoder=CustomDecoder)\n\n        data = {\n            'my_field': datetime.datetime(2023, 10, 26, 10, 30, 0, tzinfo=timezone.utc).isoformat() + \"Z\"\n        }\n        form = MyForm(data)\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['my_json'], datetime.datetime(2023, 10, 26, 10, 30, 0, tzinfo=timezone.utc))\n\n\n\n"], "sample_1002": ["    def test_sympify_mpmath_complex():\n        z = mpmath.mpc(1, 2)\n        result = sympify_mpmath(z)\n        assert isinstance(result, Mul)\n        assert result.args[0] == S.One\n        assert result.args[1] == S.ImaginaryUnit * S.Two\n"], "sample_969": ["    def test_restify_typing_union(self):\n        assert restify(Union[int, str]) == 'int | str'\n        assert restify(Union[int, str, None]) == 'int | str | None'\n        assert restify(Union[MyInt, str]) == 'MyInt | str'\n        assert restify(Union[int, Union[str, int]]) == 'int | str | int'\n        assert restify(Union[int, MyList[int], None]) == 'int | List[T] | None'\n\n\n\n"], "sample_240": ["    def test_token_generation_with_custom_email_field(self):\n        with ignore_warnings(category=RemovedInDjango40Warning):\n            user = User.objects.create_user(username='testuser', password='testpassword')\n            user.email = 'test@example.com'\n            user.save()\n\n            # Create a custom email field\n            CustomEmailField.objects.create(user=user, custom_email='custom@example.com')\n\n            generator = MockedPasswordResetTokenGenerator(datetime.now())\n            token = generator.make_token(user)\n\n            # Assert that the token is valid\n            self.assertTrue(generator.check_token(user, token))\n"], "sample_528": ["compilation error"], "sample_806": ["compilation error"], "sample_8": ["    def test_masked_array_from_array_and_mask(self):\n        for data, mask in [(self.a, self.mask_a), (self.b, self.mask_b),\n                          (self.c, self.mask_c)]:\n            masked_array = Masked(data, mask)\n            assert_masked_equal(masked_array, Masked(data, mask))\n            assert_masked_equal(masked_array, Masked(data, mask))\n            assert masked_array.dtype == data.dtype\n            assert masked_array.mask.dtype == bool\n"], "sample_263": ["    def test_dumpdata_with_natural_keys(self):\n        with self.settings(\n            INSTALLED_APPS=[\n                'django.contrib.sites',\n                'tests',\n            ],\n        ):\n            # Create a test site\n            Site.objects.create(domain='example.com', name='example.com')\n            # Create some test data\n            Article.objects.create(title='Test Article', category=Category.objects.create(name='Test Category'))\n            # Dump the data with natural keys\n            with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n                temp_file_path = temp_file.name\n                management.call_command(\n                    'dumpdata',\n                    '-o', temp_file_path,\n                    '--natural-foreign',\n                    '--natural-primary',\n                )\n            # Load the data with natural keys\n            with open(temp_file_path, 'r') as f:\n                data = f.read()\n            # Assert that the data was loaded correctly\n            self.assertEqual(Article.objects.count(), 1)\n            self.assertEqual(Category.objects.count(), 1)\n            os.remove(temp_file_path)\n\n\n\n"], "sample_916": ["compilation error"], "sample_1188": ["compilation error"], "sample_15": ["    def test_ufunc_with_quantity_and_array(self):\n        a = np.array([1, 2, 3])\n        b = u.Quantity(a, 'm')\n        c = np.array([4, 5, 6])\n        result = np.add(b, c)\n        assert isinstance(result, u.Quantity)\n        assert result.unit == 'm'\n        assert_array_equal(result.value, np.array([5, 7, 9]))\n\n\n\n"], "sample_947": ["    def test_c_alias_role(self):\n        check('alias',\n              'c:alias::my_alias',\n              {'1': 'c:alias::my_alias'},\n              'c:alias::my_alias',\n              asTextOutput='c:alias::my_alias')\n\n\n\n"], "sample_518": ["    def test_fancyarrowpatch_mutation_scale(self):\n        fig, ax = plt.subplots()\n        arrow = FancyArrowPatch((0, 0), (1, 1),\n                               arrowstyle=\"->\", mutation_scale=2)\n        ax.add_artist(arrow)\n        plt.show()\n"], "sample_385": ["    def test_autocomplete_select_required_field(self):\n        form = RequiredBandForm()\n        rendered_html = form.as_p()\n        self.assertIn(\n            '<select class=\"my-class admin-autocomplete\" data-ajax--url=\"/admin/band/autocomplete/\"',\n            rendered_html,\n        )\n        self.assertIn(\n            '<option value=\"\">'\n            + _(\"Select a band\")\n            + \"</option>\",\n            rendered_html,\n        )\n"], "sample_149": ["    def test_check_user_model_non_unique_username(self):\n        with override_settings(AUTH_USER_MODEL='auth_tests.CustomUserNonUniqueUsername'):\n            errors = check_user_model()\n            self.assertEqual(len(errors), 1)\n            self.assertEqual(errors[0].id, 'auth.E003')\n"], "sample_908": ["compilation error"], "sample_1035": ["def test_measure_partial_oneshot_multiple_qubits():\n    from sympy.physics.quantum.qubit import Qubit, measure_partial_oneshot\n    c = Qubit('101')\n    result = measure_partial_oneshot(c, (0, 2))\n    assert result.as_int() in [1, 3]\n"], "sample_779": ["    def fit(self, X, y=None):\n        self.X_shape_ = check_array(X).shape\n        return self\n"], "sample_365": ["    def test_lazy_object_unpickling(self):\n        @lazy\n            return 'hello'\n\n        lazy_obj = my_func()\n        with ignore_warnings(category=RemovedInDjango50Warning):\n            pickled_obj = pickle.dumps(lazy_obj)\n        unpickled_obj = pickle.loads(pickled_obj)\n        self.assertEqual(unpickled_obj(), 'hello')\n"], "sample_890": ["compilation error"], "sample_66": ["    def test_get_full_path_with_slash(self):\n        request = HttpRequest()\n        request.path = '/path/to/resource/'\n        self.assertEqual(request.get_full_path(), '/path/to/resource/')\n"], "sample_402": ["    def test_should_redirect_with_slash_append(self):\n        request = self.rf.get(\"/foo\")\n        self.assertFalse(CommonMiddleware().should_redirect_with_slash(request))\n\n        request = self.rf.get(\"/foo/\")\n        self.assertFalse(CommonMiddleware().should_redirect_with_slash(request))\n\n        request = self.rf.get(\"/foo\")\n        request.urlconf = \"middleware.urls\"\n        self.assertTrue(CommonMiddleware().should_redirect_with_slash(request))\n"], "sample_595": ["    def test_replace_regex_callable(self, dtype):\n        da = xr.DataArray(\n            [\"apple\", \"banana\", \"cherry\"], dtype=dtype\n        )\n            return str(len(match.group(0)))\n\n        result = da.str.replace(r\"a\", replace_with_length, regex=True)\n        expected = xr.DataArray(\n            [\"pple\", \"bannna\", \"cherry\"], dtype=dtype\n        )\n        assert_equal(result, expected)\n"], "sample_918": ["    def test_parse_annotation(self):\n        assert _parse_annotation('int') == 'int'\n        assert _parse_annotation('int, str') == 'int, str'\n        assert _parse_annotation('List[int]') == 'List[int]'\n        assert _parse_annotation('Optional[str]') == 'Optional[str]'\n        assert _parse_annotation('Union[int, float]') == 'Union[int, float]'\n        assert _parse_annotation('typing.List[int]') == 'typing.List[int]'\n        assert _parse_annotation('typing.Optional[str]') == 'typing.Optional[str]'\n        assert _parse_annotation('typing.Union[int, float]') == 'typing.Union[int, float]'\n        assert _parse_annotation('MyClass') == 'MyClass'\n\n\n\n"], "sample_223": ["compilation error"], "sample_1199": ["compilation error"], "sample_157": ["    def test_test_db_signature(self):\n        connection = get_connection_copy()\n        connection.settings_dict['NAME'] = 'test_db'\n        signature = connection.creation.test_db_signature()\n        self.assertEqual(signature, (\n            connection.settings_dict['HOST'],\n            connection.settings_dict['PORT'],\n            connection.settings_dict['ENGINE'],\n            'test_db',\n        ))\n"], "sample_988": ["    def test_sympify_complex():\n        assert sympify(1 + 2j) == S.One + 2*S.ImaginaryUnit\n        assert sympify(1.23 + 4.56j) == S.One + 2*S.ImaginaryUnit\n        assert sympify(complex(1, 2)) == S.One + 2*S.ImaginaryUnit\n        assert sympify(complex(1.23, 4.56)) == S.One + 2*S.ImaginaryUnit\n        assert sympify(0j) == 0*S.ImaginaryUnit\n        assert sympify(-1j) == -S.ImaginaryUnit\n        assert sympify(complex(0, 0)) == 0*S.ImaginaryUnit\n"], "sample_142": ["    def test_system_checks_admin_checks(self):\n        site = AdminSite()\n        site.register(Song, MyAdmin)\n        checks_result = checks.run_checks(site)\n        self.assertEqual(len(checks_result), 1)\n        self.assertEqual(checks_result[0].id, 'admin.W001')\n        self.assertEqual(checks_result[0].msg, 'error!')\n"], "sample_914": ["compilation error"], "sample_589": ["    def test_interp_nan(self, da, frac_nan, non_uniform):\n        da, df = make_interpolate_example_data((10, 10), frac_nan, non_uniform=non_uniform)\n        interp_da = da.interp(\n            x=da.x.values,\n            method=\"linear\",\n            limit=2,\n            fill_value=np.nan,\n        )\n        assert_array_equal(interp_da.values, da.values)\n"], "sample_871": ["    def test_silhouette_score_sparse_matrix():\n        X = csr_matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n        labels = np.array([0, 1, 0])\n        score = silhouette_score(X, labels, metric=\"precomputed\")\n        assert np.isclose(score, 0.5773502691896257)\n"], "sample_48": ["    def test_aggregate_with_filter(self):\n        with self.assertNumQueries(1):\n            result = Book.objects.filter(rating__gt=4).annotate(\n                avg_rating=Avg('rating')\n            ).values('avg_rating')\n        self.assertEqual(result[0]['avg_rating'], 4.375)\n\n        with self.assertNumQueries(1):\n            result = Book.objects.filter(rating__gt=4).annotate(\n                avg_rating=Avg('rating', filter=F('pages') > 300)\n            ).values('avg_rating')\n        self.assertEqual(result[0]['avg_rating'], 4.5)\n"], "sample_761": ["    def test_missing_indicator_missing_only_with_sparse_data(self):\n        X = sparse.csc_matrix(\n            [[1, 2, np.nan], [4, np.nan, 6], [7, 8, 9]])\n        indicator = MissingIndicator(features='missing-only', sparse='auto')\n        indicator.fit(X)\n        imputer_mask = indicator.transform(X)\n        expected_mask = sparse.csc_matrix(\n            [[False, False, True], [False, True, False], [False, False, False]])\n        assert_allclose_dense_sparse(imputer_mask, expected_mask)\n\n\n\n"], "sample_360": ["    def test_cache_middleware_with_vary_header(self):\n        request = HttpRequest()\n        request.COOKIES = {'some_cookie': 'value'}\n        response = HttpResponse()\n        response['Vary'] = 'Cookie'\n        response['Cache-Control'] = 'max-age=3600'\n\n        middleware = UpdateCacheMiddleware(lambda r: r)\n        middleware.process_response(request, response)\n\n        self.assertEqual(response['Cache-Control'], 'max-age=3600')\n        self.assertEqual(response['Vary'], 'Cookie')\n\n        request = HttpRequest()\n        request.COOKIES = {}\n        response = HttpResponse()\n        response['Vary'] = 'Cookie'\n        response['Cache-Control'] = 'max-age=3600'\n\n        middleware = UpdateCacheMiddleware(lambda r: r)\n        response = middleware.process_response(request, response)\n\n        self.assertEqual(response['Cache-Control'], 'max-age=3600')\n        self.assertEqual(response['Vary'], 'Cookie')\n"], "sample_1004": ["    def test_dummy_eq_different_base_sets(self):\n        c1 = ConditionSet(x, x < 1, {x, y})\n        c2 = ConditionSet(x, x < 1, {x, z})\n        assert c1.dummy_eq(c2)\n        c3 = ConditionSet(x, x < 1, {x, y, z})\n        assert c1.dummy_eq(c3)\n        c4 = ConditionSet(x, x > 1, {x, y})\n        assert not c1.dummy_eq(c4)\n"], "sample_640": ["def test_is_reserved_name(name: str, expected: bool) -> None:\n    assert utils.is_reserved_name(name) == expected\n\n\n"], "sample_394": ["    def test_admin_change_form_with_inline_formsets(self):\n        response = self.client.get(reverse(\"admin:article_change\", args=(self.a1.pk,)))\n        self.assertContentBefore(response, b\"Article 1\", b\"Article 2\")\n        response = self.client.post(\n            reverse(\"admin:article_change\", args=(self.a1.pk,)),\n            self.inline_post_data,\n            follow=True,\n        )\n        self.assertContentBefore(response, b\"Article 1\", b\"Article 2\")\n        self.assertContentBefore(response, b\"Norske bostaver \u00e6\u00f8\u00e5 skaper problemer\", b\"Need a title.\")\n        self.assertContentBefore(response, b\"Newest content\", b\"Oldest content\")\n\n        # Check that the inline forms are rendered correctly\n        fields = self.get_admin_form_fields(response)\n        self.assertIn(\"article_set\", [f.field[\"name\"] for f in fields])\n        self.assertEqual(len(fields), 6)\n        self.assertEqual(len(self.get_admin_readonly_fields(response)), 0)\n"], "sample_613": ["    def test_groupby_first_last(array, dataset):\n        # Test first and last along a dimension\n        grouped = array.groupby(\"x\")\n        first = grouped.first()\n        last = grouped.last()\n\n        assert_equal(first.dims, (\"y\", \"z\"))\n        assert_equal(last.dims, (\"y\", \"z\"))\n\n        # Check that the first and last values are correct\n        for i in range(3):\n            assert_allclose(first[\"foo\"][i, 0, 0], array[i, 0, 0])\n            assert_allclose(last[\"foo\"][i, 3, 1], array[i, 3, 1])\n"], "sample_617": ["    def test_unify_chunks_no_dask(array_type, expected_type):\n        if has_dask and dask_version.release < Version(\"2022.10\"):\n            pytest.skip(\n                \"dask.array.core.unify_chunks is not compatible with \"\n                f\"dask versions before 2022.10\"\n            )\n        a = array_type(np.arange(10))\n        b = array_type(np.arange(10))\n        result = unify_chunks(a, b)\n        assert isinstance(result[0], expected_type)\n        assert isinstance(result[1], expected_type)\n        assert_identical(result[0], a)\n        assert_identical(result[1], b)\n\n\n\n"], "sample_707": ["    def test_iterparentnodeids_root(self, testdir: Pytester) -> None:\n        p = testdir.makepyfile(\n            \"\"\"\n                pass\n            \"\"\"\n        )\n        p.chdir()\n        item = testdir.getitems()[0]\n        assert list(nodes.iterparentnodeids(item.nodeid)) == [\"\", \"\"]\n"], "sample_578": ["    def test_bar_edgewidth(self):\n        data = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [4, 5, 6]})\n        scales = {\"x\": {\"type\": \"continuous\", \"range\": (0, 4)}, \"y\": {\"type\": \"continuous\", \"range\": (0, 7)}}\n        variables = {\"data\": data, \"scales\": scales, \"orient\": \"x\"}\n        mark_kws = {\"width\": .5, \"baseline\": 0, \"edgewidth\": Mappable(1.5)}\n        layer_kws = {\"color\": \"red\"}\n        bars = self.plot_bars(**variables, **mark_kws, **layer_kws)\n        for bar in bars:\n            self.check_bar(bar, 1, 0, 0.5, 4)\n            assert bar.get_linewidth() == 1.5\n\n\n\n"], "sample_404": ["    def test_filter_expression_resolve(self):\n        c = Context({'article': {'section': 'News'}})\n        parser = self._engine().parse(\n            \"{{ article.section|default:'No section' }}\"\n        )\n        node = parser.nodelist[0]\n        output = node.render_annotated(c)\n        self.assertEqual(output, 'News')\n\n        c = Context({'article': {'section': None}})\n        output = node.render_annotated(c)\n        self.assertEqual(output, 'No section')\n\n        parser = self._engine().parse(\n            \"{{ article.section|default:'No section'|upper }}\"\n        )\n        node = parser.nodelist[0]\n        output = node.render_annotated(c)\n        self.assertEqual(output, 'NEWS')\n\n        parser = self._engine().parse(\n            \"{{ article.section|default:'No section'|upper|trim }}\"\n        )\n        node = parser.nodelist[0]\n        output = node.render_annotated(c)\n        self.assertEqual(output, 'NEWS')\n\n        parser = self._engine().parse(\n            \"{{ article.section|default:'No section'|upper|trim|default:'No section' }}\"\n        )\n        node = parser.nodelist[0]\n        output = node.render_annotated(c)\n        self.assertEqual(output, 'NEWS')\n\n        parser = self._engine().parse(\n            \"{{ article.section|default:'No section'|upper|trim|default:'No section'|upper }}\"\n        )\n        node = parser.nodelist[0]\n        output = node.render_annotated(c)\n        self.assertEqual(output, 'NEWS')\n\n\n\n"], "sample_628": ["    def test_ignore_words(self):\n        self.checker.config.spelling_ignore_words = \"param,pylint\"\n        code = \"\"\"\n            \"\"\"This is a docstring with pylint: disable=spelling\n            and a param.\"\"\"\n            pass\n        \"\"\"\n        tree = astroid.parse(code)\n        self.checker.visit_functiondef(tree.body[0])\n        messages = self.get_messages()\n        assert len(messages) == 0\n"], "sample_532": ["    def test_contourf_levels(self):\n        x = np.linspace(-5, 5, 100)\n        y = np.linspace(-5, 5, 100)\n        X, Y = np.meshgrid(x, y)\n        Z = np.sin(np.sqrt(X**2 + Y**2))\n        fig, ax = plt.subplots()\n        cs = ax.contourf(X, Y, Z, levels=[-0.8, -0.5, 0, 0.5, 0.8],\n                         cmap='viridis')\n        ax.set_title('Contourf with levels')\n        ax.set_xlabel('X')\n        ax.set_ylabel('Y')\n        plt.colorbar(cs)\n\n\n\n"], "sample_979": ["    def test_matrix_element_derivative():\n        M = MatrixSymbol('M', 3, 3)\n        e = MatrixElement(M, 1, 2)\n        dM_dx = diff(M[1, 2], x)\n        assert e.diff(x) == dM_dx\n"], "sample_275": ["    def test_delete_locking_with_select_for_update(self):\n        with transaction.atomic(using=self.conn2):\n            p1 = Person.objects.create(name='Person 1')\n            p2 = Person.objects.create(name='Person 2')\n\n            # Acquire a lock on Person 1 using SELECT FOR UPDATE\n            with self.conn2.cursor() as cursor:\n                cursor.execute(\"SELECT * FROM django_content_type WHERE name = %s FOR UPDATE\", ('Person',))\n                cursor.execute(\"SELECT * FROM django_auth_user WHERE username = %s\", ('admin',))\n                cursor.execute(\"SELECT * FROM django_auth_user WHERE username = %s\", ('admin',))\n\n            # Try to delete Person 1 from the first connection\n            with transaction.atomic():\n                try:\n                    Person.objects.filter(id=p1.id).delete()\n                    self.fail(\"Should have raised a deadlock exception\")\n                except Exception as e:\n                    self.assertIn(\"deadlock\", str(e))\n\n            # Commit the transaction on the second connection\n            self.conn2.commit()\n\n\n\n"], "sample_951": ["    def test_signature_from_ast_with_kw_defaults():\n        code = \"\"\""], "sample_392": ["    def test_key_transform_lookup_with_nested_keys(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\n                \"\"\"\n                INSERT INTO jsonmodel (id, data) VALUES\n                (1, '{\"a\": {\"b\": 1, \"c\": 2}}'),\n                (2, '{\"a\": {\"b\": 3, \"d\": 4}}')\n                \"\"\"\n            )\n\n        self.assertEqual(\n            JSONModel.objects.filter(data__a__b=1).count(), 1\n        )\n        self.assertEqual(\n            JSONModel.objects.filter(data__a__c=2).count(), 1\n        )\n        self.assertEqual(\n            JSONModel.objects.filter(data__a__d=4).count(), 1\n        )\n\n        self.assertEqual(\n            JSONModel.objects.filter(\n                data__a__b__gt=2\n            ).count(),\n            1,\n        )\n        self.assertEqual(\n            JSONModel.objects.filter(\n                data__a__b__lte=2\n            ).count(),\n            1,\n        )\n\n        self.assertEqual(\n            JSONModel.objects.filter(\n                data__a__c__isnull=True\n            ).count(),\n            0,\n        )\n        self.assertEqual(\n            JSONModel.objects.filter(\n                data__a__d__isnull=True\n            ).count(),\n            0,\n        )\n\n        self.assertEqual(\n            JSONModel.objects.filter(\n                data__a__b__in=[1, 3]\n            ).count(),\n            2,\n        )\n        self.assertEqual(\n            JSONModel.objects.filter(\n                data__a__b__regex=\"^1\"\n            ).count(),\n            1,\n        )\n        self.assertEqual(\n            JSONModel.objects.filter(\n                data__a__b__startswith=\"1\"\n            ).count(),\n            1,\n        )\n        self.assertEqual(\n            JSONModel.objects.filter(\n                data__a__b__endswith=\"1\"\n            ).count(),\n            0,\n        )\n\n\n\n"], "sample_795": ["    def test_sparse_transformer(self):\n        estimator = SparseTransformer()\n        X = np.array([[1, 2], [3, 4]])\n        X_sparse = sp.csr_matrix(X)\n        estimator.fit_transform(X_sparse)\n        transformed_X = estimator.transform(X_sparse)\n        assert isinstance(transformed_X, sp.csr_matrix)\n        assert transformed_X.shape == X_sparse.shape\n\n\n\n"], "sample_799": ["    def test_validation_curve_with_single_fit_call_allowed(self):\n        estimator = MockEstimatorWithSingleFitCallAllowed(param=0.5)\n        param_name = 'param'\n        param_range = np.linspace(0.1, 0.9, 5)\n        X, y = make_classification(n_samples=100, n_features=20, random_state=42)\n        groups = np.array([0, 0, 1, 1, 2, 2, 3, 3, 4, 4])\n        scores = validation_curve(estimator, X, y, param_name, param_range,\n                                  groups=groups, cv=5, scoring='accuracy')\n        assert hasattr(estimator, 'fit_called_')\n        assert estimator.fit_called_\n\n\n\n"], "sample_1109": ["    def test_frac_complex_imaginary_part(self):\n        assert frac(I).evalf() == 1j\n        assert frac(2*I).evalf() == 2*I\n        assert frac(I + 2).evalf() == I\n        assert frac(2*I + 3).evalf() == 2*I\n"], "sample_1137": ["    def test_quantity_simplify_mixed_units():\n        from sympy.physics.units import meter, second, kilogram, newton\n        expr = 10*meter + 5*kilogram*meter/second**2\n        result = quantity_simplify(expr)\n        expected = 10*meter + 5*kilogram*meter/second**2\n        assert result == expected\n"], "sample_214": ["    def test_key_transform_lookup_with_nested_keys(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\n                'INSERT INTO jsonmodel (id, data) VALUES (%s, %s)',\n                [(uuid.uuid4(), {'a': {'b': 'value'}}),]\n            )\n            connection.commit()\n\n        qs = JSONModel.objects.filter(\n            data__json_contains={'a': {'b': 'value'}}\n        )\n        self.assertEqual(qs.count(), 1)\n\n        qs = JSONModel.objects.filter(\n            data__json_contains={'a': {'b': 'value'}}\n        )\n        self.assertEqual(qs.count(), 1)\n\n        qs = JSONModel.objects.filter(\n            data__json_contains={'a': {'b': 'value'}}\n        )\n        self.assertEqual(qs.count(), 1)\n\n        qs = JSONModel.objects.filter(\n            data__json_contains={'a': {'b': 'value'}}\n        )\n        self.assertEqual(qs.count(), 1)\n\n        qs = JSONModel.objects.filter(\n            data__json_contains={'a': {'b': 'value'}}\n        )\n        self.assertEqual(qs.count(), 1)\n\n        qs = JSONModel.objects.filter(\n            data__json_contains={'a': {'b': 'value'}}\n        )\n        self.assertEqual(qs.count(), 1)\n\n\n\n"], "sample_1194": ["    def test_sparse_matrix():\n        A = SparseMatrix([[1, 2, 0], [0, 0, 3], [4, 0, 0]])\n        code = julia_code(A)\n        assert code == \"sparse(1, 1, 1, 3, 3)\"\n\n\n\n"], "sample_965": ["    def test_signature_from_str_with_varargs_and_kwargs():\n        signature = \"(a, b, *args, **kwargs)\"\n        sig = inspect.signature_from_str(signature)\n        assert sig.parameters['a'].kind == inspect.Parameter.POSITIONAL_OR_KEYWORD\n        assert sig.parameters['b'].kind == inspect.Parameter.POSITIONAL_OR_KEYWORD\n        assert sig.parameters['args'].kind == inspect.Parameter.VAR_POSITIONAL\n        assert sig.parameters['kwargs'].kind == inspect.Parameter.VAR_KEYWORD\n"], "sample_97": ["    def test_iter_modules_and_files_with_zip_modules(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            zip_filename = self.temporary_file('my_module.zip')\n            with zipfile.ZipFile(zip_filename, 'w') as zf:\n                zf.write('__init__.py', arcname='my_module')\n                zf.write('module.py', arcname='my_module/module.py')\n            extend_sys_path([str(zip_filename)])\n            self.import_and_cleanup('my_module')\n            self.assertFileFound(zip_filename)\n            self.assertFileFound(zip_filename / 'my_module/module.py')\n            self.assertFileFound(zip_filename / '__init__.py')\n"], "sample_543": ["    def test_lasso(self, ax):\n        lasso = Lasso(ax, (0.2, 0.2), lambda verts: None)\n        click_and_drag(ax, (0.2, 0.2), (0.8, 0.8))\n        click_and_drag(ax, (0.8, 0.8), (0.2, 0.8))\n        click_and_drag(ax, (0.2, 0.8), (0.2, 0.2))\n        plt.close()\n\n\n\n"], "sample_1206": ["    def test_sympify_complex():\n        assert sympify(complex(1, 2)) == 1 + 2*I\n        assert sympify(complex(3.14, -1.618)) == 3.14 - 1.618*I\n        assert sympify(complex(0, 0)) == 0\n        assert sympify(complex(1, 0)) == 1\n        assert sympify(complex(-1, 0)) == -1\n    "], "sample_891": ["    def test_top_k_accuracy_score_multiclass(drop, normalize):\n        y_true, y_pred, y_score = make_prediction(binary=False)\n        k = 2\n        score = top_k_accuracy_score(y_true, y_score, k=k, normalize=normalize)\n        if normalize:\n            assert 0.5 <= score <= 1.0\n        else:\n            assert 0 <= score <= len(y_true)\n"], "sample_864": ["    def test_bin_seeding(self):\n        X = np.random.rand(100, 2)\n        bin_size = 0.2\n        seeds = get_bin_seeds(X, bin_size)\n        assert len(seeds) < len(X)\n        assert np.all(np.round(seeds / bin_size) == np.round(X / bin_size))\n"], "sample_408": ["    def test_migration_dependencies_circular(self):\n        before_states = self.make_project_state(\n            [\n                rabbit,\n                knight,\n            ]\n        )\n        after_states = self.make_project_state(\n            [\n                rabbit,\n                knight,\n            ]\n        )\n        changes = self.get_changes(before_states, after_states)\n        self.assertMigrationDependencies(\n            changes, \"eggs\", 0, [\"eggs.Knight\"]\n        )\n        self.assertMigrationDependencies(\n            changes, \"eggs\", 1, [\"eggs.Knight\"]\n        )\n\n\n\n"], "sample_616": ["    def test_unified_dim_sizes(array, dim, expected):\n        assert unified_dim_sizes(array, dim) == expected\n\n\n\n"], "sample_78": ["    def test_dance_command(self):\n        with captured_stderr() as stderr:\n            management.execute_from_command_line(['dance'])\n        self.assertIn('Dancing!', stderr.getvalue())\n"], "sample_829": ["    def test_incremental_pca_sparse_data(self):\n        X = sparse.csr_matrix(iris.data)\n        ipca = IncrementalPCA(n_components=2, batch_size=10)\n        ipca.fit(X)\n        X_transformed = ipca.transform(X)\n        pca = PCA(n_components=2)\n        X_transformed_dense = pca.fit_transform(iris.data)\n        assert_allclose_dense_sparse(X_transformed, X_transformed_dense)\n"], "sample_1167": ["    def test_multiline_latex_with_matrices(self):\n        from sympy.matrices import Matrix\n\n        A = Matrix([[1, 2], [3, 4]])\n        B = Matrix([[5, 6], [7, 8]])\n\n        expr = Eq(A + B, 2*A)\n        result = multiline_latex(expr, terms_per_line=2, environment=\"align*\")\n        expected = r'\\begin{align*}"], "sample_462": ["    def test_choice_field_empty_values(self):\n        field = ChoiceField(choices=[('a', 'A'), ('b', 'B')])\n        self.assertEqual(field.empty_values, ())\n\n        field = ChoiceField(choices=[('a', 'A'), ('b', 'B')], empty_value=\"\")\n        self.assertEqual(field.empty_values, ('',))\n\n        field = ChoiceField(choices=[('a', 'A'), ('b', 'B')], empty_value=\"None\")\n        self.assertEqual(field.empty_values, ('None',))\n\n        field = ChoiceField(choices=[('a', 'A'), ('b', 'B')], empty_value=[\"None\"])\n        self.assertEqual(field.empty_values, ('None',))\n"], "sample_1000": ["    def test_sparse_matrix(self):\n        A = SparseMatrix([[1, 2, 0], [0, 3, 4], [5, 0, 6]])\n        code = octave_code(A)\n        expected = \"sparse(1 2 0, 1 3 4 5, 6, 3, 3)\"\n        assert code == expected\n"], "sample_609": ["    def test_ordered_set_intersection_empty():\n        assert ordered_set_intersection(set(), set()) == set()\n        assert ordered_set_intersection(set(), {1, 2}) == set()\n        assert ordered_set_intersection({1, 2}, set()) == set()\n"], "sample_896": ["    def test_partial_fit_multiple_calls(self, Estimator, solver):\n        n_samples = 100\n        n_features = 50\n        n_components = 10\n        X = np.random.rand(n_samples, n_features)\n        X_train = X[:50]\n        X_test = X[50:]\n\n        estimator = Estimator(\n            n_components=n_components, solver=solver, random_state=0\n        )\n\n        # First call to partial_fit\n        estimator.partial_fit(X_train)\n\n        # Second call to partial_fit\n        estimator.partial_fit(X_test)\n\n        # Check if the model converged\n        with ignore_warnings(category=ConvergenceWarning):\n            W_train = estimator.transform(X_train)\n            W_test = estimator.transform(X_test)\n\n        assert_allclose(estimator.components_, estimator.components_)\n        assert_allclose(W_train, estimator.transform(X_train))\n        assert_allclose(W_test, estimator.transform(X_test))\n"], "sample_110": ["    def test_window_expressions(self):\n        with self.subTest('simple'):\n            events = Event.objects.annotate(\n                running_total=Window(\n                    expression=Value('count(*)'),\n                    partition_by=['group'],\n                    order_by=['timestamp'],\n                )\n            ).values('group', 'timestamp', 'running_total')\n            self.assert_pickles(events)\n\n        with self.subTest('frame'):\n            events = Event.objects.annotate(\n                running_total=Window(\n                    expression=Value('count(*)'),\n                    partition_by=['group'],\n                    order_by=['timestamp'],\n                    frame=RowRange(start=1, end=2),\n                )\n            ).values('group', 'timestamp', 'running_total')\n            self.assert_pickles(events)\n"], "sample_565": ["    def test_inset_axes_basic(self):\n        fig, ax = plt.subplots(1, 1)\n        ax_ins = inset_axes(ax, width=0.4, height=0.4, loc='upper right')\n        ax_ins.plot([1, 2, 3], [4, 5, 6])\n        plt.show()\n"], "sample_665": ["    def test_showfixtures(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n                pass\n            \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"*fixtures defined from <module 'test_fixtures'.*\",\n                \"*test_one -- test_fixtures.py:1\",\n            ]\n        )\n        result = testdir.runpytest(\"--showfixtures\")\n        result.stdout.fnmatch_lines(\n            [\n                \"*fixtures defined from <module 'test_fixtures'.*\",\n                \"*test_one -- test_fixtures.py:1\",\n            ]\n        )\n"], "sample_139": ["    def test_changelist_template_context(self):\n        # Test that the changelist template context contains the expected data.\n        response = self._mocked_authenticated_request(reverse('admin:parent_changelist'), self.superuser)\n        self.assertEqual(response.status_code, 200)\n        context = response.context\n        self.assertIn('title', context)\n        self.assertEqual(context['title'], 'Parent list')\n        self.assertIn('object_list', context)\n        self.assertIsInstance(context['object_list'], list)\n        self.assertIn('is_popup', context)\n        self.assertFalse(context['is_popup'])\n        self.assertIn('to_field', context)\n        self.assertIsNone(context['to_field'])\n        self.assertIn('media', context)\n        self.assertIsInstance(context['media'], forms.Media)\n        self.assertIn('preserved_filters', context)\n        self.assertIsInstance(context['preserved_filters'], dict)\n\n\n\n"], "sample_1001": ["    def test_latex_special_functions(self):\n        self.assertEqual(latex(Chi(x)), r\"\\chi{\\left (x \\right )}\")\n        self.assertEqual(latex(Ci(x)), r\"\\operatorname{Ci}{\\left (x \\right )}\")\n        self.assertEqual(latex(Ei(x)), r\"\\operatorname{Ei}{\\left (x \\right )}\")\n        self.assertEqual(latex(Shi(x)), r\"\\operatorname{Shi}{\\left (x \\right )}\")\n        self.assertEqual(latex(Si(x)), r\"\\operatorname{Si}{\\left (x \\right )}\")\n        self.assertEqual(latex(Zeta(x)), r\"\\zeta{\\left (x \\right )}\")\n        self.assertEqual(latex(lowergamma(x)), r\"\\Gamma{\\left (x \\right )}\")\n        self.assertEqual(latex(uppergamma(x)), r\"\\Gamma{\\left (x \\right )}\")\n        self.assertEqual(latex(erfi(x)), r\"\\operatorname{erfi}{\\left (x \\right )}\")\n        self.assertEqual(latex(erfc(x)), r\"\\operatorname{erfc}{\\left (x \\right )}\")\n        self.assertEqual(latex(polylog(2, x)), r\"\\operatorname{Li}_{2}{\\left (x \\right )}\")\n        self.assertEqual(latex(meijerg(x, y)), r\"\\operatorname{MeijerG}{\\left (x, y \\right )}\")\n        self.assertEqual(latex(gamma(x)), r\"\\Gamma{\\left (x \\right )}\")\n        self.assertEqual(latex(beta(x, y)), r\"\\operatorname{B}{\\left (x, y \\right )}\")\n        self.assertEqual(latex(catalan(x)), r\"\\operatorname{Catalan}{\\left (x \\right )}\")\n        self.assertEqual(latex(binomial(x, y)), r\"\\binom{x}{y}\")\n        self.assertEqual(latex(factorial(x)), r\"\\operatorname{factorial}{\\left (x \\right )}\")\n        self.assertEqual(latex(factorial2(x)), r\"\\operatorname{factorial2}{\\left (x \\right )}\")\n        self.assertEqual(latex(subfactorial(x)), r\"\\operatorname{subfactorial}{\\left (x \\right )}\")\n        self.assertEqual"], "sample_202": ["    def test_cookie_storage_max_size(self):\n        storage = self.storage_class()\n        messages = [\n            Message(constants.INFO, 'Message 1'),\n            Message(constants.INFO, 'Message 2'),\n            Message(constants.INFO, 'Message 3'),\n            Message(constants.INFO, 'Message 4'),\n            Message(constants.INFO, 'Message 5'),\n            Message(constants.INFO, 'Message 6'),\n            Message(constants.INFO, 'Message 7'),\n            Message(constants.INFO, 'Message 8'),\n            Message(constants.INFO, 'Message 9'),\n            Message(constants.INFO, 'Message 10'),\n        ]\n        response = self.get_response()\n\n        # Store the messages, which should exceed the max_cookie_size\n        unstored_messages = storage._store(messages, response, remove_oldest=True)\n        self.assertEqual(len(unstored_messages), 1)\n\n        # Check that the cookie contains the expected number of messages\n        self.assertEqual(self.stored_messages_count(storage, response), 9)\n\n        # Check that the oldest message was removed\n        self.assertEqual(unstored_messages[0].message, 'Message 1')\n\n        # Check that the cookie is still valid\n        decoded_messages = storage._decode(response.cookies[storage.cookie_name].value)\n        self.assertEqual(len(decoded_messages), 9)\n\n\n\n"], "sample_576": ["    def test_init_defaults(self):\n        p = Plot(data=Default(), mark=MockMark(), scales=Default())\n        assert p._subplots == []\n        assert p._legend_contents == []\n        assert p._scales == {}\n        assert p._limits == {}\n\n\n\n"], "sample_785": ["    def test_shuffle_split_with_groups(self):\n        X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n        y = np.array([0, 0, 1, 1])\n        groups = np.array([0, 0, 1, 1])\n        n_samples = len(X)\n        n_test = int(n_samples * 0.25)\n\n        cv = ShuffleSplit(n_splits=5, test_size=0.25, random_state=42)\n        for train_index, test_index in cv.split(X, y, groups):\n            assert len(np.unique(groups[train_index])) == 2\n            assert len(np.unique(groups[test_index])) == 2\n"], "sample_544": ["    def test_image_interpolation_with_non_uniform_data(self):\n        # Test interpolation with non-uniform data\n        x = np.array([0, 1, 2, 3, 4])\n        y = np.array([0, 1, 2, 3, 4])\n        data = np.array([[1, 2, 3, 4, 5],\n                         [6, 7, 8, 9, 10],\n                         [11, 12, 13, 14, 15]])\n\n        fig, ax = plt.subplots()\n        im = NonUniformImage(ax, x, y, data, interpolation='nearest')\n        im.set_clim(0, 15)\n        plt.show()\n"], "sample_934": ["compilation error"], "sample_957": ["    def test_restify_typing_union(self):\n        assert restify(Union[int, str]) == 'Union[int, str]'\n        assert restify(Union[int, str, None]) == 'Union[int, str, None]'\n        assert restify(Union[int, None]) == 'Optional[int]'\n        assert restify(Union[MyInt, str]) == 'Union[MyInt, str]'\n        assert restify(Union[MyInt, str, None]) == 'Union[MyInt, str, None]'\n        assert restify(Union[MyInt, None]) == 'Optional[MyInt]'\n        assert restify(Union[MyList[int], MyList[str]]) == 'Union[List[int], List[str]]'\n        assert restify(Union[MyList[int], MyList[str], None]) == 'Union[List[int], List[str], None]'\n        assert restify(Union[MyList[int], None]) == 'Optional[List[int]]'\n\n\n\n"], "sample_245": ["    def test_no_translation_files(self):\n        with self.tmp_dir() as tmpdir:\n            self.copy_template_files(tmpdir)\n            with captured_stdout() as stdout:\n                execute_from_command_line(['django-admin', 'makemessages', '--locale', LOCALE, '--no-default-ignore', '--no-wrap', '--no-location', '--no-obsolete', '--keep-pot', tmpdir])\n            self.assertFalse(os.path.exists(self.PO_FILE))\n            self.assertTrue(os.path.exists(os.path.join(tmpdir, 'locale', LOCALE, 'LC_MESSAGES', 'django.pot')))\n            self.assertEqual(stdout.getvalue(), '')\n\n\n\n"], "sample_726": ["    def test_multilabel_binarizer_sparse_output(self):\n        mlb = MultiLabelBinarizer(sparse_output=True)\n        y = [[1, 2], [3, 4]]\n        y_bin = mlb.fit_transform(y)\n        assert isinstance(y_bin, csr_matrix)\n        assert y_bin.shape == (2, 4)\n\n        mlb = MultiLabelBinarizer(sparse_output=True)\n        y = [[1, 2], [3, 4]]\n        y_bin = mlb.fit_transform(y)\n        assert isinstance(y_bin, csr_matrix)\n        assert y_bin.shape == (2, 4)\n\n        mlb = MultiLabelBinarizer(sparse_output=True)\n        y = [[1, 2], [3, 4]]\n        y_bin = mlb.fit_transform(y)\n        assert isinstance(y_bin, csr_matrix)\n        assert y_bin.shape == (2, 4)\n"], "sample_167": ["    def test_naturaltime_future_day(self):\n        with override_settings(USE_TZ=True):\n            tz = get_fixed_timezone(timedelta(hours=5))\n            now = MockDateTime.now(tz)\n            future_day = now + datetime.timedelta(days=1)\n            self.assertEqual(humanize.naturaltime(future_day), '1 day from now')\n"], "sample_827": ["    def test_inplace_swap_row_csc_large(self):\n        n_samples = 1000\n        n_features = 500\n        X = sp.csc_matrix((np.random.rand(n_samples * n_features),\n                           (np.random.randint(0, n_features, n_samples),\n                            np.random.randint(0, n_samples, n_features))),\n                          shape=(n_samples, n_features))\n        m = np.random.randint(0, n_samples)\n        n = np.random.randint(0, n_samples)\n        inplace_swap_row(X, m, n)\n        X_ref = sp.csc_matrix(X.copy())\n        X_ref[m, :] = X_ref[n, :]\n        X_ref[n, :] = X[m, :]\n        assert_array_equal(X.toarray(), X_ref.toarray())\n"], "sample_945": ["    def test_parse_annotation(self):\n        assert _parse_annotation('int') == 'int'\n        assert _parse_annotation('int: str') == 'int: str'\n        assert _parse_annotation('int, str') == 'int, str'\n        assert _parse_annotation('int -> str') == 'int -> str'\n        assert _parse_annotation('int -> None') == 'int -> None'\n        assert _parse_annotation('int -> list[str]') == 'int -> list[str]'\n        assert _parse_annotation('int -> typing.List[str]') == 'int -> typing.List[str]'\n        assert _parse_annotation('int -> Optional[str]') == 'int -> Optional[str]'\n        assert _parse_annotation('int -> Union[str, int]') == 'int -> Union[str, int]'\n        assert _parse_annotation('int -> Tuple[str, int]') == 'int -> Tuple[str, int]'\n\n\n\n"], "sample_702": ["    def test_testdir_run_python_c(self, testdir):\n        \"\"\"Test runpython_c with a simple command.\"\"\"\n        testdir.makepyfile(\"\"\"\n            assert 1 == 1\n        \"\"\")\n        result = testdir.runpython_c(\"import test_module; test_module.test_func()\")\n        assert result.ret == 0\n        assert \"test_func\" in result.out\n\n\n\n"], "sample_451": ["    def test_parse_docstring(self):\n        title, body, metadata = parse_docstring(self.docstring)\n        self.assertEqual(title, \"This __doc__ output is required for testing. I copied this example from admindocs documentation.\")\n        self.assertEqual(\n            body,\n            \"Display an individual :model:`myapp.MyModel`. \\n\\n**Context**\\n\\n``RequestContext``\\n\\n``mymodel``\\n        An instance of :model:`myapp.MyModel`. \\n\\n**Template:**\\n\\n:template:`myapp/my_template.html`\",\n        )\n        self.assertEqual(metadata, {\"some_metadata\": \"some data\"})\n"], "sample_787": ["    def test_brier_score_loss_with_sample_weight():\n        y_true = np.array([0, 1, 1, 0])\n        y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n        sample_weight = np.array([0.2, 0.5, 0.1, 0.2])\n        score = brier_score_loss(y_true, y_prob, sample_weight=sample_weight)\n        expected_score = 0.037\n        assert_almost_equal(score, expected_score)\n\n"], "sample_775": ["    def test_gridsearchcv(self):\n        grid = {'param1': [1, 2], 'param2': [3, 4]}\n        gs = GridSearchCV(LogisticRegression(), grid)\n        pp = _EstimatorPrettyPrinter(compact=True)\n        s = pp.pformat(gs)\n        self.assertIn('GridSearchCV(LogisticRegression()', s)\n        self.assertIn('param1=[1, 2], param2=[3, 4])', s)\n"], "sample_403": ["    def test_add_remove_constraint(self):\n        with atomic():\n            # Create a model with a constraint\n            self.create_model(\n                \"app\",\n                \"MyModel\",\n                fields=[\n                    models.CharField(max_length=100),\n                    models.ForeignKey(\"app.MyModel\", on_delete=models.CASCADE),\n                ],\n            )\n\n            # Add a constraint\n            with self.assertNumQueries(1):\n                self.migrate_forwards(\n                    [\n                        AddConstraint(\n                            \"app.MyModel\",\n                            models.UniqueConstraint(\n                                fields=[\"charfield\"],\n                                name=\"unique_charfield\",\n                            ),\n                        )\n                    ]\n                )\n\n            # Check that the constraint exists\n            with self.assertNumQueries(1):\n                with connection.cursor() as cursor:\n                    cursor.execute(\n                        \"SELECT constraint_name FROM information_schema.key_column_usage WHERE table_name = %s AND column_name = %s\",\n                        (\"mymodel\", \"charfield\"),\n                    )\n                    result = cursor.fetchone()\n                    self.assertEqual(result[0], \"unique_charfield\")\n\n            # Remove the constraint\n            with self.assertNumQueries(1):\n                self.migrate_backwards(\n                    [\n                        RemoveConstraint(\n                            \"app.MyModel\", \"unique_charfield\"\n                        )\n                    ]\n                )\n\n            # Check that the constraint is gone\n            with self.assertNumQueries(1):\n                with connection.cursor() as cursor:\n                    cursor.execute(\n                        \"SELECT constraint_name FROM information_schema.key_column_usage WHERE table_name = %s AND column_name = %s\",\n                        (\"mymodel\", \"charfield\"),\n                    )\n                    result = cursor.fetchone()\n                    self.assertIsNone(result)\n\n\n\n"], "sample_1155": ["compilation error"], "sample_1209": ["    def test_prefix_unit_binary():\n        from sympy.physics.units.quantities import Quantity\n        units = prefix_unit(meter, BIN_PREFIXES)\n        assert len(units) == 6\n        assert isinstance(units[0], Quantity)\n        assert units[0].name == 'kibi meter'\n        assert units[0].abbrev == 'Kibm'\n        assert units[0].scale_factor == kibi.scale_factor\n"], "sample_12": ["    def test_wrap_at_inplace(self):\n        a = Angle([10, 20, 30] * u.deg)\n        a_copy = a.copy()\n        a.wrap_at(180 * u.deg, inplace=True)\n        assert_array_equal(a.degree, np.array([-10, 20, 30]))\n        assert_array_equal(a_copy.degree, np.array([10, 20, 30]))\n"], "sample_1187": ["    def test_integration_reduction_dynamic_2d():\n        from sympy.integrals.intpoly import integration_reduction_dynamic\n        poly = Polygon(Point(0, 0), Point(1, 0), Point(1, 1), Point(0, 1))\n        expr = x**2 + y\n        result = integration_reduction_dynamic(poly, expr)\n        assert result == S(1/3) * (1**3) + S(1/2) * (1**2)\n"], "sample_1179": ["    def test_print_MatrixSymbol(self):\n        self.assertEqual(sstr(MatrixSymbol('A', 2, 3)), 'MatrixSymbol(\"A\", 2, 3)')\n        self.assertEqual(sstr(MatrixSymbol('B', 1, 1)), 'MatrixSymbol(\"B\", 1, 1)')\n        self.assertEqual(sstr(MatrixSymbol('C', 3)), 'MatrixSymbol(\"C\", 3)')\n"], "sample_203": ["    def test_email_validator_with_punycode(self):\n        validator = validators.EmailValidator()\n        self.assertRaises(ValidationError, validator, 'invalid.email')\n        self.assertRaises(ValidationError, validator, 'invalid@domain')\n        self.assertRaises(ValidationError, validator, 'invalid@domain.')\n        self.assertRaises(ValidationError, validator, 'invalid@domain..')\n        self.assertRaises(ValidationError, validator, 'invalid@domain.invalid')\n        self.assertRaises(ValidationError, validator, 'invalid@domain..invalid')\n        self.assertRaises(ValidationError, validator, 'invalid@domain.invalid.')\n        self.assertRaises(ValidationError, validator, 'invalid@domain..invalid.')\n\n        # Test with punycode domain\n        try:\n            validator('xn--invalid-domain.com')\n            self.fail('Expected ValidationError')\n        except ValidationError:\n            pass\n\n        # Test with valid punycode domain\n        validator('xn--p1ai')\n\n\n\n"], "sample_1196": ["    def test_contains_with_eq(self):\n        x = Symbol('x')\n        s = FiniteSet(x)\n        with raises(TypeError):\n            Contains(x, Eq(x, x))\n"], "sample_423": ["compilation error"], "sample_816": ["    def test_stop_words_with_vocabulary(self):\n        vectorizer = TfidfVectorizer(stop_words='english', vocabulary=['the', 'pizza', 'beer'])\n        X = vectorizer.fit_transform(JUNK_FOOD_DOCS)\n        assert_array_equal(vectorizer.get_feature_names(), ['the', 'pizza', 'beer'])\n        assert_array_equal(X.toarray(), [[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [0, 1, 1], [0, 1, 1]])\n\n"], "sample_663": ["    def test_collect_ignore_collect(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n                pass\n            \"\"\"\n        )\n        p.chdir()\n        # testdir.makepyfile(\n        #     \"\"\"\n        #     def test_two():\n        #         pass\n        #     \"\"\"\n        # )\n        # p.chdir()\n        # testdir.makepyfile(\n        #     \"\"\"\n        #     def test_three():\n        #         pass\n        #     \"\"\"\n        # )\n        # p.chdir()\n\n        # testdir.makepyfile(\n        #     \"\"\"\n        #     def test_four():\n        #         pass\n        #     \"\"\"\n        # )\n        # p.chdir()\n\n        # testdir.makepyfile(\n        #     \"\"\"\n        #     def test_five():\n        #         pass\n        #     \"\"\"\n        # )\n        # p.chdir()\n\n        # testdir.makepyfile(\n        #     \"\"\"\n        #     def test_six():\n        #         pass\n        #     \"\"\"\n        # )\n        # p.chdir()\n\n        # testdir.makepyfile(\n        #     \"\"\"\n        #     def test_seven():\n        #         pass\n        #     \"\"\"\n        # )\n        # p.chdir()\n\n        # testdir.makepyfile(\n        #     \"\"\"\n        #     def test_eight():\n        #         pass\n        #     \"\"\"\n        # )\n        # p.chdir()\n\n        # testdir.makepyfile(\n        #     \"\"\"\n        #     def test_nine():\n        #         pass\n        #     \"\"\"\n        # )\n        # p.chdir()\n\n        # testdir.makepyfile(\n        #     \"\"\"\n        #     def test_ten():\n        #         pass\n        #     \"\"\"\n        # )\n        # p.chdir()\n\n        # testdir.makepyfile(\n        #     \"\"\"\n        #     def test_eleven():\n        #         pass\n        #     \"\"\"\n        # )\n        # p.chdir()\n\n        # testdir.makepy"], "sample_337": ["    def test_rotate_token(self):\n        with override_settings(CSRF_COOKIE_NAME='csrf_cookie_test'):\n            request = HttpRequest()\n            request.method = 'POST'\n            request.META['HTTP_ORIGIN'] = 'https://example.com'\n            request.META['CSRF_COOKIE'] = MASKED_TEST_SECRET1\n            response = sandwiched_rotate_token_view(request)\n            self.assertEqual(response.status_code, 200)\n            self.assertIn('csrf_cookie_test', response.cookies)\n            self.assertNotEqual(request.META['CSRF_COOKIE'], MASKED_TEST_SECRET1)\n"], "sample_56": ["    def test_system_checks_admin_checks(self):\n        site = AdminSite()\n        site.register(Song, ValidFields)\n        site.register(Album, MyAdmin)\n        site.register(Book, admin.ModelAdmin)\n        site.register(Author, admin.ModelAdmin)\n        site.register(City, admin.ModelAdmin)\n        site.register(State, admin.ModelAdmin)\n        site.register(TwoAlbumFKAndAnE, admin.ModelAdmin)\n        site.register(Influence, admin.ModelAdmin)\n\n        errors = checks.run_checks(site)\n        self.assertEqual(len(errors), 1)\n        self.assertIn('error!', [error.msg for error in errors])\n\n\n\n"], "sample_681": ["    def test_log_file_handler(self, testdir: Testdir) -> None:\n        p = testdir.makepyfile(\n            \"\"\"\n            import logging\n\n            logging.basicConfig(level=logging.DEBUG)\n            logging.debug(\"This is a debug message\")\n            logging.info(\"This is an info message\")\n            logging.warning(\"This is a warning message\")\n            logging.error(\"This is an error message\")\n            logging.critical(\"This is a critical message\")\n            \"\"\"\n        )\n        result = testdir.runpytest(\n            \"-v\", \"--log-file=test.log\", \"--log-file-level=DEBUG\"\n        )\n        result.stdout.fnmatch_lines(\n            [\n                \"*DEBUG: This is a debug message*\",\n                \"*INFO: This is an info message*\",\n                \"*WARNING: This is a warning message*\",\n                \"*ERROR: This is an error message*\",\n                \"*CRITICAL: This is a critical message*\",\n            ]\n        )\n        assert os.path.exists(\"test.log\")\n        with open(\"test.log\", \"r\") as f:\n            log_content = f.read()\n        assert \"This is a debug message\" in log_content\n        assert \"This is an info message\" in log_content\n        assert \"This is a warning message\" in log_content\n        assert \"This is an error message\" in log_content\n        assert \"This is a critical message\" in log_content\n        os.remove(\"test.log\")\n\n\n\n"], "sample_285": ["    def test_check_finders_errors(self):\n        with override_settings(STATICFILES_FINDERS=['django.contrib.staticfiles.finders.FileSystemFinder',\n                                                     'django.contrib.staticfiles.finders.AppDirectoriesFinder']):\n            errors = check_finders(apps=self.apps)\n            self.assertEqual(len(errors), 0)\n\n        with override_settings(STATICFILES_FINDERS=['django.contrib.staticfiles.finders.FileSystemFinder',\n                                                     'nonexistent_finder']):\n            errors = check_finders(apps=self.apps)\n            self.assertEqual(len(errors), 1)\n            self.assertIn('Finder \"nonexistent_finder\" is not a subclass of \"django.contrib.staticfiles.finders.BaseFinder\"', str(errors[0]))\n\n        with override_settings(STATICFILES_FINDERS=['django.contrib.staticfiles.finders.FileSystemFinder',\n                                                     'django.contrib.staticfiles.finders.AppDirectoriesFinder',\n                                                     'django.contrib.staticfiles.finders.DefaultStorageFinder']):\n            errors = check_finders(apps=self.apps)\n            self.assertEqual(len(errors), 0)\n\n\n\n"], "sample_492": ["    def test_serialize_custom_types(self):\n        operation = custom_migration_operations.more_operations.CreateCustomModel(\n            name=\"CustomModel\",\n            fields=[\n                models.CharField(max_length=100),\n                models.DecimalField(max_digits=10, decimal_places=2),\n                models.FileField(upload_to=\"custom_uploads/\"),\n                models.ForeignKey(\n                    \"TestModel1\", on_delete=models.CASCADE, related_name=\"related_custom\"\n                ),\n                models.ManyToManyField(\"TestModel1\", related_name=\"related_custom_many\"),\n                models.EnumField(enum_type=TextEnum),\n                models.EnumField(enum_type=TextTranslatedEnum),\n                models.EnumField(enum_type=BinaryEnum),\n                models.EnumField(enum_type=IntEnum),\n                models.EnumField(enum_type=IntFlagEnum),\n                models.DecimalField(max_digits=10, decimal_places=2, default=Money(10.50)),\n            ],\n        )\n        writer = OperationWriter(operation)\n        output, imports = writer.serialize()\n        self.assertIn(\"CustomModel\", output)\n        self.assertIn(\"CharField\", output)\n        self.assertIn(\"DecimalField\", output)\n        self.assertIn(\"FileField\", output)\n        self.assertIn(\"ForeignKey\", output)\n        self.assertIn(\"ManyToManyField\", output)\n        self.assertIn(\"EnumField\", output)\n        self.assertIn(\"TestModel1\", output)\n        self.assertIn(\"custom_uploads/\", output)\n        self.assertIn(\"from custom_migration_operations.more_operations import CreateCustomModel\", imports)\n        self.assertIn(\"from django.db import models\", imports)\n"], "sample_255": ["    def test_handle_request_with_content_length(self):\n        request = self.request_factory.get('/')\n        request.META['CONTENT_LENGTH'] = '10'\n        environ = request.get_environ()\n        handler = WSGIRequestHandler(\n            Stub(rfile=BytesIO(b'test'), wfile=Stub(), get_stderr=lambda: Stub()),\n            environ,\n        )\n        handler.handle()\n        self.assertEqual(handler.get_environ()['CONTENT_LENGTH'], '10')\n"], "sample_824": ["    def test_pairwise_distances_chunked_reduce_func(self, metric):\n        X = np.random.rand(100, 3)\n        Y = np.random.rand(100, 3)\n\n            return np.mean(D_chunk, axis=1)\n\n        gen = pairwise_distances_chunked(X, Y, reduce_func=reduce_func,\n                                         metric=metric)\n        for i in range(10):\n            chunk = next(gen)\n            assert isinstance(chunk, np.ndarray)\n            assert chunk.shape[0] == 10\n"], "sample_1024": ["    def test_sympify_mpmath_complex():\n        z = mpmath.complex(1, 2)\n        assert sympify_mpmath(z) == 1 + 2*I\n"], "sample_434": ["    def test_view_method_names(self):\n        class MyView(View):\n            http_method_names = [\"get\", \"post\"]\n\n        view = MyView()\n        self.assertEqual(view.http_method_names, [\"get\", \"post\"])\n\n        with self.assertRaises(ImproperlyConfigured):\n            class BadView(View):\n                http_method_names = [\"get\", \"post\", \"invalid\"]\n\n        with self.assertRaises(ImproperlyConfigured):\n            class AsyncBadView(View):\n                http_method_names = [\"get\", \"post\", \"invalid\"]\n                async def get(self, request):\n                    return HttpResponse(\"Hello\")\n"], "sample_219": ["    def test_raw_sql(self):\n        raw_sql = RawSQL(\n            'SELECT name, num_employees FROM companies WHERE num_employees > 10',\n            [],\n        )\n        result = list(raw_sql.as_sql(compiler=connection.compiler))\n        self.assertEqual(result, [\n            ('Example Inc.', 2300),\n        ])\n"], "sample_476": ["    def test_imagefield_file_delete(self):\n        instance = self.PersonModel.objects.create(mugshot=self.file1)\n        self.check_dimensions(instance, 4, 8)\n        instance.mugshot.delete()\n        self.assertFalse(instance.mugshot)\n        self.assertIsNone(getattr(instance, \"mugshot_width\"))\n        self.assertIsNone(getattr(instance, \"mugshot_height\"))\n"], "sample_606": ["    def test_ordered_set_intersection_empty(\n        ):\n        assert ordered_set_intersection(set(), set()) == set()\n        assert ordered_set_intersection(set(), {1, 2}) == set()\n        assert ordered_set_intersection({1, 2}, set()) == set()\n"], "sample_883": ["    def test_ard_regression_scores(self, compute_score):\n        X, y = diabetes.data, diabetes.target\n        rng = check_random_state(0)\n        X_train = X[:100]\n        y_train = y[:100]\n        X_test = X[100:]\n        y_test = y[100:]\n\n        clf = ARDRegression(compute_score=compute_score)\n        clf.fit(X_train, y_train)\n\n        if compute_score:\n            assert len(clf.scores_) > 0\n\n        y_pred = clf.predict(X_test)\n        assert_array_almost_equal(y_pred, clf.predict(X_test))\n"], "sample_693": ["compilation error"], "sample_100": ["    def test_iter_all_python_module_files_with_zip_modules(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_filename = self.temporary_file('my_module.zip')\n            with zipfile.ZipFile(zip_filename, 'w') as zf:\n                zf.write('__init__.py', arcname='my_module')\n                zf.write('module.py', arcname='my_module/module.py')\n            extend_sys_path([tempdir])\n            self.import_and_cleanup('my_module')\n            self.assertFileFound(zip_filename)\n            self.assertFileFound(zip_filename / 'my_module' / '__init__.py')\n            self.assertFileFound(zip_filename / 'my_module' / 'module.py')\n            \n            # Test that the zip file is not included in the list of files\n            # when it's not a module.\n            self.assertNotIn(zip_filename, list(autoreload.iter_all_python_module_files()))\n\n\n\n"], "sample_231": ["    def test_callable_setting_wrapper_calls_callable(self):\n            return 'called'\n\n        wrapped = CallableSettingWrapper(callable_setting)\n        self.assertEqual(wrapped(), 'called')\n"], "sample_266": ["    def test_inconsistent_history(self):\n        with override_settings(DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3'}, 'other': {'ENGINE': 'django.db.backends.sqlite3'}}):\n            for db_name in self.databases:\n                connection = connections[db_name]\n                with connection.schema_editor() as schema_editor:\n                    schema_editor.execute(\"CREATE TABLE test_table (id INTEGER PRIMARY KEY)\")\n                loader = MigrationLoader(connection)\n                loader.build_graph()\n                recorder = MigrationRecorder(connection)\n                recorder.record_migration('app1', '0001_initial')\n                loader.check_consistent_history(connection)\n                with self.assertRaises(InconsistentMigrationHistory):\n                    recorder.record_migration('app1', '0002_another')\n"], "sample_111": ["    def test_get_ordering_field_columns(self):\n        admin.site.unregister(Parent)\n        admin.site.register(Parent, ParentAdmin)\n        admin.site.register(Child, ChildAdmin)\n\n        request = self._mocked_authenticated_request(reverse('admin:parent_changelist'), self.superuser)\n        changelist = ChangeList(request, Parent, ParentAdmin.list_display, ParentAdmin.list_display_links,\n                                ParentAdmin.list_filter, ParentAdmin.date_hierarchy, ParentAdmin.search_fields,\n                                ParentAdmin.list_select_related, ParentAdmin.list_per_page,\n                                ParentAdmin.list_max_show_all, ParentAdmin.list_editable, ParentAdmin,\n                                ParentAdmin.sortable_by)\n        ordering_fields = changelist.get_ordering_field_columns()\n        self.assertEqual(ordering_fields, {'0': 'asc'})\n\n        request = self._mocked_authenticated_request(reverse('admin:parent_changelist') + '?%s=name-id' % ORDER_VAR, self.superuser)\n        changelist = ChangeList(request, Parent, ParentAdmin.list_display, ParentAdmin.list_display_links,\n                                ParentAdmin.list_filter, ParentAdmin.date_hierarchy, ParentAdmin.search_fields,\n                                ParentAdmin.list_select_related, ParentAdmin.list_per_page,\n                                ParentAdmin.list_max_show_all, ParentAdmin.list_editable, ParentAdmin,\n                                ParentAdmin.sortable_by)\n        ordering_fields = changelist.get_ordering_field_columns()\n        self.assertEqual(ordering_fields, {'0': 'desc', '1': 'asc'})\n"], "sample_530": ["    def test_offsetbox_clipping(self):\n        fig, ax = plt.subplots()\n        ax.set_xlim(0, 10)\n        ax.set_ylim(0, 10)\n\n        bbox = AnchoredOffsetbox(\n            loc='upper right', pad=0.4, borderpad=0.5,\n            child=mpatches.Rectangle((0, 0), 1, 1, facecolor='red'),\n            bbox_to_anchor=(1.2, 1.2),\n            bbox_transform=ax.transAxes)\n        bbox.draw(ax.figure.canvas.get_renderer())\n\n        # Check that the bbox is clipped outside the axes\n        bbox.set_annotation_clip(True)\n        bbox.draw(ax.figure.canvas.get_renderer())\n\n        bbox.set_annotation_clip(False)\n        bbox.draw(ax.figure.canvas.get_renderer())\n\n        bbox.set_annotation_clip(None)\n        bbox.draw(ax.figure.canvas.get_renderer())\n"], "sample_314": ["    def test_password_validation(self):\n        form = UserCreationForm(data={'username': 'testuser', 'password1': 'password', 'password2': 'wrongpassword'})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors['password2'], [self.error_messages['password_mismatch']])\n\n        form = UserCreationForm(data={'username': 'testuser', 'password1': 'password', 'password2': 'password'})\n        self.assertTrue(form.is_valid())\n"], "sample_766": ["    def test_sparse_coder_transform(self):\n        dl = DictionaryLearning(n_components=3, random_state=0)\n        dl.fit(X)\n        sparse_coder = SparseCoder(dictionary=dl.components_)\n        code = sparse_coder.transform(X)\n        assert_array_almost_equal(sparse_coder.transform(X), code)\n        assert code.shape[1] == 3\n"], "sample_620": ["    def test_concat_coords_different_with_compat(\n        self, compat: str, expected_error: type[Exception] | None"], "sample_932": ["    def test_template_param_in_qualified_name(self):\n        input = \"template <typename T> struct S { };\"\n        output = \"template <typename T> struct S { };\"\n        idDict = {1: \"S\", 2: \"S.T\"}\n        check(\n            \"struct\",\n            input,\n            idDict,\n            output,\n            key=\"S\",\n            asTextOutput=\"template <typename T> struct S { }\"\n        )\n"], "sample_666": ["    def test_capture_manager_with_disabled_capture(self, method):\n        capture_manager = CaptureManager(\n            config=pytest.config,\n            capture_method=method,\n            global_capture=False,\n            fixture_capture=False,\n        )\n        with capture_manager.global_and_fixture_disabled():\n            with capture.CaptureOutput() as captured:\n                print(\"This should not be captured\")\n        assert captured.out == \"\"\n        assert captured.err == \"\"\n"], "sample_943": ["    def test_exclude_private_modules(apidoc):\n        coderoot, outdir = apidoc\n        assert (outdir / 'private_module.rst').exists() is False\n"], "sample_91": ["    def test_permission_denied_with_custom_template(self):\n        request = self.request_factory.get('/nonexistent_url/')\n        response = permission_denied(request, exception=Exception('Permission denied!'))\n        self.assertEqual(response.status_code, 403)\n        self.assertTemplateUsed(response, '403.html')\n"], "sample_660": ["    def test_double_fail_report(self, testdir):\n        result, report = runandparse(testdir, \"-v\", \"--junitxml=junit.xml\")\n        assert result.ret == 0\n        assert report.find_first_by_tag(\"testcase\").get_unique_child.tag == \"failure\"\n        assert report.find_first_by_tag(\"testcase\").get_unique_child.text == \"test teardown failure\"\n        assert report.find_first_by_tag(\"testcase\").get_unique_child.find_first_by_tag(\"message\").text == \"test teardown failure\"\n\n"], "sample_475": ["    def test_check_date_hierarchy_invalid(self):\n        class MyAdmin(ModelAdmin):\n            date_hierarchy = \"non_existent_field\"\n\n        self.assertIsInvalid(\n            MyAdmin, ValidationTestModel,\n            \"The value of 'date_hierarchy' refers to 'non_existent_field', which does not refer to a Field.\"\n        )\n"], "sample_5": ["    def test_model_bounding_box(model):\n        model_class = model['class']\n        params = model['parameters']\n        if 'bounding_box' in model:\n            bounding_box = model['bounding_box']\n        else:\n            bounding_box = None\n        \n        model_instance = model_class(**params)\n        if bounding_box is not None:\n            assert isinstance(bounding_box, ModelBoundingBox)\n            assert model_instance.bounding_box is not None\n            assert model_instance.bounding_box.lower_bounds == bounding_box.lower_bounds\n            assert model_instance.bounding_box.upper_bounds == bounding_box.upper_bounds\n        else:\n            assert model_instance.bounding_box is None\n"], "sample_376": ["    def test_encode_decode_with_safestring(self):\n        message = Message(constants.INFO, mark_safe('<b>Safe Data</b>'))\n        encoded = self.storage_class._encode([message])\n        decoded = self.storage_class._decode(encoded)\n        self.assertEqual(decoded[0].message, '<b>Safe Data</b>')\n        self.assertIsInstance(decoded[0].message, SafeData)\n"], "sample_599": ["    def test_cf_scale_offset_coder_roundtrip(self):\n        data = np.array([1, 2, 3], dtype=np.float32)\n        scale_factor = 2.0\n        add_offset = 1.5\n        attrs = {\"scale_factor\": scale_factor, \"add_offset\": add_offset}\n        var = xr.Variable((\"x\",), data, attrs=attrs)\n\n        encoded_var = encode_cf_variable(var)\n        decoded_var = decode_cf_variable(encoded_var)\n\n        assert_allclose(decoded_var.data, data * scale_factor + add_offset)\n        assert_equal(decoded_var.attrs[\"scale_factor\"], scale_factor)\n        assert_equal(decoded_var.attrs[\"add_offset\"], add_offset)\n\n"], "sample_682": ["    def test_skip_marks(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n                pass\n            \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*::test_me PASSED*\"])\n\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skip(reason=\"skip me\")\n                pass\n            \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*::test_me SKIPPED*\"])\n\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(sys.platform == 'win32', reason=\"skip on windows\")\n                pass\n            \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*::test_me SKIPPED*\"])\n\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.skipif(sys.platform == 'win32', reason=\"skip on windows\")\n                pass\n            \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*::test_me SKIPPED*\"])\n"], "sample_468": ["    def test_request_context_processors(self):\n        request = HttpRequest()\n        engine = Engine()\n        engine.template_context_processors = [\n            lambda r: {\"processor1\": \"value1\"},\n            lambda r: {\"processor2\": \"value2\"},\n        ]\n\n        context = RequestContext(request, engine=engine)\n\n        self.assertEqual(context[\"processor1\"], \"value1\")\n        self.assertEqual(context[\"processor2\"], \"value2\")\n\n        # Test that context processors are removed after rendering\n        with context.bind_template(Template(\"dummy\")):\n            pass\n        self.assertFalse(\"processor1\" in context)\n        self.assertFalse(\"processor2\" in context)\n\n\n\n"], "sample_503": ["compilation error"], "sample_212": ["    def test_session_middleware_save_every_request(self):\n        # Test that the session is saved every request when settings.SESSION_SAVE_EVERY_REQUEST is True\n        settings.SESSION_SAVE_EVERY_REQUEST = True\n        with self.settings(SESSION_SAVE_EVERY_REQUEST=True):\n            request = HttpRequest()\n            response = HttpResponse()\n            middleware = SessionMiddleware()\n            middleware.process_request(request)\n            middleware.process_response(request, response)\n            # Assert that the session was saved\n            self.assertTrue(request.session.modified)\n"], "sample_82": ["    def test_value_from_datadict_with_empty_values(self):\n        data = {\n            'date_year': '',\n            'date_month': '',\n            'date_day': '',\n        }\n        form = Form({'date': DateField()})\n        self.assertIsNone(self.widget.value_from_datadict(data, {}, 'date'))\n"], "sample_796": ["compilation error"], "sample_1121": ["    def test_as_content_primitive_with_sqrt():\n        from sympy import sqrt\n        expr = 2*sqrt(2)*(3 - 2*sqrt(2))\n        r, res = expr.as_content_primitive(radical=True)\n        assert r == 6\n        assert res == -sqrt(2)*(1 - sqrt(2))\n"], "sample_813": ["    def test_ard_regression_with_threshold(self):\n        X, y = diabetes.data, diabetes.target\n        n_samples, n_features = X.shape\n        # Create an ARDRegression model with a low threshold_lambda\n        # to ensure some weights are pruned\n        ard_reg = ARDRegression(threshold_lambda=1e-4)\n        ard_reg.fit(X, y)\n        # Check that the number of non-zero weights is less than the original\n        # number of features\n        assert_array_less(np.count_nonzero(ard_reg.coef_), n_features)\n\n        # Compare the predictions of the ARDRegression model with a Ridge\n        # regression model with the same regularization strength\n        ridge_reg = Ridge(alpha=ard_reg.lambda_.sum())\n        ridge_reg.fit(X, y)\n        assert_array_almost_equal(ard_reg.predict(X), ridge_reg.predict(X))\n"], "sample_50": ["    def test_runshell_db_with_password(self):\n        dbinfo = {\n            'host': 'localhost',\n            'port': '5432',\n            'database': 'mydatabase',\n            'user': 'myuser',\n            'password': 'mypassword',\n        }\n        args, pgpassword = self._run_it(dbinfo)\n        self.assertEqual(args, [\n            'psql',\n            '-U', 'myuser',\n            '-h', 'localhost',\n            '-p', '5432',\n            'mydatabase',\n        ])\n        self.assertEqual(pgpassword, 'mypassword')\n"], "sample_614": ["    def test_short_numpy_repr(self, array, expected):\n        with formatting.set_numpy_options(\n            precision=6, linewidth=100, threshold=100\n        ):\n            assert repr(array) == expected\n\n\n\n"], "sample_750": ["    def test_omp_gram_path(self):\n        coefs, n_iter = orthogonal_mp_gram(G, Xy, n_nonzero_coefs=3,\n                                           tol=None,\n                                           norms_squared=None,\n                                           copy_Gram=True,\n                                           copy_Xy=True,\n                                           return_path=True)\n        assert_array_equal(coefs.shape, (n_features, n_targets, 3))\n        assert_equal(n_iter.shape, (n_targets,))\n"], "sample_1122": ["compilation error"], "sample_1055": ["    def test_bg_private_key_invalid_prime():\n        with raises(ValueError):\n            bg_private_key(2, 3)"], "sample_1049": ["    def test_projection_line_parallel_to_normal(self):\n        p = Plane(Point3D(1, 1, 1), normal_vector=(1, 1, 1))\n        l = Line3D(Point3D(1, 1, 0), Point3D(2, 2, 1))\n        result = p.projection_line(l)\n        assert isinstance(result, Point3D)\n        assert result == Point3D(1, 1, 1)\n\n\n\n"], "sample_391": ["    def test_rename_model_with_field_rename(self):\n        operations = [\n            RenameModel(\"OldModel\", \"NewModel\"),\n            AlterField(\n                app_label=\"migrations\",\n                model_name=\"NewModel\",\n                name=\"old_field\",\n                field=models.CharField(max_length=100),\n            ),\n        ]\n        self.assertOptimizesTo(\n            operations,\n            [\n                RenameModel(\"OldModel\", \"NewModel\"),\n                AlterField(\n                    app_label=\"migrations\",\n                    model_name=\"NewModel\",\n                    name=\"old_field\",\n                    field=models.CharField(max_length=100),\n                ),\n            ],\n        )\n\n\n\n"], "sample_867": ["    def test_parameter_grid_invalid_input(self, klass, input, error_type,\n                                         error_message):\n        with pytest.raises(error_type, match=error_message):\n            klass(input)\n"], "sample_898": ["    def test_label_ranking_loss_multilabel_indicator(self):\n        y_true = np.array([[0, 1, 0],\n                          [1, 0, 1],\n                          [0, 1, 1]])\n        y_score = np.array([[0.1, 0.8, 0.2],\n                           [0.7, 0.3, 0.9],\n                           [0.4, 0.6, 0.5]])\n        loss = label_ranking_loss(y_true, y_score)\n        assert_almost_equal(loss, 0.66666667)\n"], "sample_258": ["    def test_receiver_decorator(self):\n        @receiver(a_signal)\n            return 'test_receiver'\n\n        response = a_signal.send(sender=self, arg1='test')\n        self.assertEqual(response[0][1], 'test_receiver')\n\n        self.assertTestIsClean(a_signal)\n    "], "sample_588": ["    def test_infer_concat_order_from_positions_simple(self):\n        ds1 = create_test_data(\n            {\"x\": np.arange(2), \"y\": np.arange(2)},\n            {\"temperature\": np.arange(4)},\n        )\n        ds2 = create_test_data(\n            {\"x\": np.arange(2, 4), \"y\": np.arange(2, 4)},\n            {\"temperature\": np.arange(4, 8)},\n        )\n        combined_ids, concat_dims = _infer_concat_order_from_positions(\n            [ds1, ds2]\n        )\n        expected_combined_ids = OrderedDict(\n            [\n                (\"0\", ds1),\n                (\"1\", ds2),\n            ]\n        )\n        expected_concat_dims = [\"x\", \"y\"]\n        assert_combined_tile_ids_equal(combined_ids, expected_combined_ids)\n        assert concat_dims == expected_concat_dims\n"], "sample_669": ["    def test_capture_manager_is_capturing(self, method):\n        capman = CaptureManager(method)\n        assert not capman.is_capturing()\n\n        capman.start_global_capturing()\n        assert capman.is_capturing()\n\n        capman.stop_global_capturing()\n        assert not capman.is_capturing()\n"], "sample_567": ["    def test_annotation_arrow_style(self, image_comparison_data):\n        fig, ax = plt.subplots()\n        a = Annotation(\"Hello\", (0.5, 0.5), xytext=(0.7, 0.7),\n                       arrowprops=dict(arrowstyle=\"->\"))\n        a.set_fontsize(12)\n        ax.add_artist(a)\n        plt.show()\n"], "sample_920": ["    def test_namedtuple_subclass(self):\n        docstring = cleandoc(\"\"\"\n        Sample namedtuple subclass\n\n        Attributes\n        ----------\n        attr1 : Arbitrary type\n            Quick description of attr1\n        attr2 : Another arbitrary type\n            Quick description of attr2\n        attr3 : Type\n\n            Adds a newline after the type\n        \"\"\")\n        config = Config(napoleon_use_rtype=True)\n        docstring_obj = NumpyDocstring(docstring, config)\n        expected_output = dedent(\"\"\"\n        Sample namedtuple subclass\n\n        Attributes\n        ----------\n        attr1 : Arbitrary type\n        attr2 : Another arbitrary type\n        attr3 : Type\n\n        \"\"\")\n        self.assertEqual(docstring_obj.__str__(), expected_output)\n"], "sample_401": ["    def test_formset_factory_with_renderer(self):\n        with mock.patch(\"django.forms.renderers.get_default_renderer\") as mock_renderer:\n            mock_renderer.return_value = TemplatesSetting(\n                template_name=\"my_template\"\n            )\n            formset = formset_factory(\n                Choice, renderer=TemplatesSetting(template_name=\"custom_template\")\n            )\n            self.assertEqual(formset.template_name, \"custom_template\")\n"], "sample_863": ["    def test_pipeline_with_no_fit_transformers(self):\n        clf = DummyEstimatorParams()\n        scaler = StandardScaler()\n        pipeline = Pipeline([('scaler', scaler), ('clf', clf)])\n        X = np.random.rand(10, 5)\n        y = np.random.randint(0, 2, size=10)\n        pipeline.fit(X, y)\n        assert clf.got_attribute is False\n\n        pipeline.predict(X)\n        assert clf.got_attribute is True\n\n\n\n"], "sample_1198": ["    def test_parse_complex_function(self):\n        code = \"f[x_, y_] := Sin[x] + Cos[y]\"\n        expr = parse_mathematica(code)\n        assert expr == Lambda( (x, y), sin(x) + cos(y) )\n"], "sample_690": ["    def test_skip_marks(self, pytester: Pytester):\n        pytester.getitems(\n            \"-k\", \"test_skip_marks\",\n        )\n        result = pytester.runpytest()\n        result.assert_outcomes(passed=1)\n        result.stdout.fnmatch_lines(\n            [\n                \"*test_skip_marks.py::test_skip_marks PASSED*\",\n            ]\n        )\n"], "sample_10": ["    def test_set_column_with_masked_column(self):\n        a = MaskedColumn([1, 2, 3], name='a', mask=[False, True, False])\n        t = self._table_type([a])\n        t['a'] = self.a\n        assert_array_equal(t['a'].data, [1, 2, 3])\n        assert_array_equal(t['a'].mask, [False, True, False])\n\n\n\n"], "sample_604": ["    def test_array_repr(self, array, expected):\n        assert formatting.array_repr(array) == expected\n\n\n\n"], "sample_467": ["    def test_value_from_datadict_with_empty_values(self):\n        data = {\n            \"form-year\": \"\",\n            \"form-month\": \"\",\n            \"form-day\": \"\",\n        }\n        form = Form({\"date\": DateField(widget=self.widget)})\n        self.assertIsNone(form.cleaned_data[\"date\"])\n"], "sample_94": ["    def test_create_superuser_with_invalid_password(self):\n        with mock.patch('builtins.input', side_effect=['']):\n            with self.assertRaises(CommandError) as cm:\n                call_command('createsuperuser', verbosity=0)\n            self.assertIn('Error: Your passwords didn\\'t match.', str(cm.exception))\n"], "sample_838": ["    def test_remainder_estimator(self):\n        X = np.array([[1, 2], [3, 4]])\n        remainder_est = Trans()\n        ct = ColumnTransformer(\n            transformers=[('scaler', StandardScaler(), [0]),\n                          ('remainder', remainder_est, [1])],\n            remainder='remainder'\n        )\n        ct.fit(X)\n        transformed = ct.transform(X)\n        expected = np.hstack((\n            StandardScaler().fit_transform(X[:, 0].reshape(-1, 1)),\n            remainder_est.transform(X[:, 1].reshape(-1, 1))\n        ))\n        assert_array_equal(transformed, expected)\n"], "sample_87": ["    def test_iter_modules_and_files_with_zip_modules(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_filename = self.temporary_file('my_module.zip')\n            with zipfile.ZipFile(zip_filename, 'w') as zipf:\n                zipf.write('__init__.py', '')\n                zipf.write('module1.py', '')\n            extend_sys_path([tempdir])\n            with open(zip_filename, 'rb') as f:\n                zipimporter = zipfile.ZipFile(f)\n                module = zipimporter.open('my_module/__init__.py').read().decode('utf-8')\n                sys.modules['my_module'] = types.ModuleType('my_module')\n                exec(module, sys.modules['my_module'].__dict__)\n            self.assertFileFound(zip_filename)\n            self.assertFileFound(zip_filename / '__init__.py')\n            self.assertFileFound(zip_filename / 'module1.py')\n            del sys.modules['my_module']\n            shutil.rmtree(tempdir)\n"], "sample_555": ["    def test_fancyarrowpatch_mutation(self):\n        fig, ax = plt.subplots()\n        arrow = FancyArrowPatch((0, 0), (1, 1),\n                                arrowstyle=\"->\",\n                                mutation_scale=2,\n                                mutation_aspect=0.5)\n        ax.add_artist(arrow)\n        plt.show()\n"], "sample_1126": ["    def test_dagger_matrix_multiplication(self):\n        A = Matrix([[1, 2], [3, 4]])\n        B = Matrix([[5, 6], [7, 8]])\n        self.assertEqual(Dagger(A * B), Dagger(B) * Dagger(A))\n"], "sample_533": ["    def test_contourf_levels(self):\n        x = np.linspace(0, 10, 100)\n        y = np.linspace(0, 10, 100)\n        X, Y = np.meshgrid(x, y)\n        Z = np.sin(np.sqrt(X**2 + Y**2))\n\n        fig, ax = plt.subplots()\n        contour = ax.contourf(X, Y, Z, levels=np.linspace(0, 1, 11), cmap='viridis')\n        ax.clabel(contour, inline=True, fontsize=8)\n        ax.set_title('Contourf with levels')\n        ax.set_xlabel('X')\n        ax.set_ylabel('Y')\n        plt.show()\n"], "sample_1090": ["compilation error"], "sample_144": ["    def test_related_fields_with_ordering(self):\n        # Test ordering on related fields with multiple levels of inheritance\n        congressman = Congressman.objects.create(name=\"John Doe\")\n        senator = Senator.objects.create(name=\"Jane Doe\", congressman=congressman)\n\n        # Order by senator's name\n        senators = Senator.objects.order_by('name')\n        self.assertEqual(senators.count(), 1)\n        self.assertEqual(senators[0].name, 'Jane Doe')\n\n        # Order by congressman's name\n        congressmen = Congressman.objects.order_by('name')\n        self.assertEqual(congressmen.count(), 1)\n        self.assertEqual(congressmen[0].name, 'John Doe')\n\n\n\n"], "sample_1088": ["compilation error"], "sample_106": ["    def test_patch_vary_headers(self):\n        response = HttpResponse()\n        patch_vary_headers(response, ['Accept-Language', 'User-Agent'])\n        self.assertEqual(response['Vary'], 'Accept-Language,User-Agent')\n\n        response = HttpResponse()\n        patch_vary_headers(response, ['*'])\n        self.assertEqual(response['Vary'], '*')\n\n        response = HttpResponse()\n        patch_vary_headers(response, ['Accept-Language', 'User-Agent', 'Accept-Encoding'])\n        self.assertEqual(response['Vary'], 'Accept-Language,User-Agent,Accept-Encoding')\n\n        response = HttpResponse()\n        patch_vary_headers(response, [])\n        self.assertFalse('Vary' in response)\n\n\n\n"], "sample_312": ["    def test_add_squash(self):\n        node3 = Node(connector='AND', children=[('c', 3)])\n        result = self.node1.add(node3, 'AND', squash=True)\n        self.assertEqual(result, node3)\n        self.assertEqual(self.node1.children, [node3])\n"], "sample_1022": ["    def test_split_symbols_custom(self):\n            return symbol in ('list', 'of', 'unsplittable', 'names')\n\n        transformations = (split_symbols_custom(can_split),)\n        self.assertEqual(parse_expr(\"unsplittablexyz\", transformations=transformations),\n                         sympy.Symbol('unsplittablexyz'))\n        self.assertEqual(parse_expr(\"listofunsplittablexyz\", transformations=transformations),\n                         sympy.Symbol('listofunsplittablexyz'))\n        self.assertEqual(parse_expr(\"xyz\", transformations=transformations),\n                         sympy.Symbol('xyz'))\n"], "sample_905": ["    def test_getdoc_inherited_method():\n        class Base:\n                pass\n\n        class Derived(Base):\n                pass\n\n        doc = inspect.getdoc(Derived.method)\n        assert doc is None\n\n        doc = inspect.getdoc(Derived.method, allow_inherited=True)\n        assert doc is not None\n\n\n\n"], "sample_493": ["compilation error"], "sample_597": ["    def test_merge_identical_with_conflicting_attrs(self):\n        x = create_test_data(\n            dims=(\"lat\", \"lon\"),\n            coords={\"lat\": [35, 40], \"lon\": [100, 120]},\n            data=np.random.rand(2, 2),\n        )\n        y = create_test_data(\n            dims=(\"lat\", \"lon\"),\n            coords={\"lat\": [35, 42], \"lon\": [100, 150]},\n            data=np.random.rand(2, 2),\n        )\n        x.attrs[\"foo\"] = \"bar\"\n        y.attrs[\"foo\"] = \"baz\"\n        with pytest.raises(MergeError):\n            merge([x, y], compat=\"identical\")\n"], "sample_1101": ["    def test_schur_partition_large_n():\n        for i in range(5, 10):\n            partition = schur_partition(i * 10)\n            assert len(partition) == _schur_subsets_number(i * 10)\n            for subset in partition:\n                assert all(1 <= x <= i * 10 for x in subset)\n                assert sum(subset) == 0\n"], "sample_338": ["    def test_migration_dependencies_circular_fk(self):\n        before_states = self.make_project_state([\n            rabbit,\n        ])\n        after_states = self.make_project_state([\n            rabbit,\n        ], {\n            \"eggs\": [\n                {\"operation\": \"AlterField\", \"model\": \"eggs.Rabbit\", \"field\": \"parent\", \"to\": \"eggs.Knight\"},\n            ],\n        })\n        changes = self.get_changes(before_states, after_states)\n        self.assertMigrationDependencies(changes, \"eggs\", 0, [\"eggs.Knight\"])\n"], "sample_1156": ["    def test_asech_complex():\n        from sympy.functions.special.hyperbolic import asech\n        z = asech(S.ImaginaryUnit)\n        assert z == -I*pi/2\n        z = asech(S.ImaginaryUnit*(sqrt(6) - sqrt(2)))\n        assert z == -5*I*pi/12\n        z = asech(S.ImaginaryUnit*2)\n        assert z == -I*pi/3\n        z = asech(S.ImaginaryUnit*(-2))\n        assert z == 2*I*pi/3\n        z = asech(S.ImaginaryUnit*sqrt(2))\n        assert z == -3*I*pi/4\n        z = asech(S.ImaginaryUnit*sqrt(2 + sqrt(2)))\n        assert z == -3*I*pi/8\n        z = asech(S.ImaginaryUnit*sqrt(2 - 2/sqrt(5)))\n        assert z == -2*I*pi/5\n        z = asech(S.ImaginaryUnit*(sqrt(5)-1))\n        assert z == -3*I*pi/10\n        z = asech(S.ImaginaryUnit*2 / sqrt(3))\n        assert z == -I*pi/3\n        z = asech(S.ImaginaryUnit*2 / sqrt(2 + sqrt(2)))\n        assert z == -3*I*pi/8\n        z = asech(S.ImaginaryUnit*(sqrt(6) + sqrt(2)))\n        assert z == 5*I*pi/12\n        z = asech(S.ImaginaryUnit*(-sqrt(6) - sqrt(2)))\n        assert z == 7*I*pi/12\n        z = asech(S.ImaginaryUnit*sqrt(2*(2 + sqrt(2))))\n        assert z == 3*I*pi/8\n        z = asech(S.ImaginaryUnit*(1 + sqrt(5)))\n        assert z == 2*I*pi/5\n        z = asech(S.ImaginaryUnit*(-1 - sqrt(5)))\n        assert z == 3*I*pi/5\n\n\n\n"], "sample_645": ["def test_log_cli_level(testdir: Pytester) -> None:\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n        logging.basicConfig(level=logging.DEBUG)\n        logging.getLogger(__name__).info(\"This is an info message\")\n        logging.getLogger(__name__).warning(\"This is a warning message\")\n    \"\"\"\n    )\n\n    result = testdir.runpytest(\n        \"--log-cli-level=WARNING\",\n        \"--log-cli-format=%(asctime)s %(levelname)s %(message)s\",\n    )\n    result.assert_outcomes(passed=1)\n    result.stdout.re_match(r\"WARNING.*This is a warning message\")\n    result.stdout.re_match(r\"DEBUG.*This is an info message\", False)\n\n\n\n"], "sample_40": ["compilation error"], "sample_22": ["compilation error"], "sample_234": ["    def test_union_with_distinct(self):\n        # Test UNION with DISTINCT\n        distinct_numbers = Number.objects.filter(num__gt=5).distinct()\n        union_numbers = Number.objects.filter(num__gt=5).union(Number.objects.filter(num__lt=5))\n        self.assertNumbersEqual(distinct_numbers, [Number(num=6, other_num=4), Number(num=7, other_num=3), Number(num=8, other_num=2), Number(num=9, other_num=1)])\n        self.assertNumbersEqual(union_numbers, [Number(num=6, other_num=4), Number(num=7, other_num=3), Number(num=8, other_num=2), Number(num=9, other_num=1), Number(num=0, other_num=10), Number(num=1, other_num=9), Number(num=2, other_num=8), Number(num=3, other_num=7), Number(num=4, other_num=6)])\n\n\n\n"], "sample_1127": ["    def test_coset_operations(self):\n        G = PermutationGroup([Permutation([1, 2, 0]), Permutation([0, 2, 1])])\n        H = G.subgroup([Permutation([1, 2, 0])])\n        g = Permutation([0, 2, 1])\n        c1 = Coset(g, H, dir=\"+\")\n        c2 = Coset(g, H, dir=\"-\")\n        self.assertEqual(c1.as_list(), c2.as_list())\n        self.assertEqual(c1.is_right_coset, True)\n        self.assertEqual(c2.is_left_coset, True)\n        \n        g2 = Permutation([0, 1, 2])\n        c3 = Coset(g2, H, dir=\"+\")\n        self.assertNotEqual(c1.as_list(), c3.as_list())\n"], "sample_744": ["    def test_power_transform_ordinal(self):\n        X = np.array([[1, 2], [3, 4], [5, 6]])\n        pt = PowerTransformer(method='ordinal', copy=False)\n        X_trans = pt.fit_transform(X)\n        expected_out = np.array([[0, 1], [2, 3], [4, 5]])\n        assert_array_equal(X_trans, expected_out)\n"], "sample_508": ["    def test_setp_kwargs_with_args(self):\n        fig, ax = plt.subplots()\n        line, = ax.plot([1, 2, 3])\n\n        setp(line, linewidth=2, color='r', linestyle='--')\n        setp(line, marker='o', markersize=8)\n\n        # Check that kwargs are applied correctly\n        assert line.get_linewidth() == 2\n        assert line.get_color() == 'r'\n        assert line.get_linestyle() == '--'\n        assert line.get_marker() == 'o'\n        assert line.get_markersize() == 8\n\n        plt.close(fig)\n\n\n\n"], "sample_220": ["    def test_set_cookie_with_expires(self):\n        response = HttpResponse()\n        response.set_cookie('test_cookie', 'test_value', expires=datetime.utcnow() + timedelta(days=1))\n        self.assertEqual(response.cookies['test_cookie']['expires'], http_date(time.time() + 86400))\n\n        with freeze_time(datetime(2023, 10, 27, 12, 0, 0, tzinfo=utc)):\n            response = HttpResponse()\n            response.set_cookie('test_cookie', 'test_value', expires=datetime.utcnow() + timedelta(days=1))\n            self.assertEqual(response.cookies['test_cookie']['expires'], http_date(time.time() + 86400))\n"], "sample_561": ["    def test_marker_style_diamond(self, image_comparison_path):\n        fig, ax = plt.subplots()\n        ax.plot([0, 1], [0, 1], marker='D', markersize=10)\n        ax.set_xlim([0, 1])\n        ax.set_ylim([0, 1])\n        fig.savefig(image_comparison_path)\n"], "sample_470": ["    def test_lazy_object_copy(self):\n        class MyObject:\n                self.value = value\n\n            return MyObject(value)\n\n        lazy_obj = SimpleLazyObject(create_object)\n        lazy_obj._wrapped = MyObject(1)  # Force initialization\n\n        copy_obj = copy.copy(lazy_obj)\n        self.assertNotSame(lazy_obj, copy_obj)\n        self.assertEqual(lazy_obj._wrapped.value, 1)\n        self.assertEqual(copy_obj._wrapped.value, 1)\n\n        # Test deepcopy\n        deepcopy_obj = copy.deepcopy(lazy_obj)\n        self.assertNotSame(lazy_obj, deepcopy_obj)\n        self.assertEqual(lazy_obj._wrapped.value, 1)\n        self.assertEqual(deepcopy_obj._wrapped.value, 1)\n"], "sample_680": ["    def test_evaluate_skip_marks_unconditional_skip(self):\n        item = _pytest.nodes.Item(\n            name=\"test_function\",\n            parent=None,\n            funcargs=None,\n            keywords=None,\n            config=None,\n        )\n        mark = pytest.mark.skip(reason=\"This test is skipped\")\n        result = evaluate_skip_marks(item)\n        assert result is not None\n        assert result.reason == \"This test is skipped\"\n"], "sample_851": ["    def test_mean_tweedie_deviance_power_out_of_range(self):\n        y_true = np.array([1, 2, 3])\n        y_pred = np.array([1.5, 2.5, 3.5])\n\n        with pytest.raises(ValueError):\n            mean_tweedie_deviance(y_true, y_pred, power=-2)\n        with pytest.raises(ValueError):\n            mean_tweedie_deviance(y_true, y_pred, power=1.5)\n"], "sample_150": ["    def test_check_database_backends_with_databases(self):\n        with mock.patch('django.core.checks.database.check_database_backends') as mock_check:\n            mock_check.return_value = [\n                check_database_backends(self.databases, 'default', 'sqlite3'),\n                check_database_backends(self.databases, 'other', 'postgresql'),\n            ]\n            result = check_database_backends(self.databases, 'default', 'sqlite3')\n            self.assertEqual(mock_check.call_count, 2)\n            self.assertEqual(result, [\n                check_database_backends(self.databases, 'default', 'sqlite3'),\n                check_database_backends(self.databases, 'other', 'postgresql'),\n            ])\n"], "sample_319": ["compilation error"], "sample_542": ["    def test_annotation_offset_coords(self):\n        fig, ax = plt.subplots()\n        a = Annotation(\"Hello\", (0.5, 0.5), xycoords='data',\n                       xytext=(0.6, 0.6), textcoords='offset points',\n                       arrowprops=dict(arrowstyle=\"->\"))\n        ax.text(0.5, 0.5, \"World\", ha=\"center\", va=\"center\")\n        plt.show()\n"], "sample_28": ["    def test_long_commentary_card(self):\n        # Test that long commentary cards are handled correctly\n        hdu = fits.PrimaryHDU()\n        hdu.header.add_comment(\"This is a very long comment that \"\n                               \"spans multiple lines and should be \"\n                               \"correctly handled as a single \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the second part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the third part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the fourth part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the fifth part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the sixth part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the seventh part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the eighth part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the ninth part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the tenth part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the eleventh part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the twelfth part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the thirteenth part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the fourteenth part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the fifteenth part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the sixteenth part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is the seventeenth part of the \"\n                               \"commentary card.\")\n        hdu.header.add_comment(\"This is"], "sample_1021": ["    def test_from_rotation_matrix_complex(self):\n        M = Matrix([[cos(x), -sin(x), 0],\n                    [sin(x), cos(x), 0],\n                    [0, 0, 1]])\n        q = Quaternion.from_rotation_matrix(M)\n        assert q.a == cos(x)\n        assert q.b == -sin(x)\n        assert q.c == 0\n        assert q.d == 0\n        \n        M = Matrix([[cos(x), -sin(x), 0],\n                    [sin(x), cos(x), 0],\n                    [0, 0, 1]])\n        q = Quaternion.from_rotation_matrix(M, v=(1, 1, 1))\n        assert q.a == cos(x)\n        assert q.b == -sin(x)\n        assert q.c == 0\n        assert q.d == 0\n"], "sample_299": ["    def test_check_default_cache_is_configured(self):\n        with self.subTest(\n            'default cache is configured',\n        ):\n            errors = check_default_cache_is_configured(\n                app_configs=[],\n            )\n            self.assertEqual(errors, [])\n\n        with self.subTest(\n            'default cache is not configured',\n        ):\n            errors = check_default_cache_is_configured(\n                app_configs=[],\n                settings=override_settings(CACHES={}),\n            )\n            self.assertEqual(errors, [E001])\n"], "sample_900": ["    def test_partial_fit_classification(self, activation):\n        mlp = MLPClassifier(activation=activation, random_state=0,\n                            max_iter=10, solver='sgd')\n        X, y = classification_datasets[0]\n        mlp.partial_fit(X[:50], y[:50])\n        mlp.partial_fit(X[50:100], y[50:100])\n        y_pred = mlp.predict(X[:10])\n        assert_array_equal(y_pred, y[:10])\n"], "sample_915": ["    def test_signature_from_str_with_defaults(self):\n        signature = \"(a: int, b=1, c=2, *args, **kwargs)\"\n        sig = inspect.Signature.from_str(signature)\n        expected_params = [\n            Parameter('a', Parameter.POSITIONAL_OR_KEYWORD, annotation=inspect.Signature.empty),\n            Parameter('b', Parameter.POSITIONAL_OR_KEYWORD, default=1),\n            Parameter('c', Parameter.POSITIONAL_OR_KEYWORD, default=2),\n            Parameter('args', Parameter.VAR_POSITIONAL, annotation=inspect.Signature.empty),\n            Parameter('kwargs', Parameter.VAR_KEYWORD, annotation=inspect.Signature.empty),\n        ]\n        assert sig.parameters == expected_params\n        assert sig.return_annotation == inspect.Signature.empty\n"], "sample_710": ["            def test_something(self):\n                pass"], "sample_649": ["    def test_log_file_handler_path(self, testdir: Pytester) -> None:\n        testdir.makepyfile(\n            \"\"\"\n            import logging\n            logging.basicConfig(level=logging.DEBUG)\n                pass\n            \"\"\"\n        )\n\n        # Test that the log file handler path can be set.\n        reconfigure_result = testdir.reconfigure(\n            \"--log-file=test.log\",\n            \"--log-level=DEBUG\",\n        )\n        result = reconfigure_result.runpytest()\n        result.assert_outcomes(passed=1)\n        assert os.path.exists(\"test.log\")\n        os.remove(\"test.log\")\n\n        # Test that the log file handler path can be set to a relative path.\n        reconfigure_result = testdir.reconfigure(\n            \"--log-file=../test.log\",\n            \"--log-level=DEBUG\",\n        )\n        result = reconfigure_result.runpytest()\n        result.assert_outcomes(passed=1)\n        assert os.path.exists(\"../test.log\")\n        os.remove(\"../test.log\")\n"], "sample_381": ["    def test_migration_dependencies_circular(self):\n        before_states = self.make_project_state([\n            rabbit,\n        ])\n        after_states = self.make_project_state([\n            rabbit,\n        ], {\n            'eggs': [\n                ('Rabbit', [\n                    ('id', models.AutoField(primary_key=True)),\n                    ('knight', models.ForeignKey('eggs.Knight', models.CASCADE)),\n                    ('parent', models.ForeignKey('eggs.Rabbit', models.CASCADE)),\n                ],\n                {\n                    \"unique_together\": {(\"parent\", \"knight\")},\n                    \"indexes\": [models.Index(fields=[\"parent\", \"knight\"], name='rabbit_circular_fk_index')],\n                }),\n            ],\n        })\n        changes = self.get_changes(before_states, after_states)\n        self.assertMigrationDependencies(changes, 'eggs', 0, ['eggs.Knight'])\n"], "sample_2": ["    def test_wcs_keyword_removal_for_wcs_test_files(tmpdir):\n        # This test checks that the WCS keywords are correctly removed from the\n        # header when a WCS object is generated from the header.\n        # It also checks that the WCS object is correctly generated.\n        # The test uses a set of test files that have different types of WCS\n        # keywords in the header.\n\n        test_files = get_pkg_data_filenames('astropy/nddata/ccddata_test_files',\n                                            'wcs_test_files')\n        for filename in test_files:\n            with fits.open(filename) as hdus:\n                hdr = hdus[0].header\n                wcs, new_hdr = _generate_wcs_and_update_header(hdr)\n                assert set(new_hdr) == set(hdr) - _KEEP_THESE_KEYWORDS_IN_HEADER\n                assert wcs is not None\n"], "sample_1060": ["    def test_sparse_matrix(self):\n        m = SparseMatrix([[1, 2], [3, 4]], shape=(2, 2))\n        code = pycode(m, printer=SciPyPrinter)\n        assert code == 'scipy.sparse.coo_matrix([[1, 2], [3, 4]], ((0, 0), (0, 1), (1, 0), (1, 1)), shape=(2, 2))'\n\n\n\n"], "sample_271": ["    def test_iter_modules_and_files_with_zip_file(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_filename = self.temporary_file('my_module.zip')\n            with zipfile.ZipFile(zip_filename, 'w') as zf:\n                zf.write('__init__.py', arcname='my_module')\n                zf.write('module.py', arcname='my_module/module.py')\n            extend_sys_path([tempdir])\n            self.assertFileFound(zip_filename)\n            self.import_and_cleanup('my_module')\n            self.assertFileFound(zip_filename)\n            self.assertFileFound(zip_filename.parent / 'my_module/module.py')\n"], "sample_520": ["    def test_poly3d_collection_projection(self):\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection='3d')\n        verts = [\n            [(0, 0, 0), (1, 0, 0), (1, 1, 0), (0, 1, 0)],\n            [(0, 0, 1), (1, 0, 1), (1, 1, 1), (0, 1, 1)],\n        ]\n        poly3d = Poly3DCollection(verts, facecolors='b', edgecolors='r')\n        ax.add_collection3d(poly3d)\n        ax.set_xlim(0, 2)\n        ax.set_ylim(0, 2)\n        ax.set_zlim(0, 2)\n        plt.draw()\n        plt.pause(0.01)\n        plt.close(fig)\n"], "sample_1028": ["    def test_mod_mul():\n        assert Mod(Mul(2, x), 3) == Mod(2*x, 3)\n        assert Mod(Mul(2, x), 3) == Mod(2*x, 3)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6*x, 5)\n        assert Mod(Mul(2*x, 3), 5) == Mod(6"], "sample_881": ["    def test_top_k_accuracy_score_multiclass(self, drop):\n        y_true, y_pred, y_score = make_prediction(binary=False)\n        k = 2\n        score = top_k_accuracy_score(y_true, y_score, k=k, normalize=normalize)\n        if normalize:\n            assert 0.5 <= score <= 1.0\n        else:\n            assert 0 <= score <= len(y_true)\n"], "sample_68": ["    def test_callable_setting_wrapper(self):\n            return 'This is a callable setting'\n\n        wrapped_setting = CallableSettingWrapper(callable_setting)\n        self.assertEqual(wrapped_setting(), 'This is a callable setting')\n        self.assertIsNot(wrapped_setting, callable_setting)\n\n        # Test that calling the wrapped object doesn't break things\n        with self.assertRaises(TypeError):\n            wrapped_setting = CallableSettingWrapper(callable_setting)\n            wrapped_setting.some_nonexistent_method()\n"], "sample_112": ["    def test_submit_row(self):\n        request = self.request_factory.get(reverse('admin:article_change', args=(1,)))\n        request.user = self.user\n        context = {'add': True, 'change': False, 'is_popup': False, 'save_as': False, 'show_save': True, 'show_save_and_add_another': True, 'show_save_and_continue': True, 'has_add_permission': True, 'has_change_permission': False, 'has_delete_permission': True, 'has_view_permission': True, 'has_editable_inline_admin_formsets': False, 'can_change': False}\n        context = submit_row(context)\n        self.assertTrue(context['show_save_and_add_another'])\n        self.assertTrue(context['show_save_and_continue'])\n        self.assertFalse(context['show_save'])\n        self.assertFalse(context['show_delete_link'])\n        self.assertFalse(context['show_save_as_new'])\n        self.assertFalse(context['show_close'])\n"], "sample_166": ["    def test_pbkdf2(self):\n        password = b'testpassword'\n        salt = b'testsalt'\n        iterations = 10000\n        dklen = 32\n\n        # Test with default digest\n        hash_value = pbkdf2(password, salt, iterations, dklen)\n        self.assertEqual(len(hash_value), dklen)\n\n        # Test with custom digest\n        hash_value = pbkdf2(password, salt, iterations, dklen, hashlib.sha512)\n        self.assertEqual(len(hash_value), dklen)\n"], "sample_93": ["    def test_window_functions(self):\n        with CaptureQueriesContext() as queries:\n            result = Book.objects.annotate(\n                avg_rating=Avg('rating', output_field=FloatField()),\n                rank=Rank()\n            ).filter(rating__gt=3.5).order_by('avg_rating').values('name', 'avg_rating', 'rank')\n            self.assertEqual(len(queries.captured_queries), 1)\n            self.assertIn('AVG(rating) OVER () AS avg_rating', queries.captured_queries[0])\n            self.assertIn('RANK() OVER (ORDER BY avg_rating DESC) AS rank', queries.captured_queries[0])\n            self.assertEqual(result, [\n                {'name': 'The Definitive Guide to Django: Web Development Done Right', 'avg_rating': 4.5, 'rank': 1},\n                {'name': 'Artificial Intelligence: A Modern Approach', 'avg_rating': 5.0, 'rank': 2},\n                {'name': 'Practical Django Projects', 'avg_rating': 4.0, 'rank': 3},\n                {'name': 'Python Web Development with Django', 'avg_rating': 4.0, 'rank': 4},\n                {'name': 'Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp', 'avg_rating': 5.0, 'rank': 5},\n            ])\n\n        with CaptureQueriesContext() as queries:\n            result = Book.objects.annotate(\n                avg_rating=Avg('rating', output_field=FloatField()),\n                rank=Dense_Rank()\n            ).filter(rating__gt=3.5).order_by('avg_rating').values('name', 'avg_rating', 'rank')\n            self.assertEqual(len(queries.captured_queries), 1)\n            self.assertIn('AVG(rating) OVER () AS avg_rating', queries.captured_queries[0])\n            self.assertIn('DENSE_RANK() OVER (ORDER BY avg_rating DESC) AS rank', queries.captured_queries[0])\n            self.assertEqual(result, [\n                {'name': 'Artificial Intelligence: A Modern Approach', 'avg_rating': 5.0, 'rank': 1},\n                "], "sample_284": ["    def test_manifest_strict_mode(self):\n        with override_settings(STATICFILES_STORAGE='django.contrib.staticfiles.storage.ManifestStaticFilesStorage'):\n            self.addCleanup(shutil.rmtree, self.temp_dir)\n            self.create_static_files()\n            call_command('collectstatic', ignore_patterns=['*.css'],\n                          verbosity=0,\n                          static_root=self.temp_dir)\n            self.assertPostCondition()\n            with self.assertRaises(ValueError):\n                storage.staticfiles_storage.stored_name('missing_file.css')\n"], "sample_95": ["    def test_full_decorator_applies_all_decorators(self):\n        response = fully_decorated(HttpRequest())\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content.decode('utf-8'), '<html><body>dummy</body></html>')\n        self.assertEqual(response.headers['Vary'], 'Accept-language,Cookie')\n        self.assertEqual(response.headers['Cache-Control'], 'private')\n        self.assertEqual(response.headers['X-Frame-Options'], 'DENY')\n        self.assertEqual(response.headers['Content-Type'], 'text/html; charset=utf-8')\n        self.assertEqual(response.headers['X-XSS-Protection'], '1; mode=block')\n        self.assertEqual(response.headers['X-Content-Type-Options'], 'nosniff')\n        self.assertEqual(response.headers['Strict-Transport-Security'], 'max-age=31536000; includeSubDomains')\n        self.assertEqual(response.headers['Referrer-Policy'], 'no-referrer-when-downgrade')\n        self.assertEqual(response.headers['Permissions-Policy'], 'interest-cohort=none;')\n        self.assertEqual(response.headers['Content-Security-Policy'], 'default-src \\'self\\';')\n        self.assertEqual(response.headers['Set-Cookie'], 'csrftoken=; Path=/; HttpOnly; Secure; SameSite=Strict')\n        self.assertEqual(response.headers['X-CSRF-Token'], 'csrftoken')\n        self.assertEqual(response.headers['Server'], 'Django/4.2.1')\n        self.assertEqual(response.headers['Date'], 'Tue, 17 Oct 2023 14:48:00 GMT')\n        self.assertEqual(response.headers['Connection'], 'close')\n        self.assertEqual(response.headers['Content-Length'], '26')\n        self.assertEqual(response.headers['Last-Modified'], 'Tue, 17 Oct 2023 14:48:00 GMT')\n        self.assertEqual(response.headers['ETag'], 'W/\"123456789"], "sample_487": ["    def test_admin_check_raw_id_fields(self):\n        class RawIdModelAdmin(ModelAdmin):\n            raw_id_fields = ['id']\n\n        self.assertIsInvalid(\n            RawIdModelAdmin,\n            ValidationTestModel,\n            \"The value of 'raw_id_fields' must be a list of field names.\",\n            id=\"admin.E131\",\n        )\n\n"], "sample_732": ["compilation error"], "sample_375": ["    def test_state_from_model_with_custom_base(self):\n        with isolate_apps(['my_app']):\n            with override_settings(INSTALLED_APPS=['my_app']):\n                model = ModelWithCustomBase()\n                state = ModelState.from_model(model)\n                self.assertEqual(state.bases, (ModelWithCustomBase, models.Model))\n"], "sample_975": ["    def test_unrad_bivariate():\n        x, y = symbols('x y')\n        eq = Eq(sqrt(x**2 + y**2) - 2, 0)\n        eq, cov = unrad(eq)\n        assert isinstance(eq, Eq)\n        assert isinstance(cov, list)\n        assert len(cov) == 2\n        assert cov[0] == x\n        assert cov[1] == x**2 + y**2 - 4\n        "], "sample_138": ["    def test_manifest_strict_missing_file(self):\n        with self.assertRaises(ValueError):\n            call_command('collectstatic', interactive=False, dry_run=True)\n        self.assertPostCondition()\n"], "sample_1033": ["    def test_primitive_radicals():\n        from sympy.core.numbers import sqrt\n        expr = 2*sqrt(2) + 4*sqrt(10)\n        con, prim = expr.as_content_primitive(radical=True)\n        assert con == 2\n        assert prim == sqrt(2)*(1 + 2*sqrt(5))\n"], "sample_1190": ["    def test_get_dimensional_expr(self):\n        system = SI\n        expr = system.get_dimensional_expr(meter * 2)\n        assert expr == 2 * length\n        expr = system.get_dimensional_expr(meter**2)\n        assert expr == length**2\n        expr = system.get_dimensional_expr(meter + meter)\n        assert expr == 2 * length\n        expr = system.get_dimensional_expr(diff(meter, time))\n        assert expr == length / time\n        expr = system.get_dimensional_expr(sin(meter))\n        assert expr == length\n        expr = system.get_dimensional_expr(exp(meter))\n        assert expr == length\n        expr = system.get_dimensional_expr(log(meter))\n        assert expr == length\n        expr = system.get_dimensional_expr(sqrt(meter))\n        assert expr == length**(1/2)\n        expr = system.get_dimensional_expr(meter * joule)\n        assert expr == length * energy\n        expr = system.get_dimensional_expr(meter / time)\n        assert expr == length / time\n        expr = system.get_dimensional_expr(meter * kilogram)\n        assert expr == length * mass\n        expr = system.get_dimensional_expr(meter * kilogram * length / time**2)\n        assert expr == length**2 * mass / time**2\n        expr = system.get_dimensional_expr(meter * kilogram * length / time**2)\n        assert expr == length**2 * mass / time**2\n"], "sample_51": ["    def test_parse_datetime_with_timezone(self):\n        dt = parse_datetime('2023-10-27T14:30:00+05:30')\n        self.assertEqual(dt.year, 2023)\n        self.assertEqual(dt.month, 10)\n        self.assertEqual(dt.day, 27)\n        self.assertEqual(dt.hour, 14)\n        self.assertEqual(dt.minute, 30)\n        self.assertEqual(dt.second, 0)\n        self.assertEqual(dt.tzinfo, get_fixed_timezone(19800))\n"], "sample_773": ["compilation error"], "sample_134": ["    def test_serialize_functools_partial(self):\n        partial = functools.partial(lambda x, y: x + y, 10)\n        serializer = serializer_factory(partial)\n        serialized_string, imports = serializer.serialize()\n        self.assertEqual(\n            serialized_string,\n            'functools.partial(lambda x, y: x + y, 10)'\n        )\n        self.assertEqual(imports, {'import functools'})\n"], "sample_584": ["def test_infer_concat_order_from_positions_simple():\n    ds1 = create_test_data(dims=('x', 'y'), coords={'x': [0, 1], 'y': [2, 3]})\n    ds2 = create_test_data(dims=('x', 'y'), coords={'x': [2, 3], 'y': [4, 5]})\n    combined_ids, concat_dims = _infer_concat_order_from_positions(\n        [(ds1, 0), (ds2, 1)])\n    assert_combined_tile_ids_equal(combined_ids, OrderedDict([(0, ds1), (1, ds2)]))\n    assert concat_dims == ['x']\n\n"], "sample_575": ["    def test_continuous_tick_locator(self, x):\n        a = self.setup_ticks(x, count=3)\n        ticks = a.get_majorticklocs()\n        assert_array_equal(ticks, [1, 3, 9])\n"], "sample_452": ["    def test_rename_index_with_unnamed_index(self):\n        with atomic():\n            self.create_model(\n                \"RenameIndexTest\",\n                models.Model(\n                    id=models.AutoField(primary_key=True),\n                    name=models.CharField(max_length=100),\n                    value=models.IntegerField(),\n                ),\n            )\n            with self.assertNumQueries(1):\n                self.execute_sql(\n                    \"CREATE INDEX idx_rename_test_on_value ON RenameIndexTest (value)\"\n                )\n\n            with self.assertNumQueries(1):\n                self.execute_sql(\n                    \"ALTER TABLE RenameIndexTest RENAME INDEX idx_rename_test_on_value TO new_value_index\"\n                )\n\n            with self.assertNumQueries(1):\n                self.execute_sql(\n                    \"ALTER TABLE RenameIndexTest RENAME INDEX new_value_index TO value_index\"\n                )\n\n            self.assertEqual(\n                self.execute_sql(\"SHOW INDEXES FROM RenameIndexTest\"),\n                [\n                    (\"value_index\", \"BTREE\", \"value\", \"\", \"\", \"ASC\", \"NULL\", \"1\"),\n                ],\n            )\n\n            with self.assertNumQueries(1):\n                self.execute_sql(\n                    \"DROP INDEX value_index ON RenameIndexTest\"\n                )\n\n\n\n"], "sample_894": ["    def test_random_state(name):\n        ForestClassifier = FOREST_CLASSIFIERS[name]\n\n        # Test that setting random_state ensures reproducibility\n        rng1 = check_random_state(1)\n        clf1 = ForestClassifier(n_estimators=10, random_state=rng1)\n        clf1.fit(X, y)\n\n        rng2 = check_random_state(1)\n        clf2 = ForestClassifier(n_estimators=10, random_state=rng2)\n        clf2.fit(X, y)\n\n        assert_array_equal(clf1.estimators_, clf2.estimators_)\n"], "sample_1097": ["    def test_block_collapse_matmul():\n        from sympy.matrices.expressions.blockmatrix import block_collapse\n        expr = MatMul(2, BlockMatrix([[A, B], [C, D]]), BlockMatrix([[E, F], [G, H]]))\n        result = block_collapse(expr)\n        expected = BlockMatrix([[2*A*E + 2*B*G, 2*A*F + 2*B*H],\n                              [2*C*E + 2*D*G, 2*C*F + 2*D*H]])\n        assert result == expected\n"], "sample_137": ["    def test_parse_docstring(self):\n        title, body, metadata = parse_docstring(self.docstring)\n        self.assertEqual(title, \"This __doc__ output is required for testing. I copied this example from admindocs documentation. (TITLE)\")\n        self.assertEqual(body, \"Display an individual :model:`myapp.MyModel`. \\n\\n**Context**\\n\\n``RequestContext``\\n\\n``mymodel``\\n        An instance of :model:`myapp.MyModel`. \\n\\n**Template:**\\n\\n:template:`myapp/my_template.html` (DESCRIPTION)\\n\\nsome_metadata: some data\")\n        self.assertEqual(metadata, {'some_metadata': 'some data'})\n"], "sample_998": ["    def test_latex_quaternion(self):\n        q = Quaternion(1, 2, 3, 4)\n        self.assertEqual(latex(q), r\"1 + 2 i + 3 j + 4 k\")\n"], "sample_1125": ["    def test_differential_operator(self):\n        from sympy.physics.quantum.state import Wavefunction\n        x = symbols('x')\n        f = Function('f')\n        d = DifferentialOperator(Derivative(f(x), x), f(x))\n        w = Wavefunction(x**2, x)\n        self.assertEqual(d*w, Wavefunction(2*x, x))\n"], "sample_315": ["    def test_redirect_to_language_specific_url(self):\n        with override_script_prefix('/'):\n            factory = RequestFactory()\n            request = factory.get('/en/about/')\n            middleware = PermanentRedirectLocaleMiddleWare()\n            response = middleware.process_request(request)\n            self.assertEqual(response.status_code, 301)\n            self.assertEqual(response['Location'], '/en/about/')\n"], "sample_949": ["    def test_default_man_pages(sphinx_app: Sphinx, tmpdir) -> None:\n        config = Config(sphinx_app)\n        config.project = 'myproject'\n        config.release = '0.1'\n        config.author = 'John Doe'\n        config.root_doc = 'index'\n\n        expected_man_pages = default_man_pages(config)\n        assert expected_man_pages == [\n            ('index', 'myproject', '%s %s' % (config.project, config.release),\n             ['John Doe'], 1)\n        ]\n"], "sample_1146": ["    def test_multiline_latex_with_symbols(self):\n        from sympy.abc import x, y, z\n        expr = x**2 + y*z + 2*x\n        print(multiline_latex(x, expr, terms_per_line=2))\n"], "sample_194": ["    def test_unique_constraint_deconstruct(self):\n        constraint = UniqueConstraint(\n            fields=['name', 'price'],\n            name='unique_name_price',\n            deferrable=Deferrable.DEFERRED,\n            opclasses=('text', 'numeric'),\n        )\n        path, args, kwargs = constraint.deconstruct()\n        self.assertEqual(path, 'django.db.models.constraints.UniqueConstraint')\n        self.assertEqual(args, ())\n        self.assertEqual(kwargs, {\n            'fields': ['name', 'price'],\n            'name': 'unique_name_price',\n            'deferrable': 'deferred',\n            'opclasses': ('text', 'numeric'),\n        })\n\n        reconstructed_constraint = UniqueConstraint(*args, **kwargs)\n        self.assertEqual(constraint, reconstructed_constraint)\n"], "sample_344": ["    def test_state_field_operations(self):\n        with isolate_apps(['food']):\n            # Create a state with a model\n            state = ProjectState()\n            state.register_model('food', UnicodeModel)\n\n            # Get the model state\n            model_state = state.models[('food', 'UnicodeModel')]\n\n            # Add a field\n            operation = AddField(\n                model_name='UnicodeModel',\n                name='new_field',\n                field=models.CharField(max_length=100),\n            )\n            operation.apply(model_state, state)\n\n            # Assert the field is present\n            self.assertIn('new_field', model_state.fields)\n\n            # Remove a field\n            operation = RemoveField(\n                model_name='UnicodeModel',\n                name='id',\n            )\n            operation.apply(model_state, state)\n\n            # Assert the field is gone\n            self.assertNotIn('id', model_state.fields)\n\n            # Alter a field\n            operation = AlterField(\n                model_name='UnicodeModel',\n                name='name',\n                field=models.CharField(max_length=200),\n            )\n            operation.apply(model_state, state)\n\n            # Assert the field is altered\n            field = model_state.get_field('name')\n            self.assertEqual(field.max_length, 200)\n"], "sample_523": ["    def test_bbox_to_anchor(self):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], [4, 5, 6])\n        legend = ax.legend(bbox_to_anchor=(0.5, 0.5))\n        plt.show()\n"], "sample_882": ["    def test_mlp_activation(self, activation):\n        for X, y in classification_datasets:\n            clf = MLPClassifier(activation=activation, random_state=0)\n            clf.fit(X, y)\n            y_pred = clf.predict(X)\n            assert_array_equal(y_pred, np.argmax(clf.predict_proba(X), axis=1))\n"], "sample_931": ["    def test_parse_annotation(self):\n        assert _parse_annotation('int') == ('int', None)\n        assert _parse_annotation('int, str') == ('int, str', None)\n        assert _parse_annotation('int: str') == ('int', 'str')\n        assert _parse_annotation('int -> str') == ('int', 'str')\n        assert _parse_annotation('int -> None') == ('int', 'None')\n        assert _parse_annotation('int -> List[str]') == ('int', 'List[str]')\n        assert _parse_annotation('int -> Dict[str, int]') == ('int', 'Dict[str, int]')\n        assert _parse_annotation('int -> Union[str, int]') == ('int', 'Union[str, int]')\n        assert _parse_annotation('int -> Optional[str]') == ('int', 'Optional[str]')\n        assert _parse_annotation('int -> Tuple[str, int]') == ('int', 'Tuple[str, int]')\n\n\n\n"], "sample_105": ["    def test_redirect_view(self):\n        view = RedirectView.as_view(url='http://www.example.com/')\n        request = self.rf.get('/')\n        response = view(request)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response['Location'], 'http://www.example.com/')\n"], "sample_162": ["    def test_no_i18n_setting(self):\n        \"\"\"\n        makemessages should not create any .po files if USE_I18N is False.\n        \"\"\"\n        with self.tmp_dir() as tmpdir:\n            self.copy_template_files(tmpdir)\n            with captured_stderr() as stderr:\n                execute_from_command_line(['django-admin', 'makemessages', '--locale', LOCALE, '--no-input'])\n            self.assertEqual(stderr.getvalue(), '')\n            self.assertFalse(os.path.exists(self.PO_FILE))\n"], "sample_935": ["    def test_template_param_in_qualified_name(self):\n        input = \"template <typename T> struct S {};\"\n        output = \"template <typename T> struct S {};\"\n        idDict = {1: \"S\"}\n        check(\"struct\", input, idDict, output)\n"], "sample_1070": ["    def test_log_expand_log_complex():\n        from sympy.functions.elementary.complexes import polar\n        z = polar(2, pi/4)\n        expr = log(z)\n        assert expr.func == log\n        assert expr.args[0] == z\n        expr = expr.expand()\n        assert expr.func == log\n        assert expr.args[0] == z\n        assert expr.args[0].is_polar\n        assert expr.args[0].r == 2\n        assert expr.args[0].theta == pi/4\n        assert expr.args[0].is_real is False\n"], "sample_372": ["compilation error"], "sample_174": ["    def test_subtract_temporals_unsupported(self):\n        with self.assertRaises(NotSupportedError) as cm:\n            self.ops.subtract_temporals('DateTimeField', (('a', []), ('b', [])), connection)\n        self.assertEqual(cm.exception.args[0], 'This backend does not support DateTimeField subtraction.')\n"], "sample_342": ["    def test_permission_denied(self):\n        request = self.factory.get(self.url, data={\n            'app_label': 'my_app',\n            'model_name': 'answer',\n            'field_name': 'question',\n            'term': 'test',\n        })\n        request.user = User.objects.create_user(\n            username='user', password='secret',\n            email='user@example.com', is_staff=False,\n        )\n        response = AutocompleteJsonView.as_view()(request, *(), **{})\n        self.assertEqual(response.status_code, 403)\n        self.assertEqual(response.json(), {'error': 'Permission denied.'})\n"], "sample_1076": ["    def test_sparse_matrix(self):\n        m = SparseMatrix(((1, 0, 2), (0, 1, 3)), shape=(2, 3))\n        self.assertEqual(pycode(m, printer=SciPyPrinter),\n                         'scipy.sparse.coo_matrix(((1, 0, 2), (0, 1, 3)), (0, 1, 1, 2, 0, 2), shape=(2, 3))')\n\n\n\n"], "sample_622": ["    def test_bool_type_array(self):\n        data = np.array([True, False, True], dtype=bool)\n        var = Variable(dims=(\"x\",), data=data, dtype=\"bool\")\n        encoded_var = encode_cf_variable(var)\n        assert encoded_var.dtype == \"bool\"\n        assert encoded_var.encoding.get(\"dtype\") == \"bool\"\n\n\n\n"], "sample_165": ["compilation error"], "sample_853": ["    def test_transformer_with_inverse_func(self, regressor):\n        tt = TransformedTargetRegressor(regressor=regressor,\n                                        func=np.log,\n                                        inverse_func=np.exp)\n        X, y = friedman\n\n        tt.fit(X, y)\n        y_pred = tt.predict(X)\n        assert_allclose(y_pred, np.exp(tt.regressor_.predict(X)))\n"], "sample_501": ["    def test_bbox_to_anchor(self):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], [4, 5, 6])\n        legend = ax.legend(bbox_to_anchor=(0.5, 1.05), loc='upper center')\n        plt.show()\n"], "sample_961": ["    def test_parse_annotation(self):\n        assert _parse_annotation('int') == ('int', None)\n        assert _parse_annotation('int, str') == ('int, str', None)\n        assert _parse_annotation('int: str') == ('int', 'str')\n        assert _parse_annotation('int -> str') == ('int', 'str')\n        assert _parse_annotation('int -> None') == ('int', 'None')\n        assert _parse_annotation('int -> List[str]') == ('int', 'List[str]')\n        assert _parse_annotation('int -> Dict[str, int]') == ('int', 'Dict[str, int]')\n        assert _parse_annotation('int -> typing.List[str]') == ('int', 'typing.List[str]')\n        assert _parse_annotation('int -> typing.Dict[str, int]') == ('int', 'typing.Dict[str, int]')\n        assert _parse_annotation('int -> Optional[str]') == ('int', 'Optional[str]')\n        assert _parse_annotation('int -> Union[str, int]') == ('int', 'Union[str, int]')\n\n\n\n"], "sample_1111": ["compilation error"], "sample_357": ["    def test_migration_dependencies_circular(self):\n        before_states = self.make_project_state([\n            rabbit,\n        ])\n        after_states = self.make_project_state([\n            rabbit,\n        ], {\n            \"eggs\": [\n                (\"0001_initial\", [\n                    models.CreateModel(\n                        name=\"Rabbit\",\n                        fields=[\n                            models.AutoField(primary_key=True),\n                            models.ForeignKey(\"Knight\", on_delete=models.CASCADE),\n                            models.ForeignKey(\"Rabbit\", on_delete=models.CASCADE, related_name=\"parent\"),\n                        ],\n                        options={\n                            \"unique_together\": {(\"parent\", \"knight\")},\n                            \"indexes\": [\n                                models.Index(fields=[\"parent\", \"knight\"], name='rabbit_circular_fk_index'),\n                            ],\n                        },\n                    ),\n                ]),\n            ],\n        })\n        changes = self.get_changes(before_states, after_states)\n        self.assertMigrationDependencies(changes, \"eggs\", 0, [\"eggs.Knight\"])\n"], "sample_1177": ["    def test_polar_lift_with_symbols():\n        x = Symbol('x', polar=True)\n        y = Symbol('y', polar=True)\n        assert polar_lift(x*y) == polar_lift(x)*polar_lift(y)\n        assert polar_lift(x + y) == polar_lift(x) + polar_lift(y)\n        assert polar_lift(x**y) == polar_lift(x)**polar_lift(y)\n        assert polar_lift(x**2) == polar_lift(x)**2\n        assert polar_lift(x**2*y) == polar_lift(x)**2*polar_lift(y)\n"], "sample_635": ["    def test_param_doc_missing_type(self):\n        \"\"\"Test that missing type in docstring is flagged.\"\"\"\n        code = \"\"\""], "sample_1027": ["    def test_groebner_fglm_order_change():\n        from sympy.abc import x, y\n        from sympy import groebner\n\n        F = [x**2 - 3*y - x + 1, y**2 - 2*x + y - 1]\n        G = groebner(F, x, y, order='grlex')\n\n        # Convert to lex order\n        G_lex = G.fglm('lex')\n\n        # Check that the result is equivalent to computing Groebner basis\n        # directly in lex order\n        G_lex_direct = groebner(F, x, y, order='lex')\n\n        assert _strict_eq(G_lex, G_lex_direct)\n\n\n\n"], "sample_164": ["    def test_callback_filter(self):\n        class MyCallbackFilter(CallbackFilter):\n                super().__init__(lambda record: should_log)\n\n                return super().filter(record)\n\n        # Create a logger with the callback filter\n        logger = logging.getLogger('test')\n        filter = MyCallbackFilter(True)\n        logger.addFilter(filter)\n\n        # Log a message\n        logger.info('This message should be logged')\n\n        # Log a message that should not be logged\n        logger.info('This message should not be logged')\n\n        # Assert that only the first message was logged\n        self.assertEqual(len(logger.handlers[0].emitted), 1)\n\n        # Create a logger with a different callback filter\n        logger = logging.getLogger('test')\n        filter = MyCallbackFilter(False)\n        logger.addFilter(filter)\n\n        # Log a message\n        logger.info('This message should not be logged')\n\n        # Assert that no messages were logged\n        self.assertEqual(len(logger.handlers[0].emitted), 0)\n"], "sample_803": ["    def test_roc_curve_with_drop_intermediate(drop):\n        y_true, y_pred, _ = make_prediction()\n        fpr, tpr, thresholds = roc_curve(y_true, y_pred, drop_intermediate=drop)\n        assert_array_almost_equal(fpr, _partial_roc_auc_score(y_true, y_pred, fpr[-1]))\n        assert_array_almost_equal(tpr, _partial_roc_auc_score(y_true, y_pred, tpr[-1]))\n"], "sample_1029": ["compilation error"], "sample_355": ["    def test_get_user_permissions(self):\n        user = self.user\n        permissions = user.get_user_permissions()\n        self.assertEqual(permissions, ['user_perm'])\n\n        permissions = user.get_group_permissions()\n        self.assertEqual(permissions, [])\n"], "sample_630": ["    def test_generated_dot_file(generated_file):\n        expected_lines = _file_lines(\n            os.path.join(os.path.dirname(__file__), \"expected\", generated_file)\n        )\n        actual_lines = _file_lines(generated_file)\n        diff = unified_diff(expected_lines, actual_lines, fromfile=\"expected\", tofile=generated_file)\n        assert not diff, f\"Generated {generated_file} differs from expected:\\n{''.join(diff)}\"\n"], "sample_369": ["    def test_migration_detection_with_custom_user_inheritance(self):\n        before_states = self.make_project_state([\n            author_with_user,\n            custom_user_no_inherit,\n        ])\n        after_states = self.make_project_state([\n            author_with_user,\n            custom_user,\n        ])\n        changes = self.get_changes(before_states, after_states)\n        self.assertNumberMigrations(changes, \"thirdapp\", 1)\n        self.assertMigrationDependencies(changes, \"thirdapp\", 0, [])\n        self.assertOperationTypes(changes, \"thirdapp\", 0, [\"CreateModel\"])\n        self.assertOperationFieldAttributes(changes, \"thirdapp\", 0, 0, username__field__max_length=255)\n\n\n\n"], "sample_1110": ["    def test_sympy_printing(self):\n        expr = Piecewise((x, x < 0), (x**2, x >= 0))\n        self.assertEqual(pycode(expr, standard='python3'), 'sympy.Piecewise((x, x < 0), (x**2, x >= 0))')\n        self.assertEqual(pycode(expr, standard='python2'), 'sympy.Piecewise((x, x < 0), (x**2, x >= 0))')\n        \n        expr = MatrixSolve(MatrixSymbol('A', 2, 2), MatrixSymbol('B', 2, 1))\n        self.assertEqual(pycode(expr, standard='python3'), 'sympy.matrices.MatrixSolve(A, B)')\n        self.assertEqual(pycode(expr, standard='python2'), 'sympy.matrices.MatrixSolve(A, B)')\n        \n        expr = SparseMatrix(((1, 0, 0), (0, 2, 0)), (2, 3))\n        self.assertEqual(pycode(expr, standard='python3'), 'sympy.matrices.SparseMatrix(((1, 0, 0), (0, 2, 0)), (2, 3))')\n        self.assertEqual(pycode(expr, standard='python2'), 'sympy.matrices.SparseMatrix(((1, 0, 0), (0, 2, 0)), (2, 3))')\n        \n        expr = Identity(2)\n        self.assertEqual(pycode(expr, standard='python3'), 'sympy.matrices.Identity(2)')\n        self.assertEqual(pycode(expr, standard='python2'), 'sympy.matrices.Identity(2)')\n        \n        expr = KroneckerDelta(x, y)\n        self.assertEqual(pycode(expr, standard='python3'), 'sympy.functions.KroneckerDelta(x, y)')\n        self.assertEqual(pycode(expr, standard='python2'), 'sympy.functions.KroneckerDelta(x, y)')\n        \n        expr = sqrt(x)\n        self.assertEqual(pycode(expr, standard='python3'), 'sympy.sqrt(x)')\n        self"], "sample_217": ["    def test_media_from_multiwidget(self):\n        class MyMultiWidget(MultiWidget):\n                super().__init__(*args, **kwargs)\n                self.widgets = [TextInput(), TextInput()]\n\n                return value\n\n        form = Form(\n            {\n                'field1': CharField(),\n            },\n            widgets={'field1': MyMultiWidget()}\n        )\n        self.assertEqual(form.media, Media(js=['http://media.example.com/static/js/my_multiwidget.js']))\n\n\n\n"], "sample_585": ["    def test_groupby_apply_with_dim(self, dim):\n        data = xr.Dataset({\n            \"a\": ((\"x\", \"y\"), np.arange(12).reshape(3, 4)),\n            \"b\": ((\"x\", \"y\"), np.arange(12).reshape(3, 4) + 1),\n        })\n        grouped = data.groupby(\"x\")\n\n            return ds.assign(c=ds[\"a\"] + ds[\"b\"])\n\n        result = grouped.apply(func, dim=dim)\n\n        if dim is None:\n            expected = xr.Dataset({\n                \"a\": ((\"x\", \"y\"), np.arange(12).reshape(3, 4)),\n                \"b\": ((\"x\", \"y\"), np.arange(12).reshape(3, 4) + 1),\n                \"c\": ((\"x\", \"y\"), np.arange(24).reshape(3, 4)),\n            })\n        else:\n            expected = xr.Dataset({\n                \"a\": ((\"y\"), np.arange(12).reshape(3, 4)),\n                \"b\": ((\"y\"), np.arange(12).reshape(3, 4) + 1),\n                \"c\": ((\"y\"), np.arange(24).reshape(3, 4)),\n            })\n\n        assert_identical(result, expected)\n\n\n\n"], "sample_459": ["    def test_integer_field_overflow_exceptions(self):\n        with self.assertRaises(IntegrityError):\n            self.model.objects.create(value=2147483648)\n        with self.assertRaises(IntegrityError):\n            self.model.objects.create(value=-2147483649)\n"], "sample_432": ["    def test_custom_paginator(self):\n        custom_site.register(OrderedObject, CustomPaginationAdmin)\n        response = self._mocked_authenticated_request(\n            reverse(\"admin:orderedobject_changelist\"), self.superuser\n        )\n        self.assertEqual(response.status_code, 200)\n        self.assertIn(\n            '<div class=\"pagination\">', response.content.decode(\"utf-8\")\n        )\n        self.assertIn(\n            '<ul class=\"pagination\">', response.content.decode(\"utf-8\")\n        )\n        self.assertIn(\n            '<li class=\"page-item\"><a class=\"page-link\" href=\"...\" aria-label=\"Previous\">',\n            response.content.decode(\"utf-8\"),\n        )\n        self.assertIn(\n            '<li class=\"page-item active\"><a class=\"page-link\" href=\"...\" aria-current=\"page\">1</a></li>',\n            response.content.decode(\"utf-8\"),\n        )\n        self.assertIn(\n            '<li class=\"page-item\"><a class=\"page-link\" href=\"...\" aria-label=\"Next\">',\n            response.content.decode(\"utf-8\"),\n        )\n\n\n\n"], "sample_547": ["    def test_offsetbox_padding(self):\n        fig, ax = plt.subplots()\n        bbox = OffsetBox(\n            DrawingArea(width=1, height=1),\n            loc='center',\n            pad=0.5,\n            borderpad=0.2\n        )\n        bbox.draw(ax.figure.canvas)\n        bbox_width, bbox_height = bbox.get_window_extent().width, bbox.get_window_extent().height\n        assert_allclose(bbox_width, 1.2)\n        assert_allclose(bbox_height, 1.2)\n        \n        bbox = OffsetBox(\n            DrawingArea(width=1, height=1),\n            loc='center',\n            pad=0.5,\n            borderpad=0.2\n        )\n        bbox.draw(ax.figure.canvas)\n        bbox_width, bbox_height = bbox.get_window_extent().width, bbox.get_window_extent().height\n        assert_allclose(bbox_width, 1.2)\n        assert_allclose(bbox_height, 1.2)\n"], "sample_225": ["    def test_available_apps_context(self):\n        self.assertIn('available_apps', self.ctx)\n        self.assertIsInstance(self.ctx['available_apps'], list)\n        self.assertEqual(len(self.ctx['available_apps']), 2)\n        self.assertIn({'name': 'auth', 'app_label': 'auth', 'app_url': '/test_admin/admin/auth/', 'has_module_perms': True, 'models': []}, self.ctx['available_apps'])\n        self.assertIn({'name': 'test_app', 'app_label': 'test_app', 'app_url': '/test_admin/admin/test_app/', 'has_module_perms': True, 'models': []}, self.ctx['available_apps'])\n"], "sample_1045": ["    def test_sympify_fractions():\n        assert sympify(fractions.Fraction(1, 2)) == Rational(1, 2)\n        assert sympify(fractions.Fraction(1, 3)) == Rational(1, 3)\n        assert sympify(fractions.Fraction(1, 0)) == S.Infinity\n        assert sympify(fractions.Fraction(0, 1)) == S.Zero\n"], "sample_754": ["    def test_sparse_pca_transform_ridge_alpha(norm_comp):\n        n_components = 3\n        n_samples = 100\n        image_size = (10, 10)\n        random_state = 42\n        X, U, V = generate_toy_data(n_components, n_samples, image_size, random_state)\n\n        sparse_pca = SparsePCA(n_components=n_components,\n                               normalize_components=norm_comp,\n                               ridge_alpha=0.1)\n        sparse_pca.fit(X)\n        X_transformed = sparse_pca.transform(X)\n\n        # Check if the transformed data has the correct shape\n        assert_equal(X_transformed.shape, (n_samples, n_components))\n\n        # Check if the transformed data is close to the original data\n        # projected onto the sparse components\n        if norm_comp:\n            assert_allclose(X_transformed, np.dot(X, sparse_pca.components_), atol=1e-3)\n        else:\n            assert_allclose(X_transformed, np.dot(X, sparse_pca.components_), atol=1e-2)\n\n        # Test with ridge_alpha=None\n        sparse_pca = SparsePCA(n_components=n_components,\n                               normalize_components=norm_comp)\n        sparse_pca.fit(X)\n        X_transformed = sparse_pca.transform(X)\n        assert_allclose(X_transformed, sparse_pca.transform(X, ridge_alpha=0.1), atol=1e-3)\n\n"], "sample_907": ["compilation error"], "sample_322": ["    def test_migration_plan_with_replacements(self):\n        with self.settings(MIGRATION_MODULES={\"migrations\": \"migrations.test_migrations\"}):\n            with self.connection.cursor() as cursor:\n                self.connection.introspection.execute_sql(\n                    \"CREATE TABLE migrations_test_migrations_0001_initial (id INT PRIMARY KEY)\"\n                )\n            self.loader = MigrationLoader(self.connection)\n            self.recorder = MigrationRecorder(self.connection)\n            self.executor = MigrationExecutor(\n                self.connection, progress_callback=lambda *args: None\n            )\n            self.executor.loader = self.loader\n            self.executor.recorder = self.recorder\n            self.loader.build_graph()\n            plan = self.executor.migration_plan(\n                [(\"migrations\", \"0001_initial\")], clean_start=True\n            )\n            self.assertEqual(len(plan), 1)\n            self.assertEqual(plan[0][0].name, \"0001_initial\")\n            self.assertFalse(plan[0][1])\n            self.loader.replace_migrations = True\n            self.loader.build_graph()\n            plan = self.executor.migration_plan(\n                [(\"migrations\", \"0001_initial\")], clean_start=True\n            )\n            self.assertEqual(len(plan), 1)\n            self.assertEqual(plan[0][0].name, \"0001_initial\")\n            self.assertFalse(plan[0][1])\n"], "sample_233": ["    def test_token_expiration(self):\n        user = User(username='testuser', email='test@example.com')\n        user.save()\n\n        generator = MockedPasswordResetTokenGenerator(datetime.now())\n        token = generator.make_token(user)\n\n        # Check that the token is valid immediately after creation\n        self.assertTrue(generator.check_token(user, token))\n\n        # Advance time past the password reset timeout\n        future_time = datetime.now() + timedelta(seconds=settings.PASSWORD_RESET_TIMEOUT + 1)\n        generator = MockedPasswordResetTokenGenerator(future_time)\n        self.assertFalse(generator.check_token(user, token))\n"], "sample_187": ["    def test_smart_split(self):\n        self.assertEqual(list(text.smart_split('This is \"a person\\'s\" test.')), ['This', 'is', '\"a person\\\\\\'s\"', 'test.'])\n        self.assertEqual(list(text.smart_split(r\"Another 'person\\'s' test.\")), ['Another', \"'person\\\\'s'\", 'test.'])\n        self.assertEqual(list(text.smart_split(r'A \"\\\"funky\\\" style\" test.')), ['A', '\"\\\\\"funky\\\\\" style\"', 'test.'])\n        self.assertEqual(list(text.smart_split('This is a \"quoted\" string')), ['This', 'is', 'a', '\"quoted\"', 'string'])\n        self.assertEqual(list(text.smart_split('This is a \\'quoted\\' string')), ['This', 'is', 'a', \"'quoted'\", 'string'])\n        self.assertEqual(list(text.smart_split('This is a \"quoted\" string with \\'single\\' quotes')), ['This', 'is', 'a', '\"quoted\"', 'string', 'with', \"'single'\", 'quotes'])\n        self.assertEqual(list(text.smart_split('This is a \\'quoted\\' string with \"double\" quotes')), ['This', 'is', 'a', \"'quoted'\", 'string', 'with', '\"double\"', 'quotes'])\n        self.assertEqual(list(text.smart_split('This is a \"quoted\" string with \\'single\\' and \"double\" quotes')), ['This', 'is', 'a', '\"quoted\"', 'string', 'with', \"'single'\", 'and', '\"double\"', 'quotes'])\n\n\n\n"], "sample_239": ["    def test_formset_factory_with_custom_kwargs(self):\n        class CustomForm(Form):\n            custom_field = CharField()\n\n        class CustomFormSet(BaseFormSet):\n                super().__init__(*args, **kwargs)\n                self.custom_kwargs = kwargs.get('custom_kwargs', {})\n\n        CustomFormSet = formset_factory(CustomForm, formset=CustomFormSet, custom_kwargs={'custom_value': 'test'})\n\n        formset = CustomFormSet()\n        self.assertEqual(formset.custom_kwargs, {'custom_value': 'test'})\n\n        formset_data = {'custom_field': 'test_value'}\n        formset = CustomFormSet(formset_data, custom_kwargs={'custom_override': 'override'})\n        self.assertEqual(formset.custom_kwargs, {'custom_value': 'test', 'custom_override': 'override'})\n"], "sample_999": ["    def test_latex_quotient_ring(self):\n        R = ring(ZZ, ideal(2))\n        self.assertEqual(latex(R), r\"\\frac{\\mathbb{Z}}{2\\mathbb{Z}}\")\n"], "sample_1081": ["    def test_is_abundant():\n        assert is_abundant(12) is True\n        assert is_abundant(28) is True\n        assert is_abundant(15) is False\n        assert is_abundant(20) is False\n        assert is_abundant(1) is False\n        assert is_abundant(2) is False\n        assert is_abundant(3) is False\n        assert is_abundant(4) is False\n        assert is_abundant(6) is False\n        assert is_abundant(7) is False\n        assert is_abundant(8) is False\n        assert is_abundant(9) is False\n        assert is_abundant(10) is False\n        assert is_abundant(11) is False\n        assert is_abundant(12) is True\n        assert is_abundant(13) is False\n        assert is_abundant(14) is False\n        assert is_abundant(16) is False\n        assert is_abundant(17) is False\n        assert is_abundant(18) is False\n        assert is_abundant(19) is False\n        assert is_abundant(20) is False\n        assert is_abundant(21) is False\n        assert is_abundant(22) is False\n        assert is_abundant(23) is False\n        assert is_abundant(24) is False\n        assert is_abundant(25) is False\n        assert is_abundant(26) is False\n        assert is_abundant(27) is False\n        assert is_abundant(28) is True\n        assert is_abundant(29) is False\n        assert is_abundant(30) is False\n        assert is_abundant(31) is False\n        assert is_abundant(32) is False\n        assert is_abundant(33) is False\n        assert is_abundant(34) is False\n        assert is_abundant(35) is False\n        assert is_abundant(36) is False\n        assert is_abundant(37) is False\n"], "sample_548": ["def test_colorbar_extension_length(tmpdir):\n    \"\"\"\n    Test that colorbar extensions have the correct length for different\n    spacing and extend settings.\n    \"\"\"\n    for spacing in ('uniform', 'proportional'):\n        fig = _colorbar_extension_length(spacing)\n        fig.savefig(f'{tmpdir}/colorbar_extension_length_{spacing}.png')\n\n\n\n"], "sample_388": ["    def test_remote_user_with_email(self):\n        with self.settings(REMOTE_USER=self.known_user, REMOTE_EMAIL=\"test@example.com\"):\n            response = self.client.get(\"/\")\n            self.assertEqual(response.status_code, 200)\n            user = authenticate(username=self.known_user)\n            self.assertIsNotNone(user)\n            self.assertEqual(user.email, \"test@example.com\")\n"], "sample_351": ["    def test_modelchoicefield_queryset_limit_choices_to(self):\n        with self.subTest('callable'):\n            class CallableLimitChoicesTo(forms.Form):\n                category = forms.ModelChoiceField(\n                    queryset=Category.objects.all(),\n                    limit_choices_to=lambda form: Category.objects.filter(name__startswith='T')\n                )\n\n            form = CallableLimitChoicesTo()\n            self.assertEqual(len(form.fields['category'].choices), 2)\n            self.assertIn(self.c2, form.fields['category'].choices)\n            self.assertIn(self.c3, form.fields['category'].choices)\n\n        with self.subTest('value'):\n            class ValueLimitChoicesTo(forms.Form):\n                category = forms.ModelChoiceField(\n                    queryset=Category.objects.all(),\n                    limit_choices_to='Entertainment'\n                )\n\n            form = ValueLimitChoicesTo()\n            self.assertEqual(len(form.fields['category'].choices), 1)\n            self.assertIn(self.c1, form.fields['category'].choices)\n"], "sample_870": ["    def test_predict_with_multi_output(kernel):\n        X_train = np.atleast_2d([1.0, 3.0, 5.0, 6.0, 7.0, 8.0]).T\n        y_train = np.array([[f(x) for x in X_train], [2 * f(x) for x in X_train]]).T\n        gpr = GaussianProcessRegressor(kernel=kernel, alpha=1e-10)\n        gpr.fit(X_train, y_train)\n\n        X_test = np.atleast_2d([2.0, 4.0, 5.5, 6.5, 7.5]).T\n        y_pred, _ = gpr.predict(X_test, return_cov=False)\n\n        assert y_pred.shape[1] == 2\n        assert_array_almost_equal(y_pred[:, 0], [2 * np.sin(x) for x in X_test])\n        assert_array_almost_equal(y_pred[:, 1], [4 * np.sin(x) for x in X_test])\n"], "sample_659": ["    def test_raises_with_contextmanager(self):\n        with dummy_context_manager():\n            raise ValueError(\"boom\")\n\n        with pytest.raises(ValueError) as excinfo:\n            with dummy_context_manager():\n                raise ValueError(\"boom\")\n        assert excinfo.value.args[0] == \"boom\"\n"], "sample_1162": ["    def test_count_ops_complex():\n        from sympy.core.complexnumbers import I\n        from sympy.functions import sin, cos, exp\n        assert count_ops(I, visual=True) == 'I'\n        assert count_ops(sin(I), visual=True) == 'SIN'\n        assert count_ops(cos(I), visual=True) == 'COS'\n        assert count_ops(exp(I), visual=True) == 'EXP'\n        assert count_ops(I*sin(I), visual=True) == 'MUL + SIN'\n        assert count_ops(I*sin(I) + cos(I), visual=True) == 'MUL + SIN + COS'\n        assert count_ops(I*sin(I) + cos(I) + exp(I), visual=True) == 'MUL + SIN + COS + EXP'\n"], "sample_819": ["    def test_voting_classifier_multilabel(self):\n        X, y = make_multilabel_classification(n_samples=100, n_features=10,\n                                              n_classes=3, random_state=42)\n        clf = VotingClassifier(estimators=[\n            ('lr', LogisticRegression(multi_class='multinomial')),\n            ('rf', RandomForestClassifier(random_state=42))\n        ], voting='soft')\n        with pytest.raises(NotImplementedError):\n            clf.fit(X, y)\n"], "sample_992": ["    def test_sparse_matrix(self):\n        mat = SparseMatrix(((1, 0, 2), (0, 1, 3)), (2, 3))\n        code = SciPyPrinter().doprint(mat)\n        assert code == \"scipy.sparse.coo_matrix([[1, 2], [0, 3]], ((0, 0), (0, 2), (1, 1)), shape=(2, 3))\"\n"], "sample_820": ["    def test_voting_classifier_multilabel(self):\n        X, y = make_multilabel_classification(n_samples=100, n_features=10,\n                                              n_classes=3,\n                                              random_state=42)\n        clf1 = LogisticRegression(multi_class='multinomial', random_state=42)\n        clf2 = RandomForestClassifier(random_state=42)\n        eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)],\n                                voting='hard')\n        with pytest.raises(NotImplementedError):\n            eclf.fit(X, y)\n"], "sample_140": ["    def test_sensitive_post_parameters_decorator(self):\n        @sensitive_post_parameters('password')\n            return 'OK'\n\n        view = my_view\n        request = RequestFactory().post({'password': 'secret', 'other': 'data'})\n        response = view(request)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(request.sensitive_post_parameters, ('password',))\n"], "sample_374": ["    def test_prefetch_related_with_nested_lookups(self):\n        with self.assertNumQueries(2):\n            qs = Reader.objects.prefetch_related(\n                Prefetch('books_read', queryset=Book.objects.prefetch_related(\n                    Prefetch('authors', to_attr='book_authors')\n                ))\n            )\n        for reader in qs:\n            for book in reader.books_read.all():\n                self.assertEqual(len(book.book_authors), 1)\n                self.assertIn(book.authors.first(), book.book_authors)\n\n\n\n"], "sample_88": ["    def test_sanitize_address(self):\n        self.assertEqual(sanitize_address(None), '')\n        self.assertEqual(sanitize_address('john.doe'), 'John Doe')\n        self.assertEqual(sanitize_address('john.doe@example.com'), 'John Doe <john.doe@example.com>')\n        self.assertEqual(sanitize_address('john doe <john.doe@example.com>'), 'John Doe <john.doe@example.com>')\n        self.assertEqual(sanitize_address(' \"John Doe\" <john.doe@example.com>'), 'John Doe <john.doe@example.com>')\n        self.assertEqual(sanitize_address('John Doe <john.doe@example.com>'), 'John Doe <john.doe@example.com>')\n        self.assertEqual(sanitize_address('John Doe <john.doe@example.com>'), 'John Doe <john.doe@example.com>')\n        self.assertEqual(sanitize_address('  John Doe <john.doe@example.com>  '), 'John Doe <john.doe@example.com>')\n        self.assertEqual(sanitize_address('John Doe <john.doe@example.com>\\n'), 'John Doe <john.doe@example.com>')\n        self.assertEqual(sanitize_address('John Doe <john.doe@example.com>\\r\\n'), 'John Doe <john.doe@example.com>')\n        self.assertEqual(sanitize_address('John Doe <john.doe@example.com>\\r'), 'John Doe <john.doe@example.com>')\n\n        # Test with invalid addresses\n        with self.assertRaises(ValueError):\n            sanitize_address('john doe')\n        with self.assertRaises(ValueError):\n            sanitize_address('john.doe@example')\n        with self.assertRaises(ValueError):\n            sanitize_address('john.doe@example.com@example.com')\n"], "sample_441": ["    def test_clean_password2_mismatch(self):\n        form = UserCreationForm(data={\"username\": \"test\", \"password1\": \"pass\", \"password2\": \"fail\"})\n        with self.assertRaises(ValidationError) as context:\n            form.clean()\n        self.assertEqual(context.exception.code, \"password_mismatch\")\n"], "sample_514": ["def test_colorbar_extension_length(tmpdir):\n    \"\"\"Test colorbar extensions with varying lengths.\"\"\"\n    for spacing in ('uniform', 'proportional'):\n        fig = _colorbar_extension_length(spacing)\n        fig.savefig(f'{tmpdir}/colorbar_extension_length_{spacing}.png')\n\n\n\n"], "sample_168": ["    def test_remove_stale_content_types_interactive(self):\n        with captured_stdout() as stdout:\n            call_command('remove_stale_content_types', interactive=True)\n        self.assertEqual(ContentType.objects.count(), self.before_count)\n        self.assertIn('Are you sure you want to delete these content types?', stdout.getvalue())\n"], "sample_306": ["    def test_parse_datetime_with_timezone_offset(self):\n        dt = parse_datetime('2023-10-26T14:30:00+05:30')\n        self.assertEqual(dt.year, 2023)\n        self.assertEqual(dt.month, 10)\n        self.assertEqual(dt.day, 26)\n        self.assertEqual(dt.hour, 14)\n        self.assertEqual(dt.minute, 30)\n        self.assertEqual(dt.second, 0)\n        self.assertEqual(dt.tzinfo, get_fixed_timezone(19800))\n"], "sample_378": ["    def test_bulk_update_with_related_objects(self):\n        self.create_tags()\n        notes = Note.objects.all()\n        for note in notes:\n            note.tags.add(*self.tags[:3])\n        notes = Note.objects.all()\n        notes.update(note='Updated Note', misc='Updated Misc')\n        for note in notes:\n            self.assertEqual(note.note, 'Updated Note')\n            self.assertEqual(note.misc, 'Updated Misc')\n            self.assertEqual(len(note.tags.all()), 3)\n"], "sample_1054": ["    def test_complex_region_intersection_polar(self):\n        r1 = ComplexRegion(Interval(0, 1)*Interval(0, pi), polar=True)\n        r2 = ComplexRegion(Interval(0.5, 1.5)*Interval(pi/2, 2*pi), polar=True)\n        self.assertEqual(r1.intersect(r2), ComplexRegion(Interval(0.5, 1)*Interval(pi/2, pi), polar=True))\n"], "sample_160": ["    def test_large_numbers(self):\n        for number in [1e100, -1e100, 1e300, -1e300]:\n            formatted_number = nformat(number, decimal_sep=',', decimal_pos=2)\n            self.assertEqual(formatted_number, str(number)[:100])\n"], "sample_1150": ["    def test_complex_region_from_real(self):\n        from sympy import Interval, ComplexRegion\n        unit = Interval(0,1)\n        region = ComplexRegion.from_real(unit)\n        self.assertEqual(region, CartesianComplexRegion(ProductSet(unit, FiniteSet(0))))\n\n        # Test with a non-subset of reals\n        with raises(ValueError):\n            ComplexRegion.from_real(S.Reals)\n\n\n\n"], "sample_84": ["    def test_urlencode_multivalue(self):\n        query = MultiValueDict({'key': ['value1', 'value2'], 'another': ['value3']})\n        encoded = urlencode(query)\n        self.assertEqual(encoded, 'key=value1&key=value2&another=value3')\n"], "sample_64": ["    def test_query_dict_mutable(self):\n        q = QueryDict('a=1&b=2')\n        q.update({'c': '3', 'd': '4'})\n        self.assertEqual(list(q.items()), [('a', '1'), ('b', '2'), ('c', '3'), ('d', '4')])\n\n        q.append('b', '5')\n        self.assertEqual(list(q.items()), [('a', '1'), ('b', ['2', '5']), ('c', '3'), ('d', '4')])\n\n        q.pop('b')\n        self.assertEqual(list(q.items()), [('a', '1'), ('c', '3'), ('d', '4')])\n\n        del q['a']\n        self.assertEqual(list(q.items()), [('c', '3'), ('d', '4')])\n"], "sample_79": ["    def test_pluralize_with_comma(self):\n        self.check_values(\n            (0, 'candies'),\n            (1, 'candy'),\n            (2, 'candies'),\n        )\n"], "sample_1039": ["    def test_matrix_symbol(self):\n        m = MatrixSymbol('A', 2, 2)\n        s = MathMLContentPrinter()\n        xml = s._print(m)\n        s.apply_patch()\n        pretty_xml = xml.toprettyxml()\n        s.restore_patch()\n        assert 'mfenced' in pretty_xml\n        assert 'mi' in pretty_xml\n        assert 'A' in pretty_xml\n\n        s = MathMLPresentationPrinter()\n        xml = s._print(m)\n        s.apply_patch()\n        pretty_xml = xml.toprettyxml()\n        s.restore_patch()\n        assert 'mfenced' in pretty_xml\n        assert 'mi' in pretty_xml\n        assert 'A' in pretty_xml\n"], "sample_705": ["    def test_testdir_run_with_plugins(self, testdir):\n        \"\"\"Test that plugins are loaded correctly when running pytest via Testdir.\"\"\"\n        p = testdir.makepyfile(\n            \"\"\"\n                pass\n            \"\"\"\n        )\n        testdir.make_plugin(\"myplugin\", \"test_one\")\n        result = testdir.runpytest()\n        assert result.ret == 0\n        assert len(result.passed) == 1\n\n\n\n"], "sample_607": ["    def test_build_engines_with_duplicate_entrypoints(\n        dummy_duplicated_entrypoints, monkeypatch, engine, expected_backend"], "sample_229": ["    def test_union_with_distinct(self):\n        self.assertNumbersEqual(\n            Number.objects.filter(num__gt=5).union(Number.objects.filter(num__lt=5)).distinct(),\n            [Number(num=6), Number(num=7), Number(num=8), Number(num=9), Number(num=10), Number(num=0), Number(num=1), Number(num=2), Number(num=3), Number(num=4)],\n            ordered=False\n        )\n\n\n\n"], "sample_790": ["    def test_kernel_pca_sparse_data(self):\n        n_samples = 100\n        n_features = 50\n        X, _ = make_circles(n_samples=n_samples, n_features=n_features,\n                            noise=0.1, random_state=42)\n        X_sparse = sp.csr_matrix(X)\n        pca = PCA(n_components=2)\n        kpca = KernelPCA(n_components=2, kernel='linear')\n\n        X_pca = pca.fit_transform(X)\n        X_kpca = kpca.fit_transform(X_sparse)\n\n        assert_allclose(X_pca, X_kpca)\n\n        # Test with a non-linear kernel\n        kpca = KernelPCA(n_components=2, kernel='rbf', gamma=0.1)\n        X_kpca = kpca.fit_transform(X_sparse)\n\n        assert_allclose(X_pca, X_kpca)\n"], "sample_997": ["    def test_repeated_decimals(self):\n        self.assertEqual(parse_expr(\"0.2[1]\"), Rational(21, 90))\n        self.assertEqual(parse_expr(\"0.12[34]\"), Rational(1234, 9990))\n        self.assertEqual(parse_expr(\"0.123[456]\"), Rational(123456, 999990))\n        self.assertEqual(parse_expr(\"0.123[456789]\"), Rational(123456789, 999999990))\n        self.assertEqual(parse_expr(\"1.234[567]\"), Rational(1234567, 999900))\n        self.assertEqual(parse_expr(\"0.123[4567890]\"), Rational(1234567890, 9999999990))\n        with raises(TokenError):\n            parse_expr(\"0.2[123]\")\n        with raises(TokenError):\n            parse_expr(\"0.2[1234]\")\n        with raises(TokenError):\n            parse_expr(\"0.2[12345678901234567890]\")\n"], "sample_735": ["    def test_covariance_estimation_tied(self):\n        rng = np.random.RandomState(0)\n        n_samples = 500\n        n_features = 2\n        n_components = 3\n        weights = rng.rand(n_components)\n        weights /= weights.sum()\n        means = rng.rand(n_components, n_features)\n        tied_covariance = make_spd_matrix(n_features, random_state=rng)\n        X = generate_data(n_samples, n_features, weights, means,\n                          {'tied': tied_covariance}, 'tied')\n\n        gmm = GaussianMixture(n_components=n_components,\n                             covariance_type='tied',\n                             reg_covar=1e-6)\n        gmm.fit(X)\n\n        assert_allclose(gmm.means_, means, atol=1e-2)\n        assert_allclose(gmm.precisions_cholesky_['tied'],\n                        linalg.cholesky(tied_covariance), atol=1e-2)\n"], "sample_400": ["    def test_detect_changes_with_field_rename(self):\n        before_states = self.make_project_state(\n            [\n                author_name_nested_deconstructible_extra_arg,\n                book,\n            ]\n        )\n        after_states = self.make_project_state(\n            [\n                author_name_nested_deconstructible_extra_arg.replace(\n                    \"name\", \"new_name\"\n                ),\n                book,\n            ]\n        )\n        changes = self.get_changes(before_states, after_states)\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertMigrationDependencies(changes, \"testapp\", 0, [])\n        self.assertOperationTypes(changes, \"testapp\", 0, [\"RemoveField\", \"AddField\"])\n        self.assertOperationAttributes(\n            changes,\n            \"testapp\",\n            0,\n            0,\n            name=\"name\",\n            model_name=\"Author\",\n        )\n        self.assertOperationAttributes(\n            changes,\n            \"testapp\",\n            0,\n            1,\n            name=\"new_name\",\n            model_name=\"Author\",\n        )\n\n"], "sample_927": ["    def test_cpp_domain_template_params(self):\n        input = \"template <typename T> void foo(T x) {}\"\n        output = \"template <typename T> void foo(T x) {}\"\n        idDict = {1: \"foo_1\", 2: \"foo_2\"}\n        check(\"function\", input, idDict, output)\n"], "sample_709": ["    def test_run_python_c(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n                return 42\n            \"\"\"\n        )\n        result = testdir.runpytest_subprocess(\n            \"--collectonly\", \"-c\", \"my_function()\"\n        )\n        assert result.ret == 0\n        assert len(result.out) > 0\n        assert \"my_function\" in result.out\n\n\n\n"], "sample_75": ["    def test_prefetch_related_with_m2m_field(self):\n        with CaptureQueriesContext() as queries:\n            reader1_books = Reader.objects.prefetch_related('books_read').get(name='Amy')\n            self.assertEqual(len(queries.captured_queries), 2)\n            self.assertWhereContains(queries.captured_queries[1], 'reader_id')\n\n            reader1_books = Reader.objects.prefetch_related('books_read').get(name='Amy')\n            self.assertEqual(len(queries.captured_queries), 2)\n            self.assertWhereContains(queries.captured_queries[1], 'reader_id')\n"], "sample_1003": ["    def test_domain_with_gens(self):\n        with raises(GeneratorsError):\n            Options((x, y), {'domain': ZZ.poly_ring(x, y)})\n"], "sample_989": ["    def test_sympify_complex():\n        assert sympify(complex(1, 2)) == S.One + 2*S.ImaginaryUnit\n        assert sympify(complex(1.2, 3.4)) == S.One + 2*S.ImaginaryUnit\n        assert sympify(complex(0, 0)) == S.Zero\n        assert sympify(complex(1, 0)) == S.One\n        assert sympify(complex(-1, 0)) == -S.One\n        assert sympify(complex(0, 1)) == S.ImaginaryUnit\n        assert sympify(complex(-1j)) == -S.ImaginaryUnit\n        assert sympify(complex(1j)) == S.ImaginaryUnit\n        assert sympify(complex(1.234j)) == 1.234*S.ImaginaryUnit\n\n\n\n"], "sample_828": ["    def test_pairwise_distances_chunked_with_reduce_func(self, metric):\n        n_samples = 100\n        n_features = 5\n        X = np.random.rand(n_samples, n_features)\n        Y = np.random.rand(n_samples, n_features)\n\n            return np.mean(D_chunk, axis=1)\n\n        with config_context({\"working_memory\": 10}):\n            gen = pairwise_distances_chunked(X, Y, metric=metric,\n                                            reduce_func=reduce_func)\n            for i in range(n_samples):\n                chunk = next(gen)\n                assert isinstance(chunk, np.ndarray)\n                assert chunk.shape[0] == n_samples\n                assert_allclose(chunk, np.mean(\n                    pairwise_distances(X[i:i+1], Y, metric=metric), axis=1))\n\n\n\n"], "sample_261": ["    def test_parse_datetime_with_postgres_interval(self):\n        dt = parse_datetime(\"3 days 04:05:06\")\n        self.assertEqual(dt.date(), date(2023, 10, 27))\n        self.assertEqual(dt.time(), time(4, 5, 6))\n        self.assertEqual(dt.tzinfo, get_fixed_timezone(0))\n"], "sample_835": ["    def test_adaboost_regressor_sparse_data(self):\n        X_sparse = csr_matrix(\n            [[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n        y = np.array([1, 2, 3])\n        reg = AdaBoostRegressor(n_estimators=10)\n        reg.fit(X_sparse, y)\n        y_pred = reg.predict(X_sparse)\n        assert_array_almost_equal(y_pred, y)\n"], "sample_221": ["    def test_prefetch_related_with_nested_lookups(self):\n        Container.objects.create(name='Container 1')\n        Container.objects.create(name='Container 2')\n\n        # Create some events\n        event1 = Event.objects.create(name='Event 1', container=Container.objects.first())\n        event2 = Event.objects.create(name='Event 2', container=Container.objects.first())\n        event3 = Event.objects.create(name='Event 3', container=Container.objects.last())\n\n        # Create some groups\n        group1 = Group.objects.create(name='Group 1')\n        group2 = Group.objects.create(name='Group 2')\n\n        # Create some happenings\n        happening1 = Happening.objects.create(name='Happening 1', event=event1, group=group1)\n        happening2 = Happening.objects.create(name='Happening 2', event=event2, group=group2)\n        happening3 = Happening.objects.create(name='Happening 3', event=event3, group=group1)\n\n        # Pre-fetch related objects\n        containers = Container.objects.prefetch_related(\n            'events',\n            'events__happenings',\n            'events__happenings__group'\n        )\n\n        # Verify the pre-fetched data\n        for container in containers:\n            for event in container.events.all():\n                for happening in event.happenings.all():\n                    self.assertEqual(happening.group, happening.event.container.events.get(id=event.id).group)\n\n\n\n"], "sample_1168": ["    def test_multiset_partitions_taocp():\n        from sympy.utilities.enumerative import multiset_partitions_taocp\n        for n in range(5):\n            for s in multiset_partitions_taocp(n, 3):\n                assert len(s) == 3\n                assert sum(s) == n\n    \n"], "sample_317": ["    def test_atom_feed_with_enclosures(self):\n        feed = Atom1Feed(\n            title=\"My Feed\",\n            link=\"http://example.com/\",\n            description=\"This is my feed.\",\n            items=[\n                {\n                    'title': 'My first entry',\n                    'link': 'http://example.com/1',\n                    'enclosures': [Enclosure('http://example.com/image.jpg', '1024', 'image/jpeg')],\n                },\n            ],\n        )\n        xml = feed.writeString('utf-8')\n        dom = minidom.parseString(xml)\n        self.assertChildNodes(dom.documentElement, ['entry'])\n        entry = dom.getElementsByTagName('entry')[0]\n        self.assertChildNodes(entry, ['title', 'link', 'id', 'published', 'updated', 'summary', 'link'])\n        self.assertChildNodeContent(entry, {\n            'title': 'My first entry',\n            'link': 'http://example.com/',\n            'id': 'tag:example.com,2008-01-02T12:30:00Z',\n            'published': '2006-03-17T18:00:00Z',\n            'updated': '2008-01-02T12:30:00Z',\n            'summary': 'This is my feed.',\n        })\n        enclosure = entry.getElementsByTagName('link')[1]\n        self.assertEqual(enclosure.getAttribute('rel'), 'enclosure')\n        self.assertEqual(enclosure.getAttribute('href'), 'http://example.com/image.jpg')\n        self.assertEqual(enclosure.getAttribute('length'), '1024')\n        self.assertEqual(enclosure.getAttribute('type'), 'image/jpeg')\n\n\n\n"], "sample_554": ["    def test_annotation_offset_coords(self):\n        fig, ax = plt.subplots()\n\n        # Test offset coordinates\n        annotation = Annotation(\"Test\", (0.5, 0.5), xycoords='data',\n                                textcoords='offset points',\n                                arrowprops=dict(arrowstyle='->'))\n        annotation.set_position((0.5, 0.5) + (10, 0))\n        ax.add_artist(annotation)\n\n        plt.show()\n\n\n\n"], "sample_1178": ["    def test_function_call(self):\n        fcall = FunctionCall('foo', [x, y])\n        self.assertEqual(str(fcall), 'foo(x, y)')\n\n        fcall = FunctionCall('bar', [1, 2, 3])\n        self.assertEqual(str(fcall), 'bar(1, 2, 3)')\n\n        fcall = FunctionCall('baz', [])\n        self.assertEqual(str(fcall), 'baz()')\n\n\n\n"], "sample_427": ["    def test_formset_factory_with_renderer(self):\n        renderer = TemplatesSetting(\n            \"django/forms/formsets/div.html\",\n            \"django/forms/formsets/p.html\",\n            \"django/forms/formsets/table.html\",\n            \"django/forms/formsets/ul.html\",\n        )\n        CustomFormSet = formset_factory(\n            CustomKwargForm, renderer=renderer\n        )\n        formset = CustomFormSet(\n            {\"custom_kwarg\": \"test_value\"}, prefix=\"custom_formset\"\n        )\n        self.assertEqual(formset.renderer, renderer)\n        self.assertEqual(formset.template_name, renderer.formset_template_name)\n"], "sample_367": ["    def test_cache_page_decorator(self):\n        @cache_page(timeout=3600)\n            return HttpResponse('Hello, world!')\n\n        response = view(HttpRequest())\n        self.assertEqual(response.status_code, 200)\n        self.assertIn('Cache-Control', response)\n        self.assertIn('max-age=3600', response['Cache-Control'])\n"], "sample_1051": ["    def test_dotprint_float():\n        f = Float('1.234')\n        dot = dotprint(f)\n        assert 'Float(1.234)' in dot\n        assert 'shape=\"ellipse\"' in dot\n    "], "sample_129": ["    def test_floatformat_with_negative_precision(self):\n        with localcontext() as ctx:\n            ctx.prec = 3\n            self.assertEqual(floatformat(Decimal('1.23456789'), -1), '1')\n            self.assertEqual(floatformat(Decimal('1.23456789'), -2), '1.23')\n            self.assertEqual(floatformat(Decimal('1.23456789'), -3), '1.234')\n\n\n\n"], "sample_235": ["    def test_on_commit_in_atomic_block(self):\n        with transaction.atomic():\n            self.do(1)\n            self.do(2)\n        self.assertNotified([1, 2])\n\n"], "sample_671": ["    def test_xfail_strict(self):\n        item = runtestprotocol.TestItem()\n        item._store[MarkEvaluator.key] = MarkEvaluator(item, \"xfail\", condition=True, strict=True)\n        pytest_runtest_setup(item)\n        assert item._store[MarkEvaluator.key].istrue()\n        assert item._store[MarkEvaluator.key].get(\"strict\") is True\n        assert item._store[MarkEvaluator.key].getexplanation() is not None\n"], "sample_874": ["    def test_step_selector_fit_transform(self):\n        selector = StepSelector(step=2)\n        selector.fit(X, y)\n        assert_array_equal(selector.transform(X), Xt)\n        assert_array_equal(selector.get_support(), support)\n        assert_array_equal(selector.get_feature_names_out(), feature_names_t)\n"], "sample_667": ["    def test_getbasetemp_from_env(tmp_path_factory):\n        os.environ[\"PYTEST_DEBUG_TEMPROOT\"] = \"/tmp/pytest-debug\"\n        basetemp = tmp_path_factory.getbasetemp()\n        assert basetemp.exists()\n        assert basetemp.parent == pathlib.Path(\"/tmp\")\n        assert basetemp.name.startswith(\"pytest-\")\n        del os.environ[\"PYTEST_DEBUG_TEMPROOT\"]\n"], "sample_1078": ["    def test_idx_bounds_invalid(self):\n        with raises(TypeError):\n            Idx('i', 'a')\n        with raises(TypeError):\n            Idx('i', [1, 2, 3])\n        with raises(TypeError):\n            Idx('i', (1, 2, 3))\n        with raises(TypeError):\n            Idx('i', (1, 'a'))\n        with raises(TypeError):\n            Idx('i', (1, oo + 1))\n        with raises(TypeError):\n            Idx('i', (oo, -oo))\n\n\n\n"], "sample_658": ["    def test_setup_fixtures(self, doctest_namespace):\n        doctest_item = DoctestItem(\n            name=\"test\", parent=object(), runner=None, dtest=None\n        )\n        fixture_request = _setup_fixtures(doctest_item)\n        assert fixture_request is not None\n        assert isinstance(fixture_request, FixtureRequest)\n        assert fixture_request.function is None\n        assert fixture_request.cls is None\n        assert fixture_request.node is doctest_item\n        assert fixture_request.funcargs == {}\n        assert fixture_request._fixtureinfo is not None\n        doctest_namespace[\"fixture_value\"] = \"fixture_value\"\n        assert fixture_request.getfixturevalue(\"fixture_value\") == \"fixture_value\"\n"], "sample_1013": ["    def test_lambdify_with_numpy_and_numexpr():\n        if not numexpr:\n            skip(\"numexpr not available\")\n        f = lambdify((x, y), x**2 + y**2, modules=['numexpr'])\n        assert f(2, 3) == 13\n"], "sample_725": ["    def test_check_is_fitted_with_custom_msg(self):\n        class CustomEstimator:\n                pass\n\n        estimator = CustomEstimator()\n        with assert_raises_regex(NotFittedError,\n                                 \"Estimator, CustomEstimator, must be fitted\"):\n            check_is_fitted(estimator, \"coef_\",\n                            msg=\"Estimator, %(name)s, must be fitted\")\n\n\n\n"], "sample_350": ["    def test_union_with_distinct(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\"CREATE TEMP TABLE temp_numbers (num INTEGER, other_num INTEGER)\")\n            cursor.execute(\"INSERT INTO temp_numbers SELECT num, other_num FROM django_test_number\")\n\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT DISTINCT num FROM temp_numbers\")\n            distinct_numbers = [row[0] for row in cursor.fetchall()]\n\n        numbers = Number.objects.union(Number.objects.filter(num__gt=5).distinct())\n        self.assertNumbersEqual(numbers, distinct_numbers)\n\n\n\n"], "sample_875": ["    def test_brier_score_loss_with_string_labels():\n        y_true = np.array([\"spam\", \"ham\", \"ham\", \"spam\"])\n        y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n        with pytest.raises(ValueError):\n            brier_score_loss(y_true, y_prob)\n        brier_score_loss(y_true, y_prob, pos_label=\"ham\")\n"], "sample_294": ["    def test_reject_request_with_bad_origin(self):\n        req = self._get_POST_csrf_cookie_request()\n        req.META['HTTP_ORIGIN'] = 'http://badhost.com'\n        middleware = CsrfViewMiddleware()\n        response = middleware.process_request(req, token_view)\n        self.assertEqual(response.status_code, 403)\n        self.assertIn(REASON_BAD_ORIGIN % 'http://badhost.com', response.content.decode())\n\n"], "sample_696": ["    def test_deprecated_collect_module(pytester: Pytester):\n        pytester.raises(\n            PytestDeprecationWarning,\n            lambda: getattr(pytest.collect, \"my_nonexistent_method\"),\n        )\n"], "sample_382": ["    def test_watch_for_template_changes(self, mock_reset_loaders):\n        autoreload.start()\n\n        # Create a template file in the extra templates directory\n        (EXTRA_TEMPLATES_DIR / \"test_template.html\").write(\"Hello, world!\")\n\n        # Assert that reset_loaders was called\n        mock_reset_loaders.assert_called_once()\n"], "sample_728": ["    def test_make_biclusters_shape(self):\n        shape = (10, 10)\n        n_clusters = 3\n        X, _, _ = make_biclusters(shape, n_clusters)\n        assert_equal(X.shape, shape)\n"], "sample_85": ["    def test_m2m_through_field_name(self):\n        class CustomModel(models.Model):\n            name = models.CharField(max_length=255)\n\n        class M2MThroughModel(models.Model):\n            custom_model = models.ForeignKey(CustomModel, on_delete=models.CASCADE)\n            related_model = models.ForeignKey(M2MFrom, on_delete=models.CASCADE)\n\n        class M2MFrom(models.Model):\n            name = models.CharField(max_length=255)\n\n        m2m_field = models.ManyToManyField(\n            M2MFrom,\n            through=M2MThroughModel,\n            through_fields=('custom_model', 'related_model'),\n        )\n        m2m_field.contribute_to_class(CustomModel, 'm2m_field')\n        self.assertEqual(CustomModel.m2m_field.m2m_field_name(), 'custom_model')\n        self.assertEqual(CustomModel.m2m_field.m2m_reverse_field_name(), 'related_model')\n\n\n\n"], "sample_486": ["    def test_inline_formset_with_auto_pk_parent(self):\n        AutoPKParent.objects.create(name=\"Parent 1\")\n        AutoPKChildOfUUIDPKParent.objects.create(\n            parent=AutoPKParent.objects.first(), name=\"Child 1\"\n        )\n        AutoPKChildOfUUIDPKParent.objects.create(\n            parent=AutoPKParent.objects.first(), name=\"Child 2\"\n        )\n\n        FormSet = inlineformset_factory(\n            AutoPKParent,\n            AutoPKChildOfUUIDPKParent,\n            fields=(\"name\",),\n            extra=1,\n        )\n\n        formset = FormSet(data=[{\"name\": \"Child 3\"}])\n        self.assertTrue(formset.is_valid())\n        formset.save()\n\n        self.assertEqual(AutoPKChildOfUUIDPKParent.objects.count(), 3)\n        self.assertEqual(\n            AutoPKChildOfUUIDPKParent.objects.last().name, \"Child 3\"\n        )\n\n\n\n"], "sample_968": ["    def test_parse_annotation(self):\n        assert _parse_annotation('int') == ('int', None)\n        assert _parse_annotation('int, str') == ('int, str', None)\n        assert _parse_annotation('int: str') == ('int', 'str')\n        assert _parse_annotation('int -> str') == ('int', 'str')\n        assert _parse_annotation('int -> None') == ('int', 'None')\n        assert _parse_annotation('int -> list[str]') == ('int', 'list[str]')\n        assert _parse_annotation('int -> typing.List[str]') == ('int', 'typing.List[str]')\n        assert _parse_annotation('int -> Optional[str]') == ('int', 'Optional[str]')\n        assert _parse_annotation('int -> Union[str, int]') == ('int', 'Union[str, int]')\n\n\n\n"], "sample_397": ["    def test_invalid_template_loader(self):\n        with self.assertRaises(ImproperlyConfigured):\n            Engine(loaders=[\"invalid_loader\"])\n"], "sample_1163": ["    def test_polar_lift_evalf():\n        from sympy.functions.elementary.complexes import polar_lift\n        z = polar_lift(2 + 3*I)\n        assert N_equals(z.evalf(), 2 + 3*I)\n        z = polar_lift(2*I)\n        assert N_equals(z.evalf(), 2*I)\n        z = polar_lift(-2*I)\n        assert N_equals(z.evalf(), -2*I)\n        z = polar_lift(2*I*pi)\n        assert N_equals(z.evalf(), 2*pi*I)\n        z = polar_lift(-2*I*pi)\n        assert N_equals(z.evalf(), -2*pi*I)\n        z = polar_lift(2*I*pi*I)\n        assert N_equals(z.evalf(), 2*pi*I**2)\n        z = polar_lift(2*I*pi*I*I)\n        assert N_equals(z.evalf(), 2*pi*I**3)\n        z = polar_lift(2*I*pi*I*I*I)\n        assert N_equals(z.evalf(), 2*pi*I**4)\n\n\n\n"], "sample_704": ["    def test_iterparentnodeids_empty(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n                pass\n            \"\"\"\n        )\n        item = p.getitems()[0]\n        assert list(nodes.iterparentnodeids(item.nodeid)) == [\"\"]\n"], "sample_425": ["    def test_serialize_datetime_with_timezone(self):\n        now = datetime.datetime.now(zoneinfo.ZoneInfo(\"America/New_York\"))\n        serializer = DateTimeSerializer(now)\n        serialized, imports = serializer.serialize()\n        self.assertEqual(\n            serialized,\n            \"datetime.datetime(2023, 10, 26, 14, 37, 42, 123456, tzinfo=datetime.timezone(datetime.timedelta(hours= -5)))\",\n            \"Datetime serialization with timezone should be correct\",\n        )\n        self.assertEqual(imports, {\"import datetime\"}, \"Imports should be correct\")\n\n\n\n"], "sample_176": ["    def test_migration_detection_with_custom_user_inheritance(self):\n        before_states = [\n            ModelState(\"thirdapp\", \"CustomUser\", [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"username\", models.CharField(max_length=255)),\n            ], bases=(AbstractBaseUser,)),\n            ModelState(\"testapp\", \"Author\", [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=200)),\n            ]),\n        ]\n        after_states = [\n            ModelState(\"thirdapp\", \"CustomUser\", [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"username\", models.CharField(max_length=255)),\n            ]),\n            ModelState(\"testapp\", \"Author\", [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=200)),\n            ]),\n        ]\n        changes = self.get_changes(before_states, after_states)\n        self.assertNumberMigrations(changes, \"thirdapp\", 0)\n        self.assertNumberMigrations(changes, \"testapp\", 0)\n\n\n\n"], "sample_990": ["    def test_acsch_eval_rewrite_as_log():\n        from sympy.functions.special.hyperbolic import acsch\n        x = Symbol('x')\n        assert acsch(x)._eval_rewrite_as_log(x) == log(1/x + sqrt(1/x**2 + 1))\n        assert acsch(2)._eval_rewrite_as_log(2) == log(1/2 + sqrt(1/4 + 1))\n        assert acsch(-2)._eval_rewrite_as_log(-2) == log(1/-2 + sqrt(1/4 + 1))\n        assert acsch(S.ImaginaryUnit)._eval_rewrite_as_log(S.ImaginaryUnit) == log(1/S.ImaginaryUnit + sqrt(1/S.ImaginaryUnit**2 + 1))\n"], "sample_745": ["compilation error"], "sample_496": ["    def test_custom_settings(self):\n        self.write_settings('settings.py', sdict={'CUSTOM_VAR': 'custom_value'})\n        with open(os.path.join(self.test_dir, 'custom_templates', 'custom_template.html'), 'w') as f:\n            f.write('This is a custom template')\n        with mock.patch('django.conf.settings.TEMPLATES', [\n            {'BACKEND': 'django.template.backends.django.DjangoTemplates',\n             'DIRS': [custom_templates_dir],\n             'APP_DIRS': True,\n             'OPTIONS': {}},\n        ]) as mock_templates:\n            call_command('runserver', '--noreload', '--settings', 'admin_scripts.test_admin_scripts.test_project.settings')\n            self.assertIn('This is a custom template', subprocess.check_output(['curl', 'http://127.0.0.1:8000/']))\n        self.remove_settings('settings.py')\n        shutil.rmtree(custom_templates_dir)\n\n\n\n"], "sample_1086": ["    def test_print_MatrixSymbol(self):\n        self.assertEqual(sstr(MatrixSymbol('A', 2, 3)), 'MatrixSymbol(\"A\", 2, 3)')\n        self.assertEqual(sstr(MatrixSymbol('B', 1)), 'MatrixSymbol(\"B\", 1)')\n"], "sample_293": ["compilation error"], "sample_668": ["    def test_deprecated_warnings():\n        with pytest.warns(deprecated.FUNCARGNAMES) as warning:\n            inspect.getmembers(nodes.Node)\n        assert warning[0].category is deprecated.PytestDeprecationWarning\n"], "sample_1080": ["    def test_refine_Piecewise():\n        from sympy.assumptions.refine import refine\n        p = Piecewise((x, x > 0), (x**2, x <= 0))\n        assert refine(p, Q.positive(x)) == x\n        assert refine(p, Q.negative(x)) == x**2\n"], "sample_801": ["    def test_repr_pipeline(self):\n        pipeline = make_pipeline(\n            StandardScaler(),\n            LogisticRegression(random_state=42)\n        )\n        repr_ = pipeline.__repr__()\n        expected_repr = (\n            \"Pipeline(steps=[('standardscaler', \"\n            \"StandardScaler()), \"\n            \"('logisticregression', LogisticRegression(random_state=42))])\"\n        )\n        assert repr_ == expected_repr\n"], "sample_155": ["    def test_file_response_with_content_type(self):\n        with tempfile.NamedTemporaryFile(mode='w+b') as temp_file:\n            temp_file.write(b'some content')\n            temp_file.seek(0)\n            response = FileResponse(temp_file, content_type='text/plain')\n            self.assertEqual(response['Content-Type'], 'text/plain')\n"], "sample_985": ["    def test_minmax_as_Piecewise():\n        from sympy.functions.elementary.piecewise import Piecewise\n        from sympy.core.relational import Equality, Relational\n        from sympy.core.numbers import S\n        a = symbols('a b c')\n        assert (Max(a, b, c)._eval_rewrite_as_Piecewise(a, b, c) ==\n                Piecewise((a, Relational(a, b, \">=\") & Relational(a, c, \">=\")),\n                          (b, Relational(b, a, \">=\") & Relational(b, c, \">=\")),\n                          (c, True)))\n        assert (Min(a, b, c)._eval_rewrite_as_Piecewise(a, b, c) ==\n                Piecewise((a, Relational(a, b, \"<=\") & Relational(a, c, \"<=\")),\n                          (b, Relational(b, a, \"<=\") & Relational(b, c, \"<=\")),\n                          (c, True)))\n"], "sample_178": ["    def test_formset_factory_with_absolute_max(self):\n        with self.assertRaises(ValueError):\n            formset_factory(Choice, max_num=100, absolute_max=99)\n"], "sample_1091": ["    def test_rel_with_symbols():\n        for op in ['==', '!=', '>', '<', '>=', '<=']:\n            a = Symbol('a')\n            b = Symbol('b')\n            r = eval(f'{a} {op} {b}')\n            assert r.is_Relational\n            assert r.args[0] is a\n            assert r.args[1] is b\n            assert r.func.__name__ == op\n\n\n\n"], "sample_856": ["    def test_train_test_split_sparse_output_type(self):\n        X = coo_matrix((np.ones(10), (range(10), range(10))))\n        y = np.arange(10)\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n        assert isinstance(X_train, csr_matrix)\n        assert isinstance(X_test, csr_matrix)\n"], "sample_811": ["    def test_pairwise_distances_chunked_reduce_func(metric):\n        X = np.random.rand(100, 5)\n        n_jobs = 2\n        chunk_size = 10\n\n            return np.mean(D_chunk, axis=1)\n\n        with config_context({'working_memory': 100}):\n            gen = pairwise_distances_chunked(X, reduce_func=reduce_func,\n                                            n_jobs=n_jobs, metric=metric)\n            for i in range(10):\n                chunk = next(gen)\n                assert chunk.shape[0] == chunk_size\n                assert chunk.shape[1] == chunk_size\n"], "sample_850": ["    def test_additive_chi2_sampler_sparse(self):\n        X_sparse = csr_matrix(X)\n        sampler = AdditiveChi2Sampler(sample_steps=2)\n        X_transformed = sampler.fit_transform(X_sparse)\n        assert isinstance(X_transformed, csr_matrix)\n        assert X_transformed.shape[1] == X.shape[1] * 6\n\n\n\n"], "sample_83": ["    def test_filter_registration(self):\n        @self.library.filter\n            return value.upper()\n\n        self.assertIn('my_filter', self.library.filters)\n        self.assertEqual(self.library.filters['my_filter'], my_filter)\n"], "sample_1147": ["    def test_multiline_latex_with_symbols(self):\n        from sympy import symbols\n        x, y, z = symbols('x y z')\n        expr = x**2 + y*z + 2*z**3\n        result = multiline_latex(x, expr, terms_per_line=2)\n        expected = r'\\begin{align*}"], "sample_199": ["    def test_exists_with_subquery(self):\n        subquery = Book.objects.filter(rating__gt=4).values('isbn')\n        exists_query = Book.objects.filter(isbn__in=Exists(subquery))\n        self.assertEqual(exists_query.count(), 3)\n"], "sample_940": ["    def test_signature_from_str_with_defaults(self):\n        code = 'def func(a: int = 42, b: str = \"hello\") -> str: pass'\n        sig = inspect.signature_from_str(code)\n        expected_sig = inspect.Signature(\n            parameters=[\n                Parameter('a', Parameter.POSITIONAL_OR_KEYWORD, default=42, annotation=int),\n                Parameter('b', Parameter.POSITIONAL_OR_KEYWORD, default=\"hello\", annotation=str),\n            ],\n            return_annotation=str\n        )\n        assert sig == expected_sig\n"], "sample_876": ["    def test_partial_fit_incremental_with_sparse_data(self):\n        X_sparse = csr_matrix(X_digits)\n        y = y_digits\n        clf = MLPClassifier(solver='lbfgs', random_state=0)\n        clf.partial_fit(X_sparse, y)\n        clf.partial_fit(X_sparse, y)\n        assert_almost_equal(clf.score(X_sparse, y), clf.score(X_digits, y_digits))\n\n"], "sample_736": ["    def test_logistic_regression_cv_multiclass_ovr(self):\n        X, y = make_classification(n_samples=100, n_features=20,\n                                   n_informative=10, n_redundant=5,\n                                   n_classes=3, random_state=42)\n        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n        clf = LogisticRegressionCV(Cs=10, cv=cv, solver='lbfgs',\n                                   multi_class='ovr', random_state=42)\n        clf.fit(X, y)\n        assert_equal(clf.coef_.shape, (3, 20))\n        assert_equal(clf.intercept_.shape, (3,))\n        assert_equal(clf.Cs_.shape, (10,))\n        assert_equal(clf.n_iter_.shape, (3, 5, 10))\n"], "sample_836": ["compilation error"], "sample_859": ["    def test_multi_task_elastic_net_cv_with_l1_ratio_list(self):\n        X, y = load_boston(return_X_y=True)\n        X = check_array(X, dtype=np.float64, order='F')\n        y = check_array(y, dtype=np.float64)\n        n_targets = y.shape[1]\n\n        # Test with a list of l1_ratio values\n        clf = MultiTaskElasticNetCV(l1_ratio=[0.1, 0.5, 0.9], cv=5)\n        clf.fit(X, y)\n        assert clf.l1_ratio_ is not None\n        assert clf.alpha_ is not None\n        assert clf.mse_path_.shape[0] == clf.n_alphas\n\n        # Check that the best l1_ratio is selected\n        best_l1_ratio = clf.l1_ratio_\n        best_mse = clf.mse_path_[clf.n_alphas // 2, :]\n        for l1_ratio in clf.l1_ratio:\n            clf = MultiTaskElasticNetCV(l1_ratio=l1_ratio, cv=5)\n            clf.fit(X, y)\n            mse = clf.mse_path_[clf.n_alphas // 2, :]\n            assert mse[best_l1_ratio] <= mse[l1_ratio]\n\n\n\n"], "sample_752": ["    def test_contamination_auto(self):\n        X, y = iris.data, iris.target\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n        # Test with contamination='auto'\n        clf1 = IsolationForest(contamination='auto', random_state=42)\n        clf1.fit(X_train)\n        y_pred1 = clf1.predict(X_test)\n\n        # Test with contamination=0.1\n        clf2 = IsolationForest(contamination=0.1, random_state=42)\n        clf2.fit(X_train)\n        y_pred2 = clf2.predict(X_test)\n\n        # Check if predictions are similar\n        assert_array_equal(y_pred1, y_pred2)\n\n        # Check if the threshold is correctly set\n        assert_greater(clf1.threshold_, clf2.threshold_)\n"], "sample_672": ["    def test_saferepr_exception(monkeypatch):\n        class MyException(Exception):\n            pass\n\n        class MyClass:\n                raise MyException()\n\n        obj = MyClass()\n        result = saferepr(obj)\n        assert \"<[MyException raised in repr()] MyClass object at 0x...\" in result\n"], "sample_596": ["    def test_concat_dataset_with_different_coords(\n        self,"], "sample_923": ["    def test_enum_declaration(self):\n        check('enum', 'enum MyEnum { VALUE1, VALUE2 }',\n              {'1': 'MyEnum.VALUE1', '2': 'MyEnum.VALUE2'},\n              'MyEnum: MyEnum.VALUE1, MyEnum.VALUE2')\n"], "sample_569": ["    def test_regplot_dropna(self):\n        with pytest.raises(ValueError):\n            lm.regplot(x=\"x\", y=\"y_na\", data=self.df, dropna=False)\n        ax = lm.regplot(x=\"x\", y=\"y\", data=self.df, dropna=True)\n        assert ax.lines[0].get_data()[0].size == 50\n        assert ax.scatter.get_offsets().size == 50\n"], "sample_413": ["    def test_check_setting_app_dirs_loaders(self):\n        with self.subTest(\"app_dirs and loaders\"):\n            errors = check_setting_app_dirs_loaders(None, **{})\n            self.assertEqual(errors, [E001])\n\n        with self.subTest(\"no app_dirs\"):\n            settings_no_app_dirs = deepcopy(self.TEMPLATES_APP_DIRS_AND_LOADERS)\n            settings_no_app_dirs[0][\"APP_DIRS\"] = False\n            errors = check_setting_app_dirs_loaders(None, **{})\n            self.assertEqual(errors, [])\n\n        with self.subTest(\"no loaders\"):\n            settings_no_loaders = deepcopy(self.TEMPLATES_APP_DIRS_AND_LOADERS)\n            del settings_no_loaders[0][\"OPTIONS\"][\"loaders\"]\n            errors = check_setting_app_dirs_loaders(None, **{})\n            self.assertEqual(errors, [])\n"], "sample_724": ["compilation error"], "sample_1123": ["    def test_conditionset_subs_dummy_symbol(self):\n        cs = ConditionSet(x, x < 1, {x, y})\n        cs_subs = cs.subs(x, y)\n        assert cs_subs.sym == y\n        assert cs_subs.condition == y < 1\n        assert cs_subs.base_set == FiniteSet(y, z)\n\n        cs_subs_again = cs_subs.subs(y, L)\n        assert cs_subs_again.sym == L\n        assert cs_subs_again.condition == L < 1\n        assert cs_subs_again.base_set == FiniteSet(L, z)\n\n        with warns_deprecated_sympy(\n                feature=\"Using {} for condition\".format(FiniteSet(1, 2)),\n                issue=17651,\n                deprecated_since_version='1.5',\n                useinstead=\"{} for condition\".format(Eq(1, 1) & Eq(2, 2))\n                ):\n            cs_finite = ConditionSet(x, x < 1, FiniteSet(1, 2))\n        assert cs_finite.condition == Eq(1, 1) & Eq(2, 2)\n"], "sample_9": ["    def test_write_table_id(self, html_table_id):\n        data = np.array([[1, 2], [3, 4]])\n        table = Table(data=data)\n        table.meta['name'] = 'my_table'\n        html_writer = html.HTML(htmldict={'table_id': html_table_id})\n        html_output = html_writer.write(table)\n        if html_table_id is not None:\n            assert f'id=\"{html_table_id}\"' in html_output[0]\n        else:\n            assert 'id' not in html_output[0]\n\n\n\n"], "sample_348": ["    def test_raw_id_fields_in_inlines(self):\n        class InlineWithRawId(TabularInline):\n            model = ValidationTestInlineModel\n            extra = 1\n            fields = ['raw_id', 'name']\n\n        class ValidationTestAdmin(ModelAdmin):\n            inlines = [InlineWithRawId]\n\n        self.assertIsInvalid(\n            ValidationTestAdmin(ValidationTestModel, AdminSite()),\n            ValidationTestModel,\n            r\"Field 'raw_id' on model 'ValidationTestInlineModel' has 'raw_id_fields' set, but it is not a ForeignKey.\",\n            id='raw_id_fields_in_inlines',\n        )\n"], "sample_283": ["    def test_runshell_handles_sigint(self):\n        with mock.patch('subprocess.Popen', autospec=True) as mock_popen:\n            client = DatabaseClient()\n            client.runshell([])\n\n            # Assert that the original SIGINT handler was restored.\n            self.assertEqual(signal.getsignal(signal.SIGINT), signal.SIG_DFL)\n\n            # Assert that the psql process was started with SIGINT ignored.\n            mock_popen.assert_called_once_with(\n                ['psql'],\n                env={'PGPASSWORD': None},\n                stdin=subprocess.PIPE,\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n            )\n            mock_popen.return_value.communicate.assert_called_once()\n"], "sample_942": ["    def test_parse_annotation(self):\n        assert _parse_annotation(\"int\") == (\"int\", None)\n        assert _parse_annotation(\"int: str\") == (\"int\", \"str\")\n        assert _parse_annotation(\"int -> str\") == (\"int\", \"str\")\n        assert _parse_annotation(\"int -> None\") == (\"int\", None)\n        assert _parse_annotation(\"int, str\") == (\"int, str\", None)\n        assert _parse_annotation(\"int, str: None\") == (\"int, str\", None)\n        assert _parse_annotation(\"List[int]\") == (\"List[int]\", None)\n        assert _parse_annotation(\"List[int]: str\") == (\"List[int]\", \"str\")\n        assert _parse_annotation(\"Optional[int]\") == (\"Optional[int]\", None)\n        assert _parse_annotation(\"Optional[int]: str\") == (\"Optional[int]\", \"str\")\n        assert _parse_annotation(\"Union[int, str]\") == (\"Union[int, str]\", None)\n        assert _parse_annotation(\"Union[int, str]: None\") == (\"Union[int, str]\", None)\n        assert _parse_annotation(\"Callable[[int], str]\") == (\"Callable[[int], str]\", None)\n        assert _parse_annotation(\"Callable[[int], str]: None\") == (\"Callable[[int], str]\", None)\n\n\n\n"], "sample_198": ["    def test_window_functions(self):\n        with self.subTest('Avg'):\n            avg_salary = self.company_query.annotate(avg_salary=Avg('employees__salary')).values('name', 'avg_salary')\n            self.assertQuerysetEqual(avg_salary, [\n                {'name': 'Example Inc.', 'avg_salary': 10},\n                {'name': 'Foobar Ltd.', 'avg_salary': 20},\n                {'name': 'Test GmbH', 'avg_salary': 30},\n            ])\n\n        with self.subTest('Count'):\n            count_employees = self.company_query.annotate(employee_count=Count('employees')).values('name', 'employee_count')\n            self.assertQuerysetEqual(count_employees, [\n                {'name': 'Example Inc.', 'employee_count': 2300},\n                {'name': 'Foobar Ltd.', 'employee_count': 3},\n                {'name': 'Test GmbH', 'employee_count': 32},\n            ])\n\n        with self.subTest('Max'):\n            max_salary = self.company_query.annotate(max_salary=Max('employees__salary')).values('name', 'max_salary')\n            self.assertQuerysetEqual(max_salary, [\n                {'name': 'Example Inc.', 'max_salary': 10},\n                {'name': 'Foobar Ltd.', 'max_salary': 20},\n                {'name': 'Test GmbH', 'max_salary': 30},\n            ])\n\n        with self.subTest('Min'):\n            min_salary = self.company_query.annotate(min_salary=Min('employees__salary')).values('name', 'min_salary')\n            self.assertQuerysetEqual(min_salary, [\n                {'name': 'Example Inc.', 'min_salary': 10},\n                {'name': 'Foobar Ltd.', 'min_salary': 20},\n                {'name': 'Test GmbH', 'min_salary': 30},\n            ])\n\n        with self.subTest('Sum'):\n            total_salary = self.company_query.annotate(total_salary=Sum('employees__salary')).values('name', 'total"], "sample_906": ["compilation error"], "sample_316": ["    def test_get_image_dimensions_from_file_with_zlib_error(self):\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as f:\n            f.write(b'\\x42\\x4D\\x00\\x00')  # Start of a BMP file\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f.write(b'\\x00\\x00\\x00\\x00')\n            f."], "sample_1026": ["    def test_lambdify_with_numexpr():\n        if numexpr is None:\n            skip(\"numexpr is not available\")\n        f = lambdify((x, y), x**2 + y**2, modules=['numexpr'])\n        assert f(2, 3) == 13\n"], "sample_873": ["    def test_inverse_transform_sparse(self):\n        step_selector = StepSelector(step=2)\n        X_sparse = sp.csc_matrix(X)\n        step_selector.fit(X_sparse)\n        X_transformed = step_selector.transform(X_sparse)\n        X_inverse_transformed = step_selector.inverse_transform(X_transformed)\n        assert_array_equal(X_inverse_transformed.toarray(), X_sparse.toarray())\n"], "sample_721": ["    def test_check_memory_cachedir(self):\n        with NamedTemporaryFile(delete=False) as tmpdir:\n            cachedir = tmpdir.name\n            memory = Memory(cachedir=cachedir)\n            assert isinstance(memory, Memory)\n            assert memory.cachedir == cachedir\n\n            with ignore_warnings(category=DeprecationWarning):\n                memory = Memory(cachedir=None)\n            assert isinstance(memory, Memory)\n            assert memory.cachedir is None\n\n            with ignore_warnings(category=DeprecationWarning):\n                memory = Memory(cachedir=\"invalid_path\")\n            assert isinstance(memory, Memory)\n            assert memory.cachedir == \"invalid_path\"\n\n            with pytest.raises(ValueError):\n                memory = Memory(\"invalid_path\", mode='r')\n\n            with pytest.raises(ValueError):\n                memory = Memory(cachedir=\"invalid_path\", verbose=1)\n\n            with pytest.raises(ValueError):\n                memory = Memory(cachedir=\"invalid_path\", verbose=10)\n\n\n\n"], "sample_1087": ["    def test_swinnerton_dyer_poly_order_1():\n        for i in range(5):\n            n = i + 1\n            for polys in [True, False]:\n                p = swinnerton_dyer_poly(n, polys=polys)\n                if polys:\n                    assert p.as_expr() == p\n                else:\n                    assert isinstance(p, Poly)\n                    assert p.degree() == n - 1\n"], "sample_65": ["    def test_set_language_redirects_to_next_with_language(self):\n        inactive_language = self._get_inactive_language_code()\n        response = self.client.post(\n            reverse('set_language'),\n            {'next': '/some/path', LANGUAGE_QUERY_PARAMETER: inactive_language},\n        )\n        self.assertRedirects(response, f'/some/path?{LANGUAGE_QUERY_PARAMETER}={inactive_language}')\n        self.assertEqual(get_language(), inactive_language)\n"], "sample_416": ["    def test_runshell_handles_sigint(self):\n        with mock.patch('subprocess.Popen', autospec=True) as mock_popen:\n            client = DatabaseClient()\n            client.runshell([])\n            mock_popen.assert_called_once_with(\n                ['psql'],\n                env={'PGPASSWORD': os.environ.get('PGPASSWORD')},\n                stdin=subprocess.PIPE,\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE\n            )\n"], "sample_311": ["    def test_admin_change_list_with_inline_formset(self):\n        response = self.client.get(reverse('admin:article_changelist'))\n        self.assertContentBefore(response, b'Add Article', b'Edit Article')\n        response = self.client.post(\n            reverse('admin:article_changelist'),\n            self.inline_post_data,\n            follow=True,\n        )\n        self.assertRedirects(response, reverse('admin:article_changelist'))\n        self.assertEqual(Article.objects.count(), 6)\n        self.assertEqual(Chapter.objects.count(), 4)\n        self.assertEqual(ChapterXtra1.objects.count(), 2)\n\n\n\n"], "sample_169": ["    def test_json_field_serialization_with_custom_decoder(self):\n        obj = JSONModel(json_field={'a': 1, 'b': '2'})\n        obj.save()\n        serialized = serializers.serialize('xml', [obj])\n        deserialized = serializers.deserialize('xml', serialized)[0].object\n        self.assertEqual(deserialized.json_field, {'a': 1, 'b': '2'})\n        self.assertEqual(deserialized.json_field, obj.json_field)\n"], "sample_1047": ["    def test_inconsistent_assumptions():\n        x = Symbol('x')\n        with raises(InconsistentAssumptions):\n            x.is_integer = True\n            x.is_real = False\n"], "sample_618": ["    def test_ordered_set_intersection_empty():\n        assert ordered_set_intersection(set(), set()) == set()\n        assert ordered_set_intersection(set(), {1, 2}) == set()\n        assert ordered_set_intersection({1, 2}, set()) == set()\n"], "sample_723": ["compilation error"], "sample_421": ["    def test_case_expression_with_empty_result_set(self):\n        empty_case = Case(\n            When(CaseTestModel.objects.none(), then=Value(1)),\n            default=Value(0),\n        )\n        with self.assertRaises(EmptyResultSet):\n            empty_case.resolve_expression(query=CaseTestModel.objects.all())\n"], "sample_151": ["    def test_migration_dependencies_circular_fk(self):\n        before_states = [\n            rabbit,\n            knight,\n        ]\n        after_states = [\n            rabbit,\n            knight,\n        ]\n        changes = self.get_changes(before_states, after_states)\n        self.assertMigrationDependencies(changes, \"eggs\", 0, [])\n        self.assertMigrationDependencies(changes, \"eggs\", 1, [])\n\n\n\n"], "sample_259": ["    def test_prefetch_related_objects_with_nested_lookups(self):\n        prefetch_lookups = [\n            Prefetch('authors', queryset=Author.objects.filter(name='Charlotte'), to_attr='charlotte_authors'),\n            Prefetch('readers', queryset=Reader.objects.filter(name='Amy'), to_attr='amy_readers'),\n        ]\n        books = Book.objects.all()\n        prefetch_related_objects(books, *prefetch_lookups)\n\n        for book in books:\n            self.assertEqual(len(book.charlotte_authors), 1)\n            self.assertEqual(len(book.amy_readers), 1)\n"], "sample_407": ["compilation error"], "sample_180": ["    def test_index_together_with_conditions(self):\n        with override_settings(DATABASE_ROUTERS={'default': EmptyRouter()}):\n            class MyModel(models.Model):\n                name = models.CharField(max_length=100)\n                value = models.IntegerField()\n\n                class Meta:\n                    indexes = [\n                        models.Index(fields=['name', 'value'], condition=models.Q(value__gt=10)),\n                    ]\n\n            with self.assertRaises(Warning) as context:\n                _check_lazy_references(MyModel)\n            self.assertIn(\n                \"supports indexes with conditions\", str(context.exception)\n            )\n\n\n"], "sample_466": ["    def test_serialize_custom_types(self):\n        operation = custom_migration_operations.more_operations.CreateCustomModel(\n            name=\"CustomModel\",\n            fields=[\n                models.CharField(max_length=100),\n                models.DecimalField(max_digits=10, decimal_places=2),\n                models.ForeignKey(\n                    \"TestModel1\", on_delete=models.CASCADE, related_name=\"related_custom\"\n                ),\n                models.ManyToManyField(\"TestModel1\", related_name=\"related_custom_many\"),\n                models.FileField(upload_to=lambda instance: \"uploads/%s\" % instance.id),\n                models.BooleanField(default=True),\n                models.DateTimeField(auto_now_add=True),\n                models.DateTimeField(auto_now=True),\n                models.TimeField(),\n                models.DateField(),\n                models.UUIDField(),\n                models.BigIntegerField(),\n                models.SmallIntegerField(),\n                models.PositiveIntegerField(),\n                models.PositiveSmallIntegerField(),\n                models.GenericIPAddressField(),\n                models.URLField(),\n                models.EmailField(validators=[EmailValidator()]),\n                models.RegexField(regex=r\"^\\d+$\", validators=[RegexValidator()]),\n                models.JSONField(),\n                models.JSONBField(),\n                models.Text(),\n                models.TextField(),\n                models.SlugField(),\n                models.AutoField(),\n                models.NullBooleanField(),\n                models.GeometryField(),\n                models.PointField(),\n                models.LineStringField(),\n                models.PolygonField(),\n                models.MultiPointField(),\n                models.MultiLineStringField(),\n                models.MultiPolygonField(),\n                models.GeometryCollectionField(),\n                models.EnumField(enum_type=TextEnum),\n                models.EnumField(enum_type=TextTranslatedEnum),\n                models.EnumField(enum_type=BinaryEnum),\n                models.EnumField(enum_type=IntEnum),\n                models.EnumField(enum_type=IntFlagEnum),\n                models.OneToOneField(\n                    \"TestModel1\", on_delete=models.CASCADE, primary_key=True\n                ),\n                models.OneToOneField(\n                    \"TestModel1"], "sample_855": ["    def test_dummy_classifier_sparse_output(self):\n        X = np.array([[1, 2], [3, 4], [5, 6]])\n        y = sp.csr_matrix([[1], [2], [3]])\n        clf = DummyClassifier(strategy=\"most_frequent\", sparse_output=True)\n        clf.fit(X, y)\n        y_pred = clf.predict(X)\n        assert isinstance(y_pred, sp.csc_matrix)\n        assert y_pred.shape == y.shape\n"], "sample_273": ["    def test_check_model_name_db_lookup_clashes(self):\n        with override_settings(DATABASE_ROUTERS=[EmptyRouter()]):\n            class ModelWithClash(models.Model):\n                pass\n\n            with self.assertRaises(checks.Error) as cm:\n                checks.run_checks([ModelWithClash], [])\n            self.assertIn(\n                \"The model name 'ModelWithClash' cannot start with an underscore\",\n                str(cm.exception),\n            )\n\n\n\n"], "sample_489": ["    def test_bulk_create_with_related_objects(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\"TRUNCATE TABLE pizzeria\")\n            cursor.execute(\"TRUNCATE TABLE country\")\n        Country.objects.bulk_create(self.data)\n        Pizzeria.objects.bulk_create(self.data2)\n        self.assertEqual(Pizzeria.objects.count(), 3)\n        self.assertEqual(Country.objects.count(), 4)\n\n\n\n"], "sample_1034": ["    def test_grover_iteration_multiple_iterations(self):\n        numqubits = 2\n        oracle = OracleGate(numqubits, return_one_on_two)\n        iterations = 5\n        initial_state = superposition_basis(numqubits)\n        for i in range(iterations):\n            initial_state = grover_iteration(initial_state, oracle)\n        result = qapply(initial_state)\n        self.assertEqual(result, IntQubit(2))\n"], "sample_677": ["    def test_paren_nesting():\n        assert evaluate(\"((True))\", lambda x: True) is True\n        assert evaluate(\"((False))\", lambda x: True) is False\n        assert evaluate(\"((True) and (False))\", lambda x: True) is False\n        assert evaluate(\"(True or (False))\", lambda x: True) is True\n        with pytest.raises(ParseError):\n            evaluate(\"((\", lambda x: True)\n\n\n\n"], "sample_774": ["    def test_onehotencoder_fit_transform_sparse_with_drop(self):\n        X = np.array([[0, 1, 2], [1, 2, 0], [0, 1, 2]])\n        enc = OneHotEncoder(sparse=True, drop='first')\n        enc.fit(X)\n        X_transformed = enc.transform(X)\n        expected_shape = (3, 3)\n        assert_equal(X_transformed.shape, expected_shape)\n        assert_allclose(toarray(X_transformed),\n                        [[1, 0, 0, 0, 1, 0, 0, 0, 1],\n                         [0, 1, 0, 0, 0, 1, 0, 0, 1],\n                         [1, 0, 0, 0, 1, 0, 0, 0, 1]])\n"], "sample_1135": ["    def test_as_content_primitive_with_sqrt():\n        from sympy import sqrt\n        expr = 2*sqrt(2)*(2 - 2*sqrt(2))\n        r, s = expr.as_content_primitive(radical=True)\n        assert r == 6\n        assert s == -sqrt(2)*(1 - sqrt(2))\n"], "sample_537": ["    def test_stride_windows_2d(self):\n        x = np.random.rand(100, 100)\n        NFFT = 20\n        noverlap = 10\n        result = _stride_windows(x, NFFT, noverlap)\n        target = self.calc_window_target(x, NFFT, noverlap, axis=0)\n        assert_array_almost_equal_nulp(result, target, 5)\n"], "sample_37": ["    def test_wcs_from_file(self, filename):\n        with catch_warnings():\n            warnings.simplefilter(\"ignore\", category=FITSFixedWarning)\n            with open(get_pkg_data_filename(\"maps\", filename), \"r\") as f:\n                header = fits.Header.fromstring(f.read())\n            wcs = wcs.WCS(header)\n            assert wcs.naxis == header['NAXIS']\n            assert wcs.wcs.ctype == header['CTYPE'].split()\n            assert wcs.wcs.crval == header['CRVAL'].split()\n            assert wcs.wcs.crpix == header['CRPIX'].split()\n            assert wcs.wcs.cdelt == header['CDELT'].split()\n            assert wcs.wcs.cd == header['CD'].split()\n\n\n\n"], "sample_295": ["    def test_window_functions(self):\n        with self.assertNumQueries(2):\n            # Test with a simple window function\n            result = Company.objects.annotate(\n                avg_employees=Avg('num_employees'),\n            ).values('name', 'avg_employees').order_by('name')\n            self.assertEqual(list(result), [\n                {'name': 'Example Inc.', 'avg_employees': 2300},\n                {'name': 'Foobar Ltd.', 'avg_employees': 3},\n                {'name': 'Test GmbH', 'avg_employees': 32},\n            ])\n\n        with self.assertNumQueries(2):\n            # Test with a window function and a frame\n            result = Company.objects.annotate(\n                avg_employees=Avg('num_employees', window=Window(\n                    partition_by='name',\n                    order_by=OrderBy('num_employees', descending=True),\n                    frame=RowRange(end=1),\n                )),\n            ).values('name', 'avg_employees').order_by('name')\n            self.assertEqual(list(result), [\n                {'name': 'Example Inc.', 'avg_employees': 2300},\n                {'name': 'Foobar Ltd.', 'avg_employees': 3},\n                {'name': 'Test GmbH', 'avg_employees': 32},\n            ])\n\n\n\n"], "sample_661": ["    def test_double_failure_handling(self, testdir):\n        result, dom = runandparse(testdir, \"-v\", \"--junitxml=junit.xml\", \"test_double_failure.py\")\n        assert result.ret == 0\n        suite = dom.find_first_by_tag(\"testsuite\")\n        assert suite.get_unique_child.tag == \"testcase\"\n        assert suite.get_unique_child.attrs[\"name\"] == \"test_double_failure\"\n        assert suite.get_unique_child.attrs[\"classname\"] == \"test_double_failure\"\n        assert suite.get_unique_child.find_first_by_tag(\"failure\").text == \"xfail-marked test passes unexpectedly\"\n        assert suite.get_unique_child.find_first_by_tag(\"error\").text == \"teardown error\"\n\n\n\n"], "sample_878": ["    def test_remainder_passthrough(self):\n        X = np.array([[1, 2], [3, 4], [5, 6]])\n        ct = make_column_transformer(\n            (StandardScaler(), [\"numerical_column\"]),\n            remainder=\"passthrough\",\n        )\n        ct.fit(X)\n        X_transformed = ct.transform(X)\n        assert_allclose(X_transformed[:, 0], \n                        (X[:, 0] - X[:, 0].mean()) / X[:, 0].std())\n        assert_allclose(X_transformed[:, 1], X[:, 1])\n"], "sample_398": ["    def test_login_view_redirect_to_login_url(self):\n        self.logout()\n        login_url = reverse_lazy(\"login\")\n        response = self.client.get(login_url)\n        self.assertRedirects(response, login_url)\n"], "sample_730": ["    def test_multi_task_lasso_cv_with_l1_ratio_list(self):\n        X, y = load_boston(return_X_y=True)\n        X = check_array(X, dtype=np.float64)\n        y = check_array(y, dtype=np.float64)\n        n_tasks = 1\n        y = np.reshape(y, (y.shape[0], n_tasks))\n\n        # Test with a list of l1_ratio values\n        clf = MultiTaskLassoCV(l1_ratio=[0.1, 0.5, 0.9], cv=5)\n        clf.fit(X, y)\n        assert_greater(clf.alpha_, 0)\n        assert_equal(clf.l1_ratio_, 0.9)\n        assert_equal(clf.mse_path_.shape[0], clf.n_alphas)\n        assert_equal(clf.alphas_.shape[0], clf.n_alphas)\n        assert_equal(clf.coef_.shape, (n_tasks, X.shape[1]))\n"], "sample_1093": ["    def test_sparse_matrix(self):\n        m = SparseMatrix(((1, 0, 2), (0, 1, 3)), shape=(2, 3))\n        code = pycode(m, printer=SciPyPrinter())\n        expected = \"scipy.sparse.coo_matrix([[2, 0, 3], [1, 1, 0]], ((0, 0), (0, 1), (0, 2), (1, 1), (1, 0)), shape=(2, 3))\"\n        assert code == expected\n"], "sample_1172": ["    def test_solve_poly_system_rational_roots():\n        a = Poly(x**2 - 2, x, domain=QQ)\n        b = Poly(y**2 - 2, y, domain=QQ)\n        with raises(SolveFailed):\n            solve_poly_system([a, b], x, y)\n"], "sample_1099": ["    def test_partial_derivative_product(self):\n        A = Tensor(A, [i])\n        B = Tensor(B, [j])\n        expr = PartialDerivative(A(i)*B(j), i)\n        result = expr.doit()\n        expected = B(j)\n        self.assertEqual(result, expected)\n"], "sample_513": ["    def test_bbox_to_anchor(self):\n        fig, ax = plt.subplots()\n        ax.plot([1, 2, 3], [4, 5, 6])\n        ax.legend(bbox_to_anchor=(0.5, 1.05), loc='upper center')\n        plt.show()\n"], "sample_1065": ["    def test_binomial_mod_large_prime(self):\n        n = 100000\n        k = 50000\n        q = 1000000007\n        res = binomial(n, k).evalf(50).mod(q)\n        res_exact = binomial(n, k).evalf(50)\n        assert res == res_exact % q\n"], "sample_675": ["    def test_log_file_path(self, testdir):\n        \"\"\"Test that log file path can be set.\"\"\"\n        testdir.makepyfile(\n            \"\"\"\n            import logging\n\n            logging.basicConfig(level=logging.DEBUG)\n\n                pass\n            \"\"\"\n        )\n\n        result = testdir.runpytest()\n        result.assert_outcomes(passed=1)\n\n        # Check that the log file was created\n        log_file = os.path.join(testdir.tmpdir, \"test_log.log\")\n        assert os.path.exists(log_file)\n\n        # Set a new log file path\n        testdir.parseconfig(\n            \"--log-file=test_log_new.log\"\n        )\n        result = testdir.runpytest()\n        result.assert_outcomes(passed=1)\n\n        # Check that the new log file was created\n        assert os.path.exists(os.path.join(testdir.tmpdir, \"test_log_new.log\"))\n        assert not os.path.exists(log_file)\n\n\n\n"], "sample_719": ["    def test_stop_words_with_max_df(self):\n        # Test stop words removal based on max_df\n        vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n        X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n        stop_words = vectorizer.stop_words_\n\n        # Assert that common words like 'the' are removed\n        assert 'the' in stop_words\n        assert 'pizza' not in stop_words\n        assert 'burger' not in stop_words\n\n        # Assert that the vocabulary size is smaller than without max_df\n        vectorizer_no_max_df = TfidfVectorizer(stop_words='english')\n        X_no_max_df = vectorizer_no_max_df.fit_transform(ALL_FOOD_DOCS)\n        assert len(vectorizer.vocabulary_) < len(vectorizer_no_max_df.vocabulary_)\n"], "sample_1195": ["compilation error"], "sample_966": ["    def test_parse_annotation(self):\n        assert _parse_annotation(\"int\") == (\"int\", None)\n        assert _parse_annotation(\"int: str\") == (\"int\", \"str\")\n        assert _parse_annotation(\"int -> str\") == (\"int\", \"str\")\n        assert _parse_annotation(\"int -> None\") == (\"int\", None)\n        assert _parse_annotation(\"int -> List[str]\") == (\"int\", \"List[str]\")\n        assert _parse_annotation(\"int -> typing.List[str]\") == (\"int\", \"typing.List[str]\")\n        assert _parse_annotation(\"int -> Optional[str]\") == (\"int\", \"Optional[str]\")\n        assert _parse_annotation(\"int -> Union[str, int]\") == (\"int\", \"Union[str, int]\")\n        assert _parse_annotation(\"int -> Tuple[str, int]\") == (\"int\", \"Tuple[str, int]\")\n        assert _parse_annotation(\"int -> Callable[[str], int]\") == (\"int\", \"Callable[[str], int]\")\n\n\n\n"], "sample_248": ["    def test_command_argument(self):\n        with captured_stdout() as stdout:\n            call_command('shell', '-c', self.script_globals)\n        self.assertEqual(stdout.getvalue(), 'True\\n')\n"], "sample_1007": ["    def test_binomial_negative_k(self):\n        n = Symbol('n', integer=True)\n        for k in [-1, -2, -3]:\n            with self.assertWarns(UserWarning):\n                binomial(n, k)\n            with self.assertWarns(UserWarning):\n                binomial(n, k).rewrite('tractable')\n            with self.assertWarns(UserWarning):\n                binomial(n, k).rewrite('factorial')\n            with self.assertWarns(UserWarning):\n                binomial(n, k).rewrite('gamma')\n            with self.assertWarns(UserWarning):\n                binomial(n, k).rewrite('FallingFactorial')\n"], "sample_177": ["    def test_get_related_models_recursive(self):\n        with isolate_apps(['food']):\n            # Create a simple model hierarchy\n            class Food(models.Model):\n                name = models.CharField(max_length=100)\n\n            class Fruit(Food):\n                color = models.CharField(max_length=50)\n\n            class Vegetable(Food):\n                is_green = models.BooleanField()\n\n            # Get the related models recursively\n            related_models = get_related_models_recursive(Food)\n            self.assertEqual(set(related_models), {\n                ('food', 'Food'),\n                ('food', 'Fruit'),\n                ('food', 'Vegetable'),\n            })\n"], "sample_424": ["    def test_add_remove_constraint(self):\n        with atomic():\n            # Create a model with a constraint\n            class MyModel(models.Model):\n                name = models.CharField(max_length=100)\n                value = models.IntegerField(unique=True)\n\n            self.add_model(MyModel)\n\n            # Add a constraint\n            with self.assertNumQueries(1):\n                self.operations.add_constraint(\n                    \"myapp\", \"MyModel\", models.UniqueConstraint(fields=[\"name\", \"value\"])\n                )\n                self.apply_operations()\n\n            # Check the constraint exists in the database\n            with connection.cursor() as cursor:\n                cursor.execute(\n                    \"PRAGMA table_info(myapp_mymodel)\"\n                )\n                result = cursor.fetchall()\n                self.assertIn(\n                    (\"constraint_name\", \"UNIQUE_myapp_mymodel_name_value\"), result\n                )\n\n            # Remove the constraint\n            with self.assertNumQueries(1):\n                self.operations.remove_constraint(\"myapp\", \"MyModel\", \"UNIQUE_myapp_mymodel_name_value\")\n                self.apply_operations()\n\n            # Check the constraint is gone\n            with connection.cursor() as cursor:\n                cursor.execute(\n                    \"PRAGMA table_info(myapp_mymodel)\"\n                )\n                result = cursor.fetchall()\n                self.assertNotIn(\n                    (\"constraint_name\", \"UNIQUE_myapp_mymodel_name_value\"), result\n                )\n\n\n\n"], "sample_807": ["    def test_calibration_curve(self):\n        X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n        clf = RandomForestClassifier(random_state=42)\n        clf.fit(X, y)\n        y_prob = clf.predict_proba(X)[:, 1]\n\n        prob_true, prob_pred = calibration_curve(y, y_prob, n_bins=10)\n        assert_array_almost_equal(prob_true, prob_pred)\n\n        # Test with normalize=True\n        prob_true, prob_pred = calibration_curve(y, y_prob, normalize=True, n_bins=10)\n        assert_array_almost_equal(prob_true, prob_pred)\n\n        # Test with quantile strategy\n        prob_true, prob_pred = calibration_curve(y, y_prob, strategy='quantile', n_bins=10)\n        assert_array_almost_equal(prob_true, prob_pred)\n"], "sample_982": ["    def test_udivisor_sigma_special_cases():\n        assert udivisor_sigma(1, 0) == 1\n        assert udivisor_sigma(1, 1) == 1\n        assert udivisor_sigma(1, 2) == 1\n        assert udivisor_sigma(2, 0) == 2\n        assert udivisor_sigma(2, 1) == 3\n        assert udivisor_sigma(2, 2) == 3\n        assert udivisor_sigma(3, 0) == 2\n        assert udivisor_sigma(3, 1) == 6\n        assert udivisor_sigma(3, 2) == 13\n        assert udivisor_sigma(6, 0) == 4\n        assert udivisor_sigma(6, 1) == 12\n        assert udivisor_sigma(6, 2) == 31\n        assert udivisor_sigma(12, 0) == 6\n        assert udivisor_sigma(12, 1) == 28\n        assert udivisor_sigma(12, 2) == 105\n        assert udivisor_sigma(15, 0) == 4\n        assert udivisor_sigma(15, 1) == 56\n        assert udivisor_sigma(15, 2) == 221\n        assert udivisor_sigma(24, 0) == 6\n        assert udivisor_sigma(24, 1) == 114\n        assert udivisor_sigma(24, 2) == 47450\n        assert udivisor_sigma(30, 0) == 6\n        assert udivisor_sigma(30, 1) == 156\n        assert udivisor_sigma(30, 2) == 7656\n\n\n\n"], "sample_1052": ["    def test_multiple_return_values(self):\n        x, y, z = symbols('x y z')\n        expr = [x + y*z, x**2 + y**2]\n        routines = [make_routine('test', expr, language='C')]\n        source = get_string(CCodeGen.dump_c, routines, prefix=\"test\")\n        expected = \"\"\""], "sample_188": ["    def test_window_functions(self):\n        with self.subTest('avg'):\n            avg_salary = self.company_query.annotate(avg_salary=Avg('employees__salary')).values('name', 'avg_salary')\n            self.assertQuerysetEqual(avg_salary, [\n                {'name': 'Example Inc.', 'avg_salary': 10},\n                {'name': 'Foobar Ltd.', 'avg_salary': 20},\n                {'name': 'Test GmbH', 'avg_salary': 30},\n            ])\n\n        with self.subTest('count'):\n            count_employees = self.company_query.annotate(num_employees=Count('employees')).values('name', 'num_employees')\n            self.assertQuerysetEqual(count_employees, [\n                {'name': 'Example Inc.', 'num_employees': 2300},\n                {'name': 'Foobar Ltd.', 'num_employees': 3},\n                {'name': 'Test GmbH', 'num_employees': 1},\n            ])\n\n        with self.subTest('max'):\n            max_salary = self.company_query.annotate(max_salary=Max('employees__salary')).values('name', 'max_salary')\n            self.assertQuerysetEqual(max_salary, [\n                {'name': 'Example Inc.', 'max_salary': 10},\n                {'name': 'Foobar Ltd.', 'max_salary': 20},\n                {'name': 'Test GmbH', 'max_salary': 30},\n            ])\n\n        with self.subTest('min'):\n            min_salary = self.company_query.annotate(min_salary=Min('employees__salary')).values('name', 'min_salary')\n            self.assertQuerysetEqual(min_salary, [\n                {'name': 'Example Inc.', 'min_salary': 10},\n                {'name': 'Foobar Ltd.', 'min_salary': 20},\n                {'name': 'Test GmbH', 'min_salary': 30},\n            ])\n\n        with self.subTest('sum'):\n            total_salary = self.company_query.annotate(total_salary=Sum('employees__salary')).values('name', 'total_"], "sample_77": ["    def test_urlize_with_trailing_punctuation(self):\n        self.check_output(urlize, \"This is a URL: http://www.example.com.,\")\n        self.check_output(urlize, \"This is a URL: http://www.example.com;\")\n        self.check_output(urlize, \"This is a URL: http://www.example.com!\")\n        self.check_output(urlize, \"This is a URL: http://www.example.com(\")\n        self.check_output(urlize, \"This is a URL: http://www.example.com(,)\")\n        self.check_output(urlize, \"This is a URL: http://www.example.com[.]\")\n        self.check_output(urlize, \"This is a URL: http://www.example.com[;]\")\n        self.check_output(urlize, \"This is a URL: http://www.example.com[!].\")\n        self.check_output(urlize, \"This is a URL: http://www.example.com(,)!\")\n        self.check_output(urlize, \"This is a URL: http://www.example.com[;].\")\n\n\n\n"], "sample_731": ["compilation error"], "sample_834": ["    def test_nca_fit_with_warm_start(self):\n        n_components = 2\n        n_samples = 100\n        X, y = make_classification(n_samples=n_samples, n_features=10,\n                                   n_informative=5, random_state=0)\n        nca1 = NeighborhoodComponentsAnalysis(n_components=n_components,\n                                              warm_start=False)\n        nca1.fit(X, y)\n        nca2 = clone(nca1)\n        nca2.warm_start = True\n        nca2.fit(X, y)\n        assert_array_almost_equal(nca1.components_, nca2.components_)\n"], "sample_148": ["    def test_collect_nested(self):\n        self._connect(0, 1)\n        self._connect(1, 2)\n        self._collect(0, 1, 2)\n        self._check([[0, 1, 2]])\n"], "sample_592": ["    def test_short_numpy_repr(self, array, expected):\n        with formatting.set_numpy_options(precision=6, linewidth=100):\n            assert formatting.short_numpy_repr(array) == expected\n\n\n\n"], "sample_1056": ["    def test_numexpr_matrix(self):\n        raises(TypeError, lambda: NumExprPrinter().doprint(Matrix([[1, 2], [3, 4]])))\n"], "sample_426": ["    def test_timeuntil_future_date(self):\n        now = timezone.now()\n        future_date = now + self.oneday\n        self.assertEqual(timeuntil(future_date, now), \"1 day\")\n"], "sample_1197": ["    def test_get_dimensional_expr(self):\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            expr = Quantity(10 * meter, 'm')\n            self.assertEqual(SI.get_dimensional_expr(expr), length)\n\n            expr = Quantity(10 * meter**2, 'm^2')\n            self.assertEqual(SI.get_dimensional_expr(expr), length**2)\n\n            expr = Quantity(10 * meter * kilogram, 'm kg')\n            self.assertEqual(SI.get_dimensional_expr(expr), length * mass)\n\n            expr = Quantity(10 * meter / second, 'm/s')\n            self.assertEqual(SI.get_dimensional_expr(expr), length / time)\n\n            expr = Quantity(10 * kilogram * meter**2 / second**2, 'kg m^2/s^2')\n            self.assertEqual(SI.get_dimensional_expr(expr), mass * length**2 / time**2)\n\n            expr = Quantity(10 * joule, 'J')\n            self.assertEqual(SI.get_dimensional_expr(expr), energy)\n\n            expr = Quantity(10 * volt, 'V')\n            self.assertEqual(SI.get_dimensional_expr(expr),  charge * length / time)\n\n            expr = Quantity(10 * ohm, '\u03a9')\n            self.assertEqual(SI.get_dimensional_expr(expr),  charge**2 * time / length**2)\n\n            expr = Quantity(10 * ampere, 'A')\n            self.assertEqual(SI.get_dimensional_expr(expr),  charge / time)\n\n            expr = Quantity(10 * second, 's')\n            self.assertEqual(SI.get_dimensional_expr(expr), time)\n\n            expr = Quantity(10 * kelvin, 'K')\n            self.assertEqual(SI.get_dimensional_expr(expr), temperature)\n\n            expr = Quantity(10 * mole, 'mol')\n            self.assertEqual(SI.get_dimensional_expr(expr), amount_of_substance)\n\n            expr = Quantity(10 * bit, 'bit')\n            self.assertEqual(SI.get_dimensional_expr(expr),  None"], "sample_334": ["    def test_order_fields(self):\n        class OrderedForm(Form):\n            field1 = CharField()\n            field2 = CharField()\n            field3 = CharField()\n\n        form = OrderedForm(field_order=['field3', 'field1', 'field2'])\n        self.assertEqual(list(form.fields), ['field3', 'field1', 'field2'])\n\n        form = OrderedForm()\n        self.assertEqual(list(form.fields), ['field1', 'field2', 'field3'])\n"], "sample_959": ["    def test_cpp_domain_template_parameters(self):\n        input = \"template <typename T> struct S { T value; };\"\n        output = \"template <typename T> struct S { T value; };\"\n        idDict = {\n            1: \"S_1\",\n            2: \"S_2\",\n        }\n        check(\"struct\", input, idDict, output)\n\n\n\n"], "sample_241": ["    def test_expression_ordering(self):\n        with self.assertNumQueries(1):\n            result = self.company_query.annotate(\n                total_employees_squared=F('num_employees') ** 2\n            ).order_by(\n                'total_employees_squared'\n            ).values_list('name', 'total_employees_squared')\n            self.assertEqual(\n                list(result),\n                [\n                    ('Foobar Ltd.', 9),\n                    ('Test GmbH', 1024),\n                    ('Example Inc.', 5290000),\n                ]\n            )\n\n\n"], "sample_1144": ["compilation error"], "sample_541": ["    def test_lasso_callback(self, ax):\n            assert len(verts) > 2\n            assert all(isinstance(v, tuple) and len(v) == 2 for v in verts)\n            self.verts = verts\n\n        lasso = Lasso(ax, (0.2, 0.2), callback)\n        click_and_drag(ax, (0.5, 0.5), (0.8, 0.8))\n        lasso.onrelease(mock_event(ax, 'button_release', x=0.8, y=0.8))\n        assert callback.verts == [(0.2, 0.2), (0.5, 0.5), (0.8, 0.8)]\n"], "sample_1145": ["compilation error"], "sample_362": ["    def test_migration_dependencies_circular(self):\n        before_states = self.make_project_state([\n            rabbit,\n        ])\n        after_states = self.make_project_state([\n            rabbit,\n        ],\n        )\n        changes = self.get_changes(before_states, after_states)\n        self.assertMigrationDependencies(changes, 'eggs', 0, [])\n"], "sample_657": ["    def test_empty_parameterset_mark(self, request):\n        config = mock.Mock(spec=pytest.config.Config)\n        config.getini.return_value = EMPTY_PARAMETERSET_OPTION\n        func = mock.Mock(spec=object)\n        _, lineno = getfslineno(func)\n        with pytest.raises(Collector.CollectError) as excinfo:\n            get_empty_parameterset_mark(config, [\"arg1\"], func)\n        assert (\n            str(excinfo.value)\n            == \"Empty parameter set in '...' at line 1\"\n        )\n"], "sample_623": ["    def test_to_netcdf_mode(\n        mode, expected_mode, tmp_path, engine, monkeypatch"], "sample_38": ["    def test_wcs_from_file(self, filename):\n        with catch_warnings():\n            warnings.simplefilter(\"ignore\", category=fits.FITSFixedWarning)\n            wcs = wcs.WCS(get_pkg_data_filename(\"maps\", filename))\n            assert wcs.naxis == 2\n            assert wcs.wcs.ctype[0] == 'RA---TAN'\n            assert wcs.wcs.ctype[1] == 'DEC--TAN'\n"], "sample_1200": ["    def test_get_dimensional_expr(self):\n        from sympy.physics.units import Quantity\n        unit_system = SI\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            expr = Quantity(10, 'm')\n            self.assertEqual(unit_system.get_dimensional_expr(expr), length)\n            expr = Quantity(10, 'kg')\n            self.assertEqual(unit_system.get_dimensional_expr(expr), mass)\n            expr = Quantity(10, 's')\n            self.assertEqual(unit_system.get_dimensional_expr(expr), time)\n            expr = Quantity(10, 'm/s')\n            self.assertEqual(unit_system.get_dimensional_expr(expr), length/time)\n            expr = Quantity(10, 'm/s**2')\n            self.assertEqual(unit_system.get_dimensional_expr(expr), length/time**2)\n            expr = Quantity(10, 'kg*m/s**2')\n            self.assertEqual(unit_system.get_dimensional_expr(expr), mass*length/time**2)\n            expr = Quantity(10, 'kg*m**2/s**2')\n            self.assertEqual(unit_system.get_dimensional_expr(expr), mass*length**2/time**2)\n            expr = Quantity(10, 'J')\n            self.assertEqual(unit_system.get_dimensional_expr(expr), energy)\n            expr = Quantity(10, 'N')\n            self.assertEqual(unit_system.get_dimensional_expr(expr), force)\n            expr = Quantity(10, 'Pa')\n            self.assertEqual(unit_system.get_dimensional_expr(expr), pressure)\n            expr = Quantity(10, 'K')\n            self.assertEqual(unit_system.get_dimensional_expr(expr), temperature)\n            expr = Quantity(10, 'mol')\n            self.assertEqual(unit_system.get_dimensional_expr(expr), amount_of_substance)\n            expr = Quantity(10, 'A')\n            self.assertEqual(unit_system.get_dimensional_expr(expr), current)\n            "], "sample_993": ["    def test_power_of_identity():\n        assert (F.identity).power_of(x) == True\n        assert (F.identity).power_of(y) == True\n        assert (F.identity).power_of(z) == True\n        assert (F.identity).power_of(F.identity) == True\n"], "sample_762": ["    def test_clone_nested_estimators(self):\n        from sklearn.linear_model import LogisticRegression\n\n        estimator = Pipeline([\n            ('clf', LogisticRegression()),\n            ('scaler', StandardScaler())\n        ])\n\n        cloned_estimator = clone(estimator)\n\n        assert_not_equal(estimator, cloned_estimator)\n        assert_equal(estimator.steps, cloned_estimator.steps)\n        assert_not_equal(estimator.steps[0][1], cloned_estimator.steps[0][1])\n        assert_not_equal(estimator.steps[1][1], cloned_estimator.steps[1][1])\n"], "sample_31": ["    def test_latex_names_false(self, cosmo):\n        with pytest.raises(IORegistryError):\n            write_latex(cosmo, \"test.tex\", latex_names=False)\n"], "sample_559": ["    def test_axes_grid_inset_axes_bbox_connector_patch(self):\n        fig, ax = plt.subplots()\n        inset_ax = zoomed_inset_axes(ax, zoom=2, loc='upper right', bbox_to_anchor=(0.8, 0.9))\n        bbox_connector = BboxConnectorPatch(\n            bbox_to_anchor=(0.8, 0.9),\n            bbox_transform=ax.transAxes,\n            path=inset_ax.transAxes.inverted().transform(\n                inset_ax.get_position().bounds),\n            color='red',\n            linewidth=2\n        )\n        ax.add_patch(bbox_connector)\n        fig.canvas.draw()\n        bbox = bbox_connector.get_bbox()\n        assert bbox.width > 0\n        assert bbox.height > 0\n        assert bbox.x0 > 0\n        assert bbox.y0 > 0\n\n"], "sample_593": ["def test_array_repr_with_attrs(dataarray):\n    repr_html = fh.array_repr(dataarray)\n    assert \"<pre>xarray.DataArray</pre>\" in repr_html\n    assert \"<dt><span>attrs :</span></dt>\" in repr_html\n    assert \"</dl>\" in repr_html\n    assert \"<div class='xr-array-data'>\" in repr_html\n\n\n\n"], "sample_860": ["    def test_check_sample_weight_sparse(self):\n        X = sp.csr_matrix([[1, 2], [3, 4]])\n        sample_weight = sp.csr_matrix([0.5, 0.7])\n        result = _check_sample_weight(sample_weight, X)\n        assert_allclose_dense_sparse(result, sample_weight)\n"], "sample_201": ["    def test_cookie_storage_not_finished(self):\n        storage = self.storage_class()\n        messages = [\n            Message(constants.INFO, 'Message 1'),\n            Message(constants.INFO, 'Message 2'),\n            Message(constants.INFO, 'Message 3'),\n        ]\n        response = self.get_response()\n        storage._store(messages, response, remove_oldest=False)\n        self.assertEqual(self.stored_messages_count(storage, response), 3)\n\n        # Simulate a scenario where not all messages can be stored due to\n        # size limitations.\n        set_cookie_data(storage, messages + [Message(constants.INFO, 'Message 4')])\n        response = self.get_response()\n        self.assertEqual(self.stored_messages_count(storage, response), 3)\n        self.assertIn(storage.not_finished, storage._decode(response.cookies[storage.cookie_name].value))\n"], "sample_642": ["    def test_preprocess_options_no_value(\n        caplog: CaptureFixture,\n        fake_home: str,\n        tempdir: str,"], "sample_428": ["    def test_large_numbers(self):\n        for number in [1e300, -1e300]:\n            formatted_number = nformat(number, decimal_sep=\",\", decimal_pos=2)\n            self.assertEqual(formatted_number, f\"{number:.2f}\")\n"], "sample_768": ["    def test_train_test_split_sparse_output(self):\n        X = coo_matrix((np.ones(10), (range(10), range(10))))\n        y = np.arange(10) // 2\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n        assert isinstance(X_train, csr_matrix)\n        assert isinstance(X_test, csr_matrix)\n"], "sample_42": ["compilation error"], "sample_556": ["    def test_constrained_layout_engine():\n        fig = Figure()\n        gs = gridspec.GridSpec(2, 2)\n        ax1 = fig.add_subplot(gs[0, 0])\n        ax2 = fig.add_subplot(gs[0, 1])\n        ax3 = fig.add_subplot(gs[1, 0])\n        ax4 = fig.add_subplot(gs[1, 1])\n\n        fig.set_layout_engine(ConstrainedLayoutEngine())\n        fig.canvas.draw()\n        fig.savefig('test_constrained_layout.png')\n\n\n\n"], "sample_1012": ["    def test_piecewise(self):\n        expr = Piecewise((x, x < 0), (y, x >= 0))\n        code = pycode(expr)\n        assert code == 'numpy.select(x < 0, x, y)'\n\n        expr = Piecewise((x, x < 0), (y, (x >= 0) & (x <= 1)), (z, x > 1))\n        code = pycode(expr)\n        assert code == 'numpy.select((x < 0), x, numpy.select((x >= 0) & (x <= 1), y, z))'\n"], "sample_412": ["    def test_urlize_mailto(self):\n        self.check_output(urlize, \"john.doe@example.com\", \"john.doe@example.com\")\n        self.check_output(urlize, \"john.doe@example.net\", \"mailto:john.doe@example.net\")\n        self.check_output(urlize, \"john.doe@example.com (test)\", \"john.doe@example.com (test)\")\n        self.check_output(urlize, \"john.doe@example.com, jane.doe@example.net\", \"john.doe@example.com, jane.doe@example.net\")\n"], "sample_783": ["compilation error"], "sample_516": ["    def test_text_kerning(self):\n        fig, ax = plt.subplots()\n        ax.text(0.5, 0.5, 'This is a test with kerning.', ha='center', va='center')\n        plt.savefig(io.BytesIO(), format='pdf')\n"], "sample_124": ["    def test_form_rendering_with_custom_renderer(self):\n        renderer = DjangoTemplates(\n            template_dir='django/contrib/admin/templates',\n            autoescape=True\n        )\n        form = Person(initial={'first_name': 'John', 'last_name': 'Doe'})\n        rendered_form = form.render(renderer)\n        self.assertIn('<input type=\"text\" name=\"first_name\" id=\"id_first_name\" value=\"John\">', rendered_form)\n        self.assertIn('<input type=\"text\" name=\"last_name\" id=\"id_last_name\" value=\"Doe\">', rendered_form)\n"], "sample_277": ["    def test_q_deconstruct(self):\n        q = Q(id__gt=1)\n        path, args, kwargs = q.deconstruct()\n        self.assertEqual(path, 'django.db.models.query_utils.Q')\n        self.assertEqual(args, (id__gt=1,))\n        self.assertEqual(kwargs, {})\n\n        q = Q(name='test', age__lt=30)\n        path, args, kwargs = q.deconstruct()\n        self.assertEqual(path, 'django.db.models.query_utils.Q')\n        self.assertEqual(args, (name='test', age__lt=30))\n        self.assertEqual(kwargs, {})\n\n        q = Q(id__gt=1, _connector=Q.OR)\n        path, args, kwargs = q.deconstruct()\n        self.assertEqual(path, 'django.db.models.query_utils.Q')\n        self.assertEqual(args, (id__gt=1,))\n        self.assertEqual(kwargs, {'_connector': Q.OR})\n\n        q = Q(id__gt=1, _negated=True)\n        path, args, kwargs = q.deconstruct()\n        self.assertEqual(path, 'django.db.models.query_utils.Q')\n        self.assertEqual(args, (id__gt=1,))\n        self.assertEqual(kwargs, {'_negated': True})\n\n        q = Q(id__gt=1) & Q(name='test')\n        path, args, kwargs = q.deconstruct()\n        self.assertEqual(path, 'django.db.models.query_utils.Q')\n        self.assertEqual(args, (id__gt=1, name='test'))\n        self.assertEqual(kwargs, {})\n\n\n\n"], "sample_90": ["    def test_custom_error_messages(self):\n        form = CustomErrorMessageForm(data={'name1': 'invalid'})\n        self.assertEqual(form.errors['name1'], ['Form custom error message.'])\n\n\n\n"], "sample_1151": ["    def test_mod_mul():\n        from sympy.core.numbers import nan\n        p = Mod(Mul(2, x), 3)\n        assert p.args == (Mul(2, x), 3)\n        assert p.evalf(3) == 2.0\n        p = Mod(Mul(2*x, 3), 5)\n        assert p.evalf(3) == 1.0\n        p = Mod(Mul(2*x, 3), 2)\n        assert p.evalf(3) == 0.0\n        p = Mod(Mul(2*x, 3), 0)\n        assert p is nan\n        p = Mod(Mul(2*x, 3), -2)\n        assert p.evalf(3) == 1.0\n        p = Mod(Mul(2*x, 3), -3)\n        assert p.evalf(3) == 0.0\n"], "sample_538": ["    def test_scaled_translation_identity(fig):\n        trans = ScaledTranslation(0, 0, fig.dpi_scale_trans)\n        assert_allclose(trans.get_matrix(), np.identity(3))\n"], "sample_545": ["    def test_constrained_layout_engine_with_subplots(self):\n        fig, axes = plt.subplots(2, 2)\n\n        # Add some content to the subplots\n        axes[0, 0].plot([1, 2, 3])\n        axes[0, 1].hist(np.random.randn(100))\n        axes[1, 0].scatter([1, 2, 3], [4, 5, 6])\n        axes[1, 1].text(0.5, 0.5, 'Text', ha='center', va='center')\n\n        # Set the constrained layout engine\n        fig.set_layout_engine(ConstrainedLayoutEngine())\n\n        # Adjust the layout\n        fig.tight_layout()\n\n        # Check that the layout is tight\n        check_figures_equal(fig, self.get_image_data('constrained_layout_subplots'))\n"], "sample_347": ["    def test_localtime_with_zoneinfo(self):\n        dt = datetime.datetime(2023, 10, 26, 10, 0, tzinfo=CET)\n        self.assertEqual(timezone.localtime(dt), dt.astimezone(timezone.get_current_timezone()))\n"], "sample_208": ["    def test_migration_dependencies_with_circular_fk(self):\n        before_states = [\n            rabbit,\n            knight,\n        ]\n        after_states = [\n            rabbit,\n            knight,\n        ]\n        changes = self.get_changes(before_states, after_states)\n        self.assertMigrationDependencies(changes, \"eggs\", 0, [])\n        self.assertMigrationDependencies(changes, \"eggs\", 1, [])\n\n\n\n"], "sample_1139": ["    def test_complex_region_from_real(self):\n        from sympy import Interval, ComplexRegion\n\n        unit = Interval(0,1)\n        region = ComplexRegion.from_real(unit)\n        self.assertEqual(region, CartesianComplexRegion(ProductSet(unit, FiniteSet(0))))\n        \n        self.assertEqual(region.a_interval, unit)\n        self.assertEqual(region.b_interval, FiniteSet(0))\n"], "sample_371": ["    def test_callable_setting_wrapper_repr(self):\n        callable_setting = lambda: 'value'\n        wrapper = CallableSettingWrapper(callable_setting)\n        self.assertEqual(repr(wrapper), repr(callable_setting))\n\n"], "sample_553": ["    def test_blitting_with_func_animation(self, anim):\n        # Test blitting with FuncAnimation\n        # This test is a bit more complex, as it involves creating a\n        # FuncAnimation object and then checking that the blitting works\n        # as expected.\n\n        # Create a NullMovieWriter to capture the frame data\n        writer = NullMovieWriter()\n        anim.save('test_blitting.mp4', writer=writer)\n\n        # Check that the correct number of frames were saved\n        assert writer._count == anim.get_frames()\n\n        # Check that the savefig_kwargs are as expected\n        assert writer.savefig_kwargs == {'bbox_inches': 'tight'}\n\n\n\n"], "sample_1": ["compilation error"], "sample_446": ["    def test_floatformat_with_grouping(self):\n        self.assertEqual(\n            self.render_template(\"floatformat01\", {\"a\": 1234.5678, \"b\": 1234567.89}),\n            \"1,234.57 1,234,567.90\",\n        )\n"], "sample_308": ["    def test_format_rfc5322(self):\n        dt = datetime(2000, 12, 21, 16, 1, 7)\n        formatted_dt = format(dt, 'r')\n        expected_dt = 'Thu, 21 Dec 2000 16:01:07 +0200'\n        self.assertEqual(formatted_dt, expected_dt)\n"], "sample_113": ["    def test_parse_rst(self):\n        text = \"\"\""], "sample_809": ["    def test_mutual_info_regression_sparse_continuous(self):\n        X = csr_matrix([[1, 2], [3, 4], [5, 6]])\n        y = np.array([0, 1, 0])\n        mi = mutual_info_regression(X, y, discrete_features=False)\n        assert_array_equal(mi.shape, (2,))\n        assert_greater(mi.max(), 0)\n"], "sample_845": ["    def test_stop_words_with_vocabulary(self):\n        vectorizer = TfidfVectorizer(vocabulary=['the', 'pizza', 'burger', 'beer'],\n                                     stop_words='english')\n        X = vectorizer.fit_transform(JUNK_FOOD_DOCS)\n        assert_array_equal(vectorizer.get_feature_names(), ['burger', 'beer', 'pizza', 'the'])\n        assert_array_equal(X.toarray(),\n                           [[1, 2, 1, 1], [1, 2, 1, 1], [1, 2, 1, 1],\n                            [1, 1, 0, 1], [0, 1, 0, 1], [0, 1, 0, 1]])\n"], "sample_1113": ["    def test_block_collapse_matmul_identity():\n        from sympy import BlockMatrix, Identity, MatMul\n        B = BlockMatrix([[X, Z], [ZeroMatrix(m, n), Y]])\n        I = Identity(n)\n        expr = MatMul(B, I)\n        result = block_collapse(expr)\n        assert result == BlockMatrix([[X, Z], [ZeroMatrix(m, n), Y]])\n"], "sample_393": ["    def test_no_obsolete_option(self):\n        output, po_contents = self._run_makemessages(no_obsolete=True)\n        self.assertMsgIdPlural(\n            \"This is a plural form\", po_contents, use_quotes=False\n        )\n        self.assertMsgStr(\"This is a string\", po_contents, use_quotes=False)\n        self.assertNotMsgId(\n            \"This is an obsolete string\", po_contents, use_quotes=False\n        )\n"], "sample_449": ["    def test_close_connection_on_handle(self):\n        request = self.request_factory.get(\"/\")\n        handler = WSGIRequestHandler(\n            UnclosableBytesIO(), UnclosableBytesIO(), None, request.environ\n        )\n        handler.close_connection = False\n        handler.handle_one_request()\n        self.assertTrue(handler.close_connection)\n\n        # Test that the connection is closed after handle_one_request()\n        handler.close_connection = True\n        handler.handle_one_request()\n        self.assertFalse(handler.close_connection)\n"], "sample_132": ["    def test_callable_setting_wrapper_not_called(self):\n        class CallableSetting:\n                raise Exception(\"This should not be called\")\n\n        wrapped = CallableSettingWrapper(CallableSetting())\n        self.assertIsNotNone(wrapped)\n        self.assertNotEqual(wrapped, CallableSetting())\n        self.assertIsNotNone(getattr(wrapped, '__call__'))\n        with self.assertRaises(Exception):\n            wrapped()\n"], "sample_771": ["    def test_power_transform_method_warning(self):\n        X = np.random.rand(10, 5)\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"always\")\n            result = power_transform(X, method='warn')\n        assert_array_almost_equal(result, power_transform(X, method='yeo-johnson'))\n"], "sample_1014": ["    def test_reshape_invalid_size(self):\n        a = ImmutableDenseNDimArray([1, 2, 3, 4, 5, 6], (2, 3))\n        with raises(ValueError):\n            a.reshape(4, 1)\n"], "sample_1074": ["    def test_polycyclic_group():\n        from sympy.combinatorics.pc_groups import PolycyclicGroup\n        G = SymmetricGroup(4)\n        pc = G.polycyclic_group()\n        assert isinstance(pc, PolycyclicGroup)\n        assert pc.order() == G.order()\n        assert pc.generators() == G.generators()\n        assert pc.relative_orders() == G.relative_orders()\n\n        G = DihedralGroup(6)\n        pc = G.polycyclic_group()\n        assert isinstance(pc, PolycyclicGroup)\n        assert pc.order() == G.order()\n        assert pc.generators() == G.generators()\n        assert pc.relative_orders() == G.relative_orders()\n\n        G = CyclicGroup(7)\n        pc = G.polycyclic_group()\n        assert isinstance(pc, PolycyclicGroup)\n        assert pc.order() == G.order()\n        assert pc.generators() == G.generators()\n        assert pc.relative_orders() == G.relative_orders()\n"], "sample_619": ["    def test_encode_decode_cf_datetime(\n        num_dates, units, calendar"], "sample_574": ["    def test_continuous_tick_locator(self, x):\n        a = self.setup_ticks(x, count=3)\n        assert_array_equal(a.majorticklocs(), [1, 3, 9])\n"], "sample_119": ["    def test_add_fields_with_m2m(self):\n        q = Query(Ranking)\n        q.add_fields(['id', 'name', 'author__name'])\n        self.assertEqual(q.select, (\n            SimpleCol('ranking_ranking.id', output_field=Ranking._meta.pk),\n            SimpleCol('ranking_ranking.name', output_field=Ranking._meta.get_field('name')),\n            SimpleCol('author_author.name', output_field=Author._meta.get_field('name')),\n        ))\n"], "sample_1184": ["compilation error"], "sample_739": ["    def test_multilabel_binarizer_sparse_output(self):\n        mlb = MultiLabelBinarizer(sparse_output=True)\n        y = [(1, 2), (3,), (1, 2, 3)]\n        y_bin = mlb.fit_transform(y)\n        assert issparse(y_bin)\n        assert y_bin.shape == (3, 3)\n"], "sample_409": ["    def test_blocktranslate_with_filter(self):\n        with translation.override(\"en\"):\n            t = Template(self.templates[\"i18n04\"])\n            c = Context({\"anton\": \"anton\"})\n            result = t.render(c)\n        self.assertEqual(result, \"ANTON\")\n"], "sample_714": ["    def test_brier_score_loss_multilabel(self):\n        X, y_true, y_prob = make_multilabel_classification(n_samples=100,\n                                                          n_features=10,\n                                                          n_classes=3,\n                                                          random_state=42)\n        y_true = np.array(y_true, dtype=int)\n        y_prob = np.random.rand(y_true.shape[0], y_true.shape[1])\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", UndefinedMetricWarning)\n            score = brier_score_loss(y_true, y_prob, pos_label=1)\n        assert np.isfinite(score)\n"], "sample_280": ["    def test_aggregate_filter(self):\n        with self.assertNumQueries(1):\n            result = Book.objects.filter(\n                Q(rating__gt=4) | Q(price__lt=Decimal('30.00'))\n            ).annotate(\n                avg_rating=Avg('rating')\n            ).values('avg_rating')\n        self.assertEqual(result[0]['avg_rating'], 4.375)\n\n        with self.assertNumQueries(1):\n            result = Book.objects.filter(\n                Q(rating__gt=4) | Q(price__lt=Decimal('30.00'))\n            ).annotate(\n                avg_rating=Avg('rating', filter=Q(publisher__name='Apress'))\n            ).values('avg_rating')\n        self.assertEqual(result[0]['avg_rating'], 4.5)\n\n        with self.assertNumQueries(1):\n            result = Book.objects.filter(\n                Q(rating__gt=4) | Q(price__lt=Decimal('30.00'))\n            ).annotate(\n                avg_rating=Avg('rating', filter=Q(publisher__name='Apress') & Q(pages__gt=300))\n            ).values('avg_rating')\n        self.assertEqual(result[0]['avg_rating'], 4.5)\n"], "sample_415": ["    def test_unique_constraint_with_expressions(self):\n        with atomic():\n            Product.objects.create(name=\"Product A\", description=\"Description A\")\n            with self.assertRaises(IntegrityError):\n                Product.objects.create(name=F(\"name\"), description=\"Description B\")\n"], "sample_1166": ["    def test_monomial_mul_pow(self):\n        m1 = Monomial((3, 4, 5))\n        m2 = Monomial((1, 2, 3))\n        k = 2\n        result = m1 * m2**k\n        expected = Monomial((3*1 + 2*k, 4*1 + 2*k, 5*1 + 2*k))\n        self.assertEqual(result, expected)\n"], "sample_143": ["    def test_smart_split_with_escaped_quotes(self):\n        self.assertEqual(list(text.smart_split(r'This is \"a \\'quoted\\\" string\"')), ['This', 'is', '\"a \\'quoted\\\" string'])\n        self.assertEqual(list(text.smart_split(r'This is \\'a \"quoted\\\" string\\'')), ['This', 'is', \"'a \\\"quoted\\\" string'\"])\n        self.assertEqual(list(text.smart_split(r'This is \"a \\'quoted\\\" string\"')), ['This', 'is', '\"a \\'quoted\\\" string'])\n"], "sample_159": ["    def test_check_user_model_non_unique_username(self):\n        with self.subTest('non_unique_username'):\n            with override_settings(AUTH_USER_MODEL='auth_tests.CustomUserNonUniqueUsername'):\n                errors = check_user_model()\n                self.assertEqual(len(errors), 1)\n                self.assertEqual(errors[0].id, 'auth.E003')\n"], "sample_570": ["    def test_kde_cumulative(self, x, y, weights):\n        kde = KDE(cumulative=True)\n        kde_result, _ = kde(x, weights=weights)\n        expected_integral = self.integrate(kde_result, x)\n        assert_array_almost_equal(expected_integral, 1.0, decimal=4)\n"], "sample_326": ["    def test_urlize_with_trailing_punctuation(self):\n        self.check_output(urlize, \"This is a URL: http://www.example.com.,\")\n        self.check_output(urlize, \"This is a URL: http://www.example.com;\")\n        self.check_output(urlize, \"This is a URL: http://www.example.com!\")\n        self.check_output(urlize, \"This is a URL: http://www.example.com(\")\n        self.check_output(urlize, \"This is a URL: http://www.example.com(,)\")\n\n        self.check_output(urlize, \"This is a URL: http://www.example.com?param1=value1&param2=value2\")\n"], "sample_511": ["compilation error"], "sample_383": ["compilation error"], "sample_877": ["    def test_isotonic_regression_increasing_decreasing(self):\n        X = np.array([1, 2, 3, 4, 5])\n        y = np.array([2, 4, 1, 3, 5])\n\n        # Increasing\n        increasing_y = isotonic_regression(y, increasing=True)\n        increasing_y_expected = np.array([2, 3, 4, 5, 5])\n        assert_array_almost_equal(increasing_y, increasing_y_expected)\n\n        # Decreasing\n        decreasing_y = isotonic_regression(y, increasing=False)\n        decreasing_y_expected = np.array([5, 4, 3, 2, 2])\n        assert_array_almost_equal(decreasing_y, decreasing_y_expected)\n"], "sample_712": ["    def test_onehotencoder_sparse_output(self):\n        enc = OneHotEncoder(sparse=True)\n        X = [['a', 1], ['b', 2], ['a', 3]]\n        enc.fit(X)\n        X_transformed = enc.transform(X)\n        assert isinstance(X_transformed, sparse.csr_matrix)\n"], "sample_563": ["    def test_offsetbox_padding(self):\n        fig, ax = plt.subplots()\n        bbox = OffsetBox(\n            DrawingArea(\n                (0, 0, 1, 1),\n                transform=ax.transData\n            )\n        )\n        bbox.set_pad(0.5)\n        bbox.draw(ax.figure.canvas.get_renderer())\n        bbox_extent = bbox.get_window_extent(ax.figure.canvas.get_renderer())\n        assert bbox_extent.width == 1.0 + 0.5 * 2\n        assert bbox_extent.height == 1.0 + 0.5 * 2\n\n        bbox = OffsetBox(\n            DrawingArea(\n                (0, 0, 1, 1),\n                transform=ax.transData\n            )\n        )\n        bbox.set_pad(0.5)\n        bbox.draw(ax.figure.canvas.get_renderer())\n        bbox_extent = bbox.get_window_extent(ax.figure.canvas.get_renderer())\n        assert bbox_extent.width == 1.0 + 0.5 * 2\n        assert bbox_extent.height == 1.0 + 0.5 * 2\n\n\n\n"], "sample_684": ["    def test_traceback_recursion_truncation(\n        self, exc_type, exc_value, expected_repr"], "sample_364": ["    def test_include_dynamic_module(self):\n        from .urlpatterns import dynamic_urlpatterns\n\n        with self.subTest('include dynamic module'):\n            with self.assertRaises(ImproperlyConfigured):\n                path('', include(dynamic_urlpatterns))\n"], "sample_500": ["def test_colorbar_extension_length(tmpdir):\n    \"\"\"\n    Test the length of colorbar extensions for different spacing and\n    extend settings.\n    \"\"\"\n    for spacing in ('uniform', 'proportional'):\n        fig = _colorbar_extension_length(spacing)\n        fig.savefig(f'colorbar_extensions_length_{spacing}.png')\n"], "sample_921": ["    def test_is_singledispatch_function(monkeypatch):\n        @functools.singledispatch\n            return x\n\n        @my_singledispatch_function.register(str)\n            return f\"String: {x}\"\n\n        assert inspect.is_singledispatch_function(my_singledispatch_function) is False\n        assert inspect.is_singledispatch_function(my_singledispatch_function) is False\n        assert inspect.is_singledispatch_method(my_singledispatch_function) is False\n        assert inspect.is_singledispatch_function(_(1)) is False\n        assert inspect.is_singledispatch_method(_(1)) is False\n        assert inspect.is_singledispatch_function(my_singledispatch_function(1)) is False\n        assert inspect.is_singledispatch_method(my_singledispatch_function(1)) is False\n        assert inspect.is_singledispatch_function(my_singledispatch_function(\"hello\")) is False\n        assert inspect.is_singledispatch_method(my_singledispatch_function(\"hello\")) is False\n        assert inspect.is_singledispatch_function(_(\"hello\")) is True\n        assert inspect.is_singledispatch_method(_(\"hello\")) is True\n\n\n\n"], "sample_125": ["    def test_set_cookie_with_expires_datetime(self):\n        response = HttpResponse()\n        with freeze_time(datetime(2023, 10, 27, 10, 0, 0, tzinfo=utc)):\n            response.set_cookie('test_cookie', 'value', expires=datetime(2023, 10, 28, 10, 0, 0, tzinfo=utc))\n        self.assertEqual(response.cookies['test_cookie']['expires'], http_date(1703891600))\n"], "sample_741": ["    def test_randomized_search_cv_with_multi_metric_scoring(self):\n        # Test with multiple scorers\n        X, y = make_classification(n_samples=100, n_features=20, random_state=42)\n        param_dist = {'C': uniform(1e-3, 10), 'kernel': ['linear', 'rbf']}\n        scorers = {'accuracy': make_scorer(accuracy_score),\n                   'f1': make_scorer(f1_score)}\n        clf = SVC()\n        rs = RandomizedSearchCV(clf, param_distributions=param_dist,\n                                n_iter=10, scoring=scorers, cv=5,\n                                refit='accuracy', random_state=42)\n        rs.fit(X, y)\n        assert_equal(rs.best_score_, rs.cv_results_['mean_test_accuracy'].max())\n        assert_equal(rs.best_params_, rs.cv_results_['params'][\n            rs.cv_results_['mean_test_accuracy'].argmax()])\n        assert_equal(rs.best_estimator_.score(X, y), rs.best_score_)\n\n        # Check that refitted estimator uses the best parameters\n        best_estimator = rs.best_estimator_\n        best_params = rs.best_params_\n        for param_name in best_params:\n            assert_equal(getattr(best_estimator, param_name),\n                         best_params[param_name])\n\n        # Check that the best score is the one corresponding to the refit metric\n        assert_equal(rs.best_score_, rs.cv_results_['mean_test_accuracy'].max())\n\n\n\n"], "sample_260": ["    def test_rename_model_with_unique_together(self):\n        operations = [\n            RenameModel('OldModel', 'NewModel'),\n            AlterModelOptions(\n                'NewModel',\n                {\n                    'unique_together': [\n                        ('field1', 'field2'),\n                    ],\n                },\n            ),\n        ]\n        self.assertOptimizesTo(\n            operations,\n            [\n                RenameModel('OldModel', 'NewModel'),\n                AlterModelOptions(\n                    'NewModel',\n                    {\n                        'unique_together': [\n                            ('field1', 'field2'),\n                        ],\n                    },\n                ),\n            ],\n            exact=2,\n        )\n\n\n\n"], "sample_268": ["    def test_iter_modules_and_files_with_zip(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            zip_path = Path(tmpdir) / 'test.zip'\n            with zipfile.ZipFile(zip_path, 'w') as zf:\n                zf.write('test_module.py', arcname='test_module.py')\n            extend_sys_path([tmpdir])\n            self.import_and_cleanup('test_module')\n            self.assertFileFound(zip_path / 'test_module.py')\n            self.assertFileFound(Path(tmpdir) / 'test_module.py')\n            self.assertFileNotFound(Path(__file__).parent / 'test_module.py')\n"], "sample_175": ["    def test_restricted_error(self):\n        b1 = create_a(B1, name='b1')\n        b2 = create_a(B2, name='b2')\n        b3 = create_a(B3, name='b3')\n        r = create_a(R, name='r', b1=b1)\n\n        with self.assertRaises(RestrictedError) as context:\n            collector = Collector(using=connection.db)\n            collector.collect(\n                [r], source=R, nullable=False, collect_related=True,\n                fail_on_restricted=True\n            )\n            collector.delete()\n        self.assertIn(\n            \"Cannot delete some instances of model 'R' because they are \"\n            \"referenced through restricted foreign keys: \"\n            \"'R.b1'\",\n            str(context.exception),\n        )\n"], "sample_879": ["    def test_ordinal_encoder_with_missing_values(\n        self, categories, handle_unknown, unknown_value, expected_output"], "sample_1069": ["    def test_piecewise_with_assign_to(self):\n        from sympy import Piecewise\n        expr = Piecewise((x + 1, x > 0), (x, True))\n        code = glsl_code(expr, assign_to=\"float y\")\n        expected = \"float y = if (x > 0) { x + 1; } else { x; }\"\n        self.assertEqual(code, expected)\n"], "sample_185": ["    def test_localize_input_with_datetime_formats(self):\n        with patch_formats('de', DATE_FORMAT='%d.%m.%Y', TIME_FORMAT='%H:%M'):\n            value = datetime.datetime(2023, 10, 26, 15, 30)\n            self.assertEqual(localize_input(value), '26.10.2023 15:30')\n"], "sample_587": ["    def test_merge_core_explicit_coords(self):\n        data = create_test_data(\n            {\"x\": np.arange(3), \"y\": np.arange(2)},\n            {\"z\": np.arange(2)},\n        )\n        coords = create_test_data(\n            {\"x\": np.arange(3), \"y\": np.arange(2)},\n            {\"z\": np.arange(2)},\n        )\n        explicit_coords = {\"x\", \"y\"}\n        with raises_regex(\n            MergeError,\n            r\"coordinate 'z' shares a name with a dataset dimension\",\n        ):\n            merge_core(\n                [data, coords],\n                explicit_coords=explicit_coords,\n            )\n"], "sample_324": ["    def test_csrf_exempt_view(self):\n        @csrf_exempt\n            return HttpResponse('CSRF exempt')\n\n        response = self.client.get(self.url_path)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content.decode(), 'CSRF exempt')\n\n        response = self.client.post(self.url_path)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content.decode(), 'CSRF exempt')\n"], "sample_738": ["    def test_stop_words_max_df(self):\n        # Test stop words removal based on max_df\n        vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n        X = vectorizer.fit_transform(ALL_FOOD_DOCS)\n        stop_words = vectorizer.stop_words_\n\n        # Check if 'the' is removed as it appears in more than 70% of documents\n        assert 'the' in stop_words\n\n        # Check if 'pizza' is not removed as it appears in less than 70% of documents\n        assert 'pizza' not in stop_words\n"], "sample_839": ["    def test_stop_words_with_vocabulary(self):\n        # Test stop words with a fixed vocabulary\n        vectorizer = TfidfVectorizer(vocabulary=[\"the\", \"pizza\", \"burger\", \"beer\", \"copyright\"],\n                                     stop_words='english')\n        X = vectorizer.fit_transform(JUNK_FOOD_DOCS)\n        assert_array_equal(vectorizer.stop_words_, set(['the']))\n        assert_array_equal(X.getnnz(axis=1), [3, 3, 3, 3, 2, 2])\n"], "sample_57": ["    def test_clean_password2_mismatch(self):\n        form = UserCreationForm(data={'username': 'test', 'password1': 'password', 'password2': 'wrongpassword'})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors['password2'], [self.error_messages['password_mismatch']])\n"], "sample_215": ["    def test_callable_setting_wrapper_calls_callable(self):\n            return 'called'\n\n        wrapped = CallableSettingWrapper(callable_setting)\n        self.assertEqual(wrapped(), 'called')\n\n\n\n"], "sample_521": ["    def test_poly3d_collection_projection(self):\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection='3d')\n\n        verts = [\n            [(0, 0, 0), (1, 0, 0), (1, 1, 0), (0, 1, 0)],\n            [(0, 0, 1), (1, 0, 1), (1, 1, 1), (0, 1, 1)],\n        ]\n        poly = Poly3DCollection(verts, facecolors='b', edgecolors='r')\n        ax.add_collection3d(poly)\n\n        ax.set_xlim(0, 1)\n        ax.set_ylim(0, 1)\n        ax.set_zlim(0, 1)\n        plt.show()\n"], "sample_689": ["    def test_deprecated_warnings(testdir):\n        testdir.makepyfile(\"\"\"\n                deprecated.FILLFUNCARGS\n        \"\"\")\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\n            * [f\"WARNING: {warning.message}\" for warning in deprecated.FILLFUNCARGS.args]\n        ])\n"], "sample_1205": ["    def test_content_primitive(self):\n        R, x = ring(\"x\", ZZ)\n        f = x**2 + 2*x + 1\n        c, p = f.content(), f.primitive()\n        self.assertEqual(c, 1)\n        self.assertEqual(p, x**2 + 2*x + 1)\n\n        f = 2*x**2 + 4*x + 2\n        c, p = f.content(), f.primitive()\n        self.assertEqual(c, 2)\n        self.assertEqual(p, x**2 + 2*x + 1)\n\n        f = 3*x**3 - 6*x**2 + 9*x\n        c, p = f.content(), f.primitive()\n        self.assertEqual(c, 3)\n        self.assertEqual(p, x**3 - 2*x**2 + 3*x)\n"], "sample_305": ["    def test_aggregate_with_subquery(self):\n        from django.db.models import OuterRef, Subquery\n\n        # Test that aggregates work correctly when used with a subquery\n        subquery = (\n            Book.objects.filter(rating__gt=4).values('publisher_id')\n        )\n        result = (\n            Book.objects.annotate(\n                publisher_count=Count('publisher', filter=Subquery(subquery))\n            ).values('publisher_id', 'publisher_count')\n        )\n        self.assertEqual(result.count(), 3)\n        self.assertObjectAttrs(result[0], publisher_id=1, publisher_count=2)\n        self.assertObjectAttrs(result[1], publisher_id=3, publisher_count=2)\n        self.assertObjectAttrs(result[2], publisher_id=4, publisher_count=1)\n"], "sample_58": ["    def test_hidden_fields(self):\n        form = Person()\n        hidden_fields = form.hidden_fields()\n        self.assertEqual(len(hidden_fields), 0)\n\n        form = PersonNew()\n        hidden_fields = form.hidden_fields()\n        self.assertEqual(len(hidden_fields), 0)\n\n        form = Person()\n        form.fields['first_name'] = HiddenInput()\n        hidden_fields = form.hidden_fields()\n        self.assertEqual(len(hidden_fields), 1)\n        self.assertEqual(hidden_fields[0].name, 'first_name')\n\n        form = PersonNew()\n        form.fields['first_name'] = HiddenInput()\n        hidden_fields = form.hidden_fields()\n        self.assertEqual(len(hidden_fields), 1)\n        self.assertEqual(hidden_fields[0].name, 'first_name')\n"], "sample_946": ["    def test_parse_annotation(self):\n        assert _parse_annotation('int') == 'int'\n        assert _parse_annotation('int, str') == 'int, str'\n        assert _parse_annotation('List[int]') == 'List[int]'\n        assert _parse_annotation('Optional[str]') == 'Optional[str]'\n        assert _parse_annotation('Union[int, str]') == 'Union[int, str]'\n        assert _parse_annotation('typing.List[int]') == 'typing.List[int]'\n        assert _parse_annotation('typing.Optional[str]') == 'typing.Optional[str]'\n        assert _parse_annotation('typing.Union[int, str]') == 'typing.Union[int, str]'\n\n\n\n"], "sample_572": ["    def test_kde_cumulative(self, x, y, weights):\n        kde = KDE(cumulative=True)\n        kde_eval = kde(x, weights=weights)\n        # Check that the integral of the KDE is approximately 1\n        assert_array_almost_equal(self.integrate(kde_eval, x), 1.0, decimal=4)\n"], "sample_396": ["compilation error"], "sample_800": ["    def __init__(self):\n        self.deprecated_tag = True\n"], "sample_899": ["    def test_sparse_transformer_fit_transform(self):\n        X = np.array([[1, 2], [3, 4], [5, 6]])\n        transformer = SparseTransformer()\n        X_sparse = transformer.fit_transform(X)\n        assert isinstance(X_sparse, sp.csr_matrix)\n        assert X_sparse.shape == X.shape\n\n\n\n"], "sample_390": ["    def test_serve_directory_index(self):\n        response = self.client.get(f\"/{self.prefix}/\")\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, \"Index of /site_media/\")\n        self.assertContains(response, \"<ul>\")\n        self.assertContains(response, \"</ul>\")\n"], "sample_861": ["    def test_param_grid_invalid_input(self, klass, input, error_type,\n                                      error_message):\n        with pytest.raises(error_type, match=error_message):\n            klass(input)\n"], "sample_1112": ["compilation error"], "sample_6": ["    def test_wrap_at_inplace(self):\n        a = Angle([10, 20, 30] * u.deg)\n        b = a.copy()\n        a.wrap_at(180 * u.deg, inplace=True)\n        assert_allclose(a.degree, np.array([-10, 20, 30]))\n        assert_allclose(b.degree, np.array([10, 20, 30]))\n"], "sample_267": ["    def test_sqlite_datetime_extract(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\"CREATE TABLE test_datetime_extract (dt DATETIME)\")\n            cursor.execute(\"INSERT INTO test_datetime_extract (dt) VALUES ('2023-10-27 10:30:00')\")\n            cursor.execute(\"INSERT INTO test_datetime_extract (dt) VALUES ('2023-10-27 15:45:00')\")\n\n        with connection.cursor() as cursor:\n            cursor.execute(\"SELECT week_day FROM test_datetime_extract WHERE dt = '2023-10-27 10:30:00'\")\n            self.assertEqual(cursor.fetchone()[0], 5)\n\n            cursor.execute(\"SELECT iso_week_day FROM test_datetime_extract WHERE dt = '2023-10-27 10:30:00'\")\n            self.assertEqual(cursor.fetchone()[0], 5)\n\n            cursor.execute(\"SELECT week FROM test_datetime_extract WHERE dt = '2023-10-27 10:30:00'\")\n            self.assertEqual(cursor.fetchone()[0], 43)\n\n            cursor.execute(\"SELECT quarter FROM test_datetime_extract WHERE dt = '2023-10-27 10:30:00'\")\n            self.assertEqual(cursor.fetchone()[0], 4)\n\n            cursor.execute(\"SELECT iso_year FROM test_datetime_extract WHERE dt = '2023-10-27 10:30:00'\")\n            self.assertEqual(cursor.fetchone()[0], 2023)\n\n            cursor.execute(\"SELECT year FROM test_datetime_extract WHERE dt = '2023-10-27 10:30:00'\")\n            self.assertEqual(cursor.fetchone()[0], 2023)\n\n            cursor.execute(\"SELECT month FROM test_datetime_extract WHERE dt = '2023-10-27 10:30:00'\")\n            self.assertEqual(cursor.fetchone()[0],"], "sample_1160": ["    def test_intersection_sets_productset_productset():\n        a = ProductSet((S.Naturals, S.Integers))\n        b = ProductSet((S.Integers, S.Naturals))\n        expected = ProductSet((S.Naturals, S.Integers))\n        assert intersection_sets(a, b) == expected\n\n"], "sample_697": ["    def test_getbasetemp_from_env(tmpdir_factory: TempPathFactory, pytester: Pytester) -> None:\n        os.environ[\"PYTEST_DEBUG_TEMPROOT\"] = str(pytester.getpath(\"temp\"))\n        factory = TempPathFactory.from_config(pytester.config, _ispytest=True)\n        basetemp = factory.getbasetemp()\n        assert basetemp.exists()\n        assert basetemp.parent == pathlib.Path(os.environ[\"PYTEST_DEBUG_TEMPROOT\"])\n        os.environ.pop(\"PYTEST_DEBUG_TEMPROOT\", None)\n"], "sample_654": ["    def test_fixture_lookup_error(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n                return \"fixture value\"\n\n            @pytest.fixture\n                raise ValueError(\"fixture error\")\n\n                assert myfixture == \"fixture value\"\n\n                assert myfixture_error == \"fixture error\"\n            \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines(\n            [\n                \"*= test_myfixture.py*::test_myfixture PASSED*\",\n                \"*= test_myfixture.py*::test_myfixture_error FAILED*\",\n                \"*FixtureLookupError: myfixture_error*\",\n            ]\n        )\n\n\n\n"], "sample_181": ["    def test_filtered_aggregate_with_subquery(self):\n        subquery = Book.objects.filter(rating__gt=3.5).values('contact__name')\n        avg_rating = Book.objects.annotate(\n            avg_rating=Avg('rating'),\n        ).filter(\n            contact__name__in=subquery\n        ).values('avg_rating')\n        self.assertEqual(list(avg_rating), [\n            {'avg_rating': 4.5},\n        ])\n\n\n\n"], "sample_1008": ["    def test_partial_velocity_multiple_frames(self):\n        N = ReferenceFrame('N')\n        A = N.orientnew('A', 'Body', [pi/2, pi/4, 0])\n        B = A.orientnew('B', 'Body', [pi/3, 0, pi/6])\n        u1, u2, u3 = dynamicsymbols('u1, u2, u3')\n        A.set_ang_vel(N, u1 * A.x + u2 * A.y)\n        B.set_ang_vel(A, u3 * B.z)\n        \n        self.assertEqual(B.partial_velocity(N, u1), B.z * u1)\n        self.assertEqual(B.partial_velocity(N, u2), B.y * u2)\n        self.assertEqual(B.partial_velocity(N, u3), B.z * u3)\n"], "sample_524": ["def test_colorbar_extension_length(tmpdir):\n    \"\"\"\n    Test the length of the colorbar extensions for different spacing and\n    extend types.\n    \"\"\"\n    fig = _colorbar_extension_length(spacing='uniform')\n    fig.savefig(str(tmpdir / 'colorbar_extension_length_uniform.png'))\n    fig = _colorbar_extension_length(spacing='proportional')\n    fig.savefig(str(tmpdir / 'colorbar_extension_length_proportional.png'))\n"], "sample_49": ["    def test_media_for_multiwidget(self):\n        class MyMultiWidget(MultiWidget):\n                super().__init__(*args, **kwargs)\n                self.widgets = [TextInput(), TextInput()]\n\n                return value\n\n        form = Form(\n            {\n                'field1': CharField(),\n            },\n            widgets={\n                'field1': MyMultiWidget(),\n            },\n        )\n        self.assertEqual(form.media, Media(js=['http://media.example.com/static/js/my_multiwidget.js']))\n\n\n\n"], "sample_780": ["    def test_partial_fit_perplexity(self, learning_method):\n        n_components, X = _build_sparse_mtx()\n        lda = LatentDirichletAllocation(n_components=n_components,\n                                        learning_method=learning_method,\n                                        total_samples=X.shape[0])\n        # partial_fit should work correctly even if we call it multiple times\n        for _ in range(5):\n            lda.partial_fit(X)\n\n        # Check perplexity\n        perplexity = lda.perplexity(X)\n        assert perplexity > 0\n\n\n\n"], "sample_131": ["    def test_test_db_signature(self):\n        connection = self.get_connection_copy()\n        # Mock out the _get_test_db_name method to return a specific value.\n        with mock.patch.object(connection, '_get_test_db_name', return_value='my_test_db'):\n            signature = connection.creation.test_db_signature()\n            self.assertEqual(signature, (\n                connection.settings_dict['HOST'],\n                connection.settings_dict['PORT'],\n                connection.settings_dict['ENGINE'],\n                'my_test_db',\n            ))\n"], "sample_789": ["    def test_adaboost_regressor_sample_weight(self):\n        X, y = shuffle(boston.data, boston.target, random_state=rng)\n        sample_weight = np.random.rand(boston.data.shape[0])\n        reg = AdaBoostRegressor(n_estimators=10, random_state=rng)\n        reg.fit(X, y, sample_weight=sample_weight)\n        assert_array_almost_equal(reg.estimator_weights_, np.exp(reg.estimator_weights_))\n"], "sample_889": ["    def test_calibration_display_from_estimator_ensemble(method, ensemble):\n        X, y = data()\n        if ensemble:\n            clf = VotingClassifier(\n                estimators=[\n                    (\"lr\", LogisticRegression(random_state=42)),\n                    (\"dt\", DecisionTreeClassifier(random_state=42)),\n                ],\n                voting=\"hard\",\n            )\n        else:\n            clf = LogisticRegression(random_state=42)\n        clf.fit(X, y)\n\n        disp = CalibrationDisplay.from_estimator(\n            clf, X, y, method=method, n_bins=10, ref_line=True\n        )\n        disp.plot()\n"], "sample_825": ["    def test_pls_with_non_square_matrices(self):\n        X = np.array([[1, 2], [3, 4], [5, 6]])\n        y = np.array([[7, 8], [9, 10], [11, 12]])\n        pls = PLSRegression(n_components=1)\n        with pytest.raises(ValueError):\n            pls.fit(X, y)\n"], "sample_781": ["    def test_oob_score(name):\n        ForestClassifier = FOREST_CLASSIFIERS[name]\n        clf = ForestClassifier(n_estimators=10, oob_score=True, random_state=1)\n        X, y = make_classification(n_samples=100, n_features=20, random_state=1)\n        clf.fit(X, y)\n        assert 'oob_score_' in clf.get_params()\n        assert 'oob_score' in clf.score(X, y)\n"], "sample_152": ["    def test_restricted_error(self):\n        b1 = create_a(B1, name='b1')\n        b2 = create_a(B2, name='b2')\n        b3 = create_a(B3, name='b3')\n        r = create_a(R, name='r', b1=b1, b2=b2)\n        with self.assertRaises(RestrictedError) as context:\n            b1.delete()\n        self.assertIn(str(b1), str(context.exception))\n        self.assertIn(str(r), str(context.exception))\n\n\n\n"], "sample_904": ["    def test_resolve_numref_xref_with_caption(self):\n        app = mock.Mock()\n        builder = mock.Mock()\n        env = mock.Mock()\n        env.config = mock.Mock(numfig_format={'figure': '{name} {number}'})\n        node = pending_xref(\n            'numref', 'fig1', 'refexplicit', 'My Figure Caption'\n        )\n        contnode = nodes.paragraph()\n        docname = 'testdoc'\n        target_node = nodes.paragraph(ids=['fig1'])\n        target_node.append(nodes.title(text='My Figure Caption'))\n        env.get_doctree = mock.Mock(return_value=nodes.document(\n            [target_node]\n        ))\n        domain = StandardDomain(env)\n        result = domain._resolve_numref_xref(env, 'testdoc', builder, 'numref',\n                                            'fig1', node, contnode)\n        assert_node(result, nodes.inline(\n            text='My Figure Caption',\n            classes=['std', 'numref']\n        ))\n\n\n\n"], "sample_153": ["    def test_check_database_backends(self):\n        with mock.patch('django.apps.apps.get_app_config') as get_app_config:\n            get_app_config.return_value = mock.MagicMock(name='myapp')\n            with mock.patch('django.db.backends.base.validation.BaseDatabaseValidation.check') as check:\n                check.return_value = []\n                result = check_database_backends(self.databases)\n                self.assertEqual(result, [])\n"], "sample_621": ["compilation error"], "sample_522": ["def test_colorbar_extension_length(tmpdir):\n    \"\"\"\n    Test that the colorbar extension length is correctly set for different\n    spacing and extend values.\n    \"\"\"\n    fig = _colorbar_extension_length(spacing='uniform')\n    fig.savefig(str(tmpdir.join('colorbar_extension_length_uniform.png')))\n    fig = _colorbar_extension_length(spacing='proportional')\n    fig.savefig(str(tmpdir.join('colorbar_extension_length_proportional.png')))\n"], "sample_844": ["def test_extend_region(r_plot, end):\n    n_samples = len(r_plot)\n    steep_point = np.ones(n_samples, dtype=bool)\n    xward_point = np.zeros(n_samples, dtype=bool)\n    start = 0\n    index = _extend_region(steep_point, xward_point, start, 2)\n    assert index == end\n"], "sample_895": ["    def test_remainder_passthrough(self):\n        X = np.array([[1, 2, 3], [4, 5, 6]])\n        ct = make_column_transformer(\n            (StandardScaler(), [0]), remainder=\"passthrough\"\n        )\n        X_transformed = ct.fit_transform(X)\n        assert_allclose(X_transformed[:, 0], StandardScaler().fit_transform(X[:, 0].reshape(-1, 1)))\n        assert_allclose(X_transformed[:, 1:], X[:, 1:])\n"], "sample_791": ["    def test_onehotencoder_fit_transform_sparse_with_drop(self):\n        X = np.array([[0, 1], [1, 0], [2, 1]])\n        encoder = OneHotEncoder(sparse=True, drop='first')\n        encoder.fit(X)\n        X_transformed = encoder.transform(X)\n        expected_shape = (3, 2)\n        assert_equal(X_transformed.shape, expected_shape)\n        assert_allclose(toarray(X_transformed),\n                        [[1, 0, 0],\n                         [0, 1, 0],\n                         [0, 0, 1]])\n"], "sample_539": ["    def test_span_selector_basic(ax, kwargs):\n        span_selector = widgets.SpanSelector(ax, lambda *args: None,\n                                            useblit=kwargs.get('useblit'),\n                                            button=kwargs.get('button'))\n        click_and_drag(ax, (0.1, 0.1), (0.9, 0.9))\n        assert_allclose(span_selector.verts, [(0.1, 0.1), (0.9, 0.9)])\n        span_selector.disconnect_events()\n"], "sample_331": ["    def test_parse_datetime_with_postgres_interval(self):\n        self.assertEqual(parse_datetime(\"3 days 04:05:06\"), datetime(2023, 10, 27, 4, 5, 6, tzinfo=get_fixed_timezone(0)))\n"], "sample_13": ["    def test_wrap_at_inplace(self):\n        a = Angle([10, 20, 30] * u.deg)\n        a_copy = a.copy()\n        a.wrap_at(180 * u.deg, inplace=True)\n        assert_allclose(a.degree, np.array([-10, 20, 30]))\n        assert_array_equal(a_copy.degree, np.array([10, 20, 30]))\n"], "sample_977": ["compilation error"], "sample_534": ["    def test_contourf_levels(self):\n        x = np.linspace(0, 10, 100)\n        y = np.linspace(0, 10, 100)\n        X, Y = np.meshgrid(x, y)\n        Z = np.sin(np.sqrt(X**2 + Y**2))\n        fig, ax = plt.subplots()\n        contour = ax.contourf(X, Y, Z, levels=np.linspace(0, 1, 11), cmap='viridis')\n        ax.set_xlim(0, 10)\n        ax.set_ylim(0, 10)\n        ax.set_aspect('equal')\n        plt.colorbar(contour)\n        plt.show()\n"], "sample_321": ["    def test_origin_verification_failure(self):\n        with override_settings(CSRF_TRUSTED_ORIGINS=['https://example.com']):\n            req = TestingHttpRequest()\n            req.method = 'POST'\n            req.META['HTTP_ORIGIN'] = 'http://evil.com'\n            middleware = CsrfViewMiddleware()\n            with self.assertRaises(RejectRequest) as cm:\n                middleware.process_request(req)\n            self.assertEqual(cm.exception.reason, REASON_BAD_ORIGIN % 'http://evil.com')\n\n"], "sample_126": ["    def test_migration_dependencies_circular(self):\n        before_states = [\n            rabbit,\n        ]\n        after_states = [\n            rabbit,\n        ]\n        changes = self.get_changes(before_states, after_states)\n        self.assertMigrationDependencies(changes, \"eggs\", 0, [])\n"], "sample_328": ["    def test_bulk_update_with_related_objects(self):\n        self.create_tags()\n        notes = Note.objects.all()\n        notes.update(tag=self.tags[0])\n        self.assertEqual(notes.first().tag, self.tags[0])\n"], "sample_615": ["    def test_unify_chunks_no_chunks(array, dim, expected):\n        result = unify_chunks(array, array)\n        assert_identical(result[0], expected)\n\n\n\n"], "sample_70": ["    def test_protected_error(self):\n        a = create_a()\n        r = R.objects.create(a=a)\n        with self.assertRaises(ProtectedError) as context:\n            a.delete()\n        self.assertIn(str(r), str(context.exception))\n"], "sample_1084": ["    def test_intersection_sets_complex_region_polar():\n        r = Symbol('r', positive=True)\n        theta = Symbol('theta')\n        cr1 = ComplexRegion(Interval(1, 2), Interval(0, pi))\n        cr2 = ComplexRegion(Interval(2, 3), Interval(pi/2, pi))\n        cr3 = cr1.intersect(cr2)\n        assert cr3.polar is True\n        assert cr3.sets == (Interval(2, 2), Interval(pi/2, pi))\n\n        cr4 = ComplexRegion(Interval(1, 2), Interval(0, pi))\n        cr5 = ComplexRegion(Interval(1, 2), Interval(pi/2, 2*pi))\n        cr6 = cr4.intersect(cr5)\n        assert cr6.polar is True\n        assert cr6.sets == (Interval(1, 2), Interval(pi/2, pi))\n\n        cr7 = ComplexRegion(Interval(1, 2), Interval(0, pi))\n        cr8 = ComplexRegion(Interval(2, 3), Interval(0, pi/2))\n        cr9 = cr7.intersect(cr8)\n        assert cr9.polar is True\n        assert cr9.sets == (Interval(2, 2), Interval(0, pi/2))\n\n        cr10 = ComplexRegion(Interval(1, 2), Interval(0, pi))\n        cr11 = ComplexRegion(Interval(2, 3), Interval(pi, 2*pi))\n        cr12 = cr10.intersect(cr11)\n        assert cr12.polar is True\n        assert cr12.sets == (Interval(2, 2), Interval(pi, pi))\n\n        cr13 = ComplexRegion(Interval(1, 2), Interval(0, pi))\n        cr14 = ComplexRegion(Interval(2, 3), Interval(pi, 2*pi))\n        cr15 = cr13.intersect(cr14)\n        assert cr15.polar is True\n        assert cr15.sets == (Interval(2, 2), Interval(pi, pi))\n\n        cr16 = ComplexRegion(Interval"], "sample_1157": ["    def test_implicit_multiplication_application_nested_parentheses(self):\n        expr = \"((2*x)*y)+z\"\n        result = parse_expr(expr, transformations=(implicit_multiplication_application,))\n        expected = Mul(Mul(2, x), y) + z\n        self.assertEqual(result, expected)\n\n\n\n"], "sample_1114": ["    def test_complex_region_from_real(self):\n        from sympy import Interval, ComplexRegion\n        unit = Interval(0,1)\n        region = ComplexRegion.from_real(unit)\n        self.assertEqual(region, CartesianComplexRegion(ProductSet(unit, FiniteSet(0))))\n"], "sample_353": ["    def test_create_superuser_with_password_validation_bypass(self):\n        with mock.patch('builtins.input', lambda prompt: None):\n            with mock.patch('getpass.getpass', lambda prompt: 'password123'):\n                call_command('createsuperuser', verbosity=0)\n"], "sample_204": ["    def test_inconsistent_history(self):\n        with override_settings(DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3'}}):\n            connection = connections['default']\n            with connection.cursor() as cursor:\n                cursor.execute(\"CREATE TABLE test_app_migration (id INTEGER PRIMARY KEY)\")\n            loader = MigrationLoader(connection)\n            recorder = MigrationRecorder(connection)\n            recorder.record_migration('test_app', '0001_initial')\n            loader.check_consistent_history(connection)\n            with self.assertRaises(InconsistentMigrationHistory):\n                recorder.record_migration('test_app', '0002_second')\n"], "sample_464": ["    def test_file_response_with_seekable_file(self):\n        with tempfile.NamedTemporaryFile(mode=\"wb\") as f:\n            f.write(b\"Hello, world!\")\n            f.seek(0)\n            response = FileResponse(f, as_attachment=True, filename=\"test.txt\")\n            self.assertEqual(response.status_code, 200)\n            self.assertEqual(response[\"Content-Type\"], \"application/octet-stream\")\n            self.assertEqual(response[\"Content-Disposition\"], 'attachment; filename=\"test.txt\"')\n            self.assertEqual(response[\"Content-Length\"], 13)\n            content = io.BytesIO()\n            for chunk in response:\n                content.write(chunk)\n            self.assertEqual(content.getvalue(), b\"Hello, world!\")\n"], "sample_941": ["    def test_restify_callable(self):\n            pass\n        assert restify(my_func) == ':class:`my_func[[int, str], *, c: Optional[float]]`'\n"], "sample_384": ["    def test_bulk_update_with_related_objects(self):\n        note = self.notes[0]\n        tag = self.tags[0]\n        note.tags.add(tag)\n        note.save()\n\n        notes = Note.objects.filter(id=note.id)\n        notes.update(note=\"Updated note\", misc=\"Updated misc\")\n        notes.update(tags=self.tags)\n\n        updated_note = Note.objects.get(id=note.id)\n        self.assertEqual(updated_note.note, \"Updated note\")\n        self.assertEqual(updated_note.misc, \"Updated misc\")\n        self.assertIn(tag, updated_note.tags.all())\n\n\n\n"], "sample_639": ["    def test_get_full_documentation(self):\n        checker = OtherBasicChecker()\n        doc = checker.get_full_documentation(\n            msgs=checker.msgs, options=checker.options_and_values(), reports=checker.reports\n        )\n        assert \"Basic checker has an example.\" in doc\n        assert \"example-args\" in doc\n        assert \"basic\" in doc\n        assert \"This checker is provided by ``__main__``.\" in doc\n\n\n\n"], "sample_184": ["    def test_index_together_with_related_fields(self):\n        with override_settings(DATABASE_ROUTERS={'default': EmptyRouter()}):\n            class Author(models.Model):\n                name = models.CharField(max_length=100)\n                books = models.ManyToManyField('Book', related_name='authors')\n\n            class Book(models.Model):\n                title = models.CharField(max_length=100)\n                authors = models.ManyToManyField('Author', related_name='books')\n\n                class Meta:\n                    index_together = [('title', 'authors')]\n\n            # Create some objects\n            author1 = Author.objects.create(name='Author 1')\n            author2 = Author.objects.create(name='Author 2')\n            book1 = Book.objects.create(title='Book 1')\n            book2 = Book.objects.create(title='Book 2')\n\n            book1.authors.add(author1)\n            book2.authors.add(author2)\n\n            # Check that the index is created\n            with connection.cursor() as cursor:\n                cursor.execute(\"SHOW INDEXES IN %s\" % Book._meta.db_table)\n                indexes = [row[2] for row in cursor.fetchall()]\n                self.assertIn('(title, authors)', indexes)\n\n"], "sample_1131": ["    def test_sympy_printer_sparse_matrix(self):\n        smat = SparseMatrix([[1, 2], [3, 4]], shape=(2, 2))\n        code = SymPyPrinter().doprint(smat)\n        self.assertEqual(code, \"sympy.Matrix([[1, 2], [3, 4]])\")\n"], "sample_458": ["    def test_floatformat_with_grouping(self):\n        self.assertEqual(\n            self.render_template(\"floatformat01\", {\"a\": 1234.5678, \"b\": 1234567.89}),\n            \"1,234.57 1,234,567.89\",\n        )\n"], "sample_99": ["    def test_trunc_datetime_with_tzinfo(self):\n        tz = pytz.timezone('America/New_York')\n        now = datetime.now(tz)\n        model = self.create_model(start_datetime=now, end_datetime=now + timedelta(hours=1))\n        truncated_datetime = Trunc('start_datetime', 'day')(model).resolve()\n        self.assertEqual(truncated_datetime, truncate_to(now, 'day', tz))\n"], "sample_937": ["compilation error"], "sample_1154": ["compilation error"], "sample_14": ["    def test_wrap_at_inplace(self):\n        a = Angle([10, 20, 30] * u.deg)\n        a_copy = a.copy()\n        a.wrap_at(180 * u.deg, inplace=True)\n        assert_allclose(a.degree, np.array([-170, 20, 10]) )\n        assert_allclose(a_copy.degree, np.array([10, 20, 30]))\n"], "sample_746": ["    def test_brier_score_loss_with_sample_weight():\n        y_true = np.array([0, 1, 1, 0])\n        y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n        sample_weight = np.array([0.2, 0.5, 0.1, 0.2])\n        score = brier_score_loss(y_true, y_prob, sample_weight=sample_weight)\n        expected_score = 0.037\n        assert_almost_equal(score, expected_score)\n"], "sample_814": ["compilation error"], "sample_509": ["    def test_microsecond_locator_epoch_far_from_default(self, tz):\n        with rc_context(\n            {\"date.converter\": \"auto\", \"date.interval_multiples\": True},\n        ):\n            fig, ax = plt.subplots()\n            x = np.arange(date2num(datetime.datetime(1900, 1, 1)),\n                          date2num(datetime.datetime(2000, 1, 1)),\n                          step=1e-6)\n            ax.plot(x, np.random.rand(len(x)))\n            ax.xaxis.set_major_locator(mdates.MicrosecondLocator(interval=1000))\n            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S.%f'))\n            plt.draw()\n            plt.close()\n\n\n\n"], "sample_608": ["    def test_format_timestamp(self):\n        ts = pd.Timestamp(\"2023-10-26 14:30:00\")\n        assert formatting.format_timestamp(ts) == \"2023-10-26 14:30:00\"\n\n        ts_with_tz = pd.Timestamp(\"2023-10-26 14:30:00\", tz=\"UTC\")\n        assert formatting.format_timestamp(ts_with_tz) == \"2023-10-26 14:30:00+00:00\"\n\n        ts_nan = pd.Timestamp.NaT\n        assert formatting.format_timestamp(ts_nan) == \"NaT\"\n"], "sample_748": ["def test_grid_search_cv_param_grid_errors():\n    from sklearn.model_selection import GridSearchCV\n    for input, error_type, error_message in [\n        (0, TypeError, 'Parameter grid is not a dict or a list (0)'),\n        ([{'foo': [0]}, 0], TypeError, 'Parameter grid is not a dict (0)'),\n        ({'foo': 0}, TypeError, \"Parameter grid value is not iterable \"\n         \"(key='foo', value=0)\"),\n        ({'foo': [0, 1]}, TypeError, \"Parameter grid value is not a list (key='foo', value=0)\"),\n        ({'foo': [0, 1], 'bar': 2}, TypeError, \"Parameter grid value is not a list (key='bar', value=2)\"),\n    ]:\n        with pytest.raises(error_type, match=error_message):\n            GridSearchCV(estimator=MockClassifier(), param_grid=input)\n\n\n\n"], "sample_601": ["    def test_timedelta_fields(self, field):\n        with pytest.raises(AttributeError):\n            self.data.dt.days_in_month\n"], "sample_145": ["    def test_check_raw_id_fields(self):\n        class RawIdAdmin(ModelAdmin):\n            raw_id_fields = ['id']\n\n        self.assertIsInvalid(RawIdAdmin, ValidationTestModel, 'The value of \"raw_id_fields\" must be a list of strings.', id='admin.E131')\n\n\n\n"], "sample_1020": ["compilation error"], "sample_1072": ["    def test_frac_complex():\n        assert frac(I).is_imaginary\n        assert frac(I).args[0] == I\n        assert frac(2*I).is_imaginary\n        assert frac(2*I).args[0] == 2*I\n        assert frac(x + I).is_imaginary\n        assert frac(x + I).args[0] == x + I\n        assert frac(x + I*y).is_imaginary\n        assert frac(x + I*y).args[0] == x + I*y\n        assert frac(x + I*y).rewrite(floor) == (x + I*y) - floor(x + I*y)\n        assert frac(x + I*y).rewrite(ceiling) == (x + I*y) + ceiling(-x - I*y)\n        assert frac(I*x).is_imaginary\n        assert frac(I*x).args[0] == I*x\n        assert frac(I*x).rewrite(floor) == (I*x) - floor(I*x)\n        assert frac(I*x).rewrite(ceiling) == (I*x) + ceiling(-I*x)\n        assert frac(x + I*x).is_imaginary\n        assert frac(x + I*x).args[0] == x + I*x\n        assert frac(x + I*x).rewrite(floor) == (x + I*x) - floor(x + I*x)\n        assert frac(x + I*x).rewrite(ceiling) == (x + I*x) + ceiling(-x - I*x)\n        assert frac(I*x + I*y).is_imaginary\n        assert frac(I*x + I*y).args[0] == I*x + I*y\n        assert frac(I*x + I*y).rewrite(floor) == (I*x + I*y) - floor(I*x + I*y)\n        assert frac(I*x + I*y).rewrite(ceiling) == (I*x + I*y) + ceiling(-I*x - I*y)\n\n\n\n"], "sample_228": ["    def test_formset_factory_with_custom_kwargs(self):\n        class CustomFormSet(formset_factory(CustomKwargForm, extra=1)):\n            pass\n\n        formset = CustomFormSet(custom_kwarg='test_value')\n        self.assertEqual(formset.forms[0].custom_kwarg, 'test_value')\n"], "sample_757": ["    def test_onehotencoder_legacy_fit_transform_with_unknown_categories(self):\n        enc = OneHotEncoder(handle_unknown='ignore', n_values=[2, 3])\n        X = np.array([[0, 1], [2, 0], [3, 2]])\n        X_transformed = enc.fit_transform(X)\n        assert_array_equal(X_transformed.shape, (3, 5))\n        assert_allclose(X_transformed.toarray(),\n                        [[1., 0., 0., 0., 0.],\n                         [0., 1., 0., 0., 0.],\n                         [0., 0., 0., 1., 0.]])\n"], "sample_764": ["    def test_remainder_estimator(self):\n        X = np.array([[1, 2], [3, 4]])\n        remainder_est = Trans()\n        ct = ColumnTransformer(\n            transformers=[(\"scaler\", StandardScaler(), [0]),\n                          (\"remainder\", remainder_est, [1])],\n            remainder='remainder',\n        )\n        ct.fit(X)\n        transformed_X = ct.transform(X)\n        expected_X = np.array([[1, 2], [3, 4]])\n        expected_X[:, 0] = ct.transformers_[0][1].transform(expected_X[:, 0].reshape(-1, 1))\n        expected_X[:, 1] = remainder_est.transform(expected_X[:, 1].reshape(-1, 1))\n        assert_allclose_dense_sparse(transformed_X, expected_X)\n"], "sample_994": ["    def test_sympify_complex():\n        assert sympify(complex(1, 2)) == S.One + 2*S.ImaginaryUnit\n        assert sympify(complex(1.2, 3.4)) == S.One + 2*S.ImaginaryUnit\n        assert sympify(complex(0, 1)) == S.ImaginaryUnit\n        assert sympify(complex(1, 0)) == S.One\n        assert sympify(complex(-1, 0)) == -S.One\n        assert sympify(complex(0, -1)) == -S.ImaginaryUnit\n        assert sympify(complex(1j)) == S.ImaginaryUnit\n        assert sympify(complex(-1j)) == -S.ImaginaryUnit\n        assert sympify(complex(1.234j)) == 1.234*S.ImaginaryUnit\n        assert sympify(complex(1.234, -1.234j)) == S.One + 2*S.ImaginaryUnit\n        assert sympify(complex(0.0, 1.0)) == S.ImaginaryUnit\n        assert sympify(complex(1.0, 0.0)) == S.One\n        assert sympify(complex(0.0, -1.0)) == -S.ImaginaryUnit\n        assert sympify(complex(1.0, 1.0)) == S.One + S.ImaginaryUnit\n        assert sympify(complex(-1.0, -1.0)) == -S.One - S.ImaginaryUnit\n        assert sympify(complex(1.0, -1.0)) == S.One - S.ImaginaryUnit\n        assert sympify(complex(-1.0, 1.0)) == -S.One + S.ImaginaryUnit\n"], "sample_257": ["    def test_json_field_contains_lookup(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\n                'INSERT INTO jsonmodel (id, data) VALUES (%s, %s)',\n                [(1, '{\"name\": \"John\", \"age\": 30}'),]\n            )\n        self.assertEqual(\n            JSONModel.objects.filter(data__contains={'name': 'John'}).count(), 1\n        )\n        self.assertEqual(\n            JSONModel.objects.filter(data__contains={'age': 30}).count(), 1\n        )\n        self.assertEqual(\n            JSONModel.objects.filter(data__contains={'city': 'New York'}).count(), 0\n        )\n"], "sample_141": ["    def test_serialize_with_deferred_fields(self):\n        article = self.create_article()\n        article.categories.add(self.create_category('Reference'))\n        article.categories.add(self.create_category('Non-fiction'))\n        article.save()\n\n        # Serialize the article with deferred fields\n        serializer = serializers.get_serializer('json')\n        serialized_data = serializer.serialize([article], use_natural_foreign_keys=True)\n\n        # Deserialize the data\n        deserializer = serializers.get_deserializer('json')\n        deserialized_objects = list(deserializer(serialized_data))\n\n        # Assert that the deserialized object has the correct categories\n        self.assertEqual(len(deserialized_objects), 1)\n        deserialized_article = deserialized_objects[0]\n        self.assertEqual(deserialized_article.object.categories.count(), 2)\n        self.assertIn(self.create_category('Reference'), deserialized_article.object.categories.all())\n        self.assertIn(self.create_category('Non-fiction'), deserialized_article.object.categories.all())\n\n\n\n"], "sample_494": ["    def test_serialize_datetime_with_timezone(self):\n        now = datetime.datetime.now(zoneinfo.ZoneInfo(\"America/Los_Angeles\"))\n        serializer = DateTimeSerializer(now)\n        serialized, imports = serializer.serialize()\n        self.assertEqual(\n            serialized,\n            \"datetime.datetime(2023, 10, 26, 16, 48, 37, 123456, tzinfo=datetime.timezone(datetime.timedelta(hours=-8)))\",\n            \"Serialized datetime with timezone should be correct\",\n        )\n        self.assertEqual(imports, {\"import datetime\"}, \"Imports should be correct\")\n"], "sample_1066": ["    def test_mathml_presentation_complex(self):\n        expr = complex(1, 2)\n        s = MathMLPresentationPrinter()\n        xml = s._print(expr)\n        s.apply_patch()\n        pretty_xml = xml.toprettyxml()\n        s.restore_patch()\n        assert 'mi' in pretty_xml and 'mn' in pretty_xml and 'mo' in pretty_xml\n        assert '1' in pretty_xml and '2' in pretty_xml and 'i' in pretty_xml\n"], "sample_74": ["    def test_runshell_db_with_ssl(self):\n        dbinfo = {\n            'host': 'localhost',\n            'database': 'mydatabase',\n            'user': 'myuser',\n            'password': 'mypassword',\n            'sslmode': 'require',\n            'sslrootcert': '/path/to/rootcert',\n            'sslcert': '/path/to/cert',\n            'sslkey': '/path/to/key',\n        }\n        args, env = self._run_it(dbinfo)\n        self.assertIn('-h', args)\n        self.assertIn('-U', args)\n        self.assertIn('mydatabase', args)\n        self.assertIn('PGSSLMODE', env)\n        self.assertEqual(env['PGSSLMODE'], 'require')\n        self.assertIn('PGSSLROOTCERT', env)\n        self.assertEqual(env['PGSSLROOTCERT'], '/path/to/rootcert')\n        self.assertIn('PGSSLCERT', env)\n        self.assertEqual(env['PGSSLCERT'], '/path/to/cert')\n        self.assertIn('PGSSLKEY', env)\n        self.assertEqual(env['PGSSLKEY'], '/path/to/key')\n"], "sample_61": ["    def test_ascii_username_validator(self):\n        validator = ASCIIUsernameValidator()\n        self.assertEqual(validator.regex, r'^[\\w.@+-]+\\Z')\n        self.assertEqual(validator.message, _(\n            'Enter a valid username. This value may contain only English letters, '\n            'numbers, and @/./+/-/_ characters.'\n        ))\n        self.assertEqual(validator.flags, re.ASCII)\n\n        self.assertTrue(validator('johndoe'))\n        self.assertTrue(validator('john.doe'))\n        self.assertTrue(validator('john_doe'))\n        self.assertTrue(validator('john+doe'))\n        self.assertTrue(validator('john@doe'))\n\n        with self.assertRaises(ValidationError):\n            validator('john doe')\n        with self.assertRaises(ValidationError):\n            validator('john123!@#$%^')\n"], "sample_926": ["    def test_enum_with_scoped_name("], "sample_43": ["    def test_regular_events(self, dt):\n        t = np.arange(0, 10, dt)\n        x = np.zeros(len(t))\n        x[np.random.randint(0, len(t), len(t) // 10)] = 1\n        edges = bayesian_blocks(t, x, fitness='regular_events', dt=dt)\n        assert len(edges) > 1\n        assert np.all(edges[1:] > edges[:-1])\n"], "sample_1191": ["compilation error"], "sample_96": ["    def test_check_ordering_item_with_random_ordering(self):\n        class MyModelAdmin(ModelAdmin):\n            ordering = ['?', 'title']\n\n        self.assertIsInvalid(\n            MyModelAdmin(ValidationTestModel, AdminSite()),\n            ValidationTestModel,\n            \"The value of 'ordering' has the random ordering marker '?', but contains other fields as well.\",\n            id='admin.E032',\n        )\n"], "sample_158": ["    def test_check_through_fields(self):\n        with override_settings(DATABASE_ROUTERS=['django.db.backends.sqlite3.base.Router']):\n            class MyModel(models.Model):\n                pass\n\n            class MyThroughModel(models.Model):\n                pass\n\n            class MyOtherModel(models.Model):\n                pass\n\n            class MyModelWithManyToMany(models.Model):\n                my_m2m = models.ManyToManyField(MyOtherModel, through=MyThroughModel, through_fields=('my_field1', 'my_field2'))\n\n            with self.assertRaises(Error) as context:\n                MyModelWithManyToMany._meta.get_field('my_m2m').check()\n            self.assertIn('The intermediary model \"MyThroughModel\" has no field \"my_field1\"', str(context.exception))\n\n            with self.assertRaises(Error) as context:\n                MyModelWithManyToMany._meta.get_field('my_m2m').check()\n            self.assertIn('The intermediary model \"MyThroughModel\" has no field \"my_field2\"', str(context.exception))\n\n            with self.assertRaises(Error) as context:\n                MyModelWithManyToMany._meta.get_field('my_m2m').check()\n            self.assertIn('Did you mean one of the following foreign keys to \"MyOtherModel\":', str(context.exception))\n\n\n\n"], "sample_102": ["    def test_union_with_distinct(self):\n        numbers = Number.objects.filter(num__gt=5).union(Number.objects.filter(num__lt=5))\n        self.assertNumbersEqual(numbers, list(range(10)))\n\n        numbers = Number.objects.filter(num__gt=5).union(Number.objects.filter(num__lt=5), distinct=True)\n        self.assertNumbersEqual(numbers, list(range(10)), ordered=False)\n"], "sample_352": ["    def test_where_node_split_having(self):\n        from django.db.models.sql.where import WhereNode\n\n        # Test split_having with a simple aggregate\n        node = WhereNode(\n            [\n                WhereNode(\n                    [Q(id__gt=1)],\n                    connector=AND,\n                    negated=False,\n                ),\n                Count('id'),\n            ],\n            connector=AND,\n            negated=False,\n        )\n        where, having = node.split_having()\n        self.assertIsNotNone(where)\n        self.assertIsNotNone(having)\n        self.assertEqual(where.children[0].children[0].children[0].connector, AND)\n        self.assertEqual(having.children[0].__class__.__name__, 'Count')\n\n        # Test split_having with a complex expression\n        node = WhereNode(\n            [\n                WhereNode(\n                    [\n                        Q(id__gt=1),\n                        Q(name__startswith='a'),\n                    ],\n                    connector=AND,\n                    negated=False,\n                ),\n                Count('id'),\n            ],\n            connector=AND,\n            negated=False,\n        )\n        where, having = node.split_having()\n        self.assertIsNotNone(where)\n        self.assertIsNotNone(having)\n        self.assertEqual(where.children[0].children[0].children[0].connector, AND)\n        self.assertEqual(having.children[0].__class__.__name__, 'Count')\n\n        # Test split_having with no aggregates\n        node = WhereNode(\n            [Q(id__gt=1), Q(name__startswith='a')], connector=AND, negated=False\n        )\n        where, having = node.split_having()\n        self.assertIsNotNone(where)\n        self.assertIsNone(having)\n        self.assertEqual(where.children[0].children[0].connector, AND)\n\n        # Test split_having with negated conditions\n        node = WhereNode(\n            [\n                WhereNode(\n                    [Q(id__lt=1)], connector=AND, negated=True\n                ),\n                Count('id'),\n            ],\n            "], "sample_815": ["    def test_brier_score_loss_multiclass():\n        X, y_true, y_prob = make_prediction(dataset=datasets.load_iris(), binary=False)\n        y_true = label_binarize(y_true, classes=range(3))\n        with ignore_warnings(category=UndefinedMetricWarning):\n            assert_almost_equal(brier_score_loss(y_true, y_prob),\n                                brier_score_loss(y_true, y_prob,\n                                                pos_label=1))\n\n\n\n"], "sample_1189": ["    def test_lambdastr_with_nested_lists():\n        expr = x + y + [z]\n        args = [x, y, z]\n        expected = 'lambda _0,_1,_2: (_0 + _1 + [_2])'\n        assert lambdastr(args, expr) == expected\n"], "sample_189": ["    def test_incr_decr(self):\n        cache = cache\n        key = 'test_incr_decr'\n        cache.set(key, 10)\n        self.assertEqual(cache.incr(key), 11)\n        self.assertEqual(cache.get(key), 11)\n        self.assertEqual(cache.decr(key), 10)\n        self.assertEqual(cache.get(key), 10)\n\n\n\n"], "sample_281": ["    def test_autocomplete_with_permission_denied(self):\n        request = self.factory.get(self.url, data={\n            'app_label': 'my_app',\n            'model_name': 'question',\n            'field_name': 'author',\n            'term': 'foo',\n        })\n        request.user = self.user\n        with self.assertRaises(PermissionDenied):\n            AutocompleteJsonView.as_view()(request, *self.as_view_args)\n"], "sample_846": ["    def test_remainder_estimator(self):\n        # Test remainder estimator\n        class RemainderEstimator(BaseEstimator):\n                return self\n\n                return X * 2\n\n        X = np.array([[1, 2], [3, 4], [5, 6]])\n        ct = ColumnTransformer(\n            transformers=[\n                (\"scaler\", StandardScaler(), [0]),\n                (\"remainder\", RemainderEstimator(), slice(1, None))\n            ],\n            remainder=\"remainder\"\n        )\n        ct.fit(X)\n        transformed_X = ct.transform(X)\n        expected_X = np.array([[1.41421356, 4.0],\n                              [1.41421356, 4.0],\n                              [1.41421356, 4.0]])\n        assert_allclose_dense_sparse(transformed_X, expected_X)\n"], "sample_1104": ["    def test_print_complex_root_of(self):\n        expr = RootSum(x**2 + 1, 0)\n        s = sstr(expr)\n        self.assertEqual(s, \"RootSum(x**2 + 1, 0)\")\n"], "sample_4": ["    def test_write_html_table_latex_names(self, cosmo):\n        with pytest.raises(ValueError) as excinfo:\n            write_html_table(cosmo, \"test.html\", latex_names=True)\n        assert \"format must be 'ascii.html', not 'ascii.html'\" in str(excinfo.value)\n"], "sample_442": ["    def test_signature_expires(self):\n        signer = signing.get_cookie_signer()\n        data = {\"key\": \"value\"}\n        signed_data = signer.sign_object(data, max_age=1)\n        with self.assertRaises(signing.SignatureExpired):\n            signer.unsign_object(signed_data, max_age=0)\n"], "sample_33": ["    def test_strip_accents(self):\n        assert misc.strip_accents(\"\u00f6\") == \"o\"\n        assert misc.strip_accents(\"\u00e4\") == \"a\"\n        assert misc.strip_accents(\"\u00e9\") == \"e\"\n        assert misc.strip_accents(\"\u00fc\") == \"u\"\n        assert misc.strip_accents(\"\u00c5\") == \"A\"\n        assert misc.strip_accents(\"\u00df\") == \"ss\"\n        assert misc.strip_accents(\"\u00f1\") == \"n\"\n        assert misc.strip_accents(\"\u00e7\") == \"c\"\n        assert misc.strip_accents(\"\u00e0\") == \"a\"\n        assert misc.strip_accents(\"\u00e2\") == \"a\"\n        assert misc.strip_accents(\"\u00e9\") == \"e\"\n        assert misc.strip_accents(\"\u00ea\") == \"e\"\n        assert misc.strip_accents(\"\u00eb\") == \"e\"\n        assert misc.strip_accents(\"\u00ef\") == \"i\"\n        assert misc.strip_accents(\"\u00ee\") == \"i\"\n        assert misc.strip_accents(\"\u00f4\") == \"o\"\n        assert misc.strip_accents(\"\u00fb\") == \"u\"\n        assert misc.strip_accents(\"\u00f9\") == \"u\"\n        assert misc.strip_accents(\"\u00ff\") == \"y\"\n        assert misc.strip_accents(\"\u00fe\") == \"th\"\n        assert misc.strip_accents(\"\u00de\") == \"Th\"\n        assert misc.strip_accents(\"\u0153\") == \"oe\"\n        assert misc.strip_accents(\"\u0152\") == \"Oe\"\n        assert misc.strip_accents(\"\u00df\") == \"ss\"\n        assert misc.strip_accents(\"\u00c5\") == \"A\"\n        assert misc.strip_accents(\"\u00c6\") == \"AE\"\n        assert misc.strip_accents(\"\u00e6\") == \"ae\"\n        assert misc.strip_accents(\"\u00c7\") == \"C\"\n        assert misc.strip_accents(\"\u00d0\") == \"D\"\n        assert misc.strip_accents(\"\u00f0\") == \"d\"\n        assert misc.strip_accents(\"\u00d1\") == \"N\"\n        "], "sample_86": ["    def test_lazy_object_copy(self):\n        class MyObject:\n                self.value = value\n\n            return MyObject(value)\n\n        lazy_obj = SimpleLazyObject(create_object)\n        lazy_obj._wrapped = MyObject(1)\n        copy_obj = copy.copy(lazy_obj)\n        self.assertNotSame(lazy_obj, copy_obj)\n        self.assertEqual(lazy_obj._wrapped.value, 1)\n        self.assertEqual(copy_obj._wrapped.value, 1)\n"], "sample_249": ["    def test_db_signature(self):\n        with override_settings(DATABASES={'default': {'NAME': 'test_db'}}):\n            connection.close()\n            connection.connect()\n            creation = BaseDatabaseCreation(get_connection_copy())\n            signature1 = creation.test_db_signature()\n\n            # Modify the database name\n            connections['default'].settings_dict['NAME'] = 'test_db_modified'\n            signature2 = creation.test_db_signature()\n\n            self.assertNotEqual(signature1, signature2)\n\n            # Restore the original database name\n            connections['default'].settings_dict['NAME'] = 'test_db'\n"], "sample_1203": ["compilation error"], "sample_359": ["    def test_alter_model_options(self):\n        with atomic():\n            # Create a model with some options\n            self.create_model(\n                'my_app',\n                'MyModel',\n                fields=[\n                    models.CharField(max_length=100),\n                ],\n                options={\n                    'ordering': ['name'],\n                    'permissions': [\n                        ('can_view', 'Can view my model'),\n                    ],\n                },\n            )\n            # Get the initial state\n            state = self.get_state()\n\n            # Alter the options\n            state.alter_model_options(\n                'my_app', 'mymodel', {\n                    'ordering': ['name', '-id'],\n                    'permissions': [\n                        ('can_edit', 'Can edit my model'),\n                    ],\n                },\n            )\n\n            # Apply the changes\n            with self.assertNumQueries(2):\n                self.apply_state(state)\n\n            # Check the new state\n            new_state = self.get_state()\n            self.assertEqual(\n                new_state.models['my_app', 'mymodel'].options['ordering'],\n                ['name', '-id'],\n            )\n            self.assertEqual(\n                new_state.models['my_app', 'mymodel'].permissions,\n                [('can_edit', 'Can edit my model')],\n            )\n\n            # Roll back the changes\n            with self.assertNumQueries(2):\n                self.rollback_state(state)\n\n            # Check the original state\n            state = self.get_state()\n            self.assertEqual(\n                state.models['my_app', 'mymodel'].options['ordering'],\n                ['name'],\n            )\n            self.assertEqual(\n                state.models['my_app', 'mymodel'].permissions,\n                [('can_view', 'Can view my model')],\n            )\n\n\n\n"], "sample_484": ["    def test_right(self):\n        john_smith = Author.objects.get(name=\"John Smith\")\n        right_name = Author.objects.filter(name=\"John Smith\").values(\n            \"name\"\n        ).annotate(\n            right_three=Right(\"name\", 3)\n        ).get()\n        self.assertEqual(right_name[\"right_three\"], \"ith\")\n"], "sample_34": ["    def test_composite_unit_pickle(tmpdir):\n        u = u.CompositeUnit(10, [u.meter, u.meter], [1, 2])\n        with open(tmpdir / 'test.pickle', 'wb') as f:\n            pickle.dump(u, f)\n        with open(tmpdir / 'test.pickle', 'rb') as f:\n            u_loaded = pickle.load(f)\n        assert u_loaded.scale == 10\n        assert u_loaded.bases == [u.meter, u.meter]\n        assert u_loaded.powers == [1, 2]\n\n\n\n"], "sample_298": ["    def test_token_generation_with_custom_email_field(self):\n        settings.PASSWORD_RESET_TIMEOUT = 10\n        with override_settings(PASSWORD_RESET_TIMEOUT=10):\n            user = User.objects.create_user(username='testuser', password='password')\n            user.email = 'test@example.com'\n            user.save()\n            user.email_field = CustomEmailField()\n            user.save()\n\n            generator = MockedPasswordResetTokenGenerator(datetime.now())\n            token = generator.make_token(user)\n\n            self.assertTrue(generator.check_token(user, token))\n"], "sample_243": ["    def test_add_ordering(self):\n        q = Query(Ranking)\n        q.add_ordering('id')\n        self.assertEqual(q.order_by, [('id', 'ASC')])\n\n        q = Query(Ranking)\n        q.add_ordering('-id')\n        self.assertEqual(q.order_by, [('id', 'DESC')])\n\n        q = Query(Ranking)\n        q.add_ordering('name')\n        self.assertEqual(q.order_by, [('name', 'ASC')])\n\n        q = Query(Ranking)\n        q.add_ordering('?')\n        self.assertEqual(q.order_by, [('?', 'ASC')])\n\n        q = Query(Ranking)\n        q.add_ordering('id', 'DESC')\n        self.assertEqual(q.order_by, [('id', 'DESC')])\n\n        q = Query(Ranking)\n        q.add_ordering('id', 'ASC')\n        self.assertEqual(q.order_by, [('id', 'ASC')])\n\n        q = Query(Ranking)\n        q.add_ordering('name', 'DESC')\n        self.assertEqual(q.order_by, [('name', 'DESC')])\n\n        q = Query(Ranking)\n        q.add_ordering('id', 'ASC', 'name', 'DESC')\n        self.assertEqual(q.order_by, [('id', 'ASC'), ('name', 'DESC')])\n\n        q = Query(Ranking)\n        q.add_ordering('id', 'ASC', 'name', 'ASC')\n        self.assertEqual(q.order_by, [('id', 'ASC'), ('name', 'ASC')])\n\n        q = Query(Ranking)\n        q.add_ordering('id', 'DESC', 'name', 'ASC')\n        self.assertEqual(q.order_by, [('id', 'DESC'), ('name', 'ASC')])\n\n        q = Query(Ranking)\n        q.add_ordering('id', 'ASC', 'name', 'DESC')\n        self.assertEqual(q.order_by, [('id', 'ASC'), ('name', 'DESC')])\n\n        q = Query(Ranking)\n        q.add_"], "sample_1050": ["    def test_sparse_matrix(self):\n        m = SparseMatrix(((1, 0, 2), (0, 1, 3)), shape=(2, 3))\n        s = SciPyPrinter().doprint(m)\n        assert s == \"scipy.sparse.coo_matrix([[2, 0, 0], [0, 1, 3]], ((0, 0), (1, 1), (1, 2)), shape=(2, 3))\"\n\n\n\n"], "sample_769": ["    def test_brier_score_loss_with_sample_weight():\n        y_true = np.array([0, 1, 1, 0])\n        y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n        sample_weight = np.array([0.2, 0.5, 0.1, 0.2])\n        score = brier_score_loss(y_true, y_prob, sample_weight=sample_weight)\n        expected_score = 0.037\n        assert_almost_equal(score, expected_score)\n\n\n\n"], "sample_933": ["    def test_gettext_output(self, app, tmpdir):\n        app.build()\n        pot_file = os.path.join(app.outdir, 'messages.pot')\n        assert os.path.exists(pot_file)\n\n        with open(pot_file, 'r', encoding='utf-8') as f:\n            pot_content = f.read()\n\n        # Check if the POT file contains expected messages\n        assert 'msgid \"Hello, world!\"' in pot_content\n        assert 'msgid \"This is a test message.\" ' in pot_content\n\n        # Check if the POT file has the correct header information\n        header_match = re.search(r'Project-Id-Version: sphinx\\s+(.*)', pot_content, re.MULTILINE)\n        assert header_match is not None\n        assert header_match.group(1) == self.app.config.version\n\n        # Check if the POT file has the correct copyright information\n        header_match = re.search(r'Copyright: (.*)', pot_content, re.MULTILINE)\n        assert header_match is not None\n        assert header_match.group(1) == self.app.config.copyright\n\n\n\n"], "sample_193": ["    def test_state_m2m_field_handling(self):\n        with isolate_apps(apps=['my_app']):\n            with override_settings(INSTALLED_APPS=['my_app']):\n                # Create a model with a ManyToManyField\n                class MyModel(models.Model):\n                    name = models.CharField(max_length=100)\n                    foods = models.ManyToManyField(Food, related_name='my_models')\n\n                # Create a project state\n                state = ProjectState(apps=Apps())\n                state.add_model(MyModel)\n\n                # Check that the ManyToManyField is correctly represented\n                model_state = state.models['my_app.mymodel']\n                self.assertEqual(model_state.fields['foods'].field_type, 'ManyToManyField')\n                self.assertEqual(model_state.fields['foods'].remote_field.model, Food)\n\n                # Check that the related model is also correctly represented\n                related_model_state = state.models['my_app.food']\n                self.assertEqual(related_model_state.fields['my_models'].field_type, 'ManyToManyField')\n                self.assertEqual(related_model_state.fields['my_models'].remote_field.model, MyModel)\n\n\n\n"], "sample_1098": ["    def test_appellf1_limits(self):\n        a, b1, b2, c, x, y = symbols('a b1 b2 c x y')\n        with self.subtests():\n            self.subtest('x->0')(\n                tn(limit(appellf1(a, b1, b2, c, x, y), x, 0), 1))\n            self.subtest('y->0')(\n                tn(limit(appellf1(a, b1, b2, c, x, y), y, 0), 1))\n            self.subtest('x->1')(\n                tn(limit(appellf1(a, b1, b2, c, x, y), x, 1),\n                   appellf1(a, b1, b2, c, 1, y)))\n            self.subtest('y->1')(\n                tn(limit(appellf1(a, b1, b2, c, x, y), y, 1),\n                   appellf1(a, b1, b2, c, x, 1)))\n\n\n\n"], "sample_186": ["    def test_system_checks_admin_checks(self):\n        admin_site = AdminSite()\n        admin_site.register(Song, ValidFields)\n        admin_site.register(Album, MyAdmin)\n        admin_site.register(Author, admin.ModelAdmin)\n        admin_site.register(Book, admin.ModelAdmin)\n        admin_site.register(City, admin.ModelAdmin)\n        admin_site.register(State, admin.ModelAdmin)\n        admin_site.register(TwoAlbumFKAndAnE, admin.ModelAdmin)\n\n        errors = checks.run_checks(admin_site)\n        self.assertEqual(len(errors), 2)\n        self.assertIn('error!', [error.id for error in errors])\n        self.assertIn('admin.E129', [error.id for error in errors])\n\n\n\n"], "sample_831": ["    def test_export_graphviz_with_special_characters(self):\n        tree = DecisionTreeClassifier(random_state=0).fit(X, y)\n        with assert_raises_regex(ValueError, \"Invalid node_id\"):\n            export_graphviz(tree, special_characters=False)\n"], "sample_232": ["    def test_key_transform_lookup_with_null_value(self):\n        with self.assertNumQueries(1):\n            result = JSONModel.objects.filter(\n                data__key_transform__isnull=True,\n            ).count()\n        self.assertEqual(result, 1)\n\n        with self.assertNumQueries(1):\n            result = JSONModel.objects.filter(\n                data__key_transform__isnull=False,\n            ).count()\n        self.assertEqual(result, 0)\n\n\n\n"], "sample_662": ["    def test_collect_report_serialization(self):\n        report = CollectReport(\n            nodeid=\"test.py::Test\",\n            outcome=\"passed\",\n            longrepr=None,\n            result=[],\n            sections=[(\"Captured stdout\", \"hello\\nworld\\n\"),],\n        )\n        serialized = pytest_report_to_serializable(report)\n        deserialized = pytest_report_from_serializable(serialized)\n        assert isinstance(deserialized, CollectReport)\n        assert deserialized.nodeid == \"test.py::Test\"\n        assert deserialized.outcome == \"passed\"\n        assert deserialized.longrepr is None\n        assert deserialized.result == []\n        assert deserialized.sections == [(\"Captured stdout\", \"hello\\nworld\\n\")]\n"], "sample_1089": ["    def test_factor_nc_symbols():\n        from sympy.physics.secondquant import Commutator, NO, F, Fd\n        A, B, C = symbols('A,B,C', commutative=False)\n        eq = A*Commutator(A, B) + B*Commutator(A, C)\n        expr, rep, nc_syms = _mask_nc(eq, 'd')\n        assert expr.is_commutative\n        assert rep == {Dummy(): Commutator(A, B), Dummy(): Commutator(A, C)}\n        assert nc_syms == [Dummy(), Dummy(), A, B]\n        fact = factor_nc(eq)\n        assert fact.is_commutative\n        assert fact == A*Commutator(A, B) + B*Commutator(A, C)\n\n\n\n"], "sample_922": ["    def test_parse_annotation(self):\n        assert _parse_annotation('int') == ['int']\n        assert _parse_annotation('int, str') == ['int', 'str']\n        assert _parse_annotation('List[int]') == ['List', ['int']]\n        assert _parse_annotation('Optional[str]') == ['Optional', ['str']]\n        assert _parse_annotation('Union[int, float]') == ['Union', ['int', 'float']]\n        assert _parse_annotation('Tuple[int, str]') == ['Tuple', ['int', 'str']]\n        assert _parse_annotation('Callable[[int], str]') == ['Callable', [['int'], ['str']]]\n        assert _parse_annotation('None') == ['None']\n        assert _parse_annotation('int | str') == ['int', 'str']\n        assert _parse_annotation('int | None') == ['int', 'None']\n        assert _parse_annotation('int | List[str]') == ['int', 'List', ['str']]\n        assert _parse_annotation('typing.List[int]') == ['typing.List', ['int']]\n\n\n\n"], "sample_1115": ["    def test_riemann_cyclic_replace():\n        from sympy.tensor.tensor import TensorIndexType, tensor_indices, TensorHead, riemann_cyclic_replace, TensorSymmetry\n        Lorentz = TensorIndexType('Lorentz', dummy_name='L')\n        i, j, k, l = tensor_indices('i,j,k,l', Lorentz)\n        R = TensorHead('R', [Lorentz]*4, TensorSymmetry.riemann())\n        t = R(i,j,k,l)*(R(-i,-j,-k,-l) - 2*R(-i,-k,-j,-l))\n        t_cyclic = riemann_cyclic_replace(t)\n        t_cyclic = t_cyclic.doit()\n        assert _is_equal(t_cyclic, 0)\n"], "sample_479": ["    def test_rename_index_with_unnamed_index(self):\n        operations = [\n            RenameIndex(\n                \"UnicodeModel\",\n                new_name=\"unnamed_index_2\",\n                old_fields=[\"name\"],\n            ),\n            RenameIndex(\n                \"UnicodeModel\",\n                new_name=\"unnamed_index_1\",\n                old_fields=[\"name\"],\n            ),\n        ]\n        self.assertOptimizesTo(\n            operations,\n            [\n                RenameIndex(\n                    \"UnicodeModel\",\n                    new_name=\"unnamed_index_1\",\n                    old_fields=[\"name\"],\n                )\n            ],\n            exact=1,\n        )\n\n\n\n"], "sample_363": ["    def test_formfield_for_dbfield_ManyToManyField(self):\n        ff = self.assertFormfield(Student, 'groups', widgetclass=ManyToManyRawIdWidget)\n        self.assertEqual(ff.attrs['class'], 'vManyToManyRawIdAdminField')\n"], "sample_282": ["    def test_multi_value_field_errors(self):\n        form = ComplexFieldForm({'field1': ['John', 'P', '2023-10-26 10:00:00']})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors['field1'][0], 'This field is required.')\n"], "sample_1073": ["compilation error"], "sample_602": ["    def test_to_netcdf_with_invalid_netcdf(self):\n        ds = xr.Dataset(\n            {\n                \"a\": ((\"x\", \"y\"), np.random.rand(3, 4)),\n                \"b\": ((\"x\",), np.random.rand(3)),\n            },\n            coords={\"x\": np.arange(3), \"y\": np.arange(4)},\n        )\n        with self.assertRaises(ValueError):\n            to_netcdf(ds, \"test.nc\", mode=\"w\", engine=\"scipy\", invalid_netcdf=True)\n"], "sample_1043": ["compilation error"], "sample_1136": ["    def test_is_positive_negative_nonpositive_nonnegative(self):\n        for K in [ZZ, QQ, EX]:\n            for a in [1, -1, 0, 2.5, -2.5]:\n                a = K(a)\n                self.assertTrue(K.is_positive(a) == a.ex.is_positive)\n                self.assertTrue(K.is_negative(a) == a.ex.could_extract_minus_sign())\n                self.assertTrue(K.is_nonpositive(a) == a.ex.as_coeff_mul()[0].is_nonpositive)\n                self.assertTrue(K.is_nonnegative(a) == a.ex.as_coeff_mul()[0].is_nonnegative)\n"], "sample_1138": ["    def test_TR111():\n        assert TR111(sin(x)**2 + cos(x)**2) == 1\n        assert TR111(sin(x)**2 - cos(x)**2) == cos(2*x)\n        assert TR111(2*sin(x)*cos(x)) == sin(2*x)\n        assert TR111(sin(2*x)) == 2*sin(x)*cos(x)\n        assert TR111(cos(2*x)) == cos(x)**2 - sin(x)**2\n    "], "sample_778": ["    def test_init_params(self, init):\n        X = np.random.rand(10, 5)\n        nmf = NMF(n_components=3, init=init)\n        nmf.fit(X)\n        assert nmf.n_components_ == 3\n        if init == \"custom\":\n            assert nmf.components_.shape == (3, 5)\n        else:\n            assert nmf.components_.shape == (3, 5)\n"], "sample_929": ["    def test_parse_annotation(self):\n        assert _parse_annotation('int', self.env) == ('int', None)\n        assert _parse_annotation('int: str', self.env) == ('int', 'str')\n        assert _parse_annotation('int -> str', self.env) == ('int', 'str')\n        assert _parse_annotation('int -> None', self.env) == ('int', None)\n        assert _parse_annotation('int, str', self.env) == ('int, str', None)\n        assert _parse_annotation('int, str -> None', self.env) == ('int, str', None)\n        assert _parse_annotation('typing.List[int]', self.env) == ('typing.List[int]', None)\n        assert _parse_annotation('typing.List[int] -> str', self.env) == ('typing.List[int]', 'str')\n\n\n\n"], "sample_25": ["    def test_long_commentary_card(self):\n        hdu = fits.PrimaryHDU()\n        hdu.header.add_comment(\"This is a very long comment that spans multiple lines and \"\n                               \"should be handled correctly by the FITS standard.\")\n        hdu.header.add_comment(\"This is the second line of the long comment.\")\n        hdu.header.add_comment(\"This is the third line of the long comment.\")\n        hdu.header.add_comment(\"This is the fourth line of the long comment.\")\n        hdu.header.add_comment(\"This is the fifth line of the long comment.\")\n        hdu.header.add_comment(\"This is the sixth line of the long comment.\")\n\n        hdu.writeto(StringIO(), overwrite=True)\n        hdu = fits.open(StringIO())[0]\n        self.assertEqual(len(hdu.header), 6)\n        self.assertEqual(hdu.header['COMMENT'].value,\n                         \"This is a very long comment that spans multiple lines and \\n\"\n                         \"should be handled correctly by the FITS standard.\\n\"\n                         \"This is the second line of the long comment.\\n\"\n                         \"This is the third line of the long comment.\\n\"\n                         \"This is the fourth line of the long comment.\\n\"\n                         \"This is the fifth line of the long comment.\\n\"\n                         \"This is the sixth line of the long comment.\")\n        hdu.close()\n\n\n\n"], "sample_506": ["    def test_spine_position(self, fig_manager):\n        fig, ax = plt.subplots()\n        spines = Spines(\n            left=Spine.linear_spine(ax, 'left', color='red'),\n            right=Spine.linear_spine(ax, 'right', color='green'),\n            bottom=Spine.linear_spine(ax, 'bottom', color='blue'),\n            top=Spine.linear_spine(ax, 'top', color='purple'),\n        )\n        spines['left'].set_position('outward', 10)\n        spines['right'].set_position('axes', 0.8)\n        spines['bottom'].set_position('data', 0.2)\n        spines['top'].set_position('center')\n        ax.set_xlim(0, 1)\n        ax.set_ylim(0, 1)\n        fig_manager.canvas.draw()\n"], "sample_1100": ["    def test_as_content_primitive_sqrt():\n        from sympy import sqrt\n        assert sqrt(4 + 4*sqrt(2)).as_content_primitive() == (2, sqrt(1 + sqrt(2)))\n        assert sqrt(3 + 3*sqrt(2)).as_content_primitive() == (1, sqrt(3)*sqrt(1 + sqrt(2)))\n        assert sqrt(4 + 4*sqrt(3)).as_content_primitive() == (2, sqrt(1 + sqrt(3)))\n        assert sqrt(3 + 3*sqrt(3)).as_content_primitive() == (1, sqrt(3)*sqrt(1 + sqrt(3)))\n        assert sqrt(4 + 4*sqrt(5)).as_content_primitive() == (2, sqrt(1 + sqrt(5)))\n        assert sqrt(3 + 3*sqrt(5)).as_content_primitive() == (1, sqrt(3)*sqrt(1 + sqrt(5)))\n        assert sqrt(4 + 4*sqrt(7)).as_content_primitive() == (2, sqrt(1 + sqrt(7)))\n        assert sqrt(3 + 3*sqrt(7)).as_content_primitive() == (1, sqrt(3)*sqrt(1 + sqrt(7)))\n        assert sqrt(4 + 4*sqrt(11)).as_content_primitive() == (2, sqrt(1 + sqrt(11)))\n        assert sqrt(3 + 3*sqrt(11)).as_content_primitive() == (1, sqrt(3)*sqrt(1 + sqrt(11)))\n\n\n\n"], "sample_379": ["    def test_mark_safe_callable(self):\n        @mark_safe\n            return f\"Hello, {x}!\"\n\n        self.assertIsInstance(my_func(\"world\"), SafeString)\n        self.assertEqual(my_func(\"world\"), \"Hello, world!\")\n\n        @mark_safe\n            return customescape(f\"Hello, {x}!\")\n\n        self.assertIsInstance(my_func_with_custom_escape(\"world\"), SafeString)\n        self.assertEqual(my_func_with_custom_escape(\"world\"), \"Hello, <<world>>!\")\n"], "sample_1037": ["compilation error"], "sample_276": ["    def test_model_detail_view(self):\n        url = reverse('admin:admindocs_model_detail', kwargs={'app_label': 'myapp', 'model_name': 'company'})\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, 'Company')\n        self.assertContains(response, 'Name')\n        self.assertContains(response, 'Description')\n        self.assertContains(response, 'Number of Employees')\n"], "sample_488": ["    def test_set_installed_apps_unset_installed_apps(self):\n        with isolate_apps([\"apps.apps.MyAdmin\"]):\n            apps.set_installed_apps(SOME_INSTALLED_APPS)\n            with self.assertRaises(AppRegistryNotReady):\n                apps.get_app_config(\"nonexistent_app\")\n\n            apps.unset_installed_apps()\n            self.assertEqual(apps.get_app_config(\"admin\").name, \"django.contrib.admin\")\n            self.assertEqual(apps.get_app_config(\"auth\").name, \"django.contrib.auth\")\n"], "sample_89": ["    def test_iter_modules_and_files_with_zip_modules(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_filename = Path(tempdir) / 'test_module.zip'\n            with zipfile.ZipFile(zip_filename, 'w') as zipf:\n                zipf.write('__init__.py', arcname='__init__.py')\n                zipf.write('module.py', arcname='module.py')\n            self.import_and_cleanup('zipimport.zipimporter')\n            extend_sys_path([tempdir])\n            zipimporter = zipimport.zipimporter(zip_filename)\n            module = zipimporter.find_module('module')\n            self.assertFileFound(zip_filename)\n            self.assertFileFound(zip_filename / 'module.py')\n            self.assertFileFound(zip_filename / '__init__.py')\n"], "sample_798": ["    def test_ridge_regression_sparse_data(self, X_type, y_type):\n        X = X_type(np.random.rand(100, 5))\n        y = y_type(np.random.rand(100))\n        ridge = Ridge(alpha=0.1)\n        ridge.fit(X, y)\n        assert_allclose(ridge.coef_, ridge.coef_)\n        assert_allclose(ridge.intercept_, ridge.intercept_)\n\n"], "sample_251": ["    def test_expression_wrapper(self):\n        from django.db.models.expressions import ExpressionWrapper\n\n        # Test that ExpressionWrapper works with a simple expression\n        expr = ExpressionWrapper(F('book__rating') * 2, output_field=FloatField())\n        self.assertEqual(\n            expr.as_sql(connection=connection),\n            '(\"book\".\"rating\") * 2::FLOAT'\n        )\n\n        # Test that ExpressionWrapper works with a more complex expression\n        expr = ExpressionWrapper(\n            Case(\n                When(F('book__rating') > 4, then=F('book__price') * 0.1),\n                When(F('book__rating') <= 4, then=F('book__price') * 0.05),\n                default=0\n            ),\n            output_field=FloatField()\n        )\n        self.assertEqual(\n            expr.as_sql(connection=connection),\n            'CASE WHEN (\"book\".\"rating\" > 4) THEN (\"book\".\"price\" * 0.1) WHEN (\"book\".\"rating\" <= 4) THEN (\"book\".\"price\" * 0.05) ELSE 0 END::FLOAT'\n        )\n\n\n\n"], "sample_590": ["    def test_concat_with_existing_dim_and_different_coords(\n        self,"], "sample_872": ["    def test_top_k_accuracy_score_multiclass_with_labels(drop):\n        y_true = np.array([0, 1, 2, 2, 0, 1, 2])\n        y_score = np.array([[0.1, 0.3, 0.6],\n                           [0.2, 0.5, 0.3],\n                           [0.4, 0.2, 0.7],\n                           [0.3, 0.6, 0.1],\n                           [0.5, 0.1, 0.4],\n                           [0.7, 0.2, 0.1],\n                           [0.6, 0.3, 0.1]])\n        labels = np.array([0, 1, 2])\n        \n        # Test with k=2\n        score = top_k_accuracy_score(y_true, y_score, k=2, labels=labels)\n        assert score == 0.8571428571428571\n\n        # Test with k=1\n        score = top_k_accuracy_score(y_true, y_score, k=1, labels=labels)\n        assert score == 0.5714285714285714\n\n        # Test with normalize=False\n        score = top_k_accuracy_score(y_true, y_score, k=2, normalize=False, labels=labels)\n        assert score == 6\n"], "sample_287": ["    def test_system_checks_admin_checks(self):\n        admin_site = AdminSite()\n        admin_site.register(Song, ValidFields)\n        admin_site.register(Album, MyAdmin)\n        admin_site.register(Book, admin.ModelAdmin)\n        admin_site.register(Author, admin.ModelAdmin)\n        admin_site.register(City, admin.ModelAdmin)\n        admin_site.register(State, admin.ModelAdmin)\n        admin_site.register(TwoAlbumFKAndAnE, admin.ModelAdmin)\n\n        errors = checks.run_checks(\n            [\n                admin_site,\n                AuthenticationMiddlewareSubclass(),\n                MessageMiddlewareSubclass(),\n                ModelBackendSubclass(),\n                SessionMiddlewareSubclass(),\n            ]\n        )\n        self.assertEqual(len(errors), 1)\n        self.assertIn('error!', str(errors[0]))\n\n\n\n"], "sample_21": ["    def test_err_specs_with_multiple_tables(self):\n        data = np.random.rand(10, 5)\n        table1 = Table(data=data, names=['col1', 'col2', 'col3', 'col4', 'col5'])\n        table2 = Table(data=data, names=['col6', 'col7', 'col8', 'col9', 'col10'])\n        combined_table = Table.vstack([table1, table2])\n\n        # Write the tables to a temporary file\n        with tempfile.NamedTemporaryFile(delete=False) as f:\n            _write_table_qdp(combined_table, filename=f.name, err_specs={'serr': [1, 3], 'terr': [2]})\n            f.close()\n\n        # Read the tables back\n        with open(f.name, 'r') as f:\n            lines = f.readlines()\n        tables = _get_tables_from_qdp_file(lines)\n\n        # Check that the tables were read correctly\n        assert len(tables) == 2\n        assert np.allclose(tables[0]['col1'], data[:, 0])\n        assert np.allclose(tables[0]['col3_err'], data[:, 2] * 0.5)\n        assert np.allclose(tables[1]['col6'], data[:, 5])\n        assert np.allclose(tables[1]['col8_perr'], data[:, 7] * 0.5)\n\n        os.remove(f.name)\n\n\n\n"], "sample_330": ["    def test_date_quoting(self):\n        date_str = '2023-10-26'\n        quoted_date = typecast_date(date_str)\n        self.assertEqual(quoted_date, datetime.date(2023, 10, 26))\n"], "sample_349": ["    def test_autocomplete_select_required_field(self):\n        form = RequiredBandForm()\n        rendered_html = form.render(None)\n        self.assertIn(self.empty_option, rendered_html)\n        self.assertNotIn('<option value=\"1\">Band 1</option>', rendered_html)\n        self.assertNotIn('<option value=\"2\">Band 2</option>', rendered_html)\n"], "sample_16": ["    def test_array_repr(self):\n        from astropy.units import Quantity\n\n            q = Quantity(np.arange(9.0).reshape(3, 3) / 4.0 * u.m)\n            repr_str = func(q)\n            # Check that the repr includes the unit\n            assert \"unit='m'\" in repr_str\n\n        with pytest.raises(TypeError):\n            test_repr(np.array_repr)\n\n        test_repr(array_repr)\n\n\n\n"], "sample_1164": ["compilation error"], "sample_278": ["    def test_select_related_descend(self):\n        # Test select_related_descend with various scenarios\n        self.assertTrue(select_related_descend(\n            Employee.objects.get(id=1).department.field,\n            restricted=False,\n            requested={},\n            load_fields=None,\n            reverse=False\n        ))\n        self.assertFalse(select_related_descend(\n            Employee.objects.get(id=1).department.field,\n            restricted=True,\n            requested={},\n            load_fields=None,\n            reverse=False\n        ))\n        self.assertTrue(select_related_descend(\n            Employee.objects.get(id=1).department.field,\n            restricted=False,\n            requested={\"department\"},\n            load_fields=None,\n            reverse=False\n        ))\n        self.assertFalse(select_related_descend(\n            Employee.objects.get(id=1).department.field,\n            restricted=True,\n            requested={\"other_field\"},\n            load_fields=None,\n            reverse=False\n        ))\n        self.assertTrue(select_related_descend(\n            Employee.objects.get(id=1).department.field,\n            restricted=False,\n            requested={},\n            load_fields={\"department\"},\n            reverse=False\n        ))\n        self.assertFalse(select_related_descend(\n            Employee.objects.get(id=1).department.field,\n            restricted=True,\n            requested={\"department\"},\n            load_fields={\"other_field\"},\n            reverse=False\n        ))\n        self.assertTrue(select_related_descend(\n            Employee.objects.get(id=1).department.field,\n            restricted=False,\n            requested={},\n            load_fields=None,\n            reverse=True\n        ))\n        self.assertFalse(select_related_descend(\n            Employee.objects.get(id=1).department.field,\n            restricted=True,\n            requested={},\n            load_fields=None,\n            reverse=True\n        ))\n\n\n\n"], "sample_60": ["    def test_media_inline_formset(self):\n        response = self.client.get(reverse('admin:episode_episode_change', args=(self.episode_pk,)))\n        self.assertContains(response, 'Media')\n        self.assertContains(response, 'http://example.com/podcast.mp3')\n        self.assertContains(response, 'http://example.com/logo.png')\n\n        # Test adding a new media item\n        data = {\n            'form-TOTAL_FORMS': '3',\n            'form-INITIAL_FORMS': '2',\n            'form-MAX_NUM_FORMS': DEFAULT_MAX_NUM,\n            'form-0-url': 'http://example.com/new_media.jpg',\n            'form-1-url': self.mp3_media_pk,\n            'form-2-url': self.png_media_pk,\n        }\n        response = self.client.post(reverse('admin:episode_episode_change', args=(self.episode_pk,)), data)\n        self.assertRedirects(response, reverse('admin:episode_episode_change', args=(self.episode_pk,)))\n\n        # Check that the new media item was added\n        response = self.client.get(reverse('admin:episode_episode_change', args=(self.episode_pk,)))\n        self.assertContains(response, 'http://example.com/new_media.jpg')\n\n\n\n"], "sample_345": ["    def test_iter_modules_and_files_with_zip_file(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_filename = Path(tempdir) / 'test.zip'\n            with zipfile.ZipFile(zip_filename, 'w') as zipf:\n                zipf.write('test_module.py', arcname='test_module.py')\n            self.import_and_cleanup('test_module')\n            self.assertFileFound(zip_filename)\n            self.assertFileFound(zip_filename / 'test_module.py')\n            self.assertFileNotFound(Path(tempdir) / 'nonexistent_file.py')\n\n"], "sample_841": ["    def test_ridge_solve_eigen_covariance(self, X_type, solver):\n        n_samples, n_features = 100, 50\n        X = X_type(np.random.rand(n_samples, n_features))\n        y = np.random.rand(n_samples)\n        alpha = 0.1\n        X_mean, eigvals, U, _ = _svd_decompose_design_matrix(X, y, None)\n        if solver == \"svd\":\n            expected_dual_coef = _solve_eigen_covariance(\n                alpha, y, None, X_mean, eigvals, U)\n        else:\n            expected_dual_coef = _solve_eigen_covariance_no_intercept(\n                alpha, y, None, X_mean, eigvals, U)\n        dual_coef = ridge_regression(\n            X, y, alpha, solver=solver, fit_intercept=False)\n        assert_allclose(dual_coef, expected_dual_coef)\n\n"], "sample_901": ["    def test_partial_fit_multiple_calls(self, representation, dtype,\n                                        random_state):\n        if representation == 'sparse':\n            X = X_csr\n        else:\n            X = X.astype(dtype)\n        algo = algo\n        n_samples = X.shape[0]\n        n_batches = 3\n        batch_size = n_samples // n_batches\n\n        kmeans = MiniBatchKMeans(n_clusters=3,\n                                 batch_size=batch_size,\n                                 random_state=random_state)\n\n        for i in range(n_batches):\n            kmeans.partial_fit(X[i * batch_size:(i + 1) * batch_size])\n\n        # Check that the cluster centers converged\n        kmeans.fit(X)\n        assert_array_almost_equal(kmeans.cluster_centers_,\n                                  kmeans.cluster_centers_)\n\n        # Check that the labels are correct\n        labels = kmeans.predict(X)\n        assert_array_equal(labels, true_labels)\n"], "sample_763": ["    def test_check_array_dtype(self, dtype):\n        X = np.array([[1, 2], [3, 4]], dtype=dtype)\n        X_converted = check_array(X, dtype=dtype)\n        assert_array_equal(X_converted, X)\n"], "sample_638": ["    def test_output_format_handling(\n        mock_graphviz, args, expected_output"], "sample_986": ["    def test_evalf_bernoulli():\n        from sympy.functions.special.bernoulli import bernoulli\n        for k in range(10):\n            v = bernoulli(k)\n            result = N(v, 10)\n            assert abs(result - bernoulli(k).evalf(10)) < 1e-8\n"], "sample_473": ["    def test_get_script_prefix(self):\n        self.assertEqual(get_script_prefix({\"root_path\": \"\"}), \"/myproject/\")\n        self.assertEqual(get_script_prefix({\"root_path\": \"admin/\"}), \"/myproject/admin/\")\n        self.assertEqual(get_script_prefix({\"root_path\": \"blog/\"}), \"/myproject/blog/\")\n        self.assertEqual(get_script_prefix({\"root_path\": \"blog/\"},), \"/myproject/blog/\")\n        self.assertEqual(get_script_prefix({\"root_path\": \"blog/\",}), \"/myproject/blog/\")\n        self.assertEqual(get_script_prefix({\"root_path\": \"blog/admin/\"}), \"/myproject/blog/admin/\")\n        self.assertEqual(get_script_prefix({\"root_path\": \"blog/admin/\"},), \"/myproject/blog/admin/\")\n        self.assertEqual(get_script_prefix({\"root_path\": \"blog/admin/\"},), \"/myproject/blog/admin/\")\n        self.assertEqual(get_script_prefix({\"root_path\": \"blog/admin/\",}), \"/myproject/blog/admin/\")\n        self.assertEqual(get_script_prefix({\"root_path\": \"blog/admin/\"},), \"/myproject/blog/admin/\")\n        self.assertEqual(get_script_prefix({\"root_path\": \"blog/admin/\"},), \"/myproject/blog/admin/\")\n        self.assertEqual(get_script_prefix({\"root_path\": \"blog/admin/\"},), \"/myproject/blog/admin/\")\n        self.assertEqual(get_script_prefix({\"root_path\": \"blog/admin/\"},), \"/myproject/blog/admin/\")\n        self.assertEqual(get_script_prefix({\"root_path\": \"blog/admin/\"},), \"/myproject/blog/admin/\")\n        self.assertEqual(get_script_prefix({\"root_path\": \"blog/admin/\"},), \"/myproject/blog/admin/\")\n        self.assertEqual(get_script_prefix({\"root_path\": \"blog/admin/\"},), \"/myproject/blog/admin/\")\n        self.assertEqual(get_script_prefix({\"root_path"], "sample_18": ["    def test_info_propagation_addition(self):\n        q2 = u.Quantity(np.arange(5.0, 9.0), \"m/s\")\n        q2.info.name = \"w\"\n        q2.info.description = \"air speed of a european swallow\"\n        result = self.q + q2\n        assert_info_equal(result, self.q, ignore={\"name\", \"description\"})\n        assert result.info.unit.is_equivalent(self.q.unit)\n"], "sample_1183": ["    def test_field_from_expr():\n        from sympy import symbols, sin, cos, exp\n        x, y = symbols('x y')\n        K = field((x*sin(x) + 4*x**2)*exp(1/x + log(x)/3)/x**2, ZZ, order='lex')\n        assert K.symbols == (x,)\n        assert K.domain == ZZ\n        assert K.order == lex\n        assert K.gens == (x*sin(x) + 4*x**2)*exp(1/x + log(x)/3)/x**2\n        assert K.to_domain() == ZZ\n\n        K = field((x*sin(x) + 4*x**2)*exp(1/x + log(x)/3)/x**2, QQ, order='lex')\n        assert K.symbols == (x,)\n        assert K.domain == QQ\n        assert K.order == lex\n        assert K.gens == (x*sin(x) + 4*x**2)*exp(1/x + log(x)/3)/x**2\n        assert K.to_domain() == QQ\n\n        K = field((x*sin(x) + 4*x**2)*exp(1/x + log(x)/3)/x**2, RR, order='lex')\n        assert K.symbols == (x,)\n        assert K.domain == RR\n        assert K.order == lex\n        assert K.gens == (x*sin(x) + 4*x**2)*exp(1/x + log(x)/3)/x**2\n        assert K.to_domain() == RR\n\n        K = field((x*sin(x) + 4*x**2)*exp(1/x + log(x)/3)/x**2, CC, order='lex')\n        assert K.symbols == (x,)\n        assert K.domain == CC\n        assert K.order == lex\n        assert K.gens == (x*sin(x) + 4*x**2)*exp(1/x + log(x)/3)/x**2\n        assert K.to_domain() == CC\n\n        K = field((x*sin(x)"], "sample_792": ["    def test_bernoulli_nb_binarize(self):\n        X = np.array([[0, 1, 0, 1], [1, 0, 1, 0], [0, 0, 1, 1]])\n        clf = BernoulliNB(binarize=0.5)\n        X_bin = clf._binarize(X, threshold=0.5)\n        assert_array_equal(X_bin, np.array([[0, 1, 0, 1],\n                                            [1, 0, 1, 0],\n                                            [0, 0, 1, 1]]))\n\n        X_bin = clf._binarize(X, threshold=0.2)\n        assert_array_equal(X_bin, np.array([[0, 1, 0, 1],\n                                            [1, 0, 1, 0],\n                                            [0, 0, 1, 1]]))\n\n        X_bin = clf._binarize(X, threshold=0.8)\n        assert_array_equal(X_bin, np.array([[0, 0, 0, 0],\n                                            [1, 1, 1, 1],\n                                            [0, 0, 1, 1]]))\n"], "sample_786": ["def test_inverse_transform_ordinal():\n    est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n    est.fit(X)\n    Xt = est.transform(X)\n    Xinv = est.inverse_transform(Xt)\n    assert_array_equal(Xinv, np.array([[-1.5, 1.5, -3.5, -0.5],\n                                       [-0.5, 2.5, -2.5, -0.5],\n                                       [0.5, 3.5, -1.5, 0.5],\n                                       [0.5, 3.5, -1.5, 1.5]]))\n\n"], "sample_256": ["    def test_clean_password2_mismatch(self):\n        form = UserCreationForm(data={'username': 'test', 'password1': 'password', 'password2': 'wrongpassword'})\n        with self.assertRaises(ValidationError) as context:\n            form.clean()\n        self.assertEqual(context.exception.code, 'password_mismatch')\n"], "sample_865": ["    def test_sparse_data(self):\n        for name in DATASETS:\n            if name in [\"sparse-pos\", \"sparse-neg\", \"sparse-mix\"]:\n                X = DATASETS[name][\"X\"]\n                y = DATASETS[name][\"y\"]\n                for clf_type in [\"DecisionTreeClassifier\", \"ExtraTreeClassifier\"]:\n                    clf = ALL_TREES[clf_type](random_state=0)\n                    clf.fit(X, y)\n                    tree_ = clf.tree_\n                    # Check that the tree structure is the same\n                    assert_tree_equal(tree_, clf.tree_,\n                                      f\"Tree structure mismatch for {clf_type} \"\n                                      f\"on sparse data {name}\")\n\n                for reg_type in [\"DecisionTreeRegressor\", \"ExtraTreeRegressor\"]:\n                    reg = ALL_TREES[reg_type](random_state=0)\n                    reg.fit(X, y)\n                    tree_ = reg.tree_\n                    # Check that the tree structure is the same\n                    assert_tree_equal(tree_, reg.tree_,\n                                      f\"Tree structure mismatch for {reg_type} \"\n                                      f\"on sparse data {name}\")\n"], "sample_45": ["    def test_trunc_datetime_with_tzinfo(self):\n        tz_utc = pytz.UTC\n        tz_local = pytz.timezone('America/Los_Angeles')\n\n        now_utc = datetime.now(tz_utc)\n        now_local = datetime.now(tz_local)\n\n        model = self.create_model(now_utc, now_utc + timedelta(hours=1))\n\n        # Truncate to different levels with timezone info\n        truncated_utc = Trunc('start_datetime', 'day')(model).values_list('start_datetime', flat=True)[0]\n        truncated_local = Trunc('start_datetime', 'day')(model).values_list('start_datetime', flat=True)[0].astimezone(tz_local)\n\n        self.assertEqual(truncated_utc.tzinfo, tz_utc)\n        self.assertEqual(truncated_local.tzinfo, tz_local)\n\n        self.assertEqual(truncated_utc.date(), now_utc.date())\n        self.assertEqual(truncated_local.date(), now_local.date())\n"], "sample_154": ["    def test_check_database_backends_empty_databases(self, mock_check):\n        mock_check.return_value = []\n        result = check_database_backends(databases=None)\n        self.assertEqual(result, [])\n"], "sample_370": ["    def test_prefetch_related_with_related_manager(self):\n        with CaptureQueriesContext() as queries:\n            reader1 = Reader.objects.prefetch_related('books_read__authors').get(name='Amy')\n            self.assertEqual(len(queries), 1)\n            self.assertWhereContains(queries[0].sql, 'INNER JOIN \"auth_book\" \"book_authors\" ON \"auth_book\".\"book_id\" = \"book\".\"id\"')\n\n            self.assertEqual(len(reader1.books_read.all()), 2)\n            for book in reader1.books_read.all():\n                self.assertEqual(len(book.authors.all()), 1)\n\n\n\n"], "sample_634": ["    def test_expand_modules_ignore_list_re(self):\n        ignore_list_re = [re.compile(r\"test_.*\")]\n        files_or_modules = [\"test_file.py\", \"module1.py\", \"test_module2.py\"]\n        ignore_list = []\n        path = []\n        result, errors = expand_modules(\n            files_or_modules, ignore_list, ignore_list_re, []\n        )\n        assert len(result) == 1\n        assert result[0][\"path\"] == \"module1.py\"\n        assert len(errors) == 2\n\n\n\n"], "sample_472": ["    def test_get_elided_page_range(self):\n        paginator = Paginator(\n            list(range(50)), per_page=10, orphans=0\n        )\n        for i in paginator.get_elided_page_range(number=43):\n            self.assertIn(i, range(1, paginator.num_pages + 1))\n\n\n\n"], "sample_172": ["    def test_formfield_for_dbfield_date_field(self):\n        ff = self.assertFormfield(Event, 'date', forms.DateField,\n                                  form_class=EventAdmin.form)\n        self.assertEqual(ff.input_formats, ['%Y-%m-%d'])\n"], "sample_485": ["    def test_urlize(self):\n        self.check_output(urlize, \"http://www.example.com\", \"http://www.example.com\")\n        self.check_output(urlize, \"https://www.example.com\", \"https://www.example.com\")\n        self.check_output(urlize, \"www.example.com\", \"http://www.example.com\")\n        self.check_output(urlize, \"example.com\", \"http://example.com\")\n        self.check_output(urlize, \"mailto:john.doe@example.com\", \"mailto:john.doe@example.com\")\n        self.check_output(urlize, \"john.doe@example.com\", \"john.doe@example.com\")\n        self.check_output(urlize, \"http://example.com/path/to/page?query=value\", \"http://example.com/path/to/page?query=value\")\n        self.check_output(urlize, \"http://example.com/path/to/page?query=value#fragment\", \"http://example.com/path/to/page?query=value#fragment\")\n        self.check_output(urlize, \"http://example.com/path/to/page?query=value&another=param\", \"http://example.com/path/to/page?query=value&another=param\")\n        self.check_output(urlize, \"http://example.com/path/to/page?query=value&another=param#fragment\", \"http://example.com/path/to/page?query=value&another=param#fragment\")\n        self.check_output(urlize, \"This is a link: http://www.example.com\", \"This is a link: <a href=\\\"http://www.example.com\\\">http://www.example.com</a>\")\n        self.check_output(urlize, \"This is a link: https://www.example.com\", \"This is a link: <a href=\\\"https://www.example.com\\\">https://www.example.com</a>\")\n        self.check_output(urlize, \"This is a link: www.example"], "sample_536": ["    def test_lasso_callback(self, ax):\n            assert len(verts) > 2\n            assert all(isinstance(v, tuple) and len(v) == 2 for v in verts)\n            self.verts = verts\n\n        lasso = Lasso(ax, (0.2, 0.2), callback)\n        click_and_drag(ax, (0.5, 0.5), (0.8, 0.8))\n        assert lasso.verts is not None\n        lasso.disconnect_events()\n\n\n\n"], "sample_1148": ["    def test_from_index_summation_trace(self):\n        from sympy import trace\n        expr = Sum(A[i, i], (i, 0, n-1))\n        result = MatrixExpr.from_index_summation(expr)\n        self.assertEqual(result, trace(A))\n"], "sample_826": ["    def test_onehotencoder_fit_transform_with_sparse_output(self):\n        X = np.array([[0, 1], [1, 0], [0, 1]])\n        enc = OneHotEncoder(sparse=True)\n        enc.fit(X)\n        X_transformed = enc.transform(X)\n        assert isinstance(X_transformed, sparse.csr_matrix)\n        assert X_transformed.shape == (3, 2)\n"], "sample_272": ["    def test_migration_plan_with_replacements(self):\n        with self.subTest(\"migration plan with replacements\"):\n            # Create a migration plan with replacements\n            executor = MigrationExecutor(connection, progress_callback=mock.Mock())\n            plan = executor.migration_plan(\n                [(\"migrations\", \"0001_initial\")], clean_start=True\n            )\n            self.assertEqual(len(plan), 1)\n            migration, _ = plan[0]\n            self.assertEqual(migration.replaces, [(\"migrations\", \"0000_initial\")])\n\n            # Run the migration plan\n            executor.migrate(\n                [(\"migrations\", \"0001_initial\")], plan=plan, state=None, fake=False, fake_initial=False\n            )\n\n            # Check that the replacement migration is recorded\n            recorder = MigrationRecorder(connection)\n            applied_migrations = recorder.applied_migrations()\n            self.assertIn((\"migrations\", \"0001_initial\"), applied_migrations)\n            self.assertIn((\"migrations\", \"0000_initial\"), applied_migrations)\n\n\n\n"], "sample_610": ["    def test_parse_iso8601_with_reso(string, expected):\n        date, _ = _parse_iso8601_with_reso(cftime.Date, string)\n        assert date_dict(**expected) == date.to_dict()\n"], "sample_1082": ["    def test_asech_complex():\n        from sympy.functions.special.hyperbolic import asech\n        z = asech(S.ImaginaryUnit*(sqrt(6) - sqrt(2)))\n        assert z == -5*I*pi/12\n        z = asech(S.ImaginaryUnit*2)\n        assert z == -I*pi/6\n        z = asech(S.ImaginaryUnit)\n        assert z == -I*pi/2\n        z = asech(S.ImaginaryUnit*(sqrt(2) - sqrt(6)))\n        assert z == 11*I*pi/12\n        z = asech(S.ImaginaryUnit*2 / sqrt(2 + sqrt(2)))\n        assert z == 7*I*pi/8\n        z = asech(S.ImaginaryUnit*sqrt(2 - 2/sqrt(5)))\n        assert z == 3*I*pi/10\n        z = asech(S.ImaginaryUnit*(sqrt(6) + sqrt(2)))\n        assert z == 5*I*pi/12\n        z = asech(S.ImaginaryUnit*2 / sqrt(3))\n        assert z == 5*I*pi/6\n        z = asech(S.ImaginaryUnit*sqrt(2 + 2/sqrt(5)))\n        assert z == 3*I*pi/5\n        z = asech(S.ImaginaryUnit*sqrt(2))\n        assert z == 3*I*pi/4\n        z = asech(S.ImaginaryUnit*(sqrt(5)-1))\n        assert z == -3*I*pi/10\n        z = asech(S.ImaginaryUnit*2 / sqrt(2 + sqrt(2)))\n        assert z == -3*I*pi/8\n        z = asech(S.ImaginaryUnit*sqrt(2 - 2/sqrt(5)))\n        assert z == 7*I*pi/10\n        z = asech(S.ImaginaryUnit*(sqrt(6) - sqrt(2)))\n        assert z == -5*I*pi/12\n        z = asech(S.ImaginaryUnit*2)\n        assert z == -I*pi/6"], "sample_107": ["    def test_callable_setting_wrapper(self):\n            return 'This is a callable setting'\n\n        wrapped_setting = CallableSettingWrapper(callable_setting)\n        self.assertIsNot(wrapped_setting, callable_setting)\n        self.assertEqual(wrapped_setting(), 'This is a callable setting')\n"], "sample_279": ["    def test_unique_constraint_deconstruct(self):\n        constraint = UniqueConstraint(\n            fields=['name', 'price'],\n            name='unique_name_price',\n            deferrable=Deferrable.DEFERRED,\n            opclasses=('text_ops',),\n        )\n        path, args, kwargs = constraint.deconstruct()\n        self.assertEqual(path, 'django.db.models.constraints.UniqueConstraint')\n        self.assertEqual(args, ())\n        self.assertEqual(kwargs, {\n            'fields': ['name', 'price'],\n            'name': 'unique_name_price',\n            'deferrable': 'deferred',\n            'opclasses': ('text_ops',),\n        })\n\n        reconstructed_constraint = UniqueConstraint(*args, **kwargs)\n        self.assertEqual(constraint, reconstructed_constraint)\n"], "sample_1186": ["    def test_reshape(self):\n        for ArrayType in array_types:\n            a = ArrayType([[1, 2], [3, 4]])\n            b = a.reshape((2, 2))\n            self.assertTrue(a == b)\n            c = a.reshape((4,))\n            self.assertTrue(a.tolist() == c.tolist())\n            d = a.reshape((1, 4))\n            self.assertTrue(a.tolist() == d.tolist())\n"], "sample_302": ["    def test_runshell_handles_sigint(self):\n        with mock.patch('django.db.backends.base.client.BaseDatabaseClient.runshell') as mock_runshell:\n            self.client.runshell([])\n            mock_runshell.assert_called_once_with([])\n"], "sample_495": ["    def test_page_object(self):\n        paginator = Paginator(\n            list(range(10)), per_page=3, orphans=0\n        )\n        page = paginator.page(2)\n        self.assertEqual(len(page), 3)\n        self.assertEqual(page[0], 5)\n        self.assertEqual(page.number, 2)\n        self.assertEqual(page.paginator, paginator)\n        self.assertTrue(page.has_next())\n        self.assertTrue(page.has_previous())\n        self.assertEqual(page.start_index(), 6)\n        self.assertEqual(page.end_index(), 9)\n\n"], "sample_612": ["    def test_groupby_reduce_with_keepdims(self, dataset):\n        ds = dataset.copy()\n        ds = ds.groupby(\"x\").reduce(\n            lambda x: x.sum(dim=\"y\", keepdims=True), keep_attrs=False\n        )\n        expected_shape = (3, 1, 2)\n        assert_array_equal(ds.foo.shape, expected_shape)\n        assert_equal(ds.foo.dims, (\"x\", \"z\"))\n        assert_equal(ds.foo.attrs, {})\n"], "sample_1174": ["    def test_polar_lift_evalf():\n        from sympy.functions.elementary.complexes import polar_lift\n        z = polar_lift(2 + 3*I)\n        assert N_equals(z.evalf(), 2 + 3*I)\n        z = polar_lift(2 - 3*I)\n        assert N_equals(z.evalf(), 2 - 3*I)\n        z = polar_lift(-2 + 3*I)\n        assert N_equals(z.evalf(), -2 + 3*I)\n        z = polar_lift(-2 - 3*I)\n        assert N_equals(z.evalf(), -2 - 3*I)\n        z = polar_lift(0)\n        assert N_equals(z.evalf(), 0)\n        z = polar_lift(I)\n        assert N_equals(z.evalf(), I)\n        z = polar_lift(-I)\n        assert N_equals(z.evalf(), -I)\n"], "sample_1134": ["    def test_latex_printing_of_symbols(self):\n        self.assertEqual(latex(x), 'x')\n        self.assertEqual(latex(y), 'y')\n        self.assertEqual(latex(z), 'z')\n        self.assertEqual(latex(t), 't')\n        self.assertEqual(latex(w), 'w')\n        self.assertEqual(latex(a), 'a')\n        self.assertEqual(latex(b), 'b')\n        self.assertEqual(latex(c), 'c')\n        self.assertEqual(latex(s), 's')\n        self.assertEqual(latex(p), 'p')\n        self.assertEqual(latex(k), 'k')\n        self.assertEqual(latex(m), 'm')\n        self.assertEqual(latex(n), 'n')\n        self.assertEqual(latex(mu), 'mu')\n        self.assertEqual(latex(tau), 'tau')\n"], "sample_0": ["    def test_propagate_add_sub_with_correlated_uncertainties(self, UncertClass):\n        data1 = NDData([1, 2, 3], unit='m')\n        data2 = NDData([4, 5, 6], unit='m')\n\n        if UncertClass in uncertainty_types_with_conversion_support:\n            uncert1 = UncertClass(np.array([0.1, 0.2, 0.3]), unit='m')\n            uncert2 = UncertClass(np.array([0.4, 0.5, 0.6]), unit='m')\n        else:\n            uncert1 = UncertClass(np.array([0.1, 0.2, 0.3]))\n            uncert2 = UncertClass(np.array([0.4, 0.5, 0.6]))\n\n        data1.uncertainty = uncert1\n        data2.uncertainty = uncert2\n\n        result_data = data1 + data2\n\n        # Test addition\n        result_uncert = result_data.uncertainty\n        expected_uncert = UncertClass._propagate_add(uncert1, uncert2,\n                                                    result_data.data,\n                                                    correlation=0.5)\n        assert_allclose(result_uncert.array, expected_uncert.array)\n\n        # Test subtraction\n        result_data = data1 - data2\n        result_uncert = result_data.uncertainty\n        expected_uncert = UncertClass._propagate_subtract(uncert1, uncert2,\n                                                        result_data.data,\n                                                        correlation=0.5)\n        assert_allclose(result_uncert.array, expected_uncert.array)\n"], "sample_264": ["    def test_cookie_storage_max_size(self):\n        storage = self.storage_class()\n        messages = [\n            Message(constants.INFO, 'Message 1', extra_tags='tag1'),\n            Message(constants.INFO, 'Message 2', extra_tags='tag2'),\n            Message(constants.INFO, 'Message 3', extra_tags='tag3'),\n            Message(constants.INFO, 'Message 4', extra_tags='tag4'),\n            Message(constants.INFO, 'Message 5', extra_tags='tag5'),\n            Message(constants.INFO, 'Message 6', extra_tags='tag6'),\n            Message(constants.INFO, 'Message 7', extra_tags='tag7'),\n            Message(constants.INFO, 'Message 8', extra_tags='tag8'),\n            Message(constants.INFO, 'Message 9', extra_tags='tag9'),\n            Message(constants.INFO, 'Message 10', extra_tags='tag10'),\n        ]\n        response = self.mock_response()\n\n        # Store messages, exceeding max_cookie_size\n        unstored_messages = storage._store(messages, response, remove_oldest=True)\n        self.assertEqual(len(unstored_messages), 1)\n        self.assertEqual(stored_cookie_messages_count(storage, response), 9)\n\n        # Retrieve messages, should include the not_finished sentinel\n        messages, all_retrieved = storage._get(response)\n        self.assertFalse(all_retrieved)\n        self.assertEqual(len(messages), 9)\n\n        # Store the remaining messages, should now be successful\n        storage._store(unstored_messages, response, remove_oldest=False)\n        self.assertEqual(stored_cookie_messages_count(storage, response), 10)\n"], "sample_546": ["    def test_figure_canvas_base_stale(self, backend_name):\n        canvas = FigureCanvasBase(Figure())\n        canvas.draw()\n        assert not canvas.stale\n        canvas.stale = True\n        assert canvas.stale\n        canvas.draw()\n        assert not canvas.stale\n"], "sample_685": ["    def test_log_file_handler(self, testdir: Testdir) -> None:\n        p = testdir.makepyfile(\n            \"\"\"\n            import logging\n\n            logging.basicConfig(level=logging.DEBUG, filename=\"test.log\", format=\"%(asctime)s - %(levelname)s - %(message)s\")\n\n                logging.debug(\"This is a debug message\")\n                logging.info(\"This is an info message\")\n                logging.warning(\"This is a warning message\")\n                logging.error(\"This is an error message\")\n                logging.critical(\"This is a critical message\")\n            \"\"\"\n        )\n        result = testdir.runpytest()\n        result.assert_outcomes(passed=1)\n        assert os.path.exists(\"test.log\")\n        with open(\"test.log\", \"r\") as f:\n            lines = f.readlines()\n        assert \"This is a debug message\" in lines\n        assert \"This is an info message\" in lines\n        assert \"This is a warning message\" in lines\n        assert \"This is an error message\" in lines\n        assert \"This is a critical message\" in lines\n        os.remove(\"test.log\")\n\n\n\n"], "sample_242": ["    def test_year_lookup_bounds(self):\n        class YearLookupTest(YearLookup):\n                return (start, finish)\n\n        lookup = YearLookupTest(\n            lhs=Value(1999), rhs=Value(2000)\n        )\n        connection = mock.MagicMock()\n        connection.features.has_native_uuid_field = False\n        bounds = lookup.year_lookup_bounds(connection, 2000)\n        self.assertEqual(bounds, (1999, 2000))\n"], "sample_797": ["    def test_power_transform_method_change(self):\n        X = np.random.rand(10, 5)\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            # Test with the default method\n            transformed_data = power_transform(X, method='warn')\n            # Test with the explicit method\n            transformed_data_explicit = power_transform(X, method='yeo-johnson')\n        assert_array_almost_equal(transformed_data, transformed_data_explicit)\n"], "sample_76": ["    def test_check_setting_languages_bidi(self):\n        with self.settings(LANGUAGES_BIDI=self.valid_tags):\n            errors = check_setting_languages_bidi(None, {})\n            self.assertEqual(errors, [])\n\n        with self.settings(LANGUAGES_BIDI=self.invalid_tags):\n            errors = check_setting_languages_bidi(None, {})\n            self.assertNotEqual(errors, [])\n\n"], "sample_552": ["    def test_constrained_layout_engine_with_subplots(self):\n        fig = Figure()\n        gs = gridspec.GridSpec(2, 2)\n        ax1 = fig.add_subplot(gs[0, 0])\n        ax2 = fig.add_subplot(gs[0, 1])\n        ax3 = fig.add_subplot(gs[1, 0])\n        ax4 = fig.add_subplot(gs[1, 1])\n\n        fig.set_layout_engine(ConstrainedLayoutEngine())\n        fig.tight_layout()\n\n        # Check that the subplots are arranged correctly\n        assert ax1.get_position().x == 0.1\n        assert ax1.get_position().y == 0.1\n        assert ax2.get_position().x == 0.5\n        assert ax2.get_position().y == 0.1\n        assert ax3.get_position().x == 0.1\n        assert ax3.get_position().y == 0.5\n        assert ax4.get_position().x == 0.5\n        assert ax4.get_position().y == 0.5\n\n"], "sample_758": ["    def test_check_array_dtype(self, dtype):\n        X = np.array([[1, 2], [3, 4]], dtype=dtype)\n        X_converted = check_array(X, dtype=dtype)\n        assert_array_equal(X, X_converted)\n"], "sample_519": ["    def test_constrained_layout_pads(self):\n        fig = Figure()\n        with fig.canvas.manager.window.wait_for_event('draw_event'):\n            pass\n        pads = fig.get_constrained_layout_pads(relative=True)\n        assert pads[0] > 0\n        assert pads[1] > 0\n        assert pads[2] > 0\n        assert pads[3] > 0\n        fig.set_constrained_layout_pads(w_pad=0.1, h_pad=0.2)\n        pads = fig.get_constrained_layout_pads(relative=True)\n        assert pads[0] == 0.1\n        assert pads[1] == 0.2\n        assert pads[2] == 0\n        assert pads[3] == 0\n"], "sample_598": ["    def test_short_numpy_repr(self, array, expected):\n        with set_numpy_options(precision=6, linewidth=100, threshold=20"], "sample_103": ["    def test_aggregate_filter(self):\n        with self.assertNumQueries(1):\n            result = Book.objects.filter(rating__gt=4).annotate(\n                avg_rating=Avg('rating')\n            ).values('avg_rating')\n        self.assertEqual(result[0]['avg_rating'], 4.375)\n\n        with self.assertNumQueries(1):\n            result = Book.objects.filter(rating__gt=4).annotate(\n                avg_rating=Avg('rating', filter=Q(publisher__name='Apress'))\n            ).values('avg_rating')\n        self.assertEqual(result[0]['avg_rating'], 4.5)\n\n        with self.assertNumQueries(1):\n            result = Book.objects.filter(rating__gt=4).annotate(\n                avg_rating=Avg('rating', filter=Q(pages__gt=300))\n            ).values('avg_rating')\n        self.assertEqual(result[0]['avg_rating'], 4.5)\n\n        with self.assertNumQueries(1):\n            result = Book.objects.filter(rating__gt=4).annotate(\n                avg_rating=Avg('rating', filter=Q(pages__gt=300) & Q(publisher__name='Apress'))\n            ).values('avg_rating')\n        self.assertEqual(result[0]['avg_rating'], 4.5)\n\n\n\n"], "sample_361": ["    def test_urlize(self):\n        self.check_output(urlize, 'http://www.example.com', '<a href=\"http://www.example.com\">http://www.example.com</a>')\n        self.check_output(urlize, 'https://www.example.com', '<a href=\"https://www.example.com\">https://www.example.com</a>')\n        self.check_output(urlize, 'example@example.com', '<a href=\"mailto:example@example.com\">example@example.com</a>')\n        self.check_output(urlize, 'www.example.com', '<a href=\"http://www.example.com\">www.example.com</a>')\n        self.check_output(urlize, 'http://example.com/path/to/page', '<a href=\"http://example.com/path/to/page\">http://example.com/path/to/page</a>')\n        self.check_output(urlize, 'http://example.com/path/to/page?query=string', '<a href=\"http://example.com/path/to/page?query=string\">http://example.com/path/to/page?query=string</a>')\n        self.check_output(urlize, 'http://example.com/path/to/page#fragment', '<a href=\"http://example.com/path/to/page#fragment\">http://example.com/path/to/page#fragment</a>')\n        self.check_output(urlize, 'This is a link: http://example.com', 'This is a link: <a href=\"http://example.com\">http://example.com</a>')\n        self.check_output(urlize, 'This is a link: www.example.com', 'This is a link: <a href=\"http://www.example.com\">www.example.com</a>')\n        self.check_output(urlize, 'This is a link: example@example.com', 'This is a link: <a href=\"mailto:example@example.com\">example@example.com</a>')\n        self.check_output(urlize, 'This is a"], "sample_490": ["    def test_unique_constraint_deconstruct(self):\n        constraint = UniqueConstraint(\n            fields=[\"name\", \"price\"],\n            name=\"unique_name_price\",\n            deferrable=Deferrable.DEFERRED,\n        )\n        path, args, kwargs = constraint.deconstruct()\n        self.assertEqual(path, \"django.db.models.constraints.UniqueConstraint\")\n        self.assertEqual(args, ())\n        self.assertEqual(kwargs, {\"fields\": [\"name\", \"price\"], \"name\": \"unique_name_price\", \"deferrable\": \"deferred\"})\n\n        reconstructed_constraint = UniqueConstraint(**kwargs)\n        self.assertEqual(constraint, reconstructed_constraint)\n\n\n\n"], "sample_568": ["    def test_poly_collection_2d_to_3d_with_codes(self):\n        verts = [\n            [[0, 0, 0], [1, 0, 0], [1, 1, 0], [0, 1, 0]],\n            [[0, 0, 1], [1, 0, 1], [1, 1, 1], [0, 1, 1]],\n        ]\n        codes = [\n            [mpath.Path.MOVETO, mpath.Path.LINETO, mpath.Path.LINETO,\n             mpath.Path.CLOSEPOLY],\n            [mpath.Path.MOVETO, mpath.Path.LINETO, mpath.Path.LINETO,\n             mpath.Path.CLOSEPOLY],\n        ]\n        col = PolyCollection(verts, facecolors='r', edgecolors='b',\n                             codes=codes)\n        col_3d = poly_collection_2d_to_3d(col, zs=0.5, zdir='z')\n        fig, ax = plt.subplots(subplot_kw={'projection': '3d'})\n        col_3d.set_alpha(0.5)\n        col_3d.set_zorder(10)\n        ax.add_collection3d(col_3d)\n        ax.set_xlim(0, 1.5)\n        ax.set_ylim(0, 1.5)\n        ax.set_zlim(0, 1.5)\n        plt.show()\n"], "sample_930": ["    def test_index_entries_group(app, env, status, warning):\n        IndexEntries(env).create_index(app.builder, group_entries=True)\n        # assert that the grouped entries are as expected\n        # ...\n"], "sample_309": ["    def test_urlencode_multivalue(self):\n        query = MultiValueDict({'a': ['1', '2'], 'b': ['3', '4']})\n        encoded = urlencode(query, doseq=True)\n        self.assertEqual(encoded, 'a=1&a=2&b=3&b=4')\n"], "sample_1201": ["    def test_cgs_gauss_coulomb_constant():\n        assert convert_to(coulomb_constant, cgs_gauss) == 1\n"], "sample_1085": ["    def test_sympify_mpmath_complex():\n        z = mpmath.mpc(1, 2)\n        result = sympify(z)\n        assert isinstance(result, complex)\n        assert result.real == 1\n        assert result.imag == 2\n"], "sample_802": ["    def test_pipeline_memory_caching(self):\n        X = np.random.rand(10, 5)\n        y = np.random.randint(0, 2, size=10)\n\n        # Test with a simple pipeline\n        pipeline = Pipeline([\n            ('scaler', StandardScaler()),\n            ('clf', LogisticRegression())\n        ], memory=Memory(cachedir=mkdtemp()))\n\n        # First fit should train the models\n        pipeline.fit(X, y)\n\n        # Second fit should use cached transformers\n        pipeline.fit(X, y)\n        # Check that the timestamp of the cached transformer is different\n        # from the first fit\n        assert pipeline.steps[0][1].timestamp_ != pipeline.steps[0][1].timestamp_\n\n        # Test with a more complex pipeline\n        pipeline = Pipeline([\n            ('scaler', StandardScaler()),\n            ('feature_selection', SelectKBest(f_classif, k=2)),\n            ('clf', LogisticRegression())\n        ], memory=Memory(cachedir=mkdtemp()))\n\n        pipeline.fit(X, y)\n        pipeline.fit(X, y)\n        # Check that the timestamp of the cached transformers are different\n        # from the first fit\n        assert pipeline.steps[0][1].timestamp_ != pipeline.steps[0][1].timestamp_\n        assert pipeline.steps[1][1].timestamp_ != pipeline.steps[1][1].timestamp_\n\n        # Clean up temporary directory\n        shutil.rmtree(pipeline.memory.cachedir)\n"], "sample_1202": ["    def test_sympify_mpmath_complex():\n        z = mpmath.complex(1, 2)\n        result = sympify(z)\n        assert isinstance(result, Mul)\n        assert result.args[0] == 1\n        assert result.args[1] == S.ImaginaryUnit * 2\n\n"], "sample_866": ["    def test_affinity_propagation_equal_similarities_and_preferences(self):\n        # Test case where all similarities and preferences are equal\n        S = np.ones((3, 3))\n        preference = 0.5\n        assert _equal_similarities_and_preferences(S, preference)\n        \n        S = np.ones((3, 3))\n        preference = np.ones(3)\n        assert _equal_similarities_and_preferences(S, preference)\n        \n        # Test case where all similarities are equal but preferences are not\n        S = np.ones((3, 3))\n        preference = np.array([0.1, 0.2, 0.3])\n        assert not _equal_similarities_and_preferences(S, preference)\n        \n        # Test case where all preferences are equal but similarities are not\n        S = np.array([[1, 2, 3], [2, 1, 4], [3, 4, 1]])\n        preference = 1\n        assert not _equal_similarities_and_preferences(S, preference)\n"], "sample_253": ["    def test_iter_modules_and_files_with_zip_module(self):\n        with tempfile.TemporaryDirectory() as tempdir:\n            zip_filename = Path(tempdir) / 'my_module.zip'\n            with zipfile.ZipFile(zip_filename, 'w') as zf:\n                zf.write('__init__.py', arcname='my_module')\n                zf.write('module.py', arcname='my_module/module.py')\n            extend_sys_path([tempdir])\n            self.import_and_cleanup('my_module')\n            self.assertFileFound(zip_filename)\n            self.assertFileFound(zip_filename / 'my_module/module.py')\n            self.assertFileNotFound(zip_filename / 'nonexistent_file.py')\n"], "sample_63": ["    def test_select_template_with_invalid_templates(self):\n        with self.assertRaises(TemplateDoesNotExist):\n            self.engine.select_template(['nonexistent_template.html', 'another_nonexistent.html'])\n"], "sample_886": ["compilation error"], "sample_127": ["    def test_bulk_create_with_related_objects(self):\n        pizzerias = [\n            Pizzeria(name=\"Pizza Palace\", country=self.data[0]),\n            Pizzeria(name=\"Pizza Hut\", country=self.data[1]),\n            Pizzeria(name=\"Pizza Express\", country=self.data[2]),\n        ]\n        with connection.cursor() as cursor:\n            cursor.execute(\"TRUNCATE TABLE pizzeria_pizzeria\")\n            cursor.execute(\"TRUNCATE TABLE countries\")\n        Pizzeria.objects.bulk_create(pizzerias)\n        self.assertEqual(Pizzeria.objects.count(), 3)\n        self.assertEqual(Country.objects.count(), 4)\n\n\n\n"], "sample_292": ["    def test_csrf_cookie_domain(self):\n        with override_settings(CSRF_COOKIE_DOMAIN='example.com'):\n            request = self._get_GET_csrf_cookie_request()\n            response = self.middleware.process_request(request)\n            self.assertIsNone(response)\n            response = self.view.as_view()(request)\n            self.assertEqual(response.status_code, 200)\n            self._check_token_present(response)\n\n        with override_settings(CSRF_COOKIE_DOMAIN='example.com', SESSION_COOKIE_DOMAIN='example.net'):\n            request = self._get_GET_csrf_cookie_request()\n            response = self.middleware.process_request(request)\n            self.assertIsNone(response)\n            response = self.view.as_view()(request)\n            self.assertEqual(response.status_code, 200)\n            self._check_token_present(response)\n\n        with override_settings(CSRF_COOKIE_DOMAIN='.example.com'):\n            request = self._get_GET_csrf_cookie_request()\n            response = self.middleware.process_request(request)\n            self.assertIsNone(response)\n            response = self.view.as_view()(request)\n            self.assertEqual(response.status_code, 200)\n            self._check_token_present(response)\n\n        with override_settings(CSRF_COOKIE_DOMAIN=None):\n            request = self._get_GET_csrf_cookie_request()\n            response = self.middleware.process_request(request)\n            self.assertIsNone(response)\n            response = self.view.as_view()(request)\n            self.assertEqual(response.status_code, 200)\n            self._check_token_present(response)\n\n\n\n"], "sample_310": ["    def test_view_detail_view(self):\n        url = reverse('admin:admindocs_view_detail', kwargs={'view': 'company_list'})\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, 'Company list')\n        self.assertContains(response, 'List of all Company objects')\n"], "sample_627": ["    def test_concat_identical_arrays_with_compat(\n        compat: CompatOptions, expected_result: bool"], "sample_670": ["    def test_parentheses():\n        assert evaluate(\"((a) or b)\", lambda x: x == \"a\") is True\n        assert evaluate(\"((a) and b)\", lambda x: x == \"a\") is True\n        assert evaluate(\"not (a)\", lambda x: x == \"a\") is False\n        assert evaluate(\"(a) and not (b)\", lambda x: x in (\"a\", \"b\")) is True\n        with pytest.raises(ParseError):\n            evaluate(\"((a\", lambda x: x == \"a\")\n        with pytest.raises(ParseError):\n            evaluate(\"(a) or\", lambda x: x == \"a\")\n"], "sample_389": ["    def test_settings_override(self):\n        self.assertEqual(settings.ITEMS, [\"b\", \"d\", \"c\"])\n        self.assertEqual(settings.ITEMS_OUTER, [1, 2, 3])\n        self.assertEqual(settings.TEST, \"override\")\n        self.assertEqual(settings.TEST_OUTER, \"outer\")\n"], "sample_1165": ["    def test_from_rotation_matrix_complex(self):\n        M = Matrix([[cos(phi), -sin(phi), 0],\n                    [sin(phi), cos(phi), 0],\n                    [0, 0, 1]])\n        q = Quaternion.from_rotation_matrix(M)\n        self.assert_quaternion_equal(q, Quaternion(cos(phi), sin(phi), 0, 0))\n"], "sample_571": ["    def test_regplot_dropna(self):\n        with pytest.raises(ValueError):\n            lm.regplot(x=\"y_na\", y=\"x\", data=self.df)\n        ax = lm.regplot(x=\"x\", y=\"y\", data=self.df, dropna=True)\n        assert len(ax.get_lines()) == 2\n        assert len(ax.get_children()) == 3  # including the horizontal line\n"], "sample_651": ["    def test_deprecated_call_with_match(self, pytester: Pytester) -> None:\n        pytester.write(\n            \"test_deprecated_call.py\",\n            \"\"\"\n                warnings.warn('use v3 of this api', DeprecationWarning)\n                return 200\n\n            @pytest.deprecated_call(match='use v3 of this api')\n                assert api_call_v2() == 200\n            \"\"\",\n        )\n        result = pytester.runpytest()\n        result.assert_outcomes(passed=1)\n        recwarn = WarningsRecorder()\n        with recwarn:\n            warnings.warn('use v3 of this api', DeprecationWarning)\n        assert len(recwarn.list) == 1\n        assert recwarn.list[0].message == \"use v3 of this api\"\n"], "sample_1062": ["compilation error"], "sample_405": ["    def test_add_remove_constraint(self):\n        with atomic():\n            # Create a model with a constraint\n            class MyModel(models.Model):\n                name = models.CharField(max_length=100)\n                value = models.IntegerField(unique=True)\n\n            self.create_model(MyModel)\n\n            # Add a constraint\n            with self.assertNumQueries(1):\n                with transaction.atomic():\n                    self.apps.migrate(\"my_app\", \"0001_initial\")\n            # Check the constraint exists\n            with self.assertNumQueries(1):\n                with transaction.atomic():\n                    self.assertEqual(\n                        connection.introspection.get_constraints(MyModel._meta.db_table),\n                        [\n                            {\"name\": \"unique_value\", \"type\": \"UNIQUE\", \"columns\": [\"value\"]},\n                        ],\n                    )\n\n            # Remove the constraint\n            with self.assertNumQueries(1):\n                with transaction.atomic():\n                    self.apps.migrate(\"my_app\", \"0002_remove_constraint\")\n            # Check the constraint is gone\n            with self.assertNumQueries(1):\n                with transaction.atomic():\n                    self.assertEqual(\n                        connection.introspection.get_constraints(MyModel._meta.db_table),\n                        [],\n                    )\n\n\n\n"], "sample_333": ["    def test_form_renderer(self):\n        renderer = get_default_renderer()\n        form = Person()\n        output = renderer.render(form)\n        self.assertIn('<label for=\"id_first_name\">First name:</label>', output)\n        self.assertIn('<label for=\"id_last_name\">Last name:</label>', output)\n        self.assertIn('<label for=\"id_birthday\">Birthday:</label>', output)\n\n        form = PersonNew()\n        output = renderer.render(form)\n        self.assertIn('<input type=\"text\" id=\"first_name_id\" name=\"first_name\">', output)\n\n\n\n"], "sample_944": ["    def test_restify_typing_union(self):\n        assert restify(Union[int, str]) == 'Union[int, str]'\n        assert restify(Union[int, str, None]) == 'Optional[Union[int, str]]'\n        assert restify(Union[int, Union[str, None]]) == 'Union[int, Optional[str]]'\n        assert restify(Union[int, str, Union[None, int]]) == 'Union[int, str, Optional[int]]'\n        assert restify(Union[int, None, str]) == 'Optional[Union[int, str]]'\n        assert restify(Union[int, int]) == 'int'\n        assert restify(Union[str, str]) == 'str'\n\n\n\n"], "sample_123": ["    def test_urlencode_multivalue_dict(self):\n        data = MultiValueDict({'a': ['1', '2'], 'b': ['3', '4', '5']})\n        encoded = urlencode(data)\n        self.assertEqual(encoded, 'a=1&a=2&b=3&b=4&b=5')\n\n        encoded = urlencode(data, doseq=False)\n        self.assertEqual(encoded, 'a=1&b=3&a=2&b=4&b=5')\n"], "sample_440": ["    def test_bulk_create_with_related_objects(self):\n        Country.objects.all().delete()\n        Pizzeria.objects.all().delete()\n        with connection.cursor() as cursor:\n            cursor.execute(\"SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED\")\n        with self.assertRaises(IntegrityError):\n            Pizzeria.objects.bulk_create(self.data2)\n\n\n\n"], "sample_557": ["    def test_constrained_layout_engine_execute(self):\n        fig = Figure()\n        ax1 = fig.add_subplot(2, 1, 1)\n        ax2 = fig.add_subplot(2, 1, 2)\n\n        # Add some content to the axes\n        ax1.plot([1, 2, 3])\n        ax2.bar([1, 2, 3], [4, 5, 6])\n\n        # Set up the constrained layout engine\n        engine = ConstrainedLayoutEngine()\n        engine.execute(fig)\n\n        # Check that the axes are properly spaced\n        assert ax1.get_position().x0 > 0\n        assert ax1.get_position().y0 > 0\n        assert ax2.get_position().x0 > 0\n        assert ax2.get_position().y0 > 0\n\n        # Check that the layout is tight\n        fig.tight_layout()\n        fig.canvas.draw()\n        fig.canvas.flush_events()\n        # This test relies on the visual inspection of the generated image\n        # to ensure the layout is tight.\n        # You can uncomment the following line to compare the generated image\n        # with a reference image.\n        # self.assert_images_equal(fig.canvas.tostring_rgb(),\n        #                         'constrained_layout_engine_execute')\n\n\n\n"], "sample_218": ["    def test_trunc_datetime_with_tzinfo(self):\n        tz_utc = pytz.UTC\n        tz_pst = pytz.timezone('America/Los_Angeles')\n\n        # Create a datetime object with timezone information\n        dt_with_tz = datetime(2023, 10, 26, 15, 30, 0, tzinfo=tz_utc)\n\n        # Truncate to different time units\n        for kind in ['year', 'quarter', 'month', 'week', 'day', 'hour', 'minute', 'second']:\n            truncated_dt = truncate_to(dt_with_tz, kind, tz_utc)\n            truncated_dt_pst = truncate_to(dt_with_tz.astimezone(tz_pst), kind, tz_pst)\n\n            # Assert that truncation is consistent across timezones\n            self.assertEqual(truncated_dt, truncated_dt_pst.astimezone(tz_utc))\n\n            # Test using Trunc function with timezone information\n            model = self.create_model(dt_with_tz, None)\n            if kind == 'date':\n                truncated_model = model.objects.annotate(\n                    truncated_date=TruncDate('start_datetime')\n                ).first()\n                self.assertEqual(truncated_model.truncated_date, truncated_dt.date())\n            else:\n                truncated_model = model.objects.annotate(\n                    truncated_datetime=Trunc(\n                        'start_datetime', kind\n                    )\n                ).first()\n                self.assertEqual(truncated_model.truncated_datetime, truncated_dt)\n\n\n\n"], "sample_1015": ["    def test_ccode_indexed_with_contract(self):\n        from sympy import IndexedBase, Idx\n        len_y = 5\n        y = IndexedBase('y', shape=(len_y,))\n        i = Idx('i', len_y)\n        expr = y[i] + y[i + 1]\n        ccode(expr, assign_to=y[i], contract=True, standard='C89')\n        # Expected output:\n        # for (int i = 0; i < len_y - 1; i++) {\n        #   y[i] = y[i] + y[i + 1];\n        # }\n\n\n\n"], "sample_192": ["    def test_formset_factory_validation(self):\n        with self.assertRaises(ValueError):\n            formset_factory(Choice, max_num=10, absolute_max=5)\n"], "sample_410": ["    def test_natural_key(self):\n        user = IntegerUsernameUser.objects.create(\n            username=123,\n        )\n        self.assertEqual(user.natural_key(), (123,))\n"], "sample_517": ["    def test_annotation_offset_coords(self):\n        fig, ax = plt.subplots()\n\n        # Test offset coordinates\n        annotation = Annotation('Test', (0.5, 0.5), xycoords='data',\n                                textcoords='offset points',\n                                arrowprops=dict(arrowstyle='->'))\n        annotation.set_size(12)\n        annotation.set_ha('center')\n        annotation.set_va('center')\n        annotation.draggable(state=True)\n        ax.add_artist(annotation)\n\n        plt.show()\n"], "sample_368": ["    def test_migration_plan_with_replacements(self):\n        with self.settings(MIGRATION_MODULES={\"migrations\": \"migrations.test_migrations\"}):\n            with isolate_lru_cache():\n                executor = MigrationExecutor(connection, progress_callback=mock.Mock())\n                graph = MigrationGraph(executor.loader)\n                plan = executor.migration_plan(\n                    [(\"migrations\", \"0001_initial\")], clean_start=True\n                )\n                self.assertEqual(len(plan), 1)\n                self.assertEqual(plan[0][0].replaces, [(\"migrations\", \"0002_replacement\")])\n                executor.loader.replace_migrations = False\n                plan = executor.migration_plan(\n                    [(\"migrations\", \"0001_initial\")], clean_start=True\n                )\n                self.assertEqual(len(plan), 1)\n                self.assertEqual(plan[0][0].replaces, [])\n"], "sample_387": ["    def test_formfield_for_dbfield_with_custom_widget(self):\n        class MyModel(models.Model):\n            my_field = models.CharField(max_length=100)\n\n        class MyModelAdmin(admin.ModelAdmin):\n            formfield_overrides = {\n                models.CharField: {\"widget\": forms.TextInput(attrs={\"class\": \"my-custom-class\"})},\n            }\n\n        ff = self.assertFormfield(MyModel, \"my_field\", forms.TextInput, admin_overrides={\"formfield_overrides\": None})\n        self.assertEqual(ff.widget.attrs[\"class\"], \"my-custom-class\")\n"], "sample_960": ["    def test_parse_annotation(self):\n        assert _parse_annotation('int') == 'int'\n        assert _parse_annotation('int, str') == ('int', 'str')\n        assert _parse_annotation('List[int]') == ('List', ['int'])\n        assert _parse_annotation('Optional[str]') == ('Optional', ['str'])\n        assert _parse_annotation('Union[int, float]') == ('Union', ['int', 'float'])\n        assert _parse_annotation('typing.List[int]') == ('typing.List', ['int'])\n        assert _parse_annotation('typing.Optional[str]') == ('typing.Optional', ['str'])\n        assert _parse_annotation('typing.Union[int, float]') == ('typing.Union', ['int', 'float'])\n\n\n\n"], "sample_237": ["    def test_check_user_model_non_unique_username(self):\n        with self.assertLogs(level=checks.ERROR) as logs:\n            check_user_model(app_configs=self.apps.get_app_configs('auth_tests'))\n        self.assertEqual(len(logs.output), 1)\n        self.assertIn('\"%s.%s\" is named as the \"USERNAME_FIELD\", but it is not unique.' % (\n            CustomUserNonUniqueUsername._meta.object_name, CustomUserNonUniqueUsername.USERNAME_FIELD\n        ), logs.output[0])\n"], "sample_491": ["    def test_boundfield_label_tag(self):\n        form = PersonNew()\n        bound_field = form.fields[\"first_name\"]\n        rendered_label = bound_field.label_tag()\n        self.assertIn(\n            f\"for=\\\"first_name_id\\\"\", rendered_label\n        )\n        self.assertIn(\"First name\", rendered_label)\n\n        # Test with custom label\n        form = PersonNew(\n            initial={\"first_name\": \"John Doe\"},\n            auto_id=None,\n        )\n        bound_field = form.fields[\"first_name\"]\n        rendered_label = bound_field.label_tag(contents=\"Given Name\")\n        self.assertIn(f\"for=\\\"first_name_id\\\"\", rendered_label)\n        self.assertIn(\"Given Name\", rendered_label)\n\n        # Test with custom attrs\n        form = PersonNew(\n            initial={\"first_name\": \"John Doe\"},\n            auto_id=None,\n        )\n        bound_field = form.fields[\"first_name\"]\n        rendered_label = bound_field.label_tag(\n            attrs={\"class\": \"custom-label\"}\n        )\n        self.assertIn(f\"for=\\\"first_name_id\\\"\", rendered_label)\n        self.assertIn(\"class=\\\"custom-label\\\"\", rendered_label)\n\n        # Test with label suffix\n        form = PersonNew(\n            initial={\"first_name\": \"John Doe\"},\n            auto_id=None,\n        )\n        bound_field = form.fields[\"first_name\"]\n        rendered_label = bound_field.label_tag(\n            label_suffix=\" *\"\n        )\n        self.assertIn(f\"for=\\\"first_name_id\\\"\", rendered_label)\n        self.assertIn(\"First name *\", rendered_label)\n\n        # Test with no ID\n        form = PersonNew(\n            initial={\"first_name\": \"John Doe\"},\n            auto_id=None,\n        )\n        bound_field = form.fields[\"last_name\"]\n        rendered_label = bound_field.label_tag()\n        self.assertNotIn(f\"for=\\\"\", rendered_label)\n        self.assertIn(\"Last name\", rendered_label)\n\n\n\n"], "sample_433": ["    def test_unique_together_with_existing_data(self):\n        with self.assertRaises(IntegrityError):\n            models.Model.objects.create(\n                id=3,\n                newfield=1,\n                author=author_instance,\n                title=\"The Book of Awesome\",\n            )\n"], "sample_130": ["    def test_add_fields_with_m2m(self):\n        q = Query(Ranking)\n        q.add_fields(['id', 'name', 'author__name'], allow_m2m=True)\n        self.assertEqual(q.select, (\n            SimpleCol('ranking_ranking.id', output_field=Ranking._meta.pk),\n            SimpleCol('ranking_ranking.name', output_field=Ranking._meta.get_field('name')),\n            SimpleCol('author_author.name', output_field=Author._meta.get_field('name')),\n        ))\n"], "sample_117": ["    def test_password_validation(self):\n        form = UserCreationForm(data={'username': 'testuser', 'password1': 'password', 'password2': 'wrongpassword'})\n        self.assertFalse(form.is_valid())\n        self.assertIn('password2', form.errors)\n        self.assertEqual(form.errors['password2'][0], _('The two password fields didn\u2019t match.'))\n\n        form = UserCreationForm(data={'username': 'testuser', 'password1': 'password', 'password2': 'password'})\n        self.assertTrue(form.is_valid())\n"], "sample_222": ["    def test_lock_file(self):\n        with tempfile.NamedTemporaryFile(delete=False) as f:\n            file_path = f.name\n            with locks.lock(f, locks.LOCK_EX):\n                with open(file_path, 'a') as f2:\n                    f2.write('test')\n            with locks.lock(f, locks.LOCK_SH):\n                with open(file_path, 'r') as f3:\n                    self.assertEqual(f3.read(), 'test')\n"], "sample_20": ["    def test_write_table_fits_mixin_columns(self):\n        t = Table(self.data)\n        t.meta[\"__serialized_columns__\"] = {\"a\": {\"description\": \"Column a\"}}\n        t.meta[\"__serialized_columns__\"][\"a\"][\"meta\"] = {\"unit\": \"m\"}\n        with pytest.warns(AstropyDeprecationWarning) as warnings:\n            write_table_fits(t, \"test_mixin_table.fits\")\n        with fits.open(\"test_mixin_table.fits\") as hdul:\n            hdu = hdul[0]\n            t_read = Table.read(hdu)\n        assert equal_data(t, t_read)\n        assert t.meta[\"__serialized_columns__\"] == t_read.meta[\"__serialized_columns__\"]\n        assert t.meta[\"a\"].get(\"description\") == t_read.meta[\"a\"].get(\"description\")\n        assert t.meta[\"a\"].get(\"meta\").get(\"unit\") == t_read.meta[\"a\"].get(\"meta\").get(\"unit\")\n        os.remove(\"test_mixin_table.fits\")\n\n\n\n"], "sample_577": ["    def test_init_with_empty_data(self):\n        p = Plot(data=PlotData(frame=pd.DataFrame()))\n        assert p._subplots == []\n        assert p._scales == {}\n        assert p._legend_contents == []\n        assert p._layout_spec == {\"engine\": Default}\n\n\n\n"], "sample_849": ["    def test_train_test_split_sparse(self):\n        X_sparse = coo_matrix((np.ones(5), (range(5), range(5))))\n        X_dense = np.ones(5)\n        y = np.arange(5)\n\n        X_train, X_test, y_train, y_test = train_test_split(\n            X_sparse, y, test_size=0.33, random_state=42)\n\n        assert isinstance(X_train, csr_matrix)\n        assert isinstance(X_test, csr_matrix)\n        assert isinstance(y_train, np.ndarray)\n        assert isinstance(y_test, np.ndarray)\n\n        X_train, X_test, y_train, y_test = train_test_split(\n            X_dense, y, test_size=0.33, random_state=42)\n\n        assert isinstance(X_train, np.ndarray)\n        assert isinstance(X_test, np.ndarray)\n        assert isinstance(y_train, np.ndarray)\n        assert isinstance(y_test, np.ndarray)\n"], "sample_1193": ["    def test_idiff_complex():\n        x, y = Symbol('x'), Symbol('y')\n        eq = x**2 + y**2 - 4\n        with raises(ValueError):\n            idiff(eq, [y, x], x)\n        with raises(ValueError):\n            idiff(eq, x + y, x)\n        with raises(ValueError):\n            idiff(eq, 'y', x)\n        with raises(ValueError):\n            idiff(eq, Function('y')(x), x)\n"], "sample_17": ["    def test_array_repr(self):\n        from astropy.units import Quantity\n\n        class MyQuantity(Quantity):\n            pass\n\n        MyQuantity.unit = u.m\n\n        q = MyQuantity(np.arange(9.0).reshape(3, 3) / 4.0)\n        repr_str = array_repr(q)\n        assert repr_str == f\"array([[0.0, 0.25, 0.5 ],\\n       [0.75, 1.0, 1.25],\\n       [1.5, 1.75, 2.0 ]],\\n      dtype=float64, unit='m')\"\n"], "sample_562": ["    def test_dashed_lines(self):\n        fig, ax = plt.subplots()\n        x = np.linspace(0, 1, 10)\n        y = np.sin(2 * np.pi * x)\n        line, = ax.plot(x, y, linestyle='--', linewidth=2)\n        ax.set_xlim(0, 1)\n        ax.set_ylim(-1.2, 1.2)\n        plt.show()\n\n\n\n"], "sample_991": ["compilation error"], "sample_1006": ["    def test_binomial_negative_n(self):\n        n = Symbol('n', negative=True)\n        k = Symbol('k', integer=True)\n        with raises(ValueError):\n            binomial(n, k)\n"], "sample_884": ["    def test_deprecated_class_inheritance(self):\n        with pytest.warns(FutureWarning, match=\"Class MockClass1 is deprecated\"):\n            MockClass5(1)\n"], "sample_652": ["    def test_showfixtures_with_no_fixtures(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n                pass\n            \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"*::test_something*\"])\n        assert result.ret == 0\n"], "sample_711": ["compilation error"], "sample_755": ["    def test_silhouette_score_with_sparse_data(self):\n        X, y = datasets.make_blobs(n_samples=100, centers=3, random_state=42)\n        X_sparse = csr_matrix(X)\n        score = silhouette_score(X_sparse, y)\n        assert np.isclose(score, silhouette_score(X, y))\n"], "sample_118": ["    def test_year_lookup_exact(self):\n        qs = Article.objects.filter(pub_date__year__exact=2005)\n        self.assertQuerysetEqual(qs, ['<Article: Article 1>', '<Article: Article 2>', '<Article: Article 3>', '<Article: Article 4>'])\n\n        qs = Article.objects.filter(pub_date__year__exact=2006)\n        self.assertQuerysetEqual(qs, [])\n\n"], "sample_1192": ["    def test_disambiguate_nested():\n        from sympy.abc import x, y, z\n        expr = (x + y) * (x + z)\n        result = disambiguate(expr)\n        assert result == (x_1 + y) * (x_1 + z)\n"], "sample_453": ["    def test_submit_row_tag(self):\n        user = self.create_user(\"testuser\", \"testuser@example.com\")\n        self.login(user)\n        request = self.request_factory.get(reverse('admin:article_change', args=(1,)))\n        request.user = user\n        request.method = 'GET'\n        context = {'add': False, 'change': True, 'is_popup': False, 'save_as': False, 'has_add_permission': True, 'has_change_permission': True, 'has_delete_permission': True, 'show_delete': True, 'has_editable_inline_admin_formsets': False, 'show_save_and_add_another': True, 'show_save_and_continue': True}\n        context.update(submit_row(context))\n        self.assertContains(self.render_template('submit_line.html', context), 'Save and Continue')\n        self.assertContains(self.render_template('submit_line.html', context), 'Save and Add Another')\n        self.assertContains(self.render_template('submit_line.html', context), 'Delete')\n"], "sample_843": ["    def test_kernel_operator(kernel):\n        kernel_op = KernelOperator(kernel)\n        K = kernel_op(X)\n        assert_array_almost_equal(K, kernel(X))\n        K_grad = kernel_op.gradient(X)\n        assert_array_equal(K_grad.shape, (X.shape[0], X.shape[0], 1))\n        if hasattr(kernel, 'hyperparameter_length_scale'):\n            kernel_op.hyperparameter_length_scale.fixed = False\n            K_grad_fixed = kernel_op.gradient(X)\n            assert_array_equal(K_grad_fixed.shape, (X.shape[0], X.shape[0], 1))\n        else:\n            pass\n\n\n\n"], "sample_207": ["    def test_key_transform_lookup_mysql(self):\n        with connection.cursor() as cursor:\n            cursor.execute(\n                'CREATE TABLE test_key_transform_lookup (id INT PRIMARY KEY, data JSON)'\n            )\n        with connection.cursor() as cursor:\n            cursor.execute(\n                'INSERT INTO test_key_transform_lookup (id, data) VALUES (1, {\"key\": \"value\"})'\n            )\n        instance = JSONModel.objects.create(data={'key': 'value'})\n        self.assertEqual(JSONModel.objects.filter(data__key_transform__startswith='v').count(), 1)\n        self.assertEqual(JSONModel.objects.filter(data__key_transform__contains='v').count(), 1)\n        self.assertEqual(JSONModel.objects.filter(data__key_transform__endswith='e').count(), 1)\n        self.assertEqual(JSONModel.objects.filter(data__key_transform__regex='v.*').count(), 1)\n        self.assertEqual(JSONModel.objects.filter(data__key_transform__isnull=True).count(), 0)\n\n        with connection.cursor() as cursor:\n            cursor.execute(\n                'DROP TABLE test_key_transform_lookup'\n            )\n\n\n\n"], "sample_224": ["    def test_duration_field(self):\n        with self.assertNumQueries(1):\n            duration = Publisher.objects.get(name='Apress').duration\n        self.assertEqual(duration, datetime.timedelta(days=1))\n"], "sample_527": ["    def test_tight_layout_with_constrained_layout(self):\n        fig = Figure()\n        ax1 = fig.add_subplot(2, 1, 1)\n        ax2 = fig.add_subplot(2, 1, 2)\n\n        ax1.set_title('Top')\n        ax2.set_title('Bottom')\n\n        fig.tight_layout()\n\n        # Check that the layout is correct\n        assert ax1.get_position().y0 > 0.1\n        assert ax2.get_position().y0 < 0.9\n\n\n\n"], "sample_1036": ["    def test_transpose_identity():\n        assert (Identity(2).transpose() == Identity(2))"], "sample_822": ["    def test_pairwise_distances_chunked_with_reduce_func(metric):\n        X = np.random.rand(100, 3)\n        reduce_func = lambda D_chunk, start: np.mean(D_chunk, axis=1)\n        gen = pairwise_distances_chunked(X, reduce_func=reduce_func,\n                                        metric=metric)\n        for i in range(10):\n            chunk = next(gen)\n            assert isinstance(chunk, np.ndarray)\n            assert chunk.shape[0] == 10\n            assert chunk.shape[1] == 1\n"], "sample_80": ["    def test_add_fields_with_m2m(self):\n        q = Query(Item)\n        q.add_fields(['author__name', 'author__books__title'])\n        self.assertEqual(q.select, [\n            SimpleCol('author__name', output_field=CharField()),\n            SimpleCol('author__books__title', output_field=CharField()),\n        ])\n        self.assertEqual(q.extra_tables, {'author': Author._meta.db_table})\n        self.assertEqual(q.alias_map, {'item': Item._meta.db_table, 'author': Author._meta.db_table})\n        self.assertEqual(q.alias_refcount, {'item': 1, 'author': 1})\n"], "sample_1124": ["    def test_sfield_symbols_in_exprs():\n        x, y, z = symbols(\"x y z\")\n        K, f = sfield((x*log(x) + 4*x**2)*exp(1/x + log(x)/3)/x**2, symbols=[x, y, z])\n        assert K.symbols == (x, y, z)\n        assert f.as_expr(x, y, z) == (x*log(x) + 4*x**2)*exp(1/x + log(x)/3)/x**2\n\n\n\n"], "sample_676": ["    def test_build_summary_stats_line_unknown_types(self, option):\n        stats = {\n            \"failed\": [BaseReport()],\n            \"unknown_type\": [BaseReport()],\n            \"passed\": [BaseReport()],\n        }\n        line, color = build_summary_stats_line(stats)\n        assert \"unknown_type\" in line\n        assert color == \"yellow\"\n"], "sample_1118": ["    def test_matpow_negative_exponent_non_square(self):\n        with raises(NonSquareMatrixError):\n            MatPow(A, -1)\n"], "sample_1009": ["    def test_diff():\n        q1 = dynamicsymbols('q1')\n        N = ReferenceFrame('N')\n        A = N.orientnew('A', 'Axis', [q1, N.y])\n        v = A.x + N.z\n        dv_dq1 = v.diff(q1, N)\n        assert dv_dq1 == -A.z\n        dv_dq1_N = v.diff(q1, N, var_in_dcm=False)\n        assert dv_dq1_N == -A.z\n\n        # Test with a vector in a different frame\n        B = ReferenceFrame('B')\n        u1, u2 = dynamicsymbols('u1, u2')\n        w = u1 * A.x + u2 * B.y\n        dw_du2 = w.diff(u2, N, var_in_dcm=False)\n        assert dw_du2 == B.y\n"], "sample_910": ["    def test_pending_warnings(self):\n        with logging.pending_warnings() as memhandler:\n            logging.getLogger(logging.NAMESPACE).warning('Warning message!')\n        assert len(memhandler.logs) == 1\n        assert isinstance(memhandler.logs[0], logging.LogRecord)\n        assert memhandler.logs[0].levelno == logging.WARNING\n        assert 'Warning message!' in memhandler.logs[0].msg\n"], "sample_551": ["compilation error"], "sample_1142": ["    def test_from_index_summation_trace():\n        expr = Sum(A[i, i], (i, 0, n - 1))\n        result = MatrixExpr.from_index_summation(expr)\n        assert result == Trace(A)\n"], "sample_163": ["    def test_login_view_redirect_to_login_url(self):\n        self.logout()\n        response = self.client.get(reverse(\"login\"))\n        self.assertRedirects(response, reverse(\"login\"), 302)\n"], "sample_254": ["    def test_inline_formset_with_custom_form(self):\n        response = self.client.get(reverse('admin:inlines_inner_changelist'))\n        self.assertContains(response, INLINE_CHANGELINK_HTML)\n        self.assertContains(response, 'Inner')\n\n        response = self.client.get(reverse('admin:inlines_inner_change', args=(self.holder.id,)))\n        self.assertContains(response, INLINE_CHANGELINK_HTML)\n        self.assertContains(response, 'Inner')\n\n\n\n"], "sample_880": ["compilation error"], "sample_1106": ["compilation error"], "sample_1077": ["    def test_complex_region_intersection_polar(self):\n        r1 = Interval(0, 1)\n        theta1 = Interval(0, pi/2)\n        r2 = Interval(0.5, 1.5)\n        theta2 = Interval(pi/4, 3*pi/4)\n        c1 = ComplexRegion(r1*theta1, polar=True)\n        c2 = ComplexRegion(r2*theta2, polar=True)\n        intersection = c1.intersect(c2)\n        expected = ComplexRegion(ProductSet(Interval(0.5, 1), Interval(pi/4, pi/2)), True)\n        self.assertEqual(intersection, expected)\n\n\n\n"], "sample_478": ["    def test_check_raw_id_fields(self):\n        class RawIdAdmin(ModelAdmin):\n            raw_id_fields = ['id']\n\n        self.assertIsInvalid(\n            RawIdAdmin,\n            ValidationTestModel,\n            \"The value of 'raw_id_fields' must be a list of field names.\",\n            id=\"admin.E131\",\n        )\n\n"], "sample_505": ["    def test_microsecond_locator_with_epoch_far_from_origin(self, tz):\n        with rc_context(\n            {'date.converter': 'auto', 'date.interval_multiples': True},\n            {'figure.figsize': (6, 4)}):\n            fig, ax = plt.subplots()\n            x = np.arange(date2num(datetime.datetime(1900, 1, 1))\n                          , date2num(datetime.datetime(1900, 1, 1) +\n                                     datetime.timedelta(days=1000)))\n            ax.plot(x, np.random.rand(len(x)))\n            ax.xaxis.set_major_locator(mdates.MicrosecondLocator(interval=1000))\n            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S.%f'))\n            plt.draw()\n            image_comparison(\n                'microsecond_locator_far_from_epoch',\n                tol=0.05,\n                savefig_kwargs={'bbox_inches': 'tight'})\n"], "sample_643": ["    def test_colorized_text_reporter_with_custom_color_mapping(\n        reporter: TextReporter, disable: list[str]"], "sample_236": ["    def test_restricted_error(self):\n        a = create_a()\n        b = B(a=a)\n        b.save()\n        collector = Collector(using=connection.db)\n        with self.assertRaises(RestrictedError) as context:\n            collector.collect(b, field=a.b_set.remote_field,\n                             source=a, nullable=False,\n                             fail_on_restricted=True)\n        self.assertEqual(\n            str(context.exception),\n            'Cannot delete some instances of model \\'b\\' because they are '\n            'referenced through restricted foreign keys: '\n            '[\\'b.a\\']'\n        )\n\n\n\n"], "sample_954": ["    def test_manpage_builder_with_nested_inline(self, tmpdir):\n        \"\"\"Test the manpage builder with nested inline nodes.\"\"\"\n        self.build_test_doc(\n            tmpdir,\n            source='nested_inline.rst',\n            builder=default_man_pages,\n            config=Config(\n                man_pages=['man1'],\n                project='test',\n                version='0.1',\n                subtitle='test subtitle',\n                authors=['John Doe'],\n                today='2023-10-26',\n                copyright='Copyright 2023',\n            ),\n        )\n        output = self.get_expected_output('nested_inline.man')\n        assert self.get_output_lines(tmpdir) == output\n"], "sample_395": ["    def test_watch_for_template_changes(self, mock_reset_loaders):\n        autoreload.start()\n        (ROOT / \"templates_extra\" / \"test.html\").write_text(\"<h1>Hello</h1>\")\n        mock_reset_loaders.assert_called_once()\n"], "sample_701": ["    def test_deprecated_collect_module(pytester: Pytester):\n        pytester.writefile(\"test_module.py\", \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"attribute\", pytest.collect.__all__)\n            pytest.collect.{attribute}\n        \"\"\")\n        result = pytester.runpytest()\n        assert result.retcode == 0\n        # Check for the deprecation warning\n        warnings_output = result.stdout.str()\n        assert deprecated.PYTEST_COLLECT_MODULE.message in warnings_output\n"], "sample_1019": ["    def test_factor_nc_nested():\n        from sympy.physics.secondquant import Commutator, NO, F, Fd\n        A, B, C = symbols('A,B,C', commutative=False)\n        eq = (NO(Fd(x)*F(y))*NO(Fd(z)*F(w))).expand()\n        fac = factor_nc(eq)\n        assert fac == NO(Fd(x)*F(y))*NO(Fd(z)*F(w))\n        "]}, "raw_scored_generations": {"sample_0": [false], "sample_1": [false], "sample_3": [false], "sample_2": [false], "sample_4": [true], "sample_5": [false], "sample_6": [false], "sample_7": [false], "sample_8": [true], "sample_9": [false], "sample_10": [false], "sample_11": [false], "sample_12": [false], "sample_13": [false], "sample_14": [false], "sample_15": [false], "sample_16": [false], "sample_17": [false], "sample_18": [true], "sample_19": [false], "sample_20": [false], "sample_21": [false], "sample_22": [false], "sample_23": [false], "sample_24": [false], "sample_25": [false], "sample_26": [false], "sample_27": [false], "sample_28": [false], "sample_29": [false], "sample_30": [false], "sample_31": [false], "sample_32": [true], "sample_33": [false], "sample_34": [false], "sample_35": [false], "sample_36": [false], "sample_37": [false], "sample_38": [false], "sample_39": [false], "sample_40": [false], "sample_41": [false], "sample_42": [false], "sample_43": [false], "sample_44": [false], "sample_45": [false], "sample_46": [false], "sample_47": [false], "sample_48": [false], "sample_49": [false], "sample_50": [true], "sample_51": [false], "sample_52": [false], "sample_54": [false], "sample_53": [true], "sample_55": [false], "sample_58": [false], "sample_56": [false], "sample_57": [false], "sample_59": [false], "sample_60": [false], "sample_61": [false], "sample_62": [true], "sample_63": [false], "sample_64": [false], "sample_65": [false], "sample_67": [false], "sample_66": [true], "sample_68": [false], "sample_69": [false], "sample_70": [false], "sample_71": [false], "sample_72": [false], "sample_73": [true], "sample_75": [false], "sample_74": [true], "sample_76": [false], "sample_77": [false], "sample_78": [false], "sample_79": [false], "sample_80": [false], "sample_82": [true], "sample_81": [false], "sample_83": [false], "sample_85": [false], "sample_84": [false], "sample_86": [false], "sample_88": [false], "sample_87": [false], "sample_89": [false], "sample_90": [false], "sample_91": [false], "sample_92": [true], "sample_93": [false], "sample_94": [false], "sample_95": [false], "sample_98": [false], "sample_96": [false], "sample_99": [false], "sample_97": [false], "sample_100": [false], "sample_102": [false], "sample_101": [false], "sample_103": [false], "sample_104": [true], "sample_107": [false], "sample_106": [false], "sample_105": [true], "sample_108": [false], "sample_109": [false], "sample_111": [false], "sample_110": [false], "sample_112": [false], "sample_113": [false], "sample_114": [false], "sample_115": [false], "sample_116": [false], "sample_117": [true], "sample_118": [false], "sample_119": [false], "sample_120": [false], "sample_121": [false], "sample_122": [true], "sample_123": [false], "sample_124": [false], "sample_125": [false], "sample_126": [false], "sample_127": [false], "sample_128": [false], "sample_129": [false], "sample_130": [false], "sample_131": [false], "sample_132": [false], "sample_133": [false], "sample_135": [false], "sample_134": [false], "sample_136": [false], "sample_139": [false], "sample_137": [false], "sample_138": [true], "sample_140": [false], "sample_141": [false], "sample_142": [false], "sample_143": [false], "sample_144": [false], "sample_145": [false], "sample_146": [false], "sample_147": [false], "sample_148": [false], "sample_151": [false], "sample_149": [true], "sample_152": [false], "sample_150": [false], "sample_153": [false], "sample_154": [true], "sample_155": [true], "sample_156": [false], "sample_157": [false], "sample_158": [false], "sample_159": [true], "sample_160": [false], "sample_161": [false], "sample_162": [true], "sample_163": [false], "sample_164": [false], "sample_165": [false], "sample_166": [true], "sample_167": [false], "sample_168": [false], "sample_169": [false], "sample_171": [false], "sample_170": [false], "sample_172": [false], "sample_173": [true], "sample_174": [false], "sample_175": [false], "sample_176": [true], "sample_177": [false], "sample_178": [true], "sample_180": [false], "sample_179": [false], "sample_182": [false], "sample_181": [false], "sample_183": [false], "sample_184": [false], "sample_185": [false], "sample_186": [false], "sample_187": [false], "sample_188": [false], "sample_189": [false], "sample_190": [false], "sample_191": [false], "sample_192": [true], "sample_193": [false], "sample_194": [false], "sample_195": [false], "sample_196": [false], "sample_198": [false], "sample_197": [false], "sample_199": [false], "sample_200": [false], "sample_201": [false], "sample_202": [false], "sample_203": [false], "sample_204": [false], "sample_205": [false], "sample_206": [false], "sample_207": [false], "sample_208": [false], "sample_209": [false], "sample_210": [true], "sample_211": [false], "sample_213": [false], "sample_212": [false], "sample_214": [false], "sample_215": [false], "sample_216": [false], "sample_217": [false], "sample_218": [false], "sample_219": [false], "sample_220": [false], "sample_221": [false], "sample_222": [false], "sample_223": [false], "sample_224": [true], "sample_225": [false], "sample_226": [false], "sample_227": [false], "sample_228": [false], "sample_229": [false], "sample_230": [false], "sample_231": [false], "sample_232": [false], "sample_233": [true], "sample_234": [false], "sample_235": [true], "sample_236": [false], "sample_237": [false], "sample_238": [false], "sample_239": [false], "sample_240": [false], "sample_241": [true], "sample_242": [false], "sample_243": [false], "sample_244": [false], "sample_245": [true], "sample_246": [true], "sample_247": [false], "sample_248": [true], "sample_249": [false], "sample_250": [false], "sample_251": [false], "sample_252": [false], "sample_253": [false], "sample_254": [false], "sample_256": [false], "sample_255": [false], "sample_257": [false], "sample_258": [false], "sample_259": [false], "sample_260": [false], "sample_261": [false], "sample_262": [false], "sample_263": [false], "sample_264": [false], "sample_265": [false], "sample_266": [false], "sample_267": [false], "sample_268": [false], "sample_269": [false], "sample_270": [false], "sample_271": [false], "sample_272": [false], "sample_273": [false], "sample_274": [false], "sample_275": [true], "sample_276": [false], "sample_277": [false], "sample_278": [false], "sample_279": [false], "sample_280": [false], "sample_281": [true], "sample_282": [true], "sample_283": [false], "sample_284": [true], "sample_285": [false], "sample_286": [false], "sample_287": [false], "sample_288": [false], "sample_289": [true], "sample_290": [false], "sample_291": [false], "sample_292": [true], "sample_293": [false], "sample_294": [true], "sample_295": [false], "sample_296": [false], "sample_297": [false], "sample_298": [true], "sample_299": [false], "sample_300": [false], "sample_301": [false], "sample_302": [true], "sample_303": [false], "sample_304": [false], "sample_305": [false], "sample_306": [false], "sample_307": [false], "sample_308": [false], "sample_309": [true], "sample_310": [false], "sample_312": [false], "sample_311": [false], "sample_313": [false], "sample_314": [false], "sample_315": [false], "sample_316": [false], "sample_317": [false], "sample_318": [false], "sample_319": [false], "sample_320": [false], "sample_321": [true], "sample_322": [false], "sample_323": [false], "sample_324": [false], "sample_325": [false], "sample_326": [false], "sample_327": [true], "sample_328": [true], "sample_329": [false], "sample_330": [false], "sample_331": [false], "sample_332": [false], "sample_333": [false], "sample_334": [true], "sample_335": [false], "sample_336": [false], "sample_337": [false], "sample_338": [false], "sample_339": [false], "sample_340": [false], "sample_341": [false], "sample_342": [false], "sample_343": [false], "sample_344": [false], "sample_345": [false], "sample_346": [false], "sample_347": [true], "sample_348": [false], "sample_349": [false], "sample_350": [false], "sample_351": [false], "sample_352": [false], "sample_353": [false], "sample_354": [false], "sample_355": [false], "sample_356": [false], "sample_357": [false], "sample_358": [false], "sample_359": [false], "sample_360": [true], "sample_361": [false], "sample_362": [false], "sample_363": [false], "sample_364": [false], "sample_365": [false], "sample_366": [false], "sample_367": [false], "sample_368": [false], "sample_369": [false], "sample_370": [false], "sample_371": [true], "sample_372": [false], "sample_373": [false], "sample_374": [false], "sample_375": [false], "sample_376": [false], "sample_377": [false], "sample_378": [false], "sample_379": [false], "sample_380": [false], "sample_381": [false], "sample_382": [false], "sample_383": [false], "sample_384": [false], "sample_385": [false], "sample_386": [false], "sample_387": [false], "sample_388": [false], "sample_389": [false], "sample_390": [false], "sample_391": [false], "sample_392": [false], "sample_393": [true], "sample_394": [false], "sample_395": [false], "sample_396": [false], "sample_397": [false], "sample_398": [false], "sample_399": [false], "sample_400": [false], "sample_401": [false], "sample_402": [false], "sample_403": [false], "sample_404": [true], "sample_405": [false], "sample_406": [false], "sample_407": [false], "sample_408": [false], "sample_409": [false], "sample_410": [true], "sample_411": [false], "sample_412": [false], "sample_413": [false], "sample_414": [false], "sample_415": [false], "sample_416": [false], "sample_417": [false], "sample_418": [false], "sample_419": [false], "sample_420": [false], "sample_421": [false], "sample_422": [false], "sample_423": [false], "sample_424": [false], "sample_425": [false], "sample_426": [false], "sample_427": [false], "sample_428": [false], "sample_429": [false], "sample_430": [false], "sample_431": [false], "sample_432": [false], "sample_433": [false], "sample_434": [false], "sample_435": [false], "sample_436": [false], "sample_437": [false], "sample_438": [false], "sample_439": [true], "sample_440": [false], "sample_441": [false], "sample_442": [false], "sample_443": [false], "sample_444": [true], "sample_445": [false], "sample_446": [false], "sample_447": [false], "sample_448": [false], "sample_449": [false], "sample_450": [false], "sample_451": [false], "sample_453": [false], "sample_452": [false], "sample_454": [false], "sample_455": [false], "sample_456": [false], "sample_457": [false], "sample_458": [false], "sample_459": [false], "sample_460": [false], "sample_461": [false], "sample_462": [false], "sample_463": [false], "sample_464": [false], "sample_465": [false], "sample_466": [false], "sample_467": [false], "sample_469": [false], "sample_468": [false], "sample_470": [false], "sample_471": [false], "sample_472": [false], "sample_473": [false], "sample_474": [false], "sample_475": [false], "sample_476": [false], "sample_477": [false], "sample_478": [false], "sample_479": [false], "sample_480": [false], "sample_481": [false], "sample_482": [false], "sample_483": [false], "sample_484": [true], "sample_485": [false], "sample_486": [false], "sample_487": [false], "sample_488": [false], "sample_489": [false], "sample_490": [false], "sample_491": [false], "sample_492": [false], "sample_493": [false], "sample_494": [false], "sample_495": [false], "sample_496": [false], "sample_497": [false], "sample_498": [false], "sample_499": [false], "sample_500": [false], "sample_501": [false], "sample_502": [false], "sample_503": [false], "sample_504": [false], "sample_505": [false], "sample_506": [false], "sample_507": [false], "sample_508": [false], "sample_509": [false], "sample_510": [false], "sample_511": [false], "sample_512": [false], "sample_513": [false], "sample_514": [false], "sample_515": [false], "sample_516": [false], "sample_517": [false], "sample_518": [false], "sample_519": [false], "sample_520": [false], "sample_521": [false], "sample_522": [false], "sample_523": [false], "sample_524": [false], "sample_525": [false], "sample_526": [false], "sample_527": [false], "sample_528": [false], "sample_529": [false], "sample_530": [false], "sample_531": [false], "sample_532": [false], "sample_533": [false], "sample_534": [false], "sample_535": [false], "sample_536": [false], "sample_537": [false], "sample_538": [false], "sample_539": [false], "sample_540": [false], "sample_541": [false], "sample_542": [false], "sample_543": [false], "sample_544": [false], "sample_545": [false], "sample_546": [false], "sample_547": [false], "sample_548": [false], "sample_549": [true], "sample_550": [false], "sample_551": [false], "sample_552": [false], "sample_553": [false], "sample_554": [false], "sample_555": [false], "sample_556": [false], "sample_557": [false], "sample_558": [false], "sample_559": [false], "sample_560": [false], "sample_561": [false], "sample_562": [false], "sample_563": [false], "sample_564": [false], "sample_565": [false], "sample_566": [false], "sample_567": [false], "sample_568": [false], "sample_569": [false], "sample_570": [false], "sample_571": [false], "sample_572": [false], "sample_573": [false], "sample_574": [false], "sample_575": [false], "sample_576": [false], "sample_577": [false], "sample_578": [false], "sample_579": [false], "sample_580": [false], "sample_581": [false], "sample_582": [false], "sample_583": [false], "sample_584": [false], "sample_585": [false], "sample_586": [false], "sample_587": [false], "sample_588": [false], "sample_589": [false], "sample_590": [false], "sample_591": [false], "sample_592": [false], "sample_593": [false], "sample_594": [false], "sample_595": [false], "sample_596": [false], "sample_597": [false], "sample_598": [false], "sample_599": [false], "sample_600": [false], "sample_601": [false], "sample_602": [false], "sample_603": [true], "sample_604": [false], "sample_605": [false], "sample_606": [false], "sample_607": [false], "sample_608": [false], "sample_609": [false], "sample_610": [false], "sample_611": [false], "sample_612": [false], "sample_613": [false], "sample_614": [false], "sample_615": [false], "sample_616": [false], "sample_617": [false], "sample_618": [false], "sample_619": [false], "sample_620": [false], "sample_621": [false], "sample_622": [false], "sample_623": [false], "sample_624": [false], "sample_625": [false], "sample_626": [false], "sample_627": [false], "sample_628": [false], "sample_629": [false], "sample_630": [false], "sample_631": [false], "sample_632": [false], "sample_633": [false], "sample_634": [false], "sample_635": [false], "sample_636": [false], "sample_637": [false], "sample_638": [false], "sample_639": [false], "sample_640": [false], "sample_641": [false], "sample_642": [false], "sample_643": [false], "sample_644": [false], "sample_645": [false], "sample_646": [false], "sample_647": [false], "sample_648": [false], "sample_649": [false], "sample_650": [false], "sample_651": [false], "sample_652": [false], "sample_653": [false], "sample_654": [false], "sample_655": [false], "sample_656": [false], "sample_657": [false], "sample_658": [false], "sample_659": [false], "sample_660": [false], "sample_661": [false], "sample_662": [false], "sample_663": [false], "sample_664": [false], "sample_665": [false], "sample_666": [false], "sample_667": [false], "sample_668": [false], "sample_669": [false], "sample_670": [false], "sample_671": [false], "sample_672": [false], "sample_673": [false], "sample_674": [false], "sample_675": [false], "sample_676": [false], "sample_677": [false], "sample_678": [false], "sample_679": [false], "sample_680": [false], "sample_681": [false], "sample_682": [false], "sample_683": [false], "sample_684": [false], "sample_685": [false], "sample_686": [false], "sample_687": [false], "sample_688": [false], "sample_689": [false], "sample_690": [false], "sample_691": [false], "sample_692": [false], "sample_693": [false], "sample_694": [false], "sample_695": [false], "sample_696": [false], "sample_697": [false], "sample_698": [false], "sample_699": [false], "sample_700": [false], "sample_701": [false], "sample_702": [false], "sample_703": [false], "sample_704": [false], "sample_705": [false], "sample_706": [true], "sample_707": [false], "sample_708": [false], "sample_709": [false], "sample_710": [false], "sample_711": [false], "sample_712": [false], "sample_713": [false], "sample_714": [false], "sample_715": [false], "sample_716": [false], "sample_717": [false], "sample_718": [false], "sample_719": [false], "sample_720": [false], "sample_721": [false], "sample_722": [false], "sample_723": [false], "sample_724": [false], "sample_725": [false], "sample_726": [false], "sample_727": [false], "sample_728": [false], "sample_729": [false], "sample_730": [false], "sample_731": [false], "sample_732": [false], "sample_733": [false], "sample_734": [false], "sample_735": [false], "sample_736": [true], "sample_737": [false], "sample_738": [false], "sample_739": [false], "sample_740": [false], "sample_741": [false], "sample_742": [false], "sample_743": [true], "sample_744": [false], "sample_745": [false], "sample_746": [false], "sample_747": [false], "sample_748": [false], "sample_749": [false], "sample_750": [false], "sample_751": [false], "sample_752": [false], "sample_753": [false], "sample_754": [false], "sample_755": [false], "sample_756": [false], "sample_757": [false], "sample_758": [false], "sample_759": [false], "sample_760": [false], "sample_761": [false], "sample_762": [false], "sample_763": [false], "sample_764": [false], "sample_765": [false], "sample_766": [false], "sample_767": [false], "sample_768": [false], "sample_769": [false], "sample_770": [false], "sample_771": [false], "sample_772": [false], "sample_773": [false], "sample_774": [false], "sample_775": [false], "sample_776": [false], "sample_777": [false], "sample_778": [false], "sample_779": [false], "sample_780": [true], "sample_781": [false], "sample_782": [false], "sample_783": [false], "sample_784": [false], "sample_785": [false], "sample_786": [false], "sample_787": [false], "sample_788": [false], "sample_789": [false], "sample_790": [false], "sample_791": [false], "sample_792": [false], "sample_793": [false], "sample_794": [false], "sample_795": [false], "sample_796": [false], "sample_797": [false], "sample_798": [false], "sample_799": [false], "sample_800": [false], "sample_801": [false], "sample_802": [false], "sample_803": [false], "sample_804": [false], "sample_805": [false], "sample_806": [false], "sample_807": [false], "sample_808": [false], "sample_809": [false], "sample_810": [false], "sample_811": [false], "sample_812": [false], "sample_813": [false], "sample_814": [false], "sample_815": [false], "sample_816": [false], "sample_817": [false], "sample_818": [false], "sample_819": [false], "sample_820": [false], "sample_821": [false], "sample_822": [false], "sample_823": [false], "sample_824": [false], "sample_825": [false], "sample_826": [true], "sample_827": [false], "sample_828": [false], "sample_829": [false], "sample_830": [false], "sample_831": [false], "sample_832": [false], "sample_833": [false], "sample_834": [false], "sample_835": [false], "sample_836": [false], "sample_837": [false], "sample_838": [false], "sample_839": [false], "sample_840": [false], "sample_841": [false], "sample_842": [false], "sample_843": [false], "sample_844": [false], "sample_845": [false], "sample_846": [false], "sample_847": [false], "sample_848": [false], "sample_849": [false], "sample_850": [false], "sample_851": [false], "sample_852": [false], "sample_853": [false], "sample_854": [false], "sample_855": [false], "sample_856": [false], "sample_857": [true], "sample_858": [false], "sample_859": [false], "sample_860": [false], "sample_861": [false], "sample_862": [false], "sample_863": [false], "sample_864": [false], "sample_865": [false], "sample_866": [false], "sample_867": [false], "sample_868": [false], "sample_869": [false], "sample_870": [false], "sample_871": [false], "sample_872": [false], "sample_873": [false], "sample_874": [false], "sample_875": [false], "sample_876": [false], "sample_877": [false], "sample_878": [false], "sample_879": [false], "sample_880": [false], "sample_881": [false], "sample_882": [false], "sample_883": [false], "sample_884": [false], "sample_885": [false], "sample_886": [false], "sample_887": [false], "sample_888": [false], "sample_889": [false], "sample_890": [false], "sample_891": [false], "sample_892": [false], "sample_893": [false], "sample_894": [false], "sample_895": [false], "sample_896": [false], "sample_897": [false], "sample_898": [false], "sample_899": [false], "sample_900": [false], "sample_901": [false], "sample_902": [false], "sample_903": [false], "sample_904": [false], "sample_905": [false], "sample_906": [false], "sample_907": [false], "sample_908": [false], "sample_909": [false], "sample_910": [false], "sample_911": [false], "sample_912": [false], "sample_913": [false], "sample_914": [false], "sample_915": [false], "sample_916": [false], "sample_917": [false], "sample_918": [false], "sample_919": [false], "sample_920": [false], "sample_921": [false], "sample_922": [false], "sample_923": [false], "sample_924": [false], "sample_925": [false], "sample_926": [false], "sample_927": [false], "sample_928": [false], "sample_929": [false], "sample_930": [false], "sample_931": [false], "sample_932": [false], "sample_933": [false], "sample_934": [false], "sample_935": [false], "sample_936": [false], "sample_937": [false], "sample_938": [false], "sample_939": [false], "sample_940": [false], "sample_941": [false], "sample_942": [false], "sample_943": [false], "sample_944": [false], "sample_945": [false], "sample_946": [false], "sample_947": [false], "sample_948": [false], "sample_949": [false], "sample_950": [false], "sample_951": [false], "sample_952": [false], "sample_953": [false], "sample_954": [false], "sample_955": [false], "sample_956": [false], "sample_957": [false], "sample_958": [false], "sample_959": [false], "sample_960": [false], "sample_961": [false], "sample_962": [false], "sample_963": [false], "sample_964": [false], "sample_965": [false], "sample_966": [false], "sample_967": [false], "sample_968": [false], "sample_969": [true], "sample_970": [false], "sample_971": [false], "sample_972": [true], "sample_973": [false], "sample_974": [false], "sample_975": [false], "sample_976": [false], "sample_977": [false], "sample_978": [false], "sample_979": [false], "sample_980": [false], "sample_981": [false], "sample_982": [true], "sample_983": [false], "sample_984": [false], "sample_985": [false], "sample_986": [true], "sample_987": [true], "sample_988": [false], "sample_989": [true], "sample_990": [false], "sample_991": [false], "sample_992": [false], "sample_993": [false], "sample_994": [true], "sample_995": [true], "sample_996": [false], "sample_997": [false], "sample_998": [false], "sample_999": [false], "sample_1000": [false], "sample_1001": [false], "sample_1002": [true], "sample_1003": [false], "sample_1004": [false], "sample_1005": [false], "sample_1006": [false], "sample_1007": [false], "sample_1008": [false], "sample_1009": [false], "sample_1010": [false], "sample_1011": [false], "sample_1012": [false], "sample_1013": [false], "sample_1014": [false], "sample_1015": [false], "sample_1016": [false], "sample_1017": [false], "sample_1018": [false], "sample_1019": [false], "sample_1020": [false], "sample_1021": [false], "sample_1022": [false], "sample_1023": [false], "sample_1024": [true], "sample_1025": [false], "sample_1026": [false], "sample_1027": [true], "sample_1028": [false], "sample_1029": [false], "sample_1030": [false], "sample_1031": [false], "sample_1032": [false], "sample_1033": [true], "sample_1034": [true], "sample_1035": [false], "sample_1036": [false], "sample_1037": [false], "sample_1038": [false], "sample_1039": [false], "sample_1040": [false], "sample_1041": [false], "sample_1042": [false], "sample_1043": [false], "sample_1044": [false], "sample_1045": [true], "sample_1046": [true], "sample_1047": [false], "sample_1048": [false], "sample_1049": [false], "sample_1050": [false], "sample_1051": [false], "sample_1052": [false], "sample_1053": [true], "sample_1054": [false], "sample_1055": [false], "sample_1056": [false], "sample_1057": [false], "sample_1058": [false], "sample_1059": [false], "sample_1060": [false], "sample_1061": [true], "sample_1062": [false], "sample_1063": [false], "sample_1064": [true], "sample_1065": [false], "sample_1066": [false], "sample_1067": [false], "sample_1068": [false], "sample_1069": [false], "sample_1070": [false], "sample_1071": [false], "sample_1072": [false], "sample_1073": [false], "sample_1074": [false], "sample_1075": [false], "sample_1076": [false], "sample_1077": [false], "sample_1078": [false], "sample_1079": [false], "sample_1080": [false], "sample_1081": [true], "sample_1082": [false], "sample_1083": [false], "sample_1084": [false], "sample_1085": [true], "sample_1086": [false], "sample_1087": [false], "sample_1088": [false], "sample_1089": [false], "sample_1090": [false], "sample_1091": [true], "sample_1092": [false], "sample_1093": [false], "sample_1094": [false], "sample_1095": [false], "sample_1096": [false], "sample_1097": [false], "sample_1098": [false], "sample_1099": [false], "sample_1100": [true], "sample_1101": [false], "sample_1102": [true], "sample_1103": [false], "sample_1104": [false], "sample_1105": [false], "sample_1106": [false], "sample_1107": [false], "sample_1108": [false], "sample_1109": [false], "sample_1110": [false], "sample_1111": [false], "sample_1112": [false], "sample_1113": [false], "sample_1114": [false], "sample_1115": [true], "sample_1116": [false], "sample_1117": [false], "sample_1118": [false], "sample_1119": [false], "sample_1120": [false], "sample_1121": [true], "sample_1122": [false], "sample_1123": [false], "sample_1124": [false], "sample_1125": [false], "sample_1126": [false], "sample_1127": [false], "sample_1128": [false], "sample_1129": [false], "sample_1130": [false], "sample_1131": [false], "sample_1132": [false], "sample_1133": [false], "sample_1134": [false], "sample_1135": [true], "sample_1136": [true], "sample_1137": [false], "sample_1138": [false], "sample_1139": [false], "sample_1140": [false], "sample_1141": [false], "sample_1142": [false], "sample_1143": [true], "sample_1144": [false], "sample_1145": [false], "sample_1146": [false], "sample_1147": [false], "sample_1148": [false], "sample_1149": [false], "sample_1150": [false], "sample_1151": [true], "sample_1152": [false], "sample_1153": [true], "sample_1154": [false], "sample_1155": [false], "sample_1156": [false], "sample_1157": [false], "sample_1158": [false], "sample_1159": [false], "sample_1160": [false], "sample_1161": [false], "sample_1162": [false], "sample_1163": [true], "sample_1164": [false], "sample_1165": [false], "sample_1166": [false], "sample_1167": [false], "sample_1168": [false], "sample_1169": [false], "sample_1170": [false], "sample_1171": [false], "sample_1172": [false], "sample_1173": [false], "sample_1174": [true], "sample_1175": [false], "sample_1176": [true], "sample_1177": [true], "sample_1178": [false], "sample_1179": [false], "sample_1180": [false], "sample_1181": [false], "sample_1182": [false], "sample_1183": [false], "sample_1184": [false], "sample_1185": [false], "sample_1186": [false], "sample_1187": [false], "sample_1188": [false], "sample_1189": [false], "sample_1190": [false], "sample_1191": [false], "sample_1192": [false], "sample_1193": [false], "sample_1194": [false], "sample_1195": [false], "sample_1196": [false], "sample_1197": [false], "sample_1198": [false], "sample_1199": [false], "sample_1200": [false], "sample_1201": [false], "sample_1202": [true], "sample_1203": [false], "sample_1204": [false], "sample_1205": [false], "sample_1206": [true], "sample_1207": [false], "sample_1208": [false], "sample_1209": [false]}}