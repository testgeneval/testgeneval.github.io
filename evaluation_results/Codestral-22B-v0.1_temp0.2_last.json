{"raw_generations": {"sample_200": ["def test_send_messages_with_connection_exception(self):\n    \"\"\"\n    send_messages() should handle exceptions raised while sending messages.\n    \"\"\"\n    backend = smtp.EmailBackend()\n    backend.connection = True\n    email = EmailMessage('Subject', 'Content', 'from@example.com', ['to@example.com'])\n\n        raise SMTPException(\"Error sending message\")\n\n    backend.connection.sendmail = mock_sendmail\n    sent = backend.send_messages([email])\n    self.assertEqual(sent, 0)\n"], "sample_1007": ["def test_subfactorial():\n    n = Symbol('n', integer=True)\n    assert subfactorial(0) == 1\n    assert subfactorial(1) == 0\n    assert subfactorial(2) == 1\n    assert subfactorial(3) == 2\n    assert subfactorial(4) == 9\n    assert subfactorial(5) == 44\n    assert subfactorial(n).func == subfactorial\n    assert subfactorial(n).is_even is None\n    assert subfactorial(n).is_odd is None\n    assert subfactorial(n).is_integer is None\n    assert subfactorial(n).is_nonnegative is None\n    assert subfactorial(n + 1).func == subfactorial\n    assert subfactorial(n + 1).is_even is None\n    assert subfactorial(n + 1).is_odd is None\n    assert subfactorial(n + 1).is_integer is None\n    assert subfactorial(n + 1).is_nonnegative is None\n    assert subfactorial(n).rewrite(uppergamma) == uppergamma(n + 1, -1)/S.Exp1\n"], "sample_55": ["def test_get_formsets_with_inlines_argument(self):\n    # Test get_formsets_with_inlines() during add_view\n    response = self.client.get(reverse('admin:admin_views_getformsetsargumentchecking_add'))\n    self.assertNotIn('obj', response.context_data)\n\n    # Test get_formsets_with_inlines() during change_view\n    obj = GetFormsetsArgumentChecking.objects.create(name='Test')\n    response = self.client.get(reverse('admin:admin_views_getformsetsargumentchecking_change', args=(obj.pk,)))\n    self.assertEqual(response.context_data['obj'], obj)\n"], "sample_744": ["def test_power_transformer_yeo_johnson():\n    X = np.abs(X_2d)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method='yeo-johnson', standardize=standardize)\n\n        X_trans_class = pt.fit_transform(X)\n        X_trans_func = power_transform(X, method='yeo-johnson', standardize=standardize)\n\n        for X_trans in [X_trans_class, X_trans_func]:\n            for j in range(X_trans.shape[1]):\n                X_expected, lmbda = stats.yeojohnson(X[:, j].flatten())\n\n                if standardize:\n                    X_expected = scale(X_expected)\n\n                assert_almost_equal(X_trans[:, j], X_expected)\n                assert_almost_equal(lmbda, pt.lambdas_[j])\n\n            # Test inverse transformation\n            X_inv = pt.inverse_transform(X_trans)\n            assert_array_almost_equal(X_inv, X)\n\n        assert len(pt.lambdas_) == X.shape[1]\n        assert isinstance(pt.lambdas_, np.ndarray)\n"], "sample_908": ["def test_unparse_arguments():\n    source = \"def func(a, b=1, *args, c=2, **kwargs): pass\"\n    expected = \"a, b=1, *args, c=2, **kwargs\"\n    module = ast.parse(source)\n    assert ast.unparse_arguments(module.body[0].args) == expected\n"], "sample_1060": ["def test_issue_14283_additional():\n    prntr = PythonCodePrinter()\n\n    assert prntr.doprint(oo) == \"float('inf')\"\n"], "sample_693": ["def test_do_cleanups_on_test_failure(pytester: Pytester) -> None:\n    testpath = pytester.makepyfile(\n        \"\"\"\n        import unittest\n        class MyTestCase(unittest.TestCase):\n            values = []\n                    self.values.append(1)\n                self.addCleanup(cleanup)\n                assert False\n                pass\n            assert MyTestCase.values == [1, 1]\n    \"\"\"\n    )\n    reprec = pytester.inline_run(testpath)\n    passed, skipped, failed = reprec.countoutcomes()\n    assert failed == 1\n    assert passed == 2\n"], "sample_488": ["    def test_get_registered_model(self):\n        \"\"\"\n        Tests apps.get_registered_model().\n        \"\"\"\n        model = apps.get_registered_model(\"apps\", \"TotallyNormal\")\n        self.assertEqual(model, TotallyNormal)\n\n        with self.assertRaises(LookupError):\n            apps.get_registered_model(\"apps\", \"SoAlternative\")\n\n        with self.assertRaises(LookupError):\n            apps.get_registered_model(\"nonexistent\", \"Model\")\n"], "sample_572": ["def test_bivariate_probability_stat_weights(self, x, y, weights):\n\n    h = Histogram(stat=\"probability\")\n    heights, _ = h(x, y, weights=weights)\n    assert heights.sum() == pytest.approx(1)\n"], "sample_416": ["def test_no_dbname_no_service(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env(\n            {\n                \"USER\": \"someuser\",\n                \"HOST\": \"somehost\",\n                \"PORT\": \"444\",\n            }\n        ),\n        (\n            [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"],\n            None,\n        ),\n    )\n"], "sample_1114": ["def test_issue_18146():\n    e = Symbol('e', integer=True, even=True)\n    o = Symbol('o', integer=True, odd=True)\n    assert Range(5).contains(i) == And(i >= 0, i <= 4)\n    assert Range(1).contains(i) == Eq(i, 0)\n    assert Range(-oo, 5, 1).contains(i) == (i <= 4)\n    assert Range(-oo, oo).contains(i) == True\n    assert Range(0, 8, 2).contains(i) == Contains(i, Range(0, 8, 2))\n    assert Range(0, 8, 2).contains(e) == And(e >= 0, e <= 6)\n    assert Range(0, 8, 2).contains(2*i) == And(2*i >= 0, 2*i <= 6)\n    assert Range(0, 8, 2).contains(o) == False\n    assert Range(1, 9, 2).contains(e) == False\n    assert Range(1, 9, 2).contains(o) == And(o >= 1, o <= 7)\n    assert Range(8, 0, -2).contains(o) == False\n    assert Range(9, 1, -2).contains(o) == And(o >= 3, o <= 9)\n    assert Range(-oo, 8, 2).contains(i) == Contains(i, Range(-oo, 8, 2))\n"], "sample_5": ["def test_models_evaluate_with_units_param_array_broadcasting(model):\n\n    if not HAS_SCIPY and model['class'] in SCIPY_MODELS:\n        pytest.skip()\n\n    params = {}\n    for key, value in model['parameters'].items():\n        if value is None or key == 'degree':\n            params[key] = value\n        else:\n            params[key] = np.repeat(value, 2)\n\n    params['n_models'] = 2\n\n    m = model['class'](**params)\n\n    for args in model['evaluation']:\n        if len(args) == 2:\n            x, y = args\n            x_arr = u.Quantity([x, x], subok=True)\n            result = m(x_arr)\n            assert_quantity_allclose(result, u.Quantity([y, y], subok=True))\n\n            # Test broadcasting\n            result = m(x)\n            assert_quantity_allclose(result, u.Quantity([y, y]))\n        else:\n            x, y, z = args\n            x_arr = u.Quantity([x, x])\n            y_arr = u.Quantity([y, y])\n            result = m(x_arr, y_arr)\n            assert_quantity_allclose(result, u.Quantity([z, z]))\n\n            # Test broadcasting\n            result = m(x, y)\n            assert_quantity_allclose(result, u.Quantity([z, z]))\n"], "sample_1029": ["def test_Cycle():\n    from sympy import Cycle\n    c = Cycle(1, 2, 3)\n    sT(c, \"Cycle((1, 2, 3))\")\n"], "sample_738": ["def test_vectorizer_custom_analyzer():\n        return s.split(' ')\n\n    vect = CountVectorizer(analyzer=custom_analyzer)\n    X = vect.fit_transform(['hello world', 'hello hello']).toarray()\n    assert_array_equal(X.ravel(), [1, 1, 2])\n    assert_equal(vect.get_feature_names(), ['hello', 'world'])\n"], "sample_272": ["def test_minimize_rollbacks_unapplied_migration(self):\n    \"\"\"\n    Minimize rollbacks when target is an unapplied migration.\n\n    a: 1 <---- 3 <--\\\n              \\ \\- 2 <--- 4\n               \\       \\\n    b:      \\- 1 <--- 2\n    \"\"\"\n    a1_impl = FakeMigration('a1')\n    a1 = ('a', '1')\n    a2_impl = FakeMigration('a2')\n    a2 = ('a', '2')\n    a3_impl = FakeMigration('a3')\n    a3 = ('a', '3')\n    a4_impl = FakeMigration('a4')\n    a4 = ('a', '4')\n    b1_impl = FakeMigration('b1')\n    b1 = ('b', '1')\n    b2_impl = FakeMigration('b2')\n    b2 = ('b', '2')\n    graph = MigrationGraph()\n    graph.add_node(a1, a1_impl)\n    graph.add_node(a2, a2_impl)\n    graph.add_node(a3, a3_impl)\n    graph.add_node(a4, a4_impl)\n    graph.add_node(b1, b1_impl)\n    graph.add_node(b2, b2_impl)\n    graph.add_dependency(None, a2, a1)\n    graph.add_dependency(None, a3, a1)\n    graph.add_dependency(None, a4, a2)\n    graph.add_dependency(None, a4, a3)\n    graph.add_dependency(None, b2, b1)\n    graph.add_dependency(None, b1, a1)\n    graph.add_dependency(None, b2, a2)\n\n    executor = MigrationExecutor(None)\n    executor.loader = FakeLoader(graph, {\n        a1: a1_impl,\n        b1: b1_impl,\n        a2: a"], "sample_234": ["def test_union_with_empty_qs_and_ordering(self):\n    qs1 = Number.objects.all().order_by('num')\n    qs2 = Number.objects.none()\n    self.assertNumbersEqual(qs1.union(qs2).order_by('num'), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"], "sample_312": ["def test_add_squash(self):\n    node = Node(['a'], 'OR')\n    node.add(Node(['b'], 'OR'), 'OR')\n    self.assertEqual(node, Node(['a', 'b'], 'OR'))\n"], "sample_584": ["def test_auto_combine_with_no_dimension_coords(self):\n    objs = [Dataset({'foo': ('x', [0])}),\n            Dataset({'foo': ('x', [1])})]\n    with pytest.warns(FutureWarning, match=\"The datasets supplied do not have global dimension coordinates\"):\n        auto_combine(objs)\n"], "sample_1138": ["def test_as_f_sign_1():\n    assert as_f_sign_1(x + 1) == (1, x, 1)\n    assert as_f_sign_1(x - 1) == (1, x, -1)\n    assert as_f_sign_1(-x + 1) == (-1, x, -1)\n    assert as_f_sign_1(-x - 1) == (-1, x, 1)\n    assert as_f_sign_1(2*x + 2) == (2, x, 1)\n"], "sample_329": ["def test_serialize_deconstructible(self):\n    instance = DeconstructibleInstances()\n    self.assertSerializedEqual(instance)\n    self.assertSerializedResultEqual(\n        instance,\n        (\"migrations.test_writer.DeconstructibleInstances()\", {'import migrations.test_writer'})\n    )\n"], "sample_1170": ["def test_issue_21823_with_list():\n    assert str(Partition([1, 2, 2])) == 'Partition({1, 2})'\n    assert str(Partition({1, 2, 2})) == 'Partition({1, 2})'\n"], "sample_18": ["def test_binary_op_structured(self):\n    q2 = u.Quantity([(5.0, 6.0)], \"m, m/s\")\n    q = self.q + q2\n    assert_no_info(q)\n"], "sample_184": ["def test_unique_constraint_include_pointing_to_fk(self):\n    class Target(models.Model):\n        pass\n\n    class Model(models.Model):\n        fk_1 = models.ForeignKey(Target, models.CASCADE, related_name='target_1')\n        fk_2 = models.ForeignKey(Target, models.CASCADE, related_name='target_2')\n\n        class Meta:\n            constraints = [\n                models.UniqueConstraint(\n                    fields=['id'],\n                    include=['fk_1_id', 'fk_2'],\n                    name='name',\n                ),\n            ]\n\n    self.assertEqual(Model.check(databases=self.databases), [])\n"], "sample_39": ["def test_sip_with_altkey_relax():\n    \"\"\"\n    Test that when creating a WCS object using a key, CTYPE with\n    that key is looked at and not the primary CTYPE.\n    fix for #5443.\n    \"\"\"\n    with fits.open(get_pkg_data_filename('data/sip.fits')) as f:\n        w = wcs.WCS(f[0].header)\n    # create a header with two WCSs.\n    h1 = w.to_header(relax=True, key='A')\n    h2 = w.to_header(relax=False)\n    h1['CTYPE1A'] = \"RA---SIN-SIP\"\n    h1['CTYPE2A'] = \"DEC--SIN-SIP\"\n    h1.update(h2)\n    w = wcs.WCS(h1, key='A', relax=True)\n    assert (w.wcs.ctype == np.array(['RA---SIN-SIP', 'DEC--SIN-SIP'])).all()\n"], "sample_45": ["def test_trunc_func_with_timezone_and_output_field(self):\n    start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n    end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n    self.create_model(end_datetime, start_datetime)\n\n    melb = pytz.timezone('Australia/Melbourne')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=output_field, tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(melb), kind, melb).time() if output_field == TimeField() else truncate_to(start_datetime.astimezone(melb), kind, melb).date()),\n                (end_datetime, truncate_to(end_datetime.astimezone(melb), kind, melb).time() if output_field == TimeField() else truncate_to(end_datetime.astimezone(melb), kind, melb).date())\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_datetime_kind('day', DateField())\n    test_datetime_kind('hour', TimeField())\n"], "sample_686": ["def test_warning_captured_hook_is_deprecated(testdir) -> None:\n    \"\"\"Test that the pytest_warning_captured hook is deprecated.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import warnings\n\n            warnings.warn(\"This is a deprecated warning.\", DeprecationWarning)\n        \"\"\"\n    )\n\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: The pytest_warning_captured is deprecated*\",\n            \"*Please use pytest_warning_recorded instead.*\",\n        ]\n    )\n"], "sample_391": ["def test_create_model_add_index(self):\n    \"\"\"\n    AddIndex should optimize into CreateModel.\n    \"\"\"\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                \"Foo\", [(\"name\", models.CharField(max_length=255))]\n            ),\n            migrations.AddIndex(\n                \"Foo\",\n                models.Index(fields=[\"name\"], name=\"foo_name_idx\"),\n            ),\n        ],\n        [\n            migrations.CreateModel(\n                \"Foo\",\n                [(\"name\", models.CharField(max_length=255))],\n                options={\n                    \"indexes\": [\n                        models.Index(fields=[\"name\"], name=\"foo_name_idx\"),\n                    ],\n                },\n            ),\n        ],\n    )\n"], "sample_688": ["def test_collect_sub_with_symlinks_and_init(testdir):\n    \"\"\"Collection works with symlinked files, broken symlinks, and __init__.py\"\"\"\n    sub = testdir.mkdir(\"sub\")\n    sub.ensure(\"__init__.py\")\n    sub.join(\"test_file.py\").write(\"def test_file(): pass\")\n\n    # Create a broken symlink.\n    symlink_or_skip(\"test_doesnotexist.py\", sub.join(\"test_broken.py\"))\n\n    # Symlink that gets collected.\n    symlink_or_skip(\"test_file.py\", sub.join(\"test_symlink.py\"))\n\n    result = testdir.runpytest(\"-v\", str(sub))\n    result.stdout.fnmatch_lines(\n        [\n            \"sub/test_file.py::test_file PASSED*\",\n            \"sub/test_symlink.py::test_file PASSED*\",\n            \"*2 passed in*\",\n        ]\n    )\n"], "sample_888": ["def test_iforest_with_feature_names():\n    \"\"\"Test whether iforest handles feature names correctly\"\"\"\n\n    X = np.array([[1, 2], [3, 4]])\n    feature_names = [\"feature1\", \"feature2\"]\n    X_df = pd.DataFrame(X, columns=feature_names)\n\n    iforest = IsolationForest()\n    iforest.fit(X_df)\n\n    assert hasattr(iforest, \"feature_names_in_\")\n    assert_array_equal(iforest.feature_names_in_, feature_names)\n"], "sample_1148": ["def test_MatrixElement_diff_with_MatrixSymbol():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    expr = (A*B)[k, p]\n    dexpr = diff(expr, A[i, j])\n    assert dexpr == KroneckerDelta(k, i, (0, n-1))*B[j, p]\n"], "sample_802": ["def test_pipeline_memory_disabled():\n    X = np.array([[1, 2]])\n    pipe = Pipeline([('transf', Transf()), ('clf', Mult())], memory=None)\n    pipe.fit(X, y=None)\n    assert not hasattr(pipe.named_steps['transf'], 'means_')\n"], "sample_1089": ["def test_issue_8263_non_zero():\n    F, G = symbols('F, G', commutative=False, cls=Function)\n    x, y = symbols('x, y')\n    expr, dummies, _ = _mask_nc(F(x)*G(y) - F(x)*G(y))\n    assert expr.is_zero\n"], "sample_647": ["def test_unformatted_warning_format(pytester: Pytester) -> None:\n    \"\"\"Test the format method of UnformattedWarning.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        from _pytest.warning_types import UnformattedWarning, PytestWarning\n\n            warning = UnformattedWarning(PytestWarning, \"Test warning: {value}\")\n            formatted_warning = warning.format(value=\"example\")\n            assert str(formatted_warning) == \"Test warning: example\"\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1)\n"], "sample_359": ["def test_references_field_by_limit_choices_to(self):\n    operation = FieldOperation(\n        'Model', 'field', models.ForeignKey('Other', models.CASCADE, limit_choices_to={'field': 'value'})\n    )\n    self.assertIs(operation.references_field('Other', 'field', 'migrations'), True)\n    self.assertIs(operation.references_field('Other', 'whatever', 'migrations'), False)\n    self.assertIs(operation.references_field('Missing', 'whatever', 'migrations'), False)\n"], "sample_14": ["def test_angle_from_quantity():\n    \"\"\"\n    Test creating an Angle from a Quantity\n    \"\"\"\n    q = u.Quantity(54.12412, unit=u.degree)\n    a = Angle(q)\n    assert_allclose(a.degree, 54.12412)\n\n    q = u.Quantity(3.60827466667, unit=u.hour)\n    a = Angle(q)\n    assert_allclose(a.hour, 3.60827466667)\n\n    q = u.Quantity(0.944644098745, unit=u.radian)\n    a = Angle(q)\n    assert_allclose(a.radian, 0.944644098745)\n"], "sample_465": ["def test_inline_has_change_permission_uses_obj(self):\n    class ConcertInline(TabularInline):\n        model = Concert\n\n            return bool(obj)\n\n    class BandAdmin(ModelAdmin):\n        inlines = [ConcertInline]\n\n    ma = BandAdmin(Band, AdminSite())\n    request = MockRequest()\n    request.user = self.MockChangeUser()\n    self.assertEqual(ma.get_inline_instances(request), [])\n    band = Band(name=\"The Doors\", bio=\"\", sign_date=date(1965, 1, 1))\n    inline_instances = ma.get_inline_instances(request, band)\n    self.assertEqual(len(inline_instances), 1)\n    self.assertIsInstance(inline_instances[0], ConcertInline)\n"], "sample_273": ["def test_default_auto_field_setting_on_app_config(self):\n    class Model(models.Model):\n        pass\n\n    self.apps.get_app_config('check_framework').default_auto_field = 'django.db.models.BigAutoField'\n    self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n"], "sample_1050": ["def test_NumPyPrinter_relational():\n    p = NumPyPrinter()\n    assert p.doprint(x == y) == 'numpy.equal(x, y)'\n    assert p.doprint(x != y) == 'numpy.not_equal(x, y)'\n    assert p.doprint(x < y) == 'numpy.less(x, y)'\n    assert p.doprint(x <= y) == 'numpy.less_equal(x, y)'\n    assert p.doprint(x > y) == 'numpy.greater(x, y)'\n    assert p.doprint(x >= y) == 'numpy.greater_equal(x, y)'\n"], "sample_793": ["def test_iforest_contamination_auto():\n    # Test IsolationForest with contamination='auto'\n    X = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1], [6, 3], [-4, 7]]\n    clf = IsolationForest(behaviour='new', random_state=rng, contamination='auto')\n    clf.fit(X)\n    decision_func = -clf.decision_function(X)\n    pred = clf.predict(X)\n    # assert offset_ is -0.5\n    assert_equal(clf.offset_, -0.5)\n    # assert outliers are detected correctly\n    assert_greater(np.min(decision_func[-2:]), np.max(decision_func[:-2]))\n    assert_array_equal(pred, 6 * [1] + 2 * [-1])\n"], "sample_52": ["def test_modelchoicefield_limit_choices_to(self):\n    f = forms.ModelChoiceField(Category.objects.all(), limit_choices_to={'name__startswith': 'T'})\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c2.pk, 'A test'),\n        (self.c3.pk, 'Third'),\n    ])\n"], "sample_726": ["def test_label_binarize_multilabel_indicator_mismatch():\n    y = np.array([[0, 1, 0], [1, 1, 1], [0, 0, 0]])\n    classes = [0, 1]\n    assert_raises(ValueError, label_binarize, y, classes)\n"], "sample_1028": ["def test_issue_14392_complex():\n    assert (sin(zoo)*cos(zoo)).as_real_imag() == (nan, nan)\n"], "sample_441": ["    def test_integer_username(self):\n        data = {\n            \"username\": 1234567,\n            \"password1\": \"testclient\",\n            \"password2\": \"testclient\",\n        }\n        form = UserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        form.save()\n        self.assertEqual(form.cleaned_data[\"username\"], 1234567)\n"], "sample_521": ["def test_scatter_spiral_depthshade():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    th = np.linspace(0, 2 * np.pi * 6, 256)\n    sc = ax.scatter(np.sin(th), np.cos(th), th, s=(1 + th * 5), c=th ** 2, depthshade=False)\n    fig.canvas.draw()\n"], "sample_490": ["def test_validate_expression_custom_error(self):\n    constraint = models.UniqueConstraint(\n        Lower(\"name\"),\n        name=\"name_lower_uniq\",\n        violation_error_code=\"custom_code\",\n        violation_error_message=\"Custom message\",\n    )\n    msg = \"Custom message\"\n    with self.assertRaisesMessage(ValidationError, msg) as cm:\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=self.p1.name.upper()),\n        )\n    self.assertEqual(cm.exception.code, \"custom_code\")\n"], "sample_141": ["def test_helpful_error_message_for_many2many_invalid_type(self):\n    \"\"\"\n    Invalid type for many-to-many field value throws a helpful error message.\n    \"\"\"\n    test_string = \"\"\"[{\n        \"pk\": 1,\n        \"model\": \"serializers.m2mdata\",\n        \"fields\": {\"data\": \"invalid_type\"}\n    }]\"\"\"\n\n    expected = \"(serializers.m2mdata:pk=1) field_value was 'invalid_type'\"\n    with self.assertRaisesMessage(DeserializationError, expected):\n        next(serializers.deserialize('json', test_string, ignore=False))\n"], "sample_626": ["def test_getitem(indexes) -> None:\n    pd_idx = pd.Index([1, 2, 3])\n    expected = PandasIndex(pd_idx, \"x\", coord_dtype=np.int32)\n    actual = indexes[\"x\"][1:]\n\n    assert actual.index.equals(pd_idx[1:])\n    assert actual.dim == expected.dim\n    assert actual.coord_dtype == expected.coord_dtype\n"], "sample_204": ["def test_atomic(self):\n    \"\"\"\n    Makes sure the loader uses Migration.atomic.\n    \"\"\"\n    # Load and test the plan\n    migration_loader = MigrationLoader(connection)\n    self.assertEqual(\n        migration_loader.graph.forwards_plan((\"migrations\", \"0002_second\")),\n        [\n            (\"migrations\", \"0001_initial\"),\n            (\"migrations\", \"0002_second\"),\n        ],\n    )\n    # Check atomic attribute of migrations\n    migration_1 = migration_loader.get_migration(\"migrations\", \"0001_initial\")\n    migration_2 = migration_loader.get_migration(\"migrations\", \"0002_second\")\n    self.assertTrue(migration_1.atomic)\n    self.assertFalse(migration_2.atomic)\n"], "sample_984": ["def test_HadamardProduct():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    assert str(A .* B) == 'A.*B'\n"], "sample_422": ["def test_foreignkey_forward(self):\n    authors = Author.objects.order_by(\"name\")\n    with self.assertNumQueries(3):\n        books = list(\n            Book.objects.prefetch_related(\n                Prefetch(\"first_book__authors\", authors),\n                Prefetch(\"first_book__authors\", authors[1:], to_attr=\"authors_sliced\"),\n            )\n        )\n    for book in books:\n        with self.subTest(book=book):\n            self.assertEqual(book.authors_sliced, list(book.first_book.authors.all())[1:])\n"], "sample_1100": ["def test_divmod_with_symbols():\n    x, y = symbols('x y')\n    assert divmod(x, y) == (floor(x/y), x % y)\n    assert divmod(x, 3) == (floor(x/3), x % 3)\n    assert divmod(3, x) == (floor(3/x), 3 % x)\n"], "sample_226": ["    def test_non_migrated_app(self):\n        # serialize_db_to_string() skips non-migrated apps.\n        with self.settings(TEST_NON_SERIALIZED_APPS=['backends']):\n            data = connection.creation.serialize_db_to_string()\n        self.assertEqual(data, '[]')\n"], "sample_727": ["def test_imputation_invalid_strategy():\n    # Test imputation with an invalid strategy\n    X = np.array([[1, 2], [np.nan, 3], [7, 6]])\n    imputer = Imputer(missing_values=np.nan, strategy=\"invalid_strategy\")\n    assert_raises(ValueError, imputer.fit, X)\n"], "sample_855": ["def test_dummy_classifier_sparse_target_prediction_error():\n    X = [[0]] * 5  # ignored\n    y = sp.csc_matrix(np.array([[2, 1],\n                                [2, 2],\n                                [1, 4],\n                                [4, 2],\n                                [1, 1]]))\n\n    clf = DummyClassifier(strategy=\"uniform\", random_state=0)\n    clf.fit(X, y)\n\n    X = [[0]] * 500\n    with pytest.raises(ValueError, match=\"Sparse target prediction is not supported with the uniform strategy\"):\n        clf.predict(X)\n"], "sample_953": ["def test_quickstart_with_existing_master_file(tempdir):\n    (tempdir / 'master.rst').write_text('Existing master file')\n    answers = {\n        'Root path': tempdir,\n        'Project name': 'Sphinx Test',\n        'Author name': 'Georg Brandl',\n        'Project version': '0.1',\n        'Name of your master document': 'master',\n        'Please enter a new file name, or rename the existing file and press Enter': 'new_master',\n    }\n    qs.term_input = mock_input(answers)\n    d = {}\n    qs.ask_user(d)\n    qs.generate(d)\n\n    assert (tempdir / 'master.rst').isfile()\n    assert (tempdir / 'new_master.rst').isfile()\n"], "sample_1062": ["def test_TR15_16_17():\n    assert TR15(1 - 1/sin(x)**2) == -cot(x)**2\n    assert TR16(1 - 1/cos(x)**2) == -tan(x)**2\n    assert TR111(1 - 1/tan(x)**2) == 1 - cot(x)**2\n"], "sample_300": ["def test_filter_conditional_transform(self):\n    query = Query(Author, alias_cols=False)\n    with register_lookup(CharField, Lower):\n        where = query.build_where(Func(Lower('name'), output_field=BooleanField()))\n    exact = where.children[0]\n    self.assertIsInstance(exact, Exact)\n    self.assertIsInstance(exact.lhs, Func)\n    self.assertIsInstance(exact.lhs.source_expressions[0], Lower)\n    self.assertIsInstance(exact.lhs.source_expressions[0].source_expressions[0], Col)\n    self.assertIsNone(exact.lhs.source_expressions[0].source_expressions[0].alias)\n    self.assertEqual(exact.lhs.source_expressions[0].source_expressions[0].target, Author._meta.get_field('name'))\n    self.assertIs(exact.rhs, True)\n"], "sample_1045": ["def test_Float_floor_ceiling():\n    a = Float('1.23')\n    b = Float('-1.23')\n\n    assert(a.floor() == Float('1.0'))\n    assert(a.ceiling() == Float('2.0'))\n    assert(b.floor() == Float('-2.0'))\n    assert(b.ceiling() == Float('-1.0'))\n"], "sample_1071": ["def test_convert_to_incompatible_units():\n    assert convert_to(meter, second) == meter\n    assert convert_to(second, meter) == second\n"], "sample_467": ["def test_render_with_attrs(self):\n    widget = SelectDateWidget(years=(\"2014\",), attrs={\"class\": \"custom-class\"})\n    self.assertInHTML(\n        '<select name=\"mydate_year\" id=\"id_mydate_year\" class=\"custom-class\">',\n        widget.render(\"mydate\", \"\"),\n    )\n"], "sample_593": ["def test_repr_of_dataarray_with_attrs(dataarray):\n    dataarray.attrs[\"description\"] = \"Test data.\"\n    formatted = fh.array_repr(dataarray)\n    # attrs have an item so they'll be enabled and collapsed\n    assert (\n        formatted.count(\"class='xr-section-summary-in' type='checkbox'  checked>\") == 1\n    )\n    assert \"description\" in formatted\n    assert \"Test data.\" in formatted\n"], "sample_712": ["def test_one_hot_encoder_specified_categories_wrong_shape():\n    X = np.array([['a', 'b'], ['c', 'd']], dtype=object)\n    enc = OneHotEncoder(categories=[['a', 'b', 'c']])\n    with pytest.raises(ValueError, match=\"Shape mismatch: if n_values is an array, it has to be of shape \\\\(n_features,\\\\).\"):\n        enc.fit_transform(X)\n"], "sample_108": ["def test_converter_with_custom_to_url(self):\n    @DynamicConverter.register_to_url\n        return value.upper()\n\n    url = reverse('dynamic', kwargs={'value': 'hello'})\n    self.assertEqual(url, '/dynamic/HELLO/')\n"], "sample_531": ["def test_figure_pickle_with_device_pixel_ratio():\n    fig = Figure(dpi=42)\n    fig.canvas._set_device_pixel_ratio(7)\n    assert fig.dpi == 42*7\n    fig2 = pickle.loads(pickle.dumps(fig))\n    assert fig2.dpi == 42*7\n"], "sample_928": ["def test_heading(app):\n    env = Environment()\n    env.language = 'en'\n    assert heading(env, 'Test Heading', 1) == 'Test Heading\\n==========='\n    assert heading(env, 'Test Heading', 2) == 'Test Heading\\n-----------'\n    assert heading(env, 'Test Heading', 3) == 'Test Heading\\n~~~~~~~~~~~'\n    env.language = 'ja'\n    assert heading(env, '\u30c6\u30b9\u30c8\u898b\u51fa\u3057', 1) == '\u30c6\u30b9\u30c8\u898b\u51fa\u3057\\n============'\n"], "sample_590": ["def test_concat_positions(self):\n    ds1 = Dataset({\"foo\": (\"x\", [1, 2])}, {\"x\": [0, 1]})\n    ds2 = Dataset({\"foo\": (\"x\", [3, 4])}, {\"x\": [2, 3]})\n    expected = Dataset({\"foo\": (\"x\", [1, 2, 3, 4])}, {\"x\": [0, 1, 2, 3]})\n    actual = concat([ds1, ds2], dim=\"x\", positions=[[0, 1], [2, 3]])\n    assert_identical(actual, expected)\n"], "sample_550": ["def test_interactive_zoom_with_twinx():\n    fig, ax1 = plt.subplots()\n    ax2 = ax1.twinx()\n    ax1.plot(np.arange(10), np.arange(10))\n    ax2.plot(np.arange(10), np.arange(10, 20))\n\n    # Mouse from x=2 to x=6 (data coordinates, \"d\").\n    d0 = (2, 0.5)\n    d1 = (6, 0.5)\n    # Convert to screen coordinates (\"s\").  Events are defined only with pixel\n    # precision, so round the pixel values, and below, check against the\n    # corresponding xdata/ydata, which are close but not equal to d0/d1.\n    s0 = ax1.transData.transform(d0).astype(int)\n    s1 = ax1.transData.transform(d1).astype(int)\n\n    # Zoom in.\n    start_event = MouseEvent(\n        \"button_press_event\", fig.canvas, *s0, MouseButton.LEFT)\n    fig.canvas.callbacks.process(start_event.name, start_event)\n    stop_event = MouseEvent(\n        \"button_release_event\", fig.canvas, *s1, MouseButton.LEFT)\n    fig.canvas.callbacks.process(stop_event.name, stop_event)\n    assert ax1.get_xlim() == (start_event.xdata, stop_event.xdata)\n    assert ax2.get_xlim() == (0, 10)  # Should not change.\n\n    # Zoom out.\n    start_event = MouseEvent(\n        \"button_press_event\", fig.canvas, *s1, MouseButton.RIGHT)\n    fig.canvas.callbacks.process(start_event.name, start_event)\n    stop_event = MouseEvent(\n        \"button_release_event\", fig.canvas, *s0, MouseButton.RIGHT)\n    fig.canvas.callbacks.process(stop_event.name, stop_event"], "sample_1151": ["def test_issue_17130_complex_numbers():\n    e = Add(I, -I, b, -b, evaluate=False)\n    assert e.is_zero is True\n"], "sample_1099": ["def test_eval_partial_derivative_expr2():\n\n    tau, alpha, beta = symbols(\"tau alpha beta\")\n\n    # this is another special expression\n    # tested: vector derivative\n    # tested: scalar derivative\n    # tested: tensor derivative\n    base_expr2 = B(i)*H(-i, j) + B(i)*B(-i)*B(j) + tau**beta*B(j)\n\n    tensor_derivative = PartialDerivative(base_expr2, H(k, m))._perform_derivative()\n    vector_derivative = PartialDerivative(base_expr2, B(k))._perform_derivative()\n    scalar_derivative = PartialDerivative(base_expr2, tau)._perform_derivative()\n\n    assert (tensor_derivative - B(L_0)*L.metric(-L_0, -L_1)*L.delta(L_1, -k)*L.delta(j, -m)) == 0\n\n    assert (vector_derivative - (tau**beta*L.delta(j, -k) +\n        L.delta(L_0, -k)*B(-L_0)*B(j) +\n        B(L_0)*L.metric(-L_0, -L_1)*L.delta(L_1, -k)*B(j) +\n        B(L_0)*B(-L_0)*L.delta(j, -k) +\n        L.delta(L_0, -k)*H(-L_0, j))).expand() == 0\n\n    assert (vector_derivative.contract_metric(L.metric).contract_delta(L.delta) -\n        (tau**beta*L.delta(j, -k) + B(L_0)*B(-L_0)*L.delta(j, -k) + H(-k, j) + 2*B(j)*B(-k))).expand() == 0\n\n    assert scalar_derivative - beta*1/tau*tau**beta*B(j) == 0\n"], "sample_863": ["def test_pipeline_fit_params_with_intermediate_steps():\n    # tests that Pipeline passes fit_params to intermediate steps\n    # when fit is invoked\n    pipe = Pipeline([('transf', TransfFitParams()), ('clf', FitParamT())])\n    pipe.fit(X=None,\n             y=None,\n             transf__should_get_this=True,\n             clf__should_succeed=True)\n    assert pipe.named_steps['transf'].fit_params['should_get_this']\n    assert pipe.named_steps['clf'].successful\n    assert 'should_succeed' not in pipe.named_steps['transf'].fit_params\n"], "sample_206": ["def test_file_equality(self):\n    \"\"\"\n    FileField should be equal to a File object with the same name.\n    \"\"\"\n    d = Document(myfile='something.txt')\n    f = File(open('something.txt', 'rb'), name='something.txt')\n    self.assertEqual(d.myfile, f)\n"], "sample_532": ["def test_contour_invalid_levels():\n    fig, ax = plt.subplots()\n    data = [[0, 1], [1, 0]]\n    with pytest.raises(ValueError, match=r\"Contour levels must be increasing\"):\n        ax.contour(Z=data, levels=[2, 1])\n"], "sample_566": ["def test_subfigures_wspace_hspace_with_floats():\n    sub_figs = plt.figure().subfigures(2, 3, hspace=0.5, wspace=1/6., width_ratios=[1.5, 1, 2])\n\n    w = 640\n    h = 480\n\n    np.testing.assert_allclose(sub_figs[0, 0].bbox.min, [0., h * 0.6])\n    np.testing.assert_allclose(sub_figs[0, 0].bbox.max, [w * 0.375, h])\n\n    np.testing.assert_allclose(sub_figs[0, 1].bbox.min, [w * 0.425, h * 0.6])\n    np.testing.assert_allclose(sub_figs[0, 1].bbox.max, [w * 0.625, h])\n\n    np.testing.assert_allclose(sub_figs[0, 2].bbox.min, [w * 0.625, h * 0.6])\n    np.testing.assert_allclose(sub_figs[0, 2].bbox.max, [w, h])\n\n    np.testing.assert_allclose(sub_figs[1, 0].bbox.min, [0, 0])\n    np.testing.assert_allclose(sub_figs[1, 0].bbox.max, [w * 0.375, h * 0.4])\n\n    np.testing.assert_allclose(sub_figs[1, 1].bbox.min, [w * 0.425, 0])\n    np.testing.assert_allclose(sub_figs[1, 1].bbox.max, [w * 0.625, h * 0.4])\n\n    np.testing.assert_allclose(sub_figs[1, 2].bbox.min, [w * 0.6"], "sample_990": ["def test_tanh_expansion():\n    x, y = symbols('x,y')\n    assert tanh(x+y).expand(trig=True) == (tanh(x) + tanh(y)) / (1 + tanh(x)*tanh(y))\n    assert tanh(2*x).expand(trig=True).expand() == 2*tanh(x) / (1 + tanh(x)**2)\n"], "sample_831": ["def test_plot_tree_gini_impurity(pyplot):\n    # Check correctness of export_graphviz for criterion = gini impurity\n    clf = DecisionTreeClassifier(max_depth=3,\n                                 min_samples_split=2,\n                                 criterion=\"gini\",\n                                 random_state=2)\n    clf.fit(X, y)\n\n    # Test export code\n    feature_names = ['first feat', 'sepal_width']\n    nodes = plot_tree(clf, feature_names=feature_names)\n    assert len(nodes) == 3\n    assert nodes[0].get_text() == (\"first feat <= 0.0\\ngini = 0.5\\n\"\n                                   \"samples = 6\\nvalue = [3, 3]\")\n    assert nodes[1].get_text() == \"gini = 0.0\\nsamples = 3\\nvalue = [3, 0]\"\n    assert nodes[2].get_text() == \"gini = 0.0\\nsamples = 3\\nvalue = [0, 3]\"\n"], "sample_8": ["def test_masked_array_from_masked_with_masked_values():\n    \"\"\"Check that we can initialize a MaskedArray with masked values.\"\"\"\n    np_ma = np.ma.MaskedArray(self.ma, mask=self.mb.mask)\n    assert type(np_ma) is np.ma.MaskedArray\n    assert type(np_ma.data) is self._data_cls\n    assert type(np_ma.mask) is np.ndarray\n    assert_array_equal(np_ma.data, self.a)\n    assert_array_equal(np_ma.mask, self.mb.mask)\n"], "sample_914": ["def test_unparse_assign(source, expected):\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].value) == expected\n"], "sample_161": ["def test_foreign_object_to_unique_field_with_unique_together(self):\n    class Person(models.Model):\n        country_id = models.IntegerField()\n        city_id = models.IntegerField()\n\n        class Meta:\n            unique_together = (('country_id', 'city_id'),)\n\n    class MMembership(models.Model):\n        person_country_id = models.IntegerField()\n        person_city_id = models.IntegerField()\n        person = models.ForeignObject(\n            Person,\n            on_delete=models.CASCADE,\n            from_fields=['person_country_id', 'person_city_id'],\n            to_fields=['country_id', 'city_id'],\n        )\n\n    field = MMembership._meta.get_field('person')\n    self.assertEqual(field.check(), [])\n"], "sample_504": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    data = np.arange(1200).reshape(30, 40)\n    levels = [0, 200, 400, 600, 800, 1000, 1200]\n    im = ax.contourf(data, levels=levels)\n    cbar = fig.colorbar(im)\n    cbar.set_alpha(0.5)\n    assert cbar.alpha == 0.5\n    cbar.set_alpha(None)\n    assert cbar.alpha is None\n"], "sample_1171": ["def test_issue_18081():\n    assert ImageSet(Lambda(n, n*log(2)), S.Integers).intersection(\n        S.Integers).dummy_eq(Intersection(ImageSet(\n        Lambda(n, n*log(2)), S.Integers), S.Integers))\n"], "sample_472": ["def test_paginator_with_custom_error_messages(self):\n    custom_messages = {\n        \"invalid_page\": \"Custom invalid page message\",\n        \"min_page\": \"Custom min page message\",\n        \"no_results\": \"Custom no results message\",\n    }\n    paginator = Paginator([1, 2, 3], 2, error_messages=custom_messages)\n    msg = \"Custom invalid page message\"\n    with self.assertRaisesMessage(PageNotAnInteger, msg):\n        paginator.validate_number(1.2)\n    msg = \"Custom min page message\"\n    with self.assertRaisesMessage(EmptyPage, msg):\n        paginator.validate_number(-1)\n    msg = \"Custom no results message\"\n    with self.assertRaisesMessage(EmptyPage, msg):\n        paginator.validate_number(3)\n"], "sample_898": ["def test_sample_weight_invariance_multilabel_indicator(n_samples=50, n_classes=3):\n    random_state = check_random_state(0)\n    y_true = random_state.randint(0, 2, size=(n_samples, n_classes))\n    y_pred = random_state.randint(0, 2, size=(n_samples, n_classes))\n    y_score = random_state.random_sample(size=(n_samples, n_classes))\n    for name in ALL_METRICS:\n        if name not in MULTILABELS_METRICS + THRESHOLDED_MULTILABEL_METRICS:\n            continue\n        if name in METRICS_WITHOUT_SAMPLE_WEIGHT:\n            continue\n        metric = ALL_METRICS[name]\n        if name in THRESHOLDED_METRICS:\n            yield check_sample_weight_invariance, name, metric, y_true, y_score\n        else:\n            yield check_sample_weight_invariance, name, metric, y_true, y_pred\n"], "sample_985": ["def test_eval_rewrite_as_Heaviside():\n    x, y, z = symbols('x y z')\n    assert Max(x, y)._eval_rewrite_as_Heaviside(x, y) == x*Heaviside(x - y) + y*Heaviside(y - x)\n    assert Max(x, y, z)._eval_rewrite_as_Heaviside(x, y, z) == x*Heaviside(x - y)*Heaviside(x - z) + y*Heaviside(y - x)*Heaviside(y - z) + z*Heaviside(z - x)*Heaviside(z - y)\n    assert Min(x, y)._eval_rewrite_as_Heaviside(x, y) == x*Heaviside(y - x) + y*Heaviside(x - y)\n    assert Min(x, y, z)._eval_rewrite_as_Heaviside(x, y, z) == x*Heaviside(x - y)*Heaviside(x - z) + y*Heaviside(y - x)*Heaviside(y - z) + z*Heaviside(z - x)*Heaviside(z - y)\n"], "sample_942": ["def test_pyfunction_signature_with_default_value(app):\n    text = \".. py:function:: hello(name='World') -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_operator, \"=\"],\n                                                      [nodes.inline, \"'World'\"])])\n"], "sample_818": ["def test_spectral_clustering_with_different_n_components():\n    # Test that spectral_clustering returns the correct number of clusters\n    # when n_components is different from n_clusters\n    X, y = make_blobs(n_samples=200, random_state=0,\n                      centers=[[1, 1], [-1, -1], [1, -1], [-1, 1]], cluster_std=0.6)\n    labels = spectral_clustering(X, n_clusters=4, n_components=2, random_state=0)\n    assert len(np.unique(labels)) == 4\n"], "sample_435": ["    def test_password_validation(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\n            \"password1\": \"testclient\",  # same as username\n            \"password2\": \"testclient\",\n        }\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertIn(\n            \"The password is too similar to the username.\", form.errors[\"password2\"]\n        )\n        self.assertEqual(form.changed_data, [])\n"], "sample_1136": ["def test_issue_19579():\n    p = Poly(2 + 3*I, x, domain=ZZ_I)\n    q = Poly(1 - I, x, domain=ZZ_I)\n    assert p.div(q, auto=False) == (Poly(0, x, domain='ZZ_I'), Poly(2 + 3*I, x, domain='ZZ_I'))\n    assert p.div(q, auto=True) == (Poly(-S(1)/2 + 5*I/2, x, domain='QQ_I'), Poly(0, x, domain='QQ_I'))\n"], "sample_705": ["def test_pytester_assert_outcomes_errors(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n            raise ValueError(\"some custom error\")\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(failed=1, errors=1)\n"], "sample_1047": ["def test_complex_reciprocal_real():\n    assert (1 / (4 - 3*I)).is_real is False\n"], "sample_1193": ["def test_are_coplanar():\n    from sympy.geometry import Plane\n\n    # Test with coplanar points\n    p1, p2, p3, p4 = Point3D(1, 2, 3), Point3D(4, 5, 6), Point3D(7, 8, 9), Point3D(10, 11, 12)\n    assert are_coplanar(p1, p2, p3, p4)\n\n    # Test with non-coplanar points\n    p5 = Point3D(13, 14, 15)\n    assert not are_coplanar(p1, p2, p3, p5)\n\n    # Test with a plane and coplanar points\n    plane = Plane(p1, p2, p3)\n    assert are_coplanar(plane, p4)\n\n    # Test with a plane and non-coplanar points\n    assert not are_coplanar(plane, p5)\n\n    # Test with collinear points\n    p6 = Point3D(2, 4, 6)\n    assert not are_coplanar(p1, p2, p6)\n\n    # Test with 2D entities\n    p7, p8 = Point2D(1, 2), Point2D(3, 4)\n    assert are_coplanar(p7, p8)\n\n    # Test with a mix of 2D and 3D entities\n    assert are_coplanar(p7, p8, p1)\n"], "sample_666": ["def test_encodedfile_readline(tmpfile: BinaryIO) -> None:\n    ef = capture.EncodedFile(tmpfile, encoding=\"utf-8\")\n    tmpfile.write(b\"line1\\nline2\\nline3\")\n    tmpfile.seek(0)\n    assert ef.readline() == \"line1\\n\"\n    assert ef.readline(4) == \"line\"\n    assert ef.readline() == \"2\\n\"\n    assert ef.readline() == \"line3\"\n    assert ef.readline() == \"\"\n    tmpfile.close()\n    with pytest.raises(ValueError):\n        ef.write(\"foo\")\n"], "sample_1115": ["def test_tensorhead_with_symmetry():\n    L = TensorIndexType(\"L\")\n    i, j = tensor_indices(\"i j\", L)\n    A = tensorhead('A', [L, L], symmetry=[(0, 1)])\n    assert A(i, j).symmetry == TensorSymmetry.fully_symmetric(2)\n"], "sample_466": ["def test_serialize_complex(self):\n    self.assertSerializedEqual(complex(1, 2))\n    self.assertSerializedResultEqual(\n        complex(1, 2),\n        (\"complex((1, 2))\", set()),\n    )\n"], "sample_486": ["def test_inlineformset_factory_nulls_default_pks_auto_parent_auto_child(self):\n    \"\"\"\n    #24958 - Variant of test_inlineformset_factory_nulls_default_pks for\n    the case of a parent object with an AutoField primary key and a child\n    object with an AutoField primary key.\n    \"\"\"\n    FormSet = inlineformset_factory(\n        AutoPKParent, AutoPKChildOfUUIDPKParent, fields=\"__all__\"\n    )\n    formset = FormSet()\n    self.assertIsNone(formset.forms[0].fields[\"parent\"].initial)\n"], "sample_403": ["def test_references_field_by_through_fields(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ManyToManyField(\"Other\", through_fields=(\"from\", \"to\")),\n    )\n    self.assertIs(operation.references_field(\"Model\", \"from\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Model\", \"to\", \"migrations\"), False)\n    self.assertIs(operation.references_field(\"Other\", \"from\", \"migrations\"), False)\n    self.assertIs(operation.references_field(\"Model\", \"to\", \"migrations\"), False)\n"], "sample_1140": ["def test_issue_18343():\n    assert pretty(Integral(x**2, (x, 0, 1))**2) == \\"], "sample_682": ["def test_marked_xfail_with_boolean_without_reason(self, testdir) -> None:\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(False)\n            pass\n    \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_xfail_marks(item)\n    assert excinfo.value.msg is not None\n    assert (\n        \"\"\"Error evaluating 'xfail': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n        in excinfo.value.msg\n    )\n"], "sample_679": ["def test_mark_evaluator_istrue_with_reason(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        from _pytest.nodes import Item\n        from _pytest.mark import MarkEvaluator\n\n        @pytest.mark.foo(reason=\"custom reason\")\n            pass\n\n            item = Item.from_parent(None, name=\"test_func\")\n            evaluator = MarkEvaluator(item, \"foo\")\n            assert evaluator.istrue()\n            assert evaluator.getexplanation() == \"custom reason\"\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=2)\n"], "sample_343": ["def test_get_object_cache_respects_updated_objects(self):\n    question = Question.objects.create(text='Who?')\n    post = Post.objects.create(title='Answer', parent=question)\n\n    question.text = 'Who updated?'\n    question.save()\n\n    post = Post.objects.get(pk=post.pk)\n    with self.assertNumQueries(1):\n        self.assertEqual(post.parent.text, 'Who updated?')\n        self.assertEqual(post.parent.text, 'Who updated?')\n"], "sample_1059": ["def test_assoc_laguerre():\n    n = Symbol(\"n\")\n    alpha = Symbol(\"alpha\")\n\n    assert assoc_laguerre(0, alpha, x) == 1\n    assert assoc_laguerre(1, alpha, x) == alpha - x + 1\n    assert assoc_laguerre(2, alpha, x) == alpha**2/2 + 3*alpha/2 + x**2/2 + x*(-alpha - 2) + 1\n\n    assert assoc_laguerre(n, 0, x) == laguerre(n, x)\n    assert assoc_laguerre(n, alpha, 0) == binomial(n + alpha, alpha)\n\n    assert diff(assoc_laguerre(n, alpha, x), x) == -assoc_laguerre(n - 1, alpha + 1, x)\n    assert diff(assoc_laguerre(n, alpha, x), alpha) == Sum(assoc_laguerre(_k, alpha, x)/(-alpha + n), (_k, 0, n - 1))\n\n    _k = Dummy('k')\n    assert assoc_laguerre(n, alpha, x).rewrite(\"polynomial\").dummy_eq(\n        gamma(n + alpha + 1)/factorial(n) * Sum(x**_k * RisingFactorial(-n, _k) / (gamma(_k + alpha + 1) * factorial(_k)), (_k, 0, n)))\n\n    assert conjugate(assoc_laguerre(n, alpha, x)) == assoc_laguerre(n, alpha.conjugate(), x.conjugate())\n\n    raises(ValueError, lambda: assoc_laguerre(-2.1, alpha, x))\n    raises(ValueError, lambda: assoc_laguerre(Rational(5, 2), alpha, x))\n    raises(ArgumentIndexError, lambda: assoc_laguerre(n, alpha, x).fdiff(1))\n    raises(ArgumentIndexError, lambda: assoc_laguerre(n, alpha"], "sample_142": ["def test_fieldsets_duplicate_fields(self):\n    \"\"\"\n    The fieldsets' fields must not contain duplicate fields.\n    \"\"\"\n    class DuplicateFieldsAdmin(admin.ModelAdmin):\n        fieldsets = [\n            (None, {\n                \"fields\": [\"title\", \"title\"]\n            }),\n        ]\n\n    errors = DuplicateFieldsAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"There are duplicate field(s) in 'fieldsets[0][1]'.\",\n            obj=DuplicateFieldsAdmin,\n            id='admin.E012',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_124": ["def test_field_deep_copy_widget(self):\n    class CustomTextInput(TextInput):\n            kwargs['attrs'] = {'class': 'custom-class'}\n            super().__init__(**kwargs)\n\n    field = CharField(widget=CustomTextInput())\n    field_copy = copy.deepcopy(field)\n    self.assertIsInstance(field_copy, CharField)\n    self.assertIsNot(field_copy.widget, field.widget)\n    self.assertIsInstance(field_copy.widget, CustomTextInput)\n    self.assertIsNot(field_copy.widget.attrs, field.widget.attrs)\n"], "sample_1011": ["def test_octave_user_functions():\n    f = Function('f')\n    g = Function('g')\n    custom_functions = {\n        \"f\": \"existing_octave_fcn\",\n        \"g\": [(lambda x: x.is_Matrix, \"my_mat_fcn\"),\n              (lambda x: not x.is_Matrix, \"my_fcn\")]\n    }\n    mat = Matrix([[1, x]])\n    assert mcode(f(x) + g(x) + g(mat), user_functions=custom_functions) == 'existing_octave_fcn(x) + my_fcn(x) + my_mat_fcn([1 x])'\n"], "sample_186": ["def test_check_list_display_links_not_in_list_display(self):\n    class SongAdmin(admin.ModelAdmin):\n        list_display = [\"pk\", \"title\"]\n        list_display_links = [\"album\"]\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'list_display_links[0]' refers to 'album', which is not defined in 'list_display'.\",\n            obj=SongAdmin,\n            id='admin.E111',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_409": ["def test_i18n_asvar_safestring_with_context(self):\n    context = {\"title\": \"<Main Title>\"}\n    output = self.engine.render_to_string(\"i18n_asvar_safestring_with_context\", context=context)\n    self.assertEqual(output, \"&lt;Main Title&gt;other text\")\n"], "sample_709": ["def test_pytester_assert_outcomes_deselected(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.skipif(True, reason=\"skipping this test\")\n            pass\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(skipped=1, deselected=1)\n"], "sample_362": ["def test_add_model_with_field_removed_from_base_model_with_m2m(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name and a ManyToManyField.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n            ('authors', models.ManyToManyField('app.Author')),\n        ], bases=('app.readable',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n"], "sample_659": ["def test_raises_with_raising_dunder_getattr(self):\n    \"\"\"Test current behavior with regard to exceptions via __getattr__ (#4284).\"\"\"\n\n    class CrappyGetattr(Exception):\n            assert False, \"via __getattr__\"\n\n    with pytest.raises(\n        Failed,\n        match=r\"DID NOT RAISE <class 'raises(\\..*)*CrappyGetattr'>\",\n    ):\n        pytest.raises(CrappyGetattr, lambda: None)\n"], "sample_74": ["def test_no_host_port(self):\n    self.assertEqual(\n        self._run_it({\n            'database': 'dbname',\n            'user': 'someuser',\n        }), (\n            ['psql', '-U', 'someuser', 'dbname'],\n            {},\n        )\n    )\n"], "sample_1180": ["def test_direction_cosine_direction_ratio():\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(2, 3, 5)\n    assert p1.direction_cosine(p2) == [sqrt(6)/6, sqrt(6)/6, sqrt(6)/3]\n    assert p1.direction_ratio(p2) == [1, 1, 2]\n"], "sample_385": ["def test_build_attrs_with_french_language(self):\n    form = AlbumForm()\n    attrs = form[\"band\"].field.widget.get_context(\n        name=\"my_field\", value=None, attrs={}\n    )[\"widget\"][\"attrs\"]\n    self.assertEqual(attrs[\"lang\"], \"fr\")\n"], "sample_631": ["def test_unused_variable_in_function(self):\n    node = astroid.extract_node(\n        \"\"\"\n            unused_var = 10\n        \"\"\"\n    )\n    with self.assertAddsMessages(\n        Message(\"unused-variable\", node=node[\"unused_var\"], args=\"unused_var\")\n    ):\n        self.checker.visit_module(node.root())\n        self.checker.visit_functiondef(node)\n        self.checker.leave_functiondef(node)\n"], "sample_919": ["def test_xref_consistency_for_texpr_role():\n        pattern = '<li><p>%s<code .*?><span .*?>%s</span></code></p></li>' % spec\n        res = re.search(pattern, text)\n        if not res:\n            print(\"Pattern\\n\\t%s\\nnot found in %s\" % (pattern, file))\n            assert False\n\n    f = 'roles.html'\n    t = (app.outdir / f).read_text()\n    texprPatterns = [\n        ('ref function without parens ', 'texpr_1'),\n        ('ref function with parens ', 'texpr_2()'),\n        ('ref function without parens, explicit title ', 'texpr_3_title'),\n        ('ref function with parens, explicit title ', 'texpr_4_title()'),\n        ('ref op call without parens ', r'texpr_5::operator\\(\\)'),\n        ('ref op call with parens ', r'texpr_6::operator\\(\\)()'),\n        ('ref op call without parens, explicit title ', 'texpr_7_title'),\n        ('ref op call with parens, explicit title ', 'texpr_8_title()')\n    ]\n\n    for s in texprPatterns:\n        check(s, t, f)\n"], "sample_967": ["def test_custom_mathjax_path(app, status, warning):\n    app.builder.build_all()\n\n    content = (app.outdir / 'index.html').read_text()\n    assert 'http://example.com/mathjax.js' in content\n"], "sample_318": ["    def test_urlpattern_resolve_with_converters(self):\n        test_urls = [\n            ('converter-int', '/converter/42/', {'arg': 42}),\n            ('converter-str', '/converter/foo/', {'arg': 'foo'}),\n            ('converter-slug', '/converter/foo-bar/', {'arg': 'foo-bar'}),\n            ('converter-uuid', '/converter/123e4567-e89b-12d3-a456-426614174000/', {'arg': '123e4567-e89b-12d3-a456-426614174000'}),\n        ]\n        for name, path, expected_kwargs in test_urls:\n            with self.subTest(name=name, path=path):\n                match = resolve(path)\n                self.assertEqual(match.kwargs, expected_kwargs)\n"], "sample_555": ["def test_arc_setters():\n    arc = Arc((0, 0), 1, 1, theta1=0, theta2=90)\n    arc.center = (0.5, 0.5)\n    arc.width = 1.5\n    arc.height = 0.5\n    arc.theta1 = 10\n    arc.theta2 = 20\n    arc.angle = 30\n    assert arc.center == (0.5, 0.5)\n    assert arc.width == 1.5\n    assert arc.height == 0.5\n    assert arc.theta1 == 10\n    assert arc.theta2 == 20\n    assert arc.angle == 30\n"], "sample_975": ["def test_nsolve_precision():\n    x = Symbol('x')\n    eq = Eq(x**2, 2)\n    sol = nsolve(eq, x, 1, prec=50)\n    assert abs(sol - mpf('1.4142135623730950488016887242096980785696718753769')) < 1e-50\n"], "sample_194": ["def test_opclasses_database_constraint(self):\n    UniqueConstraintProduct.objects.create(name='p1', color='red')\n    with self.assertRaises(IntegrityError):\n        UniqueConstraintProduct.objects.create(name='p1', color='Red')\n"], "sample_236": ["def test_fast_delete_with_select_related(self):\n    # The cascading fast-delete of SecondReferrer should not be affected\n    # by select_related() on the queryset.\n    origin = Origin.objects.create()\n    referer = Referrer.objects.create(origin=origin, unique_field=42)\n    with self.assertNumQueries(2):\n        Referrer.objects.select_related('origin').filter(pk=referer.pk).delete()\n"], "sample_443": ["def test_cache_versioning_touch(self):\n    cache.set(\"answer1\", 37, version=1)\n    cache.set(\"answer1\", 42, version=2)\n    self.assertIs(cache.touch(\"answer1\"), True)\n    self.assertEqual(cache.get(\"answer1\", version=1), 37)\n    self.assertEqual(cache.get(\"answer1\", version=2), 42)\n\n    cache.set(\"answer2\", 37, version=1)\n    cache.set(\"answer2\", 42, version=2)\n    self.assertIs(cache.touch(\"answer2\", version=2), True)\n    self.assertEqual(cache.get(\"answer2\", version=1), 37)\n    self.assertEqual(cache.get(\"answer2\", version=2), 42)\n\n    cache.set(\"answer3\", 37, version=1)\n    cache.set(\"answer3\", 42, version=2)\n    self.assertIs(caches[\"v2\"].touch(\"answer3\"), True)\n    self.assertEqual(cache.get(\"answer3\", version=1), 37)\n    self.assertEqual(cache.get(\"answer3\", version=2), 42)\n\n    cache.set(\"answer4\", 37, version=1)\n    cache.set(\"answer4\", 42, version=2)\n    self.assertIs(caches[\"v2\"].touch(\"answer4\", version=1), True)\n    self.assertEqual(cache.get(\"answer4\", version=1), 37)\n    self.assertEqual(cache.get(\"answer4\", version=2), 42)\n"], "sample_212": ["    def test_session_middleware(self):\n        request = HttpRequest()\n        response = HttpResponse()\n        middleware = SessionMiddleware(lambda r: response)\n\n        # Test process_request\n        middleware.process_request(request)\n        self.assertIsInstance(request.session, middleware.SessionStore)\n\n        # Test process_response\n        request.session.modified = True\n        request.session.accessed = True\n        request.session.save = lambda: None\n        response = middleware.process_response(request, response)\n        self.assertIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n        # Test process_response with empty session\n        request.session.clear()\n        response = middleware.process_response(request, response)\n        self.assertNotIn(settings.SESSION_COOKIE_NAME, response.cookies)\n"], "sample_297": ["    def test_ticket_24605_with_values(self):\n        \"\"\"\n        Subquery table names should be quoted when using values().\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(\n            Individual.objects.filter(Q(alive=False), Q(related_individual__isnull=True)).values('pk'),\n            [{'pk': i4.pk}]\n        )\n        self.assertSequenceEqual(\n            Individual.objects.exclude(Q(alive=False), Q(related_individual__isnull=True)).values('pk').order_by('pk'),\n            [{'pk': i1.pk}, {'pk': i2.pk}, {'pk': i3.pk}]\n        )\n"], "sample_156": ["def test_field_deep_copy_widget(self):\n    class CustomTextInput(TextInput):\n            kwargs['attrs'] = {'class': 'custom-class'}\n            super().__init__(**kwargs)\n\n    field = CharField(widget=CustomTextInput())\n    field_copy = copy.deepcopy(field)\n    self.assertIsInstance(field_copy, CharField)\n    self.assertIsNot(field_copy.widget, field.widget)\n    self.assertIsNot(field_copy.widget.attrs, field.widget.attrs)\n"], "sample_452": ["def test_references_field_by_through_fields(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ManyToManyField(\"Other\", through_fields=(\"from\", \"to\")),\n    )\n    self.assertIs(operation.references_field(\"Model\", \"from\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Model\", \"to\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Other\", \"from\", \"migrations\"), False)\n    self.assertIs(operation.references_field(\"Other\", \"to\", \"migrations\"), False)\n"], "sample_1120": ["def test_MatrixElement_diff_matrix():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    X = MatrixSymbol('X', n, n)\n    Y = MatrixSymbol('Y', l, l)\n\n    assert (A[0, 1]*B[1, 0]).diff(X) == ZeroMatrix(n, l)\n    assert (A[0, 1]*B[1, 0]).diff(Y) == ZeroMatrix(n, n)\n    assert (A[0, 1]*B[1, 0]).diff(A) == Matrix([[0, B[1, 0]], [0, 0]])\n    assert (A[0, 1]*B[1, 0]).diff(B) == Matrix([[0], [A[0, 1]]])\n"], "sample_34": ["def test_unit_division_with_string():\n    \"\"\"Check that division with strings produces the correct unit.\"\"\"\n    u1 = u.cm\n    us = 'kg'\n    assert u1 / us == u1 / u.Unit(us)\n"], "sample_368": ["def test_migrate_backward_to_replaced_migration(self):\n    executor = MigrationExecutor(connection)\n    try:\n        self.assertTableNotExists('migrations_author')\n        self.assertTableNotExists('migrations_book')\n        executor.migrate([('migrations', '0001_squashed_0002')])\n        self.assertTableExists('migrations_author')\n        self.assertTableExists('migrations_book')\n        executor.loader.build_graph()\n        # Migrate backward to a replaced migration.\n        executor.migrate([('migrations', '0001_initial')])\n        self.assertTableExists('migrations_author')\n        self.assertTableNotExists('migrations_book')\n    finally:\n        # Unmigrate everything.\n        executor = MigrationExecutor(connection)\n        executor.migrate([('migrations', None)])\n        self.assertTableNotExists('migrations_author')\n        self.assertTableNotExists('migrations_book')\n"], "sample_994": ["def test_Float_from_numpy():\n    from sympy.external import import_module\n    np = import_module('numpy')\n    if not np:\n        skip('numpy not installed. Abort numpy tests.')\n\n        x = Float(npval)\n        y = Float(ratval, precision=x._prec)\n        assert abs((x - y)/y) < 2**(-(x._prec + 1))\n\n    check_prec_and_relerr(np.float16(2/3), S(2)/3)\n    check_prec_and_relerr(np.float32(2/3), S(2)/3)\n    check_prec_and_relerr(np.float64(2/3), S(2)/3)\n    # extended precision, on some arch/compilers:\n    x = np.longdouble(2)/3\n    check_prec_and_relerr(x, S(2)/3)\n"], "sample_339": ["def test_modelformset_factory_with_custom_form_and_fields(self):\n    class CustomBookForm(forms.ModelForm):\n        class Meta:\n            model = Book\n            fields = ['title']\n\n    BookFormSet = modelformset_factory(Book, form=CustomBookForm)\n    formset = BookFormSet()\n    self.assertEqual(len(formset.forms), 1)\n    self.assertIn('title', formset.forms[0].fields)\n    self.assertNotIn('author', formset.forms[0].fields)\n"], "sample_598": ["def test_format_timedelta_out_of_bounds():\n    from datetime import timedelta\n\n    delta = timedelta(days=1000000)\n    expected = \"11574 days 00:00:00\"\n    result = formatting.format_timedelta(delta)\n    assert result == expected\n\n    delta = timedelta(days=-1000000)\n    expected = \"-11574 days +00:00:00\"\n    result = formatting.format_timedelta(delta)\n    assert result == expected\n"], "sample_396": ["    def test_ticket_24605_additional(self):\n        \"\"\"\n        Subquery table names should be quoted with additional filters.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(\n            Individual.objects.filter(\n                Q(alive=False), Q(related_individual__isnull=True), Q(pk=i4.pk)\n            ),\n            [i4],\n        )\n        self.assertSequenceEqual(\n            Individual.objects.exclude(\n                Q(alive=False), Q(related_individual__isnull=True), Q(pk=i4.pk)\n            ).order_by(\"pk\"),\n            [i1, i2, i3],\n        )\n"], "sample_998": ["def test_Quaternion_latex_printing_with_zero_components():\n    q = Quaternion(0, 0, 0, 0)\n    assert latex(q) == \"0\"\n    q = Quaternion(0, y, 0, 0)\n    assert latex(q) == \"y i\"\n    q = Quaternion(0, 0, z, 0)\n    assert latex(q) == \"z j\"\n    q = Quaternion(0, 0, 0, t)\n    assert latex(q) == \"t k\"\n"], "sample_1195": ["def test_gamma_trace_function():\n    i0, i1, i2, i3 = tensor_indices('i0:4', LorentzIndex)\n    p, q = tensor_heads('p, q', [LorentzIndex])\n    ps = p(i0)*G(-i0)\n    qs = q(i0)*G(-i0)\n\n    # Test gamma_trace function\n    assert _is_tensor_eq(gamma_trace(G(i0)*G(i1)), 4*LorentzIndex.metric(i0, i1))\n    assert _is_tensor_eq(gamma_trace(ps*ps), 4*p(i0)*p(-i0))\n    assert _is_tensor_eq(gamma_trace(ps*qs + ps*ps), 4*p(i0)*p(-i0) + 4*p(i0)*q(-i0))\n"], "sample_49": ["def test_media_ordering(self):\n    ###############################################################\n    # Media ordering\n    ###############################################################\n\n    # Media objects should preserve the order of CSS and JS files\n    class MyWidget1(TextInput):\n        class Media:\n            css = {\n                'all': ('path/to/css1', '/path/to/css2')\n            }\n            js = ('/path/to/js1', 'http://media.other.com/path/to/js2')\n\n    class MyWidget2(TextInput):\n        class Media:\n            css = {\n                'all': ('/path/to/css3',)\n            }\n            js = ('/path/to/js3',)\n\n    w1 = MyWidget1()\n    w2 = MyWidget2()\n    self.assertEqual(\n        str(w1.media + w2.media),\n        \"\"\"<link href=\"http://media.example.com/static/path/to/css1\" type=\"text/css\" media=\"all\" rel=\"stylesheet\">"], "sample_987": ["def test_evalf_complex_accuracy():\n    assert complex_accuracy((from_float(2.0), from_float(10.0), 35, 100)) == 37\n    assert complex_accuracy((from_float(2.0), from_float(1000.0), 35, 100)) == 43\n    assert complex_accuracy((from_float(2.0), from_float(10.0), 100, 35)) == 35\n    assert complex_accuracy((from_float(2.0), from_float(1000.0), 100, 35)) == 35\n"], "sample_542": ["def test_text_rotation_mode():\n    fig, ax = plt.subplots()\n    text = ax.text(0.5, 0.5, 'test', rotation=30, rotation_mode='anchor')\n    fig.canvas.draw()\n    assert text.get_rotation_mode() == 'anchor'\n    assert text.get_rotation() == 30\n\n    text.set_rotation_mode('default')\n    fig.canvas.draw()\n    assert text.get_rotation_mode() == 'default'\n    assert text.get_rotation() == 30\n"], "sample_334": ["def test_field_deep_copy_widget(self):\n    class CustomTextInput(TextInput):\n            kwargs['attrs'] = {'class': 'custom-class'}\n            super().__init__(**kwargs)\n\n    field = CharField(widget=CustomTextInput())\n    field_copy = copy.deepcopy(field)\n    self.assertIsInstance(field_copy, CharField)\n    self.assertIsNot(field_copy.widget, field.widget)\n    self.assertIsInstance(field_copy.widget, CustomTextInput)\n    self.assertIsNot(field_copy.widget.attrs, field.widget.attrs)\n"], "sample_835": ["def test_adaboost_classifier_feature_importances():\n    # Test feature importances for AdaBoostClassifier\n    X, y = datasets.make_classification(n_samples=100, n_features=10, n_informative=5, random_state=42)\n    clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n    clf.fit(X, y)\n    importances = clf.feature_importances_\n    assert len(importances) == 10\n    assert np.all(importances >= 0)\n    assert np.sum(importances) > 0\n"], "sample_305": ["def test_annotate_with_f_expression(self):\n    # Test annotate with F expression\n    qs = Book.objects.annotate(discounted_price=F('price') * 0.9)\n    book = qs.get(pk=self.b1.pk)\n    self.assertEqual(book.discounted_price, Decimal('27.00'))\n"], "sample_964": ["def test_pyfunction_with_positional_only_arguments(app):\n    text = \".. py:function:: hello(a, /, b)\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, ([desc_parameter, desc_sig_name, \"a\"],\n                                      [desc_parameter, desc_sig_operator, \"/\"],\n                                      [desc_parameter, desc_sig_name, \"b\"])])\n"], "sample_774": ["def test_one_hot_encoder_drop_first():\n    enc = OneHotEncoder(drop='first')\n    X = [['abc', 12, 2, 55],\n         ['def', 12, 1, 55],\n         ['def', 12, 3, 56]]\n    trans = enc.fit_transform(X).toarray()\n    exp = [[0, 1, 1],\n           [1, 0, 1],\n           [1, 1, 0]]\n    assert_array_equal(trans, exp)\n    dropped_cats = [cat[feature]\n                    for cat, feature in zip(enc.categories_,\n                                            enc.drop_idx_)]\n    assert_array_equal(dropped_cats, ['abc', 12, 2, 55])\n    assert_array_equal(np.array(X, dtype=object),\n                       enc.inverse_transform(trans))\n"], "sample_946": ["def test_pyfunction_with_default_value(app):\n    text = \".. py:function:: hello(name='World') -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, ([desc_parameter, ([desc_sig_name, \"name\"],\n                                                        [desc_sig_operator, \"=\"],\n                                                        [nodes.inline, \"'World'\"])])])\n"], "sample_962": ["def test_restify_mock_decorator():\n    with mock(['decorator']):\n        import decorator\n        @decorator.decorator\n            return f(*args, **kwargs)\n\n        assert restify(func) == ':py:func:`decorator.decorator<func>`'\n"], "sample_1013": ["def test_lambdify_with_custom_module():\n    # Test for issue 14655 (custom module part)\n    custom_module = {'sin': lambda x: x}\n    f = lambdify(x, sin(x), custom_module)\n    assert f(2) == 2\n"], "sample_459": ["def test_integerfield_float_rounding(self):\n    instance = self.model(value=1.5)\n    instance.full_clean()\n    instance.save()\n    qs = self.model.objects.filter(value__gte=2)\n    self.assertEqual(qs.count(), 1)\n    self.assertEqual(qs[0].value, 2)\n"], "sample_527": ["def test_interactive_zoom_with_scroll():\n    fig, ax = plt.subplots()\n    ax.plot([0, 1], [0, 1])\n    assert ax.get_navigate_mode() is None\n\n    xlim0 = ax.get_xlim()\n    ylim0 = ax.get_ylim()\n\n    # Zoom in with scroll.\n    scroll_event = MouseEvent(\"scroll_event\", fig.canvas, 0, 0, step=1)\n    fig.canvas.callbacks.process(scroll_event.name, scroll_event)\n    assert ax.get_xlim() != xlim0\n    assert ax.get_ylim() != ylim0\n\n    # Zoom out with scroll.\n    scroll_event = MouseEvent(\"scroll_event\", fig.canvas, 0, 0, step=-1)\n    fig.canvas.callbacks.process(scroll_event.name, scroll_event)\n    assert ax.get_xlim() == pytest.approx(xlim0, rel=0, abs=1e-10)\n    assert ax.get_ylim() == pytest.approx(ylim0, rel=0, abs=1e-10)\n"], "sample_786": ["def test_transform_invalid_n_features():\n    est = KBinsDiscretizer(n_bins=[2, 3, 3, 3], encode='ordinal').fit(X)\n    bad_X = np.arange(12).reshape(3, -1)\n    assert_raise_message(ValueError,\n                         \"Incorrect number of features. Expecting 4, \"\n                         \"received 3\", est.transform, bad_X)\n"], "sample_387": ["def test_ForeignKey_with_custom_to_field(self):\n    from selenium.webdriver.common.by import By\n\n    self.admin_login(username=\"super\", password=\"secret\", login_url=\"/\")\n    self.selenium.get(\n        self.live_server_url + reverse(\"admin:admin_widgets_album_add\")\n    )\n    main_window = self.selenium.current_window_handle\n\n    # No value has been selected yet\n    self.assertEqual(\n        self.selenium.find_element(By.ID, \"id_band\").get_attribute(\"value\"), \"\"\n    )\n\n    # Open the popup window and click on a band\n    self.selenium.find_element(By.ID, \"lookup_id_band\").click()\n    self.wait_for_and_switch_to_popup()\n    link = self.selenium.find_element(By.LINK_TEXT, \"Bogey Blues\")\n    self.assertIn(\"/band/42/\", link.get_attribute(\"href\"))\n    link.click()\n\n    # The field now contains the selected band's uuid\n    self.selenium.switch_to.window(main_window)\n    self.wait_for_value(\"#id_band\", str(Band.objects.get(id=42).uuid))\n"], "sample_669": ["def test_encodedfile_write_bytes(tmpfile: BinaryIO) -> None:\n    ef = capture.EncodedFile(tmpfile, encoding=\"utf-8\")\n    ef.write(b\"hello\")\n    ef.flush()\n    tmpfile.seek(0)\n    assert tmpfile.read() == b\"hello\"\n    tmpfile.close()\n    with pytest.raises(ValueError):\n        ef.read()\n"], "sample_27": ["def test_fitsdiff_with_different_ver(tmp_path):\n    \"\"\"Make sure diff report reports HDU ver if different in files\"\"\"\n    path1 = tmp_path / \"test1.fits\"\n    path2 = tmp_path / \"test2.fits\"\n\n    hdulist = HDUList([PrimaryHDU(), ImageHDU(data=np.zeros(5), name=\"SCI\", ver=1)])\n    hdulist.writeto(path1)\n    hdulist[1].ver = 2\n    hdulist.writeto(path2)\n\n    diff = FITSDiff(path1, path2)\n    assert \"Extension HDU 1 (SCI, 2):\" in diff.report()\n"], "sample_673": ["def test_doctest_module_with_setup_py(self, testdir):\n    testdir.makepyfile(\n        setup=\"\"\"\n        from setuptools import setup\n        setup(name='sample', version='0.0', description='description')\n        \"\"\",\n        test_module=\"\"\"\n            '''\n            >>> test_func()\n            'test'\n            '''\n            return 'test'\n        \"\"\"\n    )\n    result = testdir.runpytest(\"--doctest-modules\")\n    result.stdout.fnmatch_lines([\"*collected 1 item*\"])\n"], "sample_710": ["def test_do_cleanups_on_test_failure(pytester: Pytester) -> None:\n    testpath = pytester.makepyfile(\n        \"\"\"\n        import unittest\n        class MyTestCase(unittest.TestCase):\n            values = []\n                    self.values.append(1)\n                self.addCleanup(cleanup)\n                assert False\n                pass\n            assert MyTestCase.values == [1, 1]\n    \"\"\"\n    )\n    reprec = pytester.inline_run(testpath)\n    passed, skipped, failed = reprec.countoutcomes()\n    assert failed == 1\n    assert passed == 2\n"], "sample_834": ["def test_transform_before_fit():\n    # Test that transform raises an error if fit has not been called\n    nca = NeighborhoodComponentsAnalysis()\n    X = iris_data\n    assert_raises(NotFittedError, nca.transform, X)\n"], "sample_678": ["def test_ensure_deletable(tmp_path):\n    \"\"\"Ensure that ensure_deletable returns True if lock does not exist.\"\"\"\n    path = tmp_path / \"temp-1\"\n    path.mkdir()\n    assert ensure_deletable(path, 0) is True\n\n    lock_path = get_lock_path(path)\n    lock_path.touch()\n    assert ensure_deletable(path, 0) is False\n\n    os.utime(str(lock_path), (0, 0))\n    assert ensure_deletable(path, 1) is True\n    assert not lock_path.exists()\n"], "sample_635": ["def test_finds_missing_raises_in_setter_google(self) -> None:\n    \"\"\"Example of a setter having missing raises documentation in\n    its own Google style docstring\n    \"\"\"\n    setter_node, node = astroid.extract_node(\n        \"\"\"\n    class Foo(object):\n        @property\n            '''int: docstring ...\n\n            Raises:\n                RuntimeError: Always\n            '''\n            raise RuntimeError()\n            return 10\n\n        @foo.setter\n            '''setter docstring ...\n\n            Returns:\n                None\n            '''\n            raise AttributeError() #@\n    \"\"\"\n    )\n    with self.assertAddsMessages(\n        MessageTest(\n            msg_id=\"missing-raises-doc\", node=setter_node, args=(\"AttributeError\",)\n        )\n    ):\n        self.checker.visit_raise(node)\n"], "sample_1156": ["def test_sinh_nonnegative():\n    k = symbols('k', real=True)\n    n = symbols('n', integer=True)\n\n    assert sinh(k, evaluate=False).is_nonnegative is None\n    assert sinh(k + 2*n*pi*I, evaluate=False).is_nonnegative is None\n    assert sinh(I*pi/2, evaluate=False).is_nonnegative is True\n    assert sinh(3*I*pi/2, evaluate=False).is_nonnegative is False\n    assert sinh(S.Zero, evaluate=False).is_nonnegative is True\n"], "sample_741": ["def test_grid_search_cv_splits_consistency_with_groups():\n    # Check if a one time iterable is accepted as a cv parameter with groups.\n    n_samples = 100\n    n_splits = 5\n    X, y = make_classification(n_samples=n_samples, random_state=0)\n    groups = np.random.randint(0, 3, n_samples)\n\n    gs = GridSearchCV(LinearSVC(random_state=0),\n                      param_grid={'C': [0.1, 0.2, 0.3]},\n                      cv=GroupKFold(n_splits=n_splits))\n    gs.fit(X, y, groups=groups)\n\n    gs2 = GridSearchCV(LinearSVC(random_state=0),\n                       param_grid={'C': [0.1, 0.2, 0.3]},\n                       cv=LeaveOneGroupOut())\n    gs2.fit(X, y, groups=groups)\n\n    # Check if the splits are consistent\n    np.testing.assert_equal(_pop_time_keys(gs.cv_results_),\n                            _pop_time_keys(gs2.cv_results_))\n"], "sample_434": ["    def test_dispatch_with_allowed_method(self):\n        request_factory = RequestFactory()\n        view = SyncView()\n        view.setup(request_factory.get(\"/\"))\n        response = view.dispatch(request_factory.get(\"/\"))\n        self.assertIsInstance(response, HttpResponse)\n        self.assertEqual(response.content, b\"Hello (sync) world!\")\n"], "sample_529": ["def test_legend_markers_from_line2d_with_different_colors():\n    # Test that markers can be copied for legend lines with different colors (#17960)\n    _markers = ['.', '*', 'v']\n    _colors = ['r', 'g', 'b']\n    fig, ax = plt.subplots()\n    lines = [mlines.Line2D([0], [0], ls='None', marker=mark, color=col)\n             for mark, col in zip(_markers, _colors)]\n    labels = [\"foo\", \"bar\", \"xyzzy\"]\n    markers = [line.get_marker() for line in lines]\n    colors = [line.get_color() for line in lines]\n    legend = ax.legend(lines, labels)\n\n    new_markers = [line.get_marker() for line in legend.get_lines()]\n    new_colors = [line.get_color() for line in legend.get_lines()]\n    new_labels = [text.get_text() for text in legend.get_texts()]\n\n    assert markers == new_markers == _markers\n    assert colors == new_colors == _colors\n    assert labels == new_labels\n"], "sample_1145": ["def test_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[0, 0], Q.symmetric(X)) == X[0, 0]\n    assert refine(X[1, 1], Q.symmetric(X)) == X[1, 1]\n"], "sample_602": ["def test_open_dataset_with_custom_engine():\n    expected = xr.Dataset(\n        dict(a=2 * np.arange(5)), coords=dict(x=(\"x\", np.arange(5), dict(units=\"s\")))\n    )\n\n    class CustomBackend(xr.backends.BackendEntrypoint):\n            filename_or_obj,\n            drop_variables=None,\n            **kwargs,\n        ):\n            return expected.copy(deep=True)\n\n    actual = xr.open_dataset(\"fake_filename\", engine=CustomBackend, decode_times=False)\n    assert_identical(expected, actual)\n"], "sample_1161": ["def test_ArraySymbol():\n    A = ArraySymbol('A', (3, 3))\n    assert str(A) == \"A\"\n"], "sample_70": ["def test_fast_delete_with_signals(self):\n    # Test that fast_delete still works when there are signals connected\n        pass\n    models.signals.post_delete.connect(noop, sender=User)\n    u = User.objects.create(\n        avatar=Avatar.objects.create()\n    )\n    a = Avatar.objects.get(pk=u.avatar_id)\n    # 1 query to fast-delete the user\n    # 1 query to delete the avatar\n    self.assertNumQueries(2, a.delete)\n    self.assertFalse(User.objects.exists())\n    self.assertFalse(Avatar.objects.exists())\n    models.signals.post_delete.disconnect(noop, sender=User)\n"], "sample_811": ["def test_check_preserve_type_sparse():\n    # Ensures that type float32 is preserved for sparse matrices.\n    XA = csr_matrix(np.resize(np.arange(40), (5, 8)).astype(np.float32))\n    XB = csr_matrix(np.resize(np.arange(40), (5, 8)).astype(np.float32))\n\n    XA_checked, XB_checked = check_pairwise_arrays(XA, None)\n    assert_equal(XA_checked.dtype, np.float32)\n\n    # both float32\n    XA_checked, XB_checked = check_pairwise_arrays(XA, XB)\n    assert_equal(XA_checked.dtype, np.float32)\n    assert_equal(XB_checked.dtype, np.float32)\n\n    # mismatched A\n    XA_checked, XB_checked = check_pairwise_arrays(XA.astype(np.float), XB)\n    assert_equal(XA_checked.dtype, np.float)\n    assert_equal(XB_checked.dtype, np.float)\n\n    # mismatched B\n    XA_checked, XB_checked = check_pairwise_arrays(XA, XB.astype(np.float))\n    assert_equal(XA_checked.dtype, np.float)\n    assert_equal(XB_checked.dtype, np.float)\n"], "sample_483": ["def test_check_fieldsets_duplicate_fields(self):\n    class MyModelAdmin(admin.ModelAdmin):\n        fieldsets = [\n            (None, {\"fields\": [\"title\", \"title\"]}),\n        ]\n\n    errors = MyModelAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"There are duplicate field(s) in 'fieldsets[0][1]'.\",\n            obj=MyModelAdmin,\n            id=\"admin.E012\",\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_10": ["def test_rename_columns_invalid_names_messages():\n    t = table.table_helpers.simple_table(1)\n    with pytest.raises(KeyError, match='column \"d\" does not exist'):\n        t.rename_columns(['c', 'd'], ['c', 'd2'])\n    with pytest.raises(KeyError,\n                       match='columns {\\'[de]\\', \\'[de]\\'} do not exist'):\n        t.rename_columns(['c', 'd', 'e'], ['c', 'd2', 'e2'])\n"], "sample_717": ["def test_load_fake_lfw_pairs():\n    lfw_pairs = fetch_lfw_pairs(subset='train', data_home=SCIKIT_LEARN_DATA,\n                                download_if_missing=False)\n\n    # The data is croped around the center as a rectangular bounding box\n    # around the face. Colors are converted to gray levels:\n    assert_equal(lfw_pairs.pairs.shape, (10, 2, 62, 47))\n    assert_equal(lfw_pairs.data.shape, (10, 2 * 62 * 47))\n\n    # the target is array of binary labels indicating whether the pair is of the same person or not\n    assert_array_equal(lfw_pairs.target, [1, 0, 1, 0, 1, 0, 1, 0, 0, 1])\n\n    # the target names are 'Different persons' and 'Same person'\n    assert_array_equal(lfw_pairs.target_names, ['Different persons', 'Same person'])\n\n    # It is possible to ask for the original data without any croping or color\n    # conversion\n    lfw_pairs = fetch_lfw_pairs(subset='train', data_home=SCIKIT_LEARN_DATA,\n                                resize=None, slice_=None, color=True,\n                                download_if_missing=False)\n    assert_equal(lfw_pairs.pairs.shape, (10, 2, 250, 250, 3))\n\n    # the labels and target names are the same as previously\n    assert_array_equal(lfw_pairs.target, [1, 0, 1, 0, 1, 0, 1, 0, 0, 1])\n    assert_array_equal(lfw_pairs.target_names, ['Different persons', 'Same person'])\n"], "sample_140": ["    def test_sensitive_variables_with_specified_variables(self):\n        @sensitive_variables('user', 'password')\n            password = user.password\n            return user, password\n\n        user = User()\n        user.password = 'secret'\n        _, password = test_func(user)\n        self.assertEqual(password, 'secret')\n        self.assertEqual(test_func.sensitive_variables, ('user', 'password'))\n"], "sample_971": ["def test_prefixed_warnings(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    with prefixed_warnings(\"prefix:\"):\n        logger.warning('message')\n        assert 'prefix: WARNING: message' in warning.getvalue()\n\n    # It also works during pending_warnings.\n    with logging.pending_warnings():\n        with prefixed_warnings(\"prefix:\"):\n            logger.warning('message')\n            assert 'prefix: WARNING: message' in warning.getvalue()\n"], "sample_382": ["def test_python_file_changed(self, mock_reset):\n    python_file_path = Path(__file__).parent / 'templates' / 'custom_filters.py'\n    self.assertIsNone(autoreload.template_changed(None, python_file_path))\n    mock_reset.assert_not_called()\n"], "sample_642": ["def test_init_hook_abbreviation(capsys: CaptureFixture) -> None:\n    \"\"\"Test that we correctly handle an abbreviated init-hook option.\"\"\"\n    with tempdir() as chroot:\n        with fake_home():\n            chroot_path = Path(chroot)\n            testutils.create_files([\"a/b/c/d/__init__.py\"])\n            os.chdir(chroot_path / \"a/b/c\")\n            with mock.patch(\"builtins.exec\") as mock_exec:\n                with pytest.raises(SystemExit):\n                    Run([\"--init-h\", \"import os\"])\n                mock_exec.assert_called_once_with(\"import os\")\n"], "sample_420": ["def test_setattr_raises_validation_error_non_field_specific(self):\n    \"\"\"\n    A model ValidationError using the dict form with a non-field error should\n    put the error message into __all__ (i.e. non-field errors) on the form.\n    \"\"\"\n    form_class = modelform_factory(model=StrictAssignmentNonFieldSpecific, fields=[\"title\"])\n    form = form_class(data={\"title\": \"testing setattr\"}, files=None)\n    # This line turns on the ValidationError; it avoids the model erroring\n    # when its own __init__() is called when creating form.instance.\n    form.instance._should_error = True\n    self.assertFalse(form.is_valid())\n    self.assertEqual(\n        form.errors,\n        {\n            \"__all__\": [\"Cannot set attribute\"],\n            \"title\": [\"This field cannot be blank.\"],\n        },\n    )\n"], "sample_31": ["def test_write_latex_no_latex_names(self, write, tmp_path, format):\n    \"\"\"Test to write a LaTeX file without latex_names\"\"\"\n    fp = tmp_path / \"test_write_latex_no_latex_names.tex\"\n    write(fp, format=format, latex_names=False)\n    tbl = QTable.read(fp)\n    # asserts each column name has not been renamed to LaTeX format\n    for column_name in tbl.colnames[2:]:\n        assert column_name not in _FORMAT_TABLE.values()\n"], "sample_64": ["    def test_redirect_with_query_params(self):\n        response = HttpResponseRedirect('/redirected/?param1=value1&param2=value2')\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response.url, '/redirected/?param1=value1&param2=value2')\n"], "sample_694": ["def test_argument_type_str_choice(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n            group = parser.getgroup(\"custom options\")\n            group.addoption(\n                \"--custom-option\",\n                type=\"str\",\n                choices=[\"choice1\", \"choice2\"],\n                help=\"Custom option with string type and choices\",\n            )\n        \"\"\"\n    )\n    result = pytester.runpytest(\"-Wdefault::pytest.PytestRemovedIn8Warning\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestRemovedIn8Warning: `type` argument to addoption() is the string 'str'.*\",\n            \"*For choices this is optional and can be omitted.*\",\n            \"*(options: --custom-option)*\",\n        ]\n    )\n"], "sample_159": ["    def test_method_fields_in_required_fields(self):\n        \"\"\"Method fields should not appear in REQUIRED_FIELDS.\"\"\"\n        class CustomUserMethodFields(AbstractBaseUser):\n            username = models.CharField(max_length=30, unique=True)\n            date_of_birth = models.DateField()\n\n            USERNAME_FIELD = 'username'\n            REQUIRED_FIELDS = ['get_full_name', 'date_of_birth']\n\n                return self.username\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The field named as a method 'get_full_name' for a custom user model \"\n                \"must not be included in 'REQUIRED_FIELDS'.\",\n                hint=(\n                    \"The 'get_full_name' is a method, you \"\n                    \"should remove 'get_full_name' from the 'REQUIRED_FIELDS'.\"\n                ),\n                obj=CustomUserMethodFields,\n                id='auth.E009',\n            ),\n        ])\n"], "sample_1082": ["def test_asinh_expansion():\n    x = Symbol('x')\n    assert asinh(x).expand(trig=True) == log(x + sqrt(x**2 + 1))\n    assert asinh(2*x).expand(trig=True) == log(2*x + sqrt(4*x**2 + 1))\n    assert asinh(3*x).expand(trig=True) == log(3*x + sqrt(9*x**2 + 1))\n"], "sample_848": ["def test_multi_output_classification_sample_weights_api():\n    X = [[1, 2, 3], [4, 5, 6]]\n    y = [[3, 2], [2, 3]]\n    w = [0.8, 0.6]\n\n    clf = MultiOutputClassifier(LogisticRegression())\n    assert_raises_regex(ValueError, \"does not support sample weights\",\n                        clf.fit, X, y, w)\n\n    # no exception should be raised if the base estimator supports weights\n    clf = MultiOutputClassifier(LogisticRegression(solver='liblinear'))\n    clf.fit(X, y, w)\n"], "sample_473": ["    def test_view_exception(self):\n        response = self.client.get(\"/exception/\")\n        self.assertEqual(response.status_code, 500)\n        self.assertIn(b\"Internal Server Error\", response.content)\n"], "sample_745": ["def test_function_transformer_sparse_input():\n    X_sparse = sparse.csr_matrix([[1, 0], [0, 1]])\n    F = FunctionTransformer(np.sqrt, accept_sparse=True)\n    X_transformed = F.transform(X_sparse)\n    assert sparse.issparse(X_transformed)\n    assert_array_equal(X_transformed.toarray(), np.sqrt(X_sparse.toarray()))\n"], "sample_1184": ["def test_beam_parameter_properties():\n    p = BeamParameter(530e-9, 1, w=1e-3)\n    assert p.q == 1 + 1.88679245283019*I*pi\n    assert N(p.q) == 1.0 + 5.92753330865999*I\n    assert p.w_0 == 0.00100000000000000\n    assert p.z_r == 5.92753330865999\n    fs = FreeSpace(10)\n    p1 = fs*p\n    assert N(p.w) == 0.00101413072159615\n    assert N(p1.w) == 0.00210803120913829\n"], "sample_360": ["def test_cache_versioning_touch(self):\n    cache.set('answer1', 37, version=1)\n    cache.set('answer1', 42, version=2)\n    self.assertIs(cache.touch('answer1'), True)\n    self.assertEqual(cache.get('answer1', version=1), 37)\n    self.assertEqual(cache.get('answer1', version=2), 42)\n\n    cache.set('answer2', 37, version=1)\n    cache.set('answer2', 42, version=2)\n    self.assertIs(cache.touch('answer2', version=2), True)\n    self.assertEqual(cache.get('answer2', version=1), 37)\n    self.assertEqual(cache.get('answer2', version=2), 42)\n\n    cache.set('answer3', 37, version=1)\n    cache.set('answer3', 42, version=2)\n    self.assertIs(caches['v2'].touch('answer3'), True)\n    self.assertEqual(cache.get('answer3', version=1), 37)\n    self.assertEqual(cache.get('answer3', version=2), 42)\n\n    cache.set('answer4', 37, version=1)\n    cache.set('answer4', 42, version=2)\n    self.assertIs(caches['v2'].touch('answer4', version=1), True)\n    self.assertEqual(cache.get('answer4', version=1), 37)\n    self.assertEqual(cache.get('answer4', version=2), 42)\n"], "sample_1143": ["def test_Float_floor_ceiling():\n    a = Float('3.7')\n    b = Float('-3.7')\n\n    assert a.floor() == Float('3.0')\n    assert a.ceiling() == Float('4.0')\n    assert b.floor() == Float('-4.0')\n    assert b.ceiling() == Float('-3.0')\n"], "sample_1009": ["def test_vector_applyfunc():\n    N = ReferenceFrame('N')\n    v = x*N.x + y*N.y + z*N.z\n    v_applied = v.applyfunc(sin)\n    assert v_applied == sin(x)*N.x + sin(y)*N.y + sin(z)*N.z\n"], "sample_250": ["def test_time_format_specifiers(self):\n    my_time = datetime(1984, 8, 7, 14, 30, 45)\n\n    self.assertEqual(dateformat.time_format(my_time, 'a'), 'p.m.')\n    self.assertEqual(dateformat.time_format(my_time, 'A'), 'PM')\n    self.assertEqual(dateformat.time_format(my_time, 'f'), '2:30')\n    self.assertEqual(dateformat.time_format(my_time, 'g'), '2')\n    self.assertEqual(dateformat.time_format(my_time, 'G'), '14')\n    self.assertEqual(dateformat.time_format(my_time, 'h'), '02')\n    self.assertEqual(dateformat.time_format(my_time, 'H'), '14')\n    self.assertEqual(dateformat.time_format(my_time, 'i'), '30')\n    self.assertEqual(dateformat.time_format(my_time, 'P'), '2:30 p.m.')\n    self.assertEqual(dateformat.time_format(my_time, 's'), '45')\n    self.assertEqual(dateformat.time_format(my_time, 'u'), '000000')\n"], "sample_3": ["def test_masked_vals_in_array_subtypes_with_strings():\n    \"\"\"Test null values in fixed and variable array subtypes with strings.\"\"\"\n    t = Table()\n    t['f'] = np.ma.array([['a', 'b'], ['c', 'd']], mask=[[0, 1], [1, 0]], dtype='<U1')\n    t['v'] = np.empty(2, dtype=object)\n    t['v'][0] = np.ma.array(['a', 'b'], mask=[0, 1], dtype='<U1')\n    t['v'][1] = np.ma.array(['c', 'd', 'e'], mask=[1, 0, 0], dtype='<U1')\n\n    out = StringIO()\n    t.write(out, format='ascii.ecsv')\n    txt = \"\"\"\n    # %ECSV 1.0\n    # ---\n    # datatype:\n    # - {name: f, datatype: string, subtype: 'string[2]'}\n    # - {name: v, datatype: string, subtype: 'string[null]'}\n    # schema: astropy-2.0\n    f v\n    [\"a\",\"null\"] [\"a\",\"null\"]\n    [\"null\",\"d\"] [\"null\",\"d\",\"e\"]\n    \"\"\"\n    hdr = _get_ecsv_header_dict(out.getvalue())\n    hdr_exp = _get_ecsv_header_dict(txt)\n    assert hdr == hdr_exp\n    t2 = Table.read(out.getvalue(), format='ascii.ecsv')\n    assert t2.colnames == t.colnames\n    for name in t2.colnames:\n        assert t2[name].dtype == t[name].dtype\n        assert type(t2[name]) is type(t[name])\n        for val1, val2 in zip(t2[name], t[name]):\n            if isinstance(val1, np.ndarray):\n                assert val1.dtype == val2.dtype\n            if isinstance(val1, np.ma.MaskedArray):\n               "], "sample_570": ["def test_bivariate_probability_stat_weights(self, x, y, weights):\n\n    h = Histogram(stat=\"probability\")\n    heights, _ = h(x, y, weights=weights)\n    assert heights.sum() == pytest.approx(1)\n"], "sample_797": ["def test_power_transformer_sparse_input(method, standardize):\n    # check that PowerTransformer works with sparse input\n    X = sparse.csr_matrix(X_1col)\n    if method == 'box-cox':\n        X.data = np.abs(X.data)\n\n    pt = PowerTransformer(method, standardize)\n    X_trans = pt.fit_transform(X)\n    assert sparse.issparse(X_trans)\n    assert_array_almost_equal(X_trans.toarray(), pt.transform(X.toarray()))\n\n    X_inv_trans = pt.inverse_transform(X_trans)\n    assert sparse.issparse(X_inv_trans)\n    assert_array_almost_equal(X_inv_trans.toarray(), pt.inverse_transform(X_trans.toarray()))\n"], "sample_530": ["def test_offsetbox_get_children():\n    # Test the get_children method of OffsetBox\n    ob = OffsetBox()\n    child1 = OffsetBox()\n    child2 = OffsetBox()\n    ob._children = [child1, child2]\n    assert ob.get_children() == [child1, child2]\n"], "sample_996": ["def test_issue_14036_simplification():\n    a, n = symbols('a n')\n    p = product(1 - a**2 / (n*pi)**2, [n, 1, oo])\n    simplified_p = simplify(p)\n    assert simplified_p == sin(pi*a)\n"], "sample_901": ["def test_k_means_empty_cluster_relocated_sparse():\n    # check that empty clusters are correctly relocated when using sample\n    # weights with sparse data (#13486)\n    X = sp.csr_matrix([[-1], [1]])\n    sample_weight = [1.9, 0.1]\n    init = np.array([[-1], [10]])\n\n    km = KMeans(n_clusters=2, init=init, n_init=1)\n    km.fit(X, sample_weight=sample_weight)\n\n    assert len(set(km.labels_)) == 2\n    assert_allclose(km.cluster_centers_, [[-1], [1]])\n"], "sample_1137": ["def test_issue_14932_with_units():\n    assert (log(inch) - log(2*inch)).simplify() == log(S.Half)\n    assert (log(inch) - log(foot/12)).simplify() == 0\n    p = symbols('p', positive=True)\n    assert (log(inch) - log(p*inch)).simplify() == log(1/p)\n"], "sample_285": ["def test_dirs_contains_nonexistent_path(self):\n    self.assertEqual(check_finders(None), [\n        Warning(\n            \"The directory '/nonexistent/path' in the STATICFILES_DIRS setting \"\n            \"does not exist.\",\n            id='staticfiles.W004',\n        )\n    ])\n"], "sample_1150": ["def test_issue_18146():\n    e = Symbol('e', integer=True, even=True)\n    o = Symbol('o', integer=True, odd=True)\n    assert Range(5).contains(i) == And(i >= 0, i <= 4)\n    assert Range(1, 9, 2).contains(o) == And(o >= 1, o <= 7)\n    assert Range(8, 0, -2).contains(o) == False\n    assert Range(9, 1, -2).contains(o) == And(o >= 3, o <= 9)\n    assert Range(-oo, 8, 2).contains(i) == Contains(i, Range(-oo, 8, 2))\n"], "sample_492": ["def test_serialize_complex(self):\n    complex_num = complex(1, 2)\n    self.assertSerializedEqual(complex_num)\n    self.assertSerializedResultEqual(\n        complex_num,\n        (\"complex('1+2j')\", set()),\n    )\n"], "sample_940": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n    @singledispatch\n        pass\n\n    @func.register(int)\n        pass\n\n    assert inspect.is_singledispatch_function(func) is True\n    assert inspect.is_singledispatch_function(func.register) is False\n\n        pass\n\n    assert inspect.is_singledispatch_function(not_singledispatch) is False\n"], "sample_1176": ["def test_Float_floor_ceiling():\n    a = Float(3.7)\n    b = Float(3.2)\n\n    assert a.floor() == 3\n    assert a.ceiling() == 4\n    assert b.floor() == 3\n    assert b.ceiling() == 4\n"], "sample_254": ["def test_inline_formset_error_message(self):\n    self.admin_login(username='super', password='secret')\n    self.selenium.get(self.live_server_url + reverse('admin:admin_inlines_holder5_add'))\n    self.wait_until_visible('#id_dummy')\n    self.selenium.find_element_by_id('id_dummy').send_keys(1)\n    fields = ['id_inner5stacked_set-0-dummy', 'id_inner5tabular_set-0-dummy']\n    show_links = self.selenium.find_elements_by_link_text('SHOW')\n    for show_index, field_name in enumerate(fields):\n        show_links[show_index].click()\n        self.wait_until_visible('#' + field_name)\n        self.selenium.find_element_by_id(field_name).send_keys(1)\n\n    self.selenium.find_element_by_xpath('//input[@value=\"Save\"]').click()\n\n    # Test the error messages for stacked and tabular inlines\n    stacked_error_message = self.selenium.find_element_by_css_selector('div#inner5stacked_set-group ul.errorlist li').text\n    self.assertEqual(stacked_error_message, 'Please correct the error below.')\n    tabular_error_message = self.selenium.find_element_by_css_selector('div#inner5tabular_set-group tr.row-form-errors ul.errorlist li').text\n    self.assertEqual(tabular_error_message, 'Please correct the error below.')\n"], "sample_665": ["def test_collect_sub_with_init_and_file(testdir):\n    sub = testdir.mkdir(\"sub\")\n    sub.ensure(\"__init__.py\").write(\"def test_init(): pass\")\n    sub.ensure(\"test_file.py\").write(\"def test_file(): pass\")\n\n    result = testdir.runpytest(\"-v\", str(sub))\n    result.stdout.fnmatch_lines(\n        [\n            \"sub/__init__.py::test_init PASSED*\",\n            \"sub/test_file.py::test_file PASSED*\",\n            \"*2 passed in*\",\n        ]\n    )\n"], "sample_57": ["    def test_integer_username(self):\n        data = {\n            'username': 1234567,\n            'password1': 'test123',\n            'password2': 'test123',\n        }\n        form = UserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        u = form.save()\n        self.assertEqual(u.username, 1234567)\n"], "sample_569": ["def test_regplot_color(self):\n\n    f, ax = plt.subplots()\n    color = 'r'\n    ax = lm.regplot(x=\"x\", y=\"y\", data=self.df, color=color)\n    assert ax.lines[0].get_color() == color\n    assert ax.collections[0].get_facecolors()[0, :3] == mpl.colors.to_rgb(color)\n"], "sample_482": ["def test_empty(self):\n    output = self.engine.render_to_string(\"escapeseq_empty\", {\"a\": []})\n    self.assertEqual(output, \"\")\n"], "sample_852": ["def test_make_classification_flip_y():\n    \"\"\"Test the flipping of labels in make_classification\"\"\"\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=5,\n                               n_redundant=1, n_repeated=1, n_classes=3,\n                               n_clusters_per_class=1, hypercube=False,\n                               shift=None, scale=None, flip_y=0.5,\n                               random_state=0)\n\n    assert X.shape == (100, 20), \"X shape mismatch\"\n    assert y.shape == (100,), \"y shape mismatch\"\n    assert np.unique(y).shape == (3,), \"Unexpected number of classes\"\n    assert sum(y == 0) > 0, \"Class #0 should have some samples\"\n    assert sum(y == 1) > 0, \"Class #1 should have some samples\"\n    assert sum(y == 2) > 0, \"Class #2 should have some samples\"\n    assert sum(y == 0) < 50, \"Class #0 should have less than 50 samples\"\n    assert sum(y == 1) < 50, \"Class #1 should have less than 50 samples\"\n    assert sum(y == 2) < 50, \"Class #2 should have less than 50 samples\"\n"], "sample_436": ["def test_custom_project_template_from_zip_by_path(self):\n    \"\"\"\n    The startproject management command is able to use a different project\n    template from a zip file.\n    \"\"\"\n    template_path = os.path.join(custom_templates_dir, \"project_template.zip\")\n    args = [\"startproject\", \"--template\", template_path, \"ziptestproject\"]\n    testproject_dir = os.path.join(self.test_dir, \"ziptestproject\")\n\n    out, err = self.run_django_admin(args)\n    self.assertNoOutput(err)\n    self.assertTrue(os.path.isdir(testproject_dir))\n    self.assertTrue(os.path.exists(os.path.join(testproject_dir, \"run.py\")))\n"], "sample_15": ["def test_radian_invalid_units(self, function):\n    with pytest.raises(TypeError):\n        function(3.0 * u.m, 2.0 * u.s, 1.0 * u.kg)\n"], "sample_534": ["def test_linestyles_iterable():\n    delta = 0.025\n    x = np.arange(-3.0, 3.0, delta)\n    y = np.arange(-2.0, 2.0, delta)\n    X, Y = np.meshgrid(x, y)\n    Z1 = np.exp(-X**2 - Y**2)\n    Z2 = np.exp(-(X - 1)**2 - (Y - 1)**2)\n    Z = (Z1 - Z2) * 2\n\n    # Iterable of linestyles\n    fig1, ax1 = plt.subplots()\n    CS1 = ax1.contour(X, Y, Z, 6, colors='k', linestyles=['solid', 'dashed'])\n    ax1.clabel(CS1, fontsize=9, inline=True)\n    ax1.set_title('Iterable of linestyles')\n    assert CS1.linestyles == ['solid', 'dashed']\n\n    # Ensure linestyles do not change when negative_linestyles is defined\n    fig2, ax2 = plt.subplots()\n    CS2 = ax2.contour(X, Y, Z, 6, colors='k', linestyles=['solid', 'dashed'],\n                      negative_linestyles='dashdot')\n    ax2.clabel(CS2, fontsize=9, inline=True)\n    ax2.set_title('Iterable of linestyles')\n    assert CS2.linestyles == ['solid', 'dashed']\n"], "sample_271": ["def test_extra_files(self, mocked_modules, notify_mock):\n    extra_file = self.ensure_file(self.tempdir / 'extra_file.py')\n    self.reloader.extra_files.add(extra_file)\n    with self.tick_twice():\n        self.increment_mtime(extra_file)\n    self.assertEqual(notify_mock.call_count, 1)\n    self.assertCountEqual(notify_mock.call_args[0], [extra_file])\n"], "sample_427": ["def test_formset_with_custom_renderer(self):\n    \"\"\"A custom renderer passed to a formset_factory() is passed to all forms and ErrorList.\"\"\"\n    from django.forms.renderers import Jinja2\n\n    renderer = Jinja2()\n    data = {\n        \"choices-TOTAL_FORMS\": \"2\",\n        \"choices-INITIAL_FORMS\": \"0\",\n        \"choices-MIN_NUM_FORMS\": \"0\",\n        \"choices-0-choice\": \"Zero\",\n        \"choices-0-votes\": \"0\",\n        \"choices-1-choice\": \"One\",\n        \"choices-1-votes\": \"1\",\n    }\n    ChoiceFormSet = formset_factory(Choice, renderer=renderer)\n    formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n    self.assertEqual(formset.renderer, renderer)\n    self.assertEqual(formset.forms[0].renderer, renderer)\n    self.assertEqual(formset.management_form.renderer, renderer)\n    self.assertEqual(formset.non_form_errors().renderer, renderer)\n    self.assertEqual(formset.empty_form.renderer, renderer)\n"], "sample_672": ["def test_broken_repr_on_newstyle():\n    \"\"\"saferepr() can create proper representations of classes with\n    broken __repr__ (#7145)\n    \"\"\"\n\n    class SomeClass:\n            raise RuntimeError\n\n    assert \"RuntimeError\" in saferepr(SomeClass())\n"], "sample_1066": ["def test_print_kronecker_delta():\n    assert mathml(KroneckerDelta(x, y), printer='presentation') == \\\n        '<mrow><mi>&#x3B4;</mi><mfenced><mi>x</mi><mi>y</mi></mfenced></mrow>'\n    assert mathml(KroneckerDelta(x, x), printer='presentation') == \\\n        '<mrow><mi>&#x3B4;</mi><mfenced><mi>x</mi><mi>x</mi></mfenced></mrow>'\n    assert mathml(KroneckerDelta(x, 0), printer='presentation') == \\\n        '<mrow><mi>&#x3B4;</mi><mfenced><mi>x</mi><mn>0</mn></mfenced></mrow>'\n    assert mathml(KroneckerDelta(0, x), printer='presentation') == \\\n        '<mrow><mi>&#x3B4;</mi><mfenced><mn>0</mn><mi>x</mi></mfenced></mrow>'\n"], "sample_1042": ["def test_Indexed_derivative_with_array():\n    from sympy import NDimArray\n    A = NDimArray([[1, 2], [3, 4]])\n    i, j = symbols('i j', integer=True)\n    A_indexed = Indexed(A, i, j)\n    assert A_indexed.diff(A[i, j]) == KroneckerDelta(i, i) * KroneckerDelta(j, j)\n    assert A_indexed.diff(A[i, j+1]) == KroneckerDelta(i, i) * KroneckerDelta(j, j+1)\n    assert A_indexed.diff(A[i+1, j]) == KroneckerDelta(i, i+1) * KroneckerDelta(j, j)\n"], "sample_1073": ["def test_sqrtdenest_rational_combination():\n    z = sqrt(1 + sqrt(3)) + sqrt(3 + 3*sqrt(3)) - sqrt(10 + 6*sqrt(3))\n    assert sqrtdenest(z) == 0\n"], "sample_1027": ["def test_Poly_as_expr():\n    p = Poly(x**2 - 2*x + 1, x)\n    assert p.as_expr() == x**2 - 2*x + 1\n\n    p = Poly(x**2 - 2*x + 1, x, domain='ZZ')\n    assert p.as_expr() == x**2 - 2*x + 1\n\n    p = Poly(x**2 - 2*x + 1, x, domain='QQ')\n    assert p.as_expr() == x**2 - 2*x + 1\n\n    p = Poly(x**2 - 2*x + 1, x, domain='RR')\n    assert p.as_expr() == x**2 - 2*x + 1\n\n    p = Poly(x**2 - 2*x + 1, x, domain='CC')\n    assert p.as_expr() == x**2 - 2*x + 1\n\n    p = Poly(x**2 - 2*x + 1, x, domain='EX')\n    assert p.as_expr() == x**2 - 2*x + 1\n"], "sample_394": ["def test_missing_slash_append_slash_true_non_staff_user_without_final_catch_all_view(self):\n    user = User.objects.create_user(\n        username=\"user\",\n        password=\"secret\",\n        email=\"user@example.com\",\n        is_staff=False,\n    )\n    self.client.force_login(user)\n    known_url = reverse(\"admin10:admin_views_article_changelist\")\n    response = self.client.get(known_url[:-1])\n    self.assertRedirects(\n        response,\n        \"/test_admin/admin10/login/?next=/test_admin/admin10/admin_views/article\",\n    )\n"], "sample_84": ["    def test_escape_leading_slashes(self):\n        self.assertEqual(escape_leading_slashes('//example.com'), '/%2Fexample.com')\n        self.assertEqual(escape_leading_slashes('http://example.com'), 'http://example.com')\n        self.assertEqual(escape_leading_slashes('/path'), '/path')\n"], "sample_192": ["def test_formset_with_deletion_and_empty_forms(self):\n    \"\"\"FormSets with deletion and empty forms.\"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_delete=True, extra=2)\n    initial = [{'choice': 'Calexico', 'votes': 100}, {'choice': 'Fergie', 'votes': 900}]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    data = {\n        'choices-TOTAL_FORMS': '4',  # the number of forms rendered\n        'choices-INITIAL_FORMS': '2',  # the number of forms with initial data\n        'choices-MIN_NUM_FORMS': '0',  # min number of forms\n        'choices-MAX_NUM_FORMS': '0',  # max number of forms\n        'choices-0-choice': 'Calexico',\n        'choices-0-votes': '100',\n        'choices-0-DELETE': '',\n        'choices-1-choice': 'Fergie',\n        'choices-1-votes': '900',\n        'choices-1-DELETE': 'on',\n        'choices-2-choice': '',\n        'choices-2-votes': '',\n        'choices-2-DELETE': '',\n        'choices-3-choice': '',\n        'choices-3-votes': '',\n        'choices-3-DELETE': '',\n    }\n    formset = ChoiceFormSet(data, auto_id=False, prefix='choices')\n    self.assertTrue(formset.is_valid())\n    self.assertEqual(\n        [form.cleaned_data for form in formset.forms],\n        [\n            {'votes': 100, 'DELETE': False, 'choice': 'Calexico'},\n            {'votes': 900, 'DELETE': True, 'choice': 'Fergie'},\n            {},\n            {},\n        ],\n    )\n    self.assertEqual(\n        [form.cleaned_data for form"], "sample_643": ["def test_colorize_ansi_with_message_style(recwarn: WarningsRecorder) -> None:\n    \"\"\"Test colorize_ansi function with MessageStyle parameter.\"\"\"\n    msg = \"Test message\"\n    msg_style = MessageStyle(\"red\", (\"bold\",))\n    result = colorize_ansi(msg, msg_style)\n    assert result == \"\\033[1;31mTest message\\033[0m\"\n    assert len(recwarn) == 0\n"], "sample_1040": ["def test_print_random_symbol():\n    X = RandomSymbol('X', Real)\n    assert mpp.doprint(X) == '<mi>X</mi>'\n    assert mp.doprint(X) == '<ci>X</ci>'\n"], "sample_581": ["def test_blueprint_url_defaults_override(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.route(\"/foo\", defaults={\"baz\": 42})\n        return f\"{bar}/{baz:d}\"\n\n    app.register_blueprint(bp, url_prefix=\"/1\", url_defaults={\"bar\": 23})\n    app.register_blueprint(bp, name=\"bp2\", url_prefix=\"/2\", url_defaults={\"bar\": 19, \"baz\": 50})\n\n    assert client.get(\"/1/foo\").data == b\"23/42\"\n    assert client.get(\"/2/foo\").data == b\"19/50\"\n"], "sample_993": ["def test_FreeGroupElm_subword():\n    w = x**5*y*x**2*y**-4*x\n    assert w.subword(2, 6) == x**3*y\n    assert w.subword(0, 0) == F.identity\n    assert w.subword(0, 1) == x**5\n    assert w.subword(3, 5) == x**2*y**-4\n    assert w.subword(5, 5) == F.identity\n"], "sample_187": ["def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('CamelCaseExample'), 'camel case example')\n    self.assertEqual(text.camel_case_to_spaces('AnotherExample'), 'another example')\n    self.assertEqual(text.camel_case_to_spaces('NoCamelCase'), 'no camel case')\n    self.assertEqual(text.camel_case_to_spaces(''), '')\n    self.assertEqual(text.camel_case_to_spaces('AllCaps'), 'all caps')\n    self.assertEqual(text.camel_case_to_spaces('lazystrExample'), 'lazystr example')\n"], "sample_103": ["def test_stddev_variance_aggregates(self):\n    books = Book.objects.aggregate(price_stddev=StdDev('price'), price_variance=Variance('price'))\n    self.assertIsInstance(books['price_stddev'], Decimal)\n    self.assertIsInstance(books['price_variance'], Decimal)\n\n    books = Book.objects.aggregate(price_stddev_sample=StdDev('price', sample=True), price_variance_sample=Variance('price', sample=True))\n    self.assertIsInstance(books['price_stddev_sample'], Decimal)\n    self.assertIsInstance(books['price_variance_sample'], Decimal)\n"], "sample_983": ["def test_sparse_matrix_scalar_multiply():\n    A = SparseMatrix([[1, 2], [3, 4]])\n    B = A.scalar_multiply(2)\n    assert B == SparseMatrix([[2, 4], [6, 8]])\n    B = A.scalar_multiply(0)\n    assert B == SparseMatrix([[0, 0], [0, 0]])\n"], "sample_60": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n"], "sample_1204": ["def test_coset_class_exceptions():\n    a = Permutation(1, 2)\n    b = Permutation(0, 1)\n    G = PermutationGroup([a, b])\n    H = PermutationGroup([a])\n    g = Permutation(0, 1, 2)\n    with pytest.raises(ValueError):\n        Coset(g, H, G, dir='+')\n    with pytest.raises(ValueError):\n        Coset(g, G, H, dir='+')\n    with pytest.raises(TypeError):\n        Coset(g, H, G, dir=1)\n    with pytest.raises(ValueError):\n        Coset(g, H, G, dir='*')\n"], "sample_432": ["def test_list_editable_with_invalid_data(self):\n    a = Swallow.objects.create(origin=\"Swallow A\", load=4, speed=1)\n    data = {\n        \"form-TOTAL_FORMS\": \"1\",\n        \"form-INITIAL_FORMS\": \"1\",\n        \"form-MIN_NUM_FORMS\": \"0\",\n        \"form-MAX_NUM_FORMS\": \"1000\",\n        \"form-0-uuid\": str(a.pk),\n        \"form-0-load\": \"invalid_data\",\n        \"_save\": \"Save\",\n    }\n    superuser = self._create_superuser(\"superuser\")\n    self.client.force_login(superuser)\n    changelist_url = reverse(\"admin:admin_changelist_swallow_changelist\")\n    response = self.client.post(changelist_url, data)\n    self.assertEqual(response.status_code, 200)\n    self.assertContains(response, \"Enter a number.\")\n    a.refresh_from_db()\n    self.assertEqual(a.load, 4)\n"], "sample_762": ["def test_get_params_deep_false():\n    # Test that get_params(deep=False) returns the correct parameters\n    test = T(K(c=1, d=2), K(c=3, d=4))\n    expected_params = {'a': K(c=1, d=2), 'b': K(c=3, d=4)}\n    assert_dict_equal(test.get_params(deep=False), expected_params)\n"], "sample_536": ["def test_polygon_selector_box_props(ax):\n    # Create a diamond shape\n    verts = [(20, 0), (0, 20), (20, 40), (40, 20)]\n    event_sequence = [\n        *polygon_place_vertex(*verts[0]),\n        *polygon_place_vertex(*verts[1]),\n        *polygon_place_vertex(*verts[2]),\n        *polygon_place_vertex(*verts[3]),\n        *polygon_place_vertex(*verts[0]),\n    ]\n\n    # Create selector with custom box props\n    tool = widgets.PolygonSelector(ax, onselect=noop, draw_bounding_box=True,\n                                   box_props=dict(facecolor='r', alpha=0.2),\n                                   box_handle_props=dict(alpha=0.5))\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n\n    # Check that box props were set correctly\n    assert tool._box._selection_artist.get_facecolor() == mcolors.to_rgba('r', alpha=0.2)\n    for artist in tool._box._handles_artists:\n        assert artist.get_alpha() == 0.5\n"], "sample_619": ["def test_decode_cf_datetime_uint64_with_cftime_out_of_bounds():\n    units = \"days since 1700-01-01\"\n    calendar = \"360_day\"\n    num_dates = np.uint64(182621)\n    with pytest.raises(OutOfBoundsDatetime):\n        decode_cf_datetime(num_dates, units, calendar)\n"], "sample_819": ["def test_transform_hard_voting():\n    \"\"\"Check transform method of VotingClassifier with hard voting on toy dataset.\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    X = np.array([[-1.1, -1.5], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n    y = np.array([1, 1, 2, 2])\n\n    eclf = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='hard').fit(X, y)\n\n    assert_array_equal(eclf.transform(X).shape, (4, 3))\n    assert_array_equal(eclf.transform(X), np.array([[1, 1, 1], [1, 1, 1], [2, 1, 2], [2, 2, 2]]))\n"], "sample_446": ["def test_large_numbers(self):\n    with localcontext() as ctx:\n        ctx.prec = 100\n        self.assertEqual(floatformat(1.2345678901234567890123456789, 20), \"1.23456789012345678901\")\n        self.assertEqual(floatformat(12345678901234567890123456789.123456789, 20), \"12345678901234567890123456789.1234567890\")\n"], "sample_350": ["def test_union_with_values_list_and_order_by_annotation(self):\n    qs1 = Number.objects.annotate(\n        annotation=Value(1),\n    ).filter(num__gte=6)\n    qs2 = Number.objects.annotate(\n        annotation=Value(2),\n    ).filter(num__lte=5)\n    self.assertSequenceEqual(\n        qs1.union(qs2).order_by('annotation', 'num').values_list('num', flat=True),\n        [6, 7, 8, 9, 0, 1, 2, 3, 4, 5],\n    )\n"], "sample_845": ["def test_vectorizer_max_df_min_df():\n    test_data = ['abc', 'dea', 'eat']\n    vect = CountVectorizer(analyzer='char', max_df=0.5, min_df=0.5)\n    vect.fit(test_data)\n    assert 'a' not in vect.vocabulary_.keys()  # {ae} ignored\n    assert len(vect.vocabulary_.keys()) == 2    # {bd} remain\n    assert 'a' in vect.stop_words_\n    assert 'c' in vect.stop_words_\n    assert len(vect.stop_words_) == 2\n"], "sample_484": ["def test_expression_length(self):\n    Author.objects.create(name=\"Jane Doe\", alias=\"doe\")\n    authors = Author.objects.annotate(name_part=Right(\"name\", Length(\"alias\") * 2))\n    self.assertQuerySetEqual(\n        authors.order_by(\"name\"),\n        [\"e Doe\", \"ne\"],\n        lambda a: a.name_part,\n    )\n"], "sample_81": ["    def test_match(self):\n        pattern = RoutePattern('foo/<int:pk>')\n        match = pattern.match('foo/123')\n        self.assertEqual(match, ('', (), {'pk': 123}))\n"], "sample_418": ["def test_length_is12(self):\n    output = self.engine.render_to_string(\"length_is12\", {\"mylist\": [1, 2, 3]})\n    self.assertEqual(output, \"Length is 3\")\n"], "sample_748": ["def test_grid_search_cv_splits_consistency_with_groups():\n    # Check if a one time iterable is accepted as a cv parameter with groups.\n    n_samples = 100\n    n_splits = 5\n    X, y = make_classification(n_samples=n_samples, random_state=0)\n    groups = np.random.randint(0, 3, n_samples)\n\n    gs = GridSearchCV(LinearSVC(random_state=0),\n                      param_grid={'C': [0.1, 0.2, 0.3]},\n                      cv=LeaveOneGroupOut())\n    gs.fit(X, y, groups=groups)\n\n    gs2 = GridSearchCV(LinearSVC(random_state=0),\n                       param_grid={'C': [0.1, 0.2, 0.3]},\n                       cv=GroupKFold(n_splits=n_splits))\n    gs2.fit(X, y, groups=groups)\n\n    # Give generator as a cv parameter\n    assert_true(isinstance(GroupKFold(n_splits=n_splits).split(X, y, groups),\n                           GeneratorType))\n    gs3 = GridSearchCV(LinearSVC(random_state=0),\n                       param_grid={'C': [0.1, 0.2, 0.3]},\n                       cv=GroupKFold(n_splits=n_splits).split(X, y, groups))\n    gs3.fit(X, y, groups=groups)\n\n    gs4 = GridSearchCV(LinearSVC(random_state=0),\n                       param_grid={'C': [0.1, 0.2, 0.3]},\n                       cv=GroupKFold(n_splits=n_splits))\n    gs4.fit(X, y, groups=groups)\n\n        for key in ('mean_fit_time', 'std_fit_time',"], "sample_753": ["def test_logreg_intercept_scaling_non_zero():\n    # Test that intercept_scaling is used when fit_intercept is True\n\n    clf = LogisticRegression(fit_intercept=True, intercept_scaling=2.0)\n    clf.fit(X, Y1)\n    assert_equal(clf.intercept_, 2.0 * clf.coef_[-1])\n"], "sample_1207": ["def test_lambda_notation():\n    x = Symbol('x')\n    f = parse_expr('lambda x: x**2')\n    assert f(x) == x**2\n    g = parse_expr('lambda x, y: x + y')\n    assert g(x, 2) == x + 2\n    raises(TokenError, lambda: parse_expr('lambda *args: args'))\n    raises(TokenError, lambda: parse_expr('lambda **kwargs: kwargs'))\n    raises(SyntaxError, lambda: parse_expr('lambda'))\n"], "sample_761": ["def test_iterative_imputer_n_nearest_features():\n    rng = np.random.RandomState(0)\n    n = 100\n    d = 10\n    X = sparse_random_matrix(n, d, density=0.10, random_state=rng).toarray()\n\n    imputer = IterativeImputer(missing_values=0,\n                               max_iter=1,\n                               n_nearest_features=5,\n                               random_state=rng)\n    imputer.fit_transform(X)\n\n    # check that n_nearest_features is used correctly\n    for triplet in imputer.imputation_sequence_:\n        assert len(triplet.neighbor_feat_idx) == 5\n"], "sample_675": ["def test_logging_emit_error_handled(testdir: Testdir) -> None:\n    \"\"\"\n    An exception raised during emit() should be handled and not fail the test.\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logger = logging.getLogger(__name__)\n            logger.warning('oops', 'first', 2, exc_info=True)\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=1)\n    result.stdout.no_fnmatch_line(\"*not all arguments converted during string formatting*\")\n"], "sample_701": ["def test_argument_type_str_choice_is_deprecated(pytester: Pytester) -> None:\n    p = pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n            parser.addoption(\n                \"--myoption\",\n                type='str',\n                choices=['choice1', 'choice2'],\n                help=\"my option: 'choice1' or 'choice2'\",\n            )\n        \"\"\"\n    )\n    result = pytester.runpytest(\"--help\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: `type` argument to addoption() is the string 'str'.*\",\n        ]\n    )\n    result.assert_outcomes(warnings=1)\n"], "sample_1061": ["def test_Float_floor_ceiling():\n    a = Float(3.7)\n    b = Float(3.2)\n\n    assert(a.floor() == 3)\n    assert(a.ceiling() == 4)\n    assert(b.floor() == 3)\n    assert(b.ceiling() == 4)\n"], "sample_1133": ["def test_refraction_angle_errors():\n    r1 = Ray3D(Point3D(-1, -1, 1), Point3D(0, 0, 0))\n    n = Matrix([0, 0, 1])\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, n, plane=P))\n    raises(ValueError, lambda: refraction_angle(2, 1, 1, n))\n    raises(ValueError, lambda: refraction_angle(0.5, 1, 1, n))\n    raises(ValueError, lambda: refraction_angle(pi/2, 1, 1, n))\n    raises(ValueError, lambda: refraction_angle(0.6, 2, 1, n))\n"], "sample_252": ["def test_key_transform_exact(self):\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__d__1__f__exact='g'),\n        [self.objs[4]],\n    )\n"], "sample_357": ["def test_alter_model_options_verbose_name_plural(self):\n    \"\"\"Changing a model's verbose_name_plural should make a change.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_with_options_plural])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, options={\n        \"verbose_name_plural\": \"Authors\",\n    })\n\n    # Changing it back to empty should also make a change\n    changes = self.get_changes([self.author_with_options_plural], [self.author_empty])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", options={})\n"], "sample_266": ["def test_run_before_invalid(self):\n    \"\"\"\n    Makes sure the loader raises an error for invalid run_before dependencies.\n    \"\"\"\n    with self.assertRaises(NodeNotFoundError):\n        MigrationLoader(connection)\n"], "sample_687": ["def test_caplog_records_with_exception(caplog):\n    caplog.set_level(logging.ERROR)\n    try:\n        raise Exception(\"test exception\")\n    except Exception:\n        logger.exception(\"oops\")\n\n    assert len(caplog.records) == 1\n    assert caplog.records[0].levelno == logging.ERROR\n    assert caplog.records[0].exc_info is not None\n    assert \"test exception\" in caplog.text\n"], "sample_274": ["def test_modelchoicefield_to_field_name(self):\n    # Create choices for the model choice field tests below.\n    ChoiceModel.objects.create(pk=1, name='a')\n    ChoiceModel.objects.create(pk=2, name='b')\n    ChoiceModel.objects.create(pk=3, name='c')\n\n    # ModelChoiceField with to_field_name\n    e = {\n        'required': 'REQUIRED',\n        'invalid_choice': 'INVALID CHOICE',\n    }\n    f = ModelChoiceField(queryset=ChoiceModel.objects.all(), to_field_name='name', error_messages=e)\n    self.assertFormErrors(['REQUIRED'], f.clean, '')\n    self.assertFormErrors(['INVALID CHOICE'], f.clean, 'd')\n"], "sample_616": ["def test_polyval_invalid_degree_dim(use_dask):\n    x = xr.DataArray([1, 2, 3], dims=\"x\")\n    coeffs = xr.DataArray([2, 3, 4], dims=\"degree\", coords={\"degree\": [0, 1, 2]})\n    if use_dask:\n        coeffs = coeffs.chunk({\"degree\": 2})\n        x = x.chunk({\"x\": 2})\n    with pytest.raises(ValueError):\n        xr.polyval(x, coeffs, degree_dim=\"invalid_dim\")\n"], "sample_758": ["def test_retrieve_samples_from_non_standard_shape():\n    class TestNonNumericShape:\n            self.shape = (\"not numeric\",)\n\n    with pytest.raises(TypeError):\n        _num_samples(TestNonNumericShape())\n"], "sample_122": ["def test_cache_key_varies_by_accept_encoding(self):\n    \"\"\"\n    get_cache_key keys differ by Accept-Encoding header\n    \"\"\"\n    request1 = self.factory.get(self.path, HTTP_ACCEPT_ENCODING='gzip')\n    learn_cache_key(request1, HttpResponse())\n    request2 = self.factory.get(self.path, HTTP_ACCEPT_ENCODING='identity')\n    learn_cache_key(request2, HttpResponse())\n    self.assertNotEqual(get_cache_key(request1), get_cache_key(request2))\n"], "sample_1012": ["def test_PythonCodePrinter_print_NoneToken():\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(none) == 'None'\n"], "sample_696": ["def test_argument_type_str_choice(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n            parser.addoption('--foo', type='str', choices=['a', 'b'])\n        \"\"\"\n    )\n    result = pytester.runpytest(\"--foo\", \"a\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: `type` argument to addoption() is the string 'str'.*\",\n        ]\n    )\n"], "sample_689": ["def test_strict_option_is_deprecated(testdir: Testdir) -> None:\n    result = testdir.runpytest(\"--strict\")\n    result.stdout.fnmatch_lines([\"*The --strict option is deprecated*\"])\n"], "sample_311": ["def test_url_with_trailing_slash_if_not_authenticated(self):\n    url = reverse('admin:article_extra_json') + '/'\n    response = self.client.get(url)\n    self.assertRedirects(response, '%s?next=%s' % (reverse('admin:login'), url))\n"], "sample_730": ["def test_enet_positive_constraint_with_precompute():\n    X = [[-1], [0], [1]]\n    y = [1, 0, -1]       # just a straight line with negative slope\n\n    enet = ElasticNet(alpha=0.1, max_iter=1000, positive=True, precompute=True)\n    enet.fit(X, y)\n    assert_true(min(enet.coef_) >= 0)\n"], "sample_568": ["def test_surface3d_zsort_nan():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n\n    x, y = np.mgrid[-2:2:0.1, -2:2:0.1]\n    z = np.sin(x)**2 + np.cos(y)**2\n    z[x.shape[0] // 2:, x.shape[1] // 2:] = np.nan\n\n    ax.plot_surface(x, y, z, cmap='jet')\n    ax.view_init(elev=45, azim=145)\n"], "sample_398": ["def test_logout_with_custom_redirect_url(self):\n    self.login()\n    response = self.client.post(\"/logout/custom_redirect/\")\n    self.assertRedirects(response, \"/custom/\", fetch_redirect_response=False)\n    self.confirm_logged_out()\n"], "sample_439": ["def test_custom_error_list_class(self):\n    class CustomErrorList(ErrorList):\n        error_class = \"custom-error-class\"\n\n    class CommentForm(Form):\n        name = CharField(max_length=50, required=False)\n        email = EmailField()\n        comment = CharField()\n\n    data = {\"email\": \"invalid\"}\n    f = CommentForm(data, auto_id=False, error_class=CustomErrorList)\n    self.assertHTMLEqual(\n        f.as_p(),\n        '<p>Name: <input type=\"text\" name=\"name\" maxlength=\"50\"></p>'\n        '<ul class=\"errorlist custom-error-class\">'\n        '<li>Enter a valid email address.</li></ul>'\n        '<p>Email: <input type=\"email\" name=\"email\" value=\"invalid\" required></p>'\n        '<ul class=\"errorlist custom-error-class\">'\n        '<li>This field is required.</li></ul>'\n        '<p>Comment: <input type=\"text\" name=\"comment\" required></p>',\n    )\n"], "sample_690": ["def test_marked_xfail_with_boolean_without_reason(pytester: Pytester) -> None:\n    item = pytester.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(False)\n            pass\n        \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_xfail_marks(item)\n    assert excinfo.value.msg is not None\n    assert (\n        \"\"\"Error evaluating 'xfail': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n        in excinfo.value.msg\n    )\n"], "sample_96": ["def test_actions_unique_with_different_names(self):\n        pass\n    action1.__name__ = 'action1'\n\n        pass\n    action2.__name__ = 'action2'\n\n    class BandAdmin(ModelAdmin):\n        actions = (action1, action2)\n\n    self.assertIsValid(BandAdmin, Band)\n"], "sample_304": ["    def test_email_validator_domain_allowlist(self):\n        validator = EmailValidator(allowlist=['example.com'])\n        self.assertIsNone(validator('test@example.com'))\n        with self.assertRaises(ValidationError):\n            validator('test@invalid.com')\n"], "sample_1052": ["def test_c_with_custom_printer():\n    x, y = symbols('x y')\n    expr = x**y\n\n    printer = CustomPrinter()\n    gen = C99CodeGen(printer=printer)\n\n    expected = (\n        '#include \"expr.h\"\\n'\n        '#include <math.h>\\n'\n        'double expr(double x, double y) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastpow(x, y);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n\n    result = codegen(('expr', expr), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    assert source == expected\n"], "sample_197": ["def test_custom_time_strings(self):\n    \"\"\" Test custom time strings. \"\"\"\n    custom_time_strings = {\n        'year': '{} yr',\n        'month': '{} mo',\n        'week': '{} wk',\n        'day': '{} d',\n        'hour': '{} hr',\n        'minute': '{} min',\n    }\n    self.assertEqual(timesince(self.t, self.t + self.oneminute, time_strings=custom_time_strings), '1 min')\n    self.assertEqual(timesince(self.t, self.t + self.onehour, time_strings=custom_time_strings), '1 hr')\n    self.assertEqual(timesince(self.t, self.t + self.oneday, time_strings=custom_time_strings), '1 d')\n    self.assertEqual(timesince(self.t, self.t + self.oneweek, time_strings=custom_time_strings), '1 wk')\n    self.assertEqual(timesince(self.t, self.t + self.onemonth, time_strings=custom_time_strings), '1 mo')\n    self.assertEqual(timesince(self.t, self.t + self.oneyear, time_strings=custom_time_strings), '1 yr')\n"], "sample_365": ["def test_classproperty_setter(self):\n    class Foo:\n        _foo_attr = 123\n\n        @classproperty\n            return cls._foo_attr\n\n        @foo.setter\n            cls._foo_attr = value\n\n    Foo.foo = 456\n    self.assertEqual(Foo.foo, 456)\n"], "sample_183": ["def test_when_with_empty_q_object(self):\n    msg = \"An empty Q() can't be used as a When() condition.\"\n    with self.assertRaisesMessage(ValueError, msg):\n        When(Q())\n"], "sample_857": ["def test_prune_tree_raises_invalid_ccp_alpha():\n    clf = DecisionTreeClassifier()\n    msg = \"ccp_alpha must be a non-negative float\"\n\n    with pytest.raises(ValueError, match=msg):\n        clf.set_params(ccp_alpha=\"invalid\")\n        clf.fit(X, y)\n\n    with pytest.raises(ValueError, match=msg):\n        clf.set_params(ccp_alpha=None)\n        clf.fit(X, y)\n"], "sample_1201": ["def test_electromagnetic_conversions():\n    assert convert_to(statvolt, volt, cgs_gauss) == volt/299792458000000\n    assert convert_to(volt, statvolt, cgs_gauss) == 299792458000000*statvolt\n    assert convert_to(statvolt, sqrt(gram/centimeter)*erg/statcoulomb, cgs_gauss) == sqrt(gram/centimeter)*erg/statcoulomb\n    assert convert_to(volt, sqrt(gram/centimeter)*erg/statcoulomb, cgs_gauss) == 299792458000000*sqrt(gram/centimeter)*erg/statcoulomb\n\n    assert convert_to(ohm, henry/farad, cgs_gauss) == second/sqrt(gram*centimeter)\n    assert convert_to(henry/farad, ohm, cgs_gauss) == sqrt(gram*centimeter)/second\n"], "sample_614": ["def test_format_timedelta_invalid_pandas_format() -> None:\n    expected = \"10 days 1 hour 00\"\n    with pytest.raises(ValueError):\n        formatting.format_timedelta(expected)\n"], "sample_630": ["def test_get_annotation_complex_types(assign, label):\n    \"\"\"Complex types\"\"\"\n    node = astroid.extract_node(assign)\n    got = get_annotation(node.value).name\n    assert isinstance(node, astroid.AnnAssign)\n    assert got == label, f\"got {got} instead of {label} for value {node}\"\n"], "sample_1113": ["def test_block_matrix_multiplication():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    D = MatrixSymbol('D', 2, 2)\n    block_A = BlockMatrix([[A, B], [C, D]])\n    block_B = BlockMatrix([[A, C], [B, D]])\n    expected_result = BlockMatrix([[A*A + B*C, A*B + B*D], [C*A + D*C, C*B + D*D]])\n    assert block_A * block_B == expected_result\n"], "sample_175": ["def test_fast_delete_with_keeping_parents(self):\n    child = RChild.objects.create()\n    parent_id = child.r_ptr_id\n    # 1 for self delete, 1 for fast delete of empty \"rchild\" qs.\n    self.assertNumQueries(2, child.delete(keep_parents=True))\n    self.assertFalse(RChild.objects.filter(id=child.id).exists())\n    self.assertTrue(R.objects.filter(id=parent_id).exists())\n"], "sample_864": ["def test_mean_shift_with_sparse_matrix():\n    # Test MeanShift algorithm with sparse matrix\n    X = sparse.csr_matrix(X)\n    ms = MeanShift(bandwidth=1.2)\n    labels = ms.fit(X).labels_\n    labels_unique = np.unique(labels)\n    n_clusters_ = len(labels_unique)\n    assert n_clusters_ == 3\n"], "sample_82": ["def test_selectdate_custom_id_for_label(self):\n    widget = SelectDateWidget(years=('2013',))\n    self.assertEqual(widget.id_for_label('mydate'), 'mydate_month')\n"], "sample_270": ["def test_unique_constraint_include_pointing_to_fk(self):\n    class Target(models.Model):\n        pass\n\n    class Model(models.Model):\n        fk_1 = models.ForeignKey(Target, models.CASCADE, related_name='target_1')\n        fk_2 = models.ForeignKey(Target, models.CASCADE, related_name='target_2')\n\n        class Meta:\n            constraints = [\n                models.UniqueConstraint(\n                    fields=['id'],\n                    include=['fk_1_id', 'fk_2'],\n                    name='name',\n                ),\n            ]\n\n    self.assertEqual(Model.check(databases=self.databases), [])\n"], "sample_77": ["def test_urlize_nofollow(self):\n    value = 'Check out this link: http://example.com'\n    output = 'Check out this link: <a href=\"http://example.com\" rel=\"nofollow\">http://example.com</a>'\n    self.assertEqual(urlize(value, nofollow=True), output)\n"], "sample_352": ["    def test_ticket_24605_with_values(self):\n        \"\"\"\n        Subquery table names should be quoted when using values().\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(\n            Individual.objects.filter(Q(alive=False), Q(related_individual__isnull=True)).values('pk'),\n            [{'pk': i4.pk}]\n        )\n        self.assertSequenceEqual(\n            Individual.objects.exclude(Q(alive=False), Q(related_individual__isnull=True)).values('pk').order_by('pk'),\n            [{'pk': i1.pk}, {'pk': i2.pk}, {'pk': i3.pk}]\n        )\n"], "sample_840": ["def test_pls_algorithm():\n    # Test that the algorithm parameter is correctly handled\n    d = load_linnerud()\n    X = d.data\n    Y = d.target\n    pls_nipals = pls_.PLSCanonical(algorithm=\"nipals\")\n    pls_svd = pls_.PLSCanonical(algorithm=\"svd\")\n    pls_nipals.fit(X, Y)\n    pls_svd.fit(X, Y)\n    # Check that the results are similar for both algorithms\n    assert_array_almost_equal(pls_nipals.x_scores_, pls_svd.x_scores_)\n    assert_array_almost_equal(pls_nipals.y_scores_, pls_svd.y_scores_)\n    # Check that an error is raised for an unknown algorithm\n    with pytest.raises(ValueError):\n        pls_.PLSCanonical(algorithm=\"unknown\")\n"], "sample_968": ["def test_pyfunction_signature_with_default_value(app):\n    text = \".. py:function:: hello(name='World') -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_operator, \"=\"],\n                                                      [desc_sig_literal_string, \"'World'\"])])\n"], "sample_791": ["def test_one_hot_encoder_drop_first():\n    enc = OneHotEncoder(drop='first')\n    X = [['abc', 12, 2, 55],\n         ['def', 12, 1, 55],\n         ['def', 12, 3, 56]]\n    trans = enc.fit_transform(X).toarray()\n    exp = [[0, 1, 1],\n           [1, 0, 1],\n           [1, 1, 0]]\n    assert_array_equal(trans, exp)\n    dropped_cats = [cat[feature]\n                    for cat, feature in zip(enc.categories_,\n                                            enc.drop_idx_)]\n    assert_array_equal(dropped_cats, ['abc', 12, 2, 55])\n    X_inv = enc.inverse_transform(trans)\n    X_inv[:, 1] = 12  # drop column makes 12 unknown\n    assert_array_equal(np.array(X, dtype=object), X_inv)\n"], "sample_597": ["def test_merge_override(self):\n    ds1 = xr.Dataset({\"x\": (\"y\", [1, 2])}, coords={\"y\": [0, 1]})\n    ds2 = xr.Dataset({\"x\": (\"y\", [3, 4])}, coords={\"y\": [1, 2]})\n    expected = xr.Dataset({\"x\": (\"y\", [1, 3, 4])}, coords={\"y\": [0, 1, 2]})\n    assert expected.identical(ds1.merge(ds2, compat=\"override\"))\n    assert expected.identical(ds2.merge(ds1, compat=\"override\"))\n"], "sample_1010": ["def test_Quaternion_latex_printing_with_zero_components():\n    q = Quaternion(0, 0, 0, 0)\n    assert latex(q) == \"0\"\n    q = Quaternion(x, 0, 0, 0)\n    assert latex(q) == \"x\"\n    q = Quaternion(0, y, 0, 0)\n    assert latex(q) == \"y i\"\n    q = Quaternion(0, 0, z, 0)\n    assert latex(q) == \"z j\"\n    q = Quaternion(0, 0, 0, t)\n    assert latex(q) == \"t k\"\n"], "sample_812": ["def test_compact_representation():\n    # Test compact representation of estimators\n    pp = _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=True)\n\n    lr = LogisticRegression(C=99, class_weight=.4, fit_intercept=False,\n                            tol=1234, verbose=True)\n    expected = \"LogisticRegression(C=99, class_weight=0.4, fit_intercept=False, tol=1234, verbose=True)\"\n    assert pp.pformat(lr) == expected\n\n    pipeline = make_pipeline(StandardScaler(), LogisticRegression(C=999))\n    expected = \"Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=999))])\"\n    assert pp.pformat(pipeline) == expected\n"], "sample_770": ["def test_davies_bouldin_score():\n    assert_raises_on_only_one_label(davies_bouldin_score)\n\n    assert_raises_on_all_points_same_cluster(davies_bouldin_score)\n\n    # Assert the value is 0. when all samples are equals\n    assert_equal(0., davies_bouldin_score(np.ones((10, 2)),\n                                          [0] * 5 + [1] * 5))\n\n    # Assert the value is 0. when all the mean cluster are equal\n    assert_equal(0., davies_bouldin_score([[-1, -1], [1, 1]] * 10,\n                                          [0] * 10 + [1] * 10))\n\n    # General case (with non numpy arrays)\n    X = ([[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5 +\n         [[0, 4], [1, 3]] * 5 + [[3, 1], [4, 0]] * 5)\n    labels = [0] * 10 + [1] * 10 + [2] * 10 + [3] * 10\n    pytest.approx(davies_bouldin_score(X, labels),\n                  0.5 * (1 + 1 + 2 + 2))\n"], "sample_413": ["    def test_template_tags_with_different_library_names_but_same_module_path(self):\n        with self.settings(\n            TEMPLATES=[\n                self.get_settings(\n                    \"library1\", \"same_tags_app_1.templatetags.same_tags\"\n                ),\n                self.get_settings(\n                    \"library2\", \"same_tags_app_1.templatetags.same_tags\"\n                ),\n            ]\n        ):\n            self.assertEqual(\n                check_for_template_tags_with_the_same_name(None),\n                [\n                    Error(\n                        E003.msg.format(\n                            \"'same_tags'\",\n                            \"'check_framework.template_test_apps.same_tags_app_1.\"\n                            \"templatetags.same_tags'\",\n                        ),\n                        id=E003.id,\n                    )\n                ],\n            )\n"], "sample_1203": ["def test_group_isomorphism_with_free_groups():\n    # FreeGroup -> FreeGroup\n    F, a, b = free_group(\"a, b\")\n    G = FpGroup(F, [a*b*a**-1*b**-1])\n    check, T = group_isomorphism(F, G)\n    assert check\n    assert T(a*b*a**-1*b**-1).is_identity\n\n    # FreeGroup -> FpGroup\n    H = FpGroup(F, [a**2, b**3, (a*b)**2])\n    check, T = group_isomorphism(F, H)\n    assert check\n    assert T(a**2*b**3*(a*b)**-2).is_identity\n"], "sample_407": ["def test_fk_to_field_assignment_and_related_object_cache(self):\n    # Tests of ForeignKey assignment with to_field and the related-object cache.\n\n    p = Parent.objects.create(name=\"Parent\")\n    c = ToFieldChild.objects.create(parent=p)\n\n    # Look up the object again so that we get a \"fresh\" object.\n    c = ToFieldChild.objects.get(parent=p)\n    p = c.parent\n\n    # Accessing the related object again returns the exactly same object.\n    self.assertIs(c.parent, p)\n\n    # But if we kill the cache, we get a new object.\n    del c._state.fields_cache[\"parent\"]\n    self.assertIsNot(c.parent, p)\n\n    # Assigning a new object results in that object getting cached immediately.\n    p2 = Parent.objects.create(name=\"Parent 2\")\n    c.parent = p2\n    self.assertIs(c.parent, p2)\n\n    # Assigning None will not fail: ToFieldChild.parent is null=True.\n    c.parent = None\n    self.assertIsNone(c.parent)\n\n    # Creation using keyword argument should cache the related object.\n    p = Parent.objects.get(name=\"Parent\")\n    c = ToFieldChild(parent=p)\n    self.assertIs(c.parent, p)\n\n    # Creation using keyword argument and unsaved related instance (#8070).\n    p = Parent()\n    msg = (\n        \"save() prohibited to prevent data loss due to unsaved related object \"\n        \"'parent'.\"\n    )\n    with self.assertRaisesMessage(ValueError, msg):\n        ToFieldChild.objects.create(parent=p)\n\n    # Creation using attname keyword argument and an id will cause the\n    # related object to be fetched.\n    p = Parent.objects.get(name=\"Parent\")\n    c = ToFieldChild(parent_id=p.name)\n    self.assertIsNot(c.parent, p)\n    self.assertEqual(c.parent"], "sample_117": ["    def test_integer_username(self):\n        data = {\n            'username': 1234567,\n            'password1': 'test123',\n            'password2': 'test123',\n        }\n        form = UserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        u = form.save()\n        self.assertEqual(u.username, 1234567)\n"], "sample_546": ["def test_toolmanager_add_tool():\n    with pytest.warns(UserWarning, match=_EXPECTED_WARNING_TOOLMANAGER):\n        plt.rcParams['toolbar'] = 'toolmanager'\n    fig = plt.gcf()\n    initial_len = len(fig.canvas.manager.toolmanager.tools)\n    assert 'custom_tool' not in fig.canvas.manager.toolmanager.tools\n    fig.canvas.manager.toolmanager.add_tool('custom_tool', 'Custom Tool')\n    assert len(fig.canvas.manager.toolmanager.tools) == initial_len + 1\n    assert 'custom_tool' in fig.canvas.manager.toolmanager.tools\n"], "sample_296": ["def test_safedata_preservation(self):\n    \"\"\"\n    A message containing SafeData is properly preserved when\n    retrieved from the message storage and re-stored.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    safe_message = mark_safe('This is a safe message')\n    storage.add(constants.INFO, safe_message)\n    storage.update(response)\n\n    # Simulate the message being consumed and then re-stored\n    for _ in storage:\n        pass\n    storage.update(response)\n\n    # Decode the stored message and check if it's still safe\n    encoded_message = response.cookies['messages'].value\n    decoded_message = storage._decode(encoded_message)[0].message\n    self.assertIsInstance(decoded_message, SafeData)\n    self.assertEqual(decoded_message, safe_message)\n"], "sample_512": ["def test_subplot_mosaic_empty_sentinel():\n    fig, ax_dict = plt.subplot_mosaic({'A': [1, 2], 'B': [3, 4]}, empty_sentinel='.')\n    assert 'A' in ax_dict\n    assert 'B' in ax_dict\n    assert '.' not in ax_dict\n"], "sample_1": ["def test_custom_model_separability_matrix():\n    @custom_model\n        return x + y, x - y\n\n    result = separability_matrix(model_b)\n    expected = np.array([[True, True], [True, True]])\n    assert_allclose(result, expected)\n"], "sample_513": ["def test_legend_markers_from_line2d_with_different_colors():\n    # Test that markers can be copied for legend lines with different colors (#17960)\n    _markers = ['.', '*', 'v']\n    _colors = ['r', 'g', 'b']\n    fig, ax = plt.subplots()\n    lines = [mlines.Line2D([0], [0], ls='None', marker=mark, color=col)\n             for mark, col in zip(_markers, _colors)]\n    labels = [\"foo\", \"bar\", \"xyzzy\"]\n    markers = [line.get_marker() for line in lines]\n    colors = [line.get_color() for line in lines]\n    legend = ax.legend(lines, labels)\n\n    new_markers = [line.get_marker() for line in legend.get_lines()]\n    new_colors = [line.get_color() for line in legend.get_lines()]\n    new_labels = [text.get_text() for text in legend.get_texts()]\n\n    assert markers == new_markers == _markers\n    assert colors == new_colors == _colors\n    assert labels == new_labels\n"], "sample_725": ["def test_check_memory():\n    # Test with None\n    memory = check_memory(None)\n    assert isinstance(memory, Memory)\n\n    # Test with a string\n    memory = check_memory('cache_dir')\n    assert isinstance(memory, Memory)\n\n    # Test with a Memory object\n    memory_obj = Memory(cachedir='cache_dir', verbose=0)\n    memory = check_memory(memory_obj)\n    assert memory is memory_obj\n\n    # Test with an invalid object\n    with pytest.raises(ValueError):\n        check_memory('invalid')\n"], "sample_181": ["def test_filtered_aggregate_ref_annotation_with_default(self):\n    aggs = Author.objects.annotate(\n        double_age=F('age') * 2,\n        default_age=Max('age', default=0),\n    ).aggregate(\n        cnt=Count('pk', filter=Q(double_age__gt=F('default_age'))),\n    )\n    self.assertEqual(aggs['cnt'], 1)\n"], "sample_936": ["def test_stringify_type_hints_broken_type():\n    assert stringify(BrokenType) == \"test_util_typing.BrokenType\"\n"], "sample_617": ["def test_polyval_invalid_degree_dim():\n    x = xr.DataArray([1, 2, 3], dims=\"x\")\n    coeffs = xr.DataArray([2, 3, 4], dims=\"degree\", coords={\"degree\": [\"a\", \"b\", \"c\"]})\n    with pytest.raises(ValueError):\n        xr.polyval(x, coeffs)\n"], "sample_425": ["def test_serialize_complex(self):\n    self.assertSerializedEqual(complex(1, 2))\n    self.assertSerializedResultEqual(\n        complex(1, 2),\n        (\"complex((1+2j))\", set()),\n    )\n"], "sample_655": ["def test_capture_with_live_logging_disabled(testdir, capture_fixture):\n    # Test that capture works with live cli logging disabled\n\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        import sys\n\n        logger = logging.getLogger(__name__)\n\n            print(\"hello\")\n            sys.stderr.write(\"world\\\\n\")\n            with {0}.disabled():\n                logging.info(\"something\")\n                print(\"next\")\n                logging.info(\"something\")\n\n            captured = {0}.readouterr()\n            assert captured.out == \"hello\\\\nnext\\\\n\"\n            assert captured.err == \"world\\\\n\"\n        \"\"\".format(\n            capture_fixture\n        )\n    )\n\n    result = testdir.runpytest_subprocess(\"--log-cli-level=INFO\")\n    assert result.ret == 0\n"], "sample_400": ["def test_add_model_with_field_removed_from_base_model_with_m2m(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name and a ManyToManyField with the same name.\n    \"\"\"\n    before = [\n        ModelState(\n            \"app\",\n            \"readable\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"title\", models.CharField(max_length=200)),\n            ],\n        ),\n    ]\n    after = [\n        ModelState(\n            \"app\",\n            \"readable\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n            ],\n        ),\n        ModelState(\n            \"app\",\n            \"book\",\n            [\n                (\"title\", models.CharField(max_length=200)),\n                (\"authors\", models.ManyToManyField(\"app.Author\")),\n            ],\n            bases=(\"app.readable\",),\n        ),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, \"app\", 1)\n    self.assertOperationTypes(changes, \"app\", 0, [\"RemoveField\", \"CreateModel\"])\n    self.assertOperationAttributes(\n        changes, \"app\", 0, 0, name=\"title\", model_name=\"readable\"\n    )\n    self.assertOperationAttributes(changes, \"app\", 0, 1, name=\"book\")\n"], "sample_816": ["def test_vectorizer_max_df_min_df():\n    test_data = ['abc', 'dea', 'eat']\n    vect = CountVectorizer(analyzer='char', max_df=0.5, min_df=0.5)\n    vect.fit(test_data)\n    assert 'a' not in vect.vocabulary_.keys()  # {ae} ignored\n    assert_equal(len(vect.vocabulary_.keys()), 2)    # {ae} remain\n    assert 'c' in vect.stop_words_\n    assert_equal(len(vect.stop_words_), 1)\n"], "sample_111": ["def test_get_ordering_field_columns_with_f_expression(self):\n    \"\"\"\n    Regression test for #17198: The get_ordering_field_columns() method\n    should handle F() expressions correctly.\n    \"\"\"\n    class OrderedByFBandAdmin(admin.ModelAdmin):\n        list_display = ['name', 'genres', 'nr_of_members']\n        ordering = (\n            F('nr_of_members').desc(nulls_last=True),\n            Upper(F('name')).asc(),\n            F('genres').asc(),\n        )\n\n    m = OrderedByFBandAdmin(Band, custom_site)\n    request = self.factory.get('/band/')\n    request.user = self.superuser\n    cl = m.get_changelist_instance(request)\n    self.assertEqual(cl.get_ordering_field_columns(), {3: 'desc', 2: 'asc'})\n"], "sample_952": ["def test_is_builtin_class_method_with_custom_class():\n    class CustomClass:\n            pass\n\n    assert inspect.is_builtin_class_method(CustomClass, 'custom_method') is False\n"], "sample_788": ["def test_inverse_transform_outside_fit_range():\n    X = np.array([0, 1, 2, 3])[:, None]\n    kbd = KBinsDiscretizer(n_bins=4, strategy='uniform', encode='ordinal')\n    kbd.fit(X)\n\n    X2t = np.array([[-1], [4]])\n    X2inv = kbd.inverse_transform(X2t)\n    assert_array_equal(X2inv.max(axis=0), X.max(axis=0))\n    assert_array_equal(X2inv.min(axis=0), X.min(axis=0))\n"], "sample_1081": ["def test_is_amicable():\n    assert is_amicable(220, 284) is True\n    assert is_amicable(1184, 1210) is True\n    assert is_amicable(2620, 2924) is True\n    assert is_amicable(5020, 5564) is True\n    assert is_amicable(6232, 6368) is True\n    assert is_amicable(10744, 10856) is True\n    assert is_amicable(12285, 14595) is True\n    assert is_amicable(17296, 18416) is True\n    assert is_amicable(6368, 2620) is True  # Testing commutativity\n    assert is_amicable(220, 220) is False  # Testing reflexivity\n"], "sample_773": ["def test_logistic_regression_path_coefs_ovr():\n    # Make sure that the returned coefs by logistic_regression_path when\n    # multi_class='ovr' don't override each other (used to be a bug).\n    X, y = make_classification(n_samples=200, n_classes=3, n_informative=2,\n                               n_redundant=0, n_clusters_per_class=1,\n                               random_state=0, n_features=2)\n    Cs = [.00001, 1, 10000]\n    coefs, _, _ = _logistic_regression_path(X, y, penalty='l1', Cs=Cs,\n                                            solver='saga', random_state=0,\n                                            multi_class='ovr')\n\n    with pytest.raises(AssertionError):\n        assert_array_almost_equal(coefs[0], coefs[1], decimal=1)\n    with pytest.raises(AssertionError):\n        assert_array_almost_equal(coefs[0], coefs[2], decimal=1)\n    with pytest.raises(AssertionError):\n        assert_array_almost_equal(coefs[1], coefs[2], decimal=1)\n"], "sample_823": ["def test_check_preserve_type_sparse():\n    # Ensures that type float32 is preserved for sparse matrices.\n    XA = csr_matrix(np.resize(np.arange(40), (5, 8)).astype(np.float32))\n    XB = csr_matrix(np.resize(np.arange(40), (5, 8)).astype(np.float32))\n\n    XA_checked, XB_checked = check_pairwise_arrays(XA, None)\n    assert_equal(XA_checked.dtype, np.float32)\n\n    # both float32\n    XA_checked, XB_checked = check_pairwise_arrays(XA, XB)\n    assert_equal(XA_checked.dtype, np.float32)\n    assert_equal(XB_checked.dtype, np.float32)\n\n    # mismatched A\n    XA_checked, XB_checked = check_pairwise_arrays(XA.astype(np.float), XB)\n    assert_equal(XA_checked.dtype, np.float)\n    assert_equal(XB_checked.dtype, np.float)\n\n    # mismatched B\n    XA_checked, XB_checked = check_pairwise_arrays(XA, XB.astype(np.float))\n    assert_equal(XA_checked.dtype, np.float)\n    assert_equal(XB_checked.dtype, np.float)\n"], "sample_202": ["def test_safedata_preservation(self):\n    \"\"\"\n    A message containing SafeData is properly preserved when\n    retrieved from the message storage and re-stored.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    safe_message = mark_safe('This is a safe message')\n    storage.add(constants.INFO, safe_message)\n    storage.update(response)\n\n    # Simulate the message being stored and retrieved\n    set_cookie_data(storage, [safe_message])\n\n    # The message should still be marked as safe\n    self.assertIsInstance(list(storage)[0], SafeData)\n"], "sample_815": ["def test_balanced_accuracy_score_sample_weight():\n    y_true = ['a', 'b', 'a', 'b']\n    y_pred = ['a', 'a', 'a', 'b']\n    sample_weight = [1, 1, 2, 1]\n    balanced = balanced_accuracy_score(y_true, y_pred, sample_weight=sample_weight)\n    assert balanced == pytest.approx(0.75)\n"], "sample_65": ["def test_i18n_language_with_custom_domain(self):\n    \"\"\"\n    Check if the JavaScript i18n view returns a complete language catalog\n    if a custom domain is used.\n    \"\"\"\n    with self.settings(LANGUAGE_CODE='en-us'), override('fr'):\n        response = self.client.get('/jsi18n/app6/custom_domain/')\n        self.assertContains(response, 'this app6 string with custom domain is to be translated')\n"], "sample_806": ["def test_gradient_boosting_with_custom_loss():\n    # Check that GradientBoostingRegressor works with a custom loss function\n\n        return np.mean((y_true - y_pred) ** 2)\n\n        return 2 * (y_pred - y_true)\n\n        return np.ones_like(y_true) * 2\n\n    X, y = make_regression(random_state=0)\n    gb = GradientBoostingRegressor(loss=custom_loss, init=None)\n    gb.fit(X, y)\n    y_pred = gb.predict(X)\n    assert_array_almost_equal(y_pred, y, decimal=2)\n\n    gb = GradientBoostingRegressor(loss=custom_loss, init=DummyRegressor())\n    gb.fit(X, y)\n    y_pred = gb.predict(X)\n    assert_array_almost_equal(y_pred, y, decimal=2)\n\n    gb = GradientBoostingRegressor(loss=custom_loss, init=LinearRegression())\n    gb.fit(X, y)\n    y_pred = gb.predict(X)\n    assert_array_almost_equal(y_pred, y, decimal=2)\n"], "sample_547": ["def test_offsetimage():\n    fig, ax = plt.subplots()\n\n    data = np.random.rand(10, 10)\n    im = OffsetImage(data, zoom=2)\n    ab = AnnotationBbox(im, (0.5, 0.5), xycoords='data')\n    ax.add_artist(ab)\n"], "sample_275": ["def test_delete_with_filtered_relation(self):\n    \"\"\"\n    Test that delete() works correctly with FilteredRelation.\n    \"\"\"\n    person = Person.objects.create(name='John Doe')\n    email1 = Email.objects.create(label='personal', email_address='john@example.com')\n    email2 = Email.objects.create(label='work', email_address='john@work.com')\n    person.contacts.add(email1, email2)\n\n    # Delete only the 'personal' email\n    person.contacts.filter(label='personal').delete()\n\n    # Check that only the 'personal' email is deleted\n    self.assertEqual(Email.objects.count(), 1)\n    self.assertEqual(Email.objects.get().label, 'work')\n    self.assertEqual(person.contacts.count(), 1)\n    self.assertEqual(person.contacts.get().label, 'work')\n"], "sample_1049": ["def test_parameter_value():\n    p = Plane((2, 0, 0), (0, 0, 1), (0, 1, 0))\n    on_circle = p.arbitrary_point(pi/4)\n    assert p.parameter_value(on_circle, t) == {t: pi/4}\n    off_circle = p.p1 + (on_circle - p.p1)*2\n    assert p.parameter_value(off_circle, t) == {t: pi/4}\n    assert p.parameter_value(on_circle, u, v) == {u: sqrt(10)/10, v: sqrt(10)/30}\n    assert p.parameter_value(off_circle, u, v) == {u: sqrt(10)/5, v: sqrt(10)/15}\n    raises(ValueError, lambda: p.parameter_value(Point3D(1, 2, 3), t))\n"], "sample_165": ["def test_modelchoicefield_to_field_name(self):\n    # Create choices for the model choice field tests below.\n    ChoiceModel.objects.create(pk=1, name='a')\n    ChoiceModel.objects.create(pk=2, name='b')\n    ChoiceModel.objects.create(pk=3, name='c')\n\n    # ModelChoiceField with to_field_name\n    e = {\n        'required': 'REQUIRED',\n        'invalid_choice': 'INVALID CHOICE',\n    }\n    f = ModelChoiceField(queryset=ChoiceModel.objects.all(), to_field_name='name', error_messages=e)\n    self.assertFormErrors(['REQUIRED'], f.clean, '')\n    self.assertFormErrors(['INVALID CHOICE'], f.clean, 'd')\n"], "sample_759": ["def test_one_hot_encoder_unsorted_categories_error():\n    X = np.array([[2, 1]]).T\n\n    enc = OneHotEncoder(categories=[[2, 1, 3]])\n    msg = 'Unsorted categories are not supported'\n    with pytest.raises(ValueError, match=msg):\n        enc.fit_transform(X)\n"], "sample_859": ["def test_lassoCV_does_not_set_precompute_multitask(monkeypatch, precompute,\n                                                   inner_precompute):\n    X, y, _, _ = build_dataset(n_targets=3)\n    calls = 0\n\n    class MultiTaskLassoMock(MultiTaskLasso):\n            super().fit(X, y)\n            nonlocal calls\n            calls += 1\n            assert self.precompute == inner_precompute\n\n    monkeypatch.setattr(\"sklearn.linear_model.coordinate_descent.MultiTaskLasso\", MultiTaskLassoMock)\n\n    LassoCV(precompute=precompute).fit(X, y)\n    assert calls == 3\n"], "sample_522": ["def test_colorbar_set_ticks_locator():\n    # check that the locator properties echo what is on the axis:\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc)\n    cb.set_ticks(np.arange(10))\n    assert isinstance(cb.locator, FixedLocator)\n    assert cb.locator.locs == np.arange(10)\n"], "sample_814": ["def test_gradient_boosting_with_init_custom_estimator():\n    # Check that the init estimator can be a custom estimator\n\n    class CustomEstimator(BaseEstimator):\n            self.classes_ = np.unique(y)\n            return self\n\n            return np.full(X.shape[0], self.classes_[0])\n\n    X, y = make_classification(n_classes=2, random_state=0)\n    init = CustomEstimator()\n    gb = GradientBoostingClassifier(init=init)\n    gb.fit(X, y)  # custom estimator without sample_weight works fine\n\n    with pytest.raises(\n            ValueError,\n            match='The initial estimator CustomEstimator does not support sample weights'):\n        gb.fit(X, y, sample_weight=np.ones(X.shape[0]))\n"], "sample_903": ["def test_non_euclidean_metrics():\n    # Test t-SNE with non-euclidean metrics\n    random_state = check_random_state(0)\n    X = random_state.randn(100, 2)\n    for metric in [manhattan_distances, cosine_distances]:\n        tsne = TSNE(n_components=2, perplexity=10, learning_rate=100.0,\n                    random_state=0, method='exact', metric=metric)\n        X_embedded = tsne.fit_transform(X)\n        t = trustworthiness(X, X_embedded, n_neighbors=1, metric=metric)\n        assert t > 0.85\n"], "sample_1084": ["def test_Rationals_intersection():\n    assert S.Rationals.intersect(S.Integers) == S.Integers\n    assert S.Rationals.intersect(S.Naturals) == S.Naturals\n    assert S.Rationals.intersect(S.Naturals0) == S.Naturals0\n    assert S.Rationals.intersect(S.Reals) == S.Rationals\n    assert S.Rationals.intersect(S.Complexes) == S.Rationals\n    assert S.Rationals.intersect(Interval(0, 1)) == Intersection(S.Rationals, Interval(0, 1))\n    assert S.Rationals.intersect(FiniteSet(0, 1, 2, S.Half)) == FiniteSet(0, 1, 2, S.Half)\n"], "sample_1132": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((1, 0, 0))) == [(1, 0, 0), (-1, 0, 0), (1, -0, 0), (-1, -0, 0), (1, 0, -0), (-1, 0, -0), (1, -0, -0), (-1, -0, -0)]\n"], "sample_554": ["def test_annotation_antialiased_with_usetex():\n    annot = Annotation(\"$foo$\", (.5, .5), antialiased=True, usetex=True)\n    assert annot._antialiased is True\n    assert annot.get_antialiased() == annot._antialiased\n\n    annot2 = Annotation(\"$foo$\", (.5, .5), antialiased=False, usetex=True)\n    assert annot2._antialiased is False\n    assert annot2.get_antialiased() == annot2._antialiased\n\n    annot3 = Annotation(\"$foo$\", (.5, .5), antialiased=False, usetex=True)\n    annot3.set_antialiased(True)\n    assert annot3.get_antialiased() is True\n    assert annot3._antialiased is True\n\n    annot4 = Annotation(\"$foo$\", (.5, .5), usetex=True)\n    assert annot4._antialiased == mpl.rcParams['text.antialiased']\n"], "sample_188": ["def test_expression_wrapper_with_aggregate(self):\n    Number.objects.create(integer=1000, float=1.2)\n    Employee.objects.create(salary=1000)\n    qs = Number.objects.annotate(\n        min_valuable_count=ExpressionWrapper(\n            Employee.objects.filter(\n                salary=OuterRef('integer'),\n            ).annotate(cnt=Count('salary')).filter(cnt__gt=0).values('cnt')[:1],\n            output_field=IntegerField(),\n        ),\n    )\n    self.assertEqual(qs.get().float, 1.2)\n"], "sample_478": ["def test_actions_unique_with_different_names(self):\n    @admin.action(name=\"action1\")\n        pass\n\n    @admin.action(name=\"action2\")\n        pass\n\n    class BandAdmin(ModelAdmin):\n        actions = (action1, action2)\n\n    self.assertIsValid(BandAdmin, Band)\n"], "sample_1102": ["def test_issue_18205_with_rational():\n    assert cancel((2 + Rational(1, 2)*I)*(3 - Rational(1, 2)*I)) == Rational(13, 2) + Rational(1, 2)*I\n    assert cancel((2 + Rational(1, 2)*I)*(2 - Rational(1, 2)*I)) == 5\n"], "sample_462": ["def test_choicefield_initial(self):\n    f = ChoiceField(choices=[(\"1\", \"One\"), (\"2\", \"Two\")], initial=\"1\")\n    self.assertEqual(\"1\", f.clean(\"1\"))\n    self.assertEqual(\"2\", f.clean(\"2\"))\n    msg = \"'Select a valid choice. 3 is not one of the available choices.'\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        f.clean(\"3\")\n    self.assertEqual(\"1\", f.clean(\"\"))\n    self.assertEqual(\"1\", f.clean(None))\n"], "sample_633": ["def test_ignore_signatures_class_methods_with_decorators_pass() -> None:\n    output = StringIO()\n    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n        similar.Run([\"--ignore-signatures\", SIMILAR_CLS_B, SIMILAR_CLS_A])\n    assert ex.value.code == 0\n    assert (\n        output.getvalue().strip()\n        == \"\"\""], "sample_930": ["def test_create_index_with_category(app):\n    text = (\".. index:: single: docutils\\n\"\n            \"   :category: tools\\n\"\n            \".. index:: single: Python\\n\"\n            \"   :category: languages\\n\"\n            \".. index:: Sphinx\\n\"\n            \"   :category: tools\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n\n    # check index is created correctly\n    assert len(index) == 2\n    assert index[0] == ('languages', [('Python', [[('', '#index-1')], [], 'languages'])])\n    assert index[1] == ('tools', [('docutils', [[('', '#index-0')], [], 'tools']),\n                                  ('Sphinx', [[('', '#index-2')], [], 'tools'])])\n"], "sample_317": ["def test_atom_feed_author_elements(self):\n    \"\"\"\n    Test the author elements in the Atom feed.\n    \"\"\"\n    response = self.client.get('/syndication/atom/')\n    feed = minidom.parseString(response.content).firstChild\n    entries = feed.getElementsByTagName('entry')\n\n    author = entries[0].getElementsByTagName('author')[0]\n    self.assertChildNodes(author, ['name', 'email', 'uri'])\n    self.assertChildNodeContent(author, {\n        'name': 'Sally Smith',\n        'email': 'test@example.com',\n        'uri': 'http://example.com/',\n    })\n"], "sample_216": ["def test_add_model_with_field_removed_from_base_model_and_altered(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name and altering it.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=300)),\n        ], bases=('app.readable',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel', 'AlterField'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n    self.assertOperationAttributes(changes, 'app', 0, 2, name='title', model_name='book')\n"], "sample_1110": ["def test_airyaiprime_airybiprime():\n    from sympy import airyaiprime, airybiprime\n\n    expr1 = airyaiprime(x)\n    expr2 = airybiprime(x)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr1) == 'scipy.special.airy(x)[1]'\n    assert prntr.doprint(expr2) == 'scipy.special.airy(x)[3]'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr1) == '  # Not supported in Python with NumPy:\\n  # airyaiprime\\nairyaiprime(x)'\n    assert prntr.doprint(expr2) == '  # Not supported in Python with NumPy:\\n  # airybiprime\\nairybiprime(x)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr1) == '  # Not supported in Python:\\n  # airyaiprime\\nairyaiprime(x)'\n    assert prntr.doprint(expr2) == '  # Not supported in Python:\\n  # airybiprime\\nairybiprime(x)'\n"], "sample_1032": ["def test_rewrite_as_Abs_with_constants():\n    from sympy.functions.elementary.complexes import Abs\n    assert Max(2, 3).rewrite(Abs) == 3\n    assert Min(2, 3).rewrite(Abs) == 2\n    assert Max(2, 3, 4).rewrite(Abs) == 4\n    assert Min(2, 3, 4).rewrite(Abs) == 2\n"], "sample_363": ["    def test_clear_file_input(self):\n        from selenium.webdriver.common.by import By\n        band = Band.objects.create(name='Linkin Park')\n        album = band.album_set.create(\n            name='Hybrid Theory', cover_art=r'albums\\hybrid_theory.jpg'\n        )\n        self.admin_login(username='super', password='secret', login_url='/')\n        self.selenium.get(self.live_server_url + reverse('admin:admin_widgets_album_change', args=(album.id,)))\n\n        # Check that the clear checkbox is not checked\n        clear_checkbox = self.selenium.find_element(By.ID, 'id_cover_art-clear')\n        self.assertFalse(clear_checkbox.is_selected())\n\n        # Check the clear checkbox\n        clear_checkbox.click()\n        self.assertTrue(clear_checkbox.is_selected())\n\n        # Save the form\n        with self.wait_page_loaded():\n            self.selenium.find_element(By.NAME, '_save').click()\n\n        # Check that the file field is empty\n        album.refresh_from_db()\n        self.assertFalse(album.cover_art)\n"], "sample_979": ["def test_matrix_symbol_subs():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = MatrixSymbol('C', p, p)\n\n    assert A.subs({n: p, m: p}) == MatrixSymbol('A', p, p)\n    assert (A*B).subs({B: C}) == A*C\n    assert (A*B).subs({l: n}) == A*MatrixSymbol('B', m, n)\n"], "sample_263": ["def test_dumpdata_with_invalid_format(self):\n    with self.assertRaisesMessage(management.CommandError, \"Unknown serialization format: invalid_format\"):\n        self._dumpdata_assert(['fixtures'], '', format='invalid_format')\n"], "sample_19": ["def test_celestial():\n    w = wcs.WCS(naxis=3)\n    w.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\", \"TIME\"]\n    w.wcs.set()\n    assert w.has_celestial\n    assert w.sub([wcs.WCSSUB_CELESTIAL]).is_celestial\n    assert np.allclose(w.wcs_pix2world([[1, 2, 3]], 0)[0, :2], w.celestial.wcs_pix2world([[1, 2]], 0)[0])\n"], "sample_30": ["def test_timesys_refposition_errors():\n    output = io.StringIO()\n    validate(get_pkg_data_filename(\"data/timesys_refposition_errors.xml\"), output, xmllint=False)\n    outstr = output.getvalue()\n    assert \"E24: Invalid refposition attribute 'bad-position'\" in outstr\n"], "sample_458": ["def test_large_numbers(self):\n    with localcontext() as ctx:\n        ctx.prec = 100\n        self.assertEqual(floatformat(1.23456789123456789123456789, 20), \"1.23456789123456789123\")\n        self.assertEqual(floatformat(123456789.123456789123456789, 20), \"123456789.123456789123\")\n        self.assertEqual(floatformat(123456789123456789.123456789123456789, 20), \"123456789123456789.123456789123\")\n"], "sample_925": ["def test_mock_object_attributes():\n    attributes = {'attr1': 'value1', 'attr2': 'value2'}\n    mock = _MockObject(attributes=attributes)\n\n    assert mock.attr1 == 'value1'\n    assert mock.attr2 == 'value2'\n    assert not hasattr(mock, 'attr3')\n"], "sample_506": ["def test_spines_bounds():\n    fig, ax = plt.subplots()\n    ax.spines['left'].set_bounds(-1, 1)\n    ax.spines['bottom'].set_bounds(0, 2)\n    ax.set_xlim([-2, 2])\n    ax.set_ylim([-2, 2])\n    assert ax.spines['left'].get_bounds() == (-1, 1)\n    assert ax.spines['bottom'].get_bounds() == (0, 2)\n"], "sample_255": ["def test_close_connection(self):\n    \"\"\"WSGIRequestHandler closes the connection if the 'Connection' header is 'close'.\"\"\"\n    request = WSGIRequest(self.request_factory.get('/').environ)\n    request.makefile = lambda *args, **kwargs: BytesIO()\n    handler = WSGIRequestHandler(request, '192.168.0.2', None)\n    handler.headers = {'Connection': 'close'}\n    handler.close_connection = False\n    handler.handle_one_request()\n    self.assertTrue(handler.close_connection)\n"], "sample_480": ["def test_key_transform_expression_wrapper(self):\n    self.assertCountEqual(\n        NullableJSONModel.objects.annotate(\n            expr=ExpressionWrapper(\n                KeyTransform(\"a\", \"value\"),\n                output_field=TextField(),\n            ),\n        ).filter(expr__isnull=False),\n        [self.objs[3], self.objs[4]],\n    )\n"], "sample_661": ["def test_record_testsuite_property_multiple_calls(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", \"all good\")\n            record_testsuite_property(\"version\", \"1.0\")\n\n            record_testsuite_property(\"stats\", \"still good\")\n            record_testsuite_property(\"version\", \"1.1\")\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p2_node = properties_node.find_nth_by_tag(\"property\", 1)\n    p3_node = properties_node.find_nth_by_tag(\"property\", 2)\n    p4_node = properties_node.find_nth_by_tag(\"property\", 3)\n    p1_node.assert_attr(name=\"stats\", value=\"all good\")\n    p2_node.assert_attr(name=\"version\", value=\"1.0\")\n    p3_node.assert_attr(name=\"stats\", value=\"still good\")\n    p4_node.assert_attr(name=\"version\", value=\"1.1\")\n"], "sample_837": ["def test_show_versions(capsys):\n    show_versions()\n    captured = capsys.readouterr()\n\n    assert \"System:\" in captured.out\n    assert \"BLAS:\" in captured.out\n    assert \"Python deps:\" in captured.out\n\n    sys_info = _get_sys_info()\n    deps_info = _get_deps_info()\n    blas_info = _get_blas_info()\n\n    for k in sys_info.keys():\n        assert k in captured.out\n\n    for k in deps_info.keys():\n        assert k in captured.out\n\n    for k in blas_info.keys():\n        assert k in captured.out\n"], "sample_469": ["def test_alias_with_m2m(self):\n    qs = Book.objects.alias(author_age=F(\"authors__age\")).filter(pk=self.b1.pk).order_by(\"author_age\")\n    self.assertEqual(qs[0].author_age, 34)\n    self.assertEqual(qs[1].author_age, 35)\n"], "sample_267": ["def test_disable_constraint_checking(self):\n    \"\"\"\n    Test that disable_constraint_checking() and enable_constraint_checking()\n    methods work as expected.\n    \"\"\"\n    with connection.cursor() as cursor:\n        cursor.execute('PRAGMA foreign_keys = ON')\n        self.assertTrue(connection.disable_constraint_checking())\n        cursor.execute('PRAGMA foreign_keys = OFF')\n        self.assertFalse(connection.disable_constraint_checking())\n        connection.enable_constraint_checking()\n        cursor.execute('PRAGMA foreign_keys = ON')\n        self.assertTrue(connection.disable_constraint_checking())\n"], "sample_364": ["    def test_path_inclusion_with_namespace(self):\n        match = resolve('/namespaced_urls/extra/something/')\n        self.assertEqual(match.url_name, 'namespaced-inner-extra')\n        self.assertEqual(match.kwargs, {'extra': 'something'})\n        self.assertEqual(match.namespace, 'namespaced')\n\n        url = reverse('namespaced:inner-extra', kwargs={'extra': 'something'})\n        self.assertEqual(url, '/namespaced_urls/extra/something/')\n"], "sample_1091": ["def test_issue_18188_multivariate():\n    from sympy.sets.conditionset import ConditionSet\n    result = Eq(x*cos(x) - 3*sin(x) + y, 0)\n    assert result.as_set() == ConditionSet((x, y), Eq(x*cos(x) - 3*sin(x) + y, 0), Reals)\n"], "sample_102": ["def test_union_with_different_fields(self):\n    qs1 = Number.objects.filter(num=1).values('num')\n    qs2 = Number.objects.filter(num=2).values('other_num')\n    with self.assertRaisesMessage(TypeError, \"Merging 'QuerySet' classes must involve the same values in each case.\"):\n        list(qs1.union(qs2))\n"], "sample_487": ["def test_actions_unique_with_different_names(self):\n    @admin.action(name=\"action1\")\n        pass\n\n    @admin.action(name=\"action2\")\n        pass\n\n    class BandAdmin(ModelAdmin):\n        actions = (action1, action2)\n\n    self.assertIsValid(BandAdmin, Band)\n"], "sample_1183": ["def test_Domain_is_zero():\n    assert ZZ.is_zero(ZZ(0)) == True\n    assert ZZ.is_zero(ZZ(1)) == False\n    assert QQ.is_zero(QQ(0)) == True\n    assert QQ.is_zero(QQ(1, 2)) == False\n    assert RR.is_zero(RR(0)) == True\n    assert RR.is_zero(RR(1e-50)) == False\n    assert CC.is_zero(CC(0)) == True\n    assert CC.is_zero(CC(1, 0)) == False\n    assert CC.is_zero(CC(0, 1)) == False\n"], "sample_316": ["    def test_image_dimensions(self):\n        img_path = os.path.join(os.path.dirname(__file__), \"test.png\")\n        with open(img_path, 'rb') as fh:\n            image = images.ImageFile(fh)\n            image_pil = Image.open(fh)\n            self.assertEqual(image.width, image_pil.width)\n            self.assertEqual(image.height, image_pil.height)\n"], "sample_524": ["def test_colorbar_set_formatter_locator_horizontal():\n    # check that the locator properties echo what is on the axis for horizontal colorbar\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc, orientation='horizontal')\n    cb.ax.xaxis.set_major_locator(FixedLocator(np.arange(10)))\n    cb.ax.xaxis.set_minor_locator(FixedLocator(np.arange(0, 10, 0.2)))\n    assert cb.locator is cb.ax.xaxis.get_major_locator()\n    assert cb.minorlocator is cb.ax.xaxis.get_minor_locator()\n    cb.ax.xaxis.set_major_formatter(LogFormatter())\n    cb.ax.xaxis.set_minor_formatter(LogFormatter())\n    assert cb.formatter is cb.ax.xaxis.get_major_formatter()\n    assert cb.minorformatter is cb.ax.xaxis.get_minor_formatter()\n\n    # check that the setter works as expected for horizontal colorbar\n    loc = FixedLocator(np.arange(7))\n    cb.locator = loc\n    assert cb.ax.xaxis.get_major_locator() is loc\n    loc = FixedLocator(np.arange(0, 7, 0.1))\n    cb.minorlocator = loc\n    assert cb.ax.xaxis.get_minor_locator() is loc\n    fmt = LogFormatter()\n    cb.formatter = fmt\n    assert cb.ax.xaxis.get_major_formatter() is fmt\n    fmt = LogFormatter()\n    cb.minorformatter = fmt\n    assert cb.ax.xaxis.get_minor_formatter() is fmt\n"], "sample_1074": ["def test_polycyclic_group():\n    G = PermutationGroup([Permutation(0,1,2), Permutation(0,2,3)])\n    P = G.polycyclic_group()\n    assert P.is_isomorphic(G)\n\n    G = AlternatingGroup(5)\n    P = G.polycyclic_group()\n    assert P.is_isomorphic(G)\n\n    G = SymmetricGroup(3)\n    P = G.polycyclic_group()\n    assert P.is_isomorphic(G)\n"], "sample_854": ["def test_svc_ovr_decision_function_shape():\n    # Test decision_function_shape='ovr' for SVC and NuSVC\n    X, y = make_blobs(n_samples=80, centers=5, random_state=0)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\n    for SVCClass in [svm.SVC, svm.NuSVC]:\n        clf = SVCClass(kernel='linear', C=0.1, decision_function_shape='ovr').fit(X_train, y_train)\n        dec = clf.decision_function(X_test)\n        assert dec.shape == (len(X_test), 5)\n        assert_array_equal(clf.predict(X_test), np.argmax(dec, axis=1))\n"], "sample_1101": ["def test_schur_number():\n    assert SchurNumber(1) == 1\n    assert SchurNumber(2) == 4\n    assert SchurNumber(3) == 13\n    assert SchurNumber(4) == 44\n    assert SchurNumber(5) == SchurNumber(5)\n    assert SchurNumber(6).lower_bound() == 364\n    raises(ValueError, lambda: SchurNumber(0))\n    raises(ValueError, lambda: SchurNumber(-1))\n    raises(ValueError, lambda: SchurNumber(S.Infinity))\n    x = symbols(\"x\")\n    raises(ValueError, lambda: SchurNumber(x))\n"], "sample_53": ["def test_render_options_with_custom_placeholder(self):\n    \"\"\"Custom placeholder is used if provided.\"\"\"\n    form = AlbumForm(initial={'band': None})\n    form.fields['band'].widget.placeholder = 'Select a band'\n    output = form.as_table()\n    self.assertIn('data-placeholder=\"Select a band\"', output)\n"], "sample_650": ["def test_log_auto_indent(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n\n        logger = logging.getLogger(__name__)\n\n            logger.warning('text\\\\nwith\\\\nmultiple\\\\nlines')\n            assert False\n        \"\"\"\n    )\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_auto_indent=True\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 1\n    result.stdout.fnmatch_lines(\n        [\n            \"WARNING  test_log_auto_indent:test_log_auto_indent.py:6 text\",\n            \"                             with\",\n            \"                             multiple\",\n            \"                             lines\",\n        ]\n    )\n"], "sample_553": ["def test_save_count_override_warnings_no_length(anim):\n    save_count = 5\n    frames = lambda: iter(range(2))\n    match_target = (\n        f'You passed in an explicit {save_count=} '\n        \"which is being ignored in favor of \"\n        f\"{save_count=}.\"\n    )\n\n    with pytest.warns(UserWarning, match=re.escape(match_target)):\n        anim = animation.FuncAnimation(\n            **{**anim, 'frames': frames, 'save_count': save_count}\n        )\n    assert anim._save_count == save_count\n    anim._init_draw()\n"], "sample_670": ["compilation error"], "sample_1096": ["def test_Indexed_derivative_with_array():\n    from sympy import NDimArray\n    i, j = symbols('i j', integer=True)\n    A = NDimArray([[1, 2], [3, 4]])\n    B = IndexedBase(A)\n    assert B[i, j].diff(B[i, j]) == 1\n    assert B[i, j].diff(B[i, j+1]) == 0\n    assert B[i, j].diff(B[i+1, j]) == 0\n    assert B[i, j].diff(B[i, j+1], B[i, j]) == 0\n    assert B[i, j].diff(B[i, j], B[i, j+1]) == 0\n    assert B[i, j].diff(B[i, j], B[i+1, j]) == 0\n    assert B[i, j].diff(B[i, j], B[i, j], B[i, j]) == 0\n"], "sample_871": ["def test_silhouette_samples_invalid_metric():\n    \"\"\"Check that silhouette_samples raises an error for invalid metrics.\"\"\"\n    X = np.array([[0.2, 0.1, 0.1, 0.2, 0.1, 1.6, 0.2, 0.1]], dtype=np.float32).T\n    y = [0, 0, 0, 0, 1, 1, 1, 1]\n    with pytest.raises(ValueError, match=\"Unknown metric\"):\n        silhouette_samples(X, y, metric=\"invalid_metric\")\n"], "sample_493": ["def test_aggregation_default_using_float_from_python(self):\n    result = Book.objects.filter(rating__lt=3.0).aggregate(\n        value=Sum(\"price\", default=0.0),\n    )\n    self.assertEqual(result[\"value\"], 0.0)\n"], "sample_893": ["def test_plot_tree_errors(pyplot):\n    # Check for errors of plot_tree\n    clf = DecisionTreeClassifier(max_depth=3, min_samples_split=2)\n\n    # Check not-fitted decision tree error\n    with pytest.raises(NotFittedError):\n        plot_tree(clf)\n\n    clf.fit(X, y)\n\n    # Check if it errors when length of feature_names\n    # mismatches with number of features\n    message = \"Length of feature_names, 1 does not match number of features, 2\"\n    with pytest.raises(ValueError, match=message):\n        plot_tree(clf, feature_names=[\"a\"])\n\n    message = \"Length of feature_names, 3 does not match number of features, 2\"\n    with pytest.raises(ValueError, match=message):\n        plot_tree(clf, feature_names=[\"a\", \"b\", \"c\"])\n\n    # Check error when argument is not an estimator\n    message = \"is not an estimator instance\"\n    with pytest.raises(TypeError, match=message):\n        plot_tree(clf.fit(X, y).tree_)\n\n    # Check class_names error\n    with pytest.raises(IndexError):\n        plot_tree(clf, class_names=[])\n\n    # Check precision error\n    with pytest.raises(ValueError, match=\"should be greater or equal\"):\n        plot_tree(clf, precision=-1)\n    with pytest.raises(ValueError, match=\"should be an integer\"):\n        plot_tree(clf, precision=\"1\")\n"], "sample_444": ["def test_template_tag_non_ascii(self):\n    relpath = self.hashed_file_path(\"cached/nonascii.css\")\n    self.assertEqual(relpath, \"cached/nonascii.55e7c226dda1.css\")\n    with storage.staticfiles_storage.open(relpath) as relfile:\n        content = relfile.read()\n        self.assertIn(b\"url('../cached/img/nonascii.acae32e4532b.png')\", content)\n    self.assertPostCondition()\n"], "sample_668": ["def test_fixture_positional_arguments_warning(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            pass\n\n            pass\n        \"\"\"\n    )\n\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*Passing arguments to pytest.fixture() as positional arguments is deprecated - pass them*\",\n            \"*as a keyword argument instead.*\",\n        ]\n    )\n"], "sample_718": ["def test_check_estimator_classifiers_regression_target():\n    # Check if classifier throws an exception when fed regression targets\n    from sklearn.datasets import load_boston\n    boston = load_boston()\n    X, y = boston.data, boston.target\n    e = BaseBadClassifier()\n    msg = 'Unknown label type: '\n    assert_raises_regex(ValueError, msg, e.fit, X, y)\n"], "sample_280": ["def test_aggregation_default_using_float_from_python(self):\n    result = Book.objects.filter(rating__lt=3.0).aggregate(\n        value=Sum('pages', default=0.0),\n    )\n    self.assertEqual(result['value'], 0.0)\n"], "sample_949": ["def test_config_values(app, status, warning):\n    app.builder.build_all()\n    content = (app.outdir / 'python.1').read_text()\n\n    assert 'Custom Title' in content\n    assert 'Custom Description' in content\n    assert 'Custom Author' in content\n    assert '2' in content  # Custom section\n"], "sample_367": ["    def test_cache_page_decorator_http_request(self):\n        class MyClass:\n            @cache_page(60)\n                return HttpResponse()\n\n        request = HttpRequest()\n        response = MyClass().a_view(request)\n        self.assertIsInstance(response, HttpResponse)\n\n        # Test with a different key_prefix\n        class MyClass2:\n            @cache_page(60, key_prefix=\"test\")\n                return HttpResponse()\n\n        response2 = MyClass2().a_view(request)\n        self.assertIsInstance(response2, HttpResponse)\n"], "sample_713": ["def test_ridge_classifier_cv_no_support_multilabel():\n    X, y = make_multilabel_classification(n_samples=10, random_state=0)\n    assert_raises(ValueError, RidgeClassifierCV().fit, X, y)\n"], "sample_281": ["def test_custom_paginator(self):\n    \"\"\"Custom paginator can be used.\"\"\"\n    class CustomPaginatorQuestionAdmin(QuestionAdmin):\n        paginator = Paginator\n\n    Question.objects.bulk_create(Question(question=str(i)) for i in range(PAGINATOR_SIZE + 10))\n    # The first page of results.\n    request = self.factory.get(self.url, {'term': '', **self.opts})\n    request.user = self.superuser\n    with model_admin(Question, CustomPaginatorQuestionAdmin):\n        response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    self.assertEqual(response.status_code, 200)\n    data = json.loads(response.content.decode('utf-8'))\n    self.assertEqual(data, {\n        'results': [{'id': str(q.pk), 'text': q.question} for q in Question.objects.all()[:PAGINATOR_SIZE]],\n        'pagination': {'more': True},\n    })\n    # The second page of results.\n    request = self.factory.get(self.url, {'term': '', 'page': '2', **self.opts})\n    request.user = self.superuser\n    with model_admin(Question, CustomPaginatorQuestionAdmin):\n        response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    self.assertEqual(response.status_code, 200)\n    data = json.loads(response.content.decode('utf-8'))\n    self.assertEqual(data, {\n        'results': [{'id': str(q.pk), 'text': q.question} for q in Question.objects.all()[PAGINATOR_SIZE:]],\n        'pagination': {'more': False},\n    })\n"], "sample_905": ["def test_is_builtin_class_method():\n    class MyInt(int):\n            pass\n\n    assert inspect.is_builtin_class_method(MyInt, 'my_method') is False\n    assert inspect.is_builtin_class_method(int, '__init__') is True\n"], "sample_683": ["def test_encodedfile_readline(tmpfile: BinaryIO) -> None:\n    ef = capture.EncodedFile(tmpfile, encoding=\"utf-8\")\n    ef.write(\"line1\\nline2\")\n    ef.flush()\n    tmpfile.seek(0)\n    assert ef.readline() == \"line1\\n\"\n    assert ef.readline() == \"line2\"\n    assert ef.readline() == \"\"\n    tmpfile.close()\n    with pytest.raises(ValueError):\n        ef.write(\"line3\")\n"], "sample_1054": ["def test_ComplexRegion_from_real():\n    unit = Interval(0, 1)\n    assert ComplexRegion.from_real(unit) == ComplexRegion(unit * FiniteSet(0))\n\n    raises(ValueError, lambda: ComplexRegion.from_real(S.Complexes))\n"], "sample_1182": ["def test_log1p_and_expm1():\n    expr1 = log1p(x)\n    expr2 = expm1(x)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr1) == 'scipy.special.log1p(x)'\n    assert prntr.doprint(expr2) == 'scipy.special.expm1(x)'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr1) == 'numpy.log1p(x)'\n    assert prntr.doprint(expr2) == 'numpy.expm1(x)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr1) == 'math.log1p(x)'\n    assert prntr.doprint(expr2) == 'expm1(x)'\n\n    prntr = MpmathPrinter()\n    assert prntr.doprint(expr1) == 'mpmath.log1p(x)'\n    assert prntr.doprint(expr2) == 'mpmath.expm1(x)'\n"], "sample_1160": ["def test_issue_18999():\n    assert Range(n, oo).is_finite_set is False\n    assert Range(-oo, n).is_finite_set is False\n    assert Range(n, -oo).is_finite_set is True\n    assert Range(oo, n).is_finite_set is True\n"], "sample_1006": ["def test_subfactorial():\n    n = Symbol('n', integer=True)\n    assert subfactorial(0) == 1\n    assert subfactorial(1) == 0\n    assert subfactorial(2) == 1\n    assert subfactorial(3) == 2\n    assert subfactorial(4) == 9\n    assert subfactorial(5) == 44\n    assert subfactorial(n).func == subfactorial\n    assert subfactorial(n).is_integer is None\n    assert subfactorial(n).is_nonnegative is None\n    assert subfactorial(n).is_even is None\n    assert subfactorial(n).is_odd is None\n    assert subfactorial(n).rewrite(uppergamma) == uppergamma(n + 1, -1)/S.Exp1\n"], "sample_208": ["def test_add_model_with_field_removed_from_base_model_and_altered(self):\n    \"\"\"\n    Removing a base field, altering it, and adding a new inherited model that\n    has a field with the same name are all handled correctly.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=300)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n        ], bases=('app.readable',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['AlterField', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n"], "sample_233": ["def test_token_with_different_algorithm(self):\n    \"\"\"\n    A valid token can be created with a different algorithm by\n    using the PasswordResetTokenGenerator.algorithm attribute.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    new_algorithm = 'sha256'\n    # Create and check a token with a different algorithm.\n    p0 = PasswordResetTokenGenerator()\n    p0.algorithm = new_algorithm\n    tk0 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk0), True)\n    # Create and check a token with the default algorithm.\n    p1 = PasswordResetTokenGenerator()\n    self.assertEqual(p1.algorithm, settings.DEFAULT_HASHING_ALGORITHM)\n    self.assertNotEqual(p1.algorithm, new_algorithm)\n    tk1 = p1.make_token(user)\n    # Tokens created with a different algorithm don't validate.\n    self.assertIs(p0.check_token(user, tk1), False)\n    self.assertIs(p1.check_token(user, tk0), False)\n"], "sample_496": ["def test_custom_project_template_with_non_ascii_templates_in_filename(self):\n    \"\"\"\n    The startproject management command is able to render templates with\n    non-ASCII content in the filename.\n    \"\"\"\n    template_path = os.path.join(custom_templates_dir, 'project_template')\n    args = ['startproject', '--template', template_path, '--extension=txt', 'customtestproject']\n    testproject_dir = os.path.join(self.test_dir, 'customtestproject')\n    self.addCleanup(shutil.rmtree, testproject_dir, True)\n\n    out, err = self.run_django_admin(args)\n    self.assertNoOutput(err)\n    self.assertTrue(os.path.isdir(testproject_dir))\n    path = os.path.join(testproject_dir, 'ticket-18091-non-ascii-template-\u00e9.txt')\n    with codecs.open(path, 'r', encoding='utf-8') as f:\n        self.assertEqual(f.read().splitlines(False), [\n            'Some non-ASCII text for testing ticket #18091:',\n            '\u00fc\u00e4\u00f6 \u20ac'])\n"], "sample_190": ["def test_exact_query_rhs_with_selected_columns_and_limit(self):\n    newest_author = Author.objects.create(name='Author 3')\n    authors_max_ids = Author.objects.filter(\n        name='Author 3',\n    ).values(\n        'name',\n    ).annotate(\n        max_id=Max('id'),\n    ).values('max_id')[:1]\n    authors = Author.objects.filter(id=authors_max_ids)\n    self.assertEqual(authors.get(), newest_author)\n"], "sample_841": ["def test_ridge_classifier_cv_no_support_multilabel():\n    X, y = make_multilabel_classification(n_samples=10, random_state=0)\n    assert_raises(ValueError, RidgeClassifierCV().fit, X, y)\n"], "sample_876": ["def test_mlp_warm_start_with_different_data():\n    \"\"\"Check that warm start works with different data.\"\"\"\n    mlp = MLPClassifier(max_iter=10, random_state=0, warm_start=True)\n    mlp.fit(X_iris, y_iris)\n    n_iter_ = mlp.n_iter_\n    mlp.fit(X_iris[:50], y_iris[:50])\n    assert mlp.n_iter_ > n_iter_\n"], "sample_145": ["def test_actions_unique_with_different_names(self):\n        action1.__name__ = 'action1'\n        pass\n\n        action2.__name__ = 'action2'\n        pass\n\n    class BandAdmin(ModelAdmin):\n        actions = (action1, action2)\n\n    self.assertIsValid(BandAdmin, Band)\n"], "sample_479": ["def test_create_model_add_index(self):\n    \"\"\"\n    AddIndex should optimize into CreateModel.\n    \"\"\"\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                \"Foo\", [(\"name\", models.CharField(max_length=255))]\n            ),\n            migrations.AddIndex(\"Foo\", models.Index(fields=[\"name\"], name=\"idx_name\")),\n        ],\n        [\n            migrations.CreateModel(\n                \"Foo\",\n                [(\"name\", models.CharField(max_length=255))],\n                options={\"indexes\": [models.Index(fields=[\"name\"], name=\"idx_name\")]},\n            ),\n        ],\n    )\n"], "sample_313": ["def test_django_path_excluded(self):\n    self.assertSetEqual(\n        autoreload.get_template_directories(),\n        {\n            EXTRA_TEMPLATES_DIR,\n        }\n    )\n"], "sample_258": ["def test_receiver_sender_specific(self):\n    @receiver(a_signal, sender=self)\n        self.state = val\n\n    self.state = False\n    a_signal.send(sender=self, val=True)\n    self.assertTrue(self.state)\n\n    self.state = False\n    a_signal.send(sender=object(), val=True)\n    self.assertFalse(self.state)\n"], "sample_645": ["def test_caplog_captures_for_all_stages_with_exception(caplog, logging_during_setup_and_teardown):\n    try:\n        raise Exception(\"Test exception\")\n    except Exception:\n        logger.exception(\"Exception occurred\")\n\n    assert [x.message for x in caplog.get_records(\"call\")] == [\"Exception occurred\"]\n    assert [x.message for x in caplog.get_records(\"setup\")] == [\"a_setup_log\"]\n    assert set(caplog._item.stash[caplog_records_key]) == {\"setup\", \"call\"}\n"], "sample_501": ["def test_legend_title_fontprop_dict():\n    # test the title_fontproperties kwarg with a dict\n    plt.plot(range(10))\n    leg = plt.legend(title='Aardvark', title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg.get_title().get_fontproperties().get_family() == ['serif']\n    assert leg.get_title().get_fontproperties().get_size() == 22\n"], "sample_1144": ["def test_requires_partial_with_derivative():\n    x, y = symbols('x y')\n    f = Derivative(x**2, x)\n    assert requires_partial(Derivative(f, x)) is False\n    assert requires_partial(Derivative(f, y)) is True\n"], "sample_991": ["def test_product_with_zero_factor():\n    assert product(0, (k, 1, n)) == 0\n    assert product(k*0, (k, 1, n)) == 0\n    assert product(k, (k, 1, n), (k, 0, m)) == 0\n"], "sample_144": ["def test_create_new_instance_with_explicit_pk(self):\n    p1 = Profile.objects.create(username='john', pk=100)\n    p2 = User.objects.get(pk=100).profile\n    # Create a new profile by setting pk = None and providing an explicit pk.\n    p2.pk = None\n    p2.user_ptr_id = None\n    p2.username = 'bill'\n    p2.save(force_insert=True, pk=200)\n    self.assertEqual(Profile.objects.count(), 2)\n    self.assertEqual(User.objects.get(pk=100).username, 'john')\n    self.assertEqual(User.objects.get(pk=200).username, 'bill')\n"], "sample_749": ["def test_column_transformer_remainder_transformer_error():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n\n    # remainder transformer that raises an error\n    class TransRaise(BaseEstimator):\n            raise ValueError(\"specific message\")\n\n            raise ValueError(\"specific message\")\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])], remainder=TransRaise())\n    assert_raise_message(ValueError, \"specific message\", ct.fit, X_array)\n    assert_raise_message(ValueError, \"specific message\", ct.fit_transform, X_array)\n"], "sample_1016": ["def test_octave_user_functions():\n    f = Function('f')\n    g = Function('g')\n    custom_functions = {\n        \"f\": \"existing_octave_fcn\",\n        \"g\": [(lambda x: x.is_Matrix, \"my_mat_fcn\"),\n              (lambda x: not x.is_Matrix, \"my_fcn\")]\n    }\n    mat = Matrix([[1, x]])\n    assert mcode(f(x) + g(x) + g(mat), user_functions=custom_functions) == 'existing_octave_fcn(x) + my_fcn(x) + my_mat_fcn([1 x])'\n"], "sample_131": ["    def test_migrate_test_setting_true(self, mocked_migrate, mocked_ensure_connection):\n        creation = connection.creation_class(connection)\n        saved_settings = copy.deepcopy(connection.settings_dict)\n        try:\n            connection.settings_dict['TEST']['MIGRATE'] = True\n            with mock.patch.object(creation, '_create_test_db'):\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n            mocked_migrate.assert_called_once()\n        finally:\n            connection.settings_dict = saved_settings\n"], "sample_256": ["def test_password_change_form_validates_password(self):\n    user = User.objects.get(username='testclient')\n    data = {\n        'old_password': 'password',\n        'new_password1': 'testclient',\n        'new_password2': 'testclient',\n    }\n    form = PasswordChangeForm(user, data)\n    self.assertFalse(form.is_valid())\n    self.assertEqual(len(form[\"new_password2\"].errors), 2)\n    self.assertIn('The password is too similar to the username.', form[\"new_password2\"].errors)\n    self.assertIn(\n        'This password is too short. It must contain at least 12 characters.',\n        form[\"new_password2\"].errors\n    )\n"], "sample_331": ["    def test_parse_datetime_invalid_inputs(self):\n        invalid_inputs = (\n            '2012-04-56T09:15:90',  # Invalid date\n            '2012-04-23T25:15:00',  # Invalid hour\n            '2012-04-23T09:60:00',  # Invalid minute\n            '2012-04-23T09:15:60',  # Invalid second\n            '2012-04-23T09:15:00+25',  # Invalid timezone offset\n            '2012-04-23T09:15:00+25:60',  # Invalid timezone offset\n        )\n        for source in invalid_inputs:\n            with self.subTest(source=source):\n                with self.assertRaises(ValueError):\n                    parse_datetime(source)\n"], "sample_217": ["def test_media_inheritance_with_empty_media(self):\n    # If a widget extends another and defines an empty media, it should not inherit the parent widget's media\n    class MyWidget1(TextInput):\n        class Media:\n            css = {\n                'all': ('path/to/css1', '/path/to/css2')\n            }\n            js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')\n\n    class MyWidget13(MyWidget1):\n        class Media:\n            pass\n\n    w13 = MyWidget13()\n    self.assertEqual(str(w13.media), '')\n"], "sample_981": ["def test_commutes_with():\n    p = Permutation([1, 5, 2, 0, 3, 6, 4])\n    q = Permutation([[1, 2, 3, 5, 6], [0, 4]])\n    assert p.commutes_with(q) == False\n    assert q.commutes_with(p) == False\n    r = Permutation([0, 1, 2, 3])\n    assert r.commutes_with(r) == True\n"], "sample_1003": ["def test_Gen_preprocess():\n    assert Gen.preprocess(x) == x\n    assert Gen.preprocess(0) == 0\n\n    raises(OptionError, lambda: Gen.preprocess('x'))\n"], "sample_997": ["def test_convert_xor():\n    from sympy.parsing.sympy_parser import convert_xor\n    transformations = standard_transformations + (convert_xor,)\n    x = Symbol('x')\n    y = Symbol('y')\n    assert parse_expr(\"x^y\", transformations=transformations) == x**y\n"], "sample_558": ["def test_grid_set_label_mode():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 2))\n    grid.set_label_mode(\"all\")\n    for ax in grid.axes_all:\n        assert not ax.axis[\"bottom\"].get_ticklabels()[0].get_visible()\n        assert not ax.axis[\"left\"].get_ticklabels()[0].get_visible()\n    grid.set_label_mode(\"L\")\n    for ax in grid.axes_column[0][:-1]:\n        assert not ax.axis[\"bottom\"].get_ticklabels()[0].get_visible()\n        assert ax.axis[\"left\"].get_ticklabels()[0].get_visible()\n    for col in grid.axes_column[1:]:\n        for ax in col[:-1]:\n            assert ax.axis[\"bottom\"].get_ticklabels()[0].get_visible()\n            assert ax.axis[\"left\"].get_ticklabels()[0].get_visible()\n        ax = col[-1]\n        assert not ax.axis[\"bottom\"].get_ticklabels()[0].get_visible()\n        assert ax.axis[\"left\"].get_ticklabels()[0].get_visible()\n    grid.set_label_mode(\"1\")\n    for ax in grid.axes_all[:-1]:\n        assert ax.axis[\"bottom\"].get_ticklabels()[0].get_visible()\n        assert ax.axis[\"left\"].get_ticklabels()[0].get_visible()\n    ax = grid.axes_all[-1]\n    assert not ax.axis[\"bottom\"].get_ticklabels()[0].get_visible()\n    assert not ax.axis[\"left\"].get_ticklabels()[0].get_visible()\n"], "sample_1098": ["def test_appellf1_derivative_parameters():\n    from sympy import diff\n    a, b1, b2, c, x, y = symbols('a b1 b2 c x y')\n    assert diff(appellf1(a, b1, b2, c, x, y), a) == Derivative(appellf1(a, b1, b2, c, x, y), a)\n    assert diff(appellf1(a, b1, b2, c, x, y), b1) == Derivative(appellf1(a, b1, b2, c, x, y), b1)\n    assert diff(appellf1(a, b1, b2, c, x, y), b2) == Derivative(appellf1(a, b1, b2, c, x, y), b2)\n    assert diff(appellf1(a, b1, b2, c, x, y), c) == Derivative(appellf1(a, b1, b2, c, x, y), c)\n"], "sample_746": ["def test_log_loss_single_class():\n    # Test log loss with a single class\n    y_true = [0, 0, 0]\n    y_pred = [[1, 0], [1, 0], [1, 0]]\n    error_str = ('y_true contains only one label (0). Please provide '\n                 'the true labels explicitly through the labels argument.')\n    assert_raise_message(ValueError, error_str, log_loss, y_true, y_pred)\n\n    # Works when the labels argument is used\n    loss = log_loss(y_true, y_pred, labels=[0, 1])\n    assert_almost_equal(loss, 0.0)\n"], "sample_244": ["def test_formset_with_custom_error_messages(self):\n    \"\"\"\n    Formsets can have custom error messages.\n    \"\"\"\n    data = {\n        'drinks-TOTAL_FORMS': '2',  # the number of forms rendered\n        'drinks-INITIAL_FORMS': '0',  # the number of forms with initial data\n        'drinks-MIN_NUM_FORMS': '0',  # min number of forms\n        'drinks-MAX_NUM_FORMS': '0',  # max number of forms\n        'drinks-0-name': 'Gin and Tonic',\n        'drinks-1-name': 'Gin and Tonic',\n    }\n    custom_error_messages = {'missing_management_form': 'Custom management form error'}\n    formset = FavoriteDrinksFormSet(data, prefix='drinks', error_messages=custom_error_messages)\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(formset.non_form_errors(), ['You may only specify a drink once.'])\n    self.assertEqual(formset.error_messages['missing_management_form'], 'Custom management form error')\n"], "sample_884": ["def test_pickle_deprecated():\n    # Test if deprecated classes and functions can be pickled and unpickled\n    mock_class1 = MockClass1()\n    pickled_mock_class1 = pickle.dumps(mock_class1)\n    unpickled_mock_class1 = pickle.loads(pickled_mock_class1)\n    assert isinstance(unpickled_mock_class1, MockClass1)\n\n    mock_function_result = mock_function()\n    pickled_mock_function = pickle.dumps(mock_function)\n    unpickled_mock_function = pickle.loads(pickled_mock_function)\n    assert unpickled_mock_function() == mock_function_result\n"], "sample_264": ["def test_legacy_hash_invalid(self):\n    # Test that the legacy hash function returns None for invalid data\n    storage = self.storage_class(self.get_request())\n    invalid_data = 'invalid_data'\n    self.assertIsNone(storage._legacy_decode(invalid_data))\n"], "sample_127": ["def test_bulk_create_ignore_conflicts(self):\n    # Create some initial data\n    Country.objects.bulk_create(self.data[:2])\n\n    # Try to bulk create the same data again, but this time ignore conflicts\n    Country.objects.bulk_create(self.data[:2], ignore_conflicts=True)\n\n    # The count should still be 2, as the duplicates were ignored\n    self.assertEqual(Country.objects.count(), 2)\n"], "sample_951": ["def test_is_builtin_class_method_with_custom_class():\n    class CustomClass:\n            pass\n\n    assert inspect.is_builtin_class_method(CustomClass, 'custom_method') is False\n"], "sample_838": ["def test_column_transformer_with_empty_transformer_list():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n\n    ct = ColumnTransformer([])\n    assert_raise_message(ValueError, \"No transformers were specified\",\n                         ct.fit, X_array)\n    assert_raise_message(ValueError, \"No transformers were specified\",\n                         ct.fit_transform, X_array)\n"], "sample_475": ["def test_actions_unique_with_different_names(self):\n    @admin.action(description=\"Action 1\")\n        pass\n\n    @admin.action(description=\"Action 2\")\n        pass\n\n    class BandAdmin(ModelAdmin):\n        actions = (action1, action2)\n\n    self.assertIsValid(BandAdmin, Band)\n"], "sample_404": ["def test_compile_filter_expression_error_in_extended_template(self):\n    \"\"\"\n    Errors raised while compiling filter expressions in extended templates\n    should include the token information.\n    \"\"\"\n    engine = self._engine(app_dirs=True)\n    t = engine.get_template(\"test_extends_filter_error.html\")\n    with self.assertRaises(TemplateSyntaxError) as e:\n        t.render(Context())\n    if self.debug_engine:\n        self.assertEqual(e.exception.template_debug[\"during\"], \"{{ foo@bar }}\")\n"], "sample_149": ["    def test_is_anonymous_authenticated_properties(self):\n        \"\"\"\n        <User Model>.is_anonymous/is_authenticated can be properties.\n        \"\"\"\n        class CustomUserWithProperties(AbstractBaseUser):\n            username = models.CharField(max_length=30, unique=True)\n            USERNAME_FIELD = 'username'\n\n            @property\n                return False\n\n            @property\n                return True\n\n        errors = checks.run_checks(app_configs=self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n"], "sample_830": ["def test_show_versions(capsys):\n    show_versions()\n    captured = capsys.readouterr()\n\n    assert \"System:\" in captured.out\n    assert \"BLAS:\" in captured.out\n    assert \"Python deps:\" in captured.out\n\n    sys_info = _get_sys_info()\n    deps_info = _get_deps_info()\n    blas_info = _get_blas_info()\n\n    for k in sys_info.keys():\n        assert k in captured.out\n\n    for k in deps_info.keys():\n        assert k in captured.out\n\n    for k in blas_info.keys():\n        assert k in captured.out\n"], "sample_414": ["def test_ForeignKey_with_uuid(self):\n    from selenium.webdriver.common.by import By\n\n    band_with_uuid = Band.objects.create(name=\"UUID Band\", uuid=\"123e4567-e89b-12d3-a456-426614174000\")\n    self.admin_login(username=\"super\", password=\"secret\", login_url=\"/\")\n    self.selenium.get(\n        self.live_server_url + reverse(\"admin:admin_widgets_event_add\")\n    )\n    main_window = self.selenium.current_window_handle\n\n    # Open the popup window and click on a band with UUID\n    self.selenium.find_element(By.ID, \"lookup_id_main_band\").click()\n    self.wait_for_and_switch_to_popup()\n    link = self.selenium.find_element(By.LINK_TEXT, \"UUID Band\")\n    self.assertIn(\"/band/123e4567-e89b-12d3-a456-426614174000/\", link.get_attribute(\"href\"))\n    link.click()\n\n    # The field now contains the selected band's UUID\n    self.selenium.switch_to.window(main_window)\n    self.wait_for_value(\"#id_main_band\", \"123e4567-e89b-12d3-a456-426614174000\")\n"], "sample_321": ["def test_https_good_referer_matches_cookie_domain_with_port_in_host(self):\n    \"\"\"\n    A POST HTTPS request with a good referer should be accepted from a\n    subdomain that's allowed by SESSION_COOKIE_DOMAIN and a port in the host.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_HOST'] = 'www.example.com:8000'\n    req.META['HTTP_REFERER'] = 'https://foo.example.com:8000/'\n    req.META['SERVER_PORT'] = '443'\n    mw = CsrfViewMiddleware(post_form_view)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n"], "sample_714": ["def test_log_loss_with_sample_weight():\n    # case when sample_weight is provided\n    y_true = [0, 1, 2, 0]\n    y_pred = [[0.2, 0.7, 0.1], [0.6, 0.2, 0.2], [0.6, 0.1, 0.3], [0.2, 0.7, 0.1]]\n    sample_weight = [1, 2, 3, 4]\n    loss = log_loss(y_true, y_pred, sample_weight=sample_weight, normalize=False)\n    assert_almost_equal(loss, 10.6904911, decimal=6)\n"], "sample_622": ["def test_decode_cf_variable_with_invalid_units() -> None:\n    v = Variable([\"t\"], [1, 2, 3], {\"units\": \"invalid_units\"})\n    with pytest.raises(ValueError, match=\"unable to decode time\"):\n        conventions.decode_cf_variable(\"test\", v)\n"], "sample_1051": ["def test_dotprint_styles():\n    styles = [(Basic, {'color': 'red', 'shape': 'box'}),\n              (Expr,  {'color': 'green'})]\n    text = dotprint(x + 2, styles=styles)\n    assert '\"color\"=\"red\"' in text\n    assert '\"color\"=\"green\"' in text\n    assert '\"shape\"=\"box\"' in text\n"], "sample_495": ["def test_paginator_with_orphans(self):\n    \"\"\"\n    Tests the paginator attributes with orphans using varying inputs.\n    \"\"\"\n    nine = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    ten = nine + [10]\n    eleven = ten + [11]\n    tests = (\n        # Each item is two tuples:\n        #     First tuple is Paginator parameters - object_list, per_page,\n        #         orphans, and allow_empty_first_page.\n        #     Second tuple is resulting Paginator attributes - count,\n        #         num_pages, and page_range.\n        # Ten items, varying orphans, no empty first page.\n        ((ten, 4, 3, False), (10, 2, [1, 2])),\n        ((ten, 4, 6, False), (10, 1, [1])),\n        # Eleven items, varying orphans, no empty first page.\n        ((eleven, 4, 3, False), (11, 3, [1, 2, 3])),\n        ((eleven, 4, 6, False), (11, 2, [1, 2])),\n    )\n    for params, output in tests:\n        self.check_paginator(params, output)\n"], "sample_589": ["def test_interpolate_na_max_gap_time_specifier_dataset(ds, time_range_func):\n    ds[\"time\"] = time_range_func(\"2001-01-01\", freq=\"H\", periods=11)\n    expected = ds.copy()\n    expected[\"var1\"] = ds[\"var1\"].copy(data=[np.nan, 1, 2, 3, 4, 5, np.nan, np.nan, np.nan, np.nan, 10])\n    actual = ds.interpolate_na(\"time\", max_gap=\"3H\")\n    assert_equal(actual, expected)\n"], "sample_353": ["def test_fields_with_fk_non_interactive(self):\n    new_io = StringIO()\n    group = Group.objects.create(name='mygroup')\n    email = Email.objects.create(email='mymail@gmail.com')\n    call_command(\n        'createsuperuser',\n        interactive=False,\n        username=email.pk,\n        email=email.email,\n        group=group.pk,\n        stdout=new_io,\n    )\n    command_output = new_io.getvalue().strip()\n    self.assertEqual(command_output, 'Superuser created successfully.')\n    u = CustomUserWithFK._default_manager.get(email=email)\n    self.assertEqual(u.username, email)\n    self.assertEqual(u.group, group)\n"], "sample_95": ["def test_vary_on_headers_decorator(self):\n    \"\"\"\n    Ensures @vary_on_headers properly sets the Vary header.\n    \"\"\"\n    @vary_on_headers('Accept-Language', 'User-Agent')\n        return HttpResponse()\n    r = a_view(HttpRequest())\n    self.assertEqual(r['Vary'], 'Accept-Language, User-Agent')\n"], "sample_113": ["def test_replace_named_groups(self):\n    self.assertEqual(utils.replace_named_groups(r'^(?P<a>\\w+)/b/(\\w+)$'), r'^<a>/b/(\\w+)$')\n    self.assertEqual(utils.replace_named_groups(r'^(?P<a>\\w+)/b/(?P<c>\\w+)/$'), r'^<a>/b/<c>/$')\n    self.assertEqual(utils.replace_named_groups(r'^(?P<a>\\w+)/b/(\\w+)'), r'^<a>/b/(\\w+)')\n    self.assertEqual(utils.replace_named_groups(r'^(?P<a>\\w+)/b/(?P<c>\\w+)'), r'^<a>/b/<c>')\n"], "sample_944": ["def test_stringify_type_hints_Ellipsis():\n    assert stringify(...) == \"...\"\n"], "sample_37": ["def test_to_fits_2():\n    \"\"\"\n    Test to_fits() with SIP distortion.\n    \"\"\"\n    fits_name = get_pkg_data_filename('data/sip.fits')\n    w = wcs.WCS(fits_name)\n    wfits = w.to_fits()\n    assert isinstance(wfits, fits.HDUList)\n    assert isinstance(wfits[0], fits.PrimaryHDU)\n    assert isinstance(wfits[1], fits.ImageHDU)\n"], "sample_878": ["def test_column_transformer_with_transformer_weights():\n    pd = pytest.importorskip(\"pandas\")\n    X_df = pd.DataFrame(\n        {\n            \"col_int\": np.array([0, 1, 2], dtype=int),\n            \"col_float\": np.array([0.0, 1.0, 2.0], dtype=float),\n            \"col_cat\": [\"one\", \"two\", \"one\"],\n            \"col_str\": [\"low\", \"middle\", \"high\"],\n        },\n        columns=[\"col_int\", \"col_float\", \"col_cat\", \"col_str\"],\n    )\n    X_df[\"col_str\"] = X_df[\"col_str\"].astype(\"category\")\n\n    cat_selector = make_column_selector(dtype_include=[\"category\", object])\n    num_selector = make_column_selector(dtype_include=np.number)\n\n    ohe = OneHotEncoder()\n    scaler = StandardScaler()\n\n    ct_selector = make_column_transformer(\n        (ohe, cat_selector), (scaler, num_selector), transformer_weights={\"ohe\": 0.5, \"scaler\": 0.5}\n    )\n    ct_direct = make_column_transformer(\n        (ohe, [\"col_cat\", \"col_str\"]), (scaler, [\"col_float\", \"col_int\"]), transformer_weights={\"ohe\": 0.5, \"scaler\": 0.5}\n    )\n\n    X_selector = ct_selector.fit_transform(X_df)\n    X_direct = ct_direct.fit_transform(X_df)\n\n    assert_allclose(X_selector, X_direct)\n"], "sample_143": ["def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('CamelCaseExample'), 'camel case example')\n    self.assertEqual(text.camel_case_to_spaces('AnotherExample'), 'another example')\n    self.assertEqual(text.camel_case_to_spaces('NoCamelCase'), 'no camel case')\n    self.assertEqual(text.camel_case_to_spaces(''), '')\n    self.assertEqual(text.camel_case_to_spaces('AllCaps'), 'all caps')\n    self.assertEqual(text.camel_case_to_spaces('lazystrExample'), 'lazystr example')\n"], "sample_502": ["def test_subplot_mosaic_empty_sentinel():\n    fig, ax_dict = plt.subplot_mosaic({'a': ['b', 'c'], 'd': ['e', 'f']}, empty_sentinel='.')\n    assert 'a' not in ax_dict\n    assert 'd' not in ax_dict\n    assert isinstance(ax_dict['b'], plt.Axes)\n    assert isinstance(ax_dict['c'], plt.Axes)\n    assert isinstance(ax_dict['e'], plt.Axes)\n    assert isinstance(ax_dict['f'], plt.Axes)\n"], "sample_158": ["def test_foreign_object_to_unique_field_with_unique_together(self):\n    class Person(models.Model):\n        country_id = models.IntegerField()\n        city_id = models.IntegerField()\n\n        class Meta:\n            unique_together = (('country_id', 'city_id'),)\n\n    class MMembership(models.Model):\n        person_country_id = models.IntegerField()\n        person_city_id = models.IntegerField()\n        person = models.ForeignObject(\n            Person,\n            on_delete=models.CASCADE,\n            from_fields=['person_country_id', 'person_city_id'],\n            to_fields=['country_id', 'city_id'],\n        )\n\n    field = MMembership._meta.get_field('person')\n    self.assertEqual(field.check(), [])\n"], "sample_1111": ["def test_sqrt_function():\n    x = Symbol('x')\n    lines = [\n        '      1 |                                                     ..',\n        '        |                                                  ...  ',\n        '        |                                                ..     ',\n        '        |                                             ...       ',\n        '        |                                          ...          ',\n        '        |                                        ..             ',\n        '        |                                     ...               ',\n        '        |                                  ...                  ',\n        '        |                                ..                     ',\n        '        |                             ...                       ',\n        '      0 |-------------------------------------------------------',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '        |                                                       ',\n        '      0 |_______________________________________________________',\n        '        0                          0.5                        1'\n    ]\n    assert lines == list(textplot_str(sqrt(x), 0, 1))\n"], "sample_40": ["def test_with_H0():\n    H0 = 70 * u.km / u.s / u.Mpc\n    q = 1 * u.littleh\n    assert_quantity_allclose(q.to(u.Mpc, u.with_H0(H0)), 1 / H0.value * u.Mpc)\n    assert_quantity_allclose(q.to(u.Mpc, u.with_H0()), 1 / cosmology.default_cosmology.get().H0.value * u.Mpc)\n"], "sample_580": ["def test_categorical_order():\n\n    s = pd.Series([\"b\", \"c\", \"a\", \"b\", \"c\", \"a\"])\n    assert categorical_order(s) == [\"b\", \"c\", \"a\"]\n\n    s = pd.Series([3, 2, 1, 2, 3, 1])\n    assert categorical_order(s) == [1, 2, 3]\n\n    s = pd.Series([\"b\", \"c\", \"a\", \"b\", \"c\", \"a\"], dtype=\"category\")\n    assert categorical_order(s) == [\"b\", \"c\", \"a\"]\n\n    s = pd.Series([3, 2, 1, 2, 3, 1], dtype=\"category\")\n    assert categorical_order(s) == [1, 2, 3]\n\n    s = pd.Series([\"b\", \"c\", \"a\", \"b\", \"c\", \"a\"])\n    assert categorical_order(s, order=[\"a\", \"b\", \"c\"]) == [\"a\", \"b\", \"c\"]\n"], "sample_639": ["def test_base_checker_consistency() -> None:\n    consistent_checker = OtherBasicChecker()\n    consistent_checker.check_consistency()  # This should not raise an exception\n\n    inconsistent_checker = DifferentBasicChecker()\n    with pytest.raises(InvalidMessageError):\n        inconsistent_checker.check_consistency()  # This should raise an exception\n"], "sample_704": ["def test_node_add_report_section(pytester: Pytester) -> None:\n    items = pytester.getitems(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    item = items[0]\n    item.add_report_section(\"call\", \"custom\", \"custom content\")\n    assert item._report_sections == [(\"call\", \"custom\", \"custom content\")]\n"], "sample_752": ["def test_iforest_threshold_deprecation():\n    \"\"\"Test that the threshold_ attribute is deprecated.\"\"\"\n    X = iris.data\n    clf = IsolationForest().fit(X)\n    with pytest.warns(DeprecationWarning):\n        clf.threshold_\n"], "sample_1024": ["def test_Float_from_mpmath():\n    import mpmath\n    mpmath.mp.dps = 100\n    mp_pi = mpmath.pi()\n\n    assert Float(mp_pi, 100) == Float(mp_pi._mpf_, 100) == pi.evalf(100)\n\n    mpmath.mp.dps = 15\n\n    assert Float(mp_pi, 100) == Float(mp_pi._mpf_, 100) == pi.evalf(100)\n"], "sample_239": ["def test_formset_with_deletion_and_min_num(self):\n    \"\"\"FormSets with deletion and min_num.\"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_delete=True, min_num=2)\n    initial = [\n        {'choice': 'Calexico', 'votes': 100},\n        {'choice': 'Fergie', 'votes': 900},\n    ]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_92": ["    def setUpTestData(cls):\n        cls.user = User.objects.create_user(\n            username=cls.remote_user, email='test@example.com', is_active=False,\n            password='test'\n        )\n"], "sample_224": ["def test_aggregation_subquery_annotation_values_list(self):\n    \"\"\"\n    Subquery annotations and external aliases are excluded from the GROUP\n    BY if they are not selected.\n    \"\"\"\n    books_qs = Book.objects.annotate(\n        first_author_the_same_age=Subquery(\n            Author.objects.filter(\n                age=OuterRef('contact__friends__age'),\n            ).order_by('age').values('id')[:1],\n        )\n    ).filter(\n        publisher=self.p1,\n        first_author_the_same_age__isnull=False,\n    ).annotate(\n        min_age=Min('contact__friends__age'),\n    ).values_list('name', 'min_age').order_by('name')\n    self.assertEqual(list(books_qs), [\n        ('Practical Django Projects', 34),\n        ('The Definitive Guide to Django: Web Development Done Right', 29),\n    ])\n"], "sample_1072": ["def test_frac_series():\n    x, y = symbols('x, y')\n    assert frac(x).nseries(x, y, 100) == frac(y)\n    assert frac(x).nseries(x, pi, 100) == pi - floor(pi)\n    assert frac(x).nseries(x, 0, 100) == 0\n    assert frac(-x).nseries(x, 0, 100) == 0\n"], "sample_609": ["def test_where_with_datasets() -> None:\n    ds1 = xr.Dataset({\"a\": (\"x\", [1, 2]), \"x\": [0, 1]})\n    ds2 = xr.Dataset({\"a\": (\"x\", [99, 3]), \"x\": [1, 2]})\n    expected = xr.Dataset({\"a\": (\"x\", [1, 3]), \"x\": [0, 1, 2]})\n\n    actual = xr.where(ds1[\"x\"] == ds2[\"x\"], ds1, ds2)\n    assert_identical(expected, actual)\n"], "sample_1202": ["def test_Integer_negation():\n    assert -Integer(0) is S.Zero\n    assert -Integer(1) == -1\n    assert -Integer(-1) == 1\n    assert -Integer(2) == -2\n    assert -Integer(-2) == 2\n"], "sample_653": ["def test_log_cli_format(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n            logging.warning(\"test message\")\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n        log_cli_format=%(levelname)s:%(message)s\n        \"\"\"\n    )\n\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*::test_log_cli_format \",\n            \"*WARNING:test message*\",\n            \"PASSED *100%*\",\n            \"=* 1 passed in *=\",\n        ]\n    )\n"], "sample_739": ["def test_label_binarize_multilabel_indicator_mismatch():\n    y = np.array([[0, 1, 0], [1, 1, 1], [0, 0, 0]])\n    classes = [0, 1]\n    assert_raises(ValueError, label_binarize, y, classes)\n"], "sample_579": ["def test_clustermap_annotation_overwrite_kws(self):\n\n    annot_kws = dict(color=\"0.3\", va=\"bottom\", ha=\"left\")\n    g = mat.clustermap(self.df_norm, annot=True, fmt=\".1f\", annot_kws=annot_kws)\n    for text in g.ax_heatmap.texts:\n        assert text.get_color() == \"0.3\"\n        assert text.get_ha() == \"left\"\n        assert text.get_va() == \"bottom\"\n"], "sample_47": ["    def test_cleanse_setting_dict(self):\n        self.assertEqual(cleanse_setting('TEST', {'PASSWORD': 'super_secret'}), {'PASSWORD': CLEANSED_SUBSTITUTE})\n        self.assertEqual(cleanse_setting('TEST', {'KEY': 'value'}), {'KEY': 'value'})\n"], "sample_507": ["def test_plot_empty_data(self, plotter):\n    ax = plt.figure().subplots()\n    plotter(ax, [], [])\n    assert ax.xaxis.units is None\n    assert ax.yaxis.units is None\n"], "sample_62": ["def test_unregister_not_registered_model(self):\n    \"\"\"\n    Unregistering a model that is not registered should raise NotRegistered.\n    \"\"\"\n    msg = \"The model Person is not registered\"\n    with self.assertRaisesMessage(admin.sites.NotRegistered, msg):\n        self.site.unregister(Person)\n"], "sample_79": ["def test_singular_and_plural_suffix_for_items(self):\n    self.check_values(('0', 'items'), ('1', 'item'), ('2', 'items'))\n"], "sample_301": ["def test_watch_dir_with_unresolvable_path_in_glob(self, mocked_modules, notify_mock):\n    path = Path('unresolvable_directory')\n    with mock.patch.object(Path, 'glob', side_effect=FileNotFoundError):\n        self.reloader.watch_dir(path, '**/*.mo')\n    self.assertEqual(list(self.reloader.directory_globs), [])\n"], "sample_193": ["def test_generic_fk_with_abstract_base(self):\n    A = self.create_model(\"A\", abstract=True, foreign_keys=[GenericForeignKey()])\n    B = self.create_model(\"B\", bases=(A,))\n    C = self.create_model(\"C\", foreign_keys=[models.ForeignKey('B', models.CASCADE)])\n    self.assertRelated(A, [B])\n    self.assertRelated(B, [A, C])\n    self.assertRelated(C, [A, B])\n"], "sample_238": ["def test_aggregation_subquery_annotation_related_field_filter(self):\n    publisher = Publisher.objects.create(name=self.a9.name, num_awards=2)\n    book = Book.objects.create(\n        isbn='159059999', name='Test book.', pages=819, rating=2.5,\n        price=Decimal('14.44'), contact=self.a9, publisher=publisher,\n        pubdate=datetime.date(2019, 12, 6),\n    )\n    book.authors.add(self.a5, self.a6, self.a7)\n    books_qs = Book.objects.annotate(\n        contact_publisher=Subquery(\n            Publisher.objects.filter(\n                pk=OuterRef('publisher'),\n                name=OuterRef('contact__name'),\n                num_awards__gt=1,\n            ).values('name')[:1],\n        )\n    ).filter(\n        contact_publisher__isnull=False,\n    ).annotate(count=Count('authors'))\n    self.assertSequenceEqual(books_qs, [book])\n"], "sample_182": ["def test_union_with_different_fields(self):\n    qs1 = Number.objects.filter(num__lte=1).values('num')\n    qs2 = Number.objects.filter(num__gte=2, num__lte=3).values('other_num')\n    with self.assertRaises(TypeError):\n        qs1.union(qs2)\n"], "sample_743": ["def test_sparse_metric_callable_with_fit():\n        assert_true(issparse(x) and issparse(y))\n        return x.dot(y.T).A.item()\n\n    CLASSES = 15\n    X = csr_matrix(np.eye(CLASSES))\n    y = [ch for ch in 'ABCDEFGHIJKLMNOPQRSTU'[:CLASSES]]\n\n    classifier = neighbors.KNeighborsClassifier(n_neighbors=1, metric=sparse_metric)\n    result = classifier.fit(X, y).predict(X)\n    assert_array_equal(result, y)\n"], "sample_623": ["    def test_split_chunks(self, shape, pref_chunks, req_chunks):\n        # ... existing code ...\n"], "sample_956": ["def test_inspect_main_invalid_file(capsys, tempdir):\n    \"\"\"inspect_main interface, with invalid file argument\"\"\"\n    inv_file = tempdir / 'invalid_inventory'\n    inv_file.write_text(\"Invalid inventory content\")\n\n    inspect_main([str(inv_file)])\n\n    stdout, stderr = capsys.readouterr()\n    assert \"unknown or unsupported inventory version\" in stderr\n"], "sample_9": ["def test_write_table_html_css():\n    \"\"\"\n    Test that passing css should include it in the output\n    \"\"\"\n    buffer_output = StringIO()\n    t = Table([[1], [2]], names=('a', 'b'))\n    ascii.write(t, buffer_output, format='html', htmldict={'css': 'body {background-color: powderblue;}'})\n\n    assert '<style>body {background-color: powderblue;}</style>' in buffer_output.getvalue()\n"], "sample_591": ["def test_merge_overwrite_vars(self):\n    ds1 = xr.Dataset({\"a\": (\"x\", [1, 2]), \"x\": [0, 1]})\n    ds2 = xr.Dataset({\"a\": (\"x\", [2, 3]), \"x\": [1, 2]})\n    expected = xr.Dataset({\"a\": (\"x\", [2, 3]), \"x\": [0, 1]})\n    assert expected.identical(ds1.merge(ds2, overwrite_vars=\"a\"))\n    assert expected.identical(ds2.merge(ds1, overwrite_vars=\"a\"))\n"], "sample_582": ["def test_run_cert_key_with_ssl_context(monkeypatch):\n    ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n    monkeypatch.setitem(sys.modules, \"ssl_context\", ssl_context)\n\n    # --key is not used with SSLContext\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"ssl_context\", \"--key\", __file__])\n"], "sample_794": ["def test_ridge_classifier_cv_no_support_multilabel():\n    X, y = make_multilabel_classification(n_samples=10, random_state=0)\n    assert_raises(ValueError, RidgeClassifierCV().fit, X, y)\n"], "sample_829": ["def test_incremental_pca_sparse_transform():\n    # Test that transform works correctly with sparse input.\n    X = iris.data\n    pca = PCA(n_components=2)\n    pca.fit_transform(X)\n    X_sparse = sparse.csr_matrix(X)\n    batch_size = X_sparse.shape[0] // 3\n    ipca = IncrementalPCA(n_components=2, batch_size=batch_size)\n    ipca.fit(X_sparse)\n\n    X_transformed_sparse = ipca.transform(X_sparse)\n    X_transformed_dense = ipca.transform(X)\n\n    assert_array_almost_equal(X_transformed_sparse, X_transformed_dense)\n"], "sample_514": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc)\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n    cb.set_alpha(None)\n    assert cb.alpha is None\n"], "sample_383": ["def test_ticket_24605_with_values(self):\n    \"\"\"\n    Subquery table names should be quoted when using values().\n    \"\"\"\n    i1 = Individual.objects.create(alive=True)\n    RelatedIndividual.objects.create(related=i1)\n    i2 = Individual.objects.create(alive=False)\n    RelatedIndividual.objects.create(related=i2)\n    i3 = Individual.objects.create(alive=True)\n    i4 = Individual.objects.create(alive=False)\n\n    self.assertSequenceEqual(\n        Individual.objects.filter(\n            Q(alive=False), Q(related_individual__isnull=True)\n        ).values('id'),\n        [{'id': i4.id}],\n    )\n    self.assertSequenceEqual(\n        Individual.objects.exclude(\n            Q(alive=False), Q(related_individual__isnull=True)\n        ).values('id').order_by('pk'),\n        [{'id': i1.id}, {'id': i2.id}, {'id': i3.id}],\n    )\n"], "sample_961": ["def test_pyfunction_with_positional_only_arguments(app):\n    text = \".. py:function:: hello(a, /, b)\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, ([desc_parameter, desc_sig_name, \"a\"],\n                                      [desc_parameter, desc_sig_operator, \"/\"],\n                                      [desc_parameter, desc_sig_name, \"b\"])])\n"], "sample_332": ["def test_formset_with_custom_prefix(self):\n    \"\"\"Formsets can have a custom prefix.\"\"\"\n    class CustomPrefixFormSet(BaseFormSet):\n        @classmethod\n            return 'custom'\n\n    CustomPrefixFormSetFormSet = formset_factory(FavoriteDrinkForm, formset=CustomPrefixFormSet)\n    formset = CustomPrefixFormSetFormSet()\n    self.assertEqual(formset.management_form.prefix, 'custom')\n"], "sample_265": ["def test_templatetag_discovery_unicode(self):\n    \"\"\"\n    Unicode characters in tag modules should be handled correctly.\n    \"\"\"\n    engine = DjangoTemplates({\n        'DIRS': [],\n        'APP_DIRS': False,\n        'NAME': 'django',\n        'OPTIONS': {},\n    })\n    self.assertEqual(\n        engine.engine.libraries['unicode_tags'],\n        'template_backends.apps.unicode.templatetags.unicode_tags',\n    )\n"], "sample_6": ["def test_angle_wrap_at():\n    \"\"\"\n    Test the wrap_at method of the Angle class.\n    \"\"\"\n    a1 = Angle([365, -365, 720, -720], unit=u.degree)\n    a2 = a1.wrap_at(360 * u.degree)\n    npt.assert_almost_equal(a2.value, [5, 355, 0, 0])\n\n    a3 = Angle([185, -185, 360, -360], unit=u.degree)\n    a4 = a3.wrap_at(180 * u.degree)\n    npt.assert_almost_equal(a4.value, [-175, 175, 0, 0])\n\n    a5 = Angle([185, -185, 360, -360], unit=u.degree)\n    a5.wrap_at(180 * u.degree, inplace=True)\n    npt.assert_almost_equal(a5.value, [-175, 175, 0, 0])\n"], "sample_269": ["def test_i18n_language_with_custom_domain(self):\n    \"\"\"\n    Check if the JavaScript i18n view returns a complete language catalog\n    if a custom domain is used.\n    \"\"\"\n    with self.settings(LANGUAGE_CODE='en-us'), override('fr'):\n        response = self.client.get('/jsi18n/app6/custom_domain/')\n        self.assertContains(response, 'this app6 string with custom domain is to be translated')\n"], "sample_38": ["def test_sip_with_altkey_and_relax():\n    \"\"\"\n    Test that when creating a WCS object using a key, CTYPE with\n    that key is looked at and not the primary CTYPE.\n    Also test that when relax is True, \"-SIP\" is added to CTYPE.\n    fix for #5443.\n    \"\"\"\n    with fits.open(get_pkg_data_filename('data/sip.fits')) as f:\n        w = wcs.WCS(f[0].header)\n    # create a header with two WCSs.\n    h1 = w.to_header(relax=True, key='A')\n    h2 = w.to_header(relax=False)\n    h1['CTYPE1A'] = \"RA---SIN\"\n    h1['CTYPE2A'] = \"DEC--SIN\"\n    h1.update(h2)\n    w = wcs.WCS(h1, key='A', relax=True)\n    assert (w.wcs.ctype == np.array(['RA---SIN-SIP', 'DEC--SIN-SIP'])).all()\n"], "sample_1172": ["def test_solve_generic():\n    x, y = symbols('x y')\n\n    # Test a system with no solutions\n    f_1 = x**2 + y**2 - 1\n    f_2 = x**2 + y**2 - 4\n    assert solve_poly_system([f_1, f_2], x, y) == []\n\n    # Test a system with one solution\n    f_1 = x**2 + y**2 - 1\n    f_2 = x - y\n    assert solve_poly_system([f_1, f_2], x, y) == [(1/sqrt(2), 1/sqrt(2))]\n\n    # Test a system with multiple solutions\n    f_1 = x**2 + y**2 - 1\n    f_2 = x - y\n    f_3 = x + y - 1\n    assert solve_poly_system([f_1, f_2, f_3], x, y) == [(0, 1/2), (1/2, 0)]\n\n    # Test a system with complex solutions\n    f_1 = x**2 + y**2 - 1\n    f_2 = x - y\n    f_3 = x + y\n    assert solve_poly_system([f_1, f_2, f_3], x, y) == [(I/sqrt(2), -I/sqrt(2)), (-I/sqrt(2), I/sqrt(2))]\n"], "sample_118": ["def test_exact_with_queryset_and_no_select_fields(self):\n    qs = Article.objects.filter(pk=OuterRef('pk'))\n    qs.clear_select_clause()\n    authors = Author.objects.annotate(\n        article_exists=Exists(qs),\n    ).filter(\n        article_exists=True,\n    )\n    self.assertCountEqual(authors, Author.objects.filter(pk__in=[self.au1.pk, self.au2.pk]))\n"], "sample_549": ["def test_safe_first_element_with_nan():\n    arr = np.array([np.nan, 1, 2, 3])\n    ret = cbook._safe_first_finite(arr)\n    assert ret == 1\n"], "sample_107": ["def test_template_encoding_in_email(self):\n    \"\"\"\n    The templates are loaded directly, not via a template loader, and\n    should be opened as utf-8 charset as is the default specified on\n    template engines.\n    \"\"\"\n    with self.settings(ADMINS=[('Admin', 'admin@fattie-breakie.com')]):\n        mail.outbox = []  # Empty outbox\n        request = self.rf.post('/some_url/', self.breakfast_data)\n        sensitive_view(request)\n        self.assertEqual(len(mail.outbox), 1)\n        email = mail.outbox[0]\n        with mock.patch.object(DebugPath, 'open') as m:\n            ExceptionReporter(request, None, None, None).get_traceback_html()\n            m.assert_called_once_with(encoding='utf-8')\n            m.reset_mock()\n            ExceptionReporter(request, None, None, None).get_traceback_text()\n            m.assert_called_once_with(encoding='utf-8')\n"], "sample_776": ["def test_lasso_lars_vs_lasso_cd_early_stopping_with_copy_X(verbose=False):\n    # Test that LassoLars and Lasso using coordinate descent give the\n    # same results when early stopping is used and copy_X is False.\n    # (test : before, in the middle, and in the last part of the path)\n    alphas_min = [10, 0.9, 1e-4]\n\n    for alpha_min in alphas_min:\n        alphas, _, lasso_path = linear_model.lars_path(X, y, method='lasso',\n                                                       alpha_min=alpha_min, copy_X=False)\n        lasso_cd = linear_model.Lasso(fit_intercept=False, tol=1e-8, copy_X=False)\n        lasso_cd.alpha = alphas[-1]\n        lasso_cd.fit(X, y)\n        error = linalg.norm(lasso_path[:, -1] - lasso_cd.coef_)\n        assert_less(error, 0.01)\n\n    # same test, with normalization\n    for alpha_min in alphas_min:\n        alphas, _, lasso_path = linear_model.lars_path(X, y, method='lasso',\n                                                       alpha_min=alpha_min, copy_X=False)\n        lasso_cd = linear_model.Lasso(fit_intercept=True, normalize=True,\n                                      tol=1e-8, copy_X=False)\n        lasso_cd.alpha = alphas[-1]\n        lasso_cd.fit(X, y)\n        error = linalg.norm(lasso_path[:, -1] - lasso_cd.coef_)\n        assert_less(error, 0.01)\n"], "sample_485": ["def test_urlize_with_autoescape(self):\n    tests = (\n        (\n            \"Search for google.com/?q=! and see.\",\n            'Search for <a href=\"http://google.com/?q=&quot;\">google.com/?q=</a>! and '\n            \"see.\",\n        ),\n        (\n            \"foo@example.com\",\n            '<a href=\"mailto:foo@example.com\">foo@example.com</a>',\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value, autoescape=True), output)\n"], "sample_1022": ["def test_custom_symbol_splitting():\n        if symbol not in ('list', 'of', 'unsplittable', 'names'):\n            return _token_splittable(symbol)\n        return False\n\n    transformations = standard_transformations + (split_symbols_custom(can_split),)\n    assert parse_expr('unsplittable', transformations=transformations) == sympy.Symbol('unsplittable')\n    assert parse_expr('splittable', transformations=transformations) != sympy.Symbol('splittable')\n"], "sample_20": ["def test_read_with_hdu_5(self, tmp_path):\n    filename = tmp_path / \"test_read_with_hdu_5.fits\"\n    self.hdus.writeto(filename)\n    with pytest.raises(ValueError, match=\"Specified hdu=5 not found\"):\n        Table.read(filename, hdu=5)\n"], "sample_245": ["    def test_no_obsolete_enabled(self):\n        management.call_command('makemessages', locale=[LOCALE], verbosity=0, no_obsolete=True)\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertNotIn(\"#~\", po_contents)\n"], "sample_50": ["def test_no_host_port(self):\n    self.assertEqual(\n        self._run_it({\n            'database': 'dbname',\n            'user': 'someuser',\n            'password': 'somepassword',\n        }), (\n            ['psql', '-U', 'someuser', 'dbname'],\n            'somepassword',\n        )\n    )\n"], "sample_162": ["    def test_no_obsolete_enabled(self):\n        management.call_command('makemessages', locale=[LOCALE], verbosity=0, no_obsolete=True)\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertNotIn(\"#~\", po_contents)\n"], "sample_1147": ["def test_latex_MatrixExpr():\n    from sympy import MatrixSymbol, Identity\n    A = MatrixSymbol('A', 3, 3)\n    B = MatrixSymbol('B', 3, 3)\n    expr = A * B + Identity(3)\n    assert latex(expr) == r\"A B + \\mathbf{I}\"\n"], "sample_734": ["def test_fowlkes_mallows_score_symmetry():\n    # Test symmetry of Fowlkes-Mallows score\n    labels_a = np.array([1, 1, 2, 2, 3, 3])\n    labels_b = np.array([1, 2, 1, 2, 3, 3])\n    score_ab = fowlkes_mallows_score(labels_a, labels_b)\n    score_ba = fowlkes_mallows_score(labels_b, labels_a)\n    assert_almost_equal(score_ab, score_ba)\n"], "sample_172": ["def test_ForeignKey_with_query_parameters(self):\n    self.admin_login(username='super', password='secret', login_url='/')\n    self.selenium.get(self.live_server_url + reverse('admin:admin_widgets_event_add') + '?main_band__name=Bogey')\n    main_window = self.selenium.current_window_handle\n\n    # Open the popup window and check that the query parameter is applied\n    self.selenium.find_element_by_id('lookup_id_main_band').click()\n    self.wait_for_and_switch_to_popup()\n    self.assertIn('main_band__name=Bogey', self.selenium.current_url)\n\n    # Click on a band and check that the field now contains the selected band's id\n    link = self.selenium.find_element_by_link_text('Bogey Blues')\n    self.assertIn('/band/42/', link.get_attribute('href'))\n    link.click()\n    self.selenium.switch_to.window(main_window)\n    self.wait_for_value('#id_main_band', '42')\n"], "sample_767": ["def test_column_transformer_empty_transformers():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n\n    ct = ColumnTransformer([])\n    assert_array_equal(ct.fit_transform(X_array), X_array)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_array)\n    assert len(ct.transformers_) == 1\n    assert ct.transformers_[0][0] == 'remainder'\n    assert ct.transformers_[0][1] == 'drop'\n    assert_array_equal(ct.transformers_[0][2], [0, 1])\n"], "sample_1044": ["def test_issue_10829():\n    x = Symbol('x', real=True)\n    assert ((2**x - 3*x + 2).subs(2**x, exp(x*log(2))) == exp(x*log(2))**2 - 3*x + 2)\n"], "sample_620": ["def test_concat_index_with_name() -> None:\n    ds1 = Dataset(coords={\"x\": (\"x\", [1, 2])})\n    ds2 = Dataset(coords={\"x\": (\"x\", [3, 4])})\n\n    expected = Dataset(coords={\"x\": (\"x\", [1, 2, 3, 4])})\n    actual = concat([ds1, ds2], dim=\"x\")\n\n    assert_identical(actual, expected)\n    assert isinstance(actual.indexes[\"x\"], PandasIndex)\n"], "sample_785": ["def test_build_repr_with_default_values():\n    splitter = MockSplitter(a=1)\n    assert_equal(_build_repr(splitter), \"MockSplitter(a=1, b=0, c=None)\")\n"], "sample_213": ["def test_file_storage_open_mode(self):\n    \"\"\"\n    File storage should open files in the specified mode.\n    \"\"\"\n    content = b'test content'\n    self.storage.save('test.file', ContentFile(content))\n    self.addCleanup(self.storage.delete, 'test.file')\n\n    with self.storage.open('test.file', 'rb') as f:\n        self.assertEqual(f.read(), content)\n\n    with self.storage.open('test.file', 'ab') as f:\n        f.write(b' appended')\n\n    with self.storage.open('test.file', 'rb') as f:\n        self.assertEqual(f.read(), content + b' appended')\n"], "sample_345": ["def test_watch_dir_with_unresolvable_path_in_glob(self, mocked_modules, notify_mock):\n    path = Path('unresolvable_directory')\n    with mock.patch.object(Path, 'glob', side_effect=FileNotFoundError):\n        self.reloader.watch_dir(path, '**/*.mo')\n    self.assertEqual(list(self.reloader.directory_globs), [])\n"], "sample_219": ["def test_expression_wrapper_with_aggregate(self):\n    Number.objects.create(integer=10, float=123.45)\n    qs = Number.objects.annotate(\n        wrapped_sum=ExpressionWrapper(Sum('integer'), output_field=IntegerField())\n    )\n    self.assertEqual(qs.get().wrapped_sum, 10)\n"], "sample_1185": ["def test_compogen():\n    assert compogen([sin(x), cos(x)], x) == sin(cos(x))\n    assert compogen([x**2 + x + 1, sin(x)], x) == sin(x)**2 + sin(x) + 1\n    assert compogen([sqrt(x), 6*x**2 - 5], x) == sqrt(6*x**2 - 5)\n    assert compogen([sin(x), sqrt(x), cos(x), x**2 + 1], x) == sin(sqrt(cos(x**2 + 1)))\n    assert compogen([x**2 - x - 1, x**2 + x], x) == -x**2 - x + (x**2 + x)**2 - 1\n"], "sample_1189": ["def test_lambdify_with_tensorflow():\n    if not tensorflow:\n        skip(\"tensorflow not installed\")\n\n    expr = Max(sin(x), Abs(1/(x+2)))\n    func = lambdify(x, expr, modules=\"tensorflow\")\n\n    with tensorflow.compat.v1.Session() as s:\n        a = tensorflow.constant(0.5, dtype=tensorflow.float32)\n        assert abs(func(a).eval(session=s) - 0.5) < 1e-6\n"], "sample_379": ["def test_safe_string_subclass_behavior(self):\n    \"\"\"\n    Test that SafeString subclasses behave as expected.\n    \"\"\"\n    class CustomSafeString(SafeString):\n        pass\n\n    s = CustomSafeString('a&b')\n    self.assertIsInstance(s, SafeData)\n    self.assertRenderEqual('{{ s }}', 'a&b', s=s)\n    self.assertRenderEqual('{{ s|force_escape }}', 'a&amp;b', s=s)\n"], "sample_167": ["def test_naturaltime_with_future_dates(self):\n    future_date = now + datetime.timedelta(days=100)\n    test_list = [future_date]\n    result_list = ['3 months, 1 week from now']\n\n    orig_humanize_datetime, humanize.datetime = humanize.datetime, MockDateTime\n    try:\n        with translation.override('en'):\n            self.humanize_tester(test_list, result_list, 'naturaltime')\n    finally:\n        humanize.datetime = orig_humanize_datetime\n"], "sample_421": ["def test_when_with_empty_q_object(self):\n    msg = \"An empty Q() can't be used as a When() condition.\"\n    with self.assertRaisesMessage(ValueError, msg):\n        When(Q())\n"], "sample_849": ["def test_leave_p_out_empty_trainset():\n    cv = LeavePOut(p=2)\n    X, y = [[1]], [0]  # 1 sample\n    with pytest.raises(\n            ValueError,\n            match='Cannot perform LeavePOut with n_samples=1 and p=2'):\n        next(cv.split(X, y))\n"], "sample_12": ["def test_angle_from_quantity():\n    \"\"\"\n    Test creating an Angle from a Quantity\n    \"\"\"\n    q = u.Quantity(54.12412, unit=u.degree)\n    a = Angle(q)\n    assert_allclose(a.degree, 54.12412)\n\n    q = u.Quantity(3.60827466667, unit=u.hour)\n    a = Angle(q)\n    assert_allclose(a.hour, 3.60827466667)\n\n    q = u.Quantity(0.944644098745, unit=u.radian)\n    a = Angle(q)\n    assert_allclose(a.radian, 0.944644098745)\n"], "sample_523": ["def test_legend_markers_from_line2d_with_different_sizes():\n    # Test that markers can be copied for legend lines with different sizes (#17960)\n    _markers = ['.', '*', 'v']\n    _sizes = [10, 20, 30]\n    fig, ax = plt.subplots()\n    lines = [mlines.Line2D([0], [0], ls='None', marker=mark, ms=size)\n             for mark, size in zip(_markers, _sizes)]\n    labels = [\"foo\", \"bar\", \"xyzzy\"]\n    markers = [line.get_marker() for line in lines]\n    sizes = [line.get_markersize() for line in lines]\n    legend = ax.legend(lines, labels)\n\n    new_markers = [line.get_marker() for line in legend.get_lines()]\n    new_sizes = [line.get_markersize() for line in legend.get_lines()]\n    new_labels = [text.get_text() for text in legend.get_texts()]\n\n    assert markers == new_markers == _markers\n    assert sizes == new_sizes == _sizes\n    assert labels == new_labels\n"], "sample_68": ["def test_sensitive_settings_in_callable(self):\n    \"\"\"\n    The debug page should not show some sensitive settings\n    (password, secret key, ...) even if they are in a callable.\n    \"\"\"\n        return {\"SECRET_KEY\": \"should not be displayed\"}\n\n    with self.settings(DEBUG=True, FOOBAR=callable_setting):\n        response = self.client.get('/raises500/')\n        self.assertNotContains(response, 'should not be displayed', status_code=500)\n"], "sample_90": ["def test_setattr_raises_validation_error_multiple_fields(self):\n    \"\"\"\n    A model ValidationError using the dict form with multiple fields should\n    put the error messages into the correct keys of form.errors.\n    \"\"\"\n    form_class = modelform_factory(model=StrictAssignmentMultipleFields, fields=['title', 'description'])\n    form = form_class(data={'title': 'testing setattr', 'description': 'testing setattr'}, files=None)\n    # This line turns on the ValidationError; it avoids the model erroring\n    # when its own __init__() is called when creating form.instance.\n    form.instance._should_error = True\n    self.assertFalse(form.is_valid())\n    self.assertEqual(form.errors, {\n        'title': ['Cannot set attribute'],\n        'description': ['Cannot set attribute', 'This field cannot be blank.']\n    })\n"], "sample_381": ["def test_add_model_with_field_removed_from_base_model_with_m2m(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name and a ManyToManyField.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n            ('authors', models.ManyToManyField('app.Author')),\n        ], bases=('app.readable',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n"], "sample_373": ["def test_simplify_regex(self):\n    test_cases = [\n        ('^(?P<sport_slug>\\\\w+)/athletes/(?P<athlete_slug>\\\\w+)/$', '/<sport_slug>/athletes/<athlete_slug>/'),\n        ('^(?P<pk>[0-9]+)/$', '/<pk>/'),\n        ('^$', '/'),\n        ('^(?P<year>[0-9]{4})/(?P<month>[0-9]{2})/(?P<day>[0-9]{2})/$', '/<year>/<month>/<day>/'),\n        ('^(?P<pk>[0-9]+)/(?P<slug>[\\\\w-]+)/$', '/<pk>/<slug>/'),\n    ]\n    for pattern, expected in test_cases:\n        with self.subTest(pattern=pattern):\n            self.assertEqual(simplify_regex(pattern), expected)\n"], "sample_261": ["    def test_parse_duration_iso8601(self):\n        test_values = (\n            ('P4Y', None),  # ISO 8601 doesn't support years\n            ('P4M', None),  # ISO 8601 doesn't support months\n            ('P4W', None),  # ISO 8601 doesn't support weeks\n            ('P4D', timedelta(days=4)),\n            ('P1DT2H3M4S', timedelta(days=1, hours=2, minutes=3, seconds=4)),\n            ('P1DT2H3M', timedelta(days=1, hours=2, minutes=3)),\n            ('P1DT2H', timedelta(days=1, hours=2)),\n            ('PT2H3M4S', timedelta(hours=2, minutes=3, seconds=4)),\n            ('PT3M4S', timedelta(minutes=3, seconds=4)),\n            ('PT4S', timedelta(seconds=4)),\n            ('P4DT2H3M4S', timedelta(days=4, hours=2, minutes=3, seconds=4)),\n            ('-P4D', timedelta(days=-4)),\n            ('-P1DT2H3M4S', timedelta(days=-1, hours=-2, minutes=-3, seconds=-4)),\n            ('-PT2H3M4S', timedelta(hours=-2, minutes=-3, seconds=-4)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_306": ["    def test_parse_iso8601_format(self):\n        test_values = (\n            ('P4Y', None),  # ISO 8601 doesn't support years\n            ('P4M', None),  # ISO 8601 doesn't support months\n            ('P4W', None),  # ISO 8601 doesn't support weeks\n            ('P4D', timedelta(days=4)),\n            ('PT4H', timedelta(hours=4)),\n            ('PT4M', timedelta(minutes=4)),\n            ('PT4S', timedelta(seconds=4)),\n            ('P4DT4H3M2S', timedelta(days=4, hours=4, minutes=3, seconds=2)),\n            ('P4.5D', timedelta(days=4, hours=12)),\n            ('PT4.5H', timedelta(hours=4, minutes=30)),\n            ('PT4.5M', timedelta(minutes=4, seconds=30)),\n            ('PT4.5S', timedelta(seconds=4, microseconds=500000)),\n            ('-P4D', timedelta(days=-4)),\n            ('-PT4H', timedelta(hours=-4)),\n            ('-PT4M', timedelta(minutes=-4)),\n            ('-PT4S', timedelta(seconds=-4)),\n            ('-P4DT4H3M2S', timedelta(days=-4, hours=-4, minutes=-3, seconds=-2)),\n            ('-P4.5D', timedelta(days=-4, hours=-12)),\n            ('-PT4.5H', timedelta(hours=-4, minutes=-30)),\n            ('-PT4.5M', timedelta(minutes=-4, seconds=-30)),\n            ('-PT4.5S', timedelta(seconds=-4, microseconds=-500000)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self."], "sample_1103": ["def test_divmod_with_symbols():\n    x, y = symbols('x y')\n    assert divmod(x, y) == (floor(x/y), x % y)\n    assert divmod(x, 3) == (floor(x/3), x % 3)\n    assert divmod(3, x) == (floor(3/x), 3 % x)\n"], "sample_411": ["def test_call_command_with_invalid_type_for_option(self):\n    msg = \"invalid int value: 'invalid'\"\n    with self.assertRaisesMessage(CommandError, msg):\n        management.call_command(\"dance\", integer=\"invalid\")\n"], "sample_1168": ["def test_has_variety():\n    assert has_variety((1, 2, 1)) is True\n    assert has_variety((1, 1, 1)) is False\n"], "sample_809": ["def test_mutual_info_regression_sparse():\n    # Test that sparse matrix with continuous features raises an error.\n    X = csr_matrix([[0, 1], [2, 0]])\n    y = np.array([0, 1])\n    assert_raises(ValueError, mutual_info_regression, X, y)\n"], "sample_42": ["def test_with_H0():\n    H0 = 70 * u.km / u.s / u.Mpc\n    little_h = 0.7\n    distance = 10 * u.Mpc / little_h\n    physical_distance = distance.to(u.Mpc, u.with_H0(H0))\n    assert_quantity_allclose(physical_distance, 10 * u.Mpc)\n\n    # Test with default cosmology\n    cosmo = cosmology.Planck15\n    distance = 10 * u.Mpc / cosmo.h\n    physical_distance = distance.to(u.Mpc, u.with_H0())\n    assert_quantity_allclose(physical_distance, 10 * u.Mpc)\n"], "sample_210": ["def test_template_params_with_query_string(self):\n    \"\"\"A generic template view passes kwargs and query string as context.\"\"\"\n    response = self.client.get('/template/simple/bar/?param=value')\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(response.context['foo'], 'bar')\n    self.assertEqual(response.context['param'], 'value')\n    self.assertIsInstance(response.context['view'], View)\n"], "sample_800": ["def test_check_class_weight_balanced_linear_classifier():\n    # check that check_class_weight_balanced_linear_classifier works correctly\n    check_class_weight_balanced_linear_classifier(\"LinearRegression\", LinearRegression)\n"], "sample_652": ["def test_call_fixture_function_error_with_request(request):\n    \"\"\"Check if an error is raised if a fixture function is called directly with a request (#4545)\"\"\"\n\n    @pytest.fixture\n        return 1\n\n    with pytest.raises(pytest.fail.Exception):\n        assert fix(request) == 1\n"], "sample_862": ["def test_callable_analyzer_reraise_error(tmpdir, Estimator):\n    # check if a custom exception from the analyzer is shown to the user\n        raise Exception(\"testing\")\n\n    data = ['this is text, not file or filename']\n    with pytest.raises(Exception, match=\"testing\"):\n        Estimator(analyzer=analyzer).fit_transform(data)\n"], "sample_729": ["def test_enet_sparse_input():\n    # Test ElasticNet with sparse input\n    X, y, _, _ = build_dataset(n_samples=20, n_features=10)\n    X_sparse = sparse.csr_matrix(X)\n    clf = ElasticNet(alpha=0.5, max_iter=100, fit_intercept=True, normalize=True)\n    clf.fit(X_sparse, y)\n    assert_equal(clf.coef_.dtype, np.float64)\n"], "sample_516": ["def test_glyphs_subset():\n    \"\"\"Test that subsetting works correctly\"\"\"\n    font_path = _get_data_path('fonts/ttf/DejaVuSans.ttf')\n    font = FT2Font(font_path)\n    glyphs = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n    glyph_indices = [font.get_char_index(ord(g)) for g in glyphs]\n    subset_data = get_glyphs_subset(font_path, glyphs)\n    subset_font = FT2Font(subset_data)\n    subset_glyph_indices = [subset_font.get_char_index(ord(g)) for g in glyphs]\n    assert glyph_indices == subset_glyph_indices\n"], "sample_287": ["def test_autocomplete_fields_not_list_or_tuple(self):\n    class SongAdmin(admin.ModelAdmin):\n        autocomplete_fields = 'test'\n\n    self.assertEqual(SongAdmin(Song, AdminSite()).check(), [\n        checks.Error(\n            \"The value of 'autocomplete_fields' must be a list or tuple.\",\n            obj=SongAdmin,\n            id='admin.E036',\n        )\n    ])\n"], "sample_880": ["def test_ovr_decision_function():\n    predictions = np.array([[0, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.2, 0.3, 0.1], [0.4, 0.5, 0.6]])\n    n_classes = 3\n\n    expected_output = np.array([[0.33333333, -0.16666667, 0.16666667],\n                               [-0.16666667, 0.33333333, 0.16666667]])\n\n    output = _ovr_decision_function(predictions, confidences, n_classes)\n    assert_allclose(output, expected_output)\n"], "sample_71": ["    def test_decimal_subclass_with_grouping(self):\n        class EuroDecimal(Decimal):\n            \"\"\"\n            Wrapper for Decimal which prefixes each amount with the \u20ac symbol.\n            \"\"\"\n                amount = super().__format__(specifier, **kwargs)\n                return '\u20ac {}'.format(amount)\n\n        price = EuroDecimal('1234567.89')\n        self.assertEqual(nformat(price, '.', grouping=3, thousand_sep=',', force_grouping=True), '\u20ac 1,234,567.89')\n"], "sample_562": ["def test_linestyle_prop_cycle(fig_test, fig_ref):\n    \"\"\"Test that we can set linestyle prop_cycle.\"\"\"\n    linestyles = ['-', '--', '-.', ':']\n\n    x = np.linspace(0, 10)\n    y = np.sin(x)\n\n    axs = fig_ref.add_subplot()\n    for i, ls in enumerate(linestyles):\n        axs.plot(x, y + i, linestyle=ls)\n\n    matplotlib.rcParams['axes.prop_cycle'] = cycler(linestyle=linestyles)\n\n    ax = fig_test.add_subplot()\n    for i in range(len(linestyles)):\n        ax.plot(x, y + i)\n"], "sample_180": ["def test_unique_constraint_pointing_to_fk(self):\n    class Foo(models.Model):\n        pass\n\n    class Bar(models.Model):\n        foo_1 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_1')\n        foo_2 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_2')\n\n        class Meta:\n            constraints = [models.UniqueConstraint(fields=['foo_1_id', 'foo_2'], name='unique_constraint')]\n\n    self.assertEqual(Bar.check(databases=self.databases), [])\n"], "sample_1209": ["def test_prefix_multiplication():\n    assert kilo * kibi == Prefix('kibikilo', 'Ki', 13, 2)\n    assert kibi * kilo == Prefix('kibikilo', 'Ki', 13, 2)\n"], "sample_1130": ["def test_auto_vel_inconsistent_relative_positions():\n    q, u = dynamicsymbols('q u')\n    N = ReferenceFrame('N')\n    O = Point('O')\n    P = Point('P')\n    Q = Point('Q')\n    O.set_pos(P, q * N.x)\n    O.set_pos(Q, q * N.y)\n    P.set_vel(N, u * N.x)\n    Q.set_vel(N, u * N.y)\n    with warnings.catch_warnings(): #There are two possible velocities for O, thus a warning is raised\n        warnings.simplefilter(\"error\")\n        raises(UserWarning ,lambda: O.vel(N))\n"], "sample_494": ["def test_serialize_complex(self):\n    complex_num = complex(1, 2)\n    self.assertSerializedEqual(complex_num)\n    self.assertSerializedResultEqual(complex_num, (\"complex('1+2j')\", set()))\n"], "sample_116": ["def test_cache_versioning_delete_many(self):\n    cache.set('answer1', 37, version=1)\n    cache.set('answer1', 42, version=2)\n    cache.set('answer2', 37, version=1)\n    cache.set('answer2', 42, version=2)\n    cache.delete_many(['answer1', 'answer2'], version=2)\n    self.assertEqual(cache.get('answer1', version=1), 37)\n    self.assertIsNone(cache.get('answer1', version=2))\n    self.assertEqual(cache.get('answer2', version=1), 37)\n    self.assertIsNone(cache.get('answer2', version=2))\n\n    cache.set('answer3', 37, version=1)\n    cache.set('answer3', 42, version=2)\n    cache.set('answer4', 37, version=1)\n    cache.set('answer4', 42, version=2)\n    caches['v2'].delete_many(['answer3', 'answer4'], version=1)\n    self.assertIsNone(cache.get('answer3', version=1))\n    self.assertEqual(cache.get('answer3', version=2), 42)\n    self.assertIsNone(cache.get('answer4', version=1))\n    self.assertEqual(cache.get('answer4', version=2), 42)\n"], "sample_295": ["def test_expression_wrapper_with_transformed_field(self):\n    Employee.objects.create(firstname='Max', lastname='Mustermann')\n    with register_lookup(CharField, Length):\n        qs = Employee.objects.annotate(wrapper=ExpressionWrapper(F('lastname__length'), output_field=IntegerField()))\n        self.assertEqual(qs.get().wrapper, 10)\n"], "sample_76": ["def test_language_settings_consistent(self):\n    msg = 'You have provided a value for the LANGUAGE_CODE setting that is not in the LANGUAGES setting.'\n    with self.settings(LANGUAGE_CODE='fr', LANGUAGES=[('en', 'English'), ('de', 'German')]):\n        self.assertEqual(check_language_settings_consistent(None), [\n            Error(msg, id='translation.E004'),\n        ])\n"], "sample_48": ["def test_stddev_variance(self):\n    # Test StdDev and Variance aggregations\n    books = Book.objects.aggregate(price_stddev=StdDev('price'), price_variance=Variance('price'))\n    self.assertIsInstance(books['price_stddev'], Decimal)\n    self.assertIsInstance(books['price_variance'], Decimal)\n\n    # Test sample StdDev and Variance\n    books = Book.objects.aggregate(price_stddev_sample=StdDev('price', sample=True), price_variance_sample=Variance('price', sample=True))\n    self.assertIsInstance(books['price_stddev_sample'], Decimal)\n    self.assertIsInstance(books['price_variance_sample'], Decimal)\n"], "sample_333": ["def test_field_deep_copy_widget(self):\n    class CustomTextInput(TextInput):\n            kwargs['attrs'] = {'class': 'custom-class'}\n            super().__init__(**kwargs)\n\n    field = CharField(widget=CustomTextInput())\n    field_copy = copy.deepcopy(field)\n    self.assertIsInstance(field_copy, CharField)\n    self.assertIsNot(field_copy.widget, field.widget)\n    self.assertIsInstance(field_copy.widget, CustomTextInput)\n    self.assertIsNot(field_copy.widget.attrs, field.widget.attrs)\n"], "sample_577": ["def test_multi_layer_different_variables(self, xy):\n\n    s1 = pd.Series([\"a\", \"b\", \"a\", \"c\"], name=\"s1\")\n    s2 = pd.Series([\"m\", \"m\", \"p\", \"m\"], name=\"s2\")\n    sem = dict(color=s1), dict(marker=s2)\n    variables = {\"s1\": \"color\", \"s2\": \"marker\"}\n    p = Plot(**xy).add(MockMark(), **sem[0]).add(MockMark(), **sem[1]).plot()\n    e1, e2 = p._legend_contents\n\n    for e, s in zip([e1, e2], [s1, s2]):\n        assert e[0] == (s.name, s.name)\n\n        labels = categorical_order(s)\n        assert e[-1] == labels\n\n        artists = e[1]\n        assert len(artists) == len(labels)\n        for a, label in zip(artists, labels):\n            assert isinstance(a, mpl.artist.Artist)\n            assert a.value == label\n            assert a.variables == [variables[s.name]]\n"], "sample_565": ["def test_inset_axes_with_bbox_transform():\n    fig, ax = plt.subplots(figsize=[5, 4])\n\n    # prepare the demo image\n    Z = cbook.get_sample_data(\"axes_grid/bivariate_normal.npy\")\n    extent = (-3, 4, -4, 3)\n    Z2 = np.zeros((150, 150))\n    ny, nx = Z.shape\n    Z2[30:30+ny, 30:30+nx] = Z\n\n    ax.imshow(Z2, extent=extent, interpolation=\"nearest\", origin=\"lower\")\n\n    # creating our inset axes with a bbox_transform parameter\n    axins = inset_axes(ax, width=1., height=1., bbox_to_anchor=(200, 100),\n                       bbox_transform=ax.transAxes, loc=3, borderpad=0)\n\n    axins.imshow(Z2, extent=extent, interpolation=\"nearest\", origin=\"lower\")\n    axins.yaxis.get_major_locator().set_params(nbins=7)\n    axins.xaxis.get_major_locator().set_params(nbins=7)\n    x1, x2, y1, y2 = -1.5, -0.9, -2.5, -1.9\n    axins.set_xlim(x1, x2)\n    axins.set_ylim(y1, y2)\n\n    plt.xticks(visible=False)\n    plt.yticks(visible=False)\n\n    mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n\n    fig.canvas.draw()\n    assert_array_almost_equal(\n        axins.get_position().extents,\n        [200/fig.dpi/fig.get_size_inches()[0], 100/fig.dpi/fig."], "sample_1083": ["def test_tanh_real():\n    x = symbols('x')\n    k = symbols('k', real=True)\n    n = symbols('n', integer=True)\n\n    assert tanh(k).is_real is True\n    assert tanh(k + (2*n + 1)*pi*I).is_real is True\n    assert tanh(I*pi/4).is_real is False\n    assert tanh(3*I*pi/4).is_real is False\n    assert tanh(S.Zero).is_real is True\n"], "sample_662": ["def test_user_properties(self, testdir):\n    \"\"\"Test that user properties are serialized and deserialized correctly.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.user_property(\"key1\", \"value1\")\n        @pytest.mark.user_property(\"key2\", \"value2\")\n            pass\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    reports = reprec.getreports(\"pytest_runtest_logreport\")\n    assert len(reports) == 3\n    test_a_call = reports[1]\n    assert test_a_call.user_properties == [(\"key1\", \"value1\"), (\"key2\", \"value2\")]\n    data = test_a_call._to_json()\n    assert data[\"user_properties\"] == [(\"key1\", \"value1\"), (\"key2\", \"value2\")]\n    new_report = TestReport._from_json(data)\n    assert new_report.user_properties == [(\"key1\", \"value1\"), (\"key2\", \"value2\")]\n"], "sample_410": ["    def test_normalize_email_with_unicode(self):\n        email = \"test@ExamPle.com\"\n        normalized_email = UserManager.normalize_email(email)\n        self.assertEqual(normalized_email, \"test@example.com\")\n"], "sample_290": ["def test_add_model_with_field_removed_from_base_model_with_m2m(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name and a ManyToManyField.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n            ('authors', models.ManyToManyField('app.Author')),\n        ], bases=('app.readable',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n"], "sample_525": ["def test_subplots_adjust():\n    fig, axs = plt.subplots(2, 2)\n    fig.subplots_adjust(left=0.2, right=0.8, bottom=0.2, top=0.8, wspace=0.2, hspace=0.2)\n    assert fig.subplotpars.left == 0.2\n    assert fig.subplotpars.right == 0.8\n    assert fig.subplotpars.bottom == 0.2\n    assert fig.subplotpars.top == 0.8\n    assert fig.subplotpars.wspace == 0.2\n    assert fig.subplotpars.hspace == 0.2\n"], "sample_157": ["    def test_serialize_test_setting_true(self, mocked_migrate, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=True)\n            self.assertIsNotNone(test_connection._test_serialized_contents)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_338": ["def test_add_model_with_field_removed_from_base_model_with_m2m(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name and a ManyToManyField.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n            ('authors', models.ManyToManyField('app.Author')),\n        ], bases=('app.readable',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n"], "sample_497": ["def test_minorticks_on():\n    fig, ax = plt.subplots()\n    ax.minorticks_on()\n    assert len(ax.xaxis.get_minor_ticks()) > 0\n    assert len(ax.yaxis.get_minor_ticks()) > 0\n"], "sample_46": ["def test_regex(self):\n    self.assertSequenceEqual(\n        NullableUUIDModel.objects.filter(field__regex=r'^550e8400'),\n        [self.objs[1]]\n    )\n"], "sample_977": ["def test_Sum():\n    assert mcode(Sum(x**k, (k, 0, n))) == \"Hold[Sum[x^k, {k, 0, n}]]\"\n    assert mcode(Sum(k**2, (k, 1, n))) == \"Hold[Sum[k^2, {k, 1, n}]]\"\n"], "sample_463": ["def test_alter_field_to_fk_dependency_other_app_with_initial_true(self):\n    class Migration(migrations.Migration):\n        initial = True\n        operations = [\n            migrations.CreateModel(\"Author\", fields=[(\"id\", models.AutoField(primary_key=True))]),\n            migrations.CreateModel(\"Book\", fields=[(\"author\", models.ForeignKey(\"Author\", models.CASCADE))]),\n        ]\n\n    migration = Migration(\"0001_initial\", \"test_app\")\n    changes = self.get_changes([], [migration])\n    self.assertNumberMigrations(changes, \"test_app\", 1)\n    self.assertOperationTypes(changes, \"test_app\", 0, [\"CreateModel\", \"CreateModel\"])\n    self.assertMigrationDependencies(changes, \"test_app\", 0, [])\n"], "sample_440": ["def test_update_conflicts_unique_fields_multiple(self):\n    UpsertConflict.objects.bulk_create(\n        [\n            UpsertConflict(number=1, rank=1, name=\"John\"),\n            UpsertConflict(number=2, rank=2, name=\"Mary\"),\n            UpsertConflict(number=3, rank=3, name=\"Hannah\"),\n        ]\n    )\n    self.assertEqual(UpsertConflict.objects.count(), 3)\n\n    conflicting_objects = [\n        UpsertConflict(number=1, rank=4, name=\"Steve\"),\n        UpsertConflict(number=2, rank=2, name=\"Olivia\"),\n        UpsertConflict(number=3, rank=1, name=\"Hannah\"),\n    ]\n    UpsertConflict.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        update_fields=[\"name\", \"rank\"],\n        unique_fields=[\"number\", \"rank\"],\n    )\n    self.assertEqual(UpsertConflict.objects.count(), 3)\n    self.assertCountEqual(\n        UpsertConflict.objects.values(\"number\", \"rank\", \"name\"),\n        [\n            {\"number\": 1, \"rank\": 1, \"name\": \"John\"},\n            {\"number\": 2, \"rank\": 2, \"name\": \"Olivia\"},\n            {\"number\": 3, \"rank\": 3, \"name\": \"Hannah\"},\n        ],\n    )\n"], "sample_177": ["def test_abstract_base_with_fk(self):\n    A = self.create_model(\"A\", abstract=True, foreign_keys=[models.ForeignKey('B', models.CASCADE)])\n    B = self.create_model(\"B\")\n    C = self.create_model(\"C\", bases=(A,))\n    self.assertRelated(A, [B, C])\n    self.assertRelated(B, [A, C])\n    self.assertRelated(C, [A, B])\n"], "sample_853": ["def test_transform_target_regressor_default_regressor():\n    X, y = friedman\n    regr = TransformedTargetRegressor(transformer=StandardScaler())\n    regr.fit(X, y)\n    assert isinstance(regr.regressor_, LinearRegression)\n"], "sample_933": ["def test_gettext_location_and_uuid(app):\n    app.builder.build(['index_entries'])\n\n    pot = (app.outdir / 'index_entries.pot').read_text()\n    assert \"#: index_entries.rst:1\" in pot\n    assert \"#: index_entries.rst:2\" in pot\n    assert \"#: index_entries.rst:3\" in pot\n    assert \"#: index_entries.rst:5\" in pot\n    assert \"#: index_entries.rst:6\" in pot\n    assert \"#: index_entries.rst:7\" in pot\n    assert \"#: index_entries.rst:8\" in pot\n    assert \"#: index_entries.rst:9\" in pot\n    assert \"#: index_entries.rst:11\" in pot\n    assert \"#: index_entries.rst:12\" in pot\n    assert \"#: index_entries.rst:13\" in pot\n    assert \"#: index_entries.rst:14\" in pot\n    assert \"#: index_entries.rst:15\" in pot\n    assert \"#: index_entries.rst:16\" in pot\n    assert \"#: index_entries.rst:17\" in pot\n    assert \"#: index_entries.rst:18\" in pot\n    assert \"#: index_entries.rst:19\" in pot\n    assert \"#: index_entries.rst:20\" in pot\n    assert \"#: index_entries.rst:21\" in pot\n    assert \"#: index_entries.rst:22\" in pot\n    assert \"#: index_entries.rst:23\" in pot\n    assert \"#: index_entries.rst:24\" in pot\n    assert \"#: index_entries.rst:25\" in pot\n    assert \"#: index_entries.rst:26\" in pot\n    assert \"#: index_entries.rst:"], "sample_424": ["def test_references_field_by_through_fields(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ManyToManyField(\"Other\", through_fields=(\"from\", \"to\")),\n    )\n    self.assertIs(operation.references_field(\"Model\", \"from\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Model\", \"to\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Other\", \"from\", \"migrations\"), False)\n    self.assertIs(operation.references_field(\"Other\", \"to\", \"migrations\"), False)\n"], "sample_326": ["def test_urlize_nofollow(self):\n    value = 'Check out this link: http://example.com'\n    output = 'Check out this link: <a href=\"http://example.com\" rel=\"nofollow\">http://example.com</a>'\n    self.assertEqual(urlize(value, nofollow=True), output)\n"], "sample_351": ["def test_model_choice_iterator_value_equality(self):\n    value_1 = ModelChoiceIteratorValue(self.c1.pk, self.c1)\n    value_2 = ModelChoiceIteratorValue(self.c1.pk, self.c2)\n    value_3 = ModelChoiceIteratorValue(self.c2.pk, self.c2)\n    self.assertEqual(value_1, value_2)\n    self.assertNotEqual(value_1, value_3)\n    self.assertNotEqual(value_1, self.c1.pk)\n"], "sample_448": ["def test_contains_expressions(self):\n    constraint_with_expressions = models.UniqueConstraint(\n        Lower(\"title\"),\n        F(\"author\"),\n        name=\"book_func_uq\",\n    )\n    constraint_without_expressions = models.UniqueConstraint(\n        fields=[\"foo\", \"bar\"],\n        name=\"unique_fields\",\n    )\n    self.assertTrue(constraint_with_expressions.contains_expressions)\n    self.assertFalse(constraint_without_expressions.contains_expressions)\n"], "sample_17": ["def test_structured_to_unstructured_nested_dtype(self):\n    struct = [(5, (400.0, 3e6))] * u.Unit(\"m, (cm, um)\")\n    unstruct = rfn.structured_to_unstructured(struct)\n    assert_array_equal(unstruct, [[5, 4, 3]] * u.m)\n"], "sample_760": ["def test_scorer_with_none_scoring():\n    # Test that check_scoring returns None when allow_none is True and no scoring is specified\n    estimator = EstimatorWithFit()\n    scorer = check_scoring(estimator, allow_none=True)\n    assert scorer is None\n"], "sample_657": ["def test_pytest_param_unknown_kwargs(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import warnings\n\n            with warnings.catch_warnings(record=True) as w:\n                pytest.param(1, 2, unknown_kwarg=3)\n                assert len(w) == 1\n                assert issubclass(w[-1].category, pytest.PytestWarning)\n                assert \"unknown_kwarg\" in str(w[-1].message)\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=1)\n"], "sample_346": ["def test_cache_control_decorator(self):\n    @cache_control(public=True, max_age=3600)\n        return HttpResponse()\n    r = a_view(HttpRequest())\n    self.assertEqual(r.headers['Cache-Control'], 'public, max-age=3600')\n"], "sample_922": ["def test_pyfunction_signature_with_type_annotation(app):\n    text = \".. py:function:: hello(name: str) -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_punctuation, \":\"],\n                                                      \" \",\n                                                      [nodes.inline, pending_xref, \"str\"])])\n"], "sample_314": ["    def test_validates_password(self):\n        user = User.objects.get(username='testclient')\n        data = {\n            'password1': 'testclient',\n            'password2': 'testclient',\n        }\n        form = AdminPasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(len(form[\"password2\"].errors), 2)\n        self.assertIn('The password is too similar to the username.', form[\"password2\"].errors)\n        self.assertIn(\n            'This password is too short. It must contain at least 12 characters.',\n            form[\"password2\"].errors\n        )\n"], "sample_656": ["def test_capture_with_live_logging_disabled(testdir, capture_fixture):\n    # Test that capture works with live cli logging disabled\n\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        import sys\n\n        logger = logging.getLogger(__name__)\n\n            print(\"hello\")\n            sys.stderr.write(\"world\\\\n\")\n            with {0}.disabled():\n                logging.info(\"something\")\n                print(\"next\")\n                logging.info(\"something\")\n\n            captured = {0}.readouterr()\n            assert captured.out == \"hello\\\\nworld\\\\nnext\\\\n\"\n        \"\"\".format(\n            capture_fixture\n        )\n    )\n\n    result = testdir.runpytest_subprocess(\"--log-cli-level=INFO\")\n    assert result.ret == 0\n"], "sample_453": ["def test_cell_count(self):\n    \"\"\"\n    cell_count template filter should return the correct number of cells.\n    \"\"\"\n    request = self.request_factory.get(\n        reverse(\"admin:admin_views_article_change\", args=[self.article.pk])\n    )\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    inline_admin_form = admin.get_inline_instances(request)[0]\n    count = cell_count(inline_admin_form)\n    # Calculate the expected count manually\n    expected_count = 1  # Hidden cell with hidden 'id' field\n    for fieldset in inline_admin_form:\n        for line in fieldset:\n            for field in line:\n                try:\n                    is_hidden = field.field.is_hidden\n                except AttributeError:\n                    is_hidden = field.field[\"is_hidden\"]\n                if not is_hidden:\n                    expected_count += 1\n    if inline_admin_form.formset.can_delete:\n        expected_count += 1  # Delete checkbox\n    self.assertEqual(count, expected_count)\n"], "sample_171": ["def test_makemigrations_app_name_specified_as_label_with_correct_label(self):\n    out = io.StringIO()\n    with self.temporary_migration_module(module=\"django.contrib.auth.migrations\"):\n        call_command(\"makemigrations\", \"auth\", stdout=out)\n    self.assertIn(\"Migrations for 'auth'\", out.getvalue())\n"], "sample_1208": ["def test_sample_numpy():\n    numpy = import_module('numpy')\n    if not numpy:\n        skip('NumPy is not installed. Abort tests for _sample_numpy.')\n    else:\n        # Currently, numpy_rv_map is empty in SampleMatrixNumpy class.\n        # So, we can't test it with any distribution.\n        # Once numpy_rv_map is updated with some distributions, we can add tests here.\n        pass\n"], "sample_1164": ["def test_cg_simp():\n    a = CG(1, 1, 0, 0, 1, 1)\n    b = CG(1, 0, 0, 0, 1, 0)\n    c = CG(1, -1, 0, 0, 1, -1)\n    assert cg_simp(a + b + c) == 3\n"], "sample_1122": ["def test_issue_14692():\n    from sympy import principal_branch, polar_lift, exp_polar, pi, I\n    x = Symbol('x')\n    assert principal_branch(exp_polar(-I*pi/2)/polar_lift(x), 2*pi) == exp_polar(-I*pi/2)/x\n"], "sample_78": ["def test_call_command_with_invalid_integer_option(self):\n    msg = \"argument --integer: invalid int value: 'invalid'\"\n    with self.assertRaisesMessage(CommandError, msg):\n        management.call_command('dance', '--integer=invalid')\n"], "sample_882": ["def test_mlp_early_stopping_with_partial_fit():\n    \"\"\"Check that early stopping works with partial fit.\"\"\"\n    mlp = MLPClassifier(max_iter=10, random_state=0, early_stopping=True)\n    mlp.partial_fit(X_iris[:50], y_iris[:50], classes=np.unique(y_iris))\n    n_validation_scores = len(mlp.validation_scores_)\n    mlp.partial_fit(X_iris[50:], y_iris[50:])\n    assert len(mlp.validation_scores_) > n_validation_scores\n"], "sample_347": ["def test_localtime(self):\n    naive = datetime.datetime(2015, 1, 1, 0, 0, 1)\n    with self.assertRaisesMessage(ValueError, 'localtime() cannot be applied to a naive datetime'):\n        timezone.localtime(naive)\n    with self.assertRaisesMessage(ValueError, 'localtime() cannot be applied to a naive datetime'):\n        timezone.localtime(naive, timezone=EAT)\n\n    aware = datetime.datetime(2015, 1, 1, 0, 0, 1, tzinfo=ICT)\n    self.assertEqual(timezone.localtime(aware, timezone=EAT), datetime.datetime(2014, 12, 31, 18, 0, 1, tzinfo=EAT))\n    with timezone.override(EAT):\n        self.assertEqual(timezone.localtime(aware), datetime.datetime(2014, 12, 31, 18, 0, 1, tzinfo=EAT))\n\n    with mock.patch('django.utils.timezone.now', return_value=aware):\n        self.assertEqual(timezone.localtime(timezone=EAT), datetime.datetime(2014, 12, 31, 18, 0, 1, tzinfo=EAT))\n        with timezone.override(EAT):\n            self.assertEqual(timezone.localtime(), datetime.datetime(2014, 12, 31, 18, 0, 1, tzinfo=EAT))\n"], "sample_397": ["def test_template_loaders_config(self):\n    \"\"\"Test the configuration of template loaders.\"\"\"\n    # Test with custom loaders\n    engine = DjangoTemplates(\n        {\n            \"DIRS\": [],\n            \"APP_DIRS\": False,\n            \"NAME\": \"django\",\n            \"OPTIONS\": {\n                \"loaders\": [\n                    \"django.template.loaders.filesystem.Loader\",\n                    \"django.template.loaders.app_directories.Loader\",\n                ],\n            },\n        }\n    )\n    self.assertEqual(\n        engine.engine.loaders,\n        [\n            (\n                \"django.template.loaders.cached.Loader\",\n                [\n                    \"django.template.loaders.filesystem.Loader\",\n                    \"django.template.loaders.app_directories.Loader\",\n                ],\n            )\n        ],\n    )\n\n    # Test with app_dirs and custom loaders\n    with self.assertRaisesMessage(\n        ImproperlyConfigured,\n        \"app_dirs must not be set when loaders is defined.\",\n    ):\n        DjangoTemplates(\n            {\n                \"DIRS\": [],\n                \"APP_DIRS\": True,\n                \"NAME\": \"django\",\n                \"OPTIONS\": {\n                    \"loaders\": [\n                        \"django.template.loaders.filesystem.Loader\",\n                    ],\n                },\n            }\n        )\n"], "sample_390": ["def test_directory_index_template(self):\n    response = self.client.get(\"/%s/\" % self.prefix)\n    self.assertContains(response, \"<title>Index of ./</title>\")\n    self.assertContains(response, \"<h1>Index of ./</h1>\")\n    self.assertContains(response, \"<li><a href=\\\"subdir/\\\">subdir/</a></li>\")\n"], "sample_386": ["def test_safe_string_concatenation(self):\n    s1 = mark_safe(\"a&b\")\n    s2 = mark_safe(\"c&d\")\n    s3 = s1 + s2\n    self.assertIsInstance(s3, SafeString)\n    self.assertEqual(s3, \"a&bc&d\")\n"], "sample_119": ["def test_foreign_key_related_name(self):\n    query = Query(Item)\n    where = query.build_where(Q(creator__items__modified__gt=datetime(2017, 1, 1)))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertEqual(lookup.lhs.target, Item._meta.get_field('modified'))\n    self.assertEqual(lookup.lhs.alias, 'creator__items')\n"], "sample_881": ["def test_top_k_accuracy_score_multiclass_without_labels():\n    \"\"\"Test when y_score is multiclass and labels is None.\"\"\"\n    y_true = np.array([0, 1, 1, 2])\n    y_score = np.array(\n        [\n            [0.4, 0.3, 0.2, 0.1],\n            [0.1, 0.3, 0.4, 0.2],\n            [0.4, 0.1, 0.2, 0.3],\n            [0.3, 0.2, 0.4, 0.1],\n        ]\n    )\n    true_score = 0.75\n\n    score = top_k_accuracy_score(y_true, y_score, k=2)\n    assert score == pytest.approx(true_score)\n"], "sample_832": ["def test_bayesian_ridge_intercept():\n    # Test BayesianRidge with and without intercept\n    X = np.array([[1], [2], [6], [8], [10]])\n    Y = np.array([1, 2, 6, 8, 10])\n    clf_with_intercept = BayesianRidge(compute_score=True, fit_intercept=True)\n    clf_without_intercept = BayesianRidge(compute_score=True, fit_intercept=False)\n    clf_with_intercept.fit(X, Y)\n    clf_without_intercept.fit(X, Y)\n\n    # Check that the intercept is not zero when fit_intercept is True\n    assert clf_with_intercept.intercept_ != 0\n\n    # Check that the intercept is zero when fit_intercept is False\n    assert clf_without_intercept.intercept_ == 0\n\n    # Check that the coefficients are not equal when fit_intercept is True and False\n    assert_array_almost_equal(clf_with_intercept.coef_, clf_without_intercept.coef_, decimal=5)\n"], "sample_231": ["    def test_unicode_error_in_post_parameters(self):\n        \"\"\"\n        Unicode errors in POST parameters should be handled gracefully.\n        \"\"\"\n        data = {'key': 'value\\x80'}\n        request = self.rf.post('/some_url/', data)\n        try:\n            raise ValueError(\"Test error\")\n        except ValueError:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        html = reporter.get_traceback_html()\n        self.assertIn(\"'key': 'value\\\\x80'\", html)\n"], "sample_1019": ["def test_issue_8263_with_commutative_symbols():\n    x, y = symbols('x, y')\n    expr, dummies, _ = _mask_nc(x*y - y*x)\n    assert expr == 0\n    assert dummies == {}\n"], "sample_21": ["def test_read_write_simple_with_err_specs(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3]))\n    t1.add_column(Column(name=\"a_err\", data=[0.1, 0.2, 0.3]))\n    t1.write(test_file, format=\"ascii.qdp\", err_specs={\"serr\": [2]})\n    t2 = Table.read(test_file, table_id=0, format=\"ascii.qdp\", names=[\"a\"])\n    assert np.allclose(t2[\"a\"], t1[\"a\"])\n    assert np.allclose(t2[\"a_err\"], t1[\"a_err\"])\n"], "sample_765": ["def test_balanced_accuracy_score_multiclass():\n    # Test balanced accuracy score for multiclass classification task\n    y_true, y_pred, _ = make_prediction(binary=False)\n\n    # compute score with default labels introspection\n    score = balanced_accuracy_score(y_true, y_pred)\n    assert_almost_equal(score, 0.51, 2)\n\n    # compute score with explicit label ordering\n    score = balanced_accuracy_score(y_true, y_pred, labels=[2, 1, 0])\n    assert_almost_equal(score, 0.51, 2)\n"], "sample_253": ["def test_glob_with_nonexistent_directory(self, mocked_modules, notify_mock):\n    nonexistent_dir = self.tempdir / 'nonexistent'\n    self.reloader.watch_dir(nonexistent_dir, '*.py')\n    with self.tick_twice():\n        pass\n    self.assertEqual(notify_mock.call_count, 0)\n"], "sample_246": ["    def test_no_obsolete_enabled(self):\n        management.call_command('makemessages', locale=[LOCALE], verbosity=0, no_obsolete=True)\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertNotIn(\"#~\", po_contents)\n"], "sample_796": ["def test_huber_epsilon_validation():\n    # Test that an error is raised when epsilon is less than 1.0\n    X, y = make_regression_with_outliers()\n    with pytest.raises(ValueError, match=\"epsilon should be greater than or equal to 1.0, got\"):\n        huber = HuberRegressor(epsilon=0.9)\n        huber.fit(X, y)\n"], "sample_35": ["def test_isinstancemethod():\n    class MyClass:\n\n        @classmethod\n\n        @staticmethod\n\n    assert isinstancemethod(MyClass, MyClass.an_instancemethod)\n    assert not isinstancemethod(MyClass, MyClass.a_classmethod)\n    assert not isinstancemethod(MyClass, MyClass.a_staticmethod)\n"], "sample_913": ["def test_pyclass_signature(app):\n    text = \".. py:class:: Class\\n\"\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_name, \"Class\"])],\n                                  [desc_content, ()])]))\n    assert 'Class' in domain.objects\n    assert domain.objects['Class'] == ('index', 'Class', 'class')\n"], "sample_508": ["def test_set_is_not_overwritten():\n    \"\"\"set() defined in Artist subclasses should not be overwritten.\"\"\"\n    class MyArtist4(martist.Artist):\n            \"\"\"Not overwritten.\"\"\"\n\n    assert MyArtist4.set.__doc__ == \"Not overwritten.\"\n"], "sample_865": ["def test_prune_tree_raises_not_fitted():\n    clf = DecisionTreeClassifier()\n    msg = \"This DecisionTreeClassifier instance is not fitted yet\"\n\n    with pytest.raises(NotFittedError, match=msg):\n        clf._prune_tree()\n"], "sample_941": ["def test_restify_type_hints_NewType():\n    assert restify(MyInt) == \":class:`MyInt`\"\n"], "sample_109": ["def test_render_options_with_custom_choices(self):\n    beatles = Band.objects.create(name='The Beatles', style='rock')\n    who = Band.objects.create(name='The Who', style='rock')\n    choices = [(beatles.pk, 'Fab Four'), (who.pk, 'The Who')]\n    form = forms.Form({\n        'band': beatles.pk,\n    }, widgets={\n        'band': AutocompleteSelect(\n            Album._meta.get_field('band').remote_field,\n            admin.site,\n            choices=choices,\n        ),\n    })\n    output = form.as_table()\n    selected_option = '<option value=\"%s\" selected>Fab Four</option>' % beatles.pk\n    option = '<option value=\"%s\">The Who</option>' % who.pk\n    self.assertIn(selected_option, output)\n    self.assertNotIn(option, output)\n"], "sample_380": ["def test_aggregation_default_using_float_from_python(self):\n    result = Book.objects.filter(rating__lt=3.0).aggregate(\n        value=Sum('price', default=0.0),\n    )\n    self.assertEqual(result['value'], 0.0)\n"], "sample_615": ["def test_polyval_with_nan() -> None:\n    xcoord = xr.DataArray(\n        pd.date_range(\"2000-01-01\", freq=\"D\", periods=10), dims=(\"x\",), name=\"x\"\n    )\n    xcoord[5] = np.nan\n    da = xr.DataArray(\n        np.stack((1.0 + xcoord + 2.0 * xcoord**2, 1.0 + 2.0 * xcoord + 3.0 * xcoord**2)),\n        dims=(\"d\", \"x\"),\n        coords={\"x\": xcoord, \"d\": [0, 1]},\n    )\n    coeffs = xr.DataArray(\n        [[2, 1, 1], [3, 2, 1]],\n        dims=(\"d\", \"degree\"),\n        coords={\"d\": [0, 1], \"degree\": [2, 1, 0]},\n    )\n\n    da_pv = xr.polyval(da.x, coeffs)\n\n    xr.testing.assert_allclose(da, da_pv.T, equal_nan=True)\n"], "sample_605": ["def test_groupby_fillna(array):\n    grouped = array.groupby(\"y\")\n    filled = grouped.fillna(0)\n    assert_identical(filled, array.fillna(0))\n"], "sample_628": ["def test_skip_unicode_and_raw_strings(self):\n    stmt = astroid.extract_node(\n        'class ComentAbc(object):\\n   \"\"\"u\"coment\" and r\"coment\" are not misspelled\"\"\"\\n   pass'\n    )\n    self.checker.visit_classdef(stmt)\n    assert self.linter.release_messages() == []\n"], "sample_583": ["def test_posify_mask_subindexer():\n    index = np.array([0, 1, -1, 3, -1, 5])\n    expected = np.array([0, 1, 2, 3, 4, 5])\n    actual = indexing._posify_mask_subindexer(index)\n    np.testing.assert_array_equal(expected, actual)\n\n    index = np.array([-1, -1, -1, -1, -1])\n    expected = np.array([0, 0, 0, 0, 0])\n    actual = indexing._posify_mask_subindexer(index)\n    np.testing.assert_array_equal(expected, actual)\n\n    index = np.array([0, 1, 2, 3, 4])\n    expected = np.array([0, 1, 2, 3, 4])\n    actual = indexing._posify_mask_subindexer(index)\n    np.testing.assert_array_equal(expected, actual)\n"], "sample_170": ["def test_sensitive_variables_decorator_with_all_variables(self):\n    \"\"\"\n    The sensitive_variables decorator works when all variables are marked as sensitive.\n    \"\"\"\n    self.verify_paranoid_response(sensitive_view, check_for_POST_params=False)\n    self.verify_paranoid_email(sensitive_view, check_for_POST_params=False)\n"], "sample_241": ["def test_expression_wrapper_with_none(self):\n    expr = ExpressionWrapper(Value(None), output_field=IntegerField())\n    self.assertIsNone(expr.resolve_expression(query=None))\n"], "sample_772": ["def test_custom_backend():\n    # Test if custom backend is used\n    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)\n    all_estimators = [RandomForestClassifier, RandomForestRegressor,\n                      ExtraTreesClassifier, ExtraTreesRegressor]\n\n    for Estimator in all_estimators:\n        backend = MyBackend()\n        with register_parallel_backend('test', backend):\n            with parallel_backend('test'):\n                est = Estimator(n_jobs=2)\n                est.fit(X, y)\n                assert backend.count > 0\n"], "sample_1097": ["def test_BlockMatrix_as_real_imag():\n    A, B, C, D = [MatrixSymbol(s, 3, 3) for s in 'ABCD']\n    X = BlockMatrix([[A, B], [C, D]])\n    real_X, imag_X = X.as_real_imag()\n    assert real_X == BlockMatrix([[re(A), re(B)], [re(C), re(D)]])\n    assert imag_X == BlockMatrix([[im(A), im(B)], [im(C), im(D)]])\n"], "sample_1187": ["def test_hyperplane_parameters():\n    triangle = Polygon(Point(0, 3), Point(5, 3), Point(1, 1))\n    assert hyperplane_parameters(triangle) == [((0, 1), 3), ((1, -2), -1), ((-2, -1), -3)]\n\n    cube = [[(0, 0, 0), (0, 0, 5), (0, 5, 0), (0, 5, 5), (5, 0, 0),\n             (5, 0, 5), (5, 5, 0), (5, 5, 5)],\n            [2, 6, 7, 3], [3, 7, 5, 1], [7, 6, 4, 5], [1, 5, 4, 0],\n            [3, 1, 0, 2], [0, 4, 6, 2]]\n    assert hyperplane_parameters(cube[1:], cube[0]) == [([0, -1, 0], -5), ([0, 0, -1], -5),\n                                                       ([-1, 0, 0], -5), ([0, 1, 0], 0),\n                                                       ([1, 0, 0], 0), ([0, 0, 1], 0)]\n"], "sample_322": ["def test_minimize_rollbacks_with_replacements(self):\n    \"\"\"\n    Minimize rollbacks when target has replacements.\n\n    a: 1 <---- 3 <--\\\n              \\ \\- 2 <--- 4\n               \\       \\\n    b:      \\- 1 <--- 2\n    \"\"\"\n    a1_impl = FakeMigration('a1')\n    a1 = ('a', '1')\n    a2_impl = FakeMigration('a2')\n    a2 = ('a', '2')\n    a3_impl = FakeMigration('a3')\n    a3 = ('a', '3')\n    a4_impl = FakeMigration('a4')\n    a4 = ('a', '4')\n    b1_impl = FakeMigration('b1')\n    b1 = ('b', '1')\n    b2_impl = FakeMigration('b2')\n    b2 = ('b', '2')\n    graph = MigrationGraph()\n    graph.add_node(a1, a1_impl)\n    graph.add_node(a2, a2_impl)\n    graph.add_node(a3, a3_impl)\n    graph.add_node(a4, a4_impl)\n    graph.add_node(b1, b1_impl)\n    graph.add_node(b2, b2_impl)\n    graph.add_dependency(None, a2, a1)\n    graph.add_dependency(None, a3, a1)\n    graph.add_dependency(None, a4, a2)\n    graph.add_dependency(None, a4, a3)\n    graph.add_dependency(None, b2, b1)\n    graph.add_dependency(None, b1, a1)\n    graph.add_dependency(None, b2, a2)\n\n    # Add replacement for a2\n    a2_replaced_impl = FakeMigration('a2_replaced')\n    a2_replaced = ('a', '2_replaced')\n    graph.add"], "sample_912": ["def test_pyclass_signature(app):\n    text = \".. py:class:: Class\\n\"\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_name, \"Class\"])],\n                                  [desc_content, ()])]))\n    assert 'Class' in domain.objects\n    assert domain.objects['Class'] == ('index', 'class', 'class')\n"], "sample_155": ["def test_file_from_disk_with_custom_filename(self):\n    custom_filename = \"custom_file.py\"\n    response = FileResponse(open(__file__, 'rb'), filename=custom_filename)\n    self.assertEqual(response['Content-Length'], str(os.path.getsize(__file__)))\n    self.assertIn(response['Content-Type'], ['text/x-python', 'text/plain'])\n    self.assertEqual(response['Content-Disposition'], f'inline; filename=\"{custom_filename}\"')\n    response.close()\n"], "sample_625": ["def test_polyfit_polyval_integration_with_coords(\n    use_dask: bool, x: xr.DataArray, y: xr.DataArray"], "sample_137": ["def test_replace_named_groups(self):\n    pattern = \"^(?P<a>\\w+)/b/(\\w+)$\"\n    replaced_pattern = replace_named_groups(pattern)\n    self.assertEqual(replaced_pattern, \"^<a>/b/(\\\\w+)$\")\n\n    pattern = \"^(?P<a>\\w+)/b/(?P<c>\\w+)/$\"\n    replaced_pattern = replace_named_groups(pattern)\n    self.assertEqual(replaced_pattern, \"^<a>/b/<c>/$\")\n\n    pattern = \"^(?P<a>\\w+)/b/(\\w+)\"\n    replaced_pattern = replace_named_groups(pattern)\n    self.assertEqual(replaced_pattern, \"^<a>/b/(\\\\w+)\")\n\n    pattern = \"^(?P<a>\\w+)/b/(?P<c>\\w+)\"\n    replaced_pattern = replace_named_groups(pattern)\n    self.assertEqual(replaced_pattern, \"^<a>/b/<c>\")\n"], "sample_125": ["def test_secure_cookie(self):\n    \"\"\"Cookie with secure flag is set when key starts with __Secure- or __Host-.\"\"\"\n    response = HttpResponse()\n    response.set_cookie('__Secure-example', 'value')\n    secure_cookie = response.cookies['__Secure-example']\n    self.assertIn('; %s' % cookies.Morsel._reserved['secure'], str(secure_cookie))\n    self.assertIs(secure_cookie['secure'], True)\n\n    response = HttpResponse()\n    response.set_cookie('__Host-example', 'value')\n    host_cookie = response.cookies['__Host-example']\n    self.assertIn('; %s' % cookies.Morsel._reserved['secure'], str(host_cookie))\n    self.assertIs(host_cookie['secure'], True)\n"], "sample_457": ["def test_expressions_and_deferrable(self):\n    message = \"UniqueConstraint with expressions cannot be deferred.\"\n    with self.assertRaisesMessage(ValueError, message):\n        models.UniqueConstraint(\n            Lower(\"name\"),\n            name=\"deferred_expression_unique\",\n            deferrable=models.Deferrable.DEFERRED,\n        )\n"], "sample_67": ["def test_setattr_raises_validation_error_multiple_fields(self):\n    \"\"\"\n    A model ValidationError using the dict form with multiple fields should\n    put the error messages into the correct keys of form.errors.\n    \"\"\"\n    form_class = modelform_factory(model=StrictAssignmentMultipleFields, fields=['title', 'description'])\n    form = form_class(data={'title': 'testing setattr', 'description': 'testing setattr'}, files=None)\n    # This line turns on the ValidationError; it avoids the model erroring\n    # when its own __init__() is called when creating form.instance.\n    form.instance._should_error = True\n    self.assertFalse(form.is_valid())\n    self.assertEqual(form.errors, {\n        'title': ['Cannot set attribute'],\n        'description': ['Cannot set attribute', 'This field cannot be blank.']\n    })\n"], "sample_627": ["def test_concat_index_types() -> None:\n    # Test concatenating datasets with different index types\n    ds1 = Dataset(coords={\"x\": pd.Index([1, 2], name=\"x\")})\n    ds2 = Dataset(coords={\"x\": pd.MultiIndex.from_tuples([(3, \"a\"), (4, \"b\")], names=[\"x\", \"y\"])})\n\n    with pytest.raises(ValueError, match=r\"'x' must have either an index or no index in all datasets.*\"):\n        concat([ds1, ds2], dim=\"x\")\n"], "sample_606": ["def test_polyval_with_nan() -> None:\n    xcoord = xr.DataArray(\n        pd.date_range(\"2000-01-01\", freq=\"D\", periods=10), dims=(\"x\",), name=\"x\"\n    )\n    xcoord[5] = np.nan\n\n    da = xr.DataArray(\n        np.stack((1.0 + x + 2.0 * x ** 2, 1.0 + 2.0 * x + 3.0 * x ** 2)),\n        dims=(\"d\", \"x\"),\n        coords={\"x\": xcoord, \"d\": [0, 1]},\n    )\n    coeffs = xr.DataArray(\n        [[2, 1, 1], [3, 2, 1]],\n        dims=(\"d\", \"degree\"),\n        coords={\"d\": [0, 1], \"degree\": [2, 1, 0]},\n    )\n\n    da_pv = xr.polyval(da.x, coeffs)\n\n    xr.testing.assert_allclose(da.isel(x=~np.isnan(xcoord)), da_pv.T.isel(x=~np.isnan(xcoord)))\n"], "sample_867": ["def test_grid_search_cv_splits_consistency_with_groups():\n    # Check if a one time iterable is accepted as a cv parameter with groups.\n    n_samples = 100\n    n_splits = 5\n    X, y = make_classification(n_samples=n_samples, random_state=0)\n    groups = np.random.randint(0, 3, n_samples)\n\n    gs = GridSearchCV(LinearSVC(random_state=0),\n                      param_grid={'C': [0.1, 0.2, 0.3]},\n                      cv=GroupKFold(n_splits=n_splits),\n                      return_train_score=True)\n    gs.fit(X, y, groups=groups)\n\n    gs2 = GridSearchCV(LinearSVC(random_state=0),\n                       param_grid={'C': [0.1, 0.2, 0.3]},\n                       cv=LeaveOneGroupOut(),\n                       return_train_score=True)\n    gs2.fit(X, y, groups=groups)\n\n    # Check if the splits are consistent\n    np.testing.assert_equal({k: v for k, v in gs.cv_results_.items()\n                             if not k.endswith('_time')},\n                            {k: v for k, v in gs2.cv_results_.items()\n                             if not k.endswith('_time')})\n"], "sample_178": ["def test_formset_with_initial_and_extra(self):\n    \"\"\"FormSet with initial data and extra forms.\"\"\"\n    initial = [{'choice': 'Calexico', 'votes': 100}]\n    ChoiceFormSet = formset_factory(Choice, extra=2)\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_1124": ["def test_FracElement_compose():\n    F, x, y = field(\"x, y\", ZZ)\n    G, u, v = field(\"u, v\", F)\n    f = (u + v) / (u - v)\n    g = u**2 - v\n    h = f.compose(u, g)\n    assert h == (g + g**2) / (g - g**2)\n"], "sample_100": ["def test_watch_dir_with_unresolvable_path_in_glob(self, mocked_modules, notify_mock):\n    path = Path('unresolvable_directory')\n    with mock.patch.object(Path, 'glob', side_effect=FileNotFoundError):\n        self.reloader.watch_dir(path, '**/*.mo')\n    self.assertEqual(list(self.reloader.directory_globs), [])\n"], "sample_755": ["def test_davies_bouldin_score():\n    assert_raises_on_only_one_label(davies_bouldin_score)\n\n    assert_raises_on_all_points_same_cluster(davies_bouldin_score)\n\n    # Assert the value is 0. when all samples are equals\n    assert 0. == davies_bouldin_score(np.ones((10, 2)),\n                                      [0] * 5 + [1] * 5)\n\n    # Assert the value is 0. when all the mean cluster are equal\n    assert 0. == davies_bouldin_score([[-1, -1], [1, 1]] * 10,\n                                      [0] * 10 + [1] * 10)\n\n    # General case (with non numpy arrays)\n    X = ([[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5 +\n         [[0, 4], [1, 3]] * 5 + [[3, 1], [4, 0]] * 5)\n    labels = [0] * 10 + [1] * 10 + [2] * 10 + [3] * 10\n    pytest.approx(davies_bouldin_score(X, labels),\n                  0.5 * (1 + 1 + 2 + 2) / 4)\n"], "sample_879": ["def test_ordinal_encoder_missing_unknown_encoding_min():\n    \"\"\"Check missing value or unknown encoding can equal the minimum cardinality.\"\"\"\n    X = np.array([[\"dog\"], [\"cat\"], [np.nan]], dtype=object)\n    X_trans = OrdinalEncoder(encoded_missing_value=-1).fit_transform(X)\n    assert_allclose(X_trans, [[0], [1], [-1]])\n\n    enc = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1).fit(X)\n    X_test = np.array([[\"snake\"]])\n    X_trans = enc.transform(X_test)\n    assert_allclose(X_trans, [[-1]])\n"], "sample_335": ["def test_decimalfield_invalid_input(self):\n    f = DecimalField(max_digits=4, decimal_places=2)\n    with self.assertRaisesMessage(ValidationError, \"'Enter a number.'\"):\n        f.clean('invalid')\n"], "sample_222": ["    def test_lock_unlock_with_file_object(self):\n        with tempfile.NamedTemporaryFile() as temp_file:\n            self.assertIs(locks.lock(temp_file, locks.LOCK_EX), True)\n            self.assertIs(locks.unlock(temp_file), True)\n"], "sample_392": ["def test_key_transform_exact(self):\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__d__1__f__exact=\"g\"),\n        [self.objs[4]],\n    )\n"], "sample_1109": ["def test_frac_with_complex_arguments():\n    assert frac(I*r) == I*frac(r)\n    assert frac(1 + I*r) == I*frac(r)\n    assert frac(0.5 + I*r) == 0.5 + I*frac(r)\n    assert frac(n + I*r) == I*frac(r)\n    assert frac(n + I*k) == 0\n    assert unchanged(frac, x + I*x)\n    assert frac(x + I*n) == frac(x)\n"], "sample_310": ["    def test_simplify_regex_with_named_groups(self):\n        pattern = \"^(?P<sport_slug>\\w+)/athletes/(?P<athlete_slug>\\w+)/$\"\n        simplified = simplify_regex(pattern)\n        self.assertEqual(simplified, \"/<sport_slug>/athletes/<athlete_slug>/\")\n"], "sample_1053": ["def test_Float_floor_ceiling():\n    a = Float(3.7)\n    b = Float(3.2)\n\n    assert(a.floor() == 3.0)\n    assert(a.ceiling() == 4.0)\n    assert(b.floor() == 3.0)\n    assert(b.ceiling() == 4.0)\n"], "sample_1129": ["def test_log1p_and_expm1():\n    expr1 = log1p(x)\n    expr2 = expm1(x)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr1) == 'numpy.log1p(x)'\n    assert prntr.doprint(expr2) == 'numpy.expm1(x)'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr1) == 'numpy.log1p(x)'\n    assert prntr.doprint(expr2) == 'numpy.expm1(x)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr1) == 'math.log1p(x)'\n    assert prntr.doprint(expr2) == 'math.expm1(x)'\n\n    prntr = MpmathPrinter()\n    assert prntr.doprint(expr1) == 'mpmath.log1p(x)'\n    assert prntr.doprint(expr2) == 'mpmath.expm1(x)'\n"], "sample_528": ["def test_context_with_after_reset():\n    original_value = 'gray'\n    other_value = 'blue'\n    mpl.rcParams[PARAM] = original_value\n    with temp_style('test', DUMMY_SETTINGS):\n        with style.context('test', after_reset=True):\n            assert mpl.rcParams[PARAM] == VALUE\n    # Check that this value is reset after the exiting the context.\n    assert mpl.rcParams[PARAM] == original_value\n"], "sample_700": ["def test_mark_skip_item(pytester: Pytester) -> None:\n    # Ensure pytest.mark.skip works with non-Python Item\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n        class MyItem(pytest.Item):\n            nodeid = 'foo'\n                marker = pytest.mark.skip(\"Expected skip\")\n                self.add_marker(marker)\n                assert False\n\n            return MyItem.from_parent(name=\"foo\", parent=parent)\n    \"\"\"\n    )\n    result = pytester.inline_run()\n    passed, skipped, failed = result.listoutcomes()\n    assert not failed\n    assert skipped\n"], "sample_248": ["def test_shell_with_bpython_not_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import bpython interface.\"):\n        call_command('shell', interface='bpython')\n"], "sample_519": ["def test_figure_pick():\n    fig, ax = plt.subplots()\n    line, = ax.plot([0, 1], [0, 1], picker=True)\n    fig.canvas.draw()\n    assert not fig.stale\n\n    mouse_event = SimpleNamespace(x=ax.bbox.x0 + ax.bbox.width / 2,\n                                  y=ax.bbox.y0 + ax.bbox.height / 2,\n                                  inaxes=ax, guiEvent=None)\n    fig.pick(mouse_event)\n    assert not fig.stale\n"], "sample_1163": ["def test_issue_14692():\n    from sympy import principal_branch, polar_lift, exp_polar, I, pi\n    x = Symbol('x', real=True)\n    assert principal_branch(exp_polar(-I*pi/2)/polar_lift(x), 2*pi) == exp_polar(-I*pi/2)/x\n"], "sample_747": ["def test_power_transformer_yeo_johnson():\n    X = np.abs(X_2d)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method='yeo-johnson', standardize=standardize)\n\n        X_trans_class = pt.fit_transform(X)\n        X_trans_func = power_transform(X, method='yeo-johnson', standardize=standardize)\n\n        for X_trans in [X_trans_class, X_trans_func]:\n            for j in range(X_trans.shape[1]):\n                X_expected, lmbda = stats.yeojohnson(X[:, j].flatten())\n\n                if standardize:\n                    X_expected = scale(X_expected)\n\n                assert_almost_equal(X_trans[:, j], X_expected)\n                assert_almost_equal(lmbda, pt.lambdas_[j])\n\n            # Test inverse transformation\n            X_inv = pt.inverse_transform(X_trans)\n            assert_array_almost_equal(X_inv, X)\n\n        assert len(pt.lambdas_) == X.shape[1]\n        assert isinstance(pt.lambdas_, np.ndarray)\n"], "sample_1021": ["def test_quaternion_multiplication():\n    q1 = Quaternion(1, 2, 3, 4)\n    q2 = Quaternion(5, 6, 7, 8)\n    assert q1 * q2 == Quaternion(-60, 12, 30, 24)\n    assert q1 * 2 == Quaternion(2, 4, 6, 8)\n    assert 2 * q1 == Quaternion(2, 4, 6, 8)\n    q3 = Quaternion(3 + 4*I, 2 + 5*I, 0, 7 + 8*I, real_field = False)\n    assert q3 * (2 + 3*I) == Quaternion((2 + 3*I)*(3 + 4*I), (2 + 3*I)*(2 + 5*I), 0, (2 + 3*I)*(7 + 8*I))\n"], "sample_641": ["def test_load_results_nonexistent_file(path: str) -> None:\n    loaded = load_results(path)\n    assert loaded is None\n"], "sample_104": ["def test_template_tag_non_ascii_content(self):\n    relpath = self.hashed_file_path(\"test/nonascii.css\")\n    self.assertEqual(relpath, \"test/nonascii.deploy12345.css\")\n    with storage.staticfiles_storage.open(relpath) as relfile:\n        content = relfile.read()\n        self.assertNotIn(b\"test/nonascii.png\", content)\n        self.assertIn(b\"nonascii.deploy12345.png\", content)\n"], "sample_894": ["def test_random_trees_embedding_feature_names_out_input_features():\n    \"\"\"Check feature names out for Random Trees Embedding with input features.\"\"\"\n    random_state = np.random.RandomState(0)\n    X = np.abs(random_state.randn(100, 4))\n    input_features = [\"feature_1\", \"feature_2\", \"feature_3\", \"feature_4\"]\n    hasher = RandomTreesEmbedding(\n        n_estimators=2, max_depth=2, sparse_output=False, random_state=0\n    ).fit(X, feature_names=input_features)\n    names = hasher.get_feature_names_out(input_features=input_features)\n    expected_names = [\n        f\"randomtreesembedding_{tree}_{leaf}\"\n        # Note: nodes with indices 0, 1 and 4 are internal split nodes and\n        # therefore do not appear in the expected output feature names.\n        for tree, leaf in [\n            (0, 2),\n            (0, 3),\n            (0, 5),\n            (0, 6),\n            (1, 2),\n            (1, 3),\n            (1, 5),\n            (1, 6),\n        ]\n    ]\n    assert_array_equal(expected_names, names)\n"], "sample_51": ["    def test_parse_iso8601_duration(self):\n        test_values = (\n            ('P1D', timedelta(days=1)),\n            ('P1DT1H', timedelta(days=1, hours=1)),\n            ('P1DT1H1M', timedelta(days=1, hours=1, minutes=1)),\n            ('P1DT1H1M1S', timedelta(days=1, hours=1, minutes=1, seconds=1)),\n            ('P1DT1H1M1.5S', timedelta(days=1, hours=1, minutes=1, seconds=1, milliseconds=500)),\n            ('P1Y', None),  # Years are not supported by timedelta\n            ('P1M', None),  # Months are not supported by timedelta\n            ('P1W', None),  # Weeks are not supported by timedelta\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_355": ["    def setUpTestData(cls):\n        cls.user = User.objects.create_user('test', 'test@example.com', 'test')\n"], "sample_461": ["def test_urlfield_clean_with_assume_scheme(self):\n    f = URLField(assume_scheme=\"https\")\n    self.assertEqual(f.clean(\"example.com\"), \"https://example.com\")\n    self.assertEqual(f.clean(\"http://example.com\"), \"http://example.com\")\n    self.assertEqual(f.clean(\"https://example.com\"), \"https://example.com\")\n"], "sample_22": ["def test_matrix_product():\n    \"\"\"Test the matrix product function ``matrix_product``.\"\"\"\n    m1 = np.array([[1, 2], [3, 4]])\n    m2 = np.array([[5, 6], [7, 8]])\n    expected_product = np.array([[19, 22], [43, 50]])\n    assert_array_equal(matrix_product(m1, m2), expected_product)\n\n    # Test with more than two matrices\n    m3 = np.array([[9, 10], [11, 12]])\n    expected_product = np.array([[87, 100], [183, 214]])\n    assert_array_equal(matrix_product(m1, m2, m3), expected_product)\n\n    # Test with deprecated function\n    with pytest.warns(AstropyDeprecationWarning):\n        assert_array_equal(matrix_product(m1, m2), np.matmul(m1, m2))\n"], "sample_375": ["def test_abstract_model_children_inherit_constraints(self):\n    class Abstract(models.Model):\n        size = models.IntegerField()\n\n        class Meta:\n            app_label = 'migrations'\n            abstract = True\n            constraints = [models.CheckConstraint(check=models.Q(size__gt=1), name='size_gt_1')]\n\n    class Child1(Abstract):\n        pass\n\n    class Child2(Abstract):\n        pass\n\n    child1_state = ModelState.from_model(Child1)\n    child2_state = ModelState.from_model(Child2)\n    constraint_names = [constraint.name for constraint in child1_state.options['constraints']]\n    self.assertEqual(constraint_names, ['size_gt_1'])\n    constraint_names = [constraint.name for constraint in child2_state.options['constraints']]\n    self.assertEqual(constraint_names, ['size_gt_1'])\n\n    # Modifying the state doesn't modify the constraint on the model.\n    child1_state.options['constraints'][0].name = 'bar'\n    self.assertEqual(Child1._meta.constraints[0].name, 'size_gt_1')\n"], "sample_539": ["def test_polygon_selector_box_handle_props(ax):\n    # Create a diamond shape\n    verts = [(20, 0), (0, 20), (20, 40), (40, 20)]\n    event_sequence = [\n        *polygon_place_vertex(*verts[0]),\n        *polygon_place_vertex(*verts[1]),\n        *polygon_place_vertex(*verts[2]),\n        *polygon_place_vertex(*verts[3]),\n        *polygon_place_vertex(*verts[0]),\n    ]\n\n    # Create selector with custom box handle properties\n    tool = widgets.PolygonSelector(ax, onselect=noop, draw_bounding_box=True,\n                                   box_handle_props={'color': 'r', 'size': 10})\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n\n    # Check that the box handle properties were set correctly\n    for handle in tool._box._corner_handles.artists:\n        assert handle.get_color() == 'r'\n        assert handle.get_size() == 10\n"], "sample_220": ["def test_delete_cookie_samesite_none(self):\n    \"\"\"\n    delete_cookie() sets the secure flag if samesite='none'.\n    \"\"\"\n    response = HttpResponse()\n    response.delete_cookie('c', samesite='none')\n    self.assertIs(response.cookies['c']['secure'], True)\n"], "sample_1128": ["def test_point_vel_with_different_frames():\n    q1, q2 = dynamicsymbols('q1 q2')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    P = Point('P')\n    P.set_vel(N, q1 * N.x)\n    P.set_vel(B, q2 * B.y)\n    assert P.vel(N) == q1 * N.x\n    assert P.vel(B) == q2 * B.y\n"], "sample_763": ["def test_retrieve_samples_from_non_standard_shape():\n    class TestNonNumericShape:\n            self.shape = (\"not numeric\",)\n\n    with pytest.raises(TypeError):\n        _num_samples(TestNonNumericShape())\n"], "sample_1067": ["def test_issue_6421():\n    x = Symbol('x')\n    a = Wild('a')\n    assert (I*x).match(a*I) == {a: x}\n    assert (x*I).match(a*I) == {a: x}\n    assert (x*I*I).match(a*I) == {a: -x}\n    assert (x*I*I*I).match(a*I) == {a: -I*x}\n    assert (x*I*I*I*I).match(a*I) == {a: x}\n"], "sample_207": ["def test_key_transform_exact(self):\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__d__1__exact={'f': 'g'}),\n        [self.objs[4]],\n    )\n"], "sample_943": ["def test_pep_0420_enabled_separate_private(make_app, apidoc):\n    outdir = apidoc.outdir\n    assert (outdir / 'conf.py').isfile()\n    assert (outdir / 'a.b.c.rst').isfile()\n    assert (outdir / 'a.b.e.rst').isfile()\n    assert (outdir / 'a.b.e.f.rst').isfile()\n    assert (outdir / 'a.b.x.rst').isfile()\n    assert (outdir / 'a.b.x.y.rst').isfile()\n    assert (outdir / 'a.b._private.rst').isfile()\n\n    with open(outdir / 'a.b.c.rst') as f:\n        rst = f.read()\n        assert \".. toctree::\\n   :maxdepth: 4\\n\\n   a.b.c.d\\n\" in rst\n\n    with open(outdir / 'a.b.e.rst') as f:\n        rst = f.read()\n        assert \".. toctree::\\n   :maxdepth: 4\\n\\n   a.b.e.f\\n\" in rst\n\n    with open(outdir / 'a.b.x.rst') as f:\n        rst = f.read()\n        assert \".. toctree::\\n   :maxdepth: 4\\n\\n   a.b.x.y\\n\" in rst\n\n    with open(outdir / 'a.b._private.rst') as f:\n        rst = f.read()\n        assert \".. automodule:: a.b._private\\n\" in rst\n        assert \":private-members:\" in rst\n\n    app = make_app('text', srcdir=outdir)\n"], "sample_498": ["def test_legend_markers_from_line2d_with_kwargs():\n    # Test that markers can be copied for legend lines with kwargs (#17960)\n    _markers = ['.', '*', 'v']\n    fig, ax = plt.subplots()\n    lines = [mlines.Line2D([0], [0], ls='None', marker=mark)\n             for mark in _markers]\n    labels = [\"foo\", \"bar\", \"xyzzy\"]\n    markers = [line.get_marker() for line in lines]\n    legend = ax.legend(lines, labels, markerfirst=False)\n\n    new_markers = [line.get_marker() for line in legend.get_lines()]\n    new_labels = [text.get_text() for text in legend.get_texts()]\n\n    assert markers == new_markers == _markers\n    assert labels == new_labels[::-1]\n"], "sample_517": ["def test_annotation_arrowprops():\n    fig, ax = plt.subplots()\n    ann = ax.annotate(\n        \"hello\", xy=(.4, .4), xytext=(.6, .6), arrowprops={\"arrowstyle\": \"->\"})\n    fig.canvas.draw()\n    assert ann.arrow_patch.arrowstyle == \"->\"\n"], "sample_703": ["def test_complex_expressions(expr: str, expected: bool) -> None:\n    matcher = {\"True\": True, \"False\": False}.__getitem__\n    assert evaluate(expr, matcher) is expected\n"], "sample_677": ["def test_complex_expressions(expr: str) -> None:\n    matcher = {\"True\": True, \"False\": False}.__getitem__\n    assert evaluate(expr, matcher) is eval(expr, {\"True\": True, \"False\": False})\n"], "sample_376": ["def test_message_serializer(self):\n    \"\"\"\n    The MessageSerializer correctly serializes and deserializes messages.\n    \"\"\"\n    messages = [\n        Message(constants.INFO, 'Test message'),\n        Message(constants.ERROR, 'Error message'),\n        Message(constants.WARNING, 'Warning message', extra_tags='extra'),\n        Message(constants.DEBUG, mark_safe('<b>Safe message</b>')),\n    ]\n    serializer = MessageSerializer()\n    serialized_messages = serializer.dumps(messages)\n    deserialized_messages = serializer.loads(serialized_messages)\n    self.assertEqual(messages, deserialized_messages)\n"], "sample_185": ["def test_get_language_bidi_null(self):\n    self.assertIs(trans_null.get_language_bidi(), False)\n    with override_settings(LANGUAGE_CODE='he'):\n        self.assertIs(get_language_bidi(), True)\n"], "sample_405": ["def test_references_field_by_limit_choices_to(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ForeignKey(\n            \"Other\",\n            models.CASCADE,\n            limit_choices_to={\"field\": \"value\"},\n        ),\n    )\n    self.assertIs(operation.references_field(\"Other\", \"field\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Other\", \"whatever\", \"migrations\"), False)\n    self.assertIs(operation.references_field(\"Missing\", \"whatever\", \"migrations\"), False)\n"], "sample_707": ["def test_node_add_report_section(pytester: Pytester) -> None:\n    items = pytester.getitems(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    item = items[0]\n    item.add_report_section(\"call\", \"custom\", \"custom content\")\n    assert item._report_sections == [(\"call\", \"custom\", \"custom content\")]\n"], "sample_1014": ["def test_mutable_ndim_array():\n    from sympy import MutableDenseNDimArray\n\n    # Test __setitem__ method\n    arr = MutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    arr[0, 0] = 5\n    assert arr[0, 0] == 5\n\n    # Test as_immutable method\n    immutable_arr = arr.as_immutable()\n    assert isinstance(immutable_arr, ImmutableDenseNDimArray)\n    assert immutable_arr == arr\n\n    # Test free_symbols property\n    from sympy.abc import x\n    arr = MutableDenseNDimArray([x, 2, 3, 4], (2, 2))\n    assert arr.free_symbols == {x}\n"], "sample_402": ["def test_prepend_www_append_slash_have_slash_custom_urlconf_with_subdomain(self):\n    request = self.rf.get(\"http://subdomain.testserver/customurlconf/slash/\")\n    request.urlconf = \"middleware.extra_urls\"\n    r = CommonMiddleware(get_response_empty).process_request(request)\n    self.assertEqual(r.status_code, 301)\n    self.assertEqual(r.url, \"http://subdomain.testserver/customurlconf/slash/\")\n"], "sample_742": ["def test_logreg_intercept_scaling_fit_intercept():\n    # Test that intercept_scaling is used when fit_intercept is True\n\n    clf = LogisticRegression(fit_intercept=True, intercept_scaling=2.0)\n    clf.fit(X, Y1)\n    assert_equal(clf.intercept_, 2.0 * clf.coef_[:, -1])\n"], "sample_442": ["def test_sign_unsign_with_custom_serializer(self):\n    class CustomSerializer:\n            return json.dumps(obj).encode(\"utf-8\")\n\n            return json.loads(data.decode(\"utf-8\"))\n\n    signer = signing.Signer(key=\"predictable-secret\")\n    obj = {\"key\": \"value\"}\n    signed_obj = signer.sign_object(obj, serializer=CustomSerializer)\n    self.assertNotEqual(obj, signed_obj)\n    self.assertEqual(obj, signer.unsign_object(signed_obj, serializer=CustomSerializer))\n"], "sample_173": ["def test_explain_query_prefix_raise_not_supported_error(self):\n    msg = 'This backend does not support explaining query execution.'\n    with self.assertRaisesMessage(NotSupportedError, msg):\n        self.ops.explain_query_prefix()\n"], "sample_691": ["def test_faulthandler_stderr_key(pytester: Pytester) -> None:\n    \"\"\"Test that the fault handler stderr key is correctly stored and closed.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n            pass\n        \"\"\"\n    )\n    result = pytester.runpytest_subprocess()\n    assert result.ret == 0\n    assert 'fault_handler_stderr_key' in result.config._store\n    assert isinstance(result.config._store['fault_handler_stderr_key'], io.TextIOWrapper)\n    assert result.config._store['fault_handler_stderr_key'].closed\n"], "sample_428": ["    def test_none_and_empty_string(self):\n        self.assertEqual(nformat(None, \".\"), \"\")\n        self.assertEqual(nformat(\"\", \".\"), \"\")\n"], "sample_1134": ["def test_latex_Str():\n    from sympy.core.symbol import Str\n    assert latex(Str('x')) == r'\\text{x}'\n"], "sample_1190": ["def test_physical_constant_property():\n    assert not meter.is_physical_constant\n    assert not joule.is_physical_constant\n    assert not day.is_physical_constant\n    assert not second.is_physical_constant\n    assert not volt.is_physical_constant\n    assert not ohm.is_physical_constant\n    assert not centimeter.is_physical_constant\n    assert not kilometer.is_physical_constant\n    assert not kilogram.is_physical_constant\n    assert not pebibyte.is_physical_constant\n    assert elementary_charge.is_physical_constant\n    assert speed_of_light.is_physical_constant\n    assert vacuum_permittivity.is_physical_constant\n    assert molar_gas_constant.is_physical_constant\n    assert gravitational_constant.is_physical_constant\n"], "sample_719": ["def test_vectorizer_max_df_min_df_interaction():\n    test_data = ['abc', 'dea', 'eat']\n    vect = CountVectorizer(analyzer='char', max_df=0.5, min_df=2)\n    vect.fit(test_data)\n    assert_true('a' not in vect.vocabulary_.keys())  # {ae} ignored\n    assert_equal(len(vect.vocabulary_.keys()), 1)    # {a} not in min_df\n    assert_true('a' in vect.stop_words_)\n    assert_equal(len(vect.stop_words_), 5)\n"], "sample_1181": ["def test_numpy_print_methods_coverage():\n    prntr = NumPyPrinter()\n    assert hasattr(prntr, '_print_acosh')\n    assert hasattr(prntr, '_print_asin')\n    assert hasattr(prntr, '_print_asinh')\n    assert hasattr(prntr, '_print_atan')\n    assert hasattr(prntr, '_print_atan2')\n    assert hasattr(prntr, '_print_atanh')\n    assert hasattr(prntr, '_print_exp2')\n    assert hasattr(prntr, '_print_sign')\n    assert hasattr(prntr, '_print_logaddexp')\n    assert hasattr(prntr, '_print_logaddexp2')\n    assert hasattr(prntr, '_print_MatMul')\n    assert hasattr(prntr, '_print_MatPow')\n    assert hasattr(prntr, '_print_Inverse')\n    assert hasattr(prntr, '_print_DotProduct')\n    assert hasattr(prntr, '_print_MatrixSolve')\n    assert hasattr(prntr, '_print_ZeroMatrix')\n    assert hasattr(prntr, '_print_OneMatrix')\n    assert hasattr(prntr, '_print_FunctionMatrix')\n    assert hasattr(prntr, '_print_HadamardProduct')\n    assert hasattr(prntr, '_print_KroneckerProduct')\n    assert hasattr(prntr, '_print_Adjoint')\n    assert hasattr(prntr, '_print_DiagonalOf')\n    assert hasattr(prntr, '_print_DiagMatrix')\n    assert hasattr(prntr, '_print_DiagonalMatrix')\n    assert hasattr(prntr, '_print_Piecewise')\n    assert hasattr(prntr, '_print_Relational')\n    assert hasattr(prntr, '_print_And')\n    assert hasattr(prntr, '_print_Or')\n    assert hasattr(prntr, '_print_Not')\n    assert hasattr(pr"], "sample_98": ["    def test_underscore_headers_stripped(self):\n        \"\"\"\n        Headers with underscores in the name are stripped before constructing\n        the WSGI environ. This prevents header-spoofing based on ambiguity\n        between underscores and dashes both normalized to underscores in WSGI\n        env vars. Nginx and Apache 2.4+ both do this as well.\n        \"\"\"\n        conn = HTTPConnection(LiveServerHeaders.server_thread.host, LiveServerHeaders.server_thread.port)\n        try:\n            conn.request('GET', '/environ_view/', headers={\"Header_With_Underscore\": \"value\"})\n            response = conn.getresponse()\n            self.assertEqual(response.status, 200)\n            self.assertNotIn(b\"HTTP_HEADER_WITH_UNDERSCORE\", response.read())\n        finally:\n            conn.close()\n"], "sample_868": ["def test_empty_input(metric_name):\n    # All clustering metrics should return 1.0 for empty input\n    metric = SUPERVISED_METRICS[metric_name]\n    assert metric([], []) == 1.0\n"], "sample_636": ["def test_duplicate_code_raw_strings_disable_line_multiple(self) -> None:\n    \"\"\"Tests disabling duplicate-code at multiple lines in a piece of similar code.\"\"\"\n    path = join(DATA, \"raw_strings_disable_line_multiple\")\n    expected_output = \"Similar lines in 2 files\"\n    self._test_output(\n        [path, \"--disable=all\", \"--enable=duplicate-code\"],\n        expected_output=expected_output,\n    )\n"], "sample_500": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    sm = cm.ScalarMappable(norm=mcolors.Normalize(), cmap='viridis')\n    cb = fig.colorbar(sm)\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n    cb.set_alpha(None)\n    assert cb.alpha is None\n"], "sample_75": ["def test_prefetch_reverse_foreign_key_with_to_attr(self):\n    with self.assertNumQueries(2):\n        bookwithyear1, = BookWithYear.objects.prefetch_related(Prefetch('bookreview_set', to_attr='reviews'))\n    with self.assertNumQueries(0):\n        self.assertCountEqual(bookwithyear1.reviews, [self.bookreview1])\n    with self.assertNumQueries(0):\n        prefetch_related_objects([bookwithyear1], 'reviews')\n"], "sample_89": ["def test_nonexistent_file(self, mocked_modules, notify_mock):\n    self.reloader.watch_file(self.nonexistent_file)\n    with self.tick_twice():\n        pass  # No change to the nonexistent file\n    self.assertEqual(notify_mock.call_count, 0)\n"], "sample_847": ["def test_enet_multitarget_with_precompute():\n    n_targets = 3\n    X, y, _, _ = build_dataset(n_samples=10, n_features=8,\n                               n_informative_features=10, n_targets=n_targets)\n    estimator = ElasticNet(alpha=0.01, precompute=True)\n    estimator.fit(X, y)\n    coef, intercept, dual_gap = (estimator.coef_, estimator.intercept_,\n                                 estimator.dual_gap_)\n\n    for k in range(n_targets):\n        estimator.fit(X, y[:, k])\n        assert_array_almost_equal(coef[k, :], estimator.coef_)\n        assert_array_almost_equal(intercept[k], estimator.intercept_)\n        assert_array_almost_equal(dual_gap[k], estimator.dual_gap_)\n"], "sample_692": ["def test_tmp_path_factory_from_config(pytester: Pytester, monkeypatch) -> None:\n    \"\"\"Test that tmp_path_factory is created correctly from config.\"\"\"\n    mytemp = pytester.mkdir(\"mytemp\")\n    monkeypatch.setenv(\"PYTEST_DEBUG_TEMPROOT\", str(mytemp))\n    p = pytester.makepyfile(\n        \"\"\"\n            assert tmp_path_factory.getbasetemp().resolve() == str(mytemp)\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n"], "sample_795": ["def test_check_class_weight_balanced_linear_classifier():\n    # check that balanced class weights are computed correctly for linear classifiers\n    check_class_weight_balanced_linear_classifier(\"LinearClassifier\", LinearClassifier)\n"], "sample_0": ["def test_self_conversion_via_variance_not_supported(UncertClass):\n    uncert = np.arange(1, 11).reshape(2, 5) * u.adu\n    start_uncert = UncertClass(uncert)\n    with pytest.raises(TypeError):\n        start_uncert.represent_as(UncertClass)\n"], "sample_559": ["def test_anchored_locator_base_call_with_args():\n    fig = plt.figure(figsize=(3, 3))\n    fig1, fig2 = fig.subfigures(nrows=2, ncols=1)\n\n    ax = fig1.subplots()\n    ax.set(aspect=1, xlim=(-15, 15), ylim=(-20, 5))\n    ax.set(xticks=[], yticks=[])\n\n    Z = cbook.get_sample_data(\"axes_grid/bivariate_normal.npy\")\n    extent = (-3, 4, -4, 3)\n\n    axins = zoomed_inset_axes(ax, zoom=2, loc=\"upper left\", bbox_to_anchor=(0.1, 0.9), bbox_transform=ax.transAxes)\n    axins.set(xticks=[], yticks=[])\n\n    axins.imshow(Z, extent=extent, origin=\"lower\")\n"], "sample_684": ["def test_frame_eval(capsys):\n        y = x * 2\n        return sys._getframe(0)\n\n    fr = Frame(f(3))\n    result = fr.eval(\"y\")\n    assert result == 6\n    captured = capsys.readouterr()\n    assert captured.out == \"\"\n    assert captured.err == \"\"\n"], "sample_393": ["def test_no_obsolete_enabled(self):\n    management.call_command(\n        \"makemessages\", locale=[LOCALE], verbosity=0, no_obsolete=True\n    )\n    self.assertTrue(os.path.exists(self.PO_FILE))\n    with open(self.PO_FILE) as fp:\n        po_contents = fp.read()\n        self.assertNotIn(\"#, fuzzy\", po_contents)\n"], "sample_477": ["def test_random03(self):\n    output = self.engine.render_to_string(\n        \"random03\", {\"a\": [\"a&b\", \"a&b\"], \"b\": [mark_safe(\"a&b\"), mark_safe(\"a&b\")]}\n    )\n    self.assertEqual(output, \"a&amp;b a&amp;b\")\n"], "sample_1139": ["def test_issue_17858():\n    assert 1 in Range(-oo, oo)\n    assert 0 in Range(oo, -oo, -1)\n    assert oo not in Range(-oo, oo)\n    assert -oo not in Range(-oo, oo)\n"], "sample_520": ["def test_Poly3DCollection_get_alpha():\n    # Smoke test to see that get_alpha does not raise\n    # See GH#4067\n    y, x = np.ogrid[1:10:100j, 1:10:100j]\n    z2 = np.cos(x) ** 3 - np.sin(y) ** 2\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    r = ax.plot_surface(x, y, z2, cmap='hot')\n    r.get_alpha()\n"], "sample_105": ["def test_template_params_with_special_chars(self):\n    \"\"\"A generic template view passes kwargs with special characters as context.\"\"\"\n    response = self.client.get('/template/simple/b@r/')\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(response.context['foo'], 'b@r')\n    self.assertIsInstance(response.context['view'], View)\n"], "sample_988": ["def test_issue_13348():\n    assert Eq(True, 1) is S.false\n    assert Eq(False, 0) is S.false\n    assert Eq(True, 0) is S.false\n    assert Eq(False, 1) is S.false\n"], "sample_1008": ["def test_orient_dcm():\n    N = ReferenceFrame('N')\n    dcm = Matrix([[0, 1, 0], [0, 0, -1], [-1, 0, 0]])\n    A = N.orientnew('A', 'DCM', dcm)\n    assert A.dcm(N) == dcm\n    assert N.dcm(A) == dcm.T\n"], "sample_937": ["def test_unparse_assign(source, expected):\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].value) == expected\n"], "sample_225": ["    def setUpTestData(cls):\n        cls.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.u2 = User.objects.create_user(username='user', password='secret', email='user@example.com')\n"], "sample_896": ["def test_nmf_n_components_auto_with_init():\n    # Check that n_components is correctly inferred from the provided\n    # initialization method.\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((6, 5))\n    est = NMF(\n        n_components=\"auto\",\n        init=\"nndsvd\",\n        random_state=0,\n        tol=1e-6,\n    )\n    est.fit_transform(X)\n    assert est._n_components == min(X.shape)\n"], "sample_328": ["def test_json_field_nullable(self):\n    json_field_nullables = [\n        JSONFieldNullable.objects.create(json_field=None)\n        for _ in range(10)\n    ]\n    for json_field_nullable in json_field_nullables:\n        json_field_nullable.json_field = {'key': 'value'}\n    JSONFieldNullable.objects.bulk_update(json_field_nullables, ['json_field'])\n    self.assertCountEqual(\n        JSONFieldNullable.objects.values_list('json_field', flat=True),\n        [cat.json_field for cat in json_field_nullables]\n    )\n"], "sample_101": ["def test_limited_stream(self):\n    \"\"\"\n    LimitedStream correctly limits the number of bytes that can be read.\n    \"\"\"\n    data = b'a' * 10\n    stream = LimitedStream(BytesIO(data), 5)\n    self.assertEqual(stream.read(3), b'aaaaa')\n    self.assertEqual(stream.read(3), b'a')\n    self.assertEqual(stream.read(3), b'')\n\n    stream = LimitedStream(BytesIO(data), 5)\n    self.assertEqual(stream.readline(3), b'aaa')\n    self.assertEqual(stream.readline(3), b'a')\n    self.assertEqual(stream.readline(3), b'')\n"], "sample_982": ["def test_primeomega():\n    assert primeomega(1) == 0\n    assert primeomega(2) == 1\n    assert primeomega(2 * 3) == 2\n    assert primeomega(2 * 3 * 5) == 3\n    assert primeomega(3 * 25) == primeomega(3) + primeomega(25)\n    assert [primeomega(p) for p in primerange(1, 10)] == [0, 1, 1, 1]\n    assert primeomega(fac(50)) == 61\n    assert primeomega(2 ** 9941 - 1) == 9940\n    n = Symbol('n', integer=True)\n    assert primeomega(n)\n    assert primeomega(n).subs(n, 2 ** 31 - 1) == 31\n    assert summation(primeomega(n), (n, 2, 30)) == 46\n"], "sample_621": ["def test_copy_indexes(self, indexes) -> None:\n    new_indexes, new_index_vars = indexes.copy_indexes()\n\n    assert new_indexes.keys() == indexes.keys()\n    assert new_index_vars.keys() == indexes.variables.keys()\n\n    for k in new_indexes:\n        assert new_indexes[k] is not indexes[k]\n        assert new_indexes[k].equals(indexes[k])\n\n    for k in new_index_vars:\n        assert new_index_vars[k] is not indexes.variables[k]\n        assert new_index_vars[k].equals(indexes.variables[k])\n"], "sample_476": ["    def test_delete_method(self):\n        p = self.PersonModel(name=\"Joe\", mugshot=self.file1)\n        p.save()\n        self.check_dimensions(p, 4, 8)\n\n        # Deleting the image field should clear dimensions.\n        p.mugshot.delete(save=False)\n        self.check_dimensions(p, None, None)\n\n        # Deleting the image field again should not raise an error.\n        p.mugshot.delete(save=False)\n        self.check_dimensions(p, None, None)\n"], "sample_215": ["    def test_multivalue_dict_sensitive_request(self):\n        \"\"\"\n        Sensitive POST parameters cannot be seen in the default error reports\n        for sensitive requests when using MultiValueDict.\n        \"\"\"\n        request = self.rf.post('/some_url/', self.breakfast_data)\n        request.POST = request.POST.copy()\n        request.POST.setlist('sausage-key', ['sausage-value1', 'sausage-value2'])\n        request.POST.setlist('bacon-key', ['bacon-value1', 'bacon-value2'])\n\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(sensitive_view)\n            self.verify_unsafe_email(sensitive_view)\n\n        with self.settings(DEBUG=False):\n            self.verify_safe_response(sensitive_view)\n            self.verify_safe_email(sensitive_view)\n"], "sample_708": ["def test_getstatementrange_with_decorator() -> None:\n    source = Source(\n        \"\"\"\\\n        @decorator\n            assert True\n        \"\"\"\n    )\n    assert source.getstatementrange(1) == (0, 3)\n"], "sample_134": ["def test_serialize_complex(self):\n    self.assertSerializedEqual(complex(1, 2))\n    self.assertSerializedResultEqual(\n        complex(1, 2),\n        (\"complex((1+2j))\", set())\n    )\n"], "sample_249": ["    def test_keepdb_true(self, mocked_sync_apps, mocked_migrate, *mocked_objects):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = test_connection.creation_class(test_connection)\n        if connection.vendor == 'oracle':\n            # Don't close connection on Oracle.\n            creation.connection.close = mock.Mock()\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db') as mock_create_test_db:\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=False, keepdb=True)\n            # _create_test_db is called with keepdb=True\n            mock_create_test_db.assert_called_with(0, True, True)\n            # Migrations run.\n            mocked_migrate.assert_called()\n            args, kwargs = mocked_migrate.call_args\n            self.assertEqual(args, ([('app_unmigrated', '0001_initial')],))\n            self.assertEqual(len(kwargs['plan']), 1)\n            # App is not synced.\n            mocked_sync_apps.assert_not_called()\n        finally:\n            with"], "sample_1192": ["def test_disambiguate():\n    x, y = symbols('x y')\n    ix = Symbol('x', integer=True)\n    vx = Symbol('x')\n    assert disambiguate(vx + ix) == (x + x_1,)\n    eqs = Tuple(Symbol('x')/y, Dummy('x')/y)\n    mapping = dict(zip(eqs.free_symbols, disambiguate(*eqs.free_symbols)))\n    assert eqs.xreplace(mapping) == (x_1/y, x/y)\n"], "sample_1112": ["def test_is_palindromic():\n    assert is_palindromic(121) == True\n    assert is_palindromic(12321) == True\n    assert is_palindromic(12345) == False\n    assert is_palindromic(123321, 10) == True\n    assert is_palindromic(123321, 2) == False\n"], "sample_1000": ["def test_octave_user_functions():\n    f = Function('f')\n    g = Function('g')\n    custom_functions = {\n        \"f\": \"existing_octave_fcn\",\n        \"g\": [(lambda x: x.is_Matrix, \"my_mat_fcn\"),\n              (lambda x: not x.is_Matrix, \"my_fcn\")]\n    }\n    mat = Matrix([[1, x]])\n    assert mcode(f(x) + g(x) + g(mat), user_functions=custom_functions) == 'existing_octave_fcn(x) + my_fcn(x) + my_mat_fcn([1 x])'\n"], "sample_1001": ["def test_issue_14237_2():\n    A = MatrixSymbol(\"A\", 3, 3)\n    B = MatrixSymbol(\"B\", 3, 3)\n    C = MatrixSymbol(\"C\", 3, 3)\n\n    assert latex(A + B + C) == r\"A + B + C\"\n    assert latex(A - B - C) == r\"A - B - C\"\n    assert latex(A * B * C) == r\"A B C\"\n    assert latex(A / B / C) == r\"\\frac{A}{B C}\"\n"], "sample_870": ["def test_diag_method_does_not_mutate_input():\n    \"\"\"\n    Check that the diag method of a custom kernel does not mutate the input\n    matrix X.\n    \"\"\"\n    rng = np.random.RandomState(0)\n    X = rng.randn(10, 3)\n    y = rng.randn(10)\n\n    kernel = CustomKernel(1.0)\n    model = GaussianProcessRegressor(kernel=kernel)\n    model.fit(X, y)\n\n    X_copy = X.copy()\n    model.predict(X, return_std=True)\n    assert_array_equal(X, X_copy)\n"], "sample_1186": ["def test_array_addition_subtraction():\n    for ArrayType in array_types:\n        A = ArrayType([[1, 2], [3, 4]])\n        B = ArrayType([[5, 6], [7, 8]])\n        assert A + B == ArrayType([[6, 8], [10, 12]])\n        assert A - B == ArrayType([[-4, -4], [-4, -4]])\n"], "sample_366": ["    def test_parse_datetime_invalid_inputs(self):\n        invalid_inputs = (\n            '2012-04-56T09:15:90',\n            '2012-04-23T10:20:30.400+25:00',\n            '2012-04-23T10:20:30.400-25:00',\n            '2012-04-23T10:20:30.400+25',\n            '2012-04-23T10:20:30.400-25',\n            '2012-04-23T10:20:30.400 +25:00',\n            '2012-04-23T10:20:30.400 -25:00',\n            '2012-04-23T10:20:30.400 +25',\n            '2012-04-23T10:20:30.400 -25',\n        )\n        for source in invalid_inputs:\n            with self.subTest(source=source):\n                with self.assertRaises(ValueError):\n                    parse_datetime(source)\n"], "sample_251": ["def test_alias_with_m2m(self):\n    qs = Book.objects.alias(\n        author_age=F('authors__age'),\n    ).filter(pk=self.b1.pk).order_by('author_age')\n    self.assertIs(hasattr(qs.first(), 'author_age'), False)\n    self.assertEqual(qs[0].authors.all()[0].age, 34)\n    self.assertEqual(qs[1].authors.all()[0].age, 35)\n"], "sample_737": ["def test_vectorizer_invalid_ngram_range():\n    with pytest.raises(ValueError):\n        CountVectorizer(ngram_range=(2, 1))\n"], "sample_26": ["def test_scale_back_compressed_float_assignment(self):\n    \"\"\"\n    Extend fix for #4600 to assignment to data\n\n    Identical to test_scale_back_uint_assignment() but uses a compressed\n    image with floating point data.\n\n    Suggested by:\n    https://github.com/astropy/astropy/pull/4602#issuecomment-208713748\n    \"\"\"\n\n    a = np.arange(100, 200, dtype=np.float32)\n    fits.CompImageHDU(a).writeto(self.temp(\"test.fits\"))\n    with fits.open(self.temp(\"test.fits\"), mode=\"update\", scale_back=True) as hdul:\n        hdul[1].data[:] = 0\n        assert np.allclose(hdul[1].data, 0)\n"], "sample_902": ["def test_pipeline_memory_disabled():\n    # Test that the memory is disabled when memory is None\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    transf = DummyTransf()\n    pipe = Pipeline([('transf', transf), ('svc', SVC())], memory=None)\n    pipe.fit(X, y)\n    assert_false(hasattr(transf, 'means_'))\n"], "sample_417": ["def test_decimal_input(self):\n    self.assertEqual(floatformat(Decimal(\"123456.789\"), 2), \"123456.79\")\n    self.assertEqual(floatformat(Decimal(\"123456.789\"), -2), \"123456.79\")\n    self.assertEqual(floatformat(Decimal(\"123456.789\"), \"2\"), \"123456.79\")\n    self.assertEqual(floatformat(Decimal(\"123456.789\"), \"2g\"), \"123,456.79\")\n    self.assertEqual(floatformat(Decimal(\"123456.789\"), \"2u\"), \"123456.79\")\n"], "sample_790": ["def test_kernel_pca_inverse_transform_sparse():\n    rng = np.random.RandomState(0)\n    X_fit = sp.csr_matrix(rng.random_sample((5, 4)))\n    X_pred = sp.csr_matrix(rng.random_sample((2, 4)))\n\n    for eigen_solver in (\"auto\", \"arpack\"):\n        for kernel in (\"linear\", \"rbf\", \"poly\"):\n            # transform fit data\n            kpca = KernelPCA(4, kernel=kernel, eigen_solver=eigen_solver,\n                             fit_inverse_transform=True)\n            X_fit_transformed = kpca.fit_transform(X_fit)\n\n            # inverse transform\n            assert_raises(NotImplementedError, kpca.inverse_transform, X_pred)\n"], "sample_681": ["def test_logging_emit_error_propagated(testdir: Testdir) -> None:\n    \"\"\"\n    If logging is configured to propagate errors, pytest\n    propagates errors during emit().\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            monkeypatch.setattr(logging, 'raiseExceptions', True)\n            logging.warning('oops', 'first', 2)\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(failed=1)\n    result.stdout.fnmatch_lines(\n        [\n            \"====* FAILURES *====\",\n            \"*not all arguments converted during string formatting*\",\n        ]\n    )\n"], "sample_904": ["def test_cmd_option_with_subcommand(app):\n    text = \".. program:: git\\n\\n.. option:: commit -m\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (index,\n                          [desc, ([desc_signature, ([desc_name, 'commit'],\n                                                    [desc_addname, ' -m'])],\n                                  [desc_content, ()])]))\n    assert_node(doctree[0], addnodes.index,\n                entries=[('pair', 'git command line option; commit -m', 'cmdoption-git-commit-m', '', None)])\n\n    objects = list(app.env.get_domain(\"std\").get_objects())\n    assert ('git.commit', 'git.commit', 'cmdoption', 'index', 'cmdoption-git-commit-m', 1) in objects\n"], "sample_2": ["def test_wcs_attribute_modification(tmpdir):\n    \"\"\"\n    Check that modifying the WCS attribute of a CCDData object updates the\n    header correctly when the object is converted to an HDU.\n    \"\"\"\n    ccd_data = create_ccd_data()\n    tmpfile = tmpdir.join('temp.fits')\n    wcs = WCS(naxis=2)\n    wcs.wcs.crpix = np.array(ccd_data.shape) / 2\n    wcs.wcs.cdelt = np.array([-0.066667, 0.066667])\n    wcs.wcs.crval = [0, -90]\n    wcs.wcs.ctype = [\"RA---AIR\", \"DEC--AIR\"]\n    wcs.wcs.set_pv([(2, 1, 45.0)])\n    ccd_data.wcs = wcs\n    ccd_data.write(tmpfile.strpath)\n\n    ccd_new = CCDData.read(tmpfile.strpath)\n    ccd_new.wcs.wcs.cdelt *= 2\n    ccd_new_hdu = ccd_new.to_hdu()[0]\n    assert ccd_new_hdu.header['CDELT1'] == ccd_new.wcs.wcs.cdelt[0]\n    assert ccd_new_hdu.header['CDELT2'] == ccd_new.wcs.wcs.cdelt[1]\n"], "sample_135": ["def test_time_format_specifiers(self):\n    my_time = datetime(1984, 8, 7, 12, 34, 56)\n\n    for specifier in ['b', 'c', 'd', 'D', 'E', 'F', 'I', 'j', 'l', 'L', 'm', 'M', 'n', 'N', 'o', 'S', 't', 'U', 'w', 'W', 'y', 'Y', 'z']:\n        msg = (\n            \"The format for time objects may not contain date-related \"\n            \"format specifiers (found '%s').\" % specifier\n        )\n        with self.assertRaisesMessage(TypeError, msg):\n            dateformat.time_format(my_time.time(), specifier)\n"], "sample_356": ["def test_alter_field_with_default(self):\n    \"\"\"#22030 - Altering a field with a default should work.\"\"\"\n    changes = self.get_changes([self.author_name_default], [self.author_name_new_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, 'testapp', 0, 0, default='New Default')\n"], "sample_294": ["def test_good_origin_wildcard_csrf_trusted_origin_allowed_with_port(self):\n    \"\"\"\n    A POST request with an origin that matches a CSRF_TRUSTED_ORIGINS\n    wildcard and a non-default port is accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_HOST'] = 'www.example.com:8080'\n    req.META['HTTP_ORIGIN'] = 'https://foo.example.com:8080'\n    mw = CsrfViewMiddleware(post_form_view)\n    self.assertIs(mw._origin_verified(req), True)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n    self.assertEqual(mw.allowed_origins_exact, set())\n    self.assertEqual(mw.allowed_origin_subdomains, {'https': ['.example.com']})\n"], "sample_699": ["def test_doctest_module_with_mock_objects(pytester: Pytester):\n    pytester.makepyfile(\n        \"\"\"\n        from unittest.mock import Mock\n        class Example(object):\n            '''\n            >>> mock = Mock()\n            >>> mock.method()\n            <Mock name='mock.method()' id='...'>\n            '''\n        \"\"\"\n    )\n    result = pytester.runpytest(\"--doctest-modules\")\n    result.stdout.fnmatch_lines([\"* 1 passed *\"])\n"], "sample_1048": ["def test_parabola_intersection():\n    p1 = Parabola(Point(0, 0), Line(Point(5, 8), Point(7, 8)))\n    p2 = Parabola(Point(0, 0), Line(Point(0, 5), Point(0, 7)))\n    l1 = Line(Point(1, -2), Point(-1, -2))\n    e1 = Ellipse(Point(0, 0), 2, 5)\n    s1 = Segment((-12, -65), (14, -68))\n\n    assert p1.intersection(p2) == [p2]\n    assert p1.intersection(Point(0, 16)) == [Point(0, 16)]\n    assert p1.intersection(Point(0, 17)) == []\n    assert p1.intersection(l1) == [Point(-4, 3), Point(4, 3)]\n    assert p1.intersection(e1) == [Point(-2, 0), Point(2, 0)]\n    assert p1.intersection(s1) == []\n\n    raises(TypeError, lambda: p1.intersection(Line(Point(1, 2, 3), Point(4, 5, 6))))\n    raises(TypeError, lambda: p1.intersection(\"invalid type\"))\n"], "sample_1165": ["def test_quaternion_division():\n    q1 = Quaternion(3 + 4*I, 2 + 5*I, 0, 7 + 8*I, real_field = False)\n    q2 = Quaternion(1, 2, 3, 5)\n\n    assert q1 / q2 == q1 * q2.inverse()\n    assert q1 / 2 == q1 * Rational(1, 2)\n    assert 2 / q1 == Rational(2, 1) * q1.inverse()\n"], "sample_784": ["def test_calibration_multilabel():\n    \"\"\"Test calibration for multilabel \"\"\"\n    # test multi-label setting with classifier that implements\n    # only decision function\n    clf = LinearSVC()\n    X, y = make_multilabel_classification(n_samples=100, n_features=2,\n                                          n_classes=3, n_labels=2,\n                                          random_state=42)\n\n    X_train, y_train = X[::2], y[::2]\n    X_test, y_test = X[1::2], y[1::2]\n\n    clf.fit(X_train, y_train)\n    for method in ['isotonic', 'sigmoid']:\n        cal_clf = CalibratedClassifierCV(clf, method=method, cv=2)\n        cal_clf.fit(X_train, y_train)\n        probas = cal_clf.predict_proba(X_test)\n        # Check that the sum of probabilities for each sample is 1\n        assert_array_almost_equal(np.sum(probas, axis=1), np.ones(len(X_test)))\n\n        # Check that log-loss of calibrated classifier is smaller than\n        # log-loss of naively turned OvR decision function to probabilities\n        # via softmax\n            e = np.exp(-y_pred)\n            return e / e.sum(axis=1).reshape(-1, 1)\n\n        uncalibrated_log_loss = \\\n            log_loss(y_test, softmax(clf.decision_function(X_test)))\n        calibrated_log_loss = log_loss(y_test, probas)\n        assert_greater_equal(uncalibrated_log_loss, calibrated_log_loss)\n"], "sample_230": ["def test_disabled_field(self):\n    field = JSONField(disabled=True)\n    self.assertFalse(field.has_changed({'a': 'b'}, '{\"a\": \"b\"}'))\n"], "sample_644": ["def test_import_outside_toplevel(self) -> None:\n    module = astroid.MANAGER.ast_from_module_name(\"outside_toplevel\", REGR_DATA)\n    import_from = module.body[0]\n\n    msg = MessageTest(\n        msg_id=\"import-outside-toplevel\",\n        node=import_from,\n        args=\"os\",\n        line=3,\n        col_offset=4,\n        end_line=3,\n        end_col_offset=15,\n    )\n    with self.assertAddsMessages(msg):\n        self.checker.visit_importfrom(import_from)\n"], "sample_227": ["def test_emptylistfieldfilter_reverse_relationships_ordering(self):\n    class UserAdminReverseRelationship(UserAdmin):\n        list_filter = (\n            ('books_contributed', EmptyFieldListFilter),\n        )\n\n    self.guitar_book.employee = self.john\n    self.guitar_book.save()\n    self.django_book.employee = self.jack\n    self.django_book.save()\n\n    modeladmin = UserAdminReverseRelationship(User, site)\n    request = self.request_factory.get('/')\n    request.user = self.alfred\n    changelist = modeladmin.get_changelist_instance(request)\n    filterspec = changelist.get_filters(request)[0][0]\n    self.assertEqual(filterspec.lookup_choices, [\n        (self.guitar_book.pk, 'Guitar for dummies'),\n        (self.django_book.pk, 'The Django Book'),\n    ])\n"], "sample_228": ["def test_formset_with_deletion_and_min_num(self):\n    \"\"\"FormSets with deletion and min_num.\"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_delete=True, min_num=2)\n    initial = [\n        {'choice': 'Calexico', 'votes': 100},\n        {'choice': 'Fergie', 'votes': 900},\n    ]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_370": ["def test_nested_prefetch_related_with_to_attr(self):\n    \"\"\"\n    Nested prefetches with to_attr are allowed.\n    \"\"\"\n    occupants = Person.objects.prefetch_related(\n        Prefetch('houses', to_attr='some_attr_name'),\n        Prefetch('houses', queryset=House.objects.prefetch_related('main_room'), to_attr='houses_with_main_room'),\n    )\n    houses = House.objects.prefetch_related(Prefetch('occupants', queryset=occupants))\n    with self.assertNumQueries(5):\n        self.traverse_qs(list(houses), [['occupants', 'houses_with_main_room', 'main_room']])\n"], "sample_954": ["def test_python_domain(app, status, warning):\n    app.builder.build_all()\n    content = (app.outdir / 'python.1').read_text()\n\n    # test python domain objects\n    assert '\\n.B class\\n' in content\n    assert '\\n.B function\\n' in content\n    assert '\\n.B method\\n' in content\n    assert '\\n.B exception\\n' in content\n    assert '\\n.B data\\n' in content\n    assert '\\n.B attribute\\n' in content\n\n    # test python domain signatures\n    assert '\\n.B function\\n\\\\fBfunc\\\\fP\\\\fI(arg1, arg2)\\\\fP\\n' in content\n    assert '\\n.B method\\n\\\\fBMyClass.method\\\\fP\\\\fI(arg1, arg2)\\\\fP\\n' in content\n    assert '\\n.B exception\\n\\\\fBMyException\\\\fP\\\\fI(arg1, arg2)\\\\fP\\n' in content\n    assert '\\n.B data\\n\\\\fBmy_data\\\\fP\\n' in content\n    assert '\\n.B attribute\\n\\\\fBMyClass.my_attr\\\\fP\\n' in content\n"], "sample_340": ["def test_run_before_invalid(self):\n    \"\"\"\n    Makes sure the loader raises an error for invalid run_before dependencies.\n    \"\"\"\n    # Load and test the plan\n    with self.assertRaises(NodeNotFoundError):\n        MigrationLoader(connection)\n"], "sample_419": ["def test_formset_with_custom_prefix(self):\n    \"\"\"Formsets with custom prefix.\"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_order=True, can_delete=True)\n    initial = [\n        {\"choice\": \"Calexico\", \"votes\": 100},\n        {\"choice\": \"Fergie\", \"votes\": 900},\n        {\"choice\": \"The Decemberists\", \"votes\": 500},\n    ]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix=\"custom_prefix\")\n    self.assertHTMLEqual(\n        \"\\n\".join(form.as_ul() for form in formset.forms),\n        '<li>Choice: <input type=\"text\" name=\"custom_prefix-0-choice\" value=\"Calexico\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"custom_prefix-0-votes\" value=\"100\"></li>'\n        '<li>Order: <input type=\"number\" name=\"custom_prefix-0-ORDER\" value=\"1\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"custom_prefix-0-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"custom_prefix-1-choice\" value=\"Fergie\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"custom_prefix-1-votes\" value=\"900\"></li>'\n        '<li>Order: <input type=\"number\" name=\"custom_prefix-1-ORDER\" value=\"2\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"custom_prefix-1-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"custom_prefix-2-choice\" '\n        'value=\"The Decemberists\"></li>'\n        '<li>Votes: <input type=\"number\" name=\"custom_prefix-2-votes\" value=\"500\"></li>'\n        '<li>Order: <input type=\"number\" name=\"custom_prefix-2-ORDER\" value=\"3\"></li>'"], "sample_963": ["def test_restify_type_hints_forward_ref():\n    from typing import ForwardRef  # type: ignore\n    assert restify(ForwardRef(\"MyClass1\")) == \":py:class:`MyClass1`\"\n"], "sample_1090": ["def test_mul():\n    with evaluate(False):\n        p = oo * oo\n        assert isinstance(p, Mul) and p.args == (oo, oo)\n        p = 5 * oo\n        assert isinstance(p, Mul) and p.args == (oo, 5)\n        p = oo * 5\n        assert isinstance(p, Mul) and p.args == (oo, 5)\n        p = -oo * 5\n        assert isinstance(p, Mul) and p.args == (-oo, 5)\n        p = 5 * -oo\n        assert isinstance(p, Mul) and p.args == (-oo, 5)\n        p = -oo * -oo\n        assert isinstance(p, Mul) and p.args == (oo, oo)\n\n    with evaluate(False):\n        expr = x * x\n        assert isinstance(expr, Mul)\n        assert expr.args == (x, x)\n\n        with evaluate(True):\n            assert (x * x).args == (x**2,)\n\n        assert (x * x).args == (x, x)\n\n    assert isinstance(x * x, Pow)\n\n    with evaluate(False):\n        assert S.One * 1 == Mul(1, 1)\n        assert 1 * S.One == Mul(1, 1)\n\n        assert S(4) / 3 == Mul(4, S.One / 3)\n        assert S.One / 3 * 4 == Mul(S.One / 3, 4)\n\n        assert 9 ** S(2) == Pow(9, 2)\n        assert S(2) ** 9 == Pow(2, 9)\n\n        assert S(2) / 2 == Mul(2, S.One / 2)\n        assert S.One / 2 * 2 == Mul(S.One / 2, 2)\n\n        assert S(2) / 3 * 1 == Mul(S(2) / 3, 1)\n        assert 1 * S(2) / 3 == Mul(1, S(2) / 3)\n\n        assert S("], "sample_268": ["def test_tick_triggers_on_file_creation(self, mock_notify_file_changed):\n    new_file = self.tempdir / 'new_file.py'\n    with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file, new_file]):\n        ticker = self.reloader.tick()\n        next(ticker)\n        new_file.touch()\n        next(ticker)\n        self.assertEqual(mock_notify_file_changed.call_count, 1)\n        self.assertCountEqual(mock_notify_file_changed.call_args[0], [new_file])\n"], "sample_63": ["def test_app_dirs_with_loaders(self):\n    msg = \"app_dirs must not be set when loaders is defined.\"\n    with self.assertRaisesMessage(ImproperlyConfigured, msg):\n        Engine(app_dirs=True)\n"], "sample_1039": ["def test_presentation_mathml_root_notation():\n    mml = mpp._print(x**(S(1)/3))\n    assert mml.nodeName == 'mroot'\n    assert mml.childNodes[0].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[1].childNodes[0].nodeValue == '3'\n\n    mml = mpp._print(x**(S(1)/3), root_notation=False)\n    assert mml.nodeName == 'msup'\n    assert mml.childNodes[0].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[1].nodeName == 'mfrac'\n    assert mml.childNodes[1].childNodes[0].childNodes[0].nodeValue == '1'\n    assert mml.childNodes[1].childNodes[1].childNodes[0].nodeValue == '3'\n"], "sample_361": ["def test_urlize_with_nofollow(self):\n    value = 'Check out this link: http://example.com'\n    output = 'Check out this link: <a href=\"http://example.com\" rel=\"nofollow\">http://example.com</a>'\n    self.assertEqual(urlize(value, nofollow=True), output)\n"], "sample_240": ["def test_token_with_different_algorithm(self):\n    \"\"\"\n    A valid token can be created with a different algorithm by using the\n    PasswordResetTokenGenerator.algorithm attribute.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    new_algorithm = 'sha512'\n    # Create and check a token with a different algorithm.\n    p0 = PasswordResetTokenGenerator()\n    p0.algorithm = new_algorithm\n    tk0 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk0), True)\n    # Create and check a token with the default algorithm.\n    p1 = PasswordResetTokenGenerator()\n    self.assertNotEqual(p1.algorithm, new_algorithm)\n    tk1 = p1.make_token(user)\n    # Tokens created with a different algorithm don't validate.\n    self.assertIs(p0.check_token(user, tk1), False)\n    self.assertIs(p1.check_token(user, tk0), False)\n"], "sample_651": ["def test_warns_context_manager_with_invalid_args(self) -> None:\n    with pytest.raises(TypeError) as excinfo:\n        with pytest.warns(UserWarning, \"invalid_arg\"):  # type: ignore\n            pass\n    assert \"Unexpected positional arguments\" in str(excinfo.value)\n"], "sample_112": ["def test_cell_count(self):\n    \"\"\"\n    cell_count template filter should return the correct number of cells.\n    \"\"\"\n    request = self.request_factory.get(reverse('admin:admin_views_article_add'))\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    response = admin.add_view(request)\n    inline_admin_form = response.context_data['inline_admin_formsets'][0].form\n    count = cell_count(inline_admin_form)\n    expected_count = 1 + len(inline_admin_form.fields) + int(inline_admin_form.formset.can_delete)\n    self.assertEqual(count, expected_count)\n"], "sample_900": ["def test_invscaling_learning_rate():\n    X = [[3, 2], [1, 6]]\n    y = [1, 0]\n    clf = MLPClassifier(tol=0.5, max_iter=3000, solver='sgd', learning_rate='invscaling')\n    clf.fit(X, y)\n    assert clf.max_iter > clf.n_iter_\n    assert clf._optimizer.learning_rate < clf.learning_rate_init\n"], "sample_533": ["def test_contour_invalid_levels():\n    x = np.arange(9)\n    z = np.random.random((9, 9))\n\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError, match=\"Contour levels must be increasing\"):\n        ax.contour(x, x, z, levels=[2, 1])\n"], "sample_578": ["def test_baseline(self, x, y):\n\n    baseline = 2\n    p = Plot(x, y).add(Bars(baseline=baseline)).plot()\n    ax = p._figure.axes[0]\n    paths = ax.collections[0].get_paths()\n    for i, path in enumerate(paths):\n        verts = path.vertices\n        assert verts[0, 1] == baseline\n        assert verts[3, 1] == baseline + y[i]\n"], "sample_126": ["def test_add_blank_textfield_and_charfield_with_default(self):\n    \"\"\"\n    #23405 - Adding a NOT NULL and blank `CharField` or `TextField`\n    with default should not prompt for a default.\n    \"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_with_biography_blank_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0)\n"], "sample_262": ["def test_classproperty_setter(self):\n    class Foo:\n        _bar = 123\n\n        @classproperty\n            return cls._bar\n\n        @bar.setter\n            cls._bar = value\n\n    Foo.bar = 456\n    self.assertEqual(Foo.bar, 456)\n"], "sample_148": ["def test_quote_unquote(self):\n    \"\"\"\n    Test quote and unquote functions.\n    \"\"\"\n    s = \"test_string:with/special_chars_123\"\n    quoted_s = quote(s)\n    self.assertEqual(unquote(quoted_s), s)\n"], "sample_722": ["def test_k_means_elkan_algorithm():\n    # Test the 'elkan' algorithm for KMeans\n    km = KMeans(n_clusters=n_clusters, algorithm='elkan', random_state=42)\n    km.fit(X)\n    _check_fitted_model(km)\n"], "sample_989": ["def test_Float_comparison():\n    fpi = Float(pi)\n    assert (fpi == pi) == (pi == fpi)\n    assert (fpi != pi) == (pi != fpi)\n    assert (fpi < pi) == (pi > fpi)\n    assert (fpi <= pi) == (pi >= fpi)\n    assert (fpi > pi) == (pi < fpi)\n    assert (fpi >= pi) == (pi <= fpi)\n"], "sample_695": ["def test_node_add_report_section(pytester: Pytester) -> None:\n    items = pytester.getitems(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    item = items[0]\n    item.add_report_section(\"call\", \"custom\", \"custom content\")\n    assert item._report_sections == [(\"call\", \"custom\", \"custom content\")]\n"], "sample_139": ["def test_dynamic_list_display_with_callable(self):\n    \"\"\"\n    Regression tests for #14206: dynamic list_display support with callable.\n    \"\"\"\n    parent = Parent.objects.create(name='parent')\n    for i in range(10):\n        Child.objects.create(name='child %s' % i, parent=parent)\n\n    user_noparents = self._create_superuser('noparents')\n    user_parents = self._create_superuser('parents')\n\n    # Test with user 'noparents'\n    m = DynamicListDisplayChildAdmin(Child, custom_site)\n    m.list_display = ('parent', 'name', 'age', 'callable_field')\n    request = self._mocked_authenticated_request('/child/', user_noparents)\n    response = m.changelist_view(request)\n    self.assertNotContains(response, 'Callable Field')\n\n    # Test with user 'parents'\n    m = DynamicListDisplayChildAdmin(Child, custom_site)\n    m.list_display = ('parent', 'name', 'age', 'callable_field')\n    request = self._mocked_authenticated_request('/child/', user_parents)\n    response = m.changelist_view(request)\n    self.assertContains(response, 'Callable Field')\n"], "sample_938": ["def test_man_show_urls(app, status, warning):\n    app.build()\n    content = (app.outdir / 'python.1').read_text()\n    assert 'http://www.sphinx-doc.org/' in content\n"], "sample_7": ["def test_column_insert_with_quantity():\n    \"\"\"Test inserting a Quantity into a Column.\"\"\"\n    c = table.Column([1, 2, 3], unit='m')\n    c1 = c.insert(1, 10 * u.m)\n    assert np.all(c1 == [1, 10, 2, 3])\n    assert c1.unit == 'm'\n"], "sample_503": ["def test_valid_capstyles():\n    line = mlines.Line2D([], [])\n    with pytest.raises(ValueError):\n        line.set_dash_capstyle('foobar')\n    with pytest.raises(ValueError):\n        line.set_solid_capstyle('foobar')\n"], "sample_632": ["def test_ignore_docstrings_and_comments():\n    output = StringIO()\n    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n        similar.Run([\"--ignore-docstrings\", \"--ignore-comments\", SIMILAR1, SIMILAR2])\n    assert ex.value.code == 0\n    assert (\n        output.getvalue().strip()\n        == \"\"\""], "sample_372": ["    def test_pattern_startswith_slash(self):\n        test_urls = [\n            ('/normal/', []),\n            ('normal/', [Warning(\"Your URL pattern 'normal/' has a route beginning with a '/'. Remove this slash as it is unnecessary. If this pattern is targeted in an include(), ensure the include() pattern has a trailing '/'.\")]),\n            ('/included/normal/', []),\n            ('included/normal/', [Warning(\"Your URL pattern 'included/normal/' has a route beginning with a '/'. Remove this slash as it is unnecessary. If this pattern is targeted in an include(), ensure the include() pattern has a trailing '/'.\")]),\n            ('/test1/inner/', []),\n            ('test1/inner/', [Warning(\"Your URL pattern 'test1/inner/' has a route beginning with a '/'. Remove this slash as it is unnecessary. If this pattern is targeted in an include(), ensure the include() pattern has a trailing '/'.\")]),\n        ]\n        for pattern, expected_warnings in test_urls:\n            with self.subTest(pattern=pattern):\n                url_pattern = URLPattern(RegexPattern(pattern), views.empty_view)\n                self.assertEqual(url_pattern.check(), expected_warnings)\n"], "sample_1046": ["def test_tensor_replace_indices():\n    L = TensorIndexType(\"L\")\n    i, j, k, l = tensor_indices(\"i j k l\", L)\n    A, B = tensorhead(\"A B\", [L], [[1]])\n\n    expr = A(i)*B(j)\n    expr_replaced = expr.replace_indices((i, k), (j, l))\n    assert expr_replaced == A(k)*B(l)\n\n    expr_replaced = expr.replace_indices((i, -k), (j, l))\n    assert expr_replaced == A(-k)*B(l)\n\n    expr_replaced = expr.replace_indices((i, k), (j, -l))\n    assert expr_replaced == A(k)*B(-l)\n\n    expr_replaced = expr.replace_indices((i, -k), (j, -l))\n    assert expr_replaced == A(-k)*B(-l)\n"], "sample_412": ["def test_urlize_with_autoescape(self):\n    tests = (\n        (\n            \"Search for google.com/?q=! and see.\",\n            'Search for <a href=\"http://google.com/?q=&quot;\">google.com/?q=</a>! and '\n            \"see.\",\n        ),\n        (\n            \"foo@example.com\",\n            '<a href=\"mailto:foo@example.com\">foo@example.com</a>',\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value, autoescape=True), output)\n"], "sample_408": ["def test_add_model_with_field_removed_from_base_model_and_renamed(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name, and renaming the field.\n    \"\"\"\n    before = [\n        ModelState(\n            \"app\",\n            \"readable\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"title\", models.CharField(max_length=200)),\n            ],\n        ),\n    ]\n    after = [\n        ModelState(\n            \"app\",\n            \"readable\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n            ],\n        ),\n        ModelState(\n            \"app\",\n            \"book\",\n            [\n                (\"new_title\", models.CharField(max_length=200)),\n            ],\n            bases=(\"app.readable\",),\n        ),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, \"app\", 1)\n    self.assertOperationTypes(changes, \"app\", 0, [\"RemoveField\", \"CreateModel\"])\n    self.assertOperationAttributes(\n        changes, \"app\", 0, 0, name=\"title\", model_name=\"readable\"\n    )\n    self.assertOperationAttributes(changes, \"app\", 0, 1, name=\"book\")\n"], "sample_1178": ["def test_ComplexType():\n    val9_11 = 123.456789049 + 0.123456789049j\n    raises(ValueError, lambda: c64.cast_check(.12345678949 + .12345678949j))\n    assert abs(val9_11 - c64.cast_check(val9_11) - 4.9e-8) < 1e-8\n\n    dcm21 = Float('0.123456789012345670499') + 1e-20j  # 21 decimals\n    assert abs(dcm21 - c128.cast_check(dcm21) - 4.99e-19) < 1e-19\n    v19 = Float('0.1234567890123456749') + 1j*Float('0.1234567890123456749')\n    raises(ValueError, lambda: c128.cast_check(v19))\n\n    assert c64.cast_nocheck(val9_11) == val9_11\n    assert c128.cast_nocheck(dcm21) == dcm21\n"], "sample_354": ["def test_validate_fk_via_option_non_interactive(self):\n    email = Email.objects.create(email='mymail@gmail.com')\n    Group.objects.all().delete()\n    nonexistent_group_id = 1\n    msg = f'group instance with id {nonexistent_group_id} does not exist.'\n\n    with self.assertRaisesMessage(CommandError, msg):\n        call_command(\n            'createsuperuser',\n            interactive=False,\n            username=email.pk,\n            email=email.email,\n            group=nonexistent_group_id,\n            verbosity=0,\n        )\n"], "sample_789": ["def test_sample_weight_adaboost_classifier():\n    \"\"\"\n    AdaBoostClassifier should work with sample_weights in the base estimator\n    The sample_weights are used internally in the _boost method in\n    AdaBoostClassifier.\n    \"\"\"\n    class DummyEstimator(BaseEstimator):\n\n            self.sample_weight = sample_weight\n            return self\n\n            return np.zeros(X.shape[0])\n\n    X, y = datasets.make_classification(n_samples=20, n_features=2, n_informative=2,\n                                        n_redundant=0, random_state=0, shuffle=False)\n    sample_weight = np.random.RandomState(0).rand(20)\n\n    clf = AdaBoostClassifier(base_estimator=DummyEstimator(), random_state=0)\n    clf.fit(X, y, sample_weight=sample_weight)\n\n    assert_array_equal(clf.estimators_[0].sample_weight, sample_weight)\n"], "sample_567": ["def test_annotation_antialiased_with_math():\n    annot = Annotation(r\"$foo\\nbar$\", (.5, .5), antialiased=True)\n    assert annot._antialiased is True\n    assert annot.get_antialiased() == annot._antialiased\n\n    annot2 = Annotation(r\"$foo\\nbar$\", (.5, .5), antialiased=False)\n    assert annot2._antialiased is False\n    assert annot2.get_antialiased() == annot2._antialiased\n\n    annot3 = Annotation(r\"$foo\\nbar$\", (.5, .5), antialiased=False)\n    annot3.set_antialiased(True)\n    assert annot3.get_antialiased() is True\n    assert annot3._antialiased is True\n\n    annot4 = Annotation(r\"$foo\\nbar$\", (.5, .5))\n    assert annot4._antialiased == mpl.rcParams['text.antialiased']\n"], "sample_543": ["def test_polygon_selector_box_props(ax):\n    # Create a diamond shape\n    verts = [(20, 0), (0, 20), (20, 40), (40, 20)]\n    event_sequence = [\n        *polygon_place_vertex(*verts[0]),\n        *polygon_place_vertex(*verts[1]),\n        *polygon_place_vertex(*verts[2]),\n        *polygon_place_vertex(*verts[3]),\n        *polygon_place_vertex(*verts[0]),\n    ]\n\n    # Create selector with custom box props\n    tool = widgets.PolygonSelector(ax, onselect=noop, draw_bounding_box=True,\n                                   box_props=dict(facecolor='r', alpha=0.2),\n                                   box_handle_props=dict(alpha=0.5))\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n\n    # Check that box props were set correctly\n    assert tool._box._selection_artist.get_facecolor() == mcolors.to_rgba('r', alpha=0.2)\n    for artist in tool._box._handles_artists:\n        assert artist.get_alpha() == 0.5\n"], "sample_344": ["def test_abstract_model_children_inherit_constraints(self):\n    class Abstract(models.Model):\n        size = models.IntegerField()\n\n        class Meta:\n            app_label = 'migrations'\n            abstract = True\n            constraints = [models.CheckConstraint(check=models.Q(size__gt=1), name='size_gt_1')]\n\n    class Child1(Abstract):\n        pass\n\n    class Child2(Abstract):\n        pass\n\n    child1_state = ModelState.from_model(Child1)\n    child2_state = ModelState.from_model(Child2)\n    constraint_names = [constraint.name for constraint in child1_state.options['constraints']]\n    self.assertEqual(constraint_names, ['size_gt_1'])\n    constraint_names = [constraint.name for constraint in child2_state.options['constraints']]\n    self.assertEqual(constraint_names, ['size_gt_1'])\n\n    # Modifying the state doesn't modify the constraint on the model.\n    child1_state.options['constraints'][0].name = 'bar'\n    self.assertEqual(Child1._meta.constraints[0].name, 'size_gt_1')\n"], "sample_307": ["def test_time_formats_with_microseconds(self):\n    dt = datetime(2009, 5, 16, 5, 30, 30, 123456)\n    self.assertEqual(dateformat.format(dt, 'u'), '123456')\n"], "sample_613": ["def test_groupby_bins_multidim_with_nan():\n    array = make_groupby_multidim_example_array()\n    array[0, 0, 0] = np.nan\n    bins = [0, 15, 20]\n    bin_coords = pd.cut(array[\"lat\"].values.flat, bins).categories\n    expected = DataArray([15, 40], dims=\"lat_bins\", coords={\"lat_bins\": bin_coords})\n    actual = array.groupby_bins(\"lat\", bins).map(lambda x: x.sum(skipna=True))\n    assert_identical(expected, actual)\n"], "sample_966": ["def test_pyfunction_signature_with_defaults(app):\n    text = \".. py:function:: hello(name='World') -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_operator, \"=\"],\n                                                      [nodes.inline, \"'World'\"])])\n"], "sample_282": ["def test_form_initial_data(self):\n    initial_data = 'some text,JP,2007-04-25 06:24:00'\n    form = ComplexFieldForm(initial={'field1': initial_data})\n    self.assertHTMLEqual(\n        form.as_table(),\n        \"\"\"\n        <tr><th><label for=\"id_field1_0\">Field1:</label></th>\n        <td><input type=\"text\" name=\"field1_0\" value=\"some text\" id=\"id_field1_0\" required>\n        <select multiple name=\"field1_1\" id=\"id_field1_1\" required>\n        <option value=\"J\" selected>John</option>\n        <option value=\"P\" selected>Paul</option>\n        <option value=\"G\">George</option>\n        <option value=\"R\">Ringo</option>\n        </select>\n        <input type=\"text\" name=\"field1_2_0\" value=\"2007-04-25\" id=\"id_field1_2_0\" required>\n        <input type=\"text\" name=\"field1_2_1\" value=\"06:24:00\" id=\"id_field1_2_1\" required></td></tr>\n        \"\"\",\n    )\n"], "sample_1077": ["def test_ComplexRegion_properties():\n    a = Interval(2, 3)\n    b = Interval(4, 6)\n    c = Interval(7, 9)\n    c1 = ComplexRegion(a*b)\n    c2 = ComplexRegion(Union(a*b, c*a))\n\n    assert c1.sets == a*b\n    assert c2.sets == Union(a*b, c*a)\n    assert c1.psets == (a*b,)\n    assert c2.psets == (a*b, c*a)\n    assert c1.a_interval == a\n    assert c2.a_interval == Union(a, c)\n    assert c1.b_interval == b\n    assert c2.b_interval == Union(b, a)\n    assert c1.polar == False\n    assert c2.polar == False\n    assert c1._measure == 6\n    assert c2._measure == 18\n"], "sample_58": ["def test_field_named_files(self):\n    class FilesForm(Form):\n        file = FileField()\n\n    f = FilesForm({}, files={'file': SimpleUploadedFile('name', b'content')})\n    self.assertTrue(f.is_valid())\n    self.assertEqual(f.cleaned_data['file'].read(), b'content')\n"], "sample_401": ["def test_formset_with_custom_prefix(self):\n    \"\"\"Formsets can have a custom prefix.\"\"\"\n    ChoiceFormSet = formset_factory(Choice)\n    formset = ChoiceFormSet(prefix=\"custom_prefix\")\n    self.assertEqual(formset.management_form.prefix, \"custom_prefix\")\n    self.assertHTMLEqual(\n        str(formset.management_form),\n        '<input type=\"hidden\" name=\"custom_prefix-TOTAL_FORMS\" value=\"1\">'\n        '<input type=\"hidden\" name=\"custom_prefix-INITIAL_FORMS\" value=\"0\">'\n        '<input type=\"hidden\" name=\"custom_prefix-MIN_NUM_FORMS\" value=\"0\">'\n        '<input type=\"hidden\" name=\"custom_prefix-MAX_NUM_FORMS\" value=\"1000\">',\n    )\n"], "sample_573": ["def test_order_too_high(self, df):\n\n    groupby = GroupBy([\"group\"])\n    order = df[\"x\"].nunique()\n    res = PolyFit(order=order, gridsize=100)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n\n    assert res.empty\n"], "sample_474": ["def test_null_value(self):\n    authors = Author.objects.annotate(first_initial=Left(F(\"alias\"), 1))\n    self.assertCountEqual(authors.filter(first_initial=Chr(ord(\"J\"))), [self.john])\n    self.assertCountEqual(authors.filter(first_initial=Chr(None)), [self.rhonda])\n"], "sample_468": ["def test_bind_template(self):\n    request = self.request_factory.get(\"/\")\n    template = mock.Mock()\n    template.engine.template_context_processors = [context_process_returning_none]\n    context = RequestContext(request)\n    with context.bind_template(template):\n        self.assertEqual(context.template, template)\n        self.assertEqual(context.dicts[context._processors_index], {})\n    self.assertIsNone(context.template)\n    self.assertEqual(context.dicts[context._processors_index], {})\n"], "sample_939": ["def test_unparse_complex_expression():\n    source = \"a + b * (c - d) / e\"\n    expected = \"a + b * (c - d) / e\"\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].value, source) == expected\n"], "sample_1023": ["def test_sieve_reset():\n    sieve._reset()\n    assert sieve._list == _array('l', [2, 3, 5, 7, 11, 13])\n    assert sieve._tlist == _array('l', [0, 1, 1, 2, 2, 4])\n    assert sieve._mlist == _array('l', [0, 1, -1, -1, 0, -1])\n\n    sieve._reset(prime=False)\n    assert sieve._list == _array('l', [2, 3, 5, 7, 11, 13])\n    assert sieve._tlist != _array('l', [0, 1, 1, 2, 2, 4])\n    assert sieve._mlist != _array('l', [0, 1, -1, -1, 0, -1])\n\n    sieve._reset(totient=False)\n    assert sieve._list == _array('l', [2, 3, 5, 7, 11, 13])\n    assert sieve._tlist == _array('l', [0, 1, 1, 2, 2, 4])\n    assert sieve._mlist != _array('l', [0, 1, -1, -1, 0, -1])\n\n    sieve._reset(mobius=False)\n    assert sieve._list == _array('l', [2, 3, 5, 7, 11, 13])\n    assert sieve._tlist == _array('l', [0, 1, 1, 2, 2, 4])\n    assert sieve._mlist == _array('l', [0, 1, -1, -1, 0, -1])\n"], "sample_777": ["def test_gradient_boosting_with_sample_weight():\n    # Check that GradientBoostingRegressor works when sample_weight is provided\n    X, y = make_regression()\n    sample_weight = np.random.RandomState(42).rand(100)\n\n    gbr = GradientBoostingRegressor(n_estimators=100, random_state=42)\n    gbr.fit(X, y, sample_weight=sample_weight)\n    assert hasattr(gbr, 'feature_importances_')\n"], "sample_505": ["def test_date2num_numpy_datetime64():\n    # Test date2num with numpy datetime64 objects\n    dt = np.datetime64('2000-01-01')\n    assert mdates.date2num(dt) == 730120.0\n\n    dt_array = np.array(['2000-01-01', '2000-01-02'], dtype='datetime64[D]')\n    expected_array = np.array([730120.0, 730121.0])\n    np.testing.assert_array_equal(mdates.date2num(dt_array), expected_array)\n"], "sample_899": ["def test_check_estimator_sparsify_coefficients():\n    # check that check_estimator() works on estimator with sparsify_coefficients\n    est = LinearRegression()\n    check_estimator(est)\n"], "sample_721": ["def test_check_memory():\n    memory = check_memory(None)\n    assert isinstance(memory, sklearn.externals.joblib.Memory)\n\n    memory = check_memory('/tmp/')\n    assert isinstance(memory, sklearn.externals.joblib.Memory)\n\n    memory = DummyMemory()\n    assert memory == check_memory(memory)\n\n    invalid_memory = 'invalid'\n    with pytest.raises(ValueError, match=\"'memory' should be None, a string or have the same interface as sklearn.externals.joblib.Memory.\"):\n        check_memory(invalid_memory)\n"], "sample_915": ["def test_getdoc_inherited_decorated_method():\n    class Foo:\n            \"\"\"docstring.\"\"\"\n\n    class Bar(Foo):\n        @functools.wraps(Foo.meth)\n            pass\n\n    assert inspect.getdoc(Bar.meth, allow_inherited=True, cls=Bar, name='meth') == \"docstring.\"\n"], "sample_649": ["def test_log_file_cli_subdirectories_are_successfully_created_with_absolute_path(\n    pytester: Pytester,"], "sample_680": ["def test_skipif_with_boolean_without_reason(testdir) -> None:\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(False)\n            pass\n    \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_xfail_marks(item)\n    assert excinfo.value.msg is not None\n    assert (\n        \"\"\"Error evaluating 'xfail': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n        in excinfo.value.msg\n    )\n"], "sample_551": ["def test_patch_collection_3d():\n    fig, ax = plt.subplots(subplot_kw=dict(projection='3d'))\n    x = np.arange(10)\n    y = np.arange(10)\n    z = np.zeros(10)\n    verts = [list(zip(x, y, z))]\n    pc = art3d.Patch3DCollection(verts, facecolors='r', alpha=0.5)\n    ax.add_collection3d(pc)\n"], "sample_839": ["def test_vectorizer_max_df_min_df():\n    test_data = ['abc', 'dea', 'eat']\n    vect = CountVectorizer(analyzer='char', max_df=0.5, min_df=2)\n    vect.fit(test_data)\n    assert 'a' not in vect.vocabulary_.keys()  # {ae} ignored\n    assert len(vect.vocabulary_.keys()) == 2    # {bd} remain\n    assert 'a' in vect.stop_words_\n    assert len(vect.stop_words_) == 3\n"], "sample_782": ["def test_column_transformer_callable_specifier_pandas():\n    pd = pytest.importorskip('pandas')\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    X_df = pd.DataFrame(X_array, columns=['first', 'second'])\n    X_res_first = np.array([[0, 1, 2]]).T\n\n        assert_array_equal(X.columns, X_df.columns)\n        assert_array_equal(X.values, X_df.values)\n        return ['first']\n\n    ct = ColumnTransformer([('trans', Trans(), func)],\n                           remainder='drop')\n    assert_array_equal(ct.fit_transform(X_df), X_res_first)\n    assert_array_equal(ct.fit(X_df).transform(X_df), X_res_first)\n    assert callable(ct.transformers[0][2])\n    assert ct.transformers_[0][2] == ['first']\n"], "sample_945": ["def test_pyfunction_with_default_values(app):\n    text = \".. py:function:: hello(name='World', age=30)\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, ([desc_parameter, ([desc_sig_name, \"name\"],\n                                                        [desc_sig_operator, \"=\"],\n                                                        [nodes.inline, \"'World'\"])],\n                                      [desc_parameter, ([desc_sig_name, \"age\"],\n                                                        [desc_sig_operator, \"=\"],\n                                                        [nodes.inline, \"30\"])])])\n"], "sample_571": ["def test_regplot_line_kws_alpha(self):\n\n    f, ax = plt.subplots()\n    color = np.array([[0.3, 0.8, 0.5, 0.5]])\n    ax = lm.regplot(x=\"x\", y=\"y\", data=self.df,\n                    line_kws={'color': color})\n    assert ax.lines[0].get_alpha() == 0.5\n\n    f, ax = plt.subplots()\n    color = np.array([[0.3, 0.8, 0.5]])\n    ax = lm.regplot(x=\"x\", y=\"y\", data=self.df,\n                    line_kws={'color': color, 'alpha': 0.4})\n    assert ax.lines[0].get_alpha() == 0.4\n\n    f, ax = plt.subplots()\n    color = 'r'\n    ax = lm.regplot(x=\"x\", y=\"y\", data=self.df,\n                    line_kws={'color': color})\n    assert ax.lines[0].get_alpha() == 1.0\n"], "sample_163": ["def test_logout_with_custom_redirect_argument_and_allowed_hosts(self):\n    self.login()\n    response = self.client.post(\"/logout/allowed_hosts/custom_query/?follow=https://otherserver/\")\n    self.assertRedirects(response, \"https://otherserver/\", fetch_redirect_response=False)\n    self.confirm_logged_out()\n"], "sample_637": ["def test_regex_codetag(self) -> None:\n    code = \"\"\"a = 1\n            # HACK\n            \"\"\"\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"fixme\", line=2, args=\"HACK\", col_offset=17)\n    ):\n        self.checker.process_tokens(_tokenize_str(code))\n"], "sample_667": ["def test_tmp_path_factory_with_given_basetemp(tmp_path):\n    from _pytest.tmpdir import TempPathFactory\n\n    config = FakeConfig(tmp_path)\n    t = TempPathFactory.from_config(config)\n    tmp = t.mktemp(\"test\")\n    assert tmp.parent == tmp_path\n    assert tmp.name.startswith(\"test\")\n"], "sample_337": ["def test_https_good_referer_matches_cookie_domain_with_trailing_slash(self):\n    \"\"\"\n    A POST HTTPS request with a good referer should be accepted from a\n    subdomain that's allowed by SESSION_COOKIE_DOMAIN and has a trailing slash.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_REFERER'] = 'https://foo.example.com/'\n    req.META['SERVER_PORT'] = '443'\n    mw = CsrfViewMiddleware(post_form_view)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n"], "sample_59": ["def test_model_save_with_unsaved_related_object(self):\n    # Test that saving a model instance with an unsaved related object raises a ValueError\n    department = Department(name=\"Test Department\")\n    worker = Worker(name=\"Test Worker\", department=department)\n    with self.assertRaises(ValueError):\n        worker.save()\n"], "sample_1085": ["def test_Float_floor_ceiling():\n    a = Float(3.7)\n    b = Float(3.2)\n\n    assert a.floor() == 3.0\n    assert a.ceiling() == 4.0\n    assert b.floor() == 3.0\n    assert b.ceiling() == 4.0\n"], "sample_54": ["def test_file_from_buffer_with_filename(self):\n    response = FileResponse(io.BytesIO(b'binary content'), filename='test.txt')\n    self.assertEqual(response['Content-Length'], '14')\n    self.assertEqual(response['Content-Type'], 'text/plain')\n    self.assertEqual(response['Content-Disposition'], 'inline; filename=\"test.txt\"')\n    self.assertEqual(list(response), [b'binary content'])\n"], "sample_491": ["def test_custom_renderer_field_template_name_override(self):\n    class Person(Form):\n        first_name = CharField(template_name=\"forms_tests/custom_field_override.html\")\n\n    get_default_renderer.cache_clear()\n    t = Template(\"{{ form.first_name.as_field_group }}\")\n    html = t.render(Context({\"form\": Person()}))\n    expected = \"\"\"\n    <label for=\"id_first_name\">First name:</label>\n    <p>Custom Field Override<p>\n    <input type=\"text\" name=\"first_name\" required id=\"id_first_name\">\n    \"\"\"\n    self.assertHTMLEqual(html, expected)\n    get_default_renderer.cache_clear()\n"], "sample_327": ["def test_custom_encoder_decoder_with_invalid_json(self):\n    class CustomDecoder(json.JSONDecoder):\n            return super().__init__(object_hook=self.as_uuid, *args, **kwargs)\n\n            if 'uuid' in dct:\n                dct['uuid'] = uuid.UUID(dct['uuid'])\n            return dct\n\n    invalid_json = '{\"uuid\": \"invalid-uuid\"}'\n    field = JSONField(encoder=DjangoJSONEncoder, decoder=CustomDecoder)\n    with self.assertRaisesMessage(ValidationError, 'Enter a valid JSON.'):\n        field.clean(invalid_json)\n"], "sample_450": ["def test_get_admin_log_tag(self):\n    \"\"\"\n    Test the 'get_admin_log' template tag.\n    \"\"\"\n    # Create additional log entries for different users\n    user2 = User.objects.create_user(username=\"user2\", password=\"secret2\")\n    content_type_pk = ContentType.objects.get_for_model(Article).pk\n    LogEntry.objects.log_action(\n        user2.pk,\n        content_type_pk,\n        self.a1.pk,\n        repr(self.a1),\n        CHANGE,\n        change_message=\"Changed something by user2\",\n    )\n\n    # Render a template with the 'get_admin_log' tag\n    template = Template(\n        \"{% load admin_log %}\"\n        \"{% get_admin_log 10 as admin_log for_user user %}\"\n    )\n    context = Context({\"log_entries\": LogEntry.objects.all(), \"user\": self.user})\n    rendered = template.render(context)\n\n    # Check that the rendered template contains the correct log entries\n    self.assertIn(\"Changed something\", rendered)\n    self.assertNotIn(\"Changed something by user2\", rendered)\n"], "sample_856": ["def test_leave_p_out_empty_trainset():\n    cv = LeavePOut(p=2)\n    X, y = [[1]], [0]  # 1 sample\n    with pytest.raises(\n            ValueError,\n            match='Cannot perform LeavePOut with n_samples=1 and p=2'):\n        next(cv.split(X, y))\n"], "sample_875": ["def test_balanced_accuracy_score_multilabel():\n    y_true = np.array([[0, 1, 1], [1, 0, 0], [0, 0, 1]])\n    y_pred = np.array([[0, 1, 0], [1, 0, 0], [0, 0, 1]])\n    balanced = balanced_accuracy_score(y_true, y_pred)\n    assert balanced == pytest.approx(0.8888888888888888)\n"], "sample_980": ["def test_commutes_with():\n    p = Permutation([1, 5, 2, 0, 3, 6, 4])\n    q = Permutation([[1, 2, 3, 5, 6], [0, 4]])\n    assert p.commutes_with(q) == False\n    assert q.commutes_with(p) == False\n    r = Permutation([0, 1, 2, 3])\n    assert r.commutes_with(r) == True\n"], "sample_824": ["def test_check_preserve_type_sparse():\n    # Ensures that type float32 is preserved for sparse matrices.\n    XA = csr_matrix(np.resize(np.arange(40), (5, 8)).astype(np.float32))\n    XB = csr_matrix(np.resize(np.arange(40), (5, 8)).astype(np.float32))\n\n    XA_checked, XB_checked = check_pairwise_arrays(XA, None)\n    assert_equal(XA_checked.dtype, np.float32)\n\n    # both float32\n    XA_checked, XB_checked = check_pairwise_arrays(XA, XB)\n    assert_equal(XA_checked.dtype, np.float32)\n    assert_equal(XB_checked.dtype, np.float32)\n\n    # mismatched A\n    XA_checked, XB_checked = check_pairwise_arrays(XA.astype(np.float), XB)\n    assert_equal(XA_checked.dtype, np.float)\n    assert_equal(XB_checked.dtype, np.float)\n\n    # mismatched B\n    XA_checked, XB_checked = check_pairwise_arrays(XA, XB.astype(np.float))\n    assert_equal(XA_checked.dtype, np.float)\n    assert_equal(XB_checked.dtype, np.float)\n"], "sample_438": ["def test_get_object_cache_respects_updated_objects(self):\n    question = Question.objects.create(text=\"Who?\")\n    post = Post.objects.create(title=\"Answer\", parent=question)\n\n    question.text = \"Who is your favorite author?\"\n    question.save()\n\n    post = Post.objects.get(pk=post.pk)\n    with self.assertNumQueries(1):\n        self.assertEqual(post.parent.text, \"Who is your favorite author?\")\n"], "sample_671": ["def test_skip_with_allow_module_level(testdir):\n    \"\"\"\n    Verify that using pytest.skip(allow_module_level=True) at module level is allowed\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        pytest.skip(\"skip_module_level\", allow_module_level=True)\n\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxs\")\n    result.stdout.fnmatch_lines([\"*SKIP*skip_module_level\"])\n"], "sample_564": ["def test_panecolor_kwargs():\n    fig = plt.figure(figsize=(1, 1))\n    fig.add_subplot(projection='3d', xpane={'color': 'r'}, ypane={'color': 'g'}, zpane={'color': 'b'})\n"], "sample_1078": ["def test_Indexed_derivative_with_array():\n    from sympy import NDimArray\n    i, j = symbols('i j', integer=True)\n    A = NDimArray([[1, 2], [3, 4]])\n    B = IndexedBase(A)\n    assert B[i, j].diff(B[i, j]) == 1\n    assert B[i, j].diff(B[i, j+1]) == 0\n    assert B[i, j].diff(B[i+1, j]) == 0\n    assert B[i, j].diff(B[i+1, j+1]) == 0\n"], "sample_1131": ["def test_log1p():\n    expr = log1p(x)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr) == 'scipy.special.log1p(x)'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr) == 'numpy.log1p(x)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr) == 'math.log(x + 1)'\n\n    prntr = MpmathPrinter()\n    assert prntr.doprint(expr) == 'mpmath.log(x + 1)'\n"], "sample_787": ["def test_balanced_accuracy_score_multiclass():\n    # Test balanced accuracy score for multiclass classification task\n    y_true, y_pred, _ = make_prediction(binary=False)\n\n    # compute score with default labels introspection\n    score = balanced_accuracy_score(y_true, y_pred)\n    assert_almost_equal(score, 0.53, 2)\n\n    # compute score with explicit label ordering\n    score = balanced_accuracy_score(y_true, y_pred, labels=[0, 2, 1])\n    assert_almost_equal(score, 0.53, 2)\n"], "sample_1108": ["def test_has_variety():\n    assert has_variety((1, 2, 1)) is True\n    assert has_variety((1, 1, 1)) is False\n"], "sample_820": ["def test_sample_weight_regressor():\n    \"\"\"Tests sample_weight parameter of VotingRegressor\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(random_state=123)\n    ereg1 = VotingRegressor(estimators=[\n        ('lr', reg1), ('rf', reg2)],\n        weights=[1, 2]).fit(X_r, y_r, sample_weight=np.ones((len(y_r),)))\n    ereg2 = VotingRegressor(estimators=[\n        ('lr', reg1), ('rf', reg2)],\n        weights=[1, 2]).fit(X_r, y_r)\n    assert_array_equal(ereg1.predict(X_r), ereg2.predict(X_r))\n\n    sample_weight = np.random.RandomState(123).uniform(size=(len(y_r),))\n    ereg3 = VotingRegressor(estimators=[('lr', reg1)], weights=[1])\n    ereg3.fit(X_r, y_r, sample_weight)\n    reg1.fit(X_r, y_r, sample_weight)\n    assert_array_equal(ereg3.predict(X_r), reg1.predict(X_r))\n"], "sample_221": ["def test_filter_with_exclude(self):\n    group = Group.objects.create(name='test')\n    Event.objects.create(title='event1', group=group)\n    Event.objects.create(title='event2', group=group)\n    events = Event.objects.filter(group=group).exclude(title='event1')\n    self.assert_pickles(events)\n"], "sample_999": ["def test_Quaternion_latex_printing_with_zero_components():\n    q = Quaternion(0, 0, 0, 0)\n    assert latex(q) == \"0\"\n    q = Quaternion(0, y, 0, 0)\n    assert latex(q) == \"y i\"\n    q = Quaternion(0, 0, z, 0)\n    assert latex(q) == \"z j\"\n    q = Quaternion(0, 0, 0, t)\n    assert latex(q) == \"t k\"\n"], "sample_821": ["def test_affinity_propagation_sparse_input():\n    # Test AffinityPropagation with sparse input\n    X_sparse = csr_matrix(X)\n    af = AffinityPropagation(affinity=\"euclidean\")\n    labels_sparse = af.fit_predict(X_sparse)\n    labels_dense = af.fit_predict(X)\n    assert_array_equal(labels_sparse, labels_dense)\n"], "sample_284": ["def test_template_tag_with_spaces(self):\n    relpath = self.hashed_file_path(\"cached/spaces.css\")\n    self.assertEqual(relpath, \"cached/spaces.123456789abc.css\")\n    with storage.staticfiles_storage.open(relpath) as relfile:\n        content = relfile.read()\n        self.assertNotIn(b\"cached/other.css\", content)\n        self.assertIn(b\"other.d41d8cd98f00.css\", content)\n    self.assertPostCondition()\n"], "sample_349": ["def test_render_options_with_custom_to_field(self):\n    beatles = Band.objects.create(name='The Beatles', style='rock')\n    album = Album.objects.create(name='Rubber Soul', band=beatles, featuring=beatles)\n    release_event = ReleaseEvent.objects.create(name='Test Target', album=album)\n    form = VideoStreamForm(initial={'release_event': release_event.name})\n    output = form.as_table()\n    selected_option = '<option value=\"%s\" selected>Test Target</option>' % release_event.pk\n    self.assertIn(selected_option, output)\n"], "sample_960": ["def test_pyfunction_with_positional_only_arguments(app):\n    text = \".. py:function:: hello(a, /, b)\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, ([desc_parameter, desc_sig_name, \"a\"],\n                                      [desc_parameter, desc_sig_operator, \"/\"],\n                                      [desc_parameter, desc_sig_name, \"b\"])])\n"], "sample_4": ["def test_readwrite_html_table_units(self, cosmo_cls, cosmo, read, write, tmp_path, add_cu):\n    \"\"\"Test cosmology -> ascii.html -> cosmology with units.\"\"\"\n    fp = tmp_path / \"test_readwrite_html_table_units.html\"\n\n    # Write cosmology to HTML table with units\n    write(fp, format=\"ascii.html\")\n\n    # Read cosmology from HTML table with units\n    got = read(fp, format=\"ascii.html\")\n\n    # Check that the read cosmology is equal to the original cosmology\n    assert got == cosmo\n"], "sample_464": ["def test_file_response_with_content_type_none(self):\n    \"\"\"\n    FileResponse should set Content-Type to application/octet-stream if no content_type is provided.\n    \"\"\"\n    response = FileResponse(io.BytesIO(b\"binary content\"))\n    self.assertEqual(response.headers[\"Content-Type\"], \"application/octet-stream\")\n"], "sample_1055": ["def test_bg_public_key():\n    assert 1573 == bg_public_key(23, 68)\n    assert 3003 == bg_public_key(71, 43)\n    raises(ValueError, lambda: bg_public_key(15, 19))\n"], "sample_1070": ["def test_exp_power():\n    x = Symbol('x')\n    assert exp(x)**2 == exp(2*x)\n    assert exp(x)**(1/2) == exp(x/2)\n    assert exp(x)**(-1) == exp(-x)\n    assert exp(x)**y == exp(x*y)\n"], "sample_1127": ["def test_coset_class_exceptions():\n    a = Permutation(1, 2)\n    b = Permutation(0, 1)\n    G = PermutationGroup([a, b])\n    H = PermutationGroup([a])\n    g = Permutation(0, 1, 2)\n    with pytest.raises(ValueError):\n        Coset(g, H, G, dir='+')\n    with pytest.raises(ValueError):\n        Coset(g, G, H, dir='+')\n    with pytest.raises(NotImplementedError):\n        Coset(1, H, G, dir='+')\n    with pytest.raises(NotImplementedError):\n        Coset(g, 1, G, dir='+')\n    with pytest.raises(NotImplementedError):\n        Coset(g, H, 1, dir='+')\n    with pytest.raises(ValueError):\n        Coset(g, H, G, dir='*')\n"], "sample_518": ["def test_default_joinstyle():\n    patch = Patch()\n    assert patch.get_joinstyle() == 'miter'\n"], "sample_654": ["def test_call_fixture_function_error(fix):\n    with pytest.raises(RuntimeError):\n        fix()\n"], "sample_574": ["def test_label_concise(self, t):\n\n    s = Temporal().label(concise=True)\n    a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n    a.set_view_interval(10, 1000)\n    label, = a.major.formatter.format_ticks([100])\n    assert label == \"1970\"\n"], "sample_648": ["def test_mark_decorator_with_args(pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.a(1, 2, key='value')\n            pass\n        \"\"\"\n    )\n    items, rec = pytester.inline_genitems(p)\n    marker = items[0].get_closest_marker(\"a\")\n    assert marker is not None\n    assert marker.args == (1, 2)\n    assert marker.kwargs == {\"key\": \"value\"}\n"], "sample_596": ["def test_concat_coords_different_with_override():\n    ds1 = Dataset({\"a\": (\"x\", [1, 2])}, coords={\"x\": [0, 1], \"y\": 1})\n    ds2 = Dataset({\"a\": (\"x\", [3, 4])}, coords={\"x\": [2, 3], \"y\": 2})\n\n    with pytest.raises(ValueError, match=\"Cannot specify both coords='different' and compat='override'.\"):\n        concat([ds1, ds2], dim=\"x\", coords=\"different\", compat=\"override\")\n"], "sample_891": ["def test_top_k_accuracy_score_error_labels_length(y_true, y_score, labels, msg):\n    with pytest.raises(ValueError, match=msg):\n        top_k_accuracy_score(y_true, y_score, k=2, labels=labels)\n"], "sample_229": ["def test_union_with_different_fields(self):\n    qs1 = Number.objects.filter(num=1).values('num')\n    qs2 = Number.objects.filter(num=2).values('other_num')\n    msg = \"Merging 'QuerySet' classes must involve the same values in each case.\"\n    with self.assertRaisesMessage(TypeError, msg):\n        list(qs1.union(qs2))\n"], "sample_535": ["def test_cell_text_props():\n    fig, ax = plt.subplots()\n    table = Table(ax)\n\n    cell = table.add_cell(0, 0, 1, 1, text='Test')\n    cell.set_text_props(color='red', weight='bold')\n\n    plt.tight_layout()\n"], "sample_286": ["def test_refresh_fk_on_delete_cascade(self):\n    a = Article.objects.create(\n        headline='Parrot programs in Python',\n        pub_date=datetime(2005, 7, 28),\n    )\n    s1 = SelfRef.objects.create(article=a)\n    a.delete()\n    with self.assertRaises(SelfRef.DoesNotExist):\n        s1.refresh_from_db()\n"], "sample_471": ["def test_integerfield_invalid_input(self):\n    f = IntegerField()\n    with self.assertRaisesMessage(ValidationError, \"'Enter a whole number.'\"):\n        f.clean(\"invalid\")\n"], "sample_426": ["def test_years_edge(self):\n    t = datetime.datetime(2000, 1, 1)\n    tests = [\n        (datetime.datetime(2000, 12, 31), \"11\\xa0months, 4\\xa0weeks\"),\n        (datetime.datetime(2001, 1, 1), \"1\\xa0year\"),\n        (datetime.datetime(2001, 12, 31), \"1\\xa0year, 11\\xa0months\"),\n        (datetime.datetime(2002, 1, 1), \"2\\xa0years\"),\n        (datetime.datetime(2002, 12, 31), \"2\\xa0years, 11\\xa0months\"),\n        (datetime.datetime(2003, 1, 1), \"3\\xa0years\"),\n        (datetime.datetime(2003, 12, 31), \"3\\xa0years, 11\\xa0months\"),\n        (datetime.datetime(2004, 1, 1), \"4\\xa0years\"),\n        (datetime.datetime(2004, 12, 31), \"4\\xa0years, 11\\xa0months\"),\n        (datetime.datetime(2005, 1, 1), \"5\\xa0years\"),\n        (datetime.datetime(2005, 12, 31), \"5\\xa0years, 11\\xa0months\"),\n        (datetime.datetime(2006, 1, 1), \"6\\xa0years\"),\n        (datetime.datetime(2006, 12, 31), \"6\\xa0years, 11\\xa0months\"),\n        (datetime.datetime(2007, 1, 1), \"7\\xa0years\"),\n        (datetime.datetime(2007, 12, 31), \"7\\xa0years, 11\\xa0months"], "sample_801": ["def test_simple_imputer():\n    # Render a SimpleImputer object\n    imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\", fill_value=None, verbose=0, copy=True)\n    expected = \"\"\""], "sample_283": ["def test_no_dbname_or_service(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env({\n            'USER': 'someuser',\n            'HOST': 'somehost',\n            'PORT': '444',\n        }), (\n            ['psql', '-U', 'someuser', '-h', 'somehost', '-p', '444', 'postgres'],\n            {},\n        )\n    )\n"], "sample_733": ["def test_vectorizer_invalid_ngram_range():\n    message = (\"Invalid value for ngram_range=(3, 2), \"\n               \"lower boundary larger than the upper boundary.\")\n    for vec in [CountVectorizer(), TfidfVectorizer(), HashingVectorizer()]:\n        vec.ngram_range = (3, 2)\n        assert_raise_message(\n            ValueError, message, vec.fit_transform, [\"hello world!\"])\n"], "sample_716": ["def test_ridge_classifier_cv_no_support_multilabel():\n    X, y = make_multilabel_classification(n_samples=10, random_state=0)\n    assert_raises(ValueError, RidgeClassifierCV().fit, X, y)\n"], "sample_833": ["def test_logistic_regression_path_intercept_scaling():\n    # Test that intercept_scaling is ignored when fit_intercept is False\n\n    coefs, _, _ = _logistic_regression_path(X, Y1, fit_intercept=False, intercept_scaling=2.0)\n    assert_equal(coefs.shape[-1], X.shape[1])\n"], "sample_986": ["def test_evalf_atan():\n    assert NS('atan(1)', 15) == '0.785398163397448'\n    assert NS('atan(0)', 15) == '0.000000000000000'\n    assert NS('atan(inf)', 15) == '1.57079632679490'\n    assert NS('atan(-inf)', 15) == '-1.57079632679490'\n"], "sample_120": ["def test_serialize_complex(self):\n    self.assertSerializedEqual(complex(1, 2))\n    self.assertSerializedResultEqual(\n        complex(1, 2),\n        (\"complex((1+2j))\", set())\n    )\n"], "sample_594": ["def test_format_timedelta():\n    cases = [\n        (pd.Timedelta(\"10 days 1 hour\"), \"10 days 01:00:00\", \"10 days\", \"01:00:00\"),\n        (pd.Timedelta(\"-3 days\"), \"-3 days +00:00:00\", \"-3 days\", \"00:00:00\"),\n        (pd.Timedelta(\"3 hours\"), \"0 days 03:00:00\", \"0 days\", \"03:00:00\"),\n        (pd.Timedelta(\"NaT\"), \"NaT\", \"NaT\", \"NaT\"),\n    ]\n    for item, expected, date_expected, time_expected in cases:\n        actual = formatting.format_timedelta(item)\n        assert expected == actual\n        actual_date = formatting.format_timedelta(item, timedelta_format=\"date\")\n        assert date_expected == actual_date\n        actual_time = formatting.format_timedelta(item, timedelta_format=\"time\")\n        assert time_expected == actual_time\n"], "sample_1200": ["def test_physical_constant_property():\n    assert not meter.is_physical_constant\n    assert not joule.is_physical_constant\n    assert not day.is_physical_constant\n    assert not second.is_physical_constant\n    assert not volt.is_physical_constant\n    assert not ohm.is_physical_constant\n    assert not centimeter.is_physical_constant\n    assert not kilometer.is_physical_constant\n    assert not kilogram.is_physical_constant\n    assert not pebibyte.is_physical_constant\n    assert elementary_charge.is_physical_constant\n    assert vacuum_permittivity.is_physical_constant\n    assert molar_gas_constant.is_physical_constant\n    assert gravitational_constant.is_physical_constant\n"], "sample_13": ["def test_angle_from_quantity():\n    \"\"\"\n    Test creating an Angle from a Quantity\n    \"\"\"\n    q = u.Quantity(54.12412, unit=u.degree)\n    a = Angle(q)\n    assert_allclose(a.degree, 54.12412)\n\n    q = u.Quantity(3.60827466667, unit=u.hour)\n    a = Angle(q)\n    assert_allclose(a.hour, 3.60827466667)\n\n    q = u.Quantity(0.944644098745, unit=u.radian)\n    a = Angle(q)\n    assert_allclose(a.radian, 0.944644098745)\n"], "sample_921": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n    @singledispatch\n        pass\n\n    @func.register(int)\n        pass\n\n    assert inspect.is_singledispatch_function(func) is True\n    assert inspect.is_singledispatch_function(func.register) is False\n\n        pass\n\n    assert inspect.is_singledispatch_function(not_singledispatch_func) is False\n"], "sample_456": ["def test_formset_with_custom_error_messages(self):\n    data = {\n        \"choices-TOTAL_FORMS\": \"2\",\n        \"choices-INITIAL_FORMS\": \"0\",\n        \"choices-MIN_NUM_FORMS\": \"0\",\n        \"choices-MAX_NUM_FORMS\": \"0\",\n        \"choices-0-choice\": \"Calexico\",\n        \"choices-0-votes\": \"\",\n        \"choices-1-choice\": \"One\",\n        \"choices-1-votes\": \"\",\n    }\n    custom_error_messages = {\n        \"missing_management_form\": \"Custom management form error message\",\n        \"too_many_forms\": \"Custom too many forms error message\",\n        \"too_few_forms\": \"Custom too few forms error message\",\n    }\n    ChoiceFormSet = formset_factory(Choice, error_messages=custom_error_messages)\n    formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(\n        formset.non_form_errors(),\n        [\"Custom too few forms error message\"],\n    )\n    self.assertEqual(\n        formset.errors,\n        [{\"votes\": [\"This field is required.\"]}, {\"votes\": [\"This field is required.\"]}],\n    )\n"], "sample_585": ["def test_da_groupby_apply_func_kwargs():\n\n        return kwargs['arg1'] + kwargs['arg2'] + kwargs.get('arg3', 0)\n\n    array = xr.DataArray([1, 1, 1], [('x', [1, 2, 3])])\n    expected = xr.DataArray([3, 3, 3], [('x', [1, 2, 3])])\n    actual = array.groupby('x').apply(func, arg1=1, arg2=1, arg3=1)\n    assert_identical(expected, actual)\n"], "sample_147": ["def test_union_with_different_models(self):\n    ReservedName.objects.create(name='99 little bugs', order=99)\n    qs1 = Number.objects.filter(num=1).values_list('num', flat=True)\n    qs2 = ReservedName.objects.values_list('order', flat=True)\n    self.assertEqual(list(qs1.union(qs2).order_by('num')), [1, 99])\n"], "sample_160": ["    def test_grouping_sequence(self):\n        self.assertEqual(nformat(123456789, '.', grouping=(3, 2), thousand_sep=',', force_grouping=True), '12,34,56,78,9')\n        self.assertEqual(nformat(123456789, '.', grouping=(3, 2, 0), thousand_sep=',', force_grouping=True), '123,45,67,89')\n"], "sample_1197": ["def test_physical_constant_property():\n    assert not meter.is_physical_constant\n    assert not joule.is_physical_constant\n    assert not day.is_physical_constant\n    assert not second.is_physical_constant\n    assert not volt.is_physical_constant\n    assert not ohm.is_physical_constant\n    assert not centimeter.is_physical_constant\n    assert not kilometer.is_physical_constant\n    assert not kilogram.is_physical_constant\n    assert not pebibyte.is_physical_constant\n    assert elementary_charge.is_physical_constant\n    assert vacuum_permittivity.is_physical_constant\n    assert molar_gas_constant.is_physical_constant\n    assert gravitational_constant.is_physical_constant\n"], "sample_751": ["def test_sample_weight_adaboost_classifier():\n    \"\"\"\n    AdaBoostClassifier should work without sample_weights in the base estimator\n\n    The random weighted sampling is done internally in the _boost method in\n    AdaBoostClassifier.\n    \"\"\"\n    class DummyEstimator(BaseEstimator):\n\n            pass\n\n            return np.zeros(len(X))\n\n    X, y = datasets.make_classification(n_samples=100, n_features=20, n_informative=2,\n                                        n_redundant=10, n_classes=2, random_state=42)\n    clf = AdaBoostClassifier(base_estimator=DummyEstimator(), random_state=42)\n    clf.fit(X, y)\n    assert clf.score(X, y) >= 0.5  # Dummy estimator should at least perform as good as random guessing\n"], "sample_892": ["def test_adaboost_classifier_sample_weight_zero():\n    # Test that it gives proper results when sample weight is zero.\n    clf = AdaBoostClassifier()\n    sample_weight = np.ones(len(y_class))\n    sample_weight[0] = 0\n    clf.fit(X, y_class, sample_weight=sample_weight)\n    assert clf.predict(T).shape == (len(T),)\n"], "sample_860": ["def test_check_array_force_all_finite_object_unsafe_casting_to_int():\n    # casting a float array containing NaN or inf to int dtype should\n    # raise an error irrespective of the force_all_finite parameter.\n    X = np.array([[1, np.nan], [2, np.inf]], dtype=np.float)\n    with pytest.raises(ValueError, match='Input contains NaN, infinity or a value too large for.*int'):\n        check_array(X, dtype=np.int, force_all_finite=True)\n    with pytest.raises(ValueError, match='Input contains NaN, infinity or a value too large for.*int'):\n        check_array(X, dtype=np.int, force_all_finite=False)\n"], "sample_995": ["def test_Float_from_numpy():\n    from sympy.utilities.pytest import skip\n    from sympy.external import import_module\n    np = import_module('numpy')\n    if not np:\n        skip('numpy not installed. Abort numpy tests.')\n\n    x = np.float64(2.5)\n    y = Float(x)\n    assert y == 2.5\n    assert y._prec == 53\n"], "sample_1205": ["def test_PolyElement_sqf_part():\n    _, x = ring(\"x\", ZZ)\n\n    f = x**5 - x**3 - x**2 + 1\n    p = x**4 + x**3 - x - 1\n\n    assert f.sqf_part() == p\n"], "sample_198": ["def test_expression_wrapper_with_none_output_field(self):\n    expr = ExpressionWrapper(Value(3), output_field=None)\n    self.assertEqual(expr.get_group_by_cols(alias=None), [])\n"], "sample_191": ["def test_watch_dir_with_unresolvable_path_in_glob(self, mocked_modules, notify_mock):\n    path = Path('unresolvable_directory')\n    with mock.patch.object(Path, 'glob', side_effect=FileNotFoundError):\n        self.reloader.watch_dir(path, '**/*.mo')\n    self.assertEqual(list(self.reloader.directory_globs), [])\n"], "sample_629": ["def test_expand_modules():\n    files_or_modules = [\"test_module.py\", \"test_package\"]\n    ignore_list = [\"ignore_module.py\"]\n    ignore_list_re = [re.compile(\".*ignore_pattern.*\")]\n    ignore_list_paths_re = [re.compile(\".*ignore_path_pattern.*\")]\n\n    result, errors = expand_modules(files_or_modules, ignore_list, ignore_list_re, ignore_list_paths_re)\n\n    # Add assertions based on the expected behavior of expand_modules function\n    # For example:\n    assert len(result) > 0\n    assert len(errors) == 0\n"], "sample_537": ["def test_psd_twosided_norm():\n    u = np.array([0, 1, 2, 3, 1, 2, 1])\n    dt = 1.0\n    Su = np.abs(np.fft.fft(u) * dt)**2 / (dt * u.size)\n    P, f = mlab.psd(u, NFFT=u.size, Fs=1/dt, window=mlab.window_none,\n                    detrend=mlab.detrend_none, noverlap=0, pad_to=None,\n                    scale_by_freq=None,\n                    sides='twosided')\n    assert_allclose(P, Su, atol=1e-06)\n"], "sample_607": ["def test_get_backend_valid_string():\n    backend = plugins.get_backend(\"dummy\")\n    assert isinstance(backend, DummyBackendEntrypoint1)\n"], "sample_164": ["    def test_server_formatter_uses_server_time(self):\n        formatter = ServerFormatter()\n        formatter._fmt = '{server_time} - {message}'\n        self.assertTrue(formatter.uses_server_time())\n\n        formatter._fmt = '{message}'\n        self.assertFalse(formatter.uses_server_time())\n"], "sample_106": ["def test_cache_key_varies_by_accept_encoding(self):\n    \"\"\"\n    get_cache_key keys differ by Accept-Encoding header\n    \"\"\"\n    request1 = self.factory.get(self.path, HTTP_ACCEPT_ENCODING='gzip')\n    learn_cache_key(request1, HttpResponse())\n    request2 = self.factory.get(self.path, HTTP_ACCEPT_ENCODING='identity')\n    learn_cache_key(request2, HttpResponse())\n    self.assertNotEqual(get_cache_key(request1), get_cache_key(request2))\n"], "sample_16": ["def test_matmul(self):\n    q1 = np.array([[1, 0], [0, 1]]) * u.m\n    q2 = np.array([[4, 1], [2, 2]]) * u.s\n    out = np.matmul(q1, q2)\n    expected = np.matmul(q1.value, q2.value) * u.m * u.s\n    assert np.all(out == expected)\n"], "sample_897": ["def test_partial_dependence_display_kind_list_length_mismatch(\n    pyplot,\n    clf_diabetes,\n    diabetes,"], "sample_618": ["def test_polyval_invalid_degree_dim():\n    x = xr.DataArray([1, 2, 3], dims=\"x\")\n    coeffs = xr.DataArray([2, 3, 4], dims=\"degree\", coords={\"degree\": [0, 1, 2]})\n    with pytest.raises(ValueError):\n        xr.polyval(x, coeffs, degree_dim=\"invalid_dim\")\n"], "sample_992": ["def test_CustomPrintedObject():\n    obj = CustomPrintedObject()\n    assert pycode(obj) == 'numpy'\n    assert MpmathPrinter().doprint(obj) == 'mpmath'\n"], "sample_541": ["def test_polygon_selector_box_props(ax):\n    # Create a diamond shape\n    verts = [(20, 0), (0, 20), (20, 40), (40, 20)]\n    event_sequence = [\n        *polygon_place_vertex(*verts[0]),\n        *polygon_place_vertex(*verts[1]),\n        *polygon_place_vertex(*verts[2]),\n        *polygon_place_vertex(*verts[3]),\n        *polygon_place_vertex(*verts[0]),\n    ]\n\n    # Create selector with custom box props\n    box_props = dict(edgecolor='red', facecolor='yellow', alpha=0.5)\n    tool = widgets.PolygonSelector(ax, onselect=noop, draw_bounding_box=True,\n                                   box_props=box_props)\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n\n    # Check that the box props were set correctly\n    assert tool._box._selection_artist.get_edgecolor() == 'red'\n    assert tool._box._selection_artist.get_facecolor() == 'yellow'\n    assert tool._box._selection_artist.get_alpha() == 0.5\n"], "sample_330": ["    def test_update_reference_to_existent(self):\n        obj1 = Object.objects.create()\n        obj2 = Object.objects.create()\n        ref = ObjectReference.objects.create(obj=obj1)\n        ref.obj = obj2\n        ref.save()\n        ref_new = ObjectReference.objects.get(id=ref.id)\n        self.assertEqual(ref_new.obj, obj2)\n"], "sample_481": ["def test_join09(self):\n    output = self.engine.render_to_string(\n        \"join09\", {\"a\": [\"alpha\", \"beta & me\"], \"var\": \"<br>\"}\n    )\n    self.assertEqual(output, \"alpha&lt;br&gt;beta &amp; me\")\n"], "sample_499": ["def test_legend_title_fontprop_dict():\n    # test the title_fontproperties kwarg with a dict\n    plt.plot(range(10))\n    leg = plt.legend(title='Aardvark', title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg.get_title().get_fontproperties().get_family() == ['serif']\n    assert leg.get_title().get_fontproperties().get_size() == 22\n"], "sample_858": ["def test_voting_regressor_with_sample_weight():\n    \"\"\"Tests sample_weight parameter of VotingRegressor\"\"\"\n    reg1 = DummyRegressor(strategy='mean')\n    reg2 = DummyRegressor(strategy='median')\n    ereg1 = VotingRegressor([('mean', reg1), ('median', reg2)], weights=[1, 2]).fit(X_r, y_r, sample_weight=np.ones((len(y_r),)))\n    ereg2 = VotingRegressor([('mean', reg1), ('median', reg2)], weights=[1, 2]).fit(X_r, y_r)\n    assert_array_equal(ereg1.predict(X_r), ereg2.predict(X_r))\n\n    sample_weight = np.random.RandomState(123).uniform(size=(len(y_r),))\n    ereg3 = VotingRegressor([('mean', reg1)], weights=[1])\n    ereg3.fit(X_r, y_r, sample_weight)\n    reg1.fit(X_r, y_r, sample_weight)\n    assert_array_equal(ereg3.predict(X_r), reg1.predict(X_r))\n"], "sample_1121": ["def test_divmod_with_symbols():\n    x, y = symbols('x y')\n    assert divmod(x, y) == (x//y, x % y)\n    assert divmod(x, 3) == (x//3, x % 3)\n    assert divmod(3, x) == (3//x, 3 % x)\n"], "sample_406": ["def test_save_with_update_fields(self):\n    a = Article.objects.create(headline=\"original\", pub_date=datetime(2014, 5, 16))\n    current_id = a.id\n    a.headline = \"Updated headline\"\n    a.save(update_fields=[\"headline\"])\n    self.assertEqual(a.id, current_id)\n    self.assertEqual(Article.objects.get(id=current_id).headline, \"Updated headline\")\n"], "sample_1196": ["def test_contains_with_non_set():\n    class NotASet:\n        pass\n\n    x = Symbol('x')\n    raises(TypeError, lambda: Contains(x, NotASet()))\n"], "sample_93": ["def test_aggregate_with_filter(self):\n    books = Book.objects.filter(rating__gt=4).aggregate(avg_price=Avg('price'))\n    self.assertEqual(books['avg_price'], Decimal('75.00'))\n"], "sample_810": ["def test_pipeline_with_fit_params():\n    X = np.array([[1, 2]])\n    y = np.array([0])\n    pipe = Pipeline([('transf', TransfFitParams()), ('clf', Mult())])\n    pipe.fit(X, y, transf__should_get_this=True)\n    assert pipe.named_steps['transf'].fit_params['should_get_this']\n    assert 'should_get_this' not in pipe.named_steps['clf'].fit_params\n"], "sample_433": ["def test_alter_field_to_fk_dependency_other_app_with_initial(self):\n    class Migration(migrations.Migration):\n        initial = True\n        operations = [\n            migrations.CreateModel(\"Author\", name=\"Author\", fields=[(\"id\", models.AutoField(primary_key=True))]),\n            migrations.CreateModel(\"Book\", name=\"Book\", fields=[(\"author\", models.ForeignKey(\"Author\", models.CASCADE))]),\n        ]\n\n    migration = Migration(\"0001_initial\", \"test_app\")\n    changes = self.get_changes([], [migration])\n    self.assertNumberMigrations(changes, \"test_app\", 1)\n    self.assertOperationTypes(changes, \"test_app\", 0, [\"CreateModel\", \"CreateModel\"])\n    self.assertMigrationDependencies(changes, \"test_app\", 0, [])\n"], "sample_83": ["    def setUp(self):\n        self.library = Library()\n"], "sample_43": ["def test_events_fitness_with_x(rseed=0):\n    rng = np.random.RandomState(rseed)\n    t = rng.rand(100)\n    x = rng.randint(1, 10, size=100)\n\n    bins1 = bayesian_blocks(t, x, fitness='events')\n    bins2 = bayesian_blocks(t, fitness='events')\n\n    assert_allclose(bins1, bins2, atol=0.05)\n"], "sample_861": ["def test_grid_search_bad_cv():\n    # Use global X, y\n\n    class BrokenKFold(KFold):\n            return 1\n\n    # create bad cv\n    cv = BrokenKFold(n_splits=3)\n\n    train_size = 100\n    grid = GridSearchCV(Ridge(), {'alpha': [1e-3, 1e-2, 1e-1]}, cv=cv)\n\n    # assert that this raises an error\n    with pytest.raises(ValueError,\n                       match='cv.split and cv.get_n_splits returned '\n                             'inconsistent results. Expected \\\\d+ '\n                             'splits, got \\\\d+'):\n        grid.fit(X[:train_size], y[:train_size])\n"], "sample_711": ["def test_node_from_parent_with_path_and_fspath() -> None:\n    path = Path(\"/path/to/test.py\")\n    fspath = legacy_path(path)\n    node = nodes.Node.from_parent(None, path=path, fspath=fspath)\n    assert node.path == path\n    assert node.fspath == fspath\n"], "sample_658": ["def test_is_mocked_with_broken_object(self):\n    \"\"\"\n    Test that _is_mocked returns True for an object that raises KeyError on attribute access.\n    \"\"\"\n    broken_obj = Broken()\n    assert _is_mocked(broken_obj) is True\n"], "sample_663": ["def test_collect_sub_with_symlinks_and_conftest(testdir):\n    sub = testdir.mkdir(\"sub\")\n    sub.ensure(\"__init__.py\")\n    sub.ensure(\"test_file.py\").write(\"def test_file(): pass\")\n    sub.ensure(\"conftest.py\").write(\"collect_ignore = ['test_file.py']\")\n\n    # Symlink that gets collected.\n    sub.join(\"test_symlink.py\").mksymlinkto(\"test_file.py\")\n\n    result = testdir.runpytest(\"-v\", str(sub))\n    result.stdout.fnmatch_lines([\"*no tests ran in*\"])\n"], "sample_1198": ["def test_parser_mathematica_fullform():\n    parser = MathematicaParser()\n\n    # Test parsing of FullForm expressions\n    assert parser._from_fullform_to_fullformlist(\"List[1, 2, List[3, 4]]\") == [\"List\", \"1\", \"2\", [\"List\", \"3\", \"4\"]]\n    assert parser._from_fullform_to_fullformlist(\"Plus[1, 2, Times[3, 4]]\") == [\"Plus\", \"1\", \"2\", [\"Times\", \"3\", \"4\"]]\n    assert parser._from_fullform_to_fullformlist(\"Power[2, Plus[1, 1]]\") == [\"Power\", \"2\", [\"Plus\", \"1\", \"1\"]]\n\n    # Test conversion of FullForm list to SymPy expression\n    assert parser._from_fullformlist_to_sympy([\"Plus\", \"1\", \"2\", [\"Times\", \"3\", \"4\"]]) == 1 + 2 + 3*4\n    assert parser._from_fullformlist_to_sympy([\"Power\", \"2\", [\"Plus\", \"1\", \"1\"]]) == 2**(1 + 1)\n"], "sample_1017": ["def test_issue_12717_additional():\n    assert Not(S.true).is_Atom == True\n    assert Not(S.false).is_Atom == True\n"], "sample_1015": ["def test_ccode_Float():\n    f32_printer = C99CodePrinter(dict(type_aliases={real: float32}))\n    f64_printer = C99CodePrinter(dict(type_aliases={real: float64}))\n    f80_printer = C99CodePrinter(dict(type_aliases={real: float80}))\n    assert f32_printer.doprint(Float(2.1)) == '2.1F'\n    assert f64_printer.doprint(Float(2.1)) == '2.1000000000000001'\n    assert f80_printer.doprint(Float('2.0')) == '2.0L'\n"], "sample_1149": ["def test_singleton_registry():\n    class TestSingleton(Basic, metaclass=Singleton):\n        pass\n\n    assert not hasattr(S, 'TestSingleton')\n    assert S.TestSingleton is TestSingleton()\n    assert hasattr(S, 'TestSingleton')\n\n    # Test sympify shortcut\n    assert S(Rational(1, 2)) == Rational(1, 2)\n"], "sample_323": ["def test_minimize_rollbacks_with_unapplied_migrations(self):\n    \"\"\"\n    Minimize rollbacks when target has unapplied migrations.\n\n    a: 1 <---- 3 <--\\\n              \\ \\- 2 <--- 4\n               \\       \\\n    b:      \\- 1 <--- 2\n    \"\"\"\n    a1_impl = FakeMigration('a1')\n    a1 = ('a', '1')\n    a2_impl = FakeMigration('a2')\n    a2 = ('a', '2')\n    a3_impl = FakeMigration('a3')\n    a3 = ('a', '3')\n    a4_impl = FakeMigration('a4')\n    a4 = ('a', '4')\n    b1_impl = FakeMigration('b1')\n    b1 = ('b', '1')\n    b2_impl = FakeMigration('b2')\n    b2 = ('b', '2')\n    graph = MigrationGraph()\n    graph.add_node(a1, a1_impl)\n    graph.add_node(a2, a2_impl)\n    graph.add_node(a3, a3_impl)\n    graph.add_node(a4, a4_impl)\n    graph.add_node(b1, b1_impl)\n    graph.add_node(b2, b2_impl)\n    graph.add_dependency(None, a2, a1)\n    graph.add_dependency(None, a3, a1)\n    graph.add_dependency(None, a4, a2)\n    graph.add_dependency(None, a4, a3)\n    graph.add_dependency(None, b2, b1)\n    graph.add_dependency(None, b1, a1)\n    graph.add_dependency(None, b2, a2)\n\n    executor = MigrationExecutor(None)\n    executor.loader = FakeLoader(graph, {\n        a1: a1_impl,\n        b1: b1_impl,\n        a2:"], "sample_766": ["def test_dict_learning_online_lars_code_positivity():\n    n_components = 8\n    err_msg = \"Positive constraint not supported for '{}' coding method.\"\n    err_msg = err_msg.format(\"lars\")\n    with pytest.raises(ValueError, match=err_msg):\n        dict_learning_online(X, n_components=n_components, method=\"lars\",\n                             alpha=1, random_state=0, positive_code=True)\n"], "sample_886": ["def test_set_output_method_with_index():\n    \"\"\"Check that the output DataFrame has the correct index.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X = pd.DataFrame([[1, 0, 3], [0, 0, 1]], index=[\"a\", \"b\"])\n    est = EstimatorWithSetOutputIndex().fit(X)\n    est.set_output(transform=\"pandas\")\n\n    X_trans_pd = est.transform(X)\n    assert isinstance(X_trans_pd, pd.DataFrame)\n    assert_array_equal(X_trans_pd.index, [\"s0\", \"s1\"])\n"], "sample_557": ["def test_subfigures_wspace_hspace_with_gridspec_kw():\n    sub_figs = plt.figure().subfigures(2, 3, hspace=0.5, wspace=1/6., gridspec_kw={'left': 0.1, 'right': 0.9})\n\n    w = 640\n    h = 480\n\n    np.testing.assert_allclose(sub_figs[0, 0].bbox.min, [w * 0.1, h * 0.6])\n    np.testing.assert_allclose(sub_figs[0, 0].bbox.max, [w * 0.3, h])\n\n    np.testing.assert_allclose(sub_figs[0, 1].bbox.min, [w * 0.35, h * 0.6])\n    np.testing.assert_allclose(sub_figs[0, 1].bbox.max, [w * 0.65, h])\n\n    np.testing.assert_allclose(sub_figs[0, 2].bbox.min, [w * 0.7, h * 0.6])\n    np.testing.assert_allclose(sub_figs[0, 2].bbox.max, [w * 0.9, h])\n\n    np.testing.assert_allclose(sub_figs[1, 0].bbox.min, [w * 0.1, 0])\n    np.testing.assert_allclose(sub_figs[1, 0].bbox.max, [w * 0.3, h * 0.4])\n\n    np.testing.assert_allclose(sub_figs[1, 1].bbox.min, [w * 0.35, 0])\n    np.testing.assert_allclose(sub_figs[1, 1].bbox.max, [w * 0.65, h * 0.4])\n\n    np.testing.assert_allclose(sub_figs[1, 2"], "sample_1146": ["def test_latex_MatrixExpr():\n    from sympy import MatrixSymbol, Identity\n    A = MatrixSymbol('A', 3, 3)\n    B = MatrixSymbol('B', 3, 3)\n    expr = A * B + Identity(3)\n    assert latex(expr) == r\"A B + \\mathbf{I}\"\n"], "sample_358": ["    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'],\n            lambda column: column.upper(),\n            col_suffixes=['ASC', 'DESC'],\n            opclasses=['varchar_pattern_ops', 'text_pattern_ops'],\n        )\n"], "sample_69": ["def test_file_deletion(self, mocked_modules, notify_mock):\n    self.reloader.watch_file(self.existing_file)\n    with self.tick_twice():\n        self.existing_file.unlink()\n    self.assertEqual(notify_mock.call_count, 1)\n    self.assertCountEqual(notify_mock.call_args[0], [self.existing_file])\n"], "sample_515": ["def test_colorbar_extend_alpha_horizontal():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]], alpha=0.3, interpolation=\"none\")\n    fig.colorbar(im, extend='both', boundaries=[0.5, 1.5, 2.5], orientation='horizontal')\n"], "sample_510": ["def test_subplot_mosaic_reuse():\n    # create an Axes\n    ax1 = plt.subplot_mosaic({'A': [0, 0]})['A']\n    # check that it is current\n    assert ax1 is plt.gca()\n    # make sure we get it back if we ask again\n    assert ax1 is plt.subplot_mosaic({'A': [0, 0]})['A']\n    # remove it\n    ax1.remove()\n    # create a polar plot\n    ax2 = plt.subplot_mosaic({'A': [0, 0]}, subplot_kw={'projection': 'polar'})['A']\n    assert ax2 is plt.gca()\n    # this should have deleted the first axes\n    assert ax1 not in plt.gcf().axes\n    # assert we get it back if no extra parameters passed\n    assert ax2 is plt.subplot_mosaic({'A': [0, 0]})['A']\n    ax2.remove()\n    # now check explicitly setting the projection to rectilinear\n    # makes a new axes\n    ax3 = plt.subplot_mosaic({'A': [0, 0]}, subplot_kw={'projection': 'rectilinear'})['A']\n    assert ax3 is plt.gca()\n    assert ax3 is not ax2\n    assert ax2 not in plt.gcf().axes\n"], "sample_341": ["def test_formset_with_custom_prefix(self):\n    \"\"\"Formsets can have a custom prefix.\"\"\"\n    ChoiceFormSet = formset_factory(Choice)\n    formset = ChoiceFormSet(prefix='custom_prefix')\n    self.assertEqual(formset.management_form.prefix, 'custom_prefix')\n    self.assertHTMLEqual(\n        str(formset.management_form),\n        '<input type=\"hidden\" name=\"custom_prefix-TOTAL_FORMS\" value=\"1\">'\n        '<input type=\"hidden\" name=\"custom_prefix-INITIAL_FORMS\" value=\"0\">'\n        '<input type=\"hidden\" name=\"custom_prefix-MIN_NUM_FORMS\" value=\"0\">'\n        '<input type=\"hidden\" name=\"custom_prefix-MAX_NUM_FORMS\" value=\"1000\">'\n    )\n"], "sample_223": ["    def test_ticket_24605_with_values(self):\n        \"\"\"\n        Subquery table names should be quoted when using values().\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(\n            Individual.objects.filter(Q(alive=False), Q(related_individual__isnull=True)).values('pk'),\n            [{'pk': i4.pk}]\n        )\n        self.assertSequenceEqual(\n            Individual.objects.exclude(Q(alive=False), Q(related_individual__isnull=True)).values('pk').order_by('pk'),\n            [{'pk': i1.pk}, {'pk': i2.pk}, {'pk': i3.pk}]\n        )\n"], "sample_1162": ["def test_MatMul_kind():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    assert MatMul(A, B).kind is MatrixKind(NumberKind)\n"], "sample_146": ["def test_consistent_language_settings(self):\n    for tag in ['en', 'en-US', 'en-GB']:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [])\n"], "sample_291": ["def test_redirect_with_query_string(self):\n    \"\"\"\n    Test a RedirectView with a query string in the URL.\n    \"\"\"\n    response = RedirectView.as_view(url='/bar/?key=value')(self.rf.get('/foo/'))\n    self.assertEqual(response.status_code, 302)\n    self.assertEqual(response.url, '/bar/?key=value')\n"], "sample_754": ["def test_sparse_pca_with_different_alphas(norm_comp):\n    rng = np.random.RandomState(0)\n    Y, _, _ = generate_toy_data(3, 10, (8, 8), random_state=rng)  # wide array\n    spca_lars_alpha1 = SparsePCA(n_components=3, method='lars', alpha=1,\n                                 random_state=0, normalize_components=norm_comp)\n    spca_lars_alpha1.fit(Y)\n    spca_lars_alpha2 = SparsePCA(n_components=3, method='lars', alpha=2,\n                                 random_state=0, normalize_components=norm_comp)\n    spca_lars_alpha2.fit(Y)\n    assert not np.array_equal(spca_lars_alpha1.components_, spca_lars_alpha2.components_)\n"], "sample_29": ["def test_write_latex_valid_format(self, write, tmp_path):\n    \"\"\"Test to write a LaTeX file with a valid format\"\"\"\n    fp = tmp_path / \"test_write_latex_valid_format.tex\"\n    write(fp, format=\"latex\")\n    assert fp.is_file()\n"], "sample_799": ["def test_score_with_custom_scorer():\n    # Test _score function with a custom scorer\n    X, y = make_classification(n_samples=30, random_state=0)\n    clf = SVC(kernel=\"linear\", random_state=0)\n    train, test = next(ShuffleSplit().split(X))\n    clf.fit(X[train], y[train])\n\n        return np.mean(estimator.predict(X_test) == y_test)\n\n    score = _score(clf, X[test], y[test], custom_scorer)\n    assert isinstance(score, float)\n    assert 0 <= score <= 1\n"], "sample_114": ["def test_add_blank_textfield_and_charfield_with_default(self):\n    \"\"\"\n    #23405 - Adding a NOT NULL and blank `CharField` or `TextField`\n    with default should not prompt for a default.\n    \"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_with_biography_blank_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0)\n"], "sample_804": ["def test_one_hot_encoder_drop_first():\n    enc = OneHotEncoder(drop='first')\n    X = [['abc', 12, 2, 55],\n         ['def', 12, 1, 55],\n         ['def', 12, 3, 56]]\n    trans = enc.fit_transform(X).toarray()\n    exp = [[0, 1, 1],\n           [1, 0, 1],\n           [1, 0, 0]]\n    assert_array_equal(trans, exp)\n    dropped_cats = [cat[feature]\n                    for cat, feature in zip(enc.categories_,\n                                            enc.drop_idx_)]\n    assert_array_equal(dropped_cats, ['abc', 12, 2, 55])\n    assert_array_equal(np.array(X, dtype=object),\n                       enc.inverse_transform(trans))\n"], "sample_509": ["def test_date_ticker_factory_numticks():\n    span = 0.02\n    numticks = 3\n    locator, _ = mdates.date_ticker_factory(span, numticks=numticks)\n    assert isinstance(locator, mdates.MinuteLocator)\n    assert locator.interval == 2\n"], "sample_872": ["def test_top_k_accuracy_score_multiclass_without_labels():\n    \"\"\"Test when y_score is multiclass and labels is None.\"\"\"\n    y_true = np.array([0, 1, 2, 3])\n    y_score = np.array(\n        [\n            [0.4, 0.3, 0.2, 0.1],\n            [0.1, 0.3, 0.4, 0.2],\n            [0.4, 0.1, 0.2, 0.3],\n            [0.3, 0.2, 0.4, 0.1],\n        ]\n    )\n\n    score = top_k_accuracy_score(y_true, y_score, k=2)\n    assert score == pytest.approx(0.75)\n"], "sample_1079": ["def test_project():\n    a = Point(1, 2)\n    b = Point(2, 5)\n    z = a.origin\n    p = Point.project(a, b)\n    assert Line(p, a).is_perpendicular(Line(p, b))\n    assert Point.is_collinear(z, p, b)\n"], "sample_1194": ["def test_julia_matrix_slicing():\n    A = MatrixSymbol('A', 3, 3)\n    assert julia_code(A[0:2, 0:2]) == \"A[1:2,1:2]\"\n    assert julia_code(A[1:3, 1:3]) == \"A[2:end,2:end]\"\n    assert julia_code(A[0:3:2, 0:3:2]) == \"A[1:2:end,1:2:end]\"\n"], "sample_176": ["def test_mti_inheritance_model_addition(self):\n    Animal = ModelState('app', 'Animal', [\n        (\"id\", models.AutoField(primary_key=True)),\n    ])\n    changes = self.get_changes([Animal], [Animal, ModelState('app', 'Dog', [], bases=('app.Animal',))])\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='Dog')\n"], "sample_805": ["def test_regression_metrics_with_sample_weight():\n    y_true = np.array([1, 2, 3, 4, 5])\n    y_pred = np.array([1.2, 2.1, 3.0, 3.9, 5.1])\n    sample_weight = np.array([0.1, 0.2, 0.3, 0.2, 0.2])\n\n    assert_almost_equal(mean_squared_error(y_true, y_pred, sample_weight=sample_weight), 0.028, decimal=2)\n    assert_almost_equal(mean_absolute_error(y_true, y_pred, sample_weight=sample_weight), 0.16, decimal=2)\n    assert_almost_equal(r2_score(y_true, y_pred, sample_weight=sample_weight), 0.991, decimal=2)\n    assert_almost_equal(explained_variance_score(y_true, y_pred, sample_weight=sample_weight), 0.991, decimal=2)\n"], "sample_885": ["def test_real_not_int_interval():\n    \"\"\"Check that the 'real_not_int' type in Interval works as expected.\"\"\"\n    constraint = Interval(\"real_not_int\", 0, 1, closed=\"both\")\n    assert constraint.is_satisfied_by(0.5)\n    assert not constraint.is_satisfied_by(1)\n    assert not constraint.is_satisfied_by(\"1.0\")\n"], "sample_168": ["    def test_include_stale_apps_true(self):\n        \"\"\"\n        --include-stale-apps option deletes stale content types even if the\n        app is not in INSTALLED_APPS.\n        \"\"\"\n        with mock.patch('builtins.input', return_value='yes'):\n            with captured_stdout() as stdout:\n                call_command('remove_stale_contenttypes', include_stale_apps=True, verbosity=2)\n        self.assertIn(\"Deleting stale content type\", stdout.getvalue())\n        self.assertEqual(ContentType.objects.count(), self.before_count)\n"], "sample_348": ["    def test_actions_unique_across_classes(self):\n        @admin.action\n            pass\n\n        class BandAdmin(ModelAdmin):\n            actions = (action,)\n\n        class SongAdmin(ModelAdmin):\n            actions = (action,)\n\n        self.assertIsInvalid(\n            SongAdmin, Song,\n            \"__name__ attributes of actions defined in SongAdmin must be \"\n            \"unique. Name 'action' is not unique.\",\n            id='admin.E130',\n        )\n"], "sample_377": ["    def test_request_cookies_filtering(self):\n        self.rf.cookies[\"SECRET_COOKIE\"] = \"super_secret\"\n        request = self.rf.get(\"/\")\n        reporter_filter = SafeExceptionReporterFilter()\n        self.assertEqual(\n            reporter_filter.get_safe_cookies(request)[\"SECRET_COOKIE\"],\n            reporter_filter.cleansed_substitute,\n        )\n"], "sample_1043": ["def test_user_functions():\n        return x**2 + 2*x + 1\n\n    settings = {'user_functions': {'custom_func': 'CustomFunction'}}\n    assert mcode(custom_func(x), **settings) == \"CustomFunction[x]\"\n"], "sample_1123": ["def test_CondSet_union():\n    input_conditionset1 = ConditionSet(x, x > 0, Interval(1, 4, False, False))\n    input_conditionset2 = ConditionSet(x, x < 0, Interval(-4, -1, False, False))\n    output_conditionset = Interval(-4, 4, False, False)\n    assert Union(input_conditionset1, input_conditionset2) == output_conditionset\n"], "sample_1107": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((0, 0, 0))) == [(0, 0, 0)]\n    assert list(permute_signs((1, -1, 1))) == [(1, -1, 1), (-1, -1, 1), (1, 1, 1), (-1, 1, 1), (1, -1, -1), (-1, -1, -1), (1, 1, -1), (-1, 1, -1)]\n"], "sample_129": ["def test_floatformat03(self):\n    output = self.engine.render_to_string('floatformat03', {\"a\": \"13.1031\", \"b\": mark_safe(\"11.0000\")})\n    self.assertEqual(output, \"13.103 11.000\")\n"], "sample_189": ["def test_cache_versioning_delete_many(self):\n    cache.set('answer1', 37, version=1)\n    cache.set('answer1', 42, version=2)\n    cache.set('answer2', 37, version=1)\n    cache.set('answer2', 42, version=2)\n    self.assertIs(cache.delete_many(['answer1', 'answer2']), True)\n    self.assertIsNone(cache.get('answer1', version=1))\n    self.assertIsNone(cache.get('answer1', version=2))\n    self.assertIsNone(cache.get('answer2', version=1))\n    self.assertIsNone(cache.get('answer2', version=2))\n\n    cache.set('answer3', 37, version=1)\n    cache.set('answer3', 42, version=2)\n    cache.set('answer4', 37, version=1)\n    cache.set('answer4', 42, version=2)\n    self.assertIs(cache.delete_many(['answer3', 'answer4'], version=2), True)\n    self.assertEqual(cache.get('answer3', version=1), 37)\n    self.assertIsNone(cache.get('answer3', version=2))\n    self.assertEqual(cache.get('answer4', version=1), 37)\n    self.assertIsNone(cache.get('answer4', version=2))\n\n    cache.set('answer5', 37, version=1)\n    cache.set('answer5', 42, version=2)\n    cache.set('answer6', 37, version=1)\n    cache.set('answer6', 42, version=2)\n    self.assertIs(caches['v2'].delete_many(['answer5', 'answer6']), True)\n    self.assertEqual(cache.get('answer5', version=1), 37)\n    self.assertIsNone(cache.get('answer5', version=2))\n    self.assertEqual(cache.get('answer6', version=1),"], "sample_136": ["def test_wsgirequest_headers_getitem(self):\n    request = WSGIRequest(self.ENVIRON)\n    self.assertEqual(request.headers['User-Agent'], 'python-requests/1.2.0')\n    self.assertEqual(request.headers['user-agent'], 'python-requests/1.2.0')\n    self.assertEqual(request.headers['user_agent'], 'python-requests/1.2.0')\n    self.assertEqual(request.headers['Content-Type'], 'text/html')\n    self.assertEqual(request.headers['Content-Length'], '100')\n"], "sample_447": ["def test_alias_with_m2m(self):\n    qs = Book.objects.alias(\n        author_age=F(\"authors__age\"),\n    ).filter(pk=self.b1.pk).order_by(\"author_age\")\n    self.assertIs(hasattr(qs.first(), \"author_age\"), False)\n    self.assertEqual(qs[0].authors.all()[0].age, 34)\n    self.assertEqual(qs[1].authors.all()[0].age, 35)\n"], "sample_80": ["def test_related_isnull(self):\n    query = Query(Author)\n    where = query.build_where(Q(item__isnull=True))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, RelatedIsNull)\n    self.assertEqual(lookup.lhs.field, Author._meta.get_field('item'))\n"], "sample_257": ["def test_key_transform_exact(self):\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__d__1__f__exact='g'),\n        [self.objs[4]],\n    )\n"], "sample_1030": ["def test_closest_points():\n    points = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4)]\n    assert closest_points(*points) == {(Point2D(1, 1), Point2D(1, 2))}\n"], "sample_895": ["def test_column_transformer_with_callable_specifier_pandas():\n    # assert that function gets the full dataframe\n    pd = pytest.importorskip(\"pandas\")\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    X_res_first = np.array([[0, 1, 2]]).T\n\n    X_df = pd.DataFrame(X_array, columns=[\"first\", \"second\"])\n\n        assert_array_equal(X.columns, X_df.columns)\n        assert_array_equal(X.values, X_df.values)\n        return [\"first\"]\n\n    ct = ColumnTransformer([(\"trans\", Trans(), func)], remainder=\"drop\")\n    assert_array_equal(ct.fit_transform(X_df), X_res_first)\n    assert_array_equal(ct.fit(X_df).transform(X_df), X_res_first)\n    assert callable(ct.transformers[0][2])\n    assert ct.transformers_[0][2] == [\"first\"]\n"], "sample_199": ["def test_annotation_with_subquery(self):\n    subquery = Book.objects.filter(publisher=OuterRef('pk')).values('publisher').annotate(book_count=Count('id')).values('book_count')\n    publishers = Publisher.objects.annotate(num_books=Subquery(subquery))\n    for publisher in publishers:\n        self.assertEqual(publisher.num_books, publisher.book_set.count())\n"], "sample_292": ["def test_https_good_referer_matches_cookie_domain_with_port_in_host(self):\n    \"\"\"\n    A POST HTTPS request with a good referer should be accepted from a\n    subdomain that's allowed by CSRF_COOKIE_DOMAIN and a port in the host.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_HOST'] = 'www.example.com:8000'\n    req.META['HTTP_REFERER'] = 'https://foo.example.com:8000/'\n    req.META['SERVER_PORT'] = '443'\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.process_request(req)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n"], "sample_460": ["def test_missing_slash_append_slash_true_non_staff_user_without_final_catch_all_view(self):\n    user = User.objects.create_user(\n        username=\"user\",\n        password=\"secret\",\n        email=\"user@example.com\",\n        is_staff=False,\n    )\n    self.client.force_login(user)\n    known_url = reverse(\"admin10:admin_views_article_changelist\")\n    response = self.client.get(known_url[:-1])\n    self.assertRedirects(\n        response,\n        \"/test_admin/admin10/login/?next=/test_admin/admin10/admin_views/article\",\n    )\n"], "sample_769": ["def test_balanced_accuracy_score_multiclass():\n    # Test balanced accuracy score for multiclass classification task\n    y_true, y_pred, _ = make_prediction(binary=False)\n\n    # compute score with default labels introspection\n    score = balanced_accuracy_score(y_true, y_pred)\n    assert_almost_equal(score, 0.51, 2)\n\n    # compute score with explicit label ordering\n    score = balanced_accuracy_score(y_true, y_pred, labels=[2, 1, 0])\n    assert_almost_equal(score, 0.51, 2)\n"], "sample_36": ["def test_biweight_midcorrelation_symmetric():\n    \"\"\"\n    Test that biweight_midcorrelation is symmetric.\n    \"\"\"\n\n    rng = np.random.RandomState(1)\n    x = rng.normal(0, 2, size=500)\n    y = rng.normal(0, 2, size=500)\n    assert_allclose(biweight_midcorrelation(x, y), biweight_midcorrelation(y, x))\n"], "sample_768": ["def test_build_repr_with_default_values():\n    splitter = MockSplitter(a=1)\n    assert_equal(_build_repr(splitter), \"MockSplitter(a=1, b=0, c=None)\")\n"], "sample_235": ["def test_hook_in_hook_with_rollback(self):\n        with transaction.atomic():\n            if add_hook:\n                transaction.on_commit(lambda: on_commit(i + 10, False))\n            t = Thing.objects.create(num=i)\n            self.notify(t.num)\n            if i == 2:\n                raise ForcedError()\n\n    try:\n        with transaction.atomic():\n            transaction.on_commit(lambda: on_commit(1, True))\n            transaction.on_commit(lambda: on_commit(2, True))\n    except ForcedError:\n        pass\n\n    self.assertDone([1])\n"], "sample_646": ["def test_unittest_skip_class_issue148(pytester: Pytester) -> None:\n    testpath = pytester.makepyfile(\n        \"\"\"\n        import unittest\n\n        @unittest.skip(\"hello\")\n        class MyTestCase(unittest.TestCase):\n                pass\n    \"\"\"\n    )\n    reprec = pytester.inline_run(testpath)\n    reprec.assertoutcome(skipped=1)\n"], "sample_33": ["def test_dtype_bytes_or_chars():\n    assert misc.dtype_bytes_or_chars(np.dtype('int32')) == 32\n    assert misc.dtype_bytes_or_chars(np.dtype('float64')) == 64\n    assert misc.dtype_bytes_or_chars(np.dtype('U5')) == 5\n    assert misc.dtype_bytes_or_chars(np.dtype('S10')) == 10\n"], "sample_87": ["def test_nonexistent_glob(self, mocked_modules, notify_mock):\n    self.reloader.watch_dir(self.tempdir, 'nonexistent_pattern.py')\n    with self.tick_twice():\n        self.increment_mtime(self.existing_file)\n    self.assertEqual(notify_mock.call_count, 0)\n"], "sample_931": ["def test_pyfunction_signature_with_module_option(app):\n    text = \".. py:function:: hello(name: str) -> str\\n   :module: mymodule\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_addname, \"mymodule.\"],\n                                                    [desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_punctuation, \":\"],\n                                                      \" \",\n                                                      [nodes.inline, pending_xref, \"str\"])])\n"], "sample_1167": ["def test_latex_MatrixExpr():\n    from sympy import MatrixSymbol, Identity\n    A = MatrixSymbol('A', 3, 3)\n    B = MatrixSymbol('B', 3, 3)\n    expr = A * B + Identity(3)\n    assert latex(expr) == r\"A B + I\"\n"], "sample_44": ["def test_neg_pos_methods(self):\n    for mag in self.mags:\n        neg_mag = mag.__neg__()\n        assert np.all(neg_mag.value == -mag.value)\n        assert neg_mag.unit.physical_unit == mag.unit.physical_unit**-1\n        pos_mag = mag.__pos__()\n        assert np.all(pos_mag.value == mag.value)\n        assert pos_mag.unit == mag.unit\n"], "sample_866": ["def test_affinity_propagation_sparse_input():\n    # Test AffinityPropagation with sparse input\n    X_sparse = csr_matrix(X)\n    af = AffinityPropagation(affinity=\"euclidean\")\n    labels_sparse = af.fit_predict(X_sparse)\n    labels_dense = af.fit_predict(X)\n    assert_array_equal(labels_sparse, labels_dense)\n"], "sample_342": ["def test_custom_paginator(self):\n    \"\"\"\n    The ModelAdmin's paginator is used for autocomplete views.\n    \"\"\"\n    class CustomPaginatorQuestionAdmin(QuestionAdmin):\n            return Paginator(queryset, per_page=per_page * 2, orphans=orphans, allow_empty_first_page=allow_empty_first_page)\n\n    Question.objects.bulk_create(Question(question=str(i)) for i in range(PAGINATOR_SIZE + 10))\n    # The first page of results.\n    request = self.factory.get(self.url, {'term': '', **self.opts})\n    request.user = self.superuser\n    with model_admin(Question, CustomPaginatorQuestionAdmin):\n        response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    self.assertEqual(response.status_code, 200)\n    data = json.loads(response.content.decode('utf-8'))\n    self.assertEqual(data, {\n        'results': [{'id': str(q.pk), 'text': q.question} for q in Question.objects.all()[:PAGINATOR_SIZE * 2]],\n        'pagination': {'more': True},\n    })\n    # The second page of results.\n    request = self.factory.get(self.url, {'term': '', 'page': '2', **self.opts})\n    request.user = self.superuser\n    with model_admin(Question, CustomPaginatorQuestionAdmin):\n        response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    self.assertEqual(response.status_code, 200)\n    data = json.loads(response.content.decode('utf-8'))\n    self.assertEqual(data, {\n        'results': [{'id': str(q.pk), 'text': q.question} for q in Question.objects.all()[PAGINATOR"], "sample_61": ["    def test_ascii_validator(self):\n        valid_usernames = ['joe', 'Rene', '12345', 'joe.smith', 'joe+smith', 'joe-smith', 'joe_smith', 'joe@smith']\n        invalid_usernames = ['joe@example.com', 'Ren\u00e9', '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f']\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n"], "sample_1179": ["def test_MatrixPow():\n    A = MatrixSymbol(\"A\", 2, 2)\n    assert str(A**2) == \"A**2\"\n    assert str(A**-1) == \"A**(-1)\"\n"], "sample_201": ["def test_legacy_hash(self):\n    \"\"\"\n    Test the legacy hash function used for backward compatibility.\n    \"\"\"\n    storage = self.storage_class(self.get_request())\n    value = 'test_value'\n    hash_value = storage._legacy_hash(value)\n    self.assertEqual(len(hash_value), 40)  # SHA1 hash length is 40 characters\n    self.assertNotEqual(hash_value, value)  # Hash should not be equal to the original value\n"], "sample_429": ["def test_prohibit_null_characters_validator_equality(self):\n    self.assertEqual(\n        ProhibitNullCharactersValidator(),\n        ProhibitNullCharactersValidator(),\n    )\n    self.assertEqual(\n        ProhibitNullCharactersValidator(message=\"Custom message\"),\n        ProhibitNullCharactersValidator(message=\"Custom message\"),\n    )\n    self.assertEqual(\n        ProhibitNullCharactersValidator(code=\"custom_code\"),\n        ProhibitNullCharactersValidator(code=\"custom_code\"),\n    )\n    self.assertNotEqual(\n        ProhibitNullCharactersValidator(),\n        ProhibitNullCharactersValidator(message=\"Custom message\"),\n    )\n    self.assertNotEqual(\n        ProhibitNullCharactersValidator(),\n        ProhibitNullCharactersValidator(code=\"custom_code\"),\n    )\n    self.assertNotEqual(\n        ProhibitNullCharactersValidator(message=\"Custom message\"),\n        ProhibitNullCharactersValidator(code=\"custom_code\"),\n    )\n"], "sample_540": ["def test_animation_pause_resume(anim):\n    # Test the pause and resume methods of the animation\n    anim = animation.FuncAnimation(**anim)\n    anim.pause()\n    assert not anim.event_source.is_running()\n    anim.resume()\n    assert anim.event_source.is_running()\n"], "sample_395": ["def test_reset_loaders_with_locmem_loader(self, mock_reset):\n    autoreload.reset_loaders()\n    self.assertEqual(mock_reset.call_count, 3)\n"], "sample_1191": ["def test_hermite_normal():\n\n    m = DM([[12, 6, 4], [3, 9, 6], [2, 16, 14]], ZZ)\n    hnf = DM([[10, 0, 2], [0, 15, 3], [0, 0, 2]], ZZ)\n    assert hermite_normal_form(m).to_dense() == hnf\n\n    m = DM([[12, 6, 4], [3, 9, 6], [2, 16, 14]], ZZ)\n    D = 30\n    hnf_mod_D = DM([[10, 0, 2], [0, 15, 3], [0, 0, 0]], ZZ)\n    assert _hermite_normal_form_modulo_D(m, D).to_dense() == hnf_mod_D\n\n    m = DM([[12, 6, 4], [3, 9, 6], [2, 16, 14]], QQ)\n    raises(DMDomainError, lambda: hermite_normal_form(m))\n\n    m = DM([[12, 6, 4], [3, 9, 6]], ZZ)\n    D = 30\n    raises(DMShapeError, lambda: _hermite_normal_form_modulo_D(m, D))\n"], "sample_877": ["def test_isotonic_regression_with_duplicate_y():\n    # Test from #15012\n    # Check that IsotonicRegression handles duplicate y values correctly\n    X = np.array([0, 1, 2, 3, 4])\n    y = np.array([0, 0, 1, 1, 2])\n    y_true = np.array([0, 0.5, 1, 1.5, 2])\n\n    ir = IsotonicRegression()\n    ir.fit(X, y)\n    assert_array_almost_equal(ir.transform(X), y_true)\n    assert_array_almost_equal(ir.fit_transform(X, y), y_true)\n"], "sample_920": ["def test_attributes_with_backslash(self):\n    docstring = \"\"\"\\"], "sample_299": ["    def test_relative_path(self):\n        with self.settings(CACHES={\n            'default': {\n                'BACKEND': 'django.core.cache.backends.filebased.FileBasedCache',\n                'LOCATION': 'relative/path/cache',\n            },\n        }):\n            self.assertEqual(check_file_based_cache_is_absolute(None), [\n                Warning(\n                    \"Your 'default' cache LOCATION path is relative. Use an \"\n                    \"absolute path instead.\",\n                    id='caches.W003',\n                ),\n            ])\n"], "sample_73": ["def test_template_tag_non_ascii_content(self):\n    relpath = self.hashed_file_path(\"test/nonascii.css\")\n    self.assertEqual(relpath, \"test/nonascii.deploy12345.css\")\n    with storage.staticfiles_storage.open(relpath) as relfile:\n        content = relfile.read()\n        self.assertIn(b\"url('nonascii.eot?#iefix')\", content)\n        self.assertIn(b\"url('nonascii.svg#webfontIyfZbseF')\", content)\n        self.assertIn(b\"url('nonascii.svg#path/to/../../nonascii.svg')\", content)\n        self.assertIn(b\"url('data:font/woff;charset=utf-8;base64,d09GRgABAAAAADJoAA0AAAAAR2QAAQAAAAAAAAAAAAA')\", content)\n        self.assertIn(b\"url('#default#VML')\", content)\n    self.assertPostCondition()\n"], "sample_808": ["def test_iforest_contamination_auto():\n    \"\"\"Test Isolation Forest with contamination='auto'\"\"\"\n\n    # Generate train/test data\n    rng = check_random_state(2)\n    X = 0.3 * rng.randn(120, 2)\n    X_train = np.r_[X + 2, X - 2]\n    X_train = X[:100]\n\n    # Generate some abnormal novel observations\n    X_outliers = rng.uniform(low=-4, high=4, size=(20, 2))\n    X_test = np.r_[X[100:], X_outliers]\n    y_test = np.array([0] * 20 + [1] * 20)\n\n    # fit the model with contamination='auto'\n    clf = IsolationForest(max_samples=100, random_state=rng, contamination='auto').fit(X_train)\n\n    # predict scores (the lower, the more normal)\n    y_pred = - clf.decision_function(X_test)\n\n    # check that the number of outliers detected is close to the expected contamination rate\n    assert_allclose(np.mean(y_pred > np.percentile(y_pred, 100 * clf._contamination)), clf._contamination, atol=0.05)\n"], "sample_548": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cb = fig.colorbar(im)\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n    cb.set_alpha(None)\n    assert cb.alpha is None\n"], "sample_950": ["def test_pyfunction_with_default_value(app):\n    text = \".. py:function:: hello(name='World') -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, ([desc_parameter, ([desc_sig_name, \"name\"],\n                                                        [desc_sig_operator, \"=\"],\n                                                        [nodes.inline, \"'World'\"])])])\n"], "sample_1094": ["def test_is_comparable():\n    assert (I*exp(I*pi/2)).is_comparable\n    assert not (I*exp(I*pi*2)).is_comparable\n    e = 2**pi*(1 + 2**pi)\n    dif = e - e.expand()\n    assert not dif.is_comparable\n    assert dif.n(2)._prec == 1\n"], "sample_822": ["def test_check_preserve_type_sparse():\n    # Ensures that type float32 is preserved for sparse matrices.\n    XA = csr_matrix(np.resize(np.arange(40), (5, 8)).astype(np.float32))\n    XB = csr_matrix(np.resize(np.arange(40), (5, 8)).astype(np.float32))\n\n    XA_checked, XB_checked = check_pairwise_arrays(XA, None)\n    assert_equal(XA_checked.dtype, np.float32)\n\n    # both float32\n    XA_checked, XB_checked = check_pairwise_arrays(XA, XB)\n    assert_equal(XA_checked.dtype, np.float32)\n    assert_equal(XB_checked.dtype, np.float32)\n\n    # mismatched A\n    XA_checked, XB_checked = check_pairwise_arrays(XA.astype(np.float), XB)\n    assert_equal(XA_checked.dtype, np.float)\n    assert_equal(XB_checked.dtype, np.float)\n\n    # mismatched B\n    XA_checked, XB_checked = check_pairwise_arrays(XA, XB.astype(np.float))\n    assert_equal(XA_checked.dtype, np.float)\n    assert_equal(XB_checked.dtype, np.float)\n"], "sample_664": ["def test_funcargnames_is_deprecated(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            pass\n\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*The `funcargnames` attribute was an alias for `fixturenames`, since pytest 2.3 - use the newer attribute instead.*\",\n        ]\n    )\n"], "sample_1086": ["def test_issue_15716_as_terms():\n    e = Integral(log(x), (x, 1, 2))\n    assert e.as_terms() == ([(e, ((1.0, 0.0), (1,), ()))], [e])\n"], "sample_624": ["def test_format_timedelta_invalid_pandas_format() -> None:\n    expected = \"10 days 12:00:00 00\"\n    with pytest.raises(ValueError):\n        formatting.format_timedelta(expected)\n"], "sample_214": ["def test_key_transform_exact(self):\n    self.assertIs(NullableJSONModel.objects.filter(value__foo=KeyTransform('foo', 'value')).exists(), True)\n    self.assertIs(NullableJSONModel.objects.filter(value__foo=KeyTransform('bar', 'value')).exists(), False)\n"], "sample_1033": ["def test_Mul_is_zero():\n    x, y = symbols('x y', zero=True)\n    assert (x * y).is_zero\n\n    z = symbols('z', zero=False)\n    assert (x * z).is_zero\n    assert (z * x).is_zero\n"], "sample_1093": ["def test_NumPyPrinter_print_log2():\n    n = NumPyPrinter()\n\n    assert n._print_log2(x) == 'numpy.log(x)/numpy.log(2)'\n"], "sample_728": ["def test_make_classification_flip_y():\n    \"\"\"Test the flipping of labels in make_classification\"\"\"\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=5,\n                               n_redundant=1, n_repeated=1, n_classes=3,\n                               n_clusters_per_class=1, hypercube=False,\n                               shift=None, scale=None, flip_y=0.5,\n                               random_state=0)\n\n    assert_equal(X.shape, (100, 20), \"X shape mismatch\")\n    assert_equal(y.shape, (100,), \"y shape mismatch\")\n    assert_equal(np.unique(y).shape, (3,), \"Unexpected number of classes\")\n    assert_true(np.sum(y != np.arange(3).repeat(33)) > 20,\n                \"Not enough labels flipped\")\n"], "sample_702": ["def test_pytester_makefile_ext_empty_string_raises_value_error(pytester: Pytester) -> None:\n    with pytest.raises(ValueError, match=\"pytester.makefile expects a file extension\"):\n        pytester.makefile(\"\", \"\")\n"], "sample_1020": ["def test_Sum():\n    assert mcode(Sum(x**k, (k, 0, n))) == \"Hold[Sum[x^k, {k, 0, n}]]\"\n    assert mcode(Sum(x**k, (k, 0, n), (n, 1, m))) == \"Hold[Sum[x^k, {k, 0, n}, {n, 1, m}]]\"\n"], "sample_237": ["def test_username_unique(self):\n    \"\"\"A unique USERNAME_FIELD should not raise any errors.\"\"\"\n    class CustomUserWithUniqueUsername(AbstractBaseUser):\n        username = models.CharField(max_length=30, unique=True)\n        USERNAME_FIELD = 'username'\n\n    errors = checks.run_checks(app_configs=self.apps.get_app_configs())\n    self.assertEqual(errors, [])\n"], "sample_978": ["def test_basic_degree_0_with_floats():\n    d = 0\n    knots = [0.0, 1.0, 2.0, 3.0, 4.0]\n    splines = bspline_basis_set(d, knots, x)\n    for i in range(len(splines)):\n        assert splines[i] == Piecewise((1, Interval(i, i + 1).contains(x)),\n                                       (0, True))\n"], "sample_66": ["def test_wsgirequest_headers_getitem(self):\n    request = WSGIRequest(self.ENVIRON)\n    self.assertEqual(request.headers['User-Agent'], 'python-requests/1.2.0')\n    self.assertEqual(request.headers['user-agent'], 'python-requests/1.2.0')\n    self.assertEqual(request.headers['user_agent'], 'python-requests/1.2.0')\n    self.assertEqual(request.headers['Content-Type'], 'text/html')\n    self.assertEqual(request.headers['Content-Length'], '100')\n"], "sample_24": ["def test_nan_to_num(self):\n    self.check(np.nan_to_num)\n    ma = Masked([np.nan, 1.0], mask=[True, False])\n    o = np.nan_to_num(ma, copy=False)\n    assert_masked_equal(o, Masked([0.0, 1.0], mask=[True, False]))\n    assert ma is o\n"], "sample_218": ["def test_trunc_func_with_timezone_and_output_field(self):\n    start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n    end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n    self.create_model(end_datetime, start_datetime)\n\n    melb = pytz.timezone('Australia/Melbourne')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=output_field, tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(melb), kind, melb)),\n                (end_datetime, truncate_to(end_datetime.astimezone(melb), kind, melb))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_datetime_kind('year', DateTimeField())\n    test_datetime_kind('quarter', DateTimeField())\n    test_datetime_kind('month', DateTimeField())\n    test_datetime_kind('week', DateTimeField())\n    test_datetime_kind('day', DateTimeField())\n    test_datetime_kind('hour', DateTimeField())\n    test_datetime_kind('minute', DateTimeField())\n    test_datetime_kind('second', DateTimeField())\n    test_datetime_kind('day', DateField())\n    test_datetime_kind('hour', TimeField())\n"], "sample_813": ["def test_bayesian_ridge_intercept():\n    # Test BayesianRidge with and without intercept\n    X = np.array([[1], [2], [6], [8], [10]])\n    Y = np.array([1, 2, 6, 8, 10])\n    clf_with_intercept = BayesianRidge(fit_intercept=True)\n    clf_without_intercept = BayesianRidge(fit_intercept=False)\n    clf_with_intercept.fit(X, Y)\n    clf_without_intercept.fit(X - np.mean(X), Y - np.mean(Y))\n\n    # Check that the coefficients and intercepts are close\n    assert_array_almost_equal(clf_with_intercept.coef_, clf_without_intercept.coef_)\n    assert_almost_equal(clf_with_intercept.intercept_, np.mean(Y) - np.mean(X) * clf_without_intercept.coef_)\n"], "sample_736": ["def test_saga_vs_liblinear_dual():\n    iris = load_iris()\n    X, y = iris.data, iris.target\n    X = np.concatenate([X] * 10)\n    y = np.concatenate([y] * 10)\n\n    X_bin = X[y <= 1]\n    y_bin = y[y <= 1] * 2 - 1\n\n    X_sparse, y_sparse = make_classification(n_samples=50, n_features=20,\n                                             random_state=0)\n    X_sparse = sparse.csr_matrix(X_sparse)\n\n    for (X, y) in ((X_bin, y_bin), (X_sparse, y_sparse)):\n        for dual in [True, False]:\n            n_samples = X.shape[0]\n            # alpha=1e-3 is time consuming\n            for alpha in np.logspace(-1, 1, 3):\n                saga = LogisticRegression(\n                    C=1. / (n_samples * alpha),\n                    solver='saga',\n                    multi_class='ovr',\n                    max_iter=200,\n                    fit_intercept=False,\n                    penalty='l2',\n                    dual=dual,\n                    random_state=0,\n                    tol=1e-24)\n\n                liblinear = LogisticRegression(\n                    C=1. / (n_samples * alpha),\n                    solver='liblinear',\n                    multi_class='ovr',\n                    max_iter=200,\n                    fit_intercept=False,\n                    penalty='l2',\n                    dual=dual,\n                    random_state=0,\n                    tol=1e-24)\n\n                saga.fit(X, y)\n                liblinear.fit(X, y)\n                # Convergence for alpha=1e-3 is very slow\n                assert_array_almost"], "sample_110": ["def test_pickle_subquery_queryset_still_usable(self):\n    group = Group.objects.create(name='group')\n    Event.objects.create(title='event', group=group)\n    groups = Group.objects.annotate(\n        event_count=models.Subquery(\n            Event.objects.filter(group_id=models.OuterRef('id')).values('title').annotate(count=models.Count('*')).values('count'),\n        ),\n    )\n    groups2 = pickle.loads(pickle.dumps(groups))\n    self.assertSequenceEqual(groups2.filter(event_count=1), [group])\n"], "sample_166": ["def test_get_random_string_length(self):\n    length = 22\n    random_string = get_random_string(length)\n    self.assertEqual(len(random_string), length)\n"], "sample_209": ["def test_model_with_evaluate_method_and_lookup(self):\n    \"\"\"\n    You can filter by objects that have an 'evaluate' attr using a lookup\n    \"\"\"\n    dept = Department.objects.create(pk=1, name='abc')\n    dept.evaluate = 'abc'\n    Worker.objects.filter(department__evaluate='abc')\n"], "sample_277": ["def test_combine_and_or(self):\n    q1 = Q(x=1)\n    q2 = Q(y=2)\n    q3 = Q(z=3)\n    combined_q = (q1 & q2) | q3\n    path, args, kwargs = combined_q.deconstruct()\n    self.assertEqual(args, ((('x', 1), ('y', 2)), ('z', 3)))\n    self.assertEqual(kwargs, {'_connector': 'OR'})\n"], "sample_41": ["def test_unit_summary_physical_type():\n    \"\"\"\n    Test for a few units that the unit summary table correctly reports\n    the physical type of the unit.\n\n    Regression test for https://github.com/astropy/astropy/issues/3835\n    \"\"\"\n\n    from astropy.units import astrophys\n\n    for summary in utils._iter_unit_summary(astrophys.__dict__):\n        unit, _, _, physical_type, _ = summary\n\n        if unit.name == 'lyr':\n            assert physical_type == 'length'\n        elif unit.name == 'pc':\n            assert physical_type == 'length'\n        elif unit.name == 'barn':\n            assert physical_type == 'area'\n        elif unit.name == 'cycle':\n            assert physical_type == 'dimensionless'\n        elif unit.name == 'vox':\n            assert physical_type == 'volume'\n"], "sample_592": ["def test_inline_variable_array_repr():\n    var = xr.Variable((\"x\", \"y\"), np.array([[1, 2, 3], [4, 5, 6]], dtype=\"int64\"))\n    max_width = 15\n    expected = \"1 2 ... 5 6\"\n    actual = formatting.inline_variable_array_repr(var, max_width)\n    assert actual == expected\n"], "sample_526": ["def test_num2date_roundoff_negative():\n    assert mdates.num2date(-100000.0000578702) == datetime.datetime(\n        1756, 11, 23, 0, 0, 4, 999980, tzinfo=datetime.timezone.utc)\n    # Slightly larger, steps of 20 microseconds\n    assert mdates.num2date(-100000.0000578703) == datetime.datetime(\n        1756, 11, 23, 0, 0, 5, tzinfo=datetime.timezone.utc)\n"], "sample_289": ["    def test_setlist(self):\n        x = MultiValueDict({'a': [1, 2]})\n        x.setlist('a', [3, 4])\n        self.assertEqual(list(x.lists()), [('a', [3, 4])])\n"], "sample_470": ["def test_classproperty_setter(self):\n    class Foo:\n        _bar = 123\n\n        @classproperty\n            return cls._bar\n\n        @bar.setter\n            cls._bar = value\n\n    Foo.bar = 456\n    self.assertEqual(Foo.bar, 456)\n"], "sample_121": ["    def test_unique_constraints(self):\n        class Model(models.Model):\n            username = models.CharField(max_length=50, unique=True)\n            email = models.EmailField(unique=True)\n\n        errors = Model.check()\n        self.assertEqual(errors, [])\n"], "sample_1206": ["def test_Float_negation():\n    assert -Float(0.0) == 0.0\n    assert -Float(1.5) == -1.5\n    assert -Float('-1.5') == 1.5\n    assert -Float('inf') == -oo\n    assert -Float('-inf') == oo\n    assert -Float('nan') is nan\n"], "sample_929": ["def test_pyfunction_signature_with_default_value(app):\n    text = \".. py:function:: hello(name: str = 'World') -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_punctuation, \":\"],\n                                                      \" \",\n                                                      [nodes.inline, pending_xref, \"str\"],\n                                                      \" \",\n                                                      [desc_sig_operator, \"=\"],\n                                                      \" \",\n                                                      [nodes.inline, \"'World'\"])])\n"], "sample_674": ["def test_node_add_marker():\n    node = nodes.Node(\"test_node\")\n    node.add_marker(\"slow\")\n    assert \"slow\" in node.keywords\n    assert node.own_markers[0].name == \"slow\"\n\n    with pytest.raises(ValueError, match=\"is not a string or pytest.mark.* Marker\"):\n        node.add_marker(123)\n"], "sample_887": ["def test_calibration_with_non_sample_aligned_fit_param_ensemble_false(data):\n    \"\"\"Check that CalibratedClassifierCV does not enforce sample alignment\n    for fit parameters when ensemble is False.\"\"\"\n\n    class TestClassifier(LogisticRegression):\n            assert fit_param is not None\n            return super().fit(X, y, sample_weight=sample_weight)\n\n    CalibratedClassifierCV(estimator=TestClassifier(), ensemble=False).fit(\n        *data, fit_param=np.ones(len(data[1]) + 1)\n    )\n"], "sample_957": ["def test_restify_type_hints_Annotated():\n    from typing import Annotated\n    assert restify(Annotated[str, \"foo\", \"bar\"]) == \":class:`str`\"\n"], "sample_25": ["def test_header_from_fileobj(self):\n    \"\"\"Test reading a Header from a file-like object.\"\"\"\n    with open(self.data(\"test0.fits\"), \"rb\") as fobj:\n        pri_hdr_from_fileobj = fits.Header.fromfile(fobj)\n\n    pri_hdr = fits.getheader(self.data(\"test0.fits\"))\n    assert pri_hdr[\"NAXIS\"] == pri_hdr_from_fileobj[\"NAXIS\"]\n    assert pri_hdr == pri_hdr_from_fileobj\n    assert pri_hdr.tostring() == pri_hdr_from_fileobj.tostring()\n"], "sample_151": ["def test_add_non_blank_textfield_and_charfield_with_default(self, mocked_ask_method):\n    \"\"\"\n    #23405 - Adding a NOT NULL and non-blank `CharField` or `TextField`\n    with default should not prompt for a default.\n    \"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_with_biography_non_blank_default])\n    self.assertEqual(mocked_ask_method.call_count, 0)\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0)\n"], "sample_697": ["def test_tmp_path_factory_with_given_basetemp(tmp_path: Path) -> None:\n    \"\"\"Test TempPathFactory with a given basetemp.\"\"\"\n    given_basetemp = tmp_path / \"given_basetemp\"\n    given_basetemp.mkdir()\n    t = TempPathFactory(given_basetemp, lambda *k: None, _ispytest=True)\n    assert t.getbasetemp() == given_basetemp\n"], "sample_844": ["def test_predecessor_correction():\n    # Test the predecessor correction functionality\n    X = np.array([[0, 0], [0, 1], [1, 1], [2, 2], [2, 3], [3, 3], [4, 4]])\n    expected_labels = np.array([0, 0, 0, 1, 1, 1, 2])\n    clust = OPTICS(min_samples=2, min_cluster_size=2, max_eps=np.inf, cluster_method='xi', xi=0.04, predecessor_correction=True).fit(X)\n    assert_array_equal(clust.labels_, expected_labels)\n"], "sample_890": ["def test_cv_object(direction):\n    \"\"\"Check that SequentialFeatureSelector works with a custom cv object\"\"\"\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5, random_state=0)\n    knn = KNeighborsClassifier(n_neighbors=3)\n    groups = np.repeat(np.arange(10), 10)\n    cv = LeaveOneGroupOut()\n    sfs = SequentialFeatureSelector(knn, n_features_to_select=3, direction=direction, cv=cv)\n    sfs.fit(X, y, groups=groups)\n    assert sfs.transform(X).shape[1] == 3\n"], "sample_599": ["def test_CFScaleOffsetCoder_decode():\n    original = xr.Variable((\"x\",), [0, 1, 2], {\"scale_factor\": 2, \"add_offset\": 1})\n    expected = xr.Variable((\"x\",), [1, 3, 5])\n    coder = variables.CFScaleOffsetCoder()\n    encoded = coder.decode(original)\n    assert_identical(expected, encoded)\n"], "sample_1018": ["def test_fcode_Infinity():\n    x = symbols('x')\n    assert fcode(S.Infinity) == \"      (huge(0d0) + 1)\"\n    assert fcode(S.NegativeInfinity) == \"      -(huge(0d0) + 1)\"\n"], "sample_138": ["def test_template_tag_relative_import(self):\n    relpath = self.hashed_file_path(\"cached/relative_import.css\")\n    self.assertEqual(relpath, \"cached/relative_import.f53576679e5a.css\")\n    with storage.staticfiles_storage.open(relpath) as relfile:\n        content = relfile.read()\n        self.assertNotIn(b\"@import 'styles.css';\", content)\n        self.assertIn(b\"@import 'styles.5e0040571e1a.css';\", content)\n    self.assertPostCondition()\n"], "sample_750": ["def test_omp_cv_multi_target():\n    ompcv = OrthogonalMatchingPursuitCV(normalize=True, fit_intercept=False,\n                                        max_iter=10, cv=5)\n    ompcv.fit(X, y)\n    assert_equal(ompcv.n_nonzero_coefs_, n_nonzero_coefs)\n    assert_array_almost_equal(ompcv.coef_, gamma)\n    omp = OrthogonalMatchingPursuit(normalize=True, fit_intercept=False,\n                                    n_nonzero_coefs=ompcv.n_nonzero_coefs_)\n    omp.fit(X, y)\n    assert_array_almost_equal(ompcv.coef_, omp.coef_)\n"], "sample_1002": ["def test_Float_from_numpy():\n    from sympy.utilities.pytest import skip\n    from sympy.external import import_module\n    np = import_module('numpy')\n    if not np:\n        skip('numpy not installed. Abort numpy tests.')\n\n    x = np.float64(2.5)\n    y = Float(x)\n    assert y == Float(2.5)\n    assert y._prec == 53\n"], "sample_324": ["def test_https_good_referer_matches_cookie_domain_with_trailing_slash(self):\n    \"\"\"\n    A POST HTTPS request with a good referer should be accepted from a\n    subdomain that's allowed by SESSION_COOKIE_DOMAIN and has a trailing slash.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_REFERER'] = 'https://foo.example.com/'\n    req.META['SERVER_PORT'] = '443'\n    mw = CsrfViewMiddleware(post_form_view)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n"], "sample_179": ["def test_unique_constraint_with_deferrable_required_db_features(self):\n    class Model(models.Model):\n        age = models.IntegerField()\n\n        class Meta:\n            required_db_features = {'supports_deferrable_unique_constraints'}\n            constraints = [\n                models.UniqueConstraint(\n                    fields=['age'],\n                    name='unique_age_deferrable',\n                    deferrable=models.Deferrable.DEFERRED,\n                ),\n            ]\n\n    self.assertEqual(Model.check(databases=self.databases), [])\n"], "sample_451": ["def test_replace_metacharacters(self):\n    self.assertEqual(replace_metacharacters(r\"a*b+c?d$e^f\"), \"abcdf\")\n    self.assertEqual(replace_metacharacters(r\"a\\*b\\+c\\?d\\$e\\^f\"), \"a*b+c?d$e^f\")\n"], "sample_608": ["def test_format_array_flat_with_large_strings() -> None:\n    long_str = [\" \".join([\"hello world\" for _ in range(100)])]\n    actual = formatting.format_array_flat(np.asarray([long_str]), 21)\n    expected = \"'hello world hello...\"\n    assert expected == actual\n\n    actual = formatting.format_array_flat(np.asarray([long_str]), 100)\n    expected = \"'hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello"], "sample_1041": ["def test_matrix_symbol_simplify():\n    A = MatrixSymbol('A', n, m)\n    assert A._eval_simplify() == A\n"], "sample_298": ["def test_token_with_different_algorithm(self):\n    \"\"\"\n    A valid token can be created with a different algorithm by using the\n    PasswordResetTokenGenerator.algorithm attribute.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    new_algorithm = 'sha1'\n    # Create and check a token with a different algorithm.\n    p0 = PasswordResetTokenGenerator()\n    p0.algorithm = new_algorithm\n    tk0 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk0), True)\n    # Create and check a token with the default algorithm.\n    p1 = PasswordResetTokenGenerator()\n    self.assertEqual(p1.algorithm, 'sha256')\n    self.assertNotEqual(p1.algorithm, new_algorithm)\n    tk1 = p1.make_token(user)\n    # Tokens created with a different algorithm don't validate.\n    self.assertIs(p0.check_token(user, tk1), False)\n    self.assertIs(p1.check_token(user, tk0), False)\n"], "sample_94": ["def test_fields_with_fk_non_interactive(self):\n    new_io = StringIO()\n    group = Group.objects.create(name='mygroup')\n    email = Email.objects.create(email='mymail@gmail.com')\n\n    call_command(\n        'createsuperuser',\n        interactive=False,\n        username=email.pk,\n        email=email.email,\n        group=group.pk,\n        stdout=new_io,\n    )\n\n    command_output = new_io.getvalue().strip()\n    self.assertEqual(command_output, 'Superuser created successfully.')\n    u = CustomUserWithFK._default_manager.get(email=email)\n    self.assertEqual(u.username, email)\n    self.assertEqual(u.group, group)\n"], "sample_1095": ["def test_permutation_apply_with_evaluate():\n    x = Symbol('x', integer=True)\n    p = Permutation(0, 1, 2)\n    assert p.apply(x, evaluate=True) == p.apply(x)\n    assert p.apply(0, evaluate=True) == 1\n    assert p.apply(x, evaluate=False) == AppliedPermutation(p, x)\n"], "sample_638": ["def test_graphviz_unsupported_image_format(mock_writer, mock_subprocess, capsys):\n    \"\"\"Test that an error is raised if the image format is not supported.\"\"\"\n    with pytest.raises(SystemExit) as wrapped_sysexit:\n        # we have to catch the SystemExit so the test execution does not stop\n        main.Run([\"-o\", \"unsupported_format\", TEST_DATA_DIR])\n    # Check that the right error message is shown to the user\n    assert \"Format unsupported_format is not supported.\" in capsys.readouterr().out\n    # Check that pyreverse did not make the call to create the diagram and we exit with an error\n    mock_writer.DiagramWriter().write.assert_not_called()\n    assert wrapped_sysexit.value.code == 1\n"], "sample_288": ["def test_key_transform_exact(self):\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__d__1__f__exact='g'),\n        [self.objs[4]],\n    )\n"], "sample_489": ["def test_update_conflicts_with_db_column(self):\n    FieldsWithDbColumns.objects.bulk_create(\n        [\n            FieldsWithDbColumns(db_column_field=1, name=\"a\"),\n            FieldsWithDbColumns(db_column_field=2, name=\"b\"),\n        ]\n    )\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n\n    conflicting_objects = [\n        FieldsWithDbColumns(db_column_field=1, name=\"c\"),\n        FieldsWithDbColumns(db_column_field=2, name=\"d\"),\n    ]\n    results = FieldsWithDbColumns.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        unique_fields=[\"db_column_field\"],\n        update_fields=[\"name\"],\n    )\n    self.assertEqual(len(results), len(conflicting_objects))\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n    self.assertCountEqual(\n        FieldsWithDbColumns.objects.values(\"db_column_field\", \"name\"),\n        [\n            {\"db_column_field\": 1, \"name\": \"c\"},\n            {\"db_column_field\": 2, \"name\": \"d\"},\n        ],\n    )\n"], "sample_445": ["def test_time_strings(self):\n    \"\"\"Test custom time strings.\"\"\"\n    custom_time_strings = {\n        \"year\": \"%(num)d yr\",\n        \"month\": \"%(num)d mo\",\n        \"week\": \"%(num)d wk\",\n        \"day\": \"%(num)d d\",\n        \"hour\": \"%(num)d hr\",\n        \"minute\": \"%(num)d min\",\n    }\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneyear, time_strings=custom_time_strings),\n        \"1 yr\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.onemonth, time_strings=custom_time_strings),\n        \"1 mo\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneweek, time_strings=custom_time_strings),\n        \"1 wk\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneday, time_strings=custom_time_strings),\n        \"1 d\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.onehour, time_strings=custom_time_strings),\n        \"1 hr\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneminute, time_strings=custom_time_strings),\n        \"1 min\",\n    )\n"], "sample_278": ["def test_expression_wrapper_with_none_value(self):\n    expr = ExpressionWrapper(Value(None), output_field=IntegerField())\n    self.assertIsNone(expr.resolve_expression(query=None))\n"], "sample_807": ["def test_calibration_multilabel():\n    \"\"\"Test calibration for multilabel \"\"\"\n    # test multi-label setting with classifier that implements\n    # only decision function\n    clf = LinearSVC()\n    X, y = make_multilabel_classification(n_samples=100, n_features=2, random_state=42,\n                                          n_classes=3, n_labels=2)\n\n    X_train, y_train = X[::2], y[::2]\n    X_test, y_test = X[1::2], y[1::2]\n\n    clf.fit(X_train, y_train)\n    for method in ['isotonic', 'sigmoid']:\n        cal_clf = CalibratedClassifierCV(clf, method=method, cv=2)\n        cal_clf.fit(X_train, y_train)\n        probas = cal_clf.predict_proba(X_test)\n        assert_array_almost_equal(np.sum(probas, axis=1), np.ones(len(X_test)))\n\n        # Check that log-loss of calibrated classifier is smaller than\n        # log-loss of naively turned OvR decision function to probabilities\n        # via softmax\n            e = np.exp(-y_pred)\n            return e / e.sum(axis=1).reshape(-1, 1)\n\n        uncalibrated_log_loss = \\\n            log_loss(y_test, softmax(clf.decision_function(X_test)))\n        calibrated_log_loss = log_loss(y_test, probas)\n        assert_greater_equal(uncalibrated_log_loss, calibrated_log_loss)\n"], "sample_32": ["def test_de_density_scale(self, cosmo, z):\n    \"\"\"Test :meth:`astropy.cosmology.w0wzCDM.de_density_scale`.\"\"\"\n    expected = (z + 1.0) ** (3.0 * (1.0 + cosmo.w0 - cosmo.wz)) * np.exp(3.0 * cosmo.wz * z)\n    assert u.allclose(cosmo.de_density_scale(z), expected)\n"], "sample_771": ["def test_power_transformer_sparse_input(method, standardize):\n    # Check that PowerTransformer works with sparse input\n    X = sparse.csr_matrix(X_2d)\n    if method == 'box-cox':\n        X.data = np.abs(X.data)\n\n    pt = PowerTransformer(method, standardize)\n    X_trans = pt.fit_transform(X)\n    assert sparse.issparse(X_trans)\n    assert_array_almost_equal(X_trans.toarray(), pt.fit_transform(X_2d))\n\n    X_inv_trans = pt.inverse_transform(X_trans)\n    assert sparse.issparse(X_inv_trans)\n    assert_array_almost_equal(X_inv_trans.toarray(), X_2d)\n"], "sample_11": ["def test_world_to_pixel_values_different_int_types():\n    int_sliced = SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, np.s_[:, 0, :])\n    np64_sliced = SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, np.s_[:, np.int64(0), :])\n    world_arrays = ([12.86995801, 20.49217541], 20, [20.49217541, 12.86995801])\n    for int_coord, np64_coord in zip(int_sliced.world_to_pixel_values(*world_arrays),\n                                     np64_sliced.world_to_pixel_values(*world_arrays)):\n        assert all(int_coord == np64_coord)\n"], "sample_1065": ["def test_binomial_series():\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True)\n\n    assert binomial(n, k).series(n, 0, 3) == \\\n        binomial(0, k) + k*binomial(0, k - 1)*n/1 + (k*(k - 1)*binomial(0, k - 2)*n**2/2 + O(n**3))/2\n"], "sample_86": ["def test_lazy_hash(self):\n    \"\"\"\n    hash() works correctly for Promises.\n    \"\"\"\n    lazy_a = lazy(lambda: 4, int)\n    lazy_b = lazy(lambda: 4, int)\n    lazy_c = lazy(lambda: 5, int)\n\n    self.assertEqual(hash(lazy_a()), hash(lazy_b()))\n    self.assertNotEqual(hash(lazy_b()), hash(lazy_c()))\n"], "sample_1199": ["def test_tensor_product_trace():\n    assert Tr(TP(A, B)).doit() == Tr(A)*Tr(B)\n    assert Tr(TP(A, B), indices=[0]).doit() == Tr(A)*B\n    assert Tr(TP(A, B), indices=[1]).doit() == A*Tr(B)\n"], "sample_1080": ["def test_sign_complex():\n    x = Symbol('x', complex=True)\n    assert refine(sign(x), Q.positive(re(x))) == sign(re(x))\n    assert refine(sign(x), Q.negative(re(x))) == -sign(re(x))\n    assert refine(sign(x), Q.zero(re(x)) & Q.positive(im(x))) == S.ImaginaryUnit\n    assert refine(sign(x), Q.zero(re(x)) & Q.negative(im(x))) == -S.ImaginaryUnit\n"], "sample_783": ["def test_imputation_constant_strategy(X, missing_values, strategy, fill_value, X_trans_exp):\n    imputer = SimpleImputer(missing_values=missing_values, strategy=strategy, fill_value=fill_value)\n    X_trans = imputer.fit_transform(X)\n    assert_array_equal(X_trans, X_trans_exp)\n"], "sample_563": ["def test_offsetbox_get_offset():\n    # Test the get_offset method of OffsetBox and its subclasses\n    fig, ax = plt.subplots()\n    ob = OffsetBox()\n    ob.set_offset((10, 20))\n    assert ob.get_offset() == (10, 20)\n\n    da = DrawingArea(100, 100)\n    da.set_offset((30, 40))\n    assert da.get_offset() == (30, 40)\n\n    ta = TextArea(\"Test\")\n    ta.set_offset((50, 60))\n    assert ta.get_offset() == (50, 60)\n\n    ab = AnchoredOffsetbox(\"upper left\", child=da)\n    ab.set_offset((70, 80))\n    assert ab.get_offset() == (70, 80)\n"], "sample_211": ["def test_get_redirect_url_with_args_and_kwargs(self):\n    \"\"\"\n    Test get_redirect_url with args and kwargs\n    \"\"\"\n    request = self.rf.get('/')\n    view = RedirectView.as_view(pattern_name='artist_detail')\n    view.setup(request, 1, pk=2)\n    url = view.get_redirect_url()\n    self.assertEqual(url, '/detail/artist/2/')\n"], "sample_740": ["def test_check_array_large_indices_supported_scipy_version(X_64bit):\n    # Large indices should be allowed for scipy>=0.14.0\n    if LARGE_SPARSE_SUPPORTED:\n        check_array(X_64bit, accept_sparse=True, accept_large_sparse=True)\n"], "sample_595": ["def test_encode_decode_errors():\n    data = xr.DataArray([\"a\", \"b\", \"a\\xe4\"])\n    encoded = data.str.encode(\"utf-8\")\n    with pytest.raises(UnicodeDecodeError):\n        decoded = encoded.str.decode(\"ascii\")\n"], "sample_123": ["    def test_escape_leading_slashes(self):\n        self.assertEqual(escape_leading_slashes('//example.com'), '/%2Fexample.com')\n        self.assertEqual(escape_leading_slashes('http://example.com'), 'http://example.com')\n        self.assertEqual(escape_leading_slashes('/path'), '/path')\n        self.assertEqual(escape_leading_slashes('///path'), '/%2F/path')\n"], "sample_735": ["def test_gaussian_mixture_predict_proba_shape():\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng)\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        g = GaussianMixture(n_components=rand_data.n_components,\n                            random_state=rng, weights_init=rand_data.weights,\n                            means_init=rand_data.means,\n                            precisions_init=rand_data.precisions[covar_type],\n                            covariance_type=covar_type)\n        g.fit(X)\n        Y_pred_proba = g.predict_proba(X)\n        assert_equal(Y_pred_proba.shape, (rand_data.n_samples, rand_data.n_components))\n"], "sample_932": ["def test_xref_consistency_cpp_expr(app, status, warning):\n    app.builder.build_all()\n\n    test = 'xref_consistency.html'\n    output = (app.outdir / test).read_text()\n\n    # Test the classes for the cpp:expr role\n    expr_classes = RoleClasses('cpp:expr', 'code', ['span'])\n    assert 'cpp-expr' in expr_classes.classes\n    assert 'cpp-expr' in expr_classes.content_classes['span']\n"], "sample_99": ["def test_trunc_func_with_timezone_and_output_field(self):\n    start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n    end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n    self.create_model(end_datetime, start_datetime)\n\n    melb = pytz.timezone('Australia/Melbourne')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=output_field, tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(melb), kind, melb)),\n                (end_datetime, truncate_to(end_datetime.astimezone(melb), kind, melb))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_datetime_kind('year', DateTimeField())\n    test_datetime_kind('quarter', DateTimeField())\n    test_datetime_kind('month', DateTimeField())\n    test_datetime_kind('week', DateTimeField())\n    test_datetime_kind('day', DateTimeField())\n    test_datetime_kind('hour', DateTimeField())\n    test_datetime_kind('minute', DateTimeField())\n    test_datetime_kind('second', DateTimeField())\n    test_datetime_kind('year', DateField())\n    test_datetime_kind('quarter', DateField())\n    test_datetime_kind('month', DateField())\n    test_datetime_kind('week"], "sample_378": ["def test_bulk_update_with_related_objects(self):\n    self.create_tags()\n    notes = [\n        Note.objects.create(note=str(i), misc=str(i), tag=self.tags[i % len(self.tags)])\n        for i in range(10)\n    ]\n    for note in notes:\n        note.tag = self.tags[(note.id + 1) % len(self.tags)]\n    Note.objects.bulk_update(notes, ['tag'])\n    self.assertCountEqual(\n        Note.objects.values_list('tag', flat=True),\n        [note.tag_id for note in notes]\n    )\n"], "sample_130": ["def test_complex_transform(self):\n    query = Query(Author)\n    with register_lookup(CharField, Lower):\n        where = query.build_where(~Q(name__lower__startswith='foo'))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, StartsWith)\n    self.assertIsInstance(lookup.lhs, Lower)\n    self.assertIsInstance(lookup.lhs.lhs, SimpleCol)\n    self.assertEqual(lookup.lhs.lhs.target, Author._meta.get_field('name'))\n"], "sample_23": ["def test_angle_unicode_formatting():\n    \"\"\"\n    Tests string formatting for Angle objects with unicode separators\n    \"\"\"\n\n    angle = Angle(\"54.12412\", unit=u.degree)\n\n    res = \"Angle as HMS: 3\u02b036\u1d5029.7888\u02e2\"\n    assert f\"Angle as HMS: {angle.to_string(unit=u.hour, format='unicode')}\" == res\n\n    res = \"Angle as DMS: 54\u00b036\u203226.832\u2033\"\n    assert f\"Angle as DMS: {angle.to_string(unit=u.degree, format='unicode')}\" == res\n\n    res = \"Angle as rad: 0.944644098745 rad\"\n    assert f\"Angle as rad: {angle.to_string(unit=u.radian, format='unicode')}\" == res\n"], "sample_1135": ["def test_divmod_with_symbols():\n    x, y = symbols('x y')\n    assert divmod(x, y) == (floor(x/y), x % y)\n    assert divmod(x, 3) == (floor(x/3), x % 3)\n    assert divmod(3, x) == (floor(3/x), 3 % x)\n"], "sample_556": ["def test_savefig_metadata_invalid_key():\n    with pytest.raises(KeyError):\n        Figure().savefig(io.BytesIO(), format='png', metadata={'invalid_key': 'value'})\n"], "sample_371": ["def test_template_encoding_text(self):\n    \"\"\"\n    The templates are loaded directly, not via a template loader, and\n    should be opened as utf-8 charset as is the default specified on\n    template engines.\n    \"\"\"\n    response = self.client.get('/raises500/', HTTP_ACCEPT='text/plain')\n    self.assertEqual(response.headers['Content-Type'], 'text/plain; charset=utf-8')\n"], "sample_384": ["def test_bulk_update_with_related_objects(self):\n    related_objects = [RelatedObject.objects.create() for _ in range(10)]\n    single_objects = [SingleObject.objects.create() for _ in range(10)]\n    for related_obj, single_obj in zip(related_objects, single_objects):\n        related_obj.single = single_obj\n    RelatedObject.objects.bulk_update(related_objects, [\"single\"])\n    self.assertCountEqual(\n        RelatedObject.objects.values_list(\"single\", flat=True),\n        [obj.single_id for obj in related_objects],\n    )\n"], "sample_203": ["def test_file_extension_validator(self):\n    validator = validators.FileExtensionValidator(allowed_extensions=['txt', 'pdf'])\n    valid_file = SimpleUploadedFile(\"file.txt\", b\"file_content\", content_type=\"text/plain\")\n    invalid_file = SimpleUploadedFile(\"file.doc\", b\"file_content\", content_type=\"application/msword\")\n\n    self.assertIsNone(validator(valid_file))\n\n    with self.assertRaises(ValidationError) as e:\n        validator(invalid_file)\n    self.assertEqual(e.exception.message, 'File extension \u201cdoc\u201d is not allowed. Allowed extensions are: txt, pdf.')\n"], "sample_918": ["def test_pyfunction_signature_with_annotation(app):\n    text = \".. py:function:: hello(name: str) -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_punctuation, \":\"],\n                                                      \" \",\n                                                      [nodes.inline, pending_xref, \"str\"])])\n"], "sample_369": ["def test_add_model_with_field_removed_from_base_model_with_same_name(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n        ], bases=('app.readable',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n"], "sample_974": ["def test_ccode_AugmentedAssignment():\n    expr = aug_assign(x, '+=', y + z)\n    assert ccode(expr) == 'x += y + z;'\n"], "sample_388": ["    def test_clean_username(self):\n        backend = RemoteUserBackend()\n        self.assertEqual(backend.clean_username(\"username@example.com\"), \"username\")\n        self.assertEqual(backend.clean_username(\"username\"), \"username\")\n        self.assertEqual(backend.clean_username(\"username@\"), \"username\")\n        self.assertEqual(backend.clean_username(\"@example.com\"), \"\")\n"], "sample_817": ["def test_sparse_zero_variance():\n    # Test VarianceThreshold with sparse matrix and zero variance.\n    X = bsr_matrix(data)\n    sel = VarianceThreshold().fit(X)\n    assert_array_equal([0, 1, 3, 4], sel.get_support(indices=True))\n"], "sample_259": ["def test_prefetch_object_with_queryset(self):\n    book1 = Book.objects.get(id=self.book1.id)\n    book2 = Book.objects.get(id=self.book2.id)\n    with self.assertNumQueries(1):\n        prefetch_related_objects(\n            [book1],\n            Prefetch('authors', queryset=Author.objects.filter(name__startswith='C')),\n        )\n    with self.assertNumQueries(0):\n        self.assertCountEqual(book1.authors.all(), [self.author1, self.author2])\n    with self.assertNumQueries(1):\n        prefetch_related_objects(\n            [book2],\n            Prefetch('authors', queryset=Author.objects.filter(name__startswith='C')),\n        )\n    with self.assertNumQueries(0):\n        self.assertCountEqual(book2.authors.all(), [])\n"], "sample_169": ["def test_key_transform_with_none_value(self):\n    obj = NullableJSONModel.objects.create(value={'a': None})\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__a=KeyTransform('a', 'value')),\n        [obj],\n    )\n"], "sample_561": ["def test_marker_scaled_with_transform():\n    marker = markers.MarkerStyle(\"1\", transform=Affine2D().translate(1, 1))\n    new_marker = marker.scaled(2, 3)\n    assert new_marker is not marker\n    expected = Affine2D().translate(1, 1).scale(2, 3)\n    assert new_marker.get_user_transform() == expected\n    assert marker._user_transform is not new_marker._user_transform\n"], "sample_374": ["def test_nested_prefetch_related_with_to_attr(self):\n    \"\"\"\n    Nested prefetches with to_attr are allowed.\n    \"\"\"\n    occupants = Person.objects.prefetch_related(\n        Prefetch('houses', to_attr='some_attr_name'),\n        Prefetch('some_attr_name', queryset=House.objects.prefetch_related('main_room')),\n    )\n    houses = House.objects.prefetch_related(Prefetch('occupants', queryset=occupants))\n    with self.assertNumQueries(5):\n        self.traverse_qs(list(houses), [['occupants', 'some_attr_name', 'main_room']])\n"], "sample_910": ["def test_prefixed_warnings(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    logger.warning('message1')\n    with prefixed_warnings(\"prefix:\"):\n        logger.warning('message2')\n        assert 'WARNING: message1' in warning.getvalue()\n        assert 'WARNING: prefix: message2' in warning.getvalue()\n\n    logger.warning('message3')\n    assert 'WARNING: message3' in warning.getvalue()\n"], "sample_720": ["def test_power_transformer_yeo_johnson():\n    X = np.abs(X_2d)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method='yeo-johnson', standardize=standardize)\n\n        X_trans_class = pt.fit_transform(X)\n        X_trans_func = power_transform(X, method='yeo-johnson', standardize=standardize)\n\n        for X_trans in [X_trans_class, X_trans_func]:\n            for j in range(X_trans.shape[1]):\n                X_expected, lmbda = stats.yeojohnson(X[:, j].flatten())\n\n                if standardize:\n                    X_expected = scale(X_expected)\n\n                assert_almost_equal(X_trans[:, j], X_expected)\n                assert_almost_equal(lmbda, pt.lambdas_[j])\n\n            # Test inverse transformation\n            X_inv = pt.inverse_transform(X_trans)\n            assert_array_almost_equal(X_inv, X)\n\n        assert len(pt.lambdas_) == X.shape[1]\n        assert isinstance(pt.lambdas_, np.ndarray)\n"], "sample_792": ["def test_gnb_var_smoothing():\n    \"\"\"Test whether var_smoothing is properly used in GNB.\"\"\"\n    clf = GaussianNB(var_smoothing=0.1).fit(X, y)\n    assert_greater(clf.sigma_.min(), 0.1)\n"], "sample_955": ["def test_unparse_Subscript_with_simple_tuple():\n    source = \"a[1, 2]\"\n    expected = \"a[1, 2]\"\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].value, source) == expected\n"], "sample_869": ["def test_balanced_accuracy_score_multiclass():\n    y_true = [0, 1, 2, 0, 1, 2]\n    y_pred = [0, 2, 1, 0, 1, 2]\n    balanced = balanced_accuracy_score(y_true, y_pred)\n    assert balanced == pytest.approx(0.5)\n"], "sample_1177": ["def test_issue_22190():\n    x = Symbol('x')\n    for a in (sqrt(7 - 2*x) - 2, 1 - x):\n        assert Abs(a) + Abs(-a) == 2*Abs(a), a\n"], "sample_965": ["def test_is_builtin_class_method_with_custom_class():\n    class MyClass:\n            pass\n\n            pass\n\n    assert inspect.is_builtin_class_method(MyClass, '__init__') is False\n    assert inspect.is_builtin_class_method(MyClass, 'my_method') is False\n"], "sample_775": ["def test_indent_at_name():\n    # Test the indent_at_name parameter\n    pp = _EstimatorPrettyPrinter(compact=True, indent=2, indent_at_name=False)\n    lr = LogisticRegression(C=99)\n    expected = \"\"\"\n  LogisticRegression(C=99, class_weight=None, dual=False, fit_intercept=True,\n                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n                     multi_class='warn', n_jobs=None, penalty='l2',\n                     random_state=None, solver='warn', tol=0.0001, verbose=0,\n                     warm_start=False)\"\"\"\n    expected = expected[1:]  # remove first \\n\n    assert pp.pformat(lr) == expected\n\n    pp = _EstimatorPrettyPrinter(compact=True, indent=2, indent_at_name=True)\n    lr = LogisticRegression(C=99)\n    expected = \"\"\""], "sample_325": ["def test_field_deep_copy_widget(self):\n    class CustomTextInput(TextInput):\n            kwargs['attrs'] = {'class': 'custom-class'}\n            super().__init__(**kwargs)\n\n    field = CharField(widget=CustomTextInput())\n    field_copy = copy.deepcopy(field)\n    self.assertIsInstance(field_copy, CharField)\n    self.assertIsNot(field_copy.widget, field.widget)\n    self.assertIsInstance(field_copy.widget, CustomTextInput)\n    self.assertIsNot(field_copy.widget.attrs, field.widget.attrs)\n"], "sample_205": ["    def test_update_error_dict(self):\n        error1 = ValidationError('message')\n        error2 = ValidationError({'field1': 'error1', 'field2': 'error2'})\n        error3 = ValidationError([error1, error2])\n\n        error_dict = {}\n        error1.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {NON_FIELD_ERRORS: ['message']})\n\n        error_dict = {}\n        error2.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {'field1': ['error1'], 'field2': ['error2']})\n\n        error_dict = {}\n        error3.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {NON_FIELD_ERRORS: ['message'], 'field1': ['error1'], 'field2': ['error2']})\n"], "sample_85": ["def test_fast_delete_m2m_through(self):\n    t = M2MTo.objects.create()\n    f = M2MFrom.objects.create()\n    f.m2m_through.create(from_field=f, to_field=t)\n    # 1 to delete f, 1 to fast-delete m2m_through for f\n    self.assertNumQueries(2, f.delete)\n"], "sample_634": ["def test_expand_modules_with_non_existent_module(self, files_or_modules, expected):\n    \"\"\"Test expand_modules with a non-existent module\"\"\"\n    ignore_list, ignore_list_re = [], []\n    modules, errors = expand_modules(\n        files_or_modules,\n        ignore_list,\n        ignore_list_re,\n        get_global_option(self, \"ignore-paths\"),\n    )\n    assert not modules\n    assert errors == expected\n"], "sample_909": ["def test_attributes_with_ivar(self):\n    docstring = \"\"\"\\"], "sample_612": ["def test_groupby_bins_multidim_with_nan(self):\n    array = self.make_groupby_multidim_example_array()\n    array[0, 0, 0] = np.nan\n    bins = [0, 15, 20]\n    bin_coords = pd.cut(array[\"lat\"].values.flat, bins).categories\n    expected = DataArray([15, 40], dims=\"lat_bins\", coords={\"lat_bins\": bin_coords})\n    actual = array.groupby_bins(\"lat\", bins).map(lambda x: x.sum(skipna=True))\n    assert_identical(expected, actual)\n"], "sample_399": ["def test_aggregation_default_using_float_from_python(self):\n    result = Book.objects.filter(rating__lt=3.0).aggregate(\n        value=Sum(\"price\", default=0.0),\n    )\n    self.assertEqual(result[\"value\"], 0.0)\n"], "sample_91": ["def test_permission_denied(self):\n    request = self.request_factory.get('/')\n    response = permission_denied(request, Exception())\n    self.assertContains(response, b'<h1>403 Forbidden</h1>', status_code=403)\n"], "sample_1104": ["def test_MatPow():\n    A = MatrixSymbol(\"A\", 2, 2)\n    assert str(A**2) == \"A**2\"\n    assert str(A**-1) == \"A**(-1)\"\n"], "sample_293": ["    def test_pattern_startswith_slash(self):\n        test_urls = [\n            ('/normal/', []),\n            ('/normal/<int:arg1>/<int:arg2>/', []),\n            ('/view_class/<int:arg1>/<int:arg2>/', []),\n            ('/included/normal/<int:arg1>/<int:arg2>/', []),\n            ('/included/view_class/<int:arg1>/<int:arg2>/', []),\n            ('/mixed_args/<int:arg1>/<int:arg2>/', []),\n            ('/included/mixed_args/<int:arg1>/<int:arg2>/', []),\n            ('/included/<int:arg1>/mixed_args/<int:arg1>/<int:arg2>/', []),\n            ('/unnamed/normal/<int:arg1>/<int:arg2>/', []),\n            ('/unnamed/view_class/<int:arg1>/<int:arg2>/', []),\n            ('/no_kwargs/<int:arg1>/<int:arg2>/', []),\n            ('/included/no_kwargs/<int:arg1>/<int:arg2>/', []),\n            ('/included/<int:arg1>/no_kwargs/<int:arg1>/<int:arg2>/', []),\n            ('/test1/inner/<int:arg1>/<int:arg2>/', []),\n            ('/included/test3/inner/<int:arg1>/<int:arg2>/', []),\n            ('/ns-included1/normal/<int:arg1>/<int:arg2>/', []),\n            ('/included/test3/inner/<int:arg1>/<int:arg2>/', []),\n            ('/default/inner/<int:arg1>/<int:arg2>/', []),\n            ('/other2/inner/<int:"], "sample_56": ["def test_check_list_display_links_with_invalid_field(self):\n    class SongAdmin(admin.ModelAdmin):\n        list_display = [\"pk\", \"title\"]\n        list_display_links = [\"invalid_field\"]\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'list_display_links[0]' refers to 'invalid_field', which is not defined in 'list_display'.\",\n            obj=SongAdmin,\n            id='admin.E111',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_260": ["def test_create_model_add_index(self):\n    \"\"\"\n    AddIndex should optimize into CreateModel.\n    \"\"\"\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n            ),\n            migrations.AddIndex(\"Foo\", models.Index(fields=['name'], name='idx_name')),\n        ],\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[\n                    (\"name\", models.CharField(max_length=255)),\n                ],\n                options={'indexes': [models.Index(fields=['name'], name='idx_name')]},\n            ),\n        ],\n    )\n"], "sample_889": ["def test_calibration_with_non_sample_aligned_fit_param_cv_prefit(data):\n    \"\"\"Check that CalibratedClassifierCV does not enforce sample alignment\n    for fit parameters when cv='prefit'.\"\"\"\n\n    class TestClassifier(LogisticRegression):\n            assert fit_param is not None\n            return super().fit(X, y, sample_weight=sample_weight)\n\n    X, y = data\n    clf = TestClassifier().fit(X, y)\n    calibrated_classifier = CalibratedClassifierCV(estimator=clf, cv='prefit')\n    calibrated_classifier.fit(X, y, fit_param=np.ones(len(y) + 1))\n"], "sample_1175": ["def test_issue_18327():\n    assert pretty(Sum(x, (x, 1, 2))) == \\\n    '  2     \\n'\\\n    ' ___    \\n'\\\n    ' \\\\  `   \\n'\\\n    '  \\\\    x\\n'\\\n    '  /_,   \\n'\\\n    'x = 1   '\n\n    assert upretty(Sum(x, (x, 1, 2))) == \\\n    '  2     \\n'\\\n    ' ___    \\n'\\\n    ' \u2572      \\n'\\\n    '  \u2572    x\\n'\\\n    '  \u2571     \\n'\\\n    ' \u203e\u203e\u203e    \\n'\\\n    'x = 1   '\n"], "sample_389": ["    def test_prefixed(self):\n        # Add SCRIPT_NAME prefix to relative paths.\n        tests = (\"/path/\", \"path/\")\n        for setting in (\"MEDIA_URL\", \"STATIC_URL\"):\n            for path in tests:\n                new_settings = {setting: path}\n                for script_name in [\"/somesubpath\", \"/somesubpath/\", \"/\", \"\", None]:\n                    with self.subTest(script_name=script_name, **new_settings):\n                        try:\n                            self.set_script_name(script_name)\n                            if script_name:\n                                expected_path = urljoin(script_name, path)\n                            else:\n                                expected_path = path\n                            self.assertEqual(getattr(settings, setting), expected_path)\n                        finally:\n                            clear_script_prefix()\n"], "sample_336": ["    def test_include_app_name_namespace_conflict(self):\n        msg = 'Cannot override the namespace for a dynamic module that provides a namespace.'\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            include((self.url_patterns, 'app_name'), namespace='namespace')\n"], "sample_276": ["    def test_simplify_regex_with_named_groups(self):\n        pattern = \"^(?P<sport_slug>\\w+)/athletes/(?P<athlete_slug>\\w+)/$\"\n        simplified = simplify_regex(pattern)\n        self.assertEqual(simplified, \"/<sport_slug>/athletes/<athlete_slug>/\")\n"], "sample_757": ["def test_one_hot_encoder_specified_categories_wrong_shape():\n    X = np.array([['a', 'b']], dtype=object).T\n    enc = OneHotEncoder(categories=[['a', 'b', 'c'], [0, 1]])\n    msg = \"Shape mismatch: if n_values is an array, it has to be of shape (n_features,).\"\n    with pytest.raises(ValueError, match=msg):\n        enc.fit_transform(X)\n"], "sample_1166": ["def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n"], "sample_128": ["    def test_covering_descending_index(self):\n        index = Index(\n            name='covering_desc_headline_idx',\n            fields=['-headline'],\n            include=['pub_date', 'published'],\n        )\n        with connection.schema_editor() as editor:\n            self.assertIn(\n                '(%s DESC) INCLUDE (%s, %s)' % (\n                    editor.quote_name('headline'),\n                    editor.quote_name('pub_date'),\n                    editor.quote_name('published'),\n                ),\n                str(index.create_sql(Article, editor)),\n            )\n            editor.add_index(Article, index)\n            with connection.cursor() as cursor:\n                constraints = connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                )\n                self.assertIn(index.name, constraints)\n                self.assertEqual(\n                    constraints[index.name]['columns'],\n                    ['headline', 'pub_date', 'published'],\n                )\n                self.assertEqual(\n                    constraints[index.name]['orders'],\n                    ['DESC', '', ''],\n                )\n            editor.remove_index(Article, index)\n            with connection.cursor() as cursor:\n                self.assertNotIn(index.name, connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                ))\n"], "sample_803": ["def test_roc_auc_score_max_fpr():\n    # Test Area Under the Partial Receiver Operating Characteristic Curve\n    y_true, _, probas_pred = make_prediction(binary=True)\n    expected_auc = _partial_roc_auc_score(y_true, probas_pred, max_fpr=0.5)\n\n    roc_auc = roc_auc_score(y_true, probas_pred, max_fpr=0.5)\n    assert_array_almost_equal(roc_auc, expected_auc, decimal=2)\n\n    # Test max_fpr out of range\n    with pytest.raises(ValueError):\n        roc_auc_score(y_true, probas_pred, max_fpr=1.5)\n    with pytest.raises(ValueError):\n        roc_auc_score(y_true, probas_pred, max_fpr=0)\n"], "sample_28": ["def test_subclass_update(self):\n    \"\"\"Check that subclasses don't get ignored on updating.\"\"\"\n\n    class MyHeader(fits.Header):\n            if comment is None:\n                # Just for our checks we add a comment if there is none.\n                comment = \"no comment\"\n\n            return super().set(key, value, comment, *args, **kwargs)\n\n    my_header = MyHeader()\n    my_header.update({\"a\": 1.0, \"b\": 2.0, \"c\": 3.0})\n\n    assert my_header.comments[\"a\"] == \"no comment\"\n    assert my_header.comments[\"b\"] == \"no comment\"\n    assert my_header.comments[\"c\"] == \"no comment\"\n\n    my_header.update({\"a\": 1.1, \"b\": 2.2})\n    assert my_header.comments[\"a\"] == \"no comment\"\n    assert my_header.comments[\"b\"] == \"no comment\"\n    assert my_header.comments[\"c\"] == \"no comment\"\n"], "sample_883": ["def test_bayesian_ridge_max_iter_default():\n    \"\"\"Check the default value of `max_iter`.\"\"\"\n    X, y = diabetes.data, diabetes.target\n    model = BayesianRidge()\n    model.fit(X, y)\n    assert model.max_iter == 300\n"], "sample_511": ["def test_subplot_mosaic_reuse():\n    # create an Axes\n    ax1 = plt.subplot_mosaic({'A': [1, 1]})['A']\n    # check that it is current\n    assert ax1 is plt.gca()\n    # make sure we get it back if we ask again\n    assert ax1 is plt.subplot_mosaic({'A': [1, 1]})['A']\n    # remove it\n    ax1.remove()\n    # create a polar plot\n    ax2 = plt.subplot_mosaic({'A': [1, 1]}, subplot_kw={'projection': 'polar'})['A']\n    assert ax2 is plt.gca()\n    # this should have deleted the first axes\n    assert ax1 not in plt.gcf().axes\n    # assert we get it back if no extra parameters passed\n    assert ax2 is plt.subplot_mosaic({'A': [1, 1]})['A']\n    ax2.remove()\n    # now check explicitly setting the projection to rectilinear\n    # makes a new axes\n    ax3 = plt.subplot_mosaic({'A': [1, 1]}, subplot_kw={'projection': 'rectilinear'})['A']\n    assert ax3 is plt.gca()\n    assert ax3 is not ax2\n    assert ax2 not in plt.gcf().axes\n"], "sample_676": ["def test_line_with_reprcrash_message_long(monkeypatch):\n    import _pytest.terminal\n    from wcwidth import wcswidth\n\n    mocked_verbose_word = \"FAILED\"\n    mocked_pos = \"some::nodeid\"\n    mocked_message = \"This is a long message that should be truncated\"\n\n        return mocked_pos\n\n    monkeypatch.setattr(_pytest.terminal, \"_get_pos\", mock_get_pos)\n\n    class config(object):\n        pass\n\n    class longrepr(object):\n        class reprcrash(object):\n            message = mocked_message\n\n    class rep(object):\n            return mocked_verbose_word\n\n        longrepr = longrepr\n\n    termwidth = 80\n    line = _get_line_with_reprcrash_message(config, rep, termwidth)\n    expected_line = \"{} {} - {}...\".format(mocked_verbose_word, mocked_pos, mocked_message[:termwidth - len(mocked_verbose_word) - len(mocked_pos) - 6])\n    assert line == expected_line\n"], "sample_152": ["def test_fast_delete_with_signals(self):\n    # Test that fast delete still works when signals are connected\n        pass\n\n    models.signals.pre_delete.connect(receiver, sender=User)\n    models.signals.post_delete.connect(receiver, sender=User)\n\n    u = User.objects.create(\n        avatar=Avatar.objects.create()\n    )\n    a = Avatar.objects.get(pk=u.avatar_id)\n    # 1 query to delete the user\n    # 1 query to delete the avatar\n    self.assertNumQueries(2, a.delete)\n    self.assertFalse(User.objects.exists())\n    self.assertFalse(Avatar.objects.exists())\n\n    models.signals.pre_delete.disconnect(receiver, sender=User)\n    models.signals.post_delete.disconnect(receiver, sender=User)\n"], "sample_247": ["def test_alias_with_m2m(self):\n    qs = Book.objects.alias(author_age=F('authors__age')).filter(pk=self.b1.pk).order_by('author_age')\n    self.assertIs(hasattr(qs.first(), 'author_age'), False)\n    self.assertEqual(qs[0].authors.all()[0].age, 34)\n    self.assertEqual(qs[1].authors.all()[0].age, 35)\n"], "sample_715": ["def test_cross_val_predict_with_method_multilabel():\n    X, y = make_multilabel_classification(n_classes=3, n_labels=2,\n                                          allow_unlabeled=False,\n                                          return_indicator=True,\n                                          random_state=1)\n    est = LogisticRegression()\n    check_cross_val_predict_with_method(est)\n"], "sample_544": ["def test_imshow_interpolation(interpolation):\n    fig, ax = plt.subplots()\n    arr = np.arange(100).reshape((10, 10))\n    ax.imshow(arr, interpolation=interpolation, extent=(1, 2, 1, 2))\n    ax.set_xlim(0, 3)\n    ax.set_ylim(0, 3)\n"], "sample_545": ["def test_savefig_metadata_invalid_key():\n    with pytest.raises(ValueError, match=\"Unrecognized metadata key 'invalid_key'\"):\n        Figure().savefig(io.BytesIO(), format='png', metadata={'invalid_key': 'value'})\n"], "sample_640": ["def test_is_overload_stub() -> None:\n    code = astroid.extract_node(\n        \"\"\"\n    from typing import overload\n\n    @overload\n        ...\n\n        return x\n\n    class MyClass:\n        @overload\n            ...\n\n            return x\n    \"\"\"\n    )\n    assert isinstance(code, list) and len(code) == 2\n\n    assert isinstance(code[0], nodes.FunctionDef)\n    assert utils.is_overload_stub(code[0]) is True\n    assert isinstance(code[1], nodes.FunctionDef)\n    assert utils.is_overload_stub(code[1]) is True\n"], "sample_698": ["def test_get_auto_indent():\n    from _pytest.logging import PercentStyleMultiline\n\n    assert PercentStyleMultiline._get_auto_indent(None) == 0\n    assert PercentStyleMultiline._get_auto_indent(True) == -1\n    assert PercentStyleMultiline._get_auto_indent(False) == 0\n    assert PercentStyleMultiline._get_auto_indent(5) == 5\n    assert PercentStyleMultiline._get_auto_indent(\"True\") == -1\n    assert PercentStyleMultiline._get_auto_indent(\"False\") == 0\n    assert PercentStyleMultiline._get_auto_indent(\"5\") == 5\n    assert PercentStyleMultiline._get_auto_indent(\"junk\") == 0\n    assert PercentStyleMultiline._get_auto_indent({}) == 0\n"], "sample_423": ["def test_alter_field_to_fk_dependency_other_app_with_initial_true(self):\n    class Migration(migrations.Migration):\n        initial = True\n        operations = [\n            migrations.CreateModel(\"Author\", name=\"Author\", fields=[(\"id\", models.AutoField(primary_key=True))]),\n            migrations.CreateModel(\"Book\", name=\"Book\", fields=[(\"author\", models.ForeignKey(\"Author\", models.CASCADE))]),\n        ]\n\n    migration = Migration(\"0001_initial\", \"test_app\")\n    changes = migration.apply(self.make_project_state([]), self.make_project_state([self.author_empty, self.book]))\n    self.assertNumberMigrations(changes, \"test_app\", 1)\n    self.assertOperationTypes(changes, \"test_app\", 0, [\"CreateModel\", \"CreateModel\"])\n    self.assertMigrationDependencies(changes, \"test_app\", 0, [])\n"], "sample_911": ["def test_xref_consistency_with_add_function_parentheses(app, status, warning):\n    app.builder.build_all()\n\n    test = 'xref_consistency.html'\n    output = (app.outdir / test).read_text()\n\n        pattern = (r'{role}-role:.*?'\n                   r'<(?P<tag>{tag}) .*?class=[\"\\'](?P<classes>.*?)[\"\\'].*?>'\n                   r'.*'\n                   r'</(?P=tag)>').format(role=role, tag=tag)\n        result = re.search(pattern, output)\n        expect = '''\\"], "sample_1169": ["def test_issue_19661_latex():\n    a = Symbol('0')\n    assert latex(Commutator(Bd(a)**2, B(a))) == '- \\\\left[b_{0},{b^\\\\dagger_{0}}^{2}\\\\right]'\n"], "sample_660": ["def test_record_testsuite_property_multiple_calls(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats1\", \"all good\")\n            record_testsuite_property(\"stats2\", 10)\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p2_node = properties_node.find_nth_by_tag(\"property\", 1)\n    p1_node.assert_attr(name=\"stats1\", value=\"all good\")\n    p2_node.assert_attr(name=\"stats2\", value=\"10\")\n"], "sample_798": ["def test_ridge_classifier_cv_no_support_multilabel():\n    X, y = make_multilabel_classification(n_samples=10, random_state=0)\n    assert_raises(ValueError, RidgeClassifierCV().fit, X, y)\n"], "sample_1188": ["def test_pretty_print_unicode_d():\n    assert upretty(d[0]) == '(0|0)'\n    assert upretty(d[1]) == '(i_N|k_N)'\n    assert upretty(d[4]) == '(a) (i_N|k_N)'\n    assert upretty(d[5]) == '(a) (i_N|k_N) + (-b) (j_N|k_N)'\n    assert upretty(d[8]) == '(j_N|k_N) + (C.x**2 - \u222b f(b) db) (k_N|k_N)'\n    assert upretty(d[10]) == '(cos(a)) (i_C|k_N) + (-sin(a)) (j_C|k_N)'\n"], "sample_97": ["def test_nonexistent_file(self, mocked_modules, notify_mock):\n    self.reloader.watch_file(self.nonexistent_file)\n    with self.tick_twice():\n        # The file doesn't exist, so it shouldn't trigger a change.\n        pass\n    self.assertEqual(notify_mock.call_count, 0)\n"], "sample_851": ["def test_regression_multioutput_variance_weighted():\n    y_true = [[1, 2], [2.5, -1], [4.5, 3], [5, 7]]\n    y_pred = [[1, 1], [2, -1], [5, 4], [5, 6.5]]\n\n    r = r2_score(y_true, y_pred, multioutput='variance_weighted')\n    evs = explained_variance_score(y_true, y_pred, multioutput='variance_weighted')\n\n    assert_almost_equal(r, 0.94, decimal=2)\n    assert_almost_equal(evs, 0.94, decimal=2)\n"], "sample_449": ["def test_connection_close_header(self):\n    \"\"\"WSGIRequestHandler sets Connection: close for HEAD requests without Content-Length.\"\"\"\n\n        \"\"\"A WSGI app that returns a hello world without Content-Length.\"\"\"\n        start_response(\"200 OK\", [])\n        return [b\"Hello World\"]\n\n    rfile = BytesIO(b\"HEAD / HTTP/1.1\\r\\n\")\n    rfile.seek(0)\n\n    wfile = UnclosableBytesIO()\n\n        if mode == \"rb\":\n            return rfile\n        elif mode == \"wb\":\n            return wfile\n\n    request = Stub(makefile=makefile)\n    server = Stub(base_environ={}, get_app=lambda: test_app)\n\n    # Prevent logging from appearing in test output.\n    with self.assertLogs(\"django.server\", \"INFO\"):\n        # Instantiating a handler runs the request as side effect.\n        WSGIRequestHandler(request, \"192.168.0.2\", server)\n\n    wfile.seek(0)\n    lines = list(wfile.readlines())\n    self.assertIn(b\"Connection: close\\r\\n\", lines)\n"], "sample_756": ["def test_core_distances_calculation():\n    # Test the calculation of core distances\n    X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n    nbrs = NearestNeighbors(n_neighbors=3)\n    nbrs.fit(X)\n    clust = OPTICS(min_samples=3)\n    core_distances = clust._compute_core_distances_(X, nbrs)\n    expected_core_distances = np.array([5.65685425, 5.65685425, 5.65685425, 5.65685425, 5.65685425])\n    assert_allclose(core_distances, expected_core_distances)\n"], "sample_115": ["def test_sensitive_function_keyword_arguments_with_debug_false(self):\n    \"\"\"\n    Sensitive variables don't leak in the sensitive_variables decorator's\n    frame, when those variables are passed as keyword arguments to the\n    decorated function, even when DEBUG is False.\n    \"\"\"\n    self.verify_safe_response(sensitive_kwargs_function_caller, check_for_POST_params=False)\n    self.verify_safe_email(sensitive_kwargs_function_caller, check_for_POST_params=False)\n"], "sample_778": ["def test_nmf_max_iter():\n    # Test that the maximum number of iterations is reached\n    n_samples = 6\n    n_features = 5\n    n_components = 3\n    max_iter = 10\n\n    rng = np.random.mtrand.RandomState(42)\n    X = np.abs(rng.randn(n_samples, n_features))\n\n    for solver in ['cd', 'mu']:\n        model = nmf.NMF(n_components=n_components, solver=solver,\n                        max_iter=max_iter, random_state=42)\n        model.fit(X)\n        assert_equal(model.n_iter_, max_iter)\n"], "sample_72": ["def test_serialize_complex(self):\n    self.assertSerializedEqual(complex(1, 2))\n    self.assertSerializedResultEqual(\n        complex(1, 2),\n        (\"complex((1+2j))\", set())\n    )\n"], "sample_846": ["def test_column_transformer_remainder_transformer_with_empty_columns():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n\n    # second and third columns are doubled when remainder = DoubleTrans\n    X_res_both = X_array.copy()\n    X_res_both[:, 1:3] *= 2\n\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', 'drop', [1, 2])],\n                           remainder=DoubleTrans())\n\n    assert_array_equal(ct.fit_transform(X_array), X_res_both[:, 0].reshape(-1, 1))\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_both[:, 0].reshape(-1, 1))\n    assert len(ct.transformers_) == 3\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], DoubleTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n"], "sample_538": ["def test_transformwrapper_dimensions():\n    t = mtransforms.TransformWrapper(mtransforms.Affine2D())\n    with pytest.raises(ValueError, match=(\n            r\"The input and output dims of the new child \\(2, 3\\) \"\n            r\"do not match those of current child \\(2, 2\\)\")):\n        t.set(mtransforms.Affine2D().scale(1, 2, 3))\n"], "sample_850": ["def test_nystroem_kernel_params():\n    # Test Nystroem with kernel_params.\n    rnd = np.random.RandomState(42)\n    n_samples = 10\n    X = rnd.uniform(size=(n_samples, 4))\n\n        return np.exp(-gamma * np.sum((x - y) ** 2))\n\n    K = custom_kernel(X[:, np.newaxis, :], X[np.newaxis, :, :], gamma=0.5)\n    nystroem = Nystroem(kernel=custom_kernel, n_components=n_samples, kernel_params={'gamma': 0.5})\n    X_transformed = nystroem.fit_transform(X)\n    assert_array_almost_equal(np.dot(X_transformed, X_transformed.T), K)\n"], "sample_174": ["def test_explain_query_prefix_raise_not_supported_error(self):\n    msg = 'This backend does not support explaining query execution.'\n    with self.assertRaisesMessage(NotSupportedError, msg):\n        self.ops.explain_query_prefix()\n"], "sample_88": ["def test_send_messages_with_fail_silently(self):\n    \"\"\"A message isn't sent if it doesn't have any recipients and fail_silently is True.\"\"\"\n    backend = smtp.EmailBackend(fail_silently=True)\n    backend.connection = True\n    email = EmailMessage('Subject', 'Content', 'from@example.com', to=[])\n    sent = backend.send_messages([email])\n    self.assertEqual(sent, 0)\n"], "sample_552": ["def test_add_subplot_kwargs_with_sharex_sharey():\n    # fig.add_subplot() with sharex and sharey should create new axes with the same limits.\n    fig, ax1 = plt.subplots()\n    ax1.set_xlim(0, 10)\n    ax1.set_ylim(0, 10)\n    ax2 = fig.add_subplot(1, 1, 1, sharex=ax1, sharey=ax1)\n    assert ax2.get_xlim() == ax1.get_xlim()\n    assert ax2.get_ylim() == ax1.get_ylim()\n    plt.close()\n"], "sample_706": ["def test_operator_precedence() -> None:\n    matcher = {\"true\": True, \"false\": False}.__getitem__\n    assert evaluate(\"true or false and true\", matcher) is True\n    assert evaluate(\"true and false or true\", matcher) is True\n    assert evaluate(\"not true and false or true\", matcher) is True\n    assert evaluate(\"true and not false or true\", matcher) is True\n"], "sample_315": ["    def test_en_redirect_with_query_string(self):\n        response = self.client.get('/account/register/?param=value', HTTP_ACCEPT_LANGUAGE='en')\n        self.assertRedirects(response, '/en/account/register/?param=value')\n\n        response = self.client.get(response.headers['location'])\n        self.assertEqual(response.status_code, 200)\n"], "sample_601": ["def test_cftime_round_accessor(cftime_rounding_dataarray, cftime_date_type, use_dask):\n    import dask.array as da\n\n    freq = \"D\"\n    expected = xr.DataArray(\n        [\n            [cftime_date_type(1, 1, 1, 0), cftime_date_type(1, 1, 2, 0)],\n            [cftime_date_type(1, 1, 1, 0), cftime_date_type(1, 1, 2, 0)],\n        ],\n        name=\"round\",\n    )\n\n    if use_dask:\n        chunks = {\"dim_0\": 1}\n        # Currently a compute is done to inspect a single value of the array\n        # if it is of object dtype to check if it is a cftime.datetime (if not\n        # we raise an error when using the dt accessor).\n        with raise_if_dask_computes(max_computes=1):\n            result = cftime_rounding_dataarray.chunk(chunks).dt.round(freq)\n        expected = expected.chunk(chunks)\n        assert isinstance(result.data, da.Array)\n        assert result.chunks == expected.chunks\n    else:\n        result = cftime_rounding_dataarray.dt.round(freq)\n\n    assert_identical(result, expected)\n"], "sample_1092": ["def test_issue_18203_additional():\n    eq = CRootOf(x**5 + 11*x - 2, 0) - CRootOf(x**5 + 11*x - 2, 1)\n    assert cse(eq) == ([], [eq])\n"], "sample_600": ["def test_CFMaskCoder_encode_decode_with_fill_value():\n    original = xr.Variable((\"x\",), [0, 1, 2], {\"_FillValue\": 2})\n    expected = xr.Variable((\"x\",), [0, 1, np.nan], {\"_FillValue\": 2})\n    coder = variables.CFMaskCoder()\n    encoded = coder.encode(original)\n    decoded = coder.decode(encoded)\n    assert_identical(expected, decoded)\n"], "sample_1031": ["def test_quantity_scale_factor_dimension_match():\n    # check that scale factors are the right SI dimensions:\n    for _scale_factor, _dimension in zip(\n            Quantity.SI_quantity_scale_factors.values(),\n            Quantity.SI_quantity_dimension_map.values()):\n        dimex = Quantity.get_dimensional_expr(_scale_factor)\n        if dimex != 1:\n            assert dimsys_default.equivalent_dims(_dimension, Dimension(dimex))\n"], "sample_764": ["def test_column_transformer_remainder_transformer_with_empty_columns():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n\n    ct = ColumnTransformer([('trans1', 'drop', [0, 1, 2])],\n                           remainder=DoubleTrans())\n\n    assert_array_equal(ct.fit_transform(X_array), np.empty((3, 0)))\n    assert_array_equal(ct.fit(X_array).transform(X_array), np.empty((3, 0)))\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], DoubleTrans)\n    assert_array_equal(ct.transformers_[-1][2], [])\n"], "sample_836": ["def test_ovr_decision_function():\n    predictions = np.array([[0, 1, 2], [1, 2, 0]])\n    confidences = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]])\n    n_classes = 3\n    expected_output = np.array([[0.03333333, 0.33333333, 0.63333333],\n                                [0.36666667, 0.66666667, 0.06666667]])\n    output = _ovr_decision_function(predictions, confidences, n_classes)\n    assert_allclose(output, expected_output)\n"], "sample_560": ["def test_legend_loc_outside_figure():\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.plot([1, 2, 3], [1, 2, 3], label='Test')\n    with pytest.raises(ValueError, match=\"'outside' option for loc='right upper' keyword argument only works for figure legends\"):\n        ax.legend(loc='outside right upper')\n"], "sample_685": ["def test_caplog_records_for_all_stages(caplog, logging_during_setup_and_teardown):\n    assert not caplog.records\n    assert not caplog.get_records(\"call\")\n    logger.info(\"a_call_log\")\n    assert len(caplog.get_records(\"call\")) == 1\n    assert caplog.get_records(\"call\")[0].message == \"a_call_log\"\n\n    assert len(caplog.get_records(\"setup\")) == 1\n    assert caplog.get_records(\"setup\")[0].message == \"a_setup_log\"\n\n    # This reaches into private API, don't use this type of thing in real tests!\n    assert set(caplog._item._store[caplog_records_key]) == {\"setup\", \"call\", \"teardown\"}\n"], "sample_843": ["def test_kernel_bounds():\n    # Test that the bounds property of kernels is consistent with theta.\n    for kernel in kernels:\n        bounds = kernel.bounds\n        assert bounds.shape[0] == kernel.theta.shape[0]\n        assert np.all(bounds[:, 0] <= kernel.theta)\n        assert np.all(bounds[:, 1] >= kernel.theta)\n"], "sample_1158": ["def test_sympify_numpy_complex():\n    if not numpy:\n        skip(\"numpy not installed.\")\n\n    c1 = numpy.complex(1 + 2j)\n    c2 = numpy.complex64(1 + 2j)\n    c3 = numpy.complex128(1 + 2j)\n    c4 = numpy.longcomplex(1 + 2j)\n\n    assert sympify(c1) == S(1.0 + 2.0*I)\n    assert sympify(c2) == S(1.0 + 2.0*I)\n    assert sympify(c3) == S(1.0 + 2.0*I)\n    assert sympify(c4) == S(1.0 + 2.0*I)\n"], "sample_587": ["def test_merge_override(self):\n    ds1 = xr.Dataset({\"x\": 0})\n    ds2 = xr.Dataset({\"x\": 1})\n    expected = xr.Dataset({\"x\": 1})\n    actual = ds1.merge(ds2, compat=\"override\")\n    assert expected.identical(actual)\n"], "sample_970": ["def test_is_builtin_class_method_with_custom_class():\n    class MyClass:\n            pass\n\n            pass\n\n    assert inspect.is_builtin_class_method(MyClass, '__init__') is False\n    assert inspect.is_builtin_class_method(MyClass, 'my_method') is False\n"], "sample_150": ["def test_check_migrations_called(self, mocked_check_migrations):\n    command = BaseCommand()\n    command.requires_migrations_checks = True\n    command.execute()\n    self.assertTrue(mocked_check_migrations.called)\n"], "sample_972": ["def test_restify_type_hints_typevars_bound():\n    T = TypeVar('T', bound=int)\n    assert restify(T) == \":py:obj:`tests.test_util_typing.T`\"\n    assert restify(List[T]) == \":py:class:`~typing.List`\\\\ [:py:obj:`tests.test_util_typing.T`]\"\n"], "sample_1105": ["def test_matmul_with_noncommutative_scalars():\n    a, b = symbols('a b', commutative=False)\n    assert MatMul(a, A, b, A.T) == MatMul(a, b, A, A.T)\n    assert MatMul(a, A, b, A.T).doit() == a*b*A*A.T\n"], "sample_916": ["def test_xref_consistency_with_add_function_parentheses(app, status, warning):\n    app.builder.build_all()\n\n    test = 'xref_consistency.html'\n    output = (app.outdir / test).read_text()\n\n        pattern = (r'{role}-role:.*?'\n                   r'<(?P<tag>{tag}) .*?class=[\"\\'](?P<classes>.*?)[\"\\'].*?>'\n                   r'.*'\n                   r'</(?P=tag)>').format(role=role, tag=tag)\n        result = re.search(pattern, output)\n        expect = '''\\"], "sample_320": ["def test_references_field_by_through_fields(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ManyToManyField(\"Other\", through_fields=(\"from\", \"to\")),\n    )\n    self.assertIs(operation.references_field(\"Model\", \"from\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Model\", \"to\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Other\", \"from\", \"migrations\"), False)\n    self.assertIs(operation.references_field(\"Other\", \"to\", \"migrations\"), False)\n"], "sample_1157": ["def test_split_symbols_custom_predicate():\n        if symbol not in ('list', 'of', 'unsplittable', 'names'):\n                return _token_splittable(symbol)\n        return False\n\n    transformations = standard_transformations + (split_symbols_custom(can_split), implicit_multiplication)\n    x = Symbol('x')\n    y = Symbol('y')\n    unsplittable = Symbol('unsplittable')\n\n    assert parse_expr(\"unsplittable\", transformations=transformations) == unsplittable\n    assert parse_expr(\"xy\", transformations=transformations) == x*y\n"], "sample_947": ["def test_build_duplicate_declaration(app, warning):\n    app.builder.build_all()\n    ws = filter_warnings(warning, \"duplicate_declaration\")\n    assert len(ws) == 1\n    assert \"WARNING: Duplicate C declaration, also defined at index.rst:42.\" in ws[0]\n"], "sample_874": ["def test_get_feature_names_out():\n    sel = StepSelector()\n    sel.fit(X, y)\n    feature_names_out = sel.get_feature_names_out(input_features=feature_names)\n    assert_array_equal(feature_names_t, feature_names_out)\n"], "sample_1005": ["def test_Quaternion_latex_printing_with_zero_components():\n    q = Quaternion(0, 0, 0, 0)\n    assert latex(q) == \"0\"\n    q = Quaternion(0, y, 0, 0)\n    assert latex(q) == \"y i\"\n    q = Quaternion(0, 0, z, 0)\n    assert latex(q) == \"z j\"\n    q = Quaternion(0, 0, 0, t)\n    assert latex(q) == \"t k\"\n"], "sample_1153": ["def test_Abs_is_algebraic():\n    x = Symbol('x', algebraic=True)\n    y = Symbol('y', algebraic=False)\n    assert Abs(x).is_algebraic is True\n    assert Abs(y).is_algebraic is False\n    assert Abs(x + y).is_algebraic is False\n"], "sample_924": ["def test_build_domain_cpp_template_alias(app, status, warning):\n    app.builder.build_all()\n    ws = filter_warnings(warning, \"template-alias\")\n    assert len(ws) == 0\n"], "sample_308": ["def test_time_formats_with_microseconds(self):\n    dt = datetime(1979, 7, 8, 22, 0, 0, 123456)\n\n    self.assertEqual(dateformat.format(dt, 'u'), '123456')\n"], "sample_232": ["def test_key_transform_exact(self):\n    self.assertIs(NullableJSONModel.objects.filter(value__foo=KeyTransform('foo', 'value')).exists(), True)\n    self.assertIs(NullableJSONModel.objects.filter(value__foo=KeyTransform('bar', 'value')).exists(), False)\n"], "sample_610": ["def test_infer_freq_non_standard_calendar():\n    indx = xr.cftime_range(\"1990-02-03\", periods=4, freq=\"MS\", calendar=\"noleap\")\n    assert xr.infer_freq(indx) == \"MS\"\n"], "sample_455": ["def test_validate_expression_with_custom_error(self):\n    constraint = models.UniqueConstraint(Lower(\"name\"), name=\"name_lower_uniq\")\n    constraint.violation_error_message = \"Custom message\"\n    constraint.violation_error_code = \"custom_code\"\n    msg = \"Custom message\"\n    with self.assertRaisesMessage(ValidationError, msg) as cm:\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=self.p1.name.upper()),\n        )\n    self.assertEqual(cm.exception.code, \"custom_code\")\n"], "sample_576": ["def test_legend_with_facets(self, long_df):\n\n    p = Plot(long_df, x=\"x\", y=\"y\", color=\"a\").facet(col=\"b\").add(MockMark()).plot()\n    legend = p._figure.legends[0]\n    assert legend.get_title().get_text() == \"a\"\n    labels = [t.get_text() for t in legend.get_texts()]\n    assert labels == categorical_order(long_df[\"a\"])\n"], "sample_724": ["def test_imputation_invalid_strategy():\n    # Test imputation with an invalid strategy.\n    X = np.array([\n        [np.nan, 0, 0, 0, 5],\n        [np.nan, 1, 0, np.nan, 3],\n        [np.nan, 2, 0, 0, 0],\n        [np.nan, 6, 0, 5, 13],\n    ])\n\n    imputer = Imputer(strategy=\"invalid_strategy\")\n    assert_raises(ValueError, imputer.fit, X)\n"], "sample_242": ["def test_year_lookup_bounds(self):\n    lookup = YearLookup(Value(datetime(2022, 1, 1)), Value(2022))\n    connection = mock.MagicMock()\n    connection.ops.year_lookup_bounds_for_datetime_field.return_value = (datetime(2022, 1, 1), datetime(2022, 12, 31))\n    bounds = lookup.year_lookup_bounds(connection, 2022)\n    self.assertEqual(bounds, (datetime(2022, 1, 1), datetime(2022, 12, 31)))\n\n    lookup = YearLookup(Value(datetime(2022, 1, 1).date()), Value(2022))\n    connection.ops.year_lookup_bounds_for_date_field.return_value = (datetime(2022, 1, 1).date(), datetime(2022, 12, 31).date())\n    bounds = lookup.year_lookup_bounds(connection, 2022)\n    self.assertEqual(bounds, (datetime(2022, 1, 1).date(), datetime(2022, 12, 31).date()))\n"], "sample_842": ["def test_kernel_gradient_with_fixed_hyperparameters():\n    # Test that the gradient is zero for fixed hyperparameters.\n    kernel = RBF(length_scale=2.0, length_scale_bounds=\"fixed\")\n    _, K_gradient = kernel(X, eval_gradient=True)\n    assert_array_equal(K_gradient, np.zeros_like(K_gradient))\n"], "sample_1026": ["def test_lambdify_with_custom_printer():\n    class CustomPrinter(LambdaPrinter):\n            return f\"custom_{expr}\"\n\n    expr = x + y\n    f = lambdify((x, y), expr, printer=CustomPrinter())\n    assert f(1, 2) == 3\n"], "sample_153": ["def test_model_unpickle(self):\n    from django.apps import apps\n    from django.db.models import Model\n\n    model_id = ('app_label', 'ModelName')\n    with mock.patch.object(apps, 'get_model', return_value=Model) as mock_get_model:\n        model_instance = model_unpickle(model_id)\n        mock_get_model.assert_called_once_with(*model_id)\n        self.assertIsInstance(model_instance, Model)\n"], "sample_1056": ["def test_custom_printed_object():\n    obj = CustomPrintedObject()\n    assert lambdarepr(obj) == 'lambda'\n    assert TensorflowPrinter().doprint(obj) == 'tensorflow'\n    assert NumExprPrinter().doprint(obj) == 'numexpr'\n    assert LambdaPrinter({'method': 'numpy'}).doprint(obj) == 'numpy'\n    assert LambdaPrinter({'method': 'mpmath'}).doprint(obj) == 'mpmath'\n"], "sample_1076": ["def test_PythonCodePrinter_print_sign():\n    prntr = PythonCodePrinter()\n    assert prntr._print_sign(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n"], "sample_1057": ["def test_render_as_module():\n    from sympy import symbols\n\n    x, y = symbols('x y')\n    content = Print(x + y)\n    result = render_as_module(content)\n\n    assert 'from sympy import symbols' in result\n    assert 'from sympy.codegen.ast import Print' in result\n    assert 'print(x + y)' in result\n"], "sample_196": ["def test_explain_query_prefix_raise_not_supported_error(self):\n    msg = 'This backend does not support explaining query execution.'\n    with self.assertRaisesMessage(NotSupportedError, msg):\n        self.ops.explain_query_prefix()\n"], "sample_1106": ["def test_matadd_construction():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    matadd = MatAdd(A, B, C)\n    assert isinstance(matadd, MatAdd)\n    assert matadd.args == (A, B, C)\n    assert matadd.shape == (2, 2)\n"], "sample_1088": ["def test_viete():\n    assert viete(x**2 + x + 1, [a, b], x) == [(a + b, -1), (a*b, 1)]\n    assert viete(x**3 - x**2 - x + 1, [a, b, c], x) == [(a + b + c, 1), (a*b + a*c + b*c, -1), (a*b*c, -1)]\n    raises(ValueError, lambda: viete(1, [a], x))\n    raises(MultivariatePolynomialError, lambda: viete(x*y + x + y + 1, [a, b], x, y))\n"], "sample_1068": ["def test_DiracDelta_printing():\n    assert octave_code(DiracDelta(x)) == 'dirac(x)'\n    assert octave_code(DiracDelta(x, y)) == 'dirac(y, x)'\n"], "sample_973": ["def test_is_builtin_class_method_with_custom_class():\n    class MyCustomClass:\n            self.value = value\n\n            return f'MyCustomClass({self.value})'\n\n    assert inspect.is_builtin_class_method(MyCustomClass, '__init__') is False\n    assert inspect.is_builtin_class_method(MyCustomClass, '__str__') is False\n"], "sample_1154": ["def test__linsolve_complex():\n    eqs = [\n        x + I*y - 1,\n        x - I*y - 1\n    ]\n    sol = {x: 1/2, y: 1/2*I}\n    assert _linsolve(eqs, (x, y)) == sol\n"], "sample_1119": ["def test_matrix_pow():\n    assert MatPow(C, 2) == C*C\n    assert MatPow(C, -1) == Inverse(C)\n    assert MatPow(C, 0) == Identity(C.rows)\n    assert MatPow(C, 1) == C\n    assert MatPow(C, n) == C**n\n    assert MatPow(C, -n) == Inverse(C**n)\n"], "sample_1036": ["def test_matmul_args_cnc_symbols():\n    a, b = symbols('a b', commutative=False)\n    assert MatMul(n, a, b, A, A.T).args_cnc() == [[n], [a, b, A, A.T]]\n    assert MatMul(n, a, A, b, A.T).args_cnc() == [[n], [a, A, b, A.T]]\n"], "sample_927": ["def test_xref_consistency_cpp_expr(app, status, warning):\n    app.builder.build_all()\n\n    test = 'xref_consistency.html'\n    output = (app.outdir / test).read_text()\n\n    expr_classes = RoleClasses('cpp:expr', 'code', ['span'])\n    assert 'cpp-expr' in expr_classes.classes\n    assert 'cpp-expr' in expr_classes.content_classes['span']\n"], "sample_588": ["def test_auto_combine_with_no_dimension_coords(self):\n    objs = [Dataset({\"foo\": (\"x\", [0])}), Dataset({\"foo\": (\"x\", [1])})]\n    with pytest.warns(FutureWarning, match=\"The datasets supplied do not have global dimension coordinates\"):\n        auto_combine(objs)\n"], "sample_430": ["def test_alter_field_to_fk_dependency_other_app_with_initial_true(self):\n    class Migration(migrations.Migration):\n        initial = True\n        operations = [\n            migrations.CreateModel(\"Author\", fields=[(\"id\", models.AutoField(primary_key=True))]),\n            migrations.CreateModel(\"Book\", fields=[(\"author\", models.ForeignKey(\"Author\", models.CASCADE))]),\n        ]\n\n    migration = Migration(\"0001_initial\", \"test_app\")\n    changes = self.get_changes([], [migration])\n    self.assertNumberMigrations(changes, \"test_app\", 1)\n    self.assertOperationTypes(changes, \"test_app\", 0, [\"CreateModel\", \"CreateModel\"])\n    self.assertMigrationDependencies(changes, \"test_app\", 0, [])\n"], "sample_959": ["def test_domain_cpp_parse_noindexentry_with_template(app):\n    text = (\".. cpp:function:: template<typename T> void f()\\n\"\n            \".. cpp:function:: template<typename T> void g()\\n\"\n            \"   :noindexentry:\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index, desc, addnodes.index, desc))\n    assert_node(doctree[0], addnodes.index, entries=[('single', 'f (C++ function)', '_CPPv4I0E1fv', '', None)])\n    assert_node(doctree[2], addnodes.index, entries=[])\n"], "sample_1118": ["def test_matpow():\n    assert MatPow(C, 2).shape == (n, n)\n    assert MatPow(C, 0) == Identity(n)\n    assert MatPow(C, 1) == C\n    assert MatPow(C, -1) == Inverse(C)\n    raises(NonSquareMatrixError, lambda: MatPow(A, 2))\n    raises(NonInvertibleMatrixError, lambda: MatPow(ZeroMatrix(n, n), -1))\n"], "sample_969": ["def test_restify_type_ForwardRef_in_Union():\n    from typing import ForwardRef  # type: ignore\n    assert restify(Union[ForwardRef(\"myint\"), int]) == (\":py:obj:`~typing.Union`\\\\ \"\n                                                        \"[:py:class:`myint`, :py:class:`int`]\")\n"], "sample_1141": ["def test_MatrixSymbol_as_explicit():\n    A = MatrixSymbol('A', 2, 2)\n    A_explicit = A.as_explicit()\n    assert isinstance(A_explicit, ImmutableMatrix)\n    assert A_explicit.shape == A.shape\n    assert A_explicit[0, 0] == A[0, 0]\n    assert A_explicit[0, 1] == A[0, 1]\n    assert A_explicit[1, 0] == A[1, 0]\n    assert A_explicit[1, 1] == A[1, 1]\n"], "sample_1174": ["def test_issue_14692():\n    from sympy import principal_branch, polar_lift, exp_polar, I, pi\n    x = Symbol('x', real=True)\n    assert principal_branch(exp_polar(-I*pi/2)/polar_lift(x), 2*pi) == exp_polar(-I*pi/2)/x\n"], "sample_133": ["def test_i18n_language_with_custom_domain(self):\n    \"\"\"\n    Check if the JavaScript i18n view returns a complete language catalog\n    if a custom domain is used.\n    \"\"\"\n    with self.settings(LANGUAGE_CODE='en-us'), override('fr'):\n        response = self.client.get('/jsi18n/app6/custom_domain/')\n        self.assertContains(response, 'this app6 string with custom domain is to be translated')\n"], "sample_1058": ["def test_SymPyPrinter():\n    p = SymPyPrinter()\n    expr = acos(x)\n    assert p.doprint(expr) == 'sympy.acos(x)'\n    assert 'sympy' in p.module_imports\n"], "sample_828": ["def test_check_preserve_type_sparse():\n    # Ensures that type float32 is preserved for sparse matrices.\n    XA = csr_matrix(np.resize(np.arange(40), (5, 8)).astype(np.float32))\n    XB = csr_matrix(np.resize(np.arange(40), (5, 8)).astype(np.float32))\n\n    XA_checked, XB_checked = check_pairwise_arrays(XA, None)\n    assert_equal(XA_checked.dtype, np.float32)\n\n    # both float32\n    XA_checked, XB_checked = check_pairwise_arrays(XA, XB)\n    assert_equal(XA_checked.dtype, np.float32)\n    assert_equal(XB_checked.dtype, np.float32)\n\n    # mismatched A\n    XA_checked, XB_checked = check_pairwise_arrays(XA.astype(np.float), XB)\n    assert_equal(XA_checked.dtype, np.float)\n    assert_equal(XB_checked.dtype, np.float)\n\n    # mismatched B\n    XA_checked, XB_checked = check_pairwise_arrays(XA, XB.astype(np.float))\n    assert_equal(XA_checked.dtype, np.float)\n    assert_equal(XB_checked.dtype, np.float)\n"], "sample_827": ["def test_inplace_csr_row_normalize_l1():\n    X = np.array([[0, 3, 0],\n                  [2, 4, 0],\n                  [0, 0, 0],\n                  [9, 8, 7],\n                  [4, 0, 5]], dtype=np.float64)\n    X_csr = sp.csr_matrix(X)\n    X_normalized = X / np.sum(np.abs(X), axis=1, keepdims=True)\n    inplace_csr_row_normalize_l1(X_csr)\n    assert_array_almost_equal(X_csr.toarray(), X_normalized)\n\n    X = np.array([[0, 3, 0],\n                  [2, 4, 0],\n                  [0, 0, 0],\n                  [9, 8, 7],\n                  [4, 0, 5]], dtype=np.float32)\n    X_csr = sp.csr_matrix(X)\n    X_normalized = X / np.sum(np.abs(X), axis=1, keepdims=True)\n    inplace_csr_row_normalize_l1(X_csr)\n    assert_array_almost_equal(X_csr.toarray(), X_normalized)\n\n    X = np.array([[0, 3, 0],\n                  [2, 4, 0],\n                  [0, 0, 0],\n                  [9, 8, 7],\n                  [4, 0, 5]], dtype=np.int32)\n    X_csr = sp.csr_matrix(X)\n    X_normalized = X / np.sum(np.abs(X), axis=1, keepdims=True)\n    inplace_csr_row_normalize_l1(X_csr)\n    assert_array_almost_equal(X_csr.toarray(), X_normalized)\n"], "sample_154": ["    def test_database_checks_return_issues(self, mocked_check):\n        mocked_check.return_value = [('test_error', 'Test error message')]\n        issues = check_database_backends(databases=self.databases)\n        self.assertEqual(len(issues), 1)\n        self.assertEqual(issues[0], ('test_error', 'Test error message'))\n"], "sample_319": ["def test_alter_field_to_fk_dependency_other_app_with_initial_true(self):\n    class Migration(migrations.Migration):\n        initial = True\n        operations = [\n            migrations.CreateModel(\"Author\", fields=[(\"id\", models.AutoField(primary_key=True))]),\n            migrations.CreateModel(\"Book\", fields=[(\"author\", models.ForeignKey(\"Author\", models.CASCADE))]),\n        ]\n\n    migration = Migration(\"0001_initial\", \"test_app\")\n    autodetector = MigrationAutodetector(None, self.make_project_state([migration]))\n    changes = autodetector._detect_changes()\n    self.assertNumberMigrations(changes, \"test_app\", 1)\n    self.assertOperationTypes(changes, \"test_app\", 0, [\"CreateModel\", \"CreateModel\"])\n    self.assertMigrationDependencies(changes, \"test_app\", 0, [])\n"], "sample_415": ["def test_contains_expressions(self):\n    constraint_with_expressions = models.UniqueConstraint(\n        Lower(\"title\"),\n        F(\"author\"),\n        name=\"book_func_uq\",\n    )\n    constraint_without_expressions = models.UniqueConstraint(\n        fields=[\"foo\", \"bar\"],\n        name=\"unique_fields\",\n    )\n    self.assertTrue(constraint_with_expressions.contains_expressions)\n    self.assertFalse(constraint_without_expressions.contains_expressions)\n"], "sample_826": ["def test_one_hot_encoder_drop_first():\n    enc = OneHotEncoder(drop='first')\n    X = [['abc', 2, 55], ['def', 1, 55], ['abc', 3, 55]]\n    trans = enc.fit_transform(X).toarray()\n    exp = [[0, 1, 1], [1, 0, 1], [0, 1, 0]]\n    assert_array_equal(trans, exp)\n    dropped_cats = [cat[feature]\n                    for cat, feature in zip(enc.categories_,\n                                            enc.drop_idx_)]\n    assert_array_equal(dropped_cats, ['abc', 2, 55])\n    assert_array_equal(np.array(X, dtype=object),\n                       enc.inverse_transform(trans))\n"], "sample_781": ["def test_forest_feature_importances_shape():\n    X, y = make_classification(n_samples=15, n_features=10, random_state=1,\n                               n_classes=3)\n    clf = RandomForestClassifier(random_state=42).fit(X, y)\n    assert clf.feature_importances_.shape == (10,)\n"], "sample_195": ["def test_sql_flush_with_tables(self):\n    Author.objects.create(name='Test Author')\n    Book.objects.create(title='Test Book', author=Author.objects.first())\n    with transaction.atomic():\n        sql = connection.ops.sql_flush(no_style(), ['backends_author', 'backends_book'])\n        self.assertEqual(len(sql), 2)\n        self.assertIn('DELETE FROM \"backends_author\";', sql)\n        self.assertIn('DELETE FROM \"backends_book\";', sql)\n"], "sample_1152": ["def test_issue_18000():\n    x, y = symbols('x y', real=True)\n    e = sqrt(x**2 + y**2)\n    assert powsimp(e**2) == x**2 + y**2\n"], "sample_934": ["def test_xref_consistency_cpp_type(app, status, warning):\n    app.builder.build_all()\n\n    test = 'xref_consistency.html'\n    output = (app.outdir / test).read_text()\n\n    cpp_type = RoleClasses('cpp:type', 'a', ['span'])\n    assert 'xref' in cpp_type.classes\n    assert 'cpp' in cpp_type.classes\n    assert 'cpp-type' in cpp_type.classes\n    assert 'xref' in cpp_type.content_classes['span']\n    assert 'cpp' in cpp_type.content_classes['span']\n    assert 'cpp-type' in cpp_type.content_classes['span']\n"], "sample_132": ["    def test_unicode_error(self):\n        try:\n            ''.encode('ascii').decode('utf-8')\n        except UnicodeError:\n            exc_type, exc_value, tb = sys.exc_info()\n        request = self.rf.get('/test_view/')\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        html = reporter.get_traceback_html()\n        self.assertIn('<h2>Unicode error hint</h2>', html)\n        self.assertIn('The string that could not be encoded/decoded was: ', html)\n        self.assertIn('<strong>&#x27;&#x27;</strong>', html)\n"], "sample_731": ["def test_fetch_california_housing_return_X_y():\n    \"\"\"Test if fetch_california_housing returns data and target when return_X_y is True.\"\"\"\n    data, target = fetch_california_housing(return_X_y=True)\n    assert data.shape == (20640, 8)\n    assert target.shape == (20640,)\n"], "sample_603": ["def test_summarize_variable_with_unsafe_name_and_preview():\n    var = xr.DataArray(np.random.rand(3, 4), name=\"<test>\")\n    formatted = fh.summarize_variable(\"<test>\", var, preview=\"<unsafe>\")\n    assert \"&lt;test&gt;\" in formatted\n    assert \"&lt;unsafe&gt;\" in formatted\n"], "sample_935": ["def test_xref_consistency_cpp_expr(app, status, warning):\n    app.builder.build_all()\n\n    test = 'xref_consistency.html'\n    output = (app.outdir / test).read_text()\n\n    # Test the classes for the cpp:expr role\n    expr_classes = RoleClasses('cpp:expr', 'code', ['span'])\n    assert 'cpp-expr' in expr_classes.classes\n    assert 'cpp-expr' in expr_classes.content_classes['span']\n"], "sample_923": ["def test_build_domain_cpp_warn_template_param_qualified_name(app, status, warning):\n    app.builder.build_all()\n    ws = filter_warnings(warning, \"warn-template-param-qualified-name\")\n    assert len(ws) == 2\n    assert \"WARNING: cpp:type reference target not found: T::typeWarn\" in ws[0]\n    assert \"WARNING: cpp:type reference target not found: T::U::typeWarn\" in ws[1]\n"], "sample_302": ["    def test_runshell(self):\n        with mock.patch('subprocess.Popen') as mock_popen:\n            self.client.runshell(['-c', 'SELECT 1'])\n            mock_popen.assert_called_once()\n"], "sample_732": ["def test_subset_shuffle():\n    try:\n        data = fetch_kddcup99(subset='SF', download_if_missing=False)\n    except IOError:\n        raise SkipTest(\"kddcup99 dataset can not be loaded.\")\n\n    data_shuffled = fetch_kddcup99(subset='SF', shuffle=True, random_state=0)\n    assert_equal(data.data.shape, data_shuffled.data.shape)\n    assert_equal(data.target.shape, data_shuffled.target.shape)\n"], "sample_575": ["def test_label_concise(self, t):\n\n    s = Temporal().label(concise=True)\n    a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n    a.set_view_interval(10, 1000)\n    label, = a.major.formatter.format_ticks([100])\n    assert \"1970\" in label\n"], "sample_926": ["def test_xref_consistency_for_function_role(app, status, warning):\n    app.builder.build_all()\n\n    test = 'xref_consistency.html'\n    output = (app.outdir / test).read_text()\n\n    role_classes = RoleClasses('func', 'a', ['span'])\n    assert 'xref' in role_classes.classes\n    assert 'cpp' in role_classes.classes\n    assert 'cpp-func' in role_classes.classes\n    assert 'xref' in role_classes.content_classes['span']\n    assert 'cpp' in role_classes.content_classes['span']\n    assert 'cpp-func' in role_classes.content_classes['span']\n"], "sample_279": ["def test_opclasses_database_constraint(self):\n    UniqueConstraintProduct.objects.create(name='p1', color='red')\n    with self.assertRaises(IntegrityError):\n        UniqueConstraintProduct.objects.create(name='p1', color='RED')\n"], "sample_611": ["def test_date_range_like_leap_year(start, freq, cal_src, cal_tgt, use_cftime, exp0, exp_pd):\n    source = date_range(start, periods=2, freq=freq, calendar=cal_src)\n\n    out = date_range_like(source, cal_tgt, use_cftime=use_cftime)\n\n    assert len(out) == 2\n    assert infer_freq(out) == freq\n\n    assert out[0].isoformat().startswith(exp0)\n\n    if exp_pd:\n        assert isinstance(out, pd.DatetimeIndex)\n    else:\n        assert isinstance(out, CFTimeIndex)\n        assert out.calendar == cal_tgt\n"], "sample_1064": ["def test_MatrixElement_assignment():\n    A = MatrixSymbol(\"A\", 1, 3)\n    B = MatrixSymbol(\"B\", 1, 3)\n\n    F = A[0, 0]\n    F = B[0, 0]\n    assert tensorflow_code(F) == \"B[0, 0]\"\n"], "sample_948": ["def test_mix_decl_duplicate_with_different_signatures(app, warning):\n    # Test for duplicate declarations with different signatures\n    text = (\".. cpp:struct:: A\\n\"\n            \".. cpp:function:: void A()\\n\"\n            \".. cpp:function:: void A(int)\\n\")\n    restructuredtext.parse(app, text)\n    ws = warning.getvalue().split(\"\\n\")\n    assert len(ws) == 5\n    assert \"index.rst:2: WARNING: Duplicate C++ declaration, also defined at index:1.\" in ws[0]\n    assert \"Declaration is '.. cpp:function:: void A(int)'.\" in ws[1]\n    assert \"index.rst:3: WARNING: Duplicate C++ declaration, also defined at index:1.\" in ws[2]\n    assert \"Declaration is '.. cpp:struct:: A'.\" in ws[3]\n    assert ws[4] == \"\"\n"], "sample_1069": ["def test_octave_user_functions():\n    custom_functions = {\n        \"ceiling\": \"CEIL\",\n        \"Abs\": [(lambda x: not x.is_integer, \"fabs\"),\n                (lambda x: x.is_integer, \"ABS\")]\n    }\n    assert mcode(Abs(x) + ceiling(x), user_functions=custom_functions) == 'fabs(x) + CEIL(x)'\n"], "sample_1125": ["def test_operator_multiplication():\n    A = Operator('A')\n    B = Operator('B')\n    assert A*B != B*A\n    assert (A*B).is_commutative is False\n    assert (A*B*A).expand() == A**2*B + A*B*A\n"], "sample_723": ["def test_imputation_with_copy_false():\n    # Test imputation with copy=False.\n    X = np.array([\n        [np.nan, 0, 0, 0, 5],\n        [np.nan, 1, 0, np.nan, 3],\n        [np.nan, 2, 0, 0, 0],\n        [np.nan, 6, 0, 5, 13],\n    ])\n\n    X_imputed_mean = np.array([\n        [3, 5],\n        [1, 3],\n        [2, 7],\n        [6, 13],\n    ])\n\n    imputer = SimpleImputer(strategy=\"mean\", copy=False)\n    X_trans = imputer.fit_transform(X.copy())\n    assert_array_almost_equal(X_trans, X_imputed_mean)\n    assert_false(np.may_share_memory(X, X_trans))\n"], "sample_1142": ["def test_MatrixElement_diff_matrix():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    X = MatrixSymbol('X', n, n)\n    assert (A[0, 1]*B[1, 0]).diff(X) == ZeroMatrix(n, l)\n    assert (A[0, 1]*B[1, 0]).diff(A) == B[1, 0]*Identity(n)\n    assert (A[0, 1]*B[1, 0]).diff(B) == A[0, 1]*Identity(l)\n"], "sample_309": ["    def test_escape_leading_slashes(self):\n        self.assertEqual(escape_leading_slashes('//example.com'), '/%2Fexample.com')\n        self.assertEqual(escape_leading_slashes('/path'), '/path')\n        self.assertEqual(escape_leading_slashes('http://example.com'), 'http://example.com')\n"], "sample_1038": ["def test_MatrixElement_diff_with_Inverse():\n    A = MatrixSymbol('A', n, n)\n    i, j, k = symbols('i j k')\n    assert (A.I[i, j]).diff(A[k, l]) == -A.I[i, k]*A.I[l, j]\n"], "sample_431": ["def test_refresh_fk_on_delete_cascade(self):\n    a = Article.objects.create(\n        headline=\"Parrot programs in Python\",\n        pub_date=datetime(2005, 7, 28),\n    )\n    s1 = SelfRef.objects.create(article=a)\n    a.delete()\n    with self.assertRaises(ObjectDoesNotExist):\n        s1.refresh_from_db()\n"], "sample_604": ["def test_short_data_repr():\n    da = xr.DataArray(np.random.randn(100, 5, 1))\n    result = formatting.short_data_repr(da)\n    assert len(result.splitlines()) == 1\n\n    da = xr.DataArray(np.random.randn(1000000))\n    result = formatting.short_data_repr(da)\n    assert result == \"[1000000 values with dtype=float64]\"\n"], "sample_917": ["def test_xref_consistency_with_add_function_parentheses(app, status, warning):\n    app.builder.build_all()\n\n    test = 'xref_consistency.html'\n    output = (app.outdir / test).read_text()\n\n        pattern = (r'{role}-role:.*?'\n                   r'<(?P<tag>{tag}) .*?class=[\"\\'](?P<classes>.*?)[\"\\'].*?>'\n                   r'.*'\n                   r'</(?P=tag)>').format(role=role, tag=tag)\n        result = re.search(pattern, output)\n        expect = '''\\"], "sample_1159": ["def test_issue_17557():\n    z = -I*oo\n    assert z.is_imaginary is False\n    assert z.is_finite is False\n"], "sample_1173": ["def test_split_symbols_custom_predicate():\n        if symbol not in ('list', 'of', 'unsplittable', 'names'):\n                return _token_splittable(symbol)\n        return False\n\n    transformation = split_symbols_custom(can_split)\n    transformations = standard_transformations + (transformation, implicit_multiplication)\n\n    assert parse_expr('unsplittable', transformations=transformations) == Symbol('unsplittable')\n    assert parse_expr('splittable', transformations=transformations) != Symbol('splittable')\n"], "sample_1034": ["def test_apply_grover():\n    nqubits = 2\n    oracle = return_one_on_two\n    result = apply_grover(oracle, nqubits)\n    expected = IntQubit(2, nqubits)\n    assert qapply(result) == expected\n"], "sample_437": ["    def test_validate_thread_sharing_allowed(self):\n        connection.inc_thread_sharing()\n        self.assertTrue(connection.allow_thread_sharing)\n        connection.validate_thread_sharing()\n        connection.dec_thread_sharing()\n        self.assertFalse(connection.allow_thread_sharing)\n"], "sample_1155": ["def test_construct_domain_with_algebraic_numbers():\n    alg = QQ.algebraic_field(GoldenRatio)\n    assert construct_domain([GoldenRatio, 1/GoldenRatio], extension=True) == (\n        alg,\n        [alg.convert(GoldenRatio),\n         alg.convert(1/GoldenRatio)]\n    )\n"], "sample_1037": ["def test_MatMul_simplify():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    assert simplify(MatMul(A, B, C)) == MatMul(A*B, C)\n    assert simplify(MatMul(A, Identity(2), C)) == MatMul(A, C)\n    assert simplify(MatMul(A, ZeroMatrix(2, 2), C)) == ZeroMatrix(2, 2)\n"], "sample_1063": ["def test_issue_17000():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    f = lambdify(x, besselj(0, x), modules='scipy')\n    assert abs(f(1.3) - scipy.special.jv(0, 1.3)) <= 1e-10\n\n    f = lambdify(x, bessely(0, x), modules='scipy')\n    assert abs(f(1.3) - scipy.special.yv(0, 1.3)) <= 1e-10\n\n    f = lambdify(x, besseli(0, x), modules='scipy')\n    assert abs(f(1.3) - scipy.special.iv(0, 1.3)) <= 1e-10\n\n    f = lambdify(x, besselk(0, x), modules='scipy')\n    assert abs(f(1.3) - scipy.special.kv(0, 1.3)) <= 1e-10\n"], "sample_586": ["def test_concat_positions(self):\n    ds1 = Dataset({\"foo\": (\"x\", [1, 2])}, {\"x\": [0, 1]})\n    ds2 = Dataset({\"foo\": (\"x\", [3, 4])}, {\"x\": [2, 3]})\n    expected = Dataset({\"foo\": (\"x\", [1, 2, 3, 4])}, {\"x\": [0, 1, 2, 3]})\n    actual = concat([ds1, ds2], dim=\"x\", positions=[[0, 1], [2, 3]])\n    assert_identical(actual, expected)\n"], "sample_780": ["def test_lda_transform_input_format():\n    # Test LDA transform for sparse and dense input\n    # transform result should be the same for both dense and sparse input\n    n_components, X = _build_sparse_mtx()\n    lda = LatentDirichletAllocation(n_components=n_components, max_iter=1,\n                                    learning_method='batch',\n                                    total_samples=100, random_state=0)\n    lda.fit(X)\n    transform_1 = lda.transform(X)\n    transform_2 = lda.transform(X.toarray())\n    assert_array_almost_equal(transform_1, transform_2)\n"], "sample_1075": ["def test_beta_function_properties():\n    x, y = Symbol('x'), Symbol('y')\n\n    # Test the property B(a, 1) = 1/a\n    assert beta(x, 1) == 1/x\n\n    # Test the property B(a, b) = B(b, a)\n    assert beta(x, y) == beta(y, x)\n\n    # Test the property B(a, b) = Gamma(a) * Gamma(b) / Gamma(a + b)\n    assert beta(x, y) == expand_func(beta(x, y))\n\n    # Test the derivative of beta function with respect to x\n    assert diff(beta(x, y), x) == beta(x, y)*(digamma(x) - digamma(x + y))\n\n    # Test the derivative of beta function with respect to y\n    assert diff(beta(x, y), y) == beta(x, y)*(digamma(y) - digamma(x + y))\n\n    # Test the derivative of beta function with invalid argument index\n    with raises(ArgumentIndexError):\n        beta(x, y).fdiff(3)\n\n    # Test the conjugate of beta function\n    assert conjugate(beta(x, y)) == beta(conjugate(x), conjugate(y))\n"], "sample_906": ["def test_domain_cpp_parse_noindexentry_with_title(app):\n    text = (\".. cpp:function:: void f()\\n\"\n            \".. cpp:function:: void g()\\n\"\n            \"   :noindexentry:\\n\"\n            \"   :noindex:\\n\"\n            \"   :name: custom-title\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index, desc, addnodes.index, desc))\n    assert_node(doctree[0], addnodes.index, entries=[('single', 'f (C++ function)', '_CPPv41fv', '', None)])\n    assert_node(doctree[2], addnodes.index, entries=[('single', 'custom-title', 'custom-title', '', None)])\n"], "sample_825": ["def test_pls_algorithm_error():\n    d = load_linnerud()\n    X = d.data\n    Y = d.target\n    pls = pls_.PLSCanonical(algorithm=\"invalid_algorithm\")\n    assert_raise_message(ValueError, \"Got algorithm invalid_algorithm when only 'svd' and 'nipals' are known\",\n                         pls.fit, X, Y)\n"], "sample_1004": ["def test_CondSet_union():\n    input_conditionset1 = ConditionSet(x, x > 0, Interval(1, 4, False, False))\n    input_conditionset2 = ConditionSet(x, x < 3, Interval(2, 5, False, False))\n    output_conditionset = ConditionSet(x, Or(x > 0, x < 3), Interval(1, 5, False, False))\n    assert Union(input_conditionset1, input_conditionset2) == output_conditionset\n"], "sample_958": ["def test_domain_cpp_parse_noindexentry_with_title(app):\n    text = (\".. cpp:function:: void f()\\n\"\n            \".. cpp:function:: void g()\\n\"\n            \"   :noindexentry:\\n\"\n            \"   :noindex:\\n\"\n            \"   :name: custom-name\\n\"\n            \"   :title: Custom Title\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index, desc, addnodes.index, desc))\n    assert_node(doctree[0], addnodes.index, entries=[('single', 'f (C++ function)', '_CPPv41fv', '', None)])\n    assert_node(doctree[2], addnodes.index, entries=[('single', 'Custom Title', 'custom-name', '', None)])\n"], "sample_303": ["    def test_runshell(self, mock_run):\n        self.client.settings_to_cmd_args_env = mock.MagicMock(return_value=(['cmd'], {'env': 'value'}))\n        self.client.runshell('parameters')\n        mock_run.assert_called_once_with(['cmd'], env={'env': 'value', **os.environ}, check=True)\n"], "sample_1126": ["def test_operator_dagger():\n    A = Operator('A')\n    B = Operator('B')\n    assert Dagger(A*B) == Dagger(B)*Dagger(A)\n    assert Dagger(A+B) == Dagger(A) + Dagger(B)\n    assert Dagger(A**2) == Dagger(A)**2\n"], "sample_1117": ["def test_matrix_element_sets_hadamard():\n    from sympy.matrices.expressions.hadamard import HadamardProduct\n    X = MatrixSymbol('X', 4, 4)\n    Y = MatrixSymbol('Y', 4, 4)\n    assert ask(Q.integer_elements(HadamardProduct(X, Y)),\n                    Q.integer_elements(X) & Q.integer_elements(Y))\n    assert ask(Q.real_elements(HadamardProduct(X, Y)),\n                    Q.real_elements(X) & Q.real_elements(Y))\n    assert ask(Q.complex_elements(HadamardProduct(X, Y)),\n                    Q.complex_elements(X) & Q.complex_elements(Y))\n"], "sample_1035": ["def test_measure_partial():\n    from sympy.physics.quantum.qubit import Qubit, measure_partial\n    from sympy.physics.quantum.gate import H\n    from sympy.physics.quantum.qapply import qapply\n\n    c = H(0)*H(1)*Qubit('00')\n    q = qapply(c)\n    result = measure_partial(q, (0,))\n    expected = [(sqrt(2)*Qubit('00')/2 + sqrt(2)*Qubit('10')/2, 1/2), (sqrt(2)*Qubit('01')/2 + sqrt(2)*Qubit('11')/2, 1/2)]\n    assert result == expected\n"], "sample_1116": ["def test_inverse_derivative():\n    x = symbols('x')\n    A = MatrixSymbol('A', 2, 2, real=True)\n    B = Matrix([[x, 1], [2, x]])\n    assert Inverse(B)._eval_derivative_matrix_lines(x) == -B.I * B.diff(x) * B.I\n"], "sample_779": ["def test_check_class_weight_balanced_linear_classifier():\n    # check that check_class_weight_balanced_linear_classifier works on\n    # LinearRegression\n    check_class_weight_balanced_linear_classifier(\"LinearRegression\", LinearRegression)\n"], "sample_454": ["def test_validate_custom_error_message(self):\n    constraint = models.CheckConstraint(\n        check=models.Q(price__gt=0),\n        name=\"positive_price\",\n        violation_error_message=\"Price must be positive\",\n    )\n    invalid_product = Product(price=-10, discounted_price=5)\n    msg = \"Price must be positive\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        constraint.validate(Product, invalid_product)\n"], "sample_1087": ["def test_fateman_poly_F_3():\n    f, g, h = fateman_poly_F_3(1)\n    F, G, H = dmp_fateman_poly_F_3(1, ZZ)\n\n    assert [t.rep.rep for t in [f, g, h]] == [F, G, H]\n\n    f, g, h = fateman_poly_F_3(3)\n    F, G, H = dmp_fateman_poly_F_3(3, ZZ)\n\n    assert [t.rep.rep for t in [f, g, h]] == [F, G, H]\n"], "sample_243": ["def test_filter_with_f_expression(self):\n    query = Query(Item)\n    where = query.build_where(Q(modified__gt=F('created')))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertIsInstance(lookup.lhs, Col)\n    self.assertIsInstance(lookup.rhs, Col)\n    self.assertEqual(lookup.lhs.target, Item._meta.get_field('modified'))\n    self.assertEqual(lookup.rhs.target, Item._meta.get_field('created'))\n"], "sample_1025": ["def test_PythonCodePrinter_with_custom_functions():\n    prntr = PythonCodePrinter({'user_functions': {'custom_func': 'my_module.custom_func'}})\n    assert prntr.doprint(custom_func(x)) == 'my_module.custom_func(x)'\n"], "sample_976": ["def test_symbol_assumptions():\n    x = Symbol('x', real=True, positive=True)\n    assert x.is_real\n    assert x.is_positive\n\n    y = Symbol('y', integer=True, negative=True)\n    assert y.is_integer\n    assert y.is_negative\n\n    z = Symbol('z', complex=True, zero=True)\n    assert z.is_complex\n    assert z.is_zero\n\n    raises(ValueError, lambda: Symbol('a', commutative=None))\n"], "sample_907": ["def test_domain_cpp_parse_noindexentry_with_name(app):\n    text = (\".. cpp:function:: void f()\\n\"\n            \"   :name: my_function\\n\"\n            \".. cpp:function:: void g()\\n\"\n            \"   :noindexentry:\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index, desc, addnodes.index, desc))\n    assert_node(doctree[0], addnodes.index, entries=[('single', 'my_function (C++ function)', 'my_function', '', None)])\n    assert_node(doctree[2], addnodes.index, entries=[])\n"], "sample_873": ["def test_get_feature_names_out():\n    sel = StepSelector()\n    sel.fit(X, y)\n    feature_names_out_actual = sel.get_feature_names_out(input_features=feature_names)\n    assert_array_equal(feature_names_t, feature_names_out_actual)\n\n    # Check with None input_features\n    feature_names_out_actual = sel.get_feature_names_out()\n    assert_array_equal(feature_names_t, feature_names_out_actual)\n\n    # Check with mismatched input_features\n    with pytest.raises(ValueError):\n        sel.get_feature_names_out(input_features=feature_names[:-1])\n"]}, "raw_scored_generations": {"sample_0": [false], "sample_3": [false], "sample_1": [false], "sample_2": [true], "sample_4": [false], "sample_5": [false], "sample_6": [true], "sample_7": [true], "sample_8": [false], "sample_9": [false], "sample_10": [false], "sample_11": [true], "sample_12": [true], "sample_13": [true], "sample_14": [true], "sample_15": [false], "sample_16": [false], "sample_17": [false], "sample_18": [false], "sample_19": [true], "sample_20": [false], "sample_21": [false], "sample_22": [false], "sample_23": [false], "sample_24": [false], "sample_25": [false], "sample_26": [false], "sample_27": [false], "sample_28": [false], "sample_29": [false], "sample_30": [false], "sample_31": [false], "sample_32": [false], "sample_33": [false], "sample_34": [true], "sample_35": [false], "sample_36": [true], "sample_37": [false], "sample_38": [false], "sample_39": [true], "sample_40": [false], "sample_41": [false], "sample_42": [false], "sample_43": [false], "sample_44": [false], "sample_45": [false], "sample_46": [true], "sample_47": [false], "sample_48": [true], "sample_49": [false], "sample_50": [true], "sample_51": [true], "sample_52": [true], "sample_54": [true], "sample_53": [true], "sample_55": [true], "sample_58": [true], "sample_56": [true], "sample_57": [false], "sample_59": [true], "sample_60": [false], "sample_61": [false], "sample_62": [true], "sample_63": [true], "sample_64": [true], "sample_65": [true], "sample_67": [true], "sample_66": [true], "sample_68": [false], "sample_69": [true], "sample_70": [false], "sample_71": [false], "sample_72": [true], "sample_73": [true], "sample_75": [true], "sample_74": [true], "sample_76": [true], "sample_77": [true], "sample_78": [true], "sample_79": [false], "sample_80": [true], "sample_82": [true], "sample_81": [true], "sample_83": [false], "sample_85": [true], "sample_84": [true], "sample_86": [true], "sample_88": [true], "sample_87": [true], "sample_89": [true], "sample_90": [true], "sample_91": [true], "sample_92": [false], "sample_93": [true], "sample_94": [true], "sample_95": [false], "sample_98": [false], "sample_96": [false], "sample_99": [false], "sample_97": [true], "sample_100": [true], "sample_102": [true], "sample_101": [true], "sample_103": [true], "sample_104": [true], "sample_107": [true], "sample_106": [true], "sample_105": [true], "sample_108": [false], "sample_109": [true], "sample_111": [true], "sample_110": [true], "sample_112": [true], "sample_113": [true], "sample_114": [true], "sample_115": [false], "sample_116": [true], "sample_117": [false], "sample_118": [true], "sample_119": [true], "sample_120": [true], "sample_121": [true], "sample_122": [true], "sample_123": [true], "sample_124": [true], "sample_125": [true], "sample_126": [true], "sample_127": [true], "sample_128": [true], "sample_129": [true], "sample_130": [true], "sample_131": [true], "sample_132": [false], "sample_133": [true], "sample_135": [true], "sample_134": [true], "sample_136": [true], "sample_139": [true], "sample_137": [true], "sample_138": [true], "sample_140": [false], "sample_141": [true], "sample_142": [true], "sample_143": [true], "sample_144": [true], "sample_145": [false], "sample_146": [true], "sample_147": [true], "sample_148": [true], "sample_151": [true], "sample_149": [false], "sample_152": [false], "sample_150": [true], "sample_153": [true], "sample_154": [false], "sample_155": [true], "sample_156": [true], "sample_157": [false], "sample_158": [true], "sample_159": [false], "sample_160": [false], "sample_161": [true], "sample_162": [true], "sample_163": [true], "sample_164": [true], "sample_165": [true], "sample_166": [true], "sample_167": [false], "sample_168": [false], "sample_169": [true], "sample_171": [true], "sample_170": [false], "sample_172": [true], "sample_173": [true], "sample_174": [true], "sample_175": [true], "sample_176": [true], "sample_177": [true], "sample_178": [false], "sample_180": [true], "sample_179": [true], "sample_182": [true], "sample_181": [true], "sample_183": [true], "sample_184": [true], "sample_185": [true], "sample_186": [true], "sample_187": [true], "sample_188": [true], "sample_189": [false], "sample_190": [true], "sample_191": [true], "sample_192": [false], "sample_193": [true], "sample_194": [true], "sample_195": [true], "sample_196": [true], "sample_198": [true], "sample_197": [true], "sample_199": [true], "sample_200": [false], "sample_201": [true], "sample_202": [true], "sample_203": [true], "sample_204": [true], "sample_205": [false], "sample_206": [true], "sample_207": [true], "sample_208": [true], "sample_209": [false], "sample_210": [true], "sample_211": [true], "sample_213": [true], "sample_212": [false], "sample_214": [true], "sample_215": [false], "sample_216": [true], "sample_217": [true], "sample_218": [false], "sample_219": [true], "sample_220": [true], "sample_221": [true], "sample_222": [true], "sample_223": [true], "sample_224": [true], "sample_225": [false], "sample_226": [true], "sample_227": [true], "sample_228": [false], "sample_229": [true], "sample_230": [true], "sample_231": [false], "sample_232": [true], "sample_233": [true], "sample_234": [true], "sample_235": [false], "sample_236": [true], "sample_237": [true], "sample_238": [true], "sample_239": [false], "sample_240": [true], "sample_241": [true], "sample_242": [true], "sample_243": [true], "sample_244": [true], "sample_245": [true], "sample_246": [true], "sample_247": [true], "sample_248": [true], "sample_249": [false], "sample_250": [true], "sample_251": [true], "sample_252": [true], "sample_253": [true], "sample_254": [true], "sample_256": [true], "sample_255": [true], "sample_257": [true], "sample_258": [false], "sample_259": [true], "sample_260": [true], "sample_261": [true], "sample_262": [false], "sample_263": [true], "sample_264": [true], "sample_265": [true], "sample_266": [true], "sample_267": [true], "sample_268": [true], "sample_269": [true], "sample_270": [true], "sample_271": [true], "sample_272": [false], "sample_273": [true], "sample_274": [true], "sample_275": [true], "sample_276": [true], "sample_277": [true], "sample_278": [true], "sample_279": [true], "sample_280": [true], "sample_281": [true], "sample_282": [true], "sample_283": [true], "sample_284": [true], "sample_285": [true], "sample_286": [true], "sample_287": [true], "sample_288": [true], "sample_289": [true], "sample_290": [true], "sample_291": [true], "sample_292": [true], "sample_293": [false], "sample_294": [true], "sample_295": [true], "sample_296": [true], "sample_297": [true], "sample_298": [true], "sample_299": [true], "sample_300": [true], "sample_301": [true], "sample_302": [false], "sample_303": [false], "sample_304": [false], "sample_305": [true], "sample_306": [false], "sample_307": [true], "sample_308": [true], "sample_309": [true], "sample_310": [true], "sample_312": [true], "sample_311": [true], "sample_313": [true], "sample_314": [false], "sample_315": [true], "sample_316": [true], "sample_317": [true], "sample_318": [false], "sample_319": [true], "sample_320": [true], "sample_321": [true], "sample_322": [false], "sample_323": [false], "sample_324": [true], "sample_325": [true], "sample_326": [true], "sample_327": [false], "sample_328": [true], "sample_329": [true], "sample_330": [true], "sample_331": [true], "sample_332": [false], "sample_333": [true], "sample_334": [true], "sample_335": [true], "sample_336": [false], "sample_337": [true], "sample_338": [true], "sample_339": [true], "sample_340": [true], "sample_341": [true], "sample_342": [false], "sample_343": [true], "sample_344": [true], "sample_345": [true], "sample_346": [false], "sample_347": [true], "sample_348": [false], "sample_349": [true], "sample_350": [true], "sample_351": [true], "sample_352": [true], "sample_353": [true], "sample_354": [true], "sample_355": [false], "sample_356": [true], "sample_357": [true], "sample_358": [false], "sample_359": [true], "sample_360": [true], "sample_361": [true], "sample_362": [true], "sample_363": [true], "sample_364": [false], "sample_365": [false], "sample_366": [true], "sample_367": [false], "sample_368": [true], "sample_369": [true], "sample_370": [true], "sample_371": [true], "sample_372": [false], "sample_373": [true], "sample_374": [true], "sample_375": [true], "sample_376": [true], "sample_377": [false], "sample_378": [true], "sample_379": [true], "sample_380": [true], "sample_381": [true], "sample_382": [true], "sample_383": [true], "sample_384": [true], "sample_385": [true], "sample_386": [true], "sample_387": [true], "sample_388": [false], "sample_389": [false], "sample_390": [true], "sample_391": [true], "sample_392": [true], "sample_393": [true], "sample_394": [true], "sample_395": [true], "sample_396": [true], "sample_397": [true], "sample_398": [true], "sample_399": [true], "sample_400": [true], "sample_401": [true], "sample_402": [true], "sample_403": [true], "sample_404": [true], "sample_405": [true], "sample_406": [true], "sample_407": [false], "sample_408": [true], "sample_409": [true], "sample_410": [true], "sample_411": [true], "sample_412": [true], "sample_413": [false], "sample_414": [true], "sample_415": [true], "sample_416": [true], "sample_417": [true], "sample_418": [true], "sample_419": [false], "sample_420": [true], "sample_421": [true], "sample_422": [true], "sample_423": [true], "sample_424": [true], "sample_425": [true], "sample_426": [false], "sample_427": [true], "sample_428": [false], "sample_429": [true], "sample_430": [true], "sample_431": [true], "sample_432": [true], "sample_433": [true], "sample_434": [true], "sample_435": [false], "sample_436": [true], "sample_437": [true], "sample_438": [true], "sample_439": [true], "sample_440": [true], "sample_441": [false], "sample_442": [false], "sample_443": [true], "sample_444": [true], "sample_445": [true], "sample_446": [true], "sample_447": [true], "sample_448": [true], "sample_449": [false], "sample_450": [true], "sample_451": [true], "sample_453": [true], "sample_452": [true], "sample_454": [true], "sample_455": [true], "sample_456": [true], "sample_457": [true], "sample_458": [true], "sample_459": [true], "sample_460": [true], "sample_461": [true], "sample_462": [true], "sample_463": [true], "sample_464": [true], "sample_465": [false], "sample_466": [true], "sample_467": [true], "sample_469": [true], "sample_468": [true], "sample_470": [false], "sample_471": [true], "sample_472": [true], "sample_473": [false], "sample_474": [true], "sample_475": [false], "sample_476": [false], "sample_477": [true], "sample_478": [false], "sample_479": [true], "sample_480": [true], "sample_481": [true], "sample_482": [true], "sample_483": [true], "sample_484": [true], "sample_485": [true], "sample_486": [true], "sample_487": [false], "sample_488": [true], "sample_489": [true], "sample_490": [true], "sample_491": [true], "sample_492": [true], "sample_493": [true], "sample_494": [true], "sample_495": [false], "sample_496": [true], "sample_497": [true], "sample_498": [false], "sample_499": [true], "sample_500": [true], "sample_501": [true], "sample_502": [false], "sample_503": [true], "sample_504": [true], "sample_505": [false], "sample_506": [true], "sample_507": [false], "sample_508": [false], "sample_509": [false], "sample_510": [false], "sample_511": [false], "sample_512": [false], "sample_513": [true], "sample_514": [true], "sample_515": [false], "sample_516": [false], "sample_517": [false], "sample_518": [true], "sample_519": [true], "sample_520": [false], "sample_521": [false], "sample_522": [false], "sample_523": [true], "sample_524": [true], "sample_525": [true], "sample_526": [false], "sample_527": [false], "sample_528": [true], "sample_529": [true], "sample_530": [true], "sample_531": [false], "sample_532": [false], "sample_533": [false], "sample_534": [true], "sample_535": [false], "sample_536": [true], "sample_537": [false], "sample_538": [false], "sample_539": [false], "sample_540": [false], "sample_541": [false], "sample_542": [true], "sample_543": [true], "sample_544": [false], "sample_545": [false], "sample_546": [false], "sample_547": [false], "sample_548": [true], "sample_549": [true], "sample_550": [false], "sample_551": [false], "sample_552": [true], "sample_553": [false], "sample_554": [true], "sample_555": [true], "sample_556": [false], "sample_557": [false], "sample_558": [false], "sample_559": [false], "sample_560": [false], "sample_561": [true], "sample_562": [false], "sample_563": [false], "sample_564": [false], "sample_565": [false], "sample_566": [false], "sample_567": [true], "sample_568": [false], "sample_569": [false], "sample_570": [false], "sample_571": [false], "sample_572": [false], "sample_573": [false], "sample_574": [false], "sample_575": [false], "sample_576": [false], "sample_577": [false], "sample_578": [false], "sample_579": [false], "sample_580": [false], "sample_581": [false], "sample_582": [true], "sample_583": [false], "sample_584": [false], "sample_585": [false], "sample_586": [false], "sample_587": [false], "sample_588": [false], "sample_589": [false], "sample_590": [false], "sample_591": [false], "sample_592": [false], "sample_593": [true], "sample_594": [false], "sample_595": [true], "sample_596": [true], "sample_597": [false], "sample_598": [false], "sample_599": [true], "sample_600": [false], "sample_601": [false], "sample_602": [false], "sample_603": [false], "sample_604": [false], "sample_605": [true], "sample_606": [false], "sample_607": [false], "sample_608": [false], "sample_609": [false], "sample_610": [true], "sample_611": [false], "sample_612": [false], "sample_613": [false], "sample_614": [true], "sample_615": [false], "sample_616": [false], "sample_617": [true], "sample_618": [true], "sample_619": [false], "sample_620": [false], "sample_621": [false], "sample_622": [false], "sample_623": [false], "sample_624": [false], "sample_625": [false], "sample_626": [false], "sample_627": [false], "sample_628": [false], "sample_629": [false], "sample_630": [false], "sample_631": [false], "sample_632": [false], "sample_633": [false], "sample_634": [false], "sample_635": [false], "sample_636": [false], "sample_637": [false], "sample_638": [false], "sample_639": [false], "sample_640": [false], "sample_641": [false], "sample_642": [true], "sample_643": [false], "sample_644": [false], "sample_645": [true], "sample_646": [false], "sample_647": [false], "sample_648": [false], "sample_649": [false], "sample_650": [false], "sample_651": [false], "sample_652": [false], "sample_653": [false], "sample_654": [false], "sample_655": [false], "sample_656": [false], "sample_657": [false], "sample_658": [false], "sample_659": [false], "sample_660": [false], "sample_661": [false], "sample_662": [false], "sample_663": [false], "sample_664": [false], "sample_665": [false], "sample_666": [true], "sample_667": [true], "sample_668": [false], "sample_669": [false], "sample_670": [false], "sample_671": [false], "sample_672": [false], "sample_673": [false], "sample_674": [false], "sample_675": [false], "sample_676": [false], "sample_677": [false], "sample_678": [true], "sample_679": [false], "sample_680": [false], "sample_681": [false], "sample_682": [false], "sample_683": [true], "sample_684": [false], "sample_685": [false], "sample_686": [false], "sample_687": [true], "sample_688": [false], "sample_689": [false], "sample_690": [false], "sample_691": [false], "sample_692": [false], "sample_693": [false], "sample_694": [false], "sample_695": [false], "sample_696": [false], "sample_697": [true], "sample_698": [true], "sample_699": [false], "sample_700": [false], "sample_701": [false], "sample_702": [false], "sample_703": [false], "sample_704": [false], "sample_705": [false], "sample_706": [true], "sample_707": [false], "sample_708": [false], "sample_709": [false], "sample_710": [false], "sample_711": [false], "sample_712": [true], "sample_713": [false], "sample_714": [false], "sample_715": [false], "sample_716": [false], "sample_717": [true], "sample_718": [false], "sample_719": [false], "sample_720": [false], "sample_721": [false], "sample_722": [false], "sample_723": [false], "sample_724": [true], "sample_725": [false], "sample_726": [true], "sample_727": [true], "sample_728": [false], "sample_729": [true], "sample_730": [true], "sample_731": [true], "sample_732": [true], "sample_733": [false], "sample_734": [true], "sample_735": [true], "sample_736": [false], "sample_737": [false], "sample_738": [false], "sample_739": [true], "sample_740": [false], "sample_741": [false], "sample_742": [false], "sample_743": [false], "sample_744": [false], "sample_745": [true], "sample_746": [true], "sample_747": [false], "sample_748": [false], "sample_749": [false], "sample_750": [false], "sample_751": [false], "sample_752": [false], "sample_753": [false], "sample_754": [false], "sample_755": [true], "sample_756": [false], "sample_757": [false], "sample_758": [false], "sample_759": [true], "sample_760": [true], "sample_761": [true], "sample_762": [false], "sample_763": [false], "sample_764": [false], "sample_765": [false], "sample_766": [true], "sample_767": [false], "sample_768": [false], "sample_769": [false], "sample_770": [true], "sample_771": [false], "sample_772": [false], "sample_773": [false], "sample_774": [false], "sample_775": [false], "sample_776": [false], "sample_777": [true], "sample_778": [false], "sample_779": [false], "sample_780": [true], "sample_781": [false], "sample_782": [false], "sample_783": [false], "sample_784": [false], "sample_785": [false], "sample_786": [false], "sample_787": [false], "sample_788": [false], "sample_789": [false], "sample_790": [false], "sample_791": [false], "sample_792": [true], "sample_793": [true], "sample_794": [false], "sample_795": [false], "sample_796": [true], "sample_797": [false], "sample_798": [false], "sample_799": [false], "sample_800": [false], "sample_801": [false], "sample_802": [true], "sample_803": [true], "sample_804": [false], "sample_805": [false], "sample_806": [false], "sample_807": [false], "sample_808": [false], "sample_809": [true], "sample_810": [false], "sample_811": [true], "sample_812": [false], "sample_813": [true], "sample_814": [false], "sample_815": [true], "sample_816": [false], "sample_817": [true], "sample_818": [false], "sample_819": [false], "sample_820": [true], "sample_821": [true], "sample_822": [true], "sample_823": [true], "sample_824": [true], "sample_825": [true], "sample_826": [false], "sample_827": [false], "sample_828": [true], "sample_829": [true], "sample_830": [false], "sample_831": [true], "sample_832": [true], "sample_833": [false], "sample_834": [false], "sample_835": [true], "sample_836": [false], "sample_837": [false], "sample_838": [false], "sample_839": [false], "sample_840": [false], "sample_841": [false], "sample_842": [true], "sample_843": [false], "sample_844": [false], "sample_845": [false], "sample_846": [false], "sample_847": [true], "sample_848": [false], "sample_849": [false], "sample_850": [false], "sample_851": [true], "sample_852": [true], "sample_853": [true], "sample_854": [false], "sample_855": [false], "sample_856": [false], "sample_857": [false], "sample_858": [true], "sample_859": [false], "sample_860": [true], "sample_861": [false], "sample_862": [false], "sample_863": [true], "sample_864": [false], "sample_865": [true], "sample_866": [true], "sample_867": [false], "sample_868": [false], "sample_869": [false], "sample_870": [false], "sample_871": [true], "sample_872": [false], "sample_873": [false], "sample_874": [true], "sample_875": [false], "sample_876": [false], "sample_877": [false], "sample_878": [false], "sample_879": [false], "sample_880": [false], "sample_881": [false], "sample_882": [false], "sample_883": [false], "sample_884": [true], "sample_885": [true], "sample_886": [true], "sample_887": [false], "sample_888": [false], "sample_889": [false], "sample_890": [false], "sample_891": [false], "sample_892": [true], "sample_893": [false], "sample_894": [false], "sample_895": [false], "sample_896": [true], "sample_897": [false], "sample_898": [false], "sample_899": [false], "sample_900": [true], "sample_901": [true], "sample_902": [false], "sample_903": [false], "sample_904": [false], "sample_905": [true], "sample_906": [false], "sample_907": [false], "sample_908": [true], "sample_909": [false], "sample_910": [true], "sample_911": [false], "sample_912": [true], "sample_913": [true], "sample_914": [false], "sample_915": [false], "sample_916": [false], "sample_917": [false], "sample_918": [true], "sample_919": [false], "sample_920": [false], "sample_921": [false], "sample_922": [true], "sample_923": [false], "sample_924": [true], "sample_925": [false], "sample_926": [false], "sample_927": [false], "sample_928": [false], "sample_929": [true], "sample_930": [false], "sample_931": [false], "sample_932": [false], "sample_933": [false], "sample_934": [false], "sample_935": [false], "sample_936": [true], "sample_937": [false], "sample_938": [false], "sample_939": [false], "sample_940": [false], "sample_941": [true], "sample_942": [true], "sample_943": [false], "sample_944": [true], "sample_945": [true], "sample_946": [true], "sample_947": [false], "sample_948": [false], "sample_949": [false], "sample_950": [true], "sample_951": [true], "sample_952": [true], "sample_953": [true], "sample_954": [false], "sample_955": [true], "sample_956": [false], "sample_957": [false], "sample_958": [false], "sample_959": [false], "sample_960": [true], "sample_961": [true], "sample_962": [false], "sample_963": [true], "sample_964": [true], "sample_965": [false], "sample_966": [true], "sample_967": [false], "sample_968": [false], "sample_969": [true], "sample_970": [false], "sample_971": [false], "sample_972": [true], "sample_973": [false], "sample_974": [false], "sample_975": [false], "sample_976": [false], "sample_977": [false], "sample_978": [false], "sample_979": [false], "sample_980": [true], "sample_981": [true], "sample_982": [false], "sample_983": [true], "sample_984": [false], "sample_985": [false], "sample_986": [false], "sample_987": [true], "sample_988": [true], "sample_989": [true], "sample_990": [false], "sample_991": [false], "sample_992": [false], "sample_993": [false], "sample_994": [false], "sample_995": [true], "sample_996": [false], "sample_997": [true], "sample_998": [false], "sample_999": [false], "sample_1000": [true], "sample_1001": [false], "sample_1002": [true], "sample_1003": [true], "sample_1004": [false], "sample_1005": [false], "sample_1006": [true], "sample_1007": [true], "sample_1008": [false], "sample_1009": [true], "sample_1010": [false], "sample_1011": [true], "sample_1012": [true], "sample_1013": [true], "sample_1014": [false], "sample_1015": [true], "sample_1016": [true], "sample_1017": [true], "sample_1018": [false], "sample_1019": [true], "sample_1020": [false], "sample_1021": [true], "sample_1022": [false], "sample_1023": [false], "sample_1024": [true], "sample_1025": [false], "sample_1026": [false], "sample_1027": [false], "sample_1028": [true], "sample_1029": [false], "sample_1030": [true], "sample_1031": [true], "sample_1032": [true], "sample_1033": [false], "sample_1034": [true], "sample_1035": [true], "sample_1036": [false], "sample_1037": [false], "sample_1038": [false], "sample_1039": [false], "sample_1040": [false], "sample_1041": [true], "sample_1042": [true], "sample_1043": [false], "sample_1044": [false], "sample_1045": [true], "sample_1046": [false], "sample_1047": [true], "sample_1048": [false], "sample_1049": [false], "sample_1050": [false], "sample_1051": [false], "sample_1052": [false], "sample_1053": [true], "sample_1054": [true], "sample_1055": [false], "sample_1056": [false], "sample_1057": [false], "sample_1058": [true], "sample_1059": [false], "sample_1060": [true], "sample_1061": [true], "sample_1062": [true], "sample_1063": [true], "sample_1064": [true], "sample_1065": [false], "sample_1066": [false], "sample_1067": [false], "sample_1068": [false], "sample_1069": [false], "sample_1070": [false], "sample_1071": [true], "sample_1072": [false], "sample_1073": [true], "sample_1074": [false], "sample_1075": [false], "sample_1076": [true], "sample_1077": [false], "sample_1078": [true], "sample_1079": [true], "sample_1080": [false], "sample_1081": [false], "sample_1082": [false], "sample_1083": [false], "sample_1084": [true], "sample_1085": [true], "sample_1086": [false], "sample_1087": [true], "sample_1088": [true], "sample_1089": [true], "sample_1090": [false], "sample_1091": [false], "sample_1092": [true], "sample_1093": [false], "sample_1094": [true], "sample_1095": [false], "sample_1096": [true], "sample_1097": [false], "sample_1098": [true], "sample_1099": [true], "sample_1100": [true], "sample_1101": [false], "sample_1102": [false], "sample_1103": [true], "sample_1104": [true], "sample_1105": [false], "sample_1106": [false], "sample_1107": [false], "sample_1108": [false], "sample_1109": [false], "sample_1110": [true], "sample_1111": [false], "sample_1112": [true], "sample_1113": [false], "sample_1114": [false], "sample_1115": [false], "sample_1116": [false], "sample_1117": [true], "sample_1118": [false], "sample_1119": [false], "sample_1120": [false], "sample_1121": [true], "sample_1122": [false], "sample_1123": [false], "sample_1124": [false], "sample_1125": [false], "sample_1126": [true], "sample_1127": [false], "sample_1128": [true], "sample_1129": [false], "sample_1130": [false], "sample_1131": [false], "sample_1132": [false], "sample_1133": [false], "sample_1134": [false], "sample_1135": [true], "sample_1136": [true], "sample_1137": [false], "sample_1138": [true], "sample_1139": [true], "sample_1140": [false], "sample_1141": [true], "sample_1142": [false], "sample_1143": [true], "sample_1144": [false], "sample_1145": [true], "sample_1146": [false], "sample_1147": [false], "sample_1148": [false], "sample_1149": [false], "sample_1150": [false], "sample_1151": [false], "sample_1152": [true], "sample_1153": [true], "sample_1154": [false], "sample_1155": [true], "sample_1156": [false], "sample_1157": [false], "sample_1158": [true], "sample_1159": [true], "sample_1160": [false], "sample_1161": [true], "sample_1162": [true], "sample_1163": [false], "sample_1164": [false], "sample_1165": [true], "sample_1166": [false], "sample_1167": [false], "sample_1168": [false], "sample_1169": [true], "sample_1170": [false], "sample_1171": [false], "sample_1172": [false], "sample_1173": [false], "sample_1174": [false], "sample_1175": [false], "sample_1176": [true], "sample_1177": [true], "sample_1178": [false], "sample_1179": [true], "sample_1180": [true], "sample_1181": [false], "sample_1182": [false], "sample_1183": [true], "sample_1184": [false], "sample_1185": [true], "sample_1186": [true], "sample_1187": [true], "sample_1188": [false], "sample_1189": [true], "sample_1190": [true], "sample_1191": [false], "sample_1192": [false], "sample_1193": [false], "sample_1194": [true], "sample_1195": [true], "sample_1196": [false], "sample_1197": [true], "sample_1198": [true], "sample_1199": [false], "sample_1200": [true], "sample_1201": [false], "sample_1202": [true], "sample_1203": [false], "sample_1204": [false], "sample_1205": [true], "sample_1206": [true], "sample_1207": [true], "sample_1208": [false], "sample_1209": [false]}}