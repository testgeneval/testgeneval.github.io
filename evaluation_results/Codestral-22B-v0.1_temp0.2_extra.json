{"raw_generations": {"sample_200": ["def test_send_messages_with_fail_silently(self):\n    \"\"\"\n    A message isn't sent if it doesn't have any recipients and fail_silently is True.\n    \"\"\"\n    backend = smtp.EmailBackend(fail_silently=True)\n    backend.connection = True\n    email = EmailMessage('Subject', 'Content', 'from@example.com', to=[])\n    sent = backend.send_messages([email])\n    self.assertEqual(sent, 0)\n"], "sample_1007": ["def test_binomial_series():\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True)\n\n    assert binomial(n, k).series(n, 0, 3) == \\\n        binomial(k, k)*(1 - k*EulerGamma + k**2*(EulerGamma**2/2 + pi**2/12) + O(k**3))\n"], "sample_55": ["def test_get_formsets_with_inlines_argument(self):\n    # Test get_formsets_with_inlines() during add_view\n    response = self.client.get(reverse('admin:admin_views_getformsetsargumentchecking_add'))\n    self.assertIsNone(response.context['adminform'].form.instance)\n\n    # Test get_formsets_with_inlines() during change_view\n    obj = GetFormsetsArgumentChecking.objects.create(name='Test')\n    response = self.client.get(reverse('admin:admin_views_getformsetsargumentchecking_change', args=(obj.pk,)))\n    self.assertEqual(response.context['adminform'].form.instance, obj)\n"], "sample_744": ["def test_power_transformer_standardize_exception():\n    pt = PowerTransformer(method='box-cox', standardize='yes')\n    X = np.abs(X_2d)\n\n    # An exception should be raised if PowerTransformer.standardize isn't valid\n    bad_standardize_message = \"'standardize' must be either True or False\"\n    assert_raise_message(ValueError, bad_standardize_message,\n                         pt.fit, X)\n"], "sample_908": ["def test_unparse_annotations():\n    source = \"def func(a: int, b: str = 'default', *args: List[int], c: Dict[str, str], **kwargs: Any) -> None:\"\n    expected = \"def func(a: int, b: str = 'default', *args: List[int], c: Dict[str, str], **kwargs: Any) -> None:\"\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0]) == expected\n"], "sample_1060": ["def test_NumPyPrinter_print_MatMul():\n    n = NumPyPrinter()\n\n    A = MatrixSymbol(\"A\", 2, 3)\n    B = MatrixSymbol(\"B\", 3, 2)\n    assert n.doprint(A*B) == '(A).dot(B)'\n"], "sample_693": ["def test_do_cleanups_on_test_failure(pytester: Pytester) -> None:\n    testpath = pytester.makepyfile(\n        \"\"\"\n        import unittest\n        class MyTestCase(unittest.TestCase):\n            values = []\n                    self.values.append(1)\n                self.addCleanup(cleanup)\n                assert False\n                pass\n            assert MyTestCase.values == [1, 1]\n    \"\"\"\n    )\n    reprec = pytester.inline_run(testpath)\n    passed, skipped, failed = reprec.countoutcomes()\n    assert failed == 1\n    assert passed == 2\n"], "sample_488": ["def test_get_registered_model(self):\n    \"\"\"\n    Tests apps.get_registered_model().\n    \"\"\"\n    model = apps.get_registered_model(\"apps\", \"TotallyNormal\")\n    self.assertEqual(model, TotallyNormal)\n\n    with self.assertRaises(LookupError):\n        apps.get_registered_model(\"apps\", \"SoAlternative\")\n\n    with self.assertRaises(LookupError):\n        apps.get_registered_model(\"nonexistent\", \"Model\")\n"], "sample_572": ["def test_bivariate_probability_stat_weights(self, x, y, weights):\n\n    h = Histogram(stat=\"probability\")\n    heights, _ = h(x, y, weights=weights)\n    assert heights.sum() == pytest.approx(1)\n"], "sample_416": ["def test_no_dbname_or_service(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env({\"USER\": \"someuser\"}),\n        ([\"psql\", \"-U\", \"someuser\", \"postgres\"], None),\n    )\n"], "sample_1114": ["def test_issue_18146():\n    e = Symbol('e', integer=True, even=True)\n    o = Symbol('o', integer=True, odd=True)\n    assert Range(5).contains(i) == And(i >= 0, i <= 4)\n    assert Range(1, 4).contains(i) == And(i >= 1, i <= 3)\n    assert Range(1, 4).contains(e) == And(e >= 2, e <= 4)\n    assert Range(1, 4).contains(o) == And(o >= 1, o <= 3)\n    assert Range(1, 4, 2).contains(i) == And(i >= 1, i <= 3, Eq(i % 2, 1))\n    assert Range(1, 4, 2).contains(e) == False\n    assert Range(1, 4, 2).contains(o) == And(o >= 1, o <= 3)\n    assert Range(4, 1, -1).contains(i) == And(i >= 1, i <= 3)\n    assert Range(4, 1, -1).contains(e) == And(e >= 2, e <= 4)\n    assert Range(4, 1, -1).contains(o) == And(o >= 1, o <= 3)\n    assert Range(4, 1, -2).contains(i) == And(i >= 1, i <= 3, Eq(i % 2, 1))\n    assert Range(4, 1, -2).contains(e) == False\n    assert Range(4, 1, -2).contains(o) == And(o >= 1, o <= 3)\n"], "sample_5": ["def test_models_evaluate_with_units_param_array_non_finite():\n    model = {\n        'class': PowerLaw1D,\n        'parameters': {'amplitude': 5 * u.kg, 'x_0': 10 * u.cm, 'alpha': 1},\n        'evaluation': [(0 * u.m, np.nan * u.kg)],\n    }\n\n    params = {}\n    for key, value in model['parameters'].items():\n        params[key] = np.repeat(value, 2)\n\n    params['n_models'] = 2\n    params['x_0'][-1] = 0 * u.cm\n\n    m = model['class'](**params)\n\n    for args in model['evaluation']:\n        x, y = args\n        x_arr = u.Quantity([x, x], subok=True)\n        result = m(x_arr)\n        assert np.isnan(result[-1].value)\n"], "sample_1029": ["def test_Cycle():\n    from sympy import Cycle\n    sT(Cycle(1, 2, 3), \"Cycle((1, 2, 3))\")\n"], "sample_738": ["def test_vectorizer_custom_preprocessor():\n        return s.replace(' ', '_')\n\n    cv = CountVectorizer(preprocessor=custom_preprocessor)\n    X = cv.fit_transform(['hello world', 'goodbye world'])\n    assert_array_equal(cv.get_feature_names(), ['goodbye_world', 'hello_world'])\n    assert_array_equal(X.toarray(), [[0, 1], [1, 0]])\n"], "sample_272": ["def test_minimize_rollbacks_multiple_targets(self):\n    r\"\"\"\n    Minimize rollbacks when targeting multiple apps.\n\n    a: 1 <---- 3 <--\\\n              \\ \\- 2 <--- 4\n               \\       \\\n    b:     1 <--- 2 <--- 3\n    \"\"\"\n    a1_impl = FakeMigration('a1')\n    a1 = ('a', '1')\n    a2_impl = FakeMigration('a2')\n    a2 = ('a', '2')\n    a3_impl = FakeMigration('a3')\n    a3 = ('a', '3')\n    a4_impl = FakeMigration('a4')\n    a4 = ('a', '4')\n    b1_impl = FakeMigration('b1')\n    b1 = ('b', '1')\n    b2_impl = FakeMigration('b2')\n    b2 = ('b', '2')\n    b3_impl = FakeMigration('b3')\n    b3 = ('b', '3')\n    graph = MigrationGraph()\n    graph.add_node(a1, a1_impl)\n    graph.add_node(a2, a2_impl)\n    graph.add_node(a3, a3_impl)\n    graph.add_node(a4, a4_impl)\n    graph.add_node(b1, b1_impl)\n    graph.add_node(b2, b2_impl)\n    graph.add_node(b3, b3_impl)\n    graph.add_dependency(None, a2, a1)\n    graph.add_dependency(None, a3, a1)\n    graph.add_dependency(None, a4, a2)\n    graph.add_dependency(None, a4, a3)\n    graph.add_dependency(None, b2, b1)\n    graph.add_dependency(None, b3, b2)\n\n    executor = MigrationExecutor(None)\n    executor.loader = FakeLoader(graph, {\n        a1:"], "sample_234": ["def test_union_with_different_values(self):\n    qs1 = Number.objects.filter(num=1).values('num')\n    qs2 = Number.objects.filter(num=2).values('other_num')\n    with self.assertRaisesMessage(TypeError, \"Merging 'QuerySet' classes must involve the same values in each case.\"):\n        qs1.union(qs2)\n"], "sample_312": ["def test_add_squash(self):\n    node = Node(['a'], 'AND')\n    node.add(Node(['b'], 'AND'), 'AND')\n    self.assertEqual(node, Node(['a', 'b'], 'AND'))\n"], "sample_584": ["def test_auto_combine_with_empty_input(self):\n    assert_identical(Dataset(), auto_combine([]))\n"], "sample_1138": ["def test_TR18():\n    assert TR18(tan(x)**2) == sec(x)**2 - 1\n    assert TR18(cot(x)**2) == csc(x)**2 - 1\n"], "sample_329": ["def test_serialize_deconstructible(self):\n    deconstructible_instance = DeconstructibleInstances()\n    self.assertSerializedEqual(deconstructible_instance)\n    self.assertSerializedResultEqual(\n        deconstructible_instance,\n        (\"migrations.test_writer.DeconstructibleInstances()\", {'import migrations.test_writer'})\n    )\n"], "sample_1170": ["def test_issue_21823_with_list():\n    assert str(Partition([1, 2, 2])) == 'Partition({1, 2})'\n    assert str(Partition({1, 2, 2})) == 'Partition({1, 2})'\n"], "sample_18": ["def test_binary_op_structured(self):\n    q2 = u.Quantity([(5.0, 6.0)], \"m, m/s\")\n    q = self.q + q2\n    assert_no_info(q)\n"], "sample_184": ["def test_unique_constraint_include_pointing_to_joined_fields(self):\n    class Model(models.Model):\n        age = models.SmallIntegerField()\n        parent = models.ForeignKey('self', models.CASCADE)\n\n        class Meta:\n            constraints = [\n                models.UniqueConstraint(\n                    name='name',\n                    fields=['age'],\n                    include=['parent__age'],\n                ),\n            ]\n\n    self.assertEqual(Model.check(databases=self.databases), [\n        Error(\n            \"'constraints' refers to the joined field 'parent__age'.\",\n            obj=Model,\n            id='models.E041',\n        )\n    ])\n"], "sample_39": ["def test_scalar_inputs_world2pix():\n    \"\"\"\n    Test scalar inputs for all_world2pix\n    \"\"\"\n    wcsobj = wcs.WCS(naxis=1)\n    result = wcsobj.all_world2pix(2, 1)\n    assert_array_equal(result, [np.array(2.)])\n    assert result[0].shape == ()\n\n    result = wcsobj.all_world2pix([2], 1)\n    assert_array_equal(result, [np.array([2.])])\n    assert result[0].shape == (1,)\n"], "sample_45": ["def test_trunc_func_with_timezone_and_output_field(self):\n    start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n    end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n    self.create_model(end_datetime, start_datetime)\n\n    melb = pytz.timezone('Australia/Melbourne')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=output_field, tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(melb), kind, melb).time() if output_field == TimeField() else truncate_to(start_datetime.astimezone(melb), kind, melb).date() if output_field == DateField() else truncate_to(start_datetime.astimezone(melb), kind, melb)),\n                (end_datetime, truncate_to(end_datetime.astimezone(melb), kind, melb).time() if output_field == TimeField() else truncate_to(end_datetime.astimezone(melb), kind, melb).date() if output_field == DateField() else truncate_to(end_datetime.astimezone(melb), kind, melb))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_datetime_kind('year', DateField())\n    test_datetime_kind('quarter', TimeField"], "sample_686": ["def test_warning_captured_hook_is_deprecated(testdir: Testdir) -> None:\n    testdir.makepyfile(\n        \"\"\"\n        import warnings\n\n            warnings.warn(\"This is a deprecated warning\", DeprecationWarning)\n        \"\"\"\n    )\n\n    class WarningPlugin:\n            pass\n\n    result = testdir.runpytest_subprocess(\"--capture=no\", \"-p\", \"no:warning_module\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: The pytest_warning_captured is deprecated*\",\n            \"*Please use pytest_warning_recorded instead.*\",\n        ]\n    )\n"], "sample_391": ["def test_create_model_with_unique_constraint(self):\n    \"\"\"\n    CreateModel with unique constraint should optimize correctly.\n    \"\"\"\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                \"Foo\",\n                [\n                    (\"name\", models.CharField(max_length=255, unique=True)),\n                ],\n            ),\n            migrations.AddConstraint(\n                \"Foo\",\n                models.UniqueConstraint(fields=[\"name\"], name=\"unique_name\"),\n            ),\n        ],\n        [\n            migrations.CreateModel(\n                \"Foo\",\n                [\n                    (\"name\", models.CharField(max_length=255, unique=True)),\n                ],\n                options={\n                    \"constraints\": [\n                        models.UniqueConstraint(fields=[\"name\"], name=\"unique_name\"),\n                    ],\n                },\n            ),\n        ],\n    )\n"], "sample_688": ["def test_collect_sub_with_symlinks_and_init(testdir):\n    \"\"\"Collection works with symlinked files, broken symlinks, and __init__.py\"\"\"\n    sub = testdir.mkdir(\"sub\")\n    sub.ensure(\"__init__.py\")\n    sub.join(\"test_file.py\").write(\"def test_file(): pass\")\n\n    # Create a broken symlink.\n    symlink_or_skip(\"test_doesnotexist.py\", sub.join(\"test_broken.py\"))\n\n    # Symlink that gets collected.\n    symlink_or_skip(\"test_file.py\", sub.join(\"test_symlink.py\"))\n\n    result = testdir.runpytest(\"-v\", str(sub))\n    result.stdout.fnmatch_lines(\n        [\n            \"sub/test_file.py::test_file PASSED*\",\n            \"sub/test_symlink.py::test_file PASSED*\",\n            \"*2 passed in*\",\n        ]\n    )\n"], "sample_888": ["def test_iforest_with_contamination_zero():\n    \"\"\"Test whether iforest predicts all samples as inliers when contamination is 0\"\"\"\n\n    rng = np.random.RandomState(0)\n    X = rng.randn(100, 10)\n    iforest = IsolationForest(contamination=0)\n    iforest.fit(X)\n\n    assert all(iforest.predict(X) == 1)\n"], "sample_1148": ["def test_matrix_symbol_transpose():\n    A = MatrixSymbol('A', n, m)\n    assert A.T.shape == (m, n)\n    assert A.T.T == A\n    assert (A.T*A).T == A*A.T\n"], "sample_802": ["def test_pipeline_with_no_final_estimator():\n    # Test the pipeline with no final estimator\n    X = np.array([[1, 2]])\n    pipe = Pipeline([('transf', Transf())])\n    X_trans = pipe.fit_transform(X)\n    assert_array_almost_equal(X_trans, X)\n    X_back = pipe.inverse_transform(X_trans)\n    assert_array_almost_equal(X_back, X)\n"], "sample_1089": ["def test_issue_18059():\n    x = symbols('x')\n    assert factor_terms(x**(2*sqrt(2))) == x**(2*sqrt(2))\n    assert factor_terms(x**(2*sqrt(2)), radical=True) == (x**sqrt(2))**2\n"], "sample_647": ["def test_unformatted_warning_format():\n    \"\"\"Test the format method of UnformattedWarning.\"\"\"\n    unformatted_warning = warning_types.UnformattedWarning(\n        category=warning_types.PytestWarning,\n        template=\"Test warning with {name}\",\n    )\n    formatted_warning = unformatted_warning.format(name=\"example\")\n    assert str(formatted_warning) == \"Test warning with example\"\n"], "sample_359": ["def test_references_field_by_limit_choices_to(self):\n    operation = FieldOperation(\n        'Model', 'field', models.ForeignKey('Other', models.CASCADE, limit_choices_to={'field': 'value'})\n    )\n    self.assertIs(operation.references_field('Other', 'field', 'migrations'), True)\n    self.assertIs(operation.references_field('Other', 'whatever', 'migrations'), False)\n    self.assertIs(operation.references_field('Missing', 'whatever', 'migrations'), False)\n"], "sample_14": ["def test_angle_to_string_precision():\n    \"\"\"\n    Test the precision of the to_string method.\n    \"\"\"\n    angle = Angle(1.23456789, unit=u.degree)\n    assert angle.to_string(precision=2) == '1d14m04.45s'\n    assert angle.to_string(precision=4) == '1d14m04.4444s'\n    assert angle.to_string(precision=6) == '1d14m04.444444s'\n"], "sample_465": ["def test_inline_has_change_permission_uses_obj(self):\n    class ConcertInline(TabularInline):\n        model = Concert\n\n            return bool(obj)\n\n    class BandAdmin(ModelAdmin):\n        inlines = [ConcertInline]\n\n    ma = BandAdmin(Band, AdminSite())\n    request = MockRequest()\n    request.user = self.MockChangeUser()\n    self.assertEqual(ma.get_inline_instances(request), [])\n    band = Band(name=\"The Doors\", bio=\"\", sign_date=date(1965, 1, 1))\n    inline_instances = ma.get_inline_instances(request, band)\n    self.assertEqual(len(inline_instances), 1)\n    self.assertIsInstance(inline_instances[0], ConcertInline)\n"], "sample_273": ["    def test_indexes_with_joined_fields(self):\n        class RelatedModel(models.Model):\n            name = models.CharField(max_length=20)\n\n        class Model(models.Model):\n            related = models.ForeignKey(RelatedModel, on_delete=models.CASCADE)\n\n            class Meta:\n                indexes = [\n                    models.Index(fields=['related__name']),\n                ]\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"'constraints' refers to the joined field 'related__name'.\",\n                obj=Model,\n                id='models.E041',\n            ),\n        ])\n"], "sample_1050": ["def test_NumPyPrinter_print_Relational():\n    n = NumPyPrinter()\n\n    assert n.doprint(x < y) == 'numpy.less(x, y)'\n    assert n.doprint(x <= y) == 'numpy.less_equal(x, y)'\n    assert n.doprint(x > y) == 'numpy.greater(x, y)'\n    assert n.doprint(x >= y) == 'numpy.greater_equal(x, y)'\n"], "sample_793": ["def test_iforest_sample_weight():\n    X = np.array([[0, 1], [1, 2], [2, 3], [3, 4], [4, 5]])\n    sample_weight = np.array([1, 1, 2, 2, 2])\n    clf = IsolationForest(random_state=rng).fit(X, sample_weight=sample_weight)\n    scores = clf.decision_function(X)\n    assert len(scores) == len(X)\n"], "sample_52": ["def test_modelchoicefield_limit_choices_to(self):\n    f = forms.ModelChoiceField(Category.objects.all(), limit_choices_to={'slug__contains': 'test'})\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c2.pk, 'A test'),\n        (self.c3.pk, 'Third'),\n    ])\n\n    # limit_choices_to can be a callable.\n    f = forms.ModelChoiceField(Category.objects.all(), limit_choices_to=lambda: {'slug__contains': 'test'})\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c2.pk, 'A test'),\n        (self.c3.pk, 'Third'),\n    ])\n\n    # limit_choices_to can be changed after the field is created.\n    f.limit_choices_to = {'slug__contains': 'entertainment'}\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c1.pk, 'Entertainment'),\n    ])\n"], "sample_726": ["def test_label_binarize_multilabel_indicator():\n    y_ind = np.array([[0, 1, 0], [1, 1, 1], [0, 0, 0]])\n    classes = [0, 1, 2]\n    pos_label = 1\n    neg_label = 0\n    expected = y_ind\n    y_sparse = [sparse_matrix(y_ind)\n                for sparse_matrix in [coo_matrix, csc_matrix, csr_matrix,\n                                      dok_matrix, lil_matrix]]\n\n    for y in [y_ind] + y_sparse:\n        yield (check_binarized_results, y, classes, pos_label, neg_label,\n               expected)\n"], "sample_1028": ["def test_divmod_with_symbols():\n    x, y = symbols('x y')\n    assert divmod(x, y) == (x//y, x % y)\n    assert divmod(x, 3) == (x//3, x % 3)\n    assert divmod(3, x) == (3//x, 3 % x)\n"], "sample_441": ["    def test_custom_user_model(self):\n        data = {\n            'email': 'test@example.com',\n            'password1': 'testpassword',\n            'password2': 'testpassword',\n            'date_of_birth': '1990-01-01',\n        }\n        form = UserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        user = form.save()\n        self.assertEqual(user.email, 'test@example.com')\n        self.assertEqual(user.date_of_birth, datetime.date(1990, 1, 1))\n        self.assertTrue(user.check_password('testpassword'))\n"], "sample_521": ["def test_view_init_vertical_axis_invalid():\n    ax = plt.subplot(1, 1, 1, projection=\"3d\")\n    with pytest.raises(ValueError, match=\"vertical_axis must be 'x', 'y' or 'z'\"):\n        ax.view_init(elev=0, azim=0, roll=0, vertical_axis='invalid')\n"], "sample_490": ["def test_validate_expression_with_custom_error(self):\n    constraint = models.UniqueConstraint(\n        Lower(\"name\"),\n        name=\"name_lower_uniq\",\n        violation_error_message=\"Custom message\",\n        violation_error_code=\"custom_code\",\n    )\n    msg = \"Custom message\"\n    with self.assertRaisesMessage(ValidationError, msg) as cm:\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=self.p1.name.upper()),\n        )\n    self.assertEqual(cm.exception.code, \"custom_code\")\n"], "sample_141": ["def test_helpful_error_message_for_many2many_invalid_type(self):\n    \"\"\"\n    Invalid type for many-to-many field value throws a helpful error message.\n    \"\"\"\n    test_string = \"\"\"[{\n        \"pk\": 1,\n        \"model\": \"serializers.m2mdata\",\n        \"fields\": {\"data\": \"invalid_type\"}\n    }]\"\"\"\n\n    expected = \"(serializers.m2mdata:pk=1) field_value was 'invalid_type'\"\n    with self.assertRaisesMessage(DeserializationError, expected):\n        next(serializers.deserialize('json', test_string, ignore=False))\n"], "sample_626": ["def test_getitem(indexes) -> None:\n    x_idx = indexes[\"x\"]\n    expected = PandasIndex(x_idx.index[1:], \"x\", coord_dtype=x_idx.coord_dtype)\n    actual = x_idx[1:]\n\n    assert actual.index.equals(expected.index)\n    assert actual.dim == expected.dim\n    assert actual.coord_dtype == expected.coord_dtype\n"], "sample_204": ["def test_atomic_migration(self):\n    \"\"\"\n    Makes sure the 'atomic' attribute of migrations is respected.\n    \"\"\"\n    # Load and test the plan\n    migration_loader = MigrationLoader(connection)\n    self.assertEqual(\n        migration_loader.graph.forwards_plan((\"migrations\", \"0002_second\")),\n        [\n            (\"migrations\", \"0001_initial\"),\n            (\"migrations\", \"0002_second\"),\n        ],\n    )\n    # Now collect SQL statements\n    plan = [\n        (migration_loader.get_migration(\"migrations\", \"0001_initial\"), False),\n        (migration_loader.get_migration(\"migrations\", \"0002_second\"), False),\n    ]\n    statements = migration_loader.collect_sql(plan)\n    self.assertIn(\"BEGIN;\", statements[0])\n    self.assertIn(\"COMMIT;\", statements[-1])\n"], "sample_984": ["def test_MatrixPow():\n    A = MatrixSymbol(\"A\", 2, 2)\n    assert str(A**2) == \"A**2\"\n    assert str(A**-1) == \"A**(-1)\"\n"], "sample_422": ["def test_foreignkey_forward(self):\n    authors = Author.objects.order_by(\"name\")\n    with self.assertNumQueries(3):\n        books = list(\n            Book.objects.prefetch_related(\n                Prefetch(\"first_book__authors\", authors),\n                Prefetch(\"first_book__authors\", authors[1:], to_attr=\"authors_sliced\"),\n            )\n        )\n    for book in books:\n        with self.subTest(book=book):\n            self.assertEqual(book.authors_sliced, list(book.first_book.authors.all())[1:])\n"], "sample_1100": ["def test_issue_18507_2():\n    assert Mul(zoo, 0, zoo) is nan\n"], "sample_226": ["    def test_keepdb_true(self, mocked_sync_apps, mocked_migrate, *mocked_objects):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        test_connection.settings_dict['TEST']['KEEPDB'] = True\n        creation = test_connection.creation_class(test_connection)\n        if connection.vendor == 'oracle':\n            # Don't close connection on Oracle.\n            creation.connection.close = mock.Mock()\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db') as mock_create_test_db:\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=False, keepdb=True)\n            # _create_test_db is called with keepdb=True\n            mock_create_test_db.assert_called_with(0, True, True)\n            # Migrations run.\n            mocked_migrate.assert_called()\n            args, kwargs = mocked_migrate.call_args\n            self.assertEqual(args, ([('app_unmigrated', '0001_initial')],))\n            self.assertEqual(len(kwargs['plan']), 1)\n            # App is not synced.\n            mocked"], "sample_727": ["def test_imputation_invalid_strategy():\n    # Test imputation with an invalid strategy\n    X = np.array([\n        [np.nan, 0, 0, 0, 5],\n        [np.nan, 1, 0, np.nan, 3],\n        [np.nan, 2, 0, 0, 0],\n        [np.nan, 6, 0, 5, 13],\n    ])\n\n    imputer = Imputer(strategy=\"invalid_strategy\")\n    assert_raises(ValueError, imputer.fit, X)\n"], "sample_855": ["def test_constant_strategy_multioutput_sparse_target():\n    X = [[0], [0], [0], [0]]  # ignored\n    y = sp.csc_matrix(np.array([[2, 0, 5, 4, 3],\n                                [2, 0, 1, 2, 5],\n                                [1, 0, 4, 5, 2],\n                                [1, 3, 3, 2, 0]]))\n\n    n_samples = len(X)\n\n    clf = DummyClassifier(strategy=\"constant\", random_state=0, constant=[1, 0, 5, 4, 3])\n    clf.fit(X, y)\n    y_pred = clf.predict(X)\n    assert sp.issparse(y_pred)\n    assert_array_equal(y_pred.toarray(), np.hstack([np.ones((n_samples, 1)),\n                                                    np.zeros((n_samples, 1)),\n                                                    np.full((n_samples, 1), 5),\n                                                    np.full((n_samples, 1), 4),\n                                                    np.full((n_samples, 1), 3)]))\n"], "sample_953": ["def test_quickstart_with_custom_template(tempdir, monkeypatch):\n    # Mock the template directory to use a custom template\n    custom_template_dir = tempdir / 'custom_templates'\n    custom_template_dir.mkdir()\n    (custom_template_dir / 'root_doc.rst_t').write_text('Custom template content')\n\n    answers = {\n        'Root path': tempdir,\n        'Project name': 'Custom Template Test',\n        'Author name': 'Test Author',\n        'Project version': '1.0',\n    }\n    qs.term_input = mock_input(answers)\n    d = {}\n    qs.ask_user(d)\n    qs.generate(d, templatedir=str(custom_template_dir))\n\n    # Check if the custom template was used\n    masterfile = tempdir / 'source' / 'index.rst'\n    assert masterfile.isfile()\n    assert masterfile.read_text() == 'Custom template content'\n"], "sample_1062": ["def test_TR22():\n    assert TR22(1 + tan(x)**2) == sec(x)**2\n    assert TR22(1 + cot(x)**2) == csc(x)**2\n    assert TR22(1 + tan(x)**4) == (sec(x)**2 - 1)**2 + 2*(sec(x)**2 - 1) + 1\n    assert TR22(1 + cot(x)**4) == (csc(x)**2 - 1)**2 + 2*(csc(x)**2 - 1) + 1\n"], "sample_300": ["def test_filter_with_transform(self):\n    query = Query(Author, alias_cols=False)\n    with register_lookup(CharField, Lower):\n        where = query.build_where(Q(name__lower='foo'))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, Exact)\n    self.assertIsInstance(lookup.lhs, Lower)\n    self.assertIsInstance(lookup.lhs.lhs, Col)\n    self.assertIsNone(lookup.lhs.lhs.alias)\n    self.assertEqual(lookup.lhs.lhs.target, Author._meta.get_field('name'))\n"], "sample_1045": ["def test_Float_floor_ceiling():\n    a = Float('1.5')\n    b = Float('-1.5')\n\n    assert(a.floor() == Float('1.0'))\n    assert(a.ceiling() == Float('2.0'))\n    assert(b.floor() == Float('-2.0'))\n    assert(b.ceiling() == Float('-1.0'))\n"], "sample_1071": ["def test_convert_to_incompatible_units():\n    assert convert_to(meter, second) == meter\n    assert convert_to(second, meter) == second\n"], "sample_467": ["def test_selectdate_id_for_label(self):\n    widget = SelectDateWidget()\n    self.assertEqual(widget.id_for_label(\"id\"), \"id_month\")\n"], "sample_593": ["def test_summarize_variable_with_unsafe_name_and_dtype():\n    var = xr.Variable([\"<x>\", \"<y>\"], [[1, 2, 3], [4, 5, 6]], {\"foo\": \"bar\"})\n    formatted = fh.summarize_variable(\"<name>\", var, dtype=\"<dtype>\")\n    assert \"&lt;name&gt;\" in formatted\n    assert \"&lt;x&gt;, &lt;y&gt;\" in formatted\n    assert \"&lt;dtype&gt;\" in formatted\n"], "sample_712": ["def test_one_hot_encoder_specified_categories_wrong_shape():\n    X = np.array([['a', 'b'], ['c', 'd']], dtype=object)\n    enc = OneHotEncoder(categories=[['a', 'b', 'c']])\n    with pytest.raises(ValueError, match=\"Shape mismatch: if n_values is an array, it has to be of shape \\\\(n_features,\\\\).\"):\n        enc.fit_transform(X)\n"], "sample_108": ["def test_path_lookup_with_multiple_parameters_and_converter(self):\n    match = resolve('/articles/2015/04/12/slug-example/')\n    self.assertEqual(match.url_name, 'articles-year-month-day-slug')\n    self.assertEqual(match.args, ())\n    self.assertEqual(match.kwargs, {'year': 2015, 'month': 4, 'day': 12, 'slug': 'slug-example'})\n    self.assertEqual(match.route, 'articles/<int:year>/<int:month>/<int:day>/<slug:slug>/')\n"], "sample_531": ["def test_add_subplot_kwargs_with_gridspec_kw():\n    # fig.add_subplot() with gridspec_kw should create new axes, even if axes kwargs differ.\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1, gridspec_kw={'left': 0.1, 'right': 0.9})\n    ax1 = fig.add_subplot(1, 1, 1, gridspec_kw={'left': 0.2, 'right': 0.8})\n    assert ax is not None\n    assert ax1 is not ax\n    plt.close()\n\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1, projection='polar', gridspec_kw={'left': 0.1, 'right': 0.9})\n    ax1 = fig.add_subplot(1, 1, 1, projection='polar', gridspec_kw={'left': 0.2, 'right': 0.8})\n    assert ax is not None\n    assert ax1 is not ax\n    plt.close()\n\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1, projection='polar', gridspec_kw={'left': 0.1, 'right': 0.9})\n    ax1 = fig.add_subplot(1, 1, 1, gridspec_kw={'left': 0.2, 'right': 0.8})\n    assert ax is not None\n    assert ax1.name == 'rectilinear'\n    assert ax1 is not ax\n    plt.close()\n"], "sample_928": ["def test_default_role(app):\n    from sphinx.util import docutils\n    from sphinx.util.rst import default_role\n\n    with default_role('dummy.rst', 'code'):\n        assert docutils.get_role_fn('code') is not None\n\n    with default_role('dummy.rst', 'unknown'):\n        assert docutils.get_role_fn('unknown') is None\n"], "sample_590": ["def test_concat_positions(self):\n    ds1 = Dataset({\"foo\": (\"x\", [1, 2])}, {\"x\": [0, 1]})\n    ds2 = Dataset({\"foo\": (\"x\", [3, 4])}, {\"x\": [2, 3]})\n    expected = Dataset({\"foo\": (\"x\", [1, 2, 3, 4])}, {\"x\": [0, 1, 2, 3]})\n    actual = concat([ds1, ds2], dim=\"x\", positions=[[0, 1], [2, 3]])\n    assert_identical(expected, actual)\n"], "sample_550": ["def test_interactive_zoom_twinned():\n    fig, ax1 = plt.subplots()\n    ax2 = ax1.twinx()\n    ax1.plot([0, 1], [0, 1])\n    ax2.plot([0, 1], [1, 0])\n\n    # Zoom from x=0.2, y=0.1 to x=0.8, y=0.9 (data coordinates, \"d\").\n    d0 = (0.2, 0.1)\n    d1 = (0.8, 0.9)\n    # Convert to screen coordinates (\"s\").  Events are defined only with pixel\n    # precision, so round the pixel values, and below, check against the\n    # corresponding xdata/ydata, which are close but not equal to d0/d1.\n    s0 = ax1.transData.transform(d0).astype(int)\n    s1 = ax1.transData.transform(d1).astype(int)\n\n    # Zoom in.\n    start_event = MouseEvent(\n        \"button_press_event\", fig.canvas, *s0, MouseButton.LEFT)\n    fig.canvas.callbacks.process(start_event.name, start_event)\n    stop_event = MouseEvent(\n        \"button_release_event\", fig.canvas, *s1, MouseButton.LEFT)\n    fig.canvas.callbacks.process(stop_event.name, stop_event)\n    assert ax1.get_xlim() == (start_event.xdata, stop_event.xdata)\n    assert ax1.get_ylim() == (start_event.ydata, stop_event.ydata)\n    assert ax2.get_xlim() == (0, 1)\n    assert ax2.get_ylim() == (0, 1)\n\n    # Zoom out.\n    start_event = MouseEvent(\n        \"button_press_event\", fig.canvas, *s1, MouseButton.RIGHT)\n    fig.canvas.callbacks.process(start_event.name, start_event)\n    stop_event = MouseEvent("], "sample_1151": ["def test_issue_21034_round():\n    e = -I*log((re(asin(5)) + I*im(asin(5)))/sqrt(re(asin(5))**2 + im(asin(5))**2))/pi\n    assert round(e, 2) == round(-I*log((re(asin(5)) + I*im(asin(5)))/sqrt(re(asin(5))**2 + im(asin(5))**2))/pi, 2)\n"], "sample_1099": ["def test_eval_partial_derivative_mixed_tensor_expr3():\n\n    base_expr3 = H(i, j)*H(-i, -j) + A(i)*H(-i, j)\n\n    tensor_expression = PartialDerivative(base_expr3, H(k, m))._perform_derivative()\n    assert (tensor_expression - (L.delta(i, -k)*L.delta(j, -m)*H(-i, -j) +\n        H(i, j)*L.metric(-i, -L_0)*L.delta(L_0, -k)*L.metric(-j, -L_1)*L.delta(L_1, -m))).expand() == 0\n\n    vector_expression = PartialDerivative(base_expr3, A(k))._perform_derivative()\n    assert (vector_expression - (L.delta(j, -k)*H(-i, j) +\n        A(L_0)*L.metric(-L_0, -L_1)*L.delta(L_1, -k)*H(-i, j) +\n        L.delta(L_0, -k)*H(L_0, j))).expand() == 0\n"], "sample_863": ["def test_pipeline_fit_params_with_intermediate_steps():\n    # tests that Pipeline passes fit_params to intermediate steps\n    # when fit is invoked\n    pipe = Pipeline([('transf', TransfFitParams()), ('clf', FitParamT())])\n    pipe.fit(X=None,\n             y=None,\n             transf__should_get_this=True,\n             clf__should_succeed=True)\n    assert pipe.named_steps['transf'].fit_params['should_get_this']\n    assert pipe.named_steps['clf'].successful\n    assert 'should_succeed' not in pipe.named_steps['transf'].fit_params\n"], "sample_206": ["def test_file_descriptor_get(self):\n    \"\"\"\n    Test the __get__ method of FileDescriptor.\n    \"\"\"\n    d = Document(myfile='something.txt')\n    field = d._meta.get_field('myfile')\n    file = field.descriptor_class(field).__get__(d)\n    self.assertIsInstance(file, field.attr_class)\n    self.assertEqual(file.name, 'something.txt')\n"], "sample_532": ["def test_contour_invalid_algorithm():\n    z = np.array([[1.0, 2.0], [3.0, 4.0]])\n    with pytest.raises(ValueError):\n        plt.contourf(z, algorithm='invalid')\n"], "sample_566": ["def test_get_constrained_layout_pads_relative():\n    params = {'w_pad': 0.01, 'h_pad': 0.02, 'wspace': 0.03, 'hspace': 0.04}\n    expected = tuple([*params.values()])\n    fig = plt.figure(layout=mpl.layout_engine.ConstrainedLayoutEngine(**params))\n    fig.set_size_inches(6, 4)\n    fig.draw_without_rendering()\n    with pytest.warns(PendingDeprecationWarning, match=\"will be deprecated\"):\n        pads = fig.get_constrained_layout_pads(relative=True)\n    np.testing.assert_allclose(pads, expected, rtol=1e-3)\n"], "sample_990": ["def test_tanh_expansion():\n    x, y = symbols('x,y')\n    assert tanh(x+y).expand(trig=True) == (tanh(x) + tanh(y)) / (1 + tanh(x)*tanh(y))\n    assert tanh(2*x).expand(trig=True) == 2*tanh(x) / (1 + tanh(x)**2)\n    assert tanh(3*x).expand(trig=True).expand() == (3*tanh(x) - 3*tanh(x)**3) / (1 - 3*tanh(x)**2)\n"], "sample_831": ["def test_plot_tree_multi_output(pyplot):\n    # Test multi-output with weighted samples\n    clf = DecisionTreeClassifier(max_depth=2,\n                                 min_samples_split=2,\n                                 criterion=\"gini\",\n                                 random_state=2)\n    clf = clf.fit(X, y2, sample_weight=w)\n\n    nodes = plot_tree(clf, filled=True, impurity=False)\n    assert len(nodes) == 5\n    assert nodes[0].get_text() == \"X[0] <= 0.0\\nsamples = 6\\nvalue = [[3.0, 1.5, 0.0]\\n[3.0, 1.0, 0.5]]\"\n    assert nodes[1].get_text() == \"samples = 3\\nvalue = [[3, 0, 0]\\n[3, 0, 0]]\"\n    assert nodes[2].get_text() == \"X[0] <= 1.5\\nsamples = 3\\nvalue = [[0.0, 1.5, 0.0]\\n[0.0, 1.0, 0.5]]\"\n    assert nodes[3].get_text() == \"samples = 2\\nvalue = [[0, 1, 0]\\n[0, 1, 0]]\"\n    assert nodes[4].get_text() == \"samples = 1\\nvalue = [[0.0, 0.5, 0.0]\\n[0.0, 0.0, 0.5]]\"\n"], "sample_8": ["def test_masked_array_from_masked_with_fill_value(self):\n    \"\"\"Check that we can initialize a MaskedArray with a fill value.\"\"\"\n    fill_value = 99\n    np_ma = np.ma.MaskedArray(self.ma, fill_value=fill_value)\n    assert type(np_ma) is np.ma.MaskedArray\n    assert type(np_ma.data) is self._data_cls\n    assert type(np_ma.mask) is np.ndarray\n    expected_data = np.where(self.mask_a, fill_value, self.a)\n    assert_array_equal(np_ma.data, expected_data)\n    assert_array_equal(np_ma.mask, self.mask_a)\n"], "sample_914": ["def test_unparse_arguments_with_annotation(source, expected):\n    module = ast.parse(f\"def func({source}): pass\")\n    assert ast.unparse(module.body[0].args) == expected\n"], "sample_161": ["def test_foreign_object_to_unique_field_with_unique_together(self):\n    class Person(models.Model):\n        country_id = models.IntegerField()\n        city_id = models.IntegerField()\n\n        class Meta:\n            unique_together = (('country_id', 'city_id'),)\n\n    class MMembership(models.Model):\n        person_country_id = models.IntegerField()\n        person_city_id = models.IntegerField()\n        person = models.ForeignObject(\n            Person,\n            on_delete=models.CASCADE,\n            from_fields=['person_country_id', 'person_city_id'],\n            to_fields=['country_id', 'city_id'],\n        )\n\n    field = MMembership._meta.get_field('person')\n    self.assertEqual(field.check(), [])\n"], "sample_504": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    data = np.arange(1200).reshape(30, 40)\n    levels = [0, 200, 400, 600, 800, 1000, 1200]\n    im = ax.contourf(data, levels=levels)\n    cbar = fig.colorbar(im)\n    cbar.set_alpha(0.5)\n    assert cbar.alpha == 0.5\n    cbar.set_alpha(None)\n    assert cbar.alpha is None\n"], "sample_1171": ["def test_issue_18146():\n    e = Symbol('e', integer=True, even=True)\n    o = Symbol('o', integer=True, odd=True)\n    assert Range(5).contains(i) == And(i >= 0, i <= 4)\n    assert Range(1, 9, 2).contains(e) == False\n    assert Range(1, 9, 2).contains(o) == And(o >= 1, o <= 7)\n    assert Range(8, 0, -2).contains(o) == False\n    assert Range(9, 1, -2).contains(o) == And(o >= 3, o <= 9)\n"], "sample_472": ["def test_paginator_with_custom_page_class(self):\n    \"\"\"\n    Paginator can be passed a custom page class.\n    \"\"\"\n    class CustomPage(Page):\n            return f\"Custom page {self.number} of {self.paginator.num_pages}\"\n\n    paginator = Paginator([1, 2, 3], 2, page_class=CustomPage)\n    page = paginator.page(1)\n    self.assertEqual(str(page), \"Custom page 1 of 2\")\n"], "sample_898": ["def test_pos_label_option_binary_classification(n_samples=20):\n    # Test in the binary case\n    random_state = check_random_state(0)\n    y_true = random_state.randint(0, 2, size=(n_samples, ))\n    y_score = random_state.random_sample(size=(n_samples,))\n\n    for name in METRICS_WITH_POS_LABEL:\n        metrics = ALL_METRICS[name]\n        measure = metrics(y_true, y_score, pos_label=1)\n        assert_almost_equal(metrics(y_true, 1 - y_score, pos_label=0), 1 - measure)\n"], "sample_985": ["def test_eval_is_real():\n    x, y = symbols('x y')\n    assert sin(x).is_real is None\n    assert sin(x).subs(x, 0).is_real is True\n    assert sin(x).subs(x, pi/2).is_real is True\n    assert sin(x).subs(x, pi).is_real is True\n    assert sin(x).subs(x, 3*pi/2).is_real is True\n    assert sin(x).subs(x, 2*pi).is_real is True\n    assert sin(x + y).is_real is None\n    assert sin(x + y).subs({x: 0, y: 0}).is_real is True\n    assert sin(x + y).subs({x: pi/2, y: pi/2}).is_real is True\n    assert sin(x + y).subs({x: pi, y: pi}).is_real is True\n    assert sin(x + y).subs({x: 3*pi/2, y: 3*pi/2}).is_real is True\n    assert sin(x + y).subs({x: 2*pi, y: 2*pi}).is_real is True\n"], "sample_942": ["def test_pyfunction_signature_with_default_value(app):\n    text = \".. py:function:: hello(name='World') -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_operator, \"=\"],\n                                                      [nodes.inline, \"'World'\"])])\n"], "sample_818": ["def test_spectral_clustering_with_different_n_init():\n    # Test that spectral_clustering with different n_init values\n    # gives the same result\n    X, y = make_blobs(n_samples=20, random_state=0,\n                      centers=[[1, 1], [-1, -1]], cluster_std=0.01)\n    labels_n_init_10 = spectral_clustering(X, n_clusters=2, n_init=10, random_state=0)\n    labels_n_init_20 = spectral_clustering(X, n_clusters=2, n_init=20, random_state=0)\n    assert adjusted_rand_score(labels_n_init_10, labels_n_init_20) == 1\n"], "sample_435": ["    def test_password_validation(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\n            \"password1\": \"testclient\",\n            \"password2\": \"testclient\",\n        }\n        with override_settings(\n            AUTH_PASSWORD_VALIDATORS=[\n                {\n                    \"NAME\": (\n                        \"django.contrib.auth.password_validation.\"\n                        \"UserAttributeSimilarityValidator\"\n                    )\n                },\n                {\n                    \"NAME\": (\n                        \"django.contrib.auth.password_validation.MinimumLengthValidator\"\n                    ),\n                    \"OPTIONS\": {\n                        \"min_length\": 12,\n                    },\n                },\n            ]\n        ):\n            form = AdminPasswordChangeForm(user, data)\n            self.assertFalse(form.is_valid())\n            self.assertEqual(len(form[\"password2\"].errors), 2)\n            self.assertIn(\n                \"The password is too similar to the username.\", form[\"password2\"].errors\n            )\n            self.assertIn(\n                \"This password is too short. It must contain at least 12 characters.\",\n                form[\"password2\"].errors,\n            )\n"], "sample_1136": ["def test_poly_copy_domain_equals_original():\n    poly = Poly(x + y, x, y, z, domain='ZZ[x,y,z]')\n    copy = poly.copy()\n    assert poly.domain == copy.domain, (\n        \"Copied polynomial has different domain than original.\")\n"], "sample_705": ["def test_pytester_outcomes_with_multiple_warnings(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import warnings\n\n            warnings.warn(UserWarning(\"warning 1\"))\n\n            warnings.warn(UserWarning(\"warning 2\"))\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=2, warnings=2)\n"], "sample_1047": ["def test_issue_16313_extended():\n    x = Symbol('x', real=False)\n    k = Symbol('k', real=True, positive=True)\n    l = Symbol('l', real=True, negative=True)\n    assert (k*x).is_positive is None  # k can be zero also\n    assert (l*x).is_positive is False\n    assert (l*x*x).is_positive is None  # since x*x can be a negative number\n    assert (-x).is_negative is False\n"], "sample_1193": ["def test_are_coplanar_with_plane():\n    from sympy.geometry import Plane\n\n    a = Plane(Point3D(1, 0, 0), Point3D(0, 1, 0), Point3D(0, 0, 1))\n    b = Line3D(Point3D(0, 0, 0), Point3D(1, 1, 1))\n    c = Point3D(2, 2, 2)\n    d = Point3D(3, 3, 3)\n\n    assert are_coplanar(a, b) == True\n    assert are_coplanar(a, c) == True\n    assert are_coplanar(a, d) == False\n"], "sample_666": ["def test_logging_while_collecting_no_duplicates(testdir):\n    \"\"\"Issue #6240: Calls to logging.xxx() during collection should not cause duplicated logging calls to stderr\"\"\"\n    p = testdir.makepyfile(\n        \"\"\"\\\n        import logging\n\n        logging.warning(\"during collection\")\n\n            logging.warning(\"during call\")\n            assert False\n        \"\"\"\n    )\n    result = testdir.runpytest_subprocess(p, \"--log-cli-level=WARNING\")\n    assert result.ret == ExitCode.TESTS_FAILED\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_*.py F*\",\n            \"====* FAILURES *====\",\n            \"____*____\",\n            \"*--- Captured log call*\",\n            \"WARNING * during call\",\n            \"*1 failed*\",\n        ]\n    )\n    result.stdout.no_fnmatch_line(\"*Captured stderr call*\")\n    result.stdout.no_fnmatch_line(\"*during collection*\")\n    result.stderr.fnmatch_lines([\"WARNING * during collection\"])\n    result.stderr.no_fnmatch_line(\"*during call*\")\n"], "sample_1115": ["def test_tensor_replace_indices():\n    L = TensorIndexType(\"L\")\n    i, j, k, l = tensor_indices(\"i j k l\", L)\n    A, B, C, D = tensor_heads(\"A B C D\", [L])\n    H = TensorHead(\"H\", [L, L])\n    K = TensorHead(\"K\", [L]*4)\n\n    expr = H(i, j)\n    assert expr.replace_indices((i, k), (j, l)) == H(k, l)\n    assert expr.replace_indices((i, -k), (j, l)) == H(-k, l)\n    assert expr.replace_indices((i, k), (j, -l)) == H(k, -l)\n    assert expr.replace_indices((i, -k), (j, -l)) == H(-k, -l)\n\n    expr = A(i)*B(j)\n    assert expr.replace_indices((i, k), (j, l)) == A(k)*B(l)\n    assert expr.replace_indices((i, -k), (j, l)) == A(-k)*B(l)\n    assert expr.replace_indices((i, k), (j, -l)) == A(k)*B(-l)\n    assert expr.replace_indices((i, -k), (j, -l)) == A(-k)*B(-l)\n\n    expr = K(i, j, k, l)\n    assert expr.replace_indices((i, k), (j, l)) == K(k, l, i, j)\n    assert expr.replace_indices((i, -k), (j, l)) == K(-k, l, i, j)\n    assert expr.replace_indices((i, k), (j, -l)) == K(k, -l, i, j)\n    assert expr.replace_indices((i, -k), (j, -l)) == K(-k, -l, i, j)\n"], "sample_466": ["def test_serialize_custom_field(self):\n    class CustomField(models.CharField):\n            self.custom_arg = custom_arg\n            super().__init__(*args, **kwargs)\n\n            name, path, args, kwargs = super().deconstruct()\n            kwargs['custom_arg'] = self.custom_arg\n            return name, path, args, kwargs\n\n    field = CustomField(max_length=255, custom_arg='test')\n    string, imports = MigrationWriter.serialize(field)\n    self.assertEqual(\n        string,\n        \"migrations.test_writer.CustomField(custom_arg='test', max_length=255)\",\n    )\n    self.assertIn(\"import migrations.test_writer\", imports)\n"], "sample_486": ["def test_inlineformset_factory_nulls_default_pks_auto_child_auto_parent(self):\n    \"\"\"\n    #24958 - Variant of test_inlineformset_factory_nulls_default_pks for\n    the case of a parent object with an AutoField primary key and a child\n    object with an AutoField primary key.\n    \"\"\"\n    FormSet = inlineformset_factory(\n        AutoPKParent, AutoPKChildOfUUIDPKParent, fields=\"__all__\"\n    )\n    formset = FormSet()\n    self.assertIsNone(formset.forms[0].fields[\"parent\"].initial)\n"], "sample_403": ["def test_references_field_by_limit_choices_to(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ForeignKey(\n            \"Other\",\n            models.CASCADE,\n            limit_choices_to={\"field\": models.F(\"other_field\")},\n        ),\n    )\n    self.assertIs(operation.references_field(\"Model\", \"other_field\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Other\", \"field\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Other\", \"other_field\", \"migrations\"), False)\n"], "sample_1140": ["def test_issue_18475():\n    assert pretty(Integral(x**2, (x, 0, 1))**2) == \\"], "sample_682": ["def test_xfail_with_boolean_without_reason(self, testdir) -> None:\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(False)\n            pass\n    \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_xfail_marks(item)\n    assert excinfo.value.msg is not None\n    assert (\n        \"\"\"Error evaluating 'xfail': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n        in excinfo.value.msg\n    )\n"], "sample_679": ["def test_mark_evaluator_istrue_with_reason(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        from _pytest.nodes import Node\n        from _pytest.mark import MarkEvaluator\n\n        @pytest.mark.condition(True, reason=\"custom reason\")\n            pass\n\n            item = Node.from_parent(None, name=\"test_func\")\n            evaluator = MarkEvaluator(item, \"condition\")\n            assert evaluator.istrue() is True\n            assert evaluator.getexplanation() == \"custom reason\"\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=2)\n"], "sample_343": ["def test_get_object_cache_respects_updated_objects(self):\n    question1 = Question.objects.create(text='Who?')\n    question2 = Question.objects.create(text='What?')\n    post = Post.objects.create(title='Answer', parent=question1)\n\n    question2.pk = question1.pk\n    question2.save()\n\n    post = Post.objects.get(pk=post.pk)\n    with self.assertNumQueries(1):\n        self.assertEqual(post.object_id, question1.pk)\n        self.assertEqual(post.parent, question2)\n        self.assertEqual(post.parent, question2)\n"], "sample_1059": ["def test_jacobi_normalized():\n    n = Symbol(\"n\")\n    a = Symbol(\"a\")\n    b = Symbol(\"b\")\n\n    assert jacobi_normalized(n, a, b, x) == \\\n           (jacobi(n, a, b, x)/sqrt(2**(a + b + 1)*gamma(a + n + 1)*gamma(b + n + 1)\n                                    /((a + b + 2*n + 1)*factorial(n)*gamma(a + b + n + 1))))\n\n    assert jacobi_normalized(n, a, b, x)._eval_conjugate() == \\\n           jacobi_normalized(n, conjugate(a), conjugate(b), conjugate(x))\n\n    raises(ValueError, lambda: jacobi_normalized(-2.1, a, b, x))\n    raises(ValueError, lambda: jacobi_normalized(Dummy(positive=True, integer=True), 1, 2, oo))\n"], "sample_142": ["def test_readonly_fields_on_inline(self):\n    class CityInline(admin.TabularInline):\n        model = City\n        readonly_fields = ['name']\n\n    errors = CityInline(State, AdminSite()).check()\n    self.assertEqual(errors, [])\n"], "sample_124": ["def test_field_deep_copy_widget(self):\n    class CustomTextInput(TextInput):\n            kwargs['attrs'] = {'class': 'custom-class'}\n            super().__init__(**kwargs)\n\n    field = CharField(widget=CustomTextInput())\n    field_copy = copy.deepcopy(field)\n    self.assertIsInstance(field_copy, CharField)\n    self.assertIsNot(field_copy.widget, field.widget)\n    self.assertIsNot(field_copy.widget.attrs, field.widget.attrs)\n"], "sample_1011": ["def test_MatrixSlice_printing():\n    A = MatrixSymbol(\"A\", 3, 4)\n    assert mcode(A[0:2, 1:3]) == \"A(1:2, 2:3)\"\n    assert mcode(A[0:3:2, 0:4:2]) == \"A(1:2:3, 1:2:4)\"\n    assert mcode(A[0:1, :]) == \"A(1, :)\"\n    assert mcode(A[:, 0:1]) == \"A(:, 1)\"\n    assert mcode(A[0, :]) == \"A(1, :)\"\n    assert mcode(A[:, 0]) == \"A(:, 1)\"\n"], "sample_186": ["def test_list_filter_with_field_list_filter_class(self):\n    class SongAdmin(admin.ModelAdmin):\n        list_filter = [('title', admin.CharFieldListFilter)]\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'list_filter[0][1]' must inherit from 'FieldListFilter'.\",\n            obj=SongAdmin,\n            id='admin.E115',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_409": ["def test_i18n_asvar_safestring_with_filter(self):\n    context = {\"title\": \"<Main Title>\"}\n    output = self.engine.render_to_string(\"i18n_asvar_safestring_with_filter\", context=context)\n    self.assertEqual(output, \"&lt;MAIN TITLE&gt;other text\")\n"], "sample_709": ["def test_pytester_outcomes_deselected_with_multiple_tests(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n            pass\n\n            pass\n\n            pass\n        \"\"\"\n    )\n    result = pytester.runpytest(\"-k\", \"test_one or test_three\")\n    result.assert_outcomes(passed=2, deselected=1)\n"], "sample_362": ["def test_add_custom_fk_with_hardcoded_to_field(self):\n    class HardcodedForeignKey(models.ForeignKey):\n            kwargs['to_field'] = 'custom_id'\n            super().__init__(*args, **kwargs)\n\n            name, path, args, kwargs = super().deconstruct()\n            del kwargs['to_field']\n            return name, path, args, kwargs\n\n    book_hardcoded_fk_to_field = ModelState('testapp', 'Book', [\n        ('author', HardcodedForeignKey('testapp.Author', on_delete=models.CASCADE)),\n    ])\n    changes = self.get_changes(\n        [self.author_empty],\n        [self.author_empty, book_hardcoded_fk_to_field],\n    )\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, ['CreateModel'])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Book')\n"], "sample_659": ["def test_raises_match_unicode(self):\n    msg = u\"with base \\u2603\"\n    with pytest.raises(ValueError, match=msg):\n        int(\"asdf\")\n"], "sample_74": ["def test_no_user(self):\n    self.assertEqual(\n        self._run_it({\n            'database': 'dbname',\n            'host': 'somehost',\n            'port': '444',\n        }), (\n            ['psql', '-h', 'somehost', '-p', '444', 'dbname'],\n            {},\n        )\n    )\n"], "sample_1180": ["def test_direction_ratio():\n    p1 = Point3D(0, 0, 0)\n    p2 = Point3D(1, 1, 1)\n\n    assert p1.direction_ratio(Point3D(1, 0, 0)) == [1, 0, 0]\n    assert p1.direction_ratio(Point3D(0, 1, 0)) == [0, 1, 0]\n    assert p1.direction_ratio(Point3D(0, 0, pi)) == [0, 0, pi]\n\n    assert p1.direction_ratio(Point3D(5, 0, 0)) == [5, 0, 0]\n    assert p1.direction_ratio(Point3D(0, sqrt(3), 0)) == [0, sqrt(3), 0]\n    assert p1.direction_ratio(Point3D(0, 0, 5)) == [0, 0, 5]\n\n    assert p1.direction_ratio(Point3D(2.4, 2.4, 0)) == [2.4, 2.4, 0]\n    assert p1.direction_ratio(Point3D(1, 1, 1)) == [1, 1, 1]\n    assert p1.direction_ratio(Point3D(-12, 0, -15)) == [-12, 0, -15]\n\n    assert p2.direction_ratio(Point3D(0, 0, 0)) == [-1, -1, -1]\n    assert p2.direction_ratio(Point3D(1, 1, 12)) == [-1, -1, 11]\n    assert p2.direction_ratio(Point3D(12, 1, 12)) == [11, 0, 11]\n"], "sample_385": ["def test_render_options_with_empty_value(self):\n    \"\"\"Empty option is present if the field isn't required and value is empty.\"\"\"\n    form = NotRequiredBandForm(initial={\"band\": \"\"})\n    output = form.as_table()\n    self.assertIn(self.empty_option, output)\n"], "sample_631": ["def test_unused_variable_in_function(self):\n    node = astroid.extract_node(\n        \"\"\"\n            unused_var = 10\n        \"\"\"\n    )\n    with self.assertAddsMessages(\n        Message(\"unused-variable\", node=node[\"unused_var\"], args=\"unused_var\")\n    ):\n        self.checker.visit_module(node.root())\n        self.checker.visit_functiondef(node)\n        self.checker.leave_functiondef(node)\n"], "sample_919": ["def test_xref_consistency_cpp_roles(app, status, warning):\n    app.builder.build_all()\n\n    test = 'xref_consistency.html'\n    output = (app.outdir / test).read_text()\n\n        pattern = (r'{role}-role:.*?'\n                   r'<(?P<tag>{tag}) .*?class=[\"\\'](?P<classes>.*?)[\"\\'].*?>'\n                   r'.*'\n                   r'</(?P=tag)>').format(role=role, tag=tag)\n        result = re.search(pattern, output)\n        expect = '''\\"], "sample_967": ["def test_custom_mathjax_path(app, status, warning):\n    app.builder.build_all()\n\n    content = (app.outdir / 'index.html').read_text()\n    assert 'https://example.com/mathjax.js' in content\n"], "sample_318": ["    def test_urlpattern_resolve_with_converters(self):\n        test_urls = [\n            ('/converter/int/42/', {'value': 42}),\n            ('/converter/slug/hello-world/', {'value': 'hello-world'}),\n            ('/converter/uuid/123e4567-e89b-12d3-a456-426614174000/', {'value': '123e4567-e89b-12d3-a456-426614174000'}),\n        ]\n        for path, expected_kwargs in test_urls:\n            with self.subTest(path=path):\n                match = resolve(path)\n                self.assertEqual(match.kwargs, expected_kwargs)\n"], "sample_555": ["def test_default_fill():\n    patch = Patch()\n    assert patch.get_fill() is True\n"], "sample_975": ["def test_nsolve_with_complex_solution():\n    x = Symbol('x')\n    eq = x**2 + 1\n    sol = nsolve(eq, x, 1)\n    assert abs(sol - 1j) < 1e-15\n"], "sample_194": ["def test_opclasses_database_constraint(self):\n    UniqueConstraintProduct.objects.create(name='p1', color='red')\n    with self.assertRaises(IntegrityError):\n        UniqueConstraintProduct.objects.create(name='p1', color='red')\n"], "sample_236": ["def test_fast_delete_with_keeping_parents(self):\n    child = RChild.objects.create()\n    parent_id = child.r_ptr_id\n    collector = Collector(using='default')\n    self.assertTrue(collector.can_fast_delete(child))\n    child.delete(keep_parents=True)\n    self.assertFalse(RChild.objects.filter(id=child.id).exists())\n    self.assertTrue(R.objects.filter(id=parent_id).exists())\n"], "sample_443": ["def test_cache_versioning_get_many(self):\n    # set, using default version = 1\n    cache.set_many({\"ford1\": 37, \"arthur1\": 42})\n    self.assertEqual(\n        cache.get_many([\"ford1\", \"arthur1\"]), {\"ford1\": 37, \"arthur1\": 42}\n    )\n    self.assertEqual(\n        cache.get_many([\"ford1\", \"arthur1\"], version=1),\n        {\"ford1\": 37, \"arthur1\": 42},\n    )\n    self.assertEqual(cache.get_many([\"ford1\", \"arthur1\"], version=2), {})\n\n    self.assertEqual(caches[\"v2\"].get_many([\"ford1\", \"arthur1\"]), {})\n    self.assertEqual(\n        caches[\"v2\"].get_many([\"ford1\", \"arthur1\"], version=1),\n        {\"ford1\": 37, \"arthur1\": 42},\n    )\n    self.assertEqual(caches[\"v2\"].get_many([\"ford1\", \"arthur1\"], version=2), {})\n\n    # set, default version = 1, but manually override version = 2\n    cache.set_many({\"ford2\": 37, \"arthur2\": 42}, version=2)\n    self.assertEqual(cache.get_many([\"ford2\", \"arthur2\"]), {})\n    self.assertEqual(cache.get_many([\"ford2\", \"arthur2\"], version=1), {})\n    self.assertEqual(\n        cache.get_many([\"ford2\", \"arthur2\"], version=2),\n        {\"ford2\": 37, \"arthur2\": 42},\n    )\n\n    self.assertEqual(\n        caches[\"v2\"].get_many([\"ford2\", \"arthur2\"]), {\"ford2\": 37, \"arthur2\": 42}\n    )\n    self.assertEqual(caches[\"v2\"].get_many([\"ford2\", \"arthur2\"], version=1), {})\n    self."], "sample_212": ["def test_session_middleware_process_request(self):\n    \"\"\"\n    Test that SessionMiddleware.process_request() sets request.session correctly.\n    \"\"\"\n    request = HttpRequest()\n    request.COOKIES[settings.SESSION_COOKIE_NAME] = 'test_session_key'\n    middleware = SessionMiddleware(lambda r: HttpResponse())\n    middleware.process_request(request)\n    self.assertIsInstance(request.session, middleware.SessionStore)\n    self.assertEqual(request.session.session_key, 'test_session_key')\n"], "sample_297": ["    def test_ticket_24605_exclude(self):\n        \"\"\"\n        Test exclude() with a subquery.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(\n            Individual.objects.exclude(Q(alive=False), Q(related_individual__isnull=True)),\n            [i1, i3]\n        )\n"], "sample_156": ["def test_field_deep_copy_widget(self):\n    class CustomTextInput(TextInput):\n            kwargs['attrs'] = {'class': 'custom-class'}\n            super().__init__(**kwargs)\n\n    field = CharField(widget=CustomTextInput())\n    field_copy = copy.deepcopy(field)\n    self.assertIsInstance(field_copy, CharField)\n    self.assertIsNot(field_copy.widget, field.widget)\n    self.assertIsInstance(field_copy.widget, CustomTextInput)\n    self.assertIsNot(field_copy.widget.attrs, field.widget.attrs)\n"], "sample_452": ["def test_references_field_by_limit_choices_to(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ForeignKey(\n            \"Other\",\n            models.CASCADE,\n            limit_choices_to={\"field\": models.F(\"other_field\")},\n        ),\n    )\n    self.assertIs(operation.references_field(\"Model\", \"other_field\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Other\", \"field\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Other\", \"other_field\", \"migrations\"), False)\n"], "sample_1120": ["def test_matrix_symbol_subs():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = MatrixSymbol('C', p, q)\n\n    assert A.subs(A, B) == B\n    assert A.subs(A, C) == C\n    assert (A*B).subs(A, C) == C*B\n    assert (A*B).subs(B, C) == A*C\n    assert (A*B).subs({A: C, B: D}) == C*D\n"], "sample_34": ["def test_unit_summary_physical_type():\n    \"\"\"\n    Test for a few units that the unit summary table correctly reports\n    the physical type of the unit.\n\n    Regression test for https://github.com/astropy/astropy/issues/3835\n    \"\"\"\n\n    from .. import astrophys\n\n    for summary in utils._iter_unit_summary(astrophys.__dict__):\n        unit, _, _, physical_type, _ = summary\n\n        if unit.name == 'lyr':\n            assert physical_type == 'length'\n        elif unit.name == 'pc':\n            assert physical_type == 'length'\n        elif unit.name == 'barn':\n            assert physical_type == 'area'\n        elif unit.name == 'cycle':\n            assert physical_type == 'dimensionless'\n        elif unit.name == 'vox':\n            assert physical_type == 'volume'\n"], "sample_368": ["def test_minimize_rollbacks_multiple_targets(self):\n    r\"\"\"\n    Minimize rollbacks when targeting multiple migrations.\n\n    a: 1 <---- 3 <--\\\n              \\ \\- 2 <--- 4\n               \\       \\\n    b:      \\- 1 <--- 2\n    \"\"\"\n    a1_impl = FakeMigration('a1')\n    a1 = ('a', '1')\n    a2_impl = FakeMigration('a2')\n    a2 = ('a', '2')\n    a3_impl = FakeMigration('a3')\n    a3 = ('a', '3')\n    a4_impl = FakeMigration('a4')\n    a4 = ('a', '4')\n    b1_impl = FakeMigration('b1')\n    b1 = ('b', '1')\n    b2_impl = FakeMigration('b2')\n    b2 = ('b', '2')\n    graph = MigrationGraph()\n    graph.add_node(a1, a1_impl)\n    graph.add_node(a2, a2_impl)\n    graph.add_node(a3, a3_impl)\n    graph.add_node(a4, a4_impl)\n    graph.add_node(b1, b1_impl)\n    graph.add_node(b2, b2_impl)\n    graph.add_dependency(None, a2, a1)\n    graph.add_dependency(None, a3, a1)\n    graph.add_dependency(None, a4, a2)\n    graph.add_dependency(None, a4, a3)\n    graph.add_dependency(None, b2, b1)\n    graph.add_dependency(None, b1, a1)\n    graph.add_dependency(None, b2, a2)\n\n    executor = MigrationExecutor(None)\n    executor.loader = FakeLoader(graph, {\n        a1: a1_impl,\n        b1: b1_impl,\n        a2: a2_impl,"], "sample_994": ["def test_Float_from_mpmath():\n    import mpmath\n    mpmath.mp.dps = 100\n    mp_pi = mpmath.pi()\n\n    assert Float(mp_pi, 100) == Float(mp_pi._mpf_, 100) == pi.evalf(100)\n\n    mpmath.mp.dps = 15\n\n    assert Float(mp_pi, 100) == Float(mp_pi._mpf_, 100) == pi.evalf(100)\n"], "sample_339": ["def test_modelformset_factory_with_custom_form_class(self):\n    class CustomBookForm(forms.ModelForm):\n        class Meta:\n            model = Book\n            fields = '__all__'\n\n    BookFormSet = modelformset_factory(Book, form=CustomBookForm)\n    formset = BookFormSet()\n    self.assertIsInstance(formset.form, CustomBookForm)\n"], "sample_598": ["def test_format_timedelta():\n    cases = [\n        (pd.Timedelta(\"10 days 1 hour\"), \"10 days 01:00:00\", \"10 days\", \"01:00:00\"),\n        (pd.Timedelta(\"-3 days\"), \"-3 days +00:00:00\", \"-3 days\", \"00:00:00\"),\n        (pd.Timedelta(\"3 hours\"), \"0 days 03:00:00\", \"0 days\", \"03:00:00\"),\n        (pd.Timedelta(\"NaT\"), \"NaT\", \"NaT\", \"NaT\"),\n    ]\n    for item, expected, date_expected, time_expected in cases:\n        actual = formatting.format_timedelta(item)\n        assert expected == actual\n        actual_date = formatting.format_timedelta(item, timedelta_format=\"date\")\n        assert date_expected == actual_date\n        actual_time = formatting.format_timedelta(item, timedelta_format=\"time\")\n        assert time_expected == actual_time\n"], "sample_396": ["    def test_ticket_24605_exclude(self):\n        \"\"\"\n        Test exclude() with a subquery.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(\n            Individual.objects.exclude(\n                Q(alive=False), Q(related_individual__isnull=True)\n            ).order_by(\"pk\"),\n            [i1, i2, i3],\n        )\n"], "sample_998": ["def test_Quaternion_latex_printing_with_zero_components():\n    q = Quaternion(0, 0, 0, 0)\n    assert latex(q) == \"0\"\n    q = Quaternion(0, y, 0, 0)\n    assert latex(q) == \"y i\"\n    q = Quaternion(0, 0, z, 0)\n    assert latex(q) == \"z j\"\n    q = Quaternion(0, 0, 0, t)\n    assert latex(q) == \"t k\"\n"], "sample_1195": ["def test_gamma_matrix_simplify_with_tensor_heads():\n    p, q = tensor_heads('p, q', [LorentzIndex])\n    i0, i1, i2, i3, i4, i5 = tensor_indices('i0:6', LorentzIndex)\n    ps = p(i0)*G(-i0)\n    qs = q(i0)*G(-i0)\n    t = ps*qs*ps*qs\n    r = simplify_gamma_expression(t)\n    assert _is_tensor_eq(r, 8*p(i0)*q(-i0)*p(i1)*q(-i1) - 4*p(i0)*p(-i0)*q(i1)*q(-i1))\n"], "sample_49": ["def test_media_inheritance_from_widget(self):\n    # If a widget extends another but defines media, it extends the parent widget's media,\n    # even if the parent defined media using a widget.\n    class MyWidget1(TextInput):\n        class Media:\n            css = {\n                'all': ('path/to/css1', '/path/to/css2')\n            }\n            js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')\n\n    class MyWidget4(TextInput):\n        media = Media(css={'all': ('/some/path',)}, js=('/some/js',))\n\n    class MyWidget9(MyWidget4):\n        class Media:\n            css = {\n                'all': ('/other/path',)\n            }\n            js = ('/other/js',)\n\n    w9 = MyWidget9()\n    self.assertEqual(\n        str(w9.media),\n        \"\"\"<link href=\"/some/path\" type=\"text/css\" media=\"all\" rel=\"stylesheet\">"], "sample_987": ["def test_evalf_complex_accuracy():\n    assert complex_accuracy((from_float(2.0), from_float(10.0), 35, 100)) == 37\n    assert complex_accuracy((from_float(2.0), from_float(1000.0), 35, 100)) == 43\n    assert complex_accuracy((from_float(2.0), from_float(10.0), 100, 35)) == 35\n    assert complex_accuracy((from_float(2.0), from_float(1000.0), 100, 35)) == 35\n"], "sample_542": ["def test_text_rotation_mode():\n    fig, ax = plt.subplots()\n    text = ax.text(0.5, 0.5, 'test', rotation=30, rotation_mode='anchor')\n    fig.canvas.draw()\n    assert text.get_rotation_mode() == 'anchor'\n    assert text.get_rotation() == 30\n\n    text.set_rotation_mode('default')\n    fig.canvas.draw()\n    assert text.get_rotation_mode() == 'default'\n    assert text.get_rotation() == 30\n"], "sample_334": ["def test_field_deep_copy_widget(self):\n    class CustomTextInput(TextInput):\n            kwargs['attrs'] = {'class': 'custom-class'}\n            super().__init__(**kwargs)\n\n    field = CharField(widget=CustomTextInput())\n    field_copy = copy.deepcopy(field)\n    self.assertIsInstance(field_copy, CharField)\n    self.assertIsNot(field_copy.widget, field.widget)\n    self.assertIsInstance(field_copy.widget, CustomTextInput)\n    self.assertIsNot(field_copy.widget.attrs, field.widget.attrs)\n"], "sample_835": ["def test_adaboost_regressor_loss_functions():\n    # Check that all loss functions work correctly in AdaBoostRegressor\n    X, y = datasets.make_regression(n_samples=100, n_features=10, noise=0.1, random_state=0)\n\n    for loss in ['linear', 'square', 'exponential']:\n        reg = AdaBoostRegressor(n_estimators=50, loss=loss, random_state=0)\n        reg.fit(X, y)\n        score = reg.score(X, y)\n        assert score > 0.8, f\"Failed with loss function {loss} and score = {score}\"\n"], "sample_305": ["def test_annotate_with_f_expression(self):\n    # Test annotate with F expression\n    qs = Book.objects.annotate(discounted_price=F('price') * 0.9)\n    book = qs.get(pk=self.b1.pk)\n    self.assertEqual(book.discounted_price, Decimal('27.00'))\n"], "sample_964": ["def test_pyfunction_with_positional_only_arguments(app):\n    text = \".. py:function:: hello(a, /, b)\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, ([desc_parameter, desc_sig_name, \"a\"],\n                                      [desc_parameter, desc_sig_operator, \"/\"],\n                                      [desc_parameter, desc_sig_name, \"b\"])])\n"], "sample_774": ["def test_one_hot_encoder_drop_first():\n    enc = OneHotEncoder(drop='first')\n    X = [['abc', 2, 55], ['def', 1, 55], ['abc', 3, 55]]\n    trans = enc.fit_transform(X).toarray()\n    exp = [[0, 1, 1], [1, 0, 1], [0, 1, 0]]\n    assert_array_equal(trans, exp)\n    dropped_cats = [cat[feature]\n                    for cat, feature in zip(enc.categories_,\n                                            enc.drop_idx_)]\n    assert_array_equal(dropped_cats, ['abc', 2, 55])\n    assert_array_equal(np.array(X, dtype=object),\n                       enc.inverse_transform(trans))\n"], "sample_946": ["def test_pyfunction_signature_with_default_value(app):\n    text = \".. py:function:: hello(name: str = 'World') -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_punctuation, \":\"],\n                                                      \" \",\n                                                      [nodes.inline, pending_xref, \"str\"],\n                                                      \" \",\n                                                      [desc_sig_operator, \"=\"],\n                                                      \" \",\n                                                      [nodes.inline, \"'World'\"])])\n"], "sample_962": ["def test_restify_mock_decorator():\n    with mock(['decorator']):\n        import decorator\n        @decorator.decorator\n            pass\n\n        @my_decorator\n            pass\n\n        assert restify(my_function) == ':py:func:`tests.test_util_typing.my_function`'\n"], "sample_1013": ["def test_lambdify_with_custom_function():\n        return x**3\n\n    f = lambdify(x, custom_func(x), {'custom_func': custom_func})\n    assert f(2) == 8\n"], "sample_459": ["def test_integerfield_float_rounding(self):\n    instance = self.model(value=1.5)\n    instance.full_clean()\n    instance.save()\n    qs = self.model.objects.filter(value=2)\n    self.assertEqual(qs.count(), 1)\n    self.assertEqual(qs[0].value, 2)\n"], "sample_527": ["def test_toolmanager_add_tool():\n    with pytest.warns(UserWarning, match=_EXPECTED_WARNING_TOOLMANAGER):\n        plt.rcParams['toolbar'] = 'toolmanager'\n    fig = plt.gcf()\n    initial_len = len(fig.canvas.manager.toolmanager.tools)\n    assert 'custom_tool' not in fig.canvas.manager.toolmanager.tools\n    fig.canvas.manager.toolmanager.add_tool('custom_tool', 'Custom Tool')\n    assert len(fig.canvas.manager.toolmanager.tools) == initial_len + 1\n    assert 'custom_tool' in fig.canvas.manager.toolmanager.tools\n"], "sample_786": ["def test_transform_invalid_shape():\n    est = KBinsDiscretizer(n_bins=3).fit(X)\n    bad_X = np.arange(12).reshape(3, -1)\n    assert_raise_message(ValueError,\n                         \"Incorrect number of features. Expecting 4, \"\n                         \"received 3\", est.transform, bad_X)\n"], "sample_387": ["def test_ForeignKey_with_limit_choices_to(self):\n    from selenium.webdriver.common.by import By\n    from selenium.webdriver.support.ui import Select\n\n    # Create a band that matches the limit_choices_to condition\n    Band.objects.create(id=100, name=\"Limited Band\", genre=\"Rock\")\n    # Create a band that doesn't match the limit_choices_to condition\n    Band.objects.create(id=101, name=\"Excluded Band\", genre=\"Pop\")\n\n    self.admin_login(username=\"super\", password=\"secret\", login_url=\"/\")\n    self.selenium.get(\n        self.live_server_url + reverse(\"admin:admin_widgets_event_add\")\n    )\n\n    # Check that the limited band is in the dropdown\n    select = Select(self.selenium.find_element(By.ID, \"id_limited_band\"))\n    options = [option.text for option in select.options]\n    self.assertIn(\"Limited Band\", options)\n    # Check that the excluded band is not in the dropdown\n    self.assertNotIn(\"Excluded Band\", options)\n"], "sample_669": ["def test_encodedfile_isatty(tmpfile: BinaryIO) -> None:\n    ef = capture.EncodedFile(tmpfile, encoding=\"utf-8\")\n    assert not ef.isatty()\n"], "sample_27": ["def test_rawdatadiff_diff_with_atol(tmp_path):\n    \"\"\"Regression test for https://github.com/astropy/astropy/issues/13330\"\"\"\n    path1 = tmp_path / \"test1.fits\"\n    path2 = tmp_path / \"test2.fits\"\n    a = np.zeros((10, 2), dtype=\"float32\")\n    a[:, 0] = np.arange(10, dtype=\"float32\") + 10\n    a[:, 1] = np.arange(10, dtype=\"float32\") + 20\n    b = a.copy()\n    changes = [(3, 13.1, 23.1), (8, 20.5, 30.5)]\n    for i, v, w in changes:\n        b[i, 0] = v\n        b[i, 1] = w\n\n    ca = Column(\"A\", format=\"20E\", array=[a])\n    cb = Column(\"A\", format=\"20E\", array=[b])\n    hdu_a = BinTableHDU.from_columns([ca])\n    hdu_a.writeto(path1, overwrite=True)\n    hdu_b = BinTableHDU.from_columns([cb])\n    hdu_b.writeto(path2, overwrite=True)\n    with fits.open(path1) as fits1:\n        with fits.open(path2) as fits2:\n            diff = FITSDiff(fits1, fits2, atol=0.001, rtol=0)\n            str1 = diff.report(fileobj=None, indent=0)\n\n            diff = FITSDiff(fits1, fits2, atol=0.1, rtol=0)\n            str2 = diff.report(fileobj=None, indent=0)\n\n    assert \"...and at 1 more indices.\" in str1\n    assert \"...and at 1 more indices.\" not in str2\n"], "sample_673": ["def test_doctest_module_with_conftest(self, testdir):\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            return 42\n        \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n            '''\n            >>> myfixture\n            42\n            '''\n        \"\"\"\n    )\n    reprec = testdir.inline_run(\"--doctest-modules\")\n    reprec.assertoutcome(passed=1)\n"], "sample_710": ["def test_teardown_class_exception(pytester: Pytester) -> None:\n    testpath = pytester.makepyfile(\n        \"\"\"\n        import unittest\n        class MyTestCase(unittest.TestCase):\n            values = []\n            @classmethod\n                cls.values.append(1)\n                raise Exception(\"tearDownClass exception\")\n                pass\n            assert MyTestCase.values == [1]\n    \"\"\"\n    )\n    reprec = pytester.inline_run(testpath)\n    passed, skipped, failed = reprec.countoutcomes()\n    assert passed == 1\n    assert failed == 1\n"], "sample_834": ["def test_transform_before_fit():\n    # Test that transform raises an error if fit has not been called\n    nca = NeighborhoodComponentsAnalysis()\n    X = iris_data\n    assert_raises(NotFittedError, nca.transform, X)\n"], "sample_678": ["def test_ensure_deletable_no_lock(tmp_path):\n    \"\"\"ensure_deletable should return True if no lock file exists\"\"\"\n    path = tmp_path / \"dir\"\n    path.mkdir()\n    assert ensure_deletable(path, consider_lock_dead_if_created_before=0)\n"], "sample_635": ["def test_finds_missing_raises_from_setter_epytext(self) -> None:\n    \"\"\"Example of a setter having missing raises documentation in\n    the Epytext style docstring of the property\n    \"\"\"\n    property_node, node = astroid.extract_node(\n        \"\"\"\n    class Foo(object):\n        @property\n            '''@type: int\n\n            Include a \"@raise\" section so that this is identified\n            as an Epytext docstring and not a Sphinx docstring.\n\n            @raise RuntimeError: Always\n            '''\n            raise RuntimeError()\n            return 10\n\n        @foo.setter\n            raise AttributeError() #@\n    \"\"\"\n    )\n    with self.assertAddsMessages(\n        MessageTest(\n            msg_id=\"missing-raises-doc\",\n            node=property_node,\n            args=(\"AttributeError\",),\n        )\n    ):\n        self.checker.visit_raise(node)\n"], "sample_1156": ["def test_tanh_positive():\n    p = Symbol('p', positive=True)\n    n = Symbol('n', negative=True)\n    assert tanh(p).is_positive is True\n    assert tanh(n).is_negative is True\n"], "sample_741": ["def test_grid_search_with_custom_scorer():\n    # Test grid-search with custom scorer\n    X, y = make_classification(n_samples=50, n_features=4, random_state=42)\n\n        y_pred = estimator.predict(X)\n        return np.mean(y_pred == y)\n\n    grid_search = GridSearchCV(SVC(gamma='scale'), param_grid={'C': [1, 10]}, scoring=custom_scorer)\n    grid_search.fit(X, y)\n    assert_true(grid_search.best_score_ >= 0)\n    assert_true(grid_search.best_score_ <= 1)\n"], "sample_434": ["    def test_dispatch_calls_correct_handler(self):\n        request_factory = RequestFactory()\n        tests = [\n            (SyncView, False),\n            (AsyncView, True),\n        ]\n        for view_cls, is_coroutine in tests:\n            with self.subTest(view_cls=view_cls, is_coroutine=is_coroutine):\n                instance = view_cls()\n                instance.setup(request_factory.get(\"/\"))\n                response = instance.dispatch(request_factory.get(\"/\"))\n                self.assertIs(\n                    asyncio.iscoroutine(response),\n                    is_coroutine,\n                )\n                if is_coroutine:\n                    response = asyncio.run(response)\n\n                self.assertEqual(response.content, b\"Hello (sync) world!\")\n"], "sample_529": ["def test_legend_markers_from_line2d_with_no_marker():\n    # Test that markers can be copied for legend lines when no marker is specified\n    fig, ax = plt.subplots()\n    lines = [mlines.Line2D([0], [0], ls='-')]\n    labels = [\"line\"]\n    legend = ax.legend(lines, labels)\n\n    new_markers = [line.get_marker() for line in legend.get_lines()]\n    new_labels = [text.get_text() for text in legend.get_texts()]\n\n    assert new_markers == ['None']\n    assert labels == new_labels\n"], "sample_1145": ["def test_refine_abs_mul():\n    x = Symbol('x', real=True)\n    y = Symbol('y', real=True)\n    assert refine(Abs(x * y), Q.positive(x) & Q.positive(y)) == x * y\n    assert refine(Abs(x * y), Q.positive(x) & Q.negative(y)) == -x * y\n    assert refine(Abs(x * y), Q.negative(x) & Q.positive(y)) == -x * y\n    assert refine(Abs(x * y), Q.negative(x) & Q.negative(y)) == x * y\n"], "sample_602": ["def test_open_dataset_with_decode_coords():\n    # Create a simple dataset with a coordinate variable\n    ds = xr.Dataset(\n        data_vars={\"var\": (\"x\", np.arange(5))},\n        coords={\"coord\": (\"x\", np.arange(5), {\"coordinates\": \"var\"})},\n    )\n\n    # Save the dataset to a temporary file\n    with xr.testing.create_tmp_file() as tmp_file:\n        ds.to_netcdf(tmp_file)\n\n        # Open the dataset with decode_coords=True\n        ds_decoded = xr.open_dataset(tmp_file, decode_coords=True)\n\n        # Check that the coordinate variable is now a coordinate\n        assert \"coord\" in ds_decoded.coords\n"], "sample_1161": ["def test_issue_21537():\n    assert str(Mul(x, Pow(1/y, -1, evaluate=False), evaluate=False)) == 'x/(1/y)'\n"], "sample_70": ["def test_fast_delete_with_signals(self):\n    # Test that fast_delete still works when there are signals connected\n        pass\n\n    models.signals.pre_delete.connect(noop, sender=User)\n    models.signals.post_delete.connect(noop, sender=User)\n\n    u = User.objects.create(\n        avatar=Avatar.objects.create()\n    )\n    a = Avatar.objects.get(pk=u.avatar_id)\n    # 1 query to fast-delete the user\n    # 1 query to delete the avatar\n    self.assertNumQueries(2, a.delete)\n    self.assertFalse(User.objects.exists())\n    self.assertFalse(Avatar.objects.exists())\n\n    models.signals.pre_delete.disconnect(noop, sender=User)\n    models.signals.post_delete.disconnect(noop, sender=User)\n"], "sample_811": ["def test_pairwise_distances_callable():\n    # Test the pairwise_distance helper function\n    # with a callable function, with given keywords.\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((5, 4))\n    Y = rng.random_sample((2, 4))\n\n    metric = callable_rbf_kernel\n    kwds = {'gamma': 0.1}\n    S = pairwise_distances(X, Y, metric=metric, **kwds)\n    S2 = rbf_kernel(X, Y, **kwds)\n    assert_array_almost_equal(S, S2)\n\n    # callable function, X=Y\n    S = pairwise_distances(X, Y=X, metric=metric, **kwds)\n    S2 = rbf_kernel(X, Y=X, **kwds)\n    assert_array_almost_equal(S, S2)\n"], "sample_483": ["def test_list_display_links_not_a_list_or_tuple(self):\n    class SongAdmin(admin.ModelAdmin):\n        list_display_links = \"test\"\n\n    self.assertEqual(\n        SongAdmin(Song, AdminSite()).check(),\n        [\n            checks.Error(\n                \"The value of 'list_display_links' must be a list, a tuple, or None.\",\n                obj=SongAdmin,\n                id=\"admin.E110\",\n            )\n        ],\n    )\n"], "sample_10": ["def test_read_write_with_compression(tmp_path):\n    test_file = tmp_path / \"test.csv.gz\"\n    t1 = Table()\n    t1['a'] = [1, 2, 3]\n    t1.write(test_file, format='ascii.csv', overwrite=True)\n    t2 = Table.read(test_file, format='ascii.csv')\n    assert np.all(t2['a'] == [1, 2, 3])\n"], "sample_717": ["def test_load_fake_lfw_pairs_invalid_subset():\n    assert_raises(ValueError, fetch_lfw_pairs, data_home=SCIKIT_LEARN_DATA, subset='invalid', download_if_missing=False)\n"], "sample_140": ["    def test_sensitive_variables_decorator(self):\n        @sensitive_variables('password')\n            return password\n\n        request = RequestFactory().get('/')\n        request.password = 'secret'\n        response = test_func(request.password)\n        self.assertEqual(response, 'secret')\n        self.assertEqual(test_func.sensitive_variables, ('password',))\n"], "sample_971": ["def test_warning_suppressor_filter(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    app.config.suppress_warnings = ['test.logging']\n    warning_suppressor = logging.WarningSuppressor(app)\n\n    record = logging.LogRecord('test', logging.WARNING, 'test.txt', 10, 'message', (), None, 'test', 'logging')\n    assert warning_suppressor.filter(record) is False\n\n    record = logging.LogRecord('test', logging.WARNING, 'test.txt', 10, 'message', (), None, 'test', 'crash')\n    assert warning_suppressor.filter(record) is True\n\n    record = logging.LogRecord('test', logging.WARNING, 'test.txt', 10, 'message', (), None, 'actual', 'logging')\n    assert warning_suppressor.filter(record) is True\n"], "sample_382": ["def test_django_path_not_included(self, mock_reset):\n    with mock.patch('django.utils.autoreload.is_django_path', return_value=True):\n        self.assertIsNone(autoreload.template_changed(None, EXTRA_TEMPLATES_DIR / 'index.html'))\n        mock_reset.assert_not_called()\n"], "sample_642": ["def test_init_hook_abbreviation(capsys: CaptureFixture) -> None:\n    \"\"\"Test that we correctly handle an abbreviated init-hook option.\"\"\"\n    with tempdir() as chroot:\n        with fake_home():\n            chroot_path = Path(chroot)\n            testutils.create_files([\"a/b/c/d/__init__.py\"])\n            os.chdir(chroot_path / \"a/b/c\")\n            with mock.patch(\"builtins.exec\") as mock_exec:\n                with pytest.raises(SystemExit):\n                    Run([\"--init-h\", \"print('test')\"])\n                mock_exec.assert_called_once_with(\"print('test')\")\n"], "sample_420": ["def test_many_to_many_through(self):\n    \"\"\"Data for a ManyToManyField with a through model is a list rather than a lazy QuerySet.\"\"\"\n    item = Dice.objects.create()\n    n1 = Number.objects.create(value=1)\n    n2 = Number.objects.create(value=2)\n    item.numbers.set([n1])\n    data = model_to_dict(item)[\"numbers\"]\n    self.assertEqual(data, [n1])\n    item.numbers.set([n2])\n    # If data were a QuerySet, it would be reevaluated here and give \"n2\"\n    # instead of the original value.\n    self.assertEqual(data, [n1])\n"], "sample_31": ["def test_write_latex_no_latex_names(self, write, tmp_path, format):\n    \"\"\"Test to write a LaTeX file without using LaTeX names for the parameters\"\"\"\n    fp = tmp_path / \"test_write_latex_no_latex_names.tex\"\n    write(fp, format=format, latex_names=False)\n    tbl = QTable.read(fp)\n    # asserts each column name has not been changed\n    for column_name in tbl.colnames[2:]:\n        assert column_name not in _FORMAT_TABLE.values()\n"], "sample_64": ["    def test_redirect_with_query_params(self):\n        response = HttpResponseRedirect('/redirected/?param1=value1&param2=value2')\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(response.url, '/redirected/?param1=value1&param2=value2')\n"], "sample_694": ["def test_argument_type_str_choice(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n            group = parser.getgroup('custom')\n            group.addoption('--custom-option', type='str', choices=['a', 'b'])\n        \"\"\"\n    )\n    result = pytester.runpytest(\"-Wdefault::pytest.PytestRemovedIn8Warning\")\n    result.assert_outcomes(passed=1)\n\n    # No warning should be raised as 'str' is a valid type for choices\n    assert \"PytestRemovedIn8Warning\" not in result.stdout.str()\n"], "sample_159": ["def test_is_anonymous_authenticated_properties(self):\n    \"\"\"\n    <User Model>.is_anonymous/is_authenticated can be properties.\n    \"\"\"\n    class CustomUserWithProperties(AbstractBaseUser):\n        username = models.CharField(max_length=30, unique=True)\n        USERNAME_FIELD = 'username'\n\n        @property\n            return False\n\n        @property\n            return True\n\n    errors = checks.run_checks(app_configs=self.apps.get_app_configs())\n    self.assertEqual(errors, [])\n"], "sample_1082": ["def test_asinh_expansion():\n    x, y = symbols('x, y')\n    assert asinh(x + y).expand(trig=True) == asinh(x) + asinh(y) + log(1 + x*y/sqrt(1 + x**2)/sqrt(1 + y**2))\n    assert asinh(2*x).expand(trig=True) == asinh(x) + log(sqrt(2) + 1)\n    assert asinh(3*x).expand(trig=True).expand() == asinh(x) + log(3 + 3*sqrt(2))\n"], "sample_848": ["def test_multi_output_regressor_score():\n    # Test the score method of MultiOutputRegressor\n    X, y = datasets.make_regression(n_targets=3)\n    X_train, y_train = X[:50], y[:50]\n    X_test, y_test = X[50:], y[50:]\n\n    rgr = MultiOutputRegressor(GradientBoostingRegressor(random_state=0))\n    rgr.fit(X_train, y_train)\n    score = rgr.score(X_test, y_test)\n\n    assert isinstance(score, float)\n    assert 0 <= score <= 1\n"], "sample_473": ["compilation error"], "sample_745": ["def test_function_transformer_sparse_input():\n    X_sparse = sparse.csr_matrix(np.array([[1, 0, 3], [0, 4, 0], [5, 0, 7]]))\n    transformer = FunctionTransformer(func=np.sqrt, accept_sparse=True)\n    X_sparse_trans = transformer.fit_transform(X_sparse)\n    assert sparse.issparse(X_sparse_trans)\n    assert_allclose_dense_sparse(X_sparse_trans.toarray(), np.sqrt(X_sparse.toarray()))\n"], "sample_1184": ["def test_beam_parameter_n():\n    p = BeamParameter(530e-9, 1, w=1e-3, n=2)\n    assert p.n == 2\n"], "sample_360": ["def test_cache_key_varies_by_host(self):\n    \"\"\"\n    get_cache_key keys differ by host instead of path\n    \"\"\"\n    request1 = self.factory.get(self.path, HTTP_HOST='sub-1.example.com')\n    learn_cache_key(request1, HttpResponse())\n    request2 = self.factory.get(self.path, HTTP_HOST='sub-2.example.com')\n    learn_cache_key(request2, HttpResponse())\n    self.assertNotEqual(get_cache_key(request1), get_cache_key(request2))\n"], "sample_1143": ["def test_Float_floordiv():\n    assert Float(2.7) // Float(1.3) == 2.0\n    assert Float(2.7) // 1.3 == 2.0\n    assert 2.7 // Float(1.3) == 2.0\n"], "sample_1009": ["def test_vector_applyfunc():\n    x, y, z = symbols('x y z')\n    N = ReferenceFrame('N')\n\n    v = x * N.x + y * N.y + z * N.z\n    v_applied = v.applyfunc(sin)\n\n    assert v_applied == sin(x) * N.x + sin(y) * N.y + sin(z) * N.z\n"], "sample_250": ["def test_time_formats_with_microseconds(self):\n    dt = datetime(2009, 5, 16, 5, 30, 30, 123456)\n    self.assertEqual(dateformat.format(dt, 'u'), '123456')\n"], "sample_3": ["def test_guess_ecsv_with_delimiter():\n    \"\"\"Test guessing ECSV with a specified delimiter\"\"\"\n    txt = \"\"\"\n    # %ECSV 1.0\n    # ---\n    # datatype:\n    # - {name: col1, datatype: int64}\n    # - {name: col2, datatype: float64}\n    # delimiter: ','\n    # schema: astropy-2.0\n    col1,col2\n    1,1.0\n    2,2.0\n    \"\"\"\n    t = ascii.read(txt, delimiter=',')\n    assert t['col1'].dtype.kind == 'i'\n    assert t['col2'].dtype.kind == 'f'\n"], "sample_570": ["def test_bivariate_probability_stat_weights(self, x, y, weights):\n\n    h = Histogram(stat=\"probability\")\n    heights, _ = h(x, y, weights=weights)\n    assert heights.sum() == pytest.approx(1)\n"], "sample_797": ["def test_power_transformer_sparse_input():\n    # Check that sparse input is handled correctly\n    X_dense = np.abs(X_2d)\n    X_sparse = sparse.csr_matrix(X_dense)\n\n    for standardize in [True, False]:\n        pt_dense = PowerTransformer(method='box-cox', standardize=standardize)\n        pt_sparse = PowerTransformer(method='box-cox', standardize=standardize)\n\n        X_trans_dense = pt_dense.fit_transform(X_dense)\n        X_trans_sparse = pt_sparse.fit_transform(X_sparse)\n\n        assert_array_almost_equal(X_trans_dense, X_trans_sparse.toarray())\n\n        # Test inverse transformation\n        X_inv_dense = pt_dense.inverse_transform(X_trans_dense)\n        X_inv_sparse = pt_sparse.inverse_transform(X_trans_sparse)\n\n        assert_array_almost_equal(X_inv_dense, X_inv_sparse.toarray())\n"], "sample_530": ["def test_offsetbox_set_figure():\n    fig1, ax1 = plt.subplots()\n    fig2, ax2 = plt.subplots()\n    ob = OffsetBox()\n    ob.set_figure(fig1)\n    assert ob.figure == fig1\n    ob.set_figure(fig2)\n    assert ob.figure == fig2\n"], "sample_996": ["def test_product_with_zero_factor():\n    assert product(0, (k, 1, n)) == 0\n"], "sample_901": ["def test_k_means_elkan_algorithm_with_sparse_data():\n    # check that elkan algorithm raises TypeError when sparse data is passed\n    km = KMeans(algorithm='elkan')\n    assert_raises(TypeError, km.fit, X_csr)\n"], "sample_1137": ["def test_quantity_simplify():\n    from sympy.physics.units.util import quantity_simplify\n    from sympy.physics.units.prefixes import kilo\n    from sympy.physics.units import foot, inch\n    assert quantity_simplify(kilo*foot*inch) == 250*foot**2/3\n    assert quantity_simplify(foot - 6*inch) == foot/2\n"], "sample_285": ["def test_default_storage_finder_without_base_location(self):\n    with self.assertRaisesMessage(ImproperlyConfigured, \"The storage backend of the staticfiles finder 'DefaultStorageFinder' doesn't have a valid location.\"):\n        get_finder('django.contrib.staticfiles.finders.DefaultStorageFinder')\n"], "sample_1150": ["def test_issue_18146():\n    e = Symbol('e', integer=True, even=True)\n    o = Symbol('o', integer=True, odd=True)\n    assert Range(5).contains(i) == And(i >= 0, i <= 4)\n    assert Range(1, 9, 2).contains(e) == False\n    assert Range(1, 9, 2).contains(o) == And(o >= 1, o <= 7)\n    assert Range(8, 0, -2).contains(o) == False\n    assert Range(9, 1, -2).contains(o) == And(o >= 3, o <= 9)\n"], "sample_492": ["def test_serialize_custom_field(self):\n    class CustomField(models.CharField):\n            self.custom_arg = custom_arg\n            super().__init__(*args, **kwargs)\n\n            name, path, args, kwargs = super().deconstruct()\n            kwargs['custom_arg'] = self.custom_arg\n            return name, path, args, kwargs\n\n    field = CustomField(max_length=255, custom_arg='custom_value')\n    string, imports = MigrationWriter.serialize(field)\n    self.assertEqual(\n        string,\n        \"migrations.test_writer.CustomField(max_length=255, custom_arg='custom_value')\",\n    )\n    self.assertIn(\"import migrations.test_writer\", imports)\n"], "sample_940": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n    @singledispatch\n        pass\n\n    @func.register(int)\n        pass\n\n    assert inspect.is_singledispatch_function(func) is True\n    assert inspect.is_singledispatch_function(func.register) is False\n\n        pass\n\n    assert inspect.is_singledispatch_function(not_singledispatch) is False\n"], "sample_1176": ["def test_floordiv_with_integers():\n    assert Integer(10) // Integer(3) == 3\n    assert Integer(10) // Integer(-3) == -4\n    assert Integer(-10) // Integer(3) == -4\n    assert Integer(-10) // Integer(-3) == 3\n    assert Integer(0) // Integer(3) == 0\n    assert Integer(3) // Integer(1) == 3\n    assert Integer(3) // Integer(-1) == -3\n    assert Integer(-3) // Integer(1) == -3\n    assert Integer(-3) // Integer(-1) == 3\n"], "sample_254": ["def test_inline_form_custom_labels(self):\n    \"\"\"\n    Custom labels are displayed correctly in the inline form.\n    \"\"\"\n    self.admin_login(username='super', password='secret')\n    self.selenium.get(self.live_server_url + reverse('admin:admin_inlines_profilecollection_add'))\n\n    # Check the labels of the first inline\n    self.assertEqual(self.selenium.find_element_by_css_selector('label[for=id_profile_set-0-first_name]').text, 'Custom First Name')\n    self.assertEqual(self.selenium.find_element_by_css_selector('label[for=id_profile_set-0-last_name]').text, 'Custom Last Name')\n\n    # Add an inline and check its labels\n    self.selenium.find_element_by_link_text('Add another Profile').click()\n    self.assertEqual(self.selenium.find_element_by_css_selector('label[for=id_profile_set-1-first_name]').text, 'Custom First Name')\n    self.assertEqual(self.selenium.find_element_by_css_selector('label[for=id_profile_set-1-last_name]').text, 'Custom Last Name')\n"], "sample_665": ["def test_collect_with_chdir_during_import_and_testpaths(testdir, monkeypatch):\n    subdir = testdir.tmpdir.mkdir(\"sub\")\n    testdir.tmpdir.join(\"conftest.py\").write(\n        textwrap.dedent(\n            \"\"\"\n            import os\n            os.chdir(%r)\n            \"\"\"\n            % (str(subdir),)\n        )\n    )\n    testdir.makepyfile(\n        \"\"\"\n            import os\n            assert os.getcwd() == %r\n        \"\"\"\n        % (str(subdir),)\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        testpaths = .\n    \"\"\"\n    )\n    with testdir.tmpdir.as_cwd():\n        result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed in*\"])\n    assert result.ret == 0\n"], "sample_57": ["    def test_unicode_username_normalization(self):\n        ohm_username = 'test\u2126'  # U+2126 OHM SIGN\n        data = {\n            'username': ohm_username,\n            'password1': 'pwd2',\n            'password2': 'pwd2',\n        }\n        form = UserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        user = form.save()\n        self.assertNotEqual(user.username, ohm_username)\n        self.assertEqual(user.username, 'test\u03a9')  # U+03A9 GREEK CAPITAL LETTER OMEGA\n"], "sample_569": ["def test_regplot_line_kws(self):\n\n    f, ax = plt.subplots()\n    color = 'g'\n    ax = lm.regplot(x=\"x\", y=\"y\", data=self.df,\n                    line_kws={'color': color})\n    assert ax.lines[0].get_color() == color\n\n    f, ax = plt.subplots()\n    linewidth = 2.5\n    ax = lm.regplot(x=\"x\", y=\"y\", data=self.df,\n                    line_kws={'linewidth': linewidth})\n    assert ax.lines[0].get_linewidth() == linewidth\n"], "sample_482": ["def test_empty(self):\n    output = self.engine.render_to_string(\"escapeseq_empty\", {\"a\": []})\n    self.assertEqual(output, \"\")\n"], "sample_852": ["def test_make_classification_n_features_gt_n_informative():\n    \"\"\"Test the construction of redundant and repeated features in make_classification\"\"\"\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=5,\n                               n_redundant=5, n_repeated=5, n_classes=3,\n                               n_clusters_per_class=1, hypercube=False,\n                               shift=None, scale=None, random_state=0)\n\n    assert X.shape == (100, 20), \"X shape mismatch\"\n    assert y.shape == (100,), \"y shape mismatch\"\n    assert np.unique(y).shape == (3,), \"Unexpected number of classes\"\n    assert X[:, 5:10].shape == (100, 5), \"Redundant features shape mismatch\"\n    assert X[:, 10:15].shape == (100, 5), \"Repeated features shape mismatch\"\n    assert np.unique(X[:, 10:15], axis=0).shape == (5, 5), \"Repeated features are not unique\"\n"], "sample_436": ["def test_custom_project_template_with_non_ascii_files(self):\n    \"\"\"\n    The startproject management command is able to render files with\n    non-ASCII content.\n    \"\"\"\n    template_path = os.path.join(custom_templates_dir, \"project_template\")\n    args = [\n        \"startproject\",\n        \"--template\",\n        template_path,\n        \"customtestproject\",\n    ]\n    testproject_dir = os.path.join(self.test_dir, \"customtestproject\")\n\n    out, err = self.run_django_admin(args)\n    self.assertNoOutput(err)\n    self.assertTrue(os.path.isdir(testproject_dir))\n    path = os.path.join(testproject_dir, \"ticket-18091-non-ascii-file.txt\")\n    with open(path, encoding=\"utf-8\") as f:\n        self.assertEqual(\n            f.read().splitlines(False),\n            [\"Some non-ASCII text for testing ticket #18091:\", \"\u00fc\u00e4\u00f6 \u20ac\"],\n        )\n"], "sample_15": ["def test_radian_invalid_units(self, function):\n    with pytest.raises(TypeError):\n        function(3.0 * u.m, 2.0 * u.s, 1.0 * u.kg)\n"], "sample_534": ["def test_contour_linestyles(style):\n    delta = 0.025\n    x = np.arange(-3.0, 3.0, delta)\n    y = np.arange(-2.0, 2.0, delta)\n    X, Y = np.meshgrid(x, y)\n    Z1 = np.exp(-X**2 - Y**2)\n    Z2 = np.exp(-(X - 1)**2 - (Y - 1)**2)\n    Z = (Z1 - Z2) * 2\n\n    fig, ax = plt.subplots()\n    CS = ax.contour(X, Y, Z, 6, colors='k', linestyles=style)\n    ax.clabel(CS, fontsize=9, inline=True)\n    ax.set_title(f'Single color - positive contours {style}')\n    assert CS.linestyles == style\n"], "sample_271": ["def test_watch_dir_with_unresolvable_path_in_glob(self, mocked_modules, notify_mock):\n    path = Path('unresolvable_directory')\n    with mock.patch.object(Path, 'absolute', side_effect=FileNotFoundError):\n        self.reloader.watch_dir(path, '**/*.mo')\n    self.assertEqual(list(self.reloader.directory_globs), [])\n"], "sample_427": ["def test_formset_with_custom_deletion_widget(self):\n    \"\"\"FormSets with custom deletion widget.\"\"\"\n    class CustomDeletionWidget(CheckboxInput):\n            default_attrs = {'class': 'custom-deletion-widget'}\n            if attrs is not None:\n                default_attrs.update(attrs)\n            super().__init__(attrs=default_attrs, check_test=check_test)\n\n    class CustomDeletionFormSet(BaseFormSet):\n        deletion_widget = CustomDeletionWidget\n\n    ChoiceFormSet = formset_factory(Choice, formset=CustomDeletionFormSet, can_delete=True)\n    initial = [\n        {\"choice\": \"Calexico\", \"votes\": 100},\n        {\"choice\": \"Fergie\", \"votes\": 900},\n    ]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix=\"choices\")\n    self.assertHTMLEqual(\n        \"\\n\".join(form.as_ul() for form in formset.forms),\n        '<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"choices-0-votes\" value=\"100\"></li>'\n        '<li>Delete: <input class=\"custom-deletion-widget\" type=\"checkbox\" name=\"choices-0-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"choices-1-choice\" value=\"Fergie\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"choices-1-votes\" value=\"900\"></li>'\n        '<li>Delete: <input class=\"custom-deletion-widget\" type=\"checkbox\" name=\"choices-1-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"choices-2-choice\"></li>'\n        '<li>Votes: <input"], "sample_672": ["def test_nested_objects():\n    class Nested:\n            self.value = value\n\n            return f\"Nested({self.value})\"\n\n    obj = Nested(Nested(Nested(1)))\n    s = saferepr(obj, maxsize=25)\n    assert len(s) == 25\n    assert s == \"Nested(Nested(Nested(1)))\"\n"], "sample_1066": ["def test_print_MatrixExpr():\n    from sympy.matrices import MatrixSymbol, MatrixExpr\n    X = MatrixSymbol('X', 2, 2)\n    Y = MatrixSymbol('Y', 2, 2)\n    expr = MatrixExpr([[X, Y], [Y, X]])\n    assert mathml(expr, printer='presentation') == \\\n        '<mfenced close=\"]\" open=\"[\"><mtable><mtr><mtd><mi>X</mi></mtd><mtd><mi>Y</mi></mtd></mtr><mtr><mtd><mi>Y</mi></mtd><mtd><mi>X</mi></mtd></mtr></mtable></mfenced>'\n"], "sample_1042": ["def test_Indexed_derivative_with_IndexedBase():\n    A = IndexedBase('A')\n    i, j = symbols('i j', integer=True)\n    expr = A[i] * A[j]\n    assert expr.diff(A[i]) == A[j]\n    assert expr.diff(A[j]) == A[i]\n    assert expr.diff(A[k]) == 0\n"], "sample_1073": ["def test_sqrtdenest_issue_12420_2():\n    I = S.ImaginaryUnit\n    e = sqrt(2 + I) + sqrt(3 + 3*I) - sqrt(5 + 5*I)\n    assert sqrtdenest(e) == I\n"], "sample_1027": ["def test_issue_14364_lcm_list():\n    assert lcm_list([S(7)/sqrt(15)/2, S(5)/sqrt(15)/6, S(5)/sqrt(15)/8]) == S(35)/(2*sqrt(15))\n"], "sample_394": ["def test_url_with_trailing_slash_if_not_authenticated(self):\n    url = reverse(\"admin:article_extra_json\") + \"/\"\n    response = self.client.get(url)\n    self.assertRedirects(response, \"%s?next=%s\" % (reverse(\"admin:login\"), url))\n"], "sample_84": ["    def test_fields_limit(self):\n        qs = 'a=1&b=2&c=3&d=4&e=5'\n        self.assertEqual(limited_parse_qsl(qs, fields_limit=3), [('a', '1'), ('b', '2'), ('c', '3')])\n        with self.assertRaises(TooManyFieldsSent):\n            limited_parse_qsl(qs, fields_limit=2)\n"], "sample_192": ["def test_formset_with_custom_prefix(self):\n    \"\"\"Formsets can have a custom prefix.\"\"\"\n    data = {\n        'custom-TOTAL_FORMS': '1',\n        'custom-INITIAL_FORMS': '0',\n        'custom-MIN_NUM_FORMS': '0',\n        'custom-MAX_NUM_FORMS': '0',\n        'custom-0-choice': 'Calexico',\n        'custom-0-votes': '100',\n    }\n    formset = self.make_choiceformset(formset_data=data, prefix='custom')\n    self.assertTrue(formset.is_valid())\n    self.assertEqual(formset.management_form.prefix, 'custom')\n"], "sample_643": ["def test_colorize_ansi_deprecation(recwarn: WarningsRecorder) -> None:\n    \"\"\"Test the deprecation warning for colorize_ansi.\"\"\"\n    from pylint.reporters.text import colorize_ansi\n\n    colorize_ansi(\"test\", \"red\", \"bold\")\n    warning = recwarn.pop()\n    assert \"In pylint 3.0, the colorize_ansi function of Text reporters will only accept a MessageStyle parameter\" in str(warning)\n"], "sample_1040": ["def test_print_negative_infinity():\n    assert mathml(-oo, printer='presentation') == '<mrow><mo>-</mo><mi>&#x221E;</mi></mrow>'\n    assert mathml(-oo, printer='content') == '<apply><minus/><infinity/></apply>'\n"], "sample_581": ["def test_blueprint_url_value_preprocessor_with_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_url_value_preprocessor\n        values[\"lang_code\"] = values[\"lang_code\"][::-1]\n\n    @bp.route(\"/<lang_code>/\")\n        return lang_code\n\n    app.register_blueprint(bp)\n\n    assert client.get(\"/en/\").data == b\"ne\"\n"], "sample_993": ["def test_FreeGroupElm_cyclic_conjugates():\n    w = x*y*x*y*x\n    assert w.cyclic_conjugates() == {x*y*x**2*y, x**2*y*x*y, y*x*y*x**2, y*x**2*y*x, x*y*x*y*x}\n\n    s = x*y*x**2*y*x\n    assert s.cyclic_conjugates() == {x**2*y*x**2*y, y*x**2*y*x**2, x*y*x**2*y*x}\n"], "sample_187": ["def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('CamelCaseExample'), 'camel case example')\n    self.assertEqual(text.camel_case_to_spaces('AnotherExample'), 'another example')\n    self.assertEqual(text.camel_case_to_spaces('NoCamelCase'), 'no camel case')\n    self.assertEqual(text.camel_case_to_spaces(''), '')\n    self.assertEqual(text.camel_case_to_spaces('SingleWord'), 'single word')\n    self.assertEqual(text.camel_case_to_spaces('ALLCAPS'), 'allcaps')\n    self.assertEqual(text.camel_case_to_spaces('lazystrExample'), 'lazystr example')\n"], "sample_103": ["def test_aggregate_filter_clause(self):\n    if connection.features.supports_aggregate_filter_clause:\n        books = Book.objects.aggregate(\n            avg_price_recent=Avg('price', filter=Q(pubdate__year__gt=2007))\n        )\n        self.assertEqual(books['avg_price_recent'], Decimal('47.39'))\n"], "sample_983": ["def test_scalar_multiply():\n    A = SparseMatrix([[1, 2], [3, 4]])\n    B = A.scalar_multiply(2)\n    assert B == SparseMatrix([[2, 4], [6, 8]])\n    B = A.scalar_multiply(0)\n    assert B == SparseMatrix([[0, 0], [0, 0]])\n    B = A.scalar_multiply(Symbol('x'))\n    assert B == SparseMatrix([[Symbol('x'), 2*Symbol('x')], [3*Symbol('x'), 4*Symbol('x')]])\n"], "sample_60": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n"], "sample_1204": ["def test_symmetricpermutationgroup_contains():\n    G = SymmetricPermutationGroup(4)\n    assert Permutation(1, 2, 3) in G\n    assert Permutation(1, 2, 3, 4, 5) not in G\n"], "sample_432": ["def test_dynamic_list_filter_with_callable(self):\n    \"\"\"\n    Regression tests for ticket #17646: dynamic list_filter support with callable.\n    \"\"\"\n    parent = Parent.objects.create(name=\"parent\")\n    for i in range(10):\n        Child.objects.create(name=\"child %s\" % i, parent=parent)\n\n    user_noparents = self._create_superuser(\"noparents\")\n    user_parents = self._create_superuser(\"parents\")\n\n    # Test with user 'noparents'\n    m = DynamicListFilterChildAdmin(Child, custom_site)\n    m.list_filter = [lambda request: \"parent\"]\n    request = self._mocked_authenticated_request(\"/child/\", user_noparents)\n    response = m.changelist_view(request)\n    self.assertEqual(response.context_data[\"cl\"].list_filter, [\"name\", \"age\"])\n\n    # Test with user 'parents'\n    m = DynamicListFilterChildAdmin(Child, custom_site)\n    m.list_filter = [lambda request: \"parent\" if request.user.has_perm(\"admin_changelist.change_parent\") else None]\n    request = self._mocked_authenticated_request(\"/child/\", user_parents)\n    response = m.changelist_view(request)\n    self.assertEqual(\n        response.context_data[\"cl\"].list_filter, (\"parent\", \"name\", \"age\")\n    )\n"], "sample_762": ["def test_clone_with_unsafe_option():\n    # Test that clone works with the safe=False option\n    no_estimator = NoEstimator()\n    cloned_no_estimator = clone(no_estimator, safe=False)\n    assert no_estimator is not cloned_no_estimator\n"], "sample_536": ["def test_polygon_selector_box_handle_props(ax):\n    # Create a diamond shape\n    verts = [(20, 0), (0, 20), (20, 40), (40, 20)]\n    event_sequence = [\n        *polygon_place_vertex(*verts[0]),\n        *polygon_place_vertex(*verts[1]),\n        *polygon_place_vertex(*verts[2]),\n        *polygon_place_vertex(*verts[3]),\n        *polygon_place_vertex(*verts[0]),\n    ]\n\n    # Create selector with custom handle props\n    tool = widgets.PolygonSelector(ax, onselect=noop, draw_bounding_box=True,\n                                   box_handle_props={'color': 'r', 'alpha': 0.5})\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n\n    # Check that handle props were set correctly\n    for handle in tool._box._corner_handles.artists:\n        assert handle.get_color() == 'r'\n        assert handle.get_alpha() == 0.5\n"], "sample_619": ["def test_decode_cf_datetime_with_cftime_overflow_error():\n    units = \"microseconds since 1700-01-01\"\n    calendar = \"360_day\"\n    num_dates = np.uint64(1_000_000 * 86_400 * 360 * 500_000)\n    with pytest.raises(OverflowError):\n        decode_cf_datetime(num_dates, units, calendar, use_cftime=True)\n"], "sample_819": ["def test_transform_hard_voting():\n    \"\"\"Check transform method of VotingClassifier with hard voting on toy dataset.\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    X = np.array([[-1.1, -1.5], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n    y = np.array([1, 1, 2, 2])\n\n    eclf = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='hard').fit(X, y)\n\n    assert_array_equal(eclf.transform(X).shape, (4, 3))\n    assert_array_equal(eclf.transform(X),\n                       np.array([[1, 1, 1],\n                                 [1, 1, 1],\n                                 [2, 1, 2],\n                                 [2, 2, 2]]))\n"], "sample_446": ["def test_large_numbers(self):\n    self.assertEqual(floatformat(12345678901234567890.123456789, 10), \"12345678901234567890.1234567890\")\n    self.assertEqual(floatformat(12345678901234567890.123456789, -10), \"12345678901234567890\")\n    self.assertEqual(floatformat(12345678901234567890.123456789, \"10\"), \"12345678901234567890.1234567890\")\n    self.assertEqual(floatformat(12345678901234567890.123456789, \"-10\"), \"12345678901234567890\")\n    self.assertEqual(floatformat(Decimal(\"12345678901234567890.123456789\"), 10), \"12345678901234567890.1234567890\")\n    self.assertEqual(floatformat(Decimal(\"12345678901234567890.123456789\"), -10), \"12345678901234567890\")\n"], "sample_350": ["def test_union_with_values_list_and_order_by_annotation(self):\n    qs1 = Number.objects.annotate(\n        annotation=Value(1),\n    ).filter(num__gte=6)\n    qs2 = Number.objects.annotate(\n        annotation=Value(2),\n    ).filter(num__lte=5)\n    self.assertSequenceEqual(\n        qs1.union(qs2).order_by('annotation', 'num').values_list('num', flat=True),\n        [6, 7, 8, 9, 0, 1, 2, 3, 4, 5],\n    )\n"], "sample_845": ["def test_vectorizer_max_df_min_df():\n    test_data = ['abc', 'dea', 'eat']\n    vect = CountVectorizer(analyzer='char', max_df=0.5, min_df=0.5)\n    vect.fit(test_data)\n    assert 'a' not in vect.vocabulary_.keys()  # {ae} ignored\n    assert len(vect.vocabulary_.keys()) == 2    # {bd} remain\n    assert 'a' in vect.stop_words_\n    assert 'c' in vect.stop_words_\n    assert len(vect.stop_words_) == 2\n"], "sample_484": ["def test_null_name(self):\n    Author.objects.create(alias=\"null\")\n    authors = Author.objects.annotate(name_part=Right(\"name\", 5))\n    self.assertQuerySetEqual(\n        authors.order_by(\"name\"),\n        [\n            \"\" if connection.features.interprets_empty_strings_as_nulls else None,\n            \"null\",\n        ],\n        lambda a: a.name_part,\n    )\n"], "sample_81": ["    def test_resolver_cache_dynamic_urlconf(self):\n        # resolver for a dynamic URLconf (passing an argument) and for the\n        # same dynamic URLconf is the same cached object.\n        self.assertIs(get_resolver('urlpatterns.path_dynamic_urls'), get_resolver('urlpatterns.path_dynamic_urls'))\n        self.assertIsNot(get_resolver('urlpatterns.path_dynamic_urls'), get_resolver('urlpatterns.path_urls'))\n"], "sample_418": ["def test_length_is12(self):\n    output = self.engine.render_to_string(\"length_is12\", {\"mylist\": [1, 2, 3]})\n    self.assertEqual(output, \"Length is 3\")\n"], "sample_748": ["compilation error"], "sample_753": ["def test_logreg_intercept_scaling_non_zero():\n    # Test that intercept_scaling is used when fit_intercept is True\n\n    clf = LogisticRegression(fit_intercept=True, intercept_scaling=2.0)\n    clf.fit(X, Y1)\n    assert_equal(clf.intercept_, 2.0 * clf.coef_[-1])\n"], "sample_1207": ["def test_lambda_notation():\n    x = Symbol('x')\n    f = parse_expr('lambda x: x**2', transformations=(lambda_notation,))\n    assert f(x) == x**2\n    g = parse_expr('lambda x, y: x + y', transformations=(lambda_notation,))\n    assert g(x, 2) == x + 2\n    raises(TokenError, lambda: parse_expr('lambda *x: x', transformations=(lambda_notation,)))\n    raises(TokenError, lambda: parse_expr('lambda: x', transformations=(lambda_notation,)))\n"], "sample_761": ["def test_iterative_imputer_n_nearest_features():\n    rng = np.random.RandomState(0)\n    n = 100\n    d = 10\n    X = sparse_random_matrix(n, d, density=0.10, random_state=rng).toarray()\n\n    imputer = IterativeImputer(missing_values=0,\n                               max_iter=1,\n                               n_nearest_features=5,\n                               random_state=rng)\n    imputer.fit_transform(X)\n\n    # check that n_nearest_features is used correctly\n    for triplet in imputer.imputation_sequence_:\n        assert len(triplet.neighbor_feat_idx) == 5\n"], "sample_675": ["def test_log_file_rotation(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        \"\"\".format(\n            log_file\n        )\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        import time\n\n            logger = logging.getLogger('catchlog')\n            for i in range(10):\n                logger.info(f\"This is log message {i}\")\n                time.sleep(0.1)\n        \"\"\"\n    )\n\n    result = testdir.runpytest(\"-s\")\n\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        for i in range(10):\n            assert f\"This is log message {i}\" in contents\n\n    # Test log file rotation\n    log_file_rotated = log_file + \".1\"\n    assert os.path.isfile(log_file_rotated)\n    with open(log_file_rotated) as rfh:\n        contents = rfh.read()\n        for i in range(10):\n            assert f\"This is log message {i}\" not in contents\n"], "sample_701": ["def test_warning_captured_hook_is_deprecated(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n            ...\n\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: The pytest_warning_captured is deprecated*\",\n            \"*Please use pytest_warning_recorded instead.*\",\n        ]\n    )\n"], "sample_1061": ["def test_Float_floordiv():\n    assert Float(2.5) // Float(1.2) == 2.0\n    assert Float(2.5) // Float(1.5) == 1.0\n    assert Float(2.5) // Float(2.5) == 1.0\n    assert Float(2.5) // Float(3.0) == 0.0\n    assert Float(2.5) // Float(-1.2) == -3.0\n    assert Float(2.5) // Float(-1.5) == -2.0\n    assert Float(2.5) // Float(-2.5) == -1.0\n    assert Float(2.5) // Float(-3.0) == 0.0\n"], "sample_1133": ["def test_lens_makers_formula_convex_plano_lens():\n    n1, n2 = symbols('n1, n2')\n    m1 = Medium('m1', permittivity=e0, n=1)\n    m2 = Medium('m2', permittivity=e0, n=1.33)\n    assert ae(lens_makers_formula(m1, m2, oo, -10), 10.0, 2)\n    assert lens_makers_formula(n1, n2, oo, -10) == -10.0*n2/(n1 - n2)\n"], "sample_252": ["def test_key_transform_exact(self):\n    self.assertIs(NullableJSONModel.objects.filter(value__foo=KeyTransform('foo', 'value')).exists(), True)\n    self.assertIs(NullableJSONModel.objects.filter(value__foo=KeyTransform('bar', 'value')).exists(), False)\n"], "sample_357": ["def test_add_model_with_field_removed_from_base_model_with_m2m(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name and a ManyToManyField.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n            ('authors', models.ManyToManyField('app.Author')),\n        ], bases=('app.readable',)),\n        ModelState('app', 'author', [\n            ('id', models.AutoField(primary_key=True)),\n            ('name', models.CharField(max_length=200)),\n        ]),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n    self.assertOperationAttributes(changes, 'app', 0, 2, name='author')\n"], "sample_266": ["def test_run_before_invalid(self):\n    \"\"\"\n    Makes sure the loader raises an error for invalid Migration.run_before.\n    \"\"\"\n    with self.assertRaises(NodeNotFoundError):\n        MigrationLoader(connection)\n"], "sample_687": ["def test_log_report_captures_according_to_config_option_upon_success(testdir):\n    \"\"\"Test that upon success:\n    (1) `caplog` succeeded to capture the DEBUG message and assert on it => No `Exception` is raised.\n    (2) The `DEBUG`, `INFO`, and `WARNING` messages DO appear in the `Captured log call` report.\n    (3) The stdout message DOES appear in the test reports.\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n\n            logging.debug('DEBUG log ' + 'message')\n            logging.info('INFO log ' + 'message')\n            logging.warning('WARNING log ' + 'message')\n            print('Print ' + 'message')\n\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_level == logging.INFO\n\n            with caplog.at_level(logging.DEBUG):\n                function_that_logs()\n\n            if 'DEBUG log ' + 'message' not in caplog.text:\n                raise Exception('caplog failed to ' + 'capture DEBUG')\n    \"\"\"\n    )\n\n    result = testdir.runpytest(\"--log-level=INFO\")\n    result.stdout.no_fnmatch_line(\"*Exception: caplog failed to capture DEBUG*\")\n    result.stdout.fnmatch_lines(\n        [\"*Print message*\", \"*DEBUG log message*\", \"*INFO log message*\", \"*WARNING log message*\"]\n    )\n    assert result.ret == 0\n"], "sample_274": ["def test_modelchoicefield_to_field_name(self):\n    # Create choices for the model choice field tests below.\n    ChoiceModel.objects.create(pk=1, name='a')\n    ChoiceModel.objects.create(pk=2, name='b')\n    ChoiceModel.objects.create(pk=3, name='c')\n\n    # ModelChoiceField with to_field_name\n    e = {\n        'required': 'REQUIRED',\n        'invalid_choice': 'INVALID CHOICE',\n    }\n    f = ModelChoiceField(queryset=ChoiceModel.objects.all(), to_field_name='name', error_messages=e)\n    self.assertFormErrors(['REQUIRED'], f.clean, '')\n    self.assertFormErrors(['INVALID CHOICE'], f.clean, 'd')\n"], "sample_616": ["def test_cross_with_nan(a, b, ae, be, dim: str, axis: int, use_dask: bool) -> None:\n    ae = np.array(ae)\n    be = np.array(be)\n    ae[0] = np.nan\n    be[1] = np.nan\n    expected = np.cross(ae, be, axis=axis)\n\n    if use_dask:\n        if not has_dask:\n            pytest.skip(\"test for dask.\")\n        a = a.chunk()\n        b = b.chunk()\n\n    actual = xr.cross(a, b, dim=dim)\n    xr.testing.assert_duckarray_allclose(expected, actual)\n"], "sample_758": ["def test_check_array_accept_sparse_list_exception():\n    X = [[1, 2], [3, 4]]\n    X_csr = sp.csr_matrix(X)\n    invalid_list = ['csr', None]\n\n    msg = (\"Parameter 'accept_sparse' should be a string, boolean or list of strings. You provided 'accept_sparse={}'.\")\n    assert_raise_message(ValueError, msg.format(invalid_list),\n                         check_array, X_csr, accept_sparse=invalid_list)\n"], "sample_122": ["def test_cache_key_varies_by_accept_encoding(self):\n    \"\"\"\n    get_cache_key keys differ by Accept-Encoding header\n    \"\"\"\n    request1 = self.factory.get(self.path, HTTP_ACCEPT_ENCODING='gzip')\n    learn_cache_key(request1, HttpResponse())\n    request2 = self.factory.get(self.path, HTTP_ACCEPT_ENCODING='identity')\n    learn_cache_key(request2, HttpResponse())\n    self.assertNotEqual(get_cache_key(request1), get_cache_key(request2))\n"], "sample_1012": ["def test_PythonCodePrinter_known_functions():\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(abs(x)) == 'abs(x)'\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(acosh(x)) == 'math.acosh(x)'\n    assert prntr.doprint(asin(x)) == 'math.asin(x)'\n    assert prntr.doprint(asinh(x)) == 'math.asinh(x)'\n    assert prntr.doprint(atan(x)) == 'math.atan(x)'\n    assert prntr.doprint(atan2(x, y)) == 'math.atan2(x, y)'\n    assert prntr.doprint(atanh(x)) == 'math.atanh(x)'\n    assert prntr.doprint(ceil(x)) == 'math.ceil(x)'\n    assert prntr.doprint(cos(x)) == 'math.cos(x)'\n    assert prntr.doprint(cosh(x)) == 'math.cosh(x)'\n    assert prntr.doprint(erf(x)) == 'math.erf(x)'\n    assert prntr.doprint(erfc(x)) == 'math.erfc(x)'\n    assert prntr.doprint(exp(x)) == 'math.exp(x)'\n    assert prntr.doprint(expm1(x)) == 'math.expm1(x)'\n    assert prntr.doprint(factorial(x)) == 'math.factorial(x)'\n    assert prntr.doprint(floor(x)) == 'math.floor(x)'\n    assert prntr.doprint(gamma(x)) == 'math.gamma(x)'\n    assert prntr.doprint(hypot(x, y)) == 'math.h"], "sample_696": ["def test_argument_type_str_choice_is_deprecated(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n            group = parser.getgroup('mygroup')\n            group.addoption(\n                '--myoption',\n                type='str',\n                choices=['choice1', 'choice2'],\n                help='My option with choices'\n            )\n        \"\"\"\n    )\n    result = pytester.runpytest(\"--help\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: `type` argument to addoption() is the string 'str'.*\",\n        ]\n    )\n"], "sample_689": ["def test_warning_captured_hook_is_deprecated(testdir: Testdir) -> None:\n    \"\"\"Test that the pytest_warning_captured hook is deprecated.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import warnings\n\n            pass\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\"*The pytest_warning_captured is deprecated*pytest_warning_recorded*\"]\n    )\n"], "sample_311": ["def test_url_with_trailing_slash_if_not_authenticated(self):\n    url = reverse('admin:article_extra_json') + '/'\n    response = self.client.get(url)\n    self.assertRedirects(response, '%s?next=%s' % (reverse('admin:login'), url))\n"], "sample_730": ["def test_enet_positive_constraint_with_precompute():\n    X = [[-1], [0], [1]]\n    y = [1, 0, -1]       # just a straight line with negative slope\n\n    enet = ElasticNet(alpha=0.1, max_iter=1000, positive=True, precompute=True)\n    enet.fit(X, y)\n    assert_true(min(enet.coef_) >= 0)\n"], "sample_568": ["def test_Poly3DCollection_init_value_error_edgecolors():\n    # smoke test to ensure the input check works for edgecolors\n    # GH#26420\n    with pytest.raises(ValueError,\n                       match='You must provide facecolors, edgecolors, '\n                        'or both for shade to work.'):\n        poly = np.array([[0, 0, 1], [0, 1, 1], [0, 0, 0]], float)\n        c = art3d.Poly3DCollection([poly], edgecolors='k', shade=True)\n"], "sample_398": ["    def setUpTestData(cls):\n        cls.u1 = UUIDUser.objects.create_user(\n            email=\"testclient@example.com\",\n            username=\"testclient\",\n            password=\"password\",\n        )\n"], "sample_439": ["def test_error_list_class_has_multiple_classes_specified(self):\n    e = ErrorList(error_class=\"foobar-error-class another-error-class\")\n    e.append(\"Foo\")\n    e.append(ValidationError(\"Foo%(bar)s\", code=\"foobar\", params={\"bar\": \"bar\"}))\n    self.assertEqual(\n        e.as_ul(),\n        '<ul class=\"errorlist foobar-error-class another-error-class\"><li>Foo</li><li>Foobar</li></ul>',\n    )\n"], "sample_690": ["def test_marked_xfail_with_boolean_without_reason(pytester: Pytester) -> None:\n    item = pytester.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(False)\n            pass\n        \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_xfail_marks(item)\n    assert excinfo.value.msg is not None\n    assert (\n        \"\"\"Error evaluating 'xfail': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n        in excinfo.value.msg\n    )\n"], "sample_96": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            exclude = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin, ValidationTestModel,\n            \"The value of 'exclude' must be a list or tuple.\",\n            'admin.E014'\n        )\n"], "sample_304": ["    def test_email_validator_idn_domain(self):\n        validator = EmailValidator()\n        self.assertIsNone(validator('test@domain.with.idn.tld.\u0909\u0926\u093e\u0939\u0930\u0923.\u092a\u0930\u0940\u0915\u094d\u0937\u093e'))\n"], "sample_1052": ["def test_fcode_complex_matrix():\n    import sympy.utilities.codegen\n    sympy.utilities.codegen.COMPLEX_ALLOWED = True\n    x = Symbol('x', real=True)\n    y = Symbol('y', real=True)\n    A = MatrixSymbol('A', 2, 2)\n    result = codegen(('test', A*Matrix([[x], [y]])), 'f95', 'test', header=False, empty=False)\n    source = (result[0][1])\n    expected = (\n        \"subroutine test(A, x, y, out_%(hash)s)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in) :: x\\n\"\n        \"REAL*8, intent(in) :: y\\n\"\n        \"REAL*8, intent(in), dimension(1:2, 1:2) :: A\\n\"\n        \"REAL*8, intent(out), dimension(1:2, 1:1) :: out_%(hash)s\\n\"\n        \"out_%(hash)s(1, 1) = A(1, 1)*x + A(1, 2)*y\\n\"\n        \"out_%(hash)s(2, 1) = A(2, 1)*x + A(2, 2)*y\\n\"\n        \"end subroutine\\n\"\n    )\n    # look for the magic number\n    a = source.splitlines()[4]\n    b = a.split('_')\n    out = b[1]\n    expected = expected % {'hash': out}\n    assert source == expected\n    sympy.utilities.codegen.COMPLEX_ALLOWED = False\n"], "sample_197": ["def test_leap_year_with_time(self):\n    start_date = datetime.datetime(2016, 12, 25, 12, 0, 0)\n    self.assertEqual(timeuntil(start_date + self.oneweek, start_date), '1\\xa0week')\n    self.assertEqual(timesince(start_date, start_date + self.oneweek), '1\\xa0week')\n"], "sample_365": ["def test_lazy_modulo(self):\n    \"\"\"\n    % works correctly for Promises.\n    \"\"\"\n    lazy_obj = lazy(lambda: 'test', str)\n    self.assertEqual(lazy_obj() % 'ing', 'testing')\n"], "sample_183": ["def test_case_with_empty_when_and_default(self):\n    objects = CaseTestModel.objects.annotate(\n        selected=Case(\n            When(pk__in=[], then=Value('selected')),\n            default=Value('not selected'),\n            output_field=CharField()\n        )\n    )\n    self.assertEqual(len(objects), CaseTestModel.objects.count())\n    self.assertTrue(all(obj.selected == 'not selected' for obj in objects))\n"], "sample_857": ["def test_prune_tree_raises_invalid_ccp_alpha():\n    clf = DecisionTreeClassifier()\n    msg = \"ccp_alpha must be a non-negative float\"\n\n    with pytest.raises(ValueError, match=msg):\n        clf.set_params(ccp_alpha=\"invalid\")\n        clf.fit(X, y)\n\n    with pytest.raises(ValueError, match=msg):\n        clf.set_params(ccp_alpha=None)\n        clf.fit(X, y)\n"], "sample_1201": ["def test_cgs_gauss_unit_conversions():\n    assert convert_to(statvolt, volt, cgs_gauss) == volt*299792458/10**6\n    assert convert_to(volt, statvolt, cgs_gauss) == 10**6*statvolt/299792458\n    assert convert_to(statampere, coulomb/second, cgs_gauss) == statcoulomb/second\n    assert convert_to(coulomb/second, statampere, cgs_gauss) == statcoulomb/second\n"], "sample_614": ["def test_dim_summary_limited(n_dims: int = 100) -> None:\n    expected = \"\"\"\\\n    dim_0: 3, dim_1: 3, dim_2: 3, dim_3: 3, dim_4: 3, dim_5: 3, dim_6: 3,\n    dim_7: 3, dim_8: 3, dim_9: 3, dim_10: 3, dim_11: 3, dim_12: 3, dim_13: 3,\n    dim_14: 3, dim_15: 3, dim_16: 3, dim_17: 3, dim_18: 3, dim_19: 3, dim_20: 3,\n    dim_21: 3, dim_22: 3, dim_23: 3, ..., dim_76: 3, dim_77: 3, dim_78: 3,\n    dim_79: 3, dim_80: 3, dim_81: 3, dim_82: 3, dim_83: 3, dim_84: 3, dim_85: 3,\n    dim_86: 3, dim_87: 3, dim_88: 3, dim_89: 3, dim_90: 3, dim_91: 3, dim_92: 3,\n    dim_93: 3, dim_94: 3, dim_95: 3, dim_96: 3, dim_97: 3, dim_98: 3, dim_99: 3\"\"\"\n    expected = dedent(expected)\n\n    obj = xr.Dataset({f\"dim_{k}\": 3 for k in np.arange(n_dims)})\n    col_width = formatting._calculate_col_width(obj.variables)\n    actual = formatting.dim_summary_limited(obj, col_width=col_width, max_rows=12"], "sample_630": ["def test_get_annotation_complex_types(assign, label):\n    \"\"\"Complex types\"\"\"\n    node = astroid.extract_node(assign)\n    got = get_annotation(node.value).name\n    assert isinstance(node, astroid.AnnAssign)\n    assert got == label, f\"got {got} instead of {label} for value {node}\"\n"], "sample_1113": ["def test_block_matrix_multiplication():\n    A = BlockMatrix([[A1, A2], [A3, A4]])\n    B = BlockMatrix([[B1, B2], [B3, B4]])\n    C = A * B\n    assert C.blocks[0, 0] == A1 * B1 + A2 * B3\n    assert C.blocks[0, 1] == A1 * B2 + A2 * B4\n    assert C.blocks[1, 0] == A3 * B1 + A4 * B3\n    assert C.blocks[1, 1] == A3 * B2 + A4 * B4\n"], "sample_175": ["def test_fast_delete_with_keeping_parents(self):\n    child = RChild.objects.create()\n    parent_id = child.r_ptr_id\n    self.assertTrue(Collector(using='default').can_fast_delete(child, keep_parents=True))\n    child.delete(keep_parents=True)\n    self.assertFalse(RChild.objects.filter(id=child.id).exists())\n    self.assertTrue(R.objects.filter(id=parent_id).exists())\n"], "sample_864": ["def test_mean_shift_with_sparse_matrix():\n    # Test MeanShift algorithm with sparse matrix\n    X_sparse = sparse.csr_matrix(X)\n    ms = MeanShift(bandwidth=1.2)\n    labels = ms.fit(X_sparse).labels_\n    labels_unique = np.unique(labels)\n    n_clusters_ = len(labels_unique)\n    assert n_clusters_ == 3\n"], "sample_82": ["def test_selectdate_id_for_label(self):\n    widget = SelectDateWidget()\n    self.assertEqual(widget.id_for_label('mydate'), 'mydate_month')\n"], "sample_270": ["def test_unique_constraint_include_pointing_to_joined_fields(self):\n    class Model(models.Model):\n        age = models.SmallIntegerField()\n        parent = models.ForeignKey('self', models.CASCADE)\n\n        class Meta:\n            constraints = [\n                models.UniqueConstraint(\n                    name='name',\n                    fields=['age'],\n                    include=['parent__age'],\n                ),\n            ]\n\n    self.assertEqual(Model.check(databases=self.databases), [\n        Error(\n            \"'constraints' refers to the joined field 'parent__age'.\",\n            obj=Model,\n            id='models.E041',\n        )\n    ])\n"], "sample_77": ["def test_urlize_nofollow(self):\n    value = 'Check out <a href=\"http://example.com\">this link</a>.'\n    output = 'Check out <a href=\"http://example.com\" rel=\"nofollow\">this link</a>.'\n    self.assertEqual(urlize(value, nofollow=True), output)\n"], "sample_352": ["    def test_ticket_24605_exclude(self):\n        \"\"\"\n        Test exclude() with a subquery.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(\n            Individual.objects.exclude(Q(alive=False), Q(related_individual__isnull=True)),\n            [i1, i2, i3]\n        )\n"], "sample_840": ["def test_pls_algorithm_error():\n    d = load_linnerud()\n    X = d.data\n    Y = d.target\n    pls = pls_.PLSCanonical(algorithm=\"invalid_algorithm\")\n    assert_raise_message(ValueError, \"Got algorithm invalid_algorithm when only 'svd' and 'nipals' are known\",\n                         pls.fit, X, Y)\n"], "sample_968": ["def test_python_use_unqualified_type_names_with_module(app, status, warning):\n    app.build()\n    content = (app.outdir / 'index.html').read_text()\n    assert ('<span class=\"n\"><a class=\"reference internal\" href=\"#bar.Name\" title=\"bar.Name\">'\n            '<span class=\"pre\">Name</span></a></span>' in content)\n    assert '<span class=\"n\"><span class=\"pre\">bar.Age</span></span>' in content\n    assert ('<p><strong>name</strong> (<a class=\"reference internal\" href=\"#bar.Name\" '\n            'title=\"bar.Name\"><em>Name</em></a>) \u2013 blah blah</p>' in content)\n    assert '<p><strong>age</strong> (<em>bar.Age</em>) \u2013 blah blah</p>' in content\n"], "sample_791": ["def test_one_hot_encoder_drop_first():\n    enc = OneHotEncoder(drop='first')\n    X = [['abc', 2, 55], ['def', 1, 55], ['abc', 3, 55]]\n    trans = enc.fit_transform(X).toarray()\n    exp = [[0, 1, 1], [1, 0, 1], [0, 1, 0]]\n    assert_array_equal(trans, exp)\n    dropped_cats = [cat[feature]\n                    for cat, feature in zip(enc.categories_,\n                                            enc.drop_idx_)]\n    assert_array_equal(dropped_cats, ['abc', 2, 55])\n    assert_array_equal(np.array(X, dtype=object),\n                       enc.inverse_transform(trans))\n"], "sample_597": ["def test_merge_overwrite_vars(self):\n    ds1 = xr.Dataset({\"a\": 0, \"b\": 1})\n    ds2 = xr.Dataset({\"b\": 2, \"c\": 3})\n\n    expected = xr.Dataset({\"a\": 0, \"b\": 2, \"c\": 3})\n    assert expected.identical(ds1.merge(ds2, overwrite_vars=\"b\"))\n\n    expected = xr.Dataset({\"a\": 0, \"b\": 1, \"c\": 3})\n    assert expected.identical(ds1.merge(ds2, overwrite_vars=[\"c\"]))\n"], "sample_1010": ["def test_Quaternion_latex_printing_with_zero_components():\n    q = Quaternion(0, 0, 0, 0)\n    assert latex(q) == \"0\"\n    q = Quaternion(0, y, 0, 0)\n    assert latex(q) == \"y i\"\n    q = Quaternion(0, 0, z, 0)\n    assert latex(q) == \"z j\"\n    q = Quaternion(0, 0, 0, t)\n    assert latex(q) == \"t k\"\n"], "sample_812": ["def test_compact_output():\n    # Test compact output\n    lr = LogisticRegression(C=99, class_weight=.4, fit_intercept=False,\n                            tol=1234, verbose=True)\n    pp = _EstimatorPrettyPrinter(compact=True)\n    expected = \"LogisticRegression(C=99, class_weight=0.4, fit_intercept=False, tol=1234, verbose=True)\"\n    assert pp.pformat(lr) == expected\n"], "sample_770": ["def test_silhouette_sparse_input():\n    # Test silhouette_score and silhouette_samples with sparse input\n    rng = np.random.RandomState(0)\n    X_sparse = sp.csr_matrix(rng.rand(10, 2))\n    y = np.array([0] * 5 + [1] * 5)\n\n    # Test silhouette_score with sparse input\n    score_sparse = silhouette_score(X_sparse, y)\n    score_dense = silhouette_score(X_sparse.toarray(), y)\n    pytest.approx(score_sparse, score_dense)\n\n    # Test silhouette_samples with sparse input\n    samples_sparse = silhouette_samples(X_sparse, y)\n    samples_dense = silhouette_samples(X_sparse.toarray(), y)\n    assert_array_equal(samples_sparse, samples_dense)\n"], "sample_413": ["    def test_template_tags_with_same_library_name_different_modules(self):\n        with self.settings(\n            TEMPLATES=[\n                self.get_settings(\n                    \"same_tags\", \"different_tags_app_1.templatetags.same_tags\"\n                ),\n                self.get_settings(\n                    \"same_tags\", \"different_tags_app_2.templatetags.same_tags\"\n                ),\n            ]\n        ):\n            self.assertEqual(\n                check_for_template_tags_with_the_same_name(None),\n                [self.error_same_tags],\n            )\n"], "sample_1203": ["def test_group_isomorphism_with_free_groups():\n    # FreeGroup -> FpGroup\n    F, a, b = free_group(\"a, b\")\n    G = FpGroup(F, [a*b*a**-1*b**-1])\n    check, T = group_isomorphism(F, G)\n    assert check\n    assert T(a*b*a**-1*b**-1).is_identity\n\n    # FpGroup -> FreeGroup\n    H = FpGroup(E, [c**3, d**3, (c*d)**2])\n    check, T = group_isomorphism(G, H)\n    assert check\n    assert T(a**3*b**2) == c**3*d**2\n"], "sample_407": ["def test_fk_assignment_and_related_object_cache_with_to_field(self):\n    # Tests of ForeignKey assignment and the related-object cache with to_field.\n\n    p = Parent.objects.create(name=\"Parent\")\n    c = ToFieldChild.objects.create(parent=p)\n\n    # Look up the object again so that we get a \"fresh\" object.\n    c = ToFieldChild.objects.get(parent=p)\n    p = c.parent\n\n    # Accessing the related object again returns the exactly same object.\n    self.assertIs(c.parent, p)\n\n    # But if we kill the cache, we get a new object.\n    del c._state.fields_cache[\"parent\"]\n    self.assertIsNot(c.parent, p)\n\n    # Assigning a new object results in that object getting cached immediately.\n    p2 = Parent.objects.create(name=\"Parent 2\")\n    c.parent = p2\n    self.assertIs(c.parent, p2)\n\n    # Assigning None will not fail: ToFieldChild.parent is null=True.\n    c.parent = None\n    self.assertIsNone(c.parent)\n\n    # Creation using keyword argument should cache the related object.\n    p = Parent.objects.get(name=\"Parent\")\n    c = ToFieldChild(parent=p)\n    self.assertIs(c.parent, p)\n\n    # Creation using keyword argument and unsaved related instance (#8070).\n    p = Parent()\n    msg = (\n        \"save() prohibited to prevent data loss due to unsaved related object \"\n        \"'parent'.\"\n    )\n    with self.assertRaisesMessage(ValueError, msg):\n        ToFieldChild.objects.create(parent=p)\n\n    # Creation using attname keyword argument and an id will cause the\n    # related object to be fetched.\n    p = Parent.objects.get(name=\"Parent\")\n    c = ToFieldChild(parent_id=p.name)\n    self.assertIsNot(c.parent, p)\n    self.assertEqual(c"], "sample_117": ["    def test_integer_username(self):\n        data = {\n            'username': 1234567,\n            'password1': 'testclient',\n            'password2': 'testclient',\n        }\n        form = UserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        u = form.save()\n        self.assertEqual(u.username, 1234567)\n"], "sample_546": ["def test_toolmanager_add_tool():\n    with pytest.warns(UserWarning, match=_EXPECTED_WARNING_TOOLMANAGER):\n        plt.rcParams['toolbar'] = 'toolmanager'\n    fig = plt.gcf()\n    initial_len = len(fig.canvas.manager.toolmanager.tools)\n    assert 'custom_tool' not in fig.canvas.manager.toolmanager.tools\n    fig.canvas.manager.toolmanager.add_tool('custom_tool', 'Custom Tool')\n    assert len(fig.canvas.manager.toolmanager.tools) == initial_len + 1\n    assert 'custom_tool' in fig.canvas.manager.toolmanager.tools\n"], "sample_296": ["def test_store_empty_messages(self):\n    \"\"\"\n    If no messages are provided, the cookie is deleted.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n    storage._store([], response)\n    self.assertNotIn(storage.cookie_name, response.cookies)\n"], "sample_512": ["def test_subplot_mosaic_empty_sentinel():\n    fig, ax_dict = plt.subplot_mosaic({'A': [1, 2], 'B': [3, 4]}, empty_sentinel='.')\n    assert 'A' in ax_dict\n    assert 'B' in ax_dict\n    assert '.' not in ax_dict\n"], "sample_1": ["def test_separable_single_input_multiple_outputs():\n    # Test case where there is a single input and multiple outputs\n    model = sh1 & sh2\n    assert_allclose(is_separable(model), np.array([False, False]))\n    assert_allclose(separability_matrix(model), np.ones((2, 1), dtype=np.bool_))\n"], "sample_513": ["def test_legend_edgecolor_inherit():\n    # Test that edgecolor='inherit' uses the axes edgecolor\n    fig, ax = plt.subplots()\n    ax.plot([0, 1], [0, 1], label=\"line\")\n    leg = ax.legend(edgecolor='inherit')\n    assert leg.get_frame().get_edgecolor() == ax.spines['right'].get_edgecolor()\n"], "sample_725": ["def test_check_X_y_complex_data_error():\n    X = np.array([[1 + 2j, 3 + 4j, 5 + 7j], [2 + 3j, 4 + 5j, 6 + 7j]])\n    y = np.array([1, 2])\n    assert_raises_regex(\n        ValueError, \"Complex data not supported\", check_X_y, X, y)\n\n    # list of lists\n    X = [[1 + 2j, 3 + 4j, 5 + 7j], [2 + 3j, 4 + 5j, 6 + 7j]]\n    assert_raises_regex(\n        ValueError, \"Complex data not supported\", check_X_y, X, y)\n\n    # tuple of tuples\n    X = ((1 + 2j, 3 + 4j, 5 + 7j), (2 + 3j, 4 + 5j, 6 + 7j))\n    assert_raises_regex(\n        ValueError, \"Complex data not supported\", check_X_y, X, y)\n\n    # list of np arrays\n    X = [np.array([1 + 2j, 3 + 4j, 5 + 7j]),\n         np.array([2 + 3j, 4 + 5j, 6 + 7j])]\n    assert_raises_regex(\n        ValueError, \"Complex data not supported\", check_X_y, X, y)\n\n    # tuple of np arrays\n    X = (np.array([1 + 2j, 3 + 4j, 5 + 7j]),\n         np.array([2 + 3j, 4 + 5j, 6 + 7j]))\n    assert_raises_regex(\n        ValueError, \"Complex data not supported\", check_X_y, X, y)\n\n    # dataframe\n    X = MockDataFrame(\n        np.array([[1 + 2j, 3 + 4j, 5 + 7j], [2 + 3j, 4 + "], "sample_181": ["def test_filtered_aggregate_with_exists(self):\n    agg = Sum('age', filter=Q(book__isnull=False))\n    qs = Author.objects.annotate(total_age=agg).filter(total_age__isnull=False)\n    self.assertEqual(qs.count(), 2)\n"], "sample_936": ["def test_stringify_type_hints_generic():\n    class MyGeneric(Generic[T]):\n        pass\n\n    assert stringify(MyGeneric) == \"test_util_typing.MyGeneric\"\n    assert stringify(MyGeneric[int]) == \"test_util_typing.MyGeneric[int]\"\n    assert stringify(MyGeneric[str]) == \"test_util_typing.MyGeneric[str]\"\n"], "sample_617": ["def test_cross_with_missing_values(a, b, ae, be, dim: str, axis: int, use_dask: bool) -> None:\n    expected = np.cross(ae, be, axis=axis)\n\n    if use_dask:\n        if not has_dask:\n            pytest.skip(\"test for dask.\")\n        a = a.chunk()\n        b = b.chunk()\n\n    actual = xr.cross(a, b, dim=dim)\n    xr.testing.assert_duckarray_allclose(expected, actual)\n"], "sample_425": ["def test_serialize_complex(self):\n    self.assertSerializedEqual(complex(1, 2))\n    self.assertSerializedResultEqual(\n        complex(1, 2),\n        (\"complex((1+2j))\", set()),\n    )\n"], "sample_655": ["def test_capture_with_live_logging_disabled(testdir, capture_fixture):\n    # Issue 3819\n    # capture should work with live cli logging disabled\n\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        import sys\n\n        logger = logging.getLogger(__name__)\n\n            print(\"hello\")\n            sys.stderr.write(\"world\\\\n\")\n            with {0}.disabled():\n                print(\"disabled\")\n                sys.stderr.write(\"disabled\\\\n\")\n            captured = {0}.readouterr()\n            assert captured.out == \"hello\\\\n\"\n            assert captured.err == \"world\\\\n\"\n\n            logging.info(\"something\")\n            print(\"next\")\n            logging.info(\"something\")\n\n            captured = {0}.readouterr()\n            assert captured.out == \"next\\\\n\"\n        \"\"\".format(\n            capture_fixture\n        )\n    )\n\n    result = testdir.runpytest_subprocess(\"--log-cli-level=INFO\")\n    assert result.ret == 0\n"], "sample_400": ["def test_add_model_with_field_removed_from_base_model_with_m2m(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name and a ManyToManyField.\n    \"\"\"\n    before = [\n        ModelState(\n            \"app\",\n            \"readable\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"title\", models.CharField(max_length=200)),\n            ],\n        ),\n    ]\n    after = [\n        ModelState(\n            \"app\",\n            \"readable\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n            ],\n        ),\n        ModelState(\n            \"app\",\n            \"book\",\n            [\n                (\"title\", models.CharField(max_length=200)),\n                (\"authors\", models.ManyToManyField(\"app.Author\")),\n            ],\n            bases=(\"app.readable\",),\n        ),\n        ModelState(\n            \"app\",\n            \"author\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=200)),\n            ],\n        ),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, \"app\", 1)\n    self.assertOperationTypes(changes, \"app\", 0, [\"RemoveField\", \"CreateModel\", \"CreateModel\"])\n    self.assertOperationAttributes(\n        changes, \"app\", 0, 0, name=\"title\", model_name=\"readable\"\n    )\n    self.assertOperationAttributes(changes, \"app\", 0, 1, name=\"book\")\n    self.assertOperationAttributes(changes, \"app\", 0, 2, name=\"author\")\n"], "sample_816": ["def test_vectorizer_max_df_min_df():\n    test_data = ['abc', 'dea', 'eat']\n    vect = CountVectorizer(analyzer='char', max_df=0.5, min_df=0.5)\n    vect.fit(test_data)\n    assert 'a' not in vect.vocabulary_.keys()  # {ae} ignored\n    assert_equal(len(vect.vocabulary_.keys()), 2)    # {ae} remain\n    assert 'c' in vect.stop_words_\n    assert_equal(len(vect.stop_words_), 1)\n"], "sample_111": ["def test_get_ordering_field_columns_with_f_expression(self):\n    \"\"\"\n    Regression test for #17198: get_ordering_field_columns() should handle\n    F() expressions correctly.\n    \"\"\"\n    class OrderedByFBandAdmin(admin.ModelAdmin):\n        list_display = ['name', 'genres', 'nr_of_members']\n        ordering = (\n            F('nr_of_members').desc(nulls_last=True),\n            Upper(F('name')).asc(),\n            F('genres').asc(),\n        )\n\n    m = OrderedByFBandAdmin(Band, custom_site)\n    request = self.factory.get('/band/')\n    request.user = self.superuser\n    cl = m.get_changelist_instance(request)\n    self.assertEqual(cl.get_ordering_field_columns(), {3: 'desc', 2: 'asc'})\n"], "sample_952": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n    @singledispatch\n        pass\n\n    @fun.register(int)\n        pass\n\n    assert inspect.is_singledispatch_function(fun) is True\n    assert inspect.is_singledispatch_function(fun.register) is False\n\n        pass\n\n    assert inspect.is_singledispatch_function(not_singledispatch) is False\n"], "sample_788": ["def test_inverse_transform_outside_fit_range():\n    X = np.array([0, 1, 2, 3])[:, None]\n    kbd = KBinsDiscretizer(n_bins=4, strategy='uniform', encode='ordinal')\n    kbd.fit(X)\n\n    X2t = np.array([[-1], [4]])\n    X2inv = kbd.inverse_transform(X2t)\n    assert_array_equal(X2inv.max(axis=0), X.max(axis=0))\n    assert_array_equal(X2inv.min(axis=0), X.min(axis=0))\n"], "sample_1081": ["def test_factorrat_visual_io():\n    fr = factorrat\n    # with factorrat\n    for th in [S(12)/1, Rational(25, 14), S(-25)/14/9]:\n        assert fr(th, visual=True) == fr(th, visual=1)\n    for th in [S(12)/1, Rational(25, 14), S(-25)/14/9]:\n        assert fr(th, visual=False) == fr(th)\n    assert [fr(th, visual=None) for th in [S(12)/1, Rational(25, 14), S(-25)/14/9]] == [fr(th) for th in [S(12)/1, Rational(25, 14), S(-25)/14/9]]\n    assert [fr(th, visual=0) for th in [S(12)/1, Rational(25, 14), S(-25)/14/9]] == [fr(th) for th in [S(12)/1, Rational(25, 14), S(-25)/14/9]]\n"], "sample_773": ["def test_logistic_regression_path_coefs_ovr():\n    # Make sure that the returned coefs by logistic_regression_path when\n    # multi_class='ovr' don't override each other (used to be a bug).\n    X, y = make_classification(n_samples=200, n_classes=3, n_informative=2,\n                               n_redundant=0, n_clusters_per_class=1,\n                               random_state=0, n_features=2)\n    Cs = [.00001, 1, 10000]\n    coefs, _, _ = _logistic_regression_path(X, y, penalty='l1', Cs=Cs,\n                                            solver='saga', random_state=0,\n                                            multi_class='ovr')\n\n    with pytest.raises(AssertionError):\n        assert_array_almost_equal(coefs[0], coefs[1], decimal=1)\n    with pytest.raises(AssertionError):\n        assert_array_almost_equal(coefs[0], coefs[2], decimal=1)\n    with pytest.raises(AssertionError):\n        assert_array_almost_equal(coefs[1], coefs[2], decimal=1)\n"], "sample_823": ["def test_pairwise_distances_callable_metric():\n    # Test the pairwise_distance helper function with a callable metric\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((5, 4))\n    Y = rng.random_sample((2, 4))\n\n        return np.sum(np.abs(x - y))\n\n    S = pairwise_distances(X, Y, metric=custom_metric)\n    S2 = np.array([[custom_metric(x, y) for y in Y] for x in X])\n    assert_array_almost_equal(S, S2)\n"], "sample_202": ["def test_empty_cookie(self):\n    \"\"\"\n    If the cookie is empty, the storage should return an empty list of messages.\n    \"\"\"\n    request = self.get_request()\n    storage = self.storage_class(request)\n    request.COOKIES = {CookieStorage.cookie_name: ''}\n    self.assertEqual(list(storage), [])\n"], "sample_815": ["def test_multilabel_jaccard_similarity_score_samplewise():\n    # Dense label indicator matrix format\n    y1 = np.array([[0, 1, 1], [1, 0, 1]])\n    y2 = np.array([[0, 0, 1], [1, 0, 1]])\n\n    # size(y1 \\inter y2) = [1, 1]\n    # size(y1 \\union y2) = [2, 2]\n\n    assert_equal(jaccard_similarity_score(y1, y2, average='samples'), 0.5)\n    assert_equal(jaccard_similarity_score(y1, y1, average='samples'), 1)\n    assert_equal(jaccard_similarity_score(y2, y2, average='samples'), 1)\n    assert_equal(jaccard_similarity_score(y2, np.logical_not(y2), average='samples'), 0)\n    assert_equal(jaccard_similarity_score(y1, np.logical_not(y1), average='samples'), 0)\n    assert_equal(jaccard_similarity_score(y1, np.zeros(y1.shape), average='samples'), 0)\n    assert_equal(jaccard_similarity_score(y2, np.zeros(y1.shape), average='samples'), 0)\n"], "sample_65": ["def test_i18n_language_with_custom_domain(self):\n    \"\"\"\n    Check if the JavaScript i18n view returns a complete language catalog\n    if the domain is custom and a translation available for that domain.\n    \"\"\"\n    with self.settings(LANGUAGE_CODE='en-us'), override('fr'):\n        response = self.client.get('/jsi18n/app6/', {'domain': 'custom'})\n        self.assertContains(response, 'il faut traduire cette cha\u00eene de caract\u00e8res de app6')\n"], "sample_806": ["def test_gradient_boosting_with_init_zero():\n    # Check that GradientBoostingRegressor works when init is 'zero'\n\n    X, y = make_regression(random_state=0)\n    sample_weight = np.random.RandomState(42).rand(100)\n\n    gb = GradientBoostingRegressor(init='zero')\n    gb.fit(X, y, sample_weight=sample_weight)\n"], "sample_547": ["def test_offsetimage():\n    fig, ax = plt.subplots()\n\n    data = np.random.rand(10, 10)\n    im = OffsetImage(data, zoom=2)\n    ab = AnnotationBbox(im, (0.5, 0.5), xycoords='axes fraction')\n    ax.add_artist(ab)\n"], "sample_275": ["def test_19187_values_list(self):\n    msg = 'Cannot call delete() after .values() or .values_list()'\n    with self.assertRaisesMessage(TypeError, msg):\n        Image.objects.values_list().delete()\n"], "sample_1049": ["def test_plane_properties():\n    p1 = Plane(Point3D(1, 2, 3), normal_vector=(1, 1, 1))\n    p2 = Plane(Point3D(1, 2, 3), normal_vector=(2, 2, 2))\n    p3 = Plane(Point3D(1, 2, 3), normal_vector=(-1, 4, 6))\n\n    assert p1.equals(p2)\n    assert not p1.equals(p3)\n\n    assert p1.is_coplanar(p2)\n    assert not p1.is_coplanar(p3)\n\n    assert p1.is_parallel(p2)\n    assert not p1.is_parallel(p3)\n\n    assert p1.is_perpendicular(p3)\n    assert not p1.is_perpendicular(p2)\n"], "sample_165": ["def test_modelchoicefield_to_field_name(self):\n    # Create choices for the model choice field tests below.\n    ChoiceModel.objects.create(pk=1, name='a')\n    ChoiceModel.objects.create(pk=2, name='b')\n    ChoiceModel.objects.create(pk=3, name='c')\n\n    # ModelChoiceField with to_field_name\n    e = {\n        'required': 'REQUIRED',\n        'invalid_choice': 'INVALID CHOICE',\n    }\n    f = ModelChoiceField(queryset=ChoiceModel.objects.all(), to_field_name='name', error_messages=e)\n    self.assertFormErrors(['REQUIRED'], f.clean, '')\n    self.assertFormErrors(['INVALID CHOICE'], f.clean, 'd')\n"], "sample_759": ["def test_one_hot_encoder_unseen_categories():\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc = OneHotEncoder(categories=[['Male', 'Female'], [1, 2, 3, 4]])\n    enc.fit(X)\n    X_new = [['Male', 5], ['Unknown', 2]]\n    with pytest.raises(ValueError, match=\"Found unknown categories\"):\n        enc.transform(X_new)\n"], "sample_859": ["def test_multi_task_elastic_net_cv_dtype():\n    n_samples, n_features = 10, 3\n    rng = np.random.RandomState(42)\n    X = rng.binomial(1, .5, size=(n_samples, n_features))\n    X = X.astype(int)  # make it explicit that X is int\n    y = X[:, [0, 0]].copy()\n    est = MultiTaskElasticNetCV(n_alphas=5, fit_intercept=True).fit(X, y)\n    assert_array_almost_equal(est.coef_, [[1, 0, 0]] * 2, decimal=3)\n"], "sample_522": ["def test_colorbar_set_formatter_locator_horizontal():\n    # check that the locator properties echo what is on the axis:\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc, orientation='horizontal')\n    cb.ax.xaxis.set_major_locator(FixedLocator(np.arange(10)))\n    cb.ax.xaxis.set_minor_locator(FixedLocator(np.arange(0, 10, 0.2)))\n    assert cb.locator is cb.ax.xaxis.get_major_locator()\n    assert cb.minorlocator is cb.ax.xaxis.get_minor_locator()\n    cb.ax.xaxis.set_major_formatter(LogFormatter())\n    cb.ax.xaxis.set_minor_formatter(LogFormatter())\n    assert cb.formatter is cb.ax.xaxis.get_major_formatter()\n    assert cb.minorformatter is cb.ax.xaxis.get_minor_formatter()\n\n    # check that the setter works as expected:\n    loc = FixedLocator(np.arange(7))\n    cb.locator = loc\n    assert cb.ax.xaxis.get_major_locator() is loc\n    loc = FixedLocator(np.arange(0, 7, 0.1))\n    cb.minorlocator = loc\n    assert cb.ax.xaxis.get_minor_locator() is loc\n    fmt = LogFormatter()\n    cb.formatter = fmt\n    assert cb.ax.xaxis.get_major_formatter() is fmt\n    fmt = LogFormatter()\n    cb.minorformatter = fmt\n    assert cb.ax.xaxis.get_minor_formatter() is fmt\n"], "sample_814": ["def test_gradient_boosting_with_init_custom():\n    # Check that the init estimator can be a custom estimator\n\n    class CustomInitEstimator(BaseEstimator):\n            pass\n\n            return np.zeros(X.shape[0])\n\n    X, y = make_regression(random_state=0)\n    init = CustomInitEstimator()\n    gb = GradientBoostingRegressor(init=init)\n    gb.fit(X, y)  # custom estimator without sample_weight works fine\n\n    with pytest.raises(\n            ValueError,\n            match='The initial estimator CustomInitEstimator does not support sample weights'):\n        gb.fit(X, y, sample_weight=np.ones(X.shape[0]))\n"], "sample_903": ["def test_tsne_with_custom_distance_metric():\n    \"\"\"Make sure that TSNE works with a custom distance metric\"\"\"\n    random_state = check_random_state(0)\n    n_components_original = 3\n    n_components_embedding = 2\n    X = random_state.randn(50, n_components_original).astype(np.float32)\n\n        return np.sum(np.abs(x - y))\n\n    X_transformed_tsne = TSNE(\n        metric=custom_distance, n_components=n_components_embedding,\n        random_state=0).fit_transform(X)\n    X_transformed_tsne_precomputed = TSNE(\n        metric='precomputed', n_components=n_components_embedding,\n        random_state=0).fit_transform(pairwise_distances(X, metric=custom_distance))\n    assert_array_equal(X_transformed_tsne, X_transformed_tsne_precomputed)\n"], "sample_1084": ["def test_rationals_intersection():\n    assert S.Rationals.intersect(S.Integers) == S.Integers\n    assert S.Rationals.intersect(S.Naturals) == S.Naturals\n    assert S.Rationals.intersect(S.Naturals0) == S.Naturals0\n    assert S.Rationals.intersect(S.Reals) == S.Rationals\n    assert S.Rationals.intersect(S.Complexes) == S.Rationals\n"], "sample_1132": ["def test_has_variety():\n    assert has_variety((1, 2, 1)) is True\n    assert has_variety((1, 1, 1)) is False\n"], "sample_554": ["def test_annotation_antialiased_with_usetex():\n    annot = Annotation(\"$foo$\", (.5, .5), antialiased=True, usetex=True)\n    assert annot._antialiased is True\n    assert annot.get_antialiased() == annot._antialiased\n\n    annot2 = Annotation(\"$foo$\", (.5, .5), antialiased=False, usetex=True)\n    assert annot2._antialiased is False\n    assert annot2.get_antialiased() == annot2._antialiased\n\n    annot3 = Annotation(\"$foo$\", (.5, .5), antialiased=False, usetex=True)\n    annot3.set_antialiased(True)\n    assert annot3.get_antialiased() is True\n    assert annot3._antialiased is True\n\n    annot4 = Annotation(\"$foo$\", (.5, .5), usetex=True)\n    assert annot4._antialiased == mpl.rcParams['text.antialiased']\n"], "sample_188": ["def test_expression_wrapper_as_sql(self):\n    expr = ExpressionWrapper(F('name'), output_field=CharField())\n    sql, params = expr.as_sql(compiler=None, connection=None)\n    self.assertEqual(sql, 'expressions_company.name')\n    self.assertEqual(params, [])\n"], "sample_478": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            exclude = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'exclude' must be a list or tuple.\",\n            \"admin.E014\",\n        )\n"], "sample_1102": ["def test_issue_18205_with_extension():\n    assert cancel((2 + I)*(3 - I), extension=I) == 7 + I\n    assert cancel((2 + I)*(2 - I), extension=I) == 5\n"], "sample_462": ["def test_choicefield_with_initial_value(self):\n    f = ChoiceField(choices=[(\"1\", \"One\"), (\"2\", \"Two\")], initial=\"1\")\n    self.assertEqual(\"1\", f.clean(\"\"))\n    self.assertEqual(\"1\", f.clean(None))\n    self.assertEqual(\"1\", f.clean(1))\n    self.assertEqual(\"1\", f.clean(\"1\"))\n    msg = \"'Select a valid choice. 3 is not one of the available choices.'\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        f.clean(\"3\")\n"], "sample_633": ["def test_ignore_signatures_with_empty_functions() -> None:\n    output = StringIO()\n    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n        similar.Run([\"--ignore-signatures\", EMPTY_FUNCTION_1, EMPTY_FUNCTION_2])\n    assert ex.value.code == 0\n    assert (\n        output.getvalue().strip()\n        == \"\"\""], "sample_930": ["def test_create_index_with_duplicate_entries(app):\n    text = (\".. index:: docutils\\n\"\n            \".. index:: docutils\\n\"\n            \".. index:: Python\\n\"\n            \".. index:: Python\\n\"\n            \".. index:: Sphinx\\n\"\n            \".. index:: Sphinx\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 3\n    assert index[0] == ('D', [('docutils', [[('', '#index-0'), ('', '#index-1')], [], None])])\n    assert index[1] == ('P', [('Python', [[('', '#index-2'), ('', '#index-3')], [], None])])\n    assert index[2] == ('S', [('Sphinx', [[('', '#index-4'), ('', '#index-5')], [], None])])\n"], "sample_317": ["def test_atom_feed_author_elements(self):\n    \"\"\"\n    Test the author elements in the Atom feed.\n    \"\"\"\n    response = self.client.get('/syndication/atom/')\n    feed = minidom.parseString(response.content).firstChild\n    entries = feed.getElementsByTagName('entry')\n\n    author = entries[0].getElementsByTagName('author')[0]\n    self.assertChildNodes(author, ['name', 'email', 'uri'])\n    self.assertChildNodeContent(author, {\n        'name': 'Sally Smith',\n        'email': 'test@example.com',\n        'uri': 'http://example.com/',\n    })\n"], "sample_216": ["def test_add_model_with_field_removed_from_base_model_and_altered(self):\n    \"\"\"\n    Removing a base field, altering it, and adding a new inherited model that\n    has a field with the same name are all handled correctly.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=300)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n        ], bases=('app.readable',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['AlterField', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n"], "sample_1110": ["def test_log1p():\n    from sympy import log1p\n\n    expr = log1p(x)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr) == 'scipy.special.log1p(x)'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr) == 'numpy.log(x + 1)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr) == 'math.log(x + 1)'\n\n    prntr = MpmathPrinter()\n    assert prntr.doprint(expr) == 'mpmath.log1p(x)'\n"], "sample_1032": ["def test_minmax_rewrite_as_Abs():\n    from sympy.functions.elementary.complexes import Abs\n    from sympy.abc import x, y, z\n\n    assert Min(x, y).rewrite(Abs) == (x + y - Abs(x - y)) / 2\n    assert Max(x, y).rewrite(Abs) == (x + y + Abs(x - y)) / 2\n    assert Min(x, y, z).rewrite(Abs) == (x + y + z - Abs(x - y) - Abs(x - z) - Abs(y - z)) / 2\n"], "sample_363": ["    def test_AdminFileWidget_clear_checkbox(self):\n        from selenium.webdriver.common.by import By\n        self.admin_login(username='super', password='secret', login_url='/')\n        band = Band.objects.create(name='Linkin Park')\n        album = band.album_set.create(\n            name='Hybrid Theory', cover_art=r'albums\\hybrid_theory.jpg'\n        )\n        self.selenium.get(self.live_server_url + reverse('admin:admin_widgets_album_change', args=(album.id,)))\n        clear_checkbox = self.selenium.find_element(By.NAME, 'cover_art-clear')\n        clear_checkbox.click()\n        self.assertFalse(clear_checkbox.is_selected())\n        save_button = self.selenium.find_element(By.NAME, '_save')\n        save_button.click()\n        self.assertEqual(Album.objects.get(id=album.id).cover_art, '')\n"], "sample_979": ["def test_MatrixElement_with_symbolic_indices():\n    i, j = symbols(\"i j\", integer=True)\n    A = MatrixSymbol(\"A\", n, m)\n    Aij = A[i, j]\n    assert isinstance(Aij, MatrixElement)\n    assert Aij.parent == A\n    assert Aij.i == i\n    assert Aij.j == j\n    assert Aij.is_symbol\n    assert Aij.is_commutative\n    assert Aij.diff(A[k, l]) == KroneckerDelta(i, k)*KroneckerDelta(j, l)\n    assert Aij.diff(A[i, j]) == 1\n    assert Aij.diff(A[i, j+1]) == 0\n    assert Aij.diff(A[i+1, j]) == 0\n    assert Aij.diff(x) == 0\n"], "sample_263": ["def test_dumpdata_with_invalid_format(self):\n    with self.assertRaisesMessage(management.CommandError, \"Unknown serialization format: invalid_format\"):\n        self._dumpdata_assert(['fixtures'], '', format='invalid_format')\n"], "sample_19": ["def test_swapaxes_different_val_roundtrip():\n    w = wcs.WCS(naxis=3)\n    w.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\", \"FREQ\"]\n    w.wcs.crpix = [32.5, 16.5, 1.0]\n    w.wcs.crval = [5.63, -72.05, 1.0]\n    w.wcs.pc = [[5.9e-06, 1.3e-05, 0.0], [-1.2e-05, 5.0e-06, 0.0], [0.0, 0.0, 1.0]]\n    w.wcs.cdelt = [1.0, 1.0, 1.0]\n    w.wcs.set()\n    axes_order = [3, 1, 2]\n    axes_order0 = list(i - 1 for i in axes_order)\n    ws = w.sub(axes_order)\n    imcoord = np.array([3, 5, 7])\n    imcoords = imcoord[axes_order0]\n    val_ref = w.wcs_pix2world([imcoord], 0)[0]\n    val_swapped = ws.wcs_pix2world([imcoords], 0)[0]\n\n    # check original axis and swapped give same results\n    assert np.allclose(val_ref[axes_order0], val_swapped, rtol=0, atol=1e-8)\n\n    # check round-tripping:\n    assert np.allclose(w.wcs_world2pix([val_ref], 0)[0], imcoord, rtol=0, atol=1e-8)\n"], "sample_30": ["def test_get_infos_by_name_empty():\n    vot = parse(\n        io.BytesIO(\n            b\"\"\"\n        <VOTABLE xmlns=\"http://www.ivoa.net/xml/VOTable/v1.3\"\n          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" version=\"1.4\">\n          <RESOURCE type=\"results\">\n            <INFO name=\"creator-name\" value=\"Cannon, A.\"/>\n            <INFO name=\"creator-name\" value=\"Fleming, W.\"/>\n          </RESOURCE>\n        </VOTABLE>\"\"\"\n        )\n    )\n    infos = vot.get_infos_by_name(\"unknown-name\")\n    assert list(infos) == []\n"], "sample_458": ["def test_large_numbers(self):\n    self.assertEqual(floatformat(12345678901234567890.123456789, 10), \"12345678901234567890.1234567890\")\n    self.assertEqual(floatformat(12345678901234567890.123456789, \"-10\"), \"12345678901234567890\")\n    self.assertEqual(floatformat(12345678901234567890.123456789, \"10g\"), \"12,345,678,901,234,567,890.1234567890\")\n    self.assertEqual(floatformat(12345678901234567890.123456789, \"-10g\"), \"12,345,678,901,234,567,890\")\n    self.assertEqual(floatformat(12345678901234567890.123456789, \"10u\"), \"12345678901234567890.1234567890\")\n    self.assertEqual(floatformat(12345678901234567890.123456789, \"-10u\"), \"12345678901234567890\")\n"], "sample_925": ["def test_mock_object_attributes():\n    attributes = {'attr1': 'value1', 'attr2': 'value2'}\n    mock = _MockObject(attributes=attributes)\n\n    assert mock.attr1 == 'value1'\n    assert mock.attr2 == 'value2'\n    assert not hasattr(mock, 'attr3')\n"], "sample_506": ["def test_spines_bounds():\n    fig, ax = plt.subplots()\n    ax.spines['left'].set_bounds(-1, 1)\n    ax.spines['bottom'].set_bounds(0, 2)\n    ax.set_xlim([-2, 2])\n    ax.set_ylim([-2, 2])\n"], "sample_255": ["def test_threaded_server(self):\n    \"\"\"ThreadedWSGIServer sets daemon_threads to True.\"\"\"\n    server = ThreadedWSGIServer(('localhost', 0), WSGIRequestHandler)\n    self.assertTrue(server.daemon_threads)\n"], "sample_480": ["def test_key_transform_exact(self):\n    tests = [\n        (\"value__c__exact\", 14, self.objs[3:5]),\n        (\"value__foo__exact\", \"bar\", [self.objs[7]]),\n        (\"value__foo__exact\", KeyTransform(\"foo\", KeyTransform(\"bax\", \"value\")), [self.objs[7]]),\n        (\"value__foo__exact\", F(\"value__bax__foo\"), [self.objs[7]]),\n        (\"value__h__exact\", True, [self.objs[4]]),\n        (\"value__i__exact\", False, [self.objs[4]]),\n        (\"value__j__exact\", None, [self.objs[4]]),\n        (\"value__p__exact\", 4.2, [self.objs[4]]),\n    ]\n    for lookup, value, expected in tests:\n        with self.subTest(lookup=lookup, value=value):\n            self.assertCountEqual(\n                NullableJSONModel.objects.filter(**{lookup: value}),\n                expected,\n            )\n"], "sample_661": ["def test_logging_passing_tests_enabled_logs_test_output(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        junit_log_passing_tests=True\n        junit_logging=system-out\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n        import sys\n\n            sys.stdout.write('This is stdout')\n            sys.stderr.write('This is stderr')\n            logging.warning('hello')\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testcase\")\n    assert len(node.find_by_tag(\"system-err\")) == 1\n    assert len(node.find_by_tag(\"system-out\")) == 1\n"], "sample_837": ["def test_get_blas_info():\n    blas_info = _get_blas_info()\n\n    assert 'macros' in blas_info\n    assert 'lib_dirs' in blas_info\n    assert 'cblas_libs' in blas_info\n"], "sample_469": ["def test_alias_forbidden_chars(self):\n    tests = [\n        'al\"ias',\n        \"a'lias\",\n        \"ali`as\",\n        \"alia s\",\n        \"alias\\t\",\n        \"ali\\nas\",\n        \"alias--\",\n        \"ali/*as\",\n        \"alias*/\",\n        \"alias;\",\n        # [] are used by MSSQL.\n        \"alias[\",\n        \"alias]\",\n    ]\n    msg = (\n        \"Column aliases cannot contain whitespace characters, quotation marks, \"\n        \"semicolons, or SQL comments.\"\n    )\n    for crafted_alias in tests:\n        with self.subTest(crafted_alias):\n            with self.assertRaisesMessage(ValueError, msg):\n                Book.objects.alias(**{crafted_alias: Value(1)})\n"], "sample_267": ["def test_disable_constraint_checking(self):\n    \"\"\"\n    Test that disable_constraint_checking() and enable_constraint_checking()\n    methods work as expected.\n    \"\"\"\n    with connection.cursor() as cursor:\n        cursor.execute('PRAGMA foreign_keys')\n        self.assertEqual(cursor.fetchone()[0], 1)  # foreign keys are enabled by default\n\n    self.assertTrue(connection.disable_constraint_checking())\n\n    with connection.cursor() as cursor:\n        cursor.execute('PRAGMA foreign_keys')\n        self.assertEqual(cursor.fetchone()[0], 0)  # foreign keys are disabled\n\n    self.assertTrue(connection.enable_constraint_checking())\n\n    with connection.cursor() as cursor:\n        cursor.execute('PRAGMA foreign_keys')\n        self.assertEqual(cursor.fetchone()[0], 1)  # foreign keys are enabled again\n"], "sample_364": ["    def test_path_inclusion_with_namespace(self):\n        match = resolve('/namespaced_urls/extra/something/')\n        self.assertEqual(match.url_name, 'namespaced-inner-extra')\n        self.assertEqual(match.kwargs, {'extra': 'something'})\n        self.assertEqual(match.namespace, 'namespaced')\n\n        url = reverse('namespaced:inner-extra', kwargs={'extra': 'something'})\n        self.assertEqual(url, '/namespaced_urls/extra/something/')\n"], "sample_1091": ["def test_issue_18188_complex():\n    from sympy.sets.conditionset import ConditionSet\n    result1 = Eq(x*cos(x) - 3*sin(x) + I, 0)\n    assert result1.as_set() == ConditionSet(x, Eq(x*cos(x) - 3*sin(x) + I, 0), S.Complexes)\n\n    result2 = Eq(x**2 + sqrt(x*2) + sin(x) + I, 0)\n    assert result2.as_set() == ConditionSet(x, Eq(sqrt(2)*sqrt(x) + x**2 + sin(x) + I, 0), S.Complexes)\n"], "sample_102": ["def test_union_with_values_list_and_annotation(self):\n    ReservedName.objects.bulk_create([\n        ReservedName(name='rn1', order=7),\n        ReservedName(name='rn2', order=5),\n        ReservedName(name='rn0', order=6),\n        ReservedName(name='rn9', order=-1),\n    ])\n    qs1 = ReservedName.objects.filter(order__gte=6).annotate(num=Value(1, IntegerField()))\n    qs2 = ReservedName.objects.filter(order__lte=5).annotate(num=Value(2, IntegerField()))\n    union_qs = qs1.union(qs2)\n    for qs, expected_result in (\n        # Order by a single column.\n        (union_qs.order_by('-pk').values_list('num', 'order'), [(1, 7), (1, 6), (2, 5), (2, -1)]),\n        (union_qs.order_by('pk').values_list('num', 'order'), [(2, -1), (2, 5), (1, 6), (1, 7)]),\n        (union_qs.values_list('num', 'order').order_by('-pk'), [(1, 7), (1, 6), (2, 5), (2, -1)]),\n        (union_qs.values_list('num', 'order').order_by('pk'), [(2, -1), (2, 5), (1, 6), (1, 7)]),\n        # Order by multiple columns.\n        (union_qs.order_by('-name', 'pk').values_list('num', 'order'), [(2, 5), (1, 7), (1, 6), (2, -1)]),\n        (union_qs.values_list('num', 'order').order_by('-name', 'pk'), [(2, 5), (1, 7), (1, 6), (2, -1)]),\n    ):\n        with self.subTest(qs=qs):\n           "], "sample_487": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            exclude = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'exclude' must be a list or tuple.\",\n            \"admin.E014\",\n        )\n"], "sample_1183": ["def test_Domain_is_zero():\n    assert ZZ.is_zero(ZZ(0)) is True\n    assert ZZ.is_zero(ZZ(1)) is False\n    assert QQ.is_zero(QQ(0)) is True\n    assert QQ.is_zero(QQ(1, 2)) is False\n    assert RR.is_zero(RR(0)) is True\n    assert RR.is_zero(RR(1e-50)) is False\n    assert CC.is_zero(CC(0)) is True\n    assert CC.is_zero(CC(1e-50)) is False\n    assert CC.is_zero(CC(0, 1e-50)) is False\n"], "sample_316": ["    def test_image_dimensions(self):\n        img_path = os.path.join(os.path.dirname(__file__), \"test.png\")\n        with open(img_path, 'rb') as fh:\n            image = images.ImageFile(fh)\n            image_pil = Image.open(fh)\n            self.assertEqual(image.width, image_pil.width)\n            self.assertEqual(image.height, image_pil.height)\n"], "sample_524": ["def test_colorbar_set_formatter_locator_horizontal():\n    # check that the locator properties echo what is on the axis:\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc, orientation='horizontal')\n    cb.ax.xaxis.set_major_locator(FixedLocator(np.arange(10)))\n    cb.ax.xaxis.set_minor_locator(FixedLocator(np.arange(0, 10, 0.2)))\n    assert cb.locator is cb.ax.xaxis.get_major_locator()\n    assert cb.minorlocator is cb.ax.xaxis.get_minor_locator()\n    cb.ax.xaxis.set_major_formatter(LogFormatter())\n    cb.ax.xaxis.set_minor_formatter(LogFormatter())\n    assert cb.formatter is cb.ax.xaxis.get_major_formatter()\n    assert cb.minorformatter is cb.ax.xaxis.get_minor_formatter()\n\n    # check that the setter works as expected:\n    loc = FixedLocator(np.arange(7))\n    cb.locator = loc\n    assert cb.ax.xaxis.get_major_locator() is loc\n    loc = FixedLocator(np.arange(0, 7, 0.1))\n    cb.minorlocator = loc\n    assert cb.ax.xaxis.get_minor_locator() is loc\n    fmt = LogFormatter()\n    cb.formatter = fmt\n    assert cb.ax.xaxis.get_major_formatter() is fmt\n    fmt = LogFormatter()\n    cb.minorformatter = fmt\n    assert cb.ax.xaxis.get_minor_formatter() is fmt\n"], "sample_1074": ["def test_composition_factors():\n    a = Permutation(1, 2, 3)\n    b = Permutation(1, 2)\n    G = PermutationGroup([a, b])\n    comp_factors = G.composition_factors()\n    assert comp_factors == [G.order(), 2]\n    # The first factor in the composition factors is always the order of the group and\n    # the last factor in the series is 1.\n    S = SymmetricGroup(4)\n    assert S.composition_factors()[0] == S.order()\n    assert len(S.composition_factors()) == 5\n    A = AlternatingGroup(4)\n    assert A.composition_factors()[0] == A.order()\n    assert len(A.composition_factors()) == 4\n\n    # the composition factors for C_8 is [8, 4, 2, 1]\n    G = CyclicGroup(8)\n    factors = G.composition_factors()\n    assert factors == [8, 4, 2, 1]\n"], "sample_854": ["def test_svc_decision_function_shape_ovo():\n    # Test decision_function_shape='ovo'\n    X, y = make_blobs(n_samples=80, centers=3, random_state=0)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\n    clf = svm.SVC(kernel='linear', C=0.1, decision_function_shape='ovo').fit(X_train, y_train)\n    dec = clf.decision_function(X_test)\n    assert dec.shape == (len(X_test), 3)\n    assert_array_equal(clf.predict(X_test), np.argmax(dec, axis=1))\n"], "sample_1101": ["def test_schur_partition_edge_cases():\n    assert schur_partition(1) == [[1]]\n    assert schur_partition(3) == [[1, 2, 3]]\n    assert schur_partition(4) == [[3, 2], [1, 4]]\n    assert schur_partition(5) == [[3, 2], [5], [1, 4]]\n"], "sample_53": ["def test_render_options_with_custom_placeholder(self):\n    \"\"\"Custom placeholder is used if it is provided.\"\"\"\n    form = AlbumForm(initial={'band': None})\n    form.fields['band'].widget.placeholder = 'Select a band'\n    output = form.as_table()\n    self.assertIn('data-placeholder=\"Select a band\"', output)\n"], "sample_650": ["def test_log_cli_format(pytester: Pytester) -> None:\n    # Custom log format\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_handler.formatter._fmt == '%(levelname)s: %(message)s'\n            logging.getLogger('catchlog').info(\"This log message will be shown in custom format\")\n            print('PASSED')\n    \"\"\"\n    )\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n        log_cli_format=%(levelname)s: %(message)s\n        \"\"\"\n    )\n\n    result = pytester.runpytest(\"-s\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines(\n        [\n            \"*INFO: This log message will be shown in custom format\",\n            \"PASSED\",  # 'PASSED' on its own line because the log message prints a new line\n        ]\n    )\n\n    # make sure that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n"], "sample_553": ["def test_save_count_override_warnings_generator(anim):\n    save_count = 5\n    frames = lambda: (i for i in range(3))\n    match_target = (\n        f'You passed in an explicit {save_count=} '\n        \"which is being ignored in favor of \"\n        f\"the length of the generated frames.\"\n    )\n\n    with pytest.warns(UserWarning, match=re.escape(match_target)):\n        anim = animation.FuncAnimation(\n            **{**anim, 'frames': frames, 'save_count': save_count}\n        )\n\n    assert anim._save_count == 3\n    anim._init_draw()\n"], "sample_670": ["def test_complex_expressions(expr: str, expected: bool) -> None:\n    matcher = {\"true\": True, \"false\": False}.__getitem__\n    assert evaluate(expr, matcher) is expected\n"], "sample_1096": ["def test_IndexedBase_strides():\n    i, j = symbols('i j', integer=True)\n    a = IndexedBase('a', strides=(2, 3))\n    assert a[i, j].strides == (2, 3)\n    assert a[i, j].subs(i, 1).subs(j, 2) == a[1, 2]\n    assert a[i, j].subs(i, 1).subs(j, 2).doit() == a[1, 2].doit()\n"], "sample_871": ["def test_silhouette_samples_sparse_input():\n    \"\"\"Check that silhouette_samples works for sparse input correctly.\"\"\"\n    X = csr_matrix([[0.2, 0.1, 0.1, 0.2, 0.1, 1.6, 0.2, 0.1]], dtype=np.float32).T\n    y = [0, 0, 0, 0, 1, 1, 1, 1]\n    pdist_dense = pairwise_distances(X.toarray())\n    output_with_sparse_input = silhouette_samples(X, y)\n    output_with_dense_input = silhouette_samples(pdist_dense, y, metric=\"precomputed\")\n    assert_allclose(output_with_sparse_input, output_with_dense_input)\n"], "sample_493": ["def test_aggregation_default_using_float_from_python(self):\n    result = Book.objects.filter(rating__lt=3.0).aggregate(\n        value=Sum(\"price\", default=0.0),\n    )\n    self.assertEqual(result[\"value\"], 0.0)\n"], "sample_893": ["def test_plot_tree_max_depth(pyplot):\n    # Testing if max_depth parameter works correctly\n    clf = DecisionTreeClassifier(max_depth=2, random_state=0)\n    clf.fit(X, y)\n\n    nodes = plot_tree(clf, max_depth=1)\n    assert len(nodes) == 2\n    assert nodes[0].get_text() == \"feature_1 <= 0.00\\ngini = 0.5\\nsamples = 6\\nvalue = [3, 3]\"\n    assert nodes[1].get_text() == \"(...)\"\n"], "sample_444": ["def test_template_tag_non_ascii(self):\n    relpath = self.hashed_file_path(\"cached/nonascii.css\")\n    self.assertEqual(relpath, \"cached/nonascii.55e7c226dda1.css\")\n    with storage.staticfiles_storage.open(relpath) as relfile:\n        content = relfile.read()\n        self.assertIn(b\"url('../cached/img/nonascii.acae32e4532b.png')\", content)\n    self.assertPostCondition()\n"], "sample_668": ["def test_fixture_positional_arguments(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            pass\n\n            pass\n        \"\"\"\n    )\n\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*Passing arguments to pytest.fixture() as positional arguments is deprecated - pass them*\",\n            \"*as a keyword argument instead.*\",\n        ]\n    )\n"], "sample_718": ["def test_check_estimator_sparse_data():\n    # check that check_estimator_sparse_data works correctly\n    from sklearn.utils.estimator_checks import check_estimator_sparse_data\n    from sklearn.linear_model import LinearRegression\n\n    est = LinearRegression()\n    check_estimator_sparse_data(\"LinearRegression\", est)\n"], "sample_280": ["def test_aggregation_default_passed_another_aggregate_with_filter(self):\n    result = Book.objects.aggregate(\n        value=Sum('price', filter=Q(rating__lt=3.0), default=Avg('pages', filter=Q(rating__gt=4.0)) / 10.0),\n    )\n    self.assertAlmostEqual(result['value'], Decimal('113.20'), places=2)\n"], "sample_949": ["def test_image_in_manpage(app, status, warning):\n    app.build()\n    content = (app.outdir / 'python.1').read_text()\n    assert 'No images are supported in manpage output' in warning.getvalue()\n"], "sample_367": ["    def test_cache_page_decorator_http_request(self):\n        class MyClass:\n            @cache_page(60)\n                return HttpResponse()\n\n        request = HttpRequest()\n        response = MyClass().a_view(request)\n        self.assertIsInstance(response, HttpResponse)\n"], "sample_713": ["def test_ridge_classifier_cv_sample_weight():\n    X = np.array([[-1.0, -1.0], [-1.0, 0], [-.8, -1.0],\n                  [1.0, 1.0], [1.0, 0.0]])\n    y = np.array([1, 1, 1, -1, -1])\n    sample_weight = np.array([1, 1, 2, 1, 1])\n\n    reg = RidgeClassifierCV(alphas=[.01, .1, 1], sample_weight=sample_weight)\n    reg.fit(X, y)\n\n    assert_array_equal(reg.predict([[-.2, 2]]), np.array([-1]))\n"], "sample_281": ["def test_custom_paginator(self):\n    \"\"\"\n    The ModelAdmin's paginator is used for autocomplete results.\n    \"\"\"\n    class CustomPaginatorQuestionAdmin(QuestionAdmin):\n        paginator = Paginator\n\n    Question.objects.bulk_create(Question(question=str(i)) for i in range(PAGINATOR_SIZE + 10))\n    # The first page of results.\n    request = self.factory.get(self.url, {'term': '', **self.opts})\n    request.user = self.superuser\n    with model_admin(Question, CustomPaginatorQuestionAdmin):\n        response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    self.assertEqual(response.status_code, 200)\n    data = json.loads(response.content.decode('utf-8'))\n    self.assertEqual(data, {\n        'results': [{'id': str(q.pk), 'text': q.question} for q in Question.objects.all()[:PAGINATOR_SIZE]],\n        'pagination': {'more': True},\n    })\n    # The second page of results.\n    request = self.factory.get(self.url, {'term': '', 'page': '2', **self.opts})\n    request.user = self.superuser\n    with model_admin(Question, CustomPaginatorQuestionAdmin):\n        response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    self.assertEqual(response.status_code, 200)\n    data = json.loads(response.content.decode('utf-8'))\n    self.assertEqual(data, {\n        'results': [{'id': str(q.pk), 'text': q.question} for q in Question.objects.all()[PAGINATOR_SIZE:]],\n        'pagination': {'more': False},\n    })\n"], "sample_905": ["def test_isabstractmethod():\n    from abc import ABC, abstractmethod\n\n    class AbstractClass(ABC):\n        @abstractmethod\n            pass\n\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(AbstractClass.concrete_method) is False\n    assert inspect.isabstractmethod(AbstractClass().abstract_method) is True\n    assert inspect.isabstractmethod(AbstractClass().concrete_method) is False\n"], "sample_683": ["def test_encodedfile_readline(tmpfile: BinaryIO) -> None:\n    ef = capture.EncodedFile(tmpfile, encoding=\"utf-8\")\n    ef.write(\"line1\\nline2\")\n    ef.flush()\n    tmpfile.seek(0)\n    assert ef.readline() == \"line1\\n\"\n    assert ef.readline() == \"line2\"\n    tmpfile.close()\n    with pytest.raises(ValueError):\n        ef.readline()\n"], "sample_1054": ["def test_ComplexRegion_from_real():\n    unit = Interval(0, 1)\n    assert ComplexRegion.from_real(unit) == ComplexRegion(unit * FiniteSet(0))\n\n    raises(ValueError, lambda: ComplexRegion.from_real(S.Complexes))\n"], "sample_1182": ["def test_log2():\n    from sympy.functions.elementary.exponential import log\n\n    expr = log(x, 2)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr) == 'numpy.log2(x)'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr) == 'numpy.log2(x)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr) == 'math.log(x)/math.log(2)'\n\n    prntr = MpmathPrinter()\n    assert prntr.doprint(expr) == 'mpmath.log2(x)'\n"], "sample_1160": ["def test_issue_18999():\n    assert Range(n, oo).is_finite_set is False\n    assert Range(-oo, n).is_finite_set is False\n    # assert Range(n, -oo).is_finite_set is True\n    # assert Range(oo, n).is_finite_set is True\n    # Above tests fail due to a (potential) bug in sympy.sets.fancysets.Range.size (See issue #18999)\n"], "sample_1006": ["def test_binomial_series():\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True)\n\n    assert binomial(n, k).series(n, 0, 3) == \\\n        binomial(k, k)*(1 - k*EulerGamma + k**2*(EulerGamma**2/2 + pi**2/12) + O(k**3))\n"], "sample_208": ["def test_add_model_with_field_removed_from_base_model_and_altered(self):\n    \"\"\"\n    Removing a base field, altering it, and adding a new inherited model\n    that has a field with the same name.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=300)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n        ], bases=('app.readable',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['AlterField', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n"], "sample_233": ["def test_token_with_different_password(self):\n    \"\"\"Updating the user password invalidates the token.\"\"\"\n    user = User.objects.create_user('changepassworduser', 'test5@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk1), True)\n    user.set_password('newtestpw')\n    user.save()\n    self.assertIs(p0.check_token(user, tk1), False)\n"], "sample_496": ["def test_custom_project_template_with_non_ascii_templates_in_filename(self):\n    \"\"\"\n    The startproject management command is able to render templates with\n    non-ASCII content in the filename.\n    \"\"\"\n    template_path = os.path.join(custom_templates_dir, 'project_template')\n    args = ['startproject', '--template', template_path, '--extension=txt', 'customtestproject']\n    testproject_dir = os.path.join(self.test_dir, 'customtestproject')\n    self.addCleanup(shutil.rmtree, testproject_dir, True)\n\n    out, err = self.run_django_admin(args)\n    self.assertNoOutput(err)\n    self.assertTrue(os.path.isdir(testproject_dir))\n    path = os.path.join(testproject_dir, 'ticket-18091-non-ascii-template-\u00e9.txt')\n    with codecs.open(path, 'r', encoding='utf-8') as f:\n        self.assertEqual(f.read().splitlines(False), [\n            'Some non-ASCII text for testing ticket #18091:',\n            '\u00fc\u00e4\u00f6 \u20ac'])\n"], "sample_190": ["def test_exact_query_rhs_with_selected_columns_and_limit(self):\n    newest_author = Author.objects.create(name='Author 3')\n    authors_max_ids = Author.objects.filter(\n        name='Author 3',\n    ).values(\n        'name',\n    ).annotate(\n        max_id=Max('id'),\n    ).values('max_id')\n    authors = Author.objects.filter(id=authors_max_ids[:2])\n    self.assertEqual(list(authors), [newest_author])\n"], "sample_841": ["def test_ridge_saga_with_X_fortran():\n    # check that Fortran array are converted when using SAGA solver\n    X, y = make_regression(random_state=42)\n    # for the order of X and y to not be C-ordered arrays\n    X = np.asfortranarray(X)\n    X = X[::2, :]\n    y = y[::2]\n    Ridge(solver='saga').fit(X, y)\n"], "sample_876": ["def test_mlp_classifier_sparse_input():\n    # Test that MLPClassifier handles sparse input correctly\n    from scipy.sparse import csr_matrix\n\n    X_sparse = csr_matrix(X_digits_binary[:50])\n    y = y_digits_binary[:50]\n\n    clf = MLPClassifier(solver=\"lbfgs\", hidden_layer_sizes=15, random_state=1)\n    clf.fit(X_sparse, y)\n    pred1 = clf.predict(X_sparse)\n\n    clf = MLPClassifier(solver=\"lbfgs\", hidden_layer_sizes=15, random_state=1)\n    clf.fit(X_sparse.toarray(), y)\n    pred2 = clf.predict(X_sparse.toarray())\n\n    assert_array_equal(pred1, pred2)\n"], "sample_145": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            exclude = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin, ValidationTestModel,\n            \"The value of 'exclude' must be a list or tuple.\",\n            'admin.E014'\n        )\n"], "sample_479": ["def test_create_model_add_index(self):\n    \"\"\"\n    AddIndex should optimize into CreateModel.\n    \"\"\"\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                \"Foo\", [(\"name\", models.CharField(max_length=255))]\n            ),\n            migrations.AddIndex(\n                \"Foo\",\n                models.Index(fields=[\"name\"], name=\"idx_foo_name\"),\n            ),\n        ],\n        [\n            migrations.CreateModel(\n                \"Foo\",\n                [(\"name\", models.CharField(max_length=255))],\n                options={\"indexes\": [models.Index(fields=[\"name\"], name=\"idx_foo_name\")]},\n            ),\n        ],\n    )\n"], "sample_313": ["def test_get_template_directories_with_eggs_loader(self, mock_is_django_path):\n    self.assertSetEqual(\n        autoreload.get_template_directories(),\n        {\n            EXTRA_TEMPLATES_DIR,\n        }\n    )\n    mock_is_django_path.assert_called_once_with(EXTRA_TEMPLATES_DIR)\n"], "sample_258": ["def test_send_robust_multiple_receivers(self):\n        return val * 2\n\n        return val * 3\n\n    a_signal.connect(receiver_1)\n    a_signal.connect(receiver_2)\n    result = a_signal.send_robust(sender=self, val=2)\n    self.assertEqual(result, [(receiver_1, 4), (receiver_2, 6)])\n    a_signal.disconnect(receiver_1)\n    a_signal.disconnect(receiver_2)\n    self.assertTestIsClean(a_signal)\n"], "sample_645": ["def test_log_report_captures_according_to_config_option_upon_success(\n    pytester: Pytester,"], "sample_501": ["def test_legend_title_fontprop_dict():\n    # test the title_fontproperties kwarg with a dict\n    plt.plot(range(10))\n    leg = plt.legend(title='Aardvark', title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg.get_title().get_fontproperties().get_family() == ['serif']\n    assert leg.get_title().get_fontproperties().get_size() == 22\n"], "sample_1144": ["def test_requires_partial_derivative_of_derivative():\n    x, y = symbols('x y')\n    f = x * y\n    assert requires_partial(Derivative(Derivative(f, x), y)) is True\n    assert requires_partial(Derivative(Derivative(f, x), x)) is False\n"], "sample_991": ["def test_product_with_zero_factor():\n    assert product(0, (k, 1, n)) == 0\n"], "sample_144": ["def test_queryset_update_on_child_model(self):\n    \"\"\"\n    Regression test for #10362\n    It is possible to call update() and only change a field in\n    a child model.\n    \"\"\"\n    article = ArticleWithAuthor.objects.create(\n        author=\"fred\",\n        headline=\"Hey there!\",\n        pub_date=datetime.datetime(2009, 3, 1, 8, 0, 0),\n    )\n    update = ArticleWithAuthor.objects.filter(author='fred').update(headline='Oh, no!')\n    self.assertEqual(update, 1)\n    update = ArticleWithAuthor.objects.filter(pk=article.pk).update(headline='Oh, no!')\n    self.assertEqual(update, 1)\n\n    derivedm1 = DerivedM.objects.create(\n        customPK=44,\n        base_name=\"b1\",\n        derived_name='d1',\n    )\n    update = DerivedM.objects.filter(customPK=44).update(derived_name='d2')\n    self.assertEqual(update, 1)\n    derivedm1.refresh_from_db()\n    self.assertEqual(derivedm1.derived_name, 'd2')\n"], "sample_749": ["def test_column_transformer_remainder_transformer_with_weights():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n    X_res_both = X_array.copy()\n\n    # second and third columns are doubled when remainder = DoubleTrans\n    X_res_both[:, 1:3] *= 2\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=DoubleTrans(),\n                           transformer_weights={'remainder': 2})\n\n    assert_array_equal(ct.fit_transform(X_array), 2 * X_res_both)\n    assert_array_equal(ct.fit(X_array).transform(X_array), 2 * X_res_both)\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], DoubleTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n"], "sample_1016": ["def test_MatrixSlice_printing():\n    A = MatrixSymbol(\"A\", 3, 3)\n    assert mcode(A[0:2, 0:2]) == \"A(1:2, 1:2)\"\n    assert mcode(A[0:3:2, 0:3:2]) == \"A(1:2:3, 1:2:3)\"\n    assert mcode(A[0:1, 0:1]) == \"A(1, 1)\"\n    assert mcode(A[0:1, :]) == \"A(1, :)\"\n    assert mcode(A[:, 0:1]) == \"A(:, 1)\"\n"], "sample_131": ["    def test_serialize_db_to_string(self):\n        # Test that the serialize_db_to_string method correctly serializes the database\n        creation = connection.creation_class(connection)\n        serialized_data = creation.serialize_db_to_string()\n        self.assertIsInstance(serialized_data, str)\n        self.assertNotEqual(serialized_data, '')\n"], "sample_256": ["    def test_integer_username(self):\n        data = {\n            'username': 123456,\n            'password1': 'testclient',\n            'password2': 'testclient',\n        }\n        form = UserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        u = form.save()\n        self.assertEqual(u.username, 123456)\n"], "sample_331": ["    def test_parse_datetime_with_microseconds(self):\n        valid_inputs = (\n            ('2012-04-23T10:20:30.400000+02:30', datetime(2012, 4, 23, 10, 20, 30, 400000, get_fixed_timezone(150))),\n            ('2012-04-23T10:20:30.400000-02', datetime(2012, 4, 23, 10, 20, 30, 400000, get_fixed_timezone(-120))),\n            ('2012-04-23T10:20:30.400000 +0230', datetime(2012, 4, 23, 10, 20, 30, 400000, get_fixed_timezone(150))),\n            ('2012-04-23T10:20:30.400000 +00', datetime(2012, 4, 23, 10, 20, 30, 400000, get_fixed_timezone(0))),\n            ('2012-04-23T10:20:30.400000   -02', datetime(2012, 4, 23, 10, 20, 30, 400000, get_fixed_timezone(-120))),\n        )\n        for source, expected in valid_inputs:\n            with self.subTest(source=source):\n                self.assertEqual(parse_datetime(source), expected)\n"], "sample_217": ["def test_media_inheritance_extends_js(self):\n    # A widget can explicitly enable full media inheritance for js by specifying 'extend=('js',)'\n    class MyWidget1(TextInput):\n        class Media:\n            css = {\n                'all': ('path/to/css1', '/path/to/css2')\n            }\n            js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')\n\n    class MyWidget13(MyWidget1):\n        class Media:\n            extend = ('js',)\n            css = {\n                'all': ('/path/to/css3', 'path/to/css1')\n            }\n            js = ('/path/to/js1', '/path/to/js4')\n\n    w13 = MyWidget13()\n    self.assertEqual(\n        str(w13.media),\n        \"\"\"<link href=\"/path/to/css3\" type=\"text/css\" media=\"all\" rel=\"stylesheet\">"], "sample_981": ["def test_commutes_with():\n    p = Permutation([1, 5, 2, 0, 3, 6, 4])\n    q = Permutation([[1, 2, 3, 5, 6], [0, 4]])\n    assert p.commutes_with(q) == False\n    assert q.commutes_with(p) == False\n    r = Permutation([3, 2, 1, 0])\n    assert p.commutes_with(r) == False\n    assert r.commutes_with(p) == False\n    assert q.commutes_with(r) == False\n    assert r.commutes_with(q) == False\n    s = Permutation([0, 1, 2, 3])\n    assert p.commutes_with(s) == False\n    assert s.commutes_with(p) == False\n    assert q.commutes_with(s) == False\n    assert s.commutes_with(q) == False\n    assert r.commutes_with(s) == True\n    assert s.commutes_with(r) == True\n"], "sample_1003": ["def test_Options_init():\n    opt = Options((x, y, z), {'domain': 'ZZ', 'expand': False})\n\n    assert opt.gens == (x, y, z)\n    assert opt.domain == ZZ\n    assert opt.expand is False\n\n    raises(OptionError, lambda: Options((x, y, z), {'domain': 'ZZ', 'gens': (x, y)}))\n    raises(OptionError, lambda: Options((x, y, z), {'invalid_option': True}))\n    raises(OptionError, lambda: Options((x, y, z), {'expand': True, 'frac': True}, strict=True))\n"], "sample_997": ["def test_convert_equality_operators():\n    transformations = standard_transformations + (convert_equals_signs,)\n    x = Symbol('x')\n    y = Symbol('y')\n    assert parse_expr(\"1*2==x\", transformations=transformations) == Eq(2, x)\n    assert parse_expr(\"y==x\", transformations=transformations) == Eq(y, x)\n    assert parse_expr(\"(2*y==x)==False\", transformations=transformations) == Eq(Eq(2*y, x), False)\n"], "sample_558": ["def test_grid_with_axes_class_overriding_axis():\n    class CustomAxes(mpl.axes.Axes):\n            super().__init__(*args, **kwargs)\n            self.axis = \"custom\"\n\n    grid = Grid(plt.figure(), 111, (2, 2), axes_class=CustomAxes)\n    for ax in grid:\n        assert ax.axis == \"custom\"\n"], "sample_1098": ["def test_appellf1_series():\n    a, b1, b2, c, x, y = symbols('a b1 b2 c x y')\n    f = appellf1(a, b1, b2, c, x, y)\n    series_x = f.series(x, 0, 3)\n    series_y = f.series(y, 0, 3)\n    assert series_x == 1 + a*b1*x/c + (a*(a + 1)*b1*(b1 + 1)*x**2/(2*c*(c + 1))) + O(x**3)\n    assert series_y == 1 + a*b2*y/c + (a*(a + 1)*b2*(b2 + 1)*y**2/(2*c*(c + 1))) + O(y**3)\n"], "sample_746": ["def test_brier_score_loss_with_sample_weight():\n    # Check brier_score_loss function with sample_weight\n    y_true = np.array([0, 1, 1, 0, 1, 1])\n    y_pred = np.array([0.1, 0.8, 0.9, 0.3, 1., 0.95])\n    sample_weight = np.array([1, 2, 1, 1, 1, 1])\n    true_score = np.sum((y_true - y_pred) ** 2 * sample_weight) / np.sum(sample_weight)\n\n    assert_almost_equal(brier_score_loss(y_true, y_pred, sample_weight=sample_weight), true_score)\n"], "sample_244": ["def test_formset_with_deletion_extra_forms(self):\n    \"\"\"\n    Formset with deletion and extra forms.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_delete=True, extra=2)\n    initial = [{'choice': 'Calexico', 'votes': 100}, {'choice': 'Fergie', 'votes': 900}]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_884": ["def test_property_decorator():\n    with pytest.warns(FutureWarning, match=\"n_features_ is deprecated\"):\n        MockClass2().n_features_\n"], "sample_264": ["def test_empty_messages(self):\n    \"\"\"\n    An empty list of messages is properly encoded/decoded by the custom JSON\n    encoder/decoder classes.\n    \"\"\"\n    messages = []\n    storage = self.get_storage()\n    encoded = storage._encode(messages)\n    decoded = storage._decode(encoded)\n    self.assertEqual(messages, decoded)\n"], "sample_127": ["def test_bulk_create_with_returning_fields(self):\n    data = [\n        Country(name=\"France\", iso_two_letter=\"FR\"),\n        Country(name=\"Spain\", iso_two_letter=\"ES\"),\n    ]\n    created = Country.objects.bulk_create(data, returning_fields=['id', 'name'])\n    self.assertEqual(len(created), 2)\n    self.assertEqual(created[0].name, \"France\")\n    self.assertEqual(created[1].name, \"Spain\")\n    self.assertIsNotNone(created[0].id)\n    self.assertIsNotNone(created[1].id)\n"], "sample_951": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n    @singledispatch\n        pass\n\n    @func.register(int)\n        pass\n\n    assert inspect.is_singledispatch_function(func) is True\n    assert inspect.is_singledispatch_function(func.register) is False\n\n        pass\n\n    assert inspect.is_singledispatch_function(not_singledispatch_func) is False\n"], "sample_838": ["def test_column_transformer_reordered_column_names_no_remainder():\n    \"\"\"Regression test for issue #14223: 'Named col indexing fails with\n       ColumnTransformer remainder on changing DataFrame column ordering'\n\n       Should allow for reordered column names as long as no remainder is used.\n    \"\"\"\n    pd = pytest.importorskip('pandas')\n\n    X_fit_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    X_fit_df = pd.DataFrame(X_fit_array, columns=['first', 'second'])\n\n    X_trans_array = np.array([[2, 4, 6], [0, 1, 2]]).T\n    X_trans_df = pd.DataFrame(X_trans_array, columns=['second', 'first'])\n\n    tf = ColumnTransformer([('bycol', Trans(), 'first')])\n\n    tf.fit(X_fit_df)\n    # No error for reordered columns if no remainder is used\n    tf.transform(X_trans_df)  # No error should be raised\n"], "sample_475": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            exclude = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'exclude' must be a list or tuple.\",\n            \"admin.E014\",\n        )\n"], "sample_404": ["def test_compile_filter_expression_error_in_variable(self):\n    \"\"\"\n    FilterExpression errors in variables should be highlighted correctly.\n    \"\"\"\n    engine = self._engine()\n    msg = \"Could not parse the remainder: '@bar' from 'foo@bar'\"\n\n    with self.assertRaisesMessage(TemplateSyntaxError, msg) as e:\n        engine.from_string(\"{{ foo@bar }}\")\n\n    if self.debug_engine:\n        debug = e.exception.template_debug\n        self.assertEqual((debug[\"start\"], debug[\"end\"]), (0, 11))\n        self.assertEqual((debug[\"during\"]), \"{{ foo@bar }}\")\n"], "sample_149": ["def test_is_anonymous_authenticated_properties(self):\n    \"\"\"\n    <User Model>.is_anonymous/is_authenticated can be properties.\n    \"\"\"\n    class CustomUserWithProperties(AbstractBaseUser):\n        username = models.CharField(max_length=30, unique=True)\n        USERNAME_FIELD = 'username'\n\n        @property\n            return False\n\n        @property\n            return True\n\n    errors = checks.run_checks(app_configs=self.apps.get_app_configs())\n    self.assertEqual(errors, [])\n"], "sample_830": ["def test_get_blas_info():\n    blas_info = _get_blas_info()\n\n    assert 'macros' in blas_info\n    assert 'lib_dirs' in blas_info\n    assert 'cblas_libs' in blas_info\n"], "sample_414": ["def test_ForeignKey_using_to_field_with_invalid_value(self):\n    from selenium.webdriver.common.by import By\n    from selenium.webdriver.support.ui import Select\n\n    self.admin_login(username=\"super\", password=\"secret\", login_url=\"/\")\n    self.selenium.get(\n        self.live_server_url + reverse(\"admin:admin_widgets_profile_add\")\n    )\n\n    select = Select(self.selenium.find_element(By.ID, \"id_user\"))\n    select.select_by_value(\"invaliduser\")\n\n    save_button_css_selector = \".submit-row > input[type=submit]\"\n    self.selenium.find_element(By.CSS_SELECTOR, save_button_css_selector).click()\n\n    self.wait_for_text(\n        \".errorlist\", \"Select a valid choice. That choice is not one of the available choices.\"\n    )\n"], "sample_321": ["def test_https_good_referer_matches_cookie_domain_with_port_80(self):\n    \"\"\"\n    A POST HTTPS request with a good referer should be accepted from a\n    subdomain that's allowed by CSRF_COOKIE_DOMAIN and port 80.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['HTTP_REFERER'] = 'http://foo.example.com/'\n    req.META['SERVER_PORT'] = '443'\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.process_request(req)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n"], "sample_714": ["def test_brier_score_loss_sample_weight():\n    # Check brier_score_loss function with sample_weight\n    y_true = np.array([0, 1, 1, 0, 1, 1])\n    y_pred = np.array([0.1, 0.8, 0.9, 0.3, 1., 0.95])\n    sample_weight = np.array([1, 2, 1, 2, 1, 2])\n    true_score = np.sum((y_true - y_pred) ** 2 * sample_weight) / np.sum(sample_weight)\n\n    assert_almost_equal(brier_score_loss(y_true, y_pred, sample_weight=sample_weight), true_score)\n"], "sample_622": ["def test_decode_cf_variable_with_invalid_units():\n    variable = Variable([\"time\"], [1, 2, 3], {\"units\": \"invalid units\"})\n    with pytest.raises(ValueError, match=\"unable to decode time\"):\n        conventions.decode_cf_variable(\"time\", variable)\n"], "sample_1051": ["def test_float_precision():\n    f = Float('1.23456789', precision=10)\n    assert purestr(f) == \"Float('1.23456789', precision=10)\"\n    f = Float('1.23456789', precision=5)\n    assert purestr(f) == \"Float('1.2346', precision=5)\"\n"], "sample_495": ["def test_paginator_with_orphans(self):\n    \"\"\"\n    Test paginator with orphans.\n    \"\"\"\n    paginator = Paginator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 3, orphans=2)\n    self.assertEqual(paginator.num_pages, 4)\n    self.assertEqual(list(paginator.page_range), [1, 2, 3, 4])\n    page1 = paginator.page(1)\n    self.assertEqual(list(page1), [1, 2, 3])\n    page4 = paginator.page(4)\n    self.assertEqual(list(page4), [10])\n"], "sample_589": ["def test_interpolate_na_max_gap_int(da_time):\n    da_time[\"t\"] = np.arange(11)\n    expected = da_time.copy(data=[np.nan, 1, 2, 3, 4, 5, np.nan, np.nan, np.nan, np.nan, 10])\n    actual = da_time.interpolate_na(\"t\", max_gap=2, use_coordinate=False)\n    assert_equal(actual, expected)\n"], "sample_353": ["def test_fields_with_fk_non_interactive(self):\n    new_io = StringIO()\n    group = Group.objects.create(name='mygroup')\n    email = Email.objects.create(email='mymail@gmail.com')\n    call_command(\n        'createsuperuser',\n        interactive=False,\n        username=email.pk,\n        email=email.email,\n        group=group.pk,\n        stdout=new_io,\n    )\n    command_output = new_io.getvalue().strip()\n    self.assertEqual(command_output, 'Superuser created successfully.')\n    u = CustomUserWithFK._default_manager.get(email=email)\n    self.assertEqual(u.username, email)\n    self.assertEqual(u.group, group)\n"], "sample_95": ["def test_vary_on_headers(self):\n        return HttpResponse(\"response\")\n    my_view_vary = vary_on_headers('Accept-Language')(my_view)\n    request = HttpRequest()\n    request.META['HTTP_ACCEPT_LANGUAGE'] = 'en-US'\n    response = my_view_vary(request)\n    self.assertEqual(response['Vary'], 'Accept-Language')\n"], "sample_113": ["    def test_replace_named_groups(self):\n        tests = (\n            (r'^(?P<a>\\w+)/b/(\\w+)$', r'^<a>/b/(\\w+)$'),\n            (r'^(?P<a>\\w+)/b/(?P<c>\\w+)/$', r'^<a>/b/<c>/$'),\n            (r'^(?P<a>\\w+)/b/(\\w+)', r'^<a>/b/(\\w+)'),\n            (r'^(?P<a>\\w+)/b/(?P<c>\\w+)', r'^<a>/b/<c>'),\n        )\n        for pattern, output in tests:\n            with self.subTest(pattern=pattern):\n                self.assertEqual(utils.replace_named_groups(pattern), output)\n"], "sample_944": ["def test_restify_type_hints_Ellipsis():\n    assert restify(...) == \"...\"\n"], "sample_37": ["def test_sip_with_altkey_and_relax():\n    \"\"\"\n    Test that when creating a WCS object using a key, CTYPE with\n    that key is looked at and not the primary CTYPE.\n    Also test that when relax is True, \"-SIP\" is added to CTYPE.\n    fix for #5443.\n    \"\"\"\n    with fits.open(get_pkg_data_filename('data/sip.fits')) as f:\n        w = wcs.WCS(f[0].header)\n    # create a header with two WCSs.\n    h1 = w.to_header(relax=True, key='A')\n    h2 = w.to_header(relax=False)\n    h1['CTYPE1A'] = \"RA---SIN\"\n    h1['CTYPE2A'] = \"DEC--SIN\"\n    h1.update(h2)\n    w = wcs.WCS(h1, key='A', relax=True)\n    assert (w.wcs.ctype == np.array(['RA---SIN-SIP', 'DEC--SIN-SIP'])).all()\n"], "sample_878": ["def test_column_transformer_with_callable_column_transformer():\n    pd = pytest.importorskip(\"pandas\")\n\n    X_df = pd.DataFrame({\"col1\": [\"a\", \"a\", \"b\"], \"col2\": [\"z\", \"z\", \"z\"]})\n\n        return [\"col1\"]\n\n    ct = ColumnTransformer([(\"ohe\", OneHotEncoder(), selector)])\n    ct.fit(X_df)\n\n    assert_array_equal(ct.get_feature_names_out(), [\"ohe__col1_a\", \"ohe__col1_b\"])\n"], "sample_143": ["def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('CamelCaseExample'), 'camel case example')\n    self.assertEqual(text.camel_case_to_spaces('AnotherExample'), 'another example')\n    self.assertEqual(text.camel_case_to_spaces('NoCamelCase'), 'no camel case')\n    self.assertEqual(text.camel_case_to_spaces(''), '')\n    self.assertEqual(text.camel_case_to_spaces('AllCaps'), 'all caps')\n    self.assertEqual(text.camel_case_to_spaces('lazystrExample'), 'lazystr example')\n"], "sample_502": ["def test_subplot_mosaic_empty_sentinel():\n    fig, ax_dict = plt.subplot_mosaic({'A': [1, 2], 'B': [3, 4]}, empty_sentinel='.')\n    assert 'A' in ax_dict\n    assert 'B' in ax_dict\n    assert '.' not in ax_dict\n"], "sample_158": ["def test_foreign_object_to_unique_field_with_unique_together(self):\n    class Person(models.Model):\n        country_id = models.IntegerField()\n        city_id = models.IntegerField()\n\n        class Meta:\n            unique_together = (('country_id', 'city_id'),)\n\n    class MMembership(models.Model):\n        person_country_id = models.IntegerField()\n        person_city_id = models.IntegerField()\n        person = models.ForeignObject(\n            Person,\n            on_delete=models.CASCADE,\n            from_fields=['person_country_id', 'person_city_id'],\n            to_fields=['country_id', 'city_id'],\n        )\n\n    field = MMembership._meta.get_field('person')\n    self.assertEqual(field.check(), [])\n"], "sample_1111": ["def test_zero_function():\n    x = Symbol('x')\n    lines = [\n        '      0 |_______________________________________________________',\n        '         -1                         0                          1'\n    ]\n    assert list(textplot_str(0, -1, 1)) == lines\n"], "sample_40": ["def test_with_H0_default():\n    # Test with_H0 equivalency without specifying H0\n    h100dist = 100 * u.Mpc/u.littleh\n    H0_default_cosmo = cosmology.default_cosmology.get().H0\n    assert_quantity_allclose(h100dist.to(u.Mpc, u.with_H0()),\n                             H0_default_cosmo.value*u.Mpc)\n"], "sample_580": ["def test_variable_type_extension_dtype():\n\n    s = pd.Series([True, False, True], dtype=\"boolean\")\n    assert variable_type(s, boolean_type=\"boolean\", strict_boolean=True) == \"boolean\"\n\n    s = pd.Series([True, False, True], dtype=\"bool\")\n    assert variable_type(s, boolean_type=\"boolean\", strict_boolean=True) == \"boolean\"\n\n    s = pd.Series([True, False, True], dtype=\"object\")\n    assert variable_type(s, boolean_type=\"boolean\", strict_boolean=True) == \"numeric\"\n"], "sample_639": ["def test_base_checker_consistency() -> None:\n    \"\"\"Test consistency of msgid in the checker.\"\"\"\n    consistent_checker = OtherBasicChecker()\n    consistent_checker.check_consistency()  # This should not raise any exception\n\n    inconsistent_checker = DifferentBasicChecker()\n    with pytest.raises(InvalidMessageError):\n        inconsistent_checker.check_consistency()  # This should raise InvalidMessageError\n"], "sample_704": ["def test_node_add_report_section(pytester: Pytester) -> None:\n    items = pytester.getitems(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    item = items[0]\n    item.add_report_section(\"call\", \"custom\", \"custom content\")\n    assert item._report_sections == [(\"call\", \"custom\", \"custom content\")]\n"], "sample_752": ["def test_iforest_contamination_auto():\n    \"\"\"Test Isolation Forest with contamination='auto'\"\"\"\n\n    # Generate train/test data\n    rng = check_random_state(2)\n    X = 0.3 * rng.randn(120, 2)\n    X_train = np.r_[X + 2, X - 2]\n    X_train = X[:100]\n\n    # Generate some abnormal novel observations\n    X_outliers = rng.uniform(low=-4, high=4, size=(20, 2))\n    X_test = np.r_[X[100:], X_outliers]\n    y_test = np.array([0] * 20 + [1] * 20)\n\n    # fit the model with contamination='auto'\n    clf = IsolationForest(max_samples=100, random_state=rng, contamination='auto').fit(X_train)\n\n    # predict scores (the lower, the more normal)\n    y_pred = - clf.decision_function(X_test)\n\n    # check that the number of outliers detected is close to the expected contamination rate\n    assert_almost_equal(np.mean(y_pred > 0), 0.1, delta=0.05)\n"], "sample_1024": ["def test_Float_from_mpmath():\n    import mpmath\n    mpmath.mp.dps = 100\n    mp_pi = mpmath.pi()\n\n    assert Float(mp_pi, 100) == Float(mp_pi._mpf_, 100) == pi.evalf(100)\n\n    mpmath.mp.dps = 15\n\n    assert Float(mp_pi, 100) == Float(mp_pi._mpf_, 100) == pi.evalf(100)\n"], "sample_239": ["def test_formset_with_deletion_and_empty_forms(self):\n    \"\"\"FormSets with deletion and empty forms.\"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_delete=True, extra=2)\n    initial = [\n        {'choice': 'Calexico', 'votes': 100},\n        {'choice': 'Fergie', 'votes': 900},\n    ]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    # Let's delete Fergie and leave the extra forms empty.\n    data = {\n        'choices-TOTAL_FORMS': '4',  # the number of forms rendered\n        'choices-INITIAL_FORMS': '2',  # the number of forms with initial data\n        'choices-MIN_NUM_FORMS': '0',  # min number of forms\n        'choices-MAX_NUM_FORMS': '0',  # max number of forms\n        'choices-0-choice': 'Calexico',\n        'choices-0-votes': '100',\n        'choices-0-DELETE': '',\n        'choices-1-choice': 'Fergie',\n        'choices-1-votes': '900',\n        'choices-1-DELETE': 'on',\n        'choices-2-choice': '',\n        'choices-2-votes': '',\n        'choices-2-DELETE': '',\n        'choices-3-choice': '',\n        'choices-3-votes': '',\n        'choices-3-DELETE': '',\n    }\n    formset = ChoiceFormSet(data, auto_id=False, prefix='choices')\n    self.assertTrue(formset.is_valid())\n    self.assertEqual(\n        [form.cleaned_data for form in formset.forms],\n        [\n            {'votes': 100, 'DELETE': False, 'choice': 'Calexico'},\n            {'votes': 900, 'DELETE': True, 'choice': 'Fergie'},\n            {},\n           "], "sample_92": ["    def setUpTestData(cls):\n        cls.user = User.objects.create_user(\n            username=cls.remote_user, email='test@example.com', is_active=False\n        )\n"], "sample_224": ["def test_aggregation_subquery_annotation_related_field_with_filter(self):\n    publisher = Publisher.objects.create(name=self.a9.name, num_awards=2)\n    book = Book.objects.create(\n        isbn='159059999', name='Test book.', pages=819, rating=2.5,\n        price=Decimal('14.44'), contact=self.a9, publisher=publisher,\n        pubdate=datetime.date(2019, 12, 6),\n    )\n    book.authors.add(self.a5, self.a6, self.a7)\n    books_qs = Book.objects.annotate(\n        contact_publisher=Subquery(\n            Publisher.objects.filter(\n                pk=OuterRef('publisher'),\n                name=OuterRef('contact__name'),\n                num_awards__gt=1,\n            ).values('name')[:1],\n        )\n    ).filter(\n        contact_publisher__isnull=False,\n    ).annotate(count=Count('authors'))\n    self.assertSequenceEqual(books_qs, [book])\n"], "sample_1072": ["def test_floor_ceiling_complex():\n    assert floor(2 + 3*I) == 2 + 3*I\n    assert ceiling(2 + 3*I) == 2 + 3*I\n    assert floor(2 - 3*I) == 2 - 3*I\n    assert ceiling(2 - 3*I) == 2 - 3*I\n    assert floor(2.5 + 3.5*I) == 2 + 3*I\n    assert ceiling(2.5 + 3.5*I) == 3 + 4*I\n    assert floor(2.5 - 3.5*I) == 2 - 4*I\n    assert ceiling(2.5 - 3.5*I) == 3 - 3*I\n"], "sample_609": ["def test_polyval_with_nan() -> None:\n    xcoord = xr.DataArray(\n        pd.date_range(\"2000-01-01\", freq=\"D\", periods=10), dims=(\"x\",), name=\"x\"\n    )\n    xcoord[5] = np.nan\n\n    da = xr.DataArray(\n        np.stack((1.0 + xcoord + 2.0 * xcoord ** 2, 1.0 + 2.0 * xcoord + 3.0 * xcoord ** 2)),\n        dims=(\"d\", \"x\"),\n        coords={\"x\": xcoord, \"d\": [0, 1]},\n    )\n    coeffs = xr.DataArray(\n        [[2, 1, 1], [3, 2, 1]],\n        dims=(\"d\", \"degree\"),\n        coords={\"d\": [0, 1], \"degree\": [2, 1, 0]},\n    )\n\n    da_pv = xr.polyval(da.x, coeffs)\n\n    xr.testing.assert_allclose(da, da_pv.T, equal_nan=True)\n"], "sample_1202": ["def test_exponentiation_of_1():\n    x = Symbol('x')\n    assert 1**x == S.One\n    assert unchanged(Pow, 1, x)\n"], "sample_653": ["def test_log_cli_format(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n            logging.warning(\"test message\")\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n        log_cli_format=%(levelname)s:%(message)s\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"test_log_cli_format.py::test_log_cli \",\n            \"*-- live log call --*\",\n            \"WARNING:test message\",\n            \"PASSED*\",\n        ]\n    )\n"], "sample_739": ["def test_label_binarize_multilabel_indicator():\n    y_ind = np.array([[0, 1, 0], [1, 1, 1], [0, 0, 0]])\n    classes = [0, 1, 2]\n    pos_label = 3\n    neg_label = 0\n    expected = np.where(y_ind, pos_label, neg_label)\n    y_sparse = [sparse_matrix(y_ind)\n                for sparse_matrix in [coo_matrix, csc_matrix, csr_matrix,\n                                      dok_matrix, lil_matrix]]\n\n    for y in [y_ind] + y_sparse:\n        yield (check_binarized_results, y, classes, pos_label, neg_label,\n               expected)\n\n    assert_raises(ValueError, label_binarize, y, classes, neg_label=-1,\n                  pos_label=pos_label, sparse_output=True)\n"], "sample_579": ["def test_clustermap_with_custom_linkage(self):\n    try:\n        import fastcluster\n        row_linkage = fastcluster.linkage_vector(self.df_norm, method='single', metric='euclidean')\n        col_linkage = fastcluster.linkage_vector(self.df_norm.T, method='single', metric='euclidean')\n    except ImportError:\n        row_dists = distance.pdist(self.df_norm, metric='euclidean')\n        col_dists = distance.pdist(self.df_norm.T, metric='euclidean')\n        row_linkage = hierarchy.linkage(row_dists, method='single')\n        col_linkage = hierarchy.linkage(col_dists, method='single')\n\n    kws = self.default_kws.copy()\n    kws['row_linkage'] = row_linkage\n    kws['col_linkage'] = col_linkage\n\n    cm = mat.clustermap(self.df_norm, **kws)\n\n    npt.assert_array_equal(cm.dendrogram_row.linkage, row_linkage)\n    npt.assert_array_equal(cm.dendrogram_col.linkage, col_linkage)\n"], "sample_47": ["    def test_unicode_error_with_non_ascii_string(self):\n        \"\"\"\n        A UnicodeError displays a portion of the problematic string even when\n        it contains non-ASCII characters.\n        \"\"\"\n        try:\n            mark_safe('abcdefghijkl<p>mn\u1f40p</p>qrstuwxyz').encode('ascii')\n        except Exception:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(None, exc_type, exc_value, tb)\n        html = reporter.get_traceback_html()\n        self.assertIn('<h2>Unicode error hint</h2>', html)\n        self.assertIn('The string that could not be encoded/decoded was: ', html)\n        self.assertIn('<strong>&lt;p&gt;mn\u1f40p&lt;/p&gt;</strong>', html)\n"], "sample_507": ["def test_convert_with_none_unit():\n    with pytest.raises(ValueError):\n        cat.StrCategoryConverter.convert(['a', 'b', 'c'], None, None)\n"], "sample_62": ["def test_unregister_registered_model(self):\n    self.site.register(Person)\n    self.site.unregister(Person)\n    self.assertFalse(self.site.is_registered(Person))\n"], "sample_79": ["def test_singular_and_plural_suffix_with_empty_string(self):\n    self.check_values(('0', 'items'), ('1', 'item'), ('2', 'items'))\n"], "sample_301": ["def test_extra_files(self, mocked_modules, notify_mock):\n    extra_file = self.ensure_file(self.tempdir / 'extra_file.py')\n    self.reloader.extra_files.add(extra_file)\n    with self.tick_twice():\n        self.increment_mtime(extra_file)\n    self.assertEqual(notify_mock.call_count, 1)\n    self.assertCountEqual(notify_mock.call_args[0], [extra_file])\n"], "sample_193": ["def test_generic_fk_with_limit_choices_to(self):\n    A = self.create_model(\"A\", foreign_keys=[\n        models.ForeignKey('B', models.CASCADE),\n        GenericForeignKey('content_type', 'object_id', limit_choices_to={'app_label': 'migrations'}),\n    ])\n    B = self.create_model(\"B\", foreign_keys=[\n        models.ForeignKey('C', models.CASCADE),\n    ])\n    self.assertRelated(A, [B, 'contenttypes.ContentType'])\n    self.assertRelated(B, [A])\n"], "sample_238": ["def test_aggregation_subquery_annotation_related_field_with_filter(self):\n    publisher = Publisher.objects.create(name=self.a9.name, num_awards=2)\n    book = Book.objects.create(\n        isbn='159059999', name='Test book.', pages=819, rating=2.5,\n        price=Decimal('14.44'), contact=self.a9, publisher=publisher,\n        pubdate=datetime.date(2019, 12, 6),\n    )\n    book.authors.add(self.a5, self.a6, self.a7)\n    books_qs = Book.objects.annotate(\n        contact_publisher=Subquery(\n            Publisher.objects.filter(\n                pk=OuterRef('publisher'),\n                name=OuterRef('contact__name'),\n                num_awards__gt=1,\n            ).values('name')[:1],\n        )\n    ).filter(\n        contact_publisher__isnull=False,\n    ).annotate(count=Count('authors'))\n    self.assertSequenceEqual(books_qs, [book])\n"], "sample_182": ["def test_union_with_different_fields(self):\n    qs1 = Number.objects.filter(num=1).values('num')\n    qs2 = Number.objects.filter(num=2).values('other_num')\n    with self.assertRaisesMessage(TypeError, \"Merging 'QuerySet' classes must involve the same values in each case.\"):\n        list(qs1.union(qs2))\n"], "sample_743": ["def test_sparse_metric_callable_with_metric_params():\n        assert_true(issparse(x) and issparse(y))\n        return x.dot(V).dot(y.T).A.item()\n\n    X = csr_matrix([  # Population matrix\n        [1, 1, 1, 1, 1],\n        [1, 0, 1, 0, 1],\n        [0, 0, 1, 0, 0]\n    ])\n\n    Y = csr_matrix([  # Query matrix\n        [1, 1, 0, 1, 1],\n        [1, 0, 0, 0, 1]\n    ])\n\n    V = csr_matrix(np.eye(5))  # Metric parameter\n\n    nn = neighbors.NearestNeighbors(algorithm='brute', n_neighbors=2,\n                                    metric=sparse_metric, metric_params={'V': V}).fit(X)\n    N = nn.kneighbors(Y, return_distance=False)\n\n    # GS indices of nearest neighbours in `X` for `sparse_metric` with `V`\n    gold_standard_nn = np.array([\n        [2, 1],\n        [2, 1]\n    ])\n\n    assert_array_equal(N, gold_standard_nn)\n"], "sample_623": ["    def create_dataset(self, shape, pref_chunks):\n        \"\"\"Return a dataset with a variable with the given shape and preferred chunks.\"\"\"\n        dims = tuple(f\"dim_{idx}\" for idx in range(len(shape)))\n        return xr.Dataset(\n            {\n                self.var_name: xr.Variable(\n                    dims,\n                    np.empty(shape, dtype=np.dtype(\"V1\")),\n                    encoding={\"preferred_chunks\": dict(zip(dims, pref_chunks))},\n                )\n            }\n        )\n"], "sample_956": ["def test_inspect_main_invalid_url(capsys):\n    \"\"\"inspect_main interface, with invalid url argument\"\"\"\n    url = 'http://localhost:7777/' + INVENTORY_FILENAME\n\n    inspect_main([url])\n\n    stdout, stderr = capsys.readouterr()\n    assert \"Failed to establish a new connection\" in stderr\n"], "sample_9": ["def test_write_table_html_css():\n    \"\"\"\n    Test that passing css should include it in the output\n    \"\"\"\n    buffer_output = StringIO()\n    t = Table([[1], [2]], names=('a', 'b'))\n    ascii.write(t, buffer_output, format='html', htmldict={'css': 'body {background-color: powderblue;}'})\n\n    assert '<style>body {background-color: powderblue;}</style>' in buffer_output.getvalue()\n"], "sample_591": ["def test_merge_overwrite_vars(self):\n    ds1 = xr.Dataset({\"a\": (\"x\", [1, 2]), \"x\": [0, 1]})\n    ds2 = xr.Dataset({\"a\": (\"x\", [2, 3]), \"x\": [1, 2]})\n    expected = xr.Dataset({\"a\": (\"x\", [2, 3]), \"x\": [1, 2]})\n\n    assert expected.identical(ds1.merge(ds2, overwrite_vars=\"a\"))\n    assert expected.identical(ds2.merge(ds1, overwrite_vars=[\"a\"]))\n"], "sample_582": ["def test_run_cert_key_with_ssl_context(monkeypatch):\n    ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n    monkeypatch.setitem(sys.modules, \"ssl_context\", ssl_context)\n\n    # key specified with SSLContext\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"ssl_context\", \"--key\", __file__])\n"], "sample_794": ["def test_ridge_regression_with_sample_weight():\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 6, 5\n    X = rng.randn(n_samples, n_features)\n    coef = rng.randn(n_features)\n    y = np.dot(X, coef) + 0.01 * rng.randn(n_samples)\n    alpha = 1.0\n    sample_weight = rng.rand(n_samples)\n    rtol = 1e-2 if os.name == 'nt' and _IS_32BIT else 1e-5\n\n    results = dict()\n    for current_dtype in (np.float32, np.float64):\n        results[current_dtype] = ridge_regression(X.astype(current_dtype),\n                                                  y.astype(current_dtype),\n                                                  alpha=alpha,\n                                                  solver='auto',\n                                                  random_state=rng,\n                                                  sample_weight=sample_weight,\n                                                  max_iter=500,\n                                                  tol=1e-10,\n                                                  return_n_iter=False,\n                                                  return_intercept=False)\n\n    assert results[np.float32].dtype == np.float32\n    assert results[np.float64].dtype == np.float64\n    assert_allclose(results[np.float32], results[np.float64], rtol=rtol)\n"], "sample_829": ["def test_incremental_pca_sparse_transform():\n    # Test that transform works with sparse input.\n    X = iris.data\n    pca = PCA(n_components=2)\n    pca.fit_transform(X)\n    X_sparse = sparse.csr_matrix(X)\n    batch_size = X_sparse.shape[0] // 3\n    ipca = IncrementalPCA(n_components=2, batch_size=batch_size)\n    ipca.fit(X_sparse)\n\n    X_transformed = ipca.transform(X_sparse)\n\n    assert X_transformed.shape == (X_sparse.shape[0], 2)\n    np.testing.assert_allclose(ipca.explained_variance_ratio_.sum(),\n                               pca.explained_variance_ratio_.sum(), rtol=1e-3)\n"], "sample_514": ["def test_colorbar_set_ticklabels():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc)\n    cb.set_ticklabels(['Low', 'Medium', 'High'])\n    fig.canvas.draw()\n    labels = [label.get_text() for label in cb.ax.get_yticklabels()]\n    assert labels == ['Low', 'Medium', 'High']\n"], "sample_383": ["    def test_ticket_24605_exclude(self):\n        \"\"\"\n        Test exclude() with a subquery.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(\n            Individual.objects.exclude(\n                Q(alive=False), Q(related_individual__isnull=False)\n            ),\n            [i3],\n        )\n"], "sample_961": ["def test_pyfunction_with_positional_only_arguments(app):\n    text = \".. py:function:: hello(a, /, b)\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, ([desc_parameter, desc_sig_name, \"a\"],\n                                      [desc_parameter, desc_sig_operator, \"/\"],\n                                      [desc_parameter, desc_sig_name, \"b\"])])\n"], "sample_332": ["def test_formset_with_custom_prefix(self):\n    \"\"\"Formsets can have a custom prefix.\"\"\"\n    class CustomPrefixFormSet(BaseFormSet):\n        @classmethod\n            return 'custom'\n\n    CustomPrefixFavoriteDrinksFormSet = formset_factory(FavoriteDrinkForm, formset=CustomPrefixFormSet)\n    formset = CustomPrefixFavoriteDrinksFormSet()\n    self.assertEqual(formset.management_form.prefix, 'custom')\n    data = {\n        'custom-TOTAL_FORMS': '2',\n        'custom-INITIAL_FORMS': '0',\n        'custom-MIN_NUM_FORMS': '0',\n        'custom-MAX_NUM_FORMS': '0',\n    }\n    formset = CustomPrefixFavoriteDrinksFormSet(data=data)\n    self.assertEqual(formset.management_form.prefix, 'custom')\n    formset = CustomPrefixFavoriteDrinksFormSet(initial={})\n    self.assertEqual(formset.management_form.prefix, 'custom')\n"], "sample_265": ["def test_template_origin(self):\n    engine = DjangoTemplates({\n        'DIRS': [Path(__file__).parent / 'templates' / 'template_backends'],\n        'APP_DIRS': False,\n        'NAME': 'django',\n        'OPTIONS': {},\n    })\n    template = engine.get_template('hello.html')\n    self.assertEqual(template.origin.name, 'hello.html')\n"], "sample_6": ["def test_angle_wrap_at():\n    a1 = Angle([350, 10, -10], unit=u.degree)\n    a2 = a1.wrap_at(180 * u.degree)\n    npt.assert_almost_equal(a2.degree, [-10, 10, -10])\n\n    a3 = Angle([350, 10, -10], unit=u.degree)\n    a3.wrap_at(180 * u.degree, inplace=True)\n    npt.assert_almost_equal(a3.degree, [-10, 10, -10])\n\n    a4 = Angle([350, 10, -10], unit=u.degree)\n    a4.wrap_at('180d', inplace=True)\n    npt.assert_almost_equal(a4.degree, [-10, 10, -10])\n\n    with pytest.raises(ValueError):\n        a5 = Angle([350, 10, -10], unit=u.degree)\n        a5.wrap_at('invalid', inplace=True)\n"], "sample_269": ["def test_i18n_language_with_custom_domain(self):\n    \"\"\"\n    Check if the JavaScript i18n view returns a complete language catalog\n    if a custom domain is used.\n    \"\"\"\n    with self.settings(LANGUAGE_CODE='en-us'), override('fr'):\n        response = self.client.get('/jsi18n/app6/custom_domain/')\n        self.assertContains(response, 'this app6 string is to be translated with custom domain')\n"], "sample_38": ["def test_scalar_inputs_world2pix():\n    \"\"\"\n    Issue #7845\n    \"\"\"\n    wcsobj = wcs.WCS(naxis=1)\n    result = wcsobj.all_world2pix(2, 1)\n    assert_array_equal(result, [np.array(2.)])\n    assert result[0].shape == ()\n\n    result = wcsobj.all_world2pix([2], 1)\n    assert_array_equal(result, [np.array([2.])])\n    assert result[0].shape == (1,)\n"], "sample_1172": ["def test_solve_poly_system_with_parameters():\n    x, y, a, b = symbols('x y a b')\n\n    # Test with parameters\n    assert solve_poly_system([x - a, y - b], x, y) == [(a, b)]\n\n    # Test with parameters and expressions\n    assert solve_poly_system([x - a*y, y - b*x], x, y) == [{x: 0, y: 0}, {x: b, y: a}]\n\n    # Test with parameters and non-trivial expressions\n    assert solve_poly_system([x**2 - a*y, y**2 - b*x], x, y) == [{x: 0, y: 0}, {x: sqrt(a*b), y: sqrt(a*b)}]\n"], "sample_118": ["def test_exact_query_rhs_with_selected_columns_and_filter(self):\n    newest_author = Author.objects.create(name='Author 3')\n    authors_max_ids = Author.objects.filter(\n        name='Author 3',\n    ).values(\n        'name',\n    ).annotate(\n        max_id=Max('id'),\n    ).filter(\n        max_id__gt=self.au2.id,\n    ).values('max_id')\n    authors = Author.objects.filter(id=authors_max_ids[:1])\n    self.assertEqual(authors.get(), newest_author)\n"], "sample_549": ["def test_safe_first_element_with_numpy_array():\n    arr = np.array([np.nan, 1, 2, 3])\n    actual = cbook._safe_first_finite(arr)\n    assert actual == 1\n"], "sample_107": ["def test_sensitive_settings_in_callable(self):\n    \"\"\"\n    The debug page should not show some sensitive settings\n    (password, secret key, ...) even if they are in a callable.\n    \"\"\"\n        return {\"SECRET_KEY\": \"should not be displayed\"}\n\n    with self.settings(DEBUG=True, FOOBAR=callable_setting):\n        response = self.client.get('/raises500/')\n        self.assertNotContains(response, 'should not be displayed', status_code=500)\n"], "sample_776": ["def test_lasso_lars_vs_R_implementation_with_intercept():\n    # Test that sklearn LassoLars implementation agrees with the LassoLars\n    # implementation available in R (lars library) when fit_intercept=True\n    # and normalize=False\n\n    # Let's generate the data used in the bug report 7778\n    y = np.array([-6.45006793, -3.51251449, -8.52445396, 6.12277822,\n                  -19.42109366])\n    x = np.array([[0.47299829, 0, 0, 0, 0],\n                  [0.08239882, 0.85784863, 0, 0, 0],\n                  [0.30114139, -0.07501577, 0.80895216, 0, 0],\n                  [-0.01460346, -0.1015233, 0.0407278, 0.80338378, 0],\n                  [-0.69363927, 0.06754067, 0.18064514, -0.0803561,\n                   0.40427291]])\n\n    X = x.T\n\n    # The R result was obtained using the following code:\n    #\n    # library(lars)\n    # model_lasso_lars = lars(X, t(y), type=\"lasso\", intercept=TRUE,\n    #                         trace=TRUE, normalize=FALSE)\n    # r = t(model_lasso_lars$beta)\n    #\n\n    r = np.array([[0, 0, 0, 0, 0,"], "sample_485": ["def test_urlize_nofollow(self):\n    value = \"Check out https://example.com.\"\n    output = 'Check out <a href=\"https://example.com/\" rel=\"nofollow\">https://example.com</a>.'\n    self.assertEqual(urlize(value, nofollow=True), output)\n"], "sample_1022": ["def test_convert_equals_signs():\n    cases = {\n        '1=2': 'Eq(1, 2)',\n        '1*2=x': 'Eq(1*2, x)',\n        '(1=2)=False': 'Eq(Eq(1, 2), False)',\n        '(1*2=x)=False': 'Eq(Eq(1*2, x), False)',\n    }\n    transformations = standard_transformations + (convert_equals_signs,)\n    for case in cases:\n        converted = parse_expr(case, transformations=transformations)\n        normal = parse_expr(cases[case])\n        assert(converted == normal)\n"], "sample_20": ["def test_fits_time_subclass_with_location(tmp_path):\n    \"\"\"Test writing and reading a Time subclass with location\"\"\"\n    filename = tmp_path / \"test_simple.fits\"\n    name = \"tm_loc\"\n    col = Time([50000, 50001], format=\"mjd\", location=(\"Earth\", 123, 456))\n    t = Table([col], names=[name])\n    t.write(filename, format=\"fits\")\n    t2 = Table.read(filename, format=\"fits\", astropy_native=True)\n    assert_objects_equal(t[name], t2[name], compare_attrs[name])\n"], "sample_245": ["def test_no_obsolete_enabled(self):\n    management.call_command('makemessages', locale=[LOCALE], verbosity=0, no_obsolete=True)\n    self.assertTrue(os.path.exists(self.PO_FILE))\n    with open(self.PO_FILE) as fp:\n        po_contents = fp.read()\n        self.assertNotIn(\"#, fuzzy\", po_contents)\n"], "sample_50": ["def test_no_user(self):\n    self.assertEqual(\n        self._run_it({\n            'database': 'dbname',\n            'password': 'somepassword',\n            'host': 'somehost',\n            'port': '444',\n        }), (\n            ['psql', '-h', 'somehost', '-p', '444', 'dbname'],\n            'somepassword',\n        )\n    )\n"], "sample_162": ["    def test_no_obsolete_enabled(self):\n        management.call_command('makemessages', locale=[LOCALE], verbosity=0, no_obsolete=True)\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertNotIn('#~ msgid \"This should be removed.\"', po_contents)\n"], "sample_1147": ["def test_latex_ArrayElement_with_symbols():\n    x, y, z = symbols('x y z')\n    A = ArraySymbol('A', 3, 3)\n    assert latex(ArrayElement(A, (x, y, z))) == r\"{{A}_{x, y, z}}\"\n"], "sample_734": ["def test_mutual_info_score_with_sparse_contingency():\n    # Test mutual_info_score with sparse contingency matrix\n    labels_a = np.array([1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3])\n    labels_b = np.array([1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 3, 1, 3, 3, 3, 2, 2])\n    C_sparse = contingency_matrix(labels_a, labels_b, sparse=True)\n    mi = mutual_info_score(labels_a, labels_b, contingency=C_sparse)\n    assert_almost_equal(mi, 0.41022, 5)\n"], "sample_172": ["def test_ForeignKey_using_to_field_with_existing_user(self):\n    existing_user = User.objects.create_user(username='existinguser', password='password')\n    self.admin_login(username='super', password='secret', login_url='/')\n    self.selenium.get(self.live_server_url + reverse('admin:admin_widgets_profile_add'))\n\n    main_window = self.selenium.current_window_handle\n    # Click the Change User button to change it\n    self.selenium.find_element_by_id('change_id_user').click()\n    self.wait_for_and_switch_to_popup()\n\n    # Select the existing user\n    select = Select(self.selenium.find_element_by_id('id_username'))\n    select.select_by_visible_text('existinguser')\n\n    save_button_css_selector = '.submit-row > input[type=submit]'\n    self.selenium.find_element_by_css_selector(save_button_css_selector).click()\n    self.selenium.switch_to.window(main_window)\n    self.selenium.find_element_by_css_selector('#id_user option[value=existinguser]')\n\n    # Go ahead and submit the form to make sure it works\n    self.selenium.find_element_by_css_selector(save_button_css_selector).click()\n    self.wait_for_text('li.success', 'The profile \u201cexistinguser\u201d was added successfully.')\n    profiles = Profile.objects.all()\n    self.assertEqual(len(profiles), 1)\n    self.assertEqual(profiles[0].user.username, 'existinguser')\n"], "sample_767": ["def test_column_transformer_empty_transformers():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n\n    ct = ColumnTransformer([])\n    assert_array_equal(ct.fit_transform(X_array), X_array)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_array)\n    assert len(ct.transformers_) == 1\n    assert ct.transformers_[0][0] == 'remainder'\n    assert ct.transformers_[0][1] == 'drop'\n    assert_array_equal(ct.transformers_[0][2], [0, 1])\n"], "sample_1044": ["def test_issue_10302_simplified():\n    u = -(3*2**pi)**(1/pi) + 2*3**(1/pi)\n    i = u + u*I\n    assert (u + i).is_zero is False\n"], "sample_620": ["def test_concat_index_not_same_length() -> None:\n    ds1 = Dataset(coords={\"x\": (\"x\", [1, 2])})\n    ds2 = Dataset(coords={\"x\": (\"x\", [3, 4, 5])})\n\n    with pytest.raises(\n        ValueError,\n        match=r\"Cannot concatenate along dimension 'x' indexes with different lengths.*\",\n    ):\n        concat([ds1, ds2], dim=\"x\")\n"], "sample_785": ["def test_leave_one_out_changing_groups():\n    # Check that LeaveOneOut works normally if the groups variable is changed before calling split\n    groups = np.array([0, 1, 2, 1, 1, 2, 0, 0])\n    X = np.ones(len(groups))\n    groups_changing = np.array(groups, copy=True)\n    loo = LeaveOneOut().split(X, groups=groups)\n    loo_changing = LeaveOneOut().split(X, groups=groups)\n    groups_changing[:] = 0\n    for lo, lo_changing in [(loo, loo_changing)]:\n        for (train, test), (train_chan, test_chan) in zip(lo, lo_changing):\n            assert_array_equal(train, train_chan)\n            assert_array_equal(test, test_chan)\n\n    # n_splits = no of unique groups (C(uniq_lbls, 1) = n_unique_groups)\n    assert_equal(3, LeaveOneOut().get_n_splits(X, y=X, groups=groups))\n"], "sample_213": ["    def test_delete_nonexistent_file(self):\n        \"\"\"\n        Calling delete on a nonexistent file should not raise an exception.\n        \"\"\"\n        self.storage.delete('nonexistent_file')\n"], "sample_345": ["def test_watch_dir_with_unresolvable_path_in_glob(self, mocked_modules, notify_mock):\n    path = Path('unresolvable_directory')\n    with mock.patch.object(Path, 'absolute', side_effect=FileNotFoundError):\n        self.reloader.watch_dir(path, '**/*.mo')\n    self.assertEqual(list(self.reloader.directory_globs), [])\n"], "sample_219": ["def test_expression_wrapper_with_outerref(self):\n    self.gmbh.point_of_contact = Employee.objects.get(lastname='Meyer')\n    self.gmbh.save()\n    inner = Employee.objects.filter(\n        lastname__startswith=Left(OuterRef(OuterRef('lastname')), 1),\n    )\n    qs = Employee.objects.annotate(\n        ceo_company=Subquery(\n            Company.objects.filter(\n                point_of_contact__in=inner,\n                ceo__pk=OuterRef('pk'),\n            ).values('name'),\n        ),\n    ).filter(ceo_company__isnull=False)\n    self.assertEqual(qs.get().ceo_company, 'Test GmbH')\n"], "sample_1185": ["def test_decompogen_min_max():\n    assert decompogen(Max(sin(x), cos(x)), x) == [Max(sin(x), cos(x))]\n    assert decompogen(Min(x**2, x**3), x) == [Min(x**2, x**3)]\n    assert decompogen(Max(sin(x), x**2), x) == [Max(sin(x), x**2)]\n    assert decompogen(Min(cos(x), x**2), x) == [Min(cos(x), x**2), cos(x)]\n"], "sample_1189": ["def test_lambdify_with_custom_printer():\n    class CustomPrinter(LambdaPrinter):\n            return \"custom_function(%s)\" % self.stringify(expr.args, \", \")\n\n    MyFunction = Function('MyFunction')\n    expr = MyFunction(x, y)\n    f = lambdify((x, y), expr, printer=CustomPrinter())\n    assert f(1, 2) == \"custom_function(1, 2)\"\n"], "sample_379": ["def test_safe_string_concatenation(self):\n    \"\"\"\n    Concatenating two SafeString instances results in a SafeString instance.\n    \"\"\"\n    s1 = mark_safe('a&b')\n    s2 = mark_safe('c&d')\n    s3 = s1 + s2\n    self.assertIsInstance(s3, SafeString)\n    self.assertRenderEqual('{{ s3 }}', 'a&bc&d', s3=s3)\n"], "sample_167": ["def test_intword_large_numbers(self):\n    # Test intword with large numbers.\n    test_list = (\n        '10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_421": ["def test_case_with_empty_when_and_default(self):\n    obj = CaseTestModel.objects.create(integer=0, decimal=Decimal(\"1\"))\n    qs = CaseTestModel.objects.annotate(\n        x=Case(\n            When(pk__in=[], then=Value(\"empty\")),\n            default=Value(\"default\"),\n        )\n    )\n    self.assertSequenceEqual(qs.filter(x=\"default\"), [obj])\n"], "sample_849": ["def test_leave_p_out_empty_trainset_with_groups():\n    cv = LeavePGroupsOut(n_groups=2)\n    X, y = [[1], [2]], [0, 3]  # 2 samples\n    with pytest.raises(\n            ValueError,\n            match=\"The groups parameter contains fewer than \\\\(or equal to\\\\) n_groups \\\\(2\\\\) numbers of unique groups \\\\(2\\\\). LeavePGroupsOut expects that at least n_groups \\\\+ 1 \\\\(3\\\\) unique groups be present\"):\n        next(cv.split(X, y, groups=[1, 1]))\n"], "sample_12": ["def test_angle_from_quantity():\n    \"\"\"\n    Test creating an Angle from a Quantity\n    \"\"\"\n    q = u.Quantity(54.12412, unit=u.degree)\n    a = Angle(q)\n    assert_allclose(a.degree, 54.12412)\n\n    q = u.Quantity(3.60827466667, unit=u.hour)\n    a = Angle(q)\n    assert_allclose(a.hour, 3.60827466667)\n\n    q = u.Quantity(0.944644098745, unit=u.radian)\n    a = Angle(q)\n    assert_allclose(a.radian, 0.944644098745)\n\n    # Test creating an Angle from a Quantity with a non-angular unit\n    q = u.Quantity(54.12412, unit=u.m)\n    with pytest.raises(u.UnitsError):\n        a = Angle(q)\n"], "sample_523": ["def test_legend_title_fontprop_fontsize_none():\n    # test the title_fontsize kwarg with None value\n    plt.plot(range(10))\n    leg = plt.legend(title='Aardvark', title_fontsize=None)\n    assert leg.get_title().get_fontsize() == mpl.rcParams['font.size']\n"], "sample_68": ["    def test_template_encoding(self):\n        \"\"\"\n        The templates are loaded directly, not via a template loader, and\n        should be opened as utf-8 charset as is the default specified on\n        template engines.\n        \"\"\"\n        try:\n            raise Exception(\"Test exception\")\n        except Exception:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(None, exc_type, exc_value, tb)\n        with mock.patch.object(DebugPath, 'open') as m:\n            reporter.get_traceback_html()\n            m.assert_called_once_with(encoding='utf-8')\n            m.reset_mock()\n            reporter.get_traceback_text()\n            m.assert_called_once_with(encoding='utf-8')\n"], "sample_90": ["def test_many_to_many_with_through(self):\n    \"\"\"Data for a ManyToManyField with a through model is a list rather than a lazy QuerySet.\"\"\"\n    blue = Colour.objects.create(name='blue')\n    red = Colour.objects.create(name='red')\n    item = ColourfulItem.objects.create()\n    item.colours.through.objects.create(colourfulitem=item, colour=blue)\n    data = model_to_dict(item)['colours']\n    self.assertEqual(data, [blue])\n    item.colours.through.objects.create(colourfulitem=item, colour=red)\n    # If data were a QuerySet, it would be reevaluated here and give \"red\"\n    # instead of the original value.\n    self.assertEqual(data, [blue])\n"], "sample_381": ["def test_add_model_with_field_removed_from_base_model_with_m2m(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name and a ManyToManyField.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n            ('authors', models.ManyToManyField('app.Author')),\n        ], bases=('app.readable',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n"], "sample_373": ["def test_model_detail_with_custom_field(self):\n    class CustomField(models.Field):\n        description = \"A custom field type\"\n\n    class CustomModel(models.Model):\n        custom_field = CustomField()\n\n    with self.settings(INSTALLED_APPS=['admin_docs']):\n        response = self.client.get(reverse('django-admindocs-models-detail', args=['admin_docs', 'custommodel']))\n        self.assertContains(response, '<td>custom_field</td>')\n        self.assertContains(response, '<td>A custom field type</td>')\n"], "sample_261": ["    def test_parse_datetime_invalid_tzinfo(self):\n        # Invalid timezone inputs\n        with self.assertRaises(ValueError):\n            parse_datetime('2012-04-23T09:15:00+24:00')\n        with self.assertRaises(ValueError):\n            parse_datetime('2012-04-23T09:15:00-24:00')\n        with self.assertRaises(ValueError):\n            parse_datetime('2012-04-23T09:15:00+99:00')\n        with self.assertRaises(ValueError):\n            parse_datetime('2012-04-23T09:15:00-99:00')\n"], "sample_306": ["    def test_parse_datetime_invalid_tzinfo(self):\n        # Invalid timezone offsets\n        with self.assertRaises(ValueError):\n            parse_datetime('2012-04-23T09:15:00+24:00')\n        with self.assertRaises(ValueError):\n            parse_datetime('2012-04-23T09:15:00-24:00')\n        with self.assertRaises(ValueError):\n            parse_datetime('2012-04-23T09:15:00+99:00')\n        with self.assertRaises(ValueError):\n            parse_datetime('2012-04-23T09:15:00-99:00')\n"], "sample_1103": ["def test_divmod_with_symbols():\n    x, y = symbols('x y')\n    assert divmod(x, y) == (x//y, x % y)\n    assert divmod(x, 3) == (x//3, x % 3)\n    assert divmod(3, x) == (3//x, 3 % x)\n"], "sample_411": ["def test_call_command_with_invalid_verbosity_level(self):\n    msg = \"argument --verbosity: invalid choice: 4 (choose from 0, 1, 2, 3)\"\n    with self.assertRaisesMessage(CommandError, msg):\n        management.call_command(\"dance\", verbosity=4)\n"], "sample_1168": ["def test_has_variety():\n    assert has_variety((1, 2, 1)) is True\n    assert has_variety((1, 1, 1)) is False\n"], "sample_809": ["def test_mutual_info_regression_sparse():\n    # Test that sparse matrix input raises an error when discrete_features is False\n    X = csr_matrix([[0, 0, 0],\n                    [1, 1, 0],\n                    [2, 0, 1],\n                    [2, 0, 1],\n                    [2, 0, 1]])\n    y = np.array([0, 1, 2, 2, 1])\n\n    with assert_raises(ValueError):\n        mutual_info_regression(X, y, discrete_features=False)\n"], "sample_42": ["def test_with_H0_default():\n    # Test that with_H0() uses the default cosmology if no H0 is provided\n    cosmodist = cosmology.default_cosmology.get().H0.value * u.Mpc/u.littleh\n    assert_quantity_allclose(cosmodist.to(u.Mpc, u.with_H0()), 100*u.Mpc)\n"], "sample_210": ["def test_template_params_with_query_string(self):\n    \"\"\"A generic template view passes kwargs and query string as context.\"\"\"\n    response = self.client.get('/template/simple/bar/?param=value')\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(response.context['foo'], 'bar')\n    self.assertEqual(response.context['param'], 'value')\n    self.assertIsInstance(response.context['view'], View)\n"], "sample_800": ["def test_check_estimator_transformer_n_iter():\n    # check that transformers with a parameter max_iter, return the\n    # attribute of n_iter_ at least 1.\n    estimator = NMF()\n    if hasattr(estimator, \"max_iter\"):\n        X, _ = make_blobs(n_samples=30, centers=[[0, 0, 0], [1, 1, 1]],\n                          random_state=0, n_features=2, cluster_std=0.1)\n        X -= X.min() - 0.1\n        set_random_state(estimator, 0)\n        estimator.fit(X)\n        assert estimator.n_iter_ >= 1\n"], "sample_652": ["def test_call_fixture_function_error_with_request(request):\n    \"\"\"Check if an error is raised if a fixture function is called directly with a request (#4545)\"\"\"\n\n    @pytest.fixture\n        return 1\n\n    with pytest.raises(pytest.fail.Exception):\n        assert fix(request) == 1\n"], "sample_862": ["def test_vectorizer_max_df_min_df():\n    test_data = ['abc', 'dea', 'eat']\n    vect = CountVectorizer(analyzer='char', max_df=0.5, min_df=0.5)\n    vect.fit(test_data)\n    assert 'a' not in vect.vocabulary_.keys()  # {ae} ignored\n    assert len(vect.vocabulary_.keys()) == 2    # {bd} remain\n    assert 'a' in vect.stop_words_\n    assert len(vect.stop_words_) == 3\n"], "sample_729": ["def test_enet_positive_constraint_with_precompute():\n    X = [[-1], [0], [1]]\n    y = [1, 0, -1]       # just a straight line with negative slope\n\n    enet = ElasticNet(alpha=0.1, max_iter=1000, positive=True, precompute=True)\n    enet.fit(X, y)\n    assert_true(min(enet.coef_) >= 0)\n"], "sample_516": ["def test_multibyte_characters():\n    \"\"\"Test that multibyte characters are handled correctly\"\"\"\n    fig = plt.figure()\n    s = \"\u3053\u3093\u306b\u3061\u306f\u3001\u4e16\u754c\uff01\"\n    fig.text(0, .5, s, size=20)\n"], "sample_287": ["def test_list_display_links_not_in_list_display(self):\n    class SongAdmin(admin.ModelAdmin):\n        list_display = [\"pk\", \"title\"]\n        list_display_links = [\"album\"]\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'list_display_links[0]' refers to 'album', which is not defined in 'list_display'.\",\n            obj=SongAdmin,\n            id='admin.E111',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_880": ["def test_ovr_decision_function_invalid_input():\n    # Test _ovr_decision_function with invalid input\n    predictions = np.array([[0, 1, 1], [0, 1, 0], [0, 1, 1], [0, 1, 1]])\n    confidences = np.array([[-1e16, 0, -1e16], [1.0, 2.0, -3.0], [-5.0, 2.0, 5.0]])\n    n_classes = 3\n\n    # Test with mismatched shapes\n    with pytest.raises(ValueError):\n        _ovr_decision_function(predictions, confidences, n_classes)\n\n    # Test with invalid n_classes\n    with pytest.raises(ValueError):\n        _ovr_decision_function(predictions, confidences, 4)\n"], "sample_71": ["    def test_grouping_sequence(self):\n        self.assertEqual(nformat(123456789, '.', grouping=(3, 2, 0), thousand_sep=','), '12,34,56,789')\n        self.assertEqual(nformat(123456789, '.', grouping=(3, 2, 0), thousand_sep=',', force_grouping=True), '12,34,56,789')\n        self.assertEqual(nformat(123456789, '.', grouping=(3, 2), thousand_sep=','), '123,45,6789')\n        self.assertEqual(nformat(123456789, '.', grouping=(3, 2), thousand_sep=',', force_grouping=True), '123,45,6789')\n"], "sample_562": ["def test_line_capstyle():\n    fig, ax = plt.subplots()\n    for capstyle in ['butt', 'round', 'projecting']:\n        ax.plot([0, 1], [0, 1], solid_capstyle=capstyle, label=capstyle)\n    ax.legend()\n    fig.canvas.draw()\n"], "sample_180": ["def test_unique_constraint_name_constraints(self):\n    class Model(models.Model):\n        class Meta:\n            constraints = [\n                models.UniqueConstraint(fields=['id'], name='_unique_name'),\n                models.UniqueConstraint(fields=['id'], name='5unique_name'),\n            ]\n\n    self.assertEqual(Model.check(databases=self.databases), [\n        Error(\n            \"The constraint name '%sunique_name' cannot start with an \"\n            \"underscore or a number.\" % prefix,\n            obj=Model,\n            id='models.E033',\n        ) for prefix in ('_', '5')\n    ])\n"], "sample_1209": ["def test_prefix_multiplication():\n    assert kilo * kibi == Prefix('kibikilo', 'Ki', 13, 2)\n    assert kibi * kilo == Prefix('kibikilo', 'Ki', 13, 2)\n    assert kilo / kibi == Prefix('kibideci', 'di', 7, 2)\n    assert kibi / kilo == Prefix('kibideci', 'di', -7, 2)\n"], "sample_1130": ["def test_auto_vel_inconsistent_relative_positions():\n    N = ReferenceFrame('N')\n    O = Point('O')\n    P = Point('P')\n    Q = Point('Q')\n    P.set_vel(N, N.x)\n    Q.set_vel(N, N.y)\n    O.set_pos(P, N.z)\n    O.set_pos(Q, -N.z)\n    with warnings.catch_warnings(): #There are two possible velocities for O, thus a warning is raised\n        warnings.simplefilter(\"error\")\n        raises(ValueError, lambda: O.vel(N))\n"], "sample_494": ["def test_serialize_complex(self):\n    self.assertSerializedEqual(complex(1, 2))\n    self.assertSerializedResultEqual(\n        complex(1, 2),\n        (\"complex((1+2j))\", set()),\n    )\n"], "sample_116": ["def test_cache_versioning_delete_many(self):\n    cache.set('answer1', 37, version=1)\n    cache.set('answer1', 42, version=2)\n    cache.set('answer2', 37, version=1)\n    cache.set('answer2', 42, version=2)\n    cache.delete_many(['answer1', 'answer2'])\n    self.assertIsNone(cache.get('answer1', version=1))\n    self.assertIsNone(cache.get('answer1', version=2))\n    self.assertIsNone(cache.get('answer2', version=1))\n    self.assertIsNone(cache.get('answer2', version=2))\n\n    cache.set('answer3', 37, version=1)\n    cache.set('answer3', 42, version=2)\n    cache.set('answer4', 37, version=1)\n    cache.set('answer4', 42, version=2)\n    cache.delete_many(['answer3', 'answer4'], version=2)\n    self.assertEqual(cache.get('answer3', version=1), 37)\n    self.assertIsNone(cache.get('answer3', version=2))\n    self.assertEqual(cache.get('answer4', version=1), 37)\n    self.assertIsNone(cache.get('answer4', version=2))\n\n    cache.set('answer5', 37, version=1)\n    cache.set('answer5', 42, version=2)\n    cache.set('answer6', 37, version=1)\n    cache.set('answer6', 42, version=2)\n    caches['v2'].delete_many(['answer5', 'answer6'])\n    self.assertEqual(cache.get('answer5', version=1), 37)\n    self.assertIsNone(cache.get('answer5', version=2))\n    self.assertEqual(cache.get('answer6', version=1), 37)\n    self.assertIsNone(cache.get('answer6', version=2))"], "sample_295": ["def test_expression_wrapper_with_transformed_field(self):\n    Employee.objects.create(firstname='Max', lastname='Mustermann')\n    with register_lookup(CharField, Length):\n        qs = Employee.objects.annotate(wrapper=ExpressionWrapper(F('lastname__length'), output_field=IntegerField()))\n        self.assertEqual(qs.get().wrapper, 10)\n"], "sample_76": ["def test_consistent_language_settings(self):\n    with self.settings(LANGUAGE_CODE='en', LANGUAGES=[('en', 'English')]):\n        self.assertEqual(check_language_settings_consistent(None), [])\n"], "sample_48": ["def test_aggregate_with_filter(self):\n    books = Book.objects.aggregate(\n        expensive_books=Count('id', filter=Q(price__gt=Decimal(\"40.0\"))),\n        cheap_books=Count('id', filter=Q(price__lte=Decimal(\"40.0\"))),\n    )\n    self.assertEqual(books['expensive_books'], 2)\n    self.assertEqual(books['cheap_books'], 4)\n"], "sample_333": ["def test_field_deep_copy_widget(self):\n    class CustomTextInput(TextInput):\n            kwargs['attrs'] = {'class': 'custom-class'}\n            super().__init__(**kwargs)\n\n    field = CharField(widget=CustomTextInput())\n    field_copy = copy.deepcopy(field)\n    self.assertIsInstance(field_copy, CharField)\n    self.assertIsNot(field_copy.widget, field.widget)\n    self.assertIsInstance(field_copy.widget, CustomTextInput)\n    self.assertIsNot(field_copy.widget.attrs, field.widget.attrs)\n"], "sample_577": ["def test_default_stat(self, long_df):\n\n    class MockStat(Stat):\n            self.called = True\n            return data\n\n    m = MockMark()\n    s = MockStat()\n    Plot(long_df, x=\"a\", y=\"z\").add(m, s).plot()\n    assert s.called\n"], "sample_565": ["def test_inset_axes_with_axes_class():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], [1, 2, 3])\n    ax.axis([1, 3, 1, 3])\n    inset_ax = inset_axes(ax, width=\"40%\", height=\"30%\", loc='lower right', axes_class=mpl.axes.Axes)\n    inset_ax.axis([1.1, 1.4, 1.1, 1.4])\n    fig.canvas.draw()\n    assert isinstance(inset_ax, mpl.axes.Axes)\n"], "sample_1083": ["def test_tanh_positive():\n    x = symbols('x')\n    k = symbols('k', real=True)\n    n = symbols('n', integer=True)\n\n    assert tanh(k).is_positive is None\n    assert tanh(k + (2*n + 1)*pi*I).is_positive is True\n    assert tanh(I*pi/4).is_positive is True\n    assert tanh(3*I*pi/4).is_positive is False\n"], "sample_662": ["def test_user_properties(self, testdir):\n    \"\"\"Test that user properties are serialized and deserialized correctly.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.user_property(\"key1\"==\"value1\")\n        @pytest.mark.user_property(\"key2\"==\"value2\")\n            pass\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    reports = reprec.getreports(\"pytest_runtest_logreport\")\n    assert len(reports) == 3  # setup, call, teardown\n    report = reports[1]  # call report\n    assert report.user_properties == [(\"key1\", \"value1\"), (\"key2\", \"value2\")]\n    data = report._to_json()\n    assert data[\"user_properties\"] == [(\"key1\", \"value1\"), (\"key2\", \"value2\")]\n    new_report = TestReport._from_json(data)\n    assert new_report.user_properties == [(\"key1\", \"value1\"), (\"key2\", \"value2\")]\n"], "sample_410": ["    def test_password_validation(self):\n        with self.assertRaises(ValidationError):\n            User.objects.create_user(username=\"user\", password=\"short\")\n\n        with self.assertRaises(ValidationError):\n            User.objects.create_user(username=\"user\", password=\"commonpassword\")\n\n        user = User.objects.create_user(username=\"user\", password=\"validpassword123\")\n        self.assertTrue(user.check_password(\"validpassword123\"))\n"], "sample_290": ["def test_add_model_with_field_removed_from_base_model_and_index_together(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name and index_together.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n        ], bases=('app.readable',), options={'index_together': {('title',)}}),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel', 'AlterIndexTogether'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n    self.assertOperationAttributes(changes, 'app', 0, 2, name='book', index_together={('title',)})\n"], "sample_525": ["def test_figure_pickle():\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.plot([1, 2, 3], [4, 5, 6])\n\n    pickled_fig = pickle.dumps(fig)\n    unpickled_fig = pickle.loads(pickled_fig)\n\n    assert isinstance(unpickled_fig, Figure)\n    assert len(unpickled_fig.axes) == 1\n    assert isinstance(unpickled_fig.axes[0], Axes)\n    assert len(unpickled_fig.axes[0].lines) == 1\n    assert isinstance(unpickled_fig.axes[0].lines[0], Line2D)\n"], "sample_157": ["    def test_serialize_test_setting_true(self, mocked_migrate, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['SERIALIZE'] = True\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=True)\n            self.assertIsNotNone(test_connection._test_serialized_contents)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_338": ["def test_alter_field_to_fk_dependency_other_app_with_initial_true(self):\n    class InitialMigration(migrations.Migration):\n        initial = True\n        operations = [\n            migrations.CreateModel('Author', fields=[\n                ('id', models.AutoField(primary_key=True)),\n            ]),\n        ]\n\n    before = self.make_project_state([InitialMigration('0001_initial', 'testapp')])\n    after = self.make_project_state([\n        InitialMigration('0001_initial', 'testapp'),\n        ModelState('otherapp', 'Book', [\n            ('id', models.AutoField(primary_key=True)),\n            ('author', models.ForeignKey('testapp.Author', models.CASCADE)),\n        ]),\n    ])\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['CreateModel'])\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '0001_initial')])\n"], "sample_497": ["def test_set_remove_overlapping_locs():\n    fig, ax = plt.subplots()\n    ax.xaxis.set_remove_overlapping_locs(True)\n    assert ax.xaxis.remove_overlapping_locs is True\n    ax.xaxis.set_remove_overlapping_locs(False)\n    assert ax.xaxis.remove_overlapping_locs is False\n"], "sample_46": ["def test_in_lookup(self):\n    u1 = PrimaryKeyUUIDModel.objects.create()\n    u2 = PrimaryKeyUUIDModel.objects.create()\n    u3 = PrimaryKeyUUIDModel.objects.create()\n    RelatedToUUIDModel.objects.create(uuid_fk=u1)\n    RelatedToUUIDModel.objects.create(uuid_fk=u2)\n    related_objects = RelatedToUUIDModel.objects.filter(uuid_fk__in=[u1.pk, u2.pk])\n    self.assertEqual(related_objects.count(), 2)\n    self.assertIn(u1, [obj.uuid_fk for obj in related_objects])\n    self.assertIn(u2, [obj.uuid_fk for obj in related_objects])\n    self.assertNotIn(u3, [obj.uuid_fk for obj in related_objects])\n"], "sample_977": ["def test_TrigonometricFunctions():\n    assert mcode(sin(x)) == \"Sin[x]\"\n    assert mcode(cos(x)) == \"Cos[x]\"\n    assert mcode(exp(x)) == \"Exp[x]\"\n    assert mcode(sin(x) + cos(x)) == \"Cos[x] + Sin[x]\"\n    assert mcode(sin(x) * cos(x)) == \"Cos[x]*Sin[x]\"\n"], "sample_463": ["def test_alter_index_together_to_index(self):\n    changes = self.get_changes(\n        [AutodetectorTests.author_empty, self.book_index_together],\n        [AutodetectorTests.author_empty, AutodetectorTests.book_indexes],\n    )\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterIndexTogether\", \"AddIndex\"])\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        0,\n        name=\"book\",\n        index_together=set(),\n    )\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        1,\n        model_name=\"book\",\n        fields=[\"author\", \"title\"],\n        name=\"book_title_author_idx\",\n    )\n"], "sample_440": ["def test_update_conflicts_with_expressions(self):\n    UpsertConflict.objects.bulk_create(\n        [\n            UpsertConflict(number=1, rank=1, name=\"John\"),\n            UpsertConflict(number=2, rank=2, name=\"Mary\"),\n        ]\n    )\n    self.assertEqual(UpsertConflict.objects.count(), 2)\n\n    conflicting_objects = [\n        UpsertConflict(number=1, rank=Lower(Value(4)), name=Lower(Value(\"Steve\"))),\n        UpsertConflict(number=2, rank=2, name=\"Olivia\"),\n    ]\n    UpsertConflict.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        update_fields=[\"name\", \"rank\"],\n        unique_fields=[\"number\"],\n    )\n    self.assertEqual(UpsertConflict.objects.count(), 2)\n    self.assertCountEqual(\n        UpsertConflict.objects.values(\"number\", \"rank\", \"name\"),\n        [\n            {\"number\": 1, \"rank\": 4, \"name\": \"steve\"},\n            {\"number\": 2, \"rank\": 2, \"name\": \"Olivia\"},\n        ],\n    )\n"], "sample_177": ["    def test_abstract_base_with_m2m(self):\n        A = self.create_model(\"A\", abstract=True, foreign_keys=[models.ManyToManyField('B')])\n        B = self.create_model(\"B\")\n        C = self.create_model(\"C\", bases=(A,))\n        self.assertRelated(A, [B, C])\n        self.assertRelated(B, [A, C])\n        self.assertRelated(C, [B, A.a_1.rel.through])\n"], "sample_853": ["def test_transform_target_regressor_default_regressor():\n    X, y = friedman\n    regr = TransformedTargetRegressor(transformer=StandardScaler())\n    regr.fit(X, y)\n    assert isinstance(regr.regressor_, LinearRegression)\n"], "sample_933": ["def test_build_gettext_uuid(app):\n    app.builder.build_all()\n\n    pot = (app.outdir / 'extapi.pot').read_text()\n    assert 'msgid \"\"' in pot\n    assert '\"#: extapi.rst:1\"' in pot\n    assert '\"#: extapi.rst:2\"' in pot\n    assert '\"#: extapi.rst:3\"' in pot\n    assert '\"#: extapi.rst:4\"' in pot\n    assert '\"#: extapi.rst:5\"' in pot\n    assert '\"#: extapi.rst:6\"' in pot\n    assert '\"#: extapi.rst:7\"' in pot\n    assert '\"#: extapi.rst:8\"' in pot\n    assert '\"#: extapi.rst:9\"' in pot\n    assert '\"#: extapi.rst:10\"' in pot\n    assert '\"#: extapi.rst:11\"' in pot\n    assert '\"#: extapi.rst:12\"' in pot\n    assert '\"#: extapi.rst:13\"' in pot\n    assert '\"#: extapi.rst:14\"' in pot\n    assert '\"#: extapi.rst:15\"' in pot\n    assert '\"#: extapi.rst:16\"' in pot\n    assert '\"#: extapi.rst:17\"' in pot\n    assert '\"#: extapi.rst:18\"' in pot\n    assert '\"#: extapi.rst:19\"' in pot\n    assert '\"#: extapi.rst:20\"' in pot\n    assert '\"#: extapi.rst:21\"' in pot\n    assert '\"#: extapi.rst:22\"' in pot\n    assert '\"#: extapi.rst:23\"' in pot\n    assert '\"#: extapi.rst:24\"' in"], "sample_424": ["def test_references_field_by_limit_choices_to(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ForeignKey(\n            \"Other\",\n            models.CASCADE,\n            limit_choices_to={\"field\": models.F(\"other_field\")},\n        ),\n    )\n    self.assertIs(operation.references_field(\"Model\", \"other_field\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Other\", \"field\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Other\", \"other_field\", \"migrations\"), False)\n"], "sample_326": ["def test_urlize_autoescape(self):\n    tests = (\n        ('<script>alert(\"Hello, world!\");</script>', '&lt;script&gt;alert(\"Hello, world!\");&lt;/script&gt;'),\n        ('<a href=\"http://example.com\">Link</a>', '&lt;a href=\"http://example.com\"&gt;Link&lt;/a&gt;'),\n        ('<img src=\"image.jpg\" alt=\"Image\">', '&lt;img src=\"image.jpg\" alt=\"Image\"&gt;'),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value, autoescape=True), output)\n"], "sample_351": ["def test_modelchoicefield_limit_choices_to(self):\n    f = forms.ModelChoiceField(Category.objects.all(), limit_choices_to={'slug': 'entertainment'})\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c1.pk, 'Entertainment'),\n    ])\n    with self.assertRaises(ValidationError):\n        f.clean(self.c2.id)\n"], "sample_448": ["def test_contains_expressions(self):\n    constraint_with_expressions = models.UniqueConstraint(\n        Lower(\"title\"),\n        F(\"author\"),\n        name=\"book_func_uq\",\n    )\n    constraint_without_expressions = models.UniqueConstraint(\n        fields=[\"foo\", \"bar\"],\n        name=\"unique_fields\",\n    )\n    self.assertTrue(constraint_with_expressions.contains_expressions)\n    self.assertFalse(constraint_without_expressions.contains_expressions)\n"], "sample_17": ["def test_matmul(self):\n    q1 = np.array([[1, 0], [0, 1]]) * u.m\n    q2 = np.array([[4, 1], [2, 2]]) * u.s\n    out = np.matmul(q1, q2)\n    expected = np.matmul(q1.value, q2.value) * u.m * u.s\n    assert np.all(out == expected)\n"], "sample_760": ["def test_scoring_with_custom_function():\n    # Test that check_scoring works with a custom scoring function\n        return np.mean(estimator.predict(X) == y)\n\n    estimator = EstimatorWithFitAndPredict()\n    estimator.fit([[1], [2], [3]], [1, 0, 1])\n\n    scorer = check_scoring(estimator, custom_scorer)\n    assert_almost_equal(scorer(estimator, [[1], [2], [3]], [1, 0, 0]), 0.5)\n"], "sample_657": ["def test_mark_decorator_with_args(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.a(1, 2, x=3)\n            pass\n\n            assert test_func.pytestmark[0].args == (1, 2)\n            assert test_func.pytestmark[0].kwargs == {'x': 3}\n        \"\"\"\n    )\n    items, rec = testdir.inline_genitems(p)\n    assert len(items) == 2\n    assert items[0].name == \"test_func\"\n    assert items[1].name == \"test_func_markers\"\n"], "sample_346": ["    def test_classonlymethod(self):\n        class MyClass:\n            @classonlymethod\n                return cls.__name__\n\n        self.assertEqual(MyClass.my_method(), 'MyClass')\n        with self.assertRaises(AttributeError):\n            MyClass().my_method()\n"], "sample_922": ["def test_pyfunction_signature_with_module_option(app):\n    text = \".. py:function:: hello(name: str) -> str\\n   :module: test.extra\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_addname, \"test.extra.\"],\n                                                    [desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_punctuation, \":\"],\n                                                      \" \",\n                                                      [nodes.inline, pending_xref, \"str\"])])\n"], "sample_314": ["    def test_unicode_username_normalization(self):\n        ohm_username = 'test\u2126'  # U+2126 OHM SIGN\n        data = {\n            'username': ohm_username,\n            'password1': 'pwd2',\n            'password2': 'pwd2',\n        }\n        form = UserCreationForm(data)\n        self.assertTrue(form.is_valid())\n        user = form.save()\n        self.assertNotEqual(user.username, ohm_username)\n        self.assertEqual(user.username, 'test\u03a9')  # U+03A9 GREEK CAPITAL LETTER OMEGA\n"], "sample_656": ["def test_capture_with_live_logging_disabled(testdir, capture_fixture):\n    # Issue 3819\n    # capture should work with live cli logging disabled\n\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        import sys\n\n        logger = logging.getLogger(__name__)\n\n            print(\"hello\")\n            sys.stderr.write(\"world\\\\n\")\n            with {0}.disabled():\n                print(\"disabled\")\n                sys.stderr.write(\"disabled\\\\n\")\n            captured = {0}.readouterr()\n            assert captured.out == \"hello\\\\n\"\n            assert captured.err == \"world\\\\n\"\n\n            logging.info(\"something\")\n            print(\"next\")\n            logging.info(\"something\")\n\n            captured = {0}.readouterr()\n            assert captured.out == \"next\\\\n\"\n        \"\"\".format(\n            capture_fixture\n        )\n    )\n\n    result = testdir.runpytest_subprocess(\"--log-cli-level=INFO\")\n    assert result.ret == 0\n"], "sample_453": ["def test_cell_count(self):\n    \"\"\"\n    cell_count template filter should return the correct number of cells used in a tabular inline.\n    \"\"\"\n    request = self.request_factory.get(\n        reverse(\"admin:admin_views_article_change\", args=[self.article.pk])\n    )\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    response = admin.change_view(request, str(self.article.pk))\n    inline_admin_form = response.context_data[\"inline_admin_formsets\"][0].form\n    cell_count_result = cell_count(inline_admin_form)\n    # Calculate the expected cell count manually\n    expected_cell_count = 1  # Hidden cell with hidden 'id' field\n    for fieldset in inline_admin_form:\n        for line in fieldset:\n            for field in line:\n                try:\n                    is_hidden = field.field.is_hidden\n                except AttributeError:\n                    is_hidden = field.field[\"is_hidden\"]\n                if not is_hidden:\n                    expected_cell_count += 1\n    if inline_admin_form.formset.can_delete:\n        expected_cell_count += 1  # Delete checkbox\n    self.assertEqual(cell_count_result, expected_cell_count)\n"], "sample_171": ["def test_makemigrations_with_invalid_squashed_name(self):\n    msg = 'The squashed migration name must be a valid Python identifier.'\n    with self.assertRaisesMessage(CommandError, msg):\n        call_command('makemigrations', 'migrations', '--squashed-name', 'invalid name', '--empty')\n"], "sample_1208": ["def test_sample_numpy():\n    numpy = import_module('numpy')\n    if not numpy:\n        skip('NumPy is not installed. Abort tests for _sample_numpy.')\n    else:\n        # Currently, there are no matrix distributions implemented in numpy_rv_map.\n        # Once they are added, we can uncomment the following lines to test _sample_numpy.\n        # distribs_numpy = [\n        #     MatrixNormal('M', [[5, 6], [3, 4]], [[1, 0], [0, 1]], [[2, 1], [1, 2]]),\n        #     Wishart('W', 7, [[2, 1], [1, 2]])\n        # ]\n        # size = 3\n        # for X in distribs_numpy:\n        #     samps = sample(X, size=size, library='numpy')\n        #     for sam in samps:\n        #         assert Matrix(sam) in X.pspace.distribution.set\n        M = MatrixGamma('M', 1, 2, [[1, 0], [0, 1]])\n        raises(NotImplementedError, lambda: sample(M, size=3, library='numpy'))\n"], "sample_1164": ["def test_cg_simp():\n    a = symbols('a')\n    alpha = symbols('alpha')\n    b = symbols('b')\n    c = symbols('c')\n    cg1 = CG(a, alpha, b, 0, a, alpha)\n    cg2 = CG(a, 0, 0, 0, a, 0)\n    cg3 = CG(a, -alpha, a, alpha, c, 0)\n    cg4 = CG(a, alpha, b, beta, c, gamma)\n    cg5 = CG(a, alpha, b, beta, c, gamma)\n    cg6 = CG(a, alpha, b, beta, c, gamma)\n    cg7 = CG(a, alpha, b, beta, c, gamma)\n    cg8 = CG(a, alpha, b, beta, c, gamma)\n    cg9 = CG(a, alpha, b, beta, c, gamma)\n    cg10 = CG(a, alpha, b, beta, c, gamma)\n    cg11 = CG(a, alpha, b, beta, c, gamma)\n    cg12 = CG(a, alpha, b, beta, c, gamma)\n    cg13 = CG(a, alpha, b, beta, c, gamma)\n    cg14 = CG(a, alpha, b, beta, c, gamma)\n    cg15 = CG(a, alpha, b, beta, c, gamma)\n    cg16 = CG(a, alpha, b, beta, c, gamma)\n    cg17 = CG(a, alpha, b, beta, c, gamma)\n    cg18 = CG(a, alpha, b, beta, c, gamma)\n    cg19 = CG(a, alpha, b, beta, c, gamma)\n    cg20 = CG(a, alpha, b, beta, c, gamma)\n    cg21 = CG(a, alpha,"], "sample_1122": ["def test_issue_15893_complex():\n    f = Function('f', complex=True)\n    x = Symbol('x', real=True)\n    eq = Derivative(Abs(f(x)), f(x))\n    assert eq.doit() == sign(f(x)) * conjugate(f(x)) / Abs(f(x))\n"], "sample_78": ["def test_call_command_with_invalid_integer_option(self):\n    msg = \"argument --integer: invalid int value: 'invalid'\"\n    with self.assertRaisesMessage(CommandError, msg):\n        management.call_command('dance', '--integer=invalid')\n"], "sample_882": ["def test_mlp_early_stopping_with_partial_fit():\n    \"\"\"Check that early stopping works with partial fit.\"\"\"\n    mlp = MLPClassifier(max_iter=10, random_state=0, early_stopping=True)\n    mlp.partial_fit(X_iris[:50], y_iris[:50], classes=np.unique(y_iris))\n    n_validation_scores = len(mlp.validation_scores_)\n    mlp.partial_fit(X_iris[50:], y_iris[50:])\n    assert len(mlp.validation_scores_) > n_validation_scores\n"], "sample_347": ["def test_localtime(self):\n    naive = datetime.datetime(2015, 1, 1, 0, 0, 1)\n    with self.assertRaisesMessage(ValueError, 'localtime() cannot be applied to a naive datetime'):\n        timezone.localtime(naive)\n    with self.assertRaisesMessage(ValueError, 'localtime() cannot be applied to a naive datetime'):\n        timezone.localtime(naive, timezone=EAT)\n\n    aware = datetime.datetime(2015, 1, 1, 0, 0, 1, tzinfo=ICT)\n    self.assertEqual(timezone.localtime(aware, timezone=EAT), datetime.datetime(2014, 12, 31, 18, 0, 1, tzinfo=EAT))\n    with timezone.override(EAT):\n        self.assertEqual(timezone.localtime(aware), datetime.datetime(2014, 12, 31, 18, 0, 1, tzinfo=EAT))\n\n    with mock.patch('django.utils.timezone.now', return_value=aware):\n        self.assertEqual(timezone.localtime(timezone=EAT), datetime.datetime(2014, 12, 31, 18, 0, 1, tzinfo=EAT))\n        with timezone.override(EAT):\n            self.assertEqual(timezone.localtime(), datetime.datetime(2014, 12, 31, 18, 0, 1, tzinfo=EAT))\n"], "sample_397": ["def test_template_loaders_config(self):\n    \"\"\"Test the configuration of template loaders.\"\"\"\n    # Test with custom loaders\n    engine = DjangoTemplates(\n        {\n            \"DIRS\": [],\n            \"APP_DIRS\": False,\n            \"NAME\": \"django\",\n            \"OPTIONS\": {\n                \"loaders\": [\n                    \"django.template.loaders.filesystem.Loader\",\n                    \"django.template.loaders.app_directories.Loader\",\n                ],\n            },\n        }\n    )\n    self.assertEqual(\n        engine.engine.loaders,\n        [\n            \"django.template.loaders.filesystem.Loader\",\n            \"django.template.loaders.app_directories.Loader\",\n        ],\n    )\n\n    # Test with app_dirs and custom loaders\n    with self.assertRaisesMessage(\n        ImproperlyConfigured,\n        \"app_dirs must not be set when loaders is defined.\",\n    ):\n        DjangoTemplates(\n            {\n                \"DIRS\": [],\n                \"APP_DIRS\": True,\n                \"NAME\": \"django\",\n                \"OPTIONS\": {\n                    \"loaders\": [\n                        \"django.template.loaders.filesystem.Loader\",\n                    ],\n                },\n            }\n        )\n"], "sample_390": ["def test_directory_index_template_context(self):\n    response = self.client.get(\"/%s/\" % self.prefix)\n    self.assertEqual(response.context[\"directory\"], \"./\")\n    self.assertIn(\"file.txt\", response.context[\"file_list\"])\n    self.assertIn(\"subdir/\", response.context[\"file_list\"])\n"], "sample_386": ["def test_mark_safe_decorator_with_args(self):\n    \"\"\"\n    mark_safe used as a decorator with arguments leaves the result of a function\n    unchanged.\n    \"\"\"\n\n        return f\"<{tag}>dummy</{tag}>\"\n\n    decorated_func = mark_safe(clean_string_provider)\n    self.assertEqual(decorated_func(\"html\"), \"<html>dummy</html>\")\n    self.assertEqual(decorated_func(\"body\"), \"<body>dummy</body>\")\n"], "sample_119": ["def test_complex_transform(self):\n    query = Query(Author)\n    with register_lookup(CharField, Lower):\n        where = query.build_where(~Q(name__lower__startswith='foo'))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, StartsWith)\n    self.assertIsInstance(lookup.lhs, Lower)\n    self.assertIsInstance(lookup.lhs.lhs, SimpleCol)\n    self.assertEqual(lookup.lhs.lhs.target, Author._meta.get_field('name'))\n"], "sample_881": ["def test_top_k_accuracy_score_error_labels_length(y_true, y_score, labels, msg):\n    with pytest.raises(ValueError, match=msg):\n        top_k_accuracy_score(y_true, y_score, k=2, labels=labels)\n"], "sample_832": ["def test_bayesian_ridge_intercept():\n    # Test BayesianRidge with intercept\n    X = np.vander(np.linspace(0, 4, 5), 4)\n    y = np.array([1., 2., 3., 4., 5.])    # y = x + 1\n\n    reg = BayesianRidge(fit_intercept=True)\n    reg.fit(X, y)\n    # Check the intercept is close to 1.\n    assert_almost_equal(reg.intercept_, 1.)\n"], "sample_231": ["    def test_unicode_error(self):\n        try:\n            ''.encode('ascii')\n        except UnicodeError:\n            exc_type, exc_value, tb = sys.exc_info()\n        request = self.client.get('/raises500/')\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        html = reporter.get_traceback_html()\n        self.assertIn('<h2>Unicode error hint</h2>', html)\n        self.assertIn('The string that could not be encoded/decoded was: ', html)\n        self.assertIn('<strong></strong>', html)\n"], "sample_1019": ["def test_issue_8263_non_commutative_symbols():\n    F, G = symbols('F, G', commutative=False, cls=Function)\n    x, y = symbols('x, y')\n    expr, dummies, _ = _mask_nc(F(x)*G(y) - G(y)*F(x))\n    for v in dummies.values():\n        assert not v.is_commutative\n    assert not expr.is_zero\n"], "sample_21": ["def test_read_write_simple_with_err_specs(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3]))\n    t1.add_column(Column(name=\"a_err\", data=[0.1, 0.2, 0.3]))\n    t1.add_column(Column(name=\"b\", data=[4.0, 5.0, 6.0]))\n    t1.add_column(Column(name=\"b_perr\", data=[0.4, 0.5, 0.6]))\n    t1.add_column(Column(name=\"b_nerr\", data=[0.7, 0.8, 0.9]))\n    t1.write(test_file, format=\"ascii.qdp\", err_specs={\"serr\": [2], \"terr\": [4]})\n    t2 = Table.read(test_file, table_id=0, format=\"ascii.qdp\", names=[\"a\", \"b\"])\n    assert np.allclose(t2[\"a\"], t1[\"a\"])\n    assert np.allclose(t2[\"a_err\"], t1[\"a_err\"])\n    assert np.allclose(t2[\"b\"], t1[\"b\"])\n    assert np.allclose(t2[\"b_perr\"], t1[\"b_perr\"])\n    assert np.allclose(t2[\"b_nerr\"], t1[\"b_nerr\"])\n"], "sample_765": ["def test_balanced_accuracy_score_multiclass():\n    y_true = np.array([0, 1, 2, 0, 1, 2])\n    y_pred = np.array([0, 2, 1, 0, 1, 2])\n    balanced = balanced_accuracy_score(y_true, y_pred)\n    expected_balanced = (1/3 + 1/3 + 1/3) / 3\n    assert balanced == pytest.approx(expected_balanced)\n"], "sample_253": ["def test_extra_files(self, mocked_modules, notify_mock):\n    extra_file = self.ensure_file(self.tempdir / 'extra_file.py')\n    self.reloader.extra_files.add(extra_file)\n    with self.tick_twice():\n        self.increment_mtime(extra_file)\n    self.assertEqual(notify_mock.call_count, 1)\n    self.assertCountEqual(notify_mock.call_args[0], [extra_file])\n"], "sample_246": ["    def test_no_obsolete_enabled(self):\n        management.call_command('makemessages', locale=[LOCALE], verbosity=0, no_obsolete=True)\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertNotIn('#~ msgid \"Obsolete message\"', po_contents)\n"], "sample_796": ["def test_huber_epsilon_validation():\n    # Test that an error is raised when epsilon is less than 1.0\n    X, y = make_regression_with_outliers()\n    with pytest.raises(ValueError, match=\"epsilon should be greater than or equal to 1.0, got\"):\n        huber = HuberRegressor(epsilon=0.9)\n        huber.fit(X, y)\n"], "sample_35": ["def test_isinstancemethod():\n    class MyClass:\n\n        @classmethod\n\n        @staticmethod\n\n    assert isinstancemethod(MyClass, MyClass.an_instancemethod)\n    assert not isinstancemethod(MyClass, MyClass.a_classmethod)\n    assert not isinstancemethod(MyClass, MyClass.a_staticmethod)\n"], "sample_913": ["def test_pyfunction_signature_with_annotation(app):\n    text = \".. py:function:: hello(name: str) -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_punctuation, \":\"],\n                                                      \" \",\n                                                      [nodes.inline, pending_xref, \"str\"])])\n    assert_node(doctree[1][0][2],\n                [desc_returns, pending_xref, \"str\"])\n"], "sample_508": ["def test_artist_update():\n    # Test the update method of the Artist class\n    artist = martist.Artist()\n    props = {'alpha': 0.5, 'visible': False, 'zorder': 10}\n    artist.update(props)\n    assert artist.get_alpha() == 0.5\n    assert artist.get_visible() == False\n    assert artist.get_zorder() == 10\n"], "sample_865": ["def test_prune_tree_raises_not_fitted():\n    clf = DecisionTreeClassifier()\n    msg = \"This DecisionTreeClassifier instance is not fitted yet\"\n\n    with pytest.raises(NotFittedError, match=msg):\n        clf._prune_tree()\n"], "sample_941": ["def test_restify_type_hints_NewType():\n    assert restify(MyInt) == \":class:`MyInt`\"\n"], "sample_109": ["def test_render_options_with_custom_choices(self):\n    beatles = Band.objects.create(name='The Beatles', style='rock')\n    who = Band.objects.create(name='The Who', style='rock')\n    choices = [(beatles.pk, 'Fab Four'), (who.pk, 'The Who')]\n    form = forms.Form({\n        'band': beatles.pk,\n    }, widgets={\n        'band': AutocompleteSelect(\n            Album._meta.get_field('band').remote_field,\n            admin.site,\n            choices=choices,\n        ),\n    })\n    output = form.as_table()\n    selected_option = '<option value=\"%s\" selected>Fab Four</option>' % beatles.pk\n    option = '<option value=\"%s\">The Who</option>' % who.pk\n    self.assertIn(selected_option, output)\n    self.assertNotIn(option, output)\n"], "sample_380": ["def test_aggregation_default_with_filter(self):\n    result = Book.objects.filter(rating__gt=4.0).aggregate(\n        value=Sum('price', default=Decimal('0.00'), filter=Q(pages__gt=300)),\n    )\n    self.assertEqual(result['value'], Decimal('75.00'))\n"], "sample_615": ["def test_cross_errors(use_dask):\n    a = xr.DataArray([1, 2, 3], dims=[\"dim_0\"])\n    b = xr.DataArray([4, 5, 6], dims=[\"dim_1\"])\n\n    if use_dask:\n        if not has_dask:\n            pytest.skip(\"test for dask.\")\n        a = a.chunk()\n        b = b.chunk()\n\n    with pytest.raises(ValueError, match=\"Dimension 'dim_0' not on b\"):\n        xr.cross(a, b, dim=\"dim_0\")\n\n    with pytest.raises(ValueError, match=\"Dimension 'dim_1' not on a\"):\n        xr.cross(a, b, dim=\"dim_1\")\n\n    a = xr.DataArray([1, 2], dims=[\"dim_0\"])\n    b = xr.DataArray([4, 5, 6], dims=[\"dim_0\"])\n\n    with pytest.raises(ValueError, match=\"The size of 'dim_0' on a must be 1, 2, or 3 to be compatible with a cross product but is 2\"):\n        xr.cross(a, b, dim=\"dim_0\")\n\n    a = xr.DataArray([1, 2, 3], dims=[\"dim_0\"])\n    b = xr.DataArray([4, 5], dims=[\"dim_0\"])\n\n    with pytest.raises(ValueError, match=\"The size of 'dim_0' on b must be 1, 2, or 3 to be compatible with a cross product but is 2\"):\n        xr.cross(a, b, dim=\"dim_0\")\n\n    a = xr.DataArray([1, 2, 3, 4], dims=[\"dim_0\"])\n    b = xr.DataArray([4, 5, 6, 7], dims=[\"dim_0\"])\n\n    with"], "sample_605": ["def test_groupby_first_last(array):\n    grouped = array.groupby(\"y\")\n    assert_identical(array.isel(y=0), grouped.first())\n    assert_identical(array.isel(y=-1), grouped.last())\n"], "sample_628": ["def test_docstring_lines_that_look_like_comments_7(self):\n    stmt = astroid.extract_node(\n        '''def f():\n    \"\"\"\n    # msitake\n    cat\n    \"\"\"'''\n    )\n    with self.assertAddsMessages(\n        Message(\n            \"wrong-spelling-in-docstring\",\n            line=3,\n            args=(\n                \"msitake\",\n                \"# msitake\",\n                \"  ^^^^^^^\",\n                self._get_msg_suggestions(\"msitake\"),\n            ),\n        )\n    ):\n        self.checker.visit_functiondef(stmt)\n"], "sample_583": ["def test_posify_mask_indexer():\n    indexer = indexing.OuterIndexer((np.array([0, -1, 2]),))\n    expected = indexing.OuterIndexer((np.array([0, 0, 2]),))\n    actual = indexing.posify_mask_indexer(indexer)\n    np.testing.assert_array_equal(expected.tuple, actual.tuple)\n\n    indexer = indexing.VectorizedIndexer(\n        (np.array([0, -1, 2]), np.array([0, 1, -1])))\n    expected = indexing.VectorizedIndexer(\n        (np.array([0, 0, 2]), np.array([0, 1, 1])))\n    actual = indexing.posify_mask_indexer(indexer)\n    np.testing.assert_array_equal(expected.tuple, actual.tuple)\n"], "sample_170": ["def test_sensitive_variables_decorator_with_args(self):\n    \"\"\"\n    The sensitive_variables decorator works with arguments.\n    \"\"\"\n    with self.settings(DEBUG=True):\n        self.verify_unsafe_response(sensitive_args_function_caller)\n        self.verify_unsafe_email(sensitive_args_function_caller)\n\n    with self.settings(DEBUG=False):\n        self.verify_safe_response(sensitive_args_function_caller, check_for_POST_params=False)\n        self.verify_safe_email(sensitive_args_function_caller, check_for_POST_params=False)\n"], "sample_241": ["def test_expression_wrapper_with_none_output_field(self):\n    value = Value('f')\n    value.output_field = None\n    expr = ExpressionWrapper(Lower(value))\n    msg = 'ExpressionWrapper requires an output_field.'\n    with self.assertRaisesMessage(FieldError, msg):\n        expr.get_group_by_cols(alias=None)\n"], "sample_772": ["def test_max_features_auto():\n    X, y = datasets.make_classification(n_samples=100, n_features=20, n_informative=10, random_state=42)\n    all_estimators = [RandomForestClassifier, RandomForestRegressor, ExtraTreesClassifier, ExtraTreesRegressor]\n\n    for Estimator in all_estimators:\n        est = Estimator(max_features='auto')\n        est.fit(X, y)\n        for tree in est.estimators_:\n            assert_equal(tree.max_features, 'auto')\n"], "sample_1097": ["def test_BlockMatrix_as_real_imag():\n    A, B, C, D = [MatrixSymbol(s, 3, 3) for s in 'ABCD']\n    X = BlockMatrix([[A, B], [C, D]])\n    real_X, imag_X = X.as_real_imag()\n    assert real_X == BlockMatrix([[re(A), re(B)], [re(C), re(D)]])\n    assert imag_X == BlockMatrix([[im(A), im(B)], [im(C), im(D)]])\n"], "sample_1187": ["def test_hyperplane_parameters():\n    triangle = Polygon(Point(0, 3), Point(5, 3), Point(1, 1))\n    assert hyperplane_parameters(triangle) == [((0, 1), 3), ((1, -2), -1), ((-2, -1), -3)]\n\n    cube = [[(0, 0, 0), (0, 0, 5), (0, 5, 0), (0, 5, 5), (5, 0, 0),\n             (5, 0, 5), (5, 5, 0), (5, 5, 5)],\n            [2, 6, 7, 3], [3, 7, 5, 1], [7, 6, 4, 5], [1, 5, 4, 0],\n            [3, 1, 0, 2], [0, 4, 6, 2]]\n    assert hyperplane_parameters(cube[1:], cube[0]) == [([0, -1, 0], -5), ([0, 0, -1], -5),\n                                                       ([-1, 0, 0], -5), ([0, 1, 0], 0),\n                                                       ([1, 0, 0], 0), ([0, 0, 1], 0)]\n"], "sample_322": ["def test_minimize_rollbacks_multiple_targets(self):\n    r\"\"\"\n    Minimize rollbacks when targeting multiple migrations.\n\n    a: 1 <---- 3 <--\\\n              \\ \\- 2 <--- 4\n               \\       \\\n    b:      \\- 1 <--- 2\n    \"\"\"\n    a1_impl = FakeMigration('a1')\n    a1 = ('a', '1')\n    a2_impl = FakeMigration('a2')\n    a2 = ('a', '2')\n    a3_impl = FakeMigration('a3')\n    a3 = ('a', '3')\n    a4_impl = FakeMigration('a4')\n    a4 = ('a', '4')\n    b1_impl = FakeMigration('b1')\n    b1 = ('b', '1')\n    b2_impl = FakeMigration('b2')\n    b2 = ('b', '2')\n    graph = MigrationGraph()\n    graph.add_node(a1, a1_impl)\n    graph.add_node(a2, a2_impl)\n    graph.add_node(a3, a3_impl)\n    graph.add_node(a4, a4_impl)\n    graph.add_node(b1, b1_impl)\n    graph.add_node(b2, b2_impl)\n    graph.add_dependency(None, a2, a1)\n    graph.add_dependency(None, a3, a1)\n    graph.add_dependency(None, a4, a2)\n    graph.add_dependency(None, a4, a3)\n    graph.add_dependency(None, b2, b1)\n    graph.add_dependency(None, b1, a1)\n    graph.add_dependency(None, b2, a2)\n\n    executor = MigrationExecutor(None)\n    executor.loader = FakeLoader(graph, {\n        a1: a1_impl,\n        b1: b1_impl,\n        a2: a2_impl,"], "sample_912": ["def test_pyclass_signature(app):\n    text = \".. py:class:: Class\\n\"\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_name, \"Class\"])],\n                                  [desc_content, ()])]))\n    assert 'Class' in domain.objects\n    assert domain.objects['Class'] == ('index', 'class', 'class')\n"], "sample_155": ["def test_file_from_buffer_with_filename(self):\n    response = FileResponse(io.BytesIO(b'binary content'), filename='example.txt')\n    self.assertEqual(response['Content-Length'], '14')\n    self.assertEqual(response['Content-Type'], 'text/plain')\n    self.assertEqual(response['Content-Disposition'], 'inline; filename=\"example.txt\"')\n    self.assertEqual(list(response), [b'binary content'])\n"], "sample_625": ["def test_cross_different_dimensions(a, b, ae, be, dim: str, axis: int, use_dask: bool) -> None:\n    expected = np.cross(ae, be, axis=axis)\n\n    if use_dask:\n        if not has_dask:\n            pytest.skip(\"test for dask.\")\n        a = a.chunk()\n        b = b.chunk()\n\n    actual = xr.cross(a, b, dim=dim)\n    xr.testing.assert_duckarray_allclose(expected, actual)\n"], "sample_137": ["    def test_replace_named_groups(self):\n        from django.contrib.admindocs.utils import replace_named_groups\n        self.assertEqual(replace_named_groups(r'^(?P<a>\\w+)/b/(\\w+)$'), r'^<a>/b/(\\w+)$')\n        self.assertEqual(replace_named_groups(r'^(?P<a>\\w+)/b/(?P<c>\\w+)/$'), r'^<a>/b/<c>/$')\n        self.assertEqual(replace_named_groups(r'^(?P<a>\\w+)/b/(\\w+)'), r'^<a>/b/(\\w+)')\n        self.assertEqual(replace_named_groups(r'^(?P<a>\\w+)/b/(?P<c>\\w+)'), r'^<a>/b/<c>')\n"], "sample_125": ["def test_set_cookie_with_path_and_domain(self):\n    \"\"\"set_cookie() accepts path and domain parameters.\"\"\"\n    response = HttpResponse()\n    response.set_cookie('example', path='/path', domain='example.com')\n    example_cookie = response.cookies['example']\n    self.assertEqual(example_cookie['path'], '/path')\n    self.assertEqual(example_cookie['domain'], 'example.com')\n"], "sample_457": ["def test_validate_expression_exclude(self):\n    constraint = models.UniqueConstraint(Lower(\"name\"), name=\"name_lower_uniq\")\n    p3 = UniqueConstraintProduct.objects.create(name=\"ANOTHER-NAME\")\n    # Excluded fields in expressions are ignored.\n    constraint.validate(\n        UniqueConstraintProduct,\n        UniqueConstraintProduct(name=p3.name.upper()),\n        exclude={\"name\"},\n    )\n"], "sample_67": ["    def test_exclude_many_to_many(self):\n        \"\"\"ManyToManyField can be excluded from model_to_dict.\"\"\"\n        blue = Colour.objects.create(name='blue')\n        item = ColourfulItem.objects.create()\n        item.colours.set([blue])\n        data = model_to_dict(item, exclude=['colours'])\n        self.assertNotIn('colours', data)\n"], "sample_627": ["def test_concat_index_not_same_length() -> None:\n    ds1 = Dataset(coords={\"x\": (\"x\", [1, 2])})\n    ds2 = Dataset(coords={\"x\": (\"x\", [3, 4, 5])})\n\n    with pytest.raises(\n        ValueError,\n        match=r\"Cannot concatenate along dimension 'x' indexes with different lengths.*\",\n    ):\n        concat([ds1, ds2], dim=\"x\")\n"], "sample_606": ["def test_cross_errors(use_dask):\n    a = xr.DataArray(\n        [1, 2, 3],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    b = xr.DataArray(\n        [4, 5, 6],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    if use_dask:\n        if not has_dask:\n            pytest.skip(\"test for dask.\")\n        a = a.chunk()\n        b = b.chunk()\n\n    with pytest.raises(ValueError, match=\"Dimension 'time' not on a\"):\n        xr.cross(a, b, dim=\"time\")\n\n    with pytest.raises(ValueError, match=\"Dimension 'time' not on b\"):\n        xr.cross(b, a, dim=\"time\")\n\n    a = xr.DataArray(\n        [1, 2],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\"])),\n    )\n    b = xr.DataArray(\n        [4, 5, 6],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    if use_dask:\n        a = a.chunk()\n        b = b.chunk()\n\n    with pytest.raises(ValueError, match=\"The size of 'cartesian' on a must be 1, 2, or 3 to be compatible with a cross product but is 2\"):\n        xr.cross(a, b, dim=\"cartesian\")\n\n    with pytest.raises(ValueError, match=\"The size of 'cartesian' on b must be 1, 2, or 3 to be compatible with a cross product but is"], "sample_867": ["def test_search_cv_with_precomputed_kernel():\n    # Test that search cv works when the input features are given in the\n    # form of a precomputed kernel matrix\n    X_, y_ = make_classification(n_samples=200, n_features=100, random_state=0)\n\n    # compute the training kernel matrix corresponding to the linear kernel\n    K_train = np.dot(X_[:180], X_[:180].T)\n    y_train = y_[:180]\n\n    clf = SVC(kernel='precomputed')\n    cv = GridSearchCV(clf, {'C': [0.1, 1.0]})\n    cv.fit(K_train, y_train)\n\n    assert cv.best_score_ >= 0\n\n    # compute the test kernel matrix\n    K_test = np.dot(X_[180:], X_[:180].T)\n    y_test = y_[180:]\n\n    y_pred = cv.predict(K_test)\n\n    assert np.mean(y_pred == y_test) >= 0\n\n    # test error is raised when the precomputed kernel is not array-like\n    # or sparse\n    assert_raises(ValueError, cv.fit, K_train.tolist(), y_train)\n"], "sample_178": ["def test_formset_with_custom_prefix(self):\n    \"\"\"The management form has the correct prefix when a custom prefix is used.\"\"\"\n    formset = FavoriteDrinksFormSet(prefix='custom')\n    self.assertEqual(formset.management_form.prefix, 'custom')\n    data = {\n        'custom-TOTAL_FORMS': '2',\n        'custom-INITIAL_FORMS': '0',\n        'custom-MIN_NUM_FORMS': '0',\n        'custom-MAX_NUM_FORMS': '0',\n    }\n    formset = FavoriteDrinksFormSet(data=data, prefix='custom')\n    self.assertEqual(formset.management_form.prefix, 'custom')\n    formset = FavoriteDrinksFormSet(initial={}, prefix='custom')\n    self.assertEqual(formset.management_form.prefix, 'custom')\n"], "sample_1124": ["def test_FracElement_to_poly():\n    F, x, y = field(\"x,y\", ZZ)\n    f = x / y\n    assert f.to_poly() == x * y**(-1)\n\n    g = x * y\n    with raises(ValueError):\n        g.to_poly()\n"], "sample_100": ["def test_watch_dir_with_unresolvable_path_in_glob(self, mocked_modules, notify_mock):\n    path = Path('unresolvable_directory')\n    with mock.patch.object(Path, 'glob', side_effect=FileNotFoundError):\n        self.reloader.watch_dir(path, '**/*.mo')\n    self.assertEqual(list(self.reloader.directory_globs), [])\n"], "sample_755": ["def test_silhouette_sparse_input():\n    # Test silhouette_score and silhouette_samples with sparse input\n    X_csr = csr_matrix([[0, 0], [1, 1], [2, 2], [3, 3]])\n    labels = [0, 0, 1, 1]\n\n    # Test silhouette_score with sparse input\n    score_csr = silhouette_score(X_csr, labels, metric='euclidean')\n    score_dense = silhouette_score(X_csr.toarray(), labels, metric='euclidean')\n    pytest.approx(score_csr, score_dense)\n\n    # Test silhouette_samples with sparse input\n    samples_csr = silhouette_samples(X_csr, labels, metric='euclidean')\n    samples_dense = silhouette_samples(X_csr.toarray(), labels, metric='euclidean')\n    assert_array_equal(samples_csr, samples_dense)\n"], "sample_879": ["def test_ordinal_encoder_missing_unknown_encoding_min():\n    \"\"\"Check missing value or unknown encoding can equal the minimum cardinality.\"\"\"\n    X = np.array([[\"dog\"], [\"cat\"], [np.nan]], dtype=object)\n    X_trans = OrdinalEncoder(encoded_missing_value=-1).fit_transform(X)\n    assert_allclose(X_trans, [[1], [0], [-1]])\n\n    enc = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1).fit(X)\n    X_test = np.array([[\"snake\"]])\n    X_trans = enc.transform(X_test)\n    assert_allclose(X_trans, [[-1]])\n"], "sample_335": ["def test_decimalfield_invalid_input(self):\n    f = DecimalField(max_digits=4, decimal_places=2)\n    with self.assertRaisesMessage(ValidationError, \"'Enter a number.'\"):\n        f.clean('invalid')\n"], "sample_222": ["    def test_lock_unlock_with_file_object(self):\n        with tempfile.NamedTemporaryFile() as temp_file:\n            with open(temp_file.name, 'wb') as f:\n                self.assertIs(locks.lock(f, locks.LOCK_EX), True)\n                self.assertIs(locks.unlock(f), True)\n"], "sample_392": ["def test_key_transform_expression_wrapper(self):\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.annotate(\n            expr=ExpressionWrapper(\n                KeyTransform(\"c\", \"value\"),\n                output_field=IntegerField(),\n            ),\n        ).filter(expr__gt=10),\n        [self.objs[3], self.objs[4]],\n    )\n"], "sample_1109": ["def test_frac_with_complex_arguments():\n    assert frac(I*r) == I*frac(r)\n    assert frac(1 + I*r) == I*frac(r)\n    assert frac(0.5 + I*r) == 0.5 + I*frac(r)\n    assert frac(n + I*r) == I*frac(r)\n    assert frac(n + I*k) == 0\n    assert unchanged(frac, x + I*x)\n    assert frac(x + I*n) == frac(x)\n"], "sample_310": ["def test_model_detail_with_custom_field(self):\n    class CustomField(models.Field):\n        description = \"A custom field type\"\n\n    class CustomModel(models.Model):\n        custom_field = CustomField()\n\n    with self.settings(INSTALLED_APPS=['admin_docs']):\n        response = self.client.get(reverse('django-admindocs-models-detail', args=['admin_docs', 'custommodel']))\n        self.assertContains(response, '<td>custom_field</td>')\n        self.assertContains(response, '<td>A custom field type</td>')\n"], "sample_1053": ["def test_Float_floordiv():\n    assert Float(2.5)//Float(0.5) == 5.0\n    assert Float(2.5)//Float(1.5) == 1.0\n    assert Float(2.5)//Float(2.5) == 1.0\n    assert Float(2.5)//Float(3.5) == 0.0\n    assert Float(2.5)//Float(-0.5) == -5.0\n    assert Float(2.5)//Float(-1.5) == -2.0\n    assert Float(2.5)//Float(-2.5) == -1.0\n    assert Float(2.5)//Float(-3.5) == -1.0\n"], "sample_1129": ["def test_log2():\n    from sympy import log\n\n    expr = log(x, 2)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr) == 'numpy.log2(x)'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr) == 'numpy.log(x)/numpy.log(2)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr) == 'math.log(x)/math.log(2)'\n\n    prntr = MpmathPrinter()\n    assert prntr.doprint(expr) == 'mpmath.log(x, 2)'\n"], "sample_528": ["def test_context_with_after_reset():\n    original_value = 'gray'\n    other_value = 'blue'\n    mpl.rcParams[PARAM] = original_value\n    with temp_style('test', DUMMY_SETTINGS):\n        with style.context('test', after_reset=True):\n            assert mpl.rcParams[PARAM] == VALUE\n    # Check that this value is reset after the exiting the context.\n    assert mpl.rcParams[PARAM] == original_value\n"], "sample_700": ["def test_xfail_imperative_in_teardown_function(self, pytester: Pytester) -> None:\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest\n            pytest.xfail(\"hello\")\n\n            assert 0\n    \"\"\"\n    )\n    result = pytester.runpytest(p)\n    result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n    result = pytester.runpytest(p, \"-rx\")\n    result.stdout.fnmatch_lines([\"*XFAIL*test_this*\", \"*reason:*hello*\"])\n    result = pytester.runpytest(p, \"--runxfail\")\n    result.stdout.fnmatch_lines(\n        \"\"\"\n        *def test_this*\n        *1 fail*\n    \"\"\"\n    )\n"], "sample_248": ["def test_shell_with_ipython_installed(self, select):\n    select.return_value = ([], [], [])\n    call_command('shell', interface='ipython')\n    IPython.start_ipython.assert_called_once_with(argv=[])\n"], "sample_519": ["def test_figure_pickle():\n    fig1 = plt.figure()\n    ax1 = fig1.add_subplot(111)\n    ax1.plot([0, 1], [2, 3])\n    ax1.set_yscale('log')\n\n    fig1_pickled = pickle.dumps(fig1)\n    fig2 = pickle.loads(fig1_pickled)\n\n    # Make sure it is a new object\n    assert fig2.axes[0] is not ax1\n    # And that the axis scale got propagated\n    assert fig2.axes[0].get_yscale() == 'log'\n    # Update the deepcopy and check the original isn't modified\n    fig2.axes[0].set_yscale('linear')\n    assert ax1.get_yscale() == 'log'\n\n    # And test the limits of the axes don't get propagated\n    ax1.set_xlim(1e-1, 1e2)\n    # Draw these to make sure limits are updated\n    fig1.draw_without_rendering()\n    fig2.draw_without_rendering()\n\n    assert ax1.get_xlim() == (1e-1, 1e2)\n    assert fig2.axes[0].get_xlim() == (0, 1)\n"], "sample_1163": ["def test_issue_15893_complex():\n    f = Function('f', complex=True)\n    x = Symbol('x', real=True)\n    eq = Derivative(Abs(f(x)), f(x))\n    assert eq.doit() == sign(f(x)) * conjugate(f(x)) / Abs(f(x))\n"], "sample_747": ["def test_power_transformer_yeo_johnson():\n    X = np.abs(X_2d)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method='yeo-johnson', standardize=standardize)\n\n        X_trans_class = pt.fit_transform(X)\n        X_trans_func = power_transform(X, method='yeo-johnson', standardize=standardize)\n\n        for X_trans in [X_trans_class, X_trans_func]:\n            for j in range(X_trans.shape[1]):\n                X_expected, lmbda = stats.yeojohnson(X[:, j].flatten())\n\n                if standardize:\n                    X_expected = scale(X_expected)\n\n                assert_almost_equal(X_trans[:, j], X_expected)\n                assert_almost_equal(lmbda, pt.lambdas_[j])\n\n            # Test inverse transformation\n            X_inv = pt.inverse_transform(X_trans)\n            assert_array_almost_equal(X_inv, X)\n\n        assert len(pt.lambdas_) == X.shape[1]\n        assert isinstance(pt.lambdas_, np.ndarray)\n"], "sample_1021": ["def test_quaternion_multiplication():\n    q1 = Quaternion(1, 2, 3, 4)\n    q2 = Quaternion(5, 6, 7, 8)\n\n    assert q1 * q2 == Quaternion(-60, 12, 30, 24)\n    assert q1 * 2 == Quaternion(2, 4, 6, 8)\n    assert 2 * q1 == Quaternion(2, 4, 6, 8)\n\n    q3 = Quaternion(3 + 4*I, 2 + 5*I, 0, 7 + 8*I, real_field = False)\n    q4 = Quaternion(1, 4, 7, 8)\n\n    assert q3 * q4 == Quaternion(-10, 11, 38, -5)\n    assert q4 * q3 == Quaternion(-10, 11, 38, -5)\n    assert q3 * (2 + 3*I) == Quaternion((2 + 3*I)*(3 + 4*I), (2 + 3*I)*(2 + 5*I), 0, (2 + 3*I)*(7 + 8*I))\n"], "sample_641": ["def test_save_results_oserror(path: str, linter_stats: LinterStats, monkeypatch) -> None:\n        raise OSError(\"Mock OSError\")\n\n    monkeypatch.setattr(\"builtins.open\", mock_open)\n    save_results(linter_stats, path)\n"], "sample_104": ["def test_template_tag_non_ascii(self):\n    relpath = self.hashed_file_path(\"test/nonascii.css\")\n    self.assertEqual(relpath, \"test/nonascii.1234567890ab.css\")\n    with storage.staticfiles_storage.open(relpath) as relfile:\n        content = relfile.read()\n        self.assertNotIn(b\"test/nonascii.png\", content)\n        self.assertIn(b\"nonascii.1234567890ab.png\", content)\n    self.assertPostCondition()\n"], "sample_894": ["def test_max_samples_float_boundary():\n    X_train, X_test, y_train, y_test = train_test_split(\n        X_reg, y_reg, train_size=0.7, test_size=0.3, random_state=0\n    )\n\n    ms_0_model = RandomForestRegressor(\n        bootstrap=True, max_samples=0.0, random_state=0\n    )\n    ms_0_predict = ms_0_model.fit(X_train, y_train).predict(X_test)\n\n    ms_1_model = RandomForestRegressor(\n        bootstrap=True, max_samples=1.0, random_state=0\n    )\n    ms_1_predict = ms_1_model.fit(X_train, y_train).predict(X_test)\n\n    ms_0_ms = mean_squared_error(ms_0_predict, y_test)\n    ms_1_ms = mean_squared_error(ms_1_predict, y_test)\n\n    assert ms_0_ms == pytest.approx(ms_1_ms)\n"], "sample_51": ["    def test_parse_datetime_invalid_tzinfo(self):\n        # Invalid timezone offsets\n        with self.assertRaises(ValueError):\n            parse_datetime('2012-04-23T09:15:00+2400')\n        with self.assertRaises(ValueError):\n            parse_datetime('2012-04-23T09:15:00-2400')\n        with self.assertRaises(ValueError):\n            parse_datetime('2012-04-23T09:15:00+24')\n        with self.assertRaises(ValueError):\n            parse_datetime('2012-04-23T09:15:00-24')\n        with self.assertRaises(ValueError):\n            parse_datetime('2012-04-23T09:15:00+90')\n        with self.assertRaises(ValueError):\n            parse_datetime('2012-04-23T09:15:00-90')\n"], "sample_355": ["    def setUpTestData(cls):\n        cls.user = CustomUser.objects.create_user(\n            email='test@example.com',\n            password='test',\n            date_of_birth=date(2006, 4, 25)\n        )\n        cls.superuser = CustomUser.objects.create_superuser(\n            email='test2@example.com',\n            password='test',\n            date_of_birth=date(1976, 11, 8)\n        )\n"], "sample_461": ["def test_urlfield_clean_with_assume_scheme(self):\n    f = URLField(assume_scheme=\"https\")\n    self.assertEqual(f.clean(\"example.com\"), \"https://example.com\")\n    self.assertEqual(f.clean(\"http://example.com\"), \"http://example.com\")\n    self.assertEqual(f.clean(\"https://example.com\"), \"https://example.com\")\n"], "sample_22": ["def test_matrix_transpose():\n    \"\"\"Test the matrix transpose function ``matrix_transpose``.\"\"\"\n    # Normal 2D matrix\n    m1 = np.array([[1, 2], [3, 4]])\n    assert_array_equal(matrix_transpose(m1), np.array([[1, 3], [2, 4]]))\n    # and (M, 2, 2)\n    n1 = np.tile(m1, (2, 1, 1))\n    assert_array_equal(matrix_transpose(n1), np.tile(np.array([[1, 3], [2, 4]]), (2, 1, 1)))\n\n    # Non-square matrix\n    m2 = np.array([[1, 2, 3], [4, 5, 6]])\n    assert_array_equal(matrix_transpose(m2), np.array([[1, 4], [2, 5], [3, 6]]))\n    # and (M, 2, 3)\n    n2 = np.tile(m2, (2, 1, 1))\n    assert_array_equal(matrix_transpose(n2), np.tile(np.array([[1, 4], [2, 5], [3, 6]]), (2, 1, 1)))\n"], "sample_375": ["def test_abstract_model_children_inherit_constraints(self):\n    class Abstract(models.Model):\n        size = models.IntegerField()\n\n        class Meta:\n            app_label = 'migrations'\n            abstract = True\n            constraints = [models.CheckConstraint(check=models.Q(size__gt=1), name='size_gt_1')]\n\n    class Child1(Abstract):\n        pass\n\n    class Child2(Abstract):\n        pass\n\n    child1_state = ModelState.from_model(Child1)\n    child2_state = ModelState.from_model(Child2)\n    constraint_names = [constraint.name for constraint in child1_state.options['constraints']]\n    self.assertEqual(constraint_names, ['size_gt_1'])\n    constraint_names = [constraint.name for constraint in child2_state.options['constraints']]\n    self.assertEqual(constraint_names, ['size_gt_1'])\n\n    # Modifying the state doesn't modify the constraint on the model.\n    child1_state.options['constraints'][0].name = 'bar'\n    self.assertEqual(Child1._meta.constraints[0].name, 'size_gt_1')\n"], "sample_539": ["def test_polygon_selector_box_handle_props(ax):\n    # Create a diamond shape\n    verts = [(20, 0), (0, 20), (20, 40), (40, 20)]\n    event_sequence = [\n        *polygon_place_vertex(*verts[0]),\n        *polygon_place_vertex(*verts[1]),\n        *polygon_place_vertex(*verts[2]),\n        *polygon_place_vertex(*verts[3]),\n        *polygon_place_vertex(*verts[0]),\n    ]\n\n    # Create selector with custom box handle properties\n    tool = widgets.PolygonSelector(ax, onselect=noop, draw_bounding_box=True,\n                                   box_handle_props={'color': 'red', 'size': 10})\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n\n    # Check that the box handles have the correct properties\n    for handle in tool._box._corner_handles.artists:\n        assert handle.get_color() == 'red'\n        assert handle.get_size() == 10\n"], "sample_220": ["def test_delete_cookie_with_path_and_domain(self):\n    \"\"\"delete_cookie() accepts path and domain arguments.\"\"\"\n    response = HttpResponse()\n    response.delete_cookie('c', path='/path/', domain='example.com')\n    cookie = response.cookies['c']\n    self.assertEqual(cookie['path'], '/path/')\n    self.assertEqual(cookie['domain'], 'example.com')\n"], "sample_1128": ["def test_point_vel_with_connected_frames_and_different_vel_definitions():\n    t = dynamicsymbols._t\n    q, q1, q2, u1, u2 = dynamicsymbols('q q1 q2 u1 u2')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    O = Point('O')\n    O.set_vel(N, u1 * N.x)\n    P = Point('P')\n    P.set_pos(O, q1 * N.x + q2 * B.y)\n    P.set_vel(B, u2 * B.z)\n    N.orient(B, 'Axis', (q, B.x))\n    assert P.vel(N) == (u1 + q1.diff(t)) * N.x + q2.diff(t) * B.y + u2 * B.z - q2 * q.diff(t) * B.x\n"], "sample_763": ["def test_check_X_y_multi_output():\n    X = np.ones((2, 2))\n    y = np.array([[1, 2], [3, 4]])\n    X_checked, y_checked = check_X_y(X, y, multi_output=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    y_1d = np.array([1, 2])\n    assert_raises(ValueError, check_X_y, X, y_1d, multi_output=True)\n"], "sample_1067": ["def test_issue_6421():\n    x = Symbol('x')\n    a = Wild('a')\n    assert (I*x).match(a*I) == {a: x}\n    assert (x*I).match(a*I) == {a: x}\n    assert (-I*x).match(a*I) == {a: -x}\n    assert (-x*I).match(a*I) == {a: -x}\n"], "sample_207": ["def test_key_transform_exact(self):\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__d__1__f__exact='g'),\n        [self.objs[4]],\n    )\n"], "sample_943": ["def test_pep_0420_enabled_separate_private(make_app, apidoc):\n    outdir = apidoc.outdir\n    assert (outdir / 'conf.py').isfile()\n    assert (outdir / 'a.b.c.rst').isfile()\n    assert (outdir / 'a.b.e.rst').isfile()\n    assert (outdir / 'a.b.e.f.rst').isfile()\n    assert (outdir / 'a.b.x.rst').isfile()\n    assert (outdir / 'a.b.x.y.rst').isfile()\n    assert (outdir / 'a.b._private.rst').isfile()\n\n    with open(outdir / 'a.b.c.rst') as f:\n        rst = f.read()\n        assert \".. toctree::\\n   :maxdepth: 4\\n\\n   a.b.c.d\\n\" in rst\n\n    with open(outdir / 'a.b.e.rst') as f:\n        rst = f.read()\n        assert \".. toctree::\\n   :maxdepth: 4\\n\\n   a.b.e.f\\n\" in rst\n\n    with open(outdir / 'a.b.x.rst') as f:\n        rst = f.read()\n        assert \".. toctree::\\n   :maxdepth: 4\\n\\n   a.b.x.y\\n\" in rst\n\n    with open(outdir / 'a.b._private.rst') as f:\n        rst = f.read()\n        assert \"a.b._private module\\n\" in rst\n        assert \":private-members:\" in rst\n\n    app = make_app('text', srcdir=outdir)\n    app.build"], "sample_498": ["def test_legend_markers_from_line2d_with_no_marker():\n    # Test that markers can be copied for legend lines even when no marker is specified\n    fig, ax = plt.subplots()\n    lines = [mlines.Line2D([0], [0], ls='-')]\n    labels = [\"line\"]\n    legend = ax.legend(lines, labels)\n\n    new_markers = [line.get_marker() for line in legend.get_lines()]\n    new_labels = [text.get_text() for text in legend.get_texts()]\n\n    assert new_markers == ['None']\n    assert labels == new_labels\n"], "sample_517": ["def test_text_rotation_mode():\n    fig, ax = plt.subplots()\n    text = ax.text(0.5, 0.5, 'test', rotation=45, rotation_mode='anchor')\n    fig.canvas.draw()\n    assert text.get_rotation_mode() == 'anchor'\n    assert text.get_rotation() == 45\n\n    text.set_rotation_mode('default')\n    fig.canvas.draw()\n    assert text.get_rotation_mode() == 'default'\n    assert text.get_rotation() == 45\n"], "sample_703": ["def test_complex_expressions(expr: str) -> None:\n    matcher = {\"true\": True, \"false\": False}.__getitem__\n    assert evaluate(expr, matcher)\n"], "sample_677": ["def test_complex_expressions(expr: str, expected: bool) -> None:\n    matcher = {\"True\": True, \"False\": False}.__getitem__\n    assert evaluate(expr, matcher) is expected\n"], "sample_376": ["def test_store_empty_messages(self):\n    \"\"\"\n    If no messages are provided, the cookie is deleted.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # Set initial data.\n    example_messages = ['test', 'me']\n    set_cookie_data(storage, example_messages)\n\n    # Store empty messages.\n    storage._store([], response)\n\n    # The cookie should be deleted.\n    self.assertNotIn(storage.cookie_name, response.cookies)\n"], "sample_185": ["def test_get_language_bidi_null(self):\n    self.assertIs(trans_null.get_language_bidi(), False)\n    with override_settings(LANGUAGE_CODE='he'):\n        self.assertIs(get_language_bidi(), True)\n"], "sample_405": ["def test_references_field_by_limit_choices_to(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ForeignKey(\n            \"Other\",\n            models.CASCADE,\n            limit_choices_to={\"field\": \"value\"},\n        ),\n    )\n    self.assertIs(operation.references_field(\"Other\", \"field\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Other\", \"whatever\", \"migrations\"), False)\n    self.assertIs(operation.references_field(\"Missing\", \"whatever\", \"migrations\"), False)\n"], "sample_707": ["def test_node_add_marker(pytester: Pytester) -> None:\n    \"\"\"\n    Test adding a marker to a node.\n    \"\"\"\n    items = pytester.getitems(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.foo\n            pass\n    \"\"\"\n    )\n    item = items[0]\n    item.add_marker(\"bar\")\n    assert item.get_closest_marker(\"bar\") is not None\n    assert item.get_closest_marker(\"foo\") is not None\n"], "sample_1014": ["def test_mutable_ndim_array():\n    from sympy import MutableDenseNDimArray\n\n    # Testing MutableDenseNDimArray initialization\n    arr = MutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    assert arr.shape == (2, 2)\n    assert arr.tolist() == [[1, 2], [3, 4]]\n\n    # Testing __setitem__ method\n    arr[0, 0] = 5\n    assert arr.tolist() == [[5, 2], [3, 4]]\n\n    # Testing as_immutable method\n    immutable_arr = arr.as_immutable()\n    assert isinstance(immutable_arr, ImmutableDenseNDimArray)\n    assert immutable_arr.tolist() == [[5, 2], [3, 4]]\n\n    # Testing free_symbols property\n    from sympy.abc import x\n    arr = MutableDenseNDimArray([x, 2, 3, 4], (2, 2))\n    assert arr.free_symbols == {x}\n"], "sample_402": ["def test_prepend_www_append_slash_have_slash_custom_urlconf_with_subdomain(self):\n    request = self.rf.get(\"http://subdomain.testserver/customurlconf/slash/\")\n    request.urlconf = \"middleware.extra_urls\"\n    r = CommonMiddleware(get_response_empty).process_request(request)\n    self.assertEqual(r.status_code, 301)\n    self.assertEqual(r.url, \"http://subdomain.testserver/customurlconf/slash/\")\n"], "sample_742": ["def test_logreg_predict_proba_binary():\n    X, y = make_classification(n_samples=10, n_features=20, random_state=0)\n\n    # Predicted probabilities using the logistic function should give a\n    # smaller loss than those using the soft-max function.\n    clf_bin = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\")\n    clf_bin.fit(X, y)\n    clf_bin_loss = log_loss(y, clf_bin.predict_proba(X))\n    clf_wrong_loss = log_loss(y, clf_bin._predict_proba_lr(X))\n    assert_greater(clf_wrong_loss, clf_bin_loss)\n"], "sample_442": ["def test_sign_unsign_with_custom_serializer(self):\n    class CustomSerializer:\n            return str(obj).encode(\"utf-8\")\n\n            return data.decode(\"utf-8\")\n\n    signer = signing.Signer(key=\"predictable-secret\")\n    value = \"test value\"\n    signed_value = signer.sign_object(value, serializer=CustomSerializer)\n    self.assertEqual(value, signer.unsign_object(signed_value, serializer=CustomSerializer))\n"], "sample_173": ["def test_adapt_ipaddressfield_value(self):\n    self.assertIsNone(self.ops.adapt_ipaddressfield_value(None))\n    self.assertEqual(self.ops.adapt_ipaddressfield_value('192.168.0.1'), '192.168.0.1')\n"], "sample_691": ["def test_faulthandler_stderr_key(pytester: Pytester) -> None:\n    \"\"\"Test that the fault handler stderr key is correctly stored and closed.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n    import faulthandler\n        assert faulthandler.is_enabled()\n    \"\"\"\n    )\n    result = pytester.runpytest_subprocess()\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n    assert result.ret == 0\n\n    # Check that the fault handler stderr key is closed\n    from _pytest.faulthandler import fault_handler_stderr_key\n    assert fault_handler_stderr_key not in pytester.config._store\n"], "sample_428": ["    def test_grouping_sequence(self):\n        self.assertEqual(\n            nformat(123456789, \".\", grouping=(3, 2, 0), thousand_sep=\",\"),\n            \"123,45,6789\"\n        )\n        self.assertEqual(\n            nformat(123456789, \".\", grouping=(3, 2, 0), thousand_sep=\",\", force_grouping=True),\n            \"123,45,67,89\"\n        )\n"], "sample_1134": ["def test_latex_StrPrinter():\n    from sympy.printing.str import StrPrinter\n    assert str(StrPrinter().doprint(I)) == 'I'\n"], "sample_1190": ["def test_physical_constant_conversion():\n    from sympy.physics.units import joule, meter, second\n    assert elementary_charge.convert_to(joule*second) == elementary_charge.scale_factor*joule*second\n    assert speed_of_light.convert_to(meter/second) == speed_of_light.scale_factor*meter/second\n"], "sample_719": ["def test_vectorizer_max_df_min_df_interaction():\n    test_data = ['abc', 'dea', 'eat']\n    vect = CountVectorizer(analyzer='char', max_df=0.5, min_df=2)\n    vect.fit(test_data)\n    assert_true('a' not in vect.vocabulary_.keys())  # {ae} ignored\n    assert_equal(len(vect.vocabulary_.keys()), 1)    # {a} is removed due to min_df\n    assert_true('a' in vect.stop_words_)\n    assert_equal(len(vect.stop_words_), 5)\n"], "sample_1181": ["def test_numpy_print_known_funcs_consts():\n    prntr = NumPyPrinter()\n    assert prntr._print_func('exp2') == 'numpy.exp2'\n    assert prntr._print_func('sign') == 'numpy.sign'\n    assert prntr._print_const('Exp1') == 'numpy.e'\n    assert prntr._print_const('Pi') == 'numpy.pi'\n"], "sample_98": ["    def test_underscores_in_headers_are_stripped(self):\n        \"\"\"\n        Headers with underscores in the name are stripped before constructing\n        the WSGI environ. This prevents header-spoofing based on ambiguity\n        between underscores and dashes both normalized to underscores in WSGI\n        env vars. Nginx and Apache 2.4+ both do this as well.\n        \"\"\"\n        conn = HTTPConnection(LiveServerHeaderNormalization.server_thread.host, LiveServerHeaderNormalization.server_thread.port)\n        try:\n            conn.request('GET', '/environ_view/', headers={\"Header_With_Underscore\": \"value\"})\n            response = conn.getresponse()\n            self.assertEqual(response.status, 200)\n            self.assertNotIn(b\"HTTP_HEADER_WITH_UNDERSCORE\", response.read())\n        finally:\n            conn.close()\n"], "sample_868": ["def test_empty_input(metric_name):\n    metric = SUPERVISED_METRICS[metric_name]\n    assert metric([], []) == 1.0\n"], "sample_636": ["def test_duplicate_code_raw_strings_disable_scope_class(self) -> None:\n    \"\"\"Tests disabling duplicate-code at an inner scope level with a class.\"\"\"\n    path = join(DATA, \"raw_strings_disable_scope_class\")\n    expected_output = \"Similar lines in 2 files\"\n    self._test_output(\n        [path, \"--disable=all\", \"--enable=duplicate-code\"],\n        expected_output=expected_output,\n    )\n"], "sample_500": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.arange(100).reshape(10, 10))\n    cb = fig.colorbar(pc)\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n    cb.set_alpha(None)\n    assert cb.alpha is None\n"], "sample_75": ["def test_prefetch_reverse_foreign_key_with_to_attr(self):\n    with self.assertNumQueries(2):\n        bookwithyear1, = BookWithYear.objects.prefetch_related(Prefetch('bookreview_set', to_attr='reviews'))\n    with self.assertNumQueries(0):\n        self.assertCountEqual(bookwithyear1.reviews, [self.bookreview1])\n    with self.assertNumQueries(0):\n        prefetch_related_objects([bookwithyear1], 'reviews')\n"], "sample_89": ["    def test_tick_notifies_file_changed(self):\n        reloader = autoreload.StatReloader()\n        reloader.watch_file(self.existing_file)\n        notify_mock = mock.MagicMock()\n        reloader.notify_file_changed = notify_mock\n        ticker = reloader.tick()\n        next(ticker)\n        self.increment_mtime(self.existing_file)\n        next(ticker)\n        self.assertEqual(notify_mock.call_count, 1)\n        self.assertCountEqual(notify_mock.call_args[0], [self.existing_file])\n"], "sample_847": ["def test_enet_multitarget_with_precompute():\n    n_targets = 3\n    X, y, _, _ = build_dataset(n_samples=10, n_features=8,\n                               n_informative_features=10, n_targets=n_targets)\n    estimator = ElasticNet(alpha=0.01, precompute=True)\n    estimator.fit(X, y)\n    coef, intercept, dual_gap = (estimator.coef_, estimator.intercept_,\n                                 estimator.dual_gap_)\n\n    for k in range(n_targets):\n        estimator.fit(X, y[:, k])\n        assert_array_almost_equal(coef[k, :], estimator.coef_)\n        assert_array_almost_equal(intercept[k], estimator.intercept_)\n        assert_array_almost_equal(dual_gap[k], estimator.dual_gap_)\n"], "sample_692": ["def test_tmp_path_factory_mktemp_with_invalid_basename(tmp_path_factory: TempPathFactory) -> None:\n    with pytest.raises(ValueError, match=\"..\\\\\\\\foo is not a normalized and relative path\"):\n        tmp_path_factory.mktemp(\"..\\\\foo\")\n"], "sample_795": ["def test_check_estimator_transformer_n_iter():\n    # check that transformers with a parameter max_iter, return the\n    # attribute of n_iter_ at least 1.\n    from sklearn.decomposition import PCA\n    est = PCA(max_iter=10)\n    check_estimator(est)\n"], "sample_0": ["def test_conversion_to_from_variance_not_supported(UncertClass):\n    uncert = np.arange(1, 11).reshape(2, 5) * u.adu\n    start_uncert = UncertClass(uncert)\n    with pytest.raises(TypeError):\n        var_uncert = start_uncert.represent_as(VarianceUncertainty)\n    with pytest.raises(TypeError):\n        final_uncert = VarianceUncertainty(uncert).represent_as(UncertClass)\n"], "sample_559": ["def test_anchored_locator_base_call_with_axes_class():\n    fig = plt.figure(figsize=(3, 3))\n    fig1, fig2 = fig.subfigures(nrows=2, ncols=1)\n\n    ax = fig1.subplots(axes_class=mpl.axes.Axes)\n    ax.set(aspect=1, xlim=(-15, 15), ylim=(-20, 5))\n    ax.set(xticks=[], yticks=[])\n\n    Z = cbook.get_sample_data(\"axes_grid/bivariate_normal.npy\")\n    extent = (-3, 4, -4, 3)\n\n    axins = zoomed_inset_axes(ax, zoom=2, loc=\"upper left\")\n    axins.set(xticks=[], yticks=[])\n\n    axins.imshow(Z, extent=extent, origin=\"lower\")\n"], "sample_684": ["def test_frame_eval(capsys):\n        y = x * 2\n        return y\n\n    fr = Frame(f(3))\n    result = fr.eval(\"y\")\n    assert result == 6\n\n    captured = capsys.readouterr()\n    assert captured.out == \"\"\n    assert captured.err == \"\"\n"], "sample_393": ["def test_no_obsolete_enabled(self):\n    management.call_command(\n        \"makemessages\", locale=[LOCALE], verbosity=0, no_obsolete=True\n    )\n    self.assertTrue(os.path.exists(self.PO_FILE))\n    with open(self.PO_FILE) as fp:\n        po_contents = fp.read()\n        self.assertNotIn(\"#~\", po_contents)\n"], "sample_477": ["def test_non_empty_list(self):\n    test_list = [\"apple\", \"banana\", \"cherry\"]\n    output = self.engine.render_to_string(\"non_empty_list\", {\"list\": test_list})\n    self.assertIn(output, test_list)\n"], "sample_1139": ["def test_issue_18146():\n    e = Symbol('e', integer=True, even=True)\n    o = Symbol('o', integer=True, odd=True)\n    assert Range(5).contains(i) == And(i >= 0, i <= 4)\n    assert Range(1).contains(i) == Eq(i, 0)\n    assert Range(-oo, 5, 1).contains(i) == (i <= 4)\n    assert Range(-oo, oo).contains(i) == True\n    assert Range(0, 8, 2).contains(i) == Contains(i, Range(0, 8, 2))\n    assert Range(0, 8, 2).contains(e) == And(e >= 0, e <= 6)\n    assert Range(0, 8, 2).contains(2*i) == And(2*i >= 0, 2*i <= 6)\n    assert Range(0, 8, 2).contains(o) == False\n    assert Range(1, 9, 2).contains(e) == False\n    assert Range(1, 9, 2).contains(o) == And(o >= 1, o <= 7)\n    assert Range(8, 0, -2).contains(o) == False\n    assert Range(9, 1, -2).contains(o) == And(o >= 3, o <= 9)\n    assert Range(-oo, 8, 2).contains(i) == Contains(i, Range(-oo, 8, 2))\n"], "sample_520": ["def test_view_init_vertical_axis_invalid():\n    ax = plt.subplot(1, 1, 1, projection=\"3d\")\n    with pytest.raises(ValueError, match=\"vertical_axis must be 'x', 'y' or 'z'\"):\n        ax.view_init(elev=0, azim=0, roll=0, vertical_axis='invalid')\n"], "sample_105": ["def test_template_engine_attribute(self):\n    \"\"\"\n    Test a view that renders a template on GET with the template engine as\n    an attribute on the class.\n    \"\"\"\n    request = self.rf.get('/using/')\n    view = TemplateView.as_view(template_name='generic_views/using.html', template_engine='jinja2')\n    self.assertEqual(view(request).render().content, b'Jinja2\\n')\n"], "sample_988": ["def test_issue_13348():\n    assert Eq(True, 1) is S.false\n    assert Eq(False, 0) is S.true\n    assert Eq(True, 0) is S.false\n    assert Eq(False, 1) is S.false\n"], "sample_1008": ["def test_orientnew_with_custom_indices():\n    N = ReferenceFrame('N')\n    q1 = dynamicsymbols('q1')\n    custom_indices = ['i', 'j', 'k']\n    A = N.orientnew('A', 'Axis', [q1, N.z], indices=custom_indices)\n    assert A.indices == custom_indices\n    assert A[custom_indices[0]] == A.x\n    assert A[custom_indices[1]] == A.y\n    assert A[custom_indices[2]] == A.z\n"], "sample_937": ["def test_unparse_slice(source, expected):\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].value) == expected\n"], "sample_225": ["    def setUp(self):\n        self.site = admin.AdminSite()\n"], "sample_896": ["def test_nmf_custom_init_shape_error_update_H_False():\n    # Check that an informative error is raised when custom initialization does not\n    # have the right shape when update_H is False\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((6, 5))\n    H = rng.random_sample((2, 5))\n    nmf = NMF(n_components=2, init=\"custom\", random_state=0)\n\n    with pytest.raises(ValueError, match=\"Array with wrong second dimension passed\"):\n        nmf.fit(X, H=H, W=rng.random_sample((6, 3)), update_H=False)\n"], "sample_328": ["def test_functions_with_expressions(self):\n    Note.objects.update(note='TEST')\n    for note in self.notes:\n        note.note = Lower(F('note')) + '1'\n    Note.objects.bulk_update(self.notes, ['note'])\n    self.assertEqual(set(Note.objects.values_list('note', flat=True)), {'test1'})\n"], "sample_101": ["def test_limited_stream(self):\n    \"\"\"\n    LimitedStream correctly limits the amount of data that can be read.\n    \"\"\"\n    data = b'a' * 10\n    stream = LimitedStream(BytesIO(data), 5)\n    self.assertEqual(stream.read(3), b'aaaaa')\n    self.assertEqual(stream.read(3), b'a')\n    self.assertEqual(stream.read(3), b'')\n\n    stream = LimitedStream(BytesIO(data), 5)\n    self.assertEqual(stream.readline(3), b'aaa')\n    self.assertEqual(stream.readline(3), b'a\\n')\n    self.assertEqual(stream.readline(3), b'')\n"], "sample_982": ["def test_udivisor_sigma_with_symbols():\n    m = Symbol(\"m\", integer=True)\n    k = Symbol(\"k\", integer=True)\n    assert udivisor_sigma(m)\n    assert udivisor_sigma(m, k)\n    assert udivisor_sigma(m).subs(m, 4**9) == 262145\n    assert udivisor_sigma(m, k).subs([(m, 4**9), (k, 2)]) == 68719476737\n    assert summation(udivisor_sigma(m), (m, 2, 15)) == 169\n"], "sample_621": ["def test_copy(self, indexes) -> None:\n    copied = indexes.copy()\n    assert copied is not indexes\n    assert copied._indexes is not indexes._indexes\n    assert copied._variables is not indexes._variables\n    assert copied._indexes == indexes._indexes\n    assert copied._variables == indexes._variables\n"], "sample_476": ["    def test_delete_method(self):\n        p = self.PersonModel(name=\"Joe\", mugshot=self.file1)\n        p.save()\n        self.check_dimensions(p, 4, 8)\n\n        # Deleting the image should clear dimensions.\n        p.mugshot.delete(save=False)\n        self.check_dimensions(p, None, None)\n\n        # Assigning a new image should update dimensions.\n        p.mugshot = self.file2\n        self.check_dimensions(p, 8, 4)\n\n        # Deleting the instance should delete the image.\n        p.delete()\n        self.assertFalse(os.path.exists(p.mugshot.path))\n"], "sample_215": ["    def test_multivalue_dict_sensitive_request(self):\n        \"\"\"\n        Sensitive POST parameters cannot be seen in the default error reports\n        for sensitive requests when the sensitive POST parameters are\n        MultiValueDict instances.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(multivalue_dict_key_error)\n            self.verify_unsafe_email(multivalue_dict_key_error)\n\n        with self.settings(DEBUG=False):\n            self.verify_safe_response(multivalue_dict_key_error)\n            self.verify_safe_email(multivalue_dict_key_error)\n"], "sample_708": ["def test_getstatementrange_with_decorators():\n    source = Source(\n        \"\"\"\\\n        @decorator1\n        @decorator2\n            assert 1 == 1\n        \"\"\"\n    )\n    assert source.getstatementrange(2) == (0, 4)\n"], "sample_134": ["def test_serialize_model_field_with_default(self):\n    field = models.CharField(default='test')\n    string = MigrationWriter.serialize(field)[0]\n    self.assertEqual(string, \"models.CharField(default='test')\")\n"], "sample_249": ["    def test_keepdb_true(self, mocked_sync_apps, mocked_migrate, *mocked_objects):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = test_connection.creation_class(test_connection)\n        if connection.vendor == 'oracle':\n            # Don't close connection on Oracle.\n            creation.connection.close = mock.Mock()\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db') as mock_create_test_db:\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=False, keepdb=True)\n            # _create_test_db is called with keepdb=True\n            mock_create_test_db.assert_called_with(0, True, True)\n            # Migrations run.\n            mocked_migrate.assert_called()\n            args, kwargs = mocked_migrate.call_args\n            self.assertEqual(args, ([('app_unmigrated', '0001_initial')],))\n            self.assertEqual(len(kwargs['plan']), 1)\n            # App is not synced.\n            mocked_sync_apps.assert_not_called()\n        finally:\n            with"], "sample_1192": ["def test_symbol_assumptions():\n    x = Symbol('x', real=True, positive=True)\n    assert x.is_real\n    assert x.is_positive\n\n    y = Symbol('y', real=False, positive=False)\n    assert not y.is_real\n    assert not y.is_positive\n\n    z = Symbol('z', commutative=False)\n    assert not z.is_commutative\n\n    raises(ValueError, lambda: Symbol('w', commutative=None))\n"], "sample_1112": ["def test_digits_large_numbers():\n    assert digits(12345678901234567890, 10) == [10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0]\n    assert digits(12345678901234567890, 16) == [16, 1, 12, 10, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n    assert digits(12345678901234567890, 36) == [36, 1, 10, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18]\n"], "sample_1000": ["def test_octave_user_functions():\n    f = Function('f')\n    g = Function('g')\n    custom_functions = {\n        \"f\": \"existing_octave_fcn\",\n        \"g\": [(lambda x: x.is_Matrix, \"my_mat_fcn\"),\n              (lambda x: not x.is_Matrix, \"my_fcn\")]\n    }\n    mat = Matrix([[1, x]])\n    assert mcode(f(x) + g(x) + g(mat), user_functions=custom_functions) == 'existing_octave_fcn(x) + my_fcn(x) + my_mat_fcn([1 x])'\n"], "sample_1001": ["def test_latex_radian():\n    expr1 = pi*radian\n    assert latex(expr1) == r\"\\pi \\detokenize {radian}\"\n    expr2 = x*radian\n    assert latex(expr2) == r\"x \\detokenize {radian}\"\n    expr3 = sin(x*radian + pi*radian)\n    assert latex(expr3) == r'\\sin{\\left (x \\detokenize {radian} + \\pi \\detokenize {radian} \\right )}'\n"], "sample_870": ["def test_gpr_predict_input_not_modified_with_cov():\n    \"\"\"\n    Check that the input X is not modified by the predict method of the\n    GaussianProcessRegressor when setting return_cov=True.\n    \"\"\"\n    gpr = GaussianProcessRegressor(kernel=CustomKernel()).fit(X, y)\n\n    X2_copy = np.copy(X2)\n    _, _ = gpr.predict(X2, return_cov=True)\n\n    assert_allclose(X2, X2_copy)\n"], "sample_1186": ["def test_array_multiplication():\n    for ArrayType in array_types:\n        A = ArrayType([[1, 2], [3, 4]])\n        B = ArrayType([[5, 6], [7, 8]])\n        assert A * 2 == ArrayType([[2, 4], [6, 8]])\n        assert 2 * A == ArrayType([[2, 4], [6, 8]])\n        assert A * B == ArrayType([[19, 22], [43, 50]])\n"], "sample_366": ["    def test_parse_datetime_invalid_tzinfo(self):\n        # Invalid time zone offsets\n        self.assertIsNone(parse_datetime('2012-04-23T09:15:00+25:00'))\n        self.assertIsNone(parse_datetime('2012-04-23T09:15:00-25:00'))\n        self.assertIsNone(parse_datetime('2012-04-23T09:15:00+25'))\n        self.assertIsNone(parse_datetime('2012-04-23T09:15:00-25'))\n        self.assertIsNone(parse_datetime('2012-04-23T09:15:00+2500'))\n        self.assertIsNone(parse_datetime('2012-04-23T09:15:00-2500'))\n        self.assertIsNone(parse_datetime('2012-04-23T09:15:00+25:'))\n        self.assertIsNone(parse_datetime('2012-04-23T09:15:00-25:'))\n        self.assertIsNone(parse_datetime('2012-04-23T09:15:00+25:60'))\n        self.assertIsNone(parse_datetime('2012-04-23T09:15:00-25:60'))\n"], "sample_251": ["def test_alias_with_m2m(self):\n    qs = Book.objects.alias(author_age=F('authors__age')).filter(pk=self.b1.pk).order_by('author_age')\n    self.assertIs(hasattr(qs.first(), 'author_age'), False)\n    self.assertEqual(qs[0].authors.all()[0].age, 34)\n    self.assertEqual(qs[1].authors.all()[0].age, 35)\n"], "sample_737": ["def test_vectorizer_max_df_min_df_consistency():\n    # Test that max_df < min_df raises a ValueError\n    with pytest.raises(ValueError):\n        CountVectorizer(max_df=0.5, min_df=0.6)\n\n    with pytest.raises(ValueError):\n        TfidfVectorizer(max_df=0.5, min_df=0.6)\n"], "sample_26": ["def test_int16(tmp_path):\n    \"\"\"Test for int16 support, https://github.com/astropy/astropy/issues/11995\"\"\"\n    img = np.arange(-500, 500, dtype=np.int16).reshape(10, 10)\n    hdu = fits.PrimaryHDU(img)\n    hdu.writeto(tmp_path / \"int16.fits\")\n\n    with fits.open(tmp_path / \"int16.fits\") as hdul:\n        assert hdul[0].header[\"BITPIX\"] == 16\n        assert hdul[0].header[\"BZERO\"] == 32768\n        assert hdul[0].header[\"BSCALE\"] == 1.0\n        assert_equal(hdul[0].data, img)\n        assert hdul[0].data.dtype == img.dtype\n"], "sample_902": ["def test_pipeline_with_none_estimator():\n    # Test that a pipeline with None as the final estimator works correctly\n    X = np.array([[1, 2]])\n    pipe = Pipeline([('transf', Transf())])\n    pipe.fit(X, y=None)\n    assert_array_equal(pipe.transform(X), X)\n    assert_array_equal(pipe.fit_transform(X), X)\n    assert_array_equal(pipe.inverse_transform(X), X)\n    assert_raises(AttributeError, getattr, pipe, 'predict')\n    assert_raises(AttributeError, getattr, pipe, 'predict_proba')\n    assert_raises(AttributeError, getattr, pipe, 'predict_log_proba')\n    assert_raises(AttributeError, getattr, pipe, 'decision_function')\n    assert_raises(AttributeError, getattr, pipe, 'score')\n    assert_raises(AttributeError, getattr, pipe, 'classes_')\n"], "sample_417": ["def test_large_numbers(self):\n    self.assertEqual(floatformat(12345678901234567890.123456789, 9), \"12345678901234567890.123456789\")\n    self.assertEqual(floatformat(12345678901234567890.123456789, -9), \"12345678901234567890\")\n"], "sample_790": ["def test_kernel_pca_inverse_transform_sparse():\n    rng = np.random.RandomState(0)\n    X_fit = sp.csr_matrix(rng.random_sample((5, 4)))\n    X_pred = sp.csr_matrix(rng.random_sample((2, 4)))\n\n    for eigen_solver in (\"auto\", \"arpack\"):\n        for kernel in (\"linear\", \"rbf\", \"poly\"):\n            # transform fit data\n            kpca = KernelPCA(4, kernel=kernel, eigen_solver=eigen_solver,\n                             fit_inverse_transform=True)\n            X_fit_transformed = kpca.fit_transform(X_fit)\n\n            # inverse transform\n            assert_raises(NotImplementedError, kpca.inverse_transform, X_pred)\n"], "sample_681": ["def test_log_file_cli_subdirectories_are_successfully_created_absolute_path(testdir):\n    path = testdir.makepyfile(\"\"\" def test_logger(): pass \"\"\")\n    expected = os.path.join(str(testdir.tmpdir), \"foo\", \"bar\")\n    result = testdir.runpytest(\"--log-file=foo/bar/logf.log\", \"--log-file-level=INFO\")\n    assert \"logf.log\" in os.listdir(expected)\n    assert result.ret == ExitCode.OK\n"], "sample_904": ["def test_cmd_option_with_subcommand(app):\n    text = \".. program:: git\\n\\n.. option:: commit -m\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (index,\n                          [desc, ([desc_signature, ([desc_name, 'commit'],\n                                                    [desc_addname, ' -m'])],\n                                  [desc_content, ()])]))\n    assert_node(doctree[0], addnodes.index,\n                entries=[('pair', 'git command line option; commit -m', 'cmdoption-git-commit-m', '', None)])\n\n    objects = list(app.env.get_domain(\"std\").get_objects())\n    assert ('git.commit', 'git.commit', 'cmdoption', 'index', 'cmdoption-git-commit-m', 1) in objects\n"], "sample_2": ["def test_wcs_slicing():\n    wcs = WCS(naxis=2)\n    wcs.wcs.crpix = 10, 10\n    ccd = CCDData(np.ones((10, 10)), wcs=wcs, unit='pixel')\n    sliced_ccd = ccd[2:-2, 2:-2]\n    assert isinstance(sliced_ccd.wcs, WCS)\n    assert sliced_ccd.wcs.wcs.crpix == [8, 8]\n"], "sample_135": ["def test_time_formats_with_microseconds(self):\n    timestamp = datetime(2008, 5, 19, 11, 45, 23, 123456)\n\n    self.assertEqual(dateformat.format(timestamp, 'u'), '123456')\n"], "sample_356": ["def test_add_model_with_field_removed_from_base_model_with_m2m(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name and a ManyToManyField.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n            ('authors', models.ManyToManyField('app.Author')),\n        ], bases=('app.readable',)),\n        ModelState('app', 'author', [\n            ('id', models.AutoField(primary_key=True)),\n            ('name', models.CharField(max_length=200)),\n        ]),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n    self.assertOperationAttributes(changes, 'app', 0, 2, name='author')\n"], "sample_294": ["def test_good_origin_wildcard_csrf_trusted_origin_allowed_with_port(self):\n    \"\"\"\n    A POST request with an origin that matches a CSRF_TRUSTED_ORIGINS\n    wildcard and includes a port is accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['HTTP_ORIGIN'] = 'https://foo.example.com:8000'\n    mw = CsrfViewMiddleware(post_form_view)\n    self.assertIs(mw._origin_verified(req), True)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n    self.assertEqual(mw.allowed_origins_exact, set())\n    self.assertEqual(mw.allowed_origin_subdomains, {'https': ['.example.com']})\n"], "sample_699": ["def test_doctest_module_with_fixtures_and_namespace(pytester: Pytester):\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            return 42\n\n        @pytest.fixture\n            return {'my_fixture': request.getfixturevalue('my_fixture')}\n        \"\"\"\n    )\n    p = pytester.makepyfile(\n        \"\"\"\n        '''\n            >>> my_fixture\n            42\n        '''\n        \"\"\"\n    )\n    reprec = pytester.inline_run(p, \"--doctest-modules\")\n    reprec.assertoutcome(passed=1)\n"], "sample_1048": ["def test_parabola_3d_intersection():\n    l1 = Line(Point3D(1, -2, 3), Point3D(-1, -2, 3))\n    p1 = Point3D(0, 0, 3)\n    parabola1 = Parabola(p1, l1)\n\n    # parabola with 3D line\n    raises(TypeError, lambda: parabola1.intersection(Line3D(Point3D(-7, 3, 2), Point3D(12, 3, 2))))\n"], "sample_1165": ["def test_quaternion_division():\n    q1 = Quaternion(3 + 4*I, 2 + 5*I, 0, 7 + 8*I, real_field = False)\n    q2 = Quaternion(1, 2, 3, 5)\n\n    assert q1 / q2 == q1 * q2.inverse()\n    assert q2 / 2 == Quaternion(0.5, 1, 1.5, 2.5)\n    assert 2 / q2 == Quaternion(0.5, -1, -1.5, -2.5)\n"], "sample_784": ["def test_calibration_multilabel():\n    \"\"\"Test calibration for multilabel \"\"\"\n    # test multi-label setting with classifier that implements\n    # only decision function\n    clf = LinearSVC()\n    X, y = make_multilabel_classification(n_samples=100, n_features=2, random_state=42,\n                                          n_classes=3, n_labels=2)\n\n    X_train, y_train = X[::2], y[::2]\n    X_test, y_test = X[1::2], y[1::2]\n\n    clf.fit(X_train, y_train)\n    for method in ['isotonic', 'sigmoid']:\n        cal_clf = CalibratedClassifierCV(clf, method=method, cv=2)\n        cal_clf.fit(X_train, y_train)\n        probas = cal_clf.predict_proba(X_test)\n        assert_array_almost_equal(np.sum(probas, axis=1), np.ones(len(X_test)))\n\n        # Check that log-loss of calibrated classifier is smaller than\n        # log-loss of naively turned OvR decision function to probabilities\n        # via softmax\n            e = np.exp(-y_pred)\n            return e / e.sum(axis=1).reshape(-1, 1)\n\n        uncalibrated_log_loss = \\\n            log_loss(y_test, softmax(clf.decision_function(X_test)))\n        calibrated_log_loss = log_loss(y_test, probas)\n        assert_greater_equal(uncalibrated_log_loss, calibrated_log_loss)\n"], "sample_230": ["def test_json_field_with_custom_encoder(self):\n    class CustomEncoder(json.JSONEncoder):\n            if isinstance(obj, uuid.UUID):\n                return str(obj)\n            return super().default(obj)\n\n    value = {'uuid': uuid.UUID('{c141e152-6550-4172-a784-05448d98204b}')}\n    encoded_value = '{\"uuid\": \"c141e152-6550-4172-a784-05448d98204b\"}'\n    field = JSONField(encoder=CustomEncoder)\n    self.assertEqual(field.prepare_value(value), encoded_value)\n    self.assertEqual(field.clean(encoded_value), value)\n"], "sample_644": ["def test_import_outside_toplevel(self) -> None:\n    module = astroid.MANAGER.ast_from_module_name(\"outside_toplevel\", REGR_DATA)\n    import_from = module.body[0].body[0]\n\n    msg = MessageTest(\n        msg_id=\"import-outside-toplevel\",\n        node=import_from,\n        args=\"os\",\n        line=3,\n        col_offset=4,\n        end_line=3,\n        end_col_offset=15,\n    )\n    with self.assertAddsMessages(msg):\n        self.checker.visit_importfrom(import_from)\n"], "sample_227": ["def test_emptylistfieldfilter_reverse_relationships_non_empty_field(self):\n    class UserAdminReverseRelationship(UserAdmin):\n        list_filter = (\n            ('books_authored', EmptyFieldListFilter),\n        )\n\n    modeladmin = UserAdminReverseRelationship(User, site)\n    request = self.request_factory.get('/')\n    request.user = self.alfred\n    msg = (\n        \"The list filter 'EmptyFieldListFilter' cannot be used with field \"\n        \"'books_authored' which doesn't allow empty strings and nulls.\"\n    )\n    with self.assertRaisesMessage(ImproperlyConfigured, msg):\n        modeladmin.get_changelist_instance(request)\n"], "sample_228": ["def test_formset_with_deletion_and_empty_forms(self):\n    \"\"\"FormSets with deletion and empty forms.\"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_delete=True, extra=2)\n    initial = [\n        {'choice': 'Calexico', 'votes': 100},\n        {'choice': 'Fergie', 'votes': 900},\n    ]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    # Let's delete Fergie and leave the extra forms empty.\n    data = {\n        'choices-TOTAL_FORMS': '4',  # the number of forms rendered\n        'choices-INITIAL_FORMS': '2',  # the number of forms with initial data\n        'choices-MIN_NUM_FORMS': '0',  # min number of forms\n        'choices-MAX_NUM_FORMS': '0',  # max number of forms\n        'choices-0-choice': 'Calexico',\n        'choices-0-votes': '100',\n        'choices-0-DELETE': '',\n        'choices-1-choice': 'Fergie',\n        'choices-1-votes': '900',\n        'choices-1-DELETE': 'on',\n        'choices-2-choice': '',\n        'choices-2-votes': '',\n        'choices-2-DELETE': '',\n        'choices-3-choice': '',\n        'choices-3-votes': '',\n        'choices-3-DELETE': '',\n    }\n    formset = ChoiceFormSet(data, auto_id=False, prefix='choices')\n    self.assertTrue(formset.is_valid())\n    self.assertEqual(\n        [form.cleaned_data for form in formset.forms],\n        [\n            {'votes': 100, 'DELETE': False, 'choice': 'Calexico'},\n            {'votes': 900, 'DELETE': True, 'choice': 'Fergie'},\n            {},\n           "], "sample_370": ["def test_nested_prefetch_with_custom_queryset(self):\n    \"\"\"\n    Nested prefetches with custom querysets are allowed.\n    \"\"\"\n    rooms_qs = Room.objects.filter(name='Kitchen')\n    houses_qs = House.objects.prefetch_related(Prefetch('rooms', queryset=rooms_qs))\n    with self.assertNumQueries(2):\n        self.traverse_qs(list(houses_qs), [['rooms']])\n"], "sample_954": ["def test_domain_python(app, status, warning):\n    app.builder.build_all()\n    content = (app.outdir / 'python.1').read_text()\n\n    # test domain-specific object descriptions\n    assert '\\n.B function::\\n    ' in content\n    assert '\\n.B class::\\n    ' in content\n    assert '\\n.B exception::\\n    ' in content\n    assert '\\n.B data::\\n    ' in content\n    assert '\\n.B attribute::\\n    ' in content\n    assert '\\n.B method::\\n    ' in content\n    assert '\\n.B staticmethod::\\n    ' in content\n    assert '\\n.B classmethod::\\n    ' in content\n    assert '\\n.B module::\\n    ' in content\n    assert '\\n.B currentmodule::\\n    ' in content\n"], "sample_340": ["def test_run_before_invalid(self):\n    \"\"\"\n    Makes sure the loader raises an error for invalid run_before dependencies.\n    \"\"\"\n    with self.assertRaises(NodeNotFoundError):\n        MigrationLoader(connection)\n"], "sample_419": ["def test_formset_with_custom_prefix(self):\n    \"\"\"Formsets with custom prefix.\"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_order=True, can_delete=True)\n    initial = [\n        {\"choice\": \"Calexico\", \"votes\": 100},\n        {\"choice\": \"Fergie\", \"votes\": 900},\n        {\"choice\": \"The Decemberists\", \"votes\": 500},\n    ]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix=\"custom_prefix\")\n    self.assertHTMLEqual(\n        \"\\n\".join(form.as_ul() for form in formset.forms),\n        '<li>Choice: <input type=\"text\" name=\"custom_prefix-0-choice\" value=\"Calexico\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"custom_prefix-0-votes\" value=\"100\"></li>'\n        '<li>Order: <input type=\"number\" name=\"custom_prefix-0-ORDER\" value=\"1\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"custom_prefix-0-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"custom_prefix-1-choice\" value=\"Fergie\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"custom_prefix-1-votes\" value=\"900\"></li>'\n        '<li>Order: <input type=\"number\" name=\"custom_prefix-1-ORDER\" value=\"2\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"custom_prefix-1-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"custom_prefix-2-choice\" '\n        'value=\"The Decemberists\"></li>'\n        '<li>Votes: <input type=\"number\" name=\"custom_prefix-2-votes\" value=\"500\"></li>'\n        '<li>Order: <input type=\"number\" name=\"custom_prefix-2-ORDER\" value=\"3\"></li>'"], "sample_963": ["def test_restify_type_ForwardRef_evaluated():\n    from typing import ForwardRef\n    class MyClass:\n        pass\n    assert restify(ForwardRef(\"MyClass\")) == \":py:class:`tests.test_util_typing.MyClass`\"\n"], "sample_1090": ["def test_mul():\n    with evaluate(False):\n        expr = x * x\n        assert isinstance(expr, Mul)\n        assert expr.args == (x, x)\n\n        with evaluate(True):\n            assert (x * x).args == (x**2,)\n\n        assert (x * x).args == (x, x)\n\n    assert isinstance(x * x, Pow)\n\n    with evaluate(False):\n        assert S.One * 1 == Mul(1, 1)\n        assert 1 * S.One == Mul(1, 1)\n\n        assert S(4) / 3 == Mul(4, S.One / 3)\n        assert S.One / 3 * 4 == Mul(S.One / 3, 4)\n\n        assert 9 ** S(2) == Pow(9, 2)\n        assert S(2) ** 9 == Pow(2, 9)\n\n        assert S(2) / 4 * 4 == Mul(S(2) / 4, 4)\n        assert 4 * (S(2) / 4) == Mul(4, S(2) / 4)\n\n        assert S(6) / 3 == Mul(6, S.One / 3)\n        assert S.One / 3 * 6 == Mul(S.One / 3, 6)\n\n        assert S.One / 2 * 10.333 == Mul(S.One / 2, 10.333)\n        assert 10.333 * S.One / 2 == Mul(10.333, S.One / 2)\n\n        assert sqrt(2) * sqrt(2) == Mul(sqrt(2), sqrt(2))\n\n        assert S.One / x * x == Mul(S.One / x, x)\n        assert x * S.One / x == Mul(x, S.One / x)\n"], "sample_268": ["def test_watch_dir_with_non_existing_directory(self, mocked_modules, notify_mock):\n    non_existing_dir = self.tempdir / 'non_existing_directory'\n    self.reloader.watch_dir(non_existing_dir, '*.py')\n    with self.tick_twice():\n        # No changes should be detected in a non-existing directory\n        pass\n    self.assertEqual(notify_mock.call_count, 0)\n"], "sample_63": ["def test_custom_template_libraries(self):\n    engine = Engine.get_default()\n    self.assertIn('custom_tags', engine.template_libraries)\n"], "sample_1039": ["def test_presentation_mathml_negative_infinity():\n    mml = mpp._print(-oo)\n    assert mml.nodeName == 'mrow'\n    assert mml.childNodes[0].nodeName == 'mo'\n    assert mml.childNodes[0].childNodes[0].nodeValue == '-'\n    assert mml.childNodes[1].nodeName == 'mi'\n    assert mml.childNodes[1].childNodes[0].nodeValue == '&#x221E;'\n"], "sample_361": ["def test_urlize_trim_url_limit(self):\n    tests = (\n        (\n            'Search for google.com/?q=12345678901234567890 and see.',\n            10,\n            'Search for <a href=\"http://google.com/?q=12345678901234567890\">google.com/\u2026</a> and see.'\n        ),\n        (\n            'Search for google.com/?q=12345678901234567890 and see.',\n            None,\n            'Search for <a href=\"http://google.com/?q=12345678901234567890\">google.com/?q=12345678901234567890</a> and see.'\n        ),\n        (\n            lazystr('Search for google.com/?q=12345678901234567890'),\n            10,\n            'Search for <a href=\"http://google.com/?q=12345678901234567890\">google.com/\u2026</a>'\n        ),\n    )\n    for value, limit, output in tests:\n        with self.subTest(value=value, limit=limit):\n            self.assertEqual(urlize(value, trim_url_limit=limit), output)\n"], "sample_240": ["def test_token_with_different_password(self):\n    \"\"\"Updating the user password invalidates the token.\"\"\"\n    user = User.objects.create_user('changepassworduser', 'test5@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk1), True)\n    user.set_password('newtestpw')\n    user.save()\n    self.assertIs(p0.check_token(user, tk1), False)\n"], "sample_651": ["def test_warns_context_manager_with_match(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        import warnings\n\n            with pytest.warns(UserWarning, match='expected warning'):\n                warnings.warn('expected warning', UserWarning)\n\n            with pytest.raises(pytest.fail.Exception):\n                with pytest.warns(UserWarning, match='unexpected warning'):\n                    warnings.warn('expected warning', UserWarning)\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed in*\"])\n"], "sample_112": ["def test_cell_count(self):\n    \"\"\"\n    cell_count template filter should return the correct number of cells used in a tabular inline.\n    \"\"\"\n    request = self.request_factory.get(reverse('admin:admin_views_article_change', args=[self.article.pk]))\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    response = admin.change_view(request, str(self.article.pk))\n    inline_admin_form = response.context_data['inline_admin_formsets'][0].form\n    cell_count_result = cell_count(inline_admin_form)\n    # Calculate the expected cell count manually\n    expected_cell_count = 1  # Hidden cell with hidden 'id' field\n    for fieldset in inline_admin_form:\n        for line in fieldset:\n            for field in line:\n                expected_cell_count += 1\n    if inline_admin_form.formset.can_delete:\n        expected_cell_count += 1\n    self.assertEqual(cell_count_result, expected_cell_count)\n"], "sample_900": ["def test_early_stopping_validation_fraction():\n    # Test early stopping with a custom validation fraction\n    X = X_digits_binary[:100]\n    y = y_digits_binary[:100]\n    tol = 0.2\n    validation_fraction = 0.2\n    clf = MLPClassifier(tol=tol, max_iter=3000, solver='sgd',\n                        early_stopping=True, validation_fraction=validation_fraction)\n    clf.fit(X, y)\n    assert clf.max_iter > clf.n_iter_\n\n    valid_scores = clf.validation_scores_\n    best_valid_score = clf.best_validation_score_\n    assert max(valid_scores) == best_valid_score\n    assert best_valid_score + tol > valid_scores[-2]\n    assert best_valid_score + tol > valid_scores[-1]\n    assert len(valid_scores) == int(clf.n_iter_ / (validation_fraction * clf.max_iter))\n"], "sample_533": ["def test_contour_invalid_algorithm():\n    x, y = np.meshgrid(np.linspace(0.0, 1.0, 10), np.linspace(0.0, 1.0, 6))\n    z = np.sin(15*x)*np.cos(10*y) + np.random.normal(scale=0.5, size=(6, 10))\n\n    with pytest.raises(ValueError):\n        plt.contourf(x, y, z, algorithm='invalid')\n"], "sample_578": ["def test_baseline(self, x, y):\n\n    baseline = 2\n    p = Plot(x, y).add(Bars(baseline=baseline)).plot()\n    ax = p._figure.axes[0]\n    paths = ax.collections[0].get_paths()\n    for i, path in enumerate(paths):\n        verts = path.vertices\n        assert verts[0, 1] == baseline\n        assert verts[3, 1] == y[i] + baseline\n"], "sample_126": ["def test_mti_inheritance_model_removal_with_fk(self):\n    Animal = ModelState('app', 'Animal', [\n        (\"id\", models.AutoField(primary_key=True)),\n    ])\n    Dog = ModelState('app', 'Dog', [], bases=('app.Animal',))\n    Owner = ModelState('app', 'Owner', [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"pet\", models.ForeignKey('app.Animal', models.CASCADE)),\n    ])\n    changes = self.get_changes([Animal, Dog, Owner], [Animal, Owner])\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['DeleteModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='Dog')\n"], "sample_262": ["def test_lazy_modulo(self):\n    \"\"\"\n    % works correctly for Promises.\n    \"\"\"\n    lazy_str = lazy(lambda: 'Django %s', str)\n    self.assertEqual(lazy_str() % 'rocks', 'Django rocks')\n"], "sample_148": ["def test_display_for_value_boolean(self):\n    self.assertEqual(\n        display_for_value(True, '', boolean=True),\n        '<img src=\"/static/admin/img/icon-yes.svg\" alt=\"True\">'\n    )\n    self.assertEqual(\n        display_for_value(False, '', boolean=True),\n        '<img src=\"/static/admin/img/icon-no.svg\" alt=\"False\">'\n    )\n"], "sample_722": ["def test_k_means_elkan_algorithm():\n    # Test the 'elkan' algorithm for KMeans\n    km = KMeans(n_clusters=n_clusters, algorithm='elkan', random_state=42)\n    km.fit(X)\n    _check_fitted_model(km)\n"], "sample_989": ["def test_Float_comparison():\n    f1 = Float('1.0', precision=15)\n    f2 = Float('1.0', precision=20)\n    assert f1 == f2\n    assert not f1 != f2\n    assert not f1 < f2\n    assert f1 <= f2\n    assert not f1 > f2\n    assert f1 >= f2\n\n    f3 = Float('1.000000000000001', precision=20)\n    assert f1 != f3\n    assert f1 < f3\n    assert f1 <= f3\n    assert not f1 > f3\n    assert not f1 >= f3\n\n    f4 = Float('0.999999999999999', precision=20)\n    assert f1 != f4\n    assert not f1 < f4\n    assert not f1 <= f4\n    assert f1 > f4\n    assert f1 >= f4\n"], "sample_695": ["def test_node_from_parent_with_path_and_fspath() -> None:\n    path = Path(\"/path/to/file\")\n    fspath = legacy_path(path)\n    node = nodes.Node.from_parent(None, path=path, fspath=fspath)\n    assert node.path == path\n    assert node.fspath == fspath\n"], "sample_139": ["def test_get_queryset_with_custom_method(self):\n    class CustomQuerySetAdmin(admin.ModelAdmin):\n            qs = super().get_queryset(request)\n            return qs.filter(name__startswith='A')\n\n    m = CustomQuerySetAdmin(Band, custom_site)\n    request = self.factory.get('/band/')\n    request.user = self.superuser\n    cl = m.get_changelist_instance(request)\n    self.assertEqual(cl.queryset.count(), Band.objects.filter(name__startswith='A').count())\n"], "sample_938": ["def test_image_in_manpage(app, status, warning):\n    app.build()\n    content = (app.outdir / 'python.1').read_text()\n    assert 'No images should be included in manpage output' in content\n"], "sample_7": ["def test_column_insert_with_quantity():\n    \"\"\"Test inserting a Quantity into a Column.\"\"\"\n    c = table.Column([1, 2, 3], unit='m')\n    c1 = c.insert(1, 1.5 * u.m)\n    assert np.all(c1 == [1, 1.5, 2, 3])\n    assert c1.unit == u.m\n"], "sample_503": ["def test_marker_as_markerstyle_with_fillstyle():\n    fig, ax = plt.subplots()\n    line, = ax.plot([2, 4, 3], marker=MarkerStyle(\"D\", fillstyle='full'))\n    fig.canvas.draw()\n    assert line.get_marker() == \"D\"\n    assert line.get_fillstyle() == 'full'\n\n    # continue with smoke tests:\n    line.set_fillstyle('left')\n    fig.canvas.draw()\n    line.set_fillstyle('right')\n    fig.canvas.draw()\n    line.set_fillstyle('bottom')\n    fig.canvas.draw()\n    line.set_fillstyle('top')\n    fig.canvas.draw()\n    line.set_fillstyle('none')\n    fig.canvas.draw()\n"], "sample_632": ["def test_ignore_signatures_with_empty_functions():\n    output = StringIO()\n    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n        similar.Run([\"--ignore-signatures\", EMPTY_FUNCTION_1, EMPTY_FUNCTION_2])\n    assert ex.value.code == 0\n    assert (\n        output.getvalue().strip()\n        == \"\"\""], "sample_372": ["    def test_urlpattern_resolve_with_prefix(self):\n        test_urls = [\n            ('/prefix/normal/42/37/', 'normal-view', '', '', 'normal-view', views.empty_view, (), {'arg1': '42', 'arg2': '37'}),\n            ('/prefix/included/normal/42/37/', 'inc-normal-view', 'included_namespace_urls', 'included_namespace_urls', 'included_namespace_urls:inc-normal-view', views.empty_view, (), {'arg1': '42', 'arg2': '37'}),\n            ('/prefix/test1/inner/42/37/', 'urlobject-view', 'testapp', 'test-ns1', 'test-ns1:urlobject-view', views.empty_view, (), {'arg1': '42', 'arg2': '37'}),\n        ]\n        for path_, url_name, app_name, namespace, view_name, func, args, kwargs in test_urls:\n            with self.subTest(path=path_):\n                with override_script_prefix('/prefix/'):\n                    match = resolve(path_)\n                    self.assertEqual(match.url_name, url_name)\n                    self.assertEqual(match.app_name, app_name)\n                    self.assertEqual(match.namespace, namespace)\n                    self.assertEqual(match.view_name, view_name)\n                    self.assertEqual(match.func, func)\n                    self.assertEqual(match.args, args)\n                    self.assertEqual(match.kwargs, kwargs)\n"], "sample_1046": ["def test_tensor_replace_indices():\n    L = TensorIndexType(\"L\")\n    i, j, k, l = tensor_indices(\"i j k l\", L)\n    A, B = tensorhead(\"A B\", [L, L], [[1], [1]])\n\n    expr = A(i, j)\n    assert expr.replace_indices((i, k), (j, l)) == A(k, l)\n    assert expr.replace_indices((i, -k), (j, l)) == A(-k, l)\n    assert expr.replace_indices((i, k), (j, -l)) == A(k, -l)\n    assert expr.replace_indices((i, -k), (j, -l)) == A(-k, -l)\n\n    expr = A(i, j) + B(k, l)\n    assert expr.replace_indices((i, k), (j, l)) == A(k, l) + B(k, l)\n    assert expr.replace_indices((i, -k), (j, l)) == A(-k, l) + B(k, l)\n    assert expr.replace_indices((i, k), (j, -l)) == A(k, -l) + B(k, l)\n    assert expr.replace_indices((i, -k), (j, -l)) == A(-k, -l) + B(k, l)\n"], "sample_412": ["def test_urlize_nofollow(self):\n    value = \"Check out https://example.com.\"\n    output = 'Check out <a href=\"https://example.com/\" rel=\"nofollow\">https://example.com</a>.'\n    self.assertEqual(urlize(value, nofollow=True), output)\n"], "sample_408": ["def test_add_model_with_field_removed_from_base_model_with_m2m(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name, even if the base model has a\n    ManyToManyField.\n    \"\"\"\n    before = [\n        ModelState(\n            \"app\",\n            \"readable\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"title\", models.CharField(max_length=200)),\n                (\"tags\", models.ManyToManyField(\"app.Tag\")),\n            ],\n        ),\n    ]\n    after = [\n        ModelState(\n            \"app\",\n            \"readable\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"tags\", models.ManyToManyField(\"app.Tag\")),\n            ],\n        ),\n        ModelState(\n            \"app\",\n            \"book\",\n            [\n                (\"title\", models.CharField(max_length=200)),\n            ],\n            bases=(\"app.readable\",),\n        ),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, \"app\", 1)\n    self.assertOperationTypes(changes, \"app\", 0, [\"RemoveField\", \"CreateModel\"])\n    self.assertOperationAttributes(\n        changes, \"app\", 0, 0, name=\"title\", model_name=\"readable\"\n    )\n    self.assertOperationAttributes(changes, \"app\", 0, 1, name=\"book\")\n"], "sample_1178": ["def test_FunctionCall_replace():\n    x = Variable('x', real)\n    y = Variable('y', real)\n    n = Variable('n', integer)\n\n    pwer = FunctionDefinition(real, 'pwer', [x, n], [pow(x.symbol, n.symbol)])\n    pcall = FunctionCall('pwer', [y, 3])\n\n    tree1 = CodeBlock(pwer, pcall)\n    tree2 = tree1.replace(pcall, FunctionCall('power', [y, 3]))\n\n    assert str(tree1.args[1].name) == 'pwer'\n    assert str(tree2.args[1].name) == 'power'\n"], "sample_354": ["def test_validate_fk_via_option_non_interactive(self):\n    email = Email.objects.create(email='mymail@gmail.com')\n    Group.objects.all().delete()\n    nonexistent_group_id = 1\n    msg = f'group instance with id {nonexistent_group_id} does not exist.'\n\n    with self.assertRaisesMessage(CommandError, msg):\n        call_command(\n            'createsuperuser',\n            interactive=False,\n            username=email.pk,\n            email=email.email,\n            group=nonexistent_group_id,\n            verbosity=0,\n        )\n"], "sample_789": ["def test_adaboost_classifier_feature_importances():\n    # Test feature importances for AdaBoostClassifier\n    X, y = datasets.make_classification(n_samples=100, n_features=10, n_informative=5, random_state=42)\n    clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n    clf.fit(X, y)\n    importances = clf.feature_importances_\n    assert_equal(importances.shape, (10,))\n    assert_array_less(0, importances)\n    assert_array_less(importances, 1)\n"], "sample_567": ["def test_annotation_clip():\n    fig, ax = plt.subplots()\n    ann = ax.annotate('test', xy=(0, 0), xytext=(0.5, 0.5),\n                      arrowprops={'arrowstyle': '->'},\n                      annotation_clip=True)\n    fig.canvas.draw()\n    assert not ann.contains(MouseEvent('button_press_event', fig.canvas, 0, 0, 1, None))\n\n    ann = ax.annotate('test', xy=(0, 0), xytext=(0.5, 0.5),\n                      arrowprops={'arrowstyle': '->'},\n                      annotation_clip=False)\n    fig.canvas.draw()\n    assert ann.contains(MouseEvent('button_press_event', fig.canvas, 0, 0, 1, None))\n"], "sample_543": ["def test_polygon_selector_set_verts(ax):\n    verts = [(50, 50), (150, 50), (50, 150)]\n    tool = widgets.PolygonSelector(ax, onselect=noop)\n    tool.verts = verts\n    assert tool.verts == verts\n"], "sample_344": ["def test_abstract_model_children_inherit_constraints(self):\n    class Abstract(models.Model):\n        size = models.IntegerField()\n\n        class Meta:\n            app_label = 'migrations'\n            abstract = True\n            constraints = [models.CheckConstraint(check=models.Q(size__gt=1), name='size_gt_1')]\n\n    class Child1(Abstract):\n        pass\n\n    class Child2(Abstract):\n        pass\n\n    child1_state = ModelState.from_model(Child1)\n    child2_state = ModelState.from_model(Child2)\n    constraint_names = [constraint.name for constraint in child1_state.options['constraints']]\n    self.assertEqual(constraint_names, ['size_gt_1'])\n    constraint_names = [constraint.name for constraint in child2_state.options['constraints']]\n    self.assertEqual(constraint_names, ['size_gt_1'])\n\n    # Modifying the state doesn't modify the constraint on the model.\n    child1_state.options['constraints'][0].name = 'bar'\n    self.assertEqual(Child1._meta.constraints[0].name, 'size_gt_1')\n"], "sample_307": ["def test_time_formats_with_microseconds(self):\n    dt = datetime(2009, 5, 16, 5, 30, 30, 123456)\n\n    self.assertEqual(dateformat.format(dt, 'u'), '123456')\n"], "sample_613": ["def test_groupby_bins_multidim_with_nan():\n    array = make_groupby_multidim_example_array()\n    array[0, 0, 0] = np.nan\n    bins = [0, 15, 20]\n    bin_coords = pd.cut(array[\"lat\"].values.flat, bins).categories\n    expected = DataArray([15, 40], dims=\"lat_bins\", coords={\"lat_bins\": bin_coords})\n    actual = array.groupby_bins(\"lat\", bins).map(lambda x: x.sum(skipna=True))\n    assert_identical(expected, actual)\n"], "sample_966": ["def test_pyfunction_signature_with_defaults(app):\n    text = \".. py:function:: hello(name='World') -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, ([desc_parameter, ([desc_sig_name, \"name\"],\n                                                        [desc_sig_operator, \"=\"],\n                                                        [nodes.inline, \"'World'\"])])])\n"], "sample_282": ["def test_bound_field_subwidgets(self):\n    form = ComplexFieldForm()\n    bound_field = form['field1']\n    subwidgets = bound_field.subwidgets\n    self.assertEqual(len(subwidgets), 3)\n    self.assertIsInstance(subwidgets[0], BoundWidget)\n    self.assertIsInstance(subwidgets[1], BoundWidget)\n    self.assertIsInstance(subwidgets[2], BoundWidget)\n"], "sample_1077": ["def test_imageset_intersection_complex():\n    n = Dummy()\n    s = ImageSet(Lambda(n, I*n), S.Integers)\n    assert s.intersect(S.Reals) == S.EmptySet\n    assert s.intersect(S.Complexes) == s\n"], "sample_58": ["def test_custom_renderer_subclass(self):\n    class CustomRendererSubclass(CustomRenderer):\n        pass\n\n    class CustomForm(Form):\n        default_renderer = CustomRendererSubclass\n\n    form = CustomForm()\n    self.assertTrue(isinstance(form.renderer, CustomForm.default_renderer))\n"], "sample_401": ["def test_formset_with_custom_prefix(self):\n    \"\"\"Formsets can have a custom prefix.\"\"\"\n    CustomPrefixFormSet = formset_factory(Choice, extra=3, prefix=\"custom\")\n    formset = CustomPrefixFormSet()\n    self.assertHTMLEqual(\n        \"\\n\".join(str(form) for form in formset.forms),\n        \"\"\"<tr><th><label for=\"id_custom-0-choice\">Choice:</label></th>"], "sample_573": ["def test_order_less_than_unique_values(self, df):\n\n    groupby = GroupBy([\"group\"])\n    df = pd.DataFrame(dict(x=[1, 2, 3], y=[1, 2, 3], group=[\"x\", \"x\", \"x\"]))\n    res = PolyFit(order=3, gridsize=100)(df, groupby, \"x\", {})\n\n    assert res.empty\n"], "sample_474": ["def test_multiple_characters(self):\n    authors = Author.objects.annotate(first_two_initials=Left(\"name\", 2))\n    self.assertCountEqual(authors.filter(first_two_initials=Chr(ord(\"J\")) + Chr(ord(\"o\"))), [self.john])\n    self.assertCountEqual(\n        authors.exclude(first_two_initials=Chr(ord(\"J\")) + Chr(ord(\"o\"))), [self.elena, self.rhonda]\n    )\n"], "sample_468": ["def test_context_with_request_context(self):\n    request = self.request_factory.get(\"/\")\n    context = RequestContext(request, {\"a\": 1, \"b\": \"xyzzy\"})\n    self.assertEqual(context[\"a\"], 1)\n    self.assertEqual(context.push(), {})\n    context[\"a\"] = 2\n    self.assertEqual(context[\"a\"], 2)\n    self.assertEqual(context.get(\"a\"), 2)\n    self.assertEqual(context.pop(), {\"a\": 2})\n    self.assertEqual(context[\"a\"], 1)\n    self.assertEqual(context.get(\"foo\", 42), 42)\n    self.assertEqual(context, mock.ANY)\n"], "sample_939": ["def test_unparse_subscript_slice(source, expected):\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].value, source) == expected\n"], "sample_1023": ["def test_sieve_extend():\n    s = Sieve()\n    s.extend(100)\n    assert s._list == _array('l', [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97])\n    s.extend(200)\n    assert s._list == _array('l', [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199])\n"], "sample_777": ["def test_gradient_boosting_with_sample_weight():\n    # Check that GradientBoostingRegressor works when sample_weight is provided\n    X, y = make_regression()\n    sample_weight = np.random.RandomState(42).rand(100)\n\n    gbr = GradientBoostingRegressor(random_state=42)\n    gbr.fit(X, y, sample_weight=sample_weight)\n    assert gbr.score(X, y) > 0.5\n"], "sample_505": ["def test_microsecond_locator():\n    # Test MicrosecondLocator with different intervals\n    locator = mdates.MicrosecondLocator(interval=1000)\n    locator.create_dummy_axis()\n    locator.axis.set_view_interval(mdates.date2num(datetime.datetime(2022, 1, 1)),\n                                   mdates.date2num(datetime.datetime(2022, 1, 1, 0, 0, 1)))\n    assert list(map(str, mdates.num2date(locator()))) == ['2022-01-01 00:00:00.000000',\n                                                          '2022-01-01 00:00:00.001000',\n                                                          '2022-01-01 00:00:00.002000',\n                                                          '2022-01-01 00:00:00.003000',\n                                                          '2022-01-01 00:00:00.004000',\n                                                          '2022-01-01 00:00:00.005000',\n                                                          '2022-01-01 00:00:00.006000',\n                                                          '2022-01-01 00:00:00.007000',\n                                                          '2022-01-01 00:00:00.008000',\n                                                          '2022-01-01 00:00:00.009000']\n"], "sample_899": ["def test_check_estimator_sparse_data():\n    # check that check_estimator() works on estimator with sparse data\n    est = LinearRegression()\n    check_estimator_sparse_data(\"LinearRegression\", est)\n"], "sample_721": ["def test_check_array_force_all_finite_complex():\n    X = np.array([[1 + 1j, 2 + 2j], [3 + 3j, 4 + 4j]])\n    with pytest.raises(ValueError, match=\"Complex data not supported\"):\n        check_array(X, force_all_finite=True)\n"], "sample_915": ["def test_isabstractmethod(app):\n    from target.methods import Base, AbstractBase\n\n    assert inspect.isabstractmethod(AbstractBase.abstractmeth) is True\n    assert inspect.isabstractmethod(Base.meth) is False\n"], "sample_649": ["def test_log_cli_format(pytester: Pytester) -> None:\n    # Custom log format\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_handler.formatter._fmt == '%(levelname)s - %(message)s'\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n        log_cli_format = %(levelname)s - %(message)s\n        \"\"\"\n    )\n\n    result = pytester.runpytest(\"-s\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines(\n        [\n            \"*INFO - This log message will be shown\",\n            \"PASSED\",  # 'PASSED' on its own line because the log message prints a new line\n        ]\n    )\n\n    # make sure that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n"], "sample_680": ["def test_marked_xfail_with_boolean_without_reason(self, testdir) -> None:\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(False)\n            pass\n    \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_xfail_marks(item)\n    assert excinfo.value.msg is not None\n    assert (\n        \"\"\"Error evaluating 'xfail': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n        in excinfo.value.msg\n    )\n"], "sample_551": ["def test_patch_collection_legend_elements():\n    from matplotlib.patches import Circle\n    x, y, z = np.random.rand(3, 10)\n    colors = ['blue', 'green', 'red']\n\n    fig, ax = plt.subplots(subplot_kw=dict(projection='3d'))\n    pc = ax.scatter(x, y, z, c=colors)\n\n    artists, labels = pc.legend_elements(prop=\"colors\")\n    assert labels == ['blue', 'green', 'red']\n    assert all(isinstance(a, Circle) for a in artists)\n    assert all(same_color(a.get_facecolor(), c)\n               for a, c in zip(artists, colors))\n"], "sample_839": ["def test_vectorizer_max_df_min_df():\n    test_data = ['abc', 'dea', 'eat']\n    vect = CountVectorizer(analyzer='char', max_df=0.5, min_df=0.5)\n    vect.fit(test_data)\n    assert 'a' not in vect.vocabulary_.keys()  # {ae} ignored\n    assert len(vect.vocabulary_.keys()) == 2    # {bd} remain\n    assert 'a' in vect.stop_words_\n    assert len(vect.stop_words_) == 3\n"], "sample_782": ["def test_column_transformer_callable_specifier_empty():\n    # assert that function gets the full array / dataframe\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n\n        assert_array_equal(X, X_array)\n        return []\n\n    ct = ColumnTransformer([('trans', Trans(), func)],\n                           remainder='drop')\n    assert_array_equal(ct.fit_transform(X_array), np.empty((3, 0)))\n    assert_array_equal(ct.fit(X_array).transform(X_array), np.empty((3, 0)))\n    assert callable(ct.transformers[0][2])\n    assert ct.transformers_[0][2] == []\n\n    pd = pytest.importorskip('pandas')\n    X_df = pd.DataFrame(X_array, columns=['first', 'second'])\n\n        assert_array_equal(X.columns, X_df.columns)\n        assert_array_equal(X.values, X_df.values)\n        return []\n\n    ct = ColumnTransformer([('trans', Trans(), func)],\n                           remainder='drop')\n    assert_array_equal(ct.fit_transform(X_df), np.empty((3, 0)))\n    assert_array_equal(ct.fit(X_df).transform(X_df), np.empty((3, 0)))\n    assert callable(ct.transformers[0][2])\n    assert ct.transformers_[0][2] == []\n"], "sample_945": ["def test_pyfunction_with_default_value(app):\n    text = \".. py:function:: hello(name='World') -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, ([desc_parameter, ([desc_sig_name, \"name\"],\n                                                        [desc_sig_operator, \"=\"],\n                                                        [nodes.inline, \"'World'\"])])])\n"], "sample_571": ["def test_regplot_line_kws(self):\n\n    f, ax = plt.subplots()\n    color = 'r'\n    ax = lm.regplot(x=\"x\", y=\"y\", data=self.df,\n                    line_kws={'color': color})\n    assert ax.lines[0].get_color() == color\n\n    f, ax = plt.subplots()\n    linewidth = 2\n    ax = lm.regplot(x=\"x\", y=\"y\", data=self.df,\n                    line_kws={'linewidth': linewidth})\n    assert ax.lines[0].get_linewidth() == linewidth\n"], "sample_163": ["def test_user_change_different_user_email(self):\n    u = User.objects.get(email=\"staffmember@example.com\")\n    original_email = u.email\n    new_email = \"new_\" + original_email\n    response = self.client.post(\n        reverse(\"auth_test_admin:auth_user_change\", args=(u.pk,)),\n        self.get_user_data(u) | {\"email\": new_email},\n    )\n    self.assertRedirects(response, reverse(\"auth_test_admin:auth_user_changelist\"))\n    row = LogEntry.objects.latest(\"id\")\n    self.assertEqual(row.user_id, self.admin.pk)\n    self.assertEqual(row.object_id, str(u.pk))\n    self.assertEqual(row.get_change_message(), \"Changed Email address.\")\n    u.refresh_from_db()\n    self.assertEqual(u.email, new_email)\n"], "sample_637": ["def test_regex_codetag(self) -> None:\n    code = \"\"\"a = 1\n            # HACK\n            \"\"\"\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"fixme\", line=2, args=\"HACK\", col_offset=17)\n    ):\n        self.checker.process_tokens(_tokenize_str(code))\n"], "sample_667": ["def test_tmp_path_factory_with_read_only_files(testdir):\n    \"\"\"Integration test for #5524 with tmp_path_factory\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import os\n        import stat\n\n            tmp_path = tmp_path_factory.mktemp('test')\n            fn = tmp_path / 'foo.txt'\n            fn.write_text('hello')\n            mode = os.stat(str(fn)).st_mode\n            os.chmod(str(fn), mode & ~stat.S_IREAD)\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--basetemp=tmp\")\n    assert result.ret == 0\n    # running a second time and ensure we don't crash\n    result = testdir.runpytest(\"--basetemp=tmp\")\n    assert result.ret == 0\n"], "sample_337": ["def test_https_good_referer_matches_cookie_domain_with_port(self):\n    \"\"\"\n    A POST HTTPS request with a good referer should be accepted from a\n    subdomain that's allowed by CSRF_COOKIE_DOMAIN and a non-standard port.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['HTTP_REFERER'] = 'https://foo.example.com:8080/'\n    req.META['SERVER_PORT'] = '8080'\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.process_request(req)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n"], "sample_59": ["def test_model_with_order_with_respect_to(self):\n    \"\"\"\n    Test the order_with_respect_to feature of the model.\n    \"\"\"\n    department = Department.objects.create(name=\"IT\")\n    worker1 = Worker.objects.create(department=department, name=\"Worker 1\")\n    worker2 = Worker.objects.create(department=department, name=\"Worker 2\")\n\n    # Test get_next_in_order and get_previous_in_order methods\n    self.assertEqual(worker1.get_next_in_order(), worker2)\n    self.assertEqual(worker2.get_previous_in_order(), worker1)\n\n    # Test set_order method\n    department.set_worker_order([worker2.pk, worker1.pk])\n    worker1.refresh_from_db()\n    worker2.refresh_from_db()\n    self.assertEqual(worker1.get_next_in_order(), worker2)\n    self.assertEqual(worker2.get_previous_in_order(), worker1)\n"], "sample_1085": ["def test_Float_floordiv():\n    assert Float(2.5)//Float(0.5) == 5.0\n    assert Float(2.5)//Float(1.5) == 1.0\n    assert Float(2.5)//Float(2.5) == 1.0\n    assert Float(2.5)//Float(3.5) == 0.0\n    assert Float(2.5)//Float(-0.5) == -5.0\n    assert Float(2.5)//Float(-1.5) == -2.0\n    assert Float(2.5)//Float(-2.5) == -1.0\n    assert Float(2.5)//Float(-3.5) == -1.0\n"], "sample_54": ["def test_file_from_buffer_with_filename(self):\n    response = FileResponse(io.BytesIO(b'binary content'), filename='test.txt')\n    self.assertEqual(response['Content-Length'], '14')\n    self.assertEqual(response['Content-Type'], 'text/plain')\n    self.assertEqual(response['Content-Disposition'], 'inline; filename=\"test.txt\"')\n    self.assertEqual(list(response), [b'binary content'])\n"], "sample_491": ["def test_custom_renderer_field_template_name_override(self):\n    class Person(Form):\n        first_name = CharField(template_name=\"forms_tests/custom_field.html\")\n\n    get_default_renderer.cache_clear()\n    t = Template(\"{{ form.first_name.as_field_group }}\")\n    html = t.render(Context({\"form\": Person()}))\n    expected = \"\"\"\n    <label for=\"id_first_name\">First name:</label>\n    <p>Custom Field<p>\n    <input type=\"text\" name=\"first_name\" required id=\"id_first_name\">\n    \"\"\"\n    self.assertHTMLEqual(html, expected)\n    get_default_renderer.cache_clear()\n"], "sample_327": ["def test_custom_encoder_decoder_with_invalid_json(self):\n    class CustomDecoder(json.JSONDecoder):\n            return super().__init__(object_hook=self.as_uuid, *args, **kwargs)\n\n            if 'uuid' in dct:\n                dct['uuid'] = uuid.UUID(dct['uuid'])\n            return dct\n\n    field = JSONField(encoder=DjangoJSONEncoder, decoder=CustomDecoder)\n    with self.assertRaisesMessage(ValidationError, 'Enter a valid JSON.'):\n        field.clean('{some badly formed: json}')\n"], "sample_450": ["def test_get_admin_log_tag(self):\n    \"\"\"\n    Test the 'get_admin_log' template tag.\n    \"\"\"\n    # Create some additional log entries for testing\n    for i in range(5):\n        LogEntry.objects.log_action(\n            self.user.pk,\n            ContentType.objects.get_for_model(Article).pk,\n            self.a1.pk,\n            repr(self.a1),\n            CHANGE,\n            change_message=f\"Changed something {i}\",\n        )\n\n    # Render a template with the 'get_admin_log' tag\n    template = Template(\n        \"{% load admin_log %}\"\n        \"{% get_admin_log 3 as admin_log for_user user %}\"\n    )\n    context = Context({\"log_entries\": LogEntry.objects.all(), \"user\": self.user})\n    rendered = template.render(context)\n\n    # Check that the correct number of log entries are returned\n    self.assertEqual(len(context[\"admin_log\"]), 3)\n\n    # Check that the log entries are for the correct user\n    for log_entry in context[\"admin_log\"]:\n        self.assertEqual(log_entry.user, self.user)\n\n    # Check that the log entries are ordered by action_time\n    action_times = [log_entry.action_time for log_entry in context[\"admin_log\"]]\n    self.assertEqual(action_times, sorted(action_times, reverse=True))\n"], "sample_856": ["def test_leave_p_out_empty_trainset_with_groups():\n    cv = LeavePGroupsOut(n_groups=2)\n    X, y = [[1], [2]], [0, 3]  # 2 samples\n    with pytest.raises(\n            ValueError,\n            match=\"The groups parameter contains fewer than \\\\(or equal to\\\\) n_groups \\\\(2\\\\) numbers of unique groups \\\\(2\\\\). LeavePGroupsOut expects that at least n_groups \\\\+ 1 \\\\(3\\\\) unique groups be present\"):\n        next(cv.split(X, y, groups=[1, 1]))\n"], "sample_875": ["def test_classification_metric_multiclass(metric):\n    \"\"\"Check that the metric works with multiclass inputs.\"\"\"\n    rng = np.random.RandomState(42)\n    n_samples, n_classes = 10, 3\n    y_true = rng.randint(0, n_classes, size=n_samples)\n    y_pred = rng.randint(0, n_classes, size=n_samples)\n    result = metric(y_true, y_pred, average=\"macro\")\n    assert not np.any(np.isnan(result))\n"], "sample_980": ["def test_commutes_with():\n    p = Permutation([1, 5, 2, 0, 3, 6, 4])\n    q = Permutation([[1, 2, 3, 5, 6], [0, 4]])\n    assert p.commutes_with(q) == False\n    assert q.commutes_with(p) == False\n    r = Permutation([3, 2, 1, 0])\n    assert p.commutes_with(r) == False\n    assert r.commutes_with(p) == False\n    assert q.commutes_with(r) == False\n    assert r.commutes_with(q) == False\n    s = Permutation([0, 1, 2, 3])\n    assert p.commutes_with(s) == False\n    assert s.commutes_with(p) == False\n    assert q.commutes_with(s) == True\n    assert s.commutes_with(q) == True\n    assert r.commutes_with(s) == True\n    assert s.commutes_with(r) == True\n"], "sample_824": ["def test_pairwise_distances_precomputed_non_negative():\n    # Test non-negative values\n    assert_raises_regexp(ValueError, '.* non-negative values.*',\n                         pairwise_distances, np.full((5, 5), -1),\n                         metric='precomputed')\n"], "sample_438": ["def test_get_object_cache_respects_deleted_objects_with_generic_relation(self):\n    question = Question.objects.create(text=\"Who?\")\n    answer = Answer.objects.create(text=\"Answer\", question=question)\n\n    question_pk = question.pk\n    Question.objects.all().delete()\n\n    answer = Answer.objects.get(pk=answer.pk)\n    with self.assertNumQueries(1):\n        self.assertEqual(answer.object_id, question_pk)\n        self.assertIsNone(answer.question)\n        self.assertIsNone(answer.question)\n"], "sample_671": ["def test_skip_with_allow_module_level(testdir):\n    \"\"\"\n    Verify that using pytest.skip(allow_module_level=True) at module level is allowed\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        pytest.skip(\"skip_module_level\", allow_module_level=True)\n\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxs\")\n    result.stdout.fnmatch_lines([\"*SKIP*skip_module_level\"])\n"], "sample_564": ["def test_scatter_masked_color_with_none():\n    \"\"\"\n    Test color parameter usage with None in the coordinate arrays.\n\n    GH#26236\n    \"\"\"\n\n    x = [None, 1, 2,  1]\n    y = [0, np.inf, 2,  1]\n    z = [0, 1, -np.inf, 1]\n    colors = [\n        [0.0, 0.0, 0.0, 1],\n        [0.0, 0.0, 0.0, 1],\n        [0.0, 0.0, 0.0, 1],\n        [0.0, 0.0, 0.0, 1]\n    ]\n\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    path3d = ax.scatter(x, y, z, color=colors)\n\n    # Assert sizes' equality\n    assert len(path3d.get_offsets()) ==\\\n           len(super(type(path3d), path3d).get_facecolors())\n"], "sample_1078": ["def test_Indexed_derivative_with_IndexedBase():\n    A = IndexedBase(\"A\")\n    i, j, k = symbols(\"i,j,k\")\n    assert A[i].diff(A[j]) == KroneckerDelta(i, j)\n    assert A[i].diff(A[i]) == 1\n    assert A[i].diff(A[k]) == KroneckerDelta(i, k)\n    assert A[i].diff(A[i], A[j]) == 0\n    assert A[i].diff(A[j], A[i]) == 0\n    assert A[i].diff(A[i], A[i]) == 0\n"], "sample_1131": ["def test_log2():\n    from sympy import log\n    from sympy.functions import log2\n\n    expr = log(x, 2)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr) == 'numpy.log2(x)'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr) == 'numpy.log(x)/numpy.log(2)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr) == 'math.log(x)/math.log(2)'\n\n    prntr = MpmathPrinter()\n    assert prntr.doprint(expr) == 'mpmath.log(x)/mpmath.log(2)'\n\n    prntr = PythonCodePrinter({'allow_unknown_functions': True})\n    assert prntr.doprint(log2(x)) == 'log2(x)'\n"], "sample_787": ["def test_balanced_accuracy_score_sample_weight():\n    y_true = ['a', 'b', 'a', 'b']\n    y_pred = ['a', 'a', 'a', 'b']\n    sample_weight = [1, 1, 2, 1]\n    macro_recall = recall_score(y_true, y_pred, average='macro', labels=np.unique(y_true), sample_weight=sample_weight)\n    with ignore_warnings():\n        # Warnings are tested in test_balanced_accuracy_score_unseen\n        balanced = balanced_accuracy_score(y_true, y_pred, sample_weight=sample_weight)\n    assert balanced == pytest.approx(macro_recall)\n    adjusted = balanced_accuracy_score(y_true, y_pred, adjusted=True, sample_weight=sample_weight)\n    chance = balanced_accuracy_score(y_true, np.full_like(y_true, y_true[0]), sample_weight=sample_weight)\n    assert adjusted == (balanced - chance) / (1 - chance)\n"], "sample_1108": ["def test_has_variety():\n    assert has_variety((1, 2, 1)) is True\n    assert has_variety((1, 1, 1)) is False\n"], "sample_820": ["def test_sample_weight_regressor():\n    \"\"\"Tests sample_weight parameter of VotingRegressor\"\"\"\n    reg1 = DummyRegressor(strategy='mean')\n    reg2 = DummyRegressor(strategy='median')\n    ereg1 = VotingRegressor([('mean', reg1), ('median', reg2)], weights=[1, 2]).fit(X_r, y_r, sample_weight=np.ones((len(y_r),)))\n    ereg2 = VotingRegressor([('mean', reg1), ('median', reg2)], weights=[1, 2]).fit(X_r, y_r)\n    assert_array_equal(ereg1.predict(X_r), ereg2.predict(X_r))\n\n    sample_weight = np.random.RandomState(123).uniform(size=(len(y_r),))\n    ereg3 = VotingRegressor([('mean', reg1)], weights=[1])\n    ereg3.fit(X_r, y_r, sample_weight)\n    reg1.fit(X_r, y_r, sample_weight)\n    assert_array_equal(ereg3.predict(X_r), reg1.predict(X_r))\n\n    # check that an error is raised and indicative if sample_weight is not\n    # supported.\n    reg3 = RandomForestRegressor(n_estimators=5)\n    ereg3 = VotingRegressor([('mean', reg1), ('rf', reg3)], weights=[1, 2])\n    msg = ('Underlying estimator RandomForestRegressor does not support '\n           'sample weights.')\n    with pytest.raises(ValueError, match=msg):\n        ereg3.fit(X_r"], "sample_221": ["def test_filter_with_expression(self):\n    qs = Happening.objects.filter(number1=models.F('number2'))\n    self.assert_pickles(qs)\n"], "sample_999": ["def test_Quaternion_latex_printing_with_zero_components():\n    q = Quaternion(0, 0, 0, 0)\n    assert latex(q) == \"0\"\n    q = Quaternion(0, 0, 0, t)\n    assert latex(q) == \"t k\"\n    q = Quaternion(0, 0, z, 0)\n    assert latex(q) == \"z j\"\n    q = Quaternion(0, y, 0, 0)\n    assert latex(q) == \"y i\"\n    q = Quaternion(x, 0, 0, 0)\n    assert latex(q) == str(x)\n"], "sample_821": ["def test_affinity_propagation_single_sample():\n    # Test AffinityPropagation with a single sample\n    X = np.array([[0, 0]])\n    S = -euclidean_distances(X, squared=True)\n\n    # setting preference > similarity\n    cluster_center_indices, labels = assert_warns_message(\n        UserWarning, \"mutually equal\", affinity_propagation, S, preference=0)\n\n    # expect the single sample to become an exemplar\n    assert_array_equal([0], cluster_center_indices)\n    assert_array_equal([0], labels)\n\n    # setting preference < similarity\n    cluster_center_indices, labels = assert_warns_message(\n        UserWarning, \"mutually equal\", affinity_propagation, S, preference=-10)\n\n    # expect one cluster, with the single sample as exemplar\n    assert_array_equal([0], cluster_center_indices)\n    assert_array_equal([0], labels)\n"], "sample_284": ["def test_template_tag_with_unicode(self):\n    relpath = self.hashed_file_path(\"unicode/file.txt\")\n    self.assertEqual(relpath, \"unicode/file.dad0999e4f8f.txt\")\n    with storage.staticfiles_storage.open(relpath) as relfile:\n        content = relfile.read().decode('utf-8')\n        self.assertEqual(content, \"This is a unicode file with content: \u4f60\u597d\uff0c\u4e16\u754c\")\n    self.assertPostCondition()\n"], "sample_349": ["def test_render_options_with_custom_to_field(self):\n    beatles = Band.objects.create(name='The Beatles', style='rock')\n    rubber_soul = Album.objects.create(name='Rubber Soul', band=beatles)\n    release_event = ReleaseEvent.objects.create(name='Test Target', album=rubber_soul)\n    form = VideoStreamForm(initial={'release_event': release_event.name})\n    output = form.as_table()\n    selected_option = '<option value=\"%s\" selected>Test Target</option>' % release_event.pk\n    self.assertIn(selected_option, output)\n"], "sample_960": ["def test_pyfunction_with_positional_only_arguments(app):\n    text = \".. py:function:: hello(a, /, b)\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, ([desc_parameter, desc_sig_name, \"a\"],\n                                      [desc_parameter, desc_sig_operator, \"/\"],\n                                      [desc_parameter, desc_sig_name, \"b\"])])\n"], "sample_4": ["def test_readwrite_html_table_bad_format(self, cosmo, write, tmp_path):\n    \"\"\"Test if the format is not 'ascii.html'.\"\"\"\n    fp = tmp_path / \"test_readwrite_html_table_bad_format.html\"\n\n    with pytest.raises(ValueError, match=\"format must be 'ascii.html', not 'ascii.csv'\"):\n        write(fp, format=\"ascii.csv\")\n"], "sample_464": ["def test_content_length_file_like_object(self):\n    class FileLikeObject:\n            self.content = content\n            self.position = 0\n\n            if n_bytes == -1:\n                result = self.content[self.position:]\n                self.position = len(self.content)\n            else:\n                result = self.content[self.position:self.position + n_bytes]\n                self.position += n_bytes\n            return result\n\n            if whence == io.SEEK_SET:\n                self.position = offset\n            elif whence == io.SEEK_CUR:\n                self.position += offset\n            elif whence == io.SEEK_END:\n                self.position = len(self.content) + offset\n\n            return True\n\n    content = b\"binary content\"\n    file_like_object = FileLikeObject(content)\n    response = FileResponse(file_like_object)\n    self.assertEqual(response.headers[\"Content-Length\"], str(len(content)))\n"], "sample_1055": ["def test_decipher_shift_with_symbols():\n    assert decipher_shift(\"ZAB\", -1, symbols=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\") == \"ABC\"\n"], "sample_1070": ["def test_exp_power():\n    x = Symbol('x')\n    assert exp(x)**2 == exp(2*x)\n    assert exp(x)**(1/2) == exp(x/2)\n    assert exp(x)**(-1) == exp(-x)\n    assert exp(x)**y == exp(x*y)\n"], "sample_1127": ["def test_coset_class_exceptions():\n    a = Permutation(1, 2)\n    b = Permutation(0, 1)\n    G = PermutationGroup([a, b])\n    g = Permutation(0, 1, 2, 3)\n    H = PermutationGroup([g])\n    with pytest.raises(ValueError):\n        Coset(a, H, G)\n    with pytest.raises(ValueError):\n        Coset(g, G, H)\n    with pytest.raises(NotImplementedError):\n        Coset(1, G)\n    with pytest.raises(NotImplementedError):\n        Coset(a, 1)\n    with pytest.raises(NotImplementedError):\n        Coset(a, G, 1)\n    with pytest.raises(TypeError):\n        Coset(a, G, dir=1)\n    with pytest.raises(ValueError):\n        Coset(a, G, dir='-+')\n"], "sample_518": ["def test_default_fill():\n    patch = Patch()\n    assert patch.get_fill() is True\n"], "sample_654": ["def test_fixture_param_shadowing_indirect_param(arg2):\n    assert arg2 == 2\n"], "sample_574": ["def test_tick_locator_input_check(self, t):\n\n    err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n    with pytest.raises(TypeError, match=err):\n        Temporal().tick((1, 2))\n"], "sample_648": ["def test_mark_mro_with_duplicates() -> None:\n    xfail = pytest.mark.xfail\n\n    @xfail(\"a\")\n    @xfail(\"b\")\n    class A:\n        pass\n\n    @xfail(\"b\")\n    @xfail(\"c\")\n    class B:\n        pass\n\n    @xfail(\"c\")\n    @xfail(\"d\")\n    class C(A, B):\n        pass\n\n    from _pytest.mark.structures import get_unpacked_marks\n\n    all_marks = get_unpacked_marks(C)\n\n    assert all_marks == [xfail(\"c\").mark, xfail(\"d\").mark, xfail(\"a\").mark, xfail(\"b\").mark]\n\n    assert get_unpacked_marks(C, consider_mro=False) == [xfail(\"c\").mark, xfail(\"d\").mark]\n"], "sample_596": ["def test_concat_coords_different_with_override():\n    ds1 = Dataset({\"a\": (\"x\", [0, 1])}, coords={\"x\": [0, 1], \"y\": 1})\n    ds2 = Dataset({\"a\": (\"x\", [2, 3])}, coords={\"x\": [2, 3], \"y\": 2})\n\n    with pytest.raises(ValueError, match=\"Cannot specify both coords='different' and compat='override'.\"):\n        concat([ds1, ds2], dim=\"x\", coords=\"different\", compat=\"override\")\n"], "sample_891": ["def test_roc_curve_with_probablity_estimates_threshold_limit(global_random_seed):\n    \"\"\"Check that thresholds do not exceed 1.0 when `y_score` is a probability\n    estimate and the maximum value is greater than 1.0.\n\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/26193\n    \"\"\"\n    rng = np.random.RandomState(global_random_seed)\n    y_true = rng.randint(0, 2, size=10)\n    y_score = rng.rand(10) * 2  # values greater than 1.0\n    _, _, thresholds = roc_curve(y_true, y_score)\n    assert np.isinf(thresholds[0])\n    assert np.all(thresholds[1:] <= 1.0)\n"], "sample_229": ["def test_union_with_different_values(self):\n    qs1 = Number.objects.filter(num=1).values('num')\n    qs2 = Number.objects.filter(num=2).values('other_num')\n    msg = \"Merging 'QuerySet' classes must involve the same values in each case.\"\n    with self.assertRaisesMessage(TypeError, msg):\n        qs1.union(qs2)\n"], "sample_535": ["def test_cell_alignment():\n    cellText = [['Left', 'Center', 'Right'],\n                ['Left', 'Center', 'Right']]\n    locs = ['left', 'center', 'right']\n\n    _, axs = plt.subplots(nrows=len(locs), figsize=(4, len(locs)+1))\n    for ax, loc in zip(axs, locs):\n        ax.table(\n                cellText=cellText,\n                loc='center',\n                cellLoc=loc,\n                )\n        ax.axis('off')\n    plt.tight_layout()\n"], "sample_286": ["def test_refresh_fk_on_delete_cascade(self):\n    a = Article.objects.create(\n        headline='Parrot programs in Python',\n        pub_date=datetime(2005, 7, 28),\n    )\n    s1 = SelfRef.objects.create(article=a)\n    a.delete()\n    with self.assertRaises(ObjectDoesNotExist):\n        s1.refresh_from_db()\n"], "sample_471": ["def test_integerfield_step_size_max_value(self):\n    f = IntegerField(step_size=3, max_value=10)\n    self.assertWidgetRendersTo(\n        f,\n        '<input name=\"f\" max=\"10\" step=\"3\" type=\"number\" id=\"id_f\" required>',\n    )\n    msg = (\n        \"Ensure this value is a multiple of step size 3, up to 10, e.g. 0, 3, 6, 9, and so on.\"\n    )\n    with self.assertRaisesMessage(ValidationError, msg):\n        f.clean(\"11\")\n    self.assertEqual(f.clean(\"9\"), 9)\n    self.assertEqual(f.clean(\"0\"), 0)\n    self.assertEqual(f.step_size, 3)\n"], "sample_426": ["def test_years_edge(self):\n    t = datetime.datetime(2000, 1, 1)\n    tests = [\n        (datetime.datetime(2000, 12, 31), \"11\\xa0months, 3\\xa0weeks, 6\\xa0days\"),\n        (datetime.datetime(2001, 1, 1), \"1\\xa0year\"),\n        (datetime.datetime(2001, 12, 31), \"1\\xa0year, 11\\xa0months, 3\\xa0weeks, 6\\xa0days\"),\n        (datetime.datetime(2002, 1, 1), \"2\\xa0years\"),\n        (datetime.datetime(2002, 12, 31), \"2\\xa0years, 11\\xa0months, 3\\xa0weeks, 6\\xa0days\"),\n        (datetime.datetime(2003, 1, 1), \"3\\xa0years\"),\n        (datetime.datetime(2003, 12, 31), \"3\\xa0years, 11\\xa0months, 3\\xa0weeks, 6\\xa0days\"),\n        (datetime.datetime(2004, 1, 1), \"4\\xa0years\"),\n        (datetime.datetime(2004, 12, 31), \"4\\xa0years, 11\\xa0months, 3\\xa0weeks, 6\\xa0days\"),\n        (datetime.datetime(2005, 1, 1), \"5\\xa0years\"),\n        (datetime.datetime(2005, 12, 31), \"5\\xa0years, 11\\xa0months, 3\\xa0weeks, 6\\xa0days\"),\n        (datetime.datetime(2006, 1, 1), \"6\\xa0years\"),\n        (datetime.datetime(2006, 12, "], "sample_801": ["def test_simple_imputer():\n    # Render a SimpleImputer object\n    imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\", fill_value=None, verbose=0, copy=True)\n    expected = \"\"\""], "sample_283": ["def test_no_dbname_or_service(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env({\n            'USER': 'someuser',\n            'HOST': 'somehost',\n            'PORT': '444',\n        }), (\n            ['psql', '-U', 'someuser', '-h', 'somehost', '-p', '444', 'postgres'],\n            {},\n        )\n    )\n"], "sample_733": ["def test_vectorizer_max_features_with_stop_words():\n    # Test that max_features works correctly when stop_words is set\n    expected_vocabulary = set(['burger', 'beer', 'salad'])\n    expected_stop_words = set([u'celeri', u'tomato', u'copyright', u'coke',\n                               u'sparkling', u'water', u'the', u'pizza'])\n\n    vectorizer = CountVectorizer(max_df=0.6, max_features=3, stop_words=['pizza'])\n    vectorizer.fit(ALL_FOOD_DOCS)\n    assert_equal(set(vectorizer.vocabulary_), expected_vocabulary)\n    assert_equal(vectorizer.stop_words_, expected_stop_words)\n"], "sample_716": ["def test_ridge_classifier_cv_no_support_multilabel():\n    X, y = make_multilabel_classification(n_samples=10, random_state=0)\n    assert_raises(ValueError, RidgeClassifierCV().fit, X, y)\n"], "sample_833": ["def test_logistic_regression_path_intercept_scaling():\n    # Test that intercept_scaling is ignored when fit_intercept is False\n    X, y = make_classification(n_samples=1000, random_state=0)\n    lr = LogisticRegression(fit_intercept=False, intercept_scaling=2, solver='liblinear')\n    lr.fit(X, y)\n    assert_equal(lr.intercept_, 0.)\n"], "sample_986": ["def test_evalf_complex_accuracy():\n    assert complex_accuracy((from_float(2.0), from_float(10.0), 35, 100)) == 37\n    assert complex_accuracy((from_float(2.0), from_float(1000.0), 35, 100)) == 43\n    assert complex_accuracy((from_float(2.0), from_float(10.0), 100, 35)) == 35\n    assert complex_accuracy((from_float(2.0), from_float(1000.0), 100, 35)) == 35\n"], "sample_120": ["def test_serialize_model_with_custom_manager(self):\n    class CustomManager(models.Manager):\n            return self.filter(is_active=True)\n\n    class CustomModel(models.Model):\n        objects = CustomManager()\n\n    self.assertSerializedEqual(CustomModel.objects)\n    self.assertSerializedResultEqual(\n        CustomModel.objects,\n        (\"migrations.test_writer.CustomModel.objects\", {'import migrations.test_writer'})\n    )\n"], "sample_594": ["def test_format_timedelta_out_of_bounds():\n    from datetime import timedelta\n\n    delta = timedelta(days=1000000)\n    expected = \"11574 days 00:00:00\"\n    result = formatting.format_timedelta(delta)\n    assert result == expected\n\n    delta = timedelta(days=-1000000)\n    expected = \"-11574 days +00:00:00\"\n    result = formatting.format_timedelta(delta)\n    assert result == expected\n"], "sample_1200": ["def test_physical_constant_properties():\n    from sympy.physics.units import definitions\n\n    for name in dir(definitions):\n        quantity = getattr(definitions, name)\n        if not isinstance(quantity, Quantity):\n            continue\n        if name.endswith('_constant'):\n            assert quantity.is_physical_constant, f\"{name} is not marked as physics constant when it should be\"\n            assert quantity.is_constant, f\"{name} is not marked as constant when it should be\"\n            assert quantity.is_commutative, f\"{name} is not marked as commutative when it should be\"\n            assert quantity.is_real, f\"{name} is not marked as real when it should be\"\n            assert quantity.is_finite, f\"{name} is not marked as finite when it should be\"\n\n    for const in [gravitational_constant, molar_gas_constant, vacuum_permittivity, speed_of_light, elementary_charge]:\n        assert const.is_physical_constant, f\"{const} is not marked as physics constant when it should be\"\n        assert const.is_constant, f\"{const} is not marked as constant when it should be\"\n        assert const.is_commutative, f\"{const} is not marked as commutative when it should be\"\n        assert const.is_real, f\"{const} is not marked as real when it should be\"\n        assert const.is_finite, f\"{const} is not marked as finite when it should be\"\n\n    assert not meter.is_physical_constant\n    assert not meter.is_constant\n    assert not joule.is_physical_constant\n    assert not joule.is_constant\n"], "sample_13": ["def test_angle_from_quantity():\n    \"\"\"\n    Test creating an Angle from a Quantity\n    \"\"\"\n    q = u.Quantity(54.12412, unit=u.degree)\n    a = Angle(q)\n    assert_allclose(a.degree, 54.12412)\n\n    q = u.Quantity(3.60827466667, unit=u.hour)\n    a = Angle(q)\n    assert_allclose(a.hour, 3.60827466667)\n\n    q = u.Quantity(0.944644098745, unit=u.radian)\n    a = Angle(q)\n    assert_allclose(a.radian, 0.944644098745)\n"], "sample_921": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n    @singledispatch\n        pass\n\n    @func.register(int)\n        pass\n\n    assert inspect.is_singledispatch_function(func) is True\n    assert inspect.is_singledispatch_function(func.register) is False\n\n        pass\n\n    assert inspect.is_singledispatch_function(not_singledispatch) is False\n"], "sample_456": ["def test_formset_with_custom_deletion_widget(self):\n    \"\"\"FormSets with custom deletion widget.\"\"\"\n    class CustomDeletionWidget(CheckboxInput):\n            default_attrs = {'class': 'custom-deletion-widget'}\n            if attrs is not None:\n                default_attrs.update(attrs)\n            super().__init__(attrs=default_attrs, check_test=check_test)\n\n    class CustomDeletionFormSet(BaseFormSet):\n        deletion_widget = CustomDeletionWidget\n\n    ChoiceFormSet = formset_factory(Choice, formset=CustomDeletionFormSet, can_delete=True)\n    initial = [\n        {\"choice\": \"Calexico\", \"votes\": 100},\n        {\"choice\": \"Fergie\", \"votes\": 900},\n    ]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix=\"choices\")\n    self.assertHTMLEqual(\n        \"\\n\".join(form.as_ul() for form in formset.forms),\n        '<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"choices-0-votes\" value=\"100\"></li>'\n        '<li>Delete: <input class=\"custom-deletion-widget\" type=\"checkbox\" name=\"choices-0-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"choices-1-choice\" value=\"Fergie\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"choices-1-votes\" value=\"900\"></li>'\n        '<li>Delete: <input class=\"custom-deletion-widget\" type=\"checkbox\" name=\"choices-1-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"choices-2-choice\"></li>'\n        '<li>Votes: <input"], "sample_585": ["def test_groupby_da_binary_op():\n    # test binary operations with groupby for DataArray\n    array1 = xr.DataArray([1, 2, 3], [('x', [1, 2, 3])])\n    array2 = xr.DataArray([4, 5, 6], [('x', [1, 2, 3])])\n    expected = xr.DataArray([5, 7, 9], [('x', [1, 2, 3])])\n    actual = array1.groupby('x') + array2\n    assert_identical(expected, actual)\n"], "sample_147": ["def test_union_with_values_list_and_distinct(self):\n    ReservedName.objects.bulk_create([\n        ReservedName(name='rn1', order=1),\n        ReservedName(name='rn2', order=1),\n        ReservedName(name='rn3', order=2),\n    ])\n    qs1 = ReservedName.objects.filter(order=1)\n    qs2 = ReservedName.objects.filter(order=2)\n    union_qs = qs1.union(qs2)\n    for qs, expected_result in (\n        (union_qs.values_list('order', flat=True).distinct(), [1, 2]),\n        (union_qs.distinct().values_list('order', flat=True), [1, 2]),\n    ):\n        with self.subTest(qs=qs):\n            self.assertEqual(list(qs), expected_result)\n"], "sample_160": ["    def test_grouping_sequence(self):\n        self.assertEqual(nformat(123456789, '.', grouping=(3, 2), thousand_sep=',', force_grouping=True), '12,34,56,78,9')\n        self.assertEqual(nformat(123456789, '.', grouping=(3, 2, 0), thousand_sep=',', force_grouping=True), '123,45,67,89')\n"], "sample_1197": ["def test_physical_constant_conversion():\n    from sympy.physics.units import definitions, joule, second, meter\n\n    for name in dir(definitions):\n        quantity = getattr(definitions, name)\n        if not isinstance(quantity, PhysicalConstant):\n            continue\n        converted_quantity = quantity.convert_to(joule*second/meter**2)\n        assert converted_quantity.is_number, f\"Conversion of {quantity} to joule*second/meter**2 should result in a number, but got {converted_quantity}\"\n"], "sample_751": ["def test_adaboost_classifier_with_sample_weight():\n    # Check classification on a toy dataset with sample weights.\n    sample_weight = np.array([1, 1, 1, 2, 2, 2])\n    for alg in ['SAMME', 'SAMME.R']:\n        clf = AdaBoostClassifier(algorithm=alg, random_state=0)\n        clf.fit(X, y_class, sample_weight=sample_weight)\n        assert_array_equal(clf.predict(T), y_t_class)\n        assert_array_equal(np.unique(np.asarray(y_t_class)), clf.classes_)\n        assert_equal(clf.predict_proba(T).shape, (len(T), 2))\n        assert_equal(clf.decision_function(T).shape, (len(T),))\n"], "sample_892": ["def test_adaboost_classifier_sample_weight_zero():\n    # Test that it gives proper result when sample weight is zero.\n    clf = AdaBoostClassifier()\n    sample_weight = np.zeros(len(y_class))\n    clf.fit(X, y_class, sample_weight=sample_weight)\n    assert len(clf.estimators_) == 0\n"], "sample_860": ["def test_check_array_dtype_stability_with_list_of_lists():\n    # test that lists of lists with ints don't get converted to floats\n    X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n    assert check_array(X).dtype.kind == \"i\"\n    assert check_array(X, ensure_2d=False).dtype.kind == \"i\"\n"], "sample_995": ["def test_Float_complex():\n    assert Float(complex(1, 2)) == 1 + 2*I\n    assert Float(complex(1.5, 2.5)) == 1.5 + 2.5*I\n    assert Float(complex(1, 2), precision=10) == Float(1, precision=10) + Float(2, precision=10)*I\n    assert Float(complex(1.5, 2.5), precision=10) == Float(1.5, precision=10) + Float(2.5, precision=10)*I\n"], "sample_1205": ["def test_PolyElement_imul_num():\n    R, x = ring(\"x\", ZZ)\n    f = x**2 + 2*x + 1\n\n    f.imul_num(3)\n    assert f == 3*x**2 + 6*x + 3\n\n    f = x\n    g = f.imul_num(3)\n    assert g == 3*x and g is not f\n"], "sample_198": ["def test_expression_wrapper_with_none_output_field(self):\n    expr = ExpressionWrapper(Lower(Value('f')))\n    group_by_cols = expr.get_group_by_cols(alias=None)\n    self.assertEqual(group_by_cols, [expr.expression])\n    self.assertIsNone(expr.output_field)\n"], "sample_191": ["def test_watch_dir_with_unresolvable_path_in_glob(self, mocked_modules, notify_mock):\n    path = Path('unresolvable_directory')\n    with mock.patch.object(Path, 'glob', side_effect=FileNotFoundError):\n        self.reloader.watch_dir(path, '**/*.mo')\n    self.assertEqual(list(self.reloader.directory_globs), [])\n"], "sample_629": ["def test_expand_modules_with_ignore_list():\n    files_or_modules = [__file__, Path(__file__).parent]\n    ignore_list = [\"unittest_lint.py\"]\n    ignore_list_re = []\n    ignore_list_paths_re = []\n    expected = [this_file, init_of_package, this_file_from_init]\n    modules, errors = expand_modules(\n        files_or_modules, ignore_list, ignore_list_re, ignore_list_paths_re\n    )\n    modules.sort(key=lambda d: d[\"name\"])\n    assert modules == expected\n    assert not errors\n"], "sample_537": ["def test_psd_twosided_norm():\n    u = np.array([0, 1, 2, 3, 1, 2, 1])\n    dt = 1.0\n    Su = np.abs(np.fft.fft(u) * dt)**2 / (dt * u.size)\n    P, f = mlab.psd(u, NFFT=u.size, Fs=1/dt, window=mlab.window_none,\n                    detrend=mlab.detrend_none, noverlap=0, pad_to=None,\n                    scale_by_freq=None,\n                    sides='twosided')\n    assert_allclose(P, Su, atol=1e-06)\n"], "sample_607": ["def test_get_backend_valid_engine():\n    backend = plugins.get_backend(\"dummy\")\n    assert isinstance(backend, DummyBackendEntrypoint1)\n"], "sample_164": ["    def test_server_formatter_with_status_code(self):\n        self.assertLogsRequest(\n            url='/server_error/',\n            level='ERROR',\n            msg='Internal Server Error: /server_error/',\n            status_code=500,\n            logger='django.request',\n        )\n        self.assertIn('HTTP_SERVER_ERROR', self.logger_output.getvalue())\n"], "sample_106": ["def test_cache_key_varies_by_accept_encoding(self):\n    \"\"\"\n    get_cache_key keys differ by Accept-Encoding header\n    \"\"\"\n    request1 = self.factory.get(self.path, HTTP_ACCEPT_ENCODING='gzip')\n    learn_cache_key(request1, HttpResponse())\n    request2 = self.factory.get(self.path, HTTP_ACCEPT_ENCODING='identity')\n    learn_cache_key(request2, HttpResponse())\n    self.assertNotEqual(get_cache_key(request1), get_cache_key(request2))\n"], "sample_16": ["def test_apply_along_axis(self):\n        return np.sum(np.square(x), axis)\n\n    out = np.apply_along_axis(function, self.q, 0)\n    expected = np.apply_along_axis(function, self.q.value, 0)\n    expected = expected * self.q.unit ** 2\n    assert_array_equal(out, expected)\n"], "sample_897": ["def test_plot_partial_dependence_subsampling_with_kind(\n    pyplot, clf_diabetes, diabetes, kind, expected_shape"], "sample_618": ["def test_cross_with_missing_values(a, b, ae, be, dim: str, axis: int, use_dask: bool) -> None:\n    expected = np.cross(ae, be, axis=axis)\n\n    if use_dask:\n        if not has_dask:\n            pytest.skip(\"test for dask.\")\n        a = a.chunk()\n        b = b.chunk()\n\n    actual = xr.cross(a, b, dim=dim)\n    xr.testing.assert_duckarray_allclose(expected, actual)\n"], "sample_992": ["def test_CustomPrintedObject():\n    obj = CustomPrintedObject()\n    assert PythonCodePrinter().doprint(obj) == 'CustomPrintedObject()'\n"], "sample_541": ["def test_polygon_selector_ignore_outside(ax):\n    onselect = mock.Mock(spec=noop, return_value=None)\n\n    tool = widgets.PolygonSelector(ax, onselect, ignore_event_outside=True)\n    event_sequence = [\n        *polygon_place_vertex(50, 50),\n        *polygon_place_vertex(150, 50),\n        *polygon_place_vertex(50, 150),\n        *polygon_place_vertex(50, 50),\n    ]\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n    onselect.assert_called_once()\n    assert tool.verts == [(50, 50), (150, 50), (50, 150)]\n\n    onselect.reset_mock()\n    # Trigger event outside of polygon\n    event_sequence = [\n        *polygon_place_vertex(250, 250),\n        *polygon_place_vertex(260, 260),\n    ]\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n    # event have been ignored and polygon haven't changed.\n    onselect.assert_not_called()\n    assert tool.verts == [(50, 50), (150, 50), (50, 150)]\n"], "sample_330": ["    def test_callproc(self):\n        with mock.patch.object(connection.db, 'validate_no_broken_transaction') as mock_validate:\n            with mock.patch.object(connection.db, 'wrap_database_errors') as mock_wrap:\n                with mock.patch.object(connection.cursor, 'callproc') as mock_callproc:\n                    cursor_wrapper = CursorWrapper(connection.cursor, connection.db)\n                    cursor_wrapper.callproc('procname', params=('param1', 'param2'), kparams=None)\n                    mock_validate.assert_called_once()\n                    mock_wrap.assert_called_once()\n                    mock_callproc.assert_called_once_with('procname', ('param1', 'param2'))\n"], "sample_481": ["def test_join09(self):\n    output = self.engine.render_to_string(\n        \"join09\", {\"a\": [\"alpha\", \"beta & me\"], \"var\": \" & \"}\n    )\n    self.assertEqual(output, \"alpha &amp; beta &amp;amp; me\")\n"], "sample_499": ["def test_legend_title_fontprop_dict():\n    # test the title_fontproperties kwarg with a dict\n    plt.plot(range(10))\n    leg = plt.legend(title='Aardvark', title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg.get_title().get_fontproperties().get_family() == ['serif']\n    assert leg.get_title().get_fontproperties().get_size() == 22\n"], "sample_858": ["def test_voting_regressor_with_1d_y():\n    \"\"\"Check VotingRegressor with 1D y input.\"\"\"\n    reg1 = DummyRegressor(strategy='mean')\n    reg2 = DummyRegressor(strategy='median')\n    ereg = VotingRegressor([('mean', reg1), ('median', reg2)])\n\n    X_r_train, X_r_test, y_r_train, y_r_test = \\\n        train_test_split(X_r, y_r, test_size=.25)\n\n    y_r_train_1d = y_r_train.reshape(-1)\n    y_r_test_1d = y_r_test.reshape(-1)\n\n    ereg.fit(X_r_train, y_r_train_1d)\n    ereg_pred = ereg.predict(X_r_test)\n\n    avg = np.average(np.asarray([reg1.fit(X_r_train, y_r_train_1d).predict(X_r_test),\n                                 reg2.fit(X_r_train, y_r_train_1d).predict(X_r_test)]), axis=0)\n    assert_almost_equal(ereg_pred, avg, decimal=2)\n"], "sample_1121": ["def test_issue_18507_2():\n    assert Mul(zoo, 0, zoo) is nan\n"], "sample_406": ["def test_save_with_update_fields(self):\n    a = Article.objects.create(headline=\"original\", pub_date=datetime(2014, 5, 16))\n    current_id = a.id\n    a.headline = \"Updated headline\"\n    a.save(update_fields=[\"headline\"])\n    self.assertEqual(a.id, current_id)\n    self.assertEqual(Article.objects.get(id=current_id).headline, \"Updated headline\")\n"], "sample_1196": ["def test_contains_with_interval():\n    x = Symbol('x')\n    assert Contains(x, Interval(0, 1)) == (S.Zero <= x) & (x <= 1)\n    assert Contains(2, Interval(0, 1)) is S.false\n    assert Contains(0, Interval(0, 1)) is S.true\n    assert Contains(1, Interval(0, 1)) is S.true\n    assert Contains(0.5, Interval(0, 1)) is S.true\n"], "sample_93": ["def test_aggregate_with_filter(self):\n    # Test aggregate function with filter\n    books = Book.objects.filter(rating__gt=4).aggregate(Avg('price'))\n    self.assertEqual(books['price__avg'], Decimal('75.00'))\n"], "sample_810": ["def test_pipeline_with_fit_params():\n    X = np.array([[1, 2]])\n    y = np.array([0])\n    pipe = Pipeline([('transf', TransfFitParams()), ('clf', Mult())])\n    pipe.fit(X, y, transf__should_get_this=True)\n    assert pipe.named_steps['transf'].fit_params['should_get_this']\n    assert 'should_get_this' not in pipe.named_steps['clf'].fit_params\n"], "sample_433": ["def test_alter_index_together_to_index(self):\n    changes = self.get_changes(\n        [AutodetectorTests.author_empty, self.book_index_together],\n        [AutodetectorTests.author_empty, AutodetectorTests.book_indexes],\n    )\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterIndexTogether\", \"AddIndex\"])\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        0,\n        name=\"book\",\n        index_together=set(),\n    )\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        1,\n        model_name=\"book\",\n        fields=[\"author\", \"title\"],\n        name=\"book_title_author_idx\",\n    )\n"], "sample_83": ["    def setUp(self):\n        self.library = Library()\n"], "sample_43": ["def test_fitness_function_errors():\n    \"\"\"Test errors for fitness functions\"\"\"\n    rng = np.random.RandomState(42)\n\n    # Invalid fitness function\n    t = rng.randn(100)\n    with pytest.raises(ValueError):\n        bayesian_blocks(t, fitness='invalid')\n\n    # Invalid fitness function instance\n    class InvalidFitness(FitnessFunc):\n        pass\n    with pytest.raises(NotImplementedError):\n        bayesian_blocks(t, fitness=InvalidFitness())\n\n    # Invalid fitness function class\n    with pytest.raises(TypeError):\n        bayesian_blocks(t, fitness=int)\n"], "sample_861": ["def test_grid_search_bad_cv():\n    # Use global X, y\n\n    class BrokenKFold(KFold):\n            return 1\n\n    # create bad cv\n    cv = BrokenKFold(n_splits=3)\n\n    train_size = 100\n    grid = GridSearchCV(Ridge(), {'alpha': [1e-3, 1e-2, 1e-1]}, cv=cv)\n\n    # assert that this raises an error\n    with pytest.raises(ValueError,\n                       match='cv.split and cv.get_n_splits returned '\n                             'inconsistent results. Expected \\\\d+ '\n                             'splits, got \\\\d+'):\n        grid.fit(X[:train_size], y[:train_size])\n"], "sample_711": ["def test_node_from_parent_with_path_and_fspath() -> None:\n    path = Path(\"/path/to/test\")\n    fspath = legacy_path(\"/path/to/test\")\n    node = nodes.Node.from_parent(None, path=path, fspath=fspath)\n    assert node.path == path\n    assert node.fspath == fspath\n"], "sample_658": ["def test_doctest_module_with_mock_objects(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        from unittest.mock import Mock\n        class Example(object):\n            '''\n            >>> mock = Mock()\n            >>> mock.method()\n            >>> mock.method.assert_called_once()\n            '''\n        \"\"\"\n    )\n    result = testdir.runpytest(\"--doctest-modules\")\n    result.stdout.fnmatch_lines([\"* 1 passed *\"])\n"], "sample_663": ["def test_collect_pkg_init_only_with_tbstyle(testdir):\n    subdir = testdir.mkdir(\"sub\")\n    init = subdir.ensure(\"__init__.py\")\n    init.write(\"def test_init():\\n    assert 0\")\n\n    result = testdir.runpytest(str(init), \"--tb=native\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*_ ERROR collecting __init__.py _*\",\n            \"Traceback (most recent call last):\",\n            '  File \"__init__.py\", line 2, in test_init',\n            \"    assert 0\",\n            \"AssertionError: assert 0\",\n            \"*! Interrupted: 1 error during collection !*\",\n            \"*= 1 error in *\",\n        ]\n    )\n"], "sample_1198": ["def test_parser_mathematica_special_functions():\n    parser = MathematicaParser()\n\n    chain = lambda expr: parser._from_tokens_to_fullformlist(parser._from_mathematica_to_tokens(expr))\n\n    # Special functions\n    assert chain(\"AiryAi[x]\") == [\"AiryAi\", \"x\"]\n    assert chain(\"AiryAiPrime[x]\") == [\"AiryAiPrime\", \"x\"]\n    assert chain(\"AiryBi[x]\") == [\"AiryBi\", \"x\"]\n    assert chain(\"AiryBiPrime[x]\") == [\"AiryBiPrime\", \"x\"]\n    assert chain(\"LogIntegral[x]\") == [\"LogIntegral\", \"x\"]\n    assert chain(\"PrimePi[x]\") == [\"PrimePi\", \"x\"]\n    assert chain(\"Prime[x]\") == [\"Prime\", \"x\"]\n    assert chain(\"PrimeQ[x]\") == [\"PrimeQ\", \"x\"]\n"], "sample_1017": ["def test_BooleanFunction_diff_multiple_variables():\n    assert And(x, y).diff(z) == S.Zero\n"], "sample_1015": ["def test_ccode_complex_numbers():\n    assert ccode(complex(1, 2)) == '1.0 + 2.0*I'\n    assert ccode(complex(1, 2), type_aliases={real: float32}) == '1.0F + 2.0F*I'\n    assert ccode(complex(1, 2), type_aliases={real: float80}) == '1.0L + 2.0L*I'\n    assert ccode(complex(1, 2), type_aliases={real: complex64}) == '1.0F + 2.0F*I'\n    assert ccode(complex(1, 2), type_aliases={real: complex128}) == '1.0 + 2.0*I'\n"], "sample_1149": ["def test_singleton_registry_sympify():\n    # Test that the SingletonRegistry can be used as a shortcut for sympify\n    assert S(1) == S.Integer(1)\n    assert S(\"x\") == S.Symbol(\"x\")\n    assert S(\"1/2\") == S.Rational(1, 2)\n"], "sample_323": ["def test_minimize_rollbacks_multiple_targets(self):\n    r\"\"\"\n    Minimize rollbacks when targeting multiple apps.\n\n    a: 1 <--- 2\n    b:    \\- 1\n    c:     \\- 1\n\n    If a1 and b1 are applied already and a2 and c1 are not, and we're asked to\n    migrate to a1 and b1, don't apply or unapply c1, regardless of its current\n    state.\n    \"\"\"\n    a1_impl = FakeMigration('a1')\n    a1 = ('a', '1')\n    a2_impl = FakeMigration('a2')\n    a2 = ('a', '2')\n    b1_impl = FakeMigration('b1')\n    b1 = ('b', '1')\n    c1_impl = FakeMigration('c1')\n    c1 = ('c', '1')\n    graph = MigrationGraph()\n    graph.add_node(a1, a1_impl)\n    graph.add_node(a2, a2_impl)\n    graph.add_node(b1, b1_impl)\n    graph.add_node(c1, c1_impl)\n    graph.add_dependency(None, a2, a1)\n    graph.add_dependency(None, b1, a1)\n    graph.add_dependency(None, c1, a1)\n\n    executor = MigrationExecutor(None)\n    executor.loader = FakeLoader(graph, {\n        a1: a1_impl,\n        b1: b1_impl,\n    })\n\n    plan = executor.migration_plan({a1, b1})\n\n    self.assertEqual(plan, [(a2_impl, True)])\n"], "sample_766": ["def test_dict_learning_online_lars_code_positivity():\n    n_components = 8\n    dico = MiniBatchDictionaryLearning(\n        n_components, transform_algorithm=\"lars\", random_state=0,\n        positive_code=True, fit_algorithm='cd').fit(X)\n\n    err_msg = \"Positive constraint not supported for '{}' coding method.\"\n    err_msg = err_msg.format(\"lars\")\n    with pytest.raises(ValueError, match=err_msg):\n        dico.transform(X)\n"], "sample_886": ["def test_set_output_mixin_with_fit_transform():\n    \"\"\"Check that set_output works with fit_transform.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    class EstimatorWithFitTransform(_SetOutputMixin):\n            self.n_features_in_ = X.shape[1]\n            return self\n\n            return X\n\n            return self.fit(X, y).transform(X)\n\n            return np.asarray([f\"X{i}\" for i in range(self.n_features_in_)], dtype=object)\n\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    est = EstimatorWithFitTransform().set_output(transform=\"pandas\")\n\n    X_trans_pd = est.fit_transform(X)\n    assert isinstance(X_trans_pd, pd.DataFrame)\n"], "sample_557": ["def test_get_constrained_layout_pads_relative():\n    params = {'w_pad': 0.01, 'h_pad': 0.02, 'wspace': 0.03, 'hspace': 0.04}\n    expected = tuple([*params.values()])\n    fig = plt.figure(layout=mpl.layout_engine.ConstrainedLayoutEngine(**params))\n    fig.set_size_inches(6, 4)\n    fig.draw_without_rendering()\n    with pytest.warns(PendingDeprecationWarning, match=\"will be deprecated\"):\n        pads = fig.get_constrained_layout_pads(relative=True)\n    np.testing.assert_allclose(pads, (0.01 / 6, 0.02 / 4, 0.03, 0.04))\n"], "sample_1146": ["def test_latex_printing_of_ArrayElement_with_complex_indices():\n    A = ArraySymbol(\"A\", 2, 3, 4)\n    i, j, k = symbols(\"i j k\")\n    element = ArrayElement(A, (i, j, k))\n    assert latex(element) == \"{{A}_{i, j, k}}\"\n"], "sample_358": ["    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'],\n            lambda column: column.upper(),\n            col_suffixes=['ASC', 'DESC'],\n            opclasses=['text_ops', 'varchar_ops'],\n        )\n"], "sample_69": ["    def test_tick_notifies_file_changed(self):\n        reloader = autoreload.StatReloader()\n        reloader.watch_file(Path(__file__))\n        with mock.patch.object(reloader, 'notify_file_changed') as mock_notify:\n            ticker = reloader.tick()\n            next(ticker)\n            self.increment_mtime(Path(__file__))\n            next(ticker)\n            mock_notify.assert_called_once_with(Path(__file__))\n"], "sample_515": ["def test_colorbar_set_ticklabels():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc)\n    cb.set_ticklabels(['a', 'b', 'c', 'd', 'e'])\n    fig.canvas.draw()\n    assert [t.get_text() for t in cb.ax.yaxis.get_ticklabels()] == ['a', 'b', 'c', 'd', 'e']\n"], "sample_510": ["def test_subplot_mosaic_empty_sentinel():\n    fig, ax_dict = plt.subplot_mosaic({'A': [1, 2], 'B': [3, 4]}, empty_sentinel='.')\n    assert 'A' in ax_dict\n    assert 'B' in ax_dict\n    assert '.' not in ax_dict\n"], "sample_341": ["def test_formset_with_deletion_extra_forms(self):\n    \"\"\"\n    FormSet with can_delete and extra forms should have delete checkboxes\n    for all forms.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_delete=True, extra=2)\n    initial = [{'choice': 'Calexico', 'votes': 100}, {'choice': 'Fergie', 'votes': 900}]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_223": ["    def test_ticket_24605_exclude(self):\n        \"\"\"\n        Exclude query with a subquery should work correctly.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(\n            Individual.objects.exclude(Q(alive=False), Q(related_individual__isnull=False)),\n            [i3]\n        )\n"], "sample_1162": ["def test_MatMul_noncommutative():\n    M = Matrix([[1,2],[3,4]])\n    assert MatMul(noncomm_x, M).kind is UndefinedKind\n"], "sample_146": ["def test_valid_script_consistent_language_settings(self):\n    tests = [\n        # language + script.\n        'sr-Latn',\n    ]\n    for tag in tests:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [])\n"], "sample_291": ["def test_template_response_mixin_with_template(self):\n    \"\"\"\n    Test that the TemplateResponseMixin correctly uses the provided template.\n    \"\"\"\n    view = views.TemplateResponseWithTemplate()\n    template_names = view.get_template_names()\n    self.assertEqual(template_names, ['generic_views/test_template.html'])\n"], "sample_754": ["def test_sparse_pca_with_different_methods(norm_comp):\n    rng = np.random.RandomState(0)\n    Y, _, _ = generate_toy_data(3, 10, (8, 8), random_state=rng)\n    spca_lars = SparsePCA(n_components=3, method='lars', random_state=rng, normalize_components=norm_comp)\n    spca_cd = SparsePCA(n_components=3, method='cd', random_state=rng, normalize_components=norm_comp)\n    spca_lars.fit(Y)\n    spca_cd.fit(Y)\n    assert_array_almost_equal(spca_lars.components_, spca_cd.components_)\n"], "sample_29": ["def test_write_latex_valid_format(self, write, tmp_path):\n    \"\"\"Test passing a valid format\"\"\"\n    fp = tmp_path / \"test_write_latex_valid_format.tex\"\n    write(fp, format=\"latex\")\n    assert fp.is_file()\n"], "sample_799": ["def test_fit_and_score_with_scorer_callable():\n    X, y = make_classification(n_samples=30, random_state=0)\n    clf = SVC(kernel=\"linear\", random_state=0)\n    train, test = next(ShuffleSplit().split(X))\n\n        return estimator.score(X_test, y_test)\n\n    fit_and_score_args = [clf, X, y, scorer, train, test, 0]\n    fit_and_score_kwargs = {'parameters': None, 'fit_params': None}\n    result = _fit_and_score(*fit_and_score_args, **fit_and_score_kwargs)\n    assert isinstance(result, float)\n"], "sample_114": ["def test_mti_inheritance_model_addition(self):\n    Animal = ModelState('app', 'Animal', [\n        (\"id\", models.AutoField(primary_key=True)),\n    ])\n    Dog = ModelState('app', 'Dog', [], bases=('app.Animal',))\n    changes = self.get_changes([Animal], [Animal, Dog])\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='Dog')\n"], "sample_804": ["def test_one_hot_encoder_drop_first():\n    enc = OneHotEncoder(drop='first')\n    X = [['abc', 2, 55], ['def', 1, 55], ['abc', 3, 55]]\n    trans = enc.fit_transform(X).toarray()\n    exp = [[0, 1], [1, 0], [1, 1]]\n    assert_array_equal(trans, exp)\n    dropped_cats = [cat[feature]\n                    for cat, feature in zip(enc.categories_,\n                                            enc.drop_idx_)]\n    assert_array_equal(dropped_cats, ['abc', 1, 55])\n    assert_array_equal(np.array(X, dtype=object),\n                       enc.inverse_transform(trans))\n"], "sample_509": ["def test_date_ticker_factory_numticks():\n    span = 0.02\n    numticks = 3\n    locator, _ = mdates.date_ticker_factory(span, numticks=numticks)\n    assert isinstance(locator, mdates.MinuteLocator)\n    assert locator.interval == 2\n"], "sample_872": ["def test_label_ranking_avg_precision_score_should_allow_csc_matrix_for_y_true_input():\n    # Test that label_ranking_avg_precision_score accept sparse y_true.\n    # Non-regression test for #22575\n    y_true = csc_matrix([[1, 0, 0], [0, 0, 1]])\n    y_score = np.array([[0.5, 0.9, 0.6], [0, 0, 1]])\n    result = label_ranking_average_precision_score(y_true, y_score)\n    assert result == pytest.approx(2 / 3)\n"], "sample_1079": ["def test_project():\n    a = Point(1, 2)\n    b = Point(2, 5)\n    z = a.origin\n    p = Point.project(a, b)\n    assert Line(p, a).is_perpendicular(Line(p, b))\n    assert Point.is_collinear(z, p, b)\n"], "sample_1194": ["def test_julia_user_functions():\n    f = Function('f')\n    g = Function('g')\n    custom_functions = {\n        \"f\": \"existing_julia_fcn\",\n        \"g\": [(lambda x: x.is_Matrix, \"my_mat_fcn\"),\n              (lambda x: not x.is_Matrix, \"my_fcn\")]\n    }\n    mat = Matrix([[1, x]])\n    assert julia_code(f(x) + g(x) + g(mat), user_functions=custom_functions) == \\\n           'existing_julia_fcn(x) + my_fcn(x) + my_mat_fcn([1 x])'\n"], "sample_176": ["def test_add_model_with_field_removed_from_base_model_with_m2m(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name, even if the base field is a ManyToManyField.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('tags', models.ManyToManyField('app.Tag')),\n        ]),\n        ModelState('app', 'tag', [\n            ('id', models.AutoField(primary_key=True)),\n            ('name', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'book', [\n            ('tags', models.ManyToManyField('app.Tag')),\n        ], bases=('app.readable',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='tags', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n"], "sample_805": ["def test_regression_metrics_with_sample_weight():\n    y_true = np.array([1, 2, 3, 4, 5])\n    y_pred = np.array([1.2, 2.1, 3.3, 3.9, 5.1])\n    sample_weight = np.array([0.1, 0.2, 0.3, 0.2, 0.2])\n\n    assert_almost_equal(mean_squared_error(y_true, y_pred, sample_weight=sample_weight), 0.028, decimal=2)\n    assert_almost_equal(mean_absolute_error(y_true, y_pred, sample_weight=sample_weight), 0.16, decimal=2)\n    assert_almost_equal(median_absolute_error(y_true, y_pred), 0.2, decimal=2)\n    assert_almost_equal(max_error(y_true, y_pred), 0.3, decimal=2)\n    assert_almost_equal(r2_score(y_true, y_pred, sample_weight=sample_weight), 0.98, decimal=2)\n    assert_almost_equal(explained_variance_score(y_true, y_pred, sample_weight=sample_weight), 0.98, decimal=2)\n"], "sample_885": ["def test_generate_invalid_param_val_real_not_int():\n    \"\"\"Check that the value generated for a \"real_not_int\" interval constraint does not satisfy the constraint.\"\"\"\n    constraint = Interval(\"real_not_int\", 0, 1, closed=\"both\")\n    bad_value = generate_invalid_param_val(constraint)\n    assert not constraint.is_satisfied_by(bad_value)\n"], "sample_168": ["def test_no_stale_content_types(self):\n    \"\"\"\n    The command should not delete any content types if there are no stale content types.\n    \"\"\"\n    with mock.patch('builtins.input', return_value='yes'), captured_stdout() as stdout:\n        call_command('remove_stale_contenttypes', verbosity=2)\n    self.assertNotIn('Deleting stale content type', stdout.getvalue())\n    self.assertEqual(ContentType.objects.count(), self.before_count + 1)\n"], "sample_348": ["    def test_actions_on_get_not_boolean(self):\n        @admin.action(actions_on_top=1)\n            pass\n\n        class BandAdmin(ModelAdmin):\n            actions = (action,)\n\n        self.assertIsInvalid(\n            BandAdmin, Band,\n            \"The value of 'actions_on_top' must be a boolean.\",\n            id='admin.E131',\n            invalid_obj=action,\n        )\n"], "sample_377": ["    def test_sensitive_cookies(self):\n        \"\"\"\n        Sensitive cookies cannot be seen in the default error reports.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            request = self.rf.get(\"/some_url/\")\n            request.COOKIES = {\"sensitive_cookie\": \"sensitive_value\"}\n            response = sensitive_view(request)\n            self.assertNotContains(response, \"sensitive_value\", status_code=500)\n\n        with self.settings(DEBUG=False):\n            request = self.rf.get(\"/some_url/\")\n            request.COOKIES = {\"sensitive_cookie\": \"sensitive_value\"}\n            response = sensitive_view(request)\n            self.assertNotContains(response, \"sensitive_value\", status_code=500)\n"], "sample_1043": ["def test_user_functions():\n        return x**2 + 2*x + 1\n\n    settings = {'user_functions': {'custom_func': 'CustomFunction'}}\n    assert mcode(custom_func(x), **settings) == \"CustomFunction[x]\"\n"], "sample_1123": ["def test_CondSet_union():\n    input_conditionset1 = ConditionSet(x, x > 0, Interval(1, 4, False, False))\n    input_conditionset2 = ConditionSet(x, x < 0, Interval(-4, -1, False, False))\n    output_conditionset = Interval(-4, 4, False, False)\n    assert Union(input_conditionset1, input_conditionset2) == output_conditionset\n"], "sample_1107": ["def test_has_variety():\n    assert has_variety((1, 2, 1)) is True\n    assert has_variety((1, 1, 1)) is False\n"], "sample_129": ["    def test_large_numbers(self):\n        self.assertEqual(floatformat(12345678901234567890.123456789, 2), '12345678901234567890.12')\n        self.assertEqual(floatformat(12345678901234567890.123456789, -2), '12345678901234567890')\n        self.assertEqual(floatformat(12345678901234567890.123456789, 10), '12345678901234567890.1234567890')\n        self.assertEqual(floatformat(12345678901234567890.123456789, -10), '12345678901234567890')\n"], "sample_189": ["def test_cache_versioning_delete_many(self):\n    cache.set('answer1', 37, version=1)\n    cache.set('answer1', 42, version=2)\n    cache.set('answer2', 37, version=1)\n    cache.set('answer2', 42, version=2)\n    self.assertIs(cache.delete_many(['answer1', 'answer2']), None)\n    self.assertIsNone(cache.get('answer1', version=1))\n    self.assertIsNone(cache.get('answer1', version=2))\n    self.assertIsNone(cache.get('answer2', version=1))\n    self.assertIsNone(cache.get('answer2', version=2))\n\n    cache.set('answer3', 37, version=1)\n    cache.set('answer3', 42, version=2)\n    cache.set('answer4', 37, version=1)\n    cache.set('answer4', 42, version=2)\n    self.assertIs(caches['v2'].delete_many(['answer3', 'answer4']), None)\n    self.assertIsNone(cache.get('answer3', version=1))\n    self.assertIsNone(cache.get('answer3', version=2))\n    self.assertIsNone(cache.get('answer4', version=1))\n    self.assertIsNone(cache.get('answer4', version=2))\n"], "sample_136": ["def test_wsgirequest_headers(self):\n    request = WSGIRequest({\n        'PATH_INFO': '/somepath/',\n        'REQUEST_METHOD': 'get',\n        'wsgi.input': BytesIO(b''),\n        'SERVER_NAME': 'internal.com',\n        'SERVER_PORT': 80,\n        'CONTENT_TYPE': 'text/html',\n        'CONTENT_LENGTH': '100',\n        'HTTP_ACCEPT': '*',\n        'HTTP_HOST': 'example.com',\n        'HTTP_USER_AGENT': 'python-requests/1.2.0',\n    })\n    self.assertEqual(dict(request.headers), {\n        'Content-Type': 'text/html',\n        'Content-Length': '100',\n        'Accept': '*',\n        'Host': 'example.com',\n        'User-Agent': 'python-requests/1.2.0',\n    })\n"], "sample_447": ["def test_alias_forbidden_chars(self):\n    tests = [\n        'al\"ias',\n        \"a'lias\",\n        \"ali`as\",\n        \"alia s\",\n        \"alias\\t\",\n        \"ali\\nas\",\n        \"alias--\",\n        \"ali/*as\",\n        \"alias*/\",\n        \"alias;\",\n        # [] are used by MSSQL.\n        \"alias[\",\n        \"alias]\",\n    ]\n    msg = (\n        \"Column aliases cannot contain whitespace characters, quotation marks, \"\n        \"semicolons, or SQL comments.\"\n    )\n    for crafted_alias in tests:\n        with self.subTest(crafted_alias):\n            with self.assertRaisesMessage(ValueError, msg):\n                Book.objects.alias(**{crafted_alias: Value(1)})\n"], "sample_80": ["def test_foreign_key_with_transform(self):\n    query = Query(Item)\n    with register_lookup(CharField, Lower):\n        where = query.build_where(Q(creator__name__lower='foo'))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, Exact)\n    self.assertIsInstance(lookup.lhs, Lower)\n    self.assertIsInstance(lookup.lhs.lhs, SimpleCol)\n    self.assertEqual(lookup.lhs.lhs.target, Author._meta.get_field('name'))\n"], "sample_257": ["def test_key_transform_with_integer_key(self):\n    obj = NullableJSONModel.objects.create(value=[1, 2, 3])\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__1=2),\n        [obj],\n    )\n"], "sample_1030": ["def test_ordered_points():\n    p1, p2, p3 = Point2D(1, 2), Point2D(3, 4), Point2D(2, 1)\n    assert _ordered_points((p1, p2, p3)) == (p3, p1, p2)\n    assert _ordered_points((p2, p1, p3)) == (p3, p1, p2)\n    assert _ordered_points((p3, p2, p1)) == (p3, p1, p2)\n"], "sample_895": ["def test_column_transformer_with_transformer_weights():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n\n    X_res_first = np.array([0, 1, 2]).reshape(-1, 1)\n    X_res_second = np.array([2, 4, 6]).reshape(-1, 1)\n    X_res_both = X_array\n\n    # test with transformer_weights\n    transformer_weights = {\"trans1\": 0.1, \"trans2\": 10}\n    both = ColumnTransformer(\n        [(\"trans1\", Trans(), [0]), (\"trans2\", Trans(), [1])],\n        transformer_weights=transformer_weights,\n    )\n    res = np.vstack(\n        [\n            transformer_weights[\"trans1\"] * X_res_first,\n            transformer_weights[\"trans2\"] * X_res_second,\n        ]\n    ).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    both = ColumnTransformer(\n        [(\"trans\", Trans(), [0, 1])], transformer_weights={\"trans\": 0.1}\n    )\n    assert_array_equal(both.fit_transform(X_array), 0.1 * X_res_both)\n    assert_array_equal(both.fit(X_array).transform(X_array), 0.1 * X_res_both)\n    assert len(both.transformers_) == 1\n"], "sample_199": ["def test_annotation_aggregate_with_m2m(self):\n    qs = Author.objects.filter(age__lt=30).annotate(\n        total_pages=Sum(F('book__pages')),\n    ).values('name', 'total_pages')\n    self.assertCountEqual(qs, [\n        {'name': 'James Bennett', 'total_pages': 300},\n        {'name': 'Paul Bissex', 'total_pages': 300},\n        {'name': 'Wesley J. Chun', 'total_pages': 300},\n    ])\n"], "sample_292": ["def test_good_origin_wildcard_csrf_trusted_origin_allowed_with_port(self):\n    \"\"\"\n    A POST request with an origin that matches a CSRF_TRUSTED_ORIGINS\n    wildcard and includes a port is accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['HTTP_ORIGIN'] = 'https://foo.example.com:8000'\n    mw = CsrfViewMiddleware(post_form_view)\n    self.assertIs(mw._origin_verified(req), True)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n    self.assertEqual(mw.allowed_origins_exact, set())\n    self.assertEqual(mw.allowed_origin_subdomains, {'https': ['.example.com']})\n"], "sample_460": ["def test_missing_slash_append_slash_true_non_staff_user_without_final_catch_all_view(self):\n    user = User.objects.create_user(\n        username=\"user\",\n        password=\"secret\",\n        email=\"user@example.com\",\n        is_staff=False,\n    )\n    self.client.force_login(user)\n    known_url = reverse(\"admin10:admin_views_article_changelist\")\n    response = self.client.get(known_url[:-1])\n    self.assertRedirects(\n        response,\n        \"/test_admin/admin10/login/?next=/test_admin/admin10/admin_views/article\",\n    )\n"], "sample_769": ["def test_balanced_accuracy_score_sample_weight():\n    y_true = ['a', 'b', 'a', 'b']\n    y_pred = ['a', 'a', 'a', 'b']\n    sample_weight = [1, 1, 2, 1]\n    balanced = balanced_accuracy_score(y_true, y_pred, sample_weight=sample_weight)\n    assert balanced == pytest.approx(0.75)\n"], "sample_36": ["def test_biweight_location_with_M():\n    \"\"\"Test biweight_location with a given M.\"\"\"\n    with NumpyRNGContext(12345):\n        data = normal(5, 2, 100)\n        M = np.mean(data)\n        cbl = biweight_location(data, M=M)\n        assert_allclose(cbl, M)\n"], "sample_768": ["def test_group_kfold_changing_groups():\n    # Check that GroupKFold works normally if the groups variable is changed before calling split\n    groups = np.array([0, 1, 2, 1, 1, 2, 0, 0])\n    X = np.ones(len(groups))\n    groups_changing = np.array(groups, copy=True)\n    gkf = GroupKFold(n_splits=3).split(X, groups=groups)\n    gkf_changing = GroupKFold(n_splits=3).split(X, groups=groups)\n    groups_changing[:] = 0\n    for g, g_changing in zip(gkf, gkf_changing):\n        assert_array_equal(g[0], g_changing[0])\n        assert_array_equal(g[1], g_changing[1])\n"], "sample_235": ["def test_hooks_cleared_after_error_in_hook(self):\n        raise ForcedError()\n\n    try:\n        with transaction.atomic():\n            transaction.on_commit(on_commit_error)\n    except ForcedError:\n        pass\n\n    with transaction.atomic():\n        self.do(1)\n\n    self.assertDone([1])\n"], "sample_646": ["def test_raising_unittest_skiptest_during_collection_with_reason(\n    pytester: Pytester,"], "sample_33": ["def test_indent():\n    s = \"Hello\\nWorld\"\n    indented = misc.indent(s)\n    assert indented == \"    Hello\\n    World\"\n\n    indented = misc.indent(s, shift=2)\n    assert indented == \"        Hello\\n        World\"\n\n    indented = misc.indent(s, width=2)\n    assert indented == \"  Hello\\n  World\"\n\n    s = \"Hello\\nWorld\\n\"\n    indented = misc.indent(s)\n    assert indented == \"    Hello\\n    World\\n\"\n"], "sample_87": ["    def test_notify_file_changed_no_handlers(self):\n        reloader = autoreload.BaseReloader()\n        with mock.patch('django.utils.autoreload.trigger_reload') as mocked_trigger:\n            reloader.notify_file_changed('test.py')\n        self.assertEqual(mocked_trigger.call_count, 1)\n"], "sample_931": ["def test_pyfunction_signature_with_default_value(app):\n    text = \".. py:function:: hello(name: str = 'World') -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_punctuation, \":\"],\n                                                      \" \",\n                                                      [nodes.inline, pending_xref, \"str\"],\n                                                      \" \",\n                                                      [desc_sig_operator, \"=\"],\n                                                      \" \",\n                                                      [nodes.inline, \"'World'\"])])\n"], "sample_1167": ["def test_latex_printing_of_ArrayElement_with_complex_indices():\n    A = ArraySymbol(\"A\", 2, 3, 4)\n    i, j, k = symbols(\"i j k\")\n    element = ArrayElement(A, (i, j, k))\n    assert latex(element) == \"{{A}_{i, j, k}}\"\n"], "sample_44": ["def test_neg_pos_methods(self):\n    for mag in self.mags:\n        neg_mag = -mag\n        assert np.all(neg_mag.value == -mag.value)\n        assert neg_mag.unit == mag.unit\n        pos_mag = +mag\n        assert np.all(pos_mag.value == mag.value)\n        assert pos_mag.unit == mag.unit\n"], "sample_866": ["def test_affinity_propagation_preference_none():\n    # Test AffinityPropagation with preference=None\n    af = AffinityPropagation(preference=None)\n    labels = af.fit_predict(X)\n    assert labels.size == X.shape[0]\n    assert np.unique(labels).size <= X.shape[0]\n"], "sample_342": ["def test_custom_paginator(self):\n    \"\"\"\n    The ModelAdmin's paginator is used for autocomplete views.\n    \"\"\"\n    class CustomPaginatorQuestionAdmin(QuestionAdmin):\n            return Paginator(queryset, per_page=per_page * 2, orphans=orphans, allow_empty_first_page=allow_empty_first_page)\n\n    Question.objects.bulk_create(Question(question=str(i)) for i in range(PAGINATOR_SIZE * 2 + 10))\n    # The first page of results.\n    request = self.factory.get(self.url, {'term': '', **self.opts})\n    request.user = self.superuser\n    with model_admin(Question, CustomPaginatorQuestionAdmin):\n        response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    self.assertEqual(response.status_code, 200)\n    data = json.loads(response.content.decode('utf-8'))\n    self.assertEqual(data, {\n        'results': [{'id': str(q.pk), 'text': q.question} for q in Question.objects.all()[:PAGINATOR_SIZE * 2]],\n        'pagination': {'more': True},\n    })\n    # The second page of results.\n    request = self.factory.get(self.url, {'term': '', 'page': '2', **self.opts})\n    request.user = self.superuser\n    with model_admin(Question, CustomPaginatorQuestionAdmin):\n        response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    self.assertEqual(response.status_code, 200)\n    data = json.loads(response.content.decode('utf-8'))\n    self.assertEqual(data, {\n        'results': [{'id': str(q.pk), 'text': q.question} for q in Question.objects.all()[P"], "sample_61": ["    def test_validate(self):\n        valid_usernames = ['glenn', 'GLEnN', 'jean-marc', 'user.name', 'user+name', 'user-name', 'user_name']\n        invalid_usernames = [\"o'connell\", '\u00c9ric', 'jean marc', \"\u0623\u062d\u0645\u062f\", 'trailingnewline\\n', 'user@name']\n        v = ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n"], "sample_1179": ["def test_issue_22689_2():\n    assert str(Mul(Pow(x,-2, evaluate=False), Pow(3,-1,evaluate=False), evaluate=False)) == \"3**(-1)*x**(-2)\"\n"], "sample_201": ["def test_empty_messages(self):\n    \"\"\"\n    An empty list of messages is properly encoded/decoded by the custom JSON\n    encoder/decoder classes.\n    \"\"\"\n    messages = []\n    encoder = MessageEncoder(separators=(',', ':'))\n    value = encoder.encode(messages)\n    decoded_messages = json.loads(value, cls=MessageDecoder)\n    self.assertEqual(messages, decoded_messages)\n"], "sample_429": ["compilation error"], "sample_540": ["def test_animation_pause_resume(anim):\n    anim = animation.FuncAnimation(**anim)\n    anim.pause()\n    assert not anim.event_source.is_running()\n    anim.resume()\n    assert anim.event_source.is_running()\n"], "sample_395": ["def test_reset_loaders_with_locmem_loader(self, mock_reset):\n    autoreload.reset_loaders()\n    self.assertEqual(mock_reset.call_count, 1)\n"], "sample_1191": ["def test_hermite_normal_modulo_D():\n    m = DM([[2, 7, 17, 29, 41], [3, 11, 19, 31, 43], [5, 13, 23, 37, 47]], ZZ)\n    hnf = DM([[1, 0, 0], [0, 2, 1], [0, 0, 1]], ZZ)\n    assert hermite_normal_form(m, D=ZZ(96)) == hnf\n"], "sample_877": ["def test_isotonic_regression_2darray_input():\n    # Test from #15012\n    # Check that IsotonicRegression can handle 2darray with only 1 feature\n    X = np.arange(10).reshape(-1, 1)\n    y = np.arange(10)\n\n    iso_reg = IsotonicRegression().fit(X, y)\n    y_pred = iso_reg.predict(X)\n\n    assert y_pred.shape == (10,)\n    assert_array_equal(y_pred, y)\n"], "sample_920": ["def test_attributes_with_type_reference(self):\n    docstring = \"\"\"\\"], "sample_299": ["    def test_non_file_based_cache(self):\n        with self.settings(CACHES={\n            'default': {\n                'BACKEND': 'django.core.cache.backends.locmem.LocMemCache',\n            },\n        }):\n            self.assertEqual(check_file_based_cache_is_absolute(None), [])\n"], "sample_73": ["def test_template_tag_non_ascii(self):\n    relpath = self.hashed_file_path(\"test/nonascii.css\")\n    self.assertEqual(relpath, \"test/nonascii.401f2509a628.css\")\n    with storage.staticfiles_storage.open(relpath) as relfile:\n        content = relfile.read()\n        self.assertIn(b'@font-face { font-family: \"\\u041f\\u0435\\u0440\\u0435\\u043a\\u0440\\u0435\\u0441\\u0442\"; }', content)\n    self.assertPostCondition()\n"], "sample_808": ["def test_iforest_sample_weight():\n    \"\"\"Test Isolation Forest with sample weights\"\"\"\n\n    # Generate train/test data\n    rng = check_random_state(2)\n    X = 0.3 * rng.randn(120, 2)\n    X_train = np.r_[X + 2, X - 2]\n    X_train = X[:100]\n\n    # Generate some abnormal novel observations\n    X_outliers = rng.uniform(low=-4, high=4, size=(20, 2))\n    X_test = np.r_[X[100:], X_outliers]\n    y_test = np.array([0] * 20 + [1] * 20)\n\n    # Generate sample weights\n    sample_weight = np.ones(X_train.shape[0])\n    sample_weight[50:] = 2  # Double the weight of the second half of the data\n\n    # fit the model with sample weights\n    clf = IsolationForest(max_samples=100, random_state=rng).fit(X_train, sample_weight=sample_weight)\n\n    # predict scores (the lower, the more normal)\n    y_pred = - clf.decision_function(X_test)\n\n    # check that there is at most 6 errors (false positive or false negative)\n    assert_greater(roc_auc_score(y_test, y_pred), 0.98)\n"], "sample_548": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cb = fig.colorbar(im)\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n    cb.set_alpha(None)\n    assert cb.alpha is None\n"], "sample_950": ["def test_pyfunction_with_default_value(app):\n    text = \".. py:function:: hello(name='World') -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, ([desc_parameter, ([desc_sig_name, \"name\"],\n                                                        [desc_sig_operator, \"=\"],\n                                                        [nodes.inline, \"'World'\"])])])\n"], "sample_1094": ["def test_replace_pattern_expr():\n    from sympy import Wild\n    x, y = symbols('x y')\n    a, b = map(Wild, 'ab')\n    e = (x + y)**(x + y)\n    assert e.replace(sin(a), tan(a)) == e\n    assert e.replace(sin(a), tan(a/2)) == e\n    assert e.replace(a + b, a - b) == (x - y)**(x - y)\n    assert (2*x + y).replace(a*x + b, b - a) == y - 2\n    assert (2*x).replace(a*x + b, b - a, exact=False) == 2/x\n"], "sample_822": ["def test_pairwise_distances_precomputed_non_negative():\n    # Test non-negative values\n    assert_raises_regexp(ValueError, '.* non-negative values.*',\n                         pairwise_distances, np.full((5, 5), -1),\n                         metric='precomputed')\n"], "sample_664": ["def test_fixture_positional_arguments(testdir, fixture_args, warning_msg):\n    \"\"\"Test the deprecation warning for passing arguments to pytest.fixture() as positional arguments.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture({fixture_args})\n            pass\n\n            pass\n    \"\"\".format(fixture_args=fixture_args if isinstance(fixture_args, str) else str(fixture_args))\n    )\n\n    result = testdir.runpytest()\n    if warning_msg:\n        result.stdout.fnmatch_lines([warning_msg])\n    else:\n        result.stdout.no_fnmatch_line(\"*PytestDeprecationWarning*\")\n"], "sample_1086": ["def test_issue_14567_part2():\n    assert str(factorial(Sum(-1, (x, 0, 0))) + y) == \"y + 1\"\n"], "sample_624": ["def test_format_timedelta_invalid_pandas_format() -> None:\n    expected = \"10 days 01:00:00 00\"\n    with pytest.raises(ValueError):\n        formatting.format_timedelta(expected)\n"], "sample_214": ["def test_key_transform_exact(self):\n    self.assertIs(NullableJSONModel.objects.filter(value__foo__exact='bar').exists(), True)\n    self.assertIs(NullableJSONModel.objects.filter(value__foo__exact='\"bar\"').exists(), False)\n"], "sample_1033": ["def test_divmod_with_symbols():\n    x, y = symbols('x y')\n    assert divmod(x, y) == (x//y, x % y)\n    assert divmod(x, 3) == (x//3, x % 3)\n    assert divmod(3, x) == (3//x, 3 % x)\n"], "sample_1093": ["def test_log1p():\n    from sympy import log1p\n\n    expr = log1p(x)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr) == 'scipy.special.log1p(x)'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr) == 'numpy.log(x + 1)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr) == 'math.log(x + 1)'\n\n    prntr = MpmathPrinter()\n    assert prntr.doprint(expr) == 'mpmath.log(x + 1)'\n"], "sample_728": ["def test_make_classification_flip_y():\n    \"\"\"Test the flipping of labels in make_classification\"\"\"\n    n_samples = 1000\n    flip_y = 0.5\n    X, y = make_classification(n_samples=n_samples, n_classes=2, flip_y=flip_y, random_state=0)\n\n    # Check that the correct number of labels were flipped\n    assert_equal(np.sum(y == 0), np.sum(y == 1), \"Unexpected number of samples in each class\")\n    assert_almost_equal(np.sum(y == 0) / n_samples, 0.5, decimal=2,\n                        err_msg=\"Unexpected proportion of flipped labels\")\n"], "sample_702": ["def test_pytester_assert_outcomes_warnings_no_warnings(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n            pass\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.assert_outcomes(passed=1, warnings=0)\n"], "sample_1020": ["def test_user_functions():\n    settings = {'user_functions': {'custom_func': 'CustomFunction'}}\n    assert mcode(custom_func(x, y), **settings) == \"CustomFunction[x, y]\"\n"], "sample_237": ["def test_username_unique(self):\n    \"\"\"\n    A unique USERNAME_FIELD should not raise any errors.\n    \"\"\"\n    class CustomUserUniqueUsername(AbstractBaseUser):\n        username = models.CharField(max_length=30, unique=True)\n        USERNAME_FIELD = 'username'\n\n    errors = checks.run_checks(app_configs=self.apps.get_app_configs())\n    self.assertEqual(errors, [])\n"], "sample_978": ["def test_degree_0_with_floats():\n    d = 0\n    knots = [0.0, 1.0, 2.0, 3.0, 4.0]\n    splines = bspline_basis_set(d, knots, x)\n    for i in range(len(splines)):\n        assert splines[i] == Piecewise((1, Interval(i, i + 1).contains(x)),\n                                       (0, True))\n"], "sample_66": ["def test_wsgirequest_headers_getitem(self):\n    request = WSGIRequest(self.ENVIRON)\n    self.assertEqual(request.headers['User-Agent'], 'python-requests/1.2.0')\n    self.assertEqual(request.headers['user-agent'], 'python-requests/1.2.0')\n    self.assertEqual(request.headers['user_agent'], 'python-requests/1.2.0')\n    self.assertEqual(request.headers['Content-Type'], 'text/html')\n    self.assertEqual(request.headers['Content-Length'], '100')\n"], "sample_24": ["def test_nan_to_num(self):\n    self.check(np.nan_to_num)\n    ma = Masked([np.nan, 1.0], mask=[True, False])\n    o = np.nan_to_num(ma, copy=False)\n    assert_masked_equal(o, Masked([0.0, 1.0], mask=[True, False]))\n    assert ma is o\n"], "sample_218": ["def test_trunc_func_with_timezone_and_explicit_timezone_priority(self):\n    start_datetime = datetime(2015, 6, 15, 23, 30, 50, 321)\n    end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n\n    melb = pytz.timezone('Australia/Melbourne')\n\n    with timezone.override(melb):\n        model = DTModel.objects.annotate(\n            truncated_melb=Trunc('start_datetime', 'day'),\n            truncated_utc=Trunc('start_datetime', 'day', tzinfo=timezone.utc),\n        ).order_by('start_datetime').get()\n        self.assertEqual(model.truncated_melb, truncate_to(start_datetime.astimezone(melb), 'day', melb))\n        self.assertEqual(model.truncated_utc, truncate_to(start_datetime, 'day'))\n"], "sample_813": ["def test_bayesian_ridge_intercept():\n    # Test BayesianRidge with and without intercept\n    X = np.array([[1], [2], [6], [8], [10]])\n    Y = np.array([2, 3, 7, 9, 11])\n    clf_with_intercept = BayesianRidge(compute_score=True, fit_intercept=True)\n    clf_without_intercept = BayesianRidge(compute_score=True, fit_intercept=False)\n    clf_with_intercept.fit(X, Y)\n    clf_without_intercept.fit(X - np.mean(X), Y - np.mean(Y))\n    assert_array_almost_equal(clf_with_intercept.coef_, clf_without_intercept.coef_)\n    assert_almost_equal(clf_with_intercept.intercept_, np.mean(Y) - np.mean(X) * clf_without_intercept.coef_)\n"], "sample_736": ["def test_logreg_intercept_scaling_fit_intercept():\n    # Test that intercept_scaling is used when fit_intercept is True\n\n    clf = LogisticRegression(fit_intercept=True, intercept_scaling=2.0)\n    clf.fit(X, Y1)\n    assert_equal(clf.intercept_, 2.0 * clf.coef_[:, -1])\n"], "sample_110": ["def test_pickle_subquery_queryset_still_usable(self):\n    group = Group.objects.create(name='group')\n    Event.objects.create(title='event', group=group)\n    groups = Group.objects.annotate(\n        event_title=models.Subquery(\n            Event.objects.filter(group_id=models.OuterRef('id')).values('title'),\n        ),\n    )\n    groups2 = pickle.loads(pickle.dumps(groups))\n    self.assertSequenceEqual(groups2.filter(event_title='event'), [group])\n"], "sample_166": ["def test_get_random_string_length(self):\n    length = 22\n    result = get_random_string(length)\n    self.assertEqual(len(result), length)\n"], "sample_209": ["def test_model_with_evaluate_method_and_related_objects(self):\n    \"\"\"\n    You can filter by objects that have an 'evaluate' attr and related objects\n    \"\"\"\n    dept = Department.objects.create(pk=1, name='abc')\n    dept.evaluate = 'abc'\n    worker = Worker.objects.create(name='worker', department=dept)\n    worker.evaluate = 'xyz'\n    Worker.objects.filter(department=dept, evaluate='xyz')\n"], "sample_277": ["def test_combine_and_or(self):\n    q1 = Q(x=1)\n    q2 = Q(y=2)\n    q3 = Q(z=3)\n    combined_q = (q1 & q2) | q3\n    expected_q = Q(Q(Q(x=1) & Q(y=2)) | Q(z=3))\n    self.assertEqual(combined_q, expected_q)\n"], "sample_41": ["def test_unit_multiplication_with_quantity():\n    \"\"\"Check that multiplication with quantities produces the correct unit.\"\"\"\n    u1 = u.cm\n    q = 5.0 * u.s\n    assert q * u1 == (5.0 * u.s * u.cm)\n    assert u1 * q == (5.0 * u.cm * u.s)\n"], "sample_592": ["def test_inline_variable_array_repr():\n    var = xr.Variable((\"x\", \"y\"), np.array([[1, 2, 3], [4, 5, 6]], dtype=\"int64\"))\n    max_width = 20\n    expected = \"1 2 3 ... 4 5 6\"\n    actual = formatting.inline_variable_array_repr(var, max_width)\n    assert actual == expected\n"], "sample_526": ["def test_num2date_out_of_range():\n    with pytest.raises(ValueError, match=\"Date ordinal 1000000000000000000000 converts to year 288270319167 which is outside the range of valid years\"):\n        mdates.num2date(1000000000000000000000)\n"], "sample_289": ["    def test_setlistdefault(self):\n        x = MultiValueDict({'a': [1]})\n        a = x.setlistdefault('a', [2])\n        b = x.setlistdefault('b', [3])\n        self.assertEqual(a, [1])\n        self.assertEqual(b, [3])\n        self.assertEqual(list(x.lists()), [('a', [1]), ('b', [3])])\n"], "sample_470": ["def test_lazy_modulo(self):\n    \"\"\"\n    % works correctly for Promises.\n    \"\"\"\n    lazy_obj = lazy(lambda: \"test %s\", str)\n    self.assertEqual(lazy_obj() % \"example\", \"test example\")\n"], "sample_121": ["    def test_proxy_model_with_fields(self):\n        class BaseModel(models.Model):\n            field1 = models.CharField(max_length=10)\n\n        class ProxyModel(BaseModel):\n            field2 = models.IntegerField()\n\n            class Meta:\n                proxy = True\n\n        self.assertEqual(ProxyModel.check(), [\n            Error(\n                \"Proxy model 'ProxyModel' has model fields.\",\n                obj=ProxyModel,\n                id='models.E017',\n            ),\n        ])\n"], "sample_1206": ["def test_exponentiation_of_1():\n    x = Symbol('x')\n    assert 1**x == S.One\n    assert unchanged(Pow, 1, x)\n"], "sample_929": ["def test_pyfunction_signature_with_default_value(app):\n    text = \".. py:function:: hello(name: str = 'World') -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_punctuation, \":\"],\n                                                      \" \",\n                                                      [nodes.inline, pending_xref, \"str\"],\n                                                      \" \",\n                                                      [desc_sig_operator, \"=\"],\n                                                      \" \",\n                                                      [nodes.inline, \"'World'\"])])\n"], "sample_674": ["def test_node_repr():\n    node = nodes.Node(\"test_node\")\n    assert repr(node) == \"<Node test_node>\"\n"], "sample_887": ["def test_calibration_with_sample_weight_base_estimator_and_fit_params(data):\n    \"\"\"Tests that sample_weight and fit_params are passed to the underlying base\n    estimator.\n    \"\"\"\n    X, y = data\n    sample_weight = np.ones_like(y)\n    fit_params = {\"fit_param\": np.ones_like(y)}\n\n    class ClfWithSampleWeightAndFitParams(CheckingClassifier):\n            assert sample_weight is not None\n            assert \"fit_param\" in fit_params\n            return super().fit(X, y, sample_weight=sample_weight, **fit_params)\n\n    clf = ClfWithSampleWeightAndFitParams()\n    pc_clf = CalibratedClassifierCV(clf)\n\n    pc_clf.fit(X, y, sample_weight=sample_weight, **fit_params)\n"], "sample_957": ["def test_restify_type_hints_forward_ref():\n    from typing import ForwardRef\n    assert restify(ForwardRef(\"MyClass1\")) == \":class:`MyClass1`\"\n"], "sample_25": ["def test_header_from_fileobj(self):\n    \"\"\"Test reading a Header from a file-like object.\"\"\"\n    with open(self.data(\"test0.fits\"), \"rb\") as fobj:\n        pri_hdr_from_fileobj = fits.Header.fromfile(fobj)\n\n    pri_hdr = fits.getheader(self.data(\"test0.fits\"))\n    assert pri_hdr[\"NAXIS\"] == pri_hdr_from_fileobj[\"NAXIS\"]\n    assert pri_hdr == pri_hdr_from_fileobj\n    assert pri_hdr.tostring() == pri_hdr_from_fileobj.tostring()\n"], "sample_151": ["def test_mti_inheritance_model_addition(self):\n    Animal = ModelState('app', 'Animal', [\n        (\"id\", models.AutoField(primary_key=True)),\n    ])\n    changes = self.get_changes([Animal], [Animal, ModelState('app', 'Dog', [], bases=('app.Animal',))])\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='Dog')\n"], "sample_697": ["def test_tmp_path_factory_handles_existing_directory(\n    tmp_path_factory: TempPathFactory, monkeypatch: MonkeyPatch"], "sample_844": ["def test_precomputed_dists_invalid():\n    redX = X[::2]\n    dists = pairwise_distances(redX, metric='euclidean')\n    dists[0, 1] = -1  # invalid distance\n    clust = OPTICS(min_samples=10, algorithm='brute', metric='precomputed')\n    with pytest.raises(ValueError, match=\"precomputed metric requires non-negative values\"):\n        clust.fit(dists)\n"], "sample_890": ["def test_cv_object_support():\n    \"\"\"Check that no exception raised when cv is a CV splitter object\n\n    non-regression test for #25957\n    \"\"\"\n    X, y = make_classification(random_state=0)\n\n    groups = np.zeros_like(y, dtype=int)\n    groups[y.size // 2 :] = 1\n\n    cv = LeaveOneGroupOut()\n\n    knc = KNeighborsClassifier(n_neighbors=5)\n\n    sfs = SequentialFeatureSelector(knc, n_features_to_select=5, cv=cv)\n    sfs.fit(X, y)\n"], "sample_599": ["def test_CFMaskCoder_encode_decode_with_missing_value():\n    original = xr.Variable((\"x\",), [0, -9999, 1], {\"missing_value\": -9999})\n    expected = xr.Variable((\"x\",), [0, np.nan, 1])\n    coder = variables.CFMaskCoder()\n    encoded = coder.encode(original)\n    decoded = coder.decode(encoded)\n    assert_identical(expected, decoded)\n"], "sample_1018": ["def test_fcode_Infinity():\n    x = symbols('x')\n    assert fcode(S.Infinity) == \"      (huge(0d0) + 1)\"\n    assert fcode(S.NegativeInfinity) == \"      -(huge(0d0) + 1)\"\n"], "sample_138": ["def test_template_tag_with_spaces(self):\n    relpath = self.hashed_file_path(\"cached/spaces.css\")\n    self.assertEqual(relpath, \"cached/spaces.5e0040571e1a.css\")\n    with storage.staticfiles_storage.open(relpath) as relfile:\n        content = relfile.read()\n        self.assertNotIn(b\"cached/other.css\", content)\n        self.assertIn(b\"other.d41d8cd98f00.css\", content)\n    self.assertPostCondition()\n"], "sample_750": ["def test_omp_cv_with_intercept():\n    y_ = y[:, 0]\n    gamma_ = gamma[:, 0]\n    ompcv = OrthogonalMatchingPursuitCV(normalize=True, fit_intercept=True,\n                                        max_iter=10, cv=5)\n    ompcv.fit(X, y_)\n    assert_equal(ompcv.n_nonzero_coefs_, n_nonzero_coefs)\n    assert_array_almost_equal(ompcv.coef_, gamma_, decimal=1)\n    omp = OrthogonalMatchingPursuit(normalize=True, fit_intercept=True,\n                                    n_nonzero_coefs=ompcv.n_nonzero_coefs_)\n    omp.fit(X, y_)\n    assert_array_almost_equal(ompcv.coef_, omp.coef_, decimal=1)\n"], "sample_1002": ["def test_Float_from_mpmath():\n    import mpmath\n    mpmath.mp.dps = 100\n    mp_pi = mpmath.pi()\n\n    assert Float(mp_pi, 100) == Float(mp_pi._mpf_, 100) == pi.evalf(100)\n\n    mpmath.mp.dps = 15\n\n    assert Float(mp_pi, 100) == Float(mp_pi._mpf_, 100) == pi.evalf(100)\n"], "sample_324": ["def test_https_good_referer_matches_cookie_domain_with_port_80(self):\n    \"\"\"\n    A POST HTTPS request with a good referer should be accepted from a\n    subdomain that's allowed by CSRF_COOKIE_DOMAIN and port 80.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['HTTP_REFERER'] = 'http://foo.example.com/'\n    req.META['SERVER_PORT'] = '443'\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.process_request(req)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n"], "sample_179": ["def test_unique_constraint_with_deferrable(self):\n    class Model(models.Model):\n        age = models.IntegerField()\n\n        class Meta:\n            constraints = [\n                models.UniqueConstraint(\n                    fields=['age'],\n                    name='unique_age_deferrable',\n                    deferrable=models.Deferrable.DEFERRED,\n                ),\n            ]\n\n    errors = Model.check(databases=self.databases)\n    expected = [] if connection.features.supports_deferrable_unique_constraints else [\n        Warning(\n            '%s does not support deferrable unique constraints.'\n            % connection.display_name,\n            hint=(\n                \"A constraint won't be created. Silence this warning if \"\n                \"you don't care about it.\"\n            ),\n            obj=Model,\n            id='models.W038',\n        ),\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_451": ["def test_replace_metacharacters(self):\n    self.assertEqual(replace_metacharacters(r'a*b+c?d$e^f'), 'abcdf')\n    self.assertEqual(replace_metacharacters(r'a\\*b\\+c\\?d\\$e\\^f'), 'a*b+c?d$e^f')\n"], "sample_608": ["def test_format_timedelta_invalid_pandas_format() -> None:\n    expected = \"10 days 12:00:00 00\"\n    with pytest.raises(ValueError):\n        formatting.format_timedelta(expected)\n"], "sample_1041": ["def test_MatrixElement_diff_with_Inverse():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    i, j = symbols('i j')\n    assert (A.I[i, j]).diff(A[k, l]) == -A.I[i, k]*A.I[l, j]\n    assert (B*A.I[i, j]).diff(A[k, l]) == -B*A.I[i, k]*A.I[l, j]\n"], "sample_298": ["def test_token_with_different_algorithm(self):\n    \"\"\"\n    A valid token can be created with a different algorithm by using the\n    PasswordResetTokenGenerator.algorithm attribute.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    new_algorithm = 'sha1'\n    # Create and check a token with a different algorithm.\n    p0 = PasswordResetTokenGenerator()\n    p0.algorithm = new_algorithm\n    tk0 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk0), True)\n    # Create and check a token with the default algorithm.\n    p1 = PasswordResetTokenGenerator()\n    self.assertNotEqual(p1.algorithm, new_algorithm)\n    tk1 = p1.make_token(user)\n    # Tokens created with a different algorithm don't validate.\n    self.assertIs(p0.check_token(user, tk1), False)\n    self.assertIs(p1.check_token(user, tk0), False)\n"], "sample_94": ["def test_fields_with_fk_non_interactive(self):\n    new_io = StringIO()\n    group = Group.objects.create(name='mygroup')\n    email = Email.objects.create(email='mymail@gmail.com')\n    call_command(\n        'createsuperuser',\n        interactive=False,\n        username=email.pk,\n        email=email.email,\n        group=group.pk,\n        stdout=new_io,\n    )\n    command_output = new_io.getvalue().strip()\n    self.assertEqual(command_output, 'Superuser created successfully.')\n    u = CustomUserWithFK._default_manager.get(email=email)\n    self.assertEqual(u.username, email)\n    self.assertEqual(u.group, group)\n\n    non_existent_group = 'nonexistentgroup'\n    msg = 'group instance with id %r does not exist.' % non_existent_group\n    with self.assertRaisesMessage(CommandError, msg):\n        call_command(\n            'createsuperuser',\n            interactive=False,\n            username=email.pk,\n            email=email.email,\n            group=non_existent_group,\n            stdout=new_io,\n        )\n"], "sample_1095": ["def test_permutation_resize():\n    p = Permutation(0, 1, 2)\n    assert p.resize(5) == Permutation(0, 1, 2, size=5)\n    assert p.resize(4) == Permutation(0, 1, 2, size=4)\n    assert p.resize(3) == p\n    raises(ValueError, lambda: p.resize(2))\n\n    p = Permutation(0, 1, 2)(3, 4)(5, 6)\n    assert p.resize(3) == Permutation(0, 1, 2)\n    raises(ValueError, lambda: p.resize(4))\n"], "sample_638": ["def test_no_arguments_provided(capsys):\n    \"\"\"Test that the help message is printed when no arguments are provided.\"\"\"\n    with pytest.raises(SystemExit) as wrapped_sysexit:\n        # we have to catch the SystemExit so the test execution does not stop\n        main.Run([])\n    # Check that the help message is printed to the user\n    assert \"Usage: \" in capsys.readouterr().out\n    # Check that we exited with the expected error code\n    assert wrapped_sysexit.value.code == 1\n"], "sample_288": ["def test_key_transform_expression_with_value(self):\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__d__0__isnull=False).annotate(\n            key=KeyTransform('d', 'value'),\n            chain=KeyTransform('0', 'key'),\n            expr=Value('e'),\n        ).filter(chain=F('expr')),\n        [self.objs[4]],\n    )\n"], "sample_489": ["def test_update_conflicts_unique_fields_update_fields_db_column_no_unique_fields(self):\n    FieldsWithDbColumns.objects.bulk_create(\n        [\n            FieldsWithDbColumns(rank=1, name=\"a\"),\n            FieldsWithDbColumns(rank=2, name=\"b\"),\n        ]\n    )\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n\n    conflicting_objects = [\n        FieldsWithDbColumns(rank=1, name=\"c\"),\n        FieldsWithDbColumns(rank=2, name=\"d\"),\n    ]\n    results = FieldsWithDbColumns.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        update_fields=[\"name\"],\n    )\n    self.assertEqual(len(results), len(conflicting_objects))\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n    self.assertCountEqual(\n        FieldsWithDbColumns.objects.values(\"rank\", \"name\"),\n        [\n            {\"rank\": 1, \"name\": \"c\"},\n            {\"rank\": 2, \"name\": \"d\"},\n        ],\n    )\n"], "sample_445": ["def test_time_strings(self):\n    \"\"\"Test custom time strings.\"\"\"\n    custom_time_strings = {\n        \"year\": \"%(num)d yr\",\n        \"month\": \"%(num)d mo\",\n        \"week\": \"%(num)d wk\",\n        \"day\": \"%(num)d d\",\n        \"hour\": \"%(num)d hr\",\n        \"minute\": \"%(num)d min\",\n    }\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneyear, time_strings=custom_time_strings),\n        \"1 yr\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.onemonth, time_strings=custom_time_strings),\n        \"1 mo\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneweek, time_strings=custom_time_strings),\n        \"1 wk\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneday, time_strings=custom_time_strings),\n        \"1 d\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.onehour, time_strings=custom_time_strings),\n        \"1 hr\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneminute, time_strings=custom_time_strings),\n        \"1 min\",\n    )\n"], "sample_278": ["def test_expression_wrapper_with_transformed_field_bitwise_or(self):\n    Employee.objects.create(firstname='Max', lastname='Mustermann')\n    with register_lookup(CharField, Length):\n        qs = Employee.objects.annotate(bitor=ExpressionWrapper(F('lastname__length').bitor(48), output_field=IntegerField()))\n        self.assertEqual(qs.get().bitor, 58)\n"], "sample_807": ["def test_calibration_multilabel():\n    \"\"\"Test calibration for multilabel \"\"\"\n    # test multi-label setting with classifier that implements\n    # only decision function\n    clf = LinearSVC()\n    X, y = make_multilabel_classification(n_samples=100, n_features=2, random_state=42,\n                                          n_classes=3, n_labels=2)\n\n    X_train, y_train = X[::2], y[::2]\n    X_test, y_test = X[1::2], y[1::2]\n\n    clf.fit(X_train, y_train)\n    for method in ['isotonic', 'sigmoid']:\n        cal_clf = CalibratedClassifierCV(clf, method=method, cv=2)\n        cal_clf.fit(X_train, y_train)\n        probas = cal_clf.predict_proba(X_test)\n        assert_array_almost_equal(np.sum(probas, axis=1), np.ones(len(X_test)))\n\n        # Check that log-loss of calibrated classifier is smaller than\n        # log-loss of naively turned OvR decision function to probabilities\n        # via softmax\n            e = np.exp(-y_pred)\n            return e / e.sum(axis=1).reshape(-1, 1)\n\n        uncalibrated_log_loss = \\\n            log_loss(y_test, softmax(clf.decision_function(X_test)))\n        calibrated_log_loss = log_loss(y_test, probas)\n        assert_greater_equal(uncalibrated_log_loss, calibrated_log_loss)\n"], "sample_32": ["def test_w_method():\n    cosmo = w0wzCDM(H0=70, Om0=0.3, Ode0=0.50, w0=-1, wz=0.5)\n\n    z = np.array([0.1, 0.2, 0.5, 1.5, 2.5])\n    assert u.allclose(\n        cosmo.w(z),\n        [-1.05, -1.1, -1.25, -1.75, -2.0],\n        rtol=1e-4,\n    )\n\n    assert u.allclose(cosmo.w(3), cosmo.w(3.0), rtol=1e-7)\n    assert u.allclose(\n        cosmo.w([1, 2, 3]),\n        cosmo.w([1.0, 2.0, 3.0]),\n        rtol=1e-7,\n    )\n\n    # Flat tests\n    cosmo = w0wzCDM(H0=70, Om0=0.3, Ode0=0.7, w0=-1, wz=0.5)\n    flatcosmo = Flatw0wzCDM(H0=70, Om0=0.3, w0=-1, wz=0.5)\n\n    assert u.allclose(\n        cosmo.w(z), flatcosmo.w(z), rtol=1e-4\n    )\n"], "sample_771": ["def test_power_transformer_sparse_input():\n    # Check that sparse input is supported\n    X_dense = np.abs(X_2d)\n    X_sparse = sparse.csr_matrix(X_dense)\n\n    pt_dense = PowerTransformer(method='box-cox', standardize=False)\n    pt_sparse = PowerTransformer(method='box-cox', standardize=False)\n\n    X_trans_dense = pt_dense.fit_transform(X_dense)\n    X_trans_sparse = pt_sparse.fit_transform(X_sparse)\n\n    assert_array_almost_equal(X_trans_dense, X_trans_sparse.toarray())\n"], "sample_11": ["def test_coupled_pixel_slicing():\n    fits_wcs = WCS(header=COUPLED_WCS_HEADER)\n    sl = SlicedLowLevelWCS(fits_wcs, (slice(None), 0, slice(None)))\n    world = fits_wcs.pixel_to_world_values(0,0,0)\n    out_pix = sl.world_to_pixel_values(world[0], world[2])\n\n    assert np.allclose(out_pix[1], 0)\n"], "sample_1065": ["def test_subfactorial_rewrite():\n    n = Symbol('n', integer=True)\n    assert subfactorial(n).rewrite(uppergamma) == uppergamma(n + 1, -1)/S.Exp1\n    assert subfactorial(n + 1).rewrite(uppergamma) == subfactorial(n + 1)\n"], "sample_86": ["def test_lazy_hash(self):\n    \"\"\"\n    hash() works correctly for Promises.\n    \"\"\"\n    lazy_a = lazy(lambda: 4, int)\n    lazy_b = lazy(lambda: 4, int)\n    lazy_c = lazy(lambda: 5, int)\n\n    self.assertEqual(hash(lazy_a()), hash(lazy_b()))\n    self.assertNotEqual(hash(lazy_b()), hash(lazy_c()))\n"], "sample_1199": ["def test_tensor_product_matrices():\n    assert TensorProduct(mat1, mat2) == Matrix([[2*I, 6, 3*I, 6], [(4*I + 1)*I, 6, (4*I + 3)*I, 6], [2*I, 3, 3*I, 9], [(4*I + 1)*I, 3, (4*I + 3)*I, 9]])\n    assert TensorProduct(mat2, mat1) == Matrix([[2*I, (4*I + 1)*I, 6*I, 6*I + 3], [3, 2, 9, 6], [3*I, (4*I + 3)*I, 6*I, 9*I + 9], [6, 4*I, 12*I, 6*I + 6]])\n"], "sample_1080": ["def test_sign_complex():\n    x = Symbol('x', complex=True)\n    assert refine(sign(x), Q.positive(x)) == 1\n    assert refine(sign(x), Q.negative(x)) == -1\n    assert refine(sign(x), Q.zero(x)) == 0\n    assert refine(sign(x), Q.positive(re(x))) == 1\n    assert refine(sign(x), Q.negative(re(x))) == -1\n    assert refine(sign(x), Q.positive(im(x))) == S.ImaginaryUnit\n    assert refine(sign(x), Q.negative(im(x))) == -S.ImaginaryUnit\n"], "sample_783": ["def test_imputation_error_invalid_dtype():\n    # Test that an error is raised when the input data contains unsupported dtype\n    X = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.complex128)\n\n    with pytest.raises(ValueError, match=\"SimpleImputer does not support data\"):\n        imputer = SimpleImputer()\n        imputer.fit_transform(X)\n"], "sample_563": ["def test_offsetimage():\n    fig, ax = plt.subplots()\n\n    data = np.random.rand(10, 10)\n    im = OffsetImage(data, zoom=2)\n    ab = AnnotationBbox(im, (0.5, 0.5), xycoords='axes fraction')\n    ax.add_artist(ab)\n"], "sample_211": ["def test_template_engine_without_template(self):\n    \"\"\"\n    A template view may provide a template engine, but it should not be used\n    if no template is provided.\n    \"\"\"\n    view = TemplateView.as_view(template_engine='jinja2')\n    msg = (\n        \"TemplateResponseMixin requires either a definition of \"\n        \"'template_name' or an implementation of 'get_template_names()'\"\n    )\n    with self.assertRaisesMessage(ImproperlyConfigured, msg):\n        view(self.rf.get('/'))\n"], "sample_740": ["def test_check_array_memmap_copy_on_write():\n    X = np.ones((4, 4))\n    with TempMemmap(X, mmap_mode='r+') as X_memmap:\n        X_checked = check_array(X_memmap, copy=False)\n        assert np.may_share_memory(X_memmap, X_checked)\n        assert X_checked.flags['WRITEABLE']\n        X_checked[0, 0] = 2\n        assert X_memmap[0, 0] == 1\n"], "sample_595": ["def test_slice_replace_out_of_bounds():\n    da = lambda x: xr.DataArray(x)\n    values = da([\"short\", \"a bit longer\", \"evenlongerthanthat\", \"\"])\n\n    expected = da([\"short\", \"a bit longer\", \"evenlongerthanthat\", \"\"])\n    result = values.str.slice_replace(10, 20)\n    assert_equal(result, expected)\n\n    expected = da([\"short\", \"a bit longer\", \"evenlongerthanthat\", \"z\"])\n    result = values.str.slice_replace(10, 20, \"z\")\n    assert_equal(result, expected)\n\n    expected = da([\"short\", \"a bit longer\", \"evenlongerthanthat\", \"z\"])\n    result = values.str.slice_replace(-10, -20)\n    assert_equal(result, expected)\n\n    expected = da([\"zshort\", \"a bit longer\", \"evenlongerthanthat\", \"z\"])\n    result = values.str.slice_replace(-10, -20, \"z\")\n    assert_equal(result, expected)\n"], "sample_123": ["    def test_ipv6_url(self):\n        self.assertIs(\n            url_has_allowed_host_and_scheme('http://[2001:db8::1]/', allowed_hosts={'[2001:db8::1]'}),\n            True,\n        )\n        self.assertIs(\n            url_has_allowed_host_and_scheme('http://[2001:db8::1]/', allowed_hosts={'2001:db8::1'}),\n            False,\n        )\n"], "sample_735": ["def test_gaussian_mixture_predict_proba_shape():\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng)\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        g = GaussianMixture(n_components=rand_data.n_components,\n                            random_state=rng, weights_init=rand_data.weights,\n                            means_init=rand_data.means,\n                            precisions_init=rand_data.precisions[covar_type],\n                            covariance_type=covar_type)\n        g.fit(X)\n        Y_pred_proba = g.predict_proba(X)\n        assert_equal(Y_pred_proba.shape, (rand_data.n_samples, rand_data.n_components))\n"], "sample_932": ["def test_noindexentry_member():\n    text = (\".. cpp:class:: MyClass\\n\"\n            \"   .. cpp:member:: void f()\\n\"\n            \"   .. cpp:member:: void g()\\n\"\n            \"      :noindexentry:\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index, desc, addnodes.index, desc))\n    assert_node(doctree[0], addnodes.index, entries=[('single', 'MyClass::f (C++ member)', '_CPPvN7MyClass1fEv', '', None)])\n    assert_node(doctree[2], addnodes.index, entries=[])\n"], "sample_99": ["def test_trunc_func_with_timezone_and_output_field(self):\n    start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n    end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n    self.create_model(end_datetime, start_datetime)\n\n    melb = pytz.timezone('Australia/Melbourne')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, tzinfo=melb, output_field=DateTimeField())\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(melb), kind, melb)),\n                (end_datetime, truncate_to(end_datetime.astimezone(melb), kind, melb))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_date', kind, tzinfo=melb, output_field=DateField())\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.date(), kind)),\n                (end_datetime, truncate_to(end_datetime.date(), kind))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n        self.assertQuerysetEqual"], "sample_378": ["def test_bulk_update_with_related_objects(self):\n    related_objects = [RelatedObject.objects.create() for _ in range(10)]\n    single_objects = [SingleObject.objects.create() for _ in range(10)]\n    for related_obj, single_obj in zip(related_objects, single_objects):\n        related_obj.single = single_obj\n    RelatedObject.objects.bulk_update(related_objects, ['single'])\n    self.assertCountEqual(\n        RelatedObject.objects.values_list('single', flat=True),\n        [obj.single_id for obj in related_objects]\n    )\n"], "sample_130": ["def test_transform_with_lookup(self):\n    query = Query(Author)\n    with register_lookup(CharField, Lower):\n        where = query.build_where(Q(name__lower__startswith='foo'))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, StartsWith)\n    self.assertIsInstance(lookup.lhs, Lower)\n    self.assertIsInstance(lookup.lhs.lhs, SimpleCol)\n    self.assertEqual(lookup.lhs.lhs.target, Author._meta.get_field('name'))\n"], "sample_23": ["def test_angle_unicode_formatting():\n    \"\"\"\n    Tests string formatting for Angle objects with unicode characters\n    \"\"\"\n\n    angle = Angle(\"54.12412\", unit=u.degree)\n\n    res = \"Angle as DMS: 54\u00b007'26.832\\\"\"\n    assert f\"Angle as DMS: {angle.to_string(unit=u.degree, format='unicode')}\" == res\n\n    res = \"Angle as HMS: 3h36m29.7888s\"\n    assert f\"Angle as HMS: {angle.to_string(unit=u.hour, format='unicode')}\" == res\n\n    res = \"Angle as rad: 0.944644098745 rad\"\n    assert f\"Angle as rad: {angle.to_string(unit=u.radian, format='unicode')}\" == res\n"], "sample_1135": ["def test_issue_18507_2():\n    assert Mul(zoo, 0, zoo) is nan\n"], "sample_556": ["def test_savefig_pil_kwargs():\n    fig = plt.figure()\n    buf = io.BytesIO()\n    fig.savefig(buf, format='png', pil_kwargs={'optimize': True})\n    buf.seek(0)\n    img = Image.open(buf)\n    assert img.info.get('optimize') == True\n"], "sample_371": ["    def test_template_encoding(self):\n        \"\"\"\n        The templates are loaded directly, not via a template loader, and\n        should be opened as utf-8 charset as is the default specified on\n        template engines.\n        \"\"\"\n        try:\n            raise ValueError(\"Can't find my keys\")\n        except ValueError:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(None, exc_type, exc_value, tb)\n        with mock.patch.object(DebugPath, 'open') as m:\n            reporter.get_traceback_html()\n            m.assert_called_once_with(encoding='utf-8')\n            m.reset_mock()\n            reporter.get_traceback_text()\n            m.assert_called_once_with(encoding='utf-8')\n"], "sample_384": ["def test_bulk_update_with_functions_and_f_expressions(self):\n    notes = [Note.objects.create(note=str(i), misc=str(i)) for i in range(10)]\n    for note in notes:\n        note.note = Lower(F(\"note\")) + \"test\"\n    Note.objects.bulk_update(notes, [\"note\"])\n    self.assertCountEqual(\n        Note.objects.values_list(\"note\", flat=True),\n        [f\"{i}test\" for i in range(10)],\n    )\n"], "sample_203": ["def test_file_extension_validator_custom_message(self):\n    class MyForm(forms.Form):\n        field = forms.FileField(\n            validators=[validators.FileExtensionValidator(allowed_extensions=['txt'])],\n            error_messages={'invalid_extension': '%(extension)s is not allowed'},\n        )\n\n    form = MyForm(files={'field': SimpleUploadedFile('myfile.pdf', b'abc')})\n    self.assertIs(form.is_valid(), False)\n    self.assertEqual(form.errors, {'field': ['pdf is not allowed']})\n"], "sample_918": ["def test_pyfunction_signature_with_annotation(app):\n    text = \".. py:function:: hello(name: str) -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_punctuation, \":\"],\n                                                      \" \",\n                                                      [nodes.inline, pending_xref, \"str\"])])\n"], "sample_369": ["def test_add_field_with_db_column(self):\n    \"\"\"#23405 - Adding a field with a db_column should not prompt for a default.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_with_biography_db_column])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"biography\")\n"], "sample_974": ["def test_ccode_AugmentedAssignment():\n    expr = aug_assign(x, '+=', y)\n    assert ccode(expr) == 'x += y;'\n    expr = aug_assign(x, '-=', y)\n    assert ccode(expr) == 'x -= y;'\n    expr = aug_assign(x, '*=', y)\n    assert ccode(expr) == 'x *= y;'\n    expr = aug_assign(x, '/=', y)\n    assert ccode(expr) == 'x /= y;'\n    expr = aug_assign(x, '%=', y)\n    assert ccode(expr) == 'x %= y;'\n"], "sample_388": ["    def configure_user(self, request, user, created=True):\n        user.email = request.META.get(RemoteUserTest.email_header, \"\")\n        user.save()\n        return user\n"], "sample_817": ["def test_sparse_matrix_variance():\n    # Test VarianceThreshold with sparse matrix and custom variance.\n    X = bsr_matrix(data)\n    sel = VarianceThreshold(threshold=1.5).fit(X)\n    assert_array_equal([1, 3], sel.get_support(indices=True))\n"], "sample_259": ["def test_prefetch_object_with_queryset(self):\n    book1 = Book.objects.get(id=self.book1.id)\n    book2 = Book.objects.get(id=self.book2.id)\n    with self.assertNumQueries(1):\n        prefetch_related_objects(\n            [book1],\n            Prefetch('authors', queryset=Author.objects.filter(name__startswith='C'))\n        )\n    with self.assertNumQueries(1):\n        prefetch_related_objects(\n            [book1, book2],\n            Prefetch('authors', queryset=Author.objects.filter(name__startswith='J'))\n        )\n    with self.assertNumQueries(0):\n        self.assertCountEqual(book2.authors.all(), [self.author1])\n"], "sample_169": ["def test_key_transform_with_lookups(self):\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__d__0__contains='e'),\n        [self.objs[4]],\n    )\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__baz__has_key='c'),\n        [self.objs[7]],\n    )\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__baz__has_keys=['a', 'c']),\n        [self.objs[7]],\n    )\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__baz__has_any_keys=['a', 'x']),\n        [self.objs[7]],\n    )\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__contains=KeyTransform('bax', 'value')),\n        [self.objs[7]],\n    )\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__has_key=KeyTextTransform('foo', 'value')),\n        [self.objs[7]],\n    )\n    if connection.vendor != 'oracle':\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__baz__contained_by={'a': 'b', 'c': 'd', 'e': 'f'}),\n            [self.objs[7]],\n        )\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__contained_by=KeyTransform('x', RawSQL(self.raw_sql, ['{\"x\": {\"a\": \"b\", \"c\": 1, \"d\": \"e\"}}']))),\n            [self.objs[7]],\n        )\n"], "sample_561": ["def test_marker_fillstyle_change():\n    marker = markers.MarkerStyle(\"o\", fillstyle=\"full\")\n    assert marker.get_fillstyle() == \"full\"\n    marker._set_fillstyle(\"none\")\n    assert marker.get_fillstyle() == \"none\"\n"], "sample_374": ["def test_nested_prefetch_with_duplicate_prefetcher(self):\n    \"\"\"\n    Nested prefetches whose name clashes with descriptor names\n    (Person.houses here) are allowed.\n    \"\"\"\n    occupants = Person.objects.prefetch_related(\n        Prefetch('houses', to_attr='some_attr_name'),\n        Prefetch('houses', queryset=House.objects.prefetch_related('main_room')),\n    )\n    houses = House.objects.prefetch_related(Prefetch('occupants', queryset=occupants))\n    with self.assertNumQueries(5):\n        self.traverse_qs(list(houses), [['occupants', 'houses', 'main_room']])\n"], "sample_910": ["def test_log_collector(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    collector = logging.LogCollector()\n    with collector.collect():\n        logger.info('message1')\n        logger.warning('message2', location='index')\n\n    assert len(collector.logs) == 2\n    assert collector.logs[0].msg == 'message1'\n    assert collector.logs[1].msg == 'message2'\n    assert collector.logs[1].location == 'index.txt'\n"], "sample_720": ["def test_power_transformer_yeo_johnson():\n    X = np.abs(X_2d)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method='yeo-johnson', standardize=standardize)\n\n        X_trans_class = pt.fit_transform(X)\n        X_trans_func = power_transform(X, method='yeo-johnson', standardize=standardize)\n\n        for X_trans in [X_trans_class, X_trans_func]:\n            for j in range(X_trans.shape[1]):\n                X_expected, lmbda = stats.yeojohnson(X[:, j].flatten())\n\n                if standardize:\n                    X_expected = scale(X_expected)\n\n                assert_almost_equal(X_trans[:, j], X_expected)\n                assert_almost_equal(lmbda, pt.lambdas_[j])\n\n            # Test inverse transformation\n            X_inv = pt.inverse_transform(X_trans)\n            assert_array_almost_equal(X_inv, X)\n\n        assert len(pt.lambdas_) == X.shape[1]\n        assert isinstance(pt.lambdas_, np.ndarray)\n"], "sample_792": ["def test_gnb_var_smoothing():\n    # Test whether var_smoothing is properly used\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([1, 2, 3])\n    clf = GaussianNB(var_smoothing=0.5)\n    clf.fit(X, y)\n    assert_greater(clf.sigma_.min(), 0.5)\n"], "sample_955": ["def test_unparse_subscript_slice(source, expected):\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].value, source) == expected\n"], "sample_869": ["def test_multilabel_jaccard_similarity_score_sample_weight():\n    # Dense label indicator matrix format\n    y1 = np.array([[0, 1, 1], [1, 0, 1]])\n    y2 = np.array([[0, 0, 1], [1, 0, 1]])\n    sample_weight = np.array([1, 2])\n\n    # size(y1 \\inter y2) = [1, 2]\n    # size(y1 \\union y2) = [2, 2]\n\n    assert jaccard_similarity_score(y1, y2, sample_weight=sample_weight) == 0.8\n    assert jaccard_similarity_score(y1, y1, sample_weight=sample_weight) == 1\n    assert jaccard_similarity_score(y2, y2, sample_weight=sample_weight) == 1\n    assert jaccard_similarity_score(y2, np.logical_not(y2), sample_weight=sample_weight) == 0\n    assert jaccard_similarity_score(y1, np.logical_not(y1), sample_weight=sample_weight) == 0\n    assert jaccard_similarity_score(y1, np.zeros(y1.shape), sample_weight=sample_weight) == 0\n    assert jaccard_similarity_score(y2, np.zeros(y1.shape), sample_weight=sample_weight) == 0\n"], "sample_1177": ["def test_issue_15893_complex():\n    f = Function('f', complex=True)\n    x = Symbol('x', real=True)\n    eq = Derivative(Abs(f(x)), f(x))\n    assert eq.doit() == sign(f(x)) * conjugate(f(x)) / Abs(f(x))\n"], "sample_965": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n    @singledispatch\n        pass\n\n    @func.register(int)\n        pass\n\n    assert inspect.is_singledispatch_function(func) is True\n    assert inspect.is_singledispatch_function(func.register) is False\n\n        pass\n\n    assert inspect.is_singledispatch_function(not_singledispatch) is False\n"], "sample_775": ["def test_indent_at_name():\n    # Test the indent_at_name parameter\n    pp = _EstimatorPrettyPrinter(compact=True, indent=2, indent_at_name=False)\n    lr = LogisticRegression(C=99)\n    expected = \"\"\"\n  LogisticRegression(C=99, class_weight=None, dual=False, fit_intercept=True,\n                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n                     multi_class='warn', n_jobs=None, penalty='l2',\n                     random_state=None, solver='warn', tol=0.0001, verbose=0,\n                     warm_start=False)\"\"\"\n    expected = expected[1:]  # remove first \\n\n    assert pp.pformat(lr) == expected\n\n    pp = _EstimatorPrettyPrinter(compact=True, indent=2, indent_at_name=True)\n    lr = LogisticRegression(C=99)\n    expected = \"\"\""], "sample_325": ["def test_field_deep_copy_widget(self):\n    class CustomTextInput(TextInput):\n            kwargs['attrs'] = {'class': 'custom-class'}\n            super().__init__(**kwargs)\n\n    field = CharField(widget=CustomTextInput())\n    field_copy = copy.deepcopy(field)\n    self.assertIsInstance(field_copy, CharField)\n    self.assertIsNot(field_copy.widget, field.widget)\n    self.assertIsInstance(field_copy.widget, CustomTextInput)\n    self.assertIsNot(field_copy.widget.attrs, field.widget.attrs)\n"], "sample_205": ["def test_update_error_dict(self):\n    error_dict = {}\n    exception = ValidationError('message')\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['message']})\n\n    error_dict = {}\n    exception = ValidationError({'field1': 'error1', 'field2': 'error2'})\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['error1'], 'field2': ['error2']})\n\n    error_dict = {'field1': ['error1']}\n    exception = ValidationError({'field2': 'error2'})\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['error1'], 'field2': ['error2']})\n"], "sample_85": ["def test_fast_delete_with_signals(self):\n        pass\n\n        pass\n\n    models.signals.pre_delete.connect(pre_delete_receiver, sender=User)\n    models.signals.post_delete.connect(post_delete_receiver, sender=User)\n\n    u = User.objects.create(avatar=Avatar.objects.create())\n    a = Avatar.objects.get(pk=u.avatar_id)\n\n    # 1 query to fast-delete the user\n    # 1 query to delete the avatar\n    # 1 query for pre_delete signal\n    # 1 query for post_delete signal\n    self.assertNumQueries(4, a.delete)\n\n    self.assertFalse(User.objects.exists())\n    self.assertFalse(Avatar.objects.exists())\n\n    models.signals.pre_delete.disconnect(pre_delete_receiver, sender=User)\n    models.signals.post_delete.disconnect(post_delete_receiver, sender=User)\n"], "sample_634": ["def test_expand_modules_with_non_existent_file(self, files_or_modules, expected):\n    \"\"\"Test expand_modules with a non-existent file\"\"\"\n    ignore_list, ignore_list_re = [], []\n    modules, errors = expand_modules(\n        files_or_modules,\n        ignore_list,\n        ignore_list_re,\n        get_global_option(self, \"ignore-paths\"),\n    )\n    assert modules == expected\n    assert len(errors) == 1\n    assert errors[0][\"key\"] == \"fatal\"\n    assert errors[0][\"mod\"] == \"non_existent_file\"\n    assert isinstance(errors[0][\"ex\"], ImportError)\n"], "sample_909": ["def test_attributes_with_ivar(self):\n    docstring = \"\"\"\\"], "sample_612": ["def test_groupby_bins_multidim_with_nan():\n    array = make_groupby_multidim_example_array()\n    array[0, 0, 0] = np.nan\n    bins = [0, 15, 20]\n    bin_coords = pd.cut(array[\"lat\"].values.flat, bins).categories\n    expected = DataArray([15, 40], dims=\"lat_bins\", coords={\"lat_bins\": bin_coords})\n    actual = array.groupby_bins(\"lat\", bins).map(lambda x: x.sum(skipna=True))\n    assert_identical(expected, actual)\n"], "sample_399": ["def test_aggregation_default_using_float_from_python(self):\n    result = Book.objects.filter(rating__lt=3.0).aggregate(\n        value=Sum(\"price\", default=0.0),\n    )\n    self.assertEqual(result[\"value\"], 0.0)\n"], "sample_91": ["def test_permission_denied(self):\n    request = self.request_factory.get('/')\n    response = permission_denied(request, Exception(\"Permission Denied\"))\n    self.assertContains(response, b'<h1>403 Forbidden</h1>', status_code=403)\n    self.assertContains(response, b'Permission Denied')\n"], "sample_1104": ["def test_MatPow():\n    A = MatrixSymbol(\"A\", 2, 2)\n    assert str(A**2) == \"A**2\"\n    assert str(A**-1) == \"A**(-1)\"\n"], "sample_293": ["def test_include_app_name_namespace_override(self):\n    self.assertEqual(\n        include(self.app_urls, namespace='override'),\n        (self.app_urls, 'inc-app', 'override')\n    )\n"], "sample_56": ["def test_list_display_links_not_in_list_display(self):\n    class SongAdmin(admin.ModelAdmin):\n        list_display = [\"pk\", \"title\"]\n        list_display_links = [\"album\"]\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'list_display_links[0]' refers to 'album', which is not defined in 'list_display'.\",\n            obj=SongAdmin,\n            id='admin.E111',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_260": ["def test_create_model_alter_managers(self):\n    \"\"\"\n    AlterModelManagers should optimize into CreateModel.\n    \"\"\"\n    managers = [('custom_manager', models.Manager())]\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n                options={'verbose_name': 'Foo'},\n                bases=(UnicodeModel,),\n                managers=[('objects', models.Manager())],\n            ),\n            migrations.AlterModelManagers(\"Foo\", managers),\n        ],\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n                options={'verbose_name': 'Foo'},\n                bases=(UnicodeModel,),\n                managers=managers,\n            ),\n        ],\n    )\n"], "sample_889": ["def test_calibration_with_sample_aligned_fit_param(data):\n    \"\"\"Check that CalibratedClassifierCV enforces sample alignment for fit\n    parameters when sample_weight is not provided.\"\"\"\n\n    class TestClassifier(LogisticRegression):\n            assert fit_param is not None\n            assert len(fit_param) == len(y)\n            return super().fit(X, y, sample_weight=sample_weight)\n\n    CalibratedClassifierCV(estimator=TestClassifier()).fit(\n        *data, fit_param=np.ones(len(data[1]))\n    )\n"], "sample_1175": ["def test_issue_18400():\n    assert pretty(Integral(x**2, (x, 0, 1))**2) == \\"], "sample_389": ["    def test_get_full_path_with_query_string(self):\n        request = HttpRequest()\n        request.path = \"/test/\"\n        request.META[\"QUERY_STRING\"] = \"param1=value1&param2=value2\"\n        self.assertEqual(request.get_full_path(), \"/test/?param1=value1&param2=value2\")\n"], "sample_336": ["    def test_urlpattern_resolve_with_prefix(self):\n        with override_script_prefix('/prefix/'):\n            match = resolve('/prefix/normal/42/37/')\n            self.assertEqual(match.url_name, 'normal-view')\n            self.assertEqual(match.kwargs, {'arg1': '42', 'arg2': '37'})\n"], "sample_276": ["def test_model_detail_with_custom_field(self):\n    class CustomField(models.Field):\n        description = \"A custom field type\"\n\n    class CustomModel(models.Model):\n        custom_field = CustomField()\n\n    response = self.client.get(reverse('django-admindocs-models-detail', args=['admin_docs', 'custommodel']))\n    self.assertContains(response, '<td>custom_field</td>')\n    self.assertContains(response, '<td>A custom field type</td>')\n"], "sample_757": ["def test_one_hot_encoder_unseen_categories():\n    X = [['Male', 1], ['Female', 3], ['Female', 2]]\n    enc = OneHotEncoder(categories=[['Male', 'Female'], [1, 2, 3]])\n    enc.fit(X)\n\n    X_new = [['Male', 4], ['Unknown', 2]]\n    enc.handle_unknown = 'ignore'\n    X_tr = enc.transform(X_new)\n    exp = np.array([[1., 0., 0., 0.], [0., 0., 1., 0.]])\n    assert_array_equal(X_tr.toarray(), exp)\n\n    enc.handle_unknown = 'error'\n    with pytest.raises(ValueError, match=\"Found unknown categories\"):\n        enc.transform(X_new)\n"], "sample_1166": ["def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n"], "sample_128": ["    def test_partial_index_with_functions(self):\n        with connection.schema_editor() as editor:\n            index = Index(\n                name='headline_length_idx',\n                fields=['headline'],\n                condition=Q(headline__length__gt=10),\n            )\n            self.assertIn(\n                'WHERE CHAR_LENGTH(%s)' % editor.quote_name('headline'),\n                str(index.create_sql(Article, schema_editor=editor))\n            )\n            editor.add_index(index=index, model=Article)\n            with connection.cursor() as cursor:\n                self.assertIn(index.name, connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                ))\n            editor.remove_index(index=index, model=Article)\n"], "sample_803": ["def test_roc_auc_score_pos_label_errors():\n    # Raise an error when pos_label is not in binary y_true\n    y_true = np.array([0, 1])\n    y_pred = np.array([0, 1])\n    error_message = (\"pos_label=2 is invalid. Set it to a label in y_true.\")\n    assert_raise_message(ValueError, error_message, roc_auc_score,\n                         y_true, y_pred, pos_label=2)\n    # Raise an error for multilabel-indicator y_true with\n    # pos_label other than 1\n    y_true = np.array([[1, 0], [0, 1], [0, 1], [1, 0]])\n    y_pred = np.array([[0.9, 0.1], [0.1, 0.9], [0.8, 0.2], [0.2, 0.8]])\n    error_message = (\"Parameter pos_label is fixed to 1 for multilabel\"\n                     \"-indicator y_true. Do not set pos_label or set \"\n                     \"pos_label to 1.\")\n    assert_raise_message(ValueError, error_message, roc_auc_score,\n                         y_true, y_pred, pos_label=0)\n"], "sample_28": ["def test_header_insert_before_keyword_with_duplicates(self):\n    \"\"\"\n    Test that a keyword name or tuple can be used to insert new keywords\n    before a keyword that has duplicates.\n\n    Regression test for https://github.com/spacetelescope/PyFITS/issues/12\n    \"\"\"\n\n    header = fits.Header(\n        [(\"NAXIS1\", 10), (\"COMMENT\", \"Comment 1\"), (\"COMMENT\", \"Comment 3\"), (\"NAXIS1\", 20)]\n    )\n\n    header.insert(\"NAXIS1\", (\"NAXIS\", 15), before=True)\n    assert list(header.keys())[0] == \"NAXIS\"\n    assert header[0] == 15\n    assert header.comments[0] == \"\"\n    assert list(header.keys())[1] == \"NAXIS1\"\n    assert header[1] == 10\n    assert list(header.keys())[2] == \"NAXIS1\"\n    assert header[2] == 20\n"], "sample_883": ["def test_bayesian_ridge_max_iter_default():\n    \"\"\"Check that the default value of `max_iter` is used when `max_iter` is not set.\"\"\"\n    X, y = diabetes.data, diabetes.target\n    model = BayesianRidge()\n    model.fit(X, y)\n    assert model.max_iter == 300\n"], "sample_511": ["def test_subplot_mosaic():\n    fig, ax_dict = plt.subplot_mosaic({'A': [1, 2], 'B': [3, 4]})\n    assert isinstance(fig, plt.Figure)\n    assert isinstance(ax_dict, dict)\n    assert set(ax_dict.keys()) == {'A', 'B'}\n    assert isinstance(ax_dict['A'], plt.Axes)\n    assert isinstance(ax_dict['B'], plt.Axes)\n"], "sample_676": ["def test_line_with_reprcrash_unicode_surrogate(monkeypatch):\n    import _pytest.terminal\n    from wcwidth import wcswidth\n\n    mocked_verbose_word = \"FAILED\"\n    mocked_pos = \"some::nodeid\"\n\n        return mocked_pos\n\n    monkeypatch.setattr(_pytest.terminal, \"_get_pos\", mock_get_pos)\n\n    class config(object):\n        pass\n\n    class rep(object):\n            return mocked_verbose_word\n\n        class longrepr:\n            class reprcrash:\n                pass\n\n        __tracebackhide__ = True\n        if msg:\n            rep.longrepr.reprcrash.message = msg\n        actual = _get_line_with_reprcrash_message(config, rep(), width)\n\n        assert actual == expected\n        if actual != \"%s %s\" % (mocked_verbose_word, mocked_pos):\n            assert len(actual) <= width\n            assert wcswidth(actual) <= width\n\n    # Test unicode surrogate safety.\n    check(u\"\\ud83d\\ude00\\ud83d\\ude00\\ud83d\\ude00\\ud83d\\ude00\\ud83d\\ude00\\n2nd line\", 29, u\"FAILED some::nodeid - ...\")\n    check(u\"\\ud83d\\ude00\\ud83d\\ude00\\ud83d\\ude00\\ud83d\\ude00\\ud83d\\ude00\\n2nd line\", 30, u\"FAILED some::nodeid - ...\")\n    check(u\"\\ud83d\\ude00\\ud83d\\ude00\\ud83d\\ude00\\ud83d\\ude00\\ud83d\\ude00\\n2nd line\", "], "sample_152": ["def test_fast_delete_with_keeping_parents(self):\n    child = RChild.objects.create()\n    parent_id = child.r_ptr_id\n    # 1 for self delete, 1 for fast delete of empty \"rchild\" qs.\n    self.assertNumQueries(2, child.delete(keep_parents=True))\n    self.assertFalse(RChild.objects.filter(id=child.id).exists())\n    self.assertTrue(R.objects.filter(id=parent_id).exists())\n"], "sample_247": ["def test_alias_with_m2m(self):\n    qs = Book.objects.alias(author_age=F('authors__age')).filter(pk=self.b1.pk).order_by('author_age')\n    self.assertIs(hasattr(qs.first(), 'author_age'), False)\n    self.assertEqual(qs[0].authors.all()[0].age, 34)\n    self.assertEqual(qs[1].authors.all()[0].age, 35)\n"], "sample_715": ["def test_cross_val_predict_method_checking_with_failing_estimator():\n    # Test that cross_val_predict does not check estimator methods before fitting\n    # even when the estimator fails to fit\n    est = FailingClassifier(FailingClassifier.FAILING_PARAMETER)\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=10, n_classes=2, random_state=42)\n    assert_raises(ValueError, cross_val_predict, est, X, y, method='predict_proba')\n"], "sample_544": ["def test_axesimage_get_extent():\n    # generate dummy image to test get_extent method\n    ax = plt.gca()\n    im = AxesImage(ax)\n    with pytest.raises(RuntimeError, match=\"You must first set the image array\"):\n        im.get_extent()\n    z = np.arange(12, dtype=float).reshape((4, 3))\n    im.set_data(z)\n    assert im.get_extent() == (-0.5, 2.5, 3.5, -0.5)\n"], "sample_545": ["def test_subfigures_with_different_dpi():\n    fig = plt.figure()\n    sub_fig1 = fig.subfigures(nrows=1, ncols=2, dpi=100)\n    sub_fig2 = fig.subfigures(nrows=1, ncols=2, dpi=200)\n\n    assert sub_fig1[0].get_dpi() == 100\n    assert sub_fig1[1].get_dpi() == 100\n    assert sub_fig2[0].get_dpi() == 200\n    assert sub_fig2[1].get_dpi() == 200\n"], "sample_640": ["def test_is_overload_stub() -> None:\n    code = astroid.extract_node(\n        \"\"\"\n    from typing import overload\n\n    @overload\n        ...\n\n        return x\n\n    class MyClass:\n        @overload\n            ...\n\n            return x\n    \"\"\"\n    )\n    assert isinstance(code, list) and len(code) == 2\n\n    assert isinstance(code[0], nodes.FunctionDef)\n    assert utils.is_overload_stub(code[0]) is True\n    assert isinstance(code[1], nodes.FunctionDef)\n    assert utils.is_overload_stub(code[1]) is True\n"], "sample_698": ["def test_coloredlogformatter_with_extra_fields() -> None:\n    logfmt = \"%(filename)-25s %(lineno)4d %(levelname)-8s %(message)s %(extra_field)s\"\n\n    record = logging.LogRecord(\n        name=\"dummy\",\n        level=logging.INFO,\n        pathname=\"dummypath\",\n        lineno=10,\n        msg=\"Test Message\",\n        args=(),\n        exc_info=None,\n        extra={\"extra_field\": \"Extra Info\"},\n    )\n\n    tw = TerminalWriter()\n    tw.hasmarkup = True\n    formatter = ColoredLevelFormatter(tw, logfmt)\n    output = formatter.format(record)\n    assert output == (\n        \"dummypath                   10 \\x1b[32mINFO    \\x1b[0m Test Message Extra Info\"\n    )\n\n    tw.hasmarkup = False\n    formatter = ColoredLevelFormatter(tw, logfmt)\n    output = formatter.format(record)\n    assert output == (\"dummypath                   10 INFO     Test Message Extra Info\")\n"], "sample_423": ["def test_alter_field_to_fk_dependency_other_app_with_initial_true(self):\n    class Migration(migrations.Migration):\n        initial = True\n        operations = [\n            migrations.CreateModel(\"Author\", name=\"Author\", fields=[(\"id\", models.AutoField(primary_key=True))]),\n            migrations.CreateModel(\"Book\", name=\"Book\", fields=[(\"author\", models.ForeignKey(\"Author\", models.CASCADE))]),\n        ]\n\n    migration = Migration(\"0001_initial\", \"test_app\")\n    autodetector = MigrationAutodetector(None, self.make_project_state([migration]))\n    changes = autodetector._detect_changes()\n    self.assertNumberMigrations(changes, \"test_app\", 1)\n    self.assertOperationTypes(changes, \"test_app\", 0, [\"CreateModel\", \"CreateModel\"])\n    self.assertMigrationDependencies(changes, \"test_app\", 0, [])\n"], "sample_911": ["def test_xref_consistency_cpp_roles(app, status, warning):\n    app.builder.build_all()\n\n    test = 'xref_consistency.html'\n    output = (app.outdir / test).read_text()\n\n        pattern = (r'{role}-role:.*?'\n                   r'<(?P<tag>{tag}) .*?class=[\"\\'](?P<classes>.*?)[\"\\'].*?>'\n                   r'.*'\n                   r'</(?P=tag)>').format(role=role, tag=tag)\n        result = re.search(pattern, output)\n        expect = '''\\"], "sample_1169": ["def test_canonical_ordering_AntiSymmetricTensor_with_dummies():\n    v = symbols(\"v\")\n\n    a, b = symbols(('a','b'), above_fermi=True, cls=Dummy)\n    i, j = symbols(('i','j'), below_fermi=True, cls=Dummy)\n\n    # Test with dummies\n    assert AntiSymmetricTensor(v, (i, j), (a, b)) == -AntiSymmetricTensor(v, (j, i), (a, b))\n    assert AntiSymmetricTensor(v, (i, j), (a, b)) == AntiSymmetricTensor(v, (j, i), (b, a))\n    assert AntiSymmetricTensor(v, (i, j), (a, b)) == -AntiSymmetricTensor(v, (i, j), (b, a))\n    assert AntiSymmetricTensor(v, (i, i), (a, b)) == 0\n    assert AntiSymmetricTensor(v, (a, b), (i, i)) == 0\n"], "sample_660": ["def test_logging_passing_tests_enabled_logs_test_output(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        junit_log_passing_tests=True\n        junit_logging=system-out\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n        import sys\n\n            sys.stdout.write('This is stdout')\n            sys.stderr.write('This is stderr')\n            logging.warning('hello')\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testcase\")\n    assert len(node.find_by_tag(\"system-err\")) == 1\n    assert len(node.find_by_tag(\"system-out\")) == 1\n"], "sample_798": ["def test_ridge_classifier_cv_store_cv_values_with_cv():\n    x = np.array([[-1.0, -1.0], [-1.0, 0], [-.8, -1.0],\n                  [1.0, 1.0], [1.0, 0.0]])\n    y = np.array([1, 1, 1, -1, -1])\n\n    n_samples = x.shape[0]\n    alphas = [1e-1, 1e0, 1e1]\n    n_alphas = len(alphas)\n\n    cv = KFold(5)\n    r = RidgeClassifierCV(alphas=alphas, cv=cv, store_cv_values=True)\n\n    # with len(y.shape) == 1\n    n_targets = 1\n    with pytest.raises(ValueError):\n        r.fit(x, y)\n\n    # with len(y.shape) == 2\n    y = np.array([[1, 1, 1, -1, -1],\n                  [1, -1, 1, -1, 1],\n                  [-1, -1, 1, -1, -1]]).transpose()\n    n_targets = y.shape[1]\n    with pytest.raises(ValueError):\n        r.fit(x, y)\n"], "sample_1188": ["def test_pretty_print_unicode_d():\n    assert upretty(d[0]) == '(0|0)'\n    assert upretty(d[1]) == '(i_N|k_N)'\n    assert upretty(d[4]) == '(a) (i_N|k_N)'\n    assert upretty(d[5]) == '(a) (i_N|k_N) + (-b) (j_N|k_N)'\n    assert upretty(d[7]) == upretty_d_7\n    assert upretty(d[10]) == '(cos(a)) (i_C|k_N) + (-sin(a)) (j_C|k_N)'\n"], "sample_97": ["def test_file_deletion(self, mocked_modules, notify_mock):\n    self.reloader.watch_file(self.existing_file)\n    with self.tick_twice():\n        self.existing_file.unlink()\n    self.assertEqual(notify_mock.call_count, 1)\n    self.assertCountEqual(notify_mock.call_args[0], [self.existing_file])\n"], "sample_851": ["def test_regression_metrics_with_sample_weight():\n    y_true = np.array([1, 2, 3, 4, 5])\n    y_pred = np.array([1.1, 2.2, 3.3, 4.4, 5.5])\n    sample_weight = np.array([0.1, 0.2, 0.3, 0.2, 0.2])\n\n    assert_almost_equal(mean_squared_error(y_true, y_pred, sample_weight=sample_weight), 0.016, decimal=3)\n    assert_almost_equal(mean_absolute_error(y_true, y_pred, sample_weight=sample_weight), 0.16, decimal=2)\n    assert_almost_equal(median_absolute_error(y_true, y_pred), 0.1, decimal=1)\n    assert_almost_equal(r2_score(y_true, y_pred, sample_weight=sample_weight), 0.994, decimal=3)\n    assert_almost_equal(explained_variance_score(y_true, y_pred, sample_weight=sample_weight), 0.994, decimal=3)\n"], "sample_449": ["def test_ipv6_support(self):\n    \"\"\"WSGIServer supports IPv6.\"\"\"\n    server = WSGIServer((\"::1\", 0), WSGIRequestHandler, ipv6=True)\n    self.assertEqual(server.address_family, socket.AF_INET6)\n    server.server_close()\n"], "sample_756": ["def test_min_maxima_ratio():\n    # Test that min_maxima_ratio parameter affects the number of clusters\n    centers = [[1, 1], [-1, -1], [1, -1]]\n    X, labels_true = make_blobs(n_samples=750, centers=centers,\n                                cluster_std=0.4, random_state=0)\n\n    # Compute OPTICS with default min_maxima_ratio\n    clust1 = OPTICS(min_samples=10).fit(X)\n    n_clusters1 = len(set(clust1.labels_)) - int(-1 in clust1.labels_)\n\n    # Compute OPTICS with smaller min_maxima_ratio\n    clust2 = OPTICS(min_samples=10, min_maxima_ratio=0.0005).fit(X)\n    n_clusters2 = len(set(clust2.labels_)) - int(-1 in clust2.labels_)\n\n    # Check that smaller min_maxima_ratio results in more clusters\n    assert n_clusters2 > n_clusters1\n"], "sample_115": ["    def test_get_cleansed_multivaluedict(self):\n        request = self.rf.post('/some_url/', self.breakfast_data)\n        request.sensitive_post_parameters = ['sausage-key', 'bacon-key']\n        reporter_filter = SafeExceptionReporterFilter()\n        cleansed_dict = reporter_filter.get_cleansed_multivaluedict(request, request.POST)\n        self.assertEqual(cleansed_dict['sausage-key'], reporter_filter.cleansed_substitute)\n        self.assertEqual(cleansed_dict['bacon-key'], reporter_filter.cleansed_substitute)\n        self.assertEqual(cleansed_dict['baked-beans-key'], 'baked-beans-value')\n        self.assertEqual(cleansed_dict['hash-brown-key'], 'hash-brown-value')\n"], "sample_778": ["def test_nmf_zero_input():\n    # Test that NMF handles zero input correctly\n    X = np.zeros((10, 10))\n    model = NMF(n_components=5, init='random', random_state=0)\n    W = model.fit_transform(X)\n    H = model.components_\n    assert_array_equal(W, np.zeros((10, 5)))\n    assert_array_equal(H, np.zeros((5, 10)))\n"], "sample_72": ["def test_serialize_model_field_with_upload_to(self):\n    \"\"\"\n    Test serializing a ModelField with an upload_to function.\n    \"\"\"\n    field = models.FileField(upload_to=TestModel1.upload_to)\n    string = MigrationWriter.serialize(field)[0]\n    self.assertEqual(\n        string,\n        \"models.FileField(upload_to=migrations.test_writer.TestModel1.upload_to)\"\n    )\n"], "sample_846": ["def test_column_transformer_with_empty_transformer_list():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    ct = ColumnTransformer([])\n    assert_array_equal(ct.fit_transform(X_array), X_array)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_array)\n    assert len(ct.transformers_) == 0\n"], "sample_538": ["def test_transform_angles_radians():\n    t = mtransforms.Affine2D()  # Identity transform\n    angles = np.array([np.pi/9, np.pi/4, np.pi/3])\n    points = np.array([[0, 0], [1, 1], [2, 2]])\n\n    # Identity transform does not change angles\n    new_angles = t.transform_angles(angles, points, radians=True)\n    assert_array_almost_equal(angles, new_angles)\n\n    # Test with radians=False\n    angles_deg = np.degrees(angles)\n    new_angles_deg = t.transform_angles(angles_deg, points, radians=False)\n    assert_array_almost_equal(angles_deg, new_angles_deg)\n"], "sample_850": ["def test_nystroem_sparse_input():\n    # Test Nystroem with sparse input\n    rnd = np.random.RandomState(42)\n    X = rnd.uniform(size=(10, 4))\n    X_sparse = csr_matrix(X)\n\n    nystroem = Nystroem(n_components=2, random_state=rnd)\n    X_transformed = nystroem.fit_transform(X_sparse)\n    assert X_transformed.shape == (X.shape[0], 2)\n\n    # Check that the result is the same as with dense input\n    X_transformed_dense = nystroem.fit_transform(X)\n    assert_array_almost_equal(X_transformed, X_transformed_dense)\n"], "sample_174": ["def test_adapt_ipaddressfield_value(self):\n    self.assertIsNone(self.ops.adapt_ipaddressfield_value(None))\n    self.assertEqual(self.ops.adapt_ipaddressfield_value('192.168.0.1'), '192.168.0.1')\n"], "sample_88": ["def test_send_messages_with_fail_silently(self):\n    \"\"\"\n    A message isn't sent if it doesn't have any recipients and fail_silently is True.\n    \"\"\"\n    backend = smtp.EmailBackend()\n    backend.connection = True\n    backend.fail_silently = True\n    email = EmailMessage('Subject', 'Content', 'from@example.com', to=[])\n    sent = backend.send_messages([email])\n    self.assertEqual(sent, 0)\n"], "sample_552": ["def test_add_subplot_kwargs_with_sharex_sharey():\n    # fig.add_subplot() with sharex and sharey should create new axes with the same limits.\n    fig, ax1 = plt.subplots()\n    ax1.set_xlim(0, 10)\n    ax1.set_ylim(0, 10)\n    ax2 = fig.add_subplot(1, 1, 1, sharex=ax1, sharey=ax1)\n    assert ax2.get_xlim() == ax1.get_xlim()\n    assert ax2.get_ylim() == ax1.get_ylim()\n    plt.close()\n"], "sample_706": ["def test_complex_expressions(expr: str) -> None:\n    matcher = {\"true\": True, \"false\": False}.__getitem__\n    assert evaluate(expr, matcher)\n"], "sample_315": ["    def test_en_redirect_with_query_string(self):\n        response = self.client.get('/account/register/?param=value', HTTP_ACCEPT_LANGUAGE='en')\n        self.assertRedirects(response, '/en/account/register/?param=value')\n\n        response = self.client.get(response.headers['location'])\n        self.assertEqual(response.status_code, 200)\n"], "sample_601": ["def test_cftime_strftime_accessor(cftime_rounding_dataarray, cftime_date_type, use_dask):\n    import dask.array as da\n\n    date_format = \"%Y-%m-%d\"\n    expected = xr.DataArray(\n        [\n            [\"0001-01-01\", \"0001-01-01\"],\n            [\"0001-01-02\", \"0001-01-02\"],\n        ],\n        name=\"strftime\",\n    )\n\n    if use_dask:\n        chunks = {\"dim_0\": 1}\n        # Currently a compute is done to inspect a single value of the array\n        # if it is of object dtype to check if it is a cftime.datetime (if not\n        # we raise an error when using the dt accessor).\n        with raise_if_dask_computes(max_computes=1):\n            result = cftime_rounding_dataarray.chunk(chunks).dt.strftime(date_format)\n        expected = expected.chunk(chunks)\n        assert isinstance(result.data, da.Array)\n        assert result.chunks == expected.chunks\n    else:\n        result = cftime_rounding_dataarray.dt.strftime(date_format)\n\n    assert_identical(result, expected)\n"], "sample_1092": ["def test_unevaluated_add():\n    eq = Add(x + y, x + y, evaluate=False)\n    assert cse(eq) == ([(x0, x + y)], [2*x0])\n"], "sample_600": ["def test_CFMaskCoder_encode_missing_fill_values():\n    original = xr.Variable((\"x\",), [0.0, np.nan, 1.0], {\"_FillValue\": np.nan})\n    expected = xr.Variable((\"x\",), [0.0, np.finfo(np.float32).max, 1.0], {\"_FillValue\": np.finfo(np.float32).max})\n    coder = variables.CFMaskCoder()\n    encoded = coder.encode(original)\n    assert_identical(expected, encoded)\n"], "sample_1031": ["def test_quantity_scale_factor_dimension_match():\n    # check that scale factors are the right SI dimensions:\n    for _scale_factor, _dimension in zip(\n            Quantity.SI_quantity_scale_factors.values(),\n            Quantity.SI_quantity_dimension_map.values()):\n        dimex = Quantity.get_dimensional_expr(_scale_factor)\n        assert dimex == 1 or DimensionSystem.default.equivalent_dims(_dimension, Dimension(dimex))\n"], "sample_764": ["def test_column_transformer_remainder_transformer_with_empty_columns():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n\n    ct = ColumnTransformer([('trans1', 'drop', [0, 1, 2])],\n                           remainder=DoubleTrans())\n\n    assert_array_equal(ct.fit_transform(X_array), np.empty((3, 0)))\n    assert_array_equal(ct.fit(X_array).transform(X_array), np.empty((3, 0)))\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], DoubleTrans)\n    assert_array_equal(ct.transformers_[-1][2], [])\n"], "sample_836": ["def test_ovr_decision_function_invalid_input():\n    # Test _ovr_decision_function with invalid input\n    predictions = np.array([[0, 1, 1], [0, 1, 0]])\n    confidences = np.array([[-1e16, 0, -1e16], [1., 2., -3.]])\n    n_classes = 4  # Invalid number of classes\n\n    with pytest.raises(ValueError):\n        _ovr_decision_function(predictions, confidences, n_classes)\n"], "sample_560": ["def test_legend_loc_outside_figure():\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label='test')\n    with pytest.raises(ValueError, match=\"'outside' option for loc='upper right' keyword argument only works for figure legends\"):\n        ax.legend(loc='outside upper right')\n"], "sample_685": ["def test_log_report_captures_according_to_config_option_upon_success(testdir):\n    \"\"\" Test that upon success:\n    (1) `caplog` succeeded to capture the DEBUG message and assert on it => No `Exception` is raised\n    (2) The `DEBUG`, `INFO`, and `WARNING` messages DO appear in the `Captured log call` report\n    (3) The stdout message DOES NOT appear in the test reports due to `--log-level=WARNING`\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n\n            logging.debug('DEBUG log ' + 'message')\n            logging.info('INFO log ' + 'message')\n            logging.warning('WARNING log ' + 'message')\n            print('Print ' + 'message')\n\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_level == logging.WARNING\n\n            with caplog.at_level(logging.DEBUG):\n                function_that_logs()\n\n            if 'DEBUG log ' + 'message' not in caplog.text:\n                raise Exception('caplog failed to ' + 'capture DEBUG')\n    \"\"\"\n    )\n\n    result = testdir.runpytest(\"--log-level=WARNING\")\n    result.stdout.no_fnmatch_line(\"*Exception: caplog failed to capture DEBUG*\")\n    result.stdout.fnmatch_lines(\n        [\"*DEBUG log message*\", \"*INFO log message*\", \"*WARNING log message*\"]\n    )\n    result.stdout.no_fnmatch_line(\"*Print message*\")\n    assert result.ret == 0\n"], "sample_843": ["def test_kernel_bounds(kernel):\n    # Test that the bounds on the kernel parameters are consistent.\n    bounds = kernel.bounds\n    assert bounds.shape[0] == kernel.theta.shape[0]\n    assert bounds.shape[1] == 2\n    assert np.all(bounds[:, 0] >= 0)\n    assert np.all(bounds[:, 1] >= bounds[:, 0])\n"], "sample_1158": ["def test_issue_21536_evaluate_False_with_numpy():\n    if not numpy:\n        skip(\"numpy not installed.\")\n\n    u = sympify(numpy.array([\"x+3*x+2\"]), evaluate=False)\n    v = sympify(numpy.array([\"2*x+4*x+2+4\"]), evaluate=False)\n\n    assert u[0].is_Add and set(u[0].args) == {x, 3*x, 2}\n    assert v[0].is_Add and set(v[0].args) == {2*x, 4*x, 2, 4}\n    assert sympify(numpy.array([\"x+3*x+2\", \"2*x+4*x+2+4\"]), evaluate=False) == [u[0], v[0]]\n"], "sample_587": ["def test_merge_override(self):\n    ds1 = xr.Dataset({\"x\": 0})\n    ds2 = xr.Dataset({\"x\": 1})\n    expected = xr.Dataset({\"x\": 1})\n    assert expected.identical(ds1.merge(ds2, compat=\"override\"))\n    assert expected.identical(ds2.merge(ds1, compat=\"override\"))\n"], "sample_970": ["def test_isabstractmethod():\n    from abc import ABC, abstractmethod\n\n    class AbstractClass(ABC):\n        @abstractmethod\n            pass\n\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(AbstractClass.concrete_method) is False\n    assert inspect.isabstractmethod(AbstractClass().abstract_method) is True\n    assert inspect.isabstractmethod(AbstractClass().concrete_method) is False\n"], "sample_150": ["def test_check_called_when_required(self, mocked_check):\n    command = BaseCommand()\n    command.requires_system_checks = True\n    command.execute(skip_checks=False)\n    self.assertTrue(mocked_check.called)\n"], "sample_972": ["def test_restify_type_hints_typevars_with_constraints():\n    T = TypeVar('T', bound=int)\n    assert restify(T) == \":py:obj:`tests.test_util_typing.T`\"\n    assert restify(List[T]) == \":py:class:`~typing.List`\\\\ [:py:obj:`tests.test_util_typing.T`]\"\n"], "sample_1105": ["def test_matmul_with_generic_identity():\n    assert MatMul(C, GenericIdentity(), D) == MatMul(C, D)\n    assert MatMul(GenericIdentity(), C, D) == MatMul(C, D)\n    assert MatMul(C, D, GenericIdentity()) == MatMul(C, D)\n"], "sample_916": ["def test_xref_consistency_cpp_roles(app, status, warning):\n    app.builder.build_all()\n\n    test = 'xref_consistency.html'\n    output = (app.outdir / test).read_text()\n\n        pattern = (r'{role}-role:.*?'\n                   r'<(?P<tag>{tag}) .*?class=[\"\\'](?P<classes>.*?)[\"\\'].*?>'\n                   r'.*'\n                   r'</(?P=tag)>').format(role=role, tag=tag)\n        result = re.search(pattern, output)\n        expect = '''\\"], "sample_320": ["def test_references_field_by_limit_choices_to(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ForeignKey(\n            \"Other\",\n            models.CASCADE,\n            limit_choices_to={\"field\": models.F(\"other_field\")},\n        ),\n    )\n    self.assertIs(operation.references_field(\"Model\", \"other_field\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Other\", \"field\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Other\", \"other_field\", \"migrations\"), False)\n"], "sample_1157": ["def test_split_symbols_custom_predicate():\n        if symbol not in ('list', 'of', 'unsplittable', 'names'):\n                return _token_splittable(symbol)\n        return False\n\n    transformations = standard_transformations + (split_symbols_custom(can_split), implicit_multiplication,)\n    x = Symbol('x')\n    y = Symbol('y')\n    unsplittable = Symbol('unsplittable')\n\n    assert parse_expr(\"unsplittable\", transformations=transformations) == unsplittable\n    assert parse_expr(\"xy\", transformations=transformations) == x*y\n"], "sample_947": ["def test_build_domain_c_anon_dup_decl_2(app, status, warning):\n    app.builder.build_all()\n    ws = filter_warnings(warning, \"anon-dup-decl-2\")\n    assert len(ws) == 2\n    assert \"WARNING: c:identifier reference target not found: @a\" in ws[0]\n    assert \"WARNING: c:identifier reference target not found: @b\" in ws[1]\n"], "sample_874": ["def test_transform_with_feature_names():\n    sel = StepSelector()\n    sel.fit(X, y, feature_names=feature_names)\n    Xt_actual = sel.transform(X)\n    feature_names_t_actual = sel.get_feature_names_out()\n    assert_array_equal(Xt, Xt_actual)\n    assert_array_equal(feature_names_t, feature_names_t_actual)\n"], "sample_1005": ["def test_Quaternion_latex_printing_with_zero():\n    q = Quaternion(0, y, z, t)\n    assert latex(q) == \"y i + z j + t k\"\n    q = Quaternion(0, 0, z, t)\n    assert latex(q) == \"z j + t k\"\n    q = Quaternion(0, 0, 0, t)\n    assert latex(q) == \"t k\"\n    q = Quaternion(0, 0, 0, 0)\n    assert latex(q) == \"0\"\n"], "sample_1153": ["def test_issue_15893_complex():\n    f = Function('f', complex=True)\n    x = Symbol('x', real=True)\n    eq = Derivative(Abs(f(x)), f(x))\n    assert eq.doit() == sign(f(x)) * conjugate(f(x)) / Abs(f(x))\n"], "sample_924": ["def test_xref_consistency_cpp_roles(app, status, warning):\n    app.builder.build_all()\n\n    test = 'xref_consistency.html'\n    output = (app.outdir / test).read_text()\n\n        pattern = (r'{role}-role:.*?'\n                   r'<(?P<tag>{tag}) .*?class=[\"\\'](?P<classes>.*?)[\"\\'].*?>'\n                   r'.*'\n                   r'</(?P=tag)>').format(role=role, tag=tag)\n        result = re.search(pattern, output)\n        expect = '''\\"], "sample_308": ["def test_time_formats_with_microseconds(self):\n    dt = datetime(2009, 5, 16, 5, 30, 30, 123456)\n\n    self.assertEqual(dateformat.format(dt, 'u'), '123456')\n"], "sample_232": ["def test_key_transform_exact(self):\n    self.assertIs(NullableJSONModel.objects.filter(value__foo=KeyTransform('foo', 'value')).exists(), True)\n    self.assertIs(NullableJSONModel.objects.filter(value__foo=KeyTransform('bar', 'value')).exists(), False)\n"], "sample_610": ["def test_cftimeindex_freq_property(freq, calendar):\n    index = xr.cftime_range(start=\"2000\", periods=3, freq=freq, calendar=calendar)\n    assert index.freq == freq\n"], "sample_455": ["def test_validate_expression_custom_error(self):\n    constraint = models.UniqueConstraint(Lower(\"name\"), name=\"name_lower_uniq\")\n    constraint.violation_error_message = \"Custom message\"\n    constraint.violation_error_code = \"custom_code\"\n    msg = \"Custom message\"\n    with self.assertRaisesMessage(ValidationError, msg) as cm:\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=self.p1.name.upper()),\n        )\n    self.assertEqual(cm.exception.code, \"custom_code\")\n"], "sample_576": ["def test_default_is_no_pyplot(self):\n\n    p = Plot().plot()\n\n    assert not plt.get_fignums()\n    assert isinstance(p._figure, mpl.figure.Figure)\n"], "sample_724": ["def test_imputation_invalid_strategy():\n    # Test imputation with an invalid strategy\n    X = np.array([[1, 2], [np.nan, 3], [7, 6]])\n    imputer = Imputer(missing_values=np.nan, strategy=\"invalid_strategy\")\n    assert_raises(ValueError, imputer.fit, X)\n"], "sample_242": ["def test_year_lookup_bounds(self):\n    lookup = YearLookup(\n        lhs=Value(datetime(2010, 1, 1, 0, 0, 0), output_field=DateTimeField()),\n        rhs=Value(2010),\n    )\n    connection = mock.Mock()\n    connection.ops.year_lookup_bounds_for_datetime_field.return_value = (\n        datetime(2010, 1, 1, 0, 0, 0),\n        datetime(2010, 12, 31, 23, 59, 59),\n    )\n    start, finish = lookup.year_lookup_bounds(connection, 2010)\n    self.assertEqual(start, datetime(2010, 1, 1, 0, 0, 0))\n    self.assertEqual(finish, datetime(2010, 12, 31, 23, 59, 59))\n"], "sample_842": ["def test_kernel_operator_associative():\n    # Adding and multiplying kernels should be associative.\n    # Check addition\n    assert_almost_equal((RBF(2.0) + RBF(3.0) + RBF(4.0))(X),\n                        ((RBF(2.0) + RBF(3.0)) + RBF(4.0))(X))\n\n    # Check multiplication\n    assert_almost_equal((RBF(2.0) * RBF(3.0) * RBF(4.0))(X),\n                        ((RBF(2.0) * RBF(3.0)) * RBF(4.0))(X))\n"], "sample_1026": ["def test_lambdify_with_custom_printer():\n    class CustomPrinter(LambdaPrinter):\n            return f\"custom_{expr}\"\n\n    expr = x + y\n    f = lambdify((x, y), expr, printer=CustomPrinter())\n    assert f(1, 2) == 3\n"], "sample_153": ["def test_mysql_sql_mode_no_engine(self):\n    with mock.patch(\n        'django.db.backends.utils.CursorWrapper.fetchone', create=True,\n        return_value=('',)\n    ):\n        # One warning for each database alias\n        result = check_database_backends(databases=self.databases)\n        self.assertEqual(len(result), 2)\n        self.assertEqual([r.id for r in result], ['mysql.W002', 'mysql.W002'])\n"], "sample_1056": ["def test_numexpr_functions():\n    # Test some of the functions supported by NumExprPrinter\n    assert NumExprPrinter().doprint(sin(x)) == \"evaluate('sin(x)', truediv=True)\"\n    assert NumExprPrinter().doprint(cos(x)) == \"evaluate('cos(x)', truediv=True)\"\n    assert NumExprPrinter().doprint(tan(x)) == \"evaluate('tan(x)', truediv=True)\"\n    assert NumExprPrinter().doprint(sqrt(x)) == \"evaluate('sqrt(x)', truediv=True)\"\n    assert NumExprPrinter().doprint(abs(x)) == \"evaluate('abs(x)', truediv=True)\"\n"], "sample_1076": ["def test_log2_and_log1p():\n    from sympy import log2, log1p\n\n    expr1 = log2(x)\n    expr2 = log1p(x)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr1) == 'numpy.log(x)/numpy.log(2)'\n    assert prntr.doprint(expr2) == 'numpy.log(x + 1)'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr1) == 'numpy.log2(x)'\n    assert prntr.doprint(expr2) == 'numpy.log1p(x)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr1) == 'math.log(x)/math.log(2)'\n    assert prntr.doprint(expr2) == 'math.log1p(x)'\n\n    prntr = MpmathPrinter()\n    assert prntr.doprint(expr1) == 'mpmath.log(x)/mpmath.log(2)'\n    assert prntr.doprint(expr2) == 'mpmath.log(x + 1)'\n"], "sample_1057": ["def test_fully_qualified_modules():\n    from sympy import symbols\n    x, y = symbols('x y')\n    ast = Print((x, y), \"coordinate: %12.5g %12.5g\")\n    assert render_as_module(ast, standard='python3', fully_qualified_modules=True) == \\\n        'import sympy.codegen.ast\\nimport sympy.printing.pycode\\n\\nprint(\"coordinate: %12.5g %12.5g\" % (x, y))'\n    assert render_as_module(ast, standard='python3', fully_qualified_modules=False) == \\\n        'from sympy.codegen.ast import Print\\nfrom sympy.printing.pycode import PythonCodePrinter\\n\\nprint(\"coordinate: %12.5g %12.5g\" % (x, y))'\n"], "sample_196": ["def test_adapt_ipaddressfield_value(self):\n    self.assertIsNone(self.ops.adapt_ipaddressfield_value(None))\n    self.assertEqual(self.ops.adapt_ipaddressfield_value('192.168.0.1'), '192.168.0.1')\n"], "sample_1106": ["def test_matadd_construction():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    matadd = MatAdd(A, B, C)\n    assert isinstance(matadd, MatAdd)\n    assert matadd.args == (A, B, C)\n    assert matadd.shape == (2, 2)\n"], "sample_1088": ["def test_symmetrize_formal():\n    x, y, z = symbols('x y z')\n    s1 = x + y + z\n    s2 = x*y + x*z + y*z\n    s3 = x*y*z\n\n    assert symmetrize(x**2 + y**2 + z**2, x, y, z, formal=True) == \\\n        (s1**2 - 2*s2, 0, [(s1, x + y + z), (s2, x*y + x*z + y*z), (s3, x*y*z)])\n"], "sample_1068": ["def test_MatrixSlice_printing():\n    A = MatrixSymbol(\"A\", 3, 3)\n    assert mcode(A[0:2, 0:2]) == \"A(1:2, 1:2)\"\n    assert mcode(A[0:3, 0:3:2]) == \"A(1:end, 1:2:end)\"\n    assert mcode(A[0:3:2, 0:3]) == \"A(1:2:end, 1:end)\"\n"], "sample_973": ["def test_isabstractmethod():\n    from abc import ABC, abstractmethod\n\n    class AbstractClass(ABC):\n        @abstractmethod\n            pass\n\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(AbstractClass.concrete_method) is False\n    assert inspect.isabstractmethod(AbstractClass().abstract_method) is True\n    assert inspect.isabstractmethod(AbstractClass().concrete_method) is False\n"], "sample_1154": ["def test__linsolve_complex():\n    eqs = [\n        x + I*y - 1 - I,\n        x - I*y - 2 + I\n    ]\n    sol = {x: 1.5, y: 0.5}\n    assert _linsolve(eqs, (x, y)) == sol\n"], "sample_1119": ["def test_inverse_matmul_canonicalization():\n    A = MatrixSymbol('A', 3, 3)\n    B = MatrixSymbol('B', 3, 3)\n    assert Inverse(A*B).doit() == Inverse(B)*Inverse(A).doit()\n"], "sample_1036": ["def test_matmul_with_symbol():\n    x = Symbol('x')\n    assert MatMul(x, A) == MatMul(x, A, evaluate=False)\n    assert MatMul(A, x) == MatMul(A, x, evaluate=False)\n"], "sample_927": ["def test_noindexentry_with_name(app):\n    text = (\".. cpp:function:: void f()\\n\"\n            \"   :noindexentry:\\n\"\n            \".. cpp:function:: void g()\\n\"\n            \"   :noindexentry: h\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index, desc, addnodes.index, desc))\n    assert_node(doctree[0], addnodes.index, entries=[])\n    assert_node(doctree[2], addnodes.index, entries=[('single', 'h', '_CPPv41gv', '', None)])\n"], "sample_588": ["def test_auto_combine_with_different_data_vars(self):\n    objs = [Dataset({\"x\": [0]}), Dataset({\"y\": [1]})]\n    with pytest.warns(FutureWarning, match=\"The datasets supplied require both concatenation and merging\"):\n        auto_combine(objs)\n"], "sample_430": ["def test_alter_index_together_to_index(self):\n    changes = self.get_changes(\n        [AutodetectorTests.author_empty, self.book_index_together],\n        [AutodetectorTests.author_empty, AutodetectorTests.book_indexes],\n    )\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterIndexTogether\", \"AddIndex\"])\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        0,\n        name=\"book\",\n        index_together=set(),\n    )\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        1,\n        model_name=\"book\",\n        fields=[\"author\", \"title\"],\n        name=\"book_title_author_idx\",\n    )\n"], "sample_959": ["def test_domain_cpp_parse_mix_decl_duplicate_with_noindex(app, warning):\n    # Issue 8270 with :noindex:\n    text = (\".. cpp:struct:: A\\n\"\n            \"   :noindex:\\n\"\n            \".. cpp:function:: void A()\\n\"\n            \".. cpp:struct:: A\\n\")\n    restructuredtext.parse(app, text)\n    ws = warning.getvalue().split(\"\\n\")\n    assert len(ws) == 3\n    assert \"index.rst:3: WARNING: Duplicate C++ declaration, also defined at index:1.\" in ws[0]\n    assert \"Declaration is '.. cpp:struct:: A'.\" in ws[1]\n    assert ws[2] == \"\"\n"], "sample_1118": ["def test_matpow_non_square():\n    A = MatrixSymbol('A', n, m)\n    raises(NonSquareMatrixError, lambda: MatPow(A, 2))\n"], "sample_969": ["def test_restify_type_ForwardRef_in_type_hints():\n    from typing import ForwardRef  # type: ignore\n    assert restify(List[ForwardRef(\"int\")]) == (\":py:class:`~typing.List`\\\\ \"\n                                                \"[:py:class:`int`]\")\n"], "sample_1141": ["def test_matrixsymbol_solving_with_constants():\n    A = MatrixSymbol('A', 2, 2)\n    B = Matrix([[1, 2], [3, 4]])\n    Z = ZeroMatrix(2, 2)\n    assert -(-A + B) - A + B == Z\n    assert (-(-A + B) - A + B).simplify() == Z\n    assert (-(-A + B) - A + B).expand() == Z\n    assert (-(-A + B) - A + B - Z).simplify() == Z\n    assert (-(-A + B) - A + B - Z).expand() == Z\n"], "sample_1174": ["def test_issue_15893_complex():\n    f = Function('f', complex=True)\n    x = Symbol('x', real=True)\n    eq = Derivative(Abs(f(x)), f(x))\n    assert eq.doit() == f(x) / Abs(f(x))\n"], "sample_133": ["def test_i18n_language_with_custom_domain(self):\n    \"\"\"\n    Check if the JavaScript i18n view returns a complete language catalog\n    if a custom domain is used.\n    \"\"\"\n    with self.settings(LANGUAGE_CODE='en-us'), override('fr'):\n        response = self.client.get('/jsi18n/app6/custom_domain/')\n        self.assertContains(response, 'this app6 string with custom domain is to be translated')\n"], "sample_1058": ["def test_NumPyPrinter_print_MatMul():\n    p = NumPyPrinter()\n    A = MatrixSymbol(\"A\", 2, 3)\n    B = MatrixSymbol(\"B\", 3, 2)\n    assert p.doprint(A*B) == \"(A).dot(B)\"\n"], "sample_828": ["def test_pairwise_distances_data_derived_params_sparse():\n    # check that pairwise_distances give the same result in sequential and\n    # parallel, when metric has data-derived parameters and input is sparse.\n    with config_context(working_memory=1):  # to have more than 1 chunk\n        rng = np.random.RandomState(0)\n        X = csr_matrix(rng.random_sample((1000, 10)))\n        Y = csr_matrix(rng.random_sample((1000, 10)))\n\n        expected_dist_default_params = pairwise_distances(X, Y, metric=\"seuclidean\")\n        params = {'V': np.var(np.vstack([X.toarray(), Y.toarray()]), axis=0, ddof=1)}\n        expected_dist_explicit_params = pairwise_distances(X, Y, metric=\"seuclidean\", **params)\n        dist = np.vstack(tuple(pairwise_distances_chunked(X, Y, metric=\"seuclidean\", n_jobs=2)))\n\n        assert_allclose(dist, expected_dist_explicit_params)\n        assert_allclose(dist, expected_dist_default_params)\n"], "sample_827": ["def test_inplace_normalize_zero_rows():\n    rs = RandomState(10)\n\n    for inplace_csr_row_normalize in (inplace_csr_row_normalize_l1,\n                                      inplace_csr_row_normalize_l2):\n        for dtype in (np.float64, np.float32):\n            X = np.zeros((10, 5)).astype(dtype)\n            X_csr = sp.csr_matrix(X)\n            for index_dtype in [np.int32, np.int64]:\n                # csr_matrix will use int32 indices by default,\n                # up-casting those to int64 when necessary\n                if index_dtype is np.int64:\n                    X_csr.indptr = X_csr.indptr.astype(index_dtype)\n                    X_csr.indices = X_csr.indices.astype(index_dtype)\n                assert X_csr.indices.dtype == index_dtype\n                assert X_csr.indptr.dtype == index_dtype\n                inplace_csr_row_normalize(X_csr)\n                assert_equal(X_csr.dtype, dtype)\n                assert_array_equal(X_csr.toarray(), X)  # should be unchanged\n"], "sample_154": ["def test_no_issues_returned_when_no_database_errors(self, mocked_check):\n    issues = check_database_backends(databases=self.databases)\n    self.assertEqual(issues, [])\n    mocked_check.assert_called()\n"], "sample_319": ["def test_add_model_with_indexes_and_constraints(self):\n    author = ModelState(\n        \"otherapp\",\n        \"Author\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=200)),\n        ],\n        {\n            \"indexes\": [\n                models.Index(fields=[\"name\"], name=\"create_model_with_indexes_idx\")\n            ],\n            \"constraints\": [\n                models.CheckConstraint(\n                    check=models.Q(name__contains=\"Bob\"), name=\"name_contains_bob\"\n                )\n            ],\n        },\n    )\n    changes = self.get_changes([], [author])\n    added_index = models.Index(\n        fields=[\"name\"], name=\"create_model_with_indexes_idx\"\n    )\n    added_constraint = models.CheckConstraint(\n        check=models.Q(name__contains=\"Bob\"), name=\"name_contains_bob\"\n    )\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(\n        changes, \"otherapp\", 0, [\"CreateModel\", \"AddIndex\", \"AddConstraint\"]\n    )\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"Author\")\n    self.assertOperationAttributes(\n        changes, \"otherapp\", 0, 1, model_name=\"author\", index=added_index\n    )\n    self.assertOperationAttributes(\n        changes, \"otherapp\", 0, 2, model_name=\"author\", constraint=added_constraint\n    )\n"], "sample_415": ["def test_contains_expressions(self):\n    constraint_with_expressions = models.UniqueConstraint(\n        Lower(\"title\"),\n        F(\"author\"),\n        name=\"book_func_uq\",\n    )\n    constraint_without_expressions = models.UniqueConstraint(\n        fields=[\"foo\", \"bar\"],\n        name=\"unique_fields\",\n    )\n    self.assertTrue(constraint_with_expressions.contains_expressions)\n    self.assertFalse(constraint_without_expressions.contains_expressions)\n"], "sample_826": ["def test_one_hot_encoder_drop_first():\n    enc = OneHotEncoder(drop='first')\n    X = [['abc', 2, 55], ['def', 1, 55], ['abc', 3, 55]]\n    trans = enc.fit_transform(X).toarray()\n    exp = [[0, 1], [1, 0], [1, 1]]\n    assert_array_equal(trans, exp)\n    dropped_cats = [cat[feature] for cat, feature in zip(enc.categories_, enc.drop_idx_)]\n    assert_array_equal(dropped_cats, ['abc', 1, 55])\n    assert_array_equal(np.array(X, dtype=object), enc.inverse_transform(trans))\n"], "sample_781": ["def test_forest_feature_importances_shape():\n    X, y = make_classification(n_samples=15, n_features=10, random_state=1,\n                               n_classes=3)\n    clf = RandomForestClassifier(random_state=42).fit(X, y)\n    assert clf.feature_importances_.shape == (10,)\n"], "sample_195": ["def test_adapt_datetimefield_value_unaware(self):\n    now = timezone.now()\n    self.assertEqual(self.ops.adapt_datetimefield_value(now), str(now))\n"], "sample_1152": ["def test_issue_20000():\n    # Test case for issue #20000\n    x, y = symbols('x y', real=True)\n    e = exp(x*log(y))\n    assert powdenest(e) == y**x\n"], "sample_934": ["def test_noindexentry_for_member():\n    text = (\".. cpp:member:: int A::f\\n\"\n            \".. cpp:member:: int A::g\\n\"\n            \"   :noindexentry:\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index, desc, addnodes.index, desc))\n    assert_node(doctree[0], addnodes.index, entries=[('single', 'f (C++ member)', '_CPPvN1A1fE', '', None)])\n    assert_node(doctree[2], addnodes.index, entries=[])\n"], "sample_132": ["def test_sensitive_variables_decorator_with_all_variables(self):\n    \"\"\"\n    The sensitive_variables decorator works when all variables are sensitive.\n    \"\"\"\n    self.verify_paranoid_response(sensitive_view, check_for_POST_params=False)\n    self.verify_paranoid_email(sensitive_view, check_for_POST_params=False)\n"], "sample_731": ["def test_feature_names():\n    data = fetch()\n    expected_feature_names = [\"MedInc\", \"HouseAge\", \"AveRooms\", \"AveBedrms\",\n                              \"Population\", \"AveOccup\", \"Latitude\", \"Longitude\"]\n    assert(expected_feature_names == data.feature_names)\n"], "sample_603": ["def test_summarize_variable_with_unsafe_name_and_dtype():\n    var = xr.Variable([\"<x>\", \"<y>\"], [[1, 2, 3], [4, 5, 6]], {\"foo\": \"bar\"})\n    formatted = fh.summarize_variable(\"<name>\", var, dtype=\"<dtype>\")\n    assert \"&lt;name&gt;\" in formatted\n    assert \"&lt;x&gt;, &lt;y&gt;\" in formatted\n    assert \"&lt;dtype&gt;\" in formatted\n"], "sample_935": ["def test_noindexentry_for_member():\n    text = (\".. cpp:member:: int A::a\\n\"\n            \".. cpp:member:: int A::b\\n\"\n            \"   :noindexentry:\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index, desc, addnodes.index, desc))\n    assert_node(doctree[0], addnodes.index, entries=[('single', 'A::a (C++ member)', '_CPPv4N1A1aE', '', None)])\n    assert_node(doctree[2], addnodes.index, entries=[])\n"], "sample_923": ["def test_xref_consistency_cpp_roles(app, status, warning):\n    app.builder.build_all()\n\n    test = 'xref_consistency.html'\n    output = (app.outdir / test).read_text()\n\n        pattern = (r'{role}-role:.*?'\n                   r'<(?P<tag>{tag}) .*?class=[\"\\'](?P<classes>.*?)[\"\\'].*?>'\n                   r'.*'\n                   r'</(?P=tag)>').format(role=role, tag=tag)\n        result = re.search(pattern, output)\n        expect = '''\\"], "sample_302": ["def test_runshell_signal_handling(self):\n    with mock.patch('subprocess.run') as run:\n        with mock.patch.object(\n            BaseDatabaseClient,\n            'settings_to_cmd_args_env',\n            return_value=([], None),\n        ):\n            with mock.patch('signal.getsignal') as getsignal:\n                with mock.patch('signal.signal') as signal:\n                    self.client.runshell(None)\n                    getsignal.assert_called_once_with(signal.SIGINT)\n                    signal.assert_any_call(signal.SIGINT, signal.SIG_IGN)\n                    signal.assert_any_call(signal.SIGINT, mock.ANY)\n"], "sample_732": ["def test_subset_none():\n    try:\n        data = fetch_kddcup99(subset=None, download_if_missing=False)\n    except IOError:\n        raise SkipTest(\"kddcup99 dataset can not be loaded.\")\n\n    assert_equal(data.data.shape, (494021, 41))\n    assert_equal(data.target.shape, (494021,))\n"], "sample_575": ["def test_label_formatter_input_check(self, x):\n\n    err = \"Label formatter must be an instance of .*?, not <class 'str'>.\"\n    with pytest.raises(TypeError, match=err):\n        Temporal().label(\"{x}\")\n"], "sample_926": ["def test_noindexentry_for_class():\n    text = (\".. cpp:class:: MyClass\\n\"\n            \".. cpp:class:: MyOtherClass\\n\"\n            \"   :noindexentry:\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index, desc, addnodes.index, desc))\n    assert_node(doctree[0], addnodes.index, entries=[('single', 'MyClass (C++ class)', '_CPPv46MyClass', '', None)])\n    assert_node(doctree[2], addnodes.index, entries=[])\n"], "sample_279": ["def test_opclasses_database_constraint(self):\n    UniqueConstraintProduct.objects.create(name='p1', color='red')\n    with self.assertRaises(IntegrityError):\n        UniqueConstraintProduct.objects.create(name='p1', color='red')\n"], "sample_611": ["def test_date_range_with_end(start, end, freq, calendar, use_cftime, expected_type):\n    dr = date_range(\n        start=start, end=end, freq=freq, calendar=calendar, use_cftime=use_cftime\n    )\n\n    assert isinstance(dr, expected_type)\n"], "sample_1064": ["def test_tensorflow_log():\n    if not tf:\n        skip(\"TensorFlow not installed\")\n\n    expr = log(x)\n    assert tensorflow_code(expr) == \"tensorflow.math.log(x)\"\n    _compare_tensorflow_scalar((x,), expr, rng=lambda: random.uniform(0.1, 10))\n"], "sample_948": ["def test_template_args_with_default():\n    # from #3542\n    check('type', \"template<typename T = int> {key}\"\n          \"enable_if_not_array_t = std::enable_if_t<!is_array<T>::value, int>\",\n          {2: \"I0E21enable_if_not_array_t\"},\n          key='using')\n"], "sample_1069": ["def test_octave_matrix_solve():\n    A = MatrixSymbol('A', 3, 3)\n    b = MatrixSymbol('b', 3, 1)\n    x = MatrixSolve(A, b)\n    assert mcode(x) == \"A \\\\ b\"\n"], "sample_1125": ["def test_operator_multiplication():\n    A = Operator('A')\n    B = Operator('B')\n    I = IdentityOperator()\n    assert A*B != B*A\n    assert A*I == A\n    assert I*A == A\n"], "sample_723": ["def test_imputation_invalid_strategy():\n    # Test imputation with an invalid strategy\n    X = np.array([\n        [np.nan, 0, 0, 0, 5],\n        [np.nan, 1, 0, np.nan, 3],\n        [np.nan, 2, 0, 0, 0],\n        [np.nan, 6, 0, 5, 13],\n    ])\n\n    imputer = SimpleImputer(strategy=\"invalid_strategy\")\n    assert_raises(ValueError, imputer.fit, X)\n"], "sample_1142": ["def test_matrix_symbol_transpose():\n    A = MatrixSymbol('A', n, m)\n    assert A.T.shape == (m, n)\n    assert A.T.T == A\n    assert (A.T).T == A\n    assert (A.T).T.T == A\n    assert (A.T).T.T.T == A\n"], "sample_309": ["    def test_parsing_invalid(self):\n        invalid_dates = (\n            'Sun, 06 Nov 1994 08:49:37',\n            'Sun, 06 Nov 1994 08:49:37 UTC',\n            'Sun, 06 Nov 1994 08:49:37 GMT+00:00',\n            'Sun, 06 Nov 1994 08:49:37 GMT-00:00',\n            'Sun, 06 Nov 1994 08:49:37 GMT+01:00',\n            'Sun, 06 Nov 1994 08:49:37 GMT-01:00',\n            'Sun, 06 Nov 1994 08:49:37 GMT+12:34',\n            'Sun, 06 Nov 1994 08:49:37 GMT-12:34',\n            'Sun, 06 Nov 1994 08:49:37 GMT+12:34:56',\n            'Sun, 06 Nov 1994 08:49:37 GMT-12:34:56',\n            'Sun, 06 Nov 1994 08:49:37 GMT+12:34:56.789',\n            'Sun, 06 Nov 1994 08:49:37 GMT-12:34:56.789',\n            'Sun, 06 Nov 1994 08:49:37 GMT+12:34:56.789123',\n            'Sun, 06 Nov 1994 08:49:37 GMT-12:34:56.789123',\n            'Sun,"], "sample_1038": ["def test_MatrixElement_diff_with_MatrixSymbol():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    X = MatrixSymbol('X', n, n)\n    assert (A[0, 0]*B[0, 0]).diff(X[0, 0]) == 0\n    assert (A[0, 0]*B[0, 0]).diff(A[0, 0]) == B[0, 0]\n    assert (A[0, 0]*B[0, 0]).diff(B[0, 0]) == A[0, 0]\n"], "sample_431": ["def test_refresh_fk_on_delete_cascade(self):\n    a = Article.objects.create(\n        headline=\"Parrot programs in Python\",\n        pub_date=datetime(2005, 7, 28),\n    )\n    s1 = SelfRef.objects.create(article=a)\n    a.delete()\n    with self.assertRaises(ObjectDoesNotExist):\n        s1.refresh_from_db()\n"], "sample_604": ["def test_format_timedelta_out_of_bounds():\n    from datetime import timedelta\n\n    delta = timedelta(days=1000000)\n    expected = \"11574 days 00:00:00\"\n    result = formatting.format_timedelta(delta)\n    assert result == expected\n\n    delta = timedelta(days=-1000000)\n    expected = \"-11574 days +00:00:00\"\n    result = formatting.format_timedelta(delta)\n    assert result == expected\n"], "sample_917": ["def test_xref_consistency_cpp_roles(app, status, warning):\n    app.builder.build_all()\n\n    test = 'xref_consistency.html'\n    output = (app.outdir / test).read_text()\n\n        pattern = (r'{role}-role:.*?'\n                   r'<(?P<tag>{tag}) .*?class=[\"\\'](?P<classes>.*?)[\"\\'].*?>'\n                   r'.*'\n                   r'</(?P=tag)>').format(role=role, tag=tag)\n        result = re.search(pattern, output)\n        expect = '''\\"], "sample_1159": ["def test_issue_17556_extended_real():\n    z = oo\n    assert z.is_extended_real is True\n    assert z.is_finite is False\n"], "sample_1173": ["def test_split_symbols_custom_predicate():\n        if symbol not in ('list', 'of', 'unsplittable', 'names'):\n                return _token_splittable(symbol)\n        return False\n\n    transformation = split_symbols_custom(can_split)\n    transformations = standard_transformations + (transformation, implicit_multiplication)\n\n    assert parse_expr(\"unsplittable\", transformations=transformations) == Symbol(\"unsplittable\")\n    assert parse_expr(\"splittable\", transformations=transformations) != Symbol(\"splittable\")\n"], "sample_1034": ["def test_grover_iteration_3():\n    numqubits = 3\n    basis_states = superposition_basis(numqubits)\n    v = OracleGate(numqubits, return_one_on_two)\n    # After (pi/4)sqrt(pow(2, n)), IntQubit(2) should have highest prob\n    # In this case, after around pi times (3 or 4)\n    iterated = grover_iteration(basis_states, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    iterated = qapply(iterated)\n    # In this case, probability was highest after 3 iterations\n    # Probability of Qubit('010') was 251/512 (3) vs 781/2048 (4)\n    expected = (-13*basis_states)/32 + 264*IntQubit(2, numqubits)/256\n    assert qapply(expected) == iterated\n"], "sample_437": ["def test_close_if_health_check_failed(self):\n    self.patch_settings_dict(conn_health_checks=True)\n    self.assertIsNone(connection.connection)\n    # Newly created connections are considered healthy without performing\n    # the health check.\n    with patch.object(connection, \"is_usable\", side_effect=AssertionError):\n        self.run_query()\n\n    old_connection = connection.connection\n    # Simulate connection health check failing.\n    with patch.object(\n        connection, \"is_usable\", return_value=False\n    ) as mocked_is_usable:\n        connection.close_if_health_check_failed()\n        new_connection = connection.connection\n        # A new connection is established.\n        self.assertIsNot(new_connection, old_connection)\n    self.assertEqual(mocked_is_usable.call_count, 1)\n"], "sample_1155": ["def test_construct_domain_with_complex_numbers():\n    assert construct_domain([1 + I, 2 - I]) == (CC, [CC(1, 1), CC(2, -1)])\n    assert construct_domain([1 + I, 2 - I], field=True) == (CC, [CC(1, 1), CC(2, -1)])\n    assert construct_domain([1 + I, 2 - I], extension=True) == (EX, [EX(1 + I), EX(2 - I)])\n"], "sample_1037": ["def test_matmul_simplify_with_constants():\n    A = MatrixSymbol('A', 2, 2)\n    B = ImmutableMatrix([[1, 2], [3, 4]])\n    C = ImmutableMatrix([[5, 6], [7, 8]])\n    assert simplify(MatMul(A, B, C)) == MatMul(A, ImmutableMatrix([[19, 22], [43, 50]]))\n"], "sample_1063": ["def test_issue_17000():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    f = lambdify(x, sin(x) + cos(x), modules='scipy')\n    assert abs(f(1.3) - (sin(1.3) + cos(1.3))) <= 1e-10\n"], "sample_586": ["def test_concat_positions(self):\n    ds1 = Dataset({\"foo\": (\"x\", [1, 2])}, {\"x\": [0, 1]})\n    ds2 = Dataset({\"foo\": (\"x\", [3, 4])}, {\"x\": [2, 3]})\n    expected = Dataset({\"foo\": (\"x\", [1, 2, 3, 4])}, {\"x\": [0, 1, 2, 3]})\n    actual = concat([ds1, ds2], dim=\"x\", positions=[[0, 1], [2, 3]])\n    assert_identical(actual, expected)\n"], "sample_780": ["def test_lda_transform_input_format():\n    # Test LDA transform for sparse and dense input\n    # transform result should be the same for both dense and sparse input\n    n_components, X = _build_sparse_mtx()\n    lda = LatentDirichletAllocation(n_components=n_components, max_iter=1,\n                                    learning_method='batch',\n                                    total_samples=100, random_state=0)\n    lda.fit(X)\n    transform_1 = lda.transform(X)\n    transform_2 = lda.transform(X.toarray())\n    assert_array_almost_equal(transform_1, transform_2)\n"], "sample_1075": ["def test_beta_real():\n    x, y = Symbol('x', real=True), Symbol('y', real=True)\n\n    assert beta(x, y).is_real is True\n    assert beta(x, y).conjugate() == beta(x, y)\n"], "sample_906": ["def test_domain_cpp_parse_noindexentry_enum(app):\n    text = (\".. cpp:enum:: A\\n\"\n            \"   :noindexentry:\\n\"\n            \"   .. cpp:enumerator:: a\\n\"\n            \"   .. cpp:enumerator:: b\\n\"\n            \"      :noindexentry:\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index, desc, addnodes.index, desc))\n    assert_node(doctree[0], addnodes.index, entries=[])\n    assert_node(doctree[2], addnodes.index, entries=[('single', 'b (C++ enumerator)', '_CPPv41b', '', None)])\n"], "sample_825": ["def test_pls_algorithm_selection():\n    # Test that the algorithm parameter is correctly handled\n    d = load_linnerud()\n    X = d.data\n    Y = d.target\n    pls_nipals = pls_.PLSCanonical(algorithm=\"nipals\")\n    pls_svd = pls_.PLSCanonical(algorithm=\"svd\")\n    pls_nipals.fit(X, Y)\n    pls_svd.fit(X, Y)\n    assert_array_almost_equal(pls_nipals.x_scores_, pls_svd.x_scores_, decimal=4)\n    assert_array_almost_equal(pls_nipals.y_scores_, pls_svd.y_scores_, decimal=4)\n    assert_raise_message(ValueError, \"Got algorithm B when only 'svd' and 'nipals' are known\",\n                         pls_.PLSCanonical, algorithm=\"B\")\n"], "sample_1004": ["def test_CondSet_union():\n    input_conditionset1 = ConditionSet(x, x > 0, Interval(1, 4, False, False))\n    input_conditionset2 = ConditionSet(x, x < 3, Interval(2, 5, False, False))\n    output_conditionset = ConditionSet(x, Or(x > 0, x < 3), Interval(1, 5, False, False))\n    assert Union(input_conditionset1, input_conditionset2) == output_conditionset\n"], "sample_958": ["def test_domain_cpp_parse_mix_decl_duplicate_with_noindexentry(app, warning):\n    # Issue 8270\n    text = (\".. cpp:struct:: A\\n\"\n            \".. cpp:function:: void A()\\n\"\n            \"   :noindexentry:\\n\"\n            \".. cpp:struct:: A\\n\")\n    restructuredtext.parse(app, text)\n    ws = warning.getvalue().split(\"\\n\")\n    assert len(ws) == 3\n    assert \"index.rst:3: WARNING: Duplicate C++ declaration, also defined at index:1.\" in ws[0]\n    assert \"Declaration is '.. cpp:struct:: A'.\" in ws[1]\n    assert ws[2] == \"\"\n"], "sample_303": ["def test_runshell_use_provided_env(self):\n    provided_env = {'TEST_ENV': 'test_value'}\n    with mock.patch('subprocess.run') as run:\n        with mock.patch.object(\n            BaseDatabaseClient,\n            'settings_to_cmd_args_env',\n            return_value=([], provided_env),\n        ):\n            self.client.runshell(None)\n        expected_env = {**os.environ, **provided_env}\n        run.assert_called_once_with([], env=expected_env, check=True)\n"], "sample_1126": ["def test_operator_dagger():\n    A = Operator('A')\n    B = Operator('B')\n    assert Dagger(A*B) == Dagger(B)*Dagger(A)\n    assert Dagger(A+B) == Dagger(A) + Dagger(B)\n    assert Dagger(A**2) == Dagger(A)**2\n"], "sample_1117": ["def test_matrix_element_sets_hadamard_product():\n    from sympy.matrices.expressions.hadamard import HadamardProduct\n    X = MatrixSymbol('X', 4, 4)\n    Y = MatrixSymbol('Y', 4, 4)\n    assert ask(Q.integer_elements(HadamardProduct(X, Y)),\n                        Q.integer_elements(X) & Q.integer_elements(Y))\n"], "sample_1035": ["def test_measure_partial():\n    from sympy.physics.quantum.qubit import Qubit, measure_partial\n    from sympy.physics.quantum.gate import H\n    from sympy.physics.quantum.qapply import qapply\n\n    c = H(0)*H(1)*Qubit('00')\n    q = qapply(c)\n    result = measure_partial(q, (0,))\n    expected = [(sqrt(2)*Qubit('00')/2 + sqrt(2)*Qubit('10')/2, 1/2), (sqrt(2)*Qubit('01')/2 + sqrt(2)*Qubit('11')/2, 1/2)]\n    assert result == expected\n"], "sample_1116": ["def test_inverse_derivative():\n    x = symbols('x')\n    A = MatrixSymbol('A', 3, 3, function=True)\n    assert Inverse(A(x))._eval_derivative_matrix_lines(x) == -A(x).T * Inverse(A(x)) * A(x).diff(x) * Inverse(A(x))\n"], "sample_779": ["def test_check_estimator_with_deprecated_fit():\n    # Tests that check_estimator works on a class with a deprecated fit method\n\n    class TestEstimatorWithDeprecatedFitMethod(BaseEstimator):\n        @deprecated(\"Deprecated for the purpose of testing check_estimator\")\n            return self\n\n    check_estimator(TestEstimatorWithDeprecatedFitMethod)\n"], "sample_454": ["def test_validate_custom_error_message(self):\n    constraint = models.CheckConstraint(\n        check=models.Q(price__gt=0),\n        name=\"positive_price\",\n        violation_error_message=\"Price must be greater than zero.\",\n    )\n    invalid_product = Product(price=-10, discounted_price=5)\n    msg = \"Price must be greater than zero.\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        constraint.validate(Product, invalid_product)\n"], "sample_1087": ["def test_f_polys():\n    from sympy.polys.specialpolys import f_polys\n    from sympy.polys.rings import ring\n\n    R, x, y, z = ring(\"x,y,z\", ZZ)\n    f0, f1, f2, f3, f4, f5, f6 = f_polys()\n\n    assert f0 == x**2*y*z**2 + 2*x**2*y*z + 3*x**2*y + 2*x**2 + 3*x + 4*y**2*z**2 + 5*y**2*z + 6*y**2 + y*z**2 + 2*y*z + y + 1\n    assert f1 == x**3*y*z + x**2*y**2*z**2 + x**2*y**2 + 20*x**2*y*z + 30*x**2*y + x**2*z**2 + 10*x**2*z + x*y**3*z + 30*x*y**2*z + 20*x*y**2 + x*y*z**3 + 10*x*y*z**2 + x*y*z + 610*x*y + 20*x*z**2 + 230*x*z + 300*x + y**2*z**2 + 10*y**2*z + 30*y*z**2 + 320*y*z + 200*y + 600*z + 6000\n    assert f2 == x**5*y**3 + x**5*y**2*z + x**5*y*z**2 + x**5*z**3 + x**3*y**2 + x**3*y*z + 90*x**3*y + 90*x**3*z + x**2*y**2*z - 11*x**2*y**2 + x**2*z**3 -"], "sample_243": ["def test_filter_with_transform(self):\n    query = Query(Author, alias_cols=False)\n    with register_lookup(CharField, Lower):\n        where = query.build_where(Q(name__lower='foo'))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, Exact)\n    self.assertIsInstance(lookup.lhs, Lower)\n    self.assertIsInstance(lookup.lhs.lhs, Col)\n    self.assertIsNone(lookup.lhs.lhs.alias)\n    self.assertEqual(lookup.lhs.lhs.target, Author._meta.get_field('name'))\n"], "sample_1025": ["def test_NumPyPrinter_relational():\n    p = NumPyPrinter()\n    assert p.doprint(x == y) == 'numpy.equal(x, y)'\n    assert p.doprint(x != y) == 'numpy.not_equal(x, y)'\n    assert p.doprint(x < y) == 'numpy.less(x, y)'\n    assert p.doprint(x <= y) == 'numpy.less_equal(x, y)'\n    assert p.doprint(x > y) == 'numpy.greater(x, y)'\n    assert p.doprint(x >= y) == 'numpy.greater_equal(x, y)'\n"], "sample_976": ["def test_symbol_assumptions():\n    x = Symbol('x', real=True, positive=True)\n    assert x.is_real\n    assert x.is_positive\n\n    y = Symbol('y', real=False, positive=False)\n    assert not y.is_real\n    assert not y.is_positive\n\n    z = Symbol('z', integer=True)\n    assert z.is_integer\n\n    w = Symbol('w', commutative=False)\n    assert not w.is_commutative\n\n    raises(ValueError, lambda: Symbol('a', commutative=None))\n"], "sample_907": ["def test_domain_cpp_parse_mix_decl_duplicate_with_different_signatures(app, warning):\n    # Issue 8270 with different signatures\n    text = (\".. cpp:struct:: A\\n\"\n            \".. cpp:function:: void A(int)\\n\"\n            \".. cpp:function:: void A(double)\\n\"\n            \".. cpp:struct:: A\\n\")\n    restructuredtext.parse(app, text)\n    ws = warning.getvalue().split(\"\\n\")\n    assert len(ws) == 5\n    assert \"index.rst:3: WARNING: Duplicate C++ declaration, also defined at index:1.\" in ws[0]\n    assert \"Declaration is '.. cpp:struct:: A'.\" in ws[1]\n    assert \"index.rst:4: WARNING: Duplicate C++ declaration, also defined at index:1.\" in ws[2]\n    assert \"Declaration is '.. cpp:struct:: A'.\" in ws[3]\n    assert ws[4] == \"\"\n"], "sample_873": ["def test_get_feature_names_out():\n    sel = StepSelector()\n    sel.fit(X, y)\n    assert_array_equal(feature_names_t, sel.get_feature_names_out(input_features=feature_names))\n"]}, "raw_scored_generations": {"sample_0": [false], "sample_3": [true], "sample_1": [false], "sample_2": [false], "sample_4": [false], "sample_5": [false], "sample_6": [true], "sample_7": [false], "sample_8": [false], "sample_9": [false], "sample_10": [true], "sample_11": [false], "sample_12": [true], "sample_13": [true], "sample_14": [false], "sample_15": [false], "sample_16": [false], "sample_17": [false], "sample_18": [false], "sample_19": [true], "sample_20": [false], "sample_21": [false], "sample_22": [false], "sample_23": [false], "sample_24": [false], "sample_25": [false], "sample_26": [false], "sample_27": [false], "sample_28": [false], "sample_29": [false], "sample_30": [true], "sample_31": [false], "sample_32": [false], "sample_33": [true], "sample_34": [false], "sample_35": [false], "sample_36": [false], "sample_37": [false], "sample_38": [true], "sample_39": [true], "sample_40": [true], "sample_41": [true], "sample_42": [true], "sample_43": [false], "sample_44": [false], "sample_45": [false], "sample_46": [true], "sample_47": [true], "sample_48": [true], "sample_49": [false], "sample_50": [true], "sample_51": [true], "sample_52": [true], "sample_54": [true], "sample_53": [true], "sample_55": [true], "sample_58": [true], "sample_56": [true], "sample_57": [true], "sample_59": [true], "sample_60": [false], "sample_61": [false], "sample_62": [true], "sample_63": [true], "sample_64": [true], "sample_65": [true], "sample_67": [true], "sample_66": [true], "sample_68": [true], "sample_69": [true], "sample_70": [false], "sample_71": [false], "sample_72": [true], "sample_73": [true], "sample_75": [true], "sample_74": [true], "sample_76": [true], "sample_77": [true], "sample_78": [true], "sample_79": [false], "sample_80": [true], "sample_82": [true], "sample_81": [true], "sample_83": [false], "sample_85": [false], "sample_84": [false], "sample_86": [true], "sample_88": [true], "sample_87": [false], "sample_89": [true], "sample_90": [true], "sample_91": [true], "sample_92": [false], "sample_93": [true], "sample_94": [true], "sample_95": [false], "sample_98": [false], "sample_96": [true], "sample_99": [false], "sample_97": [true], "sample_100": [true], "sample_102": [false], "sample_101": [true], "sample_103": [true], "sample_104": [true], "sample_107": [false], "sample_106": [true], "sample_105": [true], "sample_108": [true], "sample_109": [true], "sample_111": [true], "sample_110": [true], "sample_112": [true], "sample_113": [true], "sample_114": [true], "sample_115": [false], "sample_116": [true], "sample_117": [false], "sample_118": [true], "sample_119": [true], "sample_120": [false], "sample_121": [false], "sample_122": [true], "sample_123": [true], "sample_124": [true], "sample_125": [true], "sample_126": [true], "sample_127": [true], "sample_128": [false], "sample_129": [false], "sample_130": [true], "sample_131": [false], "sample_132": [false], "sample_133": [true], "sample_135": [true], "sample_134": [true], "sample_136": [true], "sample_139": [false], "sample_137": [true], "sample_138": [true], "sample_140": [false], "sample_141": [true], "sample_142": [true], "sample_143": [true], "sample_144": [true], "sample_145": [true], "sample_146": [true], "sample_147": [true], "sample_148": [true], "sample_151": [true], "sample_149": [false], "sample_152": [true], "sample_150": [true], "sample_153": [true], "sample_154": [true], "sample_155": [true], "sample_156": [true], "sample_157": [false], "sample_158": [true], "sample_159": [false], "sample_160": [false], "sample_161": [true], "sample_162": [true], "sample_163": [true], "sample_164": [false], "sample_165": [true], "sample_166": [true], "sample_167": [false], "sample_168": [true], "sample_169": [true], "sample_171": [true], "sample_170": [false], "sample_172": [true], "sample_173": [true], "sample_174": [true], "sample_175": [true], "sample_176": [true], "sample_177": [false], "sample_178": [true], "sample_180": [true], "sample_179": [true], "sample_182": [true], "sample_181": [true], "sample_183": [true], "sample_184": [true], "sample_185": [true], "sample_186": [true], "sample_187": [true], "sample_188": [true], "sample_189": [true], "sample_190": [true], "sample_191": [true], "sample_192": [true], "sample_193": [true], "sample_194": [true], "sample_195": [true], "sample_196": [true], "sample_198": [true], "sample_197": [true], "sample_199": [true], "sample_200": [true], "sample_201": [true], "sample_202": [true], "sample_203": [true], "sample_204": [true], "sample_205": [true], "sample_206": [true], "sample_207": [true], "sample_208": [true], "sample_209": [false], "sample_210": [true], "sample_211": [true], "sample_213": [false], "sample_212": [true], "sample_214": [true], "sample_215": [false], "sample_216": [true], "sample_217": [false], "sample_218": [true], "sample_219": [true], "sample_220": [true], "sample_221": [true], "sample_222": [true], "sample_223": [false], "sample_224": [true], "sample_225": [false], "sample_226": [false], "sample_227": [true], "sample_228": [false], "sample_229": [true], "sample_230": [false], "sample_231": [false], "sample_232": [true], "sample_233": [true], "sample_234": [true], "sample_235": [false], "sample_236": [true], "sample_237": [true], "sample_238": [true], "sample_239": [false], "sample_240": [true], "sample_241": [true], "sample_242": [true], "sample_243": [true], "sample_244": [false], "sample_245": [true], "sample_246": [true], "sample_247": [true], "sample_248": [true], "sample_249": [false], "sample_250": [true], "sample_251": [true], "sample_252": [true], "sample_253": [true], "sample_254": [true], "sample_256": [false], "sample_255": [true], "sample_257": [true], "sample_258": [false], "sample_259": [true], "sample_260": [true], "sample_261": [true], "sample_262": [true], "sample_263": [true], "sample_264": [true], "sample_265": [true], "sample_266": [true], "sample_267": [true], "sample_268": [true], "sample_269": [true], "sample_270": [true], "sample_271": [true], "sample_272": [false], "sample_273": [false], "sample_274": [true], "sample_275": [true], "sample_276": [true], "sample_277": [true], "sample_278": [true], "sample_279": [true], "sample_280": [true], "sample_281": [true], "sample_282": [true], "sample_283": [true], "sample_284": [true], "sample_285": [true], "sample_286": [true], "sample_287": [true], "sample_288": [true], "sample_289": [true], "sample_290": [true], "sample_291": [true], "sample_292": [true], "sample_293": [true], "sample_294": [true], "sample_295": [true], "sample_296": [true], "sample_297": [false], "sample_298": [true], "sample_299": [true], "sample_300": [true], "sample_301": [true], "sample_302": [true], "sample_303": [true], "sample_304": [true], "sample_305": [true], "sample_306": [true], "sample_307": [true], "sample_308": [true], "sample_309": [false], "sample_310": [true], "sample_312": [true], "sample_311": [true], "sample_313": [true], "sample_314": [true], "sample_315": [true], "sample_316": [true], "sample_317": [true], "sample_318": [false], "sample_319": [true], "sample_320": [true], "sample_321": [true], "sample_322": [false], "sample_323": [true], "sample_324": [true], "sample_325": [true], "sample_326": [true], "sample_327": [false], "sample_328": [true], "sample_329": [true], "sample_330": [false], "sample_331": [true], "sample_332": [false], "sample_333": [true], "sample_334": [true], "sample_335": [true], "sample_336": [false], "sample_337": [true], "sample_338": [true], "sample_339": [true], "sample_340": [true], "sample_341": [false], "sample_342": [false], "sample_343": [true], "sample_344": [true], "sample_345": [true], "sample_346": [false], "sample_347": [true], "sample_348": [false], "sample_349": [true], "sample_350": [true], "sample_351": [true], "sample_352": [true], "sample_353": [true], "sample_354": [true], "sample_355": [false], "sample_356": [true], "sample_357": [true], "sample_358": [false], "sample_359": [true], "sample_360": [true], "sample_361": [true], "sample_362": [false], "sample_363": [true], "sample_364": [false], "sample_365": [true], "sample_366": [false], "sample_367": [false], "sample_368": [false], "sample_369": [true], "sample_370": [true], "sample_371": [true], "sample_372": [false], "sample_373": [true], "sample_374": [true], "sample_375": [true], "sample_376": [true], "sample_377": [false], "sample_378": [true], "sample_379": [true], "sample_380": [true], "sample_381": [true], "sample_382": [true], "sample_383": [false], "sample_384": [true], "sample_385": [true], "sample_386": [false], "sample_387": [true], "sample_388": [false], "sample_389": [true], "sample_390": [true], "sample_391": [true], "sample_392": [true], "sample_393": [true], "sample_394": [true], "sample_395": [true], "sample_396": [true], "sample_397": [true], "sample_398": [false], "sample_399": [true], "sample_400": [true], "sample_401": [false], "sample_402": [true], "sample_403": [true], "sample_404": [true], "sample_405": [true], "sample_406": [true], "sample_407": [false], "sample_408": [true], "sample_409": [true], "sample_410": [false], "sample_411": [true], "sample_412": [true], "sample_413": [false], "sample_414": [false], "sample_415": [true], "sample_416": [true], "sample_417": [true], "sample_418": [true], "sample_419": [false], "sample_420": [true], "sample_421": [true], "sample_422": [true], "sample_423": [true], "sample_424": [true], "sample_425": [true], "sample_426": [false], "sample_427": [false], "sample_428": [false], "sample_429": [false], "sample_430": [true], "sample_431": [true], "sample_432": [true], "sample_433": [true], "sample_434": [false], "sample_435": [true], "sample_436": [true], "sample_437": [true], "sample_438": [true], "sample_439": [true], "sample_440": [true], "sample_441": [false], "sample_442": [false], "sample_443": [false], "sample_444": [true], "sample_445": [true], "sample_446": [true], "sample_447": [true], "sample_448": [true], "sample_449": [true], "sample_450": [true], "sample_451": [true], "sample_453": [true], "sample_452": [true], "sample_454": [true], "sample_455": [true], "sample_456": [false], "sample_457": [false], "sample_458": [true], "sample_459": [true], "sample_460": [true], "sample_461": [true], "sample_462": [true], "sample_463": [true], "sample_464": [false], "sample_465": [false], "sample_466": [false], "sample_467": [true], "sample_469": [true], "sample_468": [true], "sample_470": [true], "sample_471": [true], "sample_472": [false], "sample_473": [false], "sample_474": [true], "sample_475": [true], "sample_476": [true], "sample_477": [true], "sample_478": [true], "sample_479": [true], "sample_480": [true], "sample_481": [true], "sample_482": [true], "sample_483": [true], "sample_484": [true], "sample_485": [true], "sample_486": [true], "sample_487": [true], "sample_488": [true], "sample_489": [true], "sample_490": [true], "sample_491": [true], "sample_492": [false], "sample_493": [true], "sample_494": [true], "sample_495": [true], "sample_496": [true], "sample_497": [true], "sample_498": [true], "sample_499": [true], "sample_500": [true], "sample_501": [true], "sample_502": [false], "sample_503": [true], "sample_504": [true], "sample_505": [false], "sample_506": [false], "sample_507": [true], "sample_508": [true], "sample_509": [false], "sample_510": [false], "sample_511": [false], "sample_512": [false], "sample_513": [true], "sample_514": [false], "sample_515": [false], "sample_516": [false], "sample_517": [true], "sample_518": [true], "sample_519": [true], "sample_520": [false], "sample_521": [false], "sample_522": [true], "sample_523": [true], "sample_524": [true], "sample_525": [false], "sample_526": [false], "sample_527": [false], "sample_528": [true], "sample_529": [true], "sample_530": [false], "sample_531": [false], "sample_532": [true], "sample_533": [true], "sample_534": [false], "sample_535": [false], "sample_536": [false], "sample_537": [false], "sample_538": [true], "sample_539": [false], "sample_540": [false], "sample_541": [false], "sample_542": [true], "sample_543": [true], "sample_544": [true], "sample_545": [false], "sample_546": [false], "sample_547": [false], "sample_548": [true], "sample_549": [true], "sample_550": [false], "sample_551": [false], "sample_552": [true], "sample_553": [false], "sample_554": [true], "sample_555": [true], "sample_556": [false], "sample_557": [true], "sample_558": [false], "sample_559": [false], "sample_560": [false], "sample_561": [true], "sample_562": [false], "sample_563": [false], "sample_564": [false], "sample_565": [true], "sample_566": [false], "sample_567": [false], "sample_568": [false], "sample_569": [false], "sample_570": [false], "sample_571": [false], "sample_572": [false], "sample_573": [false], "sample_574": [false], "sample_575": [false], "sample_576": [false], "sample_577": [false], "sample_578": [false], "sample_579": [false], "sample_580": [true], "sample_581": [false], "sample_582": [true], "sample_583": [true], "sample_584": [false], "sample_585": [true], "sample_586": [false], "sample_587": [false], "sample_588": [false], "sample_589": [false], "sample_590": [false], "sample_591": [false], "sample_592": [false], "sample_593": [false], "sample_594": [false], "sample_595": [false], "sample_596": [true], "sample_597": [false], "sample_598": [false], "sample_599": [true], "sample_600": [false], "sample_601": [false], "sample_602": [false], "sample_603": [false], "sample_604": [false], "sample_605": [false], "sample_606": [false], "sample_607": [false], "sample_608": [false], "sample_609": [false], "sample_610": [false], "sample_611": [false], "sample_612": [false], "sample_613": [false], "sample_614": [false], "sample_615": [false], "sample_616": [false], "sample_617": [false], "sample_618": [false], "sample_619": [false], "sample_620": [false], "sample_621": [false], "sample_622": [false], "sample_623": [false], "sample_624": [false], "sample_625": [false], "sample_626": [false], "sample_627": [false], "sample_628": [false], "sample_629": [false], "sample_630": [false], "sample_631": [false], "sample_632": [false], "sample_633": [false], "sample_634": [false], "sample_635": [false], "sample_636": [false], "sample_637": [false], "sample_638": [true], "sample_639": [false], "sample_640": [false], "sample_641": [false], "sample_642": [true], "sample_643": [true], "sample_644": [false], "sample_645": [false], "sample_646": [false], "sample_647": [true], "sample_648": [false], "sample_649": [false], "sample_650": [false], "sample_651": [false], "sample_652": [false], "sample_653": [false], "sample_654": [false], "sample_655": [false], "sample_656": [false], "sample_657": [false], "sample_658": [false], "sample_659": [false], "sample_660": [false], "sample_661": [false], "sample_662": [false], "sample_663": [false], "sample_664": [false], "sample_665": [false], "sample_666": [false], "sample_667": [false], "sample_668": [false], "sample_669": [true], "sample_670": [false], "sample_671": [false], "sample_672": [false], "sample_673": [false], "sample_674": [false], "sample_675": [false], "sample_676": [false], "sample_677": [false], "sample_678": [true], "sample_679": [false], "sample_680": [false], "sample_681": [true], "sample_682": [false], "sample_683": [true], "sample_684": [false], "sample_685": [false], "sample_686": [false], "sample_687": [false], "sample_688": [false], "sample_689": [false], "sample_690": [false], "sample_691": [false], "sample_692": [false], "sample_693": [false], "sample_694": [false], "sample_695": [false], "sample_696": [false], "sample_697": [false], "sample_698": [false], "sample_699": [false], "sample_700": [false], "sample_701": [false], "sample_702": [false], "sample_703": [false], "sample_704": [false], "sample_705": [false], "sample_706": [false], "sample_707": [false], "sample_708": [false], "sample_709": [false], "sample_710": [false], "sample_711": [false], "sample_712": [true], "sample_713": [false], "sample_714": [true], "sample_715": [true], "sample_716": [false], "sample_717": [true], "sample_718": [false], "sample_719": [false], "sample_720": [false], "sample_721": [true], "sample_722": [false], "sample_723": [true], "sample_724": [true], "sample_725": [false], "sample_726": [false], "sample_727": [true], "sample_728": [false], "sample_729": [true], "sample_730": [true], "sample_731": [false], "sample_732": [true], "sample_733": [false], "sample_734": [true], "sample_735": [true], "sample_736": [false], "sample_737": [false], "sample_738": [false], "sample_739": [true], "sample_740": [false], "sample_741": [false], "sample_742": [false], "sample_743": [false], "sample_744": [false], "sample_745": [true], "sample_746": [true], "sample_747": [false], "sample_748": [false], "sample_749": [false], "sample_750": [true], "sample_751": [true], "sample_752": [false], "sample_753": [false], "sample_754": [false], "sample_755": [true], "sample_756": [false], "sample_757": [false], "sample_758": [false], "sample_759": [true], "sample_760": [false], "sample_761": [true], "sample_762": [true], "sample_763": [false], "sample_764": [false], "sample_765": [false], "sample_766": [true], "sample_767": [false], "sample_768": [true], "sample_769": [true], "sample_770": [true], "sample_771": [false], "sample_772": [true], "sample_773": [false], "sample_774": [false], "sample_775": [false], "sample_776": [false], "sample_777": [true], "sample_778": [true], "sample_779": [false], "sample_780": [true], "sample_781": [false], "sample_782": [false], "sample_783": [false], "sample_784": [false], "sample_785": [false], "sample_786": [false], "sample_787": [true], "sample_788": [false], "sample_789": [true], "sample_790": [false], "sample_791": [false], "sample_792": [true], "sample_793": [true], "sample_794": [false], "sample_795": [false], "sample_796": [true], "sample_797": [false], "sample_798": [true], "sample_799": [false], "sample_800": [false], "sample_801": [false], "sample_802": [true], "sample_803": [false], "sample_804": [false], "sample_805": [false], "sample_806": [false], "sample_807": [false], "sample_808": [true], "sample_809": [true], "sample_810": [false], "sample_811": [true], "sample_812": [false], "sample_813": [true], "sample_814": [false], "sample_815": [false], "sample_816": [false], "sample_817": [false], "sample_818": [false], "sample_819": [false], "sample_820": [false], "sample_821": [true], "sample_822": [true], "sample_823": [false], "sample_824": [true], "sample_825": [false], "sample_826": [false], "sample_827": [true], "sample_828": [false], "sample_829": [true], "sample_830": [false], "sample_831": [true], "sample_832": [false], "sample_833": [true], "sample_834": [false], "sample_835": [true], "sample_836": [false], "sample_837": [false], "sample_838": [false], "sample_839": [false], "sample_840": [true], "sample_841": [false], "sample_842": [true], "sample_843": [false], "sample_844": [false], "sample_845": [false], "sample_846": [false], "sample_847": [true], "sample_848": [true], "sample_849": [false], "sample_850": [false], "sample_851": [false], "sample_852": [false], "sample_853": [true], "sample_854": [false], "sample_855": [true], "sample_856": [false], "sample_857": [false], "sample_858": [true], "sample_859": [false], "sample_860": [true], "sample_861": [false], "sample_862": [false], "sample_863": [true], "sample_864": [false], "sample_865": [true], "sample_866": [true], "sample_867": [true], "sample_868": [false], "sample_869": [false], "sample_870": [true], "sample_871": [true], "sample_872": [false], "sample_873": [true], "sample_874": [false], "sample_875": [false], "sample_876": [true], "sample_877": [true], "sample_878": [false], "sample_879": [true], "sample_880": [true], "sample_881": [false], "sample_882": [false], "sample_883": [false], "sample_884": [false], "sample_885": [true], "sample_886": [false], "sample_887": [false], "sample_888": [false], "sample_889": [false], "sample_890": [false], "sample_891": [false], "sample_892": [false], "sample_893": [false], "sample_894": [false], "sample_895": [false], "sample_896": [false], "sample_897": [false], "sample_898": [false], "sample_899": [false], "sample_900": [false], "sample_901": [true], "sample_902": [true], "sample_903": [false], "sample_904": [false], "sample_905": [false], "sample_906": [false], "sample_907": [false], "sample_908": [false], "sample_909": [false], "sample_910": [false], "sample_911": [false], "sample_912": [true], "sample_913": [true], "sample_914": [false], "sample_915": [false], "sample_916": [false], "sample_917": [false], "sample_918": [true], "sample_919": [false], "sample_920": [false], "sample_921": [false], "sample_922": [false], "sample_923": [false], "sample_924": [false], "sample_925": [false], "sample_926": [false], "sample_927": [false], "sample_928": [false], "sample_929": [true], "sample_930": [false], "sample_931": [true], "sample_932": [false], "sample_933": [false], "sample_934": [false], "sample_935": [false], "sample_936": [false], "sample_937": [false], "sample_938": [false], "sample_939": [false], "sample_940": [false], "sample_941": [true], "sample_942": [true], "sample_943": [false], "sample_944": [true], "sample_945": [true], "sample_946": [true], "sample_947": [false], "sample_948": [false], "sample_949": [false], "sample_950": [true], "sample_951": [false], "sample_952": [false], "sample_953": [false], "sample_954": [false], "sample_955": [false], "sample_956": [false], "sample_957": [true], "sample_958": [false], "sample_959": [false], "sample_960": [true], "sample_961": [true], "sample_962": [false], "sample_963": [false], "sample_964": [true], "sample_965": [false], "sample_966": [true], "sample_967": [false], "sample_968": [false], "sample_969": [true], "sample_970": [false], "sample_971": [false], "sample_972": [true], "sample_973": [false], "sample_974": [false], "sample_975": [false], "sample_976": [true], "sample_977": [false], "sample_978": [false], "sample_979": [true], "sample_980": [false], "sample_981": [false], "sample_982": [true], "sample_983": [true], "sample_984": [false], "sample_985": [true], "sample_986": [true], "sample_987": [true], "sample_988": [false], "sample_989": [false], "sample_990": [false], "sample_991": [false], "sample_992": [false], "sample_993": [true], "sample_994": [true], "sample_995": [false], "sample_996": [false], "sample_997": [false], "sample_998": [false], "sample_999": [false], "sample_1000": [true], "sample_1001": [true], "sample_1002": [true], "sample_1003": [true], "sample_1004": [false], "sample_1005": [false], "sample_1006": [false], "sample_1007": [false], "sample_1008": [true], "sample_1009": [true], "sample_1010": [false], "sample_1011": [false], "sample_1012": [false], "sample_1013": [false], "sample_1014": [false], "sample_1015": [false], "sample_1016": [false], "sample_1017": [true], "sample_1018": [false], "sample_1019": [true], "sample_1020": [false], "sample_1021": [false], "sample_1022": [false], "sample_1023": [true], "sample_1024": [true], "sample_1025": [false], "sample_1026": [false], "sample_1027": [true], "sample_1028": [true], "sample_1029": [false], "sample_1030": [false], "sample_1031": [true], "sample_1032": [false], "sample_1033": [true], "sample_1034": [false], "sample_1035": [true], "sample_1036": [true], "sample_1037": [false], "sample_1038": [true], "sample_1039": [false], "sample_1040": [false], "sample_1041": [false], "sample_1042": [false], "sample_1043": [false], "sample_1044": [false], "sample_1045": [true], "sample_1046": [false], "sample_1047": [false], "sample_1048": [false], "sample_1049": [false], "sample_1050": [true], "sample_1051": [false], "sample_1052": [false], "sample_1053": [true], "sample_1054": [true], "sample_1055": [true], "sample_1056": [false], "sample_1057": [false], "sample_1058": [true], "sample_1059": [false], "sample_1060": [true], "sample_1061": [false], "sample_1062": [false], "sample_1063": [true], "sample_1064": [true], "sample_1065": [false], "sample_1066": [false], "sample_1067": [true], "sample_1068": [false], "sample_1069": [true], "sample_1070": [false], "sample_1071": [true], "sample_1072": [true], "sample_1073": [false], "sample_1074": [false], "sample_1075": [true], "sample_1076": [false], "sample_1077": [false], "sample_1078": [true], "sample_1079": [true], "sample_1080": [false], "sample_1081": [true], "sample_1082": [false], "sample_1083": [false], "sample_1084": [true], "sample_1085": [true], "sample_1086": [false], "sample_1087": [false], "sample_1088": [false], "sample_1089": [true], "sample_1090": [false], "sample_1091": [false], "sample_1092": [true], "sample_1093": [false], "sample_1094": [false], "sample_1095": [true], "sample_1096": [false], "sample_1097": [false], "sample_1098": [false], "sample_1099": [false], "sample_1100": [true], "sample_1101": [false], "sample_1102": [true], "sample_1103": [true], "sample_1104": [true], "sample_1105": [true], "sample_1106": [false], "sample_1107": [false], "sample_1108": [false], "sample_1109": [false], "sample_1110": [false], "sample_1111": [false], "sample_1112": [false], "sample_1113": [false], "sample_1114": [false], "sample_1115": [false], "sample_1116": [false], "sample_1117": [true], "sample_1118": [false], "sample_1119": [true], "sample_1120": [false], "sample_1121": [true], "sample_1122": [false], "sample_1123": [false], "sample_1124": [false], "sample_1125": [true], "sample_1126": [true], "sample_1127": [false], "sample_1128": [false], "sample_1129": [false], "sample_1130": [false], "sample_1131": [false], "sample_1132": [false], "sample_1133": [false], "sample_1134": [true], "sample_1135": [true], "sample_1136": [false], "sample_1137": [true], "sample_1138": [false], "sample_1139": [false], "sample_1140": [false], "sample_1141": [false], "sample_1142": [false], "sample_1143": [true], "sample_1144": [false], "sample_1145": [true], "sample_1146": [true], "sample_1147": [true], "sample_1148": [false], "sample_1149": [false], "sample_1150": [false], "sample_1151": [false], "sample_1152": [true], "sample_1153": [false], "sample_1154": [false], "sample_1155": [false], "sample_1156": [true], "sample_1157": [false], "sample_1158": [true], "sample_1159": [true], "sample_1160": [false], "sample_1161": [true], "sample_1162": [false], "sample_1163": [false], "sample_1164": [false], "sample_1165": [false], "sample_1166": [false], "sample_1167": [true], "sample_1168": [false], "sample_1169": [true], "sample_1170": [false], "sample_1171": [false], "sample_1172": [false], "sample_1173": [false], "sample_1174": [false], "sample_1175": [false], "sample_1176": [true], "sample_1177": [false], "sample_1178": [true], "sample_1179": [false], "sample_1180": [false], "sample_1181": [false], "sample_1182": [false], "sample_1183": [true], "sample_1184": [true], "sample_1185": [false], "sample_1186": [false], "sample_1187": [true], "sample_1188": [true], "sample_1189": [false], "sample_1190": [false], "sample_1191": [true], "sample_1192": [true], "sample_1193": [false], "sample_1194": [true], "sample_1195": [false], "sample_1196": [false], "sample_1197": [false], "sample_1198": [true], "sample_1199": [false], "sample_1200": [false], "sample_1201": [false], "sample_1202": [false], "sample_1203": [false], "sample_1204": [true], "sample_1205": [true], "sample_1206": [false], "sample_1207": [false], "sample_1208": [true], "sample_1209": [false]}}