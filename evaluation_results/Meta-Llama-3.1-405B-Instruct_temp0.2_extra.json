{"raw_generations": {"sample_0": ["def test_conversion_to_from_variance_with_correlated_uncertainty(UncertClass):\n    uncert = np.arange(1, 11).reshape(2, 5) * u.adu\n    start_uncert = UncertClass(uncert)\n    var_uncert = start_uncert.represent_as(VarianceUncertainty)\n    final_uncert = var_uncert.represent_as(UncertClass)\n    assert_array_equal(start_uncert.array, final_uncert.array)\n    assert start_uncert.unit == final_uncert.unit\n\n    # Test with correlated uncertainty\n    correlated_uncert = UncertClass(uncert, unit=u.adu)\n    correlated_var_uncert = correlated_uncert.represent_as(VarianceUncertainty)\n    correlated_final_uncert = correlated_var_uncert.represent_as(UncertClass)\n    assert_array_equal(correlated_uncert.array, correlated_final_uncert.array)\n    assert correlated_uncert.unit == correlated_final_uncert.unit\n"], "sample_3": ["def test_ecsv_header_with_comments():\n    \"\"\"Test that ECSV header with comments is correctly parsed\"\"\"\n    txt = \"\"\"\n    # %ECSV 1.0\n    # ---\n    # datatype:\n    # - {name: col, datatype: string}  # This is a comment\n    # schema: astropy-2.0\n    col\n    1\n    2\n    \"\"\"\n    t = ascii.read(txt, format='ecsv')\n    assert t['col'].dtype.kind == 'U'\n"], "sample_1": ["def test_separable_single_input_multi_output():\n    model = models.Shift(1) & models.Shift(2)\n    assert_allclose(is_separable(model), np.array([False, False]))\n    assert_allclose(separability_matrix(model), np.array([[True, True], [True, True]]))\n"], "sample_6": ["def test_angle_to_string():\n    \"\"\"\n    Test the to_string method of Angle objects.\n    \"\"\"\n    a = Angle(1.2345, unit=u.deg)\n    assert a.to_string() == \"1.2345\u00b0\"\n    assert a.to_string(decimal=True) == \"1.2345\"\n    assert a.to_string(sep=\":\", precision=2) == \"1:14:04.20\"\n    assert a.to_string(format=\"latex\") == r\"$1.2345^\\circ$\"\n    assert a.to_string(format=\"unicode\") == \"1.2345\u00b0\"\n\n    a = Angle(12.3456, unit=u.hour)\n    assert a.to_string() == \"12h 20m 44.16s\"\n    assert a.to_string(decimal=True) == \"12.3456\"\n    assert a.to_string(sep=\":\", precision=2) == \"12:20:44.16\"\n    assert a.to_string(format=\"latex\") == r\"$12^\\mathrm{h}20^\\mathrm{m}44.16^\\mathrm{s}$\"\n    assert a.to_string(format=\"unicode\") == \"12\u02b020\u1d5044\u02e2.16\"\n"], "sample_9": ["def test_read_html_css_class():\n    \"\"\"\n    Test reading an HTML table with a CSS class\n    \"\"\"\n    table_in = ['<table class=\"my_table\">',\n                '<tr><th>A</th></tr>',\n                '<tr><td>1</td></tr>',\n                '</table>']\n    dat = Table.read(table_in, format='ascii.html')\n    assert dat.colnames == ['A']\n    assert len(dat) == 1\n"], "sample_12": ["def test_angle_to_string_precision():\n    \"\"\"\n    Test that the precision argument in Angle.to_string works as expected.\n    \"\"\"\n    a = Angle(1.23456789, unit=u.deg)\n    assert a.to_string(precision=0) == '1d14m04s'\n    assert a.to_string(precision=1) == '1d14m04.6s'\n    assert a.to_string(precision=2) == '1d14m04.57s'\n    assert a.to_string(precision=3) == '1d14m04.568s'\n    assert a.to_string(precision=4) == '1d14m04.5679s'\n    assert a.to_string(precision=5) == '1d14m04.56789s'\n"], "sample_13": ["def test_angle_to_string_precision():\n    \"\"\"\n    Test that the precision argument in Angle.to_string works correctly.\n    \"\"\"\n    a = Angle('1d2m3.456789s')\n    assert a.to_string(precision=0) == '1d02m03s'\n    assert a.to_string(precision=1) == '1d02m03.5s'\n    assert a.to_string(precision=2) == '1d02m03.46s'\n    assert a.to_string(precision=3) == '1d02m03.457s'\n    assert a.to_string(precision=4) == '1d02m03.4568s'\n    assert a.to_string(precision=5) == '1d02m03.45679s'\n    assert a.to_string(precision=6) == '1d02m03.456789s'\n    assert a.to_string(precision=7) == '1d02m03.4567890s'\n"], "sample_14": ["def test_angle_to_string_precision():\n    \"\"\"\n    Test that the precision argument in to_string works correctly.\n    \"\"\"\n    angle = Angle(1.23456789, unit=u.deg)\n    assert angle.to_string(precision=0) == '1d14m04s'\n    assert angle.to_string(precision=1) == '1d14m04.6s'\n    assert angle.to_string(precision=2) == '1d14m04.57s'\n    assert angle.to_string(precision=3) == '1d14m04.568s'\n    assert angle.to_string(precision=4) == '1d14m04.5679s'\n    assert angle.to_string(precision=5) == '1d14m04.56789s'\n"], "sample_20": ["def test_read_table_fits_with_invalid_unit(tmp_path):\n    filename = tmp_path / \"test_invalid_unit.fits\"\n    data = np.array(\n        list(zip([1, 2, 3, 4], [\"a\", \"b\", \"c\", \"d\"], [2.3, 4.5, 6.7, 8.9])),\n        dtype=[(\"a\", int), (\"b\", \"U1\"), (\"c\", float)],\n    )\n    hdu = BinTableHDU(data)\n    hdu.columns[0].unit = \" invalid unit \"\n    hdu.writeto(filename)\n\n    with pytest.warns(u.UnitsWarning, match=\"did not parse as fits unit\"):\n        t = Table.read(filename)\n\n    assert t[\"a\"].unit == u.UnrecognizedUnit(\" invalid unit \")\n"], "sample_21": ["def test_line_type():\n    assert _line_type(\"READ SERR 3\") == \"command\"\n    assert _line_type(\" \\\\n    !some gibberish\") == \"comment\"\n    assert _line_type(\"   \") == \"comment\"\n    assert _line_type(\" 21345.45\") == \"data,1\"\n    assert _line_type(\" 21345.45 1.53e-3 1e-3 .04 NO nan\") == \"data,6\"\n    assert _line_type(\" 21345.45,1.53e-3,1e-3,.04,NO,nan\", delimiter=',') == \"data,6\"\n    assert _line_type(\" 21345.45 ! a comment to disturb\") == \"data,1\"\n    assert _line_type(\"NO NO NO NO NO\") == \"new\"\n    assert _line_type(\"NO,NO,NO,NO,NO\", delimiter=',') == \"new\"\n\n    with pytest.raises(ValueError):\n        _line_type(\"N O N NOON OON O\")\n\n    with pytest.raises(ValueError):\n        _line_type(\" some non-comment gibberish\")\n"], "sample_22": ["def test_matrix_transpose():\n    \"\"\"Test the matrix transpose function.\"\"\"\n    # Create a 3x3 matrix\n    m1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    \n    # Transpose the matrix using the function\n    m1_transposed = matrix_transpose(m1)\n    \n    # Check if the transposed matrix is correct\n    assert_array_equal(m1_transposed, np.transpose(m1))\n    \n    # Create a stack of 2 3x3 matrices\n    n1 = np.stack((m1, m1))\n    \n    # Transpose the stack of matrices using the function\n    n1_transposed = matrix_transpose(n1)\n    \n    # Check if the transposed stack of matrices is correct\n    assert_array_equal(n1_transposed, np.transpose(n1, (0, 2, 1)))\n"], "sample_23": ["def test_angle_to_string_precision():\n    \"\"\"\n    Test that the precision argument in to_string works as expected.\n    \"\"\"\n    angle = Angle(1.23456789, unit=u.deg)\n    assert angle.to_string(precision=0) == \"1d14m04s\"\n    assert angle.to_string(precision=1) == \"1d14m04.6s\"\n    assert angle.to_string(precision=2) == \"1d14m04.57s\"\n    assert angle.to_string(precision=3) == \"1d14m04.568s\"\n    assert angle.to_string(precision=4) == \"1d14m04.5679s\"\n    assert angle.to_string(precision=5) == \"1d14m04.56789s\"\n"], "sample_25": ["def test_header_fromstring_bytes_with_trailing_newline(self):\n    \"\"\"\n    Test reading a Header from a `bytes` string with a trailing newline.\n\n    See https://github.com/astropy/astropy/issues/8706\n    \"\"\"\n\n    with open(self.data(\"test0.fits\"), \"rb\") as fobj:\n        pri_hdr_from_bytes = fits.Header.fromstring(fobj.read() + b\"\\n\")\n\n    pri_hdr = fits.getheader(self.data(\"test0.fits\"))\n    assert pri_hdr[\"NAXIS\"] == pri_hdr_from_bytes[\"NAXIS\"]\n    assert pri_hdr == pri_hdr_from_bytes\n    assert pri_hdr.tostring() == pri_hdr_from_bytes.tostring()\n"], "sample_26": ["def test_uint_scale_back(tmp_path):\n    # Regression test for https://github.com/astropy/astropy/issues/2305\n\n    filename = tmp_path / \"uint_scale_back.fits\"\n\n    # Create an unsigned int array with values that wouldn't fit in a signed\n    # int array of the same bit width\n    arr = np.array([65530, 65531], dtype=np.uint16)\n\n    hdu = fits.PrimaryHDU(data=arr)\n    hdu.writeto(filename)\n\n    with fits.open(filename, mode=\"update\", scale_back=True) as hdul:\n        hdul[0].data[:] = 0\n\n    with fits.open(filename, do_not_scale_image_data=True) as hdul:\n        assert hdul[0].header[\"BITPIX\"] == 16\n        assert hdul[0].header[\"BZERO\"] == 32768\n        assert hdul[0].header[\"BSCALE\"] == 1\n        assert (hdul[0].data == 32768).all()\n"], "sample_27": ["def test_fitsdiff_ignore_keywords(tmp_path):\n    \"\"\"Test that FITSDiff ignores specified keywords\"\"\"\n    path1 = tmp_path / \"test1.fits\"\n    path2 = tmp_path / \"test2.fits\"\n\n    hdulist = HDUList([PrimaryHDU(), ImageHDU(data=np.zeros(5), name=\"SCI\")])\n    hdulist.writeto(path1)\n    hdulist[1].header[\"TEST\"] = 1\n    hdulist.writeto(path2)\n\n    diff = FITSDiff(path1, path2, ignore_keywords=[\"TEST\"])\n    assert diff.identical\n"], "sample_28": ["def test_header_fromstring_bytes_with_trailing_newline(self):\n    \"\"\"\n    Test reading a Header from a `bytes` string with a trailing newline.\n\n    See https://github.com/astropy/astropy/issues/8706\n    \"\"\"\n\n    with open(self.data(\"test0.fits\"), \"rb\") as fobj:\n        pri_hdr_from_bytes = fits.Header.fromstring(fobj.read() + b\"\\n\")\n\n    pri_hdr = fits.getheader(self.data(\"test0.fits\"))\n    assert pri_hdr[\"NAXIS\"] == pri_hdr_from_bytes[\"NAXIS\"]\n    assert pri_hdr == pri_hdr_from_bytes\n    assert pri_hdr.tostring() == pri_hdr_from_bytes.tostring()\n"], "sample_29": ["def test_write_latex_format_mismatch(self, write, tmp_path):\n    \"\"\"Test passing a format that doesn't match 'latex'\"\"\"\n    fp = tmp_path / \"test_write_latex_format_mismatch.tex\"\n    with pytest.raises(ValueError, match=\"format must be 'latex'\"):\n        write(fp, format=\"ascii\")\n"], "sample_30": ["def test_get_table_by_id():\n    votable = parse(get_pkg_data_filename(\"data/regression.xml\"))\n    table = votable.get_table_by_id(\"table.1\")\n    assert isinstance(table, tree.Table)\n    assert len(table.array) == 5\n\n    with pytest.raises(KeyError):\n        votable.get_table_by_id(\"nonexistent_table\")\n"], "sample_31": ["def test_write_latex_with_kwargs(self, write, tmp_path, format):\n    \"\"\"Test passing kwargs to the underlying table writer\"\"\"\n    fp = tmp_path / \"test_write_latex_with_kwargs.tex\"\n    write(fp, format=format, latex_names=True, caption=\"Cosmology Parameters\")\n    # Check that the caption is included in the LaTeX file\n    with open(fp, \"r\") as f:\n        contents = f.read()\n        assert r\"\\caption{Cosmology Parameters}\" in contents\n"], "sample_32": ["def test_w0wzcdm_inv_efuncs():\n    \"\"\"Test inverse efunc scalars for w0wzCDM.\"\"\"\n    cosmo = w0wzCDM(H0=70, Om0=0.3, Ode0=0.50, w0=-1, wz=0.5)\n\n    # Test that the inverse efunc scalars are set correctly\n    assert (\n        cosmo._inv_efunc_scalar\n        == scalar_inv_efuncs.w0wzcdm_inv_efunc_norel\n        or cosmo._inv_efunc_scalar\n        == scalar_inv_efuncs.w0wzcdm_inv_efunc_nomnu\n        or cosmo._inv_efunc_scalar == scalar_inv_efuncs.w0wzcdm_inv_efunc\n    )\n\n    # Test that the arguments passed to the inverse efunc scalars are correct\n    if cosmo._Tcmb0.value == 0:\n        assert cosmo._inv_efunc_scalar_args == (\n            cosmo._Om0,\n            cosmo._Ode0,\n            cosmo._Ok0,\n            cosmo._w0,\n            cosmo._wz,\n        )\n    elif not cosmo._massivenu:\n        assert cosmo._inv_efunc_scalar_args == (\n            cosmo._Om0,\n            cosmo._Ode0,\n            cosmo._Ok0,\n            cosmo._Ogamma0 + cosmo._Onu0,\n            cosmo._w0,\n            cosmo._wz,\n        )\n    else:\n        assert cosmo._inv_efunc_scalar_args == (\n            cosmo._Om0,\n            cosmo._Ode0,\n            cosmo._Ok0,\n            cosmo._Ogamma0,\n            cosmo._neff_per_nu,\n            cosmo._nmasslessnu,\n            cosmo._nu_y_list,\n            cosmo._w0,\n            cosmo._wz,\n        )\n"], "sample_33": ["def test_indent():\n    text = \"This is a\\nmultiline string.\\nIt has three lines.\"\n    expected = \"    This is a\\n    multiline string.\\n    It has three lines.\\n\"\n    assert misc.indent(text, width=4) == expected\n    assert misc.indent(text, width=4, shift=2) == \"        This is a\\n        multiline string.\\n        It has three lines.\\n\"\n"], "sample_34": ["def test_unit_to_string():\n    # Test that to_string() returns the correct string representation of a unit\n    assert u.m.to_string() == 'm'\n    assert (u.m / u.s).to_string() == 'm / s'\n    assert (u.m ** 2).to_string() == 'm2'\n\n    # Test that to_string() works with different formats\n    assert u.m.to_string(format='latex') == 'm'\n    assert (u.m / u.s).to_string(format='latex') == r'\\frac{m}{s}'\n    assert (u.m ** 2).to_string(format='latex') == r'm^{2}'\n\n    # Test that to_string() raises an error for unknown formats\n    with pytest.raises(ValueError):\n        u.m.to_string(format='unknown')\n"], "sample_35": ["def test_isinstancemethod():\n    class MyClass:\n\n        @classmethod\n\n        @staticmethod\n\n    assert isinstancemethod(MyClass, MyClass.an_instancemethod)\n    assert not isinstancemethod(MyClass, MyClass.a_classmethod)\n    assert not isinstancemethod(MyClass, MyClass.a_staticmethod)\n\n    # Test with inheritance\n    class MySubclass(MyClass):\n        pass\n\n    assert isinstancemethod(MySubclass, MySubclass.an_instancemethod)\n    assert not isinstancemethod(MySubclass, MySubclass.a_classmethod)\n    assert not isinstancemethod(MySubclass, MySubclass.a_staticmethod)\n"], "sample_36": ["def test_biweight_location_M_axis():\n    \"\"\"Test that biweight_location handles M with axis keyword.\"\"\"\n    with NumpyRNGContext(12345):\n        ny = 100\n        nx = 200\n        data = normal(5, 2, (ny, nx))\n        M = np.median(data, axis=0)\n\n        bw = biweight_location(data, M=M, axis=0)\n        bwi = []\n        for i in range(nx):\n            bwi.append(biweight_location(data[:, i], M=M[i]))\n        bwi = np.array(bwi)\n        assert_allclose(bw, bwi)\n\n        M = np.median(data, axis=1)\n        bw = biweight_location(data, M=M, axis=1)\n        bwi = []\n        for i in range(ny):\n            bwi.append(biweight_location(data[i, :], M=M[i]))\n        bwi = np.array(bwi)\n        assert_allclose(bw, bwi)\n"], "sample_41": ["def test_unit_scale_error():\n    \"\"\"Test that UnitScaleError is raised when a scaled unit is used in FITS format.\"\"\"\n    with pytest.raises(u.UnitScaleError):\n        u.Unit(\"10 m\", format=\"fits\")\n"], "sample_43": ["def test_bayesian_blocks_empty_input():\n    \"\"\"Test bayesian_blocks with empty input\"\"\"\n    t = np.array([])\n    edges = bayesian_blocks(t, fitness='events')\n    assert_allclose(edges, [])\n\n    t = np.array([1])\n    edges = bayesian_blocks(t, fitness='events')\n    assert_allclose(edges, [1])\n\n    t = np.array([1, 2])\n    edges = bayesian_blocks(t, fitness='events')\n    assert_allclose(edges, [1, 2])\n"], "sample_44": ["    def test_pickle(self):\n        lq = u.Magnitude(np.arange(1., 10.)*u.Jy)\n        s = pickle.dumps(lq)\n        lq2 = pickle.loads(s)\n        assert np.all(lq.value == lq2.value)\n        assert lq.unit == lq2.unit\n"], "sample_47": ["    def test_cleanse_setting_dictionary_with_non_string_key(self):\n        initial = {42: 'cooper', 'password': 'secret'}\n        expected = {42: 'cooper', 'password': CLEANSED_SUBSTITUTE}\n        self.assertEqual(cleanse_setting('SETTING_NAME', initial), expected)\n"], "sample_48": ["def test_aggregate_over_subquery(self):\n    subquery = Book.objects.filter(rating__gt=4).values('publisher_id').annotate(\n        num_books=Count('id')\n    ).values('num_books')\n    publishers = Publisher.objects.annotate(num_books=Subquery(subquery)).filter(num_books__gt=0)\n    self.assertQuerysetEqual(publishers, ['Morgan Kaufmann'], lambda p: p.name)\n"], "sample_49": ["def test_media_order_conflict_warning(self):\n    class MyWidget1(TextInput):\n        class Media:\n            js = ('/path/to/js1', '/path/to/js2')\n\n    class MyWidget2(TextInput):\n        class Media:\n            js = ('/path/to/js2', '/path/to/js1')\n\n    with self.assertWarnsMessage(RuntimeWarning, 'Detected duplicate Media files in an opposite order'):\n        MyWidget1().media + MyWidget2().media\n"], "sample_50": ["def test_empty_params(self):\n    self.assertEqual(\n        self._run_it({}),\n        (['psql', ''], None),\n    )\n"], "sample_51": ["def test_parse_duration_invalid_inputs(self):\n    invalid_inputs = (\n        'abc',\n        '1 year',\n        '1 month',\n        'P4Y2M',\n        'P4M2D',\n        'PT5H2M',\n        'PT5M2S',\n        'PT5S2',\n        '-P4D',\n        '-PT5H',\n        '-PT5M',\n        '-PT5S',\n    )\n    for source in invalid_inputs:\n        with self.subTest(source=source):\n            self.assertIsNone(parse_duration(source))\n"], "sample_54": ["def test_file_response_with_filename(self):\n    response = FileResponse(io.BytesIO(b'binary content'), filename='example.txt')\n    self.assertEqual(response['Content-Type'], 'text/plain')\n    self.assertEqual(response['Content-Disposition'], 'inline; filename=\"example.txt\"')\n    response.close()\n"], "sample_58": ["def test_media(self):\n    class MediaForm(Form):\n        pass\n\n    form = MediaForm()\n    self.assertEqual(form.media, Media())\n\n    class MediaForm(Form):\n        media = Media(js=['some.js'])\n\n    form = MediaForm()\n    self.assertEqual(form.media, Media(js=['some.js']))\n\n    class MediaForm(Form):\n        class Media:\n            js = ['some.js']\n\n    form = MediaForm()\n    self.assertEqual(form.media, Media(js=['some.js']))\n"], "sample_57": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = '!'\n        html = widget.render(name='password', value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_59": ["    def test_deferred_fields(self):\n        # Create an instance with deferred fields and check that accessing them\n        # results in a database query.\n        obj = Article.objects.defer('headline').get()\n        with self.assertNumQueries(1):\n            obj.headline\n\n        # Check that accessing a deferred field again doesn't result in another\n        # database query.\n        with self.assertNumQueries(0):\n            obj.headline\n\n        # Check that deferred fields are properly cleared when refreshing the\n        # object from the database.\n        obj.refresh_from_db()\n        with self.assertNumQueries(1):\n            obj.headline\n"], "sample_61": ["    def test_regex(self):\n        v = UnicodeUsernameValidator()\n        self.assertEqual(v.regex, r'^[\\w.@+-]+\\Z')\n        self.assertEqual(v.flags, 0)\n"], "sample_62": ["    def setUp(self):\n        self.site = admin.AdminSite()\n"], "sample_63": ["    def test_find_template(self):\n        engine = Engine(dirs=[TEMPLATE_DIR])\n        template, origin = engine.find_template('index.html')\n        self.assertEqual(template.name, 'index.html')\n"], "sample_65": ["    def test_jsoncatalog(self):\n        response = self.client.get('/jsoncatalog/')\n        data = json.loads(response.content.decode())\n        self.assertIn('catalog', data)\n        self.assertIn('formats', data)\n        self.assertEqual(data['formats']['TIME_INPUT_FORMATS'], ['%H:%M:%S', '%H:%M:%S.%f', '%H:%M'])\n        self.assertEqual(data['formats']['FIRST_DAY_OF_WEEK'], 0)\n        self.assertIn('plural', data)\n        self.assertEqual(data['catalog']['month name\\x04May'], 'Mai')\n        self.assertIn('DATETIME_FORMAT', data['formats'])\n        self.assertEqual(data['plural'], '(n != 1)')\n"], "sample_68": ["    def test_cleanse_setting_with_callable(self):\n            return \"This should not be displayed\"\n        cleansed = cleanse_setting('SETTING_NAME', callable_setting)\n        self.assertIsInstance(cleansed, CallableSettingWrapper)\n        self.assertEqual(repr(cleansed), repr(callable_setting))\n"], "sample_69": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_70": ["def test_collector_sort(self):\n    # Create some objects with dependencies\n    r = R.objects.create()\n    s1 = S.objects.create(r=r)\n    s2 = S.objects.create(r=r)\n    t1 = T.objects.create(s=s1)\n    t2 = T.objects.create(s=s2)\n\n    collector = Collector(using='default')\n    collector.collect([r], collect_related=True)\n\n    # Check that the collector has sorted the objects correctly\n    self.assertEqual(collector.data, {\n        T: {t1, t2},\n        S: {s1, s2},\n        R: {r},\n    })\n"], "sample_71": ["def test_non_uniform_digit_grouping(self):\n    # Test non-uniform digit grouping.\n    self.assertEqual(nformat(1234567, '.', grouping=(3, 2, 0), thousand_sep=','), '1,23,45,67')\n    self.assertEqual(nformat(123456789, '.', grouping=(3, 2, 0), thousand_sep=','), '123,45,67,89')\n    self.assertEqual(nformat(123456789012, '.', grouping=(3, 2, 0), thousand_sep=','), '123,456,78,9012')\n    self.assertEqual(nformat(12345678901234, '.', grouping=(3, 2, 0), thousand_sep=','), '12,345,678,90,1234')\n"], "sample_74": ["def test_empty_params(self):\n    self.assertEqual(\n        self._run_it({}),\n        (['psql', ''], {})\n    )\n"], "sample_76": ["def test_consistent_language_settings(self):\n    with self.settings(LANGUAGE_CODE='fr', LANGUAGES=[('fr', 'French')]):\n        self.assertEqual(check_language_settings_consistent(None), [])\n\n    with self.settings(LANGUAGE_CODE='en-us', LANGUAGES=[('en-us', 'English (US)')]):\n        self.assertEqual(check_language_settings_consistent(None), [])\n\n    with self.settings(LANGUAGE_CODE='en-us', LANGUAGES=[]):\n        self.assertEqual(check_language_settings_consistent(None), [\n            Error(\n                'You have provided a value for the LANGUAGE_CODE setting that is '\n                'not in the LANGUAGES setting.',\n                id='translation.E004',\n            ),\n        ])\n"], "sample_77": ["def test_urlize_trailing_punctuation(self):\n    tests = (\n        ('Check out www.djangoproject.com.', 'Check out <a href=\"http://www.djangoproject.com\">www.djangoproject.com</a>.'),\n        ('Welcome to my site: https://example.com!', 'Welcome to my site: <a href=\"https://example.com\">https://example.com</a>!'),\n        ('The URL is http://example.com...', 'The URL is <a href=\"http://example.com\">http://example.com</a>...'),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_78": ["def test_command_error(self):\n    \"\"\"Test that CommandError is raised when an error occurs.\"\"\"\n    with self.assertRaises(CommandError):\n        management.call_command('dance', example=\"raise\", stderr=StringIO())\n"], "sample_82": ["def test_value_from_datadict_invalid_date(self):\n    data = {'date_year': '2010', 'date_month': '13', 'date_day': '32'}\n    self.assertIsNone(self.widget.value_from_datadict(data, {}, 'date'))\n"], "sample_81": ["    def test_str(self):\n        pattern = RegexPattern(r'^test/$')\n        url_pattern = URLPattern(pattern, lambda x: None)\n        self.assertEqual(str(url_pattern), '<URLPattern ^test/$>')\n"], "sample_83": ["    def test_get_resolved_arguments(self):\n        class DummyNode(TagHelperNode):\n                super().__init__(func, takes_context, args, kwargs)\n\n            return ''\n\n        node = DummyNode(dummy_func, True, ['arg1', 'arg2'], {'kwarg1': 'value1'})\n        context = {'arg1': 'resolved_arg1', 'arg2': 'resolved_arg2', 'value1': 'resolved_value1'}\n        resolved_args, resolved_kwargs = node.get_resolved_arguments(context)\n        self.assertEqual(resolved_args, [context, 'resolved_arg1', 'resolved_arg2'])\n        self.assertEqual(resolved_kwargs, {'kwarg1': 'resolved_value1'})\n\n        node = DummyNode(dummy_func, False, ['arg1', 'arg2'], {'kwarg1': 'value1'})\n        resolved_args, resolved_kwargs = node.get_resolved_arguments(context)\n        self.assertEqual(resolved_args, ['resolved_arg1', 'resolved_arg2'])\n        self.assertEqual(resolved_kwargs, {'kwarg1': 'resolved_value1'})\n"], "sample_84": ["    def test_fields_limit(self):\n        query_string = 'a=1&b=2&c=3'\n        result = limited_parse_qsl(query_string, fields_limit=2)\n        self.assertEqual(result, [('a', '1'), ('b', '2')])\n"], "sample_86": ["def test_lazy_hash(self):\n    \"\"\"\n    hash() works correctly for Promises.\n    \"\"\"\n    lazy_a = lazy(lambda: 4, int)\n    lazy_b = lazy(lambda: 4, int)\n    lazy_c = lazy(lambda: 5, int)\n\n    self.assertEqual(hash(lazy_a()), hash(lazy_b()))\n    self.assertNotEqual(hash(lazy_b()), hash(lazy_c()))\n"], "sample_87": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_89": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_91": ["def test_permission_denied(self):\n    request = self.request_factory.get('/')\n    exception = Exception('Test exception')\n    response = permission_denied(request, exception)\n    self.assertContains(response, b'<h1>403 Forbidden</h1>', status_code=403)\n    self.assertIn(b'<!doctype html>', response.content)\n    self.assertIn(b'<html lang=\"en\">', response.content)\n    self.assertIn(b'<head>', response.content)\n    self.assertIn(b'<title>403 Forbidden</title>', response.content)\n    self.assertIn(b'<body>', response.content)\n    self.assertIn(str(exception).encode(), response.content)\n"], "sample_92": ["    def setUpTestData(cls):\n        cls.user = User.objects.create_user('test', 'test@example.com')\n"], "sample_94": ["    def test_get_input_data(self):\n        field = User._meta.get_field('username')\n        message = 'Username: '\n        default = None\n\n        # Test with valid input\n        with mock.patch.object(builtins, 'input', return_value='test'):\n            result = createsuperuser.Command().get_input_data(field, message, default)\n            self.assertEqual(result, 'test')\n\n        # Test with invalid input\n        with mock.patch.object(builtins, 'input', return_value='invalid'):\n            with mock.patch.object(field, 'clean', side_effect=exceptions.ValidationError('Error')):\n                result = createsuperuser.Command().get_input_data(field, message, default)\n                self.assertIsNone(result)\n\n        # Test with default value\n        with mock.patch.object(builtins, 'input', return_value=''):\n            result = createsuperuser.Command().get_input_data(field, message, 'default')\n            self.assertEqual(result, 'default')\n"], "sample_98": ["    def test_wsgi_application(self):\n        \"\"\"\n        Test that the WSGI application is properly loaded and used by the live server.\n        \"\"\"\n        with self.urlopen('/wsgi_app_test/') as f:\n            self.assertEqual(f.read(), b'WSGI application works')\n"], "sample_100": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_101": ["def test_limited_stream(self):\n    \"\"\"\n    Test the LimitedStream class.\n    \"\"\"\n    stream = BytesIO(b'Hello World!')\n    limited_stream = LimitedStream(stream, 5)\n\n    self.assertEqual(limited_stream.read(3), b'Hel')\n    self.assertEqual(limited_stream.read(2), b'lo')\n    self.assertEqual(limited_stream.read(), b'')\n\n    stream = BytesIO(b'Hello World!')\n    limited_stream = LimitedStream(stream, 15)\n\n    self.assertEqual(limited_stream.read(13), b'Hello World!')\n    self.assertEqual(limited_stream.read(), b'')\n\n    stream = BytesIO(b'Hello\\nWorld!')\n    limited_stream = LimitedStream(stream, 10)\n\n    self.assertEqual(limited_stream.readline(), b'Hello\\n')\n    self.assertEqual(limited_stream.readline(), b'World!')\n    self.assertEqual(limited_stream.readline(), b'')\n"], "sample_103": ["def test_aggregate_over_subquery_annotation(self):\n    \"\"\"Aggregates can be used over subquery annotations.\"\"\"\n    latest_book_pubdate_qs = Book.objects.filter(\n        publisher=OuterRef('pk')\n    ).order_by('-pubdate').values('pubdate')[:1]\n    publisher_qs = Publisher.objects.annotate(\n        latest_book_pubdate=Subquery(latest_book_pubdate_qs),\n    ).aggregate(Max('latest_book_pubdate'))\n    self.assertEqual(\n        publisher_qs,\n        {'latest_book_pubdate__max': datetime.date(2008, 11, 3)}\n    )\n"], "sample_107": ["    def test_cleanse_setting_callable(self):\n            return \"This should not be displayed\"\n        cleansed = cleanse_setting('SETTING_NAME', callable_setting)\n        self.assertIsInstance(cleansed, CallableSettingWrapper)\n"], "sample_106": ["def test_patch_cache_control_with_max_age(self):\n    response = HttpResponse()\n    patch_cache_control(response, max_age=3600)\n    self.assertEqual(response['Cache-Control'], 'max-age=3600')\n\n    response = HttpResponse()\n    patch_cache_control(response, max_age=3600, public=True)\n    self.assertEqual(response['Cache-Control'], 'max-age=3600, public')\n\n    response = HttpResponse()\n    patch_cache_control(response, max_age=3600, private=True)\n    self.assertEqual(response['Cache-Control'], 'max-age=3600, private')\n"], "sample_105": ["    def test_get_context_data(self):\n        view = ContextMixin()\n        context = view.get_context_data()\n        self.assertIn('view', context)\n        self.assertEqual(context['view'], view)\n"], "sample_108": ["    def test_check_pattern_name(self):\n        msg = (\n            \"URL route 'hello/' uses a name including a ':'. Remove the colon, to \"\n            \"avoid ambiguous namespace references.\"\n        )\n        with self.assertRaisesMessage(Warning, msg):\n            path('hello/', empty_view, name='view:name')\n"], "sample_111": ["def test_get_filters_params(self):\n    \"\"\"\n    Test that get_filters_params returns all params except IGNORED_PARAMS.\n    \"\"\"\n    m = ChildAdmin(Child, custom_site)\n    request = self.factory.get('/child/', data={'age': '10', ALL_VAR: '', SEARCH_VAR: 'test'})\n    request.user = self.superuser\n    cl = m.get_changelist_instance(request)\n    filters_params = cl.get_filters_params()\n    self.assertEqual(filters_params, {'age': '10'})\n"], "sample_112": ["def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should return a list of dictionaries.\n    \"\"\"\n    request = self.request_factory.get(reverse('admin:auth_user_change', args=[self.superuser.pk]))\n    request.user = self.superuser\n    admin = UserAdmin(User, site)\n    response = admin.change_view(request, str(self.superuser.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIsInstance(template_context['prepopulated_fields'], list)\n    self.assertIsInstance(template_context['prepopulated_fields_json'], str)\n    for field in template_context['prepopulated_fields']:\n        self.assertIsInstance(field, dict)\n        self.assertIn('id', field)\n        self.assertIn('name', field)\n        self.assertIn('dependency_ids', field)\n        self.assertIn('dependency_list', field)\n        self.assertIn('maxLength', field)\n        self.assertIn('allowUnicode', field)\n"], "sample_113": ["    def test_function_view(self):\n            pass\n        self.assertEqual(get_view_name(view_func), 'tests.test_get_view_name.view_func')\n"], "sample_115": ["    def test_technical_404_template(self):\n        exception = Http404('Page not found')\n        request = RequestFactory().get('/test/')\n        response = technical_404_response(request, exception)\n        self.assertContains(response, '<h1>Page not found <span>(404)</span></h1>', status_code=404)\n"], "sample_117": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = UNUSABLE_PASSWORD_PREFIX + 'unusable'\n        html = widget.render(name='password', value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_122": ["    def test_get_max_age(self):\n        response = HttpResponse()\n        self.assertIsNone(get_max_age(response))\n\n        patch_cache_control(response, max_age=3600)\n        self.assertEqual(get_max_age(response), 3600)\n\n        patch_cache_control(response, max_age='not an integer')\n        self.assertIsNone(get_max_age(response))\n"], "sample_123": ["    def test_fields_limit(self):\n        qs = 'a=1&b=2&c=3'\n        self.assertEqual(limited_parse_qsl(qs, fields_limit=2), [('a', '1'), ('b', '2')])\n        with self.assertRaises(TooManyFieldsSent):\n            limited_parse_qsl(qs, fields_limit=1)\n"], "sample_125": ["    def test_content_type(self):\n        response = HttpResponse()\n        self.assertEqual(response['Content-Type'], 'text/html; charset=utf-8')\n"], "sample_128": ["    def test_covering_index_with_opclasses(self):\n        index = Index(\n            name='covering_headline_idx',\n            fields=['headline'],\n            opclasses=['varchar_pattern_ops'],\n            include=['pub_date', 'published'],\n        )\n        with connection.schema_editor() as editor:\n            self.assertIn(\n                '(%s varchar_pattern_ops) INCLUDE (%s, %s)' % (\n                    editor.quote_name('headline'),\n                    editor.quote_name('pub_date'),\n                    editor.quote_name('published'),\n                ),\n                str(index.create_sql(Article, editor)),\n            )\n            editor.add_index(Article, index)\n            with connection.cursor() as cursor:\n                constraints = connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                )\n                self.assertIn(index.name, constraints)\n                self.assertEqual(\n                    constraints[index.name]['columns'],\n                    ['headline', 'pub_date', 'published'],\n                )\n            editor.remove_index(Article, index)\n            with connection.cursor() as cursor:\n                self.assertNotIn(index.name, connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                ))\n"], "sample_131": ["def test_create_test_db_clone_settings(self):\n    creation = connection.creation_class(connection)\n    suffix = 'test_suffix'\n    clone_settings = creation.get_test_db_clone_settings(suffix)\n    self.assertEqual(clone_settings['NAME'], '{}_{}'.format(connection.settings_dict['NAME'], suffix))\n    for key, value in connection.settings_dict.items():\n        if key != 'NAME':\n            self.assertEqual(clone_settings[key], value)\n"], "sample_132": ["    def test_technical_404_response(self):\n        exception = Http404('Page not found')\n        request = RequestFactory().get('/test_view/')\n        response = technical_404_response(request, exception)\n        self.assertEqual(response.status_code, 404)\n        self.assertContains(response, 'Page not found', status_code=404)\n"], "sample_133": ["    def test_jsoncatalog(self):\n        response = self.client.get('/jsoni18n/')\n        self.assertEqual(response['Content-Type'], 'application/json')\n        data = json.loads(response.content.decode())\n        self.assertIn('catalog', data)\n        self.assertIn('formats', data)\n        self.assertIn('plural', data)\n"], "sample_139": ["def test_changelist_view_list_editable_changed_objects_uses_filter_with_F_expression(self):\n    \"\"\"list_editable edits use a filtered queryset to limit memory usage.\"\"\"\n    a = Swallow.objects.create(origin='Swallow A', load=4, speed=1)\n    Swallow.objects.create(origin='Swallow B', load=2, speed=2)\n    data = {\n        'form-TOTAL_FORMS': '2',\n        'form-INITIAL_FORMS': '2',\n        'form-MIN_NUM_FORMS': '0',\n        'form-MAX_NUM_FORMS': '1000',\n        'form-0-uuid': str(a.pk),\n        'form-0-load': '10',\n        '_save': 'Save',\n    }\n    superuser = self._create_superuser('superuser')\n    self.client.force_login(superuser)\n    changelist_url = reverse('admin:admin_changelist_swallow_changelist')\n\n    class SwallowAdmin(admin.ModelAdmin):\n        list_display = ('origin', 'load', 'speed')\n        list_editable = ('load', 'speed')\n        ordering = (F('load').desc(nulls_last=True), Upper(F('origin')).asc())\n\n    custom_site.register(Swallow, SwallowAdmin)\n    model_admin = SwallowAdmin(Swallow, custom_site)\n\n    request = self.factory.post(changelist_url, data=data)\n    pks = model_admin._get_edited_object_pks(request, prefix='form')\n    queryset = model_admin._get_list_editable_queryset(request, prefix='form')\n    self.assertEqual(queryset.count(), 1)\n    data['form-0-uuid'] = 'INVALD_PRIMARY_KEY'\n    # The unfiltered queryset is returned if there's invalid data.\n    request = self.factory.post(changelist_url, data=data)\n    queryset = model_admin._get_list_editable_queryset(request, prefix='form')\n    self.assertEqual(queryset.count(), 2)\n"], "sample_137": ["def test_replace_named_groups(self):\n    pattern = r'^(?P<a>\\w+)/b/(?P<c>\\w+)/$'\n    expected_output = '^<a>/b/<c>/$'\n    self.assertEqual(replace_named_groups(pattern), expected_output)\n\n    pattern = r'^(?P<a>\\w+)/b/(\\w+)$'\n    expected_output = '^<a>/b/(\\\\w+)$'\n    self.assertEqual(replace_named_groups(pattern), expected_output)\n"], "sample_138": ["    def setUp(self):\n        super().setUp()\n        self._temp_dir = temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, 'test'))\n        self.addCleanup(shutil.rmtree, temp_dir)\n"], "sample_140": ["    def test_sensitive_variables(self):\n        @sensitive_variables('password', 'credit_card')\n            raise Exception\n\n        try:\n            my_function('user123', 'pass123', '1234-5678-9012-3456')\n        except Exception:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(None, exc_type, exc_value, tb)\n        html = reporter.get_traceback_html()\n        self.assertIn('password', html)\n        self.assertNotIn('pass123', html)\n        self.assertIn('credit_card', html)\n        self.assertNotIn('1234-5678-9012-3456', html)\n"], "sample_141": ["    def test_progress_bar(self):\n        output = StringIO()\n        progress_bar = serializers.base.ProgressBar(output, 10)\n        for i in range(11):\n            progress_bar.update(i)\n        self.assertEqual(output.getvalue().count('\\n'), 1)\n"], "sample_143": ["def test_camel_case_to_spaces(self):\n    items = [\n        ('camelCase', 'camel case'),\n        ('CamelCase', 'camel case'),\n        ('CAMELCase', 'camel case'),\n        ('_camelCase', '_camel case'),\n        ('_CamelCase', '_camel case'),\n        ('__camelCase', '__camel case'),\n        ('__CamelCase', '__camel case'),\n        ('helloWorld', 'hello world'),\n        ('HelloWorld', 'hello world'),\n        ('hello_World', 'hello_ world'),\n        ('Hello_World', 'hello_ world'),\n    ]\n    for value, output in items:\n        self.assertEqual(text.camel_case_to_spaces(value), output)\n    # Test with lazy string\n    self.assertEqual(text.camel_case_to_spaces(lazystr('camelCase')), 'camel case')\n"], "sample_144": ["def test_inheritance_with_custom_primary_key(self):\n    # Test that a model with a custom primary key can be used as a base class.\n    obj = Child.objects.create(child_data=37, parent_data=42)\n    self.assertEqual(obj.pk, 42)\n\n    # Test that the child's primary key is correctly determined.\n    self.assertEqual(Child._meta.pk.name, 'parent_data')\n    self.assertEqual(Child._meta.pk.model, Parent)\n\n    # Test that the child's primary key is correctly set when creating a new instance.\n    obj = Child(child_data=38, parent_data=43)\n    self.assertEqual(obj.pk, 43)\n\n    # Test that the child's primary key is correctly updated when updating an existing instance.\n    obj = Child.objects.get(pk=42)\n    obj.parent_data = 44\n    obj.save()\n    self.assertEqual(obj.pk, 44)\n"], "sample_146": ["def test_invalid_variant_consistent_language_settings(self):\n    tests = [\n        # language + script.\n        'zh-Hans',\n        # language + region (not in LANGUAGES).\n        'fr-BE',\n        # language + region + variant (not in LANGUAGES).\n        'ca-ES-barcelona',\n    ]\n    msg = (\n        'You have provided a value for the LANGUAGE_CODE setting that is '\n        'not in the LANGUAGES setting.'\n    )\n    for tag in tests:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [\n                Error(msg, id='translation.E004'),\n            ])\n"], "sample_148": ["def test_unquote(self):\n    self.assertEqual(unquote('something_0Aor_0Aother'), 'something\\nor\\nother')\n    self.assertEqual(unquote('nothing'), 'nothing')\n    self.assertEqual(unquote('something_3Delse'), 'something=else')\n    self.assertEqual(unquote('something_2Felse'), 'something/else')\n"], "sample_149": ["def test_check_models_permissions_with_app_configs(self):\n    class Checked(models.Model):\n        class Meta:\n            permissions = [\n                ('my_custom_permission', 'Some permission'),\n            ]\n\n    errors = check_models_permissions(app_configs=self.apps.get_app_configs())\n    self.assertEqual(errors, [])\n"], "sample_152": ["def test_collector_sort(self):\n    # Create some objects to delete\n    r1 = R.objects.create()\n    r2 = R.objects.create()\n    s1 = S.objects.create(r=r1)\n    s2 = S.objects.create(r=r2)\n    t1 = T.objects.create(s=s1)\n    t2 = T.objects.create(s=s2)\n\n    # Create a collector and add the objects to delete\n    collector = Collector(using='default')\n    collector.add([r1, r2])\n    collector.add([s1, s2])\n    collector.add([t1, t2])\n\n    # Sort the collector\n    collector.sort()\n\n    # Check that the objects are in the correct order for deletion\n    self.assertEqual(collector.data, {\n        T: {t1, t2},\n        S: {s1, s2},\n        R: {r1, r2},\n    })\n"], "sample_150": ["    def test_base_command(self):\n        command = BaseCommand()\n        self.assertEqual(command.style, no_style())\n        self.assertIsNone(command.stderr.style_func)\n"], "sample_154": ["def test_check_database_backends_empty_connections(self, mocked_connections):\n    mocked_connections.items.return_value = []\n    issues = check_database_backends(databases=self.databases)\n    self.assertEqual(issues, [])\n"], "sample_155": ["def test_file_response_close(self):\n    file = open(__file__, 'rb')\n    response = FileResponse(file)\n    self.assertFalse(file.closed)\n    response.close()\n    self.assertTrue(file.closed)\n"], "sample_156": ["def test_field_order_with_inheritance(self):\n    class ParentForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n\n    class ChildForm(ParentForm):\n        field3 = CharField()\n        field4 = CharField()\n\n        field_order = ['field4', 'field2']\n\n    form = ChildForm()\n    self.assertEqual(list(form.fields), ['field4', 'field2', 'field1', 'field3'])\n"], "sample_157": ["    def test_create_test_db_with_keepdb(self, mocked_migrate, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=False, keepdb=True)\n            self.assertEqual(test_connection.settings_dict['NAME'], creation._get_test_db_name())\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_159": ["def test_permission_name_max_length_with_non_ascii_characters(self):\n    class Checked(models.Model):\n        class Meta:\n            verbose_name = 'some ridiculously long verbose name with non-ascii characters '\n\n    errors = checks.run_checks(self.apps.get_app_configs())\n    self.assertEqual(errors, [\n        checks.Error(\n            \"The verbose_name of model 'auth_tests.Checked' must be at most 244 \"\n            \"characters for its builtin permission names to be at most 255 characters.\",\n            obj=Checked,\n            id='auth.E007',\n        ),\n    ])\n"], "sample_160": ["def test_non_uniform_digit_grouping(self):\n    self.assertEqual(nformat(1234567, '.', grouping=(3, 2, 0), thousand_sep=','), '1,23,45,67')\n    self.assertEqual(nformat(123456789, '.', grouping=(3, 2, 0), thousand_sep=','), '123,45,67,89')\n    self.assertEqual(nformat(1234, '.', grouping=(3, 2, 0), thousand_sep=','), '1,234')\n    self.assertEqual(nformat(123456789012, '.', grouping=(3, 2, 0), thousand_sep=','), '123,45,67,89012')\n"], "sample_162": ["    def test_obsolete_message_removal_enabled(self):\n        management.call_command('makemessages', locale=[LOCALE], verbosity=0, no_obsolete=True)\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertNotIn('#~ msgid \"\"', po_contents)\n"], "sample_163": ["    def test_get_success_url(self):\n        login_view = LoginView()\n        login_view.request = HttpRequest()\n        login_view.request.GET = {\"next\": \"/next/\"}\n        self.assertEqual(login_view.get_success_url(), \"/next/\")\n"], "sample_164": ["    def test_log_response(self):\n        logger = logging.getLogger('django')\n        request = RequestFactory().get('/')\n        response = views.HttpResponse('OK')\n\n        log_response('message', response=response, request=request, logger=logger)\n        self.assertEqual(len(logger.handlers[0].buffer), 1)\n"], "sample_166": ["    def test_get_random_string_length(self):\n        for length in range(1, 100):\n            self.assertEqual(len(get_random_string(length)), length)\n"], "sample_167": ["def test_naturaltime_seconds_only(self):\n    \"\"\"\n    Test naturaltime filter when time difference is less than a minute.\n    \"\"\"\n    test_list = [\n        now,\n        now - datetime.timedelta(seconds=1),\n        now - datetime.timedelta(seconds=2),\n        now - datetime.timedelta(seconds=59),\n        now + datetime.timedelta(seconds=1),\n        now + datetime.timedelta(seconds=2),\n        now + datetime.timedelta(seconds=59),\n    ]\n    result_list = [\n        'now',\n        'a second ago',\n        '2\\xa0seconds ago',\n        '59\\xa0seconds ago',\n        'a second from now',\n        '2\\xa0seconds from now',\n        '59\\xa0seconds from now',\n    ]\n\n    orig_humanize_datetime, humanize.datetime = humanize.datetime, MockDateTime\n    try:\n        with translation.override('en'):\n            self.humanize_tester(test_list, result_list, 'naturaltime')\n    finally:\n        humanize.datetime = orig_humanize_datetime\n"], "sample_168": ["def test_interactive_false_with_dependent_objects(self):\n    \"\"\"\n    non-interactive mode deletes stale content types and their dependent objects.\n    \"\"\"\n    post = Post.objects.create(title='post', content_type=self.content_type)\n    ModelWithNullFKToSite.objects.create(post=post)\n    with captured_stdout() as stdout:\n        call_command('remove_stale_contenttypes', interactive=False, verbosity=2)\n    self.assertEqual(Post.objects.count(), 0)\n    output = stdout.getvalue()\n    self.assertIn('Deleting stale content type', output)\n    self.assertEqual(ContentType.objects.count(), self.before_count)\n"], "sample_171": ["def test_migrate_syncdb_deferred_sql_executed_with_schemaeditor_for_unmigrated_app(self):\n    \"\"\"\n    For an unmigrated app, editor.execute() is used for executing the syncdb\n    deferred SQL.\n    \"\"\"\n    stdout = io.StringIO()\n    with mock.patch.object(BaseDatabaseSchemaEditor, 'execute') as execute:\n        call_command('migrate', run_syncdb=True, verbosity=1, stdout=stdout, no_color=True)\n        create_table_count = len([call for call in execute.mock_calls if 'CREATE TABLE' in str(call)])\n        self.assertEqual(create_table_count, 2)\n        # There's at least one deferred SQL for creating the foreign key index.\n        self.assertGreater(len(execute.mock_calls), 2)\n    stdout = stdout.getvalue()\n    self.assertIn('Synchronize unmigrated apps: unmigrated_app_syncdb', stdout)\n    self.assertIn('Creating tables...', stdout)\n    table_name = truncate_name('unmigrated_app_syncdb_classroom', connection.ops.max_name_length())\n    self.assertIn('Creating table %s' % table_name, stdout)\n"], "sample_170": ["    def test_technical_404_response(self):\n        exception = Http404('Test 404 message')\n        request = RequestFactory().get('/test/')\n        response = technical_404_response(request, exception)\n        self.assertEqual(response.status_code, 404)\n        self.assertContains(response, 'Test 404 message', status_code=404)\n"], "sample_177": ["def test_get_related_models_recursive_with_self_referential_foreign_key(self):\n    class A(models.Model):\n        to_a = models.ForeignKey('A', models.CASCADE)\n\n        class Meta:\n            app_label = \"migrations\"\n\n    related_models = get_related_models_recursive(A)\n    self.assertEqual(related_models, set())\n"], "sample_178": ["def test_formset_absolute_max_with_initial_data(self):\n    \"\"\"absolute_max limits the number of forms with initial data.\"\"\"\n    LimitedFavoriteDrinkFormSet = formset_factory(\n        FavoriteDrinkForm,\n        extra=1,\n        max_num=1000,\n        absolute_max=2,\n    )\n    initial = [\n        {'name': 'Fernet and Coke'},\n        {'name': 'Bloody Mary'},\n        {'name': 'Gin Tonic'},  # this one will be ignored\n    ]\n    formset = LimitedFavoriteDrinkFormSet(initial=initial)\n    self.assertEqual(len(formset.forms), 3)  # 2 initial, 1 extra\n    self.assertEqual(formset.initial_form_count(), 2)\n    self.assertEqual(formset.total_form_count(), 3)\n"], "sample_185": ["    def test_reset_format_cache(self):\n        # Populate _format_cache with temporary values\n        _format_cache[('DATE_FORMAT', 'en')] = '%m/%d/%Y'\n        _format_cache[('TIME_FORMAT', 'en')] = '%I:%M %p'\n        reset_format_cache()\n        self.assertEqual(_format_cache, {})\n        self.assertEqual(_format_modules_cache, {})\n"], "sample_187": ["def test_camel_case_to_spaces(self):\n    items = [\n        ('camelCase', 'camel case'),\n        ('CamelCase', 'camel case'),\n        ('CAMELCase', 'camel case'),\n        ('_camelCase', '_camel case'),\n        ('Camel_Case', 'camel case'),\n        ('__Camel_Case__', 'camel case'),\n        ('Camel-Case', 'camel case'),\n        ('Camel Case', 'camel case'),\n    ]\n    for value, output in items:\n        self.assertEqual(text.camel_case_to_spaces(value), output)\n        self.assertEqual(text.camel_case_to_spaces(lazystr(value)), output)\n"], "sample_189": ["    def test_get_cache_key_with_vary_on_cookie(self):\n        request = RequestFactory().get('/view/')\n        request.COOKIES = {'sessionid': 'abc123'}\n        response = HttpResponse()\n        response['Vary'] = 'Cookie'\n        learn_cache_key(request, response)\n        cache_key = get_cache_key(request)\n        self.assertIn('Cookie', cache_key)\n"], "sample_191": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertEqual(mocked_termios.tcgetattr.call_count, 1)\n        self.assertEqual(mocked_termios.tcsetattr.call_count, 1)\n"], "sample_192": ["def test_formset_with_empty_data(self):\n    \"\"\"A formset with empty data should not raise an AttributeError.\"\"\"\n    data = {\n        'choices-TOTAL_FORMS': '1',\n        'choices-INITIAL_FORMS': '0',\n        'choices-MIN_NUM_FORMS': '0',\n        'choices-MAX_NUM_FORMS': '0',\n    }\n    ChoiceFormSet = formset_factory(Choice)\n    formset = ChoiceFormSet(data, auto_id=False, prefix='choices')\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(formset.errors, [{},])\n"], "sample_193": ["def test_foreign_key_to_abstract_model(self):\n    new_apps = Apps()\n\n    class AbstractModel(models.Model):\n        class Meta:\n            abstract = True\n            app_label = \"migrations\"\n            apps = new_apps\n\n    class ConcreteModel(models.Model):\n        fk = models.ForeignKey(AbstractModel, models.CASCADE)\n\n        class Meta:\n            app_label = \"migrations\"\n            apps = new_apps\n\n    msg = (\n        \"The field migrations.ConcreteModel.fk was declared with a lazy reference \"\n        \"to 'migrations.abstractmodel', but app 'migrations' doesn't provide model 'abstractmodel'.\"\n    )\n    with self.assertRaisesMessage(ValueError, msg):\n        ModelState.from_model(ConcreteModel)\n"], "sample_194": ["def test_clone(self):\n    constraint = models.UniqueConstraint(fields=['foo', 'bar'], name='unique')\n    cloned_constraint = constraint.clone()\n    self.assertEqual(constraint, cloned_constraint)\n    self.assertIsNot(constraint, cloned_constraint)\n\n    constraint_with_condition = models.UniqueConstraint(\n        fields=['foo', 'bar'],\n        name='unique',\n        condition=models.Q(foo=models.F('bar'))\n    )\n    cloned_constraint_with_condition = constraint_with_condition.clone()\n    self.assertEqual(constraint_with_condition, cloned_constraint_with_condition)\n    self.assertIsNot(constraint_with_condition, cloned_constraint_with_condition)\n\n    constraint_with_deferrable = models.UniqueConstraint(\n        fields=['foo', 'bar'],\n        name='unique',\n        deferrable=models.Deferrable.DEFERRED,\n    )\n    cloned_constraint_with_deferrable = constraint_with_deferrable.clone()\n    self.assertEqual(constraint_with_deferrable, cloned_constraint_with_deferrable)\n    self.assertIsNot(constraint_with_deferrable, cloned_constraint_with_deferrable)\n\n    constraint_with_include = models.UniqueConstraint(\n        fields=['foo', 'bar'],\n        name='unique',\n        include=['baz_1', 'baz_2'],\n    )\n    cloned_constraint_with_include = constraint_with_include.clone()\n    self.assertEqual(constraint_with_include, cloned_constraint_with_include)\n    self.assertIsNot(constraint_with_include, cloned_constraint_with_include)\n\n    constraint_with_opclasses = models.UniqueConstraint(\n        fields=['foo', 'bar'],\n        name='unique',\n        opclasses=['text_pattern_ops', 'varchar_pattern_ops'],\n    )\n    cloned_constraint_with_opclasses = constraint_with_opclasses.clone()\n    self.assertEqual(constraint_with_opclasses, cloned_constraint_with_opclasses)\n    self.assertIsNot(constraint_with_opclasses, cloned_constraint_with_opclasses)\n"], "sample_197": ["def test_custom_time_strings(self):\n    \"\"\" Test custom time strings. \"\"\"\n    time_strings = {\n        'year': npgettext_lazy('custom-years', '%d year', '%d years'),\n        'month': npgettext_lazy('custom-months', '%d month', '%d months'),\n        'week': npgettext_lazy('custom-weeks', '%d week', '%d weeks'),\n        'day': npgettext_lazy('custom-days', '%d day', '%d days'),\n        'hour': npgettext_lazy('custom-hours', '%d hour', '%d hours'),\n        'minute': npgettext_lazy('custom-minutes', '%d minute', '%d minutes'),\n    }\n    with translation.override('en'):\n        self.assertEqual(timesince(self.t, self.t + self.oneminute, time_strings=time_strings), '1\\xa0minute')\n        self.assertEqual(timesince(self.t, self.t + self.onehour, time_strings=time_strings), '1\\xa0hour')\n        self.assertEqual(timesince(self.t, self.t + self.oneday, time_strings=time_strings), '1\\xa0day')\n        self.assertEqual(timesince(self.t, self.t + self.oneweek, time_strings=time_strings), '1\\xa0week')\n        self.assertEqual(timesince(self.t, self.t + self.onemonth, time_strings=time_strings), '1\\xa0month')\n        self.assertEqual(timesince(self.t, self.t + self.oneyear, time_strings=time_strings), '1\\xa0year')\n"], "sample_200": ["def test_sanitize_address_with_non_ascii_domain(self):\n    \"\"\"\n    Test that sanitize_address handles non-ASCII domains correctly.\n    \"\"\"\n    email_address = 'test@\u00f6\u00e4\u00fc.com'\n    sanitized_email = sanitize_address(email_address, encoding='utf-8')\n    self.assertEqual(sanitized_email, 'test@xn--4ca9at.com')\n"], "sample_201": ["def test_update_cookie(self):\n    \"\"\"\n    The _update_cookie method sets the cookie with the encoded data if there is\n    any data to store, or deletes the cookie.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # Test setting the cookie with encoded data\n    messages = ['this', 'that']\n    encoded_data = storage._encode(messages)\n    storage._update_cookie(encoded_data, response)\n    self.assertIn('messages', response.cookies)\n    self.assertEqual(response.cookies['messages'].value, encoded_data)\n\n    # Test deleting the cookie when there is no data to store\n    storage._update_cookie(None, response)\n    self.assertIn('messages', response.cookies)\n    self.assertEqual(response.cookies['messages']['max-age'], 0)\n"], "sample_202": ["def test_update_cookie(self):\n    \"\"\"\n    The _update_cookie method sets the cookie with the encoded data if there is\n    any data to store, or deletes the cookie.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # Test setting the cookie with encoded data\n    messages = [Message(constants.INFO, 'Test message')]\n    encoded_data = storage._encode(messages)\n    storage._update_cookie(encoded_data, response)\n    self.assertIn('messages', response.cookies)\n    self.assertEqual(response.cookies['messages'].value, encoded_data)\n\n    # Test deleting the cookie when there is no data to store\n    storage._update_cookie(None, response)\n    self.assertIn('messages', response.cookies)\n    self.assertEqual(response.cookies['messages']['max-age'], 0)\n"], "sample_203": ["    def test_null_characters_not_allowed(self):\n        validator = validators.ProhibitNullCharactersValidator()\n        with self.assertRaises(ValidationError) as e:\n            validator('a\\0b')\n        self.assertEqual(e.exception.code, 'null_characters_not_allowed')\n"], "sample_204": ["def test_circular_dependencies(self):\n    \"\"\"\n    Tests that circular dependencies are correctly detected.\n    \"\"\"\n    loader = MigrationLoader(connection)\n    with self.assertRaises(NodeNotFoundError):\n        loader.build_graph()\n"], "sample_205": ["def test_update_error_dict(self):\n    error_dict = {'field1': ['error1']}\n    exception = ValidationError('message')\n    updated_dict = exception.update_error_dict(error_dict)\n    self.assertEqual(updated_dict, {'field1': ['error1'], '__all__': ['message']})\n\n    error_dict = {'field1': ['error1']}\n    exception = ValidationError({'field2': ['error2']})\n    updated_dict = exception.update_error_dict(error_dict)\n    self.assertEqual(updated_dict, {'field1': ['error1'], 'field2': ['error2']})\n\n    error_dict = {'field1': ['error1']}\n    exception = ValidationError(['message1', 'message2'])\n    updated_dict = exception.update_error_dict(error_dict)\n    self.assertEqual(updated_dict, {'field1': ['error1'], '__all__': ['message1', 'message2']})\n"], "sample_206": ["def test_fieldfile_eq(self):\n    \"\"\"\n    FieldFile __eq__ method should compare name attribute or the file itself.\n    \"\"\"\n    d = Document.objects.create(myfile='something.txt')\n    self.assertEqual(d.myfile, 'something.txt')\n    self.assertEqual(d.myfile, d.myfile)\n    other_file = File(None, name='something.txt')\n    self.assertEqual(d.myfile, other_file)\n    other_file.name = 'else.txt'\n    self.assertNotEqual(d.myfile, other_file)\n"], "sample_208": ["def test_alter_model_table_with_mti_inheritance(self):\n    \"\"\"\n    AlterModelTable operation should be generated when a model with MTI inheritance\n    has its db_table changed.\n    \"\"\"\n    before = [\n        ModelState('app', 'Animal', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'Dog', [], bases=('app.Animal',)),\n    ]\n    after = [\n        ModelState('app', 'Animal', [\n            ('id', models.AutoField(primary_key=True)),\n        ], options={'db_table': 'new_animal'}),\n        ModelState('app', 'Dog', [], bases=('app.Animal',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['AlterModelTable'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='animal', table='new_animal')\n"], "sample_210": ["    def test_get_context_data(self):\n        view = ContextMixin()\n        context = view.get_context_data()\n        self.assertIn('view', context)\n        self.assertEqual(context['view'], view)\n"], "sample_211": ["    def test_get_context_data(self):\n        view = ContextMixin()\n        context = view.get_context_data(test_key='test_value')\n        self.assertEqual(context['test_key'], 'test_value')\n"], "sample_213": ["    def test_field_file_methods(self):\n        obj = Storage()\n        obj.normal.save(\"django_test.txt\", ContentFile(\"content\"))\n        field_file = obj.normal\n\n        # Test FieldFile methods\n        self.assertEqual(field_file.name, \"tests/django_test.txt\")\n        self.assertEqual(field_file.path, os.path.join(temp_storage_location, \"tests/django_test.txt\"))\n        self.assertEqual(field_file.url, \"/test_media_url/tests/django_test.txt\")\n        self.assertEqual(field_file.size, 7)\n\n        with field_file.open() as f:\n            self.assertEqual(f.read(), b\"content\")\n\n        with field_file.open('rb') as f:\n            self.assertEqual(f.read(), b\"content\")\n\n        field_file.close()\n        field_file.open()\n        self.assertFalse(field_file.closed)\n        field_file.close()\n        self.assertTrue(field_file.closed)\n\n        # Delete the file and check that it's gone\n        field_file.delete()\n        self.assertFalse(os.path.exists(field_file.path))\n"], "sample_212": ["def test_session_middleware_process_response(self):\n    class DummySession:\n            self.session_key = session_key\n            self.accessed = True\n            self.modified = True\n            self.empty = False\n\n            return False\n\n            return 3600\n\n            pass\n\n            return self.empty\n\n    class DummyRequest:\n        COOKIES = {settings.SESSION_COOKIE_NAME: 'session_key'}\n        session = DummySession('session_key')\n\n    class DummyResponse(HttpResponse):\n        status_code = 200\n\n    request = DummyRequest()\n    response = DummyResponse()\n\n    SessionMiddleware().process_response(request, response)\n\n    self.assertIn(settings.SESSION_COOKIE_NAME, response.cookies)\n    self.assertEqual(response.cookies[settings.SESSION_COOKIE_NAME]['max-age'], 3600)\n    self.assertEqual(response.cookies[settings.SESSION_COOKIE_NAME]['expires'], http_date(time.time() + 3600))\n"], "sample_216": ["def test_resolve_relation_recursive(self):\n    model_tuple = ('testapp', 'Author')\n    self.assertEqual(resolve_relation(RECURSIVE_RELATIONSHIP_CONSTANT, *model_tuple), model_tuple)\n    with self.assertRaises(TypeError):\n        resolve_relation(RECURSIVE_RELATIONSHIP_CONSTANT)\n"], "sample_220": ["    def test_reason_phrase(self):\n        response = HttpResponse()\n        self.assertEqual(response.reason_phrase, 'OK')\n"], "sample_222": ["    def test_lock_exclusive_on_closed_file(self):\n        with tempfile.TemporaryFile() as temp:\n            file = File(temp, name='something.txt')\n            file.close()\n            with self.assertRaises(ValueError):\n                locks.lock(file, locks.LOCK_EX)\n"], "sample_226": ["    def test_create_test_db_with_keepdb(self):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        with mock.patch.object(creation, '_create_test_db') as mocked_create:\n            creation.create_test_db(verbosity=0, autoclobber=True, keepdb=True)\n            mocked_create.assert_called_once_with(verbosity=0, autoclobber=True, keepdb=True)\n"], "sample_227": ["def test_genericrelation_reverse(self):\n    class TaggedItemAdmin(ModelAdmin):\n        list_filter = ('content_type',)\n\n    modeladmin = TaggedItemAdmin(TaggedItem, site)\n    request = self.request_factory.get('/')\n    request.user = self.alfred\n    changelist = modeladmin.get_changelist_instance(request)\n    filterspec = changelist.get_filters(request)[0][0]\n    self.assertEqual(filterspec.title, 'content type')\n    choices = list(filterspec.choices(changelist))\n    self.assertEqual(len(choices), 2)\n    self.assertEqual(choices[0]['display'], 'All')\n    self.assertIs(choices[0]['selected'], True)\n    self.assertEqual(choices[0]['query_string'], '?')\n    self.assertEqual(choices[1]['display'], 'bookmark')\n    self.assertIs(choices[1]['selected'], False)\n    self.assertEqual(choices[1]['query_string'], '?content_type__id__exact=13')\n"], "sample_228": ["def test_formset_absolute_max_with_initial_data(self):\n    \"\"\"absolute_max limits the number of forms, even with initial data.\"\"\"\n    LimitedFavoriteDrinkFormSet = formset_factory(\n        FavoriteDrinkForm,\n        extra=1,\n        max_num=1000,\n        absolute_max=2,\n    )\n    initial = [\n        {'name': 'Fernet and Coke'},\n        {'name': 'Bloody Mary'},\n        {'name': 'Gin Tonic'},\n    ]\n    formset = LimitedFavoriteDrinkFormSet(initial=initial)\n    self.assertEqual(len(formset.forms), 2)\n    self.assertEqual(formset.absolute_max, 2)\n"], "sample_231": ["    def test_get_safe_settings(self):\n        reporter_filter = SafeExceptionReporterFilter()\n        settings_dict = reporter_filter.get_safe_settings()\n        self.assertIn('SECRET_KEY', settings_dict)\n        self.assertEqual(settings_dict['SECRET_KEY'], reporter_filter.cleansed_substitute)\n"], "sample_233": ["def test_token_with_invalid_timestamp(self):\n    \"\"\"A token with an invalid timestamp is rejected.\"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    # Parse the token\n    ts_b36, _ = tk1.split(\"-\")\n    # Replace the timestamp with an invalid one\n    invalid_ts_b36 = ' invalid'\n    invalid_tk1 = f'{invalid_ts_b36}-{tk1.split(\"-\")[1]}'\n    self.assertIs(p0.check_token(user, invalid_tk1), False)\n"], "sample_235": ["def test_on_commit_with_closed_connection(self):\n    with transaction.atomic():\n        self.do(1)\n        connection.close()\n\n    # Reconnect and check that the hook is still executed.\n    connection.connect()\n    self.assertDone([1])\n"], "sample_237": ["def test_builtin_permission_codename_length(self):\n    model_name = 'X' * 90\n    model = type(model_name, (models.Model,), {'__module__': self.__module__})\n    errors = checks.run_checks(self.apps.get_app_configs())\n    self.assertEqual(errors, [\n        checks.Error(\n            \"The name of model 'auth_tests.%s' must be at most 93 \"\n            \"characters for its builtin permission codenames to be at \"\n            \"most 100 characters.\" % model_name,\n            obj=model,\n            id='auth.E011',\n        ),\n    ])\n"], "sample_239": ["def test_formset_with_empty_data(self):\n    \"\"\"A formset with empty data should be invalid.\"\"\"\n    data = {\n        'choices-TOTAL_FORMS': '1',\n        'choices-INITIAL_FORMS': '0',\n        'choices-MIN_NUM_FORMS': '0',\n        'choices-MAX_NUM_FORMS': '0',\n        'choices-0-choice': '',\n        'choices-0-votes': '',\n    }\n    ChoiceFormSet = formset_factory(Choice)\n    formset = ChoiceFormSet(data, auto_id=False, prefix='choices')\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(formset.errors, [{'choice': ['This field is required.'], 'votes': ['This field is required.']},])\n"], "sample_240": ["def test_token_with_different_last_login(self):\n    \"\"\"Updating the user last login invalidates the token.\"\"\"\n    user = User.objects.create_user('lastloginuser', 'test5@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk1), True)\n    user.last_login = datetime.now()\n    user.save()\n    self.assertIs(p0.check_token(user, tk1), False)\n"], "sample_241": ["    def test_query_pickling(self):\n        qs = Company.objects.filter(name='Example Inc.')\n        pickle.loads(pickle.dumps(qs))\n        # Intentionally no assert\n"], "sample_244": ["def test_formset_with_disabled_fields(self):\n    \"\"\"Formsets can handle disabled fields.\"\"\"\n    class DisabledForm(Form):\n        field = IntegerField(disabled=True)\n\n    DisabledFormSet = formset_factory(DisabledForm)\n    data = {\n        'form-TOTAL_FORMS': '1',\n        'form-INITIAL_FORMS': '0',\n        'form-0-field': '123',\n    }\n    formset = DisabledFormSet(data, prefix='form')\n    self.assertTrue(formset.is_valid())\n    self.assertEqual([{}], formset.cleaned_data)\n"], "sample_245": ["    def test_no_obsolete_enabled(self):\n        management.call_command('makemessages', locale=[LOCALE], verbosity=0, no_obsolete=True)\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertNotIn('#~ msgid \"\"', po_contents)\n"], "sample_248": ["def test_shell_with_no_interfaces_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import python interface.\"):\n        call_command('shell')\n"], "sample_249": ["    def test_create_test_db_with_keepdb(self):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        with mock.patch.object(creation, '_create_test_db'):\n            creation.create_test_db(verbosity=0, autoclobber=True, serialize=False, keepdb=True)\n        self.assertEqual(test_connection.settings_dict['NAME'], creation._get_test_db_name())\n        with mock.patch.object(creation, '_destroy_test_db'):\n            creation.destroy_test_db(verbosity=0, keepdb=True)\n        self.assertEqual(test_connection.settings_dict['NAME'], creation._get_test_db_name())\n"], "sample_253": ["    def test_not_a_tty(self, mocked_isatty):\n        autoreload.ensure_echo_on()\n        self.assertFalse(mocked_isatty.called)\n"], "sample_256": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = 'unusable password'\n        html = widget.render(name='password', value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_255": ["    def test_close(self):\n        \"\"\"ServerHandler's close() calls _read_limited() on LimitedStream.\"\"\"\n        stream = LimitedStream(BytesIO(b'Hello, world!'), 13)\n        handler = ServerHandler(stream, BytesIO(), BytesIO(), {})\n        handler.close()\n        self.assertEqual(stream._read_limited(), b'')\n"], "sample_258": ["def test_receiver_weakref(self):\n    class WeakReceiver:\n            self.state = val\n\n    receiver = WeakReceiver()\n    weak_receiver = weakref.ref(receiver)\n    a_signal.connect(weak_receiver())\n    del receiver\n    garbage_collect()\n    result = a_signal.send(sender=self, val=\"test\")\n    self.assertEqual(result, [])\n    self.assertTestIsClean(a_signal)\n"], "sample_261": ["def test_parse_duration_invalid_inputs(self):\n    # Invalid inputs\n    invalid_inputs = (\n        'abc',\n        '10:15:30:45',\n        '10.15.30',\n        'P',\n        'PT',\n        'P1',\n        'PT1',\n        'P1Y2M3W4D5H6M7S',\n        '-P1Y2M3W4D5H6M7S',\n    )\n    for source in invalid_inputs:\n        with self.subTest(source=source):\n            self.assertIsNone(parse_duration(source))\n"], "sample_262": ["def test_lazy_object_hash(self):\n    class Klazz:\n            return 123\n\n    lazy_obj = lazy(lambda: Klazz(), Klazz)()\n    self.assertEqual(hash(lazy_obj), 123)\n"], "sample_264": ["def test_update_cookie_empty_messages(self):\n    storage = self.get_storage()\n    response = self.get_response()\n    storage.update(response)\n    self.assertEqual(response.cookies.get(storage.cookie_name), None)\n    # Test that the cookie is deleted when there are no messages.\n    storage.add(constants.INFO, 'test')\n    for m in storage:\n        pass  # Iterate through the storage to simulate consumption of messages.\n    storage.update(response)\n    self.assertEqual(response.cookies[storage.cookie_name]['max-age'], 0)\n"], "sample_265": ["def test_copy_exception(self):\n    original_exc = TemplateDoesNotExist('template.html', tried=['path1', 'path2'])\n    original_exc.template_debug = {'name': 'template.html'}\n    copied_exc = copy_exception(original_exc)\n    self.assertEqual(copied_exc.args, original_exc.args)\n    self.assertEqual(copied_exc.tried, original_exc.tried)\n    self.assertEqual(copied_exc.template_debug, original_exc.template_debug)\n    self.assertIsNot(copied_exc, original_exc)\n"], "sample_266": ["def test_collect_sql(self):\n    \"\"\"\n    Test collect_sql() with a migration plan.\n    \"\"\"\n    loader = MigrationLoader(connection)\n    recorder = MigrationRecorder(connection)\n    self.addCleanup(recorder.flush)\n\n    # Create a plan to apply the 0001_initial and 0002_second migrations.\n    plan = [\n        ('migrations', '0001_initial'),\n        ('migrations', '0002_second'),\n    ]\n\n    # Collect SQL for the plan.\n    sql_statements = loader.collect_sql(plan)\n\n    # Check that the SQL statements are not empty.\n    self.assertGreater(len(sql_statements), 0)\n\n    # Check that the SQL statements contain the expected table creations.\n    self.assertIn('CREATE TABLE \"migrations_author\"', '\\n'.join(sql_statements))\n    self.assertIn('CREATE TABLE \"migrations_book\"', '\\n'.join(sql_statements))\n"], "sample_269": ["    def test_javascript_catalog(self):\n        response = self.client.get('/jsi18n/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response['Content-Type'], 'text/javascript; charset=\"utf-8\"')\n"], "sample_271": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_272": ["def test_migration_plan_with_replaced(self):\n    \"\"\"\n    Tests that replaced migrations are correctly handled in the migration plan.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Create a fake migration history where 0001_initial is applied, but its\n    # replacement 0001_squashed_0002 is not.\n    executor.recorder.record_applied(\"migrations\", \"0001_initial\")\n    plan = executor.migration_plan([(\"migrations\", \"0002_second\")])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_squashed_0002\"], False),\n        ],\n    )\n    # Now let's apply 0001_squashed_0002 and make sure the plan doesn't try to\n    # reapply it.\n    executor.migrate([(\"migrations\", \"0001_squashed_0002\")], fake=True)\n    plan = executor.migration_plan([(\"migrations\", \"0002_second\")])\n    self.assertEqual(plan, [])\n"], "sample_276": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n        self.response = self.client.get(reverse('django-admindocs-models-detail', args=['admin_docs', 'Employee']))\n"], "sample_277": ["def test_register_lookup(self):\n    class MyLookup:\n        lookup_name = 'mylookup'\n\n    class MyModel:\n        pass\n\n    RegisterLookupMixin.register_lookup(MyLookup, MyModel)\n    self.assertIn('mylookup', RegisterLookupMixin.get_lookups())\n    self.assertEqual(RegisterLookupMixin._get_lookup('mylookup'), MyLookup)\n\n    # Test unregistering a lookup\n    RegisterLookupMixin._unregister_lookup(MyLookup)\n    self.assertNotIn('mylookup', RegisterLookupMixin.get_lookups())\n    self.assertIsNone(RegisterLookupMixin._get_lookup('mylookup'))\n"], "sample_278": ["    def test_combine(self):\n        q1 = Q(x=1)\n        q2 = Q(y=2)\n        combined = q1 & q2\n        self.assertEqual(combined.children, [q1, q2])\n        self.assertEqual(combined.connector, Q.AND)\n\n        combined = q1 | q2\n        self.assertEqual(combined.children, [q1, q2])\n        self.assertEqual(combined.connector, Q.OR)\n"], "sample_280": ["def test_aggregation_default_passed_another_aggregate_with_filter(self):\n    result = Book.objects.aggregate(\n        value=Sum('price', filter=Q(rating__lt=3.0), default=Avg('pages', filter=Q(rating__gt=4.0)) / 10.0),\n    )\n    self.assertAlmostEqual(result['value'], Decimal('94.6'), places=2)\n"], "sample_281": ["def test_process_request_invalid_app_label(self):\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': ' invalid', 'model_name': Answer._meta.model_name, 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n"], "sample_282": ["def test_boundfield_widget_type(self):\n    form = ComplexFieldForm()\n    bound_field = form['field1']\n    self.assertEqual(bound_field.widget_type, 'complexmultiwidget')\n"], "sample_283": ["def test_default_database(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env({}),\n        (['psql', 'postgres'], {}),\n    )\n"], "sample_284": ["    def setUp(self):\n        super().setUp()\n        self._temp_dir = temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, 'test'))\n        self.addCleanup(shutil.rmtree, temp_dir)\n"], "sample_285": ["def test_get_finder(self):\n    finder_path = 'django.contrib.staticfiles.finders.FileSystemFinder'\n    finder = get_finder(finder_path)\n    self.assertIsInstance(finder, BaseFinder)\n\n    # Test that the finder is cached.\n    finder2 = get_finder(finder_path)\n    self.assertIs(finder, finder2)\n\n    # Test that an invalid finder path raises an error.\n    with self.assertRaises(ImportError):\n        get_finder('invalid.finder.path')\n\n    # Test that a finder that is not a subclass of BaseFinder raises an error.\n    class InvalidFinder:\n        pass\n\n    with mock.patch('django.contrib.staticfiles.finders.import_string', return_value=InvalidFinder):\n        with self.assertRaisesMessage(ImproperlyConfigured, 'Finder \"InvalidFinder\" is not a subclass of \"BaseFinder\"'):\n            get_finder('invalid.finder.path')\n"], "sample_290": ["def test_suggest_name_with_custom_migration_name_fragment(self):\n    class CustomOperation(migrations.operations.base.Operation):\n            self.name = name\n\n            return (self.__class__.__name__, [self.name], {})\n\n            return f\"Custom operation {self.name}\"\n\n        @property\n            return f\"custom_{self.name}\"\n\n    class Migration(migrations.Migration):\n        operations = [\n            CustomOperation('create'),\n            CustomOperation('delete'),\n        ]\n\n    migration = Migration('some_migration', 'test_app')\n    self.assertEqual(migration.suggest_name(), 'custom_create_custom_delete')\n"], "sample_291": ["    def test_get_context_data(self):\n        view = ContextMixin()\n        context = view.get_context_data(test_key='test_value')\n        self.assertEqual(context['test_key'], 'test_value')\n"], "sample_292": ["def test_csrf_trusted_origins_with_mixed_schemes(self):\n    \"\"\"\n    CsrfViewMiddleware accepts origins with mixed schemes in CSRF_TRUSTED_ORIGINS.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['HTTP_ORIGIN'] = 'https://example.com'\n    mw = CsrfViewMiddleware(post_form_view)\n    self.assertIs(mw._origin_verified(req), True)\n    req.META['HTTP_ORIGIN'] = 'http://example.net'\n    self.assertIs(mw._origin_verified(req), True)\n    req.META['HTTP_ORIGIN'] = 'https://example.net'\n    self.assertIs(mw._origin_verified(req), False)\n"], "sample_293": ["    def test_check_url_pattern(self):\n        resolver = get_resolver()\n        messages = check_resolver(resolver)\n        self.assertEqual(len(messages), 0)\n"], "sample_296": ["def test_update_cookie_empty_messages(self):\n    \"\"\"\n    Test that updating the cookie with an empty list of messages results in\n    deleting the cookie.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # Set initial data.\n    example_messages = ['test', 'me']\n    set_cookie_data(storage, example_messages)\n\n    # Update the cookie with an empty list of messages.\n    storage._update_cookie(storage._encode([]), response)\n\n    # The cookie should be deleted.\n    self.assertEqual(response.cookies[storage.cookie_name]['max-age'], 0)\n"], "sample_298": ["def test_make_token_with_timestamp(self):\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    timestamp = self._num_seconds(datetime.now())\n    token = p0._make_token_with_timestamp(user, timestamp)\n    self.assertIsNotNone(token)\n    ts_b36, _ = token.split(\"-\")\n    self.assertEqual(base36_to_int(ts_b36), timestamp)\n"], "sample_301": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_302": ["def test_database_client_settings_to_cmd_args_env(self):\n    settings_dict = {\n        'HOST': 'localhost',\n        'PORT': 5432,\n        'NAME': 'mydatabase',\n        'USER': 'myuser',\n        'PASSWORD': 'mypassword',\n        'OPTIONS': {\n            'passfile': '/path/to/passfile',\n            'service': 'myservice',\n            'sslmode': 'require',\n            'sslrootcert': '/path/to/sslrootcert',\n            'sslcert': '/path/to/sslcert',\n            'sslkey': '/path/to/sslkey',\n        },\n    }\n    parameters = ['--extra-param']\n    args, env = DatabaseClient.settings_to_cmd_args_env(settings_dict, parameters)\n\n    expected_args = [\n        'psql',\n        '-U', 'myuser',\n        '-h', 'localhost',\n        '-p', '5432',\n        'mydatabase',\n        '--extra-param',\n    ]\n    expected_env = {\n        'PGPASSWORD': 'mypassword',\n        'PGSERVICE': 'myservice',\n        'PGSSLMODE': 'require',\n        'PGSSLROOTCERT': '/path/to/sslrootcert',\n        'PGSSLCERT': '/path/to/sslcert',\n        'PGSSLKEY': '/path/to/sslkey',\n        'PGPASSFILE': '/path/to/passfile',\n    }\n\n    self.assertEqual(args, expected_args)\n    self.assertEqual(env, expected_env)\n"], "sample_303": ["def test_runshell_with_env(self):\n    env = {'TEST_VAR': 'test_value'}\n    with mock.patch('subprocess.run') as run:\n        with mock.patch.object(\n            BaseDatabaseClient,\n            'settings_to_cmd_args_env',\n            return_value=([], env),\n        ):\n            self.client.runshell(None)\n        run.assert_called_once_with([], env={**os.environ, **env}, check=True)\n"], "sample_304": ["    def test_repr(self):\n        validator = RegexValidator(r'^(?:[a-z0-9\\.\\-]*)://')\n        self.assertEqual(\n            repr(validator),\n            f\"RegexValidator({repr(validator.regex.pattern)})\"\n        )\n"], "sample_306": ["def test_parse_duration_invalid_inputs(self):\n    invalid_inputs = (\n        'abc',\n        '123abc',\n        '1 day 2',\n        '1:2:3:4',\n        '1.2.3',\n        'P',\n        'PT',\n        'P1',\n        'PT1',\n        'P1D2',\n        'PT1H2',\n        'P1DT1H2',\n    )\n    for source in invalid_inputs:\n        with self.subTest(source=source):\n            self.assertIsNone(parse_duration(source))\n"], "sample_309": ["    def test_valid_date(self):\n        date_str = 'Sun, 06 Nov 1994 08:49:37 GMT'\n        self.assertEqual(parse_http_date_safe(date_str), parse_http_date(date_str))\n"], "sample_310": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n"], "sample_312": ["def test_add_squash(self):\n    node = Node([('a', 1), ('b', 2)], 'OR')\n    node_to_add = Node([('c', 3), ('d', 4)], 'OR')\n    node.add(node_to_add, 'OR')\n    self.assertEqual(len(node), 4)\n    self.assertEqual(str(node), \"(OR: ('a', 1), ('b', 2), ('c', 3), ('d', 4))\")\n"], "sample_313": ["def test_get_template_directories_with_to_path_error(self, mock_to_path):\n    mock_to_path.side_effect = Exception('Mocked to_path error')\n    with self.assertRaises(Exception) as context:\n        autoreload.get_template_directories()\n    self.assertEqual(str(context.exception), 'Mocked to_path error')\n"], "sample_314": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = '!'\n        html = widget.render(name='password', value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_315": ["    def test_middleware_with_language_prefix(self):\n        response = self.client.get('/en/account/register/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.headers['content-language'], 'en')\n        self.assertEqual(response.context['LANGUAGE_CODE'], 'en')\n"], "sample_316": ["    def test_image_file_properties(self):\n        img_path = os.path.join(os.path.dirname(__file__), \"test.png\")\n        with open(img_path, 'rb') as fh:\n            image_file = images.ImageFile(fh)\n            self.assertEqual(image_file.width, Image.open(fh).size[0])\n            self.assertEqual(image_file.height, Image.open(fh).size[1])\n"], "sample_318": ["    def test_warning_on_invalid_pattern(self):\n        msg = (\n            \"Your URL pattern '^invalid-regex/$' [name='invalid-regex'] has a \"\n            \"route that contains '(?P<', begins with a '^', or ends with a '$'. \"\n            \"This was likely an oversight when migrating to django.urls.path().\"\n        )\n        warnings = URLPattern(\n            RegexPattern(r'^invalid-regex/$'),\n            views.empty_view,\n            name='invalid-regex',\n        ).check()\n        self.assertEqual(len(warnings), 1)\n        self.assertEqual(str(warnings[0]), msg)\n"], "sample_321": ["def test_csrf_trusted_origins_wildcard_subdomains(self):\n    \"\"\"\n    A POST request with an origin that matches a CSRF_TRUSTED_ORIGINS wildcard\n    subdomain is accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['HTTP_ORIGIN'] = 'https://sub.sub.example.com'\n    mw = CsrfViewMiddleware(post_form_view)\n    with override_settings(CSRF_TRUSTED_ORIGINS=['https://*.example.com']):\n        self.assertIs(mw._origin_verified(req), True)\n        resp = mw.process_view(req, post_form_view, (), {})\n        self.assertIsNone(resp)\n"], "sample_322": ["def test_migration_plan_with_replaced_migrations(self):\n    \"\"\"\n    Tests that replaced migrations are properly handled in the migration plan.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Create a graph with a replaced migration\n    graph = MigrationGraph()\n    graph.add_node((\"migrations\", \"0001_initial\"), FakeMigration(\"0001_initial\"))\n    graph.add_node((\"migrations\", \"0002_second\"), FakeMigration(\"0002_second\"))\n    graph.add_node((\"migrations\", \"0003_third\"), FakeMigration(\"0003_third\"))\n    graph.add_dependency(None, (\"migrations\", \"0002_second\"), (\"migrations\", \"0001_initial\"))\n    graph.add_dependency(None, (\"migrations\", \"0003_third\"), (\"migrations\", \"0002_second\"))\n    graph.add_replacement((\"migrations\", \"0002_second\"), [(\"migrations\", \"0002_2_second\")])\n    executor.loader.graph = graph\n\n    # Make a plan to migrate to 0003_third\n    plan = executor.migration_plan([(\"migrations\", \"0003_third\")])\n\n    # The plan should include the replaced migration\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n            (executor.loader.graph.nodes[\"migrations\", \"0002_2_second\"], False),\n            (executor.loader.graph.nodes[\"migrations\", \"0003_third\"], False),\n        ],\n    )\n"], "sample_323": ["def test_migration_plan_with_replaced_migrations(self):\n    \"\"\"\n    Tests that replaced migrations are properly handled in the migration plan.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Create a fake migration history where 0001_initial is applied, but its\n    # replacement 0001_squashed_0002 is not.\n    executor.recorder.record_applied(\"migrations\", \"0001_initial\")\n    plan = executor.migration_plan([(\"migrations\", \"0002_second\")])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_squashed_0002\"], False),\n        ],\n    )\n    # Now let's apply 0001_squashed_0002 and make sure the plan doesn't try to\n    # reapply it.\n    executor.migrate([(\"migrations\", \"0001_squashed_0002\")], fake=True)\n    plan = executor.migration_plan([(\"migrations\", \"0002_second\")])\n    self.assertEqual(plan, [])\n"], "sample_324": ["def test_csrf_cookie_samesite_defaults_to_lax(self):\n    req = self._get_GET_no_csrf_cookie_request()\n    mw = CsrfViewMiddleware(token_view)\n    mw.process_view(req, token_view, (), {})\n    resp = mw(req)\n    self.assertEqual(resp.cookies[settings.CSRF_COOKIE_NAME]['samesite'], 'Lax')\n"], "sample_326": ["def test_urlize_trailing_punctuation(self):\n    tests = (\n        ('Check out www.google.com.', 'Check out <a href=\"http://www.google.com\">www.google.com</a>.'),\n        ('Check out www.google.com!', 'Check out <a href=\"http://www.google.com\">www.google.com</a>!'),\n        ('Check out www.google.com?', 'Check out <a href=\"http://www.google.com\">www.google.com</a>?'),\n        ('Check out www.google.com...', 'Check out <a href=\"http://www.google.com\">www.google.com</a>...'),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_330": ["    def test_typecast_date(self):\n        self.assertIsNone(typecast_date(None))\n        self.assertEqual(typecast_date('2022-01-01'), datetime.date(2022, 1, 1))\n"], "sample_331": ["def test_parse_duration_invalid_inputs(self):\n    invalid_inputs = (\n        'abc',\n        '123abc',\n        '1 day 2',\n        '1:2:3:4',\n        '1.2.3',\n        'P',\n        'PT',\n        'P1',\n        'PT1',\n        'P1D2',\n        'PT1H2',\n        'P1DT1H2',\n    )\n    for source in invalid_inputs:\n        with self.subTest(source=source):\n            self.assertIsNone(parse_duration(source))\n"], "sample_332": ["def test_formset_with_disabled_fields(self):\n    \"\"\"Formsets with disabled fields.\"\"\"\n    class DisabledForm(Form):\n        field = IntegerField(disabled=True)\n\n    DisabledFormSet = formset_factory(DisabledForm)\n    data = {\n        'form-TOTAL_FORMS': '1',\n        'form-INITIAL_FORMS': '0',\n        'form-0-field': '200',\n    }\n    formset = DisabledFormSet(data, prefix='form')\n    self.assertTrue(formset.is_valid())\n    self.assertEqual([{'field': 200}], formset.cleaned_data)\n"], "sample_333": ["def test_field_order_with_inheritance(self):\n    class ParentForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n\n    class ChildForm(ParentForm):\n        field3 = CharField()\n        field4 = CharField()\n\n    form = ChildForm()\n    self.assertEqual(list(form.fields), ['field1', 'field2', 'field3', 'field4'])\n\n    class ChildForm(ParentForm):\n        field3 = CharField()\n        field4 = CharField()\n        field_order = ['field4', 'field3']\n\n    form = ChildForm()\n    self.assertEqual(list(form.fields), ['field1', 'field2', 'field4', 'field3'])\n\n    class ChildForm(ParentForm):\n        field3 = CharField()\n        field4 = CharField()\n        field_order = ['field4', 'field3', 'field1', 'field2']\n\n    form = ChildForm()\n    self.assertEqual(list(form.fields), ['field4', 'field3', 'field1', 'field2'])\n"], "sample_336": ["    def test_warning_on_unnamed_url_pattern(self):\n        msg = (\n            \"URL route 'unnamed/normal/<arg1>/<arg2>/' has a name including a ':'. \"\n            \"Remove the colon, to avoid ambiguous namespace references.\"\n        )\n        with self.assertWarnsMessage(Warning, msg):\n            check_resolver(get_resolver('urlpatterns_reverse.urls'))\n"], "sample_337": ["def test_csrf_token_in_header_with_multiple_values(self):\n    \"\"\"\n    The token may be passed in a header with multiple values.\n    \"\"\"\n    req = self._get_POST_csrf_cookie_request(meta_token=f\"{self._csrf_id_token}, invalid\")\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.process_request(req)\n    resp = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(resp)\n"], "sample_339": ["def test_modelformset_factory_with_custom_form(self):\n    class CustomBookForm(forms.ModelForm):\n            super().__init__(*args, **kwargs)\n            self.fields['title'].required = False\n\n        class Meta:\n            model = Book\n            fields = '__all__'\n\n    BookFormSet = modelformset_factory(Book, form=CustomBookForm)\n    formset = BookFormSet()\n    self.assertFalse(formset.forms[0].fields['title'].required)\n"], "sample_340": ["def test_collect_sql(self):\n    loader = MigrationLoader(connection)\n    recorder = MigrationRecorder(connection)\n    self.addCleanup(recorder.flush)\n    plan = [\n        ('migrations', '0001_initial'),\n        ('migrations', '0002_second'),\n    ]\n    sql_statements = loader.collect_sql(plan)\n    self.assertGreater(len(sql_statements), 0)\n    for statement in sql_statements:\n        self.assertIsInstance(statement, str)\n"], "sample_341": ["def test_formset_with_disabled_fields(self):\n    \"\"\"Formsets can handle disabled fields.\"\"\"\n    class DisabledForm(Form):\n        field = IntegerField(disabled=True)\n\n    DisabledFormSet = formset_factory(DisabledForm)\n    data = {\n        'form-TOTAL_FORMS': '1',\n        'form-INITIAL_FORMS': '0',\n        'form-0-field': '123',\n    }\n    formset = DisabledFormSet(data, prefix='form')\n    self.assertTrue(formset.is_valid())\n    self.assertEqual([form.cleaned_data for form in formset.forms], [{'field': 123}])\n"], "sample_342": ["def test_process_request_invalid_app_label(self):\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'invalid', 'model_name': Answer._meta.model_name, 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n"], "sample_345": ["    def test_not_a_tty(self, mocked_isatty):\n        autoreload.ensure_echo_on()\n        self.assertFalse(termios.tcgetattr.called)\n"], "sample_346": ["    def test_sync_and_async_middleware(self):\n        @sync_and_async_middleware\n            return get_response\n\n        self.assertTrue(my_middleware.sync_capable)\n        self.assertTrue(my_middleware.async_capable)\n"], "sample_347": ["def test_get_current_timezone_name(self):\n    \"\"\"\n    The get_current_timezone_name() function must return the name of the\n    currently active time zone.\n    \"\"\"\n    timezone.activate(EAT)\n    self.assertEqual(timezone.get_current_timezone_name(), 'Etc/GMT-3')\n    timezone.deactivate()\n    self.assertEqual(timezone.get_current_timezone_name(), 'America/Chicago')\n"], "sample_351": ["def test_model_choice_iterator_value_equality(self):\n    value_1 = ModelChoiceIteratorValue(self.c1.pk, self.c1)\n    value_2 = ModelChoiceIteratorValue(self.c1.pk, None)\n    value_3 = ModelChoiceIteratorValue(self.c2.pk, self.c2)\n\n    self.assertEqual(value_1, value_2)\n    self.assertEqual(value_1, self.c1.pk)\n    self.assertNotEqual(value_1, value_3)\n    self.assertNotEqual(value_1, self.c2.pk)\n"], "sample_353": ["    def test_custom_user_required_fields(self):\n        new_io = StringIO()\n        with self.assertRaisesMessage(CommandError, 'You must use --date_of_birth with --noinput.'):\n            call_command(\n                \"createsuperuser\",\n                interactive=False,\n                email=\"joe@somewhere.org\",\n                first_name=\"Joe\",\n                stdout=new_io\n            )\n        command_output = new_io.getvalue().strip()\n        self.assertEqual(command_output, '')\n        self.assertFalse(CustomUser._default_manager.filter(email=\"joe@somewhere.org\").exists())\n"], "sample_354": ["    def test_get_default_username_checks_database(self):\n        User.objects.create(username=get_default_username())\n        default_username_other_db = get_default_username(database='other')\n        self.assertEqual(default_username_other_db, get_system_username())\n"], "sample_355": ["    def setUpTestData(cls):\n        cls.user = User.objects.create_user('test', 'test@example.com', 'test')\n        cls.content_type = ContentType.objects.get_for_model(Group)\n        cls.perm1 = Permission.objects.create(name='test1', content_type=cls.content_type, codename='test1')\n        cls.perm2 = Permission.objects.create(name='test2', content_type=cls.content_type, codename='test2')\n"], "sample_358": ["    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(),\n            col_suffixes=('ASC', 'DESC'), opclasses=('int4_ops', 'text_ops')\n        )\n"], "sample_360": ["    def tearDown(self):\n        cache.clear()\n"], "sample_361": ["def test_urlize_trailing_punctuation(self):\n    tests = (\n        ('Check out www.google.com.', 'Check out <a href=\"http://www.google.com\">www.google.com</a>.'),\n        ('Check out www.google.com!', 'Check out <a href=\"http://www.google.com\">www.google.com</a>!'),\n        ('Check out www.google.com?', 'Check out <a href=\"http://www.google.com\">www.google.com</a>?'),\n        ('Check out www.google.com...', 'Check out <a href=\"http://www.google.com\">www.google.com</a>...'),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_364": ["def test_include_with_namespace(self):\n    msg = (\n        'Specifying a namespace in include() without providing an app_name '\n        'is not supported. Set the app_name attribute in the included '\n        'module, or pass a 2-tuple containing the list of patterns and '\n        'app_name instead.',\n    )\n    with self.assertRaisesMessage(ImproperlyConfigured, msg):\n        include('urlpatterns.included_urls', namespace='namespace')\n"], "sample_365": ["def test_lazy_object_hash(self):\n    lazy_obj = lazy(lambda: 'test', str)\n    self.assertEqual(hash(lazy_obj()), hash('test'))\n"], "sample_366": ["def test_parse_duration_invalid_inputs(self):\n    invalid_inputs = (\n        'abc',\n        '123abc',\n        '1 day 2',\n        '1:2:3:4',\n        '1.2.3',\n        'P',\n        'PT',\n        'P1',\n        'PT1',\n        'P1D2H',\n        'PT1H2M3S4',\n    )\n    for source in invalid_inputs:\n        with self.subTest(source=source):\n            self.assertIsNone(parse_duration(source))\n"], "sample_367": ["    def test_cache_page_decorator(self, mock_CacheMiddleware):\n        @cache_page(123)\n            return HttpResponse()\n\n        request = HttpRequest()\n        a_view(request)\n\n        mock_CacheMiddleware.assert_called_once_with(\n            page_timeout=123,\n            cache_alias=None,\n            key_prefix=None,\n        )\n"], "sample_368": ["def test_migration_plan_with_replaced_migrations(self):\n    \"\"\"\n    Test that replaced migrations are properly handled in the migration plan.\n    \"\"\"\n    a1_impl = FakeMigration('a1')\n    a1 = ('a', '1')\n    a2_impl = FakeMigration('a2')\n    a2 = ('a', '2')\n    a3_impl = FakeMigration('a3')\n    a3 = ('a', '3')\n    graph = MigrationGraph()\n    graph.add_node(a1, a1_impl)\n    graph.add_node(a2, a2_impl)\n    graph.add_node(a3, a3_impl)\n    graph.add_dependency(None, a2, a1)\n    graph.add_dependency(None, a3, a2)\n    graph.add_replacement(a3, [a1, a2])\n\n    executor = MigrationExecutor(None)\n    executor.loader = FakeLoader(graph, {\n        a1: a1_impl,\n        a2: a2_impl,\n    })\n\n    plan = executor.migration_plan({a3})\n\n    self.assertEqual(plan, [(a3_impl, False)])\n"], "sample_371": ["    def test_technical_404_template(self):\n        exception = Http404('Testing technical 404.')\n        request = self.rf.get('/test_view/')\n        response = technical_404_response(request, exception)\n        self.assertContains(response, '<h1>Page not found <span>(404)</span></h1>', status_code=404)\n        self.assertContains(response, 'Testing technical 404.', status_code=404)\n"], "sample_372": ["    def test_check_pattern_startswith_slash(self):\n        msg = (\n            \"Your URL pattern '^/test/$' has a route beginning with a '/'. \"\n            \"Remove this slash as it is unnecessary. If this pattern is \"\n            \"targeted in an include(), ensure the include() pattern has a \"\n            \"trailing '/'\"\n        )\n        with self.assertRaisesMessage(Warning, msg):\n            path('/test/', views.empty_view).check()\n"], "sample_373": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n"], "sample_376": ["def test_update_cookie(self):\n    \"\"\"\n    The _update_cookie method correctly sets or deletes the cookie.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # Test setting the cookie with encoded data\n    encoded_data = storage._encode(['message'])\n    storage._update_cookie(encoded_data, response)\n    self.assertIn(CookieStorage.cookie_name, response.cookies)\n    self.assertEqual(response.cookies[CookieStorage.cookie_name].value, encoded_data)\n\n    # Test deleting the cookie when there is no encoded data\n    storage._update_cookie(None, response)\n    self.assertIn(CookieStorage.cookie_name, response.cookies)\n    self.assertEqual(response.cookies[CookieStorage.cookie_name]['max-age'], 0)\n"], "sample_377": ["    def test_get_safe_settings(self):\n        reporter_filter = SafeExceptionReporterFilter()\n        settings_dict = reporter_filter.get_safe_settings()\n        self.assertIn(\"SECRET_KEY\", settings_dict)\n        self.assertEqual(settings_dict[\"SECRET_KEY\"], reporter_filter.cleansed_substitute)\n"], "sample_379": ["def test_safe_string_addition(self):\n    \"\"\"\n    Test that adding two SafeString instances results in another SafeString.\n    \"\"\"\n    s1 = mark_safe('a&b')\n    s2 = mark_safe('c&d')\n\n    result = s1 + s2\n    self.assertIsInstance(result, SafeString)\n    self.assertEqual(result, 'a&bc&d')\n\n    # Test that adding a SafeString with a regular string results in a regular string\n    result = s1 + 'e&f'\n    self.assertNotIsInstance(result, SafeString)\n    self.assertEqual(result, 'a&be&f')\n"], "sample_380": ["def test_aggregate_over_subquery_annotation(self):\n    subquery = Book.objects.filter(publisher=OuterRef('pk')).values('publisher').annotate(c=Count('*')).values('c')\n    publishers = Publisher.objects.annotate(count=Subquery(subquery)).aggregate(Sum('count'))\n    self.assertEqual(publishers['count__sum'], 6)\n"], "sample_382": ["    def test_template_changed_with_loader_without_get_dirs(self, mock_reset):\n        template_path = Path(__file__).parent / 'templates' / 'index.html'\n        self.assertTrue(autoreload.template_changed(None, template_path))\n        mock_reset.assert_called_once()\n"], "sample_383": ["    def test_ticket_24863(self):\n        \"\"\"\n        Make sure that filtering on a related field with a subquery and an __in lookup works correctly.\n        \"\"\"\n        school = School.objects.create()\n        student1 = Student.objects.create(school=school)\n        student2 = Student.objects.create(school=school)\n        classroom = Classroom.objects.create(school=school)\n        classroom.students.add(student1, student2)\n\n        subquery = Student.objects.filter(classroom=classroom).values_list(\"pk\", flat=True)\n        self.assertSequenceEqual(\n            Student.objects.filter(pk__in=subquery), [student1, student2]\n        )\n"], "sample_385": ["def test_autocomplete_select_multiple(self):\n    beatles = Band.objects.create(name=\"The Beatles\", style=\"rock\")\n    who = Band.objects.create(name=\"The Who\", style=\"rock\")\n    form = AlbumForm(initial={\"featuring\": [beatles.pk, who.pk]})\n    output = form.as_table()\n    selected_option1 = (\n        '<option value=\"%s\" selected>The Beatles</option>' % beatles.pk\n    )\n    selected_option2 = '<option value=\"%s\" selected>The Who</option>' % who.pk\n    self.assertIn(selected_option1, output)\n    self.assertIn(selected_option2, output)\n"], "sample_386": ["def test_safe_string_addition(self):\n    s1 = SafeString(\"a&b\")\n    s2 = SafeString(\"c&d\")\n\n    result = s1 + s2\n    self.assertIsInstance(result, SafeString)\n    self.assertEqual(result, \"a&bc&d\")\n\n    s3 = \"e&f\"\n    result = s1 + s3\n    self.assertNotIsInstance(result, SafeString)\n    self.assertEqual(result, \"a&be&f\")\n"], "sample_388": ["    def setUp(self):\n        self.patched_settings = modify_settings(\n            AUTHENTICATION_BACKENDS={\"append\": \"django.contrib.auth.backends.RemoteUserBackend\"},\n            MIDDLEWARE={\"append\": \"django.contrib.auth.middleware.RemoteUserMiddleware\"},\n        )\n        self.patched_settings.enable()\n        self.user = User.objects.create(username=\"testuser\")\n"], "sample_390": ["def test_was_modified_since_invalid_header(self):\n    \"\"\"\n    Test was_modified_since with an invalid header value.\n    \"\"\"\n    mtime = 1343416141\n    header = \"Invalid Header Value\"\n    self.assertTrue(was_modified_since(header, mtime))\n"], "sample_393": ["    def test_obsolete_message_removal_enabled(self):\n        management.call_command(\n            \"makemessages\", locale=[LOCALE], verbosity=0, no_obsolete=True\n        )\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertNotIn(\"#~ msgid\", po_contents)\n"], "sample_395": ["def test_get_template_directories_with_locmem_loader(self):\n    self.assertSetEqual(\n        autoreload.get_template_directories(),\n        {\n            EXTRA_TEMPLATES_DIR,\n            ROOT / \"templates\",\n        },\n    )\n"], "sample_397": ["def test_get_template_loaders(self):\n    engine = DjangoTemplates(\n        {\n            \"DIRS\": [],\n            \"APP_DIRS\": False,\n            \"NAME\": \"django\",\n            \"OPTIONS\": {\n                \"loaders\": [\n                    \"django.template.loaders.filesystem.Loader\",\n                    \"django.template.loaders.app_directories.Loader\",\n                ],\n            },\n        }\n    )\n    loaders = engine.engine.get_template_loaders(engine.engine.loaders)\n    self.assertEqual(len(loaders), 2)\n    self.assertIsInstance(loaders[0], import_string(\"django.template.loaders.filesystem.Loader\"))\n    self.assertIsInstance(loaders[1], import_string(\"django.template.loaders.app_directories.Loader\"))\n"], "sample_398": ["    def test_get_default_redirect_url(self):\n        view = LoginView()\n        view.next_page = None\n        request = HttpRequest()\n        request.user = self.u1\n        view.request = request\n        self.assertEqual(view.get_default_redirect_url(), settings.LOGIN_REDIRECT_URL)\n"], "sample_402": ["def test_prepend_www_append_slash_redirect_querystring(self):\n    \"\"\"\n    PREPEND_WWW and APPEND_SLASH should preserve querystrings when redirecting.\n    \"\"\"\n    request = self.rf.get(\"/slash?test=1\")\n    resp = CommonMiddleware(get_response_404)(request)\n    self.assertEqual(resp.url, \"http://www.testserver/slash/?test=1\")\n"], "sample_404": ["def test_variable_resolve(self):\n    \"\"\"\n    Test that Variable instances can be resolved correctly.\n    \"\"\"\n    engine = self._engine()\n    template = engine.from_string(\"{{ foo }}\")\n    context = Context({\"foo\": \"bar\"})\n    self.assertEqual(template.render(context), \"bar\")\n\n    # Test that a Variable instance can be resolved when it's an attribute of another object\n    template = engine.from_string(\"{{ foo.bar }}\")\n    context = Context({\"foo\": {\"bar\": \"baz\"}})\n    self.assertEqual(template.render(context), \"baz\")\n\n    # Test that a Variable instance can be resolved when it's a method call\n    class Foo:\n            return \"baz\"\n\n    template = engine.from_string(\"{{ foo.bar }}\")\n    context = Context({\"foo\": Foo()})\n    self.assertEqual(template.render(context), \"baz\")\n\n    # Test that a Variable instance can be resolved when it's a list index\n    template = engine.from_string(\"{{ foo.0 }}\")\n    context = Context({\"foo\": [\"bar\", \"baz\"]})\n    self.assertEqual(template.render(context), \"bar\")\n"], "sample_406": ["    def test_manager_descriptor(self):\n        # Make sure the manager descriptor is correctly assigned to the model class.\n        self.assertIsInstance(Article.objects, ManagerDescriptor)\n        self.assertEqual(Article.objects.manager, Article._default_manager)\n"], "sample_407": ["def test_foreign_key_to_field_instance_type(self):\n    parent = Parent.objects.create(name=\"a\")\n    child = ToFieldChild.objects.create(parent=parent)\n    self.assertIsInstance(child.parent, Parent)\n    self.assertEqual(child.parent_id, parent.name)\n\n    # Test assignment of a new instance to the foreign key field.\n    new_parent = Parent.objects.create(name=\"b\")\n    child.parent = new_parent\n    self.assertIsInstance(child.parent, Parent)\n    self.assertEqual(child.parent_id, new_parent.name)\n\n    # Test assignment of None to the foreign key field.\n    child.parent = None\n    self.assertIsNone(child.parent)\n    self.assertIsNone(child.parent_id)\n"], "sample_409": ["    def test_get_language_info(self):\n        node = GetLanguageInfoNode(lang_code=\"en\", variable=\"lang_info\")\n        context = Context()\n        node.render(context)\n        self.assertIn(\"lang_info\", context)\n        self.assertIsInstance(context[\"lang_info\"], dict)\n        self.assertEqual(context[\"lang_info\"][\"code\"], \"en\")\n"], "sample_410": ["    def test_get_email_field_name(self):\n        user = User()\n        self.assertEqual(user.get_email_field_name(), \"email\")\n"], "sample_411": ["def test_command_error_returncode(self):\n    \"\"\"Test that CommandError takes an optional returncode argument.\"\"\"\n    e = CommandError(\"An error occurred\", returncode=42)\n    self.assertEqual(e.returncode, 42)\n    e = CommandError(\"An error occurred\")\n    self.assertEqual(e.returncode, 1)\n"], "sample_412": ["def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            \"Search for google.com/?q=! and see.\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>! and '\n            \"see.\",\n        ),\n        (\n            \"Check out www.google.com.\",\n            'Check out <a href=\"http://www.google.com\">www.google.com</a>.',\n        ),\n        (\n            \"Check out www.google.com,\",\n            'Check out <a href=\"http://www.google.com\">www.google.com</a>,',\n        ),\n        (\n            \"Check out www.google.com?\",\n            'Check out <a href=\"http://www.google.com\">www.google.com</a>?',\n        ),\n        (\n            \"Check out www.google.com!\",\n            'Check out <a href=\"http://www.google.com\">www.google.com</a>!',\n        ),\n        (\n            \"Check out www.google.com;\",\n            'Check out <a href=\"http://www.google.com\">www.google.com</a>;',\n        ),\n        (\n            \"Check out www.google.com:\",\n            'Check out <a href=\"http://www.google.com\">www.google.com</a>:',\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_413": ["    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n"], "sample_416": ["def test_default_database(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env({}),\n        ([\"psql\", \"postgres\"], None),\n    )\n"], "sample_420": ["    def test_new_with_no_fields_or_exclude(self):\n        class MyModelForm(forms.ModelForm):\n            class Meta:\n                model = Person\n\n        msg = (\n            \"Creating a ModelForm without either the 'fields' attribute \"\n            \"or the 'exclude' attribute is prohibited; form MyModelForm \"\n            \"needs updating.\"\n        )\n        with self.assertRaisesMessage(ImproperlyConfigured, msg):\n            MyModelForm()\n"], "sample_426": ["def test_timeuntil_depth(self):\n    t = datetime.datetime(2022, 1, 1)\n    tests = [\n        (datetime.datetime(2022, 1, 31), 1, \"4\\xa0weeks\"),\n        (datetime.datetime(2022, 1, 31), 2, \"4\\xa0weeks, 2\\xa0days\"),\n        (datetime.datetime(2022, 2, 1), 1, \"1\\xa0month\"),\n        (datetime.datetime(2022, 2, 28), 1, \"1\\xa0month\"),\n        (datetime.datetime(2022, 2, 28), 2, \"1\\xa0month, 3\\xa0weeks\"),\n        (datetime.datetime(2022, 3, 1), 1, \"2\\xa0months\"),\n        (datetime.datetime(2022, 12, 31), 1, \"11\\xa0months\"),\n        (datetime.datetime(2022, 12, 31), 2, \"11\\xa0months, 4\\xa0weeks\"),\n    ]\n    for value, depth, expected in tests:\n        with self.subTest():\n            self.assertEqual(timeuntil(t, value, depth=depth), expected)\n"], "sample_428": ["def test_non_uniform_grouping(self):\n    self.assertEqual(\n        nformat(123456789, \".\", grouping=(3, 2, 0), thousand_sep=\",\", force_grouping=True),\n        \"12,34,56,789\",\n    )\n    self.assertEqual(\n        nformat(123456789, \".\", grouping=(3, 2), thousand_sep=\",\", force_grouping=True),\n        \"123,45,6789\",\n    )\n    self.assertEqual(\n        nformat(123456789, \".\", grouping=(2,), thousand_sep=\",\", force_grouping=True),\n        \"12,34,56,78,90\",\n    )\n"], "sample_429": ["def test_prohibit_null_characters_validator(self):\n    validator = ProhibitNullCharactersValidator()\n    with self.assertRaisesMessage(ValidationError, \"Null characters are not allowed.\"):\n        validator(\"Hello\\x00World\")\n    self.assertIsNone(validator(\"Hello World\"))\n    self.assertIsNone(validator(\"\"))\n    self.assertIsNone(validator(None))\n"], "sample_433": ["def test_suggest_name_with_custom_migration_name(self):\n    class Migration(migrations.Migration):\n        operations = [\n            migrations.CreateModel(\"Person\", fields=[]),\n            migrations.DeleteModel(\"Animal\"),\n        ]\n\n    migration = Migration(\"custom_name\", \"test_app\")\n    self.assertEqual(migration.suggest_name(), \"0001_custom_name\")\n"], "sample_434": ["    def test_template_view_renders_template(self):\n        class TestTemplateView(TemplateView):\n            template_name = \"test_template.html\"\n\n        request_factory = RequestFactory()\n        request = request_factory.get(\"/\")\n        response = TestTemplateView.as_view()(request)\n\n        self.assertIsInstance(response, TemplateResponse)\n        self.assertEqual(response.template_name, [\"test_template.html\"])\n"], "sample_435": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = \"unusable password\"\n        html = widget.render(name=\"password\", value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_436": ["    def test_runserver_command_options(self):\n        out, err = self.run_manage([\"runserver\", \"--help\"])\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"--noreload\")\n        self.assertOutput(out, \"--nothreading\")\n        self.assertOutput(out, \"--ipv6\")\n        self.assertOutput(out, \"--address\")\n        self.assertOutput(out, \"--port\")\n"], "sample_437": ["    def test_validate_thread_sharing(self):\n        connection.inc_thread_sharing()\n        self.assertTrue(connection.allow_thread_sharing)\n        with patch.object(connection, \"_thread_ident\", return_value=None):\n            with self.assertRaises(DatabaseError):\n                connection.validate_thread_sharing()\n        connection.dec_thread_sharing()\n        self.assertFalse(connection.allow_thread_sharing)\n"], "sample_438": ["def test_generic_foreign_key_with_deferred_fields(self):\n    class Model(models.Model):\n        field = GenericForeignKey()\n\n    instance = Model()\n    instance.field = Question.objects.create(text=\"Deferred fields test\")\n    self.assertEqual(instance.field.text, \"Deferred fields test\")\n\n    # Check that deferred fields are properly cleared when assigning a new value\n    instance.refresh_from_db()\n    instance.field = Question.objects.create(text=\"New question\")\n    self.assertEqual(instance.field.text, \"New question\")\n"], "sample_441": ["    def test_normalize_username(self):\n        field = UsernameField()\n        self.assertEqual(field.to_python(\"test\u2126\"), \"test\u03a9\")\n"], "sample_442": ["    def test_dumps_loads(self):\n        serializer = signing.JSONSerializer()\n        tests = [\n            [\"a\", \"list\"],\n            \"a string \\u2019\",\n            {\"a\": \"dictionary\"},\n        ]\n        for obj in tests:\n            with self.subTest(obj=obj):\n                dumped = serializer.dumps(obj)\n                self.assertIsInstance(dumped, bytes)\n                loaded = serializer.loads(dumped)\n                self.assertEqual(obj, loaded)\n"], "sample_443": ["    def test_path_traversal(self):\n        cache = caches[\"default\"]\n        key = \"../test_key\"\n        value = \"test_value\"\n\n        # Attempt to set a cache key with a path traversal attack\n        cache.set(key, value)\n\n        # Check if the cache file was created in the correct location\n        cache_file_path = os.path.join(cache._dir, cache._key_to_file(key))\n        self.assertFalse(os.path.exists(cache_file_path))\n\n        # Attempt to get the cache key with a path traversal attack\n        self.assertIsNone(cache.get(key))\n\n        # Attempt to delete the cache key with a path traversal attack\n        self.assertIs(cache.delete(key), False)\n"], "sample_444": ["    def setUp(self):\n        super().setUp()\n        self._temp_dir = temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, \"test\"))\n        self.addCleanup(shutil.rmtree, temp_dir)\n"], "sample_445": ["def test_timeuntil(self):\n    \"\"\"Test timeuntil with various inputs.\"\"\"\n    tests = [\n        (self.t, self.t, \"0\\xa0minutes\"),\n        (self.t, self.t + self.onemicrosecond, \"0\\xa0minutes\"),\n        (self.t, self.t + self.onesecond, \"0\\xa0minutes\"),\n        (self.t, self.t + self.oneminute, \"1\\xa0minute\"),\n        (self.t, self.t + self.onehour, \"1\\xa0hour\"),\n        (self.t, self.t + self.oneday, \"1\\xa0day\"),\n        (self.t, self.t + self.oneweek, \"1\\xa0week\"),\n        (self.t, self.t + self.onemonth, \"1\\xa0month\"),\n        (self.t, self.t + self.oneyear, \"1\\xa0year\"),\n    ]\n    for d, now, expected in tests:\n        with self.subTest():\n            self.assertEqual(timeuntil(d, now), expected)\n"], "sample_448": ["def test_validate_expression_with_exclude(self):\n    constraint = models.UniqueConstraint(Lower(\"name\"), name=\"name_lower_uniq\")\n    instance = UniqueConstraintProduct(name=self.p1.name.upper())\n    with self.assertRaises(ValidationError):\n        constraint.validate(UniqueConstraintProduct, instance)\n    constraint.validate(\n        UniqueConstraintProduct,\n        instance,\n        exclude={\"name\"},\n    )\n    constraint.validate(\n        UniqueConstraintProduct,\n        instance,\n        exclude=[Lower(\"name\")],\n    )\n    constraint.validate(\n        UniqueConstraintProduct,\n        instance,\n        exclude={\"name\": Lower},\n    )\n"], "sample_449": ["    def test_finish_response(self):\n        \"\"\"ServerHandler.finish_response() handles HEAD requests correctly.\"\"\"\n        hello_world_body = b\"<!DOCTYPE html><html><body>Hello World</body></html>\"\n\n            \"\"\"A WSGI app that returns a hello world.\"\"\"\n            start_response(\"200 OK\", [])\n            return [hello_world_body]\n\n        rfile = BytesIO(b\"HEAD / HTTP/1.0\\r\\n\")\n        rfile.seek(0)\n\n        wfile = UnclosableBytesIO()\n\n            if mode == \"rb\":\n                return rfile\n            elif mode == \"wb\":\n                return wfile\n\n        request = Stub(makefile=makefile)\n        server = Stub(base_environ={}, get_app=lambda: test_app)\n\n        handler = ServerHandler(rfile, wfile, None, request.get_environ())\n        handler.request_handler = Stub(close_connection=True)\n        handler.result = test_app(request.get_environ(), lambda x, y: None)\n\n        # Prevent logging from appearing in test output.\n        with self.assertLogs(\"django.server\", \"INFO\"):\n            handler.finish_response()\n\n        wfile.seek(0)\n        lines = list(wfile.readlines())\n        body = lines[-1]\n        # The body is not returned in a HEAD response.\n        self.assertEqual(body, b\"\\r\\n\")\n        self.assertIs(\n            any([line.startswith(b\"Content-Length:\") for line in lines]), False\n        )\n        self.assertNotIn(b\"Connection: close\\r\\n\", lines)\n"], "sample_450": ["def test_get_admin_log_template_tag(self):\n    \"\"\"\n    The get_admin_log template tag returns a list of LogEntry objects for the\n    given user and content type.\n    \"\"\"\n    # Create some log entries\n    LogEntry.objects.log_action(\n        self.user.pk,\n        ContentType.objects.get_for_model(Article).pk,\n        self.a1.pk,\n        \"Article changed\",\n        CHANGE,\n        change_message=\"Article changed message\",\n    )\n    LogEntry.objects.log_action(\n        self.user.pk,\n        ContentType.objects.get_for_model(Car).pk,\n        Car.objects.create().pk,\n        \"Car created\",\n        ADDITION,\n        change_message=\"Car created message\",\n    )\n\n    # Test the template tag\n    template = Template('{% load admin_list %}{% get_admin_log 10 as admin_log for_user user %}{{ admin_log|length }}')\n    context = Context({'user': self.user})\n    rendered = template.render(context)\n    self.assertEqual(rendered, '2')\n\n    # Test the template tag with a specific content type\n    template = Template('{% load admin_list %}{% get_admin_log 10 as admin_log for_user user %}{{ admin_log.0.content_type.model }}')\n    context = Context({'user': self.user})\n    rendered = template.render(context)\n    self.assertEqual(rendered, 'article')\n\n    # Test the template tag with an invalid user\n    template = Template('{% load admin_list %}{% get_admin_log 10 as admin_log for_user invalid_user %}{{ admin_log|length }}')\n    context = Context({'invalid_user': 'invalid'})\n    rendered = template.render(context)\n    self.assertEqual(rendered, '0')\n"], "sample_453": ["def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should return a list of dictionaries\n    containing field information.\n    \"\"\"\n    admin = UserAdmin(User, site)\n    request = self.request_factory.get(\n        reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n    )\n    request.user = self.superuser\n    response = admin.change_view(request, str(self.superuser.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIsInstance(template_context[\"prepopulated_fields_json\"], str)\n    fields = json.loads(template_context[\"prepopulated_fields_json\"])\n    self.assertIsInstance(fields, list)\n    for field in fields:\n        self.assertIsInstance(field, dict)\n        self.assertIn(\"id\", field)\n        self.assertIn(\"name\", field)\n        self.assertIn(\"dependency_ids\", field)\n        self.assertIn(\"dependency_list\", field)\n        self.assertIn(\"maxLength\", field)\n        self.assertIn(\"allowUnicode\", field)\n"], "sample_456": ["def test_formset_with_disabled_fields(self):\n    \"\"\"Formsets can handle disabled fields.\"\"\"\n    class DisabledForm(Form):\n        field = CharField(disabled=True)\n\n    DisabledFormSet = formset_factory(DisabledForm)\n    data = {\n        \"form-TOTAL_FORMS\": \"1\",\n        \"form-INITIAL_FORMS\": \"0\",\n        \"form-MIN_NUM_FORMS\": \"0\",\n        \"form-MAX_NUM_FORMS\": \"0\",\n        \"form-0-field\": \"Test\",\n    }\n    formset = DisabledFormSet(data, prefix=\"form\")\n    self.assertTrue(formset.is_valid())\n    self.assertEqual([{\"field\": \"Test\"}], formset.cleaned_data)\n"], "sample_464": ["def test_file_response_with_async_iterator(self):\n    async def async_iterator():\n        yield b\"Hello, \"\n        yield b\"world!\"\n\n    response = FileResponse(async_iterator())\n    self.assertEqual(list(response), [b\"Hello, world!\"])\n"], "sample_466": ["def test_serialize_zoneinfo(self):\n    self.assertSerializedEqual(zoneinfo.ZoneInfo(\"America/New_York\"))\n    tz = zoneinfo.ZoneInfo(\"Europe/Paris\")\n    string, imports = MigrationWriter.serialize(tz)\n    self.assertEqual(\n        string,\n        \"zoneinfo.ZoneInfo('Europe/Paris')\",\n    )\n    self.assertEqual(imports, {\"import zoneinfo\"})\n"], "sample_470": ["def test_lazy_object_deepcopy(self):\n    class Klazz:\n            self.value = value\n\n    original_object = Klazz(15)\n    lazy_obj = lazy(lambda: original_object, Klazz)\n    copied_lazy_obj = copy.deepcopy(lazy_obj())\n    self.assertEqual(original_object.value, copied_lazy_obj.value)\n    self.assertIsNot(original_object, copied_lazy_obj)\n"], "sample_472": ["def test_paginating_ordered_object_list_does_not_warn(self):\n    \"\"\"\n    Ordered object list does not raise a warning.\n    \"\"\"\n\n    class ObjectList:\n        ordered = True\n\n    object_list = ObjectList()\n    with warnings.catch_warnings(record=True) as recorded:\n        Paginator(object_list, 5)\n    self.assertEqual(len(recorded), 0)\n"], "sample_473": ["compilation error"], "sample_474": ["    def setUpTestData(cls):\n        cls.author = Author.objects.create(name=\"John Smith\", alias=\"smithj\")\n"], "sample_476": ["    def test_close_called(self):\n        \"\"\"\n        Test that close() is called on the underlying File object when\n        closing an ImageFieldFile.\n        \"\"\"\n        class MockFile:\n            closed = False\n\n                self.closed = True\n\n        file = MockFile()\n        image_file = ImageFieldFile(None, ImageField(), file)\n        image_file.close()\n        self.assertTrue(file.closed)\n"], "sample_477": ["def test_dictsort(self):\n    output = self.engine.render_to_string(\n        \"dictsort\", {\"dict\": [{\"key\": 2}, {\"key\": 1}, {\"key\": 3}]}\n    )\n    self.assertEqual(output, \"{'key': 1}{'key': 2}{'key': 3}\")\n"], "sample_478": ["    def test_readonly_fields_is_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = \"name\"\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            id=\"admin.E034\",\n        )\n"], "sample_484": ["    def setUpTestData(cls):\n        Author.objects.create(name=\"John Smith\", alias=\"smithj\")\n        Author.objects.create(name=\"Rhonda\")\n"], "sample_485": ["def test_urlize_trailing_punctuation(self):\n    tests = (\n        (\"Check out www.google.com.\", 'Check out <a href=\"http://www.google.com\">www.google.com</a>.'),\n        (\"Check out www.google.com!\", 'Check out <a href=\"http://www.google.com\">www.google.com</a>!'),\n        (\"Check out www.google.com?\", 'Check out <a href=\"http://www.google.com\">www.google.com</a>?'),\n        (\"Check out www.google.com:\", 'Check out <a href=\"http://www.google.com\">www.google.com</a>:'),\n        (\"Check out www.google.com;\", 'Check out <a href=\"http://www.google.com\">www.google.com</a>;'),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_488": ["def test_set_available_apps(self):\n    \"\"\"\n    Tests apps.set_available_apps().\n    \"\"\"\n    old_app_configs = apps.app_configs\n    try:\n        apps.set_available_apps([\"django.contrib.admin\"])\n        self.assertEqual(len(apps.app_configs), 1)\n        self.assertIn(\"admin\", apps.app_configs)\n    finally:\n        apps.unset_available_apps()\n        self.assertEqual(apps.app_configs, old_app_configs)\n\n    with self.assertRaises(ValueError):\n        apps.set_available_apps([\"nonexistent\"])\n"], "sample_492": ["def test_serialize_zoneinfo(self):\n    self.assertSerializedEqual(zoneinfo.ZoneInfo(\"America/New_York\"))\n    tz = zoneinfo.ZoneInfo(\"Europe/Paris\")\n    string, imports = MigrationWriter.serialize(tz)\n    self.assertEqual(\n        string,\n        \"zoneinfo.ZoneInfo('Europe/Paris')\",\n    )\n    self.assertEqual(imports, {\"import zoneinfo\"})\n"], "sample_495": ["def test_page_repr(self):\n    paginator = Paginator([1, 2, 3], 2)\n    page = paginator.page(1)\n    self.assertEqual(repr(page), '<Page 1 of 2>')\n"], "sample_496": ["    def test_command_error(self):\n        class Command(BaseCommand):\n            requires_system_checks = False\n\n                raise CommandError(\"An error occurred.\")\n\n        out = StringIO()\n        err = StringIO()\n        command = Command(stdout=out, stderr=err)\n        with self.assertRaises(SystemExit):\n            call_command(command)\n\n        self.assertEqual(out.getvalue(), \"\")\n        self.assertIn(\"CommandError: An error occurred.\", err.getvalue())\n"], "sample_499": ["def test_legend_bbox_to_anchor():\n    # Test that legend can be placed using bbox_to_anchor argument.\n    fig, ax = plt.subplots()\n    ax.plot([0, 1], [0, 1], label=\"line\")\n    leg = ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n    assert leg.get_bbox_to_anchor().x0 == 1.05\n    assert leg.get_bbox_to_anchor().y0 == 1\n"], "sample_500": ["def test_colorbar_with_alpha():\n    fig, ax = plt.subplots()\n    data = np.random.rand(10, 10)\n    alpha = np.random.rand(10, 10)\n    cmap = cm.get_cmap('viridis')\n    cmap.set_bad(color='red')\n    im = ax.imshow(data, cmap=cmap, alpha=alpha)\n    cb = fig.colorbar(im)\n    assert cb.alpha is None\n    assert cb.cmap == cmap\n    assert cb.get_ticks() is not None\n"], "sample_504": ["def test_colorbar_set_label():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[1, 2], [3, 4]])\n    cbar = fig.colorbar(im)\n    cbar.set_label('Test Label')\n    assert cbar.ax.get_ylabel() == 'Test Label'\n    cbar.set_label(None)\n    assert cbar.ax.get_ylabel() == ''\n    cbar.set_label('Test Label 2')\n    assert cbar.ax.get_ylabel() == 'Test Label 2'\n\n    cbar2 = fig.colorbar(im, orientation='horizontal')\n    cbar2.set_label('Test Label')\n    assert cbar2.ax.get_xlabel() == 'Test Label'\n    cbar2.set_label(None)\n    assert cbar2.ax.get_xlabel() == ''\n    cbar2.set_label('Test Label 2')\n    assert cbar2.ax.get_xlabel() == 'Test Label 2'\n"], "sample_507": ["def test_StrCategoryConverter_convert_pass_through_deprecation():\n    cc = cat.StrCategoryConverter()\n    unit = cat.UnitData()\n    ax = FakeAxis(unit)\n    \n    with pytest.warns(MatplotlibDeprecationWarning):\n        result = cc.convert([1, 2, 3], unit, ax)\n        \n    np.testing.assert_array_equal(result, np.array([1, 2, 3]))\n"], "sample_508": ["def test_artist_stale_callback():\n    class TestArtist(martist.Artist):\n            super().__init__()\n            self.stale_called = False\n\n            self.stale_called = True\n\n    art = TestArtist()\n    art.stale_callback = art.stale_callback\n    art.stale = True\n    assert art.stale_called\n"], "sample_509": ["def test_date2num_out_of_range():\n    with pytest.raises(ValueError, match=\"Matplotlib dates must be between\"):\n        mdates.date2num(np.datetime64('0000-01-01'))\n    with pytest.raises(ValueError, match=\"Matplotlib dates must be between\"):\n        mdates.date2num(np.datetime64('10000-01-01'))\n"], "sample_513": ["def test_legend_set_bbox_to_anchor():\n    # Test that setting bbox_to_anchor updates the legend's position correctly.\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='line')\n    leg = ax.legend()\n\n    # Set bbox_to_anchor to a new value\n    leg.set_bbox_to_anchor((0.5, 0.5))\n\n    # Check that the legend's position has been updated correctly\n    assert leg.get_bbox_to_anchor().x0 == 0.5\n    assert leg.get_bbox_to_anchor().y0 == 0.5\n"], "sample_514": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc)\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n    cb.set_alpha(None)\n    assert cb.alpha is None\n"], "sample_515": ["def test_colorbar_with_no_ticks():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cb = fig.colorbar(im)\n    cb.set_ticks([])\n    assert len(cb.ax.yaxis.get_ticklocs()) == 0\n    assert len(cb.ax.yaxis.get_ticklabels()) == 0\n"], "sample_520": ["def test_line3d_modification(fig_test, fig_ref):\n    # Modifying the Line3D position after the fact should work the same as\n    # setting it directly.\n    x, y, z = [0, 1], [2, 3], [4, 5]\n    x2, y2, z2 = [6, 7], [8, 9], [10, 11]\n\n    ax_test = fig_test.add_subplot(projection='3d')\n    line = ax_test.plot(x, y, z)[0]\n    line.set_data_3d(x2, y2, z2)\n\n    ax_ref = fig_ref.add_subplot(projection='3d')\n    ax_ref.plot(x2, y2, z2)\n"], "sample_522": ["def test_colorbar_with_no_mappable():\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        fig.colorbar(ax=None)\n"], "sample_523": ["def test_legend_handles_labels_from_parent_axes():\n    # Test that legend handles and labels are correctly retrieved from parent axes\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='line')\n    ax2 = ax.twinx()\n    ax2.plot([1, 2], [5, 6], label='line2')\n    handles, labels = mlegend._get_legend_handles_labels([ax])\n    assert len(handles) == 1\n    assert len(labels) == 1\n    handles, labels = mlegend._get_legend_handles_labels([ax2])\n    assert len(handles) == 1\n    assert len(labels) == 1\n    handles, labels = mlegend._get_legend_handles_labels([ax, ax2])\n    assert len(handles) == 2\n    assert len(labels) == 2\n"], "sample_524": ["def test_colorbar_with_no_mappable():\n    fig, ax = plt.subplots()\n    with pytest.raises(TypeError):\n        fig.colorbar(None)\n"], "sample_525": ["def test_subfigure_repr():\n    fig = plt.figure()\n    sub_fig = fig.subfigures(1, 1)\n    assert repr(sub_fig[0]) == \"<SubFigure size 640x480 with 0 Axes>\"\n"], "sample_526": ["def test_MicrosecondLocator():\n    locator = mdates.MicrosecondLocator(interval=1000)\n    ticks = locator.tick_values(0, 1)\n    assert np.allclose(ticks, [0, 0.001, 0.002, 0.003, 0.004, 0.005,\n                               0.006, 0.007, 0.008, 0.009, 0.01])\n"], "sample_527": ["def test_figure_repr():\n    fig = Figure()\n    assert repr(fig) == f\"<{type(fig).__name__} size {fig.get_size_inches()[0]:g}x{fig.get_size_inches()[1]:g} with 0 Axes>\"\n    ax = fig.add_subplot(111)\n    assert repr(fig) == f\"<{type(fig).__name__} size {fig.get_size_inches()[0]:g}x{fig.get_size_inches()[1]:g} with 1 Axes>\"\n"], "sample_528": ["def test_reload_library():\n    original_library = style.library.copy()\n    with temp_style('test', DUMMY_SETTINGS):\n        assert 'test' in style.library\n    style.reload_library()\n    assert style.library == original_library\n"], "sample_529": ["def test_legend_handles_labels():\n    # Test that legend handles and labels are correctly returned\n    fig, ax = plt.subplots()\n    line1, = ax.plot([0, 1], label='line1')\n    line2, = ax.plot([0, 2], label='line2')\n    handles, labels = ax.get_legend_handles_labels()\n    assert handles == [line1, line2]\n    assert labels == ['line1', 'line2']\n"], "sample_530": ["def test_offsetbox_repr():\n    ob = OffsetBox()\n    assert repr(ob) == \"OffsetBox()\"\n    ab = AnchoredOffsetbox(loc=1, child=ob)\n    assert repr(ab) == \"AnchoredOffsetbox(1, child=OffsetBox())\"\n    at = AnchoredText(\"test\", loc=1)\n    assert repr(at) == \"AnchoredText('test', loc=1)\"\n    da = DrawingArea(10, 20)\n    assert repr(da) == \"DrawingArea(10, 20)\"\n    ta = TextArea(\"test\")\n    assert repr(ta) == \"TextArea('test')\"\n    oi = OffsetImage(np.array([[1]]))\n    assert repr(oi) == \"OffsetImage(array([[1]]))\"\n    aob = AnnotationBbox(ob, (0, 0))\n    assert repr(aob) == \"AnnotationBbox((0, 0), child=OffsetBox())\"\n"], "sample_533": ["def test_contour_label_inline_spacing():\n    x, y = np.meshgrid(np.arange(0, 10), np.arange(0, 10))\n    z = np.max(np.dstack([abs(x), abs(y)]), 2)\n\n    fig, ax = plt.subplots()\n    cs = ax.contour(x, y, z)\n    ax.clabel(cs, inline=True, inline_spacing=10)\n    assert len(ax.texts) == len(cs.levels)\n"], "sample_534": ["def test_contour_label_rotations():\n    # Test contour label rotations for different angles.\n    fig, ax = plt.subplots()\n    x, y = np.meshgrid(np.arange(0, 10), np.arange(0, 10))\n    z = np.max(np.dstack([abs(x), abs(y)]), 2)\n    cs = ax.contour(x, y, z)\n    for label in cs.labelTexts:\n        angle = label.get_rotation()\n        assert -90 <= angle <= 90\n    plt.close(fig)\n"], "sample_535": ["def test_table_edges():\n    fig, ax = plt.subplots()\n    table = Table(ax)\n    table.edges = 'open'\n    assert table.edges == ''\n\n    table.edges = 'closed'\n    assert table.edges == 'BRTL'\n\n    table.edges = 'horizontal'\n    assert table.edges == 'BT'\n\n    table.edges = 'vertical'\n    assert table.edges == 'RL'\n\n    table.edges = 'invalid'\n    assert table.edges == 'BRTL'  # should be the default\n\n    table.edges = 'B'\n    assert table.edges == 'B'\n\n    table.edges = None\n    assert table.edges == 'BRTL'  # should be the default\n"], "sample_537": ["def test_psd_window_normalization():\n    \"\"\"Test that the PSD is normalized correctly for different window functions.\"\"\"\n    u = np.array([0, 1, 2, 3, 1, 2, 1])\n    dt = 1.0\n    NFFT = u.size\n\n    # Test with no window (i.e., a rectangular window)\n    P, f = mlab.psd(u, NFFT=NFFT, Fs=1/dt, window=mlab.window_none,\n                    detrend=mlab.detrend_none, noverlap=0, pad_to=None,\n                    scale_by_freq=None,\n                    sides='onesided')\n    Su_1side = np.abs(np.fft.fft(u) * dt)**2 / (dt * u.size)\n    Su_1side = np.append([Su_1side[0]], Su_1side[1:4] + Su_1side[4:][::-1])\n    assert_allclose(P, Su_1side, atol=1e-06)\n\n    # Test with a Hanning window\n    P, f = mlab.psd(u, NFFT=NFFT, Fs=1/dt, window=mlab.window_hanning,\n                    detrend=mlab.detrend_none, noverlap=0, pad_to=None,\n                    scale_by_freq=None,\n                    sides='onesided')\n    w = mlab.window_hanning(np.ones(NFFT))\n    Su_1side = np.abs(np.fft.fft(u*w) * dt)**2 / ((w**2).sum() * dt)\n    Su_1side = np.append([Su_1side[0]], Su_1side[1:4] + Su_1side[4:][::-1])\n    assert_allclose(P, Su_1side, atol=1e-06)\n"], "sample_538": ["def test_affine_delta_transform():\n    # Test that the affine delta transform correctly transforms displacements.\n    t = mtransforms.Affine2D().translate(10, 20).scale(2, 3)\n    dt = mtransforms.AffineDeltaTransform(t)\n\n    points = np.array([[1, 2], [3, 4]])\n    deltas = np.array([[5, 6], [7, 8]])\n\n    expected = t.transform(points + deltas) - t.transform(points)\n    result = dt.transform(deltas)\n\n    assert_array_almost_equal(result, expected)\n"], "sample_540": ["def test_movie_writer_adjusted_figsize():\n    fig = plt.figure()\n    w, h = fig.get_size_inches()\n    dpi = 100\n\n    # Test with n=2 (default for h264)\n    adjusted_w, adjusted_h = animation.adjusted_figsize(w, h, dpi, 2)\n    assert adjusted_w % (2 / dpi) == 0\n    assert adjusted_h % (2 / dpi) == 0\n\n    # Test with n=1\n    adjusted_w, adjusted_h = animation.adjusted_figsize(w, h, dpi, 1)\n    assert adjusted_w % (1 / dpi) == 0\n    assert adjusted_h % (1 / dpi) == 0\n\n    # Test with a different DPI\n    dpi = 50\n    adjusted_w, adjusted_h = animation.adjusted_figsize(w, h, dpi, 2)\n    assert adjusted_w % (2 / dpi) == 0\n    assert adjusted_h % (2 / dpi) == 0\n"], "sample_544": ["def test_imshow_uint64(fig_test, fig_ref):\n    # Test that uint64 images are handled correctly.\n    data = np.arange(256).reshape((16, 16)).astype(np.uint64)\n    ax = fig_test.subplots()\n    ax.imshow(data)\n    ax = fig_ref.subplots()\n    ax.imshow(data.astype(np.uint8))\n"], "sample_547": ["def test_auxtransformbox():\n    fig, ax = plt.subplots()\n    aux_transform = mtransforms.Affine2D().translate(10, 20)\n    box = AuxTransformBox(aux_transform)\n    box.add_artist(mpatches.Rectangle((0, 0), 5, 5))\n    ax.add_artist(box)\n    fig.canvas.draw()\n    assert not fig.stale\n"], "sample_548": ["def test_colorbar_set_label():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cb = fig.colorbar(im)\n    cb.set_label('Test Label')\n    assert cb.ax.get_ylabel() == 'Test Label'\n    cb.set_label(None)\n    assert cb.ax.get_ylabel() == ''\n    cb.set_label('Test Label 2')\n    assert cb.ax.get_ylabel() == 'Test Label 2'\n\n    cb2 = fig.colorbar(im, orientation='horizontal')\n    cb2.set_label('Test Label')\n    assert cb2.ax.get_xlabel() == 'Test Label'\n    cb2.set_label(None)\n    assert cb2.ax.get_xlabel() == ''\n    cb2.set_label('Test Label 2')\n    assert cb2.ax.get_xlabel() == 'Test Label 2'\n"], "sample_555": ["def test_arc_setters():\n    arc = Arc((0, 0), 1, 1)\n    assert arc.center == (0, 0)\n    assert arc.width == 1\n    assert arc.height == 1\n    assert arc.angle == 0\n\n    arc.set_center((1, 1))\n    arc.set_width(2)\n    arc.set_height(3)\n    arc.set_angle(45)\n\n    assert arc.center == (1, 1)\n    assert arc.width == 2\n    assert arc.height == 3\n    assert arc.angle == 45\n"], "sample_558": ["def test_grid_set_axes_locator():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 3))\n    locator = grid.get_axes_locator()\n    grid.set_axes_locator(locator)\n    assert grid.get_axes_locator() == locator\n"], "sample_560": ["def test_legend_set_bbox_to_anchor():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='line')\n    leg = ax.legend()\n\n    # Test setting bbox_to_anchor with a tuple\n    leg.set_bbox_to_anchor((0.5, 0.5))\n    assert leg.get_bbox_to_anchor().x0 == 0.5\n    assert leg.get_bbox_to_anchor().y0 == 0.5\n\n    # Test setting bbox_to_anchor with a BboxBase instance\n    bbox = mtransforms.Bbox.from_bounds(0.2, 0.2, 0.6, 0.6)\n    leg.set_bbox_to_anchor(bbox)\n    assert leg.get_bbox_to_anchor().bounds == (0.2, 0.2, 0.6, 0.6)\n\n    # Test setting bbox_to_anchor with None\n    leg.set_bbox_to_anchor(None)\n    assert leg.get_bbox_to_anchor() is None\n"], "sample_561": ["def test_marker_get_path():\n    marker = markers.MarkerStyle(\"o\")\n    path = marker.get_path()\n    assert isinstance(path, Path)\n    assert len(path.vertices) > 0\n\n    marker = markers.MarkerStyle(\"\")\n    path = marker.get_path()\n    assert isinstance(path, Path)\n    assert len(path.vertices) == 0\n"], "sample_563": ["def test_auxtransformbox():\n    # smoke test AuxTransformBox\n    fig, ax = plt.subplots()\n    atb = AuxTransformBox(mtransforms.Affine2D().rotate_deg(45))\n    atb.add_artist(TextArea(\"foo\"))\n    ax.add_artist(atb)\n    fig.draw_without_rendering()\n"], "sample_565": ["def test_inset_axes_locator():\n    fig, ax = plt.subplots()\n    inset_ax = inset_axes(ax, width=\"30%\", height=\"40%\")\n    assert isinstance(inset_ax.get_axes_locator(), AnchoredSizeLocator)\n    zoomed_ax = zoomed_inset_axes(ax, zoom=2.5)\n    assert isinstance(zoomed_ax.get_axes_locator(), AnchoredZoomLocator)\n"], "sample_567": ["def test_text_bbox():\n    fig, ax = plt.subplots()\n    text = ax.text(0.5, 0.5, 'test', bbox=dict(facecolor='red'))\n    fig.canvas.draw()\n    assert isinstance(text.get_bbox_patch(), mpatches.FancyBboxPatch)\n    text.set_bbox(None)\n    assert text.get_bbox_patch() is None\n"], "sample_570": ["    def test_units(self, long_df):\n\n        agg = EstimateAggregator(\"mean\")\n        out = agg(long_df, \"x\", units=\"cm\")\n        assert out[\"x\"] == long_df[\"x\"].mean()\n        assert out.attrs[\"units\"] == \"cm\"\n"], "sample_572": ["    def test_units(self, long_df):\n\n        agg = EstimateAggregator(\"mean\", \"ci\", n_boot=100000, seed=0)\n        out = agg(long_df, \"y\")\n        assert out.index.tolist() == [\"y\", \"ymin\", \"ymax\"]\n\n        long_df[\"units\"] = np.random.choice([\"A\", \"B\"], size=len(long_df))\n        out = agg(long_df, \"y\")\n        assert out.index.tolist() == [\"y\", \"ymin\", \"ymax\"]\n"], "sample_573": ["def test_insufficient_unique_x(self, df):\n\n    groupby = GroupBy([\"group\"])\n    df[\"x\"] = df[\"group\"]\n    res = PolyFit(order=2)(df, groupby, \"x\", {})\n\n    assert_array_equal(res.columns, [\"x\", \"y\", \"group\"])\n\n    for _, part in res.groupby(\"group\"):\n        assert part.empty\n"], "sample_578": ["def test_baseline(self, x, y):\n\n    baseline = 2\n    p = Plot(x, y).add(Bars(baseline=baseline)).plot()\n    ax = p._figure.axes[0]\n    paths = ax.collections[0].get_paths()\n    for i, path in enumerate(paths):\n        verts = path.vertices\n        assert verts[0, 1] == pytest.approx(baseline)\n        assert verts[3, 1] == pytest.approx(y[i] + baseline)\n"], "sample_579": ["def test_clustermap_cbar_kws(self):\n    kws = self.default_kws.copy()\n    cbar_kws = dict(shrink=0.5, aspect=10)\n    g = mat.clustermap(self.df_norm, cbar_kws=cbar_kws)\n    assert g.cax.get_position().height == 0.2 * 0.5\n    assert g.cax.get_aspect() == 10\n"], "sample_580": ["def test_variable_type_strict_boolean():\n\n    s = pd.Series([True, False, True], dtype=\"boolean\")\n    assert variable_type(s) == \"numeric\"\n    assert variable_type(s, boolean_type=\"boolean\") == \"boolean\"\n    assert variable_type(s, boolean_type=\"boolean\", strict_boolean=True) == \"boolean\"\n\n    s = pd.Series([1, 0, 1])\n    assert variable_type(s, boolean_type=\"boolean\") == \"boolean\"\n    assert variable_type(s, boolean_type=\"boolean\", strict_boolean=True) == \"numeric\"\n\n    s = pd.Series([True, False, True], dtype=\"object\")\n    assert variable_type(s, boolean_type=\"boolean\") == \"boolean\"\n    assert variable_type(s, boolean_type=\"boolean\", strict_boolean=True) == \"numeric\"\n"], "sample_582": ["def test_cli_group_name_collision(app):\n    \"\"\"Test that blueprints with the same CLI group name do not collide.\"\"\"\n    bp1 = Blueprint(\"bp1\", __name__, cli_group=\"group\")\n    bp2 = Blueprint(\"bp2\", __name__, cli_group=\"group\")\n\n    @bp1.cli.command(\"cmd\")\n        click.echo(\"cmd1\")\n\n    @bp2.cli.command(\"cmd\")\n        click.echo(\"cmd2\")\n\n    app.register_blueprint(bp1)\n    app.register_blueprint(bp2)\n\n    result = app.test_cli_runner().invoke(args=[\"group\", \"--help\"])\n    assert \"cmd\" in result.output\n    assert \"cmd1\" not in result.output\n    assert \"cmd2\" not in result.output\n\n    result = app.test_cli_runner().invoke(args=[\"group\", \"cmd\"])\n    assert result.exit_code == 2, f\"Unexpected success:\\n\\n{result.output}\"\n"], "sample_584": ["    def test_concat_along_new_dim_with_none(self):\n        objs = [Dataset({'a': ('x', [10]), 'x': [0]}),\n                Dataset({'a': ('x', [20]), 'x': [0]})]\n        expected = Dataset({'a': (('t', 'x'), [[10], [20]]), 'x': [0]})\n        actual = _combine_nd({(0,): objs[0], (1,): objs[1]}, concat_dims=['t'])\n        assert_identical(expected, actual)\n\n        # Same but with a DataArray as new dim, see GH #1988 and #2647\n        dim = DataArray([100, 150], name='baz', dims='baz')\n        expected = Dataset({'a': (('baz', 'x'), [[10], [20]]),\n                            'x': [0], 'baz': [100, 150]})\n        actual = _combine_nd({(0,): objs[0], (1,): objs[1]}, concat_dims=[dim])\n        assert_identical(expected, actual)\n"], "sample_585": ["def test_groupby_fillna():\n    # Test filling NaN values in grouped DataArray\n    array = xr.DataArray([1, 2, np.nan, 4, 5, np.nan],\n                         [('x', [1, 1, 1, 2, 2, 2])])\n\n    expected = xr.DataArray([1, 2, 0, 4, 5, 0], [('x', [1, 1, 1, 2, 2, 2])])\n    actual = array.groupby('x').fillna(0)\n    assert_identical(expected, actual)\n\n    # Test filling NaN values in grouped Dataset\n    dataset = xr.Dataset({'foo': ('x', [1, 2, np.nan, 4, 5, np.nan])},\n                         {'x': [1, 1, 1, 2, 2, 2]})\n\n    expected = xr.Dataset({'foo': ('x', [1, 2, 0, 4, 5, 0])},\n                          {'x': [1, 1, 1, 2, 2, 2]})\n    actual = dataset.groupby('x').fillna(0)\n    assert_identical(expected, actual)\n"], "sample_586": ["def test_concat_positions(self):\n    # Test that the positions argument works as expected\n    data = create_test_data()\n    split_data = [data.isel(dim1=slice(3)), data.isel(dim1=slice(3, None))]\n    positions = [[0, 1, 2], [3, 4, 5]]\n    actual = concat(split_data, \"dim1\", positions=positions)\n    assert_identical(data, actual)\n\n    # Test that incorrect positions raise an error\n    with raises_regex(ValueError, \"Length of positions does not match\"):\n        concat(split_data, \"dim1\", positions=[[0, 1], [3, 4, 5]])\n\n    # Test that positions work with a new dimension\n    actual = concat(split_data, \"new_dim\", positions=positions)\n    expected = Dataset()\n    for var in data.data_vars:\n        expected[var] = ((\"new_dim\",) + data[var].dims, np.concatenate([data[var].values, data[var].values]))\n    assert_identical(expected, actual)\n"], "sample_588": ["def test_combine_nested_with_empty_datasets(self):\n    objs = [[Dataset(), Dataset()], [Dataset(), Dataset()]]\n    actual = combine_nested(objs, concat_dim=[\"x\", \"y\"])\n    expected = Dataset()\n    assert_identical(expected, actual)\n"], "sample_589": ["def test_interpolate_na_max_gap_float(da):\n    da[\"x\"] = np.arange(len(da))\n    expected = da.copy(data=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n    actual = da.interpolate_na(\"x\", max_gap=2.0)\n    assert_equal(actual, expected)\n"], "sample_590": ["def test_concat_positions(self):\n    # Test that the positions argument works as expected\n    data = Dataset(\n        {\n            \"foo\": ([\"x\", \"y\"], np.random.random((2, 3))),\n            \"bar\": ([\"x\", \"y\"], np.random.random((2, 3))),\n        },\n        {\"x\": [0, 1]},\n    )\n    foo = data[\"foo\"]\n    bar = data[\"bar\"]\n\n    # Test with integer positions\n    actual = concat([foo, bar], dim=\"w\", positions=[0, 1])\n    expected = DataArray(\n        np.array([foo.values, bar.values]),\n        dims=[\"w\", \"x\", \"y\"],\n        coords={\"x\": [0, 1]},\n    )\n    assert_equal(expected, actual)\n\n    # Test with array-like positions\n    actual = concat([foo, bar], dim=\"w\", positions=np.array([0, 1]))\n    assert_equal(expected, actual)\n\n    # Test with list of integer arrays\n    actual = concat([foo, bar], dim=\"w\", positions=[[0], [1]])\n    assert_equal(expected, actual)\n\n    # Test with invalid positions\n    with raises_regex(ValueError, \"positions must be\"):\n        concat([foo, bar], dim=\"w\", positions=[0, 1, 2])\n\n    with raises_regex(ValueError, \"positions must be\"):\n        concat([foo, bar], dim=\"w\", positions=\"invalid\")\n"], "sample_592": ["def test_inline_variable_array_repr():\n    import dask.array as da\n\n    # Test with numpy array\n    var = xr.Variable((\"x\",), np.array([1, 2, 3]))\n    expected = \"[1 2 3]\"\n    actual = formatting.inline_variable_array_repr(var, 80)\n    assert expected == actual\n\n    # Test with dask array\n    var = xr.Variable((\"x\",), da.from_array(np.array([1, 2, 3]), chunks=2))\n    expected = \"dask.array<chunksize=(2,), meta='ndarray'>\"\n    actual = formatting.inline_variable_array_repr(var, 80)\n    assert expected == actual\n\n    # Test with sparse array\n    try:\n        import sparse\n\n        var = xr.Variable(\n            (\"x\",), sparse.COO(np.array([1, 2, 3]), fill_value=0, shape=(3,))\n        )\n        expected = \"<COO: nnz=3, fill_value=0>\"\n        actual = formatting.inline_variable_array_repr(var, 80)\n        assert expected == actual\n    except ImportError:\n        pass\n"], "sample_593": ["def test_collapsible_section():\n    name = \"Test Section\"\n    inline_details = \"Inline details\"\n    details = \"Detailed information\"\n    n_items = 5\n    enabled = True\n    collapsed = False\n\n    section = fh.collapsible_section(\n        name, inline_details, details, n_items, enabled, collapsed\n    )\n\n    assert f\"<input id='section-\" in section\n    assert f\"class='xr-section-summary-in' type='checkbox' {'checked' if not collapsed else ''}>\" in section\n    assert f\"<label for='section-\" in section\n    assert f\"class='xr-section-summary' title='Expand/collapse section'>{name}: <span>({n_items})</span></label>\" in section\n    assert f\"<div class='xr-section-inline-details'>{inline_details}</div>\" in section\n    assert f\"<div class='xr-section-details'>{details}</div>\" in section\n"], "sample_594": ["def test_limit_lines():\n    string = \"\\n\".join(str(i) for i in range(100))\n    expected = \"\\n\".join(\n        [\"0\", \"1\", \"2\", \"...\", \"97\", \"98\", \"99\"]\n    )\n    actual = formatting.limit_lines(string, limit=7)\n    assert actual == expected\n"], "sample_596": ["def test_concat_dim_coord_name_conflict():\n    ds1 = Dataset({\"x\": 0})\n    ds2 = Dataset({\"x\": 1})\n\n    # conflict between dim and coord name\n    with raises_regex(ValueError, \"coordinate 'x' has the same name as the new dimension\"):\n        concat([ds1, ds2], dim=\"x\")\n\n    # no conflict if the dim is not added as a coordinate\n    actual = concat([ds1, ds2], dim=\"x\", coords=\"minimal\")\n    expected = Dataset({\"x\": (\"x\", [0, 1])})\n    assert_identical(actual, expected)\n"], "sample_597": ["def test_merge_update(self):\n    ds1 = xr.Dataset({\"a\": 0})\n    ds2 = xr.Dataset({\"b\": 1})\n    expected = xr.Dataset({\"a\": 0, \"b\": 1})\n    assert expected.identical(ds1.merge(ds2))\n\n    ds1 = xr.Dataset({\"a\": 0, \"c\": 2})\n    ds2 = xr.Dataset({\"b\": 1, \"c\": 3})\n    expected = xr.Dataset({\"a\": 0, \"b\": 1, \"c\": 3})\n    assert expected.identical(ds1.merge(ds2))\n"], "sample_598": ["def test_short_data_repr():\n    array = np.random.randn(100, 5, 1)\n    data_array = xr.DataArray(array)\n\n    # Test that short_data_repr returns a short representation of the array\n    assert len(formatting.short_data_repr(data_array)) < 100\n\n    # Test that short_data_repr works with non-numeric arrays\n    array = np.array([\"hello\"] * 1000)\n    data_array = xr.DataArray(array)\n    assert len(formatting.short_data_repr(data_array)) < 100\n\n    # Test that short_data_repr works with arrays that have a _repr_inline_ method\n    class CustomArray:\n            self.value = value\n\n            return \"CustomArray\"\n\n    custom_array = CustomArray(np.array([1, 2, 3]))\n    data_array = xr.DataArray(custom_array)\n    assert formatting.short_data_repr(data_array) == \"CustomArray\"\n"], "sample_599": ["def test_UnsignedIntegerCoder_encode():\n    original = xr.Variable((\"x\",), np.array([0, 255], dtype=\"uint8))\n    original.encoding[\"_Unsigned\"] = \"true\"\n    coder = variables.UnsignedIntegerCoder()\n    encoded = coder.encode(original)\n    assert encoded.dtype == np.int8\n    assert \"_Unsigned\" not in encoded.encoding\n"], "sample_600": ["compilation error"], "sample_601": ["def test_cftime_strftime_accessor(cftime_rounding_dataarray, cftime_date_type):\n    date_format = \"%Y-%m-%d %H:%M:%S\"\n    expected = xr.DataArray(\n        [\n            [cftime_date_type(1, 1, 1, 1).strftime(date_format), cftime_date_type(1, 1, 1, 15).strftime(date_format)],\n            [cftime_date_type(1, 1, 1, 23).strftime(date_format), cftime_date_type(1, 1, 2, 1).strftime(date_format)],\n        ],\n        name=\"strftime\",\n    )\n\n    result = cftime_rounding_dataarray.dt.strftime(date_format)\n\n    assert_identical(result, expected)\n"], "sample_602": ["def test_open_dataset_invalid_engine():\n    with pytest.raises(ValueError):\n        xr.open_dataset(\"example.nc\", engine=\"invalid_engine\")\n"], "sample_603": ["def test_summarize_variable_with_unsafe_name_and_dtype():\n    var = xr.Variable([\"x\"], [1, 2, 3], {\"foo\": \"bar\"}, name=\"<unsafe_name>\")\n    formatted = fh.summarize_variable(\"<unsafe_name>\", var)\n    assert \"&lt;unsafe_name&gt;\" in formatted\n    assert \"int64\" in formatted\n\n    var = xr.Variable([\"x\"], [1.0, 2.0, 3.0], {\"foo\": \"bar\"}, name=\"safe_name\")\n    formatted = fh.summarize_variable(\"safe_name\", var, dtype=\"<unsafe_dtype>\")\n    assert \"safe_name\" in formatted\n    assert \"&lt;unsafe_dtype&gt;\" in formatted\n"], "sample_604": ["def test__calculate_col_width():\n    col_items = [\"short\", \"longer_column_name\"]\n    expected = len(\"longer_column_name\") + 6\n    actual = formatting._calculate_col_width(col_items)\n    assert actual == expected\n\n    col_items = []\n    expected = 7 + 6\n    actual = formatting._calculate_col_width(col_items)\n    assert actual == expected\n"], "sample_605": ["def test_groupby_fillna():\n    # Test filling NaN values in grouped DataArray\n    array = xr.DataArray(\n        [[1, 2, np.nan], [4, 5, 6], [np.nan, 8, 9]],\n        dims=[\"x\", \"y\"],\n        coords={\"x\": [1, 2, 3], \"y\": [1, 2, 3]},\n    )\n    filled_array = array.groupby(\"x\").fillna(0)\n    expected = xr.DataArray(\n        [[1, 2, 0], [4, 5, 6], [0, 8, 9]],\n        dims=[\"x\", \"y\"],\n        coords={\"x\": [1, 2, 3], \"y\": [1, 2, 3]},\n    )\n    assert_identical(filled_array, expected)\n\n    # Test filling NaN values in grouped Dataset\n    dataset = xr.Dataset()\n    dataset[\"a\"] = array\n    filled_dataset = dataset.groupby(\"x\").fillna(0)\n    expected_dataset = xr.Dataset()\n    expected_dataset[\"a\"] = expected\n    assert_identical(filled_dataset, expected_dataset)\n"], "sample_607": ["def test_get_backend_str():\n    backend = plugins.get_backend(\"dummy\")\n    assert isinstance(backend, DummyBackendEntrypoint1)\n\n"], "sample_608": ["def test__calculate_col_width() -> None:\n    col_items = [\"short\", \"longer_column_name\"]\n    expected = len(\"longer_column_name\") + 6\n    actual = formatting._calculate_col_width(col_items)\n    assert expected == actual\n\n    col_items = []\n    expected = 7\n    actual = formatting._calculate_col_width(col_items)\n    assert expected == actual\n"], "sample_609": ["def test_unify_chunks() -> None:\n    da1 = xr.DataArray(np.arange(10), dims=\"x\", chunks=5)\n    da2 = xr.DataArray(np.arange(10), dims=\"x\", chunks=2)\n\n    da1_unified, da2_unified = unify_chunks(da1, da2)\n\n    assert da1_unified.chunks == ((2, 2, 2, 2, 2),)\n    assert da2_unified.chunks == ((2, 2, 2, 2, 2),)\n"], "sample_610": ["def test_cftimeindex_repr_empty():\n    index = xr.CFTimeIndex([])\n    expected = \"CFTimeIndex([], dtype='object', length=0, calendar=None, freq=None)\"\n    assert repr(index) == expected\n"], "sample_611": ["def test_date_range_like_invalid_calendar():\n    src = date_range(\"2000-01-01\", periods=12, freq=\"D\")\n    with pytest.raises(ValueError, match=\"Invalid calendar\"):\n        date_range_like(src, \"invalid_calendar\")\n"], "sample_612": ["def test_groupby_dataset_map_dataarray_func_with_kwargs():\n    # regression GH6379\n    ds = xr.Dataset({\"foo\": (\"x\", [1, 2, 3, 4])}, coords={\"x\": [0, 0, 1, 1]})\n    actual = ds.groupby(\"x\").map(lambda grp: grp.foo.mean(), dim=\"x\")\n    expected = xr.DataArray([1.5, 3.5], coords={\"x\": [0, 1]}, dims=\"x\", name=\"foo\")\n    assert_identical(actual, expected)\n"], "sample_613": ["def test_groupby_map_blocks(self):\n    array = self.da\n    # Test multiple blocks along a single dimension\n    blocks = [array.isel(x=slice(0, 2)), array.isel(x=slice(2, None))]\n    expected = xr.concat([b.groupby(\"abc\").mean(...) for b in blocks], dim=\"x\")\n    actual = array.groupby(\"abc\").map_blocks(np.mean)\n    assert_identical(expected, actual)\n\n    # Test a single block along multiple dimensions\n    blocks = [\n        array.isel(x=slice(0, 2), y=slice(0, 3)),\n        array.isel(x=slice(0, 2), y=slice(3, None)),\n        array.isel(x=slice(2, None), y=slice(0, 3)),\n        array.isel(x=slice(2, None), y=slice(3, None)),\n    ]\n    expected = xr.concat(\n        [\n            xr.concat([blocks[0], blocks[1]], dim=\"y\"),\n            xr.concat([blocks[2], blocks[3]], dim=\"y\"),\n        ],\n        dim=\"x\",\n    ).groupby(\"abc\").mean(...)\n    actual = array.groupby(\"abc\").map_blocks(np.mean, chunks={\"x\": 2, \"y\": 3})\n    assert_identical(expected, actual)\n"], "sample_614": ["def test__calculate_col_width() -> None:\n    cases = [\n        ([\"short\"], 7),\n        ([\"longer_name\"], 11),\n        ([\"short\", \"longer_name\"], 11),\n        ([\"a\" * 50], 50 + 6),\n        ([], 7),\n    ]\n    for col_items, expected in cases:\n        actual = formatting._calculate_col_width(col_items)\n        assert actual == expected\n"], "sample_619": ["def test_encode_cf_datetime_with_cftime_timezone() -> None:\n    import cftime\n\n    calendar = \"gregorian\"\n    times = cftime.num2date([0, 1], \"hours since 2000-01-01\", calendar)\n    units = \"days since 2000-01-01T00:00:00-05:00\"\n\n    encoded, _, _ = encode_cf_datetime(times, units, calendar)\n\n    expected = cftime.date2num(times, units, calendar)\n    np.testing.assert_equal(encoded, expected)\n"], "sample_620": ["def test_concat_positions() -> None:\n    # Test that the positions argument is used correctly\n    ds1 = Dataset(coords={\"x\": (\"x\", [1, 2])})\n    ds2 = Dataset(coords={\"x\": (\"x\", [3, 4])})\n\n    # Test with integer positions\n    actual = concat([ds1, ds2], dim=\"x\", positions=[[0, 1], [2, 3]])\n    expected = Dataset(coords={\"x\": (\"x\", [1, 2, 3, 4])})\n    assert_identical(actual, expected)\n\n    # Test with array-like positions\n    actual = concat([ds1, ds2], dim=\"x\", positions=[np.array([0, 1]), np.array([2, 3])])\n    assert_identical(actual, expected)\n\n    # Test with incorrect positions\n    with pytest.raises(ValueError, match=r\"positions must be a list of integer arrays\"):\n        concat([ds1, ds2], dim=\"x\", positions=[[\"a\", \"b\"], [\"c\", \"d\"]])\n\n    # Test with positions that are not the same length as the datasets\n    with pytest.raises(\n        ValueError, match=r\"Length of positions does not match length of datasets\"\n    ):\n        concat([ds1, ds2], dim=\"x\", positions=[[0, 1], [2]])\n\n    # Test with positions that are not unique\n    with pytest.raises(ValueError, match=r\"Positions must be unique\"):\n        concat([ds1, ds2], dim=\"x\", positions=[[0, 1], [1, 2]])\n"], "sample_622": ["def test_decode_cf_variable_with_invalid_units() -> None:\n    v = Variable([\"t\"], [1, 2, 3], {\"units\": \" invalid units\"})\n    with pytest.raises(ValueError, match=\"Failed to decode variable 'test'\"):\n        conventions.decode_cf_variable(\"test\", v)\n"], "sample_623": ["def test_open_dataset_chunks_auto() -> None:\n    \"\"\"Test that open_dataset with chunks='auto' works correctly.\"\"\"\n    # Create a sample dataset\n    ds = xr.Dataset()\n    ds[\"x\"] = xr.DataArray(np.arange(100), dims=[\"x\"])\n\n    # Open the dataset with chunks='auto'\n    with assert_no_warnings():\n        ds_auto = xr.open_dataset(ds, engine=PassThroughBackendEntrypoint, chunks=\"auto\")\n\n    # Check that the chunks were automatically determined\n    assert ds_auto[\"x\"].chunks == ((100,),)\n"], "sample_627": ["def test_concat_positions() -> None:\n    # Test that the positions argument works as expected\n    ds1 = Dataset(coords={\"x\": (\"x\", [1, 2])})\n    ds2 = Dataset(coords={\"x\": (\"x\", [3, 4])})\n\n    # Test with integer positions\n    actual = concat([ds1, ds2], dim=\"x\", positions=[[0, 1], [2, 3]])\n    expected = Dataset(coords={\"x\": (\"x\", [1, 2, 3, 4])})\n    assert_identical(actual, expected)\n\n    # Test with list of integer arrays\n    actual = concat([ds1, ds2], dim=\"x\", positions=[np.array([0, 1]), np.array([2, 3])])\n    assert_identical(actual, expected)\n\n    # Test with invalid positions\n    with pytest.raises(ValueError, match=r\"positions must be a list of lists or arrays\"):\n        concat([ds1, ds2], dim=\"x\", positions=[0, 1])\n\n    with pytest.raises(ValueError, match=r\"positions must have the same length as objects\"):\n        concat([ds1, ds2], dim=\"x\", positions=[[0, 1]])\n\n    with pytest.raises(ValueError, match=r\"positions must have the same length as objects\"):\n        concat([ds1, ds2], dim=\"x\", positions=[[0, 1], [2]])\n\n    with pytest.raises(ValueError, match=r\"positions must be integers\"):\n        concat([ds1, ds2], dim=\"x\", positions=[[0.5, 1], [2, 3]])\n"], "sample_628": ["def test_words_with_apostrophes(self):\n    stmt = astroid.extract_node(\n        '''def f():\n    \"\"\"\n    it's a mistake\n    \"\"\"'''\n    )\n    with self.assertAddsMessages(\n        Message(\n            \"wrong-spelling-in-docstring\",\n            line=3,\n            args=(\n                \"mistake\",\n                \"    it's a mistake\",\n                \"          ^^^^^^^\",\n                self._get_msg_suggestions(\"mistake\"),\n            ),\n        )\n    ):\n        self.checker.visit_functiondef(stmt)\n"], "sample_629": ["def test_expand_modules_with_ignore_list(files_or_modules, ignore_list, expected):\n    ignore_list_re, ignore_list_paths_re = [], []\n    modules, errors = expand_modules(\n        files_or_modules, ignore_list, ignore_list_re, ignore_list_paths_re\n    )\n    modules.sort(key=lambda d: d[\"name\"])\n    assert modules == expected\n    assert not errors\n"], "sample_630": ["def test_get_annotation_label(func, expected):\n    \"\"\"Test get_annotation_label function\"\"\"\n    node = astroid.extract_node(func)\n    got = get_annotation_label(node.returns)\n    assert got == expected, f\"got {got} instead of {expected} for value {node}\"\n"], "sample_633": ["def test_set_duplicate_lines_to_negative() -> None:\n    output = StringIO()\n    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n        similar.Run([\"--duplicates=-1\", SIMILAR1, SIMILAR2])\n    assert ex.value.code == 0\n    assert (\n        output.getvalue().strip()\n        == \"\"\""], "sample_634": ["    def test_expand_modules_with_errors(self, files_or_modules, ignore_list, expected):\n        \"\"\"Test expand_modules with errors\"\"\"\n        ignore_list_re = []\n        modules, errors = expand_modules(\n            files_or_modules,\n            ignore_list,\n            ignore_list_re,\n            get_global_option(self, \"ignore-paths\"),\n        )\n        assert not modules\n        for error in expected:\n            assert any(\n                all(key in e and e[key] == value for key, value in error.items())\n                for e in errors\n            )\n"], "sample_635": ["def test_numpy_docstring_with_multiple_types(self) -> None:\n    \"\"\"Example of a function with multiple types in the Numpy style docstring\"\"\"\n    node = astroid.extract_node(\n        \"\"\"\n        '''function foo ...\n\n        Parameters\n        ----------\n        x : int or float\n            bla\n        y : list[str] or tuple[int]\n            bar\n\n        Returns\n        -------\n        str or None\n            baz\n        '''\n        return x + y\n    \"\"\"\n    )\n    with self.assertNoMessages():\n        self.checker.visit_functiondef(node)\n"], "sample_637": ["def test_fixme_pattern_with_notes_rgx(self) -> None:\n    code = \"\"\"a = 1\n            # FIXME message\n            \"\"\"\n    set_config(notes_rgx=\"FIXME|TODO\")\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"fixme\", line=2, args=\"FIXME message\", col_offset=17)\n    ):\n        self.checker.open()\n        self.checker.process_tokens(_tokenize_str(code))\n"], "sample_638": ["def test_run_without_args(mock_writer, capsys):\n    \"\"\"Test that running pyreverse without arguments shows the help message.\"\"\"\n    with pytest.raises(SystemExit) as wrapped_sysexit:\n        main.Run([])\n    # Check that the right info message is shown to the user\n    assert \"Usage:\" in capsys.readouterr().out\n    # Check that we exited with the expected error code\n    assert wrapped_sysexit.value.code == 1\n    # Check that no diagram was created\n    mock_writer.DiagramWriter().write.assert_not_called()\n"], "sample_639": ["def test_base_checker_get_full_documentation() -> None:\n    \"\"\"Test the get_full_documentation method of BaseChecker.\"\"\"\n    checker = OtherBasicChecker()\n    expected_doc = \"\"\"\\"], "sample_641": ["def test_load_result_file_does_not_exist(path: str) -> None:\n    assert load_results(path) is None\n"], "sample_642": ["def test_preprocess_options() -> None:\n    \"\"\"Test that pre-processable options are correctly handled.\"\"\"\n    run = Run([\"--init-hook\", \"import os\", \"--rcfile\", \"path/to/rcfile\"])\n    processed_args = _preprocess_options(run, [\"--init-hook=import os\", \"--rcfile=path/to/rcfile\"])\n    assert processed_args == []\n    assert run._rcfile == \"path/to/rcfile\"\n"], "sample_643": ["def test_colorized_text_reporter_output() -> None:\n    \"\"\"Test the output of the ColorizedTextReporter.\"\"\"\n    output = StringIO()\n    reporter = ColorizedTextReporter(output)\n    message = Message(\n        symbol=\"missing-docstring\",\n        msg_id=\"C0123\",\n        location=MessageLocationTuple(\"abspath\", \"path\", \"module\", \"obj\", 1, 2, 1, 3),\n        msg=\"Missing docstring\",\n        confidence=HIGH,\n    )\n    reporter.handle_message(message)\n    assert \"\\033[\" in output.getvalue()\n    assert \"Missing docstring\" in output.getvalue()\n"], "sample_645": ["def test_percent_style_multiline_auto_indent(caplog):\n    caplog.set_level(logging.INFO)\n    logger.info(\"boo\\n%s\", \"arg\")\n    assert \"boo\" in caplog.text\n    assert \"arg\" in caplog.text\n\n    # Test auto-indent is on by default.\n    lines = caplog.text.splitlines()\n    indentation = len(lines[1]) - len(lines[1].lstrip())\n    assert indentation > 0\n\n    # Test explicit auto-indent off.\n    caplog.clear()\n    logger.info(\"boo\\n%s\", \"arg\", extra={\"auto_indent\": False})\n    lines = caplog.text.splitlines()\n    indentation = len(lines[1]) - len(lines[1].lstrip())\n    assert indentation == 0\n\n    # Test explicit auto-indent on.\n    caplog.clear()\n    logger.info(\"boo\\n%s\", \"arg\", extra={\"auto_indent\": True})\n    lines = caplog.text.splitlines()\n    indentation = len(lines[1]) - len(lines[1].lstrip())\n    assert indentation > 0\n\n    # Test explicit fixed auto-indent.\n    caplog.clear()\n    logger.info(\"boo\\n%s\", \"arg\", extra={\"auto_indent\": 10})\n    lines = caplog.text.splitlines()\n    indentation = len(lines[1]) - len(lines[1].lstrip())\n    assert indentation == 10\n"], "sample_646": ["def test_unittest_subtest(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n\n        class TestIt(unittest.TestCase):\n                for i in range(5):\n                    with self.subTest(i=i):\n                        if i == 3:\n                            assert False\n                        else:\n                            assert True\n        \"\"\"\n    )\n    reprec = pytester.inline_run()\n    passed, skipped, failed = reprec.countoutcomes()\n    assert passed == 1\n    assert failed == 1\n    assert reprec.ret == 1\n"], "sample_647": ["def test_warning_types_messages(warning_class: type, expected_message: str) -> None:\n    \"\"\"Test the messages of warnings declared in _pytest.warning_types.\"\"\"\n    if warning_class == warning_types.PytestExperimentalApiWarning:\n        warning = warning_class.simple(\"some_api\")\n    else:\n        warning = warning_class(\"some message\")\n    assert str(warning) == expected_message\n"], "sample_648": ["def test_get_empty_parameterset_mark_reason(pytester: Pytester) -> None:\n    config = pytester.parseconfig()\n    from _pytest.mark import get_empty_parameterset_mark\n\n    mark = get_empty_parameterset_mark(config, [\"a\", \"b\"], lambda: None)\n    assert mark.kwargs[\"reason\"] == \"got empty parameter set ['a', 'b'], function <lambda> at {}:{}\".format(\n        __file__, get_empty_parameterset_mark.__code__.co_firstlineno + 1\n    )\n"], "sample_649": ["def test_log_file_cli_level_overrides_ini(pytester: Pytester) -> None:\n    log_file = str(pytester.path.joinpath(\"pytest.log\"))\n\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level=WARNING\n        \"\"\".format(\n            log_file\n        )\n    )\n\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_file_handler.level == logging.INFO\n            logging.getLogger('catchlog').debug(\"This log message won't be shown\")\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n\n    result = pytester.runpytest(\"-s\", f\"--log-file={log_file}\", \"--log-file-level=INFO\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines([\"test_log_file_cli_level_overrides_ini.py PASSED\"])\n\n    # make sure that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert \"This log message will be shown\" in contents\n        assert \"This log message won't be shown\" not in contents\n"], "sample_650": ["def test_log_file_formatting(pytester: Pytester) -> None:\n    \"\"\"Check that log_file_format affects output.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n\n        logger = logging.getLogger(__name__)\n\n            logger.warning('text')\n            assert False\n        \"\"\"\n    )\n    log_file = str(pytester.path.joinpath(\"pytest.log\"))\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_format=%(asctime)s; %(levelname)s; %(message)s\n        log_file_date_format=%Y-%m-%d %H:%M:%S\n    \"\"\".format(\n            log_file\n        )\n    )\n    result = pytester.runpytest()\n    assert result.ret == 1\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert re.match(r\"^[0-9-]{10} [0-9:]{8}; WARNING; text\", contents)\n"], "sample_651": ["def test_warns_context_manager_with_match_and_kwargs(self) -> None:\n    with pytest.raises(TypeError) as excinfo:\n        with pytest.warns(UserWarning, match=\"foo\", foo=\"bar\"):  # type: ignore\n            pass\n    assert \"Unexpected keyword arguments\" in str(excinfo.value)\n"], "sample_652": ["def test_fixture_scope_overrides_parametrize_scope(testdir):\n    \"\"\"Test that a fixture's scope can override the scope of a parametrize call (#517).\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture(scope=\"module\", params=[1, 2])\n            return request.param\n\n        @pytest.mark.parametrize(\"arg\", [10, 20], scope=\"function\")\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"* 4 passed in *\"])\n"], "sample_653": ["def test_log_file_format(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        log_file_format = %(asctime)s %(levelname)s %(message)s\n        log_file_date_format = %Y-%m-%d %H:%M:%S\n        \"\"\".format(\n            log_file\n        )\n    )\n\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logging.getLogger().info(\"Normal message\")\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file, encoding=\"utf-8\") as rfh:\n        contents = rfh.read()\n        assert re.match(r\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} INFO Normal message\", contents)\n"], "sample_655": ["def test_capturing_with_keyboard_interrupt(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import sys\n            print('hello')\n            raise KeyboardInterrupt()\n        \"\"\"\n    )\n    result = testdir.runpytest(p)\n    result.stdout.fnmatch_lines([\"*KeyboardInterrupt*\"])\n    assert result.ret == 2\n"], "sample_656": ["def test_capturing_with_keyboard_interrupt(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import sys\n            print('hello')\n            raise KeyboardInterrupt()\n        \"\"\"\n    )\n    result = testdir.runpytest(p)\n    result.stdout.fnmatch_lines([\"*KeyboardInterrupt*\", \"*hello*\"])\n"], "sample_657": ["def test_mark_decorator_with_multiple_args(testdir):\n    \"\"\"Test that a mark decorator with multiple arguments is applied correctly.\"\"\"\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.foo('bar', 'baz')\n            pass\n    \"\"\"\n    )\n    items, rec = testdir.inline_genitems(p)\n    assert len(items) == 1\n    item = items[0]\n    markers = list(item.iter_markers(name='foo'))\n    assert len(markers) == 1\n    marker = markers[0]\n    assert marker.args == ('bar', 'baz')\n"], "sample_658": ["def test_doctest_namespace_isolation(self, testdir):\n    \"\"\"\n    Check that doctest_namespace is isolated between tests.\n    \"\"\"\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture(autouse=True)\n            doctest_namespace['foo'] = 'bar'\n    \"\"\"\n    )\n    p1 = testdir.maketxtfile(\n        test_doc1=\"\"\"\n        >>> foo\n        'bar'\n        >>> foo = 'baz'\n        >>> foo\n        'baz'\n    \"\"\"\n    )\n    p2 = testdir.maketxtfile(\n        test_doc2=\"\"\"\n        >>> foo\n        'bar'\n    \"\"\"\n    )\n    reprec = testdir.inline_run(p1, p2)\n    reprec.assertoutcome(passed=2)\n"], "sample_660": ["def test_log_passing_tests_enabled_logs_test_output(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        junit_log_passing_tests=True\n        junit_logging=system-out\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n        import sys\n\n            sys.stdout.write('This is stdout')\n            sys.stderr.write('This is stderr')\n            logging.warning('hello')\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testcase\")\n    assert len(node.find_by_tag(\"system-err\")) == 1\n    assert len(node.find_by_tag(\"system-out\")) == 1\n"], "sample_661": ["def test_escaped_systemout_issue3533(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n            print('1 <> 2')\n            assert False\n    \"\"\"\n    )\n    _, dom = runandparse(testdir)\n    node = dom.find_first_by_tag(\"testcase\")\n    snode = node.find_first_by_tag(\"system-out\")\n    assert \"1 <> 2\" in snode.text\n"], "sample_663": ["def test_collect_with_broken_conftest(testdir):\n    \"\"\"Check that a broken conftest.py does not prevent collection of tests (#4752).\"\"\"\n    sub = testdir.mkdir(\"sub\")\n    sub.ensure(\"conftest.py\").write(\"assert 0, 'broken conftest'\")\n    sub.ensure(\"test_file.py\").write(\"def test_file(): pass\")\n\n    result = testdir.runpytest(\"-v\", str(sub))\n    result.stdout.fnmatch_lines(\n        [\n            \"*ERROR collecting sub/test_file.py*\",\n            \"*conftest.py:1: AssertionError: broken conftest*\",\n            \"*1 error in *\",\n        ]\n    )\n"], "sample_664": ["def test_fixture_positional_arguments_warning(pytestconfig):\n    \"\"\"Check that passing arguments to pytest.fixture() as positional arguments raises a warning\"\"\"\n    with pytest.warns(deprecated.FIXTURE_POSITIONAL_ARGUMENTS):\n        pytest.fixture(autouse=True)\n"], "sample_665": ["def test_collect_with_import_prefix(testdir):\n    \"\"\"Test that collect works with import prefixes (#4668).\"\"\"\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        python_files = tests/*.py\n        python_functions = *_test\n    \"\"\"\n    )\n    testdir.mkdir(\"tests\")\n    testdir.makepyfile(\n        tests=\"\"\"\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"*1 passed in*\"])\n"], "sample_666": ["def test_percent_style_multiline_auto_indent(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logging.warning(\"hello\\\\n  world\")\n            assert False\n        \"\"\"\n    )\n    result = testdir.runpytest_subprocess(p, \"--log-auto-indent\", \"True\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_*.py F*\",\n            \"====* FAILURES *====\",\n            \"____*____\",\n            \"*--- Captured log call*\",\n            \"WARNING * hello\",\n            \"  world\",\n            \"*1 failed*\",\n        ]\n    )\n"], "sample_667": ["def test_tmp_path_factory_cleanup(tmp_path_factory, tmp_path):\n    \"\"\"Test that the tmp_path_factory cleans up after itself.\"\"\"\n    # Create a new temporary directory using the factory\n    new_tmp_path = tmp_path_factory.mktemp(\"new_tmp_path\")\n\n    # Check that the new directory exists\n    assert new_tmp_path.exists()\n\n    # Check that the new directory is a subdirectory of the base temporary directory\n    assert new_tmp_path.parent == tmp_path_factory.getbasetemp()\n\n    # Clean up the temporary directory\n    tmp_path_factory._basetemp = None\n\n    # Check that the new directory has been cleaned up\n    assert not new_tmp_path.exists()\n"], "sample_668": ["def test_fixture_positional_arguments_warning():\n    with pytest.warns(\n        PytestDeprecationWarning,\n        match=\"Passing arguments to pytest.fixture\\\\(\\\\) as positional arguments is deprecated - pass them as a keyword argument instead.\",\n    ):\n        pytest.fixture(autouse=True)\n"], "sample_669": ["def test_capture_manager_is_globally_capturing():\n    capman = CaptureManager(\"fd\")\n    assert not capman.is_globally_capturing()\n    capman.start_global_capturing()\n    assert capman.is_globally_capturing()\n    capman.stop_global_capturing()\n    assert not capman.is_globally_capturing()\n"], "sample_670": ["def test_matcher(expr: str, matcher: Callable[[str], bool], expected: bool) -> None:\n    assert evaluate(expr, matcher) is expected\n"], "sample_671": ["def test_xfail_strict_with_multiple_conditions(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(\"True or False\", reason=\"Expected failure\", strict=True)\n            assert 1\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxX\")\n    result.stdout.fnmatch_lines([\"*XPASS(strict)*Expected failure*\"])\n"], "sample_672": ["def test_saferepr_with_recursive_data_structure():\n    \"\"\"Test saferepr() with recursive data structures.\"\"\"\n\n    class Node:\n            self.value = value\n            self.children = []\n\n    node1 = Node(1)\n    node2 = Node(2)\n    node3 = Node(3)\n\n    node1.children.append(node2)\n    node2.children.append(node3)\n    node3.children.append(node1)  # Create a cycle\n\n    repr_node1 = saferepr(node1)\n    assert \"Node\" in repr_node1\n    assert \"value=1\" in repr_node1\n    assert \"children=[...]\" in repr_node1  # Check for ellipsis\n"], "sample_673": ["def test_doctest_namespace_isolation(self, testdir):\n    \"\"\"\n    Check that each doctest has its own namespace.\n    \"\"\"\n    testdir.makepyfile(\n        \"\"\"\n            '''\n            >>> x = 1\n            >>> x\n            1\n            '''\n            '''\n            >>> x\n            Traceback (most recent call last):\n            NameError: name 'x' is not defined\n            '''\n        \"\"\"\n    )\n    result = testdir.runpytest(\"--doctest-modules\")\n    result.stdout.fnmatch_lines([\"* 2 passed *\"])\n"], "sample_674": ["def test_get_fslocation_from_item():\n    class FakeItem:\n            self.location = location\n            self.obj = obj\n            self.fspath = fspath\n\n    item = FakeItem(location=(\"path/to/file.py\", 10))\n    assert nodes.get_fslocation_from_item(item) == (\"path/to/file.py\", 10)\n\n    item = FakeItem(obj=\"some_object\")\n    with pytest.raises(TypeError, match=\".*has no attribute '__code__'\"):\n        nodes.get_fslocation_from_item(item)\n\n    item = FakeItem(fspath=\"path/to/file.py\")\n    assert nodes.get_fslocation_from_item(item) == (\"path/to/file.py\", -1)\n"], "sample_676": ["def test_terminal_summary_warnings_are_displayed_with_quiet_flag(testdir):\n    \"\"\"Test that warnings emitted during pytest_terminal_summary are displayed even with the -q flag.\"\"\"\n    testdir.makeconftest(\n        \"\"\"\n        import warnings\n            warnings.warn(UserWarning('internal warning'))\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n            import warnings\n            warnings.warn(\"warning_from_\" + \"test\")\n            assert 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-q\", \"-ra\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*= warnings summary =*\",\n            \"*warning_from_test*\",\n            \"*= short test summary info =*\",\n            \"*= warnings summary (final) =*\",\n            \"*conftest.py:3:*internal warning\",\n            \"*== 1 failed, 2 warnings in *\",\n        ]\n    )\n    assert \"None\" not in result.stdout.str()\n    stdout = result.stdout.str()\n    assert stdout.count(\"warning_from_test\") == 1\n    assert stdout.count(\"=== warnings summary \") == 2\n"], "sample_677": ["def test_matcher_adapter() -> None:\n    matcher = {\"foo\": True, \"bar\": False}.__getitem__\n    adapter = MatcherAdapter(matcher)\n    assert adapter[\"$foo\"] is True\n    assert adapter[\"$bar\"] is False\n    with pytest.raises(KeyError):\n        adapter[\"$baz\"]\n"], "sample_678": ["def test_cleanup_candidates(tmp_path):\n    \"\"\"Test that cleanup_candidates returns the correct directories to be removed.\"\"\"\n    root = tmp_path / \"root\"\n    root.mkdir()\n    for i in range(10):\n        (root / f\"prefix{i}\").mkdir()\n\n    candidates = list(cleanup_candidates(root, \"prefix\", 5))\n    assert len(candidates) == 5\n    for candidate in candidates:\n        assert candidate.name.startswith(\"prefix\")\n        assert int(candidate.name[6:]) < 5\n"], "sample_679": ["def test_mark_evaluator_get_closest_marker():\n    item = mock.Mock(spec=Item)\n    item.keywords = [\"mark1\", \"mark2\"]\n    item.own_markers = [Mark(\"mark1\", (), {}), Mark(\"mark2\", (), {})]\n    evaluator = MarkEvaluator(item, \"mark1\")\n    assert evaluator.get_closest_marker(\"mark1\") == item.own_markers[0]\n    assert evaluator.get_closest_marker(\"mark2\") == item.own_markers[1]\n    assert evaluator.get_closest_marker(\"mark3\") is None\n"], "sample_680": ["def test_xfail_strict_ini(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = True\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n            assert 1\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n"], "sample_681": ["def test_log_file_cli_subdirectories_with_absolute_path_are_successfully_created(testdir):\n    path = testdir.makepyfile(\"\"\" def test_logger(): pass \"\"\")\n    expected = os.path.join(os.path.dirname(str(path)), \"foo\", \"bar\")\n    result = testdir.runpytest(\"--log-file={}/logf.log\".format(os.path.abspath(expected)))\n    assert \"logf.log\" in os.listdir(expected)\n    assert result.ret == ExitCode.OK\n"], "sample_682": ["def test_xfail_strict_with_multiple_conditions(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(strict=True, condition=\"True or False\")\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxX\")\n    result.stdout.fnmatch_lines([\"*XPASS(strict)*\"])\n"], "sample_685": ["def test_log_file(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n\n            logger = logging.getLogger('catchlog')\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_file_level == logging.WARNING\n\n            logger.info(\"INFO message won't be shown\")\n\n            logger.warning(\"WARNING message will be shown\")\n            logger.error(\"ERROR message will be shown\")\n\n            assert 'INFO' not in caplog.text\n            assert 'WARNING' in caplog.text\n            assert 'ERROR' in caplog.text\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file=pytest.log\n        log_file_level=WARNING\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n\n    with open(\"pytest.log\") as f:\n        log_content = f.read()\n\n    assert \"INFO\" not in log_content\n    assert \"WARNING\" in log_content\n    assert \"ERROR\" in log_content\n"], "sample_686": ["def test_fixture_positional_arguments_warning() -> None:\n    with pytest.warns(\n        pytest.PytestDeprecationWarning,\n        match=\"Passing arguments to pytest.fixture\\\\(\\\\) as positional arguments is deprecated\",\n    ):\n        pytest.fixture(autouse=True)\n"], "sample_689": ["def test_warning_captured_hook_is_deprecated() -> None:\n    with pytest.warns(\n        pytest.PytestDeprecationWarning,\n        match=re.escape(\n            \"The pytest_warning_captured is deprecated and will be removed in a future release.\\n\"\n            \"Please use pytest_warning_recorded instead.\"\n        ),\n    ):\n        warnings.warn(deprecated.WARNING_CAPTURED_HOOK)\n"], "sample_690": ["def test_xfail_strict_ini(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = True\n    \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n"], "sample_691": ["def test_unconfigure(pytester: Pytester, monkeypatch) -> None:\n    \"\"\"Test that faulthandler is properly unconfigured after pytest finishes.\"\"\"\n    import faulthandler\n    from _pytest.faulthandler import FaultHandlerHooks\n\n    called = []\n\n    monkeypatch.setattr(faulthandler, \"disable\", lambda: called.append(1))\n    monkeypatch.setattr(\n        FaultHandlerHooks, \"_get_stderr_fileno\", lambda self: sys.__stderr__.fileno()\n    )\n\n    pytester.makepyfile(\"def test_pass(): pass\")\n    result = pytester.runpytest_subprocess()\n    assert result.ret == 0\n\n    assert called == [1]\n"], "sample_692": ["def test_tmp_path_factory_handles_lock_timeout(\n    tmp_path_factory: TempPathFactory, monkeypatch: MonkeyPatch"], "sample_693": ["def test_unittest_subtest(pytester: Pytester) -> None:\n    pytest.importorskip(\"unittest.subTest\")\n\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n\n        class MyTestCase(unittest.TestCase):\n                for i in range(5):\n                    with self.subTest(i=i):\n                        self.assertEqual(i % 2, 0)\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*3 failed*\"])\n"], "sample_695": ["def test_node_repr_failure_with_conftest_import_failure(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n            raise Exception(\"Something went wrong\")\n    \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    items = pytester.getitems()\n    excinfo = pytest.raises(Exception, items[0].runtest)\n    rep = items[0].repr_failure(excinfo)\n    assert \"ConftestImportFailure\" in str(rep)\n    assert \"Exception: Something went wrong\" in str(rep)\n"], "sample_696": ["def test_argument_percent_default_is_deprecated() -> None:\n    with pytest.warns(\n        pytest.PytestDeprecationWarning,\n        match=r\"pytest now uses argparse. %default should be changed to %(default)s\",\n    ):\n        pytest.deprecated.ARGUMENT_PERCENT_DEFAULT\n"], "sample_697": ["def test_tmp_path_factory_uses_given_basetemp(tmp_path_factory: TempPathFactory, tmp_path: Path) -> None:\n    given_basetemp = tmp_path / \"given-basetemp\"\n    tmp_path_factory = TempPathFactory(given_basetemp, lambda *args: None, _ispytest=True)\n    basetemp = tmp_path_factory.getbasetemp()\n    assert basetemp == given_basetemp\n    assert basetemp.exists()\n"], "sample_698": ["def test_get_option_ini() -> None:\n    from _pytest.logging import get_option_ini\n\n    class Config:\n            if name == \"log_format\":\n                return \"%(levelname)s %(message)s\"\n            return None\n\n            if name == \"log_date_format\":\n                return \"%Y-%m-%d\"\n            return None\n\n    config = Config()\n    assert get_option_ini(config, \"log_format\") == \"%(levelname)s %(message)s\"\n    assert get_option_ini(config, \"log_date_format\") == \"%Y-%m-%d\"\n    assert get_option_ini(config, \"non_existent_option\") is None\n"], "sample_699": ["def test_doctest_namespace_isolation(self, pytester: Pytester) -> None:\n    \"\"\"Test that doctest_namespace is isolated between tests.\"\"\"\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture(autouse=True)\n            doctest_namespace['x'] = 1\n        \"\"\"\n    )\n    pytester.maketxtfile(\n        test_doc1=\"\"\"\n        >>> x\n        1\n        >>> x = 2\n        \"\"\",\n        test_doc2=\"\"\"\n        >>> x\n        1\n        \"\"\",\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=2)\n"], "sample_700": ["def test_bestrelpath_with_rootdir(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        **{\n            \"tests/test_1.py\": \"\"\"\n        import pytest\n        @pytest.mark.skip()\n            pass\n            \"\"\",\n        }\n    )\n    result = pytester.runpytest(\"-rs\", \"tests/test_1.py\", \"--rootdir=.\")\n    result.stdout.fnmatch_lines(\n        [\"SKIPPED [[]1[]] tests/test_1.py:2: unconditional skip\"]\n    )\n"], "sample_701": ["def test_argument_percent_default_is_deprecated(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n            parser.addoption(\"--foo\", default=\"bar\", help=\"%%default\")\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: pytest now uses argparse. \"\n            '\"%default\" should be changed to \"%(default)s\"',\n        ]\n    )\n"], "sample_703": ["def test_expression_compile_cache() -> None:\n    expr1 = Expression.compile(\"true\")\n    expr2 = Expression.compile(\"true\")\n    assert expr1.code is expr2.code\n\n    expr3 = Expression.compile(\"false\")\n    assert expr1.code is not expr3.code\n"], "sample_706": ["def test_expression_compile_and_evaluate_with_default_matcher() -> None:\n    expr = Expression.compile(\"true\")\n    assert expr.evaluate(lambda ident: True)\n    assert not expr.evaluate(lambda ident: False)\n"], "sample_707": ["def test_node_repr_failure_with_explicit_tbstyle(pytester: Pytester) -> None:\n    \"\"\"Test that the tbstyle option is respected when creating a failure representation.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n            assert False\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--tb=short\")\n    result.stdout.fnmatch_lines([\"*AssertionError*\"])\n    result = pytester.runpytest(\"--tb=long\")\n    result.stdout.fnmatch_lines([\"*AssertionError*\", \"*test_node_repr_failure_with_explicit_tbstyle*\"])\n"], "sample_708": ["def test_getstatementrange_with_nested_blocks() -> None:\n    source = Source(\n        \"\"\"\\"], "sample_710": ["def test_unittest_subtest(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n\n        class MyTestCase(unittest.TestCase):\n                for i in range(5):\n                    with self.subTest(i=i):\n                        if i == 3:\n                            assert False\n                        else:\n                            assert True\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*1 failed, 4 passed*\"])\n"], "sample_712": ["def test_ordinal_encoder_categories():\n    X = [['abc', 2, 55], ['def', 1, 55]]\n    enc = OrdinalEncoder(categories=[['abc', 'def'], [1, 2], [55]])\n    exp = np.array([[0, 1, 0],\n                    [1, 0, 0]], dtype='int64')\n    assert_array_equal(enc.fit_transform(X), exp.astype('float64'))\n    enc = OrdinalEncoder(categories=[['abc', 'def'], [1, 2], [55]], dtype='int64')\n    assert_array_equal(enc.fit_transform(X), exp)\n\n    # incorrect categories raises\n    X = [['abc', 2, 55], ['def', 1, 55]]\n    enc = OrdinalEncoder(categories=[['abc', 'de'], [1, 2], [55]])\n    msg = re.escape('Found unknown categories')\n    assert_raises_regex(ValueError, msg, enc.fit, X)\n"], "sample_713": ["def test_ridgecv_scorer():\n    # Test that RidgeCV works with a custom scorer\n    X, y = make_regression(n_samples=100, n_features=10, random_state=42)\n    scorer = make_scorer(mean_squared_error, greater_is_better=False)\n    ridgecv = RidgeCV(scorer=scorer)\n    ridgecv.fit(X, y)\n    assert hasattr(ridgecv, 'best_score_')\n    assert hasattr(ridgecv, 'alpha_')\n"], "sample_714": ["def test_brier_score_loss_multiclass():\n    # Check brier_score_loss function for multiclass case\n    y_true = np.array([0, 1, 2, 0, 1, 2])\n    y_pred = np.array([[0.9, 0.05, 0.05], [0.05, 0.9, 0.05],\n                       [0.05, 0.05, 0.9], [0.8, 0.1, 0.1],\n                       [0.1, 0.8, 0.1], [0.1, 0.1, 0.8]])\n    true_score = np.mean(np.sum((y_true[:, np.newaxis] != np.arange(3)) *\n                                (y_pred - 1) ** 2, axis=1))\n\n    assert_almost_equal(brier_score_loss(y_true, y_pred), true_score)\n    assert_raises(ValueError, brier_score_loss, y_true, y_pred[1:])\n    assert_raises(ValueError, brier_score_loss, y_true, y_pred + 1.)\n    assert_raises(ValueError, brier_score_loss, y_true, y_pred - 1.)\n"], "sample_715": ["def test_cross_val_score_with_scoring_object():\n    # Test cross_val_score with a scoring object\n    from sklearn.metrics.scorer import get_scorer\n    scorer = get_scorer('accuracy')\n    clf = MockClassifier()\n    scores = cross_val_score(clf, X, y2, scoring=scorer)\n    assert_array_equal(scores, clf.score(X, y2))\n"], "sample_716": ["def test_ridgecv_scorer():\n    # Test that RidgeCV works with a custom scorer\n    X, y = make_regression(n_samples=100, n_features=10, random_state=0)\n    scorer = make_scorer(mean_squared_error, greater_is_better=False)\n    ridge = RidgeCV(scorer=scorer)\n    ridge.fit(X, y)\n    assert hasattr(ridge, 'best_score_')\n    assert hasattr(ridge, 'alpha_')\n"], "sample_719": ["def test_vectorizer_stop_words_set():\n    stop_words = set([\"the\", \"and\"])\n    cv = CountVectorizer(stop_words=stop_words)\n    X_counted = cv.fit_transform(ALL_FOOD_DOCS)\n    assert_equal(\"the\" not in cv.vocabulary_, True)\n    assert_equal(\"and\" not in cv.vocabulary_, True)\n\n    tv = TfidfVectorizer(stop_words=stop_words)\n    X_tfidf = tv.fit_transform(ALL_FOOD_DOCS)\n    assert_equal(\"the\" not in tv.vocabulary_, True)\n    assert_equal(\"and\" not in tv.vocabulary_, True)\n"], "sample_721": ["def test_check_X_y():\n    # Test that X and y are checked correctly\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # Test that X and y are checked correctly when X is sparse\n    X_sparse = sp.csr_matrix(X)\n    X_checked, y_checked = check_X_y(X_sparse, y)\n    assert_array_equal(X_checked.toarray(), X)\n    assert_array_equal(y_checked, y)\n\n    # Test that an error is raised when X and y have different lengths\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1, 2])\n    assert_raises_regex(ValueError, 'Found input variables with inconsistent'\n                        ' numbers of samples', check_X_y, X, y)\n\n    # Test that an error is raised when y is not a 1D array\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([[0, 1], [2, 3]])\n    assert_raises_regex(ValueError, 'bad input shape \\(2, 2\\)', check_X_y, X, y)\n\n    # Test that an error is raised when y has non-numeric values\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array(['a', 'b'])\n    assert_raises_regex(ValueError, 'Unknown label type: \\'\\[\\'a\\' \\'b\\'\\]\\'',\n                        check_X_y, X, y, y_numeric=True)\n"], "sample_722": ["def test_k_means_init_callable():\n    # Test that a callable can be passed to the init parameter of KMeans.\n        return X[:k]\n\n    km = KMeans(init=init, n_clusters=n_clusters, n_init=1)\n    km.fit(X)\n    _check_fitted_model(km)\n"], "sample_723": ["def test_imputation_axis1_sparse():\n    # Test imputation with axis=1 on sparse matrices.\n    X = sparse.csr_matrix(np.array([\n        [0, 0, 0, 5],\n        [1, 2, -1, 3],\n        [-1, 1, 3, -1],\n        [-1, 2, 3, 7],\n    ]))\n\n    imputer = SimpleImputer(missing_values=-1, strategy=\"mean\", axis=1)\n    Xt = imputer.fit_transform(X)\n\n    assert_array_almost_equal(imputer.statistics_, np.array([1., 2., 3.]))\n    assert_array_almost_equal(Xt.toarray(), np.array([\n        [0, 0, 0, 5],\n        [1, 2, 2, 3],\n        [2, 1, 3, 2],\n        [2, 2, 3, 7],\n    ]))\n"], "sample_724": ["def test_imputation_axis1_sparse():\n    # Test imputation with axis=1 on sparse matrices.\n    X = sparse.csr_matrix(np.array([\n        [0, 0, 0, 5],\n        [0, 2, 0, 3],\n        [0, 1, 3, 0],\n        [0, 2, 3, 7],\n    ]))\n\n    X_true = np.array([\n        [2, 0, 5],\n        [2, 3, 3],\n        [1, 3, 3],\n        [2, 3, 7],\n    ])\n\n    imputer = Imputer(missing_values=0, strategy=\"most_frequent\", axis=1)\n    Xt = imputer.fit_transform(X)\n\n    assert_array_almost_equal(Xt.toarray(), X_true)\n"], "sample_725": ["def test_check_X_y():\n    # Test that check_X_y returns the original arrays when they are already\n    # valid (2D, same length, etc.)\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X, X_checked)\n    assert_array_equal(y, y_checked)\n\n    # Test that check_X_y raises an error when the lengths of X and y are\n    # different.\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1, 2])\n    assert_raises_regex(ValueError, 'Found input variables with inconsistent'\n                        ' numbers of samples', check_X_y, X, y)\n\n    # Test that check_X_y raises an error when y is not a 1D array.\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([[0, 1], [2, 3]])\n    assert_raises_regex(ValueError, 'bad input shape', check_X_y, X, y)\n\n    # Test that check_X_y raises an error when y contains non-numeric values.\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array(['a', 'b'])\n    assert_raises_regex(ValueError, 'Unknown label type', check_X_y, X, y)\n\n    # Test that check_X_y converts y to float64 when it contains numeric\n    # values.\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1], dtype=np.int32)\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X, X_checked)\n    assert_array_equal(y, y_checked)\n    assert_equal(y_checked.dtype, np.float64)\n"], "sample_726": ["def test_label_binarize_empty_input():\n    y = []\n    classes = [0, 1, 2]\n    pos_label = 2\n    neg_label = 0\n\n    lb = LabelBinarizer(neg_label=neg_label, pos_label=pos_label)\n    binarized = lb.fit_transform(y)\n    assert_array_equal(binarized, np.array([]))\n    assert_array_equal(lb.classes_, classes)\n\n    binarized = label_binarize(y, classes, neg_label=neg_label,\n                               pos_label=pos_label)\n    assert_array_equal(binarized, np.array([]))\n"], "sample_727": ["def test_imputation_sparse_most_frequent():\n    # Test imputation using the most-frequent strategy on sparse data.\n    X = sparse.csr_matrix(np.array([\n        [0, 1, 0, 5],\n        [0, 2, 0, 3],\n        [0, 1, 3, 0],\n        [0, 2, 3, 7],\n    ]))\n\n    X_true = np.array([\n        [2, 0, 5],\n        [2, 3, 3],\n        [1, 3, 3],\n        [2, 3, 7],\n    ])\n\n    _check_statistics(X, X_true, \"most_frequent\", [np.nan, 2, 3, 3], 0)\n"], "sample_729": ["def test_enet_l1_ratio_warning():\n    # Test that a warning message is raised if l1_ratio < 0.01\n    X = np.array([[1, 2, 4, 5, 8], [3, 5, 7, 7, 8]]).T\n    y = np.array([12, 10, 11, 21, 5])\n\n    msg = (\"l1_ratio parameter is less than 0.01; it may lead to \"\n           \"incorrect results.\")\n    with ignore_warnings(category=FutureWarning):\n        assert_warns_message(FutureWarning, msg, ElasticNetCV(\n            l1_ratio=0.001, random_state=42).fit, X, y)\n        assert_warns_message(FutureWarning, msg, MultiTaskElasticNetCV(\n            l1_ratio=0.001, random_state=42).fit, X, y[:, None])\n"], "sample_730": ["def test_enet_l1_ratio_warning():\n    # Test that a warning message is raised if l1_ratio < 0.01\n    X = np.array([[1, 2, 4, 5, 8], [3, 5, 7, 7, 8]]).T\n    y = np.array([12, 10, 11, 21, 5])\n\n    msg = (\"l1_ratio <= 0.01 is not reliable, unless you supply your own \"\n           \"sequence of alpha.\")\n    with assert_warns_message(UserWarning, msg):\n        ElasticNetCV(l1_ratio=0.001, random_state=42).fit(X, y)\n    with assert_warns_message(UserWarning, msg):\n        MultiTaskElasticNetCV(l1_ratio=0.001, random_state=42).fit(X, y[:, None])\n"], "sample_731": ["def test_california_housing_feature_names():\n    try:\n        data = fetch()\n    except IOError:\n        raise SkipTest(\"California housing dataset can not be loaded.\")\n    expected_feature_names = [\"MedInc\", \"HouseAge\", \"AveRooms\", \"AveBedrms\",\n                              \"Population\", \"AveOccup\", \"Latitude\", \"Longitude\"]\n    assert data.feature_names == expected_feature_names\n"], "sample_732": ["def test_download_if_missing():\n    try:\n        fetch_kddcup99(download_if_missing=False, percent10=True)\n    except IOError:\n        # dataset is not downloaded\n        pass\n    else:\n        raise AssertionError(\"Dataset should not be available\")\n\n    try:\n        fetch_kddcup99(download_if_missing=True, percent10=True)\n    except IOError:\n        raise AssertionError(\"Dataset should be downloaded\")\n"], "sample_733": ["def test_vectorizer_empty_input():\n    # Test that vectorizers can handle empty input\n    vectorizers = [\n        CountVectorizer(),\n        TfidfVectorizer(),\n        HashingVectorizer()\n    ]\n\n    for vec in vectorizers:\n        X = vec.fit_transform([])\n        assert_equal(X.shape, (0, 0))\n\n        # Test that the vocabulary is empty\n        if hasattr(vec, 'vocabulary_'):\n            assert_equal(vec.vocabulary_, {})\n"], "sample_734": ["def test_contingency_matrix_eps():\n    labels_a = np.array([1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3])\n    labels_b = np.array([1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 3, 1, 3, 3, 3, 2, 2])\n    C = contingency_matrix(labels_a, labels_b)\n    C_eps = contingency_matrix(labels_a, labels_b, eps=0.5)\n    assert_array_almost_equal(C_eps, C + 0.5)\n"], "sample_736": ["def test_logistic_regression_multiclass_predict_proba():\n    # Test that predict_proba works for multiclass classification problems\n    X, y = make_classification(n_samples=100, n_features=20, random_state=0,\n                               n_classes=3, n_informative=10)\n\n    clf_multi = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n    clf_multi.fit(X, y)\n    assert_array_almost_equal(clf_multi.predict_proba(X).sum(axis=1), 1.0)\n\n    clf_ovr = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\")\n    clf_ovr.fit(X, y)\n    assert_array_almost_equal(clf_ovr.predict_proba(X).sum(axis=1), 1.0)\n"], "sample_737": ["def test_vectorizer_empty_input():\n    # Test that vectorizers can handle empty input\n    for vec in [CountVectorizer(), TfidfVectorizer(), HashingVectorizer()]:\n        X = vec.fit_transform([])\n        assert_equal(X.shape, (0, vec.n_features))\n        assert_equal(X.nnz, 0)\n"], "sample_738": ["def test_vectorizer_empty_input():\n    # Test that vectorizers can handle empty input\n    for vec in [CountVectorizer(), TfidfVectorizer(), HashingVectorizer()]:\n        X = vec.fit_transform([])\n        assert_equal(X.shape, (0, 0))\n        assert_array_equal(X.data, [])\n        assert_array_equal(X.indices, [])\n        assert_array_equal(X.indptr, [0])\n"], "sample_739": ["def test_label_binarize_empty_input():\n    y = []\n    classes = [0, 1, 2]\n    pos_label = 1\n    neg_label = 0\n\n    lb = LabelBinarizer(neg_label=neg_label, pos_label=pos_label)\n    binarized = lb.fit_transform(y)\n    assert_array_equal(binarized, np.array([]))\n    assert_array_equal(lb.classes_, classes)\n\n    binarized = label_binarize(y, classes, neg_label=neg_label,\n                               pos_label=pos_label)\n    assert_array_equal(binarized, np.array([]))\n"], "sample_740": ["def test_check_X_y():\n    # Test that X and y are checked correctly\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X, X_checked)\n    assert_array_equal(y, y_checked)\n\n    # Test that X and y are checked correctly when X is sparse\n    X_sparse = sp.csr_matrix(X)\n    X_checked, y_checked = check_X_y(X_sparse, y)\n    assert_array_equal(X_sparse.toarray(), X_checked.toarray())\n    assert_array_equal(y, y_checked)\n\n    # Test that X and y are checked correctly when y is None\n    X_checked, y_checked = check_X_y(X, None)\n    assert_array_equal(X, X_checked)\n    assert y_checked is None\n\n    # Test that an error is raised when X and y have different lengths\n    assert_raises(ValueError, check_X_y, X, np.array([0, 1, 2]))\n\n    # Test that an error is raised when y is not a 1D array\n    assert_raises(ValueError, check_X_y, X, np.array([[0, 1], [2, 3]]))\n\n    # Test that an error is raised when y has non-numeric values\n    assert_raises(ValueError, check_X_y, X, np.array(['a', 'b']))\n\n    # Test that an error is raised when X has non-numeric values\n    assert_raises(ValueError, check_X_y, np.array([[1, 'a'], [2, 'b']]), y)\n"], "sample_742": ["def test_logistic_regression_multiclass_predict_proba():\n    # Test that predict_proba works for multiclass classification problems\n    X, y = make_classification(n_samples=100, n_features=20, random_state=0,\n                               n_classes=3, n_informative=10)\n\n    clf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n    clf.fit(X, y)\n    y_pred_proba = clf.predict_proba(X)\n\n    assert_array_almost_equal(y_pred_proba.sum(axis=1), np.ones(X.shape[0]))\n\n    # Check that the highest probability class is the same as the predicted class\n    assert_array_equal(np.argmax(y_pred_proba, axis=1), clf.predict(X))\n"], "sample_743": ["def test_radius_neighbors_regressor_multioutput_with_distance_weight():\n    # Test radius neighbors in multi-output regression (distance weight)\n\n    rng = check_random_state(0)\n    n_features = 5\n    n_samples = 40\n    n_output = 4\n\n    X = rng.rand(n_samples, n_features)\n    y = rng.rand(n_samples, n_output)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\n    for algorithm in ALGORITHMS:\n        rnn = neighbors.RadiusNeighborsRegressor(weights='distance',\n                                                 algorithm=algorithm)\n        rnn.fit(X_train, y_train)\n\n        neigh_idx = rnn.radius_neighbors(X_test, return_distance=False)\n        y_pred_idx = np.array([np.average(y_train[idx], axis=0,\n                                          weights=_get_weights(\n                                              pairwise_distances(X_test[i],\n                                                                  X_train[idx]),\n                                              'distance'))\n                               for i, idx in enumerate(neigh_idx)])\n\n        y_pred = rnn.predict(X_test)\n\n        assert_equal(y_pred.shape, y_test.shape)\n        assert_array_almost_equal(y_pred, y_pred_idx)\n"], "sample_745": ["def test_function_transformer_sparse_output():\n    X = np.array([[1, 0, 0], [0, 2, 0], [0, 0, 3]])\n    transformer = FunctionTransformer(func=sparse.csr_matrix, validate=False)\n    X_trans = transformer.fit_transform(X)\n    assert sparse.issparse(X_trans)\n    assert_array_equal(X_trans.toarray(), X)\n"], "sample_750": ["def test_omp_n_iter():\n    omp = OrthogonalMatchingPursuit(n_nonzero_coefs=5)\n    omp.fit(X, y[:, 0])\n    assert_equal(omp.n_iter_, 5)\n\n    omp = OrthogonalMatchingPursuit(tol=1.0)\n    omp.fit(X, y[:, 0])\n    assert_true(omp.n_iter_ > 0)\n\n    omp = OrthogonalMatchingPursuit(n_nonzero_coefs=5)\n    omp.fit(X, y)\n    assert_array_equal(omp.n_iter_, np.repeat(5, n_targets))\n\n    omp = OrthogonalMatchingPursuit(tol=1.0)\n    omp.fit(X, y)\n    assert_array_equal(omp.n_iter_, np.repeat(1, n_targets))\n"], "sample_751": ["def test_forest_regressor_attributes():\n    # Check ForestRegressor attributes.\n    X, y = datasets.make_regression(n_samples=15, n_features=5, n_targets=1,\n                                    random_state=42)\n\n    reg = RandomForestRegressor(random_state=0)\n    reg.fit(X, y)\n\n    assert hasattr(reg, 'feature_importances_')\n    assert hasattr(reg, 'n_features_')\n    assert hasattr(reg, 'n_outputs_')\n    assert hasattr(reg, 'oob_score_')\n    assert hasattr(reg, 'oob_prediction_')\n\n    extra_reg = ExtraTreesRegressor(random_state=0)\n    extra_reg.fit(X, y)\n\n    assert hasattr(extra_reg, 'feature_importances_')\n    assert hasattr(extra_reg, 'n_features_')\n    assert hasattr(extra_reg, 'n_outputs_')\n    assert hasattr(extra_reg, 'oob_score_')\n    assert hasattr(extra_reg, 'oob_prediction_')\n"], "sample_752": ["def test_iforest_contamination_auto():\n    # Test that the 'auto' contamination parameter works as expected\n    X = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1], [6, 3], [-4, 7]]\n\n    clf = IsolationForest(contamination='auto', random_state=rng)\n    clf.fit(X)\n\n    # Check that the offset is correctly calculated\n    assert_almost_equal(clf.offset_, -0.5)\n\n    # Check that the predict method works as expected\n    pred = clf.predict(X)\n    assert_array_equal(pred, 6 * [1] + 2 * [-1])\n"], "sample_754": ["def test_sparse_pca_verbose(norm_comp):\n    rng = np.random.RandomState(0)\n    X = rng.randn(12, 10)\n    spca = SparsePCA(n_components=8, random_state=rng, verbose=10,\n                     normalize_components=norm_comp)\n    U = spca.fit_transform(X)\n    assert_equal(spca.components_.shape, (8, 10))\n    assert_equal(U.shape, (12, 8))\n"], "sample_755": ["def test_calinski_harabasz_score_sparse_input():\n    # Assert the function works with sparse inputs\n    X = csr_matrix(np.array([[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5))\n    labels = [0] * 10 + [1] * 10\n    pytest.approx(calinski_harabasz_score(X, labels),\n                  45 * (40 - 4) / (5 * (4 - 1)))\n"], "sample_756": ["def test_optics_fit_predict():\n    # Test that fit and predict give same results\n    clust1 = OPTICS(min_samples=10)\n    clust1.fit(X)\n    labels1 = clust1.labels_\n\n    clust2 = OPTICS(min_samples=10)\n    labels2 = clust2.fit_predict(X)\n\n    assert_array_equal(labels1, labels2)\n"], "sample_757": ["def test_ordinal_encoder_dtype():\n    X = [['abc', 2, 55], ['def', 1, 55]]\n    enc = OrdinalEncoder(dtype='int32')\n    exp = np.array([[0, 1, 0],\n                    [1, 0, 0]], dtype='int32')\n    assert_array_equal(enc.fit_transform(X), exp)\n\n    X = np.array([[10, 2, 55], [20, 1, 55]])\n    enc = OrdinalEncoder(dtype='float64')\n    exp = np.array([[0, 1, 0],\n                    [1, 0, 0]], dtype='float64')\n    assert_array_equal(enc.fit_transform(X), exp)\n"], "sample_758": ["def test_check_array_dtype_object_conversion_with_nans():\n    # Test that data-frame like objects with dtype object and NaN values\n    # get converted correctly\n    X = np.array([[1, 2, np.nan], [4, 5, 6], [7, 8, 9]], dtype=np.object)\n    X_df = MockDataFrame(X)\n    X_checked = check_array(X_df, force_all_finite='allow-nan')\n    assert_equal(X_checked.dtype.kind, \"f\")\n    assert_array_equal(X_checked, X.astype(np.float64))\n"], "sample_759": ["def test_one_hot_encoder_get_feature_names_with_multiple_features():\n    enc = OneHotEncoder()\n    X = [['Male', 1, 'girl', 2, 3],\n         ['Female', 41, 'girl', 1, 10],\n         ['Male', 51, 'boy', 12, 3],\n         ['Male', 91, 'girl', 21, 30]]\n\n    enc.fit(X)\n    feature_names = enc.get_feature_names(['gender', 'age_group', 'child_gender', 'score', 'weight'])\n    assert isinstance(feature_names, np.ndarray)\n\n    assert_array_equal(['gender_Female', 'gender_Male',\n                        'age_group_1', 'age_group_41', 'age_group_51', 'age_group_91',\n                        'child_gender_boy', 'child_gender_girl',\n                        'score_1', 'score_2', 'score_12', 'score_21',\n                        'weight_3', 'weight_10', 'weight_30'], feature_names)\n"], "sample_760": ["def test_make_scorer_with_kwargs():\n    # Test that make_scorer can handle keyword arguments.\n    f = lambda y_true, y_pred, **kwargs: 0\n    scorer = make_scorer(f, greater_is_better=True, needs_proba=False,\n                         needs_threshold=False, some_kwarg='some_value')\n    assert scorer._kwargs == {'some_kwarg': 'some_value'}\n"], "sample_761": ["def test_iterative_imputer_n_nearest_features():\n    rng = np.random.RandomState(0)\n    n = 100\n    d = 10\n    X = sparse_random_matrix(n, d, density=0.10,\n                             random_state=rng).toarray()\n\n    imputer = IterativeImputer(missing_values=0,\n                               max_iter=1,\n                               n_nearest_features=5,\n                               sample_posterior=False,\n                               min_value=0,\n                               max_value=1,\n                               verbose=1,\n                               imputation_order='random',\n                               random_state=rng)\n\n    imputer.fit(X)\n\n    # check that the number of features used to impute is correct\n    for triplet in imputer.imputation_sequence_:\n        assert len(triplet.neighbor_feat_idx) == 5\n"], "sample_762": ["def test_get_params_with_list_of_estimators():\n    # Test that get_params works with a list of estimators.\n    estimators = [DecisionTreeClassifier(), DecisionTreeRegressor()]\n    pipeline = Pipeline([('estimators', estimators)])\n    params = pipeline.get_params()\n    assert 'estimators' in params\n    assert isinstance(params['estimators'], list)\n    assert len(params['estimators']) == 2\n"], "sample_763": ["def test_check_X_y_length_mismatch():\n    X = np.ones((2, 2))\n    y = np.array([1, 2, 3])\n    assert_raise_message(ValueError, \"Found input variables with inconsistent\"\n                         \" numbers of samples: [2, 3]\", check_X_y, X, y)\n"], "sample_766": ["def test_sparse_coder_estimator_positive_code():\n    n_components = 12\n    rng = np.random.RandomState(0)\n    V = rng.randn(n_components, n_features)  # random init\n    V /= np.sum(V ** 2, axis=1)[:, np.newaxis]\n    code = SparseCoder(dictionary=V, transform_algorithm='lasso_lars',\n                       positive_code=True).transform(X)\n    assert (code >= 0).all()\n"], "sample_770": ["def test_silhouette_score_non_finite_values():\n    # Test silhouette score with non-finite values\n    X = np.array([[0, 0], [1, 1], [2, 2]])\n    labels = np.array([0, 0, 1])\n    \n    # Test with NaN values\n    X_nan = X.copy()\n    X_nan[0, 0] = np.nan\n    assert_raises_regexp(ValueError,\n                         \"Array contains NaN or infinity\",\n                         silhouette_score, X_nan, labels)\n    \n    # Test with infinite values\n    X_inf = X.copy()\n    X_inf[0, 0] = np.inf\n    assert_raises_regexp(ValueError,\n                         \"Array contains NaN or infinity\",\n                         silhouette_score, X_inf, labels)\n"], "sample_772": ["def check_n_features_deprecation(name):\n    # Check that the `n_features` attribute is deprecated.\n    ForestEstimator = FOREST_ESTIMATORS[name]\n    est = ForestEstimator()\n    est.fit(X, y)\n    assert_warns(DeprecationWarning, getattr, est, 'n_features')\n    assert_equal(est.n_features_, est.n_features)\n\n"], "sample_773": ["def test_logistic_regression_path_multiclass():\n    # Test that logistic_regression_path returns the correct coefs for\n    # multiclass problems.\n    X, y = make_classification(n_samples=200, n_features=20, n_informative=10,\n                               n_redundant=0, n_repeated=0, n_classes=3,\n                               random_state=0)\n    Cs = np.logspace(-4, 4, 3)\n\n    coefs, Cs, _ = _logistic_regression_path(X, y, Cs=Cs, solver='saga',\n                                             penalty='l2', max_iter=1000,\n                                             tol=1e-3, multi_class='multinomial')\n    assert coefs.shape == (3, len(Cs), X.shape[1])\n"], "sample_774": ["def test_ordinal_encoder_set_params():\n    X = np.array([['a', 'b'], [0, 2]], dtype=object).T\n    enc = OrdinalEncoder()\n    # set params on not yet fitted object\n    enc.set_params(categories=[['a', 'b', 'c'], [0, 1, 2]])\n    assert enc.get_params()['categories'] == [['a', 'b', 'c'], [0, 1, 2]]\n    assert_array_equal(enc.fit_transform(X), np.array([[0.], [1.]]))\n    # set params on already fitted object\n    enc.set_params(categories=[['a', 'b', 'c', 'd'], [0, 1, 2, 3]])\n    assert_array_equal(enc.fit_transform(X), np.array([[0.], [1.]]))\n"], "sample_776": ["def test_lars_path_with_positive_constrained():\n    # Test lars_path with positive constraint on coefficients.\n    X, y = diabetes.data, diabetes.target\n    max_iter = 10\n\n    alphas, active, coefs = linear_model.lars_path(X, y, method='lasso',\n                                                   positive=True,\n                                                   max_iter=max_iter)\n    assert np.all(coefs >= 0)\n\n    # Check that the returned coefficients are the same when using LassoLars\n    lasso_lars = linear_model.LassoLars(max_iter=max_iter, positive=True)\n    lasso_lars.fit(X, y)\n    assert_array_almost_equal(coefs[:, -1], lasso_lars.coef_)\n"], "sample_777": ["def test_gradient_boosting_init_estimator_with_n_iter_no_change():\n    # Check that GradientBoostingRegressor works when init is a sklearn\n    # estimator and n_iter_no_change is specified.\n\n    X, y = make_regression()\n    init_est = DummyRegressor()\n\n    gb = GradientBoostingRegressor(init=init_est, n_iter_no_change=5)\n    gb.fit(X, y)\n\n    assert gb.n_estimators_ > 0\n    assert gb.init_ == init_est\n"], "sample_778": ["def test_nmf_fit_transform_check_is_fitted():\n    # Test that fit_transform raises an error if not enough iterations\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(6, 5))\n    model = NMF(n_components=2, solver='cd', init='random',\n                random_state=0, max_iter=1)\n    with pytest.raises(ValueError):\n        model.transform(A)\n    model.fit_transform(A)\n    assert model.n_iter_ > 0\n"], "sample_780": ["def test_lda_components_shape():\n    # Test that the shape of components_ is correct\n    n_components, X = _build_sparse_mtx()\n    lda = LatentDirichletAllocation(n_components=n_components)\n    lda.fit(X)\n    assert_equal(lda.components_.shape, (n_components, X.shape[1]))\n"], "sample_781": ["def test_forest_estimators_sample_weights():\n    # Test that sample weights are properly passed to the trees.\n    X, y = make_classification(n_samples=100, n_features=10, random_state=0)\n    sample_weight = np.random.rand(100)\n\n    forest = RandomForestClassifier(n_estimators=10, random_state=0)\n    forest.fit(X, y, sample_weight=sample_weight)\n\n    for tree in forest.estimators_:\n        assert_array_equal(tree.sample_weight, sample_weight)\n"], "sample_783": ["def test_simple_imputer_get_params():\n    # Test SimpleImputer.get_params() to ensure it returns the correct params\n    imputer = SimpleImputer(missing_values=np.nan, strategy='mean',\n                            fill_value=None, verbose=0, copy=True)\n    params = imputer.get_params()\n    assert params == {'copy': True,\n                      'fill_value': None,\n                      'missing_values': np.nan,\n                      'strategy': 'mean',\n                      'verbose': 0}\n"], "sample_784": ["def test_calibration_curve_input_validation():\n    \"\"\"Check calibration_curve function input validation\"\"\"\n    y_true = np.array([0, 0, 0, 1, 1, 1])\n    y_pred = np.array([0., 0.1, 0.2, 0.8, 0.9, 1.])\n\n    # Check that y_true and y_pred have the same length\n    assert_raises(ValueError, calibration_curve, y_true[:5], y_pred)\n\n    # Check that y_true is a binary array\n    assert_raises(ValueError, calibration_curve, np.array([0, 1, 2]), y_pred)\n\n    # Check that y_pred is a 1D array\n    assert_raises(ValueError, calibration_curve, y_true, np.vstack((y_pred, y_pred)))\n\n    # Check that n_bins is at least 2\n    assert_raises(ValueError, calibration_curve, y_true, y_pred, n_bins=1)\n"], "sample_786": ["def test_fit_transform_constant_feature():\n    X = np.array([[1, 2, 3], [1, 4, 5], [1, 6, 7]])\n    est = KBinsDiscretizer(n_bins=3, encode='ordinal')\n    Xt = est.fit_transform(X)\n    assert_array_equal(Xt[:, 0], np.zeros(X.shape[0]))\n    assert est.n_bins_[0] == 1\n    assert len(est.bin_edges_[0]) == 2\n"], "sample_788": ["def test_fit_transform_constant_feature():\n    X = np.array([[1, 2, 3], [1, 4, 5], [1, 6, 7]])\n    est = KBinsDiscretizer(n_bins=3, encode='ordinal')\n    Xt = est.fit_transform(X)\n    assert_array_equal(Xt[:, 0], np.zeros(X.shape[0]))\n    assert est.n_bins_[0] == 1\n    assert len(est.bin_edges_[0]) == 2\n"], "sample_789": ["def test_adaboost_regressor_with_constant_target():\n    \"\"\"\n    Check that AdaBoostRegressor works with constant target.\n    \"\"\"\n    X = np.random.randn(50, 3)\n    y = np.ones(50)\n\n    boost = AdaBoostRegressor(n_estimators=5)\n    boost.fit(X, y)\n    assert_array_almost_equal(boost.predict(X), y)\n"], "sample_790": ["def test_kernel_pca_n_jobs():\n    rng = np.random.RandomState(0)\n    X_fit = rng.random_sample((5, 4))\n    X_pred = rng.random_sample((2, 4))\n\n    for n_jobs in [1, -1]:\n        kpca = KernelPCA(n_components=2, n_jobs=n_jobs)\n        X_fit_transformed = kpca.fit_transform(X_fit)\n        X_pred_transformed = kpca.transform(X_pred)\n\n        assert_equal(X_fit_transformed.shape, (5, 2))\n        assert_equal(X_pred_transformed.shape, (2, 2))\n"], "sample_791": ["def test_ordinal_encoder_dtype():\n    X = [['abc', 2, 55], ['def', 1, 55]]\n    enc = OrdinalEncoder(dtype=np.int32)\n    X_tr = enc.fit_transform(X)\n    assert X_tr.dtype == np.int32\n\n    enc = OrdinalEncoder(dtype=np.float64)\n    X_tr = enc.fit_transform(X)\n    assert X_tr.dtype == np.float64\n\n    enc = OrdinalEncoder(dtype='int64')\n    X_tr = enc.fit_transform(X)\n    assert X_tr.dtype == np.int64\n"], "sample_793": ["def test_iforest_fit_predict_sparse():\n    # Test fit and predict on sparse data\n    X_train = csr_matrix(np.array([[0, 1], [1, 2]]))\n    X_test = csr_matrix(np.array([[2, 1], [1, 1]]))\n\n    clf = IsolationForest(random_state=rng)\n    clf.fit(X_train)\n    y_pred = clf.predict(X_test)\n\n    assert_array_equal(y_pred, [-1, -1])\n"], "sample_794": ["def test_ridgecv_scorer():\n    # Test that RidgeCV works with a custom scorer.\n    X, y = make_regression(n_samples=100, n_features=10, random_state=0)\n    scorer = make_scorer(mean_squared_error, greater_is_better=False)\n\n    ridge_cv = RidgeCV(scoring=scorer)\n    ridge_cv.fit(X, y)\n\n    assert hasattr(ridge_cv, 'best_score_')\n    assert hasattr(ridge_cv, 'alpha_')\n    assert isinstance(ridge_cv.coef_, np.ndarray)\n    assert isinstance(ridge_cv.intercept_, float)\n"], "sample_795": ["def test_check_estimator_sparse_data():\n    # check that estimator can handle sparse data correctly\n\n    class SparseEstimator(BaseEstimator):\n            X = check_array(X, accept_sparse=True)\n            return self\n\n            X = check_array(X, accept_sparse=True)\n            return np.ones(X.shape[0])\n\n    check_estimator(SparseEstimator())\n"], "sample_796": ["def test_huber_raise_error_for_invalid_epsilon():\n    # Test that HuberRegressor raises an error for invalid epsilon values.\n    X, y = make_regression_with_outliers()\n    huber = HuberRegressor(epsilon=0.5)\n    with pytest.raises(ValueError):\n        huber.fit(X, y)\n\n    huber = HuberRegressor(epsilon=-1.0)\n    with pytest.raises(ValueError):\n        huber.fit(X, y)\n"], "sample_798": ["def test_ridgecv_scorer():\n    # Test that RidgeCV works with a custom scorer\n    X, y = make_regression(n_samples=10, n_features=5, random_state=0)\n    scorer = make_scorer(mean_squared_error, greater_is_better=False)\n    ridgecv = RidgeCV(scorer=scorer)\n    ridgecv.fit(X, y)\n    assert hasattr(ridgecv, 'best_score_')\n    assert hasattr(ridgecv, 'alpha_')\n"], "sample_802": ["def test_pipeline_get_params():\n    # Test that get_params returns all the parameters of the pipeline\n    pipe = Pipeline([('transf', Transf()), ('clf', FitParamT())])\n    params = pipe.get_params()\n    assert 'transf' in params\n    assert 'clf' in params\n    assert 'steps' in params\n\n    # Check that parameter names are correct\n    assert 'transf__a' in params\n    assert 'transf__b' in params\n    assert 'clf__should_succeed' in params\n\n    # Check that get_params returns the correct values\n    assert params['transf'] is pipe.named_steps['transf']\n    assert params['clf'] is pipe.named_steps['clf']\n    assert params['steps'] is pipe.steps\n    assert params['transf__a'] is None\n    assert params['transf__b'] is None\n    assert not params['clf__should_succeed']\n"], "sample_803": ["def test_roc_auc_score_average():\n    # Test average parameter in roc_auc_score function\n    y_true = np.array([[0, 1], [0, 1]])\n    y_score = np.array([[0, 1], [1, 0]])\n\n    # Test 'macro' average\n    assert_almost_equal(roc_auc_score(y_true, y_score, average='macro'), 0.5)\n\n    # Test 'weighted' average\n    assert_almost_equal(roc_auc_score(y_true, y_score, average='weighted'), 0.5)\n\n    # Test 'samples' average\n    assert_almost_equal(roc_auc_score(y_true, y_score, average='samples'), 0.5)\n\n    # Test 'micro' average\n    assert_almost_equal(roc_auc_score(y_true, y_score, average='micro'), 0.5)\n"], "sample_804": ["def test_ordinal_encoder_categories_dtype():\n    X = np.array([['a', 'b']], dtype=object).T\n    enc = OrdinalEncoder(categories=[np.array(['a', 'b', 'c'], dtype='S4')])\n    exp = np.array([[0.], [1.]])\n    assert_array_equal(enc.fit_transform(X), exp)\n    assert enc.categories_[0].dtype == 'S4'\n"], "sample_805": ["def test_mean_tweedie_deviance_weighted():\n    y_true = np.array([1.0, 2.0, 3.0])\n    y_pred = np.array([1.5, 2.5, 3.5])\n    sample_weight = np.array([0.5, 1.0, 1.5])\n\n    # Test with p=0 (Normal distribution)\n    score = mean_tweedie_deviance(y_true, y_pred, sample_weight=sample_weight, p=0)\n    assert_almost_equal(score, mean_squared_error(y_true, y_pred, sample_weight=sample_weight))\n\n    # Test with p=1 (Poisson distribution)\n    score = mean_tweedie_deviance(y_true, y_pred, sample_weight=sample_weight, p=1)\n    assert_almost_equal(score, mean_poisson_deviance(y_true, y_pred, sample_weight=sample_weight))\n\n    # Test with p=2 (Gamma distribution)\n    score = mean_tweedie_deviance(y_true, y_pred, sample_weight=sample_weight, p=2)\n    assert_almost_equal(score, mean_gamma_deviance(y_true, y_pred, sample_weight=sample_weight))\n"], "sample_806": ["def test_gradient_boosting_init_estimator_with_sample_weight():\n    # Check that GradientBoosting estimators work with an init estimator and\n    # sample weights.\n\n    X, y = make_classification(random_state=0)\n    sample_weight = np.random.RandomState(42).rand(y.shape[0])\n\n    # init supports sample weights\n    init_est = DummyClassifier()\n    gb = GradientBoostingClassifier(init=init_est)\n    gb.fit(X, y, sample_weight=sample_weight)\n\n    init_est = DummyRegressor()\n    gb = GradientBoostingRegressor(init=init_est)\n    gb.fit(X, y, sample_weight=sample_weight)\n"], "sample_807": ["def test_calibration_curve_input_validation():\n    \"\"\"Check calibration_curve function input validation\"\"\"\n    y_true = np.array([0, 0, 0, 1, 1, 1])\n    y_pred = np.array([0., 0.1, 0.2, 0.8, 0.9, 1.])\n\n    # Check that y_true and y_pred have the same length\n    assert_raises(ValueError, calibration_curve, y_true[:5], y_pred)\n\n    # Check that n_bins is at least 2\n    assert_raises(ValueError, calibration_curve, y_true, y_pred, n_bins=1)\n\n    # Check that strategy is either 'uniform' or 'quantile'\n    assert_raises(ValueError, calibration_curve, y_true, y_pred,\n                  strategy='invalid')\n"], "sample_808": ["def test_iforest_fit_predict_sparse():\n    \"\"\"Test fit and predict methods with sparse data\"\"\"\n    X_train = csr_matrix(np.array([[0, 1], [1, 2]]))\n    X_test = csr_matrix(np.array([[2, 1], [1, 1]]))\n\n    clf = IsolationForest(random_state=rng)\n    clf.fit(X_train)\n\n    y_pred = clf.predict(X_test)\n    assert_array_equal(y_pred, [-1, -1])\n"], "sample_809": ["def test_mutual_info_classif_sparse():\n    # Test that sparse and dense inputs give the same results for mutual_info_classif.\n    X = np.array([[0, 0, 0],\n                  [1, 1, 0],\n                  [2, 0, 1],\n                  [2, 0, 1],\n                  [2, 0, 1]])\n    y = np.array([0, 1, 2, 2, 1])\n\n    X_sparse = csr_matrix(X)\n\n    mi_dense = mutual_info_classif(X, y, discrete_features='auto')\n    mi_sparse = mutual_info_classif(X_sparse, y, discrete_features='auto')\n\n    assert_array_equal(mi_dense, mi_sparse)\n"], "sample_810": ["def test_pipeline_get_params():\n    # Test that get_params returns all the parameters of the pipeline\n    # and its components.\n    clf = make_pipeline(LogisticRegression())\n    params = clf.get_params()\n    assert 'logisticregression' in params\n    assert 'steps' in params\n\n    # Check that the returned parameters are not a view on the internal\n    # state of the object, but a fresh copy.\n    orig_params = clf.get_params(deep=True)\n    orig_params['logisticregression__C'] = 42\n    new_params = clf.get_params(deep=True)\n    assert new_params['logisticregression__C'] != 42\n"], "sample_813": ["def test_bayesian_ridge_with_sample_weights():\n    # Test BayesianRidge with sample weights\n    X = np.array([[1, 1], [3, 4], [5, 7], [4, 1], [2, 6], [3, 10], [3, 2]])\n    y = np.array([1, 2, 3, 2, 0, 4, 5]).T\n    w = np.array([4, 3, 3, 1, 1, 2, 3]).T\n\n    # Fit model without sample weights\n    br_model = BayesianRidge(compute_score=True).fit(X, y)\n\n    # Fit model with sample weights\n    br_model_weighted = BayesianRidge(compute_score=True).fit(X, y, sample_weight=w)\n\n    # Check that the models are not identical\n    assert_not_equal(br_model.coef_, br_model_weighted.coef_)\n    assert_not_equal(br_model.intercept_, br_model_weighted.intercept_)\n"], "sample_815": ["def test_balanced_accuracy_score_binary():\n    y_true = [0, 1, 0, 0, 1, 0]\n    y_pred = [0, 1, 0, 0, 0, 1]\n\n    # Calculate balanced accuracy manually\n    tp = sum(1 for t, p in zip(y_true, y_pred) if t == p == 1)\n    tn = sum(1 for t, p in zip(y_true, y_pred) if t == p == 0)\n    fp = sum(1 for t, p in zip(y_true, y_pred) if t == 0 and p == 1)\n    fn = sum(1 for t, p in zip(y_true, y_pred) if t == 1 and p == 0)\n\n    recall_p = tp / (tp + fn)\n    recall_n = tn / (tn + fp)\n    balanced_accuracy = (recall_p + recall_n) / 2\n\n    assert_almost_equal(balanced_accuracy_score(y_true, y_pred), balanced_accuracy)\n"], "sample_816": ["def test_countvectorizer_empty_input():\n    # Test that CountVectorizer can handle empty input\n    cv = CountVectorizer()\n    X = cv.fit_transform([])\n    assert_equal(X.shape, (0, 0))\n    assert_equal(cv.vocabulary_, {})\n"], "sample_817": ["def test_variance_threshold_sparse():\n    # Test VarianceThreshold with sparse matrix and custom variance.\n    X = csr_matrix([[0, 1, 2, 3], [0, 2, 2, 3]])\n    sel = VarianceThreshold(threshold=.4).fit(X)\n    assert_array_equal([1, 3], sel.get_support(indices=True))\n"], "sample_819": ["def test_voting_regressor_get_params():\n    \"\"\"Test that VotingRegressor get_params returns the correct estimators\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor()\n    ereg = VotingRegressor([('lr', reg1), ('rf', reg2)])\n    params = ereg.get_params()\n    assert 'lr' in params\n    assert 'rf' in params\n    assert params['lr'] is reg1\n    assert params['rf'] is reg2\n"], "sample_820": ["def test_voting_classifier_get_params():\n    \"\"\"Check the get_params method of VotingClassifier.\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    eclf = VotingClassifier(estimators=[\n                ('lr', clf1), ('rf', clf2)],\n                voting='soft',\n                weights=[1, 2],\n                n_jobs=2,\n                flatten_transform=True)\n\n    params = eclf.get_params()\n    assert 'estimators' in params\n    assert 'voting' in params\n    assert 'weights' in params\n    assert 'n_jobs' in params\n    assert 'flatten_transform' in params\n\n    assert params['voting'] == 'soft'\n    assert params['weights'] == [1, 2]\n    assert params['n_jobs'] == 2\n    assert params['flatten_transform'] is True\n\n    # check that estimators are returned as a list of tuples\n    assert isinstance(params['estimators'], list)\n    for estimator in params['estimators']:\n        assert isinstance(estimator, tuple)\n        assert len(estimator) == 2\n        assert isinstance(estimator[0], str)\n        assert isinstance(estimator[1], BaseEstimator)\n"], "sample_821": ["def test_affinity_propagation_return_n_iter():\n    # Test that the number of iterations is returned when return_n_iter=True\n    S = -euclidean_distances(X, squared=True)\n    preference = np.median(S) * 10\n    cluster_centers_indices, labels, n_iter = affinity_propagation(\n        S, preference=preference, return_n_iter=True)\n\n    assert isinstance(n_iter, int)\n    assert n_iter > 0\n\n    af = AffinityPropagation(preference=preference, affinity=\"precomputed\")\n    af.fit(S)\n    assert hasattr(af, 'n_iter_')\n    assert af.n_iter_ == n_iter\n"], "sample_825": ["def test_pls_predict_shape():\n    # Test that predict returns a 2D array even when Y is univariate\n    d = load_linnerud()\n    X = d.data\n    Y = d.target[:, 0]  # Univariate target\n    pls = pls_.PLSRegression(n_components=2)\n    pls.fit(X, Y)\n    y_pred = pls.predict(X)\n    assert y_pred.ndim == 2\n    assert y_pred.shape[1] == 1\n"], "sample_826": ["def test_ordinal_encoder_set_params():\n    X = np.array([['a', 'b']], dtype=object).T\n\n    enc = OrdinalEncoder()\n    enc.fit(X)\n\n    # set params on already fitted object\n    enc.set_params(categories=[['a', 'b', 'c']])\n    assert enc.get_params()['categories'] == [['a', 'b', 'c']]\n    assert_array_equal(enc.transform([['a'], ['b']]), [[0.], [1.]])\n"], "sample_827": ["def test_inplace_csr_row_normalize_l1_zeros():\n    X = sp.csr_matrix(np.array([[0, 3, 0],\n                                [2, -1, 0],\n                                [0, 0, 0],\n                                [9, 8, 7],\n                                [4, 0, 5]], dtype=np.float64))\n    inplace_csr_row_normalize_l1(X)\n    assert_array_almost_equal(np.abs(X).sum(axis=1), np.ones((X.shape[0], 1)))\n    assert_array_almost_equal(X.toarray()[2], np.zeros((1, X.shape[1])))\n"], "sample_829": ["def test_incremental_pca_batch_size_none():\n    # Test that batch_size=None is handled correctly\n    rng = np.random.RandomState(1999)\n    n_samples = 100\n    n_features = 3\n    X = rng.randn(n_samples, n_features)\n\n    ipca = IncrementalPCA(n_components=2, batch_size=None)\n    ipca.fit(X)\n\n    assert ipca.batch_size_ == 5 * n_features\n    assert ipca.components_.shape == (2, n_features)\n"], "sample_830": ["def test_get_blas_info():\n    blas_info = _get_blas_info()\n\n    assert 'macros' in blas_info\n    assert 'lib_dirs' in blas_info\n    assert 'cblas_libs' in blas_info\n"], "sample_831": ["def test_plot_tree_multiclass(pyplot):\n    # mostly smoke tests\n    # Check correctness of export_graphviz for multiclass\n    clf = DecisionTreeClassifier(max_depth=3,\n                                 min_samples_split=2,\n                                 criterion=\"gini\",\n                                 random_state=2)\n    y_multiclass = [0, 0, 0, 1, 1, 2]\n    clf.fit(X, y_multiclass)\n\n    # Test export code\n    feature_names = ['first feat', 'sepal_width']\n    nodes = plot_tree(clf, feature_names=feature_names)\n    assert len(nodes) == 5\n    assert nodes[0].get_text() == (\"first feat <= 0.0\\ngini = 0.6667\\n\"\n                                   \"samples = 6\\nvalue = [3, 2, 1]\")\n    assert nodes[1].get_text() == \"gini = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]\"\n    assert nodes[2].get_text() == (\"first feat <= 1.5\\ngini = 0.5\\n\"\n                                   \"samples = 3\\nvalue = [0, 2, 1]\")\n    assert nodes[3].get_text() == \"gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]\"\n    assert nodes[4].get_text() == \"gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]\"\n"], "sample_832": ["def test_bayesian_ridge_init_parameters():\n    # Test BayesianRidge with different initial values (alpha_init, lambda_init)\n    X = np.vander(np.linspace(0, 4, 5), 4)\n    y = np.array([0., 1., 0., -1., 0.])    # y = (x^3 - 6x^2 + 8x) / 3\n\n    # In this case, starting from the default initial values will increase\n    # the bias of the fitted curve. So, lambda_init should be small.\n    reg1 = BayesianRidge(alpha_init=1., lambda_init=1e-3)\n    reg2 = BayesianRidge(alpha_init=1., lambda_init=1.)\n    reg3 = BayesianRidge(alpha_init=0.1, lambda_init=1e-3)\n\n    # Check that different initial parameters lead to different scores\n    score1 = reg1.fit(X, y).score(X, y)\n    score2 = reg2.fit(X, y).score(X, y)\n    score3 = reg3.fit(X, y).score(X, y)\n    assert not np.isclose(score1, score2)\n    assert not np.isclose(score1, score3)\n    assert not np.isclose(score2, score3)\n"], "sample_833": ["def test_logistic_regression_path_multiclass():\n    # Test that logistic_regression_path returns the correct coefs for\n    # multiclass classification.\n    X, y = make_classification(n_samples=200, n_classes=3, n_informative=2,\n                               n_redundant=0, n_clusters_per_class=1,\n                               random_state=0, n_features=2)\n    Cs = [.00001, 1, 10000]\n    coefs, _, _ = _logistic_regression_path(X, y, penalty='l1', Cs=Cs,\n                                            solver='saga', random_state=0,\n                                            multi_class='multinomial')\n    assert coefs.shape == (3, len(Cs), X.shape[1] + 1)\n"], "sample_834": ["def test_components_shape():\n    \"\"\"Test that the components_ attribute has the expected shape.\"\"\"\n    X = iris_data\n    y = iris_target\n\n    nca = NeighborhoodComponentsAnalysis(n_components=2)\n    nca.fit(X, y)\n\n    assert_equal(nca.components_.shape, (2, X.shape[1]))\n"], "sample_835": ["def test_adaboost_regressor_with_constant_target():\n    # Check that AdaBoostRegressor works with constant target values.\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([5, 5, 5])\n\n    model = AdaBoostRegressor()\n    model.fit(X, y)\n\n    assert_array_almost_equal(model.predict(X), y)\n"], "sample_836": ["def test_class_distribution_with_sparse_and_weights():\n    # Test class_distribution with sparse matrix and sample weights\n\n    y = sp.csr_matrix(np.array([[1, 0, 0, 1],\n                                [2, 2, 0, 1],\n                                [1, 3, 0, 1],\n                                [4, 2, 0, 1],\n                                [2, 0, 0, 1],\n                                [1, 3, 0, 1]]))\n\n    sample_weight = np.array([1.0, 2.0, 1.0, 2.0, 1.0, 2.0])\n\n    classes, n_classes, class_prior = class_distribution(y)\n    classes_sw, n_classes_sw, class_prior_sw = class_distribution(y, sample_weight)\n\n    assert_array_almost_equal(classes, classes_sw)\n    assert_array_almost_equal(n_classes, n_classes_sw)\n    assert not np.array_equal(class_prior, class_prior_sw)\n"], "sample_837": ["def test_get_blas_info():\n    blas_info = _get_blas_info()\n\n    assert 'macros' in blas_info\n    assert 'lib_dirs' in blas_info\n    assert 'cblas_libs' in blas_info\n"], "sample_839": ["def test_vectorizer_empty_input():\n    # Test that vectorizers can handle empty input\n    vectorizers = [\n        CountVectorizer(),\n        TfidfVectorizer(),\n        HashingVectorizer()\n    ]\n\n    for vec in vectorizers:\n        X = vec.fit_transform([])\n        assert X.shape == (0, 0)\n        if not isinstance(vec, HashingVectorizer):\n            assert vec.vocabulary_ == {}\n"], "sample_840": ["def test_pls_predict_shape():\n    # Test that predict returns correct shape\n    d = load_linnerud()\n    X = d.data\n    Y = d.target\n    for clf in [pls_.PLSCanonical(), pls_.PLSRegression(),\n                pls_.PLSSVD()]:\n        clf.fit(X, Y)\n        assert clf.predict(X).shape == Y.shape\n"], "sample_841": ["def test_ridge_saga_solver_convergence():\n    # Test that the SAGA solver converges to the same solution as the\n    # Cholesky solver for a wide range of alpha values.\n    X, y = make_regression(n_samples=100, n_features=10, random_state=42)\n    alphas = np.logspace(-5, 5, 10)\n\n    for alpha in alphas:\n        saga_ridge = Ridge(alpha=alpha, solver='saga', max_iter=1000,\n                           tol=1e-8, random_state=42)\n        cholesky_ridge = Ridge(alpha=alpha, solver='cholesky')\n        saga_ridge.fit(X, y)\n        cholesky_ridge.fit(X, y)\n        assert_allclose(saga_ridge.coef_, cholesky_ridge.coef_, atol=1e-4)\n        assert_allclose(saga_ridge.intercept_, cholesky_ridge.intercept_,\n                        atol=1e-4)\n"], "sample_842": ["def test_kernel_str(kernel):\n    # Smoke-test for str in kernels.\n\n    str(kernel)\n"], "sample_843": ["def test_kernel_operator_composition():\n    # Test that kernel operators can be composed.\n    kernel1 = RBF(length_scale=2.0)\n    kernel2 = ConstantKernel(constant_value=3.0)\n    kernel3 = WhiteKernel(noise_level=4.0)\n\n    kernel_composed = (kernel1 + kernel2) * kernel3\n\n    K_composed = kernel_composed(X)\n    K_expected = (kernel1(X) + kernel2(X)) * kernel3(X)\n\n    assert_almost_equal(K_composed, K_expected)\n"], "sample_845": ["def test_vectorizer_dtype():\n    # Test that the dtype parameter is propagated to the matrix.\n    X = [\"This is a sample document.\", \"Another document for testing.\"]\n    vectorizers = [\n        CountVectorizer(dtype=np.float32),\n        TfidfVectorizer(dtype=np.float64),\n        HashingVectorizer(dtype=np.int32)\n    ]\n\n    for v in vectorizers:\n        X_trans = v.fit_transform(X)\n        assert X_trans.dtype == v.dtype\n"], "sample_847": ["def test_lassoCV_sparse_input_dtype():\n    X, y, _, _ = build_dataset(n_features=10)\n    clf = LassoCV(n_alphas=5)\n    clf.fit(sparse.csr_matrix(X), y)\n    clf1 = LassoCV(n_alphas=5)\n    clf1.fit(sparse.csr_matrix(X, dtype=np.float32), y)\n    assert_almost_equal(clf.alpha_, clf1.alpha_, decimal=6)\n    assert_almost_equal(clf.coef_, clf1.coef_, decimal=6)\n"], "sample_848": ["def test_multi_output_regressor_sample_weights_api():\n    X = [[1, 2, 3], [4, 5, 6]]\n    y = [[3.141, 2.718], [2.718, 3.141]]\n    w = [0.8, 0.6]\n\n    rgr = MultiOutputRegressor(Lasso())\n    assert_raises_regex(ValueError, \"does not support sample weights\",\n                        rgr.fit, X, y, w)\n\n    # no exception should be raised if the base estimator supports weights\n    rgr = MultiOutputRegressor(GradientBoostingRegressor(random_state=0))\n    rgr.fit(X, y, w)\n"], "sample_850": ["def test_nystroem_invalid_kernel():\n    # Test Nystroem with an invalid kernel.\n    rnd = np.random.RandomState(42)\n    X = rnd.uniform(size=(10, 4))\n\n    msg = \"Invalid kernel name 'invalid_kernel'\"\n\n    with pytest.raises(ValueError, match=msg):\n        Nystroem(kernel='invalid_kernel', n_components=X.shape[0]).fit(X)\n\n    msg = \"Kernel must be a callable or one of the predefined kernels.\"\n\n    with pytest.raises(ValueError, match=msg):\n        Nystroem(kernel=None, n_components=X.shape[0]).fit(X)\n\n    msg = \"Kernel must be a callable or one of the predefined kernels.\"\n\n    with pytest.raises(ValueError, match=msg):\n        Nystroem(kernel=1, n_components=X.shape[0]).fit(X)\n"], "sample_851": ["def test_mean_poisson_deviance():\n    y_true = np.array([1, 2, 3, 4])\n    y_pred = np.array([1.5, 2.5, 3.5, 4.5])\n\n    # Test that mean Poisson deviance is equivalent to mean Tweedie deviance\n    # with power=1\n    assert_almost_equal(mean_poisson_deviance(y_true, y_pred),\n                        mean_tweedie_deviance(y_true, y_pred, power=1))\n\n    # Test that mean Poisson deviance raises an error when y_true contains\n    # negative values\n    y_true_negative = np.array([1, -2, 3, 4])\n    msg = \"Mean Poisson deviance can only be used on non-negative y_true.\"\n    with pytest.raises(ValueError, match=msg):\n        mean_poisson_deviance(y_true_negative, y_pred)\n\n    # Test that mean Poisson deviance raises an error when y_pred contains\n    # non-positive values\n    y_pred_non_positive = np.array([1.5, 0, 3.5, 4.5])\n    msg = \"Mean Poisson deviance can only be used on strictly positive y_pred.\"\n    with pytest.raises(ValueError, match=msg):\n        mean_poisson_deviance(y_true, y_pred_non_positive)\n"], "sample_853": ["def test_transform_target_regressor_check_inverse_with_2d_transformer():\n    # Check that the check_inverse parameter works correctly with a 2D transformer\n    X, y = friedman\n    transformer = StandardScaler()\n    regr = TransformedTargetRegressor(regressor=LinearRegression(),\n                                      transformer=transformer,\n                                      check_inverse=True)\n    regr.fit(X, y)\n\n    # Modify the transformer to make it non-invertible\n    regr.transformer_.scale_ *= 2\n\n    with pytest.raises(UserWarning, match=\"The provided functions or transformer are not strictly inverse of each other\"):\n        regr.fit(X, y)\n"], "sample_854": ["def test_libsvm_sparse_input():\n    # Test that sparse input to libsvm raises an informative error message\n    X = sparse.csr_matrix(np.array([[0, 1], [1, 0]]))\n    y = np.array([0, 1])\n\n    clf = svm.SVC(kernel='precomputed')\n    with pytest.raises(TypeError, match=\"Sparse precomputed kernels are not supported\"):\n        clf.fit(X, y)\n"], "sample_855": ["def test_dummy_classifier_sparse_output():\n    X = [[0]] * 5  # ignored\n    y = sp.csc_matrix(np.array([[1, 0],\n                                [1, 3],\n                                [4, 0],\n                                [0, 1],\n                                [1, 0]]))\n\n    clf = DummyClassifier(strategy=\"most_frequent\", random_state=0)\n    clf.fit(X, y)\n\n    assert clf.sparse_output_\n    y_pred = clf.predict(X)\n    assert sp.issparse(y_pred)\n"], "sample_857": ["def test_prune_tree_ccp_alpha_not_affecting_fitting():\n    # ccp_alpha should not affect the structure of the initial tree before\n    # pruning. It only serves as a pruning parameter.\n    X, y = iris.data, iris.target\n\n    clf1 = DecisionTreeClassifier(random_state=0)\n    clf1.fit(X, y)\n\n    clf2 = DecisionTreeClassifier(random_state=0, ccp_alpha=10)\n    clf2.fit(X, y)\n\n    assert_tree_equal(clf1.tree_, clf2.tree_)\n"], "sample_858": ["def test_voting_regressor_transform():\n    \"\"\"Check transform method of VotingRegressor on toy dataset.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(random_state=123)\n    X = np.array([[-1.1, -1.5], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n    y = np.array([1, 1, 2, 2])\n\n    ereg = VotingRegressor(estimators=[\n        ('lr', reg1), ('rf', reg2)]).fit(X, y)\n\n    assert_array_equal(ereg.transform(X).shape, (4, 2))\n    assert_array_almost_equal(ereg.transform(X),\n                              np.column_stack((reg1.fit(X, y).predict(X),\n                                               reg2.fit(X, y).predict(X))))\n"], "sample_861": ["def test_grid_search_cv_results_rank_tie_breaking_with_refit_callable():\n    X, y = make_blobs(n_samples=50, random_state=42)\n\n    # The two C values are close enough to give similar models\n    # which would result in a tie of their mean cv-scores\n    param_grid = {'C': [1, 1.001, 0.001]}\n\n        return cv_results['mean_test_score'].argmin()\n\n    grid_search = GridSearchCV(SVC(), param_grid=param_grid,\n                               return_train_score=True, refit=refit_callable)\n    grid_search.fit(X, y)\n    cv_results = grid_search.cv_results_\n    # Check tie breaking strategy -\n    # Check that there is a tie in the mean scores between\n    # candidates 1 and 2 alone\n    assert_almost_equal(cv_results['mean_test_score'][0],\n                        cv_results['mean_test_score'][1])\n    assert_almost_equal(cv_results['mean_train_score'][0],\n                        cv_results['mean_train_score'][1])\n    assert not np.allclose(cv_results['mean_test_score'][1],\n                           cv_results['mean_test_score'][2])\n    assert not np.allclose(cv_results['mean_train_score'][1],\n                           cv_results['mean_train_score'][2])\n    # 'min' rank should be assigned to the tied candidates\n    assert_almost_equal(grid_search.cv_results_['rank_test_score'], [1, 1, 3])\n"], "sample_862": ["def test_tfidfvectorizer_dtype():\n    # Test that TfidfVectorizer produces the correct dtype\n    X = [\"This is a sample document.\", \"Another example document.\"]\n    vectorizer = TfidfVectorizer(dtype=np.float32)\n    X_tfidf = vectorizer.fit_transform(X)\n    assert X_tfidf.dtype == np.float32\n\n    vectorizer = TfidfVectorizer(dtype=np.float64)\n    X_tfidf = vectorizer.fit_transform(X)\n    assert X_tfidf.dtype == np.float64\n"], "sample_864": ["def test_mean_shift_single_seed():\n    # Test _mean_shift_single_seed function\n    my_mean = np.array([1, 1])\n    X = np.array([[1, 1], [2, 1], [1, 0],\n                  [4, 7], [3, 5], [3, 6]])\n    nbrs = NearestNeighbors(radius=2).fit(X)\n    max_iter = 300\n\n    result = _mean_shift_single_seed(my_mean, X, nbrs, max_iter)\n\n    assert isinstance(result, tuple)\n    assert len(result) == 3\n    assert isinstance(result[0], tuple)\n    assert isinstance(result[1], int)\n    assert isinstance(result[2], int)\n"], "sample_865": ["def test_prune_tree_with_sample_weight():\n    # Test pruning with sample weights.\n    X = np.array([[0, 0], [1, 1], [2, 2], [3, 3]])\n    y = np.array([0, 0, 1, 1])\n    sample_weight = np.array([1, 1, 2, 2])\n\n    clf = DecisionTreeClassifier(random_state=0)\n    clf.fit(X, y, sample_weight=sample_weight)\n\n    path = clf.cost_complexity_pruning_path(X, y, sample_weight=sample_weight)\n    ccp_alphas = path.ccp_alphas\n    impurities = path.impurities\n\n    assert np.all(np.diff(ccp_alphas) >= 0)\n    assert np.all(np.diff(impurities) >= 0)\n\n    for alpha in ccp_alphas:\n        clf_ccp = DecisionTreeClassifier(random_state=0, ccp_alpha=alpha)\n        clf_ccp.fit(X, y, sample_weight=sample_weight)\n        assert_is_subtree(clf.tree_, clf_ccp.tree_)\n"], "sample_866": ["def test_affinity_propagation_verbose():\n    # Test AffinityPropagation with verbose output\n    af = AffinityPropagation(verbose=True)\n    with pytest.raises(ValueError):\n        af.fit(np.array([[1, 2], [3, 4]]))\n    af.fit(np.array([[1, 2], [1, 4], [1, 0],\n                     [4, 2], [4, 4], [4, 0]]))\n"], "sample_867": ["def test_search_cv__estimator_type_property_delegated_to_base_estimator():\n    \"\"\"\n    Test implementation of BaseSearchCV has the _estimator_type property\n    which matches the _estimator_type property of its estimator.\n    This test make sure _estimator_type is delegated to the base estimator.\n\n    Non-regression test for issue #13920.\n    \"\"\"\n    est = BaseEstimator()\n    attr_message = \"BaseSearchCV _estimator_type property must match estimator\"\n\n    for _estimator_type_setting in ['classifier', 'regressor']:\n        setattr(est, '_estimator_type', _estimator_type_setting)\n        cv = GridSearchCV(est, {'n_neighbors': [10]})\n        assert _estimator_type_setting == cv._estimator_type, attr_message\n"], "sample_870": ["def test_gpr_predict_multioutput_std():\n    \"\"\"\n    Check that the output shape of `predict` with return_std=True is correct for\n    multi-output GPR.\n\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/22174\n    \"\"\"\n    rng = np.random.RandomState(1234)\n\n    n_features, n_samples_train, n_samples_test = 6, 9, 7\n    n_targets = 3\n\n    X_train = rng.randn(n_samples_train, n_features)\n    X_test = rng.randn(n_samples_test, n_features)\n    y_train = rng.randn(n_samples_train, n_targets)\n\n    model = GaussianProcessRegressor()\n    model.fit(X_train, y_train)\n\n    y_mean, y_std = model.predict(X_test, return_std=True)\n\n    assert y_mean.shape == (n_samples_test, n_targets)\n    assert y_std.shape == (n_samples_test, n_targets)\n"], "sample_871": ["def test_calinski_harabasz_score_sparse_input():\n    # Assert the function works with sparse input\n    from scipy.sparse import csr_matrix\n\n    X = csr_matrix(np.array([[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5))\n    labels = [0] * 10 + [1] * 10\n    pytest.approx(calinski_harabasz_score(X, labels), 45 * (40 - 4) / (5 * (4 - 1)))\n"], "sample_872": ["def test_roc_auc_score_average_parameter():\n    # Test that roc_auc_score function returns an error when the 'average'\n    # parameter is not one of [None, 'micro', 'macro', 'weighted', 'samples']\n    rng = check_random_state(404)\n    y_pred = rng.rand(10)\n    y_true = np.array([0] * 5 + [1] * 5)\n\n    with pytest.raises(ValueError):\n        roc_auc_score(y_true, y_pred, average=\"somethingelse\")\n"], "sample_873": ["def test_get_feature_names_out():\n    sel = StepSelector()\n    sel.fit(X, y)\n    assert_array_equal(feature_names_t, sel.get_feature_names_out())\n    assert_array_equal(feature_names_t, sel.get_feature_names_out(input_features=feature_names))\n"], "sample_876": ["def test_mlp_classifier_predict_proba_output_shape():\n    # Test that predict_proba outputs a 2D array with correct shape\n    X = X_digits_binary[:50]\n    y = y_digits_binary[:50]\n\n    clf = MLPClassifier(hidden_layer_sizes=5, activation=\"logistic\", random_state=1)\n    with ignore_warnings(category=ConvergenceWarning):\n        clf.fit(X, y)\n\n    y_proba = clf.predict_proba(X)\n    assert y_proba.shape == (X.shape[0], np.unique(y).size)\n"], "sample_877": ["def test_isotonic_regression_increasing_parameter_validation():\n    \"\"\"Check that `increasing` parameter is validated correctly.\"\"\"\n    X = np.arange(10)\n    y = np.arange(10)\n\n    # Test that valid values do not raise an error\n    IsotonicRegression(increasing=True).fit(X, y)\n    IsotonicRegression(increasing=False).fit(X, y)\n    IsotonicRegression(increasing=\"auto\").fit(X, y)\n\n    # Test that invalid values raise a ValueError\n    msg = r\"increasing must be 'auto', True or False.\"\n    with pytest.raises(ValueError, match=msg):\n        IsotonicRegression(increasing=None).fit(X, y)\n    with pytest.raises(ValueError, match=msg):\n        IsotonicRegression(increasing=\"invalid\").fit(X, y)\n    with pytest.raises(ValueError, match=msg):\n        IsotonicRegression(increasing=1).fit(X, y)\n"], "sample_879": ["def test_one_hot_encoder_get_feature_names_out_with_infrequent():\n    \"\"\"Check get_feature_names_out with infrequent categories.\"\"\"\n    X = np.array([[\"a\"] * 5 + [\"b\"] * 20 + [\"c\"] * 10 + [\"d\"] * 3]).T\n    ohe = OneHotEncoder(\n        handle_unknown=\"infrequent_if_exist\",\n        sparse_output=False,\n        max_categories=2,\n    ).fit(X)\n\n    feature_names = ohe.get_feature_names_out()\n    assert_array_equal([\"x0_b\", \"x0_infrequent_sklearn\"], feature_names)\n"], "sample_881": ["def test_roc_auc_score_average_parameter():\n    # Test that roc_auc_score function returns an error when trying\n    # to compute average ROC AUC for parameters where an output\n    # is not defined.\n    rng = check_random_state(404)\n    y_true = rng.randint(0, 2, size=10)\n    y_pred = rng.rand(10)\n\n    with pytest.raises(ValueError):\n        roc_auc_score(y_true, y_pred, average=\"samples\")\n    with pytest.raises(ValueError):\n        roc_auc_score(y_true, y_pred, average=\"weighted\")\n    with pytest.raises(ValueError):\n        roc_auc_score(y_true, y_pred, average=None)\n"], "sample_882": ["def test_mlp_classifier_multiclass_partial_fit():\n    \"\"\"Check that partial fit works with multiclass classification.\"\"\"\n    X, y = make_classification(n_samples=100, n_features=10, n_informative=5, n_redundant=0, n_classes=3)\n    mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1, random_state=42)\n    for _ in range(10):\n        mlp.partial_fit(X, y, classes=np.unique(y))\n    assert mlp.score(X, y) > 0.8\n"], "sample_883": ["def test_bayesian_ridge_ard_with_zero_variance_target():\n    # Test BayesianRidge and ARDRegression when target has zero variance.\n    X = np.array([[1, 1], [3, 4], [5, 7], [4, 1], [2, 6], [3, 10], [3, 2]])\n    y = np.array([1, 1, 1, 1, 1, 1, 1]).T\n\n    for clf in [BayesianRidge(), ARDRegression()]:\n        clf.fit(X, y)\n        assert clf.alpha_ > 0\n        assert clf.lambda_ > 0\n        assert clf.coef_.shape == (X.shape[1],)\n"], "sample_884": ["def test_deprecated_property():\n    with pytest.warns(FutureWarning, match=\"n_features_ is deprecated\"):\n        MockClass2().n_features_\n    assert MockClass2().n_features_ == 10\n"], "sample_886": ["def test__wrap_in_pandas_container_columns_none():\n    \"\"\"Check _wrap_in_pandas_container with columns=None.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    X_df = pd.DataFrame(X)\n\n    # If X is a DataFrame and columns=None, then the column names are not changed.\n    wrapped_X_df = _wrap_in_pandas_container(X_df, columns=None)\n    assert_array_equal(wrapped_X_df.columns, X_df.columns)\n\n    # If X is not a DataFrame and columns=None, then the column names are range(n_features).\n    wrapped_X = _wrap_in_pandas_container(X, columns=None)\n    assert_array_equal(wrapped_X.columns, range(X.shape[1]))\n"], "sample_887": ["def test_calibration_display_with_invalid_estimator_name(pyplot, iris_data_binary):\n    \"\"\"Check that an error is raised when passing an invalid estimator name.\"\"\"\n    X, y = iris_data_binary\n\n    lr = LogisticRegression().fit(X, y)\n    msg = \"Invalid 'name' should be a string.\"\n    with pytest.raises(ValueError, match=msg):\n        CalibrationDisplay.from_estimator(lr, X, y, name=123)\n\n    msg = \"Invalid 'name' should not be empty.\"\n    with pytest.raises(ValueError, match=msg):\n        CalibrationDisplay.from_estimator(lr, X, y, name=\"\")\n"], "sample_888": ["def test_iforest_feature_names_outliers():\n    \"\"\"Check that feature names are preserved when predicting outliers.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    rng = np.random.RandomState(0)\n\n    X = pd.DataFrame(data=rng.randn(10, 2), columns=[\"a\", \"b\"])\n    model = IsolationForest(random_state=0)\n\n    model.fit(X)\n    outliers = pd.DataFrame(data=rng.randn(5, 2), columns=[\"a\", \"b\"])\n\n    # Check that feature names are preserved when predicting outliers\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\", UserWarning)\n        model.predict(outliers)\n"], "sample_889": ["def test_calibration_display_with_invalid_estimator_name(pyplot, iris_data_binary):\n    \"\"\"Check that `CalibrationDisplay` raises an error when the estimator name is not a string.\"\"\"\n    X, y = iris_data_binary\n    lr = LogisticRegression().fit(X, y)\n    with pytest.raises(TypeError, match=\"estimator_name must be a string\"):\n        CalibrationDisplay.from_estimator(lr, X, y, name=123)\n"], "sample_890": ["def test_get_support_mask():\n    # Make sure get_support_mask returns a boolean mask of shape (# input features,)\n\n    X, y = make_regression(n_features=10)\n    sfs = SequentialFeatureSelector(\n        LinearRegression(), n_features_to_select=\"auto\", cv=2\n    )\n    sfs.fit(X, y)\n    support_mask = sfs.get_support_mask()\n    assert support_mask.dtype == bool\n    assert support_mask.shape == (X.shape[1],)\n"], "sample_892": ["def test_adaboost_regressor_with_constant_target():\n    # Check that AdaBoostRegressor works with constant target.\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([5, 5])\n    model = AdaBoostRegressor()\n    model.fit(X, y)\n    assert_array_almost_equal(model.predict(X), y)\n"], "sample_893": ["def test_plot_tree_filled(pyplot):\n    # mostly smoke tests\n    # Check correctness of export_graphviz for filled option\n    clf = DecisionTreeClassifier(\n        max_depth=3, min_samples_split=2, criterion=\"gini\", random_state=2\n    )\n    clf.fit(X, y)\n\n    # Test export code\n    feature_names = [\"first feat\", \"sepal_width\"]\n    nodes = plot_tree(clf, feature_names=feature_names, filled=True)\n    assert len(nodes) == 3\n    assert (\n        nodes[0].get_text()\n        == \"first feat <= 0.0\\ngini = 0.5\\nsamples = 6\\nvalue = [3, 3]\"\n    )\n    assert nodes[1].get_text() == \"gini = 0.0\\nsamples = 3\\nvalue = [3, 0]\"\n    assert nodes[2].get_text() == \"gini = 0.0\\nsamples = 3\\nvalue = [0, 3]\"\n    # check if the boxes are filled with the correct colors\n    assert nodes[0].get_bbox_patch().get_facecolor() == (1.0, 1.0, 1.0, 1.0)\n    assert nodes[1].get_bbox_patch().get_facecolor() == (0.9333333333333333, 0.5098039215686274, 0.9333333333333333, 1.0)\n    assert nodes[2].get_bbox_patch().get_facecolor() == (0.596078431372549, 0.8745098039215686, 0.8862745098039215, 1.0)\n"], "sample_894": ["def test_forest_max_features_auto():\n    # Check that the new default value of `max_features` is 'sqrt' for classification and '1.0' for regression.\n    X, y = make_classification(n_samples=100, n_features=10, random_state=0)\n    clf = RandomForestClassifier()\n    clf.fit(X, y)\n    assert clf.max_features == \"sqrt\"\n\n    X, y = make_regression(n_samples=100, n_features=10, random_state=0)\n    reg = RandomForestRegressor()\n    reg.fit(X, y)\n    assert reg.max_features == 1.0\n"], "sample_898": ["def test_auc_score_non_increasing_scores():\n    # Test AUC score with non-increasing scores\n\n    y_true = np.array([0, 1, 1, 0, 1])\n    y_score = np.array([0.2, 0.8, 0.6, 0.4, 0.9])\n\n    # Check that AUC is computed correctly when scores are not increasing\n    auc = roc_auc_score(y_true, y_score)\n    assert_almost_equal(auc, 0.88)\n\n    # Check that AUC is computed correctly when scores are not increasing and\n    # sample weights are provided\n    sample_weight = np.array([1, 2, 3, 4, 5])\n    auc = roc_auc_score(y_true, y_score, sample_weight=sample_weight)\n    assert_almost_equal(auc, 0.86)\n"], "sample_900": ["def test_mlpclassifier_partial_fit_classes():\n    # Test that the `classes_` attribute is set after calling partial_fit.\n    X = [[3, 2], [1, 6]]\n    y = [0, 1]\n    clf = MLPClassifier(solver='sgd')\n    assert not hasattr(clf, 'classes_')\n    clf.partial_fit(X, y, classes=[0, 1])\n    assert_array_equal(clf.classes_, [0, 1])\n"], "sample_901": ["def test_k_means_init_centers_dtype():\n    # This test is used to check KMeans won't mutate the user provided input\n    # array silently even if input data and init centers have different types\n    X_small = np.array([[1.1, 1.1], [-7.5, -7.5], [-1.1, -1.1], [7.5, 7.5]])\n    init_centers = np.array([[0.0, 0.0], [5.0, 5.0], [-5.0, -5.0]], dtype=np.float32)\n    for dtype in [np.int32, np.int64, np.float64]:\n        X_test = dtype(X_small)\n        km = KMeans(init=init_centers, n_clusters=3, n_init=1)\n        km.fit(X_test)\n        assert np.may_share_memory(km.cluster_centers_,\n                                   init_centers) is False\n        assert km.cluster_centers_.dtype == X_test.dtype\n"], "sample_902": ["def test_pipeline_get_params():\n    # Test that get_params returns all parameters of the estimators\n    mult2 = Mult(2)\n    mult3 = Mult(3)\n    pipeline = Pipeline([('m1', mult2), ('m2', mult3)])\n\n    params = pipeline.get_params()\n    assert 'm1' in params\n    assert 'm2' in params\n    assert 'm1__mult' in params\n    assert 'm2__mult' in params\n\n    assert params['m1'] is mult2\n    assert params['m2'] is mult3\n    assert params['m1__mult'] == 2\n    assert params['m2__mult'] == 3\n"], "sample_904": ["def test_get_full_qualified_name_for_option_with_subcommand(app):\n    env = mock.Mock(domaindata={})\n    env.app.registry.enumerable_nodes = {}\n    domain = StandardDomain(env)\n\n    node = nodes.reference(reftype='option', reftarget='-l', **{'std:program': 'ls dir'})\n    assert domain.get_full_qualified_name(node) == 'ls-dir.-l'\n"], "sample_908": ["def test_unparse_arguments(source, expected):\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].args) == expected\n"], "sample_909": ["def test_usage_section(self):\n    docstring = \"\"\"\\"], "sample_912": ["def test_pyfunction_signature_with_typehints(app):\n    text = \".. py:function:: hello(name: str, age: int) -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, ([desc_parameter, ([desc_sig_name, \"name\"],\n                                                        [desc_sig_punctuation, \":\"],\n                                                        \" \",\n                                                        [nodes.inline, pending_xref, \"str\"])],\n                                      [desc_parameter, ([desc_sig_name, \"age\"],\n                                                        [desc_sig_punctuation, \":\"],\n                                                        \" \",\n                                                        [nodes.inline, pending_xref, \"int\"])]])\n"], "sample_913": ["def test_pyfunction_with_annotation(app):\n    text = \".. py:function:: hello(name: str) -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_punctuation, \":\"],\n                                                      \" \",\n                                                      [nodes.inline, pending_xref, \"str\"])])\n\n    # check annotation is correctly parsed\n    annotation = doctree[1][0][1][0][2]\n    assert annotation.astext() == \": str\"\n    assert annotation.children[0].astext() == \":\"\n    assert annotation.children[2].astext() == \"str\"\n\n    # check return type is correctly parsed\n    returns = doctree[1][0][1][1]\n    assert returns.astext() == \"-> str\"\n    assert returns.children[0].astext() == \"->\"\n    assert returns.children[1].astext() == \"str\"\n"], "sample_914": ["def test_unparse_arguments(source, expected):\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].args) == expected\n"], "sample_916": ["def test_lookup_key():\n    root = Symbol(None, None, None, None)\n    s1 = root.add_name(ASTNestedName([ASTIdentifier(\"S1\")], rooted=False))\n    s2 = s1.add_name(ASTNestedName([ASTIdentifier(\"S2\")], rooted=False))\n    s3 = s2.add_name(ASTNestedName([ASTIdentifier(\"S3\")], rooted=False))\n\n    assert str(s1.get_lookup_key()) == \"[(S1, None)]\"\n    assert str(s2.get_lookup_key()) == \"[(S1, None), (S2, None)]\"\n    assert str(s3.get_lookup_key()) == \"[(S1, None), (S2, None), (S3, None)]\"\n\n    decl = ASTDeclaration('function', 'function', ASTTypeWithInit(\n        ASTType(ASTDeclSpecs('function', ASTDeclSpecsSimple('void', None, False,\n                                                           False, False, []),\n                            ASTDeclSpecsSimple(None, None, False, False, False, []),\n                            ASTTrailingTypeSpecFundamental('int')),\n                     ASTDeclaratorNameParam(\n                         ASTNestedName([ASTIdentifier(\"myFunction\")], rooted=False),\n                         [], None)),\n        None))\n    s4 = s3.add_declaration(decl, docname=\"TestDoc\")\n\n    assert str(s4.get_lookup_key()) == \"[(S1, None), (S2, None), (S3, None), (myFunction, TestDoc::S1::S2::S3::myFunction)]\"\n"], "sample_918": ["def test_pyattribute_with_type_annotation(app):\n    text = (\".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:attribute:: attr: str\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_name, \"Class\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc)])]))\n    assert_node(doctree[1][1][0], addnodes.index,\n                entries=[('single', 'attr (Class attribute)', 'Class.attr', '', None)])\n    assert_node(doctree[1][1][1], ([desc_signature, ([desc_name, \"attr\"],\n                                                     [desc_annotation, (\": \",\n                                                                        [pending_xref, \"str\"])])],\n                                   [desc_content, ()]))\n    assert 'Class.attr' in domain.objects\n    assert domain.objects['Class.attr'] == ('index', 'Class.attr', 'attribute')\n"], "sample_920": ["def test_usage_section(self):\n    docstring = \"\"\"\\"], "sample_925": ["def test_MockObject_repr():\n    mock = _MockObject()\n    assert repr(mock) == '_MockObject'\n    assert repr(mock.some_attr) == '_MockObject.some_attr'\n    assert repr(mock.some_method) == '_MockObject.some_method'\n\n    # subclassing\n    class SubClass(mock.SomeClass):\n        pass\n\n    obj = SubClass()\n    assert repr(obj) == 'SubClass'\n    assert repr(obj.other_method()) == 'SubClass.other_method'\n"], "sample_926": ["def test_type_with_init():\n    check('type', '{key}int i = 42', {1: 'i', 2: '1i'})\n    check('type', '{key}int i(42)', {1: 'i', 2: '1i'})\n    check('type', '{key}int i{42}', {1: 'i', 2: '1i'})\n    check('type', '{key}int i = {42}', {1: 'i', 2: '1i'})\n    check('type', '{key}int i[] = {1, 2, 3}', {1: 'iA', 2: '1i'})\n    check('type', '{key}int i[] = {{1, 2, 3}}', {1: 'iA', 2: '1i'})\n    check('type', '{key}int i[] = {{1, 2, 3}, {4, 5, 6}}', {1: 'iA', 2: '1i'})\n    check('type', '{key}int i[2] = {1, 2, 3}', {1: 'iA2', 2: '1i'})\n    check('type', '{key}int i[2][3] = {{1, 2, 3}, {4, 5, 6}}', {1: 'iA2A3', 2: '1i'})\n    check('type', '{key}int i[] = {1, 2, 3,}', {1: 'iA', 2: '1i'})\n    check('type', '{key}int i[] = {{1, 2, 3}, {4, 5, 6},}', {1: 'iA', 2: '1i'})\n"], "sample_928": ["def test_default_role():\n    docname = 'dummy'\n    name = 'strong'\n\n    with default_role(docname, name):\n        # check if the role is registered\n        assert docutils.roles._roles.get('', None) is not None\n\n    # check if the role is unregistered after context exit\n    assert docutils.roles._roles.get('', None) is None\n"], "sample_929": ["def test_pyclasslike(app):\n    text = (\".. py:class:: Class\\n\"\n            \"   :final:\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"final class \"],\n                                                    [desc_name, \"Class\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"class\",\n                domain=\"py\", objtype=\"class\", noindex=False)\n\n    assert 'Class' in domain.objects\n    assert domain.objects['Class'] == ('index', 'Class', 'class')\n"], "sample_930": ["def test_create_index_with_group_entries(app):\n    text = (\".. index:: single: docutils\\n\"\n            \".. index:: single: Python\\n\"\n            \".. index:: pair: Sphinx; documentation tool\\n\"\n            \".. index:: pair: Sphinx; :+1:\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder, group_entries=False)\n    assert len(index) == 4\n    assert index[0] == ('D', [('docutils', [[('', '#index-0')], [], None])])\n    assert index[1] == ('P', [('Python', [[('', '#index-1')], [], None])])\n    assert index[2] == ('S', [('Sphinx', [[(), ('documentation tool', [('', '#index-2')])], None]),\n                              ('Sphinx', [[(), (':+1:', [('', '#index-3')])], None])])\n    assert index[3] == ('Symbols', [(':+1:', [[], [('Sphinx', [('', '#index-3')])], None])])\n"], "sample_931": ["def test_pydecorator_function(app):\n    text = (\".. py:decorator:: my_decorator\\n\"\n            \"   :module: my_module\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_addname, \"@\"],\n                                                    [desc_name, \"my_decorator\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n\n    assert 'my_module.my_decorator' in domain.objects\n    assert domain.objects['my_module.my_decorator'] == ('index', 'my_module.my_decorator', 'function')\n"], "sample_933": ["def test_should_write_pot_file(app):\n    app.builder.build_all()\n\n    pot_file_path = app.outdir / 'markup.pot'\n    assert pot_file_path.isfile()\n\n    # Test should_write function\n    with pot_file_path.open('r') as f:\n        original_content = f.read()\n\n    # If the content is the same, should_write should return False\n    assert not should_write(str(pot_file_path), original_content)\n\n    # If the content is different, should_write should return True\n    new_content = original_content + '\\nmsgid \"New message\"\\n'\n    assert should_write(str(pot_file_path), new_content)\n"], "sample_936": ["def test_stringify_type_hints_forward_ref():\n    ForwardRefType = ForwardRef('int')\n    assert stringify(ForwardRefType) == \"int\"\n\n    class MyClass:\n        pass\n\n    ForwardRefClass = ForwardRef('MyClass')\n    assert stringify(ForwardRefClass) == \"MyClass\"\n"], "sample_937": ["def test_unparse_arguments(source, expected):\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].args) == expected\n"], "sample_938": ["def test_custom_man_page(app, status, warning):\n    app.build()\n    assert (app.outdir / 'test.5').exists()\n\n    content = (app.outdir / 'test.5').read_text()\n    assert '.TH \"TEST\" \"5\" \"\" \"\" \"\"' in content\n    assert '.SH NAME' in content\n    assert 'Test Manual Page' in content\n    assert '.SH AUTHOR' in content\n    assert 'Author' in content\n"], "sample_941": ["def test_stringify_type_hints_Ellipsis():\n    assert stringify(Ellipsis) == '...'\n"], "sample_943": ["def test_is_excluded(tempdir):\n    outdir = path(tempdir)\n    (outdir / 'testpkg').makedirs()\n    (outdir / 'testpkg' / '__init__.py').write_text('')\n    (outdir / 'testpkg' / 'example.py').write_text('')\n\n    assert is_excluded(str(outdir / 'testpkg' / 'example.py'), [str(outdir / 'testpkg' / 'example.py')])\n    assert not is_excluded(str(outdir / 'testpkg' / 'example.py'), [str(outdir / 'testpkg' / 'other.py')])\n    assert is_excluded(str(outdir / 'testpkg' / 'example.py'), [str(outdir / 'testpkg' / '*')])\n    assert not is_excluded(str(outdir / 'testpkg' / 'example.py'), [str(outdir / 'otherpkg' / '*')])\n"], "sample_944": ["def test_stringify_type_hints_ForwardRef():\n    from typing import ForwardRef  # type: ignore\n    assert stringify(ForwardRef(\"myint\")) == \"myint\"\n"], "sample_949": ["def test_custom_man_page(app, status, warning):\n    app.build()\n    assert (app.outdir / 'custom_name.1').exists()\n\n    content = (app.outdir / 'custom_name.1').read_text()\n    assert '.TH \"CUSTOM_NAME\" \"1\" \"\" \"\"' in content\n    assert '.SH \"NAME\"\\n\\fBCustom Name \\- Custom Description\\fP\\n' in content\n    assert '.SH \"AUTHOR\"\\n\\fBCustom Author\\fP\\n' in content\n"], "sample_953": ["def test_valid_dir(tempdir):\n    d = {'path': tempdir}\n    assert qs.valid_dir(d) is True\n\n    d['sep'] = True\n    assert qs.valid_dir(d) is True\n\n    (tempdir / 'conf.py').touch()\n    assert qs.valid_dir(d) is False\n\n    d['sep'] = False\n    (tempdir / '_static').mkdir()\n    assert qs.valid_dir(d) is False\n\n    d['dot'] = '.'\n    d['master'] = 'index'\n    d['suffix'] = '.rst'\n    (tempdir / 'index.rst').touch()\n    assert qs.valid_dir(d) is False\n"], "sample_954": ["def test_production_list(app, status, warning):\n    app.builder.build_all()\n    content = (app.outdir / 'sphinxtests.1').read_text()\n    assert '.nf\\n' in content\n    assert '.fi\\n' in content\n    assert 'production1 ::= foo bar\\n' in content\n    assert 'production2 ::= baz qux\\n' in content\n"], "sample_955": ["def test_unparse_arguments(source, expected):\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].args, source) == expected\n"], "sample_956": ["def test_resolve_reference_in_domain_by_target(tempdir, app, status, warning):\n    inv_file = tempdir / 'inventory'\n    inv_file.write_bytes(inventory_v2)\n    set_config(app, {\n        'https://docs.python.org/': inv_file,\n    })\n\n    # load the inventory and check if it's done correctly\n    normalize_intersphinx_mapping(app, app.config)\n    load_mappings(app)\n\n    domain = app.env.get_domain('py')\n    node, contnode = fake_node('py', 'func', 'module1.func', 'foo')\n\n    # case sensitive match\n    result = _resolve_reference_in_domain_by_target(None, app.env.intersphinx_inventory, domain, ['py:func'], 'module1.func', node, contnode)\n    assert isinstance(result, nodes.reference)\n\n    # case insensitive match for terms only\n    result = _resolve_reference_in_domain_by_target(None, app.env.intersphinx_inventory, domain, ['std:term'], 'A TERM', node, contnode)\n    assert isinstance(result, nodes.reference)\n\n    # no match\n    result = _resolve_reference_in_domain_by_target(None, app.env.intersphinx_inventory, domain, ['py:func'], 'unknown', node, contnode)\n    assert result is None\n"], "sample_957": ["def test_stringify_type_ForwardRef():\n    from typing import ForwardRef  # type: ignore\n    assert stringify(ForwardRef(\"myint\")) == \"myint\"\n"], "sample_960": ["def test_get_objects(app):\n    text = (\".. py:module:: example\\n\"\n            \".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:method:: meth1\\n\"\n            \"   .. py:method:: meth2\\n\"\n            \"      :classmethod:\\n\"\n            \"   .. py:method:: meth3\\n\"\n            \"      :staticmethod:\\n\")\n    restructuredtext.parse(app, text)\n    domain = app.env.get_domain('py')\n    objects = list(domain.get_objects())\n    assert len(objects) == 4\n    assert objects[0] == ('example', 'example', 'module', 'index', 'module-example', 0)\n    assert objects[1] == ('Class', 'example.Class', 'class', 'index', 'example.Class', 1)\n    assert objects[2] == ('meth1', 'example.Class.meth1', 'method', 'index', 'example.Class.meth1', 1)\n    assert objects[3] == ('meth2', 'example.Class.meth2', 'method', 'index', 'example.Class.meth2', 1)\n"], "sample_962": ["def test_ismock():\n    with mock(['unknown']):\n        import unknown\n        assert ismock(unknown)\n        assert ismock(unknown.secret)\n        assert ismock(unknown.secret.Class)\n        assert not ismock(int)\n        assert not ismock(str)\n        assert not ismock(None)\n"], "sample_963": ["def test_stringify_type_hints_ForwardRef():\n    from typing import ForwardRef  # type: ignore\n    assert stringify(ForwardRef(\"myint\")) == \"myint\"\n"], "sample_967": ["def test_mathjax_custom_path(app, status, warning):\n    app.builder.build_all()\n\n    content = (app.outdir / 'index.html').read_text()\n    assert 'https://example.com/mathjax.js' in content\n"], "sample_968": ["def test_get_full_qualified_name_for_module(app):\n    env = Mock(domaindata={})\n    domain = PythonDomain(env)\n\n    node = nodes.reference(reftarget='module1')\n    assert domain.get_full_qualified_name(node) == 'module1'\n\n    node = nodes.reference(reftarget='module1', **{'py:module': 'package'})\n    assert domain.get_full_qualified_name(node) == 'package.module1'\n"], "sample_969": ["def test_get_type_hints():\n        pass\n\n    hints = get_type_hints(func)\n    assert hints == {'a': int, 'b': str, 'return': float}\n\n    class MyClass:\n            pass\n\n    hints = get_type_hints(MyClass.method)\n    assert hints == {'a': int, 'b': str, 'return': float}\n\n    # Test with ForwardRef\n    from typing import ForwardRef\n    ref = ForwardRef('MyForwardRef')\n    hints = get_type_hints(ref)\n    assert hints == {}\n\n    # Test with broken class\n    class BrokenClass:\n        __annotations__ = 'broken'\n\n    hints = get_type_hints(BrokenClass)\n    assert hints == {}\n"], "sample_972": ["def test_stringify_type_hints_ForwardRef():\n    from typing import ForwardRef  # type: ignore\n    assert stringify(ForwardRef(\"myint\")) == \"myint\"\n    assert stringify(ForwardRef(\"myint\"), \"fully-qualified\") == \"myint\"\n    assert stringify(ForwardRef(\"myint\"), \"smart\") == \"myint\"\n"], "sample_974": ["def test_ccode_AugmentedAssignment():\n    expr = aug_assign(x, '+', y + z)\n    assert ccode(expr) == 'x += y + z;'\n    expr = aug_assign(x, '-', y + z)\n    assert ccode(expr) == 'x -= y + z;'\n    expr = aug_assign(x, '*', y + z)\n    assert ccode(expr) == 'x *= y + z;'\n    expr = aug_assign(x, '/', y + z)\n    assert ccode(expr) == 'x /= y + z;'\n"], "sample_975": ["def test_nsolve_matrix():\n    x, y = symbols('x y')\n    f1 = x**2 + y**2 - 4\n    f2 = x*y - 2\n    f = Matrix((f1, f2)).T\n    assert nsolve(f, (x, y), (1, 1)) == Matrix([[-sqrt(2)], [-sqrt(2)]])\n"], "sample_976": ["def test_symbols_empty_range():\n    assert symbols('x:0') == ()\n    assert symbols(':0') == ()\n    assert symbols('a:d,x:0') == (Symbol('a'), Symbol('b'), Symbol('c'), Symbol('d'))\n    assert symbols(('a:d', 'x:0')) == ((Symbol('a'), Symbol('b'), Symbol('c'), Symbol('d')), ())\n"], "sample_977": ["def test_user_functions():\n    assert mcode(sin(x), user_functions={'sin': 'MySin'}) == \"MySin[x]\"\n    assert mcode(cos(x), user_functions={'cos': 'MyCos'}) == \"MyCos[x]\"\n    assert mcode(exp(x), user_functions={'exp': 'MyExp'}) == \"MyExp[x]\"\n"], "sample_978": ["def test_repeated_knots():\n    d = 2\n    knots = [0, 0, 0, 1, 2, 3, 4, 4, 4]\n    splines = bspline_basis_set(d, knots, x)\n    assert len(splines) == len(knots) - d - 1\n    for spline in splines:\n        assert isinstance(spline, Piecewise)\n"], "sample_979": ["def test_MatrixElement_as_real_imag():\n    A = MatrixSymbol('A', 2, 2)\n    a11, a12, a21, a22 = symbols('a11 a12 a21 a22')\n    A_expr = ImmutableMatrix([[a11 + I*a12, a21 + I*a22], [0, 0]])\n    A_real, A_imag = A_expr.as_real_imag()\n    assert A[0, 0].subs(A, A_expr).as_real_imag() == (A_real[0, 0], A_imag[0, 0])\n    assert A[0, 1].subs(A, A_expr).as_real_imag() == (A_real[0, 1], A_imag[0, 1])\n    assert A[1, 0].subs(A, A_expr).as_real_imag() == (A_real[1, 0], A_imag[1, 0])\n    assert A[1, 1].subs(A, A_expr).as_real_imag() == (A_real[1, 1], A_imag[1, 1])\n"], "sample_982": ["def test_factorint_limit():\n    # Test factorint with limit parameter\n    assert factorint(2**31*3**20, limit=30) == {2: 31, 3: 20}\n    assert factorint(2**31*3**20, limit=25) == {2: 31, 3: 20}\n    assert factorint(2**31*3**20, limit=10) == {2: 31, 3**10*9: 1}\n    assert factorint(2**31*3**20, limit=5) == {2: 31, 3**4*81: 1}\n    assert factorint(2**31*3**20, limit=2) == {2: 31, 3**2*81**2: 1}\n    assert factorint(2**31*3**20, limit=1) == {2**31*3**20: 1}\n"], "sample_984": ["def test_DMP():\n    from sympy.polys.domains import ZZ\n    f = ZZ.map([1, 2, 3])\n    assert str(f) == \"Poly(1 + 2*x + 3*x**2, x, domain='ZZ')\"\n"], "sample_985": ["def test_real_root():\n    from sympy import real_root, Rational, symbols\n    x = symbols('x')\n    assert real_root(-8, 3) == -2\n    assert real_root(Rational(-27, 8), 3) == Rational(-3, 2)\n    assert real_root(1000000000000000000000001, 10) == 10**20 + 1\n    assert real_root(x, 4).subs(x, 16) == 2\n    assert real_root((x - 1)**3, 3).subs(x, 10) == 3\n"], "sample_991": ["def test_issue_19673():\n    n = Symbol('n', integer=True)\n    p = Product(n, (n, 1, -5))\n    assert p.doit() == 1 / factorial(5)\n"], "sample_992": ["def test_NumPyPrinter():\n    p = NumPyPrinter()\n    assert p.doprint(x**y) == 'x**y'\n    assert p.doprint(Mod(x, 2)) == 'numpy.mod(x, 2)'\n    assert p.doprint(And(x, y)) == 'numpy.logical_and.reduce((x, y))'\n    assert p.doprint(Or(x, y)) == 'numpy.logical_or.reduce((x, y))'\n    assert p.doprint(pi) == 'numpy.pi'\n    assert p.doprint(acos(x)) == 'numpy.arccos(x)'\n    assert p.doprint(Assignment(x, 2)) == 'x = 2'\n    assert p.doprint(SparseMatrix(2, 5, {(0, 1): 3})) == 'numpy.array([[0, 3, 0, 0, 0], [0, 0, 0, 0, 0]])'\n"], "sample_993": ["def test_FreeGroupElm_cyclic_reduction():\n    w1 = x**2*y**-1*x**-1\n    assert w1.cyclic_reduction() == y**-1\n\n    w2 = y*x**2*y**2\n    assert w2.cyclic_reduction() == w2\n\n    w3 = x**-3*y**-1*x**5\n    assert w3.cyclic_reduction() == y**-1*x**2\n\n    w4 = x**2*y**2*x**-1\n    assert w4.cyclic_reduction() == x*y**2\n"], "sample_996": ["def test_issue_16458():\n    n = Symbol('n', integer=True, positive=True)\n    p = Product(n**2 / (n**2 + 1), (n, 1, oo))\n    assert p.is_convergent() is S.false\n    assert product(n**2 / (n**2 + 1), (n, 1, oo)) == p.doit()\n"], "sample_998": ["def test_latex_Tuple():\n    assert latex(Tuple(x, y)) == r\"\\left ( x, \\quad y\\right )\"\n    assert latex(Tuple(x, y, z)) == r\"\\left ( x, \\quad y, \\quad z\\right )\"\n"], "sample_1000": ["def test_Indexed_printing():\n    # test cases for issue #11821\n    A = IndexedBase(\"A\", shape=(3, 3))\n    i = Symbol('i', integer=True)\n    j = Symbol('j', integer=True)\n\n    assert mcode(A[i, j]) == \"A(i, j)\"\n    assert mcode(3 * A[i, j]) == \"3*A(i, j)\"\n\n    F = A[i, j].subs(A, A**2)\n    assert mcode(F) == \"(A.^2)(i, j)\"\n"], "sample_1004": ["def test_CondSet_union():\n    input_conditionset1 = ConditionSet(x, x**2 > 4, Interval(1, 4, False, False))\n    input_conditionset2 = ConditionSet(x, x**2 < 4, Interval(0, 3, False, False))\n    output_conditionset = ConditionSet(x, (x**2 > 4) | (x**2 < 4), Interval(0, 4, False, False))\n    assert Union(input_conditionset1, input_conditionset2) == output_conditionset\n"], "sample_1006": ["def test_factorial_Mod():\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True)\n\n    assert factorial(n).Mod(k) == Mod(factorial(n), k)\n    assert factorial(5).Mod(3) == 0\n    assert factorial(6).Mod(7) == 6\n    assert factorial(-1).Mod(4) == 0\n    assert factorial(-2).Mod(5) == 0\n    assert factorial(n).Mod(1) == 0\n    assert factorial(0).Mod(k) == 1 % k\n    assert factorial(1).Mod(k) == 1 % k\n"], "sample_1007": ["def test_factorial_Mod():\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True)\n\n    assert factorial(n).Mod(k) == Mod(factorial(n), k)\n    assert factorial(5).Mod(3) == 0\n    assert factorial(6).Mod(7) == 6\n    assert factorial(-1).Mod(5) == 0\n    assert factorial(-2).Mod(7) == 0\n    assert factorial(n).Mod(1) == 0\n    assert factorial(n).Mod(0) == Mod(factorial(n), 0)\n"], "sample_1011": ["def test_Indexed_printing():\n    # test cases for Indexed objects\n    A = IndexedBase('A')\n    i, j = symbols('i j', integer=True)\n    assert mcode(A[i]) == 'A(i)'\n    assert mcode(A[i + 1]) == 'A(i + 1)'\n    assert mcode(A[i, j]) == 'A(i, j)'\n    assert mcode(A[i, j + 1]) == 'A(i, j + 1)'\n"], "sample_1013": ["def test_lambdify_with_integer_types():\n    f = lambdify(x, x**2)\n    assert f(2) == 4\n    assert f(2.0) == 4.0\n    assert f(numpy.int8(2)) == 4\n    assert f(numpy.int16(2)) == 4\n    assert f(numpy.int32(2)) == 4\n    assert f(numpy.int64(2)) == 4\n"], "sample_1014": ["def test_free_symbols():\n    x, y = symbols(\"x y\")\n    M = ImmutableDenseNDimArray([[x, y], [1, 2]])\n    assert M.free_symbols == {x, y}\n    Ms = ImmutableSparseNDimArray([[x, y], [1, 2]])\n    assert Ms.free_symbols == {x, y}\n    Mo = ImmutableDenseNDimArray([1, 2, 3])\n    assert Mo.free_symbols == set()\n    Mos = ImmutableSparseNDimArray([1, 2, 3])\n    assert Mos.free_symbols == set()\n"], "sample_1015": ["def test_ccode_While():\n    assert ccode(While(x > 1, [aug_assign(x, '-', 1)])) == (\n        'while (x > 1) {\\n'\n        '   x -= 1;\\n'\n        '}'\n    )\n    assert ccode(While(x > 1, [aug_assign(x, '-', 1), aug_assign(y, '+', 2)])) == (\n        'while (x > 1) {\\n'\n        '   x -= 1;\\n'\n        '   y += 2;\\n'\n        '}'\n    )\n"], "sample_1016": ["def test_Indexed_printing():\n    # test cases for Indexed printing\n    A = MatrixSymbol(\"A\", 3, 3)\n    i = Symbol('i', integer=True)\n    j = Symbol('j', integer=True)\n\n    assert mcode(A[i, j]) == \"A(i + 1, j + 1)\"\n    assert mcode(A[i, 0]) == \"A(i + 1, 1)\"\n    assert mcode(A[0, j]) == \"A(1, j + 1)\"\n    assert mcode(A[0, 0]) == \"A(1, 1)\"\n"], "sample_1018": ["def test_fcode_ImpliedDoLoop():\n    i = symbols('i', integer=True)\n    x = IndexedBase('x')\n    expr = ImpliedDoLoop(x[i], (i, Range(1, 10)))\n    assert fcode(expr) == \"      (/x(i), i = 1, 10/)\"\n    expr = ImpliedDoLoop(x[i], (i, Range(1, 10, 2)))\n    assert fcode(expr) == \"      (/x(i), i = 1, 10, 2/)\"\n"], "sample_1020": ["def test_user_functions():\n    assert mcode(sin(x), user_functions={'sin': 'MySin'}) == \"MySin[x]\"\n    assert mcode(cos(x), user_functions={'cos': 'MyCos'}) == \"MyCos[x]\"\n    assert mcode(exp(x), user_functions={'exp': 'MyExp'}) == \"MyExp[x]\"\n    assert mcode(f(x), user_functions={f: 'MyF'}) == \"MyF[x]\"\n"], "sample_1023": ["def test_sieve_reset():\n    sieve._reset(prime=True)\n    assert len(sieve._list) == 6\n    sieve.extend(30)\n    assert len(sieve._list) > 6\n    sieve._reset(prime=True)\n    assert len(sieve._list) == 6\n\n    sieve._reset(totient=True)\n    assert len(sieve._tlist) == 6\n    list(sieve.totientrange(5, 15))\n    assert len(sieve._tlist) > 6\n    sieve._reset(totient=True)\n    assert len(sieve._tlist) == 6\n\n    sieve._reset(mobius=True)\n    assert len(sieve._mlist) == 6\n    list(sieve.mobiusrange(5, 15))\n    assert len(sieve._mlist) > 6\n    sieve._reset(mobius=True)\n    assert len(sieve._mlist) == 6\n"], "sample_1025": ["def test_PythonCodePrinter_printing_of_infinities():\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(oo) == \"float('inf')\"\n    assert prntr.doprint(-oo) == \"float('-inf')\"\n    assert prntr.doprint(zoo) == \"float('nan')\"\n"], "sample_1026": ["def test_lambdify_matrix_inverse():\n    if not numpy:\n        skip(\"numpy not installed.\")\n    A = Matrix([[x, y], [z, x]])\n    f = lambdify((x, y, z), A**-1, modules=\"numpy\")\n    A_val = numpy.array([[2, 3], [4, 2]])\n    numpy.testing.assert_allclose(f(2, 3, 4), numpy.linalg.inv(A_val))\n"], "sample_1028": ["def test_Mod_is_finite():\n    x = Symbol('x', finite=True)\n    y = Symbol('y', finite=False)\n    assert Mod(x, y).is_finite is None\n    assert Mod(y, x).is_finite is False\n    assert Mod(x, 2).is_finite is True\n    assert Mod(y, 2).is_finite is False\n"], "sample_1029": ["def test_Cycle():\n    from sympy.combinatorics import Cycle\n    sT(Cycle((1, 2, 3)), \"Cycle((1, 2, 3))\")\n"], "sample_1032": ["def test_issue_16473():\n    from sympy.abc import x, y\n    assert Min(x, y).is_commutative is True\n    assert Max(x, y).is_commutative is True\n    assert Min(x, y).is_antihermitian is None\n    assert Max(x, y).is_antihermitian is None\n    assert Min(x, y).is_hermitian is None\n    assert Max(x, y).is_hermitian is None\n"], "sample_1033": ["def test_issue_16353():\n    assert (x**2 + 2*x + 1).as_expr() == x**2 + 2*x + 1\n    assert Add(x, x, evaluate=False).as_expr() == 2*x\n    assert Mul(x, x, evaluate=False).as_expr() == x**2\n"], "sample_1034": ["def test_WGate_represent():\n    nqubits = 2\n    wgate = WGate(nqubits)\n    basis_states = superposition_basis(nqubits)\n    expected_matrix = represent(wgate, basis_states)\n    assert expected_matrix.is_Unitary\n"], "sample_1035": ["def test_measure_all():\n    q = IntQubit(0)/sqrt(2) + IntQubit(1)/sqrt(2)\n    result = [(IntQubit(0), 1/2), (IntQubit(1), 1/2)]\n    assert measure_all(q) == result\n\n    q = IntQubit(0, nqubits=2)/2 + IntQubit(1, nqubits=2)/2 + IntQubit(2, nqubits=2)/2 + IntQubit(3, nqubits=2)/2\n    result = [(IntQubit(0, nqubits=2), 1/4), (IntQubit(1, nqubits=2), 1/4), \n              (IntQubit(2, nqubits=2), 1/4), (IntQubit(3, nqubits=2), 1/4)]\n    assert measure_all(q) == result\n"], "sample_1037": ["def test_MatMul_doit():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n\n    assert MatMul(A, B, C).doit() == MatMul(A, B)*C\n    assert MatMul(A, B, C).doit(deep=False) == MatMul(A, B)*C\n\n    A_val = Matrix([[1, 2], [3, 4]])\n    B_val = Matrix([[5, 6], [7, 8]])\n\n    assert MatMul(A, B).subs({A: A_val, B: B_val}).doit() == A_val*B_val\n    assert MatMul(A, B).subs({A: A_val, B: B_val}).doit(deep=False) == A_val*B_val\n"], "sample_1038": ["def test_matrix_derivative():\n    from sympy import sin, cos\n    x = symbols('x')\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    D = MatrixSymbol('D', 2, 2)\n    E = MatrixSymbol('E', 2, 2)\n    F = MatrixSymbol('F', 2, 2)\n\n    # With one symbol\n    expr = sin(x)*A + cos(x)*B\n    assert expr.diff(x) == cos(x)*A - sin(x)*B\n\n    # With two symbols\n    expr = sin(x)*A + cos(x)*B*x\n    assert expr.diff(x) == cos(x)*A - sin(x)*B*x + cos(x)*B\n\n    # With matrix multiplication\n    expr = A*B\n    assert expr.diff(A) == B.T\n    assert expr.diff(B) == A.T\n\n    # With matrix addition\n    expr = A + B\n    assert expr.diff(A) == Identity(2)\n    assert expr.diff(B) == Identity(2)\n\n    # With transpose\n    expr = A.T\n    assert expr.diff(A) == Identity(2)\n\n    # With inverse\n    expr = A.inv()\n    assert expr.diff(A) == -A.inv().T*A.inv()\n\n    # With more complicated expression\n    expr = (A*B).inv()*C*(D*E).T\n    assert expr.diff(A) == -(B.T*(A*B).inv().T*C*(D*E).T + (A*B).inv()*C*(D*E).T*A.inv())\n    assert expr.diff(B) == -(A.T*(A*B).inv().T*C*(D*E).T)\n    assert expr.diff(C) == (A*B).inv()*(D*E).T\n    assert expr.diff(D) == (A*B).inv()*C*E.T\n    assert expr.diff(E) == (A*B).inv()*C*D.T\n"], "sample_1041": ["def test_matrix_derivative():\n    from sympy import sin, cos\n    x = symbols('x')\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    f = sin(x)*A + cos(x)*B\n    assert f.diff(x) == cos(x)*A - sin(x)*B\n    assert f.diff(A) == sin(x)*Identity(2)\n    assert f.diff(B) == cos(x)*Identity(2)\n"], "sample_1042": ["def test_IndexedBase_shape_with_infinite_dimension():\n    i, j = symbols('i j', integer=True)\n    a = IndexedBase('a', shape=(oo, 3))\n    assert a.shape == Tuple(oo, 3)\n    assert Indexed(a, Idx(i), Idx(j)).ranges == [Tuple(None, None), Tuple(0, 2)]\n    assert Indexed(a, Idx(i), Idx(j)).shape == Tuple(oo, 3)\n"], "sample_1043": ["def test_user_functions():\n    assert mcode(sin(x), user_functions={'sin': 'MySin'}) == \"MySin[x]\"\n    assert mcode(cos(x), user_functions={'cos': 'MyCos'}) == \"MyCos[x]\"\n    assert mcode(exp(x), user_functions={'exp': 'MyExp'}) == \"MyExp[x]\"\n"], "sample_1044": ["def test_Pow_is_finite():\n    x = Symbol('x', finite=True)\n    y = Symbol('y', finite=False)\n    z = Symbol('z')\n    assert (x**2).is_finite is True\n    assert (y**2).is_finite is False\n    assert (z**2).is_finite is None\n    assert (S.Infinity**2).is_finite is False\n    assert (S.NegativeInfinity**3).is_finite is False\n    assert (S.ComplexInfinity**4).is_finite is False\n    assert (S.NaN**5).is_finite is None\n"], "sample_1047": ["def test_issue_16332():\n    x = Symbol('x', real=True, finite=False)\n    assert (1/x).is_finite is None  # x can be infinite\n    assert (1/x).is_infinite is None  # x can be zero or infinite\n    y = Symbol('y', real=True, nonzero=True, finite=False)\n    assert (1/y).is_finite is True  # y cannot be zero\n    assert (1/y).is_infinite is False  # y cannot be zero\n"], "sample_1048": ["def test_parabola_equation():\n    x, y = symbols('x y')\n    p1 = Point(0, 0)\n    l1 = Line(Point(5, 8), Point(7, 8))\n    parabola1 = Parabola(p1, l1)\n\n    # equation with default symbols\n    assert parabola1.equation() == -x**2 - 16*y + 64\n\n    # equation with custom symbols\n    assert parabola1.equation(x='f', y='g') == -f**2 - 16*g + 64\n\n    # equation with only one custom symbol\n    assert parabola1.equation(x='h') == -h**2 - 16*y + 64\n    assert parabola1.equation(y='i') == -x**2 - 16*i + 64\n"], "sample_1051": ["def test_dotprint_custom_styles():\n    styles = [(Basic, {'color': 'red', 'shape': 'box'}),\n              (Expr,  {'color': 'green'})]\n    text = dotprint(x+2, styles=styles)\n    assert '\"color\"=\"green\"' in text\n    assert '\"shape\"=\"ellipse\"' in text\n    assert '\"color\"=\"red\"' not in text\n    assert '\"shape\"=\"box\"' not in text\n\n    text = dotprint(x, styles=styles)\n    assert '\"color\"=\"green\"' in text\n    assert '\"shape\"=\"ellipse\"' in text\n    assert '\"color\"=\"red\"' not in text\n    assert '\"shape\"=\"box\"' not in text\n"], "sample_1052": ["def test_julia_codegen():\n    x, y, z = symbols('x,y,z')\n    expr = (x + y)*z\n    result = codegen((\"test\", expr), \"julia\", \"file\", header=False, empty=False)\n    expected = [\n        (\"file.jl\",\n        \"function test(x, y, z)\\n\"\n        \"   test_result = z*(x + y)\\n\"\n        \"   return test_result\\n\"\n        \"end\\n\"),\n    ]\n    assert result == expected\n"], "sample_1054": ["def test_issue_12345():\n    # Test case for ImageSet with multiple variables\n    x, y = symbols('x y')\n    f = Lambda((x, y), x + y)\n    domain = Interval(0, 1) * Interval(0, 1)\n    imgset = ImageSet(f, domain)\n\n    assert (0.5, 0.5) in imgset\n    assert (2, 2) not in imgset\n\n    # Test case for ComplexRegion with multiple intervals\n    cr = ComplexRegion(Union(Interval(0, 1)*Interval(0, 1), Interval(1, 2)*Interval(1, 2)))\n\n    assert 0.5 + 0.5*I in cr\n    assert 1.5 + 1.5*I in cr\n    assert 2.5 + 2.5*I not in cr\n"], "sample_1056": ["def test_numexpr_functions():\n    # Test that NumExprPrinter can handle various SymPy functions\n    x = symbols('x')\n    n = NumExprPrinter()\n\n    assert n.doprint(sin(x)) == \"evaluate('sin(x)', truediv=True)\"\n    assert n.doprint(cos(x)) == \"evaluate('cos(x)', truediv=True)\"\n    assert n.doprint(tan(x)) == \"evaluate('tan(x)', truediv=True)\"\n    assert n.doprint(asin(x)) == \"evaluate('arcsin(x)', truediv=True)\"\n    assert n.doprint(acos(x)) == \"evaluate('arccos(x)', truediv=True)\"\n    assert n.doprint(atan(x)) == \"evaluate('arctan(x)', truediv=True)\"\n    assert n.doprint(exp(x)) == \"evaluate('exp(x)', truediv=True)\"\n    assert n.doprint(log(x)) == \"evaluate('log(x)', truediv=True)\"\n    assert n.doprint(sqrt(x)) == \"evaluate('sqrt(x)', truediv=True)\"\n    assert n.doprint(Abs(x)) == \"evaluate('abs(x)', truediv=True)\"\n"], "sample_1057": ["def test_module_imports():\n    ast = Print('x y'.split(), \"coordinate: %12.5g %12.5g\")\n    printer = PythonCodePrinter({'standard':'python3', 'fully_qualified_modules': True})\n    printer.module_imports = ['math']\n    assert render_as_module(ast, standard='python3') == \\\n        'import math\\n\\nprint(\"coordinate: %12.5g %12.5g\" % (x, y))'\n    printer = PythonCodePrinter({'standard':'python3', 'fully_qualified_modules': False})\n    printer.module_imports = {'math': ['sin', 'cos']}\n    assert render_as_module(ast, standard='python3') == \\\n        'from math import sin, cos\\n\\nprint(\"coordinate: %12.5g %12.5g\" % (x, y))'\n"], "sample_1060": ["def test_NumPyPrinter_print_Pow():\n    n = NumPyPrinter()\n\n    assert n.doprint(x**0.5) == 'numpy.sqrt(x)'\n    assert n.doprint(x**2) == 'x**2'\n"], "sample_1063": ["def test_lambdify_with_integer_symbols():\n    n = symbols('n', integer=True)\n    f = lambdify(n, n**2)\n    assert f(3) == 9\n    assert f(-2) == 4\n"], "sample_1065": ["def test_factorial2_diff():\n    n = Symbol('n', integer=True)\n\n    assert factorial2(n).diff(n) == \\\n        2**(n/2)*gamma(n/2 + 1)*(polygamma(0, n/2 + 1)/2 - log(2))\n    assert factorial2(n**2).diff(n) == \\\n        n*2**(n**2/2)*gamma(n**2/2 + 1)*(polygamma(0, n**2/2 + 1) - log(4))\n    raises(ArgumentIndexError, lambda: factorial2(n**2).fdiff(2))\n"], "sample_1067": ["def test_issue_3539_extension():\n    a = Wild('a')\n    x = Symbol('x')\n    assert (x - 2).match(a + x) == {a: -2}\n    assert (6/x).match(a/x) == {a: 6}\n    assert (6/x**2).match(a*x) is None\n"], "sample_1068": ["def test_octave_inline_piecewise_times_const():\n    pw = Piecewise((x, x < 1), (x**2, True))\n    assert mcode(2*pw, inline=True) == \"2*((x < 1).*(x) + (~(x < 1)).*(x.^2))\"\n    assert mcode(pw/x, inline=True) == \"((x < 1).*(x) + (~(x < 1)).*(x.^2))./x\"\n    assert mcode(pw/(x*y), inline=True) == \"((x < 1).*(x) + (~(x < 1)).*(x.^2))./(x.*y)\"\n    assert mcode(pw/3, inline=True) == \"((x < 1).*(x) + (~(x < 1)).*(x.^2))/3\"\n"], "sample_1069": ["def test_glsl_code():\n    assert glsl_code(sin(x) ** cos(x)) == \"pow(sin(x), cos(x))\"\n    assert glsl_code(sign(x)) == \"sign(x)\"\n    assert glsl_code(exp(x)) == \"exp(x)\"\n    assert glsl_code(log(x)) == \"log(x)\"\n    assert glsl_code(factorial(x)) == \"factorial(x)\"\n    assert glsl_code(floor(x)) == \"floor(x)\"\n    assert glsl_code(atan2(y, x)) == \"atan(y, x)\"\n    assert glsl_code(beta(x, y)) == 'beta(x, y)'\n    assert glsl_code(polylog(x, y)) == 'polylog(x, y)'\n    assert glsl_code(harmonic(x)) == 'harmonic(x)'\n    assert glsl_code(bernoulli(x)) == \"bernoulli(x)\"\n    assert glsl_code(bernoulli(x, y)) == \"bernoulli(x, y)\"\n    assert glsl_code(legendre(x, y)) == \"legendre(x, y)\"\n"], "sample_1070": ["def test_exp_polar_rewrite():\n    from sympy.concrete.summations import Sum\n    assert exp_polar(x).rewrite(sin) == sinh(x) + cosh(x)\n    assert exp_polar(x*I).rewrite(cos) == cos(x) + I*sin(x)\n    assert exp_polar(1).rewrite(cos) == sinh(1) + cosh(1)\n    assert exp_polar(1).rewrite(sin) == sinh(1) + cosh(1)\n    assert exp_polar(x).rewrite(tanh) == (1 + tanh(x/2))/(1 - tanh(x/2))\n    assert exp_polar(pi*I/4).rewrite(sqrt) == sqrt(2)/2 + sqrt(2)*I/2\n    assert exp_polar(pi*I/3).rewrite(sqrt) == S(1)/2 + sqrt(3)*I/2\n    assert exp_polar(x*log(y)).rewrite(Pow) == y**x\n    assert exp_polar(log(x)*log(y)).rewrite(Pow) in [x**log(y), y**log(x)]\n    assert exp_polar(log(log(x))*y).rewrite(Pow) == log(x)**y\n\n    n = Symbol('n', integer=True)\n\n    assert Sum((exp_polar(pi*I/2)/2)**n, (n, 0, oo)).rewrite(sqrt).doit() == S(4)/5 + 2*I/5\n    assert Sum((exp_polar(pi*I/4)/2)**n, (n, 0, oo)).rewrite(sqrt).doit() == 1/(1 - sqrt(2)*(1 + I)/4)\n    assert Sum((exp_polar(pi*I/3)/2)**n, (n, 0, oo)).rewrite(sqrt).doit() == 1/(S(3)/4 - sqrt(3)*I/4)\n"], "sample_1071": ["def test_convert_to_with_prefixes():\n    from sympy.physics.units import kilo, mega, meter, second\n    assert convert_to(kilo*meter, meter) == 1000*meter\n    assert convert_to(mega*meter, kilo*meter) == 1000*kilo*meter\n    assert convert_to(kilo*meter/second, meter/second) == 1000*meter/second\n    assert convert_to(mega*meter/second, kilo*meter/second) == 1000*kilo*meter/second\n"], "sample_1072": ["def test_frac_real_imaginary_part():\n    r = Symbol('r', real=True)\n    i = Symbol('i', imaginary=True)\n\n    assert frac(r + i) == frac(r) + frac(i)\n    assert frac(r - i) == frac(r) - frac(i)\n    assert frac(i).rewrite(floor) == i - floor(i)\n    assert frac(i).rewrite(ceiling) == i + ceiling(-i)\n"], "sample_1073": ["def test_sqrt_biquadratic_denest():\n    z = sqrt((2*sqrt(2) + 4)*sqrt(2 + sqrt(2)) + 5*sqrt(2) + 8)\n    assert sqrtdenest(z) == sqrt(2) + sqrt(sqrt(2) + 2) + 2\n    w = 2 + r2 + r3 + (1 + r3)*sqrt(2 + r2 + 5*r3)\n    z = sqrt((w**2).expand())\n    assert sqrtdenest(z) == w.expand()\n    z = sqrt(-6*sqrt(55)-6*sqrt(35)-2*sqrt(22)-2*sqrt(14)+2*sqrt(77)+6*sqrt(10)+65)\n    assert sqrtdenest(z) == -sqrt(11) - sqrt(7) + sqrt(2) + 3*sqrt(5)\n"], "sample_1075": ["def test_beta_eval_is_real():\n    x, y = Symbol('x', real=True), Symbol('y', real=True)\n    assert beta(x, y)._eval_is_real() is True\n\n    x, y = Symbol('x', real=False), Symbol('y', real=True)\n    assert beta(x, y)._eval_is_real() is None\n\n    x, y = Symbol('x', real=True), Symbol('y', real=False)\n    assert beta(x, y)._eval_is_real() is None\n\n    x, y = Symbol('x', real=False), Symbol('y', real=False)\n    assert beta(x, y)._eval_is_real() is None\n"], "sample_1076": ["def test_SciPyPrinter_print_arg():\n    p = SciPyPrinter()\n    expr = x.as_real_imag()[1]\n    assert p.doprint(expr) == 'numpy.angle(x)'\n"], "sample_1078": ["def test_IndexedBase_shape_inheritance():\n    i, j = symbols('i j', integer=True)\n    A = IndexedBase('A', shape=(3, 4))\n    B = IndexedBase(A)\n    assert B.shape == (3, 4)\n    assert B[i, j].shape == (3, 4)\n"], "sample_1080": ["def test_refine_abs_with_real_and_imaginary_parts():\n    x = Symbol('x', real=True)\n    y = Symbol('y', imaginary=True)\n    expr1 = refine(Abs(x + y), Q.positive(x))\n    expr2 = refine(Abs(x + y), Q.negative(x))\n    assert expr1 == Abs(x + y)\n    assert expr2 == Abs(x + y)\n    expr3 = refine(Abs(x * y), Q.positive(x))\n    expr4 = refine(Abs(x * y), Q.negative(x))\n    assert expr3 == x * Abs(y)\n    assert expr4 == -x * Abs(y)\n"], "sample_1084": ["def test_issue_17355():\n    S53 = ImageSet(Lambda(n, 5*n + 3), S.Integers)\n    assert S53.intersect(S.Integers) == S53\n    assert S53.intersect(S.Reals) == S53\n    assert S53.intersect(Interval(0, 10)) == FiniteSet(3, 8)\n    assert S53.intersect(Range(0, 10)) == FiniteSet(3, 8)\n"], "sample_1087": ["def test_w_polys():\n    w1, w2 = w_polys()\n    assert w1.is_Poly and w2.is_Poly\n    assert w1.domain == ZZ and w2.domain == ZZ\n    assert w1.gens == (x, y, z) and w2.gens == (x, y)\n    assert w1.degree() == 6 and w2.degree() == 8\n"], "sample_1088": ["def test_symmetrize_iterable():\n    assert symmetrize([x**2, y**2], x, y) == [(-2*x*y + (x + y)**2, 0), (-2*x*y + (x + y)**2, 0)]\n    assert symmetrize([x**2, y**2], x, y, formal=True) == ([(-2*x*y + s1**2, 0), (-2*x*y + s1**2, 0)], [(s1, x + y), (s2, x*y)])\n    assert symmetrize([x**2, y**2, x*y], x, y) == [(-2*x*y + (x + y)**2, 0), (-2*x*y + (x + y)**2, 0), (x*y, 0)]\n"], "sample_1089": ["def test_issue_18059():\n    assert Factors((x**2)**S.Half).as_expr() == (x**2)**S.Half\n    assert Factors(x**(2*S.Half)).as_expr() == x\n"], "sample_1092": ["def test_cse_with_matrix_expressions():\n    A = MatrixSymbol('A', 3, 3)\n    B = MatrixSymbol('B', 3, 3)\n    exprs = [A*B, A*B*A]\n    subst, red = cse(exprs)\n    assert len(subst) > 0\n    for i, e in enumerate(red):\n        assert (e.subs(reversed(subst)) - exprs[i]).simplify() == 0\n"], "sample_1094": ["def test_replace_issue_10268():\n    from sympy import Wild, sin, cos\n    x = symbols('x')\n    a, b = map(Wild, 'ab')\n    e = sin(x)**2 + cos(x)**2 - 1\n    assert e.replace(a*b**2, a) == e\n    assert e.replace(sin(a)**2 + cos(a)**2, 1) == 0\n    assert e.replace(sin(a)**2 + cos(b)**2, 1) == e\n"], "sample_1096": ["def test_IndexedBase_strides():\n    i, j = symbols('i j', integer=True)\n    A = IndexedBase('A', strides=(2, 3))\n    assert A.strides == (2, 3)\n    assert A[i, j].base.strides == (2, 3)\n"], "sample_1099": ["def test_eval_partial_derivative_mixed_tensor_expr3():\n\n    tau, alpha = symbols(\"tau alpha\")\n\n    base_expr3 = H(i, j)*A(-j) + A(i)*H(j, -j)\n\n    tensor_expression1 = PartialDerivative(base_expr3, H(k, m))._perform_derivative()\n    assert (tensor_expression1 -\n            (L.delta(L_0, -k)*L.delta(i, -m)*A(-L_0) +\n             L.delta(i, -k)*L.metric(L_0, L_1)*L.delta(-L_1, m)*A(-L_0) +\n             A(i)*L.delta(L_0, -k)*L.metric(-L_0, -L_1)*L.delta(L_1, -m))).expand() == 0\n\n    tensor_expression2 = PartialDerivative(base_expr3, A(k))._perform_derivative()\n    assert (tensor_expression2 -\n            (H(i, L_0)*L.metric(-L_0, -L_1)*L.delta(L_1, -k) +\n             L.delta(i, -k)*H(L_0, -L_0))).expand() == 0\n"], "sample_1101": ["def test_schur_number_eval():\n    raises(ValueError, lambda: SchurNumber(-1))\n    raises(ValueError, lambda: SchurNumber(-5))\n    assert SchurNumber(5).is_Function is True\n    assert SchurNumber(7).is_Function is True\n    k = symbols(\"k\", positive=True, integer=True)\n    assert SchurNumber(k).is_Function is True\n"], "sample_1106": ["def test_matadd_doit():\n    assert MatAdd(A, ZeroMatrix(n, m)).doit() == A\n    assert MatAdd(A, -A).doit() == ZeroMatrix(n, m)\n    assert MatAdd(A, B, -B).doit() == A\n    assert MatAdd(A, B, C, -C).doit() == A + B\n"], "sample_1109": ["def test_frac_is_integer():\n    assert frac(0).is_integer\n    assert frac(1).is_integer\n    assert frac(-1).is_integer\n    assert not frac(Rational(1, 2)).is_integer\n    assert not frac(Rational(-1, 2)).is_integer\n    assert frac(n).is_integer\n    assert frac(nan).is_integer is None\n    assert frac(oo).is_integer is None\n    assert frac(-oo).is_integer is None\n\n    r = Symbol('r', real=True)\n    assert frac(r).is_integer is None\n    assert frac(I*r).is_integer is None\n    assert frac(1 + I*r).is_integer is None\n    assert frac(0.5 + I*r).is_integer is None\n    assert frac(n + I*r).is_integer is None\n    assert frac(n + I*k).is_integer\n    assert frac(x + I*x).is_integer is None\n    assert frac(x + I*n).is_integer is None\n"], "sample_1111": ["def test_rescale():\n    y = [1, 2, 3, 4, 5]\n    W = len(y)\n    H = 10\n    mi = 1\n    ma = 5\n    expected = [0, 2, 4, 6, 8]\n    assert rescale(y, W, H, mi, ma) == expected\n\n    y = [1.1, 2.2, 3.3, 4.4, 5.5]\n    W = len(y)\n    H = 10\n    mi = 1\n    ma = 5\n    expected = [0, 2, 4, 6, 9]\n    assert rescale(y, W, H, mi, ma) == expected\n\n    y = [None, 2, 3, None, 5]\n    W = len(y)\n    H = 10\n    mi = 1\n    ma = 5\n    expected = [None, 2, 4, None, 8]\n    assert rescale(y, W, H, mi, ma) == expected\n"], "sample_1112": ["def test_digits_edge_cases():\n    raises(ValueError, lambda: digits(123, 1))\n    raises(ValueError, lambda: digits(123, 0))\n    raises(ValueError, lambda: digits(123, -2))\n    assert digits(0, 10) == [10, 0]\n    assert digits(-0, 10) == [10, 0]\n    assert digits(0, 2) == [2, 0]\n    assert digits(0, 16) == [16, 0]\n"], "sample_1113": ["def test_block_matrix_trace():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', m, m)\n    C = BlockMatrix([[A, ZeroMatrix(n, m)], [ZeroMatrix(m, n), B]])\n    assert trace(C) == trace(A) + trace(B)\n"], "sample_1114": ["def test_issue_18999():\n    n = Symbol('n', integer=True)\n    assert Range(n, n + 20, 2).is_finite_set is True\n    assert Range(n, 0).is_finite_set is True\n    assert Range(-3, n + 7).is_finite_set is True\n    assert Range(n, m).is_finite_set is None\n    assert Range(n + m, m - n).is_finite_set is None\n    assert Range(n, n + m + n).is_finite_set is None\n    assert Range(n, oo).is_finite_set is False\n    assert Range(-oo, n).is_finite_set is False\n    assert Range(n, -oo).is_finite_set is True\n    assert Range(oo, n).is_finite_set is True\n"], "sample_1116": ["def test_inverse_derivative():\n    from sympy import symbols, diff\n    x = symbols('x')\n    A = MatrixSymbol('A', 2, 2)\n    A_diff = diff(A, x)\n    assert (Inverse(A)).diff(x) == -Inverse(A)*A_diff*Inverse(A)\n"], "sample_1118": ["def test_matpow():\n    assert MatPow(C, 0).doit() == Identity(n)\n    assert MatPow(C, 1).doit() == C\n    assert MatPow(C, -1).doit() == Inverse(C)\n    assert MatPow(Identity(n), 3).doit() == Identity(n)\n    assert MatPow(ZeroMatrix(n, n), 3).doit() == ZeroMatrix(n, n)\n    raises(NonInvertibleMatrixError, lambda: MatPow(ZeroMatrix(n, n), -1).doit())\n    raises(NonSquareMatrixError, lambda: MatPow(A, 2).doit())\n    raises(TypeError, lambda: MatPow(n, 2))\n    assert MatPow(MatPow(C, 2), 3).doit() == MatPow(C, 6).doit()\n    assert MatPow(C, S.NegativeOne).doit() == Inverse(C)\n    assert MatPow(C, S.One).doit() == C\n"], "sample_1122": ["def test_issue_16855():\n    from sympy import symbols, I, exp_polar\n    x = symbols('x')\n    assert re(exp_polar(x)).rewrite(cos) == cos(im(x))*exp(re(x))\n    assert im(exp_polar(x)).rewrite(sin) == sin(im(x))*exp(re(x))\n"], "sample_1123": ["def test_CondSet_as_relational():\n    sin_sols_principal = ConditionSet(x, Eq(sin(x), 0),\n                                      Interval(0, 2*pi, False, True))\n    assert sin_sols_principal.as_relational(pi) == And(Eq(sin(pi), 0), Contains(pi, Interval(0, 2*pi, False, True)))\n    assert sin_sols_principal.as_relational(3*pi) == And(Eq(sin(3*pi), 0), Contains(3*pi, Interval(0, 2*pi, False, True)))\n    assert sin_sols_principal.as_relational(y) == And(Eq(sin(y), 0), Contains(y, Interval(0, 2*pi, False, True)))\n"], "sample_1124": ["def test_FracElement_set_field():\n    F, x,y,z = field(\"x,y,z\", ZZ)\n    G, a,b,c = field(\"a,b,c\", QQ)\n\n    f = (x**2 + 3*y)/z\n    g = f.set_field(G)\n\n    assert g.field == G\n    assert g.numer == G.ring.gens[0]**2 + 3*G.ring.gens[1]\n    assert g.denom == G.ring.gens[2]\n"], "sample_1125": ["def test_hermitian_operator():\n    H = Operator('H', is_hermitian=True)\n    assert Dagger(H) == H\n    assert H.inv() == H**(-1)\n    assert H._eval_power(2) == H*H\n    assert H._eval_inverse() == H**(-1)\n"], "sample_1126": ["def test_dagger_add():\n    A = Operator('A')\n    B = Operator('B')\n    assert Dagger(A + B) == Dagger(A) + Dagger(B)\n    assert Dagger(A + Dagger(B)) == Dagger(A) + B\n    assert Dagger(Dagger(A) + B) == A + Dagger(B)\n"], "sample_1128": ["def test_auto_point_vel_multiple_frame_path():\n    t = dynamicsymbols._t\n    q1, q2, u1 = dynamicsymbols('q1 q2 u1')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    S = ReferenceFrame('S')\n    O = Point('O')\n    O.set_vel(N, u1 * N.x)\n    P = Point('P')\n    P.set_pos(O, q1 * N.y)\n    Q = Point('Q')\n    Q.set_pos(P, q2 * B.z)\n    raises(ValueError, lambda: Q.vel(N))  # B not oriented wrt N\n    B.orient(N, 'Axis', (q1, N.z))\n    raises(ValueError, lambda: Q.vel(S))  # O's vel not defined in S\n    assert Q.vel(N) == u1 * N.x + q1.diff(t) * N.y + q2.diff(t) * B.z\n"], "sample_1137": ["def test_check_dimensions():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    w = Quantity(\"w\")\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    assert check_dimensions(u + v) == u + v\n    assert check_dimensions(u - v) == u - v\n    raises(ValueError, lambda: check_dimensions(u + w))\n    raises(ValueError, lambda: check_dimensions(u - w))\n    raises(ValueError, lambda: check_dimensions(u + 1))\n    raises(ValueError, lambda: check_dimensions(u - 1))\n"], "sample_1139": ["def test_issue_18999():\n    n = Symbol('n', integer=True)\n    m = Symbol('m', integer=True)\n    assert Range(n, n + 49).is_finite_set is True\n    assert Range(n, 0).is_finite_set is True\n    assert Range(-3, n + 7).is_finite_set is True\n    assert Range(n, m).is_finite_set is True\n    assert Range(n + m, m - n).is_finite_set is True\n    assert Range(n, n + m + n).is_finite_set is True\n    assert Range(n, oo).is_finite_set is False\n    assert Range(-oo, n).is_finite_set is False\n    assert Range(n, -oo).is_finite_set is True\n    assert Range(oo, n).is_finite_set is True\n"], "sample_1144": ["def test_split_super_sub_edge_cases():\n    assert split_super_sub(\"a\") == (\"a\", [], [])\n    assert split_super_sub(\"_a\") == (\"\", [], [\"a\"])\n    assert split_super_sub(\"^a\") == (\"\", [\"a\"], [])\n    assert split_super_sub(\"__a\") == (\"\", [\"a\"], [])\n    assert split_super_sub(\"a__\") == (\"a\", [], [])\n    assert split_super_sub(\"a^\") == (\"a\", [], [])\n    assert split_super_sub(\"a_\") == (\"a\", [], [])\n    assert split_super_sub(\"\") == (\"\", [], [])\n    assert split_super_sub(\"   \") == (\"\", [], [])\n"], "sample_1145": ["def test_refine_Pow_non_integer():\n    x = Symbol('x', real=True)\n    y = Symbol('y', real=True)\n    assert refine((-1)**(x + y/2), Q.even(x)) == (-1)**(y/2)\n    assert refine((-1)**(x + y/2), Q.odd(x)) == -(-1)**(y/2)\n    assert refine((-1)**(x + y/4), Q.even(x)) == (-1)**(y/4)\n    assert refine((-1)**(x + y/4), Q.odd(x)) == -(-1)**(y/4)\n"], "sample_1149": ["def test_singleton_registry_repr():\n    assert repr(S) == 'S'\n"], "sample_1150": ["def test_issue_18999():\n    n = Symbol('n', integer=True)\n    assert Range(n, -n).is_finite_set is True\n    assert Range(-n, n).is_finite_set is True\n    assert Range(n, n + 10).is_finite_set is True\n    assert Range(n - 10, n).is_finite_set is True\n    assert Range(n, n + n).is_finite_set is True\n    assert Range(n - n, n).is_finite_set is True\n    assert Range(n, oo).is_finite_set is False\n    assert Range(-oo, n).is_finite_set is False\n"], "sample_1151": ["def test_Mod_is_integer():\n    x = Symbol('x')\n    y = Symbol('y', integer=True)\n    assert Mod(x, y).is_integer is None\n    assert Mod(y, x).is_integer is None\n    assert Mod(3.2, 2).is_integer is False\n    assert Mod(3.0, 2).is_integer is True\n    assert Mod(Rational(3, 2), 2).is_integer is False\n    assert Mod(Rational(4, 2), 2).is_integer is True\n"], "sample_1152": ["def test_issue_20443():\n    x, y = symbols('x y', real=True)\n    assert powsimp((x**2 + 2*x*y + y**2)**Rational(1, 4)) == (x + y)**Rational(1, 2)\n    assert powsimp((x**2 - 2*x*y + y**2)**Rational(1, 4)) == (x - y)**Rational(1, 2)\n"], "sample_1154": ["def test__linsolve_empty_symbols():\n    assert _linsolve([x-1], []) is None\n    assert _linsolve([], []) == {}\n    assert _linsolve([S.Zero], []) == {}\n"], "sample_1155": ["def test_construct_domain_with_dict():\n    # Test construct_domain with a dictionary of expressions\n    d = {(1, 2): x + y, (3, 4): x - y}\n    domain, result = construct_domain(d)\n    assert isinstance(domain, EX)\n    assert isinstance(result, dict)\n    assert len(result) == 2\n    assert result[(1, 2)] == EX(x + y)\n    assert result[(3, 4)] == EX(x - y)\n\n    # Test construct_domain with an empty dictionary\n    d = {}\n    domain, result = construct_domain(d)\n    assert domain == ZZ\n    assert result == {}\n\n    # Test construct_domain with a dictionary containing only numbers\n    d = {(1, 2): 1, (3, 4): 2}\n    domain, result = construct_domain(d)\n    assert domain == ZZ\n    assert result == {(1, 2): ZZ(1), (3, 4): ZZ(2)}\n"], "sample_1157": ["def test_lambda_notation():\n    transformations = standard_transformations + (lambda_notation,)\n    x = Symbol('x')\n    y = Symbol('y')\n\n    assert parse_expr(\"lambda x: x**2\", transformations=transformations) == Lambda(x, x**2)\n    assert parse_expr(\"(lambda x: x**2)(y)\", transformations=transformations) == Lambda(x, x**2)(y)\n"], "sample_1158": ["def test_issue_21645():\n    # Test to check sympify of nested iterables with evaluate=False\n    u = sympify(\"x+3*x+2\", evaluate=False)\n    v = sympify(\"2*x+4*x+2+4\", evaluate=False)\n    nested_list = [[\"x+3*x+2\", \"2*x+4*x+2+4\"], [\"x+1\", \"x+2\"]]\n    result = sympify(nested_list, evaluate=False)\n    assert result == [[u, v], [sympify(\"x+1\", evaluate=False), sympify(\"x+2\", evaluate=False)]]\n"], "sample_1159": ["def test_issue_18161():\n    x = Symbol('x', real=True)\n    assert (x**2).is_nonnegative is True\n    assert (x**2).is_positive is None\n    assert (x**3).is_nonnegative is None\n    assert (x**3).is_positive is None\n"], "sample_1162": ["def test_Function_kind():\n    from sympy.core.function import Function\n    f = Function('f')\n    assert f(comm_x).kind is NumberKind\n    assert f(noncomm_x).kind is UndefinedKind\n"], "sample_1166": ["def test_MonomialOps():\n    mo = MonomialOps(3)\n\n    assert mo.mul()( (1, 2, 3), (4, 5, 6) ) == (5, 7, 9)\n    assert mo.pow()( (1, 2, 3), 2 ) == (2, 4, 6)\n    assert mo.mulpow()( (1, 2, 3), (4, 5, 6), 2 ) == (9, 12, 15)\n    assert mo.ldiv()( (4, 5, 6), (1, 2, 3) ) == (3, 3, 3)\n    assert mo.div()( (4, 5, 6), (1, 2, 3) ) == (3, 3, 3)\n    assert mo.lcm()( (1, 2, 3), (4, 5, 6) ) == (4, 5, 6)\n    assert mo.gcd()( (4, 5, 6), (1, 2, 3) ) == (1, 2, 3)\n"], "sample_1170": ["def test_printing_str_DMP():\n    from sympy.polys.domains import ZZ\n    from sympy.polys.rings import ring\n\n    R, x = ring(\"x\", ZZ)\n    p = R(2*x + 1)\n    assert sstr(p) == \"Poly(2*x + 1, x, domain='ZZ')\"\n"], "sample_1171": ["def test_issue_18999():\n    n = Symbol('n', integer=True)\n    assert Range(n, n+1).is_finite_set is True\n    assert Range(n, n-1).is_finite_set is True\n    assert Range(n, n+2).is_finite_set is True\n    assert Range(n, n-2).is_finite_set is True\n    assert Range(n, n+n).is_finite_set is True\n    assert Range(n, n-n).is_finite_set is True\n    assert Range(n, n+1, 2).is_finite_set is True\n    assert Range(n, n-1, -2).is_finite_set is True\n    assert Range(n, n+2, 2).is_finite_set is True\n    assert Range(n, n-2, -2).is_finite_set is True\n    assert Range(n, n+n, n).is_finite_set is True\n    assert Range(n, n-n, -n).is_finite_set is True\n"], "sample_1172": ["def test_solve_generic():\n    f_1 = x**2 + y - 1\n    f_2 = x + y**2 - 1\n\n    assert solve_generic([f_1, f_2], (x, y)) == \\\n        [(0, 1), (1, 0)]\n\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    a, b = sqrt(2) - 1, -sqrt(2) - 1\n\n    assert solve_generic([f_1, f_2, f_3], (x, y, z)) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0), (a, a, a), (b, b, b)]\n\n    raises(NotImplementedError, lambda: solve_generic([x**3 - y**3], (x, y)))\n    raises(NotImplementedError, lambda: solve_generic(\n        [z, -2*x*y**2 + x + y**2*z, y**2*(-z - 4) + 2]))\n    raises(PolynomialError, lambda: solve_generic([1/x], x))\n"], "sample_1173": ["def test_parse_expr_evaluate_false():\n    x = Symbol('x')\n    y = Symbol('y')\n    expr1 = parse_expr('2*x + 3*y', evaluate=False)\n    expr2 = parse_expr('2*x + 3*y')\n    assert expr1 == expr2\n    assert expr1.args == (2*x, 3*y)\n    assert expr2.args == (2*x, 3*y)\n    assert expr1.func == Add\n    assert expr2.func == Add\n"], "sample_1182": ["def test_SymPyPrinter():\n    p = SymPyPrinter()\n    expr = acos(x)\n    assert 'sympy' not in p.module_imports\n    assert p.doprint(expr) == 'sympy.acos(x)'\n    assert 'sympy' in p.module_imports\n\n    smat = SparseMatrix(2, 5, {(0, 1): 3})\n    assert p.doprint(smat) == \\\n        'sympy.Matrix([[0, 3, 0, 0, 0], [0, 0, 0, 0, 0]], dtype=\"object\")'\n    assert 'sympy' in p.module_imports\n\n    assert p.doprint(S.GoldenRatio) == 'sympy.GoldenRatio'\n    assert p.doprint(S.Pi) == 'sympy.pi'\n    assert p.doprint(S.Exp1) == 'sympy.E'\n"], "sample_1183": ["def test_FracField_from_expr():\n    K, x = field(\"x\", ZZ)\n    assert K.from_expr(x) == x\n    assert K.from_expr(1/x) == 1/x\n    assert K.from_expr(x**2 + 1/x) == x**2 + 1/x\n    assert K.from_expr((x + 1)/(x - 1)) == (x + 1)/(x - 1)\n\n    K, x, y = field(\"x,y\", ZZ)\n    assert K.from_expr(x/y) == x/y\n    assert K.from_expr(y/x) == y/x\n    assert K.from_expr((x + y)/(x - y)) == (x + y)/(x - y)\n"], "sample_1185": ["def test_decompogen_pow():\n    assert decompogen(x**2, x) == [x**2]\n    assert decompogen(exp(x), x) == [exp(x)]\n    assert decompogen(exp(x**2), x) == [exp(x), x**2]\n    assert decompogen((x**2)**3, x) == [x**3, x**2]\n"], "sample_1186": ["def test_array_equality():\n    for ArrayType in array_types:\n        A = ArrayType([1, 2, 3])\n        B = ArrayType([1, 2, 3])\n        C = ArrayType([4, 5, 6])\n        D = ArrayType([1, 2])\n\n        assert A == B\n        assert A != C\n        assert A != D\n\n        # Test equality with different types\n        if ArrayType is ImmutableDenseNDimArray:\n            E = MutableDenseNDimArray([1, 2, 3])\n            assert A == E\n"], "sample_1189": ["def test_lambdify_with_cse():\n    from sympy.simplify.cse_main import cse\n\n    x, y = symbols('x y')\n    expr = (x + y) * (x - y)\n    cses, red_exprs = cse(expr)\n\n    f = lambdify((x, y), expr, cse=True)\n    assert f(1, 2) == -3\n\n    f = lambdify((x, y), expr, cse=False)\n    assert f(1, 2) == -3\n\n    f = lambdify((x, y), expr, cse=cses)\n    assert f(1, 2) == -3\n"], "sample_1190": ["def test_unit_system_get_default():\n    default_unit_system = UnitSystem.get_default_unit_system()\n    assert default_unit_system.name == \"SI\"\n    assert default_unit_system.dim == 7\n    assert default_unit_system.is_consistent\n"], "sample_1191": ["def test_hermite_normal_form_modulo_D():\n    m = DM([[2, 7, 17, 29, 41], [3, 11, 19, 31, 43], [5, 13, 23, 37, 47]], ZZ)\n    hnf = DM([[1, 0, 0], [0, 2, 1], [0, 0, 1]], ZZ)\n    assert _hermite_normal_form_modulo_D(m, ZZ(96)) == hnf\n\n    m = DM([[8, 28, 68, 116, 164], [3, 11, 19, 31, 43], [5, 13, 23, 37, 47]], ZZ)\n    hnf = DM([[4, 0, 0], [0, 2, 1], [0, 0, 1]], ZZ)\n    assert _hermite_normal_form_modulo_D(m, ZZ(8)) == hnf\n\n    raises(DMDomainError, lambda: _hermite_normal_form_modulo_D(m, QQ(96)))\n    raises(DMShapeError, lambda: _hermite_normal_form_modulo_D(DM([[1, 2]], ZZ), ZZ(1)))\n"], "sample_1192": ["def test__symbol():\n    x = Symbol('x')\n    assert _symbol(x) == x\n    assert _symbol('x') == x\n    assert _symbol('y', x) == Symbol('y')\n    assert _symbol('x', x, real=True) == x\n    assert _symbol('x', real=True).is_real\n    raises(ValueError, lambda: _symbol(1))\n"], "sample_1193": ["def test_are_similar():\n    from sympy import Circle, Triangle\n    c1, c2 = Circle(Point(0, 0), 4), Circle(Point(1, 4), 3)\n    t1 = Triangle(Point(0, 0), Point(1, 0), Point(0, 1))\n    t2 = Triangle(Point(0, 0), Point(2, 0), Point(0, 2))\n    t3 = Triangle(Point(0, 0), Point(3, 0), Point(0, 1))\n\n    assert are_similar(t1, t2) == True\n    assert are_similar(t1, t3) == False\n    raises(GeometryError, lambda: are_similar(c1, t1))\n"], "sample_1194": ["def test_julia_inline_piecewise_times_const():\n    pw = Piecewise((x, x < 1), (x**2, True))\n    assert julia_code(2*pw, inline=True) == \"2 * ((x < 1) ? (x) : (x .^ 2))\"\n    assert julia_code(pw/x, inline=True) == \"((x < 1) ? (x) : (x .^ 2)) ./ x\"\n    assert julia_code(pw/(x*y), inline=True) == \"((x < 1) ? (x) : (x .^ 2)) ./ (x .* y)\"\n    assert julia_code(pw/3, inline=True) == \"((x < 1) ? (x) : (x .^ 2)) / 3\"\n"], "sample_1195": ["def test_simplify_gpgp():\n    i0, i1, i2, i3, i4, i5 = tensor_indices('i0:6', LorentzIndex)\n    p, q = tensor_heads('p, q', [LorentzIndex])\n    ps = p(i0)*G(-i0)\n    qs = q(i0)*G(-i0)\n\n    t = ps*qs*qs\n    r = simplify_gpgp(t)\n    assert _is_tensor_eq(r, G(-i0)*p(i0)*q(i1)*q(-i1))\n\n    t = ps*qs*ps*qs\n    r = simplify_gpgp(t)\n    assert _is_tensor_eq(r, 8*p(i0)*q(-i0)*p(i1)*q(-i1) - 4*p(i0)*p(-i0)*q(i1)*q(-i1))\n"], "sample_1196": ["def test_contains_eval_method():\n    x = Symbol('x')\n    s = FiniteSet(1, 2, 3)\n    assert Contains.eval(x, s) == Contains(x, s)\n    assert Contains.eval(1, s) is S.true\n    assert Contains.eval(4, s) is S.false\n"], "sample_1197": ["def test_get_units_non_prefixed():\n    assert set(SI.get_units_non_prefixed()) == {\n        meter, second, joule, kilogram, volt, ohm, farad, gram, Da,\n        gravitational_constant, molar_gas_constant, vacuum_permittivity,\n        speed_of_light, elementary_charge\n    }\n"], "sample_1198": ["def test_parser_mathematica_function():\n    parser = MathematicaParser()\n\n    convert_chain = lambda expr: parser._from_tokens_to_fullformlist(parser._from_mathematica_to_tokens(expr))\n\n    # Test function with no arguments\n    assert convert_chain(\"f[]\") == [\"f\"]\n\n    # Test function with one argument\n    assert convert_chain(\"f[x]\") == [\"f\", \"x\"]\n\n    # Test function with multiple arguments\n    assert convert_chain(\"f[x, y, z]\") == [\"f\", \"x\", \"y\", \"z\"]\n\n    # Test function with nested arguments\n    assert convert_chain(\"f[g[x], h[y, z]]\") == [\"f\", [\"g\", \"x\"], [\"h\", \"y\", \"z\"]]\n\n    # Test function with prefix operator\n    assert convert_chain(\"!x\") == [\"Not\", \"x\"]\n\n    # Test function with postfix operator\n    assert convert_chain(\"x'\") == [\"Derivative\", \"x\"]\n\n    # Test function with infix operator\n    assert convert_chain(\"x + y\") == [\"Plus\", \"x\", \"y\"]\n"], "sample_1199": ["def test_tensor_product_simp_Mul_with_Pow():\n    # tests for Mul with Pow-expressions\n    assert tensor_product_simp(TP(A, B)**x * TP(C, D)) == TP(A**x*C, B**x*D)\n    assert tensor_product_simp(x*TP(A, B)**2 * TP(C,D)) == x*TP(A**2*C,B**2*D)\n"], "sample_1200": ["def test_get_units_non_prefixed():\n    assert set(SI.get_units_non_prefixed()) == {\n        meter, second, joule, kilogram, coulomb, volt, ohm, farad,\n        henry, siemens, weber, tesla, newton, pascal, hertz, radian,\n        steradian, lux, becquerel, gray, sievert, katal\n    }\n"], "sample_1201": ["def test_cgs_gauss_convert_units():\n    assert convert_to(statvolt, erg/statcoulomb, cgs_gauss) == erg/statcoulomb\n    assert convert_to(statampere, statcoulomb/second, cgs_gauss) == statcoulomb/second\n    assert convert_to(gauss, sqrt(gram/centimeter)/second, cgs_gauss) == sqrt(gram/centimeter)/second\n    assert convert_to(maxwell, sqrt(centimeter**3*gram)/second, cgs_gauss) == sqrt(centimeter**3*gram)/second\n\n    assert convert_to(tesla, gauss, cgs_gauss) == 10**4*gauss\n    assert convert_to(weber, maxwell, cgs_gauss) == 10**8*maxwell\n    assert convert_to(coulomb, statcoulomb, cgs_gauss) == 10*299792458*statcoulomb\n    assert convert_to(ampere, statampere, cgs_gauss) == 10*299792458*statampere\n    assert convert_to(volt, statvolt, cgs_gauss) == 10**6*statvolt/299792458\n"], "sample_1207": ["def test_parse_expr_evaluate_false():\n    x = Symbol('x')\n    y = Symbol('y')\n\n    # Test that evaluate=False preserves the order of arguments\n    expr1 = parse_expr('x + y', evaluate=False)\n    expr2 = parse_expr('y + x', evaluate=False)\n    assert expr1 != expr2\n\n    # Test that evaluate=False suppresses automatic simplification\n    expr1 = parse_expr('2**3', evaluate=False)\n    assert expr1 != 8\n    assert expr1 == 2**3\n"], "sample_1209": ["def test_prefix_properties():\n    k = PREFIXES['k']\n    assert k.name == 'kilo'\n    assert k.abbrev == 'k'\n    assert k.scale_factor == 1000\n    assert k.base == 10\n    assert str(k) == 'k'\n    assert repr(k) == \"Prefix('kilo', 'k', 3)\"\n"], "sample_2": ["def test_ccddata_to_hdu_with_flags(tmpdir):\n    ccd_data = create_ccd_data()\n    flags = np.ones_like(ccd_data.data, dtype=np.uint8)\n    ccd_data.flags = flags\n    with pytest.raises(NotImplementedError):\n        ccd_data.to_hdu(hdu_flags='FLAGS')\n"], "sample_4": ["def test_readwrite_html_table_format_argument(self, read, write, tmp_path):\n    \"\"\"Test if format argument is correctly handled\"\"\"\n    fp = tmp_path / \"test_readwrite_html_table_format_argument.html\"\n\n    # Test that format argument is set to 'ascii.html' by default\n    write(fp)\n    assert QTable.read(fp, format=\"ascii.html\")\n\n    # Test that format argument can be explicitly set to 'ascii.html'\n    write(fp, format=\"ascii.html\")\n    assert QTable.read(fp, format=\"ascii.html\")\n\n    # Test that format argument cannot be set to anything other than 'ascii.html'\n    with pytest.raises(ValueError, match=\"format must be 'ascii.html', not\"):\n        write(fp, format=\"csv\")\n"], "sample_11": ["def test_sliced_low_level_wcs_repr_with_no_pixel_bounds():\n    wcs = WCS_SPECTRAL_CUBE\n    wcs.pixel_bounds = None\n    sliced_wcs = SlicedLowLevelWCS(wcs, Ellipsis)\n    assert \"Bounds\" not in str(sliced_wcs)\n"], "sample_15": ["    def test_trace(self):\n        q = np.array([[1.0, 2.0], [3.0, 4.0]]) * u.m\n        assert np.trace(q).unit == u.m\n        assert np.trace(q).value == np.trace(q.value)\n"], "sample_17": ["    def setup_class(self):\n        self.pv_dtype = np.dtype([(\"p\", \"f8\"), (\"v\", \"f8\")])\n        self.pv_t_dtype = np.dtype(\n            [(\"pv\", np.dtype([(\"pp\", \"f8\"), (\"vv\", \"f8\")])), (\"t\", \"f8\")]\n        )\n\n        self.pv = np.array([(1.0, 0.25), (2.0, 0.5), (3.0, 0.75)], self.pv_dtype)\n        self.pv_t = np.array(\n            [((4.0, 2.5), 0.0), ((5.0, 5.0), 1.0), ((6.0, 7.5), 2.0)], self.pv_t_dtype\n        )\n\n        self.pv_unit = u.StructuredUnit((u.km, u.km / u.s), (\"p\", \"v\"))\n        self.pv_t_unit = u.StructuredUnit((self.pv_unit, u.s), (\"pv\", \"t\"))\n\n        self.q_pv = self.pv << self.pv_unit\n        self.q_pv_t = self.pv_t << self.pv_t_unit\n"], "sample_18": ["    def setup_class(self):\n        self.q = u.Quantity(np.arange(1.0, 5.0), \"m/s\")\n        self.q.info.name = \"v\"\n        self.q.info.description = \"air speed of a african swallow\"\n"], "sample_24": ["    def test_einsum(self):\n        a = np.arange(25).reshape(5, 5)\n        mask_a = np.zeros_like(a, dtype=bool)\n        mask_a[1, 1] = True\n        ma = Masked(a, mask=mask_a)\n        b = np.arange(5)\n        mask_b = np.array([False, False, True, False, False])\n        mb = Masked(b, mask=mask_b)\n        out = np.einsum(\"ij,j->i\", ma, mb)\n        expected_data = np.einsum(\"ij,j->i\", a, b)\n        expected_mask = np.einsum(\"ij,j->i\", mask_a.astype(int), ~mask_b.astype(int)) > 0\n        assert_array_equal(out.unmasked, expected_data)\n        assert_array_equal(out.mask, expected_mask)\n"], "sample_40": ["def test_with_H0_roundtrip():\n    H0_70 = 70*u.km/u.s/u.Mpc\n    h100dist = 100 * u.Mpc/u.littleh\n\n    roundtripped = h100dist.to(u.Mpc/u.littleh, u.with_H0(H0_70))\n    assert_quantity_allclose(roundtripped, h100dist)\n"], "sample_45": ["def test_trunc_func_with_timezone_transition(self):\n    \"\"\"\n    If the truncated datetime transitions to a different offset (daylight\n    saving) then the returned value will have that new timezone/offset.\n    \"\"\"\n    start_datetime = datetime(2018, 3, 11, 1, 30, 50, 321)\n    end_datetime = datetime(2018, 11, 4, 1, 10, 50, 123)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n    self.create_model(end_datetime, start_datetime)\n\n    nyc = pytz.timezone('America/New_York')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=DateTimeField(), tzinfo=nyc)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(nyc), kind, nyc)),\n                (end_datetime, truncate_to(end_datetime.astimezone(nyc), kind, nyc))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_datetime_kind('hour')\n    test_datetime_kind('minute')\n    test_datetime_kind('second')\n"], "sample_46": ["    def setUpTestData(cls):\n        cls.objs = [\n            UUIDModel.objects.create(field=uuid.uuid4()),\n            UUIDModel.objects.create(field='550e8400e29b41d4a716446655440000'),\n        ]\n"], "sample_52": ["def test_model_choice_field_with_limit_choices_to(self):\n    f = forms.ModelChoiceField(Category.objects.all(), limit_choices_to={'name__startswith': 'A'})\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c2.pk, 'A test'),\n    ])\n    with self.assertRaises(ValidationError):\n        f.clean(self.c1.id)\n    self.assertEqual(f.clean(self.c2.id).name, 'A test')\n"], "sample_64": ["    def test_set_cookie(self):\n        response = HttpResponse()\n        response.set_cookie('foo', 'bar')\n        self.assertIn('foo=bar', response.cookies.output(header=''))\n"], "sample_67": ["    def test_disabled_fields(self):\n        class DisabledFieldsForm(forms.ModelForm):\n            class Meta:\n                model = Category\n                fields = '__all__'\n                widgets = {\n                    'name': forms.TextInput(attrs={'disabled': True}),\n                }\n\n        form = DisabledFieldsForm()\n        self.assertEqual(form.fields['name'].widget.attrs, {'disabled': True})\n        self.assertTrue(form.fields['name'].disabled)\n"], "sample_73": ["    def setUp(self):\n        super().setUp()\n        self._temp_dir = temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, 'test'))\n        self.addCleanup(shutil.rmtree, temp_dir)\n"], "sample_75": ["    def setUpTestData(cls):\n        cls.book1 = Book.objects.create(title='Poems')\n        cls.book2 = Book.objects.create(title='Jane Eyre')\n        cls.author1 = Author.objects.create(name='Charlotte', first_book=cls.book1)\n        cls.author2 = Author.objects.create(name='Anne', first_book=cls.book1)\n        cls.author3 = Author.objects.create(name='Emily', first_book=cls.book2)\n"], "sample_88": ["def test_sanitize_address_with_non_ascii_display_name(self):\n    \"\"\"\n    Email addresses with non-ASCII display names are properly sanitized.\n    \"\"\"\n    email_address = ('Firstname S\u00fcrname', 'to@example.com')\n    sanitized_address = sanitize_address(email_address, encoding='utf-8')\n    self.assertEqual(sanitized_address, '=?utf-8?q?Firstname_S=C3=BCrname?= <to@example.com>')\n"], "sample_90": ["    def test_disabled_fields(self):\n        class DisabledFieldsForm(forms.ModelForm):\n            class Meta:\n                model = Category\n                fields = '__all__'\n                widgets = {\n                    'name': forms.TextInput(attrs={'disabled': True}),\n                }\n\n        form = DisabledFieldsForm()\n        self.assertIn('disabled', str(form['name']))\n\n        # The field is not in cleaned_data if it's disabled.\n        data = {'slug': 'test', 'url': '/test'}\n        form = DisabledFieldsForm(data=data)\n        self.assertTrue(form.is_valid())\n        self.assertNotIn('name', form.cleaned_data)\n\n        # If the instance has a value, it's used instead of the disabled field's value.\n        category = Category.objects.create(name='Test', slug='test', url='/test')\n        form = DisabledFieldsForm(instance=category, data=data)\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['name'], 'Test')\n\n        # If the field isn't in the form, the instance's value is used.\n        class PartialForm(forms.ModelForm):\n            class Meta:\n                model = Category\n                fields = ('slug', 'url')\n\n        form = PartialForm(instance=category, data=data)\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.cleaned_data['name'], 'Test')\n"], "sample_93": ["def test_expression_wrapper(self):\n    wrapper = ExpressionWrapper(F('price'), output_field=DecimalField())\n    self.assertEqual(wrapper.output_field, DecimalField())\n    self.assertEqual(wrapper.expression, F('price'))\n    self.assertEqual(wrapper.as_sql(None, connection), F('price').as_sql(None, connection))\n"], "sample_95": ["    def test_patch_vary_headers(self):\n        response = HttpResponse()\n        patch_vary_headers(response, ['Accept-Language'])\n        self.assertEqual(response['Vary'], 'Accept-Language')\n"], "sample_96": ["    def test_not_callable_or_boolean(self):\n        class TestModelAdmin(ModelAdmin):\n            view_on_site = 'hello'\n\n        self.assertIsInvalid(\n            TestModelAdmin, ValidationTestModel,\n            \"The value of 'view_on_site' must be a callable or a boolean value.\",\n            'admin.E025'\n        )\n"], "sample_99": ["def test_trunc_func_with_timezone_transition(self):\n    sao = pytz.timezone('America/Sao_Paulo')\n    start_datetime = datetime(2016, 10, 16, 1)\n    end_datetime = datetime(2017, 2, 19, 23)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=DateTimeField(), tzinfo=sao)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(sao), kind, sao)),\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_datetime_kind('day')\n    test_datetime_kind('hour')\n"], "sample_97": ["    def test_ensure_echo_on_calls_tcsetattr(self, mocked_termios):\n        with mock.patch('sys.stdin.isatty', return_value=True):\n            autoreload.ensure_echo_on()\n        self.assertEqual(mocked_termios.tcsetattr.call_count, 1)\n"], "sample_104": ["    def test_manifest_version(self):\n        # Check that the manifest version is written to the manifest file.\n        manifest_content = storage.staticfiles_storage.read_manifest()\n        self.assertIn(\n            '\"version\": \"%s\"' % storage.staticfiles_storage.manifest_version,\n            manifest_content\n        )\n\n        # Check that the manifest version is read from the manifest file.\n        loaded_manifest = storage.staticfiles_storage.load_manifest()\n        self.assertEqual(loaded_manifest['version'], storage.staticfiles_storage.manifest_version)\n\n        # Check that an incorrect manifest version raises an error.\n        with mock.patch('django.contrib.staticfiles.storage.ManifestFilesMixin.load_manifest') as mock_load_manifest:\n            mock_load_manifest.return_value = {'version': 'invalid'}\n            with self.assertRaisesMessage(ValueError, \"Couldn't load manifest\"):\n                storage.staticfiles_storage.load_manifest()\n"], "sample_109": ["def test_render_options_with_empty_value(self):\n    \"\"\"Empty option is selected if the field's value is empty.\"\"\"\n    form = NotRequiredBandForm()\n    output = form.as_table()\n    self.assertIn('<option value=\"\" selected></option>', output)\n"], "sample_110": ["    def test_resolve_expression(self):\n        # Ensure that expressions resolve correctly\n        expr = F('name')\n        resolved_expr = expr.resolve_expression(query=None, allow_joins=True, reuse=None, summarize=False, for_save=False)\n        self.assertEqual(resolved_expr, expr)\n\n        # Ensure that expressions with lookups resolve correctly\n        lookup_expr = F('name__lower')\n        resolved_lookup_expr = lookup_expr.resolve_expression(query=None, allow_joins=True, reuse=None, summarize=False, for_save=False)\n        self.assertEqual(resolved_lookup_expr, lookup_expr)\n"], "sample_116": ["    def test_without_vary_on(self):\n        key = make_template_fragment_key('a.fragment')\n        self.assertEqual(key, 'template.cache.a.fragment.d41d8cd98f00b204e9800998ecf8427e')\n"], "sample_119": ["def test_clone_deferred_loading(self):\n    query = Query(Item)\n    query.add_deferred_loading(['modified'])\n    clone = query.clone()\n    clone.add_deferred_loading(['created'])\n    self.assertEqual(query.deferred_loading, (frozenset(['modified']), True))\n"], "sample_130": ["def test_add_immediate_loading(self):\n    query = Query(Author)\n    query.add_immediate_loading(['name', 'num'])\n    self.assertEqual(query.deferred_loading, (frozenset(['name', 'num']), False))\n    query.add_immediate_loading(['extra'])\n    self.assertEqual(query.deferred_loading, (frozenset(['name', 'num', 'extra']), False))\n"], "sample_136": ["def test_split_domain_port_ipv6(self):\n    domain, port = split_domain_port('[2001:19f0:feee::dead:beef:cafe]:8080')\n    self.assertEqual(domain, '[2001:19f0:feee::dead:beef:cafe]')\n    self.assertEqual(port, '8080')\n\n    domain, port = split_domain_port('[2001:19f0:feee::dead:beef:cafe]')\n    self.assertEqual(domain, '[2001:19f0:feee::dead:beef:cafe]')\n    self.assertEqual(port, '')\n"], "sample_145": ["    def test_not_boolean_or_callable(self):\n        class TestModelAdmin(ModelAdmin):\n            view_on_site = 'hello'\n\n        self.assertIsInvalid(\n            TestModelAdmin, ValidationTestModel,\n            \"The value of 'view_on_site' must be a callable or a boolean value.\",\n            'admin.E025'\n        )\n"], "sample_151": ["def test_mti_inheritance_model_removal_with_fk(self):\n    Animal = ModelState('app', 'Animal', [\n        (\"id\", models.AutoField(primary_key=True)),\n    ])\n    Dog = ModelState('app', 'Dog', [], bases=('app.Animal',))\n    Kennel = ModelState('app', 'Kennel', [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"dog\", models.ForeignKey(\"app.Dog\", models.CASCADE)),\n    ])\n    changes = self.get_changes([Animal, Dog, Kennel], [Animal])\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'DeleteModel', 'DeleteModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, model_name='kennel', name='dog')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='Dog')\n    self.assertOperationAttributes(changes, 'app', 0, 2, name='Kennel')\n"], "sample_153": ["    def test_model_unpickle(self):\n        # Create a model instance and pickle it.\n        from django.apps import apps\n        model = apps.get_model('auth', 'User')\n        instance = model()\n        pickled_instance = (model._meta.app_label, model._meta.object_name)\n\n        # Unpickle the instance and check that it's an instance of the correct model.\n        unpickled_instance = model_unpickle(pickled_instance)\n        self.assertIsInstance(unpickled_instance, model)\n"], "sample_169": ["    def test_serialize_deserialize(self):\n        obj = JSONModel(value={'a': 'b', 'c': 14})\n        obj.save()\n        data = serializers.serialize('xml', [obj])\n        new_obj = list(serializers.deserialize('xml', data))[0].object\n        self.assertEqual(new_obj.value, obj.value)\n"], "sample_172": ["    def test_widget_render(self):\n        profile = Profile.objects.create(user=User.objects.create_user('testuser'))\n        rel = Profile._meta.get_field('user').remote_field\n        widget = widgets.ForeignKeyWidget(rel, admin.site)\n        output = widget.render('user', profile.user_id)\n        self.assertHTMLEqual(\n            output,\n            '<select name=\"user\">'\n            '<option value=\"\" selected>---------</option>'\n            '<option value=\"%(user_pk)s\" selected>testuser</option>'\n            '</select>' % {'user_pk': profile.user.pk},\n        )\n"], "sample_184": ["    def test_model_attribute(self):\n        class Model(models.Model):\n            pass\n\n        self.assertEqual(Model.check(), [])\n"], "sample_209": ["    def test_fields_cache(self):\n        worker = Worker.objects.create(name='worker', department_id=1)\n        self.assertEqual(worker._state.fields_cache, {})\n        # Accessing a field should populate the fields cache.\n        worker.name\n        self.assertIn('name', worker._state.fields_cache)\n"], "sample_215": ["    def test_get_traceback_data(self):\n        try:\n            request = self.rf.get('/test_view/')\n            raise ValueError(\"Can't find my keys\")\n        except ValueError:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIn('request', data)\n        self.assertIn('request_meta', data)\n        self.assertIn('filtered_POST_items', data)\n        self.assertIn('settings', data)\n        self.assertIn('sys_executable', data)\n        self.assertIn('sys_version_info', data)\n        self.assertIn('server_time', data)\n        self.assertIn('django_version_info', data)\n        self.assertIn('sys_path', data)\n        self.assertIn('template_info', data)\n        self.assertIn('template_does_not_exist', data)\n        self.assertIn('postmortem', data)\n"], "sample_217": ["def test_media_absolute_path(self):\n    media = Media(css={'screen': ['path/to/css1']}, js=['/path/to/js1', 'http://media.other.com/path/to/js2'])\n    self.assertEqual(media.absolute_path('path/to/css1'), 'http://media.example.com/static/path/to/css1')\n    self.assertEqual(media.absolute_path('/path/to/js1'), '/path/to/js1')\n    self.assertEqual(media.absolute_path('http://media.other.com/path/to/js2'), 'http://media.other.com/path/to/js2')\n"], "sample_221": ["def test_pickle_union_queryset(self):\n    group1 = Group.objects.create(name='Group 1')\n    group2 = Group.objects.create(name='Group 2')\n    Event.objects.create(title='Event 1', group=group1)\n    Event.objects.create(title='Event 2', group=group2)\n\n    qs1 = Event.objects.filter(group=group1)\n    qs2 = Event.objects.filter(group=group2)\n    union_qs = qs1.union(qs2)\n\n    self.assert_pickles(union_qs)\n"], "sample_225": ["    def setUpTestData(cls):\n        cls.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n"], "sample_236": ["def test_collector_sort(self):\n    # Create a collector and add some objects to it.\n    collector = Collector(using='default')\n    r1 = R.objects.create()\n    r2 = R.objects.create()\n    s1 = S.objects.create(r=r1)\n    s2 = S.objects.create(r=r2)\n    t1 = T.objects.create(s=s1)\n    t2 = T.objects.create(s=s2)\n\n    # Add the objects to the collector in a mixed order.\n    collector.add([t1, s1, r1, t2, s2, r2])\n\n    # Sort the collector.\n    collector.sort()\n\n    # Check that the objects are now in the correct deletion order.\n    self.assertEqual(\n        [model for model, _ in collector.instances_with_model()],\n        [T, T, S, S, R, R],\n    )\n"], "sample_238": ["def test_aggregation_with_expression_wrapper(self):\n    wrapper = ExpressionWrapper(F('price') + F('rating'), output_field=FloatField())\n    qs = Book.objects.annotate(total=wrapper).aggregate(Avg('total'))\n    self.assertAlmostEqual(qs['total__avg'], 76.74, places=2)\n"], "sample_243": ["def test_build_lookup(self):\n    query = Query(Author)\n    lookup = query.build_lookup(['exact'], Col(Author._meta.get_field('name'), 'author'), 'foo')\n    self.assertIsInstance(lookup, Exact)\n    self.assertEqual(lookup.rhs, 'foo')\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('name'))\n\n    lookup = query.build_lookup(['isnull'], Col(Author._meta.get_field('name'), 'author'), True)\n    self.assertIsInstance(lookup, IsNull)\n    self.assertEqual(lookup.rhs, True)\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('name'))\n"], "sample_246": ["    def test_no_obsolete_enabled(self):\n        management.call_command('makemessages', locale=[LOCALE], verbosity=0, no_obsolete=True)\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertNotIn('#~ msgid \"\"', po_contents)\n"], "sample_263": ["def test_dumpdata_with_indent(self):\n    management.call_command('loaddata', 'fixture1.json', verbosity=0)\n    self._dumpdata_assert(\n        ['fixtures'],\n        '[\\n'\n        '    {\\n'\n        '        \"model\": \"fixtures.category\",\\n'\n        '        \"pk\": 1,\\n'\n        '        \"fields\": {\\n'\n        '            \"description\": \"Latest news stories\",\\n'\n        '            \"title\": \"News Stories\"\\n'\n        '        }\\n'\n        '    },\\n'\n        '    {\\n'\n        '        \"model\": \"fixtures.article\",\\n'\n        '        \"pk\": 2,\\n'\n        '        \"fields\": {\\n'\n        '            \"headline\": \"Poker has no place on ESPN\",\\n'\n        '            \"pub_date\": \"2006-06-16T12:00:00\"\\n'\n        '        }\\n'\n        '    },\\n'\n        '    {\\n'\n        '        \"model\": \"fixtures.article\",\\n'\n        '        \"pk\": 3,\\n'\n        '        \"fields\": {\\n'\n        '            \"headline\": \"Time to reform copyright\",\\n'\n        '            \"pub_date\": \"2006-06-16T13:00:00\"\\n'\n        '        }\\n'\n        '    }\\n'\n        ']',\n        indent=4\n    )\n"], "sample_267": ["    def test_database_wrapper_close(self):\n        # Ensure that the database connection is closed when the DatabaseWrapper\n        # is closed.\n        db = DatabaseWrapper({'NAME': ':memory:'})\n        db.connect()\n        self.assertTrue(db.connection)\n        db.close()\n        self.assertFalse(db.connection)\n"], "sample_268": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_270": ["    def test_default_pk(self):\n        class Model(models.Model):\n            pass\n\n        self.assertEqual(Model.check(), [\n            Warning(\n                f\"Auto-created primary key used when not defining a primary key type, by default '{settings.DEFAULT_AUTO_FIELD}'.\",\n                hint=(\n                    f\"Configure the DEFAULT_AUTO_FIELD setting or the \"\n                    f\"{Model._meta.app_config.__class__.__qualname__}.\"\n                    f\"default_auto_field attribute to point to a subclass \"\n                    f\"of AutoField, e.g. 'django.db.models.BigAutoField'.\"\n                ),\n                obj=Model,\n                id='models.W042',\n            ),\n        ])\n"], "sample_274": ["    def test_modelform_unique_error_messages(self):\n        # Create a model form with unique model fields.\n        from .models import UniqueModel\n\n        class UniqueForm(forms.ModelForm):\n            class Meta:\n                model = UniqueModel\n                fields = '__all__'\n\n        # Test unique error messages for single field.\n        f = UniqueForm({'name': 'Taken'})\n        self.assertFormErrors(['Name must be unique.'], f.clean)\n\n        # Test unique error messages for multiple fields.\n        f = UniqueForm({'name': 'Taken', 'birthdate': '2000-01-01'})\n        self.assertFormErrors(['Name and birthdate must be unique together.'], f.clean)\n"], "sample_279": ["def test_clone(self):\n    constraint = models.UniqueConstraint(fields=['foo', 'bar'], name='unique')\n    cloned_constraint = constraint.clone()\n    self.assertEqual(constraint, cloned_constraint)\n    self.assertIsNot(constraint, cloned_constraint)\n\n    constraint_with_condition = models.UniqueConstraint(\n        fields=['foo', 'bar'],\n        name='unique',\n        condition=models.Q(foo=models.F('bar'))\n    )\n    cloned_constraint_with_condition = constraint_with_condition.clone()\n    self.assertEqual(constraint_with_condition, cloned_constraint_with_condition)\n    self.assertIsNot(constraint_with_condition, cloned_constraint_with_condition)\n\n    constraint_with_deferrable = models.UniqueConstraint(\n        fields=['foo', 'bar'],\n        name='unique',\n        deferrable=models.Deferrable.DEFERRED,\n    )\n    cloned_constraint_with_deferrable = constraint_with_deferrable.clone()\n    self.assertEqual(constraint_with_deferrable, cloned_constraint_with_deferrable)\n    self.assertIsNot(constraint_with_deferrable, cloned_constraint_with_deferrable)\n\n    constraint_with_include = models.UniqueConstraint(\n        fields=['foo', 'bar'],\n        name='unique',\n        include=['baz_1', 'baz_2'],\n    )\n    cloned_constraint_with_include = constraint_with_include.clone()\n    self.assertEqual(constraint_with_include, cloned_constraint_with_include)\n    self.assertIsNot(constraint_with_include, cloned_constraint_with_include)\n\n    constraint_with_opclasses = models.UniqueConstraint(\n        fields=['foo', 'bar'],\n        name='unique',\n        opclasses=['text_pattern_ops', 'varchar_pattern_ops'],\n    )\n    cloned_constraint_with_opclasses = constraint_with_opclasses.clone()\n    self.assertEqual(constraint_with_opclasses, cloned_constraint_with_opclasses)\n    self.assertIsNot(constraint_with_opclasses, cloned_constraint_with_opclasses)\n"], "sample_289": ["    def test_update(self):\n        dict1 = CaseInsensitiveMapping({\n            'Accept': 'application/json',\n            'content-type': 'text/html',\n        })\n        dict2 = {'accept': 'application/xml'}\n        with self.assertRaisesMessage(TypeError, \"'CaseInsensitiveMapping' object does not support item assignment\"):\n            dict1.update(dict2)\n        self.assertEqual(dict1, {'Accept': 'application/json', 'content-type': 'text/html'})\n"], "sample_294": ["def test_csrf_trusted_origins_wildcard_domain(self):\n    \"\"\"\n    A POST request with an origin that matches a CSRF_TRUSTED_ORIGINS wildcard\n    domain is accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['HTTP_ORIGIN'] = 'https://foo.example.com'\n    mw = CsrfViewMiddleware(post_form_view)\n    self.assertIs(mw._origin_verified(req), True)\n    resp = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(resp)\n    req.META['HTTP_ORIGIN'] = 'http://bar.example.net'\n    self.assertIs(mw._origin_verified(req), True)\n    resp = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(resp)\n"], "sample_295": ["    def setUpTestData(cls):\n        cls.company = Company.objects.create(name='Example Inc.', num_employees=2300, num_chairs=5)\n"], "sample_299": ["    def test_check_file_based_cache_is_absolute_with_multiple_caches(self):\n        self.assertEqual(check_file_based_cache_is_absolute(None), [])\n"], "sample_300": ["def test_build_lookup_with_invalid_lookup(self):\n    query = Query(Author)\n    msg = \"Unsupported lookup 'invalid' for CharField or join on the field not permitted.\"\n    with self.assertRaisesMessage(FieldError, msg):\n        query.build_lookup(['invalid'], Col(Author._meta.get_field('name'), 'alias'), 'value')\n"], "sample_317": ["def test_rss2_feed_with_no_items(self):\n    \"\"\"\n    Test the structure and content of feeds generated by Rss201rev2Feed with no items.\n    \"\"\"\n    response = self.client.get('/syndication/rss2/no-items/')\n    doc = minidom.parseString(response.content)\n\n    # Making sure there's only 1 `rss` element and that the correct\n    # RSS version was specified.\n    feed_elem = doc.getElementsByTagName('rss')\n    self.assertEqual(len(feed_elem), 1)\n    feed = feed_elem[0]\n    self.assertEqual(feed.getAttribute('version'), '2.0')\n\n    # Making sure there's only one `channel` element w/in the\n    # `rss` element.\n    chan_elem = feed.getElementsByTagName('channel')\n    self.assertEqual(len(chan_elem), 1)\n    chan = chan_elem[0]\n\n    # Ensure the content of the channel is correct\n    self.assertChildNodeContent(chan, {\n        'title': 'My blog',\n        'link': 'http://example.com/blog/',\n    })\n\n    # Check that there are no items in the feed\n    items = chan.getElementsByTagName('item')\n    self.assertEqual(len(items), 0)\n"], "sample_325": ["def test_boundfield_widget_type_with_custom_widgets(self):\n    class CustomWidget(TextInput):\n        pass\n\n    class CustomForm(Form):\n        field = CharField(widget=CustomWidget)\n\n    form = CustomForm()\n    self.assertEqual(form['field'].widget_type, 'text')\n"], "sample_334": ["def test_field_order_with_inheritance(self):\n    class ParentForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n\n        field_order = ['field2', 'field1']\n\n    class ChildForm(ParentForm):\n        field3 = CharField()\n        field4 = CharField()\n\n        field_order = ['field4', 'field3']\n\n    form = ChildForm()\n    self.assertEqual(list(form.fields), ['field4', 'field3', 'field2', 'field1'])\n"], "sample_338": ["def test_alter_model_table_with_custom_database_table_name(self):\n    \"\"\"\n    Tests that altering a model's table name works when the initial table name\n    is customized.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_with_db_table_options],\n        [self.author_with_new_db_table_options]\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelTable\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", table=\"author_two\")\n"], "sample_343": ["def test_generic_relation_get_content_type(self):\n    question = Question.objects.create(text='test')\n    answer = Answer.objects.create(question=question)\n    content_type = Question.answer_set.field.get_content_type()\n    self.assertEqual(content_type.model_class(), Answer)\n    self.assertEqual(content_type.app_label, 'contenttypes_tests')\n    self.assertEqual(content_type.model, 'answer')\n"], "sample_344": ["def test_get_related_models_recursive_with_self_referential_foreign_key(self):\n    class A(models.Model):\n        to_a = models.ForeignKey('A', models.CASCADE)\n\n        class Meta:\n            app_label = \"something\"\n\n    related_models = get_related_models_recursive(A)\n    self.assertEqual(related_models, set())\n"], "sample_348": ["    def test_model_choice_field(self):\n        class TestModelAdmin(ModelAdmin):\n            form = forms.ModelForm\n            form.Meta.model = ValidationTestModel\n            form.Meta.fields = ('users',)\n\n        self.assertIsValid(TestModelAdmin, ValidationTestModel)\n"], "sample_349": ["def test_build_attrs_with_custom_language(self):\n    form = AlbumForm()\n    with translation.override('fr'):\n        attrs = form['band'].field.widget.get_context(name='my_field', value=None, attrs={})['widget']['attrs']\n    self.assertEqual(attrs['lang'], 'fr')\n"], "sample_352": ["    def test_ticket_24863(self):\n        \"\"\"\n        Ensure that filtering on a related field with a subquery and an __in lookup works correctly.\n        \"\"\"\n        school1 = School.objects.create()\n        school2 = School.objects.create()\n        student1 = Student.objects.create(school=school1)\n        student2 = Student.objects.create(school=school2)\n        classroom1 = Classroom.objects.create(school=school1)\n        classroom2 = Classroom.objects.create(school=school2)\n        classroom1.students.add(student1)\n        classroom2.students.add(student2)\n\n        subquery = Student.objects.filter(classroom__school=F('school')).values_list('pk', flat=True)\n        self.assertSequenceEqual(School.objects.filter(students__in=subquery), [school1, school2])\n"], "sample_357": ["def test_alter_field_with_choices(self):\n    \"\"\"Tests autodetection of altered fields with choices.\"\"\"\n    before = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, choices=[('a', 'A'), ('b', 'B')])),\n    ])\n    after = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, choices=[('a', 'A'), ('c', 'C')])),\n    ])\n    changes = self.get_changes([before], [after])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True)\n"], "sample_359": ["def test_rename_field_with_index(self):\n    project_state = self.set_up_test_model(\"test_rnflwi\", index=True)\n    # Test the state alteration\n    operation = migrations.RenameField(\"Pony\", \"pink\", \"blue\")\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_rnflwi\", new_state)\n    self.assertIn(\"blue\", new_state.models[\"test_rnflwi\", \"pony\"].fields)\n    self.assertNotIn(\"pink\", new_state.models[\"test_rnflwi\", \"pony\"].fields)\n    # Make sure the index has the renamed column too\n    self.assertIn(\"blue\", new_state.models[\"test_rnflwi\", \"pony\"].options['index_together'][0])\n    self.assertNotIn(\"pink\", new_state.models[\"test_rnflwi\", \"pony\"].options['index_together'][0])\n    # Test the database alteration\n    self.assertColumnExists(\"test_rnflwi_pony\", \"pink\")\n    self.assertColumnNotExists(\"test_rnflwi_pony\", \"blue\")\n    with connection.schema_editor() as editor:\n        operation.database_forwards(\"test_rnflwi\", editor, project_state, new_state)\n    self.assertColumnExists(\"test_rnflwi_pony\", \"blue\")\n    self.assertColumnNotExists(\"test_rnflwi_pony\", \"pink\")\n    # Ensure the index constraint has been ported over\n    self.assertIndexExists(\"test_rnflwi_pony\", [\"weight\", \"blue\"])\n    # And test reversal\n    with connection.schema_editor() as editor:\n        operation.database_backwards(\"test_rnflwi\", editor, new_state, project_state)\n    self.assertColumnExists(\"test_rnflwi_pony\", \"pink\")\n    self.assertColumnNotExists(\"test_rnflwi_pony\", \"blue\")\n    # Ensure the index constraint has been reset\n    self.assertIndexExists(\"test_rnflwi_pony\", [\"weight\", \"pink\"])\n"], "sample_362": ["def test_alter_field_with_choices(self):\n    \"\"\"Tests autodetection of altered fields with choices.\"\"\"\n    changes = self.get_changes(\n        [ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True)), (\"name\", models.CharField(max_length=200, choices=[('a', 'A'), ('b', 'B')]))])],\n        [ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True)), (\"name\", models.CharField(max_length=200, choices=[('a', 'A'), ('c', 'C')]))])]\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True)\n"], "sample_363": ["    def test_build_attrs(self):\n        w = widgets.AutocompleteSelect(None, admin.site)\n        attrs = w.build_attrs({'id': 'id_test'}, name='test')\n        self.assertEqual(attrs['data-ajax--url'], reverse('admin:autocomplete'))\n        self.assertEqual(attrs['data-app-label'], '')\n        self.assertEqual(attrs['data-model-name'], '')\n        self.assertEqual(attrs['data-field-name'], '')\n        self.assertEqual(attrs['data-theme'], 'admin-autocomplete')\n"], "sample_369": ["def test_add_model_with_field_removed_from_base_model_in_different_app(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name, even if they are in different apps.\n    \"\"\"\n    before = [\n        ModelState('app1', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app1', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app2', 'book', [\n            ('title', models.CharField(max_length=200)),\n        ], bases=('app1.readable',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app1', 1)\n    self.assertOperationTypes(changes, 'app1', 0, ['RemoveField'])\n    self.assertOperationAttributes(changes, 'app1', 0, 0, name='title', model_name='readable')\n    self.assertNumberMigrations(changes, 'app2', 1)\n    self.assertOperationTypes(changes, 'app2', 0, ['CreateModel'])\n    self.assertOperationAttributes(changes, 'app2', 0, 0, name='book')\n"], "sample_381": ["def test_alter_model_table_with_custom_database_table_name(self):\n    \"\"\"\n    AlterModelTable operation should be generated when the db_table of a model\n    is changed, even if the model has a custom database table name.\n    \"\"\"\n    before = [\n        ModelState('testapp', 'Author', [\n            ('id', models.AutoField(primary_key=True)),\n        ], options={'db_table': 'custom_author_table'}),\n    ]\n    after = [\n        ModelState('testapp', 'Author', [\n            ('id', models.AutoField(primary_key=True)),\n        ], options={'db_table': 'new_custom_author_table'}),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, ['AlterModelTable'])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name='author', table='new_custom_author_table')\n"], "sample_389": ["    def test_build_absolute_uri(self):\n        request = HttpRequest()\n        request.path = \"/path/to/resource\"\n        request.META[\"SERVER_NAME\"] = \"example.com\"\n        request.META[\"SERVER_PORT\"] = 80\n\n        self.assertEqual(\n            request.build_absolute_uri(), \"http://example.com/path/to/resource\"\n        )\n"], "sample_399": ["def test_aggregation_with_filtered_relation(self):\n    publisher = Publisher.objects.create(name=\"Test Publisher\", num_awards=2)\n    book1 = Book.objects.create(\n        isbn=\"123456789\",\n        name=\"Test Book 1\",\n        pages=100,\n        rating=4.0,\n        price=Decimal(\"10.00\"),\n        contact=self.a1,\n        publisher=publisher,\n        pubdate=datetime.date(2022, 1, 1),\n    )\n    book2 = Book.objects.create(\n        isbn=\"987654321\",\n        name=\"Test Book 2\",\n        pages=200,\n        rating=5.0,\n        price=Decimal(\"20.00\"),\n        contact=self.a2,\n        publisher=publisher,\n        pubdate=datetime.date(2022, 1, 15),\n    )\n\n    filtered_publisher = Publisher.objects.filter(book__rating__gt=4).annotate(\n        total_pages=Sum(\"book__pages\")\n    )\n    self.assertEqual(filtered_publisher.get().total_pages, 200)\n\n    filtered_publisher = Publisher.objects.annotate(\n        total_pages=Sum(\"book__pages\", filter=Q(book__rating__gt=4))\n    )\n    self.assertEqual(filtered_publisher.get(total_pages__isnull=False).total_pages, 200)\n"], "sample_401": ["def test_formset_with_disabled_fields(self):\n    \"\"\"\n    FormSets with disabled fields should not include those fields in the cleaned_data.\n    \"\"\"\n\n    class DisabledForm(Form):\n        field = IntegerField(disabled=True)\n\n    DisabledFormSet = formset_factory(DisabledForm)\n    data = {\n        \"form-TOTAL_FORMS\": \"1\",\n        \"form-INITIAL_FORMS\": \"0\",\n        \"form-MIN_NUM_FORMS\": \"0\",\n        \"form-MAX_NUM_FORMS\": \"0\",\n        \"form-0-field\": \"123\",\n    }\n    formset = DisabledFormSet(data, prefix=\"form\")\n    self.assertTrue(formset.is_valid())\n    self.assertEqual([{}], formset.cleaned_data)\n"], "sample_5": ["def test_models_parameter_unit_conversion(model):\n    if not HAS_SCIPY and model['class'] in SCIPY_MODELS:\n        pytest.skip()\n\n    m = model['class'](**model['parameters'])\n\n    for param_name in m.param_names:\n        param = getattr(m, param_name)\n        if param.unit is not None:\n            # Test that the parameter can be set with a different unit\n            new_value = param.value * 2\n            new_unit = param.unit * 2\n            setattr(m, param_name, new_value * new_unit)\n            assert_quantity_allclose(getattr(m, param_name).value, new_value)\n\n            # Test that the parameter can be set with a quantity\n            new_value = param.value * 3\n            new_unit = param.unit\n            setattr(m, param_name, u.Quantity(new_value, new_unit))\n            assert_quantity_allclose(getattr(m, param_name).value, new_value)\n\n            # Test that setting the parameter with an incompatible unit raises an error\n            new_value = param.value * 4\n            new_unit = u.second\n            with pytest.raises(u.UnitsError):\n                setattr(m, param_name, new_value * new_unit)\n"], "sample_7": ["def test_column_to_list():\n    \"\"\"Test that the tolist() method works correctly for Columns.\"\"\"\n    c = table.Column([1, 2, 3], dtype='i4')\n    assert c.tolist() == [1, 2, 3]\n\n    c = table.Column(['a', 'b', 'c'], dtype='S')\n    assert c.tolist() == ['a', 'b', 'c']\n\n    c = table.Column(['a', 'b', 'c'], dtype='U')\n    assert c.tolist() == ['a', 'b', 'c']\n"], "sample_8": ["    def test_masked_array_with_numpy_median(self):\n        \"\"\"Check that numpy.median works correctly with MaskedArray.\"\"\"\n        np_median = np.median(self.ma)\n        assert type(np_median) is self._data_cls\n        expected_data = np.median(self.a[~self.mask_a])\n        assert_array_equal(np_median, expected_data)\n"], "sample_16": ["    def test_structured_to_unstructured(self):\n        # Create a structured quantity with compatible units\n        struct = u.Quantity(np.array([(1, 2, 3), (4, 5, 6)]), u.Unit(\"(m, m, m)\"))\n        unstruct = rfn.structured_to_unstructured(struct)\n        assert_array_equal(unstruct, [1, 2, 3, 4, 5, 6] * u.m)\n\n        # Create a structured quantity with incompatible units\n        struct = u.Quantity(np.array([(1, 2, 3), (4, 5, 6)]), u.Unit(\"(m, s, kg)\"))\n        with pytest.raises(u.UnitConversionError):\n            rfn.structured_to_unstructured(struct)\n"], "sample_37": ["def test_axis_type_names():\n    w = wcs.WCS(naxis=2)\n    w.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\"]\n    w.wcs.cname = [\"Longitude\", \"\"]\n    assert w.axis_type_names == [\"Longitude\", \"DEC--TAN\"]\n"], "sample_38": ["def test_axis_type_names():\n    w = wcs.WCS(naxis=2)\n    w.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\"]\n    w.wcs.cname = [\"Longitude\", \"\"]\n    assert w.axis_type_names == [\"Longitude\", \"DEC--TAN\"]\n"], "sample_39": ["def test_axis_type_names():\n    w = wcs.WCS(naxis=2)\n    w.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\"]\n    w.wcs.cname = [\"Longitude\", \"\"]\n    assert w.axis_type_names == [\"Longitude\", \"DEC--TAN\"]\n"], "sample_42": ["def test_with_H0_roundtrip():\n    H0_70 = 70*u.km/u.s/u.Mpc\n    h70dist = 100 * u.Mpc\n\n    roundtripped_dist = h70dist.to(u.Mpc/u.littleh, u.with_H0(H0_70)).to(u.Mpc, u.with_H0(H0_70))\n    assert_quantity_allclose(roundtripped_dist, h70dist)\n\n    h1lum = 1*u.Lsun\n    roundtripped_lum = h1lum.to(u.Lsun*u.littleh**-2, u.with_H0(H0_70)).to(u.Lsun, u.with_H0(H0_70))\n    assert_quantity_allclose(roundtripped_lum, h1lum)\n"], "sample_53": ["def test_splitdatetime_widget(self):\n    widget = SplitDateTimeWidget()\n    self.assertEqual(widget.supports_microseconds, False)\n    self.assertEqual(widget.template_name, 'django/forms/widgets/splitdatetime.html')\n\n    # Test decompress with a datetime object\n    dt = datetime.datetime(2022, 1, 1, 12, 0, 0)\n    self.assertEqual(widget.decompress(dt), [dt.date(), dt.time()])\n\n    # Test decompress with None\n    self.assertEqual(widget.decompress(None), [None, None])\n"], "sample_56": ["def test_list_filter_item_callable(self):\n    class MyListFilter(admin.SimpleListFilter):\n        pass\n\n    class SongAdmin(admin.ModelAdmin):\n        list_filter = [MyListFilter]\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n"], "sample_60": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n"], "sample_66": ["def test_split_domain_port_ipv6(self):\n    domain, port = split_domain_port('[2001:19f0:feee::dead:beef:cafe]:8080')\n    self.assertEqual(domain, '[2001:19f0:feee::dead:beef:cafe]')\n    self.assertEqual(port, '8080')\n\n    domain, port = split_domain_port('[2001:19f0:feee::dead:beef:cafe]')\n    self.assertEqual(domain, '[2001:19f0:feee::dead:beef:cafe]')\n    self.assertEqual(port, '')\n"], "sample_72": ["def test_serialize_type_with_module(self):\n    class TestType:\n        pass\n\n    self.assertSerializedResultEqual(\n        type(TestType),\n        (\"migrations.test_writer.TestType.__class__\", {'import migrations.test_writer'})\n    )\n"], "sample_79": ["    def test_add(self):\n        self.check_values(('0', '5'), ('1', '6'), ('2', '7'))\n"], "sample_80": ["def test_add_q(self):\n    query = Query(Author)\n    query.add_q(Q(num__gt=2))\n    self.assertEqual(len(query.where.children), 1)\n    lookup = query.where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertEqual(lookup.rhs, 2)\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('num'))\n\n    query.add_q(~Q(num__lt=0))\n    self.assertEqual(len(query.where.children), 2)\n    lookup = query.where.children[1]\n    self.assertIsInstance(lookup, LessThan)\n    self.assertEqual(lookup.rhs, 0)\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('num'))\n    self.assertTrue(lookup.negated)\n\n    query.add_q(Q(name__isnull=False) | Q(num__lt=F('id')))\n    self.assertEqual(len(query.where.children), 3)\n    name_isnull_lookup, num_lt_lookup = query.where.children[2].children\n    self.assertIsInstance(num_lt_lookup, LessThan)\n    self.assertIsInstance(num_lt_lookup.rhs, SimpleCol)\n    self.assertIsInstance(num_lt_lookup.lhs, SimpleCol)\n    self.assertIsInstance(name_isnull_lookup, IsNull)\n    self.assertIsInstance(name_isnull_lookup.lhs, SimpleCol)\n"], "sample_85": ["    def test_m2m_field_with_through_model(self):\n        m1 = M.objects.create()\n        r1 = R.objects.create()\n        mr = MR.objects.create(m=m1, r=r1)\n        self.assertEqual(mr.m, m1)\n        self.assertEqual(mr.r, r1)\n"], "sample_102": ["def test_union_with_distinct(self):\n    qs1 = Number.objects.filter(num__lte=5)\n    qs2 = Number.objects.filter(num__gte=5)\n    self.assertEqual(len(list(qs1.union(qs2).distinct())), 10)\n    self.assertEqual(len(list(qs1.union(qs2, all=True).distinct())), 10)\n"], "sample_114": ["def test_mti_inheritance_field_removal(self):\n    Animal = ModelState('app', 'Animal', [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=255)),\n    ])\n    Dog = ModelState('app', 'Dog', [], bases=('app.Animal',))\n    changes = self.get_changes([Animal, Dog], [ModelState('app', 'Animal', [\n        (\"id\", models.AutoField(primary_key=True)),\n    ]), Dog])\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='name', model_name='animal')\n"], "sample_118": ["def test_lookup_collision_with_subqueries(self):\n    \"\"\"\n    Genuine field names don't collide with built-in lookup types when used in\n    subqueries.\n    \"\"\"\n    season_2009 = Season.objects.create(year=2009, gt=111)\n    season_2010 = Season.objects.create(year=2010, gt=222)\n    season_2011 = Season.objects.create(year=2011, gt=333)\n\n    subquery = Season.objects.filter(gt=111).values('year')\n    self.assertEqual(Game.objects.filter(season__year__in=subquery).count(), 0)\n\n    subquery = Season.objects.filter(gt=111).values('gt')\n    self.assertEqual(Game.objects.filter(season__gt__in=subquery).count(), 0)\n"], "sample_120": ["def test_serialize_datetime_timezone(self):\n    tz = get_fixed_timezone(180)\n    dt = datetime.datetime(2014, 1, 1, 1, 1, tzinfo=tz)\n    string, imports = MigrationWriter.serialize(dt)\n    self.assertEqual(string, \"datetime.datetime(2014, 1, 1, 1, 1, tzinfo=utc)\")\n    self.assertEqual(imports, {'import datetime', 'from django.utils.timezone import utc'})\n"], "sample_121": ["    def test_model_attribute(self):\n        class Model(models.Model):\n            field = models.CharField(max_length=10)\n\n                pass\n\n            @property\n                return 'value'\n\n        self.assertEqual(Model.check(), [])\n\n        # Add a model attribute with a name that clashes with a field.\n        setattr(Model, 'field', 'clashing attribute')\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"The attribute 'field' clashes with the field 'field'.\",\n                obj=Model,\n                id='models.E027',\n            ),\n        ])\n\n        # Add a model attribute with a name that clashes with a method.\n        setattr(Model, 'method', 'clashing attribute')\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"The attribute 'field' clashes with the field 'field'.\",\n                obj=Model,\n                id='models.E027',\n            ),\n            Error(\n                \"The attribute 'method' clashes with the method 'method'.\",\n                obj=Model,\n                id='models.E028',\n            ),\n        ])\n\n        # Add a model attribute with a name that clashes with a property.\n        setattr(Model, 'property', 'clashing attribute')\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"The attribute 'field' clashes with the field 'field'.\",\n                obj=Model,\n                id='models.E027',\n            ),\n            Error(\n                \"The attribute 'method' clashes with the method 'method'.\",\n                obj=Model,\n                id='models.E028',\n            ),\n            Error(\n                \"The attribute 'property' clashes with the property 'property'.\",\n                obj=Model,\n                id='models.E029',\n            ),\n        ])\n"], "sample_126": ["def test_mti_inheritance_model_removal_with_child_models(self):\n    Animal = ModelState('app', 'Animal', [\n        (\"id\", models.AutoField(primary_key=True)),\n    ])\n    Dog = ModelState('app', 'Dog', [], bases=('app.Animal',))\n    Puppy = ModelState('app', 'Puppy', [], bases=('app.Dog',))\n    changes = self.get_changes([Animal, Dog, Puppy], [Animal])\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['DeleteModel', 'DeleteModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='Puppy')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='Dog')\n"], "sample_127": ["def test_bulk_update(self):\n    countries = Country.objects.bulk_create([\n        Country(name=\"United States of America\", iso_two_letter=\"US\"),\n        Country(name=\"The Netherlands\", iso_two_letter=\"NL\"),\n        Country(name=\"Germany\", iso_two_letter=\"DE\"),\n        Country(name=\"Czech Republic\", iso_two_letter=\"CZ\")\n    ])\n    Country.objects.bulk_update(countries, ['name'])\n    for country in countries:\n        self.assertEqual(Country.objects.get(pk=country.pk).name, country.name)\n"], "sample_129": ["    def test_stringformat01(self):\n        output = self.engine.render_to_string('stringformat01', {\"a\": 1.42, \"b\": \"1.42\"})\n        self.assertEqual(output, \"1.420000e+00 1.42\")\n"], "sample_135": ["def test_E_format(self):\n    # Test alternative month names as required by some locales.\n    my_birthday = datetime(1979, 7, 8, 22, 00)\n    self.assertEqual(dateformat.format(my_birthday, 'E'), 'July')\n\n    # Test all months to ensure that the alternative month names are correctly\n    # formatted.\n    for month in range(1, 13):\n        dt = datetime(2022, month, 1)\n        self.assertEqual(dateformat.format(dt, 'E'), MONTHS_ALT[month])\n"], "sample_134": ["def test_serialize_type_with_module(self):\n    class TestType:\n        pass\n\n    self.assertSerializedResultEqual(\n        type(TestType),\n        (\"type(migrations.test_writer.TestType)\", {'import migrations.test_writer'})\n    )\n"], "sample_142": ["def test_modelform_defines_fields(self):\n    class SongForm(forms.ModelForm):\n        pass\n\n    self.assertFalse(modelform_defines_fields(SongForm))\n\n    class SongForm(forms.ModelForm):\n        class Meta:\n            model = Song\n            fields = '__all__'\n\n    self.assertTrue(modelform_defines_fields(SongForm))\n"], "sample_147": ["def test_union_with_distinct_and_order_by(self):\n    ReservedName.objects.create(name='rn1', order=7)\n    ReservedName.objects.create(name='rn2', order=5)\n    ReservedName.objects.create(name='rn0', order=6)\n    ReservedName.objects.create(name='rn9', order=-1)\n    qs1 = ReservedName.objects.filter(order__gte=6)\n    qs2 = ReservedName.objects.filter(order__lte=5)\n    union_qs = qs1.union(qs2).order_by('-order').distinct()\n    self.assertEqual(list(union_qs.values_list('order', flat=True)), [7, 6, 5, -1])\n"], "sample_158": ["    def test_foreign_key_to_non_unique_field(self):\n        class Target(models.Model):\n            non_unique = models.IntegerField()\n\n        class Model(models.Model):\n            foreign_key = models.ForeignKey(Target, models.CASCADE, to_field='non_unique')\n\n        field = Model._meta.get_field('foreign_key')\n        self.assertEqual(field.check(), [\n            Error(\n                \"'Target.non_unique' must be unique because it is referenced by a foreign key.\",\n                hint=(\n                    'Add unique=True to this field or add a '\n                    'UniqueConstraint (without condition) in the model '\n                    'Meta.constraints.'\n                ),\n                obj=field,\n                id='fields.E311',\n            ),\n        ])\n"], "sample_161": ["    def test_m2m_through_table_clash(self):\n        class Person(models.Model):\n            pass\n\n        class Group(models.Model):\n            members = models.ManyToManyField(Person, through='Membership')\n\n        class Membership(models.Model):\n            person = models.ForeignKey(Person, models.CASCADE)\n            group = models.ForeignKey(Group, models.CASCADE)\n\n        class OtherGroup(models.Model):\n            members = models.ManyToManyField(Person, through='Membership')\n\n        field = OtherGroup._meta.get_field('members')\n        self.assertEqual(field.check(from_model=OtherGroup), [\n            Error(\n                \"The field's intermediary table 'invalid_models_tests.Membership' \"\n                \"clashes with the table name of 'invalid_models_tests.Membership'.\",\n                obj=field,\n                id='fields.E340',\n            ),\n        ])\n"], "sample_165": ["    def test_unique(self):\n        class UniqueModel(models.Model):\n            name = models.CharField(max_length=10, unique=True)\n\n        class UniqueForm(forms.ModelForm):\n            class Meta:\n                model = UniqueModel\n                fields = ('name',)\n\n        UniqueModel.objects.create(name='test')\n        form = UniqueForm({'name': 'test'})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(len(form.errors), 1)\n        self.assertEqual(form.errors['name'], ['UniqueModel with this Name already exists.'])\n"], "sample_175": ["def test_collector_sort(self):\n    # Create a collector and add some objects to it.\n    collector = Collector(using='default')\n    r1 = R.objects.create()\n    r2 = R.objects.create()\n    s1 = S.objects.create(r=r1)\n    s2 = S.objects.create(r=r2)\n    t1 = T.objects.create(s=s1)\n    t2 = T.objects.create(s=s2)\n\n    collector.add([r1, r2])\n    collector.add([s1, s2])\n    collector.add([t1, t2])\n\n    # Sort the collector.\n    collector.sort()\n\n    # Check that the objects are in the correct order for deletion.\n    self.assertEqual(collector.data, {\n        T: {t1, t2},\n        S: {s1, s2},\n        R: {r1, r2},\n    })\n"], "sample_176": ["def test_add_model_with_field_removed_from_grandparent_base_model(self):\n    \"\"\"\n    Removing a base field from a grandparent model takes place before adding a new \n    inherited model that has a field with the same name.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n        ModelState('app', 'book', [], bases=('app.readable',)),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n        ModelState('app', 'book', [], bases=('app.readable',)),\n        ModelState('app', 'novel', [\n            ('title', models.CharField(max_length=200)),\n        ], bases=('app.book',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='novel')\n"], "sample_180": ["    def test_model_attribute(self):\n        class Model(models.Model):\n            my_field = models.CharField(max_length=10)\n\n        self.assertEqual(Model.check(), [])\n"], "sample_179": ["    def test_model_attribute(self):\n        class Model(models.Model):\n            my_field = models.CharField(max_length=10)\n\n        self.assertEqual(Model.check(), [])\n"], "sample_182": ["def test_union_with_empty_queryset(self):\n    qs1 = Number.objects.all()\n    qs2 = Number.objects.none()\n    self.assertEqual(len(list(qs1.union(qs2))), 10)\n    self.assertEqual(len(list(qs2.union(qs1))), 10)\n    self.assertEqual(len(list(qs1.union(qs2, all=True))), 10)\n    self.assertEqual(len(list(qs2.union(qs1, all=True))), 10)\n"], "sample_181": ["def test_filtered_aggregate_ref_annotation_with_multiple_filters(self):\n    aggs = Author.objects.annotate(\n        double_age=F('age') * 2,\n        triple_age=F('age') * 3,\n    ).aggregate(\n        cnt=Count('pk', filter=Q(double_age__gt=100) & Q(triple_age__lt=300)),\n    )\n    self.assertEqual(aggs['cnt'], 1)\n"], "sample_183": ["    def setUpTestData(cls):\n        o = CaseTestModel.objects.create(integer=1, integer2=1, string='1')\n        FKCaseTestModel.objects.create(fk=o, integer=1)\n        FKCaseTestModel.objects.create(fk=o, integer=2)\n"], "sample_186": ["def test_list_filter_item_with_through_field(self):\n    class BookAdmin(admin.ModelAdmin):\n        list_filter = ['authors__name']\n\n    errors = BookAdmin(Book, AdminSite()).check()\n    self.assertEqual(errors, [])\n"], "sample_188": ["    def test_empty(self):\n        msg = 'ExpressionList requires at least one expression'\n        with self.assertRaisesMessage(ValueError, msg):\n            ExpressionList()\n"], "sample_190": ["def test_in_bulk_with_unhashable_items(self):\n    # Test that in_bulk() works with unhashable items.\n    class UnhashableInt(int):\n        __hash__ = None\n\n    articles = Article.objects.in_bulk([UnhashableInt(self.a1.id), self.a2.id])\n    self.assertEqual(articles[UnhashableInt(self.a1.id)], self.a1)\n    self.assertEqual(articles[self.a2.id], self.a2)\n"], "sample_195": ["    def test_bulk_insert_sql(self):\n        fields = ['field1', 'field2']\n        placeholder_rows = [\n            ['%s', '%s'],\n            ['%s', '%s'],\n        ]\n        sql = connection.ops.bulk_insert_sql(fields, placeholder_rows)\n        self.assertEqual(sql, \" UNION ALL \".join(\n            \"SELECT %s, %s\" for _ in placeholder_rows\n        ))\n"], "sample_198": ["    def test_empty(self):\n        msg = 'ExpressionList requires at least one expression'\n        with self.assertRaisesMessage(ValueError, msg):\n            ExpressionList()\n"], "sample_199": ["def test_annotation_with_subquery_and_outerref(self):\n    subquery = Book.objects.filter(\n        publisher=OuterRef('pk'),\n    ).values('publisher').annotate(count=Count('pk')).values('count')\n    qs = Publisher.objects.annotate(\n        total_books=Subquery(subquery, output_field=IntegerField()),\n    ).filter(total_books__gt=2).values('name')\n    self.assertCountEqual(qs, [{'name': 'Apress'}, {'name': 'Prentice Hall'}])\n"], "sample_207": ["    def test_db_check_constraints(self):\n        class Model(models.Model):\n            field = models.JSONField()\n\n        errors = Model.check()\n        self.assertEqual(errors, [])\n"], "sample_214": ["def test_key_transform_with_invalid_input(self):\n    msg = 'Value must be valid JSON.'\n    with self.assertRaisesMessage(ValidationError, msg):\n        KeyTransform('test', 'value').process_lhs(\n            compiler=models.Model.objects.get_compiler(connection=connection),\n            connection=connection,\n        )\n"], "sample_218": ["def test_trunc_func_with_timezone_transition(self):\n    \"\"\"\n    If the truncated datetime transitions to a different offset (daylight\n    saving) then the returned value will have that new timezone/offset.\n    \"\"\"\n    start_datetime = datetime(2018, 3, 25, 1, 30, 50, 321)\n    end_datetime = datetime(2018, 11, 4, 1, 10, 50, 123)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n    self.create_model(end_datetime, start_datetime)\n\n    nyc = pytz.timezone('America/New_York')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=DateTimeField(), tzinfo=nyc)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(nyc), kind, nyc)),\n                (end_datetime, truncate_to(end_datetime.astimezone(nyc), kind, nyc))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_datetime_kind('hour')\n    test_datetime_kind('minute')\n    test_datetime_kind('second')\n"], "sample_224": ["def test_aggregation_subquery_annotation_with_filter(self):\n    \"\"\"Subquery annotations are excluded from the GROUP BY if they are\n    not explicitly grouped against, even when filtered.\"\"\"\n    latest_book_pubdate_qs = Book.objects.filter(\n        publisher=OuterRef('pk'),\n        pages__gt=400,\n    ).order_by('-pubdate').values('pubdate')[:1]\n    publisher_qs = Publisher.objects.annotate(\n        latest_book_pubdate=Subquery(latest_book_pubdate_qs),\n    ).filter(latest_book_pubdate__isnull=False).annotate(count=Count('book'))\n    with self.assertNumQueries(1) as ctx:\n        list(publisher_qs)\n    self.assertEqual(ctx[0]['sql'].count('SELECT'), 2)\n    # The GROUP BY should not be by alias either.\n    self.assertEqual(ctx[0]['sql'].lower().count('latest_book_pubdate'), 1)\n"], "sample_229": ["def test_union_with_empty_queryset(self):\n    qs1 = Number.objects.all()\n    qs2 = Number.objects.none()\n    self.assertEqual(len(list(qs1.union(qs2))), 10)\n    self.assertEqual(len(list(qs2.union(qs1))), 10)\n    self.assertEqual(len(list(qs1.union(qs2, all=True))), 10)\n    self.assertEqual(len(list(qs2.union(qs1, all=True))), 10)\n"], "sample_230": ["def test_bound_data(self):\n    field = JSONField()\n    self.assertIsNone(field.bound_data(None, None))\n    self.assertEqual(field.bound_data('{\"a\": \"b\"}', None), {\"a\": \"b\"})\n    invalid_json_input = field.bound_data('{ invalid json }', None)\n    self.assertIsInstance(invalid_json_input, InvalidJSONInput)\n    self.assertEqual(str(invalid_json_input), '{ invalid json }')\n"], "sample_232": ["def test_key_transform_with_invalid_key(self):\n    obj = NullableJSONModel.objects.create(value={'a': 'b'})\n    tests = [\n        ('value__1', []),\n        ('value__c__d', []),\n        ('value__foo__bar', []),\n    ]\n    for lookup, expected in tests:\n        with self.subTest(lookup=lookup):\n            self.assertSequenceEqual(\n                NullableJSONModel.objects.filter(**{lookup: 'x'}),\n                expected,\n            )\n"], "sample_234": ["def test_union_with_subqueries(self):\n    subquery = Number.objects.filter(num__gt=5).values('num')\n    qs1 = Number.objects.filter(num__in=subquery)\n    qs2 = Number.objects.filter(num__lte=5)\n    self.assertNumbersEqual(qs1.union(qs2), list(range(10)))\n"], "sample_242": ["    def test_year_lookup_bounds_for_datetime_field(self):\n        look_up = YearLookup(\n            lhs=Value(datetime(2010, 1, 1, 0, 0, 0), output_field=DateTimeField()),\n            rhs=Value(2010),\n        )\n        start, finish = look_up.year_lookup_bounds(None, 2010)\n        self.assertEqual(start, datetime(2010, 1, 1, 0, 0, 0))\n        self.assertEqual(finish, datetime(2010, 12, 31, 23, 59, 59, 999999))\n"], "sample_247": ["def test_alias_with_m2m(self):\n    books = Book.objects.alias(author_age=F('authors__age')).filter(pk=self.b1.pk).order_by('author_age')\n    self.assertEqual(books[0].author_age, 34)\n    self.assertEqual(books[1].author_age, 35)\n"], "sample_250": ["def test_E_format(self):\n    # Test alternative month names as required by some locales.\n    my_birthday = datetime(1979, 7, 8, 22, 00)\n    self.assertEqual(dateformat.format(my_birthday, 'E'), 'July')\n"], "sample_251": ["def test_alias_with_m2m(self):\n    qs = Author.objects.alias(\n        book_isbn=F('book__isbn'),\n    ).filter(book_isbn=self.b1.isbn).order_by('book_isbn')\n    self.assertIs(hasattr(qs.first(), 'book_isbn'), False)\n    self.assertEqual(qs.count(), 2)\n"], "sample_252": ["    def test_check_constraints(self):\n        # Create a model with a JSONField that has a check constraint.\n        class Model(models.Model):\n            value = models.JSONField()\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        check=models.Q(value__has_key='a'),\n                        name='value_has_key_a',\n                    ),\n                ]\n\n        # Try to create an instance with a value that does not satisfy the constraint.\n        with self.assertRaises(IntegrityError):\n            Model.objects.create(value={'b': 1})\n\n        # Create an instance with a value that satisfies the constraint.\n        Model.objects.create(value={'a': 1})\n"], "sample_254": ["    def test_get_extra(self):\n        class ExtraInline(TabularInline):\n            model = Inner\n\n                return 2\n\n        modeladmin = ModelAdmin(Holder, admin_site)\n        modeladmin.inlines = [ExtraInline]\n        obj = Holder.objects.create()\n        url = reverse('admin:admin_inlines_holder_change', args=(obj.pk,))\n        request = self.factory.get(url)\n        request.user = self.superuser\n        response = modeladmin.changeform_view(request, object_id=str(obj.pk))\n        self.assertContains(\n            response,\n            '<input type=\"hidden\" id=\"id_inner_set-TOTAL_FORMS\" value=\"2\" '\n            'name=\"inner_set-TOTAL_FORMS\">',\n            html=True\n        )\n"], "sample_257": ["def test_key_transform_with_invalid_input(self):\n    msg = 'Value must be valid JSON.'\n    with self.assertRaisesMessage(ValidationError, msg):\n        KeyTransform('test', 'value').process_rhs(\n            compiler=connection.ops.compiler('JSONField'),\n            connection=connection,\n        )\n"], "sample_259": ["def test_prefetch_queryset_with_to_attr(self):\n    book1 = Book.objects.get(id=self.book1.id)\n    with self.assertNumQueries(1):\n        prefetch_related_objects(\n            [book1],\n            Prefetch('authors', queryset=Author.objects.filter(id__in=[self.author1.id, self.author2.id]), to_attr='filtered_authors')\n        )\n\n    with self.assertNumQueries(0):\n        self.assertCountEqual(book1.filtered_authors, [self.author1, self.author2])\n"], "sample_260": ["def test_optimize_add_remove_index(self):\n    \"\"\"\n    AddIndex and RemoveIndex should cancel each other out.\n    \"\"\"\n    index = models.Index(fields=['name'], name='foo_name_idx')\n    self.assertOptimizesTo(\n        [\n            migrations.AddIndex(\"Foo\", index),\n            migrations.RemoveIndex(\"Foo\", \"foo_name_idx\"),\n        ],\n        [],\n    )\n"], "sample_273": ["    def test_field_name_clashes_with_related_field_accessor(self):\n        class Model(models.Model):\n            foo = models.CharField(max_length=10)\n\n        class RelatedModel(models.Model):\n            model = models.ForeignKey(Model, on_delete=models.CASCADE)\n\n            @property\n                return self.model.foo\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"The property 'model_foo' clashes with a related field accessor.\",\n                obj=RelatedModel,\n                id='models.E025',\n            ),\n        ])\n"], "sample_275": ["    def test_delete_with_filter_on_many_to_many_through_model(self):\n        # Create some data\n        child = Child.objects.create(name='Child')\n        toy = Toy.objects.create(name='Toy')\n        played_with = PlayedWith.objects.create(child=child, toy=toy)\n\n        # Test that deleting a PlayedWith instance with a filter on the through model works\n        PlayedWith.objects.filter(child=child).delete()\n        self.assertEqual(PlayedWith.objects.count(), 0)\n"], "sample_286": ["    def test_get_pk_val_on_unsaved_instance(self):\n        a = Article()\n        with self.assertRaisesMessage(ValueError, \"Cannot use None as a query value\"):\n            a._get_pk_val()\n"], "sample_287": ["def test_list_filter_item(self):\n    class SongAdmin(admin.ModelAdmin):\n        list_filter = ['nonexistent']\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'list_filter[0]' refers to 'nonexistent', which does not refer to a Field.\",\n            obj=SongAdmin,\n            id='admin.E116',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_288": ["    def test_m2m(self):\n        obj = JSONModel.objects.create(value={'a': 'b'})\n        related_obj = RelatedJSONModel.objects.create(value={'c': 'd'}, json_model=obj)\n        self.assertSequenceEqual(\n            obj.relatedjsonmodel_set.values_list('value', flat=True),\n            [{'c': 'd'}],\n        )\n        self.assertEqual(related_obj.json_model.value, {'a': 'b'})\n"], "sample_305": ["    def test_exact(self):\n        self.assertQuerysetEqual(\n            Book.objects.filter(isbn__exact='159059725'),\n            ['The Definitive Guide to Django: Web Development Done Right'],\n            lambda b: b.name\n        )\n"], "sample_307": ["def test_E_format_month_names(self):\n    # Test alternative month names as required by some locales.\n    dt = datetime(2022, 1, 1)\n    for month in range(1, 13):\n        dt = dt.replace(month=month)\n        self.assertEqual(dateformat.format(dt, 'E'), MONTHS_ALT[month])\n"], "sample_308": ["def test_f_format(self):\n    tests = [\n        (datetime(2000, 1, 1, 0, 0), '12'),\n        (datetime(2000, 1, 1, 0, 30), '12:30'),\n        (datetime(2000, 1, 1, 12, 0), '12'),\n        (datetime(2000, 1, 1, 12, 30), '12:30'),\n        (datetime(2000, 1, 1, 13, 0), '1'),\n        (datetime(2000, 1, 1, 23, 59), '11:59'),\n    ]\n    for dt, expected in tests:\n        with self.subTest(dt=dt):\n            self.assertEqual(dateformat.format(dt, 'f'), expected)\n"], "sample_327": ["def test_bound_data(self):\n    field = JSONField()\n    self.assertIsNone(field.bound_data(None, None))\n    self.assertEqual(field.bound_data('{\"a\": \"b\"}', None), {'a': 'b'})\n    invalid_json_input = field.bound_data('{ invalid json }', None)\n    self.assertIsInstance(invalid_json_input, InvalidJSONInput)\n    self.assertEqual(str(invalid_json_input), '{ invalid json }')\n"], "sample_328": ["def test_bulk_update_with_ignore_conflicts(self):\n    # Create a model with a unique constraint.\n    note = Note.objects.create(note='test', misc='test')\n    note2 = Note(note='test', misc='test2')\n\n    # Try to bulk update with ignore conflicts.\n    Note.objects.bulk_update([note, note2], ['note'], ignore_conflicts=True)\n\n    # The first note should be updated, the second one not.\n    self.assertEqual(Note.objects.get(pk=note.pk).misc, 'test')\n    self.assertEqual(Note.objects.filter(note='test').count(), 1)\n"], "sample_329": ["def test_serialize_lazy_object(self):\n    lazy_object = SimpleLazyObject(lambda: \"lazy_value\")\n    self.assertSerializedEqual(lazy_object)\n    string, imports = MigrationWriter.serialize(lazy_object)\n    self.assertEqual(string, \"'lazy_value'\")\n    self.assertEqual(imports, set())\n"], "sample_335": ["def test_decimalfield_disabled(self):\n    f = DecimalField(max_digits=4, decimal_places=2, disabled=True)\n    self.assertWidgetRendersTo(f, '<input step=\"0.01\" name=\"f\" type=\"number\" id=\"id_f\" disabled>')\n    self.assertIsNone(f.clean(''))\n    self.assertIsNone(f.clean(None))\n    self.assertEqual(f.clean('1'), decimal.Decimal(\"1\"))\n    self.assertIsInstance(f.clean('1'), decimal.Decimal)\n    self.assertEqual(f.clean('23'), decimal.Decimal(\"23\"))\n    self.assertEqual(f.clean('3.14'), decimal.Decimal(\"3.14\"))\n    self.assertEqual(f.clean(3.14), decimal.Decimal(\"3.14\"))\n    self.assertEqual(f.clean(decimal.Decimal('3.14')), decimal.Decimal(\"3.14\"))\n    self.assertFalse(f.has_changed(decimal.Decimal(\"3.14\"), '3.14'))\n"], "sample_350": ["def test_union_with_subqueries(self):\n    subquery = Number.objects.filter(num__lte=5).values_list('num', flat=True)\n    qs1 = Number.objects.filter(num__in=subquery)\n    qs2 = Number.objects.filter(num__gte=8)\n    self.assertNumbersEqual(qs1.union(qs2), [0, 1, 2, 3, 4, 5, 8, 9], ordered=False)\n"], "sample_356": ["def test_alter_field_with_choices(self):\n    \"\"\"Tests autodetection of altered fields with choices.\"\"\"\n    before = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, choices=[('a', 'A'), ('b', 'B')])),\n    ])\n    after = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, choices=[('a', 'A'), ('c', 'C')])),\n    ])\n    changes = self.get_changes([before], [after])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n"], "sample_370": ["    def setUpTestData(cls):\n        cls.book1 = Book.objects.create(title='Book 1')\n        cls.book2 = Book.objects.create(title='Book 2')\n        cls.author1 = Author.objects.create(name='Author 1')\n        cls.author2 = Author.objects.create(name='Author 2')\n        cls.book1.authors.add(cls.author1, cls.author2)\n        cls.book2.authors.add(cls.author1)\n"], "sample_374": ["    def setUpTestData(cls):\n        cls.book1 = Book.objects.create(title='Poems')\n        cls.book2 = Book.objects.create(title='Jane Eyre')\n        cls.author1 = Author.objects.create(name='Charlotte', first_book=cls.book1)\n        cls.author2 = Author.objects.create(name='Anne', first_book=cls.book1)\n        cls.author3 = Author.objects.create(name='Emily', first_book=cls.book1)\n        cls.author4 = Author.objects.create(name='Jane', first_book=cls.book4)\n\n        cls.book1.authors.add(cls.author1, cls.author2, cls.author3)\n        cls.book2.authors.add(cls.author1)\n"], "sample_375": ["def test_get_related_models_tuples(self):\n    new_apps = Apps()\n\n    class Author(models.Model):\n        name = models.TextField()\n\n        class Meta:\n            app_label = \"migrations\"\n            apps = new_apps\n\n    class Book(models.Model):\n        author = models.ForeignKey(Author, models.CASCADE)\n\n        class Meta:\n            app_label = \"migrations\"\n            apps = new_apps\n\n    project_state = ProjectState()\n    project_state.add_model(ModelState.from_model(Author))\n    project_state.add_model(ModelState.from_model(Book))\n\n    related_models = get_related_models_tuples(project_state.apps.get_model('migrations', 'author'))\n    self.assertEqual(related_models, {('migrations', 'book')})\n"], "sample_378": ["def test_bulk_update_with_unique_fields(self):\n    # Create some objects with unique fields.\n    notes = [\n        Note.objects.create(note=str(i), misc=str(i))\n        for i in range(10)\n    ]\n    # Update the objects, but also specify unique fields.\n    for note in notes:\n        note.note = 'test-%s' % note.id\n    with self.assertNumQueries(1):\n        Note.objects.bulk_update(notes, ['note'], unique_fields=['misc'])\n    self.assertCountEqual(\n        Note.objects.values_list('note', flat=True),\n        [cat.note for cat in notes]\n    )\n"], "sample_384": ["def test_bulk_update_with_unique_fields(self):\n    # Create some objects with unique fields.\n    articles = [\n        Article.objects.create(name=str(i), created=datetime.datetime.today())\n        for i in range(10)\n    ]\n    # Update the objects, but also specify unique fields that can trigger\n    # the upsert.\n    Article.objects.bulk_update(\n        articles,\n        [\"name\"],\n        update_fields=[\"created\"],\n        unique_fields=[\"name\"],\n    )\n    self.assertCountEqual(\n        Article.objects.values_list(\"name\", flat=True),\n        [article.name for article in articles],\n    )\n"], "sample_387": ["    def test_readonly_field_with_foreign_key(self):\n        \"\"\"\n        Ensure that readonly fields with foreign keys are properly displayed.\n        \"\"\"\n        band = Band.objects.create(name=\"Bogey Blues\")\n        event = Event.objects.create(main_band=band)\n\n        self.client.force_login(User.objects.create_superuser(\"super\", None, \"secret\"))\n        response = self.client.get(\n            reverse(\"admin:admin_widgets_event_change\", args=(event.id,))\n        )\n\n        self.assertContains(response, band.name)\n        self.assertNotContains(response, 'id=\"id_main_band\"')\n"], "sample_391": ["def test_create_alter_model_table(self):\n    \"\"\"\n    AlterModelTable should optimize into CreateModel.\n    \"\"\"\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\"Foo\", fields=[]),\n            migrations.AlterModelTable(\"Foo\", \"new_foo\"),\n        ],\n        [\n            migrations.CreateModel(\"Foo\", fields=[], options={\"db_table\": \"new_foo\"}),\n        ],\n    )\n"], "sample_392": ["def test_key_transform_with_custom_decoder(self):\n    value = {\"uuid\": uuid.UUID(\"{d85e2076-b67c-4ee7-8c3a-2bf5a2cc2475}\")}\n    obj = NullableJSONModel.objects.create(value_custom=value)\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value_custom__uuid__exact=value[\"uuid\"]),\n        [obj],\n    )\n"], "sample_414": ["    def test_autocomplete(self):\n        from selenium.webdriver.common.by import By\n\n        self.admin_login(username=\"super\", password=\"secret\", login_url=\"/\")\n        self.selenium.get(\n            self.live_server_url + reverse(\"admin:admin_widgets_event_add\")\n        )\n\n        # No value has been selected yet\n        self.assertEqual(\n            self.selenium.find_element(By.ID, \"id_main_band\").get_attribute(\"value\"), \"\"\n        )\n\n        # Open the autocomplete dropdown and click on a band\n        self.selenium.find_element(By.ID, \"id_main_band\").send_keys(\"Bogey\")\n        self.wait_for_and_switch_to_autocomplete()\n        link = self.selenium.find_element(By.LINK_TEXT, \"Bogey Blues\")\n        link.click()\n\n        # The field now contains the selected band's id\n        self.wait_for_value(\"#id_main_band\", \"42\")\n\n        # Reopen the autocomplete dropdown and click on another band\n        self.selenium.find_element(By.ID, \"id_main_band\").clear()\n        self.selenium.find_element(By.ID, \"id_main_band\").send_keys(\"Green\")\n        self.wait_for_and_switch_to_autocomplete()\n        link = self.selenium.find_element(By.LINK_TEXT, \"Green Potatoes\")\n        link.click()\n\n        # The field now contains the other selected band's id\n        self.wait_for_value(\"#id_main_band\", \"98\")\n"], "sample_415": ["def test_validate_expression_with_exclude(self):\n    constraint = models.UniqueConstraint(Lower(\"name\"), name=\"name_lower_uniq\")\n    non_unique_product = UniqueConstraintProduct(name=self.p1.name.upper())\n    msg = \"Constraint \u201cname_lower_uniq\u201d is violated.\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        constraint.validate(UniqueConstraintProduct, non_unique_product)\n    # Exclude field used by the expression.\n    constraint.validate(\n        UniqueConstraintProduct,\n        non_unique_product,\n        exclude={\"name\"},\n    )\n    # Exclude another field not used by the expression.\n    with self.assertRaisesMessage(ValidationError, msg):\n        constraint.validate(\n            UniqueConstraintProduct,\n            non_unique_product,\n            exclude={\"color\"},\n        )\n"], "sample_417": ["    def test_stringformat01(self):\n        output = self.engine.render_to_string(\"stringformat01\", {\"a\": 1.23})\n        self.assertEqual(output, \"1.230000E+00\")\n"], "sample_418": ["def test_add(self):\n    output = self.engine.render_to_string(\"add01\", {\"num1\": 4, \"num2\": 6})\n    self.assertEqual(output, \"10\")\n"], "sample_419": ["def test_formset_template_name(self):\n    \"\"\"Formset's template_name can be overridden.\"\"\"\n    class CustomFormSet(BaseFormSet):\n        template_name = \"a/custom/formset/template.html\"\n\n    ChoiceFormSet = formset_factory(Choice, formset=CustomFormSet)\n    self.assertEqual(ChoiceFormSet().template_name, \"a/custom/formset/template.html\")\n"], "sample_421": ["    def test_expression_wrapper(self):\n        wrapper = ExpressionWrapper(Value(1), output_field=IntegerField())\n        self.assertEqual(wrapper.output_field.get_internal_type(), \"IntegerField\")\n"], "sample_422": ["    def setUpTestData(cls):\n        cls.employee1 = Employee.objects.create(name=\"John\")\n        cls.employee2 = Employee.objects.create(name=\"Jane\", boss=cls.employee1)\n        cls.employee3 = Employee.objects.create(name=\"Jim\", boss=cls.employee1)\n"], "sample_425": ["def test_serialize_enum_with_lazy_value(self):\n    class LazyEnum(enum.Enum):\n        A = SimpleLazyObject(lambda: \"a-value\")\n        B = SimpleLazyObject(lambda: \"value-b\")\n\n    self.assertSerializedResultEqual(\n        LazyEnum.A,\n        (\"migrations.test_writer.LazyEnum['A']\", {\"import migrations.test_writer\"}),\n    )\n    field = models.CharField(default=LazyEnum.B, choices=[(m.value, m) for m in LazyEnum])\n    string = MigrationWriter.serialize(field)[0]\n    self.assertEqual(\n        string,\n        \"models.CharField(choices=[\"\n        \"('a-value', migrations.test_writer.LazyEnum['A']), \"\n        \"('value-b', migrations.test_writer.LazyEnum['B'])], \"\n        \"default=migrations.test_writer.LazyEnum['B'])\",\n    )\n"], "sample_427": ["def test_formset_template_name(self):\n    \"\"\"Formset's template_name is used when rendering the formset.\"\"\"\n    class CustomFormSet(BaseFormSet):\n        template_name = \"custom/formset.html\"\n\n    ChoiceFormSet = formset_factory(Choice, formset=CustomFormSet)\n    formset = ChoiceFormSet()\n    self.assertEqual(formset.template_name, \"custom/formset.html\")\n"], "sample_431": ["    def test_get_next_or_previous_by_field(self):\n        a1 = Article.objects.create(\n            headline=\"Article 1\",\n            pub_date=datetime(2005, 7, 28),\n        )\n        a2 = Article.objects.create(\n            headline=\"Article 2\",\n            pub_date=datetime(2005, 7, 29),\n        )\n        a3 = Article.objects.create(\n            headline=\"Article 3\",\n            pub_date=datetime(2005, 7, 30),\n        )\n\n        self.assertEqual(a1.get_next_by_pub_date(), a2)\n        self.assertEqual(a2.get_next_by_pub_date(), a3)\n        self.assertIsNone(a3.get_next_by_pub_date())\n\n        self.assertIsNone(a1.get_previous_by_pub_date())\n        self.assertEqual(a2.get_previous_by_pub_date(), a1)\n        self.assertEqual(a3.get_previous_by_pub_date(), a2)\n"], "sample_432": ["def test_get_changelist_instance_sortable_by(self):\n    m = ChildAdmin(Child, custom_site)\n    request = self.factory.get(\"/child/\")\n    request.user = self.superuser\n    cl = m.get_changelist_instance(request)\n    self.assertEqual(cl.sortable_by, (\"age\",))\n    # If ModelAdmin.sortable_by is set, it's used.\n    m.sortable_by = (\"name\",)\n    cl = m.get_changelist_instance(request)\n    self.assertEqual(cl.sortable_by, (\"name\",))\n    # If ModelAdmin.sortable_by is None, the default is used.\n    m.sortable_by = None\n    cl = m.get_changelist_instance(request)\n    self.assertEqual(cl.sortable_by, (\"age\",))\n    # If ModelAdmin.list_display is set, it's used.\n    m.list_display = (\"name\", \"age\")\n    cl = m.get_changelist_instance(request)\n    self.assertEqual(cl.sortable_by, (\"name\", \"age\"))\n    # If a field in ModelAdmin.list_display is not sortable, it's ignored.\n    m.list_display = (\"name\", \"age\", \"parent\")\n    cl = m.get_changelist_instance(request)\n    self.assertEqual(cl.sortable_by, (\"name\", \"age\"))\n"], "sample_440": ["def test_bulk_create_with_nullable_foreign_key(self):\n    parent = NoFields.objects.create()\n    child1 = NullableFields(auto_field=parent, integer_field=88)\n    child2 = NullableFields(auto_field=None, integer_field=99)\n    NullableFields.objects.bulk_create([child1, child2])\n    self.assertEqual(NullableFields.objects.count(), 2)\n    self.assertEqual(NullableFields.objects.filter(auto_field=parent).count(), 1)\n    self.assertEqual(NullableFields.objects.filter(auto_field__isnull=True).count(), 1)\n"], "sample_446": ["    def test_stringformat01(self):\n        output = self.engine.render_to_string(\"stringformat01\", {\"a\": 1.23})\n        self.assertEqual(output, \"1.230000E+00\")\n"], "sample_447": ["def test_alias_with_m2m(self):\n    qs = (\n        Author.objects.alias(\n            book_name=F(\"book__name\"),\n        )\n        .filter(\n            name=\"Adrian Holovaty\",\n            book__rating=4.5,\n        )\n        .values_list(\"book_name\", flat=True)\n    )\n    self.assertCountEqual(qs, [\"The Definitive Guide to Django: Web Development Done Right\"])\n"], "sample_451": ["def test_replace_metacharacters(self):\n    pattern = r\"^Hello, world\\?$\"\n    expected_output = \"^Hello, world$\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\^Hello, world\\$\"\n    expected_output = \"^Hello, world$\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n"], "sample_454": ["    def setUpTestData(cls):\n        cls.p1 = Product.objects.create(price=10, discounted_price=5)\n"], "sample_455": ["def test_validate_expression_with_exclude(self):\n    constraint = models.UniqueConstraint(Lower(\"name\"), name=\"name_lower_uniq\")\n    instance = UniqueConstraintProduct(name=self.p1.name.upper())\n    # Exclude should ignore the unique constraint.\n    constraint.validate(UniqueConstraintProduct, instance, exclude={\"name\"})\n    # Non-matching exclude should still raise an error.\n    msg = \"Constraint \u201cname_lower_uniq\u201d is violated.\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        constraint.validate(UniqueConstraintProduct, instance, exclude={\"color\"})\n"], "sample_457": ["def test_validate_expression_with_exclude(self):\n    constraint = models.UniqueConstraint(Lower(\"name\"), name=\"name_lower_uniq\")\n    existing_product = UniqueConstraintProduct.objects.create(name=\"test\")\n    new_product = UniqueConstraintProduct(name=\"TEST\")\n    with self.assertRaises(ValidationError):\n        constraint.validate(UniqueConstraintProduct, new_product)\n    constraint.validate(\n        UniqueConstraintProduct,\n        new_product,\n        exclude={\"name\"},\n    )\n    constraint.validate(\n        UniqueConstraintProduct,\n        existing_product,\n    )\n"], "sample_458": ["    def test_stringformat01(self):\n        output = self.engine.render_to_string(\"stringformat01\", {\"a\": 1.23})\n        self.assertEqual(output, \"1.230000E+00\")\n"], "sample_459": ["    def test_uuid_field_lookups(self):\n        from .models import UUIDModel\n\n        obj = UUIDModel.objects.create(uuid=\"123e4567-e89b-12d3-a456-426655440000\")\n\n        # Test exact lookup\n        self.assertEqual(UUIDModel.objects.get(uuid__exact=\"123e4567-e89b-12d3-a456-426655440000\"), obj)\n\n        # Test iexact lookup\n        self.assertEqual(UUIDModel.objects.get(uuid__iexact=\"123E4567-E89B-12D3-A456-426655440000\"), obj)\n\n        # Test contains lookup\n        self.assertEqual(UUIDModel.objects.get(uuid__contains=\"e4567-e89b-12d3\"), obj)\n\n        # Test icontains lookup\n        self.assertEqual(UUIDModel.objects.get(uuid__icontains=\"E4567-E89B-12D3\"), obj)\n\n        # Test startswith lookup\n        self.assertEqual(UUIDModel.objects.get(uuid__startswith=\"123e4567-e89b-12d3\"), obj)\n\n        # Test istartswith lookup\n        self.assertEqual(UUIDModel.objects.get(uuid__istartswith=\"123E4567-E89B-12D3\"), obj)\n\n        # Test endswith lookup\n        self.assertEqual(UUIDModel.objects.get(uuid__endswith=\"a456-426655440000\"), obj)\n\n        # Test iendswith lookup\n        self.assertEqual(UUIDModel.objects.get(uuid__iendswith=\"A456-426655440000\"), obj)\n"], "sample_461": ["    def test_urlfield_max_length(self):\n        f = URLField(max_length=20)\n        self.assertEqual(\"http://example.com\", f.clean(\"http://example.com\"))\n        msg = \"'Ensure this value has at most 20 characters (it has 21).'\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            f.clean(\"http://example.com/long\")\n"], "sample_462": ["def test_choicefield_with_initial(self):\n    f = ChoiceField(choices=[(\"1\", \"One\"), (\"2\", \"Two\")], initial=\"2\")\n    self.assertEqual(\"2\", f.clean(\"2\"))\n    msg = \"'Select a valid choice. 3 is not one of the available choices.'\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        f.clean(\"3\")\n    # If the initial value is not in the choices, it should raise an error.\n    f = ChoiceField(choices=[(\"1\", \"One\"), (\"2\", \"Two\")], initial=\"3\")\n    msg = \"'Select a valid choice. 3 is not one of the available choices.'\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        f.clean(\"3\")\n"], "sample_465": ["def test_get_inline_formsets(self):\n    class ConcertInline(TabularInline):\n        model = Concert\n        fk_name = \"main_band\"\n\n    class BandAdmin(ModelAdmin):\n        inlines = [ConcertInline]\n\n    ma = BandAdmin(Band, self.site)\n    formsets, inline_instances = ma.get_inline_formsets(request)\n    self.assertEqual(len(formsets), 1)\n    self.assertIsInstance(formsets[0], forms.BaseInlineFormSet)\n    self.assertEqual(len(inline_instances), 1)\n    self.assertIsInstance(inline_instances[0], ConcertInline)\n"], "sample_467": ["def test_selectdate_widget_required_attribute(self):\n    widget = SelectDateWidget(years=(\"2014\",))\n    self.assertIn('required', widget.render(\"mydate\", \"\"))\n    widget = SelectDateWidget(years=(\"2014\",), required=False)\n    self.assertNotIn('required', widget.render(\"mydate\", \"\"))\n"], "sample_469": ["def test_alias_forbidden_chars(self):\n    tests = [\n        'al\"ias',\n        \"a'lias\",\n        \"ali`as\",\n        \"alia s\",\n        \"alias\\t\",\n        \"ali\\nas\",\n        \"alias--\",\n        \"ali/*as\",\n        \"alias*/\",\n        \"alias;\",\n        # [] are used by MSSQL.\n        \"alias[\",\n        \"alias]\",\n    ]\n    msg = (\n        \"Column aliases cannot contain whitespace characters, quotation marks, \"\n        \"semicolons, or SQL comments.\"\n    )\n    for crafted_alias in tests:\n        with self.subTest(crafted_alias):\n            with self.assertRaisesMessage(ValueError, msg):\n                Book.objects.alias(**{crafted_alias: Value(1)})\n"], "sample_468": ["def test_make_context(self):\n    context = make_context({\"a\": 1})\n    self.assertIsInstance(context, Context)\n    self.assertEqual(context[\"a\"], 1)\n\n    request = self.request_factory.get(\"/\")\n    context = make_context({\"a\": 1}, request)\n    self.assertIsInstance(context, RequestContext)\n    self.assertEqual(context[\"a\"], 1)\n    self.assertEqual(context.request, request)\n\n    with self.assertRaises(TypeError):\n        make_context(\"not a dict\")\n"], "sample_471": ["def test_integerfield_widget_attrs(self):\n    f = IntegerField(min_value=10, max_value=20)\n    widget = f.widget\n    self.assertEqual(widget.attrs[\"min\"], 10)\n    self.assertEqual(widget.attrs[\"max\"], 20)\n\n    f = IntegerField(min_value=None, max_value=20)\n    widget = f.widget\n    self.assertNotIn(\"min\", widget.attrs)\n    self.assertEqual(widget.attrs[\"max\"], 20)\n\n    f = IntegerField(min_value=10, max_value=None)\n    widget = f.widget\n    self.assertEqual(widget.attrs[\"min\"], 10)\n    self.assertNotIn(\"max\", widget.attrs)\n\n    f = IntegerField(min_value=None, max_value=None)\n    widget = f.widget\n    self.assertNotIn(\"min\", widget.attrs)\n    self.assertNotIn(\"max\", widget.attrs)\n"], "sample_475": ["    def test_not_callable_or_boolean(self):\n        class TestModelAdmin(ModelAdmin):\n            view_on_site = \"hello\"\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'view_on_site' must be a callable or a boolean value.\",\n            id=\"admin.E025\",\n        )\n"], "sample_479": ["def test_add_remove_constraint(self):\n    self.assertOptimizesTo(\n        [\n            migrations.AddConstraint(\n                \"Pony\",\n                models.CheckConstraint(check=models.Q(weight__gt=0), name=\"chk_pony_weight\"),\n            ),\n            migrations.RemoveConstraint(\"Pony\", \"chk_pony_weight\"),\n        ],\n        [],\n    )\n"], "sample_480": ["def test_key_transform_on_expression_with_params(self):\n    expr = RawSQL(\"JSON_EXTRACT(%s, %s)\", ['{\"x\": \"bar\"}', \"$.x\"])\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__foo=KeyTransform(\"x\", expr)),\n        [self.objs[7]],\n    )\n"], "sample_481": ["    def test_add01(self):\n        output = self.engine.render_to_string(\"add01\", {\"a\": 1, \"b\": 2})\n        self.assertEqual(output, \"3\")\n"], "sample_482": ["    def test_basic(self):\n        output = self.engine.render_to_string(\n            \"safeseq_basic\",\n            {\"a\": [\"x&y\", \"<p>\"], \"b\": [mark_safe(\"x&y\"), mark_safe(\"<p>\")]},\n        )\n        self.assertEqual(output, \"x&y, <p> -- x&y, <p>\")\n"], "sample_486": ["def test_inlineformset_factory_with_empty_queryset(self):\n    \"\"\"\n    Test that inlineformset_factory works correctly when the queryset is empty.\n    \"\"\"\n    FormSet = inlineformset_factory(UUIDPKParent, UUIDPKChild, fields=\"__all__\")\n    formset = FormSet(queryset=UUIDPKChild.objects.none())\n    self.assertEqual(formset.forms[0].fields[\"parent\"].initial, None)\n"], "sample_487": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n"], "sample_489": ["def test_update_conflicts_non_unique_fields(self):\n    msg = \"bulk_create() can only be used with concrete fields in update_fields.\"\n    with self.assertRaisesMessage(ValueError, msg):\n        TwoFields.objects.bulk_create(\n            [TwoFields(f1=1, f2=1)],\n            update_conflicts=True,\n            update_fields=[\"nonexistent\"],\n        )\n"], "sample_490": ["def test_clone(self):\n    constraint = UniqueConstraint(\n        fields=[\"foo\", \"bar\"],\n        name=\"unique_fields\",\n        condition=models.Q(foo=models.F(\"bar\")),\n        deferrable=models.Deferrable.IMMEDIATE,\n        include=[\"baz_1\", \"baz_2\"],\n        opclasses=[\"text_pattern_ops\", \"varchar_pattern_ops\"],\n        nulls_distinct=False,\n        violation_error_code=\"custom_code\",\n        violation_error_message=\"Custom message\",\n    )\n    cloned_constraint = constraint.clone()\n    self.assertEqual(constraint, cloned_constraint)\n    self.assertIsNot(constraint, cloned_constraint)\n"], "sample_493": ["def test_aggregate_with_distinct_and_expression(self):\n    authors = Author.objects.annotate(\n        distinct_books=Count(\"book\", distinct=True),\n        double_distinct_books=F(\"distinct_books\") * 2,\n    )\n    self.assertQuerySetEqual(\n        authors,\n        [\n            (1, 2),\n            (1, 2),\n            (1, 2),\n            (1, 2),\n            (1, 2),\n            (1, 2),\n            (1, 2),\n            (2, 4),\n            (1, 2),\n        ],\n        lambda a: (a.distinct_books, a.double_distinct_books),\n    )\n"], "sample_494": ["def test_serialize_type_with_module(self):\n    self.assertSerializedEqual(type(None))\n    self.assertSerializedResultEqual(\n        type(None),\n        (\"types.NoneType\", {\"import types\"}),\n    )\n    self.assertSerializedEqual(models.Model)\n    self.assertSerializedResultEqual(\n        models.Model,\n        (\"models.Model\", {\"from django.db import models\"}),\n    )\n"], "sample_497": ["def test_axis_get_tick_space():\n    fig, ax = plt.subplots()\n    ax.set_xlim(0, 10)\n    ax.set_ylim(0, 10)\n\n    # Test x-axis tick space\n    assert isinstance(ax.xaxis.get_tick_space(), int)\n\n    # Test y-axis tick space\n    assert isinstance(ax.yaxis.get_tick_space(), int)\n"], "sample_498": ["def test_legend_handler_map():\n    # Test that the custom handler map is used when provided.\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='line')\n    handler_map = {mlines.Line2D: mlegend.HandlerLine2D()}\n    leg = ax.legend(handler_map=handler_map)\n    assert leg.get_legend_handler_map() == {**mlegend.Legend.get_default_handler_map(), **handler_map}\n"], "sample_501": ["def test_legend_bbox_to_anchor_transform():\n    # Test that the bbox_to_anchor argument can be specified with a transform.\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='line')\n    leg = ax.legend(bbox_to_anchor=(0.5, 0.5), loc='center',\n                    bbox_transform=ax.transAxes)\n    assert leg.get_bbox_to_anchor().x0 == 0.5\n    assert leg.get_bbox_to_anchor().y0 == 0.5\n    assert leg.get_bbox_to_anchor().transform == ax.transAxes\n"], "sample_503": ["def test_line2d_update_from():\n    line1 = mlines.Line2D([0, 1], [0, 1])\n    line1.set_color(\"red\")\n    line1.set_linestyle(\"--\")\n    line1.set_linewidth(2)\n    line1.set_marker(\"o\")\n    line1.set_markersize(10)\n\n    line2 = mlines.Line2D([0, 1], [0, 1])\n    line2.update_from(line1)\n\n    assert line2.get_color() == \"red\"\n    assert line2.get_linestyle() == \"--\"\n    assert line2.get_linewidth() == 2\n    assert line2.get_marker() == \"o\"\n    assert line2.get_markersize() == 10\n"], "sample_505": ["def test_datestr2num():\n    dates = ['2020-01-01', '2020-02-01']\n    nums = mdates.datestr2num(dates)\n    expected = mdates.date2num([datetime.datetime(2020, 1, 1),\n                                datetime.datetime(2020, 2, 1)])\n    np.testing.assert_equal(nums, expected)\n\n    # Test with custom default date\n    default = datetime.datetime(2020, 1, 1)\n    nums = mdates.datestr2num(['01-01', '02-01'], default=default)\n    expected = mdates.date2num([datetime.datetime(2020, 1, 1),\n                                datetime.datetime(2020, 2, 1)])\n    np.testing.assert_equal(nums, expected)\n"], "sample_506": ["def test_spine_bounds():\n    fig, ax = plt.subplots()\n    spine = ax.spines['left']\n    assert spine.get_bounds() is None\n\n    spine.set_bounds(0, 1)\n    assert spine.get_bounds() == (0, 1)\n\n    spine.set_bounds(low=2)\n    assert spine.get_bounds() == (2, 1)\n\n    spine.set_bounds(high=3)\n    assert spine.get_bounds() == (2, 3)\n\n    spine.set_bounds(None, None)\n    assert spine.get_bounds() is None\n"], "sample_511": ["def test_subplot_mosaic():\n    fig, axes = plt.subplot_mosaic([['A', 'B'], ['C', 'D']])\n    assert len(axes) == 4\n    assert set(axes.keys()) == {'A', 'B', 'C', 'D'}\n    for key in axes:\n        assert isinstance(axes[key], mpl.axes.Axes)\n"], "sample_512": ["def test_subplot_mosaic():\n    fig, axes = plt.subplot_mosaic(\n        [['A', 'B'],\n         ['C', 'D']]\n    )\n    assert len(axes) == 4\n    for ax in axes.values():\n        assert isinstance(ax, mpl.axes.Axes)\n"], "sample_516": ["def test_create_pdf_info_dict():\n    metadata = {\n        'Title': 'My PDF',\n        'Author': 'Me',\n        'Subject': 'Test PDF',\n        'Keywords': 'test,pdf',\n        'Creator': None,\n        'Producer': None,\n        'CreationDate': datetime.datetime(2022, 1, 1),\n        'ModDate': datetime.datetime(2022, 1, 2),\n        'Trapped': 'True'\n    }\n    info_dict = _create_pdf_info_dict('pdf', metadata)\n    assert info_dict == {\n        'Title': 'My PDF',\n        'Author': 'Me',\n        'Subject': 'Test PDF',\n        'Keywords': 'test,pdf',\n        'Creator': f'Matplotlib v{mpl.__version__}, https://matplotlib.org',\n        'Producer': f'Matplotlib pdf backend v{mpl.__version__}',\n        'CreationDate': datetime.datetime(2022, 1, 1),\n        'ModDate': datetime.datetime(2022, 1, 2),\n        'Trapped': Name('True')\n    }\n"], "sample_517": ["def test_text_set_backgroundcolor():\n    fig, ax = plt.subplots()\n    text = ax.text(0.5, 0.5, 'test')\n    text.set_backgroundcolor('red')\n    assert text.get_bbox_patch().get_facecolor() == (1.0, 0.0, 0.0, 1.0)\n"], "sample_518": ["def test_patch_alpha():\n    patch = Patch(alpha=0.5)\n    assert patch.get_alpha() == 0.5\n\n    patch.set_alpha(0.8)\n    assert patch.get_alpha() == 0.8\n\n    patch.set_alpha(None)\n    assert patch.get_alpha() is None\n"], "sample_519": ["def test_subfigure_repr():\n    fig = Figure()\n    subfig = fig.subfigures(1, 1)[0]\n    assert repr(subfig) == \"<SubFigure size 640x480 with 0 Axes>\"\n"], "sample_521": ["def test_line3d_collection_modification(fig_test, fig_ref):\n    # Test that modifying Line3DCollection properties after creation works.\n    segments = np.random.rand(5, 2, 3)\n    c = art3d.Line3DCollection(segments, linewidths=3)\n\n    ax_test = fig_test.add_subplot(projection='3d')\n    ax_test.add_collection3d(c)\n    c.set_edgecolor('C2')\n    c.set_alpha(0.7)\n    assert c.get_depthshade()\n    c.set_depthshade(False)\n    assert not c.get_depthshade()\n\n    c = art3d.Line3DCollection(segments, edgecolor='C2', alpha=0.7,\n                               depthshade=False)\n\n    ax_ref = fig_ref.add_subplot(projection='3d')\n    ax_ref.add_collection3d(c)\n"], "sample_531": ["def test_subfigure_repr():\n    fig = plt.figure()\n    subfig = fig.subfigures(1, 1)[0]\n    assert repr(subfig) == f\"<{subfig.__class__.__name__} size {subfig.get_size_inches()[0]:g}x{subfig.get_size_inches()[1]:g} with 0 Axes>\"\n"], "sample_532": ["def test_contourf_levels():\n    # Test that contourf levels are generated correctly.\n    z = np.arange(12).reshape((3, 4))\n    cs = plt.contourf(z)\n    assert len(cs.levels) == 7\n    assert cs.levels[0] == np.min(z)\n    assert cs.levels[-1] == np.max(z)\n\n    # Test that contourf levels can be set manually.\n    levels = [2, 4, 6, 8, 10]\n    cs = plt.contourf(z, levels=levels)\n    assert cs.levels.tolist() == levels\n\n    # Test that contourf levels can be set using a locator.\n    locator = ticker.MaxNLocator(nbins=5)\n    cs = plt.contourf(z, locator=locator)\n    assert len(cs.levels) == 5\n"], "sample_542": ["def test_get_rotation_mode():\n    text = Text(0, 0, 'test')\n    assert text.get_rotation_mode() is None\n\n    text.set_rotation_mode('default')\n    assert text.get_rotation_mode() == 'default'\n\n    text.set_rotation_mode('anchor')\n    assert text.get_rotation_mode() == 'anchor'\n"], "sample_545": ["def test_subfigure_repr():\n    fig = plt.figure()\n    subfig = fig.subfigures(1, 1)[0]\n    assert repr(subfig) == f\"<{subfig.__class__.__name__} size {subfig.get_size_inches()[0]:g}x{subfig.get_size_inches()[1]:g} with 0 Axes>\"\n"], "sample_546": ["def test_figure_repr():\n    fig = Figure()\n    assert repr(fig) == \"<Figure size 640x480 with 0 Axes>\"\n    ax = fig.add_subplot(111)\n    assert repr(fig) == \"<Figure size 640x480 with 1 Axes>\"\n"], "sample_549": ["def test__get_running_interactive_framework():\n    import sys\n    import matplotlib\n    # Make sure we don't have any interactive framework already set.\n    assert not hasattr(sys, 'ps1')\n    assert matplotlib.get_backend() == 'agg'\n\n    # Test that _get_running_interactive_framework returns None when no\n    # interactive framework is running.\n    assert cbook._get_running_interactive_framework() is None\n\n    # Now, let's simulate an interactive IPython session.\n    class FakeIPython:\n            self.events = {}\n\n    fake_ipython = FakeIPython()\n    sys.modules['IPython'] = fake_ipython\n    try:\n        # We should now detect that we're running under IPython.\n        assert cbook._get_running_interactive_framework() == 'ipympl'\n    finally:\n        del sys.modules['IPython']\n\n    # Let's try simulating a different interactive framework (e.g. IDLE).\n    sys.ps1 = '>>> '\n    try:\n        # We should now detect that we're running under some other interactive\n        # framework.\n        assert cbook._get_running_interactive_framework() == 'headless'\n    finally:\n        del sys.ps1\n"], "sample_550": ["def test_axes_set_position():\n    fig, ax = plt.subplots()\n    orig_pos = ax.get_position(original=True)\n    new_pos = [orig_pos.x0 + 0.1, orig_pos.y0 + 0.1,\n               orig_pos.width - 0.2, orig_pos.height - 0.2]\n    ax.set_position(new_pos)\n    assert np.allclose(ax.get_position().bounds, new_pos)\n    ax.reset_position()\n    assert np.allclose(ax.get_position().bounds, orig_pos.bounds)\n"], "sample_551": ["def test_linecollection_2d_to_3d():\n    from matplotlib.collections import LineCollection\n    from mpl_toolkits.mplot3d import art3d\n\n    fig, ax = plt.subplots(subplot_kw=dict(projection='3d'))\n\n    # Create a 2D line collection\n    lines = [[(0, 1), (1, 1)], [(2, 3), (3, 3)]]\n    lc = LineCollection(lines)\n\n    # Convert the line collection to 3D\n    art3d.line_collection_2d_to_3d(lc, zs=5, zdir='z')\n\n    # Add the 3D line collection to the axes\n    ax.add_collection(lc)\n\n    # Check that the line collection has been correctly converted to 3D\n    assert isinstance(lc, art3d.Line3DCollection)\n    assert lc.get_zs() == 5\n    assert lc.get_zdir() == 'z'\n"], "sample_552": ["def test_subfigure_repr():\n    fig = Figure()\n    subfig = fig.subfigures(1)[0]\n    assert repr(subfig) == f\"<SubFigure size {subfig.get_size_inches()[0]:g}x{subfig.get_size_inches()[1]:g} with 0 Axes>\"\n"], "sample_553": ["def test_adjusted_figsize():\n    w, h = 10, 5\n    dpi = 100\n    n = 2\n\n    adjusted_w, adjusted_h = animation.adjusted_figsize(w, h, dpi, n)\n\n    assert adjusted_w % n == 0\n    assert adjusted_h % n == 0\n    assert abs(adjusted_w - w) < 1 / dpi\n    assert abs(adjusted_h - h) < 1 / dpi\n"], "sample_554": ["def test_text_bbox():\n    fig, ax = plt.subplots()\n    text = ax.text(0.5, 0.5, 'test', bbox=dict(facecolor='red'))\n    fig.canvas.draw()\n    assert text.get_bbox_patch() is not None\n\n    text.set_bbox(None)\n    fig.canvas.draw()\n    assert text.get_bbox_patch() is None\n\n    text.set_bbox(dict(facecolor='blue'))\n    fig.canvas.draw()\n    assert text.get_bbox_patch() is not None\n"], "sample_556": ["def test_subfigure_repr():\n    fig = plt.figure()\n    subfig = fig.subfigures(1, 2)[0]\n    assert repr(subfig) == \"<SubFigure size 640x480 with 0 Axes>\"\n"], "sample_557": ["def test_subfigure_repr():\n    fig = plt.figure()\n    subfig = fig.subfigures(1, 2)[0]\n    assert repr(subfig) == f\"<{subfig.__class__.__name__} size {subfig.get_size_inches()[0]:g}x{subfig.get_size_inches()[1]:g} with 0 Axes>\"\n"], "sample_562": ["def test_axline_transform():\n    fig, ax = plt.subplots()\n    line1 = ax.axline((.1, .1), slope=0.6)\n    line2 = ax.axline((.1, .1), (.8, .4))\n    # Testing that the transform is correctly set.\n    assert isinstance(line1.get_transform(), mtransforms.BboxTransformTo)\n    assert isinstance(line2.get_transform(), mtransforms.BboxTransformTo)\n    # Testing that the transform is correctly applied.\n    fig.canvas.draw()\n    assert len(line1.get_xydata()) == 2\n    assert len(line2.get_xydata()) == 2\n"], "sample_566": ["def test_subfigure_repr():\n    fig = plt.figure(figsize=(10, 20), dpi=10)\n    subfig = fig.subfigures(1, 2)[0]\n    assert repr(subfig) == \"<SubFigure size 100x200 with 0 Axes>\"\n"], "sample_568": ["def test_line3d_collection_zsort(fig_test, fig_ref):\n    fig_test = plt.figure()\n    ax_test = fig_test.add_subplot(projection='3d')\n    fig_ref = plt.figure()\n    ax_ref = fig_ref.add_subplot(projection='3d')\n\n    np.random.seed(0)\n    for _ in range(10):\n        x = np.random.uniform(-1, 1, 2)\n        y = np.random.uniform(-1, 1, 2)\n        z = np.random.uniform(-1, 1, 2)\n        ax_test.plot(x, y, z, 'b-')\n        ax_ref.plot(x, y, z, 'b-')\n\n    ax_test.set_xlim(-1, 1)\n    ax_test.set_ylim(-1, 1)\n    ax_test.set_zlim(-1, 1)\n    ax_ref.set_xlim(-1, 1)\n    ax_ref.set_ylim(-1, 1)\n    ax_ref.set_zlim(-1, 1)\n\n    # Manually sort the Line3D objects by their mean z-value.\n    lines = sorted(ax_test.lines, key=lambda line: np.mean(line.get_data_3d()[2]))\n    ax_test.lines = lines\n\n    # Now check that the automatic sorting gives the same result.\n    ax_ref.auto_scale_xyz(ax_test.get_xlim3d(), ax_test.get_ylim3d(), ax_test.get_zlim3d())\n    ax_ref.apply_aspect()\n    ax_ref._do_unstale_viewLim3d()\n    ax_ref.relim()\n    ax_ref.autoscale_view()\n    ax_ref.tick_params(axis='both', which='both', length=0)\n    ax_test.tick_params(axis='both', which='both', length=0)\n"], "sample_569": ["def test_lmplot_size_deprecation(self):\n\n    with pytest.warns(UserWarning):\n        lm.lmplot(x=\"x\", y=\"y\", data=self.df, size=6)\n\n    with pytest.raises(TypeError):\n        lm.lmplot(x=\"x\", y=\"y\", data=self.df, height=None)\n"], "sample_571": ["def test_lmplot_legend_labels(self):\n\n    g = lm.lmplot(x=\"x\", y=\"y\", hue=\"h\", data=self.df)\n    legend_texts = [t.get_text() for t in g._legend.texts]\n    assert legend_texts == ['x', 'y']\n"], "sample_574": ["    def test_identity_scale(self):\n\n        s = Scale._identity()\n        x = pd.Series([1, 2, 3], name=\"x\")\n        assert_series_equal(s(x), x)\n"], "sample_575": ["    def test_identity(self):\n\n        s = Scale._identity()\n        x = pd.Series([1, 2, 3], name=\"x\")\n        assert_series_equal(s(x), x)\n"], "sample_576": ["    def test_figure(self):\n\n        f = mpl.figure.Figure()\n        p = Plot().on(f).plot()\n        assert p._figure is f\n"], "sample_577": ["    def test_plot_on_with_facets(self):\n\n        f = mpl.figure.Figure()\n        p = Plot().facet([\"a\", \"b\"]).on(f)\n        with pytest.raises(RuntimeError, match=\"Cannot create multiple subplots\"):\n            p.plot()\n"], "sample_581": ["def test_blueprint_url_value_preprocessor_exception(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.url_value_preprocessor\n        raise Exception(\"Test exception\")\n\n    @bp.route(\"/test\")\n        return \"Test\"\n\n    app.register_blueprint(bp)\n\n    with pytest.raises(Exception) as e:\n        client.get(\"/test\")\n\n    assert str(e.value) == \"Test exception\"\n"], "sample_583": ["def test_posify_mask_indexer():\n    indexer = indexing.OuterIndexer((np.array([0, -1, 2]),))\n    expected = indexing.OuterIndexer((np.array([0, 0, 2]),))\n    actual = indexing.posify_mask_indexer(indexer)\n    assert isinstance(actual, indexing.OuterIndexer)\n    np.testing.assert_array_equal(expected.tuple[0], actual.tuple[0])\n\n    indexer = indexing.VectorizedIndexer(\n        (np.array([0, -1, 2]), np.array([0, 1, -1])))\n    expected = indexing.VectorizedIndexer(\n        (np.array([0, 0, 2]), np.array([0, 1, 1])))\n    actual = indexing.posify_mask_indexer(indexer)\n    assert isinstance(actual, indexing.VectorizedIndexer)\n    np.testing.assert_array_equal(expected.tuple[0], actual.tuple[0])\n    np.testing.assert_array_equal(expected.tuple[1], actual.tuple[1])\n"], "sample_587": ["def test_merge_no_conflicts_multi_dim(self):\n    ds1 = xr.Dataset({\"a\": ((\"x\", \"y\"), [[1, 2], [3, 4]])})\n    ds2 = xr.Dataset({\"a\": ((\"x\", \"y\"), [[5, 6], [7, 8]])})\n    expected = xr.Dataset(\n        {\"a\": ((\"x\", \"y\"), [[1, 2], [3, 4], [5, 6], [7, 8]])},\n        coords={\"x\": [0, 1, 2, 3], \"y\": [0, 1]},\n    )\n    assert expected.identical(ds1.merge(ds2, compat=\"no_conflicts\"))\n    assert expected.identical(ds2.merge(ds1, compat=\"no_conflicts\"))\n\n    ds1 = xr.Dataset({\"a\": ((\"x\", \"y\"), [[1, 2], [np.nan, np.nan]])})\n    ds2 = xr.Dataset({\"a\": ((\"x\", \"y\"), [[np.nan, np.nan], [7, 8]])})\n    expected = xr.Dataset(\n        {\"a\": ((\"x\", \"y\"), [[1, 2], [np.nan, np.nan], [np.nan, np.nan], [7, 8]])},\n        coords={\"x\": [0, 1, 2, 3], \"y\": [0, 1]},\n    )\n    assert expected.identical(ds1.merge(ds2, compat=\"no_conflicts\"))\n    assert expected.identical(ds2.merge(ds1, compat=\"no_conflicts\"))\n"], "sample_595": ["def test_split(dtype):\n    values = xr.DataArray([\"a_b_c\", \"c_d_e\", \"f_g_h\"]).astype(dtype)\n\n    result = values.str.split(\"_\")\n    expected = xr.DataArray([[\"a\", \"b\", \"c\"], [\"c\", \"d\", \"e\"], [\"f\", \"g\", \"h\"]])\n    assert_equal(result, expected)\n\n    result = values.str.split(\"_\", 1)\n    expected = xr.DataArray([[\"a\", \"b_c\"], [\"c\", \"d_e\"], [\"f\", \"g_h\"]])\n    assert_equal(result, expected)\n\n    result = values.str.rsplit(\"_\", 1)\n    expected = xr.DataArray([[\"a_b\", \"c\"], [\"c_d\", \"e\"], [\"f_g\", \"h\"]])\n    assert_equal(result, expected)\n"], "sample_606": ["def test_cross_broadcasting() -> None:\n    # Test broadcasting of cross product\n    a = xr.DataArray(\n        np.array([[1, 2], [3, 4]]),\n        dims=[\"x\", \"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\"])),\n    )\n    b = xr.DataArray(\n        np.array([4, 5, 6]),\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n\n    expected = np.cross(a.values[:, None, :], b.values[None, :], axis=-1)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n"], "sample_615": ["def test_cross_broadcasting() -> None:\n    # Test broadcasting of cross product\n    a = xr.DataArray(\n        np.array([[1, 2], [3, 4]]),\n        dims=[\"x\", \"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\"])),\n    )\n    b = xr.DataArray(\n        np.array([4, 5, 6]),\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n\n    expected = np.cross(a.values[:, None, :], b.values)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n"], "sample_616": ["def test_cross_broadcasting() -> None:\n    a = xr.DataArray(\n        np.array([[1, 2], [3, 4]]),\n        dims=[\"x\", \"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\"])),\n    )\n    b = xr.DataArray(\n        np.array([4, 5, 6]),\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n\n    expected = np.cross(a.values[:, np.newaxis, :], b.values[np.newaxis, :, :])\n\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n"], "sample_617": ["def test_cross_broadcasting() -> None:\n    a = xr.DataArray(\n        np.array([[1, 2], [3, 4]]),\n        dims=[\"x\", \"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\"])),\n    )\n    b = xr.DataArray(\n        np.array([4, 5, 6]),\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n\n    expected = np.cross(a.values[:, np.newaxis, :], b.values, axis=-1)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n"], "sample_618": ["def test_cross_broadcasting() -> None:\n    a = xr.DataArray(\n        np.array([[1, 2], [3, 4]]),\n        dims=[\"x\", \"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\"])),\n    )\n    b = xr.DataArray(\n        np.array([4, 5, 6]),\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n\n    expected = np.cross(a.values[:, np.newaxis, :], b.values[np.newaxis, :, :])\n\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n"], "sample_621": ["def test_filter_indexes_from_coords(self, indexes) -> None:\n    filtered_coord_names = {\"x\", \"y\", \"one\"}\n    filtered_indexes = filter_indexes_from_coords(indexes, filtered_coord_names)\n    assert set(filtered_indexes) == {\"x\", \"y\"}\n\n    filtered_coord_names = {\"z\", \"one\", \"two\"}\n    filtered_indexes = filter_indexes_from_coords(indexes, filtered_coord_names)\n    assert set(filtered_indexes) == {\"z\", \"one\", \"two\"}\n\n    filtered_coord_names = {\"x\", \"y\", \"z\"}\n    filtered_indexes = filter_indexes_from_coords(indexes, filtered_coord_names)\n    assert set(filtered_indexes) == {\"x\", \"y\"}\n"], "sample_624": ["def test_inline_dask_repr() -> None:\n    import dask.array as da\n\n    array = da.from_array(np.arange(10), chunks=5)\n    actual = formatting.inline_dask_repr(array)\n    expected = \"dask.array<chunksize=(5,), meta=np.ndarray>\"\n    assert actual == expected\n"], "sample_625": ["def test_cross_broadcasting() -> None:\n    a = xr.DataArray(\n        np.array([[1, 2], [3, 4]]),\n        dims=[\"x\", \"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\"])),\n    )\n    b = xr.DataArray(\n        np.array([4, 5, 6]),\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n\n    expected_a = np.array([[1, 2, 0], [3, 4, 0]])\n    expected_b = np.array([4, 5, 6])\n\n    expected = np.cross(expected_a, expected_b)\n\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n"], "sample_626": ["def test_create_mask():\n    shape = (3, 4)\n    indexer1 = VectorizedIndexer((np.array([0, 1]), np.array([2, 3])))\n    mask1 = create_mask(indexer1, shape)\n    assert_array_equal(mask1, np.zeros(shape, dtype=\"bool))\n\n    indexer2 = VectorizedIndexer((np.array([0, -1]), np.array([2, 3])))\n    mask2 = create_mask(indexer2, shape)\n    expected_mask2 = np.zeros(shape, dtype=\"bool)\n    expected_mask2[1, :] = True\n    assert_array_equal(mask2, expected_mask2)\n\n    indexer3 = OuterIndexer((np.array([0, 1]), slice(1, 3)))\n    mask3 = create_mask(indexer3, shape)\n    assert_array_equal(mask3, np.zeros(shape, dtype=\"bool))\n\n    indexer4 = BasicIndexer((1, slice(1, 3)))\n    mask4 = create_mask(indexer4, shape)\n    assert mask4 is False\n"], "sample_631": ["def test_undefined_variable_in_nested_function(self):\n    \"\"\"Make sure undefined-variable is raised for variables used in nested functions\"\"\"\n    node = astroid.parse(\n        \"\"\"\n                return undefined  # should raise here\n        \"\"\"\n    )\n    with self.assertAddsMessages(\n        Message(\"undefined-variable\", node=node.body[0].body[0].body[0].value, args=\"undefined\")\n    ):\n        self.walk(node)\n"], "sample_632": ["def test_combine_mapreduce_data():\n    \"\"\"Tests that a SimilarChecker respects the MapReduceMixin interface\"\"\"\n    linter = PyLinter(reporter=Reporter())\n\n    # Add a parallel checker to ensure it can map and reduce\n    sim = similar.SimilarChecker(linter)\n\n    source_streams = (\n        str(INPUT / \"similar_lines_a.py\"),\n        str(INPUT / \"similar_lines_b.py\"),\n    )\n\n    data = []\n\n    # Manually perform a 'map' type function\n    for source_fname in source_streams:\n        with open(source_fname) as stream:\n            sim.append_stream(source_fname, stream)\n        # The map bit, can you tell? ;)\n        data.extend(sim.get_map_data())\n\n    # Now we manually call combine_mapreduce_data\n    sim.combine_mapreduce_data(data)\n\n    assert len(sim.linesets) == len(data)\n    for lineset_obj1, lineset_obj2 in zip(sim.linesets, data):\n        assert lineset_obj1.name == lineset_obj2.name\n        # There doesn't seem to be a faster way of doing this, yet.\n        lines1 = (line for idx, line in lineset_obj1.enumerate_stripped())\n        lines2 = (line for idx, line in lineset_obj2.enumerate_stripped())\n        assert tuple(lines1) == tuple(lines2)\n"], "sample_636": ["def test_duplicate_code_with_ignored_imports(self) -> None:\n    \"\"\"Tests that duplicate code detection ignores imports when ignore-imports is enabled.\"\"\"\n    path = join(DATA, \"duplicate_code_with_imports\")\n    expected_output = \"Similar lines in 2 files\"\n    self._test_output(\n        [path, \"--disable=all\", \"--enable=duplicate-code\", \"--ignore-imports=y\"],\n        expected_output=expected_output,\n    )\n"], "sample_644": ["def test_import_outside_toplevel(self) -> None:\n    module = astroid.MANAGER.ast_from_module_name(\"import_outside_toplevel\", REGR_DATA)\n    function_def = module.body[0]\n    import_node = function_def.body[0]\n\n    msg = MessageTest(\n        msg_id=\"import-outside-toplevel\",\n        node=import_node,\n        args=\"os\",\n        confidence=UNDEFINED,\n        line=3,\n        col_offset=4,\n        end_line=3,\n        end_col_offset=14,\n    )\n    with self.assertAddsMessages(msg):\n        self.checker.visit_import(import_node)\n"], "sample_654": ["def test_fixture_param_shadowing_with_multiple_fixtures(testdir):\n    \"\"\"Parametrized arguments would be shadowed if multiple fixtures with the same name also exist (#5036)\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture(params=['a', 'b'])\n            return request.param\n\n        @pytest.fixture\n            return argroot\n\n        @pytest.fixture(params=['c', 'd'])\n            return request.param\n\n        # This should only be parametrized directly\n        @pytest.mark.parametrize(\"arg\", [1])\n            assert arg == 1\n\n        # This should be parametrized based on the fixtures\n            assert isinstance(arg, str)\n\n        # Indirect should still work:\n\n        @pytest.fixture\n            return 2*request.param\n\n        @pytest.mark.parametrize(\"arg2\", [1], indirect=True)\n            assert arg2 == 2\n    \"\"\"\n    )\n    # Only one test should have run\n    result = testdir.runpytest(\"-v\")\n    result.assert_outcomes(passed=6)\n    result.stdout.fnmatch_lines([\"*::test_direct[[]1[]]*\"])\n    result.stdout.fnmatch_lines([\"*::test_normal_fixture[[]a[]]*\"])\n    result.stdout.fnmatch_lines([\"*::test_normal_fixture[[]b[]]*\"])\n    result.stdout.fnmatch_lines([\"*::test_normal_fixture[[]c[]]*\"])\n    result.stdout.fnmatch_lines([\"*::test_normal_fixture[[]d[]]*\"])\n    result.stdout.fnmatch_lines([\"*::test_indirect[[]1[]]*\"])\n"], "sample_659": ["def test_traceback_entry_repr(self):\n    try:\n        raise ValueError(\"test\")\n    except ValueError:\n        excinfo = pytest.raises(ValueError).excinfo\n\n    entry = excinfo.traceback[0]\n    repr_entry = ReprEntry(\n        lines=[\"line1\", \"line2\"],\n        reprfuncargs=None,\n        reprlocals=None,\n        filelocrepr=ReprFileLocation(\"path/to/file.py\", 10, \"error message\"),\n        style=\"long\",\n    )\n    assert str(repr_entry) == \"line1\\nline2\\npath/to/file.py:10: error message\"\n"], "sample_662": ["def test_report_get_sections(self, testdir):\n    \"\"\"Test that the get_sections method of BaseReport works correctly.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    reports = reprec.getreports(\"pytest_runtest_logreport\")\n    assert len(reports) == 6\n    for rep in reports:\n        sections = list(rep.get_sections(\"Captured\"))\n        if rep.when == \"call\" and rep.outcome == \"failed\":\n            assert len(sections) > 0\n        else:\n            assert len(sections) == 0\n"], "sample_675": ["def test_log_file_format(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        log_file_format = %(asctime)s %(levelname)s %(message)s\n        log_file_date_format = %Y-%m-%d %H:%M:%S\n        \"\"\".format(\n            log_file\n        )\n    )\n\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logging.info('text going to logger from call')\n            assert True\n        \"\"\"\n    )\n\n    result = testdir.runpytest()\n    assert result.ret == 0\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert re.match(r\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} INFO text going to logger from call\", contents)\n"], "sample_683": ["def test_capture_manager_is_capturing() -> None:\n    capman = CaptureManager(\"fd\")\n    assert capman.is_capturing() == \"global\"\n    capman.start_global_capturing()\n    assert capman.is_capturing() == \"global\"\n    capman.stop_global_capturing()\n    assert capman.is_capturing() == False\n"], "sample_684": ["def test_traceback_recursion_index() -> None:\n        if n > 0:\n            recursive_function(n - 1)\n        else:\n            raise Exception(\"Base case\")\n\n    try:\n        recursive_function(5)\n    except Exception:\n        excinfo = ExceptionInfo.from_current()\n\n    assert excinfo.traceback.recursionindex() is not None\n"], "sample_687": ["def test_log_cli_enabled(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin._log_cli_enabled() == True\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--log-cli-level=INFO\")\n    assert result.ret == 0\n"], "sample_688": ["def test_absolutepath(tmpdir):\n    \"\"\"Test absolutepath function.\"\"\"\n    p = tmpdir.join(\"test.txt\")\n    p.write(\"example\")\n    assert absolutepath(p) == Path(os.path.abspath(str(p)))\n    assert absolutepath(str(p)) == Path(os.path.abspath(str(p)))\n"], "sample_694": ["def test_argument_percent_default_is_deprecated(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n            parser.addoption(\"--foo\", default=\"bar\", help=\"%%default\")\n        \"\"\"\n    )\n    result = pytester.runpytest(\"-Wdefault::pytest.PytestRemovedIn8Warning\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestRemovedIn8Warning: pytest now uses argparse. \\\"%%default\\\" should be changed to \\\"%%(default)s\\\"\",\n        ]\n    )\n"], "sample_702": ["def test_pytester_runpytest_subprocess_timeout(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import time\n\n            time.sleep(10)\n        \"\"\"\n    )\n    result = pytester.runpytest_subprocess(timeout=1)\n    assert result.ret == ExitCode.INTERRUPTED\n"], "sample_704": ["def test_node_repr_failure_with_changed_cwd(pytester: Pytester) -> None:\n    \"\"\"\n    Test failure lines should use absolute paths if cwd has changed since\n    invocation, so the path is correct (#6428).\n    \"\"\"\n    p = pytester.makepyfile(\n        \"\"\"\n        import os\n        import pytest\n\n        @pytest.fixture\n            out_dir = 'ddd'\n            os.mkdir(out_dir)\n            old_dir = os.getcwd()\n            os.chdir(out_dir)\n            yield out_dir\n            os.chdir(old_dir)\n\n            assert False\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--tb=short\")\n    result.stdout.fnmatch_lines([str(p) + \":*: AssertionError\", \"*1 failed in *\"])\n"], "sample_705": ["def test_pytester_run_with_timeout(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import time\n\n            time.sleep(10)\n        \"\"\"\n    )\n    result = pytester.runpytest(timeout=1)\n    assert result.ret == ExitCode.INTERRUPTED\n"], "sample_709": ["def test_pytester_runpytest_subprocess_with_timeout(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import time\n\n            time.sleep(10)\n        \"\"\"\n    )\n    result = pytester.runpytest_subprocess(timeout=1)\n    assert result.ret == ExitCode.INTERRUPTED\n"], "sample_711": ["def test_node_repr_failure_with_changed_cwd(pytester: Pytester) -> None:\n    \"\"\"\n    Test failure lines should use absolute paths if cwd has changed since\n    invocation, so the path is correct (#6428).\n    \"\"\"\n    p = pytester.makepyfile(\n        \"\"\"\n        import os\n        import pytest\n\n        @pytest.fixture\n            out_dir = 'ddd'\n            os.mkdir(out_dir)\n            old_dir = os.getcwd()\n            os.chdir(out_dir)\n            yield out_dir\n            os.chdir(old_dir)\n\n            assert False\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--tb=short\")\n    result.stdout.fnmatch_lines([str(p) + \":*: AssertionError\", \"*1 failed in *\"])\n"], "sample_717": ["def test_load_fake_lfw_pairs_subset():\n    lfw_pairs_train = fetch_lfw_pairs(data_home=SCIKIT_LEARN_DATA,\n                                      subset='train',\n                                      download_if_missing=False)\n\n    # The data is croped around the center as a rectangular bounding box\n    # around the face. Colors are converted to gray levels:\n    assert_equal(lfw_pairs_train.pairs.shape, (10, 2, 62, 47))\n\n    # the target is whether the person is the same or not\n    assert_array_equal(lfw_pairs_train.target, [1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n\n    # names of the persons can be found using the target_names array\n    expected_classes = ['Different persons', 'Same person']\n    assert_array_equal(lfw_pairs_train.target_names, expected_classes)\n\n    # Test that other subsets raise an error\n    assert_raises(ValueError, fetch_lfw_pairs, data_home=SCIKIT_LEARN_DATA,\n                  subset='invalid')\n"], "sample_718": ["def test_check_estimator_sparse_data():\n    # check that check_estimator() works on estimator with sparse data\n\n    class SparseEstimator(BaseEstimator):\n            X, y = check_X_y(X, y, accept_sparse=True)\n            return self\n\n            X = check_array(X, accept_sparse=True)\n            return np.ones(X.shape[0])\n\n    est = SparseEstimator()\n    check_estimator(est)\n"], "sample_728": ["def test_make_gaussian_quantiles():\n    X, y = make_gaussian_quantiles(n_samples=100, n_features=2,\n                                   n_classes=3, random_state=0)\n\n    assert_equal(X.shape, (100, 2), \"X shape mismatch\")\n    assert_equal(y.shape, (100,), \"y shape mismatch\")\n    assert_equal(np.unique(y).shape, (3,), \"Unexpected number of classes\")\n\n    # Test that clusters are on vertices of hypercube\n    for i in range(3):\n        X_i = X[y == i]\n        for j in range(2):\n            assert_almost_equal(np.abs(X_i[:, j]).mean(), 1.0, decimal=1)\n"], "sample_735": ["def test_gaussian_mixture_get_parameters():\n    # We check that the get_parameters method returns the correct parameters\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng, scale=7)\n    n_components = rand_data.n_components\n\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        gmm = GaussianMixture(n_components=n_components,\n                              covariance_type=covar_type, random_state=rng)\n        gmm.fit(X)\n\n        weights, means, covariances, precisions_cholesky = gmm._get_parameters()\n        assert_array_almost_equal(weights, gmm.weights_)\n        assert_array_almost_equal(means, gmm.means_)\n        if covar_type == 'full':\n            assert_array_almost_equal(covariances, gmm.covariances_)\n        elif covar_type == 'tied':\n            assert_array_almost_equal(covariances, gmm.covariances_)\n        else:\n            assert_array_almost_equal(covariances, gmm.covariances_)\n        assert_array_almost_equal(precisions_cholesky, gmm.precisions_cholesky_)\n"], "sample_741": ["def test_grid_search_cv_results_rank_tie_breaking_with_refit():\n    X, y = make_blobs(n_samples=50, random_state=42)\n\n    # The two C values are close enough to give similar models\n    # which would result in a tie of their mean cv-scores\n    param_grid = {'C': [1, 1.001, 0.001]}\n\n    grid_search = GridSearchCV(SVC(gamma=\"scale\"), param_grid=param_grid,\n                               refit=True)\n    grid_search.fit(X, y)\n    cv_results = grid_search.cv_results_\n    # Check tie breaking strategy -\n    # Check that there is a tie in the mean scores between\n    # candidates 1 and 2 alone\n    assert_almost_equal(cv_results['mean_test_score'][0],\n                        cv_results['mean_test_score'][1])\n    assert_almost_equal(cv_results['mean_train_score'][0],\n                        cv_results['mean_train_score'][1])\n    assert_false(np.allclose(cv_results['mean_test_score'][1],\n                             cv_results['mean_test_score'][2]))\n    assert_false(np.allclose(cv_results['mean_train_score'][1],\n                             cv_results['mean_train_score'][2]))\n    # 'min' rank should be assigned to the tied candidates\n    assert_almost_equal(grid_search.cv_results_['rank_test_score'], [1, 1, 3])\n    # Check best estimator is chosen based on 'min' rank\n    assert_equal(grid_search.best_index_, 0)\n"], "sample_746": ["def test_brier_score_loss_multiclass():\n    # Check brier_score_loss function for multiclass case\n    y_true = np.array([0, 1, 2, 0, 1, 2])\n    y_pred = np.array([[0.9, 0.05, 0.05], [0.05, 0.9, 0.05],\n                       [0.05, 0.05, 0.9], [0.8, 0.1, 0.1],\n                       [0.1, 0.8, 0.1], [0.1, 0.1, 0.8]])\n    true_score = np.mean(np.sum((y_pred - np.eye(3)[y_true]) ** 2, axis=1))\n\n    assert_almost_equal(brier_score_loss(y_true, y_pred), true_score)\n    assert_raises(ValueError, brier_score_loss, y_true, y_pred[:, :-1])\n"], "sample_748": ["def test_grid_search_cv_results_rank_tie_breaking_with_scoring():\n    X, y = make_blobs(n_samples=50, random_state=42)\n\n    # The two C values are close enough to give similar models\n    # which would result in a tie of their mean cv-scores\n    param_grid = {'C': [1, 1.001, 0.001]}\n\n    grid_search = GridSearchCV(SVC(gamma=\"scale\"), param_grid=param_grid,\n                               scoring='f1_macro')\n    grid_search.fit(X, y)\n    cv_results = grid_search.cv_results_\n    # Check tie breaking strategy -\n    # Check that there is a tie in the mean scores between\n    # candidates 1 and 2 alone\n    assert_almost_equal(cv_results['mean_test_score'][0],\n                        cv_results['mean_test_score'][1])\n    assert_almost_equal(cv_results['mean_train_score'][0],\n                        cv_results['mean_train_score'][1])\n    assert_false(np.allclose(cv_results['mean_test_score'][1],\n                             cv_results['mean_test_score'][2]))\n    assert_false(np.allclose(cv_results['mean_train_score'][1],\n                             cv_results['mean_train_score'][2]))\n    # 'min' rank should be assigned to the tied candidates\n    assert_almost_equal(grid_search.cv_results_['rank_test_score'], [1, 1, 3])\n"], "sample_749": ["def test_column_transformer_get_feature_names_with_remainder():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).astype('float').T\n    ct = ColumnTransformer([('trans1', StandardScaler(), [0])],\n                           remainder=StandardScaler())\n\n    ct.fit(X_array)\n    feature_names = ct.get_feature_names()\n    assert len(feature_names) == X_array.shape[1]\n    assert 'trans1__x0' in feature_names\n    assert 'remainder__x1' in feature_names\n    assert 'remainder__x2' in feature_names\n"], "sample_753": ["def test_logistic_regression_multiclass_predict_proba():\n    # Test that predict_proba works for both 'ovr' and 'multinomial'\n    X, y = make_classification(n_samples=100, n_features=20, random_state=0,\n                               n_classes=3, n_informative=10)\n\n    clf_ovr = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\")\n    clf_ovr.fit(X, y)\n    assert_array_almost_equal(clf_ovr.predict_proba(X).sum(axis=1), np.ones(100))\n\n    clf_multi = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n    clf_multi.fit(X, y)\n    assert_array_almost_equal(clf_multi.predict_proba(X).sum(axis=1), np.ones(100))\n"], "sample_764": ["def test_column_transformer_get_feature_names_with_remainder():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    ct = ColumnTransformer([('trans', Trans(), [0])],\n                           remainder=StandardScaler())\n    ct.fit(X_array)\n    assert_equal(ct.get_feature_names(), ['trans__x0', 'remainder__x1'])\n"], "sample_765": ["def test_balanced_accuracy_score_binary():\n    y_true = [0, 1, 0, 0, 1, 0]\n    y_pred = [0, 1, 0, 0, 0, 1]\n\n    # Calculate balanced accuracy manually\n    recall_0 = 3 / 4\n    recall_1 = 1 / 2\n    balanced_accuracy_manual = (recall_0 + recall_1) / 2\n\n    # Calculate balanced accuracy using the function\n    balanced_accuracy_function = balanced_accuracy_score(y_true, y_pred)\n\n    assert_almost_equal(balanced_accuracy_manual, balanced_accuracy_function)\n"], "sample_767": ["def test_column_transformer_get_feature_names_with_remainder():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    ct = ColumnTransformer([('trans1', StandardScaler(), [0])],\n                           remainder=StandardScaler())\n    ct.fit(X_array)\n    assert_equal(ct.get_feature_names(), ['trans1__x0', 'remainder__x1'])\n"], "sample_768": ["def test_validate_shuffle_split():\n    # Test _validate_shuffle_split function\n    n_samples = 10\n    test_size = 0.2\n    train_size = 0.8\n\n    # Check that the sum of train_size and test_size is equal to 1\n    assert_raises(ValueError, _validate_shuffle_split, n_samples,\n                  test_size=0.6, train_size=0.6)\n\n    # Check that test_size and train_size are not negative\n    assert_raises(ValueError, _validate_shuffle_split, n_samples,\n                  test_size=-0.2, train_size=1.2)\n    assert_raises(ValueError, _validate_shuffle_split, n_samples,\n                  test_size=1.2, train_size=-0.2)\n\n    # Check that test_size and train_size are not greater than n_samples\n    assert_raises(ValueError, _validate_shuffle_split, n_samples,\n                  test_size=n_samples + 1, train_size=None)\n    assert_raises(ValueError, _validate_shuffle_split, n_samples,\n                  test_size=None, train_size=n_samples + 1)\n\n    # Check that test_size and train_size are not less than n_splits\n    n_splits = 5\n    assert_raises(ValueError, _validate_shuffle_split, n_samples,\n                  test_size=n_splits - 1, train_size=None)\n    assert_raises(ValueError, _validate_shuffle_split, n_samples,\n                  test_size=None, train_size=n_splits - 1)\n\n    # Check that test_size and train_size are valid when they are floats\n    test_size_float, train_size_float = _validate_shuffle_split(\n        n_samples, test_size=test_size, train_size=train_size)\n    assert_almost_equal(test_size_float + train_size_float, 1)\n\n    # Check that test_size and train_size are valid when they are integers\n    test_size_int, train_size_int = _validate_shuffle_split(\n        n_samples, test_size=int(n_samples * test_size),\n        train_size=int(n_samples * train_size))\n    assert_equal(test_size_int + train_size_int, n_samples)\n"], "sample_769": ["def test_balanced_accuracy_score_binary():\n    y_true = [0, 1, 0, 0, 1, 0]\n    y_pred = [0, 1, 0, 0, 0, 1]\n    assert balanced_accuracy_score(y_true, y_pred) == recall_score(y_true, y_pred, average='binary')\n"], "sample_771": ["def test_power_transformer_sparse_input():\n    # Test that PowerTransformer supports sparse input\n    X_sparse = sparse.csr_matrix(X_2d)\n    pt = PowerTransformer(method='yeo-johnson')\n    X_trans_sparse = pt.fit_transform(X_sparse)\n    X_trans_dense = pt.fit_transform(X_2d)\n    assert_array_almost_equal(X_trans_sparse.toarray(), X_trans_dense)\n"], "sample_775": ["def test_indent_at_name():\n    # Test the indent_at_name parameter of _EstimatorPrettyPrinter\n\n    pp = _EstimatorPrettyPrinter(indent=1, width=80, depth=None, stream=None,\n                                 compact=False, indent_at_name=True)\n\n    lr = LogisticRegression()\n    expected = \"\"\""], "sample_779": ["def test_check_estimator_sparse_data():\n    # check that estimator can handle sparse data correctly\n\n    class SparseEstimator(BaseEstimator):\n            X, y = check_X_y(X, y, accept_sparse=True)\n            return self\n\n            X = check_array(X, accept_sparse=True)\n            return np.ones(X.shape[0])\n\n    check_estimator(SparseEstimator())\n"], "sample_782": ["def test_column_transformer_get_feature_names_with_remainder():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    ct = ColumnTransformer([('trans1', StandardScaler(), [0])],\n                           remainder=StandardScaler())\n    ct.fit(X_array)\n    assert_equal(ct.get_feature_names(), ['trans1__x0', 'remainder__x1'])\n"], "sample_785": ["def test_validate_shuffle_split_init():\n    # Test if _validate_shuffle_split_init raises errors for invalid inputs\n    assert_raises(ValueError, _validate_shuffle_split_init, None, None)\n    assert_raises(ValueError, _validate_shuffle_split_init, 0.5, 0.6)\n    assert_raises(ValueError, _validate_shuffle_split_init, 8, 6)\n    assert_raises(TypeError, _validate_shuffle_split_init, 'test', 0.2)\n    assert_raises(ValueError, _validate_shuffle_split_init, 0.1, -0.1)\n    assert_raises(ValueError, _validate_shuffle_split_init, 0.1, 1.1)\n    assert_raises(ValueError, _validate_shuffle_split_init, -0.1, 0.1)\n    assert_raises(ValueError, _validate_shuffle_split_init, 1.1, 0.1)\n"], "sample_787": ["def test_balanced_accuracy_score_binary():\n    y_true = [0, 1, 0, 0, 1, 0]\n    y_pred = [0, 1, 0, 0, 0, 1]\n\n    # Calculate balanced accuracy manually\n    conf_mat = confusion_matrix(y_true, y_pred)\n    recall_0 = conf_mat[0, 0] / (conf_mat[0, 0] + conf_mat[0, 1])\n    recall_1 = conf_mat[1, 1] / (conf_mat[1, 0] + conf_mat[1, 1])\n    balanced_acc_manual = (recall_0 + recall_1) / 2\n\n    # Calculate using the function\n    balanced_acc_func = balanced_accuracy_score(y_true, y_pred)\n\n    assert_almost_equal(balanced_acc_manual, balanced_acc_func)\n"], "sample_792": ["def test_complementnb_alpha_vector():\n    X = np.array([[1, 0], [1, 1]])\n    y = np.array([0, 1])\n\n    # Setting alpha=np.array with same length\n    # as number of features should be fine\n    alpha = np.array([1, 2])\n    nb = ComplementNB(alpha=alpha)\n    nb.partial_fit(X, y, classes=[0, 1])\n\n    # Test feature probabilities uses pseudo-counts (alpha)\n    theta = np.array([\n        [(0 + 1) / (1 + 4), (1 + 2) / (1 + 4)],\n        [(1 + 1) / (2 + 4), (0 + 2) / (2 + 4)]\n    ])\n    weights = -np.log(theta)\n    assert_array_almost_equal(nb.feature_log_prob_, weights)\n\n    # Test predictions\n    prob = np.exp(-weights.sum(axis=1))\n    prob /= prob.sum()\n    assert_array_almost_equal(nb.predict_proba(X), [prob, prob])\n\n    # Test alpha non-negative\n    alpha = np.array([1., -0.1])\n    expected_msg = ('Smoothing parameter alpha = -1.0e-01. '\n                    'alpha should be > 0.')\n    m_nb = ComplementNB(alpha=alpha)\n    assert_raise_message(ValueError, expected_msg, m_nb.fit, X, y)\n\n    # Test that too small pseudo-counts are replaced\n    ALPHA_MIN = 1e-10\n    alpha = np.array([ALPHA_MIN / 2, 0.5])\n    m_nb = ComplementNB(alpha=alpha)\n    m_nb.partial_fit(X, y, classes=[0, 1])\n    assert_array_almost_equal(m_nb._check_alpha(),\n                              [ALPHA_MIN, 0.5],\n                              decimal=12)\n\n    # Test correct dimensions\n    alpha = np.array([1., 2., 3.])\n    m_nb = ComplementNB(alpha=alpha)\n    expected_msg = ('alpha should be a scalar or a numpy array '\n                    'with shape [n_features]')\n    assert_raise_message(ValueError, expected_msg, m_nb.fit, X, y)\n"], "sample_797": ["def test_power_transformer_sparse_input():\n    # check that PowerTransformer supports sparse input\n    X_sparse = sparse.csr_matrix(X_2d)\n    pt = PowerTransformer(method='yeo-johnson')\n    X_trans_sparse = pt.fit_transform(X_sparse)\n    X_trans_dense = pt.fit_transform(X_2d)\n    assert_array_almost_equal(X_trans_sparse.toarray(), X_trans_dense)\n"], "sample_799": ["def test_cross_val_score_with_fit_params():\n    X, y = make_classification(n_samples=30, random_state=0)\n    clf = SVC(kernel=\"linear\", random_state=0)\n\n    # Test that fit_params are correctly passed to the estimator\n    scores = cross_val_score(clf, X, y, cv=5, fit_params={'C': 1.0})\n    assert len(scores) == 5\n\n    # Test that fit_params are correctly updated if already present in estimator\n    clf.set_params(C=2.0)\n    scores = cross_val_score(clf, X, y, cv=5, fit_params={'C': 1.0})\n    assert len(scores) == 5\n"], "sample_800": ["def test_check_estimator_with_tags():\n    # check that estimator tags are taken into account in check_estimator\n\n    class MyEstimator(BaseEstimator):\n            return self\n\n            return np.ones(X.shape[0])\n\n            return {'binary_only': True}\n\n    # should not raise an error\n    check_estimator(MyEstimator())\n\n    class MyEstimator2(BaseEstimator):\n            return self\n\n            return np.ones(X.shape[0])\n\n            return {'multioutput_only': True}\n\n    # should raise an error because multioutput_only is not supported\n    msg = \"Estimator MyEstimator2 should not set any attribute apart from\"\n    assert_raises_regex(AssertionError, msg, check_estimator, MyEstimator2())\n"], "sample_801": ["def test_clone():\n    # Test that clone raises an error on estimators that don't implement get_params\n    class DummyEstimator:\n            pass\n\n    assert_raises(TypeError, clone, DummyEstimator())\n\n    # Test that clone works with estimators that implement get_params\n    lr = LogisticRegression()\n    lr_cloned = clone(lr)\n    assert isinstance(lr_cloned, LogisticRegression)\n\n    # Test that clone raises an error when the estimator doesn't have a __class__\n    # attribute (e.g. it's a function)\n        pass\n\n    assert_raises(TypeError, clone, dummy_estimator)\n\n    # Test that clone works with pipelines\n    pipeline = make_pipeline(StandardScaler(), LogisticRegression())\n    pipeline_cloned = clone(pipeline)\n    assert isinstance(pipeline_cloned, Pipeline)\n    assert isinstance(pipeline_cloned.steps[0][1], StandardScaler)\n    assert isinstance(pipeline_cloned.steps[1][1], LogisticRegression)\n"], "sample_811": ["def test_pairwise_distances_chunked_reduce_callable():\n    # Test that the reduce_func can be a callable in pairwise_distances_chunked\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((400, 4))\n    Y = rng.random_sample((200, 4))\n\n        return D_chunk.sum(axis=1)\n\n    gen = pairwise_distances_chunked(X, Y, reduce_func=reduce_func,\n                                     working_memory=1)\n    assert isinstance(gen, GeneratorType)\n    sums = list(gen)\n    assert len(sums) > 1\n\n    # Check that the sums are correct\n    D = pairwise_distances(X, Y)\n    sums_expected = D.sum(axis=1)\n    assert_array_almost_equal(np.concatenate(sums), sums_expected)\n"], "sample_814": ["def test_gbr_degenerate_oob_improvement():\n    # Test if oob_improvement_ is calculated correctly when all trees have only\n    # one node (i.e. they are stumps). See #13620\n    X = np.zeros((10, 10))\n    y = np.ones((10,))\n    gbr = GradientBoostingRegressor(subsample=0.5).fit(X, y)\n    assert_array_equal(gbr.oob_improvement_, np.zeros(gbr.n_estimators))\n"], "sample_818": ["def test_spectral_clustering_with_n_init():\n    # Test that spectral_clustering works with different n_init values\n    X, y = make_blobs(n_samples=20, random_state=0,\n                      centers=[[1, 1], [-1, -1]], cluster_std=0.01)\n    sp = SpectralClustering(n_clusters=2, n_init=5, random_state=0)\n    labels = sp.fit(X).labels_\n    assert adjusted_rand_score(y, labels) == 1\n\n    sp = SpectralClustering(n_clusters=2, n_init=10, random_state=0)\n    labels = sp.fit(X).labels_\n    assert adjusted_rand_score(y, labels) == 1\n\n    # Test that n_init affects result when random_state is not set\n    sp = SpectralClustering(n_clusters=2, n_init=5)\n    labels_5 = sp.fit(X).labels_\n    sp = SpectralClustering(n_clusters=2, n_init=10)\n    labels_10 = sp.fit(X).labels_\n    assert not np.array_equal(labels_5, labels_10)\n"], "sample_822": ["def test_pairwise_distances_chunked_reduce_callable():\n    # Test that the reduce_func can be a callable in pairwise_distances_chunked\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((400, 4))\n    Y = rng.random_sample((200, 4))\n\n        return D_chunk.sum(axis=1)\n\n    gen = pairwise_distances_chunked(X, Y, reduce_func=reduce_func,\n                                     working_memory=1)\n    assert isinstance(gen, GeneratorType)\n    sums = list(gen)\n    assert len(sums) > 1\n\n    # Check that the sums are correct\n    D = pairwise_distances(X, Y)\n    sums2 = D.sum(axis=1)\n    assert_array_almost_equal(np.concatenate(sums), sums2)\n"], "sample_823": ["def test_pairwise_distances_chunked_reduce_func():\n    # Test that the reduce_func is applied correctly in pairwise_distances_chunked\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((400, 4))\n    Y = rng.random_sample((200, 4))\n\n        return D_chunk.sum(axis=1)\n\n    gen = pairwise_distances_chunked(X, Y, reduce_func=reduce_func,\n                                     working_memory=2 ** -16)\n    assert isinstance(gen, GeneratorType)\n    sums = list(gen)\n    assert len(sums) > 1\n\n    expected_sums = pairwise_distances(X, Y).sum(axis=1)\n    assert_allclose(np.concatenate(sums), expected_sums)\n"], "sample_824": ["def test_pairwise_distances_argmin_min_axis():\n    # Check pairwise minimum distances computation for any metric along axis=0\n    X = [[0], [1]]\n    Y = [[-2], [3]]\n\n    expected_idx = [0, 1]\n    expected_vals = [2, 2]\n\n    idx, vals = pairwise_distances_argmin_min(X, Y, axis=0, metric=\"euclidean\")\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(vals, expected_vals)\n\n    # Test with sparse matrix\n    Xsp = csr_matrix(X)\n    Ysp = csr_matrix(Y)\n    idxsp, valssp = pairwise_distances_argmin_min(Xsp, Ysp, axis=0,\n                                                  metric=\"euclidean\")\n    assert_array_almost_equal(idxsp, expected_idx)\n    assert_array_almost_equal(valssp, expected_vals)\n"], "sample_828": ["def test_pairwise_distances_chunked_reduce_callable():\n    # Test that pairwise_distances_chunked works with a callable reduce_func\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((400, 4))\n        return D.sum(axis=1)\n    S_chunks = pairwise_distances_chunked(X, None, reduce_func=reduce_func,\n                                          working_memory=2 ** -16)\n    assert isinstance(S_chunks, GeneratorType)\n    S_chunks = list(S_chunks)\n    assert len(S_chunks) > 1\n    S = np.vstack(S_chunks)\n    expected_S = pairwise_distances(X).sum(axis=1)\n    assert_allclose(S, expected_S)\n"], "sample_838": ["def test_column_transformer_get_feature_names_with_remainder():\n    X_array = np.array([[0., 1., 2.], [2., 4., 6.]]).T\n    ct = ColumnTransformer([('trans1', StandardScaler(), [0])],\n                           remainder=StandardScaler())\n\n    ct.fit(X_array)\n    feature_names = ct.get_feature_names()\n    assert feature_names == ['trans1__x0', 'remainder__x1', 'remainder__x2']\n"], "sample_844": ["def test_optics_fit_predict():\n    # Test that fit_predict works and gives the same result as fit + predict\n    rng = np.random.RandomState(0)\n    n_points_per_cluster = 20\n    C1 = [-5, -2] + .2 * rng.randn(n_points_per_cluster, 2)\n    C2 = [4, -1] + .2 * rng.randn(n_points_per_cluster, 2)\n    C3 = [1, 2] + .2 * rng.randn(n_points_per_cluster, 2)\n    C4 = [-2, 3] + .2 * rng.randn(n_points_per_cluster, 2)\n    X = np.vstack((C1, C2, C3, C4))\n\n    clust1 = OPTICS(cluster_method='dbscan', eps=.5).fit(X)\n    labels1 = clust1.labels_\n\n    clust2 = OPTICS(cluster_method='dbscan', eps=.5)\n    labels2 = clust2.fit_predict(X)\n\n    assert_array_equal(labels1, labels2)\n"], "sample_846": ["def test_column_transformer_get_feature_names_with_remainder():\n    X_array = np.array([[0., 1., 2.], [2., 4., 6.]]).T\n    ct = ColumnTransformer([('trans', Trans(), [0])],\n                           remainder=StandardScaler())\n    ct.fit(X_array)\n    assert ct.get_feature_names() == ['trans__x0', 'remainder__x1']\n"], "sample_849": ["def test_validate_shuffle_split():\n    # Test the _validate_shuffle_split function\n    n_samples = 10\n\n    # Test with test_size and train_size as int\n    test_size, train_size = 3, 7\n    test_size_out, train_size_out = _validate_shuffle_split(\n        n_samples, test_size, train_size)\n    assert test_size_out == test_size\n    assert train_size_out == train_size\n\n    # Test with test_size and train_size as float\n    test_size, train_size = 0.3, 0.7\n    test_size_out, train_size_out = _validate_shuffle_split(\n        n_samples, test_size, train_size)\n    assert test_size_out == int(test_size * n_samples)\n    assert train_size_out == int(train_size * n_samples)\n\n    # Test with test_size and default train_size\n    test_size, train_size = 3, None\n    test_size_out, train_size_out = _validate_shuffle_split(\n        n_samples, test_size, train_size)\n    assert test_size_out == test_size\n    assert train_size_out == n_samples - test_size\n\n    # Test with default test_size and train_size\n    test_size, train_size = None, 7\n    test_size_out, train_size_out = _validate_shuffle_split(\n        n_samples, test_size, train_size)\n    assert test_size_out == n_samples - train_size\n    assert train_size_out == train_size\n\n    # Test with both test_size and train_size being None\n    test_size, train_size = None, None\n    test_size_out, train_size_out = _validate_shuffle_split(\n        n_samples, test_size, train_size, default_test_size=0.25)\n    assert test_size_out == int(0.25 * n_samples)\n    assert train_size_out == n_samples - test_size_out\n\n    # Test with invalid input\n    test_size, train_size = 11, None\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size, train_size)\n\n    test_size, train_size = 0.11, 0.9\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size, train_size)\n"], "sample_852": ["def test_make_gaussian_quantiles():\n    X, y = make_gaussian_quantiles(mean=None, cov=1., n_samples=100,\n                                   n_features=2, n_classes=3, shuffle=True,\n                                   random_state=0)\n\n    assert X.shape == (100, 2), \"X shape mismatch\"\n    assert y.shape == (100,), \"y shape mismatch\"\n    assert np.unique(y).shape == (3,), \"Unexpected number of classes\"\n\n    # Test that clusters are on the vertices of a regular tetrahedron\n    # (up to rotation) for n_classes=4 and n_features=3.\n    X, y = make_gaussian_quantiles(n_samples=100, n_features=3, n_classes=4,\n                                   random_state=0)\n    means = [X[y == i].mean(axis=0) for i in range(4)]\n    dists = set()\n    for i in range(4):\n        for j in range(i + 1, 4):\n            dists.add(np.linalg.norm(means[i] - means[j]))\n    assert len(dists) == 1, \"Means are not on a regular tetrahedron\"\n"], "sample_856": ["def test_validate_shuffle_split():\n    # Test _validate_shuffle_split function\n    n_samples = 10\n\n    # Test when test_size is an integer\n    test_size = 3\n    train_size, test_size = _validate_shuffle_split(n_samples, test_size)\n    assert train_size == 7\n    assert test_size == 3\n\n    # Test when test_size is a float\n    test_size = 0.3\n    train_size, test_size = _validate_shuffle_split(n_samples, test_size)\n    assert train_size == 7\n    assert test_size == 3\n\n    # Test when train_size is an integer\n    train_size = 7\n    train_size, test_size = _validate_shuffle_split(n_samples, None, train_size)\n    assert train_size == 7\n    assert test_size == 3\n\n    # Test when train_size is a float\n    train_size = 0.7\n    train_size, test_size = _validate_shuffle_split(n_samples, None, train_size)\n    assert train_size == 7\n    assert test_size == 3\n\n    # Test when both test_size and train_size are specified\n    test_size = 3\n    train_size = 5\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size, train_size)\n\n    # Test when neither test_size nor train_size is specified\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples)\n"], "sample_859": ["def test_enet_coordinate_descent_sparse_float_precision():\n    # Generate dataset\n    X, y, X_test, y_test = build_dataset(n_samples=20, n_features=10)\n    # Here we have a small number of iterations, and thus the\n    # ElasticNet might not converge. This is to speed up tests\n\n    for normalize in [True, False]:\n        for fit_intercept in [True, False]:\n            coef = {}\n            intercept = {}\n            for dtype in [np.float64, np.float32]:\n                clf = ElasticNet(alpha=0.5, max_iter=100, precompute=False,\n                                 fit_intercept=fit_intercept,\n                                 normalize=normalize)\n\n                X_sparse = sparse.csr_matrix(X).astype(dtype)\n                y = dtype(y)\n                ignore_warnings(clf.fit)(X_sparse, y)\n\n                coef[('simple', dtype)] = clf.coef_\n                intercept[('simple', dtype)] = clf.intercept_\n\n                assert clf.coef_.dtype == dtype\n\n            for v in ['simple']:\n                assert_array_almost_equal(coef[(v, np.float32)],\n                                          coef[(v, np.float64)],\n                                          decimal=4)\n                assert_array_almost_equal(intercept[(v, np.float32)],\n                                          intercept[(v, np.float64)],\n                                          decimal=4)\n"], "sample_860": ["def test_check_array_dtype_object_conversion_with_nans():\n    # test that data-frame like objects with dtype object and NaN values\n    # get converted correctly\n    X = np.array([[1, 2, np.nan], [4, 5, 6]], dtype=np.object)\n    X_df = MockDataFrame(X)\n    assert check_array(X_df).dtype.kind == \"f\"\n    assert check_array(X_df, ensure_2d=False).dtype.kind == \"f\"\n"], "sample_863": ["def test_pipeline_get_params():\n    # Test that get_params returns all parameters of the estimators\n    # in the pipeline.\n    clf = LogisticRegression()\n    filter1 = SelectKBest(f_classif)\n    pipe = Pipeline([('anova', filter1), ('logistic', clf)])\n\n    params = pipe.get_params(deep=True)\n    assert 'anova__k' in params\n    assert 'logistic__C' in params\n"], "sample_868": ["def test_empty_input(metric_name, metric_func):\n    # Test that all supervised metrics handle empty input correctly\n    assert metric_func([], []) == 1.0\n    with pytest.raises(ValueError, match='labels_true and labels_pred must have'):\n        metric_func([0], [])\n    with pytest.raises(ValueError, match='labels_true and labels_pred must have'):\n        metric_func([], [0])\n"], "sample_869": ["def test_balanced_accuracy_score_single_class():\n    y_true = [1, 1, 1, 1]\n    y_pred = [1, 1, 1, 1]\n    with pytest.raises(ValueError):\n        balanced_accuracy_score(y_true, y_pred)\n"], "sample_874": ["def test_clone():\n    sel = StepSelector(step=3)\n    clone_sel = sel.__sklearn_clone__()\n    assert clone_sel.step == 3\n\n    # Check if clone is independent of original\n    clone_sel.step = 5\n    assert sel.step == 3\n\n    # Check if clone raises an error when estimator has no get_params method\n    class NoGetParamsEstimator:\n            pass\n\n    with pytest.raises(TypeError):\n        clone(NoGetParamsEstimator())\n"], "sample_878": ["def test_column_transformer_get_feature_names_out_with_callable():\n    \"\"\"Check get_feature_names_out when using a callable as column selector.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X_df = pd.DataFrame(\n        {\n            \"col_int\": np.array([0, 1, 2], dtype=int),\n            \"col_float\": np.array([0.0, 1.0, 2.0], dtype=float),\n            \"col_str\": [\"one\", \"two\", \"three\"],\n        },\n        columns=[\"col_int\", \"col_float\", \"col_str\"],\n    )\n\n        return [\"col_int\", \"col_float\"]\n\n    ct = ColumnTransformer([(\"trans\", TransWithNames(), selector)], remainder=\"drop\")\n    ct.fit(X_df)\n\n    names = ct.get_feature_names_out()\n    assert isinstance(names, np.ndarray)\n    assert names.dtype == object\n    assert_array_equal(names, [\"trans__col_int\", \"trans__col_float\"])\n"], "sample_880": ["def test_type_of_target_mixed_types():\n    # Test that type_of_target correctly handles mixed types in a list\n    y = [1, 'a', 2.0, 'b']\n    with pytest.raises(ValueError):\n        type_of_target(y)\n\n    y = np.array([1, 'a', 2.0, 'b'], dtype=object)\n    with pytest.raises(ValueError):\n        type_of_target(y)\n"], "sample_885": ["def test_interval_real_not_int_edge_cases():\n    \"\"\"Check edge cases for the type \"real_not_int\" in the Interval constraint.\"\"\"\n    constraint = Interval(\"real_not_int\", 0, 1, closed=\"both\")\n    assert not constraint.is_satisfied_by(-1)\n    assert not constraint.is_satisfied_by(2)\n    assert constraint.is_satisfied_by(0.0)\n    assert constraint.is_satisfied_by(1.0)\n    assert not constraint.is_satisfied_by(np.inf)\n    assert not constraint.is_satisfied_by(-np.inf)\n    assert not constraint.is_satisfied_by(np.nan)\n"], "sample_891": ["def test_roc_auc_score_average_parameter():\n    # Test that roc_auc_score function returns an error when the 'average'\n    # parameter is not one of the allowed values.\n    rng = check_random_state(404)\n    y_score = rng.rand(20, 3)\n    y_prob = softmax(y_score)\n    y_true = rng.randint(0, 3, size=20)\n\n    with pytest.raises(ValueError):\n        roc_auc_score(y_true, y_prob, average=\"invalid\")\n"], "sample_895": ["def test_column_transformer_feature_names_out_with_callable():\n    \"\"\"Check feature names out when using callable in ColumnTransformer.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\n\n        return [\"A\"]\n\n    ct = ColumnTransformer([(\"selector\", TransWithNames(), selector)], remainder=\"drop\")\n    ct.fit(df)\n    assert_array_equal(ct.get_feature_names_out(), [\"selector__A\"])\n"], "sample_896": ["def test_nmf_minibatchnmf_equivalence_with_regularization():\n    # Test that MiniBatchNMF is equivalent to NMF when batch_size = n_samples and\n    # forget_factor 0.0 (stopping criterion put aside) with regularization\n    rng = np.random.mtrand.RandomState(42)\n    X = np.abs(rng.randn(48, 5))\n\n    nmf = NMF(\n        n_components=5,\n        beta_loss=1,\n        solver=\"mu\",\n        random_state=0,\n        tol=0,\n        alpha_W=0.5,\n        alpha_H=0.5,\n        l1_ratio=0.5,\n    )\n    mbnmf = MiniBatchNMF(\n        n_components=5,\n        beta_loss=1,\n        random_state=0,\n        tol=0,\n        max_no_improvement=None,\n        batch_size=X.shape[0],\n        forget_factor=0.0,\n        alpha_W=0.5,\n        alpha_H=0.5,\n        l1_ratio=0.5,\n    )\n    W = nmf.fit_transform(X)\n    mbW = mbnmf.fit_transform(X)\n    assert_allclose(W, mbW)\n"], "sample_897": ["def test_partial_dependence_display_with_sample_weight(pyplot, clf_diabetes, diabetes):\n    \"\"\"Check that the utilization of a sample weight impacts the results.\"\"\"\n    sample_weight = np.random.rand(len(diabetes.target))\n    disp_sw = PartialDependenceDisplay.from_estimator(\n        clf_diabetes,\n        diabetes.data,\n        [0, 1],\n        sample_weight=sample_weight,\n        kind=\"average\",\n        method=\"brute\",\n    )\n\n    disp_no_sw = PartialDependenceDisplay.from_estimator(\n        clf_diabetes,\n        diabetes.data,\n        [0, 1],\n        kind=\"average\",\n        method=\"brute\",\n    )\n\n    assert not np.array_equal(\n        disp_sw.pd_results[0][\"average\"], disp_no_sw.pd_results[0][\"average\"]\n    )\n"], "sample_899": ["def test_check_estimator_sparse_data():\n    # check that estimator can handle sparse data correctly\n\n    class SparseEstimator(BaseEstimator):\n            X = check_array(X, accept_sparse='csr')\n            return self\n\n            X = check_array(X, accept_sparse='csr')\n            return np.ones(X.shape[0])\n\n    check_estimator(SparseEstimator())\n"], "sample_903": ["def test_tsne_with_sparse_input():\n    \"\"\"Make sure that TSNE works with sparse input\"\"\"\n    random_state = check_random_state(0)\n    n_components_original = 3\n    n_components_embedding = 2\n    X = random_state.randn(50, n_components_original).astype(np.float32)\n    X_sparse = sp.csr_matrix(X)\n\n    tsne = TSNE(n_components=n_components_embedding, random_state=0,\n                method='exact')\n    X_transformed_tsne = tsne.fit_transform(X)\n    X_transformed_tsne_sparse = tsne.fit_transform(X_sparse)\n\n    assert_array_almost_equal(X_transformed_tsne, X_transformed_tsne_sparse,\n                              decimal=3)\n"], "sample_905": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n    @singledispatch\n        return arg\n\n    assert inspect.is_singledispatch_function(fun) is True\n\n        return arg\n\n    assert inspect.is_singledispatch_function(normal_fun) is False\n\n"], "sample_910": ["def test_log_collector(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    collector = logging.LogCollector()\n    with collector.collect():\n        logger.info('message1')\n        logger.warning('message2')\n\n    assert len(collector.logs) == 2\n    assert collector.logs[0].getMessage() == 'message1'\n    assert collector.logs[1].getMessage() == 'WARNING: message2'\n"], "sample_915": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n    @singledispatch\n        return arg\n\n    assert inspect.is_singledispatch_function(fun) is True\n\n        return arg\n\n    assert inspect.is_singledispatch_function(normal_fun) is False\n\n"], "sample_921": ["def test_getargspec():\n        pass\n\n    argspec = inspect.getargspec(func)\n    assert argspec.args == ['a', 'b', 'c', 'd']\n    assert argspec.varargs == 'e'\n    assert argspec.varkw == 'f'\n    assert argspec.defaults == (1, 2)\n\n    # Test with a bound method\n    class Foo:\n            pass\n\n    argspec = inspect.getargspec(Foo().meth)\n    assert argspec.args == ['a', 'b', 'c', 'd']\n    assert argspec.varargs == 'e'\n    assert argspec.varkw == 'f'\n    assert argspec.defaults == (1, 2)\n"], "sample_922": ["def test_pyattribute_with_type_annotation(app):\n    text = (\".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:attribute:: attr\\n\"\n            \"      :type: str\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_name, \"Class\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc)])]))\n    assert_node(doctree[1][1][0], addnodes.index,\n                entries=[('single', 'attr (Class attribute)', 'Class.attr', '', None)])\n    assert_node(doctree[1][1][1], ([desc_signature, ([desc_name, \"attr\"],\n                                                     [desc_annotation, (\": \",\n                                                                        [pending_xref, \"str\"])])],\n                                   [desc_content, ()]))\n    assert 'Class.attr' in domain.objects\n    assert domain.objects['Class.attr'] == ('index', 'Class.attr', 'attribute')\n"], "sample_923": ["def test_lookup_key():\n    root = Symbol(None, None, None, None)\n    s1 = root.add_name(ASTNestedName([ASTIdentifier(\"S1\")], rooted=False))\n    s2 = s1.add_name(ASTNestedName([ASTIdentifier(\"S2\")], rooted=False))\n    s3 = s2.add_name(ASTNestedName([ASTIdentifier(\"S3\")], rooted=False))\n\n    key = s3.get_lookup_key()\n    assert len(key.data) == 3\n\n    s4 = root.direct_lookup(key)\n    assert s4 is s3\n"], "sample_939": ["def test_unparse_arguments(source, expected):\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].args, source) == expected\n"], "sample_940": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n    @singledispatch\n        return arg\n\n    assert inspect.is_singledispatch_function(fun) is True\n\n        return arg\n\n    assert inspect.is_singledispatch_function(normal_fun) is False\n\n"], "sample_942": ["def test_get_full_qualified_name_for_module(app):\n    env = Mock(domaindata={})\n    domain = PythonDomain(env)\n\n    node = nodes.reference(reftarget='module1')\n    assert domain.get_full_qualified_name(node) == 'module1'\n\n    node = nodes.reference(reftarget='module1', **{'py:module': 'module2'})\n    assert domain.get_full_qualified_name(node) == 'module2.module1'\n"], "sample_945": ["def test_pyattribute_with_union_type_operator(app):\n    text = (\".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:attribute:: attr\\n\"\n            \"      :type: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][1][0], addnodes.index,\n                entries=[('single', 'attr (Class attribute)', 'Class.attr', '', None)])\n    assert_node(doctree[1][1][1], ([desc_signature, ([desc_name, \"attr\"],\n                                                     [desc_annotation, (\": \",\n                                                                        [pending_xref, \"int\"],\n                                                                        \" \",\n                                                                        [desc_sig_punctuation, \"|\"],\n                                                                        \" \",\n                                                                        [pending_xref, \"str\"])]),\n                                   [desc_content, ()]))\n    assert_node(doctree[1][1][1][0][1][1], pending_xref, **{\"py:class\": \"Class\"})\n    assert_node(doctree[1][1][1][0][1][3], pending_xref, **{\"py:class\": \"Class\"})\n    assert 'Class.attr' in app.env.domains['py'].objects\n    assert app.env.domains['py'].objects['Class.attr'] == ('index', 'Class.attr', 'attribute', False)\n"], "sample_946": ["def test_get_full_qualified_name_for_module():\n    env = Mock(domaindata={})\n    domain = PythonDomain(env)\n\n    node = nodes.reference(reftarget='module1')\n    assert domain.get_full_qualified_name(node) == 'module1'\n\n    node = nodes.reference(reftarget='module1', **{'py:module': 'module2'})\n    assert domain.get_full_qualified_name(node) == 'module2.module1'\n"], "sample_947": ["def test_cdomain_add_declarations():\n    # Test that adding multiple declarations in the same directive works.\n    env = BuildEnvironment()\n    domain = CDomain(env)\n    rootSymbol = Symbol(None, None, None, None, None)\n    env.temp_data['c:parent_symbol'] = rootSymbol\n\n    parser = DefinitionParser(\"int a; int b\", location=None, config=env.config)\n    ast1 = parser.parse_declaration('member', 'member')\n    parser.assert_end()\n    parser = DefinitionParser(\"void f()\", location=None, config=env.config)\n    ast2 = parser.parse_declaration('function', 'function')\n    parser.assert_end()\n\n    symbol1 = rootSymbol.add_declaration(ast1, docname=\"TestDoc\", line=42)\n    symbol2 = rootSymbol.add_declaration(ast2, docname=\"TestDoc\", line=43)\n\n    assert symbol1.declaration == ast1\n    assert symbol2.declaration == ast2\n    assert symbol1.siblingBelow == symbol2\n    assert symbol2.siblingAbove == symbol1\n"], "sample_950": ["def test_pyattribute_with_union_type_operator(app):\n    text = (\".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:attribute:: attr\\n\"\n            \"      :type: int | str\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_name, \"Class\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc)])]))\n    assert_node(doctree[1][1][0], addnodes.index,\n                entries=[('single', 'attr (Class attribute)', 'Class.attr', '', None)])\n    assert_node(doctree[1][1][1], ([desc_signature, ([desc_name, \"attr\"],\n                                                     [desc_annotation, (\": \",\n                                                                        [pending_xref, \"int\"],\n                                                                        \" \",\n                                                                        [desc_sig_punctuation, \"|\"],\n                                                                        \" \",\n                                                                        [pending_xref, \"str\"])]),\n                                   [desc_content, ()]))\n    assert_node(doctree[1][1][1][0][1][1], pending_xref, **{\"py:class\": \"Class\"})\n    assert_node(doctree[1][1][1][0][1][3], pending_xref, **{\"py:class\": \"Class\"})\n    assert 'Class.attr' in domain.objects\n    assert domain.objects['Class.attr'] == ('index', 'Class.attr', 'attribute', False)\n"], "sample_951": ["def test_getmro():\n    class A:\n        pass\n\n    class B(A):\n        pass\n\n    class C(B):\n        pass\n\n    assert inspect.getmro(C) == (C, B, A, object)\n\n    # Test with a class that doesn't have an __mro__ attribute\n    class D:\n        __mro__ = None\n\n    assert inspect.getmro(D) == tuple()\n\n    # Test with a non-class object\n    assert inspect.getmro(object()) == tuple()\n"], "sample_952": ["def test_getmro():\n    class A:\n        pass\n\n    class B(A):\n        pass\n\n    class C(B):\n        pass\n\n    assert inspect.getmro(C) == (C, B, A, object)\n    assert inspect.getmro(object) == (object,)\n    assert inspect.getmro(int) == (int, object)\n\n    # Test that getmro works with single inheritance\n    class D(C):\n        pass\n\n    assert inspect.getmro(D) == (D, C, B, A, object)\n\n    # Test that getmro works with multiple inheritance\n    class E(B, A):\n        pass\n\n    assert inspect.getmro(E) == (E, B, A, object)\n\n    # Test that getmro works with diamond inheritance\n    class F(D, C):\n        pass\n\n    assert inspect.getmro(F) == (F, D, C, B, A, object)\n"], "sample_961": ["def test_pyattribute_with_union_type_operator(app):\n    text = (\".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:attribute:: attr\\n\"\n            \"      :type: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][1][1],\n                ([desc_name, \"attr\"],\n                 [desc_annotation, (\": \",\n                                    [pending_xref, \"int\"],\n                                    \" \",\n                                    [desc_sig_punctuation, \"|\"],\n                                    \" \",\n                                    [pending_xref, \"str\"])]))\n"], "sample_964": ["def test_get_full_qualified_name_with_module_and_class_context():\n    env = Mock(domaindata={})\n    domain = PythonDomain(env)\n\n    node = nodes.reference(reftarget='func', py_module='module1', py_class='Class')\n    assert domain.get_full_qualified_name(node) == 'module1.Class.func'\n"], "sample_965": ["def test_getorigbases():\n    class A:\n        pass\n\n    class B(A):\n        pass\n\n    assert inspect.getorigbases(A) is None\n    assert inspect.getorigbases(B) == (A,)\n\n    # Test with __orig_bases__ attribute\n    class C(typing.Generic[int]):\n        pass\n\n    assert inspect.getorigbases(C) == (typing.Generic[int],)\n"], "sample_966": ["def test_pyattribute_with_union_type_operator(app):\n    text = (\".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:attribute:: attr\\n\"\n            \"      :type: int | str\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, (\"class\", desc_sig_space)],\n                                                    [desc_addname, \"\"],\n                                                    [desc_name, \"Class\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc)])]))\n    assert_node(doctree[1][1][0], addnodes.index,\n                entries=[('single', 'attr (Class attribute)', 'Class.attr', '', None)])\n    assert_node(doctree[1][1][1], ([desc_signature, ([desc_name, \"attr\"],\n                                                     [desc_annotation, ([desc_sig_punctuation, ':'],\n                                                                        desc_sig_space,\n                                                                        [pending_xref, \"int\"],\n                                                                        desc_sig_space,\n                                                                        [desc_sig_punctuation, '|'],\n                                                                        desc_sig_space,\n                                                                        [pending_xref, \"str\"])])],\n                                   [desc_content, ()]))\n    assert 'Class.attr' in app.env.domains['py'].objects\n    assert app.env.domains['py'].objects['Class.attr'] == ('index', 'Class.attr', 'attribute', False)\n"], "sample_970": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n    @singledispatch\n        return arg\n\n    assert inspect.is_singledispatch_function(fun) is True\n\n        return arg\n\n    assert inspect.is_singledispatch_function(not_singledispatch_fun) is False\n\n"], "sample_971": ["def test_log_collector(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    collector = logging.LogCollector()\n    with collector.collect():\n        logger.info('message1')\n        logger.warning('message2')\n\n    assert len(collector.logs) == 2\n    assert collector.logs[0].getMessage() == 'message1'\n    assert collector.logs[1].getMessage() == 'WARNING: message2'\n"], "sample_973": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n    @singledispatch\n        return arg\n\n    assert inspect.is_singledispatch_function(fun) is True\n\n        return arg\n\n    assert inspect.is_singledispatch_function(normal_func) is False\n\n"], "sample_981": ["def test_cycle_structure():\n    p = Permutation([0, 1, 2, 3])\n    assert p.cycle_structure == {1: 4}\n    p = Permutation([0, 2, 1, 3])\n    assert p.cycle_structure == {2: 1, 1: 2}\n    p = Permutation([0, 1, 3, 2])\n    assert p.cycle_structure == {2: 1, 1: 2}\n    p = Permutation([0, 3, 1, 2])\n    assert p.cycle_structure == {3: 1, 1: 1}\n"], "sample_983": ["def test_sparse_matrix_diagonal_solve():\n    A = SparseMatrix(3, 3, {(0, 0): 2, (1, 1): 3, (2, 2): 4})\n    b = SparseMatrix(3, 1, {(0, 0): 1, (1, 0): 2, (2, 0): 3})\n    x = A._diagonal_solve(b)\n    assert x == SparseMatrix(3, 1, {(0, 0): S(1)/2, (1, 0): S(2)/3, (2, 0): S(3)/4})\n"], "sample_986": ["def test_evalf_piecewise():\n    from sympy import Piecewise, sin, cos\n    x = Symbol('x')\n    f = Piecewise((sin(x), x < 0), (cos(x), x >= 0))\n    assert NS(f.subs(x, -1)) == '-0.841470984807897'\n    assert NS(f.subs(x, 1)) == '0.540302305868140'\n    assert NS(f, subs={x: -1}) == '-0.841470984807897'\n    assert NS(f, subs={x: 1}) == '0.540302305868140'\n"], "sample_987": ["def test_evalf_piecewise():\n    from sympy import Piecewise, sin, cos\n    x = Symbol('x')\n    f = Piecewise((sin(x), x < 0), (cos(x), x >= 0))\n    assert NS(f.subs(x, -1)) == '-0.841470984807897'\n    assert NS(f.subs(x, 1)) == '0.540302305868140'\n    assert NS(f, subs={x: -1}) == '-0.841470984807897'\n    assert NS(f, subs={x: 1}) == '0.540302305868140'\n"], "sample_988": ["def test_issue_14343():\n    assert Eq(x, 1).subs({x: nan}) is S.false\n    assert Eq(nan, x).subs({x: 1}) is S.false\n    assert Eq(x, nan).subs({x: 1}) is S.false\n    assert Eq(nan, nan) is S.false\n    assert Ne(x, 1).subs({x: nan}) is S.true\n    assert Ne(nan, x).subs({x: 1}) is S.true\n    assert Ne(x, nan).subs({x: 1}) is S.true\n    assert Ne(nan, nan) is S.true\n"], "sample_989": ["def test_mod_inverse_with_Rational():\n    assert mod_inverse(Rational(3, 5), 11) == 4\n    assert mod_inverse(Rational(2, 7), 13) == 6\n    assert mod_inverse(Rational(1, 9), 17) == 2\n"], "sample_990": ["def test_hyperbolic_is_real():\n    x = Symbol('x', real=True)\n    assert sinh(x).is_real is True\n    assert cosh(x).is_real is True\n    assert tanh(x).is_real is True\n    assert coth(x).is_real is True\n    assert sech(x).is_real is True\n    assert csch(x).is_real is True\n\n    y = Symbol('y')\n    assert sinh(y).is_real is None\n    assert cosh(y).is_real is None\n    assert tanh(y).is_real is None\n    assert coth(y).is_real is None\n    assert sech(y).is_real is None\n    assert csch(y).is_real is None\n"], "sample_997": ["def test_function_exponentiation():\n    transformations = standard_transformations + (function_exponentiation,)\n    x = Symbol('x')\n    assert parse_expr('sin**2(x)', transformations=transformations) == sin(x)**2\n    assert parse_expr('sin**3(x)', transformations=transformations) == sin(x)**3\n    assert parse_expr('sin**4(x)', transformations=transformations) == sin(x)**4\n"], "sample_999": ["def test_latex_MatPow():\n    from sympy import MatrixSymbol\n    A = MatrixSymbol(\"A\", 3, 3)\n    assert latex(A**3) == r\"A^{3}\"\n    assert latex((A**3).T) == r\"\\left(A^{3}\\right)^{T}\"\n    assert latex((A**3).H) == r\"\\left(A^{3}\\right)^{\\dagger}\"\n"], "sample_1001": ["def test_latex_radian():\n    expr1 = pi*radian\n    assert latex(expr1) == r\"\\pi \\detokenize {radian}\"\n    expr2 = x*radian\n    assert latex(expr2) == r\"x \\detokenize {radian}\"\n    expr3 = sin(x*radian + pi*radian)\n    assert latex(expr3) == r'\\sin{\\left (x \\detokenize {radian} + \\pi \\detokenize {radian} \\right )}'\n"], "sample_1003": ["def test_build_options():\n    assert build_options((x, y, z), {'domain': 'ZZ'}) == Options((x, y, z), {'domain': 'ZZ'})\n    assert build_options({'domain': 'ZZ'}) == Options((), {'domain': 'ZZ'})\n    assert build_options({'opt': Options((x, y, z), {'domain': 'ZZ'})}) == Options((x, y, z), {'domain': 'ZZ'})\n\n    raises(OptionError, lambda: build_options((x, y, z), {'gens': (x, y)}))\n"], "sample_1008": ["def test_orientnew_respects_input_variables_with_custom_indices():\n    N = ReferenceFrame('N')\n    q1 = dynamicsymbols('q1')\n    indices = ['a', 'b', 'c']\n    variables = ['notn_a', 'notn_b', 'notn_c']\n    A = N.orientnew('a', 'Axis', [q1, N.z], indices=indices, variables=variables)\n\n    for j,var in enumerate(A.varlist):\n        assert var.name == variables[j]\n"], "sample_1009": ["def test_vector_magnitude_normalize():\n    N = ReferenceFrame('N')\n    x, y, z = symbols('x y z')\n\n    v1 = x * N.x + y * N.y + z * N.z\n    assert v1.magnitude() == sqrt(x**2 + y**2 + z**2)\n\n    v2 = 3 * N.x + 4 * N.y\n    assert v2.normalize() == (3/5) * N.x + (4/5) * N.y\n\n    v3 = 0 * N.x + 0 * N.y + 0 * N.z\n    raises(ZeroDivisionError, lambda: v3.normalize())\n"], "sample_1012": ["def test_PythonCodePrinter_printing_of_Infinity():\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(oo) == \"float('inf')\"\n"], "sample_1019": ["def test_mask_nc():\n    A, B = symbols('A B', commutative=False)\n    x, y = symbols('x y')\n    eq = x*A + y*B\n    masked, reps, nc_symbols = _mask_nc(eq)\n    assert masked == x*Dummy() + y*Dummy()\n    assert len(reps) == 2\n    assert set(nc_symbols) == set(reps.values())\n    assert set(reps.keys()) == set(masked.free_symbols)\n    assert eq == masked.subs({v: k for k, v in reps.items()})\n"], "sample_1021": ["def test_quaternion_from_rotation_matrix_with_symbolic_values():\n    theta = symbols(\"theta\", real=True)\n    M = Matrix([[cos(theta), -sin(theta), 0], [sin(theta), cos(theta), 0], [0, 0, 1]])\n    q = Quaternion.from_rotation_matrix(M)\n    assert trigsimp(q) == Quaternion(sqrt(2)*sqrt(cos(theta) + 1)/2, 0, 0, sqrt(-2*cos(theta) + 2)/2)\n"], "sample_1022": ["def test_lambda_notation():\n    cases = {\n        'lambda: x': 'Lambda(x)',\n        'lambda x, y: x + y': 'Lambda((x, y), x + y)',\n        'lambda: 1 if x > 2 else 3': 'Lambda(1 if x > 2 else 3)',\n    }\n    transformations = standard_transformations + (convert_xor,)\n    transformations2 = transformations + (lambda_notation,)\n    for case in cases:\n        implicit = parse_expr(case, transformations=transformations2)\n        normal = parse_expr(cases[case], transformations=transformations)\n        assert(implicit == normal)\n\n    # Test lambda with default arguments\n    raises(TokenError, lambda: parse_expr('lambda x=2: x', transformations=transformations2))\n\n    # Test lambda with variable arguments\n    raises(TokenError, lambda: parse_expr('lambda *args: args', transformations=transformations2))\n\n    # Test lambda with keyword-only arguments\n    raises(TokenError, lambda: parse_expr('lambda *, x: x', transformations=transformations2))\n"], "sample_1030": ["def test_are_coplanar():\n    from sympy import Point3D, Line3D, Plane\n    a = Line3D(Point3D(5, 0, 0), Point3D(1, -1, 1))\n    b = Line3D(Point3D(0, -2, 0), Point3D(3, 1, 1))\n    c = Line3D(Point3D(0, -1, 0), Point3D(5, -1, 9))\n    assert are_coplanar(a, b, c) is False\n    assert are_coplanar(a, a) is True\n    p = Plane(Point3D(0, 0, 0), Point3D(1, 1, 1), Point3D(1, 1, 0))\n    assert are_coplanar(p, a) is False\n    assert are_coplanar(p, p) is True\n    assert are_coplanar(Point3D(0, 0, 0), Point3D(1, 1, 1), Point3D(1, 1, 0)) is True\n    assert are_coplanar(Point3D(0, 0, 0), Point3D(1, 1, 1), Point3D(1, 1, 2)) is False\n"], "sample_1031": ["def test_get_unit_dimension_mapping():\n    ms = UnitSystem((m, s), (c,))\n    mapping = ms.get_unit_dimension_mapping()\n    assert mapping[m] == length\n    assert mapping[s] == time\n    assert mapping[c] == velocity\n"], "sample_1036": ["def test_Mul_as_coefficients_dict():\n    from sympy.abc import a, x\n    assert (3*a*x).as_coefficients_dict() == {a*x: 3}\n    assert (-3*a*x).as_coefficients_dict() == {a*x: -3}\n    assert (3*x).as_coefficients_dict() == {x: 3}\n    assert (3*a).as_coefficients_dict() == {a: 3}\n    assert (3).as_coefficients_dict() == {1: 3}\n"], "sample_1039": ["def test_print_negative_infinity():\n    assert mpp.doprint(-oo) == '<mrow><mo>-</mo><mi>&#x221E;</mi></mrow>'\n    assert mp.doprint(-oo) == '<apply><minus/><infinity/></apply>'\n"], "sample_1040": ["def test_print_function():\n    f = Function('f')\n    assert mpp.doprint(f(x)) == '<mrow><mi>f</mi><mfenced><mi>x</mi></mfenced></mrow>'\n    assert mp.doprint(f(x)) == '<apply><f/><ci>x</ci></apply>'\n"], "sample_1049": ["def test_plane_contains():\n    p1 = Point3D(0, 0, 0)\n    p2 = Point3D(1, 1, 1)\n    p3 = Point3D(1, 2, 3)\n    pl3 = Plane(p1, p2, p3)\n\n    assert p1 in pl3\n    assert p2 in pl3\n    assert p3 in pl3\n\n    l1 = Line3D(p1, p2)\n    l2 = Line3D(p1, p3)\n    l3 = Line3D(p2, p3)\n\n    assert l1 in pl3\n    assert l2 in pl3\n    assert l3 in pl3\n\n    r1 = Ray3D(p1, p2)\n    r2 = Ray3D(p1, p3)\n    r3 = Ray3D(p2, p3)\n\n    assert r1 in pl3\n    assert r2 in pl3\n    assert r3 in pl3\n\n    s1 = Segment3D(p1, p2)\n    s2 = Segment3D(p1, p3)\n    s3 = Segment3D(p2, p3)\n\n    assert s1 in pl3\n    assert s2 in pl3\n    assert s3 in pl3\n"], "sample_1050": ["def test_PythonCodePrinter_print_Pow():\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(x**2) == 'x**2'\n    assert prntr.doprint(x**(1/2)) == 'x**0.5'\n    assert prntr.doprint(x**-1) == '1/x'\n"], "sample_1055": ["def test_padded_key_symbols():\n    assert padded_key('ab', 'abcd') == 'abcd'\n    raises(ValueError, lambda: padded_key('ab', 'abcda'))\n    raises(ValueError, lambda: padded_key('abc', 'ab'))\n"], "sample_1058": ["def test_SymPyPrinter():\n    p = SymPyPrinter()\n    expr = acos(x)\n    assert 'sympy' in p.module_imports\n    assert p.doprint(expr) == 'sympy.acos(x)'\n    assert p.doprint(sign(x)) == 'sympy.sign(x)'\n    assert p.doprint(Rational(1, 2)) == 'sympy.Rational(1, 2)'\n"], "sample_1061": ["def test_Pow_is_integer():\n    assert Pow(2, 3, evaluate=False).is_integer\n    assert not Pow(2, S.Half, evaluate=False).is_integer\n    assert Pow(S.Half, -2, evaluate=False).is_integer\n    assert Pow(S.Half, -3, evaluate=False).is_integer is None\n    assert Pow(3, 2, evaluate=False).is_integer\n    assert Pow(3, -2, evaluate=False).is_integer is None\n    assert Pow(3, S.Half, evaluate=False).is_integer is None\n    assert Pow(0, 0, evaluate=False).is_integer is None\n    assert Pow(0, 1, evaluate=False).is_integer\n    assert Pow(0, 3, evaluate=False).is_integer\n    assert Pow(0, -1, evaluate=False).is_integer is None\n    assert Pow(0, -3, evaluate=False).is_integer is None\n    assert Pow(0, S.Half, evaluate=False).is_integer is None\n"], "sample_1062": ["def test_TR22():\n    assert TR22(1 + tan(x)**2) == sec(x)**2\n    assert TR22(1 + cot(x)**2) == csc(x)**2\n    assert TR22(tan(x)**4) == (sec(x)**2 - 1)**2\n    assert TR22(cot(x)**4) == (csc(x)**2 - 1)**2\n"], "sample_1064": ["def test_tensorflow_Max():\n    if not tf:\n        skip(\"TensorFlow not installed\")\n\n    expr = Max(x, y)\n    assert tensorflow_code(expr) == \"tensorflow.math.maximum(x, y)\"\n    _compare_tensorflow_scalar((x, y), expr)\n\n    expr = Max(x, y, z)\n    assert tensorflow_code(expr) == \\\n        \"tensorflow.math.maximum(tensorflow.math.maximum(x, y), z)\"\n    _compare_tensorflow_scalar((x, y, z), expr)\n\n"], "sample_1066": ["def test_print_MatMul():\n    from sympy import MatMul\n\n    X = MatrixSymbol('X', 2, 2)\n    Y = MatrixSymbol('Y', 2, 2)\n\n    assert mathml(MatMul(X, Y), printer=\"presentation\") == \\\n        '<mrow><mi>X</mi><mo>&InvisibleTimes;</mo><mi>Y</mi></mrow>'\n    assert mathml(-MatMul(X, Y), printer=\"presentation\") == \\\n        '<mrow><mo>-</mo><mi>X</mi><mo>&InvisibleTimes;</mo><mi>Y</mi></mrow>'\n    assert mathml(MatMul(X, -Y), printer=\"presentation\") == \\\n        '<mrow><mi>X</mi><mo>&InvisibleTimes;</mo><mfenced><mrow><mo>-</mo>'\\\n        '<mi>Y</mi></mrow></mfenced></mrow>'\n    assert mathml(MatMul(-X, Y), printer=\"presentation\") == \\\n        '<mrow><mfenced><mrow><mo>-</mo><mi>X</mi></mrow></mfenced>'\\\n        '<mo>&InvisibleTimes;</mo><mi>Y</mi></mrow>'\n    assert mathml(-MatMul(-X, Y), printer=\"presentation\") == \\\n        '<mrow><mi>X</mi><mo>&InvisibleTimes;</mo><mi>Y</mi></mrow>'\n    assert mathml(MatMul(X, Y)*Z, printer=\"presentation\") == \\\n        '<mrow><mfenced><mrow><mi>X</mi><mo>&InvisibleTimes;</mo>'\\\n        '<mi>Y</mi></mrow></mfenced><mo>&InvisibleTimes;</mo><mi>Z</mi></mrow>'\n    assert mathml(Z*MatMul(X, Y), printer=\"presentation\") == \\\n        '<mrow><mi>Z</mi><mo>&InvisibleTimes;</mo><mfenced><mrow><mi>X</mi>'\\\n        '<mo>&InvisibleTimes;</mo><mi>Y</mi></mrow></mfenced></mrow>'\n"], "sample_1077": ["def test_issue_19611():\n    assert ImageSet(Lambda(x, x**2), S.Integers).is_subset(S.Complexes)\n    assert ImageSet(Lambda(x, x**2), S.Integers).is_subset(S.Reals)\n    assert not ImageSet(Lambda(x, x**2 + I), S.Integers).is_subset(S.Reals)\n    assert ImageSet(Lambda(x, x**2 + I), S.Integers).is_subset(S.Complexes)\n"], "sample_1079": ["def test_orthogonal_direction():\n    p1 = Point(1, 2)\n    p2 = Point(3, 4)\n    assert p1.orthogonal_direction == Point(-2, 1)\n    assert p2.orthogonal_direction == Point(-4, 3)\n\n    p3 = Point(0, 1)\n    p4 = Point(1, 0)\n    assert p3.orthogonal_direction == Point(1, 0)\n    assert p4.orthogonal_direction == Point(0, 1)\n\n    p5 = Point(1, 1)\n    assert p5.orthogonal_direction == Point(-1, 1)\n"], "sample_1081": ["def test_abundance():\n    assert abundance(6) == 0\n    assert abundance(10) == -2\n    assert abundance(12) == 4\n    assert abundance(15) == -9\n    assert abundance(28) == 0\n    assert abundance(945) == 190\n"], "sample_1082": ["def test_finite_assumptions():\n    f = Symbol('f', finite=True)\n    i = Symbol('i', infinite=True)\n    assert sinh(f).is_finite is True\n    assert sinh(i).is_finite is False\n    assert cosh(f).is_finite is True\n    assert cosh(i).is_finite is False\n    assert tanh(f).is_finite is True\n    assert tanh(i).is_finite is True\n    assert csch(f).is_finite is True\n    assert csch(i).is_finite is False\n    assert sech(f).is_finite is True\n    assert sech(i).is_finite is False\n    assert coth(f).is_finite is True\n    assert coth(i).is_finite is True\n"], "sample_1083": ["def test_hyperbolic_is_finite():\n    x = Symbol('x')\n    assert sinh(x).is_finite is None\n    assert cosh(x).is_finite is None\n    assert tanh(x).is_finite is None\n    assert coth(x).is_finite is None\n    assert sech(x).is_finite is None\n    assert csch(x).is_finite is None\n\n    assert sinh(1).is_finite is True\n    assert cosh(1).is_finite is True\n    assert tanh(1).is_finite is True\n    assert coth(1).is_finite is True\n    assert sech(1).is_finite is True\n    assert csch(1).is_finite is True\n\n    assert sinh(oo).is_finite is False\n    assert cosh(oo).is_finite is False\n    assert tanh(oo).is_finite is True\n    assert coth(oo).is_finite is True\n    assert sech(oo).is_finite is False\n    assert csch(oo).is_finite is False\n\n    assert sinh(nan).is_finite is False\n    assert cosh(nan).is_finite is False\n    assert tanh(nan).is_finite is False\n    assert coth(nan).is_finite is False\n    assert sech(nan).is_finite is False\n    assert csch(nan).is_finite is False\n"], "sample_1086": ["def test_issue_16678():\n    from sympy import log\n    assert str(log(x, 2)) == 'log(x, 2)'\n    assert str(log(x, 10)) == 'log(x, 10)'\n"], "sample_1091": ["def test_issue_16587():\n    # Test that Eq(expr) with rhs default to 0 is deprecated\n    with warns_deprecated_sympy():\n        assert Eq(x) == Eq(x, 0)\n"], "sample_1093": ["def test_SymPyPrinter():\n    p = SymPyPrinter()\n    expr = acos(x)\n    assert 'sympy' in p.module_imports\n    assert p.doprint(expr) == 'sympy.acos(x)'\n    smat = SparseMatrix(2, 5, {(0, 1): 3})\n    assert p.doprint(smat) == 'sympy.Matrix([[0, 3, 0, 0, 0], [0, 0, 0, 0, 0]])'\n    assert 'sympy' in p.module_imports\n\n    assert p.doprint(S.GoldenRatio) == 'sympy.GoldenRatio'\n    assert p.doprint(S.Pi) == 'sympy.pi'\n    assert p.doprint(S.Exp1) == 'sympy.E'\n"], "sample_1095": ["def test_AppliedPermutation_subs():\n    x = Symbol('x')\n    p = Permutation(0, 1, 2)\n    ap = AppliedPermutation(p, x)\n    assert ap.subs(x, 0) == 1\n    assert ap.subs(x, 1) == 2\n    assert ap.subs(x, 2) == 0\n    assert ap.subs(x, 3) == 3\n"], "sample_1097": ["def test_block_collapse_inverse():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', m, m)\n    X = BlockDiagMatrix(A, B)\n\n    assert block_collapse(Inverse(X)) == BlockDiagMatrix(Inverse(A), Inverse(B))\n"], "sample_1098": ["def test_hyper_evalf():\n    from sympy import hyper, exp, log\n    assert abs(hyper([], [], 2.5).evalf() - exp(2.5)) < 1e-10\n    assert abs(hyper([1, 1], [2], 0.5).evalf() - log(1.5)) < 1e-10\n    assert abs(hyper((1, 2), (3,), 0.25).evalf() - hyper((1, 2), (3,), Rational(1, 4)).evalf()) < 1e-10\n"], "sample_1100": ["def test_Pow_is_algebraic():\n    x = Symbol('x', algebraic=True)\n    y = Symbol('y', algebraic=True)\n    z = Symbol('z', algebraic=False)\n\n    assert (x**2).is_algebraic is True\n    assert (x**Rational(1, 2)).is_algebraic is True\n    assert (x**Rational(3, 2)).is_algebraic is True\n\n    assert (y**2).is_algebraic is True\n    assert (y**Rational(1, 2)).is_algebraic is True\n    assert (y**Rational(3, 2)).is_algebraic is True\n\n    assert (z**2).is_algebraic is None\n    assert (z**Rational(1, 2)).is_algebraic is None\n    assert (z**Rational(3, 2)).is_algebraic is None\n\n    assert (x*y).is_algebraic is True\n    assert (x*z).is_algebraic is None\n    assert (y*z).is_algebraic is None\n\n    assert (x**y).is_algebraic is None\n    assert (x**z).is_algebraic is None\n    assert (y**z).is_algebraic is None\n"], "sample_1103": ["def test_Pow_is_algebraic():\n    x = Symbol('x')\n    assert (2**x).is_algebraic is None\n    assert (2**(1/x)).is_algebraic is None\n    assert (2**(S(1)/2)).is_algebraic is True\n    assert ((-2)**(S(1)/3)).is_algebraic is True\n    assert (2**(S(1)/3) + 2**(S(2)/3)).is_algebraic is True\n    assert (2**(S(1)/3) + 2**(S(2)/3)).is_integer is False\n    assert (2**(S(1)/3) + 2**(S(2)/3)).is_rational is False\n    assert (2**(S(1)/3) + 2**(S(2)/3)).is_real is True\n    assert (2**(S(1)/3) + 2**(S(2)/3)*I).is_algebraic is True\n    assert (2**(S(1)/3) + 2**(S(2)/3)*I).is_integer is False\n    assert (2**(S(1)/3) + 2**(S(2)/3)*I).is_rational is False\n    assert (2**(S(1)/3) + 2**(S(2)/3)*I).is_real is False\n"], "sample_1104": ["def test_issue_16458():\n    from sympy import symbols, Eq\n    x, y = symbols('x y')\n    eq1 = Eq(x + 2*y, 3)\n    eq2 = Eq(4*x - 5*y, 2)\n    assert str(eq1) == 'Eq(x + 2*y, 3)'\n    assert str(eq2) == 'Eq(4*x - 5*y, 2)'\n    assert str(eq1.rewrite(y)) == 'Eq(x + 2*y, 3)'\n    assert str(eq2.rewrite(y)) == 'Eq(4*x - 5*y, 2)'\n"], "sample_1105": ["def test_matmul_entry():\n    from sympy import Sum, Dummy\n    i = Dummy(\"i\")\n    assert MatMul(A, B)._entry(0, 1) == Sum(A[0, i]*B[i, 1], (i, 0, m - 1)).doit()\n"], "sample_1107": ["def test_roundrobin():\n    gen = roundrobin('ABC', 'D', 'EF')\n    assert list(gen) == ['A', 'D', 'E', 'B', 'F', 'C']\n"], "sample_1108": ["def test_roundrobin():\n    assert list(roundrobin('ABC', 'D', 'EF')) == ['A', 'D', 'E', 'B', 'F', 'C']\n    assert list(roundrobin([1, 2], [3, 4, 5])) == [1, 3, 2, 4, 5]\n    assert list(roundrobin([1, 2, 3], [4, 5], [6, 7, 8, 9])) == [\n        1, 4, 6, 2, 5, 7, 3, 8, 9]\n"], "sample_1110": ["def test_lambertw():\n    from sympy import lambertw\n\n    expr = lambertw(x)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr) == 'scipy.special.lambertw(x)'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr) == '  # Not supported in Python with NumPy:\\n  # LambertW\\nLambertW(x)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr) == '  # Not supported in Python:\\n  # LambertW\\nLambertW(x)'\n"], "sample_1117": ["def test_matrix_element_sets_inverse():\n    X = MatrixSymbol('X', 4, 4)\n    assert ask(Q.real_elements(X.I), Q.real_elements(X) & Q.invertible(X))\n    assert ask(Q.complex_elements(X.I), Q.complex_elements(X) & Q.invertible(X))\n    assert ask(Q.integer_elements(X.I), Q.integer_elements(X) & Q.invertible(X)) is None\n"], "sample_1119": ["def test_inverse_matpow_simplification():\n    A = MatrixSymbol('A', 3, 3)\n    assert (MatPow(A, -1)*A).doit() == Identity(3)\n    assert (A*MatPow(A, -1)).doit() == Identity(3)\n    assert MatPow(MatPow(A, -1), -1).doit() == A\n"], "sample_1120": ["def test_matrix_element_conjugate():\n    A = MatrixSymbol('A', 2, 2)\n    assert conjugate(A[0, 1]) == conjugate(A)[0, 1]\n    assert adjoint(A[0, 1]) == adjoint(A)[1, 0]\n"], "sample_1121": ["def test_Mul_is_algebraic():\n    a = Symbol('a', algebraic=True)\n    b = Symbol('b', algebraic=True)\n    c = Symbol('c', algebraic=False)\n\n    assert (a*b).is_algebraic is True\n    assert (a*c).is_algebraic is None\n    assert (b*c).is_algebraic is None\n    assert (c*a*b).is_algebraic is None\n"], "sample_1129": ["def test_lambertw():\n    from sympy import lambertw\n\n    expr = lambertw(x)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr) == 'scipy.special.lambertw(x)'\n"], "sample_1130": ["def test_point_vel_with_intermediate_frame():\n    q, u = dynamicsymbols('q u')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    O = Point('O')\n    P = Point('P')\n    O.set_vel(N, u * N.x)\n    P.set_pos(O, q * B.y)\n    raises(ValueError, lambda: P.vel(N))  # B's orientation with respect to N is not defined\n    B.orient(N, 'Axis', (q, N.z))\n    assert P.vel(N) == u * N.x + q.diff(dynamicsymbols._t) * B.y - q * q.diff(dynamicsymbols._t) * B.x\n"], "sample_1131": ["def test_SymPyPrinter():\n    p = SymPyPrinter()\n    expr = acos(x)\n    assert 'sympy' not in p.module_imports\n    assert p.doprint(expr) == 'sympy.acos(x)'\n    assert 'sympy' in p.module_imports\n\n    smat = SparseMatrix(2, 5, {(0, 1): 3})\n    assert p.doprint(smat) == \\\n        'sympy.Matrix([[0, 3, 0, 0, 0], [0, 0, 0, 0, 0]])'\n    assert 'sympy' in p.module_imports\n\n    assert p.doprint(S.GoldenRatio) == 'sympy.GoldenRatio'\n    assert p.doprint(S.Pi) == 'sympy.pi'\n    assert p.doprint(S.Exp1) == 'sympy.E'\n"], "sample_1132": ["def test_roundrobin():\n    assert list(roundrobin('ABC', 'D', 'EF')) == [\n        'A', 'D', 'E', 'B', 'F', 'C']\n    assert list(roundrobin([1, 2], [3, 4, 5])) == [1, 3, 2, 4]\n"], "sample_1133": ["def test_refraction_angle_total_internal_reflection():\n    n1, n2 = symbols('n1, n2')\n    m1 = Medium('m1', n=1.33)\n    m2 = Medium('m2', n=1)\n    r1 = Ray3D(Point3D(-1, -1, 1), Point3D(0, 0, 0))\n    P = Plane(Point3D(0, 0, 0), normal_vector=[0, 0, 1])\n    angle_of_incidence = critical_angle(m1, m2) + 0.1\n    assert refraction_angle(angle_of_incidence, m1, m2) == 0\n    raises(ValueError, lambda: refraction_angle(r1, m1, m2, plane=P))\n"], "sample_1135": ["def test_Mul_is_algebraic():\n    a = Symbol('a', algebraic=True)\n    b = Symbol('b', algebraic=True)\n    c = Symbol('c', algebraic=False)\n    d = Symbol('d', algebraic=False)\n\n    assert (a*b).is_algebraic is True\n    assert (a*c).is_algebraic is None\n    assert (c*d).is_algebraic is None\n    assert (a*b*c).is_algebraic is None\n    assert (a*b*d).is_algebraic is None\n    assert (c*d).is_algebraic is None\n"], "sample_1138": ["def test_TR22():\n    assert TR22(1 + tan(x)**2) == sec(x)**2\n    assert TR22(1 + cot(x)**2) == csc(x)**2\n    assert TR22(tan(x)**4) == (sec(x)**2 - 1)**2\n    assert TR22(cot(x)**4) == (csc(x)**2 - 1)**2\n"], "sample_1141": ["def test_matrixelement_subs():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    assert A[0, 0].subs(A, B) == B[0, 0]\n    assert A[0, 0].subs(B, A) == A[0, 0]\n    assert A[0, 0].subs(B, Identity(2)) == A[0, 0]\n    assert A[0, 0].subs(B, ZeroMatrix(2, 2)) == A[0, 0]\n"], "sample_1142": ["def test_matrix_derivative():\n    from sympy.tensor.array.array_derivatives import ArrayDerivative\n\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    X = MatrixSymbol('X', 2, 2)\n\n    expr = A*X*B\n    x = X[0, 0]\n    res = _matrix_derivative(expr, x)\n    assert isinstance(res, MatrixExpr)\n\n    expr = A*X**2*B\n    res = _matrix_derivative(expr, x)\n    assert isinstance(res, MatrixExpr)\n\n    expr = A*X*B*X\n    res = _matrix_derivative(expr, x)\n    assert isinstance(res, MatrixExpr)\n\n    expr = A*X + B*X\n    res = _matrix_derivative(expr, x)\n    assert isinstance(res, MatrixExpr)\n\n    expr = A*X*B + B*X*A\n    res = _matrix_derivative(expr, x)\n    assert isinstance(res, MatrixExpr)\n"], "sample_1148": ["def test_matrix_derivative():\n    from sympy.tensor.array.array_derivatives import ArrayDerivative\n    x = symbols('x')\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    f = x*A*B\n    assert _matrix_derivative(f, x) == A*B\n    assert _matrix_derivative(f, A) == x*B\n    assert _matrix_derivative(f, B) == x*A\n    assert _matrix_derivative(A, A) == Identity(2)\n    assert _matrix_derivative(B, B) == Identity(2)\n    assert _matrix_derivative(x, x) == 1\n    assert _matrix_derivative(x, A) == ZeroMatrix(1, 2)\n    assert _matrix_derivative(A, x) == ZeroMatrix(2, 1)\n"], "sample_1153": ["def test_polar_lift():\n    from sympy import polar_lift, exp_polar, pi, I\n    x = Symbol('x')\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == exp_polar(0)\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(I*pi/2)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(x) == exp_polar(I*arg(x))*Abs(x)\n    assert polar_lift(exp_polar(I*pi/4)) == exp_polar(I*pi/4)\n    assert polar_lift(exp_polar(-I*pi/4)) == exp_polar(-I*pi/4)\n    assert polar_lift(exp_polar(I*pi/4)*x) == exp_polar(I*pi/4)*polar_lift(x)\n"], "sample_1156": ["def test_issue_21474():\n    x = Symbol('x')\n    assert asinh(x).rewrite(log) == log(x + sqrt(x**2 + 1))\n    assert acosh(x).rewrite(log) == log(x + sqrt(x - 1)*sqrt(x + 1))\n    assert atanh(x).rewrite(log) == (log(1 + x) - log(1 - x)) / 2\n    assert acoth(x).rewrite(log) == (log(1 + 1/x) - log(1 - 1/x)) / 2\n    assert asech(x).rewrite(log) == log(1/x + sqrt(1/x - 1) * sqrt(1/x + 1))\n    assert acsch(x).rewrite(log) == log(1/x + sqrt(1/x**2 + 1))\n"], "sample_1160": ["def test_issue_18999():\n    n = Symbol('n', integer=True)\n    assert Range(n, n + 49).is_finite_set is True\n    assert Range(n, 0).is_finite_set is True\n    assert Range(-3, n + 7).is_finite_set is True\n    assert Range(n, m).is_finite_set is True\n    assert Range(n + m, m - n).is_finite_set is True\n    assert Range(n, n + m + n).is_finite_set is True\n    assert Range(n, oo).is_finite_set is False\n    assert Range(-oo, n).is_finite_set is False\n    assert Range(n, -oo).is_finite_set is True\n    assert Range(oo, n).is_finite_set is True\n"], "sample_1161": ["def test_printing_str_Dimension():\n    assert sstr(Dimension(\"length\")) == \"length\"\n"], "sample_1163": ["def test_issue_19627():\n    from sympy import Function, Symbol, Abs\n    x = Symbol('x')\n    f = Function('f', positive=True)\n    assert Abs(f(x)) == f(x)\n    assert Abs(f(x)**2) == f(x)**2\n    assert Abs(f(x)**3) == f(x)**3\n    assert Abs(f(x)**4) == f(x)**4\n    assert Abs(f(x)**5) == f(x)**5\n    assert Abs(f(x)**6) == f(x)**6\n"], "sample_1164": ["def test_cg_simp():\n    a = CG(1, 1, 0, 0, 1, 1)\n    b = CG(1, 0, 0, 0, 1, 0)\n    c = CG(1, -1, 0, 0, 1, -1)\n    assert cg_simp(a + b + c) == 3\n    assert cg_simp(a**2 + b**2 + c**2) == 3\n    assert cg_simp(a*b + b*c + c*a) == 0\n"], "sample_1165": ["def test_quaternion_division():\n    q1 = Quaternion(1, 2, 3, 4)\n    q2 = Quaternion(5, 6, 7, 8)\n\n    assert q1 / q2 == q1 * q2.inverse()\n    assert q1 / 2 == Quaternion(1/2, 1, 3/2, 2)\n    raises(ValueError, lambda: q1 / Quaternion(0, 0, 0, 0))\n"], "sample_483": ["def test_list_filter_item_with_through_field(self):\n    class BookAdmin(admin.ModelAdmin):\n        list_filter = [\"authors__name\"]\n\n    errors = BookAdmin(Book, AdminSite()).check()\n    self.assertEqual(errors, [])\n"], "sample_510": ["def test_subplot2grid():\n    fig = plt.figure()\n    ax1 = plt.subplot2grid((3, 3), (0, 0), colspan=2)\n    ax2 = plt.subplot2grid((3, 3), (1, 0), colspan=2, rowspan=2)\n    ax3 = plt.subplot2grid((3, 3), (0, 2), rowspan=3)\n\n    assert ax1.get_position().width > ax3.get_position().width\n    assert ax2.get_position().height > ax1.get_position().height\n    assert ax3.get_position().height > ax1.get_position().height\n"], "sample_640": ["def test_is_overload_stub() -> None:\n    code = astroid.extract_node(\n        \"\"\"\n    from typing import overload\n\n    @overload\n        ...\n\n        ...\n    \"\"\"\n    )\n    assert utils.is_overload_stub(code)\n"], "sample_812": ["def test_indent_at_name():\n    # Test that the indent_at_name parameter is correctly used\n\n    pp = _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=False)\n    lr = LogisticRegression()\n    expected = \"\"\""], "sample_980": ["def test_cycle_structure():\n    p = Permutation([0, 1, 2])\n    assert p.cycle_structure == {1: 3}\n    p = Permutation([0, 2, 1])\n    assert p.cycle_structure == {1: 1, 2: 1}\n    p = Permutation([1, 2, 0])\n    assert p.cycle_structure == {3: 1}\n    p = Permutation([0, 1, 2, 3])\n    assert p.cycle_structure == {1: 4}\n    p = Permutation([0, 3, 1, 2])\n    assert p.cycle_structure == {1: 2, 2: 1}\n"], "sample_1017": ["def test_as_set_interval():\n    assert (x > 0).as_set() == Interval(0, oo, left_open=True)\n    assert (x >= 0).as_set() == Interval(0, oo)\n    assert (x < 0).as_set() == Interval(-oo, 0, right_open=True)\n    assert (x <= 0).as_set() == Interval(-oo, 0)\n    assert (x > 1).as_set() == Interval(1, oo, left_open=True)\n    assert (x >= 1).as_set() == Interval(1, oo)\n    assert (x < 1).as_set() == Interval(-oo, 1, right_open=True)\n    assert (x <= 1).as_set() == Interval(-oo, 1)\n"], "sample_1168": ["def test_roundrobin():\n    assert list(roundrobin('ABC', 'D', 'EF')) == [\n        'A', 'D', 'E', 'B', 'F', 'C']\n    assert list(roundrobin([1, 2], [3, 4, 5])) == [1, 3, 2, 4]\n"], "sample_1169": ["def test_FockStateBosonKet():\n    n = symbols(\"n\")\n    ket = FockStateBosonKet([n])\n    assert ket.args[0] == (n,)\n    assert ket.up(0) == FockStateBosonKet([n + 1])\n    assert ket.down(0) == sqrt(n)*FockStateBosonKet([n - 1])\n"], "sample_1174": ["def test_issue_19627():\n    from sympy import Function, Symbol, Abs\n    x = Symbol('x')\n    f = Function('f', positive=True)\n    assert Abs(f(x)) == f(x)\n    assert Abs(f(x)**2) == f(x)**2\n    assert Abs(f(x)**3) == f(x)**3\n    assert Abs(f(x)**4) == f(x)**4\n"], "sample_1177": ["def test_issue_22792():\n    x = Symbol('x')\n    assert Abs(x).rewrite(sign) == x/sign(x)\n    assert sign(x).rewrite(Abs) == Piecewise((0, Eq(x, 0)), (x / Abs(x), True))\n"], "sample_1178": ["def test_Element():\n    elem = Element('x', 'ijk')\n    assert elem.symbol.name == 'x'\n    assert elem.indices == (Symbol('i'), Symbol('j'), Symbol('k'))\n    assert elem.strides == None\n    assert elem.offset == None\n\n    elem2 = Element('x', 'ijk', strides='lmn', offset='o')\n    assert elem2.symbol.name == 'x'\n    assert elem2.indices == (Symbol('i'), Symbol('j'), Symbol('k'))\n    assert elem2.strides == (Symbol('l'), Symbol('m'), Symbol('n'))\n    assert elem2.offset == Symbol('o')\n\n    assert elem != elem2\n    assert elem.func(*elem.args) == elem\n"], "sample_1179": ["def test_printing_str_elementwiseapplyfunction():\n    from sympy.tensor.array.expressions import ElementwiseApplyFunction\n    M = MatrixSymbol(\"M\", 3, 3)\n    N = MatrixSymbol(\"N\", 3, 3)\n    f = Lambda(x, x**2)\n    expr = ElementwiseApplyFunction(f, M*N)\n    assert sstr(expr) == \"Lambda(x, x**2).(M*N)\"\n"], "sample_1180": ["def test_direction_ratio():\n    p1 = Point3D(0, 0, 0)\n    p2 = Point3D(1, 1, 1)\n\n    assert p1.direction_ratio(Point3D(1, 0, 0)) == [1, 0, 0]\n    assert p1.direction_ratio(Point3D(0, 1, 0)) == [0, 1, 0]\n    assert p1.direction_ratio(Point3D(0, 0, pi)) == [0, 0, pi]\n\n    assert p1.direction_ratio(Point3D(5, 0, 0)) == [5, 0, 0]\n    assert p1.direction_ratio(Point3D(0, sqrt(3), 0)) == [0, sqrt(3), 0]\n    assert p1.direction_ratio(Point3D(0, 0, 5)) == [0, 0, 5]\n\n    assert p1.direction_ratio(Point3D(2.4, 2.4, 0)) == [2.4, 2.4, 0]\n    assert p1.direction_ratio(Point3D(1, 1, 1)) == [1, 1, 1]\n    assert p1.direction_ratio(Point3D(-12, 0 -15)) == [-12, -15, 0]\n\n    assert p2.direction_ratio(Point3D(0, 0, 0)) == [-1, -1, -1]\n    assert p2.direction_ratio(Point3D(1, 1, 12)) == [0, 0, 11]\n    assert p2.direction_ratio(Point3D(12, 1, 12)) == [11, 0, 11]\n"], "sample_1181": ["def test_scipy_printing():\n    if not import_module('scipy'):\n        skip(\"SciPy not installed\")\n\n    M = MatrixSymbol(\"M\", 2, 2)\n    N = MatrixSymbol(\"N\", 2, 2)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(M**-1 * N) == 'scipy.linalg.solve(M, N)'\n    assert prntr.doprint(M**-1 * N + N) == 'scipy.linalg.solve(M, N) + N'\n    assert prntr.doprint(ArrayTensorProduct(M, N)) == 'numpy.einsum(M, [0, 1], N, [2, 3])'\n    assert prntr.doprint(ArrayAdd(M, N)) == 'numpy.add(M, N)'\n    assert prntr.doprint(PermuteDims(M, [1, 0])) == 'numpy.transpose(M, (1, 0))'\n    assert prntr.doprint(ArrayDiagonal(M, (0, 1))) == 'numpy.diagonal(M, 0, axis1=0, axis2=1)'\n"], "sample_1184": ["def test_curved_mirror():\n    R = symbols('R')\n    cm = CurvedMirror(R)\n    assert cm == Matrix([[1, 0], [-2/R, 1]])\n    assert cm.A == 1\n    assert cm.B == 0\n    assert cm.C == -2/R\n    assert cm.D == 1\n\n    h, angle = symbols('h angle')\n    gr = GeometricRay(h, angle)\n    result = cm * gr\n    assert result.height == h\n    assert result.angle == angle - 2*h/R\n"], "sample_1187": ["def test_hyperplane_parameters():\n    triangle = Polygon(Point(0, 3), Point(5, 3), Point(1, 1))\n    assert hyperplane_parameters(triangle) == [((0, 1), 3), ((1, -2), -1), ((-2, -1), -3)]\n\n    cube = [[(0, 0, 0), (0, 0, 5), (0, 5, 0), (0, 5, 5), (5, 0, 0),\n             (5, 0, 5), (5, 5, 0), (5, 5, 5)],\n            [2, 6, 7, 3], [3, 7, 5, 1], [7, 6, 4, 5], [1, 5, 4, 0],\n            [3, 1, 0, 2], [0, 4, 6, 2]]\n    vertices = cube[0]\n    faces = cube[1:]\n    assert hyperplane_parameters(faces, vertices) == [([0, -1, 0], -5), ([0, 0, -1], -5),\n                                                     ([-1, 0, 0], -5), ([0, 1, 0], 0),\n                                                     ([1, 0, 0], 0), ([0, 0, 1], 0)]\n"], "sample_1188": ["def test_pretty_printing_mod():\n    from sympy import symbols, Mod\n    x = symbols('x')\n    assert pretty(Mod(x, 2)) == 'x mod 2'\n"], "sample_1203": ["def test_block_homomorphism():\n    from sympy.combinatorics.named_groups import DihedralGroup\n    G = DihedralGroup(8)\n    blocks = [0, 0, 1, 1, 2, 2, 3, 3]\n    T = block_homomorphism(G, blocks)\n    assert T.domain == G\n    assert T.codomain.is_subgroup(SymmetricGroup(4))\n    assert T.is_homomorphism()\n    assert not T.is_isomorphism()\n"], "sample_1205": ["def test_PolyElement_imul_num():\n    R, x, y = ring(\"x,y\", ZZ)\n\n    f = x + 2*y\n    g = f.imul_num(3)\n    assert g == 3*x + 6*y\n    assert g is f\n\n    f = x\n    g = f.imul_num(3)\n    assert g == 3*x\n    assert g is not f\n"], "sample_1208": ["def test_MatrixGammaDistribution():\n    M = MatrixGammaDistribution(1, 2, [[2, 1], [1, 2]])\n    assert M.alpha == 1\n    assert M.beta == 2\n    assert M.scale_matrix == Matrix([[2, 1], [1, 2]])\n    raises(ValueError, lambda: MatrixGammaDistribution(-1, 2, [[2, 1], [1, 2]]))\n    raises(ValueError, lambda: MatrixGammaDistribution(1, -2, [[2, 1], [1, 2]]))\n    raises(ValueError, lambda: MatrixGammaDistribution(1, 2, [[2, 1], [3, 2]]))\n    raises(ValueError, lambda: MatrixGammaDistribution(1, 2, [[2, 1], [1]]))\n"], "sample_219": ["    def test_window_function(self):\n        Company.objects.create(name='Example Inc.', num_employees=2300, num_chairs=5)\n        Company.objects.create(name='Foobar Ltd.', num_employees=3, num_chairs=4)\n        Company.objects.create(name='Test GmbH', num_employees=32, num_chairs=1)\n\n        qs = Company.objects.annotate(\n            row_number=Window(\n                expression=RowNumber(),\n                partition_by=[F('num_employees')],\n                order_by=F('num_chairs').asc(),\n            ),\n        ).order_by('num_employees', 'num_chairs')\n\n        self.assertQuerysetEqual(qs, [\n            {'name': 'Foobar Ltd.', 'row_number': 1},\n            {'name': 'Test GmbH', 'row_number': 1},\n            {'name': 'Example Inc.', 'row_number': 1},\n        ], transform=lambda x: {'name': x.name, 'row_number': x.row_number})\n"], "sample_10": ["def test_table_attribute_with_mixin():\n    \"\"\"Test that a TableAttribute is properly stored and retrieved for a mixin column\"\"\"\n    class MyTable(Table):\n        foo = TableAttribute()\n\n    t = MyTable([[1, 2]], names=['a'])\n    t['a'].info.foo = 'bar'\n    assert t['a'].info.foo == 'bar'\n    t2 = MyTable(t)\n    assert t2['a'].info.foo == 'bar'\n"], "sample_19": ["def test_pixel_bounds():\n    w = wcs.WCS(naxis=2)\n    w.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\"]\n    w.wcs.crpix = [100, 100]\n    w.wcs.crval = [0, 0]\n    w.wcs.cdelt = [1, 1]\n    w._naxis = [200, 200]\n\n    assert w.pixel_bounds is None\n\n    w.pixel_shape = (200, 200)\n    assert w.pixel_bounds == [(1, 200), (1, 200)]\n\n    w.pixel_bounds = [(10, 190), (10, 190)]\n    assert w.pixel_bounds == [(10, 190), (10, 190)]\n"], "sample_55": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n"], "sample_124": ["def test_field_order_with_error(self):\n    class TestForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n        field3 = CharField()\n        field_order = ['field3', 'field2', 'field1']\n\n    form = TestForm({'field1': 'value1'})\n    self.assertEqual(list(form.fields), ['field3', 'field2', 'field1'])\n    self.assertHTMLEqual(\n        form.as_table(),\n        \"\"\"<tr><th><label for=\"id_field3\">Field3:</label></th>"], "sample_173": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_174": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_196": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_223": ["    def test_ticket_24863(self):\n        \"\"\"\n        Ensure that filtering on a related field with a subquery and an\n        __in lookup works correctly.\n        \"\"\"\n        school1 = School.objects.create()\n        school2 = School.objects.create()\n        student1 = Student.objects.create(school=school1)\n        student2 = Student.objects.create(school=school2)\n        classroom1 = Classroom.objects.create(school=school1)\n        classroom2 = Classroom.objects.create(school=school2)\n        classroom1.students.add(student1)\n        classroom2.students.add(student2)\n\n        subquery = Student.objects.filter(classroom__school__id=school1.id).values_list('id', flat=True)\n        self.assertSequenceEqual(\n            Student.objects.filter(id__in=subquery),\n            [student1]\n        )\n"], "sample_297": ["    def test_ticket_24863(self):\n        \"\"\"\n        Make sure that filtering on a related field with __isnull=True works\n        correctly when the related field has a to_field that is not the primary\n        key.\n        \"\"\"\n        e1 = Eaten.objects.create(meal='spam with eggs')\n        e2 = Eaten.objects.create(meal='spam')\n        self.assertSequenceEqual(Eaten.objects.filter(food__isnull=True), [e1, e2])\n        self.assertSequenceEqual(Eaten.objects.filter(food__isnull=False), [])\n"], "sample_311": ["    def test_custom_handler(self):\n        superuser = User.objects.create_superuser(\n            username='super',\n            password='secret',\n            email='super@example.com',\n        )\n        self.client.force_login(superuser)\n        unknown_url = '/test_admin/admin11/unknown/'\n        response = self.client.get(unknown_url)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content, b\"Django is a magical pony!\")\n"], "sample_319": ["def test_alter_model_table_with_database_table_name(self):\n    \"\"\"\n    Tests when model and db_table changes, autodetector must create two\n    operations.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_with_db_table_options],\n        [self.author_renamed_with_new_db_table_options],\n        MigrationQuestioner({\"ask_rename_model\": True}),\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(\n        changes, \"testapp\", 0, [\"RenameModel\", \"AlterModelTable\"]\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, old_name=\"Author\", new_name=\"NewAuthor\"\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 1, name=\"newauthor\", table=\"author_three\"\n    )\n"], "sample_320": ["def test_references_field_by_order_with_respect_to(self):\n    operation = FieldOperation(\n        \"Model\", \"_order\", models.IntegerField(), model_options={\"order_with_respect_to\": \"field\"}\n    )\n    self.assertIs(operation.references_field(\"Model\", \"field\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Model\", \"whatever\", \"migrations\"), False)\n"], "sample_394": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(\n            username=\"super\", password=\"secret\", email=\"super@example.com\"\n        )\n\n        cls.s1 = State.objects.create(name=\"New York\")\n        cls.s2 = State.objects.create(name=\"Illinois\")\n        cls.s3 = State.objects.create(name=\"California\")\n        cls.c1 = City.objects.create(state=cls.s1, name=\"New York\")\n        cls.c2 = City.objects.create(state=cls.s2, name=\"Chicago\")\n        cls.c3 = City.objects.create(state=cls.s3, name=\"San Francisco\")\n        cls.r1 = Restaurant.objects.create(city=cls.c1, name=\"Italian Pizza\")\n        cls.r2 = Restaurant.objects.create(city=cls.c1, name=\"Boulevard\")\n        cls.r3 = Restaurant.objects.create(city=cls.c2, name=\"Chinese Dinner\")\n        cls.r4 = Restaurant.objects.create(city=cls.c2, name=\"Angels\")\n        cls.r5 = Restaurant.objects.create(city=cls.c2, name=\"Take Away\")\n        cls.r6 = Restaurant.objects.create(city=cls.c3, name=\"The Unknown Restaurant\")\n        cls.w1 = Worker.objects.create(work_at=cls.r1, name=\"Mario\", surname=\"Rossi\")\n        cls.w2 = Worker.objects.create(\n            work_at=cls.r1, name=\"Antonio\", surname=\"Bianchi\"\n        )\n        cls.w3 = Worker.objects.create(work_at=cls.r1, name=\"John\", surname=\"Doe\")\n"], "sample_396": ["    def test_ticket_24989(self):\n        \"\"\"\n        Make sure that filtering on a subquery annotation works correctly.\n        \"\"\"\n        note = Note.objects.create(note=\"note\", misc=\"misc\")\n        note2 = Note.objects.create(note=\"note2\", misc=\"misc2\")\n        Annotation.objects.create(note=note, name=\"annotation\")\n        Annotation.objects.create(note=note2, name=\"annotation2\")\n\n        subquery = Note.objects.filter(\n            Exists(Annotation.objects.filter(note=OuterRef(\"pk\")))\n        ).values_list(\"pk\", flat=True)\n\n        self.assertSequenceEqual(\n            Note.objects.annotate(has_annotation=Exists(subquery)).filter(\n                has_annotation=True\n            ),\n            [note, note2],\n        )\n"], "sample_400": ["def test_add_model_with_field_removed_from_base_model_and_renamed(self):\n    \"\"\"\n    Removing a base field takes place before adding a new inherited model\n    that has a field with the same name. The new model also renames one of\n    its fields.\n    \"\"\"\n    before = [\n        ModelState(\n            \"app\",\n            \"readable\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"title\", models.CharField(max_length=200)),\n            ],\n        ),\n    ]\n    after = [\n        ModelState(\n            \"app\",\n            \"readable\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n            ],\n        ),\n        ModelState(\n            \"app\",\n            \"book\",\n            [\n                (\"renamed_title\", models.CharField(max_length=200)),\n            ],\n            bases=(\"app.readable\",),\n        ),\n    ]\n    changes = self.get_changes(before, after, MigrationQuestioner({\"ask_rename\": True}))\n    self.assertNumberMigrations(changes, \"app\", 1)\n    self.assertOperationTypes(changes, \"app\", 0, [\"RemoveField\", \"CreateModel\", \"RenameField\"])\n    self.assertOperationAttributes(\n        changes, \"app\", 0, 0, name=\"title\", model_name=\"readable\"\n    )\n    self.assertOperationAttributes(changes, \"app\", 0, 1, name=\"book\")\n    self.assertOperationAttributes(\n        changes, \"app\", 0, 2, model_name=\"book\", old_name=\"title\", new_name=\"renamed_title\"\n    )\n"], "sample_403": ["def test_reduce_references_model(self):\n    operation = FieldOperation(\n        \"Model\", \"field\", models.ForeignKey(\"Other\", models.CASCADE)\n    )\n    other_operation = FieldOperation(\"Other\", \"field\", models.BooleanField(default=False))\n    self.assertIs(operation.reduce(other_operation, \"migrations\"), [other_operation])\n    other_operation = FieldOperation(\"Whatever\", \"field\", models.BooleanField(default=False))\n    self.assertIs(operation.reduce(other_operation, \"migrations\"), False)\n"], "sample_405": ["def test_rename_model_with_m2m_through_table(self):\n    app_label = \"test_rename_model_with_m2m_through_table\"\n    project_state = self.apply_operations(\n        app_label,\n        ProjectState(),\n        operations=[\n            migrations.CreateModel(\n                \"Rider\",\n                fields=[\n                    (\"id\", models.AutoField(primary_key=True)),\n                ],\n            ),\n            migrations.CreateModel(\n                \"Pony\",\n                fields=[\n                    (\"id\", models.AutoField(primary_key=True)),\n                ],\n            ),\n            migrations.CreateModel(\n                \"PonyRider\",\n                fields=[\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\n                        \"rider\",\n                        models.ForeignKey(\n                            \"test_rename_model_with_m2m_through_table.Rider\",\n                            models.CASCADE,\n                        ),\n                    ),\n                    (\n                        \"pony\",\n                        models.ForeignKey(\n                            \"test_rename_model_with_m2m_through_table.Pony\",\n                            models.CASCADE,\n                        ),\n                    ),\n                ],\n            ),\n            migrations.AddField(\n                \"Pony\",\n                \"riders\",\n                models.ManyToManyField(\n                    \"Rider\",\n                    through=\"test_rename_model_with_m2m_through_table.PonyRider\",\n                ),\n            ),\n        ],\n    )\n    Pony = project_state.apps.get_model(app_label, \"Pony\")\n    Rider = project_state.apps.get_model(app_label, \"Rider\")\n    PonyRider = project_state.apps.get_model(app_label, \"PonyRider\")\n    pony = Pony.objects.create()\n    rider = Rider.objects.create()\n    PonyRider.objects.create(pony=pony, rider=rider)\n\n    project_state = self.apply_operations(\n        app_label,\n        project_state,\n        operations=[\n            migrations.RenameModel(\"PonyRider\", \"PonyRider2\"),\n        ],\n    )\n    Pony = project_state.apps.get_model(app_label, \"Pony\")\n    Rider = project_state.apps.get_model(app_label, \"Rider\")\n    PonyRider = project_state.apps.get_model(app_label, \"PonyRider2\")\n    pony = Pony.objects.first()\n    rider = Rider.objects.create()\n    PonyRider.objects.create(pony=pony, rider=rider)\n    self.assertEqual(Pony.objects.count(), 1)\n    self.assertEqual(Rider.objects.count(), 2)\n    self.assertEqual(PonyRider.objects.count(), 2)\n    self.assertEqual(pony.riders.count(), 2)\n"], "sample_408": ["def test_add_model_with_unique_together(self):\n    \"\"\"Test creation of new model with unique_together already defined.\"\"\"\n    author = ModelState(\n        \"otherapp\",\n        \"Author\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=200)),\n        ],\n        {\n            \"unique_together\": {(\"name\",)},\n        },\n    )\n    changes = self.get_changes([], [author])\n    # Right number of migrations?\n    self.assertEqual(len(changes[\"otherapp\"]), 1)\n    # Right number of actions?\n    migration = changes[\"otherapp\"][0]\n    self.assertEqual(len(migration.operations), 2)\n    # Right actions order?\n    self.assertOperationTypes(\n        changes, \"otherapp\", 0, [\"CreateModel\", \"AlterUniqueTogether\"]\n    )\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"Author\")\n    self.assertOperationAttributes(\n        changes,\n        \"otherapp\",\n        0,\n        1,\n        name=\"author\",\n        unique_together={(\"name\",)},\n    )\n"], "sample_423": ["def test_alter_field_with_choices(self):\n    \"\"\"Tests autodetection of altered fields with choices.\"\"\"\n    changes = self.get_changes(\n        [ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True)), (\"name\", models.CharField(max_length=200, choices=[(\"a\", \"A\"), (\"b\", \"B\")]))])],\n        [ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True)), (\"name\", models.CharField(max_length=200, choices=[(\"a\", \"A\"), (\"c\", \"C\")]))])],\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n"], "sample_424": ["def test_rename_model_with_self_referential_m2m_through(self):\n    app_label = \"test_rename_model_with_self_referential_m2m_through\"\n\n    project_state = self.apply_operations(\n        app_label,\n        ProjectState(),\n        operations=[\n            migrations.CreateModel(\n                \"ReflexivePony\",\n                fields=[\n                    (\"id\", models.AutoField(primary_key=True)),\n                ],\n            ),\n            migrations.CreateModel(\n                \"ReflexivePonyThrough\",\n                fields=[\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\n                        \"from_pony\",\n                        models.ForeignKey(\n                            \"test_rename_model_with_self_referential_m2m_through.ReflexivePony\",\n                            models.CASCADE,\n                            related_name=\"from_ponies\",\n                        ),\n                    ),\n                    (\n                        \"to_pony\",\n                        models.ForeignKey(\n                            \"test_rename_model_with_self_referential_m2m_through.ReflexivePony\",\n                            models.CASCADE,\n                            related_name=\"to_ponies\",\n                        ),\n                    ),\n                ],\n            ),\n            migrations.AddField(\n                \"ReflexivePony\",\n                \"ponies\",\n                models.ManyToManyField(\n                    \"self\",\n                    through=\"test_rename_model_with_self_referential_m2m_through.ReflexivePonyThrough\",\n                    symmetrical=False,\n                ),\n            ),\n        ],\n    )\n    project_state = self.apply_operations(\n        app_label,\n        project_state,\n        operations=[\n            migrations.RenameModel(\"ReflexivePony\", \"ReflexivePony2\"),\n        ],\n    )\n    Pony = project_state.apps.get_model(app_label, \"ReflexivePony2\")\n    pony = Pony.objects.create()\n    pony.ponies.add(pony)\n"], "sample_430": ["def test_alter_model_table_with_index_together(self):\n    \"\"\"\n    Tests when model and db_table changes, autodetector must create two\n    operations.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_with_db_table_options, self.book_index_together],\n        [self.author_renamed_with_new_db_table_options, self.book_index_together],\n        MigrationQuestioner({\"ask_rename_model\": True}),\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(\n        changes, \"testapp\", 0, [\"RenameModel\", \"AlterModelTable\"]\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, old_name=\"Author\", new_name=\"NewAuthor\"\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 1, name=\"newauthor\", table=\"author_three\"\n    )\n    self.assertNumberMigrations(changes, \"otherapp\", 0)\n"], "sample_439": ["def test_boundfield_get_bound_field(self):\n    class CustomField(CharField):\n            return \"Custom bound field\"\n\n    class CustomForm(Form):\n        field = CustomField()\n\n    form = CustomForm()\n    self.assertEqual(form[\"field\"], \"Custom bound field\")\n"], "sample_452": ["def test_references_field_by_remote_field_model_with_through(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ManyToManyField(\"Other\", through=\"Through\"),\n    )\n    self.assertIs(\n        operation.references_field(\"Other\", \"whatever\", \"migrations\"), True\n    )\n    self.assertIs(\n        operation.references_field(\"Through\", \"whatever\", \"migrations\"), True\n    )\n    self.assertIs(\n        operation.references_field(\"Missing\", \"whatever\", \"migrations\"), False\n    )\n"], "sample_460": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(\n            username=\"super\", password=\"secret\", email=\"super@example.com\"\n        )\n        cls.viewuser = User.objects.create_user(\n            username=\"viewuser\", password=\"secret\", is_staff=True\n        )\n        cls.adduser = User.objects.create_user(\n            username=\"adduser\", password=\"secret\", is_staff=True\n        )\n        cls.changeuser = User.objects.create_user(\n            username=\"changeuser\", password=\"secret\", is_staff=True\n        )\n        cls.deleteuser = User.objects.create_user(\n            username=\"deleteuser\", password=\"secret\", is_staff=True\n        )\n        cls.joepublicuser = User.objects.create_user(\n            username=\"joepublic\", password=\"secret\"\n        )\n        cls.nostaffuser = User.objects.create_user(\n            username=\"nostaff\", password=\"secret\"\n        )\n        cls.s1 = Section.objects.create(name=\"Test section\")\n        cls.a1 = Article.objects.create(\n            content=\"<p>Middle content</p>\",\n            date=datetime.datetime(2008, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.a2 = Article.objects.create(\n            content=\"<p>Oldest content</p>\",\n            date=datetime.datetime(2000, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.a3 = Article.objects.create(\n            content=\"<p>Newest content</p>\",\n            date=datetime.datetime(2009, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.p1 = PrePopulatedPost.objects.create(\n            title=\"A Long Title\", published=True, slug=\"a-long-title\"\n        )\n\n        # Setup permissions, for our users who can add, change, and delete.\n        opts = Article._meta\n\n        # User who can view Articles\n        cls.viewuser.user_permissions.add(\n            get_perm(Article, get_permission_codename(\"view\", opts))\n        )\n        # User who can add Articles\n        cls.adduser.user_permissions.add(\n            get_perm(Article, get_permission_codename(\"add\", opts))\n        )\n        # User who can change Articles\n        cls.changeuser.user"], "sample_463": ["def test_alter_field_with_choices(self):\n    \"\"\"Tests autodetection of altered fields with choices.\"\"\"\n    changes = self.get_changes(\n        [self.author_name],\n        [\n            ModelState(\n                \"testapp\",\n                \"Author\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\n                        \"name\",\n                        models.CharField(\n                            max_length=200,\n                            choices=[(\"1\", \"one\"), (\"2\", \"two\")],\n                        ),\n                    ),\n                ],\n            )\n        ],\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True\n    )\n"], "sample_491": ["def test_boundfield_widget_type(self):\n    class TestForm(Form):\n        field1 = CharField()\n        field2 = CharField(widget=PasswordInput)\n        field3 = CharField(widget=HiddenInput)\n        field4 = CharField(widget=Textarea)\n        field5 = CharField(widget=TextInput)\n\n    form = TestForm()\n    self.assertEqual(form[\"field1\"].widget_type, \"text\")\n    self.assertEqual(form[\"field2\"].widget_type, \"password\")\n    self.assertEqual(form[\"field3\"].widget_type, \"hidden\")\n    self.assertEqual(form[\"field4\"].widget_type, \"textarea\")\n    self.assertEqual(form[\"field5\"].widget_type, \"text\")\n"], "sample_502": ["def test_subplot_mosaic():\n    fig, axes = plt.subplot_mosaic([['A', 'B'], ['C', 'D']])\n    assert len(axes) == 4\n    assert set(axes.keys()) == {'A', 'B', 'C', 'D'}\n    for ax in axes.values():\n        assert ax in fig.axes\n\n    fig, axes = plt.subplot_mosaic(\n        [['A', 'B'], ['C', 'D']], subplot_kw={'projection': 'polar'})\n    for ax in axes.values():\n        assert ax.name == 'polar'\n\n    fig, axes = plt.subplot_mosaic(\n        [['A', 'B'], ['C', 'D']], gridspec_kw={'height_ratios': [1, 2]})\n    assert (axes['A'].get_position().height\n            < axes['C'].get_position().height)\n"], "sample_536": ["def test_MultiCursor_disconnect():\n    (ax1, ax3) = plt.figure().subplots(2, sharex=True)\n    ax2 = plt.figure().subplots()\n\n    multi = widgets.MultiCursor(\n        None, (ax1, ax2), useblit=False, horizOn=True, vertOn=True\n    )\n\n    # mock a motion_notify_event\n    event = mock_event(ax1, xdata=.5, ydata=.25)\n    multi.onmove(event)\n\n    # disconnect the events\n    multi.disconnect()\n\n    # test a move event after disconnect\n    event = mock_event(ax1, xdata=.75, ydata=.75)\n    multi.onmove(event)\n    for l in multi.vlines:\n        assert l.get_xdata() == (.5, .5)\n    for l in multi.hlines:\n        assert l.get_ydata() == (.25, .25)\n"], "sample_539": ["def test_MultiCursor_visible(ax):\n    multi = widgets.MultiCursor(\n        None, (ax,), useblit=False, horizOn=True, vertOn=True\n    )\n    assert multi.visible\n    multi.visible = False\n    for line in multi.vlines + multi.hlines:\n        assert not line.get_visible()\n    multi.visible = True\n    for line in multi.vlines + multi.hlines:\n        assert line.get_visible()\n"], "sample_541": ["def test_LassoSelector_empty_onselect(ax):\n    tool = widgets.LassoSelector(ax, onselect=noop)\n    do_event(tool, 'press', xdata=100, ydata=100, button=1)\n    do_event(tool, 'onmove', xdata=125, ydata=125, button=1)\n    do_event(tool, 'release', xdata=150, ydata=150, button=1)\n    assert tool.verts is None\n"], "sample_543": ["def test_LassoSelector_set_props(ax):\n    tool = widgets.LassoSelector(ax, onselect=noop, props=dict(color='b', alpha=0.2))\n\n    artist = tool._selection_artist\n    assert mcolors.same_color(artist.get_color(), 'b')\n    assert artist.get_alpha() == 0.2\n    tool.set_props(color='r', alpha=0.3)\n    assert mcolors.same_color(artist.get_color(), 'r')\n    assert artist.get_alpha() == 0.3\n"], "sample_564": ["def test_set_zlim3d(fig_test, fig_ref):\n    ax_test = fig_test.add_subplot(projection='3d')\n    ax_test.set_zlim3d(-1, 1)\n    ax_ref = fig_ref.add_subplot(projection='3d')\n    ax_ref.set_zlim(-1, 1)\n"], "sample_720": ["def test_power_transformer_sparse_input():\n    X_sparse = sparse.csr_matrix(np.abs(X_2d))\n    pt = PowerTransformer(method='box-cox')\n\n    # Sparse input should raise an exception\n    assert_raise_message(TypeError, \"PowerTransformer does not support sparse\"\n                         \" input. You may consider to add a step converting\"\n                         \" the sparse matrix to dense in the preprocessing\"\n                         \" chain.\",\n                         pt.fit, X_sparse)\n"], "sample_591": ["def test_merge_no_conflicts_multi_var(self):\n    data = create_test_data()\n    data1 = data.copy(deep=True)\n    data2 = data.copy(deep=True)\n\n    expected = data[[\"var1\", \"var2\"]]\n    actual = xr.merge([data1.var1, data2.var2], compat=\"no_conflicts\")\n    assert expected.identical(actual)\n\n    data1[\"var1\"][:, :5] = np.nan\n    data2[\"var1\"][:, 5:] = np.nan\n    data1[\"var2\"][:4, :] = np.nan\n    data2[\"var2\"][4:, :] = np.nan\n    del data2[\"var3\"]\n\n    actual = xr.merge([data1, data2], compat=\"no_conflicts\")\n    assert data.equals(actual)\n"], "sample_559": ["def test_axes_divider_append_axes_with_size():\n    fig, ax = plt.subplots()\n    divider = make_axes_locatable(ax)\n    ax2 = divider.append_axes(\"top\", size=\"20%\", pad=\"10%\")\n    ax2.set_xticks([])\n    ax3 = divider.append_axes(\"right\", size=0.5, pad=0.2)\n    ax3.set_yticks([])\n"], "sample_744": ["def test_power_transformer_sparse_input():\n    X_sparse = sparse.csr_matrix(np.abs(X_2d))\n    pt = PowerTransformer(method='box-cox', standardize=False)\n\n    # An exception should be raised if PowerTransformer is given sparse input\n    sparse_message = 'PowerTransformer only accepts dense input'\n    assert_raise_message(TypeError, sparse_message,\n                         pt.fit, X_sparse)\n    assert_raise_message(TypeError, sparse_message,\n                         pt.transform, X_sparse)\n    assert_raise_message(TypeError, sparse_message,\n                         pt.inverse_transform, X_sparse)\n    assert_raise_message(TypeError, sparse_message,\n                         power_transform, X_sparse)\n"], "sample_747": ["def test_power_transformer_sparse_input():\n    X_sparse = sparse.csr_matrix(np.abs(X_2d))\n    pt = PowerTransformer(method='box-cox', standardize=False)\n\n    # Test that sparse input raises an error\n    assert_raise_message(TypeError, \"PowerTransformer does not support sparse\"\n                         \" input. You may want to pass the dense data to\"\n                         \" PowerTransformer.\",\n                         pt.fit, X_sparse)\n"], "sample_906": ["def test_domain_cpp_parse_mix_decl_duplicate_with_template(app, warning):\n    # Issue 8270\n    text = (\".. cpp:class:: A\\n\"\n            \".. cpp:function:: void A()\\n\"\n            \".. cpp:class:: A<int>\\n\")\n    restructuredtext.parse(app, text)\n    ws = warning.getvalue().split(\"\\n\")\n    assert len(ws) == 1\n    assert ws[0] == \"\"\n"], "sample_875": ["def test_balanced_accuracy_score_sample_weight():\n    y_true = [0, 0, 0, 1, 1, 1]\n    y_pred = [0, 1, 1, 0, 1, 1]\n    sample_weight = [1, 1, 1, 1, 1, 2]\n    macro_recall = recall_score(\n        y_true, y_pred, average=\"macro\", sample_weight=sample_weight\n    )\n    with ignore_warnings():\n        # Warnings are tested in test_balanced_accuracy_score_unseen\n        balanced = balanced_accuracy_score(y_true, y_pred, sample_weight=sample_weight)\n    assert balanced == pytest.approx(macro_recall)\n"], "sample_907": ["def test_domain_cpp_parse_template_introduction():\n    text = (\".. cpp:class:: A\\n\"\n            \"   .. cpp:class:: template<int> B\\n\"\n            \"   .. cpp:class:: template<int...> C\\n\"\n            \"   .. cpp:class:: template<int, int> D\\n\"\n            \"   .. cpp:class:: template<int, int...> E\\n\"\n            \"   .. cpp:class:: template<int... Ts> F\\n\"\n            \"   .. cpp:class:: template<int, int... Ts> G\\n\"\n            \"   .. cpp:class:: template<int, typename... Ts> H\\n\"\n            \"   .. cpp:class:: template<int, int, typename... Ts> I\\n\"\n            \"   .. cpp:class:: template<int, int, int, typename... Ts> J\\n\"\n            \"   .. cpp:class:: template<int, int, int, int, typename... Ts> K\\n\"\n            \"   .. cpp:class:: template<int, int, int, int, int, typename... Ts> L\\n\"\n            \"   .. cpp:class:: template<int, int, int, int, int, int, typename... Ts> M\\n\"\n            \"   .. cpp:class:: template<int, int, int, int, int, int, int, typename... Ts> N\\n\"\n            \"   .. cpp:class:: template<int, int, int, int, int, int, int, int, typename... Ts> O\\n\"\n            \"   .. cpp:class:: template<int, int, int, int, int, int, int, int, int, typename... Ts> P\\n\"\n            \"   .. cpp:class:: template<int, int, int, int, int, int, int, int, int, int, typename... Ts> Q\\n\"\n            \"   .. cpp:class:: template<int, int, int, int, int, int, int, int, int, int, int, typename... Ts> R\\n\"\n            \"   .. cpp:class:: template<int, int, int, int, int, int, int, int, int, int, int, int, typename... Ts> S\\n\"\n            \"   .. cpp:class:: template<int, int, int, int, int, int, int, int, int, int, int, int, int, typename... Ts> T\\n\"\n            \"   .. cpp:class:: template<int, int, int, int, int, int, int,"], "sample_911": ["def test_template_parameter_pack():\n    check('function', 'template<typename... Ts> void f(Ts... ts)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts...)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts..., int)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int, Ts...)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int, Ts..., int)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int, Ts..., int, Ts...)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int, Ts..., int, Ts..., int)',\n          {2: 'IDpE1fvDp1Ts'})\n"], "sample_917": ["def test_template_parameter_packs():\n    check('class', 'template<typename... Ts> A', {2: 'IDpE1A'})\n    check('class', 'template<typename Ts...> A', {2: 'IDpE1A'})\n    check('class', 'template<typename...> A', {2: 'IDpE1A'})\n    check('class', 'template<int... Is> A', {2: 'I_DpiE1A'})\n    check('class', 'template<int Is...> A', {2: 'I_DpiE1A'})\n    check('class', 'template<int...> A', {2: 'I_DpiE1A'})\n    check('class', 'template<template<typename...> typename T> A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename... Ts> typename T> A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename...> typename... Ts> A', {2: 'II0EDpEDpE1A'})\n    check('class', 'template<template<typename... Ts> typename... Ts> A', {2: 'II0EDpEDpE1A'})\n    check('class', 'template<template<typename...> typename...> A', {2: 'II0EDpEDpE1A'})\n    check('class', 'template<template<int...> typename T> A', {2: 'II_DpE0E1A'})\n    check('class', 'template<template<int Is...> typename T> A', {2: 'II_DpE0E1A'})\n    check('class', 'template<template<int...> typename... Ts> A', {2: 'II_DpE0EDpE1A'})\n    check('class', 'template<template<int Is...> typename... Ts> A', {2: 'II_DpE0EDpE1A'})\n    check('class', 'template<template<int...> typename...> A', {2: 'II_DpE0EDpE1A'})\n"], "sample_919": ["def test_template_parameter_pack():\n    check('function', 'template<typename... Ts> void f(Ts... ts)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts... ts, int i)',\n          {2: 'IDpE1fvDp1TsIiE'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts)',\n          {2: 'IDpE1fvIiEDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts, int j)',\n          {2: 'IDpE1fvIiEDp1TsIiE'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts, int j, Ts...)',\n          {2: 'IDpE1fvIiEDp1TsIiEDp'})\n    check('function', 'template<typename... Ts> void f(Ts... ts, int i, Ts...)',\n          {2: 'IDpE1fvDp1TsIiEDp'})\n    check('function', 'template<typename... Ts> void f(Ts... ts, int i, Ts..., int j)',\n          {2: 'IDpE1fvDp1TsIiEDpIiE'})\n    check('function', 'template<typename... Ts> void f(Ts... ts, int i, Ts..., int j, Ts...)',\n          {2: 'IDpE1fvDp1TsIiEDpIiEDp'})\n"], "sample_924": ["def test_template_parameter_pack():\n    check('function', 'template<typename... Ts> void f(Ts... ts)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts... ts, int i)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts, int j)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts, int j, Ts... ts2)',\n          {2: 'IDpE1fvDp1Ts'})\n"], "sample_927": ["def test_template_parameter_pack():\n    check('class', 'template<typename... Ts> {key}A', {2: 'IDpE1A'})\n    check('class', 'template<typename...> {key}A', {2: 'IDpE1A'})\n    check('class', 'template<typename... Ts> {key}A<Ts...>', {2: 'IDpE1AI2TsE'})\n    check('class', 'template<typename... Ts> {key}A<Ts...>{}', {2: 'IDpE1AI2TsE'})\n    check('class', 'template<typename... Ts> {key}A<Ts...>{};', {2: 'IDpE1AI2TsE'})\n"], "sample_932": ["def test_template_parameter_pack():\n    check('function', 'template<typename... Ts> void f(Ts... ts)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts... ts, int i)',\n          {2: 'IDpE1fvDp1Tsi'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts)',\n          {2: 'IDpE1fviDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts, int j)',\n          {2: 'IDpE1fviDp1Tsi'})\n    check('function', 'template<typename... Ts> void f(Ts... ts, Ts... ts2)',\n          {2: 'IDpE1fvDp1TsDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts... ts, int i, Ts... ts2)',\n          {2: 'IDpE1fvDp1TsiDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts, Ts... ts2)',\n          {2: 'IDpE1fviDp1TsDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts, int j, Ts... ts2)',\n          {2: 'IDpE1fviDp1TsiDp1Ts'})\n"], "sample_934": ["def test_lookup_key():\n    rootSymbol = Symbol(None, None, None, None)\n    s1 = rootSymbol.add_name(ASTNestedName([ASTIdentifier(\"S1\")], rooted=False))\n    s2 = s1.add_name(ASTNestedName([ASTIdentifier(\"S2\")], rooted=False))\n    s3 = s2.add_name(ASTNestedName([ASTIdentifier(\"S3\")], rooted=False))\n    s3.add_declaration(ASTDeclaration(\"function\", \"function\", None, False))\n    assert s3.get_lookup_key().data == [\n        (ASTIdentifier(\"S1\"), None),\n        (ASTIdentifier(\"S2\"), None),\n        (ASTIdentifier(\"S3\"), None)\n    ]\n    s3.declaration = ASTDeclaration(\"function\", \"function\", None, False)\n    s3.declaration.symbol = s3\n    assert s3.get_lookup_key().data == [\n        (ASTIdentifier(\"S1\"), None),\n        (ASTIdentifier(\"S2\"), None),\n        (ASTIdentifier(\"S3\"), s3.declaration.get_newest_id())\n    ]\n    s2.declaration = ASTDeclaration(\"class\", \"class\", None, False)\n    s2.declaration.symbol = s2\n    assert s3.get_lookup_key().data == [\n        (ASTIdentifier(\"S1\"), None),\n        (ASTIdentifier(\"S2\"), s2.declaration.get_newest_id()),\n        (ASTIdentifier(\"S3\"), s3.declaration.get_newest_id())\n    ]\n"], "sample_948": ["def test_template_parameter_pack():\n    check('function', 'template<typename... Ts> void f(Ts... ts)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts... ts, int i)',\n          {2: 'IDpE1fvDp1Tsii'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts)',\n          {2: 'IDpE1fviDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts... ts, int i, Ts... ts2)',\n          {2: 'IDpE1fvDp1TsiDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts, int j, Ts... ts2)',\n          {2: 'IDpE1fviDp1TsiDp1Ts'})\n"], "sample_935": ["def test_template_parameter_pack():\n    check('function', 'template<typename... Ts> void f(Ts... ts)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts... ts, int i)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts, int j)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts... ts, int i, Ts... ts2)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts, int j, Ts... ts2)',\n          {2: 'IDpE1fvDp1Ts'})\n"], "sample_959": ["def test_domain_cpp_parse_template_introduction():\n    check('class', 'abc::ns::foo{{id_0, id_1, id_2}} {key}xyz::bar',\n          {2: 'I000EXN3abc2ns3fooEI4id_04id_14id_2EEN3xyz3barE'})\n    check('class', 'abc::ns::foo{{id_0, id_1, ...id_2}} {key}xyz::bar',\n          {2: 'I00DpEXN3abc2ns3fooEI4id_04id_1sp4id_2EEN3xyz3barE'})\n    check('class', 'abc::ns::foo{{id_0, id_1, id_2}} {key}xyz::bar<id_0, id_1, id_2>',\n          {2: 'I000EXN3abc2ns3fooEI4id_04id_14id_2EEN3xyz3barI4id_04id_14id_2EE'})\n    check('class', 'abc::ns::foo{{id_0, id_1, ...id_2}} {key}xyz::bar<id_0, id_1, id_2...>',\n          {2: 'I00DpEXN3abc2ns3fooEI4id_04id_1sp4id_2EEN3xyz3barI4id_04id_1Dp4id_2EE'})\n\n    check('type', 'abc::ns::foo{{id_0, id_1, id_2}} {key}xyz::bar = ghi::qux',\n          {2: 'I000EXN3abc2ns3fooEI4id_04id_14id_2EEN3xyz3barE'}, key='using')\n    check('type', 'abc::ns::foo{{id_0, id_1, ...id_2}} {key}xyz::bar = ghi::qux',\n          {2: 'I00DpEXN3abc2ns3fooEI4id_04id_1sp4id_2EEN3xyz3barE'}, key='using')\n    check('function', 'abc::ns::foo{id_0, id_1, id_2} void xyz::bar"], "sample_994": ["def test_Float_hash():\n    assert hash(Float(1.0)) == hash(Float(1.0))\n    assert hash(Float(1.0)) != hash(Float(1.1))\n    assert hash(Float(1.0)) != hash(Float(-1.0))\n    assert hash(Float(1.0)) != hash(Float(1.0, 3))\n"], "sample_958": ["def test_domain_cpp_parse_template_parameter_pack(app):\n    text = (\".. cpp:class:: A\\n\"\n            \"   .. cpp:template-parameter:: Args\\n\"\n            \"      A description of the parameter pack.\\n\"\n            \"   .. cpp:template-parameter:: typename... Ts\\n\"\n            \"      A description of the parameter pack.\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (desc, desc, desc))\n    assert_node(doctree[0], desc, objtype='class', desctype='class', domain='cpp')\n    assert_node(doctree[1], desc, objtype='templateParam', desctype='templateParam', domain='cpp')\n    assert_node(doctree[2], desc, objtype='templateParam', desctype='templateParam', domain='cpp')\n"], "sample_995": ["def test_mod_inverse_finite_field():\n    F = Rational(1, 5)\n    assert mod_inverse(2, F) == 3\n    assert mod_inverse(3, F) == 2\n    assert mod_inverse(4, F) == 4\n    raises(ValueError, lambda: mod_inverse(5, F))\n    raises(ValueError, lambda: mod_inverse(0, F))\n"], "sample_1002": ["def test_issue_21462():\n    assert Integer(1).epsilon_eq(1.0)\n    assert Integer(1).epsilon_eq(1.000000000000001)\n    assert not Integer(1).epsilon_eq(1.00000000000001)\n    assert Float(1.0).epsilon_eq(1)\n    assert Float(1.000000000000001).epsilon_eq(1)\n    assert not Float(1.00000000000001).epsilon_eq(1)\n"], "sample_1010": ["def test_latex_Tensor():\n    from sympy.tensor.tensor import TensorIndexType, TensorHead, Tensor\n    Lorentz = TensorIndexType('Lorentz', dummy_name='L')\n    mu, nu = Lorentz.indices('mu nu')\n    A = TensorHead('A', [Lorentz])\n    B = TensorHead('B', [Lorentz]*2)\n    assert latex(A(mu)) == r\"A_{\\mu}\"\n    assert latex(A(mu)*B(nu, -mu)) == r\"A^{\\mu} B_{\\mu \\nu}\"\n    assert latex(A(mu)*B(-mu, nu)) == r\"A^{\\mu} B_{\\mu \\nu}\"\n    assert latex(A(mu)*B(nu, mu)) == r\"A_{\\mu} B^{\\mu \\nu}\"\n    assert latex(A(mu)*B(mu, nu)) == r\"A_{\\mu} B^{\\mu \\nu}\"\n    assert latex(A(mu)*B(-nu, mu)) == r\"A_{\\mu} B^{\\nu \\mu}\"\n    assert latex(A(mu)*B(mu, -nu)) == r\"A_{\\mu} B^{\\nu \\mu}\"\n    assert latex(A(mu)*B(nu, -mu)) == r\"A^{\\mu} B_{\\nu \\mu}\"\n    assert latex(A(mu)*B(-nu, -mu)) == r\"A^{\\mu} B_{\\nu \\mu}\"\n    assert latex(A(mu)*B(-mu, -nu)) == r\"A^{\\mu} B_{\\mu \\nu}\"\n    assert latex(A(mu)*B(mu, nu)) == r\"A_{\\mu} B^{\\mu \\nu}\"\n    assert latex(A(mu)*B(nu, mu)) == r\"A_{\\mu} B^{\\mu \\nu}\"\n    assert latex(A(mu)*B(-mu, nu)) == r\"A^{\\mu} B_{\\mu \\nu}\"\n    assert latex(A(mu)*B(nu, -mu)) == r\"A^{\\mu} B_{\\mu \\nu}\"\n    assert latex(A(mu)*B(-nu, mu)) == r\"A_{\\mu} B^{\\nu \\mu}\"\n    assert latex(A(mu)*B(mu, -nu)) == r\"A_{\\mu} B^{\\nu \\mu}\"\n    assert latex(A(mu)*B(-nu, -mu)) == r\"A^{\\mu} B"], "sample_1005": ["def test_issue_19641():\n    from sympy.tensor.array import MutableDenseNDimArray\n    arr = MutableDenseNDimArray([1, 2, 3])\n    assert latex(arr) == r'\\left[1, \\  2, \\  3\\right]'\n"], "sample_1045": ["def test_issue_16449():\n    assert Integer(2).invert(5) == 3\n    assert Integer(2).invert(S(5)/2) == S.Half\n    assert Integer(2).invert(5.) == 0.5\n    assert Integer(2).invert(S(5)) == 3\n    assert Integer(2.).invert(5) == 0.5\n    assert Integer(sqrt(2)).invert(5) == 1/sqrt(2)\n    assert Integer(sqrt(2)).invert(sqrt(3)) == 1/sqrt(2)\n    assert Integer(2).invert(S.Half) == 1\n    assert Integer(2).invert(S(3)/7) == 7/3\n"], "sample_1024": ["def test_Float_precision_rounding():\n    assert Float('1.12345678901234567890', precision=53)._prec == 53\n    assert Float('1.12345678901234567890', precision=100)._prec == 100\n    assert Float('1.12345678901234567890', precision=1000)._prec == 1000\n    assert Float('1.12345678901234567890', dps=15)._prec == 53\n    assert Float('1.12345678901234567890', dps=30)._prec == 106\n    assert Float('1.12345678901234567890', dps=100)._prec == 346\n"], "sample_1027": ["def test_issue_14364():\n    assert gcd(S(6)*(1 + sqrt(3))/5, S(3)*(1 + sqrt(3))/10) == S(3)/10 * (1 + sqrt(3))\n    assert gcd(sqrt(5)*S(4)/7, sqrt(5)*S(2)/3) == sqrt(5)*S(2)/21\n\n    assert lcm(S(2)/3*sqrt(3), S(5)/6*sqrt(3)) == S(10)*sqrt(3)/3\n    assert lcm(3*sqrt(3), S(4)/sqrt(3)) == 12*sqrt(3)\n    assert lcm(S(5)*(1 + 2**(S(1)/3))/6, S(3)*(1 + 2**(S(1)/3))/8) == S(15)/2 * (1 + 2**(S(1)/3))\n\n    assert gcd(S(2)/3*sqrt(3), S(5)/6/sqrt(3)) == sqrt(3)/18\n    assert gcd(S(4)*sqrt(13)/7, S(3)*sqrt(13)/14) == sqrt(13)/14\n\n    # gcd_list and lcm_list\n    assert gcd([S(2)*sqrt(47)/7, S(6)*sqrt(47)/5, S(8)*sqrt(47)/5]) == S(2)*sqrt(47)/35\n    assert gcd([S(6)*(1 + sqrt(7))/5, S(2)*(1 + sqrt(7))/7, S(4)*(1 + sqrt(7))/13]) == S(2)/455 * (1 + sqrt(7))\n    assert lcm((S(7)/sqrt(15)/2, S(5)/sqrt(15)/6, S(5)/sqrt(15)/8)) == S(35)/(2*sqrt(15))\n    assert lcm([S(5)*(2 + 2**(S(5)/7))/6, S(7)*(2 + 2**(S(5)/7))/2, S(13)*(2 + 2**(S(5)/7))/4]) == S(455)/2 * (2 + 2**(S(5)/7))\n"], "sample_1046": ["def test_tensor_element():\n    L = TensorIndexType(\"L\", dim=4)\n    i, j, k, l = tensor_indices(\"i j k l\", L)\n    A = tensorhead(\"A\", [L, L], [[1], [1]])\n\n    te = TensorElement(A(i, j), {i: 2})\n    assert te.get_free_indices() == [j]\n    assert te.get_indices() == [j]\n    assert te.free == [(j, 0)]\n    assert te.dum == []\n    assert te.rank == 1\n    assert te.ext_rank == 1\n    assert te.free_args == [j]\n    assert te.free_in_args == [(j, 0, 0)]\n    assert te.coeff == 1\n    assert te.nocoeff == te\n    assert te.component == A\n    assert te.components == [A]\n    assert te.split() == [te]\n    assert te.sorted_components() == te\n    assert te.get_indices() == [j]\n    assert te.get_free_indices() == [j]\n    assert te.as_base_exp() == (te, 1)\n    assert te.substitute_indices((j, k)) == TensorElement(A(i, k), {i: 2})\n    assert te(j) == TensorElement(A(i, j), {i: 2})\n    assert te(-j) == TensorElement(A(i, -j), {i: 2})\n    assert te(k) == TensorElement(A(i, k), {i: 2})\n    assert te(-k) == TensorElement(A(i, -k), {i: 2})\n    assert te(i) == TensorElement(A(i, j), {i: 2})\n    assert te(-i) == TensorElement(A(-i, j), {i: 2})\n    assert te(i, j) == TensorElement(A(i, j), {i: 2})\n    assert te(i, -j) == TensorElement(A(i, -j), {i: 2})\n    assert te(-i, j) == TensorElement(A(-i, j), {i: 2})\n    assert te(-i, -j) == TensorElement(A(-i, -j), {i: 2})\n    assert te(i, k) == TensorElement(A(i, k), {i: 2})\n    assert te(i, -k) == TensorElement(A(i"], "sample_1053": ["def test_mod_inverse_with_rational():\n    assert mod_inverse(Rational(3, 5), 11) == 4\n    assert mod_inverse(Rational(5, 3), 11) == 9\n    assert mod_inverse(Rational(21124921, 521512), 521512) == 7713\n    assert mod_inverse(Rational(124215421, 5125), 5125) == 2981\n    assert mod_inverse(Rational(214, 12515), 12515) == 1579\n    assert mod_inverse(Rational(5823991, 3299), 3299) == 1442\n    assert mod_inverse(Rational(123, 44), 44) == 39\n    assert mod_inverse(Rational(2, 3), 5) == 3\n    assert mod_inverse(Rational(-2, 3), 5) == 2\n    assert mod_inverse(Rational(2, -3), 5) == -2\n    assert mod_inverse(Rational(-2, -3), 5) == -3\n    assert mod_inverse(Rational(-3, -7), 7) == -5\n"], "sample_1059": ["def test_jacobi_normalized():\n    n = Symbol(\"n\")\n    a = Symbol(\"a\")\n    b = Symbol(\"b\")\n\n    assert jacobi_normalized(n, a, b, x) == \\\n           (jacobi(n, a, b, x)/sqrt(2**(a + b + 1)*gamma(a + n + 1)*gamma(b + n + 1)\n                                    /((a + b + 2*n + 1)*factorial(n)*gamma(a + b + n + 1))))\n    assert jacobi_normalized(0, a, b, x) == 1/sqrt(2**(a + b + 1)*gamma(a + 1)*gamma(b + 1)\n                                                   /((a + 1)*gamma(a + b + 1)))\n    assert jacobi_normalized(1, a, b, x) == (a/2 - b/2 + x*(a/2 + b/2 + 1))/sqrt(2**(a + b + 2)*\n                                                                                gamma(a + 2)*gamma(b + 2)\n                                                                                /((a + b + 3)*2*gamma(a + b + 2)))\n"], "sample_1085": ["def test_issue_16458():\n    assert unchanged(Integer, 1)\n    assert unchanged(Rational, 1, 2)\n    assert unchanged(Float, 1.0)\n"], "sample_1074": ["def test_polycyclic_group():\n    G = AlternatingGroup(4)\n    P = G.polycyclic_group()\n    assert P.order() == G.order()\n    assert P.is_polycyclic\n"], "sample_1090": ["def test_pretty():\n    with evaluate(False):\n        assert pretty(oo - oo, use_unicode=False) == 'oo - oo'\n        assert pretty(5 - oo, use_unicode=False) == '-oo + 5'\n        assert pretty(oo - 5, use_unicode=False) == 'oo - 5'\n        assert pretty(oo + 5, use_unicode=False) == 'oo + 5'\n        assert pretty(5 + oo, use_unicode=False) == 'oo + 5'\n        assert pretty(-oo + 5, use_unicode=False) == '-oo + 5'\n        assert pretty(-5 - oo, use_unicode=False) == '-oo - 5'\n        assert pretty(nan, use_unicode=False) == 'nan'\n"], "sample_1102": ["def test_issue_19367():\n    x = Symbol('x')\n    p = Poly(x**2 + 1, x)\n    assert p.as_expr().coeff(x) == 0\n    assert p.as_expr().coeff(x, 0) == 1\n    assert p.as_expr().coeff(x, 1) == 0\n    assert p.as_expr().coeff(x, 2) == 1\n    assert p.as_expr().coeff(x, 3) == 0\n"], "sample_1115": ["def test_tensor_element():\n    Lorentz = TensorIndexType(\"Lorentz\", dummy_name=\"L\")\n    i, j, k, l = tensor_indices(\"i j k l\", Lorentz)\n    A = TensorHead(\"A\", [Lorentz]*2)\n    te = TensorElement(A(i, j), {i: 2})\n    assert te.get_free_indices() == [j]\n    assert te.get_indices() == [j]\n    assert te.free_args == [j]\n    assert te.free == [(j, 0)]\n    assert te.dum == []\n    assert te.coeff == 1\n    assert te.nocoeff == te\n    assert te.component == A\n    assert te.components == [A]\n    assert te.rank == 1\n    assert te.ext_rank == 1\n    assert te.free_in_args == [(j, 0, 0)]\n    assert te.dum_in_args == []\n    assert te._get_free_indices_set() == {j}\n    assert te._get_dummy_indices_set() == set()\n    assert te._get_indices_set() == {j}\n    assert te._replace_indices({j: k}) == TensorElement(A(i, k), {i: 2})\n    assert te._extract_data({A(i, j): [[1, 2], [3, 4]]}) == ([j], Array([3, 4]))\n"], "sample_1136": ["def test_issue_20427():\n    f = Poly(-117968192370600*18**(S(1)/3)/(217603955769048*(24201 +\n        253*sqrt(9165))**(S(1)/3) + 2273005839412*sqrt(9165)*(24201 +\n        253*sqrt(9165))**(S(1)/3)) - 15720318185*2**(S(2)/3)*3**(S(1)/3)*(24201\n        + 253*sqrt(9165))**(S(2)/3)/(217603955769048*(24201 + 253*sqrt(9165))**\n        (S(1)/3) + 2273005839412*sqrt(9165)*(24201 + 253*sqrt(9165))**(S(1)/3))\n        + 15720318185*12**(S(1)/3)*(24201 + 253*sqrt(9165))**(S(2)/3)/(\n        217603955769048*(24201 + 253*sqrt(9165))**(S(1)/3) + 2273005839412*\n        sqrt(9165)*(24201 + 253*sqrt(9165))**(S(1)/3)) + 117968192370600*2**(\n        S(1)/3)*3**(S(2)/3)/(217603955769048*(24201 + 253*sqrt(9165))**(S(1)/3)\n        + 2273005839412*sqrt(9165)*(24201 + 253*sqrt(9165))**(S(1)/3)), x)\n    assert f == Poly(0, x, domain='EX')\n"], "sample_1127": ["def test_is_alternating():\n    a = Permutation(0, 1, 2)\n    b = Permutation(0, 1, size=3)\n    assert PermutationGroup(a, b).is_alternating == True\n\n    a = Permutation(0, 2, 1)\n    b = Permutation(1, 2, size=3)\n    assert PermutationGroup(a, b).is_alternating == True\n\n    a = Permutation(0, 1, 2, 3)\n    b = Permutation(0, 3)(1, 2)\n    assert PermutationGroup(a, b).is_alternating == False\n"], "sample_1134": ["def test_latex_parenthesize_super():\n    x = Symbol('x')\n    assert latex(x**2, parenthesize_super=True) == r\"x^{2}\"\n    assert latex(x**2, parenthesize_super=False) == r\"x^{2}\"\n    assert latex(x**(2+3), parenthesize_super=True) == r\"x^{2 + 3}\"\n    assert latex(x**(2+3), parenthesize_super=False) == r\"x^{2 + 3}\"\n    assert latex(x**(-2), parenthesize_super=True) == r\"x^{-2}\"\n    assert latex(x**(-2), parenthesize_super=False) == r\"x^{-2}\"\n    assert latex(x**(-2+3), parenthesize_super=True) == r\"x^{-2 + 3}\"\n    assert latex(x**(-2+3), parenthesize_super=False) == r\"x^{-2 + 3}\"\n"], "sample_1146": ["def test_printing_latex_NDimArray():\n    assert latex(ImmutableDenseNDimArray([1, 2, 3])) == r\"\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}\"\n    assert latex(ImmutableSparseNDimArray([1, 2, 3])) == r\"\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}\"\n    assert latex(MutableDenseNDimArray([1, 2, 3])) == r\"\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}\"\n    assert latex(MutableSparseNDimArray([1, 2, 3])) == r\"\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}\"\n"], "sample_1140": ["def test_pretty_TensorProduct():\n    from sympy.tensor.tensor import TensorProduct\n    from sympy.tensor.tensor import TensorIndexType\n    from sympy.tensor.tensor import tensor_indices\n    from sympy.tensor.tensor import TensorHead\n    from sympy.tensor.tensor import TensorElement\n\n    L = TensorIndexType(\"L\")\n    i, j, k = tensor_indices(\"i j k\", L)\n\n    A, B, C, D = tensor_heads(\"A B C D\", [L])\n\n    H = TensorHead(\"H\", [L, L])\n\n    expr = TensorProduct(A(i), B(j))\n    ascii_str = \\"], "sample_1143": ["def test_issue_21553():\n    assert Float('1.0', 3).epsilon_eq(Float('1.0001', 3), 1e-3) is True\n    assert Float('1.0', 3).epsilon_eq(Float('1.0001', 3), 1e-4) is False\n"], "sample_1147": ["def test_printing_latex_NDimArray():\n    assert latex(ImmutableDenseNDimArray([1, 2, 3])) == r\"\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}\"\n    assert latex(ImmutableSparseNDimArray({0: 1, 2: 3}, (3,))) == r\"\\begin{pmatrix} 1 \\\\ 0 \\\\ 3 \\end{pmatrix}\"\n    assert latex(MutableDenseNDimArray([1, 2, 3])) == r\"\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}\"\n    assert latex(MutableSparseNDimArray({0: 1, 2: 3}, (3,))) == r\"\\begin{pmatrix} 1 \\\\ 0 \\\\ 3 \\end{pmatrix}\"\n"], "sample_1167": ["def test_printing_latex_array_expressions_with_symbolic_shape():\n    n, m = symbols('n m', integer=True)\n    assert latex(ArraySymbol(\"A\", n, m)) == \"A\"\n    assert latex(ArrayElement(\"A\", (n, m))) == \"{{A}_{n, m}}\"\n"], "sample_1176": ["def test_issue_21457():\n    assert Float('1.0', precision=53).epsilon_eq(Float('1.0', precision=53), 1e-15)\n    assert not Float('1.0', precision=53).epsilon_eq(Float('1.1', precision=53), 1e-15)\n"], "sample_1175": ["def test_pretty_printing_of_vector_integrals():\n    from sympy.vector import CoordSys3D, ParametricRegion, ParametricIntegral\n    C = CoordSys3D('C', transformation='spherical')\n    r, theta, phi = C.base_scalars()\n    param_region = ParametricRegion((r, 0, 1), (theta, 0, pi), (phi, 0, 2*pi))\n    integral = ParametricIntegral(C.x, param_region)\n    assert pretty(integral) == \\\n    '  1  pi  2*pi          \\n'\\\n    '  /   /   /            \\n'\\\n    ' |   |   |             \\n'\\\n    ' |   |   |  x          \\n'\\\n    ' |   |   |  C          \\n'\\\n    ' |   |   |             \\n'\\\n    '/   /   /             \\n'\\\n    ' 0  0   0             '\n    assert upretty(integral) == \\\n    ' 1  \u03c0  2\u22c5\u03c0          \\n'\\\n    ' \u2320  \u2320  \u2320            \\n'\\\n    '\u23ae  \u23ae  \u23ae             \\n'\\\n    '\u23ae  \u23ae  \u23ae  x          \\n'\\\n    '\u23ae  \u23ae  \u23ae  C          \\n'\\\n    '\u23ae  \u23ae  \u23ae             \\n'\\\n    '\u2321  \u2321  \u2321             \\n'\\\n    '0  0   0             '\n"], "sample_1206": ["def test_issue_21855():\n    assert Integer(1).invert(5) == 1\n    assert Integer(2).invert(5) == 3\n    assert Integer(3).invert(5) == 2\n    assert Integer(4).invert(5) == 4\n    assert Integer(6).invert(5) == 1\n    assert Integer(7).invert(5) == 3\n    assert Integer(8).invert(5) == 2\n    assert Integer(9).invert(5) == 4\n"], "sample_1202": ["def test_issue_16444():\n    assert S(2)**S(3) == 8\n    assert S(2)**S(-3) == Rational(1, 8)\n    assert S(-2)**S(3) == -8\n    assert S(-2)**S(-3) == Rational(-1, 8)\n"], "sample_1204": ["def test_polycyclic_group():\n    G = PermutationGroup(Permutation(0, 1, 2), Permutation(0, 1))\n    P = G.polycyclic_group()\n    assert P == G\n    G = PermutationGroup(Permutation(0, 1, 2, 3), Permutation(0, 2))\n    P = G.polycyclic_group()\n    assert P == G\n"]}, "raw_scored_generations": {"sample_1": [false], "sample_0": [false], "sample_3": [true], "sample_2": [false], "sample_4": [false], "sample_5": [false], "sample_6": [false], "sample_7": [true], "sample_8": [false], "sample_9": [false], "sample_10": [false], "sample_11": [false], "sample_12": [false], "sample_13": [true], "sample_14": [false], "sample_15": [true], "sample_16": [false], "sample_17": [false], "sample_18": [false], "sample_19": [false], "sample_20": [false], "sample_21": [false], "sample_22": [false], "sample_23": [false], "sample_24": [false], "sample_25": [false], "sample_26": [false], "sample_27": [false], "sample_28": [false], "sample_29": [false], "sample_30": [false], "sample_31": [false], "sample_32": [false], "sample_33": [false], "sample_34": [false], "sample_35": [false], "sample_36": [true], "sample_37": [false], "sample_38": [false], "sample_39": [false], "sample_40": [true], "sample_41": [false], "sample_42": [true], "sample_43": [false], "sample_44": [true], "sample_45": [false], "sample_46": [false], "sample_47": [true], "sample_48": [true], "sample_49": [true], "sample_50": [true], "sample_51": [true], "sample_52": [true], "sample_54": [true], "sample_53": [true], "sample_55": [false], "sample_58": [true], "sample_56": [true], "sample_57": [true], "sample_59": [false], "sample_60": [false], "sample_61": [false], "sample_62": [false], "sample_63": [true], "sample_64": [true], "sample_65": [true], "sample_67": [false], "sample_66": [true], "sample_68": [false], "sample_69": [false], "sample_70": [true], "sample_71": [true], "sample_72": [true], "sample_73": [false], "sample_75": [false], "sample_74": [true], "sample_76": [true], "sample_77": [true], "sample_78": [true], "sample_79": [false], "sample_80": [true], "sample_82": [true], "sample_81": [false], "sample_83": [false], "sample_85": [true], "sample_84": [false], "sample_86": [true], "sample_88": [true], "sample_87": [false], "sample_89": [false], "sample_90": [false], "sample_91": [true], "sample_92": [false], "sample_93": [true], "sample_94": [false], "sample_95": [false], "sample_98": [false], "sample_96": [true], "sample_99": [false], "sample_97": [false], "sample_100": [false], "sample_102": [true], "sample_101": [true], "sample_103": [true], "sample_104": [false], "sample_107": [false], "sample_106": [true], "sample_105": [false], "sample_108": [false], "sample_109": [true], "sample_111": [true], "sample_110": [false], "sample_112": [true], "sample_113": [false], "sample_114": [true], "sample_115": [true], "sample_116": [true], "sample_117": [false], "sample_118": [true], "sample_119": [true], "sample_120": [true], "sample_121": [false], "sample_122": [false], "sample_123": [false], "sample_124": [false], "sample_125": [true], "sample_126": [true], "sample_127": [true], "sample_128": [false], "sample_129": [false], "sample_130": [true], "sample_131": [true], "sample_132": [true], "sample_133": [true], "sample_135": [true], "sample_134": [true], "sample_136": [true], "sample_139": [true], "sample_137": [true], "sample_138": [false], "sample_140": [false], "sample_141": [false], "sample_142": [true], "sample_143": [true], "sample_144": [true], "sample_145": [true], "sample_146": [true], "sample_147": [true], "sample_148": [true], "sample_151": [true], "sample_149": [true], "sample_152": [true], "sample_150": [false], "sample_153": [false], "sample_154": [true], "sample_155": [true], "sample_156": [true], "sample_157": [false], "sample_158": [true], "sample_159": [true], "sample_160": [true], "sample_161": [false], "sample_162": [true], "sample_163": [false], "sample_164": [false], "sample_165": [false], "sample_166": [true], "sample_167": [false], "sample_168": [true], "sample_169": [true], "sample_171": [true], "sample_170": [true], "sample_172": [true], "sample_173": [false], "sample_174": [false], "sample_175": [true], "sample_176": [true], "sample_177": [true], "sample_178": [true], "sample_180": [true], "sample_179": [true], "sample_182": [true], "sample_181": [true], "sample_183": [false], "sample_184": [true], "sample_185": [false], "sample_186": [true], "sample_187": [true], "sample_188": [true], "sample_189": [false], "sample_190": [true], "sample_191": [false], "sample_192": [true], "sample_193": [true], "sample_194": [true], "sample_195": [true], "sample_196": [false], "sample_198": [true], "sample_197": [true], "sample_199": [true], "sample_200": [true], "sample_201": [true], "sample_202": [true], "sample_203": [true], "sample_204": [true], "sample_205": [true], "sample_206": [true], "sample_207": [true], "sample_208": [true], "sample_209": [false], "sample_210": [false], "sample_211": [false], "sample_213": [false], "sample_212": [false], "sample_214": [true], "sample_215": [false], "sample_216": [true], "sample_217": [true], "sample_218": [false], "sample_219": [false], "sample_220": [true], "sample_221": [true], "sample_222": [true], "sample_223": [true], "sample_224": [true], "sample_225": [false], "sample_226": [false], "sample_227": [true], "sample_228": [true], "sample_229": [true], "sample_230": [true], "sample_231": [true], "sample_232": [true], "sample_233": [true], "sample_234": [true], "sample_235": [true], "sample_236": [true], "sample_237": [true], "sample_238": [true], "sample_239": [true], "sample_240": [true], "sample_241": [false], "sample_242": [false], "sample_243": [true], "sample_244": [true], "sample_245": [true], "sample_246": [true], "sample_247": [true], "sample_248": [true], "sample_249": [true], "sample_250": [true], "sample_251": [true], "sample_252": [false], "sample_253": [false], "sample_254": [false], "sample_256": [false], "sample_255": [false], "sample_257": [true], "sample_258": [true], "sample_259": [true], "sample_260": [true], "sample_261": [true], "sample_262": [false], "sample_263": [true], "sample_264": [true], "sample_265": [true], "sample_266": [true], "sample_267": [false], "sample_268": [false], "sample_269": [true], "sample_270": [false], "sample_271": [false], "sample_272": [true], "sample_273": [false], "sample_274": [false], "sample_275": [false], "sample_276": [false], "sample_277": [true], "sample_278": [false], "sample_279": [true], "sample_280": [true], "sample_281": [true], "sample_282": [true], "sample_283": [true], "sample_284": [false], "sample_285": [true], "sample_286": [false], "sample_287": [true], "sample_288": [false], "sample_289": [false], "sample_290": [false], "sample_291": [false], "sample_292": [true], "sample_293": [false], "sample_294": [true], "sample_295": [false], "sample_296": [true], "sample_297": [true], "sample_298": [true], "sample_299": [true], "sample_300": [true], "sample_301": [false], "sample_302": [true], "sample_303": [true], "sample_304": [false], "sample_305": [false], "sample_306": [true], "sample_307": [true], "sample_308": [true], "sample_309": [false], "sample_310": [false], "sample_312": [true], "sample_311": [false], "sample_313": [true], "sample_314": [true], "sample_315": [true], "sample_316": [true], "sample_317": [true], "sample_318": [false], "sample_319": [true], "sample_320": [true], "sample_321": [true], "sample_322": [true], "sample_323": [true], "sample_324": [true], "sample_325": [true], "sample_326": [true], "sample_327": [true], "sample_328": [true], "sample_329": [true], "sample_330": [false], "sample_331": [true], "sample_332": [true], "sample_333": [true], "sample_334": [true], "sample_335": [true], "sample_336": [false], "sample_337": [true], "sample_338": [true], "sample_339": [false], "sample_340": [true], "sample_341": [true], "sample_342": [true], "sample_343": [true], "sample_344": [true], "sample_345": [false], "sample_346": [false], "sample_347": [true], "sample_348": [false], "sample_349": [true], "sample_350": [true], "sample_351": [true], "sample_352": [false], "sample_353": [false], "sample_354": [false], "sample_355": [false], "sample_356": [true], "sample_357": [true], "sample_358": [false], "sample_359": [true], "sample_360": [false], "sample_361": [true], "sample_362": [true], "sample_363": [true], "sample_364": [true], "sample_365": [true], "sample_366": [true], "sample_367": [false], "sample_368": [true], "sample_369": [true], "sample_370": [false], "sample_371": [false], "sample_372": [false], "sample_373": [false], "sample_374": [false], "sample_375": [true], "sample_376": [true], "sample_377": [true], "sample_378": [true], "sample_379": [true], "sample_380": [true], "sample_381": [true], "sample_382": [false], "sample_383": [true], "sample_384": [true], "sample_385": [true], "sample_386": [true], "sample_387": [true], "sample_388": [false], "sample_389": [false], "sample_390": [true], "sample_391": [true], "sample_392": [true], "sample_393": [true], "sample_394": [false], "sample_395": [true], "sample_396": [false], "sample_397": [true], "sample_398": [false], "sample_399": [true], "sample_400": [true], "sample_401": [true], "sample_402": [true], "sample_403": [true], "sample_404": [false], "sample_405": [true], "sample_406": [false], "sample_407": [true], "sample_408": [true], "sample_409": [false], "sample_410": [true], "sample_411": [true], "sample_412": [true], "sample_413": [false], "sample_414": [true], "sample_415": [true], "sample_416": [true], "sample_417": [false], "sample_418": [true], "sample_419": [true], "sample_420": [false], "sample_421": [false], "sample_422": [false], "sample_423": [true], "sample_424": [false], "sample_425": [true], "sample_426": [true], "sample_427": [true], "sample_428": [true], "sample_429": [true], "sample_430": [true], "sample_431": [false], "sample_432": [true], "sample_433": [true], "sample_434": [false], "sample_435": [false], "sample_436": [false], "sample_437": [false], "sample_438": [true], "sample_439": [false], "sample_440": [true], "sample_441": [false], "sample_442": [true], "sample_443": [false], "sample_444": [false], "sample_445": [true], "sample_446": [false], "sample_447": [true], "sample_448": [true], "sample_449": [false], "sample_450": [true], "sample_451": [true], "sample_453": [true], "sample_452": [true], "sample_454": [false], "sample_455": [true], "sample_456": [true], "sample_457": [true], "sample_458": [false], "sample_459": [false], "sample_460": [false], "sample_461": [false], "sample_462": [true], "sample_463": [true], "sample_464": [true], "sample_465": [true], "sample_466": [true], "sample_467": [true], "sample_469": [true], "sample_468": [true], "sample_470": [true], "sample_471": [true], "sample_472": [true], "sample_473": [false], "sample_474": [false], "sample_475": [true], "sample_476": [false], "sample_477": [true], "sample_478": [true], "sample_479": [true], "sample_480": [true], "sample_481": [false], "sample_482": [false], "sample_483": [true], "sample_484": [false], "sample_485": [true], "sample_486": [true], "sample_487": [true], "sample_488": [true], "sample_489": [true], "sample_490": [true], "sample_491": [true], "sample_492": [true], "sample_493": [true], "sample_494": [true], "sample_495": [true], "sample_496": [false], "sample_497": [true], "sample_498": [false], "sample_499": [false], "sample_500": [false], "sample_501": [false], "sample_502": [true], "sample_503": [true], "sample_504": [true], "sample_505": [false], "sample_506": [false], "sample_507": [true], "sample_508": [false], "sample_509": [false], "sample_510": [true], "sample_511": [true], "sample_512": [true], "sample_513": [false], "sample_514": [true], "sample_515": [true], "sample_516": [false], "sample_517": [true], "sample_518": [true], "sample_519": [false], "sample_520": [false], "sample_521": [false], "sample_522": [false], "sample_523": [true], "sample_524": [false], "sample_525": [false], "sample_526": [false], "sample_527": [false], "sample_528": [true], "sample_529": [true], "sample_530": [false], "sample_531": [false], "sample_532": [false], "sample_533": [false], "sample_534": [true], "sample_535": [false], "sample_536": [false], "sample_537": [true], "sample_538": [true], "sample_539": [false], "sample_540": [false], "sample_541": [true], "sample_542": [true], "sample_543": [true], "sample_544": [false], "sample_545": [false], "sample_546": [true], "sample_547": [false], "sample_548": [true], "sample_549": [false], "sample_550": [false], "sample_551": [false], "sample_552": [false], "sample_553": [false], "sample_554": [true], "sample_555": [true], "sample_556": [false], "sample_557": [false], "sample_558": [true], "sample_559": [false], "sample_560": [false], "sample_561": [true], "sample_562": [false], "sample_563": [false], "sample_564": [false], "sample_565": [false], "sample_566": [false], "sample_567": [true], "sample_568": [false], "sample_569": [false], "sample_570": [false], "sample_571": [false], "sample_572": [true], "sample_573": [false], "sample_574": [false], "sample_575": [false], "sample_576": [true], "sample_577": [false], "sample_578": [false], "sample_579": [false], "sample_580": [true], "sample_581": [false], "sample_582": [false], "sample_583": [true], "sample_584": [true], "sample_585": [true], "sample_586": [false], "sample_587": [false], "sample_588": [false], "sample_589": [false], "sample_590": [false], "sample_591": [false], "sample_592": [false], "sample_593": [false], "sample_594": [false], "sample_595": [false], "sample_596": [false], "sample_597": [false], "sample_598": [false], "sample_599": [false], "sample_600": [false], "sample_601": [true], "sample_602": [false], "sample_603": [false], "sample_604": [true], "sample_605": [true], "sample_606": [false], "sample_607": [false], "sample_608": [false], "sample_609": [false], "sample_610": [false], "sample_611": [false], "sample_612": [false], "sample_613": [false], "sample_614": [false], "sample_615": [false], "sample_616": [false], "sample_617": [false], "sample_618": [false], "sample_619": [true], "sample_620": [false], "sample_621": [false], "sample_622": [false], "sample_623": [false], "sample_624": [true], "sample_625": [true], "sample_626": [false], "sample_627": [false], "sample_628": [false], "sample_629": [false], "sample_630": [false], "sample_631": [false], "sample_632": [false], "sample_633": [false], "sample_634": [false], "sample_635": [false], "sample_636": [false], "sample_637": [false], "sample_638": [false], "sample_639": [false], "sample_640": [false], "sample_641": [false], "sample_642": [false], "sample_643": [false], "sample_644": [false], "sample_645": [false], "sample_646": [false], "sample_647": [false], "sample_648": [false], "sample_649": [false], "sample_650": [false], "sample_651": [false], "sample_652": [false], "sample_653": [false], "sample_654": [false], "sample_655": [false], "sample_656": [false], "sample_657": [false], "sample_658": [false], "sample_659": [false], "sample_660": [false], "sample_661": [false], "sample_662": [false], "sample_663": [false], "sample_664": [false], "sample_665": [false], "sample_666": [false], "sample_667": [false], "sample_668": [false], "sample_669": [false], "sample_670": [false], "sample_671": [false], "sample_672": [false], "sample_673": [false], "sample_674": [false], "sample_675": [false], "sample_676": [false], "sample_677": [false], "sample_678": [false], "sample_679": [false], "sample_680": [false], "sample_681": [true], "sample_682": [false], "sample_683": [false], "sample_684": [false], "sample_685": [false], "sample_686": [false], "sample_687": [false], "sample_688": [false], "sample_689": [false], "sample_690": [false], "sample_691": [false], "sample_692": [false], "sample_693": [true], "sample_694": [false], "sample_695": [false], "sample_696": [false], "sample_697": [true], "sample_698": [false], "sample_699": [false], "sample_700": [false], "sample_701": [false], "sample_702": [true], "sample_703": [false], "sample_704": [false], "sample_705": [false], "sample_706": [true], "sample_707": [false], "sample_708": [false], "sample_709": [true], "sample_710": [false], "sample_711": [false], "sample_712": [false], "sample_713": [false], "sample_714": [false], "sample_715": [false], "sample_716": [false], "sample_717": [true], "sample_718": [false], "sample_719": [true], "sample_720": [false], "sample_721": [false], "sample_722": [false], "sample_723": [false], "sample_724": [false], "sample_725": [false], "sample_726": [false], "sample_727": [false], "sample_728": [false], "sample_729": [false], "sample_730": [false], "sample_731": [true], "sample_732": [true], "sample_733": [false], "sample_734": [true], "sample_735": [true], "sample_736": [true], "sample_737": [false], "sample_738": [false], "sample_739": [false], "sample_740": [false], "sample_741": [true], "sample_742": [true], "sample_743": [false], "sample_744": [false], "sample_745": [true], "sample_746": [false], "sample_747": [false], "sample_748": [true], "sample_749": [false], "sample_750": [false], "sample_751": [false], "sample_752": [true], "sample_753": [true], "sample_754": [false], "sample_755": [false], "sample_756": [true], "sample_757": [true], "sample_758": [true], "sample_759": [true], "sample_760": [true], "sample_761": [true], "sample_762": [false], "sample_763": [true], "sample_764": [false], "sample_765": [true], "sample_766": [true], "sample_767": [false], "sample_768": [false], "sample_769": [false], "sample_770": [false], "sample_771": [false], "sample_772": [true], "sample_773": [false], "sample_774": [false], "sample_775": [false], "sample_776": [false], "sample_777": [true], "sample_778": [false], "sample_779": [false], "sample_780": [true], "sample_781": [false], "sample_782": [false], "sample_783": [true], "sample_784": [false], "sample_785": [false], "sample_786": [true], "sample_787": [true], "sample_788": [true], "sample_789": [true], "sample_790": [false], "sample_791": [true], "sample_792": [false], "sample_793": [false], "sample_794": [false], "sample_795": [false], "sample_796": [true], "sample_797": [false], "sample_798": [false], "sample_799": [false], "sample_800": [false], "sample_801": [false], "sample_802": [false], "sample_803": [false], "sample_804": [false], "sample_805": [false], "sample_806": [false], "sample_807": [false], "sample_808": [false], "sample_809": [false], "sample_810": [true], "sample_811": [false], "sample_812": [false], "sample_813": [false], "sample_814": [true], "sample_815": [true], "sample_816": [false], "sample_817": [false], "sample_818": [false], "sample_819": [true], "sample_820": [true], "sample_821": [true], "sample_822": [false], "sample_823": [false], "sample_824": [true], "sample_825": [true], "sample_826": [true], "sample_827": [false], "sample_828": [false], "sample_829": [true], "sample_830": [false], "sample_831": [false], "sample_832": [false], "sample_833": [true], "sample_834": [true], "sample_835": [true], "sample_836": [false], "sample_837": [false], "sample_838": [false], "sample_839": [false], "sample_840": [false], "sample_841": [true], "sample_842": [false], "sample_843": [true], "sample_844": [true], "sample_845": [false], "sample_846": [false], "sample_847": [true], "sample_848": [true], "sample_849": [false], "sample_850": [false], "sample_851": [false], "sample_852": [false], "sample_853": [false], "sample_854": [true], "sample_855": [true], "sample_856": [false], "sample_857": [false], "sample_858": [true], "sample_859": [true], "sample_860": [false], "sample_861": [false], "sample_862": [true], "sample_863": [true], "sample_864": [false], "sample_865": [true], "sample_866": [false], "sample_867": [true], "sample_868": [false], "sample_869": [false], "sample_870": [true], "sample_871": [false], "sample_872": [true], "sample_873": [false], "sample_874": [false], "sample_875": [true], "sample_876": [true], "sample_877": [false], "sample_878": [false], "sample_879": [true], "sample_880": [false], "sample_881": [false], "sample_882": [false], "sample_883": [false], "sample_884": [true], "sample_885": [true], "sample_886": [true], "sample_887": [false], "sample_888": [false], "sample_889": [false], "sample_890": [false], "sample_891": [true], "sample_892": [true], "sample_893": [false], "sample_894": [false], "sample_895": [false], "sample_896": [true], "sample_897": [true], "sample_898": [false], "sample_899": [false], "sample_900": [true], "sample_901": [false], "sample_902": [true], "sample_903": [false], "sample_904": [false], "sample_905": [false], "sample_906": [false], "sample_907": [false], "sample_908": [false], "sample_909": [false], "sample_910": [false], "sample_911": [false], "sample_912": [false], "sample_913": [false], "sample_914": [false], "sample_915": [false], "sample_916": [false], "sample_917": [false], "sample_918": [false], "sample_919": [false], "sample_920": [false], "sample_921": [false], "sample_922": [true], "sample_923": [false], "sample_924": [false], "sample_925": [false], "sample_926": [false], "sample_927": [false], "sample_928": [false], "sample_929": [true], "sample_930": [false], "sample_931": [false], "sample_932": [false], "sample_933": [false], "sample_934": [false], "sample_935": [false], "sample_936": [false], "sample_937": [false], "sample_938": [false], "sample_939": [false], "sample_940": [false], "sample_941": [true], "sample_942": [true], "sample_943": [false], "sample_944": [true], "sample_945": [false], "sample_946": [true], "sample_947": [false], "sample_948": [false], "sample_949": [false], "sample_950": [false], "sample_951": [false], "sample_952": [true], "sample_953": [false], "sample_954": [false], "sample_955": [false], "sample_956": [false], "sample_957": [true], "sample_958": [false], "sample_959": [false], "sample_960": [false], "sample_961": [false], "sample_962": [false], "sample_963": [true], "sample_964": [false], "sample_965": [false], "sample_966": [false], "sample_967": [false], "sample_968": [true], "sample_969": [false], "sample_970": [false], "sample_971": [false], "sample_972": [true], "sample_973": [false], "sample_974": [true], "sample_975": [false], "sample_976": [true], "sample_977": [true], "sample_978": [true], "sample_979": [false], "sample_980": [false], "sample_981": [true], "sample_982": [false], "sample_983": [true], "sample_984": [false], "sample_985": [false], "sample_986": [true], "sample_987": [true], "sample_988": [true], "sample_989": [false], "sample_990": [false], "sample_991": [false], "sample_992": [false], "sample_993": [false], "sample_994": [true], "sample_995": [false], "sample_996": [false], "sample_997": [false], "sample_998": [true], "sample_999": [false], "sample_1000": [false], "sample_1001": [true], "sample_1002": [false], "sample_1003": [false], "sample_1004": [false], "sample_1005": [false], "sample_1006": [false], "sample_1007": [false], "sample_1008": [true], "sample_1009": [false], "sample_1010": [false], "sample_1011": [false], "sample_1012": [true], "sample_1013": [false], "sample_1014": [true], "sample_1015": [true], "sample_1016": [true], "sample_1017": [true], "sample_1018": [false], "sample_1019": [false], "sample_1020": [false], "sample_1021": [true], "sample_1022": [false], "sample_1023": [true], "sample_1024": [false], "sample_1025": [true], "sample_1026": [true], "sample_1027": [true], "sample_1028": [false], "sample_1029": [false], "sample_1030": [false], "sample_1031": [false], "sample_1032": [true], "sample_1033": [false], "sample_1034": [false], "sample_1035": [false], "sample_1036": [false], "sample_1037": [true], "sample_1038": [false], "sample_1039": [false], "sample_1040": [true], "sample_1041": [false], "sample_1042": [false], "sample_1043": [true], "sample_1044": [false], "sample_1045": [false], "sample_1046": [false], "sample_1047": [false], "sample_1048": [false], "sample_1049": [true], "sample_1050": [true], "sample_1051": [false], "sample_1052": [false], "sample_1053": [false], "sample_1054": [false], "sample_1055": [true], "sample_1056": [false], "sample_1057": [false], "sample_1058": [false], "sample_1059": [false], "sample_1060": [true], "sample_1061": [false], "sample_1062": [false], "sample_1063": [true], "sample_1064": [true], "sample_1065": [false], "sample_1066": [false], "sample_1067": [false], "sample_1068": [true], "sample_1069": [false], "sample_1070": [false], "sample_1071": [false], "sample_1072": [false], "sample_1073": [true], "sample_1074": [false], "sample_1075": [false], "sample_1076": [false], "sample_1077": [false], "sample_1078": [false], "sample_1079": [true], "sample_1080": [true], "sample_1081": [false], "sample_1082": [false], "sample_1083": [false], "sample_1084": [false], "sample_1085": [false], "sample_1086": [false], "sample_1087": [false], "sample_1088": [false], "sample_1089": [false], "sample_1090": [false], "sample_1091": [true], "sample_1092": [false], "sample_1093": [false], "sample_1094": [false], "sample_1095": [false], "sample_1096": [true], "sample_1097": [false], "sample_1098": [false], "sample_1099": [false], "sample_1100": [false], "sample_1101": [true], "sample_1102": [true], "sample_1103": [false], "sample_1104": [true], "sample_1105": [false], "sample_1106": [false], "sample_1107": [false], "sample_1108": [false], "sample_1109": [true], "sample_1110": [false], "sample_1111": [false], "sample_1112": [true], "sample_1113": [true], "sample_1114": [false], "sample_1115": [false], "sample_1116": [true], "sample_1117": [true], "sample_1118": [false], "sample_1119": [true], "sample_1120": [false], "sample_1121": [true], "sample_1122": [false], "sample_1123": [false], "sample_1124": [false], "sample_1125": [false], "sample_1126": [true], "sample_1127": [false], "sample_1128": [true], "sample_1129": [false], "sample_1130": [true], "sample_1131": [false], "sample_1132": [false], "sample_1133": [false], "sample_1134": [false], "sample_1135": [true], "sample_1136": [true], "sample_1137": [false], "sample_1138": [false], "sample_1139": [false], "sample_1140": [false], "sample_1141": [true], "sample_1142": [false], "sample_1143": [false], "sample_1144": [false], "sample_1145": [false], "sample_1146": [false], "sample_1147": [false], "sample_1148": [false], "sample_1149": [true], "sample_1150": [true], "sample_1151": [false], "sample_1152": [false], "sample_1153": [false], "sample_1154": [true], "sample_1155": [false], "sample_1156": [true], "sample_1157": [false], "sample_1158": [true], "sample_1159": [true], "sample_1160": [false], "sample_1161": [false], "sample_1162": [false], "sample_1163": [true], "sample_1164": [false], "sample_1165": [false], "sample_1166": [false], "sample_1167": [true], "sample_1168": [false], "sample_1169": [false], "sample_1170": [false], "sample_1171": [true], "sample_1172": [false], "sample_1173": [false], "sample_1174": [true], "sample_1175": [false], "sample_1176": [true], "sample_1177": [true], "sample_1178": [false], "sample_1179": [false], "sample_1180": [false], "sample_1181": [true], "sample_1182": [false], "sample_1183": [false], "sample_1184": [true], "sample_1185": [false], "sample_1186": [true], "sample_1187": [true], "sample_1188": [true], "sample_1189": [true], "sample_1190": [false], "sample_1191": [false], "sample_1192": [true], "sample_1193": [false], "sample_1194": [true], "sample_1195": [false], "sample_1196": [false], "sample_1197": [false], "sample_1198": [false], "sample_1199": [true], "sample_1200": [false], "sample_1201": [false], "sample_1202": [true], "sample_1203": [false], "sample_1204": [false], "sample_1205": [true], "sample_1206": [true], "sample_1207": [false], "sample_1208": [false], "sample_1209": [false]}}