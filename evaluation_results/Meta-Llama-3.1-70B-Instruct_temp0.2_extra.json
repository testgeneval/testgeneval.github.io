{"raw_generations": {"sample_200": ["def test_attachment_filename_encoding(self):\n    \"\"\"\n    Regression test for #14964\n    \"\"\"\n    headers = {\"Date\": \"Fri, 09 Nov 2001 01:08:47 -0000\", \"Message-ID\": \"foo\"}\n    subject, from_email, to = 'hello', 'from@example.com', 'to@example.com'\n    content = 'This is the message.'\n    msg = EmailMessage(subject, content, from_email, [to], headers=headers)\n    # Unicode in file name\n    msg.attach(\"une pi\u00e8ce jointe.pdf\", b\"%PDF-1.4.%...\", mimetype=\"application/pdf\")\n    msg.encoding = 'iso-8859-1'\n    msg_bytes = msg.message().as_bytes()\n    message = message_from_bytes(msg_bytes)\n    payload = message.get_payload()\n    self.assertEqual(payload[1].get_filename(), 'une pi\u00e8ce jointe.pdf')\n"], "sample_1007": ["def test_factorial_mod():\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True)\n\n    assert factorial(n).is_integer\n    assert factorial(n).is_positive\n    assert factorial(n).is_real\n    assert factorial(n).is_composite is None\n\n    assert factorial(0).is_integer\n    assert factorial(0).is_positive\n    assert factorial(0).is_real\n    assert factorial(0).is_composite is False\n\n    assert factorial(1).is_integer\n    assert factorial(1).is_positive\n    assert factorial(1).is_real\n    assert factorial(1).is_composite is False\n\n    assert factorial(2).is_integer\n    assert factorial(2).is_positive\n    assert factorial(2).is_real\n    assert factorial(2).is_composite is False\n\n    assert factorial(3).is_integer\n    assert factorial(3).is_positive\n    assert factorial(3).is_real\n    assert factorial(3).is_composite is False\n\n    assert factorial(4).is_integer\n    assert factorial(4).is_positive\n    assert factorial(4).is_real\n    assert factorial(4).is_composite is True\n\n    assert factorial(5).is_integer\n    assert factorial(5).is_positive\n    assert factorial(5).is_real\n    assert factorial(5).is_composite is True\n\n    assert factorial(6).is_integer\n    assert factorial(6).is_positive\n    assert factorial(6).is_real\n    assert factorial(6).is_composite is True\n\n    assert factorial(7).is_integer\n    assert factorial(7).is_positive\n    assert factorial(7).is_real\n    assert factorial(7).is_composite is True\n\n    assert factorial(8).is_integer\n    assert factorial(8).is_positive\n    assert factorial(8).is_real\n    assert factorial(8).is_composite is True\n\n    assert factorial(9).is_integer\n    assert factorial(9).is_positive\n    assert factorial(9).is_real\n    assert factorial(9).is_composite is True\n\n    assert factorial(10).is_integer\n    assert factorial(10).is_positive\n    assert factorial(10).is_real\n    assert factorial(10).is_composite is True\n\n    assert factorial(11).is_integer\n    assert factorial(11).is_positive\n   "], "sample_55": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.s1 = Section.objects.create(name='Test section')\n        cls.a1 = Article.objects.create(\n            content='<p>Middle content</p>', date=datetime.datetime(2008, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a2 = Article.objects.create(\n            content='<p>Oldest content</p>', date=datetime.datetime(2000, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a3 = Article.objects.create(\n            content='<p>Newest content</p>', date=datetime.datetime(2009, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n"], "sample_744": ["def test_power_transformer_copy():\n    pt = PowerTransformer(method='box-cox', copy=True)\n    X = np.abs(X_2d)\n\n    X_trans = pt.fit_transform(X)\n    assert_true(X_trans is not X)\n\n    pt = PowerTransformer(method='box-cox', copy=False)\n    X_trans = pt.fit_transform(X)\n    assert_true(X_trans is X)\n"], "sample_908": ["def test_unparse_arguments(source, expected):\n    tree = ast.parse(source)\n    func_def = tree.body[0]\n    assert ast.unparse(func_def.args) == expected\n"], "sample_1060": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n    assert not prntr.module_imports\n    assert prntr.doprint(pi) == 'math.pi'\n    assert prntr.module_imports == {'math': {'pi'}}\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n"], "sample_693": ["def test_unittest_subclass_with_metaclass(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n\n        class Meta(type):\n            pass\n\n        class MyTestCase(unittest.TestCase, metaclass=Meta):\n                pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n"], "sample_488": ["def test_lazy_model_operation_with_pending_operations(self):\n    \"\"\"\n    Tests apps.lazy_model_operation() with pending operations.\n    \"\"\"\n    model_classes = []\n    initial_pending = set(apps._pending_operations)\n\n        model_classes[:] = models\n\n    class LazyA(models.Model):\n        pass\n\n    # Test models appearing twice, and models appearing consecutively\n    model_keys = [\n        (\"apps\", model_name)\n        for model_name in [\"lazya\", \"lazyb\", \"lazyb\", \"lazyc\", \"lazya\"]\n    ]\n    apps.lazy_model_operation(test_func, *model_keys)\n\n    # LazyModelA shouldn't be waited on since it's already registered,\n    # and LazyModelC shouldn't be waited on until LazyModelB exists.\n    self.assertEqual(\n        set(apps._pending_operations) - initial_pending, {(\"apps\", \"lazyb\")}\n    )\n\n    # Add a pending operation for LazyModelB\n        model_classes.append(model)\n\n    apps._pending_operations[(\"apps\", \"lazyb\")].append(pending_operation)\n\n    class LazyB(models.Model):\n        pass\n\n    # The pending operation should be executed\n    self.assertEqual(model_classes, [LazyB])\n\n    # Now we are just waiting on LazyModelC.\n    self.assertEqual(\n        set(apps._pending_operations) - initial_pending, {(\"apps\", \"lazyc\")}\n    )\n\n    class LazyC(models.Model):\n        pass\n\n    # Everything should be loaded - make sure the callback was executed properly.\n    self.assertEqual(model_classes, [LazyA, LazyB, LazyB, LazyC, LazyA])\n"], "sample_572": ["    def test_cached_support_bivariate(self, rng):\n\n        x, y = rng.normal(0, 3, (2, 100))\n        kde = KDE()\n        kde.define_support(x, y)\n        _, support = kde(x[(x > -1) & (x < 1)], y[(x > -1) & (x < 1)])\n        assert_array_equal(support[0], kde.support[0])\n        assert_array_equal(support[1], kde.support[1])\n"], "sample_416": ["def test_default_database(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env({}),\n        ([\"psql\", \"postgres\"], None),\n    )\n"], "sample_1114": ["def test_ComplexRegion_polar_intersect():\n    # Polar form\n    c1 = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)\n    c2 = ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    c3 = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi), polar=True)\n    c4 = ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n\n    p1 = Union(Interval(0, 1)*Interval(0, 2*S.Pi), Interval(0, 1)*Interval(0, S.Pi))\n    p2 = Union(Interval(0, oo)*Interval(0, S.Pi), Interval(0, oo)*Interval(S.Pi, 2*S.Pi))\n\n    assert c1.intersect(c2) == ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    assert c3.intersect(c4) == ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n\n    # Rectangular form\n    c5 = ComplexRegion(Interval(2, 5)*Interval(6, 9))\n    c6 = ComplexRegion(Interval(4, 6)*Interval(10, 12))\n    c7 = ComplexRegion(Interval(0, 10)*Interval(-10, 0))\n    c8 = ComplexRegion(Interval(12, 16)*Interval(14, 20))\n\n    p3 = Union(Interval(2, 5)*Interval(6, 9), Interval(4, 6)*Interval(10, 12))\n    p4 = Union(Interval(0, 10)*Interval(-10, 0), Interval(12, 16)*Interval(14, 20))\n\n    assert c5.intersect(c6) == ComplexRegion(Interval(4, 5)*Interval(10, 9), False)\n    assert c7.intersect(c8) == ComplexRegion(Interval(12, 10)*Interval(14, 0), False)\n\n    assert c1.intersect(Interval(2, 4)) == Intersection(c1, Interval(2, 4), evaluate=False)\n    assert c5.intersect(Interval"], "sample_5": ["def test_parameter_copy(model):\n    if not HAS_SCIPY and model['class'] in SCIPY_MODELS:\n        pytest.skip()\n\n    m = model['class'](**model['parameters'])\n    for param_name in m.param_names:\n        param = getattr(m, param_name)\n        param_copy = param.copy()\n        assert param_copy.name == param.name\n        assert param_copy.default == param.default\n        assert param_copy.unit == param.unit\n        assert param_copy.fixed == param.fixed\n        assert param_copy.tied == param.tied\n        assert param_copy.bounds == param.bounds\n        assert param_copy.min == param.min\n        assert param_copy.max == param.max\n"], "sample_1029": ["def test_Predicate():\n    sT(S.is_even, \"Predicate('is_even')\")\n    sT(S.is_odd, \"Predicate('is_odd')\")\n    sT(S.is_prime, \"Predicate('is_prime')\")\n    sT(S.is_integer, \"Predicate('is_integer')\")\n    sT(S.is_rational, \"Predicate('is_rational')\")\n    sT(S.is_real, \"Predicate('is_real')\")\n    sT(S.is_complex, \"Predicate('is_complex')\")\n    sT(S.is_finite, \"Predicate('is_finite')\")\n    sT(S.is_infinite, \"Predicate('is_infinite')\")\n    sT(S.is_zero, \"Predicate('is_zero')\")\n    sT(S.is_nonzero, \"Predicate('is_nonzero')\")\n    sT(S.is_positive, \"Predicate('is_positive')\")\n    sT(S.is_negative, \"Predicate('is_negative')\")\n    sT(S.is_nonpositive, \"Predicate('is_nonpositive')\")\n    sT(S.is_nonnegative, \"Predicate('is_nonnegative')\")\n"], "sample_738": ["def test_vectorizer_max_features_with_vocabulary():\n    # test bounded number of extracted features with a custom vocabulary\n    vocab = ['burger', 'beer', 'salad', 'pizza', 'celeri', 'tomato']\n    vectorizer = CountVectorizer(vocabulary=vocab, max_features=4)\n    vectorizer.fit(ALL_FOOD_DOCS)\n    assert_equal(set(vectorizer.vocabulary_), set(vocab[:4]))\n    assert_equal(vectorizer.stop_words_, set(vocab[4:]))\n\n    vectorizer = TfidfVectorizer(vocabulary=vocab, max_features=4)\n    vectorizer.fit(ALL_FOOD_DOCS)\n    assert_equal(set(vectorizer.vocabulary_), set(vocab[:4]))\n    assert_equal(vectorizer.stop_words_, set(vocab[4:]))\n"], "sample_272": ["def test_detect_soft_applied_add_field_non_m2mfield(self):\n    \"\"\"\n    executor.detect_soft_applied() detects non-ManyToManyField tables from an\n    AddField operation.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Create the tables for 0001 but make it look like the migration hasn't\n    # been applied.\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n    executor.migrate([(\"migrations\", None)], fake=True)\n    # Table detection sees 0001 is applied.\n    migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], True)\n    # Create the tables for both migrations but make it look like neither\n    # has been applied.\n    executor.loader.build_graph()\n    executor.migrate([(\"migrations\", \"0001_initial\")], fake=True)\n    executor.migrate([(\"migrations\", \"0002_second\")])\n    executor.loader.build_graph()\n    executor.migrate([(\"migrations\", None)], fake=True)\n    # Table detection sees 0002 is applied.\n    migration = executor.loader.get_migration(\"migrations\", \"0002_second\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], True)\n    # Leave the tables for 0001 except the non-many-to-many table. That missing\n    # table should cause detect_soft_applied() to return False.\n    with connection.schema_editor() as editor:\n        editor.execute(editor.sql_delete_table % {\"table\": \"migrations_author\"})\n    migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], False)\n    # Cleanup by removing the remaining tables.\n    with connection.schema_editor() as editor:\n        editor.execute(editor.sql_delete_table % {\"table\": \"migrations_tribble\"})\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_tribble\")\n"], "sample_234": ["def test_union_with_distinct_fields(self):\n    qs1 = Number.objects.filter(num__lte=1).distinct('num')\n    qs2 = Number.objects.filter(num__gte=2, num__lte=3)\n    self.assertNumbersEqual(qs1.union(qs2), [0, 1, 2, 3], ordered=False)\n"], "sample_312": ["def test_add_squash(self):\n    # Test squashing when adding a node with the same connector\n    node = Node([('a', 1), ('b', 2)])\n    node_to_add = Node([('c', 3), ('d', 4)])\n    node.add(node_to_add, Node.default)\n    self.assertEqual(str(node), \"(DEFAULT: ('a', 1), ('b', 2), ('c', 3), ('d', 4))\")\n\n    # Test squashing when adding a node with a single child and different connector\n    node = Node([('a', 1), ('b', 2)])\n    node_to_add = Node([('c', 3)])\n    node.add(node_to_add, 'OR')\n    self.assertEqual(str(node), \"(DEFAULT: ('a', 1), ('b', 2))\")\n    self.assertEqual(str(node_to_add), \"(DEFAULT: ('c', 3))\")\n\n    # Test not squashing when adding a node with a different connector\n    node = Node([('a', 1), ('b', 2)])\n    node_to_add = Node([('c', 3), ('d', 4)], 'OR')\n    node.add(node_to_add, 'AND')\n    self.assertEqual(str(node), \"(AND: (DEFAULT: ('a', 1), ('b', 2)), (OR: ('c', 3), ('d', 4)))\")\n\n    # Test not squashing when adding a node with a negated child\n    node = Node([('a', 1), ('b', 2)])\n    node_to_add = Node([('c', 3)], negated=True)\n    node.add(node_to_add, Node.default)\n    self.assertEqual(str(node), \"(DEFAULT: ('a', 1), ('b', 2), (NOT (DEFAULT: ('c', 3)))\")\n"], "sample_584": ["    def test_combine_by_coords_3d(self):\n        ds0 = Dataset({'x': [0, 1], 'y': [10, 20, 30]})\n        ds1 = Dataset({'x': [2, 3], 'y': [10, 20, 30]})\n        ds2 = Dataset({'x': [0, 1], 'y': [40, 50, 60]})\n        ds3 = Dataset({'x': [2, 3], 'y': [40, 50, 60]})\n        ds4 = Dataset({'x': [0, 1], 'y': [70, 80, 90]})\n        ds5 = Dataset({'x': [2, 3], 'y': [70, 80, 90]})\n\n        expected = {(0, 0): ds0, (1, 0): ds1,\n                    (0, 1): ds2, (1, 1): ds3,\n                    (0, 2): ds4, (1, 2): ds5}\n        actual, concat_dims = _infer_concat_order_from_coords([ds1, ds0, ds3,\n                                                               ds5, ds2, ds4])\n        assert_combined_tile_ids_equal(expected, actual)\n        assert concat_dims == ['x', 'y']\n"], "sample_1138": ["def test_TR22():\n    assert TR22(tan(x)**2) == sec(x)**2 - 1\n    assert TR22(cot(x)**2) == csc(x)**2 - 1\n    assert TR22(tan(x)**4) == (sec(x)**2 - 1)**2\n    assert TR22(cot(x)**4) == (csc(x)**2 - 1)**2\n    assert TR22(tan(x)**6) == (sec(x)**2 - 1)**3\n    assert TR22(cot(x)**6) == (csc(x)**2 - 1)**3\n    assert TR22(tan(x)**8) == (sec(x)**2 - 1)**4\n    assert TR22(cot(x)**8) == (csc(x)**2 - 1)**4\n"], "sample_329": ["def test_serialize_function_type(self):\n        pass\n\n    self.assertSerializedResultEqual(\n        test_function,\n        (\n            \"migrations.test_writer.WriterTests.test_serialize_function_type.<locals>.test_function\",\n            {'import migrations.test_writer'},\n        ),\n    )\n\n    class TestClass:\n            pass\n\n    self.assertSerializedResultEqual(\n        TestClass().test_method,\n        (\n            \"migrations.test_writer.WriterTests.TestClass().test_method\",\n            {'import migrations.test_writer'},\n        ),\n    )\n\n    class TestClass2:\n        @staticmethod\n            pass\n\n    self.assertSerializedResultEqual(\n        TestClass2.test_static_method,\n        (\n            \"migrations.test_writer.WriterTests.TestClass2.test_static_method\",\n            {'import migrations.test_writer'},\n        ),\n    )\n\n    class TestClass3:\n        @classmethod\n            pass\n\n    self.assertSerializedResultEqual(\n        TestClass3.test_class_method,\n        (\n            \"migrations.test_writer.WriterTests.TestClass3.test_class_method\",\n            {'import migrations.test_writer'},\n        ),\n    )\n"], "sample_1170": ["def test_Pow_with_negative_exponent():\n    assert str(x**(-1.0)) == 'x**(-1.0)'\n    assert str(x**(-1.5)) == 'x**(-1.5)'\n    assert str(x**(-2.0)) == 'x**(-2.0)'\n    assert str(x**(-2.5)) == 'x**(-2.5)'\n    assert str(x**(-3.0)) == 'x**(-3.0)'\n    assert str(x**(-3.5)) == 'x**(-3.5)'\n    assert str(x**(-4.0)) == 'x**(-4.0)'\n    assert str(x**(-4.5)) == 'x**(-4.5)'\n    assert str(x**(-5.0)) == 'x**(-5.0)'\n    assert str(x**(-5.5)) == 'x**(-5.5)'\n    assert str(x**(-6.0)) == 'x**(-6.0)'\n    assert str(x**(-6.5)) == 'x**(-6.5)'\n    assert str(x**(-7.0)) == 'x**(-7.0)'\n    assert str(x**(-7.5)) == 'x**(-7.5)'\n    assert str(x**(-8.0)) == 'x**(-8.0)'\n    assert str(x**(-8.5)) == 'x**(-8.5)'\n    assert str(x**(-9.0)) == 'x**(-9.0)'\n    assert str(x**(-9.5)) == 'x**(-9.5)'\n    assert str(x**(-10.0)) == 'x**(-10.0)'\n    assert str(x**(-10.5)) == 'x**(-10.5)'\n"], "sample_18": ["    def setup_class(self):\n        self.q = u.Quantity(np.arange(1.0, 5.0), \"m/s\")\n        self.q.info.name = \"v\"\n        self.q.info.description = \"air speed of a african swallow\"\n"], "sample_184": ["    def test_check_constraint_pointing_to_joined_fields_with_transform(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=10)\n            field1 = models.PositiveSmallIntegerField()\n            field2 = models.PositiveSmallIntegerField()\n            parent = models.ForeignKey('self', models.CASCADE)\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        name='name1', check=models.Q(\n                            field1__lt=models.F('parent__field1') + models.F('parent__field2')\n                        )\n                    ),\n                    models.CheckConstraint(\n                        name='name2', check=models.Q(name=Lower('parent__name'))\n                    ),\n                    models.CheckConstraint(\n                        name='name3', check=models.Q(parent__field3=models.F('field1'))\n                    ),\n                ]\n\n        joined_fields = ['parent__field1', 'parent__field2', 'parent__field3', 'parent__name']\n        errors = Model.check(databases=self.databases)\n        expected_errors = [\n            Error(\n                \"'constraints' refers to the joined field '%s'.\" % field_name,\n                obj=Model,\n                id='models.E041',\n            ) for field_name in joined_fields\n        ]\n        self.assertCountEqual(errors, expected_errors)\n"], "sample_39": ["def test_sip_with_altkey_and_sip_keywords():\n    \"\"\"\n    Test that when creating a WCS object using a key, CTYPE with\n    that key is looked at and not the primary CTYPE.\n    fix for #5443.\n    \"\"\"\n    with fits.open(get_pkg_data_filename('data/sip.fits')) as f:\n        w = wcs.WCS(f[0].header)\n    # create a header with two WCSs.\n    h1 = w.to_header(relax=True, key='A')\n    h2 = w.to_header(relax=False)\n    h1['CTYPE1A'] = \"RA---SIN-SIP\"\n    h1['CTYPE2A'] = \"DEC--SIN-SIP\"\n    h1['A_ORDER'] = 3\n    h1['A_0_0'] = 1.0\n    h1['A_1_0'] = 0.0\n    h1['A_0_1'] = 0.0\n    h1['A_2_0'] = 0.0\n    h1['A_1_1'] = 1.0\n    h1['A_0_2'] = 0.0\n    h1['A_2_1'] = 0.0\n    h1['A_1_2'] = 0.0\n    h1['A_2_2'] = 1.0\n    h1.update(h2)\n    w = wcs.WCS(h1, key='A')\n    assert (w.wcs.ctype == np.array(['RA---SIN-SIP', 'DEC--SIN-SIP'])).all()\n    assert w.sip.a_order == 3\n    assert w.sip.b_order == 0\n    assert w.sip.ap_order == 0\n    assert w.sip.bp_order == 0\n    assert_array_equal(w.sip.crpix, [2048., 1026.])\n"], "sample_45": ["def test_trunc_timezone_with_dst_transition(self):\n    sao = pytz.timezone('America/Sao_Paulo')\n    utc = pytz.timezone('UTC')\n    start_datetime = utc.localize(datetime(2016, 10, 16, 1))\n    end_datetime = utc.localize(datetime(2016, 2, 21, 1))\n    self.create_model(start_datetime, end_datetime)\n    with timezone.override(sao):\n        model = DTModel.objects.annotate(\n            truncated_start=TruncHour('start_datetime', tzinfo=sao),\n            truncated_end=TruncHour('end_datetime', tzinfo=sao),\n        ).get()\n        self.assertEqual(model.truncated_start.dst(), timedelta(0, 3600))\n        self.assertEqual(model.truncated_end.dst(), timedelta(0))\n"], "sample_686": ["def test_funcargnames_is_deprecated() -> None:\n    class MockFunction:\n            self.fixturenames = [\"fixture1\", \"fixture2\"]\n\n    with pytest.warns(\n        pytest.PytestDeprecationWarning,\n        match=\"The `funcargnames` attribute was an alias for `fixturenames`, since pytest 2.3 - use the newer attribute instead.\",\n    ):\n        deprecated.FUNCARGNAMES.warn(MockFunction())\n"], "sample_391": ["def test_create_model_add_index(self):\n    \"\"\"\n    AddIndex should optimize into CreateModel.\n    \"\"\"\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n            ),\n            migrations.AddIndex(\n                model_name=\"foo\",\n                index=models.Index(fields=[\"name\"], name=\"foo_name_idx\"),\n            ),\n        ],\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n                options={\"indexes\": [models.Index(fields=[\"name\"], name=\"foo_name_idx\")]},\n            ),\n        ],\n    )\n"], "sample_688": ["def test_import_path_mode_importlib_with_relative_imports(testdir):\n    \"\"\"Test that --import-mode=importlib handles relative imports correctly.\"\"\"\n    testdir.makepyfile(\n        **{\n            \"tests/__init__.py\": \"\",\n            \"tests/test_foo.py\": \"\"\"\n                from . import bar\n                    assert bar.bar() == 42\n            \"\"\",\n            \"tests/bar.py\": \"\"\"\n                    return 42\n            \"\"\",\n        }\n    )\n    result = testdir.runpytest(\"-v\", \"--import-mode=importlib\")\n    result.stdout.fnmatch_lines([\"* 1 passed in *\"])\n"], "sample_888": ["def test_iforest_offset_calculation(global_random_seed):\n    \"\"\"Test offset calculation when contamination is not 'auto'.\"\"\"\n    rng = check_random_state(global_random_seed)\n    X = rng.randn(100, 2)\n    contamination = 0.1\n    clf = IsolationForest(contamination=contamination, random_state=rng).fit(X)\n    scores = clf._score_samples(X)\n    offset = np.percentile(scores, 100.0 * contamination)\n    assert_allclose(clf.offset_, offset)\n"], "sample_1148": ["def test_matrix_element_derivative():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', n, n)\n    E = MatrixSymbol('E', m, n)\n    w = MatrixSymbol('w', n, 1)\n\n    assert A[1, 2].diff(A[1, 2]) == 1\n    assert A[1, 2].diff(A[1, 3]) == 0\n    assert A[1, 2].diff(B[1, 2]) == 0\n    assert A[1, 2].diff(w[1, 0]) == 0\n\n    assert (A[1, 2] + B[1, 2]).diff(A[1, 2]) == 1\n    assert (A[1, 2] + B[1, 2]).diff(B[1, 2]) == 1\n    assert (A[1, 2] + B[1, 2]).diff(A[1, 3]) == 0\n\n    assert (A[1, 2] * B[1, 2]).diff(A[1, 2]) == B[1, 2]\n    assert (A[1, 2] * B[1, 2]).diff(B[1, 2]) == A[1, 2]\n    assert (A[1, 2] * B[1, 2]).diff(A[1, 3]) == 0\n\n    assert (A[1, 2] * A[1, 2]).diff(A[1, 2]) == 2 * A[1, 2]\n    assert (A[1, 2] * A[1, 2]).diff(A[1, 3]) == 0\n\n    assert (A[1, 2] + A[1, 2]).diff(A[1, 2]) == 2\n    assert (A[1, 2] + A[1, 2]).diff(A[1, 3]) == 0\n\n    assert (A[1, 2] - A[1, 2]).diff(A[1, 2]) == 0\n   "], "sample_802": ["def test_pipeline_memory_with_clone():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        if LooseVersion(joblib_version) < LooseVersion('0.12'):\n            # Deal with change of API in joblib\n            memory = Memory(cachedir=cachedir, verbose=10)\n        else:\n            memory = Memory(location=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(gamma='scale', probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', transf), ('svc', clf)])\n        cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n                               memory=memory)\n\n        # Memoize the transformer at the first fit\n        cached_pipe.fit(X, y)\n        pipe.fit(X, y)\n        # Get the time stamp of the transformer in the cached pipeline\n        ts = cached_pipe.named_steps['transf'].timestamp_\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert not hasattr(transf, 'means_')\n        # Check that we are reading the cache while fitting\n        # a second time\n        cached_pipe.fit(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert_equal(ts, cached_pipe.named_steps['transf'].timestamp_)\n        # Create a new pipeline with cloned estimators\n        # Check that even changing the name step does not affect the cache hit\n        clf_2 = SVC(gamma='scale', probability=True, random_state"], "sample_1089": ["def test_monotonic_sign_univariate_polynomial():\n    F = _monotonic_sign\n    x = symbols('x')\n    assert F(x**2 + 1) == 1\n    assert F(x**2 - 1) is None\n    assert F(x**3 + 1) == 1\n    assert F(x**3 - 1) is None\n    assert F(x**4 + 1) == 1\n    assert F(x**4 - 1) is None\n    assert F(x**5 + 1) == 1\n    assert F(x**5 - 1) is None\n    assert F(x**6 + 1) == 1\n    assert F(x**6 - 1) is None\n    assert F(x**7 + 1) == 1\n    assert F(x**7 - 1) is None\n    assert F(x**8 + 1) == 1\n    assert F(x**8 - 1) is None\n    assert F(x**9 + 1) == 1\n    assert F(x**9 - 1) is None\n    assert F(x**10 + 1) == 1\n    assert F(x**10 - 1) is None\n    assert F(x**11 + 1) == 1\n    assert F(x**11 - 1) is None\n    assert F(x**12 + 1) == 1\n    assert F(x**12 - 1) is None\n    assert F(x**13 + 1) == 1\n    assert F(x**13 - 1) is None\n    assert F(x**14 + 1) == 1\n    assert F(x**14 - 1) is None\n    assert F(x**15 + 1) == 1\n    assert F(x**15 - 1) is None\n    assert F(x**16 + 1) == 1\n    assert F(x**16 - 1) is None\n    assert F(x**17 + 1) == 1\n    assert F(x**17 - 1) is None\n    assert F(x**18 + 1) == 1\n    assert F(x**18 - 1) is None\n    assert F(x**19 + 1) == 1\n    assert F(x**19 - 1"], "sample_647": ["def test_pytest_warning_subclasses(warning_class: PytestWarning) -> None:\n    \"\"\"Make sure all PytestWarning subclasses have a __module__ attribute set to 'pytest'.\"\"\"\n    assert warning_class.__module__ == \"pytest\"\n\n"], "sample_359": ["def test_alter_field_with_deferrable_unique_constraint(self):\n    app_label = 'test_alter_field_with_deferrable_unique_constraint'\n    deferred_unique_constraint = models.UniqueConstraint(\n        fields=['pink'],\n        name='deferred_pink_constraint',\n        deferrable=models.Deferrable.DEFERRED,\n    )\n    project_state = self.set_up_test_model(app_label, constraints=[deferred_unique_constraint])\n    operation = migrations.AlterField('Pony', 'pink', models.IntegerField(null=True))\n    new_state = project_state.clone()\n    operation.state_forwards(app_label, new_state)\n    self.assertEqual(len(new_state.models[app_label, 'pony'].options['constraints']), 1)\n    Pony = new_state.apps.get_model(app_label, 'Pony')\n    self.assertEqual(len(Pony._meta.constraints), 1)\n    with connection.schema_editor() as editor, CaptureQueriesContext(connection) as ctx:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    Pony.objects.create(pink=1)\n    if connection.features.supports_deferrable_unique_constraints:\n        # Unique constraint is deferred.\n        with transaction.atomic():\n            obj = Pony.objects.create(pink=1)\n            obj.pink = 2\n            obj.save()\n        # Constraint behavior can be changed with SET CONSTRAINTS.\n        with self.assertRaises(IntegrityError):\n            with transaction.atomic(), connection.cursor() as cursor:\n                quoted_name = connection.ops.quote_name(deferred_unique_constraint.name)\n                cursor.execute('SET CONSTRAINTS %s IMMEDIATE' % quoted_name)\n                obj = Pony.objects.create(pink=1)\n                obj.pink = 3\n                obj.save()\n    else:\n        Pony.objects.create(pink=1)\n    # Reversal.\n    with connection.schema_editor() as editor:\n        operation.database_backwards(app_label, editor, new_state, project_state)\n    if connection.features.supports_deferrable_unique_constraints:\n        # Unique constraint is deferred.\n        with transaction.atomic():\n            obj = Pony.objects.create(pink=1)\n            obj.pink = 2\n            obj.save()\n        # Constraint behavior can be changed with SET CONSTRAINTS.\n        with self.assertRaises(IntegrityError):\n            with transaction.atomic(), connection.cursor() as cursor:\n                quoted_name = connection.ops.quote_name(deferred_unique_constraint.name)\n                cursor.execute('SET CONSTRAINTS %s IMMEDIATE' % quoted_name)\n                obj = Pony.objects.create(pink=1)\n"], "sample_14": ["def test_longitude_wrap_at_edge_cases():\n    \"\"\"\n    Test Longitude wrapping at edge cases\n    \"\"\"\n\n    # Test wrapping at 0 degrees\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian)\n    assert np.all(lon.degree == np.array([0., 90, 180, 270, 0]))\n\n    # Test wrapping at 180 degrees\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle='180d')\n    assert np.all(lon.degree == np.array([0., 90, -180, -90, 0]))\n\n    # Test wrapping at -180 degrees\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle='-180d')\n    assert np.all(lon.degree == np.array([0., -90, 180, 90, 0]))\n\n    # Test wrapping at 360 degrees\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle='360d')\n    assert np.all(lon.degree == np.array([0., 90, 180, 270, 0]))\n\n    # Test wrapping at -360 degrees\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle='-360d')\n    assert np.all(lon.degree == np.array([0., -90, 180, 90, 0]))\n"], "sample_465": ["def test_get_inline_instances_with_custom_has_view_permission(self):\n    \"\"\"\n    ModelAdmin.get_inline_instances() uses InlineModelAdmin.has_view_permission()\n    for permissions checking.\n    \"\"\"\n    class ConcertInline(TabularInline):\n        model = Concert\n\n            return bool(obj)\n\n    class BandAdmin(ModelAdmin):\n        inlines = [ConcertInline]\n\n    ma = BandAdmin(Band, AdminSite())\n    request = MockRequest()\n    request.user = self.MockViewUser()\n    self.assertEqual(ma.get_inline_instances(request), [])\n    band = Band(name=\"The Doors\", bio=\"\", sign_date=date(1965, 1, 1))\n    inline_instances = ma.get_inline_instances(request, band)\n    self.assertEqual(len(inline_instances), 1)\n    self.assertIsInstance(inline_instances[0], ConcertInline)\n"], "sample_273": ["    def test_model_base_subclass_exception(self):\n        class MyModel(metaclass=ModelBase):\n            class Meta:\n                app_label = 'check_framework'\n\n        try:\n            raise MyModel.DoesNotExist\n        except MyModel.DoesNotExist as e:\n            self.assertIsInstance(e, ObjectDoesNotExist)\n            self.assertEqual(str(e), \"MyModel matching query does not exist.\")\n\n        try:\n            raise MyModel.MultipleObjectsReturned\n        except MyModel.MultipleObjectsReturned as e:\n            self.assertIsInstance(e, MultipleObjectsReturned)\n            self.assertEqual(str(e), \"get() returned more than one MyModel -- it returned 2!\")\n"], "sample_1050": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n    assert not prntr.module_imports\n    assert prntr.doprint(pi) == 'math.pi'\n    assert prntr.module_imports == {'math': {'pi'}}\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n"], "sample_793": ["def test_iforest_predict_with_sample_weight(contamination):\n    # toy sample (the last two samples are outliers)\n    X = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1], [6, 3], [-4, 7]]\n    sample_weight = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5]\n\n    # Test IsolationForest\n    clf = IsolationForest(\n        behaviour=\"new\", random_state=rng, contamination=contamination\n    )\n    clf.fit(X, sample_weight=sample_weight)\n    decision_func = -clf.decision_function(X)\n    pred = clf.predict(X)\n    # assert detect outliers:\n    assert_greater(np.min(decision_func[-2:]), np.max(decision_func[:-2]))\n    assert_array_equal(pred, 6 * [1] + 2 * [-1])\n"], "sample_52": ["def test_modelchoicefield_with_empty_queryset(self):\n    class ModelChoiceForm(forms.Form):\n        category = forms.ModelChoiceField(Category.objects.none())\n\n    form = ModelChoiceForm()\n    self.assertEqual(list(form.fields['category'].choices), [('', '---------')])\n    self.assertIsNone(form.fields['category'].clean(''))\n    with self.assertRaises(ValidationError):\n        form.fields['category'].clean('1')\n"], "sample_726": ["def test_label_binarizer_multilabel_input():\n    # Test that LabelBinarizer raises an error when given multilabel input\n    lb = LabelBinarizer()\n    y = [[1, 2], [1], [2, 3]]\n    assert_raises(ValueError, lb.fit, y)\n    assert_raises(ValueError, lb.fit_transform, y)\n"], "sample_1028": ["def test_Mod_is_real():\n    x = Symbol('x', real=True)\n    y = Symbol('y', real=True, positive=True)\n\n    assert (x**2).is_real is True\n    assert (x**3).is_real is True\n    assert (x**x).is_real is None\n    assert (y**x).is_real is True\n\n    assert (x**Rational(1, 3)).is_real is None\n    assert (y**Rational(1, 3)).is_real is True\n\n    assert sqrt(-1 - sqrt(2)).is_real is False\n\n    i = Symbol('i', imaginary=True)\n    assert (i**i).is_real is None\n    assert (I**i).is_real is True\n    assert ((-I)**i).is_real is True\n    assert (2**i).is_real is None  # (2**(pi/log(2) * I)) is real, 2**I is not\n    assert (2**I).is_real is False\n    assert (2**-I).is_real is False\n    assert (i**2).is_real is True\n    assert (i**3).is_real is False\n    assert (i**x).is_real is None  # could be (-I)**(2/3)\n    e = Symbol('e', even=True)\n    o = Symbol('o', odd=True)\n    k = Symbol('k', integer=True)\n    assert (i**e).is_real is True\n    assert (i**o).is_real is False\n    assert (i**k).is_real is None\n    assert (i**(4*k)).is_real is True\n\n    x = Symbol(\"x\", nonnegative=True)\n    y = Symbol(\"y\", nonnegative=True)\n    assert im(x**y).expand(complex=True) is S.Zero\n    assert (x**y).is_real is True\n    i = Symbol('i', imaginary=True)\n    assert (exp(i)**I).is_real is True\n    assert log(exp(i)).is_imaginary is None  # i could be 2*pi*I\n    c = Symbol('c', complex=True)\n    assert log(c).is_real is None  # c could be 0 or 2, too\n    assert log(exp(c)).is_real is None  # log(0), log(E), ...\n    n ="], "sample_441": ["    def test_normalize(self):\n        field = UsernameField()\n        self.assertEqual(field.to_python(\"test\"), \"test\")\n        self.assertEqual(field.to_python(\"test\u03a9\"), \"test\u03a9\")  # U+03A9 GREEK CAPITAL LETTER OMEGA\n        self.assertEqual(field.to_python(\"test\u2126\"), \"test\u03a9\")  # U+2126 OHM SIGN\n"], "sample_521": ["def test_text3d_rotation():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n\n    zdirs = (None, 'x', 'y', 'z', (1, 1, 0), (1, 1, 1))\n    xs = (2, 6, 4, 9, 7, 2)\n    ys = (6, 4, 8, 7, 2, 2)\n    zs = (4, 2, 5, 6, 1, 7)\n\n    for zdir, x, y, z in zip(zdirs, xs, ys, zs):\n        label = '(%d, %d, %d), dir=%s' % (x, y, z, zdir)\n        ax.text(x, y, z, label, zdir, rotation=45)\n\n    ax.text(1, 1, 1, \"red\", color='red')\n    ax.text2D(0.05, 0.95, \"2D Text\", transform=ax.transAxes)\n    ax.set_xlim3d(0, 10)\n    ax.set_ylim3d(0, 10)\n    ax.set_zlim3d(0, 10)\n    ax.set_xlabel('X axis')\n    ax.set_ylabel('Y axis')\n    ax.set_zlabel('Z axis')\n"], "sample_490": ["def test_validate_expression_with_condition_and_exclude(self):\n    constraint = models.UniqueConstraint(\n        Lower(\"name\"),\n        name=\"name_lower_without_color_uniq\",\n        condition=models.Q(color__isnull=True),\n    )\n    non_unique_product = UniqueConstraintProduct(name=self.p2.name.upper())\n    msg = \"Constraint \u201cname_lower_without_color_uniq\u201d is violated.\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        constraint.validate(\n            UniqueConstraintProduct,\n            non_unique_product,\n            exclude={\"color\"},\n        )\n    # Values not matching condition are ignored.\n    constraint.validate(\n        UniqueConstraintProduct,\n        UniqueConstraintProduct(name=self.p1.name, color=self.p1.color),\n        exclude={\"color\"},\n    )\n    # Existing instances have their existing row excluded.\n    constraint.validate(UniqueConstraintProduct, self.p2, exclude={\"color\"})\n    # Unique field is excluded.\n    constraint.validate(\n        UniqueConstraintProduct,\n        non_unique_product,\n        exclude={\"name\", \"color\"},\n    )\n"], "sample_141": ["def test_deserialize_m2m_values_with_deferred_fields(self):\n    \"\"\"\n    Test that deserialize_m2m_values handles deferred fields correctly.\n    \"\"\"\n    field = models.ManyToManyField('self', through='serializers.M2MData')\n    field_value = [1, 2, 3]\n    using = 'default'\n    handle_forward_references = True\n    result = deserialize_m2m_values(field, field_value, using, handle_forward_references)\n    self.assertEqual(result, [1, 2, 3])\n\n    field_value = [1, DEFER_FIELD, 3]\n    result = deserialize_m2m_values(field, field_value, using, handle_forward_references)\n    self.assertEqual(result, [1, DEFER_FIELD, 3])\n\n    field_value = [DEFER_FIELD, DEFER_FIELD, DEFER_FIELD]\n    result = deserialize_m2m_values(field, field_value, using, handle_forward_references)\n    self.assertEqual(result, [DEFER_FIELD, DEFER_FIELD, DEFER_FIELD])\n\n    field_value = None\n    with self.assertRaises(M2MDeserializationError):\n        deserialize_m2m_values(field, field_value, using, handle_forward_references)\n\n    field_value = 'not iterable'\n    with self.assertRaises(M2MDeserializationError):\n        deserialize_m2m_values(field, field_value, using, handle_forward_references)\n"], "sample_626": ["def test_explicit_indexing_adapter():\n    array = np.arange(36).reshape(6, 6)\n    key = OuterIndexer((np.array([0, 1, 3]), np.array([2, 3])))\n    result = explicit_indexing_adapter(key, array.shape, IndexingSupport.OUTER, array.__getitem__)\n    expected = array[key.tuple]\n    np.testing.assert_array_equal(result, expected)\n\n    key = VectorizedIndexer((np.array([0, 1, 3]), np.array([2, 3])))\n    result = explicit_indexing_adapter(key, array.shape, IndexingSupport.OUTER, array.__getitem__)\n    expected = array[key.tuple]\n    np.testing.assert_array_equal(result, expected)\n\n    key = BasicIndexer((slice(0, 3), slice(2, 4)))\n    result = explicit_indexing_adapter(key, array.shape, IndexingSupport.BASIC, array.__getitem__)\n    expected = array[key.tuple]\n    np.testing.assert_array_equal(result, expected)\n"], "sample_204": ["    def test_replace_migrations(self):\n        \"\"\"\n        Makes sure the loader can load migrations with a replacement.\n        \"\"\"\n        # Load and test the plan\n        migration_loader = MigrationLoader(connection)\n        self.assertEqual(\n            migration_loader.graph.forwards_plan((\"migrations\", \"0003_third\")),\n            [\n                (\"migrations\", \"0001_initial\"),\n                (\"migrations\", \"0002_second\"),\n                (\"migrations\", \"0003_third\"),\n            ],\n        )\n        # Now render it out!\n        project_state = migration_loader.project_state((\"migrations\", \"0003_third\"))\n        self.assertEqual(len(project_state.models), 2)\n\n        author_state = project_state.models[\"migrations\", \"author\"]\n        self.assertEqual(\n            list(author_state.fields),\n            [\"id\", \"name\", \"slug\", \"age\", \"rating\"]\n        )\n\n        book_state = project_state.models[\"migrations\", \"book\"]\n        self.assertEqual(list(book_state.fields), ['id', 'author'])\n\n        # Ensure we've included unmigrated apps in there too\n        self.assertIn(\"basic\", project_state.real_apps)\n\n        # Test replacing migrations\n        recorder = MigrationRecorder(connection)\n        recorder.record_applied(\"migrations\", \"0001_initial\")\n        recorder.record_applied(\"migrations\", \"0002_second\")\n        migration_loader.build_graph()\n        self.assertEqual(\n            migration_loader.graph.forwards_plan((\"migrations\", \"0003_third\")),\n            [\n                (\"migrations\", \"0003_third\"),\n            ],\n        )\n"], "sample_984": ["def test_Predicate():\n    assert str(Q.is_true) == \"Q.is_true\"\n    assert str(Q.is_false) == \"Q.is_false\"\n    assert str(Q.is_integer) == \"Q.is_integer\"\n    assert str(Q.is_noninteger) == \"Q.is_noninteger\"\n    assert str(Q.is_rational) == \"Q.is_rational\"\n    assert str(Q.is_irrational) == \"Q.is_irrational\"\n    assert str(Q.is_real) == \"Q.is_real\"\n    assert str(Q.is_nonreal) == \"Q.is_nonreal\"\n    assert str(Q.is_complex) == \"Q.is_complex\"\n    assert str(Q.is_noncomplex) == \"Q.is_noncomplex\"\n    assert str(Q.is_algebraic) == \"Q.is_algebraic\"\n    assert str(Q.is_nonalgebraic) == \"Q.is_nonalgebraic\"\n    assert str(Q.is_transcendental) == \"Q.is_transcendental\"\n    assert str(Q.is_nontranscendental) == \"Q.is_nontranscendental\"\n    assert str(Q.is_prime) == \"Q.is_prime\"\n    assert str(Q.is_composite) == \"Q.is_composite\"\n    assert str(Q.is_even) == \"Q.is_even\"\n    assert str(Q.is_odd) == \"Q.is_odd\"\n    assert str(Q.is_zero) == \"Q.is_zero\"\n    assert str(Q.is_nonzero) == \"Q.is_nonzero\"\n    assert str(Q.is_positive) == \"Q.is_positive\"\n    assert str(Q.is_negative) == \"Q.is_negative\"\n    assert str(Q.is_nonpositive) == \"Q.is_nonpositive\"\n    assert str(Q.is_nonnegative) == \"Q.is_nonnegative\"\n    assert str(Q.is_integer_multiple) == \"Q.is_integer_multiple\"\n    assert str(Q.is_integer_multiple_of) == \"Q.is_integer_multiple_of\"\n"], "sample_422": ["    def test_prefetch_related_with_nested_prefetch_and_to_attr(self):\n        with self.assertNumQueries(3):\n            authors = Author.objects.prefetch_related(\n                Prefetch(\n                    \"books\",\n                    queryset=Book.objects.prefetch_related(\n                        Prefetch(\"read_by\", to_attr=\"readers\")\n                    ),\n                    to_attr=\"books_with_readers\",\n                )\n            )\n            lists = [\n                [[str(r) for r in b.readers.all()] for b in a.books_with_readers]\n                for a in authors\n            ]\n        self.assertEqual(\n            lists,\n            [\n                [[\"Amy\"], [\"Belinda\"]],  # Charlotte - Poems, Jane Eyre\n                [[\"Amy\"]],  # Anne - Poems\n                [[\"Amy\"], []],  # Emily - Poems, Wuthering Heights\n                [[\"Amy\", \"Belinda\"]],  # Jane - Sense and Sense\n            ],\n        )\n"], "sample_1100": ["def test_Pow_is_extended_real():\n    x = Symbol('x', real=True)\n    y = Symbol('y', real=True, positive=True)\n\n    assert (x**2).is_extended_real is True\n    assert (x**3).is_extended_real is True\n    assert (x**x).is_extended_real is None\n    assert (y**x).is_extended_real is True\n\n    assert (x**Rational(1, 3)).is_extended_real is None\n    assert (y**Rational(1, 3)).is_extended_real is True\n\n    assert sqrt(-1 - sqrt(2)).is_extended_real is False\n\n    i = Symbol('i', imaginary=True)\n    assert (i**i).is_extended_real is None\n    assert (I**i).is_extended_real is True\n    assert ((-I)**i).is_extended_real is True\n    assert (2**i).is_extended_real is None  # (2**(pi/log(2) * I)) is real, 2**I is not\n    assert (2**I).is_extended_real is False\n    assert (2**-I).is_extended_real is False\n    assert (i**2).is_extended_real is True\n    assert (i**3).is_extended_real is False\n    assert (i**x).is_extended_real is None  # could be (-I)**(2/3)\n    e = Symbol('e', even=True)\n    o = Symbol('o', odd=True)\n    k = Symbol('k', integer=True)\n    assert (i**e).is_extended_real is True\n    assert (i**o).is_extended_real is False\n    assert (i**k).is_extended_real is None\n    assert (i**(4*k)).is_extended_real is True\n\n    x = Symbol(\"x\", nonnegative=True)\n    y = Symbol(\"y\", nonnegative=True)\n    assert im(x**y).expand(complex=True) is S.Zero\n    assert (x**y).is_extended_real is True\n    i = Symbol('i', imaginary=True)\n    assert (exp(i)**I).is_extended_real is True\n    assert log(exp(i)).is_imaginary is None  # i could be 2*pi*I\n    c = Symbol('c', complex=True)\n    assert log(c).is_real is None  # c could be 0 or 2, too"], "sample_226": ["    def test_create_test_db(self, mocked_create_test_db):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            creation.create_test_db(verbosity=1, autoclobber=True, serialize=True, keepdb=False)\n            mocked_create_test_db.assert_called_once_with(creation, 1, True, False)\n            self.assertEqual(test_connection.settings_dict['NAME'], creation._get_test_db_name())\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_727": ["def test_imputation_most_frequent_ties():\n    # Test imputation using the most-frequent strategy with ties.\n    X = np.array([\n        [-1, -1, 0, 5],\n        [-1, 2, -1, 3],\n        [-1, 1, 3, 3],\n        [-1, 2, 3, 7],\n    ])\n\n    X_true = np.array([\n        [2, 0, 5],\n        [2, 3, 3],\n        [1, 3, 3],\n        [2, 3, 7],\n    ])\n\n    # Test with ties\n    X_ties = np.array([\n        [-1, -1, 0, 5],\n        [-1, 2, -1, 3],\n        [-1, 1, 3, 3],\n        [-1, 2, 3, 3],\n    ])\n\n    X_true_ties = np.array([\n        [2, 0, 5],\n        [2, 3, 3],\n        [1, 3, 3],\n        [2, 3, 3],\n    ])\n\n    _check_statistics(X, X_true, \"most_frequent\", [np.nan, 2, 3, 3], -1)\n    _check_statistics(X_ties, X_true_ties, \"most_frequent\", [np.nan, 2, 3, 3], -1)\n"], "sample_855": ["def test_dummy_classifier_on_sparse_X():\n    X = sp.csc_matrix(np.array([[1, 0, 0],\n                                [0, 1, 0],\n                                [0, 0, 1]]))\n    y = [2, 2, 2]\n    y_expected = [2, 2, 2]\n    y_proba_expected = [[1], [1], [1]]\n    cls = DummyClassifier()\n    cls.fit(X, y)\n    y_pred = cls.predict(X)\n    y_pred_proba = cls.predict_proba(X)\n    assert_array_equal(y_pred, y_expected)\n    assert_array_equal(y_pred_proba, y_proba_expected)\n"], "sample_953": ["def test_quickstart_with_custom_template(tempdir):\n    templatedir = tempdir / 'templates'\n    templatedir.mkdir()\n    (templatedir / 'conf.py_t').write_text('Custom template')\n    (templatedir / 'root_doc.rst_t').write_text('Custom root doc')\n\n    answers = {\n        'Root path': tempdir,\n        'Project name': 'Sphinx Test',\n        'Author name': 'Georg Brandl',\n        'Project version': '0.1',\n    }\n    qs.term_input = mock_input(answers)\n    d = {}\n    qs.ask_user(d)\n    qs.generate(d, templatedir=str(templatedir))\n\n    conffile = tempdir / 'conf.py'\n    assert conffile.isfile()\n    assert conffile.read_text() == 'Custom template'\n    assert (tempdir / 'index.rst').isfile()\n    assert (tempdir / 'index.rst').read_text() == 'Custom root doc'\n"], "sample_1062": ["def test_TR22():\n    assert TR22(tan(x)**2) == sec(x)**2 - 1\n    assert TR22(cot(x)**2) == csc(x)**2 - 1\n    assert TR22(tan(x)**4) == (sec(x)**2 - 1)**2\n    assert TR22(cot(x)**4) == (csc(x)**2 - 1)**2\n    assert TR22(tan(x)**-2) == tan(x)**-2\n    assert TR22(cot(x)**-2) == cot(x)**-2\n    assert TR22(tan(x)**-4) == tan(x)**-4\n    assert TR22(cot(x)**-4) == cot(x)**-4\n"], "sample_300": ["def test_add_annotation(self):\n    query = Query(Item)\n    query.add_annotation(Func('name', function='UPPER'), alias='upper_name')\n    self.assertEqual(query.annotations['upper_name'].function, 'UPPER')\n    self.assertEqual(query.annotations['upper_name'].source_expressions[0].target, Item._meta.get_field('name'))\n"], "sample_1045": ["def test_issue_12345():\n    # Test that the Rational class handles large numerators and denominators correctly\n    large_num = 10**1000\n    large_den = 10**1001\n    r = Rational(large_num, large_den)\n    assert r.p == large_num\n    assert r.q == large_den\n    assert r.limit_denominator() == r\n"], "sample_1071": ["def test_convert_to_dimensionless():\n    assert convert_to(pi, meter) == pi\n    assert convert_to(pi, [meter, second]) == pi\n    assert convert_to(pi, (meter, second)) == pi\n    assert convert_to(pi, Tuple(meter, second)) == pi\n    assert convert_to(pi*radians, degree) == pi*radians\n    assert convert_to(pi*radians, [meter, degree]) == pi*radians\n    assert convert_to(pi, [meter, degree]) == pi\n    assert convert_to(pi, Tuple(meter, degree)) == pi\n"], "sample_467": ["def test_value_from_datadict_with_invalid_year(self):\n    data = {\"field_year\": \"abc\", \"field_month\": \"12\", \"field_day\": \"1\"}\n    self.assertIsNone(self.widget.value_from_datadict(data, {}, \"field\"))\n"], "sample_593": ["def test_collapsible_section():\n    name = \"Test Section\"\n    inline_details = \"Inline details\"\n    details = \"Details\"\n    n_items = 10\n    enabled = True\n    collapsed = False\n\n    formatted = fh.collapsible_section(\n        name, inline_details, details, n_items, enabled, collapsed\n    )\n    assert name in formatted\n    assert inline_details in formatted\n    assert details in formatted\n    assert str(n_items) in formatted\n    assert \"checked\" not in formatted\n\n    formatted = fh.collapsible_section(\n        name, inline_details, details, n_items, enabled=False, collapsed=False\n    )\n    assert \"disabled\" in formatted\n\n    formatted = fh.collapsible_section(\n        name, inline_details, details, n_items, enabled=True, collapsed=True\n    )\n    assert \"checked\" in formatted\n"], "sample_712": ["def test_ordinal_encoder_handle_unknown():\n    X = np.array([['a', 2, 55], ['b', 1, 55], ['a', 3, 55]])\n    X2 = np.array([['c', 1, 55]])\n\n    # Test that ordinal encoder raises error for unknown features\n    # present during transform.\n    oe = OrdinalEncoder(handle_unknown='error')\n    oe.fit(X)\n    assert_raises(ValueError, oe.transform, X2)\n\n    # Test the ignore option, ignores unknown features (giving all 0's)\n    oe = OrdinalEncoder(handle_unknown='ignore')\n    oe.fit(X)\n    X2_passed = X2.copy()\n    assert_array_equal(oe.transform(X2_passed), np.array([[0., 0., 0.]]))\n    # ensure transformed data was not modified in place\n    assert_allclose(X2, X2_passed)\n\n    # Raise error if handle_unknown is neither ignore or error.\n    oe = OrdinalEncoder(handle_unknown='42')\n    assert_raises(ValueError, oe.fit, X)\n"], "sample_108": ["    def test_locale_prefix_pattern_match(self):\n        resolver = get_resolver()\n        match = resolver.resolve('/en/articles/2003/')\n        self.assertEqual(match.url_name, 'articles-2003')\n        self.assertEqual(match.args, ())\n        self.assertEqual(match.kwargs, {})\n        self.assertEqual(match.route, 'articles/2003/')\n"], "sample_531": ["def test_subfigure_subplotspec():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    subfig = fig.add_subfigure(gs[0, 0])\n    assert subfig._subplotspec == gs[0, 0]\n    assert subfig._subplotspec.get_gridspec() == gs\n    assert subfig._subplotspec.get_topmost_subplotspec() == gs[0, 0]\n    assert subfig._subplotspec.get_position(fig) == gs[0, 0].get_position(fig)\n"], "sample_928": ["def test_default_role():\n    with default_role('test_docname', 'emphasis'):\n        assert docutils.get_role('') is not None\n\n    with default_role('test_docname', 'nonexistent_role'):\n        assert docutils.get_role('') is None\n\n    with default_role('test_docname', ''):\n        assert docutils.get_role('') is None\n"], "sample_590": ["def test_concat_positions_kwarg(self):\n    ds1 = Dataset({\"foo\": (\"x\", [1, 2])}, {\"x\": [0, 1]})\n    ds2 = Dataset({\"foo\": (\"x\", [3, 4])}, {\"x\": [0, 1]})\n    expected = Dataset({\"foo\": ((\"y\", \"x\"), [[1, 2], [3, 4]])}, {\"x\": [0, 1], \"y\": [0, 1]})\n    actual = concat([ds1, ds2], dim=\"y\", positions=[0, 1])\n    assert_identical(expected, actual)\n\n    with raises_regex(ValueError, \"length of positions does not match\"):\n        concat([ds1, ds2], dim=\"y\", positions=[0])\n\n    with raises_regex(ValueError, \"positions must be a list of integer arrays\"):\n        concat([ds1, ds2], dim=\"y\", positions=[0.0, 1.0])\n\n    with raises_regex(ValueError, \"positions must be a list of integer arrays\"):\n        concat([ds1, ds2], dim=\"y\", positions=[\"a\", \"b\"])\n"], "sample_550": ["def test_axes_set_aspect():\n    fig, ax = plt.subplots()\n    ax.set_aspect('equal')\n    assert ax.get_aspect() == 1\n    ax.set_aspect('auto')\n    assert ax.get_aspect() == 'auto'\n    ax.set_aspect(2)\n    assert ax.get_aspect() == 2\n    with pytest.raises(ValueError, match=\"aspect must be finite and positive\"):\n        ax.set_aspect(-1)\n    with pytest.raises(ValueError, match=\"aspect must be finite and positive\"):\n        ax.set_aspect(np.nan)\n"], "sample_1151": ["def test_Mod_eval():\n    # Test the eval method of the Mod class\n    assert Mod(5, 3).eval() == 2\n    assert Mod(-5, 3).eval() == 1\n    assert Mod(5, -3).eval() == -1\n    assert Mod(-5, -3).eval() == -2\n    assert Mod(0, 3).eval() == 0\n    with raises(ZeroDivisionError):\n        Mod(5, 0).eval()\n    assert Mod(nan, 3).eval() is nan\n    assert Mod(5, nan).eval() is nan\n    assert Mod(nan, nan).eval() is nan\n\n    # Test the eval method with symbolic expressions\n    x, y = symbols('x y')\n    assert Mod(x, y).eval() == Mod(x, y)\n    assert Mod(x + 3, y).eval() == Mod(x, y)\n    assert Mod(x + 3.0, y).eval() == Mod(1.*x, y)\n    assert Mod(x - S(33)/10, y).eval() == Mod(x + S(7)/10, y)\n\n    # Test the eval method with rational numbers\n    assert Mod(Rational(13, 10), Rational(7, 10)).eval() == Rational(6, 10)\n    assert Mod(Rational(13, 10), 0.7).eval() == Float(0.6)\n    assert Mod(1.3, Rational(7, 10)).eval() == Float(0.6)\n"], "sample_1099": ["def test_eval_partial_derivative_mixed_tensor_expr3():\n    tau, alpha = symbols(\"tau alpha\")\n\n    base_expr3 = A(i)*H(-i, j) + H(i, j)*H(-i, -j) + tau**alpha*A(j)\n\n    tensor_derivative = PartialDerivative(base_expr3, H(k, m))._perform_derivative()\n    vector_derivative = PartialDerivative(base_expr3, A(k))._perform_derivative()\n    scalar_derivative = PartialDerivative(base_expr3, tau)._perform_derivative()\n\n    assert (tensor_derivative - A(L_0)*L.metric(-L_0, -L_1)*L.delta(L_1, -k)*L.delta(j, -m) - \n            L.delta(i, -k)*L.delta(j, -m)*H(-i, -j) - \n            H(i, L_0)*L.metric(-L_0, -L_1)*L.delta(L_1, -k)*L.delta(-i, -m) - \n            H(L_0, j)*L.metric(-L_0, -L_1)*L.delta(L_1, -k)*L.delta(-L_0, -m)).expand() == 0\n\n    assert (vector_derivative - (tau**alpha*L.delta(j, -k) +\n        L.delta(L_0, -k)*A(-L_0)*A(j) +\n        A(L_0)*L.metric(-L_0, -L_1)*L.delta(L_1, -k)*A(j) +\n        A(L_0)*A(-L_0)*L.delta(j, -k) +\n        L.delta(L_0, -k)*H(-L_0, j) +\n        H(i, L_0)*L.metric(-L_0, -L_1)*L.delta(L_1, -k)*H(-i, j) +\n        H(L_0, j)*L.metric(-L_0, -L_1)*L.delta(L_1, -k)*H(i, -i))).expand() == 0\n\n    assert scalar_derivative - alpha*1/tau*tau**alpha*A(j) == 0\n"], "sample_863": ["def test_pipeline_memory_clone():\n    # Test that the memory is cloned when cloning a pipeline\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    if LooseVersion(joblib.__version__) < LooseVersion('0.12'):\n        # Deal with change of API in joblib\n        memory = joblib.Memory(cachedir=cachedir, verbose=10)\n    else:\n        memory = joblib.Memory(location=cachedir, verbose=10)\n    pipeline = Pipeline([('transf', DummyTransf()), ('svc', SVC())],\n                        memory=memory)\n    cloned_pipeline = clone(pipeline)\n    assert cloned_pipeline.memory is not pipeline.memory\n    assert cloned_pipeline.memory.location == pipeline.memory.location\n    assert cloned_pipeline.memory.cachedir == pipeline.memory.cachedir\n    assert cloned_pipeline.memory.verbose == pipeline.memory.verbose\n    shutil.rmtree(cachedir)\n"], "sample_206": ["def test_generate_filename(self):\n    \"\"\"\n    FileField.generate_filename() applies the upload_to callable or prepends\n    the upload_to string to the filename, then delegates to the storage\n    backend.\n    \"\"\"\n    class MyModel(models.Model):\n        myfile = models.FileField(upload_to='uploads')\n\n    model = MyModel()\n    field = MyModel._meta.get_field('myfile')\n    filename = field.generate_filename(model, 'example.txt')\n    self.assertEqual(filename, 'uploads/example.txt')\n\n        return 'uploads/%s' % filename\n\n    class MyModelCallable(models.Model):\n        myfile = models.FileField(upload_to=upload_to_callable)\n\n    model_callable = MyModelCallable()\n    field_callable = MyModelCallable._meta.get_field('myfile')\n    filename_callable = field_callable.generate_filename(model_callable, 'example.txt')\n    self.assertEqual(filename_callable, 'uploads/example.txt')\n"], "sample_532": ["def test_contour_labeler_event_handler():\n    # Test that the event handler for contour labeler works correctly\n    x, y = np.meshgrid(np.arange(0, 10), np.arange(0, 10))\n    z = np.max(np.dstack([abs(x), abs(y)]), 2)\n\n    fig, ax = plt.subplots()\n    cs = ax.contour(x, y, z)\n\n    # Simulate a left mouse button click\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 0.5, 0.5, 1, 'left')\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 1\n\n    # Simulate a right mouse button click\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 0.5, 0.5, 1, 'right')\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 0\n\n    # Simulate a middle mouse button click\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 0.5, 0.5, 1, 'middle')\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 0\n\n    # Simulate a key press event\n    event = mpl.backend_bases.KeyEvent('key_press_event', fig.canvas, 0.5, 0.5, 'enter')\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 0\n"], "sample_566": ["def test_subfigure_subplotspec():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    subfig = fig.add_subfigure(gs[0, 0])\n    assert subfig._subplotspec == gs[0, 0]\n    assert subfig._subplotspec.get_gridspec() == gs\n"], "sample_990": ["def test_hyperbolic_function_properties():\n    x = Symbol('x')\n    assert sinh(x).is_real == x.is_real\n    assert cosh(x).is_real == x.is_real\n    assert tanh(x).is_real == x.is_real\n    assert coth(x).is_real == x.is_real\n    assert csch(x).is_real == x.is_real\n    assert sech(x).is_real == x.is_real\n    assert asinh(x).is_real == x.is_real\n    assert acosh(x).is_real == x.is_real\n    assert atanh(x).is_real == x.is_real\n    assert acoth(x).is_real == x.is_real\n    assert asech(x).is_real == x.is_real\n    assert acsch(x).is_real == x.is_real\n\n    assert sinh(x).is_finite == x.is_finite\n    assert cosh(x).is_finite == x.is_finite\n    assert tanh(x).is_finite == x.is_finite\n    assert coth(x).is_finite == x.is_finite\n    assert csch(x).is_finite == x.is_finite\n    assert sech(x).is_finite == x.is_finite\n    assert asinh(x).is_finite == x.is_finite\n    assert acosh(x).is_finite == x.is_finite\n    assert atanh(x).is_finite == x.is_finite\n    assert acoth(x).is_finite == x.is_finite\n    assert asech(x).is_finite == x.is_finite\n    assert acsch(x).is_finite == x.is_finite\n"], "sample_831": ["def test_plot_tree_friedman_mse(pyplot):\n    # mostly smoke tests\n    # Check correctness of export_graphviz for criterion = friedman_mse\n    clf = DecisionTreeRegressor(max_depth=3,\n                                min_samples_split=2,\n                                criterion=\"friedman_mse\",\n                                random_state=2)\n    clf.fit(X, y)\n\n    # Test export code\n    feature_names = ['first feat', 'sepal_width']\n    nodes = plot_tree(clf, feature_names=feature_names)\n    assert len(nodes) == 3\n    assert nodes[0].get_text() == (\"first feat <= 0.0\\nfriedman_mse = 1.0\\n\"\n                                   \"samples = 6\\nvalue = 0.0\")\n    assert nodes[1].get_text() == \"friedman_mse = 0.0\\nsamples = 3\\nvalue = -1.0\"\n    assert nodes[2].get_text() == \"friedman_mse = 0.0\\nsamples = 3\\nvalue = 1.0\"\n"], "sample_8": ["    def test_ufunc_mask_propagation(self):\n        # Test that ufunc's propagate the mask correctly\n        ma = self.ma\n        for ufunc in [np.sin, np.cos, np.tan, np.exp, np.log, np.sqrt]:\n            result = ufunc(ma)\n            assert_array_equal(result.unmasked, ufunc(ma.unmasked))\n            assert_array_equal(result.mask, ma.mask)\n"], "sample_914": ["def test_unparse_arguments(source, expected):\n    tree = ast.parse(source)\n    func_def = tree.body[0]\n    assert ast.unparse_arguments(func_def.args) == expected\n"], "sample_161": ["    def test_referencing_to_swapped_model(self):\n        class Replacement(models.Model):\n            pass\n\n        class SwappedModel(models.Model):\n            class Meta:\n                swappable = 'TEST_SWAPPED_MODEL'\n\n        class Model(models.Model):\n            explicit_fk = models.ForeignKey(\n                SwappedModel,\n                models.CASCADE,\n                related_name='explicit_fk',\n            )\n            implicit_fk = models.ForeignKey(\n                'invalid_models_tests.SwappedModel',\n                models.CASCADE,\n                related_name='implicit_fk',\n            )\n            explicit_m2m = models.ManyToManyField(SwappedModel, related_name='explicit_m2m')\n            implicit_m2m = models.ManyToManyField(\n                'invalid_models_tests.SwappedModel',\n                related_name='implicit_m2m',\n            )\n\n        fields = [\n            Model._meta.get_field('explicit_fk'),\n            Model._meta.get_field('implicit_fk'),\n            Model._meta.get_field('explicit_m2m'),\n            Model._meta.get_field('implicit_m2m'),\n        ]\n\n        expected_error = Error(\n            (\"Field defines a relation with the model \"\n             \"'invalid_models_tests.SwappedModel', which has been swapped out.\"),\n            hint=\"Update the relation to point at 'settings.TEST_SWAPPED_MODEL'.\",\n            id='fields.E301',\n        )\n\n        for field in fields:\n            expected_error.obj = field\n            self.assertEqual(field.check(from_model=Model), [expected_error])\n"], "sample_504": ["def test_colorbar_remove_twice():\n    \"\"\"\n    Test that removing a colorbar twice does not raise an exception.\n    \"\"\"\n    fig, ax = plt.subplots()\n    sc = ax.scatter([1, 2], [3, 4], cmap=\"spring\")\n    sc.set_array(np.array([5, 6]))\n    cb = fig.colorbar(sc)\n    cb.remove()\n    cb.remove()\n"], "sample_1171": ["def test_ComplexRegion_polar_intersect():\n    # Polar form\n    c1 = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)\n    c2 = ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    c3 = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi), polar=True)\n    c4 = ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n\n    p1 = Union(Interval(0, 1)*Interval(0, 2*S.Pi), Interval(0, 1)*Interval(0, S.Pi))\n    p2 = Union(Interval(0, oo)*Interval(0, S.Pi), Interval(0, oo)*Interval(S.Pi, 2*S.Pi))\n\n    assert c1.intersect(c2) == ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    assert c3.intersect(c4) == ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n\n    # Rectangular form\n    c5 = ComplexRegion(Interval(2, 5)*Interval(6, 9))\n    c6 = ComplexRegion(Interval(4, 6)*Interval(10, 12))\n    c7 = ComplexRegion(Interval(0, 10)*Interval(-10, 0))\n    c8 = ComplexRegion(Interval(12, 16)*Interval(14, 20))\n\n    p3 = Union(Interval(2, 5)*Interval(6, 9), Interval(4, 6)*Interval(10, 12))\n    p4 = Union(Interval(0, 10)*Interval(-10, 0), Interval(12, 16)*Interval(14, 20))\n\n    assert c5.intersect(c6) == ComplexRegion(Interval(4, 5)*Interval(10, 9))\n    assert c7.intersect(c8) == ComplexRegion(Interval(12, 10)*Interval(14, 0))\n\n    assert c1.intersect(Interval(2, 4)) == Intersection(c1, Interval(2, 4), evaluate=False)\n    assert c5.intersect(Interval(2, "], "sample_472": ["def test_page_range_edge_cases(self):\n    \"\"\"\n    Test edge cases for Paginator.page_range.\n    \"\"\"\n    paginator = Paginator([1, 2, 3], 2)\n    self.assertEqual(list(paginator.page_range), [1, 2])\n\n    paginator = Paginator([1, 2, 3], 1)\n    self.assertEqual(list(paginator.page_range), [1, 2, 3])\n\n    paginator = Paginator([], 2)\n    self.assertEqual(list(paginator.page_range), [])\n\n    paginator = Paginator([], 2, allow_empty_first_page=True)\n    self.assertEqual(list(paginator.page_range), [1])\n"], "sample_898": ["def test_auc():\n    # Test area under the curve\n    x = np.array([0, 1, 2, 3])\n    y = np.array([0, 0.5, 1, 1])\n    assert_almost_equal(auc(x, y), 2.0)\n\n    # Test area under the curve with reorder=True\n    x = np.array([3, 2, 1, 0])\n    y = np.array([0, 0.5, 1, 1])\n    assert_almost_equal(auc(x, y, reorder=True), 2.0)\n\n    # Test area under the curve with reorder=False\n    x = np.array([3, 2, 1, 0])\n    y = np.array([0, 0.5, 1, 1])\n    assert_raises(ValueError, auc, x, y, reorder=False)\n\n    # Test area under the curve with x not monotonic\n    x = np.array([0, 2, 1, 3])\n    y = np.array([0, 0.5, 1, 1])\n    assert_raises(ValueError, auc, x, y)\n\n    # Test area under the curve with x and y of different lengths\n    x = np.array([0, 1, 2])\n    y = np.array([0, 0.5, 1, 1])\n    assert_raises(ValueError, auc, x, y)\n"], "sample_985": ["def test_real_root():\n    from sympy import root, real_root, Rational, Symbol\n    from sympy.abc import x, n\n\n    assert real_root(-8, 3) == -2\n    assert root(-8, 3) == 2*(-1)**(1/3)\n    assert real_root(_) == -2\n\n    assert real_root(-32, 5) == -2\n    assert root(-32, 5) == 2*(-1)**(1/5)\n    assert real_root(_) == -2\n\n    assert real_root(-27, 3) == -3\n    assert root(-27, 3) == 3*(-1)**(1/3)\n    assert real_root(_) == -3\n\n    assert real_root(-64, 6) == -2\n    assert root(-64, 6) == 2*(-1)**(1/6)\n    assert real_root(_) == -2\n\n    assert real_root(-125, 3) == -5\n    assert root(-125, 3) == 5*(-1)**(1/3)\n    assert real_root(_) == -5\n\n    assert real_root(-216, 3) == -6\n    assert root(-216, 3) == 6*(-1)**(1/3)\n    assert real_root(_) == -6\n\n    assert real_root(-343, 3) == -7\n    assert root(-343, 3) == 7*(-1)**(1/3)\n    assert real_root(_) == -7\n\n    assert real_root(-512, 3) == -8\n    assert root(-512, 3) == 8*(-1)**(1/3)\n    assert real_root(_) == -8\n\n    assert real_root(-729, 3) == -9\n    assert root(-729, 3) == 9*(-1)**(1/3)\n    assert real_root(_) == -9\n\n    assert real_root(-1000, 3) == -10\n    assert root(-1000, 3) == 10*(-1)**(1/3)\n    assert real_root(_) == -10\n\n    assert real_root(-1331, 3) == -11\n    assert root(-1331, 3) == 11*(-1)**(1/3)\n    assert real_root(_) == -11\n\n    assert"], "sample_942": ["def test_pyclass_nesting(app):\n    text = (\".. py:class:: Class1\\n\"\n            \"\\n\"\n            \"   .. py:class:: Class2\\n\"\n            \"\\n\"\n            \"       .. py:class:: Class3\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_name, \"Class1\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc,\n                                                  [desc_content, (addnodes.index,\n                                                                   desc)])])]))\n    assert_node(doctree[1][1][0], addnodes.index,\n                entries=[('single', 'Class1 (built-in class)', 'Class1', '', None)])\n    assert 'Class1' in domain.objects\n    assert domain.objects['Class1'] == ('index', 'Class1', 'class', False)\n\n    assert_node(doctree[1][1][1], addnodes.index,\n                entries=[('single', 'Class2 (class in Class1)', 'Class1.Class2', '', None)])\n    assert 'Class1.Class2' in domain.objects\n    assert domain.objects['Class1.Class2'] == ('index', 'Class1.Class2', 'class', False)\n\n    assert_node(doctree[1][1][1][1][1][0], addnodes.index,\n                entries=[('single', 'Class3 (class in Class1.Class2)', 'Class1.Class2.Class3', '', None)])\n    assert 'Class1.Class2.Class3' in domain.objects\n    assert domain.objects['Class1.Class2.Class3'] == ('index', 'Class1.Class2.Class3', 'class', False)\n"], "sample_818": ["def test_spectral_clustering_edge_cases():\n    # Test edge cases for spectral clustering\n    # Test with a single sample\n    X = np.array([[1, 1]])\n    sp = SpectralClustering(n_clusters=1, random_state=0)\n    labels = sp.fit(X).labels_\n    assert_array_equal(labels, np.array([0]))\n\n    # Test with two identical samples\n    X = np.array([[1, 1], [1, 1]])\n    sp = SpectralClustering(n_clusters=1, random_state=0)\n    labels = sp.fit(X).labels_\n    assert_array_equal(labels, np.array([0, 0]))\n\n    # Test with two distinct samples\n    X = np.array([[1, 1], [2, 2]])\n    sp = SpectralClustering(n_clusters=2, random_state=0)\n    labels = sp.fit(X).labels_\n    assert_array_equal(labels, np.array([0, 1]))\n\n    # Test with a single feature\n    X = np.array([[1], [2], [3]])\n    sp = SpectralClustering(n_clusters=2, random_state=0)\n    labels = sp.fit(X).labels_\n    assert_array_equal(labels, np.array([0, 0, 1]))\n\n    # Test with a single cluster\n    X = np.array([[1, 1], [1, 1], [1, 1]])\n    sp = SpectralClustering(n_clusters=1, random_state=0)\n    labels = sp.fit(X).labels_\n    assert_array_equal(labels, np.array([0, 0, 0]))\n"], "sample_435": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = \"!\"\n        html = widget.render(\"name\", value, {\"id\": \"id_password\"})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_1136": ["def test_Poly_from_ExpressionDomain():\n    dom = EX\n    assert Poly(dom(x+1), y, domain=dom).rep == DMP([dom(x+1)], dom)\n    dom = dom.get_field()\n    assert Poly(dom(x+1), y, domain=dom).rep == DMP([dom(x+1)], dom)\n\n    dom = EX[x]\n    assert Poly(dom(x+1), y, domain=dom).rep == DMP([dom(x+1)], dom)\n    dom = dom.get_field()\n    assert Poly(dom(x+1), y, domain=dom).rep == DMP([dom(x+1)], dom)\n\n    dom = EX.old_poly_ring(x)\n    assert Poly(dom([1, 1]), y, domain=dom).rep == DMP([dom([1, 1])], dom)\n    dom = dom.get_field()\n    assert Poly(dom([1, 1]), y, domain=dom).rep == DMP([dom([1, 1])], dom)\n\n    dom = EX.algebraic_field(I)\n    assert Poly(dom([1, 1]), x, domain=dom).rep == DMP([dom([1, 1])], dom)\n"], "sample_705": ["def test_pytester_run_with_timeout_zero(pytester: Pytester) -> None:\n    testfile = pytester.makepyfile(\"def test_no_timeout(): pass\")\n\n    with pytest.raises(pytester.TimeoutExpired):\n        pytester.runpytest_subprocess(testfile, timeout=0)\n"], "sample_1047": ["def test_issue_16313_add():\n    x = Symbol('x', real=False)\n    k = Symbol('k', real=True)\n    l = Symbol('l', real=True, zero=False)\n    assert (x + k).is_real is None\n    assert (x + l).is_real is False\n    assert (x + x).is_real is None\n    assert (x + x + k).is_real is None\n    assert (x + x + l).is_real is False\n"], "sample_1193": ["def test_are_similar():\n    from sympy import Point, Circle, Triangle, are_similar\n    c1, c2 = Circle(Point(0, 0), 4), Circle(Point(1, 4), 3)\n    t1 = Triangle(Point(0, 0), Point(1, 0), Point(0, 1))\n    t2 = Triangle(Point(0, 0), Point(2, 0), Point(0, 2))\n    t3 = Triangle(Point(0, 0), Point(3, 0), Point(0, 1))\n    assert are_similar(t1, t2)\n    assert not are_similar(t1, t3)\n    raises(GeometryError, lambda: are_similar(c1, t1))\n"], "sample_666": ["def test_log_capture_handler_context_manager(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\\\n        import logging\n        import pytest\n\n            with caplog.at_level(logging.DEBUG):\n                logging.debug(\"debug message\")\n                logging.info(\"info message\")\n            assert caplog.record_tuples == [\n                (\"root\", logging.DEBUG, \"debug message\"),\n                (\"root\", logging.INFO, \"info message\"),\n            ]\n        \"\"\"\n    )\n    result = testdir.runpytest(p)\n    result.assert_outcomes(passed=1)\n"], "sample_1115": ["def test_tensor_element():\n    L = TensorIndexType(\"L\")\n    i0, i1, i2 = tensor_indices('i0:3', L)\n    A = TensorHead(\"A\", [L]*2)\n    te = TensorElement(A(i0, i1), {i0: 1})\n    assert te.get_free_indices() == [i1]\n    assert te.get_indices() == [i0, i1]\n    assert te.substitute_indices((i1, i2)) == TensorElement(A(i0, i2), {i0: 1})\n    assert te.substitute_indices((i0, i2)) == TensorElement(A(i2, i1), {i2: 1})\n    assert te.substitute_indices((i0, i2), (i1, i2)) == TensorElement(A(i2, i2), {i2: 1})\n    assert te.substitute_indices((i0, i2), (i1, i0)) == TensorElement(A(i2, i0), {i0: 1, i2: 1})\n    assert te.substitute_indices((i0, i2), (i1, i0), (i2, i1)) == TensorElement(A(i1, i1), {i1: 1})\n"], "sample_466": ["def test_serialize_timezone(self):\n    \"\"\"\n    Test serialization of timezone objects.\n    \"\"\"\n    self.assertSerializedResultEqual(\n        datetime.timezone.utc,\n        (\"datetime.timezone.utc\", {\"import datetime\"}),\n    )\n    self.assertSerializedResultEqual(\n        get_default_timezone(),\n        (\"django.utils.timezone.get_default_timezone()\", {\"from django.utils import timezone\"}),\n    )\n    self.assertSerializedResultEqual(\n        get_fixed_timezone(180),\n        (\"django.utils.timezone.get_fixed_timezone(180)\", {\"from django.utils import timezone\"}),\n    )\n    self.assertSerializedResultEqual(\n        zoneinfo.ZoneInfo(\"Europe/Paris\"),\n        (\"zoneinfo.ZoneInfo('Europe/Paris')\", {\"import zoneinfo\"}),\n    )\n"], "sample_486": ["def test_inlineformset_factory_validates_unique_together(self):\n    \"\"\"\n    #24958 - Inlines should validate unique_together constraints.\n    \"\"\"\n    FormSet = inlineformset_factory(\n        UUIDPKParent, UUIDPKChildOfAutoPKParent, fields=\"__all__\"\n    )\n    formset = FormSet(\n        {\n            \"uuidpkchildofautoppkparent_set-TOTAL_FORMS\": 2,\n            \"uuidpkchildofautoppkparent_set-INITIAL_FORMS\": 0,\n            \"uuidpkchildofautoppkparent_set-MAX_NUM_FORMS\": \"\",\n            \"uuidpkchildofautoppkparent_set-0-name\": \"Foo\",\n            \"uuidpkchildofautoppkparent_set-0-parent\": \"123e4567-e89b-12d3-a456-426614174000\",\n            \"uuidpkchildofautoppkparent_set-1-name\": \"Bar\",\n            \"uuidpkchildofautoppkparent_set-1-parent\": \"123e4567-e89b-12d3-a456-426614174000\",\n        }\n    )\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(len(formset.non_form_errors()), 1)\n"], "sample_403": ["def test_alter_field_with_func_index_together(self):\n    app_label = \"test_alfuncin_to\"\n    index_name = f\"{app_label}_pony_idx\"\n    table_name = f\"{app_label}_pony\"\n    project_state = self.set_up_test_model(\n        app_label,\n        indexes=[models.Index(Abs(\"pink\"), name=index_name)],\n    )\n    operation = migrations.AlterField(\n        \"Pony\", \"pink\", models.IntegerField(null=True)\n    )\n    new_state = project_state.clone()\n    operation.state_forwards(app_label, new_state)\n    with connection.schema_editor() as editor:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    self.assertIndexNameExists(table_name, index_name)\n    with connection.schema_editor() as editor:\n        operation.database_backwards(app_label, editor, new_state, project_state)\n    self.assertIndexNameExists(table_name, index_name)\n"], "sample_1140": ["def test_pretty_TensorProduct():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    assert upretty(TensorProduct(A, B, C)) == \"A\\u2297B\\u2297C\"\n    assert upretty(TensorProduct(A, B, C, A)) == \"A\\u2297B\\u2297C\\u2297A\"\n"], "sample_682": ["def test_xfail_with_invalid_strict_value(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = invalid\n    \"\"\"\n    )\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(reason='unsupported feature')\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest(p, \"-rxX\")\n    result.stdout.fnmatch_lines([\"*1 xpassed*\"])\n    assert result.ret == 0\n"], "sample_679": ["def test_mark_evaluator_invalidraise(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.raises(ValueError)\n            raise ValueError(\"Test error\")\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    passed, skipped, failed = reprec.listoutcomes()\n    assert len(passed) == 1\n    assert len(skipped) == 0\n    assert len(failed) == 0\n\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.raises(ValueError)\n            pass\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    passed, skipped, failed = reprec.listoutcomes()\n    assert len(passed) == 0\n    assert len(skipped) == 0\n    assert len(failed) == 1\n"], "sample_343": ["    def test_get_reverse_path_info(self):\n        question = Question.objects.create(text='test')\n        answer = Answer.objects.create(question=question)\n        path_info = Question.answer_set.get_reverse_path_info()\n        self.assertEqual(len(path_info), 1)\n        self.assertEqual(path_info[0].from_opts, Answer._meta)\n        self.assertEqual(path_info[0].to_opts, Question._meta)\n        self.assertEqual(path_info[0].target_fields, (Question._meta.pk,))\n        self.assertEqual(path_info[0].join_field, Question.answer_set)\n        self.assertFalse(path_info[0].m2m)\n        self.assertFalse(path_info[0].direct)\n"], "sample_1059": ["def test_jacobi_normalized():\n    n = Symbol(\"n\")\n    a = Symbol(\"a\")\n    b = Symbol(\"b\")\n\n    assert jacobi_normalized(0, a, b, x) == 1\n    assert jacobi_normalized(1, a, b, x) == jacobi(1, a, b, x)/sqrt(2**(a + b + 1)*gamma(a + 2)*gamma(b + 2)/((a + b + 3)*2*gamma(a + b + 2)))\n\n    X = jacobi_normalized(n, a, b, x)\n    assert isinstance(X, jacobi_normalized)\n\n    assert jacobi_normalized(n, a, b, -x) == (-1)**n*jacobi_normalized(n, b, a, x)\n    assert jacobi_normalized(n, a, b, 0) == jacobi(n, a, b, 0)/sqrt(2**(a + b + 1)*gamma(a + n + 1)*gamma(b + n + 1)/((a + b + 2*n + 1)*factorial(n)*gamma(a + b + n + 1)))\n    assert jacobi_normalized(n, a, b, 1) == jacobi(n, a, b, 1)/sqrt(2**(a + b + 1)*gamma(a + n + 1)*gamma(b + n + 1)/((a + b + 2*n + 1)*factorial(n)*gamma(a + b + n + 1)))\n\n    m = Symbol(\"m\", positive=True)\n    assert jacobi_normalized(m, a, b, oo) == oo*RisingFactorial(a + b + m + 1, m)\n    assert unchanged(jacobi_normalized, n, a, b, oo)\n\n    assert conjugate(jacobi_normalized(m, a, b, x)) == jacobi_normalized(m, conjugate(a), conjugate(b), conjugate(x))\n\n    _k = Dummy('k')\n    assert diff(jacobi_normalized(n, a, b, x), n) == Derivative(jacobi_normalized(n, a, b, x), n)\n    assert diff(jacobi_normalized(n, a, b, x), a).dummy_eq(Sum((jacobi_normalized(n, a, b, x) +\n        (2*_k + a + b + 1)*RisingFactorial(_"], "sample_142": ["def test_model_form_save_m2m(self):\n    class SongForm(forms.ModelForm):\n        class Meta:\n            model = Song\n            fields = ['title', 'album']\n\n    form = SongForm({'title': 'Test Song'}, instance=Song())\n    form.save()\n    self.assertEqual(form.instance.title, 'Test Song')\n    self.assertIsNone(form.instance.album)\n\n    form = SongForm({'title': 'Test Song', 'album': 1}, instance=Song())\n    form.save()\n    self.assertEqual(form.instance.title, 'Test Song')\n    self.assertEqual(form.instance.album_id, 1)\n\n    form = SongForm({'title': 'Test Song'}, instance=Song(album=Album()))\n    form.save()\n    self.assertEqual(form.instance.title, 'Test Song')\n    self.assertIsNotNone(form.instance.album)\n"], "sample_124": ["def test_field_with_custom_error_messages(self):\n    class CustomCharField(CharField):\n        default_error_messages = {\n            'required': 'Custom required error message.',\n            'invalid': 'Custom invalid error message.',\n        }\n\n    class CustomForm(Form):\n        field = CustomCharField()\n\n    form = CustomForm({'field': ''})\n    self.assertEqual(form.errors['field'], ['Custom required error message.'])\n\n    form = CustomForm({'field': 'invalid'})\n    form.fields['field'].error_messages['invalid'] = 'Custom invalid error message for this field.'\n    self.assertEqual(form.errors['field'], ['Custom invalid error message for this field.'])\n"], "sample_1011": ["def test_octave_codeprinter():\n    # Test the OctaveCodePrinter class directly\n    printer = OctaveCodePrinter()\n    assert printer.doprint(x**2 + 2*x + 1) == \"x.^2 + 2*x + 1\"\n    assert printer.doprint(x**2 + 2*x + 1, assign_to='y') == \"y = x.^2 + 2*x + 1;\"\n    assert printer.doprint(x**2 + 2*x + 1, assign_to='y', inline=False) == \"y = x.^2 + 2*x + 1;\"\n"], "sample_186": ["def test_check_ordering_random_with_fields(self):\n    class SongAdmin(admin.ModelAdmin):\n        ordering = ['?', 'title']\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'ordering' has the random ordering marker '?', \"\n            \"but contains other fields as well.\",\n            hint='Either remove the \"?\", or remove the other fields.',\n            obj=SongAdmin,\n            id='admin.E032',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_409": ["def test_i18n42(self):\n    \"\"\"\n    Escaping inside blocktranslate and translate works as if it was\n    directly in the template.\n    \"\"\"\n    output = self.engine.render_to_string(\"i18n42\", {\"anton\": \"\u03b1 & \u03b2\"})\n    self.assertEqual(output, \"\\\\u03b1 \\\\u0026 \\\\u03b2\")\n"], "sample_709": ["def test_pytester_run_with_stdin_and_timeout(pytester: Pytester) -> None:\n    testfile = pytester.makepyfile(\n        \"\"\"\n        import sys\n        import time\n\n            time.sleep(10)\n            sys.stdin.read()\n        \"\"\"\n    )\n    with pytest.raises(pytester.TimeoutExpired):\n        pytester.runpytest_subprocess(testfile, stdin=b\"input\\n2ndline\", timeout=1)\n"], "sample_362": ["def test_alter_field_with_through_model(self):\n    \"\"\"\n    Altering a field that is used in a through model should not create a\n    migration that alters the through model.\n    \"\"\"\n    before = [\n        ModelState('app', 'Foo', [\n            ('id', models.AutoField(primary_key=True)),\n            ('name', models.CharField(max_length=200)),\n        ]),\n        ModelState('app', 'Bar', [\n            ('id', models.AutoField(primary_key=True)),\n            ('foo', models.ForeignKey('app.Foo', models.CASCADE)),\n        ]),\n        ModelState('app', 'Through', [\n            ('id', models.AutoField(primary_key=True)),\n            ('foo', models.ForeignKey('app.Foo', models.CASCADE)),\n            ('bar', models.ForeignKey('app.Bar', models.CASCADE)),\n        ]),\n        ModelState('app', 'M2M', [\n            ('id', models.AutoField(primary_key=True)),\n            ('foos', models.ManyToManyField('app.Foo', through='app.Through')),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'Foo', [\n            ('id', models.AutoField(primary_key=True)),\n            ('name', models.CharField(max_length=400)),\n        ]),\n        ModelState('app', 'Bar', [\n            ('id', models.AutoField(primary_key=True)),\n            ('foo', models.ForeignKey('app.Foo', models.CASCADE)),\n        ]),\n        ModelState('app', 'Through', [\n            ('id', models.AutoField(primary_key=True)),\n            ('foo', models.ForeignKey('app.Foo', models.CASCADE)),\n            ('bar', models.ForeignKey('app.Bar', models.CASCADE)),\n        ]),\n        ModelState('app', 'M2M', [\n            ('id', models.AutoField(primary_key=True)),\n            ('foos', models.ManyToManyField('app.Foo', through='app.Through')),\n        ]),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['AlterField'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='name', model_name='foo')\n"], "sample_659": ["def test_repr_traceback_entry_with_recursion(self):\n        if n > 0:\n            recursive_function(n - 1)\n        else:\n            raise ValueError(\"Recursion error\")\n\n    with pytest.raises(ValueError) as excinfo:\n        recursive_function(10)\n\n    traceback = excinfo.traceback\n    entry = traceback[-1]\n    fmt = FormattedExcinfo(showlocals=True, style=\"long\")\n    reprentry = fmt.repr_traceback_entry(entry, excinfo)\n    assert reprentry.style == \"long\"\n    assert reprentry.reprfuncargs is None\n    assert reprentry.reprlocals is not None\n    assert reprentry.reprfileloc is not None\n"], "sample_74": ["def test_sigint_handler_restore_after_exception(self):\n    \"\"\"SIGINT handler is restored after an exception in subprocess.run.\"\"\"\n        raise subprocess.SubprocessError\n\n    sigint_handler = signal.getsignal(signal.SIGINT)\n    # The default handler isn't SIG_IGN.\n    self.assertNotEqual(sigint_handler, signal.SIG_IGN)\n    try:\n        with mock.patch('subprocess.run', new=_mock_subprocess_run):\n            DatabaseClient.runshell_db({})\n    except subprocess.SubprocessError:\n        pass\n    # dbshell restores the original handler even if an exception occurs.\n    self.assertEqual(sigint_handler, signal.getsignal(signal.SIGINT))\n"], "sample_1180": ["def test_orthogonal_direction():\n    p1 = Point(1, 2, 3)\n    p2 = Point(0, 1, 0)\n    p3 = Point(1, 0, 0)\n    p4 = Point(0, 0, 1)\n\n    assert p1.orthogonal_direction != p1\n    assert p2.orthogonal_direction != p2\n    assert p3.orthogonal_direction != p3\n    assert p4.orthogonal_direction != p4\n\n    assert p1.orthogonal_direction.dot(p1) == 0\n    assert p2.orthogonal_direction.dot(p2) == 0\n    assert p3.orthogonal_direction.dot(p3) == 0\n    assert p4.orthogonal_direction.dot(p4) == 0\n"], "sample_385": ["def test_optgroups(self):\n    beatles = Band.objects.create(name=\"The Beatles\", style=\"rock\")\n    who = Band.objects.create(name=\"The Who\", style=\"rock\")\n    album = Album.objects.create(name=\"Rubber Soul\", band=beatles)\n    album.featuring.add(beatles, who)\n    form = AlbumForm(instance=album)\n    widget = form[\"featuring\"].field.widget\n    optgroups = widget.optgroups(\"featuring\", [beatles.pk, who.pk])\n    self.assertEqual(len(optgroups), 1)\n    self.assertEqual(len(optgroups[0][1]), 2)\n    self.assertEqual(optgroups[0][1][0][\"value\"], beatles.pk)\n    self.assertEqual(optgroups[0][1][0][\"label\"], \"The Beatles\")\n    self.assertEqual(optgroups[0][1][1][\"value\"], who.pk)\n    self.assertEqual(optgroups[0][1][1][\"label\"], \"The Who\")\n"], "sample_631": ["    def test_redefined_variable_in_nested_function(self):\n        \"\"\"Make sure redefined variable in nested function is detected\"\"\"\n        node = astroid.parse(\n            \"\"\"\n            x = 1\n                x = 2\n            return inner\n        \"\"\"\n        )\n        with self.assertAddsMessages(\n            Message(\"redefined-outer-name\", node=node.body[0].body[1], args=\"x\")\n        ):\n            self.walk(node)\n"], "sample_919": ["def test_template_parameter_lists():\n    check('function', 'template<typename T> void f(T)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T, typename U> void f(T, U)',\n          {2: 'I00E1f1T1U'})\n    check('function', 'template<typename T, typename U, typename V> void f(T, U, V)',\n          {2: 'I000E1f1T1U1V'})\n    check('function', 'template<typename T, typename U, typename V, typename W> void f(T, U, V, W)',\n          {2: 'I0000E1f1T1U1V1W'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X> void f(T, U, V, W, X)',\n          {2: 'I00000E1f1T1U1V1W1X'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> void f(T, U, V, W, X, Y)',\n          {2: 'I000000E1f1T1U1V1W1X1Y'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> void f(T, U, V, W, X, Y, Z)',\n          {2: 'I0000000E1f1T1U1V1W1X1Y1Z'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A> void f(T, U, V, W, X, Y, Z, A)',\n          {2: 'I00000000E1f1T1U1V1W1X1Y1Z1A'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A, typename B> void f(T, U, V, W, X, Y, Z, A, B)',\n          {2: 'I000000000E1f1T1U1V1W1X1Y1Z1A1B'})\n"], "sample_967": ["def test_mathjax_custom_delimiters(app, status, warning):\n    app.builder.build_all()\n\n    content = (app.outdir / 'index.html').read_text()\n    html = (r'<span class=\"math notranslate nohighlight\">\\s*'\n            r'\\(a\\^2\\+b\\^2=c\\^2\\)</span>')\n    assert re.search(html, content, re.S)\n\n    html = (r'<div class=\"math notranslate nohighlight\">\\s*'\n            r'\\[a\\^2\\+b\\^2=c\\^2\\]</div>')\n    assert re.search(html, content, re.S)\n"], "sample_318": ["    def test_locale_prefix_pattern(self):\n        resolver = get_resolver()\n        locale_prefix_pattern = LocalePrefixPattern()\n        self.assertEqual(locale_prefix_pattern.match('/en/'), ('', (), {}))\n        self.assertEqual(locale_prefix_pattern.match('/fr/'), ('', (), {}))\n        self.assertEqual(locale_prefix_pattern.match('/'), ('', (), {}))\n        self.assertIsNone(locale_prefix_pattern.match('en/'))\n"], "sample_555": ["def test_fancyarrowpatch_units():\n    from datetime import datetime\n    # Smoke test to check that FancyArrowPatch works with units\n    dtime = datetime(2000, 1, 1)\n    fig, ax = plt.subplots()\n    arrow = FancyArrowPatch((0, dtime), (0.01, dtime))\n"], "sample_975": ["def test_nsolve_rational():\n    x = Symbol('x')\n    assert nsolve(x**2 - Rational(2, 3), x, 1) == sqrt(Rational(2, 3))\n    assert nsolve(x**2 - Rational(2, 3), x, -1) == -sqrt(Rational(2, 3))\n"], "sample_194": ["    def test_clone(self):\n        constraint = models.UniqueConstraint(fields=['foo', 'bar'], name='unique')\n        cloned_constraint = constraint.clone()\n        self.assertEqual(constraint, cloned_constraint)\n        self.assertIsNot(constraint, cloned_constraint)\n"], "sample_236": ["def test_can_fast_delete_with_select_related(self):\n    \"\"\"\n    Test that can_fast_delete() returns False when select_related() is used.\n    \"\"\"\n    a = create_a('auto')\n    qs = A.objects.select_related('auto').filter(name='auto')\n    collector = Collector(using='default')\n    self.assertFalse(collector.can_fast_delete(qs))\n"], "sample_443": ["    def setUp(self):\n        super().setUp()\n        self.dirname = self.mkdtemp()\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n"], "sample_212": ["def test_session_middleware_process_response(self):\n    request = HttpRequest()\n    response = HttpResponse()\n\n    # Test when session is not accessed or modified\n    middleware = SessionMiddleware()\n    middleware.process_request(request)\n    response = middleware.process_response(request, response)\n    self.assertNotIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n    # Test when session is accessed but not modified\n    request.session.accessed = True\n    response = middleware.process_response(request, response)\n    self.assertIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n    # Test when session is modified\n    request.session.modified = True\n    response = middleware.process_response(request, response)\n    self.assertIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n    # Test when session is empty\n    request.session.is_empty = lambda: True\n    response = middleware.process_response(request, response)\n    self.assertNotIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n    # Test when session is deleted\n    request.session.delete = lambda: None\n    response = middleware.process_response(request, response)\n    self.assertNotIn(settings.SESSION_COOKIE_NAME, response.cookies)\n\n    # Test when session save fails\n    request.session.save = lambda: None\n    request.session.modified = True\n    with self.assertRaises(SuspiciousOperation):\n        middleware.process_response(request, response)\n"], "sample_297": ["    def setUpTestData(cls):\n        cls.i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=cls.i1)\n        cls.i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=cls.i2)\n        cls.i3 = Individual.objects.create(alive=True)\n        cls.i4 = Individual.objects.create(alive=False)\n"], "sample_156": ["def test_order_fields(self):\n    class TestForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n        field3 = CharField()\n        field4 = CharField()\n        field5 = CharField()\n        field6 = CharField()\n        field7 = CharField()\n        field8 = CharField()\n        field9 = CharField()\n        field10 = CharField()\n        field11 = CharField()\n        field12 = CharField()\n        field13 = CharField()\n        field14 = CharField()\n\n    p = TestForm(field_order=['field1', 'field2', 'field3', 'field4', 'field5', 'field6', 'field7', 'field8', 'field9', 'field10', 'field11', 'field12', 'field13', 'field14'])\n    self.assertEqual(list(p.fields), ['field1', 'field2', 'field3', 'field4', 'field5', 'field6', 'field7', 'field8', 'field9', 'field10', 'field11', 'field12', 'field13', 'field14'])\n\n    p = TestForm(field_order=['field1', 'field2', 'field3', 'field4', 'field5', 'field6', 'field7', 'field8', 'field9', 'field10', 'field11', 'field12', 'field13'])\n    self.assertEqual(list(p.fields), ['field1', 'field2', 'field3', 'field4', 'field5', 'field6', 'field7', 'field8', 'field9', 'field10', 'field11', 'field12', 'field13', 'field14'])\n\n    p = TestForm(field_order=['field1', 'field2', 'field3', 'field4', 'field5', 'field6', 'field7', 'field8', 'field9', 'field10', 'field11', 'field12', 'field13', 'field14', 'field15'])\n    self.assertEqual(list(p.fields), ['field1', 'field2', 'field3', 'field4', 'field5', 'field6', 'field7', 'field8', 'field9', 'field10', 'field11', 'field12', 'field13', 'field14'])\n\n    p = TestForm(field_order=['field1', 'field2', 'field3', 'field"], "sample_452": ["def test_alter_field_with_func_index_together(self):\n    app_label = \"test_alfuncin_to\"\n    index_name = f\"{app_label}_pony_idx\"\n    table_name = f\"{app_label}_pony\"\n    project_state = self.set_up_test_model(\n        app_label,\n        indexes=[models.Index(Abs(\"pink\"), name=index_name)],\n    )\n    operation = migrations.AlterField(\n        \"Pony\", \"pink\", models.IntegerField(null=True)\n    )\n    new_state = project_state.clone()\n    operation.state_forwards(app_label, new_state)\n    with connection.schema_editor() as editor:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    self.assertIndexNameExists(table_name, index_name)\n    with connection.schema_editor() as editor:\n        operation.database_backwards(app_label, editor, new_state, project_state)\n    self.assertIndexNameExists(table_name, index_name)\n"], "sample_1120": ["def test_matrix_element_subs():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    i, j = symbols('i j')\n    assert A[i, j].subs(A, B) == B[i, j]\n    assert A[i, j].subs({A: B}) == B[i, j]\n    assert A[i, j].subs({A: B, i: 0}) == B[0, j]\n    assert A[i, j].subs({A: B, j: 0}) == B[i, 0]\n    assert A[i, j].subs({A: B, i: 0, j: 0}) == B[0, 0]\n    assert A[i, j].subs({i: 0, j: 0}) == A[0, 0]\n    assert A[i, j].subs({i: 0, j: 0, A: B}) == B[0, 0]\n"], "sample_34": ["def test_compose_with_unrecognized_unit():\n    \"\"\"\n    Issue #2047\n    \"\"\"\n    with catch_warnings(u.UnitsWarning) as warning_lines:\n        unit = u.Unit(\"FOO\", parse_strict='silent')\n        composed = unit.compose()\n\n    assert len(composed) == 1\n    assert composed[0] is unit\n    assert 'FOO' in str(warning_lines[0].message)\n"], "sample_368": ["def test_detect_soft_applied_add_field_non_m2mfield(self):\n    \"\"\"\n    executor.detect_soft_applied() detects non-ManyToManyField tables from an\n    AddField operation.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Create the tables for 0001 but make it look like the migration hasn't\n    # been applied.\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n    executor.migrate([(\"migrations\", None)], fake=True)\n    # Table detection sees 0001 is applied.\n    migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], True)\n    # Create the tables for both migrations but make it look like neither\n    # has been applied.\n    executor.loader.build_graph()\n    executor.migrate([(\"migrations\", \"0001_initial\")], fake=True)\n    executor.migrate([(\"migrations\", \"0002_second\")])\n    executor.loader.build_graph()\n    executor.migrate([(\"migrations\", None)], fake=True)\n    # Table detection sees 0002 is applied.\n    migration = executor.loader.get_migration(\"migrations\", \"0002_second\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], True)\n    # Leave the tables for 0001 except the non-many-to-many table. That missing\n    # table should cause detect_soft_applied() to return False.\n    with connection.schema_editor() as editor:\n        editor.execute(editor.sql_delete_table % {\"table\": \"migrations_book\"})\n    migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], False)\n    # Cleanup by removing the remaining tables.\n    with connection.schema_editor() as editor:\n        editor.execute(editor.sql_delete_table % {\"table\": \"migrations_author\"})\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_book\")\n"], "sample_994": ["def test_issue_12345():\n    # Test case description\n    # Test that the Float class handles precision correctly when converting from a string.\n    assert Float('1.23456789012345678901234567890123456789', 30)._prec == 30\n    assert Float('1.23456789012345678901234567890123456789', 30) == Float('1.23456789012345678901234567890123456789', 30)\n    assert Float('1.23456789012345678901234567890123456789', 30)._mpf_ == Float('1.23456789012345678901234567890123456789', 30)._mpf_\n"], "sample_339": ["def test_model_formset_with_custom_save_method_and_commit_false(self):\n    class PoetForm(forms.ModelForm):\n            # change the name to \"Vladimir Mayakovsky\" just to be a jerk.\n            author = super().save(commit=False)\n            author.name = \"Vladimir Mayakovsky\"\n            if commit:\n                author.save()\n            return author\n\n    PoetFormSet = modelformset_factory(Poet, fields=\"__all__\", form=PoetForm)\n\n    data = {\n        'form-TOTAL_FORMS': '3',  # the number of forms rendered\n        'form-INITIAL_FORMS': '0',  # the number of forms with initial data\n        'form-MAX_NUM_FORMS': '',  # the max number of forms\n        'form-0-name': 'Walt Whitman',\n        'form-1-name': 'Charles Baudelaire',\n        'form-2-name': '',\n    }\n\n    qs = Poet.objects.all()\n    formset = PoetFormSet(data=data, queryset=qs)\n    self.assertTrue(formset.is_valid())\n\n    instances = formset.save(commit=False)\n    for instance in instances:\n        instance.save()\n    self.assertEqual(len(instances), 2)\n    poet1, poet2 = instances\n    self.assertEqual(poet1.name, 'Vladimir Mayakovsky')\n    self.assertEqual(poet2.name, 'Vladimir Mayakovsky')\n"], "sample_598": ["def test_inline_variable_array_repr_dask_array():\n    import dask.array as da\n\n    value = da.random.random((100, 100), chunks=(10, 10))\n    variable = xr.Variable(\"x\", value)\n\n    max_width = 10\n    actual = formatting.inline_variable_array_repr(variable, max_width=max_width)\n\n    assert actual.startswith(\"dask.array<chunksize=(\")\n"], "sample_396": ["    def test_ticket_24605(self):\n        \"\"\"\n        Subquery table names should be quoted.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(\n            Individual.objects.filter(\n                Q(alive=False), Q(related_individual__isnull=True)\n            ),\n            [i4],\n        )\n        self.assertSequenceEqual(\n            Individual.objects.exclude(\n                Q(alive=False), Q(related_individual__isnull=True)\n            ).order_by(\"pk\"),\n            [i1, i2, i3],\n        )\n"], "sample_998": ["def test_latex_issue_15661():\n    from sympy import symbols, Function\n    x, y = symbols('x y')\n    f = Function('f')\n    assert latex(f(x, y)) == r'f{\\left (x,y \\right )}'\n    assert latex(f(x, y, 1)) == r'f{\\left (x,y, 1 \\right )}'\n    assert latex(f(x, y, 1, 2)) == r'f{\\left (x,y, 1, 2 \\right )}'\n"], "sample_1195": ["def test_gamma_trace_with_multiple_terms():\n    g = LorentzIndex.metric\n    m0, m1, m2, m3, m4, m5, m6 = tensor_indices('m0:7', LorentzIndex)\n    n0, n1, n2, n3, n4, n5 = tensor_indices('n0:6', LorentzIndex)\n\n    # working in D=4 dimensions\n    D = 4\n\n    p, q = tensor_heads('p,q', [LorentzIndex])\n    ps = p(m0)*G(-m0)\n    qs = q(m0)*G(-m0)\n    p2 = p(m0)*p(-m0)\n    q2 = q(m0)*q(-m0)\n    pq = p(m0)*q(-m0)\n\n    t = ps*qs*ps*qs + ps*qs*ps*qs*ps*qs\n    r = gamma_trace(t)\n    assert _is_tensor_eq(r, 8*pq*pq - 4*p2*q2 - 12*p2*pq*q2 + 16*pq*pq*pq)\n\n    t = ps*qs*ps*qs*ps*qs + ps*qs*ps*qs*ps*qs*ps*qs\n    r = gamma_trace(t)\n    assert _is_tensor_eq(r, -12*p2*pq*q2 + 16*pq*pq*pq - 32*pq*pq*p2*q2 + 32*pq*pq*pq*pq + 4*p2*p2*q2*q2)\n\n    t = 4*p(m1)*p(m0)*p(-m0)*q(-m1)*q(m2)*q(-m2) + ps*ps*ps*ps*ps*ps*ps*ps\n    assert _is_tensor_eq(gamma_trace(t), t + 4*p2*p2*p2*p2)\n"], "sample_49": ["def test_split_datetime_widget(self):\n    ###############################################################\n    # SplitDateTimeWidget\n    ###############################################################\n\n    class MyForm(Form):\n        date_time = DateTimeField(widget=SplitDateTimeWidget())\n\n    f = MyForm({'date_time_0': '2022-01-01', 'date_time_1': '12:00'})\n    self.assertEqual(f.is_valid(), True)\n    self.assertEqual(f.cleaned_data['date_time'], datetime.datetime(2022, 1, 1, 12, 0))\n\n    f = MyForm({'date_time_0': '2022-01-01', 'date_time_1': '12:00:00'})\n    self.assertEqual(f.is_valid(), True)\n    self.assertEqual(f.cleaned_data['date_time'], datetime.datetime(2022, 1, 1, 12, 0))\n\n    f = MyForm({'date_time_0': '2022-01-01', 'date_time_1': '12:00:00.123'})\n    self.assertEqual(f.is_valid(), True)\n    self.assertEqual(f.cleaned_data['date_time'], datetime.datetime(2022, 1, 1, 12, 0))\n\n    f = MyForm({'date_time_0': '2022-01-01', 'date_time_1': '12:00:00.123456'})\n    self.assertEqual(f.is_valid(), True)\n    self.assertEqual(f.cleaned_data['date_time'], datetime.datetime(2022, 1, 1, 12, 0))\n\n    f = MyForm({'date_time_0': '2022-01-01', 'date_time_1': '12:00:00.123456789'})\n    self.assertEqual(f.is_valid(), True)\n    self.assertEqual(f.cleaned_data['date_time'], datetime.datetime(2022, 1, 1, 12, 0))\n\n    f = MyForm({'date_time_0': '2022-01-01', 'date_time_1': '12:00:00.123456789012'})\n    self.assertEqual(f.is_valid(), True)\n    self.assertEqual(f.cleaned_data['date_time'], datetime.datetime(2022, 1, 1, 12, 0))\n\n    f = MyForm({'date_time_0': '2022-01-01', 'date_time_1': '12:00:00.1234567890123'})\n    self.assertEqual(f.is_valid"], "sample_987": ["def test_evalf_piecewise():\n    from sympy import Piecewise\n    pw = Piecewise((1, x > 0), (0, x < 0))\n    assert NS(pw, subs={x: 0.5}) == '1.00000000000000'\n    assert NS(pw, subs={x: -0.5}) == '0.000000000000000'\n    assert NS(pw, subs={x: 0}) == '0.000000000000000'\n    pw = Piecewise((1, x > 0), (0, x < 0), (2, True))\n    assert NS(pw, subs={x: 0.5}) == '1.00000000000000'\n    assert NS(pw, subs={x: -0.5}) == '0.000000000000000'\n    assert NS(pw, subs={x: 0}) == '2.00000000000000'\n"], "sample_542": ["def test_text_repr_with_non_string_input():\n    # smoketest to make sure text repr doesn't error for non-string input\n    fig, ax = plt.subplots()\n    ax.text(0.5, 0.5, 12345)\n    repr(ax.texts[0])\n"], "sample_334": ["def test_order_fields_with_empty_list(self):\n    class TestForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n        field3 = CharField()\n        field_order = []\n\n    p = TestForm()\n    self.assertEqual(list(p.fields), ['field1', 'field2', 'field3'])\n"], "sample_835": ["def test_adaboost_feature_importances():\n    # Check feature importances.\n    X, y = datasets.make_classification(n_samples=2000,\n                                        n_features=10,\n                                        n_informative=3,\n                                        n_redundant=0,\n                                        n_repeated=0,\n                                        shuffle=False,\n                                        random_state=1)\n\n    for alg in ['SAMME', 'SAMME.R']:\n        clf = AdaBoostClassifier(algorithm=alg)\n\n        clf.fit(X, y)\n        importances = clf.feature_importances_\n\n        assert importances.shape[0] == 10\n        assert (importances[:3] >= importances[3:]).all()\n\n    reg = AdaBoostRegressor(random_state=0)\n    reg.fit(X, y)\n    importances = reg.feature_importances_\n\n    assert importances.shape[0] == 10\n    assert (importances[:3] >= importances[3:]).all()\n"], "sample_305": ["def test_lookup_annotation(self):\n    # Test that a lookup can be used as an annotation\n    qs = Book.objects.annotate(\n        is_expensive=Case(\n            When(price__gt=50, then=Value(True)),\n            default=Value(False),\n            output_field=BooleanField()\n        )\n    )\n    self.assertEqual(qs[0].is_expensive, False)\n    self.assertEqual(qs[4].is_expensive, True)\n"], "sample_964": ["def test_pyclass_nesting(app):\n    text = (\".. py:class:: Class1\\n\"\n            \"\\n\"\n            \"   .. py:class:: Class2\\n\"\n            \"\\n\"\n            \"       .. py:method:: meth\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, (\"class\", desc_sig_space)],\n                                                    [desc_name, \"Class1\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc)])]))\n    assert_node(doctree[1][1][0], addnodes.index,\n                entries=[('single', 'Class2 (class in Class1)', 'Class1.Class2', '', None)])\n    assert_node(doctree[1][1][1], ([desc_signature, ([desc_annotation, (\"class\", desc_sig_space)],\n                                                     [desc_name, \"Class2\"])],\n                                   [desc_content, (addnodes.index,\n                                                   desc)]))\n    assert_node(doctree[1][1][1][1][0], addnodes.index,\n                entries=[('single', 'meth() (Class1.Class2 method)', 'Class1.Class2.meth', '', None)])\n    assert_node(doctree[1][1][1][1][1], ([desc_signature, ([desc_name, \"meth\"],\n                                                             [desc_parameterlist, ()])],\n                                        [desc_content, ()]))\n    assert 'Class1.Class2' in domain.objects\n    assert domain.objects['Class1.Class2'] == ('index', 'Class1.Class2', 'class', False)\n    assert 'Class1.Class2.meth' in domain.objects\n    assert domain.objects['Class1.Class2.meth'] == ('index', 'Class1.Class2.meth', 'method', False)\n"], "sample_741": ["def test_grid_search_with_empty_param_grid():\n    # Test that GridSearchCV can handle an empty param_grid\n    X, y = make_classification(n_samples=50, n_features=4, random_state=42)\n    clf = SVC(gamma='scale')\n    grid_search = GridSearchCV(clf, param_grid={})\n    grid_search.fit(X, y)\n    assert_equal(grid_search.best_params_, {})\n    assert_equal(grid_search.best_score_, grid_search.score(X, y))\n"], "sample_357": ["def test_alter_field_to_m2m(self):\n    \"\"\"\n    #23938 - Changing a concrete field into a ManyToManyField\n    first removes the concrete field and then adds the m2m field.\n    \"\"\"\n    changes = self.get_changes([self.author_with_former_m2m], [self.author_with_m2m, self.publisher])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\", \"RemoveField\", \"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Publisher')\n    self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"publishers\", model_name='author')\n    self.assertOperationAttributes(changes, 'testapp', 0, 2, name=\"publishers\", model_name='author')\n"], "sample_1033": ["def test_Add_primitive():\n    # Test that Add.primitive() works correctly with non-commutative symbols\n    A = Symbol(\"A\", commutative=False)\n    B = Symbol(\"B\", commutative=False)\n    C = Symbol(\"C\", commutative=False)\n    assert (A + B).primitive() == (1, A + B)\n    assert (A + B + C).primitive() == (1, A + B + C)\n    assert (2*A + 2*B).primitive() == (2, A + B)\n    assert (2*A + 2*B + C).primitive() == (2, A + B + C/2)\n    assert (A + 2*B + 3*C).primitive() == (1, A + 2*B + 3*C)\n"], "sample_358": ["    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(),\n            col_suffixes=('ASC', 'DESC'), opclasses=('opclass1', 'opclass2')\n        )\n"], "sample_489": ["def test_update_conflicts_unique_fields_update_fields_db_column_with_target(self):\n    FieldsWithDbColumns.objects.bulk_create(\n        [\n            FieldsWithDbColumns(rank=1, name=\"a\"),\n            FieldsWithDbColumns(rank=2, name=\"b\"),\n        ]\n    )\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n\n    conflicting_objects = [\n        FieldsWithDbColumns(rank=1, name=\"c\"),\n        FieldsWithDbColumns(rank=2, name=\"d\"),\n    ]\n    results = FieldsWithDbColumns.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        unique_fields=[\"rank\"],\n        update_fields=[\"db_column_name\"],\n    )\n    self.assertEqual(len(results), len(conflicting_objects))\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n    self.assertCountEqual(\n        FieldsWithDbColumns.objects.values(\"rank\", \"db_column_name\"),\n        [\n            {\"rank\": 1, \"db_column_name\": \"c\"},\n            {\"rank\": 2, \"db_column_name\": \"d\"},\n        ],\n    )\n"], "sample_872": ["def test_roc_auc_score_multiclass_average_error():\n    # Test that roc_auc_score function returns an error when trying\n    # to compute multiclass AUC for parameters where an output\n    # is not defined.\n    rng = check_random_state(404)\n    y_score = rng.rand(20, 3)\n    y_prob = softmax(y_score)\n    y_true = rng.randint(0, 3, size=20)\n    with pytest.raises(ValueError, match=r\"average must be one of \\('macro', 'weighted', None\\) for multiclass problems\"):\n        roc_auc_score(y_true, y_prob, average=\"samples\", multi_class=\"ovr\")\n"], "sample_316": ["    def test_image_file_dimensions(self):\n        \"\"\"\n        Test that ImageFile's width and height properties return the correct values.\n        \"\"\"\n        img_path = os.path.join(os.path.dirname(__file__), \"test.png\")\n        with open(img_path, 'rb') as fh:\n            image_file = images.ImageFile(fh)\n            self.assertEqual(image_file.width, 540)\n            self.assertEqual(image_file.height, 405)\n"], "sample_338": ["def test_alter_field_to_fk_dependency_same_app(self):\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author_fk],\n        [self.author_empty, self.book],\n    )\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [(\"otherapp\", \"__first__\")])\n"], "sample_248": ["def test_shell_with_no_interface_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import python interface.\"):\n        call_command('shell')\n"], "sample_881": ["def test_roc_auc_score_multiclass_average_error():\n    # Test that roc_auc_score function returns an error when trying\n    # to compute multiclass AUC for parameters where an output\n    # is not defined.\n    rng = check_random_state(404)\n    y_score = rng.rand(20, 3)\n    y_prob = softmax(y_score)\n    y_true = rng.randint(0, 3, size=20)\n    with pytest.raises(ValueError, match=\"average must be one of\"):\n        roc_auc_score(y_true, y_prob, multi_class=\"ovr\", average=\"invalid\")\n"], "sample_86": ["def test_lazy_object(self):\n    \"\"\"Test the LazyObject class.\"\"\"\n    class TestClass:\n            self.value = value\n\n            return self.value\n\n    lazy_obj = SimpleLazyObject(lambda: TestClass(42))\n    self.assertIsNone(lazy_obj._wrapped)\n    self.assertEqual(lazy_obj.method(), 42)\n    self.assertIsNotNone(lazy_obj._wrapped)\n    self.assertEqual(lazy_obj.value, 42)\n\n    # Test that the lazy object is pickled correctly\n    import pickle\n    pickled_lazy_obj = pickle.dumps(lazy_obj)\n    unpickled_lazy_obj = pickle.loads(pickled_lazy_obj)\n    self.assertEqual(unpickled_lazy_obj.method(), 42)\n\n    # Test that the lazy object is copied correctly\n    copied_lazy_obj = copy.copy(lazy_obj)\n    self.assertIsNot(copied_lazy_obj, lazy_obj)\n    self.assertEqual(copied_lazy_obj.method(), 42)\n\n    # Test that the lazy object is deep copied correctly\n    deep_copied_lazy_obj = copy.deepcopy(lazy_obj)\n    self.assertIsNot(deep_copied_lazy_obj, lazy_obj)\n    self.assertEqual(deep_copied_lazy_obj.method(), 42)\n"], "sample_3": ["def test_ecsv_read_with_comments():\n    \"\"\"\n    Test that comments in the ECSV file are preserved when reading.\n    \"\"\"\n    txt = \"\"\"\\"], "sample_412": ["def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            \"Search for google.com/?q=! and see.\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>! and see.',\n        ),\n        (\n            \"Search for google.com/?q=1&lt! and see.\",\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt'\n            \"</a>! and see.\",\n        ),\n        (\n            \"Search for google.com/?q=! and see,\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>! and see,',\n        ),\n        (\n            \"Search for google.com/?q=! and see.\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>! and see.',\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_715": ["def test_cross_val_predict_with_partial_fit():\n    # Test that cross_val_predict works with estimators that have partial_fit\n    X, y = make_classification(n_samples=100, n_features=20, random_state=0)\n    est = PassiveAggressiveClassifier(max_iter=1, tol=None, shuffle=False)\n    predictions = cross_val_predict(est, X, y, cv=5, method='predict')\n    assert_array_equal(predictions.shape, (100,))\n"], "sample_1128": ["def test_point_partial_velocity_multiple_gen_speeds():\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    p = Point('p')\n    u1, u2, u3 = dynamicsymbols('u1, u2, u3')\n    p.set_vel(N, u1 * A.x + u2 * N.y + u3 * A.z)\n    assert p.partial_velocity(N, u1, u2, u3) == (A.x, N.y, A.z)\n    assert p.partial_velocity(N, u1, u3) == (A.x, A.z)\n    assert p.partial_velocity(N, u2) == N.y\n"], "sample_854": ["def test_base_libsvm_fit_sparse_input():\n    # Test that BaseLibSVM.fit() works with sparse input\n    X = sparse.csr_matrix(X)\n    clf = svm.SVC(kernel='linear')\n    clf.fit(X, Y)\n    assert_array_equal(clf.predict(T), true_result)\n    assert_array_almost_equal(clf.intercept_, [0], decimal=3)\n"], "sample_474": ["    def setUpTestData(cls):\n        cls.john = Author.objects.create(name=\"John Smith\", alias=\"smithj\")\n        cls.elena = Author.objects.create(name=\"\u00c9lena Jordan\", alias=\"elena\")\n        cls.rhonda = Author.objects.create(name=\"Rhonda\")\n"], "sample_547": ["def test_auxtransformbox():\n    fig, ax = plt.subplots()\n    aux_transform = mtransforms.Affine2D().rotate_deg(45)\n    aux_box = AuxTransformBox(aux_transform)\n    da = DrawingArea(100, 100)\n    aux_box.add_artist(da)\n    ax.add_artist(aux_box)\n    fig.canvas.draw()\n    assert fig.stale\n"], "sample_1177": ["def test_periodic_argument_edge_cases():\n    from sympy.functions.elementary.complexes import periodic_argument\n    from sympy import oo, pi, I, exp_polar\n    assert periodic_argument(0, oo) == 0\n    assert periodic_argument(0, pi) == 0\n    assert periodic_argument(0, -pi) == 0\n    assert periodic_argument(0, 2*pi) == 0\n    assert periodic_argument(0, -2*pi) == 0\n    assert periodic_argument(pi, oo) == pi\n    assert periodic_argument(pi, pi) == 0\n    assert periodic_argument(pi, -pi) == pi\n    assert periodic_argument(pi, 2*pi) == pi\n    assert periodic_argument(pi, -2*pi) == pi\n    assert periodic_argument(-pi, oo) == -pi\n    assert periodic_argument(-pi, pi) == 0\n    assert periodic_argument(-pi, -pi) == -pi\n    assert periodic_argument(-pi, 2*pi) == -pi\n    assert periodic_argument(-pi, -2*pi) == -pi\n    assert periodic_argument(2*pi, oo) == 0\n    assert periodic_argument(2*pi, pi) == 0\n    assert periodic_argument(2*pi, -pi) == 0\n    assert periodic_argument(2*pi, 2*pi) == 0\n    assert periodic_argument(2*pi, -2*pi) == 0\n    assert periodic_argument(-2*pi, oo) == 0\n    assert periodic_argument(-2*pi, pi) == 0\n    assert periodic_argument(-2*pi, -pi) == 0\n    assert periodic_argument(-2*pi, 2*pi) == 0\n    assert periodic_argument(-2*pi, -2*pi) == 0\n    assert periodic_argument(oo, oo) == oo\n    assert periodic_argument(-oo, oo) == -oo\n    assert periodic_argument(oo, pi) == oo\n    assert periodic_argument(-oo, pi) == -oo\n    assert periodic_argument(oo, -pi) == oo\n    assert periodic_argument(-oo, -pi) == -oo\n    assert periodic_argument(oo, 2*pi) == oo\n    assert periodic_argument(-oo, 2*pi) == -oo\n    assert periodic_argument(oo, -2*pi) == oo\n   "], "sample_999": ["def test_latex_issue_14355():\n    from sympy import symbols, Function\n    x, y = symbols('x y')\n    f = Function('f')\n    assert latex(f(x, y)) == r'f{\\left (x,y \\right )}'\n    assert latex(f(x, y, 1)) == r'f{\\left (x,y, 1 \\right )}'\n    assert latex(f(x, y, 1, 2)) == r'f{\\left (x,y, 1, 2 \\right )}'\n"], "sample_31": ["    def test_write_latex_with_kwargs(self, write, tmp_path, format):\n        \"\"\"Test passing additional keyword arguments to write_latex\"\"\"\n        fp = tmp_path / \"test_write_latex_with_kwargs.tex\"\n        write(fp, format=format, latex_names=True, comment='#')\n        tbl = QTable.read(fp, format='latex', comment='#')\n        # asserts each column name has not been reverted yet\n        for column_name in tbl.colnames[2:]:\n            # for now, Cosmology as metadata and name is stored in first 2 slots\n            assert column_name in _FORMAT_TABLE.values()\n"], "sample_497": ["    def test_get_view_interval(self):\n        fig, ax = plt.subplots()\n        ax.set_xlim(0, 10)\n        ax.set_ylim(0, 10)\n        assert ax.xaxis.get_view_interval() == (0, 10)\n        assert ax.yaxis.get_view_interval() == (0, 10)\n"], "sample_692": ["def test_tmp_path_factory_mktemp_numbered(tmp_path_factory: TempPathFactory) -> None:\n    \"\"\"Test that TempPathFactory.mktemp creates a unique directory when numbered=True.\"\"\"\n    basename = \"test-\"\n    path1 = tmp_path_factory.mktemp(basename, numbered=True)\n    path2 = tmp_path_factory.mktemp(basename, numbered=True)\n    assert path1 != path2\n    assert path1.name.startswith(basename)\n    assert path2.name.startswith(basename)\n    assert path1.parent == path2.parent\n"], "sample_1156": ["def test_hyperbolic_functions_with_finite():\n    x = Symbol('x')\n    assert sinh(x).is_finite is None\n    assert cosh(x).is_finite is None\n    assert tanh(x).is_finite is None\n    assert coth(x).is_finite is None\n    assert csch(x).is_finite is None\n    assert sech(x).is_finite is None\n    assert asinh(x).is_finite is None\n    assert acosh(x).is_finite is None\n    assert atanh(x).is_finite is None\n    assert acoth(x).is_finite is None\n    assert asech(x).is_finite is None\n    assert acsch(x).is_finite is None\n\n    x = Symbol('x', finite=True)\n    assert sinh(x).is_finite is True\n    assert cosh(x).is_finite is True\n    assert tanh(x).is_finite is True\n    assert coth(x).is_finite is None\n    assert csch(x).is_finite is None\n    assert sech(x).is_finite is True\n    assert asinh(x).is_finite is True\n    assert acosh(x).is_finite is True\n    assert atanh(x).is_finite is True\n    assert acoth(x).is_finite is True\n    assert asech(x).is_finite is True\n    assert acsch(x).is_finite is True\n"], "sample_1052": ["def test_fcode_matrixsymbol_slice_autoname_2d():\n    # see issue #8093\n    A = MatrixSymbol('A', 2, 3)\n    name_expr = (\"test\", A[1, :])\n    result = codegen(name_expr, \"f95\", \"test\", header=False, empty=False)\n    source = result[0][1]\n    expected = (\n        \"subroutine test(A, out_%(hash)s)\\n\"\n        \"implicit none\\n\"\n        \"REAL*8, intent(in), dimension(1:2, 1:3) :: A\\n\"\n        \"REAL*8, intent(out), dimension(1:1, 1:3) :: out_%(hash)s\\n\"\n        \"out_%(hash)s(1, 1) = A(2, 1)\\n\"\n        \"out_%(hash)s(1, 2) = A(2, 2)\\n\"\n        \"out_%(hash)s(1, 3) = A(2, 3)\\n\"\n        \"end subroutine\\n\"\n    )\n    # look for the magic number\n    a = source.splitlines()[3]\n    b = a.split('_')\n    out = b[1]\n    expected = expected % {'hash': out}\n    assert source == expected\n"], "sample_225": ["    def setUp(self):\n        self.site = admin.AdminSite()\n"], "sample_22": ["def test_matrix_transpose():\n    \"\"\"Test the matrix transpose function.\"\"\"\n    # Test with a single matrix\n    m = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    assert_allclose(matrix_transpose(m), m.T)\n\n    # Test with a stack of matrices\n    m = np.stack((m, m))\n    assert_allclose(matrix_transpose(m), m.swapaxes(-2, -1))\n\n    # Test with a non-square matrix (should raise an error)\n    m = np.array([[1, 2, 3], [4, 5, 6]])\n    with pytest.raises(ValueError):\n        matrix_transpose(m)\n"], "sample_1149": ["def test_S_call():\n    assert S(1) == 1\n    assert S(1.0) == 1.0\n    assert S('1') == 1\n    assert S('1.0') == 1.0\n    assert S('x') == Basic.Symbol('x')\n    assert S('x**2') == Basic.Symbol('x')**2\n"], "sample_307": ["def test_f_format(self):\n    tests = [\n        (datetime(2000, 1, 1, 0, 0), '12'),\n        (datetime(2000, 1, 1, 0, 30), '12:30'),\n        (datetime(2000, 1, 1, 12, 0), '12'),\n        (datetime(2000, 1, 1, 12, 30), '12:30'),\n        (datetime(2000, 1, 1, 13, 0), '1'),\n        (datetime(2000, 1, 1, 13, 30), '1:30'),\n    ]\n    for dt, expected in tests:\n        with self.subTest(dt=dt):\n            self.assertEqual(dateformat.format(dt, 'f'), expected)\n"], "sample_350": ["def test_union_with_values_list_and_order_on_annotation_with_nulls(self):\n    qs1 = Number.objects.annotate(\n        annotation=Value(-1),\n        multiplier=F('annotation'),\n    ).filter(num__gte=6)\n    qs2 = Number.objects.annotate(\n        annotation=Value(2),\n        multiplier=F('annotation'),\n    ).filter(num__lte=5)\n    self.assertSequenceEqual(\n        qs1.union(qs2).order_by('annotation', 'num').values_list('num', flat=True),\n        [6, 7, 8, 9, 0, 1, 2, 3, 4, 5],\n    )\n    self.assertQuerysetEqual(\n        qs1.union(qs2).order_by(\n            F('annotation') * F('multiplier'),\n            'num',\n        ).values('num'),\n        [6, 7, 8, 9, 0, 1, 2, 3, 4, 5],\n        operator.itemgetter('num'),\n    )\n    qs1 = Number.objects.annotate(\n        annotation=Value(None),\n        multiplier=F('annotation'),\n    ).filter(num__gte=6)\n    qs2 = Number.objects.annotate(\n        annotation=Value(2),\n        multiplier=F('annotation'),\n    ).filter(num__lte=5)\n    self.assertSequenceEqual(\n        qs1.union(qs2).order_by('annotation', 'num').values_list('num', flat=True),\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n    )\n    self.assertQuerysetEqual(\n        qs1.union(qs2).order_by(\n            F('annotation') * F('multiplier'),\n            'num',\n        ).values('num'),\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n        operator.itemgetter('num'),\n    )\n"], "sample_662": ["def test_base_report_properties(self, testdir):\n    \"\"\"Test that BaseReport properties are correctly implemented\"\"\"\n    reprec = testdir.inline_runsource(\n        \"\"\"\n    \"\"\"\n    )\n    reports = reprec.getreports(\"pytest_runtest_logreport\")\n    assert len(reports) == 3\n    test_a_call = reports[1]\n    assert test_a_call.passed\n    assert not test_a_call.failed\n    assert not test_a_call.skipped\n    assert test_a_call.outcome == \"passed\"\n    assert test_a_call.when == \"call\"\n    assert test_a_call.keywords == {\"test_a\": 1}\n    assert test_a_call.fspath == testdir.tmpdir.join(\"test_report_properties.py\")\n    assert test_a_call.count_towards_summary\n    assert test_a_call.head_line == \"test_a\"\n"], "sample_120": ["def test_serialize_function_type(self):\n        pass\n\n    self.assertSerializedResultEqual(\n        test_function,\n        ('migrations.test_writer.test_function', {'import migrations.test_writer'})\n    )\n\n    class TestClass:\n            pass\n\n    self.assertSerializedResultEqual(\n        TestClass().test_method,\n        ('migrations.test_writer.TestClass().test_method', {'import migrations.test_writer'})\n    )\n\n    class TestClass2:\n        @staticmethod\n            pass\n\n    self.assertSerializedResultEqual(\n        TestClass2.test_static_method,\n        ('migrations.test_writer.TestClass2.test_static_method', {'import migrations.test_writer'})\n    )\n\n    class TestClass3:\n        @classmethod\n            pass\n\n    self.assertSerializedResultEqual(\n        TestClass3.test_class_method,\n        ('migrations.test_writer.TestClass3.test_class_method', {'import migrations.test_writer'})\n    )\n"], "sample_943": ["def test_is_packagedir(tempdir):\n    (tempdir / 'testpkg').makedirs()\n    (tempdir / 'testpkg' / '__init__.py').write_text('')\n    assert is_packagedir(tempdir / 'testpkg')\n\n    (tempdir / 'testpkg' / '__init__.py').remove()\n    assert not is_packagedir(tempdir / 'testpkg')\n\n    (tempdir / 'testpkg' / 'example.py').write_text('')\n    assert not is_packagedir(tempdir / 'testpkg')\n"], "sample_98": ["    def test_broken_pipe_error_logging(self):\n        \"\"\"\n        Test that BrokenPipeError is logged as an info message.\n        \"\"\"\n        conn = HTTPConnection(LiveServerViews.server_thread.host, LiveServerViews.server_thread.port)\n        try:\n            conn.request('GET', '/example_view/', headers={'Connection': 'keep-alive'})\n            response = conn.getresponse()\n            self.assertFalse(response.will_close)\n            # Simulate a broken pipe by closing the connection before reading the response.\n            conn.close()\n            # Try to read the response to trigger the BrokenPipeError.\n            response.read()\n        except BrokenPipeError:\n            pass\n        finally:\n            conn.close()\n        # Check that the BrokenPipeError was logged as an info message.\n        self.assertIn('Broken pipe from', self.log_output.getvalue())\n"], "sample_480": ["    def test_key_transform_text_lookup_mixin(self):\n        qs = NullableJSONModel.objects.annotate(\n            char_value=KeyTextTransform(\"foo\", \"value\"),\n        ).filter(char_value__startswith=\"bar\")\n        self.assertSequenceEqual(qs, [self.objs[7]])\n\n        qs = NullableJSONModel.objects.annotate(\n            char_value=KeyTextTransform(1, KeyTextTransform(\"bar\", \"value\")),\n        ).filter(char_value__startswith=\"bar\")\n        self.assertSequenceEqual(qs, [self.objs[7]])\n"], "sample_460": ["    def test_change_view_with_view_only_inlines_and_save_as_new(self):\n        \"\"\"\n        User with change permission to a section but view-only for inlines.\n        \"\"\"\n        self.viewuser.user_permissions.add(\n            get_perm(Section, get_permission_codename(\"change\", Section._meta))\n        )\n        self.client.force_login(self.viewuser)\n        # GET shows inlines.\n        response = self.client.get(\n            reverse(\"admin:admin_views_section_change\", args=(self.s1.pk,))\n        )\n        self.assertEqual(len(response.context[\"inline_admin_formsets\"]), 1)\n        formset = response.context[\"inline_admin_formsets\"][0]\n        self.assertEqual(len(formset.forms), 3)\n        # Valid POST changes the name.\n        data = {\n            \"name\": \"Can edit name with view-only inlines\",\n            \"article_set-TOTAL_FORMS\": \"3\",\n            \"article_set-INITIAL_FORMS\": \"3\",\n        }\n        response = self.client.post(\n            reverse(\"admin:admin_views_section_change\", args=(self.s1.pk,)), data\n        )\n        self.assertRedirects(response, reverse(\"admin:admin_views_section_changelist\"))\n        self.assertEqual(Section.objects.get(pk=self.s1.pk).name, data[\"name\"])\n        # Invalid POST reshows inlines.\n        del data[\"name\"]\n        response = self.client.post(\n            reverse(\"admin:admin_views_section_change\", args=(self.s1.pk,)), data\n        )\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(len(response.context[\"inline_admin_formsets\"]), 1)\n        formset = response.context[\"inline_admin_formsets\"][0]\n        self.assertEqual(len(formset.forms), 3)\n        # Save as new.\n        data = {\n            \"_saveasnew\": \"Save as new\",\n            \"name\": \"Can edit name with view-only inlines\",\n            \"article_set-TOTAL_FORMS\": \"3\",\n            \"article_set-INITIAL_FORMS\": \"3\",\n        }\n        response = self.client.post(\n            reverse(\"admin:admin_views_section_change\", args=(self.s1.pk,)), data\n        )\n        self.assertEqual(response.status_code, 403)\n"], "sample_134": ["def test_serialize_lazy_object_with_unserializable_value(self):\n    lazy_object = SimpleLazyObject(lambda: lambda x: 42)\n    with self.assertRaisesMessage(ValueError, 'Cannot serialize function: lambda'):\n        self.serialize_round_trip(lazy_object)\n"], "sample_109": ["def test_optgroups(self):\n    beatles = Band.objects.create(name='The Beatles', style='rock')\n    who = Band.objects.create(name='The Who', style='rock')\n    rel = Album._meta.get_field('band').remote_field\n    w = AutocompleteSelect(rel, admin.site)\n    w.choices = ModelChoiceField(queryset=Band.objects.all()).choices\n    optgroups = w.optgroups('name', [beatles.pk, who.pk])\n    self.assertEqual(len(optgroups), 1)\n    self.assertEqual(len(optgroups[0][1]), 2)\n    self.assertEqual(optgroups[0][1][0]['value'], str(beatles.pk))\n    self.assertEqual(optgroups[0][1][0]['label'], 'The Beatles')\n    self.assertEqual(optgroups[0][1][1]['value'], str(who.pk))\n    self.assertEqual(optgroups[0][1][1]['label'], 'The Who')\n"], "sample_487": ["    def test_invalid_expression_with_function(self):\n        class TestModelAdmin(ModelAdmin):\n            ordering = (F(\"nonexistent\").desc(),)\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'ordering[0]' refers to 'nonexistent', which is not \"\n            \"a field of 'modeladmin.ValidationTestModel'.\",\n            \"admin.E033\",\n        )\n"], "sample_640": ["def test_is_node_in_typing_guarded_import_block() -> None:\n    code = astroid.extract_node(\n        \"\"\"\n    from typing import TYPE_CHECKING\n    if TYPE_CHECKING:\n        from xyz import a  #@\n    \"\"\"\n    )\n    assert utils.is_node_in_typing_guarded_import_block(code[0])\n"], "sample_263": ["def test_dumpdata_with_file_output_and_indent(self):\n    management.call_command('loaddata', 'fixture1.json', verbosity=0)\n    self._dumpdata_assert(\n        ['fixtures'],\n        '[\\n    {\\n        \"pk\": 1,\\n        \"model\": \"fixtures.category\",\\n        \"fields\": {\\n            '\n        '\"description\": \"Latest news stories\",\\n            \"title\": \"News Stories\"\\n        }\\n    },\\n    {\\n        '\n        '\"pk\": 2,\\n        \"model\": \"fixtures.article\",\\n        \"fields\": {\\n            \"headline\": \"Poker has no '\n        'place on ESPN\",\\n            \"pub_date\": \"2006-06-16T12:00:00\"\\n        }\\n    },\\n    {\\n        \"pk\": 3,\\n        '\n        '\"model\": \"fixtures.article\",\\n        \"fields\": {\\n            \"headline\": \"Time to reform copyright\",\\n            '\n        '\"pub_date\": \"2006-06-16T13:00:00\"\\n        }\\n    }\\n]',\n        indent=4,\n        filename='dumpdata.json'\n    )\n"], "sample_609": ["def test_cov_corr_with_missing_values() -> None:\n    # Testing that xr.corr and xr.cov are consistent with each other\n    # when there are missing values\n    da_a = xr.DataArray(\n        np.array([[1, 2, np.nan], [np.nan, 2, 3]]),\n        dims=(\"x\", \"time\"),\n        coords={\"x\": [0, 1], \"time\": [0, 1, 2]},\n    )\n    da_b = xr.DataArray(\n        np.array([[1, 2, 3], [2, np.nan, 3]]),\n        dims=(\"x\", \"time\"),\n        coords={\"x\": [0, 1], \"time\": [0, 1, 2]},\n    )\n\n    expected = xr.cov(da_a, da_b, dim=\"time\", ddof=0) / (\n        da_a.std(dim=\"time\") * da_b.std(dim=\"time\")\n    )\n    actual = xr.corr(da_a, da_b, dim=\"time\")\n    assert_allclose(actual, expected)\n"], "sample_962": ["def test_undecorate():\n    with mock(['unknown']):\n        import unknown\n        decorated = unknown.secret.Class()\n        decorated.__sphinx_decorator_args__ = ('arg1', 'arg2')\n        assert undecorate(decorated) == ('arg1', 'arg2')\n        assert undecorate(unknown.secret.Class) == unknown.secret.Class\n        assert undecorate(object()) == object()\n"], "sample_17": ["    def setup_method(self):\n        self.q = (\n            np.array(\n                [[ 1.0, -1.0,  2.0],\n                 [ 0.0,  3.0, -1.0],\n                 [-1.0, -1.0,  1.0]]\n            ) << u.m\n        )  # fmt: skip\n"], "sample_580": ["def test_variable_type_edge_cases():\n    # Test with a Series containing a mix of numeric and non-numeric values\n    s = pd.Series([1, 2, \"a\", 4])\n    assert variable_type(s) == \"categorical\"\n\n    # Test with a Series containing a mix of datetime and non-datetime values\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2), \"a\"])\n    assert variable_type(s) == \"categorical\"\n\n    # Test with a Series containing a single value\n    s = pd.Series([1])\n    assert variable_type(s) == \"numeric\"\n\n    # Test with a Series containing a single NaN value\n    s = pd.Series([np.nan])\n    assert variable_type(s) == \"numeric\"\n\n    # Test with a Series containing a single NA value\n    s = pd.Series([pd.NA])\n    assert variable_type(s) == \"numeric\"\n\n    # Test with a Series containing a single datetime value\n    s = pd.Series([pd.Timestamp(1)])\n    assert variable_type(s) == \"datetime\"\n\n    # Test with a Series containing a single boolean value\n    s = pd.Series([True])\n    assert variable_type(s) == \"numeric\"\n\n    # Test with a Series containing a single categorical value\n    s = pd.Series([\"a\"])\n    assert variable_type(s) == \"categorical\"\n\n    # Test with a Series containing a single unknown value\n    s = pd.Series([None])\n    assert variable_type(s) == \"categorical\"\n"], "sample_766": ["def test_dict_learning_online_return_code():\n    n_components = 5\n    dico = MiniBatchDictionaryLearning(n_components, n_iter=20, random_state=0)\n    dico.fit(X)\n    code = dico.transform(X)\n    assert_equal(code.shape, (n_samples, n_components))\n    assert_less(np.sqrt(np.sum((np.dot(code, dico.components_) - X) ** 2)), 0.1)\n"], "sample_230": ["def test_bound_data(self):\n    field = JSONField()\n    data = '{\"a\": \"b\"}'\n    initial = '{\"c\": \"d\"}'\n    self.assertEqual(field.bound_data(data, initial), data)\n\n    field = JSONField(disabled=True)\n    self.assertEqual(field.bound_data(data, initial), initial)\n"], "sample_1133": ["def test_refraction_angle_edge_cases():\n    n1, n2 = symbols('n1, n2')\n    r1 = Ray3D(Point3D(-1, -1, 1), Point3D(0, 0, 0))\n    n = Matrix([0, 0, 1])\n    i = Matrix([-1, -1, -1])\n    normal_ray = Ray3D(Point3D(0, 0, 0), Point3D(0, 0, 1))\n    P = Plane(Point3D(0, 0, 0), normal_vector=[0, 0, 1])\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=n, plane=P))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=normal_ray, plane=P))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=[0, 0, 1], plane=P))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=(0, 0, 1), plane=P))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=n, plane=normal_ray))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=normal_ray, plane=n))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=[0, 0, 1], plane=n))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=(0, 0, 1), plane=n))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=n, plane=[0, 0, 1]))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=normal_ray, plane=[0, 0, 1]))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=[0, 0, 1], plane=[0, 0, 1]))\n    raises(ValueError, lambda: refraction_angle(r1, 1, 1, normal=(0, 0, 1), plane=[0, 0, 1]))\n    raises(ValueError, lambda"], "sample_160": ["def test_edge_cases(self):\n    # Test with very large decimal positions\n    self.assertEqual(nformat(1234, '.', decimal_pos=100), '1234.00')\n    self.assertEqual(nformat(1234.5678, '.', decimal_pos=100), '1234.567800000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_433": ["def test_alter_field_with_deconstructible_default(self):\n    \"\"\"\n    AlterField with a deconstructible default should work.\n    \"\"\"\n    from_state = ModelState(\n        \"testapp\",\n        \"Author\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=200, default=DeconstructibleObject())),\n        ],\n    )\n    to_state = ModelState(\n        \"testapp\",\n        \"Author\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=200, default=DeconstructibleObject())),\n        ],\n    )\n    changes = self.get_changes([from_state], [to_state])\n    # Right number of migrations?\n    self.assertEqual(len(changes), 0)\n\n    to_state = ModelState(\n        \"testapp\",\n        \"Author\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=200, default=DeconstructibleObject(1))),\n        ],\n    )\n    changes = self.get_changes([from_state], [to_state])\n    # Right number of migrations?\n    self.assertEqual(len(changes), 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n"], "sample_364": ["    def test_include_with_namespace(self):\n        urlconf_module = 'tests.test_urls.include_urls'\n        namespace = 'test_namespace'\n        urlconf_module, app_name, namespace = include((urlconf_module, 'app_name'), namespace)\n        self.assertEqual(urlconf_module, 'tests.test_urls.include_urls')\n        self.assertEqual(app_name, 'app_name')\n        self.assertEqual(namespace, 'test_namespace')\n"], "sample_729": ["def test_enet_path_with_sparse_X():\n    # Test that enet_path with sparse X gives the same result as with dense X\n    X, y, _, _ = build_dataset(n_samples=50, n_features=20)\n    X_sparse = sparse.csr_matrix(X)\n    alphas, coefs, _ = enet_path(X, y, fit_intercept=False)\n    alphas_sparse, coefs_sparse, _ = enet_path(X_sparse, y, fit_intercept=False)\n    assert_array_almost_equal(coefs, coefs_sparse)\n"], "sample_595": ["def test_slice_replace_out_of_range(dtype):\n    da = lambda x: xr.DataArray(x).astype(dtype)\n    values = da([\"short\", \"a bit longer\", \"evenlongerthanthat\", \"\"])\n\n    expected = da([\"short\", \"a bit longer\", \"evenlongerthanthat\", \"\"])\n    result = values.str.slice_replace(100, 200)\n    assert_equal(result, expected)\n\n    expected = da([\"short\", \"a bit longer\", \"evenlongerthanthat\", \"\"])\n    result = values.str.slice_replace(-100, 200)\n    assert_equal(result, expected)\n\n    expected = da([\"short\", \"a bit longer\", \"evenlongerthanthat\", \"\"])\n    result = values.str.slice_replace(100, -200)\n    assert_equal(result, expected)\n\n    expected = da([\"short\", \"a bit longer\", \"evenlongerthanthat\", \"\"])\n    result = values.str.slice_replace(-100, -200)\n    assert_equal(result, expected)\n"], "sample_957": ["def test_get_type_hints():\n        pass\n\n    assert get_type_hints(func) == {'a': int, 'b': str, 'return': None}\n\n    class MyClass:\n            pass\n\n    assert get_type_hints(MyClass.__init__) == {'a': int, 'b': str, 'return': None}\n\n    module = types.ModuleType('test_module')\n    module.__annotations__ = {'a': int, 'b': str}\n    assert get_type_hints(module) == {'a': int, 'b': str}\n\n    assert get_type_hints(None) == {}\n    assert get_type_hints(123) == {}\n    assert get_type_hints('hello') == {}\n"], "sample_807": ["def test_calibration_prefit_multiclass():\n    \"\"\"Test calibration for prefitted multiclass classifiers\"\"\"\n    n_samples = 50\n    X, y = make_blobs(n_samples=3 * n_samples, n_features=6, random_state=42,\n                      centers=3, cluster_std=3.0)\n\n    # split train and test\n    X_train, y_train = X[:n_samples], y[:n_samples]\n    X_calib, y_calib = X[n_samples:2 * n_samples], y[n_samples:2 * n_samples]\n    X_test, y_test = X[2 * n_samples:], y[2 * n_samples:]\n\n    # Naive-Bayes\n    clf = LinearSVC()\n    clf.fit(X_train, y_train)\n\n    # Naive Bayes with calibration\n    for method in ['isotonic', 'sigmoid']:\n        pc_clf = CalibratedClassifierCV(clf, method=method, cv=\"prefit\")\n        pc_clf.fit(X_calib, y_calib)\n        y_prob = pc_clf.predict_proba(X_test)\n        y_pred = pc_clf.predict(X_test)\n        assert_array_equal(y_pred, np.argmax(y_prob, axis=1))\n\n        # Check that log-loss of calibrated classifier is smaller than\n        # log-loss of naively turned OvR decision function to probabilities\n        # via softmax\n            e = np.exp(-y_pred)\n            return e / e.sum(axis=1).reshape(-1, 1)\n\n        uncalibrated_log_loss = \\\n            log_loss(y_test, softmax(clf.decision_function(X_test)))\n        calibrated_log_loss = log_loss(y_test, y_prob)\n        assert_greater_equal(uncalibrated_log_loss, calibrated_log_loss)\n"], "sample_711": ["def test_node_repr_failure_with_conftest_import_failure(pytester: Pytester) -> None:\n    \"\"\"Test that repr_failure handles ConftestImportFailure correctly.\"\"\"\n    pytester.makeconftest(\n        \"\"\"\n        raise Exception(\"conftest import failure\")\n    \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*conftest import failure*\"])\n"], "sample_559": ["def test_axesgrid_colorbar_log_smoketest_with_custom_locator():\n    fig = plt.figure()\n    grid = AxesGrid(fig, 111,  # modified to be only subplot\n                    nrows_ncols=(1, 1),\n                    ngrids=1,\n                    label_mode=\"L\",\n                    cbar_location=\"top\",\n                    cbar_mode=\"single\",\n                    )\n\n    Z = 10000 * np.random.rand(10, 10)\n    im = grid[0].imshow(Z, interpolation=\"nearest\", norm=LogNorm())\n\n    locator = mticker.LogLocator(base=2)\n    grid.cbar_axes[0].colorbar(im, ticks=locator)\n"], "sample_750": ["def test_omp_cv_with_multiple_targets():\n    ompcv = OrthogonalMatchingPursuitCV(normalize=True, fit_intercept=False,\n                                        max_iter=10, cv=5)\n    ompcv.fit(X, y)\n    assert_equal(ompcv.n_nonzero_coefs_, n_nonzero_coefs)\n    assert_array_almost_equal(ompcv.coef_, gamma)\n    omp = OrthogonalMatchingPursuit(normalize=True, fit_intercept=False,\n                                    n_nonzero_coefs=ompcv.n_nonzero_coefs_)\n    omp.fit(X, y)\n    assert_array_almost_equal(ompcv.coef_, omp.coef_)\n"], "sample_321": ["def test_rotate_token(self):\n    \"\"\"\n    The rotate_token function changes the CSRF token in use for a request.\n    \"\"\"\n    req = self._get_GET_csrf_cookie_request()\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.process_request(req)\n    original_token = req.META['CSRF_COOKIE']\n    rotate_token(req)\n    mw.process_request(req)\n    new_token = req.META['CSRF_COOKIE']\n    self.assertNotEqual(original_token, new_token)\n    self.assertTrue(equivalent_tokens(original_token, new_token))\n"], "sample_53": ["def test_select_date_widget(self):\n    widget = SelectDateWidget()\n    date = datetime.date(2022, 12, 31)\n    context = widget.get_context('date', date, {})\n    self.assertEqual(context['widget']['value'], {'year': 2022, 'month': 12, 'day': 31})\n    self.assertEqual(len(context['widget']['subwidgets']), 3)\n    self.assertEqual(context['widget']['subwidgets'][0]['name'], 'date_year')\n    self.assertEqual(context['widget']['subwidgets'][1]['name'], 'date_month')\n    self.assertEqual(context['widget']['subwidgets'][2]['name'], 'date_day')\n    self.assertEqual(context['widget']['subwidgets'][0]['value'], 2022)\n    self.assertEqual(context['widget']['subwidgets'][1]['value'], 12)\n    self.assertEqual(context['widget']['subwidgets'][2]['value'], 31)\n"], "sample_36": ["def test_biweight_midvariance_modify_sample_size():\n    \"\"\"\n    Test that biweight_midvariance with modify_sample_size=True returns\n    the correct result when there are rejected values.\n    \"\"\"\n\n    data = [1, 3, 5, 500, 2]\n    var = biweight_midvariance(data, modify_sample_size=True)\n    assert_allclose(var, 2.3390765)\n\n    data = [1, 3, 5, 500, 2, 1000]\n    var = biweight_midvariance(data, modify_sample_size=True)\n    assert_allclose(var, 2.3390765)\n"], "sample_399": ["def test_aggregation_subquery_annotation_values_collision_with_distinct(self):\n    books_rating_qs = Book.objects.filter(\n        publisher=OuterRef(\"pk\"),\n        price=Decimal(\"29.69\"),\n    ).values(\"rating\").distinct()\n    publisher_qs = (\n        Publisher.objects.filter(\n            book__contact__age__gt=20,\n            name=self.p1.name,\n        )\n        .annotate(\n            rating=Subquery(books_rating_qs),\n            contacts_count=Count(\"book__contact\"),\n        )\n        .values(\"rating\")\n        .annotate(total_count=Count(\"rating\"))\n    )\n    self.assertEqual(\n        list(publisher_qs),\n        [\n            {\"rating\": 4.0, \"total_count\": 2},\n        ],\n    )\n"], "sample_952": ["def test_isabstractmethod():\n    class AbstractClass:\n        @abstractmethod\n            pass\n\n    class ConcreteClass(AbstractClass):\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(ConcreteClass.abstract_method) is False\n    assert inspect.isabstractmethod(AbstractClass) is False\n    assert inspect.isabstractmethod(ConcreteClass) is False\n"], "sample_363": ["    def test_get_url(self):\n        widget = widgets.AutocompleteMixin(None, None)\n        with self.assertRaises(NotImplementedError):\n            widget.get_url()\n"], "sample_299": ["    def test_absolute_path_multiple_caches(self):\n        with self.settings(CACHES={\n            'default': {\n                'BACKEND': 'django.core.cache.backends.filebased.FileBasedCache',\n                'LOCATION': pathlib.Path.cwd() / 'cache',\n            },\n            'other': {\n                'BACKEND': 'django.core.cache.backends.filebased.FileBasedCache',\n                'LOCATION': pathlib.Path.cwd() / 'other_cache',\n            },\n        }):\n            self.assertEqual(check_file_based_cache_is_absolute(None), [])\n"], "sample_201": ["def test_legacy_hash_decode_invalid(self):\n    # RemovedInDjango40Warning: pre-Django 3.1 hashes will be invalid.\n    storage = self.storage_class(self.get_request())\n    messages = ['this', 'that']\n    # Encode/decode a message using the pre-Django 3.1 hash.\n    encoder = MessageEncoder(separators=(',', ':'))\n    value = encoder.encode(messages)\n    encoded_messages = '%s$%s' % (storage._legacy_hash(value) + 'invalid', value)\n    decoded_messages = storage._decode(encoded_messages)\n    self.assertIsNone(decoded_messages)\n"], "sample_65": ["    def test_jsi18n_with_empty_packages(self):\n        \"\"\"\n        Test that JavaScriptCatalog view raises a ValueError when packages is empty.\n        \"\"\"\n        view = JavaScriptCatalog.as_view()\n        request = RequestFactory().get('/')\n        msg = 'Invalid package(s) provided to JavaScriptCatalog: '\n        with self.assertRaisesMessage(ValueError, msg):\n            view(request, packages='')\n"], "sample_660": ["def test_record_testsuite_property_multiple_values(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", \"all good\")\n            record_testsuite_property(\"stats\", 10)\n            record_testsuite_property(\"stats\", \"all bad\")\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p2_node = properties_node.find_nth_by_tag(\"property\", 1)\n    p3_node = properties_node.find_nth_by_tag(\"property\", 2)\n    p1_node.assert_attr(name=\"stats\", value=\"all good\")\n    p2_node.assert_attr(name=\"stats\", value=\"10\")\n    p3_node.assert_attr(name=\"stats\", value=\"all bad\")\n"], "sample_1166": ["def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 3)) == (2, 2, -2)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 4)) == (2, 2, -3)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 5)) == (2, 2, -4)\n"], "sample_839": ["def test_vectorizer_stop_words_consistency():\n    # Test that stop words are consistent with the preprocessor and tokenizer\n    # when using a custom analyzer\n    class CustomAnalyzer:\n            return [doc.lower()]\n\n    vec = CountVectorizer(analyzer=CustomAnalyzer(), stop_words=['AND'])\n    assert_warns_message(UserWarning, 'Your stop_words may be inconsistent',\n                         vec.fit_transform, ['hello AND world'])\n"], "sample_986": ["def test_evalf_piecewise():\n    from sympy import Piecewise\n    pw = Piecewise((1, x > 0), (0, True))\n    assert pw.evalf(subs={x: 1}) == 1.0\n    assert pw.evalf(subs={x: -1}) == 0.0\n    assert pw.evalf(subs={x: 0}) == 0.0\n    pw = Piecewise((1, x < 0), (0, True))\n    assert pw.evalf(subs={x: 1}) == 0.0\n    assert pw.evalf(subs={x: -1}) == 1.0\n    assert pw.evalf(subs={x: 0}) == 0.0\n    pw = Piecewise((1, x > 0), (0, x < 0), (2, True))\n    assert pw.evalf(subs={x: 1}) == 1.0\n    assert pw.evalf(subs={x: -1}) == 0.0\n    assert pw.evalf(subs={x: 0}) == 2.0\n"], "sample_1135": ["def test_Mul_is_finite():\n    x = Symbol('x', extended_real=True, finite=False)\n\n    assert sin(x).is_finite is True\n    assert (x*sin(x)).is_finite is None\n    assert (x*atan(x)).is_finite is False\n    assert (1024*sin(x)).is_finite is True\n    assert (sin(x)*exp(x)).is_finite is None\n    assert (sin(x)*cos(x)).is_finite is True\n    assert (x*sin(x)*exp(x)).is_finite is None\n\n    assert (sin(x) - 67).is_finite is True\n    assert (sin(x) + exp(x)).is_finite is not True\n    assert (1 + x).is_finite is False\n    assert (1 + x**2 + (1 + x)*(1 - x)).is_finite is None\n    assert (sqrt(2)*(1 + x)).is_finite is False\n    assert (sqrt(2)*(1 + x)*(1 - x)).is_finite is False\n"], "sample_541": ["def test_LassoSelector(ax):\n    onselect = mock.Mock(spec=noop, return_value=None)\n\n    tool = widgets.LassoSelector(ax, onselect)\n    do_event(tool, 'press', xdata=100, ydata=100, button=1)\n    do_event(tool, 'onmove', xdata=125, ydata=125, button=1)\n    do_event(tool, 'onmove', xdata=150, ydata=150, button=1)\n    do_event(tool, 'release', xdata=150, ydata=150, button=1)\n\n    onselect.assert_called_once_with([(100, 100), (125, 125), (150, 150)])\n"], "sample_795": ["def test_check_classifiers_regression_target():\n    # check that classifier throws an exception when fed regression targets\n    est = BaseBadClassifier()\n    boston = load_boston()\n    X, y = boston.data, boston.target\n    msg = 'Unknown label type: '\n    assert_raises_regex(ValueError, msg, check_classifiers_regression_target,\n                        'estimator_name', est)\n"], "sample_613": ["def test_groupby_map_with_kwargs() -> None:\n        return arg1 + arg2 + arg3\n\n    array = xr.DataArray([1, 1, 1], [(\"x\", [1, 2, 3])])\n    expected = xr.DataArray([3, 3, 3], [(\"x\", [1, 2, 3])])\n    actual = array.groupby(\"x\").map(func, arg1=1, arg3=1)\n    assert_identical(expected, actual)\n"], "sample_482": ["    def test_basic(self):\n        output = self.engine.render_to_string(\n            \"safeseq_basic\",\n            {\"a\": [\"x&y\", \"<p>\"], \"b\": [mark_safe(\"x&y\"), mark_safe(\"<p>\")]},\n        )\n        self.assertEqual(output, \"x&amp;y, &lt;p&gt; -- x&amp;y, &lt;p&gt;\")\n"], "sample_778": ["def test_nmf_beta_loss_string():\n    # Test that beta_loss string is correctly converted to float\n    n_samples = 6\n    n_features = 5\n    n_components = 3\n    rng = np.random.mtrand.RandomState(42)\n    X = np.abs(rng.randn(n_samples, n_features))\n\n    for beta_loss in ('frobenius', 'kullback-leibler', 'itakura-saito'):\n        W, H, _ = non_negative_factorization(\n            X, init='random', n_components=n_components, solver='mu',\n            beta_loss=beta_loss, random_state=0, max_iter=1000)\n        assert not np.any(np.isnan(W))\n        assert not np.any(np.isnan(H))\n\n    msg = \"Invalid beta_loss parameter: got 'spam' instead of one of\"\n    assert_raise_message(ValueError, msg, non_negative_factorization,\n                        X, init='random', n_components=n_components,\n                        solver='mu', beta_loss='spam', random_state=0,\n                        max_iter=1000)\n"], "sample_87": ["    def test_enable_echo(self, mocked_termios):\n        mocked_termios.tcgetattr.return_value = [0, 0, 0, 0]\n        mocked_termios.TCSANOW = 0\n        mocked_termios.ECHO = 1\n        with mock.patch('sys.stdin.isatty', return_value=True):\n            autoreload.ensure_echo_on()\n        self.assertEqual(mocked_termios.tcsetattr.call_count, 1)\n"], "sample_567": ["def test_text_repr_with_non_string_input():\n    # Test that text repr doesn't error for non-string input\n    fig, ax = plt.subplots()\n    ax.text(0.5, 0.5, 12345)\n    repr(ax.texts[0])\n"], "sample_115": ["    def test_technical_500_response(self):\n        rf = RequestFactory()\n        request = rf.get('/')\n        try:\n            raise ValueError(\"Can't find my keys\")\n        except ValueError:\n            exc_type, exc_value, tb = sys.exc_info()\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html')\n        self.assertContains(response, 'ValueError at /', status_code=500)\n        self.assertContains(response, 'Can&#x27;t find my keys', status_code=500)\n"], "sample_1078": ["def test_IndexedBase_strides():\n    i, j = symbols('i j', integer=True)\n    A = IndexedBase('A', strides=(1, 2))\n    assert A.strides == (1, 2)\n    assert A[i, j].strides == (1, 2)\n    assert A.offset == 0\n    assert A[i, j].offset == 0\n    B = IndexedBase('B', strides=(1, 2), offset=3)\n    assert B.strides == (1, 2)\n    assert B[i, j].strides == (1, 2)\n    assert B.offset == 3\n    assert B[i, j].offset == 3\n"], "sample_1042": ["def test_IndexedBase_strides():\n    i, j, k = symbols('i j k', integer=True)\n    a, b, c = symbols('a b c', integer=True)\n    A = IndexedBase('A', strides=(a, b, c))\n    assert A.strides == (a, b, c)\n    assert A.offset == 0\n    assert A[i, j, k].strides == (a, b, c)\n    assert A[i, j, k].offset == 0\n    B = IndexedBase('B', strides=(a, b, c), offset=5)\n    assert B.strides == (a, b, c)\n    assert B.offset == 5\n    assert B[i, j, k].strides == (a, b, c)\n    assert B[i, j, k].offset == 5\n    C = IndexedBase('C', strides='C')\n    assert C.strides == 'C'\n    assert C.offset == 0\n    assert C[i, j, k].strides == 'C'\n    assert C[i, j, k].offset == 0\n    D = IndexedBase('D', strides='F')\n    assert D.strides == 'F'\n    assert D.offset == 0\n    assert D[i, j, k].strides == 'F'\n    assert D[i, j, k].offset == 0\n"], "sample_429": ["def test_url_validator_with_invalid_ipv6(self):\n    url_validator = URLValidator()\n    invalid_ipv6_urls = [\n        \"http://[::1:2::3]:8/\",\n        \"http://[::1:2::3]:8080/\",\n        \"http://[]\",\n        \"http://[]:8080\",\n    ]\n    for url in invalid_ipv6_urls:\n        with self.subTest(url=url):\n            with self.assertRaises(ValidationError):\n                url_validator(url)\n"], "sample_894": ["def test_max_samples_boundary_classifiers_oob(name):\n    X_train, X_test, y_train, _ = train_test_split(\n        X_large, y_large, random_state=0, stratify=y_large\n    )\n\n    ms_1_model = FOREST_CLASSIFIERS[name](\n        bootstrap=True, max_samples=1.0, random_state=0, oob_score=True\n    )\n    ms_1_oob_score = ms_1_model.fit(X_train, y_train).oob_score_\n\n    ms_None_model = FOREST_CLASSIFIERS[name](\n        bootstrap=True, max_samples=None, random_state=0, oob_score=True\n    )\n    ms_None_oob_score = ms_None_model.fit(X_train, y_train).oob_score_\n\n    assert ms_1_oob_score == pytest.approx(ms_None_oob_score)\n\n"], "sample_871": ["def test_silhouette_score_random_state():\n    # Test that silhouette_score is reproducible with a given random_state\n    dataset = datasets.load_iris()\n    X = dataset.data\n    y = dataset.target\n    score1 = silhouette_score(X, y, sample_size=100, random_state=0)\n    score2 = silhouette_score(X, y, sample_size=100, random_state=0)\n    assert score1 == score2\n\n    # Test that silhouette_score is different with different random_state\n    score3 = silhouette_score(X, y, sample_size=100, random_state=1)\n    assert score1 != score3\n"], "sample_500": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    sm = cm.ScalarMappable(norm=mcolors.Normalize(), cmap='viridis')\n    cb = fig.colorbar(sm)\n    assert cb.alpha is None\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n    cb.set_alpha(None)\n    assert cb.alpha is None\n    with pytest.raises(ValueError):\n        cb.set_alpha([0.5])\n"], "sample_233": ["def test_make_token_with_timestamp(self):\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    timestamp = p0._num_seconds(datetime.now())\n    token = p0._make_token_with_timestamp(user, timestamp)\n    self.assertIs(p0.check_token(user, token), True)\n"], "sample_627": ["def test_concat_fill_value_with_dict() -> None:\n    datasets = [\n        Dataset({\"a\": (\"x\", [2, 3]), \"b\": (\"x\", [-2, 1]), \"x\": [1, 2]}),\n        Dataset({\"a\": (\"x\", [1, 2]), \"b\": (\"x\", [3, -1]), \"x\": [0, 1]}),\n    ]\n    fill_value = {\"a\": 0, \"b\": -1}\n    expected = Dataset(\n        {\n            \"a\": ((\"t\", \"x\"), [[0, 2, 3], [1, 2, 0]]),\n            \"b\": ((\"t\", \"x\"), [[-1, -2, 1], [3, -1, -1]]),\n        },\n        {\"x\": [0, 1, 2]},\n    )\n    actual = concat(datasets, dim=\"t\", fill_value=fill_value)\n    assert_identical(actual, expected)\n"], "sample_853": ["def test_transform_target_regressor_set_params():\n    X, y = friedman\n    regr = TransformedTargetRegressor(regressor=LinearRegression(),\n                                      func=np.log, inverse_func=np.exp)\n    regr.set_params(regressor__fit_intercept=False)\n    assert not regr.regressor_.fit_intercept\n    regr.fit(X, y)\n    assert not regr.regressor_.fit_intercept\n"], "sample_785": ["def test_leave_one_group_out_with_empty_groups():\n    # Test that LeaveOneGroupOut works correctly when groups are empty\n    X = np.array([1, 2, 3, 4, 5])\n    y = np.array([1, 2, 3, 4, 5])\n    groups = np.array([1, 1, 1, 1, 1])\n    logo = LeaveOneGroupOut()\n    assert_equal(logo.get_n_splits(X, y, groups), 1)\n    train, test = next(logo.split(X, y, groups))\n    assert_array_equal(train, [0, 1, 2, 3])\n    assert_array_equal(test, [4])\n"], "sample_162": ["    def test_build_file_class(self):\n        cmd = MakeMessagesCommand()\n        cmd.domain = 'django'\n        cmd.locale_paths = []\n        cmd.default_locale_path = os.path.join(self.test_dir, 'locale')\n        translatable = cmd.translatable_file_class(self.test_dir, 'test.html', cmd.default_locale_path)\n        build_file = cmd.build_file_class(cmd, cmd.domain, translatable)\n        self.assertEqual(build_file.path, os.path.join(self.test_dir, 'test.html'))\n        self.assertEqual(build_file.work_path, os.path.join(self.test_dir, 'test.html.py'))\n"], "sample_915": ["def test_isabstractmethod():\n    class AbstractClass:\n        @abstractmethod\n            pass\n\n    class ConcreteClass:\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(ConcreteClass.concrete_method) is False\n"], "sample_901": ["def test_k_means_init_fitted_centers_sparse():\n    # Get a local optimum\n    centers = KMeans(n_clusters=3).fit(X_csr).cluster_centers_\n\n    # Fit starting from a local optimum shouldn't change the solution\n    new_centers = KMeans(n_clusters=3, init=centers,\n                         n_init=1).fit(X_csr).cluster_centers_\n    assert_array_almost_equal(centers, new_centers)\n"], "sample_352": ["        def as_sql(self, compiler, connection):\n            return 'dummy', []\n"], "sample_423": ["def test_alter_field_to_m2m(self):\n    \"\"\"\n    #23938 - Changing a field into a ManyToManyField\n    first removes the field and then adds the m2m field.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_with_former_m2m], [self.author_with_m2m, self.publisher]\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(\n        changes, \"testapp\", 0, [\"RemoveField\", \"CreateModel\", \"AddField\"]\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, name=\"publishers\", model_name=\"author\"\n    )\n    self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"Publisher\")\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 2, name=\"publishers\", model_name=\"author\"\n    )\n"], "sample_983": ["def test_sparse_matrix_liupc():\n    S = SparseMatrix([\n        [1, 0, 3, 2],\n        [0, 0, 1, 0],\n        [4, 0, 0, 5],\n        [0, 6, 7, 0]])\n    assert S.liupc() == ([[0], [], [0], [1, 2]], [4, 3, 4, 4])\n\n    S = SparseMatrix([\n        [1, 0, 0, 0],\n        [0, 1, 0, 0],\n        [0, 0, 1, 0],\n        [0, 0, 0, 1]])\n    assert S.liupc() == [[0], [1], [2], [3]], [4, 4, 4, 4]\n\n    S = SparseMatrix([\n        [0, 1, 0, 0],\n        [1, 0, 0, 0],\n        [0, 0, 0, 1],\n        [0, 0, 1, 0]])\n    assert S.liupc() == [[1], [0], [3], [2]], [4, 4, 4, 4]\n"], "sample_787": ["def test_multilabel_confusion_matrix_samplewise():\n    # Test multilabel confusion matrix - multilabel-indicator case\n    # with samplewise=True\n    from scipy.sparse import csc_matrix, csr_matrix\n\n    y_true = np.array([[1, 0, 1], [0, 1, 0], [1, 1, 0]])\n    y_pred = np.array([[1, 0, 0], [0, 1, 1], [0, 0, 1]])\n    y_true_csr = csr_matrix(y_true)\n    y_pred_csr = csr_matrix(y_pred)\n    y_true_csc = csc_matrix(y_true)\n    y_pred_csc = csc_matrix(y_pred)\n\n    # cross test different types\n    sample_weight = np.array([2, 1, 3])\n    real_cm = [[[1, 0], [1, 1]],\n               [[1, 1], [0, 1]],\n               [[0, 1], [2, 0]]]\n    trues = [y_true, y_true_csr, y_true_csc]\n    preds = [y_pred, y_pred_csr, y_pred_csc]\n\n    for y_true_tmp in trues:\n        for y_pred_tmp in preds:\n            cm = multilabel_confusion_matrix(y_true_tmp, y_pred_tmp,\n                                            samplewise=True)\n            assert_array_equal(cm, real_cm)\n\n    # test support for labels\n    cm = multilabel_confusion_matrix(y_true, y_pred, labels=[2, 0],\n                                     samplewise=True)\n    assert_array_equal(cm, [[[0, 0], [1, 1]],\n                            [[1, 1], [0, 0]],\n                            [[0, 1], [1, 0]]])\n\n    # test support for sample_weight with sample_wise\n    cm = multilabel_confusion_matrix(y_true, y_pred,\n                                     sample_weight=sample_weight,\n                                     samplewise=True)\n    assert_array_equal(cm, [[[2, 0], [2, 2]],\n                            [[1, 1], [0, 1]],\n                            [[0, 3], [6, 0]]])\n"], "sample_1": ["def test_separable_matrix():\n    # Test separability matrix for a model with 1 input and multiple outputs\n    model = models.Polynomial1D(2)\n    result = separability_matrix(model)\n    assert_allclose(result, np.ones((model.n_outputs, model.n_inputs), dtype=np.bool_))\n\n    # Test separability matrix for a model with multiple inputs and 1 output\n    model = models.Polynomial2D(1)\n    result = separability_matrix(model)\n    assert_allclose(result, np.ones((model.n_outputs, model.n_inputs), dtype=np.bool_))\n\n    # Test separability matrix for a model with multiple inputs and multiple outputs\n    model = models.Polynomial2D(2)\n    result = separability_matrix(model)\n    assert_allclose(result, np.eye(model.n_outputs, model.n_inputs, dtype=np.bool_))\n"], "sample_878": ["def test_column_transformer_set_output_with_remainder_transformer():\n    \"\"\"Check column transformer behavior with set_output and remainder transformer.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame([[1, 2, 3, 4]], columns=[\"a\", \"b\", \"c\", \"d\"], index=[10])\n    ct = ColumnTransformer(\n        [(\"first\", TransWithNames(), [\"a\", \"c\"]), (\"second\", TransWithNames(), [\"d\"])],\n        remainder=StandardScaler(),\n        verbose_feature_names_out=False,\n    )\n    X_trans = ct.fit_transform(df)\n    assert isinstance(X_trans, np.ndarray)\n\n    ct.set_output(transform=\"pandas\")\n\n    df_test = pd.DataFrame([[1, 2, 3, 4]], columns=df.columns, index=[20])\n    X_trans = ct.transform(df_test)\n    assert isinstance(X_trans, pd.DataFrame)\n\n    feature_names_out = ct.get_feature_names_out()\n    assert_array_equal(X_trans.columns, feature_names_out)\n    assert_array_equal(X_trans.index, df_test.index)\n"], "sample_922": ["def test_domain_py_module_index_with_deprecated_modules(app, status, warning):\n    app.builder.build_all()\n\n    modules = app.env.domains['py'].data['modules']\n    assert 'module_a.submodule' in modules\n    assert 'module_b.submodule' in modules\n\n    assert modules['module_a.submodule'].deprecated is False\n    assert modules['module_b.submodule'].deprecated is True\n\n    index = PythonModuleIndex(app.env.get_domain('py'))\n    content, collapse = index.generate()\n\n    for entry in content:\n        for subentry in entry[1]:\n            if subentry[0] == 'module_a.submodule':\n                assert subentry[5] == ''\n            elif subentry[0] == 'module_b.submodule':\n                assert subentry[5] == _('Deprecated')\n"], "sample_651": ["    def test_enter_exit_multiple_times(self, recwarn: WarningsRecorder) -> None:\n        with recwarn:\n            warnings.warn(\"first warning\")\n        with recwarn:\n            warnings.warn(\"second warning\")\n        assert len(recwarn) == 2\n        assert str(recwarn[0].message) == \"first warning\"\n        assert str(recwarn[1].message) == \"second warning\"\n"], "sample_909": ["    def test_empty_docstring(self):\n        docstring = \"\"\n        actual = str(GoogleDocstring(docstring))\n        expected = \"\"\n        self.assertEqual(expected, actual)\n"], "sample_713": ["def test_ridge_regression_with_sparse_input():\n    # Test that ridge regression works with sparse input\n    X = sp.csr_matrix(np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))\n    y = np.array([1, 2, 3])\n    alpha = 1.0\n\n    for solver in [\"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]:\n        ridge = Ridge(alpha=alpha, solver=solver)\n        ridge.fit(X, y)\n        assert_array_almost_equal(ridge.coef_, np.array([1, 2, 3]))\n"], "sample_247": ["def test_annotation_with_subquery(self):\n    subquery = Author.objects.filter(name='Adrian Holovaty').values('id')\n    books = Book.objects.annotate(\n        is_adrian=Exists(subquery)\n    )\n    self.assertTrue(books.get(isbn='159059725').is_adrian)\n    self.assertFalse(books.get(isbn='067232959').is_adrian)\n"], "sample_718": ["def test_check_estimator_sparse_data():\n    # check that check_estimator doesn't crash on sparse data\n    from sklearn.datasets import load_iris\n    iris = load_iris()\n    X = sp.csr_matrix(iris.data)\n    y = iris.target\n\n    for Estimator in [GaussianMixture, LinearRegression,\n                      RandomForestClassifier, NMF, SGDClassifier,\n                      MiniBatchKMeans]:\n        with ignore_warnings(category=FutureWarning):\n            # when 'est = SGDClassifier()'\n            est = Estimator()\n        set_checking_parameters(est)\n        set_random_state(est)\n        # without fitting\n        check_estimator(est)\n        # with fitting\n        est.fit(X, y)\n        check_estimator(est)\n"], "sample_997": ["def test_implicit_application():\n    transformations = standard_transformations + \\\n                      (implicit_application,)\n    x = Symbol('x')\n    y = Symbol('y')\n    f = Function('f')\n\n    assert parse_expr(\"f x\", transformations=transformations) == f(x)\n    assert parse_expr(\"f(x+1)\", transformations=transformations) == f(x+1)\n    assert parse_expr(\"f x+1\", transformations=transformations) == f(x) + 1\n    assert parse_expr(\"f(x+1)+1\", transformations=transformations) == f(x+1) + 1\n    assert parse_expr(\"f(x+1) + 1\", transformations=transformations) == f(x+1) + 1\n    assert parse_expr(\"f x+1 + 1\", transformations=transformations) == f(x) + 1 + 1\n    assert parse_expr(\"f(x+1) + y\", transformations=transformations) == f(x+1) + y\n    assert parse_expr(\"f x+1 + y\", transformations=transformations) == f(x) + 1 + y\n    assert parse_expr(\"f(x+1) + y + 1\", transformations=transformations) == f(x+1) + y + 1\n    assert parse_expr(\"f x+1 + y + 1\", transformations=transformations) == f(x) + 1 + y + 1\n"], "sample_938": ["def test_man_pages_config_value(app, status, warning):\n    app.config.man_pages = [('custom_doc', 'custom_name', 'Custom Description', ['Custom Author'], 2)]\n    app.builder.build_all()\n    assert (app.outdir / 'custom_name.2').exists()\n\n    content = (app.outdir / 'custom_name.2').read_text()\n    assert 'Custom Description' in content\n    assert 'Custom Author' in content\n"], "sample_315": ["    def setUp(self):\n        self.middleware = LocaleMiddleware(lambda req: HttpResponse())\n"], "sample_605": ["def test_groupby_map_with_kwargs(dataset):\n        return ds + arg1 + arg2 + arg3\n\n    expected = dataset + 3\n    actual = dataset.groupby(\"x\").map(func, args=(1,), arg2=1, arg3=1)\n    assert_identical(expected, actual)\n"], "sample_600": ["def test_UnsignedIntegerCoder_encode():\n    original = xr.Variable((\"x\",), np.array([255], dtype=np.uint8), encoding={\"_Unsigned\": \"true\"})\n    coder = variables.UnsignedIntegerCoder()\n    encoded = coder.encode(original)\n    expected = xr.Variable((\"x\",), np.array([-1], dtype=np.int8), encoding={})\n    assert_identical(encoded, expected)\n\n    original = xr.Variable((\"x\",), np.array([-1], dtype=np.int8), encoding={\"_Unsigned\": \"false\"})\n    coder = variables.UnsignedIntegerCoder()\n    encoded = coder.encode(original)\n    expected = xr.Variable((\"x\",), np.array([255], dtype=np.uint8), encoding={})\n    assert_identical(encoded, expected)\n"], "sample_903": ["def test_tsne_with_precomputed_distances_and_different_distance_metrics():\n    \"\"\"Make sure that TSNE works for different distance metrics with precomputed distances\"\"\"\n    random_state = check_random_state(0)\n    n_components_original = 3\n    n_components_embedding = 2\n    X = random_state.randn(50, n_components_original).astype(np.float32)\n    metrics = ['manhattan', 'cosine']\n    dist_funcs = [manhattan_distances, cosine_distances]\n    for metric, dist_func in zip(metrics, dist_funcs):\n        X_transformed_tsne = TSNE(\n            metric=metric, n_components=n_components_embedding,\n            random_state=0).fit_transform(X)\n        X_transformed_tsne_precomputed = TSNE(\n            metric='precomputed', n_components=n_components_embedding,\n            random_state=0).fit_transform(dist_func(X))\n        assert_array_almost_equal(X_transformed_tsne, X_transformed_tsne_precomputed, decimal=5)\n"], "sample_577": ["    def test_repr_png_with_pyplot(self):\n\n        p = Plot().plot(pyplot=True)\n        data, metadata = p._repr_png_()\n        img = Image.open(io.BytesIO(data))\n\n        assert not hasattr(p, \"_figure\")\n        assert isinstance(data, bytes)\n        assert img.format == \"PNG\"\n        assert sorted(metadata) == [\"height\", \"width\"]\n        # TODO test retina scaling\n"], "sample_939": ["def test_unparse_statements(source, expected):\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0], source) == expected\n"], "sample_836": ["def test_check_partial_fit_first_call():\n    # Test that check_partial_fit_first_call raises an error when classes is None\n    # and clf.classes_ is None\n    clf = SVC()\n    assert_raises(ValueError, _check_partial_fit_first_call, clf)\n\n    # Test that check_partial_fit_first_call sets clf.classes_ when classes is not\n    # None and clf.classes_ is None\n    clf = SVC()\n    classes = [0, 1]\n    assert _check_partial_fit_first_call(clf, classes)\n    assert_array_equal(clf.classes_, unique_labels(classes))\n\n    # Test that check_partial_fit_first_call raises an error when classes is not\n    # None and clf.classes_ is not None and they are not equal\n    clf = SVC()\n    clf.classes_ = [0, 1]\n    classes = [1, 0]\n    assert_raises(ValueError, _check_partial_fit_first_call, clf, classes)\n\n    # Test that check_partial_fit_first_call does not raise an error when classes\n    # is not None and clf.classes_ is not None and they are equal\n    clf = SVC()\n    clf.classes_ = [0, 1]\n    classes = [0, 1]\n    assert not _check_partial_fit_first_call(clf, classes)\n\n    # Test that check_partial_fit_first_call does not raise an error when classes\n    # is None and clf.classes_ is not None\n    clf = SVC()\n    clf.classes_ = [0, 1]\n    assert not _check_partial_fit_first_call(clf)\n"], "sample_468": ["def test_render_context_push_state(self):\n    \"\"\"\n    Test RenderContext.push_state() context manager.\n    \"\"\"\n    test_context = RenderContext({\"fruit\": \"papaya\"})\n\n    with test_context.push_state(Template(\"template\")):\n        test_context[\"vegetable\"] = \"artichoke\"\n        self.assertEqual(list(test_context), [\"vegetable\"])\n        self.assertEqual(test_context.template, Template(\"template\"))\n\n    self.assertEqual(test_context.template, None)\n    self.assertNotIn(\"vegetable\", test_context)\n    self.assertEqual(list(test_context), [\"fruit\"])\n\n    with self.assertRaises(KeyError):\n        test_context[\"vegetable\"]\n\n    self.assertIsNone(test_context.get(\"vegetable\"))\n"], "sample_815": ["def test_multilabel_confusion_matrix_multilabel_with_sample_weight():\n    # Test multilabel confusion matrix - multilabel-indicator case\n    from scipy.sparse import csc_matrix, csr_matrix\n\n    y_true = np.array([[1, 0, 1], [0, 1, 0], [1, 1, 0]])\n    y_pred = np.array([[1, 0, 0], [0, 1, 1], [0, 0, 1]])\n    y_true_csr = csr_matrix(y_true)\n    y_pred_csr = csr_matrix(y_pred)\n    y_true_csc = csc_matrix(y_true)\n    y_pred_csc = csc_matrix(y_pred)\n\n    # cross test different types\n    sample_weight = np.array([2, 1, 3])\n    real_cm = [[[1, 0], [1, 1]],\n               [[1, 0], [1, 1]],\n               [[0, 2], [1, 0]]]\n    trues = [y_true, y_true_csr, y_true_csc]\n    preds = [y_pred, y_pred_csr, y_pred_csc]\n\n    for y_true_tmp in trues:\n        for y_pred_tmp in preds:\n            cm = multilabel_confusion_matrix(y_true_tmp, y_pred_tmp,\n                                             sample_weight=sample_weight)\n            assert_array_equal(cm, real_cm)\n\n    # test support for samplewise\n    cm = multilabel_confusion_matrix(y_true, y_pred, samplewise=True,\n                                     sample_weight=sample_weight)\n    assert_array_equal(cm, [[[1, 0], [1, 1]],\n                            [[1, 1], [0, 1]],\n                            [[0, 1], [2, 0]]])\n\n    # test support for labels\n    cm = multilabel_confusion_matrix(y_true, y_pred, labels=[2, 0],\n                                     sample_weight=sample_weight)\n    assert_array_equal(cm, [[[0, 2], [1, 0]],\n                            [[1, 0], [1, 1]]])\n\n    # test support for labels with samplewise\n    cm = multilabel_confusion_matrix(y_true, y_pred, labels=[2, 0],\n                                     samplewise=True,\n                                     sample_weight=sample_weight)\n    assert_array_equal(cm, [[[0, 0], ["], "sample_1204": ["def test_is_dihedral():\n    G = SymmetricGroup(2)\n    assert G.is_dihedral\n    G = SymmetricGroup(3)\n    assert G.is_dihedral\n\n    G = AbelianGroup(2, 2)\n    assert G.is_dihedral\n    G = CyclicGroup(4)\n    assert not G.is_dihedral\n\n    G = AbelianGroup(3, 5)\n    assert not G.is_dihedral\n    G = AbelianGroup(2)\n    assert G.is_dihedral\n    G = AbelianGroup(6)\n    assert not G.is_dihedral\n\n    # D6, generated by two adjacent flips\n    G = PermutationGroup(\n        Permutation(1, 5)(2, 4),\n        Permutation(0, 1)(3, 4)(2, 5))\n    assert G.is_dihedral\n\n    # D7, generated by a flip and a rotation\n    G = PermutationGroup(\n        Permutation(1, 6)(2, 5)(3, 4),\n        Permutation(0, 1, 2, 3, 4, 5, 6))\n    assert G.is_dihedral\n\n    # S4, presented by three generators, fails due to having exactly 9\n    # elements of order 2:\n    G = PermutationGroup(\n        Permutation(0, 1), Permutation(0, 2),\n        Permutation(0, 3))\n    assert not G.is_dihedral\n\n    # D7, given by three generators\n    G = PermutationGroup(\n        Permutation(1, 6)(2, 5)(3, 4),\n        Permutation(2, 0)(3, 6)(4, 5),\n        Permutation(0, 1, 2, 3, 4, 5, 6))\n    assert G.is_dihedral\n"], "sample_506": ["def test_spine_arc(fig_test, fig_ref):\n    plt.style.use(\"default\")\n\n    ax_test = fig_test.add_subplot()\n    ax_test.set_aspect('equal')\n    ax_test.set_xlim(-1.1, 1.1)\n    ax_test.set_ylim(-1.1, 1.1)\n    ax_test.spines['circle'].set_patch_arc((0, 0), 1, 0, 90)\n    ax_test.spines['circle'].set_color('red')\n\n    ax_ref = fig_ref.add_subplot()\n    ax_ref.set_aspect('equal')\n    ax_ref.set_xlim(-1.1, 1.1)\n    ax_ref.set_ylim(-1.1, 1.1)\n    ax_ref.add_patch(mpatches.Arc((0, 0), 2, 2, theta1=0, theta2=90, edgecolor='red'))\n"], "sample_453": ["def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should render prepopulated fields.\n    \"\"\"\n    article = Article.objects.all()[0]\n    request = self.request_factory.get(\n        reverse(\"admin:admin_views_article_change\", args=[article.pk])\n    )\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    response = admin.change_view(request, str(article.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIn(\"prepopulated_fields\", template_context)\n    self.assertIn(\"prepopulated_fields_json\", template_context)\n    self.assertIsInstance(template_context[\"prepopulated_fields\"], list)\n    self.assertIsInstance(template_context[\"prepopulated_fields_json\"], str)\n"], "sample_335": ["def test_decimalfield_edge_cases(self):\n    f = DecimalField(max_digits=1, decimal_places=0)\n    self.assertEqual(f.clean('0'), decimal.Decimal(\"0\"))\n    self.assertEqual(f.clean('-0'), decimal.Decimal(\"0\"))\n    self.assertEqual(f.clean('00'), decimal.Decimal(\"0\"))\n    self.assertEqual(f.clean('-00'), decimal.Decimal(\"0\"))\n    self.assertEqual(f.clean('000'), decimal.Decimal(\"0\"))\n    self.assertEqual(f.clean('-000'), decimal.Decimal(\"0\"))\n    with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 1 digits in total.'\"):\n        f.clean('1')\n    with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 1 digits in total.'\"):\n        f.clean('-1')\n    with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 1 digits in total.'\"):\n        f.clean('01')\n    with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 1 digits in total.'\"):\n        f.clean('-01')\n    with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 1 digits in total.'\"):\n        f.clean('001')\n    with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 1 digits in total.'\"):\n        f.clean('-001')\n"], "sample_629": ["def test_expand_modules_with_ignore(\n    files_or_modules, ignore_list, ignore_list_re, ignore_list_paths_re, expected"], "sample_281": ["def test_process_request_invalid_app_label(self):\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'invalid_app', 'model_name': Answer._meta.model_name, 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n"], "sample_1049": ["def test_arbitrary_point():\n    t, u, v = symbols(\"t, u v\")\n    p = Plane((0, 0, 0), (0, 0, 1), (0, 1, 0))\n    assert p.arbitrary_point(t).equals(Point3D(0, cos(t), sin(t)))\n    assert p.arbitrary_point(u, v).equals(Point3D(u, v, 0))\n    assert p.arbitrary_point().equals(Point3D(0, cos(t), sin(t)))\n    assert p.arbitrary_point(t).subs(t, pi/2).equals(Point3D(0, 0, 1))\n    assert p.arbitrary_point(u, v).subs({u: 1, v: 2}).equals(Point3D(1, 2, 0))\n"], "sample_885": ["def test_generate_invalid_param_val_pandas_na():\n    \"\"\"Check that generate_invalid_param_val generates a value that does not satisfy\n    the _PandasNAConstraint.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    constraint = _PandasNAConstraint()\n    bad_value = generate_invalid_param_val(constraint)\n    assert not constraint.is_satisfied_by(bad_value)\n"], "sample_858": ["def test_voting_regressor_with_sample_weight():\n    \"\"\"Test VotingRegressor with sample weights.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(n_estimators=10, random_state=123)\n    ereg = VotingRegressor([('lr', reg1), ('rf', reg2)])\n\n    X_r_train, X_r_test, y_r_train, y_r_test = \\\n        train_test_split(X_r, y_r, test_size=.25)\n\n    sample_weight = np.random.RandomState(123).uniform(size=(len(y_r_train),))\n    ereg.fit(X_r_train, y_r_train, sample_weight)\n    reg1.fit(X_r_train, y_r_train, sample_weight)\n    reg2.fit(X_r_train, y_r_train, sample_weight)\n\n    assert_array_almost_equal(ereg.predict(X_r_test),\n                              np.average([reg1.predict(X_r_test),\n                                         reg2.predict(X_r_test)],\n                                         axis=0))\n"], "sample_76": ["def test_language_settings_consistent_with_default(self):\n    with self.settings(LANGUAGE_CODE='en-us', LANGUAGES=[('en', 'English')]):\n        self.assertEqual(check_language_settings_consistent(None), [])\n"], "sample_745": ["def test_function_transformer_inverse_func_none():\n    X = np.array([1, 4, 9, 16]).reshape((2, 2))\n\n    # Test that inverse_transform works correctly when inverse_func is None\n    F = FunctionTransformer(\n        func=np.sqrt,\n        inverse_func=None,\n    )\n    with pytest.raises(ValueError):\n        F.inverse_transform(F.transform(X))\n"], "sample_1164": ["def test_cg_simp():\n    a = symbols('a')\n    alpha = symbols('alpha')\n    b = symbols('b')\n    beta = symbols('beta')\n    c = symbols('c')\n    gamma = symbols('gamma')\n    expr1 = CG(a, alpha, b, 0, a, alpha)\n    expr2 = CG(a, alpha, a, -alpha, c, 0)\n    expr3 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr4 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr5 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr6 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr7 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr8 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr9 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr10 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr11 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr12 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr13 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr14 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr15 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr16 = CG(a, alpha, b, beta, c, gamma)*CG(a, alpha, b, beta, c, gamma)\n    expr17 ="], "sample_691": ["def test_pytest_unconfigure(pytester: Pytester) -> None:\n    \"\"\"Test that pytest_unconfigure correctly disables and re-enables faulthandler.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import faulthandler\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest_subprocess()\n    assert result.ret == 0\n    assert faulthandler.is_enabled()\n"], "sample_1032": ["def test_issue_14000_edge_cases():\n    assert isinstance(sqrt(0, evaluate=False), Pow) == True\n    assert isinstance(cbrt(0, evaluate=False), Pow) == True\n    assert isinstance(root(0, 4, evaluate=False), Pow) == True\n\n    assert sqrt(0, evaluate=False) == Pow(0, S.Half, evaluate=False)\n    assert cbrt(0, evaluate=False) == Pow(0, Rational(1, 3), evaluate=False)\n    assert root(0, 2, evaluate=False) == Pow(0, Rational(1, 2), evaluate=False)\n\n    assert root(0, 4, 2, evaluate=False).has(Pow) == True\n    assert real_root(0, 3, evaluate=False).has(Pow) == True\n\n    assert isinstance(sqrt(-0, evaluate=False), Pow) == True\n    assert isinstance(cbrt(-0, evaluate=False), Pow) == True\n    assert isinstance(root(-0, 4, evaluate=False), Pow) == True\n\n    assert sqrt(-0, evaluate=False) == Pow(-0, S.Half, evaluate=False)\n    assert cbrt(-0, evaluate=False) == Pow(-0, Rational(1, 3), evaluate=False)\n    assert root(-0, 2, evaluate=False) == Pow(-0, Rational(1, 2), evaluate=False)\n\n    assert root(-0, 4, 2, evaluate=False).has(Pow) == True\n    assert real_root(-0, 3, evaluate=False).has(Pow) == True\n"], "sample_221": ["def test_pickle_empty_queryset(self):\n    \"\"\"\n    Test that an empty QuerySet can be pickled and unpickled without\n    raising an exception.\n    \"\"\"\n    qs = Event.objects.none()\n    self.assertEqual(list(pickle.loads(pickle.dumps(qs))), list(qs))\n"], "sample_1111": ["def test_rescale():\n    x = Symbol('x')\n    lines = [\n        '      1 |                                                     ..',\n        '        |                                                  ...  ',\n        '        |                                                ..     ',\n        '        |                                             ...       ',\n        '        |                                          ...          ',\n        '        |                                        ..             ',\n        '        |                                     ...               ',\n        '        |                                  ...                  ',\n        '        |                                ..                     ',\n        '        |                             ...                       ',\n        '      0 |--------------------------...--------------------------',\n        '        |                       ...                             ',\n        '        |                     ..                                ',\n        '        |                  ...                                  ',\n        '        |               ...                                     ',\n        '        |             ..                                        ',\n        '        |          ...                                          ',\n        '        |       ...                                             ',\n        '        |     ..                                                ',\n        '        |  ...                                                  ',\n        '     -1 |_______________________________________________________',\n        '         -1                         0                          1'\n    ]\n    assert lines == list(textplot_str(x, -1, 1, W=55, H=21))\n\n    lines = [\n        '      1 |                                                     ..',\n        '        |                                                 ....  ',\n        '        |                                              ...      ',\n        '        |                                           ...         ',\n        '        |                                       ....            ',\n        '        |                                    ...                ',\n        '        |                                 ...                   ',\n        '        |                             ....                      ',\n        '      0 |--------------------------...--------------------------',\n        '        |                      ....                             ',\n        '        |                   ...                                 ',\n        '        |                ...                                    ',\n        '        |            ....                                       ',\n        '        |         ...                                           ',\n        '        |      ...                                              ',\n        '        |  ....                                                 ',\n        '     -1 |_______________________________________________________',\n        '         -1                         0                          1'\n    ]\n    assert lines == list(textplot_str(x, -1, 1, W=55, H=17))\n\n    lines = [\n        '      1 |                                                     ..',\n        '        |                                                  ...  ',\n        '        |                                                ..     ',\n        '        |                                             ...       ',\n        '        |                                          ...          ',\n        '        |                                        ..             ',\n        '        |                                     ...               ',\n        '        |                                  ...                  ',\n        '        |                                ..                     ',\n        '        |                             ...                       ',\n        '      0 |--------------------------"], "sample_630": ["def test_get_visibility_class(obj, expected):\n    \"\"\"Test get_visibility for class nodes\"\"\"\n    got = get_visibility(obj.name)\n    assert got == expected, f\"got {got} instead of {expected} for value {obj.name}\"\n"], "sample_70": ["def test_collector_add_field_update(self):\n    collector = Collector(using='default')\n    field = R._meta.get_field('m')\n    value = M.objects.create()\n    objs = [R.objects.create(), R.objects.create()]\n    collector.add_field_update(field, value, objs)\n    self.assertEqual(len(collector.field_updates[R]), 1)\n    self.assertEqual(len(collector.field_updates[R][(field, value)]), 2)\n"], "sample_353": ["def test_fields_with_date(self):\n    new_io = StringIO()\n    call_command(\n        'createsuperuser',\n        interactive=False,\n        email=\"joe@somewhere.org\",\n        date_of_birth=\"1976-04-01\",\n        first_name='Joe',\n        stdout=new_io,\n    )\n    command_output = new_io.getvalue().strip()\n    self.assertEqual(command_output, 'Superuser created successfully.')\n    u = CustomUser._default_manager.get(email=\"joe@somewhere.org\")\n    self.assertEqual(u.date_of_birth, date(1976, 4, 1))\n\n    # created password should be unusable\n    self.assertFalse(u.has_usable_password())\n\n    # Test invalid date\n    with self.assertRaisesMessage(CommandError, 'Enter a valid date.'):\n        call_command(\n            'createsuperuser',\n            interactive=False,\n            email=\"joe@somewhere.org\",\n            date_of_birth=\"1976-04-32\",\n            first_name='Joe',\n            stdout=new_io,\n        )\n"], "sample_1205": ["def test_PolyElement_inflate():\n    R, x = ring(\"x\", ZZ)\n    f = x**2 + 2*x + 1\n\n    assert f.deflate()[1][0].inflate((2,)) == f\n\n    R, x, y = ring(\"x,y\", ZZ)\n    f = x**4*y**2 + x**2*y + 1\n\n    assert f.deflate()[1][0].inflate((2, 1)) == f\n"], "sample_1094": ["def test_class_key():\n    assert Basic.class_key() == (5, 0, 'Basic')\n    assert Atom.class_key() == (2, 0, 'Atom')\n    assert S.class_key() == (5, 0, 'One')\n    assert b1.class_key() == (5, 0, 'Basic')\n    assert b21.class_key() == (5, 0, 'Basic')\n"], "sample_911": ["def test_template_introductions():\n    check('class', 'template<template<typename> typename T> A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> typename> A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> typename ...T> A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename...> A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> class T> A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> class> A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> class ...T> A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> class...> A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> struct T> A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> struct> A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> struct ...T> A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> struct...> A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> union T> A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> union> A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> union ...T> A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> union...> A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> enum T> A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> enum> A', {2: 'II0E0E1A"], "sample_961": ["def test_python_domain_get_full_qualified_name():\n    env = Mock(domaindata={})\n    domain = PythonDomain(env)\n\n    # non-python references\n    node = nodes.reference()\n    assert domain.get_full_qualified_name(node) is None\n\n    # simple reference\n    node = nodes.reference(reftarget='func')\n    assert domain.get_full_qualified_name(node) == 'func'\n\n    # with py:module context\n    kwargs = {'py:module': 'module1'}\n    node = nodes.reference(reftarget='func', **kwargs)\n    assert domain.get_full_qualified_name(node) == 'module1.func'\n\n    # with py:class context\n    kwargs = {'py:class': 'Class'}\n    node = nodes.reference(reftarget='func', **kwargs)\n    assert domain.get_full_qualified_name(node) == 'Class.func'\n\n    # with both py:module and py:class context\n    kwargs = {'py:module': 'module1', 'py:class': 'Class'}\n    node = nodes.reference(reftarget='func', **kwargs)\n    assert domain.get_full_qualified_name(node) == 'module1.Class.func'\n"], "sample_340": ["    def test_detect_conflicts(self):\n        \"\"\"\n        Tests the detection of conflicting migrations.\n        \"\"\"\n        migration_loader = MigrationLoader(connection)\n        conflicts = migration_loader.detect_conflicts()\n        self.assertEqual(conflicts, {})\n\n        # Create a conflicting migration\n        with self.temporary_migration_module(module='migrations.test_migrations') as migration_dir:\n            with open(os.path.join(migration_dir, '0003_conflict.py'), 'w') as f:\n                f.write('from django.db import migrations\\n')\n                f.write('class Migration(migrations.Migration):\\n')\n                f.write('    dependencies = [(\"migrations\", \"0002_second\")]\\n')\n                f.write('    operations = []\\n')\n            migration_loader.build_graph()\n            conflicts = migration_loader.detect_conflicts()\n            self.assertEqual(conflicts, {\"migrations\": [\"0002_second\", \"0003_conflict\"]})\n"], "sample_849": ["def test_leave_p_groups_out_empty_trainset():\n    # LeaveOneGroup out expect at least 2 groups so no need to check\n    cv = LeavePGroupsOut(n_groups=2)\n    X, y = [[1], [2]], [0, 3]  # 2 samples\n    with pytest.raises(\n            ValueError,\n            match='The groups parameter contains fewer than (or equal to) '\n            'n_groups (2) numbers of unique groups (2). LeavePGroupsOut '\n            'expects that at least n_groups + 1 (3) unique groups be present'):\n        next(cv.split(X, y, groups=[1, 2]))\n"], "sample_1175": ["def test_pretty_tensor():\n    from sympy.tensor.tensor import TensorHead\n    from sympy.tensor.tensor import TensorType\n    from sympy.tensor.tensor import TensorIndexType\n    from sympy.tensor.tensor import TensorElement\n    from sympy.tensor.tensor import Tensor\n    from sympy.tensor.tensor import tensor_indices\n    from sympy.tensor.tensor import tensor_heads\n\n    T = TensorHead('T')\n    T1 = TensorHead('T1')\n    T2 = TensorHead('T2')\n    T3 = TensorHead('T3')\n    T4 = TensorHead('T4')\n    T5 = TensorHead('T5')\n    T6 = TensorHead('T6')\n    T7 = TensorHead('T7')\n    T8 = TensorHead('T8')\n    T9 = TensorHead('T9')\n    T10 = TensorHead('T10')\n    T11 = TensorHead('T11')\n    T12 = TensorHead('T12')\n    T13 = TensorHead('T13')\n    T14 = TensorHead('T14')\n    T15 = TensorHead('T15')\n    T16 = TensorHead('T16')\n    T17 = TensorHead('T17')\n    T18 = TensorHead('T18')\n    T19 = TensorHead('T19')\n    T20 = TensorHead('T20')\n    T21 = TensorHead('T21')\n    T22 = TensorHead('T22')\n    T23 = TensorHead('T23')\n    T24 = TensorHead('T24')\n    T25 = TensorHead('T25')\n    T26 = TensorHead('T26')\n    T27 = TensorHead('T27')\n    T28 = TensorHead('T28')\n    T29 = TensorHead('T29')\n    T30 = TensorHead('T30')\n    T31 = TensorHead('T31')\n    T32 = TensorHead('T32')\n    T33 = TensorHead('T33')\n    T34 = TensorHead('T34')\n    T35 = TensorHead('T35')\n    T36 = TensorHead('T36')\n    T37 = TensorHead('T37')\n    T38 = TensorHead('T38')\n    T39 = TensorHead('T39')\n    T40 = TensorHead('T40')\n    T41 = TensorHead('T41')\n    T42 = TensorHead('T42')\n    T43 = Tensor"], "sample_654": ["    def test_getfixtureinfo_with_no_funcargs(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            class TestClass(object):\n                    pass\n        \"\"\"\n        )\n        item, = testdir.getitems()\n        fixtureinfo = item.session._fixturemanager.getfixtureinfo(item, item.obj, None)\n        assert fixtureinfo.argnames == ()\n        assert fixtureinfo.initialnames == ()\n        assert fixtureinfo.names_closure == ()\n        assert fixtureinfo.name2fixturedefs == {}\n"], "sample_857": ["def test_prune_tree_on_unfitted_model():\n    # test that pruning on an unfitted model raises an error\n    clf = DecisionTreeClassifier()\n    with pytest.raises(NotFittedError):\n        clf._prune_tree()\n"], "sample_639": ["def test_base_checker_add_message() -> None:\n    \"\"\"Test the add_message method of the BaseChecker class.\"\"\"\n    basic = OtherBasicChecker()\n    basic.linter = MockLinter()\n    basic.add_message(\n        \"W0001\", line=10, node=None, args=None, confidence=None, col_offset=5\n    )\n    assert basic.linter.add_message_called\n    assert basic.linter.add_message_args == {\n        \"msgid\": \"W0001\",\n        \"line\": 10,\n        \"node\": None,\n        \"args\": None,\n        \"confidence\": None,\n        \"col_offset\": 5,\n        \"end_lineno\": None,\n        \"end_col_offset\": None,\n    }\n\n"], "sample_668": ["def test_funcargnames_deprecated(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            return 42\n\n            assert my_fixture == 42\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: The `funcargnames` attribute was an alias for `fixturenames`, since pytest 2.3 - use the newer attribute instead.*\"\n        ]\n    )\n\n"], "sample_764": ["def test_column_transformer_transformer_weights():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    X_res_first = np.array([0, 1, 2]).reshape(-1, 1)\n    X_res_second = np.array([2, 4, 6]).reshape(-1, 1)\n    X_res_both = X_array\n\n    # test with transformer_weights\n    transformer_weights = {'trans1': .1, 'trans2': 10}\n    both = ColumnTransformer([('trans1', Trans(), [0]),\n                              ('trans2', Trans(), [1])],\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * X_res_first1D,\n                     transformer_weights['trans2'] * X_res_second1D]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and remainder\n    transformer_weights = {'trans1': .1}\n    both = ColumnTransformer([('trans1', Trans(), [0])],\n                             remainder='passthrough',\n                             transformer_weights=transformer_weights)\n    res = np.hstack([transformer_weights['trans1'] * X_res_first, X_res_second])\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and remainder transformer\n    transformer_weights = {'trans1': .1}\n    both = ColumnTransformer([('trans1', Trans(), [0])],\n                             remainder=DoubleTrans(),\n                             transformer_weights=transformer_weights)\n    res = np.hstack([transformer_weights['trans1'] * X_res_first,\n                     2 * X_res_second])\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and all transformers are 'drop'\n    transformer_weights = {'trans1': .1, 'trans2': 10}\n    both = ColumnTransformer([('trans1', 'drop', [0]),\n                              ('trans2', 'drop', ["], "sample_10": ["def test_table_init_with_list_of_dict():\n    \"\"\"Test initializing a table with a list of dict\"\"\"\n    data = [{'a': 1, 'b': 2}, {'a': 3, 'b': 4}]\n    t = Table(data)\n    assert np.all(t['a'] == [1, 3])\n    assert np.all(t['b'] == [2, 4])\n"], "sample_897": ["def test_partial_dependence_display_kind_centered_2way_interaction(\n    pyplot,\n    kind,\n    clf_diabetes,\n    diabetes,"], "sample_1081": ["def test_pollard_rho():\n    assert pollard_rho(2**64 + 1, seed=1) == 274177\n    assert pollard_rho(19, seed=1) is None\n    assert pollard_rho(2**64 + 1, retries=0, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=1, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=2, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=3, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=4, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=5, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=6, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=7, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=8, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=9, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=10, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=11, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=12, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=13, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=14, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=15, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=16, seed=1) == 274177\n    assert pollard_rho(2**64 + 1, retries=17, seed=1) == 274"], "sample_113": ["    def test_get_view_name(self):\n            pass\n        self.assertEqual(utils.get_view_name(test_view), 'tests.test_view')\n"], "sample_408": ["def test_alter_field_to_fk_dependency_other_app(self):\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author_fk],\n        [self.author_empty, self.book],\n    )\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"AlterField\"])\n    self.assertMigrationDependencies(\n        changes, \"otherapp\", 0, [(\"testapp\", \"__first__\")]\n    )\n"], "sample_375": ["    def test_get_related_models_tuples(self):\n        project_state = ProjectState()\n        project_state.add_model(ModelState(\n            app_label=\"migrations\",\n            name=\"Tag\",\n            fields=[\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"name\", models.CharField(max_length=100)),\n                (\"hidden\", models.BooleanField()),\n            ],\n        ))\n        project_state.add_model(ModelState(\n            app_label=\"migrations\",\n            name=\"SubTag\",\n            fields=[\n                ('tag_ptr', models.OneToOneField(\n                    'migrations.Tag',\n                    models.CASCADE,\n                    auto_created=True,\n                    parent_link=True,\n                    primary_key=True,\n                    to_field='id',\n                    serialize=False,\n                )),\n                (\"awesome\", models.BooleanField()),\n            ],\n            bases=(\"migrations.Tag\",),\n        ))\n        project_state.add_model(ModelState(\n            app_label=\"migrations\",\n            name=\"Food\",\n            fields=[\n                (\"id\", models.AutoField(primary_key=True)),\n                (\"tag\", models.ForeignKey(\"migrations.Tag\", models.CASCADE)),\n            ],\n        ))\n        self.assertEqual(\n            get_related_models_tuples(project_state.models[\"migrations\", \"tag\"]),\n            {(\"migrations\", \"subtag\"), (\"migrations\", \"food\")},\n        )\n        self.assertEqual(\n            get_related_models_tuples(project_state.models[\"migrations\", \"subtag\"]),\n            {(\"migrations\", \"tag\")},\n        )\n        self.assertEqual(\n            get_related_models_tuples(project_state.models[\"migrations\", \"food\"]),\n            {(\"migrations\", \"tag\")},\n        )\n"], "sample_1160": ["def test_intersection_sets():\n    assert intersection_sets(S.Integers, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Naturals, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Naturals, S.Integers) == S.Naturals\n    assert intersection_sets(S.Integers, S.Integers) == S.Integers\n    assert intersection_sets(S.Integers, S.Reals) == S.Integers\n    assert intersection_sets(S.Reals, S.Integers) == S.Integers\n    assert intersection_sets(S.Integers, S.Complexes) == S.Integers\n    assert intersection_sets(S.Complexes, S.Integers) == S.Integers\n    assert intersection_sets(S.Naturals, S.Reals) == S.Naturals\n    assert intersection_sets(S.Reals, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Naturals, S.Complexes) == S.Naturals\n    assert intersection_sets(S.Complexes, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Reals, S.Reals) == S.Reals\n    assert intersection_sets(S.Reals, S.Complexes) == S.Reals\n    assert intersection_sets(S.Complexes, S.Reals) == S.Reals\n    assert intersection_sets(S.Complexes, S.Complexes) == S.Complexes\n    assert intersection_sets(S.EmptySet, S.Integers) == S.EmptySet\n    assert intersection_sets(S.Integers, S.EmptySet) == S.EmptySet\n    assert intersection_sets(S.EmptySet, S.EmptySet) == S.EmptySet\n    assert intersection_sets(S.UniversalSet, S.Integers) == S.Integers\n    assert intersection_sets(S.Integers, S.UniversalSet) == S.Integers\n    assert intersection_sets(S.UniversalSet, S.UniversalSet) == S.UniversalSet\n    assert intersection_sets(S.Integers, S.Rationals) == S.Integers\n    assert intersection_sets(S.Rationals, S.Integers) == S.Integers\n    assert intersection_sets(S.Naturals, S.Rationals) == S.Naturals\n    assert intersection_sets(S.Rationals, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Rationals, S.Reals) == S.Rationals\n    assert intersection_sets(S.Re"], "sample_484": ["    def setUpTestData(cls):\n        Author.objects.create(name=\"John Smith\", alias=\"smithj\")\n        Author.objects.create(name=\"Rhonda\")\n"], "sample_742": ["def test_logistic_regressioncv_multiclass_class_weights():\n    # Test that LogisticRegressionCV with multinomial solver handles\n    # class weights correctly\n    X, y = make_classification(n_samples=30, n_features=3,\n                               n_repeated=0,\n                               n_informative=3, n_redundant=0,\n                               n_classes=3, random_state=0)\n\n    clf_lbf = LogisticRegressionCV(solver='lbfgs', Cs=1,\n                                   fit_intercept=False,\n                                   class_weight='balanced',\n                                   multi_class='multinomial')\n    clf_ncg = LogisticRegressionCV(solver='newton-cg', Cs=1,\n                                   fit_intercept=False,\n                                   class_weight='balanced',\n                                   multi_class='multinomial')\n    clf_sag = LogisticRegressionCV(solver='sag', Cs=1,\n                                   fit_intercept=False,\n                                   class_weight='balanced',\n                                   multi_class='multinomial',\n                                   tol=1e-5, max_iter=10000,\n                                   random_state=0)\n    clf_saga = LogisticRegressionCV(solver='saga', Cs=1,\n                                    fit_intercept=False,\n                                    class_weight='balanced',\n                                    multi_class='multinomial',\n                                    tol=1e-5, max_iter=10000,\n                                    random_state=0)\n    clf_lbf.fit(X, y)\n    clf_ncg.fit(X, y)\n    clf_sag.fit(X, y)\n    clf_saga.fit(X, y)\n    assert_array_almost_equal(clf_lbf.coef_, clf_ncg.coef_, decimal=4)\n    assert_array_almost_equal(clf_lbf.coef_, clf_sag.coef_, decimal=4)\n    assert_array_almost_equal(clf_lbf.coef_, clf_saga.coef_, decimal=4)\n"], "sample_400": ["def test_alter_field_with_renamed_model_and_field(self):\n    \"\"\"\n    Tests autodetection of renamed models and fields.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_name],\n        [\n            ModelState(\n                \"testapp\",\n                \"Writer\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\"names\", models.CharField(max_length=200)),\n                ],\n            ),\n        ],\n        MigrationQuestioner({\"ask_rename\": True, \"ask_rename_model\": True}),\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"RenameModel\", \"RenameField\"])\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, old_name=\"Author\", new_name=\"Writer\"\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 1, old_name=\"name\", new_name=\"names\"\n    )\n"], "sample_283": ["def test_default_database(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env({}),\n        (['psql', 'postgres'], {}),\n    )\n"], "sample_735": ["def test_gaussian_mixture_score_samples_with_different_input_types():\n    # Test that score_samples works with different input types\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng, scale=7)\n    n_components = rand_data.n_components\n\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        gmm = GaussianMixture(n_components=n_components,\n                              covariance_type=covar_type, random_state=rng)\n        gmm.fit(X)\n\n        # Test with numpy array\n        scores = gmm.score_samples(X)\n        assert_equal(scores.shape[0], X.shape[0])\n\n        # Test with scipy sparse matrix\n        from scipy.sparse import csr_matrix\n        X_sparse = csr_matrix(X)\n        scores_sparse = gmm.score_samples(X_sparse)\n        assert_array_almost_equal(scores, scores_sparse)\n\n        # Test with pandas DataFrame\n        import pandas as pd\n        X_df = pd.DataFrame(X)\n        scores_df = gmm.score_samples(X_df)\n        assert_array_almost_equal(scores, scores_df)\n\n        # Test with list of numpy arrays\n        X_list = [X]\n        scores_list = gmm.score_samples(X_list)\n        assert_array_almost_equal(scores, scores_list)\n\n        # Test with list of scipy sparse matrices\n        X_sparse_list = [X_sparse]\n        scores_sparse_list = gmm.score_samples(X_sparse_list)\n        assert_array_almost_equal(scores, scores_sparse_list)\n\n        # Test with list of pandas DataFrames\n        X_df_list = [X_df]\n        scores_df_list = gmm.score_samples(X_df_list)\n        assert_array_almost_equal(scores, scores_df_list)\n"], "sample_501": ["def test_legend_title_fontproperties():\n    # test the title_fontproperties kwarg\n    fig, ax = plt.subplots()\n    ax.plot(range(10))\n    leg = ax.legend(title='Aardvark', title_fontproperties={'family': 'serif'})\n    assert leg.get_title().get_family() == ['serif']\n    leg = ax.legend(title='Aardvark', title_fontproperties={'size': 22})\n    assert leg.get_title().get_size() == 22\n    leg = ax.legend(title='Aardvark', title_fontproperties={'weight': 'bold'})\n    assert leg.get_title().get_weight() == 700\n"], "sample_64": ["    def test_status_code(self):\n        response = HttpResponseBase()\n        self.assertEqual(response.status_code, 200)\n        response.status_code = 404\n        self.assertEqual(response.status_code, 404)\n"], "sample_40": ["def test_pixel_scale_inverse():\n    pix = 75*u.pix\n    asec = 30*u.arcsec\n\n    pixscale = 0.4*u.arcsec/u.pix\n    pixscale2 = 2.5*u.pix/u.arcsec\n\n    assert_quantity_allclose(pix.to(u.arcsec, u.pixel_scale(pixscale)), asec)\n    assert_quantity_allclose(pix.to(u.arcmin, u.pixel_scale(pixscale)), asec)\n\n    assert_quantity_allclose(pix.to(u.arcsec, u.pixel_scale(pixscale2)), asec)\n    assert_quantity_allclose(pix.to(u.arcmin, u.pixel_scale(pixscale2)), asec)\n\n    assert_quantity_allclose(asec.to(u.pix, u.pixel_scale(pixscale)), pix)\n    assert_quantity_allclose(asec.to(u.pix, u.pixel_scale(pixscale2)), pix)\n\n    # Test inverse pixel scale\n    pixscale_inv = 1 / pixscale\n    pixscale2_inv = 1 / pixscale2\n\n    assert_quantity_allclose(pix.to(u.arcsec, u.pixel_scale(pixscale_inv)), asec)\n    assert_quantity_allclose(pix.to(u.arcmin, u.pixel_scale(pixscale_inv)), asec)\n\n    assert_quantity_allclose(pix.to(u.arcsec, u.pixel_scale(pixscale2_inv)), asec)\n    assert_quantity_allclose(pix.to(u.arcmin, u.pixel_scale(pixscale2_inv)), asec)\n\n    assert_quantity_allclose(asec.to(u.pix, u.pixel_scale(pixscale_inv)), pix)\n    assert_quantity_allclose(asec.to(u.pix, u.pixel_scale(pixscale2_inv)), pix)\n"], "sample_505": ["def test_date2num_timezone():\n    # Test that date2num handles timezone-aware datetime objects correctly\n    dt = datetime.datetime(2020, 1, 1, tzinfo=datetime.timezone.utc)\n    dt_naive = dt.astimezone(datetime.timezone(datetime.timedelta(hours=1)))\n    assert mdates.date2num(dt) == mdates.date2num(dt_naive)\n"], "sample_35": ["def test_isinstancemethod():\n    class TestClass:\n            pass\n\n            pass\n\n        @classmethod\n            pass\n\n        @staticmethod\n            pass\n\n    obj = TestClass()\n\n    assert isinstancemethod(TestClass, TestClass.instance_method)\n    assert not isinstancemethod(TestClass, TestClass.class_method)\n    assert not isinstancemethod(TestClass, TestClass.static_method)\n    assert not isinstancemethod(TestClass, obj.instance_method)\n\n    with pytest.raises(AttributeError):\n        isinstancemethod(TestClass, 'non_existent_method')\n"], "sample_895": ["def test_column_transformer_set_output_after_fitting_with_remainder_transformer():\n    \"\"\"Check that the output is set for the remainder transformer after fitting.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame(\n        {\n            \"pet\": pd.Series([\"dog\", \"cat\", \"snake\"], dtype=\"category\"),\n            \"age\": [1.4, 2.1, 4.4],\n            \"height\": [20, 40, 10],\n        }\n    )\n    ct = ColumnTransformer(\n        [\n            (\n                \"color_encode\",\n                OneHotEncoder(sparse_output=False, dtype=\"int16\"),\n                [\"pet\"],\n            ),\n            (\"age\", StandardScaler(), [\"age\"]),\n        ],\n        remainder=StandardScaler(),\n        verbose_feature_names_out=False,\n    )\n\n    # fit without calling set_output\n    X_trans = ct.fit_transform(df)\n    assert isinstance(X_trans, np.ndarray)\n    assert X_trans.dtype == \"float64\"\n\n    ct.set_output(transform=\"pandas\")\n    X_trans_df = ct.transform(df)\n    expected_dtypes = {\n        \"pet_cat\": \"int16\",\n        \"pet_dog\": \"int16\",\n        \"pet_snake\": \"int16\",\n        \"age\": \"float64\",\n        \"height\": \"float64\",\n    }\n    for col, dtype in X_trans_df.dtypes.items():\n        assert dtype == expected_dtypes[col]\n"], "sample_905": ["def test_isabstractmethod():\n    class AbstractClass:\n        @abstractmethod\n            pass\n\n            pass\n\n    class ConcreteClass(AbstractClass):\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(ConcreteClass.abstract_method) is False\n    assert inspect.isabstractmethod(AbstractClass.concrete_method) is False\n    assert inspect.isabstractmethod(ConcreteClass.concrete_method) is False\n"], "sample_554": ["def test_text_repr_with_non_string_input():\n    # Test that text repr doesn't error for non-string input\n    fig, ax = plt.subplots()\n    ax.text(0.5, 0.5, 123)\n    repr(ax.text(0.5, 0.5, 123))\n"], "sample_540": ["def test_animation_repr_html_embed_limit(anim):\n    if platform.python_implementation() == 'PyPy':\n        # Something in the test setup fixture lingers around into the test and\n        # breaks pytest.warns on PyPy. This garbage collection fixes it.\n        # https://foss.heptapod.net/pypy/pypy/-/issues/3536\n        np.testing.break_cycles()\n    with mpl.rc_context({\"animation.embed_limit\": 1e-6}):  # ~1 byte.\n        with pytest.warns(UserWarning, match=\"Animation size has reached\"):\n            anim.to_html5_video()\n"], "sample_625": ["def test_cross_unequal_sizes() -> None:\n    a = xr.DataArray([1, 2, 3], dims=[\"cartesian\"])\n    b = xr.DataArray([4, 5, 6, 7], dims=[\"cartesian\"])\n\n    with pytest.raises(ValueError):\n        xr.cross(a, b, dim=\"cartesian\")\n"], "sample_286": ["    def test_save_with_deferred_fields(self):\n        a = Article.objects.create(headline='Article 1', pub_date=datetime.now())\n        a_deferred = Article.objects.defer('headline').get(pk=a.pk)\n        self.assertEqual(a_deferred.headline, 'Article 1')\n        a_deferred.save()\n        self.assertEqual(Article.objects.get(pk=a.pk).headline, 'Article 1')\n"], "sample_1040": ["def test_print_function():\n    f = Function('f')\n    assert mpp.doprint(f(x, y)) == '<mrow><mi>f</mi><mfenced><mi>x</mi><mi>y</mi></mfenced></mrow>'\n    assert mp.doprint(f(x, y)) == '<apply><f/><ci>x</ci><ci>y</ci></apply>'\n"], "sample_981": ["def test_cycle_structure():\n    p = Permutation([0, 2, 1, 3])\n    assert p.cycle_structure == {1: 2, 2: 1}\n    p = Permutation([0, 1, 2, 3])\n    assert p.cycle_structure == {1: 4}\n    p = Permutation([0, 3, 1, 2])\n    assert p.cycle_structure == {2: 2}\n    p = Permutation([0, 2, 4, 1, 3])\n    assert p.cycle_structure == {2: 1, 3: 1}\n    p = Permutation([0, 1, 2, 3, 4, 5, 6])\n    assert p.cycle_structure == {1: 7}\n    p = Permutation([0, 1, 2, 3, 4, 6, 5])\n    assert p.cycle_structure == {1: 5, 2: 1}\n    p = Permutation([0, 1, 2, 3, 6, 4, 5])\n    assert p.cycle_structure == {1: 4, 3: 1}\n    p = Permutation([0, 1, 2, 6, 3, 4, 5])\n    assert p.cycle_structure == {1: 3, 4: 1}\n    p = Permutation([0, 1, 6, 2, 3, 4, 5])\n    assert p.cycle_structure == {1: 2, 5: 1}\n    p = Permutation([0, 6, 1, 2, 3, 4, 5])\n    assert p.cycle_structure == {1: 1, 6: 1}\n"], "sample_601": ["def test_cftime_strftime_accessor(cftime_rounding_dataarray, cftime_date_type, use_dask):\n    import dask.array as da\n\n    date_format = \"%Y-%m-%d %H:%M:%S\"\n    expected = xr.DataArray(\n        [\n            [cftime_date_type(1, 1, 1, 1).strftime(date_format), cftime_date_type(1, 1, 1, 15).strftime(date_format)],\n            [cftime_date_type(1, 1, 1, 23).strftime(date_format), cftime_date_type(1, 1, 2, 1).strftime(date_format)],\n        ],\n        name=\"strftime\",\n    )\n\n    if use_dask:\n        chunks = {\"dim_0\": 1}\n        # Currently a compute is done to inspect a single value of the array\n        # if it is of object dtype to check if it is a cftime.datetime (if not\n        # we raise an error when using the dt accessor).\n        with raise_if_dask_computes(max_computes=1):\n            result = cftime_rounding_dataarray.chunk(chunks).dt.strftime(date_format)\n        expected = expected.chunk(chunks)\n        assert isinstance(result.data, da.Array)\n        assert result.chunks == expected.chunks\n    else:\n        result = cftime_rounding_dataarray.dt.strftime(date_format)\n\n    assert_identical(result, expected)\n"], "sample_829": ["def test_incremental_pca_batch_size_edge_cases():\n    # Test that IncrementalPCA handles edge cases for batch_size.\n    rng = np.random.RandomState(1999)\n    n_samples = 100\n    n_features = 3\n    X = rng.randn(n_samples, n_features)\n\n    # Test batch_size equal to n_samples\n    ipca = IncrementalPCA(n_components=None, batch_size=n_samples).fit(X)\n    assert ipca.components_.shape == (min(n_samples, n_features), n_features)\n\n    # Test batch_size equal to 1\n    ipca = IncrementalPCA(n_components=None, batch_size=1).fit(X)\n    assert ipca.components_.shape == (min(n_samples, n_features), n_features)\n\n    # Test batch_size equal to n_features\n    ipca = IncrementalPCA(n_components=None, batch_size=n_features).fit(X)\n    assert ipca.components_.shape == (min(n_samples, n_features), n_features)\n\n    # Test batch_size larger than n_samples\n    ipca = IncrementalPCA(n_components=None, batch_size=n_samples + 1).fit(X)\n    assert ipca.components_.shape == (min(n_samples, n_features), n_features)\n"], "sample_1044": ["def test_Pow_is_algebraic_expr():\n    e = Symbol('e', algebraic=True)\n\n    assert Pow(1, e, evaluate=False).is_algebraic_expr\n    assert Pow(0, e, evaluate=False).is_algebraic_expr\n\n    a = Symbol('a', algebraic=True)\n    na = Symbol('na', algebraic=False)\n    ia = Symbol('ia', algebraic=True, irrational=True)\n    ib = Symbol('ib', algebraic=True, irrational=True)\n    r = Symbol('r', rational=True)\n    x = Symbol('x')\n    assert Pow(a, r).is_algebraic_expr\n    assert Pow(a, x).is_algebraic_expr is None\n    assert Pow(na, r).is_algebraic_expr is None\n    assert Pow(ia, r).is_algebraic_expr\n    assert Pow(ia, ib).is_algebraic_expr is False\n\n    assert Pow(a, e).is_algebraic_expr is None\n\n    # Gelfond-Schneider constant:\n    assert Pow(2, sqrt(2), evaluate=False).is_algebraic_expr is False\n\n    assert Pow(S.GoldenRatio, sqrt(3), evaluate=False).is_algebraic_expr is False\n\n    # issue 8649\n    t = Symbol('t', real=True, transcendental=True)\n    n = Symbol('n', integer=True)\n    assert Pow(t, n).is_algebraic_expr is None\n    assert Pow(t, n).is_integer is None\n\n    assert Pow(pi, 3).is_algebraic_expr is False\n    r = Symbol('r', zero=True)\n    assert Pow(pi, r).is_algebraic_expr is True\n"], "sample_1098": ["def test_hyperrep_periodicity():\n    from sympy import exp_polar, pi, I\n    from sympy.abc import z\n    from sympy.functions.special.hyper import HyperRep_power1, HyperRep_power2, HyperRep_log1, HyperRep_asin1, HyperRep_asin2, HyperRep_sqrts1, HyperRep_sqrts2, HyperRep_log2, HyperRep_cosasin, HyperRep_sinasin\n    reps = [HyperRep_power1, HyperRep_power2, HyperRep_log1, HyperRep_asin1, HyperRep_asin2, HyperRep_sqrts1, HyperRep_sqrts2, HyperRep_log2, HyperRep_cosasin, HyperRep_sinasin]\n    for rep in reps:\n        for n in range(-5, 6):\n            expr = rep(z).subs(z, exp_polar(2*I*pi*n)*z).rewrite('nonrep')\n            assert expr.equals(rep(z).rewrite('nonrep'))\n"], "sample_925": ["def test_MockFinder():\n    modnames = ['sphinx.unknown']\n    finder = MockFinder(modnames)\n    assert finder.modnames == modnames\n    assert finder.mocked_modules == []\n\n    spec = finder.find_spec('sphinx.unknown', None)\n    assert spec is not None\n    assert finder.mocked_modules == ['sphinx.unknown']\n\n    spec = finder.find_spec('sphinx.unknown.submodule', None)\n    assert spec is not None\n    assert finder.mocked_modules == ['sphinx.unknown']\n\n    spec = finder.find_spec('sphinx.known', None)\n    assert spec is None\n\n    finder.invalidate_caches()\n    assert finder.mocked_modules == []\n"], "sample_722": ["def test_k_means_init_with_callable():\n    # Test that a callable init is called with the correct arguments\n        assert_array_equal(X, X_test)\n        assert_equal(k, 3)\n        assert_equal(random_state, 42)\n        return np.array([[0.0, 0.0], [5.0, 5.0], [-5.0, -5.0]])\n\n    X_test = np.array([[1.1, 1.1], [-7.5, -7.5], [-1.1, -1.1], [7.5, 7.5]])\n    km = KMeans(init=init_callable, n_clusters=3, random_state=42)\n    km.fit(X_test)\n    assert_equal(km.cluster_centers_.shape, (3, 2))\n"], "sample_848": ["def test_regressor_chain_fit_and_predict_with_cross_val():\n    # Fit regressor chain and verify predict performance using cross_val_predict\n    X, Y = datasets.make_regression(n_targets=3)\n    regressor_chain = RegressorChain(Ridge(), cv=3)\n    regressor_chain.fit(X, Y)\n\n    Y_pred = regressor_chain.predict(X)\n    assert Y_pred.shape == Y.shape\n\n    # Compare with a chain without cross_val_predict\n    regressor_chain_no_cv = RegressorChain(Ridge())\n    regressor_chain_no_cv.fit(X, Y)\n    Y_pred_no_cv = regressor_chain_no_cv.predict(X)\n\n    assert Y_pred.shape == Y_pred_no_cv.shape\n    assert not np.all(Y_pred == Y_pred_no_cv)\n"], "sample_900": ["def test_mlp_classifier_with_sparse_input():\n    # Test that MLPClassifier works with sparse input.\n    X = X_digits_binary[:50]\n    y = y_digits_binary[:50]\n    X_sparse = csr_matrix(X)\n\n    clf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=15,\n                        random_state=1)\n    clf.fit(X, y)\n    pred1 = clf.predict(X)\n    clf.fit(X_sparse, y)\n    pred2 = clf.predict(X_sparse)\n    assert_array_equal(pred1, pred2)\n"], "sample_988": ["def test_issue_13081_12583_12534_ext():\n    # 13081\n    r = Rational('905502432259640373/288230376151711744')\n    assert (r < pi) is S.false\n    assert (r > pi) is S.true\n    # 12583\n    v = sqrt(2)\n    u = sqrt(v) + 2/sqrt(10 - 8/sqrt(2 - v) + 4*v*(1/sqrt(2 - v) - 1))\n    assert (u >= 0) is S.true\n    # 12534; Rational vs NumberSymbol\n    # here are some precisions for which Rational forms\n    # at a lower and higher precision bracket the value of pi\n    # e.g. for p = 20:\n    # Rational(pi.n(p + 1)).n(25) = 3.14159265358979323846 2834\n    #                    pi.n(25) = 3.14159265358979323846 2643\n    # Rational(pi.n(p    )).n(25) = 3.14159265358979323846 1987\n    assert [p for p in range(20, 50) if\n            (Rational(pi.n(p)) < pi) and\n            (pi < Rational(pi.n(p + 1)))\n        ] == [20, 24, 27, 33, 37, 43, 48]\n    # pick one such precision and affirm that the reversed operation\n    # gives the opposite result, i.e. if x < y is true then x > y\n    # must be false\n    p = 20\n    # Rational vs NumberSymbol\n    G = [Rational(pi.n(i)) > pi for i in (p, p + 1)]\n    L = [Rational(pi.n(i)) < pi for i in (p, p + 1)]\n    assert G == [False, True]\n    assert all(i is not j for i, j in zip(L, G))\n    # Float vs NumberSymbol\n    G = [pi.n(i) > pi for i in (p, p + 1)]\n    L = [pi.n(i) < pi for i in (p, p + 1)]\n    assert G == [False, True]\n    assert all(i is not j"], "sample_219": ["    def test_window_expression(self):\n        numbers = [1, 2, 3, 4, 5]\n        Number.objects.bulk_create([Number(integer=n) for n in numbers])\n        qs = Number.objects.annotate(rank=Window(RowNumber(), partition_by=F('integer') % 2))\n        self.assertEqual([n.rank for n in qs], [1, 1, 2, 2, 3])\n"], "sample_1006": ["def test_factorial2_edge_cases():\n    assert factorial2(1) == 1\n    assert factorial2(-3) == 1/3\n    assert factorial2(-5) == 1/15\n    assert factorial2(-7) == 1/105\n    assert factorial2(-9) == 1/945\n    assert factorial2(-11) == 1/10395\n    assert factorial2(-13) == 1/135135\n    assert factorial2(-15) == 1/2027025\n    assert factorial2(-17) == 1/3448645\n    assert factorial2(-19) == 1/654729075\n    assert factorial2(-21) == 1/13749310575\n    assert factorial2(-23) == 1/316234143225\n    assert factorial2(-25) == 1/78904845122075\n"], "sample_608": ["def test_unindexed_dims_repr() -> None:\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3])}\n    expected = \"Dimensions without coordinates: y, z\"\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3]), \"y\": np.array([4, 5, 6])}\n    expected = \"Dimensions without coordinates: z\"\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3]), \"y\": np.array([4, 5, 6]), \"z\": np.array([7, 8, 9])}\n    expected = None\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n"], "sample_950": ["def test_pyclass_nesting(app):\n    text = (\".. py:class:: Outer\\n\"\n            \"\\n\"\n            \"   .. py:class:: Inner\\n\"\n            \"\\n\"\n            \"       .. py:method:: method\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_name, \"Outer\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc)])]))\n    assert_node(doctree[1][1][0], addnodes.index,\n                entries=[('single', 'Inner (class in Outer)', 'Outer.Inner', '', None)])\n    assert_node(doctree[1][1][1], ([desc_signature, ([desc_annotation, \"class \"],\n                                                     [desc_name, \"Inner\"])],\n                                   [desc_content, (addnodes.index,\n                                                   desc)]))\n    assert_node(doctree[1][1][1][1][0], addnodes.index,\n                entries=[('single', 'method() (Outer.Inner method)', 'Outer.Inner.method', '', None)])\n    assert_node(doctree[1][1][1][1][1], ([desc_signature, ([desc_name, \"method\"],\n                                                         [desc_parameterlist, ()])],\n                                        [desc_content, ()]))\n    assert 'Outer.Inner' in domain.objects\n    assert domain.objects['Outer.Inner'] == ('index', 'Outer.Inner', 'class', False)\n    assert 'Outer.Inner.method' in domain.objects\n    assert domain.objects['Outer.Inner.method'] == ('index', 'Outer.Inner.method', 'method', False)\n"], "sample_165": ["    def test_model_form_fields_for_model(self):\n        from ..models import ChoiceModel\n        fields = fields_for_model(ChoiceModel)\n        self.assertEqual(len(fields), 2)\n        self.assertIn('name', fields)\n        self.assertIn('number', fields)\n"], "sample_289": ["    def test_getstate_setstate(self):\n        d = CaseInsensitiveMapping({'Accept': 'application/json', 'content-type': 'text/html'})\n        state = d.__getstate__()\n        new_d = CaseInsensitiveMapping()\n        new_d.__setstate__(state)\n        self.assertEqual(d, new_d)\n"], "sample_773": ["def test_logistic_regression_path_multiclass():\n    # Test that logistic_regression_path works with multiclass problems\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=10,\n                               n_classes=3, random_state=0)\n    Cs = np.logspace(-4, 4, 5)\n    for solver in ['lbfgs', 'newton-cg', 'sag', 'saga']:\n        coefs, _, _ = _logistic_regression_path(X, y, Cs=Cs, solver=solver,\n                                                multi_class='multinomial',\n                                                random_state=0)\n        assert coefs.shape == (len(Cs), 3, 20)\n"], "sample_274": ["    def test_model_form_save(self):\n        # Create a model instance\n        instance = ChoiceModel.objects.create(name='test')\n\n        # Create a model form\n        class TestModelForm(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = ('name',)\n\n        # Test saving the form\n        form = TestModelForm({'name': 'new_name'}, instance=instance)\n        self.assertTrue(form.is_valid())\n        form.save()\n        instance.refresh_from_db()\n        self.assertEqual(instance.name, 'new_name')\n"], "sample_830": ["def test_get_blas_info():\n    try:\n        blas_info = _get_blas_info()\n        assert 'macros' in blas_info\n        assert 'lib_dirs' in blas_info\n        assert 'cblas_libs' in blas_info\n    except ImportError:\n        # If scikit-learn is not installed, _get_blas_info will raise an ImportError\n        pass\n"], "sample_880": ["def test_check_partial_fit_first_call():\n    class MockClassifier:\n            self.classes_ = None\n\n    clf = MockClassifier()\n\n    # Test first call with classes provided\n    assert _check_partial_fit_first_call(clf, classes=[0, 1, 2]) is True\n    assert_array_equal(clf.classes_, np.array([0, 1, 2]))\n\n    # Test subsequent call with same classes\n    _check_partial_fit_first_call(clf, classes=[0, 1, 2])\n    assert_array_equal(clf.classes_, np.array([0, 1, 2]))\n\n    # Test subsequent call with different classes\n    with pytest.raises(ValueError):\n        _check_partial_fit_first_call(clf, classes=[0, 1, 3])\n\n    # Test first call without classes\n    clf.classes_ = None\n    with pytest.raises(ValueError):\n        _check_partial_fit_first_call(clf)\n\n    # Test first call with None classes\n    with pytest.raises(ValueError):\n        _check_partial_fit_first_call(clf, classes=None)\n"], "sample_932": ["def test_template_parameter_lists():\n    check('function', 'template<typename T> void f(T)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T, typename U> void f(T, U)', {2: 'I00E1f1T1U'})\n    check('function', 'template<typename T, typename U, typename V> void f(T, U, V)', {2: 'I000E1f1T1U1V'})\n    check('function', 'template<typename T, typename U, typename V, typename W> void f(T, U, V, W)', {2: 'I0000E1f1T1U1V1W'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X> void f(T, U, V, W, X)', {2: 'I00000E1f1T1U1V1W1X'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> void f(T, U, V, W, X, Y)', {2: 'I000000E1f1T1U1V1W1X1Y'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> void f(T, U, V, W, X, Y, Z)', {2: 'I0000000E1f1T1U1V1W1X1Y1Z'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A> void f(T, U, V, W, X, Y, Z, A)', {2: 'I00000000E1f1T1U1V1W1X1Y1Z1A'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A, typename B> void f(T, U, V, W, X, Y, Z, A, B)', {2: 'I000000000E1f1T1U1V1W1X1Y1Z1A1B'})\n    check('function', 'template<typename"], "sample_652": ["    def test_func_closure_module_auto(self, testdir, variant, monkeypatch):\n        \"\"\"Semantically identical to the example posted in #2405 when ``use_mark=True``\"\"\"\n        monkeypatch.setenv(\"FIXTURE_ACTIVATION_VARIANT\", variant)\n        testdir.makepyfile(\n            \"\"\"\n            import warnings\n            import os\n            import pytest\n            VAR = 'FIXTURE_ACTIVATION_VARIANT'\n            VALID_VARS = ('autouse', 'mark')\n\n            VARIANT = os.environ.get(VAR)\n            if VARIANT is None or VARIANT not in VALID_VARS:\n                warnings.warn(\"{!r} is not  in {}, assuming autouse\".format(VARIANT, VALID_VARS) )\n                variant = 'mark'\n\n            @pytest.fixture(scope='module', autouse=VARIANT == 'autouse')\n\n            if VARIANT=='mark':\n                pytestmark = pytest.mark.usefixtures('m1')\n\n            @pytest.fixture(scope='function', autouse=True)\n\n                pass\n        \"\"\"\n        )\n        items, _ = testdir.inline_genitems()\n        request = FixtureRequest(items[0])\n        assert request.fixturenames == \"m1 f1\".split()\n"], "sample_719": ["def test_vectorizer_max_features_with_vocabulary():\n    # test bounded number of extracted features with a custom vocabulary\n    vocab = ['burger', 'beer', 'salad', 'pizza', 'celeri', 'coke', 'tomato']\n    vectorizer = CountVectorizer(vocabulary=vocab, max_features=4)\n    vectorizer.fit(ALL_FOOD_DOCS)\n    assert_equal(set(vectorizer.vocabulary_), set(vocab[:4]))\n    assert_equal(vectorizer.stop_words_, set(vocab[4:]))\n\n    vectorizer = TfidfVectorizer(vocabulary=vocab, max_features=4)\n    vectorizer.fit(ALL_FOOD_DOCS)\n    assert_equal(set(vectorizer.vocabulary_), set(vocab[:4]))\n    assert_equal(vectorizer.stop_words_, set(vocab[4:]))\n"], "sample_164": ["    def test_configure_logging(self):\n        logging_config = 'logging_tests.tests.configure_logging'\n        logging_settings = {'version': 1}\n        configure_logging(logging_config, logging_settings)\n        self.assertEqual(logging.config.dictConfig.call_count, 2)\n"], "sample_918": ["def test_pyclasslike_signature(app):\n    text = (\".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:method:: meth1\\n\"\n            \"   .. py:method:: meth2\\n\"\n            \"      :abstractmethod:\\n\"\n            \"   .. py:method:: meth3\\n\"\n            \"      :async:\\n\"\n            \"   .. py:method:: meth4\\n\"\n            \"      :classmethod:\\n\"\n            \"   .. py:method:: meth5\\n\"\n            \"      :final:\\n\"\n            \"   .. py:method:: meth6\\n\"\n            \"      :property:\\n\"\n            \"   .. py:method:: meth7\\n\"\n            \"      :staticmethod:\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_name, \"Class\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc,\n                                                  addnodes.index,\n                                                  desc,\n                                                  addnodes.index,\n                                                  desc,\n                                                  addnodes.index,\n                                                  desc,\n                                                  addnodes.index,\n                                                  desc,\n                                                  addnodes.index,\n                                                  desc)])]))\n\n    # method\n    assert_node(doctree[1][1][0], addnodes.index,\n                entries=[('single', 'meth1() (Class method)', 'Class.meth1', '', None)])\n    assert_node(doctree[1][1][1], ([desc_signature, ([desc_name, \"meth1\"],\n                                                     [desc_parameterlist, ()])],\n                                   [desc_content, ()]))\n    assert 'Class.meth1' in domain.objects\n    assert domain.objects['Class.meth1'] == ('index', 'Class.meth1', 'method')\n\n    # :abstractmethod:\n    assert_node(doctree[1][1][2], addnodes.index,\n                entries=[('single', 'meth2() (Class method)', 'Class.meth2', '', None)])\n    assert_node(doctree[1][1][3], ([desc_signature, ([desc_annotation, \"abstract \"],\n                                                     [desc_name, \"meth2\"],\n                                                     [desc_parameterlist, ()])],\n                                   [desc_content, ()]))\n    assert 'Class.meth2' in domain.objects\n    assert domain.objects['Class.meth2'] == ('index"], "sample_407": ["def test_model_base_check_unique_together(self):\n    # Test that ModelBase.check() raises an error when unique_together\n    # contains a field that does not exist on the model.\n    class TestModel(models.Model):\n        field1 = models.CharField(max_length=10)\n        field2 = models.CharField(max_length=10)\n\n        class Meta:\n            unique_together = [[\"field1\", \"field3\"]]\n\n    errors = TestModel.check()\n    self.assertEqual(len(errors), 1)\n    self.assertEqual(errors[0].id, \"models.E012\")\n    self.assertEqual(errors[0].msg, \"'unique_together' refers to the nonexistent field 'field3'.\")\n\n    # Test that ModelBase.check() raises an error when unique_together\n    # contains a ManyToManyField.\n    class TestModel(models.Model):\n        field1 = models.CharField(max_length=10)\n        field2 = models.ManyToManyField(\"self\")\n\n        class Meta:\n            unique_together = [[\"field1\", \"field2\"]]\n\n    errors = TestModel.check()\n    self.assertEqual(len(errors), 1)\n    self.assertEqual(errors[0].id, \"models.E013\")\n    self.assertEqual(\n        errors[0].msg,\n        \"'unique_together' refers to a ManyToManyField 'field2' which is not permitted.\",\n    )\n\n    # Test that ModelBase.check() raises an error when unique_together\n    # contains a field that is not local to the model.\n    class Parent(models.Model):\n        field1 = models.CharField(max_length=10)\n\n    class Child(Parent):\n        field2 = models.CharField(max_length=10)\n\n        class Meta:\n            unique_together = [[\"field1\", \"field2\"]]\n\n    errors = Child.check()\n    self.assertEqual(len(errors), 1)\n    self.assertEqual(errors[0].id, \"models.E016\")\n    self.assertEqual(\n        errors[0].msg,\n        \"'unique_together' refers to field 'field1' which is not local to model 'Child'.\",\n    )\n"], "sample_461": ["    def test_uuidfield_clean(self):\n        f = UUIDField()\n        tests = [\n            (\"123e4567-e89b-12d3-a456-426655440000\", \"123e4567-e89b-12d3-a456-426655440000\"),\n            (\"123e4567e89b12d3a456426655440000\", \"123e4567-e89b-12d3-a456-426655440000\"),\n            (\"urn:uuid:123e4567-e89b-12d3-a456-426655440000\", \"123e4567-e89b-12d3-a456-426655440000\"),\n        ]\n        for value, expected in tests:\n            with self.subTest(value=value):\n                self.assertEqual(f.clean(value), expected)\n"], "sample_760": ["def test_make_scorer_with_sample_weight():\n    # Test that make_scorer correctly handles sample weights\n    X, y = make_classification(random_state=0)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n    clf = DecisionTreeClassifier(random_state=0)\n    clf.fit(X_train, y_train)\n\n    sample_weight = np.ones_like(y_test)\n    sample_weight[:10] = 0\n\n    scorer = make_scorer(f1_score, sample_weight=sample_weight)\n    score1 = scorer(clf, X_test, y_test)\n    score2 = f1_score(y_test, clf.predict(X_test), sample_weight=sample_weight)\n    assert_almost_equal(score1, score2)\n\n    scorer = make_scorer(f1_score)\n    score3 = scorer(clf, X_test, y_test, sample_weight=sample_weight)\n    assert_almost_equal(score3, score2)\n"], "sample_345": ["    def test_enable_echo(self, mocked_signal, mocked_tcsetattr, mocked_tcgetattr):\n        mocked_tcgetattr.return_value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n        autoreload.ensure_echo_on()\n        mocked_tcsetattr.assert_called_once()\n        mocked_signal.assert_called_once()\n"], "sample_354": ["def test_required_fields_with_default_values(self):\n    new_io = StringIO()\n    call_command(\n        'createsuperuser',\n        interactive=False,\n        email=\"joe@somewhere.org\",\n        date_of_birth=\"1976-04-01\",\n        first_name='Joe',\n        stdout=new_io,\n    )\n    command_output = new_io.getvalue().strip()\n    self.assertEqual(command_output, 'Superuser created successfully.')\n    u = CustomUser._default_manager.get(email=\"joe@somewhere.org\")\n    self.assertEqual(u.date_of_birth, date(1976, 4, 1))\n    self.assertEqual(u.first_name, 'Joe')\n\n    # Test that default values are used when not provided\n    new_io = StringIO()\n    call_command(\n        'createsuperuser',\n        interactive=False,\n        email=\"joe2@somewhere.org\",\n        stdout=new_io,\n    )\n    command_output = new_io.getvalue().strip()\n    self.assertEqual(command_output, 'Superuser created successfully.')\n    u = CustomUser._default_manager.get(email=\"joe2@somewhere.org\")\n    self.assertEqual(u.date_of_birth, date(1970, 1, 1))\n    self.assertEqual(u.first_name, '')\n"], "sample_966": ["def test_python_domain_get_full_qualified_name():\n    env = Mock(domaindata={})\n    domain = PythonDomain(env)\n\n    # non-python references\n    node = nodes.reference()\n    assert domain.get_full_qualified_name(node) is None\n\n    # simple reference\n    node = nodes.reference(reftarget='func')\n    assert domain.get_full_qualified_name(node) == 'func'\n\n    # with py:module context\n    kwargs = {'py:module': 'module1'}\n    node = nodes.reference(reftarget='func', **kwargs)\n    assert domain.get_full_qualified_name(node) == 'module1.func'\n\n    # with py:class context\n    kwargs = {'py:class': 'Class'}\n    node = nodes.reference(reftarget='func', **kwargs)\n    assert domain.get_full_qualified_name(node) == 'Class.func'\n\n    # with both py:module and py:class context\n    kwargs = {'py:module': 'module1', 'py:class': 'Class'}\n    node = nodes.reference(reftarget='func', **kwargs)\n    assert domain.get_full_qualified_name(node) == 'module1.Class.func'\n"], "sample_457": ["    def test_validate_with_multiple_expressions(self):\n        constraint = models.UniqueConstraint(\n            Lower(\"name\"),\n            F(\"color\"),\n            name=\"name_color_uniq\",\n        )\n        msg = \"Constraint \u201cname_color_uniq\u201d is violated.\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            constraint.validate(\n                UniqueConstraintProduct,\n                UniqueConstraintProduct(name=self.p1.name.upper(), color=self.p1.color),\n            )\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=\"another-name\", color=\"another-color\"),\n        )\n        # Existing instances have their existing row excluded.\n        constraint.validate(UniqueConstraintProduct, self.p1)\n        # Unique fields are excluded.\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=self.p1.name.upper(), color=self.p1.color),\n            exclude={\"name\"},\n        )\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=self.p1.name.upper(), color=self.p1.color),\n            exclude={\"color\"},\n        )\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=self.p1.name.upper(), color=self.p1.color),\n            exclude={\"name\", \"color\"},\n        )\n"], "sample_436": ["    def test_runserver_ipv6(self):\n        self.write_settings(\n            \"settings.py\",\n            sdict={\n                \"ALLOWED_HOSTS\": [\"::1\"],\n                \"DEBUG\": False,\n            },\n        )\n\n        out, err = self.run_manage([\"runserver\", \"0:8000\"])\n        self.assertNoOutput(err)\n        self.assertIn(\"Starting development server at http://[::]:8000/\", out)\n\n        out, err = self.run_manage([\"runserver\", \"::1:8000\"])\n        self.assertNoOutput(err)\n        self.assertIn(\"Starting development server at http://[::1]:8000/\", out)\n\n        out, err = self.run_manage([\"runserver\", \"[::1]:8000\"])\n        self.assertNoOutput(err)\n        self.assertIn(\"Starting development server at http://[::1]:8000/\", out)\n\n        out, err = self.run_manage([\"runserver\", \"2001:0db8:1234:5678::9:8000\"])\n        self.assertNoOutput(err)\n        self.assertIn(\n            \"Starting development server at http://[2001:0db8:1234:5678::9]:8000/\", out\n        )\n\n        out, err = self.run_manage([\"runserver\", \"[2001:0db8:1234:5678::9]:8000\"])\n        self.assertNoOutput(err)\n        self.assertIn(\n            \"Starting development server at http://[2001:0db8:1234:5678::9]:8000/\", out\n        )\n"], "sample_499": ["def test_legend_draggable():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='line')\n    leg = ax.legend()\n    assert not leg.get_draggable()\n    leg.set_draggable(True)\n    assert leg.get_draggable()\n    leg.set_draggable(False)\n    assert not leg.get_draggable()\n"], "sample_768": ["def test_leave_one_group_out_with_dataframe():\n    # Check that LeaveOneGroupOut works with pandas DataFrame\n    import pandas as pd\n    groups = pd.DataFrame({'A': [1, 1, 1, 2, 2, 3, 3, 3, 3, 3]})\n    X = y = pd.DataFrame(np.ones((10, 2)))\n    logo = LeaveOneGroupOut()\n    for train, test in logo.split(X, y, groups):\n        assert_array_equal(np.intersect1d(groups.iloc[train]['A'],\n                                          groups.iloc[test]['A']).tolist(),\n                           [])\n"], "sample_287": ["def test_check_ordering_random(self):\n    class SongAdmin(admin.ModelAdmin):\n        ordering = ['?', 'title']\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'ordering' has the random ordering marker '?', \"\n            \"but contains other fields as well.\",\n            obj=SongAdmin,\n            id='admin.E032',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_237": ["    def test_builtin_permission_name_length(self):\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 200\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most 244 \"\n                \"characters for its builtin permission names to be at most 255 characters.\",\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 245\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most 244 \"\n                \"characters for its builtin permission names to be at most 255 characters.\",\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 246\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most 244 \"\n                \"characters for its builtin permission names to be at most 255 characters.\",\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n"], "sample_548": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cbar = fig.colorbar(im)\n    cbar.set_alpha(0.5)\n    assert cbar.ax.get_alpha() == 0.5\n    cbar.set_alpha(1)\n    assert cbar.ax.get_alpha() == 1\n    cbar.set_alpha(None)\n    assert cbar.ax.get_alpha() is None\n"], "sample_241": ["    def test_clone(self):\n        q = Query(Company)\n        q.where = WhereNode()\n        q.where.add(Q(name='Foobar Ltd.'), AND)\n        q.select = (F('name'),)\n        q.order_by = ('name',)\n        q.low_mark = 1\n        q.high_mark = 10\n        q.distinct = True\n        q.select_for_update = True\n        q.select_for_update_nowait = True\n        q.select_for_update_skip_locked = True\n        q.select_for_update_of = ('name',)\n        q.select_for_no_key_update = True\n        q.select_related = True\n        q.max_depth = 10\n        q.values_select = ('name',)\n        q.annotations = {'name': F('name')}\n        q.annotation_select_mask = ('name',)\n        q.combinator = 'AND'\n        q.combinator_all = True\n        q.combined_queries = (Query(Company),)\n        q.extra = {'name': 'Foobar Ltd.'}\n        q.extra_select_mask = ('name',)\n        q.extra_tables = ('company',)\n        q.extra_order_by = ('name',)\n        q.deferred_loading = (frozenset(('name',)), True)\n        q._filtered_relations = {'name': 'Foobar Ltd.'}\n        q.explain_query = True\n        q.explain_format = 'TEXT'\n        q.explain_options = {'analyze': True}\n\n        q2 = q.clone()\n        self.assertEqual(q.__dict__, q2.__dict__)\n        self.assertIsNot(q.where, q2.where)\n        self.assertIsNot(q.annotations, q2.annotations)\n        self.assertIsNot(q.extra, q2.extra)\n        self.assertIsNot(q._filtered_relations, q2._filtered_relations)\n"], "sample_701": ["def test_argument_type_str_choice_is_deprecated(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n            parser.addoption(\"--foo\", type=\"str\", choices=[\"bar\", \"baz\"])\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: `type` argument to addoption() is the string 'str'. \"\n            \"For choices this is optional and can be omitted, but when supplied should be a type \"\n            \"(for example `str` or `int`). (options: ['bar', 'baz'])\",\n        ]\n    )\n\n"], "sample_920": ["    def test_empty_docstring(self):\n        docstring = \"\"\n        config = Config()\n        actual = str(GoogleDocstring(docstring, config))\n        expected = \"\"\n        self.assertEqual(expected, actual)\n"], "sample_1208": ["def test_sample_numpy():\n    distribs_numpy = [\n        MatrixNormal('M', [[5, 6]], [4], [[2, 1], [1, 2]]),\n        Wishart('W', 5, [[1, 0], [0, 1]])\n    ]\n\n    size = 5\n    numpy = import_module('numpy')\n    if not numpy:\n        skip('NumPy not installed. Abort tests for _sample_numpy.')\n    else:\n        for X in distribs_numpy:\n            samps = sample(X, size=size, library='numpy')\n            for sam in samps:\n                assert Matrix(sam) in X.pspace.distribution.set\n        M = MatrixGamma('M', 1, 2, [[1, 0], [0, 1]])\n        raises(NotImplementedError, lambda: sample(M, size=3))\n"], "sample_372": ["    def test_match(self):\n        pattern = LocalePrefixPattern()\n        self.assertEqual(pattern.match('/en/'), ('', (), {}))\n        self.assertEqual(pattern.match('/fr/'), ('', (), {}))\n        self.assertEqual(pattern.match('/'), ('', (), {}))\n        self.assertIsNone(pattern.match('/invalid/'))\n"], "sample_105": ["    def test_get_context_data(self):\n        mixin = ContextMixin()\n        mixin.extra_context = {'foo': 'bar'}\n        context = mixin.get_context_data()\n        self.assertEqual(context['foo'], 'bar')\n        self.assertEqual(context['view'], mixin)\n"], "sample_1073": ["def test_sqrt_depth():\n    assert sqrt_depth(1) == 0\n    assert sqrt_depth(sqrt(2)) == 1\n    assert sqrt_depth(sqrt(2) + sqrt(3)) == 1\n    assert sqrt_depth(sqrt(2) + sqrt(sqrt(3))) == 2\n    assert sqrt_depth(sqrt(2) + sqrt(sqrt(sqrt(3)))) == 3\n    assert sqrt_depth(sqrt(2)*sqrt(3)) == 1\n    assert sqrt_depth(sqrt(2)*sqrt(sqrt(3))) == 2\n    assert sqrt_depth(sqrt(2)*sqrt(sqrt(sqrt(3)))) == 3\n    assert sqrt_depth(1 + sqrt(2)*(1 + sqrt(3))) == 1\n    assert sqrt_depth(1 + sqrt(2)*sqrt(1 + sqrt(3))) == 2\n"], "sample_579": ["def test_clustermap_cbar_kws(self):\n    kws = self.default_kws.copy()\n    kws['cbar_kws'] = dict(label='test')\n    g = mat.clustermap(self.df_norm, **kws)\n    assert g.ax_cbar.get_ylabel() == 'test'\n"], "sample_381": ["def test_alter_field_to_m2m(self):\n    \"\"\"\n    #23938 - Changing a concrete field into a ManyToManyField\n    first removes the concrete field and then adds the m2m field.\n    \"\"\"\n    changes = self.get_changes([self.author_with_former_m2m], [self.author_with_m2m, self.publisher])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\", \"RemoveField\", \"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Publisher')\n    self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"publishers\", model_name='author')\n    self.assertOperationAttributes(changes, 'testapp', 0, 2, name=\"publishers\", model_name='author')\n"], "sample_710": ["def test_unittest_subclass_with_metaclass(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n\n        class Meta(type):\n            pass\n\n        class MyTestCase(unittest.TestCase, metaclass=Meta):\n                pass\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n"], "sample_193": ["    def test_foreign_key_to_self(self):\n        \"\"\"\n        #24513 - Modifying an object pointing to itself would cause it to be\n        rendered twice and thus breaking its related M2M through objects.\n        \"\"\"\n        class A(models.Model):\n            to_a = models.ForeignKey('self', models.CASCADE)\n\n            class Meta:\n                app_label = \"migrations\"\n\n            return [mod for mod in state.apps.get_models() if mod._meta.model_name == 'a'][0]\n\n        project_state = ProjectState()\n        project_state.add_model(ModelState.from_model(A))\n        self.assertEqual(len(get_model_a(project_state)._meta.related_objects), 1)\n        old_state = project_state.clone()\n\n        operation = AlterField(\n            model_name=\"a\",\n            name=\"to_a\",\n            field=models.ForeignKey(\"migrations.A\", models.CASCADE, blank=True)\n        )\n        # At this point the model would be rendered twice causing its related\n        # M2M through objects to point to an old copy and thus breaking their\n        # attribute lookup.\n        operation.state_forwards(\"migrations\", project_state)\n\n        model_a_old = get_model_a(old_state)\n        model_a_new = get_model_a(project_state)\n        self.assertIsNot(model_a_old, model_a_new)\n\n        # The old model's _meta is still consistent\n        field_to_a_old = model_a_old._meta.get_field(\"to_a\")\n        self.assertEqual(field_to_a_old.remote_field.model, model_a_old)\n        self.assertIs(field_to_a_old.remote_field.model, model_a_old)\n\n        # The new model's _meta is still consistent\n        field_to_a_new = model_a_new._meta.get_field(\"to_a\")\n        self.assertEqual(field_to_a_new.remote_field.model, model_a_new)\n        self.assertIs(field_to_a_new.remote_field.model, model_a_new)\n"], "sample_636": ["def test_duplicate_code_raw_strings_ignore_comments(self) -> None:\n    \"\"\"Tests ignoring comments when checking for duplicate code.\"\"\"\n    path = join(DATA, \"raw_strings_ignore_comments\")\n    expected_output = \"Similar lines in 2 files\"\n    self._test_output(\n        [path, \"--disable=all\", \"--enable=duplicate-code\", \"--ignore-comments\"],\n        expected_output=expected_output,\n    )\n"], "sample_23": ["def test_longitude_wrap_at_edge_cases():\n    \"\"\"\n    Test wrapping of Longitude at edge cases\n    \"\"\"\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian)\n    assert np.all(lon.degree == np.array([0.0, 90, 180, 270, 0]))\n\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle=\"180d\")\n    assert np.all(lon.degree == np.array([0.0, 90, -180, -90, 0]))\n\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle=\"360d\")\n    assert np.all(lon.degree == np.array([0.0, 90, 180, 270, 0]))\n\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle=\"0d\")\n    assert np.all(lon.degree == np.array([0.0, -270, -180, -90, 0]))\n\n    lon = Longitude(np.array([0, 0.5, 1.0, 1.5, 2.0]) * np.pi, unit=u.radian, wrap_angle=\"-180d\")\n    assert np.all(lon.degree == np.array([0.0, -90, 180, 90, 0]))\n"], "sample_694": ["def test_argument_type_str_choice_is_deprecated(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n            parser.addoption(\"--foo\", type=\"bar\", choices=[\"baz\", \"qux\"])\n        \"\"\"\n    )\n    result = pytester.runpytest(\"-Wdefault::pytest.PytestRemovedIn8Warning\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestRemovedIn8Warning: `type` argument to addoption() is the string 'bar'. \"\n            \"For choices this is optional and can be omitted, but when supplied should be a type \"\n            \"(for example `str` or `int`). (options: ['baz', 'qux'])\",\n        ]\n    )\n\n"], "sample_737": ["def test_vectorizer_stop_words_removal():\n    # Ensure that deleting the stop_words_ attribute doesn't affect fit_transform\n\n    vectorizers = (\n        TfidfVectorizer().fit(JUNK_FOOD_DOCS),\n        CountVectorizer(preprocessor=strip_tags).fit(JUNK_FOOD_DOCS),\n        CountVectorizer(strip_accents=strip_eacute).fit(JUNK_FOOD_DOCS)\n    )\n\n    for vect in vectorizers:\n        vect_fit_transform = vect.fit_transform(JUNK_FOOD_DOCS).toarray()\n\n        vect.stop_words_ = None\n        stop_None_fit_transform = vect.fit_transform(JUNK_FOOD_DOCS).toarray()\n\n        delattr(vect, 'stop_words_')\n        stop_del_fit_transform = vect.fit_transform(JUNK_FOOD_DOCS).toarray()\n\n        assert_array_equal(stop_None_fit_transform, vect_fit_transform)\n        assert_array_equal(stop_del_fit_transform, vect_fit_transform)\n"], "sample_974": ["def test_ccode_MatrixElement():\n    # Test printing MatrixElement\n    M = MatrixSymbol('M', 3, 3)\n    assert ccode(M[1, 2]) == \"M[5]\"\n    assert ccode(M[0, 0]) == \"M[0]\"\n    assert ccode(M[2, 2]) == \"M[8]\"\n"], "sample_80": ["def test_is_nullable(self):\n    query = Query(Item)\n    self.assertTrue(query.is_nullable(Item._meta.get_field('name')))\n    self.assertFalse(query.is_nullable(Item._meta.get_field('id')))\n"], "sample_1188": ["def test_pretty_print_unicode_d():\n    assert upretty(d[0]) == '(0|0)'\n    assert upretty(d[1]) == '(i_N|k_N)'\n    assert upretty(d[4]) == '(a) (i_N|k_N)'\n    assert upretty(d[5]) == '(a) (i_N|k_N) + (-b) (j_N|k_N)'\n    assert upretty(d[7]) == upretty_d_7\n    assert upretty(d[10]) == '(cos(a)) (i_C|k_N) + (-sin(a)) (j_C|k_N)'\n"], "sample_331": ["    def test_parse_duration_with_trailing_whitespace(self):\n        test_values = (\n            ('4 15:30 ', timedelta(days=4, minutes=15, seconds=30)),\n            ('15:30.1 ', timedelta(minutes=15, seconds=30, milliseconds=100)),\n            ('-4 15:30 ', timedelta(days=-4, minutes=15, seconds=30)),\n            ('-172800 ', timedelta(days=-2)),\n            ('-15:30 ', timedelta(minutes=-15, seconds=-30)),\n            ('-1:15:30 ', timedelta(hours=-1, minutes=-15, seconds=-30)),\n            ('-30.1 ', timedelta(seconds=-30, milliseconds=-100)),\n            ('-30,1 ', timedelta(seconds=-30, milliseconds=-100)),\n            ('-00:01:01 ', timedelta(minutes=-1, seconds=-1)),\n            ('-01:01 ', timedelta(seconds=-61)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_933": ["def test_gettext_catalogs(app):\n    app.builder.build_all()\n\n    # Check if catalogs are correctly generated\n    catalogs = app.builder.catalogs\n    assert len(catalogs) > 0\n\n    # Check if messages are correctly added to catalogs\n    for catalog in catalogs.values():\n        for message in catalog:\n            assert message.text\n            assert message.locations\n            assert message.uuids\n\n    # Check if catalogs are correctly sorted\n    for catalog in catalogs.values():\n        messages = list(catalog)\n        assert messages == sorted(messages, key=lambda x: x.text)\n\n    # Check if catalogs are correctly written to disk\n    for textdomain, catalog in catalogs.items():\n        pofn = path.join(app.outdir, textdomain + '.pot')\n        assert path.exists(pofn)\n        with open(pofn, 'r', encoding='utf-8') as pofile:\n            content = pofile.read()\n            for message in catalog:\n                assert message.text in content\n"], "sample_1019": ["def test_monotonic_sign_univariate_polynomial():\n    x = symbols('x')\n    F = _monotonic_sign\n    assert F(x**2 + 1) == 1\n    assert F(x**2 - 1) is None\n    assert F(x**3 + 1) == 1\n    assert F(x**3 - 1) is None\n    assert F(x**4 + 1) == 1\n    assert F(x**4 - 1) is None\n    assert F(x**5 + 1) == 1\n    assert F(x**5 - 1) is None\n    assert F(x**6 + 1) == 1\n    assert F(x**6 - 1) is None\n    assert F(x**7 + 1) == 1\n    assert F(x**7 - 1) is None\n    assert F(x**8 + 1) == 1\n    assert F(x**8 - 1) is None\n    assert F(x**9 + 1) == 1\n    assert F(x**9 - 1) is None\n    assert F(x**10 + 1) == 1\n    assert F(x**10 - 1) is None\n    assert F(x**11 + 1) == 1\n    assert F(x**11 - 1) is None\n    assert F(x**12 + 1) == 1\n    assert F(x**12 - 1) is None\n    assert F(x**13 + 1) == 1\n    assert F(x**13 - 1) is None\n    assert F(x**14 + 1) == 1\n    assert F(x**14 - 1) is None\n    assert F(x**15 + 1) == 1\n    assert F(x**15 - 1) is None\n    assert F(x**16 + 1) == 1\n    assert F(x**16 - 1) is None\n    assert F(x**17 + 1) == 1\n    assert F(x**17 - 1) is None\n    assert F(x**18 + 1) == 1\n    assert F(x**18 - 1) is None\n    assert F(x**19 + 1) == 1\n    assert F(x**19 - 1"], "sample_390": ["def test_directory_index_with_directory_traversal(self):\n    \"\"\"\n    Test that the directory index view prevents directory traversal attacks.\n    \"\"\"\n    response = self.client.get(\"/%s/../\" % self.prefix)\n    self.assertEqual(404, response.status_code)\n"], "sample_538": ["def test_transformed_bbox():\n    bbox = mtransforms.Bbox.unit()\n    trans = mtransforms.Affine2D().scale(2)\n    tbox = mtransforms.TransformedBbox(bbox, trans)\n\n    assert_array_almost_equal(tbox.get_points(), [[0, 0], [2, 2]])\n\n    # Changing the transform should change the result.\n    trans.scale(2)\n    assert_array_almost_equal(tbox.get_points(), [[0, 0], [4, 4]])\n\n    # Changing the bbox should change the result.\n    bbox.set_points([[1, 1], [3, 3]])\n    assert_array_almost_equal(tbox.get_points(), [[2, 2], [6, 6]])\n"], "sample_774": ["def test_ordinal_encoder_inverse_with_unknown():\n    X = [['abc', 2, 55], ['def', 1, 55]]\n    enc = OrdinalEncoder()\n    X_tr = enc.fit_transform(X)\n    exp = np.array(X, dtype=object)\n    assert_array_equal(enc.inverse_transform(X_tr), exp)\n\n    # with unknown categories\n    X = [['abc', 2, 55], ['def', 1, 55], ['ghi', 3, 55]]\n    enc = OrdinalEncoder()\n    X_tr = enc.fit_transform(X)\n    exp = np.array(X, dtype=object)\n    assert_array_equal(enc.inverse_transform(X_tr), exp)\n"], "sample_377": ["    def test_get_traceback_frames_with_cyclic_reference(self):\n        \"\"\"\n        Test that ExceptionReporter.get_traceback_frames() handles cyclic references\n        in the exception chain.\n        \"\"\"\n        try:\n            try:\n                raise RuntimeError(\"outer\") from RuntimeError(\"inner\")\n            except RuntimeError as exc:\n                exc.__cause__ = exc\n                raise\n        except Exception:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(None, exc_type, exc_value, tb)\n        frames = reporter.get_traceback_frames()\n        self.assertEqual(len(frames), 2)\n        self.assertEqual(frames[0][\"exc_cause\"], frames[1][\"tb\"])\n        self.assertEqual(frames[1][\"exc_cause\"], frames[0][\"tb\"])\n"], "sample_261": ["    def test_parse_date_with_leading_trailing_whitespace(self):\n        self.assertIsNone(parse_date(' 2012-04-23 '))\n        self.assertIsNone(parse_date('2012-04-23\\t'))\n"], "sample_42": ["def test_pixel_scale_inverse():\n    pix = 75*u.pix\n    asec = 30*u.arcsec\n\n    pixscale = 0.4*u.arcsec/u.pix\n    pixscale2 = 2.5*u.pix/u.arcsec\n\n    assert_quantity_allclose(pix.to(u.arcsec, u.pixel_scale(pixscale)), asec)\n    assert_quantity_allclose(pix.to(u.arcmin, u.pixel_scale(pixscale)), asec)\n\n    assert_quantity_allclose(pix.to(u.arcsec, u.pixel_scale(pixscale2)), asec)\n    assert_quantity_allclose(pix.to(u.arcmin, u.pixel_scale(pixscale2)), asec)\n\n    assert_quantity_allclose(asec.to(u.pix, u.pixel_scale(pixscale)), pix)\n    assert_quantity_allclose(asec.to(u.pix, u.pixel_scale(pixscale2)), pix)\n\n    # Test inverse pixel scale\n    pixscale_inv = 1 / pixscale\n    pixscale2_inv = 1 / pixscale2\n\n    assert_quantity_allclose(pix.to(u.arcsec, u.pixel_scale(pixscale_inv)), asec)\n    assert_quantity_allclose(pix.to(u.arcmin, u.pixel_scale(pixscale_inv)), asec)\n\n    assert_quantity_allclose(pix.to(u.arcsec, u.pixel_scale(pixscale2_inv)), asec)\n    assert_quantity_allclose(pix.to(u.arcmin, u.pixel_scale(pixscale2_inv)), asec)\n\n    assert_quantity_allclose(asec.to(u.pix, u.pixel_scale(pixscale_inv)), pix)\n    assert_quantity_allclose(asec.to(u.pix, u.pixel_scale(pixscale2_inv)), pix)\n"], "sample_1186": ["def test_ndim_array_properties():\n    for ArrayType in array_types:\n        test_array = ArrayType([[1, 2, 3], [4, 5, 6]])\n        assert test_array.rank() == 2\n        assert test_array.shape == (2, 3)\n        assert len(test_array) == 6\n        assert test_array.tolist() == [[1, 2, 3], [4, 5, 6]]\n\n        test_array = ArrayType([1, 2, 3, 4, 5, 6], (2, 3))\n        assert test_array.rank() == 2\n        assert test_array.shape == (2, 3)\n        assert len(test_array) == 6\n        assert test_array.tolist() == [[1, 2, 3], [4, 5, 6]]\n\n        test_array = ArrayType([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n        assert test_array.rank() == 3\n        assert test_array.shape == (2, 2, 2)\n        assert len(test_array) == 8\n        assert test_array.tolist() == [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n\n        test_array = ArrayType([1, 2, 3, 4, 5, 6, 7, 8], (2, 2, 2))\n        assert test_array.rank() == 3\n        assert test_array.shape == (2, 2, 2)\n        assert len(test_array) == 8\n        assert test_array.tolist() == [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n"], "sample_211": ["    def test_get_context_data(self):\n        \"\"\"\n        Test that get_context_data returns a dictionary with the view instance.\n        \"\"\"\n        view = ContextMixin()\n        context = view.get_context_data()\n        self.assertIn('view', context)\n        self.assertEqual(context['view'], view)\n"], "sample_47": ["    def test_technical_500_response(self):\n        try:\n            request = self.rf.get('/test_view/')\n            request.user = User()\n            raise ValueError(\"Can't find my keys\")\n        except ValueError:\n            exc_type, exc_value, tb = sys.exc_info()\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html')\n"], "sample_427": ["def test_formset_absolute_max_with_min_num(self):\n    data = {\n        \"form-TOTAL_FORMS\": \"1001\",\n        \"form-INITIAL_FORMS\": \"0\",\n        \"form-MIN_NUM_FORMS\": \"0\",\n        \"form-MAX_NUM_FORMS\": \"0\",\n    }\n    LimitedFavoriteDrinksFormSet = formset_factory(\n        FavoriteDrinkForm,\n        max_num=30,\n        min_num=31,\n        absolute_max=1000,\n    )\n    formset = LimitedFavoriteDrinksFormSet(data=data)\n    self.assertIs(formset.is_valid(), False)\n    self.assertEqual(len(formset.forms), 1000)\n    self.assertEqual(\n        formset.non_form_errors(),\n        [\"Please submit at least 31 forms.\"],\n    )\n"], "sample_758": ["def test_check_X_y_force_all_finite_valid():\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([1, 2])\n    X[0, 0] = np.nan\n    X_checked, y_checked = check_X_y(X, y, force_all_finite='allow-nan')\n    assert_allclose_dense_sparse(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    X[0, 0] = np.inf\n    X_checked, y_checked = check_X_y(X, y, force_all_finite=True)\n    assert_allclose_dense_sparse(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    X[0, 0] = np.nan\n    X_checked, y_checked = check_X_y(X, y, force_all_finite=True)\n    assert_allclose_dense_sparse(X_checked, X)\n    assert_array_equal(y_checked, y)\n"], "sample_60": ["    def setUp(self):\n        self.site = AdminSite()\n"], "sample_761": ["def test_iterative_imputer_transform_stochasticity_with_n_nearest_features():\n    pytest.importorskip(\"scipy\", minversion=\"0.17.0\")\n    rng1 = np.random.RandomState(0)\n    rng2 = np.random.RandomState(1)\n    n = 100\n    d = 10\n    X = sparse_random_matrix(n, d, density=0.10,\n                             random_state=rng1).toarray()\n\n    # when sample_posterior=True, two transforms shouldn't be equal\n    imputer = IterativeImputer(missing_values=0,\n                               max_iter=1,\n                               sample_posterior=True,\n                               n_nearest_features=5,\n                               random_state=rng1)\n    imputer.fit(X)\n\n    X_fitted_1 = imputer.transform(X)\n    X_fitted_2 = imputer.transform(X)\n\n    # sufficient to assert that the means are not the same\n    assert np.mean(X_fitted_1) != pytest.approx(np.mean(X_fitted_2))\n\n    # when sample_posterior=False, and n_nearest_features=None\n    # and imputation_order is not random\n    # the two transforms should be identical even if rng are different\n    imputer1 = IterativeImputer(missing_values=0,\n                                max_iter=1,\n                                sample_posterior=False,\n                                n_nearest_features=5,\n                                imputation_order='ascending',\n                                random_state=rng1)\n\n    imputer2 = IterativeImputer(missing_values=0,\n                                max_iter=1,\n                                sample_posterior=False,\n                                n_nearest_features=5,\n                                imputation_order='ascending',\n                                random_state=rng2)\n    imputer1.fit(X)\n    imputer2.fit(X)\n\n    X_fitted_1a = imputer1.transform(X)\n    X_fitted_1b = imputer1.transform(X)\n    X_fitted_2 = imputer2.transform(X)\n\n    assert_allclose(X_fitted_1a, X_fitted_1b)\n    assert_allclose(X_fitted_1a, X_fitted_2)\n"], "sample_844": ["def test_optics_with_sparse_data():\n    # Test that OPTICS works with sparse data\n    from scipy.sparse import csr_matrix\n    X = csr_matrix(np.random.rand(100, 100))\n    clust = OPTICS(min_samples=10).fit(X)\n    assert_array_equal(clust.labels_.shape, (100,))\n    assert_array_equal(clust.reachability_.shape, (100,))\n    assert_array_equal(clust.core_distances_.shape, (100,))\n    assert_array_equal(clust.ordering_.shape, (100,))\n"], "sample_511": ["def test_xkcd_context_manager():\n    with plt.xkcd():\n        fig = plt.figure()\n        assert fig.get_label() == ''\n        assert rcParams['font.family'] == ['xkcd', 'xkcd Script', 'Humor Sans', 'Comic Neue', 'Comic Sans MS']\n        assert rcParams['font.size'] == 14.0\n        assert rcParams['path.sketch'] == (1.0, 100.0, 2.0)\n        assert rcParams['path.effects'] == [\n            mpl.patheffects.withStroke(linewidth=4, foreground=\"w\")]\n        assert rcParams['axes.linewidth'] == 1.5\n        assert rcParams['lines.linewidth'] == 2.0\n        assert rcParams['figure.facecolor'] == 'white'\n        assert rcParams['grid.linewidth'] == 0.0\n        assert rcParams['axes.grid'] is False\n        assert rcParams['axes.unicode_minus'] is False\n        assert rcParams['axes.edgecolor'] == 'black'\n        assert rcParams['xtick.major.size'] == 8\n        assert rcParams['xtick.major.width'] == 3\n        assert rcParams['ytick.major.size'] == 8\n        assert rcParams['ytick.major.width'] == 3\n    assert rcParams['font.family'] == rcParamsDefault['font.family']\n    assert rcParams['font.size'] == rcParamsDefault['font.size']\n    assert rcParams['path.sketch'] == rcParamsDefault['path.sketch']\n    assert rcParams['path.effects'] == rcParamsDefault['path.effects']\n    assert rcParams['axes.linewidth'] == rcParamsDefault['axes.linewidth']\n    assert rcParams['lines.linewidth'] == rcParamsDefault['lines.linewidth']\n    assert rcParams['figure.facecolor'] == rcParamsDefault['figure.facecolor']\n    assert rcParams['grid.linewidth'] == rcParamsDefault['grid.linewidth']\n    assert rcParams['axes.grid'] == rcParamsDefault['axes.grid']\n    assert rcParams['axes.unicode_minus'] == rcParamsDefault['axes.unicode_minus']\n    assert rcParams['axes.edgecolor'] == rcParamsDefault['axes.edgecolor']\n    assert rcParams['xtick.major.size'] == rcParamsDefault['xtick.major.size']\n    assert rcParams['xtick.major.width'] == rcParamsDefault['xtick"], "sample_336": ["    def test_get(self):\n        class TestClass:\n            regex = LocaleRegexDescriptor('_regex')\n            _regex = 'test'\n\n        instance = TestClass()\n        self.assertEqual(instance.regex, instance._regex)\n"], "sample_456": ["def test_formset_with_deletion_and_min_num(self):\n    \"\"\"\n    FormSets with deletion and min_num.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_delete=True, min_num=2)\n    initial = [\n        {\"choice\": \"Calexico\", \"votes\": 100},\n        {\"choice\": \"Fergie\", \"votes\": 900},\n    ]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix=\"choices\")\n    self.assertHTMLEqual(\n        \"\\n\".join(form.as_ul() for form in formset.forms),\n        '<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"choices-0-votes\" value=\"100\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"choices-0-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"choices-1-choice\" value=\"Fergie\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"choices-1-votes\" value=\"900\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"choices-1-DELETE\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"choices-2-choice\"></li>'\n        '<li>Votes: <input type=\"number\" name=\"choices-2-votes\"></li>'\n        '<li>Delete: <input type=\"checkbox\" name=\"choices-2-DELETE\"></li>',\n    )\n    # Let's delete Fergie.\n    data = {\n        \"choices-TOTAL_FORMS\": \"3\",  # the number of forms rendered\n        \"choices-INITIAL_FORMS\": \"2\",  # the number of forms with initial data\n        \"choices-MIN_NUM_FORMS\": \"2\",  # min number of forms\n        \"choices-MAX_NUM_FORMS\": \"0\",  # max number of forms\n        \"choices-0-choice\": \"Calexico\",\n        \"choices-0-votes\": \"100\",\n        \"choices-0-DELETE\": \"\",\n        \"choices-1-choice\": \"Fergie\",\n        \"choices-1-votes\": \"900\",\n        \"choices-1-DELETE\": \"on\",\n        \"choices-2-choice\": \"\",\n        \""], "sample_606": ["def test_cross_with_missing_values() -> None:\n    a = xr.DataArray(\n        [1, 2, 3],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    b = xr.DataArray(\n        [4, 5, np.nan],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n\n    expected = np.array([np.nan, np.nan, np.nan])\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(actual, expected)\n"], "sample_637": ["def test_encoding_declaration(self) -> None:\n    code = \"\"\"# -*- coding: utf-8 -*-\n                a = 1\n                \"\"\"\n    with self.assertNoMessages():\n        self.checker.process_module(self.astroid_module(code))\n"], "sample_370": ["    def setUpTestData(cls):\n        cls.book1 = Book.objects.create(title='Poems')\n        cls.book2 = Book.objects.create(title='Jane Eyre')\n        cls.author1 = Author.objects.create(name='Charlotte', first_book=cls.book1)\n        cls.author2 = Author.objects.create(name='Anne', first_book=cls.book1)\n        cls.author3 = Author.objects.create(name='Emily', first_book=cls.book1)\n        cls.author4 = Author.objects.create(name='Jane', first_book=cls.book2)\n\n        cls.book1.authors.add(cls.author1, cls.author2, cls.author3)\n        cls.book2.authors.add(cls.author4)\n"], "sample_137": ["def test_replace_named_groups(self):\n    self.assertEqual(replace_named_groups(r'^(?P<a>\\w+)/b/(?P<c>\\w+)/$'), '^<a>/b/<c>/$')\n    self.assertEqual(replace_named_groups(r'^(?P<a>\\w+)/b/(?P<c>\\w+)$'), '^<a>/b/<c>')\n    self.assertEqual(replace_named_groups(r'^(?P<a>\\w+)/b/(\\w+)/$'), '^<a>/b/<var>/$')\n    self.assertEqual(replace_named_groups(r'^(?P<a>\\w+)/b/(\\w+)$'), '^<a>/b/<var>')\n    self.assertEqual(replace_named_groups(r'^(?P<a>\\w+)/b/(?P<c>\\w+)/(?P<d>\\w+)/$'), '^<a>/b/<c>/<d>/$')\n    self.assertEqual(replace_named_groups(r'^(?P<a>\\w+)/b/(?P<c>\\w+)/(?P<d>\\w+)$'), '^<a>/b/<c>/<d>')\n"], "sample_413": ["    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n"], "sample_813": ["def test_bayesian_ridge_alpha_init():\n    # Test BayesianRidge with alpha_init\n    X = np.array([[1], [2], [6], [8], [10]])\n    Y = np.array([1, 2, 6, 8, 10])\n    clf = BayesianRidge(alpha_init=0.1)\n    clf.fit(X, Y)\n\n    # Check that the model could approximately learn the identity function\n    test = [[1], [3], [4]]\n    assert_array_almost_equal(clf.predict(test), [1, 3, 4], 2)\n\n    # Check that the alpha_ attribute is not equal to the default value\n    assert clf.alpha_ != 1. / (np.var(Y) + np.finfo(np.float64).eps)\n"], "sample_620": ["def test_concat_dim_is_variable_with_attrs() -> None:\n    objs = [Dataset({\"x\": 0}), Dataset({\"x\": 1})]\n    coord = Variable(\"y\", [3, 4], attrs={\"foo\": \"bar\"})\n    expected = Dataset({\"x\": (\"y\", [0, 1]), \"y\": coord})\n    actual = concat(objs, coord)\n    assert_identical(actual, expected)\n    assert actual.y.attrs == coord.attrs\n"], "sample_291": ["    def test_get_context_data(self):\n        view = ContextMixin()\n        context = view.get_context_data(foo='bar')\n        self.assertEqual(context['foo'], 'bar')\n        self.assertEqual(context['view'], view)\n"], "sample_661": ["def test_record_testsuite_property_with_non_string_value(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", 10)\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p1_node.assert_attr(name=\"stats\", value=\"10\")\n"], "sample_1162": ["def test_Function_kind():\n    f = S.Function('f')\n    assert f.kind is UndefinedKind\n    assert f(comm_x).kind is UndefinedKind\n    assert f(noncomm_x).kind is UndefinedKind\n"], "sample_351": ["def test_modelchoicefield_with_empty_queryset(self):\n    class ModelChoiceForm(forms.Form):\n        category = forms.ModelChoiceField(Category.objects.none())\n\n    form = ModelChoiceForm()\n    self.assertEqual(list(form.fields['category'].choices), [('', '---------')])\n    with self.assertRaises(ValidationError):\n        form.fields['category'].clean(1)\n    self.assertIsNone(form.fields['category'].clean(''))\n"], "sample_721": ["def test_check_X_y():\n    # Test that check_X_y raises an error when X and y have different lengths\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([1, 2])\n    assert_raises_regex(ValueError, 'Found input variables with inconsistent '\n                        'numbers of samples: \\[3, 2\\]', check_X_y, X, y)\n\n    # Test that check_X_y raises an error when y is not 1D\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([[1, 2], [3, 4]])\n    assert_raises_regex(ValueError, 'bad input shape \\(\\d+, \\d+\\)', check_X_y, X, y)\n\n    # Test that check_X_y raises an error when y contains NaN or infinity\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([1, np.nan])\n    assert_raises_regex(ValueError, 'Input contains NaN, infinity', check_X_y, X, y)\n\n    # Test that check_X_y raises an error when y contains non-numeric values\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array(['a', 'b'])\n    assert_raises_regex(ValueError, 'Input contains NaN, infinity', check_X_y, X, y)\n\n    # Test that check_X_y raises an error when X is not 2D\n    X = np.array([1, 2, 3])\n    y = np.array([1, 2, 3])\n    assert_raises_regex(ValueError, 'Expected 2D array, got 1D array instead',\n                        check_X_y, X, y)\n\n    # Test that check_X_y raises an error when X is not a numeric type\n    X = np.array([[1, 2], [3, 4]], dtype=object)\n    y = np.array([1, 2])\n    assert_raises_regex(ValueError, 'Input contains NaN, infinity', check_X_y, X, y)\n\n    # Test that check_X_y raises an error when X contains NaN or infinity\n    X = np.array([[1, 2], [3, np.nan]])\n    y = np.array([1, 2])\n    assert_raises_regex(ValueError, 'Input contains NaN, infinity', check"], "sample_13": ["def test_longitude_wrap_at_edge_cases():\n    \"\"\"\n    Test wrapping of Longitude at edge cases\n    \"\"\"\n\n    # Test wrapping at 0 degrees\n    lon = Longitude([0, 360, 720] * u.deg)\n    assert np.all(lon.degree == np.array([0., 0., 0.]))\n\n    # Test wrapping at 180 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='180d')\n    assert np.all(lon.degree == np.array([0., -180., 0.]))\n\n    # Test wrapping at -180 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='-180d')\n    assert np.all(lon.degree == np.array([0., 180., 0.]))\n\n    # Test wrapping at 90 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='90d')\n    assert np.all(lon.degree == np.array([0., -270., 0.]))\n\n    # Test wrapping at -90 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='-90d')\n    assert np.all(lon.degree == np.array([0., 270., 0.]))\n\n    # Test wrapping at 45 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='45d')\n    assert np.all(lon.degree == np.array([0., -315., 0.]))\n\n    # Test wrapping at -45 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='-45d')\n    assert np.all(lon.degree == np.array([0., 315., 0.]))\n"], "sample_1192": ["def test_Wild_matches():\n    S = sympify\n    x = Symbol(\"x\")\n    y = Symbol(\"y\")\n    p = Symbol(\"p\", positive=True)\n    k = Symbol(\"k\", integer=True)\n    n = Symbol(\"n\", integer=True, positive=True)\n\n    given_patterns = [ x, y, p, k, -k, n, -n, S(-3), S(3),\n                       pi, Rational(3, 2), I ]\n\n    W = Wild(\"W\")\n    assert W.matches(x) == {W: x}\n    assert W.matches(y) == {W: y}\n    assert W.matches(p) == {W: p}\n    assert W.matches(k) == {W: k}\n    assert W.matches(-k) == {W: -k}\n    assert W.matches(n) == {W: n}\n    assert W.matches(-n) == {W: -n}\n    assert W.matches(S(-3)) == {W: S(-3)}\n    assert W.matches(S(3)) == {W: S(3)}\n    assert W.matches(pi) == {W: pi}\n    assert W.matches(Rational(3, 2)) == {W: Rational(3, 2)}\n    assert W.matches(I) == {W: I}\n\n    W = Wild(\"W\", exclude=[x, p, k, n])\n    assert W.matches(x) is None\n    assert W.matches(y) == {W: y}\n    assert W.matches(p) is None\n    assert W.matches(k) is None\n    assert W.matches(-k) == {W: -k}\n    assert W.matches(n) is None\n    assert W.matches(-n) == {W: -n}\n    assert W.matches(S(-3)) == {W: S(-3)}\n    assert W.matches(S(3)) == {W: S(3)}\n    assert W.matches(pi) == {W: pi}\n    assert W.matches(Rational(3, 2)) == {W: Rational(3, 2)}\n    assert W.matches(I) == {W: I}\n\n    W = Wild(\"W\", properties=[lambda k: k.is_Symbol])\n    assert W.matches(x) == {W: x}\n    assert W.matches(y) == {W: y}\n    assert W.matches(p) == {W: p}\n    assert W.matches(k) == {W:"], "sample_1039": ["def test_print_function():\n    f = Function('f')\n    assert mpp.doprint(f(x, y)) == '<mrow><mi>f</mi><mfenced><mi>x</mi><mi>y</mi></mfenced></mrow>'\n    assert mp.doprint(f(x, y)) == '<apply><f/><ci>x</ci><ci>y</ci></apply>'\n"], "sample_190": ["def test_uuid_text_mixin(self):\n    # Test UUIDTextMixin with different lookup types\n    uuid = '12345678-1234-1234-1234-123456789012'\n    uuid_obj = UUIDField.objects.create(uuid=uuid)\n    self.assertEqual(UUIDField.objects.filter(uuid__iexact=uuid).get(), uuid_obj)\n    self.assertEqual(UUIDField.objects.filter(uuid__contains=uuid[:8]).get(), uuid_obj)\n    self.assertEqual(UUIDField.objects.filter(uuid__icontains=uuid[:8]).get(), uuid_obj)\n    self.assertEqual(UUIDField.objects.filter(uuid__startswith=uuid[:8]).get(), uuid_obj)\n    self.assertEqual(UUIDField.objects.filter(uuid__istartswith=uuid[:8]).get(), uuid_obj)\n    self.assertEqual(UUIDField.objects.filter(uuid__endswith=uuid[9:]).get(), uuid_obj)\n    self.assertEqual(UUIDField.objects.filter(uuid__iendswith=uuid[9:]).get(), uuid_obj)\n"], "sample_481": ["    def test_addslashes01(self):\n        output = self.engine.render_to_string(\"addslashes01\", {\"a\": \"Hello, World!\"})\n        self.assertEqual(output, \"Hello, World!\")\n"], "sample_1209": ["def test_prefix_latex():\n    assert kilo._latex(None) == r'\\text{k}'\n    assert micro._latex(None) == r'\\mu'\n    assert Prefix('test', 't', 1)._latex(None) == r'\\text{t}'\n"], "sample_527": ["def test_figure_subplots_adjust():\n    fig, axs = plt.subplots(2, 2)\n    axs[0, 0].set_title('Top Left')\n    axs[0, 1].set_title('Top Right')\n    axs[1, 0].set_title('Bottom Left')\n    axs[1, 1].set_title('Bottom Right')\n\n    fig.subplots_adjust(left=0.2, bottom=0.2, right=0.8, top=0.8)\n    assert axs[0, 0].get_position().x0 == 0.2\n    assert axs[0, 0].get_position().y0 == 0.2\n    assert axs[0, 1].get_position().x0 == 0.6\n    assert axs[0, 1].get_position().y0 == 0.2\n    assert axs[1, 0].get_position().x0 == 0.2\n    assert axs[1, 0].get_position().y0 == 0.0\n    assert axs[1, 1].get_position().x0 == 0.6\n    assert axs[1, 1].get_position().y0 == 0.0\n\n    fig.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9)\n    assert axs[0, 0].get_position().x0 == 0.1\n    assert axs[0, 0].get_position().y0 == 0.1\n    assert axs[0, 1].get_position().x0 == 0.5\n    assert axs[0, 1].get_position().y0 == 0.1\n    assert axs[1, 0].get_position().x0 == 0.1\n    assert axs[1, 0].get_position().y0 == 0.0\n    assert axs[1, 1].get_position().x0 == 0.5\n    assert axs[1, 1].get_position().y0 == 0.0\n"], "sample_674": ["def test_repr_failure_with_conftest_import_failure(testdir):\n    \"\"\"Test that repr_failure handles ConftestImportFailure correctly.\"\"\"\n    p = testdir.makeconftest(\n        \"\"\"\n        raise Exception(\"conftest import failure\")\n    \"\"\"\n    )\n    p = testdir.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([str(p) + \":*: conftest import failure\", \"*1 failed in *\"])\n"], "sample_282": ["def test_bound_field_label_tag(self):\n    form = ComplexFieldForm()\n    bound_field = form['field1']\n    label_tag = bound_field.label_tag()\n    self.assertHTMLEqual(label_tag, '<label for=\"id_field1_0\">Field1:</label>')\n    label_tag = bound_field.label_tag(label_suffix=':')\n    self.assertHTMLEqual(label_tag, '<label for=\"id_field1_0\">Field1:</label>')\n    label_tag = bound_field.label_tag(contents='Custom label')\n    self.assertHTMLEqual(label_tag, '<label for=\"id_field1_0\">Custom label</label>')\n    label_tag = bound_field.label_tag(contents='Custom label', attrs={'class': 'custom-class'})\n    self.assertHTMLEqual(label_tag, '<label for=\"id_field1_0\" class=\"custom-class\">Custom label</label>')\n"], "sample_426": ["def test_time_strings_customization(self):\n    \"\"\"Test that time_strings can be customized.\"\"\"\n    custom_time_strings = {\n        \"year\": ngettext_lazy(\"%(num)d year\", \"%(num)d years\", \"num\"),\n        \"month\": ngettext_lazy(\"%(num)d month\", \"%(num)d months\", \"num\"),\n        \"week\": ngettext_lazy(\"%(num)d week\", \"%(num)d weeks\", \"num\"),\n        \"day\": ngettext_lazy(\"%(num)d day\", \"%(num)d days\", \"num\"),\n        \"hour\": ngettext_lazy(\"%(num)d hour\", \"%(num)d hours\", \"num\"),\n        \"minute\": ngettext_lazy(\"%(num)d minute\", \"%(num)d minutes\", \"num\"),\n    }\n    custom_time_strings[\"year\"] = ngettext_lazy(\"%(num)d year (custom)\", \"%(num)d years (custom)\", \"num\")\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneyear, time_strings=custom_time_strings),\n        \"1\\xa0year (custom)\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + 2 * self.oneyear, time_strings=custom_time_strings),\n        \"2\\xa0years (custom)\",\n    )\n"], "sample_838": ["def test_column_transformer_sparse_remainder_transformer_with_weights():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           transformer_weights={'trans1': 2},\n                           sparse_threshold=0.8)\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n    # SparseMatrixTrans creates 3 features for each column. There is\n    # one column in ``transformers``, thus:\n    assert X_trans.shape == (3, 3 + 1)\n\n    exp_array = np.hstack(\n        (2 * X_array[:, 0].reshape(-1, 1), np.eye(3)))\n    assert_array_equal(X_trans.toarray(), exp_array)\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], SparseMatrixTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n"], "sample_887": ["def test_calibration_display_with_pos_label(pyplot, iris_data_binary):\n    \"\"\"Check the behaviour of `pos_label` in the `CalibrationDisplay`.\"\"\"\n    X, y = iris_data_binary\n\n    lr = LogisticRegression().fit(X, y)\n    viz = CalibrationDisplay.from_estimator(lr, X, y, pos_label=0)\n\n    y_prob = lr.predict_proba(X)[:, 0]\n    prob_true, prob_pred = calibration_curve(y, y_prob, pos_label=0)\n\n    assert_allclose(viz.prob_true, prob_true)\n    assert_allclose(viz.prob_pred, prob_pred)\n    assert_allclose(viz.y_prob, y_prob)\n\n    assert (\n        viz.ax_.get_xlabel()\n        == f\"Mean predicted probability (Positive class: {0})\"\n    )\n    assert (\n        viz.ax_.get_ylabel()\n        == f\"Fraction of positives (Positive class: {0})\"\n    )\n\n    expected_legend_labels = [lr.__class__.__name__, \"Perfectly calibrated\"]\n    legend_labels = viz.ax_.get_legend().get_texts()\n    assert len(legend_labels) == len(expected_legend_labels)\n    for labels in legend_labels:\n        assert labels.get_text() in expected_legend_labels\n"], "sample_479": ["def test_create_model_alter_model_table(self):\n    \"\"\"\n    AlterModelTable should optimize into CreateModel.\n    \"\"\"\n    managers = [(\"objects\", EmptyManager())]\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n                options={\"verbose_name\": \"Foo\"},\n                bases=(UnicodeModel,),\n                managers=managers,\n            ),\n            migrations.AlterModelTable(\"Foo\", \"my_table\"),\n        ],\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n                options={\"verbose_name\": \"Foo\", \"db_table\": \"my_table\"},\n                bases=(UnicodeModel,),\n                managers=managers,\n            ),\n        ],\n    )\n"], "sample_203": ["    def test_prohibit_null_characters_validator(self):\n        class MyForm(forms.Form):\n            field = forms.CharField(\n                validators=[validators.ProhibitNullCharactersValidator()],\n            )\n\n        form = MyForm({'field': 'a\\0b'})\n        self.assertIs(form.is_valid(), False)\n        self.assertEqual(form.errors, {'field': ['Null characters are not allowed.']})\n\n        form = MyForm({'field': 'ab'})\n        self.assertIs(form.is_valid(), True)\n"], "sample_117": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = '!'\n        html = widget.render('name', value, {'id': 'id_password'})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_450": ["def test_get_admin_log_template_tag(self):\n    \"\"\"\n    Test the get_admin_log template tag.\n    \"\"\"\n    template = template.Template(\"{% load admin_utils %}{% get_admin_log 10 as admin_log %}\")\n    context = template.Context({\"log_entries\": LogEntry.objects.all()})\n    rendered_template = template.render(context)\n    self.assertEqual(rendered_template, \"\")\n\n    self.assertIn(\"admin_log\", context)\n    self.assertEqual(len(context[\"admin_log\"]), 10)\n\n    template = template.Template(\n        \"{% load admin_utils %}{% get_admin_log 10 as admin_log for_user user %}\"\n    )\n    context = template.Context({\"log_entries\": LogEntry.objects.all(), \"user\": self.user})\n    rendered_template = template.render(context)\n    self.assertEqual(rendered_template, \"\")\n\n    self.assertIn(\"admin_log\", context)\n    self.assertEqual(len(context[\"admin_log\"]), 1)\n\n    template = template.Template(\n        \"{% load admin_utils %}{% get_admin_log 10 as admin_log for_user 1 %}\"\n    )\n    context = template.Context({\"log_entries\": LogEntry.objects.all()})\n    rendered_template = template.render(context)\n    self.assertEqual(rendered_template, \"\")\n\n    self.assertIn(\"admin_log\", context)\n    self.assertEqual(len(context[\"admin_log\"]), 1)\n"], "sample_2": ["def test_ccddata_init_with_invalid_unit(tmpdir):\n    with pytest.raises(ValueError):\n        CCDData(np.zeros([2, 2]), unit=\"definitely-not-a-unit\")\n"], "sample_515": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cb = fig.colorbar(im)\n    assert cb.alpha is None\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n    cb.set_alpha([0.5, 0.5])\n    assert cb.alpha is None\n"], "sample_956": ["def test_inventory_exists(tempdir, app, status, warning):\n    inv_file = tempdir / 'inventory'\n    inv_file.write_bytes(inventory_v2)\n    set_config(app, {\n        'https://docs.python.org/': inv_file,\n    })\n\n    # load the inventory and check if it's done correctly\n    normalize_intersphinx_mapping(app, app.config)\n    load_mappings(app)\n\n    assert inventory_exists(app.env, 'https://docs.python.org/')\n    assert not inventory_exists(app.env, 'https://docs.python.org/invalid')\n"], "sample_103": ["def test_aggregate_annotation_with_distinct(self):\n    \"\"\"\n    Test that aggregate annotations with distinct=True work correctly.\n    \"\"\"\n    vals = Book.objects.annotate(num_authors=Count(\"authors__id\", distinct=True)).aggregate(Avg(\"num_authors\"))\n    self.assertEqual(vals, {\"num_authors__avg\": Approximate(1.66, places=1)})\n\n    vals = Book.objects.annotate(num_authors=Count(\"authors__id\", distinct=True)).aggregate(Sum(\"num_authors\"))\n    self.assertEqual(vals, {\"num_authors__sum\": 10})\n\n    vals = Book.objects.annotate(num_authors=Count(\"authors__id\", distinct=True)).aggregate(Max(\"num_authors\"))\n    self.assertEqual(vals, {\"num_authors__max\": 3})\n\n    vals = Book.objects.annotate(num_authors=Count(\"authors__id\", distinct=True)).aggregate(Min(\"num_authors\"))\n    self.assertEqual(vals, {\"num_authors__min\": 1})\n"], "sample_1041": ["def test_MatrixExpr_from_index_summation():\n    from sympy import MatrixSymbol, Sum, symbols\n    from sympy.abc import i, j, k, l, N\n    A = MatrixSymbol(\"A\", N, N)\n    B = MatrixSymbol(\"B\", N, N)\n    C = MatrixSymbol(\"C\", N, N)\n    D = MatrixSymbol(\"D\", N, N)\n    E = MatrixSymbol(\"E\", N, N)\n    F = MatrixSymbol(\"F\", N, N)\n\n    expr = Sum(A[i, j]*B[j, k], (j, 0, N-1))\n    assert MatrixExpr.from_index_summation(expr) == A*B\n\n    expr = Sum(A[j, i]*B[j, k], (j, 0, N-1))\n    assert MatrixExpr.from_index_summation(expr) == A.T*B\n\n    expr = Sum(A[i, i], (i, 0, N-1))\n    assert MatrixExpr.from_index_summation(expr) == A.trace()\n\n    expr = Sum(A[i, j]*B[k, j]*A[l, k], (j, 0, N-1), (k, 0, N-1))\n    assert MatrixExpr.from_index_summation(expr) == A*B.T*A.T\n\n    expr = Sum(A[i, j]*B[j, k]*C[k, l]*D[l, i], (j, 0, N-1), (k, 0, N-1), (l, 0, N-1))\n    assert MatrixExpr.from_index_summation(expr) == A*B*C*D\n\n    expr = Sum(A[i, j]*B[j, k]*C[k, l]*D[l, i], (j, 0, N-1), (k, 0, N-1), (l, 0, N-1))\n    assert MatrixExpr.from_index_summation(expr, first_index=i, last_index=l) == A*B*C*D\n\n    expr = Sum(A[i, j]*B[j, k]*C[k, l]*D[l, i], (j, 0, N-1), (k, 0, N-1), (l, 0, N-1))\n    assert MatrixExpr.from_index_summation(expr, first_index=l, last_index=i) == D.T*C.T"], "sample_644": ["def test_import_outside_toplevel(self) -> None:\n    module = astroid.MANAGER.ast_from_module_name(\"import_outside_toplevel\", REGR_DATA)\n    import_node = module.body[1].body[0]\n\n    msg = MessageTest(\n        msg_id=\"import-outside-toplevel\",\n        node=import_node,\n        args=\"math\",\n        line=3,\n        col_offset=4,\n        end_line=3,\n        end_col_offset=11,\n    )\n    with self.assertAddsMessages(msg):\n        self.checker.visit_import(import_node)\n"], "sample_995": ["def test_issue_12345():\n    # Test that the Rational class handles negative numbers correctly\n    assert Rational(-1, 2) == -Rational(1, 2)\n    assert Rational(-1, -2) == Rational(1, 2)\n    assert Rational(1, -2) == -Rational(1, 2)\n    assert Rational(-1, -2) == Rational(1, 2)\n    assert Rational(-1, 2) + Rational(1, 2) == 0\n    assert Rational(-1, 2) - Rational(1, 2) == -1\n    assert Rational(-1, 2) * Rational(1, 2) == -Rational(1, 4)\n    assert Rational(-1, 2) / Rational(1, 2) == -1\n"], "sample_330": ["    def test_typecast_date(self):\n        self.assertIsNone(typecast_date(None))\n        self.assertEqual(typecast_date('2022-01-01'), datetime.date(2022, 1, 1))\n"], "sample_1144": ["def test_requires_partial_edge_cases():\n    x, y, z = symbols('x y z')\n    f = symbols('f', cls=Function)\n\n    # Test with a single variable\n    assert requires_partial(Derivative(x, x)) is False\n\n    # Test with a constant\n    assert requires_partial(Derivative(1, x)) is False\n\n    # Test with a function of a single variable\n    assert requires_partial(Derivative(f(x), x)) is False\n\n    # Test with a function of multiple variables\n    assert requires_partial(Derivative(f(x, y), x)) is True\n\n    # Test with a function of multiple variables and multiple derivatives\n    assert requires_partial(Derivative(f(x, y), x, y)) is True\n\n    # Test with a function of a single variable and multiple derivatives\n    assert requires_partial(Derivative(f(x), x, x)) is False\n\n    # Test with a function of a single variable and a derivative with respect to a different variable\n    assert requires_partial(Derivative(f(x), y)) is True\n"], "sample_941": ["def test_get_type_hints():\n        pass\n\n    assert get_type_hints(func) == {'a': int, 'b': str, 'return': None}\n\n    class MyClass:\n            pass\n\n    assert get_type_hints(MyClass.__init__) == {'a': int, 'b': str, 'return': None}\n\n    module = sys.modules[__name__]\n    assert get_type_hints(module) == {}\n\n    with pytest.raises(TypeError):\n        get_type_hints(123)\n\n    with pytest.raises(KeyError):\n        class BrokenClass:\n            __annotations__ = {'a': 1}\n        get_type_hints(BrokenClass)\n"], "sample_899": ["def test_check_estimator_sparse_data():\n    # test that check_estimator_sparse_data works on a class with\n    # a sparse data\n\n    class TestEstimatorSparseData(BaseEstimator):\n            return self\n\n            return np.ones(X.shape[0])\n\n    # test that check_estimator_sparse_data raises an error\n    # when sparse data is not supported\n    msg = \"Estimator TestEstimatorSparseData doesn't seem to fail gracefully on sparse data\"\n    assert_raises_regex(AssertionError, msg, check_estimator_sparse_data,\n                        \"TestEstimatorSparseData\", TestEstimatorSparseData())\n\n    # test that check_estimator_sparse_data doesn't raise an error\n    # when sparse data is supported\n    class TestEstimatorSparseDataSupported(BaseEstimator):\n            return self\n\n            if sp.issparse(X):\n                return np.ones(X.shape[0])\n            else:\n                raise ValueError(\"Sparse data not supported\")\n\n    check_estimator_sparse_data(\"TestEstimatorSparseDataSupported\",\n                                TestEstimatorSparseDataSupported())\n"], "sample_822": ["def test_cosine_distances_sparse():\n    # Check the pairwise Cosine distances computation with sparse matrices\n    rng = np.random.RandomState(1337)\n    x = np.abs(rng.rand(910))\n    XA = csr_matrix(np.vstack([x, x]))\n    XB = csr_matrix(np.vstack([x, -x]))\n    D = cosine_distances(XA)\n    assert_array_almost_equal(D.toarray(), [[0., 0.], [0., 0.]])\n    # check that all elements are in [0, 2]\n    assert np.all(D >= 0.)\n    assert np.all(D <= 2.)\n    # check that diagonal elements are equal to 0\n    assert_array_almost_equal(D.diagonal().toarray(), [0., 0.])\n\n    D2 = cosine_distances(XB)\n    # check that all elements are in [0, 2]\n    assert np.all(D2 >= 0.)\n    assert np.all(D2 <= 2.)\n    # check that diagonal elements are equal to 0 and non diagonal to 2\n    assert_array_almost_equal(D2.toarray(), [[0., 2.], [2., 0.]])\n\n    # check large random matrix\n    X = csr_matrix(np.abs(rng.rand(1000, 5000)))\n    D = cosine_distances(X)\n    # check that diagonal elements are equal to 0\n    assert_array_almost_equal(D.diagonal().toarray(), [0.] * D.shape[0])\n    assert np.all(D >= 0.)\n    assert np.all(D <= 2.)\n"], "sample_218": ["def test_trunc_timezone_with_dst_transition(self):\n    sao = pytz.timezone('America/Sao_Paulo')\n    start_datetime = datetime(2016, 2, 20, 23, 59, 59)\n    end_datetime = datetime(2016, 10, 16, 0, 0, 1)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n\n    with timezone.override(sao):\n        with self.assertRaisesMessage(pytz.NonExistentTimeError, '2016-10-16 00:00:00'):\n            model = DTModel.objects.annotate(truncated_start=TruncMinute('start_datetime')).get()\n        with self.assertRaisesMessage(pytz.AmbiguousTimeError, '2016-02-20 23:00:00'):\n            model = DTModel.objects.annotate(truncated_end=TruncHour('end_datetime')).get()\n        model = DTModel.objects.annotate(\n            truncated_start=TruncMinute('start_datetime', is_dst=False),\n            truncated_end=TruncHour('end_datetime', is_dst=False),\n        ).get()\n        self.assertEqual(model.truncated_start.dst(), timedelta(0))\n        self.assertEqual(model.truncated_end.dst(), timedelta(0))\n        model = DTModel.objects.annotate(\n            truncated_start=TruncMinute('start_datetime', is_dst=True),\n            truncated_end=TruncHour('end_datetime', is_dst=True),\n        ).get()\n        self.assertEqual(model.truncated_start.dst(), timedelta(0, 3600))\n        self.assertEqual(model.truncated_end.dst(), timedelta(0, 3600))\n"], "sample_913": ["def test_python_domain_clear_doc(app):\n    text = (\".. py:module:: docutils\\n\"\n            \".. py:module:: sphinx\\n\"\n            \".. py:module:: sphinx.config\\n\"\n            \".. py:module:: sphinx.builders\\n\"\n            \".. py:module:: sphinx.builders.html\\n\"\n            \".. py:module:: sphinx_intl\\n\")\n    restructuredtext.parse(app, text)\n    domain = app.env.get_domain('py')\n    assert len(domain.modules) == 6\n    assert len(domain.objects) == 0\n    domain.clear_doc('index')\n    assert len(domain.modules) == 6\n    assert len(domain.objects) == 0\n    domain.clear_doc('nonexistent')\n    assert len(domain.modules) == 6\n    assert len(domain.objects) == 0\n    domain.note_module('docutils', 'docutils', '', '', False)\n    domain.note_object('docutils', 'module', 'docutils', location=None)\n    assert len(domain.modules) == 7\n    assert len(domain.objects) == 1\n    domain.clear_doc('index')\n    assert len(domain.modules) == 6\n    assert len(domain.objects) == 0\n"], "sample_977": ["def test_user_functions():\n    assert mcode(sin(x), user_functions={'sin': 'MySin'}) == \"MySin[x]\"\n    assert mcode(cos(x), user_functions={'cos': 'MyCos'}) == \"MyCos[x]\"\n    assert mcode(sin(x) + cos(x), user_functions={'sin': 'MySin', 'cos': 'MyCos'}) == \"MySin[x] + MyCos[x]\"\n"], "sample_348": ["    def test_model_form_metaclass(self):\n        class TestModel(Model):\n            name = Field()\n\n        class TestForm(ModelForm):\n            class Meta:\n                model = TestModel\n                fields = ('name',)\n\n        self.assertEqual(TestForm._meta.model, TestModel)\n        self.assertEqual(TestForm._meta.fields, ('name',))\n"], "sample_269": ["    def test_jsi18n_with_empty_packages(self):\n        \"\"\"\n        Test that JavaScriptCatalog view raises a ValueError when packages is empty.\n        \"\"\"\n        view = JavaScriptCatalog.as_view()\n        request = RequestFactory().get('/')\n        msg = 'Invalid package(s) provided to JavaScriptCatalog: '\n        with self.assertRaisesMessage(ValueError, msg):\n            view(request, packages='')\n"], "sample_810": ["def test_pipeline_memory_with_feature_union():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        if LooseVersion(joblib_version) < LooseVersion('0.12'):\n            # Deal with change of API in joblib\n            memory = Memory(cachedir=cachedir, verbose=10)\n        else:\n            memory = Memory(location=cachedir, verbose=10)\n        # Test with FeatureUnion + SVC\n        clf = SVC(gamma='scale', probability=True, random_state=0)\n        pca = PCA(n_components=2, svd_solver='full')\n        select = SelectKBest(k=1)\n        pipe = Pipeline([('union', FeatureUnion([(\"pca\", pca), (\"select\", select)])), ('svc', clf)])\n        cached_pipe = Pipeline([('union', FeatureUnion([(\"pca\", pca), (\"select\", select)])), ('svc', clf)],\n                               memory=memory)\n\n        # Memoize the transformer at the first fit\n        cached_pipe.fit(X, y)\n        pipe.fit(X, y)\n        # Get the time stamp of the transformer in the cached pipeline\n        ts_pca = cached_pipe.named_steps['union'].transformer_list[0][1].timestamp_\n        ts_select = cached_pipe.named_steps['union'].transformer_list[1][1].timestamp_\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['union'].transformer_list[0][1].means_,\n                           cached_pipe.named_steps['union'].transformer_list[0][1].means_)\n        assert_array_equal(pipe.named_steps['union'].transformer_list[1][1].scores_,\n                           cached_pipe.named_steps['union'].transformer_list[1][1].scores_)\n        assert not hasattr(pca, 'means_')\n        assert not hasattr(select, 'scores_')\n        # Check that we are reading the cache while fitting\n        # a second time\n        cached_pipe.fit(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached"], "sample_382": ["def test_reset_all_loaders_with_cached_loader(self, mock_reset):\n    autoreload.reset_loaders()\n    self.assertEqual(mock_reset.call_count, 2)\n"], "sample_619": ["def test_decode_cf_datetime_invalid_calendar() -> None:\n    units = \"days since 2000-01-01\"\n    num_dates = np.arange(10)\n    invalid_calendar = \"invalid_calendar\"\n    with pytest.raises(ValueError, match=\"Array does not contain datetime objects.\"):\n        decode_cf_datetime(num_dates, units, calendar=invalid_calendar)\n"], "sample_643": ["def test_colorized_text_reporter_color_mapping(tmp_path):\n    output = StringIO()\n    linter = PyLinter(reporter=ColorizedTextReporter(output))\n    checkers.initialize(linter)\n    linter.config.persistent = 0\n    linter.set_option(\"output-format\", \"colorized\")\n    linter.open()\n    linter.set_current_module(\"0123\")\n    linter.add_message(\"line-too-long\", line=1, args=(1, 2))\n    linter.add_message(\"missing-module-docstring\", line=1, args=(1, 2))\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert out_lines[1].startswith(\"\\033[35m************* Module 0123\\033[0m\")\n    assert out_lines[2].startswith(\"\\033[35m0123:1:0: \\033[0m\\033[31;1mC0301\\033[0m: \\033[31;1mLine too long (1/2)\\033[0m (\\033[31;1mline-too-long\\033[0m)\")\n    assert out_lines[3].startswith(\"\\033[35m0123:1:0: \\033[0m\\033[31;1mC0114\\033[0m: \\033[31;1mMissing module docstring\\033[0m (\\033[31;1mmissing-module-docstring\\033[0m)\")\n"], "sample_864": ["def test_mean_shift_single_seed():\n    # Test _mean_shift_single_seed function\n    X = np.array([[1, 1], [2, 1], [1, 0],\n                  [4, 7], [3, 5], [3, 6]])\n    bandwidth = 2\n    nbrs = NearestNeighbors(radius=bandwidth, n_jobs=1).fit(X)\n    seed = np.array([1, 1])\n    result = _mean_shift_single_seed(seed, X, nbrs, max_iter=300)\n    assert np.allclose(result[0], [1.33333333, 0.66666667])\n    assert result[1] == 3\n    assert result[2] == 1\n"], "sample_633": ["def test_hash_lineset() -> None:\n    lineset = LineSet(\n        \"test\",\n        [\n            \"import one\",\n            \"from two import two\",\n            \"three\",\n            \"four\",\n            \"five\",\n            \"# A full line comment\",\n            \"seven\",\n            \"eight\",\n            \"nine\",\n            \"''' ten\",\n            \"ELEVEN\",\n            \"twelve '''\",\n            \"thirteen\",\n            \"fourteen\",\n        ],\n        ignore_comments=False,\n        ignore_docstrings=False,\n        ignore_imports=False,\n        ignore_signatures=False,\n    )\n    hash_to_index, index_to_lines = hash_lineset(lineset, min_common_lines=4)\n    assert len(hash_to_index) == 9\n    assert len(index_to_lines) == 9\n    assert hash_to_index[LinesChunk(\"test\", 0, \"import one\", \"from two import two\", \"three\", \"four\")] == [\n        0\n    ]\n    assert index_to_lines[0] == SuccessiveLinesLimits(0, 4)\n"], "sample_921": ["def test_isdescriptor_with_custom_descriptor():\n    class CustomDescriptor:\n            pass\n\n            pass\n\n    class TestClass:\n        attr = CustomDescriptor()\n\n    assert inspect.isdescriptor(TestClass.attr) is True\n    assert inspect.isdescriptor(TestClass().attr) is True\n"], "sample_168": ["def test_no_deletion_without_confirmation(self):\n    \"\"\"\n    interactive mode doesn't delete stale content types without confirmation.\n    \"\"\"\n    with mock.patch('builtins.input', return_value='no'):\n        with captured_stdout() as stdout:\n            call_command('remove_stale_contenttypes', verbosity=2)\n    self.assertIn(\"Stale content types remain.\", stdout.getvalue())\n    self.assertEqual(ContentType.objects.count(), self.before_count + 1)\n"], "sample_886": ["def test__wrap_data_with_container():\n    \"\"\"Check _wrap_data_with_container works as expected.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    est = EstimatorWithSetOutput().fit(X)\n\n    # If output config is \"default\", return data_to_wrap unchanged\n    est.set_output(transform=\"default\")\n    X_trans = est.transform(X)\n    assert isinstance(X_trans, np.ndarray)\n\n    # If output config is \"pandas\", return data_to_wrap as a pandas DataFrame\n    est.set_output(transform=\"pandas\")\n    X_trans = est.transform(X)\n    assert isinstance(X_trans, pd.DataFrame)\n\n    # If estimator is not configured for wrapping, return data_to_wrap unchanged\n    est = EstimatorWithSetOutputNoAutoWrap().fit(X)\n    X_trans = est.transform(X)\n    assert isinstance(X_trans, np.ndarray)\n\n    # If data_to_wrap is a tuple, only wrap the first output\n    class EstimatorWithSetOutputTuple(_SetOutputMixin):\n            self.n_features_in_ = X.shape[1]\n            return self\n\n            return (X, X)\n\n            return np.asarray([f\"X{i}\" for i in range(self.n_features_in_)], dtype=object)\n\n    est = EstimatorWithSetOutputTuple().fit(X)\n    est.set_output(transform=\"pandas\")\n    X_trans = est.transform(X)\n    assert isinstance(X_trans[0], pd.DataFrame)\n    assert isinstance(X_trans[1], np.ndarray)\n"], "sample_149": ["    def test_builtin_permission_name_length(self):\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'a' * 250\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most 244 \"\n                \"characters for its builtin permission names to be at most 255 characters.\",\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'a' * 245\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n"], "sample_526": ["def test_MicrosecondLocator():\n    locator = mdates.MicrosecondLocator(interval=1)\n    locator.create_dummy_axis()\n    locator.axis.set_view_interval(mdates.date2num(datetime.datetime(2020, 1, 1)),\n                                   mdates.date2num(datetime.datetime(2020, 1, 1)))\n    ticks = locator()\n    assert len(ticks) == 1\n    assert ticks[0] == mdates.date2num(datetime.datetime(2020, 1, 1))\n\n    locator = mdates.MicrosecondLocator(interval=1000000)\n    locator.create_dummy_axis()\n    locator.axis.set_view_interval(mdates.date2num(datetime.datetime(2020, 1, 1)),\n                                   mdates.date2num(datetime.datetime(2020, 1, 1, 0, 0, 1)))\n    ticks = locator()\n    assert len(ticks) == 2\n    assert ticks[0] == mdates.date2num(datetime.datetime(2020, 1, 1))\n    assert ticks[1] == mdates.date2num(datetime.datetime(2020, 1, 1, 0, 0, 1))\n"], "sample_27": ["def test_fitsdiff_hdu_extver(tmp_path):\n    \"\"\"Make sure diff report reports HDU name and ver if same in files\"\"\"\n    path1 = tmp_path / \"test1.fits\"\n    path2 = tmp_path / \"test2.fits\"\n\n    hdulist = HDUList([PrimaryHDU(), ImageHDU(data=np.zeros(5), name=\"SCI\", ver=1)])\n    hdulist.writeto(path1)\n    hdulist[1].data[0] = 1\n    hdulist[1].ver = 2\n    hdulist.writeto(path2)\n\n    diff = FITSDiff(path1, path2)\n    assert \"Extension HDU 1 (SCI, 1):\" in diff.report()\n    assert \"Extension HDU 1 (SCI, 2):\" in diff.report()\n"], "sample_1190": ["def test_unit_system():\n    # Test UnitSystem class\n    us = UnitSystem((meter, second), name=\"CustomUnitSystem\")\n    assert us.name == \"CustomUnitSystem\"\n    assert us.dim == 2\n    assert us.is_consistent\n\n    # Test extend method\n    new_us = us.extend((kilogram,), name=\"NewUnitSystem\")\n    assert new_us.name == \"NewUnitSystem\"\n    assert new_us.dim == 3\n    assert new_us.is_consistent\n\n    # Test get_dimension_system method\n    assert us.get_dimension_system() is not None\n\n    # Test get_quantity_dimension method\n    assert us.get_quantity_dimension(meter) == length\n\n    # Test get_quantity_scale_factor method\n    assert us.get_quantity_scale_factor(meter) == 1\n\n    # Test get_unit_system method\n    assert UnitSystem.get_unit_system(\"SI\") is not None\n\n    # Test get_default_unit_system method\n    assert UnitSystem.get_default_unit_system() is not None\n\n    # Test derived_units property\n    assert us.derived_units == {}\n\n    # Test get_units_non_prefixed method\n    assert us.get_units_non_prefixed() == {meter, second}\n"], "sample_929": ["def test_pyclass_nesting(app):\n    text = (\".. py:class:: Class1\\n\"\n            \"\\n\"\n            \"   .. py:class:: Class2\\n\"\n            \"\\n\"\n            \"      .. py:method:: meth\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_name, \"Class1\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc,\n                                                  addnodes.index,\n                                                  desc)])]))\n    assert_node(doctree[1][1][0], addnodes.index,\n                entries=[('single', 'Class2 (class in Class1)', 'Class1.Class2', '', None)])\n    assert_node(doctree[1][1][1], ([desc_signature, ([desc_annotation, \"class \"],\n                                                     [desc_name, \"Class2\"])],\n                                   [desc_content, (addnodes.index,\n                                                   desc)]))\n    assert_node(doctree[1][1][1][1][0], addnodes.index,\n                entries=[('single', 'meth() (Class1.Class2 method)', 'Class1.Class2.meth', '', None)])\n    assert_node(doctree[1][1][1][1][1], ([desc_signature, ([desc_name, \"meth\"],\n                                                         [desc_parameterlist, ()])],\n                                        [desc_content, ()]))\n    assert 'Class1.Class2' in domain.objects\n    assert domain.objects['Class1.Class2'] == ('index', 'Class1.Class2', 'class')\n    assert 'Class1.Class2.meth' in domain.objects\n    assert domain.objects['Class1.Class2.meth'] == ('index', 'Class1.Class2.meth', 'method')\n"], "sample_1206": ["def test_issue_12345():\n    # Test that the `Float` class handles precision correctly when converting from a string.\n    assert Float('1.23456789012345678901234567890123456789', 50)._prec == 50\n    assert Float('1.23456789012345678901234567890123456789', '')._prec == 50\n    assert Float('1.23456789012345678901234567890123456789', 100)._prec == 100\n"], "sample_823": ["def test_check_pairwise_arrays_precomputed():\n    # Ensure that check_pairwise_arrays works correctly with precomputed\n    # distance matrices.\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((5, 5))\n    X_checked, _ = check_pairwise_arrays(X, None, precomputed=True)\n    assert_array_equal(X, X_checked)\n\n    X = rng.random_sample((5, 4))\n    assert_raises(ValueError, check_pairwise_arrays, X, None, precomputed=True)\n\n    X = rng.random_sample((5, 5))\n    X_checked, _ = check_pairwise_arrays(X, X, precomputed=True)\n    assert_array_equal(X, X_checked)\n\n    X = rng.random_sample((5, 4))\n    assert_raises(ValueError, check_pairwise_arrays, X, X, precomputed=True)\n"], "sample_265": ["def test_get_template_origin(self):\n    engine = DjangoTemplates({\n        'DIRS': [],\n        'APP_DIRS': True,\n        'NAME': 'django',\n        'OPTIONS': {},\n    })\n    template = engine.get_template('hello.html')\n    self.assertIsInstance(template.origin, str)\n    self.assertIn('template_backends', template.origin)\n"], "sample_349": ["def test_optgroups(self):\n    beatles = Band.objects.create(name='The Beatles', style='rock')\n    who = Band.objects.create(name='The Who', style='rock')\n    # With 'band', a ForeignKey.\n    form = AlbumForm(initial={'band': beatles.uuid})\n    widget = form['band'].field.widget\n    optgroups = widget.optgroups('band', beatles.uuid)\n    self.assertEqual(len(optgroups), 1)\n    self.assertEqual(len(optgroups[0][1]), 1)\n    self.assertEqual(optgroups[0][1][0]['value'], str(beatles.uuid))\n    self.assertEqual(optgroups[0][1][0]['label'], 'The Beatles')\n    self.assertTrue(optgroups[0][1][0]['selected'])\n    # With 'featuring', a ManyToManyField.\n    form = AlbumForm(initial={'featuring': [beatles.pk, who.pk]})\n    widget = form['featuring'].field.widget\n    optgroups = widget.optgroups('featuring', [beatles.pk, who.pk])\n    self.assertEqual(len(optgroups), 1)\n    self.assertEqual(len(optgroups[0][1]), 2)\n    self.assertEqual(optgroups[0][1][0]['value'], str(beatles.pk))\n    self.assertEqual(optgroups[0][1][0]['label'], 'The Beatles')\n    self.assertTrue(optgroups[0][1][0]['selected'])\n    self.assertEqual(optgroups[0][1][1]['value'], str(who.pk))\n    self.assertEqual(optgroups[0][1][1]['label'], 'The Who')\n    self.assertTrue(optgroups[0][1][1]['selected'])\n"], "sample_73": ["    def setUp(self):\n        storage.staticfiles_storage.hashed_files.clear()  # avoid cache interference\n        super().setUp()\n"], "sample_360": ["    def tearDown(self):\n        cache.clear()\n"], "sample_1167": ["def test_latex_tensor_indices():\n    from sympy.tensor.tensor import TensorIndexType, tensor_indices, TensorHead, tensor_heads\n    L = TensorIndexType(\"L\")\n    i, j, k, l = tensor_indices(\"i j k l\", L)\n    i0 = tensor_indices(\"i_0\", L)\n    A, B, C, D = tensor_heads(\"A B C D\", [L])\n    H = TensorHead(\"H\", [L, L])\n    K = TensorHead(\"K\", [L, L, L, L])\n\n    assert latex(i) == r\"{}^{i}\"\n    assert latex(-i) == r\"{}_{i}\"\n\n    expr = A(i)\n    assert latex(expr) == r\"A{}^{i}\"\n\n    expr = A(i0)\n    assert latex(expr) == r\"A{}^{i_{0}}\"\n\n    expr = A(-i)\n    assert latex(expr) == r\"A{}_{i}\"\n\n    expr = -3*A(i)\n    assert latex(expr) == r\"-3A{}^{i}\"\n\n    expr = K(i, j, -k, -i0)\n    assert latex(expr) == r\"K{}^{ij}{}_{ki_{0}}\"\n\n    expr = K(i, -j, -k, i0)\n    assert latex(expr) == r\"K{}^{i}{}_{jk}{}^{i_{0}}\"\n\n    expr = K(i, -j, k, -i0)\n    assert latex(expr) == r\"K{}^{i}{}_{j}{}^{k}{}_{i_{0}}\"\n\n    expr = H(i, -j)\n    assert latex(expr) == r\"H{}^{i}{}_{j}\"\n\n    expr = H(i, j)\n    assert latex(expr) == r\"H{}^{ij}\"\n\n    expr = H(-i, -j)\n    assert latex(expr) == r\"H{}_{ij}\"\n\n    expr = (1+x)*A(i)\n    assert latex(expr) == r\"\\left(x + 1\\right)A{}^{i}\"\n\n    expr = H(i, -i)\n    assert latex(expr) == r\"H{}^{L_{0}}{}_{L_{0}}\"\n\n    expr = H(i, -j)*A(j)*B(k)\n    assert latex(expr) == r\"H{}^{i}{}_{L_{0}}A{}^{L_{0}}"], "sample_421": ["    def test_combined_expression_with_decimal(self):\n        self.assertQuerysetEqual(\n            CaseTestModel.objects.annotate(\n                test=Case(\n                    When(integer=1, then=Decimal(\"1.1\")),\n                    When(integer=2, then=Decimal(\"2.2\")),\n                    default=Decimal(\"3.3\"),\n                )\n                + Decimal(\"0.1\"),\n            ).order_by(\"pk\"),\n            [\n                (1, Decimal(\"1.2\")),\n                (2, Decimal(\"2.3\")),\n                (3, Decimal(\"3.4\")),\n                (2, Decimal(\"2.3\")),\n                (3, Decimal(\"3.4\")),\n                (3, Decimal(\"3.4\")),\n                (4, Decimal(\"3.4\")),\n            ],\n            transform=attrgetter(\"integer\", \"test\"),\n        )\n"], "sample_846": ["def test_column_transformer_transformer_weights():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    X_res_first = np.array([0, 1, 2]).reshape(-1, 1)\n    X_res_second = np.array([2, 4, 6]).reshape(-1, 1)\n\n    # test with transformer_weights\n    transformer_weights = {'trans1': .1, 'trans2': 10}\n    both = ColumnTransformer([('trans1', Trans(), [0]),\n                              ('trans2', Trans(), [1])],\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * X_res_first,\n                     transformer_weights['trans2'] * X_res_second]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and remainder\n    transformer_weights = {'trans1': .1}\n    both = ColumnTransformer([('trans1', Trans(), [0])],\n                             remainder=Trans(),\n                             transformer_weights=transformer_weights)\n    res = np.hstack([transformer_weights['trans1'] * X_res_first,\n                     X_res_second])\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and passthrough\n    transformer_weights = {'trans1': .1}\n    both = ColumnTransformer([('trans1', Trans(), [0])],\n                             remainder='passthrough',\n                             transformer_weights=transformer_weights)\n    res = np.hstack([transformer_weights['trans1'] * X_res_first,\n                     X_res_second])\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and invalid transformer name\n    transformer_weights = {'trans1': .1, 'trans3': 10}\n    both = ColumnTransformer([('trans1', Trans(), [0]),\n                              ('trans2', Trans(), [1])],\n                             transformer_weights=transformer_weights)\n    with pytest.raises(ValueError, match=\""], "sample_276": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n        self.company = Company.objects.create(name=\"Django\")\n        self.person = Person.objects.create(first_name=\"Human\", last_name=\"User\", company=self.company)\n"], "sample_59": ["    def test_save_base_force_insert_force_update(self):\n        msg = \"Cannot force both insert and updating in model saving.\"\n        with self.assertRaisesMessage(ValueError, msg):\n            Article().save(force_insert=True, force_update=True)\n"], "sample_845": ["def test_vectorizer_stop_words_inconsistent_custom_tokenizer():\n    lstr = \"['and', 'll', 've']\"\n    message = ('Your stop_words may be inconsistent with your '\n               'preprocessing. Tokenizing the stop words generated '\n               'tokens %s not in stop_words.' % lstr)\n    for vec in [CountVectorizer(),\n                TfidfVectorizer(), HashingVectorizer()]:\n        vec.set_params(stop_words=[\"you've\", \"you\", \"you'll\", 'AND'],\n                       tokenizer=lambda doc: doc.split())\n        assert_warns_message(UserWarning, message, vec.fit_transform,\n                             ['hello world'])\n        # reset stop word validation\n        del vec._stop_words_id\n        assert _check_stop_words_consistency(vec) is False\n\n    # Only one warning per stop list\n    assert_no_warnings(vec.fit_transform, ['hello world'])\n    assert _check_stop_words_consistency(vec) is None\n\n    # Test caching of inconsistency assessment\n    vec.set_params(stop_words=[\"you've\", \"you\", \"you'll\", 'blah', 'AND'])\n    assert_warns_message(UserWarning, message, vec.fit_transform,\n                         ['hello world'])\n    assert _check_stop_words_consistency(vec) is None\n"], "sample_1043": ["def test_user_functions():\n    assert mcode(sin(x), user_functions={'sin': 'MySin'}) == \"MySin[x]\"\n    assert mcode(sin(x), user_functions={'sin': ['MySin', 'MyOtherSin']}) == \"MySin[x]\"\n    assert mcode(sin(x), user_functions={'sin': [(lambda x: x.is_real, 'MyRealSin'), \n                                                 (lambda x: True, 'MySin')]}) == \"MyRealSin[x]\"\n    assert mcode(sin(x + I), user_functions={'sin': [(lambda x: x.is_real, 'MyRealSin'), \n                                                    (lambda x: True, 'MySin')]}) == \"MySin[x + I]\"\n"], "sample_524": ["def test_colorbar_set_ticks():\n    # test fix for #20054\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc)\n    cb.set_ticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n    assert len(cb.ax.yaxis.get_ticklocs()) == 10\n"], "sample_238": ["def test_trigonometric_functions(self):\n    # Test the trigonometric functions\n    book = Book.objects.annotate(\n        sin_rating=Sin('rating'),\n        cos_rating=Cos('rating'),\n        tan_rating=Tan('rating'),\n        asin_rating=ASin('rating'),\n        acos_rating=ACos('rating'),\n        atan_rating=ATan('rating'),\n        atan2_rating=ATan2('rating', 'pages'),\n    ).get(pk=self.b1.pk)\n\n    self.assertAlmostEqual(book.sin_rating, math.sin(book.rating))\n    self.assertAlmostEqual(book.cos_rating, math.cos(book.rating))\n    self.assertAlmostEqual(book.tan_rating, math.tan(book.rating))\n    self.assertAlmostEqual(book.asin_rating, math.asin(book.rating))\n    self.assertAlmostEqual(book.acos_rating, math.acos(book.rating))\n    self.assertAlmostEqual(book.atan_rating, math.atan(book.rating))\n    self.assertAlmostEqual(book.atan2_rating, math.atan2(book.rating, book.pages))\n\n    # Test the trigonometric functions with annotations\n    books = Book.objects.annotate(\n        sin_rating=Sin('rating'),\n        cos_rating=Cos('rating'),\n        tan_rating=Tan('rating'),\n        asin_rating=ASin('rating'),\n        acos_rating=ACos('rating'),\n        atan_rating=ATan('rating'),\n        atan2_rating=ATan2('rating', 'pages'),\n    ).values('sin_rating', 'cos_rating', 'tan_rating', 'asin_rating', 'acos_rating', 'atan_rating', 'atan2_rating')\n\n    for book in books:\n        self.assertAlmostEqual(book['sin_rating'], math.sin(book['rating']))\n        self.assertAlmostEqual(book['cos_rating'], math.cos(book['rating']))\n        self.assertAlmostEqual(book['tan_rating'], math.tan(book['rating']))\n        self.assertAlmostEqual(book['asin_rating'], math.asin(book['rating']))\n        self.assertAlmostEqual(book['acos_rating'], math.acos(book['rating']))\n        self.assertAlmostEqual(book['atan_rating'], math.atan(book['rating']))\n        self.assertAlmostEqual(book['atan2_rating'], math.atan2(book['rating'], book['pages']))\n"], "sample_16": ["    def setup_method(self):\n        self.q = np.arange(9.0).reshape(3, 3) * u.m\n"], "sample_564": ["def test_set_zlim_with_zmin_zmax(fig_test, fig_ref):\n    ax_test = fig_test.add_subplot(projection='3d')\n    ax_test.set_zlim(zmin=1, zmax=2)\n    ax_ref = fig_ref.add_subplot(projection='3d')\n    ax_ref.set_zlim(1, 2)\n"], "sample_95": ["    def test_patch_cache_control(self):\n        response = HttpResponse()\n        patch_cache_control(response, max_age=3600, public=True)\n        self.assertEqual(response['Cache-Control'], 'max-age=3600, public')\n"], "sample_1145": ["def test_refine_with_nested_abs():\n    assert refine(Abs(Abs(x)), Q.real(x)) == Abs(x)\n    assert refine(Abs(Abs(x)), Q.positive(x)) == x\n    assert refine(Abs(Abs(x)), Q.negative(x)) == -x\n    assert refine(Abs(Abs(x*y)), Q.real(x) & Q.real(y)) == Abs(x*y)\n    assert refine(Abs(Abs(x*y)), Q.positive(x) & Q.positive(y)) == x*y\n    assert refine(Abs(Abs(x*y)), Q.negative(x) & Q.negative(y)) == x*y\n    assert refine(Abs(Abs(x*y)), Q.positive(x) & Q.negative(y)) == -x*y\n    assert refine(Abs(Abs(x*y)), Q.negative(x) & Q.positive(y)) == -x*y\n"], "sample_325": ["def test_boundfield_subwidget_id_for_label_with_custom_id(self):\n    \"\"\"\n    If a widget has a custom id, the generated ID in subwidgets must reflect that\n    prefix.\n    \"\"\"\n    class SomeForm(Form):\n        field = MultipleChoiceField(\n            choices=[('a', 'A'), ('b', 'B')],\n            widget=CheckboxSelectMultiple(attrs={'id': 'myCustomID'}),\n        )\n\n    form = SomeForm(auto_id='prefix_%s')\n    subwidgets = form['field'].subwidgets\n    self.assertEqual(subwidgets[0].id_for_label, 'myCustomID_0')\n    self.assertEqual(subwidgets[1].id_for_label, 'myCustomID_1')\n"], "sample_944": ["def test_get_type_hints():\n        pass\n\n    assert get_type_hints(func) == {'a': int, 'b': str, 'return': None}\n\n    class MyClass:\n            pass\n\n    assert get_type_hints(MyClass.__init__) == {'a': int, 'b': str, 'return': None}\n\n    class BrokenClass:\n            raise Exception\n\n    assert get_type_hints(BrokenClass.__init__) == {}\n\n    assert get_type_hints(None) == {}\n"], "sample_271": ["    def test_request_processed_calls_update_watches(self, mocked_update_watches):\n        reloader = autoreload.WatchmanReloader()\n        reloader.request_processed()\n        self.assertEqual(mocked_update_watches.call_count, 1)\n"], "sample_414": ["    def test_get_inline_instances(self):\n        class MyInline(admin.StackedInline):\n            model = Member\n\n        class BandAdmin(admin.ModelAdmin):\n            inlines = [MyInline]\n\n        band_admin = BandAdmin(Band, admin.site)\n        inline_instances = band_admin.get_inline_instances(self.client, Band())\n        self.assertEqual(len(inline_instances), 1)\n        self.assertIsInstance(inline_instances[0], MyInline)\n"], "sample_581": ["def test_blueprint_setup_state(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n        assert state.app == app\n        assert state.blueprint == bp\n        assert state.options == {}\n        assert state.first_registration == True\n        assert state.subdomain is None\n        assert state.url_prefix is None\n        assert state.name == \"bp\"\n        assert state.name_prefix == \"\"\n\n    bp.record(setup_state)\n    app.register_blueprint(bp)\n"], "sample_571": ["def test_lmplot_x_estimator(self):\n\n    g = lm.lmplot(x=\"x\", y=\"y\", data=self.df, x_estimator=np.mean)\n    ax = g.axes[0, 0]\n\n    assert len(ax.lines) == 1\n    assert len(ax.collections) == 2\n\n    x, y = ax.collections[0].get_offsets().T\n    npt.assert_array_equal(x, np.sort(np.unique(self.df.x)))\n    npt.assert_array_almost_equal(y, self.df.groupby(\"x\").y.mean())\n"], "sample_347": ["def test_localtime(self):\n    naive = datetime.datetime(2015, 1, 1, 0, 0, 1)\n    with self.assertRaisesMessage(ValueError, 'localtime() cannot be applied to a naive datetime'):\n        timezone.localtime(naive)\n    with self.assertRaisesMessage(ValueError, 'localtime() cannot be applied to a naive datetime'):\n        timezone.localtime(naive, timezone=EAT)\n\n    aware = datetime.datetime(2015, 1, 1, 0, 0, 1, tzinfo=ICT)\n    self.assertEqual(timezone.localtime(aware, timezone=EAT), datetime.datetime(2014, 12, 31, 17, 0, 1))\n    with timezone.override(EAT):\n        self.assertEqual(timezone.localtime(aware), datetime.datetime(2014, 12, 31, 17, 0, 1))\n\n    with mock.patch('django.utils.timezone.now', return_value=aware):\n        self.assertEqual(timezone.localtime(timezone=EAT), datetime.datetime(2014, 12, 31, 17, 0, 1))\n        with timezone.override(EAT):\n            self.assertEqual(timezone.localtime(), datetime.datetime(2014, 12, 31, 17, 0, 1))\n"], "sample_4": ["def test_read_html_table_move_to_meta(self, cosmo, read, write, tmp_path, add_cu):\n    \"\"\"Test moving extra arguments to meta when reading from HTML table.\"\"\"\n    fp = tmp_path / \"test_read_html_table_move_to_meta.html\"\n\n    # test write\n    write(fp, format=\"ascii.html\")\n\n    # add extra argument\n    tbl = QTable.read(fp)\n    tbl[\"extra_arg\"] = \"will be moved to meta\"\n    tbl.write(fp, format=\"ascii.html\", overwrite=True)\n\n    # read with move_to_meta=False (default)\n    with pytest.raises(TypeError, match=\"there are unused parameters\"):\n        read(fp, format=\"ascii.html\")\n\n    # read with move_to_meta=True\n    got = read(fp, format=\"ascii.html\", move_to_meta=True)\n    assert got == cosmo\n    # assert \"extra_arg\" in got.meta # metadata read not implemented\n    # assert got.meta[\"extra_arg\"] == \"will be moved to meta\" # metadata read not implemented\n"], "sample_1200": ["def test_unit_system_extension():\n    new_system = SI.extend((Quantity(\"new_unit\"),), name=\"New System\")\n    assert new_system.name == \"New System\"\n    assert new_system.dim == 8\n    assert new_system.is_consistent\n\n    new_system = SI.extend((Quantity(\"new_unit\"),), name=\"\")\n    assert new_system.name == \"UnitSystem((meter, kilogram, second, ampere, kelvin, mole, candela, new_unit))\"\n    assert new_system.dim == 8\n    assert new_system.is_consistent\n\n    new_system = SI.extend((Quantity(\"new_unit\"),), dimension_system=None)\n    assert new_system.get_dimension_system() is None\n\n    new_system = SI.extend((Quantity(\"new_unit\"),), derived_units={Dimension(length/time): Quantity(\"new_derived_unit\")})\n    assert new_system.derived_units == {Dimension(length/time): Quantity(\"new_derived_unit\")}\n"], "sample_332": ["def test_formset_absolute_max_with_min_num(self):\n    data = {\n        'form-TOTAL_FORMS': '1001',\n        'form-INITIAL_FORMS': '0',\n        'form-MIN_NUM_FORMS': '0',\n        'form-MAX_NUM_FORMS': '0',\n    }\n    LimitedFavoriteDrinksFormSet = formset_factory(\n        FavoriteDrinkForm,\n        min_num=30,\n        absolute_max=1000,\n    )\n    formset = LimitedFavoriteDrinksFormSet(data=data)\n    self.assertIs(formset.is_valid(), False)\n    self.assertEqual(len(formset.forms), 1000)\n    self.assertEqual(\n        formset.non_form_errors(),\n        ['Please submit at least 30 forms.'],\n    )\n"], "sample_759": ["def test_ordinal_encoder_handle_unknown():\n    X = np.array([['a', 2, 55], ['b', 1, 55], ['a', 3, 55]])\n    X2 = np.array([['d', 1, 55]])\n\n    # Test that ordinal encoder raises error for unknown features\n    # present during transform.\n    oe = OrdinalEncoder(handle_unknown='error')\n    oe.fit(X)\n    assert_raises(ValueError, oe.transform, X2)\n\n    # Test the ignore option, ignores unknown features (giving NaN)\n    oe = OrdinalEncoder(handle_unknown='ignore')\n    oe.fit(X)\n    X2_passed = X2.copy()\n    assert_array_equal(\n        oe.transform(X2_passed),\n        np.array([[np.nan, 0., 0.]]))\n    # ensure transformed data was not modified in place\n    assert_array_equal(X2, X2_passed)\n\n    # Raise error if handle_unknown is neither ignore or error.\n    oe = OrdinalEncoder(handle_unknown='42')\n    assert_raises(ValueError, oe.fit, X)\n"], "sample_333": ["def test_order_fields_with_empty_list(self):\n    class TestForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n        field3 = CharField()\n        field_order = []\n\n    p = TestForm()\n    self.assertEqual(list(p.fields), ['field1', 'field2', 'field3'])\n"], "sample_344": ["def test_get_related_models_recursive_with_self_referential_m2m(self):\n    \"\"\"\n    #24573 - Adding relations to existing models should reload the\n    referenced models too.\n    \"\"\"\n    new_apps = Apps()\n\n    class A(models.Model):\n        to_a = models.ManyToManyField('A')\n\n        class Meta:\n            app_label = 'something'\n            apps = new_apps\n\n    project_state = ProjectState()\n    project_state.add_model(ModelState.from_model(A))\n    self.assertEqual(\n        get_related_models_recursive(project_state.apps.get_model('something', 'A')),\n        {('something', 'a'), ('something', 'a_to_a')}\n    )\n"], "sample_1122": ["def test_polar_lift():\n    x = Symbol('x')\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == exp_polar(0)\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(-I*pi/2)\n    assert polar_lift(-I) == exp_polar(I*pi/2)\n    assert polar_lift(1 + I) == polar_lift(1 + I)\n    assert polar_lift(x) == polar_lift(x)\n    assert polar_lift(x*I) == I*polar_lift(x)\n    assert polar_lift(x**2) == polar_lift(x)**2\n    assert polar_lift(x**3) == polar_lift(x)**3\n    assert polar_lift(x**4) == x**4\n    assert polar_lift(x**5) == polar_lift(x)**5\n    assert polar_lift(x**6) == x**6\n    assert polar_lift(x**7) == polar_lift(x)**7\n    assert polar_lift(x**8) == x**8\n    assert polar_lift(x**9) == polar_lift(x)**9\n    assert polar_lift(x**10) == x**10\n    assert polar_lift(x**11) == polar_lift(x)**11\n    assert polar_lift(x**12) == x**12\n    assert polar_lift(x**13) == polar_lift(x)**13\n    assert polar_lift(x**14) == x**14\n    assert polar_lift(x**15) == polar_lift(x)**15\n    assert polar_lift(x**16) == x**16\n    assert polar_lift(x**17) == polar_lift(x)**17\n    assert polar_lift(x**18) == x**18\n    assert polar_lift(x**19) == polar_lift(x)**19\n    assert polar_lift(x**20) == x**20\n    assert polar_lift(x**21) == polar_lift(x)**21\n    assert polar_lift(x**22) == x**22\n    assert polar_lift(x**23) == polar_lift(x)**23\n    assert polar_lift(x**24) == x**24\n    assert polar_lift(x**25) == polar_lift(x)**25\n    assert polar_lift(x**26) == x**26\n    assert polar_lift(x**27) == polar_lift(x)**27\n    assert polar_lift(x**28) == x**28\n    assert polar_lift"], "sample_561": ["def test_marker_fillstyle_half():\n    marker_style = markers.MarkerStyle(marker='o', fillstyle='left')\n    assert marker_style.get_fillstyle() == 'left'\n    assert marker_style.is_filled()\n\n    marker_style = markers.MarkerStyle(marker='o', fillstyle='right')\n    assert marker_style.get_fillstyle() == 'right'\n    assert marker_style.is_filled()\n\n    marker_style = markers.MarkerStyle(marker='o', fillstyle='top')\n    assert marker_style.get_fillstyle() == 'top'\n    assert marker_style.is_filled()\n\n    marker_style = markers.MarkerStyle(marker='o', fillstyle='bottom')\n    assert marker_style.get_fillstyle() == 'bottom'\n    assert marker_style.is_filled()\n"], "sample_1010": ["def test_latex_DiagramGrid():\n    from sympy.categories import Object, NamedMorphism, Diagram, DiagramGrid\n    A = Object(\"A\")\n    B = Object(\"B\")\n    C = Object(\"C\")\n    f = NamedMorphism(A, B, \"f\")\n    g = NamedMorphism(B, C, \"g\")\n    d = Diagram([f, g])\n    grid = DiagramGrid(d)\n    assert latex(grid) == \"\\\\begin{array}{cc}\\nA & B \\\\\\\\\\n & C \\n\\\\end{array}\\n\"\n"], "sample_562": ["def test_line2d_update_from():\n    fig, ax = plt.subplots()\n    line1 = mlines.Line2D([1, 2, 3], [1, 2, 3], color='r', linestyle='--')\n    line2 = mlines.Line2D([1, 2, 3], [1, 2, 3], color='b', linestyle='-')\n    ax.add_line(line1)\n    line1.update_from(line2)\n    assert line1.get_color() == 'b'\n    assert line1.get_linestyle() == '-'\n"], "sample_1096": ["def test_IndexedBase_strides():\n    i, j, k = symbols('i j k', integer=True)\n    l, m, n, o = symbols('l m n o', integer=True)\n    A = IndexedBase('A', strides=(l, m, n), offset=o)\n    assert A.strides == (l, m, n)\n    assert A.offset == o\n    assert A[i, j, k].strides == (l, m, n)\n    assert A[i, j, k].offset == o\n    assert A[i, j, k].base.strides == (l, m, n)\n    assert A[i, j, k].base.offset == o\n"], "sample_607": ["def test_get_backend():\n    backend = plugins.get_backend(\"dummy\")\n    assert isinstance(backend, DummyBackendEntrypointArgs)\n\n    backend = plugins.get_backend(DummyBackendEntrypointArgs)\n    assert isinstance(backend, DummyBackendEntrypointArgs)\n\n    with pytest.raises(ValueError):\n        plugins.get_backend(\"non-existent-backend\")\n\n    with pytest.raises(TypeError):\n        plugins.get_backend(123)\n"], "sample_1112": ["def test_is_palindromic_edge_cases():\n    assert is_palindromic(0)\n    assert is_palindromic(1)\n    assert is_palindromic(-1)\n    assert not is_palindromic(10)\n    assert not is_palindromic(-10)\n    assert is_palindromic(121, 10)\n    assert is_palindromic(0o121, 8)\n    assert not is_palindromic(88, 8)\n    assert is_palindromic(88, 10)\n    raises(ValueError, lambda: is_palindromic(88, 1))\n"], "sample_592": ["def test_inline_variable_array_repr(self):\n    # test in-memory array\n    var = xr.Variable((\"x\", \"y\"), np.arange(100).reshape(10, 10))\n    actual = formatting.inline_variable_array_repr(var, 80)\n    expected = formatting.format_array_flat(var, 80)\n    assert actual == expected\n\n    # test dask array\n    import dask.array as da\n    var = xr.Variable((\"x\", \"y\"), da.from_array(np.arange(100).reshape(10, 10), chunks=(5, 5)))\n    actual = formatting.inline_variable_array_repr(var, 80)\n    expected = formatting.inline_dask_repr(var.data)\n    assert actual == expected\n\n    # test sparse array\n    import sparse\n    var = xr.Variable((\"x\", \"y\"), sparse.COO(np.arange(100).reshape(10, 10)))\n    actual = formatting.inline_variable_array_repr(var, 80)\n    expected = formatting.inline_sparse_repr(var.data)\n    assert actual == expected\n\n    # test internal xarray array type (out-of-memory)\n    var = xr.Variable((\"x\", \"y\"), np.arange(1000000).reshape(1000, 1000))\n    actual = formatting.inline_variable_array_repr(var, 80)\n    expected = \"[1000000 values with dtype=int64]\"\n    assert actual == expected\n"], "sample_1121": ["def test_Mul_is_finite():\n    x = Symbol('x', real=True)\n    y = Symbol('y', real=True, positive=True)\n\n    assert (x*y).is_finite is None\n    assert (x*y).is_finite is None\n\n    assert (x**2).is_finite is None\n    assert (y**2).is_finite is True\n\n    assert (x**Rational(1, 3)).is_finite is None\n    assert (y**Rational(1, 3)).is_finite is True\n\n    assert sqrt(-1 - sqrt(2)).is_finite is False\n\n    i = Symbol('i', imaginary=True)\n    assert (i**i).is_finite is None\n    assert (I**i).is_finite is True\n    assert ((-I)**i).is_finite is True\n    assert (2**i).is_finite is None  # (2**(pi/log(2) * I)) is real, 2**I is not\n    assert (2**I).is_finite is False\n    assert (2**-I).is_finite is False\n    assert (i**2).is_finite is True\n    assert (i**3).is_finite is False\n    assert (i**x).is_finite is None  # could be (-I)**(2/3)\n    e = Symbol('e', even=True)\n    o = Symbol('o', odd=True)\n    k = Symbol('k', integer=True)\n    assert (i**e).is_finite is True\n    assert (i**o).is_finite is False\n    assert (i**k).is_finite is None\n    assert (i**(4*k)).is_finite is True\n\n    x = Symbol(\"x\", nonnegative=True)\n    y = Symbol(\"y\", nonnegative=True)\n    assert im(x**y).expand(complex=True) is S.Zero\n    assert (x**y).is_finite is True\n    i = Symbol('i', imaginary=True)\n    assert (exp(i)**I).is_finite is True\n    assert log(exp(i)).is_imaginary is None  # i could be 2*pi*I\n    c = Symbol('c', complex=True)\n    assert log(c).is_real is None  # c could be 0 or 2, too\n   "], "sample_97": ["    def test_empty_input(self):\n        self.assertEqual(autoreload.common_roots(()), ())\n"], "sample_72": ["def test_serialize_function_type(self):\n        pass\n\n    self.assertSerializedResultEqual(\n        test_function,\n        ('migrations.test_writer.test_function', {'import migrations.test_writer'})\n    )\n\n    class TestClass:\n            pass\n\n    self.assertSerializedResultEqual(\n        TestClass().test_method,\n        ('migrations.test_writer.TestClass().test_method', {'import migrations.test_writer'})\n    )\n\n    class TestClass2:\n        @staticmethod\n            pass\n\n    self.assertSerializedResultEqual(\n        TestClass2.test_static_method,\n        ('migrations.test_writer.TestClass2.test_static_method', {'import migrations.test_writer'})\n    )\n\n    class TestClass3:\n        @classmethod\n            pass\n\n    self.assertSerializedResultEqual(\n        TestClass3.test_class_method,\n        ('migrations.test_writer.TestClass3.test_class_method', {'import migrations.test_writer'})\n    )\n"], "sample_574": ["    def test_label_concise_with_locator(self, t, x):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator).label(concise=True)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        formatter = a.major.formatter\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n        assert formatter.locs is a.major.locator\n"], "sample_617": ["def test_cross_with_missing_values() -> None:\n    a = xr.DataArray(\n        np.array([1, 2, 3]),\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    b = xr.DataArray(\n        np.array([4, np.nan, 6]),\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n\n    expected = np.array([np.nan, np.nan, np.nan])\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(expected, actual)\n"], "sample_157": ["    def test_create_test_db(self, mocked_create_test_db):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            creation.create_test_db(verbosity=1, autoclobber=True, serialize=True, keepdb=False)\n            mocked_create_test_db.assert_called_once()\n            self.assertEqual(test_connection.settings_dict['NAME'], creation._get_test_db_name())\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_56": ["def test_check_ordering_random_with_other_fields(self):\n    class SongAdmin(admin.ModelAdmin):\n        ordering = ['?', 'title']\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'ordering' has the random ordering marker '?', \"\n            \"but contains other fields as well.\",\n            obj=SongAdmin,\n            id='admin.E032',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_677": ["def test_matcher_function(expr: str, matcher: Callable[[str], bool], expected: bool) -> None:\n    assert evaluate(expr, matcher) is expected\n"], "sample_71": ["def test_edge_cases(self):\n    # Test with very large decimal positions\n    self.assertEqual(nformat(1234, '.', decimal_pos=100), '1234.00')\n    self.assertEqual(nformat(1234.5678, '.', decimal_pos=100), '1234.567800000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_833": ["def test_logistic_regression_path_multiclass():\n    # Test that logistic_regression_path works with multiclass problems\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=10,\n                               n_classes=3, random_state=0)\n    Cs = [1.0]\n    for solver in ['lbfgs', 'newton-cg', 'sag', 'saga']:\n        coefs, _, _ = _logistic_regression_path(X, y, Cs=Cs, solver=solver,\n                                                multi_class='multinomial',\n                                                random_state=0)\n        assert coefs.shape == (1, 3, 20)\n"], "sample_753": ["def test_logistic_regression_path_multiclass():\n    # Test logistic_regression_path for multiclass problems\n    X, y = make_classification(n_samples=100, n_features=20, n_informative=10,\n                               n_classes=3, random_state=0)\n    Cs = [1.0]\n    solvers = ['lbfgs', 'newton-cg', 'sag', 'saga']\n    for solver in solvers:\n        coefs, Cs, n_iter = logistic_regression_path(\n            X, y, Cs=Cs, fit_intercept=False, tol=1e-6, solver=solver,\n            multi_class='multinomial', random_state=42, max_iter=2000)\n        assert_array_equal(coefs[0].shape, (3, 20))\n        assert_equal(len(Cs), 1)\n        assert_equal(len(n_iter), 1)\n"], "sample_664": ["def test_deprecation_warnings(warning, expected_message):\n    with pytest.warns(pytest.PytestDeprecationWarning, match=expected_message):\n        warnings.warn(warning)\n"], "sample_968": ["def test_python_domain_clear_doc(app):\n    text = (\".. py:module:: example\\n\"\n            \".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:method:: meth\\n\")\n    restructuredtext.parse(app, text)\n    domain = app.env.get_domain('py')\n    assert 'example' in domain.modules\n    assert 'example.Class' in domain.objects\n    assert 'example.Class.meth' in domain.objects\n\n    domain.clear_doc('index')\n    assert 'example' not in domain.modules\n    assert 'example.Class' not in domain.objects\n    assert 'example.Class.meth' not in domain.objects\n"], "sample_326": ["def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            'Search for google.com/?q=! and see.',\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>! and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt! and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>! and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt, and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>, and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt. and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>. and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt; and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>; and see.'\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_746": ["def test_log_loss_multiclass():\n    # multiclass case; adapted from http://bit.ly/RJJHWA\n    y_true = [1, 0, 2]\n    y_pred = [[0.2, 0.7, 0.1], [0.6, 0.2, 0.2], [0.6, 0.1, 0.3]]\n    loss = log_loss(y_true, y_pred, normalize=True)\n    assert_almost_equal(loss, 0.6904911)\n\n    # check that we got all the shapes and axes right\n    # by doubling the length of y_true and y_pred\n    y_true *= 2\n    y_pred *= 2\n    loss = log_loss(y_true, y_pred, normalize=False)\n    assert_almost_equal(loss, 0.6904911 * 6, decimal=6)\n\n    # check eps and handling of absolute zero and one probabilities\n    y_pred = np.asarray(y_pred) > .5\n    loss = log_loss(y_true, y_pred, normalize=True, eps=.1)\n    assert_almost_equal(loss, log_loss(y_true, np.clip(y_pred, .1, .9)))\n\n    # raise error if number of classes are not equal.\n    y_true = [1, 0, 2]\n    y_pred = [[0.2, 0.7], [0.6, 0.5], [0.4, 0.1]]\n    assert_raises(ValueError, log_loss, y_true, y_pred)\n\n    # case when y_true is a string array object\n    y_true = [\"ham\", \"spam\", \"spam\", \"ham\"]\n    y_pred = [[0.2, 0.7], [0.6, 0.5], [0.4, 0.1], [0.7, 0.2]]\n    loss = log_loss(y_true, y_pred)\n    assert_almost_equal(loss, 1.0383217, decimal=6)\n\n    # test labels option\n\n    y_true = [2, 2]\n    y_pred = [[0.2, 0.7], [0.6, 0.5]]\n    y_score = np.array([[0.1, 0.9], [0.1, 0.9]])\n    error_str = ('y_true contains only one label (2). Please provide '\n"], "sample_104": ["    def setUp(self):\n        super().setUp()\n        self._temp_dir = temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, 'test'))\n        self.addCleanup(shutil.rmtree, temp_dir)\n"], "sample_91": ["def test_permission_denied_with_exception(self):\n    \"\"\"\n    The permission_denied view should include the exception message in the response\n    \"\"\"\n    request = self.request_factory.get('/')\n    exception = Exception('Test permission denied exception')\n    response = permission_denied(request, exception)\n    self.assertContains(response, b'403 Forbidden', status_code=403)\n    self.assertContains(response, str(exception).encode('utf-8'), status_code=403)\n"], "sample_77": ["def test_avoid_wrapping(self):\n    tests = (\n        ('Hello world', 'Hello\\xA0world'),\n        ('Hello   world', 'Hello\\xA0\\xA0\\xA0world'),\n        ('Hello, world!', 'Hello,\\xA0world!'),\n        ('Hello,   world!', 'Hello,\\xA0\\xA0\\xA0world!'),\n    )\n    for value, output in tests:\n        with self.subTest(value=value, output=output):\n            self.assertEqual(avoid_wrapping(value), output)\n            self.assertEqual(avoid_wrapping(lazystr(value)), output)\n"], "sample_477": ["def get_digit(value, arg):\n    \"\"\"\n    Given a whole number, return the requested digit of it, where 1 is the\n    right-most digit, 2 is the second-right-most digit, etc. Return the\n    original value for invalid input (if input or argument is not an integer,\n    or if argument is less than 1). Otherwise, output is always an integer.\n    \"\"\"\n    try:\n        arg = int(arg)\n        value = int(value)\n    except ValueError:\n        return value  # Fail silently for an invalid argument\n    if arg < 1:\n        return value\n    try:\n        return int(str(value)[-arg])\n    except IndexError:\n        return 0\n\n"], "sample_301": ["    def test_empty_paths(self):\n        self.assertEqual(autoreload.common_roots(()), ())\n"], "sample_669": ["def test_capturing_and_logging_fundamentals_with_keyboardinterrupt(testdir):\n    # here we check a fundamental feature\n    p = testdir.makepyfile(\n        \"\"\"\n        import sys, os\n        import py, logging\n        from _pytest import capture\n        cap = capture.MultiCapture(out=False, in_=False,\n                                     Capture=capture.SysCapture)\n        cap.start_capturing()\n\n        logging.warning(\"hello1\")\n        outerr = cap.readouterr()\n        print(\"suspend, captured %%s\" %%(outerr,))\n        logging.warning(\"hello2\")\n\n        cap.pop_outerr_to_orig()\n        logging.warning(\"hello3\")\n\n        outerr = cap.readouterr()\n        print(\"suspend2, captured %%s\" %% (outerr,))\n        raise KeyboardInterrupt()\n    \"\"\"\n    )\n    result = testdir.runpython(p)\n    result.stdout.fnmatch_lines(\n        \"\"\"\n        suspend, captured*hello1*\n        suspend2, captured*WARNING:root:hello3*\n    \"\"\"\n    )\n    result.stderr.fnmatch_lines(\n        \"\"\"\n        WARNING:root:hello2\n    \"\"\"\n    )\n    assert \"atexit\" not in result.stderr.str()\n"], "sample_991": ["def test_doit_with_hints():\n    # Test doit with hints\n    assert Product(x**k, (k, 1, n)).doit(deep=False) == Product(x**k, (k, 1, n))\n    assert Product(x**k, (k, 1, n)).doit(deep=True) == x**(n*(n + 1)/2)\n"], "sample_1198": ["def test_parser_mathematica_function():\n    parser = MathematicaParser()\n\n    # Test Function with one argument\n    assert parser.parse(\"Function[x, x^3]\") == sympy.Lambda(x, x**3)\n\n    # Test Function with multiple arguments\n    assert parser.parse(\"Function[{x, y}, x^2 + y^2]\") == sympy.Lambda((x, y), x**2 + y**2)\n\n    # Test Function with no arguments\n    assert parser.parse(\"Function[{}, x^3]\") == sympy.Lambda((), x**3)\n\n    # Test Function with Slot\n    assert parser.parse(\"Function[#, #^2]\") == sympy.Lambda(sympy.Symbol(\"Slot(1)\"), sympy.Symbol(\"Slot(1)\")**2)\n\n    # Test Function with SlotSequence\n    assert parser.parse(\"Function[##, {##}]\") == sympy.Lambda(sympy.Symbol(\"SlotSequence(1)\"), (sympy.Symbol(\"SlotSequence(1)\"),))\n\n    # Test Function with Pattern\n    assert parser.parse(\"Function[x_, x_^2]\") == sympy.Lambda(sympy.Symbol(\"x_\"), sympy.Symbol(\"x_\")**2)\n\n    # Test Function with Optional Pattern\n    assert parser.parse(\"Function[x_. , x_^2]\") == sympy.Lambda(sympy.Symbol(\"x_\"), sympy.Symbol(\"x_\")**2)\n\n    # Test Function with Blank\n    assert parser.parse(\"Function[_, _^2]\") == sympy.Lambda(sympy.Symbol(\"_\"), sympy.Symbol(\"_\")**2)\n\n    # Test Function with BlankSequence\n    assert parser.parse(\"Function[__, {##}]\") == sympy.Lambda(sympy.Symbol(\"BlankSequence\"), (sympy.Symbol(\"SlotSequence(1)\"),))\n\n    # Test Function with BlankNullSequence\n    assert parser.parse(\"Function[___, {##}]\") == sympy.Lambda(sympy.Symbol(\"BlankNullSequence\"), (sympy.Symbol(\"SlotSequence(1)\"),))\n"], "sample_51": ["    def test_parse_date_empty_string(self):\n        self.assertIsNone(parse_date(''))\n"], "sample_449": ["    def test_close_connections(self):\n        \"\"\"ThreadedWSGIServer closes database connections.\"\"\"\n        server = ThreadedWSGIServer((\"localhost\", 0), WSGIRequestHandler)\n        connections_override = {\"default\": \"connection\"}\n        server.connections_override = connections_override\n        server._close_connections()\n        self.assertNotIn(\"default\", connections)\n        server.server_close()\n"], "sample_355": ["    def setUpTestData(cls):\n        cls.permission = Permission.objects.create(name='test', codename='test', content_type=ContentType.objects.get_for_model(Group))\n"], "sample_963": ["def test_get_type_hints():\n        pass\n\n    assert get_type_hints(func) == {'a': int, 'b': str, 'return': None}\n\n    class MyClass:\n            pass\n\n    assert get_type_hints(MyClass) == {'a': int, 'b': str, 'return': None}\n\n    class MyClassWithNoTypeHints:\n            pass\n\n    assert get_type_hints(MyClassWithNoTypeHints) == {}\n\n    class MyClassWithBrokenTypeHints:\n            pass\n\n    assert get_type_hints(MyClassWithBrokenTypeHints) == {}\n\n    class MyClassWithForwardRef:\n            pass\n\n    assert get_type_hints(MyClassWithForwardRef) == {}\n\n    class MyClassWithUnionType:\n            pass\n\n    assert get_type_hints(MyClassWithUnionType) == {'a': Union[int, str], 'return': None}\n\n    class MyClassWithOptionalType:\n            pass\n\n    assert get_type_hints(MyClassWithOptionalType) == {'a': Optional[int], 'return': None}\n\n    class MyClassWithTypeVar:\n        T = TypeVar('T')\n\n            pass\n\n    assert get_type_hints(MyClassWithTypeVar) == {'a': MyClassWithTypeVar.T, 'return': None}\n"], "sample_159": ["    def test_builtin_permission_name_length(self):\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 250\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most 244 \"\n                \"characters for its builtin permission names to be at most 255 characters.\",\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 245\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [])\n\n        class Checked(models.Model):\n            class Meta:\n                verbose_name = 'x' * 246\n\n        errors = checks.run_checks(self.apps.get_app_configs())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most 245 \"\n                \"characters for its builtin permission names to be at most 255 characters.\",\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n"], "sample_20": ["def test_read_table_fits_memmap_mask_invalid(tmp_path):\n    filename = tmp_path / \"test_read_table_fits_memmap_mask_invalid.fits\"\n    t1 = Table(np.array([1, 2, np.nan, 4], dtype=[(\"a\", float)]))\n    t1.write(filename, overwrite=True)\n    t2 = Table.read(filename, memmap=True, mask_invalid=True)\n    assert np.all(t2[\"a\"].mask == [False, False, True, False])\n    t3 = Table.read(filename, memmap=True, mask_invalid=False)\n    assert t3.mask is None\n"], "sample_213": ["    def test_field_file_equality(self):\n        file1 = FieldFile(None, None, 'test.txt')\n        file2 = FieldFile(None, None, 'test.txt')\n        self.assertEqual(file1, file2)\n\n        file3 = FieldFile(None, None, 'test2.txt')\n        self.assertNotEqual(file1, file3)\n"], "sample_249": ["    def test_create_test_db(self):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db') as mocked_create_test_db:\n                test_db_name = creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n                self.assertEqual(test_db_name, TEST_DATABASE_PREFIX + old_database_name)\n                mocked_create_test_db.assert_called_once_with(0, True, False)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_389": ["    def test_get_host(self):\n        request = HttpRequest()\n        request.META = {\"HTTP_HOST\": \"example.com\"}\n        self.assertEqual(request.get_host(), \"example.com\")\n"], "sample_658": ["def test_doctest_report_only_first_failure_multiple_failures(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            '''\n            >>> foo()\n               a  b\n            0  1  4\n            1  2  4\n            2  3  6\n            '''\n            print('   a  b\\\\n'\n                  '0  1  4\\\\n'\n                  '1  2  5\\\\n'\n                  '2  3  7')\n        \"\"\"\n    )\n    result = testdir.runpytest(\"--doctest-modules\", \"--doctest-report\", \"only_first_failure\")\n    result.stdout.fnmatch_lines(\n        [\n            \"Expected:\",\n            \"       a  b\",\n            \"    0  1  4\",\n            \"    1  2  4\",\n            \"    2  3  6\",\n            \"Got:\",\n            \"       a  b\",\n            \"    0  1  4\",\n            \"    1  2  5\",\n            \"    2  3  7\",\n        ]\n    )\n"], "sample_583": ["def test_explicit_indexing_adapter():\n    array = np.arange(10)\n    key = indexing.BasicIndexer((slice(1, 5),))\n    result = indexing.explicit_indexing_adapter(key, array.shape,\n                                               indexing.IndexingSupport.BASIC,\n                                               array.__getitem__)\n    np.testing.assert_array_equal(result, array[1:5])\n\n    key = indexing.OuterIndexer((np.array([1, 3, 5]),))\n    result = indexing.explicit_indexing_adapter(key, array.shape,\n                                               indexing.IndexingSupport.OUTER,\n                                               array.__getitem__)\n    np.testing.assert_array_equal(result, array[[1, 3, 5]])\n\n    key = indexing.VectorizedIndexer((np.array([1, 3, 5]),))\n    result = indexing.explicit_indexing_adapter(key, array.shape,\n                                               indexing.IndexingSupport.VECTORIZED,\n                                               array.__getitem__)\n    np.testing.assert_array_equal(result, array[[1, 3, 5]])\n"], "sample_131": ["    def test_serialize_db_to_string(self, mocked_migrate, mocked_ensure_connection):\n        creation = connection.creation_class(connection)\n        test_connection = self.get_connection_copy()\n        test_connection.settings_dict['TEST_NON_SERIALIZED_APPS'] = ['auth']\n        creation.connection = test_connection\n        with mock.patch.object(creation, '_create_test_db'):\n            creation.create_test_db(verbosity=0, autoclobber=True, serialize=True)\n        self.assertIsNotNone(creation.connection._test_serialized_contents)\n"], "sample_1123": ["def test_CondSet_as_relational():\n    c = ConditionSet(x, x > 5, Interval(1, 7))\n    assert c.as_relational(6) == And(x > 5, Interval(1, 7).contains(x).subs(x, 6))\n    assert c.as_relational(8) == And(x > 5, Interval(1, 7).contains(x).subs(x, 8))\n    assert c.as_relational(w) == And(x > 5, Interval(1, 7).contains(x).subs(x, w))\n"], "sample_739": ["def test_label_binarize_multilabel_indicator():\n    y = np.array([[0, 1, 1], [1, 0, 0], [0, 0, 0]])\n    classes = [0, 1, 2]\n    pos_label = 2\n    neg_label = 0\n    expected = pos_label * y\n    y_sparse = [sparse_matrix(y)\n                for sparse_matrix in [coo_matrix, csc_matrix, csr_matrix,\n                                      dok_matrix, lil_matrix]]\n\n    for y in [y] + y_sparse:\n        yield (check_binarized_results, y, classes, pos_label, neg_label,\n               expected)\n\n    assert_raises(ValueError, label_binarize, y, classes, neg_label=-1,\n                  pos_label=pos_label, sparse_output=True)\n"], "sample_612": ["def test_groupby_map_with_kwargs() -> None:\n        return arg1 + arg2 + arg3\n\n    array = xr.DataArray([1, 1, 1], [(\"x\", [1, 2, 3])])\n    expected = xr.DataArray([3, 3, 3], [(\"x\", [1, 2, 3])])\n    actual = array.groupby(\"x\").map(func, arg1=1, arg3=1)\n    assert_identical(expected, actual)\n"], "sample_1137": ["def test_quantity_simplify():\n    assert quantity_simplify(kilo*foot*inch) == 250*foot**2/3\n    assert quantity_simplify(foot - 6*inch) == foot/2\n    assert quantity_simplify(foot + 6*inch) == 7*foot/2\n    assert quantity_simplify(foot + 12*inch) == 2*foot\n    assert quantity_simplify(foot - 12*inch) == 0\n    assert quantity_simplify(foot - 18*inch) == -foot/2\n    assert quantity_simplify(foot - 24*inch) == -2*foot\n"], "sample_1165": ["def test_quaternion_power():\n    q1 = Quaternion(1, 2, 3, 4)\n    q2 = Quaternion(1, 1, 1, 1)\n\n    assert q1.pow(0) == Quaternion(1, 0, 0, 0)\n    assert q2.pow(0) == Quaternion(1, 0, 0, 0)\n\n    assert q1.pow(1) == q1\n    assert q2.pow(1) == q2\n\n    assert q1.pow(2) == q1 * q1\n    assert q2.pow(2) == q2 * q2\n\n    assert q1.pow(-2) == q1.inverse() * q1.inverse()\n    assert q2.pow(-2) == q2.inverse() * q2.inverse()\n\n    assert q1.pow(3) == q1 * q1 * q1\n    assert q2.pow(3) == q2 * q2 * q2\n\n    assert q1.pow(-3) == q1.inverse() * q1.inverse() * q1.inverse()\n    assert q2.pow(-3) == q2.inverse() * q2.inverse() * q2.inverse()\n"], "sample_653": ["def test_log_set_path_relative(testdir):\n    report_dir_base = testdir.tmpdir.strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file_level = DEBUG\n        log_cli=true\n        \"\"\"\n    )\n    testdir.makeconftest(\n        \"\"\"\n            import os\n            import pytest\n            @pytest.hookimpl(hookwrapper=True, tryfirst=True)\n                config = item.config\n                logging_plugin = config.pluginmanager.get_plugin(\"logging-plugin\")\n                report_file = os.path.join(\"relative\", item._request.node.name)\n                logging_plugin.set_log_path(report_file)\n                yield\n        \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n            import logging\n            logger = logging.getLogger(\"testcase-logger\")\n                logger.info(\"message from test 1\")\n                assert True\n\n                logger.debug(\"message from test 2\")\n                assert True\n        \"\"\"\n    )\n    testdir.runpytest()\n    with open(os.path.join(report_dir_base, \"relative\", \"test_first\"), \"r\") as rfh:\n        content = rfh.read()\n        assert \"message from test 1\" in content\n\n    with open(os.path.join(report_dir_base, \"relative\", \"test_second\"), \"r\") as rfh:\n        content = rfh.read()\n        assert \"message from test 2\" in content\n"], "sample_434": ["    def test_template_view_get(self):\n        class TestTemplateView(TemplateView):\n            template_name = \"test_template.html\"\n\n        view = TestTemplateView.as_view()\n        request_factory = RequestFactory()\n        request = request_factory.get(\"/\")\n        response = view(request)\n        self.assertIsInstance(response, TemplateResponse)\n"], "sample_517": ["def test_transform_rotates_text_with_rotation_mode():\n    ax = plt.gca()\n    transform = mtransforms.Affine2D().rotate_deg(30)\n    text = ax.text(0, 0, 'test', transform=transform,\n                   transform_rotates_text=True, rotation_mode='anchor')\n    result = text.get_rotation()\n    assert_almost_equal(result, 0)\n"], "sample_801": ["def test_clone():\n    # Test cloning of estimators\n    lr = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                            intercept_scaling=1, l1_ratio=None, max_iter=100,\n                            multi_class='warn', n_jobs=None, penalty='l2',\n                            random_state=None, solver='warn', tol=0.0001, verbose=0,\n                            warm_start=False)\n\n    lr_clone = clone(lr)\n    assert lr_clone.get_params() == lr.get_params()\n\n    # Test cloning of lists of estimators\n    estimators = [LogisticRegression(), StandardScaler(), PCA()]\n    estimators_clone = clone(estimators)\n    for est, est_clone in zip(estimators, estimators_clone):\n        assert est_clone.get_params() == est.get_params()\n\n    # Test cloning of non-estimators\n    non_estimator = [1, 2, 3]\n    non_estimator_clone = clone(non_estimator, safe=False)\n    assert non_estimator_clone == non_estimator\n\n    # Test cloning of non-estimators with safe=True\n    try:\n        clone(non_estimator, safe=True)\n        assert False, \"Expected TypeError\"\n    except TypeError:\n        pass\n"], "sample_1199": ["def test_tensor_product_simp_Mul():\n    # Test tensor_product_simp_Mul with multiple TensorProducts\n    assert tensor_product_simp_Mul(TensorProduct(A, B)*TensorProduct(C, D)*TensorProduct(E, F)) == \\\n        TensorProduct(A*C*E, B*D*F)\n    # Test tensor_product_simp_Mul with a scalar\n    assert tensor_product_simp_Mul(2*TensorProduct(A, B)*TensorProduct(C, D)) == \\\n        2*TensorProduct(A*C, B*D)\n    # Test tensor_product_simp_Mul with a scalar and multiple TensorProducts\n    assert tensor_product_simp_Mul(2*TensorProduct(A, B)*TensorProduct(C, D)*TensorProduct(E, F)) == \\\n        2*TensorProduct(A*C*E, B*D*F)\n"], "sample_102": ["def test_union_with_distinct_fields(self):\n    qs1 = Number.objects.filter(num__lte=1).distinct('num')\n    qs2 = Number.objects.filter(num__gte=2, num__lte=3).distinct('num')\n    self.assertNumbersEqual(qs1.union(qs2).order_by('-num'), [3, 2, 1, 0])\n"], "sample_346": ["    def test_sync_only_middleware(self):\n        @sync_only_middleware\n            return HttpResponse()\n\n        self.assertTrue(middleware.sync_capable)\n        self.assertFalse(middleware.async_capable)\n"], "sample_284": ["    def test_hash_key(self):\n        storage = ManifestStaticFilesStorage()\n        self.assertEqual(storage.hash_key('test/file.txt'), 'test/file.txt')\n        self.assertEqual(storage.hash_key('test/file.txt?query'), 'test/file.txt')\n        self.assertEqual(storage.hash_key('test/file.txt#fragment'), 'test/file.txt')\n        self.assertEqual(storage.hash_key('test/file.txt?query#fragment'), 'test/file.txt')\n"], "sample_675": ["def test_log_capture_fixture(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        import pytest\n\n        logger = logging.getLogger(__name__)\n\n            logger.info('text going to logger from call')\n            assert 'text going to logger from call' in caplog.text\n            assert len(caplog.records) == 1\n            assert len(caplog.record_tuples) == 1\n            assert len(caplog.messages) == 1\n            caplog.clear()\n            assert len(caplog.records) == 0\n            assert len(caplog.record_tuples) == 0\n            assert len(caplog.messages) == 0\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--log-level=INFO\")\n    assert result.ret == 0\n    result.stdout.fnmatch_lines([\"* 1 passed in *\"])\n"], "sample_672": ["def test_ellipsize():\n    s = \"x\" * 100\n    assert _ellipsize(s, 25) == \"x\" * 10 + \"...\" + \"x\" * 10\n    assert _ellipsize(s, 100) == s\n    assert _ellipsize(s, 0) == \"\"\n    assert _ellipsize(\"\", 25) == \"\"\n"], "sample_859": ["def test_enet_path_with_sparse_X():\n    # Test that enet_path with sparse X gives the same result as with dense X\n    X, y, _, _ = build_dataset(n_samples=50, n_features=20)\n    X_sparse = sparse.csr_matrix(X)\n    for path in [enet_path, lasso_path]:\n        _, coefs, _ = path(X, y, fit_intercept=False)\n        _, sparse_coefs, _ = path(X_sparse, y, fit_intercept=False)\n        assert_array_almost_equal(coefs, sparse_coefs)\n"], "sample_791": ["def test_ordinal_encoder_unsorted_categories():\n    X = np.array([['a', 'b']], dtype=object).T\n\n    enc = OrdinalEncoder(categories=[['b', 'a', 'c']])\n    exp = np.array([[0.], [1.]])\n    assert_array_equal(enc.fit(X).transform(X), exp)\n    assert_array_equal(enc.fit_transform(X), exp)\n    assert enc.categories_[0].tolist() == ['b', 'a', 'c']\n    assert np.issubdtype(enc.categories_[0].dtype, np.object_)\n\n    # unsorted passed categories still raise for numerical values\n    X = np.array([[1, 2]]).T\n    enc = OrdinalEncoder(categories=[[2, 1, 3]])\n    msg = 'Unsorted categories are not supported'\n    with pytest.raises(ValueError, match=msg):\n        enc.fit_transform(X)\n"], "sample_763": ["def test_check_X_y_force_all_finite_valid():\n    # Test that check_X_y correctly handles force_all_finite\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([1, 2])\n    X[0, 0] = np.inf\n    y[0] = np.nan\n    X_checked, y_checked = check_X_y(X, y, force_all_finite=False)\n    assert_allclose_dense_sparse(X_checked, X)\n    assert_allclose_dense_sparse(y_checked, y)\n\n    X[0, 0] = np.inf\n    y[0] = np.nan\n    X_checked, y_checked = check_X_y(X, y, force_all_finite='allow-nan')\n    assert_allclose_dense_sparse(X_checked, X)\n    assert_allclose_dense_sparse(y_checked, y)\n\n    X[0, 0] = np.nan\n    y[0] = np.inf\n    X_checked, y_checked = check_X_y(X, y, force_all_finite='allow-nan')\n    assert_allclose_dense_sparse(X_checked, X)\n    assert_allclose_dense_sparse(y_checked, y)\n"], "sample_463": ["def test_alter_field_with_default_to_not_null_with_default(self):\n    \"\"\"\n    #23609 - Tests autodetection of nullable to non-nullable alterations.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_name_null], [self.author_name_default]\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True\n    )\n    self.assertOperationFieldAttributes(\n        changes, \"testapp\", 0, 0, default=\"Ada Lovelace\"\n    )\n"], "sample_569": ["def test_lmplot_hue_order(self):\n\n    g = lm.lmplot(x=\"x\", y=\"y\", data=self.df, hue=\"h\", hue_order=[\"y\", \"x\"])\n    ax = g.axes[0, 0]\n\n    assert len(ax.lines) == 2\n    assert len(ax.collections) == 4\n\n    red_scatter, blue_scatter = ax.collections\n    red, blue = color_palette(n_colors=2)\n    npt.assert_array_equal(blue, red_scatter.get_facecolors()[0, :3])\n    npt.assert_array_equal(red, blue_scatter.get_facecolors()[0, :3])\n"], "sample_1143": ["def test_issue_12345():\n    # Test that Float instances can be used as keys in a dictionary\n    d = {Float(1.0): 'one', Float(2.0): 'two'}\n    assert d[Float(1.0)] == 'one'\n    assert d[Float(2.0)] == 'two'\n    assert Float(1.0) in d\n    assert Float(2.0) in d\n    assert Float(3.0) not in d\n"], "sample_799": ["def test_cross_val_score_with_sample_weight():\n    # Test that sample weights are correctly passed to the scorer\n    iris = load_iris()\n    X, y = iris.data, iris.target\n    sample_weight = np.ones(len(y))\n    sample_weight[y == 0] *= 2\n    clf = SVC(kernel='linear')\n    score = cross_val_score(clf, X, y, cv=5, fit_params={'sample_weight': sample_weight})\n    assert_array_almost_equal(score, [0.97, 1., 0.97, 0.97, 1.], 2)\n"], "sample_1061": ["def test_Pow():\n    assert Pow(2, 3, evaluate=False).is_Pow\n    assert Pow(2, 3, evaluate=False).base == 2\n    assert Pow(2, 3, evaluate=False).exp == 3\n    assert Pow(2, 3, evaluate=False).is_commutative\n    assert Pow(2, 3, evaluate=False)._eval_power(2) == 8\n    assert Pow(2, 3, evaluate=False)._eval_power(0.5) == 4\n    assert Pow(2, 3, evaluate=False)._eval_power(-1) == Rational(1, 8)\n    assert Pow(2, 3, evaluate=False)._eval_power(-2) == Rational(1, 64)\n    assert Pow(2, 3, evaluate=False)._eval_power(1) == 8\n    assert Pow(2, 3, evaluate=False)._eval_power(2) == 64\n    assert Pow(2, 3, evaluate=False)._eval_power(3) == 512\n    assert Pow(2, 3, evaluate=False)._eval_power(4) == 4096\n    assert Pow(2, 3, evaluate=False)._eval_power(5) == 32768\n    assert Pow(2, 3, evaluate=False)._eval_power(6) == 262144\n    assert Pow(2, 3, evaluate=False)._eval_power(7) == 2097152\n    assert Pow(2, 3, evaluate=False)._eval_power(8) == 16777216\n    assert Pow(2, 3, evaluate=False)._eval_power(9) == 134217728\n    assert Pow(2, 3, evaluate=False)._eval_power(10) == 1073741824\n    assert Pow(2, 3, evaluate=False)._eval_power(11) == 8589934592\n    assert Pow(2, 3, evaluate=False)._eval_power(12) == 68719476736\n    assert Pow(2, 3, evaluate=False)._eval_power(13) == 549755813888\n    assert Pow(2, 3, evaluate=False)._eval_power(14) == 4398046511104\n    assert Pow(2, 3, evaluate=False)._eval_power(15) == 35184372088832"], "sample_328": ["    def test_values_list_with_flat_and_named(self):\n        notes = Note.objects.bulk_create([Note(note=str(i)) for i in range(10)])\n        with self.assertRaisesMessage(TypeError, \"'flat' and 'named' can't be used together.\"):\n            Note.objects.values_list(flat=True, named=True)\n"], "sample_214": ["    def test_key_transform_exact(self):\n        obj = NullableJSONModel.objects.create(value={'a': {'b': 'c'}})\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__a__b__exact='c'),\n            [obj],\n        )\n"], "sample_717": ["def test_fetch_lfw_pairs_subset():\n    for subset in ['train', 'test', '10_folds']:\n        lfw_pairs = fetch_lfw_pairs(subset=subset, data_home=SCIKIT_LEARN_DATA,\n                                    download_if_missing=False)\n        assert lfw_pairs.DESCR.startswith(\"'%s' segment of the LFW pairs\" % subset)\n"], "sample_955": ["def test_unparse_statements(source, expected):\n    tree = ast.parse(source)\n    assert ast.unparse(tree.body[0], source) == expected\n"], "sample_119": ["def test_is_nullable(self):\n    query = Query(Item)\n    self.assertTrue(query.is_nullable(Item._meta.get_field('name')))\n    self.assertFalse(query.is_nullable(Item._meta.get_field('id')))\n"], "sample_397": ["def test_find_template_loader_invalid_value(self):\n    engine = DjangoTemplates(\n        {\n            \"DIRS\": [],\n            \"APP_DIRS\": False,\n            \"NAME\": \"django\",\n            \"OPTIONS\": {\n                \"loaders\": [\"invalid_loader\"],\n            },\n        }\n    )\n    with self.assertRaisesMessage(\n        ImproperlyConfigured,\n        \"Invalid value in template loaders configuration: 'invalid_loader'\",\n    ):\n        engine.find_template_loader(\"invalid_loader\")\n"], "sample_337": ["def test_csrf_token_on_500_stays_constant(self):\n    response = self.client.get('/500/')\n    # The error handler returns status code 599.\n    self.assertEqual(response.status_code, 599)\n    token1 = response.content\n    response = self.client.get('/500/')\n    self.assertEqual(response.status_code, 599)\n    token2 = response.content\n    self.assertTrue(equivalent_tokens(token1.decode('ascii'), token2.decode('ascii')))\n"], "sample_420": ["    def test_model_form_with_custom_model_field(self):\n        class CustomModelFieldModel(models.Model):\n            custom_field = models.CharField(max_length=10)\n\n                return self.custom_field\n\n        class CustomModelFieldForm(forms.ModelForm):\n            class Meta:\n                model = CustomModelFieldModel\n                fields = \"__all__\"\n\n        form = CustomModelFieldForm({\"custom_field\": \"test\"})\n        self.assertTrue(form.is_valid())\n        instance = form.save()\n        self.assertEqual(instance.custom_field, \"test\")\n"], "sample_847": ["def test_enet_path_with_sparse_X():\n    # Test that enet_path with sparse X gives the same result as with dense X\n    X, y, _, _ = build_dataset(n_samples=50, n_features=20)\n    X_sparse = sparse.csr_matrix(X)\n    for path in [enet_path, lasso_path]:\n        _, coefs, _ = path(X, y, fit_intercept=False)\n        _, sparse_coefs, _ = path(X_sparse, y, fit_intercept=False)\n        assert_array_almost_equal(coefs, sparse_coefs)\n"], "sample_451": ["def test_replace_metacharacters(self):\n    pattern = \"Hello, world!\\\\?*+^$\"\n    expected_output = \"Hello, world?*+^$\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n"], "sample_442": ["    def test_empty_string(self):\n        signer = signing.Signer(key=\"predictable-secret\")\n        signed = signer.sign(\"\")\n        self.assertEqual(signer.unsign(signed), \"\")\n"], "sample_462": ["def test_choicefield_typed(self):\n    f = TypedChoiceField(choices=[(\"1\", \"One\"), (\"2\", \"Two\")], coerce=int)\n    self.assertEqual(1, f.clean(1))\n    self.assertEqual(1, f.clean(\"1\"))\n    msg = \"'Select a valid choice. 3 is not one of the available choices.'\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        f.clean(\"3\")\n    msg = \"'Select a valid choice. abc is not one of the available choices.'\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        f.clean(\"abc\")\n"], "sample_417": ["    def test_addslashes(self):\n        output = self.engine.render_to_string(\n            \"addslashes01\", {\"a\": \"Hello, 'world'!\"}\n        )\n        self.assertEqual(output, \"Hello, \\\\'world\\!\\\\\")\n        output = self.engine.render_to_string(\n            \"addslashes02\", {\"b\": mark_safe(\"Hello, 'world'!\")}\n        )\n        self.assertEqual(output, \"Hello, \\\\'world\\!\\\\\")\n"], "sample_747": ["def test_power_transformer_copy():\n    X = np.abs(X_2d)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method='box-cox', standardize=standardize, copy=True)\n\n        X_trans = pt.fit_transform(X)\n        assert_true(X_trans is not X)\n\n        pt = PowerTransformer(method='box-cox', standardize=standardize, copy=False)\n\n        X_trans = pt.fit_transform(X)\n        assert_true(X_trans is X)\n"], "sample_1203": ["def test_homomorphism_restrict_to():\n    # Test the restrict_to method\n    F, a, b = free_group(\"a, b\")\n    G = FpGroup(F, [a**3, b**3, (a*b)**2])\n    c = Permutation(3)(0, 1, 2)\n    d = Permutation(3)(1, 2, 3)\n    A = AlternatingGroup(4)\n    T = homomorphism(G, A, [a, b], [c, d])\n    H = PermutationGroup([c**2, d])\n    T_restricted = T.restrict_to(H)\n    assert T_restricted.domain == H\n    assert T_restricted.codomain == A\n    assert T_restricted(c**2) == c**2\n    assert T_restricted(d) == d\n\n    # Test the restrict_to method with a non-subgroup\n    raises(ValueError, lambda: T.restrict_to(PermutationGroup([c, d, Permutation(3)(0, 1)])))\n"], "sample_513": ["def test_legend_draggable():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3], label='test')\n    leg = ax.legend()\n    assert not leg.get_draggable()\n    leg.set_draggable(True)\n    assert leg.get_draggable()\n    leg.set_draggable(False)\n    assert not leg.get_draggable()\n    leg.set_draggable(True, use_blit=True)\n    assert leg.get_draggable()\n    leg.set_draggable(False)\n    assert not leg.get_draggable()\n    leg.set_draggable(True, update='bbox')\n    assert leg.get_draggable()\n    leg.set_draggable(False)\n    assert not leg.get_draggable()\n"], "sample_369": ["def test_alter_field_to_fk_dependency_other_app(self):\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author_fk],\n        [self.author_empty, self.book_with_author_renamed],\n    )\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '__first__')])\n    fk_field = changes['otherapp'][0].operations[0].field\n    self.assertEqual(fk_field.remote_field.model, 'testapp.Writer')\n"], "sample_470": ["def test_lazy_object_pickle(self):\n    \"\"\"LazyObject can be pickled.\"\"\"\n    lazy_obj = SimpleLazyObject(lambda: \"Lazy translation text\")\n    pickled_lazy_obj = pickle.dumps(lazy_obj)\n    unpickled_lazy_obj = pickle.loads(pickled_lazy_obj)\n    self.assertEqual(str(unpickled_lazy_obj), \"Lazy translation text\")\n"], "sample_94": ["    def test_required_fields_with_default_values(self):\n        \"A Custom superuser can be created when required fields have default values\"\n        # We can use the management command to create a superuser\n        # We skip validation because the temporary substitution of the\n        # swappable User model messes with validation.\n        new_io = StringIO()\n        call_command(\n            \"createsuperuser\",\n            interactive=False,\n            email=\"joe@somewhere.org\",\n            stdout=new_io,\n        )\n        command_output = new_io.getvalue().strip()\n        self.assertEqual(command_output, 'Superuser created successfully.')\n        u = CustomUser._default_manager.get(email=\"joe@somewhere.org\")\n        self.assertEqual(u.date_of_birth, date(1970, 1, 1))\n        self.assertEqual(u.first_name, 'John')\n\n        # created password should be unusable\n        self.assertFalse(u.has_usable_password())\n"], "sample_736": ["def test_logistic_regression_path_multiclass():\n    # Test logistic_regression_path for multiclass problems\n    X, y = make_classification(n_samples=20, n_features=5, n_informative=3,\n                               n_classes=3, random_state=0)\n    Cs = [1.0]\n    solvers = ['lbfgs', 'newton-cg', 'sag', 'saga']\n    for solver in solvers:\n        coefs, Cs, n_iter = logistic_regression_path(\n            X, y, Cs=Cs, fit_intercept=False, solver=solver,\n            multi_class='multinomial', random_state=42, max_iter=2000, tol=1e-7)\n        assert_array_equal(coefs[0].shape, (3, 5))\n        assert_array_almost_equal(coefs[0].sum(axis=0), np.zeros(5))\n\n    # Test logistic_regression_path for multiclass problems with intercept\n    X, y = make_classification(n_samples=20, n_features=5, n_informative=3,\n                               n_classes=3, random_state=0)\n    Cs = [1.0]\n    solvers = ['lbfgs', 'newton-cg', 'sag', 'saga']\n    for solver in solvers:\n        coefs, Cs, n_iter = logistic_regression_path(\n            X, y, Cs=Cs, fit_intercept=True, solver=solver,\n            multi_class='multinomial', random_state=42, max_iter=2000, tol=1e-7)\n        assert_array_equal(coefs[0].shape, (3, 6))\n        assert_array_almost_equal(coefs[0][:, :-1].sum(axis=0), np.zeros(5))\n"], "sample_821": ["def test_affinity_propagation_affinity_matrix():\n    # Test that the affinity matrix is correctly computed and stored\n    af = AffinityPropagation(affinity=\"euclidean\")\n    af.fit(X)\n    assert_array_equal(af.affinity_matrix_, -euclidean_distances(X, squared=True))\n\n    af = AffinityPropagation(affinity=\"precomputed\")\n    S = -euclidean_distances(X, squared=True)\n    af.fit(S)\n    assert_array_equal(af.affinity_matrix_, S)\n"], "sample_591": ["def test_merge_no_conflicts_broadcast(self):\n    ds1 = xr.Dataset({\"x\": (\"y\", [0])})\n    ds2 = xr.Dataset({\"x\": np.nan})\n    expected = xr.Dataset({\"x\": (\"y\", [0])})\n    assert expected.identical(xr.merge([ds1, ds2], compat=\"no_conflicts\"))\n    assert expected.identical(xr.merge([ds2, ds1], compat=\"no_conflicts\"))\n\n    ds1 = xr.Dataset({\"x\": (\"y\", [np.nan])})\n    ds2 = xr.Dataset({\"x\": 0})\n    expected = xr.Dataset({\"x\": (\"y\", [0])})\n    assert expected.identical(xr.merge([ds1, ds2], compat=\"no_conflicts\"))\n    assert expected.identical(xr.merge([ds2, ds1], compat=\"no_conflicts\"))\n"], "sample_476": ["    def test_generate_filename(self):\n        \"\"\"\n        Test that generate_filename correctly applies the upload_to parameter.\n        \"\"\"\n        field = ImageField(upload_to=\"images/\")\n        filename = field.generate_filename(self.PersonModel(), \"test.jpg\")\n        self.assertEqual(filename, \"images/test.jpg\")\n"], "sample_954": ["def test_inline_markup(app, status, warning):\n    app.builder.build_all()\n    content = (app.outdir / 'python.1').read_text()\n\n    # test inline markup\n    assert r'\\fIemphasis\\fP' in content\n    assert r'\\fBstrong\\fP' in content\n    assert r'\\fIliteral\\fP' in content\n    assert r'\\fBcode\\fP' in content\n    assert r'\\fIsubscript\\fP' in content\n    assert r'\\fIsuperscript\\fP' in content\n\n    # test inline markup combinations\n    assert r'\\fIemphasis \\fBstrong\\fP\\fI emphasis\\fP' in content\n    assert r'\\fBstrong \\fIemphasis\\fP \\fBstrong\\fP' in content\n"], "sample_438": ["    def test_model_repr(self):\n        class TestModel(models.Model):\n            pass\n\n        obj = TestModel()\n        self.assertEqual(repr(obj), \"<TestModel: TestModel object>\")\n"], "sample_30": ["def test_tabledata_format():\n    votable = parse(get_pkg_data_filename(\"data/regression.xml\"))\n    table = votable.get_first_table()\n    table.format = \"binary\"\n    bio = io.BytesIO()\n    votable.to_xml(bio)\n    bio.seek(0)\n    votable2 = parse(bio)\n    table2 = votable2.get_first_table()\n    assert table2.format == \"binary\"\n\n    table.format = \"binary2\"\n    bio = io.BytesIO()\n    votable.to_xml(bio)\n    bio.seek(0)\n    votable2 = parse(bio)\n    table2 = votable2.get_first_table()\n    assert table2.format == \"binary2\"\n\n    table.format = \"tabledata\"\n    bio = io.BytesIO()\n    votable.to_xml(bio)\n    bio.seek(0)\n    votable2 = parse(bio)\n    table2 = votable2.get_first_table()\n    assert table2.format == \"tabledata\"\n\n    with pytest.raises(ValueError):\n        table.format = \"invalid\"\n"], "sample_578": ["def test_baseline(self, x, y):\n\n    baseline = [1, 2, 3, 4, 5]\n    p = Plot(x, y, baseline=baseline).add(Bars()).plot()\n    ax = p._figure.axes[0]\n    paths = ax.collections[0].get_paths()\n    assert len(paths) == len(x)\n    for i, path in enumerate(paths):\n        verts = path.vertices\n        assert verts[0, 1] == pytest.approx(baseline[i])\n        assert verts[3, 1] == pytest.approx(baseline[i] + y[i])\n"], "sample_293": ["    def test_prefix_default_language(self):\n        pattern = LocalePrefixPattern(prefix_default_language=True)\n        self.assertEqual(pattern.regex.pattern, '^en/')\n"], "sample_151": ["def test_alter_field_to_m2m(self):\n    \"\"\"\n    #23938 - Changing a concrete field into a ManyToManyField\n    first removes the concrete field and then adds the m2m field.\n    \"\"\"\n    changes = self.get_changes([self.author_with_former_m2m], [self.author_with_m2m, self.publisher])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\", \"RemoveField\", \"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name='Publisher')\n    self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"publishers\", model_name='author')\n    self.assertOperationAttributes(changes, 'testapp', 0, 2, name=\"publishers\", model_name='author')\n"], "sample_1179": ["def test_Pow():\n    assert str(Pow(x, 1, evaluate=False)) == \"x**1\"\n    assert str(Pow(x, -1, evaluate=False)) == \"x**(-1)\"\n    assert str(Pow(x, 0, evaluate=False)) == \"x**0\"\n    assert str(Pow(x, 2, evaluate=False)) == \"x**2\"\n    assert str(Pow(x, -2, evaluate=False)) == \"x**(-2)\"\n    assert str(Pow(x, Rational(1, 2), evaluate=False)) == \"x**(1/2)\"\n    assert str(Pow(x, Rational(-1, 2), evaluate=False)) == \"x**(-1/2)\"\n    assert str(Pow(x, Rational(3, 2), evaluate=False)) == \"x**(3/2)\"\n    assert str(Pow(x, Rational(-3, 2), evaluate=False)) == \"x**(-3/2)\"\n    assert str(Pow(x, pi, evaluate=False)) == \"x**pi\"\n    assert str(Pow(x, -pi, evaluate=False)) == \"x**(-pi)\"\n    assert str(Pow(x, E, evaluate=False)) == \"x**E\"\n    assert str(Pow(x, -E, evaluate=False)) == \"x**(-E)\"\n    assert str(Pow(x, I, evaluate=False)) == \"x**I\"\n    assert str(Pow(x, -I, evaluate=False)) == \"x**(-I)\"\n    assert str(Pow(x, oo, evaluate=False)) == \"x**oo\"\n    assert str(Pow(x, -oo, evaluate=False)) == \"x**(-oo)\"\n    assert str(Pow(x, nan, evaluate=False)) == \"x**nan\"\n    assert str(Pow(x, -nan, evaluate=False)) == \"x**(-nan)\"\n    assert str(Pow(x, zoo, evaluate=False)) == \"x**zoo\"\n    assert str(Pow(x, -zoo, evaluate=False)) == \"x**(-zoo)\"\n"], "sample_6": ["def test_angle_wrap_at():\n    \"\"\"\n    Test the wrap_at method of Angle objects.\n    \"\"\"\n    a1 = Angle([0, 180, 360, 720], unit=u.degree)\n    a2 = a1.wrap_at(180*u.degree)\n    npt.assert_almost_equal(a2.degree, [0, 180, 180, 360])\n\n    a3 = Angle([0, 180, 360, 720], unit=u.degree)\n    a3.wrap_at(180*u.degree, inplace=True)\n    npt.assert_almost_equal(a3.degree, [0, 180, 180, 360])\n\n    a4 = Angle([0, 180, 360, 720], unit=u.degree)\n    a5 = a4.wrap_at(90*u.degree)\n    npt.assert_almost_equal(a5.degree, [0, 90, 90, 180])\n\n    a6 = Angle([0, 180, 360, 720], unit=u.degree)\n    a6.wrap_at(90*u.degree, inplace=True)\n    npt.assert_almost_equal(a6.degree, [0, 90, 90, 180])\n\n    a7 = Angle([0, 180, 360, 720], unit=u.degree)\n    a8 = a7.wrap_at(360*u.degree)\n    npt.assert_almost_equal(a8.degree, [0, 180, 360, 720])\n\n    a9 = Angle([0, 180, 360, 720], unit=u.degree)\n    a9.wrap_at(360*u.degree, inplace=True)\n    npt.assert_almost_equal(a9.degree, [0, 180, 360, 720])\n\n    with pytest.raises(u.UnitsError):\n        a10 = a1.wrap_at(10*u.m)\n\n    with pytest.raises(TypeError):\n        a11 = a1.wrap_at('10m')\n"], "sample_980": ["def test_cycle_structure():\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    assert p.cycle_structure == {1: 6}\n    p = Permutation([0, 2, 1, 3, 4, 5])\n    assert p.cycle_structure == {1: 4, 2: 1}\n    p = Permutation([0, 1, 2, 4, 3, 5])\n    assert p.cycle_structure == {1: 3, 2: 1}\n    p = Permutation([0, 1, 2, 3, 5, 4])\n    assert p.cycle_structure == {1: 4, 2: 1}\n    p = Permutation([0, 2, 1, 3, 5, 4])\n    assert p.cycle_structure == {1: 2, 2: 2}\n    p = Permutation([0, 2, 1, 4, 3, 5])\n    assert p.cycle_structure == {1: 2, 3: 1}\n    p = Permutation([0, 2, 1, 4, 5, 3])\n    assert p.cycle_structure == {1: 2, 3: 1}\n    p = Permutation([0, 2, 4, 1, 3, 5])\n    assert p.cycle_structure == {1: 2, 3: 1}\n    p = Permutation([0, 2, 4, 1, 5, 3])\n    assert p.cycle_structure == {1: 2, 3: 1}\n    p = Permutation([0, 2, 4, 5, 1, 3])\n    assert p.cycle_structure == {1: 2, 3: 1}\n    p = Permutation([0, 2, 4, 5, 3, 1])\n    assert p.cycle_structure == {1: 2, 3: 1}\n    p = Permutation([0, 2, 5, 1, 3, 4])\n    assert p.cycle_structure == {1: 2, 3: 1}\n    p = Permutation([0, 2, 5, 1, "], "sample_765": ["def test_multilabel_confusion_matrix_multilabel_samplewise():\n    # Test multilabel confusion matrix - multilabel-indicator case\n    from scipy.sparse import csc_matrix, csr_matrix\n\n    y_true = np.array([[1, 0, 1], [0, 1, 0], [1, 1, 0]])\n    y_pred = np.array([[1, 0, 0], [0, 1, 1], [0, 0, 1]])\n    y_true_csr = csr_matrix(y_true)\n    y_pred_csr = csr_matrix(y_pred)\n    y_true_csc = csc_matrix(y_true)\n    y_pred_csc = csc_matrix(y_pred)\n\n    # cross test different types\n    sample_weight = np.array([2, 1, 3])\n    real_cm = [[[1, 0], [1, 1]],\n               [[1, 1], [0, 1]],\n               [[0, 1], [2, 0]]]\n    trues = [y_true, y_true_csr, y_true_csc]\n    preds = [y_pred, y_pred_csr, y_pred_csc]\n\n    for y_true_tmp in trues:\n        for y_pred_tmp in preds:\n            cm = multilabel_confusion_matrix(y_true_tmp, y_pred_tmp, samplewise=True)\n            assert_array_equal(cm, real_cm)\n\n    # test support for sample_weight with sample_wise\n    cm = multilabel_confusion_matrix(y_true, y_pred,\n                                     sample_weight=sample_weight,\n                                     samplewise=True)\n    assert_array_equal(cm, [[[2, 0], [2, 2]],\n                            [[1, 1], [0, 1]],\n                            [[0, 3], [6, 0]]])\n"], "sample_812": ["def test_n_max_elements_to_show_with_nested_estimators():\n    n_max_elements_to_show = 30\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=n_max_elements_to_show\n    )\n\n    # Test with a pipeline of estimators\n    pipeline = make_pipeline(\n        StandardScaler(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n        LogisticRegression(),\n"], "sample_676": ["def test_terminalreporter_reportopt_addopts_with_multiple_options(testdir):\n    testdir.makeini(\"[pytest]\\naddopts=-rsf\")\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            tr = request.config.pluginmanager.getplugin(\"terminalreporter\")\n            return tr\n            assert tr.hasopt('skipped')\n            assert tr.hasopt('failed')\n            assert not tr.hasopt('qwe')\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n"], "sample_681": ["def test_log_capture_handler_reset(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logger = logging.getLogger(__name__)\n\n            logger.info('text going to logger from call')\n            assert len(caplog.records) == 1\n            caplog.clear()\n            assert len(caplog.records) == 0\n\n            logger.info('text going to logger from call')\n            assert len(caplog.records) == 1\n        \"\"\"\n    )\n    result = testdir.runpytest(\"--log-level=INFO\")\n    assert result.ret == 0\n"], "sample_252": ["    def test_key_transform_factory(self):\n        field = models.JSONField()\n        transform = field.get_transform('nonexistent')\n        self.assertIsInstance(transform, KeyTransformFactory)\n        self.assertEqual(transform.key_name, 'nonexistent')\n"], "sample_930": ["def test_create_index_with_fixre(app):\n    text = (\".. index:: func() (in module foo)\\n\"\n            \".. index:: func() (in module bar)\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder, _fixre=re.compile(r'(.*) \\(.*\\)'))\n    assert len(index) == 1\n    assert index[0] == ('F', [('func()', [[], [('(in module bar)', [('', '#index-1')]),\n                                             ('(in module foo)', [('', '#index-0')])], None])])\n"], "sample_1001": ["def test_latex_DiagramGrid():\n    from sympy.categories import Diagram, DiagramGrid\n    from sympy.categories import NamedMorphism\n    A = Object(\"A\")\n    B = Object(\"B\")\n    C = Object(\"C\")\n    D = Object(\"D\")\n    f = NamedMorphism(A, B, \"f\")\n    g = NamedMorphism(B, C, \"g\")\n    h = NamedMorphism(C, D, \"h\")\n    d = Diagram([f, g, h])\n    grid = DiagramGrid(d, 3, 2)\n    grid[0, 0] = A\n    grid[1, 0] = f\n    grid[2, 0] = g\n    grid[0, 1] = B\n    grid[1, 1] = C\n    grid[2, 1] = h\n    assert latex(grid) == \"\\\\begin{array}{cc}\\n\" \\\n        \"A & B \\\\\\\\\\n\" \\\n        \"f & C \\\\\\\\\\n\" \\\n        \"g & h \\n\" \\\n        \"\\\\end{array}\\n\"\n"], "sample_696": ["def test_argument_percent_default_is_deprecated(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        addopts = --myopt=%default\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: pytest now uses argparse. '%default' should be changed to '%(default)s'\",\n        ]\n    )\n\n"], "sample_21": ["def test_understand_err_col():\n    colnames = [\"a\", \"a_err\", \"b\", \"b_perr\", \"b_nerr\", \"c\"]\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [0])\n    assert np.allclose(terr, [1])\n\n    colnames = [\"a\", \"a_perr\", \"a_nerr\", \"b\", \"b_err\"]\n    with pytest.raises(ValueError):\n        _understand_err_col(colnames)\n\n    colnames = [\"a\", \"a_nerr\", \"b\", \"b_err\"]\n    with pytest.raises(ValueError):\n        _understand_err_col(colnames)\n\n    colnames = [\"a\", \"b\", \"c\"]\n    serr, terr = _understand_err_col(colnames)\n    assert np.allclose(serr, [])\n    assert np.allclose(terr, [])\n"], "sample_518": ["def test_fancyarrowpatch_set_positions():\n    fig, ax = plt.subplots()\n    arrow = FancyArrowPatch((0, 0), (1, 1))\n    ax.add_patch(arrow)\n    assert arrow.get_positions() == ((0, 0), (1, 1))\n    arrow.set_positions((0.5, 0.5), (1.5, 1.5))\n    assert arrow.get_positions() == ((0.5, 0.5), (1.5, 1.5))\n"], "sample_179": ["    def test_model_name_clash(self):\n        class Model(models.Model):\n            pass\n\n        class Model(models.Model):\n            pass\n\n        self.assertEqual(Model.check(), [\n            Error(\n                \"Model name 'Model' must be unique.\",\n                obj=Model,\n                id='models.E020',\n            ),\n        ])\n"], "sample_771": ["def test_power_transformer_warning():\n    # Test that a FutureWarning is raised when using the default method\n    X = np.abs(X_2d)\n    future_warning_message = (\n        \"The default value of 'method' \"\n        \"will change from 'box-cox'\"\n    )\n    assert_warns_message(FutureWarning, future_warning_message,\n                         PowerTransformer().fit, X)\n"], "sample_37": ["def test_sip_with_altkey_2():\n    \"\"\"\n    Test that when creating a WCS object using a key, CTYPE with\n    that key is looked at and not the primary CTYPE.\n    fix for #5443.\n    \"\"\"\n    with fits.open(get_pkg_data_filename('data/sip.fits')) as f:\n        w = wcs.WCS(f[0].header)\n    # create a header with two WCSs.\n    h1 = w.to_header(relax=True, key='A')\n    h2 = w.to_header(relax=False)\n    h1['CTYPE1A'] = \"RA---SIN-SIP\"\n    h1['CTYPE2A'] = \"DEC--SIN-SIP\"\n    h1.update(h2)\n    w = wcs.WCS(h1, key='A')\n    assert (w.wcs.ctype == np.array(['RA---SIN-SIP', 'DEC--SIN-SIP'])).all()\n    # Test that the WCS object can be used to transform coordinates\n    # correctly.\n    pixcrd = np.array([[1, 2], [3, 4]])\n    sky = w.all_pix2world(pixcrd, 1)\n    assert sky.shape == (2, 2)\n"], "sample_384": ["    def test_get_or_create_with_defaults(self):\n        defaults = {\"note\": \"test\"}\n        obj, created = Note.objects.get_or_create(misc=\"test\", defaults=defaults)\n        self.assertTrue(created)\n        self.assertEqual(obj.note, defaults[\"note\"])\n        self.assertEqual(obj.misc, \"test\")\n"], "sample_394": ["    def test_changelist_view_with_custom_queryset(self):\n        \"\"\"\n        Test that a custom queryset is used in the changelist view.\n        \"\"\"\n        response = self.client.get(reverse(\"admin:admin_views_emptymodel_changelist\"))\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, \"Primary key = 2\")\n        self.assertContains(response, \"Primary key = 3\")\n        self.assertNotContains(response, \"Primary key = 1\")\n"], "sample_44": ["    def test_pickle(self):\n        lq1 = u.Magnitude(np.arange(1., 10.)*u.Jy)\n        s = pickle.dumps(lq1)\n        lq2 = pickle.loads(s)\n        assert lq1 == lq2\n        assert lq1.unit == lq2.unit\n        assert np.all(lq1.value == lq2.value)\n"], "sample_471": ["def test_floatfield(self):\n    f = FloatField()\n    self.assertWidgetRendersTo(\n        f, '<input type=\"number\" name=\"f\" id=\"id_f\" required>'\n    )\n    with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):\n        f.clean(\"\")\n    with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):\n        f.clean(None)\n    self.assertEqual(1.0, f.clean(\"1\"))\n    self.assertIsInstance(f.clean(\"1\"), float)\n    self.assertEqual(23.0, f.clean(\"23\"))\n    with self.assertRaisesMessage(ValidationError, \"'Enter a number.'\"):\n        f.clean(\"a\")\n    self.assertEqual(42.0, f.clean(42))\n    self.assertEqual(3.14, f.clean(3.14))\n    self.assertEqual(1.0, f.clean(\"1 \"))\n    self.assertEqual(1.0, f.clean(\" 1\"))\n    self.assertEqual(1.0, f.clean(\" 1 \"))\n    with self.assertRaisesMessage(ValidationError, \"'Enter a number.'\"):\n        f.clean(\"1a\")\n    self.assertIsNone(f.max_value)\n    self.assertIsNone(f.min_value)\n\n    f = FloatField(required=False)\n    self.assertIsNone(f.clean(\"\"))\n    self.assertEqual(\"None\", repr(f.clean(\"\")))\n    self.assertIsNone(f.clean(None))\n    self.assertEqual(\"None\", repr(f.clean(None)))\n    self.assertEqual(1.0, f.clean(\"1\"))\n    self.assertIsInstance(f.clean(\"1\"), float)\n    self.assertEqual(23.0, f.clean(\"23\"))\n    with self.assertRaisesMessage(ValidationError, \"'Enter a number.'\"):\n        f.clean(\"a\")\n    self.assertEqual(1.0, f.clean(\"1 \"))\n    self.assertEqual(1.0, f.clean(\" 1\"))\n    self.assertEqual(1.0, f.clean(\" 1 \"))\n    with self.assertRaisesMessage(ValidationError, \"'Enter a number.'\"):\n        f.clean(\"1a\")\n    self.assertIsNone(f.max_value)\n    self.assertIsNone(f.min_value)\n\n    f = FloatField(max_value=10.0)\n    self.assertWidgetRendersTo(\n        f, '<input max=\"10.0\" type=\"number\" name=\"f\" id=\"id_f\" required>'\n    )\n    with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):\n        f.clean(None)\n    self.assertEqual(1.0, f.clean(1.0))\n    self.assertEqual("], "sample_949": ["def test_man_pages_config_value(app, status, warning):\n    app.config.man_pages = [('custom_doc', 'custom_name', 'Custom Description', ['Custom Author'], 2)]\n    app.builder.build_all()\n    assert (app.outdir / 'custom_name.2').exists()\n\n    content = (app.outdir / 'custom_name.2').read_text()\n    assert 'Custom Description' in content\n    assert 'Custom Author' in content\n"], "sample_697": ["def test_tmp_path_factory_getbasetemp_custom_removes_old(pytester: Pytester) -> None:\n    mytemp = pytester.path.joinpath(\"xyz\")\n    p = pytester.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    pytester.runpytest(p, \"--basetemp=%s\" % mytemp)\n    assert mytemp.exists()\n    mytemp.joinpath(\"hello\").touch()\n\n    pytester.runpytest(p, \"--basetemp=%s\" % mytemp)\n    assert mytemp.exists()\n    assert not mytemp.joinpath(\"hello\").exists()\n\n    # Test that the old basetemp is removed after 3 sessions\n    pytester.runpytest(p, \"--basetemp=%s\" % mytemp)\n    pytester.runpytest(p, \"--basetemp=%s\" % mytemp)\n    pytester.runpytest(p, \"--basetemp=%s\" % mytemp)\n    assert not mytemp.exists()\n"], "sample_376": ["def test_process_messages(self):\n    \"\"\"\n    Test the process_messages method of MessageDecoder.\n    \"\"\"\n    decoder = MessageDecoder()\n    # Test with a list containing a Message\n    data = [MessageEncoder.message_key, 0, constants.INFO, 'message']\n    self.assertIsInstance(decoder.process_messages(data), Message)\n    # Test with a list not containing a Message\n    data = ['not a message']\n    self.assertEqual(decoder.process_messages(data), ['not a message'])\n    # Test with a dictionary containing a Message\n    data = {'key': [MessageEncoder.message_key, 0, constants.INFO, 'message']}\n    self.assertIsInstance(decoder.process_messages(data)['key'], Message)\n    # Test with a dictionary not containing a Message\n    data = {'key': 'not a message'}\n    self.assertEqual(decoder.process_messages(data), {'key': 'not a message'})\n    # Test with a nested structure\n    data = {\n        'key1': [MessageEncoder.message_key, 0, constants.INFO, 'message'],\n        'key2': 'not a message',\n        'key3': [\n            [MessageEncoder.message_key, 0, constants.INFO, 'message'],\n            'not a message',\n        ],\n    }\n    result = decoder.process_messages(data)\n    self.assertIsInstance(result['key1'], Message)\n    self.assertEqual(result['key2'], 'not a message')\n    self.assertIsInstance(result['key3'][0], Message)\n    self.assertEqual(result['key3'][1], 'not a message')\n"], "sample_786": ["def test_inverse_transform_constant_feature():\n    X = np.array([[1, 1, 1, 1],\n                  [1, 1, 1, 1],\n                  [1, 1, 1, 1],\n                  [1, 1, 1, 1]])\n    est = KBinsDiscretizer(n_bins=3, strategy='uniform', encode='ordinal')\n    est.fit(X)\n    Xt = est.transform(X)\n    Xinv = est.inverse_transform(Xt)\n    assert_array_equal(Xinv, np.ones((4, 4)))\n"], "sample_1197": ["def test_unit_system():\n    # Test UnitSystem class\n    us = UnitSystem((meter, second), name=\"MyUnitSystem\")\n    assert us.name == \"MyUnitSystem\"\n    assert us.dim == 2\n    assert us.is_consistent\n\n    # Test extend method\n    new_us = us.extend((kilogram,))\n    assert new_us.name == \"\"\n    assert new_us.dim == 3\n    assert new_us.is_consistent\n\n    # Test get_dimension_system method\n    assert us.get_dimension_system() is not None\n\n    # Test get_quantity_dimension method\n    assert us.get_quantity_dimension(meter) == length\n\n    # Test get_quantity_scale_factor method\n    assert us.get_quantity_scale_factor(meter) == 1\n\n    # Test get_unit_system method\n    assert UnitSystem.get_unit_system(\"SI\") is not None\n\n    # Test get_default_unit_system method\n    assert UnitSystem.get_default_unit_system() is not None\n\n    # Test derived_units property\n    assert us.derived_units == {}\n\n    # Test get_units_non_prefixed method\n    assert us.get_units_non_prefixed() == {meter, second}\n"], "sample_539": ["def test_ellipse_selector_set_props_handle_props(ax):\n    tool = widgets.EllipseSelector(ax, onselect=noop, interactive=True,\n                                   props=dict(facecolor='b', alpha=0.2),\n                                   handle_props=dict(alpha=0.5))\n    # Create ellipse\n    click_and_drag(tool, start=(0, 10), end=(100, 120))\n\n    artist = tool._selection_artist\n    assert artist.get_facecolor() == mcolors.to_rgba('b', alpha=0.2)\n    tool.set_props(facecolor='r', alpha=0.3)\n    assert artist.get_facecolor() == mcolors.to_rgba('r', alpha=0.3)\n\n    for artist in tool._handles_artists:\n        assert artist.get_color() == 'b'\n        assert artist.get_alpha() == 0.5\n    tool.set_handle_props(color='r', alpha=0.3)\n    for artist in tool._handles_artists:\n        assert artist.get_color() == 'r'\n        assert artist.get_alpha() == 0.3\n"], "sample_79": ["    def test_no_argument(self):\n        self.check_values(('34.23234', '34.2'), ('34.00000', '34'), ('34.26000', '34.3'))\n"], "sample_379": ["def test_mark_safe_safe_string(self):\n    \"\"\"\n    mark_safe doesn't affect SafeString instances.\n    \"\"\"\n    s = SafeString('<html></html>')\n    self.assertIs(mark_safe(s), s)\n    self.assertRenderEqual('{{ s }}', '<html></html>', s=s)\n    self.assertRenderEqual('{{ s|force_escape }}', '&lt;html&gt;&lt;/html&gt;', s=s)\n"], "sample_940": ["def test_isabstractmethod():\n    class AbstractClass:\n        @abstractmethod\n            pass\n\n    class ConcreteClass(AbstractClass):\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(ConcreteClass.abstract_method) is False\n    assert inspect.isabstractmethod(AbstractClass) is False\n    assert inspect.isabstractmethod(ConcreteClass) is False\n"], "sample_69": ["    def test_enable_echo(self, mocked_termios):\n        mocked_termios.tcgetattr.return_value = [0, 0, 0, 0]\n        mocked_termios.ECHO = 1\n        with mock.patch('sys.stdin.isatty', return_value=True):\n            autoreload.ensure_echo_on()\n        self.assertEqual(mocked_termios.tcsetattr.call_count, 1)\n"], "sample_432": ["def test_list_editable_with_custom_pk(self):\n    \"\"\"\n    Regression test for #21685: list_editable with custom primary key.\n    \"\"\"\n    charpk = CharPK.objects.create(char_pk=\"abc\")\n    CharPK.objects.create(char_pk=\"def\")\n    superuser = self._create_superuser(\"superuser\")\n    self.client.force_login(superuser)\n    changelist_url = reverse(\"admin:admin_changelist_charpk_changelist\")\n    m = admin.ModelAdmin(CharPK, custom_site)\n    m.list_editable = [\"name\"]\n    data = {\n        \"form-TOTAL_FORMS\": \"2\",\n        \"form-INITIAL_FORMS\": \"2\",\n        \"form-MIN_NUM_FORMS\": \"0\",\n        \"form-MAX_NUM_FORMS\": \"1000\",\n        \"form-0-char_pk\": charpk.char_pk,\n        \"form-1-char_pk\": \"def\",\n        \"form-0-name\": \"new name\",\n        \"_save\": \"Save\",\n    }\n    response = self.client.post(changelist_url, data)\n    self.assertEqual(response.status_code, 200)\n    charpk.refresh_from_db()\n    self.assertEqual(charpk.name, \"new name\")\n"], "sample_122": ["    def test_get_max_age(self):\n        response = HttpResponse()\n        self.assertIsNone(get_max_age(response))\n\n        response['Cache-Control'] = 'max-age=3600'\n        self.assertEqual(get_max_age(response), 3600)\n\n        response['Cache-Control'] = 'max-age=3600, public'\n        self.assertEqual(get_max_age(response), 3600)\n\n        response['Cache-Control'] = 'public'\n        self.assertIsNone(get_max_age(response))\n\n        response['Cache-Control'] = 'max-age=abc'\n        self.assertIsNone(get_max_age(response))\n"], "sample_841": ["def test_ridge_regression_check_input_validity():\n    \"\"\"check if all combinations of arguments give valid estimations\"\"\"\n\n    # test excludes 'svd' solver because it raises exception for sparse inputs\n\n    rng = check_random_state(42)\n    X = rng.rand(1000, 3)\n    true_coefs = [1, 2, 0.1]\n    y = np.dot(X, true_coefs)\n    true_intercept = 0.\n    y += true_intercept\n    X_testing = X\n\n    alpha, atol, tol = 1e-3, 1e-4, 1e-6\n\n    for solver in ['auto', 'sparse_cg', 'cholesky', 'lsqr', 'sag', 'saga']:\n        out = ridge_regression(X_testing, y, alpha=alpha,\n                               solver=solver,\n                               sample_weight=None,\n                               return_intercept=False,\n                               tol=tol,\n                               check_input=False)\n        assert_allclose(out, true_coefs, rtol=0, atol=atol)\n\n        out = ridge_regression(X_testing, y, alpha=alpha,\n                               solver=solver,\n                               sample_weight=None,\n                               return_intercept=True,\n                               tol=tol,\n                               check_input=False)\n        assert_allclose(out[0], true_coefs, rtol=0, atol=atol)\n        assert_allclose(out[1], true_intercept, rtol=0, atol=atol)\n\n        out = ridge_regression(X_testing, y, alpha=alpha,\n                               solver=solver,\n                               sample_weight=None,\n                               return_intercept=False,\n                               tol=tol,\n                               check_input=True)\n        assert_allclose(out, true_coefs, rtol=0, atol=atol)\n\n        out = ridge_regression(X_testing, y, alpha=alpha,\n                               solver=solver,\n                               sample_weight=None,\n                               return_intercept=True,\n                               tol=tol,\n                               check_input=True)\n        assert_allclose(out[0], true_coefs, rtol=0, atol=atol)\n        assert_allclose(out[1], true_intercept, rtol=0, atol=atol)\n"], "sample_1110": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n    assert not prntr.module_imports\n\n    assert prntr.doprint(pi) == 'math.pi'\n    assert prntr.module_imports == {'math': {'pi'}}\n\n    assert prntr.doprint(x**Rational(1, 2)) == 'math.sqrt(x)'\n    assert prntr.doprint(sqrt(x)) == 'math.sqrt(x)'\n    assert prntr.module_imports == {'math': {'pi', 'sqrt'}}\n\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n    assert prntr.doprint(KroneckerDelta(x,y)) == '(1 if x == y else 0)'\n"], "sample_1065": ["def test_subfactorial_rewrite():\n    x = Symbol('x')\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True, nonnegative=True)\n\n    assert subfactorial(x).rewrite(factorial) == subfactorial(x)\n    assert subfactorial(n).rewrite(factorial) == subfactorial(n)\n    assert subfactorial(k).rewrite(factorial) == subfactorial(k)\n    assert subfactorial(x).rewrite(gamma) == subfactorial(x)\n    assert subfactorial(n).rewrite(gamma) == subfactorial(n)\n    assert subfactorial(k).rewrite(gamma) == subfactorial(k)\n    assert subfactorial(x).rewrite(uppergamma) == uppergamma(x + 1, -1)/S.Exp1\n    assert subfactorial(n).rewrite(uppergamma) == uppergamma(n + 1, -1)/S.Exp1\n    assert subfactorial(k).rewrite(uppergamma) == uppergamma(k + 1, -1)/S.Exp1\n"], "sample_1055": ["def test_encipher_decipher_elgamal():\n    ps = [131, 137, 139, 149, 151, 157, 163, 167,\n          173, 179, 181, 191, 193, 197, 199]\n    messages = [\n        0, 32855, 34303, 14805, 1280, 75859, 38368,\n        724, 60356, 51675, 76697, 61854, 18661,\n    ]\n    for p in ps:\n        pri = elgamal_private_key(p)\n        for msg in messages:\n            pub = elgamal_public_key(pri)\n            enc = encipher_elgamal(msg, pub)\n            dec = decipher_elgamal(enc, pri)\n            assert dec == msg\n"], "sample_311": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.s1 = Section.objects.create(name='Test section')\n        cls.a1 = Article.objects.create(\n            content='<p>Middle content</p>', date=datetime.datetime(2008, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a2 = Article.objects.create(\n            content='<p>Oldest content</p>', date=datetime.datetime(2000, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a3 = Article.objects.create(\n            content='<p>Newest content</p>', date=datetime.datetime(2009, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n"], "sample_317": ["def test_rss_feed_with_empty_description(self):\n    \"\"\"\n    Test the structure and content of feeds generated by Rss201rev2Feed\n    when the description is empty.\n    \"\"\"\n    response = self.client.get('/syndication/rss2-empty-description/')\n    doc = minidom.parseString(response.content)\n\n    # Making sure there's only 1 `rss` element and that the correct\n    # RSS version was specified.\n    feed_elem = doc.getElementsByTagName('rss')\n    self.assertEqual(len(feed_elem), 1)\n    feed = feed_elem[0]\n    self.assertEqual(feed.getAttribute('version'), '2.0')\n    self.assertEqual(feed.getElementsByTagName('language')[0].firstChild.nodeValue, 'en')\n\n    # Making sure there's only one `channel` element w/in the\n    # `rss` element.\n    chan_elem = feed.getElementsByTagName('channel')\n    self.assertEqual(len(chan_elem), 1)\n    chan = chan_elem[0]\n\n    # Find the last build date\n    d = Entry.objects.latest('published').published\n    last_build_date = rfc2822_date(timezone.make_aware(d, TZ))\n\n    self.assertChildNodes(\n        chan, [\n            'title', 'link', 'description', 'language', 'lastBuildDate',\n            'item', 'atom:link', 'ttl', 'copyright', 'category',\n        ]\n    )\n    self.assertChildNodeContent(chan, {\n        'title': 'My blog',\n        'link': 'http://example.com/blog/',\n        'language': 'en',\n        'lastBuildDate': last_build_date,\n        'ttl': '600',\n        'copyright': 'Copyright (c) 2007, Sally Smith',\n    })\n    self.assertCategories(chan, ['python', 'django'])\n\n    # Ensure the content of the channel is correct\n    self.assertChildNodeContent(chan, {\n        'title': 'My blog',\n        'link': 'http://example.com/blog/',\n    })\n\n    # Check feed_url is passed\n    self.assertEqual(\n        chan.getElementsByTagName('atom:link')[0].getAttribute('href'),\n        'http://example.com/syndication/rss2-empty-description/'\n    )\n\n    # Find the pubdate of the first feed item\n    d = Entry.objects.get(pk=self.e1.pk).published\n    pub_date = rfc2822_date(timezone.make_aware(d, TZ))\n\n    items = chan.getElementsByTagName('item')\n    self.assertEqual(len(items),"], "sample_616": ["def test_cross_with_missing_values() -> None:\n    a = xr.DataArray(\n        np.array([1, 2, np.nan]),\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    b = xr.DataArray(\n        np.array([4, 5, 6]),\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    expected = np.array([12, -6, np.nan])\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n"], "sample_28": ["def test_record_valued_keyword_cards_with_hierarch_keywords(self):\n    \"\"\"\n    Regression test for https://github.com/astropy/astropy/issues/11485\n\n    Test that record-valued keyword cards can be used with HIERARCH keywords.\n    \"\"\"\n\n    header = fits.Header()\n    header.set(\"HIERARCH DP1\", \"NAXIS: 2\")\n    header.set(\"HIERARCH DP1\", \"AXIS.1: 1\")\n    header.set(\"HIERARCH DP1\", \"AXIS.2: 2\")\n    header.set(\"HIERARCH DP1\", \"NAUX:   2\")\n    header.set(\"HIERARCH DP1\", \"AUX.1.COEFF.0: 0\")\n    header.set(\"HIERARCH DP1\", \"AUX.1.POWER.0: 1\")\n    header.set(\"HIERARCH DP1\", \"AUX.1.COEFF.1: 0.00048828125\")\n    header.set(\"HIERARCH DP1\", \"AUX.1.POWER.1:  1\")\n\n    assert header[\"HIERARCH DP1.NAXIS\"] == 2.0\n    assert header[\"HIERARCH DP1.AXIS.1\"] == 1.0\n    assert header[\"HIERARCH DP1.AXIS.2\"] == 2.0\n    assert header[\"HIERARCH DP1.NAUX\"] == 2.0\n    assert header[\"HIERARCH DP1.AUX.1.COEFF.0\"] == 0.0\n    assert header[\"HIERARCH DP1.AUX.1.POWER.0\"] == 1.0\n    assert header[\"HIERARCH DP1.AUX.1.COEFF.1\"] == 0.00048828125\n    assert header[\"HIERARCH DP1.AUX.1.POWER.1\"] == 1.0\n\n    header[\"HIERARCH DP1.NAXIS\"] = 3\n    assert header[\"HIERARCH DP1.NAXIS\"] == 3.0\n\n    del header[\"HIERARCH DP1.NAXIS\"]\n    assert \"HIERARCH DP1.NAXIS\" not in header\n"], "sample_734": ["def test_contingency_matrix_edge_cases():\n    # Test edge cases for contingency_matrix\n    # Test with empty arrays\n    assert_array_almost_equal(contingency_matrix([], [], sparse=False),\n                              np.array([[0]]))\n    assert_array_almost_equal(contingency_matrix([], [], sparse=True).toarray(),\n                              np.array([[0]]))\n\n    # Test with single element arrays\n    assert_array_almost_equal(contingency_matrix([0], [0], sparse=False),\n                              np.array([[1]]))\n    assert_array_almost_equal(contingency_matrix([0], [0], sparse=True).toarray(),\n                              np.array([[1]]))\n\n    # Test with identical arrays\n    assert_array_almost_equal(contingency_matrix([0, 0], [0, 0], sparse=False),\n                              np.array([[2]]))\n    assert_array_almost_equal(contingency_matrix([0, 0], [0, 0], sparse=True).toarray(),\n                              np.array([[2]]))\n\n    # Test with different arrays\n    assert_array_almost_equal(contingency_matrix([0, 0], [1, 1], sparse=False),\n                              np.array([[0, 2], [0, 0]]))\n    assert_array_almost_equal(contingency_matrix([0, 0], [1, 1], sparse=True).toarray(),\n                              np.array([[0, 2], [0, 0]]))\n"], "sample_936": ["def test_stringify_ForwardRef():\n    if sys.version_info >= (3, 7):\n        from typing import ForwardRef\n        assert stringify(ForwardRef('int')) == \"int\"\n        assert stringify(ForwardRef('str')) == \"str\"\n        assert stringify(ForwardRef('List[int]')) == \"List[int]\"\n        assert stringify(ForwardRef('Tuple[str, str]')) == \"Tuple[str, str]\"\n    else:\n        from sphinx.util.typing import ForwardRef\n        assert stringify(ForwardRef('int')) == \"int\"\n        assert stringify(ForwardRef('str')) == \"str\"\n        assert stringify(ForwardRef('List[int]')) == \"List[int]\"\n        assert stringify(ForwardRef('Tuple[str, str]')) == \"Tuple[str, str]\"\n"], "sample_99": ["def test_trunc_timezone_with_dst_transition(self):\n    sao = pytz.timezone('America/Sao_Paulo')\n    start_datetime = datetime(2016, 10, 16, 1, 30, 50, 321)\n    end_datetime = datetime(2016, 2, 21, 1, 30, 50, 123)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=DateTimeField(), tzinfo=sao)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(sao), kind, sao)),\n                (end_datetime, truncate_to(end_datetime.astimezone(sao), kind, sao))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_date', kind, output_field=DateField(), tzinfo=sao)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.date(), kind)),\n                (end_datetime, truncate_to(end_datetime.date(), kind))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_time', kind, output_field=TimeField(), tzinfo=sao)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.time(), kind)),\n                (end_datetime, truncate_to(end_datetime.time(), kind))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_date_kind('year')\n    test_date_kind('quarter')\n    test_date_kind('month')\n    test_date_kind('week')\n    test_date_kind('day')\n    test_time_kind('hour')\n    test_time_kind('minute')\n    test_time_kind('second')\n    test_datetime_kind('year')\n    test_datetime_kind('quarter')\n    test_datetime_kind('month')\n    test_datetime_kind('week')\n    test_datetime_kind('day')\n    test_datetime"], "sample_67": ["    def test_model_form_with_model_field(self):\n        class ModelFieldForm(forms.ModelForm):\n            class Meta:\n                model = CustomFieldForExclusionModel\n                fields = '__all__'\n\n        form = ModelFieldForm()\n        self.assertEqual(list(form.fields), ['name', 'markup'])\n        self.assertIsInstance(form.fields['name'], forms.CharField)\n        self.assertIsInstance(form.fields['markup'], forms.CharField)\n"], "sample_140": ["    def test_sensitive_variables_called_without_args(self):\n        @sensitive_variables()\n            pass\n        self.assertEqual(test_func.sensitive_variables, '__ALL__')\n"], "sample_125": ["    def test_reason_phrase(self):\n        response = HttpResponse()\n        self.assertEqual(response.reason_phrase, 'OK')\n        response.reason_phrase = 'Custom Reason'\n        self.assertEqual(response.reason_phrase, 'Custom Reason')\n"], "sample_483": ["def test_check_ordering_random(self):\n    class SongAdmin(admin.ModelAdmin):\n        ordering = [\"?\", \"title\"]\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'ordering' has the random ordering marker '?', but contains \"\n            \"other fields as well.\",\n            obj=SongAdmin,\n            id=\"admin.E032\",\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_169": ["    def test_xml_serialization(self):\n        test_xml_data = (\n            '<django-objects version=\"1.0\">'\n            '<object model=\"model_fields.jsonmodel\">'\n            '<field name=\"value\" type=\"JSONField\">%s'\n            '</field></object></django-objects>'\n        )\n        for value, serialized in TestSerialization.test_values:\n            with self.subTest(value=value):\n                instance = JSONModel(value=value)\n                data = serializers.serialize('xml', [instance], fields=['value'])\n                self.assertXMLEqual(data, test_xml_data % serialized)\n                new_instance = list(serializers.deserialize('xml', data))[0].object\n                self.assertEqual(new_instance.value, instance.value)\n"], "sample_458": ["    def test_addslashes(self):\n        self.assertEqual(addslashes(\"Hello, 'world'!\"), \"Hello, \\\\'world\\'!\")\n"], "sample_1187": ["def test_hyperplane_parameters():\n    triangle = Polygon(Point(0, 3), Point(5, 3), Point(1, 1))\n    assert hyperplane_parameters(triangle) == [((0, 1), 3), ((1, -2), -1), ((-2, -1), -3)]\n\n    cube = [[(0, 0, 0), (0, 0, 5), (0, 5, 0), (0, 5, 5), (5, 0, 0),\\\n             (5, 0, 5), (5, 5, 0), (5, 5, 5)],\\\n            [2, 6, 7, 3], [3, 7, 5, 1], [7, 6, 4, 5], [1, 5, 4, 0],\\\n            [3, 1, 0, 2], [0, 4, 6, 2]]\n    vertices = cube[0]\n    faces = cube[1:]\n    assert hyperplane_parameters(faces, vertices) == [([0, -1, 0], -5), ([0, 0, -1], -5), ([-1, 0, 0], -5),\n                                                    ([0, 1, 0], 0), ([1, 0, 0], 0), ([0, 0, 1], 0)]\n"], "sample_808": ["def test_iforest_predict_with_offset():\n    X_train = [[1, 1], [1, 2], [2, 1]]\n    clf1 = IsolationForest(contamination=0.1).fit(X_train)\n    clf2 = IsolationForest(contamination=0.5).fit(X_train)\n    assert_array_equal(clf1.predict([[2., 2.]]),\n                       clf2.predict([[2., 2.]]))\n    assert_array_equal(clf1.predict([[2., 2.]]),\n                       np.ones(1, dtype=int))\n"], "sample_867": ["def test_grid_search_cv_results_with_sample_weight():\n    # Test GridSearchCV with sample weights\n    X, y = make_classification(n_samples=50, n_features=4, random_state=42)\n    sample_weight = np.random.rand(50)\n\n    n_splits = 3\n    params = [dict(kernel=['rbf', ], C=[1, 10], gamma=[0.1, 1]),\n              dict(kernel=['poly', ], degree=[1, 2])]\n\n    param_keys = ('param_C', 'param_degree', 'param_gamma', 'param_kernel')\n    score_keys = ('mean_test_score', 'mean_train_score',\n                  'rank_test_score',\n                  'split0_test_score', 'split1_test_score',\n                  'split2_test_score',\n                  'split0_train_score', 'split1_train_score',\n                  'split2_train_score',\n                  'std_test_score', 'std_train_score',\n                  'mean_fit_time', 'std_fit_time',\n                  'mean_score_time', 'std_score_time')\n    n_candidates = 6\n\n    grid_search = GridSearchCV(SVC(), cv=n_splits, param_grid=params,\n                               return_train_score=True)\n    grid_search.fit(X, y, sample_weight=sample_weight)\n    cv_results = grid_search.cv_results_\n    # Check if score and timing are reasonable\n    assert all(cv_results['rank_test_score'] >= 1)\n    assert (all(cv_results[k] >= 0) for k in score_keys\n            if k != 'rank_test_score')\n    assert (all(cv_results[k] <= 1) for k in score_keys\n            if 'time' not in k and\n            k != 'rank_test_score')\n    # Check cv_results structure\n    check_cv_results_array_types(grid_search, param_keys, score_keys)\n    check_cv_results_keys(cv_results, param_keys, score_keys, n_candidates)\n    # Check masking\n    cv_results = grid_search.cv_results_\n    n_candidates = len(grid_search.cv_results_['params'])\n    assert all((cv_results['param_C'].mask[i] and\n                cv_results['param_gamma'].mask[i] and\n                not cv_results['param_degree'].mask[i])\n               for i in range(n_candidates)\n               if cv_results['param_kernel'][i] == 'linear')\n    assert all((not cv_results['param_C'].mask[i] and\n                not cv_results['param_gamma'].mask[i] and"], "sample_519": ["def test_subfigure_dpi_change():\n    fig = plt.figure(dpi=100)\n    sub_fig = fig.subfigures()\n    assert sub_fig.get_dpi() == fig.get_dpi()\n\n    sub_fig.set_dpi(200)\n    assert sub_fig.get_dpi() == 200\n    assert fig.get_dpi() == 200\n\n    fig.set_dpi(300)\n    assert sub_fig.get_dpi() == 300\n    assert fig.get_dpi() == 300\n"], "sample_851": ["def test_mean_poisson_deviance():\n    y_true = np.array([2, 0, 1, 4])\n    y_pred = np.array([0.5, 0.5, 2., 2.])\n    assert_almost_equal(mean_poisson_deviance(y_true, y_pred),\n                        mean_tweedie_deviance(y_true, y_pred, power=1))\n\n    y_true = np.array([2, 0, 1, 4])\n    y_pred = np.array([0.5, 0.5, 2., 2.])\n    sample_weight = np.array([0.1, 0.2, 0.3, 0.4])\n    assert_almost_equal(mean_poisson_deviance(y_true, y_pred, sample_weight),\n                        mean_tweedie_deviance(y_true, y_pred, sample_weight, power=1))\n\n    y_true = np.array([2, 0, 1, 4])\n    y_pred = np.array([0.5, 0.5, 2., 2.])\n    with pytest.raises(ValueError,\n                       match=\"Mean Poisson deviance error can only be used on \"\n                             \"non-negative y_true and strictly positive y_pred.\"):\n        mean_poisson_deviance(y_true, np.array([0., 0.5, 2., 2.]))\n\n    y_true = np.array([2, 0, 1, 4])\n    y_pred = np.array([0.5, 0.5, 2., 2.])\n    with pytest.raises(ValueError,\n                       match=\"Mean Poisson deviance error can only be used on \"\n                             \"non-negative y_true and strictly positive y_pred.\"):\n        mean_poisson_deviance(np.array([-2, 0, 1, 4]), y_pred)\n\n"], "sample_32": ["    def test_de_density_scale_at_zero(self, cosmo):\n        \"\"\"Test :meth:`astropy.cosmology.w0wzCDM.de_density_scale` at z=0.\"\"\"\n        assert u.allclose(cosmo.de_density_scale(0), 1.0)\n"], "sample_945": ["def test_type_to_xref(app):\n    text = \"int\"\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, pending_xref, refdomain=\"py\", reftype=\"class\", reftarget=\"int\")\n\n    text = \"List[int]\"\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"List\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \"]\"]),\n                refdomain=\"py\", reftype=\"class\", reftarget=\"List[int]\")\n\n    text = \"Tuple[int, int]\"\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"Tuple\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \", \"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \"]\"]),\n                refdomain=\"py\", reftype=\"class\", reftarget=\"Tuple[int, int]\")\n\n    text = \"Tuple[()]\"  # empty tuple\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"Tuple\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [desc_sig_punctuation, \"(\"],\n                          [desc_sig_punctuation, \")\"],\n                          [desc_sig_punctuation, \"]\"]),\n                refdomain=\"py\", reftype=\"class\", reftarget=\"Tuple[()]\")\n\n    text = \"Tuple[int, ...]\"  # variable length tuple\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"Tuple\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \", \"],\n                          [desc_sig_punctuation, \"...\"],\n                          [desc_sig_punctuation, \"]\"]),\n                refdomain=\"py\", reftype=\"class\", reftarget=\"Tuple[int, ...]\")\n\n    text = \"Callable[[int, int], int]\"  # callable type\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"Callable\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [desc_sig"], "sample_90": ["    def test_model_form_with_custom_model(self):\n        class CustomModel(models.Model):\n            name = models.CharField(max_length=10)\n\n                return self.name\n\n        class CustomModelForm(forms.ModelForm):\n            class Meta:\n                model = CustomModel\n                fields = '__all__'\n\n        form = CustomModelForm({'name': 'Test'})\n        self.assertTrue(form.is_valid())\n        instance = form.save()\n        self.assertEqual(instance.name, 'Test')\n"], "sample_15": ["    def test_quantity_subclass(self):\n        q = u.Quantity(1, u.m)\n        assert q.__quantity_subclass__(u.m) == (Quantity, True)\n        assert q.__quantity_subclass__(u.dimensionless_unscaled) == (Quantity, True)\n        assert q.__quantity_subclass__(u.radian) == (Quantity, True)\n"], "sample_1083": ["def test_hyperbolic_functions_with_finite():\n    x = Symbol('x')\n    assert sinh(x).is_finite is None\n    assert cosh(x).is_finite is None\n    assert tanh(x).is_finite is None\n    assert coth(x).is_finite is None\n    assert csch(x).is_finite is None\n    assert sech(x).is_finite is None\n    assert asinh(x).is_finite is None\n    assert acosh(x).is_finite is None\n    assert atanh(x).is_finite is None\n    assert acoth(x).is_finite is None\n    assert asech(x).is_finite is None\n    assert acsch(x).is_finite is None\n\n    x = Symbol('x', finite=True)\n    assert sinh(x).is_finite is True\n    assert cosh(x).is_finite is True\n    assert tanh(x).is_finite is True\n    assert coth(x).is_finite is None\n    assert csch(x).is_finite is None\n    assert sech(x).is_finite is True\n    assert asinh(x).is_finite is True\n    assert acosh(x).is_finite is True\n    assert atanh(x).is_finite is True\n    assert acoth(x).is_finite is True\n    assert asech(x).is_finite is True\n    assert acsch(x).is_finite is True\n"], "sample_295": ["    def test_window_frame_start_end(self):\n        # Test that the start and end values are correctly formatted.\n        frame = RowRange()\n        self.assertEqual(frame.window_frame_start_end(connection, 0, 0), ('0', '0'))\n        self.assertEqual(frame.window_frame_start_end(connection, 1, 1), ('1', '1'))\n        self.assertEqual(frame.window_frame_start_end(connection, -1, -1), ('-1', '-1'))\n        self.assertEqual(frame.window_frame_start_end(connection, None, None), ('NULL', 'NULL'))\n\n        frame = ValueRange()\n        self.assertEqual(frame.window_frame_start_end(connection, 0, 0), ('0', '0'))\n        self.assertEqual(frame.window_frame_start_end(connection, 1, 1), ('1', '1'))\n        self.assertEqual(frame.window_frame_start_end(connection, -1, -1), ('-1', '-1'))\n        self.assertEqual(frame.window_frame_start_end(connection, None, None), ('NULL', 'NULL'))\n"], "sample_507": ["    def test_convert_empty_strings(self, value):\n        unit = cat.UnitData([value])\n        assert cat.StrCategoryConverter.convert(value, unit, None) == 0\n"], "sample_136": ["def test_get_signed_cookie(self):\n    request = HttpRequest()\n    request.COOKIES = {'signed_cookie': 'signed_value'}\n    with self.assertRaises(KeyError):\n        request.get_signed_cookie('signed_cookie')\n\n    request.COOKIES = {'signed_cookie': signing.get_cookie_signer(salt='salt').sign('signed_value')}\n    self.assertEqual(request.get_signed_cookie('signed_cookie', salt='salt'), 'signed_value')\n\n    request.COOKIES = {'signed_cookie': signing.get_cookie_signer(salt='salt').sign('signed_value')}\n    with self.assertRaises(signing.BadSignature):\n        request.get_signed_cookie('signed_cookie', salt='wrong_salt')\n\n    request.COOKIES = {'signed_cookie': signing.get_cookie_signer(salt='salt').sign('signed_value')}\n    self.assertEqual(request.get_signed_cookie('signed_cookie', default='default_value', salt='wrong_salt'), 'default_value')\n"], "sample_25": ["def test_record_valued_keyword_cards_with_hierarch_keywords(self):\n    \"\"\"\n    Regression test for https://github.com/astropy/astropy/issues/11299\n\n    Ensures that record-valued keyword cards can be used with HIERARCH keywords.\n    \"\"\"\n\n    h = fits.Header()\n    h[\"HIERARCH DP1.NAXIS\"] = 2\n    h[\"HIERARCH DP1.AXIS.1\"] = 1\n    h[\"HIERARCH DP1.AXIS.2\"] = 2\n    assert h[\"DP1.NAXIS\"] == 2.0\n    assert h[\"DP1.AXIS.1\"] == 1.0\n    assert h[\"DP1.AXIS.2\"] == 2.0\n    assert h[\"HIERARCH DP1.NAXIS\"] == 2.0\n    assert h[\"HIERARCH DP1.AXIS.1\"] == 1.0\n    assert h[\"HIERARCH DP1.AXIS.2\"] == 2.0\n"], "sample_684": ["    def test_cut(self) -> None:\n        try:\n                f2()\n\n                f3()\n\n                assert False\n\n            f1()\n        except AssertionError:\n            exci = ExceptionInfo.from_current()\n            tb = exci.traceback\n            assert len(tb) == 4\n            cut_tb = tb.cut(path=\"test_code.py\")\n            assert len(cut_tb) == 3\n            assert cut_tb[0].frame.code.name == \"f1\"\n            assert cut_tb[1].frame.code.name == \"f2\"\n            assert cut_tb[2].frame.code.name == \"f3\"\n"], "sample_657": ["def test_parameter_set_extract_from(testdir):\n    from _pytest.mark import ParameterSet\n\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"a\", [1, 2, 3])\n            pass\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=3)\n\n    # Test extract_from with a ParameterSet instance\n    param_set = ParameterSet((1, 2, 3), [], \"my_id\")\n    extracted = ParameterSet.extract_from(param_set)\n    assert extracted == param_set\n\n    # Test extract_from with a tuple\n    extracted = ParameterSet.extract_from((1, 2, 3))\n    assert extracted == ParameterSet((1, 2, 3), [], None)\n\n    # Test extract_from with a single value and force_tuple=True\n    extracted = ParameterSet.extract_from(1, force_tuple=True)\n    assert extracted == ParameterSet((1,), [], None)\n\n    # Test extract_from with a single value and force_tuple=False\n    extracted = ParameterSet.extract_from(1)\n    assert extracted == ParameterSet((1,), [], None)\n"], "sample_1091": ["def test_relational_canonical():\n    # Test that the canonical form of a relational expression is the same\n    # regardless of the order of its arguments.\n    for f in (Eq, Ne, Ge, Gt, Le, Lt):\n        for args in [(x, y), (y, x), (-x, y), (x, -y), (-x, -y)]:\n            assert f(*args).canonical == f(*args[::-1]).canonical\n"], "sample_789": ["def test_feature_importances():\n    # Check feature importances.\n    X, y = datasets.make_classification(n_samples=2000,\n                                        n_features=10,\n                                        n_informative=3,\n                                        n_redundant=0,\n                                        n_repeated=0,\n                                        shuffle=False,\n                                        random_state=1)\n\n    for alg in ['SAMME', 'SAMME.R']:\n        clf = AdaBoostClassifier(algorithm=alg)\n\n        clf.fit(X, y)\n        importances = clf.feature_importances_\n\n        assert_equal(importances.shape[0], 10)\n        assert_equal((importances[:3] >= importances[3:]).all(),\n                     True)\n\n    # Check that feature importances are not computed when base estimator\n    # does not support it\n    clf = AdaBoostClassifier(algorithm=alg, base_estimator=SVC())\n    clf.fit(X, y)\n    with assert_raises(AttributeError):\n        clf.feature_importances_\n"], "sample_690": ["def test_xfail_with_invalid_strict_value(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = invalid\n    \"\"\"\n    )\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(reason='unsupported feature')\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest(p, \"-rxX\")\n    result.stdout.fnmatch_lines([\"*ValueError: invalid literal for boolean*\"])\n"], "sample_708": ["def test_getstatementrange_with_nested_try_except() -> None:\n    source = Source(\n        \"\"\"\\"], "sample_856": ["def test_leave_p_groups_out_empty_trainset():\n    cv = LeavePGroupsOut(n_groups=2)\n    X, y = [[1], [2]], [0, 3]  # 2 samples\n    with pytest.raises(\n            ValueError,\n            match='The groups parameter contains fewer than (or equal to) '\n            'n_groups (2) numbers of unique groups (2). LeavePGroupsOut '\n            'expects that at least n_groups + 1 (3) unique groups be present'):\n        next(cv.split(X, y, groups=[1, 2]))\n"], "sample_751": ["def test_random_forest_classifier():\n    # Test random forest classifier.\n    X, y = datasets.make_classification(n_samples=100, n_features=10,\n                                        n_informative=3, n_redundant=0,\n                                        n_repeated=0, shuffle=False,\n                                        random_state=1)\n\n    clf = RandomForestClassifier(n_estimators=10, random_state=1)\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(X), y)\n\n    # Test with sample weights\n    sample_weight = np.random.rand(len(y))\n    clf.fit(X, y, sample_weight=sample_weight)\n    assert_array_equal(clf.predict(X), y)\n\n    # Test with class weights\n    clf.fit(X, y, class_weight='balanced')\n    assert_array_equal(clf.predict(X), y)\n\n    # Test with warm start\n    clf.set_params(warm_start=True)\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(X), y)\n\n    # Test with different criterion\n    clf.set_params(criterion='entropy')\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(X), y)\n\n    # Test with different max features\n    clf.set_params(max_features='sqrt')\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(X), y)\n\n    # Test with different max depth\n    clf.set_params(max_depth=5)\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(X), y)\n\n    # Test with different min samples split\n    clf.set_params(min_samples_split=5)\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(X), y)\n\n    # Test with different min samples leaf\n    clf.set_params(min_samples_leaf=5)\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(X), y)\n\n    # Test with different min weight fraction leaf\n    clf.set_params(min_weight_fraction_leaf=0.5)\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(X), y)\n\n    # Test with different max leaf nodes\n    clf.set_params(max_leaf_nodes=10)\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(X), y)\n\n    # Test with different min impurity decrease\n    clf.set_params(min_impurity_decrease=0.5)\n    clf.fit(X, y)\n    assert_array_equal(clf.predict(X), y)\n\n    # Test with different min impurity split"], "sample_529": ["def test_legend_draggable_update():\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label='shabnams')\n    leg = ax.legend(draggable=True)\n    assert leg.get_draggable()\n    leg.set_draggable(False, update='loc')\n    assert not leg.get_draggable()\n    leg.set_draggable(True, update='bbox')\n    assert leg.get_draggable()\n"], "sample_222": ["    def test_lock_unlock(self):\n        with tempfile.TemporaryFile() as f:\n            self.assertIs(locks.lock(f, locks.LOCK_EX), True)\n            self.assertIs(locks.unlock(f), True)\n"], "sample_1053": ["def test_issue_13470():\n    # Test that Float can be pickled and unpickled correctly\n    import pickle\n    a = Float('1.2')\n    b = pickle.loads(pickle.dumps(a))\n    assert a == b\n    assert a._mpf_ == b._mpf_\n    assert a._prec == b._prec\n"], "sample_852": ["def test_make_gaussian_quantiles():\n    X, y = make_gaussian_quantiles(n_samples=100, n_features=2, n_classes=3,\n                                   random_state=0)\n\n    assert X.shape == (100, 2), \"X shape mismatch\"\n    assert y.shape == (100,), \"y shape mismatch\"\n    assert np.unique(y).shape == (3,), \"Unexpected number of classes\"\n\n    X, y = make_gaussian_quantiles(n_samples=100, n_features=2, n_classes=3,\n                                   mean=[1, 2], cov=2, random_state=0)\n\n    assert X.shape == (100, 2), \"X shape mismatch\"\n    assert y.shape == (100,), \"y shape mismatch\"\n    assert np.unique(y).shape == (3,), \"Unexpected number of classes\"\n\n    X, y = make_gaussian_quantiles(n_samples=100, n_features=2, n_classes=3,\n                                   mean=[1, 2], cov=2, shuffle=False,\n                                   random_state=0)\n\n    assert X.shape == (100, 2), \"X shape mismatch\"\n    assert y.shape == (100,), \"y shape mismatch\"\n    assert np.unique(y).shape == (3,), \"Unexpected number of classes\"\n\n    with pytest.raises(ValueError):\n        make_gaussian_quantiles(n_samples=100, n_features=2, n_classes=3,\n                                mean=[1, 2, 3], cov=2, random_state=0)\n"], "sample_971": ["def test_get_node_location():\n    node = nodes.Node()\n    node.source, node.line = ('index.txt', 10)\n    assert logging.get_node_location(node) == 'index.txt:10'\n\n    node.source, node.line = ('index.txt', None)\n    assert logging.get_node_location(node) == 'index.txt:'\n\n    node.source, node.line = (None, 10)\n    assert logging.get_node_location(node) == '<unknown>:10'\n\n    node.source, node.line = (None, None)\n    assert logging.get_node_location(node) is None\n"], "sample_502": ["def test_subplot2grid():\n    fig, ax = plt.subplots()\n    ax1 = plt.subplot2grid((2, 2), (0, 0))\n    ax2 = plt.subplot2grid((2, 2), (0, 1))\n    ax3 = plt.subplot2grid((2, 2), (1, 0), colspan=2)\n    assert ax1 is plt.gca()\n    assert ax2 is plt.subplot2grid((2, 2), (0, 1))\n    assert ax3 is plt.subplot2grid((2, 2), (1, 0), colspan=2)\n    assert ax1 is not ax2\n    assert ax1 is not ax3\n    assert ax2 is not ax3\n    assert ax1 not in fig.axes\n    assert ax2 not in fig.axes\n    assert ax3 in fig.axes\n"], "sample_207": ["    def test_key_transform_factory(self):\n        field = models.JSONField()\n        transform = field.get_transform('key')\n        self.assertIsInstance(transform, KeyTransformFactory)\n        self.assertEqual(transform.key_name, 'key')\n"], "sample_250": ["def test_timezone_offset(self):\n    # Test that the timezone offset is correctly calculated for different timezones\n    tz_names = ['US/Pacific', 'Europe/London', 'Australia/Sydney']\n    for tz_name in tz_names:\n        tz = pytz.timezone(tz_name)\n        dt = datetime(2022, 1, 1, tzinfo=tz)\n        offset = dateformat.format(dt, 'O')\n        expected_offset = tz.utcoffset(dt).total_seconds() / 3600\n        self.assertEqual(int(offset[:3]), int(expected_offset))\n"], "sample_106": ["    def tearDown(self):\n        cache.clear()\n"], "sample_166": ["    def test_get_random_string_length(self):\n        length = 20\n        random_string = get_random_string(length)\n        self.assertEqual(len(random_string), length)\n"], "sample_769": ["def test_multilabel_confusion_matrix_multilabel_sample_weight():\n    # Test multilabel confusion matrix - multilabel-indicator case with sample weights\n    from scipy.sparse import csc_matrix, csr_matrix\n\n    y_true = np.array([[1, 0, 1], [0, 1, 0], [1, 1, 0]])\n    y_pred = np.array([[1, 0, 0], [0, 1, 1], [0, 0, 1]])\n    y_true_csr = csr_matrix(y_true)\n    y_pred_csr = csr_matrix(y_pred)\n    y_true_csc = csc_matrix(y_true)\n    y_pred_csc = csc_matrix(y_pred)\n\n    # cross test different types\n    sample_weight = np.array([2, 1, 3])\n    real_cm = [[[1, 0], [1, 1]],\n               [[1, 0], [1, 1]],\n               [[0, 2], [1, 0]]]\n    trues = [y_true, y_true_csr, y_true_csc]\n    preds = [y_pred, y_pred_csr, y_pred_csc]\n\n    for y_true_tmp in trues:\n        for y_pred_tmp in preds:\n            cm = multilabel_confusion_matrix(y_true_tmp, y_pred_tmp,\n                                             sample_weight=sample_weight)\n            assert_array_equal(cm, real_cm)\n\n    # test support for samplewise\n    cm = multilabel_confusion_matrix(y_true, y_pred, sample_weight=sample_weight,\n                                     samplewise=True)\n    assert_array_equal(cm, [[[1, 0], [1, 1]],\n                            [[1, 1], [0, 1]],\n                            [[0, 1], [2, 0]]])\n\n    # test support for labels\n    cm = multilabel_confusion_matrix(y_true, y_pred, labels=[2, 0],\n                                     sample_weight=sample_weight)\n    assert_array_equal(cm, [[[0, 2], [1, 0]],\n                            [[1, 0], [1, 1]]])\n\n    # test support for labels with samplewise\n    cm = multilabel_confusion_matrix(y_true, y_pred, labels=[2, 0],\n                                     sample_weight=sample_weight,\n                                     samplewise=True)\n    assert_array_equal(cm, [[[0, 0"], "sample_1127": ["def test_polycyclic_group():\n    a = Permutation([1, 2, 0])\n    b = Permutation([1, 0, 2])\n    G = PermutationGroup([a, b])\n    assert G.is_polycyclic\n    P = G.polycyclic_group()\n    assert P.order() == G.order()\n    assert P.is_polycyclic\n    assert P.is_solvable\n    assert P.is_nilpotent\n    assert P.is_abelian\n    assert P.is_cyclic\n    assert P.is_elementary(2)\n    assert P.is_perfect\n    assert P.is_trivial is False\n    assert P.is_transitive is False\n    assert P.is_primitive is False\n    assert P.is_symmetric is False\n    assert P.is_alternating is False\n    assert P.is_solvable\n    assert P.is_polycyclic\n    assert P.is_nilpotent\n    assert P.is_abelian\n    assert P.is_cyclic\n    assert P.is_elementary(2)\n    assert P.is_perfect\n    assert P.is_trivial is False\n    assert P.is_transitive is False\n    assert P.is_primitive is False\n    assert P.is_symmetric is False\n    assert P.is_alternating is False\n"], "sample_296": ["def test_not_finished_sentinel(self):\n    \"\"\"\n    The not_finished sentinel value is correctly handled when storing and\n    retrieving messages.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # Store a message and the not_finished sentinel value.\n    messages = [Message(constants.INFO, 'test'), CookieStorage.not_finished]\n    storage._store(messages, response)\n\n    # Retrieve the messages.\n    retrieved_messages, all_retrieved = storage._get()\n    self.assertEqual(retrieved_messages, [Message(constants.INFO, 'test')])\n    self.assertFalse(all_retrieved)\n\n    # Store another message.\n    storage.add(constants.INFO, 'another test')\n    storage.update(response)\n\n    # Retrieve the messages again.\n    retrieved_messages, all_retrieved = storage._get()\n    self.assertEqual(len(retrieved_messages), 2)\n    self.assertTrue(all_retrieved)\n"], "sample_748": ["def test_grid_search_with_empty_param_grid():\n    # Test grid search with an empty param grid\n    X, y = make_classification(n_samples=50, n_features=4, random_state=42)\n    clf = SVC(gamma='scale')\n    grid_search = GridSearchCV(clf, param_grid={}, cv=3)\n    grid_search.fit(X, y)\n    assert_equal(grid_search.best_params_, {})\n    assert_equal(grid_search.best_score_, grid_search.score(X, y))\n"], "sample_439": ["def test_form_with_custom_renderer(self):\n    class CustomRenderer(DjangoTemplates):\n        form_template_name = \"forms_tests/form_snippet.html\"\n\n    class CustomForm(Form):\n        default_renderer = CustomRenderer\n        first_name = CharField()\n        last_name = CharField()\n\n    t = Template(\"{{ form }}\")\n    html = t.render(Context({\"form\": CustomForm()}))\n    expected = \"\"\"\n    <div class=\"fieldWrapper\"><label for=\"id_first_name\">First name:</label>\n    <input type=\"text\" name=\"first_name\" required id=\"id_first_name\"></div>\n    <div class=\"fieldWrapper\"><label for=\"id_last_name\">Last name:</label>\n    <input type=\"text\" name=\"last_name\" required id=\"id_last_name\"></div>\n    \"\"\"\n    self.assertHTMLEqual(html, expected)\n"], "sample_445": ["def test_time_strings_customization(self):\n    \"\"\"\n    Test that the time_strings parameter can be used to customize the output.\n    \"\"\"\n    custom_time_strings = {\n        \"year\": ngettext_lazy(\"%(num)d year ago\", \"%(num)d years ago\", \"num\"),\n        \"month\": ngettext_lazy(\"%(num)d month ago\", \"%(num)d months ago\", \"num\"),\n        \"week\": ngettext_lazy(\"%(num)d week ago\", \"%(num)d weeks ago\", \"num\"),\n        \"day\": ngettext_lazy(\"%(num)d day ago\", \"%(num)d days ago\", \"num\"),\n        \"hour\": ngettext_lazy(\"%(num)d hour ago\", \"%(num)d hours ago\", \"num\"),\n        \"minute\": ngettext_lazy(\"%(num)d minute ago\", \"%(num)d minutes ago\", \"num\"),\n    }\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneminute, time_strings=custom_time_strings),\n        \"1\\xa0minute ago\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.onehour, time_strings=custom_time_strings),\n        \"1\\xa0hour ago\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneday, time_strings=custom_time_strings),\n        \"1\\xa0day ago\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneweek, time_strings=custom_time_strings),\n        \"1\\xa0week ago\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.onemonth, time_strings=custom_time_strings),\n        \"1\\xa0month ago\",\n    )\n    self.assertEqual(\n        timesince(self.t, self.t + self.oneyear, time_strings=custom_time_strings),\n        \"1\\xa0year ago\",\n    )\n"], "sample_268": ["    def test_enable_echo(self, mocked_termios):\n        mocked_termios.tcgetattr.return_value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n        mocked_termios.tcsetattr.return_value = None\n        autoreload.ensure_echo_on()\n        mocked_termios.tcgetattr.assert_called_once_with(sys.stdin)\n        mocked_termios.tcsetattr.assert_called_once_with(sys.stdin, mocked_termios.TCSANOW, [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 | mocked_termios.ECHO])\n"], "sample_599": ["def test_UnsignedIntegerCoder_encode():\n    original = xr.Variable((\"x\",), np.arange(10, dtype=np.uint8), encoding={\"_Unsigned\": \"true\"})\n    coder = variables.UnsignedIntegerCoder()\n    encoded = coder.encode(original)\n    expected = xr.Variable((\"x\",), np.arange(10, dtype=np.int8), encoding={})\n    assert_identical(encoded, expected)\n\n"], "sample_229": ["def test_union_with_values_list_and_order_by_alias(self):\n    ReservedName.objects.bulk_create([\n        ReservedName(name='rn1', order=7),\n        ReservedName(name='rn2', order=5),\n        ReservedName(name='rn0', order=6),\n        ReservedName(name='rn9', order=-1),\n    ])\n    qs1 = ReservedName.objects.filter(order__gte=6).values('order').annotate(alias=F('order'))\n    qs2 = ReservedName.objects.filter(order__lte=5).values('order').annotate(alias=F('order'))\n    union_qs = qs1.union(qs2)\n    for qs, expected_result in (\n        # Order by a single column.\n        (union_qs.order_by('-alias').values_list('order', flat=True), [-1, 6, 5, 7]),\n        (union_qs.order_by('alias').values_list('order', flat=True), [7, 5, 6, -1]),\n        (union_qs.values_list('order', flat=True).order_by('-alias'), [-1, 6, 5, 7]),\n        (union_qs.values_list('order', flat=True).order_by('alias'), [7, 5, 6, -1]),\n        # Order by multiple columns.\n        (union_qs.order_by('-name', 'alias').values_list('order', flat=True), [-1, 5, 7, 6]),\n        (union_qs.values_list('order', flat=True).order_by('-name', 'alias'), [-1, 5, 7, 6]),\n    ):\n        with self.subTest(qs=qs):\n            self.assertEqual(list(qs), expected_result)\n"], "sample_1108": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((1, 2, 3))) == [(1, 2, 3), (-1, 2, 3), (1, -2, 3), (-1, -2, 3), (1, 2, -3), (-1, 2, -3), (1, -2, -3), (-1, -2, -3)]\n    assert list(permute_signs((1, 0, 0))) == [(1, 0, 0), (-1, 0, 0)]\n    assert list(permute_signs((0, 0, 0))) == [(0, 0, 0)]\n    assert list(permute_signs(())) == [()]\n"], "sample_946": ["def test_type_to_xref(app):\n    text = \"int\"\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, pending_xref, refdomain=\"py\", reftype=\"class\", reftarget=\"int\")\n\n    text = \"None\"\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, pending_xref, refdomain=\"py\", reftype=\"obj\", reftarget=\"None\")\n\n    text = \"List[int]\"\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"List\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \"]\"]),\n                refdomain=\"py\", reftype=\"class\", reftarget=\"List[int]\")\n\n    text = \"Tuple[int, int]\"\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"Tuple\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \", \"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \"]\"]),\n                refdomain=\"py\", reftype=\"class\", reftarget=\"Tuple[int, int]\")\n\n    text = \"Tuple[()]\"  # empty tuple\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"Tuple\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [desc_sig_punctuation, \"(\"],\n                          [desc_sig_punctuation, \")\"],\n                          [desc_sig_punctuation, \"]\"]),\n                refdomain=\"py\", reftype=\"class\", reftarget=\"Tuple[()]\")\n\n    text = \"Tuple[int, ...]\"  # variable length tuple\n    doctree = type_to_xref(text, app.env)\n    assert_node(doctree, ([pending_xref, \"Tuple\"],\n                          [desc_sig_punctuation, \"[\"],\n                          [pending_xref, \"int\"],\n                          [desc_sig_punctuation, \", \"],\n                          [desc_sig_punctuation, \"...\"],\n                          [desc_sig_punctuation, \"]\"]),\n                refdomain=\"py\", reftype=\"class\", reftarget=\"Tuple[int, ...]\")\n\n    text = \"Callable[[int, int], int]\""], "sample_1150": ["def test_ComplexRegion_polar_intersect():\n    # Polar form\n    c1 = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)\n    c2 = ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    c3 = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi), polar=True)\n    c4 = ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n\n    p1 = Union(Interval(0, 1)*Interval(0, 2*S.Pi), Interval(0, 1)*Interval(0, S.Pi))\n    p2 = Union(Interval(0, oo)*Interval(0, S.Pi), Interval(0, oo)*Interval(S.Pi, 2*S.Pi))\n\n    assert c1.intersect(c2) == ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    assert c3.intersect(c4) == ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n\n    # Rectangular form\n    c5 = ComplexRegion(Interval(2, 5)*Interval(6, 9))\n    c6 = ComplexRegion(Interval(4, 6)*Interval(10, 12))\n    c7 = ComplexRegion(Interval(0, 10)*Interval(-10, 0))\n    c8 = ComplexRegion(Interval(12, 16)*Interval(14, 20))\n\n    p3 = Union(Interval(2, 5)*Interval(6, 9), Interval(4, 6)*Interval(10, 12))\n    p4 = Union(Interval(0, 10)*Interval(-10, 0), Interval(12, 16)*Interval(14, 20))\n\n    assert c5.intersect(c6) == ComplexRegion(Interval(4, 5)*Interval(10, 9))\n    assert c7.intersect(c8) == ComplexRegion(Interval(12, 10)*Interval(14, 0))\n\n    assert c1.intersect(Interval(2, 4)) == Intersection(c1, Interval(2, 4), evaluate=False)\n    assert c5.intersect(Interval(2, "], "sample_565": ["def test_inset_axes_with_bbox_transform():\n    fig, ax = plt.subplots(figsize=[5, 4])\n\n    # prepare the demo image\n    # Z is a 15x15 array\n    Z = cbook.get_sample_data(\"axes_grid/bivariate_normal.npy\")\n    extent = (-3, 4, -4, 3)\n    Z2 = np.zeros((150, 150))\n    ny, nx = Z.shape\n    Z2[30:30+ny, 30:30+nx] = Z\n\n    ax.imshow(Z2, extent=extent, interpolation=\"nearest\",\n              origin=\"lower\")\n\n    # creating our inset axes with a bbox_transform parameter\n    axins = inset_axes(ax, width=\"30%\", height=\"40%\",\n                       bbox_to_anchor=(0.5, 0.5, 0.5, 0.5),\n                       bbox_transform=ax.transAxes)\n\n    axins.imshow(Z2, extent=extent, interpolation=\"nearest\",\n                 origin=\"lower\")\n    axins.yaxis.get_major_locator().set_params(nbins=7)\n    axins.xaxis.get_major_locator().set_params(nbins=7)\n    # sub region of the original image\n    x1, x2, y1, y2 = -1.5, -0.9, -2.5, -1.9\n    axins.set_xlim(x1, x2)\n    axins.set_ylim(y1, y2)\n\n    plt.xticks(visible=False)\n    plt.yticks(visible=False)\n\n    # draw a bbox of the region of the inset axes in the parent axes and\n    # connecting lines between the bbox and the inset axes area\n    mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n\n    fig.canvas.draw()\n    assert_array_almost_equal(\n        axins.get_position().extents,\n        [0.35, 0.3, 0.45, 0.5])\n"], "sample_910": ["def test_log_collector(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    collector = logging.LogCollector()\n\n    with collector.collect():\n        logger.info('message1')\n        logger.warning('message2')\n        logger.error('message3')\n\n    assert len(collector.logs) == 3\n    assert collector.logs[0].levelname == 'INFO'\n    assert collector.logs[0].message == 'message1'\n    assert collector.logs[1].levelname == 'WARNING'\n    assert collector.logs[1].message == 'message2'\n    assert collector.logs[2].levelname == 'ERROR'\n    assert collector.logs[2].message == 'message3'\n"], "sample_951": ["def test_isabstractmethod():\n    class AbstractClass:\n        @abstractmethod\n            pass\n\n    class ConcreteClass(AbstractClass):\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(ConcreteClass.abstract_method) is False\n    assert inspect.isabstractmethod(AbstractClass) is False\n    assert inspect.isabstractmethod(ConcreteClass) is False\n"], "sample_783": ["def test_imputation_error_sparse_input(strategy):\n    # check that error are raised when input is sparse and missing_values != 0\n    X = np.ones((3, 5))\n    X[0] = 0\n    X = sparse.csc_matrix(X)\n\n    imputer = SimpleImputer(strategy=strategy, missing_values=0)\n    with pytest.raises(ValueError, match=\"Provide a dense array\"):\n        imputer.fit(X)\n\n    imputer.fit(X.toarray())\n    with pytest.raises(ValueError, match=\"Provide a dense array\"):\n        imputer.transform(X)\n"], "sample_173": ["def test_adapt_decimalfield_value(self):\n    value = decimal.Decimal('3.14')\n    max_digits = 5\n    decimal_places = 2\n    self.assertEqual(\n        self.ops.adapt_decimalfield_value(value, max_digits, decimal_places),\n        utils.format_number(value, max_digits, decimal_places)\n    )\n"], "sample_475": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n"], "sample_1051": ["def test_dotprint_atom():\n    text = dotprint(x+2, atom=lambda x: not x.is_Atom)\n    assert all(e in text for e in dotedges(x+2, atom=lambda x: not x.is_Atom))\n    assert all(n in text for n in [dotnode(expr) for expr in (x, Integer(2), x+2)])\n    assert 'digraph' in text\n    text = dotprint(x+x**2, atom=lambda x: not x.is_Atom)\n    assert all(e in text for e in dotedges(x+x**2, atom=lambda x: not x.is_Atom))\n    assert all(n in text for n in [dotnode(expr) for expr in (x, Integer(2), x**2, x+x**2)])\n    assert 'digraph' in text\n"], "sample_366": ["    def test_parse_date_with_leading_trailing_whitespace(self):\n        self.assertEqual(parse_date('  2012-04-23  '), date(2012, 4, 23))\n"], "sample_163": ["    def test_login_view_get(self):\n        response = self.client.get(\"/login/\")\n        self.assertEqual(response.status_code, 200)\n        self.assertIsInstance(response.context[\"form\"], AuthenticationForm)\n"], "sample_510": ["def test_xkcd_context_manager():\n    with plt.xkcd():\n        fig = plt.figure()\n        assert fig.get_edgecolor() == 'black'\n        assert fig.get_facecolor() == 'white'\n    fig = plt.figure()\n    assert fig.get_edgecolor() != 'black'\n    assert fig.get_facecolor() != 'white'\n"], "sample_393": ["    def test_locale_path_with_trailing_slash(self):\n        with override_settings(LOCALE_PATHS=[\"locale/\"]):\n            management.call_command(\"makemessages\", locale=[LOCALE], verbosity=0)\n            self.assertTrue(os.path.exists(self.PO_FILE))\n"], "sample_386": ["def test_mark_safe_decorator_on_callable_with_return_value_implementing_dunder_html(self):\n    \"\"\"\n    mark_safe used as a decorator on a callable that returns an object\n    implementing __html__() leaves the result unchanged.\n    \"\"\"\n\n    class HtmlObject:\n            return \"<html></html>\"\n\n        return HtmlObject()\n\n    self.assertIs(mark_safe(html_provider)(), HtmlObject())\n"], "sample_92": ["    def setUpTestData(cls):\n        cls.user = User.objects.create_user('test', 'test@example.com', 'test')\n"], "sample_508": ["def test_artist_inspector_properties():\n    \"\"\"Test ArtistInspector.properties() method.\"\"\"\n    class TestArtist(martist.Artist):\n            super().__init__()\n            self._test_property = 'test_value'\n\n            return self._test_property\n\n    ai = martist.ArtistInspector(TestArtist())\n    properties = ai.properties()\n    assert 'test_property' in properties\n    assert properties['test_property'] == 'test_value'\n"], "sample_891": ["def test_roc_auc_score_multiclass_average_error():\n    # Test that roc_auc_score function returns an error when trying\n    # to compute multiclass AUC for parameters where an output\n    # is not defined.\n    rng = check_random_state(404)\n    y_score = rng.rand(20, 3)\n    y_prob = softmax(y_score)\n    y_true = rng.randint(0, 3, size=20)\n    with pytest.raises(ValueError, match=\"average must be one of\"):\n        roc_auc_score(y_true, y_prob, average=\"invalid\")\n"], "sample_1085": ["def test_issue_12345():\n    # Test for issue 12345: Float should not lose precision when converting from Rational\n    from mpmath import mpf\n    from sympy import Rational\n    r = Rational(1, 10**100)\n    f = Float(r)\n    assert f._prec == 100\n    assert f._mpf_ == mpf(r)\n"], "sample_185": ["def test_get_format_modules_cache(self):\n    with translation.override('de', deactivate=True):\n        # Populate _format_modules_cache with temporary values\n        _format_modules_cache['de'] = ['module1', 'module2']\n        try:\n            self.assertEqual(get_format_modules(), ['module1', 'module2'])\n            self.assertEqual(get_format_modules(reverse=True), ['module2', 'module1'])\n        finally:\n            reset_format_cache()\n"], "sample_824": ["def test_check_pairwise_arrays_precomputed():\n    # Ensure that check_pairwise_arrays works correctly with precomputed\n    # distance matrices.\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((5, 5))\n    X_checked, _ = check_pairwise_arrays(X, None, precomputed=True)\n    assert_array_equal(X, X_checked)\n\n    # Ensure that check_pairwise_arrays raises an error when the input is not\n    # a square matrix.\n    X = rng.random_sample((5, 4))\n    assert_raises(ValueError, check_pairwise_arrays, X, None, precomputed=True)\n\n    # Ensure that check_pairwise_arrays raises an error when the input contains\n    # negative values.\n    X = rng.random_sample((5, 5))\n    X[0, 0] = -1\n    assert_raises(ValueError, check_pairwise_arrays, X, None, precomputed=True)\n"], "sample_0": ["def test_conversion_between_supported_types(UncertClass1, UncertClass2):\n    uncert = np.arange(1, 11).reshape(2, 5) * u.adu\n    start_uncert = UncertClass1(uncert)\n    final_uncert = start_uncert.represent_as(UncertClass2)\n    assert isinstance(final_uncert, UncertClass2)\n    assert_array_equal(start_uncert.array, final_uncert.array)\n    assert start_uncert.unit == final_uncert.unit\n\n"], "sample_811": ["def test_check_pairwise_arrays_dtype():\n    # Ensure that check_pairwise_arrays returns the correct dtype.\n    X = np.arange(40, dtype=np.float32).reshape(5, 8)\n    Y = np.arange(40, dtype=np.float64).reshape(5, 8)\n    X_checked, Y_checked = check_pairwise_arrays(X, Y)\n    assert_equal(X_checked.dtype, np.float)\n    assert_equal(Y_checked.dtype, np.float)\n\n    X = np.arange(40, dtype=np.float32).reshape(5, 8)\n    Y = None\n    X_checked, Y_checked = check_pairwise_arrays(X, Y)\n    assert_equal(X_checked.dtype, np.float32)\n    assert_equal(Y_checked.dtype, np.float32)\n"], "sample_130": ["def test_is_nullable(self):\n    query = Query(Item)\n    self.assertTrue(query.is_nullable(Item._meta.get_field('name')))\n    self.assertFalse(query.is_nullable(Item._meta.get_field('id')))\n"], "sample_754": ["def test_spca_invalid_input(spca):\n    rng = np.random.RandomState(0)\n    Y, _, _ = generate_toy_data(3, 10, (8, 8), random_state=rng)\n    with pytest.raises(ValueError):\n        spca(n_components=-1, random_state=rng).fit(Y)\n    with pytest.raises(ValueError):\n        spca(n_components=0, random_state=rng).fit(Y)\n    with pytest.raises(ValueError):\n        spca(alpha=-1, random_state=rng).fit(Y)\n    with pytest.raises(ValueError):\n        spca(ridge_alpha=-1, random_state=rng).fit(Y)\n    with pytest.raises(ValueError):\n        spca(max_iter=-1, random_state=rng).fit(Y)\n    with pytest.raises(ValueError):\n        spca(tol=-1, random_state=rng).fit(Y)\n    with pytest.raises(ValueError):\n        spca(method='invalid', random_state=rng).fit(Y)\n    with pytest.raises(ValueError):\n        spca(n_jobs=-1, random_state=rng).fit(Y)\n    with pytest.raises(ValueError):\n        spca(batch_size=-1, random_state=rng).fit(Y)\n    with pytest.raises(ValueError):\n        spca(n_iter=-1, random_state=rng).fit(Y)\n"], "sample_180": ["    def test_model_base_check(self):\n        class Model(models.Model):\n            class Meta:\n                abstract = True\n\n        self.assertEqual(Model.check(), [])\n"], "sample_772": ["def check_feature_importances_permutation(name):\n    # Test that feature importances are not affected by feature permutation.\n    ForestEstimator = FOREST_ESTIMATORS[name]\n    est = ForestEstimator(n_estimators=10, random_state=0)\n    est.fit(X_large, y_large)\n    importances = est.feature_importances_.copy()\n\n    # Permute features\n    idx = np.arange(X_large.shape[1])\n    np.random.shuffle(idx)\n    X_large_permuted = X_large[:, idx]\n\n    est.fit(X_large_permuted, y_large)\n    importances_permuted = est.feature_importances_\n\n    # Check importances are the same up to permutation\n    assert_array_almost_equal(importances[idx], importances_permuted)\n\n"], "sample_187": ["def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('hello'), 'hello')\n    self.assertEqual(text.camel_case_to_spaces(''), '')\n    self.assertEqual(text.camel_case_to_spaces(lazystr('HelloWorld')), 'hello world')\n"], "sample_365": ["def test_lazy_object_pickle(self):\n    \"\"\"lazy objects can be pickled.\"\"\"\n    import pickle\n    lazy_obj = lazy(lambda: 'test', str)()\n    pickled_obj = pickle.dumps(lazy_obj)\n    unpickled_obj = pickle.loads(pickled_obj)\n    self.assertEqual(str(unpickled_obj), 'test')\n"], "sample_1095": ["def test_resize_too_small():\n    p = Permutation(0, 1, 2)(3, 4)\n    raises(ValueError, lambda: p.resize(2))\n    raises(ValueError, lambda: p.resize(3))\n"], "sample_1191": ["def test_invariant_factors():\n    m = DM([[12, 6, 4, 8], [3, 9, 6, 12], [2, 16, 14, 28], [20, 10, 10, 20]], ZZ)\n    assert invariant_factors(m) == (1, 10, -30, 0)\n\n    m = DM([[1, 2], [3, 4]], ZZ)\n    assert invariant_factors(m) == (1, -2)\n\n    m = DM([[1, 0], [0, 1]], ZZ)\n    assert invariant_factors(m) == (1, 1)\n\n    m = DM([[0, 0], [0, 0]], ZZ)\n    assert invariant_factors(m) == (0, 0)\n\n    m = DM([], (0, 2), ZZ)\n    assert invariant_factors(m) == ()\n\n    m = DM([[], []], (2, 0), ZZ)\n    assert invariant_factors(m) == ()\n\n    m = DM([[2, 4]], ZZ)\n    assert invariant_factors(m) == (2,)\n\n    m = DM([[0, -2]], ZZ)\n    assert invariant_factors(m) == (-2,)\n\n    m = DM([[0], [-2]], ZZ)\n    assert invariant_factors(m) == (-2,)\n\n    m = DM([[3, 0, 0, 0], [0, 0, 0, 0], [0, 0, 2, 0]], ZZ)\n    assert invariant_factors(m) == (1, 6, 0)\n\n    raises(ValueError, lambda: invariant_factors(DM([[1]], ZZ[x])))\n"], "sample_1189": ["def test_lambdify_cse_with_piecewise():\n    x = symbols('x')\n    expr = Piecewise((x, x < 0), (x**2, x >= 0))\n    f = lambdify(x, expr, cse=True)\n    assert f(-1) == -1\n    assert f(1) == 1\n"], "sample_792": ["def test_complementnb_partial_fit():\n    # Test ComplementNB partial fit\n    X = np.array([[1, 1, 0, 0, 0, 0],\n                  [0, 1, 0, 0, 1, 0],\n                  [0, 1, 0, 1, 0, 0],\n                  [0, 1, 1, 0, 0, 1]])\n    y = np.array([0, 0, 0, 1])\n\n    clf = ComplementNB(alpha=1.0)\n    clf.partial_fit(X[:3], y[:3], classes=[0, 1])\n    clf.partial_fit(X[3:], y[3:])\n\n    # Check that counts/weights are correct.\n    feature_count = np.array([[1, 3, 0, 1, 1, 0], [0, 1, 1, 0, 0, 1]])\n    assert_array_equal(clf.feature_count_, feature_count)\n    class_count = np.array([3, 1])\n    assert_array_equal(clf.class_count_, class_count)\n    feature_all = np.array([1, 4, 1, 1, 1, 1])\n    assert_array_equal(clf.feature_all_, feature_all)\n"], "sample_698": ["def test_logcapturefixture() -> None:\n    from _pytest.logging import LogCaptureFixture, LogCaptureHandler\n\n    handler = LogCaptureHandler()\n    fixture = LogCaptureFixture(None, _ispytest=True)\n\n    # Test the properties\n    assert fixture.handler == handler\n    assert fixture.records == []\n    assert fixture.record_tuples == []\n    assert fixture.messages == []\n    assert fixture.text == \"\"\n\n    # Test the methods\n    fixture.clear()\n    assert fixture.records == []\n    assert fixture.record_tuples == []\n    assert fixture.messages == []\n    assert fixture.text == \"\"\n\n    fixture.set_level(logging.INFO)\n    assert fixture.handler.level == logging.INFO\n\n    with fixture.at_level(logging.DEBUG):\n        assert fixture.handler.level == logging.DEBUG\n    assert fixture.handler.level == logging.INFO\n\n    # Test the finalize method\n    fixture._finalize()\n    assert fixture._initial_handler_level is None\n    assert fixture._initial_logger_levels == {}\n"], "sample_1172": ["def test_solve_generic():\n    x0, y0, x1, y1, r = symbols('x0 y0 x1 y1 r')\n\n    f_1 = (x - 1)**2 + (y - 1)**2 - r**2\n    f_2 = (x - 2)**2 + (y - 2)**2 - r**2\n    s = sqrt(2*r**2 - 1)\n    a = (3 - s)/2\n    b = (3 + s)/2\n    assert solve_generic([Poly(f_1, x, y), Poly(f_2, x, y)], Poly.options(x, y)) == [(a, b), (b, a)]\n\n    f_1 = (x - 1 )**2 + (y - 2)**2 - r**2\n    f_2 = (x - x1)**2 + (y - 1)**2 - r**2\n\n    result = solve_generic([Poly(f_1, x, y), Poly(f_2, x, y)], Poly.options(x, y))\n\n    assert len(result) == 2 and all(len(r) == 2 for r in result)\n    assert all(r.count(query) == 1 for r in flatten(result))\n\n    f_1 = (x - x0)**2 + (y - y0)**2 - r**2\n    f_2 = (x - x1)**2 + (y - y1)**2 - r**2\n\n    result = solve_generic([Poly(f_1, x, y), Poly(f_2, x, y)], Poly.options(x, y))\n\n    assert len(result) == 2 and all(len(r) == 2 for r in result)\n    assert all(len(r.find(query)) == 1 for r in flatten(result))\n\n    s1 = (x*y - y, x**2 - x)\n    assert solve(s1) == [{x: 1}, {x: 0, y: 0}]\n    s2 = (x*y - x, y**2 - y)\n    assert solve(s2) == [{y: 1}, {x: 0, y: 0}]\n    gens = (x, y)\n    for seq in (s1, s2):\n        (f, g), opt = parallel_poly_from_expr(seq, *gens)\n        raises"], "sample_58": ["def test_order_fields_with_empty_list(self):\n    class TestForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n        field3 = CharField()\n        field_order = []\n\n    p = TestForm()\n    self.assertEqual(list(p.fields), ['field1', 'field2', 'field3'])\n"], "sample_804": ["def test_one_hot_encoder_drop_with_handle_unknown():\n    X = [['abc', 2, 55], ['def', 1, 55], ['def', 3, 59]]\n    enc = OneHotEncoder(drop='first', handle_unknown='error')\n    assert_warns(FutureWarning, enc.fit, X)\n    X2 = [['abc', 2, 55], ['def', 1, 55], ['def', 3, 59], ['ghi', 1, 55]]\n    assert_raises(ValueError, enc.transform, X2)\n    enc = OneHotEncoder(drop='first', handle_unknown='ignore')\n    assert_warns(FutureWarning, enc.fit, X)\n    X2 = [['abc', 2, 55], ['def', 1, 55], ['def', 3, 59], ['ghi', 1, 55]]\n    X2_passed = X2.copy()\n    assert_array_equal(enc.transform(X2_passed).toarray(),\n                       np.array([[1., 0., 1., 1.],\n                                 [0., 1., 0., 1.],\n                                 [0., 1., 0., 0.],\n                                 [0., 0., 0., 0.]]))\n    # ensure transformed data was not modified in place\n    assert_array_equal(X2, X2_passed)\n"], "sample_877": ["def test_isotonic_regression_output_transform():\n    \"\"\"Check that `transform` does return the expected output type.\n\n    We need to check that `transform` will output a DataFrame and a NumPy array\n    when we set `transform_output` to `pandas`.\n\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/25499\n    \"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X, y = make_regression(n_samples=10, n_features=1, random_state=42)\n    regressor = IsotonicRegression()\n    with sklearn.config_context(transform_output=\"pandas\"):\n        regressor.fit(X, y)\n        X_trans = regressor.transform(X)\n        assert isinstance(X_trans, pd.DataFrame)\n        assert X_trans.shape[1] == 1\n        assert X_trans.columns[0] == \"isotonicregression0\"\n"], "sample_597": ["    def test_merge_coords(self):\n        data = create_test_data()\n        coords = data.coords\n        actual = xr.merge([coords])\n        expected = xr.Dataset(coords)\n        assert actual.identical(expected)\n"], "sample_1202": ["def test_issue_14289():\n    from sympy.polys.numberfields import to_number_field\n\n    a = 1 - sqrt(2)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n\n    a = sqrt(2) + sqrt(3)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n\n    a = sqrt(2) + sqrt(5)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n\n    a = sqrt(2) + sqrt(6)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n\n    a = sqrt(3) + sqrt(5)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n\n    a = sqrt(3) + sqrt(6)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n\n    a = sqrt(5) + sqrt(6)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n\n    a = sqrt(2) + sqrt(3) + sqrt(5)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n\n    a = sqrt(2) + sqrt(3) + sqrt(6)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n\n    a = sqrt(2) + sqrt(5) + sqrt(6)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n\n    a = sqrt(3) + sqrt(5) + sqrt(6)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n\n    a = sqrt(2) + sqrt"], "sample_866": ["def test_affinity_propagation_copy():\n    # Test that the input data is not modified when copy=True\n    X = np.array([[1, 2], [1, 4], [1, 0],\n                  [4, 2], [4, 4], [4, 0]])\n    S = -euclidean_distances(X, squared=True)\n    original_S = S.copy()\n    affinity_propagation(S, copy=True)\n    assert_array_equal(S, original_S)\n\n    # Test that the input data is modified when copy=False\n    S = -euclidean_distances(X, squared=True)\n    original_S = S.copy()\n    affinity_propagation(S, copy=False)\n    assert not np.array_equal(S, original_S)\n"], "sample_678": ["def test_fnmatch_ex_with_posix_sep_on_windows(tmp_path):\n    \"\"\"Ensure fnmatch_ex works correctly with Posix path separators on Windows.\"\"\"\n    if sys.platform != \"win32\":\n        pytest.skip(\"This test is only relevant on Windows\")\n\n    path = tmp_path / \"foo/bar/baz.py\"\n    path.mkdir(parents=True)\n    path = path / \"baz.py\"\n\n    assert fnmatch_ex(\"foo/**/baz.py\", path)\n    assert fnmatch_ex(\"foo/bar/baz.py\", path)\n    assert not fnmatch_ex(\"foo/bar/baz.pyc\", path)\n    assert not fnmatch_ex(\"bar/baz.py\", path)\n"], "sample_235": ["def test_on_commit_with_nested_savepoints(self):\n    with transaction.atomic():\n        with transaction.atomic():\n            self.do(1)\n            with transaction.atomic():\n                self.do(2)\n                try:\n                    with transaction.atomic():\n                        self.do(3)\n                        raise ForcedError()\n                except ForcedError:\n                    pass\n            self.do(4)\n\n    self.assertDone([1, 2, 4])\n"], "sample_673": ["def test_doctest_report_choice_only_first_failure_with_multiple_failures(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            '''\n            >>> 1 + 1\n            3\n            >>> 2 + 2\n            5\n            '''\n        \"\"\"\n    )\n    result = testdir.runpytest(\"--doctest-modules\", \"--doctest-report=only_first_failure\")\n    result.stdout.fnmatch_lines(\n        [\n            \"Expected:\",\n            \"    3\",\n            \"Got:\",\n            \"    2\",\n            \"*1 failed*\",\n        ]\n    )\n    result.stdout.no_fnmatch_line(\"*2 + 2*\")\n"], "sample_1176": ["def test_issue_12345():\n    # Test that Float can handle very large numbers\n    large_num = 10**1000\n    assert Float(large_num)._mpf_ == (0, int(large_num), 1000, 1001)\n    assert Float(large_num)._prec == 1001\n    assert Float(large_num) == large_num\n"], "sample_820": ["def test_voting_regressor_transform():\n    \"\"\"Check transform method of VotingRegressor on toy dataset.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(n_estimators=10, random_state=1)\n    X = np.array([[1, 1], [2, 4], [3, 9], [4, 16], [5, 25], [6, 36]])\n    y = np.array([2, 6, 12, 20, 30, 42])\n\n    ereg1 = VotingRegressor([('lr', reg1), ('rf', reg2)]).fit(X, y)\n    ereg2 = VotingRegressor([('lr', reg1), ('rf', reg2)], weights=[1, 2]).fit(X, y)\n\n    assert_array_equal(ereg1.transform(X).shape, (6, 2))\n    assert_array_equal(ereg2.transform(X).shape, (6, 2))\n    assert_array_almost_equal(ereg1.transform(X), ereg2.transform(X))\n"], "sample_714": ["def test_log_loss_multiclass():\n    # multiclass case; adapted from http://bit.ly/RJJHWA\n    y_true = [1, 0, 2]\n    y_pred = [[0.2, 0.7, 0.1], [0.6, 0.2, 0.2], [0.6, 0.1, 0.3]]\n    loss = log_loss(y_true, y_pred, normalize=True)\n    assert_almost_equal(loss, 0.6904911)\n\n    # check that we got all the shapes and axes right\n    # by doubling the length of y_true and y_pred\n    y_true *= 2\n    y_pred *= 2\n    loss = log_loss(y_true, y_pred, normalize=False)\n    assert_almost_equal(loss, 0.6904911 * 6, decimal=6)\n\n    # check eps and handling of absolute zero and one probabilities\n    y_pred = np.asarray(y_pred) > .5\n    loss = log_loss(y_true, y_pred, normalize=True, eps=.1)\n    assert_almost_equal(loss, log_loss(y_true, np.clip(y_pred, .1, .9)))\n\n    # raise error if number of classes are not equal.\n    y_true = [1, 0, 2]\n    y_pred = [[0.2, 0.7], [0.6, 0.5], [0.4, 0.1]]\n    assert_raises(ValueError, log_loss, y_true, y_pred)\n\n    # case when y_true is a string array object\n    y_true = [\"ham\", \"spam\", \"spam\", \"ham\"]\n    y_pred = [[0.2, 0.7], [0.6, 0.5], [0.4, 0.1], [0.7, 0.2]]\n    loss = log_loss(y_true, y_pred)\n    assert_almost_equal(loss, 1.0383217, decimal=6)\n\n    # test labels option\n\n    y_true = [2, 2]\n    y_pred = [[0.2, 0.7], [0.6, 0.5]]\n    y_score = np.array([[0.1, 0.9], [0.1, 0.9]])\n    error_str = ('y_true contains only one label (2). Please provide '\n"], "sample_663": ["def test_collect_with_conftest_in_subdir(testdir):\n    \"\"\"Test that conftest.py in subdirectory is not collected as a test.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    testdir.mkpydir(\"sub\")\n    testdir.makeconftest(\n        \"\"\"\n            return pytest.Module(path, parent)\n    \"\"\",\n        path=testdir.tmpdir.join(\"sub\"),\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed in*\"])\n    assert result.ret == 0\n"], "sample_1183": ["def test_FracField():\n    F, x, y = field(\"x,y\", ZZ)\n    assert F.symbols == (x, y)\n    assert F.ngens == 2\n    assert F.domain == ZZ\n    assert F.order == lex\n    assert F.zero == F(0)\n    assert F.one == F(1)\n    assert F.gens == (x, y)\n\n    assert F.index(x) == 0\n    assert F.index(y) == 1\n\n    assert F == F\n    assert F != ZZ\n\n    f = F(x + y)\n    assert f == F(x + y)\n    assert f != F(x - y)\n\n    assert bool(f) is True\n    assert bool(F(0)) is False\n\n    assert f.sort_key() == ((1, 0), (1, 1))\n\n    assert f < F(x + y + 1)\n    assert f <= F(x + y + 1)\n    assert f > F(x + y - 1)\n    assert f >= F(x + y - 1)\n\n    assert +f == f\n    assert -f == F(-x - y)\n\n    assert f + F(x - y) == F(2*x)\n    assert f - F(x - y) == F(2*y)\n    assert f * F(x - y) == F(x**2 - y**2)\n    assert f / F(x - y) == F((x + y)/(x - y))\n\n    assert f ** 2 == F(x**2 + 2*x*y + y**2)\n    assert f.diff(x) == F(1)\n    assert f.diff(y) == F(1)\n\n    assert f(1, 2) == F(3)\n    assert f.evaluate([(x, 1), (y, 2)]) == F(3)\n    assert f.subs([(x, 1), (y, 2)]) == F(3)\n\n    assert F.from_expr(x + y) == f\n    assert F.from_expr(x**2 + y**2) == F(x**2 + y**2)\n\n    assert F.to_domain() == F\n    assert F.to_ring() == ZZ[x, y]\n"], "sample_615": ["def test_cross_with_missing_values() -> None:\n    a = xr.DataArray(\n        [1, 2, 3],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    b = xr.DataArray(\n        [4, np.nan, 6],\n        dims=[\"cartesian\"],\n        coords=dict(cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"])),\n    )\n    expected = np.array([np.nan, np.nan, np.nan])\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_duckarray_allclose(expected, actual)\n"], "sample_979": ["def test_MatrixElement_as_coeff_Mul():\n    assert A[0, 0].as_coeff_Mul()[0] == 1\n    assert A[0, 0].as_coeff_Mul()[1] == A[0, 0]\n"], "sample_1002": ["def test_issue_12345():\n    # Test for issue 12345: Float should not lose precision when created from Rational\n    from sympy import Rational\n    r = Rational(1, 10**100)\n    f = Float(r)\n    assert f._prec == 100\n    assert f == r\n"], "sample_245": ["    def test_build_file_class(self):\n        cmd = MakeMessagesCommand()\n        cmd.domain = 'django'\n        cmd.locale_paths = []\n        cmd.default_locale_path = os.path.join(self.test_dir, 'locale')\n        translatable = cmd.translatable_file_class(self.test_dir, 'test.html', cmd.default_locale_path)\n        build_file = cmd.build_file_class(cmd, cmd.domain, translatable)\n        self.assertEqual(build_file.path, os.path.join(self.test_dir, 'test.html'))\n        self.assertEqual(build_file.work_path, os.path.join(self.test_dir, 'test.html.py'))\n"], "sample_294": ["def test_rotate_token(self):\n    \"\"\"\n    Rotate the CSRF token after a request.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.process_request(req)\n    mw.process_view(req, post_form_view, (), {})\n    resp = mw(req)\n    csrf_cookie = resp.cookies.get(settings.CSRF_COOKIE_NAME, False)\n    self.assertIsNotNone(csrf_cookie)\n    self.assertNotEqual(csrf_cookie.value, self._csrf_id_cookie)\n    self.assertTrue(equivalent_tokens(csrf_cookie.value, self._csrf_id_cookie))\n"], "sample_536": ["def test_lasso_selector(ax):\n    onselect = mock.Mock(spec=noop, return_value=None)\n\n    tool = widgets.LassoSelector(ax, onselect)\n    do_event(tool, 'press', xdata=100, ydata=100, button=1)\n    do_event(tool, 'onmove', xdata=125, ydata=125, button=1)\n    do_event(tool, 'onmove', xdata=150, ydata=150, button=1)\n    do_event(tool, 'release', xdata=150, ydata=150, button=1)\n\n    onselect.assert_called_once_with([(100, 100), (125, 125), (150, 150)])\n"], "sample_198": ["    def test_row_range_frame(self):\n        first = Time.objects.create(time='09:00')\n        second = Time.objects.create(time='17:00')\n        third = Time.objects.create(time='21:00')\n        SimulationRun.objects.bulk_create([\n            SimulationRun(start=first, end=second, midpoint='12:00'),\n            SimulationRun(start=first, end=third, midpoint='15:00'),\n            SimulationRun(start=second, end=first, midpoint='00:00'),\n        ])\n        inner = Time.objects.filter(time=OuterRef(OuterRef('time')), pk=OuterRef('start')).values('time')\n        middle = SimulationRun.objects.annotate(other=Subquery(inner)).values('other')[:1]\n        outer = Time.objects.annotate(other=Subquery(middle, output_field=TimeField()))\n        # This is a contrived example. It exercises the double OuterRef form.\n        self.assertCountEqual(outer, [first, second, third])\n"], "sample_38": ["def test_sip_with_altkey_and_distortion():\n    \"\"\"\n    Test that when creating a WCS object using a key, CTYPE with\n    that key is looked at and not the primary CTYPE.\n    fix for #5443.\n    \"\"\"\n    with fits.open(get_pkg_data_filename('data/sip.fits')) as f:\n        w = wcs.WCS(f[0].header)\n    # create a header with two WCSs.\n    h1 = w.to_header(relax=True, key='A')\n    h2 = w.to_header(relax=False)\n    h1['CTYPE1A'] = \"RA---SIN-SIP\"\n    h1['CTYPE2A'] = \"DEC--SIN-SIP\"\n    h1.update(h2)\n    h1['D2IMDIS1'] = 'lookup'\n    h1['D2IM1.EXTVER'] = 1\n    h1['D2IM1.NAXES'] = 2\n    h1['D2IM1.AXIS.1'] = 1\n    h1['D2IM1.AXIS.2'] = 2\n    h1['CPDIS1'] = 'lookup'\n    h1['DP1.EXTVER'] = 1\n    h1['DP1.NAXES'] = 2\n    h1['DP1.AXIS.1'] = 1\n    h1['DP1.AXIS.2'] = 2\n    w = wcs.WCS(h1, key='A')\n    assert (w.wcs.ctype == np.array(['RA---SIN-SIP', 'DEC--SIN-SIP'])).all()\n    assert w.det2im1 is not None\n    assert w.cpdis1 is not None\n"], "sample_139": ["def test_dynamic_sortable_by(self):\n    \"\"\"\n    Regression tests for #17646: dynamic sortable_by support.\n    \"\"\"\n    parent = Parent.objects.create(name='parent')\n    for i in range(10):\n        Child.objects.create(name='child %s' % i, parent=parent)\n\n    user_noparents = self._create_superuser('noparents')\n    user_parents = self._create_superuser('parents')\n\n    # Test with user 'noparents'\n    m = DynamicListDisplayChildAdmin(Child, custom_site)\n    request = self._mocked_authenticated_request('/child/', user_noparents)\n    response = m.changelist_view(request)\n    self.assertEqual(response.context_data['cl'].sortable_by, ['name', 'age'])\n\n    # Test with user 'parents'\n    m = DynamicListDisplayChildAdmin(Child, custom_site)\n    request = self._mocked_authenticated_request('/child/', user_parents)\n    response = m.changelist_view(request)\n    self.assertEqual(response.context_data['cl'].sortable_by, ('parent', 'name', 'age'))\n"], "sample_563": ["def test_auxtransformbox():\n    # Test AuxTransformBox with a child DrawingArea\n    fig, ax = plt.subplots()\n    size = 100\n    da = DrawingArea(size, size)\n    aux_transform = mtransforms.Affine2D().rotate_deg(45)\n    aux_box = AuxTransformBox(aux_transform)\n    aux_box.add_artist(da)\n    bg = mpatches.Rectangle((0, 0), size, size,\n                            facecolor='#CCCCCC',\n                            edgecolor='None',\n                            linewidth=0)\n    line = mlines.Line2D([-size*.5, size*1.5], [size/2, size/2],\n                         color='black',\n                         linewidth=10)\n    da.add_artist(bg)\n    da.add_artist(line)\n    ax.add_artist(aux_box)\n    ax.set_xlim((0, 1))\n    ax.set_ylim((0, 1))\n    fig.canvas.draw()\n"], "sample_667": ["def test_getbasetemp_custom_absolute_path(testdir, monkeypatch):\n    \"\"\"#4425\"\"\"\n    from _pytest.tmpdir import TempPathFactory\n\n    monkeypatch.chdir(testdir.tmpdir)\n    config = FakeConfig(\"/absolute/path\")\n    t = TempPathFactory.from_config(config)\n    assert t.getbasetemp().resolve() == Path(\"/absolute/path\").resolve()\n"], "sample_419": ["def test_formset_with_filefield(self):\n    \"\"\"\n    Formset works with FileField.\n    \"\"\"\n    class FileForm(Form):\n        file = FileField()\n\n    FileFormSet = formset_factory(FileForm, extra=2)\n    formset = FileFormSet()\n    self.assertHTMLEqual(\n        \"\\n\".join(str(form) for form in formset.forms),\n        \"\"\"<div><label for=\"id_form-0-file\">File:</label>"], "sample_341": ["def test_formset_absolute_max_with_min_num(self):\n    data = {\n        'form-TOTAL_FORMS': '1001',\n        'form-INITIAL_FORMS': '0',\n        'form-MIN_NUM_FORMS': '0',\n        'form-MAX_NUM_FORMS': '0',\n    }\n    LimitedFavoriteDrinksFormSet = formset_factory(\n        FavoriteDrinkForm,\n        min_num=30,\n        absolute_max=1000,\n    )\n    formset = LimitedFavoriteDrinksFormSet(data=data)\n    self.assertIs(formset.is_valid(), False)\n    self.assertEqual(len(formset.forms), 1000)\n    self.assertEqual(\n        formset.non_form_errors(),\n        ['Please submit at least 30 forms.'],\n    )\n"], "sample_1201": ["def test_cgs_gauss_dimensions():\n    assert cgs_gauss.get_dimension_system().get_dimensional_dependencies('impedance') == {'time': 1, 'length': -1}\n    assert cgs_gauss.get_dimension_system().get_dimensional_dependencies('conductance') == {'time': -1, 'length': 1}\n    assert cgs_gauss.get_dimension_system().get_dimensional_dependencies('capacitance') == {'length': 1}\n    assert cgs_gauss.get_dimension_system().get_dimensional_dependencies('inductance') == {'time': 2, 'length': -1}\n    assert cgs_gauss.get_dimension_system().get_dimensional_dependencies('charge') == {'mass': S.Half, 'length': S(3)/2, 'time': -1}\n    assert cgs_gauss.get_dimension_system().get_dimensional_dependencies('current') == {'mass': One/2, 'length': 3*One/2, 'time': -2}\n    assert cgs_gauss.get_dimension_system().get_dimensional_dependencies('voltage') == {'length': -One/2, 'mass': One/2, 'time': -1}\n    assert cgs_gauss.get_dimension_system().get_dimensional_dependencies('magnetic_density') == {'length': -One/2, 'mass': One/2, 'time': -1}\n    assert cgs_gauss.get_dimension_system().get_dimensional_dependencies('magnetic_flux') == {'length': 3*One/2, 'mass': One/2, 'time': -1}\n\n    assert cgs_gauss.get_dimension_system().get_dimensional_dependencies('length') == {}\n    assert cgs_gauss.get_dimension_system().get_dimensional_dependencies('mass') == {}\n    assert cgs_gauss.get_dimension_system().get_dimensional_dependencies('time') == {}\n"], "sample_655": ["def test_capturing_and_logging_fundamentals_with_keyboardinterrupt(testdir):\n    # here we check a fundamental feature\n    p = testdir.makepyfile(\n        \"\"\"\n        import sys, os\n        import py, logging\n        from _pytest import capture\n        cap = capture.MultiCapture(out=False, in_=False,\n                                     Capture=capture.SysCapture)\n        cap.start_capturing()\n\n        logging.warning(\"hello1\")\n        outerr = cap.readouterr()\n        print(\"suspend, captured %%s\" %%(outerr,))\n        logging.warning(\"hello2\")\n\n        cap.pop_outerr_to_orig()\n        logging.warning(\"hello3\")\n\n        outerr = cap.readouterr()\n        print(\"suspend2, captured %%s\" %% (outerr,))\n        raise KeyboardInterrupt()\n    \"\"\"\n    )\n    result = testdir.runpython(p)\n    result.stdout.fnmatch_lines(\n        \"\"\"\n        suspend, captured*hello1*\n        suspend2, captured*WARNING:root:hello3*\n    \"\"\"\n    )\n    result.stderr.fnmatch_lines(\n        \"\"\"\n        WARNING:root:hello2\n    \"\"\"\n    )\n    assert \"atexit\" not in result.stderr.str()\n"], "sample_832": ["def test_bayesian_ridge_alpha_init():\n    # Test BayesianRidge with different alpha_init values\n    X = np.array([[1], [2], [6], [8], [10]])\n    Y = np.array([1, 2, 6, 8, 10])\n    clf1 = BayesianRidge(alpha_init=0.1)\n    clf2 = BayesianRidge(alpha_init=10)\n    clf1.fit(X, Y)\n    clf2.fit(X, Y)\n    assert_almost_equal(clf1.alpha_, clf2.alpha_, decimal=5)\n    assert_array_almost_equal(clf1.coef_, clf2.coef_, decimal=5)\n"], "sample_275": ["    def test_get_or_create_with_defaults(self):\n        # Test that get_or_create() with defaults works correctly\n        defaults = {'name': 'Test Book'}\n        book, created = Book.objects.get_or_create(pagecount=100, defaults=defaults)\n        self.assertTrue(created)\n        self.assertEqual(book.name, 'Test Book')\n\n        # Test that get_or_create() with defaults doesn't create a new object if it already exists\n        book, created = Book.objects.get_or_create(pagecount=100, defaults=defaults)\n        self.assertFalse(created)\n        self.assertEqual(book.name, 'Test Book')\n"], "sample_695": ["def test_node_repr_failure_with_conftest_import_failure(pytester: Pytester) -> None:\n    \"\"\"Test that repr_failure handles ConftestImportFailure correctly.\"\"\"\n    pytester.makeconftest(\n        \"\"\"\n        raise Exception(\"conftest import failure\")\n    \"\"\"\n    )\n    p = pytester.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([str(p) + \":*: Exception: conftest import failure\", \"*1 failed in *\"])\n"], "sample_649": ["def test_log_cli_level_interaction_with_log_level(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_handler.level == logging.INFO\n            logging.getLogger('catchlog').debug(\"This log message won't be shown\")\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n        log_level=DEBUG\n    \"\"\"\n    )\n\n    result = pytester.runpytest(\"-s\", \"--log-cli-level=INFO\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_log_cli_level_interaction_with_log_level.py* This log message will be shown\",\n            \"PASSED\",  # 'PASSED' on its own line because the log message prints a new line\n        ]\n    )\n    result.stdout.no_fnmatch_line(\"*This log message won't be shown*\")\n\n    # make sure that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n"], "sample_665": ["def test_collect_with_parametrize_and_indirect(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"x\", [1, 2], indirect=True)\n            assert x == 1 or x == 2\n\n        @pytest.fixture\n            return request.param\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*2 passed in*\"])\n    assert result.ret == ExitCode.OK\n"], "sample_1031": ["def test_quantity_scale_factors():\n    # Test that the scale factors of the quantities are correctly defined\n    assert m.scale_factor == 1\n    assert kg.scale_factor == 1\n    assert s.scale_factor == 1\n    assert c.scale_factor == 299792458*m/s\n    assert g.scale_factor == kg/kilo\n    assert mg.scale_factor == milli*gram\n    assert ug.scale_factor == micro*gram\n    assert newton.scale_factor == kg*m/s**2\n    assert joule.scale_factor == newton*m\n    assert watt.scale_factor == joule/s\n    assert pascal.scale_factor == newton/m**2\n    assert hertz.scale_factor == 1/s\n    assert coulomb.scale_factor == 1\n    assert volt.scale_factor == joule/coulomb\n    assert ohm.scale_factor == volt/ampere\n    assert siemens.scale_factor == ampere/volt\n    assert farad.scale_factor == coulomb/volt\n    assert henry.scale_factor == volt*s/ampere\n    assert tesla.scale_factor == volt*s/m**2\n    assert weber.scale_factor == joule/ampere\n    assert lux.scale_factor == steradian*candela/m**2\n    assert katal.scale_factor == mol/s\n    assert gray.scale_factor == m**2/s**2\n    assert becquerel.scale_factor == 1/s\n    assert km.scale_factor == kilo*meter\n    assert dm.scale_factor == deci*meter\n    assert cm.scale_factor == centi*meter\n    assert mm.scale_factor == milli*meter\n    assert um.scale_factor == micro*meter\n    assert nm.scale_factor == nano*meter\n    assert pm.scale_factor == pico*meter\n    assert ft.scale_factor == Rational(3048, 10000)*meter\n    assert inch.scale_factor == foot/12\n    assert yd.scale_factor == 3*feet\n    assert mi.scale_factor == 5280*feet\n    assert nmi.scale_factor == 6076*feet\n    assert l.scale_factor == meter**3 / 1000\n    assert dl.scale_factor == liter / 10\n    assert cl.scale_factor == liter / 100\n    assert ml.scale_factor == liter / 1000\n    assert ms.scale_factor == milli*second\n    assert us.scale_factor == micro*second\n    assert ns"], "sample_796": ["def test_huber_epsilon_value_error():\n    # Test that HuberRegressor raises a ValueError for epsilon < 1.0\n    X, y = make_regression_with_outliers()\n    huber = HuberRegressor(fit_intercept=True, epsilon=0.5)\n    with pytest.raises(ValueError):\n        huber.fit(X, y)\n"], "sample_304": ["    def test_url_validator_with_custom_schemes(self):\n        validator = URLValidator(schemes=['custom_scheme'])\n        with self.assertRaisesMessage(ValidationError, 'Enter a valid URL.'):\n            validator('http://example.com')\n        self.assertIsNone(validator('custom_scheme://example.com'))\n"], "sample_192": ["def test_formset_absolute_max_with_min_num(self):\n    data = {\n        'form-TOTAL_FORMS': '1001',\n        'form-INITIAL_FORMS': '0',\n        'form-MIN_NUM_FORMS': '0',\n        'form-MAX_NUM_FORMS': '0',\n    }\n    LimitedFavoriteDrinksFormSet = formset_factory(\n        FavoriteDrinkForm,\n        min_num=30,\n        absolute_max=1000,\n    )\n    formset = LimitedFavoriteDrinksFormSet(data=data)\n    self.assertIs(formset.is_valid(), False)\n    self.assertEqual(len(formset.forms), 1000)\n    self.assertEqual(\n        formset.non_form_errors(),\n        ['Please submit 30 or more forms.'],\n    )\n"], "sample_503": ["def test_line2d_update_from():\n    fig, ax = plt.subplots()\n    line1 = mlines.Line2D([1, 2, 3], [1, 2, 3], color='r', linestyle='--')\n    line2 = mlines.Line2D([1, 2, 3], [1, 2, 3], color='b', linestyle='-')\n    ax.add_line(line1)\n    line1.update_from(line2)\n    assert line1.get_color() == 'b'\n    assert line1.get_linestyle() == '-'\n"], "sample_127": ["def test_bulk_update(self):\n    # Create some objects\n    TwoFields.objects.bulk_create([\n        TwoFields(f1=i, f2=i + 1) for i in range(0, 100)\n    ])\n\n    # Update all objects\n    TwoFields.objects.bulk_update(TwoFields.objects.all(), ['f1', 'f2'])\n\n    # Check that all objects have been updated\n    self.assertEqual(TwoFields.objects.filter(f1=F('f2') - 1).count(), 100)\n\n    # Update some objects\n    TwoFields.objects.bulk_update(TwoFields.objects.filter(f1__gte=50), ['f1', 'f2'])\n\n    # Check that only some objects have been updated\n    self.assertEqual(TwoFields.objects.filter(f1=F('f2') - 1, f1__gte=50).count(), 50)\n\n    # Update with expressions\n    TwoFields.objects.bulk_update(TwoFields.objects.all(), ['f1'], batch_size=50)\n\n    # Check that all objects have been updated\n    self.assertEqual(TwoFields.objects.filter(f1=F('f2')).count(), 100)\n"], "sample_1009": ["def test_vector_normalize():\n    x, y, z = symbols('x, y, z')\n    N = ReferenceFrame('N')\n\n    v1 = x * N.x + y * N.y + z * N.z\n    v2 = v1.normalize()\n    assert v2.magnitude() == 1\n\n    v3 = v1 / v1.magnitude()\n    assert v2 == v3\n\n    v4 = Vector(0)\n    raises(ZeroDivisionError, lambda: v4.normalize())\n"], "sample_469": ["def test_annotation_with_subquery(self):\n    subquery = Book.objects.filter(pages__gt=400).values(\"publisher\")\n    publishers = Publisher.objects.annotate(\n        total_books=Count(\"book\"),\n        has_long_books=Exists(subquery.filter(pk=OuterRef(\"pk\"))),\n    )\n    self.assertCountEqual(\n        publishers.values_list(\"name\", \"total_books\", \"has_long_books\"),\n        [\n            (\"Apress\", 3, True),\n            (\"Jonno's House of Books\", 0, False),\n            (\"Morgan Kaufmann\", 2, True),\n            (\"Prentice Hall\", 1, True),\n            (\"Sams\", 1, True),\n        ],\n    )\n"], "sample_123": ["    def test_fields_limit(self):\n        with self.assertRaisesMessage(TooManyFieldsSent, 'The number of GET/POST parameters exceeded settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'):\n            limited_parse_qsl('a=1&b=2&c=3', fields_limit=2)\n"], "sample_1012": ["def test_PythonCodePrinter_functions():\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(acos(x).diff(x)) == 'math.cos(x)'\n    assert prntr.doprint(acos(x).diff(x).diff(x)) == '-math.sin(x)'\n    assert prntr.doprint(acos(x).diff(x).diff(x).diff(x)) == '-math.cos(x)'\n    assert prntr.doprint(acos(x).diff(x).diff(x).diff(x).diff(x)) == 'math.sin(x)'\n"], "sample_220": ["    def test_reason_phrase(self):\n        response = HttpResponse()\n        self.assertEqual(response.reason_phrase, 'OK')\n        response.reason_phrase = 'Custom Reason'\n        self.assertEqual(response.reason_phrase, 'Custom Reason')\n"], "sample_989": ["def test_issue_12345():\n    # Test for issue 12345\n    assert Float('1.23456789012345678901234567890', '')._prec == 30\n    assert Float('1.23456789012345678901234567890', 30)._prec == 30\n    assert Float('1.23456789012345678901234567890', 31)._prec == 31\n    assert Float('1.23456789012345678901234567890', 32)._prec == 32\n    assert Float('1.23456789012345678901234567890', 33)._prec == 33\n    assert Float('1.23456789012345678901234567890', 34)._prec == 34\n    assert Float('1.23456789012345678901234567890', 35)._prec == 35\n    assert Float('1.23456789012345678901234567890', 36)._prec == 36\n    assert Float('1.23456789012345678901234567890', 37)._prec == 37\n    assert Float('1.23456789012345678901234567890', 38)._prec == 38\n    assert Float('1.23456789012345678901234567890', 39)._prec == 39\n    assert Float('1.23456789012345678901234567890', 40)._prec == 40\n    assert Float('1.23456789012345678901234567890', 41)._prec == 41\n    assert Float('1.23456789012345678901234567890', 42)._prec == 42\n    assert Float('1.23456789012345678901234567890', 43)._prec == 43\n    assert Float('1.23456789012345678901234567890', 44)._prec == 44\n    assert Float('1.23456789012345678901234567890', 45)._prec == 45\n    assert Float('1.23456789012345678901234567890', 46)._prec == 46\n    assert Float('1.23456789012345678901234567890', 47)._prec == 47\n    assert Float('1.23456789012345678901234567890', 48"], "sample_879": ["def test_one_hot_encoder_infrequent_categories_with_drop():\n    \"\"\"Test that the infrequent categories are correctly handled when drop is set.\"\"\"\n    X_train = np.array([[\"a\"] * 5 + [\"b\"] * 20 + [\"c\"] * 10 + [\"d\"] * 3]).T\n    ohe = OneHotEncoder(\n        handle_unknown=\"infrequent_if_exist\", sparse_output=False, max_categories=2\n    ).fit(X_train)\n    assert_array_equal(ohe.infrequent_categories_, [[\"a\", \"c\", \"d\"]])\n\n    # Test that the infrequent categories are correctly handled when drop is set to \"first\"\n    ohe.set_params(drop=\"first\").fit(X_train)\n    assert_array_equal(ohe.infrequent_categories_, [[\"a\", \"c\", \"d\"]])\n\n    # Test that the infrequent categories are correctly handled when drop is set to \"if_binary\"\n    ohe.set_params(drop=\"if_binary\").fit(X_train)\n    assert_array_equal(ohe.infrequent_categories_, [[\"a\", \"c\", \"d\"]])\n\n    # Test that the infrequent categories are correctly handled when drop is set to a list\n    ohe.set_params(drop=[\"b\"]).fit(X_train)\n    assert_array_equal(ohe.infrequent_categories_, [[\"a\", \"c\", \"d\"]])\n"], "sample_776": ["def test_lars_path_return_n_iter():\n    # Test that return_n_iter works correctly\n    alphas, active, coefs, n_iter = linear_model.lars_path(X, y, return_n_iter=True)\n    assert n_iter == len(alphas) - 1\n"], "sample_756": ["def test_min_maxima_ratio():\n    # Test that min_maxima_ratio is used to determine neighborhood size\n    # for minimum cluster membership\n    redX = X[::2]  # reduce for speed\n    clust = OPTICS(min_samples=9, min_maxima_ratio=0.05).fit(redX)\n    cluster_boundaries = _find_local_maxima(clust.reachability_[clust.ordering_], int(0.05 * len(redX)))\n    assert len(cluster_boundaries) > 0\n    # check that a smaller min_maxima_ratio results in fewer cluster boundaries\n    clust2 = OPTICS(min_samples=9, min_maxima_ratio=0.01).fit(redX)\n    cluster_boundaries2 = _find_local_maxima(clust2.reachability_[clust2.ordering_], int(0.01 * len(redX)))\n    assert len(cluster_boundaries2) <= len(cluster_boundaries)\n"], "sample_623": ["def test_chunks_with_auto():\n    \"\"\"Test that chunks='auto' uses the backend's preferred chunks.\"\"\"\n    initial = xr.Dataset(\n        {\n            \"data\": xr.Variable(\n                (\"x\", \"y\"),\n                np.empty((5, 6), dtype=np.dtype(\"V1\")),\n                encoding={\"preferred_chunks\": (4, 2)},\n            )\n        }\n    )\n    final = xr.open_dataset(initial, engine=PassThroughBackendEntrypoint, chunks=\"auto\")\n    assert final[\"data\"].chunks == ((4, 1), (2, 2, 2))\n"], "sample_573": ["def test_low_order(self, df):\n\n    groupby = GroupBy([\"group\"])\n    df[\"x\"] = np.repeat([1, 2], 50)\n    res = PolyFit(order=1, gridsize=100)(df, groupby, \"x\", {})\n\n    assert res.columns.to_list() == [\"x\", \"y\", \"group\"]\n\n    ngroups = df[\"group\"].nunique()\n    assert_array_equal(res.index, np.arange(ngroups * 100))\n\n    for _, part in res.groupby(\"group\"):\n        assert_array_equal(part[\"x\"], np.linspace(1, 2, 100))\n        assert_array_almost_equal(part[\"y\"].diff().dropna(), np.zeros(99))\n"], "sample_553": ["def test_animation_repr_html_embed_limit(anim):\n    if platform.python_implementation() == 'PyPy':\n        # Something in the test setup fixture lingers around into the test and\n        # breaks pytest.warns on PyPy. This garbage collection fixes it.\n        # https://foss.heptapod.net/pypy/pypy/-/issues/3536\n        np.testing.break_cycles()\n    with mpl.rc_context({'animation.embed_limit': 1e-6}):  # ~1 byte.\n        with pytest.warns(UserWarning, match=\"Animation size has reached\"):\n            anim._repr_html_()\n"], "sample_1016": ["def test_octave_codeprinter_settings():\n    # Test that the OctaveCodePrinter settings are correctly applied\n    expr = x**2 + y**2\n    assert octave_code(expr, precision=10) == \"x.^2 + y.^2\"\n    assert octave_code(expr, user_functions={\"sin\": \"my_sin\"}) == \"x.^2 + y.^2\"\n    assert octave_code(expr, human=False) == (\"\", [], [])\n    assert octave_code(expr, allow_unknown_functions=True) == \"x.^2 + y.^2\"\n    assert octave_code(expr, contract=False) == \"x.^2 + y.^2\"\n    assert octave_code(expr, inline=False) == \"x.^2 + y.^2\"\n"], "sample_794": ["def test_ridge_regression_return_n_iter():\n    # Test that return_n_iter returns the correct number of iterations\n    # for each solver\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 6, 5\n    X = rng.randn(n_samples, n_features)\n    y = rng.randn(n_samples)\n\n    solvers = ['sag', 'lsqr', 'sparse_cg']\n    for solver in solvers:\n        n_iter = ridge_regression(X, y, alpha=1.0, solver=solver,\n                                  return_n_iter=True)[1]\n        assert n_iter is not None\n\n    solvers = ['svd', 'cholesky']\n    for solver in solvers:\n        n_iter = ridge_regression(X, y, alpha=1.0, solver=solver,\n                                  return_n_iter=True)[1]\n        assert n_iter is None\n"], "sample_1092": ["def test_cse_with_function():\n    f = Function('f')\n    exprs = [f(x + y), f(x + y) + z]\n    subst, red = cse(exprs)\n    assert subst == [(x0, x + y)]\n    assert red == [f(x0), f(x0) + z]\n"], "sample_19": ["def test_sip_with_altkey2():\n    \"\"\"\n    Test that when creating a WCS object using a key, CTYPE with\n    that key is looked at and not the primary CTYPE.\n    fix for #5443.\n    \"\"\"\n    with fits.open(get_pkg_data_filename(\"data/sip.fits\")) as f:\n        with pytest.warns(wcs.FITSFixedWarning):\n            w = wcs.WCS(f[0].header)\n    # create a header with two WCSs.\n    h1 = w.to_header(relax=True, key=\"A\")\n    h2 = w.to_header(relax=False)\n    h1[\"CTYPE1A\"] = \"RA---SIN-SIP\"\n    h1[\"CTYPE2A\"] = \"DEC--SIN-SIP\"\n    h1.update(h2)\n    with ctx_for_v71_dateref_warnings():\n        w = wcs.WCS(h1, key=\"A\")\n    assert (w.wcs.ctype == np.array([\"RA---SIN-SIP\", \"DEC--SIN-SIP\"])).all()\n\n    # Test that WCS object can be created with a key that is not present in the header\n    with ctx_for_v71_dateref_warnings():\n        w = wcs.WCS(h1, key=\"B\")\n    assert (w.wcs.ctype == np.array([\"RA---TAN-SIP\", \"DEC--TAN-SIP\"])).all()\n"], "sample_912": ["def test_domain_py_module_index_with_deprecated_modules(app, status, warning):\n    app.builder.build_all()\n\n    modules = app.env.domains['py'].data['modules']\n\n    assert 'module_a.submodule' in modules\n    assert 'module_b.submodule' in modules\n\n    assert modules['module_a.submodule'][4] is False\n    assert modules['module_b.submodule'][4] is True\n\n    doctree = app.env.get_doctree('module')\n    refnodes = list(doctree.traverse(pending_xref))\n    assert len(refnodes) == 16\n\n    content = (app.outdir / 'genindex.html').read_text()\n    assert ('<i>module_a.submodule</i>' in content)\n    assert ('<i>module_b.submodule</i>' in content)\n"], "sample_313": ["def test_get_template_directories_with_cached_loader(self):\n    self.assertSetEqual(\n        autoreload.get_template_directories(),\n        {\n            ROOT / 'templates',\n        }\n    )\n"], "sample_1104": ["def test_Pow_with_noncommutative_base():\n    A, B = symbols('A B', commutative=False)\n    assert str(A**2) == \"A**2\"\n    assert str(A**-2) == \"A**(-2)\"\n    assert str(A**B) == \"A**B\"\n    assert str(A**(B + 1)) == \"A**(B + 1)\"\n    assert str(A**(B - 1)) == \"A**(B - 1)\"\n    assert str(A**(B**2)) == \"A**(B**2)\"\n    assert str(A**(B**-2)) == \"A**(B**(-2))\"\n"], "sample_1014": ["def test_mutable_ndim_array():\n    # Test MutableDenseNDimArray\n    mda = MutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    assert mda.tolist() == [[1, 2], [3, 4]]\n    assert mda.shape == (2, 2)\n    assert mda.rank() == 2\n\n    # Test setting items\n    mda[0, 0] = 5\n    assert mda.tolist() == [[5, 2], [3, 4]]\n\n    # Test as_immutable\n    ida = mda.as_immutable()\n    assert ida.tolist() == [[5, 2], [3, 4]]\n    assert ida.shape == (2, 2)\n    assert ida.rank() == 2\n\n    # Test zeros\n    mda = MutableDenseNDimArray.zeros(2, 2)\n    assert mda.tolist() == [[0, 0], [0, 0]]\n    assert mda.shape == (2, 2)\n    assert mda.rank() == 2\n\n    # Test tomatrix\n    matrix = mda.tomatrix()\n    assert matrix.tolist() == [[0, 0], [0, 0]]\n    assert matrix.shape == (2, 2)\n\n    # Test __iter__\n    i = 0\n    for item in mda:\n        assert item == 0\n        i += 1\n    assert i == 4\n\n    # Test reshape\n    mda = MutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    mda = mda.reshape(4)\n    assert mda.tolist() == [1, 2, 3, 4]\n    assert mda.shape == (4,)\n    assert mda.rank() == 1\n\n    # Test __setitem__ with slice\n    mda = MutableDenseNDimArray([1, 2, 3, 4], (2, 2))\n    mda[:, 0] = [5, 6]\n    assert mda.tolist() == [[5, 2], [6, 4]]\n\n    # Test __setitem__ with tuple of slices\n    mda = MutableDenseNDimArray([1, 2, "], "sample_1181": ["def test_numpy_matrix_solve():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    M = MatrixSymbol(\"M\", 3, 3)\n    x = MatrixSymbol(\"x\", 3, 1)\n\n    expr = MatrixSolve(M, x)\n    f = lambdify((M, x), expr, 'numpy')\n\n    m0 = np.array([[1, 2, 3], [3, 2, 5], [5, 6, 7]])\n    assert np.linalg.matrix_rank(m0) == 3\n\n    x0 = np.array([3, 4, 5])\n\n    assert np.allclose(f(m0, x0), np.linalg.solve(m0, x0))\n"], "sample_1196": ["def test_eval():\n    x = Symbol('x')\n    assert Contains.eval(2, S.Integers) is S.true\n    assert Contains.eval(-2, S.Naturals) is S.false\n    assert Contains.eval(x, S.Integers) == Contains(x, S.Integers)\n    assert Contains.eval(x, FiniteSet(1, 2, 3)) == Contains(x, FiniteSet(1, 2, 3))\n"], "sample_685": ["def test_log_capture_handler_reset(caplog):\n    caplog.set_level(logging.INFO)\n    logger.info(\"boo %s\", \"arg\")\n    assert len(caplog.records) == 1\n    assert len(caplog.handler.records) == 1\n    caplog.handler.reset()\n    assert len(caplog.records) == 1\n    assert len(caplog.handler.records) == 0\n    logger.info(\"bar %s\", \"arg\")\n    assert len(caplog.records) == 2\n    assert len(caplog.handler.records) == 1\n"], "sample_266": ["def test_replacing_migration(self):\n    \"\"\"\n    Tests loading a migration that replaces another migration.\n    \"\"\"\n    loader = MigrationLoader(connection)\n    recorder = MigrationRecorder(connection)\n    self.addCleanup(recorder.flush)\n\n    # Load with nothing applied: the replacing migration is used.\n    loader.build_graph()\n    plan = set(loader.graph.forwards_plan(('migrations', '0003_replacing')))\n    plan = plan - loader.applied_migrations.keys()\n    expected_plan = {\n        ('migrations', '0001_initial'),\n        ('migrations', '0003_replacing'),\n    }\n    self.assertEqual(plan, expected_plan)\n\n    # Fake-apply the replaced migration: the replacing migration is not used.\n    recorder.record_applied('migrations', '0002_replaced')\n    loader.build_graph()\n    plan = set(loader.graph.forwards_plan(('migrations', '0003_replacing')))\n    plan = plan - loader.applied_migrations.keys()\n    expected_plan = {\n        ('migrations', '0001_initial'),\n        ('migrations', '0002_replaced'),\n        ('migrations', '0003_replacing'),\n    }\n    self.assertEqual(plan, expected_plan)\n"], "sample_728": ["def test_make_gaussian_quantiles():\n    X, y = make_gaussian_quantiles(n_samples=100, n_features=2, n_classes=3,\n                                   random_state=0)\n\n    assert_equal(X.shape, (100, 2), \"X shape mismatch\")\n    assert_equal(y.shape, (100,), \"y shape mismatch\")\n    assert_equal(np.unique(y).shape, (3,), \"Unexpected number of classes\")\n\n    # Test with specified mean\n    mean = [1.0, 2.0]\n    X, y = make_gaussian_quantiles(n_samples=100, n_features=2, n_classes=3,\n                                   mean=mean, random_state=0)\n\n    assert_equal(X.shape, (100, 2), \"X shape mismatch\")\n    assert_equal(y.shape, (100,), \"y shape mismatch\")\n    assert_equal(np.unique(y).shape, (3,), \"Unexpected number of classes\")\n    assert_array_almost_equal(X.mean(axis=0), mean, decimal=1)\n\n    # Test with specified covariance\n    cov = 0.5\n    X, y = make_gaussian_quantiles(n_samples=100, n_features=2, n_classes=3,\n                                   cov=cov, random_state=0)\n\n    assert_equal(X.shape, (100, 2), \"X shape mismatch\")\n    assert_equal(y.shape, (100,), \"y shape mismatch\")\n    assert_equal(np.unique(y).shape, (3,), \"Unexpected number of classes\")\n    assert_array_almost_equal(X.var(axis=0), [cov] * 2, decimal=1)\n"], "sample_327": ["def test_bound_data(self):\n    field = JSONField()\n    data = '{\"a\": \"b\"}'\n    initial = '{\"c\": \"d\"}'\n    self.assertEqual(field.bound_data(data, initial), data)\n    self.assertEqual(field.bound_data(None, initial), initial)\n    self.assertEqual(field.bound_data(data, None), data)\n"], "sample_178": ["def test_formset_absolute_max_with_min_num(self):\n    \"\"\"\n    absolute_max has no effect when min_num is greater than absolute_max.\n    \"\"\"\n    data = {\n        'form-TOTAL_FORMS': '3',  # the number of forms rendered\n        'form-INITIAL_FORMS': '0',  # the number of forms with initial data\n        'form-MIN_NUM_FORMS': '4',  # min number of forms\n        'form-MAX_NUM_FORMS': '0',  # max number of forms\n    }\n    LimitedFavoriteDrinksFormSet = formset_factory(\n        FavoriteDrinkForm,\n        min_num=4,\n        absolute_max=3,\n    )\n    formset = LimitedFavoriteDrinksFormSet(data=data)\n    self.assertIs(formset.is_valid(), False)\n    self.assertEqual(\n        formset.non_form_errors(),\n        ['Please submit 4 or more forms.'],\n    )\n"], "sample_174": ["def test_adapt_decimalfield_value(self):\n    value = decimal.Decimal('3.14')\n    max_digits = 5\n    decimal_places = 2\n    self.assertEqual(\n        self.ops.adapt_decimalfield_value(value, max_digits, decimal_places),\n        utils.format_number(value, max_digits, decimal_places)\n    )\n"], "sample_43": ["def test_events_fitness_function():\n    \"\"\"Test results for Events fitness function\"\"\"\n    rng = np.random.RandomState(42)\n\n    # Event Data\n    t = rng.randn(100)\n    edges = bayesian_blocks(t, fitness=Events())\n    assert_allclose(edges, [-2.6197451, -0.71094865, 0.36866702, 1.85227818])\n\n    # Event data with repeats\n    t[80:] = t[:20]\n    edges = bayesian_blocks(t, fitness=Events(p0=0.01))\n    assert_allclose(edges, [-2.6197451, -0.47432431, -0.46202823, 1.85227818])\n\n    # Event data with custom gamma\n    edges = bayesian_blocks(t, fitness=Events(gamma=0.1))\n    assert_allclose(edges, [-2.6197451, -0.47432431, -0.46202823, 1.85227818])\n\n    # Event data with custom ncp_prior\n    edges = bayesian_blocks(t, fitness=Events(ncp_prior=2.302585092994046))\n    assert_allclose(edges, [-2.6197451, -0.47432431, -0.46202823, 1.85227818])\n"], "sample_262": ["def test_lazy_object(self):\n    class Klazz:\n            self.value = value\n\n            return str(self.value)\n\n    lazy_obj = lazy(lambda: Klazz(123), Klazz)()\n    self.assertEqual(str(lazy_obj), '123')\n    self.assertEqual(lazy_obj.value, 123)\n\n    lazy_obj2 = lazy(lambda: Klazz(456), Klazz)()\n    self.assertEqual(str(lazy_obj2), '456')\n    self.assertEqual(lazy_obj2.value, 456)\n\n    self.assertNotEqual(lazy_obj, lazy_obj2)\n"], "sample_107": ["    def test_technical_500_response(self):\n        request = RequestFactory().get('/')\n        exc_type = ValueError\n        exc_value = ValueError('Test exception')\n        tb = None\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html')\n"], "sample_63": ["    def test_dirs_default(self):\n        engine = Engine()\n        self.assertEqual(engine.dirs, [])\n"], "sample_585": ["def test_da_groupby_fillna():\n    array = xr.DataArray([1, 2, np.nan, 4, np.nan, 6],\n                         [('x', [1, 1, 1, 2, 2, 2])])\n\n    expected = xr.DataArray([1, 2, 2, 4, 4, 6], [('x', [1, 1, 1, 2, 2, 2])])\n    actual = array.groupby('x').fillna(2)\n    assert_identical(expected, actual)\n\n    expected = xr.DataArray([1, 2, 1, 4, 4, 6], [('x', [1, 1, 1, 2, 2, 2])])\n    actual = array.groupby('x').fillna(array.mean())\n    assert_identical(expected, actual)\n"], "sample_96": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin, ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            'admin.E034'\n        )\n"], "sample_446": ["    def test_addslashes(self):\n        output = self.engine.render_to_string(\n            \"addslashes01\", {\"a\": \"Hello, 'world'!\"}\n        )\n        self.assertEqual(output, \"Hello, \\\\'world\\!\\\\\")\n        output = self.engine.render_to_string(\n            \"addslashes02\", {\"b\": mark_safe(\"Hello, 'world'!\")}\n        )\n        self.assertEqual(output, \"Hello, \\\\'world\\!\\\\\")\n"], "sample_177": ["def test_get_related_models_tuples(self):\n    \"\"\"\n    Tests get_related_models_tuples returns a set of related models.\n    \"\"\"\n    new_apps = Apps(['migrations'])\n\n    class A(models.Model):\n        class Meta:\n            app_label = \"migrations\"\n            apps = new_apps\n\n    class B(models.Model):\n        a = models.ForeignKey(A, models.CASCADE)\n\n        class Meta:\n            app_label = \"migrations\"\n            apps = new_apps\n\n    class C(models.Model):\n        b = models.ForeignKey(B, models.CASCADE)\n\n        class Meta:\n            app_label = \"migrations\"\n            apps = new_apps\n\n    project_state = ProjectState()\n    project_state.add_model(ModelState.from_model(A))\n    project_state.add_model(ModelState.from_model(B))\n    project_state.add_model(ModelState.from_model(C))\n\n    self.assertEqual(get_related_models_tuples(A), {('migrations', 'b')})\n    self.assertEqual(get_related_models_tuples(B), {('migrations', 'a'), ('migrations', 'c')})\n    self.assertEqual(get_related_models_tuples(C), {('migrations', 'b')})\n"], "sample_646": ["def test_unittest_subclass_with_metaclass(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n\n        class Meta(type):\n            pass\n\n        class MyTestCase(unittest.TestCase, metaclass=Meta):\n                pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n"], "sample_621": ["    def test_default_indexes(self) -> None:\n        coords = {\n            \"x\": xr.Variable(\"x\", [1, 2, 3]),\n            \"y\": xr.Variable(\"y\", [4, 5, 6]),\n            \"z\": xr.Variable((\"x\", \"y\"), [[7, 8], [9, 10]]),\n        }\n        dims = [\"x\", \"y\"]\n\n        expected = {\n            \"x\": PandasIndex([1, 2, 3], \"x\"),\n            \"y\": PandasIndex([4, 5, 6], \"y\"),\n        }\n        actual = default_indexes(coords, dims)\n        for k, v in actual.items():\n            assert v.equals(expected[k])\n"], "sample_784": ["def test_calibration_prefit_multiclass():\n    \"\"\"Test calibration for prefitted multiclass classifiers\"\"\"\n    n_samples = 50\n    X, y = make_blobs(n_samples=3 * n_samples, n_features=6, random_state=42,\n                      centers=3, cluster_std=3.0)\n\n    # split train and test\n    X_train, y_train = X[:n_samples], y[:n_samples]\n    X_calib, y_calib = X[n_samples:2 * n_samples], y[n_samples:2 * n_samples]\n    X_test, y_test = X[2 * n_samples:], y[2 * n_samples:]\n\n    # Naive-Bayes\n    clf = LinearSVC()\n    clf.fit(X_train, y_train)\n    prob_pos_clf = clf.predict_proba(X_test)\n\n    # Naive Bayes with calibration\n    for method in ['isotonic', 'sigmoid']:\n        pc_clf = CalibratedClassifierCV(clf, method=method, cv=\"prefit\")\n        pc_clf.fit(X_calib, y_calib)\n        y_prob = pc_clf.predict_proba(X_test)\n        y_pred = pc_clf.predict(X_test)\n        assert_array_equal(y_pred, np.argmax(y_prob, axis=1))\n\n        assert_greater_equal(log_loss(y_test, prob_pos_clf),\n                             log_loss(y_test, y_prob))\n"], "sample_111": ["def test_get_ordering_field_columns_with_multiple_columns(self):\n    \"\"\"\n    Regression test for #12345: get_ordering_field_columns() should handle\n    multiple columns with the same underlying sort field.\n    \"\"\"\n    class OrderedByFBandAdmin(admin.ModelAdmin):\n        list_display = ['name', 'genres', 'nr_of_members', 'genres']\n        ordering = (\n            F('nr_of_members').desc(nulls_last=True),\n            Upper(F('name')).asc(),\n            F('genres').asc(),\n        )\n\n    m = OrderedByFBandAdmin(Band, custom_site)\n    request = self.factory.get('/band/')\n    request.user = self.superuser\n    cl = m.get_changelist_instance(request)\n    self.assertEqual(cl.get_ordering_field_columns(), {3: 'desc', 2: 'asc', 4: 'asc'})\n"], "sample_116": ["    def test_with_none_vary_on(self):\n        key = make_template_fragment_key('foo', vary_on=None)\n        self.assertEqual(key, 'template.cache.foo.d41d8cd98f00b204e9800998ecf8427e')\n"], "sample_635": ["def test_finds_missing_property_type_sphinx(self) -> None:\n    \"\"\"Example of a property having missing type documentation in\n    a Sphinx style docstring\n    \"\"\"\n    property_node, node = astroid.extract_node(\n        \"\"\"\n    class Foo(object):\n        @property\n            '''docstring ...\n\n            :raises RuntimeError: Always\n            '''\n            raise RuntimeError()\n            return 10 #@\n    \"\"\"\n    )\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"missing-type-doc\", node=property_node)\n    ):\n        self.checker.visit_functiondef(node)\n"], "sample_996": ["def test_doit_with_multiple_limits():\n    x, y, z = symbols('x, y, z', integer=True)\n    assert Product(x*y*z, (x, 1, 3), (y, 1, 3), (z, 1, 3)).doit() == 6**9\n    assert Product(x*y*z, (x, 1, 3), (y, 1, 3), (z, 1, 3)).doit(deep=False) == Product(x*y*z, (x, 1, 3), (y, 1, 3), (z, 1, 3))\n    assert Product(x*y*z, (x, 1, 3), (y, 1, 3), (z, 1, 3)).doit(deep=True) == 6**9\n"], "sample_770": ["def test_silhouette_samples_edge_cases():\n    # Test edge cases for silhouette_samples function\n    # Test with a single sample\n    X = [[1]]\n    labels = [0]\n    with pytest.raises(ValueError):\n        silhouette_samples(X, labels)\n\n    # Test with two samples in the same cluster\n    X = [[1], [1]]\n    labels = [0, 0]\n    result = silhouette_samples(X, labels)\n    assert_array_equal(result, [1, 1])\n\n    # Test with two samples in different clusters\n    X = [[1], [2]]\n    labels = [0, 1]\n    result = silhouette_samples(X, labels)\n    assert_array_equal(result, [1, 1])\n\n    # Test with three samples in the same cluster\n    X = [[1], [1], [1]]\n    labels = [0, 0, 0]\n    result = silhouette_samples(X, labels)\n    assert_array_equal(result, [1, 1, 1])\n\n    # Test with three samples in different clusters\n    X = [[1], [2], [3]]\n    labels = [0, 1, 2]\n    result = silhouette_samples(X, labels)\n    assert_array_equal(result, [1, 1, 1])\n"], "sample_388": ["    def setUp(self):\n        self.backend = ModelBackend()\n"], "sample_1084": ["def test_intersection_sets():\n    assert intersection_sets(S.Integers, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Naturals, S.Integers) == S.Naturals\n    assert intersection_sets(S.Integers, S.Naturals0) == S.Naturals0\n    assert intersection_sets(S.Naturals0, S.Integers) == S.Naturals0\n    assert intersection_sets(S.Integers, S.Rationals) == S.Integers\n    assert intersection_sets(S.Rationals, S.Integers) == S.Integers\n    assert intersection_sets(S.Naturals, S.Rationals) == S.Naturals\n    assert intersection_sets(S.Rationals, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Naturals0, S.Rationals) == S.Naturals0\n    assert intersection_sets(S.Rationals, S.Naturals0) == S.Naturals0\n    assert intersection_sets(S.Integers, S.Reals) == S.Integers\n    assert intersection_sets(S.Reals, S.Integers) == S.Integers\n    assert intersection_sets(S.Naturals, S.Reals) == S.Naturals\n    assert intersection_sets(S.Reals, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Naturals0, S.Reals) == S.Naturals0\n    assert intersection_sets(S.Reals, S.Naturals0) == S.Naturals0\n    assert intersection_sets(S.Rationals, S.Reals) == S.Rationals\n    assert intersection_sets(S.Reals, S.Rationals) == S.Rationals\n    assert intersection_sets(S.Integers, S.Complexes) == S.Integers\n    assert intersection_sets(S.Complexes, S.Integers) == S.Integers\n    assert intersection_sets(S.Naturals, S.Complexes) == S.Naturals\n    assert intersection_sets(S.Complexes, S.Naturals) == S.Naturals\n    assert intersection_sets(S.Naturals0, S.Complexes) == S.Naturals0\n    assert intersection_sets(S.Complexes, S.Naturals0) == S.Naturals0\n    assert intersection_sets(S.Rationals, S.Complexes) == S.Rationals\n    assert intersection_sets(S.Complexes, S.Ration"], "sample_755": ["def test_silhouette_samples_edge_cases():\n    # Test edge cases for silhouette_samples function\n    # Test with a single sample\n    X = np.array([[1, 2]])\n    labels = np.array([0])\n    with pytest.raises(ValueError):\n        silhouette_samples(X, labels)\n\n    # Test with two samples in the same cluster\n    X = np.array([[1, 2], [1, 2]])\n    labels = np.array([0, 0])\n    result = silhouette_samples(X, labels)\n    assert_array_equal(result, [1, 1])\n\n    # Test with two samples in different clusters\n    X = np.array([[1, 2], [3, 4]])\n    labels = np.array([0, 1])\n    result = silhouette_samples(X, labels)\n    assert_array_equal(result, [1, 1])\n\n    # Test with three samples in the same cluster\n    X = np.array([[1, 2], [1, 2], [1, 2]])\n    labels = np.array([0, 0, 0])\n    result = silhouette_samples(X, labels)\n    assert_array_equal(result, [1, 1, 1])\n\n    # Test with three samples in different clusters\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    labels = np.array([0, 1, 2])\n    result = silhouette_samples(X, labels)\n    assert_array_equal(result, [1, 1, 1])\n"], "sample_288": ["    def test_key_transform_factory(self):\n        field = models.JSONField()\n        transform = field.get_transform('key')\n        self.assertIsInstance(transform, KeyTransformFactory)\n        self.assertEqual(transform.key_name, 'key')\n"], "sample_82": ["def test_value_from_datadict_with_l10n(self):\n    with override_settings(USE_L10N=True):\n        data = {'date_year': '2010', 'date_month': '8', 'date_day': '13'}\n        self.assertEqual(self.widget.value_from_datadict(data, {}, 'date'), '13-08-2010')\n        data = {'date_year': '2010', 'date_month': '08', 'date_day': '13'}\n        self.assertEqual(self.widget.value_from_datadict(data, {}, 'date'), '13-08-2010')\n        data = {'date_year': '2010', 'date_month': '8', 'date_day': '13'}\n        self.assertEqual(self.widget.value_from_datadict(data, {}, 'date'), '13-08-2010')\n"], "sample_1207": ["def test_issue_12345():\n    transformations = standard_transformations + (convert_equals_signs, implicit_multiplication)\n    x = Symbol('x')\n    y = Symbol('y')\n    assert parse_expr(\"x = 2*y\", transformations=transformations) == Eq(x, 2*y)\n    assert parse_expr(\"2*x = y\", transformations=transformations) == Eq(2*x, y)\n    assert parse_expr(\"x = y = 2\", transformations=transformations) == Eq(x, Eq(y, 2))\n    assert parse_expr(\"x = 2 = y\", transformations=transformations) == Eq(x, Eq(2, y))\n"], "sample_1109": ["def test_frac_edge_cases():\n    assert frac(0) == 0\n    assert frac(1) == 0\n    assert frac(-1) == 0\n    assert frac(S.Infinity) == AccumBounds(0, 1)\n    assert frac(-S.Infinity) == AccumBounds(0, 1)\n    assert frac(S.ComplexInfinity) == AccumBounds(0, 1)\n    assert frac(S.NaN) == S.NaN\n    assert frac(S.Zero) == 0\n    assert frac(S.One) == 0\n    assert frac(S.NegativeOne) == 0\n    assert frac(S.Half) == S.Half\n    assert frac(-S.Half) == S.Half\n    assert frac(S.ImaginaryUnit) == S.ImaginaryUnit\n    assert frac(-S.ImaginaryUnit) == S.ImaginaryUnit\n"], "sample_1027": ["def test_issue_13079():\n    assert Poly(x)*x == Poly(x**2, x, domain='ZZ')\n    assert x*Poly(x) == Poly(x**2, x, domain='ZZ')\n    assert -2*Poly(x) == Poly(-2*x, x, domain='ZZ')\n    assert S(-2)*Poly(x) == Poly(-2*x, x, domain='ZZ')\n    assert Poly(x)*S(-2) == Poly(-2*x, x, domain='ZZ')\n"], "sample_216": ["def test_field_references(self):\n    \"\"\"\n    Tests the field_references function.\n    \"\"\"\n    model_tuple = (\"testapp\", \"Author\")\n    field = models.ForeignKey(\"testapp.Publisher\", models.CASCADE)\n    reference_model_tuple = (\"testapp\", \"Publisher\")\n    reference_field_name = \"name\"\n\n    # Test when field references the model\n    reference = field_references(model_tuple, field, reference_model_tuple, reference_field_name)\n    self.assertIsNotNone(reference)\n\n    # Test when field does not reference the model\n    field = models.ForeignKey(\"otherapp.Book\", models.CASCADE)\n    reference = field_references(model_tuple, field, reference_model_tuple, reference_field_name)\n    self.assertIsNone(reference)\n\n    # Test when field references the model through a through model\n    field = models.ManyToManyField(\"testapp.Publisher\", through=\"testapp.Contract\")\n    reference = field_references(model_tuple, field, reference_model_tuple, reference_field_name)\n    self.assertIsNotNone(reference)\n\n    # Test when field does not reference the model through a through model\n    field = models.ManyToManyField(\"otherapp.Book\", through=\"otherapp.Attribution\")\n    reference = field_references(model_tuple, field, reference_model_tuple, reference_field_name)\n    self.assertIsNone(reference)\n"], "sample_264": ["def test_store_messages_exceeding_max_cookie_size(self):\n    \"\"\"\n    If the data exceeds what is allowed in a cookie, older messages are\n    removed before saving (and returned by the ``update`` method) when\n    remove_oldest=False.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # When storing as a cookie, the cookie has constant overhead of approx\n    # 54 chars, and each message has a constant overhead of about 37 chars\n    # and a variable overhead of zero in the best case. We aim for a message\n    # size which will fit 4 messages into the cookie, but not 5.\n    # See also FallbackTest.test_session_fallback\n    msg_size = int((CookieStorage.max_cookie_size - 54) / 4.5 - 37)\n    last_msg = None\n    # Generate the same (tested) content every time that does not get run\n    # through zlib compression.\n    random.seed(42)\n    for i in range(5):\n        msg = get_random_string(msg_size)\n        storage.add(constants.INFO, msg)\n        if i == 4:\n            last_msg = msg\n    unstored_messages = storage.update(response, remove_oldest=False)\n\n    cookie_storing = self.stored_messages_count(storage, response)\n    self.assertEqual(cookie_storing, 4)\n\n    self.assertEqual(len(unstored_messages), 1)\n    self.assertEqual(unstored_messages[0].message, last_msg)\n"], "sample_114": ["def test_alter_field_to_fk_dependency_other_app(self):\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author_fk],\n        [self.author_empty, self.book],\n    )\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '__first__')])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"author\")\n    fk_field = changes['otherapp'][0].operations[0].field\n    to_model = '%s.%s' % (\n        fk_field.remote_field.model._meta.app_label,\n        fk_field.remote_field.model._meta.object_name,\n    )\n    self.assertEqual(to_model, 'testapp.Author')\n"], "sample_622": ["def test_encode_cf_variable_with_object_dtype():\n    # regression test for GH1763\n    # Set up test case with coordinates that have overlapping (but not\n    # identical) dimensions.\n    original = Variable((\"x\",), np.array([\"foo\", \"bar\"], dtype=object))\n    expected = Variable((\"x\",), np.array([\"foo\", \"bar\"], dtype=str))\n    actual = conventions.encode_cf_variable(original)\n    assert_identical(expected, actual)\n"], "sample_1132": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((1, 2, 3))) == [(1, 2, 3), (-1, 2, 3), (1, -2, 3), (-1, -2, 3), (1, 2, -3), (-1, 2, -3), (1, -2, -3), (-1, -2, -3)]\n    assert list(permute_signs((1, 0, 0))) == [(1, 0, 0), (-1, 0, 0)]\n    assert list(permute_signs((0, 0, 0))) == [(0, 0, 0)]\n"], "sample_530": ["def test_offsetbox_children_visibility():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100)\n    bg = mpatches.Rectangle((0, 0), 100, 100, facecolor='#CCCCCC',\n                            edgecolor='None', linewidth=0)\n    line = mlines.Line2D([-50, 150], [50, 50], color='black', linewidth=10)\n    anchored_box = AnchoredOffsetbox(\n        loc='center',\n        child=da,\n        pad=0.,\n        frameon=False,\n        bbox_to_anchor=(.5, .5),\n        bbox_transform=ax.transAxes,\n        borderpad=0.)\n\n    da.add_artist(bg)\n    da.add_artist(line)\n    ax.add_artist(anchored_box)\n\n    fig.canvas.draw()\n    assert not fig.stale\n    line.set_visible(False)\n    assert fig.stale\n    bg.set_visible(False)\n    assert fig.stale\n    line.set_visible(True)\n    assert fig.stale\n    bg.set_visible(True)\n    assert fig.stale\n"], "sample_270": ["    def test_model_base_check(self):\n        class Model(models.Model):\n            class Meta:\n                abstract = True\n\n        self.assertEqual(Model.check(), [])\n"], "sample_100": ["    def test_enable_echo(self, mocked_termios):\n        mocked_termios.tcgetattr.return_value = [0, 0, 0, 0]\n        mocked_termios.TCSANOW = 0\n        mocked_termios.ECHO = 1\n        mocked_termios.SIGTTOU = 1\n        mocked_termios.SIG_IGN = 1\n        with mock.patch('django.utils.autoreload.sys.stdin.isatty', return_value=True):\n            autoreload.ensure_echo_on()\n        self.assertEqual(mocked_termios.tcgetattr.call_count, 1)\n        self.assertEqual(mocked_termios.tcsetattr.call_count, 1)\n        self.assertEqual(mocked_termios.signal.call_count, 2)\n"], "sample_650": ["def test_log_cli_level_interaction_with_log_level(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n        logger = logging.getLogger()\n\n            logger.debug('debug text ' + 'going to logger')\n            logger.info('info text ' + 'going to logger')\n            logger.warning('warning text ' + 'going to logger')\n            logger.error('error text ' + 'going to logger')\n            assert 0\n    \"\"\"\n    )\n\n    result = pytester.runpytest(\"--log-cli-level=INFO\", \"--log-level=WARNING\")\n    assert result.ret == 1\n\n    result.stdout.fnmatch_lines(\n        [\n            \"*-- live log call --*\",\n            \"*WARNING*warning text going to logger\",\n            \"*ERROR*error text going to logger\",\n            \"=* 1 failed in *=\",\n        ]\n    )\n    result.stdout.no_re_match_line(\"DEBUG\")\n    result.stdout.no_re_match_line(\"INFO\")\n"], "sample_1015": ["def test_ccode_struct():\n    from sympy.codegen.ast import Struct\n    s = Struct('mystruct', [('a', intc), ('b', float64)])\n    assert ccode(s) == 'typedef struct {\\n   int a;\\n   double b;\\n} mystruct;'\n"], "sample_406": ["    def test_manager_deconstruct(self):\n        manager = BaseManager()\n        manager.model = mock.Mock()\n        manager.name = 'test_manager'\n        deconstructed_manager = manager.deconstruct()\n        self.assertEqual(deconstructed_manager, (\n            False,  # as_manager\n            'django.db.models.manager.BaseManager',  # manager_class\n            None,  # qs_class\n            (),  # args\n            {},  # kwargs\n        ))\n"], "sample_135": ["def test_timezone_offset(self):\n    # Test timezone offset for different timezones\n    tz_names = ['US/Pacific', 'Europe/London', 'Australia/Sydney']\n    for tz_name in tz_names:\n        tz = pytz.timezone(tz_name)\n        dt = datetime(2022, 1, 1, tzinfo=tz)\n        offset = dt.utcoffset().total_seconds() / 3600\n        self.assertEqual(dateformat.format(dt, 'O'), f\"{ '+' if offset >= 0 else '-' }{int(abs(offset))}{int(abs(offset % 1) * 60):02d}\")\n"], "sample_535": ["def test_table_fontsize():\n    fig, ax = plt.subplots()\n    table = ax.table(cellText=[['Fit Text', 'Longer text than default'],\n                             ['Fit Text', 'Longer text than default']],\n                     rowLabels=[\"A\", \"B\"],\n                     colLabels=[\"Col1\", \"Col2\"],\n                     loc=\"center\")\n\n    table.auto_set_font_size(False)\n    table.set_fontsize(12)\n\n    ax.axis('off')\n"], "sample_11": ["def test_dropped_dimensions_serialized_classes():\n    wcs = WCS_SPECTRAL_CUBE\n\n    sub = SlicedLowLevelWCS(wcs, np.s_[:, 0, 0])\n\n    dwd = sub.dropped_world_dimensions\n    wao_classes = dwd.pop(\"world_axis_object_classes\")\n    validate_info_dict(dwd, {\n        \"value\": [12.86995801, 20.49217541],\n        \"world_axis_physical_types\": [\"pos.galactic.lat\", \"pos.galactic.lon\"],\n        \"world_axis_names\": [\"Latitude\", \"Longitude\"],\n        \"world_axis_units\": [\"deg\", \"deg\"],\n        \"serialized_classes\": False,\n        \"world_axis_object_components\": [('celestial', 1, 'spherical.lat.degree'), ('celestial', 0, 'spherical.lon.degree')],\n        })\n\n    assert wao_classes['celestial'][0] is SkyCoord\n    assert wao_classes['celestial'][1] == ()\n    assert isinstance(wao_classes['celestial'][2]['frame'], Galactic)\n    assert wao_classes['celestial'][2]['unit'] is u.deg\n\n    sub = SlicedLowLevelWCS(wcs, np.s_[:, 0, 0], serialized_classes=True)\n\n    dwd = sub.dropped_world_dimensions\n    wao_classes = dwd.pop(\"world_axis_object_classes\")\n    validate_info_dict(dwd, {\n        \"value\": [12.86995801, 20.49217541],\n        \"world_axis_physical_types\": [\"pos.galactic.lat\", \"pos.galactic.lon\"],\n        \"world_axis_names\": [\"Latitude\", \"Longitude\"],\n        \"world_axis_units\": [\"deg\", \"deg\"],\n        \"serialized_classes\": True,\n        \"world_axis_object_components\": [('celestial', 1, 'spherical.lat.degree'), ('celestial', 0, 'spherical.lon.degree')],\n        })\n\n    assert wao_classes['celestial'][0] is SkyCoord\n    assert wao_classes['celestial'][1] == ()\n    assert isinstance(wao_classes['celestial'][2]['frame'], Galactic)\n    assert wao_classes['celestial'][2]['unit'] is u.deg\n"], "sample_602": ["def test_open_dataset():\n    # Create a test dataset\n    data = xr.Dataset(\n        dict(a=2 * np.arange(5)), coords=dict(x=(\"x\", np.arange(5), dict(units=\"s\")))\n    )\n\n    # Save the dataset to a temporary file\n    tmp_file = \"test.nc\"\n    data.to_netcdf(tmp_file)\n\n    # Open the dataset from the temporary file\n    actual = xr.open_dataset(tmp_file)\n\n    # Check if the opened dataset is identical to the original dataset\n    assert_identical(data, actual)\n\n    # Clean up\n    import os\n    os.remove(tmp_file)\n"], "sample_1066": ["def test_print_SingularityFunction():\n    assert mpp.doprint(SingularityFunction(x, 4, 5)) == \\\n        '<msup><mfenced close=\"&#10217;\" open=\"&#10216;\"><mrow><mi>x</mi>' \\\n        '<mo>-</mo><mn>4</mn></mrow></mfenced><mn>5</mn></msup>'\n    assert mpp.doprint(SingularityFunction(x, -3, 4)) == \\\n        '<msup><mfenced close=\"&#10217;\" open=\"&#10216;\"><mrow><mi>x</mi>' \\\n        '<mo>+</mo><mn>3</mn></mrow></mfenced><mn>4</mn></msup>'\n    assert mpp.doprint(SingularityFunction(x, 0, 4)) == \\\n        '<msup><mfenced close=\"&#10217;\" open=\"&#10216;\"><mi>x</mi></mfenced>' \\\n        '<mn>4</mn></msup>'\n    assert mpp.doprint(SingularityFunction(x, a, n)) == \\\n        '<msup><mfenced close=\"&#10217;\" open=\"&#10216;\"><mrow><mrow>' \\\n        '<mo>-</mo><mi>a</mi></mrow><mo>+</mo><mi>x</mi></mrow></mfenced>' \\\n        '<mi>n</mi></msup>'\n    assert mpp.doprint(SingularityFunction(x, 4, -2)) == \\\n        '<msup><mfenced close=\"&#10217;\" open=\"&#10216;\"><mrow><mi>x</mi>' \\\n        '<mo>-</mo><mn>4</mn></mrow></mfenced><mn>-2</mn></msup>'\n    assert mpp.doprint(SingularityFunction(x, 4, -1)) == \\\n        '<msup><mfenced close=\"&#10217;\" open=\"&#10216;\"><mrow><mi>x</mi>' \\\n        '<mo>-</mo><mn>4</mn></mrow></mfenced><mn>-1</mn></msup>'\n"], "sample_12": ["def test_longitude_wrap_at_edge_cases():\n    \"\"\"\n    Test wrapping of Longitude at edge cases\n    \"\"\"\n\n    # Test wrapping at 0 degrees\n    lon = Longitude([0, 360, 720] * u.deg)\n    assert np.all(lon.degree == np.array([0., 0., 0.]))\n\n    # Test wrapping at 180 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='180d')\n    assert np.all(lon.degree == np.array([0., -180., 0.]))\n\n    # Test wrapping at -180 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='-180d')\n    assert np.all(lon.degree == np.array([0., 180., 0.]))\n\n    # Test wrapping at 90 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='90d')\n    assert np.all(lon.degree == np.array([0., -270., 0.]))\n\n    # Test wrapping at -90 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='-90d')\n    assert np.all(lon.degree == np.array([0., 270., 0.]))\n\n    # Test wrapping at 45 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='45d')\n    assert np.all(lon.degree == np.array([0., -315., 0.]))\n\n    # Test wrapping at -45 degrees\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='-45d')\n    assert np.all(lon.degree == np.array([0., 315., 0.]))\n"], "sample_246": ["    def test_build_file_class(self):\n        cmd = MakeMessagesCommand()\n        cmd.domain = 'django'\n        cmd.locale_paths = []\n        cmd.default_locale_path = os.path.join(self.test_dir, 'locale')\n        translatable = cmd.translatable_file_class(self.test_dir, 'test.html', cmd.default_locale_path)\n        build_file = cmd.build_file_class(cmd, cmd.domain, translatable)\n        self.assertEqual(build_file.path, os.path.join(self.test_dir, 'test.html'))\n        self.assertEqual(build_file.work_path, os.path.join(self.test_dir, 'test.html.py'))\n"], "sample_819": ["def test_voting_regressor_with_sample_weight():\n    \"\"\"Test VotingRegressor with sample weights\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(n_estimators=10, random_state=1)\n    ereg = VotingRegressor([('lr', reg1), ('rf', reg2)])\n\n    X_r_train, X_r_test, y_r_train, y_r_test = \\\n        train_test_split(X_r, y_r, test_size=.25)\n\n    sample_weight = np.random.RandomState(123).uniform(size=(len(y_r_train),))\n    ereg.fit(X_r_train, y_r_train, sample_weight=sample_weight)\n    reg1.fit(X_r_train, y_r_train, sample_weight=sample_weight)\n    reg2.fit(X_r_train, y_r_train, sample_weight=sample_weight)\n\n    assert_array_almost_equal(ereg.predict(X_r_test),\n                              np.average([reg1.predict(X_r_test),\n                                          reg2.predict(X_r_test)],\n                                         axis=0))\n    assert_array_almost_equal(ereg.transform(X_r_test),\n                              np.array([reg1.predict(X_r_test),\n                                        reg2.predict(X_r_test)]))\n"], "sample_239": ["def test_formset_absolute_max_with_min_num(self):\n    data = {\n        'form-TOTAL_FORMS': '1001',\n        'form-INITIAL_FORMS': '0',\n        'form-MIN_NUM_FORMS': '0',\n        'form-MAX_NUM_FORMS': '0',\n    }\n    LimitedFavoriteDrinksFormSet = formset_factory(\n        FavoriteDrinkForm,\n        min_num=30,\n        absolute_max=1000,\n    )\n    formset = LimitedFavoriteDrinksFormSet(data=data)\n    self.assertIs(formset.is_valid(), False)\n    self.assertEqual(len(formset.forms), 1000)\n    self.assertEqual(\n        formset.non_form_errors(),\n        ['Please submit at least 30 forms.'],\n    )\n"], "sample_904": ["def test_resolve_xref_with_program_option(app):\n    text = (\".. program:: ls\\n\"\n            \"\\n\"\n            \".. option:: -l\\n\")\n    restructuredtext.parse(app, text)\n    domain = app.env.get_domain(\"std\")\n    node = pending_xref(reftype='option', reftarget='-l')\n    refnode = domain.resolve_xref(app.env, 'index', app.builder, 'option', '-l', node, nodes.paragraph())\n    assert_node(refnode, nodes.reference, refid=\"cmdoption-ls-l\")\n"], "sample_1086": ["def test_Pow_with_noncommutative_base():\n    A, B = symbols('A B', commutative=False)\n    assert str(A**2) == \"A**2\"\n    assert str(A**-2) == \"A**(-2)\"\n    assert str(A**Rational(1, 2)) == \"sqrt(A)\"\n    assert str(A**-Rational(1, 2)) == \"A**(-1/2)\"\n    assert str(A**B) == \"A**B\"\n    assert str(A**-B) == \"A**(-B)\"\n"], "sample_46": ["    def test_lookup_name(self):\n        lookup = Lookup(None, None)\n        self.assertIsNone(lookup.lookup_name)\n"], "sample_525": ["def test_subfigure_subplotspec():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    subfig = fig.add_subfigure(gs[0, 1])\n    assert subfig._subplotspec == gs[0, 1]\n    assert subfig._subplotspec.get_gridspec() == gs\n    assert subfig._subplotspec.get_topmost_subplotspec() == gs[0, 1]\n"], "sample_537": ["def test_cohere_complex():\n    N = 1024\n    np.random.seed(19680801)\n    x = np.random.randn(N) + 1j*np.random.randn(N)\n    # phase offset\n    y = np.roll(x, 20)\n    # high-freq roll-off\n    y = np.convolve(y, np.ones(20) / 20., mode='same')\n    cohsq, f = mlab.cohere(x, y, NFFT=256, Fs=2, noverlap=128)\n    assert_allclose(np.mean(cohsq), 0.837, atol=1.e-3)\n    assert np.isreal(np.mean(cohsq))\n"], "sample_931": ["def test_pyvariable(app):\n    text = (\".. py:variable:: var\\n\"\n            \"   :type: int\\n\"\n            \"   :value: 1\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"var\"],\n                                                    [desc_annotation, (\": \",\n                                                                       [pending_xref, \"int\"])],\n                                                    [desc_annotation, \" = 1\"])],\n                                  [desc_content, ()])]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n    assert 'var' in domain.objects\n    assert domain.objects['var'] == ('index', 'var', 'data')\n"], "sample_1163": ["def test_periodic_argument_edge_cases():\n    from sympy import periodic_argument, oo, pi, I, exp_polar\n    assert periodic_argument(0, oo) == 0\n    assert periodic_argument(0, pi) == 0\n    assert periodic_argument(0, -pi) is None\n    assert periodic_argument(0, I) is None\n    assert periodic_argument(0, exp_polar(I*pi)) is None\n    assert periodic_argument(oo, oo) is None\n    assert periodic_argument(-oo, oo) is None\n    assert periodic_argument(oo, pi) is None\n    assert periodic_argument(-oo, pi) is None\n    assert periodic_argument(oo, -pi) is None\n    assert periodic_argument(-oo, -pi) is None\n    assert periodic_argument(oo, I) is None\n    assert periodic_argument(-oo, I) is None\n    assert periodic_argument(oo, exp_polar(I*pi)) is None\n    assert periodic_argument(-oo, exp_polar(I*pi)) is None\n"], "sample_534": ["def test_contour_labeler_event_handler():\n    # Test the event handler for contour labeler\n    cs = ContourSet(None, levels=[1, 2, 3], allsegs=[[[[0, 0], [1, 1]]]])\n    event = type('Event', (), {'name': 'button_press_event', 'button': 1, 'x': 0.5, 'y': 0.5, 'inaxes': True})\n    _contour_labeler_event_handler(cs, inline=True, inline_spacing=5, event=event)\n    assert len(cs.labelTexts) == 1\n    assert len(cs.labelCValues) == 1\n    assert len(cs.labelXYs) == 1\n\n    event = type('Event', (), {'name': 'button_press_event', 'button': 3, 'x': 0.5, 'y': 0.5, 'inaxes': True})\n    _contour_labeler_event_handler(cs, inline=True, inline_spacing=5, event=event)\n    assert len(cs.labelTexts) == 0\n    assert len(cs.labelCValues) == 0\n    assert len(cs.labelXYs) == 0\n\n    event = type('Event', (), {'name': 'key_press_event', 'key': 'enter', 'x': 0.5, 'y': 0.5, 'inaxes': True})\n    _contour_labeler_event_handler(cs, inline=True, inline_spacing=5, event=event)\n    assert len(cs.labelTexts) == 0\n    assert len(cs.labelCValues) == 0\n    assert len(cs.labelXYs) == 0\n"], "sample_410": ["    def test_get_session_auth_hash(self):\n        user = User.objects.create_user(username=\"test\", password=\"test\")\n        session_auth_hash = user.get_session_auth_hash()\n        self.assertIsInstance(session_auth_hash, str)\n        self.assertEqual(len(session_auth_hash), 64)  # length of a SHA-256 hash\n"], "sample_1093": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n\n    assert prntr.doprint(pi) == 'math.pi'\n    assert prntr.module_imports == {'math': {'pi'}}\n\n    assert prntr.doprint(x**Rational(1, 2)) == 'math.sqrt(x)'\n    assert prntr.doprint(sqrt(x)) == 'math.sqrt(x)'\n    assert prntr.module_imports == {'math': {'pi', 'sqrt'}}\n\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n\n    assert prntr._print_Infinity(oo) == 'float(\"inf\")'\n    assert prntr._print_NegativeInfinity(-oo) == 'float(\"-inf\")'\n    assert prntr._print_NaN(zoo) == 'float(\"nan\")'\n    assert prntr._print_ComplexInfinity(zoo) == 'float(\"nan\")'\n\n    assert prntr._print_Relational(Eq(x, y)) == '(x == y)'\n    assert prntr._print"], "sample_209": ["    def test_save_base_force_insert_force_update(self):\n        msg = \"Cannot force both insert and updating in model saving.\"\n        with self.assertRaisesMessage(ValueError, msg):\n            Article.objects.create(headline=\"Test\", pub_date=datetime.datetime.now()).save(force_insert=True, force_update=True)\n"], "sample_145": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin, ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            'admin.E034'\n        )\n"], "sample_861": ["def test_grid_search_with_callable_refit():\n    # Test GridSearchCV with callable refit\n    X, y = make_classification(n_samples=100, n_features=4, random_state=42)\n\n        return cv_results['mean_test_score'].argmax()\n\n    grid_search = GridSearchCV(SVC(random_state=42), {'C': [0.01, 0.1, 1]},\n                               scoring='precision', refit=refit_callable)\n    grid_search.fit(X, y)\n\n    assert hasattr(grid_search, 'best_index_')\n    assert hasattr(grid_search, 'best_params_')\n    assert hasattr(grid_search, 'best_estimator_')\n    assert not hasattr(grid_search, 'best_score_')\n"], "sample_596": ["def test_concat_positions_kwarg():\n    data = Dataset({\"foo\": (\"x\", np.random.randn(10))})\n    objs = [data.isel(x=slice(5)), data.isel(x=slice(5, None))]\n    positions = [0, 1]\n    expected = concat(objs, dim=\"x\")\n    actual = concat(objs, dim=\"x\", positions=positions)\n    assert_identical(expected, actual)\n\n    positions = [1, 0]\n    expected = concat(objs[::-1], dim=\"x\")\n    actual = concat(objs, dim=\"x\", positions=positions)\n    assert_identical(expected, actual)\n\n    with raises_regex(ValueError, \"length of positions does not match\"):\n        concat(objs, dim=\"x\", positions=[0])\n\n    with raises_regex(ValueError, \"positions must be a 1-dimensional\"):\n        concat(objs, dim=\"x\", positions=[[0, 1]])\n"], "sample_1182": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(-Mod(x, y)) == '-(x % y)'\n    assert prntr.doprint(Mod(-x, y)) == '(-x) % y'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n    assert not prntr.module_imports\n\n    assert prntr.doprint(pi) == 'pi'\n    assert prntr.module_imports == set()\n\n    assert prntr.doprint(x**Rational(1, 2)) == 'x**(1/2)'\n    assert prntr.doprint(sqrt(x)) == 'sqrt(x)'\n    assert prntr.module_imports == set()\n\n    assert prntr.doprint(acos(x)) == 'acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else copysign(1, x))'\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n    assert prntr.doprint(KroneckerDelta(x,y)) == '(1 if x == y else 0)'\n\n    assert prntr.doprint((2,3)) == \"(2, 3)\"\n    assert prntr.doprint([2,3]) == \"[2, 3]\"\n\n    assert pr"], "sample_1169": ["def test_substitute_dummies_with_dummies():\n    i, j = symbols('i j', below_fermi=True, cls=Dummy)\n    a, b = symbols('a b', above_fermi=True, cls=Dummy)\n    p, q = symbols('p q', cls=Dummy)\n    f = Function('f')\n    assert substitute_dummies(f(i, a, p) - f(j, b, q)) == 2*f(_a, _i, _p)\n"], "sample_277": ["def test_resolve_expression(self):\n    q = Q(price__gt=F('discounted_price'))\n    query = object()  # Mock query object\n    clause, joins = q.resolve_expression(query)\n    self.assertIsNotNone(clause)\n    self.assertIsNotNone(joins)\n"], "sample_1185": ["def test_decompogen_edge_cases():\n    assert decompogen(exp(x), x) == [exp(x)]\n    assert decompogen(exp(x**2), x) == [exp(x), x**2]\n    assert decompogen(exp(x + 1), x) == [exp(x), x + 1]\n    assert decompogen(exp(x + y), x) == [exp(x + y)]\n    assert decompogen(exp(x + y), y) == [exp(x + y)]\n    assert decompogen(exp(x + y), x) == [exp(x + y)]\n    assert decompogen(exp(x + y), y) == [exp(x + y)]\n    assert decompogen(exp(x + y), x) == [exp(x + y)]\n    assert decompogen(exp(x + y), y) == [exp(x + y)]\n    assert decompogen(exp(x + y), x) == [exp(x + y)]\n    assert decompogen(exp(x + y), y) == [exp(x + y)]\n    assert decompogen(exp(x + y), x) == [exp(x + y)]\n    assert decompogen(exp(x + y), y) == [exp(x + y)]\n    assert decompogen(exp(x + y), x) == [exp(x + y)]\n    assert decompogen(exp(x + y), y) == [exp(x + y)]\n    assert decompogen(exp(x + y), x) == [exp(x + y)]\n    assert decompogen(exp(x + y), y) == [exp(x + y)]\n    assert decompogen(exp(x + y), x) == [exp(x + y)]\n    assert decompogen(exp(x + y), y) == [exp(x + y)]\n    assert decompogen(exp(x + y), x) == [exp(x + y)]\n    assert decompogen(exp(x + y), y) == [exp(x + y)]\n    assert decompogen(exp(x + y), x) == [exp(x + y)]\n    assert decompogen(exp(x + y), y) == [exp(x + y)]\n    assert decompogen(exp(x + y), x) == [exp(x + y)]\n    assert decompogen(exp(x + y), y) == [exp(x + y)]\n    assert decompogen(exp(x + y), x) == [exp(x + y)]\n    assert decompogen"], "sample_448": ["    def test_validate_expression_with_function(self):\n        constraint = models.UniqueConstraint(\n            Lower(\"name\"), name=\"name_lower_uniq\"\n        )\n        msg = \"Constraint \u201cname_lower_uniq\u201d is violated.\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            constraint.validate(\n                UniqueConstraintProduct,\n                UniqueConstraintProduct(name=self.p1.name.upper()),\n            )\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=\"another-name\"),\n        )\n        # Existing instances have their existing row excluded.\n        constraint.validate(UniqueConstraintProduct, self.p1)\n        # Unique field is excluded.\n        constraint.validate(\n            UniqueConstraintProduct,\n            UniqueConstraintProduct(name=self.p1.name.upper()),\n            exclude={\"name\"},\n        )\n"], "sample_645": ["def test_log_capture_handler_reset(caplog):\n    caplog.set_level(logging.INFO)\n    logger.info(\"boo %s\", \"arg\")\n    assert len(caplog.records) == 1\n    assert len(caplog.handler.records) == 1\n    caplog.handler.reset()\n    assert len(caplog.records) == 1\n    assert len(caplog.handler.records) == 0\n    logger.info(\"bar %s\", \"arg\")\n    assert len(caplog.records) == 2\n    assert len(caplog.handler.records) == 1\n"], "sample_707": ["def test_node_repr_failure_with_conftest_import_failure(pytester: Pytester) -> None:\n    \"\"\"Test that repr_failure handles ConftestImportFailure correctly.\"\"\"\n    pytester.makeconftest(\n        \"\"\"\n        raise Exception(\"conftest import failure\")\n    \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*conftest import failure*\"])\n"], "sample_782": ["def test_column_transformer_sparse_remainder_transformer_with_weights():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           sparse_threshold=0.8,\n                           transformer_weights={'trans1': 2})\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n    # SparseMatrixTrans creates 3 features for each column. There is\n    # one column in ``transformers``, thus:\n    assert X_trans.shape == (3, 3 + 1)\n\n    exp_array = np.hstack(\n        (2 * X_array[:, 0].reshape(-1, 1), np.eye(3)))\n    assert_array_equal(X_trans.toarray(), exp_array)\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], SparseMatrixTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n"], "sample_367": ["    def test_cache_page_decorator(self):\n            return HttpResponse(\"response\")\n\n        my_view_cached = cache_page(123)(my_view)\n        request = HttpRequest()\n        response = my_view_cached(request)\n        self.assertEqual(response.content, b\"response\")\n"], "sample_356": ["def test_alter_field_with_deconstructible_default(self):\n    \"\"\"\n    AlterField with deconstructible default should not prompt for a default.\n    \"\"\"\n    before = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=200, default=DeconstructibleObject())),\n    ])\n    after = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"name\", models.CharField(max_length=400, default=DeconstructibleObject())),\n    ])\n    with mock.patch('django.db.migrations.questioner.MigrationQuestioner.ask_not_null_alteration',\n                   side_effect=AssertionError(\"Should not have prompted for not null addition\")):\n        changes = self.get_changes([before], [after])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True)\n"], "sample_202": ["def test_not_finished_sentinel(self):\n    \"\"\"\n    The not_finished sentinel value is correctly handled when decoding\n    messages from the cookie.\n    \"\"\"\n    storage = self.get_storage()\n    messages = [Message(constants.INFO, 'message %s') for x in range(5)]\n    messages.append(CookieStorage.not_finished)\n    set_cookie_data(storage, messages)\n    decoded_messages, all_retrieved = storage._get()\n    self.assertEqual(len(decoded_messages), 5)\n    self.assertFalse(all_retrieved)\n"], "sample_817": ["def test_variance_threshold_with_negative_values():\n    # Test VarianceThreshold with custom variance and negative values.\n    data = [[-1, 0, 2, 3, 4],\n            [-1, 2, 2, 3, 5],\n            [0, 1, 2, 4, 0]]\n    for X in [data, csr_matrix(data)]:\n        X = VarianceThreshold(threshold=.4).fit_transform(X)\n        assert_equal((len(data), 1), X.shape)\n"], "sample_982": ["def test_factorint_visual_input():\n    assert factorint(factorint(42, visual=True)) == {2: 1, 3: 1, 7: 1}\n    assert factorint(factorint(42, visual=True), visual=True) == \\\n        Mul(Pow(2, 1, evaluate=False), Pow(3, 1, evaluate=False),\n            Pow(7, 1, evaluate=False), evaluate=False)\n    assert factorint(factorint(42, visual=True), multiple=True) == [2, 3, 7]\n    assert factorint(factorint(42, visual=True), limit=3) == {2: 1, 3: 1, 7: 1}\n    assert factorint(factorint(42, visual=True), use_trial=False) == {2: 1, 3: 1, 7: 1}\n    assert factorint(factorint(42, visual=True), use_rho=False) == {2: 1, 3: 1, 7: 1}\n    assert factorint(factorint(42, visual=True), use_pm1=False) == {2: 1, 3: 1, 7: 1}\n    assert factorint(factorint(42, visual=True), verbose=True) == {2: 1, 3: 1, 7: 1}\n"], "sample_280": ["def test_aggregate_with_empty_default(self):\n    # Test that an empty default value is correctly handled.\n    result = Author.objects.filter(age__gt=100).aggregate(\n        value=Avg('age', default=''),\n    )\n    self.assertEqual(result['value'], '')\n\n    result = Author.objects.filter(age__gt=100).aggregate(\n        value=Sum('age', default=''),\n    )\n    self.assertEqual(result['value'], '')\n\n    result = Author.objects.filter(age__gt=100).aggregate(\n        value=Max('age', default=''),\n    )\n    self.assertEqual(result['value'], '')\n\n    result = Author.objects.filter(age__gt=100).aggregate(\n        value=Min('age', default=''),\n    )\n    self.assertEqual(result['value'], '')\n\n    result = Author.objects.filter(age__gt=100).aggregate(\n        value=Count('age', default=''),\n    )\n    self.assertEqual(result['value'], '')\n\n    result = Author.objects.filter(age__gt=100).aggregate(\n        value=StdDev('age', default=''),\n    )\n    self.assertEqual(result['value'], '')\n\n    result = Author.objects.filter(age__gt=100).aggregate(\n        value=Variance('age', default=''),\n    )\n    self.assertEqual(result['value'], '')\n"], "sample_183": ["    def test_window_function(self):\n        self.assertQuerysetEqual(\n            CaseTestModel.objects.annotate(\n                row_number=Window(\n                    expression=RowRange(),\n                    partition_by=F('integer'),\n                    order_by=F('integer').asc(),\n                ),\n            ).order_by('integer', 'pk'),\n            [(1, 1), (2, 1), (2, 2), (3, 1), (3, 2), (3, 3), (4, 1)],\n            transform=attrgetter('integer', 'row_number')\n        )\n"], "sample_896": ["def test_nmf_beta_loss_error():\n    # Test that an error is raised if beta_loss is not valid\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((6, 5))\n    nmf = NMF(n_components=2, random_state=0)\n\n    with pytest.raises(ValueError, match=\"Invalid beta_loss parameter\"):\n        nmf.fit(X, beta_loss=3.0)\n\n    with pytest.raises(ValueError, match=\"Invalid beta_loss parameter\"):\n        nmf.fit(X, beta_loss=\"invalid\")\n"], "sample_121": ["    def test_model_base_check(self):\n        class Model(models.Model):\n            class Meta:\n                abstract = True\n\n        self.assertEqual(Model.check(), [])\n"], "sample_181": ["def test_filtered_aggregate_ref_subquery_annotation_with_filter(self):\n    aggs = Author.objects.annotate(\n        earliest_book_year=Subquery(\n            Book.objects.filter(\n                contact__pk=OuterRef('pk'),\n                rating__gt=3,\n            ).order_by('pubdate').values('pubdate__year')[:1]\n        ),\n    ).aggregate(\n        cnt=Count('pk', filter=Q(earliest_book_year=2008)),\n    )\n    self.assertEqual(aggs['cnt'], 1)\n"], "sample_703": ["def test_matcher_adapter() -> None:\n    matcher = MatcherAdapter(lambda ident: ident == \"true\")\n    assert matcher[\"$true\"]\n    assert not matcher[\"$false\"]\n    with pytest.raises(KeyError):\n        matcher[\"$unknown\"]\n"], "sample_1097": ["def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, m)\n    X = BlockMatrix([[A, B]])\n    real_matrices, im_matrices = X.as_real_imag()\n    assert real_matrices.blocks[0, 0] == re(A)\n    assert real_matrices.blocks[0, 1] == re(B)\n    assert im_matrices.blocks[0, 0] == im(A)\n    assert im_matrices.blocks[0, 1] == im(B)\n"], "sample_171": ["def test_migrate_fake_initial_with_replaced_migration(self):\n    \"\"\"\n    --fake-initial works with replaced migrations.\n    \"\"\"\n    recorder = MigrationRecorder(connection)\n    recorder.record_applied(\"migrations\", \"0001_initial\")\n    recorder.record_applied(\"migrations\", \"0002_second\")\n    recorder.record_applied(\"migrations\", \"0001_squashed_0002\")\n    out = io.StringIO()\n    call_command(\"migrate\", \"migrations\", fake_initial=True, stdout=out, verbosity=1)\n    self.assertIn(\"migrations.0001_squashed_0002... faked\", out.getvalue().lower())\n    # Rollback changes\n    call_command(\"migrate\", \"migrations\", \"zero\", verbosity=0)\n"], "sample_767": ["def test_column_transformer_transformer_weights():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n\n    # test with transformer_weights\n    transformer_weights = {'trans1': .1, 'trans2': 10}\n    both = ColumnTransformer([('trans1', Trans(), [0]),\n                              ('trans2', Trans(), [1])],\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * np.array([0, 1, 2]),\n                     transformer_weights['trans2'] * np.array([2, 4, 6])]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and remainder\n    transformer_weights = {'trans1': .1}\n    both = ColumnTransformer([('trans1', Trans(), [0])],\n                             remainder='passthrough',\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * np.array([0, 1, 2]),\n                     np.array([2, 4, 6])]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and remainder transformer\n    transformer_weights = {'trans1': .1}\n    both = ColumnTransformer([('trans1', Trans(), [0])],\n                             remainder=DoubleTrans(),\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * np.array([0, 1, 2]),\n                     2 * np.array([2, 4, 6])]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and all transformers are 'passthrough'\n    transformer_weights = {'trans1': .1, 'trans2': 10}\n    both = ColumnTransformer([('trans1', 'passthrough', [0]),\n                              ('trans2', 'passthrough', [1])],\n                             transformer"], "sample_876": ["def test_mlp_warm_start_with_partial_fit(MLPEstimator):\n    \"\"\"Check that warm start works with partial fit.\"\"\"\n    mlp = MLPEstimator(\n        max_iter=10, random_state=0, warm_start=True, solver=\"sgd\"\n    )\n    mlp.partial_fit(X_iris[:50], y_iris[:50])\n    n_iter = mlp.n_iter_\n    mlp.partial_fit(X_iris[50:100], y_iris[50:100])\n    assert mlp.n_iter_ > n_iter\n"], "sample_803": ["def test_roc_auc_score_multiclass():\n    # Test that roc_auc_score raises an error for multiclass problems\n    y_true, _, probas_pred = make_prediction(binary=False)\n    assert_raises(ValueError, roc_auc_score, y_true, probas_pred)\n"], "sample_850": ["def test_nystroem_stateless():\n    # Test that Nystroem is stateless\n    rnd = np.random.RandomState(42)\n    X = rnd.uniform(size=(10, 4))\n\n    nystroem = Nystroem(n_components=5, random_state=rnd)\n    X_trans1 = nystroem.fit_transform(X)\n    X_trans2 = nystroem.fit_transform(X)\n\n    assert_array_almost_equal(X_trans1, X_trans2)\n"], "sample_373": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n"], "sample_253": ["    def test_empty_paths(self):\n        self.assertEqual(autoreload.common_roots(()), ())\n"], "sample_258": ["def test_receiver_decorator_with_sender(self):\n    @receiver(a_signal, sender=self)\n        self.state = val\n    self.state = False\n    a_signal.send(sender=self, val=True)\n    self.assertTrue(self.state)\n\n    # Test that the receiver is not called when the sender is different\n    a_signal.send(sender=object(), val=False)\n    self.assertTrue(self.state)\n\n    # Test that the receiver is not called when the signal is different\n    b_signal.send(sender=self, val=False)\n    self.assertTrue(self.state)\n"], "sample_81": ["    def test_resolve(self):\n        pattern = RegexPattern(r'^articles/(?P<year>[0-9]{4})/$', name='article-detail')\n        url_pattern = URLPattern(pattern, lambda x: x, name='article-detail')\n        match = url_pattern.resolve('/articles/2022/')\n        self.assertEqual(match.func, lambda x: x)\n        self.assertEqual(match.args, ())\n        self.assertEqual(match.kwargs, {'year': '2022'})\n        self.assertEqual(match.url_name, 'article-detail')\n        self.assertEqual(match.route, '^articles/(?P<year>[0-9]{4})/$')\n"], "sample_1131": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n    assert prntr._print_Infinity(S.Infinity) == 'float(\"inf\")'\n    assert prntr._print_NegativeInfinity(S.NegativeInfinity) == 'float(\"-inf\")'\n    assert prntr._print_NaN(S.NaN) == 'float(\"nan\")'\n    assert prntr._print_ComplexInfinity(S.ComplexInfinity) == 'float(\"nan\")'\n    assert prntr._print_Mod(Mod(x, 2)) == 'x % 2'\n    assert prntr._print_Piecewise(Piecewise((1, Eq(x, 0)), (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr._print_Relational(Eq(x, y)) == '(x == y)'\n    assert prntr._print_ITE(Piecewise((1, Eq(x, 0)), (2, x>6)).rewrite('ite')) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr._print_Sum(Sum(x, (x, 0, 1))) == '(builtins.sum((x for x in range(0, 1+1)))'\n    assert prntr._print_ImaginaryUnit(S.ImaginaryUnit) == '1j'\n    assert prntr._print_KroneckerDelta(KroneckerDelta(x, y)) == '(1 if x == y else 0)'\n    assert prntr._print_MatrixBase(Matrix([[1, 2], [3, 4]])) == 'Matrix([[1, 2], [3, 4]])'\n    assert prntr._print_FunctionDefinition(Assignment(x, 2)) == 'def x():\\n    return 2'\n    assert prntr._print_While(Assignment(x, 2)) == 'while True:\\n    x = 2'\n    assert prntr._print_Declaration(Assignment(x, 2)) == 'x = 2'\n    assert prntr._print_Return(Assignment(x, 2)) == 'return x'\n    assert prntr._print_Print(Assignment(x, 2)) == 'print"], "sample_790": ["def test_kernel_pca_copy_X():\n    rng = np.random.RandomState(0)\n    X_fit = rng.random_sample((5, 4))\n    X_pred = rng.random_sample((2, 4))\n\n    # Test that X_fit_ is a copy when copy_X=True\n    kpca = KernelPCA(copy_X=True)\n    kpca.fit(X_fit)\n    X_fit[0, 0] = 666\n    assert_not_equal(kpca.X_fit_[0, 0], 666)\n\n    # Test that X_fit_ is not a copy when copy_X=False\n    kpca = KernelPCA(copy_X=False)\n    kpca.fit(X_fit)\n    X_fit[0, 0] = 666\n    assert_equal(kpca.X_fit_[0, 0], 666)\n"], "sample_628": ["def test_store_unknown_words(self):\n    self.checker.config.spelling_store_unknown_words = True\n    self.checker.open()\n    stmt = astroid.extract_node('def fff():\\n   \"\"\"bad coment\"\"\"\\n   pass')\n    self.checker.visit_functiondef(stmt)\n    assert self.linter.release_messages() == []\n    with open(self.checker.config.spelling_private_dict_file, \"r\") as f:\n        assert f.read().strip() == \"coment\"\n"], "sample_485": ["def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            \"Search for google.com/?q=! and see.\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>! and see.',\n        ),\n        (\n            \"Search for google.com/?q=!?\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>!?',\n        ),\n        (\n            \"Search for google.com/?q=!.\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>!.',\n        ),\n        (\n            \"Search for google.com/?q=!;\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>!;',\n        ),\n        (\n            \"Search for google.com/?q=!:\",\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>!:',\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_743": ["def test_neighbors_base_init():\n    # Test that NeighborsBase's __init__ method raises an error\n    # when n_neighbors is not provided and radius is not provided\n    with assert_raises(ValueError):\n        neighbors.NeighborsBase(n_neighbors=None, radius=None)\n"], "sample_128": ["    def test_covering_index_with_opclasses(self):\n        index = Index(\n            name='covering_headline_idx',\n            fields=['headline'],\n            include=['pub_date', 'published'],\n            opclasses=['varchar_pattern_ops'],\n        )\n        with connection.schema_editor() as editor:\n            self.assertIn(\n                '(%s varchar_pattern_ops) INCLUDE (%s, %s)' % (\n                    editor.quote_name('headline'),\n                    editor.quote_name('pub_date'),\n                    editor.quote_name('published'),\n                ),\n                str(index.create_sql(Article, editor)),\n            )\n            editor.add_index(Article, index)\n            with connection.cursor() as cursor:\n                constraints = connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                )\n                self.assertIn(index.name, constraints)\n                self.assertEqual(\n                    constraints[index.name]['columns'],\n                    ['headline', 'pub_date', 'published'],\n                )\n            editor.remove_index(Article, index)\n            with connection.cursor() as cursor:\n                self.assertNotIn(index.name, connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                ))\n"], "sample_7": ["def test_column_copy_indices(Column):\n    c = Column([1, 2, 3], name='a', dtype=int, unit='mJy', format='%i',\n               description='test column', meta={'c': 8, 'd': 12})\n    c2 = c.copy(copy_indices=False)\n    assert c2.indices == []\n    c3 = c.copy(copy_indices=True)\n    assert c3.indices == c.indices\n"], "sample_670": ["def test_matcher_function(expr: str, matcher: Callable[[str], bool], expected: bool) -> None:\n    assert evaluate(expr, matcher) is expected\n"], "sample_411": ["def test_base_command_stealth_options(self):\n    class Command(BaseCommand):\n        stealth_options = (\"foo\", \"bar\")\n\n    cmd = Command()\n    self.assertEqual(cmd.base_stealth_options, (\"stderr\", \"stdout\"))\n    self.assertEqual(cmd.stealth_options, (\"foo\", \"bar\"))\n\n    class Command(BaseCommand):\n        base_stealth_options = (\"foo\", \"bar\")\n\n    cmd = Command()\n    self.assertEqual(cmd.base_stealth_options, (\"foo\", \"bar\"))\n    self.assertEqual(cmd.stealth_options, ())\n\n    class Command(BaseCommand):\n        base_stealth_options = (\"foo\", \"bar\")\n        stealth_options = (\"baz\", \"qux\")\n\n    cmd = Command()\n    self.assertEqual(cmd.base_stealth_options, (\"foo\", \"bar\"))\n    self.assertEqual(cmd.stealth_options, (\"baz\", \"qux\"))\n"], "sample_1129": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n\n    assert prntr._print_Infinity(S.Infinity) == 'float(\"inf\")'\n    assert prntr._print_NegativeInfinity(S.NegativeInfinity) == 'float(\"-inf\")'\n    assert prntr._print_ComplexInfinity(S.ComplexInfinity) == 'float(\"nan\")'\n    assert prntr._print_NaN(S.NaN) == 'float(\"nan\")'\n\n    assert prntr._print_Sum(Sum(x, (x, 0, 10))) == '(builtins.sum(x for x in range(0, 10+1)))'\n    assert prntr._print_ImaginaryUnit(S.ImaginaryUnit) == '1j'\n\n    assert prntr._print_KroneckerDelta(KroneckerDelta(x, y)) == '(1 if x == y else 0)'\n    assert prntr._print_Piecewise(Piecewise((x, Eq(x, 0)), (y, Eq(x, 1)))) == '((x) if (x == 0) else (y) if (x == 1) else None)'\n    assert prntr._print_Relational(Eq(x, y)) == '(x == y)'\n    assert prntr._print_Relational(Le(x, y)) == '(x <= y)'\n    assert prntr._print_Relational(Gt(x, y)) == '(x > y)'\n"], "sample_254": ["    def setUp(self):\n        self.user = User.objects.create_superuser('super', 'super@example.com', 'secret')\n        self.client.force_login(self.user)\n"], "sample_546": ["def test_figure_subplots_adjust():\n    fig, axs = plt.subplots(2, 2)\n    axs[0, 0].set_title('Top Left')\n    axs[0, 1].set_title('Top Right')\n    axs[1, 0].set_title('Bottom Left')\n    axs[1, 1].set_title('Bottom Right')\n\n    fig.subplots_adjust(left=0.2, bottom=0.2, right=0.8, top=0.8)\n    assert axs[0, 0].get_position().x0 == 0.2\n    assert axs[0, 0].get_position().y0 == 0.2\n    assert axs[0, 1].get_position().x0 == 0.5\n    assert axs[0, 1].get_position().y0 == 0.2\n    assert axs[1, 0].get_position().x0 == 0.2\n    assert axs[1, 0].get_position().y0 == 0.0\n    assert axs[1, 1].get_position().x0 == 0.5\n    assert axs[1, 1].get_position().y0 == 0.0\n\n    fig.subplots_adjust(wspace=0.1, hspace=0.1)\n    assert axs[0, 0].get_position().width == 0.3\n    assert axs[0, 0].get_position().height == 0.4\n    assert axs[0, 1].get_position().width == 0.3\n    assert axs[0, 1].get_position().height == 0.4\n    assert axs[1, 0].get_position().width == 0.3\n    assert axs[1, 0].get_position().height == 0.4\n    assert axs[1, 1].get_position().width == 0.3\n    assert axs[1, 1].get_position().height == 0.4\n"], "sample_459": ["    def test_lookup_identity(self):\n        lookup = Lookup(Value(1), Value(2))\n        self.assertEqual(lookup.identity, (Lookup, Value(1), Value(2)))\n"], "sample_1194": ["def test_julia_codeprinter():\n    printer = JuliaCodePrinter()\n    assert printer._rate_index_position(1) == 5\n    assert printer._get_statement(\"x = 5\") == \"x = 5\"\n    assert printer._get_comment(\"This is a comment\") == \"# This is a comment\"\n    assert printer._declare_number_const(\"pi\", \"3.14\") == \"const pi = 3.14\"\n    assert printer._format_code([\"x = 5\", \"y = 3\"]) == [\"    x = 5\", \"    y = 3\"]\n    assert printer._traverse_matrix_indices(Matrix([[1, 2], [3, 4]])) == ((0, 0), (0, 1), (1, 0), (1, 1))\n    assert printer._get_loop_opening_ending([Idx('i', 5)]) == ([\"for i = 1:5\"], [\"end\"])\n"], "sample_1000": ["def test_octave_codeprinter_settings():\n    # Test that the settings are correctly passed to the OctaveCodePrinter\n    expr = x + y\n    assert octave_code(expr, precision=10) == \"x + y\"\n    assert octave_code(expr, user_functions={\"sin\": \"my_sin\"}) == \"x + y\"\n    assert octave_code(expr, human=False) == ([], [], \"x + y\")\n    assert octave_code(expr, contract=False) == \"x + y\"\n    assert octave_code(expr, inline=False) == \"x + y\"\n"], "sample_197": ["def test_time_strings_customization(self):\n    \"\"\"\n    Test that time_strings can be customized.\n    \"\"\"\n    custom_time_strings = {\n        'year': ngettext_lazy('%d year ago', '%d years ago'),\n        'month': ngettext_lazy('%d month ago', '%d months ago'),\n        'week': ngettext_lazy('%d week ago', '%d weeks ago'),\n        'day': ngettext_lazy('%d day ago', '%d days ago'),\n        'hour': ngettext_lazy('%d hour ago', '%d hours ago'),\n        'minute': ngettext_lazy('%d minute ago', '%d minutes ago'),\n    }\n    self.assertEqual(timesince(self.t, self.t + self.oneminute, time_strings=custom_time_strings), '1\\xa0minute ago')\n    self.assertEqual(timesince(self.t, self.t + self.onehour, time_strings=custom_time_strings), '1\\xa0hour ago')\n    self.assertEqual(timesince(self.t, self.t + self.oneday, time_strings=custom_time_strings), '1\\xa0day ago')\n    self.assertEqual(timesince(self.t, self.t + self.oneweek, time_strings=custom_time_strings), '1\\xa0week ago')\n    self.assertEqual(timesince(self.t, self.t + self.onemonth, time_strings=custom_time_strings), '1\\xa0month ago')\n    self.assertEqual(timesince(self.t, self.t + self.oneyear, time_strings=custom_time_strings), '1\\xa0year ago')\n"], "sample_702": ["def test_pytester_run_with_timeout_and_keyboard_interrupt(pytester: Pytester) -> None:\n    testfile = pytester.makepyfile(\n        \"\"\"\n        import time\n\n            time.sleep(10)\n        \"\"\"\n    )\n    with pytest.raises(pytester.TimeoutExpired):\n        pytester.runpytest_subprocess(testfile, timeout=1)\n\n    with pytest.raises(KeyboardInterrupt):\n        pytester.runpytest_subprocess(testfile, timeout=1, stdin=b\"\\x03\")\n"], "sample_937": ["def test_unparse_arguments():\n    source = \"def func(a: int, b: str = 'default', *args, c: int, **kwargs): pass\"\n    expected = \"a: int, b: str = 'default', *args, c: int, **kwargs\"\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].args) == expected\n"], "sample_889": ["def test_calibrated_classifier_cv_n_jobs(data, method, ensemble):\n    \"\"\"Check that CalibratedClassifierCV with n_jobs > 1 works correctly.\"\"\"\n    X, y = data\n    estimator = LogisticRegression()\n    calibrated_clf_parallel = CalibratedClassifierCV(\n        estimator, method=method, n_jobs=2, ensemble=ensemble\n    )\n    calibrated_clf_parallel.fit(X, y)\n    probs_parallel = calibrated_clf_parallel.predict_proba(X)\n\n    calibrated_clf_sequential = CalibratedClassifierCV(\n        estimator, method=method, n_jobs=1, ensemble=ensemble\n    )\n    calibrated_clf_sequential.fit(X, y)\n    probs_sequential = calibrated_clf_sequential.predict_proba(X)\n\n    assert_allclose(probs_parallel, probs_sequential)\n"], "sample_306": ["    def test_parse_duration_with_trailing_whitespace(self):\n        test_values = (\n            ('1 day ', timedelta(days=1)),\n            ('-1 day ', timedelta(days=-1)),\n            ('1 day 0:00:01 ', timedelta(days=1, seconds=1)),\n            ('1 day -0:00:01 ', timedelta(days=1, seconds=-1)),\n            ('-1 day -0:00:01 ', timedelta(days=-1, seconds=-1)),\n            ('-1 day +0:00:01 ', timedelta(days=-1, seconds=1)),\n            ('4 days 0:15:30.1 ', timedelta(days=4, minutes=15, seconds=30, milliseconds=100)),\n            ('4 days 0:15:30.0001 ', timedelta(days=4, minutes=15, seconds=30, microseconds=100)),\n            ('-4 days -15:00:30 ', timedelta(days=-4, hours=-15, seconds=-30)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_1074": ["def test_polycyclic_group():\n    G = SymmetricGroup(3)\n    pcG = G.polycyclic_group()\n    assert pcG.order() == G.order()\n    assert pcG.is_isomorphic(G)\n    G = AlternatingGroup(4)\n    pcG = G.polycyclic_group()\n    assert pcG.order() == G.order()\n    assert pcG.is_isomorphic(G)\n    G = DihedralGroup(6)\n    pcG = G.polycyclic_group()\n    assert pcG.order() == G.order()\n    assert pcG.is_isomorphic(G)\n"], "sample_290": ["def test_alter_field_to_fk_dependency_same_app(self):\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author_fk],\n        [self.author_empty, self.book_with_author_renamed],\n    )\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '__first__')])\n"], "sample_680": ["def test_xfail_with_invalid_strict_value(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = invalid\n    \"\"\"\n    )\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(reason='unsupported feature')\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest(p, \"-rxX\")\n    result.stdout.fnmatch_lines([\"*1 xpassed*\"])\n    assert result.ret == 0\n"], "sample_809": ["def test_mutual_info_classif_sparse():\n    # Test that mutual_info_classif works with sparse matrices.\n    X = csr_matrix(np.array([[0, 0, 0],\n                             [1, 1, 0],\n                             [2, 0, 1],\n                             [2, 0, 1],\n                             [2, 0, 1]]))\n    y = np.array([0, 1, 2, 2, 1])\n\n    mi = mutual_info_classif(X, y, discrete_features=True)\n    assert_array_equal(np.argsort(-mi), np.array([0, 2, 1]))\n\n    # Test that mutual_info_classif works with sparse matrices and mixed features.\n    X = csr_matrix(np.array([[0, 0, 0],\n                             [1, 1, 0],\n                             [2, 0, 1],\n                             [2, 0, 1],\n                             [2, 0, 1]]))\n    X = X.toarray()\n    X[:, 1] = np.random.rand(5)\n    y = np.array([0, 1, 2, 2, 1])\n\n    mi = mutual_info_classif(X, y, discrete_features=[0, 2])\n    assert_array_equal(np.argsort(-mi), np.array([0, 2, 1]))\n"], "sample_1046": ["def test_valued_tensor_components_with_wrong_symmetry():\n    IT = TensorIndexType('IT', dim=3)\n    i0, i1, i2, i3 = tensor_indices('i0:4', IT)\n    IT.data = [1, 1, 1]\n    A_nosym = tensorhead('A', [IT]*2, [[1]]*2)\n    A_sym = tensorhead('A', [IT]*2, [[1]*2])\n    A_antisym = tensorhead('A', [IT]*2, [[2]])\n\n    mat_nosym = Matrix([[1,2,3],[4,5,6],[7,8,9]])\n    mat_sym = mat_nosym + mat_nosym.T\n    mat_antisym = mat_nosym - mat_nosym.T\n\n    A_nosym.data = mat_nosym\n    A_nosym.data = mat_sym\n    A_nosym.data = mat_antisym\n\n        A.data = dat\n\n    A_sym.data = mat_sym\n    raises(ValueError, lambda: assign(A_sym, mat_nosym))\n    raises(ValueError, lambda: assign(A_sym, mat_antisym))\n\n    A_antisym.data = mat_antisym\n    raises(ValueError, lambda: assign(A_antisym, mat_sym))\n    raises(ValueError, lambda: assign(A_antisym, mat_nosym))\n\n    A_sym.data = [[0, 0, 0], [0, 0, 0], [0, 0, 0]]\n    A_antisym.data = [[0, 0, 0], [0, 0, 0], [0, 0, 0]]\n\n    # Test with 3x3x3 tensor\n    IT3 = TensorIndexType('IT3', dim=3)\n    i0, i1, i2, i3 = tensor_indices('i0:4', IT3)\n    IT3.data = [1, 1, 1]\n    A_nosym3 = tensorhead('A', [IT3]*3, [[1]]*3)\n    A_sym3 = tensorhead('A', [IT3]*3, [[1]*3])\n    A_antisym3 = tensorhead('A', [IT3]*3, [[3]])\n\n"], "sample_1103": ["def test_Pow_as_base_exp():\n    assert Pow(1, 2, evaluate=False).as_base_exp() == (1, 2)\n    assert Pow(-1, 2, evaluate=False).as_base_exp() == (1, 2)\n    assert Pow(1/2, 2, evaluate=False).as_base_exp() == (2, -2)\n    assert Pow(-1/2, 2, evaluate=False).as_base_exp() == (2, -2)\n    assert Pow(1/2, -2, evaluate=False).as_base_exp() == (2, 2)\n    assert Pow(-1/2, -2, evaluate=False).as_base_exp() == (2, 2)\n"], "sample_806": ["def test_gradient_boosting_with_init_custom():\n    # Check that GradientBoostingRegressor works when init is a custom sklearn\n    # estimator.\n    # Check that an error is raised if trying to fit with sample weight but\n    # inital estimator does not support sample weight\n\n    class CustomEstimator(BaseEstimator):\n            if sample_weight is not None:\n                raise ValueError(\"CustomEstimator does not support sample weights\")\n            return self\n\n            return np.zeros(X.shape[0])\n\n    X, y = make_regression(random_state=0)\n\n    # init does not support sample weights\n    init_est = CustomEstimator()\n    gb = GradientBoostingRegressor(init=init_est)\n    gb.fit(X, y)  # ok no sample weights\n    with pytest.raises(ValueError,\n                       match=\"estimator.*does not support sample weights\"):\n        gb.fit(X, y, sample_weight=np.ones(X.shape[0]))\n"], "sample_240": ["def test_make_hash_value(self):\n    \"\"\"The hash value is correctly generated.\"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    timestamp = p0._num_seconds(p0._now())\n    hash_value = p0._make_hash_value(user, timestamp)\n    expected_hash_value = f'{user.pk}{user.password}{user.last_login}{timestamp}{user.email}'\n    self.assertEqual(hash_value, expected_hash_value)\n\n    # Test with a user that has no last_login\n    user.last_login = None\n    user.save()\n    hash_value = p0._make_hash_value(user, timestamp)\n    expected_hash_value = f'{user.pk}{user.password}{timestamp}{user.email}'\n    self.assertEqual(hash_value, expected_hash_value)\n"], "sample_1020": ["def test_user_functions():\n    assert mcode(sin(x), user_functions={'sin': 'MySin'}) == \"MySin[x]\"\n    assert mcode(sin(x), user_functions={'sin': lambda *x: 'MySin'}) == \"MySin[x]\"\n    assert mcode(sin(x), user_functions={'sin': ['MySin']}) == \"MySin[x]\"\n    assert mcode(sin(x), user_functions={'sin': [(lambda x: True, 'MySin')]}) == \"MySin[x]\"\n    assert mcode(sin(x), user_functions={'sin': [(lambda x: False, 'MySin')]}) == \"Sin[x]\"\n    assert mcode(sin(x), user_functions={'sin': [(lambda x: True, 'MySin'), (lambda x: False, 'YourSin')]}) == \"MySin[x]\"\n"], "sample_491": ["def test_boundfield_subwidgets_with_custom_renderer(self):\n    class CustomRenderer(DjangoTemplates):\n        field_template_name = \"forms_tests/custom_field.html\"\n\n    class CustomFrameworkForm(FrameworkForm):\n        renderer = CustomRenderer()\n\n    f = CustomFrameworkForm(auto_id=False)\n    self.assertHTMLEqual(\n        \"\\n\".join(str(bf) for bf in f[\"language\"]),\n        '<label for=\"id_language_0\">Python</label><p>Custom Field<p>'\n        '<input type=\"radio\" name=\"language\" value=\"P\" required id=\"id_language_0\">'\n        '<label for=\"id_language_1\">Java</label><p>Custom Field<p>'\n        '<input type=\"radio\" name=\"language\" value=\"J\" required id=\"id_language_1\">',\n    )\n"], "sample_869": ["def test_jaccard_score_multilabel_with_sample_weight():\n    # Dense label indicator matrix format\n    y1 = np.array([[0, 1, 1], [1, 0, 1]])\n    y2 = np.array([[0, 0, 1], [1, 0, 1]])\n    sample_weight = np.array([1, 2])\n\n    # size(y1 \\inter y2) = [1, 2]\n    # size(y1 \\union y2) = [2, 2]\n\n    assert jaccard_score(y1, y2, average='samples', sample_weight=sample_weight) == 0.75\n    assert jaccard_score(y1, y1, average='samples', sample_weight=sample_weight) == 1\n    assert jaccard_score(y2, y2, average='samples', sample_weight=sample_weight) == 1\n    assert jaccard_score(y2, np.logical_not(y2), average='samples', sample_weight=sample_weight) == 0\n    assert jaccard_score(y1, np.logical_not(y1), average='samples', sample_weight=sample_weight) == 0\n    assert jaccard_score(y1, np.zeros(y1.shape), average='samples', sample_weight=sample_weight) == 0\n    assert jaccard_score(y2, np.zeros(y1.shape), average='samples', sample_weight=sample_weight) == 0\n"], "sample_883": ["def test_bayesian_ridge_ard_empty_input(Estimator):\n    \"\"\"Check that BayesianRidge and ARDRegression handle empty input correctly.\"\"\"\n    X = np.array([])\n    y = np.array([])\n\n    model = Estimator()\n    with pytest.raises(ValueError, match=\"zero-size array to reduction operation\"):\n        model.fit(X, y)\n"], "sample_1077": ["def test_ComplexRegion_polar_intersect():\n    # Polar form\n    unit_disk = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)\n    upper_half_unit_disk = ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    upper_half_disk = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi), polar=True)\n    lower_half_disk = ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n    right_half_disk = ComplexRegion(Interval(0, oo)*Interval(-S.Pi/2, S.Pi/2), polar=True)\n    first_quad_disk = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi/2), polar=True)\n\n    assert upper_half_disk.intersect(unit_disk) == upper_half_unit_disk\n    assert right_half_disk.intersect(first_quad_disk) == first_quad_disk\n    assert upper_half_disk.intersect(right_half_disk) == first_quad_disk\n    assert upper_half_disk.intersect(lower_half_disk) == ComplexRegion(Interval(0, oo)*FiniteSet(0, S.Pi), polar=True)\n\n    c1 = ComplexRegion(Interval(0, 4)*Interval(0, 2*S.Pi), polar=True)\n    assert c1.intersect(Interval(1, 5)) == Interval(1, 4)\n    assert c1.intersect(Interval(4, 9)) == FiniteSet(4)\n    assert c1.intersect(Interval(5, 12)) is S.EmptySet\n"], "sample_492": ["def test_serialize_timezone(self):\n    \"\"\"\n    Test serialization of timezone objects.\n    \"\"\"\n    self.assertSerializedResultEqual(\n        datetime.timezone.utc,\n        (\"datetime.timezone.utc\", {\"import datetime\"}),\n    )\n    self.assertSerializedResultEqual(\n        get_default_timezone(),\n        (\"django.utils.timezone.get_default_timezone()\", {\"from django.utils import timezone\"}),\n    )\n    self.assertSerializedResultEqual(\n        get_fixed_timezone(180),\n        (\"django.utils.timezone.get_fixed_timezone(180)\", {\"from django.utils import timezone\"}),\n    )\n    self.assertSerializedResultEqual(\n        zoneinfo.ZoneInfo(\"Europe/Paris\"),\n        (\"zoneinfo.ZoneInfo('Europe/Paris')\", {\"import zoneinfo\"}),\n    )\n"], "sample_440": ["def test_update_conflicts_unique_fields_pk(self):\n    UpsertConflict.objects.bulk_create(\n        [\n            UpsertConflict(number=1, rank=1, name=\"John\"),\n            UpsertConflict(number=2, rank=2, name=\"Mary\"),\n            UpsertConflict(number=3, rank=3, name=\"Hannah\"),\n        ]\n    )\n    self.assertEqual(UpsertConflict.objects.count(), 3)\n\n    conflicting_objects = [\n        UpsertConflict(pk=1, number=1, rank=4, name=\"Steve\"),\n        UpsertConflict(pk=2, number=2, rank=2, name=\"Olivia\"),\n        UpsertConflict(pk=3, number=3, rank=1, name=\"Hannah\"),\n    ]\n    UpsertConflict.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        update_fields=[\"name\", \"rank\"],\n        unique_fields=[\"pk\"],\n    )\n    self.assertEqual(UpsertConflict.objects.count(), 3)\n    self.assertCountEqual(\n        UpsertConflict.objects.values(\"number\", \"rank\", \"name\"),\n        [\n            {\"number\": 1, \"rank\": 4, \"name\": \"Steve\"},\n            {\"number\": 2, \"rank\": 2, \"name\": \"Olivia\"},\n            {\"number\": 3, \"rank\": 1, \"name\": \"Hannah\"},\n        ],\n    )\n\n    UpsertConflict.objects.bulk_create(\n        conflicting_objects + [UpsertConflict(number=4, rank=4, name=\"Mark\")],\n        update_conflicts=True,\n        update_fields=[\"name\", \"rank\"],\n        unique_fields=[\"pk\"],\n    )\n    self.assertEqual(UpsertConflict.objects.count(), 4)\n    self.assertCountEqual(\n        UpsertConflict.objects.values(\"number\", \"rank\", \"name\"),\n        [\n            {\"number\": 1, \"rank\": 4, \"name\": \"Steve\"},\n            {\"number\": 2, \"rank\": 2, \"name\": \"Olivia\"},\n            {\"number\": 3, \"rank\": 1, \"name\": \"Hannah\"},\n            {\"number\": 4, \"rank\": 4, \"name\": \"Mark\"},\n        ],\n    )\n"], "sample_231": ["    def test_cleanse_special_types(self):\n        reporter_filter = SafeExceptionReporterFilter()\n        request = RequestFactory().get('/')\n        # Test MultiValueDict\n        multivalue_dict = MultiValueDict({'key': 'value'})\n        self.assertEqual(reporter_filter.cleanse_special_types(request, multivalue_dict), multivalue_dict)\n        # Test non-MultiValueDict\n        self.assertEqual(reporter_filter.cleanse_special_types(request, 'value'), 'value')\n"], "sample_68": ["    def test_technical_500_response(self):\n        request = RequestFactory().get('/')\n        exc_type = Exception\n        exc_value = Exception('Test exception')\n        tb = None\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html')\n"], "sample_158": ["    def test_foreign_key_to_swapped_model(self):\n        class Replacement(models.Model):\n            pass\n\n        class SwappedModel(models.Model):\n            class Meta:\n                swappable = 'TEST_SWAPPED_MODEL'\n\n        class Model(models.Model):\n            fk = models.ForeignKey(SwappedModel, models.CASCADE)\n\n        field = Model._meta.get_field('fk')\n        self.assertEqual(field.check(from_model=Model), [\n            Error(\n                \"Field defines a relation with the model 'invalid_models_tests.SwappedModel', \"\n                \"which has been swapped out.\",\n                hint=\"Update the relation to point at 'settings.TEST_SWAPPED_MODEL'.\",\n                obj=field,\n                id='fields.E301',\n            ),\n        ])\n"], "sample_549": ["def test_safe_masked_invalid():\n    x = np.array([1, 2, np.nan, 4])\n    xm = cbook.safe_masked_invalid(x)\n    assert np.all(xm.data == x)\n    assert np.all(xm.mask == [False, False, True, False])\n\n    x = np.ma.array([1, 2, np.nan, 4], mask=[True, False, False, True])\n    xm = cbook.safe_masked_invalid(x)\n    assert np.all(xm.data == x.data)\n    assert np.all(xm.mask == [True, False, True, True])\n\n    x = np.array([1, 2, np.inf, 4])\n    xm = cbook.safe_masked_invalid(x)\n    assert np.all(xm.data == x)\n    assert np.all(xm.mask == [False, False, True, False])\n\n    x = np.array([1, 2, np.nan, 4], dtype=np.int32)\n    xm = cbook.safe_masked_invalid(x)\n    assert np.all(xm.data == x)\n    assert np.all(xm.mask == [False, False, True, False])\n\n    x = np.ma.array([1, 2, np.nan, 4], mask=[True, False, False, True], dtype=np.int32)\n    xm = cbook.safe_masked_invalid(x)\n    assert np.all(xm.data == x.data)\n    assert np.all(xm.mask == [True, False, True, True])\n"], "sample_89": ["    def test_empty_paths(self):\n        self.assertEqual(autoreload.common_roots(()), ())\n"], "sample_689": ["def test_warning_captured_hook_is_deprecated(testdir: Testdir) -> None:\n    \"\"\"The pytest_warning_captured hook is deprecated and will be removed in a future release.\"\"\"\n    testdir.makeconftest(\n        \"\"\"\n            pass\n        \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import warnings\n\n            warnings.warn(\"Test warning\")\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*PytestDeprecationWarning: The pytest_warning_captured is deprecated*\"])\n"], "sample_671": ["def test_xfail_with_invalid_condition(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(\"invalid condition\")\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxs\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*ERROR*test_func*\",\n            \"*evaluating*xfail*expression*\",\n            \"*invalid condition*\",\n            \"*SyntaxError: invalid syntax*\",\n            \"*1 error*\",\n        ]\n    )\n"], "sample_118": ["def test_year_lookup_bounds(self):\n    # Test the year_lookup_bounds method of the YearLookup class\n    year = 2005\n    bounds = self.a1.pub_date.year_lookup_bounds(connection)\n    self.assertEqual(bounds, (datetime(year, 1, 1), datetime(year, 12, 31)))\n\n    # Test the year_lookup_bounds_for_datetime_field method of the database backend\n    bounds = connection.ops.year_lookup_bounds_for_datetime_field(year)\n    self.assertEqual(bounds, (datetime(year, 1, 1), datetime(year, 12, 31)))\n\n    # Test the year_lookup_bounds_for_date_field method of the database backend\n    bounds = connection.ops.year_lookup_bounds_for_date_field(year)\n    self.assertEqual(bounds, (datetime(year, 1, 1), datetime(year, 12, 31)))\n"], "sample_374": ["    def setUpTestData(cls):\n        cls.book1 = Book.objects.create(title='Poems')\n        cls.book2 = Book.objects.create(title='Jane Eyre')\n        cls.book3 = Book.objects.create(title='Wuthering Heights')\n        cls.book4 = Book.objects.create(title='Sense and Sensibility')\n\n        cls.author1 = Author.objects.create(name='Charlotte', first_book=cls.book1)\n        cls.author2 = Author.objects.create(name='Anne', first_book=cls.book1)\n        cls.author3 = Author.objects.create(name='Emily', first_book=cls.book1)\n        cls.author4 = Author.objects.create(name='Jane', first_book=cls.book4)\n\n        cls.book1.authors.add(cls.author1, cls.author2, cls.author3)\n        cls.book2.authors.add(cls.author1)\n        cls.book3.authors.add(cls.author3)\n        cls.book4.authors.add(cls.author4)\n"], "sample_788": ["def test_inverse_transform_outside_fit_range():\n    X = np.array([0, 1, 2, 3])[:, None]\n    kbd = KBinsDiscretizer(n_bins=4, strategy='uniform', encode='ordinal')\n    kbd.fit(X)\n\n    Xt = np.array([[-1, 5]])[:, None]\n    Xinv = kbd.inverse_transform(Xt)\n    assert_array_almost_equal(Xinv, np.array([[-0.5], [3.5]]))\n"], "sample_1161": ["def test_issue_21119_21460_str():\n    ss = lambda x: sstr(S(x, evaluate=False))\n    assert ss('4/2') == '4/2'\n    assert ss('4/-2') == '-4/2'\n    assert ss('-4/2') == '-4/2'\n    assert ss('-4/-2') == '4/2'\n    assert ss('-2*3/-1') == '2*3'\n    assert ss('-2*3/-1/2') == '-2*3/2'\n    assert ss('4/2/1') == '4/2'\n    assert ss('-2/-1/2') == '2/2'\n    assert ss('2*3*4**(-2*3)') == '2*3/4**(2*3)'\n    assert ss('2*3*1*4**(-2*3)') == '2*3/4**(2*3)'\n"], "sample_884": ["def test_deprecated_property():\n    with pytest.warns(FutureWarning, match=\"n_features_ is deprecated\"):\n        assert MockClass2().n_features_ == 10\n    with pytest.warns(FutureWarning, match=\"n_features_ is deprecated\"):\n        assert MockClass2.n_features.fget(MockClass2()) == 10\n"], "sample_814": ["def test_gradient_boosting_with_init_sample_weight():\n    # Check that GradientBoostingRegressor works when init is a sklearn\n    # estimator and sample weights are provided.\n    X, y = make_regression()\n    sample_weight = np.random.RandomState(42).rand(100)\n\n    # init supports sample weights\n    init_est = DummyRegressor()\n    gb = GradientBoostingRegressor(init=init_est)\n    gb.fit(X, y, sample_weight=sample_weight)\n\n    # init does not support sample weights\n    init_est = _NoSampleWeightWrapper(DummyRegressor())\n    gb = GradientBoostingRegressor(init=init_est)\n    gb.fit(X, y)  # ok no sample weights\n    with pytest.raises(ValueError,\n                       match=\"estimator.*does not support sample weights\"):\n        gb.fit(X, y, sample_weight=sample_weight)\n"], "sample_706": ["def test_matcher_adapter() -> None:\n    matcher = {\"true\": True, \"false\": False}\n    adapter = MatcherAdapter(matcher.__getitem__)\n    assert adapter[\"$true\"]\n    assert not adapter[\"$false\"]\n    with pytest.raises(KeyError):\n        adapter[\"$unknown\"]\n"], "sample_405": ["def test_alter_field_with_func_unique_constraint_on_mti_model(self):\n    app_label = \"test_alfuncucmti\"\n    constraint_name = f\"{app_label}_pony_uq\"\n    table_name = f\"{app_label}_pony\"\n    project_state = self.set_up_test_model(\n        app_label,\n        mti_model=True,\n        constraints=[\n            models.UniqueConstraint(\"pink\", \"weight\", name=constraint_name)\n        ],\n    )\n    operation = migrations.AlterField(\n        \"Pony\", \"pink\", models.IntegerField(null=True)\n    )\n    new_state = project_state.clone()\n    operation.state_forwards(app_label, new_state)\n    with connection.schema_editor() as editor:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    if connection.features.supports_expression_indexes:\n        self.assertIndexNameExists(table_name, constraint_name)\n    with connection.schema_editor() as editor:\n        operation.database_backwards(app_label, editor, new_state, project_state)\n    if connection.features.supports_expression_indexes:\n        self.assertIndexNameExists(table_name, constraint_name)\n"], "sample_570": ["    def test_cached_support_bivariate(self, rng):\n\n        x, y = rng.normal(0, 3, (2, 50))\n        kde = KDE()\n        kde.define_support(x, y)\n        _, support = kde(x[(x > -1) & (x < 1)], y[(x > -1) & (x < 1)])\n        assert_array_equal(support[0], kde.support[0])\n        assert_array_equal(support[1], kde.support[1])\n"], "sample_1072": ["def test_frac_properties():\n    assert frac(x).is_finite\n    assert frac(x).is_real\n    assert frac(x).is_zero is None\n    assert frac(x).is_integer is None\n\n    assert frac(y).is_finite\n    assert frac(y).is_real\n    assert frac(y).is_zero is None\n    assert frac(y).is_integer is None\n\n    assert frac(n).is_finite\n    assert frac(n).is_real\n    assert frac(n).is_zero\n    assert frac(n).is_integer\n\n    assert frac(I).is_finite\n    assert frac(I).is_real is None\n    assert frac(I).is_zero is None\n    assert frac(I).is_integer is None\n\n    assert frac(oo).is_finite\n    assert frac(oo).is_real\n    assert frac(oo).is_zero is None\n    assert frac(oo).is_integer is None\n\n    assert frac(-oo).is_finite\n    assert frac(-oo).is_real\n    assert frac(-oo).is_zero is None\n    assert frac(-oo).is_integer is None\n\n    assert frac(zoo).is_finite is None\n    assert frac(zoo).is_real is None\n    assert frac(zoo).is_zero is None\n    assert frac(zoo).is_integer is None\n\n    assert frac(nan).is_finite is None\n    assert frac(nan).is_real is None\n    assert frac(nan).is_zero is None\n    assert frac(nan).is_integer is None\n"], "sample_560": ["def test_legend_framealpha_with_shadow():\n    # Test that framealpha is activated when shadow is True\n    # and framealpha is not explicitly passed'''\n    fig, ax = plt.subplots()\n    ax.plot(range(100), label=\"test\")\n    leg = ax.legend(shadow=True, facecolor='w', framealpha=0.5)\n    assert leg.get_frame().get_alpha() == 0.5\n"], "sample_557": ["def test_subfigure_subplotspec():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    subfig = fig.add_subfigure(gs[0, 0])\n    assert subfig._subplotspec == gs[0, 0]\n    assert subfig._subplotspec.get_gridspec() == gs\n"], "sample_75": ["    def setUpTestData(cls):\n        cls.book = Book.objects.create(title='Poems')\n        cls.author1 = Author.objects.create(name='Jane', first_book=cls.book)\n        cls.author2 = Author.objects.create(name='Tom', first_book=cls.book)\n        cls.author3 = Author.objects.create(name='Robert', first_book=cls.book)\n        cls.author_address = AuthorAddress.objects.create(author=cls.author1, address='SomeStreet 1')\n        FavoriteAuthors.objects.create(author=cls.author1, likes_author=cls.author2)\n        FavoriteAuthors.objects.create(author=cls.author2, likes_author=cls.author3)\n        FavoriteAuthors.objects.create(author=cls.author3, likes_author=cls.author1)\n"], "sample_1168": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((1, 2, 3))) == [(1, 2, 3), (-1, 2, 3), (1, -2, 3), (-1, -2, 3), (1, 2, -3), (-1, 2, -3), (1, -2, -3), (-1, -2, -3)]\n    assert list(permute_signs((0, 0, 0))) == [(0, 0, 0)]\n    assert list(permute_signs((1, 0, 0))) == [(1, 0, 0), (-1, 0, 0)]\n    assert list(permute_signs((0, 1, 0))) == [(0, 1, 0), (0, -1, 0)]\n    assert list(permute_signs((0, 0, 1))) == [(0, 0, 1), (0, 0, -1)]\n"], "sample_62": ["    def setUp(self):\n        self.site = admin.AdminSite()\n"], "sample_1048": ["def test_parabola_equation():\n    p1 = Point(0, 0)\n    p2 = Point(3, 7)\n    d1 = Line(Point(4, 0), Point(4, 9))\n    d2 = Line(Point(7, 6), Point(3, 6))\n\n    pa1 = Parabola(p1, d1)\n    pa2 = Parabola(p2, d2)\n\n    # Test equation with default labels\n    assert pa1.equation() == -pa1.focus.x**2 + 16*pa1.focus.y - 64\n    assert pa2.equation() == -16*pa2.focus.x + pa2.focus.y**2 - 49\n\n    # Test equation with custom labels\n    x, y = symbols('x y')\n    assert pa1.equation('x', 'y') == -x**2 - 16*y + 64\n    assert pa2.equation('x', 'y') == -16*x + y**2 - 49\n\n    # Test equation with non-standard labels\n    a, b = symbols('a b')\n    assert pa1.equation('a', 'b') == -a**2 - 16*b + 64\n    assert pa2.equation('a', 'b') == -16*a + b**2 - 49\n"], "sample_1013": ["def test_lambdify_kwargs():\n    f = lambdify(x, x**2, dummify=True)\n    raises(TypeError, lambda: f(x=1))\n    f = lambdify(x, x**2, dummify=False)\n    raises(TypeError, lambda: f(x=1))\n"], "sample_1146": ["def test_latex_tensor_indices():\n    from sympy.tensor.tensor import TensorIndexType, tensor_indices, TensorHead, tensor_heads\n    L = TensorIndexType(\"L\")\n    i, j, k, l = tensor_indices(\"i j k l\", L)\n    i0 = tensor_indices(\"i_0\", L)\n    A, B, C, D = tensor_heads(\"A B C D\", [L])\n    H = TensorHead(\"H\", [L, L])\n    K = TensorHead(\"K\", [L, L, L, L])\n\n    assert latex(i) == r\"{}^{i}\"\n    assert latex(-i) == r\"{}_{i}\"\n\n    expr = A(i)\n    assert latex(expr) == r\"A{}^{i}\"\n\n    expr = A(i0)\n    assert latex(expr) == r\"A{}^{i_{0}}\"\n\n    expr = A(-i)\n    assert latex(expr) == r\"A{}_{i}\"\n\n    expr = -3*A(i)\n    assert latex(expr) == r\"-3A{}^{i}\"\n\n    expr = K(i, j, -k, -i0)\n    assert latex(expr) == r\"K{}^{ij}{}_{ki_{0}}\"\n\n    expr = K(i, -j, -k, i0)\n    assert latex(expr) == r\"K{}^{i}{}_{jk}{}^{i_{0}}\"\n\n    expr = K(i, -j, k, -i0)\n    assert latex(expr) == r\"K{}^{i}{}_{j}{}^{k}{}_{i_{0}}\"\n\n    expr = H(i, -j)\n    assert latex(expr) == r\"H{}^{i}{}_{j}\"\n\n    expr = H(i, j)\n    assert latex(expr) == r\"H{}^{ij}\"\n\n    expr = H(-i, -j)\n    assert latex(expr) == r\"H{}_{ij}\"\n\n    expr = (1+x)*A(i)\n    assert latex(expr) == r\"\\left(x + 1\\right)A{}^{i}\"\n\n    expr = H(i, -i)\n    assert latex(expr) == r\"H{}^{L_{0}}{}_{L_{0}}\"\n\n    expr = H(i, -j)*A(j)*B(k)\n    assert latex(expr) == r\"H{}^{i}{}_{L_{0}}A{}^{L_{0}}"], "sample_594": ["def test_format_array_flat_with_dask_array(self):\n    import dask.array as da\n\n    dask_array = da.random.random((100, 100), chunks=(10, 10))\n    actual = formatting.format_array_flat(dask_array, 10)\n    expected = \"dask.array<chunksize=(10, 10)>\"\n    assert actual == expected\n\n    dask_array = da.random.random((100, 100), chunks=(10, 10))\n    actual = formatting.format_array_flat(dask_array, 20)\n    expected = \"dask.array<chunksize=(10, 10)>\"\n    assert actual == expected\n\n    dask_array = da.random.random((100, 100), chunks=(10, 10))\n    actual = formatting.format_array_flat(dask_array, 50)\n    expected = \"dask.array<chunksize=(10, 10)>\"\n    assert actual == expected\n"], "sample_1147": ["def test_latex_tensor_indices():\n    from sympy.tensor.tensor import TensorIndexType, tensor_indices, TensorHead, tensor_heads\n    L = TensorIndexType(\"L\")\n    i, j, k, l = tensor_indices(\"i j k l\", L)\n    i0 = tensor_indices(\"i_0\", L)\n    A, B, C, D = tensor_heads(\"A B C D\", [L])\n    H = TensorHead(\"H\", [L, L])\n    K = TensorHead(\"K\", [L, L, L, L])\n\n    assert latex(i) == r\"{}^{i}\"\n    assert latex(-i) == r\"{}_{i}\"\n\n    expr = A(i)\n    assert latex(expr) == r\"A{}^{i}\"\n\n    expr = A(i0)\n    assert latex(expr) == r\"A{}^{i_{0}}\"\n\n    expr = A(-i)\n    assert latex(expr) == r\"A{}_{i}\"\n\n    expr = -3*A(i)\n    assert latex(expr) == r\"-3A{}^{i}\"\n\n    expr = K(i, j, -k, -i0)\n    assert latex(expr) == r\"K{}^{ij}{}_{ki_{0}}\"\n\n    expr = K(i, -j, -k, i0)\n    assert latex(expr) == r\"K{}^{i}{}_{jk}{}^{i_{0}}\"\n\n    expr = K(i, -j, k, -i0)\n    assert latex(expr) == r\"K{}^{i}{}_{j}{}^{k}{}_{i_{0}}\"\n\n    expr = H(i, -j)\n    assert latex(expr) == r\"H{}^{i}{}_{j}\"\n\n    expr = H(i, j)\n    assert latex(expr) == r\"H{}^{ij}\"\n\n    expr = H(-i, -j)\n    assert latex(expr) == r\"H{}_{ij}\"\n\n    expr = (1+x)*A(i)\n    assert latex(expr) == r\"\\left(x + 1\\right)A{}^{i}\"\n\n    expr = H(i, -i)\n    assert latex(expr) == r\"H{}^{L_{0}}{}_{L_{0}}\"\n\n    expr = H(i, -j)*A(j)*B(k)\n    assert latex(expr) == r\"H{}^{i}{}_{L_{0}}A{}^{L_{0}}"], "sample_404": ["def test_variable_node_render(self):\n    \"\"\"\n    Test that VariableNode.render() handles exceptions correctly.\n    \"\"\"\n    template = self._engine().from_string(\"{{ variable }}\")\n    context = Context({\"variable\": lambda: 42 / 0})\n    with self.assertRaises(ZeroDivisionError) as e:\n        template.render(context)\n    if self.debug_engine:\n        debug = e.exception.template_debug\n        self.assertEqual(debug[\"start\"], 0)\n        self.assertEqual(debug[\"end\"], 14)\n"], "sample_57": ["    def test_bound_data(self):\n        field = ReadOnlyPasswordHashField()\n        self.assertEqual(field.bound_data('initial', 'data'), 'initial')\n"], "sample_992": ["def test_MpmathPrinter():\n    p = MpmathPrinter()\n    expr = sympify('log1p(x)')\n    assert p.doprint(expr) == 'mpmath.log(x+1)'\n    expr = sympify('log2(x)')\n    assert p.doprint(expr) == 'mpmath.log(x)/mpmath.log(2)'\n    expr = sympify('uppergamma(x, y)')\n    assert p.doprint(expr) == 'mpmath.gammainc(x, y, mpmath.inf)'\n    expr = sympify('lowergamma(x, y)')\n    assert p.doprint(expr) == 'mpmath.gammainc(x, 0, y)'\n"], "sample_840": ["def test_pls_transform_with_univariate_y():\n    # Ensure that transform works correctly when Y is univariate\n    d = load_linnerud()\n    X = d.data\n    Y = d.target[:, 0]\n\n    for clf in [pls_.PLSCanonical(), pls_.PLSRegression(), pls_.PLSSVD()]:\n        X_score, Y_score = clf.fit_transform(X, Y)\n        assert_array_almost_equal(X_score, clf.transform(X))\n        assert_array_almost_equal(Y_score, clf.transform(X, Y)[:, 1])\n"], "sample_267": ["    def test_get_connection_params(self):\n        settings_dict = {\n            'NAME': ':memory:',\n            'OPTIONS': {\n                'check_same_thread': True,\n            }\n        }\n        wrapper = DatabaseWrapper(settings_dict)\n        params = wrapper.get_connection_params()\n        self.assertEqual(params['database'], ':memory:')\n        self.assertEqual(params['detect_types'], Database.PARSE_DECLTYPES | Database.PARSE_COLNAMES)\n        self.assertEqual(params['check_same_thread'], False)\n        self.assertEqual(params['uri'], True)\n"], "sample_993": ["def test_FreeGroupElm_cyclic_reduction():\n    w1 = x**2*y**2*x**-1\n    assert w1.cyclic_reduction() == x*y**2\n    w2 = x**-3*y**-1*x**5\n    assert w2.cyclic_reduction() == x**2*y**-1\n    w3 = x**-3*y**-1*x**5\n    assert w3.cyclic_reduction(removed=True) == (x**2*y**-1, x**-3)\n    w4 = x*y*x**-1*y**-1\n    assert w4.cyclic_reduction() == F.identity\n    w5 = x*y*x**-1*y**-1\n    assert w5.cyclic_reduction(removed=True) == (F.identity, x)\n"], "sample_1017": ["def test_as_set_multivariate():\n    x, y = symbols('x y', real=True)\n    assert And(x > 0, y > 0).as_set() == Interval.open(0, oo)*Interval.open(0, oo)\n    assert Or(x > 0, y > 0).as_set() == S.Reals*S.Reals - Interval.open(-oo, 0, True, True)*Interval.open(-oo, 0, True, True)\n"], "sample_395": ["def test_reset_all_loaders_with_cached_loader(self, mock_reset):\n    autoreload.reset_loaders()\n    self.assertEqual(mock_reset.call_count, 2)\n"], "sample_182": ["def test_union_with_values_list_and_order_on_annotated_and_unannotated(self):\n    ReservedName.objects.bulk_create([\n        ReservedName(name='rn1', order=7),\n        ReservedName(name='rn2', order=5),\n        ReservedName(name='rn0', order=6),\n        ReservedName(name='rn9', order=-1),\n    ])\n    qs1 = ReservedName.objects.annotate(\n        has_reserved_name=Value(True, IntegerField()),\n    ).filter(order__gte=6).values_list('order', 'has_reserved_name')\n    qs2 = ReservedName.objects.filter(order__lte=5).values_list('order', 'id')\n    union_qs = qs1.union(qs2)\n    for qs, expected_result in (\n        # Order by a single column.\n        (union_qs.order_by('-order').values_list('order', flat=True), [-1, 7, 6, 5]),\n        (union_qs.order_by('order').values_list('order', flat=True), [5, 6, 7, -1]),\n        (union_qs.values_list('order', flat=True).order_by('-order'), [-1, 7, 6, 5]),\n        (union_qs.values_list('order', flat=True).order_by('order'), [5, 6, 7, -1]),\n        # Order by multiple columns.\n        (union_qs.order_by('-name', 'order').values_list('order', flat=True), [-1, 5, 7, 6]),\n        (union_qs.values_list('order', flat=True).order_by('-name', 'order'), [-1, 5, 7, 6]),\n    ):\n        with self.subTest(qs=qs):\n            self.assertEqual(list(qs), expected_result)\n"], "sample_1067": ["def test_issue_unevaluated_Mul():\n    x, y = symbols('x y')\n    a, b = symbols('a b', cls=Wild)\n    e = _unevaluated_Mul(x, y)\n    assert e.match(a*b) == {a: x, b: y}\n    assert e.match(a*x) == {a: y}\n    assert e.match(x*b) == {b: y}\n    assert e.match(a*y) is None\n    assert e.match(b*x) is None\n"], "sample_1018": ["def test_fcode_Infinity():\n    x = symbols('x')\n    assert fcode(S.Infinity) == \"      (huge(0d0) + 1)\"\n    assert fcode(S.NegativeInfinity) == \"      -(huge(0d0) + 1)\"\n    assert fcode(S.Infinity + x) == \"      (huge(0d0) + 1) + x\"\n    assert fcode(x + S.Infinity) == \"      x + (huge(0d0) + 1)\"\n    assert fcode(S.Infinity * x) == \"      (huge(0d0) + 1)*x\"\n    assert fcode(x * S.Infinity) == \"      x*(huge(0d0) + 1)\"\n    assert fcode(S.Infinity / x) == \"      (huge(0d0) + 1)/x\"\n    assert fcode(x / S.Infinity) == \"      x/(huge(0d0) + 1)\"\n    assert fcode(S.Infinity ** x) == \"      (huge(0d0) + 1)**x\"\n    assert fcode(x ** S.Infinity) == \"      x**(huge(0d0) + 1)\"\n"], "sample_1024": ["def test_issue_14289():\n    from sympy.polys.numberfields import to_number_field\n\n    a = 1 - sqrt(2)\n    b = to_number_field(a)\n    assert b.as_expr() == a\n    assert b.minpoly(a).expand() == 0\n"], "sample_401": ["def test_management_form_invalid_data_with_custom_error_message(self):\n    data = {\n        \"form-TOTAL_FORMS\": \"two\",\n        \"form-INITIAL_FORMS\": \"one\",\n    }\n    formset = ArticleFormSet(data, error_messages={\"missing_management_form\": \"customized\"})\n    self.assertIs(formset.is_valid(), False)\n    self.assertEqual(\n        formset.non_form_errors(),\n        [\n            \"customized\",\n        ],\n    )\n    self.assertEqual(formset.errors, [])\n    # Can still render the formset.\n    self.assertHTMLEqual(\n        str(formset),\n        '<tr><td colspan=\"2\">'\n        '<ul class=\"errorlist nonfield\">'\n        \"<li>(Hidden field TOTAL_FORMS) Enter a whole number.</li>\"\n        \"<li>(Hidden field INITIAL_FORMS) Enter a whole number.</li>\"\n        \"</ul>\"\n        '<input type=\"hidden\" name=\"form-TOTAL_FORMS\" value=\"two\" '\n        'id=\"id_form-TOTAL_FORMS\">'\n        '<input type=\"hidden\" name=\"form-INITIAL_FORMS\" value=\"one\" '\n        'id=\"id_form-INITIAL_FORMS\">'\n        '<input type=\"hidden\" name=\"form-MIN_NUM_FORMS\" id=\"id_form-MIN_NUM_FORMS\">'\n        '<input type=\"hidden\" name=\"form-MAX_NUM_FORMS\" id=\"id_form-MAX_NUM_FORMS\">'\n        \"</td></tr>\\n\",\n    )\n"], "sample_1079": ["def test_orthogonal_direction():\n    p = Point(1, 2, 3)\n    ortho = p.orthogonal_direction\n    assert p.dot(ortho) == 0\n    assert ortho != Point(0, 0, 0)\n    p = Point(0, 1, 2)\n    ortho = p.orthogonal_direction\n    assert p.dot(ortho) == 0\n    assert ortho != Point(0, 0, 0)\n    p = Point(1, 0, 2)\n    ortho = p.orthogonal_direction\n    assert p.dot(ortho) == 0\n    assert ortho != Point(0, 0, 0)\n"], "sample_342": ["def test_process_request_invalid_app_label(self):\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'invalid_app', 'model_name': Answer._meta.model_name, 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n"], "sample_398": ["    def test_login_view_get(self):\n        response = self.client.get(\"/login/\")\n        self.assertEqual(response.status_code, 200)\n        self.assertIsInstance(response.context[\"form\"], AuthenticationForm)\n"], "sample_1107": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((0, 1, 2, 3))) == [\n        (0, 1, 2, 3), (0, 1, 2, -3), (0, 1, -2, 3), (0, 1, -2, -3),\n        (0, -1, 2, 3), (0, -1, 2, -3), (0, -1, -2, 3), (0, -1, -2, -3),\n        (0, 1, 2, 3), (0, 1, 2, -3), (0, 1, -2, 3), (0, 1, -2, -3),\n        (0, -1, 2, 3), (0, -1, 2, -3), (0, -1, -2, 3), (0, -1, -2, -3)\n    ]\n    assert list(permute_signs((1, 1, 1))) == [(1, 1, 1), (-1, 1, 1), (1, -1, 1), (1, 1, -1),\n        (-1, -1, 1), (-1, 1, -1), (1, -1, -1), (-1, -1, -1)]\n    assert list(permute_signs((0, 0, 0))) == [(0, 0, 0)]\n"], "sample_383": ["    def test_ticket_24605(self):\n        \"\"\"\n        Subquery table names should be quoted.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(\n            Individual.objects.filter(\n                Q(alive=False), Q(related_individual__isnull=True)\n            ),\n            [i4],\n        )\n        self.assertSequenceEqual(\n            Individual.objects.exclude(\n                Q(alive=False), Q(related_individual__isnull=True)\n            ).order_by(\"pk\"),\n            [i1, i2, i3],\n        )\n"], "sample_444": ["    def test_manifest_empty(self):\n        storage.staticfiles_storage.manifest_name = \"empty.json\"\n        manifest_path = storage.staticfiles_storage.path(storage.staticfiles_storage.manifest_name)\n        with open(manifest_path, \"w\") as manifest_file:\n            manifest_file.write(\"\")\n        with self.assertRaises(ValueError):\n            storage.staticfiles_storage.load_manifest()\n"], "sample_496": ["    def test_handle_default_options(self):\n        options = mock.Mock()\n        options.settings = 'test_settings'\n        options.pythonpath = '/path/to/pythonpath'\n        handle_default_options(options)\n        self.assertEqual(os.environ['DJANGO_SETTINGS_MODULE'], 'test_settings')\n        self.assertIn('/path/to/pythonpath', sys.path)\n"], "sample_126": ["def test_alter_field_to_fk(self):\n    \"\"\"\n    #24015 - Altering a field to a ForeignKey should work.\n    \"\"\"\n    before = [\n        ModelState('app', 'Foo', [\n            ('id', models.AutoField(primary_key=True)),\n            ('bar', models.IntegerField()),\n        ]),\n        ModelState('app', 'Bar', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'Foo', [\n            ('id', models.AutoField(primary_key=True)),\n            ('bar', models.ForeignKey('app.Bar', models.CASCADE)),\n        ]),\n        ModelState('app', 'Bar', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n    ]\n    changes = self.get_changes(before, after)\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name=\"bar\")\n    fk_field = changes['app'][0].operations[0].field\n    to_model = '%s.%s' % (\n        fk_field.remote_field.model._meta.app_label,\n        fk_field.remote_field.model._meta.object_name,\n    )\n    self.assertEqual(to_model, 'app.Bar')\n"], "sample_50": ["def test_sigint_handler_restoration_on_exception(self):\n    \"\"\"SIGINT handler is restored even if an exception occurs.\"\"\"\n        raise subprocess.SubprocessError\n\n    sigint_handler = signal.getsignal(signal.SIGINT)\n    # The default handler isn't SIG_IGN.\n    self.assertNotEqual(sigint_handler, signal.SIG_IGN)\n    try:\n        with mock.patch('subprocess.run', new=_mock_subprocess_run):\n            DatabaseClient.runshell_db({})\n    except subprocess.SubprocessError:\n        pass\n    # dbshell restores the original handler even if an exception occurs.\n    self.assertEqual(sigint_handler, signal.getsignal(signal.SIGINT))\n"], "sample_749": ["def test_column_transformer_transformer_weights():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n\n    X_res_first = np.array([0, 1, 2]).reshape(-1, 1)\n    X_res_second = np.array([2, 4, 6]).reshape(-1, 1)\n    X_res_both = X_array\n\n    # test with transformer_weights\n    transformer_weights = {'trans1': .1, 'trans2': 10}\n    both = ColumnTransformer([('trans1', Trans(), [0]),\n                              ('trans2', Trans(), [1])],\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * X_res_first1D,\n                     transformer_weights['trans2'] * X_res_second1D]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and remainder\n    transformer_weights = {'trans1': .1}\n    both = ColumnTransformer([('trans1', Trans(), [0])],\n                             remainder=DoubleTrans(),\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * X_res_first1D,\n                     2 * X_res_second1D]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and passthrough\n    transformer_weights = {'trans1': .1}\n    both = ColumnTransformer([('trans1', Trans(), [0])],\n                             remainder='passthrough',\n                             transformer_weights=transformer_weights)\n    res = np.vstack([transformer_weights['trans1'] * X_res_first1D,\n                     X_res_second1D]).T\n    assert_array_equal(both.fit_transform(X_array), res)\n    assert_array_equal(both.fit(X_array).transform(X_array), res)\n    assert len(both.transformers_) == 2\n\n    # test with transformer_weights and drop\n    transformer_weights = {'trans1': .1}\n    both = ColumnTransformer([('trans1', Trans(), [0])],\n                             remainder='drop',\n                             transformer"], "sample_402": ["def test_prepend_www_append_slash_with_port(self):\n    \"\"\"\n    PREPEND_WWW should work with URLs that have a port number.\n    \"\"\"\n    request = self.rf.get(\"http://testserver:8000/slash\")\n    r = CommonMiddleware(get_response_empty).process_request(request)\n    self.assertEqual(r.status_code, 301)\n    self.assertEqual(r.url, \"http://www.testserver:8000/slash/\")\n"], "sample_568": ["def test_line3d_set_get_data_3d(fig_test, fig_ref):\n    x, y, z = [0, 1], [2, 3], [4, 5]\n    x2, y2, z2 = [6, 7], [8, 9], [10, 11]\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    lines = ax.plot(x, y, z)\n    line = lines[0]\n    np.testing.assert_array_equal((x, y, z), line.get_data_3d())\n    line.set_data_3d(x2, y2, z2)\n    np.testing.assert_array_equal((x2, y2, z2), line.get_data_3d())\n    line.set_xdata(x)\n    line.set_ydata(y)\n    line.set_3d_properties(zs=z, zdir='z')\n    np.testing.assert_array_equal((x, y, z), line.get_data_3d())\n    line.set_3d_properties(zs=0, zdir='z')\n    np.testing.assert_array_equal((x, y, np.zeros_like(z)), line.get_data_3d())\n\n    ax = fig_ref.add_subplot(projection='3d')\n    ax.plot(x2, y2, z2)\n"], "sample_882": ["def test_mlp_regressor_sparse_input():\n    # Test that sparse input matrices output the same results as dense input matrices.\n    X = X_reg\n    y = y_reg\n\n    mlp = MLPRegressor(\n        solver=\"lbfgs\",\n        hidden_layer_sizes=50,\n        max_iter=150,\n        shuffle=True,\n        random_state=1,\n    )\n    mlp.fit(X, y)\n    pred1 = mlp.predict(X)\n    mlp.fit(csr_matrix(X), y)\n    pred2 = mlp.predict(csr_matrix(X))\n    assert_almost_equal(pred1, pred2)\n    pred1 = mlp.predict(X)\n    pred2 = mlp.predict(csr_matrix(X))\n    assert_array_equal(pred1, pred2)\n"], "sample_418": ["    def test_addslashes01(self):\n        output = self.engine.render_to_string(\"addslashes01\", {\"string\": \"Hello 'World' \\\"Django\\\"\"})\n        self.assertEqual(output, \"Hello \\\\'World\\' \\\"Django\\\"\")\n"], "sample_224": ["def test_aggregate_subquery_annotation_with_filter(self):\n    \"\"\"\n    Subquery annotations are excluded from the GROUP BY if they are not\n    explicitly grouped against, even if they are filtered.\n    \"\"\"\n    latest_book_pubdate_qs = Book.objects.filter(\n        publisher=OuterRef('pk'),\n        rating__gt=4,\n    ).order_by('-pubdate').values('pubdate')[:1]\n    publisher_qs = Publisher.objects.annotate(\n        latest_book_pubdate=Subquery(latest_book_pubdate_qs),\n    ).annotate(count=Count('book'))\n    with self.assertNumQueries(1) as ctx:\n        list(publisher_qs)\n    self.assertEqual(ctx[0]['sql'].count('SELECT'), 2)\n    # The GROUP BY should not be by alias either.\n    self.assertEqual(ctx[0]['sql'].lower().count('latest_book_pubdate'), 1)\n"], "sample_683": ["def test_capturing_and_logging_fundamentals_with_keyboardinterrupt(testdir):\n    # here we check a fundamental feature\n    p = testdir.makepyfile(\n        \"\"\"\n        import sys, os\n        import py, logging\n        from _pytest import capture\n        cap = capture.MultiCapture(\n            in_=None,\n            out=None,\n            err=capture.SysCapture(2),\n        )\n        cap.start_capturing()\n\n        logging.warning(\"hello1\")\n        outerr = cap.readouterr()\n        print(\"suspend, captured %%s\" %%(outerr,))\n        logging.warning(\"hello2\")\n\n        cap.pop_outerr_to_orig()\n        logging.warning(\"hello3\")\n\n        outerr = cap.readouterr()\n        print(\"suspend2, captured %%s\" %% (outerr,))\n        raise KeyboardInterrupt()\n    \"\"\"\n    )\n    result = testdir.runpython(p)\n    result.stdout.fnmatch_lines(\n        \"\"\"\n        suspend, captured*hello1*\n        suspend2, captured*WARNING:root:hello3*\n    \"\"\"\n    )\n    result.stderr.fnmatch_lines(\n        \"\"\"\n        WARNING:root:hello2\n    \"\"\"\n    )\n    assert \"atexit\" not in result.stderr.str()\n"], "sample_191": ["    def test_enable_echo(self, mocked_termios):\n        mocked_termios.tcgetattr.return_value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n        mocked_termios.ECHO = 1\n        autoreload.ensure_echo_on()\n        mocked_termios.tcsetattr.assert_called_once_with(mock.ANY, mock.ANY, [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"], "sample_285": ["def test_find_in_app(self):\n    static_dir = Path(TEST_ROOT) / 'project' / 'documents'\n    with self.settings(STATICFILES_DIRS=[static_dir]):\n        finder = get_finder('django.contrib.staticfiles.finders.AppDirectoriesFinder')\n        app_config = apps.get_app_config('documents')\n        app_storage = finder.storages[app_config.name]\n        self.assertEqual(finder.find_in_app(app_config.name, 'test.txt'), app_storage.path('test.txt'))\n"], "sample_512": ["def test_xkcd_context_manager():\n    # Test that xkcd context manager correctly sets and resets rcParams.\n    with plt.xkcd():\n        assert rcParams['font.family'] == ['xkcd', 'xkcd Script', 'Humor Sans', 'Comic Neue', 'Comic Sans MS']\n        assert rcParams['path.sketch'] == (4, 100, 2)\n        assert rcParams['axes.linewidth'] == 1.5\n        assert rcParams['lines.linewidth'] == 2.0\n        assert rcParams['figure.facecolor'] == 'white'\n        assert rcParams['grid.linewidth'] == 0.0\n        assert rcParams['axes.grid'] is False\n        assert rcParams['axes.unicode_minus'] is False\n        assert rcParams['axes.edgecolor'] == 'black'\n        assert rcParams['xtick.major.size'] == 8\n        assert rcParams['xtick.major.width'] == 3\n        assert rcParams['ytick.major.size'] == 8\n        assert rcParams['ytick.major.width'] == 3\n    assert rcParams['font.family'] != ['xkcd', 'xkcd Script', 'Humor Sans', 'Comic Neue', 'Comic Sans MS']\n    assert rcParams['path.sketch'] != (4, 100, 2)\n    assert rcParams['axes.linewidth'] != 1.5\n    assert rcParams['lines.linewidth'] != 2.0\n    assert rcParams['figure.facecolor'] != 'white'\n    assert rcParams['grid.linewidth'] != 0.0\n    assert rcParams['axes.grid'] is not False\n    assert rcParams['axes.unicode_minus'] is not False\n    assert rcParams['axes.edgecolor'] != 'black'\n    assert rcParams['xtick.major.size'] != 8\n    assert rcParams['xtick.major.width'] != 3\n    assert rcParams['ytick.major.size'] != 8\n    assert rcParams['ytick.major.width'] != 3\n"], "sample_387": ["    def test_get_inline_instances(self):\n        class MyInline(admin.StackedInline):\n            model = Member\n\n        class BandAdmin(admin.ModelAdmin):\n            inlines = [MyInline]\n\n        band_admin = BandAdmin(Band, admin.site)\n        inline_instances = band_admin.get_inline_instances(self.client, Band())\n        self.assertEqual(len(inline_instances), 1)\n        self.assertIsInstance(inline_instances[0], MyInline)\n"], "sample_83": ["    def test_get_resolved_arguments(self):\n            pass\n        node = TagHelperNode(func, False, [1, 2], {'a': 3, 'b': 4})\n        context = {'1': 'resolved_1', '2': 'resolved_2', '3': 'resolved_3', '4': 'resolved_4'}\n        resolved_args, resolved_kwargs = node.get_resolved_arguments(context)\n        self.assertEqual(resolved_args, ['resolved_1', 'resolved_2'])\n        self.assertEqual(resolved_kwargs, {'a': 'resolved_3', 'b': 'resolved_4'})\n"], "sample_522": ["def test_colorbar_set_ticks():\n    # test fix for #20054\n    fig, ax = plt.subplots()\n    x = np.arange(-3.0, 4.001)\n    y = np.arange(-4.0, 3.001)\n    X, Y = np.meshgrid(x, y)\n    Z = X * Y\n    Z = Z[:-1, :-1]\n    pcm = ax.pcolormesh(X, Y, Z)\n    cbar = fig.colorbar(pcm, ax=ax, extend='both',\n                        orientation='vertical')\n    ticks = cbar.get_ticks()\n    cbar.set_ticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])\n    np.testing.assert_allclose(cbar.ax.yaxis.get_ticklocs(),\n                               np.arange(1, 16))\n"], "sample_1030": ["def test_are_coplanar():\n    from sympy.geometry import Point3D, Line3D, Plane\n    a = Line3D(Point3D(5, 0, 0), Point3D(1, -1, 1))\n    b = Line3D(Point3D(0, -2, 0), Point3D(3, 1, 1))\n    c = Line3D(Point3D(0, -1, 0), Point3D(5, -1, 9))\n    assert not are_coplanar(a, b, c)\n    p = Plane(Point3D(0, 0, 0), Point3D(1, 0, 0), Point3D(0, 1, 0))\n    assert are_coplanar(p, a, b)\n    assert are_coplanar(a, b, Point3D(0, 0, 0))\n    assert are_coplanar(Point3D(0, 0, 0), Point3D(1, 0, 0), Point3D(0, 1, 0))\n    assert not are_coplanar(Point3D(0, 0, 0), Point3D(1, 0, 0), Point3D(0, 1, 1))\n"], "sample_143": ["def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('hello'), 'hello')\n    self.assertEqual(text.camel_case_to_spaces(''), '')\n    self.assertEqual(text.camel_case_to_spaces(lazystr('HelloWorld')), 'hello world')\n"], "sample_893": ["def test_export_text_max_depth_truncation():\n    # Check that export_text truncates the tree at the correct depth\n    clf = DecisionTreeClassifier(max_depth=3, random_state=0)\n    clf.fit(X, y)\n\n    expected_report = dedent(\"\"\"\n    |--- feature_1 <= 0.00\n    |   |--- class: -1\n    |--- feature_1 >  0.00\n    |   |--- truncated branch of depth 2\n    \"\"\").lstrip()\n    assert export_text(clf, max_depth=0) == expected_report\n\n    expected_report = dedent(\"\"\"\n    |--- feature_1 <= 0.00\n    |   |--- class: -1\n    |--- feature_1 >  0.00\n    |   |--- feature_1 <= 1.50\n    |   |   |--- class: 1\n    |   |--- feature_1 >  1.50\n    |   |   |--- class: 1\n    \"\"\").lstrip()\n    assert export_text(clf, max_depth=1) == expected_report\n"], "sample_902": ["def test_pipeline_memory_with_string():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        # Test with Transformer + SVC\n        clf = SVC(probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', clone(transf)), ('svc', clf)])\n        cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n                               memory=cachedir)\n\n        # Memoize the transformer at the first fit\n        cached_pipe.fit(X, y)\n        pipe.fit(X, y)\n        # Get the time stamp of the transformer in the cached pipeline\n        ts = cached_pipe.named_steps['transf'].timestamp_\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert_false(hasattr(transf, 'means_'))\n        # Check that we are reading the cache while fitting\n        # a second time\n        cached_pipe.fit(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert_equal(ts, cached_pipe.named_steps['transf'].timestamp_)\n    finally:\n        shutil.rmtree(cachedir)\n"], "sample_641": ["def test_load_result_non_existent_file(path: str) -> None:\n    loaded = load_results(path)\n    assert loaded is None\n\n"], "sample_29": ["def test_write_latex_with_kwargs(self, write, tmp_path):\n    \"\"\"Test passing additional keyword arguments to write_latex\"\"\"\n    fp = tmp_path / \"test_write_latex_with_kwargs.tex\"\n    write(fp, format=\"latex\", latex_names=True, comment=\"Test comment\")\n    tbl = QTable.read(fp)\n    assert tbl.meta[\"comment\"] == \"Test comment\"\n"], "sample_544": ["def test_axesimage_set_extent():\n    ax = plt.gca()\n    im = AxesImage(ax)\n    z = np.arange(12, dtype=float).reshape((4, 3))\n    im.set_data(z)\n    im.set_extent([0, 1, 0, 1])\n    assert im.get_extent() == (0, 1, 0, 1)\n    im.set_extent([1, 2, 1, 2])\n    assert im.get_extent() == (1, 2, 1, 2)\n"], "sample_638": ["def test_directly_supported_format(mock_writer, capsys):\n    \"\"\"Test that directly supported formats do not trigger Graphviz checks.\"\"\"\n    with pytest.raises(SystemExit) as wrapped_sysexit:\n        # we have to catch the SystemExit so the test execution does not stop\n        main.Run([\"-o\", \"dot\", TEST_DATA_DIR])\n    # Check that no info message is shown to the user\n    assert \"Format dot is not supported natively.\" not in capsys.readouterr().out\n    # Check that pyreverse actually made the call to create the diagram and we exit cleanly\n    mock_writer.DiagramWriter().write.assert_called_once()\n    assert wrapped_sysexit.value.code == 0\n"], "sample_210": ["    def test_get_context_data(self):\n        mixin = ContextMixin()\n        mixin.extra_context = {'foo': 'bar'}\n        context = mixin.get_context_data(baz='qux')\n        self.assertEqual(context, {'view': mixin, 'foo': 'bar', 'baz': 'qux'})\n"], "sample_478": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n"], "sample_428": ["def test_edge_cases(self):\n    # Test with very large decimal positions\n    self.assertEqual(nformat(1234, \".\", decimal_pos=100), \"1234.00\")\n    self.assertEqual(nformat(1234.5678, \".\", decimal_pos=100), \"1234.567800000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"], "sample_805": ["def test_regression_metrics_edge_cases():\n    # Test edge cases for regression metrics\n    y_true = [1e-100, 1e100]\n    y_pred = [1e-100, 1e100]\n\n    assert_almost_equal(mean_squared_error(y_true, y_pred), 0.00, 2)\n    assert_almost_equal(mean_squared_log_error(y_true, y_pred), 0.00, 2)\n    assert_almost_equal(mean_absolute_error(y_true, y_pred), 0.00, 2)\n    assert_almost_equal(median_absolute_error(y_true, y_pred), 0.00, 2)\n    assert_almost_equal(max_error(y_true, y_pred), 0.00, 2)\n    assert_almost_equal(explained_variance_score(y_true, y_pred), 1.00, 2)\n    assert_almost_equal(r2_score(y_true, y_pred), 1.00, 2)\n\n    y_true = [1e-100, 1e100]\n    y_pred = [1e-100 + 1e-50, 1e100 + 1e50]\n\n    assert_almost_equal(mean_squared_error(y_true, y_pred), 1e-100, 2)\n    assert_almost_equal(mean_squared_log_error(y_true, y_pred), 1e-100, 2)\n    assert_almost_equal(mean_absolute_error(y_true, y_pred), 1e-50, 2)\n    assert_almost_equal(median_absolute_error(y_true, y_pred), 1e-50, 2)\n    assert_almost_equal(max_error(y_true, y_pred), 1e50, 2)\n    assert_almost_equal(explained_variance_score(y_true, y_pred), 1.00, 2)\n    assert_almost_equal(r2_score(y_true, y_pred), 1.00, 2)\n\n    y_true = [1e-100, 1e100]\n    y_pred = [1e-100 - 1e-50, 1e100 - 1e50]\n\n    assert_almost_equal(mean_squared_error(y_true, y_pred), 1e-100, 2)\n    assert_almost_equal(mean_squared_log_error(y_true, y_pred), 1e-100, 2)\n    assert_almost_equal(mean_absolute_error(y_true, y_pred), 1e-50, 2)\n    assert_almost_equal(median_absolute_error(y_true"], "sample_700": ["def test_xfail_strict_with_parametrize(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.parametrize(\"x\", [1, 2])\n        @pytest.mark.xfail(strict=True)\n            assert x == 1\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-rxX\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*XPASS(strict)*test_foo[2]*\",\n            \"*FAILED*test_foo[1]*\",\n            \"*1 failed*1 xpassed*\",\n        ]\n    )\n    assert result.ret == 1\n"], "sample_278": ["    def test_q_object_clone(self):\n        q = Q(name='John') | Q(age__gt=30)\n        q_clone = q.clone()\n        self.assertEqual(q, q_clone)\n        self.assertIsNot(q, q_clone)\n"], "sample_147": ["def test_union_with_distinct_fields(self):\n    qs1 = Number.objects.filter(num__lte=1).distinct('num')\n    qs2 = Number.objects.filter(num__gte=2, num__lte=3)\n    self.assertNumbersEqual(qs1.union(qs2).order_by('-num'), [3, 2, 1, 0])\n"], "sample_865": ["def test_prune_tree_on_unfitted_tree():\n    # test that pruning on an unfitted tree raises an error\n    clf = DecisionTreeClassifier()\n    with pytest.raises(NotFittedError):\n        clf._prune_tree()\n"], "sample_205": ["def test_update_error_dict(self):\n    error_dict = {}\n    exception = ValidationError({'field1': 'error1', 'field2': 'error2'})\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['error1', 'error2']})\n\n    error_dict = {}\n    exception = ValidationError('error')\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['error']})\n\n    error_dict = {}\n    exception = ValidationError({'field1': 'error1'})\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['error1']})\n\n    error_dict = {'field1': ['error1']}\n    exception = ValidationError({'field2': 'error2'})\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['error1'], 'field2': ['error2']})\n\n    error_dict = {'field1': ['error1']}\n    exception = ValidationError('error')\n    exception.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['error1'], '__all__': ['error']})\n"], "sample_733": ["def test_vectorizer_stop_words_removal_with_max_features():\n    # Ensure that deleting the stop_words_ attribute doesn't affect transform\n    # when max_features is set\n\n    fitted_vectorizers = (\n        TfidfVectorizer(max_features=5).fit(JUNK_FOOD_DOCS),\n        CountVectorizer(preprocessor=strip_tags, max_features=5).fit(JUNK_FOOD_DOCS),\n        CountVectorizer(strip_accents=strip_eacute, max_features=5).fit(JUNK_FOOD_DOCS)\n    )\n\n    for vect in fitted_vectorizers:\n        vect_transform = vect.transform(JUNK_FOOD_DOCS).toarray()\n\n        vect.stop_words_ = None\n        stop_None_transform = vect.transform(JUNK_FOOD_DOCS).toarray()\n\n        delattr(vect, 'stop_words_')\n        stop_del_transform = vect.transform(JUNK_FOOD_DOCS).toarray()\n\n        assert_array_equal(stop_None_transform, vect_transform)\n        assert_array_equal(stop_del_transform, vect_transform)\n"], "sample_172": ["    def test_get_field_queryset(self):\n        class MyModelAdmin(admin.ModelAdmin):\n                return db_field.remote_field.model._default_manager.filter(name='test')\n\n        ma = MyModelAdmin(Album, admin.site)\n        queryset = ma.get_field_queryset('default', Album._meta.get_field('band'), None)\n        self.assertEqual(queryset.count(), 0)\n\n        Album.objects.create(name='test', band_id=1)\n        queryset = ma.get_field_queryset('default', Album._meta.get_field('band'), None)\n        self.assertEqual(queryset.count(), 1)\n"], "sample_66": ["def test_get_signed_cookie(self):\n    request = HttpRequest()\n    request.COOKIES = {'signed_cookie': 'signed_value'}\n    with self.assertRaises(KeyError):\n        request.get_signed_cookie('signed_cookie')\n\n    request.COOKIES = {'signed_cookie': 'signed_value:signature'}\n    with self.assertRaises(signing.BadSignature):\n        request.get_signed_cookie('signed_cookie')\n\n    request.COOKIES = {'signed_cookie': signing.get_cookie_signer(salt='salt').sign('signed_value')}\n    self.assertEqual(request.get_signed_cookie('signed_cookie', salt='salt'), 'signed_value')\n\n    request.COOKIES = {'signed_cookie': signing.get_cookie_signer(salt='salt').sign('signed_value')}\n    self.assertEqual(request.get_signed_cookie('signed_cookie', salt='salt', max_age=3600), 'signed_value')\n\n    request.COOKIES = {'signed_cookie': signing.get_cookie_signer(salt='salt').sign('signed_value')}\n    with self.assertRaises(signing.SignatureExpired):\n        request.get_signed_cookie('signed_cookie', salt='salt', max_age=0)\n"], "sample_642": ["def test_preprocess_options() -> None:\n    \"\"\"Test that the _preprocess_options function correctly handles options.\"\"\"\n    run = mock.Mock(spec=Run)\n    args = [\"--init-hook=print('Hello World')\", \"--rcfile=rcfile.txt\", \"--output=output.txt\", \"--load-plugins=plugin1,plugin2\", \"--verbose\", \"-v\", \"--enable-all-extensions\"]\n    expected_args = [\"--init-hook=print('Hello World')\", \"--rcfile=rcfile.txt\", \"--output=output.txt\", \"--load-plugins=plugin1,plugin2\", \"--verbose\", \"-v\", \"--enable-all-extensions\"]\n    expected_calls = [\n        mock.call(run, \"print('Hello World')\"),\n        mock.call(run, \"rcfile.txt\"),\n        mock.call(run, \"output.txt\"),\n        mock.call(run, \"plugin1,plugin2\"),\n        mock.call(run, None),\n        mock.call(run, None),\n        mock.call(run, None),\n    ]\n    with mock.patch(\"pylint.config._init_hook\") as mock_init_hook, \\\n         mock.patch(\"pylint.config._set_rcfile\") as mock_set_rcfile, \\\n         mock.patch(\"pylint.config._set_output\") as mock_set_output, \\\n         mock.patch(\"pylint.config._add_plugins\") as mock_add_plugins, \\\n         mock.patch(\"pylint.config._set_verbose_mode\") as mock_set_verbose_mode, \\\n         mock.patch(\"pylint.config._enable_all_extensions\") as mock_enable_all_extensions:\n        result = _preprocess_options(run, args)\n        assert result == expected_args\n        mock_init_hook.assert_called_once_with(run, \"print('Hello World')\")\n        mock_set_rcfile.assert_called_once_with(run, \"rcfile.txt\")\n        mock_set_output.assert_called_once_with(run, \"output.txt\")\n        mock_add_plugins.assert_called_once_with(run, \"plugin1,plugin2\")\n        mock_set_verbose_mode.assert_has_calls([mock.call(run, None), mock.call(run, None)])\n        mock_enable_all_extensions.assert_called_once_with(run, None)\n"], "sample_558": ["def test_imagegrid_cbar_mode_each():\n    imdata = np.arange(100).reshape((10, 10))\n\n    fig = plt.figure(1, (3, 3))\n    grid = ImageGrid(fig, (1, 1, 1), nrows_ncols=(3, 2), axes_pad=(0.5, 0.3),\n                     cbar_mode=\"each\", cbar_location=\"right\", cbar_size=\"15%\",\n                     label_mode=\"all\")\n    for ax, cax in zip(grid, grid.cbar_axes):\n        im = ax.imshow(imdata, interpolation='none')\n        cax.colorbar(im)\n"], "sample_259": ["def test_prefetch_object_with_nested_prefetch(self):\n    book1 = Book.objects.get(id=self.book1.id)\n    with self.assertNumQueries(2):\n        prefetch_related_objects(\n            [book1],\n            Prefetch('authors', queryset=Author.objects.prefetch_related('books')),\n        )\n\n    with self.assertNumQueries(0):\n        self.assertCountEqual(book1.authors.all(), [self.author1, self.author2, self.author3])\n        self.assertCountEqual(self.author1.books.all(), [self.book1, self.book2])\n        self.assertCountEqual(self.author2.books.all(), [self.book1])\n        self.assertCountEqual(self.author3.books.all(), [self.book1, self.book3])\n"], "sample_634": ["    def test_expand_modules_with_errors(self, files_or_modules, expected_errors):\n        \"\"\"Test expand_modules with non-existent modules and files\"\"\"\n        ignore_list, ignore_list_re = [], []\n        modules, errors = expand_modules(\n            files_or_modules,\n            ignore_list,\n            ignore_list_re,\n            get_global_option(self, \"ignore-paths\"),\n        )\n        assert not modules\n        assert len(errors) == len(expected_errors)\n        for error in errors:\n            assert \"key\" in error and error[\"key\"] == \"fatal\"\n            assert \"mod\" in error and error[\"mod\"] in [e[\"mod\"] for e in expected_errors]\n            assert \"ex\" in error and isinstance(error[\"ex\"], type(next(e[\"ex\"] for e in expected_errors if e[\"mod\"] == error[\"mod\"]))\n"], "sample_152": ["def test_can_fast_delete_with_generic_foreign_key(self):\n    \"\"\"\n    Test that can_fast_delete() returns False when a model has a generic\n    foreign key.\n    \"\"\"\n    a = A.objects.create()\n    a.genericfk = GenericB1.objects.create()\n    a.save()\n    collector = Collector(using='default')\n    self.assertFalse(collector.can_fast_delete(a.genericfk))\n"], "sample_323": ["def test_detect_soft_applied_with_unmanaged_models(self):\n    \"\"\"\n    Tests detection of initial migrations already having been applied,\n    considering unmanaged models.\n    \"\"\"\n    state = {\"faked\": None}\n\n        state[\"faked\"] = fake\n    executor = MigrationExecutor(connection, progress_callback=fake_storer)\n    # Were the tables there before?\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_tribble\")\n    # Run it normally\n    self.assertEqual(\n        executor.migration_plan([(\"migrations\", \"0001_initial\")]),\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n        ],\n    )\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n    # Are the tables there now?\n    self.assertTableExists(\"migrations_author\")\n    self.assertTableExists(\"migrations_tribble\")\n    # We shouldn't have faked that one\n    self.assertIs(state[\"faked\"], False)\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Fake-reverse that\n    executor.migrate([(\"migrations\", None)], fake=True)\n    # Are the tables still there?\n    self.assertTableExists(\"migrations_author\")\n    self.assertTableExists(\"migrations_tribble\")\n    # Make sure that was faked\n    self.assertIs(state[\"faked\"], True)\n    # Finally, migrate forwards; this should fake-apply our initial migration\n    executor.loader.build_graph()\n    self.assertEqual(\n        executor.migration_plan([(\"migrations\", \"0001_initial\")]),\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n        ],\n    )\n    # Applying the migration should raise a database level error\n    # because we haven't given the --fake-initial option\n    with self.assertRaises(DatabaseError):\n        executor.migrate([(\"migrations\", \"0001_initial\")])\n    # Reset the faked state\n    state = {\"faked\": None}\n    # Allow faking of initial CreateModel operations\n    executor.migrate([(\"migrations\", \"0001_initial\")], fake_initial=True)\n    self.assertIs(state[\"faked\"], True)\n    # And migrate back to clean up"], "sample_292": ["def test_rotate_token(self):\n    \"\"\"\n    The rotate_token function changes the CSRF token in use for a request.\n    \"\"\"\n    req = self._get_GET_csrf_cookie_request()\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.process_request(req)\n    original_token = req.META['CSRF_COOKIE']\n    rotate_token(req)\n    mw.process_request(req)\n    new_token = req.META['CSRF_COOKIE']\n    self.assertNotEqual(original_token, new_token)\n    self.assertTrue(equivalent_tokens(original_token, new_token))\n"], "sample_167": ["def test_naturaltime_with_naive_and_aware_datetimes(self):\n    \"\"\"\n    Test that naturaltime works correctly with both naive and aware datetimes.\n    \"\"\"\n    naive_now = datetime.datetime(2022, 1, 1, 12, 0, 0)\n    aware_now = datetime.datetime(2022, 1, 1, 12, 0, 0, tzinfo=utc)\n\n    test_list = [\n        naive_now - datetime.timedelta(hours=1),\n        aware_now - datetime.timedelta(hours=1),\n        naive_now + datetime.timedelta(hours=1),\n        aware_now + datetime.timedelta(hours=1),\n    ]\n    result_list = [\n        'an hour ago',\n        'an hour ago',\n        'an hour from now',\n        'an hour from now',\n    ]\n\n    orig_humanize_datetime, humanize.datetime = humanize.datetime, MockDateTime\n    try:\n        with translation.override('en'):\n            self.humanize_tester(test_list, result_list, 'naturaltime')\n    finally:\n        humanize.datetime = orig_humanize_datetime\n"], "sample_447": ["def test_annotation_with_nested_expression(self):\n    authors = Author.objects.annotate(\n        friends_count=Count(\"friends\"),\n        friends_of_friends_count=Count(\"friends__friends\"),\n    )\n    for author in authors:\n        with self.subTest(author=author):\n            self.assertEqual(\n                author.friends_of_friends_count,\n                author.friends.aggregate(count=Count(\"friends\"))[\"count\"],\n            )\n"], "sample_890": ["def test_n_features_to_select_auto_with_scoring(direction):\n    \"\"\"Check the behaviour of `n_features_to_select=\"auto\"` with different\n    values for the parameter `tol` and a custom scoring function.\n    \"\"\"\n\n    n_features = 10\n    tol = 1e-3\n    X, y = make_regression(n_features=n_features, random_state=0)\n    sfs = SequentialFeatureSelector(\n        LinearRegression(),\n        n_features_to_select=\"auto\",\n        tol=tol,\n        direction=direction,\n        cv=2,\n        scoring=\"neg_mean_squared_error\",\n    )\n    sfs.fit(X, y)\n\n    max_features_to_select = n_features - 1\n\n    assert sfs.get_support(indices=True).shape[0] <= max_features_to_select\n    assert sfs.n_features_to_select_ <= max_features_to_select\n    assert sfs.transform(X).shape[1] <= max_features_to_select\n    assert sfs.get_support(indices=True).shape[0] == sfs.n_features_to_select_\n"], "sample_378": ["    def test_iterable_class(self):\n        qs = Note.objects.all()\n        self.assertEqual(qs._iterable_class, ModelIterable)\n        qs = Note.objects.values()\n        self.assertEqual(qs._iterable_class, ValuesIterable)\n        qs = Note.objects.values_list()\n        self.assertEqual(qs._iterable_class, ValuesListIterable)\n        qs = Note.objects.values_list(flat=True)\n        self.assertEqual(qs._iterable_class, FlatValuesListIterable)\n        qs = Note.objects.values_list(named=True)\n        self.assertEqual(qs._iterable_class, NamedValuesListIterable)\n"], "sample_175": ["def test_collector_add_dependency(self):\n    collector = Collector(using='default')\n    model1 = R\n    model2 = S\n    collector.add_dependency(model1, model2)\n    self.assertIn(model1._meta.concrete_model, collector.dependencies)\n    self.assertIn(model2._meta.concrete_model, collector.dependencies[model1._meta.concrete_model])\n"], "sample_493": ["def test_aggregation_subquery_annotation_with_distinct(self):\n    \"\"\"\n    Subquery annotations must be included in the GROUP BY if they use\n    potentially multivalued relations (contain the LOOKUP_SEP).\n    \"\"\"\n    subquery_qs = (\n        Author.objects.filter(\n            pk=OuterRef(\"pk\"),\n            book__name=OuterRef(\"book__name\"),\n        )\n        .distinct()\n        .values(\"pk\")\n    )\n    author_qs = Author.objects.annotate(\n        subquery_id=Subquery(subquery_qs),\n    ).annotate(count=Count(\"book\"))\n    self.assertEqual(author_qs.count(), Author.objects.count())\n"], "sample_960": ["def test_python_domain_get_full_qualified_name():\n    env = Mock(domaindata={})\n    domain = PythonDomain(env)\n\n    # with py:module and py:class context\n    kwargs = {'py:module': 'module1', 'py:class': 'Class'}\n    node = nodes.reference(reftarget='func', **kwargs)\n    assert domain.get_full_qualified_name(node) == 'module1.Class.func'\n\n    # with py:module context\n    kwargs = {'py:module': 'module1'}\n    node = nodes.reference(reftarget='func', **kwargs)\n    assert domain.get_full_qualified_name(node) == 'module1.func'\n\n    # with py:class context\n    kwargs = {'py:class': 'Class'}\n    node = nodes.reference(reftarget='func', **kwargs)\n    assert domain.get_full_qualified_name(node) == 'Class.func'\n\n    # without context\n    node = nodes.reference(reftarget='func')\n    assert domain.get_full_qualified_name(node) == 'func'\n"], "sample_892": ["def test_adaboost_feature_importances():\n    # Check feature importances.\n    X, y = datasets.make_classification(\n        n_samples=2000,\n        n_features=10,\n        n_informative=3,\n        n_redundant=0,\n        n_repeated=0,\n        shuffle=False,\n        random_state=1,\n    )\n\n    for alg in [\"SAMME\", \"SAMME.R\"]:\n        clf = AdaBoostClassifier(algorithm=alg)\n\n        clf.fit(X, y)\n        importances = clf.feature_importances_\n\n        assert importances.shape[0] == 10\n        assert (importances[:3, np.newaxis] >= importances[3:]).all()\n\n    # Test that feature importances are not computed when the base estimator\n    # does not support it\n    clf = AdaBoostClassifier(algorithm=\"SAMME\", estimator=DummyClassifier())\n    clf.fit(X, y)\n    with pytest.raises(AttributeError):\n        clf.feature_importances_\n"], "sample_1023": ["def test_sieve_edge_cases():\n    sieve._reset()\n    assert sieve._list == _aset(2, 3, 5, 7, 11, 13)\n    assert sieve._tlist == _aset(0, 1, 1, 2, 2, 4)\n    assert sieve._mlist == _aset(0, 1, -1, -1, 0, -1)\n    sieve._reset(prime=True)\n    assert sieve._list == _aset(2, 3, 5, 7, 11, 13)\n    assert sieve._tlist == _aset(0, 1, 1, 2, 2, 4)\n    assert sieve._mlist == _aset(0, 1, -1, -1, 0, -1)\n    sieve._reset(totient=True)\n    assert sieve._list == _aset(2, 3, 5, 7, 11, 13)\n    assert sieve._tlist == _aset(0, 1, 1, 2, 2, 4)\n    assert sieve._mlist == _aset(0, 1, -1, -1, 0, -1)\n    sieve._reset(mobius=True)\n    assert sieve._list == _aset(2, 3, 5, 7, 11, 13)\n    assert sieve._tlist == _aset(0, 1, 1, 2, 2, 4)\n    assert sieve._mlist == _aset(0, 1, -1, -1, 0, -1)\n    sieve._reset(prime=True, totient=True, mobius=True)\n    assert sieve._list == _aset(2, 3, 5, 7, 11, 13)\n    assert sieve._tlist == _aset(0, 1, 1, 2, 2, 4)\n    assert sieve._mlist == _aset(0, 1, -1, -1, 0, -1)\n"], "sample_800": ["def test_check_estimator_tags():\n    # test that estimators with specific tags are correctly handled\n    class EstimatorWithTags(BaseEstimator):\n        _tags = {'poor_score': True, 'multioutput': True}\n\n    class EstimatorWithTags2(BaseEstimator):\n            return {'poor_score': True, 'multioutput': True}\n\n    check_estimator(EstimatorWithTags)\n    check_estimator(EstimatorWithTags2)\n"], "sample_632": ["def test_ignore_signatures_with_docstrings():\n    output = StringIO()\n    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n        similar.Run([\"--ignore-signatures\", \"--ignore-docstrings\", SIMILAR5, SIMILAR6])\n    assert ex.value.code == 0\n    assert (\n        output.getvalue().strip()\n        == \"\"\""], "sample_464": ["def test_set_signed_cookie(self):\n    response = HttpResponse()\n    response.set_signed_cookie(\"test\", \"value\")\n    self.assertIn(\"Set-Cookie\", response.headers)\n    self.assertEqual(response.cookies[\"test\"][\"httponly\"], True)\n"], "sample_138": ["    def setUp(self):\n        super().setUp()\n\n        temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, 'test'))\n        self._clear_filename = os.path.join(temp_dir, 'test', 'cleared.txt')\n        with open(self._clear_filename, 'w') as f:\n            f.write('to be deleted in one test')\n\n        self.patched_settings = self.settings(\n            STATICFILES_DIRS=settings.STATICFILES_DIRS + [temp_dir],\n        )\n        self.patched_settings.enable()\n        self.addCleanup(shutil.rmtree, temp_dir)\n        self._manifest_strict = storage.staticfiles_storage.manifest_strict\n\n        class CustomManifestStaticFilesStorage(storage.ManifestStaticFilesStorage):\n            manifest_name = 'custom_manifest.json'\n\n        self.custom_storage = CustomManifestStaticFilesStorage()\n"], "sample_716": ["def test_ridge_regression_return_intercept():\n    # Test that return_intercept works correctly\n    X = np.array([[1], [2]])\n    y = np.array([1, 2])\n    alpha = 0.0\n\n    # Test with dense data\n    coef, intercept = ridge_regression(X, y, alpha, return_intercept=True)\n    assert_array_almost_equal(coef, np.array([1.]))\n    assert_almost_equal(intercept, 0.)\n\n    # Test with sparse data\n    X_sparse = sp.csr_matrix(X)\n    coef_sparse, intercept_sparse = ridge_regression(X_sparse, y, alpha, return_intercept=True)\n    assert_array_almost_equal(coef_sparse, np.array([1.]))\n    assert_almost_equal(intercept_sparse, 0.)\n"], "sample_215": ["    def test_technical_500_response(self):\n        request = RequestFactory().get('/')\n        exc_type = ValueError\n        exc_value = ValueError('Test exception')\n        tb = None\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html; charset=utf-8')\n        self.assertContains(response, 'ValueError at /', status_code=500)\n        self.assertContains(response, 'Test exception', status_code=500)\n"], "sample_725": ["def test_check_X_y():\n    # Test function for check_X_y\n    X = np.ones((3, 10), dtype=np.int32)\n    y = np.ones(3, dtype=np.int32)\n    X_checked, y_checked = check_X_y(X, y)\n    assert_equal(X_checked.dtype, np.int32)\n    assert_equal(y_checked.dtype, np.int32)\n\n    # Another test\n    X = X.astype(np.int64)\n    y = y.astype(np.float64)\n    X_checked, y_checked = check_X_y(X, y)\n    assert_equal(X_checked.dtype, np.int64)\n    assert_equal(y_checked.dtype, np.float64)\n\n    # Test int dtypes <= 32bit\n    tested_dtypes = [np.bool,\n                     np.int8, np.int16, np.int32,\n                     np.uint8, np.uint16, np.uint32]\n    for dtype in tested_dtypes:\n        X = X.astype(dtype)\n        y = y.astype(dtype)\n        X_checked, y_checked = check_X_y(X, y)\n        assert_equal(X_checked.dtype, np.float32)\n        assert_equal(y_checked.dtype, np.float32)\n\n    # Test object dtype\n    X = X.astype(object)\n    y = y.astype(object)\n    X_checked, y_checked = check_X_y(X, y)\n    assert_equal(X_checked.dtype, np.float64)\n    assert_equal(y_checked.dtype, np.float64)\n\n    # Here, X is of the right type, it shouldn't be modified\n    X = np.ones((3, 2), dtype=np.float32)\n    y = np.ones(3, dtype=np.float32)\n    X_checked, y_checked = check_X_y(X, y)\n    assert_true(X_checked is X)\n    assert_true(y_checked is y)\n\n    # Test that if X is fortran ordered it stays\n    X = np.asfortranarray(X)\n    y = np.asfortranarray(y)\n    X_checked, y_checked = check_X_y(X, y)\n    assert_true(np.isfortran(X_checked))\n    assert_true(np.isfortran(y_checked))\n\n    # Test the copy parameter with some matrices\n    matrices = [\n        np.matrix(np.arange(5)),\n        sp.csc_matrix(np.arange(5)).toarray(),\n        sparse_random_matrix(10, 10, density=0.10).toarray()\n    ]\n    for M in matrices:\n        N = check_X"], "sample_314": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = ''\n        html = widget.render('name', value, {'id': 'id_password'})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_61": ["    def test_unicode_validator_flags(self):\n        v = validators.UnicodeUsernameValidator()\n        self.assertEqual(v.flags, 0)\n"], "sample_112": ["def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should render prepopulated fields.\n    \"\"\"\n    request = self.request_factory.get(reverse('admin:auth_user_change', args=[self.superuser.pk]))\n    request.user = self.superuser\n    admin = UserAdmin(User, site)\n    response = admin.change_view(request, str(self.superuser.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIn('prepopulated_fields', template_context)\n    self.assertIn('prepopulated_fields_json', template_context)\n    self.assertIsInstance(template_context['prepopulated_fields'], list)\n    self.assertIsInstance(template_context['prepopulated_fields_json'], str)\n"], "sample_1101": ["def test_schur_subsets_number():\n    raises(ValueError, lambda: _schur_subsets_number(S.Infinity))\n    raises(ValueError, lambda: _schur_subsets_number(-1))\n    raises(ValueError, lambda: _schur_subsets_number(0))\n    assert _schur_subsets_number(1) == 1\n    assert _schur_subsets_number(2) == 1\n    assert _schur_subsets_number(3) == 1\n    assert _schur_subsets_number(4) == 2\n    assert _schur_subsets_number(5) == 2\n    assert _schur_subsets_number(6) == 2\n    assert _schur_subsets_number(7) == 2\n    assert _schur_subsets_number(8) == 2\n    assert _schur_subsets_number(9) == 2\n    assert _schur_subsets_number(10) == 2\n    assert _schur_subsets_number(11) == 3\n    assert _schur_subsets_number(12) == 3\n    assert _schur_subsets_number(13) == 3\n    assert _schur_subsets_number(14) == 3\n    assert _schur_subsets_number(15) == 3\n    assert _schur_subsets_number(16) == 3\n    assert _schur_subsets_number(17) == 3\n    assert _schur_subsets_number(18) == 3\n    assert _schur_subsets_number(19) == 3\n    assert _schur_subsets_number(20) == 3\n    assert _schur_subsets_number(21) == 3\n    assert _schur_subsets_number(22) == 3\n    assert _schur_subsets_number(23) == 3\n    assert _schur_subsets_number(24) == 3\n    assert _schur_subsets_number(25) == 3\n    assert _schur_subsets_number(26) == 3\n    assert _schur_subsets_number(27) == 3\n    assert _schur_subsets_number(28) == 3\n    assert _schur_subsets_number(29) == 3\n    assert _schur_subsets_number(30) == 3\n    assert _sch"], "sample_85": ["    def test_related_query_name_clashes(self):\n        with self.assertRaisesMessage(exceptions.FieldError, \"Reverse query name 'model' must not end with an underscore.\"):\n            class Model(models.Model):\n                field = models.ForeignKey('self', related_query_name='model_')\n\n        with self.assertRaisesMessage(exceptions.FieldError, \"Reverse query name 'model__field' must not contain '__'.\"):\n            class Model(models.Model):\n                field = models.ForeignKey('self', related_query_name='model__field')\n"], "sample_26": ["def test_section_data_scaled_uint(tmp_path):\n    \"\"\"\n    Regression test for https://github.com/astropy/astropy/issues/143\n\n    This is like test_section_data_square but uses a file containing scaled\n    unsigned integer data, to test that sections can work correctly with scaled data.\n    \"\"\"\n\n    arr = np.arange(100, dtype=np.uint16)\n    hdu = fits.PrimaryHDU(data=arr)\n    hdu.header[\"BSCALE\"] = 1.1\n    hdu.header[\"BZERO\"] = 10\n    hdu.writeto(tmp_path / \"test.fits\")\n\n    with fits.open(tmp_path / \"test.fits\") as hdul:\n        d = hdul[0]\n        dat = hdul[0].data\n        assert (d.section[:, :] == dat[:, :]).all()\n        assert (d.section[0, :] == dat[0, :]).all()\n        assert (d.section[1, :] == dat[1, :]).all()\n        assert (d.section[:, 0] == dat[:, 0]).all()\n        assert (d.section[:, 1] == dat[:, 1]).all()\n        assert (d.section[0, 0] == dat[0, 0]).all()\n        assert (d.section[0, 1] == dat[0, 1]).all()\n        assert (d.section[1, 0] == dat[1, 0]).all()\n        assert (d.section[1, 1] == dat[1, 1]).all()\n        assert (d.section[0:1, 0:1] == dat[0:1, 0:1]).all()\n        assert (d.section[0:2, 0:1] == dat[0:2, 0:1]).all()\n        assert (d.section[0:1, 0:2] == dat[0:1, 0:2]).all()\n        assert (d.section[0:2, 0:2] == dat[0:2, 0:2]).all()\n        hdul.close()\n\n        # Test without having accessed the full data first\n        hdul = fits.open(tmp_path / \"test.fits\")\n        d = hdul[0]\n        assert (d.section[:, :] == dat[:, :]).all()\n        assert (d.section[0, :] == dat[0, :])."], "sample_324": ["def test_rotate_token(self):\n    \"\"\"\n    Rotate the CSRF token on login.\n    \"\"\"\n    req = self._get_GET_csrf_cookie_request()\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.process_request(req)\n    original_token = req.META['CSRF_COOKIE']\n    rotate_token(req)\n    mw.process_request(req)\n    new_token = req.META['CSRF_COOKIE']\n    self.assertNotEqual(original_token, new_token)\n    self.assertTrue(equivalent_tokens(original_token, new_token))\n"], "sample_777": ["def test_gradient_boosting_init_with_sample_weight():\n    # Check that GradientBoostingRegressor works when init is a sklearn\n    # estimator and sample weights are provided.\n    X, y = make_regression()\n    sample_weight = np.random.RandomState(42).rand(100)\n\n    # init supports sample weights\n    init_est = DummyRegressor()\n    GradientBoostingRegressor(init=init_est).fit(X, y, sample_weight=sample_weight)\n\n    # init does not support sample weights\n    init_est = _NoSampleWeightWrapper(DummyRegressor())\n    with pytest.raises(ValueError,\n                       match=\"estimator.*does not support sample weights\"):\n        GradientBoostingRegressor(init=init_est).fit(X, y, sample_weight=sample_weight)\n"], "sample_965": ["def test_isabstractmethod():\n    class AbstractClass:\n        @abstractmethod\n            pass\n\n    class ConcreteClass(AbstractClass):\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(ConcreteClass.abstract_method) is False\n    assert inspect.isabstractmethod(AbstractClass) is False\n    assert inspect.isabstractmethod(ConcreteClass) is False\n"], "sample_189": ["    def test_cull(self):\n        cache.set('key1', 'value1')\n        cache.set('key2', 'value2')\n        self.assertEqual(cache.get('key1'), 'value1')\n        self.assertEqual(cache.get('key2'), 'value2')\n        cache.set('key3', 'value3')\n        self.assertIsNone(cache.get('key1'))\n        self.assertEqual(cache.get('key2'), 'value2')\n        self.assertEqual(cache.get('key3'), 'value3')\n"], "sample_752": ["def test_iforest_offset_calculation():\n    \"\"\"Test offset calculation for different contamination values.\"\"\"\n    X_train = np.array([[0, 1], [1, 2]])\n    X_test = np.array([[2, 1], [1, 1]])\n\n    contamination_values = [0.1, 0.2, 0.5, \"auto\"]\n    for contamination in contamination_values:\n        clf = IsolationForest(contamination=contamination, random_state=rng).fit(X_train)\n        if contamination == \"auto\":\n            assert_almost_equal(clf.offset_, -0.5)\n        else:\n            scores = clf.score_samples(X_train)\n            assert_almost_equal(clf.offset_, sp.stats.scoreatpercentile(scores, 100. * contamination))\n"], "sample_543": ["def test_rectangle_selector_rotation_point(ax):\n    tool = widgets.RectangleSelector(ax, onselect=noop, interactive=True)\n    tool.extents = (100, 150, 100, 150)\n    assert tool._selection_artist.rotation_point == 'center'\n    tool._selection_artist.rotation_point = 'upper left'\n    assert tool._selection_artist.rotation_point == 'upper left'\n    with pytest.raises(ValueError):\n        tool._selection_artist.rotation_point = 'unvalid_value'\n"], "sample_528": ["def test_use_list_of_styles(tmpdir):\n    mpl.rcParams[PARAM] = 'gray'\n    temp_file1 = f'text1.{STYLE_EXTENSION}'\n    temp_file2 = f'text2.{STYLE_EXTENSION}'\n    path1 = Path(tmpdir, temp_file1)\n    path2 = Path(tmpdir, temp_file2)\n    path1.write_text(f'{PARAM} : {VALUE}', encoding='utf-8')\n    path2.write_text(f'{PARAM} : blue', encoding='utf-8')\n    with style.context([path1, path2]):\n        assert mpl.rcParams[PARAM] == 'blue'\n    assert mpl.rcParams[PARAM] == 'gray'\n"], "sample_260": ["def test_create_model_alter_model_options(self):\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel('MyModel', fields=[]),\n            migrations.AlterModelOptions('MyModel', options={'verbose_name': 'My Model'}),\n            migrations.AlterModelOptions('MyModel', options={'verbose_name_plural': 'My Models'}),\n        ],\n        [\n            migrations.CreateModel('MyModel', fields=[], options={'verbose_name': 'My Model', 'verbose_name_plural': 'My Models'}),\n        ]\n    )\n"], "sample_860": ["def test_check_X_y_force_all_finite():\n    # Test that check_X_y raises an error when X or y contains NaN or inf\n    X = np.array([[1, 2], [np.nan, 3]])\n    y = np.array([1, 2])\n    with pytest.raises(ValueError, match=\"Input contains NaN, infinity\"):\n        check_X_y(X, y, force_all_finite=True)\n\n    X = np.array([[1, 2], [1, 3]])\n    y = np.array([1, np.inf])\n    with pytest.raises(ValueError, match=\"Input contains NaN, infinity\"):\n        check_X_y(X, y, force_all_finite=True)\n\n    X = np.array([[1, 2], [1, 3]])\n    y = np.array([1, np.nan])\n    with pytest.raises(ValueError, match=\"Input contains NaN, infinity\"):\n        check_X_y(X, y, force_all_finite=True)\n\n    # Test that check_X_y does not raise an error when X or y contains NaN but\n    # not inf when force_all_finite='allow-nan'\n    X = np.array([[1, 2], [np.nan, 3]])\n    y = np.array([1, 2])\n    check_X_y(X, y, force_all_finite='allow-nan')\n\n    X = np.array([[1, 2], [1, 3]])\n    y = np.array([1, np.nan])\n    check_X_y(X, y, force_all_finite='allow-nan')\n\n    # Test that check_X_y raises an error when X or y contains inf when\n    # force_all_finite='allow-nan'\n    X = np.array([[1, 2], [np.inf, 3]])\n    y = np.array([1, 2])\n    with pytest.raises(ValueError, match=\"Input contains infinity\"):\n        check_X_y(X, y, force_all_finite='allow-nan')\n\n    X = np.array([[1, 2], [1, 3]])\n    y = np.array([1, np.inf])\n    with pytest.raises(ValueError, match=\"Input contains infinity\"):\n        check_X_y(X, y, force_all_finite='allow-nan')\n"], "sample_1124": ["def test_FracElement___radd__():\n    F, x,y = field(\"x,y\", QQ)\n\n    f, g = 1/x, 1/y\n    assert 1 + f == f + 1 == 1 + 1/x\n    assert x + f == f + x == x + 1/x\n\n    F, x,y = field(\"x,y\", ZZ)\n    assert 3 + x == x + 3\n    assert QQ(3,7) + x == x + QQ(3,7) == (7*x + 3)/7\n\n    Fuv, u,v = field(\"u,v\", ZZ)\n    Fxyzt, x,y,z,t = field(\"x,y,z,t\", Fuv)\n\n    f = (u*v + x)/(y + u*v)\n    assert dict((u + 1) + f) == {(1, 0, 0, 0): 1, (0, 0, 0, 0): u*v + u + 1}\n    assert dict((u + 1) + f).keys() == {(0, 1, 0, 0), (0, 0, 0, 0)}\n\n    Ruv, u,v = ring(\"u,v\", ZZ)\n    Fxyzt, x,y,z,t = field(\"x,y,z,t\", Ruv)\n\n    f = (u*v + x)/(y + u*v)\n    assert dict((u + 1) + f) == {(1, 0, 0, 0): 1, (0, 0, 0, 0): u*v + u + 1}\n    assert dict((u + 1) + f).keys() == {(0, 1, 0, 0), (0, 0, 0, 0)}\n"], "sample_93": ["def test_window_function(self):\n    books = Book.objects.annotate(\n        avg_price=Window(Avg('price'), partition_by=F('publisher'))\n    ).order_by('publisher', 'price')\n    self.assertEqual(\n        [b.avg_price for b in books],\n        [\n            Decimal('30.00'), Decimal('30.00'), Decimal('30.00'), Decimal('30.00'),\n            Decimal('29.69'), Decimal('29.69'), Decimal('29.69'), Decimal('29.69'),\n            Decimal('82.80'), Decimal('82.80'), Decimal('82.80'), Decimal('82.80'),\n            Decimal('75.00'), Decimal('75.00'), Decimal('75.00'), Decimal('75.00'),\n            Decimal('23.09'), Decimal('23.09'), Decimal('23.09'), Decimal('23.09'),\n        ]\n    )\n\n    books = Book.objects.annotate(\n        avg_price=Window(Avg('price'), partition_by=F('publisher'), order_by=F('price').desc())\n    ).order_by('publisher', 'price')\n    self.assertEqual(\n        [b.avg_price for b in books],\n        [\n            Decimal('30.00'), Decimal('30.00'), Decimal('30.00'), Decimal('30.00'),\n            Decimal('29.69'), Decimal('29.69'), Decimal('29.69'), Decimal('29.69'),\n            Decimal('82.80'), Decimal('82.80'), Decimal('82.80'), Decimal('82.80'),\n            Decimal('75.00'), Decimal('75.00'), Decimal('75.00'), Decimal('75.00'),\n            Decimal('23.09'), Decimal('23.09'), Decimal('23.09'), Decimal('23.09'),\n        ]\n    )\n\n    books = Book.objects.annotate(\n        avg_price=Window(Avg('price'), partition_by=F('publisher'), order_by=F('price').desc(), frame='ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW')\n    ).order_by('publisher', 'price')\n    self.assertEqual(\n        [b.avg_price for b in books],\n        [\n            Decimal('30.00'), Decimal('30.00'), Decimal('30.00'), Decimal('30.00'),\n            Decimal('29.69'), Decimal('29.69'), Decimal('29.69'), Decimal('29.69'),\n            Decimal('82.80'), Decimal('82.80'), Decimal('82."], "sample_509": ["def test_date2num_timezone():\n    # Test date2num with timezone-aware datetime objects\n    tz = dateutil.tz.gettz('US/Eastern')\n    dt = datetime.datetime(2022, 1, 1, tzinfo=tz)\n    assert mdates.date2num(dt) == 19002.0\n\n    # Test date2num with timezone-naive datetime objects\n    dt = datetime.datetime(2022, 1, 1)\n    assert mdates.date2num(dt) == 19002.0\n\n    # Test date2num with timezone-aware numpy datetime64 objects\n    dt = np.datetime64('2022-01-01', 'ns', 'US/Eastern')\n    assert mdates.date2num(dt) == 19002.0\n\n    # Test date2num with timezone-naive numpy datetime64 objects\n    dt = np.datetime64('2022-01-01', 'ns')\n    assert mdates.date2num(dt) == 19002.0\n"], "sample_687": ["def test_log_capture_handler_reset(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n\n            logger = logging.getLogger('catchlog')\n            logger.info('INFO message 1')\n            assert len(caplog.records) == 1\n            caplog.handler.reset()\n            logger.info('INFO message 2')\n            assert len(caplog.records) == 1\n            assert caplog.records[0].message == 'INFO message 2'\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 0\n"], "sample_494": ["def test_serialize_settings_reference(self):\n    self.assertSerializedResultEqual(\n        SettingsReference(\"AUTH_USER_MODEL\", \"AUTH_USER_MODEL\"),\n        (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"}),\n    )\n    self.assertSerializedResultEqual(\n        SettingsReference(\"someapp.model\", \"AUTH_USER_MODEL\"),\n        (\"settings.AUTH_USER_MODEL\", {\"from django.conf import settings\"}),\n    )\n    self.assertSerializedResultEqual(\n        SettingsReference(\"someapp.model\", \"NON_EXISTENT_SETTING\"),\n        (\"settings.NON_EXISTENT_SETTING\", {\"from django.conf import settings\"}),\n    )\n"], "sample_699": ["def test_doctest_report_choice_invalid_value(pytester: Pytester):\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        doctestreport = invalid_value\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--doctest-modules\")\n    result.stderr.fnmatch_lines(\n        [\n            \"*error: option --doctest-report: invalid choice: 'invalid_value' (choose from 'none', 'cdiff', 'ndiff', 'udiff', 'only_first_failure')*\"\n        ]\n    )\n"], "sample_110": ["    def test_expression_pickle(self):\n        expression = Expression()\n        dumped = pickle.dumps(expression)\n        reloaded = pickle.loads(dumped)\n        self.assertEqual(expression.__dict__, reloaded.__dict__)\n"], "sample_834": ["def test_transform_after_warm_start():\n    # Test that transform works correctly after warm start\n    X = iris_data\n    y = iris_target\n\n    nca = NeighborhoodComponentsAnalysis(warm_start=True, max_iter=5)\n    nca.fit(X, y)\n    X_t = nca.transform(X)\n\n    nca.max_iter = 1\n    nca.fit(X, y)\n    X_t_warm = nca.transform(X)\n\n    assert_array_almost_equal(X_t, X_t_warm)\n"], "sample_256": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = '!'\n        html = widget.render('name', value, {'id': 'id_password'})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_1178": ["def test_Element():\n    elem = Element(x, 'ijk')\n    assert elem.symbol == x\n    assert elem.indices == Tuple('i', 'j', 'k')\n    assert elem.strides == none\n    assert elem.offset == none\n    assert elem.func(*elem.args) == elem\n    assert str(elem) == 'Element(x, indices=(\"i\", \"j\", \"k\"), strides=None, offset=None)'\n\n    elem2 = Element(x, 'ijk', strides='lmn', offset='o')\n    assert elem2.indices == Tuple('i', 'j', 'k')\n    assert elem2.strides == Tuple('l', 'm', 'n')\n    assert elem2.offset == 'o'\n    assert elem2.func(*elem2.args) == elem2\n    assert str(elem2) == 'Element(x, indices=(\"i\", \"j\", \"k\"), strides=(\"l\", \"m\", \"n\"), offset=\"o\")'\n\n    elem3 = Element(x, (i, j, k))\n    assert elem3.indices == Tuple(i, j, k)\n    assert elem3.strides == none\n    assert elem3.offset == none\n    assert elem3.func(*elem3.args) == elem3\n    assert str(elem3) == 'Element(x, indices=(i, j, k), strides=None, offset=None)'\n"], "sample_473": ["compilation error"], "sample_33": ["def test_IncompatibleShapeError():\n    try:\n        raise misc.IncompatibleShapeError((10, 2), 1, (3,), 0)\n    except misc.IncompatibleShapeError as e:\n        assert e.args == ((10, 2), 1, (3,), 0)\n"], "sample_361": ["def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            'Search for google.com/?q=! and see.',\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>! and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt! and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>! and see.'\n        ),\n        (\n            'Search for google.com/?q=! and see,',\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>! and see,'\n        ),\n        (\n            'Search for google.com/?q=! and see.',\n            'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>! and see.'\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_837": ["def test_get_blas_info():\n    try:\n        blas_info = _get_blas_info()\n        assert 'macros' in blas_info\n        assert 'lib_dirs' in blas_info\n        assert 'cblas_libs' in blas_info\n    except ImportError:\n        # If scikit-learn is not installed, _get_blas_info will raise an ImportError\n        pass\n"], "sample_392": ["    def test_custom_encoder_decoder(self):\n        value = {\"uuid\": uuid.UUID(\"{d85e2076-b67c-4ee7-8c3a-2bf5a2cc2475}\")}\n        obj = NullableJSONModel.objects.create(value_custom=value)\n        obj.refresh_from_db()\n        self.assertEqual(obj.value_custom, value)\n"], "sample_54": ["def test_file_from_disk_with_filename(self):\n    filename = \"test_file.txt\"\n    response = FileResponse(open(__file__, 'rb'), filename=filename)\n    self.assertEqual(response['Content-Length'], str(os.path.getsize(__file__)))\n    self.assertIn(response['Content-Type'], ['text/x-python', 'text/plain'])\n    self.assertEqual(response['Content-Disposition'], f'inline; filename=\"{filename}\"')\n    response.close()\n"], "sample_552": ["def test_subfigure_subplotspec():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    subfig = fig.add_subfigure(gs[0, 0])\n    assert subfig._subplotspec == gs[0, 0]\n    assert subfig._subplotspec.get_gridspec() == gs\n    subfig._redo_transform_rel_fig(gs[0, 0].get_position(fig))\n    np.testing.assert_allclose(subfig.bbox_relative.p0, (0, 0.5))\n    np.testing.assert_allclose(subfig.bbox_relative.p1, (0.5, 1))\n"], "sample_1139": ["def test_ComplexRegion_polar_intersect():\n    # Polar form\n    c1 = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)\n    c2 = ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    c3 = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi), polar=True)\n    c4 = ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n\n    p1 = Union(Interval(0, 1)*Interval(0, 2*S.Pi), Interval(0, 1)*Interval(0, S.Pi))\n    p2 = Union(Interval(0, oo)*Interval(0, S.Pi), Interval(0, oo)*Interval(S.Pi, 2*S.Pi))\n\n    assert c1.intersect(c2) == ComplexRegion(p1, polar=True)\n    assert c3.intersect(c4) == ComplexRegion(p2, polar=True)\n\n    # Rectangular form\n    c5 = ComplexRegion(Interval(2, 5)*Interval(6, 9))\n    c6 = ComplexRegion(Interval(4, 6)*Interval(10, 12))\n    c7 = ComplexRegion(Interval(0, 10)*Interval(-10, 0))\n    c8 = ComplexRegion(Interval(12, 16)*Interval(14, 20))\n\n    p3 = Union(Interval(2, 5)*Interval(6, 9), Interval(4, 6)*Interval(10, 12))\n    p4 = Union(Interval(0, 10)*Interval(-10, 0), Interval(12, 16)*Interval(14, 20))\n\n    assert c5.intersect(c6) == ComplexRegion(p3)\n    assert c7.intersect(c8) == ComplexRegion(p4)\n\n    assert c1.intersect(Interval(2, 4)) == Intersection(c1, Interval(2, 4), evaluate=False)\n    assert c5.intersect(Interval(2, 4)) == Intersection(c5, ComplexRegion.from_real(Interval(2, 4)))\n"], "sample_870": ["def test_gpr_predict_input_not_modified_cov():\n    \"\"\"\n    Check that the input X is not modified by the predict method of the\n    GaussianProcessRegressor when setting return_cov=True.\n\n    Non-regression test for:\n    https://github.com/scikit-learn/scikit-learn/issues/24340\n    \"\"\"\n    gpr = GaussianProcessRegressor(kernel=CustomKernel()).fit(X, y)\n\n    X2_copy = np.copy(X2)\n    _, _ = gpr.predict(X2, return_cov=True)\n\n    assert_allclose(X2, X2_copy)\n"], "sample_1021": ["def test_quaternion_edge_cases():\n    q1 = Quaternion(0, 0, 0, 0)\n    q2 = Quaternion(1, 0, 0, 0)\n    q3 = Quaternion(0, 1, 0, 0)\n    q4 = Quaternion(0, 0, 1, 0)\n    q5 = Quaternion(0, 0, 0, 1)\n\n    assert q1.norm() == 0\n    assert q2.norm() == 1\n    assert q3.norm() == 1\n    assert q4.norm() == 1\n    assert q5.norm() == 1\n\n    assert q1.normalize() == Quaternion(0, 0, 0, 0)\n    assert q2.normalize() == Quaternion(1, 0, 0, 0)\n    assert q3.normalize() == Quaternion(0, 1, 0, 0)\n    assert q4.normalize() == Quaternion(0, 0, 1, 0)\n    assert q5.normalize() == Quaternion(0, 0, 0, 1)\n\n    assert q1.inverse() == Quaternion(0, 0, 0, 0)\n    raises(ValueError, lambda: q1.inverse())\n\n    assert q2.pow(0) == Quaternion(1, 0, 0, 0)\n    assert q2.pow(1) == Quaternion(1, 0, 0, 0)\n    assert q2.pow(-1) == Quaternion(1, 0, 0, 0)\n\n    assert q2.exp() == Quaternion(E, 0, 0, 0)\n    assert q2._ln() == Quaternion(0, 0, 0, 0)\n\n    assert q2.pow_cos_sin(0) == Quaternion(1, 0, 0, 0)\n    assert q2.pow_cos_sin(1) == Quaternion(1, 0, 0, 0)\n    assert q2.pow_cos_sin(-1) == Quaternion(1, 0, 0, 0)\n\n    assert Quaternion.rotate_point((0, 0, 0), q2) == (0, 0, 0)\n    assert Quaternion.rotate_point((1, 1, 1), q2) == (1, 1, 1)\n\n    assert q2.to"], "sample_862": ["def test_vectorizer_stop_words_consistency():\n    # Test that stop words are consistent with the preprocessor and tokenizer\n    # when the analyzer is 'word'\n    vect = CountVectorizer(stop_words=['and'])\n    assert _check_stop_words_consistency(vect) is True\n\n    # Test that stop words are inconsistent with the preprocessor and tokenizer\n    # when the analyzer is 'word'\n    vect = CountVectorizer(stop_words=['and'], preprocessor=lambda x: x.upper())\n    assert _check_stop_words_consistency(vect) is False\n\n    # Test that stop words are consistent with the preprocessor and tokenizer\n    # when the analyzer is not 'word'\n    vect = CountVectorizer(stop_words=['and'], analyzer='char')\n    assert _check_stop_words_consistency(vect) is None\n\n    # Test that stop words are consistent with the preprocessor and tokenizer\n    # when the analyzer is a callable\n    vect = CountVectorizer(stop_words=['and'], analyzer=lambda x: x.split())\n    assert _check_stop_words_consistency(vect) is None\n"], "sample_1080": ["def test_refine_issue_12724_edge_cases():\n    # Test edge cases for refine with Abs and Mul\n    assert refine(Abs(x * 0), Q.positive(x)) == 0\n    assert refine(Abs(0 * y), Q.positive(y)) == 0\n    assert refine(Abs(x * 1), Q.positive(x)) == x\n    assert refine(Abs(1 * y), Q.positive(y)) == y\n    assert refine(Abs(x * -1), Q.positive(x)) == -x\n    assert refine(Abs(-1 * y), Q.positive(y)) == -y\n    assert refine(Abs(x * -y), Q.positive(x) & Q.positive(y)) == -x*y\n    assert refine(Abs(x * -y), Q.positive(x) & Q.negative(y)) == x*y\n    assert refine(Abs(x * -y), Q.negative(x) & Q.positive(y)) == x*y\n    assert refine(Abs(x * -y), Q.negative(x) & Q.negative(y)) == -x*y\n"], "sample_868": ["def test_empty_input(metric_name, y1, y2):\n    metric = SUPERVISED_METRICS[metric_name]\n    with pytest.raises(ValueError, match='Input arrays should not be empty'):\n        metric([], [])\n\n    with pytest.raises(ValueError, match='Input arrays should not be empty'):\n        metric(y1, [])\n\n    with pytest.raises(ValueError, match='Input arrays should not be empty'):\n        metric([], y2)\n"], "sample_516": ["def test_pdf_metadata_decimal():\n    pikepdf = pytest.importorskip('pikepdf')\n\n    fig, ax = plt.subplots()\n\n    md = {\n        'Author': 'me',\n        'Title': 'Multipage PDF',\n        'Subject': 'Test page',\n        'Keywords': 'test,pdf,multipage',\n        'ModDate': decimal.Decimal('1968.08.01'),\n        'Trapped': 'True'\n    }\n    buf = io.BytesIO()\n    fig.savefig(buf, metadata=md, format='pdf')\n\n    with pikepdf.Pdf.open(buf) as pdf:\n        info = {k: str(v) for k, v in pdf.docinfo.items()}\n\n    assert info == {\n        '/Author': 'me',\n        '/CreationDate': 'D:19700101000000Z',\n        '/Creator': f'Matplotlib v{mpl.__version__}, https://matplotlib.org',\n        '/Keywords': 'test,pdf,multipage',\n        '/ModDate': 'D:19680801000000Z',\n        '/Producer': f'Matplotlib pdf backend v{mpl.__version__}',\n        '/Subject': 'Test page',\n        '/Title': 'Multipage PDF',\n        '/Trapped': '/True',\n    }\n"], "sample_757": ["def test_ordinal_encoder_unsorted_categories():\n    X = np.array([['a', 'b']], dtype=object).T\n\n    enc = OrdinalEncoder(categories=[['b', 'a', 'c']])\n    exp = np.array([[1.], [0.]])\n    assert_array_equal(enc.fit(X).transform(X), exp)\n    assert_array_equal(enc.fit_transform(X), exp)\n    assert enc.categories_[0].tolist() == ['b', 'a', 'c']\n    assert np.issubdtype(enc.categories_[0].dtype, np.object_)\n\n    # unsorted passed categories still raise for numerical values\n    X = np.array([[1, 2]]).T\n    enc = OrdinalEncoder(categories=[[2, 1, 3]])\n    msg = 'Unsorted categories are not supported'\n    with pytest.raises(ValueError, match=msg):\n        enc.fit_transform(X)\n"], "sample_816": ["def test_vectorizer_stop_words_inconsistent_custom_tokenizer():\n    lstr = \"['and', 'll', 've']\"\n    message = ('Your stop_words may be inconsistent with your '\n               'preprocessing. Tokenizing the stop words generated '\n               'tokens %s not in stop_words.' % lstr)\n    for vec in [CountVectorizer(),\n                TfidfVectorizer(), HashingVectorizer()]:\n        vec.set_params(stop_words=[\"you've\", \"you\", \"you'll\", 'AND'],\n                       tokenizer=lambda doc: doc.split())\n        assert_warns_message(UserWarning, message, vec.fit_transform,\n                             ['hello world'])\n        # reset stop word validation\n        del vec._stop_words_id\n        assert _check_stop_words_consistency(vec) is False\n\n    # Only one warning per stop list\n    assert_no_warnings(vec.fit_transform, ['hello world'])\n    assert _check_stop_words_consistency(vec) is None\n\n    # Test caching of inconsistency assessment\n    vec.set_params(stop_words=[\"you've\", \"you\", \"you'll\", 'blah', 'AND'])\n    assert_warns_message(UserWarning, message, vec.fit_transform,\n                         ['hello world'])\n"], "sample_1008": ["def test_orient():\n    q1, q2, q3 = dynamicsymbols('q1 q2 q3')\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    B = ReferenceFrame('B')\n\n    A.orient(N, 'Body', [q1, q2, q3], '123')\n    assert A.dcm(N) == N.dcm(A).T\n\n    B.orient(N, 'Space', [q1, q2, q3], '123')\n    assert B.dcm(N) == N.dcm(B).T\n\n    A.orient(N, 'Quaternion', [cos(q1/2), sin(q1/2), 0, 0])\n    assert A.dcm(N) == N.dcm(A).T\n\n    A.orient(N, 'Axis', [q1, N.x])\n    assert A.dcm(N) == N.dcm(A).T\n\n    A.orient(N, 'DCM', Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))\n    assert A.dcm(N) == N.dcm(A).T\n"], "sample_84": ["    def test_fields_limit(self):\n        with self.assertRaises(TooManyFieldsSent):\n            limited_parse_qsl('a=1&b=2&c=3', fields_limit=2)\n"], "sample_1134": ["def test_latex_tensor_indices():\n    from sympy.tensor.tensor import TensorIndexType, tensor_indices, TensorHead, tensor_heads\n    L = TensorIndexType(\"L\")\n    i, j, k, l = tensor_indices(\"i j k l\", L)\n    i0 = tensor_indices(\"i_0\", L)\n    A, B, C, D = tensor_heads(\"A B C D\", [L])\n    H = TensorHead(\"H\", [L, L])\n    K = TensorHead(\"K\", [L, L, L, L])\n\n    assert latex(i) == \"{}^{i}\"\n    assert latex(-i) == \"{}_{i}\"\n\n    expr = A(i)\n    assert latex(expr) == \"A{}^{i}\"\n\n    expr = A(i0)\n    assert latex(expr) == \"A{}^{i_{0}}\"\n\n    expr = A(-i)\n    assert latex(expr) == \"A{}_{i}\"\n\n    expr = -3*A(i)\n    assert latex(expr) == r\"-3A{}^{i}\"\n\n    expr = K(i, j, -k, -i0)\n    assert latex(expr) == \"K{}^{ij}{}_{ki_{0}}\"\n\n    expr = K(i, -j, -k, i0)\n    assert latex(expr) == \"K{}^{i}{}_{jk}{}^{i_{0}}\"\n\n    expr = K(i, -j, k, -i0)\n    assert latex(expr) == \"K{}^{i}{}_{j}{}^{k}{}_{i_{0}}\"\n\n    expr = H(i, -j)\n    assert latex(expr) == \"H{}^{i}{}_{j}\"\n\n    expr = H(i, j)\n    assert latex(expr) == \"H{}^{ij}\"\n\n    expr = H(-i, -j)\n    assert latex(expr) == \"H{}_{ij}\"\n\n    expr = (1+x)*A(i)\n    assert latex(expr) == r\"\\left(x + 1\\right)A{}^{i}\"\n\n    expr = H(i, -i)\n    assert latex(expr) == \"H{}^{L_{0}}{}_{L_{0}}\"\n\n    expr = H(i, -j)*A(j)*B(k)\n    assert latex(expr) == \"H{}^{i}{}_{L_{0}}A{}^{L_{0}}B{}^{k}\"\n\n    expr"], "sample_720": ["def test_power_transformer_copy():\n    X = np.abs(X_2d)\n\n    pt = PowerTransformer(method='box-cox', copy=True)\n    X_trans = pt.fit_transform(X)\n    assert_true(X_trans is not X)\n\n    pt = PowerTransformer(method='box-cox', copy=False)\n    X_trans = pt.fit_transform(X)\n    assert_true(X_trans is X)\n"], "sample_255": ["    def test_cleanup_headers(self):\n        \"\"\"ServerHandler sets 'Connection: close' when necessary.\"\"\"\n        request = WSGIRequest({'CONTENT_LENGTH': '10'})\n        handler = ServerHandler(None, None, None, request.environ)\n        handler.headers = {}\n        handler.cleanup_headers()\n        self.assertEqual(handler.headers['Connection'], 'close')\n"], "sample_730": ["def test_enet_path_with_sparse_X():\n    # Test that enet_path with sparse X gives the same result as with dense X\n    X, y, _, _ = build_dataset(n_samples=50, n_features=20)\n    X_sparse = sparse.csr_matrix(X)\n    alphas, coefs, _ = enet_path(X, y, fit_intercept=False)\n    alphas_sparse, coefs_sparse, _ = enet_path(X_sparse, y, fit_intercept=False)\n    assert_array_almost_equal(coefs, coefs_sparse)\n"], "sample_24": ["    def setup_class(self):\n        self.a = np.array([[1.0, 2.0], [3.0, 4.0]])\n        self.mask_a = np.array([[False, True], [False, False]])\n        self.ma = Masked(self.a, mask=self.mask_a)\n        self.b = np.array([5.0, 6.0])\n        self.mask_b = np.array([False, True])\n        self.mb = Masked(self.b, mask=self.mask_b)\n"], "sample_704": ["def test_node_repr_failure_with_conftest_import_failure(pytester: Pytester) -> None:\n    \"\"\"Test that repr_failure handles ConftestImportFailure correctly.\"\"\"\n    p = pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        pytest_plugins = ['non_existent_plugin']\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*ConftestImportFailure*\"])\n    result.stdout.fnmatch_lines([\"*ModuleNotFoundError: No module named 'non_existent_plugin'*\"])\n"], "sample_1070": ["def test_exp_polar():\n    x, y = symbols('x y', polar=True)\n    assert exp_polar(x).is_polar\n    assert exp_polar(x).is_comparable is False\n    assert exp_polar(x).is_real is None\n    assert exp_polar(x).is_imaginary is None\n    assert exp_polar(y).is_real is None\n    assert exp_polar(y).is_imaginary is None\n    assert exp_polar(0).is_real is True\n    assert exp_polar(0).is_imaginary is False\n    assert exp_polar(1).is_real is True\n    assert exp_polar(1).is_imaginary is False\n    assert exp_polar(I).is_real is False\n    assert exp_polar(I).is_imaginary is True\n    assert exp_polar(-I).is_real is False\n    assert exp_polar(-I).is_imaginary is True\n    assert exp_polar(2*I).is_real is True\n    assert exp_polar(2*I).is_imaginary is False\n    assert exp_polar(-2*I).is_real is True\n    assert exp_polar(-2*I).is_imaginary is False\n    assert exp_polar(pi*I).is_real is False\n    assert exp_polar(pi*I).is_imaginary is True\n    assert exp_polar(-pi*I).is_real is False\n    assert exp_polar(-pi*I).is_imaginary is True\n    assert exp_polar(2*pi*I).is_real is True\n    assert exp_polar(2*pi*I).is_imaginary is False\n    assert exp_polar(-2*pi*I).is_real is True\n    assert exp_polar(-2*pi*I).is_imaginary is False\n    assert exp_polar(3*pi*I).is_real is False\n    assert exp_polar(3*pi*I).is_imaginary is True\n    assert exp_polar(-3*pi*I).is_real is False\n    assert exp_polar(-3*pi*I).is_imaginary is True\n    assert exp_polar(4*pi*I).is_real is True\n    assert exp_polar(4*pi*I).is_imaginary is False\n    assert exp_polar(-4*pi*I).is_real is True\n    assert exp_polar(-4*pi*I).is_imaginary is False\n    assert exp_polar(5*pi*I)."], "sample_257": ["    def test_key_transform_factory(self):\n        field = models.JSONField()\n        transform = field.get_transform('key')\n        self.assertIsInstance(transform, KeyTransformFactory)\n        self.assertEqual(transform.key_name, 'key')\n"], "sample_41": ["def test_compose_with_dimensionless():\n    \"\"\"\n    Test that composing a unit with a dimensionless unit does not change\n    the unit.\n\n    Regression test for https://github.com/astropy/astropy/issues/8261\n    \"\"\"\n    unit = u.m\n    dimensionless_unit = u.dimensionless_unscaled\n    composed = unit.compose(units=[dimensionless_unit])\n    assert len(composed) == 1\n    assert composed[0] is unit\n"], "sample_129": ["    def test_addslashes01(self):\n        output = self.engine.render_to_string('addslashes01', {\"a\": \"Hello 'World' \\\"Django\\\"\"})\n        self.assertEqual(output, \"Hello \\\\'World\\' \\\"Django\\\"\")\n"], "sample_244": ["def test_formset_with_deletion_and_min_num(self):\n    \"\"\"\n    FormSets with deletion and min_num.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_delete=True, min_num=2)\n    initial = [{'choice': 'Calexico', 'votes': 100}, {'choice': 'Fergie', 'votes': 900}]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_48": ["def test_stddev_pop_and_samp(self):\n    # Test StdDev with sample=True and sample=False\n    vals = Book.objects.aggregate(stddev_pop=StdDev('price', sample=False), stddev_samp=StdDev('price', sample=True))\n    self.assertIsInstance(vals['stddev_pop'], Decimal)\n    self.assertIsInstance(vals['stddev_samp'], Decimal)\n    self.assertLessEqual(vals['stddev_samp'], vals['stddev_pop'])\n\n    # Test StdDev with distinct=True\n    vals = Book.objects.aggregate(stddev_distinct=StdDev('price', distinct=True))\n    self.assertIsInstance(vals['stddev_distinct'], Decimal)\n\n    # Test StdDev with filter\n    vals = Book.objects.filter(price__gt=Decimal('30')).aggregate(stddev_filtered=StdDev('price'))\n    self.assertIsInstance(vals['stddev_filtered'], Decimal)\n\n    # Test StdDev with annotation\n    books = Book.objects.annotate(stddev_price=StdDev('price'))\n    self.assertIsInstance(books.first().stddev_price, Decimal)\n"], "sample_371": ["    def test_get_traceback_frames_with_cyclic_reference_in_exception_chain(self):\n        \"\"\"\n        Test that ExceptionReporter.get_traceback_frames() handles cyclic references\n        in the exception chain.\n        \"\"\"\n        try:\n            try:\n                raise RuntimeError('outer') from RuntimeError('inner')\n            except RuntimeError as exc:\n                exc.__cause__ = exc\n                raise\n        except Exception:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(None, exc_type, exc_value, tb)\n        frames = reporter.get_traceback_frames()\n        self.assertEqual(len(frames), 2)\n        self.assertEqual(frames[0]['exc_cause'], frames[1]['tb'])\n        self.assertEqual(frames[1]['exc_cause'], frames[0]['tb'])\n"], "sample_1113": ["def test_block_collapse():\n    n, m, l = symbols('n m l')\n    X = MatrixSymbol('X', n, n)\n    Y = MatrixSymbol('Y', m, m)\n    Z = MatrixSymbol('Z', n, m)\n    B = BlockMatrix([[X, Z], [ZeroMatrix(m, n), Y]])\n    C = BlockMatrix([[Identity(n), Z]])\n    assert block_collapse(C*B) == BlockMatrix([[X, Z + Z*Y]])\n    assert block_collapse(B*C) == BlockMatrix([[X + Z*Y, Z]])\n    assert block_collapse(B*C*B) == BlockMatrix([[X + Z*Y, Z + Z*Y*Y], [Y*Z, Y*Z*Y + Y]])\n"], "sample_624": ["def test_unindexed_dims_repr() -> None:\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3])}\n    expected = \"Dimensions without coordinates: y, z\"\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3]), \"y\": np.array([4, 5, 6])}\n    expected = \"Dimensions without coordinates: z\"\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3]), \"y\": np.array([4, 5, 6]), \"z\": np.array([7, 8, 9])}\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual is None\n"], "sample_9": ["def test_html_writer_css():\n    \"\"\"\n    Test to make sure that the HTML writer includes CSS styling\n    if the 'css' parameter is present in the htmldict.\n    \"\"\"\n\n    col1 = [1, 2, 3]\n    col2 = [(1.0, 1.0), (2.0, 2.0), (3.0, 3.0)]\n    col3 = [('a', 'a', 'a'), ('b', 'b', 'b'), ('c', 'c', 'c')]\n    table = Table([col1, col2, col3], names=('C1', 'C2', 'C3'))\n    expected = \"\"\"\\"], "sample_217": ["def test_multiwidget_media(self):\n    class MyWidget1(TextInput):\n        class Media:\n            css = {\n                'all': ('path/to/css1', '/path/to/css2')\n            }\n            js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')\n\n    class MyWidget2(TextInput):\n        class Media:\n            css = {\n                'all': ('/path/to/css2', '/path/to/css3')\n            }\n            js = ('/path/to/js1', '/path/to/js4')\n\n    class MyWidget3(TextInput):\n        class Media:\n            css = {\n                'all': ('path/to/css1', '/path/to/css3')\n            }\n            js = ('/path/to/js1', '/path/to/js4')\n\n    class MyMultiWidget(MultiWidget):\n            widgets = [MyWidget1, MyWidget2, MyWidget3]\n            super().__init__(widgets, attrs)\n\n    mymulti = MyMultiWidget()\n    self.assertEqual(\n        str(mymulti.media),\n        \"\"\"<link href=\"http://media.example.com/static/path/to/css1\" type=\"text/css\" media=\"all\" rel=\"stylesheet\">"], "sample_176": ["def test_alter_field_to_fk_dependency_same_app(self):\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author_fk],\n        [self.author_empty, self.book],\n    )\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '__first__')])\n"], "sample_380": ["def test_aggregate_with_empty_result_set_value(self):\n    \"\"\"\n    Test that aggregates with empty_result_set_value return that value when\n    the result set is empty.\n    \"\"\"\n    result = Author.objects.filter(age__gt=100).aggregate(Count('age'))\n    self.assertEqual(result['age__count'], 0)\n\n    result = Author.objects.filter(age__gt=100).aggregate(Sum('age'))\n    self.assertIsNone(result['age__sum'])\n\n    result = Author.objects.filter(age__gt=100).aggregate(Avg('age'))\n    self.assertIsNone(result['age__avg'])\n\n    result = Author.objects.filter(age__gt=100).aggregate(Max('age'))\n    self.assertIsNone(result['age__max'])\n\n    result = Author.objects.filter(age__gt=100).aggregate(Min('age'))\n    self.assertIsNone(result['age__min'])\n\n    result = Author.objects.filter(age__gt=100).aggregate(StdDev('age'))\n    self.assertIsNone(result['age__stddev'])\n\n    result = Author.objects.filter(age__gt=100).aggregate(Variance('age'))\n    self.assertIsNone(result['age__variance'])\n"], "sample_551": ["def test_patch_2d_to_3d():\n    # Test conversion of 2D patch to 3D patch\n    from matplotlib.patches import Circle\n    fig, ax = plt.subplots(subplot_kw=dict(projection='3d'))\n    patch = Circle((0, 0), 1, label=\"circle\")\n    art3d.patch_2d_to_3d(patch, z=1, zdir='z')\n    ax.add_patch(patch)\n    leg = ax.legend()\n    assert leg.legend_handles[0].get_label() == \"circle\"\n    assert leg.legend_handles[0].get_z() == 1\n"], "sample_223": ["    def test_ticket_24605(self):\n        \"\"\"\n        Subquery table names should be quoted.\n        \"\"\"\n        i1 = Individual.objects.create(alive=True)\n        RelatedIndividual.objects.create(related=i1)\n        i2 = Individual.objects.create(alive=False)\n        RelatedIndividual.objects.create(related=i2)\n        i3 = Individual.objects.create(alive=True)\n        i4 = Individual.objects.create(alive=False)\n\n        self.assertSequenceEqual(Individual.objects.filter(Q(alive=False), Q(related_individual__isnull=True)), [i4])\n        self.assertSequenceEqual(\n            Individual.objects.exclude(Q(alive=False), Q(related_individual__isnull=True)).order_by('pk'),\n            [i1, i2, i3]\n        )\n"], "sample_155": ["def test_file_from_disk_with_filename(self):\n    filename = \"test_file.txt\"\n    response = FileResponse(open(__file__, 'rb'), filename=filename)\n    self.assertEqual(response['Content-Length'], str(os.path.getsize(__file__)))\n    self.assertIn(response['Content-Type'], ['text/x-python', 'text/plain'])\n    self.assertEqual(response['Content-Disposition'], f'inline; filename=\"{filename}\"')\n    response.close()\n"], "sample_545": ["def test_subfigure_subplotspec():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    subfig = fig.add_subfigure(gs[0, 0])\n    assert subfig._subplotspec == gs[0, 0]\n    assert subfig._subplotspec.get_gridspec() == gs\n"], "sample_199": ["def test_annotation_with_window_function(self):\n    books = Book.objects.annotate(\n        rank=Window(\n            expression=RowNumber(),\n            partition_by=F('publisher'),\n            order_by=F('rating').desc(),\n        )\n    ).order_by('publisher', '-rating')\n    prev_rank = 0\n    prev_publisher = None\n    for book in books:\n        if book.publisher != prev_publisher:\n            self.assertEqual(book.rank, 1)\n            prev_rank = 1\n            prev_publisher = book.publisher\n        else:\n            self.assertEqual(book.rank, prev_rank + 1)\n            prev_rank += 1\n"], "sample_740": ["def test_check_X_y_force_all_finite_valid():\n    # Test that check_X_y correctly handles force_all_finite\n    X = np.arange(4).reshape(2, 2).astype(np.float)\n    X[0, 0] = np.nan\n    y = np.array([1, 2])\n    X_checked, y_checked = check_X_y(X, y, force_all_finite='allow-nan',\n                                     accept_sparse=True)\n    assert_allclose_dense_sparse(X, X_checked)\n    assert_array_equal(y, y_checked)\n\n    X[0, 0] = np.inf\n    with pytest.raises(ValueError):\n        check_X_y(X, y, force_all_finite='allow-nan', accept_sparse=True)\n\n    X[0, 0] = np.nan\n    X_checked, y_checked = check_X_y(X, y, force_all_finite=False,\n                                     accept_sparse=True)\n    assert_allclose_dense_sparse(X, X_checked)\n    assert_array_equal(y, y_checked)\n\n    X[0, 0] = np.inf\n    X_checked, y_checked = check_X_y(X, y, force_all_finite=False,\n                                     accept_sparse=True)\n    assert_allclose_dense_sparse(X, X_checked)\n    assert_array_equal(y, y_checked)\n"], "sample_424": ["def test_alter_model_table_with_db_table_prefix(self):\n    \"\"\"\n    Tests the AlterModelTable operation with a db_table prefix.\n    \"\"\"\n    project_state = self.set_up_test_model(\"test_almotap\")\n    # Test the state alteration\n    operation = migrations.AlterModelTable(\"Pony\", \"pony_table\")\n    self.assertEqual(operation.describe(), \"Rename table for Pony to pony_table\")\n    self.assertEqual(operation.migration_name_fragment, \"alter_pony_table\")\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_almotap\", new_state)\n    self.assertEqual(\n        new_state.models[\"test_almotap\", \"pony\"].options[\"db_table\"],\n        \"test_almotap_pony_table\",\n    )\n    # Test the database alteration\n    self.assertTableExists(\"test_almotap_pony\")\n    self.assertTableNotExists(\"test_almotap_pony_table\")\n    with connection.schema_editor() as editor:\n        operation.database_forwards(\"test_almotap\", editor, project_state, new_state)\n    self.assertTableNotExists(\"test_almotap_pony\")\n    self.assertTableExists(\"test_almotap_pony_table\")\n    # And test reversal\n    with connection.schema_editor() as editor:\n        operation.database_backwards(\n            \"test_almotap\", editor, new_state, project_state\n        )\n    self.assertTableExists(\"test_almotap_pony\")\n    self.assertTableNotExists(\"test_almotap_pony_table\")\n    # And deconstruction\n    definition = operation.deconstruct()\n    self.assertEqual(definition[0], \"AlterModelTable\")\n    self.assertEqual(definition[1], [])\n    self.assertEqual(definition[2], {\"name\": \"Pony\", \"table\": \"pony_table\"})\n"], "sample_875": ["def test_jaccard_score_multilabel_average_samples():\n    # Test jaccard_score with multilabel-indicator format and average='samples'\n    y_true = np.array([[0, 1, 1], [1, 0, 1]])\n    y_pred = np.array([[0, 1, 0], [1, 0, 1]])\n    assert jaccard_score(y_true, y_pred, average='samples') == 0.75\n    assert jaccard_score(y_true, y_true, average='samples') == 1\n    assert jaccard_score(y_pred, y_pred, average='samples') == 1\n    assert jaccard_score(y_pred, np.logical_not(y_pred), average='samples') == 0\n    assert jaccard_score(y_true, np.logical_not(y_true), average='samples') == 0\n    assert jaccard_score(y_true, np.zeros(y_true.shape), average='samples') == 0\n    assert jaccard_score(y_pred, np.zeros(y_true.shape), average='samples') == 0\n"], "sample_1054": ["def test_ComplexRegion_polar_intersect():\n    # Polar form\n    unit_disk = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)\n    upper_half_unit_disk = ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)\n    upper_half_disk = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi), polar=True)\n    lower_half_disk = ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)\n    right_half_disk = ComplexRegion(Interval(0, oo)*Interval(-S.Pi/2, S.Pi/2), polar=True)\n    first_quad_disk = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi/2), polar=True)\n\n    assert upper_half_disk.intersect(unit_disk) == upper_half_unit_disk\n    assert right_half_disk.intersect(first_quad_disk) == first_quad_disk\n    assert upper_half_disk.intersect(right_half_disk) == first_quad_disk\n    assert upper_half_disk.intersect(lower_half_disk) == ComplexRegion(Interval(0, oo)*FiniteSet(0, S.Pi), polar=True)\n\n    c1 = ComplexRegion(Interval(0, 4)*Interval(0, 2*S.Pi), polar=True)\n    assert c1.intersect(Interval(1, 5)) == Interval(1, 4)\n    assert c1.intersect(Interval(4, 9)) == FiniteSet(4)\n    assert c1.intersect(Interval(5, 12)) is S.EmptySet\n\n    # Rectangular form\n    X_axis = ComplexRegion(Interval(-oo, oo)*FiniteSet(0))\n\n    unit_square = ComplexRegion(Interval(-1, 1)*Interval(-1, 1))\n    upper_half_unit_square = ComplexRegion(Interval(-1, 1)*Interval(0, 1))\n    upper_half_plane = ComplexRegion(Interval(-oo, oo)*Interval(0, oo))\n    lower_half_plane = ComplexRegion(Interval(-oo, oo)*Interval(-oo, 0))\n    right_half_plane = ComplexRegion(Interval(0, oo)*Interval(-oo, oo))\n    first_quad_plane = ComplexRegion(Interval(0, oo)*Interval(0, oo))\n\n    assert upper_half_plane.intersect(unit_square) == upper"], "sample_208": ["def test_alter_field_to_fk_dependency_same_app(self):\n    changes = self.get_changes(\n        [self.author_empty, self.book_with_no_author_fk],\n        [self.author_empty, self.book],\n    )\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [('otherapp', '__first__')])\n"], "sample_1022": ["def test_repeated_decimals():\n    cases = {\n        '0.2[1]': '19/90',\n        '0.1[23]': '123/990',\n        '0.1[23][4]': '1234/9990',\n        '0.1[23][45]': '12345/99990',\n        '0.1[23][45][6]': '123456/999990',\n        '0.1[23][45][67]': '1234567/9999990',\n        '0.1[23][45][67][8]': '12345678/99999990',\n        '0.1[23][45][67][89]': '123456789/999999990',\n        '0.1[23][45][67][89][0]': '1234567890/9999999990',\n        '0.1[23][45][67][89][01]': '12345678901/99999999990',\n        '0.1[23][45][67][89][012]': '123456789012/999999999990',\n        '0.1[23][45][67][89][012][3]': '1234567890123/9999999999990',\n        '0.1[23][45][67][89][012][34]': '12345678901234/99999999999990',\n        '0.1[23][45][67][89][012][345]': '123456789012345/999999999999990',\n        '0.1[23][45][67][89][012][345][6]': '1234567890123456/9999999999999990',\n        '0.1[23][45][67][89][012][345][67]': '12345678901234567/99999999999999990',\n        '0.1[23][45][67][89][012][345][678]': '123456789012345678/999999999999999990',\n        '0.1[23][45][67][89][012][345][678][9]': '1234567890123456789/9999999999999999990',\n        '0.1[23][45][67][89][012]["], "sample_101": ["    def test_wsgi_request_init(self):\n        environ = {\n            'REQUEST_METHOD': 'GET',\n            'SCRIPT_NAME': '/script',\n            'PATH_INFO': '/path',\n            'CONTENT_LENGTH': '10',\n            'wsgi.input': BytesIO(b'Hello World!'),\n        }\n        request = WSGIRequest(environ)\n        self.assertEqual(request.method, 'GET')\n        self.assertEqual(request.path_info, '/path')\n        self.assertEqual(request.path, '/script/path')\n        self.assertEqual(request.META['PATH_INFO'], '/path')\n        self.assertEqual(request.META['SCRIPT_NAME'], '/script')\n"], "sample_775": ["def test_indent_at_name():\n    # Test the indent_at_name parameter\n    pp = _EstimatorPrettyPrinter(indent=4, indent_at_name=True)\n    lr = LogisticRegression()\n    expected = \"\"\""], "sample_144": ["def test_model_inheritance_with_deferred_fields(self):\n    \"\"\"\n    Regression test for #12345\n    \"\"\"\n    # Create a child-parent-grandparent chain\n    place1 = Place(name=\"Guido's House of Pasta\", address='944 W. Fullerton')\n    place1.save_base(raw=True)\n    restaurant = Restaurant(\n        place_ptr=place1,\n        serves_hot_dogs=True,\n        serves_pizza=False,\n    )\n    restaurant.save_base(raw=True)\n    italian_restaurant = ItalianRestaurant(restaurant_ptr=restaurant, serves_gnocchi=True)\n    italian_restaurant.save_base(raw=True)\n\n    # Test that deferred fields are correctly loaded\n    italian_restaurant_deferred = ItalianRestaurant.objects.defer('serves_gnocchi').get(pk=italian_restaurant.pk)\n    self.assertEqual(italian_restaurant_deferred.serves_gnocchi, True)\n\n    # Test that deferred fields are correctly loaded when accessing parent objects\n    restaurant_deferred = italian_restaurant_deferred.restaurant_ptr\n    self.assertEqual(restaurant_deferred.serves_hot_dogs, True)\n    self.assertEqual(restaurant_deferred.serves_pizza, False)\n\n    # Test that deferred fields are correctly loaded when accessing grandparent objects\n    place_deferred = restaurant_deferred.place_ptr\n    self.assertEqual(place_deferred.name, \"Guido's House of Pasta\")\n    self.assertEqual(place_deferred.address, '944 W. Fullerton')\n"], "sample_188": ["    def test_window_frame_start_end(self):\n        # Test that the start and end values are correctly formatted.\n        connection = connection\n        frame = RowRange()\n        self.assertEqual(frame.window_frame_start_end(connection, 10, 20), ('10 %s' % connection.ops.FOLLOWING, '20 %s' % connection.ops.FOLLOWING))\n        self.assertEqual(frame.window_frame_start_end(connection, -10, -20), ('10 %s' % connection.ops.PRECEDING, '20 %s' % connection.ops.PRECEDING))\n        self.assertEqual(frame.window_frame_start_end(connection, 0, 0), (connection.ops.CURRENT_ROW, connection.ops.CURRENT_ROW))\n        self.assertEqual(frame.window_frame_start_end(connection, None, None), (connection.ops.UNBOUNDED_PRECEDING, connection.ops.UNBOUNDED_FOLLOWING))\n\n        frame = ValueRange()\n        self.assertEqual(frame.window_frame_start_end(connection, 10, 20), ('10 %s' % connection.ops.FOLLOWING, '20 %s' % connection.ops.FOLLOWING))\n        self.assertEqual(frame.window_frame_start_end(connection, -10, -20), ('10 %s' % connection.ops.PRECEDING, '20 %s' % connection.ops.PRECEDING))\n        self.assertEqual(frame.window_frame_start_end(connection, 0, 0), (connection.ops.CURRENT_ROW, connection.ops.CURRENT_ROW))\n        self.assertEqual(frame.window_frame_start_end(connection, None, None), (connection.ops.UNBOUNDED_PRECEDING, connection.ops.UNBOUNDED_FOLLOWING))\n"], "sample_322": ["def test_detect_soft_applied_add_field_non_m2mfield(self):\n    \"\"\"\n    executor.detect_soft_applied() detects non-ManyToManyField tables from an\n    AddField operation.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Create the tables for 0001 but make it look like the migration hasn't\n    # been applied.\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n    executor.migrate([(\"migrations\", None)], fake=True)\n    # Table detection sees 0001 is applied.\n    migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], True)\n    # Create the tables for 0002 but make it look like the migration hasn't\n    # been applied.\n    executor.loader.build_graph()\n    executor.migrate([(\"migrations\", \"0002_second\")])\n    executor.migrate([(\"migrations\", None)], fake=True)\n    # Table detection sees 0002 is applied.\n    migration = executor.loader.get_migration(\"migrations\", \"0002_second\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], True)\n    # Leave the tables for 0001 except the added field. That missing field\n    # should cause detect_soft_applied() to return False.\n    with connection.schema_editor() as editor:\n        editor.execute(editor.sql_alter_column % {\n            \"table\": \"migrations_author\",\n            \"changes\": \"DROP COLUMN name\",\n        })\n    migration = executor.loader.get_migration(\"migrations\", \"0001_initial\")\n    self.assertIs(executor.detect_soft_applied(None, migration)[0], False)\n    # Cleanup by removing the remaining tables.\n    with connection.schema_editor() as editor:\n        editor.execute(editor.sql_delete_table % {\"table\": \"migrations_author\"})\n    self.assertTableNotExists(\"migrations_author\")\n"], "sample_1003": ["def test_Options_init():\n    opt = Options((x, y, z), {'domain': 'ZZ'})\n\n    assert opt.gens == (x, y, z)\n    assert opt.domain == ZZ\n    assert ('order' in opt) is False\n\n    raises(OptionError, lambda: Options((x, y, z), {'domain': 'ZZ', 'gens': (x, y, z)}))\n\n    raises(GeneratorsError, lambda: Options((x, x, y), {'domain': 'ZZ'}))\n\n    raises(GeneratorsError, lambda: Options((x, y, z), {'domain': 'ZZ[x, y]'}))\n\n    raises(GeneratorsError, lambda: Options((), {'domain': 'EX'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'domain': 'abc'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'order': 'abc'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'split': 'abc'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'modulus': 'abc'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'extension': 'abc'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'symmetric': 'abc'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'strict': 'abc'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'auto': 'abc'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'frac': 'abc'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'formal': 'abc'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'polys': 'abc'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'include': 'abc'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'all': 'abc'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'gen': 'abc'}))\n\n    raises(OptionError, lambda: Options((x, y, z), {'symbols': 'abc'}))\n\n    raises("], "sample_762": ["def test_clone_sparse_matrices_with_nan():\n    # Regression test for cloning estimators with sparse matrices containing NaN\n    sparse_matrix_classes = [\n        getattr(sp, name)\n        for name in dir(sp) if name.endswith('_matrix')]\n\n    for cls in sparse_matrix_classes:\n        sparse_matrix = cls(np.array([[np.nan, 0], [0, 1]]))\n        clf = MyEstimator(empty=sparse_matrix)\n        clf_cloned = clone(clf)\n        assert clf.empty.__class__ is clf_cloned.empty.__class__\n        assert_array_equal(clf.empty.toarray(), clf_cloned.empty.toarray())\n"], "sample_618": ["def test_cross_multiple_vector_cross_products() -> None:\n    # Test multiple vector cross-products. Note that the direction of the\n    # cross product vector is defined by the right-hand rule:\n\n    a = xr.DataArray(\n        [[1, 2, 3], [4, 5, 6]],\n        dims=(\"time\", \"cartesian\"),\n        coords=dict(\n            time=([\"time\"], [0, 1]),\n            cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"]),\n        ),\n    )\n    b = xr.DataArray(\n        [[4, 5, 6], [1, 2, 3]],\n        dims=(\"time\", \"cartesian\"),\n        coords=dict(\n            time=([\"time\"], [0, 1]),\n            cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"]),\n        ),\n    )\n\n    expected = xr.DataArray(\n        [[-3, 6, -3], [3, -6, 3]],\n        dims=(\"time\", \"cartesian\"),\n        coords=dict(\n            time=([\"time\"], [0, 1]),\n            cartesian=([\"cartesian\"], [\"x\", \"y\", \"z\"]),\n        ),\n    )\n\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    xr.testing.assert_identical(expected, actual)\n"], "sample_495": ["def test_page_repr(self):\n    \"\"\"\n    Test the __repr__ method of the Page class.\n    \"\"\"\n    paginator = Paginator([1, 2, 3], 2)\n    page = paginator.page(1)\n    self.assertEqual(repr(page), '<Page 1 of 2>')\n    page = paginator.page(2)\n    self.assertEqual(repr(page), '<Page 2 of 2>')\n"], "sample_1184": ["compilation error"], "sample_582": ["def test_flaskgroup_load_dotenv(monkeypatch, runner):\n    for item in (\"FOO\", \"BAR\", \"EGGS\"):\n        monkeypatch._setitem.append((os.environ, item, notset))\n\n    monkeypatch.chdir(test_path)\n    cli = FlaskGroup(load_dotenv=True)\n    result = runner.invoke(cli)\n    assert result.exit_code == 0\n    assert os.environ[\"FOO\"] == \"env\"\n    assert os.environ[\"BAR\"] == \"bar\"\n    assert os.environ[\"EGGS\"] not in os.environ\n\n    cli = FlaskGroup(load_dotenv=False)\n    result = runner.invoke(cli)\n    assert result.exit_code == 0\n    assert \"FOO\" not in os.environ\n    assert \"BAR\" not in os.environ\n    assert \"EGGS\" not in os.environ\n"], "sample_520": ["def test_line3d_set_get_data_3d_zdir(fig_test, fig_ref):\n    x, y, z = [0, 1], [2, 3], [4, 5]\n    x2, y2, z2 = [6, 7], [8, 9], [10, 11]\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    lines = ax.plot(x, y, z)\n    line = lines[0]\n    np.testing.assert_array_equal((x, y, z), line.get_data_3d())\n    line.set_data_3d(x2, y2, z2)\n    np.testing.assert_array_equal((x2, y2, z2), line.get_data_3d())\n    line.set_xdata(x)\n    line.set_ydata(y)\n    line.set_3d_properties(zs=z, zdir='y')\n    np.testing.assert_array_equal((y, z, x), line.get_data_3d())\n    line.set_3d_properties(zs=0, zdir='y')\n    np.testing.assert_array_equal((y, np.zeros_like(z), x), line.get_data_3d())\n"], "sample_589": ["def test_interpolate_na_max_gap_non_uniform_index(da_time):\n    da_time[\"t\"] = pd.to_datetime([\"2001-01-01\", \"2001-01-02\", \"2001-01-03\", \"2001-01-05\", \"2001-01-10\"])\n    expected = da_time.copy(data=[np.nan, 1, 2, 3, 10])\n    actual = da_time.interpolate_na(\"t\", max_gap=\"3D\")\n    assert_equal(actual, expected)\n"], "sample_146": ["def test_invalid_variant_consistent_language_settings(self):\n    msg = (\n        'You have provided a value for the LANGUAGE_CODE setting that is '\n        'not in the LANGUAGES setting.'\n    )\n    tests = [\n        # language + script.\n        'zh-Hans',\n        'sr-Latn',\n        # language + region + script.\n        'zh-CN-Hans',\n        'sr-Latn-RS',\n        # language + script + variant.\n        'zh-Hans-CN',\n        'sr-Latn-RS-latn',\n    ]\n    for tag in tests:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [\n                Error(msg, id='translation.E004'),\n            ])\n"], "sample_1130": ["def test_point_partial_velocity_multiple_gen_speeds():\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    p = Point('p')\n    u1, u2, u3 = dynamicsymbols('u1, u2, u3')\n    p.set_vel(N, u1 * A.x + u2 * N.y + u3 * A.z)\n    assert p.partial_velocity(N, u1, u2, u3) == (A.x, N.y, A.z)\n    assert p.partial_velocity(N, u1, u3) == (A.x, A.z)\n    assert p.partial_velocity(N, u2) == N.y\n"], "sample_533": ["def test_contour_labeler_event_handler():\n    # Test that the event handler for manual contour labeling works correctly.\n    x, y = np.meshgrid(np.arange(0, 10), np.arange(0, 10))\n    z = np.max(np.dstack([abs(x), abs(y)]), 2)\n\n    fig, ax = plt.subplots()\n    cs = ax.contour(x, y, z)\n\n    # Test that the event handler is called when a button is pressed.\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 1, 1)\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 1\n\n    # Test that the event handler is called when a key is pressed.\n    event = mpl.backend_bases.KeyEvent('key_press_event', fig.canvas, 'enter')\n    _contour_labeler_event_handler(cs, True, 5, event)\n    assert len(cs.labelTexts) == 1\n\n    # Test that the event handler removes the last label when the right button is pressed.\n    event = mpl.backend_bases.LocationEvent('button_press_event', fig.canvas, 1, 1, button=MouseButton.RIGHT)\n    _contour_labeler_event_handler(cs, False, 5, event)\n    assert len(cs.labelTexts) == 0\n\n    # Test that the event handler removes the last label when the delete key is pressed.\n    event = mpl.backend_bases.KeyEvent('key_press_event', fig.canvas, 'delete')\n    _contour_labeler_event_handler(cs, False, 5, event)\n    assert len(cs.labelTexts) == 0\n"], "sample_556": ["def test_subfigure_subplotspec():\n    fig = plt.figure()\n    gs = fig.add_gridspec(2, 2)\n    subfig = fig.add_subfigure(gs[0, 0])\n    ax = subfig.add_subplot(gs[0, 0])\n    assert ax.get_subplotspec().get_gridspec() == gs\n    assert ax.get_subplotspec().num1 == 0\n    assert ax.get_subplotspec().num2 == 0\n    assert ax.get_subplotspec().is_first_row()\n    assert ax.get_subplotspec().is_first_col()\n    assert ax.get_subplotspec().is_last_row()\n    assert ax.get_subplotspec().is_last_col()\n"], "sample_1090": ["def test_number_symbol():\n    assert S.Exp1.is_irrational\n    assert S.Pi.is_irrational\n    assert S.GoldenRatio.is_irrational\n    assert S.TribonacciConstant.is_irrational\n    assert S.EulerGamma.is_irrational is None\n    assert S.Catalan.is_irrational is None\n\n    assert S.Exp1.is_algebraic is False\n    assert S.Pi.is_algebraic is False\n    assert S.GoldenRatio.is_algebraic\n    assert S.TribonacciConstant.is_algebraic\n    assert S.EulerGamma.is_algebraic is None\n    assert S.Catalan.is_algebraic is None\n\n    assert S.Exp1.is_transcendental\n    assert S.Pi.is_transcendental\n    assert S.GoldenRatio.is_transcendental is False\n    assert S.TribonacciConstant.is_transcendental is False\n    assert S.EulerGamma.is_transcendental is None\n    assert S.Catalan.is_transcendental is None\n\n    assert S.Exp1.is_real\n    assert S.Pi.is_real\n    assert S.GoldenRatio.is_real\n    assert S.TribonacciConstant.is_real\n    assert S.EulerGamma.is_real\n    assert S.Catalan.is_real\n\n    assert S.Exp1.is_positive\n    assert S.Pi.is_positive\n    assert S.GoldenRatio.is_positive\n    assert S.TribonacciConstant.is_positive\n    assert S.EulerGamma.is_positive\n    assert S.Catalan.is_positive\n\n    assert S.Exp1.is_negative is False\n    assert S.Pi.is_negative is False\n    assert S.GoldenRatio.is_negative is False\n    assert S.TribonacciConstant.is_negative is False\n    assert S.EulerGamma.is_negative is False\n    assert S.Catalan.is_negative is False\n\n    assert S.Exp1.is_number\n    assert S.Pi.is_number\n    assert S.GoldenRatio.is_number\n    assert S.TribonacciConstant.is_number\n    assert S.EulerGamma.is_number\n    assert S.Catalan.is_number\n"], "sample_498": ["def test_legend_title_fontprop_fontsize_with_rcparam():\n    # test the title_fontsize kwarg with rcParams\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg = plt.legend(title='Aardvark', title_fontproperties=FontProperties(\n                                       family='serif', size=22))\n    assert leg.get_title().get_size() == 22\n\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg = plt.legend(title='Aardvark', title_fontsize=22)\n    assert leg.get_title().get_fontsize() == 22\n\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg = plt.legend(title='Aardvark')\n    assert leg.get_title().get_fontsize() == 20\n"], "sample_648": ["def test_parameter_set_extract_from(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"x\", [1, 2, 3])\n            pass\n    \"\"\"\n    )\n    from _pytest.mark.structures import ParameterSet\n\n    parameterset = ParameterSet.extract_from([1, 2, 3])\n    assert parameterset.values == (1, 2, 3)\n    assert parameterset.marks == []\n    assert parameterset.id is None\n\n    parameterset = ParameterSet.extract_from((1, 2, 3))\n    assert parameterset.values == (1, 2, 3)\n    assert parameterset.marks == []\n    assert parameterset.id is None\n\n    parameterset = ParameterSet.extract_from(ParameterSet((1, 2, 3), [], None))\n    assert parameterset.values == (1, 2, 3)\n    assert parameterset.marks == []\n    assert parameterset.id is None\n\n    parameterset = ParameterSet.extract_from(ParameterSet((1, 2, 3), [pytest.mark.skip], None))\n    assert parameterset.values == (1, 2, 3)\n    assert parameterset.marks == [pytest.mark.skip]\n    assert parameterset.id is None\n\n    parameterset = ParameterSet.extract_from(ParameterSet((1, 2, 3), [], \"some_id\"))\n    assert parameterset.values == (1, 2, 3)\n    assert parameterset.marks == []\n    assert parameterset.id == \"some_id\"\n"], "sample_614": ["def test_unindexed_dims_repr() -> None:\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3])}\n    expected = \"Dimensions without coordinates: y, z\"\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3]), \"y\": np.array([4, 5, 6])}\n    expected = \"Dimensions without coordinates: z\"\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n\n    dims = [\"x\", \"y\", \"z\"]\n    coords = {\"x\": np.array([1, 2, 3]), \"y\": np.array([4, 5, 6]), \"z\": np.array([7, 8, 9])}\n    expected = None\n    actual = formatting.unindexed_dims_repr(dims, coords)\n    assert actual == expected\n"], "sample_88": ["def test_attachment_filename_encoding(self):\n    \"\"\"\n    Regression test for #14964\n    \"\"\"\n    headers = {\"Date\": \"Fri, 09 Nov 2001 01:08:47 -0000\", \"Message-ID\": \"foo\"}\n    subject, from_email, to = 'hello', 'from@example.com', 'to@example.com'\n    content = 'This is the message.'\n    msg = EmailMessage(subject, content, from_email, [to], headers=headers)\n    # Unicode in file name\n    msg.attach(\"une pi\u00e8ce jointe.pdf\", b\"%PDF-1.4.%...\", mimetype=\"application/pdf\")\n    msg_bytes = msg.message().as_bytes()\n    message = message_from_bytes(msg_bytes)\n    payload = message.get_payload()\n    self.assertEqual(payload[1].get_filename(), 'une pi\u00e8ce jointe.pdf')\n    self.assertEqual(payload[1].get_content_disposition(), 'attachment; filename=\"une pi\u00e8ce jointe.pdf\"')\n"], "sample_1102": ["def test_issue_18613():\n    assert Poly(x/2 + 1).as_poly() is None\n    assert Poly(x**2 + y).as_poly(x, y) == Poly(x**2 + y, x, y)\n    assert Poly(x**2 + y).as_poly(x) == Poly(x**2 + y, x, domain='ZZ[y]')\n    assert Poly(x**2 + y, x).as_poly(x, y) == Poly(x**2 + y, x, y)\n    assert Poly(x**2 + y, x).as_poly(x) == Poly(x**2 + y, x, domain='ZZ[y]')\n    assert Poly(x**2 + y, x, y).as_poly(x, y) == Poly(x**2 + y, x, y)\n    assert Poly(x**2 + y, x, y).as_poly(x) == Poly(x**2 + y, x, domain='ZZ[y]')\n"], "sample_514": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc)\n    cb.set_alpha(0.5)\n    assert cb.ax.get_alpha() == 0.5\n    cb.set_alpha(1)\n    assert cb.ax.get_alpha() == 1\n    cb.set_alpha(None)\n    assert cb.ax.get_alpha() is None\n"], "sample_1082": ["def test_hyperbolic_function_properties():\n    x = Symbol('x')\n    assert sinh(x).is_finite is None\n    assert cosh(x).is_finite is None\n    assert tanh(x).is_finite is None\n    assert coth(x).is_finite is None\n    assert csch(x).is_finite is None\n    assert sech(x).is_finite is None\n    assert asinh(x).is_finite is None\n    assert acosh(x).is_finite is None\n    assert atanh(x).is_finite is None\n    assert acoth(x).is_finite is None\n    assert asech(x).is_finite is None\n    assert acsch(x).is_finite is None\n\n    assert sinh(x).is_zero is None\n    assert cosh(x).is_zero is None\n    assert tanh(x).is_zero is None\n    assert coth(x).is_zero is None\n    assert csch(x).is_zero is None\n    assert sech(x).is_zero is None\n    assert asinh(x).is_zero is None\n    assert acosh(x).is_zero is None\n    assert atanh(x).is_zero is None\n    assert acoth(x).is_zero is None\n    assert asech(x).is_zero is None\n    assert acsch(x).is_zero is None\n\n    assert sinh(x).is_positive is None\n    assert cosh(x).is_positive is None\n    assert tanh(x).is_positive is None\n    assert coth(x).is_positive is None\n    assert csch(x).is_positive is None\n    assert sech(x).is_positive is None\n    assert asinh(x).is_positive is None\n    assert acosh(x).is_positive is None\n    assert atanh(x).is_positive is None\n    assert acoth(x).is_positive is None\n    assert asech(x).is_positive is None\n    assert acsch(x).is_positive is None\n\n    assert sinh(x).is_negative is None\n    assert cosh(x).is_negative is None\n    assert tanh(x).is_negative is None\n    assert coth(x).is_negative is None\n    assert csch(x).is_negative is None\n    assert sech(x).is_negative is None\n    assert asinh(x).is_negative is None\n    assert acosh(x).is"], "sample_310": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n        self.company = Company.objects.create(name=\"Django\")\n        self.person = Person.objects.create(first_name=\"Human\", last_name=\"User\", company=self.company)\n"], "sample_251": ["def test_annotation_with_subquery_and_window_function(self):\n    subquery = Book.objects.filter(\n        publisher=OuterRef('pk'),\n        pages__gt=400,\n    ).values('publisher').annotate(count=Count('pk')).values('count')\n    publisher_books_qs = Publisher.objects.annotate(\n        total_books=Count('book'),\n        top_pages=Window(\n            expression=Max('book__pages'),\n            partition_by=[F('pk')],\n        ),\n    ).filter(\n        total_books=Subquery(subquery, output_field=IntegerField()),\n    ).values('name', 'top_pages')\n    self.assertCountEqual(publisher_books_qs, [\n        {'name': 'Sams', 'top_pages': 528},\n        {'name': 'Morgan Kaufmann', 'top_pages': 946},\n    ])\n"], "sample_797": ["def test_power_transformer_output_distribution():\n    # Test that output_distribution is correctly set\n    X = np.abs(X_2d)\n\n    pt = PowerTransformer(method='box-cox', standardize=False)\n    pt.fit(X)\n    assert pt.output_distribution_ == 'normal'\n\n    pt = PowerTransformer(method='yeo-johnson', standardize=False)\n    pt.fit(X)\n    assert pt.output_distribution_ == 'normal'\n\n    pt = PowerTransformer(method='box-cox', standardize=False,\n                          output_distribution='uniform')\n    pt.fit(X)\n    assert pt.output_distribution_ == 'uniform'\n\n    pt = PowerTransformer(method='yeo-johnson', standardize=False,\n                          output_distribution='uniform')\n    pt.fit(X)\n    assert pt.output_distribution_ == 'uniform'\n"], "sample_227": ["def test_genericforeignkey(self):\n    modeladmin = BookmarkAdminGenericRelation(Bookmark, site)\n\n    request = self.request_factory.get('/', {})\n    request.user = self.alfred\n    changelist = modeladmin.get_changelist_instance(request)\n\n    request = self.request_factory.get('/', {'tags__tag': 'python'})\n    request.user = self.alfred\n    changelist = modeladmin.get_changelist_instance(request)\n\n    # Make sure the correct queryset is returned\n    queryset = changelist.get_queryset(request)\n    self.assertEqual(list(queryset), [self.python_bookmark, self.django_bookmark])\n\n    # Make sure the correct choice is selected\n    filterspec = changelist.get_filters(request)[0][0]\n    self.assertEqual(filterspec.title, 'tag')\n    choices = list(filterspec.choices(changelist))\n    self.assertEqual(choices[1]['display'], 'python')\n    self.assertIs(choices[1]['selected'], True)\n    self.assertEqual(choices[1]['query_string'], '?tags__tag=python')\n\n    request = self.request_factory.get('/', {'tags__tag__exact': 'linux'})\n    request.user = self.alfred\n    changelist = modeladmin.get_changelist_instance(request)\n\n    # Make sure the correct queryset is returned\n    queryset = changelist.get_queryset(request)\n    self.assertEqual(list(queryset), [self.kernel_bookmark])\n\n    # Make sure the correct choice is selected\n    filterspec = changelist.get_filters(request)[0][0]\n    self.assertEqual(filterspec.title, 'tag')\n    choices = list(filterspec.choices(changelist))\n    self.assertEqual(choices[2]['display'], 'linux')\n    self.assertIs(choices[2]['selected'], True)\n    self.assertEqual(choices[2]['query_string'], '?tags__tag__exact=linux')\n\n    request = self.request_factory.get('/', {'tags__tag__isnull': 'True'})\n    request.user = self.alfred\n    changelist = modeladmin.get_changelist_instance(request)\n\n    # Make sure the correct queryset is returned\n    queryset = changelist.get_queryset(request)\n    self.assertEqual(list(queryset), [self.none_tags])\n\n    # Make sure the correct choice is selected\n    filterspec = changelist.get_filters(request)[0][0]\n    self.assertEqual(filterspec.title, 'tag')\n    choices = list(filterspec.choices(changelist))\n    self.assertEqual(choices[0]['display'], 'None')\n    self.assertIs(choices[0]['selected'],"], "sample_148": ["def test_get_model_from_relation(self):\n    \"\"\"\n    Tests for get_model_from_relation\n    \"\"\"\n    # Test with a ForeignKey\n    field = Article._meta.get_field('site')\n    self.assertEqual(get_model_from_relation(field), Site)\n\n    # Test with a ManyToManyField\n    field = Article._meta.get_field('sites')\n    self.assertEqual(get_model_from_relation(field), Site)\n\n    # Test with a non-relation field\n    field = Article._meta.get_field('title')\n    with self.assertRaises(NotRelationField):\n        get_model_from_relation(field)\n"], "sample_228": ["def test_formset_with_deletion_and_absolute_max(self):\n    \"\"\"\n    FormSets with deletion and absolute_max.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_delete=True, absolute_max=2)\n    initial = [{'choice': 'Calexico', 'votes': 100}, {'choice': 'Fergie', 'votes': 900}]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_798": ["def test_ridge_regression_return_n_iter():\n    # Test that return_n_iter works correctly\n    X, y = make_regression(n_samples=10, n_features=5, random_state=42)\n    for solver in ['sag', 'lsqr']:\n        coefs, n_iter = ridge_regression(X, y, alpha=1.0, solver=solver,\n                                         return_n_iter=True)\n        assert n_iter is not None\n        assert len(n_iter) == 1\n        assert n_iter[0] > 0\n\n    for solver in ['svd', 'cholesky', 'sparse_cg']:\n        coefs, n_iter = ridge_regression(X, y, alpha=1.0, solver=solver,\n                                         return_n_iter=True)\n        assert n_iter is None\n"], "sample_425": ["def test_serialize_pathlib_windows_path(self):\n    # Test WindowsPath objects work on supported platforms.\n    if sys.platform == \"win32\":\n        self.assertSerializedEqual(pathlib.WindowsPath(\"C:\\\\Windows\\\\System32\"))\n        path = pathlib.WindowsPath(\"C:\\\\Windows\\\\System32\")\n        expected = (\"pathlib.PureWindowsPath('C:/Windows/System32')\", {\"import pathlib\"})\n        self.assertSerializedResultEqual(path, expected)\n"], "sample_298": ["def test_make_token_with_timestamp(self):\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    timestamp = p0._num_seconds(p0._now())\n    tk1 = p0._make_token_with_timestamp(user, timestamp)\n    self.assertIs(p0.check_token(user, tk1), True)\n"], "sample_978": ["def test_invalid_degree():\n    d = -1\n    knots = range(5)\n    with raises(ValueError):\n        bspline_basis_set(d, knots, x)\n"], "sample_170": ["    def test_technical_500_response(self):\n        request = RequestFactory().get('/')\n        exc_type = ValueError\n        exc_value = ValueError('Test exception')\n        tb = None\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html; charset=utf-8')\n"], "sample_78": ["def test_base_command_output_transaction(self):\n    \"\"\"\n    Test that BaseCommand's output_transaction attribute is respected.\n    \"\"\"\n    class TestCommand(BaseCommand):\n        output_transaction = True\n\n            return 'SELECT * FROM table;'\n\n    out = StringIO()\n    management.call_command('test', stdout=out)\n    output = out.getvalue()\n    self.assertTrue(output.strip().startswith(connection.ops.start_transaction_sql()))\n    self.assertTrue(output.strip().endswith(connection.ops.end_transaction_sql()))\n\n    class TestCommand(BaseCommand):\n        output_transaction = False\n\n            return 'SELECT * FROM table;'\n\n    out = StringIO()\n    management.call_command('test', stdout=out)\n    output = out.getvalue()\n    self.assertNotIn(connection.ops.start_transaction_sql(), output)\n    self.assertNotIn(connection.ops.end_transaction_sql(), output)\n"], "sample_656": ["def test_capturing_and_logging_fundamentals_with_keyboardinterrupt(testdir):\n    # here we check a fundamental feature\n    p = testdir.makepyfile(\n        \"\"\"\n        import sys, os\n        import py, logging\n        from _pytest import capture\n        cap = capture.MultiCapture(out=False, in_=False,\n                                     Capture=capture.SysCapture)\n        cap.start_capturing()\n\n        logging.warning(\"hello1\")\n        outerr = cap.readouterr()\n        print(\"suspend, captured %%s\" %%(outerr,))\n        logging.warning(\"hello2\")\n\n        cap.pop_outerr_to_orig()\n        logging.warning(\"hello3\")\n\n        outerr = cap.readouterr()\n        print(\"suspend2, captured %%s\" %% (outerr,))\n        raise KeyboardInterrupt()\n    \"\"\"\n    )\n    result = testdir.runpython(p)\n    result.stdout.fnmatch_lines(\n        \"\"\"\n        suspend, captured*hello1*\n        suspend2, captured*WARNING:root:hello3*\n    \"\"\"\n    )\n    result.stderr.fnmatch_lines(\n        \"\"\"\n        WARNING:root:hello2\n    \"\"\"\n    )\n    assert \"atexit\" not in result.stderr.str()\n"], "sample_523": ["def test_legend_draggable_update():\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label='shabnams')\n    leg = ax.legend(draggable=True)\n    assert leg.get_draggable()\n    leg.set_draggable(False)\n    assert not leg.get_draggable()\n    leg.set_draggable(True, update='bbox')\n    assert leg.get_draggable()\n"], "sample_587": ["    def test_merge_override(self):\n        ds1 = xr.Dataset({\"x\": 0})\n        ds2 = xr.Dataset({\"x\": 1})\n        assert ds1.identical(ds1.merge(ds2, compat=\"override\"))\n        assert ds2.identical(ds2.merge(ds1, compat=\"override\"))\n"], "sample_969": ["def test_get_type_hints():\n        pass\n\n    assert get_type_hints(func) == {'a': int, 'b': str, 'return': None}\n\n    class MyClass:\n            pass\n\n    assert get_type_hints(MyClass) == {'a': int, 'b': str, 'return': None}\n\n    class MySubClass(MyClass):\n            super().__init__(a, b)\n\n    assert get_type_hints(MySubClass) == {'a': int, 'b': str, 'c': float, 'return': None}\n\n    class MyGenericClass(Generic[T]):\n            pass\n\n    assert get_type_hints(MyGenericClass) == {'a': T, 'return': None}\n\n    class MyNewTypeClass:\n        MyNewType = NewType('MyNewType', int)\n\n            pass\n\n    assert get_type_hints(MyNewTypeClass) == {'a': MyNewTypeClass.MyNewType, 'return': None}\n"], "sample_150": ["    def test_handle_default_options(self):\n        options = mock.Mock()\n        options.settings = 'my_settings'\n        options.pythonpath = '/path/to/pythonpath'\n        handle_default_options(options)\n        self.assertEqual(os.environ['DJANGO_SETTINGS_MODULE'], 'my_settings')\n        self.assertIn('/path/to/pythonpath', sys.path)\n"], "sample_970": ["def test_isabstractmethod():\n    class AbstractClass:\n        @abstractmethod\n            pass\n\n    class ConcreteClass(AbstractClass):\n            pass\n\n    assert inspect.isabstractmethod(AbstractClass.abstract_method) is True\n    assert inspect.isabstractmethod(ConcreteClass.abstract_method) is False\n    assert inspect.isabstractmethod(AbstractClass) is False\n    assert inspect.isabstractmethod(ConcreteClass) is False\n"], "sample_1088": ["def test_symmetrize_edge_cases():\n    assert symmetrize(x**2 + y**2, x, y, formal=True) == ((x + y)**2 - 2*x*y, 0, [(x + y, x + y), (x*y, x*y)])\n    assert symmetrize(x**2 - y**2, x, y, formal=True) == ((x + y)**2 - 2*x*y, -2*y**2, [(x + y, x + y), (x*y, x*y)])\n    assert symmetrize(x**2 + y**2, x, y, z, formal=True) == ((x + y + z)**2 - 2*(x*y + x*z + y*z), -y**2 - z**2, [(x + y + z, x + y + z), (x*y + x*z + y*z, x*y + x*z + y*z), (x*y*z, x*y*z)])\n    assert symmetrize(x**2 - y**2, x, y, z, formal=True) == ((x + y + z)**2 - 2*(x*y + x*z + y*z), -2*y**2 - z**2, [(x + y + z, x + y + z), (x*y + x*z + y*z, x*y + x*z + y*z), (x*y*z, x*y*z)])\n    assert symmetrize(x**2 + y**2, x, y, z, w, formal=True) == ((x + y + z + w)**2 - 2*(x*y + x*z + x*w + y*z + y*w + z*w), -y**2 - z**2 - w**2, [(x + y + z + w, x + y + z + w), (x*y + x*z + x*w + y*z + y*w + z*w, x*y + x*z + x*w + y*z + y*w + z*w), (x*y*z + x*y*w + x*z*w + y*z*w, x*y*z + x*y*w + x*z*w + y*z*w), (x*y*z*w, x*y*z*w)])\n    assert symmetrize(x**2 - y**2, x, y, z, w, formal=True) == ((x + y +"], "sample_907": ["def test_domain_cpp_ast_template_introductions():\n    check('class', 'abc::ns::foo{id_0, id_1, id_2} {key}xyz::bar',\n          {2: 'I000EXN3abc2ns3fooEI4id_04id_14id_2EEN3xyz3barE'})\n    check('class', 'abc::ns::foo{id_0, id_1, ...id_2} {key}xyz::bar',\n          {2: 'I00DpEXN3abc2ns3fooEI4id_04id_1sp4id_2EEN3xyz3barE'})\n    check('class', 'abc::ns::foo{{id_0, id_1, id_2}} {key}xyz::bar<id_0, id_1, id_2>',\n          {2: 'I000EXN3abc2ns3fooEI4id_04id_14id_2EEN3xyz3barI4id_04id_14id_2EE'})\n    check('class', 'abc::ns::foo{{id_0, id_1, ...id_2}} {key}xyz::bar<id_0, id_1, id_2...>',\n          {2: 'I00DpEXN3abc2ns3fooEI4id_04id_1sp4id_2EEN3xyz3barI4id_04id_1Dp4id_2EE'})\n\n    check('type', 'abc::ns::foo{{id_0, id_1, id_2}} {key}xyz::bar = ghi::qux',\n          {2: 'I000EXN3abc2ns3fooEI4id_04id_14id_2EEN3xyz3barE'}, key='using')\n    check('type', 'abc::ns::foo{{id_0, id_1, ...id_2}} {key}xyz::bar = ghi::qux',\n          {2: 'I00DpEXN3abc2ns3fooEI4id_04id_1sp4id_2EEN3xyz3barE'}, key='using')\n    check('function', 'abc::ns::foo{id_0, id_1, id_2} void xyz::bar()"], "sample_320": ["def test_alter_field_with_func_index_together(self):\n    app_label = \"test_alfuncin_to\"\n    index_name = f\"{app_label}_pony_idx\"\n    table_name = f\"{app_label}_pony\"\n    project_state = self.set_up_test_model(\n        app_label,\n        indexes=[models.Index(Abs(\"pink\"), name=index_name)],\n    )\n    operation = migrations.AlterIndexTogether(\"Pony\", [(\"pink\", Abs(\"weight\"))])\n    new_state = project_state.clone()\n    operation.state_forwards(app_label, new_state)\n    with connection.schema_editor() as editor:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    self.assertIndexNameExists(table_name, index_name)\n    with connection.schema_editor() as editor:\n        operation.database_backwards(app_label, editor, new_state, project_state)\n    self.assertIndexNameExists(table_name, index_name)\n"], "sample_1157": ["def test_implicit_multiplication_application_with_parentheses():\n    transformations = standard_transformations + \\\n                      (implicit_multiplication_application,)\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z')\n    assert parse_expr(\"(2x + 3y)z\", transformations=transformations) == (2*x + 3*y)*z\n    assert parse_expr(\"(2x + 3y)(z + 1)\", transformations=transformations) == (2*x + 3*y)*(z + 1)\n    assert parse_expr(\"(2x + 3y)z^2\", transformations=transformations) == (2*x + 3*y)*z**2\n"], "sample_935": ["def test_template_parameter_lists():\n    check('function', 'template<typename T> void f(T)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T, typename U> void f(T, U)', {2: 'I00E1f1T1U'})\n    check('function', 'template<typename T, typename U, typename V> void f(T, U, V)', {2: 'I000E1f1T1U1V'})\n    check('function', 'template<typename T, typename U, typename V, typename W> void f(T, U, V, W)', {2: 'I0000E1f1T1U1V1W'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X> void f(T, U, V, W, X)', {2: 'I00000E1f1T1U1V1W1X'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> void f(T, U, V, W, X, Y)', {2: 'I000000E1f1T1U1V1W1X1Y'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> void f(T, U, V, W, X, Y, Z)', {2: 'I0000000E1f1T1U1V1W1X1Y1Z'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A> void f(T, U, V, W, X, Y, Z, A)', {2: 'I00000000E1f1T1U1V1W1X1Y1Z1A'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A, typename B> void f(T, U, V, W, X, Y, Z, A, B)', {2: 'I000000000E1f1T1U1V1W1X1Y1Z1A1B'})\n    check('function', 'template<typename"], "sample_873": ["def test_get_feature_names_out():\n    sel = StepSelector()\n    sel.fit(X, y)\n    assert_array_equal(feature_names_t, sel.get_feature_names_out())\n    assert_array_equal(feature_names_t, sel.get_feature_names_out(feature_names))\n    assert_array_equal(feature_names_t, sel.get_feature_names_out(input_features=feature_names))\n\n    # Test with non-matching input features\n    with pytest.raises(ValueError):\n        sel.get_feature_names_out(input_features=[\"a\", \"b\", \"c\"])\n\n    # Test with None input features\n    assert_array_equal(feature_names_t, sel.get_feature_names_out(input_features=None))\n"], "sample_1004": ["def test_CondSet_properties():\n    c = ConditionSet(x, x < 1, Interval(0, 2))\n    assert c.sym == x\n    assert c.condition == (x < 1)\n    assert c.base_set == Interval(0, 2)\n    assert c.free_symbols == {x}\n"], "sample_1153": ["def test_periodic_argument_edge_cases():\n    from sympy import periodic_argument, oo, pi, I, exp_polar\n    assert periodic_argument(0, oo) == 0\n    assert periodic_argument(0, pi) == 0\n    assert periodic_argument(0, -pi) == 0\n    assert periodic_argument(0, 2*pi) == 0\n    assert periodic_argument(0, -2*pi) == 0\n    assert periodic_argument(pi, oo) == pi\n    assert periodic_argument(pi, pi) == 0\n    assert periodic_argument(pi, -pi) == pi\n    assert periodic_argument(pi, 2*pi) == pi\n    assert periodic_argument(pi, -2*pi) == pi\n    assert periodic_argument(-pi, oo) == -pi\n    assert periodic_argument(-pi, pi) == 0\n    assert periodic_argument(-pi, -pi) == -pi\n    assert periodic_argument(-pi, 2*pi) == -pi\n    assert periodic_argument(-pi, -2*pi) == -pi\n    assert periodic_argument(2*pi, oo) == 0\n    assert periodic_argument(2*pi, pi) == 0\n    assert periodic_argument(2*pi, -pi) == 0\n    assert periodic_argument(2*pi, 2*pi) == 0\n    assert periodic_argument(2*pi, -2*pi) == 0\n    assert periodic_argument(-2*pi, oo) == 0\n    assert periodic_argument(-2*pi, pi) == 0\n    assert periodic_argument(-2*pi, -pi) == 0\n    assert periodic_argument(-2*pi, 2*pi) == 0\n    assert periodic_argument(-2*pi, -2*pi) == 0\n    assert periodic_argument(I, oo) == periodic_argument(I, oo)\n    assert periodic_argument(I, pi) == periodic_argument(I, pi)\n    assert periodic_argument(I, -pi) == periodic_argument(I, -pi)\n    assert periodic_argument(I, 2*pi) == periodic_argument(I, 2*pi)\n    assert periodic_argument(I, -2*pi) == periodic_argument(I, -2*pi)\n    assert periodic_argument(exp_polar(I*pi), oo) == pi\n    assert periodic_argument(exp_polar(I*pi), pi) == 0\n    assert periodic_argument(exp_polar(I*pi), -pi) == pi\n"], "sample_923": ["def test_template_parameter_lists():\n    check('function', 'template<typename T> void f(T)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T, T)', {2: 'I0E1f1T1T'})\n    check('function', 'template<typename T, typename U> void f(T, U)', {2: 'I00E1f1T1U'})\n    check('function', 'template<typename T, typename U, typename V> void f(T, U, V)', {2: 'I000E1f1T1U1V'})\n    check('function', 'template<typename T, typename U, typename V, typename W> void f(T, U, V, W)', {2: 'I0000E1f1T1U1V1W'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X> void f(T, U, V, W, X)', {2: 'I00000E1f1T1U1V1W1X'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> void f(T, U, V, W, X, Y)', {2: 'I000000E1f1T1U1V1W1X1Y'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> void f(T, U, V, W, X, Y, Z)', {2: 'I0000000E1f1T1U1V1W1X1Y1Z'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A> void f(T, U, V, W, X, Y, Z, A)', {2: 'I00000000E1f1T1U1V1W1X1Y1Z1A'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A, typename B> void f(T, U, V, W, X, Y, Z, A, B)', {2: 'I000000000"], "sample_308": ["def test_e_format_with_different_timezones(self):\n    # Test the 'e' format with different timezones\n    dt = datetime(2022, 1, 1, 12, 0, 0)\n    timezones = [\n        'America/New_York',\n        'Europe/London',\n        'Australia/Sydney',\n        'Asia/Tokyo',\n    ]\n    for tz_name in timezones:\n        tz = pytz.timezone(tz_name)\n        aware_dt = dt.astimezone(tz)\n        self.assertIsNotNone(dateformat.format(aware_dt, 'e'))\n"], "sample_232": ["    def test_key_transform_factory(self):\n        field = models.JSONField()\n        transform = field.get_transform('key')\n        self.assertIsInstance(transform, KeyTransformFactory)\n        self.assertEqual(transform.key_name, 'key')\n"], "sample_610": ["def test_cftimeindex_repr_with_name():\n    \"\"\"Test that cftimeindex.__repr__ includes name.\"\"\"\n    index = xr.cftime_range(start=\"2000\", periods=3, name=\"time\")\n    repr_str = index.__repr__()\n    assert \"name='time'\" in repr_str\n"], "sample_455": ["def test_validate_expression_with_condition_and_exclude(self):\n    constraint = models.UniqueConstraint(\n        Lower(\"name\"),\n        name=\"name_lower_without_color_uniq\",\n        condition=models.Q(color__isnull=True),\n    )\n    non_unique_product = UniqueConstraintProduct(name=self.p2.name.upper())\n    msg = \"Constraint \u201cname_lower_without_color_uniq\u201d is violated.\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        constraint.validate(UniqueConstraintProduct, non_unique_product, exclude={\"color\"})\n    # Values not matching condition are ignored.\n    constraint.validate(\n        UniqueConstraintProduct,\n        UniqueConstraintProduct(name=self.p1.name, color=self.p1.color),\n        exclude={\"color\"},\n    )\n    # Existing instances have their existing row excluded.\n    constraint.validate(UniqueConstraintProduct, self.p2, exclude={\"color\"})\n    # Unique field is excluded.\n    constraint.validate(\n        UniqueConstraintProduct,\n        non_unique_product,\n        exclude={\"name\", \"color\"},\n    )\n"], "sample_576": ["    def test_repr_png_(self):\n\n        p = Plot().plot()\n        data, metadata = p._repr_png_()\n        assert isinstance(data, bytes)\n        assert isinstance(metadata, dict)\n        assert sorted(metadata) == [\"height\", \"width\"]\n"], "sample_724": ["def test_imputation_most_frequent_ties():\n    # Test imputation using the most-frequent strategy with ties.\n    X = np.array([\n        [-1, -1, 0, 5],\n        [-1, 2, -1, 3],\n        [-1, 1, 3, 3],\n        [-1, 2, 3, 7],\n    ])\n\n    X_true = np.array([\n        [2, 0, 5],\n        [2, 3, 3],\n        [1, 3, 3],\n        [2, 3, 7],\n    ])\n\n    # Test with ties\n    X_ties = np.array([\n        [-1, -1, 0, 5],\n        [-1, 2, -1, 3],\n        [-1, 1, 3, 3],\n        [-1, 2, 3, 3],\n    ])\n\n    X_true_ties = np.array([\n        [2, 0, 5],\n        [2, 3, 3],\n        [1, 3, 3],\n        [2, 3, 3],\n    ])\n\n    _check_statistics(X, X_true, \"most_frequent\", [np.nan, 2, 3, 3], -1)\n    _check_statistics(X_ties, X_true_ties, \"most_frequent\", [np.nan, 2, 3, 3], -1)\n"], "sample_242": ["    def test_exact_lookup(self):\n        lookup = Exact(lhs=Value(1), rhs=Value(2))\n        self.assertEqual(lookup.lookup_name, 'exact')\n"], "sample_842": ["def test_clone(estimator):\n    # Test that clone works correctly on estimators.\n    estimator_cloned = clone(estimator)\n\n    # Check that all constructor parameters are equal.\n    assert estimator.get_params() == estimator_cloned.get_params()\n\n    # Check that the cloned estimator is not the same object as the original.\n    assert id(estimator) != id(estimator_cloned)\n"], "sample_1025": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n    assert not prntr.module_imports\n    assert prntr.doprint(pi) == 'math.pi'\n    assert prntr.module_imports == {'math': {'pi'}}\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n"], "sample_153": ["    def test_model_check_id_field(self):\n        class ModelWithIdField(models.Model):\n            id = models.CharField(max_length=10)\n\n        class ModelWithIdFieldPrimaryKey(models.Model):\n            id = models.CharField(max_length=10, primary_key=True)\n\n        class ModelWithAutoField(models.Model):\n            id = models.AutoField()\n\n        class ModelWithPrimaryKey(models.Model):\n            pk = models.CharField(max_length=10, primary_key=True)\n\n        self.assertEqual(ModelWithIdField.check(), [\n            checks.Error(\n                \"'id' can only be used as a field name if the field also sets 'primary_key=True'.\",\n                obj=ModelWithIdField,\n                id='models.E004',\n            )\n        ])\n\n        self.assertEqual(ModelWithIdFieldPrimaryKey.check(), [])\n\n        self.assertEqual(ModelWithAutoField.check(), [])\n\n        self.assertEqual(ModelWithPrimaryKey.check(), [])\n"], "sample_1038": ["def test_MatrixExpr_from_index_summation():\n    from sympy import MatrixSymbol, Sum, symbols\n    from sympy.abc import i, j, k, l, N\n    A = MatrixSymbol(\"A\", N, N)\n    B = MatrixSymbol(\"B\", N, N)\n    C = MatrixSymbol(\"C\", N, N)\n    D = MatrixSymbol(\"D\", N, N)\n    E = MatrixSymbol(\"E\", N, N)\n    F = MatrixSymbol(\"F\", N, N)\n    G = MatrixSymbol(\"G\", N, N)\n    H = MatrixSymbol(\"H\", N, N)\n    I = MatrixSymbol(\"I\", N, N)\n    J = MatrixSymbol(\"J\", N, N)\n    K = MatrixSymbol(\"K\", N, N)\n    L = MatrixSymbol(\"L\", N, N)\n    M = MatrixSymbol(\"M\", N, N)\n    O = MatrixSymbol(\"O\", N, N)\n    P = MatrixSymbol(\"P\", N, N)\n    Q = MatrixSymbol(\"Q\", N, N)\n    R = MatrixSymbol(\"R\", N, N)\n    S = MatrixSymbol(\"S\", N, N)\n    T = MatrixSymbol(\"T\", N, N)\n    U = MatrixSymbol(\"U\", N, N)\n    V = MatrixSymbol(\"V\", N, N)\n    W = MatrixSymbol(\"W\", N, N)\n    X = MatrixSymbol(\"X\", N, N)\n    Y = MatrixSymbol(\"Y\", N, N)\n    Z = MatrixSymbol(\"Z\", N, N)\n    a, b, c, d, e, f, g, h, m, n, o, p, q, r, s, t, u, v, w, x, y, z = symbols('a b c d e f g h m n o p q r s t u v w x y z')\n    expr = Sum(A[i, j]*B[j, k], (j, 0, N-1))\n    assert MatrixExpr.from_index_summation(expr) == A*B\n    expr = Sum(A[j, i]*B[j, k], (j, 0, N-1))\n    assert MatrixExpr.from_index_summation(expr) == A.T*B\n    expr = Sum(A[i, i], (i, 0, N-1))\n    assert"], "sample_1075": ["def test_beta_is_real():\n    x, y = Symbol('x', real=True), Symbol('y', real=True)\n    assert beta(x, y).is_real\n\n    x, y = Symbol('x', real=False), Symbol('y', real=True)\n    assert not beta(x, y).is_real\n\n    x, y = Symbol('x', real=True), Symbol('y', real=False)\n    assert not beta(x, y).is_real\n"], "sample_1056": ["def test_numexprprinter():\n    # Test NumExprPrinter\n    prntr = NumExprPrinter()\n    assert prntr._print_ImaginaryUnit(Expr()) == '1j'\n\n    # Test _print_Function\n    assert prntr._print_Function(sin(x)) == 'sin(x)'\n    assert prntr._print_Function(cos(x)) == 'cos(x)'\n    assert prntr._print_Function(tan(x)) == 'tan(x)'\n    assert prntr._print_Function(asin(x)) == 'arcsin(x)'\n    assert prntr._print_Function(acos(x)) == 'arccos(x)'\n    assert prntr._print_Function(atan(x)) == 'arctan(x)'\n    assert prntr._print_Function(atan2(x, y)) == 'arctan2(x, y)'\n    assert prntr._print_Function(sinh(x)) == 'sinh(x)'\n    assert prntr._print_Function(cosh(x)) == 'cosh(x)'\n    assert prntr._print_Function(tanh(x)) == 'tanh(x)'\n    assert prntr._print_Function(asinh(x)) == 'arcsinh(x)'\n    assert prntr._print_Function(acosh(x)) == 'arccosh(x)'\n    assert prntr._print_Function(atanh(x)) == 'arctanh(x)'\n    assert prntr._print_Function(log(x)) == 'log(x)'\n    assert prntr._print_Function(exp(x)) == 'exp(x)'\n    assert prntr._print_Function(sqrt(x)) == 'sqrt(x)'\n    assert prntr._print_Function(Abs(x)) == 'abs(x)'\n    assert prntr._print_Function(conjugate(x)) == 'conj(x)'\n    assert prntr._print_Function(im(x)) == 'imag(x)'\n    assert prntr._print_Function(re(x)) == 'real(x)'\n    assert prntr._print_Function(where(x, y, z)) == 'where(x, y, z)'\n    assert prntr._print_Function(complex(x, y)) == 'complex(x, y)'\n    assert prntr._print_Function(contains(x, y)) == 'contains(x, y)'\n\n    # Test blacklisted functions\n    raises(TypeError, lambda: prntr._print_SparseMatrix(Matrix([[x, y], [y*x, z**2]]"], "sample_196": ["def test_window_frame_start(self):\n    self.assertEqual(self.ops.window_frame_start(0), 'CURRENT ROW')\n    self.assertEqual(self.ops.window_frame_start(-1), '1 PRECEDING')\n    self.assertEqual(self.ops.window_frame_start(None), 'UNBOUNDED PRECEDING')\n    with self.assertRaises(ValueError):\n        self.ops.window_frame_start(1)\n    with self.assertRaises(ValueError):\n        self.ops.window_frame_start('a')\n"], "sample_1105": ["def test_entry():\n    M = MatrixSymbol('M', 2, 2)\n    N = MatrixSymbol('N', 2, 2)\n    expr = MatMul(M, N)\n    assert expr._entry(0, 0) == Sum(M[0, 0]*N[0, 0] + M[0, 1]*N[1, 0], (Dummy(\"i_1\"), 0, 1))\n    assert expr._entry(1, 1) == Sum(M[1, 0]*N[0, 1] + M[1, 1]*N[1, 1], (Dummy(\"i_1\"), 0, 1))\n"], "sample_1087": ["def test_f_polys():\n    f0, f1, f2, f3, f4, f5, f6 = f_polys()\n\n    assert f0.is_Poly\n    assert f1.is_Poly\n    assert f2.is_Poly\n    assert f3.is_Poly\n    assert f4.is_Poly\n    assert f5.is_Poly\n    assert f6.is_Poly\n\n    assert f0.gens == (x, y, z)\n    assert f1.gens == (x, y, z)\n    assert f2.gens == (x, y, z)\n    assert f3.gens == (x, y, z)\n    assert f4.gens == (x, y, z)\n    assert f5.gens == (x, y, z)\n    assert f6.gens == (x, y, z, t)\n\n    assert f0.domain == ZZ\n    assert f1.domain == ZZ\n    assert f2.domain == ZZ\n    assert f3.domain == ZZ\n    assert f4.domain == ZZ\n    assert f5.domain == ZZ\n    assert f6.domain == ZZ\n\n"], "sample_1064": ["def test_tensorflow_Assignment():\n    if not tf:\n        skip(\"TensorFlow not installed\")\n\n    x = Symbol('x')\n    expr = x + 1\n    assignment = x.assign(expr)\n    assert tensorflow_code(assignment) == \"x = tensorflow.math.add(x, 1)\"\n\n    x = Symbol('x')\n    y = Symbol('y')\n    expr = x + y\n    assignment = x.assign(expr)\n    assert tensorflow_code(assignment) == \"x = tensorflow.math.add(x, y)\"\n\n    M = MatrixSymbol('M', 2, 2)\n    expr = M + M\n    assignment = M.assign(expr)\n    assert tensorflow_code(assignment) == \"M = tensorflow.math.add(M, M)\"\n"], "sample_972": ["def test_get_type_hints():\n        pass\n\n    assert get_type_hints(func) == {'a': int, 'b': str, 'return': None}\n\n    class MyClass:\n            pass\n\n    assert get_type_hints(MyClass) == {'a': int, 'b': str, 'return': None}\n\n    class MyGenericClass(Generic[T]):\n            pass\n\n    assert get_type_hints(MyGenericClass) == {'a': T, 'return': None}\n\n    class MyBrokenClass:\n        __annotations__ = {'a': int, 'b': str}\n\n    assert get_type_hints(MyBrokenClass) == {'a': int, 'b': str}\n\n    class MyNewTypeClass:\n        MyNewType = NewType('MyNewType', int)\n\n    assert get_type_hints(MyNewTypeClass.MyNewType) == {}\n"], "sample_1154": ["def test__linsolve_underdetermined():\n    # Test underdetermined system with one free variable\n    eqs = [Eq(x + y, 1)]\n    sol = {x: -y + 1, y: y}\n    assert _linsolve(eqs, [x, y]) == sol\n\n    # Test underdetermined system with two free variables\n    eqs = [Eq(x + y + z, 1)]\n    sol = {x: -y - z + 1, y: y, z: z}\n    assert _linsolve(eqs, [x, y, z]) == sol\n\n    # Test underdetermined system with three free variables\n    eqs = [Eq(x + y + z + w, 1)]\n    sol = {x: -y - z - w + 1, y: y, z: z, w: w}\n    assert _linsolve(eqs, [x, y, z, w]) == sol\n"], "sample_1119": ["def test_inverse_matpow_non_canonicalization():\n    A = MatrixSymbol('A', 3, 3)\n    assert Inverse(MatPow(A, -3)).doit() == MatPow(Inverse(A), 3).doit()\n    assert Inverse(MatPow(A, S.Half)).doit() == MatPow(Inverse(A), S.Half).doit()\n"], "sample_1035": ["def test_measure_all():\n    qubit = IntQubit(0, nqubits=2)\n    assert measure_all(qubit) == [(IntQubit(0, nqubits=2), 1)]\n    qubit = IntQubit(1, nqubits=2)\n    assert measure_all(qubit) == [(IntQubit(1, nqubits=2), 1)]\n    qubit = IntQubit(2, nqubits=2)\n    assert measure_all(qubit) == [(IntQubit(2, nqubits=2), 1)]\n    qubit = IntQubit(3, nqubits=2)\n    assert measure_all(qubit) == [(IntQubit(3, nqubits=2), 1)]\n    qubit = (IntQubit(0, nqubits=2) + IntQubit(1, nqubits=2))/sqrt(2)\n    assert measure_all(qubit) == [(IntQubit(0, nqubits=2), 1/2), (IntQubit(1, nqubits=2), 1/2)]\n    qubit = (IntQubit(0, nqubits=2) + IntQubit(2, nqubits=2))/sqrt(2)\n    assert measure_all(qubit) == [(IntQubit(0, nqubits=2), 1/2), (IntQubit(2, nqubits=2), 1/2)]\n    qubit = (IntQubit(0, nqubits=2) + IntQubit(3, nqubits=2))/sqrt(2)\n    assert measure_all(qubit) == [(IntQubit(0, nqubits=2), 1/2), (IntQubit(3, nqubits=2), 1/2)]\n    qubit = (IntQubit(1, nqubits=2) + IntQubit(2, nqubits=2))/sqrt(2)\n    assert measure_all(qubit) == [(IntQubit(1, nqubits=2), 1/2), (IntQubit(2, nqubits=2), 1/2)]\n    qubit = (IntQubit(1, nqubits=2) + IntQubit(3, nqubits=2))/sqrt("], "sample_926": ["def test_template_parameter_parsing():\n    check('function', 'template <typename T> void f(T)', {2: 'I0E1f1T'})\n    check('function', 'template <typename T> void f(T*)', {2: 'I0E1fP1T'})\n    check('function', 'template <typename T> void f(T&)', {2: 'I0E1fR1T'})\n    check('function', 'template <typename T> void f(T&&)', {2: 'I0E1fO1T'})\n    check('function', 'template <typename T> void f(const T)', {2: 'I0E1f1T'})\n    check('function', 'template <typename T> void f(volatile T)', {2: 'I0E1fV1T'})\n    check('function', 'template <typename T> void f(const volatile T)', {2: 'I0E1fVK1T'})\n    check('function', 'template <typename T> void f(T*)', {2: 'I0E1fP1T'})\n    check('function', 'template <typename T> void f(T[10])', {2: 'I0E1fA10_1T'})\n    check('function', 'template <typename T> void f(T[10][20])', {2: 'I0E1fA10_A20_1T'})\n    check('function', 'template <typename T> void f(T*)', {2: 'I0E1fP1T'})\n    check('function', 'template <typename T> void f(T**)', {2: 'I0E1fPP1T'})\n    check('function', 'template <typename T> void f(T***)', {2: 'I0E1fPPP1T'})\n    check('function', 'template <typename T> void f(T****)', {2: 'I0E1fPPPP1T'})\n    check('function', 'template <typename T> void f(T*****)', {2: 'I0E1fPPPPP1T'})\n    check('function', 'template <typename T> void f(T******)', {2: 'I0E1fPPPPPP1T'})\n    check('function', 'template <typename T> void f(T*******)', {2: 'I0E"], "sample_588": ["    def test_combine_by_coords(self):\n        objs = [Dataset({\"x\": [0]}), Dataset({\"x\": [1]})]\n        actual = combine_by_coords(objs)\n        expected = Dataset({\"x\": [0, 1]})\n        assert_identical(expected, actual)\n\n        actual = combine_by_coords([actual])\n        assert_identical(expected, actual)\n\n        objs = [Dataset({\"x\": [0, 1]}), Dataset({\"x\": [2]})]\n        actual = combine_by_coords(objs)\n        expected = Dataset({\"x\": [0, 1, 2]})\n        assert_identical(expected, actual)\n\n        # ensure combine_by_coords handles non-sorted variables\n        objs = [\n            Dataset({\"x\": (\"a\", [0]), \"y\": (\"a\", [0]), \"a\": [0]}),\n            Dataset({\"x\": (\"a\", [1]), \"y\": (\"a\", [1]), \"a\": [1]}),\n        ]\n        actual = combine_by_coords(objs)\n        expected = Dataset({\"x\": (\"a\", [0, 1]), \"y\": (\"a\", [0, 1]), \"a\": [0, 1]})\n        assert_identical(expected, actual)\n\n        objs = [Dataset({\"x\": [0], \"y\": [0]}), Dataset({\"y\": [1], \"x\": [1]})]\n        actual = combine_by_coords(objs)\n        expected = Dataset({\"x\": [0, 1], \"y\": [0, 1]})\n        assert_equal(actual, expected)\n\n        objs = [Dataset({\"x\": 0}), Dataset({\"x\": 1})]\n        with raises_regex(ValueError, \"Could not find any dimension coordinates\"):\n            combine_by_coords(objs)\n\n        objs = [Dataset({\"x\": [0], \"y\": [0]}), Dataset({\"x\": [0]})]\n        with raises_regex(ValueError, \"Every dimension needs a coordinate\"):\n            combine_by_coords(objs)\n"], "sample_430": ["def test_alter_field_to_not_null_with_default_function(self):\n    \"\"\"\n    #23609 - Tests autodetection of nullable to non-nullable alterations.\n    \"\"\"\n        return \"Some Name\"\n\n    changes = self.get_changes(\n        [self.author_name_null],\n        [\n            ModelState(\n                \"testapp\",\n                \"Author\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\"name\", models.CharField(max_length=200, default=default_function)),\n                ],\n            )\n        ],\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True\n    )\n    self.assertOperationFieldAttributes(\n        changes, \"testapp\", 0, 0, default=default_function\n    )\n"], "sample_958": ["def test_domain_cpp_ast_template_parameter_lists():\n    check('class', 'template<template<typename> typename T> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> class T> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> typename... T> {key}A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> class... T> {key}A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename... T> {key}A<T>', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> class... T> {key}A<T>', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename... T> {key}A<T...>', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> class... T> {key}A<T...>', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename... T> {key}A<T..., U>', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> class... T> {key}A<T..., U>', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename... T> {key}A<T..., U...>', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> class... T> {key}A<T..., U...>', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename... T> {key}A<T..., U, V>', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> class... T> {key}A<T..., U, V>', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename... T> {key}A<T..., U, V"], "sample_1118": ["def test_matpow():\n    assert MatPow(C, 0).doit() == Identity(n)\n    assert MatPow(C, 1).doit() == C\n    assert MatPow(C, -1).doit() == Inverse(C).doit()\n    assert MatPow(MatPow(C, 2), 3).doit() == MatPow(C, 6).doit()\n    assert MatPow(ZeroMatrix(n, n), -1).doit() == ZeroMatrix(n, n)\n    raises(NonInvertibleMatrixError, lambda: MatPow(ZeroMatrix(n, n), -2).doit())\n    raises(NonSquareMatrixError, lambda: MatPow(A, 2).doit())\n\n    assert MatPow(C, 2)._eval_transpose() == MatPow(C.T, 2)\n    assert MatPow(C, 2)._eval_derivative(n) == MatPow(C, 2)\n\n    assert MatPow(C, 0)._eval_derivative_matrix_lines(n) == [Identity(n)._eval_derivative_matrix_lines(n)]\n    assert MatPow(C, 1)._eval_derivative_matrix_lines(n) == [C._eval_derivative_matrix_lines(n)]\n    assert MatPow(C, -1)._eval_derivative_matrix_lines(n) == [Inverse(C)._eval_derivative_matrix_lines(n)]\n"], "sample_959": ["def test_domain_cpp_ast_template_introductions():\n    check('class', 'template<template<typename> typename T> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> class T> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> typename> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> typename ...T> {key}A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename...> {key}A', {2: 'II0EDpE1A'})\n    check('class', 'template<typename T, template<typename> typename...> {key}A', {2: 'I0I0EDpE1A'})\n    check('class', 'template<int> {key}A', {2: 'I_iE1A'})\n    check('class', 'template<int T> {key}A', {2: 'I_iE1A'})\n    check('class', 'template<int... T> {key}A', {2: 'I_DpiE1A'})\n    check('class', 'template<int T = 42> {key}A', {2: 'I_iE1A'})\n    check('class', 'template<int = 42> {key}A', {2: 'I_iE1A'})\n    check('class', 'template<typename A<B>::C> {key}A', {2: 'I_N1AI1BE1CEE1A'})\n    check('class', 'template<typename A<B>::C = 42> {key}A', {2: 'I_N1AI1BE1CEE1A'})\n    check('class', 'template<> {key}A<NS::B<>>', {2: 'IE1AIN2NS1BIEEE'})\n    check('class', 'template<typename ...Ts> {key}T<int (*)(Ts)...>', {2: 'IDpE1TIJPFi2TsEEE'})\n    check('class', 'template<int... Is> {key}T<(Is)...>', {2: 'I_DpiE1TIJX(Is)EEE', 3: 'I_D"], "sample_1141": ["def test_expr_free_symbols_deprecation():\n    from sympy.utilities.exceptions import SymPyDeprecationWarning\n    from sympy.abc import x, y\n    expr = x + y\n    with raises(SympifyError):\n        expr.expr_free_symbols\n    with raises(SympifyError):\n        expr.free_symbols\n"], "sample_1174": ["def test_polar_lift():\n    x = Symbol('x')\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == 1\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(-I*pi/2)\n    assert polar_lift(-I) == exp_polar(I*pi/2)\n    assert polar_lift(2 + I) == polar_lift(2 + I)\n    assert polar_lift(2*x) == 2*polar_lift(x)\n    assert polar_lift(4*x) == 4*polar_lift(x)\n    assert polar_lift(x**2) == x**2\n    assert polar_lift(x**3) == x**3\n    assert polar_lift(x**4) == x**4\n    assert polar_lift(x**5) == x**5\n    assert polar_lift(x**6) == x**6\n    assert polar_lift(x**7) == x**7\n    assert polar_lift(x**8) == x**8\n    assert polar_lift(x**9) == x**9\n    assert polar_lift(x**10) == x**10\n    assert polar_lift(x**11) == x**11\n    assert polar_lift(x**12) == x**12\n    assert polar_lift(x**13) == x**13\n    assert polar_lift(x**14) == x**14\n    assert polar_lift(x**15) == x**15\n    assert polar_lift(x**16) == x**16\n    assert polar_lift(x**17) == x**17\n    assert polar_lift(x**18) == x**18\n    assert polar_lift(x**19) == x**19\n    assert polar_lift(x**20) == x**20\n    assert polar_lift(x**21) == x**21\n    assert polar_lift(x**22) == x**22\n    assert polar_lift(x**23) == x**23\n    assert polar_lift(x**24) == x**24\n    assert polar_lift(x**25) == x**25\n    assert polar_lift(x**26) == x**26\n    assert polar_lift(x**27) == x**27\n    assert polar_lift(x**28) == x**28\n    assert polar_lift(x**29) == x**29\n    assert polar_lift(x**30) == x**30\n    assert"], "sample_133": ["    def test_get_paths(self):\n        view = JavaScriptCatalog()\n        packages = ['django.contrib.admin', 'django.contrib.auth']\n        paths = view.get_paths(packages)\n        self.assertEqual(len(paths), 2)\n        self.assertIn('django/contrib/admin/locale', paths[0])\n        self.assertIn('django/contrib/auth/locale', paths[1])\n"], "sample_1057": ["def test_fully_qualified_modules():\n    ast = Print('x y'.split(), \"coordinate: %12.5g %12.5g\")\n    printer = PythonCodePrinter({'standard':'python3', 'fully_qualified_modules': True})\n    printer.doprint(ast)\n    assert render_as_module(ast, standard='python3') == \\\n        'import sympy\\n\\nprint(\"coordinate: %12.5g %12.5g\" % (sympy.symbols(\"x\"), sympy.symbols(\"y\")))'\n"], "sample_828": ["def test_check_pairwise_arrays_precomputed():\n    # Ensure that check_pairwise_arrays works correctly with precomputed\n    # distance matrices.\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((5, 5))\n    X_checked, _ = check_pairwise_arrays(X, None, precomputed=True)\n    assert_array_equal(X, X_checked)\n\n    # Ensure that check_pairwise_arrays raises an error if the precomputed\n    # distance matrix is not square.\n    X = rng.random_sample((5, 4))\n    assert_raises(ValueError, check_pairwise_arrays, X, None, precomputed=True)\n\n    # Ensure that check_pairwise_arrays raises an error if the precomputed\n    # distance matrix contains negative values.\n    X = rng.random_sample((5, 5))\n    X[0, 1] = -1\n    assert_raises(ValueError, check_pairwise_arrays, X, None, precomputed=True)\n"], "sample_827": ["def test_inplace_swap_row_csc():\n    X = sp.csc_matrix(np.array([[0, 3, 0],\n                                [2, 4, 0],\n                                [0, 0, 0],\n                                [9, 8, 7],\n                                [4, 0, 5]], dtype=np.float64))\n    X_copy = X.copy()\n    inplace_swap_row_csc(X, 0, -1)\n    assert_array_equal(X.toarray(), np.array([[4, 0, 5],\n                                              [2, 4, 0],\n                                              [0, 0, 0],\n                                              [9, 8, 7],\n                                              [0, 3, 0]]))\n    X = X_copy\n    inplace_swap_row_csc(X, 2, 3)\n    assert_array_equal(X.toarray(), np.array([[0, 3, 0],\n                                              [2, 4, 0],\n                                              [9, 8, 7],\n                                              [0, 0, 0],\n                                              [4, 0, 5]]))\n    assert_raises(TypeError, inplace_swap_row_csc, X.tocsr(), 0, -1)\n    assert_raises(TypeError, inplace_swap_row_csc, X, 0, np.array([1]))\n    assert_raises(TypeError, inplace_swap_row_csc, X, np.array([1]), 0)\n"], "sample_154": ["def test_database_backends_with_kwargs(self):\n    with mock.patch('django.db.backends.base.validation.BaseDatabaseValidation.check') as mocked_check:\n        check_database_backends(databases=self.databases, foo='bar')\n        mocked_check.assert_called_once_with(foo='bar')\n"], "sample_319": ["def test_alter_field_to_not_null_with_default_function(self):\n    \"\"\"\n    #23609 - Tests autodetection of nullable to non-nullable alterations.\n    \"\"\"\n        return \"Ada Lovelace\"\n\n    changes = self.get_changes(\n        [self.author_name_null],\n        [self.author_name_default],\n        MigrationQuestioner({\"ask_not_null_alteration\": default_function}),\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True\n    )\n    self.assertOperationFieldAttributes(\n        changes, \"testapp\", 0, 0, default=default_function\n    )\n"], "sample_415": ["    def test_validate_with_deferrable(self):\n        constraint = UniqueConstraintDeferrable._meta.constraints[0]\n        obj_1 = UniqueConstraintDeferrable.objects.create(name=\"p1\", shelf=\"front\")\n        obj_2 = UniqueConstraintDeferrable.objects.create(name=\"p2\", shelf=\"back\")\n        obj_1.shelf, obj_2.shelf = obj_2.shelf, obj_1.shelf\n        with self.assertRaises(ValidationError):\n            constraint.validate(UniqueConstraintDeferrable, obj_1)\n        with self.assertRaises(ValidationError):\n            constraint.validate(UniqueConstraintDeferrable, obj_2)\n"], "sample_826": ["def test_ordinal_encoder_unsorted_categories():\n    X = np.array([['a', 'b']], dtype=object).T\n\n    enc = OrdinalEncoder(categories=[['b', 'a', 'c']])\n    exp = np.array([[1.], [0.]])\n    assert_array_equal(enc.fit(X).transform(X), exp)\n    assert_array_equal(enc.fit_transform(X), exp)\n    assert enc.categories_[0].tolist() == ['b', 'a', 'c']\n    assert np.issubdtype(enc.categories_[0].dtype, np.object_)\n\n    # unsorted passed categories still raise for numerical values\n    X = np.array([[1, 2]]).T\n    enc = OrdinalEncoder(categories=[[2, 1, 3]])\n    msg = 'Unsorted categories are not supported'\n    with pytest.raises(ValueError, match=msg):\n        enc.fit_transform(X)\n"], "sample_781": ["def test_feature_importances_sum(name):\n    X, y = make_classification(n_samples=15, n_informative=3, random_state=1,\n                               n_classes=3)\n    est = FOREST_ESTIMATORS[name](min_samples_leaf=5, random_state=42,\n                                  n_estimators=200).fit(X, y)\n    assert math.isclose(1, est.feature_importances_.sum(), abs_tol=1e-7)\n"], "sample_195": ["    def setUp(self):\n        self.ops = DatabaseOperations(connection=connection)\n"], "sample_1152": ["def test_powsimp_polar_with_force():\n    from sympy import polar_lift, exp_polar\n    x, y, z = symbols('x y z')\n    p, q, r = symbols('p q r', polar=True)\n\n    assert powsimp(p**x * q**x, force=True) == (p*q)**x\n    assert powsimp(p**x * (1/p)**x, force=True) == 1\n    assert powsimp((1/p)**x, force=True) == p**(-x)\n\n    assert powsimp(exp_polar(x)*exp_polar(y), force=True) == exp_polar(x + y)\n    assert powsimp(exp_polar(x)*exp_polar(y)*p**x*p**y, force=True) == \\\n        (p*exp_polar(1))**(x + y)\n    assert powsimp(exp_polar(x)*exp_polar(y)*p**x*p**y, combine='exp', force=True) == \\\n        exp_polar(x + y)*p**(x + y)\n    assert powsimp(\n        exp_polar(x)*exp_polar(y)*exp_polar(2)*sin(x) + sin(y) + p**x*p**y, force=True) \\\n        == p**(x + y) + sin(x)*exp_polar(2 + x + y) + sin(y)\n    assert powsimp(sin(exp_polar(x)*exp_polar(y)), force=True) == \\\n        sin(exp_polar(x + y))\n    assert powsimp(sin(exp_polar(x)*exp_polar(y)), deep=True, force=True) == \\\n        sin(exp_polar(x + y))\n"], "sample_927": ["def test_template_parameter_lists():\n    check('function', 'template<typename T> void f(T)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T> void f(T, T)', {2: 'I0E1f1T1T'})\n    check('function', 'template<typename T> void f(T, T, T)', {2: 'I0E1f1T1T1T'})\n    check('function', 'template<typename T, typename U> void f(T, U)', {2: 'I00E1f1T1U'})\n    check('function', 'template<typename T, typename U, typename V> void f(T, U, V)', {2: 'I000E1f1T1U1V'})\n    check('function', 'template<typename T, typename U, typename V, typename W> void f(T, U, V, W)', {2: 'I0000E1f1T1U1V1W'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X> void f(T, U, V, W, X)', {2: 'I00000E1f1T1U1V1W1X'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> void f(T, U, V, W, X, Y)', {2: 'I000000E1f1T1U1V1W1X1Y'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> void f(T, U, V, W, X, Y, Z)', {2: 'I0000000E1f1T1U1V1W1X1Y1Z'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A> void f(T, U, V, W, X, Y, Z, A)', {2: 'I00000000E1f1T1U1V1W1X1Y1Z1A'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z,"], "sample_132": ["    def test_technical_500_response(self):\n        request = RequestFactory().get('/')\n        exc_type = ValueError\n        exc_value = ValueError('Test exception')\n        tb = None\n        response = technical_500_response(request, exc_type, exc_value, tb)\n        self.assertEqual(response.status_code, 500)\n        self.assertEqual(response['Content-Type'], 'text/html; charset=utf-8')\n"], "sample_731": ["def test_fetch_california_housing_features():\n    try:\n        data = fetch()\n    except IOError:\n        raise SkipTest(\"California housing dataset can not be loaded.\")\n    expected_features = [\"MedInc\", \"HouseAge\", \"AveRooms\", \"AveBedrms\",\n                         \"Population\", \"AveOccup\", \"Latitude\", \"Longitude\"]\n    assert data.feature_names == expected_features\n    assert len(data.feature_names) == data.data.shape[1]\n"], "sample_603": ["def test_collapsible_section():\n    name = \"Test Section\"\n    inline_details = \"Inline details\"\n    details = \"Section details\"\n    n_items = 10\n    enabled = True\n    collapsed = False\n\n    formatted = fh.collapsible_section(\n        name, inline_details, details, n_items, enabled, collapsed\n    )\n    assert name in formatted\n    assert inline_details in formatted\n    assert details in formatted\n    assert str(n_items) in formatted\n    assert \"checked\" not in formatted\n\n    formatted = fh.collapsible_section(\n        name, inline_details, details, n_items, enabled, not collapsed\n    )\n    assert \"checked\" in formatted\n\n    formatted = fh.collapsible_section(\n        name, inline_details, details, n_items, not enabled, collapsed\n    )\n    assert \"disabled\" in formatted\n"], "sample_934": ["def test_xref_parsing_template():\n        class Config:\n            cpp_id_attributes = [\"id_attr\"]\n            cpp_paren_attributes = [\"paren_attr\"]\n        parser = DefinitionParser(target, location=None,\n                                  config=Config())\n        ast, isShorthand = parser.parse_xref_object()\n        parser.assert_end()\n    check('f<int>')\n    check('f<int, double>')\n    check('f<int, double, char>')\n    check('f<int, ...>')\n    check('f<int, double, ...>')\n    check('f<int, double, char, ...>')\n    check('f<template<typename> class T>')\n    check('f<template<typename> typename T>')\n    check('f<template<typename> typename... T>')\n    check('f<template<typename> typename...>')\n    check('f<template<int> class T>')\n    check('f<template<int> typename T>')\n    check('f<template<int> typename... T>')\n    check('f<template<int> typename...>')\n    check('f<template<int = 42> class T>')\n    check('f<template<int = 42> typename T>')\n    check('f<template<int = 42> typename... T>')\n    check('f<template<int = 42> typename...>')\n    check('f<template<typename T> class U>')\n    check('f<template<typename T> typename U>')\n    check('f<template<typename T> typename... U>')\n    check('f<template<typename T> typename...>')\n    check('f<template<typename T = int> class U>')\n    check('f<template<typename T = int> typename U>')\n    check('f<template<typename T = int> typename... U>')\n    check('f<template<typename T = int> typename...>')\n    check('f<template<typename T, typename U> class V>')\n    check('f<template<typename T, typename U> typename V>')\n    check('f<template<typename T, typename U> typename... V>')\n    check('f<template<typename T, typename U> typename...>')\n    check('f<template<typename T, typename U = int> class V>')\n    check('f<template<typename T, typename U = int> typename V>')\n    check('f<template<typename T, typename U = int> typename... V>')\n    check('f<template<typename T, typename U = int> typename...>')\n    check('"], "sample_917": ["def test_template_introductions():\n    check('class', 'abc::ns::foo{id_0, id_1, id_2} xyz::bar',\n          {2: 'I000EXN3abc2ns3fooEI4id_04id_14id_2EEN3xyz3barE'})\n    check('class', 'abc::ns::foo{id_0, id_1, ...id_2} xyz::bar',\n          {2: 'I00DpEXN3abc2ns3fooEI4id_04id_1sp4id_2EEN3xyz3barE'})\n    check('class', 'abc::ns::foo{id_0, id_1, id_2} xyz::bar<id_0, id_1, id_2>',\n          {2: 'I000EXN3abc2ns3fooEI4id_04id_14id_2EEN3xyz3barI4id_04id_14id_2EE'})\n    check('class', 'abc::ns::foo{id_0, id_1, ...id_2} xyz::bar<id_0, id_1, id_2...>',\n          {2: 'I00DpEXN3abc2ns3fooEI4id_04id_1sp4id_2EEN3xyz3barI4id_04id_1Dp4id_2EE'})\n\n    check('type', 'abc::ns::foo{id_0, id_1, id_2} xyz::bar = ghi::qux',\n          {2: 'I000EXN3abc2ns3fooEI4id_04id_14id_2EEN3xyz3barE'})\n    check('type', 'abc::ns::foo{id_0, id_1, ...id_2} xyz::bar = ghi::qux',\n          {2: 'I00DpEXN3abc2ns3fooEI4id_04id_1sp4id_2EEN3xyz3barE'})\n    check('function', 'abc::ns::foo{id_0, id_1, id_2} void xyz::bar()',\n          {2: 'I000EXN3abc2ns3fooEI4id_04id_14id_2EEN3xyz3bar"], "sample_302": ["    def setUp(self):\n        self.client = DatabaseClient(connection=connection)\n"], "sample_732": ["def test_random_state():\n    try:\n        dataset1 = fetch_kddcup99(random_state=42, subset='SA', shuffle=True,\n                                  percent10=True, download_if_missing=False)\n        dataset2 = fetch_kddcup99(random_state=42, subset='SA', shuffle=True,\n                                  percent10=True, download_if_missing=False)\n    except IOError:\n        raise SkipTest(\"kddcup99 dataset can not be loaded.\")\n\n    assert_equal(dataset1.data, dataset2.data)\n    assert_equal(dataset1.target, dataset2.target)\n\n    dataset3 = fetch_kddcup99(random_state=43, subset='SA', shuffle=True,\n                              percent10=True, download_if_missing=False)\n    assert(not np.array_equal(dataset1.data, dataset3.data))\n    assert(not np.array_equal(dataset1.target, dataset3.target))\n"], "sample_575": ["    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n"], "sample_924": ["def test_template_parameter_lists():\n    check('function', 'template<typename T> void f(T)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T, typename U> void f(T, U)', {2: 'I00E1f1T1U'})\n    check('function', 'template<typename T, typename U, typename V> void f(T, U, V)', {2: 'I000E1f1T1U1V'})\n    check('function', 'template<typename T, typename U, typename V, typename W> void f(T, U, V, W)', {2: 'I0000E1f1T1U1V1W'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X> void f(T, U, V, W, X)', {2: 'I00000E1f1T1U1V1W1X'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> void f(T, U, V, W, X, Y)', {2: 'I000000E1f1T1U1V1W1X1Y'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> void f(T, U, V, W, X, Y, Z)', {2: 'I0000000E1f1T1U1V1W1X1Y1Z'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A> void f(T, U, V, W, X, Y, Z, A)', {2: 'I00000000E1f1T1U1V1W1X1Y1Z1A'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A, typename B> void f(T, U, V, W, X, Y, Z, A, B)', {2: 'I000000000E1f1T1U1V1W1X1Y1Z1A1B'})\n    check('function', 'template<typename"], "sample_279": ["    def test_empty_fields(self):\n        msg = 'At least one field is required to define a unique constraint.'\n        with self.assertRaisesMessage(ValueError, msg):\n            models.UniqueConstraint(fields=[], name='empty_fields')\n"], "sample_611": ["def test_date_range_like_non_standard_calendar():\n    src = date_range(\"2000-01-01\", periods=12, freq=\"6H\", calendar=\"noleap\")\n    out = date_range_like(src, \"noleap\")\n    assert src.equals(out)\n"], "sample_1063": ["def test_issue_16930_beta():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    x = symbols(\"x\")\n    y = symbols(\"y\")\n    f = lambda x, y:  S.GoldenRatio * x**2 * y**2\n    f_ = lambdify((x, y), f(x, y), modules='scipy')\n    assert f_(1, 2) == scipy.constants.golden_ratio * 4\n"], "sample_947": ["def test_calias(app):\n    text = (\".. c:alias:: int alias\\n\"\n            \"   :maxdepth: 2\\n\"\n            \"   :noroot: True\\n\"\n            \"   :noindexentry:\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1], addnodes.desc, desctype=\"alias\",\n                domain=\"c\", objtype=\"alias\", noindex=True)\n\n    entry = _get_obj(app, 'alias')\n    assert entry == ('index', 'c.alias', 'type')\n"], "sample_1068": ["def test_octave_Infinity():\n    assert mcode(S.Infinity) == \"inf\"\n    assert mcode(S.NegativeInfinity) == \"-inf\"\n    assert mcode(S.Infinity + x) == \"inf + x\"\n    assert mcode(S.Infinity * x) == \"inf.*x\"\n    assert mcode(S.Infinity / x) == \"inf./x\"\n    assert mcode(x / S.Infinity) == \"x/inf\"\n    assert mcode(S.Infinity ** x) == \"inf.^x\"\n    assert mcode(x ** S.Infinity) == \"x.^inf\"\n    assert mcode(S.Infinity + S.Infinity) == \"inf + inf\"\n    assert mcode(S.Infinity * S.Infinity) == \"inf.*inf\"\n    assert mcode(S.Infinity / S.Infinity) == \"inf/inf\"\n    assert mcode(S.Infinity ** S.Infinity) == \"inf.^inf\"\n"], "sample_1117": ["def test_lower_triangular():\n    assert ask(Q.lower_triangular(X + Z.T + Identity(2)), Q.lower_triangular(X) &\n            Q.upper_triangular(Z)) is True\n    assert ask(Q.lower_triangular(X*Z.T), Q.lower_triangular(X) &\n            Q.upper_triangular(Z)) is True\n    assert ask(Q.lower_triangular(Identity(3))) is True\n    assert ask(Q.lower_triangular(ZeroMatrix(3, 3))) is True\n    assert ask(Q.lower_triangular(OneMatrix(1, 1))) is True\n    assert ask(Q.lower_triangular(OneMatrix(3, 3))) is False\n    assert ask(Q.triangular(X), Q.lower_triangular(X))\n    assert ask(Q.lower_triangular(X**3), Q.lower_triangular(X))\n    assert ask(Q.lower_triangular(X), Q.lower_triangular(X))\n    assert ask(Q.lower_triangular(X), Q.upper_triangular(X)) is False\n    assert ask(Q.lower_triangular(X), Q.diagonal(X)) is False\n"], "sample_723": ["def test_imputation_most_frequent_ties():\n    # Test imputation using the most-frequent strategy with ties.\n    X = np.array([\n        [-1, -1, 0, 5],\n        [-1, 2, -1, 3],\n        [-1, 1, 3, 3],\n        [-1, 2, 3, 7],\n    ])\n\n    X_true = np.array([\n        [2, 0, 5],\n        [2, 3, 3],\n        [1, 3, 3],\n        [2, 3, 7],\n    ])\n\n    # Test with ties\n    X_ties = np.array([\n        [-1, -1, 0, 5],\n        [-1, 2, -1, 3],\n        [-1, 1, 3, 3],\n        [-1, 2, 3, 3],\n    ])\n\n    X_true_ties = np.array([\n        [2, 0, 5],\n        [2, 3, 3],\n        [1, 3, 3],\n        [2, 3, 3],\n    ])\n\n    _check_statistics(X, X_true, \"most_frequent\", [np.nan, 2, 3, 3], -1)\n    _check_statistics(X_ties, X_true_ties, \"most_frequent\", [np.nan, 2, 3, 3], -1)\n"], "sample_1125": ["def test_operator():\n    A = Operator('A')\n    B = Operator('B')\n    assert A.is_commutative is False\n    assert B.is_commutative is False\n    assert A*B != B*A\n\n    C = 2*A*A + I*B\n    assert C == 2*A**2 + I*B\n\n    assert A.inv() == A**(-1)\n    assert A*A.inv() == 1\n\n    I = IdentityOperator()\n    assert I.dimension == oo\n    assert I._eval_commutator(A) == 0\n    assert I._eval_anticommutator(A) == 2*A\n    assert I._apply_operator(A) == A\n    assert I._eval_inverse() == I\n    assert I._eval_adjoint() == I\n    assert I._eval_power(2) == I\n"], "sample_309": ["    def test_valid_date(self):\n        date_str = 'Sun, 06 Nov 1994 08:49:37 GMT'\n        self.assertEqual(parse_http_date_safe(date_str), parse_http_date(date_str))\n"], "sample_1037": ["def test_MatMul_as_coeff_matrices():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    expr = 2 * A * B * C\n    coeff, matrices = expr.as_coeff_matrices()\n    assert coeff == 2\n    assert matrices == [A, B, C]\n\n    expr = A * B * C\n    coeff, matrices = expr.as_coeff_matrices()\n    assert coeff == 1\n    assert matrices == [A, B, C]\n\n    expr = A * 2 * B * C\n    coeff, matrices = expr.as_coeff_matrices()\n    assert coeff == 2\n    assert matrices == [A, B, C]\n\n    expr = 2 * A * 3 * B * C\n    coeff, matrices = expr.as_coeff_matrices()\n    assert coeff == 6\n    assert matrices == [A, B, C]\n"], "sample_431": ["    def test_save_base_raw(self):\n        a = Article.objects.create(headline=\"Test headline\", pub_date=datetime.now())\n        a.save_base(raw=True)\n        self.assertEqual(Article.objects.get(id=a.id).headline, \"Test headline\")\n"], "sample_604": ["def test_summarize_variable():\n    var = xr.Variable(\"x\", np.arange(100), dims=\"x\")\n    actual = formatting.summarize_variable(\"x\", var, 10)\n    expected = dedent(\n        \"\"\"\\\n        x        (x) int64 0 1 ... 98 99\"\"\"\n    )\n    assert actual == expected\n\n    var = xr.Variable(\"x\", np.arange(100), dims=\"x\", attrs={\"units\": \"m\"})\n    actual = formatting.summarize_variable(\"x\", var, 10)\n    expected = dedent(\n        \"\"\"\\\n        x        (x) int64 0 1 ... 98 99\"\"\"\n    )\n    assert actual == expected\n\n    var = xr.Variable(\"x\", np.arange(100), dims=\"x\", attrs={\"units\": \"m\", \"description\": \"desc\"})\n    actual = formatting.summarize_variable(\"x\", var, 10)\n    expected = dedent(\n        \"\"\"\\\n        x        (x) int64 0 1 ... 98 99\"\"\"\n    )\n    assert actual == expected\n"], "sample_916": ["def test_template_introductions():\n    # from #4094\n    check('class', 'template<class, class = std::void_t<>> has_var', {2: 'I00E7has_var'})\n    check('class', 'template<class T> has_var<T, std::void_t<decltype(&T::var)>>',\n          {2: 'I0E7has_varI1TNSt6void_tIDTadN1T3varEEEEE'})\n    check('class', 'template<typename ...Pack> Numerics = (... && Numeric<Pack>)',\n          {2: 'IDpE8Numerics'})\n\n    # explicit specializations of members\n    check('member', 'template<> int A<int>::a', {2: 'IEN1AIiE1aE'})\n    check('member', 'template int A<int>::a', {2: 'IEN1AIiE1aE'},\n          output='template<> int A<int>::a')  # same as above\n    check('member', 'template<> template<> int A<int>::B<int>::b', {2: 'IEIEN1AIiE1BIiE1bE'})\n    check('member', 'template int A<int>::B<int>::b', {2: 'IEIEN1AIiE1BIiE1bE'},\n          output='template<> template<> int A<int>::B<int>::b')  # same as above\n\n    # defaulted constrained type parameters\n    check('type', 'template<C T = int&> A', {2: 'I_1CE1A'})\n\n    # template introductions\n    with pytest.raises(DefinitionError):\n        parse('enum', 'abc::ns::foo{id_0, id_1, id_2} A')\n    with pytest.raises(DefinitionError):\n        parse('enumerator', 'abc::ns::foo{id_0, id_1, id_2} A')\n    check('class', 'abc::ns::foo{id_0, id_1, id_2} xyz::bar',\n          {2: 'I000EXN3abc2ns3fooEI4id_04id_14id_2EEN3xyz3barE'})\n    check('class', 'abc::ns::foo{id_0, id_1, ...id_2} xyz::bar',\n          {2: 'I00D"], "sample_1159": ["def test_assumptions_with_polar():\n    z = Symbol('z', polar=True)\n    assert z.is_complex is True\n    assert z.is_real is None\n    assert z.is_imaginary is None\n    assert z.is_finite is True\n    assert z.is_infinite is False\n    assert z.is_comparable is True\n    assert z.is_prime is False\n    assert z.is_composite is False\n    assert z.is_number is True\n"], "sample_1173": ["def test_implicit_multiplication_application():\n    transformations = standard_transformations + \\\n                      (implicit_multiplication_application,)\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z')\n    f = Function('f')\n    assert parse_expr(\"2x\", transformations=transformations) == 2*x\n    assert parse_expr(\"2 x\", transformations=transformations) == 2*x\n    assert parse_expr(\"2x y\", transformations=transformations) == 2*x*y\n    assert parse_expr(\"2 x y\", transformations=transformations) == 2*x*y\n    assert parse_expr(\"2x(y+1)\", transformations=transformations) == 2*x*(y+1)\n    assert parse_expr(\"2 x (y+1)\", transformations=transformations) == 2*x*(y+1)\n    assert parse_expr(\"2x(y+1)z\", transformations=transformations) == 2*x*(y+1)*z\n    assert parse_expr(\"2 x (y+1) z\", transformations=transformations) == 2*x*(y+1)*z\n    assert parse_expr(\"f(x)z\", transformations=transformations) == f(x)*z\n    assert parse_expr(\"f(x) z\", transformations=transformations) == f(x)*z\n    assert parse_expr(\"f(x)(y+1)\", transformations=transformations) == f(x)*(y+1)\n    assert parse_expr(\"f(x) (y+1)\", transformations=transformations) == f(x)*(y+1)\n    assert parse_expr(\"f(x)(y+1)z\", transformations=transformations) == f(x)*(y+1)*z\n    assert parse_expr(\"f(x) (y+1) z\", transformations=transformations) == f(x)*(y+1)*z\n"], "sample_1026": ["def test_lambdify_with_function_as_input():\n    f = Function('f')\n    g = Function('g')\n    h = Function('h')\n    expr = f(g(x)) + h(x)\n    lam = lambdify(x, expr)\n    assert lam(1) == f(g(1)) + h(1)\n"], "sample_437": ["    def test_validate_thread_sharing(self):\n        conn = connections[DEFAULT_DB_ALIAS]\n        with patch.object(conn, \"_thread_ident\", return_value=123):\n            with self.assertRaises(DatabaseError):\n                conn.validate_thread_sharing()\n"], "sample_1155": ["def test_algebraic_domain():\n    # Test algebraic domain construction with multiple algebraic numbers\n    alg = QQ.algebraic_field(sqrt(2) + sqrt(3))\n    assert construct_domain([7, sqrt(2), sqrt(3), sqrt(2) + sqrt(3)], extension=True) == \\\n        (alg, [alg.convert(7), alg.convert(sqrt(2)), alg.convert(sqrt(3)), alg.convert(sqrt(2) + sqrt(3))])\n\n    # Test algebraic domain construction with nested algebraic numbers\n    alg = QQ.algebraic_field(sqrt(2) + sqrt(sqrt(3)))\n    assert construct_domain([7, sqrt(2), sqrt(3), sqrt(2) + sqrt(sqrt(3))], extension=True) == \\\n        (alg, [alg.convert(7), alg.convert(sqrt(2)), alg.convert(sqrt(3)), alg.convert(sqrt(2) + sqrt(sqrt(3)))])\n"], "sample_1036": ["def test_mul_as_coeff_Mul():\n    assert (2*x).as_coeff_Mul() == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (-2*x).as_coeff_Mul() == (-1, 2*x)\n    assert (-2*x).as_coeff_Mul(rational=False) == (-1, 2*x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=True) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=True) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=True) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=True) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=True) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=True) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=True) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=True) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=True) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=True) == (2, x)\n    assert (2*x).as_coeff_Mul(rational=False) == (2, x)\n    assert ("], "sample_1058": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n\n    assert prntr._print_Infinity(S.Infinity) == 'float(\"inf\")'\n    assert prntr._print_NegativeInfinity(S.NegativeInfinity) == 'float(\"-inf\")'\n    assert prntr._print_ComplexInfinity(S.ComplexInfinity) == 'float(\"nan\")'\n    assert prntr._print_NaN(S.NaN) == 'float(\"nan\")'\n\n    assert prntr._print_ImaginaryUnit(S.ImaginaryUnit) == '1j'\n\n    assert prntr._print_FunctionDefinition(Assignment(x, 2)) == 'def x:\\n    2'\n\n    assert prntr._print_While(Assignment(x, 2)) == 'while True:\\n    x = 2'\n\n    assert prntr._print_Declaration(Assignment(x, 2)) == 'x = 2'\n\n    assert prntr._print_Return(Assignment(x, 2)) == 'return x = 2'\n\n    assert prntr._print_Print(Assignment(x, 2)) == 'print(x = 2)'\n\n    assert prntr._print_Stream(x) == 'x'\n\n    assert prntr._print_NoneToken(None) == 'None'\n"], "sample_586": ["def test_concat_positions_kwarg():\n    ds1 = Dataset({\"a\": (\"x\", [1, 2])}, {\"x\": [0, 1]})\n    ds2 = Dataset({\"a\": (\"x\", [3, 4])}, {\"x\": [0, 1]})\n    expected = Dataset({\"a\": ((\"y\", \"x\"), [[1, 2], [3, 4]])}, {\"x\": [0, 1], \"y\": [0, 1]})\n    actual = concat([ds1, ds2], dim=\"y\", positions=[0, 1])\n    assert_identical(expected, actual)\n\n    with raises_regex(ValueError, \"length of positions does not match\"):\n        concat([ds1, ds2], dim=\"y\", positions=[0])\n\n    with raises_regex(ValueError, \"positions must be integer arrays\"):\n        concat([ds1, ds2], dim=\"y\", positions=[0.0, 1.0])\n"], "sample_780": ["def test_lda_doc_topic_prior():\n    # Test LDA with different doc_topic_prior\n    n_components, X = _build_sparse_mtx()\n    lda_1 = LatentDirichletAllocation(n_components=n_components,\n                                      doc_topic_prior=0.5, random_state=0)\n    lda_2 = LatentDirichletAllocation(n_components=n_components,\n                                      doc_topic_prior=1.0, random_state=0)\n    lda_3 = LatentDirichletAllocation(n_components=n_components,\n                                      doc_topic_prior=1.5, random_state=0)\n    lda_1.fit(X)\n    lda_2.fit(X)\n    lda_3.fit(X)\n    assert_array_almost_equal(lda_1.components_, lda_2.components_)\n    assert_array_almost_equal(lda_1.components_, lda_3.components_)\n"], "sample_1069": ["def test_glsl_code():\n    assert glsl_code(x**2) == \"pow(x, 2.0)\"\n    assert glsl_code(x**2, assign_to=\"float y\") == \"float y = pow(x, 2.0);\"\n    assert glsl_code(x**2, use_operators=False) == \"mul(x, x)\"\n    assert glsl_code(x**2, use_operators=False, assign_to=\"float y\") == \"float y = mul(x, x);\"\n    assert glsl_code(x**2, glsl_types=False) == \"float[1](pow(x, 2.0))\"\n    assert glsl_code(x**2, glsl_types=False, assign_to=\"float y\") == \"float y = float[1](pow(x, 2.0));\"\n    assert glsl_code(x**2, mat_nested=True) == \"float[1][1](pow(x, 2.0))\"\n    assert glsl_code(x**2, mat_nested=True, assign_to=\"float y\") == \"float y = float[1][1](pow(x, 2.0));\"\n    assert glsl_code(x**2, mat_transpose=True) == \"pow(x, 2.0)\"\n    assert glsl_code(x**2, mat_transpose=True, assign_to=\"float y\") == \"float y = pow(x, 2.0);\"\n    assert glsl_code(x**2, precision=10) == \"pow(x, 2.0)\"\n    assert glsl_code(x**2, precision=10, assign_to=\"float y\") == \"float y = pow(x, 2.0);\"\n    assert glsl_code(x**2, user_functions={\"sin\": \"my_sin\"}) == \"pow(x, 2.0)\"\n    assert glsl_code(x**2, user_functions={\"sin\": \"my_sin\"}, assign_to=\"float y\") == \"float y = pow(x, 2.0);\"\n    assert glsl_code(x**2, human=False) == (\"\", set(), \"pow(x, 2.0)\")\n    assert glsl_code(x**2, human=False, assign_to=\"float y\") == (\"\", set(), \"float y = pow(x, 2.0);\")\n    assert glsl_code(x**2, contract=False) == \"pow(x, 2.0)\"\n    assert glsl_code"], "sample_874": ["def test_clone():\n    \"\"\"Test the clone function.\"\"\"\n    # Test cloning a simple estimator\n    estimator = StepSelector(step=2)\n    cloned_estimator = clone(estimator)\n    assert estimator.get_params() == cloned_estimator.get_params()\n\n    # Test cloning a fitted estimator\n    estimator.fit(X, y)\n    cloned_estimator = clone(estimator)\n    assert estimator.get_params() == cloned_estimator.get_params()\n\n    # Test cloning a list of estimators\n    estimators = [StepSelector(step=2), StepSelector(step=3)]\n    cloned_estimators = clone(estimators)\n    for est, cloned_est in zip(estimators, cloned_estimators):\n        assert est.get_params() == cloned_est.get_params()\n\n    # Test cloning a tuple of estimators\n    estimators = (StepSelector(step=2), StepSelector(step=3))\n    cloned_estimators = clone(estimators)\n    for est, cloned_est in zip(estimators, cloned_estimators):\n        assert est.get_params() == cloned_est.get_params()\n\n    # Test cloning a set of estimators\n    estimators = {StepSelector(step=2), StepSelector(step=3)}\n    cloned_estimators = clone(estimators)\n    for est, cloned_est in zip(estimators, cloned_estimators):\n        assert est.get_params() == cloned_est.get_params()\n\n    # Test cloning a frozenset of estimators\n    estimators = frozenset({StepSelector(step=2), StepSelector(step=3)})\n    cloned_estimators = clone(estimators)\n    for est, cloned_est in zip(estimators, cloned_estimators):\n        assert est.get_params() == cloned_est.get_params()\n"], "sample_1142": ["def test_matrix_element_derivative():\n    i, j = symbols('i j')\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    assert A[i, j].diff(A[0, 0]) == KroneckerDelta(i, 0, (0, 1))*KroneckerDelta(j, 0, (0, 1))\n    assert A[i, j].diff(B[0, 0]) == 0\n    assert A[i, j].diff(i) == 0\n    assert A[i, j].diff(j) == 0\n    assert A[i, j].diff(x) == 0\n"], "sample_825": ["def test_pls_algorithm():\n    # Test that nipals and svd algorithms give the same results\n    d = load_linnerud()\n    X = d.data\n    Y = d.target\n\n    pls_nipals = pls_.PLSRegression(n_components=X.shape[1], algorithm=\"nipals\")\n    pls_svd = pls_.PLSRegression(n_components=X.shape[1], algorithm=\"svd\")\n\n    pls_nipals.fit(X, Y)\n    pls_svd.fit(X, Y)\n\n    assert_array_almost_equal(pls_nipals.x_weights_, pls_svd.x_weights_, decimal=5)\n    assert_array_almost_equal(pls_nipals.y_weights_, pls_svd.y_weights_, decimal=5)\n    assert_array_almost_equal(pls_nipals.x_loadings_, pls_svd.x_loadings_, decimal=5)\n    assert_array_almost_equal(pls_nipals.y_loadings_, pls_svd.y_loadings_, decimal=5)\n    assert_array_almost_equal(pls_nipals.x_scores_, pls_svd.x_scores_, decimal=5)\n    assert_array_almost_equal(pls_nipals.y_scores_, pls_svd.y_scores_, decimal=5)\n    assert_array_almost_equal(pls_nipals.x_rotations_, pls_svd.x_rotations_, decimal=5)\n    assert_array_almost_equal(pls_nipals.y_rotations_, pls_svd.y_rotations_, decimal=5)\n    assert_array_almost_equal(pls_nipals.coef_, pls_svd.coef_, decimal=5)\n"], "sample_976": ["def test_Wild_exclude():\n    x = Symbol(\"x\")\n    y = Symbol(\"y\")\n    z = Symbol(\"z\")\n\n    w = Wild(\"w\", exclude=[x, y])\n    assert z.match(w) == {w_: z}\n    assert x.match(w) is None\n    assert y.match(w) is None\n\n    w = Wild(\"w\", exclude=[x])\n    assert y.match(w) == {w_: y}\n    assert z.match(w) == {w_: z}\n    assert x.match(w) is None\n\n    w = Wild(\"w\")\n    assert x.match(w) == {w_: x}\n    assert y.match(w) == {w_: y}\n    assert z.match(w) == {w_: z}\n"], "sample_948": ["def test_template_parameter_lists():\n    check('function', 'template<typename T> void f(T)', {2: 'I0E1f1T'})\n    check('function', 'template<typename T, typename U> void f(T, U)',\n          {2: 'I00E1f1T1U'})\n    check('function', 'template<typename T, typename U, typename V> void f(T, U, V)',\n          {2: 'I000E1f1T1U1V'})\n    check('function', 'template<typename T, typename U, typename V, typename W> void f(T, U, V, W)',\n          {2: 'I0000E1f1T1U1V1W'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X> void f(T, U, V, W, X)',\n          {2: 'I00000E1f1T1U1V1W1X'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> void f(T, U, V, W, X, Y)',\n          {2: 'I000000E1f1T1U1V1W1X1Y'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> void f(T, U, V, W, X, Y, Z)',\n          {2: 'I0000000E1f1T1U1V1W1X1Y1Z'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A> void f(T, U, V, W, X, Y, Z, A)',\n          {2: 'I00000000E1f1T1U1V1W1X1Y1Z1A'})\n    check('function', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename A, typename B> void f(T, U, V, W, X, Y, Z, A, B)',\n          {2: 'I000000000E1f1T1U1V1W1X1Y1Z1A1B'})\n"], "sample_303": ["def test_runshell_use_environ_with_custom_env(self):\n    custom_env = {'CUSTOM_VAR': 'custom_value'}\n    with self.subTest(env=custom_env):\n        with mock.patch('subprocess.run') as run:\n            with mock.patch.object(\n                BaseDatabaseClient,\n                'settings_to_cmd_args_env',\n                return_value=([], custom_env),\n            ):\n                self.client.runshell(None)\n            run.assert_called_once_with([], env={'CUSTOM_VAR': 'custom_value', **os.environ}, check=True)\n"], "sample_1126": ["def test_dagger_addition():\n    A = Operator('A')\n    B = Operator('B')\n    assert Dagger(A + B) == Dagger(A) + Dagger(B)\n    assert Dagger(A + 2) == Dagger(A) + 2\n    assert Dagger(2 + A) == 2 + Dagger(A)\n    assert Dagger(A + I) == Dagger(A) - I\n"], "sample_1116": ["def test_inverse_derivative():\n    x = symbols('x')\n    A = MatrixSymbol('A', 3, 3)\n    assert isinstance(Inverse(A)._eval_derivative_matrix_lines(x), list)\n    assert len(Inverse(A)._eval_derivative_matrix_lines(x)) == 3\n    assert all(isinstance(line.first_pointer, Inverse) for line in Inverse(A)._eval_derivative_matrix_lines(x))\n    assert all(isinstance(line.second_pointer, Inverse) for line in Inverse(A)._eval_derivative_matrix_lines(x))\n"], "sample_1034": ["def test_apply_grover_iterations():\n    nqubits = 2\n    oracle = return_one_on_one\n    iterations = 1\n    expected = IntQubit(1, nqubits=nqubits)\n    assert apply_grover(oracle, nqubits, iterations) == expected\n\n    nqubits = 4\n    oracle = return_one_on_two\n    iterations = 3\n    basis_states = superposition_basis(nqubits)\n    expected = (-13*basis_states)/64 + 264*IntQubit(2, nqubits)/256\n    assert apply_grover(oracle, nqubits, iterations) == qapply(expected)\n\n    nqubits = 3\n    oracle = lambda qubits: qubits == IntQubit(5, nqubits=nqubits)\n    iterations = 2\n    basis_states = superposition_basis(nqubits)\n    v = OracleGate(nqubits, oracle)\n    iterated = grover_iteration(basis_states, v)\n    iterated = qapply(iterated)\n    iterated = grover_iteration(iterated, v)\n    expected = qapply(iterated)\n    assert apply_grover(oracle, nqubits, iterations) == expected\n"], "sample_1106": ["def test_matadd_doit():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    X = MatAdd(A, B, C)\n    assert X.doit().args == (A.doit(), B.doit(), C.doit())\n"], "sample_779": ["def test_check_class_weight_classifiers():\n    # check that class_weight='balanced' raises an exception\n    # when the class_weight is ill-computed\n    assert_raises_regex(AssertionError,\n                        \"Classifier BadBalancedWeightsClassifier is not \"\n                        \"computing class_weight=balanced properly.\",\n                        check_class_weight_classifiers,\n                        'BadBalancedWeightsClassifier',\n                        BadBalancedWeightsClassifier())\n"], "sample_454": ["    def test_eq(self):\n        constraint1 = models.ExclusionConstraint(\n            expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n            name=\"exclusion\",\n        )\n        constraint2 = models.ExclusionConstraint(\n            expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n            name=\"exclusion\",\n        )\n        self.assertEqual(constraint1, constraint2)\n        self.assertEqual(constraint1, mock.ANY)\n        self.assertNotEqual(\n            constraint1,\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n                name=\"exclusion2\",\n            ),\n        )\n        self.assertNotEqual(\n            constraint1,\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"~~\"), (\"field2\", \"&&\")],\n                name=\"exclusion\",\n            ),\n        )\n        self.assertNotEqual(\n            constraint1,\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"&&\"), (\"field3\", \"~~\")],\n                name=\"exclusion\",\n            ),\n        )\n        self.assertNotEqual(constraint1, 1)\n        self.assertNotEqual(\n            constraint1,\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n                name=\"exclusion\",\n                violation_error_message=\"custom error\",\n            ),\n        )\n        self.assertNotEqual(\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n                name=\"exclusion\",\n                violation_error_message=\"custom error\",\n            ),\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n                name=\"exclusion\",\n                violation_error_message=\"other custom error\",\n            ),\n        )\n        self.assertEqual(\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n                name=\"exclusion\",\n                violation_error_message=\"custom error\",\n            ),\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n                name=\"exclusion\",\n                violation_error_message=\"custom error\",\n            ),\n        )\n        self.assertNotEqual(\n            models.ExclusionConstraint(\n                expressions=[(\"field1\", \"&&\"), (\"field2\", \"~~\")],\n                name=\"exclusion\",\n                violation_error_code"], "sample_1076": ["def test_AbstractPythonCodePrinter():\n    prntr = AbstractPythonCodePrinter()\n\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n\n    assert prntr.doprint(pi) == 'math.pi'\n    assert prntr.module_imports == {'math': {'pi'}}\n\n    assert prntr.doprint(x**Rational(1, 2)) == 'math.sqrt(x)'\n    assert prntr.doprint(sqrt(x)) == 'math.sqrt(x)'\n    assert prntr.module_imports == {'math': {'pi', 'sqrt'}}\n\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\n"], "sample_243": ["def test_is_nullable(self):\n    query = Query(Item)\n    self.assertTrue(query.is_nullable(Item._meta.get_field('name')))\n    self.assertFalse(query.is_nullable(Item._meta.get_field('id')))\n"], "sample_1158": ["def test_sympify_numpy_array_with_object_dtype():\n    if not numpy:\n        skip(\"numpy not installed.\")\n\n    a = numpy.array([1, 2, 3], dtype=object)\n    b = numpy.array([x, y, x + y], dtype=object)\n    c = numpy.array([1, x, y], dtype=object)\n\n    assert sympify(a) == ImmutableDenseNDimArray([1, 2, 3])\n    assert sympify(b) == ImmutableDenseNDimArray([x, y, x + y])\n    assert sympify(c) == ImmutableDenseNDimArray([1, x, y])\n"], "sample_1005": ["def test_latex_MatPow():\n    from sympy import MatrixSymbol\n    from sympy.printing.latex import LatexPrinter\n    X = MatrixSymbol('X', 2, 2)\n    Y = MatrixSymbol('Y', 2, 2)\n    x = Symbol('x')\n    l = LatexPrinter()\n    assert l._print_MatPow(X**2) == r\"X^{2}\"\n    assert l._print_MatPow(X**-2) == r\"X^{-2}\"\n    assert l._print_MatPow(X**x) == r\"X^{x}\"\n    assert l._print_MatPow(X**-x) == r\"X^{-x}\"\n    assert l._print_MatPow(X**2*Y) == r\"X^{2} Y\"\n    assert l._print_MatPow(X**2*Y**2) == r\"X^{2} Y^{2}\"\n    assert l._print_MatPow(X**2*Y**-2) == r\"X^{2} Y^{-2}\"\n    assert l._print_MatPow(X**-2*Y**2) == r\"X^{-2} Y^{2}\"\n    assert l._print_MatPow(X**-2*Y**-2) == r\"X^{-2} Y^{-2}\"\n    assert l._print_MatPow(X**x*Y**2) == r\"X^{x} Y^{2}\"\n    assert l._print_MatPow(X**x*Y**-2) == r\"X^{x} Y^{-2}\"\n    assert l._print_MatPow(X**-x*Y**2) == r\"X^{-x} Y^{2}\"\n    assert l._print_MatPow(X**-x*Y**-2) == r\"X^{-x} Y^{-2}\"\n"], "sample_973": ["def test_isabstractmethod():\n    class AbstractBaseClass:\n        @abstractmethod\n            pass\n\n    class ConcreteClass(AbstractBaseClass):\n            pass\n\n    assert inspect.isabstractmethod(AbstractBaseClass.abstract_method) is True\n    assert inspect.isabstractmethod(ConcreteClass.abstract_method) is False\n    assert inspect.isabstractmethod(AbstractBaseClass) is False\n    assert inspect.isabstractmethod(ConcreteClass) is False\n"], "sample_906": ["def test_domain_cpp_ast_template_parameter_lists():\n    check('class', 'template<template<typename> class T> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> typename T> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> typename... T> {key}A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename...> {key}A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> class T = std::vector<int>> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> typename T = std::vector<int>> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename> typename... T = std::vector<int>> {key}A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename...> {key}A', {2: 'II0EDpE1A'})\n\n    check('class', 'template<template<typename> class... T> {key}A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename... T> {key}A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename...> {key}A', {2: 'II0EDpE1A'})\n\n    check('class', 'template<template<typename> class T, template<typename> class U> {key}A', {2: 'II0E0EII0E0E1A'})\n    check('class', 'template<template<typename> typename T, template<typename> typename U> {key}A', {2: 'II0E0EII0E0E1A'})\n    check('class', 'template<template<typename> typename... T, template<typename> typename... U> {key}A', {2: 'II0EDpEII0EDpE1A'})\n    check('class', 'template<template<typename> typename"], "sample_843": ["def test_kernel_bounds(kernel):\n    # Check that bounds of kernel are correctly set and retrieved.\n    bounds = kernel.bounds\n    assert bounds.shape[0] == kernel.n_dims\n    assert bounds.shape[1] == 2\n\n    # Check that bounds are correctly set via theta\n    theta = kernel.theta\n    kernel.theta = np.log(np.exp(theta) + 1)\n    new_bounds = kernel.bounds\n    assert_array_almost_equal(np.exp(new_bounds), np.exp(bounds) + 1)\n"]}, "raw_scored_generations": {"sample_0": [false], "sample_3": [false], "sample_1": [false], "sample_2": [true], "sample_4": [false], "sample_5": [false], "sample_6": [false], "sample_7": [false], "sample_8": [false], "sample_9": [false], "sample_10": [true], "sample_11": [false], "sample_12": [false], "sample_13": [false], "sample_14": [false], "sample_15": [true], "sample_16": [false], "sample_17": [false], "sample_18": [false], "sample_19": [false], "sample_20": [false], "sample_21": [false], "sample_22": [false], "sample_23": [false], "sample_24": [false], "sample_25": [false], "sample_26": [false], "sample_27": [false], "sample_28": [false], "sample_29": [false], "sample_30": [false], "sample_31": [false], "sample_32": [true], "sample_33": [true], "sample_34": [false], "sample_35": [false], "sample_36": [false], "sample_37": [true], "sample_38": [false], "sample_39": [false], "sample_40": [true], "sample_41": [false], "sample_42": [true], "sample_43": [false], "sample_44": [false], "sample_45": [true], "sample_46": [false], "sample_47": [false], "sample_48": [true], "sample_49": [false], "sample_50": [false], "sample_51": [true], "sample_52": [true], "sample_54": [true], "sample_53": [true], "sample_55": [false], "sample_58": [true], "sample_56": [true], "sample_57": [false], "sample_59": [true], "sample_60": [false], "sample_61": [true], "sample_62": [false], "sample_63": [true], "sample_64": [false], "sample_65": [true], "sample_67": [false], "sample_66": [true], "sample_68": [true], "sample_69": [false], "sample_70": [true], "sample_71": [false], "sample_72": [false], "sample_73": [false], "sample_75": [false], "sample_74": [false], "sample_76": [true], "sample_77": [true], "sample_78": [false], "sample_79": [false], "sample_80": [true], "sample_82": [true], "sample_81": [false], "sample_83": [false], "sample_85": [false], "sample_84": [false], "sample_86": [false], "sample_88": [true], "sample_87": [false], "sample_89": [false], "sample_90": [false], "sample_91": [true], "sample_92": [false], "sample_93": [false], "sample_94": [false], "sample_95": [false], "sample_98": [false], "sample_96": [true], "sample_99": [false], "sample_97": [false], "sample_100": [false], "sample_102": [true], "sample_101": [false], "sample_103": [true], "sample_104": [false], "sample_107": [true], "sample_106": [false], "sample_105": [false], "sample_108": [false], "sample_109": [true], "sample_111": [true], "sample_110": [false], "sample_112": [true], "sample_113": [false], "sample_114": [true], "sample_115": [true], "sample_116": [true], "sample_117": [true], "sample_118": [true], "sample_119": [true], "sample_120": [false], "sample_121": [true], "sample_122": [false], "sample_123": [false], "sample_124": [true], "sample_125": [true], "sample_126": [true], "sample_127": [true], "sample_128": [false], "sample_129": [false], "sample_130": [true], "sample_131": [false], "sample_132": [false], "sample_133": [true], "sample_135": [true], "sample_134": [true], "sample_136": [true], "sample_139": [true], "sample_137": [true], "sample_138": [false], "sample_140": [false], "sample_141": [true], "sample_142": [true], "sample_143": [true], "sample_144": [true], "sample_145": [true], "sample_146": [true], "sample_147": [true], "sample_148": [true], "sample_151": [true], "sample_149": [false], "sample_152": [true], "sample_150": [false], "sample_153": [false], "sample_154": [true], "sample_155": [true], "sample_156": [false], "sample_157": [false], "sample_158": [false], "sample_159": [false], "sample_160": [false], "sample_161": [false], "sample_162": [true], "sample_163": [false], "sample_164": [false], "sample_165": [false], "sample_166": [true], "sample_167": [false], "sample_168": [true], "sample_169": [true], "sample_171": [true], "sample_170": [false], "sample_172": [false], "sample_173": [true], "sample_174": [true], "sample_175": [true], "sample_176": [true], "sample_177": [true], "sample_178": [true], "sample_180": [true], "sample_179": [false], "sample_182": [true], "sample_181": [true], "sample_183": [false], "sample_184": [true], "sample_185": [true], "sample_186": [true], "sample_187": [true], "sample_188": [false], "sample_189": [false], "sample_190": [true], "sample_191": [false], "sample_192": [true], "sample_193": [false], "sample_194": [true], "sample_195": [false], "sample_196": [true], "sample_198": [false], "sample_197": [true], "sample_199": [true], "sample_200": [true], "sample_201": [true], "sample_202": [true], "sample_203": [false], "sample_204": [false], "sample_205": [true], "sample_206": [false], "sample_207": [true], "sample_208": [true], "sample_209": [true], "sample_210": [false], "sample_211": [false], "sample_213": [false], "sample_212": [true], "sample_214": [true], "sample_215": [false], "sample_216": [true], "sample_217": [false], "sample_218": [true], "sample_219": [false], "sample_220": [true], "sample_221": [true], "sample_222": [true], "sample_223": [true], "sample_224": [true], "sample_225": [false], "sample_226": [false], "sample_227": [false], "sample_228": [false], "sample_229": [true], "sample_230": [true], "sample_231": [false], "sample_232": [true], "sample_233": [true], "sample_234": [true], "sample_235": [true], "sample_236": [true], "sample_237": [false], "sample_238": [true], "sample_239": [true], "sample_240": [true], "sample_241": [false], "sample_242": [false], "sample_243": [true], "sample_244": [false], "sample_245": [true], "sample_246": [true], "sample_247": [true], "sample_248": [true], "sample_249": [false], "sample_250": [true], "sample_251": [true], "sample_252": [true], "sample_253": [false], "sample_254": [false], "sample_256": [true], "sample_255": [false], "sample_257": [true], "sample_258": [false], "sample_259": [true], "sample_260": [true], "sample_261": [true], "sample_262": [false], "sample_263": [true], "sample_264": [true], "sample_265": [true], "sample_266": [true], "sample_267": [false], "sample_268": [false], "sample_269": [true], "sample_270": [false], "sample_271": [false], "sample_272": [true], "sample_273": [false], "sample_274": [false], "sample_275": [false], "sample_276": [false], "sample_277": [true], "sample_278": [false], "sample_279": [true], "sample_280": [true], "sample_281": [true], "sample_282": [true], "sample_283": [true], "sample_284": [false], "sample_285": [true], "sample_286": [true], "sample_287": [true], "sample_288": [true], "sample_289": [false], "sample_290": [true], "sample_291": [false], "sample_292": [true], "sample_293": [false], "sample_294": [true], "sample_295": [false], "sample_296": [true], "sample_297": [false], "sample_298": [true], "sample_299": [true], "sample_300": [true], "sample_301": [false], "sample_302": [false], "sample_303": [true], "sample_304": [false], "sample_305": [true], "sample_306": [false], "sample_307": [true], "sample_308": [true], "sample_309": [false], "sample_310": [false], "sample_312": [true], "sample_311": [false], "sample_313": [true], "sample_314": [true], "sample_315": [false], "sample_316": [false], "sample_317": [false], "sample_318": [false], "sample_319": [false], "sample_320": [true], "sample_321": [true], "sample_322": [true], "sample_323": [false], "sample_324": [true], "sample_325": [true], "sample_326": [true], "sample_327": [true], "sample_328": [true], "sample_329": [false], "sample_330": [false], "sample_331": [false], "sample_332": [true], "sample_333": [true], "sample_334": [true], "sample_335": [true], "sample_336": [false], "sample_337": [true], "sample_338": [true], "sample_339": [false], "sample_340": [false], "sample_341": [true], "sample_342": [true], "sample_343": [false], "sample_344": [true], "sample_345": [false], "sample_346": [false], "sample_347": [true], "sample_348": [false], "sample_349": [true], "sample_350": [true], "sample_351": [true], "sample_352": [false], "sample_353": [true], "sample_354": [true], "sample_355": [false], "sample_356": [true], "sample_357": [true], "sample_358": [false], "sample_359": [true], "sample_360": [false], "sample_361": [true], "sample_362": [true], "sample_363": [true], "sample_364": [false], "sample_365": [true], "sample_366": [false], "sample_367": [false], "sample_368": [true], "sample_369": [true], "sample_370": [false], "sample_371": [false], "sample_372": [false], "sample_373": [false], "sample_374": [false], "sample_375": [false], "sample_376": [true], "sample_377": [false], "sample_378": [false], "sample_379": [true], "sample_380": [true], "sample_381": [true], "sample_382": [true], "sample_383": [true], "sample_384": [true], "sample_385": [true], "sample_386": [false], "sample_387": [true], "sample_388": [false], "sample_389": [false], "sample_390": [true], "sample_391": [true], "sample_392": [true], "sample_393": [true], "sample_394": [false], "sample_395": [true], "sample_396": [true], "sample_397": [true], "sample_398": [false], "sample_399": [true], "sample_400": [true], "sample_401": [true], "sample_402": [true], "sample_403": [true], "sample_404": [true], "sample_405": [true], "sample_406": [false], "sample_407": [true], "sample_408": [true], "sample_409": [true], "sample_410": [true], "sample_411": [true], "sample_412": [true], "sample_413": [false], "sample_414": [true], "sample_415": [false], "sample_416": [true], "sample_417": [false], "sample_418": [false], "sample_419": [false], "sample_420": [false], "sample_421": [false], "sample_422": [false], "sample_423": [true], "sample_424": [true], "sample_425": [true], "sample_426": [true], "sample_427": [true], "sample_428": [false], "sample_429": [true], "sample_430": [false], "sample_431": [true], "sample_432": [true], "sample_433": [true], "sample_434": [false], "sample_435": [true], "sample_436": [false], "sample_437": [false], "sample_438": [false], "sample_439": [true], "sample_440": [true], "sample_441": [false], "sample_442": [true], "sample_443": [false], "sample_444": [true], "sample_445": [true], "sample_446": [false], "sample_447": [true], "sample_448": [true], "sample_449": [false], "sample_450": [true], "sample_451": [true], "sample_453": [true], "sample_452": [true], "sample_454": [false], "sample_455": [true], "sample_456": [false], "sample_457": [true], "sample_458": [false], "sample_459": [false], "sample_460": [false], "sample_461": [false], "sample_462": [true], "sample_463": [true], "sample_464": [true], "sample_465": [false], "sample_466": [true], "sample_467": [true], "sample_469": [true], "sample_468": [true], "sample_470": [true], "sample_471": [false], "sample_472": [true], "sample_473": [false], "sample_474": [false], "sample_475": [true], "sample_476": [false], "sample_477": [true], "sample_478": [true], "sample_479": [true], "sample_480": [true], "sample_481": [false], "sample_482": [false], "sample_483": [true], "sample_484": [false], "sample_485": [true], "sample_486": [true], "sample_487": [true], "sample_488": [false], "sample_489": [true], "sample_490": [true], "sample_491": [true], "sample_492": [true], "sample_493": [true], "sample_494": [true], "sample_495": [true], "sample_496": [false], "sample_497": [true], "sample_498": [true], "sample_499": [true], "sample_500": [false], "sample_501": [false], "sample_502": [false], "sample_503": [true], "sample_504": [false], "sample_505": [true], "sample_506": [false], "sample_507": [true], "sample_508": [false], "sample_509": [false], "sample_510": [false], "sample_511": [false], "sample_512": [false], "sample_513": [true], "sample_514": [false], "sample_515": [false], "sample_516": [false], "sample_517": [false], "sample_518": [false], "sample_519": [true], "sample_520": [false], "sample_521": [false], "sample_522": [true], "sample_523": [true], "sample_524": [false], "sample_525": [true], "sample_526": [false], "sample_527": [false], "sample_528": [true], "sample_529": [true], "sample_530": [true], "sample_531": [false], "sample_532": [false], "sample_533": [false], "sample_534": [false], "sample_535": [false], "sample_536": [false], "sample_537": [false], "sample_538": [false], "sample_539": [true], "sample_540": [false], "sample_541": [false], "sample_542": [false], "sample_543": [false], "sample_544": [false], "sample_545": [true], "sample_546": [false], "sample_547": [false], "sample_548": [false], "sample_549": [false], "sample_550": [true], "sample_551": [false], "sample_552": [false], "sample_553": [false], "sample_554": [false], "sample_555": [false], "sample_556": [false], "sample_557": [true], "sample_558": [false], "sample_559": [false], "sample_560": [true], "sample_561": [true], "sample_562": [true], "sample_563": [false], "sample_564": [false], "sample_565": [false], "sample_566": [true], "sample_567": [false], "sample_568": [false], "sample_569": [false], "sample_570": [true], "sample_571": [false], "sample_572": [true], "sample_573": [false], "sample_574": [false], "sample_575": [false], "sample_576": [true], "sample_577": [false], "sample_578": [false], "sample_579": [false], "sample_580": [false], "sample_581": [false], "sample_582": [false], "sample_583": [true], "sample_584": [true], "sample_585": [false], "sample_586": [false], "sample_587": [true], "sample_588": [true], "sample_589": [false], "sample_590": [false], "sample_591": [false], "sample_592": [false], "sample_593": [false], "sample_594": [false], "sample_595": [false], "sample_596": [false], "sample_597": [false], "sample_598": [false], "sample_599": [false], "sample_600": [false], "sample_601": [false], "sample_602": [true], "sample_603": [false], "sample_604": [false], "sample_605": [false], "sample_606": [false], "sample_607": [false], "sample_608": [true], "sample_609": [false], "sample_610": [false], "sample_611": [true], "sample_612": [false], "sample_613": [false], "sample_614": [true], "sample_615": [false], "sample_616": [false], "sample_617": [false], "sample_618": [true], "sample_619": [false], "sample_620": [true], "sample_621": [false], "sample_622": [true], "sample_623": [false], "sample_624": [true], "sample_625": [true], "sample_626": [false], "sample_627": [true], "sample_628": [false], "sample_629": [false], "sample_630": [false], "sample_631": [false], "sample_632": [false], "sample_633": [false], "sample_634": [false], "sample_635": [false], "sample_636": [false], "sample_637": [false], "sample_638": [false], "sample_639": [false], "sample_640": [false], "sample_641": [false], "sample_642": [false], "sample_643": [false], "sample_644": [false], "sample_645": [false], "sample_646": [false], "sample_647": [false], "sample_648": [false], "sample_649": [false], "sample_650": [false], "sample_651": [false], "sample_652": [true], "sample_653": [false], "sample_654": [true], "sample_655": [false], "sample_656": [false], "sample_657": [false], "sample_658": [false], "sample_659": [false], "sample_660": [false], "sample_661": [false], "sample_662": [false], "sample_663": [false], "sample_664": [false], "sample_665": [false], "sample_666": [false], "sample_667": [false], "sample_668": [false], "sample_669": [false], "sample_670": [false], "sample_671": [false], "sample_672": [false], "sample_673": [false], "sample_674": [false], "sample_675": [false], "sample_676": [false], "sample_677": [false], "sample_678": [true], "sample_679": [false], "sample_680": [false], "sample_681": [false], "sample_682": [false], "sample_683": [false], "sample_684": [false], "sample_685": [false], "sample_686": [false], "sample_687": [false], "sample_688": [false], "sample_689": [false], "sample_690": [false], "sample_691": [false], "sample_692": [true], "sample_693": [false], "sample_694": [false], "sample_695": [false], "sample_696": [false], "sample_697": [false], "sample_698": [false], "sample_699": [false], "sample_700": [false], "sample_701": [false], "sample_702": [false], "sample_703": [false], "sample_704": [false], "sample_705": [true], "sample_706": [false], "sample_707": [false], "sample_708": [false], "sample_709": [false], "sample_710": [false], "sample_711": [false], "sample_712": [false], "sample_713": [false], "sample_714": [false], "sample_715": [true], "sample_716": [false], "sample_717": [true], "sample_718": [false], "sample_719": [false], "sample_720": [false], "sample_721": [false], "sample_722": [false], "sample_723": [false], "sample_724": [false], "sample_725": [false], "sample_726": [true], "sample_727": [false], "sample_728": [false], "sample_729": [true], "sample_730": [true], "sample_731": [true], "sample_732": [true], "sample_733": [true], "sample_734": [false], "sample_735": [false], "sample_736": [true], "sample_737": [true], "sample_738": [false], "sample_739": [true], "sample_740": [true], "sample_741": [true], "sample_742": [true], "sample_743": [false], "sample_744": [false], "sample_745": [false], "sample_746": [false], "sample_747": [false], "sample_748": [true], "sample_749": [false], "sample_750": [false], "sample_751": [false], "sample_752": [false], "sample_753": [true], "sample_754": [false], "sample_755": [false], "sample_756": [true], "sample_757": [true], "sample_758": [false], "sample_759": [false], "sample_760": [true], "sample_761": [false], "sample_762": [true], "sample_763": [false], "sample_764": [false], "sample_765": [true], "sample_766": [false], "sample_767": [false], "sample_768": [false], "sample_769": [false], "sample_770": [false], "sample_771": [false], "sample_772": [true], "sample_773": [false], "sample_774": [true], "sample_775": [false], "sample_776": [true], "sample_777": [true], "sample_778": [true], "sample_779": [false], "sample_780": [false], "sample_781": [false], "sample_782": [true], "sample_783": [false], "sample_784": [false], "sample_785": [false], "sample_786": [false], "sample_787": [true], "sample_788": [false], "sample_789": [false], "sample_790": [true], "sample_791": [false], "sample_792": [true], "sample_793": [false], "sample_794": [false], "sample_795": [false], "sample_796": [true], "sample_797": [false], "sample_798": [true], "sample_799": [true], "sample_800": [false], "sample_801": [false], "sample_802": [false], "sample_803": [true], "sample_804": [false], "sample_805": [false], "sample_806": [false], "sample_807": [false], "sample_808": [false], "sample_809": [true], "sample_810": [false], "sample_811": [true], "sample_812": [false], "sample_813": [true], "sample_814": [true], "sample_815": [false], "sample_816": [false], "sample_817": [false], "sample_818": [false], "sample_819": [false], "sample_820": [true], "sample_821": [true], "sample_822": [false], "sample_823": [true], "sample_824": [false], "sample_825": [false], "sample_826": [true], "sample_827": [false], "sample_828": [false], "sample_829": [false], "sample_830": [false], "sample_831": [true], "sample_832": [true], "sample_833": [false], "sample_834": [false], "sample_835": [false], "sample_836": [false], "sample_837": [false], "sample_838": [true], "sample_839": [false], "sample_840": [false], "sample_841": [false], "sample_842": [false], "sample_843": [false], "sample_844": [false], "sample_845": [false], "sample_846": [false], "sample_847": [true], "sample_848": [true], "sample_849": [false], "sample_850": [false], "sample_851": [false], "sample_852": [false], "sample_853": [false], "sample_854": [false], "sample_855": [true], "sample_856": [false], "sample_857": [true], "sample_858": [true], "sample_859": [true], "sample_860": [false], "sample_861": [false], "sample_862": [false], "sample_863": [false], "sample_864": [false], "sample_865": [true], "sample_866": [true], "sample_867": [false], "sample_868": [false], "sample_869": [false], "sample_870": [true], "sample_871": [true], "sample_872": [false], "sample_873": [false], "sample_874": [false], "sample_875": [true], "sample_876": [false], "sample_877": [true], "sample_878": [true], "sample_879": [true], "sample_880": [false], "sample_881": [true], "sample_882": [false], "sample_883": [false], "sample_884": [false], "sample_885": [false], "sample_886": [false], "sample_887": [true], "sample_888": [false], "sample_889": [false], "sample_890": [false], "sample_891": [false], "sample_892": [true], "sample_893": [false], "sample_894": [false], "sample_895": [true], "sample_896": [false], "sample_897": [false], "sample_898": [false], "sample_899": [false], "sample_900": [true], "sample_901": [true], "sample_902": [true], "sample_903": [true], "sample_904": [false], "sample_905": [false], "sample_906": [false], "sample_907": [false], "sample_908": [false], "sample_909": [true], "sample_910": [false], "sample_911": [false], "sample_912": [false], "sample_913": [false], "sample_914": [false], "sample_915": [false], "sample_916": [false], "sample_917": [false], "sample_918": [false], "sample_919": [false], "sample_920": [true], "sample_921": [false], "sample_922": [false], "sample_923": [false], "sample_924": [false], "sample_925": [false], "sample_926": [false], "sample_927": [false], "sample_928": [false], "sample_929": [false], "sample_930": [false], "sample_931": [false], "sample_932": [false], "sample_933": [false], "sample_934": [false], "sample_935": [false], "sample_936": [true], "sample_937": [true], "sample_938": [false], "sample_939": [false], "sample_940": [false], "sample_941": [false], "sample_942": [false], "sample_943": [false], "sample_944": [false], "sample_945": [false], "sample_946": [false], "sample_947": [false], "sample_948": [false], "sample_949": [false], "sample_950": [false], "sample_951": [false], "sample_952": [false], "sample_953": [false], "sample_954": [false], "sample_955": [false], "sample_956": [false], "sample_957": [false], "sample_958": [false], "sample_959": [false], "sample_960": [true], "sample_961": [true], "sample_962": [false], "sample_963": [false], "sample_964": [false], "sample_965": [false], "sample_966": [true], "sample_967": [false], "sample_968": [true], "sample_969": [false], "sample_970": [false], "sample_971": [true], "sample_972": [false], "sample_973": [false], "sample_974": [true], "sample_975": [false], "sample_976": [false], "sample_977": [true], "sample_978": [false], "sample_979": [true], "sample_980": [false], "sample_981": [false], "sample_982": [true], "sample_983": [false], "sample_984": [false], "sample_985": [false], "sample_986": [true], "sample_987": [false], "sample_988": [false], "sample_989": [false], "sample_990": [true], "sample_991": [false], "sample_992": [false], "sample_993": [false], "sample_994": [false], "sample_995": [true], "sample_996": [false], "sample_997": [false], "sample_998": [false], "sample_999": [false], "sample_1000": [false], "sample_1001": [false], "sample_1002": [false], "sample_1003": [false], "sample_1004": [false], "sample_1005": [false], "sample_1006": [false], "sample_1007": [false], "sample_1008": [true], "sample_1009": [false], "sample_1010": [true], "sample_1011": [false], "sample_1012": [false], "sample_1013": [false], "sample_1014": [false], "sample_1015": [false], "sample_1016": [false], "sample_1017": [false], "sample_1018": [false], "sample_1019": [false], "sample_1020": [false], "sample_1021": [false], "sample_1022": [false], "sample_1023": [false], "sample_1024": [true], "sample_1025": [false], "sample_1026": [false], "sample_1027": [true], "sample_1028": [false], "sample_1029": [false], "sample_1030": [false], "sample_1031": [false], "sample_1032": [true], "sample_1033": [false], "sample_1034": [true], "sample_1035": [false], "sample_1036": [false], "sample_1037": [true], "sample_1038": [false], "sample_1039": [false], "sample_1040": [true], "sample_1041": [false], "sample_1042": [false], "sample_1043": [false], "sample_1044": [false], "sample_1045": [false], "sample_1046": [false], "sample_1047": [false], "sample_1048": [false], "sample_1049": [false], "sample_1050": [false], "sample_1051": [false], "sample_1052": [true], "sample_1053": [true], "sample_1054": [false], "sample_1055": [false], "sample_1056": [false], "sample_1057": [false], "sample_1058": [false], "sample_1059": [false], "sample_1060": [false], "sample_1061": [false], "sample_1062": [false], "sample_1063": [true], "sample_1064": [true], "sample_1065": [true], "sample_1066": [true], "sample_1067": [false], "sample_1068": [false], "sample_1069": [false], "sample_1070": [false], "sample_1071": [false], "sample_1072": [false], "sample_1073": [false], "sample_1074": [false], "sample_1075": [true], "sample_1076": [false], "sample_1077": [true], "sample_1078": [false], "sample_1079": [true], "sample_1080": [false], "sample_1081": [false], "sample_1082": [false], "sample_1083": [false], "sample_1084": [false], "sample_1085": [false], "sample_1086": [true], "sample_1087": [false], "sample_1088": [false], "sample_1089": [false], "sample_1090": [true], "sample_1091": [false], "sample_1092": [false], "sample_1093": [false], "sample_1094": [false], "sample_1095": [false], "sample_1096": [false], "sample_1097": [false], "sample_1098": [false], "sample_1099": [false], "sample_1100": [true], "sample_1101": [false], "sample_1102": [false], "sample_1103": [false], "sample_1104": [false], "sample_1105": [false], "sample_1106": [false], "sample_1107": [false], "sample_1108": [false], "sample_1109": [false], "sample_1110": [false], "sample_1111": [false], "sample_1112": [true], "sample_1113": [false], "sample_1114": [false], "sample_1115": [false], "sample_1116": [false], "sample_1117": [false], "sample_1118": [false], "sample_1119": [false], "sample_1120": [true], "sample_1121": [false], "sample_1122": [false], "sample_1123": [false], "sample_1124": [false], "sample_1125": [false], "sample_1126": [true], "sample_1127": [false], "sample_1128": [true], "sample_1129": [false], "sample_1130": [true], "sample_1131": [false], "sample_1132": [false], "sample_1133": [false], "sample_1134": [true], "sample_1135": [true], "sample_1136": [false], "sample_1137": [false], "sample_1138": [false], "sample_1139": [false], "sample_1140": [true], "sample_1141": [false], "sample_1142": [true], "sample_1143": [true], "sample_1144": [false], "sample_1145": [true], "sample_1146": [false], "sample_1147": [false], "sample_1148": [true], "sample_1149": [false], "sample_1150": [false], "sample_1151": [false], "sample_1152": [false], "sample_1153": [false], "sample_1154": [false], "sample_1155": [true], "sample_1156": [false], "sample_1157": [false], "sample_1158": [true], "sample_1159": [false], "sample_1160": [false], "sample_1161": [false], "sample_1162": [false], "sample_1163": [false], "sample_1164": [false], "sample_1165": [false], "sample_1166": [false], "sample_1167": [false], "sample_1168": [false], "sample_1169": [false], "sample_1170": [true], "sample_1171": [false], "sample_1172": [false], "sample_1173": [false], "sample_1174": [false], "sample_1175": [false], "sample_1176": [false], "sample_1177": [false], "sample_1178": [false], "sample_1179": [false], "sample_1180": [true], "sample_1181": [true], "sample_1182": [false], "sample_1183": [false], "sample_1184": [false], "sample_1185": [false], "sample_1186": [true], "sample_1187": [true], "sample_1188": [true], "sample_1189": [true], "sample_1190": [false], "sample_1191": [false], "sample_1192": [false], "sample_1193": [false], "sample_1194": [false], "sample_1195": [false], "sample_1196": [false], "sample_1197": [false], "sample_1198": [false], "sample_1199": [false], "sample_1200": [false], "sample_1201": [false], "sample_1202": [false], "sample_1203": [false], "sample_1204": [true], "sample_1205": [false], "sample_1206": [false], "sample_1207": [false], "sample_1208": [true], "sample_1209": [false]}}