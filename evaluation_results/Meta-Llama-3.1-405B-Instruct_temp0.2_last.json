{"raw_generations": {"sample_0": ["def test_self_conversion_via_variance_not_supported(UncertClass):\n    uncert = np.arange(1, 11).reshape(2, 5) * u.adu\n    start_uncert = UncertClass(uncert)\n    with pytest.raises(TypeError):\n        start_uncert.represent_as(UncertClass)\n"], "sample_3": ["def test_ecsv_header_with_comments():\n    \"\"\"Test that comments in the ECSV header are properly handled.\"\"\"\n    txt = \"\"\"\n    # %ECSV 1.0\n    # ---\n    # datatype:\n    # - {name: a, datatype: int64}  # This is a comment\n    # schema: astropy-2.0\n    a\n    1\n    2\n    \"\"\"\n    t = Table.read(txt, format='ascii.ecsv')\n    assert t['a'].dtype == np.int64\n    assert len(t) == 2\n"], "sample_1": ["def test_custom_model_separable():\n    @custom_model\n        return x\n\n    @custom_model(separable=True)\n        return x, y\n\n    assert_allclose(is_separable(model_a()), np.array([True]))\n    assert_allclose(separability_matrix(model_a()), np.array([[True]]))\n    assert_allclose(is_separable(model_b()), np.array([True, True]))\n    assert_allclose(separability_matrix(model_b()), np.array([[True, False], [False, True]]))\n"], "sample_6": ["def test_angle_to_string():\n    \"\"\"\n    Test Angle to_string method.\n    \"\"\"\n    a = Angle(1.2345, unit=u.deg)\n    assert a.to_string(decimal=True) == '1.2345'\n    assert a.to_string(decimal=False) == '1d14m04.2s'\n\n    a = Angle(1.2345, unit=u.hour)\n    assert a.to_string(decimal=True) == '1.2345'\n    assert a.to_string(decimal=False) == '1h14m04.2s'\n\n    a = Angle(1.2345, unit=u.radian)\n    assert a.to_string(decimal=True) == '1.2345'\n    assert a.to_string(decimal=False) == '1.2345rad'\n\n    a = Angle([1.2345, 6.789], unit=u.deg)\n    assert np.array_equal(a.to_string(decimal=True), ['1.2345', '6.789'])\n    assert np.array_equal(a.to_string(decimal=False), ['1d14m04.2s', '6d47m24.0s'])\n\n    a = Angle([1.2345, 6.789], unit=u.hour)\n    assert np.array_equal(a.to_string(decimal=True), ['1.2345', '6.789'])\n    assert np.array_equal(a.to_string(decimal=False), ['1h14m04.2s', '6h47m24.0s'])\n\n    a = Angle([1.2345, 6.789], unit=u.radian)\n    assert np.array_equal(a.to_string(decimal=True), ['1.2345', '6.789'])\n    assert np.array_equal(a.to_string(decimal=False), ['1.2345rad', '6.789rad'])\n"], "sample_9": ["def test_write_table_html_css():\n    \"\"\"\n    Test to make sure that the HTML writer writes out using the\n    supplied CSS styling.\n    \"\"\"\n\n    col1 = [1, 2]\n    col2 = [1.234567e-11, -9.876543e11]\n    table = Table([col1, col2], names=('C1', 'C2'))\n\n    expected = \"\"\"\\"], "sample_12": ["def test_angle_to_string_precision():\n    \"\"\"\n    Test that the precision argument in Angle.to_string works correctly.\n    \"\"\"\n    a = Angle('1.23456789d')\n    assert a.to_string(precision=0) == '1d14m04s'\n    assert a.to_string(precision=1) == '1d14m04.6s'\n    assert a.to_string(precision=2) == '1d14m04.57s'\n    assert a.to_string(precision=3) == '1d14m04.568s'\n    assert a.to_string(precision=4) == '1d14m04.5679s'\n    assert a.to_string(precision=5) == '1d14m04.56789s'\n    assert a.to_string(precision=8) == '1d14m04.56789000s'\n"], "sample_13": ["def test_angle_to_string_precision():\n    \"\"\"\n    Test that the precision argument in Angle.to_string works as expected.\n    \"\"\"\n    a = Angle(1.23456789, unit=u.deg)\n    assert a.to_string(precision=0) == '1d14m04s'\n    assert a.to_string(precision=1) == '1d14m04.6s'\n    assert a.to_string(precision=2) == '1d14m04.57s'\n    assert a.to_string(precision=3) == '1d14m04.568s'\n    assert a.to_string(precision=4) == '1d14m04.5679s'\n    assert a.to_string(precision=5) == '1d14m04.56789s'\n"], "sample_14": ["def test_angle_to_string_precision():\n    \"\"\"\n    Test that the precision argument in Angle.to_string works correctly.\n    \"\"\"\n    a = Angle(1.23456789, unit=u.deg)\n    assert a.to_string(precision=0) == '1d14m04s'\n    assert a.to_string(precision=1) == '1d14m04.6s'\n    assert a.to_string(precision=2) == '1d14m04.57s'\n    assert a.to_string(precision=3) == '1d14m04.568s'\n    assert a.to_string(precision=4) == '1d14m04.5679s'\n    assert a.to_string(precision=5) == '1d14m04.56789s'\n    assert a.to_string(precision=6) == '1d14m04.567890s'\n    assert a.to_string(precision=7) == '1d14m04.5678900s'\n    assert a.to_string(precision=8) == '1d14m04.56789000s'\n    assert a.to_string(precision=9) == '1d14m04.567890000s'\n"], "sample_20": ["def test_read_with_unit_parse_strict(tmp_path):\n    filename = tmp_path / \"test_read_with_unit_parse_strict.fits\"\n    t1 = Table([[1, 2], [3, 4]], names=[\"a\", \"b\"])\n    t1[\"a\"].unit = \"m/s\"\n    t1[\"b\"].unit = \"not-a-unit\"\n\n    t1.write(filename, overwrite=True)\n\n    with pytest.warns(\n        u.UnitsWarning, match=\"'not-a-unit' did not parse as fits unit\"\n    ) as w:\n        Table.read(filename, hdu=1, unit_parse_strict=\"warn\")\n    assert len(w) == 1\n\n    with pytest.raises(\n        ValueError, match=\"'not-a-unit' did not parse as fits unit\"\n    ) as exc:\n        Table.read(filename, hdu=1, unit_parse_strict=\"raise\")\n    assert exc.value.args[0] == \"'not-a-unit' did not parse as fits unit\"\n\n    Table.read(filename, hdu=1, unit_parse_strict=\"silent\")\n"], "sample_21": ["def test_get_lines_from_file(tmp_path):\n    example_qdp = \"\"\"\n    ! Swift/XRT hardness ratio of trigger: XXXX, name: BUBU X-2\n    ! Columns are as labelled\n    READ TERR 1\n    READ SERR 2\n    ! WT -- hard data\n    !MJD            Err (pos)       Err(neg)        Rate            Error\n    53000.123456 2.37847222222222e-05    -2.37847222222222e-05   NO       0.212439\n    55045.099887 1.14467592592593e-05    -1.14467592592593e-05   0.000000        0.000000\n    \"\"\"\n\n    path = tmp_path / \"test.qdp\"\n\n    with open(path, \"w\") as fp:\n        print(example_qdp, file=fp)\n\n    lines = _get_lines_from_file(fp.name)\n    assert len(lines) == 8\n\n    lines = _get_lines_from_file(str(path))\n    assert len(lines) == 8\n\n    lines = _get_lines_from_file(example_qdp)\n    assert len(lines) == 8\n\n    with pytest.raises(ValueError):\n        _get_lines_from_file(123)\n"], "sample_22": ["def test_matrix_product():\n    \"\"\"Test the matrix product function.\"\"\"\n    # Test with two 3x3 matrices\n    m1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    m2 = np.array([[9, 8, 7], [6, 5, 4], [3, 2, 1]])\n    result = matrix_product(m1, m2)\n    assert_allclose(result, np.dot(m1, m2))\n\n    # Test with three 3x3 matrices\n    m3 = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n    result = matrix_product(m1, m2, m3)\n    assert_allclose(result, np.dot(np.dot(m1, m2), m3))\n\n    # Test with non-square matrices\n    m4 = np.array([[1, 2], [3, 4]])\n    m5 = np.array([[5, 6], [7, 8]])\n    result = matrix_product(m4, m5)\n    assert_allclose(result, np.dot(m4, m5))\n\n    # Test with a single matrix\n    result = matrix_product(m1)\n    assert_allclose(result, m1)\n\n    # Test with no matrices\n    with pytest.raises(TypeError):\n        matrix_product()\n"], "sample_23": ["def test_angle_to_string_precision():\n    \"\"\"\n    Test that the precision argument in Angle.to_string works correctly.\n    \"\"\"\n    a = Angle(\"1d2m3.456789s\")\n    assert a.to_string(precision=0) == \"1d02m03s\"\n    assert a.to_string(precision=1) == \"1d02m03.5s\"\n    assert a.to_string(precision=2) == \"1d02m03.46s\"\n    assert a.to_string(precision=3) == \"1d02m03.457s\"\n    assert a.to_string(precision=4) == \"1d02m03.4568s\"\n    assert a.to_string(precision=5) == \"1d02m03.45679s\"\n    assert a.to_string(precision=6) == \"1d02m03.456789s\"\n    assert a.to_string(precision=7) == \"1d02m03.4567890s\"\n    assert a.to_string(precision=8) == \"1d02m03.45678900s\"\n"], "sample_25": ["def test_header_fromstring_bytes_with_trailing_newline(self):\n    \"\"\"\n    Test reading a Header from a `bytes` string with a trailing newline.\n\n    See https://github.com/astropy/astropy/issues/8706\n    \"\"\"\n\n    with open(self.data(\"test0.fits\"), \"rb\") as fobj:\n        pri_hdr_from_bytes = fits.Header.fromstring(fobj.read() + b\"\\n\")\n\n    pri_hdr = fits.getheader(self.data(\"test0.fits\"))\n    assert pri_hdr[\"NAXIS\"] == pri_hdr_from_bytes[\"NAXIS\"]\n    assert pri_hdr == pri_hdr_from_bytes\n    assert pri_hdr.tostring() == pri_hdr_from_bytes.tostring()\n"], "sample_26": ["def test_image_hdu_update_header(tmp_path):\n    # Test that updating the header of an ImageHDU after it has been created\n    # correctly updates the BITPIX, NAXIS, and NAXISn keywords.\n\n    filename = tmp_path / \"test.fits\"\n\n    # Create an ImageHDU with a 2D array\n    data = np.random.rand(10, 20)\n    hdu = fits.ImageHDU(data=data)\n\n    # Write the HDU to a file\n    hdu.writeto(filename)\n\n    # Update the data to be a 3D array\n    new_data = np.random.rand(5, 10, 20)\n    hdu.data = new_data\n\n    # Update the header\n    hdu.update_header()\n\n    # Check that the BITPIX keyword has been updated\n    assert hdu.header[\"BITPIX\"] == -32\n\n    # Check that the NAXIS keyword has been updated\n    assert hdu.header[\"NAXIS\"] == 3\n\n    # Check that the NAXISn keywords have been updated\n    assert hdu.header[\"NAXIS1\"] == 20\n    assert hdu.header[\"NAXIS2\"] == 10\n    assert hdu.header[\"NAXIS3\"] == 5\n\n    # Write the updated HDU to a new file\n    hdu.writeto(tmp_path / \"test2.fits\")\n"], "sample_27": ["def test_fitsdiff_ignore_fields(tmp_path):\n    \"\"\"Test FITSDiff with ignore_fields option\"\"\"\n    path1 = tmp_path / \"test1.fits\"\n    path2 = tmp_path / \"test2.fits\"\n\n    col1 = Column(\"A\", format=\"I\", array=[1, 2])\n    col2 = Column(\"B\", format=\"I\", array=[3, 4])\n    col3 = Column(\"C\", format=\"I\", array=[5, 6])\n\n    table1 = BinTableHDU.from_columns([col1, col2, col3])\n    table2 = BinTableHDU.from_columns([col1, col2, Column(\"C\", format=\"I\", array=[7, 8])])\n\n    hdulist1 = HDUList([PrimaryHDU(), table1])\n    hdulist2 = HDUList([PrimaryHDU(), table2])\n\n    hdulist1.writeto(path1)\n    hdulist2.writeto(path2)\n\n    diff = FITSDiff(path1, path2, ignore_fields=[\"C\"])\n    assert diff.identical\n\n    report = diff.report()\n    assert \"No differences found.\" in report\n"], "sample_28": ["def test_header_fromstring_bytes_with_trailing_newline(self):\n    \"\"\"\n    Test reading a Header from a `bytes` string with a trailing newline.\n\n    See https://github.com/astropy/astropy/issues/8706\n    \"\"\"\n\n    with open(self.data(\"test0.fits\"), \"rb\") as fobj:\n        pri_hdr_from_bytes = fits.Header.fromstring(fobj.read() + b\"\\n\")\n\n    pri_hdr = fits.getheader(self.data(\"test0.fits\"))\n    assert pri_hdr[\"NAXIS\"] == pri_hdr_from_bytes[\"NAXIS\"]\n    assert pri_hdr == pri_hdr_from_bytes\n    assert pri_hdr.tostring() == pri_hdr_from_bytes.tostring()\n"], "sample_29": ["def test_write_latex_format_mismatch(self, write, tmp_path):\n    \"\"\"Test passing a format that does not match 'latex'\"\"\"\n    fp = tmp_path / \"test_write_latex_format_mismatch.tex\"\n    with pytest.raises(ValueError, match=\"format must be 'latex', not\"):\n        write(fp, format=\"ascii\")\n"], "sample_30": ["def test_get_table_by_id():\n    votable = parse(get_pkg_data_filename(\"data/regression.xml\"))\n    table = votable.get_table_by_id(\"table.1\")\n    assert isinstance(table, tree.Table)\n    assert len(table.array) == 5\n\n    with pytest.raises(KeyError):\n        votable.get_table_by_id(\"nonexistent_table\")\n"], "sample_31": ["    def test_write_latex_kwargs(self, write, tmp_path, format):\n        \"\"\"Test passing kwargs to the underlying table writer\"\"\"\n        fp = tmp_path / \"test_write_latex_kwargs.tex\"\n        write(fp, format=format, latex_names=True, caption=\"Cosmology Parameters\")\n        with open(fp, \"r\") as f:\n            contents = f.read()\n            assert \"Cosmology Parameters\" in contents\n"], "sample_32": ["def test_de_density_scale(self, cosmo):\n    \"\"\"Test :meth:`astropy.cosmology.w0wzCDM.de_density_scale`.\"\"\"\n    z = np.array([0.0, 0.5, 1.0, 1.5, 2.3])\n    expected = np.array([1.0, 1.8371173, 3.21895169, 5.32621129, 8.77208714])\n    assert u.allclose(cosmo.de_density_scale(z), expected)\n"], "sample_33": ["def test_indent():\n    text = \"This is a\\nmultiline string.\\nIt has three lines.\"\n    expected = \"    This is a\\n    multiline string.\\n    It has three lines.\\n\"\n    assert misc.indent(text, shift=1, width=4) == expected\n"], "sample_34": ["def test_find_equivalent_units():\n    # Test that find_equivalent_units returns a list of units that are equivalent to the given unit\n    equivalent_units = u.m.find_equivalent_units()\n    assert isinstance(equivalent_units, u.UnitBase.EquivalentUnitsList)\n    assert len(equivalent_units) > 0\n    for unit in equivalent_units:\n        assert unit.is_equivalent(u.m)\n\n    # Test that find_equivalent_units with equivalencies returns a list of units that are equivalent to the given unit\n    equivalent_units = u.m.find_equivalent_units(equivalencies=u.spectral())\n    assert isinstance(equivalent_units, u.UnitBase.EquivalentUnitsList)\n    assert len(equivalent_units) > 0\n    for unit in equivalent_units:\n        assert unit.is_equivalent(u.m, equivalencies=u.spectral())\n\n    # Test that find_equivalent_units with units returns a list of units that are equivalent to the given unit\n    equivalent_units = u.m.find_equivalent_units(units=[u.cm, u.km])\n    assert isinstance(equivalent_units, u.UnitBase.EquivalentUnitsList)\n    assert len(equivalent_units) > 0\n    for unit in equivalent_units:\n        assert unit.is_equivalent(u.m)\n\n    # Test that find_equivalent_units with include_prefix_units returns a list of units that are equivalent to the given unit\n    equivalent_units = u.m.find_equivalent_units(include_prefix_units=True)\n    assert isinstance(equivalent_units, u.UnitBase.EquivalentUnitsList)\n    assert len(equivalent_units) > 0\n    for unit in equivalent_units:\n        assert unit.is_equivalent(u.m)\n"], "sample_35": ["def test_minversion():\n    assert minversion('astropy', '0.1') is True\n    assert minversion('astropy', '100.0') is False\n    assert minversion(introspection, '0.1') is True\n    with pytest.raises(ValueError):\n        minversion(123, '0.1')\n    with pytest.raises(ImportError):\n        minversion('nonexistentmodule', '0.1')\n"], "sample_36": ["def test_biweight_location_M():\n    \"\"\"\n    Test that biweight_location raises error when M is not a scalar or \n    array-like with the correct shape.\n    \"\"\"\n\n    d = np.ones(10)\n    M = [[0, 1], [2, 3]]\n    with pytest.raises(ValueError) as e:\n        biweight_location(d, M=M)\n    assert 'M must be a scalar or array-like.' in str(e.value)\n\n    d = np.ones((3, 4))\n    M = np.ones(5)\n    with pytest.raises(ValueError) as e:\n        biweight_location(d, M=M, axis=0)\n    assert 'M must have the same shape as the input data along the specified axis.' in str(e.value)\n"], "sample_41": ["def test_unit_summary_scale():\n    \"\"\"\n    Test for a few units that the unit summary table correctly reports\n    whether or not that unit has a scale.\n\n    Regression test for https://github.com/astropy/astropy/issues/3835\n    \"\"\"\n\n    from astropy.units import astrophys\n\n    for summary in utils._iter_unit_summary(astrophys.__dict__):\n        unit, _, _, scale, _ = summary\n\n        if unit.name == 'lyr':\n            assert scale != 1.0\n        elif unit.name == 'pc':\n            assert scale != 1.0\n        elif unit.name == 'barn':\n            assert scale == 1.0\n        elif unit.name == 'cycle':\n            assert scale == 1.0\n        elif unit.name == 'vox':\n            assert scale == 1.0\n"], "sample_43": ["def test_events_fitness_gamma():\n    rng = np.random.RandomState(0)\n    t = np.concatenate([rng.rand(100),\n                        1 + rng.rand(200)])\n\n    bins1 = bayesian_blocks(t, fitness='events', gamma=0.01)\n    bins2 = bayesian_blocks(t, fitness='events', p0=0.05)\n\n    assert (len(bins1) == 3)\n    assert (len(bins2) == 3)\n    assert_allclose(bins1[1], bins2[1], rtol=0.02)\n"], "sample_44": ["    def setup(self):\n        self.mJy = np.arange(1., 5.).reshape(2, 2) * u.mag(u.Jy)\n        self.m1 = np.arange(1., 5.5, 0.5).reshape(3, 3) * u.mag()\n"], "sample_47": ["    def test_cleanse_setting_dictionary(self):\n        setting = {'foo': 'bar', 'password': 'super_secret'}\n        cleansed_setting = cleanse_setting('SETTING', setting)\n        self.assertEqual(cleansed_setting, {'foo': 'bar', 'password': CLEANSED_SUBSTITUTE})\n"], "sample_48": ["def test_aggregate_with_filter(self):\n    max_rating = Book.objects.aggregate(\n        max_rating=Max('rating', filter=Q(pages__gt=300)))\n    self.assertEqual(max_rating['max_rating'], 5)\n\n    min_price = Book.objects.aggregate(\n        min_price=Min('price', filter=Q(rating__lt=4.5)))\n    self.assertEqual(min_price['min_price'], Decimal('23.09'))\n\n    avg_pages = Book.objects.aggregate(\n        avg_pages=Avg('pages', filter=Q(name__contains='Django')))\n    self.assertAlmostEqual(avg_pages['avg_pages'], 447, places=0)\n"], "sample_49": ["def test_absolute_path(self):\n    media = Media(css={'all': ['path/to/css']}, js=['path/to/js'])\n    self.assertEqual(media.absolute_path('path/to/css'), 'http://media.example.com/static/path/to/css')\n    self.assertEqual(media.absolute_path('/path/to/css'), '/path/to/css')\n    self.assertEqual(media.absolute_path('http://example.com/path/to/css'), 'http://example.com/path/to/css')\n    self.assertEqual(media.absolute_path('https://example.com/path/to/css'), 'https://example.com/path/to/css')\n"], "sample_50": ["def test_sigint_handler_restored(self):\n    original_sigint_handler = signal.getsignal(signal.SIGINT)\n        # Verify that SIGINT is ignored while running subprocess.\n        self.assertEqual(signal.getsignal(signal.SIGINT), signal.SIG_IGN)\n        return subprocess.CompletedProcess(list(*args), 0)\n    with mock.patch('subprocess.run', new=_mock_subprocess_run):\n        DatabaseClient.runshell_db({\n            'database': 'dbname',\n            'user': 'someuser',\n            'password': 'somepassword',\n            'host': 'somehost',\n            'port': '444',\n        })\n    # Verify that the original SIGINT handler is restored after running subprocess.\n    self.assertEqual(signal.getsignal(signal.SIGINT), original_sigint_handler)\n"], "sample_51": ["def test_parse_iso8601_duration(self):\n    test_values = (\n        ('P3D', timedelta(days=3)),\n        ('PT4H', timedelta(hours=4)),\n        ('PT5M', timedelta(minutes=5)),\n        ('PT6S', timedelta(seconds=6)),\n        ('P3DT4H5M6S', timedelta(days=3, hours=4, minutes=5, seconds=6)),\n        ('-P3D', timedelta(days=-3)),\n        ('-PT4H', timedelta(hours=-4)),\n        ('-PT5M', timedelta(minutes=-5)),\n        ('-PT6S', timedelta(seconds=-6)),\n        ('-P3DT4H5M6S', timedelta(days=-3, hours=-4, minutes=-5, seconds=-6)),\n    )\n    for source, expected in test_values:\n        with self.subTest(source=source):\n            self.assertEqual(parse_duration(source), expected)\n"], "sample_54": ["def test_file_response_with_filename(self):\n    response = FileResponse(io.BytesIO(b'binary content'), filename='example.txt')\n    self.assertEqual(response['Content-Type'], 'text/plain')\n    self.assertEqual(response['Content-Disposition'], 'inline; filename=\"example.txt\"')\n    response.close()\n\n    response = FileResponse(io.BytesIO(b'binary content'), as_attachment=True, filename='example.txt')\n    self.assertEqual(response['Content-Type'], 'text/plain')\n    self.assertEqual(response['Content-Disposition'], 'attachment; filename=\"example.txt\"')\n    response.close()\n"], "sample_58": ["def test_media(self):\n    class MyForm(Form):\n        f1 = CharField(max_length=30, widget=Textarea)\n        f2 = ChoiceField(choices=[('P', 'Python'), ('J', 'Java')])\n\n    form = MyForm()\n    self.assertEqual(form.media, Media())\n    self.assertEqual(form.media._css, {})\n    self.assertEqual(form.media._js, [])\n"], "sample_57": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = '!'\n        html = widget.render(name='password', value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_59": ["def test_model_full_clean(self):\n    # Create an instance with a duplicate name to trigger a ValidationError on full_clean.\n    NonAutoPK.objects.create(name=\"one\")\n    again = NonAutoPK(name=\"one\")\n\n    # full_clean should raise a ValidationError.\n    with self.assertRaises(ValidationError):\n        again.full_clean()\n\n    # If we assign a new, unique name and then call full_clean again, it should not raise an error.\n    again.name = \"two\"\n    again.full_clean()  # Should not raise an error.\n"], "sample_61": ["    def test_validator(self):\n        valid_usernames = ['joe', 'joe123', 'joe_123', 'joe.123', 'joe@123']\n        invalid_usernames = [\n            \"o'connell\", \"Ren\u00e9\", \"\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30\", \"\u0623\u062d\u0645\u062f\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n"], "sample_62": ["    def setUp(self):\n        self.site = admin.AdminSite()\n"], "sample_63": ["    def test_find_template(self):\n        engine = Engine(dirs=[TEMPLATE_DIR])\n        template, origin = engine.find_template('index.html')\n        self.assertEqual(template.name, 'index.html')\n"], "sample_65": ["    def test_jsoncatalog(self):\n        response = self.client.get('/jsoni18n/')\n        self.assertEqual(response['Content-Type'], 'application/json')\n        data = json.loads(response.content.decode())\n        self.assertIn('catalog', data)\n        self.assertIn('formats', data)\n        self.assertIn('plural', data)\n"], "sample_68": ["    def test_cleanse_setting_dictionary(self):\n        setting = {'foo': 'bar', 'password': 'super_secret'}\n        cleansed_setting = cleanse_setting('SETTING', setting)\n        self.assertEqual(cleansed_setting['foo'], 'bar')\n        self.assertEqual(cleansed_setting['password'], CLEANSED_SUBSTITUTE)\n"], "sample_69": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_70": ["def test_collector_sort(self):\n    # Create some objects with dependencies between them\n    r1 = R.objects.create()\n    r2 = R.objects.create()\n    a1 = A.objects.create(setnull=r1)\n    a2 = A.objects.create(setnull=r2)\n\n    collector = Collector(using='default')\n    collector.add([a1, a2])\n    collector.add([r1, r2])\n\n    # Before sorting, the collector's data is just a dict of sets\n    self.assertIsInstance(collector.data, dict)\n    for value in collector.data.values():\n        self.assertIsInstance(value, set)\n\n    collector.sort()\n\n    # After sorting, the collector's data should be an OrderedDict of lists\n    self.assertIsInstance(collector.data, dict)\n    for value in collector.data.values():\n        self.assertIsInstance(value, list)\n\n    # The order of the models in the collector's data should be correct\n    self.assertEqual(list(collector.data.keys()), [A, R])\n"], "sample_71": ["def test_non_uniform_digit_grouping(self):\n    # Test non-uniform digit grouping.\n    self.assertEqual(nformat(1234567, '.', grouping=(3, 2, 0), thousand_sep=','), '1,23,45,67')\n    self.assertEqual(nformat(123456789, '.', grouping=(3, 2, 0), thousand_sep=','), '123,45,67,89')\n    self.assertEqual(nformat(123456789012, '.', grouping=(3, 2, 0), thousand_sep=','), '123,456,78,9012')\n    self.assertEqual(nformat(12345678901234, '.', grouping=(3, 2, 0), thousand_sep=','), '12,345,678,90,1234')\n"], "sample_74": ["def test_sigint_handler(self):\n    @mock.patch('signal.signal')\n    @mock.patch('subprocess.run')\n        DatabaseClient.runshell_db({\n            'database': 'dbname',\n            'user': 'someuser',\n            'password': 'somepassword',\n            'host': 'somehost',\n            'port': '444',\n        })\n    _run_it()\n    with mock.patch('signal.getsignal', return_value='original_handler'):\n        _run_it()\n        signal.signal.assert_any_call(signal.SIGINT, signal.SIG_IGN)\n        signal.signal.assert_called_with(signal.SIGINT, 'original_handler')\n"], "sample_76": ["def test_language_settings_consistent(self):\n    with self.settings(LANGUAGE_CODE='en', LANGUAGES=[('fr', 'French')]):\n        self.assertEqual(check_language_settings_consistent(None), [\n            Error('You have provided a value for the LANGUAGE_CODE setting that is not in the LANGUAGES setting.', id='translation.E004'),\n        ])\n\n    with self.settings(LANGUAGE_CODE='en', LANGUAGES=[('en', 'English')]):\n        self.assertEqual(check_language_settings_consistent(None), [])\n\n    with self.settings(LANGUAGE_CODE='en-us', LANGUAGES=[]):\n        self.assertEqual(check_language_settings_consistent(None), [])\n"], "sample_77": ["def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            'Check out www.google.com.',\n            'Check out <a href=\"http://www.google.com\">www.google.com</a>.'\n        ),\n        (\n            'Check out www.google.com!',\n            'Check out <a href=\"http://www.google.com\">www.google.com</a>!'\n        ),\n        (\n            'Check out www.google.com?',\n            'Check out <a href=\"http://www.google.com\">www.google.com</a>?'\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_78": ["def test_normalize_path_patterns(self):\n    patterns = ['foo/bar', 'baz', 'qux/*']\n    normalized_patterns = normalize_path_patterns(patterns)\n    self.assertEqual(normalized_patterns, ['foo/bar', 'baz', 'qux/'])\n"], "sample_82": ["def test_value_from_datadict_invalid_date(self):\n    data = {'date_year': '2010', 'date_month': '13', 'date_day': '32'}\n    self.assertEqual(self.widget.value_from_datadict(data, {}, 'date'), '2010-13-32')\n"], "sample_81": ["    def test_str(self):\n        pattern = RegexPattern(r'^test/$')\n        url_pattern = URLPattern(pattern, lambda x: None)\n        self.assertEqual(str(url_pattern), '<URLPattern ^test/$>')\n"], "sample_83": ["    def test_get_resolved_arguments(self):\n        class DummyNode(TagHelperNode):\n                super().__init__(func, takes_context, args, kwargs)\n\n            return ''\n\n        node = DummyNode(dummy_func, True, ['arg1', 'arg2'], {'kwarg1': 'value1'})\n        context = {'arg1': 'resolved_arg1', 'arg2': 'resolved_arg2', 'value1': 'resolved_value1'}\n        resolved_args, resolved_kwargs = node.get_resolved_arguments(context)\n        self.assertEqual(resolved_args, [context, 'resolved_arg1', 'resolved_arg2'])\n        self.assertEqual(resolved_kwargs, {'kwarg1': 'resolved_value1'})\n"], "sample_84": ["    def test_escape_leading_slashes(self):\n        self.assertEqual(escape_leading_slashes('//example.com'), '/%2F/example.com')\n        self.assertEqual(escape_leading_slashes('/example.com'), '/example.com')\n        self.assertEqual(escape_leading_slashes('example.com'), 'example.com')\n"], "sample_86": ["def test_lazy_hash(self):\n    \"\"\"\n    hash() works correctly for Promises.\n    \"\"\"\n    lazy_a = lazy(lambda: 4, int)\n    lazy_b = lazy(lambda: 4, int)\n    lazy_c = lazy(lambda: 5, int)\n\n    self.assertEqual(hash(lazy_a()), hash(lazy_b()))\n    self.assertNotEqual(hash(lazy_b()), hash(lazy_c()))\n"], "sample_87": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertEqual(mocked_termios.tcgetattr.call_count, 1)\n        self.assertEqual(mocked_termios.tcsetattr.call_count, 1)\n"], "sample_89": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_91": ["def test_permission_denied(self):\n    request = self.request_factory.get('/')\n    response = permission_denied(request, Exception())\n    self.assertContains(response, b'<h1>403 Forbidden</h1>', status_code=403)\n"], "sample_92": ["    def test_remote_user(self):\n        \"\"\"\n        The RemoteUserBackend should authenticate a user if the REMOTE_USER\n        environment variable is set.\n        \"\"\"\n        request = HttpRequest()\n        request.META['REMOTE_USER'] = 'testuser'\n        user = authenticate(request)\n        self.assertEqual(user.username, 'testuser')\n"], "sample_94": ["    def test_get_input_data(self):\n        command = createsuperuser.Command()\n        field = User._meta.get_field('username')\n        message = 'Username: '\n        input_value = 'test_username'\n        with mock.patch.object(builtins, 'input', return_value=input_value):\n            value = command.get_input_data(field, message)\n            self.assertEqual(value, input_value)\n"], "sample_98": ["    def test_wsgi_application(self):\n        \"\"\"\n        The WSGI application is properly loaded and used by the live server.\n        \"\"\"\n        with self.urlopen('/wsgi_view/') as f:\n            self.assertEqual(f.read(), b'WSGI view')\n"], "sample_100": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_101": ["def test_limited_stream(self):\n    \"\"\"\n    Test that LimitedStream limits the amount of data read.\n    \"\"\"\n    stream = BytesIO(b'Hello, World!')\n    limited_stream = LimitedStream(stream, 5)\n\n    self.assertEqual(limited_stream.read(), b'Hello')\n    self.assertEqual(limited_stream.read(), b'')\n"], "sample_103": ["def test_aggregate_filter(self):\n    books = Book.objects.aggregate(\n        highly_rated=Count('pk', filter=Q(rating__gte=4)),\n        lowly_rated=Count('pk', filter=Q(rating__lt=4)),\n    )\n    self.assertEqual(books['highly_rated'], 5)\n    self.assertEqual(books['lowly_rated'], 1)\n"], "sample_107": ["    def test_cleanse_setting_dictionary(self):\n        setting = {'foo': 'bar', 'password': 'super_secret'}\n        cleansed_setting = cleanse_setting('SETTING', setting)\n        self.assertEqual(cleansed_setting, {'foo': 'bar', 'password': CLEANSED_SUBSTITUTE})\n"], "sample_106": ["    def test_patch_response_headers(self):\n        response = HttpResponse()\n        patch_response_headers(response, cache_timeout=10)\n        self.assertIn('Expires', response)\n        self.assertIn('Cache-Control', response)\n"], "sample_105": ["    def test_get_context_data(self):\n        view = ContextMixin()\n        context = view.get_context_data()\n        self.assertIn('view', context)\n        self.assertEqual(context['view'], view)\n"], "sample_108": ["    def test_reverse_value_error_means_no_match(self):\n        @DynamicConverter.register_to_url\n            raise ValueError()\n        with self.assertRaises(NoReverseMatch):\n            reverse('dynamic', kwargs={'value': 'abc'})\n"], "sample_111": ["def test_get_filters_params(self):\n    \"\"\"\n    Test that get_filters_params() returns all params except IGNORED_PARAMS.\n    \"\"\"\n    m = BandAdmin(Band, custom_site)\n    request = self.factory.get('/band/', data={'genres': '0', 'o': '1', 'ot': '2', 'q': '3'})\n    request.user = self.superuser\n    cl = m.get_changelist_instance(request)\n    lookup_params = cl.get_filters_params()\n    self.assertEqual(lookup_params, {'genres': '0'})\n"], "sample_112": ["def test_prepopulated_fields_js(self):\n    \"\"\"\n    prepopulated_fields_js template tag should return a list of prepopulated fields.\n    \"\"\"\n    request = self.request_factory.get(reverse('admin:auth_user_change', args=[self.superuser.pk]))\n    request.user = self.superuser\n    admin = UserAdmin(User, site)\n    response = admin.change_view(request, str(self.superuser.pk))\n    template_context = prepopulated_fields_js(response.context_data)\n    self.assertIsInstance(template_context['prepopulated_fields'], list)\n    self.assertIsInstance(template_context['prepopulated_fields_json'], str)\n"], "sample_113": ["    def test_replace_named_groups(self):\n        pattern = r'^(?P<a>\\w+)/b/(?P<c>\\w+)/$'\n        expected_output = '^<a>/b/<c>/$'\n        self.assertEqual(utils.replace_named_groups(pattern), expected_output)\n"], "sample_115": ["    def test_technical_404_template(self):\n        exception = Http404('Page not found')\n        request = RequestFactory().get('/test/')\n        response = technical_404_response(request, exception)\n        self.assertContains(response, 'Page not found', status_code=404)\n"], "sample_117": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = '!'\n        html = widget.render(name='password', value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_122": ["    def test_patch_response_headers(self):\n        response = HttpResponse()\n        patch_response_headers(response, cache_timeout=10)\n        self.assertIn('Expires', response)\n        self.assertIn('Cache-Control', response)\n"], "sample_123": ["    def test_escape_leading_slashes(self):\n        self.assertEqual(escape_leading_slashes('//example.com'), '/%2F/example.com')\n        self.assertEqual(escape_leading_slashes('/example.com'), '/example.com')\n        self.assertEqual(escape_leading_slashes('http://example.com'), 'http://example.com')\n"], "sample_125": ["    def test_reason_phrase(self):\n        response = HttpResponse()\n        self.assertEqual(response.reason_phrase, 'OK')\n\n        response = HttpResponse(status=404)\n        self.assertEqual(response.reason_phrase, 'Not Found')\n\n        response = HttpResponse(status=500)\n        self.assertEqual(response.reason_phrase, 'Internal Server Error')\n\n        response = HttpResponse(status=200, reason='Custom Reason')\n        self.assertEqual(response.reason_phrase, 'Custom Reason')\n\n        response = HttpResponse(status=999)\n        self.assertEqual(response.reason_phrase, 'Unknown Status Code')\n"], "sample_128": ["    def test_covering_index_with_opclasses(self):\n        index = Index(\n            name='covering_headline_idx',\n            fields=['headline'],\n            opclasses=['varchar_pattern_ops'],\n            include=['pub_date', 'published'],\n        )\n        with connection.schema_editor() as editor:\n            self.assertIn(\n                '(%s varchar_pattern_ops) INCLUDE (%s, %s)' % (\n                    editor.quote_name('headline'),\n                    editor.quote_name('pub_date'),\n                    editor.quote_name('published'),\n                ),\n                str(index.create_sql(Article, editor)),\n            )\n            editor.add_index(Article, index)\n            with connection.cursor() as cursor:\n                constraints = connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                )\n                self.assertIn(index.name, constraints)\n                self.assertEqual(\n                    constraints[index.name]['columns'],\n                    ['headline', 'pub_date', 'published'],\n                )\n            editor.remove_index(Article, index)\n            with connection.cursor() as cursor:\n                self.assertNotIn(index.name, connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                ))\n"], "sample_131": ["    def test_create_test_db_clone_settings(self, mocked_migrate, mocked_ensure_connection):\n        creation = connection.creation_class(connection)\n        suffix = 'test_suffix'\n        expected_settings = {\n            **connection.settings_dict,\n            'NAME': '{}_{}'.format(connection.settings_dict['NAME'], suffix),\n        }\n        self.assertEqual(creation.get_test_db_clone_settings(suffix), expected_settings)\n"], "sample_132": ["    def test_technical_404_response(self):\n        exception = Http404('Page not found')\n        request = RequestFactory().get('/test/')\n        response = technical_404_response(request, exception)\n        self.assertEqual(response.status_code, 404)\n        self.assertContains(response, 'Page not found', status_code=404)\n"], "sample_133": ["    def test_get_paths(self):\n        view = JavaScriptCatalog()\n        packages = ['django.contrib.admin', 'django.contrib.auth']\n        paths = view.get_paths(packages)\n        self.assertEqual(len(paths), 2)\n        for package in packages:\n            app_config = apps.get_app_config(package)\n            self.assertIn(os.path.join(app_config.path, 'locale'), paths)\n"], "sample_139": ["def test_get_deleted_objects(self):\n    \"\"\"\n    get_deleted_objects() returns a list of related objects to be deleted.\n    \"\"\"\n    band = Band.objects.create(name='Linkin Park')\n    musician = Musician.objects.create(name='Chester')\n    invitation = Invitation.objects.create(band=band, player=musician)\n    deleted_objects, model_count, perms_needed, protected = self.admin.get_deleted_objects([invitation], self.request)\n    self.assertEqual(deleted_objects, ['Invitation: Invitation object (1)'])\n    self.assertEqual(model_count, {Invitation: 1})\n    self.assertEqual(perms_needed, set())\n    self.assertEqual(protected, [])\n"], "sample_137": ["def test_replace_named_groups(self):\n    pattern = r'^(?P<a>\\w+)/b/(?P<c>\\w+)/$'\n    expected_output = '^<a>/b/<c>/$'\n    self.assertEqual(replace_named_groups(pattern), expected_output)\n\n    pattern = r'^(?P<a>\\w+)/b/(\\w+)'\n    expected_output = '^<a>/b/(\\\\w+)'\n    self.assertEqual(replace_named_groups(pattern), expected_output)\n\n    pattern = r'^(?P<a>\\w+)/b/(?P<c>\\w+)'\n    expected_output = '^<a>/b/<c>'\n    self.assertEqual(replace_named_groups(pattern), expected_output)\n"], "sample_138": ["    def setUp(self):\n        super().setUp()\n        self._temp_dir = temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, 'test'))\n        self.addCleanup(shutil.rmtree, temp_dir)\n"], "sample_140": ["    def test_sensitive_variables_all(self):\n        @sensitive_variables()\n            raise Exception('Test')\n        try:\n            test_func('secret', 'user123')\n        except Exception:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(None, exc_type, exc_value, tb)\n        html = reporter.get_traceback_html()\n        self.assertNotIn('password', html)\n        self.assertNotIn('secret', html)\n        self.assertNotIn('username', html)\n        self.assertNotIn('user123', html)\n"], "sample_141": ["    def test_progress_bar(self):\n        output = StringIO()\n        progress_bar = ProgressBar(output, 10)\n        for i in range(10):\n            progress_bar.update(i + 1)\n        self.assertEqual(output.getvalue().count('\\n'), 1)\n"], "sample_143": ["def test_camel_case_to_spaces(self):\n    items = [\n        ('camelCase', 'camel case'),\n        ('CamelCase', 'camel case'),\n        ('CAMELCase', 'camel case'),\n        ('_camelCase', '_camel case'),\n        ('Camel_Case', 'camel case'),\n    ]\n    for value, output in items:\n        self.assertEqual(text.camel_case_to_spaces(value), output)\n        self.assertEqual(text.camel_case_to_spaces(lazystr(value)), output)\n"], "sample_144": ["def test_inheritance_with_custom_primary_key(self):\n    # Test that a model with a custom primary key can be used as a base class.\n    obj = Congressman.objects.create(id='123', name='John Doe')\n    self.assertEqual(obj.id, '123')\n    self.assertEqual(obj.name, 'John Doe')\n\n    # Test that the child model's primary key is correctly set.\n    senator = Senator.objects.create(id='456', name='Jane Doe', title='Senator')\n    self.assertEqual(senator.id, '456')\n    self.assertEqual(senator.name, 'Jane Doe')\n    self.assertEqual(senator.title, 'Senator')\n\n    # Test that the parent model's primary key is correctly set when creating a child instance.\n    senator = Senator.objects.create(name='Bob Smith', title='Senator')\n    self.assertIsNotNone(senator.id)\n    self.assertEqual(senator.name, 'Bob Smith')\n    self.assertEqual(senator.title, 'Senator')\n"], "sample_146": ["def test_consistent_language_settings(self):\n    self.assertEqual(check_language_settings_consistent(None), [])\n"], "sample_148": ["def test_quote(self):\n    \"\"\"\n    Test that quote() correctly escapes special characters.\n    \"\"\"\n    tests = (\n        ('hello', 'hello'),\n        ('hello world', 'hello world'),\n        ('hello/world', 'hello/_2Fworld'),\n        ('hello_world', 'hello/_5Fworld'),\n        ('hello:world', 'hello/_3Aworld'),\n    )\n    for value, expected in tests:\n        self.assertEqual(quote(value), expected)\n"], "sample_149": ["def test_check_models_permissions_empty_app_configs(self):\n    errors = check_models_permissions(app_configs=[])\n    self.assertEqual(errors, [])\n"], "sample_152": ["def test_collector_sort(self):\n    # Create some objects to delete, with dependencies between them.\n    r = R.objects.create()\n    s1 = S.objects.create(r=r)\n    s2 = S.objects.create(r=r)\n    t1 = T.objects.create(s=s1)\n    t2 = T.objects.create(s=s2)\n\n    # Create a Collector and add the objects to delete.\n    collector = Collector(using='default')\n    collector.add([r])\n    collector.add([s1, s2])\n    collector.add([t1, t2])\n\n    # Sort the objects to delete.\n    collector.sort()\n\n    # Check that the objects are deleted in the correct order.\n    with self.assertNumQueries(5):\n        collector.delete()\n\n    # Check that all objects have been deleted.\n    self.assertFalse(R.objects.exists())\n    self.assertFalse(S.objects.exists())\n    self.assertFalse(T.objects.exists())\n"], "sample_150": ["    def test_create_parser(self):\n        command = BaseCommand()\n        parser = command.create_parser('manage.py', 'test')\n        self.assertIsInstance(parser, CommandParser)\n        self.assertEqual(parser.prog, 'manage.py test')\n"], "sample_154": ["def test_database_checks_called_for_each_database(self, mocked_connections):\n    databases = {'default', 'other'}\n    check_database_backends(databases=databases)\n    self.assertEqual(mocked_connections.__getitem__.call_count, len(databases))\n    for alias in databases:\n        mocked_connections.__getitem__.assert_any_call(alias)\n"], "sample_155": ["def test_file_response_with_filename(self):\n    response = FileResponse(io.BytesIO(b'binary content'), filename='example.txt')\n    self.assertEqual(response['Content-Length'], '14')\n    self.assertEqual(response['Content-Type'], 'text/plain')\n    self.assertEqual(response['Content-Disposition'], 'inline; filename=\"example.txt\"')\n    self.assertEqual(list(response), [b'binary content'])\n"], "sample_156": ["def test_field_order_with_inheritance(self):\n    class ParentForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n\n    class ChildForm(ParentForm):\n        field3 = CharField()\n        field4 = CharField()\n\n        field_order = ['field4', 'field2', 'field1']\n\n    form = ChildForm()\n    self.assertEqual(list(form.fields), ['field4', 'field2', 'field1', 'field3'])\n"], "sample_157": ["def test_create_test_db_with_keepdb(self, mocked_migrate, mocked_ensure_connection):\n    test_connection = get_connection_copy()\n    creation = test_connection.creation_class(test_connection)\n    old_database_name = test_connection.settings_dict['NAME']\n    try:\n        with mock.patch.object(creation, '_create_test_db'):\n            creation.create_test_db(verbosity=0, autoclobber=True, serialize=False, keepdb=True)\n        mocked_migrate.assert_called_once()\n        self.assertEqual(test_connection.settings_dict['NAME'], creation._get_test_db_name())\n    finally:\n        with mock.patch.object(creation, '_destroy_test_db'):\n            creation.destroy_test_db(old_database_name, verbosity=0, keepdb=True)\n"], "sample_159": ["def test_check_models_permissions_empty_app_configs(self):\n    errors = check_models_permissions(app_configs=[])\n    self.assertEqual(errors, [])\n"], "sample_160": ["def test_non_uniform_digit_grouping(self):\n    self.assertEqual(nformat(1234567, '.', grouping=(3, 2), thousand_sep=','), '1,23,45,67')\n    self.assertEqual(nformat(123456789, '.', grouping=(3, 2, 0), thousand_sep=','), '12,34,56,789')\n    self.assertEqual(nformat(123456789012, '.', grouping=(3, 2, 0), thousand_sep=','), '123,45,67,89012')\n"], "sample_162": ["    def test_no_obsolete_disabled_by_default(self):\n        management.call_command('makemessages', locale=[LOCALE], verbosity=0)\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertIn('#~ msgid \"Obsolete message\"', po_contents)\n"], "sample_163": ["    def test_dispatch_authenticated(self):\n        self.login()\n        response = self.client.get(\"/login/\")\n        self.assertEqual(response.status_code, 200)\n"], "sample_164": ["    def test_log_response(self):\n        logger = logging.getLogger('django')\n        request = RequestFactory().get('/')\n        response = views.HttpResponse('OK')\n\n        log_response('message', response=response, request=request, logger=logger)\n        self.assertEqual(len(logger.handlers[0].buffer), 1)\n"], "sample_166": ["    def test_get_random_string_length(self):\n        for length in range(1, 100):\n            self.assertEqual(len(get_random_string(length)), length)\n"], "sample_167": ["def test_naturaltime_future_substrings(self):\n    # Test the future_substrings in NaturalTimeFormatter\n    test_list = [\n        now + datetime.timedelta(days=365),  # 1 year from now\n        now + datetime.timedelta(days=730),  # 2 years from now\n        now + datetime.timedelta(days=30),   # 1 month from now\n        now + datetime.timedelta(days=60),   # 2 months from now\n        now + datetime.timedelta(weeks=1),   # 1 week from now\n        now + datetime.timedelta(weeks=2),   # 2 weeks from now\n        now + datetime.timedelta(days=1),    # 1 day from now\n        now + datetime.timedelta(days=2),    # 2 days from now\n        now + datetime.timedelta(hours=1),   # 1 hour from now\n        now + datetime.timedelta(hours=2),   # 2 hours from now\n        now + datetime.timedelta(minutes=1), # 1 minute from now\n        now + datetime.timedelta(minutes=2), # 2 minutes from now\n    ]\n    result_list = [\n        '1\\xa0year from now',\n        '2\\xa0years from now',\n        '1\\xa0month from now',\n        '2\\xa0months from now',\n        '1\\xa0week from now',\n        '2\\xa0weeks from now',\n        '1\\xa0day from now',\n        '2\\xa0days from now',\n        'an hour from now',\n        '2\\xa0hours from now',\n        'a minute from now',\n        '2\\xa0minutes from now',\n    ]\n\n    orig_humanize_datetime, humanize.datetime = humanize.datetime, MockDateTime\n    try:\n        with translation.override('en'):\n            self.humanize_tester(test_list, result_list, 'naturaltime')\n    finally:\n        humanize.datetime = orig_humanize_datetime\n"], "sample_168": ["def test_include_stale_apps(self):\n    \"\"\"\n    The --include-stale-apps option deletes stale content types from previously\n    installed apps that have been removed from INSTALLED_APPS.\n    \"\"\"\n    ContentType.objects.create(app_label='removed_app', model='Fake')\n    with mock.patch('builtins.input', return_value='yes'), captured_stdout() as stdout:\n        call_command('remove_stale_contenttypes', include_stale_apps=True, verbosity=2)\n    self.assertIn(\n        \"Deleting stale content type 'removed_app | Fake'\",\n        stdout.getvalue(),\n    )\n    self.assertEqual(ContentType.objects.count(), self.before_count)\n"], "sample_171": ["def test_migrate_syncdb_deferred_sql_executed_with_schemaeditor_for_unmigrated_app(self):\n    \"\"\"\n    For an unmigrated app, editor.execute() is used for executing the syncdb\n    deferred SQL.\n    \"\"\"\n    stdout = io.StringIO()\n    with mock.patch.object(BaseDatabaseSchemaEditor, 'execute') as execute:\n        call_command('migrate', run_syncdb=True, verbosity=1, stdout=stdout, no_color=True)\n        create_table_count = len([call for call in execute.mock_calls if 'CREATE TABLE' in str(call)])\n        self.assertEqual(create_table_count, 2)\n        # There's at least one deferred SQL for creating the foreign key index.\n        self.assertGreater(len(execute.mock_calls), 2)\n    stdout = stdout.getvalue()\n    self.assertIn('Synchronize unmigrated apps:', stdout)\n    self.assertIn('Creating tables...', stdout)\n    table_name = truncate_name('unmigrated_app_syncdb_classroom', connection.ops.max_name_length())\n    self.assertIn('Creating table %s' % table_name, stdout)\n"], "sample_170": ["    def test_technical_404_response(self):\n        exception = Http404('Test 404 message')\n        request = RequestFactory().get('/test/')\n        response = technical_404_response(request, exception)\n        self.assertEqual(response.status_code, 404)\n        self.assertContains(response, 'Test 404 message', status_code=404)\n"], "sample_177": ["def test_get_related_models_tuples(self):\n    \"\"\"\n    get_related_models_tuples returns a set of (app_label, model_name) tuples\n    for all related models.\n    \"\"\"\n    new_apps = Apps()\n\n    class Author(models.Model):\n        name = models.TextField()\n\n        class Meta:\n            app_label = \"migrations\"\n            apps = new_apps\n\n    class Book(models.Model):\n        author = models.ForeignKey(Author, models.CASCADE)\n\n        class Meta:\n            app_label = \"migrations\"\n            apps = new_apps\n\n    project_state = ProjectState()\n    project_state.add_model(ModelState.from_model(Author))\n    project_state.add_model(ModelState.from_model(Book))\n\n    related_models = get_related_models_tuples(project_state.apps.get_model(\"migrations\", \"Author\"))\n    self.assertEqual(related_models, {('migrations', 'book')})\n"], "sample_178": ["def test_formset_with_empty_management_form_data(self):\n    \"\"\"A formset with empty management form data is invalid.\"\"\"\n    ChoiceFormSet = formset_factory(Choice)\n    formset = ChoiceFormSet({\n        'choices-TOTAL_FORMS': '',\n        'choices-INITIAL_FORMS': '',\n        'choices-MIN_NUM_FORMS': '',\n        'choices-MAX_NUM_FORMS': '',\n    })\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(formset.non_form_errors(), ['ManagementForm data is missing or has been tampered with'])\n"], "sample_185": ["    def test_reset_format_cache(self):\n        # Populate _format_cache with temporary values\n        _format_cache[('DATE_FORMAT', 'en')] = '%Y-%m-%d'\n        _format_cache[('TIME_FORMAT', 'en')] = '%H:%M:%S'\n\n        reset_format_cache()\n\n        self.assertEqual(_format_cache, {})\n        self.assertEqual(_format_modules_cache, {})\n"], "sample_187": ["def test_camel_case_to_spaces(self):\n    items = [\n        ('camelCase', 'camel case'),\n        ('CamelCase', 'camel case'),\n        ('CAMELCase', 'camel case'),\n        ('_camelCase', '_camel case'),\n        ('Camel_Case', 'camel case'),\n    ]\n    for value, output in items:\n        self.assertEqual(text.camel_case_to_spaces(value), output)\n        self.assertEqual(text.camel_case_to_spaces(lazystr(value)), output)\n"], "sample_189": ["    def test_without_vary_on(self):\n        key = make_template_fragment_key('a.fragment')\n        self.assertEqual(key, 'template.cache.cacheprefix.a.fragment.d41d8cd98f00b204e9800998ecf8427e')\n"], "sample_191": ["    def test_not_a_tty(self, mocked_isatty):\n        # Should not raise an error.\n        autoreload.ensure_echo_on()\n"], "sample_192": ["def test_formset_empty_management_form_error(self):\n    \"\"\"An empty management form raises a ValidationError.\"\"\"\n    ChoiceFormSet = formset_factory(Choice)\n    with self.assertRaisesMessage(ValidationError, 'ManagementForm data is missing or has been tampered with'):\n        ChoiceFormSet({}).is_valid()\n"], "sample_193": ["def test_get_related_models_recursive_with_through_model(self):\n    A = self.create_model(\"A\")\n    B = self.create_model(\"B\")\n    T = self.create_model(\"T\", foreign_keys=[\n        models.ForeignKey('A', models.CASCADE),\n        models.ForeignKey('B', models.CASCADE),\n    ])\n    M = self.create_model(\"M\", foreign_keys=[models.ManyToManyField('B', through='T')])\n    self.assertRelated(M, [A, B, T])\n    self.assertRelated(T, [A, B, M])\n    self.assertRelated(A, [B, M, T])\n    self.assertRelated(B, [A, M, T])\n"], "sample_194": ["def test_invalid_opclasses_length(self):\n    msg = (\n        'UniqueConstraint.fields and UniqueConstraint.opclasses must '\n        'have the same number of elements.'\n    )\n    with self.assertRaisesMessage(ValueError, msg):\n        models.UniqueConstraint(\n            name='uniq_opclasses',\n            fields=['field1', 'field2'],\n            opclasses=['jsonb_path_ops'],\n        )\n"], "sample_197": ["def test_depth_zero(self):\n    with self.assertRaises(ValueError):\n        timesince(self.t, self.t + self.oneday, depth=0)\n    with self.assertRaises(ValueError):\n        timeuntil(self.t + self.oneday, self.t, depth=0)\n"], "sample_200": ["def test_sanitize_address_with_non_ascii_localpart(self):\n    \"\"\"\n    Test that sanitize_address() correctly handles email addresses with non-ASCII localparts.\n    \"\"\"\n    address = ('Firstname S\u00fcrname', 't\u00f3@example.com')\n    sanitized_address = sanitize_address(address, encoding='utf-8')\n    self.assertEqual(sanitized_address, '=?utf-8?q?Firstname_S=C3=BCrname?= <t=C3=B3@example.com>')\n"], "sample_201": ["def test_legacy_hash(self):\n    \"\"\"\n    The _legacy_hash method returns the expected hash for a given value.\n    \"\"\"\n    storage = self.get_storage()\n    value = 'test_value'\n    legacy_hash = storage._legacy_hash(value)\n    self.assertEqual(legacy_hash, salted_hmac('django.contrib.messages', value).hexdigest())\n\n    # Test that the _legacy_decode method correctly decodes a value with a valid legacy hash.\n    encoded_data = f'{legacy_hash}${value}'\n    decoded_data = storage._legacy_decode(encoded_data)\n    self.assertEqual(decoded_data, value)\n\n    # Test that the _legacy_decode method returns None for a value with an invalid legacy hash.\n    invalid_encoded_data = f'invalid_hash${value}'\n    decoded_data = storage._legacy_decode(invalid_encoded_data)\n    self.assertIsNone(decoded_data)\n"], "sample_202": ["def test_safedata(self):\n    \"\"\"\n    A message containing SafeData is keeping its safe status when\n    retrieved from the message storage.\n    \"\"\"\n    storage = self.get_storage()\n    messages = [Message(constants.DEBUG, mark_safe('Safe message'))]\n    set_cookie_data(storage, messages)\n    retrieved_messages = list(storage)\n    self.assertEqual(len(retrieved_messages), 1)\n    self.assertIsInstance(retrieved_messages[0], SafeData)\n"], "sample_203": ["    def test_file_extension_validator(self):\n        validator = validators.FileExtensionValidator(allowed_extensions=['txt', 'pdf'])\n        file = SimpleUploadedFile('example.txt', b'file content')\n        try:\n            validator(file)\n        except ValidationError:\n            self.fail(\"ValidationError was raised unexpectedly\")\n\n        file = SimpleUploadedFile('example.doc', b'file content')\n        with self.assertRaises(ValidationError) as e:\n            validator(file)\n        self.assertEqual(e.exception.messages[0], 'File extension \u201cdoc\u201d is not allowed. Allowed extensions are: txt, pdf.')\n"], "sample_204": ["def test_circular_dependencies(self):\n    \"\"\"\n    Tests that circular dependencies are correctly detected.\n    \"\"\"\n    loader = MigrationLoader(connection)\n    with self.assertRaises(NodeNotFoundError):\n        loader.build_graph()\n"], "sample_205": ["def test_update_error_dict(self):\n    error_dict = {}\n    exception = ValidationError('message')\n    updated_dict = exception.update_error_dict(error_dict)\n    self.assertEqual(updated_dict, {'__all__': ['message']})\n\n    error_dict = {'field1': ['error1']}\n    exception = ValidationError('message')\n    updated_dict = exception.update_error_dict(error_dict)\n    self.assertEqual(updated_dict, {'field1': ['error1'], '__all__': ['message']})\n\n    error_dict = {}\n    exception = ValidationError({'field1': 'error1', 'field2': 'error2'})\n    updated_dict = exception.update_error_dict(error_dict)\n    self.assertEqual(updated_dict, {'field1': ['error1'], 'field2': ['error2']})\n\n    error_dict = {'field1': ['error1']}\n    exception = ValidationError({'field1': 'error2', 'field2': 'error3'})\n    updated_dict = exception.update_error_dict(error_dict)\n    self.assertEqual(updated_dict, {'field1': ['error1', 'error2'], 'field2': ['error3']})\n"], "sample_206": ["def test_fieldfile_path(self):\n    \"\"\"\n    FieldFile.path returns the absolute path to the file.\n    \"\"\"\n    d = Document.objects.create(myfile='something.txt')\n    self.assertEqual(d.myfile.path, os.path.join(temp.gettempdir(), 'unused', 'something.txt'))\n"], "sample_208": ["def test_alter_model_options_with_proxy(self):\n    \"\"\"Changing a model's options should make a change, even if it's a proxy.\"\"\"\n    changes = self.get_changes([self.author_proxy], [self.author_proxy_options])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"authorproxy\", options={\n        \"verbose_name\": \"Super Author\"\n    })\n"], "sample_210": ["    def test_get_context_data(self):\n        view = ContextMixin()\n        context = view.get_context_data()\n        self.assertIn('view', context)\n        self.assertEqual(context['view'], view)\n"], "sample_211": ["    def test_get_context_data(self):\n        view = ContextMixin()\n        context = view.get_context_data()\n        self.assertIn('view', context)\n        self.assertEqual(context['view'], view)\n"], "sample_213": ["    def test_field_file_methods(self):\n        obj = Storage()\n        obj.normal.save(\"django_test.txt\", ContentFile(\"content\"))\n        field_file = obj.normal\n\n        # Test FieldFile methods\n        self.assertEqual(field_file.name, \"tests/django_test.txt\")\n        self.assertEqual(field_file.size, 7)\n        self.assertEqual(field_file.url, \"/test_media_url/tests/django_test.txt\")\n\n        # Test file-like object methods\n        self.assertTrue(hasattr(field_file, 'read'))\n        self.assertTrue(hasattr(field_file, 'write'))\n        self.assertTrue(hasattr(field_file, 'close'))\n\n        # Test deletion of file\n        field_file.delete()\n        self.assertFalse(obj.normal.storage.exists(field_file.name))\n"], "sample_212": ["def test_session_middleware_process_response(self):\n    class DummySession:\n            self.session_key = session_key\n            self.accessed = True\n            self.modified = True\n            self.empty = False\n\n            return False\n\n            return 3600\n\n            pass\n\n            return self.empty\n\n    class DummyRequest:\n            self.COOKIES = {settings.SESSION_COOKIE_NAME: 'session_key'}\n            self.session = DummySession('session_key')\n\n    class DummyResponse:\n            self.status_code = 200\n            self.cookies = {}\n\n            self.cookies[key] = {\n                'value': value,\n                'max_age': max_age,\n                'expires': expires,\n                'domain': domain,\n                'path': path,\n                'secure': secure,\n                'httponly': httponly,\n                'samesite': samesite,\n            }\n\n            if key in self.cookies:\n                del self.cookies[key]\n\n    request = DummyRequest()\n    response = DummyResponse()\n\n    SessionMiddleware().process_response(request, response)\n\n    self.assertIn(settings.SESSION_COOKIE_NAME, response.cookies)\n    self.assertEqual(response.cookies[settings.SESSION_COOKIE_NAME]['value'], 'session_key')\n    self.assertEqual(response.cookies[settings.SESSION_COOKIE_NAME]['max_age'], 3600)\n"], "sample_216": ["def test_resolve_relation(self):\n    self.assertEqual(resolve_relation(\"testapp.Model\", \"testapp\", \"Model\"), (\"testapp\", \"model\"))\n    self.assertEqual(resolve_relation(\"testapp.Model\", \"otherapp\", \"OtherModel\"), (\"testapp\", \"model\"))\n    self.assertEqual(resolve_relation(models.Model, \"testapp\", \"Model\"), (\"testapp\", \"model\"))\n    with self.assertRaises(TypeError):\n        resolve_relation(\"testapp.Model\")\n    with self.assertRaises(TypeError):\n        resolve_relation(RECURSIVE_RELATIONSHIP_CONSTANT)\n    with self.assertRaises(TypeError):\n        resolve_relation(RECURSIVE_RELATIONSHIP_CONSTANT, \"testapp\")\n    self.assertEqual(\n        resolve_relation(RECURSIVE_RELATIONSHIP_CONSTANT, \"testapp\", \"Model\"),\n        (\"testapp\", \"model\")\n    )\n"], "sample_220": ["    def test_reason_phrase(self):\n        response = HttpResponse()\n        self.assertEqual(response.reason_phrase, 'OK')\n"], "sample_222": ["    def test_lock_exclusive_on_closed_file(self):\n        with tempfile.TemporaryFile() as temp:\n            file = File(temp, name='something.txt')\n            file.close()\n            self.assertIs(locks.lock(file, locks.LOCK_EX), False)\n"], "sample_226": ["    def test_get_test_db_clone_settings(self):\n        test_connection = get_connection_copy()\n        creation = BaseDatabaseCreation(test_connection)\n        suffix = 'clone_1'\n        clone_settings = creation.get_test_db_clone_settings(suffix)\n        self.assertEqual(clone_settings['NAME'], '{}_{}'.format(test_connection.settings_dict['NAME'], suffix))\n"], "sample_227": ["def test_genericrelation_reverse(self):\n    class TaggedItemAdmin(ModelAdmin):\n        list_filter = ('content_type',)\n\n    modeladmin = TaggedItemAdmin(TaggedItem, site)\n    request = self.request_factory.get('/')\n    request.user = self.alfred\n    changelist = modeladmin.get_changelist_instance(request)\n    filterspec = changelist.get_filters(request)[0][0]\n    self.assertEqual(filterspec.title, 'content type')\n    choices = list(filterspec.choices(changelist))\n    self.assertEqual(len(choices), 2)\n\n    self.assertEqual(choices[0]['display'], 'All')\n    self.assertIs(choices[0]['selected'], True)\n    self.assertEqual(choices[0]['query_string'], '?')\n\n    self.assertEqual(choices[1]['display'], 'bookmark')\n    self.assertIs(choices[1]['selected'], False)\n    self.assertEqual(choices[1]['query_string'], '?content_type__id__exact=%s' % ContentType.objects.get_for_model(Bookmark).pk)\n"], "sample_228": ["def test_formset_with_empty_data(self):\n    \"\"\"A formset with empty data should not raise an AttributeError.\"\"\"\n    data = {\n        'choices-TOTAL_FORMS': '1',\n        'choices-INITIAL_FORMS': '0',\n        'choices-MIN_NUM_FORMS': '0',\n        'choices-MAX_NUM_FORMS': '0',\n    }\n    ChoiceFormSet = formset_factory(Choice)\n    formset = ChoiceFormSet(data, auto_id=False, prefix='choices')\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(formset.errors, [{},])\n"], "sample_231": ["    def test_multivalue_dict_key_error_with_sensitive_post_parameters(self):\n        \"\"\"\n        #21098 -- Sensitive POST parameters cannot be seen in the error reports\n        for if request.POST['nonexistent_key'] throws an error and sensitive_post_parameters is used.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(multivalue_dict_key_error)\n            self.verify_unsafe_email(multivalue_dict_key_error)\n\n        with self.settings(DEBUG=False):\n            self.verify_safe_response(multivalue_dict_key_error)\n            self.verify_safe_email(multivalue_dict_key_error)\n"], "sample_233": ["def test_token_with_legacy_algorithm(self):\n    \"\"\"\n    A valid token can be created with the legacy algorithm (sha1) and is\n    correctly validated.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    # Create a token with the legacy algorithm.\n    p1 = PasswordResetTokenGenerator()\n    p1.algorithm = 'sha1'\n    tk2 = p1.make_token(user)\n    self.assertNotEqual(tk1, tk2)\n    # Check that the token created with the legacy algorithm is valid.\n    self.assertIs(p0.check_token(user, tk2), True)\n    self.assertIs(p1.check_token(user, tk1), False)\n"], "sample_235": ["def test_on_commit_with_closed_connection(self):\n    with transaction.atomic():\n        self.do(1)\n        connection.close()\n\n    with self.assertRaises(DatabaseError):\n        transaction.on_commit(lambda: self.notify(2))\n"], "sample_237": ["def test_builtin_permission_codename_max_length(self):\n    model_name = 'X' * 95\n    model = type(model_name, (models.Model,), {'__module__': self.__module__})\n    errors = checks.run_checks(self.apps.get_app_configs())\n    self.assertEqual(errors, [\n        checks.Error(\n            \"The name of model 'auth_tests.%s' must be at most 93 \"\n            \"characters for its builtin permission codenames to be at \"\n            \"most 100 characters.\" % model_name,\n            obj=model,\n            id='auth.E011',\n        ),\n    ])\n"], "sample_239": ["def test_formset_add_fields_with_can_delete(self):\n    \"\"\"The add_fields method is called with can_delete.\"\"\"\n    class CheckForm(Form):\n        pass\n\n    data = {\n        'check-TOTAL_FORMS': '2',\n        'check-INITIAL_FORMS': '0',\n        'check-MIN_NUM_FORMS': '0',\n        'check-MAX_NUM_FORMS': '0',\n        'check-0-DELETE': '',\n        'check-1-DELETE': '',\n    }\n    CheckFormSet = formset_factory(CheckForm, can_delete=True)\n    formset = CheckFormSet(data, prefix='check')\n    self.assertTrue(formset.is_valid())\n    for form in formset:\n        self.assertIn('DELETE', form.fields)\n"], "sample_240": ["def test_token_with_different_algorithm(self):\n    \"\"\"\n    A valid token can be created with an algorithm other than the default by\n    using the PasswordResetTokenGenerator.algorithm attribute.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    new_algorithm = 'md5'\n    # Create and check a token with a different algorithm.\n    p0 = PasswordResetTokenGenerator()\n    p0.algorithm = new_algorithm\n    tk0 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk0), True)\n    # Create and check a token with the default algorithm.\n    p1 = PasswordResetTokenGenerator()\n    self.assertEqual(p1.algorithm, settings.DEFAULT_HASHING_ALGORITHM)\n    self.assertNotEqual(p1.algorithm, new_algorithm)\n    tk1 = p1.make_token(user)\n    # Tokens created with a different algorithm don't validate.\n    self.assertIs(p0.check_token(user, tk1), False)\n    self.assertIs(p1.check_token(user, tk0), False)\n"], "sample_241": ["    def test_resolve_expression(self):\n        query = Query(Model)\n        inner_query = Query(Model)\n        inner_query.add_annotation(Count('*'), alias='__count', is_summary=True)\n        inner_query.clear_ordering(True)\n        inner_query.clear_limits()\n        inner_query.select_for_update = False\n        inner_query.select_related = False\n\n        with self.assertRaises(DatabaseError):\n            query.resolve_expression(inner_query)\n\n        inner_query.external_aliases = {'alias': True}\n        query.resolve_expression(inner_query)\n"], "sample_244": ["def test_formset_with_empty_management_form_data(self):\n    \"\"\"A formset with empty management form data is invalid.\"\"\"\n    data = {\n        'choices-TOTAL_FORMS': '',\n        'choices-INITIAL_FORMS': '',\n        'choices-MIN_NUM_FORMS': '',\n        'choices-MAX_NUM_FORMS': '',\n        'choices-0-choice': 'Zero',\n        'choices-0-votes': '0',\n    }\n    ChoiceFormSet = formset_factory(Choice)\n    formset = ChoiceFormSet(data, auto_id=False, prefix='choices')\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(\n        formset.non_form_errors(),\n        [\n            'ManagementForm data is missing or has been tampered with. '\n            'Missing fields: choices-TOTAL_FORMS, choices-INITIAL_FORMS. '\n            'You may need to file a bug report if the issue persists.',\n        ],\n    )\n"], "sample_245": ["    def test_remove_obsolete_messages(self):\n        management.call_command('makemessages', locale=[LOCALE], verbosity=0, no_obsolete=True)\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertNotIn('#~ msgid \"Obsolete message\"', po_contents)\n"], "sample_248": ["def test_shell_with_no_backends_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import python interface.\"):\n        call_command('shell')\n"], "sample_249": ["    def test_create_test_db_with_keepdb(self):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        with mock.patch.object(creation, '_create_test_db') as mocked_create:\n            creation.create_test_db(verbosity=0, autoclobber=True, serialize=False, keepdb=True)\n            mocked_create.assert_called_once_with(verbosity=0, autoclobber=True, keepdb=True)\n"], "sample_253": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertEqual(mocked_termios.tcgetattr.call_count, 1)\n        self.assertEqual(mocked_termios.tcsetattr.call_count, 1)\n"], "sample_256": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = '!'\n        html = widget.render(name='password', value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_255": ["def test_get_environ(self):\n    request = WSGIRequest(self.request_factory.get('/').environ)\n    request.makefile = lambda *args, **kwargs: BytesIO()\n    handler = WSGIRequestHandler(request, '192.168.0.2', None)\n\n    # Test that headers with underscores are stripped\n    handler.headers['Some_Header'] = 'bad'\n    environ = handler.get_environ()\n    self.assertNotIn('HTTP_SOME_HEADER', environ)\n\n    # Test that headers without underscores are preserved\n    handler.headers['Some-Header'] = 'good'\n    environ = handler.get_environ()\n    self.assertIn('HTTP_SOME_HEADER', environ)\n"], "sample_258": ["def test_receiver_signal_list_kwargs(self):\n    @receiver([a_signal, b_signal], sender=self.__class__)\n        self.state.append(val)\n    self.state = []\n    a_signal.send(sender=self.__class__, val=True)\n    b_signal.send(sender=self.__class__, val=False)\n    c_signal.send(sender=self.__class__, val=True)\n    self.assertEqual(self.state, [True, False])\n"], "sample_261": ["def test_parse_duration_iso8601(self):\n    test_values = (\n        ('P4DT12H30M5S', timedelta(days=4, hours=12, minutes=30, seconds=5)),\n        ('PT12H30M5S', timedelta(hours=12, minutes=30, seconds=5)),\n        ('P4D', timedelta(days=4)),\n        ('PT5S', timedelta(seconds=5)),\n        ('P0D', timedelta(days=0)),\n        ('PT0S', timedelta(seconds=0)),\n        ('-P4DT12H30M5S', timedelta(days=-4, hours=-12, minutes=-30, seconds=-5)),\n        ('-PT12H30M5S', timedelta(hours=-12, minutes=-30, seconds=-5)),\n    )\n    for source, expected in test_values:\n        with self.subTest(source=source):\n            self.assertEqual(parse_duration(source), expected)\n"], "sample_262": ["def test_classproperty_getter_override(self):\n    class Foo:\n        foo_attr = 123\n\n        @classproperty\n            return cls.foo_attr\n\n    class Bar(Foo):\n        foo_attr = 456\n\n        @Foo.foo.getter\n            return cls.foo_attr * 2\n\n    self.assertEqual(Foo.foo, 123)\n    self.assertEqual(Bar.foo, 912)\n"], "sample_264": ["def test_update_cookie(self):\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # Test setting the cookie with encoded data\n    messages = ['test', 'me']\n    encoded_data = storage._encode(messages)\n    storage._update_cookie(encoded_data, response)\n    self.assertEqual(response.cookies[storage.cookie_name].value, encoded_data)\n\n    # Test deleting the cookie when there's no data to store\n    storage._update_cookie(None, response)\n    self.assertEqual(response.cookies[storage.cookie_name]['max-age'], 0)\n"], "sample_265": ["def test_copy_exception(self):\n    original_exc = TemplateDoesNotExist('template_name', tried=['path1', 'path2'])\n    copied_exc = copy_exception(original_exc)\n    self.assertEqual(copied_exc.args, original_exc.args)\n    self.assertEqual(copied_exc.tried, original_exc.tried)\n    self.assertIsNone(copied_exc.__traceback__)\n    self.assertIsNone(copied_exc.__context__)\n    self.assertIsNone(copied_exc.__cause__)\n"], "sample_266": ["def test_collect_sql(self):\n    loader = MigrationLoader(connection)\n    recorder = MigrationRecorder(connection)\n    self.addCleanup(recorder.flush)\n    plan = [\n        ('migrations', '0001_initial'),\n        ('migrations', '0002_second'),\n    ]\n    sql_statements = loader.collect_sql(plan)\n    self.assertGreater(len(sql_statements), 0)\n    for statement in sql_statements:\n        self.assertIsInstance(statement, str)\n"], "sample_269": ["    def test_javascript_catalog(self):\n        response = self.client.get('/jsi18n/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response['Content-Type'], 'text/javascript; charset=\"utf-8\"')\n"], "sample_271": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_272": ["def test_migration_plan_with_replaced_migrations(self):\n    \"\"\"\n    Tests that replaced migrations are properly handled in the migration plan.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Create a fake migration history where 0001 is applied, but not 0002\n    executor.recorder.record_applied(\"migrations\", \"0001_initial\")\n    # Get the migration plan to go from 0001 to 0003 (which replaces 0002)\n    plan = executor.migration_plan([(\"migrations\", \"0003_third\")])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0002_second\"], False),\n            (executor.loader.graph.nodes[\"migrations\", \"0003_third\"], False),\n        ],\n    )\n    # Make sure the replaced migration is marked as applied\n    self.assertIn((\"migrations\", \"0002_second\"), executor.loader.applied_migrations)\n"], "sample_276": ["    def test_simplify_regex(self):\n        pattern = r\"^(?P<sport_slug>\\w+)/athletes/(?P<athlete_slug>\\w+)/$\"\n        simplified = simplify_regex(pattern)\n        self.assertEqual(simplified, \"/<sport_slug>/athletes/<athlete_slug>/\")\n"], "sample_277": ["def test_register_lookup(self):\n    class MyLookup:\n        lookup_name = 'mylookup'\n\n    class MyModel:\n        pass\n\n    RegisterLookupMixin.register_lookup(MyLookup, lookup_name='mylookup')\n    self.assertIn('mylookup', RegisterLookupMixin.get_lookups())\n\n    RegisterLookupMixin._unregister_lookup(MyLookup, lookup_name='mylookup')\n    self.assertNotIn('mylookup', RegisterLookupMixin.get_lookups())\n"], "sample_278": ["    def test_combine(self):\n        q1 = Q(a=1)\n        q2 = Q(b=2)\n        combined = q1 & q2\n        self.assertEqual(combined.children, [q1, q2])\n        self.assertEqual(combined.connector, Q.AND)\n\n        combined = q1 | q2\n        self.assertEqual(combined.children, [q1, q2])\n        self.assertEqual(combined.connector, Q.OR)\n"], "sample_280": ["def test_aggregation_default_using_float_from_python(self):\n    result = Book.objects.filter(rating__lt=3.0).aggregate(\n        value=Sum('price', default=0.0),\n    )\n    self.assertEqual(result['value'], 0.0)\n\n    result = Book.objects.filter(rating__lt=3.0).aggregate(\n        value=Avg('price', default=0.0),\n    )\n    self.assertEqual(result['value'], 0.0)\n"], "sample_281": ["def test_process_request_invalid_app_label(self):\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'invalid', 'model_name': Answer._meta.model_name, 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n"], "sample_282": ["def test_boundfield_subwidgets(self):\n    form = ComplexFieldForm({\n        'field1_0': 'some text',\n        'field1_1': ['J', 'P'],\n        'field1_2_0': '2007-04-25',\n        'field1_2_1': '06:24:00',\n    })\n    bound_field = form['field1']\n    subwidgets = bound_field.subwidgets\n    self.assertEqual(len(subwidgets), 3)\n    self.assertIsInstance(subwidgets[0], BoundWidget)\n    self.assertIsInstance(subwidgets[1], BoundWidget)\n    self.assertIsInstance(subwidgets[2], BoundWidget)\n    self.assertEqual(subwidgets[0].data['name'], 'field1_0')\n    self.assertEqual(subwidgets[1].data['name'], 'field1_1')\n    self.assertEqual(subwidgets[2].data['name'], 'field1_2_0')\n"], "sample_283": ["def test_runshell_parameters(self):\n    client = DatabaseClient(connection)\n    runshell_patch = mock.patch.object(DatabaseClient, 'runshell')\n    with runshell_patch as runshell_mock:\n        client.runshell(['--help'])\n        runshell_mock.assert_called_once_with(['--help'])\n"], "sample_284": ["    def setUp(self):\n        super().setUp()\n        self._temp_dir = temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, 'test'))\n        self.addCleanup(shutil.rmtree, temp_dir)\n"], "sample_285": ["def test_get_finder(self):\n    finder_path = 'django.contrib.staticfiles.finders.FileSystemFinder'\n    finder = get_finder(finder_path)\n    self.assertIsInstance(finder, BaseFinder)\n\n    # Test that the finder is cached.\n    finder2 = get_finder(finder_path)\n    self.assertIs(finder, finder2)\n\n    # Test that an invalid finder path raises an error.\n    with self.assertRaises(ImportError):\n        get_finder('invalid_finder_path')\n\n    # Test that a finder that is not a subclass of BaseFinder raises an error.\n    with mock.patch('django.utils.module_loading.import_string', return_value=object):\n        with self.assertRaises(ImproperlyConfigured):\n            get_finder(finder_path)\n"], "sample_290": ["def test_suggest_name_with_custom_migration_name(self):\n    class Migration(migrations.Migration):\n        operations = [\n            migrations.CreateModel('Person', fields=[]),\n            migrations.DeleteModel('Animal'),\n        ]\n\n    migration = Migration('some_migration', 'test_app')\n    custom_name = 'custom_name'\n    self.assertEqual(\n        migration.suggest_name(custom_name=custom_name),\n        f'{custom_name}_person_delete_animal',\n    )\n"], "sample_291": ["    def test_setup_sets_request_on_self(self):\n        view = View()\n        request = self.rf.get('/')\n        view.setup(request)\n        self.assertEqual(view.request, request)\n"], "sample_292": ["def test_csrf_trusted_origin_with_port(self):\n    \"\"\"\n    A POST request with an origin that includes a port and matches a \n    CSRF_TRUSTED_ORIGINS setting is accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['HTTP_ORIGIN'] = 'https://dashboard.example.com:8080'\n    mw = CsrfViewMiddleware(post_form_view)\n    with override_settings(ALLOWED_HOSTS=['www.example.com'], CSRF_TRUSTED_ORIGINS=['https://dashboard.example.com:8080']):\n        self.assertIs(mw._origin_verified(req), True)\n        resp = mw.process_view(req, post_form_view, (), {})\n        self.assertIsNone(resp)\n"], "sample_293": ["    def test_warning_on_invalid_pattern(self):\n        msg = (\n            \"Your URL pattern '^invalid/$' [name='invalid'] has a route \"\n            \"beginning with a '/'. Remove this slash as it is unnecessary. If \"\n            \"this pattern is targeted in an include(), ensure the include() \"\n            \"pattern has a trailing '/'\"\n        )\n        warnings = check_resolver(get_resolver())\n        self.assertEqual(len(warnings), 1)\n        self.assertEqual(warnings[0].msg, msg)\n"], "sample_296": ["def test_safedata(self):\n    storage = self.get_storage()\n    safe_message = mark_safe(\"<p>Hello, world!</p>\")\n    message = Message(constants.DEBUG, safe_message)\n    encoded = storage._encode([message])\n    decoded = storage._decode(encoded)[0]\n    self.assertIsInstance(decoded.message, SafeData)\n    self.assertEqual(decoded.message, safe_message)\n"], "sample_298": ["def test_token_with_invalid_input(self):\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    \n    # Test with invalid token format\n    self.assertIs(p0.check_token(user, 'invalid-token'), False)\n    \n    # Test with token that has been tampered with\n    ts_b36, _ = tk1.split(\"-\")\n    tampered_token = f\"{ts_b36}-tampered-hash\"\n    self.assertIs(p0.check_token(user, tampered_token), False)\n    \n    # Test with token that has an invalid timestamp\n    invalid_ts_b36 = ' invalid'\n    invalid_token = f\"{invalid_ts_b36}-{tk1.split('-')[1]}\"\n    self.assertIs(p0.check_token(user, invalid_token), False)\n"], "sample_301": ["    def test_ensure_echo_on_when_termios_available(self, mocked_termios):\n        with mock.patch('sys.stdin.isatty', return_value=True):\n            autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_302": ["    def setUp(self):\n        self.client = DatabaseClient(connection=connection)\n"], "sample_303": ["def test_runshell_raises_not_implemented_error(self):\n    msg = (\n        'subclasses of BaseDatabaseClient must provide a '\n        'settings_to_cmd_args_env() method or override a runshell().'\n    )\n    with self.assertRaisesMessage(NotImplementedError, msg):\n        self.client.runshell(None)\n"], "sample_304": ["    def test_custom_schemes(self):\n        validator = URLValidator(schemes=['http', 'https', 'custom'])\n        self.assertIsNone(validator('http://example.com'))\n        self.assertIsNone(validator('https://example.com'))\n        self.assertIsNone(validator('custom://example.com'))\n"], "sample_306": ["def test_parse_iso8601_duration(self):\n    test_values = (\n        ('P3D', timedelta(days=3)),\n        ('PT4H', timedelta(hours=4)),\n        ('PT5M', timedelta(minutes=5)),\n        ('PT6S', timedelta(seconds=6)),\n        ('P1DT2H3M4S', timedelta(days=1, hours=2, minutes=3, seconds=4)),\n        ('-P1DT2H3M4S', timedelta(days=-1, hours=-2, minutes=-3, seconds=-4)),\n        ('P0.5D', timedelta(days=0.5)),\n        ('PT0.5H', timedelta(hours=0.5)),\n        ('PT0.5M', timedelta(minutes=0.5)),\n        ('PT0.5S', timedelta(seconds=0.5)),\n    )\n    for source, expected in test_values:\n        with self.subTest(source=source):\n            self.assertEqual(parse_duration(source), expected)\n"], "sample_309": ["    def test_escape_leading_slashes(self):\n        self.assertEqual(escape_leading_slashes('//example.com'), '/%2F/example.com')\n        self.assertEqual(escape_leading_slashes('/example.com'), '/example.com')\n        self.assertEqual(escape_leading_slashes('example.com'), 'example.com')\n"], "sample_310": ["    def test_simplify_regex(self):\n        pattern = r\"^(?P<sport_slug>\\w+)/athletes/(?P<athlete_slug>\\w+)/$\"\n        simplified = simplify_regex(pattern)\n        self.assertEqual(simplified, \"/<sport_slug>/athletes/<athlete_slug>/\")\n"], "sample_312": ["def test_add_squash(self):\n    node1 = Node([('a', 1), ('b', 2)], connector='OR')\n    node2 = Node([('c', 3), ('d', 4)], connector='OR')\n    node1.add(node2, 'OR')\n    self.assertEqual(len(node1.children), 4)\n    self.assertEqual(str(node1), \"(OR: ('a', 1), ('b', 2), ('c', 3), ('d', 4))\")\n"], "sample_313": ["def test_get_template_directories_with_django_path(self, mock_is_django_path):\n    mock_is_django_path.return_value = True\n    with override_settings(\n        TEMPLATES=[{\n            'BACKEND': 'django.template.backends.django.DjangoTemplates',\n            'DIRS': [EXTRA_TEMPLATES_DIR],\n        }]\n    ):\n        self.assertSetEqual(\n            autoreload.get_template_directories(),\n            set()\n        )\n"], "sample_314": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = '!'\n        html = widget.render(name='password', value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_315": ["    def test_middleware_with_language_prefix(self):\n        response = self.client.get('/en/account/register/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.headers['content-language'], 'en')\n        self.assertEqual(response.context['LANGUAGE_CODE'], 'en')\n"], "sample_316": ["    def test_image_file_dimensions(self):\n        img_path = os.path.join(os.path.dirname(__file__), \"test.png\")\n        with open(img_path, 'rb') as fh:\n            image_file = images.ImageFile(fh)\n            self.assertEqual(image_file.width, Image.open(fh).size[0])\n            self.assertEqual(image_file.height, Image.open(fh).size[1])\n"], "sample_318": ["    def test_warning_on_invalid_pattern(self):\n        msg = (\n            \"Your URL pattern '^invalid-regex/$' [name='invalid-regex'] has a \"\n            \"route that contains '(?P<', begins with a '^', or ends with a '$'. \"\n            \"This was likely an oversight when migrating to django.urls.path().\"\n        )\n        warnings = check_resolver(get_resolver())\n        self.assertEqual(len(warnings), 1)\n        self.assertEqual(warnings[0].msg, msg)\n"], "sample_321": ["def test_csrf_trusted_origins_wildcard_domain(self):\n    \"\"\"\n    A POST request with an origin that matches a wildcard domain in\n    CSRF_TRUSTED_ORIGINS is accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req.META['HTTP_ORIGIN'] = 'https://subdomain.example.com'\n    with self.settings(CSRF_TRUSTED_ORIGINS=['https://*.example.com']):\n        mw = CsrfViewMiddleware(post_form_view)\n        self.assertIs(mw._origin_verified(req), True)\n        response = mw.process_view(req, post_form_view, (), {})\n        self.assertIsNone(response)\n"], "sample_322": ["def test_migration_plan_with_replaced_migrations(self):\n    \"\"\"\n    Tests that replaced migrations are properly handled in the migration plan.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Make sure the replaced migration is not applied\n    self.assertNotIn((\"migrations\", \"0001_initial\"), executor.loader.applied_migrations)\n    # Create a plan to apply the replacing migration\n    plan = executor.migration_plan([(\"migrations\", \"0002_second\")])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n            (executor.loader.graph.nodes[\"migrations\", \"0002_second\"], False),\n        ],\n    )\n    # Fake-apply the replaced migration\n    executor.migrate([(\"migrations\", \"0001_initial\")], fake=True)\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Create a new plan to apply the replacing migration\n    plan = executor.migration_plan([(\"migrations\", \"0002_second\")])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0002_second\"], False),\n        ],\n    )\n"], "sample_323": ["def test_migration_plan_with_replaced_migrations(self):\n    \"\"\"\n    Tests that replaced migrations are properly handled in the migration plan.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Make sure the replaced migration is not applied\n    self.assertNotIn((\"migrations\", \"0001_initial\"), executor.loader.applied_migrations)\n    # Apply the replacing migration\n    executor.migrate([(\"migrations\", \"0002_second\")])\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Check the plan for unapplying the replacing migration\n    plan = executor.migration_plan([(\"migrations\", None)])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0002_second\"], True),\n        ],\n    )\n    # Unapply the replacing migration\n    executor.migrate([(\"migrations\", None)])\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Check the plan for reapplying the replaced migration\n    plan = executor.migration_plan([(\"migrations\", \"0001_initial\")])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n        ],\n    )\n"], "sample_324": ["def test_csrf_trusted_origins_wildcard_subdomain(self):\n    \"\"\"\n    A POST request with an origin that matches a wildcard subdomain in\n    CSRF_TRUSTED_ORIGINS is accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['HTTP_ORIGIN'] = 'https://subdomain.dashboard.example.com'\n    mw = CsrfViewMiddleware(post_form_view)\n    with override_settings(CSRF_TRUSTED_ORIGINS=['https://*.dashboard.example.com']):\n        self.assertIs(mw._origin_verified(req), True)\n        response = mw.process_view(req, post_form_view, (), {})\n        self.assertIsNone(response)\n"], "sample_326": ["def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            'Search for google.com.',\n            'Search for <a href=\"http://google.com/\">google.com</a>.'\n        ),\n        (\n            'Search for google.com!?',\n            'Search for <a href=\"http://google.com/\">google.com</a>!?'\n        ),\n        (\n            'Search for www.google.com.',\n            'Search for <a href=\"http://www.google.com/\">www.google.com</a>.'\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_330": ["    def test_truncate_name_length(self):\n        # Test that the truncate_name function doesn't fail when given a length\n        # longer than the name.\n        self.assertEqual(truncate_name(identifier=\"test\", length=10), \"test\")\n"], "sample_331": ["def test_parse_iso8601_duration(self):\n    test_values = (\n        ('P3D', timedelta(days=3)),\n        ('PT4H', timedelta(hours=4)),\n        ('PT5M', timedelta(minutes=5)),\n        ('PT6S', timedelta(seconds=6)),\n        ('P3DT4H5M6S', timedelta(days=3, hours=4, minutes=5, seconds=6)),\n        ('-P3D', timedelta(days=-3)),\n        ('-PT4H', timedelta(hours=-4)),\n        ('-PT5M', timedelta(minutes=-5)),\n        ('-PT6S', timedelta(seconds=-6)),\n        ('-P3DT4H5M6S', timedelta(days=-3, hours=-4, minutes=-5, seconds=-6)),\n    )\n    for source, expected in test_values:\n        with self.subTest(source=source):\n            self.assertEqual(parse_duration(source), expected)\n"], "sample_332": ["def test_formset_add_fields(self):\n    \"\"\"A formset has an add_fields method to add fields to each form.\"\"\"\n    class AddFieldsFormSet(BaseFormSet):\n            super().add_fields(form, index)\n            form.fields['extra_field'] = CharField()\n\n    AddFieldsFormSet = formset_factory(Choice, formset=AddFieldsFormSet)\n    formset = AddFieldsFormSet()\n    for form in formset.forms:\n        self.assertIn('extra_field', form.fields)\n"], "sample_333": ["def test_field_order_with_inheritance(self):\n    class ParentForm(Form):\n        field1 = CharField()\n        field2 = CharField()\n\n    class ChildForm(ParentForm):\n        field3 = CharField()\n        field4 = CharField()\n\n        field_order = ['field3', 'field1', 'field2', 'field4']\n\n    form = ChildForm()\n    self.assertEqual(list(form.fields), ['field3', 'field1', 'field2', 'field4'])\n"], "sample_336": ["    def test_locale_regex_descriptor(self):\n        resolver = get_resolver()\n        pattern = resolver.url_patterns[0].pattern\n        self.assertIsInstance(pattern.regex, LocaleRegexDescriptor)\n        self.assertEqual(pattern.regex.__get__(pattern).pattern, '^normal/$')\n"], "sample_337": ["def test_csrf_trusted_origins_wildcard_domain(self):\n    \"\"\"\n    A POST request with an origin that matches a CSRF_TRUSTED_ORIGINS wildcard\n    domain is accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req.META['HTTP_ORIGIN'] = 'https://subdomain.example.com'\n    with self.settings(CSRF_TRUSTED_ORIGINS=['https://*.example.com']):\n        mw = CsrfViewMiddleware(post_form_view)\n        self.assertIs(mw._origin_verified(req), True)\n        response = mw.process_view(req, post_form_view, (), {})\n        self.assertIsNone(response)\n"], "sample_339": ["def test_modelformset_factory_with_custom_form(self):\n    class CustomBookForm(forms.ModelForm):\n            super().__init__(*args, **kwargs)\n            self.fields['title'].required = False\n\n        class Meta:\n            model = Book\n            fields = '__all__'\n\n    BookFormSet = modelformset_factory(Book, form=CustomBookForm)\n    formset = BookFormSet()\n    self.assertFalse(formset.forms[0].fields['title'].required)\n"], "sample_340": ["def test_collect_sql(self):\n    loader = MigrationLoader(connection)\n    recorder = MigrationRecorder(connection)\n    self.addCleanup(recorder.flush)\n    plan = [\n        ('migrations', '0001_initial'),\n        ('migrations', '0002_second'),\n    ]\n    sql_statements = loader.collect_sql(plan)\n    self.assertGreater(len(sql_statements), 0)\n    for statement in sql_statements:\n        self.assertIsInstance(statement, str)\n"], "sample_341": ["def test_formset_add_fields_with_empty_permitted(self):\n    \"\"\"A form added to a formset with empty_permitted=True is valid.\"\"\"\n    class BaseDynamicFormSet(BaseFormSet):\n            super().add_fields(form, index)\n            form.fields['extra_field'] = CharField(required=False)\n\n    DynamicFormSet = formset_factory(FavoriteDrinkForm, formset=BaseDynamicFormSet, extra=1)\n    data = {\n        'form-TOTAL_FORMS': '1',\n        'form-INITIAL_FORMS': '0',\n        'form-MIN_NUM_FORMS': '0',\n        'form-MAX_NUM_FORMS': '0',\n        'form-0-name': '',\n        'form-0-extra_field': '',\n    }\n    formset = DynamicFormSet(data, prefix='form')\n    self.assertTrue(formset.is_valid())\n"], "sample_342": ["def test_process_request_invalid_app_label(self):\n    request = self.factory.get(self.url, {'term': 'is', 'app_label': 'invalid', 'model_name': Answer._meta.model_name, 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n"], "sample_345": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_346": ["    def test_sync_and_async_middleware(self):\n        @sync_and_async_middleware\n            return get_response\n\n        self.assertTrue(my_middleware.sync_capable)\n        self.assertTrue(my_middleware.async_capable)\n"], "sample_347": ["def test_get_current_timezone_name(self):\n    \"\"\"\n    The get_current_timezone_name() function must return the name of the\n    currently active time zone.\n    \"\"\"\n    timezone.activate(EAT)\n    self.assertEqual(timezone.get_current_timezone_name(), 'Etc/GMT-3')\n\n    timezone.deactivate()\n    self.assertEqual(timezone.get_current_timezone_name(), 'America/Chicago')\n"], "sample_351": ["def test_model_choice_iterator_value_equality(self):\n    value_1 = ModelChoiceIteratorValue(self.c1.pk, self.c1)\n    value_2 = ModelChoiceIteratorValue(self.c1.pk, None)\n    value_3 = ModelChoiceIteratorValue(self.c2.pk, self.c2)\n\n    self.assertEqual(value_1, value_2)\n    self.assertEqual(value_1, self.c1.pk)\n    self.assertNotEqual(value_1, value_3)\n    self.assertNotEqual(value_1, self.c2.pk)\n"], "sample_353": ["    def test_get_default_username_checks_database(self):\n        User.objects.create(username=get_system_username())\n        self.assertEqual(get_default_username(), '')\n        self.assertEqual(get_default_username(database='other'), get_system_username())\n"], "sample_354": ["    def test_validate_fk_with_invalid_input(self):\n        email = Email.objects.create(email='mymail@gmail.com')\n        nonexistent_group_id = 'nonexistent'\n\n        @mock_inputs({\n            'password': 'nopasswd',\n            'Username (Email.id): ': email.pk,\n            'Email (Email.email): ': email.email,\n            'Group (Group.id): ': nonexistent_group_id,\n        })\n            with self.assertRaisesMessage(CommandError, f'group instance with id {nonexistent_group_id} does not exist.'):\n                call_command(\n                    'createsuperuser',\n                    interactive=True,\n                    stdin=MockTTY(),\n                    stdout=StringIO(),\n                    stderr=StringIO(),\n                )\n\n        test(self)\n"], "sample_355": ["    def setUpTestData(cls):\n        cls.user = User.objects.create_user('test', 'test@example.com', 'test')\n"], "sample_358": ["    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(),\n            col_suffixes=('ASC', 'DESC'), opclasses=('text_ops', 'int4_ops')\n        )\n"], "sample_360": ["    def tearDown(self):\n        cache.clear()\n"], "sample_361": ["def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            'Search for google.com.',\n            'Search for <a href=\"http://google.com/\">google.com</a>.'\n        ),\n        (\n            'Search for google.com!?',\n            'Search for <a href=\"http://google.com/\">google.com</a>!?'\n        ),\n        (\n            'Search for google.com,',\n            'Search for <a href=\"http://google.com/\">google.com</a>,'\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_364": ["    def test_include_with_namespace(self):\n        match = resolve('/included_urls/namespaced/something/')\n        self.assertEqual(match.url_name, 'inner-namespaced')\n        self.assertEqual(match.route, 'included_urls/namespaced/<extra>/')\n"], "sample_365": ["def test_classproperty(self):\n    class Foo:\n        foo_attr = 123\n\n            self.foo_attr = 456\n\n        @classproperty\n            return cls.foo_attr\n\n    self.assertEqual(Foo.foo, 123)\n    self.assertEqual(Foo().foo, 123)\n\n    Foo.foo_attr = 789\n    self.assertEqual(Foo.foo, 789)\n    self.assertEqual(Foo().foo, 789)\n"], "sample_366": ["def test_parse_iso8601_duration(self):\n    test_values = (\n        ('P3D', timedelta(days=3)),\n        ('PT4H', timedelta(hours=4)),\n        ('PT5M', timedelta(minutes=5)),\n        ('PT6S', timedelta(seconds=6)),\n        ('P3DT4H5M6S', timedelta(days=3, hours=4, minutes=5, seconds=6)),\n        ('-P3D', timedelta(days=-3)),\n        ('-PT4H', timedelta(hours=-4)),\n        ('-PT5M', timedelta(minutes=-5)),\n        ('-PT6S', timedelta(seconds=-6)),\n        ('-P3DT4H5M6S', timedelta(days=-3, hours=-4, minutes=-5, seconds=-6)),\n    )\n    for source, expected in test_values:\n        with self.subTest(source=source):\n            self.assertEqual(parse_duration(source), expected)\n"], "sample_367": ["    def test_cache_page_decorator_with_key_prefix(self):\n        @cache_page(60, key_prefix='test')\n            return HttpResponse()\n\n        request = HttpRequest()\n        response = a_view(request)\n        self.assertEqual(response.status_code, 200)\n"], "sample_368": ["def test_migration_plan_with_replaced_migrations(self):\n    \"\"\"\n    Tests that replaced migrations are properly handled in the migration plan.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Make sure the replaced migration is not applied\n    self.assertNotIn((\"migrations\", \"0001_initial\"), executor.loader.applied_migrations)\n    # Create a plan to apply the replacing migration\n    plan = executor.migration_plan([(\"migrations\", \"0002_second\")])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n            (executor.loader.graph.nodes[\"migrations\", \"0002_second\"], False),\n        ],\n    )\n    # Fake-apply the replaced migration\n    executor.migrate([(\"migrations\", \"0001_initial\")], fake=True)\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Create a new plan to apply the replacing migration\n    plan = executor.migration_plan([(\"migrations\", \"0002_second\")])\n    self.assertEqual(\n        plan,\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0002_second\"], False),\n        ],\n    )\n"], "sample_371": ["    def test_technical_404_template(self):\n        exception = Http404('Testing technical 404.')\n        request = self.rf.get('/test_view/')\n        response = technical_404_response(request, exception)\n        self.assertContains(response, '<h1>Page not found <span>(404)</span></h1>', status_code=404)\n        self.assertContains(response, 'Testing technical 404.', status_code=404)\n"], "sample_372": ["    def test_warning_for_pattern_starting_with_slash(self):\n        msg = (\n            \"Your URL pattern '^/test/$' has a route beginning with a '/'. \"\n            \"Remove this slash as it is unnecessary. If this pattern is targeted \"\n            \"in an include(), ensure the include() pattern has a trailing '/'\"\n        )\n        with self.assertWarnsMessage(Warning, msg):\n            check_resolver(get_resolver('urlpatterns_reverse.urls'))\n"], "sample_373": ["    def test_simplify_regex(self):\n        pattern = r\"^(?P<sport_slug>\\w+)/athletes/(?P<athlete_slug>\\w+)/$\"\n        simplified = simplify_regex(pattern)\n        self.assertEqual(simplified, \"/<sport_slug>/athletes/<athlete_slug>/\")\n"], "sample_376": ["def test_update_cookie(self):\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # Test setting the cookie with encoded data\n    messages = [Message(constants.INFO, 'Test message')]\n    encoded_data = storage._encode(messages)\n    storage._update_cookie(encoded_data, response)\n    self.assertEqual(response.cookies['messages'].value, encoded_data)\n\n    # Test deleting the cookie when there's no encoded data\n    storage._update_cookie(None, response)\n    self.assertEqual(response.cookies['messages']['max-age'], 0)\n"], "sample_377": ["    def test_is_enabled(self):\n        reporter_filter = SafeExceptionReporterFilter()\n        request = RequestFactory().get(\"/test_view/\")\n        self.assertTrue(reporter_filter.is_active(request))\n"], "sample_379": ["def test_safe_string_addition(self):\n    s1 = SafeString('a&b')\n    s2 = SafeString('c&d')\n\n    result = s1 + s2\n    self.assertIsInstance(result, SafeString)\n    self.assertEqual(result, 'a&bc&d')\n\n    s3 = 'e&f'\n    result = s1 + s3\n    self.assertNotIsInstance(result, SafeString)\n    self.assertEqual(result, 'a&be&f')\n"], "sample_380": ["def test_aggregate_over_subquery_annotation(self):\n    subquery = Book.objects.filter(publisher=OuterRef('pk')).order_by('-pubdate').values('pubdate')[:1]\n    publishers = Publisher.objects.annotate(\n        latest_book_pubdate=Subquery(subquery),\n    ).aggregate(Max('latest_book_pubdate'))\n    self.assertEqual(\n        publishers,\n        {'latest_book_pubdate__max': datetime.date(2008, 12, 6)},\n    )\n"], "sample_382": ["def test_get_template_directories_with_loader_without_get_dirs(self):\n    self.assertSetEqual(\n        autoreload.get_template_directories(),\n        {\n            EXTRA_TEMPLATES_DIR,\n            ROOT / 'templates',\n        }\n    )\n"], "sample_383": ["    def test_ticket_24748(self):\n        \"\"\"\n        Ensure that the ORM can handle a subquery with an aggregate function\n        and a non-nullable foreign key.\n        \"\"\"\n        apple = Food.objects.create(name=\"apple\")\n        lunch = Eaten.objects.create(food=apple, meal=\"lunch\")\n        dinner = Eaten.objects.create(food=apple, meal=\"dinner\")\n\n        self.assertSequenceEqual(\n            Eaten.objects.filter(\n                food__in=Food.objects.annotate(num_eaten=Count(\"eaten\")).filter(\n                    num_eaten__gt=1\n                )\n            ),\n            [lunch, dinner],\n        )\n"], "sample_385": ["def test_autocomplete_select_multiple(self):\n    beatles = Band.objects.create(name=\"The Beatles\", style=\"rock\")\n    who = Band.objects.create(name=\"The Who\", style=\"rock\")\n    form = AlbumForm(initial={\"featuring\": [beatles.pk, who.pk]})\n    output = form.as_table()\n    selected_option1 = (\n        '<option value=\"%s\" selected>The Beatles</option>' % beatles.pk\n    )\n    selected_option2 = '<option value=\"%s\" selected>The Who</option>' % who.pk\n    self.assertIn(selected_option1, output)\n    self.assertIn(selected_option2, output)\n"], "sample_386": ["def test_safe_string_addition(self):\n    \"\"\"\n    Test that adding two SafeString instances results in a new SafeString.\n    \"\"\"\n    s1 = mark_safe(\"a&b\")\n    s2 = mark_safe(\"c&d\")\n    result = s1 + s2\n    self.assertIsInstance(result, SafeString)\n    self.assertEqual(result, \"a&bc&d\")\n\n    # Test that adding a SafeString with a non-SafeString results in a non-SafeString.\n    s3 = \"e&f\"\n    result = s1 + s3\n    self.assertNotIsInstance(result, SafeString)\n    self.assertEqual(result, \"a&be&f\")\n"], "sample_388": ["    def test_csrf_rotation_with_remote_user_login(self):\n        # Create a user and a client with an initial CSRF token\n        user = User.objects.create(username=\"testuser\")\n        client = Client(enforce_csrf_checks=True)\n        response = client.get(\"/remote_user/\")\n        csrf_token = response.cookies[settings.CSRF_COOKIE_NAME].value\n\n        # Simulate a remote user login with a new CSRF token\n        new_csrf_token = _get_new_csrf_string()\n        client.cookies.load({settings.CSRF_COOKIE_NAME: new_csrf_token})\n        headers = {RemoteUserTest.header: \"testuser\"}\n        response = client.get(\"/remote_user/\", **headers)\n\n        # Verify that the CSRF token has been rotated\n        self.assertNotEqual(csrf_token, response.cookies[settings.CSRF_COOKIE_NAME].value)\n        self.assertEqual(new_csrf_token, response.cookies[settings.CSRF_COOKIE_NAME].value)\n"], "sample_390": ["def test_was_modified_since_with_size(self):\n    \"\"\"\n    Test was_modified_since with file size.\n    \"\"\"\n    mtime = 1343416141\n    size = 100\n    header = http_date(mtime) + \"; length=\" + str(size)\n    self.assertFalse(was_modified_since(header, mtime, size))\n    self.assertTrue(was_modified_since(header, mtime, size + 1))\n"], "sample_393": ["    def test_no_obsolete_enabled(self):\n        management.call_command(\n            \"makemessages\", locale=[LOCALE], verbosity=0, no_obsolete=True\n        )\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertNotIn(\"#~ msgid \\\"Obsolete message\\\"\", po_contents)\n"], "sample_395": ["def test_get_template_directories_with_locmem_loader(self):\n    self.assertSetEqual(\n        autoreload.get_template_directories(),\n        {\n            ROOT / \"templates_extra\",\n            ROOT / \"templates\",\n        },\n    )\n"], "sample_397": ["def test_get_template_loaders(self):\n    engine = DjangoTemplates(\n        {\n            \"DIRS\": [],\n            \"APP_DIRS\": False,\n            \"NAME\": \"django\",\n            \"OPTIONS\": {\n                \"loaders\": [\n                    \"django.template.loaders.filesystem.Loader\",\n                    \"django.template.loaders.app_directories.Loader\",\n                ],\n            },\n        }\n    )\n\n    loaders = engine.engine.get_template_loaders(engine.engine.loaders)\n    self.assertEqual(len(loaders), 2)\n    self.assertIsInstance(loaders[0], import_string(\"django.template.loaders.filesystem.Loader\"))\n    self.assertIsInstance(loaders[1], import_string(\"django.template.loaders.app_directories.Loader\"))\n"], "sample_398": ["    def test_login_view_with_custom_template(self):\n        response = self.client.get(\"/login/custom_template/\")\n        self.assertEqual(response.status_code, 200)\n        self.assertTemplateUsed(response, \"custom_login.html\")\n"], "sample_402": ["def test_prepend_www_append_slash_redirect_querystring(self):\n    \"\"\"\n    PREPEND_WWW and APPEND_SLASH should preserve querystrings when redirecting.\n    \"\"\"\n    request = self.rf.get(\"/slash?test=1\")\n    resp = CommonMiddleware(get_response_404)(request)\n    self.assertEqual(resp.url, \"http://www.testserver/slash/?test=1\")\n"], "sample_404": ["def test_variable_node_render(self):\n    engine = self._engine()\n    template = engine.from_string(\"{{ foo }}\")\n    context = Context({\"foo\": \"bar\"})\n    self.assertEqual(template.render(context), \"bar\")\n\n    # Test that VariableNode renders an empty string for an undefined variable.\n    template = engine.from_string(\"{{ foo }}\")\n    context = Context()\n    self.assertEqual(template.render(context), \"\")\n\n    # Test that VariableNode renders the value of a defined variable.\n    template = engine.from_string(\"{{ foo }}\")\n    context = Context({\"foo\": \"bar\"})\n    self.assertEqual(template.render(context), \"bar\")\n\n    # Test that VariableNode renders the value of a variable with a filter.\n    template = engine.from_string(\"{{ foo|upper }}\")\n    context = Context({\"foo\": \"bar\"})\n    self.assertEqual(template.render(context), \"BAR\")\n"], "sample_406": ["    def test_manager_descriptor(self):\n        # Test that the manager descriptor returns the correct manager instance\n        self.assertIsInstance(Article.objects, Manager)\n        self.assertEqual(Article.objects.__class__, ManagerDescriptor)\n"], "sample_407": ["def test_foreign_key_to_field_instance_caching(self):\n    parent = Parent.objects.create(name=\"a\")\n    child = ToFieldChild.objects.create(parent=parent)\n    with self.assertNumQueries(0):\n        self.assertIs(child.parent, parent)\n\n    # The cache should be populated after the first access.\n    with self.assertNumQueries(0):\n        self.assertIs(child.parent, parent)\n\n    # If we assign a new value to the foreign key field, the cache should be cleared.\n    child.parent_id = \"b\"\n    with self.assertNumQueries(1):\n        self.assertIsNot(child.parent, parent)\n"], "sample_409": ["    def test_render_token_list(self):\n        node = BlockTranslateNode({}, [], None, None, None)\n        token_list = [\n            Token(TokenType.TEXT, \"Hello \"),\n            Token(TokenType.VAR, \"name\"),\n            Token(TokenType.TEXT, \"!\"),\n        ]\n        result, vars = node.render_token_list(token_list)\n        self.assertEqual(result, \"Hello %(name)s!\")\n        self.assertEqual(vars, [\"name\"])\n"], "sample_410": ["    def test_get_email_field_name(self):\n        self.assertEqual(AbstractBaseUser.get_email_field_name(), \"email\")\n"], "sample_411": ["def test_suppressed_base_arguments(self):\n    class Command(BaseCommand):\n        suppressed_base_arguments = {\"--version\", \"--verbosity\"}\n\n    parser = Command().create_parser(\"prog_name\", \"subcommand\")\n    help_text = parser.format_help()\n    self.assertNotIn(\"--version\", help_text)\n    self.assertNotIn(\"--verbosity\", help_text)\n"], "sample_412": ["def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            \"Search for google.com.\",\n            'Search for <a href=\"http://google.com/\">google.com</a>.',\n        ),\n        (\n            \"Search for google.com!?\",\n            'Search for <a href=\"http://google.com/\">google.com</a>!?',\n        ),\n        (\n            \"Search for google.com,\",\n            'Search for <a href=\"http://google.com/\">google.com</a>,',\n        ),\n        (\n            \"Search for google.com;\",\n            'Search for <a href=\"http://google.com/\">google.com</a>;',\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_413": ["    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n"], "sample_416": ["def test_runshell_with_parameters(self):\n    with mock.patch.object(DatabaseClient, \"settings_to_cmd_args_env\") as mock_settings:\n        mock_settings.return_value = ([\"psql\", \"-U\", \"someuser\", \"dbname\"], None)\n        client = DatabaseClient(connection)\n        client.runshell([\"--help\"])\n        mock_settings.assert_called_once_with(connection.settings_dict, [\"--help\"])\n"], "sample_420": ["    def test_disabled_fields(self):\n        class DisabledFieldsForm(forms.ModelForm):\n            class Meta:\n                model = Category\n                fields = \"__all__\"\n                disabled_fields = (\"name\",)\n\n        form = DisabledFieldsForm()\n        self.assertTrue(form.fields[\"name\"].disabled)\n        self.assertFalse(form.fields[\"slug\"].disabled)\n        self.assertFalse(form.fields[\"url\"].disabled)\n"], "sample_426": ["def test_depth_zero(self):\n    with self.assertRaises(ValueError):\n        timesince(self.t, depth=0)\n    with self.assertRaises(ValueError):\n        timeuntil(self.t, depth=0)\n"], "sample_428": ["def test_decimal_subclass_formatting(self):\n    class EuroDecimal(Decimal):\n        \"\"\"\n        Wrapper for Decimal which prefixes each amount with the \u20ac symbol.\n        \"\"\"\n\n            amount = super().__format__(specifier, **kwargs)\n            return \"\u20ac {}\".format(amount)\n\n    euro_value = EuroDecimal(\"1234.56\")\n    self.assertEqual(nformat(euro_value, \".\"), \"\u20ac 1234.56\")\n    self.assertEqual(nformat(euro_value, \".\", decimal_pos=2), \"\u20ac 1234.56\")\n    self.assertEqual(\n        nformat(euro_value, \".\", grouping=3, thousand_sep=\",\"), \"\u20ac 1,234.56\"\n    )\n    self.assertEqual(\n        nformat(euro_value, \".\", grouping=3, thousand_sep=\",\", force_grouping=True),\n        \"\u20ac 1,234.56\",\n    )\n"], "sample_429": ["def test_prohibit_null_characters_validator_message(self):\n    v = ProhibitNullCharactersValidator(\n        message=\"Null characters are not allowed in %(value)s.\"\n    )\n    with self.assertRaisesMessage(\n        ValidationError, \"Null characters are not allowed in something.\"\n    ):\n        v(\"\\x00something\")\n"], "sample_433": ["def test_suggest_name_with_custom_migration_name(self):\n    class Migration(migrations.Migration):\n        operations = [\n            migrations.CreateModel(\"Person\", fields=[]),\n            migrations.DeleteModel(\"Animal\"),\n        ]\n\n    migration = Migration(\"custom_name\", \"test_app\")\n    self.assertEqual(migration.suggest_name(), \"0001_custom_name\")\n"], "sample_434": ["    def test_template_view_renders_correctly(self):\n        class TestTemplateView(TemplateView):\n            template_name = \"test_template.html\"\n\n        request_factory = RequestFactory()\n        request = request_factory.get(\"/\")\n        response = TestTemplateView.as_view()(request)\n        self.assertIsInstance(response, TemplateResponse)\n        self.assertEqual(response.template_name, [\"test_template.html\"])\n"], "sample_435": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = \"unusable\"\n        html = widget.render(name=\"password\", value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_436": ["    def test_runserver_command_options(self):\n        args = [\"runserver\", \"--help\"]\n        out, err = self.run_manage(args)\n        self.assertNoOutput(err)\n        self.assertOutput(out, \"--ipv6\")\n        self.assertOutput(out, \"--nothreading\")\n        self.assertOutput(out, \"--noreload\")\n"], "sample_437": ["    def test_validate_thread_sharing(self):\n        conn = connections[DEFAULT_DB_ALIAS]\n        # Simulate a connection created in another thread.\n        conn._thread_ident = 123\n\n        with self.assertRaises(DatabaseError):\n            conn.cursor()\n\n        # Allow thread sharing.\n        conn.inc_thread_sharing()\n        try:\n            conn.cursor()\n        finally:\n            conn.dec_thread_sharing()\n\n        # Disallow thread sharing again and check that an exception is raised.\n        with self.assertRaises(DatabaseError):\n            conn.cursor()\n"], "sample_438": ["def test_deferred_generic_foreign_key(self):\n    class Model(models.Model):\n        field = GenericForeignKey()\n\n    instance = Model()\n    self.assertIs(instance.field, models.DEFERRED)\n"], "sample_441": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = \"unusable\"\n        html = widget.render(name=\"password\", value=value, attrs={})\n        self.assertIn(_(\"No password set.\"), html)\n"], "sample_442": ["    def test_dumps_loads(self):\n        serializer = signing.JSONSerializer()\n        tests = [\n            [\"a\", \"list\"],\n            \"a string \\u2019\",\n            {\"a\": \"dictionary\"},\n        ]\n        for obj in tests:\n            with self.subTest(obj=obj):\n                dumped = serializer.dumps(obj)\n                self.assertIsInstance(dumped, bytes)\n                self.assertNotEqual(obj, dumped)\n                loaded = serializer.loads(dumped)\n                self.assertEqual(obj, loaded)\n"], "sample_443": ["    def test_path_traversal(self):\n        cache = caches[\"default\"]\n        key = \"../test_key\"\n        value = \"test_value\"\n\n        # Attempt to set a cache key that could potentially write outside the cache directory.\n        with self.assertRaises(ValueError):\n            cache.set(key, value)\n\n        # Attempt to get a cache key that could potentially read outside the cache directory.\n        self.assertIsNone(cache.get(key))\n\n        # Attempt to delete a cache key that could potentially delete outside the cache directory.\n        with self.assertRaises(ValueError):\n            cache.delete(key)\n"], "sample_444": ["    def setUp(self):\n        super().setUp()\n        self._temp_dir = temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, \"test\"))\n        self.addCleanup(shutil.rmtree, temp_dir)\n"], "sample_445": ["def test_timeuntil(self):\n    \"\"\"Test timeuntil function.\"\"\"\n    t = datetime.datetime(2007, 8, 14, 13, 46, 0)\n    tests = [\n        (t + self.onemicrosecond, \"0\\xa0minutes\"),\n        (t + self.onesecond, \"0\\xa0minutes\"),\n        (t + self.oneminute, \"1\\xa0minute\"),\n        (t + self.onehour, \"1\\xa0hour\"),\n        (t + self.oneday, \"1\\xa0day\"),\n        (t + self.oneweek, \"1\\xa0week\"),\n        (t + self.onemonth, \"1\\xa0month\"),\n        (t + self.oneyear, \"1\\xa0year\"),\n    ]\n    for value, expected in tests:\n        with self.subTest():\n            self.assertEqual(timeuntil(t, value), expected)\n"], "sample_448": ["def test_validate_expression_with_exclude(self):\n    constraint = models.UniqueConstraint(Lower(\"name\"), name=\"name_lower_uniq\")\n    existing_product = UniqueConstraintProduct.objects.create(name=\"test\")\n    new_product = UniqueConstraintProduct(name=\"TEST\")\n    with self.assertRaises(ValidationError):\n        constraint.validate(UniqueConstraintProduct, new_product)\n    constraint.validate(\n        UniqueConstraintProduct,\n        new_product,\n        exclude={\"name\"},\n    )\n    constraint.validate(\n        UniqueConstraintProduct,\n        existing_product,\n    )\n"], "sample_449": ["def test_connection_close_header(self):\n        \"\"\"A WSGI app that returns a hello world.\"\"\"\n        start_response(\"200 OK\", [])\n        return [b\"<!DOCTYPE html><html><body>Hello World</body></html>\"]\n\n    rfile = BytesIO(b\"GET / HTTP/1.0\\r\\n\")\n    rfile.seek(0)\n\n    wfile = UnclosableBytesIO()\n\n        if mode == \"rb\":\n            return rfile\n        elif mode == \"wb\":\n            return wfile\n\n    request = Stub(makefile=makefile)\n    server = Stub(base_environ={}, get_app=lambda: test_app)\n\n    # Prevent logging from appearing in test output.\n    with self.assertLogs(\"django.server\", \"INFO\"):\n        # Instantiating a handler runs the request as side effect.\n        WSGIRequestHandler(request, \"192.168.0.2\", server)\n\n    wfile.seek(0)\n    lines = list(wfile.readlines())\n    # The Connection: close header is not sent by default.\n    self.assertNotIn(b\"Connection: close\\r\\n\", lines)\n\n    # Now test with a WSGI app that doesn't set Content-Length.\n        \"\"\"A WSGI app that returns a hello world without setting Content-Length.\"\"\"\n        start_response(\"200 OK\", [(\"Content-Type\", \"text/html\")])\n        return [b\"<!DOCTYPE html><html><body>Hello World</body></html>\"]\n\n    rfile = BytesIO(b\"GET / HTTP/1.0\\r\\n\")\n    rfile.seek(0)\n    wfile = UnclosableBytesIO()\n\n    with self.assertLogs(\"django.server\", \"INFO\"):\n        WSGIRequestHandler(request, \"192.168.0.2\", server)\n\n    wfile.seek(0)\n    lines = list(wfile.readlines())\n    # The Connection: close header is sent when the Content-Length isn't set.\n    self.assertIn(b\"Connection: close\\r\\n\", lines)\n"], "sample_450": ["def test_get_admin_log_template_tag(self):\n    \"\"\"\n    The get_admin_log template tag returns a list of LogEntry objects for the\n    given user and content type.\n    \"\"\"\n    user_id = self.user.pk\n    content_type_pk = ContentType.objects.get_for_model(Article).pk\n    log_entries = LogEntry.objects.filter(\n        user__pk=user_id, content_type__pk=content_type_pk\n    )\n    context = {\"log_entries\": log_entries}\n    template = Template(\"{% load admin_utils %}{% get_admin_log 10 as admin_log for_user user %}{{ admin_log }}\")\n    rendered = template.render(Context({\"user\": self.user}))\n    self.assertEqual(rendered, str(list(log_entries[:10])))\n"], "sample_453": ["def test_cell_count(self):\n    \"\"\"\n    cell_count template filter should return the correct number of cells.\n    \"\"\"\n    admin = UserAdmin(User, site)\n    inline_admin_form = admin.get_inline_formsets(\n        self.request_factory.get(\"/\"), self.superuser\n    )[0](instance=self.superuser).forms[0]\n    self.assertEqual(cell_count(inline_admin_form), 3)\n\n    # Add a field to the inline form\n    inline_admin_form.fields[\"new_field\"] = \"New Field\"\n    self.assertEqual(cell_count(inline_admin_form), 4)\n\n    # Make one of the fields hidden\n    inline_admin_form.fields[\"new_field\"].is_hidden = True\n    self.assertEqual(cell_count(inline_admin_form), 3)\n"], "sample_456": ["def test_formset_with_disabled_fields(self):\n    \"\"\"Formsets with disabled fields.\"\"\"\n    class DisabledForm(Form):\n        field = IntegerField(disabled=True)\n\n    DisabledFormSet = formset_factory(DisabledForm)\n    data = {\n        \"form-TOTAL_FORMS\": \"1\",\n        \"form-INITIAL_FORMS\": \"0\",\n        \"form-MIN_NUM_FORMS\": \"0\",\n        \"form-MAX_NUM_FORMS\": \"0\",\n        \"form-0-field\": \"123\",\n    }\n    formset = DisabledFormSet(data, prefix=\"form\")\n    self.assertTrue(formset.is_valid())\n    self.assertEqual([form.cleaned_data for form in formset.forms], [{\"field\": 123}])\n"], "sample_464": ["def test_file_response_with_async_iterator(self):\n    async def async_iterator():\n        yield b\"binary\"\n        yield b\"content\"\n\n    response = FileResponse(async_iterator())\n    self.assertEqual(list(response), [b\"binary\", b\"content\"])\n"], "sample_466": ["def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return \"complex(%r)\" % self.value, {}\n\n    MigrationWriter.register_serializer(complex, ComplexSerializer)\n    MigrationWriter.unregister_serializer(complex)\n\n    with self.assertRaisesMessage(\n        ValueError, \"No serializer found for type complex\"\n    ):\n        MigrationWriter.serialize(complex(1 + 2j))\n"], "sample_470": ["def test_classproperty_getter_override(self):\n    class Parent:\n        @classproperty\n            return \"Parent\"\n\n    class Child(Parent):\n        @Parent.foo.getter\n            return \"Child\"\n\n    self.assertEqual(Parent.foo, \"Parent\")\n    self.assertEqual(Child.foo, \"Child\")\n"], "sample_472": ["def test_paginating_queryset_with_order_by(self):\n    msg = (\n        \"Pagination may yield inconsistent results with an unordered \"\n        \"object_list: <class 'pagination.models.Article'> QuerySet.\"\n    )\n    with self.notWarnsMessage(UnorderedObjectListWarning, msg) as cm:\n        Paginator(Article.objects.order_by(\"id\"), 5)\n    # No warning is raised when the queryset is ordered.\n    self.assertEqual(len(cm), 0)\n"], "sample_473": ["compilation error"], "sample_474": ["    def setUpTestData(cls):\n        cls.author = Author.objects.create(name=\"John Smith\", alias=\"smithj\")\n"], "sample_476": ["    def test_close_called(self):\n        \"\"\"\n        Test that close() is called on the underlying File object when the\n        FieldFile is garbage collected.\n        \"\"\"\n        class TestFile(File):\n            closed = False\n\n                self.closed = True\n\n        file = TestFile(None, name=\"test.txt\")\n        fieldfile = ImageFieldFile(None, ImageField(), file)\n        del fieldfile\n        self.assertTrue(file.closed)\n"], "sample_477": ["def test_add01(self):\n    output = self.engine.render_to_string(\"add01\", {\"a\": 10})\n    self.assertEqual(output, \"15\")\n"], "sample_478": ["    def test_not_callable_or_boolean(self):\n        class TestModelAdmin(ModelAdmin):\n            view_on_site = \"hello\"\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'view_on_site' must be a callable or a boolean value.\",\n            \"admin.E025\",\n        )\n"], "sample_484": ["    def setUpTestData(cls):\n        Author.objects.create(name=\"John Smith\", alias=\"smithj\")\n        Author.objects.create(name=\"Rhonda\")\n"], "sample_485": ["def test_urlize_with_trailing_punctuation(self):\n    tests = (\n        (\n            \"Search for google.com.\",\n            'Search for <a href=\"http://google.com/\">google.com</a>.',\n        ),\n        (\n            \"Search for google.com!?\",\n            'Search for <a href=\"http://google.com/\">google.com</a>!?',\n        ),\n        (\n            \"Search for google.com, and see.\",\n            'Search for <a href=\"http://google.com/\">google.com</a>, and see.',\n        ),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value), output)\n"], "sample_488": ["def test_set_available_apps(self):\n    \"\"\"\n    Tests apps.set_available_apps() and apps.unset_available_apps().\n    \"\"\"\n    original_app_configs = apps.app_configs.copy()\n    available = [\"django.contrib.admin\", \"django.contrib.auth\"]\n    apps.set_available_apps(available)\n    self.assertEqual(len(apps.app_configs), 2)\n    for app_name in available:\n        self.assertIn(app_name, [ac.name for ac in apps.app_configs.values()])\n    apps.unset_available_apps()\n    self.assertEqual(apps.app_configs, original_app_configs)\n"], "sample_492": ["def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return \"complex(%r)\" % self.value, {}\n\n    MigrationWriter.register_serializer(complex, ComplexSerializer)\n    MigrationWriter.unregister_serializer(complex)\n\n    with self.assertRaisesMessage(\n        ValueError, \"Cannot serialize: complex(1+1j) (type complex)\"\n    ):\n        MigrationWriter.serialize(1 + 1j)\n"], "sample_495": ["def test_page_repr(self):\n    paginator = Paginator([1, 2, 3], 2)\n    page = paginator.page(1)\n    self.assertEqual(repr(page), '<Page 1 of 2>')\n"], "sample_496": ["    def setUp(self):\n        self.write_settings('settings.py')\n"], "sample_499": ["def test_legend_bbox_to_anchor_transform():\n    # Test that the bbox_to_anchor argument can be specified with a transform.\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='line')\n    leg = ax.legend(bbox_to_anchor=(0.5, 0.5), loc='center',\n                    bbox_transform=ax.transAxes)\n    assert leg.get_bbox_to_anchor().x0 == 0.5\n    assert leg.get_bbox_to_anchor().y0 == 0.5\n    assert leg.get_bbox_to_anchor().transform == ax.transAxes\n"], "sample_500": ["def test_colorbar_alpha():\n    # Test that colorbar transparency is correctly set.\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.arange(100).reshape(10, 10), alpha=0.5)\n    cb = fig.colorbar(pc)\n    assert cb.alpha == 0.5\n\n    # Test that colorbar transparency is correctly updated when mappable's\n    # alpha changes.\n    pc.set_alpha(0.8)\n    cb.update_normal(pc)\n    assert cb.alpha == 0.8\n\n    # Test that colorbar transparency is correctly set when mappable has an\n    # array-like alpha.\n    pc = ax.pcolormesh(np.arange(100).reshape(10, 10), alpha=np.linspace(0, 1, 100))\n    cb = fig.colorbar(pc)\n    assert cb.alpha is None\n"], "sample_504": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.arange(100).reshape(10, 10))\n    cb = fig.colorbar(pc)\n    assert cb.alpha is None\n\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n\n    cb.set_alpha([0.1, 0.2, 0.3])\n    assert cb.alpha is None\n"], "sample_507": ["    def test_convert_empty_list(self):\n        cc = cat.StrCategoryConverter()\n        unit = cat.UnitData()\n        ax = FakeAxis(unit)\n        assert cc.convert([], unit, ax) == []\n"], "sample_508": ["def test_artist_inspector_get_setters():\n    # test the correct format and type of get_setters method\n    ai = martist.ArtistInspector(mlines.Line2D)\n    setters = ai.get_setters()\n    assert isinstance(setters, list)\n    assert all(isinstance(s, str) for s in setters)\n    assert \"linewidth\" in setters\n"], "sample_509": ["def test_date2num_out_of_range():\n    with pytest.raises(ValueError, match=\"Matplotlib dates must be between\"):\n        mdates.date2num(np.datetime64('0000-01-01'))\n    with pytest.raises(ValueError, match=\"Matplotlib dates must be between\"):\n        mdates.date2num(np.datetime64('10000-01-01'))\n"], "sample_513": ["def test_legend_set_bbox_to_anchor():\n    # Test that setting bbox_to_anchor updates the legend's position.\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='line')\n    leg = ax.legend()\n\n    # Set bbox_to_anchor to a new value.\n    leg.set_bbox_to_anchor((0.5, 0.5))\n\n    # Check that the legend's position has been updated.\n    assert leg.get_bbox_to_anchor().x0 == 0.5\n    assert leg.get_bbox_to_anchor().y0 == 0.5\n"], "sample_514": ["def test_colorbar_alpha():\n    fig, ax = plt.subplots()\n    data = np.random.rand(10, 10)\n    cmap = plt.get_cmap('viridis')\n    cmap.set_alpha(0.5)\n    im = ax.imshow(data, cmap=cmap)\n    cb = fig.colorbar(im)\n    assert cb.alpha is None\n    cb.remove()\n\n    cmap = plt.get_cmap('viridis')\n    im = ax.imshow(data, cmap=cmap, alpha=0.5)\n    cb = fig.colorbar(im)\n    assert cb.alpha == 0.5\n    cb.remove()\n\n    cmap = plt.get_cmap('viridis')\n    im = ax.imshow(data, cmap=cmap)\n    im.set_alpha(0.5)\n    cb = fig.colorbar(im)\n    assert cb.alpha == 0.5\n    cb.remove()\n\n    cmap = plt.get_cmap('viridis')\n    im = ax.imshow(data, cmap=cmap)\n    cb = fig.colorbar(im)\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n"], "sample_515": ["def test_colorbar_with_no_norm():\n    fig, ax = plt.subplots()\n    cmap = mpl.colormaps[\"viridis\"]\n    mappable = cm.ScalarMappable(cmap=cmap)\n    with pytest.raises(TypeError):\n        Colorbar(ax, mappable)\n"], "sample_520": ["def test_line3d_modification(fig_test, fig_ref):\n    # Modifying the Line3D position after the fact should work the same as\n    # setting it directly.\n    x, y, z = [0, 1], [2, 3], [4, 5]\n    x2, y2, z2 = [6, 7], [8, 9], [10, 11]\n\n    ax_test = fig_test.add_subplot(projection='3d')\n    l = ax_test.plot(x, y, z)[0]\n    l.set_data_3d(x2, y2, z2)\n\n    ax_ref = fig_ref.add_subplot(projection='3d')\n    ax_ref.plot(x2, y2, z2)\n"], "sample_522": ["def test_colorbar_with_no_mappable():\n    fig, ax = plt.subplots()\n    with pytest.raises(ValueError):\n        fig.colorbar(None)\n"], "sample_523": ["def test_legend_set_title():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='line')\n    leg = ax.legend()\n    leg.set_title('Test Title')\n    assert leg.get_title().get_text() == 'Test Title'\n    assert leg.get_title().get_visible()\n"], "sample_524": ["def test_colorbar_with_no_ticks():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc)\n    cb.set_ticks([])\n    assert len(cb.ax.yaxis.get_ticklocs()) == 0\n    assert len(cb.ax.yaxis.get_ticklabels()) == 0\n"], "sample_525": ["def test_subfigure_repr():\n    fig = plt.figure()\n    sub_fig = fig.subfigures(1, 1)\n    assert repr(sub_fig[0]) == \"<SubFigure size 640x480 with 0 Axes>\"\n"], "sample_526": ["def test_date2num_roundtrip():\n    dates = [datetime.datetime(2022, 1, 1), datetime.datetime(2022, 12, 31)]\n    nums = mdates.date2num(dates)\n    roundtripped_dates = mdates.num2date(nums)\n    assert dates == roundtripped_dates\n"], "sample_527": ["def test_figure_add_subplot():\n    fig = Figure()\n    ax1 = fig.add_subplot(221)\n    ax2 = fig.add_subplot(222)\n    ax3 = fig.add_subplot(223)\n    ax4 = fig.add_subplot(224)\n\n    assert len(fig.axes) == 4\n    assert ax1 in fig.axes\n    assert ax2 in fig.axes\n    assert ax3 in fig.axes\n    assert ax4 in fig.axes\n\n    # Test adding a subplot with a projection\n    ax5 = fig.add_subplot(111, projection='polar')\n    assert len(fig.axes) == 5\n    assert ax5 in fig.axes\n\n    # Test adding a subplot with a custom axes class\n    from matplotlib.axes import Axes\n    class CustomAxes(Axes):\n        pass\n    ax6 = fig.add_subplot(111, axes_class=CustomAxes)\n    assert len(fig.axes) == 6\n    assert ax6 in fig.axes\n    assert isinstance(ax6, CustomAxes)\n"], "sample_528": ["def test_reload_library():\n    original_library = style.library.copy()\n    with temp_style('test', DUMMY_SETTINGS):\n        assert 'test' in style.library\n    style.reload_library()\n    assert style.library == original_library\n"], "sample_529": ["def test_legend_handles_labels_with_empty_string():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='')\n    handles, labels = ax.get_legend_handles_labels()\n    assert len(handles) == 0\n    assert len(labels) == 0\n"], "sample_530": ["def test_offsetbox_repr():\n    ob = OffsetBox()\n    assert repr(ob) == \"OffsetBox()\"\n"], "sample_533": ["def test_contour_label_rotated():\n    # Test contour labels are correctly rotated when the axes aspect is not equal.\n    fig, ax = plt.subplots(figsize=(6, 3))\n    x, y = np.meshgrid(np.arange(0, 10), np.arange(0, 10))\n    z = np.max(np.dstack([abs(x), abs(y)]), 2)\n    cs = ax.contour(x, y, z)\n    ax.clabel(cs)\n    ax.set_aspect('auto')\n"], "sample_534": ["def test_contour_label_rotation():\n    fig, ax = plt.subplots()\n    x, y = np.meshgrid(np.arange(0, 10), np.arange(0, 10))\n    z = np.max(np.dstack([abs(x), abs(y)]), 2)\n    cs = ax.contour(x, y, z)\n    for label in cs.labelTexts:\n        assert label.get_rotation() == 0\n    cs = ax.contour(x, y, z, rightside_up=False)\n    for label in cs.labelTexts:\n        assert label.get_rotation() != 0\n"], "sample_535": ["def test_table_edges():\n    fig, ax = plt.subplots()\n    table = Table(ax)\n\n    # Test setting edges on the table\n    table.edges = 'horizontal'\n    assert table.edges == 'horizontal'\n\n    # Test setting edges on a cell\n    cell = table.add_cell(1, 2, 1, 1)\n    cell.visible_edges = 'vertical'\n    assert cell.visible_edges == 'vertical'\n\n    # Test that setting edges on the table doesn't change the cell's edges\n    table.edges = 'closed'\n    assert cell.visible_edges == 'vertical'\n"], "sample_537": ["def test_psd_twosided_norm():\n    u = np.array([0, 1, 2, 3, 1, 2, 1])\n    dt = 1.0\n    Su = np.abs(np.fft.fft(u) * dt)**2 / (dt * u.size)\n    P, f = mlab.psd(u, NFFT=u.size, Fs=1/dt, window=mlab.window_none,\n                    detrend=mlab.detrend_none, noverlap=0, pad_to=None,\n                    scale_by_freq=None,\n                    sides='twosided')\n    assert_allclose(P, Su, atol=1e-06)\n"], "sample_538": ["def test_affinedelta():\n    points = np.array([[1, 2], [3, 4]])\n    t = mtransforms.Affine2D().translate(10, 20).scale(2, 3)\n    dt = mtransforms.AffineDeltaTransform(t)\n\n    # Check that the translation part is removed.\n    assert_array_equal(dt.transform(points), t.scale(2, 3).transform(points))\n"], "sample_540": ["def test_adjusted_figsize():\n    w, h = 10, 5\n    dpi = 100\n    n = 2\n\n    adjusted_w, adjusted_h = animation.adjusted_figsize(w, h, dpi, n)\n\n    assert adjusted_w == int(w * dpi / n) * n / dpi\n    assert adjusted_h == int(h * dpi / n) * n / dpi\n"], "sample_544": ["def test_image_alpha(fig_test, fig_ref):\n    \"\"\"Test that image alpha is correctly applied.\"\"\"\n    ax_test = fig_test.subplots()\n    ax_ref = fig_ref.subplots()\n\n    # Create a semi-transparent image\n    img = np.zeros((10, 10, 4))\n    img[:, :, :3] = 1  # White\n    img[:, :, 3] = 0.5  # 50% transparent\n\n    ax_test.imshow(img)\n    ax_test.set_facecolor(\"red\")  # Background color to test alpha\n\n    # Reference image with manually applied alpha\n    ax_ref.imshow(img[:, :, :3] * img[:, :, 3:] + (1 - img[:, :, 3:]) * np.array([1, 0, 0, 1]))\n    ax_ref.set_facecolor(\"white\")\n"], "sample_547": ["def test_auxtransformbox():\n    fig, ax = plt.subplots()\n    aux_transform = mtransforms.Affine2D().translate(10, 20)\n    atb = AuxTransformBox(aux_transform)\n    text = TextArea(\"Hello\")\n    atb.add_artist(text)\n    ax.add_artist(atb)\n    fig.canvas.draw()\n    assert not fig.stale\n    assert_allclose(text.get_offset(), (10, 20))\n"], "sample_548": ["def test_colorbar_with_no_ticks():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    cb = fig.colorbar(im)\n    cb.set_ticks([])\n    assert len(cb.ax.yaxis.get_ticklocs()) == 0\n"], "sample_555": ["def test_fancyarrowpatch_contains():\n    fig, ax = plt.subplots()\n    arrow = FancyArrowPatch((0.1, 0.1), (0.8, 0.8))\n    ax.add_patch(arrow)\n    assert arrow.contains_point((0.5, 0.5))[0]\n    assert not arrow.contains_point((0.9, 0.9))[0]\n"], "sample_558": ["def test_grid_set_axes_locator():\n    fig = plt.figure()\n    grid = Grid(fig, 111, (2, 3))\n    locator = grid.get_axes_locator()\n    grid.set_axes_locator(locator)\n    assert grid.get_axes_locator() == locator\n"], "sample_560": ["def test_legend_handles_labels_from_containers():\n    fig, ax = plt.subplots()\n    ax.bar(range(5), range(5), label='bar')\n    ax.errorbar(range(5), range(5), yerr=1, label='errorbar')\n    ax.fill_between(range(5), range(5), label='fill_between')\n\n    handles, labels = ax.get_legend_handles_labels()\n    assert len(handles) == 3\n    assert len(labels) == 3\n\n    assert isinstance(handles[0], mpatches.Rectangle)\n    assert isinstance(handles[1], mlines.Line2D)\n    assert isinstance(handles[2], mpatches.Polygon)\n\n    assert labels == ['bar', 'errorbar', 'fill_between']\n"], "sample_561": ["def test_marker_get_path():\n    marker = markers.MarkerStyle(\"o\")\n    path = marker.get_path()\n    assert isinstance(path, Path)\n    assert len(path.vertices) > 0\n\n    marker = markers.MarkerStyle(\"\")\n    path = marker.get_path()\n    assert isinstance(path, Path)\n    assert len(path.vertices) == 0\n"], "sample_563": ["def test_offsetbox_set_figure():\n    fig, ax = plt.subplots()\n    box = OffsetBox()\n    box.set_figure(fig)\n    assert box.figure is fig\n    for child in box.get_children():\n        assert child.figure is fig\n"], "sample_565": ["def test_inset_locator_bbox_transform():\n    fig, ax = plt.subplots()\n    inset_axes(ax, width=\"30%\", height=\"40%\",\n               bbox_to_anchor=(0.4, 0.5), bbox_transform=ax.transAxes)\n    fig.canvas.draw()\n"], "sample_567": ["def test_update_from():\n    txt1 = Text(.5, .5, \"foo\\nbar\", antialiased=True)\n    txt2 = Text(.5, .5, \"baz\")\n\n    txt2.update_from(txt1)\n\n    assert txt2._antialiased == txt1._antialiased\n    assert txt2.get_antialiased() == txt1.get_antialiased()\n"], "sample_570": ["def test_validate_errorbar_arg():\n    # Test that _validate_errorbar_arg correctly handles different inputs\n\n    # Test None input\n    method, level = _validate_errorbar_arg(None)\n    assert method is None\n    assert level is None\n\n    # Test string input\n    method, level = _validate_errorbar_arg(\"ci\")\n    assert method == \"ci\"\n    assert level == 95\n\n    # Test tuple input\n    method, level = _validate_errorbar_arg((\"pi\", 50))\n    assert method == \"pi\"\n    assert level == 50\n\n    # Test callable input\n        return (x.min(), x.max())\n    method, level = _validate_errorbar_arg(custom_func)\n    assert method is custom_func\n    assert level is None\n\n    # Test invalid input\n    with pytest.raises(TypeError):\n        _validate_errorbar_arg(123)\n\n    # Test invalid method\n    with pytest.raises(ValueError):\n        _validate_errorbar_arg(\"invalid_method\")\n\n    # Test invalid level\n    with pytest.raises(TypeError):\n        _validate_errorbar_arg((\"ci\", \"invalid_level\"))\n"], "sample_572": ["    def test_string_input(self):\n        method, level = _validate_errorbar_arg(\"ci\")\n        assert method == \"ci\"\n        assert level == 95\n"], "sample_573": ["def test_insufficient_unique_x(self, df):\n\n    groupby = GroupBy([\"group\"])\n    df[\"x\"] = np.repeat(1, len(df))\n    res = PolyFit(order=2)(df, groupby, \"x\", {})\n\n    assert_frame_equal(res, pd.DataFrame(columns=[\"x\", \"y\"], index=pd.RangeIndex(0)))\n"], "sample_578": ["def test_baseline(self, x, y):\n\n    baseline = 5\n    p = Plot(x, y).add(Bars(baseline=baseline)).plot()\n    ax = p._figure.axes[0]\n    paths = ax.collections[0].get_paths()\n    for i, path in enumerate(paths):\n        verts = path.vertices\n        assert verts[0, 1] == baseline\n        assert verts[3, 1] == y[i] + baseline\n"], "sample_579": ["def test_clustermap_cbar_kws(self):\n    kws = self.default_kws.copy()\n    cbar_kws = dict(shrink=0.5, aspect=10)\n    g = mat.clustermap(self.df_norm, cbar_kws=cbar_kws)\n    assert g.ax_cbar.get_position().height < 0.1\n    assert g.ax_cbar.get_position().width > 0.05\n"], "sample_580": ["def test_categorical_order():\n\n    s = pd.Series([\"a\", \"c\", \"b\"])\n    order = categorical_order(s)\n    assert order == [\"a\", \"b\", \"c\"]\n\n    s = pd.Series([1, 3, 2])\n    order = categorical_order(s)\n    assert order == [1, 2, 3]\n\n    s = pd.Series([1., 3., 2.])\n    order = categorical_order(s)\n    assert order == [1., 2., 3.]\n\n    s = pd.Series([\"a\", \"c\", \"b\"], dtype=\"category\")\n    s = s.cat.reorder_categories([\"c\", \"b\", \"a\"])\n    order = categorical_order(s)\n    assert order == [\"c\", \"b\", \"a\"]\n\n    s = pd.Series([1, np.nan, 2])\n    order = categorical_order(s)\n    assert order == [1, 2]\n\n    s = pd.Series([1, 2, 3])\n    custom_order = [3, 2, 1]\n    order = categorical_order(s, order=custom_order)\n    assert order == custom_order\n"], "sample_582": ["def test_cli_blueprints_register(app, runner):\n    \"\"\"Test blueprint commands register correctly to the application\"\"\"\n    custom = Blueprint(\"custom\", __name__, cli_group=\"customized\")\n    nested = Blueprint(\"nested\", __name__)\n    merged = Blueprint(\"merged\", __name__, cli_group=None)\n    late = Blueprint(\"late\", __name__)\n\n    @custom.cli.command(\"custom\")\n        click.echo(\"custom_result\")\n\n    @nested.cli.command(\"nested\")\n        click.echo(\"nested_result\")\n\n    @merged.cli.command(\"merged\")\n        click.echo(\"merged_result\")\n\n    @late.cli.command(\"late\")\n        click.echo(\"late_result\")\n\n    app.register_blueprint(custom)\n    app.register_blueprint(nested)\n    app.register_blueprint(merged)\n    app.register_blueprint(late)\n\n    cli = FlaskGroup(create_app=lambda: app)\n\n    result = runner.invoke(cli, [\"custom\", \"custom\"])\n    assert result.exit_code == 0\n    assert result.output.strip() == \"custom_result\"\n\n    result = runner.invoke(cli, [\"nested\", \"nested\"])\n    assert result.exit_code == 0\n    assert result.output.strip() == \"nested_result\"\n\n    result = runner.invoke(cli, [\"merged\", \"merged\"])\n    assert result.exit_code == 0\n    assert result.output.strip() == \"merged_result\"\n\n    result = runner.invoke(cli, [\"late\", \"late\"])\n    assert result.exit_code == 0\n    assert result.output.strip() == \"late_result\"\n"], "sample_584": ["    def test_concat_once_with_none(self, create_combined_ids):\n        shape = (2,)\n        combined_ids = create_combined_ids(shape)\n        ds = create_test_data\n        result = _combine_all_along_first_dim(combined_ids, dim=None,\n                                              data_vars='all',\n                                              coords='different',\n                                              compat='no_conflicts')\n\n        expected_ds = merge([ds(0), ds(1)], compat='no_conflicts')\n        assert_combined_tile_ids_equal(result, {(): expected_ds})\n"], "sample_585": ["def test_groupby_fillna():\n    # create test data\n    times = pd.date_range('2000-01-01', periods=4)\n    foo = xr.DataArray([1, 2, np.nan, 4], coords=dict(time=times), dims='time')\n    # create test index\n    dd = times.to_pydatetime()\n    reference_dates = [dd[0], dd[2]]\n    labels = reference_dates[0:1] * 2 + reference_dates[1:2] * 2\n    ind = xr.DataArray(labels, coords=dict(time=times), dims='time',\n                       name='reference_date')\n    g = foo.groupby(ind)\n    actual = g.fillna(0)\n    expected = xr.DataArray([1, 2, 0, 4], coords=dict(time=times), dims='time')\n    assert actual.equals(expected)\n"], "sample_586": ["def test_concat_positions(self):\n    # Test that the positions argument works as expected\n    foo = DataArray([1, 2], coords=[(\"x\", [1, 2])])\n    bar = DataArray([3, 4], coords=[(\"x\", [3, 4])])\n\n    # Specify positions manually\n    actual = concat((foo, bar), dim=\"x\", positions=[[0, 1], [2, 3]])\n    expected = DataArray([1, 2, 3, 4], dims=[\"x\"], coords={\"x\": [1, 2, 3, 4]})\n    assert_identical(actual, expected)\n\n    # Use default positions (None)\n    actual = concat((foo, bar), dim=\"x\")\n    expected = DataArray([1, 2, 3, 4], dims=[\"x\"], coords={\"x\": [1, 2, 3, 4]})\n    assert_identical(actual, expected)\n\n    # Invalid positions should raise an error\n    with raises_regex(ValueError, \"positions must be a list of integer arrays\"):\n        concat((foo, bar), dim=\"x\", positions=[0, 1])\n\n    with raises_regex(ValueError, \"Length of positions does not match length of datasets\"):\n        concat((foo, bar), dim=\"x\", positions=[[0, 1]])\n"], "sample_588": ["def test_combine_nested_empty_input_with_concat_dim(self):\n    assert_identical(Dataset(), combine_nested([], concat_dim=\"x\"))\n    assert_identical(Dataset(), combine_nested([], concat_dim=[\"x\", \"y\"]))\n"], "sample_589": ["def test_interpolate_na_max_gap_float(da):\n    da[\"x\"] = np.arange(len(da))\n    expected = da.copy(data=[0, 1, 2, 3, np.nan, 5, 6, 7])\n    actual = da.interpolate_na(\"x\", max_gap=2.0)\n    assert_equal(actual, expected)\n"], "sample_590": ["def test_concat_positions(self):\n    # Test that the positions argument works as expected\n    foo = DataArray([1, 2], coords=[(\"x\", [1, 2])])\n    bar = DataArray([3, 4], coords=[(\"x\", [3, 4])])\n\n    # Test with integer positions\n    actual = concat((foo, bar), dim=\"x\", positions=[0, 1])\n    expected = DataArray([1, 2, 3, 4], dims=[\"x\"], coords={\"x\": [1, 2, 3, 4]})\n    assert_identical(actual, expected)\n\n    # Test with array-like positions\n    actual = concat((foo, bar), dim=\"x\", positions=np.array([0, 1]))\n    assert_identical(actual, expected)\n\n    # Test with list of integer arrays\n    actual = concat((foo, bar), dim=\"x\", positions=[[0], [1]])\n    assert_identical(actual, expected)\n\n    # Test with invalid positions\n    with raises_regex(ValueError, \"positions must be\"):\n        concat((foo, bar), dim=\"x\", positions=\"invalid\")\n\n    # Test with positions that are not the same length as the datasets\n    with raises_regex(ValueError, \"positions must be\"):\n        concat((foo, bar), dim=\"x\", positions=[0, 1, 2])\n"], "sample_592": ["def test_short_data_repr():\n    array = xr.DataArray(np.random.randn(500))\n    assert len(formatting.short_data_repr(array)) < 200\n\n    array = xr.DataArray(np.random.randn(20, 20))\n    assert len(formatting.short_data_repr(array)) < 200\n\n    array = xr.DataArray(np.random.randn(5, 10, 15))\n    assert len(formatting.short_data_repr(array)) < 200\n\n    array = xr.DataArray(np.random.randn(5, 10, 15, 3))\n    assert len(formatting.short_data_repr(array)) < 200\n\n    array = xr.DataArray(np.random.randn(100, 5, 1))\n    assert len(formatting.short_data_repr(array)) < 200\n"], "sample_593": ["def test_collapsible_section():\n    name = \"Test Section\"\n    inline_details = \"Inline details\"\n    details = \"Detailed information\"\n    n_items = 5\n    enabled = True\n    collapsed = False\n\n    section = fh.collapsible_section(\n        name, inline_details, details, n_items, enabled, collapsed\n    )\n\n    assert f\"<input id='section-\" in section\n    assert f\"<label for='section-\" in section\n    assert name in section\n    assert inline_details in section\n    assert details in section\n    assert str(n_items) in section\n    assert \"disabled\" not in section\n    assert \"checked\" not in section\n"], "sample_594": ["def test_limit_lines():\n    string = \"\\n\".join(str(i) for i in range(100))\n    expected = \"\\n\".join(\n        [\"0\", \"1\", \"2\", \"...\", \"97\", \"98\", \"99\"]\n    )\n    actual = formatting.limit_lines(string, limit=7)\n    assert actual == expected\n\n    string = \"\\n\".join(str(i) for i in range(5))\n    expected = string\n    actual = formatting.limit_lines(string, limit=10)\n    assert actual == expected\n"], "sample_596": ["def test_concat_dim_order():\n    # Test that the order of dimensions is preserved when concatenating\n    ds1 = Dataset({\"a\": ((\"x\", \"y\"), [[1, 2]])}, coords={\"x\": [0], \"y\": [0]})\n    ds2 = Dataset({\"a\": ((\"x\", \"y\"), [[3, 4]])}, coords={\"x\": [1], \"y\": [0]})\n\n    actual = concat([ds1, ds2], dim=\"x\")\n    expected = Dataset(\n        {\"a\": ((\"x\", \"y\"), [[1, 2], [3, 4]])}, coords={\"x\": [0, 1], \"y\": [0]}\n    )\n    assert_identical(actual, expected)\n\n    actual = concat([ds1, ds2], dim=\"y\")\n    expected = Dataset(\n        {\"a\": ((\"x\", \"y\"), [[1, 3], [2, 4]])}, coords={\"x\": [0], \"y\": [0, 1]}\n    )\n    assert_identical(actual, expected)\n"], "sample_597": ["def test_merge_no_conflicts_multi_vars(self):\n    ds1 = xr.Dataset({\"a\": (\"x\", [1, 2]), \"b\": (\"x\", [3, 4]), \"x\": [0, 1]})\n    ds2 = xr.Dataset({\"a\": (\"x\", [2, 3]), \"c\": (\"x\", [5, 6]), \"x\": [1, 2]})\n    expected = xr.Dataset(\n        {\"a\": (\"x\", [1, 2, 3]), \"b\": (\"x\", [3, 4, np.nan]), \"c\": (\"x\", [np.nan, 5, 6])},\n        {\"x\": [0, 1, 2]},\n    )\n\n    assert expected.identical(ds1.merge(ds2, compat=\"no_conflicts\"))\n    assert expected.identical(ds2.merge(ds1, compat=\"no_conflicts\"))\n\n    assert ds1.identical(ds1.merge(ds2, compat=\"no_conflicts\", join=\"left\"))\n\n    assert ds2.identical(ds1.merge(ds2, compat=\"no_conflicts\", join=\"right\"))\n\n    expected2 = xr.Dataset(\n        {\"a\": (\"x\", [2]), \"b\": (\"x\", [4]), \"c\": (\"x\", [5])}, {\"x\": [1]}\n    )\n    assert expected2.identical(ds1.merge(ds2, compat=\"no_conflicts\", join=\"inner\"))\n"], "sample_598": ["def test_short_data_repr():\n    cases = [\n        xr.DataArray(np.random.randn(500)),\n        xr.DataArray(np.random.randn(20, 20)),\n        xr.DataArray(np.random.randn(5, 10, 15)),\n        xr.DataArray(np.random.randn(5, 10, 15, 3)),\n        xr.DataArray(np.random.randn(100, 5, 1)),\n    ]\n    for array in cases:\n        repr_str = formatting.short_data_repr(array)\n        assert len(repr_str.splitlines()) < 30\n"], "sample_599": ["def test_UnsignedIntegerCoder_decode():\n    original = xr.Variable((\"x\",), [-1, 0, 1], {\"_Unsigned\": \"true\"})\n    expected = xr.Variable((\"x\",), [255, 0, 1], dtype=np.uint8)\n    coder = variables.UnsignedIntegerCoder()\n    decoded = coder.decode(original)\n    assert_identical(expected, decoded)\n"], "sample_600": ["def test_UnsignedIntegerCoder_encode():\n    original = xr.Variable((\"x\",), np.array([1, 2, 3], dtype=\"uint8\"))\n    original.attrs[\"_Unsigned\"] = \"true\"\n    coder = variables.UnsignedIntegerCoder()\n    encoded = coder.encode(original)\n    assert encoded.dtype == np.int8\n    assert encoded.attrs[\"_Unsigned\"] is None\n    roundtripped = coder.decode(encoded)\n    assert_identical(original, roundtripped)\n"], "sample_601": ["def test_cftime_round_accessor(cftime_rounding_dataarray, cftime_date_type, use_dask):\n    import dask.array as da\n\n    freq = \"D\"\n    expected = xr.DataArray(\n        [\n            [cftime_date_type(1, 1, 1, 0), cftime_date_type(1, 1, 2, 0)],\n            [cftime_date_type(1, 1, 2, 0), cftime_date_type(1, 1, 2, 0)],\n        ],\n        name=\"round\",\n    )\n\n    if use_dask:\n        chunks = {\"dim_0\": 1}\n        # Currently a compute is done to inspect a single value of the array\n        # if it is of object dtype to check if it is a cftime.datetime (if not\n        # we raise an error when using the dt accessor).\n        with raise_if_dask_computes(max_computes=1):\n            result = cftime_rounding_dataarray.chunk(chunks).dt.round(freq)\n        expected = expected.chunk(chunks)\n        assert isinstance(result.data, da.Array)\n        assert result.chunks == expected.chunks\n    else:\n        result = cftime_rounding_dataarray.dt.round(freq)\n\n    assert_identical(result, expected)\n"], "sample_602": ["def test_open_dataset_invalid_engine():\n    with pytest.raises(ValueError):\n        xr.open_dataset(\"example.nc\", engine=\"invalid_engine\")\n"], "sample_603": ["def test_collapsible_section():\n    name = \"Test Section\"\n    inline_details = \"Inline details\"\n    details = \"Details\"\n    n_items = 5\n    enabled = True\n    collapsed = False\n\n    section = fh.collapsible_section(\n        name, inline_details, details, n_items, enabled, collapsed\n    )\n\n    assert f\"<input id='section-\" in section\n    assert f\"class='xr-section-summary-in' type='checkbox' {'checked' if not collapsed else ''}>\" in section\n    assert f\"<label for='section-\" in section\n    assert f\"class='xr-section-summary' title='Expand/collapse section'>{name}: <span>({n_items})</span></label>\" in section\n    assert f\"<div class='xr-section-inline-details'>{inline_details}</div>\" in section\n    assert f\"<div class='xr-section-details'>{details}</div>\" in section\n"], "sample_604": ["def test_short_data_repr():\n    array = np.random.randn(100, 5, 1)\n    data_array = xr.DataArray(array)\n\n    # Test with default options\n    result = formatting.short_data_repr(data_array)\n    assert len(result.splitlines()) < 50\n\n    # Test with display_expand_data=False\n    with xr.set_options(display_expand_data=False):\n        result = formatting.short_data_repr(data_array)\n        assert len(result.splitlines()) == 1\n\n    # Test with duck array\n    class DuckArray:\n            self.array = array\n\n            return repr(self.array)\n\n            return \"DuckArray\"\n\n    duck_array = DuckArray(array)\n    result = formatting.short_data_repr(duck_array)\n    assert result == \"DuckArray\"\n"], "sample_605": ["def test_groupby_bins_empty():\n    # Test groupby_bins with empty DataArray\n    da = xr.DataArray([], dims=\"x\")\n    bins = [0, 1, 2]\n    with pytest.raises(ValueError):\n        da.groupby_bins(\"x\", bins)\n"], "sample_607": ["def test_detect_parameters():\n    backend = DummyBackendEntrypoint1()\n    parameters = plugins.detect_parameters(backend.open_dataset)\n    assert parameters == (\"filename_or_obj\", \"decoder\")\n\n    backend = DummyBackendEntrypointKwargs()\n    with pytest.raises(TypeError):\n        plugins.detect_parameters(backend.open_dataset)\n\n    backend = DummyBackendEntrypointArgs()\n    with pytest.raises(TypeError):\n        plugins.detect_parameters(backend.open_dataset)\n"], "sample_608": ["def test__element_formatter() -> None:\n    elements = [\"dim1\", \"dim2\", \"dim3\"]\n    col_width = 10\n    max_rows = 2\n\n    actual = formatting._element_formatter(elements, col_width, max_rows)\n    expected = \"dim1,\\ndim2, ...\"\n    assert actual == expected\n\n    actual = formatting._element_formatter(elements, col_width)\n    expected = \"dim1, dim2, dim3\"\n    assert actual == expected\n\n    elements = [\"long_dimension_name1\", \"long_dimension_name2\", \"long_dimension_name3\"]\n    actual = formatting._element_formatter(elements, col_width, max_rows)\n    expected = \"long_dimension_name1,\\nlong_dimension_name2, ...\"\n    assert actual == expected\n"], "sample_609": ["def test_where_broadcasting() -> None:\n    cond = xr.DataArray([True, False], dims=\"x\")\n    x = xr.DataArray([[1, 2], [3, 4]], dims=(\"x\", \"y\"))\n    y = xr.DataArray([[5, 6], [7, 8]], dims=(\"x\", \"y\"))\n    actual = xr.where(cond, x, y)\n    expected = xr.DataArray([[1, 2], [7, 8]], dims=(\"x\", \"y\"))\n    assert_identical(expected, actual)\n"], "sample_610": ["def test_cftimeindex_repr_empty():\n    \"\"\"Test that an empty CFTimeIndex has a valid repr.\"\"\"\n    index = xr.CFTimeIndex([])\n    expected = \"CFTimeIndex([], dtype='object', length=0, calendar=None, freq=None)\"\n    assert repr(index) == expected\n"], "sample_611": ["def test_date_range_like_error():\n    source = date_range(\"2000-01-01\", periods=12, freq=\"D\")\n    with pytest.raises(ValueError):\n        date_range_like(source, \"invalid_calendar\")\n"], "sample_612": ["def test_groupby_reduce_dim_order():\n    array = DataArray(\n        np.random.randn(5, 3),\n        coords={\"a\": (\"x\", range(5)), \"b\": (\"y\", range(3))},\n        dims=[\"x\", \"y\"],\n    )\n    for by, expected_dims in [\n        (\"x\", (\"x\",)),\n        (\"y\", (\"y\",)),\n        (\"a\", (\"a\",)),\n        (\"b\", (\"b\",)),\n    ]:\n        result = array.groupby(by).mean()\n        assert result.dims == expected_dims\n"], "sample_613": ["def test_groupby_reduce_dim_order():\n    array = DataArray(\n        np.random.randn(5, 3),\n        coords={\"a\": (\"x\", range(5)), \"b\": (\"y\", range(3))},\n        dims=[\"x\", \"y\"],\n    )\n    for by, expected_dims in [\n        (\"x\", (\"x\",)),\n        (\"y\", (\"y\",)),\n        (\"a\", (\"a\",)),\n        (\"b\", (\"b\",)),\n    ]:\n        result = array.groupby(by).mean()\n        assert result.dims == expected_dims\n"], "sample_614": ["def test__element_formatter() -> None:\n    elements = [\"dim1\", \"dim2\", \"dim3\"]\n    col_width = 10\n    max_rows = 2\n\n    result = formatting._element_formatter(\n        elements, col_width=col_width, max_rows=max_rows\n    )\n    expected = \"dim1, dim2, ...\"\n    assert result == expected\n\n    max_rows = 3\n    result = formatting._element_formatter(\n        elements, col_width=col_width, max_rows=max_rows\n    )\n    expected = \"dim1, dim2, dim3\"\n    assert result == expected\n\n    elements = [\"longer_dim_name1\", \"longer_dim_name2\", \"longer_dim_name3\"]\n    result = formatting._element_formatter(\n        elements, col_width=col_width, max_rows=max_rows\n    )\n    expected = \"longer_dim_name1, longer_dim_name2, longer_dim_name3\"\n    assert result == expected\n\n    max_rows = 1\n    result = formatting._element_formatter(\n        elements, col_width=col_width, max_rows=max_rows\n    )\n    expected = \"longer_dim_name1, ...\"\n    assert result == expected\n"], "sample_619": ["def test_encode_cf_datetime_with_cftime_timezone() -> None:\n    import cftime\n\n    calendar = \"gregorian\"\n    times = cftime.num2date([0, 1], \"hours since 2000-01-01\", calendar)\n    units = \"days since 2000-01-01T00:00:00-05:00\"\n\n    encoded, _, _ = encode_cf_datetime(times, units, calendar)\n\n    expected = cftime.date2num(times, units, calendar)\n    np.testing.assert_equal(encoded, expected)\n"], "sample_620": ["def test_concat_dim_is_pandas_index() -> None:\n    objs = [Dataset({\"x\": 0}), Dataset({\"x\": 1})]\n    coord = pd.Index([3, 4], name=\"y\")\n    expected = Dataset({\"x\": (\"y\", [0, 1]), \"y\": coord})\n    actual = concat(objs, coord)\n    assert_identical(actual, expected)\n"], "sample_622": ["def test_decode_cf_variable_with_invalid_units() -> None:\n    v = Variable([\"t\"], [1, 2, 3], {\"units\": \"foobar since\"})\n    with pytest.raises(ValueError):\n        conventions.decode_cf_variable(\"test\", v)\n"], "sample_623": ["def test_open_dataset_chunks_auto() -> None:\n    \"\"\"Test that 'auto' chunks work as expected.\"\"\"\n    # Create a dataset with some variables.\n    dataset = xr.Dataset(\n        {\n            \"a\": (\"x\", np.arange(100)),\n            \"b\": (\"y\", np.arange(200)),\n            \"c\": ((\"x\", \"y\"), np.random.rand(100, 200)),\n        }\n    )\n\n    # Set preferred chunks for each variable.\n    dataset[\"a\"].encoding[\"preferred_chunks\"] = {\"x\": 20}\n    dataset[\"b\"].encoding[\"preferred_chunks\"] = {\"y\": 50}\n    dataset[\"c\"].encoding[\"preferred_chunks\"] = {\"x\": 20, \"y\": 50}\n\n    # Open the dataset with 'auto' chunks.\n    with assert_no_warnings():\n        result = xr.open_dataset(dataset, engine=PassThroughBackendEntrypoint, chunks=\"auto\")\n\n    # Check that the resulting dataset has the correct chunks.\n    assert result[\"a\"].chunks == ((20,) * 5,)\n    assert result[\"b\"].chunks == ((50,) * 4,)\n    assert result[\"c\"].chunks == ((20,) * 5, (50,) * 4)\n"], "sample_627": ["def test_concat_positions() -> None:\n    ds1 = Dataset(coords={\"x\": (\"x\", [1, 2])})\n    ds2 = Dataset(coords={\"x\": (\"x\", [3, 4])})\n\n    # specify positions\n    actual = concat([ds1, ds2], dim=\"x\", positions=[[0, 1], [2, 3]])\n    expected = Dataset(coords={\"x\": (\"x\", [1, 2, 3, 4])})\n    assert_identical(actual, expected)\n\n    # no positions specified\n    actual = concat([ds1, ds2], dim=\"x\")\n    expected = Dataset(coords={\"x\": (\"x\", [1, 2, 3, 4])})\n    assert_identical(actual, expected)\n\n    # incorrect positions length\n    with pytest.raises(ValueError, match=r\"Length of positions does not match length of datasets\"):\n        concat([ds1, ds2], dim=\"x\", positions=[[0, 1]])\n\n    # duplicate positions\n    with pytest.raises(ValueError, match=r\"Duplicate positions are not allowed\"):\n        concat([ds1, ds2], dim=\"x\", positions=[[0, 1], [1, 2]])\n"], "sample_628": ["def test_words_with_digits_are_ignored(self):\n    stmt = astroid.extract_node(\n        '''def f():\n    \"\"\"\n    test123\n    \"\"\"'''\n    )\n    with self.assertAddsMessages():\n        self.checker.visit_functiondef(stmt)\n\n    self.checker.process_tokens(_tokenize_str(\"# test456\"))\n    assert self.linter.release_messages() == []\n"], "sample_629": ["def test_expand_modules_file():\n    files_or_modules = [\"path/to/file.py\"]\n    ignore_list = []\n    ignore_list_re = []\n    ignore_list_paths_re = []\n    result, errors = expand_modules(\n        files_or_modules, ignore_list, ignore_list_re, ignore_list_paths_re\n    )\n    assert len(result) == 1\n    assert result[0][\"path\"] == \"path/to/file.py\"\n    assert result[0][\"name\"] == \"file\"\n    assert len(errors) == 0\n"], "sample_630": ["def test_get_annotation_label(func, label):\n    \"\"\"Test get_annotation_label function\"\"\"\n    node = astroid.extract_node(func)\n    got = get_annotation_label(node.args.args[1].annotation)\n    assert got == label, f\"got {got} instead of {label} for value {node}\"\n"], "sample_633": ["def test_get_similarity_report() -> None:\n    \"\"\"Tests that the get_similarity_report method returns a report as expected\"\"\"\n    sim = similar.Similar(min_lines=2)\n    sim.linesets = [\n        similar.LineSet(\"file1\", [\"line1\", \"line2\", \"line3\"], ignore_comments=True),\n        similar.LineSet(\"file2\", [\"line1\", \"line2\", \"line4\"], ignore_comments=True),\n    ]\n    report = sim._get_similarity_report(sim._compute_sims())\n    assert \"TOTAL lines=6 duplicates=2 percent=33.33\" in report\n"], "sample_634": ["    def test_expand_modules_with_ignore_list(self, files_or_modules, ignore_list, expected):\n        \"\"\"Test expand_modules with an ignore list\"\"\"\n        ignore_list_re = []\n        modules, errors = expand_modules(\n            files_or_modules,\n            ignore_list,\n            ignore_list_re,\n            get_global_option(self, \"ignore-paths\"),\n        )\n        modules.sort(key=lambda d: d[\"name\"])\n        assert modules == expected\n        assert not errors\n"], "sample_635": ["def test_numpy_docstring_with_multiple_types(self) -> None:\n    \"\"\"Example of a function with multiple types in the Numpy style docstring\"\"\"\n    node = astroid.extract_node(\n        \"\"\"\n        '''docstring ...\n\n        Parameters\n        ----------\n        x: int or float\n            bla\n        y: str or bytes\n            bar\n\n        Returns\n        -------\n        int or float\n            sum\n        '''\n        return x + y\n    \"\"\"\n    )\n    with self.assertNoMessages():\n        self.checker.visit_functiondef(node)\n"], "sample_637": ["def test_fixme_pattern_with_notes_rgx(self) -> None:\n    code = \"\"\"a = 1\n            # FIXME message\n            \"\"\"\n    set_config(notes_rgx=\"FIXME|TODO\", notes=[])()\n    self.checker.open()\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"fixme\", line=2, args=\"FIXME message\", col_offset=17)\n    ):\n        self.checker.process_tokens(_tokenize_str(code))\n"], "sample_638": ["def test_unsupported_output_format(mock_writer, capsys):\n    \"\"\"Test that an error message is shown when an unsupported output format is used.\"\"\"\n    with pytest.raises(SystemExit) as wrapped_sysexit:\n        main.Run([\"-o\", \"unsupported_format\", TEST_DATA_DIR])\n    # Check that the right error message is shown to the user\n    assert (\n        \"Format unsupported_format is not supported natively. Pyreverse will try to generate it using Graphviz...\"\n        in capsys.readouterr().out\n    )\n    # Check that pyreverse actually made the call to create the diagram and we exit cleanly\n    mock_writer.DiagramWriter().write.assert_called_once()\n    assert wrapped_sysexit.value.code == 0\n"], "sample_639": ["def test_base_checker_get_full_documentation() -> None:\n    basic = OtherBasicChecker()\n    expected_beginning = \"\"\"\\"], "sample_641": ["def test_load_result_file_does_not_exist(path: str) -> None:\n    assert load_results(path) is None\n\n"], "sample_642": ["def test_preprocess_options() -> None:\n    \"\"\"Test that pre-processable options are correctly handled.\"\"\"\n    run = Run([\"--init-hook=import os\", \"--rcfile=foo\"])\n    with mock.patch.object(run, \"_rcfile\", None):\n        processed_args = _preprocess_options(run, [\"--init-hook=import os\", \"--rcfile=foo\"])\n        assert processed_args == []\n        assert run._rcfile == \"foo\"\n"], "sample_643": ["def test_colorized_text_reporter_color_mapping_deprecation() -> None:\n    \"\"\"Test that the color_mapping parameter of ColorizedTextReporter is deprecated.\"\"\"\n    with warnings.catch_warnings(record=True) as cm:\n        warnings.simplefilter(\"always\")\n        ColorizedTextReporter(color_mapping={\"I\": (\"green\", \"bold\")})\n\n    assert len(cm) == 1\n    assert isinstance(cm[0].message, DeprecationWarning)\n    assert (\n        \"In pylint 3.0, the ColorizedTextReporter will only accept ColorMappingDict as color_mapping parameter\"\n        in str(cm[0].message)\n    )\n"], "sample_645": ["def test_log_cli_enabled(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_cli = True\n        log_cli_level = DEBUG\n    \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n            logger = logging.getLogger('catchlog')\n            logger.debug(\"DEBUG message will be shown\")\n            assert 'DEBUG' in caplog.text\n    \"\"\"\n    )\n\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*DEBUG message will be shown*\"])\n    assert result.ret == 0\n"], "sample_646": ["def test_unittest_subtest(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n\n        class MyTestCase(unittest.TestCase):\n                for i in range(5):\n                    with self.subTest(i=i):\n                        if i == 3:\n                            assert False\n        \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*1 failed, 4 passed*\"])\n"], "sample_647": ["def test_unformatted_warning() -> None:\n    \"\"\"Test that UnformattedWarning formats the message correctly.\"\"\"\n    warning = warning_types.UnformattedWarning(\n        category=warning_types.PytestWarning, template=\"This is a {adjective} warning\"\n    )\n    formatted_warning = warning.format(adjective=\"test\")\n    assert isinstance(formatted_warning, warning_types.PytestWarning)\n    assert str(formatted_warning) == \"This is a test warning\"\n"], "sample_648": ["def test_get_empty_parameterset_mark_reason(pytester: Pytester) -> None:\n    config = pytester.parseconfig()\n    from _pytest.mark import get_empty_parameterset_mark\n\n    mark = get_empty_parameterset_mark(config, [\"a\", \"b\"], lambda: None)\n    assert mark.kwargs[\"reason\"] == \"got empty parameter set ['a', 'b'], function <lambda> at ?:?\"\n"], "sample_649": ["def test_log_file_cli_level_override(pytester: Pytester) -> None:\n    # Default log file level\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_file_handler.level == logging.INFO\n            logging.getLogger('catchlog').debug(\"This log message won't be shown\")\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n\n    log_file = str(pytester.path.joinpath(\"pytest.log\"))\n\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = WARNING\n        \"\"\".format(\n            log_file\n        )\n    )\n\n    result = pytester.runpytest(\"-s\", f\"--log-file={log_file}\", \"--log-file-level=INFO\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines([\"test_log_file_cli_level_override.py PASSED\"])\n\n    # make sure that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert \"This log message will be shown\" in contents\n        assert \"This log message won't be shown\" not in contents\n"], "sample_650": ["def test_log_file_formatting(pytester: Pytester) -> None:\n    \"\"\"Check that log_file_format affects output.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n\n        logger = logging.getLogger(__name__)\n\n            logger.warning('text')\n            assert False\n        \"\"\"\n    )\n    log_file = str(pytester.path.joinpath(\"pytest.log\"))\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_format=%(asctime)s; %(levelname)s; %(message)s\n        log_file_date_format=%Y-%m-%d %H:%M:%S\n    \"\"\".format(\n            log_file\n        )\n    )\n    result = pytester.runpytest()\n    assert result.ret == 1\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert re.match(r\"^[0-9-]{10} [0-9:]{8}; WARNING; text\", contents)\n"], "sample_651": ["def test_warns_context_manager_with_match_and_kwargs(self) -> None:\n    with pytest.raises(TypeError) as excinfo:\n        with pytest.warns(UserWarning, match=\"foo\", foo=\"bar\"):  # type: ignore\n            pass\n    assert \"Unexpected keyword arguments\" in str(excinfo.value)\n"], "sample_652": ["def test_fixture_function_with_yield_and_return():\n    \"\"\"Check if a fixture function with both yield and return statements raises an error (#4545)\"\"\"\n\n    @pytest.fixture\n        yield 1\n        return 2\n\n    with pytest.raises(pytest.fail.Exception):\n        assert fix() == 1\n"], "sample_653": ["def test_log_file_path_traversal(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        \"\"\".format(\n            log_file\n        )\n    )\n\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logging.getLogger().info(\"Normal message\")\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file, encoding=\"utf-8\") as rfh:\n        contents = rfh.read()\n        assert \"Normal message\" in contents\n\n    # Test that the log file path is not vulnerable to path traversal attacks\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file=../pytest.log\n        log_file_level = INFO\n        \"\"\"\n    )\n\n    result = testdir.runpytest()\n\n    assert result.ret == 1\n    assert \"ValueError: The log file path must be within the root directory\" in result.stdout.str()\n"], "sample_655": ["def test_capturing_with_keyboard_interrupt(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import sys\n\n            print(\"hello\")\n            raise KeyboardInterrupt()\n        \"\"\"\n    )\n    result = testdir.runpytest_subprocess()\n    assert result.ret == 2\n    result.stdout.fnmatch_lines([\"*KeyboardInterrupt*\"])\n    assert \"hello\" in result.stdout.str()\n"], "sample_656": ["def test_capturing_with_keyboard_interrupt(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import sys\n\n            print(\"hello\")\n            raise KeyboardInterrupt()\n        \"\"\"\n    )\n\n    result = testdir.runpytest_subprocess()\n    assert result.ret == 2\n    result.stdout.fnmatch_lines([\"*KeyboardInterrupt*\"])\n    assert \"hello\" in result.stdout.str()\n"], "sample_657": ["def test_mark_decorator_with_multiple_args(testdir):\n    \"\"\"Test that a mark decorator with multiple arguments is correctly applied.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.foo('bar', 'baz')\n            pass\n    \"\"\"\n    )\n    items, rec = testdir.inline_genitems()\n    item = items[0]\n    marker = item.get_closest_marker(\"foo\")\n    assert marker.args == ('bar', 'baz')\n"], "sample_658": ["def test_doctest_unwrap_mock_aware(testdir):\n    pytest.importorskip(\"mock\")\n    testdir.makepyfile(\n        \"\"\"\n        from mock import Mock\n        class Example(object):\n            '''\n            >>> 1 + 1\n            2\n            '''\n                self.mock = Mock()\n        \"\"\"\n    )\n    result = testdir.runpytest(\"--doctest-modules\")\n    result.stdout.fnmatch_lines([\"* 1 passed *\"])\n"], "sample_660": ["def test_log_passing_tests(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n            pass\n    \"\"\"\n    )\n    result, dom = runandparse(testdir, \"-o\", \"junit_log_passing_tests=False\")\n    node = dom.find_first_by_tag(\"testcase\")\n    assert not node.find_first_by_tag(\"system-out\")\n\n    result, dom = runandparse(testdir, \"-o\", \"junit_log_passing_tests=True\")\n    node = dom.find_first_by_tag(\"testcase\")\n    assert node.find_first_by_tag(\"system-out\")\n"], "sample_661": ["def test_log_passing_tests(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n            print(\"Hello, world!\")\n            pass\n    \"\"\"\n    )\n    result, dom = runandparse(testdir, \"-o\", \"junit_log_passing_tests=False\")\n    node = dom.find_first_by_tag(\"testcase\")\n    systemout = node.find_first_by_tag(\"system-out\")\n    assert systemout is None\n\n    result, dom = runandparse(testdir, \"-o\", \"junit_log_passing_tests=True\")\n    node = dom.find_first_by_tag(\"testcase\")\n    systemout = node.find_first_by_tag(\"system-out\")\n    assert systemout is not None\n    assert \"Hello, world!\" in systemout.text\n"], "sample_663": ["def test_collect_with_broken_conftest(testdir):\n    \"\"\"Test that a broken conftest does not prevent collection of other tests.\"\"\"\n    sub = testdir.mkdir(\"sub\")\n    sub.ensure(\"conftest.py\").write(\"assert 0, 'broken conftest'\")\n    sub.ensure(\"test_file.py\").write(\"def test_file(): pass\")\n\n    result = testdir.runpytest(\"-v\", str(sub))\n    result.stdout.fnmatch_lines(\n        [\n            \"*ERROR collecting sub/test_file.py*\",\n            \"E*assert 0*\",\n            \"*1 error in*\",\n        ]\n    )\n    assert result.ret == ExitCode.TESTS_FAILED\n"], "sample_664": ["def test_fixture_positional_arguments_warning():\n    \"\"\"Check that passing positional arguments to pytest.fixture() raises a warning.\"\"\"\n    with pytest.warns(deprecated.FIXTURE_POSITIONAL_ARGUMENTS):\n        pytest.fixture(autouse=True)\n"], "sample_665": ["def test_collect_file_with_dunder_init(testdir):\n    \"\"\"Test that a file with __init__.py in its path is collected correctly.\"\"\"\n    sub = testdir.mkdir(\"sub\")\n    init = sub.ensure(\"__init__.py\")\n    init.write(\"def test_init(): pass\")\n    p = sub.ensure(\"test_file.py\")\n    p.write(\"def test_file(): pass\")\n\n    result = testdir.runpytest(\"-v\", str(sub))\n    result.stdout.fnmatch_lines(\n        [\n            \"sub/__init__.py::test_init PASSED*\",\n            \"sub/test_file.py::test_file PASSED*\",\n            \"*2 passed in*\",\n        ]\n    )\n"], "sample_666": ["def test_percent_style_multiline_auto_indent(tmpfile):\n    fmt = PercentStyleMultiline(\"%(message)s\", auto_indent=True)\n    record_dict = {\"message\": \"line1\\nline2\"}\n    formatted = fmt.format(record_dict)\n    assert formatted == \"line1\\n        line2\"\n\n    fmt = PercentStyleMultiline(\"%(message)s\", auto_indent=4)\n    record_dict = {\"message\": \"line1\\nline2\"}\n    formatted = fmt.format(record_dict)\n    assert formatted == \"line1\\n    line2\"\n\n    fmt = PercentStyleMultiline(\"%(message)s\", auto_indent=False)\n    record_dict = {\"message\": \"line1\\nline2\"}\n    formatted = fmt.format(record_dict)\n    assert formatted == \"line1\\nline2\"\n"], "sample_667": ["def test_getbasetemp_with_given_basetemp(tmp_path):\n    from _pytest.tmpdir import TempPathFactory\n\n    config = FakeConfig(tmp_path)\n    t = TempPathFactory.from_config(config)\n    assert t.getbasetemp() == tmp_path.resolve()\n"], "sample_668": ["def test_fixture_positional_arguments_warning():\n    with pytest.warns(pytest.PytestDeprecationWarning) as w:\n        pytest.fixture(autouse=True)\n    assert len(w) == 1\n    assert \"Passing arguments to pytest.fixture() as positional arguments is deprecated\" in str(w[0].message)\n"], "sample_669": ["def test_capturing_with_keyboard_interrupt(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n            raise KeyboardInterrupt()\n        \"\"\"\n    )\n    result = testdir.runpytest(p)\n    result.stdout.fnmatch_lines([\"*KeyboardInterrupt*\"])\n    assert result.ret == 2\n"], "sample_670": ["def test_unknown_idents(expr: str, matcher: dict, expected: bool) -> None:\n        return matcher.get(ident, False)\n\n    assert evaluate(expr, _matcher) is expected\n"], "sample_671": ["def test_xfail_strict_with_multiple_conditions(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(\"True or False\", reason=\"first condition\", strict=True)\n            assert 1\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rxX\")\n    result.stdout.fnmatch_lines([\"*XPASS(strict)*first condition*\"])\n    assert result.ret == 1\n"], "sample_672": ["def test_saferepr_recursive():\n    \"\"\"Test saferepr() with recursive objects.\"\"\"\n\n    class Recursive:\n            self.attr = None\n\n            return \"Recursive({})\".format(self.attr)\n\n    obj1 = Recursive()\n    obj2 = Recursive()\n    obj1.attr = obj2\n    obj2.attr = obj1\n\n    assert \"...\" in saferepr(obj1)\n"], "sample_673": ["def test_doctest_namespace_fixture_with_multiple_fixtures(testdir):\n    \"\"\"\n    Check that inserting something into the namespace works with multiple fixtures.\n    \"\"\"\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n        import contextlib\n\n        @pytest.fixture(autouse=True)\n            doctest_namespace['cl'] = contextlib\n\n        @pytest.fixture(autouse=True)\n            doctest_namespace['math'] = math\n    \"\"\"\n    )\n    p = testdir.maketxtfile(\n        \"\"\"\n        >>> print(cl.__name__)\n        contextlib\n        >>> print(math.pi)\n        3.14159265359\n    \"\"\"\n    )\n    reprec = testdir.inline_run(p)\n    reprec.assertoutcome(passed=1)\n"], "sample_674": ["def test_node_repr():\n    node = nodes.Node.from_parent(None, name=\"test_node\")\n    assert repr(node) == \"<Node test_node>\"\n"], "sample_676": ["def test_line_with_reprcrash_message_truncation(monkeypatch):\n    import _pytest.terminal\n    from wcwidth import wcswidth\n\n    mocked_verbose_word = \"FAILED\"\n\n    mocked_pos = \"some::nodeid\"\n\n        return mocked_pos\n\n    monkeypatch.setattr(_pytest.terminal, \"_get_pos\", mock_get_pos)\n\n    class config(object):\n        pass\n\n    class rep(object):\n            return mocked_verbose_word\n\n        longrepr = type(\"\", (), {\"reprcrash\": type(\"\", (), {\"message\": \"a\" * 1000})})\n\n    termwidth = 80\n    line = _get_line_with_reprcrash_message(config, rep, termwidth)\n    assert len(line) <= termwidth\n    assert line.endswith(\"...\")\n"], "sample_677": ["def test_evaluate_with_matcher(expr: str, matcher: Callable[[str], bool], expected: bool) -> None:\n    assert evaluate(expr, matcher) is expected\n"], "sample_678": ["def test_ensure_deletable(tmp_path):\n    \"\"\"Test that ensure_deletable works correctly.\"\"\"\n    path = tmp_path / \"temp-1\"\n    path.mkdir()\n    lock_path = get_lock_path(path)\n    lock_path.touch()\n\n    # Test that ensure_deletable returns False when the lock file exists\n    assert not ensure_deletable(path, 0)\n\n    # Test that ensure_deletable returns True when the lock file does not exist\n    lock_path.unlink()\n    assert ensure_deletable(path, 0)\n\n    # Test that ensure_deletable returns True when the lock file is old\n    lock_path.touch()\n    lock_path.utime((0, 0))  # Set the modification time to epoch\n    assert ensure_deletable(path, 1)\n"], "sample_679": ["def test_mark_evaluator_istrue_with_condition():\n    item = mock.Mock()\n    item.iter_markers.return_value = [Mark(name=\"my_mark\", args=(\"condition\",), kwargs={})]\n    evaluator = MarkEvaluator(item, \"my_mark\")\n    assert evaluator.istrue() is True\n"], "sample_680": ["def test_xfail_strict_ini(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = True\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n            assert 1\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n    assert result.ret == 1\n"], "sample_681": ["def test_log_file_format(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        log_file_format = %(asctime)s %(levelname)s %(message)s\n        log_file_date_format = %Y-%m-%d %H:%M:%S\n        \"\"\".format(\n            log_file\n        )\n    )\n\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n            logging.info('text going to logger from call')\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 0\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert re.match(r\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} INFO text going to logger from call\", contents)\n"], "sample_682": ["def test_xfail_strict_ini(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = True\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n"], "sample_685": ["def test_log_cli_enabled(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_cli = True\n        log_cli_level = INFO\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n            logger = logging.getLogger('catchlog')\n            logger.info(\"INFO message will be shown\")\n            logger.debug(\"DEBUG message won't be shown\")\n            assert 'INFO message will be shown' in caplog.text\n            assert 'DEBUG message won\\'t be shown' not in caplog.text\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 0\n"], "sample_686": ["def test_fixture_positional_arguments_warning() -> None:\n    with pytest.warns(\n        pytest.PytestDeprecationWarning,\n        match=\"Passing arguments to pytest.fixture\\\\(\\\\) as positional arguments is deprecated\",\n    ):\n        pytest.fixture(autouse=True)\n"], "sample_689": ["def test_warning_captured_hook_is_deprecated(testdir: Testdir) -> None:\n    conftest = testdir.makeconftest(\n        \"\"\"\n            pass\n        \"\"\"\n    )\n    test_file = testdir.makepyfile(\"def test_foo(): pass\")\n    result = testdir.runpytest(conftest, test_file)\n    result.stdout.fnmatch_lines([\"*The pytest_warning_captured is deprecated*\"])\n"], "sample_690": ["def test_xfail_strict_ini(pytester: Pytester) -> None:\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        xfail_strict = True\n    \"\"\"\n    )\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n"], "sample_691": ["def test_unconfigure(pytester: Pytester, monkeypatch) -> None:\n    \"\"\"Test that faulthandler is properly unconfigured after pytest finishes.\"\"\"\n    import faulthandler\n    from _pytest.faulthandler import FaultHandlerHooks\n\n    called = []\n\n    monkeypatch.setattr(faulthandler, \"disable\", lambda: called.append(1))\n    monkeypatch.setattr(faulthandler, \"enable\", lambda file: called.append(2))\n\n    hooks = FaultHandlerHooks()\n    hooks.pytest_configure(pytester.config)\n    hooks.pytest_unconfigure(pytester.config)\n\n    assert called == [1, 2]\n"], "sample_692": ["def test_tmp_path_factory_cleanup(pytester: Pytester, tmp_path_factory: TempPathFactory) -> None:\n    \"\"\"Test that tmp_path_factory cleans up after itself.\"\"\"\n    basetemp = tmp_path_factory.getbasetemp()\n    assert basetemp.exists()\n\n    # Create a few temporary directories\n    for _ in range(3):\n        tmp_path_factory.mktemp(\"test\")\n\n    # Check that they exist\n    assert len(list(basetemp.iterdir())) == 3\n\n    # Clean up\n    tmp_path_factory._basetemp = None\n\n    # Check that the temporary directories are gone\n    assert not list(basetemp.iterdir())\n"], "sample_693": ["def test_unittest_subtest(pytester: Pytester) -> None:\n    pytest.importorskip(\"unittest\")\n\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n\n        class MyTestCase(unittest.TestCase):\n                for i in range(5):\n                    with self.subTest(i=i):\n                        self.assertEqual(i % 2, 0)\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-v\")\n    result.stdout.fnmatch_lines([\"*MyTestCase.test_one[i=0]*\", \"*MyTestCase.test_one[i=2]*\", \"*MyTestCase.test_one[i=4]*\"])\n    result.stdout.fnmatch_lines([\"*MyTestCase.test_one[i=1]*\", \"*MyTestCase.test_one[i=3]*\"])\n    result.assert_outcomes(passed=3, failed=2)\n"], "sample_695": ["def test_node_repr_failure_with_non_pytest_warning(pytester: Pytester) -> None:\n    items = pytester.getitems(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    with pytest.raises(Exception, match=\"^$\"):\n        items[0].repr_failure(excinfo=pytest.raises(Exception(\"ok\")))\n"], "sample_696": ["def test_argument_percent_default_is_deprecated() -> None:\n    with pytest.warns(\n        pytest.PytestDeprecationWarning,\n        match=r\"pytest now uses argparse. %default should be changed to %(default)s\",\n    ):\n        pytest.deprecated.ARGUMENT_PERCENT_DEFAULT.warn()\n"], "sample_697": ["def test_tmp_path_factory_uses_given_basetemp(tmp_path: Path) -> None:\n    given_basetemp = tmp_path / \"given\"\n    tmp_factory = TempPathFactory(given_basetemp, lambda *args: None, _ispytest=True)\n    basetemp = tmp_factory.getbasetemp()\n    assert basetemp == given_basetemp.resolve()\n    assert basetemp.exists()\n"], "sample_698": ["def test_percent_style_multiline_with_custom_indent() -> None:\n    from _pytest.logging import PercentStyleMultiline\n\n    logfmt = \"%(filename)-25s %(lineno)4d %(levelname)-8s %(message)s\"\n\n    record: Any = logging.LogRecord(\n        name=\"dummy\",\n        level=logging.INFO,\n        pathname=\"dummypath\",\n        lineno=10,\n        msg=\"Test Message line1\\nline2\",\n        args=(),\n        exc_info=None,\n    )\n    # this is called by logging.Formatter.format\n    record.message = record.getMessage()\n\n    ai_on_style = PercentStyleMultiline(logfmt, auto_indent=3)\n    output = ai_on_style.format(record)\n    assert output == (\n        \"dummypath                   10 INFO     Test Message line1\\n\"\n        \"                                      line2\"\n    )\n\n    ai_off_style = PercentStyleMultiline(logfmt, auto_indent=False)\n    output = ai_off_style.format(record)\n    assert output == (\n        \"dummypath                   10 INFO     Test Message line1\\nline2\"\n    )\n\n    ai_none_style = PercentStyleMultiline(logfmt, auto_indent=None)\n    output = ai_none_style.format(record)\n    assert output == (\n        \"dummypath                   10 INFO     Test Message line1\\nline2\"\n    )\n"], "sample_699": ["def test_doctest_namespace_is_not_module_scope(self, pytester: Pytester) -> None:\n    \"\"\"Test that doctest_namespace is not shared between modules (#8953).\"\"\"\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture(autouse=True)\n            doctest_namespace['foo'] = 'bar'\n            doctest_namespace['baz'] = 'qux'\n    \"\"\"\n    )\n    pytester.makepyfile(\n        mod1=\"\"\"\n            '''\n            >>> foo\n            'bar'\n            >>> baz = 'xyzzy'\n            >>> baz\n            'xyzzy'\n            '''\n    \"\"\",\n        mod2=\"\"\"\n            '''\n            >>> foo\n            'bar'\n            >>> baz\n            'qux'\n            '''\n    \"\"\",\n    )\n    result = pytester.runpytest(\"--doctest-modules\")\n    result.stdout.fnmatch_lines([\"* 2 passed *\"])\n"], "sample_700": ["def test_xfail_strict_with_condition(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(condition=True, reason=\"Expected failure\", strict=True)\n            assert True\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-rxX\")\n    result.stdout.fnmatch_lines([\"*XPASS(strict)*Expected failure*\"])\n    assert result.ret == 1\n"], "sample_701": ["def test_argument_percent_default_is_deprecated(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n            parser.addoption(\"--foo\", action=\"store\", default=\"bar\", help=\"foo: %default\")\n        \"\"\"\n    )\n    result = pytester.runpytest(\"--help\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestDeprecationWarning: pytest now uses argparse. \"\n            '\"%default\" should be changed to \"%(default)s\"',\n        ]\n    )\n"], "sample_703": ["def test_matcher_adapter() -> None:\n    matcher = {\"foo\": True, \"bar\": False}.__getitem__\n    adapter = MatcherAdapter(matcher)\n    assert adapter[\"$foo\"]\n    assert not adapter[\"$bar\"]\n    with pytest.raises(KeyError):\n        adapter[\"$baz\"]\n"], "sample_706": ["def test_matcher_adapter() -> None:\n    matcher = {\"foo\": True, \"bar\": False}.__getitem__\n    adapter = MatcherAdapter(matcher)\n    assert adapter[\"$foo\"]\n    assert not adapter[\"$bar\"]\n    with pytest.raises(KeyError):\n        adapter[\"$baz\"]\n"], "sample_707": ["def test_node_get_closest_marker() -> None:\n    class DummyNode(nodes.Node):\n            super().__init__(name, parent)\n            if markers:\n                for marker in markers:\n                    self.add_marker(marker)\n\n    node1 = DummyNode(\"node1\")\n    node2 = DummyNode(\"node2\", parent=node1, markers=[\"mark1\"])\n    node3 = DummyNode(\"node3\", parent=node2, markers=[\"mark2\"])\n\n    assert node3.get_closest_marker(\"mark1\") is not None\n    assert node3.get_closest_marker(\"mark2\") is not None\n    assert node3.get_closest_marker(\"mark3\") is None\n\n    # Test default value\n    default_marker = nodes.Mark(\"default\", (), {})\n    assert node3.get_closest_marker(\"mark3\", default=default_marker) == default_marker\n"], "sample_708": ["def test_getstatementrange_with_nested_try_except() -> None:\n    source = Source(\n        \"\"\"\\\n        try:\n            try:\n                raise ValueError\n            except ValueError:\n                pass\n        except Exception:\n            pass\n        \"\"\"\n    )\n    assert len(source) == 7\n    assert source.getstatementrange(2) == (2, 3)\n    assert source.getstatementrange(4) == (4, 5)\n    assert source.getstatementrange(6) == (6, 7)\n"], "sample_710": ["def test_unittest_subtest(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n\n        class MyTestCase(unittest.TestCase):\n                for i in range(5):\n                    with self.subTest(i=i):\n                        self.assertEqual(i % 2, 0)\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*3 failed*\"])\n"], "sample_712": ["def test_ordinal_encoder_categories():\n    X = [['abc', 2, 55], ['def', 1, 55]]\n    enc = OrdinalEncoder(categories=[['abc', 'def'], [1, 2], [54, 55, 56]])\n    exp = np.array([[0, 1, 1],\n                    [1, 0, 1]], dtype='float64')\n    assert_array_equal(enc.fit_transform(X), exp)\n    assert_array_equal(enc.categories_, [['abc', 'def'], [1, 2], [54, 55, 56]])\n\n    # manually specified categories should have same dtype as\n    # the data when coerced from lists\n    assert enc.categories_[0].dtype == 'object'\n    assert enc.categories_[1].dtype == 'int64'\n    assert enc.categories_[2].dtype == 'int64'\n\n    # when specifying categories manually, unknown categories should already\n    # raise when fitting\n    X = [['abc', 3, 55], ['def', 1, 55]]\n    enc = OrdinalEncoder(categories=[['abc', 'def'], [1, 2], [54, 55, 56]])\n    with pytest.raises(ValueError, match=\"Found unknown categories\"):\n        enc.fit(X)\n"], "sample_713": ["def test_ridgecv_scorer():\n    # Test that RidgeCV works with a custom scorer\n    X, y = make_regression(n_samples=100, n_features=10, random_state=42)\n    scorer = make_scorer(mean_squared_error, greater_is_better=False)\n    ridgecv = RidgeCV(scorer=scorer)\n    ridgecv.fit(X, y)\n    assert hasattr(ridgecv, 'best_score_')\n    assert hasattr(ridgecv, 'alpha_')\n"], "sample_714": ["def test_brier_score_loss():\n    y_true = [0, 1, 1, 0]\n    y_prob = [0.3, 0.7, 0.9, 0.1]\n    loss = brier_score_loss(y_true, y_prob)\n    assert_almost_equal(loss, 0.037)\n\n    y_true = np.array([[0, 1], [1, 0]])\n    y_prob = np.array([[0.2, 0.8], [0.7, 0.3]])\n    loss = brier_score_loss(y_true, y_prob)\n    assert_almost_equal(loss, 0.032)\n\n    # Test with sample weights\n    y_true = [0, 1, 1, 0]\n    y_prob = [0.3, 0.7, 0.9, 0.1]\n    sample_weight = [0.5, 1.0, 0.5, 1.0]\n    loss = brier_score_loss(y_true, y_prob, sample_weight=sample_weight)\n    assert_almost_equal(loss, 0.052)\n\n    # Test with pos_label\n    y_true = [0, 2, 2, 0]\n    y_prob = [0.3, 0.7, 0.9, 0.1]\n    loss = brier_score_loss(y_true, y_prob, pos_label=2)\n    assert_almost_equal(loss, 0.037)\n\n    # Test multi-output\n    y_true = np.array([[0, 1], [1, 0]])\n    y_prob = np.array([[0.2, 0.8], [0.7, 0.3]])\n    loss = brier_score_loss(y_true, y_prob)\n    assert_almost_equal(loss, 0.032)\n"], "sample_715": ["def test_cross_val_score_with_fit_params():\n    iris = load_iris()\n    X, y = iris.data, iris.target\n\n    class DummyEstimator(BaseEstimator):\n            self.fit_params = fit_params\n            return self\n\n            return 1.0\n\n    estimator = DummyEstimator()\n\n    # Test that fit_params are passed to the estimator's fit method\n    fit_params = {'foo': 'bar'}\n    scores = cross_val_score(estimator, X, y, fit_params=fit_params)\n    assert_array_equal(scores, np.ones(3))\n\n    # Test that fit_params are not modified during the cross-validation loop\n    assert_equal(estimator.fit_params, fit_params)\n"], "sample_716": ["def test_ridgecv_scorer():\n    # Test that RidgeCV works with a scorer\n    X, y = make_regression(n_samples=100, n_features=10, random_state=42)\n    scorer = get_scorer('neg_mean_squared_error')\n    ridgecv = RidgeCV(scorer=scorer)\n    ridgecv.fit(X, y)\n    assert hasattr(ridgecv, 'best_score_')\n    assert hasattr(ridgecv, 'alpha_')\n"], "sample_719": ["def test_countvectorizer_dtype():\n    # Test that the dtype parameter is propagated to the matrix.\n    vect = CountVectorizer(dtype=np.float32)\n    X = vect.fit_transform(JUNK_FOOD_DOCS)\n    assert_equal(X.dtype, np.float32)\n\n    # Test that setting dtype to 'int64' raises a warning\n    vect = CountVectorizer(dtype=np.int64)\n    with pytest.warns(UserWarning, match=\"'dtype' should be used.\"):\n        X = vect.fit_transform(JUNK_FOOD_DOCS)\n    assert_equal(X.dtype, np.float64)\n"], "sample_721": ["def test_check_memory():\n    # Test that check_memory returns a joblib.Memory instance\n    memory = check_memory(None)\n    assert isinstance(memory, Memory)\n\n    # Test that check_memory raises an error when the input is not a string or None\n    assert_raises_regex(ValueError, \"should be None, a string or have the same\",\n                        check_memory, 1)\n\n    # Test that check_memory raises an error when the input does not have a cache method\n    class Dummy:\n        pass\n    assert_raises_regex(ValueError, \"should be None, a string or have the same\",\n                        check_memory, Dummy())\n\n    # Test that check_memory works with a joblib.Memory instance\n    memory = Memory(location='/tmp')\n    checked_memory = check_memory(memory)\n    assert checked_memory is memory\n\n    # Test that check_memory works with a string\n    checked_memory = check_memory('/tmp')\n    assert isinstance(checked_memory, Memory)\n    assert checked_memory.location == '/tmp'\n"], "sample_722": ["def test_k_means_convergence_warning():\n    # Test that a ConvergenceWarning is raised when the number of iterations\n    # is less than max_iter\n    km = KMeans(n_clusters=n_clusters, init=\"random\", random_state=42,\n                n_init=1, max_iter=1)\n    assert_warns_message(ConvergenceWarning, \"Number of iterations\",\n                         km.fit, X)\n"], "sample_723": ["def test_imputation_copy():\n    # Test that imputation doesn't modify the original array when copy=True.\n    X = np.array([\n        [np.nan, 0, 0, 0, 5],\n        [np.nan, 1, 0, np.nan, 3],\n        [np.nan, 2, 0, 0, 0],\n        [np.nan, 6, 0, 5, 13],\n    ])\n\n    for strategy in [\"mean\", \"median\", \"most_frequent\"]:\n        imputer = SimpleImputer(strategy=strategy, copy=True)\n        X_imputed = imputer.fit_transform(X)\n\n        assert_false(np.array_equal(X, X_imputed))\n        assert_array_equal(X, np.array([\n            [np.nan, 0, 0, 0, 5],\n            [np.nan, 1, 0, np.nan, 3],\n            [np.nan, 2, 0, 0, 0],\n            [np.nan, 6, 0, 5, 13],\n        ]))\n\n    # Test that imputation modifies the original array when copy=False.\n    for strategy in [\"mean\", \"median\", \"most_frequent\"]:\n        imputer = SimpleImputer(strategy=strategy, copy=False)\n        X_imputed = imputer.fit_transform(X)\n\n        assert_array_equal(X, X_imputed)\n"], "sample_724": ["def test_imputation_copy():\n    # Test that imputation doesn't modify the original array when copy=True.\n    X = np.array([\n        [np.nan, 0, 0, 0, 5],\n        [np.nan, 1, 0, np.nan, 3],\n        [np.nan, 2, 0, 0, 0],\n        [np.nan, 6, 0, 5, 13],\n    ])\n\n    for strategy in [\"mean\", \"median\", \"most_frequent\"]:\n        imputer = Imputer(strategy=strategy, copy=True)\n        X_imputed = imputer.fit_transform(X)\n\n        assert_false(np.array_equal(X, X_imputed))\n        assert_array_equal(X, np.array([\n            [np.nan, 0, 0, 0, 5],\n            [np.nan, 1, 0, np.nan, 3],\n            [np.nan, 2, 0, 0, 0],\n            [np.nan, 6, 0, 5, 13],\n        ]))\n\n    # Test that imputation modifies the original array when copy=False.\n    for strategy in [\"mean\", \"median\", \"most_frequent\"]:\n        imputer = Imputer(strategy=strategy, copy=False)\n        X_imputed = imputer.fit_transform(X)\n\n        assert_array_equal(X, X_imputed)\n"], "sample_725": ["def test_check_memory():\n    # Test that check_memory returns a joblib.Memory instance\n    memory = check_memory(None)\n    assert isinstance(memory, Memory)\n\n    # Test that check_memory raises an error for invalid input\n    assert_raises_regex(ValueError, \"memory should be None, a string or have the same interface as sklearn.externals.joblib.Memory.\",\n                        check_memory, \"invalid_input\")\n\n    # Test that check_memory returns the input if it's already a joblib.Memory instance\n    memory = Memory(location=\"/tmp\")\n    assert check_memory(memory) is memory\n\n    # Test that check_memory creates a new joblib.Memory instance with the given location\n    memory = check_memory(\"/tmp\")\n    assert isinstance(memory, Memory)\n    assert memory.location == \"/tmp\"\n"], "sample_726": ["def test_label_binarize_empty_input():\n    y = []\n    classes = [0, 1, 2]\n    pos_label = 1\n    neg_label = 0\n\n    lb = LabelBinarizer(neg_label=neg_label, pos_label=pos_label)\n    binarized = lb.fit_transform(y)\n    assert_array_equal(binarized, np.array([]))\n    assert_array_equal(lb.classes_, classes)\n\n    binarized = label_binarize(y, classes, neg_label=neg_label,\n                               pos_label=pos_label)\n    assert_array_equal(binarized, np.array([]))\n"], "sample_727": ["def test_imputation_axis_deprecation():\n    # Test that axis deprecation warning is raised\n    X = np.array([[1, 2], [3, 4]])\n\n    with assert_warns_message(DeprecationWarning,\n                             \"Parameter 'axis' has been deprecated\"):\n        Imputer(axis=0).fit(X)\n\n    with assert_warns_message(DeprecationWarning,\n                             \"Parameter 'axis' has been deprecated\"):\n        Imputer(axis=1).fit(X)\n"], "sample_729": ["def test_enet_l1_ratio():\n    # Test that the l1_ratio parameter in ElasticNet has an effect on the model\n    X, y, _, _ = build_dataset(n_samples=20, n_features=10)\n    clf = ElasticNet(l1_ratio=0.5, max_iter=100, precompute=False,\n                     fit_intercept=True, normalize=False)\n    clf.fit(X, y)\n    coef_half = clf.coef_\n\n    clf = ElasticNet(l1_ratio=0.8, max_iter=100, precompute=False,\n                     fit_intercept=True, normalize=False)\n    clf.fit(X, y)\n    coef_eight = clf.coef_\n\n    assert_true(np.any(coef_half != coef_eight))\n"], "sample_730": ["def test_enet_l1_ratio_warning():\n    # Test that a warning message is raised if l1_ratio < 0.01\n    X = np.array([[1, 2, 4, 5, 8], [3, 5, 7, 7, 8]]).T\n    y = np.array([12, 10, 11, 21, 5])\n\n    msg = (\"l1_ratio <= 0.01 may lead to inaccurate results. Consider setting\"\n           \" l1_ratio > 0.01.\")\n\n    assert_warns_message(UserWarning, msg, ElasticNetCV(\n        l1_ratio=0.001, random_state=42).fit, X, y)\n    assert_warns_message(UserWarning, msg, MultiTaskElasticNetCV(\n        l1_ratio=0.001, random_state=42).fit, X, y[:, None])\n"], "sample_731": ["def test_california_housing_fetch():\n    data = fetch()\n    assert data.data.shape == (20640, 8)\n    assert data.target.shape == (20640,)\n    assert len(data.feature_names) == 8\n    assert data.DESCR.startswith(\"California housing dataset.\")\n"], "sample_732": ["def test_fetch_kddcup99_return_X_y():\n    try:\n        data = fetch_kddcup99(download_if_missing=False)\n    except IOError:\n        raise SkipTest(\"kddcup99 dataset can not be loaded.\")\n\n    X, y = fetch_kddcup99(return_X_y=True)\n    assert_equal(X.shape, (494021, 41))\n    assert_equal(y.shape, (494021,))\n    assert_equal(data.data.shape, X.shape)\n    assert_equal(data.target.shape, y.shape)\n\n    # test that return_X_y works with all subsets\n    for subset in ['SA', 'SF', 'http', 'smtp']:\n        X, y = fetch_kddcup99(subset=subset, return_X_y=True)\n        assert_equal(X.shape[0], y.shape[0])\n"], "sample_733": ["def test_countvectorizer_empty_input():\n    # Test that CountVectorizer can handle empty input\n    cv = CountVectorizer()\n    X = cv.fit_transform([])\n    assert_equal(X.shape, (0, 0))\n    assert_equal(cv.vocabulary_, {})\n    assert_equal(cv.get_feature_names(), [])\n"], "sample_734": ["def test_fowlkes_mallows_score_sparse():\n    # General case\n    score = fowlkes_mallows_score([0, 0, 0, 1, 1, 1],\n                                  [0, 0, 1, 1, 2, 2], sparse=True)\n    assert_almost_equal(score, 4. / np.sqrt(12. * 6.))\n\n    # Perfect match but where the label names changed\n    perfect_score = fowlkes_mallows_score([0, 0, 0, 1, 1, 1],\n                                          [1, 1, 1, 0, 0, 0], sparse=True)\n    assert_almost_equal(perfect_score, 1.)\n\n    # Worst case\n    worst_score = fowlkes_mallows_score([0, 0, 0, 0, 0, 0],\n                                        [0, 1, 2, 3, 4, 5], sparse=True)\n    assert_almost_equal(worst_score, 0.)\n"], "sample_736": ["def test_logistic_regressioncv_max_iter():\n    # Test that the maximum number of iteration is reached\n    X, y_bin = iris.data, iris.target.copy()\n    y_bin[y_bin == 2] = 0\n\n    solvers = ['newton-cg', 'liblinear', 'sag', 'saga', 'lbfgs']\n\n    for max_iter in range(1, 5):\n        for solver in solvers:\n            for multi_class in ['ovr', 'multinomial']:\n                if solver == 'liblinear' and multi_class == 'multinomial':\n                    continue\n                lr = LogisticRegressionCV(max_iter=max_iter, tol=1e-15,\n                                          multi_class=multi_class,\n                                          random_state=0, solver=solver)\n                assert_warns(ConvergenceWarning, lr.fit, X, y_bin)\n                assert_equal(lr.n_iter_[0][0][0], max_iter)\n"], "sample_737": ["def test_countvectorizer_empty_input():\n    # Test that CountVectorizer can handle empty input\n    cv = CountVectorizer()\n    X = cv.fit_transform([])\n    assert_equal(X.shape, (0, 0))\n    assert_equal(cv.vocabulary_, {})\n"], "sample_738": ["def test_vectorizer_input_validation():\n    # Test that invalid input types raise an error\n    message = \"Iterable over raw text documents expected, string object received.\"\n    for vec in [CountVectorizer(), TfidfVectorizer(), HashingVectorizer()]:\n        assert_raise_message(\n            ValueError, message, vec.fit_transform, 123)\n        assert_raise_message(\n            ValueError, message, vec.fit, 123)\n        assert_raise_message(\n            ValueError, message, vec.transform, 123)\n\n    # Test that empty input raises an error\n    message = \"empty vocabulary; perhaps the documents only contain stop words\"\n    for vec in [CountVectorizer(), TfidfVectorizer()]:\n        assert_raise_message(\n            ValueError, message, vec.fit_transform, [])\n        assert_raise_message(\n            ValueError, message, vec.fit, [])\n\n    # Test that None input raises an error\n    message = \"Iterable over raw text documents expected, None received.\"\n    for vec in [CountVectorizer(), TfidfVectorizer(), HashingVectorizer()]:\n        assert_raise_message(\n            ValueError, message, vec.fit_transform, None)\n        assert_raise_message(\n            ValueError, message, vec.fit, None)\n        assert_raise_message(\n            ValueError, message, vec.transform, None)\n"], "sample_739": ["def test_label_binarize_empty_input():\n    y = []\n    classes = [0, 1, 2]\n    pos_label = 1\n    neg_label = 0\n\n    lb = LabelBinarizer(neg_label=neg_label, pos_label=pos_label)\n    binarized = lb.fit_transform(y)\n    assert_array_equal(binarized, np.array([]))\n    assert_array_equal(lb.classes_, classes)\n\n    binarized = label_binarize(y, classes, neg_label=neg_label,\n                               pos_label=pos_label)\n    assert_array_equal(binarized, np.array([]))\n"], "sample_740": ["def test_check_X_y():\n    # Test that check_X_y returns the same arrays when no conversion is needed\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X, X_checked)\n    assert_array_equal(y, y_checked)\n\n    # Test that check_X_y raises an error when X and y have different lengths\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1, 2])\n    assert_raises_regex(ValueError, 'Found input variables with inconsistent'\n                        ' numbers of samples', check_X_y, X, y)\n\n    # Test that check_X_y converts a pandas DataFrame to a numpy array\n    pd = importorskip(\"pandas\")\n    X = pd.DataFrame(np.array([[1, 2], [3, 4]]))\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X.values, X_checked)\n    assert_array_equal(y, y_checked)\n\n    # Test that check_X_y converts a list to a numpy array\n    X = [[1, 2], [3, 4]]\n    y = [0, 1]\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(np.array(X), X_checked)\n    assert_array_equal(np.array(y), y_checked)\n\n    # Test that check_X_y raises an error when y is not a 1D array\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([[0, 1], [2, 3]])\n    assert_raises_regex(ValueError, 'bad input shape', check_X_y, X, y)\n\n    # Test that check_X_y raises an error when y has non-numeric values\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array(['a', 'b'])\n    assert_raises_regex(ValueError, 'Unknown label type', check_X_y, X, y)\n"], "sample_742": ["def test_logistic_regression_multiclass_predict_proba():\n    # Test that predict_proba works for multiclass classification problems\n    X, y = make_classification(n_samples=100, n_features=20, random_state=0,\n                               n_classes=3, n_informative=10)\n\n    clf_multi = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n    clf_multi.fit(X, y)\n    assert_array_almost_equal(np.sum(clf_multi.predict_proba(X), axis=1),\n                              np.ones(X.shape[0]))\n\n    clf_ovr = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\")\n    clf_ovr.fit(X, y)\n    assert_array_almost_equal(np.sum(clf_ovr.predict_proba(X), axis=1),\n                              np.ones(X.shape[0]))\n"], "sample_743": ["def test_neighbors_n_jobs():\n    # Test that the n_jobs parameter is correctly passed to the underlying\n    # BallTree or KDTree.\n    X = np.random.RandomState(0).rand(100, 5)\n    query = np.random.RandomState(0).rand(10, 5)\n\n    for algorithm in ['ball_tree', 'kd_tree']:\n        nn = neighbors.NearestNeighbors(n_neighbors=5, algorithm=algorithm,\n                                        n_jobs=4)\n        nn.fit(X)\n        dist1, ind1 = nn.kneighbors(query)\n\n        nn.set_params(n_jobs=1)\n        dist2, ind2 = nn.kneighbors(query)\n\n        assert_array_almost_equal(dist1, dist2)\n        assert_array_almost_equal(ind1, ind2)\n"], "sample_745": ["def test_function_transformer_inverse_func_kw_args():\n    X = np.array([1, 4, 9, 16]).reshape((2, 2))\n\n    # Test that inverse_func kw_args are passed correctly\n    F = FunctionTransformer(\n        func=np.sqrt,\n        inverse_func=lambda X, power: X ** power,\n        inv_kw_args=dict(power=2),\n    )\n    assert_array_equal(\n        F.inverse_transform(F.transform(X)),\n        X,\n    )\n"], "sample_750": ["def test_omp_cv_verbose():\n    y_ = y[:, 0]\n    gamma_ = gamma[:, 0]\n    ompcv = OrthogonalMatchingPursuitCV(normalize=True, fit_intercept=False,\n                                        max_iter=10, cv=5, verbose=1)\n    ompcv.fit(X, y_)\n    assert_equal(ompcv.n_nonzero_coefs_, n_nonzero_coefs)\n    assert_array_almost_equal(ompcv.coef_, gamma_)\n    omp = OrthogonalMatchingPursuit(normalize=True, fit_intercept=False,\n                                    n_nonzero_coefs=ompcv.n_nonzero_coefs_)\n    omp.fit(X, y_)\n    assert_array_almost_equal(ompcv.coef_, omp.coef_)\n"], "sample_751": ["def test_sample_weight_adaboost_classifier():\n    \"\"\"\n    AdaBoostClassifier should work without sample_weights in the base estimator\n\n    The random weighted sampling is done internally in the _boost method in\n    AdaBoostClassifier.\n    \"\"\"\n    class DummyEstimator(BaseEstimator):\n\n            pass\n\n    clf = AdaBoostClassifier(base_estimator=DummyEstimator())\n    clf.fit(X, y_class)\n"], "sample_752": ["def test_iforest_threshold_deprecation():\n    X_train = [[1, 1], [1, 2], [2, 1]]\n    clf = IsolationForest(contamination=0.1).fit(X_train)\n    with pytest.warns(DeprecationWarning):\n        threshold = clf.threshold_\n    assert threshold == clf.offset_\n"], "sample_754": ["def test_sparse_pca_verbose(norm_comp):\n    rng = np.random.RandomState(0)\n    X = rng.randn(12, 10)\n    spca = SparsePCA(n_components=8, random_state=rng, verbose=10,\n                     normalize_components=norm_comp)\n    U = spca.fit_transform(X)\n    assert_equal(spca.components_.shape, (8, 10))\n    assert_equal(U.shape, (12, 8))\n"], "sample_755": ["def test_davies_bouldin_score():\n    assert_raises_on_only_one_label(davies_bouldin_score)\n\n    assert_raises_on_all_points_same_cluster(davies_bouldin_score)\n\n    # Assert the value is 0. when all samples are equals\n    assert 0. == davies_bouldin_score(np.ones((10, 2)),\n                                      [0] * 5 + [1] * 5)\n\n    # General case (with non numpy arrays)\n    X = ([[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5 +\n         [[0, 4], [1, 3]] * 5 + [[3, 1], [4, 0]] * 5)\n    labels = [0] * 10 + [1] * 10 + [2] * 10 + [3] * 10\n    score = davies_bouldin_score(X, labels)\n    assert score >= 0.\n"], "sample_756": ["def test_optics_fit_predict():\n    # Test that fit_predict works and returns the correct labels\n\n    n_clusters = 3\n    X = generate_clustered_data(n_clusters=n_clusters)\n    clust = OPTICS(max_eps=5.0 * 6.0, min_samples=4)\n\n    # fit_predict should return the same labels as fit followed by labels_\n    labels_1 = clust.fit_predict(X)\n    clust.fit(X)\n    labels_2 = clust.labels_\n\n    assert_array_equal(labels_1, labels_2)\n"], "sample_757": ["def test_ordinal_encoder_set_params():\n    X = np.array([[1, 2]]).T\n    enc = OrdinalEncoder()\n    # set params on not yet fitted object\n    enc.set_params(categories=[[0, 1, 2, 3]])\n    assert enc.get_params()['categories'] == [[0, 1, 2, 3]]\n    assert enc.fit_transform(X).shape == (2, 1)\n    # set params on already fitted object\n    enc.set_params(categories=[[0, 1, 2, 3, 4]])\n    assert enc.fit_transform(X).shape == (2, 1)\n"], "sample_758": ["def test__num_samples():\n    # Test that _num_samples raises an error on invalid inputs.\n    assert_raises_regex(TypeError, \"Expected sequence or array-like\",\n                        _num_samples, \"not an array\")\n    assert_raises_regex(TypeError, \"Singleton array .* cannot be considered\",\n                        _num_samples, np.array(1))\n    assert_raises_regex(TypeError, \"Singleton array .* cannot be considered\",\n                        _num_samples, np.array([[[1]]]))\n    assert_raises_regex(TypeError, \"Expected sequence or array-like\",\n                        _num_samples, None)\n    assert_raises_regex(TypeError, \"Singleton array .* cannot be considered\",\n                        _num_samples, np.array([]))\n\n    # Test that _num_samples returns the correct number of samples for valid\n    # inputs.\n    assert_equal(_num_samples(np.array([1, 2, 3])), 3)\n    assert_equal(_num_samples(np.array([[1], [2], [3]])), 3)\n    assert_equal(_num_samples(np.array([[[1]], [[2]], [[3]]])), 3)\n    assert_equal(_num_samples([1, 2, 3]), 3)\n    assert_equal(_num_samples([[1], [2], [3]]), 3)\n    assert_equal(_num_samples([[1, 2], [3, 4], [5, 6]]), 3)\n"], "sample_759": ["def test_ordinal_encoder_not_fitted():\n    X = np.array([['a'], ['b']])\n    enc = OrdinalEncoder()\n    msg = (\"This OrdinalEncoder instance is not fitted yet. \"\n           \"Call 'fit' with appropriate arguments before using this method.\")\n    with pytest.raises(NotFittedError, match=msg):\n        enc.transform(X)\n"], "sample_760": ["def test_make_scorer_with_kwargs():\n    # Test that make_scorer can handle keyword arguments.\n    f = lambda y_true, y_pred, **kwargs: 0\n    scorer = make_scorer(f, greater_is_better=True, needs_proba=False,\n                         needs_threshold=False, foo='bar')\n    assert scorer._kwargs == {'foo': 'bar'}\n    assert scorer._score_func is f\n"], "sample_761": ["def test_iterative_imputer_min_value_max_value():\n    # Test that min_value and max_value are respected by IterativeImputer\n    rng = np.random.RandomState(0)\n    n = 100\n    d = 10\n    X = sparse_random_matrix(n, d, density=0.10,\n                             random_state=rng).toarray()\n\n    imputer = IterativeImputer(missing_values=0,\n                               max_iter=1,\n                               min_value=0.1,\n                               max_value=0.2,\n                               random_state=rng)\n\n    Xt = imputer.fit_transform(X)\n    assert np.min(Xt[X == 0]) >= 0.1\n    assert np.max(Xt[X == 0]) <= 0.2\n\n    # check that min_value and max_value are also respected when\n    # sample_posterior is True\n    imputer = IterativeImputer(missing_values=0,\n                               max_iter=1,\n                               sample_posterior=True,\n                               min_value=0.1,\n                               max_value=0.2,\n                               random_state=rng)\n\n    Xt = imputer.fit_transform(X)\n    assert np.min(Xt[X == 0]) >= 0.1\n    assert np.max(Xt[X == 0]) <= 0.2\n"], "sample_762": ["def test_is_regressor():\n    svc = SVC()\n    assert_false(is_regressor(svc))\n    assert is_regressor(DecisionTreeRegressor())\n    assert is_regressor(Pipeline([('reg', DecisionTreeRegressor())]))\n    assert_true(is_regressor(Pipeline(\n        [('svc_cv', GridSearchCV(DecisionTreeRegressor(), {'max_depth': [1, 2]}))])))\n"], "sample_763": ["def test__num_samples():\n    # Test that _num_samples raises an error on data with more than 2 dimensions\n    X = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n    assert_raises_regex(TypeError, \"expected sequence or array-like\", \n                        _num_samples, X)\n\n    # Test that _num_samples works correctly for numpy arrays and lists\n    X = np.array([[1, 2], [3, 4]])\n    assert_equal(_num_samples(X), 2)\n    X = [[1, 2], [3, 4]]\n    assert_equal(_num_samples(X), 2)\n\n    # Test that _num_samples works correctly for sparse matrices\n    X = sp.csr_matrix(np.array([[1, 2], [3, 4]]))\n    assert_equal(_num_samples(X), 2)\n\n    # Test that _num_samples raises an error on data with no shape attribute\n    class NoShape:\n        pass\n    X = NoShape()\n    assert_raises_regex(TypeError, \"expected sequence or array-like\", \n                        _num_samples, X)\n\n    # Test that _num_samples raises an error on data with no len\n    class NoLen:\n            self.shape = None\n    X = NoLen()\n    assert_raises_regex(TypeError, \"object of type 'NoLen' has no len()\", \n                        _num_samples, X)\n"], "sample_766": ["def test_sparse_coder_estimator_positive_code():\n    n_components = 12\n    rng = np.random.RandomState(0)\n    V = rng.randn(n_components, n_features)  # random init\n    V /= np.sum(V ** 2, axis=1)[:, np.newaxis]\n    code = SparseCoder(dictionary=V, transform_algorithm='lasso_lars',\n                       transform_alpha=0.001, positive_code=True).transform(X)\n    assert (code >= 0).all()\n"], "sample_770": ["def test_davies_bouldin_score():\n    assert_raises_on_only_one_label(davies_bouldin_score)\n\n    assert_raises_on_all_points_same_cluster(davies_bouldin_score)\n\n    # Assert the value is 0. when all samples are equals\n    assert_equal(0., davies_bouldin_score(np.ones((10, 2)),\n                                          [0] * 5 + [1] * 5))\n\n    # General case (with non numpy arrays)\n    X = ([[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5 +\n         [[0, 4], [1, 3]] * 5 + [[3, 1], [4, 0]] * 5)\n    labels = [0] * 10 + [1] * 10 + [2] * 10 + [3] * 10\n    score = davies_bouldin_score(X, labels)\n    assert_greater(score, 0.)\n    assert_less(score, 1.)\n\n    # Test with sparse input\n    X_sparse = csr_matrix(X)\n    score_sparse = davies_bouldin_score(X_sparse, labels)\n    pytest.approx(score, score_sparse)\n"], "sample_772": ["def test_n_jobs_default():\n    # Test that our default for `n_jobs` is equal to the number of cores.\n    assert_equal(RandomForestClassifier().n_jobs, None)\n    assert_equal(RandomForestRegressor().n_jobs, None)\n    assert_equal(ExtraTreesClassifier().n_jobs, None)\n    assert_equal(ExtraTreesRegressor().n_jobs, None)\n"], "sample_773": ["def test_logistic_regression_path_multinomial():\n    # Test that logistic_regression_path with multi_class='multinomial'\n    # produces the same results as LogisticRegression with the same option.\n\n    X, y = make_classification(n_samples=200, n_classes=3, n_informative=2,\n                               n_redundant=0, n_clusters_per_class=1,\n                               random_state=0, n_features=2)\n    Cs = [.00001, 1, 10000]\n    coefs, _, _ = _logistic_regression_path(X, y, penalty='l2', Cs=Cs,\n                                            solver='lbfgs', random_state=0,\n                                            multi_class='multinomial')\n\n    for i, C in enumerate(Cs):\n        lr = LogisticRegression(penalty='l2', C=C, solver='lbfgs',\n                                random_state=0, multi_class='multinomial')\n        lr.fit(X, y)\n        assert_array_almost_equal(lr.coef_, coefs[i])\n"], "sample_774": ["def test_ordinal_encoder_set_params():\n    X = np.array([['a', 'b']], dtype=object).T\n    enc = OrdinalEncoder()\n    # set params on not yet fitted object\n    enc.set_params(categories=[['a', 'b', 'c']])\n    assert enc.get_params()['categories'] == [['a', 'b', 'c']]\n    assert enc.fit_transform(X).shape == (2, 1)\n    # set params on already fitted object\n    enc.set_params(categories=[['a', 'b', 'c', 'd']])\n    assert enc.fit_transform(X).shape == (2, 1)\n"], "sample_776": ["def test_lars_path_with_positive_constraint():\n    # Test that lars_path with positive constraint returns the correct result\n\n    # Generate a random dataset\n    rng = np.random.RandomState(0)\n    X = rng.randn(100, 5)\n    y = X[:, 2] + 0.1 * rng.randn(100)\n\n    # Compute the LARS path with positive constraint\n    alphas, active, coefs = linear_model.lars_path(X, y, method='lasso',\n                                                   positive=True)\n\n    # Check that all coefficients are non-negative\n    assert np.all(coefs >= 0)\n\n    # Check that the coefficients are monotonically increasing\n    for i in range(len(alphas) - 1):\n        assert np.all(coefs[:, i] <= coefs[:, i + 1])\n"], "sample_777": ["def test_gradient_boosting_with_init_estimator_not_fitted():\n    # Check that an error is raised if trying to fit with an initial estimator\n    # that has not been fitted\n\n    X, y = make_classification()\n    init_est = DummyClassifier()\n    gb = GradientBoostingClassifier(init=init_est)\n\n    message = (\"The initial estimator must be fitted before calling fit.\")\n    with pytest.raises(ValueError, match=message):\n        gb.fit(X, y)\n"], "sample_778": ["def test_nmf_fit_transform_with_custom_init():\n    # Test that fit_transform works with custom initialization\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(6, 5))\n    n_components = 4\n    avg = np.sqrt(A.mean() / n_components)\n    H_init = np.abs(avg * rng.randn(n_components, 5))\n    W_init = np.abs(avg * rng.randn(6, n_components))\n\n    m = NMF(solver='cd', n_components=n_components, init='custom',\n            random_state=0)\n    W = m.fit_transform(A, W=W_init, H=H_init)\n    assert_array_almost_equal(W, m.transform(A), decimal=10)\n"], "sample_780": ["def test_lda_max_iter():\n    # Test that the max_iter parameter is respected\n    n_components, X = _build_sparse_mtx()\n    lda = LatentDirichletAllocation(n_components=n_components, max_iter=1,\n                                    learning_method='batch', random_state=0)\n    lda.fit(X)\n    assert_equal(lda.n_iter_, 1)\n"], "sample_781": ["def test_forest_estimators_sample_weights():\n    X, y = make_classification(n_samples=15, n_informative=3, random_state=1,\n                               n_classes=3)\n    sample_weight = np.random.rand(len(X))\n    clf = RandomForestClassifier(n_estimators=10, random_state=42)\n    clf.fit(X, y, sample_weight=sample_weight)\n\n    # Check that all estimators have the same sample weights\n    for est in clf.estimators_:\n        assert_array_equal(est.sample_weight, sample_weight)\n"], "sample_783": ["def test_missing_indicator_with_imputer_sparse():\n    X = sparse.csc_matrix(np.array([[np.nan, 1.], [1., np.nan]]))\n    trans = make_union(\n        SimpleImputer(missing_values=np.nan, strategy='most_frequent'),\n        MissingIndicator(missing_values=np.nan)\n    )\n    X_trans = trans.fit_transform(X)\n    X_trans_exp = np.array([[1., 1., True, False], [1., 1., False, True]])\n    assert_array_equal(X_trans.toarray(), X_trans_exp)\n"], "sample_784": ["def test_calibration_curve_input_validation():\n    \"\"\"Check calibration_curve input validation\"\"\"\n    y_true = np.array([0, 0, 0, 1, 1, 1])\n    y_pred = np.array([0., 0.1, 0.2, 0.8, 0.9, 1.])\n\n    # Check that y_true and y_pred have the same length\n    assert_raises(ValueError, calibration_curve, y_true[:5], y_pred)\n\n    # Check that n_bins is a positive integer\n    assert_raises(ValueError, calibration_curve, y_true, y_pred, n_bins=0)\n    assert_raises(ValueError, calibration_curve, y_true, y_pred, n_bins=-1)\n    assert_raises(ValueError, calibration_curve, y_true, y_pred, n_bins=1.5)\n\n    # Check that strategy is either 'uniform' or 'quantile'\n    assert_raises(ValueError, calibration_curve, y_true, y_pred, strategy='foo')\n"], "sample_786": ["def test_fit_transform_constant_feature():\n    X = np.array([[1, 2, 3], [1, 4, 5], [1, 6, 7]])\n    est = KBinsDiscretizer(n_bins=3, encode='ordinal')\n    Xt = est.fit_transform(X)\n    assert_array_equal(Xt[:, 0], np.zeros(X.shape[0]))\n    assert est.n_bins_[0] == 1\n    assert len(est.bin_edges_[0]) == 2\n"], "sample_788": ["def test_fit_transform_constant_feature():\n    X = np.array([[1, 2], [1, 3], [1, 4]])\n    est = KBinsDiscretizer(n_bins=3, encode='ordinal')\n    Xt = est.fit_transform(X)\n    assert_array_equal(Xt[:, 0], np.zeros(X.shape[0]))\n    assert est.n_bins_[0] == 1\n    assert len(est.bin_edges_[0]) == 2\n"], "sample_789": ["def test_adaboost_regressor_with_constant_target():\n    # Test that AdaBoostRegressor works with constant target values.\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([5, 5, 5])\n\n    reg = AdaBoostRegressor()\n    reg.fit(X, y)\n\n    assert_array_almost_equal(reg.predict(X), np.array([5, 5, 5]))\n"], "sample_790": ["def test_kernel_pca_n_jobs():\n    rng = np.random.RandomState(0)\n    X_fit = rng.random_sample((5, 4))\n    X_pred = rng.random_sample((2, 4))\n\n    for n_jobs in [1, -1]:\n        kpca = KernelPCA(n_components=2, n_jobs=n_jobs)\n        Xt = kpca.fit_transform(X_fit)\n        assert_equal(Xt.shape, (5, 2))\n\n        Xt_pred = kpca.transform(X_pred)\n        assert_equal(Xt_pred.shape, (2, 2))\n"], "sample_791": ["def test_ordinal_encoder_dtype():\n    X = [['abc', 2, 55], ['def', 1, 55]]\n    enc = OrdinalEncoder(dtype=np.int32)\n    X_tr = enc.fit_transform(X)\n    assert X_tr.dtype == np.int32\n\n    enc = OrdinalEncoder(dtype=np.float64)\n    X_tr = enc.fit_transform(X)\n    assert X_tr.dtype == np.float64\n\n    enc = OrdinalEncoder(dtype='int64')\n    X_tr = enc.fit_transform(X)\n    assert X_tr.dtype == np.int64\n"], "sample_793": ["def test_iforest_fit_predict():\n    X_train = [[1, 1], [1, 2], [2, 1]]\n    clf = IsolationForest(contamination=0.1)\n    assert clf.estimators_ is None\n    assert clf.estimators_features_ is None\n    assert clf.max_samples_ is None\n    clf.fit(X_train)\n    assert clf.estimators_ is not None\n    assert clf.estimators_features_ is not None\n    assert clf.max_samples_ is not None\n    y_pred = clf.predict([[2., 2.]])\n    assert_array_equal(y_pred, [-1])\n"], "sample_794": ["def test_ridgecv_with_scoring():\n    # Test that RidgeCV works with a custom scoring function.\n    X, y = make_regression(n_samples=100, n_features=10, random_state=0)\n    scoring = make_scorer(mean_squared_error, greater_is_better=False)\n    ridgecv = RidgeCV(scoring=scoring)\n    ridgecv.fit(X, y)\n    assert hasattr(ridgecv, 'best_score_')\n    assert hasattr(ridgecv, 'alpha_')\n"], "sample_795": ["def test_check_class_weight_balanced_linear_classifier():\n    # check that the estimator can handle class_weight='balanced' for\n    # linear classifiers.\n    X = np.array([[-1.0, -1.0], [-1.0, 0], [-.8, -1.0],\n                  [1.0, 1.0], [1.0, 0.0]])\n    y = np.array([1, 1, 1, -1, -1])\n\n    check_class_weight_balanced_linear_classifier(\"test\", SVC)\n"], "sample_796": ["def test_huber_raise_error_for_invalid_epsilon():\n    X, y = make_regression_with_outliers()\n    huber = HuberRegressor(fit_intercept=True, epsilon=0.5)\n    with pytest.raises(ValueError):\n        huber.fit(X, y)\n"], "sample_798": ["def test_ridgecv_scorer():\n    # Test that RidgeCV works with a custom scorer.\n    X, y = make_regression(n_samples=10, n_features=5, random_state=0)\n    scorer = make_scorer(mean_squared_error, greater_is_better=False)\n    ridgecv = RidgeCV(scorer=scorer)\n    ridgecv.fit(X, y)\n    assert hasattr(ridgecv, 'best_score_')\n"], "sample_802": ["def test_pipeline_memory_fit_params():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        if LooseVersion(joblib_version) < LooseVersion('0.12'):\n            # Deal with change of API in joblib\n            memory = Memory(cachedir=cachedir, verbose=10)\n        else:\n            memory = Memory(location=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(gamma='scale', probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', clone(transf)), ('svc', clf)])\n        cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n                               memory=memory)\n\n        # Memoize the transformer at the first fit\n        cached_pipe.fit(X, y)\n        pipe.fit(X, y)\n        # Get the time stamp of the transformer in the cached pipeline\n        ts = cached_pipe.named_steps['transf'].timestamp_\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert not hasattr(transf, 'means_')\n        # Check that we are reading the cache while fitting\n        # a second time with different fit params\n        cached_pipe.fit(X, y, svc__probability=False)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert_equal(ts, cached_pipe.named_steps['transf'].timestamp_)\n    finally:\n        shutil.rmtree(cachedir)\n"], "sample_803": ["def test_roc_auc_score_partial():\n    # Test whether the roc_auc_score function returns the correct scores\n    # for partial AUC computation.\n    y_true = np.array([0, 1, 1, 0, 1])\n    y_pred = np.array([0.1, 0.4, 0.35, 0.8, 0.9])\n\n    # Compute full ROC AUC\n    full_auc = roc_auc_score(y_true, y_pred)\n\n    # Compute partial ROC AUC with max_fpr=1.0 (should be equal to full ROC AUC)\n    partial_auc_1 = roc_auc_score(y_true, y_pred, max_fpr=1.0)\n    assert_almost_equal(full_auc, partial_auc_1)\n\n    # Compute partial ROC AUC with max_fpr=0.5\n    partial_auc_05 = roc_auc_score(y_true, y_pred, max_fpr=0.5)\n    assert_greater(full_auc, partial_auc_05)\n\n    # Compute partial ROC AUC with max_fpr=0.0 (should be very close to 0)\n    partial_auc_0 = roc_auc_score(y_true, y_pred, max_fpr=0.0)\n    assert_almost_equal(partial_auc_0, 0.0, decimal=2)\n\n    # Check for invalid max_fpr values\n    assert_raises(ValueError, roc_auc_score, y_true, y_pred, max_fpr=-0.1)\n    assert_raises(ValueError, roc_auc_score, y_true, y_pred, max_fpr=1.1)\n"], "sample_804": ["def test_ordinal_encoder_dtype():\n    X = [['abc', 2, 55], ['def', 1, 55]]\n    enc = OrdinalEncoder(dtype='int32')\n    X_tr = enc.fit_transform(X)\n    assert X_tr.dtype == 'int32'\n    assert_array_equal(enc.inverse_transform(X_tr), np.array(X, dtype=object))\n\n    X = [[1, 2], [3, 4]]\n    enc = OrdinalEncoder(dtype='float64')\n    X_tr = enc.fit_transform(X)\n    assert X_tr.dtype == 'float64'\n    assert_array_equal(enc.inverse_transform(X_tr), np.array(X, dtype='int64'))\n"], "sample_805": ["def test_regression_metrics_with_sample_weight():\n    y_true = np.array([1, 2, 3, 4])\n    y_pred = np.array([1, 3, 3, 4])\n    sample_weight = np.array([0.5, 1, 1, 0.5])\n\n    mse = mean_squared_error(y_true, y_pred, sample_weight=sample_weight)\n    mae = mean_absolute_error(y_true, y_pred, sample_weight=sample_weight)\n    r2 = r2_score(y_true, y_pred, sample_weight=sample_weight)\n\n    assert_almost_equal(mse, 0.375)\n    assert_almost_equal(mae, 0.5)\n    assert_almost_equal(r2, 0.875)\n"], "sample_806": ["def test_gradient_boosting_with_init_estimator_not_fitted():\n    # Check that an error is raised if trying to fit with an initial estimator\n    # that has not been fitted\n\n    X, y = make_classification()\n    init_est = DummyClassifier()\n    gb = GradientBoostingClassifier(init=init_est)\n\n    message = (\"The initial estimator DummyClassifier has not been fitted. \"\n               \"Fit the estimator and then set it as the init estimator.\")\n    with pytest.raises(ValueError, match=message):\n        gb.fit(X, y)\n"], "sample_807": ["def test_calibration_curve_fewer_bins_than_unique_values():\n    \"\"\"Check calibration_curve function when n_bins is less than the number of unique values in y_pred\"\"\"\n    y_true = np.array([0, 0, 0, 1, 1, 1])\n    y_pred = np.array([0., 0.1, 0.2, 0.8, 0.9, 1.])\n    prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=3)\n    assert_equal(len(prob_true), len(prob_pred))\n    assert_equal(len(prob_true), 3)\n    assert_almost_equal(prob_true[0], 0)\n    assert_almost_equal(prob_true[-1], 1)\n    assert_almost_equal(prob_pred[0], 0.1)\n    assert_almost_equal(prob_pred[-1], 0.9)\n"], "sample_808": ["def test_iforest_fit_predict():\n    \"\"\"Test fit_predict method of IsolationForest.\"\"\"\n    X_train = np.array([[0, 1], [1, 2]])\n    X_test = np.array([[2, 1], [1, 1]])\n\n    clf = IsolationForest(random_state=rng)\n    y_pred = clf.fit_predict(X_train)\n\n    assert_array_equal(y_pred, clf.predict(X_train))\n\n    y_pred_test = clf.predict(X_test)\n    assert_array_equal(y_pred_test, clf.fit_predict(X_test))\n"], "sample_809": ["def test_mutual_info_regression_sparse():\n    # Test that mutual_info_regression works with sparse matrices.\n    rng = check_random_state(0)\n    X = csr_matrix(rng.rand(100, 5))\n    y = rng.rand(100)\n\n    mi = mutual_info_regression(X, y, random_state=0)\n    assert_array_equal(mi.shape, (X.shape[1],))\n"], "sample_810": ["def test_pipeline_get_params():\n    # Test that get_params returns all parameters of the estimators\n    mult2 = Mult(mult=2)\n    mult3 = Mult(mult=3)\n    pipeline = Pipeline([('m1', mult2), ('m2', mult3)])\n\n    params = pipeline.get_params()\n    assert 'm1' in params\n    assert 'm2' in params\n    assert 'm1__mult' in params\n    assert 'm2__mult' in params\n\n    # Check that parameter values are correct\n    assert params['m1'] is mult2\n    assert params['m2'] is mult3\n    assert params['m1__mult'] == 2\n    assert params['m2__mult'] == 3\n"], "sample_813": ["def test_bayesian_ridge_intercept():\n    # Test BayesianRidge with and without intercept\n    X = np.array([[1], [2], [6], [8], [10]])\n    Y = np.array([1, 2, 6, 8, 10])\n    clf_with_intercept = BayesianRidge(fit_intercept=True)\n    clf_without_intercept = BayesianRidge(fit_intercept=False)\n\n    clf_with_intercept.fit(X, Y)\n    clf_without_intercept.fit(X, Y)\n\n    assert clf_with_intercept.intercept_ != 0\n    assert clf_without_intercept.intercept_ == 0\n\n    # Check that the model could approximately learn the identity function\n    test = [[1], [3], [4]]\n    assert_array_almost_equal(clf_with_intercept.predict(test), [1, 3, 4], 2)\n    assert_array_almost_equal(clf_without_intercept.predict(test), [1, 3, 4], 2)\n"], "sample_815": ["def test_balanced_accuracy_score_binary():\n    y_true = [0, 1, 0, 0, 1, 0, 1, 1]\n    y_pred = [0, 1, 0, 0, 0, 1, 1, 1]\n\n    # Calculate balanced accuracy manually\n    recall_0 = 3 / 4\n    recall_1 = 3 / 4\n    balanced_accuracy_manual = (recall_0 + recall_1) / 2\n\n    # Calculate balanced accuracy using the function\n    balanced_accuracy_function = balanced_accuracy_score(y_true, y_pred)\n\n    assert_almost_equal(balanced_accuracy_manual, balanced_accuracy_function)\n"], "sample_816": ["def test_vectorizer_build_preprocessor_deprecation():\n    vectorizer = CountVectorizer()\n    preprocessor = vectorizer.build_preprocessor()\n    with pytest.warns(FutureWarning, match=\"The 'build_preprocessor' method\"):\n        preprocessor(\"This is a test sentence.\")\n"], "sample_817": ["def test_variance_threshold_sparse():\n    # Test VarianceThreshold with sparse matrix and custom variance.\n    X = csr_matrix([[0, 1, 2, 3], [0, 2, 2, 3]])\n    sel = VarianceThreshold(threshold=.4)\n    X_trans = sel.fit_transform(X)\n    assert_equal((2, 1), X_trans.shape)\n    assert_array_equal([3], sel.get_support(indices=True))\n"], "sample_819": ["def test_voting_regressor_get_params():\n    \"\"\"Check get_params method of VotingRegressor.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor()\n    ereg = VotingRegressor(estimators=[('lr', reg1), ('rf', reg2)])\n    params = ereg.get_params()\n    assert 'estimators' in params\n    assert 'lr' in params\n    assert 'rf' in params\n    assert params['lr'] is reg1\n    assert params['rf'] is reg2\n    assert params['lr__n_jobs'] is None\n    assert params['rf__n_estimators'] == 100\n"], "sample_820": ["def test_voting_regressor_get_params():\n    \"\"\"Check get_params method of VotingRegressor.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor()\n    ereg = VotingRegressor(estimators=[('lr', reg1), ('rf', reg2)])\n    params = ereg.get_params()\n    assert 'estimators' in params\n    assert 'lr' in params\n    assert 'rf' in params\n    assert params['lr'] is reg1\n    assert params['rf'] is reg2\n    assert params['lr__n_jobs'] is None\n    assert params['rf__n_estimators'] == 100\n"], "sample_821": ["def test_affinity_propagation_sparse_input():\n    # Test that AffinityPropagation accepts sparse input when affinity is\n    # 'precomputed'\n    S = csr_matrix(np.dot(X, X.T))\n    af = AffinityPropagation(affinity='precomputed')\n    labels_sparse = af.fit(S).labels_\n    af = AffinityPropagation(affinity='euclidean')\n    labels_dense = af.fit(X).labels_\n    assert_array_equal(labels_sparse, labels_dense)\n"], "sample_825": ["def test_pls_predict_shape():\n    d = load_linnerud()\n    X = d.data\n    Y = d.target\n    for clf in [pls_.PLSCanonical(), pls_.PLSRegression(),\n                pls_.PLSSVD()]:\n        clf.fit(X, Y)\n        y_pred = clf.predict(X)\n        assert_equal(y_pred.shape, Y.shape)\n"], "sample_826": ["def test_ordinal_encoder_set_params():\n    X = np.array([['a', 'b']], dtype=object).T\n\n    enc = OrdinalEncoder()\n    exp = np.array([[0.], [1.]])\n    assert_array_equal(enc.fit_transform(X), exp)\n\n    # set params on not yet fitted object\n    enc.set_params(categories=[[0, 1, 2, 3]])\n    assert enc.get_params()['categories'] == [[0, 1, 2, 3]]\n    assert_array_equal(enc.fit_transform(np.array([[1, 2]]).T), np.array([[0.], [1.]]))\n\n    # set params on already fitted object\n    enc.set_params(categories=[[0, 1, 2, 3, 4]])\n    assert_array_equal(enc.fit_transform(np.array([[1, 2]]).T), np.array([[0.], [1.]]))\n"], "sample_827": ["def test_csc_median_axis_0_empty():\n    # Test csc_median_axis_0 on an empty matrix.\n    X = sp.csc_matrix((0, 5))\n    median = csc_median_axis_0(X)\n    assert_array_equal(median, np.full(5, np.nan))\n"], "sample_829": ["def test_incremental_pca_sparse_batch_size():\n    # Test that IncrementalPCA works with sparse input and batch_size.\n    X = iris.data\n    pca = PCA(n_components=2)\n    pca.fit_transform(X)\n    X_sparse = sparse.csr_matrix(X)\n    batch_size = X_sparse.shape[0] // 3\n    ipca = IncrementalPCA(n_components=2, batch_size=batch_size)\n\n    X_transformed = ipca.fit_transform(X_sparse)\n\n    assert X_transformed.shape == (X_sparse.shape[0], 2)\n    np.testing.assert_allclose(ipca.explained_variance_ratio_.sum(),\n                               pca.explained_variance_ratio_.sum(), rtol=1e-3)\n\n    for n_components in [1, 2, X.shape[1]]:\n        ipca = IncrementalPCA(n_components, batch_size=batch_size)\n        ipca.fit(X_sparse)\n        cov = ipca.get_covariance()\n        precision = ipca.get_precision()\n        np.testing.assert_allclose(np.dot(cov, precision),\n                                   np.eye(X_sparse.shape[1]), atol=1e-13)\n"], "sample_830": ["def test_get_blas_info():\n    blas_info = _get_blas_info()\n\n    assert 'macros' in blas_info\n    assert 'lib_dirs' in blas_info\n    assert 'cblas_libs' in blas_info\n"], "sample_831": ["def test_plot_tree_invalid_input(pyplot):\n    clf = DecisionTreeClassifier(max_depth=3,\n                                 min_samples_split=2,\n                                 criterion=\"gini\",\n                                 random_state=2)\n    clf.fit(X, y)\n\n    # Test invalid input for ax parameter\n    assert_raises(TypeError, plot_tree, clf, ax='invalid')\n\n    # Test invalid input for fontsize parameter\n    assert_raises(ValueError, plot_tree, clf, fontsize=-1)\n\n    # Test invalid input for precision parameter\n    assert_raises(ValueError, plot_tree, clf, precision=-1)\n    assert_raises(ValueError, plot_tree, clf, precision='invalid')\n"], "sample_832": ["def test_bayesian_ridge_intercept():\n    # Test BayesianRidge with and without intercept\n    X = np.array([[1], [2], [6], [8], [10]])\n    Y = np.array([1, 2, 6, 8, 10])\n    clf_with_intercept = BayesianRidge(fit_intercept=True)\n    clf_without_intercept = BayesianRidge(fit_intercept=False)\n\n    clf_with_intercept.fit(X, Y)\n    clf_without_intercept.fit(X, Y)\n\n    assert clf_with_intercept.intercept_ != 0\n    assert clf_without_intercept.intercept_ == 0\n\n    # Check that the model could approximately learn the identity function\n    test = [[1], [3], [4]]\n    assert_array_almost_equal(clf_with_intercept.predict(test), [1, 3, 4], 2)\n    assert_array_almost_equal(clf_without_intercept.predict(test), [1, 3, 4], 2)\n"], "sample_833": ["def test_logistic_regression_path_multiclass():\n    # Test that logistic_regression_path returns the correct coefs for\n    # multiclass problems.\n    X, y = make_classification(n_samples=200, n_classes=3, n_informative=2,\n                               n_redundant=0, n_clusters_per_class=1,\n                               random_state=0, n_features=2)\n    Cs = [.00001, 1, 10000]\n    coefs, _, _ = _logistic_regression_path(X, y, penalty='l2', Cs=Cs,\n                                            solver='lbfgs', random_state=0,\n                                            multi_class='multinomial')\n    assert coefs.shape == (3, len(Cs), X.shape[1])\n"], "sample_834": ["def test_components_shape():\n    \"\"\"Test that the learned components have the expected shape.\"\"\"\n    X = iris_data\n    y = iris_target\n\n    nca = NeighborhoodComponentsAnalysis(n_components=2)\n    nca.fit(X, y)\n    assert nca.components_.shape == (2, X.shape[1])\n"], "sample_835": ["def test_adaboost_regressor_with_constant_target():\n    \"\"\"\n    Check that AdaBoostRegressor works with constant target.\n    \"\"\"\n    X = np.random.randn(50, 3)\n    y = np.ones(50)\n\n    boost = AdaBoostRegressor(n_estimators=5)\n    boost.fit(X, y)\n    assert_array_almost_equal(boost.predict(X), y)\n"], "sample_836": ["def test_ovr_decision_function():\n    predictions = np.array([[0, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.2, 0.8, 0.4], [0.7, 0.3, 0.9]])\n    n_classes = 3\n\n    decision = _ovr_decision_function(predictions, confidences, n_classes)\n    assert decision.shape == (2, 3)\n\n    # Check that the confidences are monotonically transformed\n    for i in range(2):\n        for j in range(3):\n            if predictions[i, j] == 1:\n                assert decision[i, j] > 0\n            else:\n                assert decision[i, j] < 0\n"], "sample_837": ["def test_get_blas_info():\n    blas_info = _get_blas_info()\n\n    assert 'macros' in blas_info\n    assert 'lib_dirs' in blas_info\n    assert 'cblas_libs' in blas_info\n"], "sample_839": ["def test_vectorizer_stop_words_custom_tokenizer():\n    # Test that custom tokenizers are handled correctly when checking for\n    # inconsistent stop words.\n\n    class CustomTokenizer:\n            return re.findall(r'\\w+', doc)\n\n    message = (\"Your stop_words may be inconsistent with your \"\n               \"preprocessing. Tokenizing the stop words generated \"\n               \"tokens %r not in stop_words.\" % ['and'])\n    vec = CountVectorizer(tokenizer=CustomTokenizer(), stop_words=['AND'])\n    assert_warns_message(UserWarning, message, vec.fit_transform,\n                         ['hello world'])\n"], "sample_840": ["def test_pls_transform_predict_shape():\n    # Check shape of transform and predict output\n    d = load_linnerud()\n    X = d.data\n    Y = d.target\n    for clf in [pls_.PLSCanonical(), pls_.PLSRegression(),\n                pls_.PLSSVD()]:\n        clf.fit(X, Y)\n        X_trans = clf.transform(X)\n        assert X_trans.shape == (X.shape[0], clf.n_components)\n        X_pred = clf.predict(X)\n        assert X_pred.shape == (X.shape[0], Y.shape[1])\n        X_trans, Y_trans = clf.transform(X, Y)\n        assert X_trans.shape == (X.shape[0], clf.n_components)\n        assert Y_trans.shape == (Y.shape[0], clf.n_components)\n"], "sample_841": ["def test_ridgecv_scorer():\n    # Test that RidgeCV can be used with a scorer and that the scorer is used.\n    X, y = make_regression(n_samples=10, n_features=5)\n    scorer = get_scorer('neg_mean_squared_error')\n    ridgecv = RidgeCV(scorer=scorer)\n    ridgecv.fit(X, y)\n    assert hasattr(ridgecv, 'best_score_')\n    assert ridgecv.best_score_ == ridgecv.score(X, y)\n"], "sample_842": ["def test_kernel_str(kernel):\n    # Smoke-test for str in kernels.\n\n    str(kernel)\n"], "sample_843": ["def test_kernel_operator_composition():\n    # Test that kernel operators can be composed.\n    kernel1 = RBF(length_scale=2.0)\n    kernel2 = ConstantKernel(constant_value=3.0)\n    kernel3 = WhiteKernel(noise_level=4.0)\n\n    kernel_composed = (kernel1 + kernel2) * kernel3\n\n    assert isinstance(kernel_composed, Product)\n    assert isinstance(kernel_composed.k1, Sum)\n    assert isinstance(kernel_composed.k2, WhiteKernel)\n\n    K_composed = kernel_composed(X)\n    K_expected = (kernel1(X) + kernel2(X)) * kernel3(X)\n\n    assert_almost_equal(K_composed, K_expected)\n"], "sample_845": ["def test_countvectorizer_dtype():\n    # Test that the dtype parameter is taken into account\n    X = [\"This is a sample document.\", \"Another document for testing.\"]\n    vectorizer = CountVectorizer(dtype=np.float32)\n    X_counted = vectorizer.fit_transform(X)\n    assert X_counted.dtype == np.float32\n\n    # Test that the dtype parameter is propagated to the transform method\n    X_new = [\"A new document for testing.\"]\n    X_new_counted = vectorizer.transform(X_new)\n    assert X_new_counted.dtype == np.float32\n"], "sample_847": ["def test_lassoCV_sparse_input_dtype():\n    X, y, _, _ = build_dataset(n_features=10)\n    clf = LassoCV(n_alphas=5)\n    clf.fit(sparse.csr_matrix(X), y)\n    clf1 = LassoCV(n_alphas=5)\n    clf1.fit(sparse.csr_matrix(X, dtype=np.float32), y)\n    assert_almost_equal(clf.alpha_, clf1.alpha_, decimal=6)\n    assert_almost_equal(clf.coef_, clf1.coef_, decimal=6)\n"], "sample_848": ["def test_multi_output_regressor_sample_weights_with_sparse_data():\n    # weighted regressor with sparse data\n    Xw = sp.csr_matrix([[1, 2, 3], [4, 5, 6]])\n    yw = [[3.141, 2.718], [2.718, 3.141]]\n    w = np.asarray([2., 1.])\n    rgr_w = MultiOutputRegressor(GradientBoostingRegressor(random_state=0))\n    rgr_w.fit(Xw, yw, w)\n\n    # unweighted, but with repeated samples\n    X = sp.csr_matrix([[1, 2, 3], [1, 2, 3], [4, 5, 6]])\n    y = [[3.141, 2.718], [3.141, 2.718], [2.718, 3.141]]\n    rgr = MultiOutputRegressor(GradientBoostingRegressor(random_state=0))\n    rgr.fit(X, y)\n\n    X_test = sp.csr_matrix([[1.5, 2.5, 3.5], [3.5, 4.5, 5.5]])\n    assert_almost_equal(rgr.predict(X_test), rgr_w.predict(X_test))\n"], "sample_850": ["def test_nystroem_sparse_input():\n    # Test Nystroem on sparse input.\n    rnd = np.random.RandomState(42)\n    n_samples = 10\n    X = csr_matrix(rnd.uniform(size=(n_samples, 4)))\n\n    nystroem = Nystroem(n_components=5)\n    X_transformed = nystroem.fit_transform(X)\n\n    assert X_transformed.shape == (n_samples, 5)\n"], "sample_851": ["def test_mean_tweedie_deviance_sample_weight():\n    y_true = [1, 2, 3]\n    y_pred = [1.1, 1.9, 3.2]\n    sample_weight = [0.5, 1.0, 0.5]\n\n    # Test with power=0 (same as mean squared error)\n    score = mean_tweedie_deviance(y_true, y_pred, sample_weight=sample_weight,\n                                  power=0)\n    assert_almost_equal(score, mean_squared_error(y_true, y_pred,\n                                                  sample_weight=sample_weight))\n\n    # Test with power=1 (same as mean Poisson deviance)\n    score = mean_tweedie_deviance(y_true, y_pred, sample_weight=sample_weight,\n                                  power=1)\n    assert_almost_equal(score, mean_poisson_deviance(y_true, y_pred,\n                                                    sample_weight=sample_weight))\n\n    # Test with power=2 (same as mean Gamma deviance)\n    score = mean_tweedie_deviance(y_true, y_pred, sample_weight=sample_weight,\n                                  power=2)\n    assert_almost_equal(score, mean_gamma_deviance(y_true, y_pred,\n                                                  sample_weight=sample_weight))\n"], "sample_853": ["def test_transform_target_regressor_pipeline():\n    # check that the TransformedTargetRegressor can be used in a pipeline\n    X, y = friedman\n    regr = Pipeline([\n        ('transformer', StandardScaler()),\n        ('regressor', TransformedTargetRegressor(regressor=LinearRegression(),\n                                                 func=np.log, inverse_func=np.exp))\n    ])\n    regr.fit(X, y)\n    y_pred = regr.predict(X)\n    assert y.shape == y_pred.shape\n    assert_allclose(y_pred, np.exp(regr.named_steps['regressor'].regressor_.predict(\n        regr.named_steps['transformer'].transform(X))))\n"], "sample_854": ["def test_libsvm_sparse_predict():\n    # Test that sparse predict works as expected.\n    X_train = sparse.csr_matrix(np.array([[0, 1], [1, 0]]))\n    y_train = np.array([0, 1])\n    clf = svm.SVC(kernel='linear').fit(X_train, y_train)\n    X_test = sparse.csr_matrix(np.array([[1, 1]]))\n    assert_array_equal(clf.predict(X_test), np.array([0]))\n"], "sample_855": ["def test_dummy_classifier_predict_log_proba():\n    X = [[0]] * 5  # ignored\n    y = [1, 2, 1, 1, 2]\n    clf = DummyClassifier(strategy=\"prior\", random_state=0)\n    clf.fit(X, y)\n\n    log_proba = clf.predict_log_proba(X)\n    assert_array_almost_equal(np.log(clf.predict_proba(X)), log_proba)\n"], "sample_857": ["def test_prune_tree_ccp_alpha_not_affecting_fitting():\n    # ccp_alpha should not affect the structure of the tree before pruning.\n    X, y = iris.data, iris.target\n\n    clf1 = DecisionTreeClassifier(random_state=0)\n    clf1.fit(X, y)\n\n    clf2 = DecisionTreeClassifier(random_state=0, ccp_alpha=10)\n    clf2.fit(X, y)\n\n    # The trees should be identical before pruning\n    assert_tree_equal(clf1.tree_, clf2.tree_)\n"], "sample_858": ["def test_voting_regressor_transform():\n    \"\"\"Check transform method of VotingRegressor on toy dataset.\"\"\"\n    reg1 = LinearRegression()\n    reg2 = RandomForestRegressor(random_state=123)\n    X = np.array([[-1.1, -1.5], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n    y = np.array([1, 1, 2, 2])\n\n    ereg1 = VotingRegressor(estimators=[\n        ('lr', reg1), ('rf', reg2)]).fit(X, y)\n\n    assert_array_equal(ereg1.transform(X).shape, (4, 2))\n    assert_array_almost_equal(ereg1.transform(X),\n                              np.column_stack((reg1.fit(X, y).predict(X),\n                                               reg2.fit(X, y).predict(X))))\n"], "sample_861": ["def test_grid_search_cv_results_rank_tie_breaking_with_refit_callable():\n    X, y = make_blobs(n_samples=50, random_state=42)\n\n    # The two C values are close enough to give similar models\n    # which would result in a tie of their mean cv-scores\n    param_grid = {'C': [1, 1.001, 0.001]}\n\n        return cv_results['mean_test_score'].argmin()\n\n    grid_search = GridSearchCV(SVC(), param_grid=param_grid,\n                               return_train_score=True, refit=refit_callable)\n    grid_search.fit(X, y)\n    cv_results = grid_search.cv_results_\n    # Check tie breaking strategy -\n    # Check that there is a tie in the mean scores between\n    # candidates 1 and 2 alone\n    assert_almost_equal(cv_results['mean_test_score'][0],\n                        cv_results['mean_test_score'][1])\n    assert_almost_equal(cv_results['mean_train_score'][0],\n                        cv_results['mean_train_score'][1])\n    assert not np.allclose(cv_results['mean_test_score'][1],\n                           cv_results['mean_test_score'][2])\n    assert not np.allclose(cv_results['mean_train_score'][1],\n                           cv_results['mean_train_score'][2])\n    # 'min' rank should be assigned to the tied candidates\n    assert_almost_equal(grid_search.cv_results_['rank_test_score'], [1, 1, 3])\n"], "sample_862": ["def test_tfidfvectorizer_dtype():\n    # Test that the dtype parameter is correctly propagated to the underlying\n    # transformer\n    vect = TfidfVectorizer(dtype=np.float32)\n    X = vect.fit_transform(JUNK_FOOD_DOCS)\n    assert X.dtype == np.float32\n    assert vect._tfidf.dtype == np.float32\n"], "sample_864": ["def test_mean_shift_max_iter():\n    # Test MeanShift algorithm with max_iter parameter\n    ms = MeanShift(bandwidth=1.2, max_iter=10)\n    labels = ms.fit(X).labels_\n    assert ms.n_iter_ <= 10\n"], "sample_865": ["def test_prune_tree_ccp_alpha_not_affecting_fitting():\n    # ccp_alpha should not affect the initial tree construction, only pruning\n    X = iris.data\n    y = iris.target\n\n    clf1 = DecisionTreeClassifier(random_state=0)\n    clf1.fit(X, y)\n\n    clf2 = DecisionTreeClassifier(random_state=0, ccp_alpha=10)\n    clf2.fit(X, y)\n\n    # before pruning, trees are identical\n    assert_tree_equal(clf1.tree_, clf2.tree_)\n\n    # after pruning, trees can be different\n    clf2._prune_tree()\n    assert clf1.tree_.node_count != clf2.tree_.node_count\n"], "sample_866": ["def test_affinity_propagation_sparse_input():\n    # Test AffinityPropagation with sparse input\n    X_sparse = csr_matrix(X)\n    af = AffinityPropagation(affinity=\"euclidean\")\n    labels_sparse = af.fit_predict(X_sparse)\n    af_dense = AffinityPropagation(affinity=\"euclidean\")\n    labels_dense = af_dense.fit_predict(X)\n    assert_array_equal(labels_sparse, labels_dense)\n"], "sample_867": ["def test_search_cv__estimator_type_property_delegated_to_base_estimator():\n    \"\"\"\n    Test implementation of BaseSearchCV has the _estimator_type property\n    which matches the _estimator_type property of its estimator.\n    This test make sure _estimator_type is delegated to the base estimator.\n\n    Non-regression test for issue #13920.\n    \"\"\"\n    est = BaseEstimator()\n    attr_message = \"BaseSearchCV _estimator_type property must match estimator\"\n\n    for _estimator_type_setting in ['classifier', 'regressor']:\n        setattr(est, '_estimator_type', _estimator_type_setting)\n        cv = GridSearchCV(est, {'n_neighbors': [10]})\n        assert _estimator_type_setting == cv._estimator_type, attr_message\n"], "sample_870": ["def test_kernel_diag_method_does_not_mutate_input():\n    \"\"\"Check that the diag method of a kernel does not mutate the input.\"\"\"\n    X = np.array([[1, 2], [3, 4]])\n    kernel = CustomKernel()\n    kernel.diag(X)\n    assert_array_almost_equal(X, np.array([[1, 2], [3, 4]]))\n"], "sample_871": ["def test_calinski_harabasz_score_sparse_input():\n    # Assert the function works with sparse input\n    from scipy.sparse import csr_matrix\n\n    X = csr_matrix(np.array([[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5))\n    labels = [0] * 10 + [1] * 10\n    score_dense = calinski_harabasz_score(X.toarray(), labels)\n    score_sparse = calinski_harabasz_score(X, labels)\n    pytest.approx(score_dense, score_sparse)\n"], "sample_872": ["def test_top_k_accuracy_score_binary_average_parameter():\n    # Test that the average parameter is ignored for binary classification.\n    y_true = [0, 1, 0, 1]\n    y_score = np.array([[0.2, 0.8], [0.7, 0.3], [0.4, 0.6], [0.9, 0.1]])\n\n    score_macro = top_k_accuracy_score(y_true, y_score, k=1, average=\"macro\")\n    score_weighted = top_k_accuracy_score(y_true, y_score, k=1, average=\"weighted\")\n    score_none = top_k_accuracy_score(y_true, y_score, k=1, average=None)\n\n    assert score_macro == pytest.approx(score_weighted)\n    assert score_macro == pytest.approx(score_none)\n"], "sample_873": ["def test_get_support_empty():\n    sel = StepSelector(step=0)\n    sel.fit(X, y)\n    assert_array_equal(np.zeros(X.shape[1], dtype='bool), sel.get_support())\n    assert_array_equal([], sel.get_support(indices=True))\n"], "sample_876": ["def test_mlp_n_iter_no_change_with_early_stopping():\n    \"\"\"Check that n_iter_no_change works with early stopping.\"\"\"\n    mlp = MLPClassifier(\n        max_iter=1000, random_state=0, early_stopping=True, n_iter_no_change=5\n    )\n    mlp.fit(X_iris, y_iris)\n    assert mlp.n_iter_ < mlp.max_iter\n    assert len(mlp.validation_scores_) == mlp.n_iter_ // 10 + 1\n"], "sample_877": ["def test_isotonic_regression_get_params():\n    \"\"\"Check `get_params` for `IsotonicRegression`.\"\"\"\n    iso = IsotonicRegression(y_min=0.0, y_max=1.0, increasing=True, out_of_bounds=\"clip\")\n    params = iso.get_params()\n    assert params == {\n        \"y_min\": 0.0,\n        \"y_max\": 1.0,\n        \"increasing\": True,\n        \"out_of_bounds\": \"clip\",\n    }\n"], "sample_879": ["def test_one_hot_encoder_feature_names_out_with_infrequent():\n    \"\"\"Check get_feature_names_out with infrequent categories.\"\"\"\n    X = np.array([[\"a\"] * 5 + [\"b\"] * 20 + [\"c\"] * 10 + [\"d\"] * 3]).T\n    ohe = OneHotEncoder(max_categories=2, sparse_output=False).fit(X)\n\n    feature_names = ohe.get_feature_names_out()\n    assert_array_equal([\"x0_b\", \"x0_infrequent_sklearn\"], feature_names)\n"], "sample_881": ["def test_top_k_accuracy_score_binary_average_parameter():\n    # Test that the average parameter is ignored for binary classification.\n    y_true = [0, 1, 1, 0]\n    y_score = np.array([0.2, 0.8, 0.7, 0.3])\n\n    score_macro = top_k_accuracy_score(y_true, y_score, k=1, average=\"macro\")\n    score_micro = top_k_accuracy_score(y_true, y_score, k=1, average=\"micro\")\n    score_samples = top_k_accuracy_score(y_true, y_score, k=1, average=\"samples\")\n    score_weighted = top_k_accuracy_score(y_true, y_score, k=1, average=\"weighted\")\n\n    assert score_macro == score_micro == score_samples == score_weighted\n"], "sample_882": ["def test_mlp_classifier_predict_proba_output_shape():\n    # Test that predict_proba outputs a 2D array with the correct shape.\n    X = X_digits_binary[:50]\n    y = y_digits_binary[:50]\n\n    clf = MLPClassifier(hidden_layer_sizes=5, activation=\"logistic\", random_state=1)\n    with ignore_warnings(category=ConvergenceWarning):\n        clf.fit(X, y)\n\n    y_proba = clf.predict_proba(X)\n    assert y_proba.shape == (X.shape[0], np.unique(y).size)\n"], "sample_883": ["def test_bayesian_ridge_ard_fit_intercept_false():\n    # Test BayesianRidge and ARDRegression with fit_intercept=False\n    X = np.array([[1, 1], [3, 4], [5, 7], [4, 1], [2, 6], [3, 10], [3, 2]])\n    y = np.array([1, 2, 3, 2, 0, 4, 5]).T\n\n    for Estimator in [BayesianRidge, ARDRegression]:\n        model = Estimator(fit_intercept=False)\n        model.fit(X, y)\n        assert model.intercept_ == 0.0\n        assert_array_almost_equal(model.predict(X), model._decision_function(X))\n"], "sample_884": ["def test_deprecated_property():\n    with pytest.warns(FutureWarning, match=\"n_features_ is deprecated\"):\n        MockClass2().n_features_\n    assert MockClass2().n_features_ == 10\n"], "sample_886": ["def test__wrap_in_pandas_container_columns_none():\n    \"\"\"Check _wrap_in_pandas_container with columns=None.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n\n    # If X is not a DataFrame and columns=None, then use range(n_features)\n    X_wrapped = _wrap_in_pandas_container(X, columns=None)\n    assert_array_equal(X_wrapped.columns, range(X.shape[1]))\n\n    # If X is a DataFrame and columns=None, then do not change the columns\n    X_df = pd.DataFrame(X, columns=[\"a\", \"b\", \"c\"])\n    X_wrapped = _wrap_in_pandas_container(X_df, columns=None)\n    assert_array_equal(X_wrapped.columns, X_df.columns)\n"], "sample_887": ["def test_calibration_display_with_invalid_estimator_name(pyplot, iris_data_binary):\n    \"\"\"Check that an error is raised when passing an invalid estimator name.\"\"\"\n    X, y = iris_data_binary\n    lr = LogisticRegression().fit(X, y)\n\n    msg = \"Invalid 'name' should be a string.\"\n    with pytest.raises(ValueError, match=msg):\n        CalibrationDisplay.from_estimator(lr, X, y, name=123)\n"], "sample_888": ["def test_iforest_with_n_estimators_equal_to_one():\n    \"\"\"Check that Isolation Forest works with n_estimators=1\"\"\"\n    X = np.array([[0, 1], [1, 2]])\n    X_test = np.array([[2, 1], [1, 1]])\n\n    iforest = IsolationForest(n_estimators=1)\n    iforest.fit(X)\n    assert_array_equal(iforest.predict(X_test), [1, 1])\n"], "sample_889": ["def test_calibration_display_with_invalid_estimator_name(pyplot, iris_data_binary):\n    \"\"\"Check that an error is raised when passing an invalid estimator name.\"\"\"\n    X, y = iris_data_binary\n\n    lr = LogisticRegression().fit(X, y)\n    viz = CalibrationDisplay.from_estimator(lr, X, y)\n\n    msg = \"Invalid 'name' should be a string.\"\n    with pytest.raises(ValueError, match=msg):\n        viz.plot(name=123)\n"], "sample_890": ["def test_cross_val_score_with_groups():\n    # Make sure that SequentialFeatureSelector works with cross-validation\n    # splitters that require groups, such as LeaveOneGroupOut.\n\n    X, y = make_classification(n_samples=12, n_features=10, random_state=0)\n    groups = np.array([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3])\n\n    sfs = SequentialFeatureSelector(\n        KNeighborsClassifier(),\n        n_features_to_select=5,\n        cv=LeaveOneGroupOut(),\n    )\n    sfs.fit(X, y, groups=groups)\n    assert sfs.transform(X).shape[1] == 5\n"], "sample_892": ["def test_adaboost_regressor_with_constant_target():\n    # Check that AdaBoostRegressor works with constant target.\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([5, 5])\n\n    model = AdaBoostRegressor()\n    model.fit(X, y)\n\n    assert_array_almost_equal(model.predict(X), y)\n"], "sample_893": ["def test_plot_tree_filled(pyplot):\n    # mostly smoke tests\n    # Check correctness of export_graphviz for filled option\n    clf = DecisionTreeClassifier(\n        max_depth=3, min_samples_split=2, criterion=\"gini\", random_state=2\n    )\n    clf.fit(X, y)\n\n    # Test export code\n    feature_names = [\"first feat\", \"sepal_width\"]\n    nodes = plot_tree(clf, feature_names=feature_names, filled=True)\n    assert len(nodes) == 3\n    assert (\n        nodes[0].get_text()\n        == \"first feat <= 0.0\\ngini = 0.5\\nsamples = 6\\nvalue = [3, 3]\"\n    )\n    assert nodes[1].get_text() == \"gini = 0.0\\nsamples = 3\\nvalue = [3, 0]\"\n    assert nodes[2].get_text() == \"gini = 0.0\\nsamples = 3\\nvalue = [0, 3]\"\n    # check that the boxes are filled with colors\n    assert nodes[0].get_bbox_patch().get_facecolor() != (1, 1, 1, 1)\n    assert nodes[1].get_bbox_patch().get_facecolor() != (1, 1, 1, 1)\n    assert nodes[2].get_bbox_patch().get_facecolor() != (1, 1, 1, 1)\n"], "sample_894": ["def test_forest_estimator_params():\n    # Check that estimator params are set correctly\n    X, y = make_classification(n_samples=100, n_features=10, random_state=0)\n    clf = RandomForestClassifier(n_estimators=10, random_state=0)\n    clf.fit(X, y)\n\n    # Check that all trees have the same parameters\n    for tree in clf.estimators_:\n        assert tree.criterion == \"gini\"\n        assert tree.max_depth is None\n        assert tree.min_samples_split == 2\n        assert tree.min_samples_leaf == 1\n        assert tree.min_weight_fraction_leaf == 0.0\n        assert tree.max_features == \"sqrt\"\n        assert tree.max_leaf_nodes is None\n        assert tree.min_impurity_decrease == 0.0\n\n    # Check that setting estimator params works\n    clf.set_params(estimator__criterion=\"log_loss\")\n    clf.fit(X, y)\n    for tree in clf.estimators_:\n        assert tree.criterion == \"log_loss\"\n"], "sample_898": ["def test_auc_score_non_binary_class_labels():\n    # Test that roc_auc_score function raises an error when given non-binary\n    # class labels for binary classification problems.\n    rng = np.random.RandomState(0)\n    y_pred = rng.rand(10)\n\n    # Test with multiclass labels\n    y_true = rng.randint(0, 3, size=10)\n    assert_raise_message(ValueError,\n                         \"multiclass format is not supported\",\n                         roc_auc_score, y_true, y_pred)\n\n    # Test with multioutput labels\n    y_true = rng.randint(0, 2, size=(10, 3))\n    assert_raise_message(ValueError,\n                         \"multioutput format is not supported\",\n                         roc_auc_score, y_true, y_pred)\n"], "sample_900": ["def test_mlpclassifier_sparse_input():\n    # Test that sparse input matrices are handled correctly.\n    X, y = make_classification(n_samples=50, n_features=10, random_state=0)\n    X_sparse = csr_matrix(X)\n\n    mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=5, random_state=0)\n    mlp.fit(X, y)\n    mlp_sparse = MLPClassifier(solver='lbfgs', hidden_layer_sizes=5,\n                               random_state=0)\n    mlp_sparse.fit(X_sparse, y)\n\n    assert_array_equal(mlp.coefs_[0], mlp_sparse.coefs_[0])\n    assert_array_equal(mlp.intercepts_[0], mlp_sparse.intercepts_[0])\n    assert_array_equal(mlp.predict(X), mlp_sparse.predict(X_sparse))\n"], "sample_901": ["def test_k_means_n_jobs():\n    # check that n_jobs is correctly passed to the underlying function\n    from sklearn.cluster import KMeans\n    from sklearn.utils._testing import set_random_state\n    from sklearn.datasets import make_blobs\n\n    X, _ = make_blobs(n_samples=100, centers=5, cluster_std=1., random_state=42)\n    km = KMeans(n_clusters=5, init='k-means++', n_init=10, max_iter=10,\n                tol=0.0001, precompute_distances=True, verbose=0,\n                random_state=None, copy_x=True, n_jobs=-1)\n\n    with set_random_state(km):\n        km.fit(X)\n\n    assert hasattr(km, 'labels_')\n    assert hasattr(km, 'cluster_centers_')\n    assert hasattr(km, 'inertia_')\n"], "sample_902": ["def test_pipeline_with_none_step():\n    # Test that a pipeline with a None step raises an error when trying to fit\n    X = np.array([[1, 2]])\n    pipe = Pipeline([('transf', None), ('clf', Mult())])\n    assert_raises_regex(TypeError,\n                        'All intermediate steps should be transformers and '\n                        'implement fit and transform.',\n                        pipe.fit, X)\n"], "sample_904": ["def test_resolve_xref_for_label_with_explicit_title(app):\n    text = \".. _label:\\n\\nTitle\\n======\"\n    restructuredtext.parse(app, text)\n\n    domain = app.env.get_domain(\"std\")\n    refnode = domain.resolve_xref(app.env, 'index', app.builder, 'ref', 'label',\n                                  pending_xref(refexplicit=True), nodes.paragraph())\n    assert_node(refnode, nodes.reference, refid=\"label\")\n    assert_node(refnode[0], nodes.inline, \"Title\")\n"], "sample_908": ["def test_unparse_arguments():\n    # Test unparse_arguments function with various ast.arguments scenarios\n    args = ast.arguments(\n        args=[ast.arg(arg='a', annotation=None), ast.arg(arg='b', annotation=None)],\n        vararg=None,\n        kwonlyargs=[],\n        kw_defaults=[],\n        kwarg=None,\n        defaults=[]\n    )\n    assert ast.unparse_arguments(args) == 'a, b'\n\n    args = ast.arguments(\n        args=[ast.arg(arg='a', annotation=None), ast.arg(arg='b', annotation=None)],\n        vararg=ast.arg(arg='args', annotation=None),\n        kwonlyargs=[],\n        kw_defaults=[],\n        kwarg=None,\n        defaults=[]\n    )\n    assert ast.unparse_arguments(args) == 'a, b, *args'\n\n    args = ast.arguments(\n        args=[ast.arg(arg='a', annotation=None), ast.arg(arg='b', annotation=None)],\n        vararg=None,\n        kwonlyargs=[ast.arg(arg='kwonly', annotation=None)],\n        kw_defaults=[None],\n        kwarg=None,\n        defaults=[]\n    )\n    assert ast.unparse_arguments(args) == 'a, b, *, kwonly'\n\n    args = ast.arguments(\n        args=[ast.arg(arg='a', annotation=None), ast.arg(arg='b', annotation=None)],\n        vararg=None,\n        kwonlyargs=[],\n        kw_defaults=[],\n        kwarg=ast.arg(arg='kwargs', annotation=None),\n        defaults=[]\n    )\n    assert ast.unparse_arguments(args) == 'a, b, **kwargs'\n"], "sample_909": ["def test_usage_section(self):\n    docstring = \"\"\"\\"], "sample_912": ["def test_pyclass_signature(app):\n    text = \".. py:class:: MyClass(a: int, b: str)\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_name, \"MyClass\"],\n                                                    desc_parameterlist,\n                                                    [desc_sig_punctuation, \"(\"],\n                                                    [desc_sig_name, \"a\"],\n                                                    [desc_sig_punctuation, \":\"],\n                                                    \" \",\n                                                    [pending_xref, \"int\"],\n                                                    [desc_sig_punctuation, \",\"],\n                                                    \" \",\n                                                    [desc_sig_name, \"b\"],\n                                                    [desc_sig_punctuation, \":\"],\n                                                    \" \",\n                                                    [pending_xref, \"str\"],\n                                                    [desc_sig_punctuation, \")\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"class\",\n                domain=\"py\", objtype=\"class\", noindex=False)\n"], "sample_913": ["def test_pyfunction_with_annotation(app):\n    text = \".. py:function:: hello(name: str) -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_punctuation, \":\"],\n                                                      \" \",\n                                                      [nodes.inline, pending_xref, \"str\"])])\n\n    # check annotation is correctly parsed\n    annotation = doctree[1][0][1][0][2]\n    assert_node(annotation, nodes.inline, support_smartquotes=False)\n    assert_node(annotation[0], pending_xref, refdomain=\"py\", reftype=\"class\", reftarget=\"str\")\n"], "sample_914": ["def test_unparse_arguments():\n    # test unparse arguments with various combinations of args, defaults, and kwonlyargs\n    source = \"def func(a, b=1, *args, c, d=2, **kwargs): pass\"\n    module = ast.parse(source)\n    func_def = module.body[0]\n    assert ast.unparse_arguments(func_def.args) == \"a, b=1, *args, c, d=2, **kwargs\"\n\n    source = \"def func(a, b, /, c, d): pass\"  # py38+\n    if sys.version_info > (3, 8):\n        module = ast.parse(source)\n        func_def = module.body[0]\n        assert ast.unparse_arguments(func_def.args) == \"a, b, /, c, d\"\n"], "sample_916": ["def test_lookup_key():\n    rootSymbol = Symbol(None, None, None, None)\n    s1 = rootSymbol.add_name(ASTNestedName([ASTIdentifier(\"S1\")], rooted=False))\n    s2 = s1.add_name(ASTNestedName([ASTIdentifier(\"S2\")], rooted=False))\n    s3 = s2.add_name(ASTNestedName([ASTIdentifier(\"S3\")], rooted=False))\n\n    key = s3.get_lookup_key()\n    assert str(key) == \"[(S1, None), (S2, None), (S3, None)]\"\n\n    decl = ASTDeclaration('function', 'function', ASTTypeWithInit(ASTType(ASTDeclSpecs(\n        outer='function',\n        leftSpecs=ASTDeclSpecsSimple(storage=None, threadLocal=None, inline=None,\n                                     restrict=None, volatile=None, const=None,\n                                     attrs=[]),\n        rightSpecs=ASTDeclSpecsSimple(storage=None, threadLocal=None, inline=None,\n                                      restrict=None, volatile=None, const=None,\n                                      attrs=[]),\n        trailingTypeSpec=ASTTrailingTypeSpecFundamental(\"void\")),\n        ASTDeclaratorPtr(next=ASTDeclaratorNameParam(declId=ASTNestedName(\n            [ASTIdentifier(\"func\")], rooted=False), arrayOps=[], param=None),\n                         restrict=None, volatile=None, const=None, attrs=[]))),\n        init=None))\n    s3._fill_empty(decl, docname=\"TestDoc\")\n\n    key = s3.get_lookup_key()\n    assert str(key) == \"[(S1, None), (S2, None), (S3, c.TestDoc.1func)]\"\n"], "sample_918": ["def test_pyfunction_with_typehints(app):\n    text = \".. py:function:: hello(name: str) -> None\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"None\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_punctuation, \":\"],\n                                                      \" \",\n                                                      [pending_xref, \"str\"])])\n\n    # Check that the return type is correctly parsed\n    returns_node = doctree[1][0][2]\n    assert_node(returns_node, [desc_returns, pending_xref, \"None\"])\n    assert returns_node[1].astext() == \"None\"\n"], "sample_920": ["def test_usage_section(self):\n    docstring = \"\"\"\\"], "sample_925": ["def test_MockObject_repr():\n    mock = _MockObject()\n    assert repr(mock) == '_MockObject'\n    assert repr(mock.some_attr) == '_MockObject.some_attr'\n    assert repr(mock.some_method) == '_MockObject.some_method'\n\n    # check that repr is correctly updated when subclassing\n    class SubClass(mock.SomeClass):\n        pass\n\n    obj = SubClass()\n    assert repr(obj) == 'SubClass'\n    assert repr(obj.some_attr) == 'SubClass.some_attr'\n    assert repr(obj.some_method) == 'SubClass.some_method'\n"], "sample_926": ["def test_lookup_key():\n    rootSymbol = Symbol(None, None, None, None)\n    s1 = rootSymbol.add_name(ASTNestedName([ASTIdentifier(\"S1\")], rooted=False))\n    s2 = s1.add_name(ASTNestedName([ASTIdentifier(\"S2\")], rooted=False))\n    s3 = s2.add_name(ASTNestedName([ASTIdentifier(\"S3\")], rooted=False))\n\n    assert str(s1.get_lookup_key()) == '[(S1, None)]'\n    assert str(s2.get_lookup_key()) == '[(S1, None), (S2, None)]'\n    assert str(s3.get_lookup_key()) == '[(S1, None), (S2, None), (S3, None)]'\n\n    decl1 = ASTDeclaration('function', None, None)\n    decl1.symbol = s1\n    s1.declaration = decl1\n\n    decl2 = ASTDeclaration('function', None, None)\n    decl2.symbol = s2\n    s2.declaration = decl2\n\n    decl3 = ASTDeclaration('function', None, None)\n    decl3.symbol = s3\n    s3.declaration = decl3\n\n    assert str(s1.get_lookup_key()) == '[(S1, f__S1)]'\n    assert str(s2.get_lookup_key()) == '[(S1, f__S1), (S2, f__S1.S2)]'\n    assert str(s3.get_lookup_key()) == '[(S1, f__S1), (S2, f__S1.S2), (S3, f__S1.S2.S3)]'\n"], "sample_928": ["def test_heading():\n    env = Environment()\n    assert heading(env, 'Hello World', 1) == 'Hello World\\n==========='\n    assert heading(env, '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a', 2) == '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a\\n-----------'\n    assert heading(env, '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a', 3) == '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a\\n~~~~~~~~~~~'\n\n    # Test with wide characters\n    WIDECHARS['test'] = 'WFA'\n    env.language = 'test'\n    assert heading(env, '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a', 1) == '\u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a\\n==============='\n"], "sample_929": ["def test_pyfunction_with_typehints(app):\n    text = \".. py:function:: hello(name: str, age: int) -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, ([desc_parameter, ([desc_sig_name, \"name\"],\n                                                        [desc_sig_punctuation, \":\"],\n                                                        \" \",\n                                                        [pending_xref, \"str\"])],\n                                      [desc_parameter, ([desc_sig_name, \"age\"],\n                                                        [desc_sig_punctuation, \":\"],\n                                                        \" \",\n                                                        [pending_xref, \"int\"])]])\n"], "sample_930": ["def test_create_index_with_group_entries(app):\n    text = (\".. index:: single: docutils\\n\"\n            \".. index:: single: Python\\n\"\n            \".. index:: single: Python (in module foo)\\n\"\n            \".. index:: single: Python (in module bar)\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder, group_entries=True)\n\n    # check index is created correctly\n    assert len(index) == 2\n    assert index[0] == ('D', [('docutils', [[('', '#index-0')], [], None])])\n    assert index[1] == ('P', [('Python', [[('', '#index-1')],\n                                          [(' (in module bar)', [('', '#index-3')]),\n                                           (' (in module foo)', [('', '#index-2')])],\n                                         None])])\n\n    # check the reference labels are created correctly\n    std = app.env.get_domain('std')\n    assert std.anonlabels['index-0'] == ('index', 'index-0')\n    assert std.anonlabels['index-1'] == ('index', 'index-1')\n    assert std.anonlabels['index-2'] == ('index', 'index-2')\n    assert std.anonlabels['index-3'] == ('index', 'index-3')\n"], "sample_931": ["def test_pyclasslike_signature(app):\n    text = \".. py:class:: MyClass\"\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_name, \"MyClass\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"class\",\n                domain=\"py\", objtype=\"class\", noindex=False)\n\n    assert 'MyClass' in domain.objects\n    assert domain.objects['MyClass'] == ('index', 'MyClass', 'class')\n"], "sample_933": ["def test_gettext_location(app):\n    app.builder.build_all()\n    pot = (app.outdir / 'index_entries.pot').read_text()\n    assert '#: index_entries.rst:' in pot\n\n    app.config.gettext_location = False\n    app.builder.build_all()\n    pot = (app.outdir / 'index_entries.pot').read_text()\n    assert '#: index_entries.rst:' not in pot\n\n"], "sample_936": ["def test_stringify_broken_type():\n    assert stringify(BrokenType) == \"BrokenType\"\n"], "sample_937": ["def test_unparse_arguments():\n    source = \"def func(a: int, b: str = 'default', *args, **kwargs): pass\"\n    module = ast.parse(source)\n    expected = \"a: int, b: str = 'default', *args, **kwargs\"\n    assert ast.unparse(module.body[0].args) == expected\n"], "sample_938": ["def test_man_page_config(app, status, warning):\n    app.build()\n    assert (app.outdir / 'test.1').exists()\n\n    content = (app.outdir / 'test.1').read_text()\n    assert '.TH \"TEST\" \"1\"' in content\n    assert '.SH \"NAME\"\\n\\fITest man page\\fP' in content\n    assert '.SH \"AUTHOR\"\\n\\fIAuthor\\fP' in content\n"], "sample_941": ["def test_stringify_type_hints_Ellipsis():\n    assert stringify(Ellipsis) == \"...\"\n"], "sample_943": ["def test_is_excluded(tempdir):\n    excludes = [str(tempdir / 'exclude1'), str(tempdir / 'exclude2' / '*')]\n    assert is_excluded(str(tempdir / 'exclude1'), excludes)\n    assert is_excluded(str(tempdir / 'exclude2' / 'subdir'), excludes)\n    assert not is_excluded(str(tempdir / 'not_excluded'), excludes)\n"], "sample_944": ["def test_stringify_broken_type_hints():\n    assert stringify(BrokenType) == 'tests.test_util_typing.BrokenType'\n"], "sample_949": ["def test_custom_man_page(app, status, warning):\n    app.build()\n    assert (app.outdir / 'test.2').exists()\n\n    content = (app.outdir / 'test.2').read_text()\n    assert '.TH \"TEST\" \"2\"' in content\n    assert '.SH \"NAME\"\\n' in content\n    assert 'Test man page\\n' in content\n"], "sample_953": ["def test_valid_dir(tempdir):\n    d = {'path': tempdir, 'sep': True}\n    assert qs.valid_dir(d) is True\n\n    d['path'] = tempdir / 'nonexistent'\n    assert qs.valid_dir(d) is True\n\n    (tempdir / 'conf.py').touch()\n    d['path'] = tempdir\n    assert qs.valid_dir(d) is False\n\n    (tempdir / 'Makefile').touch()\n    d['path'] = tempdir\n    assert qs.valid_dir(d) is False\n\n    d['sep'] = False\n    d['dot'] = '_'\n    d['master'] = 'index'\n    d['suffix'] = '.rst'\n    (tempdir / '_static').mkdir()\n    assert qs.valid_dir(d) is False\n\n    (tempdir / '_templates').mkdir()\n    assert qs.valid_dir(d) is False\n\n    (tempdir / 'index.rst').touch()\n    assert qs.valid_dir(d) is False\n"], "sample_954": ["def test_man_show_urls(app, status, warning):\n    app.build()\n    content = (app.outdir / 'python.1').read_text()\n\n    # check if URLs are shown after links\n    assert ('<https://www.python.org/>' in content)\n"], "sample_955": ["def test_unparse_arguments(source, expected):\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].args, source) == expected\n"], "sample_956": ["def test_inspect_main_url_error(capsys, monkeypatch):\n    \"\"\"inspect_main interface, with url argument and error response\"\"\"\n    class InventoryHandler(http.server.BaseHTTPRequestHandler):\n            self.send_response(404, \"Not Found\")\n            self.end_headers()\n            self.wfile.write(b\"Error: Not Found\")\n\n    with http_server(InventoryHandler) as server:\n        url = f\"http://localhost:{server.server_port}/inventory\"\n        inspect_main([url])\n\n    stdout, stderr = capsys.readouterr()\n    assert stdout == \"\"\n    assert \"Unknown error: ('404', 'Not Found')\" in stderr\n\n    # patch requests.get to raise an exception\n        raise Exception(\"Mocked exception\")\n\n    monkeypatch.setattr(\"sphinx.ext.intersphinx.requests.get\", mock_get)\n\n    with pytest.raises(Exception):\n        inspect_main([url])\n"], "sample_957": ["def test_stringify_broken_type_hints():\n    assert stringify(BrokenType) == 'tests.test_util_typing.BrokenType'\n"], "sample_960": ["def test_pyattribute_with_union_type_operator(app):\n    text = (\".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:attribute:: attr\\n\"\n            \"      :type: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][1][1],\n                ([desc_name, \"attr\"],\n                 [desc_annotation, (\": \",\n                                    [pending_xref, \"int\"],\n                                    \" \",\n                                    [desc_sig_punctuation, \"|\"],\n                                    \" \",\n                                    [pending_xref, \"str\"])]))\n"], "sample_962": ["def test_ismock():\n    with mock(['unknown']):\n        import unknown\n        assert ismock(unknown)\n        assert ismock(unknown.secret)\n        assert ismock(unknown.secret.Class)\n\n    assert not ismock(int)\n    assert not ismock(str)\n    assert not ismock(None)\n"], "sample_963": ["def test_stringify_broken_type_hints():\n    assert stringify(BrokenType) == \"tests.test_util_typing.BrokenType\"\n"], "sample_967": ["def test_mathjax_custom_path(app, status, warning):\n    app.builder.build_all()\n\n    content = (app.outdir / 'index.html').read_text()\n    assert 'https://example.com/mathjax.js' in content\n"], "sample_968": ["def test_pyattribute_with_module_prefix(app):\n    text = (\".. py:module:: example\\n\"\n            \".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:attribute:: attr\\n\"\n            \"      :type: Optional[str]\\n\"\n            \"      :value: ''\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (nodes.target,\n                          addnodes.index,\n                          addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, (\"class\", desc_sig_space)],\n                                                    [desc_addname, \"example.\"],\n                                                    [desc_name, \"Class\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc)])]))\n    assert_node(doctree[3][1][0], addnodes.index,\n                entries=[('single', 'attr (Class attribute)', 'example.Class.attr', '', None)])\n    assert_node(doctree[3][1][1], ([desc_signature, ([desc_name, \"attr\"],\n                                                     [desc_annotation, ([desc_sig_punctuation, ':'],\n                                                                        desc_sig_space,\n                                                                        [pending_xref, \"Optional\"],\n                                                                        [desc_sig_punctuation, \"[\"],\n                                                                        [pending_xref, \"str\"],\n                                                                        [desc_sig_punctuation, \"]\"])],\n                                                     [desc_annotation, (desc_sig_space,\n                                                                        [desc_sig_punctuation, '='],\n                                                                        desc_sig_space,\n                                                                        \"''\")]\n                                                     )],\n                                   [desc_content, ()]))\n    assert_node(doctree[3][1][1][0][1][2], pending_xref, **{\"py:module\": \"example\", \"py:class\": \"Class\"})\n    assert_node(doctree[3][1][1][0][1][4], pending_xref, **{\"py:module\": \"example\", \"py:class\": \"Class\"})\n    assert 'example.Class.attr' in app.env.domains['py'].objects\n    assert app.env.domains['py'].objects['example.Class.attr'] == ('index', 'example.Class.attr', 'attribute', False)\n"], "sample_969": ["def test_stringify_type_hints_ForwardRef():\n    from typing import ForwardRef  # type: ignore\n    assert stringify(ForwardRef(\"myint\"), False) == \"myint\"\n    assert stringify(ForwardRef(\"myint\"), True) == \"myint\"\n"], "sample_972": ["def test_stringify_type_ForwardRef():\n    from typing import ForwardRef  # type: ignore\n    assert stringify(ForwardRef(\"myint\")) == \"myint\"\n    assert stringify(ForwardRef(\"myint\"), \"fully-qualified\") == \"myint\"\n    assert stringify(ForwardRef(\"myint\"), \"smart\") == \"myint\"\n"], "sample_974": ["def test_ccode_For():\n    i, n = symbols('i n', integer=True)\n    f = For(i, Range(n), [aug_assign(x, '+', i)])\n    assert ccode(f) == (\n        'for (int i=0; i<n; i++){\\n'\n        '   x += i;\\n'\n        '}'\n    )\n"], "sample_975": ["def test_nsolve_float_handling():\n    x = Symbol('x')\n    assert nsolve(x**2 - Float(2), x, 1) == sqrt(2).evalf()\n"], "sample_976": ["def test_symbols_iterator():\n    x, y, z = symbols('x:z')\n    assert list(symbols('x:2')) == [x]\n    assert list(symbols('x:3')) == [x, y]\n    assert list(symbols('x:4')) == [x, y, z]\n\n    a, b, c = symbols('a:c')\n    assert list(symbols('a:b')) == [a]\n    assert list(symbols('a:c')) == [a, b]\n    assert list(symbols('a:d')) == [a, b, c]\n"], "sample_977": ["def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]]\"\n    assert mcode(Sum(x**2 + y**2, (x, 1, 10), (y, 1, 10))) == \\\n        \"Hold[Sum[x^2 + y^2, {x, 1, 10}, {y, 1, 10}]]\"\n"], "sample_978": ["def test_repeated_degree_2():\n    d = 2\n    knots = [0, 0, 1, 2, 2, 3, 4, 4]\n    splines = bspline_basis_set(d, knots, x)\n    b0 = Piecewise((1 - 2*x + x**2, Interval(0, 1).contains(x)),\n                   (0, True))\n    b1 = Piecewise((x**2/2, Interval(0, 1).contains(x)),\n                   (Rational(-3, 2) + 3*x - x**2, Interval(1, 2).contains(x)),\n                   (0, True))\n    b2 = Piecewise((Rational(1, 2) - x + x**2/2, Interval(1, 2).contains(x)),\n                   (0, True))\n    b3 = Piecewise((Rational(9, 2) - 3*x + x**2/2, Interval(2, 3).contains(x)),\n                   (0, True))\n    b4 = Piecewise((8 - 4*x + x**2/2, Interval(3, 4).contains(x)),\n                   (0, True))\n    b5 = Piecewise((x**2/2 - 4*x + 4, Interval(3, 4).contains(x)),\n                   (0, True))\n    assert splines[0] == b0\n    assert splines[1] == b1\n    assert splines[2] == b2\n    assert splines[3] == b3\n    assert splines[4] == b4\n    assert splines[5] == b5\n"], "sample_979": ["def test_MatrixElement_as_real_imag():\n    A = MatrixSymbol('A', 2, 2)\n    a11 = A[0, 0]\n    assert a11.as_real_imag() == (a11/2 + a11.conjugate()/2, -a11/2 + a11.conjugate()/2)\n"], "sample_982": ["def test_primeomega():\n    assert primeomega(2) == 1\n    assert primeomega(2 * 3) == 2\n    assert primeomega(2 * 3 * 5) == 3\n    assert primeomega(3 * 25) == primeomega(3) + primeomega(25)\n    assert [primeomega(p) for p in primerange(1, 10)] == [1, 1, 1, 1]\n    assert primeomega(fac(50)) == 68\n    assert primeomega(2 ** 9941 - 1) == 1\n    n = Symbol('n', integer=True)\n    assert primeomega(n)\n    assert primeomega(n).subs(n, 2 ** 31 - 1) == 1\n    assert summation(primeomega(n), (n, 2, 30)) == 74\n"], "sample_984": ["def test_DMP():\n    from sympy.polys.domains import ZZ\n    f = x**3 + 2*x**2 - 7*x - 12\n    assert str(ZZ.map(f)) == \"Poly(x**3 + 2*x**2 - 7*x - 12, x, domain='ZZ')\"\n"], "sample_985": ["def test_real_root():\n    from sympy import real_root, Rational, symbols\n    x = symbols('x')\n    assert real_root(-8, 3) == -2\n    assert real_root(Rational(-27, 8), 3) == Rational(-3, 2)\n    assert real_root(10000000000000000000000, 4) == 31622776\n    assert real_root(x, 4).subs(x, 16) == 2\n    assert real_root((x**4).subs(x, -2), 4) == -2\n    assert real_root((x**5).subs(x, -2), 5) == -2\n    assert real_root(-32, 5) == -2\n    assert real_root(-32, 5, 5//2) == -2\n"], "sample_991": ["def test_issue_16469():\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True)\n    p = Product(n**2 + 1 / 2**k, (k, 0, n-1)).doit()\n    assert p.subs(n, 2).doit() == S(65)/4\n"], "sample_992": ["def test_MpmathPrinter():\n    p = MpmathPrinter()\n    assert p.doprint(pi) == 'mpmath.pi'\n    assert p.doprint(acos(x)) == 'mpmath.acos(x)'\n    expr = CustomPrintedObject()\n    assert p.doprint(expr) == 'mpmath'\n"], "sample_993": ["def test_FreeGroupElm_cyclic_reduction():\n    w1 = x**2*y**2*x**-1\n    assert w1.cyclic_reduction() == x*y**2\n\n    w2 = x**-3*y**-1*x**5\n    assert w2.cyclic_reduction() == y**-1*x**2\n\n    w3 = x*y**2*x*y**2\n    assert w3.cyclic_reduction() == w3\n\n    w4 = x**12\n    assert w4.cyclic_reduction(removed=True) == (x**12, F.identity)\n\n    w5 = x**-3*y**-2*x**3\n    assert w5.cyclic_reduction(removed=True) == (y**-2, x**-3)\n"], "sample_996": ["def test_issue_16458():\n    n = Symbol('n', integer=True)\n    p = Product(n, (n, 1, -3)).doit()\n    assert p == 1 / Product(n, (n, -2, 0)).doit()\n"], "sample_998": ["def test_latex_Quaternion_conjugate():\n    q = Quaternion(x, y, z, t)\n    assert latex(q.conjugate()) == \"x - y i - z j - t k\"\n"], "sample_1000": ["def test_octave_user_functions():\n    x = symbols('x')\n    f = Function('f')\n    g = Function('g')\n\n    custom_functions = {\n        \"f\": \"existing_octave_fcn\",\n        \"g\": [(lambda x: x.is_Matrix, \"my_mat_fcn\"),\n              (lambda x: not x.is_Matrix, \"my_fcn\")]\n    }\n\n    assert octave_code(f(x), user_functions=custom_functions) == \"existing_octave_fcn(x)\"\n    assert octave_code(g(x), user_functions=custom_functions) == \"my_fcn(x)\"\n    assert octave_code(g(Matrix([[1, x]])), user_functions=custom_functions) == \"my_mat_fcn([1 x])\"\n"], "sample_1004": ["def test_CondSet_contains():\n    sin_sols_principal = ConditionSet(x, Eq(sin(x), 0),\n                                      Interval(0, 2*pi, False, True))\n    assert sin_sols_principal.contains(pi) == And(Eq(sin(pi), 0), pi < 2*pi)\n    assert sin_sols_principal.contains(3*pi) == And(Eq(sin(3*pi), 0), 3*pi < 2*pi)\n    assert sin_sols_principal.contains(y) == And(Eq(sin(y), 0), y < 2*pi)\n    assert ConditionSet(x, x**2 > 4, S.Reals).contains(5) == And(5**2 > 4, 5 in S.Reals)\n    assert ConditionSet(x, x**2 > 4, S.Reals).contains(1) == And(1**2 > 4, 1 in S.Reals)\n"], "sample_1006": ["def test_subfactorial():\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True, nonnegative=True)\n\n    assert subfactorial(-1) == 0\n    assert subfactorial(0) == 1\n    assert subfactorial(1) == 0\n    assert subfactorial(2) == 1\n    assert subfactorial(3) == 2\n    assert subfactorial(4) == 9\n    assert subfactorial(5) == 44\n\n    assert subfactorial(n).is_integer is None\n    assert subfactorial(k).is_integer is True\n    assert subfactorial(n).is_nonnegative is None\n    assert subfactorial(k).is_nonnegative is True\n    assert subfactorial(n).is_odd is None\n    assert subfactorial(k + 1).is_odd is True\n    assert subfactorial(k + 2).is_even is True\n\n    assert subfactorial(n).rewrite(uppergamma) == uppergamma(n + 1, -1)/S.Exp1\n"], "sample_1007": ["def test_subfactorial():\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True, nonnegative=True)\n\n    assert subfactorial(-1) == 0\n    assert subfactorial(0) == 1\n    assert subfactorial(1) == 0\n    assert subfactorial(2) == 1\n    assert subfactorial(3) == 2\n    assert subfactorial(4) == 9\n    assert subfactorial(5) == 44\n\n    assert subfactorial(n).is_integer is None\n    assert subfactorial(k).is_integer is True\n\n    assert subfactorial(n).is_nonnegative is None\n    assert subfactorial(k).is_nonnegative is True\n\n    assert subfactorial(n).is_odd is None\n    assert subfactorial(k + 1).is_odd is True\n    assert subfactorial(k + 2).is_odd is False\n\n    assert subfactorial(n).is_even is None\n    assert subfactorial(k + 1).is_even is False\n    assert subfactorial(k + 2).is_even is True\n\n    assert subfactorial(n).rewrite(uppergamma) == uppergamma(n + 1, -1)/S.Exp1\n"], "sample_1011": ["def test_Indexed_printing():\n    # test cases for issue #11821\n    A = IndexedBase(\"A\", shape=(3, 3))\n    i = Symbol('i', integer=True)\n    j = Symbol('j', integer=True)\n\n    assert mcode(A[i, j]) == \"A(i + 1, j + 1)\"\n    assert mcode(3 * A[i, j]) == \"3*A(i + 1, j + 1)\"\n\n    F = A[i, j].subs(A, Matrix([[1, 2], [3, 4]]))\n    assert mcode(F) == \"[[1 2]; [3 4]](i + 1, j + 1)\"\n"], "sample_1013": ["def test_lambdify_with_integer_types():\n    f = lambdify(x, x**2)\n    assert f(2) == 4\n    assert f(2.0) == 4.0\n    assert f(numpy.int8(2)) == 4\n    assert f(numpy.int16(2)) == 4\n    assert f(numpy.int32(2)) == 4\n    assert f(numpy.int64(2)) == 4\n"], "sample_1014": ["def test_free_symbols():\n    from sympy.abc import x, y, z\n    md = ImmutableDenseNDimArray([[x, y], [x*z, x*y*z]])\n    assert md.free_symbols == {x, y, z}\n\n    sd = ImmutableSparseNDimArray(md)\n    assert sd.free_symbols == {x, y, z}\n"], "sample_1015": ["def test_ccode_While():\n    assert ccode(While(x < 10, [aug_assign(y, '*', x)])) == (\n        \"while (x < 10) {\\n\"\n        \"   y *= x;\\n\"\n        \"}\"\n    )\n"], "sample_1016": ["def test_Indexed_printing():\n    # test cases for issue #11821\n    A = IndexedBase(\"A\", shape=(3, 3))\n    B = IndexedBase(\"B\", shape=(3, 3))\n    C = IndexedBase(\"C\", shape=(3, 3))\n\n    assert mcode(A[0, 0]) == \"A(1, 1)\"\n    assert mcode(3 * A[0, 0]) == \"3*A(1, 1)\"\n\n    F = C[0, 0].subs(C, A - B)\n    assert mcode(F) == \"(-B(1, 1) + A(1, 1))\"\n"], "sample_1018": ["def test_fcode_While():\n    x = symbols('x')\n    expr = While(x < 5, [Assignment(x, x + 1)])\n    assert fcode(expr) == (\n        \"      do while (x < 5)\\n\"\n        \"         x = x + 1\\n\"\n        \"      end do\"\n    )\n"], "sample_1020": ["def test_Sum():\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]]\"\n    assert mcode(Sum(x**2 + y**2, (x, 1, 10), (y, 1, 10))) == \\\n        \"Hold[Sum[x^2 + y^2, {x, 1, 10}, {y, 1, 10}]]\"\n    assert mcode(Sum(sin(x), (x, 0, pi/2))) == \"Hold[Sum[Sin[x], {x, 0, Pi/2}]]\"\n"], "sample_1023": ["def test_sieve_attributes():\n    s = Sieve()\n    assert isinstance(s._list, _array)\n    assert isinstance(s._tlist, _array)\n    assert isinstance(s._mlist, _array)\n    assert len(s._list) == len(s._tlist) == len(s._mlist) == s._n\n    assert all(isinstance(i, int) for i in s._list)\n    assert all(isinstance(i, int) for i in s._tlist)\n    assert all(isinstance(i, int) for i in s._mlist)\n"], "sample_1025": ["def test_PythonCodePrinter_printing_of_Infinity_and_NaN():\n    p = PythonCodePrinter()\n    assert p.doprint(oo) == \"float('inf')\"\n    assert p.doprint(-oo) == \"float('-inf')\"\n    assert p.doprint(zoo) == \"float('nan')\"\n"], "sample_1026": ["def test_lambdify_matrix_symbol():\n    A = MatrixSymbol('A', 2, 2)\n    f = lambdify(A, A**2)\n    assert f([[1, 2], [3, 4]]) == [[7, 10], [15, 22]]\n"], "sample_1028": ["def test_Mul_is_integer():\n    x = Symbol('x')\n    n = Symbol('n', integer=True)\n    m = Symbol('m', integer=True, nonzero=True)\n\n    assert (n*m).is_integer is True\n    assert (x*n).is_integer is None\n    assert (n*x).is_integer is None\n    assert (m*pi).is_integer is False\n\n    r = Symbol('r', rational=True)\n    assert (pi*r).is_integer is None\n\n    # issue 8008\n    z = Symbol('z', zero=True)\n    i = Symbol('i', imaginary=True)\n    assert (z*i).is_integer is None\n    bi = Symbol('i', imaginary=True, finite=True)\n    assert (z*bi).is_zero is True\n"], "sample_1029": ["def test_MonogenicFiniteExtension():\n    A = FiniteExtension(Poly(x**2 + 1, x))\n    assert srepr(A) == \"FiniteExtension(Poly(x**2 + 1, x, domain='ZZ'))\"\n"], "sample_1032": ["def test_issue_16458():\n    from sympy.abc import x, y\n    assert Min(x, y).is_even is None\n    assert Max(x, y).is_even is None\n    assert Min(x, y).is_odd is None\n    assert Max(x, y).is_odd is None\n    assert Min(2*x, 2*y).is_even == True\n    assert Max(2*x, 2*y).is_even == True\n    assert Min(2*x + 1, 2*y + 1).is_odd == True\n    assert Max(2*x + 1, 2*y + 1).is_odd == True\n"], "sample_1033": ["def test_issue_15873():\n    e = -2*I + (1 + I)**2\n    assert e.is_zero is None\n    assert e.simplify().is_zero is True\n"], "sample_1034": ["def test_apply_grover():\n    nqubits = 2\n    oracle = lambda qubits: qubits == IntQubit(2, nqubits=nqubits)\n    result = apply_grover(oracle, nqubits)\n    assert qapply(result) == IntQubit(2, nqubits=nqubits)\n\n    nqubits = 3\n    oracle = lambda qubits: qubits == IntQubit(5, nqubits=nqubits)\n    result = apply_grover(oracle, nqubits)\n    assert qapply(result) == IntQubit(5, nqubits=nqubits)\n"], "sample_1035": ["def test_measure_all():\n    q = IntQubit(0)/sqrt(2) + IntQubit(1)/sqrt(2)\n    result = measure_all(q)\n    assert len(result) == 2\n    assert result[0][0] == IntQubit(0)\n    assert result[0][1] == 1/2\n    assert result[1][0] == IntQubit(1)\n    assert result[1][1] == 1/2\n"], "sample_1037": ["def test_MatMul_doit():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n\n    assert MatMul(A, B).doit() == A*B\n    assert MatMul(A, B, C).doit() == A*B*C\n\n    X = Matrix([[1, 2], [3, 4]])\n    Y = Matrix([[5, 6], [7, 8]])\n\n    assert MatMul(X, Y).doit() == X*Y\n    assert MatMul(X, Y, X).doit() == X*Y*X\n\n    assert MatMul(A, X).doit() == A*X\n    assert MatMul(X, A).doit() == X*A\n"], "sample_1038": ["def test_matrix_derivative():\n    from sympy import sin, cos\n    x = symbols('x')\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    D = MatrixSymbol('D', 2, 2)\n\n    assert _matrix_derivative(A, A) == Identity(2)\n    assert _matrix_derivative(A*B, A) == B.T\n    assert _matrix_derivative(A*B, B) == A\n    assert _matrix_derivative(A*B*C, A) == (B*C).T\n    assert _matrix_derivative(A*B*C, B) == A*C\n    assert _matrix_derivative(A*B*C, C) == A*B\n\n    assert _matrix_derivative(sin(A), A) == cos(A).T\n    assert _matrix_derivative(cos(A), A) == -sin(A).T\n\n    assert _matrix_derivative(A+B, A) == Identity(2)\n    assert _matrix_derivative(A+B, B) == Identity(2)\n\n    assert _matrix_derivative(A**2, A) == A + A.T\n\n    assert _matrix_derivative(A*B + C*D, A) == B.T\n    assert _matrix_derivative(A*B + C*D, B) == A\n    assert _matrix_derivative(A*B + C*D, C) == D.T\n    assert _matrix_derivative(A*B + C*D, D) == C\n"], "sample_1041": ["def test_MatrixElement_subs():\n    A = MatrixSymbol(\"A\", 2, 2)\n    B = MatrixSymbol(\"B\", 2, 2)\n    i, j = symbols(\"i j\")\n    assert A[i, j].subs(A, B) == B[i, j]\n    assert A[i, j].subs(B, A) == A[i, j]\n    assert A[i, j].subs(i, 0) == A[0, j]\n    assert A[i, j].subs(j, 1) == A[i, 1]\n    assert A[i, j].subs({i: 0, j: 1}) == A[0, 1]\n    assert A[i, j].subs({A: B, i: 0, j: 1}) == B[0, 1]\n"], "sample_1042": ["def test_IndexedBase_shape_with_infinite_dimension():\n    i, j = symbols('i j', integer=True)\n    a = IndexedBase('a', shape=(oo, 3))\n    assert a.shape == Tuple(oo, 3)\n    assert Indexed(a, i, j).shape == Tuple(oo, 3)\n    raises(IndexException, lambda: Indexed(a, i))\n    raises(IndexException, lambda: Indexed(a, i, j, 1))\n"], "sample_1043": ["def test_user_functions():\n    assert mcode(sin(x), user_functions={'sin': 'MySin'}) == \"MySin[x]\"\n    assert mcode(cos(x), user_functions={'cos': 'MyCos'}) == \"MyCos[x]\"\n    assert mcode(exp(x), user_functions={'exp': 'MyExp'}) == \"MyExp[x]\"\n    assert mcode(f(x), user_functions={f: 'MyF'}) == \"MyF[x]\"\n"], "sample_1044": ["def test_Pow_is_finite():\n    x = Symbol('x', finite=True)\n    y = Symbol('y', finite=False)\n    z = Symbol('z', zero=True)\n    assert (x**2).is_finite is True\n    assert (y**2).is_finite is False\n    assert (z**2).is_finite is True\n    assert (2**x).is_finite is None\n    assert (2**y).is_finite is False\n    assert (2**z).is_finite is True\n"], "sample_1047": ["def test_issue_10302_extension():\n    x = Symbol('x')\n    r = Symbol('r', real=True)\n    i = Symbol('i', imaginary=True)\n    assert (r + i).is_real is False\n    assert (r + i).is_imaginary is None\n    assert (x + i).is_imaginary is None\n    assert (x + r*i).is_imaginary is None\n    assert (r + i*I).is_imaginary is True\n    assert (x + i*I).is_imaginary is None\n    assert (x + r*i*I).is_imaginary is None\n"], "sample_1048": ["def test_parabola_intersection():\n    p1 = Point(0, 0)\n    p2 = Point(3, 7)\n    d1 = Line(Point(4, 0), Point(4, 9))\n    d2 = Line(Point(7, 6), Point(3, 6))\n\n    pa1 = Parabola(p1, d1)\n    pa2 = Parabola(p2, d2)\n\n    # Intersection with a point\n    assert pa1.intersection(p1) == [p1]\n    assert pa1.intersection(p2) == []\n\n    # Intersection with a line\n    l1 = Line(p1, p2)\n    assert len(pa1.intersection(l1)) == 2\n\n    # Intersection with another parabola\n    assert len(pa1.intersection(pa2)) == 2\n\n    # Intersection with an ellipse\n    e1 = Ellipse(p1, 2, 5)\n    assert len(pa1.intersection(e1)) == 2\n\n    # Intersection with a segment\n    s1 = Segment2D(p1, p2)\n    assert pa1.intersection(s1) == []\n\n    # Intersection with a ray\n    r1 = Ray2D(p1, p2)\n    assert len(pa1.intersection(r1)) == 1\n\n    # Intersection with a 3D line\n    raises(TypeError, lambda: pa1.intersection(Line(Point(0, 0, 0), Point(1, 1, 1))))\n"], "sample_1051": ["def test_dotprint_styles():\n    styles = [(Basic, {'color': 'red', 'shape': 'box'}),\n              (Expr,  {'color': 'green'})]\n    text = dotprint(x+2, styles=styles)\n    assert '\"color\"=\"green\"' in text\n    assert '\"shape\"=\"ellipse\"' in text\n    assert '\"color\"=\"black\"' not in text\n"], "sample_1052": ["def test_c_with_printer():\n    #issue 13586\n    from sympy.printing.ccode import C99CodePrinter\n    class CustomPrinter(C99CodePrinter):\n            return \"fastpow({}, {})\".format(self._print(expr.base),\n                                            self._print(expr.exp))\n\n    x, y = symbols('x y')\n    expr = x**y\n\n    gen = C99CodeGen(printer=CustomPrinter())\n\n    expected = (\n        '#include \"expr.h\"\\n'\n        '#include <math.h>\\n'\n        'double expr(double x, double y) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastpow(x, y);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n\n    result = codegen(('expr', expr), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    assert source == expected\n"], "sample_1054": ["def test_issue_12345():\n    # Test case for ImageSet with a Lambda function that has multiple arguments\n    x, y = symbols('x y')\n    f = Lambda((x, y), x + y)\n    domain = Interval(0, 1) * Interval(0, 1)\n    image_set = ImageSet(f, domain)\n\n    assert (0.5, 0.5) in domain\n    assert 1 in image_set\n\n    # Test case for ComplexRegion with a FiniteSet\n    region = ComplexRegion(FiniteSet(1, 2) * FiniteSet(3, 4))\n    assert 1 + 3*I in region\n    assert 2 + 4*I in region\n"], "sample_1056": ["def test_numexpr_functions():\n    # Test that NumExprPrinter correctly handles functions\n    x = symbols('x')\n    n = NumExprPrinter()\n\n    assert n._print(sin(x)) == \"sin(x)\"\n    assert n._print(cos(x)) == \"cos(x)\"\n    assert n._print(sqrt(x)) == \"sqrt(x)\"\n    assert n._print(abs(x)) == \"abs(x)\"\n\n    # Test that NumExprPrinter raises an error for unsupported functions\n    class UnsupportedFunction(Expr):\n        pass\n\n    raises(TypeError, lambda: n._print(UnsupportedFunction()))\n"], "sample_1057": ["def test_render_as_module_with_fully_qualified_modules():\n    content = Print(\"Hello, World!\")\n    result = render_as_module(content, standard='python3')\n    assert \"import sympy\" in result\n    assert \"print('Hello, World!')\" in result\n\n    printer = PythonCodePrinter({'standard':'python3', 'fully_qualified_modules': True})\n    pystr = printer.doprint(content)\n    module_imports_str = '\\n'.join('import %s' % k for k in printer.module_imports)\n    expected_result = module_imports_str + '\\n\\n' + pystr\n    assert result == expected_result\n"], "sample_1060": ["def test_PythonCodePrinter_printing_of_Infinity():\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(oo) == \"float('inf')\"\n    assert prntr.doprint(-oo) == \"float('-inf')\"\n    assert prntr.doprint(zoo) == \"float('nan')\"\n"], "sample_1063": ["def test_lambdify_with_integer_symbols():\n    x = symbols('x', integer=True)\n    f = lambdify(x, x**2)\n    assert f(3) == 9\n"], "sample_1065": ["def test_subfactorial():\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True, nonnegative=True)\n\n    assert subfactorial(-2) == zoo\n    assert subfactorial(0) == 1\n    assert subfactorial(1) == 0\n    assert subfactorial(5) == 44\n\n    assert subfactorial(n).is_integer is None\n    assert subfactorial(k).is_integer is True\n\n    assert subfactorial(n).is_nonnegative is None\n    assert subfactorial(k).is_nonnegative is True\n\n    assert subfactorial(n).is_odd is None\n    assert subfactorial(k + 1).is_odd is True\n    assert subfactorial(k + 2).is_odd is False\n\n    assert subfactorial(n).is_even is None\n    assert subfactorial(k + 1).is_even is False\n    assert subfactorial(k + 2).is_even is True\n\n    assert subfactorial(n).rewrite(uppergamma) == uppergamma(n + 1, -1)/S.Exp1\n"], "sample_1067": ["def test_issue_3539_edge_cases():\n    a = Wild('a')\n    x = Symbol('x')\n    assert (x - 2).match(a + x) == {a: -2}\n    assert (6/x).match(a/x) == {a: 6}\n    assert (6/x**2).match(a*x) is None\n"], "sample_1068": ["def test_Indexed_printing():\n    # test cases for Indexed printing\n    A = MatrixSymbol(\"A\", 3, 3)\n    i = Symbol('i', integer=True)\n    j = Symbol('j', integer=True)\n\n    assert mcode(A[i, j]) == \"A(i + 1, j + 1)\"\n    assert mcode(3 * A[i, j]) == \"3*A(i + 1, j + 1)\"\n\n    F = A[i, j].subs(A, A.T)\n    assert mcode(F) == \"A(j + 1, i + 1)\"\n"], "sample_1069": ["def test_glsl_code():\n    assert glsl_code(x**2) == \"pow(x, 2.0)\"\n    assert glsl_code(x**3) == \"pow(x, 3.0)\"\n    assert glsl_code(sin(x)) == \"sin(x)\"\n    assert glsl_code(cos(x)) == \"cos(x)\"\n    assert glsl_code(exp(x)) == \"exp(x)\"\n    assert glsl_code(log(x)) == \"log(x)\"\n    assert glsl_code(sqrt(x)) == \"sqrt(x)\"\n    assert glsl_code(1/x) == \"1.0/x\"\n    assert glsl_code(x/y) == \"x/y\"\n    assert glsl_code(x*y) == \"x*y\"\n    assert glsl_code(x - y) == \"x - y\"\n    assert glsl_code(x + y) == \"x + y\"\n    assert glsl_code(-x) == \"-x\"\n\n    A = Matrix([[1, 2], [3, 4]])\n    assert glsl_code(A) == \"mat2(1, 2, 3, 4)\"\n\n    v = Matrix([1, 2])\n    assert glsl_code(v) == \"vec2(1, 2)\"\n\n    f = Function('f')\n    assert glsl_code(f(x)) == \"f(x)\"\n"], "sample_1070": ["def test_log_nonpositive():\n    x = Symbol('x', nonpositive=True)\n    assert log(x).is_extended_real is False\n    assert log(x).is_finite is None\n\n    y = Symbol('y', negative=True)\n    assert log(y).is_extended_real is False\n    assert log(y).is_finite is True\n"], "sample_1071": ["def test_check_dimensions():\n    from sympy.physics.units import meter, second, kilogram\n    from sympy import symbols\n\n    x = symbols('x')\n    assert check_dimensions(meter + meter) == 2*meter\n    assert check_dimensions(meter + second) is None\n    raises(ValueError, lambda: check_dimensions(meter + 1))\n    raises(ValueError, lambda: check_dimensions(meter + x))\n    assert check_dimensions(kilogram * meter / second**2) == kilogram * meter / second**2\n    assert check_dimensions(kilogram * meter / second**2 + kilogram * meter / second**2) == 2*kilogram * meter / second**2\n"], "sample_1072": ["def test_frac_complex():\n    z = Symbol('z', complex=True)\n    assert frac(z).rewrite(floor) == z - floor(z)\n    assert frac(z).rewrite(ceiling) == z + ceiling(-z)\n\n    c1, c2 = symbols('c1 c2', real=True)\n    assert frac(c1 + I*c2) == frac(c1) + I*frac(c2)\n    assert frac(c1 - I*c2) == frac(c1) - I*frac(c2)\n\n    assert frac(I*(c1 + I*c2)) == I*frac(c1 + I*c2)\n    assert frac(-I*(c1 + I*c2)) == -I*frac(c1 + I*c2)\n\n    assert frac((c1 + I*c2)*(c1 - I*c2)) == frac(c1**2 + c2**2)\n"], "sample_1073": ["def test_sqrt_match():\n    assert _sqrt_match(1 + sqrt(2) + sqrt(3)) == [1, 1, 2]\n    assert _sqrt_match(1 + sqrt(2)*sqrt(3)) == [1, sqrt(2), 3]\n    assert _sqrt_match(sqrt(2) + sqrt(3)) == [0, 1, 2]\n    assert _sqrt_match(1 + sqrt(2) + sqrt(3) + sqrt(5)) == [1 + sqrt(3), 1, 2]\n    assert _sqrt_match(1 + sqrt(2)*sqrt(3) + sqrt(5)) == [1, sqrt(2), 3]\n"], "sample_1075": ["def test_beta_eval_expand_func():\n    x = Symbol('x')\n    y = Symbol('y')\n    assert beta(x, y)._eval_expand_func() == gamma(x)*gamma(y) / gamma(x + y)\n"], "sample_1076": ["def test_issue_16535_16536_fresnel():\n    from sympy import fresnelc, fresnels\n\n    expr1 = fresnelc(x)\n    expr2 = fresnels(x)\n\n    prntr = SymPyPrinter()\n    assert prntr.doprint(expr1) == '  # Not supported in Python with SymPy:\\n  # fresnelc\\nfresnelc(x)'\n    assert prntr.doprint(expr2) == '  # Not supported in Python with SymPy:\\n  # fresnels\\nfresnels(x)'\n"], "sample_1078": ["def test_IndexedBase_label():\n    i = Symbol('i', integer=True)\n    a = IndexedBase(i)\n    assert a.label == i\n    assert type(a.label) == Symbol\n\n    class SubClass(Symbol):\n        pass\n\n    x = SubClass('X')\n    base = IndexedBase(x)\n    assert base.label == x\n    assert type(base.label) == SubClass\n"], "sample_1080": ["def test_refine_non_Basic():\n    assert refine(1, Q.real(x)) == 1\n    assert refine(\"string\", Q.real(x)) == \"string\"\n    assert refine(None, Q.real(x)) is None\n"], "sample_1084": ["def test_issue_17471():\n    from sympy.solvers.diophantine import diop_solve\n    from sympy.abc import x, y\n    eq = 2*x + 3*y - 1\n    sol = diop_solve(eq)\n    assert imageset(Lambda((x, y), x), sol) == S.Integers\n"], "sample_1087": ["def test_fateman_poly_F_3():\n    f, g, h = fateman_poly_F_3(1)\n    F, G, H = dmp_fateman_poly_F_3(1, ZZ)\n\n    assert [ t.rep.rep for t in [f, g, h] ] == [F, G, H]\n\n    f, g, h = fateman_poly_F_3(3)\n    F, G, H = dmp_fateman_poly_F_3(3, ZZ)\n\n    assert [ t.rep.rep for t in [f, g, h] ] == [F, G, H]\n"], "sample_1088": ["def test_viete():\n    x, a, b, c, r1, r2 = symbols('x,a:c,r1:3')\n\n    assert viete(a*x**2 + b*x + c, [r1, r2], x) == [(r1 + r2, -b/a), (r1*r2, c/a)]\n\n    raises(MultivariatePolynomialError, lambda: viete(x*y))\n    raises(ValueError, lambda: viete(1, [r1, r2]))\n    raises(ValueError, lambda: viete(x, [r1, r2]))\n"], "sample_1089": ["def test_mask_nc():\n    A, B = symbols('A,B', commutative=False)\n    x, y = symbols('x,y')\n    eq = x*A + x*B\n    masked, d, _ = _mask_nc(eq)\n    assert masked == x*Dummy() + x*Dummy()\n    assert len(d) == 2\n    assert set(d.values()) == {A, B}\n"], "sample_1092": ["def test_cse_reps_toposort():\n    x, y = symbols('x y')\n    reps = [(x, y + 1), (y, 2)]\n    sorted_reps = cse_main.reps_toposort(reps)\n    assert sorted_reps == [(y, 2), (x, y + 1)]\n"], "sample_1094": ["def test_compare_pretty():\n    from sympy.core.function import UndefinedFunction\n    from sympy.core.symbol import symbols\n    x = symbols('x')\n    f = UndefinedFunction('f')\n    assert Basic._compare_pretty(f(x), x) == 1\n    assert Basic._compare_pretty(x, f(x)) == -1\n    assert Basic._compare_pretty(f(x), f(x)) == 0\n"], "sample_1096": ["def test_IndexedBase_with_Dummy():\n    i, j = symbols('i j', integer=True)\n    a = IndexedBase(Dummy('a'))\n    b = IndexedBase(Dummy('b'))\n    assert a[i, j] != b[i, j]\n    assert a[i, j].subs(a, b) == b[i, j]\n    assert a[i, j].subs(b, a) == a[i, j]\n"], "sample_1099": ["def test_eval_partial_derivative_expr2():\n\n    tau, alpha = symbols(\"tau alpha\")\n\n    # this is only some special expression\n    # tested: vector derivative\n    # tested: scalar derivative\n    # tested: tensor derivative\n    base_expr2 = A(i)*H(-i, j) + A(i)*A(-i)*A(j) + tau**alpha*A(j) + H(i, j)*A(-i)\n\n    tensor_derivative = PartialDerivative(base_expr2, H(k, m))._perform_derivative()\n    vector_derivative = PartialDerivative(base_expr2, A(k))._perform_derivative()\n    scalar_derivative = PartialDerivative(base_expr2, tau)._perform_derivative()\n\n    assert (tensor_derivative - (A(L_0)*L.metric(-L_0, -L_1)*L.delta(L_1, -k)*L.delta(j, -m) +\n        L.delta(i, -k)*L.delta(j, -m)*A(-i))) == 0\n\n    assert (vector_derivative - (tau**alpha*L.delta(j, -k) +\n        L.delta(L_0, -k)*A(-L_0)*A(j) +\n        A(L_0)*L.metric(-L_0, -L_1)*L.delta(L_1, -k)*A(j) +\n        A(L_0)*A(-L_0)*L.delta(j, -k) +\n        L.delta(L_0, -k)*H(-L_0, j) +\n        H(L_0, j)*L.metric(-L_0, -L_1)*L.delta(L_1, -k))).expand() == 0\n\n    assert (vector_derivative.contract_metric(L.metric).contract_delta(L.delta) -\n        (tau**alpha*L.delta(j, -k) + A(L_0)*A(-L_0)*L.delta(j, -k) + H(-k, j) + 2*A(j)*A(-k) + H(k, j))).expand() == 0\n\n    assert scalar_derivative - alpha*1/tau*tau**alpha*A(j) == 0\n"], "sample_1101": ["def test_schur_number():\n    assert SchurNumber(1) == 1\n    assert SchurNumber(2) == 4\n    assert SchurNumber(3) == 13\n    assert SchurNumber(4) == 44\n    assert SchurNumber(5).lower_bound() == (3**5 - 1)/2\n    raises(ValueError, lambda: SchurNumber(-1))\n    raises(ValueError, lambda: SchurNumber(0))\n    raises(ValueError, lambda: SchurNumber(S.Infinity))\n    raises(ValueError, lambda: SchurNumber(Rational(1, 2)))\n"], "sample_1106": ["def test_matadd_doit():\n    assert MatAdd(A, ZeroMatrix(n, m), evaluate=True) == A\n    assert MatAdd(A, -A, evaluate=True) == ZeroMatrix(n, m)\n    assert MatAdd(A, B, -B, evaluate=True) == A\n    assert MatAdd(A, A, evaluate=True) == 2*A\n"], "sample_1109": ["def test_frac_with_complex_numbers():\n    assert frac(1 + 2*I) == 1 + I*frac(2)\n    assert frac(-1 - 2*I) == -1 + I*frac(2)\n    assert frac(I*(1 + 2*I)) == I*frac(1 + 2*I)\n    assert frac((1 + 2*I)*(3 + 4*I)) == frac((1 + 2*I)*(3 + 4*I))\n    assert frac((1 + 2*I)/(3 + 4*I)) == frac((1 + 2*I)/(3 + 4*I))\n"], "sample_1111": ["def test_sqrt():\n    x = Symbol('x')\n    lines = [\n        '      2 |                                                     ..',\n        '        |                                                  ...  ',\n        '        |                                                ..     ',\n        '        |                                             ...       ',\n        '        |                                          ...          ',\n        '        |                                        ..             ',\n        '        |                                     ...               ',\n        '        |                                  ...                  ',\n        '        |                                ..                     ',\n        '        |                             ...                       ',\n        '      1 |--------------------------...--------------------------',\n        '        |                       ...                             ',\n        '        |                     ..                                ',\n        '        |                  ...                                  ',\n        '        |               ...                                     ',\n        '        |             ..                                        ',\n        '        |          ...                                          ',\n        '        |       ...                                             ',\n        '        |     ..                                                ',\n        '        |  ...                                                  ',\n        '      0 |_______________________________________________________',\n        '         0                          1                          4'\n    ]\n    assert lines == list(textplot_str(sqrt(x), 0, 4))\n"], "sample_1112": ["def test_is_palindromic():\n    assert is_palindromic(121) is True\n    assert is_palindromic(123) is False\n    assert is_palindromic(-121) is True\n    assert is_palindromic(0o121, 8) is True\n    assert is_palindromic(0x12321, 16) is True\n    assert is_palindromic(123456, 10) is False\n    raises(ValueError, lambda: is_palindromic(2, 1))\n"], "sample_1113": ["def test_block_collapse():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    D = MatrixSymbol('D', 2, 2)\n\n    X = BlockMatrix([[A, B], [C, D]])\n    assert block_collapse(X) == X\n\n    Y = BlockMatrix([[Identity(2), ZeroMatrix(2, 2)], [ZeroMatrix(2, 2), Identity(2)]])\n    assert block_collapse(Y*X) == BlockMatrix([[A, B], [C, D]])\n\n    Z = BlockMatrix([[A, ZeroMatrix(2, 2)], [ZeroMatrix(2, 2), D]])\n    assert block_collapse(Z) == BlockDiagMatrix(A, D)\n"], "sample_1114": ["def test_issue_18999():\n    n = Symbol('n', integer=True)\n    m = Symbol('m', integer=True)\n    assert Range(n, n + 49).is_finite_set is True\n    assert Range(n, 0).is_finite_set is True\n    assert Range(-3, n + 7).is_finite_set is True\n    assert Range(n, m).is_finite_set is True\n    assert Range(n + m, m - n).is_finite_set is True\n    assert Range(n, n + m + n).is_finite_set is True\n    assert Range(n, oo).is_finite_set is False\n    assert Range(-oo, n).is_finite_set is False\n    assert Range(n, -oo).is_finite_set is True\n    assert Range(oo, n).is_finite_set is True\n"], "sample_1116": ["def test_derivative_matrix_lines():\n    from sympy import symbols, MatrixSymbol\n    x = symbols('x')\n    A = MatrixSymbol('A', 2, 2)\n    A_diff = A.diff(x)\n    assert Inverse(A)._eval_derivative_matrix_lines(x) == [\n        (A_diff, -A.I*A.I),\n        (-A.I*A_diff*A.I, A.I)\n    ]\n"], "sample_1118": ["def test_matpow():\n    assert MatPow(C, 2).args == (C, 2)\n    assert MatPow(C, 2).shape == (n, n)\n    assert MatPow(A*E, 2).shape == (n, n)\n    assert MatPow(E*A, 2).shape == (m, m)\n    assert MatPow(C, 0) == Identity(n)\n    assert MatPow(C, 1) == C\n    assert MatPow(C, -1) == Inverse(C)\n    assert MatPow(Identity(n), 3) == Identity(n)\n    assert MatPow(ZeroMatrix(n, n), 3) == ZeroMatrix(n, n)\n\n    raises(TypeError, lambda: MatPow(n, 2))\n    raises(NonSquareMatrixError, lambda: MatPow(A, 2))\n    raises(NonInvertibleMatrixError, lambda: MatPow(ZeroMatrix(n, n), -1))\n\n    # Test doit\n    assert MatPow(C, 2).doit() == C*C\n    assert MatPow(C, -2).doit() == Inverse(C)*Inverse(C)\n    assert MatPow(C, 0).doit() == Identity(n)\n    assert MatPow(Identity(n), 3).doit() == Identity(n)\n    assert MatPow(ZeroMatrix(n, n), 3).doit() == ZeroMatrix(n, n)\n"], "sample_1122": ["def test_issue_20523():\n    from sympy import symbols, I, exp_polar, polar_lift, principal_branch\n    x = symbols('x')\n    assert exp_polar(2*I*pi*x).simplify() == exp_polar(0)\n    assert polar_lift(exp_polar(2*I*pi*x)).simplify() == 1\n    assert principal_branch(exp_polar(2*I*pi*x), 2*pi).simplify() == 1\n"], "sample_1123": ["def test_CondSet_as_relational():\n    c = ConditionSet(x, x > 5, Interval(1, 7))\n    assert c.as_relational(6) == And(6 > 5, Contains(6, Interval(1, 7)))\n    assert c.as_relational(8) == And(8 > 5, Contains(8, Interval(1, 7)))\n    assert c.as_relational(w) == And(w > 5, Contains(w, Interval(1, 7)))\n    c = ConditionSet(x, y > 5, Interval(1, 7))\n    assert c.as_relational(6) == And(y > 5, Contains(6, Interval(1, 7)))\n    assert c.as_relational(8) == And(y > 5, Contains(8, Interval(1, 7)))\n    assert c.as_relational(w) == And(y > 5, Contains(w, Interval(1, 7)))\n"], "sample_1124": ["def test_FracElement_set_field():\n    F, x,y,z = field(\"x,y,z\", ZZ)\n    G, a,b,c = field(\"a,b,c\", QQ)\n\n    f = (x**2 + 3*y)/z\n    g = f.set_field(G)\n\n    assert g.field == G\n    assert g.numer == G.ring.gens[0]**2 + 3*G.ring.gens[1]\n    assert g.denom == G.ring.gens[2]\n"], "sample_1125": ["def test_hermitian_operator():\n    H = Operator('H', is_hermitian=True)\n    assert Dagger(H) == H\n    assert H.inv() == H**(-1)\n    assert H._eval_power(2) == H*H\n    assert H._eval_inverse() == H\n"], "sample_1126": ["def test_dagger_add():\n    A = Operator('A')\n    B = Operator('B')\n    assert Dagger(A + B) == Dagger(A) + Dagger(B)\n    assert Dagger(A + Dagger(B)) == Dagger(A) + B\n    assert Dagger(Dagger(A) + B) == A + Dagger(B)\n"], "sample_1128": ["def test_point_vel_with_intermediate_frame():\n    t = dynamicsymbols._t\n    q1, q2 = dynamicsymbols('q1 q2')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    S = ReferenceFrame('S')\n    O = Point('O')\n    P = Point('P')\n    Q = Point('Q')\n    O.set_vel(N, q1 * N.x)\n    P.set_pos(O, q2 * B.y)\n    Q.set_pos(P, q1 * S.z)\n    B.set_ang_vel(N, q1 * B.z)\n    S.set_ang_vel(B, q2 * S.x)\n    raises(ValueError, lambda : Q.vel(N)) # Q's velocity cannot be calculated\n    P.set_vel(B, q2 * B.x)\n    assert Q.vel(N) == (q1.diff(t) + q2) * N.x + q2.diff(t) * B.x + q1.diff(t) * B.y + q1 * B.z + q1.diff(t) * S.z\n"], "sample_1137": ["def test_check_dimensions():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    w = Quantity(\"w\")\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    assert check_dimensions(u + v) == u + v\n    assert check_dimensions(u - v) == u - v\n    raises(ValueError, lambda: check_dimensions(u + w))\n    raises(ValueError, lambda: check_dimensions(u - w))\n    raises(ValueError, lambda: check_dimensions(u + 1))\n    raises(ValueError, lambda: check_dimensions(u - 1))\n"], "sample_1139": ["def test_issue_18999():\n    n = Symbol('n', integer=True)\n    assert Range(n, n + 20, 2).is_finite_set is True\n    assert Range(n, 0).is_finite_set is True\n    assert Range(-3, n + 7).is_finite_set is True\n    assert Range(n, m).is_finite_set is None\n    assert Range(n + m, m - n).is_finite_set is None\n    assert Range(n, n + m + n).is_finite_set is None\n    assert Range(n, oo).is_finite_set is False\n    assert Range(-oo, n).is_finite_set is False\n    assert Range(n, -oo).is_finite_set is True\n    assert Range(oo, n).is_finite_set is True\n"], "sample_1144": ["def test_requires_partial_edge_cases():\n    x, y = symbols('x y')\n\n    # Test requires_partial with an expression that doesn't have free symbols\n    assert requires_partial(5) is False\n\n    # Test requires_partial with a Derivative that has no free symbols\n    f = Derivative(5, x)\n    assert requires_partial(f) is False\n\n    # Test requires_partial with a Derivative that has an integer as the variable\n    n = symbols('n', integer=True)\n    f = Derivative(x**2, n)\n    assert requires_partial(f) is False\n\n    # Test requires_partial with a nested Derivative\n    f = Derivative(Derivative(x**2, x), y)\n    assert requires_partial(f) is True\n"], "sample_1145": ["def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n"], "sample_1149": ["def test_SingletonRegistry():\n    # Test that S can be used as a shortcut for sympify\n    assert S(1) is S.One\n    assert S(0) is S.Zero\n    assert S('1/2') is S.Half\n\n    # Test that S can be used to access singleton instances\n    assert S.Zero is S(0)\n    assert S.One is S(1)\n    assert S.Half is S('1/2')\n\n    # Test that S raises an AttributeError for unknown attributes\n    try:\n        S.Unknown\n        assert False, \"S.Unknown should raise an AttributeError\"\n    except AttributeError:\n        pass\n"], "sample_1150": ["def test_issue_18999():\n    n = Symbol('n', integer=True)\n    m = Symbol('m', integer=True)\n    assert Range(n, n + 49).is_finite_set is True\n    assert Range(n, 0).is_finite_set is True\n    assert Range(-3, n + 7).is_finite_set is True\n    assert Range(n, m).is_finite_set is None\n    assert Range(n + m, m - n).is_finite_set is None\n    assert Range(n, n + m + n).is_finite_set is None\n    assert Range(n, oo).is_finite_set is False\n    assert Range(-oo, n).is_finite_set is False\n    assert Range(n, -oo).is_finite_set is True\n    assert Range(oo, n).is_finite_set is True\n"], "sample_1151": ["def test_issue_21462():\n    assert (x**2 + 1).is_positive is None\n    assert (x**2 + 1).is_nonnegative is True\n    assert (x**2 - 1).is_positive is None\n    assert (x**2 - 1).is_nonnegative is None\n"], "sample_1152": ["def test_issue_18445():\n    x, y = symbols('x y', real=True)\n    assert powsimp((x + y)**2 / (x**2 * (1 + y/x)**2)) == 1\n    assert powsimp((x + y)**2 / (y**2 * (1 + x/y)**2)) == 1\n"], "sample_1154": ["def test__linsolve_underdetermined():\n    assert _linsolve([x + y], [x, y]) == {x: -y, y: y}\n    assert _linsolve([x + y, x + z], [x, y, z]) == {x: -y - z, y: y, z: z}\n    assert _linsolve([x + 2*y], [x, y]) == {x: -2*y, y: y}\n"], "sample_1155": ["def test_extension_option():\n    assert construct_domain([GoldenRatio], extension=True) != (EX, [EX(GoldenRatio)])\n    assert construct_domain([Catalan], extension=True) != (EX, [EX(Catalan)])\n    assert construct_domain([E], extension=True) != (EX, [EX(E)])\n    assert construct_domain([pi], extension=True) != (EX, [EX(pi)])\n\n    # Test that the extension option works with multiple algebraic numbers\n    assert construct_domain([sqrt(2), sqrt(3)], extension=True) != (EX, [EX(sqrt(2)), EX(sqrt(3))])\n"], "sample_1157": ["def test_implicit_multiplication():\n    transformations = standard_transformations + (implicit_multiplication,)\n    x = Symbol('x')\n    y = Symbol('y')\n\n    assert parse_expr(\"2x\", transformations=transformations) == 2*x\n    assert parse_expr(\"2 x\", transformations=transformations) == 2*x\n    assert parse_expr(\"2*x\", transformations=transformations) == 2*x\n    assert parse_expr(\"(2+3)x\", transformations=transformations) == (2+3)*x\n    assert parse_expr(\"(2+3) x\", transformations=transformations) == (2+3)*x\n    assert parse_expr(\"(2+3)*x\", transformations=transformations) == (2+3)*x\n    assert parse_expr(\"2(3+4)\", transformations=transformations) == 2*(3+4)\n    assert parse_expr(\"2 (3+4)\", transformations=transformations) == 2*(3+4)\n    assert parse_expr(\"2*(3+4)\", transformations=transformations) == 2*(3+4)\n    assert parse_expr(\"2sin(x)\", transformations=transformations) == 2*sin(x)\n    assert parse_expr(\"2 sin(x)\", transformations=transformations) == 2*sin(x)\n    assert parse_expr(\"2* sin(x)\", transformations=transformations) == 2*sin(x)\n    assert parse_expr(\"2xy\", transformations=transformations) == 2*x*y\n    assert parse_expr(\"2 x y\", transformations=transformations) == 2*x*y\n    assert parse_expr(\"2*x*y\", transformations=transformations) == 2*x*y\n"], "sample_1158": ["def test_sympify_dict_keys():\n    d = {1.5: 2, 'a': 3}\n    sympified_d = sympify(d)\n    assert list(sympified_d.keys()) == [Float(1.5), Symbol('a')]\n    assert list(sympified_d.values()) == [2, 3]\n"], "sample_1159": ["def test_check_assumptions_against():\n    x = Symbol('x', positive=True)\n    assert check_assumptions(1, against=x) is True\n    assert check_assumptions(-1, against=x) is False\n    i = Symbol('i', integer=True)\n    assert check_assumptions(i, against=x) is None\n    assert check_assumptions(Dummy(integer=None), against=x) is None\n    assert check_assumptions(Dummy(integer=False), against=x) is None\n    assert check_assumptions(Dummy(positive=True), against=x) is True\n    assert check_assumptions(Dummy(positive=False), against=x) is False\n"], "sample_1162": ["def test_MatMul_kind():\n    A = MatrixSymbol('A', 2,2)\n    B = MatrixSymbol('B', 2,2)\n    assert MatMul(A, B).kind is MatrixKind(NumberKind)\n    assert MatMul(A, comm_x).kind is MatrixKind(NumberKind)\n    assert MatMul(noncomm_x, A).kind is UndefinedKind\n"], "sample_1166": ["def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n"], "sample_1170": ["def test_ElementwiseApplyFunction():\n    from sympy.tensor.array.expressions.array_expressions import ArraySymbol, ElementwiseApplyFunction\n    X = ArraySymbol('X', (2, 2))\n    expr = ElementwiseApplyFunction(sin, X)\n    assert str(expr) == \"sin.(X)\"\n"], "sample_1171": ["def test_issue_18999():\n    n = Symbol('n', integer=True)\n    assert Range(n, n + 49).is_finite_set is True\n    assert Range(n, 0).is_finite_set is True\n    assert Range(-3, n + 7).is_finite_set is True\n    assert Range(n, m).is_finite_set is True\n    assert Range(n + m, m - n).is_finite_set is True\n    assert Range(n, n + m + n).is_finite_set is True\n    assert Range(n, oo).is_finite_set is False\n    assert Range(-oo, n).is_finite_set is False\n    assert Range(n, -oo).is_finite_set is True\n    assert Range(oo, n).is_finite_set is True\n"], "sample_1172": ["def test_solve_generic():\n    f_1 = x**2 + y - 1\n    f_2 = x + y**2 - 1\n\n    assert solve_generic([f_1, f_2], (x, y)) == \\\n        [(-sqrt(2)/2 + sqrt(6)/6, sqrt(2)/2 + sqrt(6)/6),\n         (-sqrt(2)/2 - sqrt(6)/6, sqrt(2)/2 - sqrt(6)/6)]\n\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    a, b = sqrt(2) - 1, -sqrt(2) - 1\n\n    assert solve_generic([f_1, f_2, f_3], (x, y, z)) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0)]\n\n    raises(NotImplementedError, lambda: solve_generic([x**3 - y**3], (x, y)))\n    raises(NotImplementedError, lambda: solve_generic(\n        [z, -2*x*y**2 + x + y**2*z, y**2*(-z - 4) + 2]))\n    raises(PolynomialError, lambda: solve_generic([1/x], x))\n"], "sample_1173": ["def test_implicit_multiplication():\n    transformations = standard_transformations + (implicit_multiplication,)\n    x = Symbol('x')\n    y = Symbol('y')\n\n    assert parse_expr(\"2x\", transformations=transformations) == 2*x\n    assert parse_expr(\"2 x\", transformations=transformations) == 2*x\n    assert parse_expr(\"2(x+y)\", transformations=transformations) == 2*(x+y)\n    assert parse_expr(\"(x+y)2\", transformations=transformations) == (x+y)*2\n    assert parse_expr(\"(x+y)(x-y)\", transformations=transformations) == (x+y)*(x-y)\n    assert parse_expr(\"x(y+z)\", transformations=transformations) == x*(y+z)\n    assert parse_expr(\"(y+z)x\", transformations=transformations) == (y+z)*x\n"], "sample_1182": ["def test_issue_20762_symbol():\n    antlr4 = import_module(\"antlr4\")\n    if not antlr4:\n        skip('antlr not installed.')\n    # Make sure pycode removes curly braces from subscripted variables\n    expr = parse_latex(r'a_{b} \\cdot b')\n    assert pycode(expr) == 'a_b*b'\n    expr = parse_latex(r'a_{11} \\cdot b')\n    assert pycode(expr) == 'a_11*b'\n    expr = parse_latex(r'a_{b_{c}} \\cdot b')\n    assert pycode(expr) == 'a_b_c*b'\n"], "sample_1183": ["def test_FracField_from_expr():\n    F, x, y = field(\"x,y\", ZZ)\n    assert F.from_expr(x) == F(x)\n    assert F.from_expr(y) == F(y)\n    assert F.from_expr(1/x) == F(1/x)\n    assert F.from_expr(1/y) == F(1/y)\n    assert F.from_expr(x/y) == F(x/y)\n    assert F.from_expr((x + 1)/(y - 1)) == F((x + 1)/(y - 1))\n    assert F.from_expr(exp(x)) is None\n    assert F.from_expr(sin(x)) is None\n"], "sample_1185": ["def test_compogen():\n    assert compogen([sin(x), cos(x)], x) == sin(cos(x))\n    assert compogen([x**2 + x + 1, sin(x)], x) == sin(x)**2 + sin(x) + 1\n    assert compogen([sqrt(x), 6*x**2 - 5], x) == sqrt(6*x**2 - 5)\n    assert compogen([sin(x), sqrt(x), cos(x), x**2 + 1], x) == sin(sqrt(cos(x**2 + 1)))\n    assert compogen([x**2 - x - 1, x**2 + x], x) == -x**2 - x + (x**2 + x)**2 - 1\n    assert compogen([Max(3, x)], x) == Max(3, x)\n    u = 2*x + 3\n    assert compogen([Max(sqrt(x), x**2), u], x) == Max(sqrt(2*x + 3), (2*x + 3)**2)\n"], "sample_1186": ["def test_array_equality():\n    for ArrayType in array_types:\n        A = ArrayType([1, 2, 3])\n        B = ArrayType([1, 2, 3])\n        C = ArrayType([4, 5, 6])\n        D = ArrayType([1, 2])\n\n        assert A == B\n        assert A != C\n        assert A != D\n\n        # Test equality with different types\n        if ArrayType is ImmutableDenseNDimArray:\n            E = MutableDenseNDimArray([1, 2, 3])\n            assert A == E\n"], "sample_1189": ["def test_lambdify_cse_multiple_statements():\n        return (), exprs\n\n    args = symbols('x y')\n    exprs = [x**2, x*y]\n    num_args = (1.0, 2.0)\n    subs_dict = dict(zip(args, num_args))\n    ref = [e.subs(subs_dict).evalf() for e in exprs]\n\n    f = lambdify(args, exprs, cse=dummy_cse)\n    result = f(*num_args)\n    assert all(abs(result[i] - r) < 1e-15 for i, r in enumerate(ref))\n"], "sample_1190": ["def test_get_units_non_prefixed():\n    assert set(SI.get_units_non_prefixed()) == {\n        meter, second, joule, kilogram, day, volt, ohm, coulomb, molar_gas_constant,\n        vacuum_permittivity, elementary_charge, gravitational_constant\n    }\n"], "sample_1191": ["def test_hermite_normal():\n    m = DM([[12, 6, 4], [3, 9, 6], [2, 16, 14]], ZZ)\n    hnf = DM([[10, 0, 2], [0, 15, 3], [0, 0, 2]], ZZ)\n    assert hermite_normal_form(m).to_dense() == hnf\n\n    raises(DMDomainError, lambda: hermite_normal_form(DM([[1]], QQ)))\n    raises(DMDomainError, lambda: hermite_normal_form(DM([[1]], ZZ), D=QQ(1)))\n\n    # Test with a non-full-rank matrix\n    m = DM([[1, 2], [2, 4]], ZZ)\n    hnf = DM([[1, 2], [0, 0]], ZZ)\n    assert hermite_normal_form(m).to_dense() == hnf\n\n    # Test with a rectangular matrix\n    m = DM([[1, 2, 3], [4, 5, 6]], ZZ)\n    hnf = DM([[1, 0, 1], [0, 1, 1]], ZZ)\n    assert hermite_normal_form(m).to_dense() == hnf\n\n    # Test the mod D algorithm\n    m = DM([[12, 6, 4], [3, 9, 6], [2, 16, 14]], ZZ)\n    hnf = DM([[10, 0, 2], [0, 15, 3], [0, 0, 2]], ZZ)\n    assert hermite_normal_form(m, D=30).to_dense() == hnf\n"], "sample_1192": ["def test_disambiguate():\n    x = Symbol('x')\n    y = Symbol('y')\n    assert disambiguate(x, x) == (x, x_1)\n    assert disambiguate(x, x, x) == (x, x_1, x_2)\n    assert disambiguate(x, y, x) == (x, y, x_1)\n    assert disambiguate(x, Dummy('x')) == (x, x_1)\n    assert disambiguate(Dummy('x'), Dummy('x')) == (x, x_1)\n    assert disambiguate(x + 1, x + 2) == (x + 1, x_1 + 2)\n    assert disambiguate(x + 1, x + 2, x + 3) == (x + 1, x_1 + 2, x_2 + 3)\n"], "sample_1193": ["def test_are_coplanar():\n    a, b = Point3D(0, 0, 0), Point3D(1, 1, 1)\n    assert are_coplanar(a) == False\n    assert are_coplanar(a, b) == False\n    assert are_coplanar(a, a, b) == True\n    assert are_coplanar(a, b, b) == True\n    assert are_coplanar(a, b, Point3D(2, 2, 2)) == True\n    assert are_coplanar(a, b, Point3D(1, 1, 2)) == False\n    assert are_coplanar(Point3D(0, 0, 0), Point3D(1, 0, 0), Point3D(1, 1, 0), Point3D(1, 1, 1)) == False\n    assert are_coplanar(Point3D(0, 0, 0), Point3D(1, 0, 0), Point3D(1, 1, 0), Point3D(0, 1, 0)) == True\n"], "sample_1194": ["def test_julia_user_functions():\n    x = symbols('x')\n    f = Function('f')\n    g = Function('g')\n\n    custom_functions = {\n        \"f\": \"existing_julia_fcn\",\n        \"g\": [(lambda x: x.is_Matrix, \"my_mat_fcn\"),\n              (lambda x: not x.is_Matrix, \"my_fcn\")]\n    }\n\n    assert julia_code(f(x), user_functions=custom_functions) == \"existing_julia_fcn(x)\"\n    assert julia_code(g(x), user_functions=custom_functions) == \"my_fcn(x)\"\n    assert julia_code(g(Matrix([[1, x]])), user_functions=custom_functions) == \"my_mat_fcn([1 x])\"\n"], "sample_1195": ["def test_gamma_trace():\n    i, j, k = tensor_indices('i,j,k', LorentzIndex)\n    A = TensorHead('A', [LorentzIndex])\n    t = G(i)*G(j)\n    ts = gamma_trace(t)\n    assert _is_tensor_eq(ts, 4*LorentzIndex.metric(i, j))\n\n    t = G(i)*A(k)*G(j)\n    ts = gamma_trace(t)\n    assert _is_tensor_eq(ts, 4*A(k)*LorentzIndex.metric(i, j))\n\n    t = G(i)*G(j)*G(k)\n    ts = gamma_trace(t)\n    assert _is_tensor_eq(ts, 0)\n\n    t = G(i)*G(j)*G(k)*G(-k)\n    ts = gamma_trace(t)\n    assert _is_tensor_eq(ts, -2*G(j)*G(i))\n"], "sample_1196": ["def test_contains_eval():\n    x = Symbol('x')\n    s = FiniteSet(1, 2, 3)\n    assert Contains(1, s).eval(1, s) is S.true\n    assert Contains(4, s).eval(4, s) is S.false\n    assert Contains(x, s).eval(x, s) == Contains(x, s)\n    assert Contains(1, S.Integers).eval(1, S.Integers) is S.true\n    assert Contains(x, S.Integers).eval(x, S.Integers) == Contains(x, S.Integers)\n"], "sample_1197": ["def test_get_units_non_prefixed():\n    assert set(SI.get_units_non_prefixed()) == {\n        meter, second, kilogram, ampere, kelvin, mole, candela\n    }\n    assert set(SI.extend(base=(meter,), name=\"SI_extended\").get_units_non_prefixed()) == {\n        meter, second, kilogram, ampere, kelvin, mole, candela\n    }\n"], "sample_1198": ["def test_parser_mathematica_from_fullform_to_sympy():\n    parser = MathematicaParser()\n\n        return parser._from_fullformsympy_to_sympy(parser._from_fullformlist_to_fullformsympy(\n            parser._from_fullform_to_fullformlist(expr)))\n\n    assert chain(\"Sin[x]\") == sin(x)\n    assert chain(\"Cos[x]\") == cos(x)\n    assert chain(\"Tan[x]\") == tan(x)\n    assert chain(\"Cot[x]\") == 1/tan(x)\n    assert chain(\"Sec[x]\") == 1/cos(x)\n    assert chain(\"Csc[x]\") == 1/sin(x)\n    assert chain(\"ArcSin[x]\") == asin(x)\n    assert chain(\"ArcCos[x]\") == acos(x)\n    assert chain(\"ArcTan[x]\") == atan(x)\n    assert chain(\"Exp[x]\") == exp(x)\n    assert chain(\"Log[x]\") == log(x)\n    assert chain(\"Sqrt[x]\") == sqrt(x)\n    assert chain(\"Mod[x, y]\") == Mod(x, y)\n    assert chain(\"Max[x, y]\") == Max(x, y)\n    assert chain(\"Min[x, y]\") == Min(x, y)\n    assert chain(\"Pochhammer[x, y]\") == rf(x, y)\n    assert chain(\"ExpIntegralEi[x]\") == Ei(x)\n    assert chain(\"SinIntegral[x]\") == Si(x)\n    assert chain(\"CosIntegral[x]\") == Ci(x)\n    assert chain(\"AiryAi[x]\") == airyai(x)\n    assert chain(\"AiryAiPrime[x]\") == airyaiprime(x)\n    assert chain(\"AiryBi[x]\") == airybi(x)\n    assert chain(\"AiryBiPrime[x]\") == airybiprime(x)\n    assert chain(\"LogIntegral[x]\") == li(x)\n    assert chain(\"PrimePi[x]\") == primepi(x)\n    assert chain(\"Prime[x]\") == prime(x)\n    assert chain(\"PrimeQ[x]\") == isprime(x)\n"], "sample_1199": ["def test_tensor_product_trace():\n    assert Tr(TP(A, B)) == Tr(A)*Tr(B)\n    assert Tr(TP(A, B), indices=[0]) == Tr(A)*B\n    assert Tr(TP(A, B), indices=[1]) == A*Tr(B)\n    assert Tr(TP(A, B), indices=[0, 1]) == Tr(A)*Tr(B)\n    assert Tr(TP(Density([A]), B)) == Tr(Density([A]))*Tr(B)\n"], "sample_1200": ["def test_unit_system_get_default():\n    default_unit_system = UnitSystem.get_default_unit_system()\n    assert default_unit_system.name == \"SI\"\n    assert isinstance(default_unit_system, UnitSystem)\n"], "sample_1201": ["def test_conversion_of_derived_units():\n    assert convert_to(statvolt, volt, cgs_gauss) == 299792458*volt\n    assert convert_to(volt, statvolt, cgs_gauss) == statvolt/299792458\n    assert convert_to(ohm, erg/statcoulomb**2/second, cgs_gauss) == centimeter/statcoulomb**2*sqrt(gram)/second\n    assert convert_to(farad, statcoulomb/volt, cgs_gauss) == statcoulomb/(299792458*volt)\n    assert convert_to(henry, statvolt*second/statampere, cgs_gauss) == statvolt*second/statampere\n"], "sample_1207": ["def test_T_class():\n    assert str(T) == transformations\n    assert T[:5] == standard_transformations\n    assert T[3, 11] == (_transformation[3], _transformation[11])\n    assert T[:] == tuple(_transformation.values())\n"], "sample_1209": ["def test_prefix_properties():\n    m = PREFIXES['m']\n    k = PREFIXES['k']\n\n    assert m.name == 'milli'\n    assert m.abbrev == 'm'\n    assert m.scale_factor == S.One / 1000\n    assert m.base == 10\n\n    assert k.name == 'kilo'\n    assert k.abbrev == 'k'\n    assert k.scale_factor == S(1000)\n    assert k.base == 10\n\n    assert str(m) == 'm'\n    assert repr(m) == \"Prefix('milli', 'm', -3)\"\n\n    assert str(k) == 'k'\n    assert repr(k) == \"Prefix('kilo', 'k', 3)\"\n"], "sample_2": ["def test_ccddata_header_is_case_sensitive():\n    ccd_data = create_ccd_data()\n    key = 'SoMeKEY'\n    ccd_data.header[key] = 10\n    assert key.lower() not in ccd_data.header\n    assert key.upper() not in ccd_data.header\n    assert key in ccd_data.header\n"], "sample_4": ["def test_read_html_table_format_error(self, tmp_path):\n    \"\"\"Test if format is not 'ascii.html'.\"\"\"\n    fp = tmp_path / \"test_read_html_table_format_error.html\"\n\n    with pytest.raises(ValueError, match=\"format must be 'ascii.html', not\"):\n        read_html_table(fp, format=\"ascii.csv\")\n"], "sample_11": ["def test_sliced_low_level_wcs_repr_with_no_pixel_bounds():\n    wcs = WCS_SPECTRAL_CUBE\n    wcs.pixel_bounds = None\n    sliced_wcs = SlicedLowLevelWCS(wcs, np.s_[:, 0, :])\n    assert \"Bounds\" not in str(sliced_wcs)\n"], "sample_15": ["    def test_trace(self):\n        q = np.array([[1, 2], [3, 4]]) * u.m\n        assert np.trace(q).unit == u.m\n        assert np.trace(q) == 5 * u.m\n"], "sample_17": ["    def setup_method(self):\n        self.pv_dtype = np.dtype([(\"p\", \"f8\"), (\"v\", \"f8\")])\n        self.pv_t_dtype = np.dtype(\n            [(\"pv\", np.dtype([(\"pp\", \"f8\"), (\"vv\", \"f8\")])), (\"t\", \"f8\")]\n        )\n\n        self.pv = np.array([(1.0, 0.25), (2.0, 0.5), (3.0, 0.75)], self.pv_dtype)\n        self.pv_t = np.array(\n            [((4.0, 2.5), 0.0), ((5.0, 5.0), 1.0), ((6.0, 7.5), 2.0)], self.pv_t_dtype\n        )\n\n        self.pv_unit = u.StructuredUnit((u.km, u.km / u.s), (\"p\", \"v\"))\n        self.pv_t_unit = u.StructuredUnit((self.pv_unit, u.s), (\"pv\", \"t\"))\n\n        self.q_pv = self.pv << self.pv_unit\n        self.q_pv_t = self.pv_t << self.pv_t_unit\n"], "sample_18": ["    def setup_class(self):\n        self.q = u.Quantity(np.arange(1.0, 5.0), \"m/s\")\n        self.q.info.name = \"v\"\n        self.q.info.description = \"air speed of a african swallow\"\n"], "sample_24": ["    def test_einsum(self):\n        out = np.einsum(\"ij,jk->ik\", self.ma, self.mb)\n        expected = np.einsum(\"ij,jk->ik\", self.a, self.b)\n        expected_mask = np.einsum(\"ij,jk->ik\", self.mask_a.astype(int), self.mask_b.astype(int)) > 0\n        assert_array_equal(out.unmasked, expected)\n        assert_array_equal(out.mask, expected_mask)\n"], "sample_40": ["def test_with_H0():\n    from ..cosmology import default_cosmology\n    H0 = default_cosmology.get().H0\n\n    # Test that the equivalency works for both little-h and physical units\n    h100_val_unit = u.Unit(H0.to((u.km/u.s)/u.Mpc).value/100 * u.littleh)\n    assert (1*h100_val_unit).to_value(1, equivalencies=u.with_H0(H0)) == 1.\n    assert (1*u.littleh).to_value(h100_val_unit, equivalencies=u.with_H0(H0)) == 1.\n\n    # Test that the equivalency fails if we try to use it with incompatible units\n    with pytest.raises(u.UnitsError):\n        (1*u.Mpc).to_value(u.littleh, equivalencies=u.with_H0(H0))\n"], "sample_45": ["def test_trunc_func_with_timezone_transition(self):\n    \"\"\"\n    If the truncated datetime transitions to a different offset (daylight saving)\n    then the returned value will have that new timezone/offset.\n    \"\"\"\n    start_datetime = datetime(2018, 3, 25, 1, 30, 50, 321)\n    end_datetime = datetime(2018, 11, 4, 1, 10, 50, 123)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n    self.create_model(end_datetime, start_datetime)\n\n    nyc = pytz.timezone('America/New_York')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=DateTimeField(), tzinfo=nyc)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(nyc), kind, nyc)),\n                (end_datetime, truncate_to(end_datetime.astimezone(nyc), kind, nyc))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_datetime_kind('hour')\n    test_datetime_kind('day')\n    test_datetime_kind('week')\n    test_datetime_kind('month')\n"], "sample_46": ["    def setUpTestData(cls):\n        cls.objs = [\n            UUIDModel.objects.create(field=uuid.uuid4()),\n            UUIDModel.objects.create(field='550e8400e29b41d4a716446655440000'),\n        ]\n"], "sample_52": ["def test_modelchoicefield_with_limit_choices_to(self):\n    f = forms.ModelChoiceField(Category.objects.all(), limit_choices_to={'name__startswith': 'A'})\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c2.pk, 'A test'),\n    ])\n    with self.assertRaises(ValidationError):\n        f.clean(self.c1.id)\n    self.assertEqual(f.clean(self.c2.id).name, 'A test')\n"], "sample_64": ["    def test_set_cookie(self):\n        response = HttpResponse()\n        response.set_cookie('foo', 'bar')\n        self.assertIn('foo=bar', response.cookies.output(header=''))\n"], "sample_67": ["    def test_disabled_fields(self):\n        class DisabledFieldsForm(forms.ModelForm):\n            class Meta:\n                model = Category\n                fields = '__all__'\n                widgets = {\n                    'name': forms.TextInput(attrs={'disabled': True}),\n                }\n\n        form = DisabledFieldsForm()\n        self.assertTrue(form.fields['name'].disabled)\n        self.assertFalse(form.fields['slug'].disabled)\n"], "sample_73": ["    def setUp(self):\n        super().setUp()\n        self._temp_dir = temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, 'test'))\n        self.addCleanup(shutil.rmtree, temp_dir)\n"], "sample_75": ["    def setUpTestData(cls):\n        cls.book1 = Book.objects.create(title='Poems')\n        cls.book2 = Book.objects.create(title='Jane Eyre')\n        cls.author1 = Author.objects.create(name='Charlotte', first_book=cls.book1)\n        cls.author2 = Author.objects.create(name='Anne', first_book=cls.book1)\n"], "sample_88": ["def test_sanitize_address_with_idna(self):\n    \"\"\"\n    Email addresses with non-ASCII domains are properly sanitized using IDNA.\n    \"\"\"\n    email_address = 'to@\u00f6\u00e4\u00fc.com'\n    sanitized_email = sanitize_address(email_address, encoding='utf-8')\n    self.assertEqual(sanitized_email, 'to@xn--4ca9at.com')\n"], "sample_90": ["    def test_disabled_fields(self):\n        class DisabledFieldsForm(forms.ModelForm):\n            class Meta:\n                model = Category\n                fields = '__all__'\n                widgets = {\n                    'name': forms.TextInput(attrs={'disabled': True}),\n                }\n\n        form = DisabledFieldsForm({'name': 'Entertainment', 'slug': 'entertainment', 'url': 'entertainment'})\n        self.assertTrue(form.is_valid())\n        instance = form.save()\n        self.assertEqual(instance.name, '')\n        self.assertEqual(instance.slug, 'entertainment')\n        self.assertEqual(instance.url, 'entertainment')\n"], "sample_93": ["def test_exists_subquery_annotation(self):\n    \"\"\"Exists subquery annotations are excluded from the GROUP BY.\"\"\"\n    has_long_books_qs = Book.objects.filter(\n        publisher=OuterRef('pk'),\n        pages__gt=400,\n    ).values('publisher')\n    publisher_qs = Publisher.objects.annotate(\n        has_long_books=Exists(has_long_books_qs),\n    ).annotate(count=Count('book'))\n    with self.assertNumQueries(1) as ctx:\n        list(publisher_qs)\n    self.assertEqual(ctx[0]['sql'].count('SELECT'), 2)\n"], "sample_95": ["    def test_patch_vary_headers(self):\n        response = HttpResponse()\n        patch_vary_headers(response, ['Accept-Language'])\n        self.assertEqual(response['Vary'], 'Accept-Language')\n"], "sample_96": ["def test_actions_unique_with_custom_name(self):\n        pass\n\n        pass\n\n    class BandAdmin(ModelAdmin):\n        actions = (action1, action2)\n\n    self.assertIsValid(BandAdmin, Band)\n"], "sample_99": ["def test_trunc_func_with_timezone_transition_crossing(self):\n    sao = pytz.timezone('America/Sao_Paulo')\n    start_datetime = datetime(2016, 10, 16, 1)\n    end_datetime = datetime(2017, 2, 19, 23)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=DateTimeField(), tzinfo=sao)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(sao), kind, sao)),\n                (end_datetime, truncate_to(end_datetime.astimezone(sao), kind, sao))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_datetime_kind('day')\n    test_datetime_kind('hour')\n"], "sample_97": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_104": ["    def setUp(self):\n        super().setUp()\n        self._temp_dir = temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, 'test'))\n        self.addCleanup(shutil.rmtree, temp_dir)\n"], "sample_109": ["def test_autocomplete_mixin_translations(self):\n    with translation.override('fr'):\n        form = AlbumForm()\n        attrs = form['band'].field.widget.get_context(name='my_field', value=None, attrs={})['widget']['attrs']\n        self.assertIn('admin/js/vendor/select2/i18n/fr.js', form['band'].field.widget.media._js)\n"], "sample_110": ["    def test_resolve_expression(self):\n        # Test that the resolve_expression method is called on each component of\n        # an expression.\n        class TestExpression(Expression):\n                super().__init__(*args, **kwargs)\n                self.resolved = False\n\n                self.resolved = True\n                return self\n\n        expr1 = TestExpression()\n        expr2 = TestExpression()\n        combined_expr = expr1 + expr2\n\n        combined_expr.resolve_expression()\n\n        self.assertTrue(expr1.resolved)\n        self.assertTrue(expr2.resolved)\n"], "sample_116": ["    def test_without_vary_on(self):\n        key = make_template_fragment_key('a.fragment')\n        self.assertEqual(key, 'template.cache.a.fragment.d41d8cd98f00b204e9800998ecf8427e')\n"], "sample_119": ["def test_foreign_key_exclusive_with_filter(self):\n    query = Query(ObjectC)\n    where = query.build_where(Q(objecta__id=1) | Q(objectb=None))\n    a_lookup = where.children[0]\n    self.assertIsInstance(a_lookup, Exact)\n    self.assertIsInstance(a_lookup.lhs, SimpleCol)\n    self.assertEqual(a_lookup.lhs.target, ObjectC._meta.get_field('objecta').target_field)\n    b_isnull = where.children[1]\n    self.assertIsInstance(b_isnull, RelatedIsNull)\n    self.assertIsInstance(b_isnull.lhs, SimpleCol)\n    self.assertEqual(b_isnull.lhs.target, ObjectC._meta.get_field('objectb'))\n"], "sample_130": ["def test_clone_deferred_loading(self):\n    query = Query(Item)\n    query.add_deferred_loading(['modified'])\n    clone = query.clone()\n    clone.add_deferred_loading(['created'])\n    self.assertEqual(query.deferred_loading, (frozenset({'modified'}), True))\n    self.assertEqual(clone.deferred_loading, (frozenset({'modified', 'created'}), True))\n"], "sample_136": ["def test_split_domain_port_ipv6(self):\n    domain, port = split_domain_port('[2001:19f0:feee::dead:beef:cafe]:8080')\n    self.assertEqual(domain, '[2001:19f0:feee::dead:beef:cafe]')\n    self.assertEqual(port, '8080')\n\n    domain, port = split_domain_port('[2001:19f0:feee::dead:beef:cafe]')\n    self.assertEqual(domain, '[2001:19f0:feee::dead:beef:cafe]')\n    self.assertEqual(port, '')\n"], "sample_145": ["    def test_not_callable_or_boolean(self):\n        class TestModelAdmin(ModelAdmin):\n            view_on_site = 'hello'\n\n        self.assertIsInvalid(\n            TestModelAdmin, ValidationTestModel,\n            \"The value of 'view_on_site' must be a callable or a boolean value.\",\n            'admin.E025'\n        )\n"], "sample_151": ["def test_alter_field_with_choices(self):\n    \"\"\"Tests autodetection of altered fields with choices.\"\"\"\n    changes = self.get_changes(\n        [ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True)), (\"name\", models.CharField(max_length=200, choices=[('a', 'A'), ('b', 'B')]))])],\n        [ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True)), (\"name\", models.CharField(max_length=200, choices=[('a', 'A'), ('c', 'C')]))])]\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True)\n"], "sample_153": ["    def test_fields_cache_descriptor(self):\n        instance = ModelState()\n        self.assertEqual(instance.fields_cache, {})\n        instance.fields_cache['test'] = 'value'\n        self.assertEqual(instance.fields_cache, {'test': 'value'})\n"], "sample_169": ["def test_key_transform_with_invalid_input(self):\n    msg = \"The given key must be a string or an integer.\"\n    with self.assertRaisesMessage(TypeError, msg):\n        KeyTransform(None, 'value')\n    with self.assertRaisesMessage(TypeError, msg):\n        KeyTransform(1.5, 'value')\n    with self.assertRaisesMessage(TypeError, msg):\n        KeyTransform([1, 2], 'value')\n    with self.assertRaisesMessage(TypeError, msg):\n        KeyTransform({'a': 1}, 'value')\n"], "sample_172": ["    def test_render(self):\n        inventory = Inventory.objects.create(barcode=86, name='Apple')\n        rel = Inventory._meta.get_field('parent').remote_field\n\n        w = widgets.ForeignKeyRawIdWidget(rel, widget_admin_site)\n        self.assertHTMLEqual(\n            w.render('test', inventory.barcode, attrs={}),\n            '<input type=\"text\" name=\"test\" value=\"86\" class=\"vForeignKeyRawIdAdminField\">'\n            '<a href=\"/admin_widgets/inventory/?_to_field=barcode\" '\n            'class=\"related-lookup\" id=\"lookup_id_test\" title=\"Lookup\"></a>&nbsp;<strong>'\n            '<a href=\"/admin_widgets/inventory/%(pk)s/change/\">Apple</a>'\n            '</strong>' % {'pk': inventory.pk}\n        )\n"], "sample_184": ["    def test_model_attribute(self):\n        class Model(models.Model):\n            my_field = models.CharField(max_length=10)\n\n        self.assertEqual(Model.check(), [])\n"], "sample_209": ["    def test_fields_cache(self):\n        # Test that the fields cache is correctly populated and cleared.\n        obj = Model1(pkey=1000)\n        self.assertEqual(obj._state.fields_cache, {})\n        obj.save()\n        self.assertIn('pkey', obj._state.fields_cache)\n        obj.refresh_from_db()\n        self.assertNotIn('pkey', obj._state.fields_cache)\n"], "sample_215": ["    def test_get_traceback_data(self):\n        try:\n            request = self.rf.get('/test_view/')\n            raise ValueError(\"Can't find my keys\")\n        except ValueError:\n            exc_type, exc_value, tb = sys.exc_info()\n        reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n        data = reporter.get_traceback_data()\n        self.assertIn('request', data)\n        self.assertIn('request_meta', data)\n        self.assertIn('filtered_POST_items', data)\n        self.assertIn('settings', data)\n        self.assertIn('sys_executable', data)\n        self.assertIn('sys_version_info', data)\n        self.assertIn('server_time', data)\n        self.assertIn('django_version_info', data)\n        self.assertIn('sys_path', data)\n        self.assertIn('template_info', data)\n        self.assertIn('template_does_not_exist', data)\n        self.assertIn('postmortem', data)\n"], "sample_217": ["def test_media_absolute_path(self):\n    m = Media(css={'all': ('path/to/css1', '/path/to/css2')}, js=('/path/to/js1', 'http://media.other.com/path/to/js2'))\n    self.assertEqual(m.absolute_path('path/to/css1'), 'http://media.example.com/static/path/to/css1')\n    self.assertEqual(m.absolute_path('/path/to/css2'), '/path/to/css2')\n    self.assertEqual(m.absolute_path('/path/to/js1'), '/path/to/js1')\n    self.assertEqual(m.absolute_path('http://media.other.com/path/to/js2'), 'http://media.other.com/path/to/js2')\n"], "sample_221": ["def test_pickle_union_queryset(self):\n    group1 = Group.objects.create(name='Group 1')\n    group2 = Group.objects.create(name='Group 2')\n    Event.objects.create(title='Event 1', group=group1)\n    Event.objects.create(title='Event 2', group=group2)\n\n    qs1 = Event.objects.filter(group=group1)\n    qs2 = Event.objects.filter(group=group2)\n    union_qs = qs1.union(qs2)\n\n    self.assert_pickles(union_qs)\n"], "sample_225": ["    def setUpTestData(cls):\n        cls.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n"], "sample_236": ["def test_collector_add_field_update(self):\n    collector = Collector(using='default')\n    model = R\n    field = model._meta.get_field('p')\n    value = P.objects.create()\n    objs = [R.objects.create()]\n    collector.add_field_update(field, value, objs)\n    self.assertIn(model, collector.field_updates)\n    self.assertIn((field, value), collector.field_updates[model])\n    self.assertEqual(collector.field_updates[model][(field, value)], set(objs))\n"], "sample_238": ["def test_aggregation_subquery_annotation_with_filter(self):\n    \"\"\"Subquery annotations can be filtered.\"\"\"\n    publisher_qs = Publisher.objects.annotate(\n        has_expensive_book=Exists(\n            Book.objects.filter(\n                publisher=OuterRef('pk'),\n                price__gt=Decimal('40.0'),\n            )\n        ),\n    ).filter(has_expensive_book=True)\n    self.assertEqual(publisher_qs.count(), 3)\n\n    publisher_qs = Publisher.objects.annotate(\n        has_expensive_book=Exists(\n            Book.objects.filter(\n                publisher=OuterRef('pk'),\n                price__gt=Decimal('1000.0'),\n            )\n        ),\n    ).filter(has_expensive_book=False)\n    self.assertEqual(publisher_qs.count(), 4)\n"], "sample_243": ["def test_build_filter_with_subquery(self):\n    subquery = Query(Item)\n    subquery.add_filter(('name', 'foo'))\n    query = Query(Author)\n    where = query.build_where(('id__in', subquery))\n    self.assertIsInstance(where.children[0], Exact)\n    self.assertIsInstance(where.children[0].rhs, Col)\n    self.assertEqual(where.children[0].rhs.target, Item._meta.get_field('id'))\n"], "sample_246": ["    def test_no_obsolete_enabled(self):\n        management.call_command('makemessages', locale=[LOCALE], verbosity=0, no_obsolete=True)\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertNotIn('#~ msgid \"\"', po_contents)\n"], "sample_263": ["def test_dumpdata_with_indent(self):\n    management.call_command('loaddata', 'fixture1.json', verbosity=0)\n    self._dumpdata_assert(\n        ['fixtures'],\n        '[\\n'\n        '    {\\n'\n        '        \"model\": \"fixtures.category\",\\n'\n        '        \"pk\": 1,\\n'\n        '        \"fields\": {\\n'\n        '            \"description\": \"Latest news stories\",\\n'\n        '            \"title\": \"News Stories\"\\n'\n        '        }\\n'\n        '    },\\n'\n        '    {\\n'\n        '        \"model\": \"fixtures.article\",\\n'\n        '        \"pk\": 2,\\n'\n        '        \"fields\": {\\n'\n        '            \"headline\": \"Poker has no place on ESPN\",\\n'\n        '            \"pub_date\": \"2006-06-16T12:00:00\"\\n'\n        '        }\\n'\n        '    },\\n'\n        '    {\\n'\n        '        \"model\": \"fixtures.article\",\\n'\n        '        \"pk\": 3,\\n'\n        '        \"fields\": {\\n'\n        '            \"headline\": \"Time to reform copyright\",\\n'\n        '            \"pub_date\": \"2006-06-16T13:00:00\"\\n'\n        '        }\\n'\n        '    }\\n'\n        ']',\n        indent=4\n    )\n"], "sample_267": ["    def test_convert_query(self):\n        wrapper = SQLiteCursorWrapper(None)\n        query = \"SELECT * FROM table WHERE name = '%s'\"\n        converted_query = wrapper.convert_query(query)\n        self.assertEqual(converted_query, \"SELECT * FROM table WHERE name = ?\")\n"], "sample_268": ["    def test_ensure_echo_on_called(self, mocked_termios):\n        autoreload.ensure_echo_on()\n        self.assertTrue(mocked_termios.tcgetattr.called)\n        self.assertTrue(mocked_termios.tcsetattr.called)\n"], "sample_270": ["    def test_model_attribute(self):\n        class Model(models.Model):\n            pass\n\n        self.assertEqual(Model.check(), [])\n"], "sample_274": ["    def test_modelform_unique_error_messages(self):\n        # Create a model with unique and unique_together constraints.\n        from .models import UniqueModel\n\n        class UniqueForm(forms.ModelForm):\n            class Meta:\n                model = UniqueModel\n                fields = '__all__'\n\n        form = UniqueForm(data={'name': 'Test', 'unique_field': 'test'})\n        form.save()\n\n        # Try to create another instance with the same values.\n        form = UniqueForm(data={'name': 'Test', 'unique_field': 'test'})\n\n        self.assertFormErrors([\n            'Please correct the duplicate data for name.',\n            'Please correct the duplicate data for unique_field.',\n        ], form.is_valid)\n\n        # Now try with unique_together constraint.\n        form = UniqueForm(data={'name': 'Test', 'unique_field': 'test2', 'unique_date': '2022-01-01'})\n\n        form.save()\n\n        form = UniqueForm(data={'name': 'Test', 'unique_field': 'test2', 'unique_date': '2022-01-01'})\n\n        self.assertFormErrors([\n            'Please correct the duplicate data for (name, unique_field, unique_date).',\n        ], form.is_valid)\n"], "sample_279": ["def test_invalid_opclasses_length(self):\n    msg = 'UniqueConstraint.fields and UniqueConstraint.opclasses must have the same number of elements.'\n    with self.assertRaisesMessage(ValueError, msg):\n        models.UniqueConstraint(\n            name='uniq_opclasses',\n            fields=['field1', 'field2'],\n            opclasses=['jsonb_path_ops'],\n        )\n"], "sample_289": ["    def test_len(self):\n        dict1 = CaseInsensitiveMapping({\n            'Accept': 'application/json',\n            'content-type': 'text/html',\n        })\n        self.assertEqual(len(dict1), 2)\n        dict2 = CaseInsensitiveMapping({})\n        self.assertEqual(len(dict2), 0)\n"], "sample_294": ["def test_csrf_trusted_origins_wildcard_domain(self):\n    \"\"\"\n    A POST request with an origin that matches a CSRF_TRUSTED_ORIGINS wildcard\n    domain is accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['HTTP_ORIGIN'] = 'https://subdomain.example.co.uk'\n    mw = CsrfViewMiddleware(post_form_view)\n    with override_settings(CSRF_TRUSTED_ORIGINS=['https://*.example.co.uk']):\n        self.assertIs(mw._origin_verified(req), True)\n        response = mw.process_view(req, post_form_view, (), {})\n        self.assertIsNone(response)\n"], "sample_295": ["    def setUpTestData(cls):\n        cls.data = [\n            {'id': 1, 'num': 1},\n            {'id': 2, 'num': 2},\n            {'id': 3, 'num': 3},\n            {'id': 4, 'num': 4},\n            {'id': 5, 'num': 5},\n        ]\n        Number.objects.bulk_create(Number(**d) for d in cls.data)\n"], "sample_299": ["    def test_non_absolute_path(self):\n        with self.settings(CACHES={\n            'default': {\n                'BACKEND': 'django.core.cache.backends.filebased.FileBasedCache',\n                'LOCATION': 'cache',  # non-absolute path\n            },\n        }):\n            warning = Warning(\n                \"Your 'default' cache LOCATION path is relative. Use an absolute path instead.\",\n                id='caches.W003',\n            )\n            self.assertEqual(check_file_based_cache_is_absolute(None), [warning])\n"], "sample_300": ["def test_build_lookup(self):\n    query = Query(Author)\n    lookup = query.build_lookup(['exact'], Col(Author._meta.get_field('name'), 'author'), 'foo')\n    self.assertIsInstance(lookup, Exact)\n    self.assertEqual(lookup.rhs, 'foo')\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('name'))\n"], "sample_317": ["def test_rss2_feed_with_no_items(self):\n    \"\"\"\n    Test the structure and content of feeds generated by Rss201rev2Feed with no items.\n    \"\"\"\n    response = self.client.get('/syndication/rss2/no-items/')\n    doc = minidom.parseString(response.content)\n\n    # Making sure there's only 1 `rss` element and that the correct\n    # RSS version was specified.\n    feed_elem = doc.getElementsByTagName('rss')\n    self.assertEqual(len(feed_elem), 1)\n    feed = feed_elem[0]\n    self.assertEqual(feed.getAttribute('version'), '2.0')\n\n    # Making sure there's only one `channel` element w/in the\n    # `rss` element.\n    chan_elem = feed.getElementsByTagName('channel')\n    self.assertEqual(len(chan_elem), 1)\n    chan = chan_elem[0]\n\n    # Ensure the content of the channel is correct\n    self.assertChildNodeContent(chan, {\n        'title': 'My blog',\n        'link': 'http://example.com/blog/',\n    })\n\n    # Check that there are no items in the feed\n    items = chan.getElementsByTagName('item')\n    self.assertEqual(len(items), 0)\n"], "sample_325": ["def test_boundfield_widget_type(self):\n    class SomeForm(Form):\n        first_name = CharField()\n        birthday = SplitDateTimeField(widget=SplitHiddenDateTimeWidget)\n\n    f = SomeForm()\n    self.assertEqual(f['first_name'].widget_type, 'text')\n    self.assertEqual(f['birthday'].widget_type, 'splithiddendatetime')\n"], "sample_334": ["def test_media(self):\n    class MyForm(Form):\n        pass\n\n    form = MyForm()\n    self.assertEqual(form.media, Media())\n\n    class MyForm(Form):\n        class Media:\n            js = ('test.js',)\n\n    form = MyForm()\n    self.assertEqual(form.media, Media(js=('test.js',)))\n\n    class MyForm(Form):\n            super().__init__(*args, **kwargs)\n            self.fields['field'] = CharField(widget=Textarea)\n\n    form = MyForm()\n    self.assertEqual(form.media, Media())\n"], "sample_338": ["def test_alter_model_table_with_m2m(self):\n    \"\"\"\n    AlterModelTable operation should be generated when a model with m2m field\n    has its db_table changed.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_with_m2m, self.publisher],\n        [self.author_with_db_table_options, self.publisher],\n    )\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, ['AlterModelTable'])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name='author', table='author_one')\n"], "sample_343": ["def test_get_content_type_with_id(self):\n    question = Question.objects.create(text='Who?')\n    content_type = Answer.question.get_content_type(id=question.content_type.id)\n    self.assertEqual(content_type.model_class(), Question)\n"], "sample_344": ["def test_get_concrete_model_key(self):\n    project_state = ProjectState()\n    model_state = ModelState(\n        app_label=\"migrations\",\n        name=\"Tag\",\n        fields=[\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=100)),\n            (\"hidden\", models.BooleanField()),\n        ],\n    )\n    project_state.add_model(model_state)\n    concrete_model_key = project_state.get_concrete_model_key(model_state)\n    self.assertEqual(concrete_model_key, (\"migrations\", \"tag\"))\n"], "sample_348": ["    def test_actions_with_description(self):\n        @admin.action(description='My Action')\n            pass\n\n        class BandAdmin(ModelAdmin):\n            actions = (action,)\n\n        self.assertIsValid(BandAdmin, Band)\n"], "sample_349": ["def test_autocomplete_select_multiple(self):\n    beatles = Band.objects.create(name='The Beatles', style='rock')\n    who = Band.objects.create(name='The Who', style='rock')\n    form = AlbumForm(initial={'featuring': [beatles.pk, who.pk]})\n    output = form.as_table()\n    selected_option1 = '<option value=\"%s\" selected>The Beatles</option>' % beatles.pk\n    selected_option2 = '<option value=\"%s\" selected>The Who</option>' % who.pk\n    self.assertIn(selected_option1, output)\n    self.assertIn(selected_option2, output)\n"], "sample_352": ["    def test_ticket_24748(self):\n        \"\"\"\n        Ensure that the ORM can handle a subquery with an aggregate function\n        and a model's field.\n        \"\"\"\n        apple = Food.objects.create(name=\"apple\")\n        lunch = Eaten.objects.create(food=apple, meal=\"lunch\")\n        dinner = Eaten.objects.create(food=apple, meal=\"dinner\")\n\n        self.assertSequenceEqual(\n            Eaten.objects.filter(meal__in=Eaten.objects.values_list('meal', flat=True).annotate(Max('id'))),\n            [lunch, dinner]\n        )\n"], "sample_357": ["def test_alter_model_table_with_m2m(self):\n    \"\"\"\n    Tests when model and db_table changes, autodetector must create two\n    operations for a model with m2m fields.\n    \"\"\"\n    before = [\n        ModelState('testapp', 'Author', [\n            ('id', models.AutoField(primary_key=True)),\n        ], options={'db_table': 'author_one'}),\n        ModelState('testapp', 'Book', [\n            ('id', models.AutoField(primary_key=True)),\n            ('authors', models.ManyToManyField('testapp.Author')),\n        ]),\n    ]\n    after = [\n        ModelState('testapp', 'NewAuthor', [\n            ('id', models.AutoField(primary_key=True)),\n        ], options={'db_table': 'author_three'}),\n        ModelState('testapp', 'Book', [\n            ('id', models.AutoField(primary_key=True)),\n            ('authors', models.ManyToManyField('testapp.NewAuthor')),\n        ]),\n    ]\n    changes = self.get_changes(before, after, MigrationQuestioner({'ask_rename_model': True}))\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"RenameModel\", \"AlterModelTable\", \"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, old_name=\"Author\", new_name=\"NewAuthor\")\n    self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"newauthor\", table=\"author_three\")\n    self.assertOperationAttributes(changes, \"testapp\", 0, 2, model_name=\"book\", name=\"authors\")\n"], "sample_359": ["def test_reduce_references_model(self):\n    operation = FieldOperation('MoDel', 'field', models.ForeignKey('Other', models.CASCADE))\n    other_operation = FieldOperation('Other', 'field', models.BooleanField(default=False))\n    self.assertIs(operation.reduce(other_operation, 'migrations'), False)\n    self.assertIs(other_operation.reduce(operation, 'migrations'), True)\n"], "sample_362": ["def test_alter_model_table_with_m2m(self):\n    \"\"\"\n    AlterModelTable should be generated before AddField for ManyToManyField.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_empty, self.book],\n        [self.author_empty, self.book_with_multiple_authors],\n    )\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterModelTable', 'AddField'])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='book', table='otherapp_book')\n    self.assertOperationAttributes(changes, 'otherapp', 0, 1, model_name='book', name='authors')\n"], "sample_363": ["    def test_render(self):\n        w = widgets.AutocompleteSelect(ForeignKeyRawIdWidget, admin.site)\n        self.assertHTMLEqual(\n            w.render('test', '42'),\n            '<input type=\"text\" name=\"test\" value=\"42\" '\n            'data-ajax--cache=\"true\" data-ajax--delay=\"250\" '\n            'data-ajax--type=\"GET\" data-ajax--url=\"/admin/autocomplete/\" '\n            'data-app-label=\"admin_widgets\" data-model-name=\"band\" '\n            'data-field-name=\"artist_ptr\" data-theme=\"admin-autocomplete\" '\n            'data-allow-clear=\"false\" data-placeholder=\"\" lang=\"en\" '\n            'class=\"vForeignKeyRawIdAdminField admin-autocomplete\">',\n        )\n"], "sample_369": ["def test_alter_model_table_with_custom_database_table(self):\n    \"\"\"\n    AlterModelTable operation should be generated when a model's db_table is\n    changed, even if the model has a custom database table name.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_with_db_table_options],\n        [ModelState(\"testapp\", \"Author\", [\n            (\"id\", models.AutoField(primary_key=True)),\n        ], {\"db_table\": \"custom_author_table\"})]\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelTable\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", table=\"custom_author_table\")\n"], "sample_381": ["def test_alter_model_options_with_custom_permissions(self):\n    \"\"\"Changing a model's options with custom permissions should make a change.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_with_options])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, options={\n        \"permissions\": [('can_hire', 'Can hire')],\n        \"verbose_name\": \"Authi\",\n    })\n\n    # Changing them back to empty should also make a change\n    changes = self.get_changes([self.author_with_options], [self.author_empty])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", options={})\n\n    # Test that the permission codename is validated.\n    invalid_codename_state = ModelState(\"testapp\", \"Author\", [\n        (\"id\", models.AutoField(primary_key=True)),\n    ], {\n        \"permissions\": [('invalid-codename', 'Invalid Codename')],\n    })\n    with self.assertRaises(ValueError):\n        self.get_changes([self.author_empty], [invalid_codename_state])\n"], "sample_389": ["    def test_http_request_repr(self):\n        request = HttpRequest()\n        self.assertEqual(repr(request), \"<HttpRequest>\")\n\n        request.method = \"GET\"\n        request.path = \"/path/\"\n        self.assertEqual(repr(request), \"<HttpRequest: GET '/path/'>\")\n"], "sample_399": ["def test_aggregation_with_distinct_and_filter(self):\n    result = Book.objects.aggregate(\n        value=Count(\"price\", distinct=True, filter=Q(rating__lt=3.0)),\n    )\n    self.assertEqual(result[\"value\"], 1)\n"], "sample_401": ["def test_formset_with_disabled_fields(self):\n    \"\"\"\n    Formsets with disabled fields should not cause errors when the form is bound.\n    \"\"\"\n\n    class DisabledForm(Form):\n        field = IntegerField(disabled=True)\n\n    DisabledFormSet = formset_factory(DisabledForm)\n    data = {\n        \"form-TOTAL_FORMS\": \"1\",\n        \"form-INITIAL_FORMS\": \"0\",\n        \"form-MIN_NUM_FORMS\": \"0\",\n        \"form-MAX_NUM_FORMS\": \"0\",\n        \"form-0-field\": \"\",\n    }\n    formset = DisabledFormSet(data, prefix=\"form\")\n    self.assertTrue(formset.is_valid())\n    self.assertEqual([{}], formset.cleaned_data)\n"], "sample_5": ["def test_parameter_unit_setting(model):\n    if not HAS_SCIPY and model['class'] in SCIPY_MODELS:\n        pytest.skip()\n\n    m = model['class'](**model['parameters'])\n\n    for param_name in m.param_names:\n        param = getattr(m, param_name)\n        if param.unit is not None:\n            new_value = param.value * 2\n            param.quantity = new_value * param.unit\n            assert param.quantity == new_value * param.unit\n            assert param.value == new_value\n"], "sample_7": ["def test_column_info_merge():\n    \"\"\"Test merging Column info attributes\"\"\"\n    col1 = table.Column([1, 2], name='a', unit='m', format='%i',\n                        description='test column', meta={'c': 8, 'd': 12})\n    col2 = table.Column([3, 4], name='b', unit='cm', format='%g',\n                        description='another test column', meta={'e': 9, 'f': 13})\n\n    attrs = col1.info.merge_cols_attributes([col1, col2], metadata_conflicts='warn')\n    assert attrs['name'] == 'a'\n    assert attrs['unit'] is None\n    assert attrs['format'] is None\n    assert attrs['description'] is None\n    assert attrs['meta'] == {}\n\n    attrs = col1.info.merge_cols_attributes([col1, col2], metadata_conflicts='error')\n    assert attrs['name'] == 'a'\n    assert attrs['unit'] is None\n    assert attrs['format'] is None\n    assert attrs['description'] is None\n    assert attrs['meta'] == {}\n\n    attrs = col1.info.merge_cols_attributes([col1, col2], metadata_conflicts='silent')\n    assert attrs['name'] == 'a'\n    assert attrs['unit'] == 'm'\n    assert attrs['format'] == '%i'\n    assert attrs['description'] == 'test column'\n    assert attrs['meta'] == {'c': 8, 'd': 12}\n"], "sample_8": ["    def test_masked_array_with_numpy_sum(self):\n        \"\"\"Check that numpy functions work properly with MaskedArray.\"\"\"\n        result = np.sum(self.ma)\n        expected_data = np.sum(self.a)\n        expected_mask = self.ma.mask.any()\n        assert_array_equal(result.unmasked, expected_data)\n        assert_array_equal(result.mask, expected_mask)\n"], "sample_16": ["    def setup_method(self):\n        self.pv_dtype = np.dtype([(\"p\", \"f8\"), (\"v\", \"f8\")])\n        self.pv_t_dtype = np.dtype(\n            [(\"pv\", np.dtype([(\"pp\", \"f8\"), (\"vv\", \"f8\")])), (\"t\", \"f8\")]\n        )\n\n        self.pv = np.array([(1.0, 0.25), (2.0, 0.5), (3.0, 0.75)], self.pv_dtype)\n        self.pv_t = np.array(\n            [((4.0, 2.5), 0.0), ((5.0, 5.0), 1.0), ((6.0, 7.5), 2.0)], self.pv_t_dtype\n        )\n\n        self.pv_unit = u.StructuredUnit((u.km, u.km / u.s), (\"p\", \"v\"))\n        self.pv_t_unit = u.StructuredUnit((self.pv_unit, u.s), (\"pv\", \"t\"))\n\n        self.q_pv = self.pv << self.pv_unit\n        self.q_pv_t = self.pv_t << self.pv_t_unit\n"], "sample_37": ["def test_to_fits_2():\n    \"\"\"\n    Test to_fits() with SIP distortion.\n    \"\"\"\n    fits_name = get_pkg_data_filename('data/sip.fits')\n    w = wcs.WCS(fits_name)\n    wfits = w.to_fits()\n    assert isinstance(wfits, fits.HDUList)\n    assert isinstance(wfits[0], fits.PrimaryHDU)\n    assert 'A_1_1' in wfits[0].header\n    assert 'B_1_1' in wfits[0].header\n"], "sample_38": ["def test_axis_type_names():\n    w = wcs.WCS(naxis=2)\n    w.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\"]\n    w.wcs.cname = [\"Longitude\", \"\"]\n    assert w.axis_type_names == [\"Longitude\", \"DEC--TAN\"]\n"], "sample_39": ["def test_wcs_naxis():\n    w = wcs.WCS(naxis=2)\n    assert w.naxis == 2\n    assert w.pixel_shape is None\n    assert w.array_shape is None\n\n    w._naxis = [100, 200]\n    assert w.naxis == 2\n    assert w.pixel_shape == (100, 200)\n    assert w.array_shape == (200, 100)\n\n    w = wcs.WCS(naxis=3)\n    w._naxis = [100, 200, 300]\n    assert w.naxis == 3\n    assert w.pixel_shape == (100, 200, 300)\n    assert w.array_shape == (300, 200, 100)\n"], "sample_42": ["def test_with_H0():\n    from astropy.cosmology import default_cosmology\n    H0 = default_cosmology.get().H0\n\n    # Test that the equivalency works for a simple case\n    x = 100 * u.littleh\n    y = x.to(u.dimensionless_unscaled, equivalencies=u.with_H0(H0))\n    assert_quantity_allclose(y, 100 / (H0.value / 100))\n\n    # Test that the equivalency works for a more complex case\n    x = 100 * u.littleh * u.Mpc\n    y = x.to(u.Mpc, equivalencies=u.with_H0(H0))\n    assert_quantity_allclose(y, 100 / (H0.value / 100) * u.Mpc)\n\n    # Test that the equivalency works when H0 is not specified\n    x = 100 * u.littleh\n    y = x.to(u.dimensionless_unscaled, equivalencies=u.with_H0())\n    assert_quantity_allclose(y, 100 / (default_cosmology.get().H0.value / 100))\n"], "sample_53": ["def test_render_options_with_empty_label(self):\n    \"\"\"Empty option is present with a custom label if the field isn't required.\"\"\"\n    form = NotRequiredBandForm()\n    form.fields['band'].empty_label = 'Select a band'\n    output = form.as_table()\n    self.assertIn('<option value=\"\">Select a band</option>', output)\n"], "sample_56": ["def test_list_filter_item(self):\n    class SongAdmin(admin.ModelAdmin):\n        list_filter = [\"title\", \"album\"]\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class InvalidListFilterAdmin(admin.ModelAdmin):\n        list_filter = [\"nonexistent\"]\n\n    errors = InvalidListFilterAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'list_filter[0]' refers to 'nonexistent', which does not refer to a Field.\",\n            obj=InvalidListFilterAdmin,\n            id='admin.E116',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_60": ["    def setUp(self):\n        self.site = AdminSite()\n"], "sample_66": ["def test_split_domain_port_ipv6(self):\n    domain, port = split_domain_port('[2001:19f0:feee::dead:beef:cafe]:8080')\n    self.assertEqual(domain, '[2001:19f0:feee::dead:beef:cafe]')\n    self.assertEqual(port, '8080')\n\n    domain, port = split_domain_port('[2001:19f0:feee::dead:beef:cafe]')\n    self.assertEqual(domain, '[2001:19f0:feee::dead:beef:cafe]')\n    self.assertEqual(port, '')\n"], "sample_72": ["def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    self.assertEqual(Serializer._registry[complex], ComplexSerializer)\n\n    Serializer.unregister(complex)\n    self.assertNotIn(complex, Serializer._registry)\n"], "sample_79": ["    def test_add(self):\n        self.check_values(('0', '5'), ('1', '6'), ('2', '7'))\n"], "sample_80": ["def test_related_isnull(self):\n    query = Query(ObjectC)\n    where = query.build_where(Q(objecta__isnull=True))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, RelatedIsNull)\n    self.assertEqual(lookup.lhs.target, ObjectC._meta.get_field('objecta'))\n"], "sample_85": ["    def test_m2m_field_with_through_model(self):\n        m = M.objects.create()\n        r = R.objects.create()\n        MR.objects.create(m=m, r=r)\n        self.assertEqual(m.m2m_through.all().count(), 1)\n"], "sample_102": ["def test_union_with_distinct(self):\n    qs1 = Number.objects.filter(num__lte=5)\n    qs2 = Number.objects.filter(num__gte=5)\n    self.assertEqual(len(qs1.union(qs2)), 10)\n    self.assertEqual(len(qs1.union(qs2, all=True)), 10)\n    self.assertEqual(len(qs1.union(qs2).distinct()), 10)\n    self.assertEqual(len(qs1.union(qs2, all=True).distinct()), 10)\n"], "sample_114": ["def test_alter_model_table_on_proxy_model(self):\n    \"\"\"\n    AlterModelTable should be generated when db_table is changed on a proxy model.\n    \"\"\"\n    changes = self.get_changes([self.author_proxy], [self.author_proxy_options])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelOptions\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"authorproxy\", options={\n        \"verbose_name\": \"Super Author\",\n    })\n\n    author_proxy_with_db_table = ModelState(\"testapp\", \"AuthorProxy\", [], {\n        \"proxy\": True,\n        \"db_table\": \"myapp_authorproxy\",\n    }, (\"testapp.author\",))\n    changes = self.get_changes([self.author_proxy], [author_proxy_with_db_table])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelTable\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"authorproxy\", table=\"myapp_authorproxy\")\n"], "sample_118": ["def test_exists_with_max(self):\n    max_id = Article.objects.aggregate(Max('id'))['id__max']\n    self.assertTrue(Article.objects.filter(id=max_id).exists())\n    self.assertFalse(Article.objects.filter(id=max_id + 1).exists())\n"], "sample_120": ["def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    Serializer.unregister(complex)\n\n    with self.assertRaisesMessage(ValueError, \"Cannot serialize: (1+2j)\"):\n        MigrationWriter.serialize(1 + 2j)\n"], "sample_121": ["    def test_model_attribute(self):\n        class Model(models.Model):\n            my_field = models.CharField(max_length=10)\n\n        self.assertEqual(Model.check(), [])\n"], "sample_126": ["def test_alter_model_table_with_m2m(self):\n    \"\"\"\n    AlterModelTable should be generated before AddField for ManyToManyField.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_empty, self.book],\n        [self.author_empty, self.book_with_multiple_authors]\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, [\"AlterModelTable\", \"AddField\"])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"book\", table=\"otherapp_book\")\n    self.assertOperationAttributes(changes, 'otherapp', 0, 1, model_name=\"book\", name=\"authors\")\n"], "sample_127": ["def test_bulk_create_with_conflicting_ids(self):\n    Country.objects.bulk_create([\n        Country(id=1, name=\"United States of America\", iso_two_letter=\"US\"),\n        Country(id=1, name=\"The Netherlands\", iso_two_letter=\"NL\"),\n    ])\n    self.assertEqual(Country.objects.count(), 1)\n    self.assertEqual(Country.objects.get().name, \"United States of America\")\n"], "sample_129": ["    def test_add01(self):\n        output = self.engine.render_to_string('add01', {\"a\": 5})\n        self.assertEqual(output, '10')\n"], "sample_135": ["def test_time_format(self):\n    my_birthday = datetime(1979, 7, 8, 22, 00)\n\n    self.assertEqual(dateformat.time_format(my_birthday, 'a'), 'p.m.')\n    self.assertEqual(dateformat.time_format(my_birthday, 'A'), 'PM')\n    self.assertEqual(dateformat.time_format(my_birthday, 'f'), '10 p.m.')\n    self.assertEqual(dateformat.time_format(my_birthday, 'g'), '10')\n    self.assertEqual(dateformat.time_format(my_birthday, 'G'), '22')\n    self.assertEqual(dateformat.time_format(my_birthday, 'h'), '10')\n    self.assertEqual(dateformat.time_format(my_birthday, 'H'), '22')\n    self.assertEqual(dateformat.time_format(my_birthday, 'i'), '00')\n    self.assertEqual(dateformat.time_format(my_birthday, 'P'), '10 p.m.')\n    self.assertEqual(dateformat.time_format(my_birthday, 's'), '00')\n    self.assertEqual(dateformat.time_format(my_birthday, 'u'), '000000')\n"], "sample_134": ["def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    Serializer.unregister(complex)\n\n    with self.assertRaisesMessage(ValueError, \"Cannot serialize: (1+2j)\\nThere are some values Django cannot serialize into migration files.\"):\n        MigrationWriter.serialize(1 + 2j)\n"], "sample_142": ["def test_modelform_defines_fields(self):\n    class SongForm(forms.ModelForm):\n        class Meta:\n            model = Song\n            fields = '__all__'\n\n    self.assertTrue(modelform_defines_fields(SongForm))\n    self.assertFalse(modelform_defines_fields(forms.ModelForm))\n"], "sample_147": ["def test_union_with_empty_queryset(self):\n    qs1 = Number.objects.all()\n    qs2 = Number.objects.none()\n    self.assertEqual(len(list(qs1.union(qs2))), 10)\n    self.assertEqual(len(list(qs2.union(qs1))), 10)\n    self.assertEqual(len(list(qs1.union(qs2, all=True))), 10)\n    self.assertEqual(len(list(qs2.union(qs1, all=True))), 10)\n"], "sample_158": ["    def test_swappable_model(self):\n        class SwappableModel(models.Model):\n            class Meta:\n                swappable = 'TEST_SWAPPABLE_MODEL'\n\n        class Model(models.Model):\n            fk = models.ForeignKey('SwappableModel', models.CASCADE)\n            m2m = models.ManyToManyField('SwappableModel')\n\n        with override_settings(TEST_SWAPPABLE_MODEL='invalid_models_tests.Replacement'):\n            class Replacement(models.Model):\n                pass\n\n            self.assertEqual(Model.check(), [\n                Error(\n                    \"Field defines a relation with the model \"\n                    \"'invalid_models_tests.SwappableModel', which has been swapped out.\",\n                    hint=\"Update the relation to point at 'settings.TEST_SWAPPABLE_MODEL'.\",\n                    obj=Model._meta.get_field('fk'),\n                    id='fields.E301',\n                ),\n                Error(\n                    \"Field defines a relation with the model \"\n                    \"'invalid_models_tests.SwappableModel', which has been swapped out.\",\n                    hint=\"Update the relation to point at 'settings.TEST_SWAPPABLE_MODEL'.\",\n                    obj=Model._meta.get_field('m2m'),\n                    id='fields.E301',\n                ),\n            ])\n"], "sample_161": ["    def test_swappable_model(self):\n        class SwappableModel(models.Model):\n            class Meta:\n                swappable = 'TEST_SWAPPABLE_MODEL'\n\n        class Model(models.Model):\n            explicit_fk = models.ForeignKey(\n                SwappableModel,\n                models.CASCADE,\n                related_name='explicit_fk',\n            )\n            implicit_fk = models.ForeignKey(\n                'invalid_models_tests.SwappableModel',\n                models.CASCADE,\n                related_name='implicit_fk',\n            )\n            explicit_m2m = models.ManyToManyField(SwappableModel, related_name='explicit_m2m')\n            implicit_m2m = models.ManyToManyField(\n                'invalid_models_tests.SwappableModel',\n                related_name='implicit_m2m',\n            )\n\n        fields = [\n            Model._meta.get_field('explicit_fk'),\n            Model._meta.get_field('implicit_fk'),\n            Model._meta.get_field('explicit_m2m'),\n            Model._meta.get_field('implicit_m2m'),\n        ]\n\n        expected_warning = DjangoWarning(\n            \"Model names used for swappable models should start with 'auth'.\",\n            id='fields.W342',\n        )\n\n        for field in fields:\n            expected_warning.obj = field\n            self.assertEqual(field.check(from_model=Model), [expected_warning])\n"], "sample_165": ["    def test_modelform_unique_error_messages(self):\n        # Create a model with unique and unique_together constraints.\n        from .models import UniqueModel\n\n        class UniqueForm(forms.ModelForm):\n            class Meta:\n                model = UniqueModel\n                fields = '__all__'\n                error_messages = {\n                    'name': {'unique': 'CUSTOM UNIQUE ERROR MESSAGE'},\n                    'NON_FIELD_ERRORS': {'unique_together': 'CUSTOM UNIQUE TOGETHER ERROR MESSAGE'},\n                }\n\n        form = UniqueForm(data={'name': 'test', 'value': 'test'})\n        form.save()\n\n        # Test unique error message.\n        form = UniqueForm(data={'name': 'test', 'value': 'test2'})\n        self.assertFormErrors(['CUSTOM UNIQUE ERROR MESSAGE'], form.clean)\n\n        # Test unique_together error message.\n        form = UniqueForm(data={'name': 'test2', 'value': 'test'})\n        self.assertFormErrors(['CUSTOM UNIQUE TOGETHER ERROR MESSAGE'], form.clean)\n"], "sample_175": ["def test_collector_sort(self):\n    # Create a collector with some data\n    collector = Collector(using='default')\n    model1 = A.objects.create(name='model1')\n    model2 = B.objects.create(a=model1)\n    model3 = C.objects.create(b=model2)\n\n    collector.add([model3])\n    collector.add([model2])\n    collector.add([model1])\n\n    # Check that the collector sorts the instances in the correct order\n    self.assertEqual(collector.data, {C: [model3], B: [model2], A: [model1]})\n\n    # Check that the collector can handle circular dependencies\n    model4 = D.objects.create(c=model3)\n    model3.d = model4\n    model3.save()\n\n    collector.add([model4])\n\n    # Check that the collector can handle circular dependencies\n    self.assertEqual(collector.data, {D: [model4], C: [model3], B: [model2], A: [model1]})\n"], "sample_176": ["def test_mti_inheritance_model_removal_with_fk(self):\n    Animal = ModelState('app', 'Animal', [\n        (\"id\", models.AutoField(primary_key=True)),\n    ])\n    Dog = ModelState('app', 'Dog', [], bases=('app.Animal',))\n    Kennel = ModelState('app', 'Kennel', [\n        (\"id\", models.AutoField(primary_key=True)),\n        (\"dog\", models.ForeignKey(\"app.Dog\", models.CASCADE)),\n    ])\n    changes = self.get_changes([Animal, Dog, Kennel], [Animal])\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'DeleteModel', 'DeleteModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='dog', model_name='kennel')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='Dog')\n    self.assertOperationAttributes(changes, 'app', 0, 2, name='Kennel')\n"], "sample_180": ["    def test_model_attribute(self):\n        class Model(models.Model):\n            pass\n\n        self.assertEqual(Model.check(), [])\n"], "sample_179": ["    def test_model_attribute(self):\n        class Model(models.Model):\n            my_field = models.CharField(max_length=10)\n\n        self.assertEqual(Model.check(), [])\n"], "sample_182": ["def test_union_with_distinct(self):\n    qs1 = Number.objects.filter(num__lte=5)\n    qs2 = Number.objects.filter(num__gte=5)\n    self.assertEqual(len(qs1.union(qs2)), 10)\n    self.assertEqual(len(qs1.union(qs2, all=True)), 10)\n    self.assertEqual(len(qs1.union(qs2).distinct()), 10)\n    self.assertEqual(len(qs1.union(qs2, all=True).distinct()), 10)\n"], "sample_181": ["def test_filtered_aggregate_ref_subquery_annotation_with_exists(self):\n    aggs = Author.objects.annotate(\n        has_book=Exists(\n            Book.objects.filter(contact__pk=OuterRef('pk'))\n        ),\n    ).aggregate(\n        cnt=Count('pk', filter=Q(has_book=True)),\n    )\n    self.assertEqual(aggs['cnt'], 3)\n"], "sample_183": ["    def setUpTestData(cls):\n        cls.data = [\n            CaseTestModel(integer=1, integer2=1),\n            CaseTestModel(integer=2, integer2=3),\n            CaseTestModel(integer=3, integer2=4),\n            CaseTestModel(integer=2, integer2=2),\n            CaseTestModel(integer=3, integer2=4),\n            CaseTestModel(integer=3, integer2=3),\n            CaseTestModel(integer=4, integer2=5),\n        ]\n        CaseTestModel.objects.bulk_create(cls.data)\n"], "sample_186": ["def test_check_list_filter_item(self):\n    class SongAdmin(admin.ModelAdmin):\n        list_filter = ['nonexistent']\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'list_filter[0]' refers to 'nonexistent', which does not refer to a Field.\",\n            obj=SongAdmin,\n            id='admin.E116',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_188": ["    def test_rawsql_requires_params(self):\n        with self.assertRaisesMessage(ValueError, 'params must be a list or tuple'):\n            RawSQL('table.col', 'not a list or tuple')\n"], "sample_190": ["def test_in_bulk_with_large_input(self):\n    # Create a large number of authors\n    Author.objects.bulk_create([Author(name=f'Author {i}') for i in range(1000)])\n\n    # Test that in_bulk() works with a large input\n    authors = list(Author.objects.all())\n    author_ids = [author.id for author in authors]\n    retrieved_authors = Author.objects.in_bulk(author_ids)\n    self.assertEqual(len(retrieved_authors), len(authors))\n    for author in authors:\n        self.assertIn(author.id, retrieved_authors)\n        self.assertEqual(retrieved_authors[author.id], author)\n"], "sample_195": ["    def test_bulk_insert_sql(self):\n        fields = ['field1', 'field2']\n        placeholder_rows = [\n            ['%s', '%s'],\n            ['%s', '%s'],\n        ]\n        sql = connection.ops.bulk_insert_sql(fields, placeholder_rows)\n        self.assertEqual(sql, \" UNION ALL \".join(\"SELECT %s, %s\" for _ in placeholder_rows))\n"], "sample_198": ["    def setUpTestData(cls):\n        cls.company = Company.objects.create(name='Example Inc.', num_employees=2300, num_chairs=5)\n"], "sample_199": ["def test_annotation_with_subquery_and_outerref(self):\n    subquery = Book.objects.filter(\n        publisher=OuterRef('pk'),\n    ).values('publisher').annotate(count=Count('pk')).values('count')\n    qs = Publisher.objects.annotate(\n        total_books=Subquery(subquery, output_field=IntegerField()),\n    ).filter(\n        total_books__gt=1,\n    ).values('name')\n    self.assertCountEqual(qs, [{'name': 'Apress'}, {'name': 'Prentice Hall'}])\n"], "sample_207": ["    def test_db_check_constraints(self):\n        field = models.JSONField()\n        errors = field.check()\n        self.assertEqual(errors, [])\n"], "sample_214": ["    def setUpTestData(cls):\n        cls.objs = [\n            NullableJSONModel.objects.create(value={'a': 1, 'b': 2}),\n            NullableJSONModel.objects.create(value={'a': 3, 'b': 4}),\n            NullableJSONModel.objects.create(value={'c': 5, 'd': 6}),\n        ]\n"], "sample_218": ["def test_trunc_func_with_timezone_transition(self):\n    sao = pytz.timezone('America/Sao_Paulo')\n    start_datetime = datetime(2016, 10, 16, 1)\n    end_datetime = datetime(2016, 2, 21, 1)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=DateTimeField(), tzinfo=sao)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(sao), kind, sao)),\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_datetime_kind('day')\n    test_datetime_kind('hour')\n"], "sample_224": ["def test_aggregation_with_duration_field(self):\n    # Explicit `output_field`.\n    self.assertEqual(\n        Publisher.objects.aggregate(Sum('duration', output_field=DurationField())),\n        {'duration__sum': datetime.timedelta(days=3)}\n    )\n    # Implicit `output_field`.\n    self.assertEqual(\n        Publisher.objects.aggregate(Sum('duration')),\n        {'duration__sum': datetime.timedelta(days=3)}\n    )\n"], "sample_229": ["def test_union_with_empty_queryset(self):\n    qs1 = Number.objects.all()\n    qs2 = Number.objects.none()\n    self.assertEqual(len(list(qs1.union(qs2))), 10)\n    self.assertEqual(len(list(qs2.union(qs1))), 10)\n    self.assertEqual(len(list(qs1.union(qs2, all=True))), 10)\n    self.assertEqual(len(list(qs2.union(qs1, all=True))), 10)\n"], "sample_230": ["def test_bound_data(self):\n    field = JSONField()\n    self.assertEqual(field.bound_data('{\"a\": \"b\"}', None), {'a': 'b'})\n    self.assertIsInstance(field.bound_data('invalid json', None), field.InvalidJSONInput)\n"], "sample_232": ["    def test_key_transform(self):\n        obj = NullableJSONModel.objects.create(value={'a': 'b', 'c': 14})\n        self.assertEqual(\n            NullableJSONModel.objects.filter(value__a='b').get(),\n            obj,\n        )\n        self.assertEqual(\n            NullableJSONModel.objects.filter(value__c=14).get(),\n            obj,\n        )\n"], "sample_234": ["def test_union_with_empty_queryset(self):\n    qs1 = Number.objects.all()\n    qs2 = Number.objects.none()\n    self.assertEqual(len(list(qs1.union(qs2))), 10)\n    self.assertEqual(len(list(qs2.union(qs1))), 10)\n    self.assertEqual(len(list(qs1.union(qs2, all=True))), 10)\n    self.assertEqual(len(list(qs2.union(qs1, all=True))), 10)\n"], "sample_242": ["def test_year_lookup_bounds(self):\n    output_field = DateTimeField()\n    year = 2022\n    lookup = YearLookup(Value(1), Value(year))\n    with mock.patch.object(output_field, 'get_internal_type', return_value='DateTimeField'):\n        bounds = lookup.year_lookup_bounds(None, year)\n        self.assertIsInstance(bounds, tuple)\n        self.assertEqual(len(bounds), 2)\n\n    with mock.patch.object(output_field, 'get_internal_type', return_value='DateField'):\n        bounds = lookup.year_lookup_bounds(None, year)\n        self.assertIsInstance(bounds, tuple)\n        self.assertEqual(len(bounds), 2)\n"], "sample_247": ["def test_alias_with_m2m(self):\n    qs = Author.objects.alias(\n        book_isbn=F('book__isbn'),\n    ).filter(book_isbn='159059725')\n    self.assertIs(hasattr(qs.first(), 'book_isbn'), False)\n    self.assertSequenceEqual(qs, [self.a1, self.a2])\n"], "sample_250": ["def test_E_format(self):\n    # Test alternative month names as required by some locales.\n    my_birthday = datetime(1979, 7, 8, 22, 00)\n    self.assertEqual(dateformat.format(my_birthday, 'E'), 'July')\n"], "sample_251": ["def test_alias_with_m2m(self):\n    qs = Author.objects.alias(\n        book_isbn=F('book__isbn'),\n    ).filter(book_isbn='159059725')\n    self.assertIs(hasattr(qs.first(), 'book_isbn'), False)\n    self.assertSequenceEqual(qs, [self.a1, self.a2])\n"], "sample_252": ["    def test_check_constraints(self):\n        # Create a model with a JSONField that has a check constraint.\n        class ModelWithCheckConstraint(models.Model):\n            value = models.JSONField()\n\n            class Meta:\n                constraints = [\n                    models.CheckConstraint(\n                        check=models.Q(value__has_key='a'),\n                        name='check_a',\n                    ),\n                ]\n\n        # Try to create an instance of the model with a value that does not satisfy the check constraint.\n        with self.assertRaises(IntegrityError):\n            ModelWithCheckConstraint.objects.create(value={'b': 1})\n\n        # Try to create an instance of the model with a value that satisfies the check constraint.\n        ModelWithCheckConstraint.objects.create(value={'a': 1})\n"], "sample_254": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n"], "sample_257": ["    def test_m2m(self):\n        related = RelatedJSONModel.objects.create(value={'foo': 'bar'})\n        obj = JSONModel.objects.create(value={'baz': 'qux'}, related=related)\n        self.assertEqual(obj.related.value, {'foo': 'bar'})\n"], "sample_259": ["def test_prefetch_object_queryset(self):\n    book1 = Book.objects.get(id=self.book1.id)\n    with self.assertNumQueries(1):\n        prefetch_related_objects([book1], Prefetch('authors', queryset=Author.objects.filter(name='Charlotte')))\n\n    with self.assertNumQueries(0):\n        self.assertEqual(list(book1.authors.all()), [self.author1])\n"], "sample_260": ["def test_optimize_through_fields_with_m2m(self):\n    \"\"\"\n    field-level through checking is working with M2M fields.\n    \"\"\"\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\"Foo\", [(\"name\", models.CharField(max_length=255))]),\n            migrations.CreateModel(\"Bar\", [(\"size\", models.IntegerField())]),\n            migrations.AddField(\"Foo\", \"bars\", models.ManyToManyField(\"Bar\")),\n            migrations.AlterField(\"Foo\", \"bars\", models.ManyToManyField(\"Bar\")),\n            migrations.RemoveField(\"Foo\", \"bars\"),\n            migrations.DeleteModel(\"Foo\"),\n        ],\n        [\n            migrations.CreateModel(\"Bar\", [(\"size\", models.IntegerField())]),\n        ],\n    )\n"], "sample_273": ["    def test_field_clashes_with_property(self):\n        class Model(models.Model):\n            my_field = models.CharField(max_length=10)\n\n            @property\n                return 'value'\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"The property 'my_field' clashes with a model field.\",\n                obj=Model,\n                id='models.E025',\n            ),\n        ])\n"], "sample_275": ["    def test_prefetch_related_delete(self):\n        # Create a few objects to test prefetch_related delete behavior.\n        person = Person.objects.create(name='John')\n        award1 = Award.objects.create(name='Award 1', content_object=person)\n        award2 = Award.objects.create(name='Award 2', content_object=person)\n\n        # Prefetch related awards and then delete the person.\n        people = list(Person.objects.prefetch_related('award_set'))\n        person.delete()\n\n        # The prefetched awards should still be accessible, even though the\n        # person has been deleted.\n        self.assertEqual(len(people[0].award_set.all()), 2)\n\n        # But trying to access the person on an award should raise an error.\n        with self.assertRaises(Award.content_object.RelatedObjectDoesNotExist):\n            award1.content_object\n\n        with self.assertRaises(Award.content_object.RelatedObjectDoesNotExist):\n            award2.content_object\n"], "sample_286": ["    def test_get_field_display(self):\n        article = Article.objects.create(\n            headline='Parrot programs in Python',\n            pub_date=datetime(2005, 7, 28),\n            status=Article.STATUS_CHOICES[0][0],\n        )\n        self.assertEqual(article.get_status_display(), 'Draft')\n"], "sample_287": ["def test_list_filter_item(self):\n    class SongAdmin(admin.ModelAdmin):\n        list_filter = ['title', 'album']\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class InvalidListFilterAdmin(admin.ModelAdmin):\n        list_filter = ['nonexistent_field']\n\n    errors = InvalidListFilterAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'list_filter[0]' refers to 'nonexistent_field', which does not refer to a Field.\",\n            obj=InvalidListFilterAdmin,\n            id='admin.E116',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_288": ["    def test_m2m(self):\n        related_obj = RelatedJSONModel.objects.create(value={'foo': 'bar'})\n        obj = JSONModel.objects.create(value={'baz': 'qux'})\n        obj.related.add(related_obj)\n        self.assertSequenceEqual(\n            JSONModel.objects.filter(related__value={'foo': 'bar'}),\n            [obj],\n        )\n        self.assertSequenceEqual(\n            JSONModel.objects.filter(related__value__foo='bar'),\n            [obj],\n        )\n"], "sample_305": ["def test_annotate_with_subquery(self):\n    subquery = Book.objects.filter(rating__gt=4).values('publisher')\n    qs = Publisher.objects.annotate(top_rated_books=Count(Subquery(subquery)))\n    self.assertEqual(qs.get(name='Apress').top_rated_books, 1)\n    self.assertEqual(qs.get(name='Prentice Hall').top_rated_books, 2)\n    self.assertEqual(qs.get(name='Morgan Kaufmann').top_rated_books, 1)\n    self.assertEqual(qs.get(name='Sams').top_rated_books, 0)\n"], "sample_307": ["def test_E_format(self):\n    my_birthday = datetime(1979, 7, 8, 22, 00)\n    self.assertEqual(dateformat.format(my_birthday, 'E'), 'July')\n"], "sample_308": ["def test_z_format_day_of_year(self):\n    tests = [\n        (datetime(2022, 1, 1), '001'),\n        (datetime(2022, 12, 31), '365'),\n        (datetime(2024, 2, 29), '060'),\n    ]\n    for dt, expected_date in tests:\n        with self.subTest(dt=dt):\n            self.assertEqual(dateformat.format(dt, 'z'), expected_date)\n"], "sample_327": ["def test_bound_data(self):\n    field = JSONField()\n    self.assertIsNone(field.bound_data(None, None))\n    self.assertEqual(field.bound_data('{\"a\": \"b\"}', None), {'a': 'b'})\n    invalid_input = '{\"a\" \"b\"}'\n    bound_data = field.bound_data(invalid_input, None)\n    self.assertIsInstance(bound_data, str)\n    self.assertEqual(bound_data, invalid_input)\n"], "sample_328": ["def test_bulk_update_with_json_field(self):\n    json_models = [\n        JSONFieldNullable.objects.create(data={'key': 'value'})\n        for _ in range(10)\n    ]\n    for model in json_models:\n        model.data = {'new_key': 'new_value'}\n    JSONFieldNullable.objects.bulk_update(json_models, ['data'])\n    self.assertCountEqual(\n        JSONFieldNullable.objects.filter(data={'new_key': 'new_value'}),\n        json_models\n    )\n"], "sample_329": ["def test_unregister_serializer(self):\n    class ComplexSerializer(BaseSerializer):\n            return 'complex(%r)' % self.value, {}\n\n    Serializer.register(complex, ComplexSerializer)\n    Serializer.unregister(complex)\n\n    with self.assertRaisesMessage(ValueError, \"Cannot serialize: (1+1j)\"):\n        MigrationWriter.serialize(1 + 1j)\n"], "sample_335": ["def test_decimalfield_disabled(self):\n    f = DecimalField(max_digits=4, decimal_places=2, disabled=True)\n    self.assertWidgetRendersTo(\n        f,\n        '<input step=\"0.01\" name=\"f\" type=\"number\" id=\"id_f\" disabled>',\n    )\n    self.assertIsNone(f.clean(''))\n    self.assertIsNone(f.clean(None))\n    self.assertEqual(f.clean('1'), decimal.Decimal(\"1\"))\n    self.assertEqual(f.max_digits, 4)\n    self.assertEqual(f.decimal_places, 2)\n    self.assertIsNone(f.max_value)\n    self.assertIsNone(f.min_value)\n    self.assertFalse(f.has_changed(decimal.Decimal(\"1\"), '1.00'))\n"], "sample_350": ["def test_union_with_empty_queryset(self):\n    qs1 = Number.objects.all()\n    qs2 = Number.objects.none()\n    self.assertEqual(len(list(qs1.union(qs2))), 10)\n    self.assertEqual(len(list(qs2.union(qs1))), 10)\n    self.assertEqual(len(list(qs1.union(qs2, all=True))), 10)\n    self.assertEqual(len(list(qs2.union(qs1, all=True))), 10)\n"], "sample_356": ["def test_alter_model_table_with_custom_database(self):\n    \"\"\"\n    AlterModelTable operation should correctly handle custom database routers.\n    \"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_with_db_table_options])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelTable\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", table=\"author_one\")\n\n    class CustomRouter:\n            return db == 'custom'\n\n    with override_settings(DATABASE_ROUTERS=[CustomRouter()]):\n        loader = MigrationLoader(connection)\n        autodetector = MigrationAutodetector(\n            from_state=self.make_project_state([self.author_empty]),\n            to_state=self.make_project_state([self.author_with_db_table_options]),\n        )\n        changes = autodetector._detect_changes(graph=loader.graph)\n\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterModelTable\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"author\", table=\"author_one\")\n"], "sample_370": ["    def setUpTestData(cls):\n        cls.book = Book.objects.create(title='Poems')\n        cls.tagged_item = TaggedItem.objects.create(tag=\"awesome\", content_object=cls.book)\n"], "sample_374": ["    def setUpTestData(cls):\n        cls.book1 = Book.objects.create(title='Book 1')\n        cls.book2 = Book.objects.create(title='Book 2')\n        cls.author1 = Author.objects.create(name='Author 1', first_book=cls.book1)\n        cls.author2 = Author.objects.create(name='Author 2', first_book=cls.book2)\n"], "sample_375": ["def test_get_related_models_tuples(self):\n    \"\"\"\n    get_related_models_tuples returns a set of (app_label, model_name) tuples for\n    all related models.\n    \"\"\"\n    new_apps = Apps()\n\n    class Author(models.Model):\n        class Meta:\n            app_label = 'migrations'\n            apps = new_apps\n\n    class Book(models.Model):\n        author = models.ForeignKey(Author, models.CASCADE)\n\n        class Meta:\n            app_label = 'migrations'\n            apps = new_apps\n\n    class Magazine(models.Model):\n        authors = models.ManyToManyField(Author)\n\n        class Meta:\n            app_label = 'migrations'\n            apps = new_apps\n\n    project_state = ProjectState()\n    project_state.add_model(ModelState.from_model(Author))\n    project_state.add_model(ModelState.from_model(Book))\n    project_state.add_model(ModelState.from_model(Magazine))\n\n    related_models = get_related_models_tuples(project_state.apps.get_model('migrations', 'author'))\n    self.assertEqual(related_models, {('migrations', 'book'), ('migrations', 'magazine')})\n"], "sample_378": ["def test_bulk_update_with_unique_fields(self):\n    # Create some objects with unique fields.\n    notes = [\n        Note.objects.create(note=str(i), misc=str(i))\n        for i in range(10)\n    ]\n    # Update the objects, but also specify unique fields.\n    for note in notes:\n        note.note = 'test-%s' % note.id\n    Note.objects.bulk_update(notes, ['note'], unique_fields=['misc'])\n    self.assertCountEqual(\n        Note.objects.values_list('note', flat=True),\n        [cat.note for cat in notes]\n    )\n"], "sample_384": ["def test_bulk_update_with_inheritance(self):\n    food = Food.objects.create(name=\"Food\")\n    food.name = \"Updated Food\"\n    with self.assertNumQueries(1):\n        Food.objects.bulk_update([food], fields=[\"name\"])\n    food.refresh_from_db()\n    self.assertEqual(food.name, \"Updated Food\")\n"], "sample_387": ["    def test_render(self):\n        album = Album.objects.create(name=\"Hybrid Theory\", band=Band.objects.create(name=\"Linkin Park\"))\n        rel = ReleaseEvent._meta.get_field(\"album\").remote_field\n        w = widgets.ForeignKeyRawIdWidget(rel, admin.site)\n        self.assertHTMLEqual(\n            w.render(\"test\", album.pk, attrs={}),\n            '<input type=\"text\" name=\"test\" value=\"%(albumpk)s\" '\n            'class=\"vForeignKeyRawIdAdminField\">'\n            '<a href=\"/admin/admin_widgets/album/?_to_field=id\" class=\"related-lookup\" '\n            'id=\"lookup_id_test\" title=\"Lookup\"></a>&nbsp;<strong>'\n            '<a href=\"/admin/admin_widgets/album/%(albumpk)s/change/\">'\n            \"Hybrid Theory</a></strong>\" % {\"albumpk\": album.pk},\n        )\n"], "sample_391": ["def test_create_model_add_index(self):\n    \"\"\"\n    AddIndex should optimize into CreateModel.\n    \"\"\"\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\"Foo\", fields=[(\"name\", models.CharField(max_length=255))]),\n            migrations.AddIndex(\"Foo\", models.Index(fields=[\"name\"], name=\"foo_name_idx\")),\n        ],\n        [\n            migrations.CreateModel(\n                \"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n                options={\"indexes\": [models.Index(fields=[\"name\"], name=\"foo_name_idx\")]},\n            ),\n        ],\n    )\n"], "sample_392": ["    def test_subquery_annotation(self):\n        subquery = NullableJSONModel.objects.filter(value__isnull=False).values(\n            \"value__a\"\n        )\n        qs = NullableJSONModel.objects.annotate(\n            value_a=Subquery(subquery),\n        ).filter(value_a=\"b\")\n        self.assertSequenceEqual(qs, [self.objs[3], self.objs[4]])\n"], "sample_414": ["    def test_render(self):\n        band = Band.objects.create(name=\"Linkin Park\")\n        rel = ReleaseEvent._meta.get_field(\"album\").remote_field\n        w = widgets.ForeignKeyRawIdWidget(rel, admin.site)\n        self.assertHTMLEqual(\n            w.render(\"test\", band.pk, attrs={}),\n            '<input type=\"text\" name=\"test\" value=\"%(bandpk)s\" '\n            'class=\"vForeignKeyRawIdAdminField\">'\n            '<a href=\"/admin/admin_widgets/album/?_to_field=id\" '\n            'class=\"related-lookup\" id=\"lookup_id_test\" title=\"Lookup\"></a>&nbsp;'\n            '<strong><a href=\"/admin/admin_widgets/album/%(bandpk)s/change/\">'\n            \"Linkin Park</a></strong>\" % {\"bandpk\": band.pk},\n        )\n"], "sample_415": ["def test_validate_expression_with_exclude(self):\n    constraint = models.UniqueConstraint(Lower(\"name\"), name=\"name_lower_uniq\")\n    non_unique_product = UniqueConstraintProduct(name=self.p1.name.upper())\n    msg = \"Constraint \u201cname_lower_uniq\u201d is violated.\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        constraint.validate(UniqueConstraintProduct, non_unique_product)\n    # Exclude field used by the expression.\n    constraint.validate(\n        UniqueConstraintProduct,\n        non_unique_product,\n        exclude={\"name\"},\n    )\n    # Exclude another field not used by the expression.\n    with self.assertRaisesMessage(ValidationError, msg):\n        constraint.validate(\n            UniqueConstraintProduct,\n            non_unique_product,\n            exclude={\"color\"},\n        )\n"], "sample_417": ["    def test_add01(self):\n        output = self.engine.render_to_string(\"add01\", {\"a\": 5})\n        self.assertEqual(output, \"6\")\n"], "sample_418": ["def test_add(self):\n    output = self.engine.render_to_string(\"add01\", {\"num1\": 4, \"num2\": 6})\n    self.assertEqual(output, \"10\")\n"], "sample_419": ["def test_formset_add_fields_with_can_delete_and_can_order(self):\n    \"\"\"FormSet.add_fields() handles can_delete and can_order correctly.\"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_delete=True, can_order=True)\n    formset = ChoiceFormSet(initial=[{\"choice\": \"Calexico\", \"votes\": 100}])\n    self.assertIn(\"DELETE\", formset.forms[0].fields)\n    self.assertIn(\"ORDER\", formset.forms[0].fields)\n    self.assertIn(\"DELETE\", formset.empty_form.fields)\n    self.assertIn(\"ORDER\", formset.empty_form.fields)\n"], "sample_421": ["    def test_expression_wrapper(self):\n        wrapper = ExpressionWrapper(Value(1), output_field=IntegerField())\n        self.assertEqual(wrapper.output_field.get_internal_type(), \"IntegerField\")\n        self.assertEqual(wrapper.as_sql(None, connection), (\"1\", []))\n"], "sample_422": ["    def setUpTestData(cls):\n        cls.employee1 = Employee.objects.create(name=\"John\")\n        cls.employee2 = Employee.objects.create(name=\"Jane\", boss=cls.employee1)\n        cls.employee3 = Employee.objects.create(name=\"Jim\", boss=cls.employee1)\n"], "sample_425": ["def test_serialize_type_with_module(self):\n    class TestType:\n        pass\n\n    self.assertSerializedEqual(TestType)\n    self.assertSerializedResultEqual(\n        MigrationWriter.serialize(TestType),\n        (\"('migrations.test_writer.TestType', {'import migrations.test_writer'})\", set()),\n    )\n"], "sample_427": ["def test_formset_with_disabled_fields(self):\n    \"\"\"\n    Formsets with disabled fields should not include those fields in the cleaned data.\n    \"\"\"\n\n    class DisabledForm(Form):\n        field = IntegerField(disabled=True)\n\n    DisabledFormSet = formset_factory(DisabledForm)\n    data = {\n        \"form-TOTAL_FORMS\": \"1\",\n        \"form-INITIAL_FORMS\": \"0\",\n        \"form-MIN_NUM_FORMS\": \"0\",\n        \"form-0-field\": \"123\",\n    }\n    formset = DisabledFormSet(data, prefix=\"form\")\n    self.assertTrue(formset.is_valid())\n    self.assertEqual([{}], formset.cleaned_data)\n"], "sample_431": ["    def test_get_next_previous_by(self):\n        pub_date = datetime.now()\n        a1 = Article.objects.create(headline=\"Article 1\", pub_date=pub_date)\n        a2 = Article.objects.create(headline=\"Article 2\", pub_date=pub_date + timedelta(days=1))\n        a3 = Article.objects.create(headline=\"Article 3\", pub_date=pub_date + timedelta(days=2))\n\n        self.assertEqual(a1.get_next_by_pub_date(), a2)\n        self.assertEqual(a2.get_next_by_pub_date(), a3)\n        self.assertIsNone(a3.get_next_by_pub_date())\n\n        self.assertIsNone(a1.get_previous_by_pub_date())\n        self.assertEqual(a2.get_previous_by_pub_date(), a1)\n        self.assertEqual(a3.get_previous_by_pub_date(), a2)\n"], "sample_432": ["def test_get_changelist_instance_sortable_by(self):\n    m = ChildAdmin(Child, custom_site)\n    request = self.factory.get(\"/child/\")\n    request.user = self.superuser\n    cl = m.get_changelist_instance(request)\n    self.assertEqual(cl.sortable_by, [\"name\", \"age\"])\n\n    # If sortable_by is set, it's used.\n    m.sortable_by = (\"age\",)\n    cl = m.get_changelist_instance(request)\n    self.assertEqual(cl.sortable_by, [\"age\"])\n"], "sample_440": ["def test_update_conflicts_no_unique_fields(self):\n    self._test_update_conflicts(unique_fields=[])\n"], "sample_446": ["    def test_stringformat01(self):\n        output = self.engine.render_to_string(\"stringformat01\", {\"a\": 1.23})\n        self.assertEqual(output, \"1.230000E+00\")\n"], "sample_447": ["def test_alias_with_m2m(self):\n    qs = (\n        Author.objects.alias(\n            book_name=F(\"book__name\"),\n        )\n        .filter(\n            name=\"Adrian Holovaty\",\n            friends__age=35,\n        )\n        .annotate(\n            jacob_name=F(\"friends__name\"),\n        )\n        .filter(\n            friends__age=29,\n        )\n        .annotate(\n            james_name=F(\"friends__name\"),\n        )\n        .values(\"jacob_name\", \"james_name\", \"book_name\")\n    )\n    self.assertCountEqual(\n        qs,\n        [\n            {\n                \"jacob_name\": \"Jacob Kaplan-Moss\",\n                \"james_name\": \"James Bennett\",\n                \"book_name\": \"The Definitive Guide to Django: Web Development Done Right\",\n            }\n        ],\n    )\n"], "sample_451": ["def test_replace_named_groups(self):\n    pattern = r\"^/(?P<a>\\w+)/b/(?P<c>\\w+)/$\"\n    expected_output = \"^/<a>/b/<c>/$\"\n    self.assertEqual(replace_named_groups(pattern), expected_output)\n\n    pattern = r\"^/(?P<a>\\w+)/b/(\\w+)$\"\n    expected_output = \"^/<a>/b/(\\\\w+)$\"\n    self.assertEqual(replace_named_groups(pattern), expected_output)\n"], "sample_454": ["    def setUpTestData(cls):\n        cls.p1 = Product.objects.create(price=10, discounted_price=5)\n"], "sample_455": ["def test_validate_expression_with_exclude(self):\n    constraint = models.UniqueConstraint(Lower(\"name\"), name=\"name_lower_uniq\")\n    instance = UniqueConstraintProduct(name=self.p1.name.upper())\n    # Excluding a field used in the expression should skip validation.\n    constraint.validate(UniqueConstraintProduct, instance, exclude={\"name\"})\n    # Excluding a field not used in the expression should still validate.\n    with self.assertRaises(ValidationError):\n        constraint.validate(\n            UniqueConstraintProduct,\n            instance,\n            exclude={\"color\"},\n        )\n"], "sample_457": ["def test_validate_expression_with_exclude(self):\n    constraint = models.UniqueConstraint(Lower(\"name\"), name=\"name_lower_uniq\")\n    instance = UniqueConstraintProduct(name=self.p1.name.upper())\n    # Exclude should ignore the unique constraint.\n    constraint.validate(UniqueConstraintProduct, instance, exclude={\"name\"})\n    # Non-matching exclude should still raise an error.\n    msg = \"Constraint \u201cname_lower_uniq\u201d is violated.\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        constraint.validate(UniqueConstraintProduct, instance, exclude={\"color\"})\n"], "sample_458": ["    def test_stringformat01(self):\n        output = self.engine.render_to_string(\"stringformat01\", {\"a\": 1.23})\n        self.assertEqual(output, \"1.230000E+00\")\n"], "sample_459": ["    def test_get_prep_lookup(self):\n        class TestModel(models.Model):\n            value = models.IntegerField()\n\n        lookup = In(lhs=TestModel._meta.get_field(\"value\"), rhs=[1, 2, 3])\n        prep_lookup = lookup.get_prep_lookup()\n        self.assertEqual(prep_lookup, [1, 2, 3])\n"], "sample_461": ["def test_urlfield_clean_max_length(self):\n    f = URLField(max_length=20)\n    msg = \"'Ensure this value has at most 20 characters (it has 37).'\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        f.clean(\"http://abcdefghijklmnopqrstuvwxyz.com\")\n    self.assertEqual(f.clean(\"http://example.com\"), \"http://example.com\")\n"], "sample_462": ["def test_choicefield_with_initial(self):\n    f = ChoiceField(choices=[(\"1\", \"One\"), (\"2\", \"Two\")], initial=\"2\")\n    self.assertEqual(\"2\", f.clean(\"2\"))\n    self.assertEqual(\"2\", f.clean(2))\n    msg = \"'Select a valid choice. 3 is not one of the available choices.'\"\n    with self.assertRaisesMessage(ValidationError, msg):\n        f.clean(\"3\")\n"], "sample_465": ["def test_get_inline_formsets(self):\n    class ConcertInline(TabularInline):\n        model = Concert\n\n    class BandAdmin(ModelAdmin):\n        inlines = [ConcertInline]\n\n    ma = BandAdmin(Band, AdminSite())\n    request = MockRequest()\n    request.user = self.MockAddUser()\n    band = Band(name=\"The Doors\", bio=\"\", sign_date=date(1965, 1, 1))\n    inline_instances = ma.get_inline_instances(request, band)\n    formsets, inlines = zip(*ma.get_formsets_with_inlines(request, band))\n    self.assertEqual(len(formsets), 1)\n    self.assertIsInstance(formsets[0], forms.models.BaseInlineFormSet)\n    self.assertEqual(len(inlines), 1)\n    self.assertIsInstance(inlines[0], ConcertInline)\n\n    inline_admin_formsets = ma.get_inline_formsets(\n        request, formsets, inline_instances, band\n    )\n    self.assertEqual(len(inline_admin_formsets), 1)\n    self.assertIsInstance(inline_admin_formsets[0], helpers.InlineAdminFormSet)\n"], "sample_467": ["def test_value_from_datadict_invalid_date(self):\n    data = {\"field_year\": \"2010\", \"field_month\": \"2\", \"field_day\": \"31\"}\n    self.assertEqual(\n        self.widget.value_from_datadict(data, {}, \"field\"), \"0-2-31\"\n    )\n"], "sample_469": ["def test_alias_with_m2m(self):\n    qs = (\n        Author.objects.alias(\n            jacob_name=F(\"friends__name\"),\n        )\n        .filter(\n            friends__age=35,\n        )\n        .annotate(\n            james_name=F(\"jacob_name\"),\n        )\n        .values(\"james_name\")\n    )\n    self.assertCountEqual(qs, [{\"james_name\": \"Jacob Kaplan-Moss\"}])\n"], "sample_468": ["def test_make_context(self):\n    context = make_context({\"a\": 1})\n    self.assertIsInstance(context, Context)\n    self.assertEqual(context[\"a\"], 1)\n\n    request = self.request_factory.get(\"/\")\n    context = make_context({\"a\": 1}, request)\n    self.assertIsInstance(context, RequestContext)\n    self.assertEqual(context[\"a\"], 1)\n    self.assertEqual(context.request, request)\n\n    with self.assertRaises(TypeError):\n        make_context(\"not a dict\")\n\n    context = make_context(None)\n    self.assertIsInstance(context, Context)\n    self.assertEqual(context.dicts, [{\"False\": False, \"None\": None, \"True\": True}])\n"], "sample_471": ["def test_integerfield_widget_attrs(self):\n    f = IntegerField(min_value=10, max_value=20)\n    widget = f.widget\n    self.assertEqual(widget.attrs['min'], 10)\n    self.assertEqual(widget.attrs['max'], 20)\n\n    f = IntegerField(min_value=None, max_value=20)\n    widget = f.widget\n    self.assertNotIn('min', widget.attrs)\n    self.assertEqual(widget.attrs['max'], 20)\n\n    f = IntegerField(min_value=10, max_value=None)\n    widget = f.widget\n    self.assertEqual(widget.attrs['min'], 10)\n    self.assertNotIn('max', widget.attrs)\n\n    f = IntegerField(min_value=None, max_value=None)\n    widget = f.widget\n    self.assertNotIn('min', widget.attrs)\n    self.assertNotIn('max', widget.attrs)\n"], "sample_475": ["    def test_view_on_site_not_callable_or_boolean(self):\n        class TestModelAdmin(ModelAdmin):\n            view_on_site = \"not a callable or boolean\"\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'view_on_site' must be a callable or a boolean value.\",\n            id=\"admin.E025\",\n        )\n"], "sample_479": ["def test_rename_index_through_create(self):\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\"Pony\", [(\"weight\", models.IntegerField())]),\n            migrations.AddIndex(\"Pony\", models.Index(fields=(\"weight\",), name=\"old_name\")),\n            migrations.RenameIndex(\"Pony\", new_name=\"new_name\", old_name=\"old_name\"),\n        ],\n        [\n            migrations.CreateModel(\n                \"Pony\",\n                [(\"weight\", models.IntegerField())],\n                options={\"indexes\": [models.Index(fields=(\"weight\",), name=\"new_name\")]},\n            ),\n        ],\n    )\n"], "sample_480": ["def test_key_transform_on_expression_wrapper(self):\n    self.assertCountEqual(\n        NullableJSONModel.objects.annotate(\n            expr=ExpressionWrapper(\n                KeyTransform(\"c\", \"value\"),\n                output_field=IntegerField(),\n            ),\n        ).filter(expr__gt=10),\n        [self.objs[3], self.objs[4]],\n    )\n"], "sample_481": ["    def test_add01(self):\n        output = self.engine.render_to_string(\"add01\", {\"a\": 5})\n        self.assertEqual(output, \"7\")\n"], "sample_482": ["    def test_basic(self):\n        output = self.engine.render_to_string(\n            \"safeseq_basic\",\n            {\"a\": [\"x&y\", \"<p>\"], \"b\": [mark_safe(\"x&y\"), mark_safe(\"<p>\")]},\n        )\n        self.assertEqual(output, \"x&y, <p> -- x&y, <p>\")\n"], "sample_486": ["def test_inlineformset_factory_with_to_field(self):\n    \"\"\"\n    #25354 - Test that inlineformset_factory works with a ForeignKey that uses\n    to_field.\n    \"\"\"\n    FormSet = inlineformset_factory(\n        ParentWithUUIDAlternateKey, ChildRelatedViaAK, fields=\"__all__\", fk_name=\"parent\"\n    )\n    formset = FormSet()\n    self.assertIsNone(formset.forms[0].fields[\"parent\"].initial)\n"], "sample_487": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            \"admin.E034\",\n        )\n"], "sample_489": ["def test_update_conflicts_fields_not_in_model(self):\n    msg = \"bulk_create() can only be used with concrete fields in update_fields.\"\n    with self.assertRaisesMessage(ValueError, msg):\n        TwoFields.objects.bulk_create(\n            [TwoFields(f1=1, f2=1)],\n            update_conflicts=True,\n            update_fields=[\"nonexistent\"],\n        )\n"], "sample_490": ["def test_unique_constraint_with_expressions_clone(self):\n    constraint = models.UniqueConstraint(\n        Lower(\"title\"),\n        F(\"author\"),\n        name=\"book_func_uq\",\n        violation_error_message=\"custom error message\",\n        violation_error_code=\"custom_error_code\",\n    )\n    cloned_constraint = constraint.clone()\n    self.assertEqual(constraint, cloned_constraint)\n    self.assertEqual(cloned_constraint.violation_error_message, \"custom error message\")\n    self.assertEqual(cloned_constraint.violation_error_code, \"custom_error_code\")\n"], "sample_493": ["def test_aggregate_over_subquery_annotation(self):\n    subquery = Book.objects.filter(publisher=OuterRef(\"pk\")).order_by(\"-pages\")\n    publishers = Publisher.objects.annotate(\n        largest_book_pages=Subquery(subquery.values(\"pages\")[:1])\n    ).aggregate(Avg(\"largest_book_pages\"))\n    self.assertEqual(publishers[\"largest_book_pages__avg\"], 568)\n"], "sample_494": ["def test_serialize_none_as_default(self):\n    field = models.CharField(max_length=255, default=None)\n    string, imports = MigrationWriter.serialize(field)\n    self.assertEqual(\n        string,\n        \"models.CharField(default=None, max_length=255)\",\n    )\n    self.assertEqual(imports, {\"from django.db import models\"})\n"], "sample_497": ["def test_axis_remove_overlapping_ticks():\n    fig, ax = plt.subplots()\n    ax.set_xlim(0, 10)\n    ax.xaxis.set_major_locator(mticker.MultipleLocator(1))\n    ax.xaxis.remove_overlapping_locs = False\n    assert len(ax.get_xticks()) == 11\n\n    ax.xaxis.remove_overlapping_locs = True\n    assert len(ax.get_xticks()) < 11\n"], "sample_498": ["def test_legend_handles_labels_from_containers():\n    fig, ax = plt.subplots()\n    ax.bar(range(3), range(3), label='bar')\n    ax.errorbar(range(3), range(3), yerr=1, label='errorbar')\n    ax.stem(range(3), range(3), label='stem')\n\n    handles, labels = ax.get_legend_handles_labels()\n    assert len(handles) == 3\n    assert len(labels) == 3\n\n    assert isinstance(handles[0], mpatches.Rectangle)\n    assert isinstance(handles[1], mlines.Line2D)\n    assert isinstance(handles[2], mlines.Line2D)\n\n    assert labels == ['bar', 'errorbar', 'stem']\n"], "sample_501": ["def test_legend_bbox_to_anchor():\n    fig, ax = plt.subplots()\n    ax.plot([1, 2], [3, 4], label='line')\n    leg = ax.legend(bbox_to_anchor=(0.5, 0.5), loc='center')\n\n    assert leg.get_bbox_to_anchor().x0 == 0.5\n    assert leg.get_bbox_to_anchor().y0 == 0.5\n"], "sample_503": ["def test_axline(fig_test, fig_ref):\n    fig_test.add_subplot().axline((0.2, 0.3), (0.8, 0.7), color='r')\n    fig_ref.add_subplot().plot([0, 1], [0.5 - 0.4/6, 0.5 + 0.4/6], color='r',\n                               transform=mtransforms.IdentityTransform())\n"], "sample_505": ["def test_date2num_out_of_range():\n    # Test that date2num raises an error for dates outside the valid range.\n    with pytest.raises(ValueError):\n        mdates.date2num(datetime.datetime(1, 1, 1) - datetime.timedelta(days=1))\n    with pytest.raises(ValueError):\n        mdates.date2num(datetime.datetime(9999, 12, 31) + datetime.timedelta(days=1))\n"], "sample_506": ["def test_spine_bounds():\n    fig, ax = plt.subplots()\n    spine = ax.spines['left']\n    assert spine.get_bounds() is None\n\n    spine.set_bounds(0, 1)\n    assert spine.get_bounds() == (0, 1)\n\n    spine.set_bounds(None, 2)\n    assert spine.get_bounds() == (0, 2)\n\n    spine.set_bounds(3, None)\n    assert spine.get_bounds() == (3, 2)\n\n    spine.set_bounds((4, 5))\n    assert spine.get_bounds() == (4, 5)\n\n    with pytest.raises(ValueError):\n        spine.set_bounds('foo', 1)\n\n    with pytest.raises(ValueError):\n        spine.set_bounds(1, 'bar')\n\n    with pytest.raises(ValueError):\n        spine.set_bounds((1, 2, 3))\n\n    with pytest.raises(ValueError):\n        spine.set_bounds((1,))\n"], "sample_511": ["def test_subplot_mosaic():\n    fig, axd = plt.subplot_mosaic([['left', 'right'], ['bottom', 'bottom']])\n    assert len(axd) == 3\n    assert axd['left'] is not None\n    assert axd['right'] is not None\n    assert axd['bottom'] is not None\n\n    # Check that the axes are in the correct positions\n    assert axd['left'].get_position().x0 < axd['right'].get_position().x0\n    assert axd['bottom'].get_position().y0 < axd['left'].get_position().y0\n    assert axd['bottom'].get_position().y0 < axd['right'].get_position().y0\n\n    # Check that the axes have the correct size\n    assert axd['left'].get_position().width > 0\n    assert axd['right'].get_position().width > 0\n    assert axd['bottom'].get_position().height > 0\n"], "sample_512": ["def test_subplot_mosaic():\n    fig, axes = plt.subplot_mosaic([['A', 'B'], ['C', 'D']])\n    assert len(axes) == 4\n    assert set(axes.keys()) == {'A', 'B', 'C', 'D'}\n    for ax in axes.values():\n        assert isinstance(ax, mpl.axes.Axes)\n"], "sample_516": ["def test_pdf_pages_close():\n    pdfio = io.BytesIO()\n    pdf = PdfPages(pdfio)\n    fig, ax = plt.subplots()\n    ax.plot([1, 2, 3])\n    pdf.savefig(fig)\n    pdf.close()\n    assert pdf._file is None\n"], "sample_517": ["def test_text_get_window_extent_with_transform():\n    fig, ax = plt.subplots()\n    text = ax.text(0.5, 0.5, 'test')\n    transform = mtransforms.Affine2D().rotate_deg(30)\n    text.set_transform(transform)\n    extent1 = text.get_window_extent(fig.canvas.renderer)\n    extent2 = text.get_window_extent(fig.canvas.renderer, dpi=fig.dpi)\n    np.testing.assert_allclose(extent1.get_points(), extent2.get_points())\n"], "sample_518": ["def test_default_joinstyle():\n    patch = Patch()\n    assert patch.get_joinstyle() == 'miter'\n"], "sample_519": ["def test_subfigure_repr():\n    fig = plt.figure()\n    subfig = fig.subfigures(1, 1)[0]\n    assert repr(subfig) == \"<SubFigure size 640x480 with 0 Axes>\"\n"], "sample_521": ["def test_line_3d(fig_test, fig_ref):\n    ax = fig_ref.add_subplot(projection=\"3d\")\n    line = lines.Line2D([0, 1], [0, 1])\n    art3d.line_2d_to_3d(line, zs=1)\n    ax.add_artist(line)\n    assert line.get_data_3d() == ([0, 1], [0, 1], [1, 1])\n\n    ax = fig_test.add_subplot(projection=\"3d\")\n    l3d = art3d.Line3D([0, 1], [0, 1], [1, 1])\n    ax.add_artist(l3d)\n    assert l3d.get_data_3d() == ([0, 1], [0, 1], [1, 1])\n"], "sample_531": ["def test_subfigure_repr():\n    fig = plt.figure()\n    subfig = fig.subfigures(1, 1)[0]\n    assert repr(subfig) == f\"<{subfig.__class__.__name__} size {subfig.get_size_inches()[0]:g}x{subfig.get_size_inches()[1]:g} with 0 Axes>\"\n"], "sample_532": ["def test_contourf_with_alpha():\n    fig, ax = plt.subplots()\n    x = np.linspace(-3.0, 3.0, 100)\n    y = np.linspace(-2.0, 2.0, 100)\n    X, Y = np.meshgrid(x, y)\n    Z1 = np.exp(-X**2 - Y**2)\n    Z2 = np.exp(-(X - 1)**2 - (Y - 1)**2)\n    Z = (Z1 - Z2) * 2\n\n    # Test contourf with alpha\n    cs = ax.contourf(X, Y, Z, alpha=0.5)\n    assert cs.alpha == 0.5\n\n    # Test contourf with alpha and colors\n    cs = ax.contourf(X, Y, Z, colors=['red', 'green', 'blue'], alpha=0.5)\n    assert cs.alpha == 0.5\n\n    # Test contourf with alpha and cmap\n    cs = ax.contourf(X, Y, Z, cmap='viridis', alpha=0.5)\n    assert cs.alpha == 0.5\n"], "sample_542": ["def test_get_rotation_mode():\n    text = Text(0, 0, 'test')\n    assert text.get_rotation_mode() is None\n\n    text.set_rotation_mode('default')\n    assert text.get_rotation_mode() == 'default'\n\n    text.set_rotation_mode('anchor')\n    assert text.get_rotation_mode() == 'anchor'\n"], "sample_545": ["def test_subfigure_repr():\n    fig = plt.figure()\n    subfig = fig.subfigures(1, 2)[0]\n    assert repr(subfig) == \"<SubFigure size 640x480 with 0 Axes>\"\n"], "sample_546": ["def test_figure_repr():\n    fig = Figure()\n    assert repr(fig) == \"<Figure size 640x480 with 0 Axes>\"\n    ax = fig.add_subplot(111)\n    assert repr(fig) == \"<Figure size 640x480 with 1 Axes>\"\n"], "sample_549": ["def test__get_nonzero_slices():\n    buf = np.array([[0, 1, 0], [0, 0, 0], [1, 0, 1]])\n    slices = cbook._get_nonzero_slices(buf)\n    assert_array_equal(buf[slices], np.array([[1, 0], [0, 0], [1, 0]]))\n"], "sample_550": ["def test_axes_set_position():\n    fig, ax = plt.subplots()\n    orig_pos = ax.get_position(original=True)\n    new_pos = [orig_pos.x0 + 0.1, orig_pos.y0 + 0.1,\n               orig_pos.width - 0.2, orig_pos.height - 0.2]\n    ax.set_position(new_pos)\n    assert np.allclose(ax.get_position().bounds, new_pos)\n    ax.reset_position()\n    assert np.allclose(ax.get_position().bounds, orig_pos.bounds)\n"], "sample_551": ["def test_text3d():\n    fig, ax = plt.subplots(subplot_kw=dict(projection='3d'))\n    text = art3d.Text3D(0.5, 0.5, 0.5, 'Hello, world!')\n    ax.add_artist(text)\n    assert text.get_position_3d() == (0.5, 0.5, 0.5)\n    text.set_position_3d((1.0, 1.0, 1.0))\n    assert text.get_position_3d() == (1.0, 1.0, 1.0)\n    text.set_z(2.0)\n    assert text.get_position_3d() == (1.0, 1.0, 2.0)\n"], "sample_552": ["def test_subfigure_repr():\n    fig = plt.figure()\n    subfig = fig.subfigures(1, 1)\n    assert repr(subfig[0]) == \"<SubFigure size 640x480 with 0 Axes>\"\n"], "sample_553": ["def test_to_jshtml(anim):\n    # Test the to_jshtml method\n    html = anim.to_jshtml()\n    assert '<script>' in html\n    assert 'data:image' in html\n"], "sample_554": ["def test_text_set_backgroundcolor():\n    fig, ax = plt.subplots()\n    text = ax.text(0.5, 0.5, 'test')\n    text.set_backgroundcolor('red')\n    assert text.get_bbox_patch().get_facecolor() == (1.0, 0.0, 0.0, 1.0)\n"], "sample_556": ["def test_subfigure_repr():\n    fig = plt.figure()\n    subfig = fig.subfigures(1, 2)[0]\n    assert repr(subfig) == f\"<{subfig.__class__.__name__} size {subfig.get_size_inches()[0]:g}x{subfig.get_size_inches()[1]:g} with 0 Axes>\"\n"], "sample_557": ["def test_subfigure_repr():\n    fig = plt.figure()\n    subfig = fig.subfigures(1, 2)[0]\n    assert repr(subfig) == \"<SubFigure size 640x480 with 0 Axes>\"\n"], "sample_562": ["def test_axline(fig_test, fig_ref):\n    ax1 = fig_test.add_subplot()\n    ax2 = fig_ref.add_subplot()\n\n    ax1.axline((0.5, 0.5), (1, 1), color='r')\n    ax2.plot([0.5, 1], [0.5, 1], color='r')\n\n    ax1.axline((0.3, 0.4), slope=2, color='g')\n    ax2.plot([0, 1], [0.1, 2.1], color='g')\n"], "sample_566": ["def test_subfigure_repr():\n    fig = plt.figure()\n    subfig = fig.subfigures(1, 1)[0]\n    assert repr(subfig) == f\"<{type(subfig).__name__} size {subfig.get_size_inches()[0]:g}x{subfig.get_size_inches()[1]:g} with 0 Axes>\"\n"], "sample_568": ["def test_line3d_collection_modification(fig_test, fig_ref):\n    # Test that modifying Line3DCollection properties after creation works.\n    x = [0, 1]\n    y = [0, 1]\n    z = [0, 1]\n    c = art3d.Line3DCollection([[(x[0], y[0], z[0]), (x[1], y[1], z[1])]],\n                               linewidths=3)\n\n    ax_test = fig_test.add_subplot(projection='3d')\n    ax_test.add_collection3d(c)\n    c.set_edgecolor('C2')\n    c.set_alpha(0.7)\n    assert c.get_depthshade()\n    c.set_depthshade(False)\n    assert not c.get_depthshade()\n\n    c = art3d.Line3DCollection([[(x[0], y[0], z[0]), (x[1], y[1], z[1])]],\n                               edgecolor='C2', alpha=0.7, depthshade=False)\n\n    ax_ref = fig_ref.add_subplot(projection='3d')\n    ax_ref.add_collection3d(c)\n"], "sample_569": ["def test_lmplot_x_estimator(self):\n\n    g = lm.lmplot(x=\"x\", y=\"y\", data=self.df, x_estimator=np.mean)\n    ax = g.axes[0, 0]\n    assert len(ax.lines) == 1\n    assert len(ax.collections) == 2\n\n    x, y = ax.collections[0].get_offsets().T\n    npt.assert_array_equal(x, np.unique(self.df.x))\n    npt.assert_array_almost_equal(y, self.df.groupby(\"x\").y.mean())\n"], "sample_571": ["def test_lmplot_legend_options(self):\n\n    g = lm.lmplot(x=\"x\", y=\"y\", hue=\"h\", data=self.df, legend=False)\n    assert g._legend is None\n\n    g = lm.lmplot(x=\"x\", y=\"y\", hue=\"h\", data=self.df, legend=True)\n    assert g._legend is not None\n"], "sample_574": ["    def test_identity(self):\n\n        s = Scale._identity()\n        x = pd.Series([1, 2, 3], name=\"x\")\n        assert_series_equal(s(x), x)\n"], "sample_575": ["    def test_coordinate_defaults(self):\n\n        scale = Continuous()._setup(pd.Series([1, 2, 3], name=\"x\"), Coordinate())\n        axis = PseudoAxis(scale._matplotlib_scale)\n        assert axis.get_scale() == scale._matplotlib_scale\n"], "sample_576": ["def test_legend_has_no_offset_with_scale(self, xy):\n\n    color = np.add(xy[\"x\"], 1e8)\n    p = Plot(**xy, color=color).scale(color=\"log\").add(MockMark()).plot()\n    legend = p._figure.legends[0]\n    assert legend.texts\n    for text in legend.texts:\n        assert float(text.get_text()) > 1e7\n"], "sample_577": ["    def test_repr_png(self):\n\n        p = Plot().plot()\n        data, metadata = p._repr_png_()\n        img = Image.open(io.BytesIO(data))\n\n        assert not hasattr(p, \"_figure\")\n        assert isinstance(data, bytes)\n        assert img.format == \"PNG\"\n        assert sorted(metadata) == [\"height\", \"width\"]\n"], "sample_581": ["def test_blueprint_cli_group(app, cli_runner):\n    bp = flask.Blueprint(\"bp\", __name__, cli_group=None)\n\n    @bp.cli.command()\n        return \"cmd\"\n\n    app.register_blueprint(bp)\n    result = cli_runner.invoke(cmd)\n    assert result.output == \"cmd\\n\"\n\n    bp2 = flask.Blueprint(\"bp2\", __name__, cli_group=\"group\")\n\n    @bp2.cli.command()\n        return \"cmd2\"\n\n    app.register_blueprint(bp2)\n    result = cli_runner.invoke(cmd2, [\"--help\"])\n    assert \"(group)\" in result.output\n\n    bp3 = flask.Blueprint(\"bp3\", __name__)\n\n    @bp3.cli.command()\n        return \"cmd3\"\n\n    app.register_blueprint(bp3, cli_group=\"group\")\n    result = cli_runner.invoke(cmd3, [\"--help\"])\n    assert \"(group)\" in result.output\n"], "sample_583": ["def test_posify_mask_indexer():\n    indexer = indexing.OuterIndexer((np.array([0, -1, 2]),))\n    expected = indexing.OuterIndexer((np.array([0, 0, 2]),))\n    actual = indexing.posify_mask_indexer(indexer)\n    assert actual.tuple == expected.tuple\n\n    indexer = indexing.VectorizedIndexer(\n        (np.array([0, -1, 2]), np.array([0, 1, -1])))\n    expected = indexing.VectorizedIndexer(\n        (np.array([0, 0, 2]), np.array([0, 1, 1])))\n    actual = indexing.posify_mask_indexer(indexer)\n    assert actual.tuple == expected.tuple\n\n    indexer = indexing.BasicIndexer((-1,))\n    expected = indexing.BasicIndexer((0,))\n    actual = indexing.posify_mask_indexer(indexer)\n    assert actual.tuple == expected.tuple\n"], "sample_587": ["def test_merge_update_no_conflicts(self):\n    data = create_test_data()\n    ds1 = data[[\"var1\"]]\n    ds2 = data[[\"var3\"]]\n\n    # check that attrs are preserved\n    ds1.attrs['foo'] = 'bar'\n    expected = xr.merge([ds1, ds2], compat=\"no_conflicts\")\n    actual = ds1.copy()\n    actual.update(ds2, compat=\"no_conflicts\")\n    assert expected.identical(actual)\n    assert actual.attrs == ds1.attrs\n\n    # check that encoding is preserved\n    ds1['var1'].encoding['foo'] = 'bar'\n    expected = xr.merge([ds1, ds2], compat=\"no_conflicts\")\n    actual = ds1.copy()\n    actual.update(ds2, compat=\"no_conflicts\")\n    assert expected.identical(actual)\n    assert actual['var1'].encoding == ds1['var1'].encoding\n"], "sample_595": ["def test_decode_encode_errors():\n    data = xr.DataArray([\"a\", \"b\", \"a\\xe4\"])\n\n    # Test decoding with errors\n    encoded = data.str.encode(\"utf-8\")\n    decoded_strict = encoded.str.decode(\"ascii\", errors=\"strict\")\n    with pytest.raises(UnicodeDecodeError):\n        decoded_strict.compute()\n\n    decoded_replace = encoded.str.decode(\"ascii\", errors=\"replace\")\n    expected_replace = xr.DataArray([\"a\", \"b\", \"a?\"])\n    assert_equal(decoded_replace, expected_replace)\n\n    decoded_ignore = encoded.str.decode(\"ascii\", errors=\"ignore\")\n    expected_ignore = xr.DataArray([\"a\", \"b\", \"a\"])\n    assert_equal(decoded_ignore, expected_ignore)\n\n    # Test encoding with errors\n    decoded = xr.DataArray([\"a\", \"b\", \"a\\xe4\"])\n    encoded_strict = decoded.str.encode(\"ascii\", errors=\"strict\")\n    with pytest.raises(UnicodeEncodeError):\n        encoded_strict.compute()\n\n    encoded_replace = decoded.str.encode(\"ascii\", errors=\"replace\")\n    expected_replace = xr.DataArray([b\"a\", b\"b\", b\"a?\"])\n    assert_equal(encoded_replace, expected_replace)\n\n    encoded_ignore = decoded.str.encode(\"ascii\", errors=\"ignore\")\n    expected_ignore = xr.DataArray([b\"a\", b\"b\", b\"a\"])\n    assert_equal(encoded_ignore, expected_ignore)\n"], "sample_606": ["def test_cross() -> None:\n    a = xr.DataArray([1, 2, 3], dims=[\"cartesian\"])\n    b = xr.DataArray([4, 5, 6], dims=[\"cartesian\"])\n\n    expected = xr.DataArray(\n        np.cross(a.values, b.values), dims=[\"cartesian\"], coords=a.coords\n    )\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(expected, actual)\n\n    # test with different dimension lengths\n    a = xr.DataArray([1, 2], dims=[\"cartesian\"])\n    b = xr.DataArray([4, 5, 6], dims=[\"cartesian\"])\n\n    expected = xr.DataArray(\n        np.cross(a.values, b.values[:2]), dims=[\"cartesian\"], coords=a.coords\n    )\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(expected, actual)\n\n    # test with broadcasting\n    a = xr.DataArray([1, 2], dims=[\"cartesian\"])\n    b = xr.DataArray([[4, 5, 6], [7, 8, 9]], dims=[\"time\", \"cartesian\"])\n\n    expected = xr.DataArray(\n        np.cross(a.values, b.values[:, :2]),\n        dims=[\"time\", \"cartesian\"],\n        coords=b.coords,\n    )\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(expected, actual)\n"], "sample_615": ["def test_cross() -> None:\n    # 1D vectors\n    a = xr.DataArray([1, 2, 3], dims=[\"cartesian\"])\n    b = xr.DataArray([4, 5, 6], dims=[\"cartesian\"])\n\n    expected = np.cross(a.values, b.values)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(actual, expected)\n\n    # 2D vectors\n    a = xr.DataArray([[1, 2], [3, 4]], dims=[\"time\", \"cartesian\"])\n    b = xr.DataArray([[4, 5], [6, 7]], dims=[\"time\", \"cartesian\"])\n\n    expected = np.cross(a.values, b.values)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(actual, expected)\n\n    # 2D vectors with different lengths\n    a = xr.DataArray([[1, 2], [3, 4]], dims=[\"time\", \"cartesian\"])\n    b = xr.DataArray([[4, 5, 6], [7, 8, 9]], dims=[\"time\", \"cartesian\"])\n\n    expected = np.cross(\n        a.values, b.values[:, :2]\n    )  # Note: numpy's cross would fail on this\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(actual, expected)\n\n    # 2D vectors with broadcasting\n    a = xr.DataArray([1, 2], dims=[\"cartesian\"])\n    b = xr.DataArray([[4, 5], [6, 7]], dims=[\"time\", \"cartesian\"])\n\n    expected = np.cross(a.values, b.values)\n    actual = xr.cross(a, b, dim=\"cartesian\")\n    assert_identical(actual, expected)\n\n    # edge cases\n    with pytest.raises(ValueError):\n        xr.cross(a, b, dim=\"wrong\")\n\n    with pytest.raises(ValueError):\n        xr.cross(a, b, dim=None)\n\n    with pytest.raises(ValueError):\n        xr.cross(a, b.values, dim=\"cartesian\")\n\n    with pytest.raises(ValueError):\n        xr.cross(a.variable, b, dim=\"cartesian\")\n\n    with pytest.raises(ValueError):\n        xr.cross(a, b.variable, dim=\"cartesian\")\n"], "sample_616": ["def test_polyval_degree_dim_checks_dataset():\n    x = xr.DataArray([1, 2, 3], dims=\"x\")\n    coeffs = xr.Dataset(\n        {\"a\": (\"degree\", [2, 3, 4])}, coords={\"degree\": [0, 1, 2]}\n    )\n    with pytest.raises(ValueError):\n        xr.polyval(x, coeffs.drop_vars(\"degree\"))\n    with pytest.raises(ValueError):\n        xr.polyval(x, coeffs.assign_coords(degree=coeffs.degree.astype(float)))\n"], "sample_617": ["def test_cross() -> None:\n    a = xr.DataArray([1, 2, 3], dims=\"x\")\n    b = xr.DataArray([4, 5, 6], dims=\"x\")\n\n    expected = xr.DataArray([-3, 6, -3], dims=\"x\")\n    actual = xr.cross(a, b, dim=\"x\")\n    assert_identical(expected, actual)\n\n    # test with broadcasting\n    a = xr.DataArray([[1, 2, 3], [4, 5, 6]], dims=(\"y\", \"x\"))\n    b = xr.DataArray([4, 5, 6], dims=\"x\")\n\n    expected = xr.DataArray([[-3, 6, -3], [-6, 12, -6]], dims=(\"y\", \"x\"))\n    actual = xr.cross(a, b, dim=\"x\")\n    assert_identical(expected, actual)\n\n    # test with 2D vectors\n    a = xr.DataArray([1, 2], dims=\"x\")\n    b = xr.DataArray([4, 5], dims=\"x\")\n\n    expected = xr.DataArray(-3)\n    actual = xr.cross(a, b, dim=\"x\")\n    assert_identical(expected, actual)\n\n    # test with 2D vectors and broadcasting\n    a = xr.DataArray([[1, 2], [3, 4]], dims=(\"y\", \"x\"))\n    b = xr.DataArray([4, 5], dims=\"x\")\n\n    expected = xr.DataArray([-3, -6], dims=\"y\")\n    actual = xr.cross(a, b, dim=\"x\")\n    assert_identical(expected, actual)\n"], "sample_618": ["def test_polyval_degree_dim_checks_dataset():\n    x = xr.DataArray([1, 2, 3], dims=\"x\")\n    coeffs = xr.Dataset(\n        {\"a\": (\"degree\", [2, 3, 4])}, coords={\"degree\": [0, 1, 2]}\n    )\n    with pytest.raises(ValueError):\n        xr.polyval(x, coeffs.drop_vars(\"degree\"))\n    with pytest.raises(ValueError):\n        xr.polyval(x, coeffs.assign_coords(degree=coeffs.degree.astype(float)))\n"], "sample_621": ["def test_copy_indexes(self, indexes) -> None:\n    new_indexes, new_variables = indexes.copy_indexes(deep=True)\n\n    assert new_indexes.keys() == indexes.keys()\n    for k in new_indexes:\n        assert new_indexes[k].equals(indexes[k])\n        assert new_indexes[k] is not indexes[k]\n\n    assert new_variables.keys() == indexes.variables.keys()\n    for k in new_variables:\n        assert_identical(new_variables[k], indexes.variables[k])\n        assert new_variables[k] is not indexes.variables[k]\n"], "sample_624": ["def test_format_timedelta() -> None:\n    cases = [\n        (pd.Timedelta(\"10 days 1 hour\"), \"10 days 01:00:00\"),\n        (pd.Timedelta(\"-3 days\"), \"-3 days +00:00:00\"),\n        (pd.Timedelta(\"3 hours\"), \"0 days 03:00:00\"),\n        (np.timedelta64(10, \"D\"), \"10 days 00:00:00\"),\n        (np.timedelta64(-3, \"D\"), \"-3 days 00:00:00\"),\n        (np.timedelta64(3, \"h\"), \"0 days 03:00:00\"),\n    ]\n    for item, expected in cases:\n        actual = formatting.format_timedelta(item)\n        assert expected == actual\n\n    # Test with different formats\n    cases = [\n        (pd.Timedelta(\"10 days 1 hour\"), \"date\", \"10 days\"),\n        (pd.Timedelta(\"-3 days\"), \"date\", \"-3 days\"),\n        (pd.Timedelta(\"3 hours\"), \"date\", \"0 days\"),\n        (pd.Timedelta(\"10 days 1 hour\"), \"time\", \"01:00:00\"),\n        (pd.Timedelta(\"-3 days\"), \"time\", \"+00:00:00\"),\n        (pd.Timedelta(\"3 hours\"), \"time\", \"03:00:00\"),\n    ]\n    for item, timedelta_format, expected in cases:\n        actual = formatting.format_timedelta(item, timedelta_format=timedelta_format)\n        assert expected == actual\n"], "sample_625": ["def test_cross() -> None:\n    a = xr.DataArray([1, 2, 3], dims=\"x\")\n    b = xr.DataArray([4, 5, 6], dims=\"x\")\n\n    expected = xr.DataArray([-3, 6, -3], dims=\"x\")\n    actual = xr.cross(a, b, dim=\"x\")\n    assert_identical(actual, expected)\n\n    # test with 2D arrays\n    a = xr.DataArray([[1, 2], [3, 4]], dims=(\"x\", \"y\"))\n    b = xr.DataArray([[4, 5], [6, 7]], dims=(\"x\", \"y\"))\n\n    expected = xr.DataArray([[-3, 6], [-3, 6]], dims=(\"x\", \"y\"))\n    actual = xr.cross(a, b, dim=\"y\")\n    assert_identical(actual, expected)\n\n    # test with different sizes along core dimension\n    a = xr.DataArray([1, 2], dims=\"x\")\n    b = xr.DataArray([4, 5, 6], dims=\"x\")\n\n    expected = xr.DataArray([-10, 2, 5], dims=\"x\")\n    actual = xr.cross(a, b, dim=\"x\")\n    assert_identical(actual, expected)\n\n    # test with Dataset\n    ds_a = xr.Dataset(dict(x=(\"dim_0\", [1]), y=(\"dim_0\", [2]), z=(\"dim_0\", [3])))\n    ds_b = xr.Dataset(dict(x=(\"dim_0\", [4]), y=(\"dim_0\", [5]), z=(\"dim_0\", [6])))\n\n    expected = xr.Dataset(\n        dict(x=(\"dim_0\", [-3]), y=(\"dim_0\", [6]), z=(\"dim_0\", [-3]))\n    )\n    actual = xr.cross(ds_a.to_array(\"cartesian\"), ds_b.to_array(\"cartesian\"), dim=\"cartesian\").to_dataset(dim=\"cartesian\")\n    assert_identical(actual, expected)\n"], "sample_626": ["def test_create_mask():\n    shape = (3, 4)\n    indexer = VectorizedIndexer((np.array([0, 1]), np.array([2, 3])))\n    expected = np.array([[False, False, True, False], [False, False, False, True], [False, False, False, False]])\n    actual = create_mask(indexer, shape)\n    assert_array_equal(actual, expected)\n\n    indexer = OuterIndexer((np.array([0, 1]), slice(None)))\n    expected = np.array([[True, True, True, True], [True, True, True, True], [False, False, False, False]])\n    actual = create_mask(indexer, shape)\n    assert_array_equal(actual, expected)\n\n    indexer = BasicIndexer((1, slice(None)))\n    expected = np.array([[False, False, False, False], [True, True, True, True], [False, False, False, False]])\n    actual = create_mask(indexer, shape)\n    assert_array_equal(actual, expected)\n"], "sample_631": ["def test_undefined_variable_in_nested_function(self):\n    \"\"\"Make sure undefined-variable is detected in nested functions\"\"\"\n    node = astroid.parse(\n        \"\"\"\n                return undefined  #@\n        \"\"\"\n    )\n    with self.assertAddsMessages(\n        Message(\"undefined-variable\", node=node.body[0].body[0].body[0].value, args=\"undefined\")\n    ):\n        self.walk(node)\n"], "sample_632": ["def test_similar_checker_process_module():\n    linter = PyLinter()\n    reporter = Reporter()\n    linter.set_reporter(reporter)\n    checker = similar.SimilarChecker(linter)\n    node = astroid.parse(\"\"\"\n            pass\n    \"\"\")\n    node.file_encoding = \"utf-8\"\n    with open(__file__, \"r\") as stream:\n        node.stream = lambda: stream\n        checker.process_module(node)\n    assert len(checker.linesets) == 1\n"], "sample_636": ["def test_duplicate_code_raw_strings_min_similarities_lines(self) -> None:\n    \"\"\"Tests duplicate code detection with different min-similarities-lines.\"\"\"\n    path = join(DATA, \"raw_strings_all\")\n    expected_output = \"Similar lines in 2 files\"\n    self._test_output(\n        [\n            path,\n            \"--disable=all\",\n            \"--enable=duplicate-code\",\n            \"--min-similarity-lines=3\",\n        ],\n        expected_output=expected_output,\n    )\n    self._runtest(\n        [\n            path,\n            \"--disable=all\",\n            \"--enable=duplicate-code\",\n            \"--min-similarity-lines=10\",\n        ],\n        code=0,\n    )\n"], "sample_644": ["def test_useless_import_alias(self) -> None:\n    module = astroid.parse(\n        \"\"\"\n        import numpy as numpy\n        from package import module as module\n        \"\"\"\n    )\n    self.checker.visit_import(module.body[0])\n    self.checker.visit_importfrom(module.body[1])\n\n    msg1 = MessageTest(\n        msg_id=\"useless-import-alias\",\n        node=module.body[0],\n        line=2,\n        col_offset=0,\n        end_line=2,\n        end_col_offset=24,\n    )\n    msg2 = MessageTest(\n        msg_id=\"consider-using-from-import\",\n        node=module.body[1],\n        args=(\"package\", \"module\"),\n        line=3,\n        col_offset=0,\n        end_line=3,\n        end_col_offset=34,\n    )\n\n    with self.assertAddsMessages(msg1, msg2):\n        pass\n"], "sample_654": ["def test_call_fixture_function_error():\n    \"\"\"Check if an error is raised if a fixture function is called directly (#4545)\"\"\"\n\n    @pytest.fixture\n        return 1\n\n    with pytest.raises(pytest.FixtureLookupError):\n        fix()\n"], "sample_659": ["def test_traceback_entry_set_repr_style(self):\n    entry = TracebackEntry(None)\n    assert entry._repr_style is None\n    entry.set_repr_style(\"short\")\n    assert entry._repr_style == \"short\"\n    with pytest.raises(AssertionError):\n        entry.set_repr_style(\"invalid\")\n"], "sample_662": ["def test_base_report_properties(self, testdir):\n    \"\"\"Test properties of BaseReport.\"\"\"\n    reprec = testdir.inline_runsource(\n        \"\"\"\n        @pytest.mark.skipif(\"True\")\n        \"\"\"\n    )\n    reports = reprec.getreports(\"pytest_runtest_logreport\")\n    assert len(reports) == 9\n\n    for rep in reports:\n        assert isinstance(rep.caplog, str)\n        assert isinstance(rep.capstdout, str)\n        assert isinstance(rep.capstderr, str)\n        assert isinstance(rep.fspath, str)\n        assert isinstance(rep.count_towards_summary, bool)\n        if rep.head_line is not None:\n            assert isinstance(rep.head_line, str)\n\n    # Check caplog, capstdout and capstderr are not empty when capturing is enabled.\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n            logging.info('info')\n            print('stdout')\n            import sys\n            print('stderr', file=sys.stderr)\n        \"\"\"\n    )\n    reprec = testdir.inline_run(\"--capture=no\")\n    reports = reprec.getreports(\"pytest_runtest_logreport\")\n    assert len(reports) == 3\n    rep = reports[1]\n    assert rep.caplog != \"\"\n    assert rep.capstdout != \"\"\n    assert rep.capstderr != \"\"\n"], "sample_675": ["def test_log_file_format(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        log_file_format = %(asctime)s %(levelname)s %(message)s\n        log_file_date_format = %Y-%m-%d %H:%M:%S\n        \"\"\".format(\n            log_file\n        )\n    )\n\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logging.info('text going to logger')\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n\n    assert result.ret == 0\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert re.match(r\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2} INFO text going to logger\", contents)\n"], "sample_683": ["def test_capture_manager_is_capturing() -> None:\n    capman = CaptureManager(\"fd\")\n    assert capman.is_capturing() == \"global\"\n    capman.start_global_capturing()\n    assert capman.is_capturing() == \"global\"\n    capman.stop_global_capturing()\n    assert capman.is_capturing() is False\n"], "sample_684": ["    def test_repr_locals(self, tw_mock) -> None:\n        locals = {\"foo\": \"bar\", \"__builtins__\": {}}\n        r = ExceptionInfo.from_current().repr_locals(locals)\n        assert r is not None\n        r.toterminal(tw_mock)\n        assert tw_mock.lines == [\"foo         = 'bar'\", \"__builtins__ = <builtins>\"]\n"], "sample_687": ["def test_log_cli_enabled(testdir):\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_cli = True\n        log_cli_level = INFO\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n            logging.info(\"INFO message will be shown\")\n            logging.debug(\"DEBUG message won't be shown\")\n            assert 1\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*INFO message will be shown*\"])\n    result.stdout.no_fnmatch_line(\"*DEBUG message won't be shown*\")\n    assert result.ret == 0\n"], "sample_688": ["def test_absolutepath(tmpdir):\n    \"\"\"Test that absolutepath returns the absolute path of a given path.\"\"\"\n    p = tmpdir.join(\"test.txt\")\n    p.write(\"test\")\n    assert absolutepath(p) == Path(os.path.abspath(str(p)))\n    assert absolutepath(str(p)) == Path(os.path.abspath(str(p)))\n"], "sample_694": ["def test_argument_percent_default_is_deprecated(pytester: Pytester) -> None:\n    pytester.makeconftest(\n        \"\"\"\n            parser.addoption(\"--foo\", default=\"bar\", help=\"%%default is deprecated\")\n        \"\"\"\n    )\n    result = pytester.runpytest(\"-Wdefault::pytest.PytestRemovedIn8Warning\")\n    result.stdout.fnmatch_lines(\n        [\n            \"*PytestRemovedIn8Warning: pytest now uses argparse. \\\"%%default\\\" should be changed to \\\"%%(default)s\\\"\",\n        ]\n    )\n"], "sample_702": ["def test_pytester_runpytest_subprocess_with_timeout(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import time\n\n            time.sleep(10)\n    \"\"\"\n    )\n    result = pytester.runpytest_subprocess(timeout=1)\n    assert result.ret == ExitCode.INTERRUPTED\n"], "sample_704": ["def test_node_repr_failure_with_non_pytest_warning(pytester: Pytester) -> None:\n    items = pytester.getitems(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    with pytest.warns(UserWarning, match=\"some message\"):\n        items[0].warn(UserWarning(\"some message\"))\n"], "sample_705": ["def test_pytester_run_with_timeout(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import time\n\n            time.sleep(10)\n        \"\"\"\n    )\n    result = pytester.runpytest(timeout=1)\n    assert result.ret == ExitCode.INTERRUPTED\n"], "sample_709": ["def test_pytester_makefile_encoding(pytester: Pytester) -> None:\n    pytester.makefile(\".txt\", [\"Hello\"], encoding=\"utf-16\")\n    with open(str(pytester.path / \"test_pytester_makefile_encoding.txt\"), \"rb\") as f:\n        assert f.read() == b\"\\xff\\xfeH\\x00e\\x00l\\x00l\\x00o\\x00\"\n"], "sample_711": ["def test_node_get_closest_marker() -> None:\n    class DummyNode(nodes.Node):\n            super().__init__(name, parent)\n            if markers:\n                for marker in markers:\n                    self.add_marker(marker)\n\n    node1 = DummyNode(\"node1\")\n    node2 = DummyNode(\"node2\", parent=node1, markers=[\"mark1\"])\n    node3 = DummyNode(\"node3\", parent=node2, markers=[\"mark2\"])\n\n    assert node3.get_closest_marker(\"mark1\") is not None\n    assert node3.get_closest_marker(\"mark2\") is not None\n    assert node3.get_closest_marker(\"mark3\") is None\n\n    default_marker = nodes.Mark(\"default\", (), {})\n    assert node3.get_closest_marker(\"mark3\", default=default_marker) == default_marker\n"], "sample_717": ["def test_load_fake_lfw_pairs_subset():\n    lfw_pairs = fetch_lfw_pairs(subset='train', data_home=SCIKIT_LEARN_DATA,\n                                download_if_missing=False)\n\n    # The data is croped around the center as a rectangular bounding box\n    # around the face. Colors are converted to gray levels:\n    assert_equal(lfw_pairs.pairs.shape, (5, 2, 62, 47))\n    assert_equal(lfw_pairs.data.shape, (5, 5828))\n\n    # the target is array of boolean values indicating whether the pairs are\n    # from the same person or not\n    assert_array_equal(lfw_pairs.target, [1, 0, 1, 0, 1])\n\n    # names of the target can be found using the target_names array\n    expected_classes = ['Different persons', 'Same person']\n    assert_array_equal(lfw_pairs.target_names, expected_classes)\n"], "sample_718": ["def test_check_estimator_sparse_data():\n    # check that check_estimator() works on estimator with sparse data\n\n    # test sparse matrix input handling\n    est = SVC()\n    check_estimator(est)\n\n    # test sparse matrix input handling with non-zero values\n    X = sp.csr_matrix(np.array([[0, 1], [1, 0]]))\n    y = np.array([0, 1])\n    est.fit(X, y)\n    check_estimator(est)\n"], "sample_728": ["def test_make_gaussian_quantiles():\n    X, y = make_gaussian_quantiles(mean=None, cov=1., n_samples=100,\n                                   n_features=2, n_classes=3,\n                                   shuffle=True, random_state=0)\n\n    assert_equal(X.shape, (100, 2), \"X shape mismatch\")\n    assert_equal(y.shape, (100,), \"y shape mismatch\")\n    assert_equal(np.unique(y).shape, (3,), \"Unexpected number of classes\")\n\n    # Test that clusters are on the same quadrant\n    for i in range(3):\n        cluster = X[y == i]\n        centroid = np.mean(cluster, axis=0)\n        assert_array_almost_equal(np.sign(centroid),\n                                  np.ones(2),\n                                  err_msg=\"Clusters are not in the same \"\n                                          \"quadrant\")\n"], "sample_735": ["def test_get_parameters():\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng, scale=7)\n    n_components = rand_data.n_components\n\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        gmm = GaussianMixture(n_components=n_components,\n                              covariance_type=covar_type, random_state=rng)\n        gmm.fit(X)\n\n        weights, means, covariances, precisions_cholesky = gmm._get_parameters()\n        assert_array_equal(weights, gmm.weights_)\n        assert_array_equal(means, gmm.means_)\n        assert_array_equal(covariances, gmm.covariances_)\n        assert_array_equal(precisions_cholesky, gmm.precisions_cholesky_)\n"], "sample_741": ["def test_grid_search_cv_results_rank_tie_breaking_with_refit():\n    X, y = make_blobs(n_samples=50, random_state=42)\n\n    # The two C values are close enough to give similar models\n    # which would result in a tie of their mean cv-scores\n    param_grid = {'C': [1, 1.001, 0.001]}\n\n    grid_search = GridSearchCV(SVC(gamma=\"scale\"), param_grid=param_grid,\n                               refit=True)\n    grid_search.fit(X, y)\n    cv_results = grid_search.cv_results_\n    # Check tie breaking strategy -\n    # Check that there is a tie in the mean scores between\n    # candidates 1 and 2 alone\n    assert_almost_equal(cv_results['mean_test_score'][0],\n                        cv_results['mean_test_score'][1])\n    assert_almost_equal(cv_results['mean_train_score'][0],\n                        cv_results['mean_train_score'][1])\n    assert_false(np.allclose(cv_results['mean_test_score'][1],\n                             cv_results['mean_test_score'][2]))\n    assert_false(np.allclose(cv_results['mean_train_score'][1],\n                             cv_results['mean_train_score'][2]))\n    # 'min' rank should be assigned to the tied candidates\n    assert_almost_equal(grid_search.cv_results_['rank_test_score'], [1, 1, 3])\n\n    # Check best estimator parameters\n    assert_equal(grid_search.best_params_, {'C': 1})\n"], "sample_746": ["def test_brier_score_loss():\n    y_true = [0, 1, 1, 0]\n    y_prob = [0.1, 0.9, 0.8, 0.3]\n    assert_almost_equal(brier_score_loss(y_true, y_prob), 0.037)\n    assert_almost_equal(brier_score_loss(y_true, 1 - np.array(y_prob),\n                                         pos_label=0), 0.037)\n\n    y_true_categorical = [\"spam\", \"ham\", \"ham\", \"spam\"]\n    y_prob = [0.1, 0.9, 0.8, 0.3]\n    assert_almost_equal(brier_score_loss(y_true_categorical, y_prob,\n                                         pos_label=\"ham\"), 0.037)\n\n    y_prob = [0, 0.9, 0.1, 0.1]\n    assert_almost_equal(brier_score_loss(y_true, y_prob), 0.240)\n\n    # Test with np array\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    assert_almost_equal(brier_score_loss(y_true, y_prob), 0.037)\n\n    # Test with lists with different lengths\n    y_true = [0, 1, 1, 0, 1]\n    y_prob = [0.1, 0.9, 0.8, 0.3]\n    assert_raises(ValueError, brier_score_loss, y_true, y_prob)\n\n    # Test with domain error for labels\n    y_true = [0, 2, 1, 0]\n    y_prob = [0.1, 0.9, 0.8, 0.3]\n    assert_raises(ValueError, brier_score_loss, y_true, y_prob)\n"], "sample_748": ["def test_grid_search_cv_results_rank_tie_breaking_with_scoring():\n    X, y = make_blobs(n_samples=50, random_state=42)\n\n    # The two C values are close enough to give similar models\n    # which would result in a tie of their mean cv-scores\n    param_grid = {'C': [1, 1.001, 0.001]}\n\n    grid_search = GridSearchCV(SVC(gamma=\"scale\"), param_grid=param_grid,\n                               scoring='f1_macro')\n    grid_search.fit(X, y)\n    cv_results = grid_search.cv_results_\n    # Check tie breaking strategy -\n    # Check that there is a tie in the mean scores between\n    # candidates 1 and 2 alone\n    assert_almost_equal(cv_results['mean_test_score'][0],\n                        cv_results['mean_test_score'][1])\n    assert_almost_equal(cv_results['mean_train_score'][0],\n                        cv_results['mean_train_score'][1])\n    assert_false(np.allclose(cv_results['mean_test_score'][1],\n                             cv_results['mean_test_score'][2]))\n    assert_false(np.allclose(cv_results['mean_train_score'][1],\n                             cv_results['mean_train_score'][2]))\n    # 'min' rank should be assigned to the tied candidates\n    assert_almost_equal(grid_search.cv_results_['rank_test_score'], [1, 1, 3])\n"], "sample_749": ["def test_column_transformer_get_feature_names_with_remainder():\n    X_array = np.array([[0., 1., 2.], [2., 4., 6.]]).T\n    ct = ColumnTransformer([('trans', Trans(), [0, 1])],\n                           remainder=StandardScaler())\n    ct.fit(X_array)\n    assert_raise_message(NotImplementedError,\n                         \"get_feature_names is not yet supported when using \"\n                         \"a 'passthrough' transformer.\",\n                         ct.get_feature_names)\n\n    ct = ColumnTransformer([('trans', StandardScaler(), [0, 1])],\n                           remainder='passthrough')\n    ct.fit(X_array)\n    assert_raise_message(NotImplementedError,\n                         \"get_feature_names is not yet supported when using \"\n                         \"a 'passthrough' transformer.\",\n                         ct.get_feature_names)\n\n    ct = ColumnTransformer([('trans', StandardScaler(), [0])],\n                           remainder=StandardScaler())\n    ct.fit(X_array)\n    exp = ['trans__x0', 'remainder__x0', 'remainder__x1']\n    assert_equal(ct.get_feature_names(), exp)\n"], "sample_753": ["def test_logistic_regression_solvers_convergence_warnings():\n    # Test that warnings are raised if the maximum number of iterations is\n    # reached (i.e. convergence is not achieved)\n    X, y = make_classification(n_features=10, n_informative=5, random_state=0)\n\n    for solver in ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']:\n        clf = LogisticRegression(solver=solver, max_iter=1, tol=1e-15)\n        with pytest.warns(ConvergenceWarning):\n            clf.fit(X, y)\n"], "sample_764": ["def test_column_transformer_get_feature_names_with_remainder():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    ct = ColumnTransformer([('trans1', StandardScaler(), [0])],\n                           remainder=StandardScaler())\n    ct.fit(X_array)\n    assert_equal(ct.get_feature_names(), ['trans1__x0', 'remainder__x1'])\n"], "sample_765": ["def test_balanced_accuracy_score_binary_averaged():\n    y_true = np.array([0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1])\n    y_pred = np.array([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1])\n\n    # compute scores with default labels introspection\n    bac = balanced_accuracy_score(y_true, y_pred)\n    assert_almost_equal(bac, 0.5)\n\n    bac = balanced_accuracy_score(y_true, y_pred, adjusted=True)\n    assert_almost_equal(bac, 0.0)\n"], "sample_767": ["def test_column_transformer_get_feature_names_with_remainder():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    ct = ColumnTransformer([('trans', StandardScaler(), [0])],\n                           remainder=StandardScaler())\n    ct.fit(X_array)\n    assert_equal(ct.get_feature_names(), ['trans__x0', 'remainder__x1'])\n"], "sample_768": ["def test_validate_shuffle_split_init():\n    # Test that _validate_shuffle_split_init raises errors for invalid inputs\n    assert_raises(ValueError, _validate_shuffle_split_init, None, None)\n    assert_raises(ValueError, _validate_shuffle_split_init, 0.5, 0.6)\n    assert_raises(ValueError, _validate_shuffle_split_init, 10, 11)\n    assert_raises(TypeError, _validate_shuffle_split_init, 'a', 0.5)\n    assert_raises(TypeError, _validate_shuffle_split_init, 0.5, 'b')\n"], "sample_769": ["def test_balanced_accuracy_score_binary():\n    y_true = [0, 1, 0, 0, 1, 0]\n    y_pred = [0, 1, 0, 0, 0, 1]\n\n    # binary case\n    assert_almost_equal(balanced_accuracy_score(y_true, y_pred),\n                        (1 + 2/3) / 2)\n"], "sample_771": ["def test_power_transformer_sparse_input():\n    # check that PowerTransformer supports sparse input\n    X_sparse = sparse.csr_matrix(X_2d)\n    pt = PowerTransformer()\n    pt.fit(X_sparse)\n    assert_array_almost_equal(pt.transform(X_sparse).toarray(),\n                              pt.transform(X_2d))\n"], "sample_775": ["def test_indent_at_name():\n    # Render an estimator with indent_at_name=False\n    pp = _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=False)\n    lr = LogisticRegression()\n    expected = \"\"\""], "sample_779": ["def test_check_class_weight_balanced_linear_classifier():\n    # check that check_class_weight_balanced_linear_classifier raises an error\n    # when the estimator does not have a 'class_weight' parameter\n\n    class DummyEstimator:\n            pass\n\n            return self\n\n    assert_raises_regex(AssertionError,\n                        \"The classifier DummyEstimator does not \"\n                        \"have a 'class_weight' parameter.\",\n                        check_class_weight_balanced_linear_classifier,\n                        \"DummyEstimator\", DummyEstimator)\n"], "sample_782": ["def test_column_transformer_get_feature_names_with_remainder():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    ct = ColumnTransformer([('trans1', StandardScaler(), [0])],\n                           remainder=StandardScaler())\n    ct.fit(X_array)\n    assert_equal(ct.get_feature_names(), ['trans1__x0', 'remainder__x1'])\n"], "sample_785": ["def test_validate_shuffle_split():\n    # Test _validate_shuffle_split function\n    n_samples = 10\n    train_size = 0.5\n    test_size = 0.3\n\n    # Check that it raises an error when test_size and train_size are both None\n    assert_raises(ValueError, _validate_shuffle_split, n_samples, None, None)\n\n    # Check that it raises an error when test_size + train_size > 1\n    assert_raises(ValueError, _validate_shuffle_split, n_samples, test_size,\n                  train_size)\n\n    # Check that it returns the correct train and test sizes\n    train_size_int, test_size_int = _validate_shuffle_split(n_samples,\n                                                            test_size=None,\n                                                            train_size=train_size)\n    assert_equal(train_size_int, int(n_samples * train_size))\n    assert_equal(test_size_int, n_samples - train_size_int)\n\n    train_size_int, test_size_int = _validate_shuffle_split(n_samples,\n                                                            test_size=test_size,\n                                                            train_size=None)\n    assert_equal(test_size_int, int(n_samples * test_size))\n    assert_equal(train_size_int, n_samples - test_size_int)\n\n    train_size_int, test_size_int = _validate_shuffle_split(n_samples,\n                                                            test_size=test_size,\n                                                            train_size=train_size)\n    assert_equal(train_size_int, int(n_samples * train_size))\n    assert_equal(test_size_int, int(n_samples * test_size))\n"], "sample_787": ["def test_balanced_accuracy_score_adjusted():\n    y_true = [0, 1, 0, 0, 1, 0]\n    y_pred = [0, 1, 0, 0, 0, 1]\n\n    # Calculate balanced accuracy score without adjustment\n    bas = balanced_accuracy_score(y_true, y_pred, adjusted=False)\n    assert_almost_equal(bas, 0.625)\n\n    # Calculate balanced accuracy score with adjustment\n    bas = balanced_accuracy_score(y_true, y_pred, adjusted=True)\n    assert_almost_equal(bas, 0.25)\n"], "sample_792": ["def test_complementnb_alpha():\n    # Test that ComplementNB handles alpha correctly.\n    X = np.array([[1, 0], [1, 1]])\n    y = np.array([0, 1])\n\n    # Test for alpha < 0\n    expected_msg = ('Smoothing parameter alpha = -1.0e-01. '\n                    'alpha should be > 0.')\n    cnb = ComplementNB(alpha=-0.1)\n    assert_raise_message(ValueError, expected_msg, cnb.fit, X, y)\n\n    cnb = ComplementNB(alpha=-0.1)\n    assert_raise_message(ValueError, expected_msg, cnb.partial_fit,\n                         X, y, classes=[0, 1])\n\n    # Test for alpha == 0\n    expected_warn = ('alpha too small will result in numeric errors, '\n                     'setting alpha = 1e-10')\n    cnb = ComplementNB(alpha=0.)\n    assert_warns(UserWarning, cnb.fit, X, y)\n    assert_warns(UserWarning, cnb.partial_fit, X, y, classes=[0, 1])\n"], "sample_797": ["def test_power_transformer_dtype():\n    # Check that PowerTransformer preserves the dtype of the input data.\n    X = np.abs(X_2d).astype(np.float32)\n    pt = PowerTransformer()\n    X_trans = pt.fit_transform(X)\n    assert X.dtype == X_trans.dtype\n    assert pt.lambdas_.dtype == np.float64\n"], "sample_799": ["def test_cross_val_score_with_ndarray_like():\n    # Test that cross_val_score works with ndarray-like inputs\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    clf = MockClassifier()\n    scores = cross_val_score(clf, X, y)\n    assert_array_equal(scores, clf.score(X, y))\n\n    # Test with a list of lists\n    X_list = [[1, 2], [3, 4]]\n    scores = cross_val_score(clf, X_list, y)\n    assert_array_equal(scores, clf.score(X, y))\n\n    # Test with a pandas DataFrame\n    try:\n        import pandas as pd\n        X_df = pd.DataFrame(X)\n        scores = cross_val_score(clf, X_df, y)\n        assert_array_equal(scores, clf.score(X, y))\n    except ImportError:\n        pass\n\n    # Test with a scipy sparse matrix\n    from scipy.sparse import csr_matrix\n    X_sparse = csr_matrix(X)\n    scores = cross_val_score(clf, X_sparse, y)\n    assert_array_equal(scores, clf.score(X, y))\n"], "sample_800": ["def test_check_estimator_with_tags():\n    # check that estimator tags are properly checked\n\n    class MyEstimator(BaseEstimator):\n            return {'non_deterministic': True}\n\n    est = MyEstimator()\n    check_estimator(est)\n\n    # check that a warning is raised when an estimator has no tags\n    class MyEstimatorNoTags(BaseEstimator):\n        pass\n\n    est_no_tags = MyEstimatorNoTags()\n    assert_warns(UserWarning, check_estimator, est_no_tags)\n"], "sample_801": ["def test_clone():\n    # Test clone function\n    lr = LogisticRegression()\n    lr_cloned = clone(lr)\n    assert lr.__class__ == lr_cloned.__class__\n    assert lr.get_params() == lr_cloned.get_params()\n\n    # Test clone function with safe=False\n    lr_cloned_safe_false = clone(lr, safe=False)\n    assert lr.__class__ == lr_cloned_safe_false.__class__\n    assert lr.get_params() == lr_cloned_safe_false.get_params()\n\n    # Test clone function with a list of estimators\n    estimators = [LogisticRegression(), LogisticRegression()]\n    cloned_estimators = clone(estimators)\n    for est, cloned_est in zip(estimators, cloned_estimators):\n        assert est.__class__ == cloned_est.__class__\n        assert est.get_params() == cloned_est.get_params()\n\n    # Test clone function with a tuple of estimators\n    estimators_tuple = (LogisticRegression(), LogisticRegression())\n    cloned_estimators_tuple = clone(estimators_tuple)\n    for est, cloned_est in zip(estimators_tuple, cloned_estimators_tuple):\n        assert est.__class__ == cloned_est.__class__\n        assert est.get_params() == cloned_est.get_params()\n\n    # Test clone function with a set of estimators\n    estimators_set = {LogisticRegression(), LogisticRegression()}\n    cloned_estimators_set = clone(estimators_set)\n    for est, cloned_est in zip(estimators_set, cloned_estimators_set):\n        assert est.__class__ == cloned_est.__class__\n        assert est.get_params() == cloned_est.get_params()\n"], "sample_811": ["def test_pairwise_distances_dtype():\n    # Test that pairwise_distances returns the correct dtype\n    X = np.random.rand(10, 5).astype(np.float32)\n    Y = np.random.rand(10, 5).astype(np.float32)\n\n    # Check with default metric (euclidean)\n    D = pairwise_distances(X, Y)\n    assert_equal(D.dtype, np.float32)\n\n    # Check with other metrics\n    for metric in ['cityblock', 'cosine', 'manhattan']:\n        D = pairwise_distances(X, Y, metric=metric)\n        assert_equal(D.dtype, np.float32)\n\n    # Check with callable metric\n        return np.sum((x - y) ** 2)\n\n    D = pairwise_distances(X, Y, metric=custom_metric)\n    assert_equal(D.dtype, np.float32)\n"], "sample_814": ["def test_gradient_boosting_init_estimator_with_sample_weight():\n    # Check that GradientBoosting estimators work when init estimator supports\n    # sample weights.\n\n    X, y = make_classification(random_state=0)\n    sample_weight = np.random.RandomState(42).rand(y.shape[0])\n\n    # init supports sample weights\n    init_est = DummyClassifier()\n    gb = GradientBoostingClassifier(init=init_est)\n    gb.fit(X, y, sample_weight=sample_weight)\n\n    init_est = DummyRegressor()\n    gb = GradientBoostingRegressor(init=init_est)\n    gb.fit(X, y, sample_weight=sample_weight)\n"], "sample_818": ["def test_spectral_clustering_with_n_init():\n    # Test that spectral_clustering works with different n_init values\n    X, y = make_blobs(n_samples=20, random_state=0,\n                      centers=[[1, 1], [-1, -1]], cluster_std=0.01)\n\n    S = rbf_kernel(X, gamma=1)\n    S = np.maximum(S - 1e-4, 0)\n    S = sparse.coo_matrix(S)\n\n    labels_single_init = SpectralClustering(random_state=0, n_clusters=2,\n                                            affinity='precomputed',\n                                            n_init=1).fit(S).labels_\n    labels_multiple_init = SpectralClustering(random_state=0, n_clusters=2,\n                                              affinity='precomputed',\n                                              n_init=10).fit(S).labels_\n\n    assert adjusted_rand_score(y, labels_single_init) == 1\n    assert adjusted_rand_score(y, labels_multiple_init) == 1\n"], "sample_822": ["def test_pairwise_distances_dtype():\n    # Test that pairwise_distances returns the correct dtype\n    X = np.random.rand(10, 5).astype(np.float32)\n    Y = np.random.rand(10, 5).astype(np.float32)\n\n    # metric='euclidean' should return float64 for float32 input\n    D = pairwise_distances(X, Y, metric='euclidean')\n    assert_equal(D.dtype, np.float32)\n\n    # metric='cosine' should return float64 for float32 input\n    D = pairwise_distances(X, Y, metric='cosine')\n    assert_equal(D.dtype, np.float32)\n\n    # metric='manhattan' should return float64 for float32 input\n    D = pairwise_distances(X, Y, metric='manhattan')\n    assert_equal(D.dtype, np.float32)\n\n    # callable metric should return float64 for float32 input\n        return np.sum((x - y) ** 2)\n    D = pairwise_distances(X, Y, metric=custom_metric)\n    assert_equal(D.dtype, np.float64)\n"], "sample_823": ["def test_pairwise_distances_chunked_reduce_memory_usage():\n    # Test that pairwise_distances_chunked with reduce_func does not use more\n    # memory than the size of the chunk.\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((1000, 10))\n    Y = rng.random_sample((1000, 10))\n\n        assert D_chunk.nbytes < 8 * 1000 * 100  # 1000x100 float64 matrix\n        return D_chunk\n\n    gen = pairwise_distances_chunked(X, Y, reduce_func=reduce_func,\n                                     working_memory=0.01)\n    next(gen)\n"], "sample_824": ["def test_pairwise_distances_chunked_reduce_func():\n    # Test pairwise_distances_chunked with a reduce function that returns\n    # multiple arrays.\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((400, 4))\n    Y = rng.random_sample((200, 4))\n\n        return D_chunk.sum(axis=1), D_chunk.max(axis=1)\n\n    gen = pairwise_distances_chunked(X, Y, reduce_func=reduce_func,\n                                     working_memory=2 ** -16)\n    sums, maxs = zip(*gen)\n    sums = np.concatenate(sums)\n    maxs = np.concatenate(maxs)\n\n    D = pairwise_distances(X, Y)\n    assert_array_almost_equal(sums, D.sum(axis=1))\n    assert_array_almost_equal(maxs, D.max(axis=1))\n"], "sample_828": ["def test_pairwise_distances_chunked_reduce_memory_usage():\n    # Test that pairwise_distances_chunked with reduce_func uses less memory\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((1000, 4))\n    Y = rng.random_sample((1000, 4))\n\n        return (D_chunk.sum(axis=1),)\n\n    mem_usage = []\n    for _ in range(10):\n        process = psutil.Process(os.getpid())\n        mem_before = process.memory_info().rss / 1024 ** 2\n        gen = pairwise_distances_chunked(X, Y, reduce_func=reduce_func,\n                                         working_memory=64)\n        result = list(gen)\n        mem_after = process.memory_info().rss / 1024 ** 2\n        mem_usage.append(mem_after - mem_before)\n\n    assert np.mean(mem_usage) < 50\n"], "sample_838": ["def test_column_transformer_get_feature_names_with_remainder():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    ct = ColumnTransformer([('trans', Trans(), [0])],\n                           remainder=StandardScaler())\n    ct.fit(X_array)\n    assert ct.get_feature_names() == ['trans__x0', 'remainder__x1', 'remainder__x2']\n"], "sample_844": ["def test_compute_optics_graph():\n    # Test the compute_optics_graph function with a small dataset\n    X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n    min_samples = 2\n    max_eps = np.inf\n    metric = 'euclidean'\n    p = 2\n    metric_params = None\n    algorithm = 'auto'\n    leaf_size = 30\n    n_jobs = None\n\n    (ordering, core_distances, reachability,\n     predecessor) = compute_optics_graph(X, min_samples, max_eps, metric, p,\n                                         metric_params, algorithm, leaf_size,\n                                         n_jobs)\n\n    assert ordering.shape == (X.shape[0],)\n    assert core_distances.shape == (X.shape[0],)\n    assert reachability.shape == (X.shape[0],)\n    assert predecessor.shape == (X.shape[0],)\n"], "sample_846": ["def test_column_transformer_feature_names_out():\n    \"\"\"Test that `get_feature_names_out` returns the correct feature names.\"\"\"\n    pd = pytest.importorskip('pandas')\n\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    X_df = pd.DataFrame(X_array, columns=['first', 'second'])\n\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', Trans(), [1])])\n\n    ct.fit(X_array)\n    assert ct.get_feature_names_out() == ['trans1__x0', 'trans2__x1']\n\n    ct.fit(X_df)\n    assert ct.get_feature_names_out() == ['trans1__first', 'trans2__second']\n"], "sample_849": ["def test_validate_shuffle_split():\n    # Test if _validate_shuffle_split returns the correct train and test sizes\n    n_samples = 10\n    test_size = 0.2\n    train_size = 0.8\n\n    n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size)\n    assert n_train == int(train_size * n_samples)\n    assert n_test == int(test_size * n_samples)\n\n    # Test if _validate_shuffle_split raises an error when test_size and \n    # train_size don't add up to 1\n    test_size = 0.3\n    train_size = 0.7\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size, train_size)\n\n    # Test if _validate_shuffle_split returns the correct default test size\n    test_size = None\n    train_size = None\n    n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n                                              default_test_size=0.25)\n    assert n_test == int(0.25 * n_samples)\n    assert n_train == n_samples - n_test\n\n    # Test if _validate_shuffle_split returns the correct default train size\n    test_size = 0.5\n    train_size = None\n    n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size)\n    assert n_test == int(test_size * n_samples)\n    assert n_train == n_samples - n_test\n\n    # Test if _validate_shuffle_split raises an error when test_size is too \n    # large\n    test_size = 1.1\n    train_size = None\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size, train_size)\n\n    # Test if _validate_shuffle_split raises an error when train_size is too \n    # large\n    test_size = None\n    train_size = 1.1\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size, train_size)\n\n    # Test if _validate_shuffle_split raises an error when neither test_size \n    # nor train_size is specified\n    test_size = None\n    train_size = None\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size, train_size)\n"], "sample_852": ["def test_make_circles():\n    X, y = make_circles(3, shuffle=False)\n    for x, label in zip(X, y):\n        center = [0.0, 0.0] if label == 0 else [0.0, 0.0]\n        dist_sqr = ((x - center) ** 2).sum()\n        assert_almost_equal(dist_sqr, 1.0 if label == 0 else 0.64,\n                            err_msg=\"Point is not on expected unit circle\")\n"], "sample_856": ["def test_validate_shuffle_split():\n    # Test _validate_shuffle_split function\n    n_samples = 10\n\n    # Test when test_size is None and train_size is a float\n    train_size, test_size = _validate_shuffle_split(n_samples, test_size=None,\n                                                    train_size=0.5)\n    assert train_size == 5\n    assert test_size == 5\n\n    # Test when test_size is None and train_size is an integer\n    train_size, test_size = _validate_shuffle_split(n_samples, test_size=None,\n                                                    train_size=5)\n    assert train_size == 5\n    assert test_size == 5\n\n    # Test when test_size is a float and train_size is None\n    train_size, test_size = _validate_shuffle_split(n_samples, test_size=0.5,\n                                                    train_size=None)\n    assert train_size == 5\n    assert test_size == 5\n\n    # Test when test_size is an integer and train_size is None\n    train_size, test_size = _validate_shuffle_split(n_samples, test_size=5,\n                                                    train_size=None)\n    assert train_size == 5\n    assert test_size == 5\n\n    # Test when both test_size and train_size are specified\n    train_size, test_size = _validate_shuffle_split(n_samples, test_size=3,\n                                                    train_size=7)\n    assert train_size == 7\n    assert test_size == 3\n\n    # Test when test_size + train_size > n_samples\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size=6, train_size=7)\n\n    # Test when test_size is not a float or an integer\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size='invalid', train_size=None)\n\n    # Test when train_size is not a float or an integer\n    with pytest.raises(ValueError):\n        _validate_shuffle_split(n_samples, test_size=None, train_size='invalid')\n"], "sample_859": ["def test_lassoCV_sparse_input_dtype():\n    X, y, _, _ = build_dataset(n_features=10)\n    clf = LassoCV(n_alphas=5)\n    clf.fit(sparse.csr_matrix(X), y)\n    clf1 = LassoCV(n_alphas=5)\n    clf1.fit(sparse.csr_matrix(X, dtype=np.float32), y)\n    assert_almost_equal(clf.alpha_, clf1.alpha_, decimal=6)\n    assert_almost_equal(clf.coef_, clf1.coef_, decimal=6)\n"], "sample_860": ["def test_check_array_dtype_object_conversion_with_nans():\n    # Test that data-frame like objects with dtype object and NaN values\n    # get converted correctly\n    X = np.array([[1, 2, np.nan], [4, 5, 6]], dtype=np.object)\n    X_df = MockDataFrame(X)\n    assert check_array(X_df).dtype.kind == \"f\"\n    assert check_array(X_df, ensure_2d=False).dtype.kind == \"f\"\n"], "sample_863": ["def test_pipeline_get_params():\n    # Test that get_params returns all the parameters of the pipeline\n    pipe = Pipeline([('transf', Transf()), ('clf', FitParamT())])\n    params = pipe.get_params()\n    assert 'steps' in params\n    assert 'memory' in params\n    assert 'verbose' in params\n    assert 'transf' in params\n    assert 'clf' in params\n    assert 'transf__a' in params\n    assert 'transf__b' in params\n    assert 'clf__should_succeed' not in params\n\n    # Test that get_params returns all the parameters of the pipeline when\n    # there are None estimators\n    pipe = Pipeline([('transf', None), ('clf', FitParamT())])\n    params = pipe.get_params()\n    assert 'steps' in params\n    assert 'memory' in params\n    assert 'verbose' in params\n    assert 'transf' in params\n    assert 'clf' in params\n    assert 'transf__a' not in params\n    assert 'transf__b' not in params\n    assert 'clf__should_succeed' not in params\n\n    # Test that get_params returns all the parameters of the pipeline when\n    # there are 'passthrough' estimators\n    pipe = Pipeline([('transf', 'passthrough'), ('clf', FitParamT())])\n    params = pipe.get_params()\n    assert 'steps' in params\n    assert 'memory' in params\n    assert 'verbose' in params\n    assert 'transf' in params\n    assert 'clf' in params\n    assert 'transf__a' not in params\n    assert 'transf__b' not in params\n    assert 'clf__should_succeed' not in params\n"], "sample_868": ["def test_empty_input(metric_name):\n    # All supervised clustering metrics should be able to handle empty input\n    metric = SUPERVISED_METRICS[metric_name]\n    assert metric([], []) == 1.0\n    assert metric([1, 2, 3], []) == 1.0\n    assert metric([], [1, 2, 3]) == 1.0\n"], "sample_869": ["def test_balanced_accuracy_score_binary():\n    y_true = [0, 1, 0, 0, 1, 0]\n    y_pred = [0, 1, 0, 0, 0, 1]\n\n    # binary case is the same as accuracy_score\n    assert balanced_accuracy_score(y_true, y_pred) == accuracy_score(y_true, y_pred)\n"], "sample_874": ["def test_clone():\n    sel = StepSelector(step=3)\n    clone_sel = sel.__sklearn_clone__()\n    assert clone_sel.step == 3\n\n    # Check if clone is independent of original\n    clone_sel.step = 5\n    assert sel.step == 3\n"], "sample_878": ["def test_column_transformer_feature_names_out_with_callable():\n    \"\"\"Check feature names out when using callable in ColumnTransformer.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    df = pd.DataFrame([[1, 2, 3, 4]], columns=[\"a\", \"b\", \"c\", \"d\"])\n\n        return [\"a\", \"c\"]\n\n    ct = ColumnTransformer(\n        [(\"bycol\", TransWithNames(), selector)], remainder=\"passthrough\"\n    )\n    ct.fit(df)\n\n    names = ct.get_feature_names_out()\n    assert isinstance(names, np.ndarray)\n    assert names.dtype == object\n    assert_array_equal(names, [\"bycol__a\", \"bycol__c\", \"remainder__b\", \"remainder__d\"])\n"], "sample_880": ["def test_ovr_decision_function():\n    # Test _ovr_decision_function with a simple example\n    predictions = np.array([[0, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.5, 0.6, 0.4], [0.7, 0.3, 0.8]])\n    n_classes = 3\n\n    decision = _ovr_decision_function(predictions, confidences, n_classes)\n    expected_decision = np.array([[0.1, 0.2, -0.3], [0.4, -0.1, 0.7]])\n\n    assert_allclose(decision, expected_decision)\n"], "sample_885": ["def test_validate_params_with_nested_constraints():\n    \"\"\"Check that validate_params works with nested constraints.\"\"\"\n    constraint = Options(type, {np.float32, np.float64})\n    nested_constraint = Options(type, {constraint, _InstancesOf(str)})\n\n    @validate_params({\"param\": [nested_constraint]})\n        pass\n\n    # check that the function can be called with a valid parameter\n    f(np.float32)\n\n    # check that the function raises an error with an invalid parameter\n    with pytest.raises(\n        InvalidParameterError, match=\"The 'param' parameter of f must be\"\n    ):\n        f(1)\n"], "sample_891": ["def test_roc_auc_score_average_parameter():\n    # Test that roc_auc_score function returns an error when the 'average'\n    # parameter is not one of the allowed values.\n    rng = check_random_state(404)\n    y_score = rng.rand(20, 3)\n    y_prob = softmax(y_score)\n    y_true = rng.randint(0, 3, size=20)\n\n    with pytest.raises(ValueError):\n        roc_auc_score(y_true, y_prob, average=\"invalid\")\n"], "sample_895": ["def test_column_transformer_feature_names_out_with_callable():\n    \"\"\"Check feature names out when using a callable as column selector.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    df = pd.DataFrame([[1, 2, 3]], columns=[\"a\", \"b\", \"c\"])\n    ct = ColumnTransformer(\n        [(\"bycol\", TransWithNames(), lambda x: [\"a\", \"c\"])],\n        remainder=\"passthrough\",\n    )\n    ct.fit(df)\n\n    assert_array_equal(ct.get_feature_names_out(), [\"bycol__a\", \"bycol__c\", \"remainder__b\"])\n"], "sample_896": ["def test_nmf_alpha_H_same():\n    # Check that alpha_H='same' is equivalent to setting alpha_H=alpha_W\n    rng = np.random.RandomState(0)\n    X = rng.random_sample((6, 5))\n    W_init = rng.random_sample((6, 2))\n    H_init = rng.random_sample((2, 5))\n\n    nmf1 = NMF(n_components=2, init=\"custom\", alpha_W=0.5, alpha_H=\"same\")\n    W1, H1 = nmf1.fit_transform(X, W=W_init, H=H_init), nmf1.components_\n\n    nmf2 = NMF(n_components=2, init=\"custom\", alpha_W=0.5, alpha_H=0.5)\n    W2, H2 = nmf2.fit_transform(X, W=W_init, H=H_init), nmf2.components_\n\n    assert_allclose(W1, W2)\n    assert_allclose(H1, H2)\n"], "sample_897": ["def test_partial_dependence_display_categorical_target(\n    pyplot, categorical_features, array_type"], "sample_899": ["def test_check_estimator_sparse_data():\n    # check that estimators raise an exception on providing sparse data\n    X = np.random.sample(10) + 1j * np.random.sample(10)\n    X = X.reshape(-1, 1)\n    y = np.random.sample(10) + 1j * np.random.sample(10)\n\n    class NonConformantEstimator(object):\n            pass\n\n    estimator = NonConformantEstimator()\n    assert_raises_regex(ValueError, \"Complex data not supported\",\n                        check_estimator_sparse_data, \"estimator\", estimator)\n"], "sample_903": ["def test_tsne_embedding_changes():\n    # Ensure that the embedding changes when fitting a new dataset.\n    random_state = check_random_state(0)\n    X1 = random_state.randn(100, 2)\n    X2 = random_state.randn(50, 3)\n\n    tsne = TSNE(n_components=2, init='random', random_state=0)\n    embedding1 = tsne.fit_transform(X1)\n    embedding2 = tsne.fit_transform(X2)\n\n    assert not np.array_equal(embedding1, embedding2)\n"], "sample_905": ["def test_is_builtin_class_method_builtin():\n    assert inspect.is_builtin_class_method(int, '__init__') is True\n    assert inspect.is_builtin_class_method(str, 'join') is True\n    assert inspect.is_builtin_class_method(list, 'append') is True\n    assert inspect.is_builtin_class_method(MyInt, '__init__') is True\n    assert inspect.is_builtin_class_method(MyInt, 'my_method') is False\n"], "sample_910": ["def test_prefixed_warnings(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    with prefixed_warnings(\"prefix:\"):\n        logger.warning('message1')\n        assert 'prefix: WARNING: message1' in warning.getvalue()\n\n    with prefixed_warnings(\"another prefix:\"):\n        logger.warning('message2')\n        assert 'another prefix: WARNING: message2' in warning.getvalue()\n\n    # nested prefixes\n    with prefixed_warnings(\"outer prefix:\"):\n        with prefixed_warnings(\"inner prefix:\"):\n            logger.warning('message3')\n            assert 'outer prefix: inner prefix: WARNING: message3' in warning.getvalue()\n"], "sample_915": ["def test_getdoc_inherited_decorated_method():\n    class Foo:\n            \"\"\"docstring.\"\"\"\n\n    class Bar(Foo):\n        @functools.wraps(Foo.meth)\n            pass\n\n    assert inspect.getdoc(Bar().meth) == \"docstring.\"\n"], "sample_921": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n    @singledispatch\n        return arg\n\n    assert inspect.is_singledispatch_function(fun) is True\n\n        return arg\n\n    assert inspect.is_singledispatch_function(normal_fun) is False\n\n"], "sample_922": ["def test_pyattribute_with_module(app):\n    text = (\".. py:module:: example\\n\"\n            \"\\n\"\n            \".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:attribute:: attr\\n\"\n            \"      :type: Optional[str]\\n\"\n            \"      :value: ''\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_addname, \"example.\"],\n                                                    [desc_name, \"Class\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc)])]))\n    assert_node(doctree[1][1][0], addnodes.index,\n                entries=[('single', 'attr (example.Class attribute)', 'example.Class.attr', '', None)])\n    assert_node(doctree[1][1][1], ([desc_signature, ([desc_name, \"attr\"],\n                                                     [desc_annotation, (\": \",\n                                                                        [pending_xref, \"Optional\"],\n                                                                        [desc_sig_punctuation, \"[\"],\n                                                                        [pending_xref, \"str\"],\n                                                                        [desc_sig_punctuation, \"]\"])],\n                                                     [desc_annotation, \" = ''\"])],\n                                   [desc_content, ()]))\n    assert 'example.Class.attr' in domain.objects\n    assert domain.objects['example.Class.attr'] == ('index', 'example.Class.attr', 'attribute')\n"], "sample_923": ["def test_lookup_key():\n    root = Symbol(None, None, None, None)\n    s1 = root.add_name(ASTNestedName([ASTIdentifier(\"S1\")], rooted=False))\n    s2 = s1.add_name(ASTNestedName([ASTIdentifier(\"S2\")], rooted=False))\n    s3 = s2.add_name(ASTNestedName([ASTIdentifier(\"S3\")], rooted=False))\n\n    key = s3.get_lookup_key()\n    assert str(key) == \"[(S1, None), (S2, None), (S3, None)]\"\n\n    decl = ASTDeclaration('function', 'function', ASTTypeWithInit(\n        ASTType(ASTDeclSpecs(outer='function',\n                             leftSpecs=ASTDeclSpecsSimple(storage=None,\n                                                          threadLocal=None,\n                                                          inline=None,\n                                                          restrict=None,\n                                                          volatile=None,\n                                                          const=None,\n                                                          attrs=[]),\n                             rightSpecs=ASTDeclSpecsSimple(storage=None,\n                                                           threadLocal=None,\n                                                           inline=None,\n                                                           restrict=None,\n                                                           volatile=None,\n                                                           const=None,\n                                                           attrs=[]),\n                             trailingTypeSpec=ASTTrailingTypeSpecFundamental(\"void\")),\n                         ASTDeclaratorNameParam(declId=ASTNestedName([ASTIdentifier(\"f\")],\n                                                                    rooted=False),\n                                               arrayOps=[],\n                                               param=ASTParameters(args=[])))),\n        ASTInitializer(None)))\n    s3.add_declaration(decl, docname=\"TestDoc\")\n\n    key = s3.get_lookup_key()\n    assert str(key) == \"[(S1, None), (S2, None), (S3, 'c.f')]\"\n"], "sample_939": ["def test_unparse_visit_arguments():\n    source = \"def func(a: int, b: str = 'default', *args, **kwargs): pass\"\n    module = ast.parse(source)\n    expected = \"a: int, b: str = 'default', *args, **kwargs\"\n    assert ast.unparse(module.body[0].args, source) == expected\n"], "sample_940": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n    @singledispatch\n        return arg\n\n    assert inspect.is_singledispatch_function(fun) is True\n\n        return arg\n\n    assert inspect.is_singledispatch_function(not_singledispatch_fun) is False\n\n"], "sample_942": ["def test_pyfunction_with_type_comment(app):\n    text = \".. py:function:: hello(name: str) -> str  # type: ignore\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],\n                                                      [desc_sig_punctuation, \":\"],\n                                                      \" \",\n                                                      [nodes.inline, pending_xref, \"str\"])])\n\n    text = \".. py:function:: hello(name)  # type: (str) -> str\"\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"hello\"],\n                                                    desc_parameterlist,\n                                                    [desc_returns, pending_xref, \"str\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"function\",\n                domain=\"py\", objtype=\"function\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_parameterlist, desc_parameter, ([desc_sig_name, \"name\"],)])\n"], "sample_945": ["def test_pyattribute_with_union_type_operator(app):\n    text = (\".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:attribute:: attr\\n\"\n            \"      :type: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][1][1],\n                ([desc_name, \"attr\"],\n                 [desc_annotation, (\": \",\n                                    [pending_xref, \"int\"],\n                                    \" \",\n                                    [desc_sig_punctuation, \"|\"],\n                                    \" \",\n                                    [pending_xref, \"str\"])]))\n"], "sample_946": ["def test_pyattribute_with_union_type_operator(app):\n    text = (\".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:attribute:: attr\\n\"\n            \"      :type: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][1][1],\n                ([desc_name, \"attr\"],\n                 [desc_annotation, (\": \",\n                                    [pending_xref, \"int\"],\n                                    \" \",\n                                    [desc_sig_punctuation, \"|\"],\n                                    \" \",\n                                    [pending_xref, \"str\"])]))\n"], "sample_947": ["def test_build_domain_c_alias(app, status, warning):\n    app.builder.build_all()\n    ws = filter_warnings(warning, \"alias\")\n    assert len(ws) == 0\n    t = (app.outdir / \"alias.html\").read_text()\n    for id_ in ('alias1', 'alias2'):\n        assert 'id=\"c.{}\"'.format(id_) in t\n"], "sample_950": ["def test_pyattribute_with_union_type_operator(app):\n    text = (\".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:attribute:: attr\\n\"\n            \"      :type: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][1][1],\n                ([desc_name, \"attr\"],\n                 [desc_annotation, (\": \",\n                                    [pending_xref, \"int\"],\n                                    \" \",\n                                    [desc_sig_punctuation, \"|\"],\n                                    \" \",\n                                    [pending_xref, \"str\"])]))\n"], "sample_951": ["def test_is_builtin_class_method():\n    assert inspect.is_builtin_class_method(int, '__init__') is True\n    assert inspect.is_builtin_class_method(list, 'append') is True\n    assert inspect.is_builtin_class_method(str, 'upper') is True\n    assert inspect.is_builtin_class_method(dict, 'keys') is True\n\n    class MyInt(int):\n            pass\n\n    assert inspect.is_builtin_class_method(MyInt, '__init__') is True\n    assert inspect.is_builtin_class_method(MyInt, 'my_method') is False\n"], "sample_952": ["def test_is_builtin_class_method_builtin():\n    assert inspect.is_builtin_class_method(int, '__init__') is True\n    assert inspect.is_builtin_class_method(str, 'join') is True\n    assert inspect.is_builtin_class_method(list, 'append') is True\n    assert inspect.is_builtin_class_method(dict, 'keys') is True\n\n    class MyInt(int):\n            pass\n\n    assert inspect.is_builtin_class_method(MyInt, '__init__') is True\n    assert inspect.is_builtin_class_method(MyInt, 'my_method') is False\n"], "sample_961": ["def test_pyattribute_with_union_type_operator(app):\n    text = (\".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:attribute:: attr\\n\"\n            \"      :type: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][1][0], addnodes.index,\n                entries=[('single', 'attr (Class attribute)', 'Class.attr', '', None)])\n    assert_node(doctree[1][1][1], ([desc_signature, ([desc_name, \"attr\"],\n                                                     [desc_annotation, (\": \",\n                                                                        [pending_xref, \"int\"],\n                                                                        \" \",\n                                                                        [desc_sig_punctuation, \"|\"],\n                                                                        \" \",\n                                                                        [pending_xref, \"str\"])]),\n                                   [desc_content, ()]))\n    assert_node(doctree[1][1][1][0][1][1], pending_xref, **{\"py:class\": \"Class\"})\n    assert_node(doctree[1][1][1][0][1][3], pending_xref, **{\"py:class\": \"Class\"})\n    assert 'Class.attr' in app.env.domains['py'].objects\n    assert app.env.domains['py'].objects['Class.attr'] == ('index', 'Class.attr', 'attribute', False)\n"], "sample_964": ["def test_pyattribute_with_union_type_operator(app):\n    text = (\".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:attribute:: attr\\n\"\n            \"      :type: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][1][1],\n                ([desc_name, \"attr\"],\n                 [desc_annotation, ([desc_sig_punctuation, ':'],\n                                    desc_sig_space,\n                                    [pending_xref, \"int\"],\n                                    desc_sig_space,\n                                    [desc_sig_punctuation, '|'],\n                                    desc_sig_space,\n                                    [pending_xref, \"str\"])]))\n"], "sample_965": ["def test_getorigbases():\n    class Base:\n        pass\n\n    class Derived(Base):\n        __orig_bases__ = (Base,)\n\n    assert inspect.getorigbases(Derived) == (Base,)\n    assert inspect.getorigbases(Base) is None\n"], "sample_966": ["def test_pytype_with_module_prefix(app):\n    text = (\".. py:module:: example\\n\"\n            \".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   :param str name: blah blah\\n\"\n            \"   :param age: blah blah\\n\"\n            \"   :type age: example.Type\\n\")\n    doctree = restructuredtext.parse(app, text)\n\n    assert_node(doctree,\n                (nodes.target,\n                 addnodes.index,\n                 addnodes.index,\n                 [desc, ([desc_signature, ([desc_annotation, (\"class\", desc_sig_space)],\n                                           [desc_addname, \"example.\"],\n                                           [desc_name, \"Class\"])],\n                         [desc_content, nodes.field_list, nodes.field])]))\n    assert_node(doctree[3][1][0][0],\n                ([nodes.field_name, \"Parameters\"],\n                 [nodes.field_body, nodes.bullet_list, ([nodes.list_item, nodes.paragraph],\n                                                        [nodes.list_item, nodes.paragraph])]))\n\n    # :param str name:\n    assert_node(doctree[3][1][0][0][1][0][0][0],\n                ([addnodes.literal_strong, \"name\"],\n                 \" (\",\n                 [pending_xref, addnodes.literal_emphasis, \"str\"],\n                 \")\",\n                 \" -- \",\n                 \"blah blah\"))\n    assert_node(doctree[3][1][0][0][1][0][0][0][2], pending_xref,\n                refdomain=\"py\", reftype=\"class\", reftarget=\"str\",\n                **{\"py:module\": \"example\", \"py:class\": \"Class\"})\n\n    # :param age: + :type age:\n    assert_node(doctree[3][1][0][0][1][0][1][0],\n                ([addnodes.literal_strong, \"age\"],\n                 \" (\",\n                 [pending_xref, addnodes.literal_emphasis, \"Type\"],\n                 \")\",\n                 \" -- \",\n                 \"blah blah\"))\n    assert_node(doctree[3][1][0][0][1][0][1][0][2], pending_xref,\n                refdomain=\"py\", reftype=\"class\", reftarget=\"example.Type\",\n                **{\"py:module\": \"example\", \"py:class\": \"Class\"})\n"], "sample_970": ["def test_is_builtin_class_method():\n    assert inspect.is_builtin_class_method(int, '__init__') is True\n    assert inspect.is_builtin_class_method(str, 'join') is True\n    assert inspect.is_builtin_class_method(list, 'append') is True\n    assert inspect.is_builtin_class_method(MyInt, '__init__') is True\n    assert inspect.is_builtin_class_method(MyInt, 'my_method') is False\n"], "sample_971": ["def test_prefixed_warnings(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    with logging.prefixed_warnings(\"prefix:\"):\n        logger.warning('message1')\n        assert 'prefix: WARNING: message1' in warning.getvalue()\n\n    logger.warning('message2')\n    assert 'WARNING: message2' in warning.getvalue()\n"], "sample_973": ["def test_is_builtin_class_method():\n    assert inspect.is_builtin_class_method(int, '__init__') is True\n    assert inspect.is_builtin_class_method(str, 'upper') is True\n    assert inspect.is_builtin_class_method(list, 'append') is True\n    assert inspect.is_builtin_class_method(dict, 'keys') is True\n\n    class MyInt(int):\n            pass\n\n    assert inspect.is_builtin_class_method(MyInt, '__init__') is True\n    assert inspect.is_builtin_class_method(MyInt, 'my_method') is False\n"], "sample_981": ["def test_cycle_structure():\n    p = Permutation([0, 1, 2, 3])\n    assert p.cycle_structure == {1: 4}\n    p = Permutation([0, 2, 1, 3])\n    assert p.cycle_structure == {1: 2, 2: 1}\n    p = Permutation([0, 1, 3, 2])\n    assert p.cycle_structure == {1: 2, 2: 1}\n    p = Permutation([1, 0, 3, 2])\n    assert p.cycle_structure == {2: 2}\n"], "sample_983": ["def test_sparse_matrix_row_structure_symbolic_cholesky():\n    S = SparseMatrix([\n        [1, 0, 3, 2],\n        [0, 0, 1, 0],\n        [4, 0, 0, 5],\n        [0, 6, 7, 0]])\n    assert S.row_structure_symbolic_cholesky() == [[0], [], [0], [1, 2]]\n"], "sample_986": ["def test_evalf_maxprec():\n    assert NS(pi, 1000) != NS(pi, 1001)\n    assert NS(pi, 1000, maxn=1000) == NS(pi, 1001, maxn=1000)\n"], "sample_987": ["def test_evalf_piecewise():\n    from sympy import Piecewise, sin, cos\n    x = Symbol('x')\n    f = Piecewise((sin(x), x < 0), (cos(x), x >= 0))\n    assert NS(f.subs(x, -1)) == '-0.841470984807897'\n    assert NS(f.subs(x, 1)) == '0.540302305868140'\n"], "sample_988": ["def test_issue_13348():\n    assert Eq(True, 1) is S.false\n    assert Eq(False, 0) is S.false\n    assert Eq(True, 0) is S.false\n    assert Eq(False, 1) is S.false\n"], "sample_989": ["def test_mod_inverse_with_Mod():\n    assert mod_inverse(3, Mod(11, 7)) == 4\n    assert mod_inverse(5, Mod(11, 7)) == 9\n    assert mod_inverse(21124921, Mod(521512, 7)) == 7713\n    assert mod_inverse(124215421, Mod(5125, 7)) == 2981\n    assert mod_inverse(214, Mod(12515, 7)) == 1579\n    assert mod_inverse(5823991, Mod(3299, 7)) == 1442\n    assert mod_inverse(123, Mod(44, 7)) == 39\n    assert mod_inverse(2, Mod(5, 7)) == 3\n    assert mod_inverse(-2, Mod(5, 7)) == -3\n    x = Symbol('x')\n    assert S(2).invert(Mod(x, 7)) == S.Half\n    raises(TypeError, lambda: mod_inverse(2, Mod(x, 7)))\n    raises(ValueError, lambda: mod_inverse(2, Mod(S.Half, 7)))\n    raises(ValueError, lambda: mod_inverse(2, Mod(cos(1)**2 + sin(1)**2, 7)))\n"], "sample_990": ["def test_csch_expansion():\n    x, y = symbols('x,y')\n    assert csch(x+y).expand(trig=True) == (csch(x)*csch(y)*cosh(x)*cosh(y) - \n                                           csch(x)*csch(y)*sinh(x)*sinh(y))\n    assert csch(2*x).expand(trig=True) == csch(x)**2*cosh(x)*sinh(x)\n    assert csch(3*x).expand(trig=True).expand() == csch(x)**3*cosh(x)**2*sinh(x) - \\\n        csch(x)**3*sinh(x)**3\n"], "sample_997": ["def test_lambda_notation():\n    transformations = standard_transformations + (lambda_notation,)\n    x = Symbol('x')\n    y = Symbol('y')\n\n    assert parse_expr(\"lambda x: x**2\", transformations=transformations) == Lambda(x, x**2)\n    assert parse_expr(\"(lambda x, y: x + y)(1, 2)\", transformations=transformations) == Lambda((x, y), x + y).subs({x: 1, y: 2})\n"], "sample_999": ["def test_latex_Quaternion_conjugate():\n    q = Quaternion(x, y, z, t)\n    assert latex(q.conjugate()) == \"x - y i - z j - t k\"\n"], "sample_1001": ["def test_latex_Quaternion_conjugate():\n    q = Quaternion(x, y, z, t)\n    assert latex(q.conjugate()) == \"x - y i - z j - t k\"\n"], "sample_1003": ["def test_Method_postprocess():\n    opt = {'method': 'something'}\n    Method.postprocess(opt)\n\n    assert opt == {'method': 'something'}\n"], "sample_1008": ["def test_coordinate_sym_equality():\n    A = ReferenceFrame('A')\n    B = ReferenceFrame('B')\n    assert A[0] == CoordinateSym('Ax', A, 0)\n    assert A[1] == CoordinateSym('Ay', A, 1)\n    assert A[2] == CoordinateSym('Az', A, 2)\n    assert A[0] != CoordinateSym('Ax', B, 0)\n    assert A[1] != CoordinateSym('Ay', B, 1)\n    assert A[2] != CoordinateSym('Az', B, 2)\n    assert A[0] != CoordinateSym('Ax', A, 1)\n    assert A[1] != CoordinateSym('Ay', A, 2)\n    assert A[2] != CoordinateSym('Az', A, 0)\n"], "sample_1009": ["def test_vector_magnitude_normalize():\n    N = ReferenceFrame('N')\n    u1, u2, u3 = symbols('u1 u2 u3')\n\n    v = u1 * N.x + u2 * N.y + u3 * N.z\n\n    assert v.magnitude() == sqrt(u1**2 + u2**2 + u3**2)\n    assert v.normalize() == v / v.magnitude()\n    assert v.normalize().magnitude() == 1\n"], "sample_1012": ["def test_PythonCodePrinter_printing_of_infinity():\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(oo) == 'float(\\'inf\\')'\n    assert prntr.doprint(-oo) == 'float(\\'-inf\\')'\n    assert prntr.doprint(zoo) == 'float(\\'nan\\')'\n"], "sample_1019": ["def test_monotonic_sign():\n    assert _monotonic_sign(x) is None\n    assert _monotonic_sign(-x) is None\n    assert _monotonic_sign(2*x + 3) == 1\n    assert _monotonic_sign(-2*x - 3) == -1\n    assert _monotonic_sign(x**2 + 2*x + 1) == 1\n    assert _monotonic_sign(-(x**2 + 2*x + 1)) == -1\n    assert _monotonic_sign(x**3 + x**2 - x - 1) is None\n    assert _monotonic_sign(-x**3 - x**2 + x + 1) is None\n    assert _monotonic_sign(exp(x)) == 1\n    assert _monotonic_sign(-exp(x)) == -1\n    assert _monotonic_sign(log(x)) == 1\n    assert _monotonic_sign(-log(x)) == -1\n"], "sample_1021": ["def test_quaternion_mul():\n    q1 = Quaternion(1, 2, 3, 4)\n    q2 = Quaternion(5, 6, 7, 8)\n\n    assert q1 * q2 == Quaternion(-60, 12, 30, 24)\n    assert q1 * 2 == Quaternion(2, 4, 6, 8)\n    assert 2 * q1 == Quaternion(2, 4, 6, 8)\n\n    x = symbols('x', real=True)\n    assert q1 * x == Quaternion(x, 2*x, 3*x, 4*x)\n    assert x * q1 == Quaternion(x, 2*x, 3*x, 4*x)\n\n    q3 = Quaternion(3 + 4*I, 2 + 5*I, 0, 7 + 8*I, real_field=False)\n    assert q3 * (2 + 3*I) == Quaternion((2 + 3*I)*(3 + 4*I), (2 + 3*I)*(2 + 5*I), 0, (2 + 3*I)*(7 + 8*I))\n"], "sample_1022": ["def test_split_symbols_custom():\n    transformations = standard_transformations + (split_symbols_custom(lambda x: False),)\n    cases = {\n        'unsplittable': 'unsplittable',\n        'names': 'names',\n        'xyz': 'xyz',\n    }\n    for case, expected in cases.items():\n        assert(parse_expr(case, transformations=transformations) ==\n               parse_expr(expected))\n\n    transformations = standard_transformations + (split_symbols_custom(lambda x: True),)\n    cases = {\n        'unsplittable': 'u*n*s*p*l*i*t*t*a*b*l*e',\n        'names': 'n*a*m*e*s',\n        'xyz': 'x*y*z',\n    }\n    for case, expected in cases.items():\n        assert(parse_expr(case, transformations=transformations) ==\n               parse_expr(expected))\n"], "sample_1030": ["def test_closest_points():\n    p1, p2, p3 = Point(0, 0), Point(1, 1), Point(1, -1)\n    assert closest_points(p1, p2, p3) == {(p1, p2), (p1, p3)}\n    p4, p5 = Point(0, 1), Point(1, 0)\n    assert closest_points(p1, p2, p3, p4, p5) == {(p1, p4), (p1, p5)}\n"], "sample_1031": ["def test_get_unit():\n    ms = UnitSystem((m, s), (c,))\n    assert ms.get_unit(length) == m\n    assert ms.get_unit(velocity) == c\n    raises(KeyError, lambda: ms.get_unit(mass))\n"], "sample_1036": ["def test_mul_as_coefficients_dict():\n    from sympy.abc import a, b\n    assert Mul(3, a, b).as_coefficients_dict() == {a*b: 3}\n    assert Mul(a, b).as_coefficients_dict() == {a*b: 1}\n    assert Mul(2, a, b).as_coefficients_dict()[a] == 0\n"], "sample_1039": ["def test_print_random_symbol():\n    A = RandomSymbol('A')\n    assert mpp.doprint(A) == '<mi>A</mi>'\n    assert mp.doprint(A) == '<ci>A</ci>'\n"], "sample_1040": ["def test_print_random_symbol():\n    A = RandomSymbol('A')\n    assert mpp.doprint(A) == '<mi>A</mi>'\n    assert mp.doprint(A) == '<ci>A</ci>'\n"], "sample_1049": ["def test_parameter_value():\n    from sympy.abc import t, u, v\n    p1 = Point3D(0, 0, 0)\n    p2 = Point3D(1, 1, 1)\n    p3 = Point3D(1, 2, 3)\n    pl3 = Plane(p1, p2, p3)\n\n    on_circle = pl3.arbitrary_point(t).subs(t, pi/4)\n    assert pl3.parameter_value(on_circle, t) == {t: pi/4}\n\n    off_circle = p1 + (on_circle - p1)*2\n    assert pl3.parameter_value(off_circle, t) == {t: pi/4}\n\n    pt = pl3.arbitrary_point(u, v)\n    sol = pl3.parameter_value(on_circle, u, v)\n    assert pt.subs(sol) == on_circle\n\n    sol = pl3.parameter_value(off_circle, u, v)\n    assert pt.subs(sol) == off_circle\n"], "sample_1050": ["def test_PythonCodePrinter_printing_of_infinity():\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(oo) == \"float('inf')\"\n    assert prntr.doprint(-oo) == \"float('-inf')\"\n    assert prntr.doprint(zoo) == \"float('nan')\"\n"], "sample_1055": ["def test_padded_key_with_default_symbols():\n    assert padded_key('b', 'ab', symbols='abcd') == 'ba'\n    raises(ValueError, lambda: padded_key('ab', 'ace', symbols='abcd'))\n    raises(ValueError, lambda: padded_key('ab', 'abba', symbols='abcd'))\n"], "sample_1058": ["def test_issue_20757():\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(1 / (x - 1)) == '1/(x - 1)'\n    assert prntr.doprint(x / (x - 1)) == 'x/(x - 1)'\n    assert prntr.doprint((x - 2) / (x - 1)) == '(x - 2)/(x - 1)'\n    assert prntr.doprint((x - 1) / x) == '(x - 1)/x'\n    assert prntr.doprint((x - 1) / (x - 2)) == '(x - 1)/(x - 2)'\n"], "sample_1061": ["def test_Pow_is_integer():\n    x = Symbol('x')\n    assert Pow(2, 3, evaluate=False).is_integer\n    assert not Pow(2, x, evaluate=False).is_integer\n    assert Pow(x, 0, evaluate=False).is_integer\n    assert Pow(2, -3, evaluate=False).is_rational\n    assert not Pow(2, -x, evaluate=False).is_rational\n    assert Pow(x, 0, evaluate=False).is_rational\n"], "sample_1062": ["def test_TR22():\n    assert TR22(1 + tan(x)**2) == sec(x)**2\n    assert TR22(1 + cot(x)**2) == csc(x)**2\n    assert TR22(tan(x)**4) == (sec(x)**2 - 1)**2\n    assert TR22(cot(x)**4) == (csc(x)**2 - 1)**2\n"], "sample_1064": ["def test_tensorflow_derivative():\n    if not tf:\n        skip(\"TensorFlow not installed\")\n\n    x = Symbol('x')\n    y = Symbol('y')\n\n    expr = Derivative(x**2, x)\n    assert tensorflow_code(expr) == \\\n        'tensorflow.gradients(x**2, x)[0]'\n    _compare_tensorflow_scalar((x,), expr)\n\n    expr = Derivative(x**2*y, x)\n    assert tensorflow_code(expr) == \\\n        'tensorflow.gradients(x**2*y, x)[0]'\n    _compare_tensorflow_scalar((x, y), expr)\n\n    expr = Derivative(x**2*y, (x, y))\n    assert tensorflow_code(expr) == \\\n        'tensorflow.gradients(tensorflow.gradients(x**2*y, x)[0], y)[0]'\n    _compare_tensorflow_scalar((x, y), expr)\n"], "sample_1066": ["def test_mathml_Inverse():\n    from sympy.matrices import MatrixSymbol, Inverse\n    X = MatrixSymbol('X', 2, 2)\n    assert mathml(Inverse(X), printer='presentation') == \\\n        '<msup><mi>X</mi><mn>-1</mn></msup>'\n    assert mathml(Inverse(X + X), printer='presentation') == \\\n        '<msup><mfenced><mrow><mi>X</mi><mo>+</mo><mi>X</mi></mrow></mfenced><mn>-1</mn></msup>'\n    assert mathml(Inverse(X)*Inverse(X), printer='presentation') == \\\n        '<mrow><msup><mi>X</mi><mn>-1</mn></msup><mo>&InvisibleTimes;</mo><msup><mi>X</mi><mn>-1</mn></msup></mrow>'\n    assert mathml(Inverse(X**2), printer='presentation') == \\\n        '<msup><mfenced><msup><mi>X</mi><mn>2</mn></msup></mfenced><mn>-1</mn></msup>'\n    assert mathml(Inverse(X)**2, printer='presentation') == \\\n        '<msup><mfenced><msup><mi>X</mi><mn>-1</mn></msup></mfenced><mn>2</mn></msup>'\n"], "sample_1077": ["def test_issue_19611():\n    assert ImageSet(Lambda(x, x**2), S.Integers).is_subset(S.Rationals)\n    assert ImageSet(Lambda(x, x/2), S.Integers).is_subset(S.Rationals)\n    assert ImageSet(Lambda(x, x/3), S.Integers).is_subset(S.Rationals)\n"], "sample_1079": ["def test_orthogonal_direction():\n    p1 = Point(1, 2)\n    p2 = Point(3, 4)\n    p3 = Point(0, 0)\n\n    assert p1.orthogonal_direction == Point(-2, 1)\n    assert p2.orthogonal_direction == Point(-4, 3)\n    assert p3.orthogonal_direction == Point(1, 0)\n\n    p4 = Point(1, 2, 3)\n    p5 = Point(4, 5, 6)\n    p6 = Point(0, 0, 0)\n\n    assert p4.orthogonal_direction == Point(-2, 1, 0)\n    assert p5.orthogonal_direction == Point(-5, 4, 0)\n    assert p6.orthogonal_direction == Point(1, 0, 0)\n"], "sample_1081": ["def test_is_amicable():\n    assert is_amicable(220, 284) is True\n    assert is_amicable(1184, 1210) is True\n    assert is_amicable(2620, 2924) is True\n    assert is_amicable(5020, 5564) is True\n    assert is_amicable(6232, 6368) is True\n    assert is_amicable(10, 15) is False\n    assert is_amicable(12, 14) is False\n"], "sample_1082": ["def test_issue_17344():\n    x = Symbol('x')\n    assert sinh(x).rewrite(csch) == 1/csch(x)\n    assert cosh(x).rewrite(sech) == 1/sech(x)\n    assert tanh(x).rewrite(coth) == 1/coth(x)\n    assert csch(x).rewrite(sinh) == 1/sinh(x)\n    assert sech(x).rewrite(cosh) == 1/cosh(x)\n    assert coth(x).rewrite(tanh) == 1/tanh(x)\n"], "sample_1083": ["def test_hyperbolic_is_extended_real():\n    x = Symbol('x', extended_real=True)\n    assert sinh(x).is_extended_real is True\n    assert cosh(x).is_extended_real is True\n    assert tanh(x).is_extended_real is True\n    assert coth(x).is_extended_real is True\n    assert sech(x).is_extended_real is True\n    assert csch(x).is_extended_real is True\n\n    x = Symbol('x', real=False)\n    assert sinh(x).is_extended_real is None\n    assert cosh(x).is_extended_real is None\n    assert tanh(x).is_extended_real is None\n    assert coth(x).is_extended_real is None\n    assert sech(x).is_extended_real is None\n    assert csch(x).is_extended_real is None\n"], "sample_1086": ["def test_issue_16458():\n    from sympy import log\n    assert str(log(x, 2)) == 'log(x, 2)'\n    assert str(log(x, 10)) == 'log(x, 10)'\n"], "sample_1091": ["def test_issue_16587():\n    with warns_deprecated_sympy():\n        Eq(x)\n    assert Eq(x) == Eq(x, 0)\n"], "sample_1093": ["def test_issue_20757():\n    from sympy import BlockMatrix\n\n    M = MatrixSymbol('M', 2, 2)\n    N = MatrixSymbol('N', 2, 2)\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(BlockMatrix([[M, N]])) == 'numpy.block([[M, N]])'\n"], "sample_1095": ["def test_AppliedPermutation():\n    x = Symbol('x')\n    p = Permutation(0, 1, 2)\n    ap = AppliedPermutation(p, x)\n\n    assert ap.subs(x, 0) == 1\n    assert ap.subs(x, 1) == 2\n    assert ap.subs(x, 2) == 0\n\n    assert ap.free_symbols == {x}\n    assert ap.func(*ap.args) == ap\n\n    assert str(ap) == 'AppliedPermutation((0 1 2), x)'\n    assert repr(ap) == 'AppliedPermutation(Permutation(0, 1, 2), x)'\n"], "sample_1097": ["def test_blockinverse_2x2():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    inv_X = block_collapse(X.inverse())\n    assert inv_X.blocks[0, 0] == (A - B*D.I*C).I\n    assert inv_X.blocks[0, 1] == -A.I*B*(D - C*A.I*B).I\n    assert inv_X.blocks[1, 0] == -(D - C*A.I*B).I*C*A.I\n    assert inv_X.blocks[1, 1] == (D - C*A.I*B).I\n"], "sample_1098": ["def test_hyper_evalf():\n    from sympy import hyper, exp, pi, I\n    assert abs(hyper([], [], 2).evalf() - exp(2)) < 1e-10\n    assert abs(hyper([1, 2], [3], 0.5).evalf() - hyper([1, 2], [3], Rational(1, 2)).evalf()) < 1e-10\n    assert abs(hyper([1, 2], [3], 2 + 3*I).evalf() - hyper([1, 2], [3], 2 + 3*I).evalf()) < 1e-10\n    assert abs(hyper([1, 2], [3], pi).evalf() - hyper([1, 2], [3], pi.evalf()).evalf()) < 1e-10\n"], "sample_1100": ["def test_Pow_is_algebraic():\n    x = Symbol('x')\n    assert (2**x).is_algebraic is None\n    assert (2**(1/x)).is_algebraic is None\n    assert (2**(1/(x + 1))).is_algebraic is None\n    assert (2**(1/(x + 1))).is_transcendental is None\n    assert (2**Rational(3, 4)).is_algebraic is True\n    assert (2**Rational(3, 4)).is_transcendental is False\n    assert (2**pi).is_algebraic is False\n    assert (2**pi).is_transcendental is True\n    assert (2**I).is_algebraic is None\n    assert (2**I).is_transcendental is None\n    assert ((-2)**I).is_algebraic is None\n    assert ((-2)**I).is_transcendental is None\n    assert (2**(I*pi)).is_algebraic is True\n    assert (2**(I*pi)).is_transcendental is False\n"], "sample_1103": ["def test_Pow_is_algebraic():\n    x = Symbol('x')\n    assert (2**x).is_algebraic is None\n    assert (2**(1/x)).is_algebraic is None\n    assert (2**(1/(x + 1))).is_algebraic is None\n    assert (2**(1/(x + 1))).is_algebraic is None\n    assert ((-2)**(1/3)).is_algebraic is True\n    assert ((-2)**Rational(1, 3)).is_algebraic is True\n    assert ((-2)**(1/4)).is_algebraic is False\n    assert ((-2)**Rational(1, 4)).is_algebraic is False\n    assert (2**(1/Sqrt(2))).is_algebraic is True\n    assert (2**(1/sqrt(2))).is_algebraic is True\n    assert (2**(1/(sqrt(2) + 1))).is_algebraic is True\n    assert (2**(1/(sqrt(2) - 1))).is_algebraic is True\n    assert (2**(1/(sqrt(2) + sqrt(3)))).is_algebraic is True\n    assert (2**(1/(sqrt(2) - sqrt(3)))).is_algebraic is True\n"], "sample_1104": ["def test_issue_16458():\n    from sympy import div\n    q, r = div(4*x**2 + 3*x + 2, 2*x + 1)\n    assert str(q) == '2*x - 1/2'\n    assert str(r) == '5/2'\n"], "sample_1105": ["def test_matmul_entry():\n    from sympy import Dummy, Sum\n    i = Dummy(\"i\")\n    j = Dummy(\"j\")\n    assert MatMul(A, B)._entry(i, j) == Sum(A[i, i]*B[i, j], (i, 0, A.shape[1] - 1))\n"], "sample_1107": ["def test_roundrobin():\n    gen = roundrobin('ABC', 'D', 'EF')\n    assert list(gen) == ['A', 'D', 'E', 'B', 'F', 'C']\n"], "sample_1108": ["def test_roundrobin():\n    assert list(roundrobin('ABC', 'D', 'EF')) == [\n        'A', 'D', 'E', 'B', 'F', 'C']\n    assert list(roundrobin([1, 2], [3, 4, 5])) == [1, 3, 2, 4]\n"], "sample_1110": ["def test_lambertw():\n    from sympy import lambertw\n\n    expr = lambertw(x)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr) == 'scipy.special.lambertw(x)'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr) == '  # Not supported in Python with NumPy:\\n  # lambertw\\nlambertw(x)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr) == '  # Not supported in Python:\\n  # lambertw\\nlambertw(x)'\n\n    prntr = MpmathPrinter()\n    assert prntr.doprint(expr) == 'mpmath.lambertw(x)'\n"], "sample_1117": ["def test_matrix_element_sets_slices_blocks_transpose():\n    from sympy.matrices.expressions import BlockMatrix\n    X = MatrixSymbol('X', 4, 4)\n    assert ask(Q.integer_elements(X[:, 3].T), Q.integer_elements(X))\n    assert ask(Q.integer_elements(BlockMatrix([[X], [X]]).T),\n                        Q.integer_elements(X))\n"], "sample_1119": ["def test_matpow():\n    assert MatPow(C, 0) == Identity(n)\n    assert MatPow(C, 1) == C\n    assert MatPow(C, -1) == Inverse(C)\n    assert MatPow(C, -2) == Inverse(C)*Inverse(C)\n    assert MatPow(C, 2).args == (C, 2)\n    assert MatPow(C, 2).shape == (n, n)\n    assert MatPow(C, -2).shape == (n, n)\n\n    assert MatPow(Identity(n), 3) == Identity(n)\n    assert MatPow(Identity(n), -3) == Identity(n)\n\n    assert MatPow(ZeroMatrix(n, n), 3) == ZeroMatrix(n, n)\n    assert MatPow(ZeroMatrix(n, n), -3) == ZeroMatrix(n, n)\n\n    assert MatPow(C, S.Half) == MatPow(C, S.Half)\n    assert MatPow(C, S(-1)/2) == MatPow(Inverse(C), S.Half)\n"], "sample_1120": ["def test_matrix_derivative():\n    from sympy import sin, cos\n    x = symbols('x')\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    f = MatrixSymbol('f', 1, 1)\n    g = MatrixSymbol('g', 1, 1)\n\n    assert _matrix_derivative(A, x) == ZeroMatrix(2, 2)\n    assert _matrix_derivative(x*A, x) == A\n    assert _matrix_derivative(A*x, x) == A\n\n    expr = sin(x)*A + cos(x)*B\n    result = diff(expr, x)\n    assert _matrix_derivative(expr, x) == result\n\n    expr = sin(x)*A*B + cos(x)*B*A\n    result = diff(expr, x)\n    assert _matrix_derivative(expr, x) == result\n\n    expr = sin(x)*f*g + cos(x)*g*f\n    result = diff(expr, x)\n    assert _matrix_derivative(expr, x) == result\n"], "sample_1121": ["def test_Mul_is_algebraic():\n    a = Symbol('a', algebraic=True)\n    b = Symbol('b', algebraic=True)\n    c = Symbol('c', algebraic=False)\n    d = Symbol('d', algebraic=False)\n\n    assert (a*b).is_algebraic is True\n    assert (a*c).is_algebraic is None\n    assert (c*d).is_algebraic is False\n\n    assert (2*a).is_algebraic is True\n    assert (2*c).is_algebraic is False\n\n    assert (a**2).is_algebraic is True\n    assert (c**2).is_algebraic is False\n"], "sample_1129": ["def test_lambertw():\n    from sympy import lambertw\n\n    expr = lambertw(x)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr) == 'scipy.special.lambertw(x)'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr) == '  # Not supported in Python with NumPy:\\n  # lambertw\\nlambertw(x)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr) == '  # Not supported in Python:\\n  # lambertw\\nlambertw(x)'\n"], "sample_1130": ["def test_point_vel_with_intermediate_frame():\n    q, u = dynamicsymbols('q u')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    O = Point('O')\n    P = Point('P')\n    O.set_vel(N, u * N.x)\n    P.set_pos(O, q * B.y)\n    raises(ValueError, lambda: P.vel(N))  # B's orientation with respect to N is not defined\n    N.orient(B, 'Axis', (q, B.x))\n    assert P.vel(N) == u * N.x + q.diff(dynamicsymbols._t) * B.y - q * q.diff(dynamicsymbols._t) * B.z\n"], "sample_1131": ["def test_lambertw():\n    from sympy import lambertw\n\n    expr = lambertw(x)\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(expr) == 'scipy.special.lambertw(x)'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(expr) == '  # Not supported in Python with NumPy:\\n  # lambertw\\nlambertw(x)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(expr) == '  # Not supported in Python:\\n  # lambertw\\nlambertw(x)'\n"], "sample_1132": ["def test_roundrobin():\n    assert list(roundrobin('ABC', 'D', 'EF')) == [\n        'A', 'D', 'E', 'B', 'F', 'C']\n    assert list(roundrobin([1, 2], [3, 4, 5], [6, 7])) == [\n        1, 3, 6, 2, 4, 7]\n"], "sample_1133": ["def test_refraction_angle_with_total_internal_reflection():\n    n1, n2 = symbols('n1, n2')\n    m1 = Medium('m1', permittivity=e0, n=1.33)\n    m2 = Medium('m2', permittivity=e0, n=1)\n    r1 = Ray3D(Point3D(-1, -1, 1), Point3D(0, 0, 0))\n    P = Plane(Point3D(0, 0, 0), normal_vector=[0, 0, 1])\n    assert refraction_angle(r1, m1, m2, plane=P) == 0\n    raises(ValueError, lambda: refraction_angle(1.5, m1, m2))\n"], "sample_1135": ["def test_Mul_is_algebraic():\n    a = Symbol('a', algebraic=True)\n    b = Symbol('b', algebraic=True)\n    c = Symbol('c', algebraic=False)\n    assert (a*b).is_algebraic is True\n    assert (a*c).is_algebraic is None\n    assert (b*c).is_algebraic is None\n    assert (c*a).is_algebraic is None\n    assert (c*b).is_algebraic is None\n    assert (c*c).is_algebraic is None\n"], "sample_1138": ["def test_TR22():\n    assert TR22(1 + tan(x)**2) == sec(x)**2\n    assert TR22(1 + cot(x)**2) == csc(x)**2\n    assert TR22(tan(x)**4) == (sec(x)**2 - 1)**2\n    assert TR22(cot(x)**4) == (csc(x)**2 - 1)**2\n"], "sample_1141": ["def test_expr_free_symbols():\n    from sympy.utilities.exceptions import SymPyDeprecationWarning\n    import warnings\n    warnings.simplefilter(\"ignore\", SymPyDeprecationWarning)\n    A = MatrixSymbol('A', 2, 2)\n    assert A.expr_free_symbols == set()\n    assert (A[0, 0]).expr_free_symbols == {A}\n"], "sample_1142": ["def test_matrix_derivative():\n    from sympy.tensor.array.array_derivatives import ArrayDerivative\n\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n\n    # Derivative of a matrix with respect to itself\n    assert _matrix_derivative(A, A) == Identity(2)\n\n    # Derivative of a matrix with respect to another matrix\n    assert _matrix_derivative(A*B, A) == B.T\n    assert _matrix_derivative(A*B, B) == A\n\n    # Derivative of a matrix with respect to a scalar\n    x = symbols('x')\n    assert _matrix_derivative(x*A, x) == A\n\n    # Higher order derivatives\n    assert _matrix_derivative(_matrix_derivative(A*B, A), B) == Identity(2)\n"], "sample_1148": ["def test_matrix_derivative():\n    from sympy.tensor.array.array_derivatives import ArrayDerivative\n\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n\n    # Matrix derivative of a matrix with respect to another matrix\n    expr = A*B\n    x = A\n    result = _matrix_derivative(expr, x)\n    assert isinstance(result, MatAdd)\n\n    # Matrix derivative of a scalar with respect to a matrix\n    expr = A[0, 0]\n    x = A\n    result = _matrix_derivative(expr, x)\n    assert isinstance(result, MatrixExpr)\n\n    # Matrix derivative of a matrix with respect to a scalar\n    expr = A*B\n    x = symbols('x')\n    result = _matrix_derivative(expr, x)\n    assert result == ZeroMatrix(2, 2)\n"], "sample_1153": ["def test_issue_19627():\n    from sympy import Function, Symbol\n    x = Symbol('x')\n    f = Function('f', positive=True)\n    assert Abs(f(x)) == f(x)\n    assert Abs(-f(x)) == f(x)\n    assert Abs(I*f(x)) == f(x)\n    assert Abs(-I*f(x)) == f(x)\n"], "sample_1156": ["def test_tanh_expansion():\n    x, y = symbols('x,y')\n    assert tanh(x+y).expand(trig=True) == (tanh(x) + tanh(y)) / (1 + tanh(x)*tanh(y))\n    assert tanh(2*x).expand(trig=True) == 2*tanh(x) / (1 + tanh(x)**2)\n    assert tanh(3*x).expand(trig=True).expand() == \\\n        (3*tanh(x) - tanh(x)**3) / (1 - 3*tanh(x)**2)\n"], "sample_1160": ["def test_issue_18999():\n    n = Symbol('n', integer=True)\n    m = Symbol('m', integer=True)\n    assert Range(n, n + 49).is_finite_set is True\n    assert Range(n, 0).is_finite_set is True\n    assert Range(-3, n + 7).is_finite_set is True\n    assert Range(n, m).is_finite_set is True\n    assert Range(n + m, m - n).is_finite_set is True\n    assert Range(n, n + m + n).is_finite_set is True\n    assert Range(n, oo).is_finite_set is False\n    assert Range(-oo, n).is_finite_set is False\n    assert Range(n, -oo).is_finite_set is True\n    assert Range(oo, n).is_finite_set is True\n"], "sample_1161": ["def test_ElementwiseApplyFunction():\n    from sympy.tensor.array.expressions.array_expressions import ElementwiseApplyFunction\n    A = ArraySymbol(\"A\", (3, 3))\n    func = Lambda(x, x**2)\n    expr = ElementwiseApplyFunction(func, A)\n    assert str(expr) == \"Lambda(x, x**2).(A)\"\n"], "sample_1163": ["def test_polar_lift():\n    from sympy import polar_lift, exp_polar, pi, I\n    x = Symbol('x')\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == exp_polar(0)\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(x) == exp_polar(log(x))\n    assert polar_lift(2 + 3*I) == polar_lift(2 + 3*I)\n    assert polar_lift((2 + 3*I)*x) == (2 + 3*I)*polar_lift(x)\n    assert polar_lift(polar_lift(x)) == polar_lift(x)\n    assert polar_lift(exp_polar(x)) == exp_polar(x)\n"], "sample_1164": ["def test_cg_simp():\n    # Test cg_simp with a simple expression\n    expr = CG(1, 1, 0, 0, 1, 1) + CG(1, 0, 0, 0, 1, 0) + CG(1, -1, 0, 0, 1, -1)\n    assert cg_simp(expr) == 3\n\n    # Test cg_simp with a more complex expression\n    expr = (CG(1, 1, 0, 0, 1, 1) + CG(1, 0, 0, 0, 1, 0) + CG(1, -1, 0, 0, 1, -1)) * 2\n    assert cg_simp(expr) == 6\n\n    # Test cg_simp with an expression that cannot be simplified\n    expr = CG(1, 1, 1, 1, 2, 2) + CG(1, 0, 1, 0, 2, 0)\n    assert cg_simp(expr) == expr\n"], "sample_1165": ["def test_quaternion_division():\n    q1 = Quaternion(1, 2, 3, 4)\n    q2 = Quaternion(5, 6, 7, 8)\n\n    assert q1 / q2 == q1 * q2.inverse()\n    assert q1 / 2 == Quaternion(1/2, 1, 3/2, 2)\n    assert 2 / q1 == 2 * q1.inverse()\n\n    raises(ValueError, lambda: q1 / Quaternion(0, 0, 0, 0))\n"], "sample_483": ["def test_list_filter_item(self):\n    class SongAdmin(admin.ModelAdmin):\n        list_filter = (\"album\",)\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class InvalidListFilterAdmin(admin.ModelAdmin):\n        list_filter = (\"nonexistent_field\",)\n\n    errors = InvalidListFilterAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'list_filter[0]' refers to 'nonexistent_field', which does not refer to a Field.\",\n            obj=InvalidListFilterAdmin,\n            id=\"admin.E116\",\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_510": ["def test_subplot2grid():\n    fig = plt.figure()\n    ax1 = plt.subplot2grid((3, 3), (0, 0))\n    ax2 = plt.subplot2grid((3, 3), (1, 1), colspan=2)\n    assert ax1.get_geometry() == (3, 3, 1)\n    assert ax2.get_geometry() == (3, 3, 5)\n    with pytest.warns(MatplotlibDeprecationWarning):\n        ax3 = plt.subplot2grid((3, 3), (0, 0))\n    assert ax3 is ax1\n    ax4 = plt.subplot2grid((3, 3), (2, 2), projection='polar')\n    assert ax4.name == 'polar'\n    assert ax4 is not ax2\n    assert ax2 not in fig.axes\n"], "sample_640": ["def test_is_overload_stub() -> None:\n    node = astroid.extract_node(\n        \"\"\"\n        from typing import overload\n\n        @overload\n            ...\n        \"\"\"\n    )\n    assert utils.is_overload_stub(node) is True\n\n    node = astroid.extract_node(\n        \"\"\"\n            ...\n        \"\"\"\n    )\n    assert utils.is_overload_stub(node) is False\n"], "sample_812": ["def test_compact_repr():\n    # Test that the compact parameter is correctly used\n    pp = _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=True)\n    vocabulary = {i: i for i in range(10)}\n    vectorizer = CountVectorizer(vocabulary=vocabulary)\n\n    expected = r\"\"\""], "sample_980": ["def test_cycle_structure():\n    p = Permutation([1, 0, 2, 3])\n    assert p.cycle_structure == {2: 1, 1: 2}\n    q = Permutation([0, 1, 2, 3])\n    assert q.cycle_structure == {1: 4}\n    r = Permutation([3, 2, 1, 0])\n    assert r.cycle_structure == {4: 1}\n"], "sample_1017": ["def test_as_set_interval():\n    assert (x > 0).as_set() == Interval.open(0, oo)\n    assert (x >= 0).as_set() == Interval(0, oo)\n    assert (x < 0).as_set() == Interval.open(-oo, 0)\n    assert (x <= 0).as_set() == Interval(-oo, 0)\n    assert (x > 1).as_set() == Interval.open(1, oo)\n    assert (x >= 1).as_set() == Interval(1, oo)\n    assert (x < 1).as_set() == Interval.open(-oo, 1)\n    assert (x <= 1).as_set() == Interval(-oo, 1)\n    assert ((x > 0) & (x < 1)).as_set() == Interval.open(0, 1)\n    assert ((x >= 0) & (x <= 1)).as_set() == Interval(0, 1)\n"], "sample_1168": ["def test_roundrobin():\n    gen = roundrobin('ABC', 'D', 'EF')\n    assert ''.join(gen) == 'ADEBFC'\n"], "sample_1169": ["def test_FockStateBosonKet():\n    n = symbols(\"n\")\n    ket = FockStateBosonKet([n])\n    assert ket.args[0] == (n,)\n    assert ket.up(0) == FockStateBosonKet([n + 1])\n    assert ket.down(0) == sqrt(n)*FockStateBosonKet([n - 1])\n"], "sample_1174": ["def test_polar_lift():\n    from sympy import polar_lift, exp_polar, pi, I\n    x = Symbol('x')\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == 1\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(I*pi/2)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(x) == x\n    assert polar_lift(exp_polar(I*pi)) == exp_polar(I*pi)\n    assert polar_lift(exp_polar(-I*pi)) == exp_polar(I*pi)\n"], "sample_1177": ["def test_polar_lift():\n    from sympy.functions.elementary.complexes import polar_lift\n    x = Symbol('x')\n    assert polar_lift(0) == 0\n    assert polar_lift(1) == exp_polar(0)\n    assert polar_lift(-1) == exp_polar(I*pi)\n    assert polar_lift(I) == exp_polar(I*pi/2)\n    assert polar_lift(-I) == exp_polar(-I*pi/2)\n    assert polar_lift(x) == exp_polar(arg(x))*Abs(x)\n    assert polar_lift(2 + 3*I) == exp_polar(arg(2 + 3*I))*(13**S.Half)\n    assert polar_lift((1 + I)**2) == polar_lift(2*I)\n    assert polar_lift((1 + I)**4) == polar_lift(-4)\n\n    p = Symbol('p', positive=True)\n    assert polar_lift(p) == p*exp_polar(0)\n    assert polar_lift(p*x) == p*polar_lift(x)\n    assert polar_lift(p*(1 + I)) == p*exp_polar(I*pi/4)*2**S.Half\n\n    n = Symbol('n', negative=True)\n    assert polar_lift(n).args[0] != n\n    assert polar_lift(n).args[0] == -n\n    assert polar_lift(n).args[1] == exp_polar(I*pi)\n    assert polar_lift(n*x) == -n*polar_lift(-x)\n    assert polar_lift(n*(1 + I)) == n*exp_polar(I*5*pi/4)*2**S.Half\n"], "sample_1178": ["def test_Element():\n    elem = Element('x', 'ijk')\n    assert elem.symbol.name == 'x'\n    assert elem.indices == (Symbol('i'), Symbol('j'), Symbol('k'))\n    assert elem.strides is None\n    assert elem.offset is None\n\n    elem2 = Element('x', 'ijk', strides='lmn', offset='o')\n    assert elem2.symbol.name == 'x'\n    assert elem2.indices == (Symbol('i'), Symbol('j'), Symbol('k'))\n    assert elem2.strides == (Symbol('l'), Symbol('m'), Symbol('n'))\n    assert elem2.offset == Symbol('o')\n\n    assert elem != elem2\n    assert elem.func(*elem.args) == elem\n"], "sample_1179": ["def test_ElementwiseApplyFunction():\n    from sympy.tensor.array.expressions.array_expressions import ElementwiseApplyFunction\n    A = ArraySymbol(\"A\", (2, 2))\n    func = Lambda(x, x**2)\n    ewaf = ElementwiseApplyFunction(func, A)\n    assert str(ewaf) == \"Lambda(x, x**2).(A)\"\n"], "sample_1180": ["def test_affine_rank():\n    assert Point.affine_rank() == -1\n    assert Point.affine_rank(Point(0, 0)) == 0\n    assert Point.affine_rank(Point(0, 0), Point(1, 1)) == 1\n    assert Point.affine_rank(Point(0, 0), Point(1, 1), Point(2, 2)) == 1\n    assert Point.affine_rank(Point(0, 0), Point(1, 0), Point(0, 1)) == 2\n    assert Point.affine_rank(Point(0, 0, 0), Point(1, 0, 0), Point(0, 1, 0), Point(0, 0, 1)) == 3\n"], "sample_1181": ["def test_scipy_print_methods():\n    prntr = SciPyPrinter()\n    assert hasattr(prntr, '_print_erf')\n    assert hasattr(prntr, '_print_factorial')\n    assert hasattr(prntr, '_print_gamma')\n    assert hasattr(prntr, '_print_loggamma')\n"], "sample_1184": ["def test_BeamParameter():\n    wavelen, z, z_r, n = symbols('wavelen z z_r n')\n    p = BeamParameter(wavelen, z, z_r=z_r, n=n)\n    assert p.wavelen == wavelen\n    assert p.z == z\n    assert p.z_r == z_r\n    assert p.n == n\n    assert p.q == z + I*z_r\n    assert p.radius == z*(1 + (z_r/z)**2)\n    assert p.w == sqrt(z_r/pi/n*wavelen)*sqrt(1 + (z/z_r)**2)\n    assert p.w_0 == sqrt(z_r/pi/n*wavelen)\n    assert p.divergence == wavelen/pi/sqrt(z_r/pi/n*wavelen)\n    assert p.gouy == atan2(z, z_r)\n    assert p.waist_approximation_limit == 2*wavelen/pi\n"], "sample_1187": ["def test_hyperplane_parameters():\n    triangle = Polygon(Point(0, 3), Point(5, 3), Point(1, 1))\n    assert hyperplane_parameters(triangle) == [((0, 1), 3), ((1, -2), -1), ((-2, -1), -3)]\n    cube = [[(0, 0, 0), (0, 0, 5), (0, 5, 0), (0, 5, 5), (5, 0, 0),\n             (5, 0, 5), (5, 5, 0), (5, 5, 5)],\n            [2, 6, 7, 3], [3, 7, 5, 1], [7, 6, 4, 5], [1, 5, 4, 0],\n            [3, 1, 0, 2], [0, 4, 6, 2]]\n    vertices = cube[0]\n    faces = cube[1:]\n    assert hyperplane_parameters(faces, vertices) == [([0, -1, 0], -5), ([0, 0, -1], -5), \n                                                     ([-1, 0, 0], -5), ([0, 1, 0], 0), \n                                                     ([1, 0, 0], 0), ([0, 0, 1], 0)]\n"], "sample_1188": ["def test_pretty_printing_mod():\n    from sympy import symbols, Mod\n    x = symbols('x')\n    assert pretty(Mod(x, 2)) == 'x mod 2'\n"], "sample_1203": ["def test_block_homomorphism():\n    # Test the block homomorphism function\n    from sympy.combinatorics.perm_groups import PermutationGroup\n    from sympy.combinatorics.named_groups import DihedralGroup\n\n    G = DihedralGroup(8)\n    blocks = [0, 1, 1, 2, 2, 3, 3, 0]\n    T = block_homomorphism(G, blocks)\n\n    assert T.domain == G\n    assert T.codomain.degree == 4\n    assert T.is_homomorphism()\n"], "sample_1205": ["def test_PolyElement_imul_num():\n    R, x, y = ring(\"x,y\", ZZ)\n\n    f = x + 2*y\n    g = f.imul_num(3)\n    assert g == 3*x + 6*y\n    assert g is f\n\n    f = x\n    g = f.imul_num(3)\n    assert g == 3*x\n    assert g is not f\n"], "sample_1208": ["def test_sample_numpy():\n    distribs_numpy = [\n        # Add distributions as they are implemented in SampleMatrixNumpy\n    ]\n\n    size = 5\n    numpy = import_module('numpy')\n    if not numpy:\n        skip('NumPy not installed. Abort tests for _sample_numpy.')\n    else:\n        for X in distribs_numpy:\n            samps = sample(X, size=size, library='numpy')\n            for sam in samps:\n                assert Matrix(sam) in X.pspace.distribution.set\n        M = MatrixGamma('M', 1, 2, [[1, 0], [0, 1]])\n        raises(NotImplementedError, lambda: sample(M, size=3, library='numpy'))\n"], "sample_219": ["    def test_window_frame_start_end(self):\n        frame = RowRange(start=5, end=10)\n        self.assertEqual(frame.window_frame_start_end(connection, 5, 10), ('ROWS 5 PRECEDING', 'ROWS 10 FOLLOWING'))\n        frame = ValueRange(start=None, end=0)\n        self.assertEqual(frame.window_frame_start_end(connection, None, 0), ('RANGE UNBOUNDED PRECEDING', 'RANGE CURRENT ROW'))\n"], "sample_10": ["def test_table_attribute_with_subclass():\n    class MyTable(Table):\n        foo = TableAttribute(default='bar')\n\n    class MySubTable(MyTable):\n        pass\n\n    t = MySubTable()\n    assert t.foo == 'bar'\n    t.foo = 'baz'\n    assert t.foo == 'baz'\n"], "sample_19": ["def test_wcs_pixel_shape():\n    w = wcs.WCS(naxis=2)\n    w._naxis = [1000, 500]\n    assert w.pixel_shape == (1000, 500)\n    assert w.array_shape == (500, 1000)\n\n    w.pixel_shape = (99, 59)\n    assert w._naxis == [99, 59]\n\n    w.array_shape = (45, 23)\n    assert w._naxis == [23, 45]\n    assert w.pixel_shape == (23, 45)\n\n    w.pixel_shape = None\n    assert w.pixel_bounds is None\n"], "sample_55": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n"], "sample_124": ["def test_field_deep_copy_widget(self):\n    class CustomCharField(CharField):\n            kwargs['widget'] = TextInput(attrs={'class': 'custom'})\n            super().__init__(**kwargs)\n\n    field = CustomCharField()\n    field_copy = copy.deepcopy(field)\n    self.assertIsInstance(field_copy, CustomCharField)\n    self.assertIsNot(field_copy.widget, field.widget)\n    self.assertEqual(field_copy.widget.attrs, field.widget.attrs)\n"], "sample_173": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_174": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_196": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_223": ["    def test_ticket_24863(self):\n        \"\"\"\n        When using select_related() and only(), we should only fetch the\n        columns needed for the model in the only() call.\n        \"\"\"\n        qs = Note.objects.select_related('extrainfo').only('note', 'extrainfo__info')\n        self.assertEqual(len(qs.query.select), 2)\n        self.assertEqual(len(qs.query.related_select_cols), 1)\n"], "sample_297": ["    def test_ticket_24863(self):\n        \"\"\"\n        Test that filtering on a subquery annotation works correctly.\n        \"\"\"\n        note = Note.objects.create(note='test')\n        annotation = Annotation.objects.create(note=note)\n        annotation2 = Annotation.objects.create(note=note)\n        qs = Annotation.objects.annotate(\n            has_note=Exists(\n                Note.objects.filter(\n                    annotation=OuterRef('pk'),\n                ),\n            ),\n        ).filter(has_note=True)\n        self.assertSequenceEqual(qs, [annotation, annotation2])\n"], "sample_311": ["    def test_custom_handler(self):\n        superuser = User.objects.create_superuser(\n            username='super',\n            password='secret',\n            email='super@example.com',\n        )\n        self.client.force_login(superuser)\n        unknown_url = '/test_admin/admin11/unknown/'\n        response = self.client.get(unknown_url)\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.content, b\"Django is a magical pony!\")\n"], "sample_319": ["def test_alter_field_with_choices(self):\n    \"\"\"Tests autodetection of altered fields with choices.\"\"\"\n    changes = self.get_changes(\n        [ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True)), (\"name\", models.CharField(max_length=200, choices=[(\"A\", \"A\"), (\"B\", \"B\")]))])],\n        [ModelState(\"testapp\", \"Author\", [(\"id\", models.AutoField(primary_key=True)), (\"name\", models.CharField(max_length=200, choices=[(\"A\", \"A\"), (\"C\", \"C\")]))])],\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n"], "sample_320": ["def test_references_field_by_through_fields(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ManyToManyField(\n            \"Other\",\n            through=\"Through\",\n            through_fields=(\"model_field\", \"other_field\"),\n        ),\n    )\n    self.assertIs(\n        operation.references_field(\"Through\", \"model_field\", \"migrations\"), True\n    )\n    self.assertIs(\n        operation.references_field(\"Through\", \"other_field\", \"migrations\"), True\n    )\n    self.assertIs(\n        operation.references_field(\"Through\", \"whatever\", \"migrations\"), False\n    )\n    self.assertIs(\n        operation.references_field(\"Missing\", \"whatever\", \"migrations\"), False\n    )\n"], "sample_394": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(\n            username=\"super\", password=\"secret\", email=\"super@example.com\"\n        )\n        cls.s1 = Section.objects.create(name=\"Test section\")\n        cls.a1 = Article.objects.create(\n            content=\"<p>Middle content</p>\",\n            date=datetime.datetime(2008, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.a2 = Article.objects.create(\n            content=\"<p>Oldest content</p>\",\n            date=datetime.datetime(2000, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.a3 = Article.objects.create(\n            content=\"<p>Newest content</p>\",\n            date=datetime.datetime(2009, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.p1 = PrePopulatedPost.objects.create(\n            title=\"A Long Title\", published=True, slug=\"a-long-title\"\n        )\n"], "sample_396": ["    def test_ticket_24748(self):\n        \"\"\"\n        Ensure that filtering on a subquery annotation doesn't crash.\n        \"\"\"\n        note = Note.objects.create(note=\"n1\", misc=\"foo\")\n        Annotation.objects.create(note=note, name=\"a1\")\n        Annotation.objects.create(note=note, name=\"a2\")\n        subquery = Annotation.objects.filter(note=OuterRef(\"pk\")).values(\"name\")\n        annotations = Note.objects.annotate(names=ArraySubquery(subquery)).filter(\n            names__contains=[\"a1\"]\n        )\n        self.assertEqual(annotations.count(), 1)\n"], "sample_400": ["def test_alter_model_options_with_custom_permissions(self):\n    \"\"\"Changing a model's options with custom permissions should make a change.\"\"\"\n    changes = self.get_changes(\n        [self.author_empty],\n        [\n            ModelState(\n                \"testapp\",\n                \"Author\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                ],\n                {\n                    \"permissions\": [\n                        (\"can_hire\", \"Can hire\"),\n                        (\"can_fire\", \"Can fire\"),\n                    ],\n                },\n            )\n        ],\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterModelOptions\"])\n    self.assertOperationAttributes(\n        changes,\n        \"testapp\",\n        0,\n        0,\n        options={\n            \"permissions\": [\n                (\"can_hire\", \"Can hire\"),\n                (\"can_fire\", \"Can fire\"),\n            ],\n        },\n    )\n"], "sample_403": ["def test_reduce_references_model(self):\n    operation = FieldOperation(\n        \"Model\", \"field\", models.ForeignKey(\"Other\", models.CASCADE)\n    )\n    other_operation = FieldOperation(\n        \"Other\", \"field\", models.BooleanField(default=False)\n    )\n    self.assertIs(operation.reduce(other_operation, \"migrations\"), [operation])\n    self.assertIs(other_operation.reduce(operation, \"migrations\"), [other_operation])\n"], "sample_405": ["def test_rename_index_with_expression(self):\n    app_label = \"test_rename_index_with_expression\"\n    project_state = self.apply_operations(\n        app_label,\n        ProjectState(),\n        operations=[\n            migrations.CreateModel(\n                \"Pony\",\n                fields=[\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\"weight\", models.FloatField()),\n                ],\n            ),\n            migrations.AddIndex(\n                \"Pony\",\n                models.Index(Abs(\"weight\"), name=\"weight_abs_idx\"),\n            ),\n        ],\n    )\n    self.assertIndexNameExists(f\"{app_label}_pony\", \"weight_abs_idx\")\n    operation = migrations.RenameIndex(\n        \"Pony\", new_name=\"new_weight_abs_idx\", old_name=\"weight_abs_idx\"\n    )\n    new_state = project_state.clone()\n    operation.state_forwards(app_label, new_state)\n    with connection.schema_editor() as editor:\n        operation.database_forwards(app_label, editor, project_state, new_state)\n    self.assertIndexNameNotExists(f\"{app_label}_pony\", \"weight_abs_idx\")\n    self.assertIndexNameExists(f\"{app_label}_pony\", \"new_weight_abs_idx\")\n    with connection.schema_editor() as editor:\n        operation.database_backwards(app_label, editor, new_state, project_state)\n    self.assertIndexNameExists(f\"{app_label}_pony\", \"weight_abs_idx\")\n    self.assertIndexNameNotExists(f\"{app_label}_pony\", \"new_weight_abs_idx\")\n"], "sample_408": ["def test_add_unique_constraint(self):\n    \"\"\"Test change detection of new unique constraints.\"\"\"\n    changes = self.get_changes(\n        [self.author_empty],\n        [\n            ModelState(\n                \"testapp\",\n                \"Author\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                ],\n                {\n                    \"constraints\": [\n                        models.UniqueConstraint(\n                            fields=[\"id\"], name=\"author_id_unique\"\n                        )\n                    ]\n                },\n            )\n        ],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AddConstraint\"])\n    added_constraint = models.UniqueConstraint(\n        fields=[\"id\"], name=\"author_id_unique\"\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, model_name=\"author\", constraint=added_constraint\n    )\n"], "sample_423": ["def test_alter_model_table_with_m2m(self):\n    \"\"\"\n    Tests when model and db_table changes, autodetector must create two\n    operations for a model with a ManyToManyField.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_with_m2m, self.publisher],\n        [\n            ModelState(\n                \"testapp\",\n                \"NewAuthor\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\n                        \"publishers\",\n                        models.ManyToManyField(\"testapp.Publisher\"),\n                    ),\n                ],\n            ),\n            self.publisher,\n        ],\n        MigrationQuestioner({\"ask_rename_model\": True}),\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(\n        changes, \"testapp\", 0, [\"RenameModel\", \"AlterModelTable\"]\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, old_name=\"Author\", new_name=\"NewAuthor\"\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 1, name=\"newauthor\", table=None\n    )\n"], "sample_424": ["def test_reduce_references_model(self):\n    operation = FieldOperation(\n        \"Model\", \"field\", models.ForeignKey(\"Other\", models.CASCADE)\n    )\n    other_operation = FieldOperation(\n        \"Other\", \"field\", models.BooleanField(default=False)\n    )\n    self.assertIs(operation.reduce(other_operation, \"migrations\"), False)\n    self.assertIs(other_operation.reduce(operation, \"migrations\"), True)\n"], "sample_430": ["def test_alter_model_table_with_index(self):\n    \"\"\"\n    Tests when model and db_table changes, autodetector must create two\n    operations and index should be created after AlterModelTable.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_with_db_table_options, self.book_indexes],\n        [\n            self.author_renamed_with_new_db_table_options,\n            ModelState(\n                \"otherapp\",\n                \"Book\",\n                [\n                    (\"id\", models.AutoField(primary_key=True)),\n                    (\n                        \"author\",\n                        models.ForeignKey(\n                            \"testapp.NewAuthor\", models.CASCADE, db_column=\"author_id\"\n                        ),\n                    ),\n                    (\"title\", models.CharField(max_length=200)),\n                ],\n                {\n                    \"indexes\": [\n                        models.Index(fields=[\"author\", \"title\"], name=\"book_title_author_idx\")\n                    ],\n                },\n            ),\n        ],\n        MigrationQuestioner({\"ask_rename_model\": True}),\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(\n        changes, \"testapp\", 0, [\"RenameModel\", \"AlterModelTable\"]\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, old_name=\"Author\", new_name=\"NewAuthor\"\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 1, name=\"newauthor\", table=\"author_three\"\n    )\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(\n        changes, \"otherapp\", 0, [\"AlterField\", \"AlterIndexTogether\", \"AddIndex\"]\n    )\n"], "sample_439": ["def test_media(self):\n    class CustomFrameworkForm(FrameworkForm):\n        class Media:\n            css = {\"all\": (\"path/to/css.css\",)}\n            js = (\"path/to/js.js\",)\n\n    f = CustomFrameworkForm()\n    self.assertEqual(\n        str(f.media),\n        '<link href=\"path/to/css.css\" media=\"all\" rel=\"stylesheet\">'\n        '<script src=\"path/to/js.js\"></script>',\n    )\n"], "sample_452": ["def test_references_field_by_through_fields(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ManyToManyField(\n            \"Other\",\n            through=\"Through\",\n            through_fields=(\"model_field\", \"other_field\"),\n        ),\n    )\n    self.assertIs(\n        operation.references_field(\"Through\", \"model_field\", \"migrations\"), True\n    )\n    self.assertIs(\n        operation.references_field(\"Through\", \"other_field\", \"migrations\"), True\n    )\n    self.assertIs(\n        operation.references_field(\"Through\", \"whatever\", \"migrations\"), False\n    )\n    self.assertIs(\n        operation.references_field(\"Missing\", \"whatever\", \"migrations\"), False\n    )\n"], "sample_460": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(\n            username=\"super\", password=\"secret\", email=\"super@example.com\"\n        )\n"], "sample_463": ["def test_alter_model_table_with_custom_database_table_name(self):\n    \"\"\"\n    Tests when model changes but db_table stays as-is, autodetector must not\n    create more than one operation.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_with_db_table_options],\n        [self.author_with_db_table_options],\n    )\n    # Right number/type of migrations?\n    self.assertEqual(len(changes), 0)\n"], "sample_491": ["def test_boundfield_get_context(self):\n    class FirstNameForm(Form):\n        first_name = CharField()\n\n    f = FirstNameForm()\n    context = f[\"first_name\"].get_context()\n    self.assertEqual(context[\"field\"], f[\"first_name\"])\n"], "sample_502": ["def test_subplot_mosaic():\n    fig, axes = plt.subplot_mosaic(\n        [['A', 'A', 'B'],\n         ['C', 'D', 'B']],\n        subplot_kw={'projection': 'polar'}\n    )\n    assert len(axes) == 4\n    for ax in axes.values():\n        assert ax.name == 'polar'\n    assert axes['A'] is axes['A']\n    assert axes['B'] is axes['B']\n    assert axes['C'] is axes['C']\n    assert axes['D'] is axes['D']\n    assert axes['A'] is not axes['B']\n    assert axes['A'] is not axes['C']\n    assert axes['A'] is not axes['D']\n    assert axes['B'] is not axes['C']\n    assert axes['B'] is not axes['D']\n    assert axes['C'] is not axes['D']\n"], "sample_536": ["def test_polygon_selector_box_handle_props(ax):\n    # Create a diamond shape\n    verts = [(20, 0), (0, 20), (20, 40), (40, 20)]\n    event_sequence = [\n        *polygon_place_vertex(*verts[0]),\n        *polygon_place_vertex(*verts[1]),\n        *polygon_place_vertex(*verts[2]),\n        *polygon_place_vertex(*verts[3]),\n        *polygon_place_vertex(*verts[0]),\n    ]\n\n    # Create selector\n    tool = widgets.PolygonSelector(ax, onselect=noop, draw_bounding_box=True,\n                                   box_handle_props={'color': 'r',\n                                                     'alpha': 0.5})\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n\n    for artist in tool._box._handles_artists:\n        assert artist.get_color() == 'r'\n        assert artist.get_alpha() == 0.5\n"], "sample_539": ["def test_polygon_selector_box_handle_props(ax):\n    # Create a diamond shape\n    verts = [(20, 0), (0, 20), (20, 40), (40, 20)]\n    event_sequence = [\n        *polygon_place_vertex(*verts[0]),\n        *polygon_place_vertex(*verts[1]),\n        *polygon_place_vertex(*verts[2]),\n        *polygon_place_vertex(*verts[3]),\n        *polygon_place_vertex(*verts[0]),\n    ]\n\n    # Create selector\n    tool = widgets.PolygonSelector(ax, onselect=noop, draw_bounding_box=True,\n                                   box_handle_props={'color': 'red',\n                                                    'alpha': 0.5})\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n\n    for artist in tool._box._handles_artists:\n        assert artist.get_color() == 'red'\n        assert artist.get_alpha() == 0.5\n\n    tool.set_handle_props(color='green', alpha=0.3)\n    for artist in tool._box._handles_artists:\n        assert artist.get_color() == 'green'\n        assert artist.get_alpha() == 0.3\n"], "sample_541": ["def test_polygon_selector_add_state(ax):\n    tool = widgets.PolygonSelector(ax, onselect=noop)\n    with pytest.raises(ValueError):\n        tool.add_state('unsupported_state')\n    with pytest.raises(ValueError):\n        tool.add_state('clear')\n    tool.add_state('move')\n    tool.add_state('square')\n    tool.add_state('center')\n"], "sample_543": ["def test_polygon_selector_box_handle_props(ax):\n    # Create a diamond shape\n    verts = [(20, 0), (0, 20), (20, 40), (40, 20)]\n    event_sequence = [\n        *polygon_place_vertex(*verts[0]),\n        *polygon_place_vertex(*verts[1]),\n        *polygon_place_vertex(*verts[2]),\n        *polygon_place_vertex(*verts[3]),\n        *polygon_place_vertex(*verts[0]),\n    ]\n\n    # Create selector\n    tool = widgets.PolygonSelector(ax, onselect=noop, draw_bounding_box=True,\n                                   box_handle_props={'color': 'r'})\n    for (etype, event_args) in event_sequence:\n        do_event(tool, etype, **event_args)\n\n    for artist in tool._box._handles_artists:\n        assert artist.get_color() == 'r'\n"], "sample_564": ["def test_mutating_input_arrays_x_and_y(fig_test, fig_ref):\n    \"\"\"\n    Test to see if the `x` and `y` axes do not get mutated\n    after a call to `Axes3D.plot`\n\n    test cases came from GH#8990\n    \"\"\"\n    ax1 = fig_test.add_subplot(111, projection='3d')\n    x = [0.0, 0.0, 0.0]\n    y = [0.0, 0.0, 0.0]\n    z = [1, 2, 3]\n    ax1.plot(x, y, z, 'o-')\n\n    # mutate x,y to get a nontrivial line\n    x[:] = [1, 2, 3]\n    y[:] = [1, 2, 3]\n\n    # draw the same plot without mutating x and y\n    ax2 = fig_ref.add_subplot(111, projection='3d')\n    x = [0.0, 0.0, 0.0]\n    y = [0.0, 0.0, 0.0]\n    z = [1, 2, 3]\n    ax2.plot(x, y, z, 'o-')\n"], "sample_720": ["def test_power_transformer_invalid_lambda():\n    pt = PowerTransformer(method='box-cox')\n    X = np.abs(X_2d)\n    pt.fit(X)\n\n    # An exception should be raised if PowerTransformer.lambdas_ isn't valid\n    pt.lambdas_ = np.array([0, 0, 0, 0, np.nan])\n    invalid_lambda_message = 'lambdas_ contains NaN or infinity'\n    assert_raise_message(ValueError, invalid_lambda_message,\n                         pt.transform, X)\n"], "sample_591": ["def test_merge_no_conflicts_multi_var(self):\n    data = create_test_data()\n    data1 = data.copy(deep=True)\n    data2 = data.copy(deep=True)\n\n    expected = data[[\"var1\", \"var2\"]]\n    actual = xr.merge([data1[[\"var1\"]], data2[[\"var2\"]]], compat=\"no_conflicts\")\n    assert expected.identical(actual)\n\n    data1[\"var1\"][:, :5] = np.nan\n    data2[\"var1\"][:, 5:] = np.nan\n    data1[\"var2\"][:4, :] = np.nan\n    data2[\"var2\"][4:, :] = np.nan\n    del data2[\"var3\"]\n\n    actual = xr.merge([data1, data2], compat=\"no_conflicts\")\n    assert data.equals(actual)\n"], "sample_559": ["def test_axes_divider_append_axes():\n    fig, ax = plt.subplots()\n    divider = make_axes_locatable(ax)\n    ax2 = divider.append_axes(\"top\", size=\"20%\", pad=\"10%\")\n    ax2.plot([1, 2, 3])\n    ax.plot([1, 2, 3])\n"], "sample_744": ["def test_power_transformer_invalid_lambda():\n    pt = PowerTransformer(method='box-cox')\n    X = np.abs(X_2d)\n    pt.fit(X)\n\n    # An exception should be raised if PowerTransformer.lambdas_ isn't valid\n    pt.lambdas_ = np.array([0, 1, 2, 3])  # wrong shape\n    bad_lambda_message = \"lambdas_ must be of shape\"\n    assert_raise_message(ValueError, bad_lambda_message,\n                         pt.transform, X)\n\n    pt.lambdas_ = np.array([np.nan, np.nan])  # contains NaN\n    bad_lambda_message = \"lambdas_ contains non-finite values\"\n    assert_raise_message(ValueError, bad_lambda_message,\n                         pt.transform, X)\n"], "sample_747": ["def test_power_transformer_sparse_matrix():\n    X_sparse = sparse.csr_matrix(np.abs(X_2d))\n    pt = PowerTransformer(method='box-cox')\n\n    assert_raises(TypeError, pt.fit, X_sparse)\n"], "sample_906": ["def test_domain_cpp_ast_fundamental_types():\n    # see https://en.cppreference.com/w/c/language/type\n    for t, id_v2 in cppDomain._id_fundamental_v2.items():\n            if t == 'decltype(auto)':\n                return None\n            id = t.replace(\" \", \"-\").replace(\"long\", \"l\")\n            if \"__int\" not in t:\n                id = id.replace(\"int\", \"i\")\n            id = id.replace(\"bool\", \"b\").replace(\"char\", \"c\")\n            id = id.replace(\"wc_t\", \"wchar_t\").replace(\"c16_t\", \"char16_t\")\n            id = id.replace(\"c8_t\", \"char8_t\")\n            id = id.replace(\"c32_t\", \"char32_t\")\n            return \"f__%s\" % id\n\n            id = id_v2\n            if t == \"std::nullptr_t\":\n                id = \"NSt9nullptr_tE\"\n            return \"1f%s\" % id\n        id1 = makeIdV1()\n        id2 = makeIdV2()\n        input = \"void f(%s arg)\" % t.replace(' ', '  ')\n        output = \"void f(%s arg)\" % t\n        check(\"function\", input, {1: id1, 2: id2}, output=output)\n        if ' ' in t:\n            # try permutations of all components\n            tcs = t.split()\n            for p in itertools.permutations(tcs):\n                input = \"void f(%s arg)\" % ' '.join(p)\n                check(\"function\", input, {1: id1, 2: id2})\n"], "sample_875": ["def test_balanced_accuracy_score_binary():\n    y_true = [0, 1, 0, 0, 1, 0, 1, 1]\n    y_pred = [0, 1, 0, 0, 1, 1, 0, 1]\n\n    # Calculate balanced accuracy manually\n    recall_0 = 3 / 4\n    recall_1 = 3 / 4\n    balanced_accuracy = (recall_0 + recall_1) / 2\n\n    assert balanced_accuracy_score(y_true, y_pred) == pytest.approx(balanced_accuracy)\n"], "sample_907": ["def test_domain_cpp_ast_template_parameter_pack():\n    check('function', 'template<typename... Ts> void f(Ts... ts)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts...)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts..., int i)',\n          {2: 'IDpE1fvDp1Ts1i'})\n    check('function', 'template<typename... Ts> void f(int i, Ts...)',\n          {2: 'IDpE1fv1iDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int i, Ts..., char c)',\n          {2: 'IDpE1fv1iDp1Ts1c'})\n    check('function', 'template<typename... Ts> void f(int i, Ts..., char c, double d)',\n          {2: 'IDpE1fv1iDp1Ts1c1d'})\n    check('function', 'template<typename... Ts> void f(int i, Ts..., char c, double d, ...)',\n          {2: 'IDpE1fv1iDp1Ts1c1dz'})\n    check('function', 'template<typename... Ts> void f(int i, Ts..., char c, double d, ...)',\n          {2: 'IDpE1fv1iDp1Ts1c1dz'})\n    check('function', 'template<typename... Ts> void f(int i, Ts..., char c, double d) = delete',\n          {2: 'IDpE1fv1iDp1Ts1c1d'})\n    check('function', 'template<typename... Ts> void f(int i, Ts..., char c, double d) = default',\n          {2: 'IDpE1fv1iDp1Ts1c1d'})\n    check('function', 'template<typename... Ts> void f(int i, Ts..., char c, double d);',\n          {2: 'IDpE1fv1iDp1Ts1c1d'})\n    check('function', 'template<typename... Ts> void f(int i, Ts..., char c, double d) const',\n          {2: 'IDpE1fv1iDp1Ts"], "sample_911": ["def test_template_parameter_pack():\n    check('class', 'template<typename... Ts> A', {2: 'IDpE1A'})\n    check('class', 'template<typename...> A', {2: 'IDpE1A'})\n    check('class', 'template<typename... Ts> A<Ts...>', {2: 'IDpE1AI2TsE'})\n    check('class', 'template<typename... Ts> A<Ts...>{}', {2: 'IDpE1AI2TsE'})\n    check('class', 'template<typename... Ts> A<Ts...>{};', {2: 'IDpE1AI2TsE'})\n    check('class', 'template<typename... Ts> A<Ts...>{} a;', {2: 'IDpE1AI2TsE'})\n    check('class', 'template<typename... Ts> A<Ts...>{} a{};', {2: 'IDpE1AI2TsE'})\n"], "sample_917": ["def test_template_parameter_pack():\n    check('class', 'template<typename... Ts> A', {2: 'IDpE1A'})\n    check('class', 'template<typename Ts...> A', {2: 'IDpE1A'})\n    check('class', 'template<typename...> A', {2: 'IDpE1A'})\n    check('class', 'template<int... Is> A', {2: 'I_DpiE1A'})\n    check('class', 'template<int Is...> A', {2: 'I_DpiE1A'})\n    check('class', 'template<int...> A', {2: 'I_DpiE1A'})\n    check('class', 'template<template<typename> typename... Ts> A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename Ts...> A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename...> A', {2: 'II0EDpE1A'})\n"], "sample_919": ["def test_template_parameter_pack():\n    check('function', 'template<typename... Ts> void f(Ts... ts)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts...)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts..., int)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int, Ts...)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int, Ts..., char)',\n          {2: 'IDpE1fvDp1Ts'})\n"], "sample_924": ["def test_template_parameter_pack():\n    check('function', 'template<typename... Ts> void f(Ts... ts)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts...)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts..., int i)',\n          {2: 'IDpE1fvDp1Tsii'})\n    check('function', 'template<typename... Ts> void f(int i, Ts...)',\n          {2: 'IDpE1fviDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int i, Ts..., char c)',\n          {2: 'IDpE1fviDp1Tsc'})\n    check('function', 'template<typename... Ts> void f(Ts..., int i, char c)',\n          {2: 'IDpE1fvDp1Tsiic'})\n    check('function', 'template<typename... Ts> void f(Ts..., int i, char c, Ts...)',\n          {2: 'IDpE1fvDp1TsiicDp1Ts'})\n"], "sample_927": ["def test_xref_consistency():\n    app = restructuredtext.App()\n    app.builder.build_all()\n\n    test = 'xref_consistency.html'\n    output = (app.outdir / test).read_text()\n\n        pattern = (r'{role}-role:.*?'\n                   r'<(?P<tag>{tag}) .*?class=[\"\\'](?P<classes>.*?)[\"\\'].*?>'\n                   r'.*'\n                   r'</(?P=tag)>').format(role=role, tag=tag)\n        result = re.search(pattern, output)\n        expect = '''\\"], "sample_932": ["def test_build_domain_cpp_template_introduction(app, status, warning):\n    app.builder.build_all()\n    ws = filter_warnings(warning, \"template-introduction\")\n    assert len(ws) == 0\n"], "sample_934": ["def test_build_domain_cpp_template_introduction(app, status, warning):\n    app.builder.build_all()\n    ws = filter_warnings(warning, \"template-introduction\")\n    assert len(ws) == 0\n"], "sample_948": ["def test_template_parameter_pack():\n    check('function', 'template<typename... Ts> void f(Ts... ts)',\n          {2: 'IDpE1fvDp1Ts'})\n    check('function', 'template<typename... Ts> void f(Ts... ts, int i)',\n          {2: 'IDpE1fvDp1TsIiE'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts)',\n          {2: 'IDpE1fvIiEDp1Ts'})\n    check('function', 'template<typename... Ts> void f(int i, Ts... ts, int j)',\n          {2: 'IDpE1fvIiEDp1TsIiE'})\n"], "sample_935": ["def test_build_domain_cpp_template_introduction(app, status, warning):\n    app.builder.build_all()\n    ws = filter_warnings(warning, \"template-introduction\")\n    assert len(ws) == 0\n"], "sample_959": ["def test_domain_cpp_ast_template_parameter_pack():\n    check('class', 'template<typename... Ts> {key}A', {2: 'IDpE1A'})\n    check('class', 'template<typename Ts> {key}A', {2: 'I0E1A'})\n    check('class', 'template<int... Is> {key}A', {2: 'I_DpiE1A'})\n    check('class', 'template<int I> {key}A', {2: 'I_iE1A'})\n    check('class', 'template<template<typename> typename... Ts> {key}A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename> typename T> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<typename...> typename... Ts> {key}A', {2: 'II0EDpE1A'})\n    check('class', 'template<template<typename...> typename T> {key}A', {2: 'II0E0E1A'})\n    check('class', 'template<template<int> typename... Ts> {key}A', {2: 'II_iEDpE1A'})\n    check('class', 'template<template<int> typename T> {key}A', {2: 'II_iE0E1A'})\n    check('class', 'template<template<int...> typename... Ts> {key}A', {2: 'II_DpiEDpE1A'})\n    check('class', 'template<template<int...> typename T> {key}A', {2: 'II_DpiE0E1A'})\n"], "sample_994": ["def test_mod_inverse_large():\n    p = 1000000007\n    a = 123456789\n    assert mod_inverse(a, p) * a % p == 1\n"], "sample_958": ["def test_domain_cpp_ast_fundamental_types():\n    # see https://en.cppreference.com/w/c/language/type\n    for t, id_v2 in cppDomain._id_fundamental_v2.items():\n            if t == 'decltype(auto)':\n                return None\n            id = t.replace(\" \", \"-\").replace(\"long\", \"l\")\n            if \"__int\" not in t:\n                id = id.replace(\"int\", \"i\")\n            id = id.replace(\"bool\", \"b\").replace(\"char\", \"c\")\n            id = id.replace(\"wc_t\", \"wchar_t\").replace(\"c16_t\", \"char16_t\")\n            id = id.replace(\"c8_t\", \"char8_t\")\n            id = id.replace(\"c32_t\", \"char32_t\")\n            return \"f__%s\" % id\n\n            id = id_v2\n            if t == \"std::nullptr_t\":\n                id = \"NSt9nullptr_tE\"\n            return \"1f%s\" % id\n        input = \"void f(%s arg)\" % t.replace(' ', '  ')\n        output = \"void f(%s arg)\" % t\n        check(\"function\", input, {1: makeIdV1(), 2: makeIdV2()}, output=output)\n"], "sample_995": ["def test_mod_inverse_nonint():\n    assert mod_inverse(2, Rational(3, 2)) == Rational(3, 4)\n    assert mod_inverse(2, Rational(5, 2)) == Rational(5, 4)\n    assert mod_inverse(3, Rational(5, 2)) == Rational(5, 6)\n    assert mod_inverse(3, Rational(7, 2)) == Rational(7, 6)\n    assert mod_inverse(Rational(1, 2), Rational(3, 2)) == Rational(3, 1)\n    assert mod_inverse(Rational(1, 2), Rational(5, 2)) == Rational(5, 1)\n    assert mod_inverse(Rational(2, 3), Rational(5, 2)) == Rational(15, 4)\n    assert mod_inverse(Rational(2, 3), Rational(7, 2)) == Rational(21, 4)\n"], "sample_1002": ["def test_mod_inverse_with_Mod():\n    assert mod_inverse(3, Mod(11, 7)) == 4\n    assert mod_inverse(5, Mod(11, 7)) == 9\n    assert mod_inverse(21124921, Mod(521512, 7)) == 7713\n    assert mod_inverse(124215421, Mod(5125, 7)) == 2981\n    assert mod_inverse(214, Mod(12515, 7)) == 1579\n    assert mod_inverse(5823991, Mod(3299, 7)) == 1442\n    assert mod_inverse(123, Mod(44, 7)) == 39\n    assert mod_inverse(2, Mod(5, 7)) == 3\n    assert mod_inverse(-2, Mod(5, 7)) == 2\n    assert mod_inverse(2, Mod(-5, 7)) == -2\n    assert mod_inverse(-2, Mod(-5, 7)) == -3\n    assert mod_inverse(-3, Mod(-7, 7)) == -5\n    x = Symbol('x')\n    assert S(2).invert(x) == S.Half\n    raises(TypeError, lambda: mod_inverse(2, x))\n    raises(ValueError, lambda: mod_inverse(2, S.Half))\n    raises(ValueError, lambda: mod_inverse(2, cos(1)**2 + sin(1)**2))\n"], "sample_1010": ["def test_latex_MatPow():\n    from sympy import MatrixSymbol\n    A = MatrixSymbol(\"A\", 3, 3)\n    assert latex(A**3) == r\"A^{3}\"\n    assert latex(A**-1) == r\"A^{-1}\"\n    assert latex(A**0) == r\"A^{0}\"\n"], "sample_1005": ["def test_latex_FreeModuleElement():\n    from sympy.polys.domains import QQ\n    R = QQ.old_poly_ring(x, y)\n    F = R.free_module(2)\n    e = F((x, 2*y))\n    assert latex(e) == r'\\left[x, \\  2 y\\right]'\n"], "sample_1045": ["def test_issue_21457():\n    assert Integer(1).invert(1) == 1\n    assert Integer(1).invert(-1) == -1\n    assert Integer(-1).invert(1) == -1\n    assert Integer(-1).invert(-1) == 1\n    assert Integer(2).invert(3) == 2\n    assert Integer(2).invert(-3) == -2\n    assert Integer(-2).invert(3) == -2\n    assert Integer(-2).invert(-3) == 2\n"], "sample_1024": ["def test_Float_precision_conversion():\n    assert Float('1.0', dps=15)._prec == 53\n    assert Float('1.0', precision=15)._prec == 15\n    assert Float('1.0', dps='15')._prec == 53\n    assert Float('1.0', precision='15')._prec == 15\n    raises(ValueError, lambda: Float('1.0', dps='a'))\n    raises(ValueError, lambda: Float('1.0', precision='a'))\n"], "sample_1027": ["def test_issue_12585():\n    # Test for this issue:\n    # https://github.com/sympy/sympy/issues/12585\n    f = Poly(x**2 + 2*x + 1, x)\n    g = Poly(x**2 + 2*x + 2, x)\n    assert f.div(g) == (Poly(1, x), Poly(-1, x))\n"], "sample_1046": ["def test_tensor_element():\n    Lorentz = TensorIndexType('Lorentz', dummy_fmt='L')\n    i, j, k, l = tensor_indices('i,j,k,l', Lorentz)\n    A = tensorhead('A', [Lorentz]*2, [[1]*2])\n\n    te = TensorElement(A(i, j), {i: 1})\n    assert te.get_free_indices() == [j]\n    assert te.get_indices() == [j]\n\n    te = TensorElement(A(i, j), {j: 1})\n    assert te.get_free_indices() == [i]\n    assert te.get_indices() == [i]\n\n    te = TensorElement(A(i, j), {i: 1, j: 1})\n    assert te.get_free_indices() == []\n    assert te.get_indices() == []\n\n    te = TensorElement(A(i, j), {})\n    assert te.get_free_indices() == [i, j]\n    assert te.get_indices() == [i, j]\n"], "sample_1053": ["def test_issue_16460():\n    assert Integer(1).invert(1) == 1\n    assert Integer(1).invert(-1) == -1\n    assert Integer(-1).invert(1) == -1\n    assert Integer(-1).invert(-1) == 1\n    assert Integer(2).invert(3) == 2\n    assert Integer(2).invert(-3) == -2\n    assert Integer(-2).invert(3) == -2\n    assert Integer(-2).invert(-3) == 2\n"], "sample_1059": ["def test_assoc_laguerre():\n    n = Symbol(\"n\")\n    m = Symbol(\"m\", negative=True)\n    a = Symbol(\"a\")\n\n    # Generalized Laguerre polynomials:\n    assert assoc_laguerre(0, a, x) == 1\n    assert assoc_laguerre(1, a, x) == a - x + 1\n    assert assoc_laguerre(2, a, x) == a**2/2 + 3*a/2 + x**2/2 + x*(-a - 2) + 1\n    assert assoc_laguerre(3, a, x) == a**3/6 + a**2 + 11*a/6 - x**3/6 + x**2*(a/2 + 3/2) + x*(-a**2/2 - 5*a/2 - 3) + 1\n\n    X = assoc_laguerre(n, a, x)\n    assert isinstance(X, assoc_laguerre)\n\n    assert assoc_laguerre(n, 0, x) == laguerre(n, x)\n    assert assoc_laguerre(n, a, 0) == binomial(a + n, a)\n\n    assert assoc_laguerre(n, a, oo) == (-1)**n*oo\n    assert assoc_laguerre(n, a, -oo) == oo\n\n    assert conjugate(assoc_laguerre(n, a, x)) == assoc_laguerre(n, conjugate(a), conjugate(x))\n\n    _k = Dummy('k')\n\n    assert assoc_laguerre(n, a, x).rewrite(\"polynomial\").dummy_eq(\n        gamma(a + n + 1)/factorial(n)*Sum((-1)**_k*x**_k*RisingFactorial(-n, _k)/\n        (gamma(_k + a + 1)*factorial(_k)), (_k, 0, n)))\n\n    assert diff(assoc_laguerre(n, a, x), x) == -assoc_laguerre(n - 1, a + 1, x)\n\n    k = Symbol('k')\n    assert assoc_laguerre(-n, a, x) == exp(x)*assoc_laguerre(n - 1, -a, -x)\n    assert assoc_laguerre"], "sample_1085": ["def test_issue_16196():\n    assert unchanged(Integer, 1)\n    assert unchanged(Rational, 1)\n    assert unchanged(Float, 1.0)\n"], "sample_1074": ["def test_polycyclic_group():\n    G = AlternatingGroup(4)\n    P = G.polycyclic_group()\n    assert is_isomorphic(P, G)\n"], "sample_1090": ["def test_rational():\n    with evaluate(False):\n        p = S(3) / 2\n        assert isinstance(p, Mul) and p.args == (S(3), S.One / 2)\n        p = S(2) / 3\n        assert isinstance(p, Mul) and p.args == (S(2), S.One / 3)\n        p = S(3) / 2 + 1\n        assert isinstance(p, Add) and p.args == (S(3) / 2, 1)\n        p = 1 + S(3) / 2\n        assert isinstance(p, Add) and p.args == (1, S(3) / 2)\n        p = S(3) / 2 - 1\n        assert isinstance(p, Add) and p.args == (S(3) / 2, -1)\n        p = 1 - S(3) / 2\n        assert isinstance(p, Add) and p.args == (1, -S(3) / 2)\n        p = S(3) / 2 * 2\n        assert isinstance(p, Mul) and p.args == (S(3) / 2, 2)\n        p = 2 * S(3) / 2\n        assert isinstance(p, Mul) and p.args == (2, S(3) / 2)\n        p = S(3) / 2 / 2\n        assert isinstance(p, Mul) and p.args == (S(3) / 2, S.One / 2)\n        p = 2 / (S(3) / 2)\n        assert isinstance(p, Mul) and p.args == (2, 2 / S(3))\n"], "sample_1102": ["def test_issue_18464():\n    x = Symbol('x')\n    p = Poly(x**2 + 1, x)\n    assert p.as_expr().coeff(x) == 0\n    assert p.as_expr().coeff(x, 0) == 1\n    assert p.as_expr().coeff(x, 1) == 0\n    assert p.as_expr().coeff(x, 2) == 1\n"], "sample_1115": ["def test_tensor_element():\n    L = TensorIndexType(\"L\", dim=4)\n    i, j, k, l = tensor_indices(\"i j k l\", L)\n    A = TensorHead(\"A\", [L]*4)\n    te = TensorElement(A(i, j, k, l), {i: 2})\n    assert te.get_free_indices() == [j, k, l]\n    assert te.get_indices() == [j, k, l]\n    assert te.free == [(j, 1), (k, 2), (l, 3)]\n    assert te.dum == []\n    assert te.coeff == 1\n    assert te.nocoeff == te\n    assert te.get_free_indices() == [j, k, l]\n    assert te._replace_indices({j: k, k: l, l: j}) == TensorElement(A(i, k, l, j), {i: 2})\n    assert te._extract_data({A(i, j, k, l): Array([[[[1, 2], [3, 4]], [[5, 6], [7, 8]]], [[[9, 10], [11, 12]], [[13, 14], [15, 16]]]])}) == ([j, k, l], Array([[[5, 6], [7, 8]], [[13, 14], [15, 16]]]))\n"], "sample_1136": ["def test_issue_20427():\n    f = Poly(-117968192370600*18**(S(1)/3)/(217603955769048*(24201 +\n        253*sqrt(9165))**(S(1)/3) + 2273005839412*sqrt(9165)*(24201 +\n        253*sqrt(9165))**(S(1)/3)) - 15720318185*2**(S(2)/3)*3**(S(1)/3)*(24201\n        + 253*sqrt(9165))**(S(2)/3)/(217603955769048*(24201 + 253*sqrt(9165))**\n        (S(1)/3) + 2273005839412*sqrt(9165)*(24201 + 253*sqrt(9165))**(S(1)/3))\n        + 15720318185*12**(S(1)/3)*(24201 + 253*sqrt(9165))**(S(2)/3)/(\n        217603955769048*(24201 + 253*sqrt(9165))**(S(1)/3) + 2273005839412*\n        sqrt(9165)*(24201 + 253*sqrt(9165))**(S(1)/3)) + 117968192370600*2**(\n        S(1)/3)*3**(S(2)/3)/(217603955769048*(24201 + 253*sqrt(9165))**(S(1)/3)\n        + 2273005839412*sqrt(9165)*(24201 + 253*sqrt(9165))**(S(1)/3)), x)\n    assert f == Poly(0, x, domain='EX')\n"], "sample_1127": ["def test_is_alternating():\n    a = Permutation(0, 1, 2)\n    b = Permutation(0, 1, size=3)\n    assert PermutationGroup(a, b).is_alternating == True\n\n    a = Permutation(0, 2, 1)\n    b = Permutation(1, 2, size=3)\n    assert PermutationGroup(a, b).is_alternating == True\n\n    a = Permutation(0, 1, 2, 3)\n    b = Permutation(0, 3)(1, 2)\n    assert PermutationGroup(a, b).is_alternating == False\n"], "sample_1134": ["def test_latex_decimal_separator_in_Rational():\n    assert latex(Rational(1, 2), decimal_separator='comma') == r'\\frac{1}{2}'\n    assert latex(Rational(1, 2), decimal_separator='period') == r'\\frac{1}{2}'\n    assert latex(Rational(1, 2).evalf(), decimal_separator='comma') == r'0{,}5'\n    assert latex(Rational(1, 2).evalf(), decimal_separator='period') == r'0.5'\n"], "sample_1146": ["def test_latex_decimal_separator_with_parenthesize_super():\n    x_star = Symbol('x^*')\n    f = Function('f')\n    assert latex(x_star**2, decimal_separator='comma', parenthesize_super=False) == r\"{x^{*}}^{2}\"\n    assert latex(x_star**2, decimal_separator='comma', parenthesize_super=True) == r\"\\left(x^{*}\\right)^{2}\"\n    assert latex(Derivative(f(x_star), x_star,2), decimal_separator='comma', parenthesize_super=False) == r\"\\frac{d^{2}}{d {x^{*}}^{2}} f{\\left(x^{*} \\right)}\"\n    assert latex(Derivative(f(x_star), x_star,2), decimal_separator='comma', parenthesize_super=True) == r\"\\frac{d^{2}}{d \\left(x^{*}\\right)^{2}} f{\\left(x^{*} \\right)}\"\n"], "sample_1140": ["def test_pretty_RandomDomain():\n    from sympy.stats import Normal, Die, Exponential, pspace, where\n    X = Normal('x1', 0, 1)\n    assert upretty(where(X > 0)) == \"Domain: 0 < x\u2081 \u2227 x\u2081 < \u221e\"\n\n    D = Die('d1', 6)\n    assert upretty(where(D > 4)) == 'Domain: d\u2081 = 5 \u2228 d\u2081 = 6'\n\n    A = Exponential('a', 1)\n    B = Exponential('b', 1)\n    assert upretty(pspace(Tuple(A, B)).domain) == \\\n        'Domain: 0 \u2264 a \u2227 0 \u2264 b \u2227 a < \u221e \u2227 b < \u221e'\n"], "sample_1143": ["def test_issue_20796():\n    assert (S(0.0) == S.false) is False\n    assert (S.false == S(0.0)) is False\n    assert (S(0) == S.false) is False\n    assert (S.false == S(0)) is False\n"], "sample_1147": ["def test_latex_decimal_separator_with_parenthesize_super():\n    x_star = Symbol('x^*')\n    f = Function('f')\n    assert latex(Derivative(f(x_star), x_star,2), decimal_separator='comma') == r'\\frac{d^{2}}{d \\left(x^{*}\\right)^{2}} f{\\left(x^{*} \\right)}'\n    assert latex(Derivative(f(x_star), x_star,2), decimal_separator='comma', parenthesize_super=False) == r'\\frac{d^{2}}{d {x^{*}}^{2}} f{\\left(x^{*} \\right)}'\n"], "sample_1167": ["def test_latex_decimal_separator_in_limits():\n    x, y, z, t = symbols('x y z t')\n    k, m, n = symbols('k m n', integer=True)\n    f, g, h = symbols('f g h', cls=Function)\n\n    assert(latex(Integral(x, (x, 1.2, 3.4)), decimal_separator='comma') == r'\\int_{1{,}2}^{3{,}4} x\\, dx')\n    assert(latex(Sum(x, (x, 1.2, 3.4)), decimal_separator='comma') == r'\\sum_{x=1{,}2}^{3{,}4} x')\n    assert(latex(Product(x, (x, 1.2, 3.4)), decimal_separator='comma') == r'\\prod_{x=1{,}2}^{3{,}4} x')\n"], "sample_1176": ["def test_issue_20796():\n    assert (S(0.0) == S.false) is False\n    assert (S.false == S(0.0)) is False\n    assert (S(0) == S.false) is False\n    assert (S.false == S(0)) is False\n"], "sample_1175": ["def test_pretty_Heaviside():\n    assert pretty(Heaviside(x)) == 'Heaviside(x)'\n    assert upretty(Heaviside(x)) == '\u03b8(x)'\n    assert pretty(Heaviside(x, y)) == 'Heaviside(x, y)'\n    assert upretty(Heaviside(x, y)) == '\u03b8(x, y)'\n"], "sample_1206": ["def test_issue_21495():\n    assert Integer(1)._eval_nseries(x, n=3, logx=t) == 1\n    assert Integer(2)._eval_nseries(x, n=3, logx=t) == 2\n    assert Integer(0)._eval_nseries(x, n=3, logx=t) == 0\n    assert Integer(-1)._eval_nseries(x, n=3, logx=t) == -1\n    assert Integer(-2)._eval_nseries(x, n=3, logx=t) == -2\n"], "sample_1202": ["def test_issue_22373():\n    assert unchanged(Integer, 1)\n    assert unchanged(Rational, 1, 2)\n    assert unchanged(Float, 1.0)\n    assert unchanged(AlgebraicNumber, sqrt(2))\n"], "sample_1204": ["def test_symmetric_permutation_group():\n    G = SymmetricPermutationGroup(4)\n    assert G.degree == 4\n    assert G.order() == 24\n    assert G.identity == Permutation(3)\n    assert G.is_abelian is False\n    assert G.is_symmetric is True\n    assert G.is_alternating is False\n    assert G.is_transitive() is True\n    assert G.is_primitive() is True\n    assert G.is_nilpotent is False\n    assert G.is_solvable is False\n    assert G.is_polycyclic is False\n    assert G.is_perfect is True\n    assert G.is_cyclic is False\n    assert G.is_dihedral is False\n    assert G.is_elementary(2) is False\n"]}, "raw_scored_generations": {"sample_1": [false], "sample_0": [false], "sample_3": [true], "sample_2": [true], "sample_4": [false], "sample_5": [false], "sample_6": [false], "sample_7": [false], "sample_8": [true], "sample_9": [false], "sample_10": [true], "sample_11": [false], "sample_12": [false], "sample_13": [false], "sample_14": [false], "sample_15": [true], "sample_16": [false], "sample_17": [false], "sample_18": [false], "sample_19": [true], "sample_20": [false], "sample_21": [false], "sample_22": [false], "sample_23": [true], "sample_24": [false], "sample_25": [false], "sample_26": [false], "sample_27": [true], "sample_28": [false], "sample_29": [false], "sample_30": [false], "sample_31": [false], "sample_32": [false], "sample_33": [false], "sample_34": [true], "sample_35": [false], "sample_36": [false], "sample_37": [false], "sample_38": [false], "sample_39": [true], "sample_40": [false], "sample_41": [false], "sample_42": [false], "sample_43": [true], "sample_44": [false], "sample_45": [false], "sample_46": [false], "sample_47": [true], "sample_48": [true], "sample_49": [true], "sample_50": [false], "sample_51": [true], "sample_52": [true], "sample_54": [true], "sample_53": [true], "sample_55": [false], "sample_58": [true], "sample_56": [true], "sample_57": [true], "sample_59": [true], "sample_60": [false], "sample_61": [true], "sample_62": [false], "sample_63": [true], "sample_64": [true], "sample_65": [true], "sample_67": [false], "sample_66": [true], "sample_68": [true], "sample_69": [false], "sample_70": [true], "sample_71": [true], "sample_72": [false], "sample_73": [false], "sample_75": [false], "sample_74": [false], "sample_76": [true], "sample_77": [true], "sample_78": [true], "sample_79": [false], "sample_80": [true], "sample_82": [true], "sample_81": [false], "sample_83": [false], "sample_85": [true], "sample_84": [false], "sample_86": [true], "sample_88": [true], "sample_87": [false], "sample_89": [false], "sample_90": [false], "sample_91": [true], "sample_92": [false], "sample_93": [true], "sample_94": [true], "sample_95": [false], "sample_98": [false], "sample_96": [false], "sample_99": [false], "sample_97": [false], "sample_100": [false], "sample_102": [true], "sample_101": [true], "sample_103": [true], "sample_104": [false], "sample_107": [true], "sample_106": [false], "sample_105": [false], "sample_108": [false], "sample_109": [true], "sample_111": [true], "sample_110": [false], "sample_112": [true], "sample_113": [true], "sample_114": [true], "sample_115": [true], "sample_116": [true], "sample_117": [true], "sample_118": [true], "sample_119": [true], "sample_120": [false], "sample_121": [true], "sample_122": [false], "sample_123": [false], "sample_124": [true], "sample_125": [false], "sample_126": [true], "sample_127": [true], "sample_128": [true], "sample_129": [false], "sample_130": [true], "sample_131": [false], "sample_132": [true], "sample_133": [true], "sample_135": [true], "sample_134": [false], "sample_136": [true], "sample_139": [true], "sample_137": [true], "sample_138": [false], "sample_140": [false], "sample_141": [false], "sample_142": [true], "sample_143": [true], "sample_144": [true], "sample_145": [true], "sample_146": [true], "sample_147": [true], "sample_148": [true], "sample_151": [true], "sample_149": [true], "sample_152": [true], "sample_150": [false], "sample_153": [false], "sample_154": [true], "sample_155": [true], "sample_156": [true], "sample_157": [true], "sample_158": [true], "sample_159": [true], "sample_160": [true], "sample_161": [false], "sample_162": [true], "sample_163": [true], "sample_164": [false], "sample_165": [false], "sample_166": [true], "sample_167": [false], "sample_168": [true], "sample_169": [true], "sample_171": [true], "sample_170": [true], "sample_172": [true], "sample_173": [false], "sample_174": [false], "sample_175": [true], "sample_176": [true], "sample_177": [true], "sample_178": [true], "sample_180": [true], "sample_179": [true], "sample_182": [true], "sample_181": [true], "sample_183": [false], "sample_184": [true], "sample_185": [false], "sample_186": [true], "sample_187": [true], "sample_188": [false], "sample_189": [false], "sample_190": [true], "sample_191": [false], "sample_192": [true], "sample_193": [true], "sample_194": [true], "sample_195": [true], "sample_196": [false], "sample_198": [false], "sample_197": [true], "sample_199": [true], "sample_200": [true], "sample_201": [true], "sample_202": [true], "sample_203": [true], "sample_204": [false], "sample_205": [true], "sample_206": [true], "sample_207": [false], "sample_208": [true], "sample_209": [false], "sample_210": [false], "sample_211": [false], "sample_213": [false], "sample_212": [false], "sample_214": [false], "sample_215": [false], "sample_216": [true], "sample_217": [true], "sample_218": [false], "sample_219": [false], "sample_220": [true], "sample_221": [true], "sample_222": [false], "sample_223": [false], "sample_224": [true], "sample_225": [false], "sample_226": [true], "sample_227": [true], "sample_228": [true], "sample_229": [true], "sample_230": [true], "sample_231": [false], "sample_232": [false], "sample_233": [true], "sample_234": [true], "sample_235": [true], "sample_236": [true], "sample_237": [true], "sample_238": [true], "sample_239": [true], "sample_240": [true], "sample_241": [false], "sample_242": [true], "sample_243": [true], "sample_244": [true], "sample_245": [true], "sample_246": [true], "sample_247": [true], "sample_248": [true], "sample_249": [false], "sample_250": [true], "sample_251": [true], "sample_252": [false], "sample_253": [false], "sample_254": [false], "sample_256": [true], "sample_255": [true], "sample_257": [false], "sample_258": [false], "sample_259": [true], "sample_260": [true], "sample_261": [true], "sample_262": [false], "sample_263": [true], "sample_264": [true], "sample_265": [true], "sample_266": [true], "sample_267": [false], "sample_268": [false], "sample_269": [true], "sample_270": [true], "sample_271": [false], "sample_272": [true], "sample_273": [false], "sample_274": [false], "sample_275": [false], "sample_276": [true], "sample_277": [true], "sample_278": [false], "sample_279": [true], "sample_280": [true], "sample_281": [true], "sample_282": [true], "sample_283": [true], "sample_284": [false], "sample_285": [true], "sample_286": [false], "sample_287": [true], "sample_288": [false], "sample_289": [true], "sample_290": [true], "sample_291": [true], "sample_292": [true], "sample_293": [false], "sample_294": [true], "sample_295": [false], "sample_296": [true], "sample_297": [false], "sample_298": [true], "sample_299": [true], "sample_300": [true], "sample_301": [false], "sample_302": [false], "sample_303": [true], "sample_304": [true], "sample_305": [true], "sample_306": [true], "sample_307": [true], "sample_308": [true], "sample_309": [false], "sample_310": [true], "sample_312": [true], "sample_311": [false], "sample_313": [true], "sample_314": [true], "sample_315": [true], "sample_316": [true], "sample_317": [true], "sample_318": [false], "sample_319": [true], "sample_320": [true], "sample_321": [true], "sample_322": [true], "sample_323": [true], "sample_324": [true], "sample_325": [true], "sample_326": [true], "sample_327": [true], "sample_328": [true], "sample_329": [false], "sample_330": [false], "sample_331": [true], "sample_332": [true], "sample_333": [true], "sample_334": [true], "sample_335": [true], "sample_336": [false], "sample_337": [true], "sample_338": [true], "sample_339": [false], "sample_340": [false], "sample_341": [true], "sample_342": [true], "sample_343": [true], "sample_344": [true], "sample_345": [false], "sample_346": [false], "sample_347": [true], "sample_348": [false], "sample_349": [true], "sample_350": [true], "sample_351": [true], "sample_352": [false], "sample_353": [false], "sample_354": [false], "sample_355": [false], "sample_356": [false], "sample_357": [true], "sample_358": [false], "sample_359": [true], "sample_360": [false], "sample_361": [true], "sample_362": [true], "sample_363": [true], "sample_364": [false], "sample_365": [false], "sample_366": [true], "sample_367": [false], "sample_368": [true], "sample_369": [true], "sample_370": [false], "sample_371": [false], "sample_372": [false], "sample_373": [true], "sample_374": [false], "sample_375": [true], "sample_376": [true], "sample_377": [true], "sample_378": [true], "sample_379": [true], "sample_380": [true], "sample_381": [true], "sample_382": [true], "sample_383": [true], "sample_384": [true], "sample_385": [true], "sample_386": [true], "sample_387": [true], "sample_388": [false], "sample_389": [true], "sample_390": [true], "sample_391": [true], "sample_392": [false], "sample_393": [true], "sample_394": [false], "sample_395": [true], "sample_396": [false], "sample_397": [true], "sample_398": [false], "sample_399": [true], "sample_400": [true], "sample_401": [true], "sample_402": [true], "sample_403": [true], "sample_404": [true], "sample_405": [true], "sample_406": [false], "sample_407": [true], "sample_408": [true], "sample_409": [true], "sample_410": [true], "sample_411": [true], "sample_412": [true], "sample_413": [false], "sample_414": [true], "sample_415": [true], "sample_416": [true], "sample_417": [false], "sample_418": [true], "sample_419": [true], "sample_420": [false], "sample_421": [false], "sample_422": [false], "sample_423": [true], "sample_424": [true], "sample_425": [true], "sample_426": [true], "sample_427": [true], "sample_428": [false], "sample_429": [true], "sample_430": [true], "sample_431": [false], "sample_432": [true], "sample_433": [true], "sample_434": [false], "sample_435": [false], "sample_436": [true], "sample_437": [false], "sample_438": [true], "sample_439": [true], "sample_440": [false], "sample_441": [false], "sample_442": [true], "sample_443": [false], "sample_444": [false], "sample_445": [true], "sample_446": [false], "sample_447": [true], "sample_448": [true], "sample_449": [false], "sample_450": [true], "sample_451": [true], "sample_453": [true], "sample_452": [true], "sample_454": [false], "sample_455": [true], "sample_456": [true], "sample_457": [true], "sample_458": [false], "sample_459": [false], "sample_460": [false], "sample_461": [true], "sample_462": [true], "sample_463": [true], "sample_464": [true], "sample_465": [true], "sample_466": [false], "sample_467": [true], "sample_469": [true], "sample_468": [true], "sample_470": [false], "sample_471": [true], "sample_472": [true], "sample_473": [false], "sample_474": [false], "sample_475": [true], "sample_476": [false], "sample_477": [true], "sample_478": [true], "sample_479": [true], "sample_480": [true], "sample_481": [false], "sample_482": [false], "sample_483": [true], "sample_484": [false], "sample_485": [true], "sample_486": [true], "sample_487": [true], "sample_488": [true], "sample_489": [true], "sample_490": [true], "sample_491": [true], "sample_492": [false], "sample_493": [true], "sample_494": [true], "sample_495": [true], "sample_496": [false], "sample_497": [false], "sample_498": [false], "sample_499": [false], "sample_500": [true], "sample_501": [false], "sample_502": [true], "sample_503": [false], "sample_504": [false], "sample_505": [false], "sample_506": [false], "sample_507": [true], "sample_508": [true], "sample_509": [false], "sample_510": [false], "sample_511": [true], "sample_512": [true], "sample_513": [false], "sample_514": [false], "sample_515": [false], "sample_516": [true], "sample_517": [false], "sample_518": [true], "sample_519": [false], "sample_520": [false], "sample_521": [false], "sample_522": [true], "sample_523": [true], "sample_524": [true], "sample_525": [false], "sample_526": [false], "sample_527": [true], "sample_528": [true], "sample_529": [true], "sample_530": [false], "sample_531": [false], "sample_532": [true], "sample_533": [false], "sample_534": [false], "sample_535": [false], "sample_536": [false], "sample_537": [false], "sample_538": [false], "sample_539": [false], "sample_540": [true], "sample_541": [false], "sample_542": [true], "sample_543": [false], "sample_544": [false], "sample_545": [false], "sample_546": [true], "sample_547": [false], "sample_548": [true], "sample_549": [false], "sample_550": [false], "sample_551": [true], "sample_552": [false], "sample_553": [false], "sample_554": [true], "sample_555": [false], "sample_556": [false], "sample_557": [false], "sample_558": [true], "sample_559": [false], "sample_560": [false], "sample_561": [true], "sample_562": [false], "sample_563": [true], "sample_564": [false], "sample_565": [false], "sample_566": [false], "sample_567": [true], "sample_568": [false], "sample_569": [false], "sample_570": [false], "sample_571": [false], "sample_572": [true], "sample_573": [false], "sample_574": [false], "sample_575": [true], "sample_576": [false], "sample_577": [false], "sample_578": [false], "sample_579": [false], "sample_580": [false], "sample_581": [false], "sample_582": [false], "sample_583": [false], "sample_584": [false], "sample_585": [false], "sample_586": [false], "sample_587": [false], "sample_588": [false], "sample_589": [false], "sample_590": [false], "sample_591": [false], "sample_592": [false], "sample_593": [false], "sample_594": [false], "sample_595": [false], "sample_596": [false], "sample_597": [false], "sample_598": [false], "sample_599": [false], "sample_600": [false], "sample_601": [false], "sample_602": [false], "sample_603": [false], "sample_604": [false], "sample_605": [true], "sample_606": [false], "sample_607": [true], "sample_608": [false], "sample_609": [true], "sample_610": [false], "sample_611": [false], "sample_612": [false], "sample_613": [false], "sample_614": [false], "sample_615": [false], "sample_616": [true], "sample_617": [false], "sample_618": [true], "sample_619": [true], "sample_620": [true], "sample_621": [false], "sample_622": [true], "sample_623": [false], "sample_624": [false], "sample_625": [false], "sample_626": [false], "sample_627": [false], "sample_628": [false], "sample_629": [false], "sample_630": [false], "sample_631": [false], "sample_632": [false], "sample_633": [false], "sample_634": [false], "sample_635": [false], "sample_636": [false], "sample_637": [false], "sample_638": [false], "sample_639": [false], "sample_640": [false], "sample_641": [false], "sample_642": [false], "sample_643": [false], "sample_644": [false], "sample_645": [false], "sample_646": [false], "sample_647": [true], "sample_648": [false], "sample_649": [false], "sample_650": [false], "sample_651": [false], "sample_652": [false], "sample_653": [false], "sample_654": [false], "sample_655": [false], "sample_656": [false], "sample_657": [false], "sample_658": [false], "sample_659": [false], "sample_660": [false], "sample_661": [false], "sample_662": [false], "sample_663": [false], "sample_664": [false], "sample_665": [false], "sample_666": [false], "sample_667": [true], "sample_668": [false], "sample_669": [true], "sample_670": [false], "sample_671": [false], "sample_672": [false], "sample_673": [false], "sample_674": [false], "sample_675": [false], "sample_676": [false], "sample_677": [false], "sample_678": [false], "sample_679": [false], "sample_680": [false], "sample_681": [false], "sample_682": [false], "sample_683": [false], "sample_684": [false], "sample_685": [false], "sample_686": [false], "sample_687": [false], "sample_688": [false], "sample_689": [false], "sample_690": [false], "sample_691": [false], "sample_692": [false], "sample_693": [false], "sample_694": [false], "sample_695": [false], "sample_696": [false], "sample_697": [true], "sample_698": [false], "sample_699": [false], "sample_700": [false], "sample_701": [false], "sample_702": [true], "sample_703": [false], "sample_704": [false], "sample_705": [false], "sample_706": [false], "sample_707": [false], "sample_708": [true], "sample_709": [false], "sample_710": [false], "sample_711": [false], "sample_712": [false], "sample_713": [false], "sample_714": [false], "sample_715": [false], "sample_716": [false], "sample_717": [true], "sample_718": [false], "sample_719": [false], "sample_720": [false], "sample_721": [false], "sample_722": [false], "sample_723": [false], "sample_724": [false], "sample_725": [false], "sample_726": [false], "sample_727": [false], "sample_728": [false], "sample_729": [true], "sample_730": [false], "sample_731": [false], "sample_732": [true], "sample_733": [false], "sample_734": [true], "sample_735": [true], "sample_736": [true], "sample_737": [false], "sample_738": [false], "sample_739": [false], "sample_740": [false], "sample_741": [true], "sample_742": [true], "sample_743": [true], "sample_744": [false], "sample_745": [true], "sample_746": [false], "sample_747": [true], "sample_748": [true], "sample_749": [false], "sample_750": [true], "sample_751": [false], "sample_752": [true], "sample_753": [false], "sample_754": [false], "sample_755": [true], "sample_756": [true], "sample_757": [true], "sample_758": [false], "sample_759": [false], "sample_760": [true], "sample_761": [true], "sample_762": [false], "sample_763": [false], "sample_764": [false], "sample_765": [false], "sample_766": [true], "sample_767": [false], "sample_768": [false], "sample_769": [false], "sample_770": [false], "sample_771": [false], "sample_772": [true], "sample_773": [false], "sample_774": [true], "sample_775": [false], "sample_776": [true], "sample_777": [false], "sample_778": [false], "sample_779": [false], "sample_780": [true], "sample_781": [false], "sample_782": [false], "sample_783": [true], "sample_784": [false], "sample_785": [false], "sample_786": [true], "sample_787": [true], "sample_788": [true], "sample_789": [true], "sample_790": [false], "sample_791": [true], "sample_792": [true], "sample_793": [false], "sample_794": [false], "sample_795": [false], "sample_796": [true], "sample_797": [true], "sample_798": [false], "sample_799": [false], "sample_800": [false], "sample_801": [false], "sample_802": [false], "sample_803": [false], "sample_804": [true], "sample_805": [false], "sample_806": [false], "sample_807": [false], "sample_808": [true], "sample_809": [false], "sample_810": [true], "sample_811": [false], "sample_812": [false], "sample_813": [true], "sample_814": [false], "sample_815": [true], "sample_816": [false], "sample_817": [false], "sample_818": [true], "sample_819": [false], "sample_820": [false], "sample_821": [false], "sample_822": [false], "sample_823": [false], "sample_824": [false], "sample_825": [false], "sample_826": [false], "sample_827": [true], "sample_828": [false], "sample_829": [true], "sample_830": [false], "sample_831": [false], "sample_832": [true], "sample_833": [false], "sample_834": [true], "sample_835": [true], "sample_836": [false], "sample_837": [false], "sample_838": [false], "sample_839": [false], "sample_840": [false], "sample_841": [false], "sample_842": [false], "sample_843": [false], "sample_844": [false], "sample_845": [true], "sample_846": [false], "sample_847": [true], "sample_848": [true], "sample_849": [false], "sample_850": [true], "sample_851": [false], "sample_852": [true], "sample_853": [true], "sample_854": [false], "sample_855": [true], "sample_856": [true], "sample_857": [false], "sample_858": [true], "sample_859": [true], "sample_860": [false], "sample_861": [false], "sample_862": [false], "sample_863": [true], "sample_864": [true], "sample_865": [false], "sample_866": [true], "sample_867": [true], "sample_868": [false], "sample_869": [false], "sample_870": [true], "sample_871": [false], "sample_872": [false], "sample_873": [false], "sample_874": [true], "sample_875": [true], "sample_876": [false], "sample_877": [true], "sample_878": [false], "sample_879": [true], "sample_880": [false], "sample_881": [false], "sample_882": [true], "sample_883": [true], "sample_884": [true], "sample_885": [false], "sample_886": [true], "sample_887": [false], "sample_888": [true], "sample_889": [false], "sample_890": [false], "sample_891": [true], "sample_892": [true], "sample_893": [false], "sample_894": [false], "sample_895": [true], "sample_896": [false], "sample_897": [false], "sample_898": [false], "sample_899": [false], "sample_900": [false], "sample_901": [false], "sample_902": [false], "sample_903": [true], "sample_904": [true], "sample_905": [false], "sample_906": [false], "sample_907": [false], "sample_908": [false], "sample_909": [false], "sample_910": [false], "sample_911": [false], "sample_912": [false], "sample_913": [false], "sample_914": [true], "sample_915": [false], "sample_916": [false], "sample_917": [false], "sample_918": [false], "sample_919": [false], "sample_920": [false], "sample_921": [false], "sample_922": [false], "sample_923": [false], "sample_924": [false], "sample_925": [false], "sample_926": [false], "sample_927": [false], "sample_928": [false], "sample_929": [false], "sample_930": [false], "sample_931": [true], "sample_932": [true], "sample_933": [false], "sample_934": [true], "sample_935": [true], "sample_936": [false], "sample_937": [true], "sample_938": [false], "sample_939": [true], "sample_940": [false], "sample_941": [true], "sample_942": [false], "sample_943": [false], "sample_944": [true], "sample_945": [false], "sample_946": [false], "sample_947": [false], "sample_948": [false], "sample_949": [false], "sample_950": [false], "sample_951": [true], "sample_952": [true], "sample_953": [false], "sample_954": [false], "sample_955": [false], "sample_956": [false], "sample_957": [true], "sample_958": [false], "sample_959": [false], "sample_960": [false], "sample_961": [false], "sample_962": [false], "sample_963": [true], "sample_964": [false], "sample_965": [true], "sample_966": [false], "sample_967": [false], "sample_968": [false], "sample_969": [true], "sample_970": [false], "sample_971": [false], "sample_972": [true], "sample_973": [true], "sample_974": [false], "sample_975": [true], "sample_976": [false], "sample_977": [true], "sample_978": [false], "sample_979": [false], "sample_980": [false], "sample_981": [true], "sample_982": [false], "sample_983": [true], "sample_984": [false], "sample_985": [false], "sample_986": [false], "sample_987": [true], "sample_988": [true], "sample_989": [false], "sample_990": [false], "sample_991": [false], "sample_992": [false], "sample_993": [true], "sample_994": [true], "sample_995": [false], "sample_996": [true], "sample_997": [false], "sample_998": [false], "sample_999": [false], "sample_1000": [true], "sample_1001": [false], "sample_1002": [false], "sample_1003": [true], "sample_1004": [false], "sample_1005": [false], "sample_1006": [false], "sample_1007": [false], "sample_1008": [true], "sample_1009": [false], "sample_1010": [false], "sample_1011": [false], "sample_1012": [true], "sample_1013": [false], "sample_1014": [true], "sample_1015": [true], "sample_1016": [false], "sample_1017": [true], "sample_1018": [true], "sample_1019": [false], "sample_1020": [false], "sample_1021": [true], "sample_1022": [false], "sample_1023": [true], "sample_1024": [true], "sample_1025": [true], "sample_1026": [false], "sample_1027": [true], "sample_1028": [true], "sample_1029": [true], "sample_1030": [false], "sample_1031": [false], "sample_1032": [false], "sample_1033": [true], "sample_1034": [false], "sample_1035": [false], "sample_1036": [true], "sample_1037": [true], "sample_1038": [false], "sample_1039": [false], "sample_1040": [false], "sample_1041": [true], "sample_1042": [false], "sample_1043": [false], "sample_1044": [false], "sample_1045": [false], "sample_1046": [false], "sample_1047": [false], "sample_1048": [false], "sample_1049": [false], "sample_1050": [true], "sample_1051": [false], "sample_1052": [false], "sample_1053": [false], "sample_1054": [false], "sample_1055": [false], "sample_1056": [false], "sample_1057": [false], "sample_1058": [false], "sample_1059": [false], "sample_1060": [true], "sample_1061": [false], "sample_1062": [false], "sample_1063": [true], "sample_1064": [true], "sample_1065": [false], "sample_1066": [false], "sample_1067": [false], "sample_1068": [false], "sample_1069": [false], "sample_1070": [false], "sample_1071": [false], "sample_1072": [false], "sample_1073": [false], "sample_1074": [false], "sample_1075": [true], "sample_1076": [true], "sample_1077": [false], "sample_1078": [true], "sample_1079": [true], "sample_1080": [true], "sample_1081": [true], "sample_1082": [false], "sample_1083": [false], "sample_1084": [false], "sample_1085": [false], "sample_1086": [false], "sample_1087": [true], "sample_1088": [false], "sample_1089": [false], "sample_1090": [false], "sample_1091": [false], "sample_1092": [true], "sample_1093": [true], "sample_1094": [true], "sample_1095": [false], "sample_1096": [true], "sample_1097": [true], "sample_1098": [true], "sample_1099": [false], "sample_1100": [false], "sample_1101": [false], "sample_1102": [true], "sample_1103": [false], "sample_1104": [false], "sample_1105": [false], "sample_1106": [false], "sample_1107": [false], "sample_1108": [false], "sample_1109": [false], "sample_1110": [false], "sample_1111": [false], "sample_1112": [true], "sample_1113": [false], "sample_1114": [false], "sample_1115": [false], "sample_1116": [false], "sample_1117": [true], "sample_1118": [false], "sample_1119": [false], "sample_1120": [false], "sample_1121": [false], "sample_1122": [false], "sample_1123": [false], "sample_1124": [false], "sample_1125": [false], "sample_1126": [true], "sample_1127": [false], "sample_1128": [false], "sample_1129": [false], "sample_1130": [true], "sample_1131": [false], "sample_1132": [false], "sample_1133": [true], "sample_1134": [true], "sample_1135": [false], "sample_1136": [true], "sample_1137": [false], "sample_1138": [false], "sample_1139": [false], "sample_1140": [true], "sample_1141": [false], "sample_1142": [false], "sample_1143": [true], "sample_1144": [false], "sample_1145": [true], "sample_1146": [true], "sample_1147": [true], "sample_1148": [false], "sample_1149": [true], "sample_1150": [false], "sample_1151": [false], "sample_1152": [false], "sample_1153": [true], "sample_1154": [false], "sample_1155": [true], "sample_1156": [false], "sample_1157": [false], "sample_1158": [true], "sample_1159": [true], "sample_1160": [true], "sample_1161": [false], "sample_1162": [false], "sample_1163": [false], "sample_1164": [false], "sample_1165": [false], "sample_1166": [false], "sample_1167": [false], "sample_1168": [false], "sample_1169": [false], "sample_1170": [false], "sample_1171": [false], "sample_1172": [false], "sample_1173": [false], "sample_1174": [false], "sample_1175": [true], "sample_1176": [true], "sample_1177": [false], "sample_1178": [false], "sample_1179": [false], "sample_1180": [true], "sample_1181": [true], "sample_1182": [true], "sample_1183": [false], "sample_1184": [true], "sample_1185": [true], "sample_1186": [true], "sample_1187": [true], "sample_1188": [true], "sample_1189": [false], "sample_1190": [false], "sample_1191": [false], "sample_1192": [false], "sample_1193": [false], "sample_1194": [true], "sample_1195": [false], "sample_1196": [false], "sample_1197": [false], "sample_1198": [false], "sample_1199": [false], "sample_1200": [false], "sample_1201": [false], "sample_1202": [false], "sample_1203": [false], "sample_1204": [false], "sample_1205": [true], "sample_1206": [false], "sample_1207": [false], "sample_1208": [true], "sample_1209": [false]}}