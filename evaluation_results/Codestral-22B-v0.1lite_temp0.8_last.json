{"raw_generations": {"sample_33": ["    def test_sender_specific_receiver(self):\n        @receiver(a_signal, sender=self)\n            self.state = val\n\n        self.state = False\n        a_signal.send(sender=self, val=True)\n        self.assertTrue(self.state)\n\n        self.state = False\n        a_signal.send(sender=object(), val=True)\n        self.assertFalse(self.state)\n", "def test_receiver_multiple_signals(self):\n    @receiver(a_signal, sender=self)\n    @receiver(b_signal, sender=self)\n        self.state.append(val)\n    self.state = []\n    a_signal.send(sender=self, val='test_a')\n    b_signal.send(sender=self, val='test_b')\n    self.assertEqual(self.state, ['test_a', 'test_b'])\n", "    def test_caching_signal(self):\n        @receiver(d_signal, sender=self)\n            self.state = val\n        self.state = False\n        d_signal.send(sender=self, val=True)\n        self.assertTrue(self.state)\n        self.assertEqual(len(d_signal.sender_receivers_cache), 1)\n        self.state = False\n        d_signal.send(sender=self, val=True)\n        self.assertTrue(self.state)\n        self.assertEqual(len(d_signal.sender_receivers_cache), 1)\n        d_signal.disconnect(f, sender=self)\n        self.assertTestIsClean(d_signal)\n", "def test_receiver_with_sender(self):\n    @receiver(a_signal, sender=self)\n        self.state = val\n    self.state = False\n    a_signal.send(sender=self, val=True)\n    self.assertTrue(self.state)\n\n    a_signal.disconnect(f, sender=self)\n    a_signal.send(sender=self, val=False)\n    self.assertFalse(self.state)\n", "    def test_receiver_multiple_signals(self):\n        @receiver([a_signal, b_signal], sender=object)\n            self.state.append(val)\n        self.state = []\n        a_signal.send(sender=object, val='a_signal')\n        b_signal.send(sender=object, val='b_signal')\n        c_signal.send(sender=object, val='c_signal')\n        self.assertEqual(self.state, ['a_signal', 'b_signal'])\n        a_signal.disconnect(f, sender=object)\n        b_signal.disconnect(f, sender=object)\n        self.assertTestIsClean(a_signal)\n        self.assertTestIsClean(b_signal)\n        self.assertTestIsClean(c_signal)\n"], "sample_42": ["def test_serialize_complex(self):\n    complex_num = complex(1, 2)\n    self.assertSerializedEqual(complex_num)\n    self.assertSerializedResultEqual(complex_num, ('complex((1+2j))', set()))\n", "def test_serialize_complex(self):\n    value = 1 + 2j\n    self.assertSerializedEqual(value)\n    self.assertSerializedResultEqual(value, (\"complex('(1+2j)')\", set()))\n", "def test_serialize_complex(self):\n    complex_value = 1 + 2j\n    self.assertSerializedEqual(complex_value)\n    self.assertSerializedResultEqual(complex_value, (\"complex('(1+2j)')\", set()))\n", "def test_serialize_complex_numbers(self):\n    complex_number = 1 + 2j\n    self.assertSerializedEqual(complex_number)\n    self.assertSerializedResultEqual(complex_number, (\"complex((1+2j))\", {}))\n", "def test_serialize_register_serializer(self):\n    class MyType:\n            self.value = value\n\n    class MyTypeSerializer(BaseSerializer):\n            return 'MyType(%r)' % self.value, {'import migrations.test_writer'}\n\n    Serializer.register(MyType, MyTypeSerializer)\n    self.assertSerializedResultEqual(MyType(42), (\"MyType(42)\", {'import migrations.test_writer'}))\n"], "sample_112": ["def test_isotonic_regression_with_increasing_auto():\n    # Test with increasing='auto'\n    x = np.array([1, 2, 3, 4, 5])\n    y_increasing = np.array([1, 2, 3, 4, 5])\n    y_decreasing = np.array([5, 4, 3, 2, 1])\n\n    ir_increasing = IsotonicRegression(increasing='auto').fit(x, y_increasing)\n    ir_decreasing = IsotonicRegression(increasing='auto').fit(x, y_decreasing)\n\n    assert ir_increasing.increasing_ is True\n    assert ir_decreasing.increasing_ is False\n", "def test_isotonic_regression_weights_not_altered():\n    # Check that calling isotonic_regression will not alter the input sample_weight\n    y = np.array([3, 7, 5, 9, 8, 7, 10])\n    sample_weight = np.array([1, 2, 3, 4, 5, 6, 7])\n    sample_weight_original = sample_weight.copy()\n\n    isotonic_regression(y, sample_weight=sample_weight)\n    assert_array_equal(sample_weight, sample_weight_original)\n", "def test_isotonic_regression_invalid_increasing_value():\n    # Test that IsotonicRegression raises error for invalid 'increasing' value\n    msg = \"Valid values are: ['auto', False, True]. Given value is: invalid\"\n    with pytest.raises(ValueError, match=msg):\n        IsotonicRegression(increasing=\"invalid\")\n", "def test_isotonic_regression_with_different_sample_weight_dtypes():\n    \"\"\"\n    Test isotonic regression fit, transform and fit_transform\n    with different data types for sample_weight\n    \"\"\"\n    x = np.array([0, 1, 2, 3, 4])\n    y = np.array([0, 0, 1, 1, 2])\n\n    for dtype in [np.int32, np.int64, np.float32, np.float64]:\n        sample_weight = np.array([1, 2, 3, 4, 5], dtype=dtype)\n        ir = IsotonicRegression()\n        ir.fit(x, y, sample_weight=sample_weight)\n        assert_array_equal(ir.transform(x), ir.fit_transform(x, y, sample_weight=sample_weight))\n", "def test_isotonic_regression_sample_weight_zero():\n    # Test from #18745\n    # Check that IsotonicRegression handles sample_weight of zero correctly\n    X = np.arange(10)\n    y = np.arange(10)\n    sample_weight = np.zeros(10)\n\n    msg = \"Input X has consistent length with sample_weight\"\n    with pytest.raises(ValueError, match=msg):\n        IsotonicRegression().fit(X, y, sample_weight=sample_weight)\n"], "sample_84": ["def test_call_fixture_function_parametrized_error():\n    \"\"\"Check if an error is raised if a parametrized fixture function is called directly (#4545)\"\"\"\n\n    @pytest.fixture(params=[1, 2])\n        return request.param\n\n    with pytest.raises(pytest.fail.Exception):\n        assert fix() == 1\n", "def test_call_fixture_function_multiple_times(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            return 1\n\n            assert fix == 1\n            with pytest.raises(pytest.fail.Exception):\n                assert fix() == 1\n        \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n", "def test_call_fixture_function_error_2():\n    \"\"\"Check if an error is raised if a fixture function is called directly (#4545)\"\"\"\n\n    @pytest.fixture\n        return 2\n\n    with pytest.raises(pytest.fail.Exception):\n        assert fix() == 2\n", "def test_call_fixture_function_directly():\n    \"\"\"Check if an error is raised if a fixture function is called directly (#4545)\"\"\"\n\n    @pytest.fixture\n        return 1\n\n    with pytest.raises(pytest.fail.Exception) as exc_info:\n        fix()\n    assert str(exc_info.value) == \"Fixture functions can only be called from a test function or fixture.\"\n", "def test_request_scope_class_with_finalizer(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.fixture(scope=\"class\")\n            request.addfinalizer(lambda: values.append(\"teardown\"))\n            values.append(\"setup\")\n            return 1\n\n        values = []\n        class TestClass:\n                values.append(\"test1\")\n\n                values.append(\"test2\")\n\n            assert values == [\"setup\", \"test1\", \"test2\", \"teardown\"]\n    \"\"\"\n    )\n    reprec = testdir.inline_run()\n    reprec.assertoutcome(passed=3)\n"], "sample_85": ["def test_log_cli_format(testdir):\n    # Custom log format\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_handler.formatter._fmt == 'custom format'\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n        log_cli_format=custom format\n        \"\"\"\n    )\n\n    result = testdir.runpytest(\"-s\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_log_cli_format.py* This log message will be shown\",\n            \"PASSED\",  # 'PASSED' on its own line because the log message prints a new line\n        ]\n    )\n\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n", "def test_log_format_option(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        log_file_format = %(asctime)s - %(name)s - %(levelname)s - %(message)s\n        \"\"\".format(\n            log_file\n        )\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n            logging.getLogger().info(\"Formatted log message\")\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert re.match(r\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d{3} - root - INFO - Formatted log message\", contents)\n", "def test_log_level_name_ini(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = WARNING\n        \"\"\".format(\n            log_file\n        )\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n        logging.getLogger().setLevel(\"INFO\")\n        logging.getLogger().warning(\"Warning message\")\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert \"Warning message\" in contents\n", "def test_log_file_format(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        log_file_format = %(levelname)s - %(message)s\n        log_file_date_format = %H:%M:%S\n        \"\"\".format(\n            log_file\n        )\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n\n        logging.getLogger().info(\"Formatted log message\")\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file, encoding=\"utf-8\") as rfh:\n        contents = rfh.read()\n        assert \"INFO - Formatted log message\" in contents\n", "def test_log_file_format(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        log_file_format = %(asctime)s %(levelname)s %(message)s\n        log_file_date_format = %Y-%m-%d %H:%M:%S\n        \"\"\".format(\n            log_file\n        )\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import logging\n        import time\n\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            time.sleep(1)  # Ensure asctime is different\n            logging.getLogger('catchlog').info(\"Another log message will be shown\")\n    \"\"\"\n    )\n\n    result = testdir.runpytest(\"-s\")\n\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file) as rfh:\n        contents = rfh.readlines()\n        assert len(contents) == 2\n        assert contents[0].split(\" \")[1] == \"INFO\"\n        assert contents[1].split(\" \")[1] == \"INFO\"\n        assert contents[0].split(\" \")[2] != contents[1].split(\" \")[2]  # Check asctime is different\n"], "sample_4": ["def test_streaming_response_custom_content_type(self):\n    r = StreamingHttpResponse(iter(['hello', 'world']), content_type='text/plain')\n    self.assertEqual(r['Content-Type'], 'text/plain')\n    self.assertEqual(list(r), [b'hello', b'world'])\n    self.assertEqual(r.getvalue(), b'helloworld')\n", "def test_set_signed_cookie(self):\n    r = HttpResponse()\n    r.set_signed_cookie('name', 'value')\n    self.assertTrue('name' in r.cookies)\n    self.assertIn('name=', r.cookies.output())\n    self.assertIn('samesite=Lax', r.cookies.output())\n", "def test_response_close_on_failed_write(self):\n    r = HttpResponse()\n    with self.assertRaises(OSError):\n        r.write(\"This should fail\")\n    self.assertTrue(r.closed)\n", "    def test_charset_from_content_type(self):\n        r = HttpResponse(content_type='text/html; charset=iso-8859-1')\n        self.assertEqual(r.charset, 'iso-8859-1')\n\n        r = HttpResponse(content_type='text/html; charset=\"utf-8\"')\n        self.assertEqual(r.charset, 'utf-8')\n\n        r = HttpResponse()\n        self.assertEqual(r.charset, 'utf-8')  # Default charset\n", "def test_unicode_cookie_values(self):\n    r = HttpResponse()\n    r.set_cookie('unicode', 'caf\u00e9')\n    self.assertEqual(r.cookies['unicode'].value, 'caf\u00e9')\n    self.assertIn('caf%C3%A9', r.cookies.output())\n\n    r = HttpResponse()\n    r.set_cookie('unicode', '\u2020')\n    self.assertEqual(r.cookies['unicode'].value, '=?utf-8?b?4oCg?=')\n    self.assertIn('=?utf-8?b?4oCg?=', r.cookies.output())\n"], "sample_66": ["def test_autocomplete_is_manytomany(self):\n    class UserAdmin(ModelAdmin):\n        search_fields = (\"name\",)\n\n    class Admin(ModelAdmin):\n        autocomplete_fields = (\"users\",)\n\n    site = AdminSite()\n    site.register(User, UserAdmin)\n    self.assertIsValid(Admin, ValidationTestModel, admin_site=site)\n", "    def test_invalid_type(self):\n        class TestModelAdmin(ModelAdmin):\n            view_on_site = \"invalid\"\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'view_on_site' must be a callable or a boolean value.\",\n            \"admin.E025\",\n        )\n", "    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            exclude = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'exclude' must be a list or tuple.\",\n            \"admin.E014\",\n        )\n", "def test_list_editable_missing_field(self):\n    class TestModelAdmin(ModelAdmin):\n        list_editable = (\"non_existent_field\",)\n\n    self.assertIsInvalid(\n        TestModelAdmin,\n        ValidationTestModel,\n        \"The value of 'list_editable[0]' refers to 'non_existent_field', which \"\n        \"is not a field of 'modeladmin.ValidationTestModel'.\",\n        \"admin.E121\",\n    )\n", "def test_inline_fk_name_in_exclude(self):\n    class ValidationTestInline(TabularInline):\n        model = ValidationTestInlineModel\n        fk_name = \"parent\"\n        exclude = (\"parent\",)\n\n    class TestModelAdmin(ModelAdmin):\n        inlines = [ValidationTestInline]\n\n    self.assertIsInvalid(\n        TestModelAdmin,\n        ValidationTestModel,\n        \"Cannot exclude the field 'parent', because it is the foreign key \"\n        \"to the parent model 'modeladmin.ValidationTestModel'.\",\n        \"admin.E201\",\n        invalid_obj=ValidationTestInline,\n    )\n"], "sample_116": ["def test_create_index_with_category(app):\n    text = (\".. index:: single: docutils\\n\"\n            \"   :category: Language\\n\"\n            \".. index:: single: Python\\n\"\n            \"   :category: Language\\n\"\n            \".. index:: single: Sphinx\\n\"\n            \"   :category: Tool\\n\"\n            \".. index:: single: pip\\n\"\n            \"   :category: Tool\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n\n    # check index is created correctly\n    assert len(index) == 2\n    assert index[0] == ('Language', [('docutils', [[('', '#index-0')], [], 'Language']),\n                                     ('Python', [[('', '#index-1')], [], 'Language')])\n    assert index[1] == ('Tool', [('Sphinx', [[('', '#index-2')], [], 'Tool']),\n                                 ('pip', [[('', '#index-3')], [], 'Tool'])])\n", "def test_create_index_with_duplicate_entries(app):\n    text = (\".. index:: single: docutils\\n\"\n            \".. index:: single: Python\\n\"\n            \".. index:: single: docutils\\n\"  # duplicate entry\n            \".. index:: pair: Python; interpreter\\n\"\n            \".. index:: pair: Python; interpreter\\n\")  # duplicate entry\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n\n    # check index is created correctly with no duplicates\n    assert len(index) == 3\n    assert index[0] == ('D', [('docutils', [[('', '#index-0')], [], None])])\n    assert index[1] == ('P', [('Python', [[], [('interpreter', [('', '#index-2')])], None])])\n    assert index[2] == ('I', [('interpreter', [[], [('Python', [('', '#index-2')])], None])])\n", "def test_create_index_with_category(app):\n    text = (\".. index:: single: docutils; Category: Software\\n\"\n            \".. index:: single: Python; Category: Programming\\n\"\n            \".. index:: single: Sphinx; Category: Software\\n\"\n            \".. index:: single: reST\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n\n    # check index is created correctly with categories\n    assert len(index) == 3\n    assert index[0] == ('Software', [('docutils', [[('', '#index-0')], [], 'Software']),\n                                     ('Sphinx', [[('', '#index-2')], [], 'Software'])])\n    assert index[1] == ('Programming', [('Python', [[('', '#index-1')], [], 'Programming'])])\n    assert index[2] == ('Symbols', [('reST', [[('', '#index-3')], [], None])])\n", "def test_create_index_with_category(app):\n    text = (\".. index:: single: docutils; category: markup\\n\"\n            \".. index:: single: Python; category: programming\\n\"\n            \".. index:: single: Sphinx; category: documentation\\n\"\n            \".. index:: single: reST; category: markup\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n\n    assert len(index) == 3\n    assert index[0] == ('markup', [('docutils', [[('', '#index-0')], [], 'markup']),\n                                   ('reST', [[('', '#index-3')], [], 'markup'])])\n    assert index[1] == ('programming', [('Python', [[('', '#index-1')], [], 'programming'])])\n    assert index[2] == ('documentation', [('Sphinx', [[('', '#index-2')], [], 'documentation'])])\n", "def test_create_index_with_category(app):\n    text = (\".. index:: single: docutils; category: tools\\n\"\n            \".. index:: single: Python; category: languages\\n\"\n            \".. index:: single: Sphinx; category: tools\\n\"\n            \".. index:: single: pip; category: tools\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 2\n    assert index[0] == ('languages', [('Python', [[('', '#index-1')], {}, 'languages'])])\n    assert index[1] == ('tools', [('Sphinx', [[('', '#index-2')], {}, 'tools']),\n                                  ('docutils', [[('', '#index-0')], {}, 'tools']),\n                                  ('pip', [[('', '#index-3')], {}, 'tools'])])\n"], "sample_52": ["def test_references_field_by_limit_choices_to(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ForeignKey(\n            \"Other\",\n            models.CASCADE,\n            limit_choices_to={\"field\": \"value\"},\n        ),\n    )\n    self.assertIs(operation.references_field(\"Other\", \"field\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Other\", \"whatever\", \"migrations\"), False)\n    self.assertIs(operation.references_field(\"Missing\", \"whatever\", \"migrations\"), False)\n", "    def test_references_field_by_through_fields(self):\n        operation = FieldOperation(\n            \"Model\",\n            \"field\",\n            models.ManyToManyField(\n                \"Other\",\n                through=\"Through\",\n                through_fields=(\"from_field\", \"to_field\"),\n            ),\n        )\n        self.assertIs(\n            operation.references_field(\"Model\", \"from_field\", \"migrations\"), True\n        )\n        self.assertIs(\n            operation.references_field(\"Model\", \"to_field\", \"migrations\"), False\n        )\n        self.assertIs(\n            operation.references_field(\"Other\", \"from_field\", \"migrations\"), False\n        )\n        self.assertIs(\n            operation.references_field(\"Through\", \"from_field\", \"migrations\"), True\n        )\n        self.assertIs(\n            operation.references_field(\"Through\", \"to_field\", \"migrations\"), True\n        )\n        self.assertIs(\n            operation.references_field(\"Missing\", \"whatever\", \"migrations\"), False\n        )\n", "def test_rename_index_state_forwards_unnamed_index_multiple_fields(self):\n    app_label = \"test_rnidsfui_multiple\"\n    project_state = self.set_up_test_model(app_label, index_together=True)\n    old_model = project_state.apps.get_model(app_label, \"Pony\")\n    new_state = project_state.clone()\n\n    operation = migrations.RenameIndex(\n        \"Pony\", new_name=\"new_pony_index\", old_fields=(\"weight\", \"pink\", \"height\")\n    )\n    operation.state_forwards(app_label, new_state)\n    new_model = new_state.apps.get_model(app_label, \"Pony\")\n    self.assertIsNot(old_model, new_model)\n    self.assertEqual(new_model._meta.index_together, tuple())\n    self.assertEqual(len(new_model._meta.indexes), 1)\n    self.assertEqual(new_model._meta.indexes[0].name, \"new_pony_index\")\n    self.assertEqual(new_model._meta.indexes[0].fields, (\"weight\", \"pink\", \"height\"))\n", "def test_references_field_by_base_field(self):\n    operation = FieldOperation(\n        \"Model\", \"field\", models.FileField(base_field=models.CharField())\n    )\n    self.assertIs(operation.references_field(\"Model\", \"field\", \"migrations\"), True)\n", "def test_references_field_by_many_to_many_through(self):\n    operation = FieldOperation(\n        \"Model\",\n        \"field\",\n        models.ManyToManyField(\"Other\", through=models.Model.objects.through),\n    )\n    self.assertIs(operation.references_field(\"Other\", \"whatever\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"migrations.Through\", \"whatever\", \"migrations\"), True)\n    self.assertIs(operation.references_field(\"Missing\", \"whatever\", \"migrations\"), False)\n"], "sample_69": ["def test_set_rasterized():\n    art = martist.Artist()\n    assert not art.get_rasterized()\n    art.set_rasterized(True)\n    assert art.get_rasterized()\n    art.set_rasterized(False)\n    assert not art.get_rasterized()\n", "def test_set_visible():\n    art = martist.Artist()\n    assert art.get_visible() is True\n    art.set_visible(False)\n    assert art.get_visible() is False\n    art.set_visible(True)\n    assert art.get_visible() is True\n", "def test_set_agg_filter():\n    art = martist.Artist()\n    filter_func = lambda x, y: x\n    art.set_agg_filter(filter_func)\n    assert art.get_agg_filter() == filter_func\n", "def test_set_mouseover():\n    # Test get_mouseover and set_mouseover methods\n    art = martist.Artist()\n    assert art.get_mouseover() == False\n    art.set_mouseover(True)\n    assert art.get_mouseover() == True\n    art.set_mouseover(False)\n    assert art.get_mouseover() == False\n", "def test_set_figure():\n    art = martist.Artist()\n    fig = plt.figure()\n    art.set_figure(fig)\n    assert art.get_figure() == fig\n    with pytest.raises(RuntimeError, match=\"Can not put single artist in more than one figure\"):\n        art.set_figure(plt.figure())\n"], "sample_127": ["def test_issue_14237_case_2():\n    A = MatrixSymbol(\"A\", 3, 3)\n    B = MatrixSymbol(\"B\", 3, 3)\n    C = MatrixSymbol(\"C\", 3, 3)\n\n    assert latex(A*B + A*B*C + B) == r\"A B + A B C + B\"\n", "def test_Quaternion_normalize():\n    q = Quaternion(1, 2, 3, 4)\n    assert latex(q.normalize()) == r\"\\frac{1}{5} + \\frac{2}{5} i + \\frac{3}{5} j + \\frac{4}{5} k\"\n", "def test_issue_13854():\n    expr = 1/(2*sqrt(2))\n    assert latex(expr) == r\"\\frac{1}{2 \\sqrt{2}}\"\n", "def test_issue_15155():\n    # test case for issue #15155\n    from sympy.printing.latex import latex\n    from sympy import symbols\n\n    x, y = symbols('x y')\n    expr = (x + y)**2\n    assert latex(expr) == r\"\\left(x + y\\right)^{2}\"\n", "def test_issue_14344():\n    # test case for issue #14344\n    expr = x * sin(x)\n    assert latex(expr.as_coefficients_dict()) == r'\\left \\{ x : 1, \\quad \\sin{\\left (x \\right )} : 1\\right \\}'\n"], "sample_65": ["def test_join09(self):\n    output = self.engine.render_to_string(\n        \"join09\", {\"a\": [\"alpha\", \"beta\", \"gamma\"], \"var\": \"\"}\n    )\n    self.assertEqual(output, \"alphabetagamma\")\n", "def test_join09(self):\n    output = self.engine.render_to_string(\n        \"join09\", {\"a\": [\"<p>Hello</p>\", \"World\"], \"var\": \" & \"}\n    )\n    self.assertEqual(output, \"&lt;p&gt;Hello&lt;/p&gt; &amp; World\")\n", "def test_join09(self):\n    output = self.engine.render_to_string(\n        \"join09\", {\"a\": [\"<p>Alpha</p>\", \"Beta & me\"], \"var\": \" & \"}\n    )\n    self.assertEqual(output, \"&lt;p&gt;Alpha&lt;/p&gt; &amp; Beta &amp;#34;me&amp;#34;\")\n", "def test_join09(self):\n    output = self.engine.render_to_string(\n        \"join09\", {\"a\": [\"Alpha\", \"Beta & me\"], \"var\": mark_safe(\" & \")}\n    )\n    self.assertEqual(output, \"Alpha & Beta & me\")\n", "def test_join09(self):\n    output = self.engine.render_to_string(\n        \"join09\", {\"a\": [\"Alpha\", \"Beta & me\"], \"var\": mark_safe(\" & \")}\n    )\n    self.assertEqual(output, \"Alpha & Beta & me\")\n"], "sample_28": ["    def setUp(self):\n        self.site = admin.AdminSite()\n", "    def setUp(self):\n        self.site = admin.AdminSite()\n", "    def setUpTestData(cls):\n        cls.u1 = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n", "    def test_get_action(self):\n        self.assertEqual(self.site.get_action('delete_selected'), delete_selected)\n        with self.assertRaises(KeyError):\n            self.site.get_action('nonexistent_action')\n", "    def test_get_action(self):\n        self.assertEqual(self.site.get_action('delete_selected'), delete_selected)\n"], "sample_89": ["def test_node_add_marker_invalid_marker():\n    node = nodes.Node(\"test_node\")\n    with pytest.raises(ValueError, match=\"is not a string or pytest.mark.* Marker\"):\n        node.add_marker(123)\n", "def test_node_init_without_parent_or_config_raises_error():\n    with pytest.raises(TypeError, match=\"config or parent must be provided\"):\n        nodes.Node(\"name\")\n", "def test_item_add_report_section(testdir):\n    item = testdir.getitem(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    item.add_report_section(\"call\", \"custom\", \"custom report section\")\n    assert (\"call\", \"custom\", \"custom report section\") in item._report_sections\n", "def test_node_repr_failure():\n    class MockExceptionInfo:\n            return \"Mocked Exception Representation\"\n\n    class MockNode(nodes.Node):\n            return self._repr_failure_py(excinfo, style)\n\n    node = MockNode()\n    excinfo = MockExceptionInfo()\n    result = node.repr_failure(excinfo)\n    assert result == \"Mocked Exception Representation\"\n", "def test_node_getparent(testdir):\n    class CustomNode(nodes.Node):\n        pass\n\n    config = testdir.parseconfig()\n    session = testdir._create_session(config)\n    parent_node = nodes.Node(\"parent\", session=session)\n    child_node = CustomNode(\"child\", parent=parent_node, session=session)\n\n    result = child_node.getparent(CustomNode)\n    assert result == child_node\n\n    result = child_node.getparent(nodes.Node)\n    assert result == parent_node\n"], "sample_80": ["def test_format_timedelta_with_format(self):\n    cases = [\n        (pd.Timedelta(\"10 days 1 hour\"), \"date\", \"10 days\"),\n        (pd.Timedelta(\"10 days 1 hour\"), \"time\", \"01:00:00\"),\n        (pd.Timedelta(\"10 days 1 hour\"), None, \"10 days 01:00:00\"),\n        (pd.Timedelta(\"3 hours\"), \"date\", \"0 days\"),\n        (pd.Timedelta(\"3 hours\"), \"time\", \"03:00:00\"),\n        (pd.Timedelta(\"3 hours\"), None, \"0 days 03:00:00\"),\n    ]\n    for item, format, expected in cases:\n        actual = formatting.format_timedelta(item, timedelta_format=format)\n        assert expected == actual\n", "def test_format_timedelta():\n    cases = [\n        (np.timedelta64(1, 'D'), '1 days 00:00:00', '1 days', '00:00:00'),\n        (np.timedelta64(-3, 'h'), '-1 days +19:00:00', '-1 days', '19:00:00'),\n        (np.timedelta64(500, 'ms'), '0 days 00:00:00.500000', '0 days', '00:00:00.500000'),\n        (pd.Timedelta('10 days 1 hour'), '10 days 01:00:00', '10 days', '01:00:00'),\n        (pd.Timedelta('-3 days'), '-3 days +00:00:00', '-3 days', '00:00:00'),\n        (pd.Timedelta('3 hours'), '0 days 03:00:00', '0 days', '03:00:00'),\n        (pd.Timedelta('NaT'), 'NaT', 'NaT', 'NaT'),\n    ]\n    for item, expected, date_expected, time_expected in cases:\n        actual = formatting.format_timedelta(item)\n        assert expected == actual\n        actual = formatting.format_timedelta(item, timedelta_format='date')\n        assert date_expected == actual\n        actual = formatting.format_timedelta(item, timedelta_format='time')\n        assert time_expected == actual\n", "def test_format_timedelta_with_time_format():\n    cases = [\n        (pd.Timedelta(\"10 days 1 hour\"), \"10 days\", \"1 hour\"),\n        (pd.Timedelta(\"-3 days\"), \"-3 days\", \"0 days\"),\n        (pd.Timedelta(\"3 hours\"), \"0 days\", \"3 hours\"),\n        (pd.Timedelta(\"NaT\"), \"NaT\", \"NaT\"),\n    ]\n    for item, expected_date, expected_time in cases:\n        actual_date = formatting.format_timedelta(item, timedelta_format=\"date\")\n        actual_time = formatting.format_timedelta(item, timedelta_format=\"time\")\n        assert expected_date == actual_date\n        assert expected_time == actual_time\n", "def test_format_timedelta_date_time_format():\n    cases = [\n        (pd.Timedelta(\"10 days 1 hour\"), \"date\", \"10 days\"),\n        (pd.Timedelta(\"-3 days\"), \"date\", \"-3 days\"),\n        (pd.Timedelta(\"3 hours\"), \"date\", \"0 days\"),\n        (pd.Timedelta(\"10 days 1 hour\"), \"time\", \"01:00:00\"),\n        (pd.Timedelta(\"-3 days 2 hours\"), \"time\", \"-23:00:00\"),\n        (pd.Timedelta(\"3 hours\"), \"time\", \"03:00:00\"),\n    ]\n    for item, timedelta_format, expected in cases:\n        actual = formatting.format_timedelta(item, timedelta_format)\n        assert expected == actual\n", "def test_inline_variable_array_repr_custom_array_function():\n    class CustomArrayFunction:\n            self.value = value\n\n            return np.array(self.value)\n\n        @property\n            return self.value.shape\n\n        @property\n            return self.value.dtype\n\n        @property\n            return self.value.ndim\n\n    value = CustomArrayFunction(np.array([20, 40]))\n    variable = xr.Variable(\"x\", value)\n\n    max_width = 10\n    actual = formatting.inline_variable_array_repr(variable, max_width=10)\n\n    assert actual == formatting.maybe_truncate(repr(variable._data).replace(\"\\n\", \" \"), max_width)\n"], "sample_124": ["def test_tanh_expansion():\n    x, y = symbols('x,y')\n    assert tanh(x+y).expand(trig=True) == (tanh(x) + tanh(y)) / (1 + tanh(x)*tanh(y))\n    assert tanh(2*x).expand(trig=True).expand() == 2*tanh(x) / (1 + tanh(x)**2)\n    assert tanh(3*x).expand(trig=True).expand() == (3*tanh(x) - 3*tanh(x)**3) / (1 + 3*tanh(x)**2 - tanh(x)**4)\n", "def test_tanh_expansion():\n    x, y = symbols('x,y')\n    assert tanh(x+y).expand(trig=True) == (tanh(x) + tanh(y)) / (1 + tanh(x)*tanh(y))\n    assert tanh(2*x).expand(trig=True) == 2*tanh(x) / (1 + tanh(x)**2)\n    assert tanh(3*x).expand(trig=True).expand() == (3*tanh(x) - tanh(x)**3) / (1 - tanh(x)**2)\n", "def test_tanh_expansion():\n    x, y = symbols('x,y')\n    assert tanh(x+y).expand(trig=True) == (tanh(x) + tanh(y))/(1 + tanh(x)*tanh(y))\n    assert tanh(2*x).expand(trig=True).expand() == (2*tanh(x))/(1 + tanh(x)**2)\n", "def test_cosh_expansion():\n    x, y = symbols('x,y')\n    assert cosh(x+y).expand(trig=True) == cosh(x)*cosh(y) - sinh(x)*sinh(y)\n    assert cosh(2*x).expand(trig=True) == 2*cosh(x)**2 - 1\n    assert cosh(3*x).expand(trig=True).expand() == 4*cosh(x)**3 - 3*cosh(x)\n", "def test_sinh_expand_trig():\n    x, y = symbols('x, y')\n    assert sinh(x + y)._eval_expand_trig(deep=True) == sinh(x)*cosh(y) + cosh(x)*sinh(y)\n    assert sinh(2*x)._eval_expand_trig(deep=True) == 2*sinh(x)*cosh(x)\n    assert sinh(3*x)._eval_expand_trig(deep=True).expand() == sinh(x)**3 + 3*sinh(x)*cosh(x)**2\n"], "sample_64": ["def test_submit_row_show_delete_link(self):\n    \"\"\"\n    The 'show_delete_link' context variable should be True if the user has delete\n    permission, the object is being changed, and 'show_delete' is not False.\n    \"\"\"\n    change_user = User.objects.create_user(\n        username=\"change_user\", password=\"secret\", is_staff=True\n    )\n    change_user.user_permissions.add(\n        get_perm(User, get_permission_codename(\"change\", User._meta)),\n        get_perm(User, get_permission_codename(\"delete\", User._meta)),\n    )\n    request = self.request_factory.get(\n        reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n    )\n    request.user = change_user\n    admin = UserAdmin(User, site)\n    response = admin.change_view(request, str(self.superuser.pk))\n    template_context = submit_row(response.context_data)\n    self.assertIs(template_context[\"show_delete_link\"], True)\n\n    change_user.user_permissions.remove(\n        get_perm(User, get_permission_codename(\"delete\", User._meta))\n    )\n    response = admin.change_view(request, str(self.superuser.pk))\n    template_context = submit_row(response.context_data)\n    self.assertIs(template_context[\"show_delete_link\"], False)\n", "def test_override_change_form_submit_row(self):\n    \"\"\"\n    Change form's submit row template tag should follow the standard search pattern\n    admin/app_label/model/template.html.\n    \"\"\"\n    article = Article.objects.all()[0]\n    request = self.request_factory.get(\n        reverse(\"admin:admin_views_article_change\", args=[article.pk])\n    )\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    response = admin.change_view(request, str(article.pk))\n    response.render()\n    self.assertContains(response, 'name=\"_save\"')\n    self.assertContains(response, 'name=\"_continue\"')\n    self.assertContains(response, 'override-submit_row')\n", "def test_override_change_form_submit_row(self):\n    \"\"\"\n    The submit_row template tag should respect the show_save and show_close\n    context variables when they are set in the extra_context.\n    \"\"\"\n    request = self.request_factory.get(\n        reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n    )\n    request.user = self.superuser\n    admin = UserAdmin(User, site)\n    extra_context = {\"show_save\": False, \"show_close\": True}\n    response = admin.change_view(\n        request, str(self.superuser.pk), extra_context=extra_context\n    )\n    template_context = submit_row(response.context_data)\n    self.assertIs(template_context[\"show_save\"], False)\n    self.assertIs(template_context[\"show_close\"], True)\n", "def test_override_prepopulated_fields_js_template_tags(self):\n    \"\"\"\n    prepopulated_fields_js template tag follows the standard search pattern\n    admin/app_label/model/template.html.\n    \"\"\"\n    article = Article.objects.all()[0]\n    request = self.request_factory.get(\n        reverse(\"admin:admin_views_article_change\", args=[article.pk])\n    )\n    request.user = self.superuser\n    admin = ArticleAdmin(Article, site)\n    response = admin.change_view(request, str(article.pk))\n    response.render()\n    self.assertContains(response, \"override-prepopulated_fields_js\")\n", "def test_override_submit_row_template_tags(self):\n    \"\"\"\n    submit_row template tag follows the standard search pattern\n    admin/app_label/model/template.html.\n    \"\"\"\n    request = self.request_factory.get(\n        reverse(\"admin:auth_user_change\", args=[self.superuser.pk])\n    )\n    request.user = self.superuser\n    admin = UserAdmin(User, site)\n    extra_context = {\"show_save\": False, \"extra\": True}\n    response = admin.change_view(\n        request, str(self.superuser.pk), extra_context=extra_context\n    )\n    template_context = submit_row(response.context_data)\n    response.render()\n    self.assertIs(template_context[\"show_save\"], False)\n    self.assertIs(template_context[\"extra\"], True)\n    self.assertNotContains(response, 'name=\"_save\"')\n    self.assertContains(response, \"override-submit_row\")\n"], "sample_15": ["def test_consistent_language_settings(self):\n    for tag in self.valid_tags:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [])\n", "def test_consistent_language_settings(self):\n    for tag in self.valid_tags:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [])\n", "def test_consistent_language_settings(self):\n    for tag in self.valid_tags:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [])\n", "def test_consistent_language_settings(self):\n    for tag in self.valid_tags:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag, LANGUAGES=[(tag, tag)]):\n            self.assertEqual(check_language_settings_consistent(None), [])\n", "def test_consistent_language_settings(self):\n    for tag in self.valid_tags:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [])\n"], "sample_2": ["def test_to_fits_2():\n    \"\"\"\n    Test to_fits() with SIP distortion.\n    \"\"\"\n    fits_name = get_pkg_data_filename('data/sip.fits')\n    w = wcs.WCS(fits_name)\n    wfits = w.to_fits()\n    assert isinstance(wfits, fits.HDUList)\n    assert isinstance(wfits[0], fits.PrimaryHDU)\n    assert isinstance(wfits[1], fits.ImageHDU)\n", "def test_to_fits_2():\n    \"\"\"\n    Test to_fits() with SIP distortion.\n    \"\"\"\n    fits_name = get_pkg_data_filename('data/sip.fits')\n    w = wcs.WCS(fits_name)\n    wfits = w.to_fits()\n    assert isinstance(wfits, fits.HDUList)\n    assert isinstance(wfits[0], fits.PrimaryHDU)\n    assert isinstance(wfits[1], fits.ImageHDU)\n    assert isinstance(wfits[2], fits.BinTableHDU)\n", "def test_axis_type_names():\n    \"\"\"\n    Test the axis_type_names property.\n    \"\"\"\n    w = wcs.WCS(naxis=3)\n    w.wcs.ctype = ['RA---TAN', 'DEC--TAN', 'VEL-HEL']\n    w.wcs.cname = ['Right Ascension', 'Declination', '']\n    assert w.axis_type_names == ['Right Ascension', 'Declination', 'VEL']\n", "def test_sip_with_altkey_to_fits():\n    \"\"\"\n    Test that when creating a WCS object using a key, CTYPE with\n    that key is looked at and not the primary CTYPE.\n    Test that the correct CTYPE is written to the header using to_fits()\n    fix for #5443.\n    \"\"\"\n    with fits.open(get_pkg_data_filename('data/sip.fits')) as f:\n        w = wcs.WCS(f[0].header)\n    # create a header with two WCSs.\n    h1 = w.to_header(relax=True, key='A')\n    h2 = w.to_header(relax=False)\n    h1['CTYPE1A'] = \"RA---SIN-SIP\"\n    h1['CTYPE2A'] = \"DEC--SIN-SIP\"\n    h1.update(h2)\n    w = wcs.WCS(h1, key='A')\n    wfits = w.to_fits(key='A')\n    assert wfits[0].header['CTYPE1A'] == \"RA---SIN-SIP\"\n    assert wfits[0].header['CTYPE2A'] == \"DEC--SIN-SIP\"\n", "def test_to_fits_2():\n    \"\"\"\n    Test to_fits() with LookupTable distortion and alt key.\n    \"\"\"\n    fits_name = get_pkg_data_filename('data/dist.fits')\n    w = wcs.WCS(fits_name)\n    wfits = w.to_fits(key='A')\n    assert isinstance(wfits, fits.HDUList)\n    assert isinstance(wfits[0], fits.PrimaryHDU)\n    assert isinstance(wfits[1], fits.ImageHDU)\n    # Add assertions to check the WCS info in the fits header\n"], "sample_41": ["def test_empty_formset_with_initial(self):\n    \"\"\"Empty forms are still allowed if initial data is provided.\"\"\"\n    initial = [\n        {'name': 'Gin Tonic'},\n        {'name': 'Bloody Mary'},\n    ]\n    LimitedFavoriteDrinkFormSet = formset_factory(FavoriteDrinkForm, extra=0)\n    formset = LimitedFavoriteDrinkFormSet(initial=initial)\n    self.assertHTMLEqual(\n        '\\n'.join(str(form) for form in formset.forms),\n        \"\"\"<tr><th><label for=\"id_form-0-name\">Name:</label></th>", "def test_empty_form_initial_data(self):\n    \"\"\"\n    An empty form within a formset can have initial data.\n    \"\"\"\n    initial_data = {'name': 'Coca Cola'}\n    formset = FavoriteDrinksFormSet(initial=[initial_data])\n    self.assertEqual(formset.empty_form.initial, initial_data)\n", "def test_empty_formset_has_changed(self):\n    \"\"\"An empty formset shouldn't have changed.\"\"\"\n    ChoiceFormSet = formset_factory(Choice)\n    formset = ChoiceFormSet()\n    self.assertFalse(formset.has_changed())\n", "def test_formset_with_initial_data_validation(self):\n    initial = [{'choice': 'Calexico', 'votes': '100'}]\n    ChoiceFormSet = formset_factory(Choice)\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>", "def test_min_num_invalid_form(self):\n    \"\"\"min_num validation is triggered even if a form is invalid.\"\"\"\n    initial = [\n        {'choice': 'Zero', 'votes': 0},\n        {'choice': 'One', 'votes': 1},\n    ]\n    data = {\n        'choices-TOTAL_FORMS': '3',\n        'choices-INITIAL_FORMS': '2',\n        'choices-MIN_NUM_FORMS': '2',\n        'choices-MAX_NUM_FORMS': '1000',\n        'choices-0-choice': 'Zero',\n        'choices-0-votes': '0',\n        'choices-1-choice': 'One',\n        'choices-1-votes': 'invalid',\n        'choices-2-choice': '',\n        'choices-2-votes': '',\n    }\n    ChoiceFormSet = formset_factory(Choice, min_num=2, validate_min=True)\n    formset = ChoiceFormSet(data, auto_id=False, prefix='choices', initial=initial)\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(formset.non_form_errors(), ['Please submit at least 2 forms.'])\n"], "sample_132": ["def test_closest_points():\n    points = [(0, 0), (1, 0), (0, 1), (1, 1), (2, 2)]\n    assert closest_points(*points) == {(Point2D(0, 0), Point2D(1, 0)), (Point2D(0, 1), Point2D(1, 1))}\n    points = [(0, 0), (1, 0), (1, 1), (2, 2)]\n    assert closest_points(*points) == {(Point2D(1, 0), Point2D(1, 1))}\n", "def test_closest_and_farthest_points():\n    points = [Point2D(1, 1), Point2D(1, 2), Point2D(3, 1), Point2D(-5, 2), Point2D(15, 4)]\n    assert closest_points(*points) == {(Point2D(1, 1), Point2D(1, 2))}\n    assert farthest_points(*points) == {(Point2D(-5, 2), Point2D(15, 4))}\n", "def test_closest_points():\n    points = [Point2D(1, 1), Point2D(1, 2), Point2D(3, 1), Point2D(-5, 2), Point2D(15, 4)]\n    assert closest_points(*points) == {(Point2D(1, 1), Point2D(1, 2))}\n", "def test_closest_points():\n    points = [(1, 1), (1, 2), (3, 1), (-5, 2), (15, 4)]\n    assert closest_points(*points) == {(Point2D(1, 1), Point2D(1, 2))}\n    raises(ValueError, lambda: closest_points(Point(0, 0)))\n", "def test_closest_points():\n    points = [(1, 2), (4, 6), (2, 3), (-1, -1), (3, -4)]\n    assert closest_points(*points) == {(Point2D(-1, -1), Point2D(1, 2))}\n"], "sample_152": ["def test_array_addition_subtraction():\n    for ArrayType in array_types:\n        A = ArrayType([[1, 2], [3, 4]])\n        B = ArrayType([[5, 6], [7, 8]])\n        assert A + B == ArrayType([[6, 8], [10, 12]])\n        assert A - B == ArrayType([[-4, -4], [-4, -4]])\n        raises(ValueError, lambda: A + ArrayType([[1, 2], [3, 4, 5]]))\n        raises(ValueError, lambda: A - ArrayType([[1, 2], [3, 4, 5]]))\n", "def test_array_addition_subtraction():\n    for ArrayType in array_types:\n        A = ArrayType([[1, 2], [3, 4]])\n        B = ArrayType([[5, 6], [7, 8]])\n        assert A + B == ArrayType([[6, 8], [10, 12]])\n        assert A - B == ArrayType([[-4, -4], [-4, -4]])\n\n        # Test addition and subtraction with scalar\n        scalar = 2\n        assert A + scalar == ArrayType([[3, 4], [5, 6]])\n        assert A - scalar == ArrayType([[-1, 0], [1, 2]])\n\n        # Test addition and subtraction with different shaped arrays\n        C = ArrayType([[1, 2, 3], [4, 5, 6]])\n        raises(ValueError, lambda: A + C)\n        raises(ValueError, lambda: A - C)\n", "def test_array_slicing():\n    for ArrayType in array_types:\n        test_array = ArrayType([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n        assert test_array[0, :] == Array([1, 2, 3, 4, 5])\n        assert test_array[1, :] == Array([6, 7, 8, 9, 10])\n        assert test_array[:, 0] == Array([1, 6])\n        assert test_array[:, 2] == Array([3, 8])\n        assert test_array[0, 0:2] == Array([1, 2])\n        assert test_array[1, 2:] == Array([8, 9, 10])\n        assert test_array[:, 1:4] == Array([[2, 3, 4], [7, 8, 9]])\n", "def test_issue_20223():\n    A = Array([[1, 2], [3, 4]])\n    B = Array([[5, 6], [7, 8]])\n    assert A + B == Array([[6, 8], [10, 12]])\n    assert A - B == Array([[-4, -4], [-4, -4]])\n    assert A * 2 == Array([[2, 4], [6, 8]])\n    assert 2 * A == Array([[2, 4], [6, 8]])\n    assert A / 2 == Array([[0.5, 1.0], [1.5, 2.0]])\n    assert -A == Array([[-1, -2], [-3, -4]])\n", "def test_issue_20223():\n    for array_type in array_types:\n        A = array_type([[1, 2], [3, 4]])\n        B = array_type([[5, 6], [7, 8]])\n        assert A + B == array_type([[6, 8], [10, 12]])\n        assert A - B == array_type([[-4, -4], [-4, -4]])\n"], "sample_51": ["def test_directory_index_template_content(self):\n    response = self.client.get(\"/%s/\" % self.prefix)\n    self.assertContains(response, \"<title>Index of /</title>\")\n    self.assertContains(response, \"<h1>Index of /</h1>\")\n    self.assertContains(response, \"../\")\n    self.assertContains(response, \"<a href=\\\"subdir/\\\">subdir/</a>\")\n", "    def test_directory_index_template(self):\n        response = self.client.get(\"/%s/\" % self.prefix)\n        self.assertContains(response, \"Index of ./\")\n        self.assertContains(response, \"<h1>Index of ./</h1>\")\n        self.assertContains(response, \"<meta http-equiv=\\\"Content-type\\\" content=\\\"text/html; charset=utf-8\\\">\")\n        self.assertContains(response, \"<meta http-equiv=\\\"Content-Language\\\" content=\\\"en-us\\\">\")\n        self.assertContains(response, \"<meta name=\\\"robots\\\" content=\\\"NONE,NOARCHIVE\\\">\")\n        self.assertContains(response, \"<title>Index of ./</title>\")\n", "def test_index_subdir_dot_file(self):\n    response = self.client.get(\"/%s/subdir/.hidden\" % self.prefix)\n    self.assertEqual(response.status_code, 404)\n", "def test_index_no_slash_with_show_indexes(self):\n    with override_settings(STATIC_URL=f'/{self.prefix}/'):\n        response = self.client.get(\"/%s\" % self.prefix)\n        self.assertContains(response, \"Index of /\")\n        self.assertIn(\"subdir/\", response.context[\"file_list\"])\n", "    def test_content_length(self):\n        \"The static view should set the Content-Length header correctly\"\n        file_name = \"file.txt\"\n        response = self.client.get(\"/%s/%s\" % (self.prefix, file_name))\n        response_content = b\"\".join(response)\n        file_path = path.join(media_dir, file_name)\n        with open(file_path, \"rb\") as fp:\n            self.assertEqual(len(fp.read()), int(response.headers[\"Content-Length\"]))\n"], "sample_134": ["def test_cbrt():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    f = lambdify((a,), Cbrt(a), 'numpy')\n    assert abs(f(27) - 3) < 1e-16\n", "def test_cbrt():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    f = lambdify((a,), Cbrt(a), 'numpy')\n    assert abs(f(27) - 3) < 1e-16\n", "def test_cbrt():\n    if not np:\n        skip(\"NumPy not installed\")\n    assert abs(lambdify((a,), Cbrt(a), 'numpy')(8) - 2) < 1e-16\n", "def test_cbrt():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    f = lambdify((a,), cbrt(a), 'numpy')\n    assert abs(f(8) - 2) < 1e-16\n\n    f = lambdify((a,), Cbrt(a), 'numpy')\n    assert abs(f(8) - 2) < 1e-16\n", "def test_codegen_cbrt():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    e = Cbrt(a)\n    f = lambdify((a,), e, 'numpy')\n\n    a_ = np.array([0, 1, 8, 27])\n    assert np.allclose(f(a_), np.cbrt(a_))\n"], "sample_55": ["def test_call_command_with_incorrect_type_for_option(self):\n    msg = \"argument --integer: invalid int value: 'invalid'\"\n    with self.assertRaisesMessage(TypeError, msg):\n        management.call_command(\"dance\", integer=\"invalid\")\n", "def test_no_translations_with_translations_activated(self):\n    \"\"\"\n    When the Command handle method is decorated with @no_translations,\n    translations are still activated outside the command.\n    \"\"\"\n    current_locale = translation.get_language()\n    with translation.override(\"pl\"):\n        result = management.call_command(\"no_translations\")\n        self.assertIsNone(result)\n    self.assertEqual(translation.get_language(), \"pl\")\n", "    def test_required_subparser_options(self):\n        out = StringIO()\n        management.call_command(\"subparser_required_options\", \"foo\", 12, bar=\"baz\", stdout=out)\n        self.assertIn(\"bar=baz\", out.getvalue())\n", "    def test_handle_label_method(self):\n        class TestCommand(LabelCommand):\n            label = \"custom_label\"\n\n                return f\"Handling {label} with options {options}\"\n\n        out = StringIO()\n        management.call_command(\"test_command\", \"label1\", \"--option\", \"value\", stdout=out)\n        self.assertIn(\"Handling label1 with options {'option': 'value'}\", out.getvalue())\n", "def test_call_command_with_required_parameters_in_mixed_args_options(self):\n    out = StringIO()\n    management.call_command(\n        \"required_option\", \"foo\", \"--needme2=bar\", stdout=out\n    )\n    self.assertIn(\"need_me\", out.getvalue())\n    self.assertIn(\"needme2\", out.getvalue())\n"], "sample_49": ["def test_reset_only_custom_loader(self, mock_reset):\n    autoreload.reset_loaders()\n    mock_reset.assert_called_once()\n", "def test_reset_loaders_non_django_template(self, mock_reset):\n    with self.settings(\n        TEMPLATES=[{\n            'BACKEND': 'django.template.backends.jinja2.Jinja2',\n            'DIRS': [EXTRA_TEMPLATES_DIR],\n        }]\n    ):\n        autoreload.reset_loaders()\n        mock_reset.assert_not_called()\n", "def test_no_template_directories(self, mock_reset):\n    self.assertIsNone(autoreload.template_changed(None, Path(__file__)))\n    mock_reset.assert_not_called()\n", "def test_custom_loader_reset(self, mock_reset):\n    autoreload.reset_loaders()\n    mock_reset.assert_called_once()\n", "def test_django_template_changed_in_directory(self, mock_reset):\n    template_path = Path(__file__).parent / 'django/template/loaders/index.html'\n    self.assertTrue(autoreload.template_changed(None, template_path))\n    mock_reset.assert_called_once()\n"], "sample_13": ["def test_parsing_asctime_single_digit_day(self, mocked_datetime):\n    mocked_datetime.side_effect = datetime\n    mocked_datetime.utcnow = mock.Mock()\n    utcnow = datetime(2020, 11, 6, 8, 49, 37)\n    mocked_datetime.utcnow.return_value = utcnow\n    parsed = parse_http_date('Sun Nov 6 08:49:37 1994')\n    self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(1994, 11, 6, 8, 49, 37))\n", "    def test_ip_address(self):\n        self.assertIs(\n            url_has_allowed_host_and_scheme('http://192.168.0.1/', allowed_hosts={'192.168.0.1'}),\n            True,\n        )\n", "    def test_parsing_year_greater_than_50_years_in_future(self):\n        parsed = parse_http_date('Sun Nov  6 08:49:37 2068')\n        self.assertEqual(datetime.utcfromtimestamp(parsed), datetime(1968, 11, 6, 8, 49, 37))\n", "    def test_parsing_invalid_date(self, mocked_datetime):\n        mocked_datetime.side_effect = datetime\n        invalid_dates = (\n            'Mon, 01 Jan 2007 01:54:21',  # Missing timezone\n            'Mon, 01 Jan 2007 01:54:21 GMTT',  # Invalid timezone\n            'Mon, 01 Jan 2007 01:54:21 UTC',  # Invalid timezone\n            'Mon, 32 Jan 2007 01:54:21 GMT',  # Invalid day\n            'Mon, 01 Feb 2007 25:54:21 GMT',  # Invalid hour\n            'Mon, 01 Feb 2007 01:60:21 GMT',  # Invalid minute\n            'Mon, 01 Feb 2007 01:54:61 GMT',  # Invalid second\n            'Mon, 01 Feb 2007 01:54:21 GM',  # Invalid timezone\n            'Mon, 01 Feb 2007 01:54:21 G',  # Invalid timezone\n            'Mon, 01 Feb 2007 01:54:21',  # Missing timezone\n            'Mon, 01 Feb 2007 01:54:21 UT',  # Invalid timezone\n            'Mon, 01 Feb 2007 01:54:21 U',  # Invalid timezone\n            'Mon, 01 Feb 2007 01:54:21 Z',  # Invalid timezone\n            '2007-01-01T01:54:21Z',  # Invalid format\n            '01/01/2007 01:54", "    def test_url_with_backslashes_in_netloc(self):\n        url = r'http://test\\server@example.com'\n        self.assertIs(url_has_allowed_host_and_scheme(url, allowed_hosts={'testserver'}), True)\n"], "sample_48": ["    def test_references_field_by_limit_choices_to(self):\n        operation = FieldOperation(\n            'Model', 'field',\n            models.ForeignKey('Other', models.CASCADE, limit_choices_to={'field': 'value'})\n        )\n        self.assertIs(operation.references_field('Other', 'field', 'migrations'), True)\n        self.assertIs(operation.references_field('Other', 'whatever', 'migrations'), False)\n        self.assertIs(operation.references_field('Missing', 'whatever', 'migrations'), False)\n", "def test_references_field_by_through_attr(self):\n    operation = FieldOperation('Model', 'field', models.ManyToManyField('Other', through_fields=('from', 'to')))\n    self.assertIs(operation.references_field('Model', 'from', 'migrations'), True)\n    self.assertIs(operation.references_field('Model', 'to', 'migrations'), True)\n    self.assertIs(operation.references_field('Other', 'from', 'migrations'), False)\n    self.assertIs(operation.references_field('Other', 'to', 'migrations'), False)\n", "    def test_references_field_by_limit_choices_to(self):\n        operation = FieldOperation(\n            'Model', 'field', models.ForeignKey('Other', models.CASCADE, limit_choices_to={'field': 'value'})\n        )\n        self.assertIs(operation.references_field('Other', 'field', 'migrations'), True)\n        self.assertIs(operation.references_field('Other', 'other_field', 'migrations'), False)\n        self.assertIs(operation.references_field('Missing', 'whatever', 'migrations'), False)\n", "    def test_references_field_many_to_many(self):\n        operation = FieldOperation('Model', 'field', models.ManyToManyField('Other'))\n        self.assertIs(operation.references_field('Model', 'field', 'migrations'), True)\n        self.assertIs(operation.references_field('Other', 'whatever', 'migrations'), True)\n        self.assertIs(operation.references_field('Missing', 'whatever', 'migrations'), False)\n", "def test_alter_field_constraint(self):\n    \"\"\"\n    Tests the AlterField operation preserves constraints.\n    \"\"\"\n    project_state = self.set_up_test_model(\"test_alflcon\")\n    # Add a constraint\n    constraint = models.CheckConstraint(check=models.Q(pink__gt=2), name=\"test_alflcon_pony_pink_gt_2\")\n    add_constraint_operation = migrations.AddConstraint(\"Pony\", constraint)\n    add_constraint_operation.state_forwards(\"test_alflcon\", project_state)\n    self.assertEqual(len(project_state.models[\"test_alflcon\", \"pony\"].options['constraints']), 1)\n    # Test the state alteration\n    operation = migrations.AlterField(\"Pony\", \"pink\", models.IntegerField(null=True))\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_alflcon\", new_state)\n    # Constraint is preserved\n    self.assertEqual(len(new_state.models[\"test_alflcon\", \"pony\"].options['constraints']), 1)\n"], "sample_12": ["def test_alter_field_to_not_null_with_default(self, mocked_ask_method):\n    \"\"\"\n    #23609 - Tests autodetection of nullable to non-nullable alterations.\n    \"\"\"\n    changes = self.get_changes([self.author_name_null], [self.author_name_default])\n    self.assertEqual(mocked_ask_method.call_count, 1)\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True)\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default='Ada Lovelace')\n", "def test_add_blank_null_textfield_and_charfield(self):\n    \"\"\"\n    #23405 - Adding a NULL and blank `CharField` or `TextField`\n    should not prompt for a default.\n    \"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_with_biography_null_blank])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0)\n", "def test_alter_blank_textfield_and_charfield(self):\n    \"\"\"\n    #23405 - Altering a NOT NULL and blank `CharField` or `TextField`\n    should not prompt for a default.\n    \"\"\"\n    changes = self.get_changes([self.author_with_biography_non_blank], [self.author_with_biography_blank])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\", \"AlterField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0)\n", "    def test_alter_blank_textfield_and_charfield(self):\n        \"\"\"\n        #23405 - Altering a `CharField` or `TextField` to be NOT NULL and blank\n        without default should not prompt for a default.\n        \"\"\"\n        changes = self.get_changes([self.author_with_biography_non_blank], [self.author_with_biography_blank])\n        # Right number/type of migrations?\n        self.assertNumberMigrations(changes, 'testapp', 1)\n        self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\", \"AlterField\"])\n        self.assertOperationAttributes(changes, 'testapp', 0, 0)\n", "def test_create_model_with_multiple_managers(self):\n    \"\"\"Test creation of new model with multiple managers already defined.\"\"\"\n    author = ModelState('otherapp', 'Author', [\n        ('id', models.AutoField(primary_key=True)),\n        ('name', models.CharField(max_length=200)),\n    ], options={'default_manager_name': 'custom_manager', 'base_manager_name': 'custom_base_manager'})\n    changes = self.get_changes([], [author])\n    # Right number of migrations?\n    self.assertEqual(len(changes['otherapp']), 1)\n    # Right number of actions?\n    migration = changes['otherapp'][0]\n    self.assertEqual(len(migration.operations), 1)\n    # Right actions order?\n    self.assertOperationTypes(changes, 'otherapp', 0, ['CreateModel'])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, name='Author', options={\n        'default_manager_name': 'custom_manager',\n        'base_manager_name': 'custom_base_manager',\n    })\n"], "sample_6": ["    def test_validate(self):\n        valid_usernames = ['joe', 'Rene', '0123456789', 'user.name', 'user@name', 'user+name', 'user-name', 'user_name']\n        invalid_usernames = ['\u00e9', 'user name', 'user,name', 'user/name', 'user:name', 'user;name']\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_validate(self):\n        valid_usernames = ['joe', 'Rene', 'user.name', 'user+name', 'user-name', 'user_name', 'user@name']\n        invalid_usernames = ['user/name', 'user:name', 'user name', 'user#name', 'user=name', 'user,name']\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_ascii_validator(self):\n        valid_usernames = ['joe', 'John123', 'user.name', 'user@email', 'user+name', 'user-name', 'user_name']\n        invalid_usernames = ['Ren\u00e9', '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f', 'user#name']\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_ascii_validator(self):\n        valid_usernames = ['joe', 'Joe123', 'joe.smith', 'joe-smith', 'joe_smith', 'joe@example.com', 'joe+smith', 'joe+smith-example']\n        invalid_usernames = ['Ren\u00e9', '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f', 'nonbreaking\\u00A0space', 'en\\u2013dash', 'trailingnewline\\u000A']\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n", "    def test_ascii_validator(self):\n        valid_usernames = ['joe', 'Rene', 'B3T4', 'user.name', 'user@name', 'user+name', 'user-name', 'user_name']\n        invalid_usernames = ['joe!', 'Ren\u00e9', '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f', 'user\\u200Bspace', 'user\\u00A0space', 'user\\u2013dash']\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n"], "sample_153": ["def test_pretty_print_unicode_d():\n    assert upretty(d[0]) == '(0|0)'\n    assert upretty(d[1]) == '(i_N|k_N)'\n    assert upretty(d[4]) == '(a) (i_N|k_N)'\n    assert upretty(d[5]) == '(a) (i_N|k_N) + (-b) (j_N|k_N)'\n    assert upretty(d[8]) == upretty_d_7\n    assert upretty(d[10]) == '(cos(a)) (i_C|k_N) + (-sin(a)) (j_C|k_N)'\n", "def test_pretty_printing_unicode_d():\n    assert upretty(d[0]) == '(0|0)'\n    assert upretty(d[1]) == '(i_N|k_N)'\n    assert upretty(d[4]) == '(a) (i_N|k_N)'\n    assert upretty(d[5]) == '(a) (i_N|k_N) + (-b) (j_N|k_N)'\n    assert upretty(d[8]) == '(N.j|N.k) + (C.x**2 - \u222bf(b) db) (N.k|N.k)'\n", "def test_issue_23059():\n    from sympy import symbols, sin, cos, pi, UnevaluatedExpr\n\n    delop = Del()\n    CC_   = CoordSys3D(\"C\")\n    y     = CC_.y\n    xhat  = CC_.i\n\n    t = symbols(\"t\")\n    ten = symbols(\"10\", positive=True)\n    eps, mu = 4*pi*ten**(-11), ten**(-5)\n\n    By = 2 * ten**(-4) * cos(ten**5 * t) * sin(ten**(-3) * y)\n    vecB = By * CC_.j\n    vecE = (1/eps) * Integral(delop.cross(vecB/mu).doit(), t)\n    vecE = vecE.doit()\n\n    vecB_str = \"\"\"\\", "def test_pretty_printing_ascii_d_10():\n    assert pretty(d[10]) == 'cos(a) (i_C|k_N) + (-1)*sin(a) (j_C|k_N)'\n", "def test_pretty_print_unicode_del():\n    assert upretty(Del()) == '\u2207'\n    assert upretty(Del(C)) == '\u2207_C'\n"], "sample_140": ["def test_point_acc():\n    q = dynamicsymbols('q')\n    qd = dynamicsymbols('q', 1)\n    qdd = dynamicsymbols('q', 2)\n    N = ReferenceFrame('N')\n    P = Point('P')\n    P.set_vel(N, qd * N.x)\n    assert P.acc(N) == qdd * N.x\n", "def test_point_acc():\n    q, q2 = dynamicsymbols('q q2')\n    qd, q2d = dynamicsymbols('q q2', 1)\n    qdd, q2dd = dynamicsymbols('q q2', 2)\n    N = ReferenceFrame('N')\n    P = Point('P')\n    P.set_vel(N, qd * N.x + q2d * N.y)\n    assert P.acc(N) == qdd * N.x + q2dd * N.y\n    P.set_acc(N, qdd * N.x + q2dd * N.y)\n    assert P.acc(N) == qdd * N.x + q2dd * N.y\n", "def test_auto_point_vel_different_frames():\n    q1, q2, u1, u2 = dynamicsymbols('q1 q2 u1 u2')\n    N = ReferenceFrame('N')\n    B = ReferenceFrame('B')\n    P = Point('P')\n    P.set_vel(N, u1 * N.x)\n    P1 = Point('P1')\n    P1.set_pos(P, q2 * B.y)\n    P1.set_vel(B, u2 * B.z)\n    assert P1.vel(N) == q2.diff(t) * (B.y).express(N) + u2 * B.z.express(N) + u1 * N.x\n", "def test_auto_point_vel_inconsistent_relative_positions():\n    t = dynamicsymbols._t\n    q1, q2, u1 = dynamicsymbols('q1, q2, u1')\n    N = ReferenceFrame('N')\n    P = Point('P')\n    P.set_vel(N, u1 * N.x)\n    P1 = Point('P1')\n    P1.set_pos(P, q2 * N.y)\n    P2 = Point('P2')\n    P2.set_pos(P1, q1 * N.x)\n    P1.set_pos(P2, q1 * N.x + q2 * N.y)  # Inconsistent with previous definition\n    raises(ValueError, lambda: P1.vel(N))  # Inconsistent relative positions\n", "def test_point_vel_non_expressible_position():\n    N = ReferenceFrame('N')\n    A = ReferenceFrame('A')\n    B = ReferenceFrame('B')\n    A.set_ang_vel(N, 5 * B.y)\n\n    p = Point('p')\n    q = Point('q')\n    q.set_pos(p, A.x)  # q's position is not expressible in N or B\n\n    with raises(ValueError):\n        q.vel(N)\n    with raises(ValueError):\n        q.vel(B)\n"], "sample_19": ["    def test_get_cleansed_multivaluedict(self):\n        request = self.rf.post('/some_url/', self.breakfast_data)\n        request.sensitive_post_parameters = ['sausage-key', 'bacon-key']\n        reporter_filter = SafeExceptionReporterFilter()\n        cleansed_post = reporter_filter.get_cleansed_multivaluedict(request, request.POST)\n        self.assertEqual(cleansed_post['sausage-key'], reporter_filter.cleansed_substitute)\n        self.assertEqual(cleansed_post['bacon-key'], reporter_filter.cleansed_substitute)\n        self.assertEqual(cleansed_post['baked-beans-key'], 'baked-beans-value')\n        self.assertEqual(cleansed_post['hash-brown-key'], 'hash-brown-value')\n", "    def test_sensitive_request(self):\n        self.verify_safe_response(sensitive_view, check_for_vars=False)\n", "def test_sensitive_function_arguments_debug_false(self):\n    \"\"\"\n    Sensitive variables don't leak in the sensitive_variables decorator's\n    frame, when those variables are passed as arguments to the decorated\n    function, even when DEBUG is False.\n    \"\"\"\n    self.verify_safe_response(sensitive_args_function_caller, check_for_POST_params=False)\n    self.verify_safe_email(sensitive_args_function_caller, check_for_POST_params=False)\n", "def test_sensitive_variables_method(self):\n    request = self.rf.post('/some_url/', self.breakfast_data)\n    request.sensitive_post_parameters = ['sausage-key', 'bacon-key']\n\n    @sensitive_variables()\n        pass\n\n    decorated_func('worcestershire')\n\n    with self.assertLogs('django.request', 'ERROR'):\n        response = sensitive_method_view(request)\n\n    self.assertNotContains(response, 'worcestershire', status_code=500)\n    self.assertNotContains(response, 'sausage-value', status_code=500)\n    self.assertNotContains(response, 'bacon-value', status_code=500)\n", "    def sensitive_func(self, password):\n        pass\n"], "sample_119": ["def test_Sum():\n    assert mcode(Sum(1/x**n, (n, 1, oo))) == \"Hold[Sum[1/x^n, {n, 1, Infinity}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**k, (k, 1, n))) == \"Hold[Sum[x^k, {k, 1, n}]]\"\n    assert mcode(Sum(sin(k), (k, 0, 2*pi))) == \"Hold[Sum[Sin[k], {k, 0, 2*Pi}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**k, (k, 0, n))) == \"Hold[Sum[x^k, {k, 0, n}]]\"\n    assert mcode(Sum(1/k, (k, 1, oo))) == \"Hold[Sum[1/k, {k, 1, Infinity}]]\"\n", "def test_Sum():\n    assert mcode(Sum(x**n, (n, 0, m))) == \"Hold[Sum[x^n, {n, 0, m}]]\"\n    assert mcode(Sum(x**n, (n, 1, m), (m, 1, k))) == \"Hold[Sum[x^n, {n, 1, m}, {m, 1, k}]]\"\n", "def test_Sum():\n    assert mcode(Sum(1/k, (k, 1, oo))) == \"Hold[Sum[1/k, {k, 1, Infinity}]]\"\n    assert mcode(Sum(x**k, (k, 0, n))) == \"Hold[Sum[x^k, {k, 0, n}]]\"\n    assert mcode(Sum(x**k*y**(n-k), (k, 0, n))) == \"Hold[Sum[x^k*y^(n - k), {k, 0, n}]]\"\n"], "sample_133": ["def test_custom_codegen_with_printer():\n    x, y = symbols('x y')\n    expr = x**y\n\n    printer = CustomPrinter()\n    gen = C99CodeGen(printer=printer)\n\n    expected = (\n        '#include \"expr.h\"\\n'\n        '#include <math.h>\\n'\n        'double expr(double x, double y) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastpow(x, y);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n\n    result = codegen(('expr', expr), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    assert source == expected\n", "def test_c_with_custom_printer():\n    x, y = symbols('x y')\n    expr = x**y\n\n    printer = CustomPrinter()\n    gen = C99CodeGen(printer=printer,\n                     preprocessor_statements=['#include \"fastpow.h\"'])\n\n    expected = (\n        '#include \"expr.h\"\\n'\n        '#include \"fastpow.h\"\\n'\n        'double expr(double x, double y) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastpow(x, y);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n\n    result = codegen(('expr', expr), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    assert source == expected\n", "def test_c_with_custom_printer():\n    x, y = symbols('x y')\n    expr = x ** y\n    gen = C99CodeGen(printer=CustomPrinter())\n    result = codegen(('expr', expr), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    expected = (\n        '#include \"expr.h\"\\n'\n        '#include <math.h>\\n'\n        'double expr(double x, double y) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastpow(x, y);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n    assert source == expected\n", "def test_custom_printer_codegen():\n    from sympy.printing.ccode import C99CodePrinter\n\n    class CustomPrinter(C99CodePrinter):\n            return \"fastpow({}, {})\".format(self._print(expr.base),\n                                            self._print(expr.exp))\n\n    x, y = symbols('x y')\n    expr = x**y\n\n    printer = CustomPrinter()\n    gen = C99CodeGen(printer=printer)\n\n    expected = (\n        '#include \"expr.h\"\\n'\n        'double expr(double x, double y) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastpow(x, y);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n\n    result = codegen(('expr', expr), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    assert source == expected\n", "def test_c_with_printer():\n    #issue 13586\n    from sympy.printing.ccode import C99CodePrinter\n    class CustomPrinter(C99CodePrinter):\n            return \"fastpow({}, {})\".format(self._print(expr.base),\n                                            self._print(expr.exp))\n\n    x, y = symbols('x y')\n    expr = x**y\n\n    printer = CustomPrinter()\n    gen = C99CodeGen(printer=printer)\n\n    expected = (\n        '#include \"expr.h\"\\n'\n        '#include <math.h>\\n'\n        'double expr(double x, double y) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastpow(x, y);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n\n    result = codegen(('expr', expr), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    assert source == expected\n"], "sample_148": ["def test_Abs_nseries():\n    x = Symbol('x')\n    assert Abs(x).nseries(x, n=2) == x + Order(x**2)\n\n    y = Symbol('y', negative=True)\n    assert Abs(y).nseries(y, n=2) == -y + Order(y**2)\n\n    z = Symbol('z', positive=True)\n    assert Abs(z).nseries(z, n=2) == z + Order(z**2)\n", "def test_zero_finite_assumptions():\n    z = Symbol('z', zero=True)\n    nf = Symbol('nonfinite', finite=False)\n\n    assert re(z).is_zero is True\n    assert im(z).is_zero is True\n    assert Abs(z).is_zero is True\n    assert sign(z).is_zero is True\n\n    assert re(nf).is_zero is None\n    assert im(nf).is_zero is None\n    assert Abs(nf).is_zero is None\n    assert sign(nf).is_zero is None\n", "def test_real_assumptions():\n    ri = Symbol('realimaginary', real=True, imaginary=True)\n    nr = Symbol('nonreal', real=False, finite=True)\n    ni = Symbol('nonimaginary', imaginary=False)\n    z = Symbol('zero', zero=True)\n\n    assert re(ri).is_real is True\n    assert im(ri).is_real is True\n\n    assert re(nr).is_real is None\n    assert im(nr).is_real is None\n\n    assert re(ni).is_real is None\n    assert im(ni).is_real is None\n\n    assert re(z).is_real is True\n    assert im(z).is_real is True\n", "def test_zero_assumptions_extended():\n    # Testing zero assumptions with extended real numbers\n    er = Symbol('extendedreal', extended_real=True, finite=True)\n    assert re(er).is_zero is None\n    assert im(er).is_zero is False\n\n    # Testing zero assumptions with extended complex numbers\n    ec = Symbol('extendedcomplex', complex=True, finite=True)\n    assert re(ec).is_zero is False\n    assert im(ec).is_zero is False\n", "def test_issue_14475():\n    # doesn't raise recursion error\n    a, b, c, d = symbols('a b c d', real=True)\n    A = Matrix([[a, b], [c, d]])\n    assert Abs(A)\n"], "sample_23": ["def test_union_with_different_fields(self):\n    qs1 = Number.objects.filter(num__lte=1).values('num')\n    qs2 = Number.objects.filter(num__gte=2, num__lte=3).values('other_num')\n    with self.assertRaisesMessage(TypeError, \"Merging 'ValuesQuerySet' classes must involve the same values in each case.\"):\n        qs1.union(qs2)\n", "def test_union_with_none(self):\n    qs1 = Number.objects.all()\n    qs2 = Number.objects.none()\n    self.assertNumbersEqual(qs1.union(qs2), list(range(10)))\n    self.assertNumbersEqual(qs2.union(qs1), list(range(10)))\n    self.assertNumbersEqual(qs2.union(qs2), [])\n", "def test_union_with_different_ordering(self):\n    qs1 = Number.objects.filter(num__lte=3).order_by('num')\n    qs2 = Number.objects.filter(num__gte=6).order_by('-num')\n    self.assertNumbersEqual(qs1.union(qs2), [0, 1, 2, 3, 9, 8, 7, 6])\n", "def test_ordering_by_annotation(self):\n    qs1 = Number.objects.filter(num__lte=1)\n    qs2 = Number.objects.filter(num__gte=2, num__lte=3).annotate(double_num=F('num') * 2)\n    self.assertNumbersEqual(qs1.union(qs2).order_by('double_num'), [0, 4, 2, 6])\n", "def test_union_with_values_list_and_filter(self):\n    ReservedName.objects.bulk_create([\n        ReservedName(name='rn1', order=7),\n        ReservedName(name='rn2', order=5),\n        ReservedName(name='rn0', order=6),\n        ReservedName(name='rn9', order=-1),\n    ])\n    qs1 = ReservedName.objects.filter(order__gte=6)\n    qs2 = ReservedName.objects.filter(order__lte=5)\n    union_qs = qs1.union(qs2).filter(order__gt=5)\n    self.assertCountEqual(union_qs.values_list('order', flat=True), [7])\n"], "sample_146": ["def test_Differential():\n    from sympy.diffgeom import Differential\n    b = BaseScalarField(rect, 0)\n    diff_b = Differential(b)\n    assert str(diff_b) == \"d(x)\"\n", "def test_issue_21537():\n    e = 1/sqrt(x**2)\n    assert str(e) == \"1/sqrt(x**2)\"\n", "def test_Transpose():\n    from sympy import Matrix\n    M = Matrix([[x, y], [z, w]])\n    assert str(M.T) == \"Matrix([[x, z], [y, w]]).T\"\n", "def test_ComplexRootOf_printing():\n    assert str(rootof(x**5 + 2*x - 1, 1)) == \"CRootOf(x**5 + 2*x - 1, 1)\"\n", "def test_AppliedPredicate_multiple_arguments():\n    assert sstr(Q.eq(x, y)) == \"Q.eq(x, y)\"\n    assert sstr(Q.ne(x, y, z)) == \"Q.ne(x, y, z)\"\n"], "sample_17": ["    def test_serialize_db_to_string(self, mocked_migrate, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=True)\n            serialized_data = creation.serialize_db_to_string()\n            self.assertIsInstance(serialized_data, str)\n            self.assertIn('\"model\": \"tests.object\"', serialized_data)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n", "    def setUp(self):\n        self.test_connection = get_connection_copy()\n        self.creation = self.test_connection.creation_class(self.test_connection)\n        self.old_database_name = self.test_connection.settings_dict['NAME']\n        with mock.patch.object(self.creation, '_create_test_db'):\n            self.creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n", "    def test_serialize_db_to_string(self, mocked_migrate, mocked_createcachetable, mocked_ensure_connection):\n        Object.objects.create(name='test_object')\n        ObjectReference.objects.create(ref_object=Object.objects.get(name='test_object'))\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=True)\n            serialized_data = creation.serialize_db_to_string()\n            self.assertIn('\"model\": \"app.object\"', serialized_data)\n            self.assertIn('\"model\": \"app.objectreference\"', serialized_data)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n", "    def test_serialize_db_to_string(self, mocked_migrate, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n\n        # Create an object in the database to serialize\n        obj = Object.objects.create(name='Test Object')\n\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=True)\n            serialized_data = creation.serialize_db_to_string()\n            self.assertIn('Test Object', serialized_data)\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n            # Clean up the object\n            obj.delete()\n", "    def test_set_as_test_mirror(self, mocked_migrate, mocked_ensure_connection):\n        primary_settings_dict = {'NAME': 'primary_db_name'}\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        creation.set_as_test_mirror(primary_settings_dict)\n        self.assertEqual(test_connection.settings_dict['NAME'], 'primary_db_name')\n"], "sample_99": ["def test_sparse_metric_brute_force():\n        assert_true(issparse(x) and issparse(y))\n        return x.dot(y.T).A.item()\n\n    X_dense = rng.random_sample((10, 3))\n    X_sparse = csr_matrix(X_dense)\n\n    nbrs = neighbors.NearestNeighbors(n_neighbors=1, algorithm='brute', metric=sparse_metric)\n    nbrs.fit(X_sparse)\n    _, ind_sparse = nbrs.kneighbors(X_sparse)\n\n    nbrs.fit(X_dense)\n    _, ind_dense = nbrs.kneighbors(X_dense)\n\n    assert_array_equal(ind_sparse, ind_dense)\n", "def test_kneighbors_graph_mode_invalid():\n    # Test kneighbors_graph with invalid mode\n    X = np.array([[0, 1], [1.01, 1.], [2, 0]])\n    invalid_mode = 'invalid_mode'\n\n    with pytest.raises(ValueError) as e:\n        neighbors.kneighbors_graph(X, 1, mode=invalid_mode)\n\n    expected_error_msg = (\n        \"Unsupported mode, must be one of 'connectivity', \"\n        \"or 'distance' but got 'invalid_mode' instead\"\n    )\n    assert str(e.value) == expected_error_msg\n", "def test_sparse_metric_kdtree_failure():\n    # Test that a callable metric raises an error when used with kd_tree algorithm\n    X = csr_matrix(rng.rand(10, 10))\n    assert_raises(ValueError, neighbors.NearestNeighbors,\n                  algorithm='kd_tree', metric=sparse_metric)\n", "def test_n_neighbors_zero_or_more_than_n_samples():\n    # Test when n_neighbors is zero or more than the number of samples\n    X = [[1, 1], [2, 2], [3, 3]]\n    y = [0, 1, 2]\n    n_samples = X.shape[0]\n\n    # n_neighbors is zero\n    knn = neighbors.KNeighborsClassifier(n_neighbors=0)\n    assert_raises_regex(ValueError, \"Expected n_neighbors > 0. Got 0\", knn.fit, X, y)\n\n    # n_neighbors is more than the number of samples\n    knn = neighbors.KNeighborsClassifier(n_neighbors=n_samples + 1)\n    assert_raises_regex(ValueError, f\"Expected n_neighbors <= n_samples, but n_samples = {n_samples}, n_neighbors = {n_samples + 1}\", knn.fit, X, y)\n", "def test_sparse_metric_callable_with_kd_tree():\n        assert_true(issparse(x) and issparse(y))\n        return x.dot(y.T).A.item()\n\n    X = np.eye(10)\n    X_csr = csr_matrix(X)\n\n    nbrs = neighbors.NearestNeighbors(n_neighbors=2, algorithm='kd_tree', metric=sparse_metric)\n    with assert_raises(ValueError, msg=\"kd_tree algorithm does not support callable metric '<function sparse_metric at .*'>\"):\n        nbrs.fit(X_csr)\n"], "sample_34": ["def test_default_auto_field_app_config(self):\n    class Model(models.Model):\n        pass\n\n    self.apps.get_app_config('check_framework').default_auto_field = 'django.db.models.BigAutoField'\n\n    self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n", "def test_default_auto_field_overridden_in_app_config(self):\n    class CheckDefaultPKConfigOverride(models.Model):\n        class Meta:\n            app_label = 'check_framework'\n            default_auto_field = 'django.db.models.BigAutoField'\n\n    class Model(models.Model):\n        pass\n\n    self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n", "    def test_ordering_with_expression(self):\n        class Model(models.Model):\n            value = models.IntegerField()\n\n            class Meta:\n                ordering = [models.F('value')]\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n", "def test_auto_created_pk_with_overridden_app_config(self):\n    class Model(models.Model):\n        class Meta:\n            app_label = 'check_framework'\n            app_config = 'check_framework.apps.CheckDefaultPKConfig'\n\n    self.apps.get_app_config(Model._meta.app_label).default_auto_field = 'django.db.models.BigAutoField'\n    self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n", "def test_default_auto_field_setting_app_config(self):\n    class Model(models.Model):\n        pass\n\n    app_config = self.apps.get_app_config('check_framework')\n    app_config.default_auto_field = 'django.db.models.BigAutoField'\n\n    self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n"], "sample_123": ["def test_Float_precision():\n    # Make sure Float inputs for keyword args work\n    assert Float('1.0', dps=Float('15.0'))._prec == 53\n    assert Float('1.0', precision=Float('15.0'))._prec == 15\n    assert type(Float('1.0', precision=Float('15.0'))._prec) == int\n    assert sympify(srepr(Float('1.0', precision=Float('15.0')))) == Float('1.0', precision=15)\n", "def test_Integer_pow_Integer():\n    assert Integer(2)**Integer(3) == Integer(8)\n    assert Integer(2)**Integer(0) == Integer(1)\n    assert Integer(0)**Integer(3) == Integer(0)\n    assert Integer(0)**Integer(0) == Integer(1)\n    assert Integer(-2)**Integer(3) == Integer(-8)\n    assert Integer(-2)**Integer(2) == Integer(4)\n    assert Integer(2)**Integer(-3) == Integer(1)/Integer(8)\n    assert Integer(2)**Integer(-2) == Integer(1)/Integer(4)\n    assert Integer(-2)**Integer(-3) == Integer(-1)/Integer(8)\n    assert Integer(-2)**Integer(-2) == Integer(1)/Integer(4)\n", "def test_issue_10020_additional():\n    assert oo + I is S.ComplexInfinity\n    assert I + oo is S.ComplexInfinity\n    assert -oo + I is S.ComplexInfinity\n    assert I - oo is -S.ComplexInfinity\n    assert oo - I is S.ComplexInfinity\n    assert -oo - I is -S.ComplexInfinity\n    assert I + zoo is S.NaN\n    assert zoo + I is S.NaN\n    assert I - zoo is S.NaN\n    assert zoo - I is S.NaN\n", "def test_issue_10267():\n    assert Integer(1).invert(1) == 1\n    assert Integer(0).invert(1) == 0\n    raises(ZeroDivisionError, lambda: Integer(1).invert(0))\n    raises(ZeroDivisionError, lambda: Integer(1).invert(-1))\n", "def test_Float_comparison():\n    x = Float('1.0', precision=10)\n    y = Float('1.0000000001', precision=20)\n    z = Float('1.0000000001', precision=10)\n\n    assert x < y\n    assert x == z\n    assert not x > y\n    assert not x != z\n    assert x <= y\n    assert x <= z\n    assert x >= z\n    assert not x >= y\n"], "sample_149": ["def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n", "def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n", "def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n", "def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n", "def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) == (2, 2, -1)\n"], "sample_46": ["    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'], lambda column: column.upper(),\n            col_suffixes=['ASC', 'DESC'], opclasses=['text_ops', 'int_ops']\n        )\n", "    def setUp(self):\n        self.reference = IndexColumns(\n            'table', ['first_column', 'second_column'],\n            lambda column: column.upper(),\n            ['ASC', 'DESC'],\n            ['opclass1', 'opclass2'],\n        )\n", "    def setUp(self):\n        compiler = Person.objects.all().query.get_compiler(connection.alias)\n        self.editor = connection.schema_editor()\n        self.expressions = Expressions(\n            table=Person._meta.db_table,\n            expressions=ExpressionList(\n                IndexExpression(F('first_name') + F('last_name')),\n            ).resolve_expression(compiler.query),\n            compiler=compiler,\n            quote_value=self.editor.quote_value,\n        )\n", "    def setUp(self):\n        compiler = Person.objects.all().query.get_compiler(connection.alias)\n        self.editor = connection.schema_editor()\n        self.expressions = Expressions(\n            table=Person._meta.db_table,\n            expressions=ExpressionList(\n                IndexExpression(F('first_name') + ' ' + Value('test')),\n            ).resolve_expression(compiler.query),\n            compiler=compiler,\n            quote_value=self.editor.quote_value,\n        )\n", "    def setUp(self):\n        compiler = Person.objects.all().query.get_compiler(connection.alias)\n        self.editor = connection.schema_editor()\n        self.expressions = Expressions(\n            table=Person._meta.db_table,\n            expressions=ExpressionList(\n                IndexExpression(F('last_name').desc()),\n                IndexExpression(F('first_name')),\n            ).resolve_expression(compiler.query),\n            compiler=compiler,\n            quote_value=self.editor.quote_value,\n        )\n"], "sample_93": ["def test_mktemp_absolute_path_raises_error(tmp_path_factory):\n    with pytest.raises(ValueError, match=\"is not a normalized and relative path\"):\n        tmp_path_factory.mktemp(\"/absolute/path\", numbered=False)\n", "def test_tmp_path_with_read_only_files(pytester: Pytester) -> None:\n    \"\"\"Integration test for #5524 using tmp_path\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import os\n        import stat\n\n            fn = tmp_path / 'foo.txt'\n            fn.write_text('hello')\n            mode = os.stat(str(fn)).st_mode\n            os.chmod(str(fn), mode & ~stat.S_IREAD)\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 0\n    # running a second time and ensure we don't crash\n    result = pytester.runpytest()\n    assert result.ret == 0\n", "def test_tmp_path_with_read_only_files(pytester: Pytester) -> None:\n    \"\"\"Integration test for #5524 with tmp_path\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import os\n        import stat\n\n            fn = tmp_path / 'foo.txt'\n            fn.write_text('hello')\n            mode = os.stat(str(fn)).st_mode\n            os.chmod(str(fn), mode & ~stat.S_IWRITE)\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    assert result.ret == 0\n    # running a second time and ensure we don't crash\n    result = pytester.runpytest()\n    assert result.ret == 0\n", "def test_basetemp_with_read_only_directories(pytester: Pytester) -> None:\n    \"\"\"Integration test for #5524 with read-only directories\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import os\n        import stat\n\n            adir = tmp_path / 'adir'\n            adir.mkdir()\n            fn = adir / 'foo.txt'\n            fn.write_text('hello')\n            mode = os.stat(str(adir)).st_mode\n            os.chmod(str(adir), mode & ~stat.S_IWRITE)\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--basetemp=tmp\")\n    assert result.ret == 0\n    # running a second time and ensure we don't crash\n    result = pytester.runpytest(\"--basetemp=tmp\")\n    assert result.ret == 0\n", "def test_tmp_path_factory_from_config(pytester: Pytester) -> None:\n    \"\"\"Test the from_config method of TempPathFactory.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n            assert tmp_path_factory._given_basetemp is None\n            assert tmp_path_factory._trace == lambda *k: None\n            assert tmp_path_factory._basetemp is None\n    \"\"\"\n    )\n    reprec = pytester.inline_run()\n    reprec.assertoutcome(passed=1)\n"], "sample_16": ["def test_boolean_display_for_field(self):\n    true_display_value = display_for_field(True, models.BooleanField(), self.empty_value)\n    self.assertEqual(true_display_value, 'Yes')\n\n    false_display_value = display_for_field(False, models.BooleanField(), self.empty_value)\n    self.assertEqual(false_display_value, 'No')\n", "def test_display_for_value(self):\n    \"\"\"\n    Test display_for_value function with different types of values\n    \"\"\"\n    test_cases = [\n        (None, self.empty_value),\n        (True, '<img src=\"/static/admin/img/icon-yes.svg\" alt=\"True\">'),\n        (False, '<img src=\"/static/admin/img/icon-no.svg\" alt=\"False\">'),\n        (datetime.min, localize(datetime.min)),\n        (datetime.date.today(), localize(datetime.date.today())),\n        (datetime.time(12, 34, 56), localize(datetime.time(12, 34, 56))),\n        (12345, '12345'),\n        (12345.6789, '12345.6789'),\n        (Decimal('12345.6789'), '12345.6789'),\n        ([1, 2, 3], '1, 2, 3'),\n        ('test', 'test'),\n    ]\n\n    for value, expected_output in test_cases:\n        with self.subTest(value=value):\n            self.assertEqual(display_for_value(value, self.empty_value), expected_output)\n", "def test_quote_and_unquote(self):\n    \"\"\"\n    Regression test for #12914: quote and unquote\n    \"\"\"\n    input_str = ':/_#?;@&=+$,\"[]<>%\\\\\\'\"'\n    quoted_str = quote(input_str)\n    self.assertEqual(unquote(quoted_str), input_str)\n", "def test_quote_and_unquote(self):\n    test_string = ':/?_#@&=+$,\"[]<>%\\\\'\n    quoted_string = quote(test_string)\n    self.assertEqual(unquote(quoted_string), test_string)\n", "def test_boolean_display_for_field(self):\n    display_value = display_for_field(True, models.BooleanField(), self.empty_value)\n    expected = '<img src=\"%sadmin/img/icon-yes.svg\" alt=\"True\" />' % settings.STATIC_URL\n    self.assertHTMLEqual(display_value, expected)\n\n    display_value = display_for_field(False, models.BooleanField(), self.empty_value)\n    expected = '<img src=\"%sadmin/img/icon-no.svg\" alt=\"False\" />' % settings.STATIC_URL\n    self.assertHTMLEqual(display_value, expected)\n\n    display_value = display_for_field(None, models.BooleanField(null=True), self.empty_value)\n    expected = '<img src=\"%sadmin/img/icon-unknown.svg\" alt=\"None\" />' % settings.STATIC_URL\n    self.assertHTMLEqual(display_value, expected)\n"], "sample_82": ["def test_groupby_fillna(array):\n    grouped = array.groupby(\"y\")\n    filled = grouped.fillna(0)\n    expected = array.fillna(0)\n    assert_identical(filled, expected)\n", "def test_groupby_single_value_group(array):\n    grouped = array.groupby(\"x\")\n    single_value_group = grouped.groups[1]\n    expected = array.isel(x=single_value_group)\n    actual = grouped[1]\n    assert_identical(expected, actual)\n", "def test_groupby_multiple_dimensions(dataset):\n    # test groupby with multiple dimensions\n    expected = dataset.groupby(\"x\").sum().groupby(\"y\").mean()\n    actual = dataset.groupby([\"x\", \"y\"]).mean()\n    assert_allclose(expected, actual)\n", "def test_groupby_fillna(array):\n    expected = array.copy()\n    expected.data = np.where(array.data % 2 == 0, array.data, np.nan)\n    actual = array.groupby(\"x\").fillna(0)\n    assert_identical(expected, actual)\n", "def test_groupby_bins_custom_bins():\n    array = xr.DataArray([1, 2, 3, 4, 5, 6], [(\"x\", [1, 1, 2, 2, 3, 3])])\n    expected = xr.DataArray([3, 7], [(\"x_bins\", [pd.Interval(1, 2, closed='right'), pd.Interval(2, 3, closed='right')])])\n    actual = array.groupby_bins(\"x\", bins=[1.5, 2.5])\n    assert_equal(expected, actual)\n"], "sample_20": ["    def test_pointing_to_missing_field(self):\n        class Model(models.Model):\n            class Meta:\n                constraints = [models.UniqueConstraint(fields=['missing_field'], name='name')]\n\n        self.assertEqual(Model.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field 'missing_field'.\",\n                obj=Model,\n                id='models.E012',\n            ),\n        ])\n", "def test_unique_constraint_name_constraints(self):\n    class Model(models.Model):\n        class Meta:\n            constraints = [\n                models.UniqueConstraint(fields=['id'], name='_unique_constraint_name'),\n                models.UniqueConstraint(fields=['id'], name='5unique_constraint_name'),\n            ]\n\n    self.assertEqual(Model.check(databases=self.databases), [\n        Error(\n            \"The constraint name '%sunique_constraint_name' cannot start with \"\n            \"an underscore or a number.\" % prefix,\n            obj=Model,\n            id='models.E032',\n        ) for prefix in ('_', '5')\n    ])\n", "    def test_unique_constraint_with_transform_and_lookup(self):\n        class Model(models.Model):\n            name = models.CharField(max_length=50)\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=[models.functions.Lower('name')],\n                        name='unique_lower_name',\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n", "def test_unique_constraint_pointing_to_fk(self):\n    class Foo(models.Model):\n        pass\n\n    class Bar(models.Model):\n        foo_1 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_1')\n        foo_2 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_2')\n\n        class Meta:\n            constraints = [models.UniqueConstraint(fields=['foo_1_id', 'foo_2'], name='unique_constraint')]\n\n    self.assertEqual(Bar.check(databases=self.databases), [])\n", "def test_check_unique_constraint_pointing_to_fk(self):\n    class Foo(models.Model):\n        pass\n\n    class Bar(models.Model):\n        foo_1 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_1')\n        foo_2 = models.ForeignKey(Foo, on_delete=models.CASCADE, related_name='bar_2')\n\n        class Meta:\n            constraints = [models.UniqueConstraint(fields=['foo_1_id', 'foo_2'], name='unique_constraint')]\n\n    self.assertEqual(Bar.check(databases=self.databases), [])\n"], "sample_136": ["def test_BlockMatrix_transpose():\n    A, B, C, D = [MatrixSymbol(s, 3, 3) for s in 'ABCD']\n    X = BlockMatrix([[A, B], [C, D]])\n    assert X.transpose() == BlockMatrix([[A.T, C.T], [B.T, D.T]])\n", "def test_BlockMatrix_properties():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', m, m)\n    X = BlockMatrix([[A, ZeroMatrix(n, m)], [ZeroMatrix(m, n), B]])\n    assert X.is_structurally_symmetric\n    assert X.equals(BlockMatrix([[A, ZeroMatrix(n, m)], [ZeroMatrix(m, n), B]]))\n    assert not X.equals(BlockMatrix([[A, ZeroMatrix(n, m)], [ZeroMatrix(m, n), Identity(m)]]))\n", "def test_BlockMatrix_real_imag():\n    A = MatrixSymbol('A', n, m, complex=True)\n    B = MatrixSymbol('B', m, l, complex=True)\n    X = BlockMatrix([[A, B]])\n\n    real_X, imag_X = X.as_real_imag()\n    assert real_X == BlockMatrix([[re(A), re(B)]])\n    assert imag_X == BlockMatrix([[im(A), im(B)]])\n", "def test_block_collapse_irregular_block():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', p, m)\n    C = MatrixSymbol('C', n, q)\n    D = MatrixSymbol('D', p, q)\n    X = BlockMatrix([[A, C], [B, D]])\n    assert block_collapse(X + X) == BlockMatrix([[2*A, 2*C], [2*B, 2*D]])\n", "def test_BlockMatrix_as_real_imag():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    real_part, imag_part = X.as_real_imag()\n\n    assert isinstance(real_part, BlockMatrix)\n    assert isinstance(imag_part, BlockMatrix)\n    assert real_part.blocks == Matrix([[A.as_real_imag()[0], B.as_real_imag()[0]], [C.as_real_imag()[0], D.as_real_imag()[0]]])\n    assert imag_part.blocks == Matrix([[A.as_real_imag()[1], B.as_real_imag()[1]], [C.as_real_imag()[1], D.as_real_imag()[1]]])\n"], "sample_91": ["def test_evaluate_xfail_marks_with_invalid_boolean(self, testdir):\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n\n        class InvalidBool:\n                raise TypeError(\"INVALID\")\n\n        @pytest.mark.xfail(InvalidBool(), reason=\"xxx\")\n            pass\n        \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_xfail_marks(item)\n    assert excinfo.value.msg is not None\n    assert \"Error evaluating 'xfail' condition as a boolean\" in excinfo.value.msg\n    assert \"INVALID\" in excinfo.value.msg\n", "def test_dynamic_xfail_multiple_marks(testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(True, reason=\"reason1\")\n        @pytest.mark.xfail(False, reason=\"reason2\")\n            assert 0\n        \"\"\"\n    )\n    result = testdir.runpytest(p, \"-rxX\")\n    result.stdout.fnmatch_lines([\"*XFAIL*test_func*\", \"*reason1*\"])\n", "def test_imperative_skip_on_xfail_test_with_allow_module_level(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail\n            assert 0\n\n            pytest.skip(\"skipping this test\", allow_module_level=True)\n    \"\"\"\n    )\n    result = testdir.runpytest(\"-rsxX\")\n    result.stdout.fnmatch_lines_random(\n        \"\"\"\n        *SKIP*skipping this test*\n        *1 xfailed*1 skipped*\n    \"\"\"\n    )\n", "def test_xfail_imperative_in_teardown_function(self, testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n            pytest.xfail(\"xfail reason\")\n\n            assert 0\n        \"\"\"\n    )\n    result = testdir.runpytest(p, \"-rxX\")\n    result.stdout.fnmatch_lines([\"*XFAIL*test_this*\", \"*xfail reason*\"])\n    result = testdir.runpytest(p, \"--runxfail\")\n    result.stdout.fnmatch_lines([\"*1 failed*\"])\n", "def test_xfail_skipif_with_module_level_condition(self, testdir):\n    p = testdir.makepyfile(\n        \"\"\"\n        import pytest\n        pytest.skipif(\"hasattr(os, 'sep')\", reason=\"Skipping on certain platforms\")\n            assert 1\n        \"\"\"\n    )\n    result = testdir.runpytest(p, \"-rx\")\n    result.stdout.fnmatch_lines([\"*Skipping on certain platforms*\", \"*1 skipped*\"])\n"], "sample_118": ["def test_ccode_increment():\n    expr = x + 1\n    assert ccode(expr, assign_to=x) == 'x += 1;'\n\n    expr = x - 1\n    assert ccode(expr, assign_to=x) == 'x -= 1;'\n\n    expr = x * 2\n    assert ccode(expr, assign_to=x) == 'x *= 2;'\n\n    expr = x / 2\n    assert ccode(expr, assign_to=x) == 'x /= 2;'\n", "def test_ccode_multiple_assignments():\n    a, b, c, d = symbols('a b c d')\n    e, f, g = symbols('e f g')\n    assignments = [Assignment(a, b + c), Assignment(d, e + f), Assignment(c, g)]\n    expected_output = 'a = b + c;\\nd = e + f;\\nc = g;\\n'\n    assert ccode(assignments) == expected_output\n", "def test_ccode_aug_assign():\n    assert ccode(aug_assign(x, '+=', y + z)) == 'x += y + z;'\n    assert ccode(aug_assign(x, '-=', y - z)) == 'x -= y - z;'\n    assert ccode(aug_assign(x, '*=', y * z)) == 'x *= y * z;'\n    assert ccode(aug_assign(x, '/=', y / z)) == 'x /= y / z;'\n", "def test_ccode_For():\n    x = IndexedBase('x')\n    y = IndexedBase('y')\n    n = symbols('n', integer=True)\n    i = symbols('i')\n    expr = For(i, Range(n), y[i], Assignment(x[i], y[i]))\n    assert ccode(expr) == (\n        \"for (i = 0; i < n; i++) {\\n\"\n        \"   x[i] = y[i];\\n\"\n        \"}\")\n", "def test_ccode_Matrix_element_assign():\n    A = MatrixSymbol('A', 3, 3)\n    i, j = symbols('i j', integer=True)\n    e = Eq(A[i, j], i + j)\n    assert ccode(e.rhs, assign_to=e.lhs) == (\n        \"for (int i=0; i<3; i++){\\n\"\n        \"   for (int j=0; j<3; j++){\\n\"\n        \"      A[i*3 + j] = i + j;\\n\"\n        \"   }\\n\"\n        \"}\"\n    )\n"], "sample_62": ["    def test_delete_many_returns_none(self):\n        cache.set_many({\"a\": 1, \"b\": 2, \"c\": 3})\n        self.assertIsNone(cache.delete_many([\"a\", \"b\", \"c\"]))\n", "def test_cache_versioning_touch(self):\n    cache.set(\"answer1\", 37, version=1)\n    cache.set(\"answer1\", 42, version=2)\n    self.assertIs(cache.touch(\"answer1\", version=2), True)\n    self.assertEqual(cache.get(\"answer1\", version=1), 37)\n    self.assertEqual(cache.get(\"answer1\", version=2), 42)\n\n    caches[\"v2\"].set(\"answer2\", 37)\n    self.assertEqual(caches[\"v2\"].get(\"answer2\"), 37)\n    self.assertIs(caches[\"v2\"].touch(\"answer2\"), True)\n    self.assertEqual(caches[\"v2\"].get(\"answer2\"), 37)\n\n    cache.set(\"answer3\", 37, version=1)\n    cache.set(\"answer3\", 42, version=2)\n    self.assertIs(caches[\"v2\"].touch(\"answer3\", version=2), True)\n    self.assertEqual(cache.get(\"answer3\", version=1), 37)\n    self.assertEqual(cache.get(\"answer3\", version=2), 42)\n\n    cache.set(\"answer4\", 37, version=1)\n    cache.set(\"answer4\", 42, version=2)\n    self.assertIs(caches[\"v2\"].touch(\"answer4\", version=1), True)\n    self.assertEqual(cache.get(\"answer4\", version=1), 37)\n    self.assertEqual(cache.get(\"answer4\", version=2), 42)\n", "def test_cache_get_set_many_types(self):\n    data = {\n        \"str_key\": \"string value\",\n        \"int_key\": 42,\n        \"float_key\": 3.14,\n        \"list_key\": [1, 2, 3],\n        \"dict_key\": {\"key\": \"value\"},\n        \"none_key\": None,\n    }\n    cache.set_many(data)\n    result = cache.get_many(data.keys())\n    self.assertEqual(data, result)\n", "def test_cache_get_or_set_racing_with_other_process(self):\n    # Simulate a racing condition where the value is set by another process\n    # between the cache.get() and cache.add() calls.\n    with mock.patch.object(cache._class, \"add\") as mock_add:\n        mock_add.side_effect = [False, True]\n        self.assertEqual(cache.get_or_set(\"key\", \"default\"), \"default\")\n        mock_add.assert_called_with(\"key\", \"default\", timeout=DEFAULT_TIMEOUT, version=None)\n", "    def test_cache_versioning_add_with_default_version(self):\n        # add, using default version = 1\n        self.assertIs(cache.add(\"answer1\", 42), True)\n        self.assertEqual(cache.get(\"answer1\"), 42)\n        self.assertEqual(cache.get(\"answer1\", version=1), 42)\n        self.assertIsNone(cache.get(\"answer1\", version=2))\n\n        self.assertIs(caches[\"v2\"].add(\"answer2\", 42), True)\n        self.assertIsNone(cache.get(\"answer2\"))\n        self.assertEqual(cache.get(\"answer2\", version=2), 42)\n"], "sample_8": ["def test_sensitive_function_keyword_arguments_email(self):\n    \"\"\"\n    Sensitive variables don't leak in the email report, when those variables are passed\n    as keyword arguments to the decorated function.\n    \"\"\"\n    self.verify_safe_email(sensitive_kwargs_function_caller, check_for_POST_params=False)\n", "def test_cleanse_setting_recursive(self):\n    \"\"\"\n    The debug page should filter out some sensitive information found in\n    recursive dict settings.\n    \"\"\"\n    sensitive_settings = [\n        'SECRET_KEY',\n        'PASSWORD',\n        'API_KEY',\n        'AUTH_TOKEN',\n    ]\n    for setting in sensitive_settings:\n        FOOBAR = {\n            'recursive': {setting: \"should not be displayed\"},\n        }\n        with self.settings(DEBUG=True, FOOBAR=FOOBAR):\n            response = self.client.get('/raises500/')\n            self.assertNotContains(response, 'should not be displayed', status_code=500)\n", "def test_template_encoding_debug(self):\n    \"\"\"\n    The templates are loaded directly, not via a template loader, and\n    should be opened as utf-8 charset as is the default specified on\n    template engines when DEBUG is True.\n    \"\"\"\n    with mock.patch.object(DebugPath, 'open') as m:\n        self.client.get('/raises500/')\n        m.assert_called_once_with(encoding='utf-8')\n        m.reset_mock()\n        self.client.get('/raises404/')\n        m.assert_called_once_with(encoding='utf-8')\n", "    def test_cleanse_setting_unhashable_type(self):\n        self.assertRaises(TypeError, cleanse_setting, 'TEST', {'unhashable_key': 'value'})\n", "def test_sensitive_function_keyword_arguments_not_evaluated(self):\n    \"\"\"\n    Sensitive variables should not be evaluated in the sensitive_variables decorator's\n    frame, when those variables are passed as keyword arguments to the decorated function.\n    \"\"\"\n    request = self.rf.post('/some_url/', self.breakfast_data)\n    response = sensitive_kwargs_function_caller(request)\n\n    # Assert that sensitive variables are not evaluated in the sensitive_variables decorator's frame\n    self.assertNotIn(CLEANSED_SUBSTITUTE, response.content.decode())\n"], "sample_101": ["def test_pipeline_memory_with_fit_params():\n    X = np.array([[1, 2]])\n    transf = TransfFitParams()\n    pipe = Pipeline([('transf', transf), ('clf', Mult())],\n                    memory=DummyMemory())\n    pipe.fit(X, y=None, transf__param1=1, transf__param2=2)\n    assert transf.fit_params == {'param1': 1, 'param2': 2}\n", "def test_pipeline_set_params_validation():\n    # Test that set_params validates the parameters\n    pipe = Pipeline([('transf', Transf()), ('clf', Mult())])\n    # setting an invalid parameter should raise an error message\n    assert_raise_message(\n        ValueError,\n        \"Invalid parameter clf__invalid for estimator Pipeline(steps=[('transf', Transf()), ('clf', Mult())]). \"\n        \"Check the list of available parameters with `estimator.get_params().keys()`.\",\n        pipe.set_params,\n        clf__invalid='invalid'\n    )\n", "def test_pipeline_memory_disabled():\n    X = np.array([[1, 2]])\n    transf = DummyTransf()\n    pipe = Pipeline([('transf', transf), ('clf', Mult())])\n    cached_pipe = Pipeline([('transf', transf), ('clf', Mult())], memory=None)\n\n    # Fit both pipelines\n    pipe.fit(X, y=None)\n    cached_pipe.fit(X, y=None)\n\n    # Check that transformer was fitted in both cases\n    assert hasattr(transf, 'means_')\n    assert hasattr(cached_pipe.named_steps['transf'], 'means_')\n\n    # Check that results are the same\n    assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n    assert_array_equal(pipe.transform(X), cached_pipe.transform(X))\n\n    # Check that cache was not used\n    assert transf.means_ is cached_pipe.named_steps['transf'].means_\n", "def test_pipeline_with_different_memory_instances():\n    X = np.array([[1, 2]])\n    cache_dir1 = mkdtemp()\n    cache_dir2 = mkdtemp()\n    try:\n        memory1 = Memory(location=cache_dir1, verbose=10)\n        memory2 = Memory(location=cache_dir2, verbose=10)\n\n        pipe1 = Pipeline([('transf', DummyTransf()), ('clf', Mult())], memory=memory1)\n        pipe2 = Pipeline([('transf', DummyTransf()), ('clf', Mult())], memory=memory2)\n\n        pipe1.fit(X, y=None)\n        pipe2.fit(X, y=None)\n\n        # Check that the transformers are not the same\n        assert pipe1.named_steps['transf'] is not pipe2.named_steps['transf']\n\n        # Check that the transformers have different means_ attribute\n        assert_array_equal(pipe1.named_steps['transf'].means_,\n                           np.mean(X, axis=0))\n        assert_array_equal(pipe2.named_steps['transf'].means_,\n                           np.mean(X, axis=0))\n        assert not np.array_equal(pipe1.named_steps['transf'].means_,\n                                  pipe2.named_steps['transf'].means_)\n    finally:\n        shutil.rmtree(cache_dir1)\n        shutil.rmtree(cache_dir2)\n", "def test_pipeline_memory_with_transformer_without_fit_transform():\n    X = np.array([[1, 2]])\n    transf = NoTrans()\n    clf = Mult()\n    pipe = Pipeline([('transf', transf), ('clf', clf)])\n    cachedir = mkdtemp()\n    try:\n        if LooseVersion(joblib_version) < LooseVersion('0.12'):\n            memory = Memory(cachedir=cachedir, verbose=10)\n        else:\n            memory = Memory(location=cachedir, verbose=10)\n        cached_pipe = Pipeline([('transf', transf), ('clf', clf)], memory=memory)\n\n        # Fit the pipelines\n        cached_pipe.fit(X)\n        pipe.fit(X)\n\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.score(X), cached_pipe.score(X))\n\n        # Check that fitting a second time does not change the result\n        cached_pipe.fit(X)\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.score(X), cached_pipe.score(X))\n    finally:\n        shutil.rmtree(cachedir)\n"], "sample_11": ["def test_serialize_complex_numbers(self):\n    self.assertSerializedEqual(1 + 2j)\n    self.assertSerializedResultEqual(\n        1 + 2j,\n        (\"complex('(1+2j)')\", {})\n    )\n\n    BaseSerializer.register(complex, ComplexSerializer)\n    self.assertSerializedResultEqual(\n        1 + 2j,\n        (\"complex('(1+2j)')\", {})\n    )\n    BaseSerializer.unregister(complex)\n", "def test_serialize_complex(self):\n    self.assertSerializedEqual(complex(1, 2))\n    self.assertSerializedResultEqual(\n        complex(1, 2),\n        (\"complex((1+2j))\", set())\n    )\n\n    complex_field = models.CharField(default=complex(3, 4))\n    string = MigrationWriter.serialize(complex_field)[0]\n    self.assertEqual(\n        string,\n        \"models.CharField(default=complex((3+4j)))\"\n    )\n\n    BaseSerializer.register(complex, ComplexSerializer)\n    self.assertSerializedEqual(complex(1, 2))\n    self.assertSerializedResultEqual(\n        complex(1, 2),\n        (\"complex(1+2j)\", set())\n    )\n\n    BaseSerializer.unregister(complex)\n    with self.assertRaises(ValueError):\n        self.assertSerializedEqual(complex(1, 2))\n", "def test_serialize_complex(self):\n    self.assertSerializedEqual(complex(1, 2))\n    self.assertSerializedResultEqual(complex(1, 2), (\"complex((1+2j))\", set()))\n", "def test_complex_serialization(self):\n    complex_num = complex(3, 4)\n    self.assertSerializedEqual(complex_num)\n    self.assertSerializedResultEqual(complex_num, ('complex((3+4j))', {}))\n", "def test_serialize_complex(self):\n    value = complex(1, 2)\n    string = MigrationWriter.serialize(value)[0]\n    self.assertEqual(string, \"complex((1+2j))\")\n    self.assertEqual(self.serialize_round_trip(value), value)\n"], "sample_122": ["def test_scalar_multiply():\n    A = SparseMatrix([[1, 2], [3, 4]])\n    scalar = 3\n    B = A.scalar_multiply(scalar)\n    assert B == SparseMatrix([[3, 6], [9, 12]])\n", "def test_fill():\n    M = SparseMatrix.zeros(3)\n    M.fill(1)\n    assert M == SparseMatrix([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\n    M.fill(0)\n    assert M == SparseMatrix.zeros(3)\n", "def test_scalar_multiply():\n    A = SparseMatrix(((1, 2), (3, 4)))\n    assert A.scalar_multiply(2) == SparseMatrix(((2, 4), (6, 8)))\n    assert A.scalar_multiply(0) == SparseMatrix(((0, 0), (0, 0)))\n    assert A.scalar_multiply(S.Zero) == SparseMatrix(((0, 0), (0, 0)))\n", "def test_solve_least_squares():\n    A = SparseMatrix([[1, 2], [3, 4], [5, 6]])\n    B = SparseMatrix([[8], [20], [32]])\n    x = A.solve_least_squares(B)\n    assert (A*x - B).norm() <= (A*A.T*x - A*B).norm()\n", "compilation error"], "sample_54": ["def test_urlize_nofollow(self):\n    text = \"Visit example.com for more information.\"\n    output = 'Visit <a href=\"http://example.com\" rel=\"nofollow\">example.com</a> for more information.'\n    self.assertEqual(urlize(text, nofollow=True), output)\n", "def test_urlize_trailing_punctuation(self):\n    value = \"Search for google.com/?q=!, and see.\"\n    output = 'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>!, and see.'\n    self.assertEqual(urlize(value), output)\n", "def test_urlize_trim_url_limit(self):\n    value = \"This is a very long URL: http://example.com/this/is/a/very/long/url\"\n    output = 'This is a very long URL: <a href=\"http://example.com/this/is/a/very/long/url\">http://example.com/this/is/a/very/l...</a>'\n    self.assertEqual(urlize(value, trim_url_limit=30), output)\n", "def test_urlize_email_with_quoted_chars(self):\n    value = \"foo@ex-ample.com\"\n    output = '<a href=\"mailto:foo@xn--ex-ample-44a.com\">foo@ex-ample.com</a>'\n    self.assertEqual(urlize(value), output)\n", "    def test_urlize_trailing_punctuation(self):\n        tests = (\n            (\n                \"Search for google.com/?q=!.\",\n                'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>!.',\n            ),\n            (\n                \"Search for google.com/?q=!, and see.\",\n                'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>!, and see.',\n            ),\n            (\n                \"Search for google.com/?q=!; and see.\",\n                'Search for <a href=\"http://google.com/?q=\">google.com/?q=</a>!; and see.',\n            ),\n        )\n        for value, output in tests:\n            with self.subTest(value=value):\n                self.assertEqual(urlize(value), output)\n"], "sample_29": ["def test_expression_wrapper_with_functions(self):\n    queryset = Company.objects.annotate(\n        upper_name=Upper(ExpressionWrapper(F('name'), output_field=CharField())),\n        length_name=Length(ExpressionWrapper(F('name'), output_field=CharField())),\n    )\n    for company in queryset:\n        self.assertEqual(company.upper_name, company.name.upper())\n        self.assertEqual(company.length_name, len(company.name))\n", "    def test_resolve_output_field(self):\n        expr = ExpressionWrapper(Value(3), output_field=IntegerField())\n        self.assertIsInstance(expr.output_field, IntegerField)\n", "    def test_output_field_with_expression(self):\n        expr = ExpressionWrapper(Expression(IntegerField()), output_field=IntegerField())\n        self.assertIsInstance(expr.output_field, IntegerField)\n", "def test_case_when_then_else(self):\n    # Test CASE WHEN THEN ELSE clause\n    qs = Company.objects.annotate(\n        ceo_status=Case(\n            When(ceo__salary__gt=20, then=Value('High Earner')),\n            When(ceo__salary__gt=10, then=Value('Medium Earner')),\n            default=Value('Low Earner'),\n            output_field=CharField(),\n        ),\n    )\n    self.assertCountEqual(\n        qs.values_list('ceo_status', flat=True),\n        ['High Earner', 'Medium Earner'],\n    )\n", "def test_annotation_with_outerref_in_filter(self):\n    self.gmbh.point_of_contact = Employee.objects.get(lastname='Meyer')\n    self.gmbh.save()\n    inner = Employee.objects.filter(\n        lastname__startswith=Left(OuterRef(OuterRef('lastname')), 1),\n    )\n    qs = Employee.objects.annotate(\n        ceo_company=Subquery(\n            Company.objects.filter(\n                point_of_contact__in=inner,\n                ceo__pk=OuterRef('pk'),\n            ).values('name'),\n        ),\n    ).filter(ceo_company__isnull=False)\n    self.assertEqual(qs.get().ceo_company, 'Test GmbH')\n"], "sample_37": ["def test_expression_wrapper_with_null_value(self):\n    employee = Employee.objects.create(firstname='John', lastname='Doe')\n    Employee.objects.update(salary=ExpressionWrapper(Value(None), output_field=IntegerField()))\n    employee.refresh_from_db()\n    self.assertIsNone(employee.salary)\n", "def test_expression_wrapper_output_field_validation(self):\n    # ExpressionWrapper should raise a TypeError if output_field is not a Field instance\n    msg = \"output_field must be a Field instance.\"\n    with self.assertRaisesMessage(TypeError, msg):\n        ExpressionWrapper(Value(3), output_field='not a field')\n", "def test_bitwise_operations_unsupported_for_wrapped_expressions(self):\n    expr = ExpressionWrapper(Value(3), output_field=IntegerField())\n    with self.assertRaises(NotImplementedError):\n        expr.bitand(3)\n    with self.assertRaises(NotImplementedError):\n        expr.bitor(3)\n    with self.assertRaises(NotImplementedError):\n        expr.bitxor(3)\n", "def test_expression_wrapper_with_none_value(self):\n    wrapper = ExpressionWrapper(Value(None), output_field=CharField())\n    self.assertIsNone(wrapper.resolve_expression(QuerySet()))\n", "def test_expression_wrapper_with_aggregate(self):\n    Company.objects.create(name=\"Test\", num_employees=10, num_chairs=5, ceo=self.max)\n    Company.objects.create(name=\"Test2\", num_employees=20, num_chairs=15, ceo=self.max)\n    qs = Company.objects.annotate(\n        total_employees=ExpressionWrapper(Sum('num_employees'), output_field=IntegerField())\n    )\n    self.assertEqual(qs.count(), 2)\n    self.assertGreater(qs.get(name=\"Test\").total_employees, 0)\n    self.assertGreater(qs.get(name=\"Test2\").total_employees, 0)\n"], "sample_56": ["    def test_no_template_configurations(self):\n        with self.settings(TEMPLATES=[]):\n            self.assertEqual(check_for_template_tags_with_the_same_name(None), [])\n", "    def get_settings(module_name, module_path):\n        return {\n            \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n            \"OPTIONS\": {\n                \"libraries\": {\n                    module_name: f\"check_framework.template_test_apps.{module_path}\",\n                },\n            },\n        }\n", "def test_template_tags_with_same_library_name_different_modules(self):\n    with self.settings(\n        TEMPLATES=[\n            self.get_settings(\n                \"same_tags\", \"same_tags_app_1.templatetags.different_tags_1\"\n            ),\n            self.get_settings(\n                \"same_tags\", \"same_tags_app_2.templatetags.different_tags_2\"\n            ),\n        ]\n    ):\n        self.assertEqual(\n            check_for_template_tags_with_the_same_name(None),\n            [],\n        )\n", "    def test_template_tags_with_different_module_name(self):\n        with self.settings(\n            TEMPLATES=[\n                self.get_settings(\n                    \"same_tags\", \"different_module_app_1.templatetags.same_tags\"\n                ),\n                self.get_settings(\n                    \"same_tags\", \"different_module_app_2.templatetags.same_tags\"\n                ),\n            ]\n        ):\n            self.assertEqual(check_for_template_tags_with_the_same_name(None), [])\n", "def test_template_tags_with_different_module_name(self):\n    with self.settings(\n        TEMPLATES=[\n            self.get_settings(\n                \"different_tags\", \"different_tags_app_1.templatetags.different_tags\"\n            ),\n            self.get_settings(\n                \"different_tags\", \"different_tags_app_2.templatetags.different_tags\"\n            ),\n        ]\n    ):\n        self.assertEqual(check_for_template_tags_with_the_same_name(None), [])\n"], "sample_88": ["def test_circular_references():\n    \"\"\"saferepr() can handle circular references (#7145)\"\"\"\n\n    class Node:\n            self.value = value\n            self.next = next\n\n            return f'Node({self.value}, {self.next!r})'\n\n    a = Node(1)\n    a.next = a\n\n    assert saferepr(a) == 'Node(1, <Node object at 0x...)'\n", "def test_broken_str():\n    \"\"\"saferepr() can create proper representations of classes with\n    broken __str__ (#7145)\n    \"\"\"\n\n    class SomeClass:\n            raise RuntimeError\n\n    assert \"<RuntimeError raised in repr()>\" in saferepr(SomeClass())\n", "def test_broken_str_repr():\n    \"\"\"saferepr() can create proper representations of classes with\n    broken __str__ and __repr__ (#issue_number)\n    \"\"\"\n\n    class SomeClass:\n            raise RuntimeError\n\n            raise RuntimeError\n\n    obj = SomeClass()\n    assert \"RuntimeError\" in saferepr(obj)\n", "def test_broken_repr_on_str():\n    \"\"\"saferepr() can create proper representations of strings with\n    broken __repr__ (#issue_number)\n    \"\"\"\n\n    class BrokenStr(str):\n            raise RuntimeError(\"Broken __repr__\")\n\n    val = BrokenStr(\"Test String\")\n    s = saferepr(val)\n    assert \"RuntimeError\" in s\n    assert \"BrokenStr\" in s\n", "def test_broken_getattribute_saferepr():\n    \"\"\"saferepr() can handle classes with broken __getattribute__ in repr (#7145)\n    \"\"\"\n\n    class BrokenGetAttribute:\n            return \"BrokenGetAttribute object\"\n\n            if attr == '__repr__':\n                raise RuntimeError\n            return super().__getattribute__(attr)\n\n    assert saferepr(BrokenGetAttribute()) == \"<[RuntimeError raised in repr()] BrokenGetAttribute object at 0x{:x}>\".format(id(BrokenGetAttribute()))\n"], "sample_74": ["def test_colorbar_update_ticks():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc)\n    cb.update_ticks()\n    fig.canvas.draw()\n    # check that the ticks are updated\n    assert len(cb.ax.yaxis.get_ticklocs()) > 0\n", "def test_colorbar_with_log_norm_and_extend():\n    fig, ax = plt.subplots()\n    data = np.logspace(-1, 1, 100).reshape(10, 10)\n    im = ax.imshow(data, norm=LogNorm())\n    cb = fig.colorbar(im, extend='both')\n    assert cb.norm == im.norm\n", "def test_colorbar_set_ticks_labels():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.arange(1, 5).reshape(2, 2), cmap='viridis')\n    cb = fig.colorbar(pc, ticks=[1.5, 2.5, 3.5])\n    cb.set_ticklabels(['Low', 'Medium', 'High'])\n    fig.draw_without_rendering()\n", "def test_colorbar_manual_ticks():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]], interpolation=\"none\")\n    cb = fig.colorbar(im, extend='both')\n    cb.set_ticks([0.5, 1.5, 2.5])\n    cb.set_ticklabels(['A', 'B', 'C'])\n    fig.draw_without_rendering()\n    assert [t.get_text() for t in cb.ax.yaxis.get_ticklabels()] == ['A', 'B', 'C']\n", "def test_colorbar_minor_ticks(orientation):\n    fig, ax = plt.subplots()\n    data = np.arange(1200).reshape(30, 40)\n    levels = [0, 200, 400, 600, 800, 1000, 1200]\n\n    cs = ax.contourf(data, levels=levels, extend='both')\n    cb = fig.colorbar(cs, orientation=orientation)\n    cb.minorticks_on()\n\n    if orientation == \"horizontal\":\n        assert len(cb.ax.xaxis.get_minorticklocs()) > 0\n    else:\n        assert len(cb.ax.yaxis.get_minorticklocs()) > 0\n"], "sample_111": ["def test_empty_input(metric):\n    # test that metrics handle empty input correctly\n    y_true = []\n    y_pred = []\n    assert metric(y_true, y_pred) == 1.0\n", "def test_empty_clusters(metric_name):\n    # All clustering metrics should return 1.0 when there are empty clusters\n    y_true = [0, 0, 0, 0, 1, 1, 1, 1]\n    y_pred = [0, 0, 0, 0, 2, 2, 2, 2]\n\n    metric = SUPERVISED_METRICS[metric_name]\n    score = metric(y_true, y_pred)\n    assert score == pytest.approx(1.0)\n", "def test_empty_inputs(metric):\n    # Test that metrics handle empty inputs correctly\n    with pytest.raises(ValueError):\n        metric([], [])\n\n    # Test that metrics handle empty true labels correctly\n    with pytest.raises(ValueError):\n        metric([], [0, 1])\n\n    # Test that metrics handle empty predicted labels correctly\n    with pytest.raises(ValueError):\n        metric([0, 1], [])\n", "def test_empty_inputs(metric):\n    # Test the metrics with empty inputs\n    for i, j in [([], []), ([], [1]), ([1], []), ([1, 2], [])]:\n        with pytest.raises(ValueError):\n            metric(i, j)\n", "def test_metric_with_empty_labels(metric_name):\n    metric = SUPERVISED_METRICS[metric_name]\n    assert metric([], []) == 1.0\n"], "sample_47": ["    def test_minimize_rollbacks_multiple_targets(self):\n        \"\"\"\n        Minimize rollbacks when there are multiple targets.\n\n        a: 1 <---- 3 <--\\\n              \\ \\- 2 <--- 4\n               \\       \\\n        b:      \\- 1 <--- 2\n        \"\"\"\n        a1_impl = FakeMigration('a1')\n        a1 = ('a', '1')\n        a2_impl = FakeMigration('a2')\n        a2 = ('a', '2')\n        a3_impl = FakeMigration('a3')\n        a3 = ('a', '3')\n        a4_impl = FakeMigration('a4')\n        a4 = ('a', '4')\n        b1_impl = FakeMigration('b1')\n        b1 = ('b', '1')\n        b2_impl = FakeMigration('b2')\n        b2 = ('b', '2')\n        graph = MigrationGraph()\n        graph.add_node(a1, a1_impl)\n        graph.add_node(a2, a2_impl)\n        graph.add_node(a3, a3_impl)\n        graph.add_node(a4, a4_impl)\n        graph.add_node(b1, b1_impl)\n        graph.add_node(b2, b2_impl)\n        graph.add_dependency(None, a2, a1)\n        graph.add_dependency(None, a3, a1)\n        graph.add_dependency(None, a4, a2)\n        graph.add_dependency(None, a4, a3)\n        graph.add_dependency(None, b2, b1)\n        graph.add_dependency(None, b1, a1)\n        graph.add_dependency(None, b2, a2)\n\n        executor = MigrationExecutor(None)\n        executor.loader = FakeLoader(graph, {\n            a1: a1_impl,\n            b1: b1_impl,\n            a2: a2_impl,", "def test_migrate_backward_to_replaced_migration(self):\n    executor = MigrationExecutor(connection)\n    try:\n        self.assertTableNotExists('migrations_author')\n        self.assertTableNotExists('migrations_book')\n        executor.migrate([('migrations', '0001_squashed_0002')])\n        self.assertTableExists('migrations_author')\n        self.assertTableExists('migrations_book')\n        executor.loader.build_graph()\n        # Migrate backward to a replaced migration.\n        executor.migrate([('migrations', '0001_initial')])\n        self.assertTableExists('migrations_author')\n        self.assertTableNotExists('migrations_book')\n    finally:\n        # Unmigrate everything.\n        executor = MigrationExecutor(connection)\n        executor.migrate([('migrations', None)])\n        self.assertTableNotExists('migrations_author')\n        self.assertTableNotExists('migrations_book')\n", "def test_minimize_rollbacks_replacement(self):\n    \"\"\"\n    Minimize rollbacks when target is a replacement migration.\n\n    a: 1 --> 3 (replaces 1, 2)\n    b:     1 <--- 2\n    \"\"\"\n    a1_impl = FakeMigration('a1')\n    a1 = ('a', '1')\n    a3_impl = FakeMigration('a3')\n    a3 = ('a', '3')\n    b1_impl = FakeMigration('b1')\n    b1 = ('b', '1')\n    b2_impl = FakeMigration('b2')\n    b2 = ('b', '2')\n    graph = MigrationGraph()\n    graph.add_node(a1, a1_impl)\n    graph.add_node(a3, a3_impl)\n    graph.add_node(b1, b1_impl)\n    graph.add_node(b2, b2_impl)\n    graph.add_dependency(None, b2, b1)\n    graph.add_dependency(None, a3, b1)\n    a3_impl.replaces = {a1}\n\n    executor = MigrationExecutor(None)\n    executor.loader = FakeLoader(graph, {\n        a1: a1_impl,\n        b1: b1_impl,\n        b2: b2_impl,\n        a3: a3_impl,\n    })\n\n    plan = executor.migration_plan({a3})\n\n    should_be_rolled_back = [b2_impl]\n    exp = [(m, True) for m in should_be_rolled_back]\n    self.assertEqual(plan, exp)\n", "def test_migrate_all_backwards_with_initial_migration(self):\n    \"\"\"\n    Test migrate_all_backwards with initial migration.\n\n    This test checks the behavior of migrate_all_backwards when an initial\n    migration is present.\n    \"\"\"\n    initial_migration_impl = FakeMigration('0001_initial')\n    initial_migration = ('migrations', '0001_initial')\n    second_migration_impl = FakeMigration('0002_second')\n    second_migration = ('migrations', '0002_second')\n\n    graph = MigrationGraph()\n    graph.add_node(initial_migration, initial_migration_impl)\n    graph.add_node(second_migration, second_migration_impl)\n    graph.add_dependency(None, second_migration, initial_migration)\n\n    executor = MigrationExecutor(None)\n    executor.loader = FakeLoader(graph, {\n        initial_migration: initial_migration_impl,\n        second_migration: second_migration_impl,\n    })\n\n    plan = [(second_migration_impl, True), (initial_migration_impl, True)]\n    full_plan = [(initial_migration_impl, False), (second_migration_impl, False)]\n\n    state = executor._migrate_all_backwards(plan, full_plan, fake=False)\n\n    self.assertNotIn(initial_migration, state.models)\n    self.assertNotIn(second_migration, state.models)\n", "def test_minimize_rollbacks_circular(self):\n    \"\"\"\n    Minimize rollbacks when target has circular dependencies.\n\n    a: 1 <-- 2 <-- 3\n         \\     /\n           -- 4\n    \"\"\"\n    a1_impl = FakeMigration('a1')\n    a1 = ('a', '1')\n    a2_impl = FakeMigration('a2')\n    a2 = ('a', '2')\n    a3_impl = FakeMigration('a3')\n    a3 = ('a', '3')\n    a4_impl = FakeMigration('a4')\n    a4 = ('a', '4')\n    graph = MigrationGraph()\n    graph.add_node(a1, a1_impl)\n    graph.add_node(a2, a2_impl)\n    graph.add_node(a3, a3_impl)\n    graph.add_node(a4, a4_impl)\n    graph.add_dependency(None, a2, a1)\n    graph.add_dependency(None, a3, a2)\n    graph.add_dependency(None, a2, a3)\n    graph.add_dependency(None, a4, a1)\n    graph.add_dependency(None, a4, a3)\n\n    executor = MigrationExecutor(None)\n    executor.loader = FakeLoader(graph, {\n        a1: a1_impl,\n        a2: a2_impl,\n        a3: a3_impl,\n        a4: a4_impl,\n    })\n\n    plan = executor.migration_plan({a1})\n\n    should_be_rolled_back = [a4_impl, a3_impl, a2_impl]\n    exp = [(m, True) for m in should_be_rolled_back]\n    self.assertEqual(plan, exp)\n"], "sample_75": ["def test_imagegrid_ngrids():\n    fig = plt.figure()\n    grid = ImageGrid(fig, 111, nrows_ncols=(2, 2), ngrids=3)\n    assert len(grid) == 3\n", "def test_imagegrid_cbar_mode_single():\n    arr = np.arange(16).reshape((4, 4))\n\n    fig = plt.figure(figsize=(9, 9))\n\n    positions = (221, 222, 223, 224)\n    cbar_locations = ['left', 'right', 'top', 'bottom']\n\n    for position, location in zip(positions, cbar_locations):\n        grid = ImageGrid(fig, position,\n                         nrows_ncols=(1, 1),\n                         cbar_location=location,\n                         cbar_size='20%',\n                         cbar_mode='single')\n        ax = grid[0]\n\n        ax.imshow(arr, cmap='nipy_spectral')\n\n        cb = ax.cax.colorbar(ax.images[0])\n\n        # Ensure the colorbar is visible\n        assert ax.cax.get_visible()\n", "def test_grid_label_mode_keep():\n    fig, ax = plt.subplots()\n    grid = Grid(fig, 111, nrows_ncols=(2, 2), label_mode=\"keep\")\n\n    # Check if all axes have tick labels by default\n    for ax in grid.axes_all:\n        assert ax.xaxis.get_ticklabels()[0].get_visible()\n        assert ax.yaxis.get_ticklabels()[0].get_visible()\n\n    # Change label mode to 'L' and check if only certain axes have tick labels\n    grid.set_label_mode('L')\n    for i, ax in enumerate(grid.axes_all):\n        col, row = grid._get_col_row(i)\n        if col == 0 and row != grid._nrows - 1:\n            assert not ax.yaxis.get_ticklabels()[0].get_visible()\n        if row == 0 and col != grid._ncols - 1:\n            assert not ax.xaxis.get_ticklabels()[0].get_visible()\n        if col != 0 or row != grid._nrows - 1:\n            assert ax.xaxis.get_ticklabels()[0].get_visible()\n        if col != grid._ncols - 1 or row != 0:\n            assert ax.yaxis.get_ticklabels()[0].get_visible()\n", "def test_image_grid_each_top_label_mode_all():\n    imdata = np.arange(100).reshape((10, 10))\n\n    fig = plt.figure(1, (3, 3))\n    grid = ImageGrid(fig, (1, 1, 1), nrows_ncols=(2, 3), axes_pad=(0.5, 0.3),\n                     cbar_mode=\"each\", cbar_location=\"top\", cbar_size=\"15%\",\n                     label_mode=\"all\")\n    assert grid.get_axes_pad() == (0.5, 0.3)\n    assert grid.get_aspect()  # True by default for ImageGrid\n    for ax, cax in zip(grid, grid.cbar_axes):\n        im = ax.imshow(imdata, interpolation='none')\n        cax.colorbar(im)\n", "def test_image_grid_cbar_location_bottom():\n    imdata = np.arange(100).reshape((10, 10))\n\n    fig = plt.figure(1, (4, 4))\n    grid = ImageGrid(fig, 111, nrows_ncols=(2, 2), axes_pad=0.1, cbar_location=\"bottom\", cbar_mode=\"each\", cbar_size=\"15%\")\n    for i in range(4):\n        im = grid[i].imshow(imdata, interpolation='none')\n        grid.cbar_axes[i].colorbar(im)\n"], "sample_147": ["def test_MatMul_kind():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    assert MatMul(A, B).kind is MatrixKind(NumberKind)\n", "def test_MatMul_kind():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    assert MatMul(A, B).kind is MatrixKind(NumberKind)\n", "def test_MatMul_kind():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    assert MatMul(A, B).kind is MatrixKind(NumberKind)\n", "def test_MatMul_kind():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    assert MatMul(A, B).kind is MatrixKind(NumberKind)\n", "def test_MatMul_kind():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    assert MatMul(A, B).kind is MatrixKind(NumberKind)\n"], "sample_115": ["def test__wrap_in_pandas_container_default_columns():\n    \"\"\"Check _wrap_in_pandas_container with default columns.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n\n    dense_default = _wrap_in_pandas_container(X, columns=None)\n    assert isinstance(dense_default, pd.DataFrame)\n    assert_array_equal(dense_default.columns, range(X.shape[1]))\n", "def test_set_output_with_index():\n    \"\"\"Check that the output index is updated when transform returns a DataFrame.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X = pd.DataFrame([[1, 0, 3], [0, 0, 1]])\n    est = EstimatorWithSetOutputIndex().fit(X)\n    est.set_output(transform=\"pandas\")\n\n    X_trans_pd = est.transform(X)\n    assert isinstance(X_trans_pd, pd.DataFrame)\n    assert list(X_trans_pd.index) == [\"s0\", \"s1\"]\n", "def test_set_output_mixin_with_index():\n    \"\"\"Check that set_output works with DataFrame input that has a custom index.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X_df = pd.DataFrame({\"feat1\": [1, 2, 3], \"feat2\": [3, 4, 5]}, index=[\"A\", \"B\", \"C\"])\n    est = EstimatorWithSetOutputIndex().fit(X_df)\n\n    est.set_output(transform=\"pandas\")\n    X_trans_pd = est.transform(X_df)\n    assert isinstance(X_trans_pd, pd.DataFrame)\n    assert list(X_trans_pd.index) == [\"s0\", \"s1\", \"s2\"]\n", "def test__wrap_in_pandas_container_no_columns():\n    \"\"\"Check _wrap_in_pandas_container with no columns.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X = np.asarray([[1, 0, 3], [0, 0, 1]])\n    index = np.asarray([0, 1])\n\n    dense_named = _wrap_in_pandas_container(X, columns=None, index=index)\n    assert isinstance(dense_named, pd.DataFrame)\n    assert_array_equal(dense_named.columns, range(X.shape[1]))\n    assert_array_equal(dense_named.index, index)\n", "def test_set_output_pandas_with_index():\n    \"\"\"Check that set_output works with pandas DataFrame input and index.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X_pd = pd.DataFrame([[1, 0, 3], [0, 0, 1]], index=[\"a\", \"b\"])\n    est = EstimatorWithSetOutputIndex().fit(X_pd)\n\n    # Original index is not changed when output is not a pandas DataFrame\n    est.set_output(transform=\"default\")\n    X_trans_default = est.transform(X_pd)\n    assert isinstance(X_trans_default, np.ndarray)\n    assert_array_equal(X_trans_default, X_pd.values)\n\n    # When output is a pandas DataFrame, the index should be changed\n    est.set_output(transform=\"pandas\")\n    X_trans_pd = est.transform(X_pd)\n    assert isinstance(X_trans_pd, pd.DataFrame)\n    assert_array_equal(X_trans_pd.index, [\"s0\", \"s1\"])\n"], "sample_126": ["def test_Float_evalf():\n    x = Float(2.0, precision=10)\n    y = x.evalf()\n    assert same_and_same_prec(y, Float(2.0))\n", "def test_Float_from_mpmath():\n    import mpmath\n    mpmath.mp.dps = 15\n    mp_val = mpmath.mpf(pi)\n    sympy_val = Float(mp_val, dps=15)\n    assert sympy_val._mpf_ == mp_val._mpf_\n    assert sympy_val._prec == 15\n", "def test_Rational_comparison_with_Float():\n    assert Rational(1, 3) < Float('0.3333', 4)\n    assert Rational(1, 3) <= Float('0.3333', 4)\n    assert Rational(1, 3) != Float('0.3333', 4)\n    assert Rational(1, 3) > Float('0.333', 3)\n    assert Rational(1, 3) >= Float('0.333', 3)\n", "def test_Float_complex():\n    c = 1 + 2*I\n    f = Float(c)\n    assert f == c\n    assert f._prec == 53\n    assert f.is_finite\n    assert not f.is_zero\n    assert f.is_complex\n    assert not f.is_imaginary\n    assert not f.is_real\n    assert f.is_number\n    assert not f.is_rational\n    assert not f.is_integer\n    assert f.is_irrational\n    assert not f.is_algebraic\n    assert f.is_transcendental\n    assert f.as_real_imag() == (1, 2)\n    assert f.as_coeff_Mul() == (1 + 2*I, 1)\n    assert f.as_coeff_exponent(I) == (1 + 2*I, 0)\n    assert f.as_coeff_terms() == (1, [(I, 2)])\n", "def test_NumberSymbol_limits():\n    # Test for issue #10212\n    assert E.limit(x, 0) == 1\n    assert pi.limit(x, 0) == pi\n    assert GoldenRatio.limit(x, 0) == GoldenRatio\n    assert EulerGamma.limit(x, 0) == EulerGamma\n    assert Catalan.limit(x, 0) == Catalan\n"], "sample_138": ["def test_BlockMatrix_transpose():\n    A, B, C, D = [MatrixSymbol(s, n, m) for s in 'ABCD']\n    X = BlockMatrix([[A, B], [C, D]])\n    assert X.transpose() == BlockMatrix([[A.T, C.T], [B.T, D.T]])\n", "def test_BlockMatrix_real_imag():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n\n    real_part, imag_part = X.as_real_imag()\n    assert real_part == BlockMatrix([[re(A), re(B)], [re(C), re(D)]])\n    assert imag_part == BlockMatrix([[im(A), im(B)], [im(C), im(D)]])\n", "def test_BlockMatrix_structurally_equal():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, k)\n    C = MatrixSymbol('C', l, m)\n    D = MatrixSymbol('D', l, k)\n    X = BlockMatrix([[A, B], [C, D]])\n    Y = BlockMatrix([[A, B], [C, D]])\n    Z = BlockMatrix([[A, C], [B, D]])\n\n    assert X.structurally_equal(Y)\n    assert not X.structurally_equal(Z)\n", "def test_BlockMatrix_as_real_imag():\n    A = Matrix([[1, 2], [3, 4]], dtype=complex)\n    B = Matrix([[5, 6], [7, 8]], dtype=complex)\n    X = BlockMatrix([[A, B], [B, A]])\n\n    real_part, imag_part = X.as_real_imag()\n    assert real_part == BlockMatrix([[A.real, B.real], [B.real, A.real]])\n    assert imag_part == BlockMatrix([[A.imag, B.imag], [B.imag, A.imag]])\n", "def test_BlockMatrix_real_imag():\n    A = Matrix([[1, 2], [3, 4]], dtype=complex)\n    B = Matrix([[5, 6], [7, 8]], dtype=complex)\n    X = BlockMatrix([[A, B], [B, A]])\n    real_X, imag_X = X.as_real_imag()\n    assert real_X == BlockMatrix([[A.real, B.real], [B.real, A.real]])\n    assert imag_X == BlockMatrix([[A.imag, B.imag], [B.imag, A.imag]])\n"], "sample_117": ["def test_stringify_type_hints_Annotated():\n    from typing import Annotated  # type: ignore\n    assert stringify(Annotated[str, \"foo\", \"bar\"]) == \"str\"  # NOQA\n", "def test_restify_type_hints_literal():\n    from typing import Literal\n    assert restify(Literal[\"a\", \"b\"]) == \":obj:`Literal`\\\\ [:obj:`'a'`, :obj:`'b'`]\"\n", "def test_restify_type_hints_Annotated():\n    from typing import Annotated\n    assert restify(Annotated[str, \"foo\", \"bar\"]) == \":class:`str`\"  # NOQA\n", "def test_restify_type_hints_ForwardRef_nested():\n    from typing import ForwardRef\n    assert restify(ForwardRef(\"List[int]\")) == \":class:`List`\\\\ [:class:`int`]\"\n", "def test_restify_type_hints_NewType():\n    assert restify(MyInt) == \":class:`MyInt`\"\n"], "sample_63": ["def test_custom_form_with_custom_username_field(self):\n    class CustomUserChangeForm(UserChangeForm):\n        class Meta(UserChangeForm.Meta):\n            model = CustomUser\n            fields = (\"custom_username\", \"password\", \"date_of_birth\")\n\n    user = CustomUser.objects.create_user(custom_username=\"testuser\", password=\"testpassword\")\n    data = {\n        \"custom_username\": \"newtestuser\",\n        \"password\": \"testpassword\",\n        \"date_of_birth\": \"1998-02-24\",\n    }\n    form = CustomUserChangeForm(data, instance=user)\n    self.assertTrue(form.is_valid())\n    form.save()\n    user.refresh_from_db()\n    self.assertEqual(form.cleaned_data[\"custom_username\"], \"newtestuser\")\n", "def test_minimum_length_validator(self):\n    user = User.objects.get(username='testclient')\n    data = {\n        'old_password': 'password',\n        'new_password1': 'short',\n        'new_password2': 'short',\n    }\n    form = PasswordChangeForm(user, data)\n    self.assertFalse(form.is_valid())\n    self.assertEqual(\n        form['new_password2'].errors,\n        ['This password is too short. It must contain at least 9 characters.']\n    )\n", "    def test_password_validator(self):\n        user = User.objects.get(username=\"testclient\")\n        data = {\n            \"old_password\": \"password\",\n            \"new_password1\": \"testclient\",  # too similar to the username\n            \"new_password2\": \"testclient\",  # too similar to the username\n        }\n        form = PasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form[\"new_password1\"].errors,\n            [\"The password is too similar to the username.\"]\n        )\n\n        data[\"new_password1\"] = \"abc12345\"  # too short\n        data[\"new_password2\"] = \"abc12345\"  # too short\n        form = PasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form[\"new_password1\"].errors,\n            [\"This password is too short. It must contain at least 8 characters.\"]\n        )\n\n        data[\"new_password1\"] = \"password\"  # common password\n        data[\"new_password2\"] = \"password\"  # common password\n        form = PasswordChangeForm(user, data)\n        self.assertFalse(form.is_valid())\n        self.assertEqual(\n            form[\"new_password1\"].errors,\n            [\"This password is too", "def test_custom_form_with_different_username_field_no_fields(self):\n    class CustomUserCreationForm(UserCreationForm):\n        class Meta(UserCreationForm.Meta):\n            model = CustomUser\n\n    data = {\n        \"password1\": \"testclient\",\n        \"password2\": \"testclient\",\n    }\n    form = CustomUserCreationForm(data)\n    self.assertFalse(form.is_valid())\n    self.assertEqual(form.errors[\"username\"], [str(Field.default_error_messages[\"required\"])])\n", "def test_unicode_password_reset(self):\n    user = User.objects.create_user(\"\u03a3\u03b1\u03c1\u03b1\", \"sara@example.com\", \"test123\")\n    data = {\"email\": \"sara@example.com\"}\n    form = PasswordResetForm(data)\n    self.assertTrue(form.is_valid())\n    form.save()\n    self.assertEqual(len(mail.outbox), 1)\n    self.assertEqual(mail.outbox[0].to, [\"sara@example.com\"])\n"], "sample_31": ["def test_shell_with_bpython_not_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import bpython interface.\"):\n        call_command('shell', interface='bpython')\n", "def test_shell_with_bpython_not_installed(self):\n    with self.assertRaisesMessage(CommandError, \"Couldn't import bpython interface.\"):\n        call_command('shell', interface='bpython')\n", "def test_shell_with_bpython_not_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import bpython interface.\"):\n        call_command('shell', interface='bpython')\n", "    def test_python_shell_imported_objects(self):\n        with mock.patch('django.core.management.commands.shell.code.interact') as mock_interact:\n            call_command('shell', interface='python')\n            mock_interact.assert_called_once()\n            imported_objects = mock_interact.call_args.kwargs['local']\n            self.assertIsInstance(imported_objects, dict)\n", "def test_shell_with_bpython_not_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import bpython interface.\"):\n        call_command('shell', interface='bpython')\n"], "sample_81": ["def test_regex_codetag(self) -> None:\n    code = \"\"\"a = 1\n            # MYTAG\n            \"\"\"\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"fixme\", line=2, args=\"MYTAG\", col_offset=17)\n    ):\n        self.checker.process_tokens(_tokenize_str(code))\n", "def test_custom_codetag(self) -> None:\n    code = \"\"\"a = 1\n            # HINT This is a custom tag\n            \"\"\"\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"fixme\", line=2, args=\"HINT This is a custom tag\", col_offset=17)\n    ):\n        self.checker.process_tokens(_tokenize_str(code))\n", "def test_custom_regex_codetag(self) -> None:\n    code = \"\"\"a = 1\n            # BUG this is a custom tag\n            # FIXME this should not trigger\n            \"\"\"\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"fixme\", line=2, args=\"BUG this is a custom tag\", col_offset=17)\n    ):\n        self.checker.process_tokens(_tokenize_str(code))\n", "def test_custom_codetag_regex(self) -> None:\n    code = \"\"\"a = 1\n            # AB\n            # XXX\n            \"\"\"\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"fixme\", line=2, args=\"AB\", col_offset=17)\n    ):\n        self.checker.process_tokens(_tokenize_str(code))\n", "def test_custom_codetag(self) -> None:\n    code = \"\"\"a = 1\n            # TICKET-123\n            # FIXME\n            \"\"\"\n    with self.assertAddsMessages(\n        MessageTest(msg_id=\"fixme\", line=2, args=\"TICKET-123\", col_offset=17)\n    ):\n        self.checker.process_tokens(_tokenize_str(code))\n"], "sample_114": ["def test_ovr_decision_function():\n    predictions = np.array([[0, 1, 0, 1, 0], [1, 0, 1, 0, 1], [0, 1, 0, 1, 0]])\n    confidences = np.array([[0.9, 0.8, 0.7, 0.6, 0.5], [0.4, 0.3, 0.2, 0.1, 0.0], [0.1, 0.2, 0.3, 0.4, 0.5]])\n    n_classes = 3\n\n    expected_result = np.array([[0.3, 0.1, -0.1], [0.1, 0.3, 0.1], [0.3, 0.1, -0.1]])\n    result = _ovr_decision_function(predictions, confidences, n_classes)\n\n    assert_allclose(result, expected_result)\n", "def test_ovr_decision_function():\n    predictions = np.array([[0, 1, 1], [1, 0, 0], [1, 1, 0]])\n    confidences = np.array([[0.2, 0.3, 0.4], [0.5, 0.6, 0.7], [0.8, 0.9, 1.0]])\n    n_classes = 3\n\n    result = _ovr_decision_function(predictions, confidences, n_classes)\n    expected_result = np.array([[0.05555556, 0.33333333, 0.61111111],\n                                [-0.11111111, 0.77777778, 0.22222222],\n                                [-0.22222222, 0.11111111, 0.77777778]])\n\n    assert_allclose(result, expected_result, atol=1e-6)\n", "def test_ovr_decision_function():\n    predictions = np.array([[0, 1, 0], [1, 1, 0], [1, 0, 1]])\n    confidences = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]])\n    n_classes = 3\n\n    expected_output = np.array([[0.23333333, 0.3, -0.03333333],\n                               [0.26666667, 0.63333333, 0.06666667],\n                               [0.13333333, 0.46666667, 0.33333333]])\n\n    output = _ovr_decision_function(predictions, confidences, n_classes)\n    assert_allclose(output, expected_output, atol=1e-5)\n", "def test_ovr_decision_function():\n    predictions = np.array([[0, 1, 1], [0, 0, 1], [0, 1, 0]])\n    confidences = np.array([[0.8, 0.2, 0.3], [0.7, 0.6, 0.1], [0.4, 0.9, 0.6]])\n    n_classes = 3\n\n    expected_votes = np.array([[1, 2, 0], [2, 0, 1], [1, 1, 1]])\n    expected_transformed_confidences = np.array([[-0.02, 0.0933, -0.0333], [-0.0333, -0.0333, 0.02], [-0.02, 0.05, -0.02]])\n    expected_output = expected_votes + expected_transformed_confidences\n\n    output = _ovr_decision_function(predictions, confidences, n_classes)\n    assert_allclose(output, expected_output)\n", "def test_ovr_decision_function():\n    predictions = np.array([[0, 1, 0], [1, 1, 0], [0, 0, 1], [1, 0, 1]])\n    confidences = np.array([[0.6, 0.8, 0.7], [0.9, 0.4, 0.6], [0.3, 0.2, 0.9], [0.7, 0.6, 0.8]])\n    n_classes = 3\n\n    decision_function = _ovr_decision_function(predictions, confidences, n_classes)\n    expected_decision_function = np.array([[0.2, 1.4, -0.5], [1.3, 0.6, -0.9], [-0.6, -0.4, 1.3], [0.2, -0.2, 1.2]])\n\n    assert_allclose(decision_function, expected_decision_function, atol=1e-15)\n"], "sample_130": ["def test_numpy_array_arg_2d():\n    # Test for issue 14655 with 2D array\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    f = lambdify([[x, y]], x*x + y, 'numpy')\n\n    assert numpy.array_equal(f(numpy.array([[2.0, 1.0], [3.0, 4.0]])), numpy.array([[5.0, 1.0], [15.0, 4.0]]))\n", "def test_lambdify_multiple_modules():\n    if not numpy:\n        skip(\"numpy not installed\")\n    if not tensorflow:\n        skip(\"tensorflow not installed\")\n\n    expr = Max(sin(x), Abs(1/(x+2)))\n    func = lambdify(x, expr, modules=[\"numpy\", \"tensorflow\"])\n\n    a = tensorflow.placeholder(dtype=tensorflow.float32)\n    s = tensorflow.Session()\n    assert func(a).eval(session=s, feed_dict={a: 0}) == 0.5\n", "def test_lambdify_implemented_function_with_multiple_arguments():\n    f = implemented_function('f', lambda x, y: x * y)\n    lam = lambdify((x, y), f(x, y))\n    assert lam(3, 4) == 12\n", "def test_lambdify_with_different_modules():\n    modules = [None, 'math', 'sympy', 'mpmath', 'numpy', 'numexpr', 'tensorflow']\n    expr = sin(x) + cos(y) + tan(z)**2 + Abs(z-y)*acos(sin(y*z)) + Abs(y-z)*acosh(2+exp(y-x)) - sqrt(x**2 + I*y**2)\n    for mod in modules:\n        f = lambdify((x, y, z), expr, modules=mod)\n        assert f(1, 2, 3) is not None\n", "def test_lambdify_with_implemented_functions():\n    # Test that lambdify uses the implemented function if it exists\n        return x ** 0.5\n\n    sqrt_func = implemented_function('sqrt', my_sqrt)\n    f = lambdify(x, sqrt_func(x))\n    assert f(4) == 2\n"], "sample_131": ["def test_MaxMin():\n    assert mcode(Max(x, y)) == \"Max[x, y]\"\n    assert mcode(Min(x, y)) == \"Min[x, y]\"\n    assert mcode(Max(x, y, z)) == \"Max[x, y, z]\"\n    assert mcode(Min(x, y, z)) == \"Min[x, y, z]\"\n", "def test_TrigonometricFunctions():\n    assert mcode(sin(x)) == \"Sin[x]\"\n    assert mcode(cos(x)) == \"Cos[x]\"\n    assert mcode(exp(x)) == \"Exp[x]\"\n    assert mcode(exp(x) * sin(y) + cos(z)) == \"Cos[z] + Exp[x]*Sin[y]\"\n", "def test_Sum():\n    assert mcode(Sum(x**n, (n, 1, oo))) == \"Hold[Sum[x^n, {n, 1, Infinity}]]\"\n    assert mcode(Sum(x**n, (n, 0, m))) == \"Hold[Sum[x^n, {n, 0, m}]]\"\n    assert mcode(Sum(x**n, (n, 0, m), (m, 1, oo))) == \"Hold[Sum[x^n, {n, 0, m}, {m, 1, Infinity}]]\"\n", "def test_MaxMin():\n    assert mcode(Max(x, y)) == \"Max[x, y]\"\n    assert mcode(Min(x, y)) == \"Min[x, y]\"\n", "def test_CustomFunction():\n        return sin(x) + cos(x)\n    assert mcode(custom_func(x), user_functions={'custom_func': 'CustomFunction'}) == \"CustomFunction[x]\"\n"], "sample_32": ["def test_key_transform_expression_wrapper(self):\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.annotate(\n            expr=ExpressionWrapper(\n                KeyTransform('c', 'value'),\n                output_field=IntegerField(),\n            ),\n        ).filter(expr__gt=5),\n        [self.objs[4]],\n    )\n", "def test_key_transform_with_list_index(self):\n    obj = NullableJSONModel.objects.create(value=[{'a': 1}, {'b': 2}])\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__1__b=2),\n        [obj],\n    )\n", "def test_key_transform_annotation_expression_with_list(self):\n    obj = NullableJSONModel.objects.create(value={'d': [1, 2, 3, 2]})\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__d__isnull=False).annotate(\n            key=F('value__d'),\n            chain=F('key__3'),\n            expr=Cast('key', models.JSONField()),\n        ).filter(chain=F('expr__1')),\n        [obj],\n    )\n", "def test_key_exact_with_key_transform(self):\n    self.assertIs(NullableJSONModel.objects.filter(\n        **{'value__baz__exact': 'c'}\n    ).exists(), False)\n    self.assertIs(NullableJSONModel.objects.filter(\n        **{'value__baz__exact': KeyTransform('c', 'value__baz')}\n    ).exists(), True)\n", "def test_key_transform_annotation_expression_with_f_expression(self):\n    obj = NullableJSONModel.objects.create(value={'d': ['e', 'e']})\n    self.assertSequenceEqual(\n        NullableJSONModel.objects.filter(value__d__0__isnull=False).annotate(\n            key=F('value__d'),\n            chain=F('key__1'),\n            expr=ExpressionWrapper(Value('e'), output_field=models.CharField()),\n        ).filter(chain=F('expr')),\n        [obj],\n    )\n"], "sample_128": ["def test_Method_postprocess():\n    opt = {'method': 'newton'}\n    Method.postprocess(opt)\n\n    assert opt == {'method': 'newton'}\n", "def test_Method_postprocess():\n    opt = {'method': 'newton'}\n    Method.postprocess(opt)\n\n    assert opt == {'method': 'newton'}\n\n    raises(OptionError, lambda: Method.preprocess(10))\n", "def test_Method_postprocess():\n    opt = {'method': 'NEWTON'}\n    Method.postprocess(opt)\n\n    assert opt == {'method': 'newton'}\n", "def test_Options_init_with_gens_and_args():\n    opt = Options((x, y, z), {'domain': 'ZZ', 'gens': (x, y)})\n    raises(OptionError, lambda: opt)\n\n    opt = Options((x, y, z), {'domain': 'ZZ', 'expand': False, 'auto': True})\n    assert opt.domain == ZZ\n    assert opt.expand is False\n    assert opt.auto is True\n", "def test_Method_postprocess():\n    opt = {'method': 'test'}\n    Method.postprocess(opt)\n\n    assert opt == {'method': 'test'}\n"], "sample_144": ["def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n", "def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n", "def test_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n", "def test_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[0, 0], Q.symmetric(X)) == X[0, 0]\n", "def test_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    X = MatrixSymbol('X', 4, 4)\n    assert refine(X[2, 3], Q.symmetric(X)) == X[3, 2]\n    assert refine(X[3, 2], Q.symmetric(X)) == X[3, 2]\n"], "sample_35": ["    def test_modelchoicefield_to_field_name(self):\n        # Create choices for the model choice field tests below.\n        ChoiceModel.objects.create(pk=1, name='a')\n        ChoiceModel.objects.create(pk=2, name='b')\n        ChoiceModel.objects.create(pk=3, name='c')\n\n        # ModelChoiceField with to_field_name\n        e = {\n            'required': 'REQUIRED',\n            'invalid_choice': 'INVALID CHOICE',\n        }\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(), to_field_name='name', error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean, '')\n        self.assertFormErrors(['INVALID CHOICE'], f.clean, 'd')\n", "    def test_limit_choices_to(self):\n        ChoiceModel.objects.create(pk=1, name='a')\n        ChoiceModel.objects.create(pk=2, name='b')\n        ChoiceModel.objects.create(pk=3, name='c')\n\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(), limit_choices_to={'pk__gt': 1})\n        self.assertEqual([c[0] for c in f.choices], [2, 3])\n\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(), limit_choices_to={'pk__in': [2, 3]})\n        self.assertEqual([c[0] for c in f.choices], [2, 3])\n\n            return {'pk__gt': 1}\n        f = ModelChoiceField(queryset=ChoiceModel.objects.all(), limit_choices_to=limit_choices_to)\n        self.assertEqual([c[0] for c in f.choices], [2, 3])\n", "    def test_custom_field(self):\n        class CustomField(ChoiceField):\n            default_error_messages = {\n                'required': 'CUSTOM REQUIRED MESSAGE',\n                'invalid_choice': 'CUSTOM INVALID CHOICE MESSAGE',\n            }\n\n        f = CustomField(choices=[('a', 'aye')])\n        self.assertFormErrors(['CUSTOM REQUIRED MESSAGE'], f.clean, '')\n        self.assertFormErrors(['CUSTOM INVALID CHOICE MESSAGE'], f.clean, 'b')\n", "def test_has_changed(self):\n    queryset = ChoiceModel.objects.all()\n    f1 = ModelChoiceField(queryset=queryset)\n    f2 = ModelMultipleChoiceField(queryset=queryset)\n    self.assertTrue(f1.has_changed(None, '2'))\n    self.assertTrue(f2.has_changed(None, ['2']))\n    self.assertFalse(f1.has_changed('1', '1'))\n    self.assertFalse(f2.has_changed(['1'], ['1']))\n", "def test_modelchoicefield_to_field(self):\n    # Create choices for the model choice field tests below.\n    ChoiceModel.objects.create(pk=1, name='x', extra_info='extra1')\n    ChoiceModel.objects.create(pk=2, name='y', extra_info='extra2')\n\n    # ModelChoiceField with to_field_name\n    e = {\n        'required': 'REQUIRED',\n        'invalid_choice': 'INVALID CHOICE',\n    }\n    f = ModelChoiceField(queryset=ChoiceModel.objects.all(), to_field_name='extra_info', error_messages=e)\n    self.assertFormErrors(['REQUIRED'], f.clean, '')\n    self.assertFormErrors(['INVALID CHOICE'], f.clean, 'extra3')\n    self.assertEqual(f.clean('extra1').pk, 1)\n"], "sample_61": ["    def test_decimal_subclass_format(self):\n        class EuroDecimal(Decimal):\n                amount = super().__format__(specifier, **kwargs)\n                return \"\u20ac {}\".format(amount)\n\n        self.assertEqual(nformat(EuroDecimal(\"1234.56\"), \".\"), \"\u20ac 1234.56\")\n        self.assertEqual(nformat(EuroDecimal(\"1234.56\"), \".\", grouping=3, thousand_sep=\",\", force_grouping=True), \"\u20ac 1,234.56\")\n", "def test_decimal_subclass_formatting(self):\n    class CustomDecimal(Decimal):\n        \"\"\"\n        Wrapper for Decimal which appends 'Custom' to the amount.\n        \"\"\"\n\n            amount = super().__format__(specifier, **kwargs)\n            return \"{} Custom\".format(amount)\n\n    self.assertEqual(nformat(CustomDecimal(\"1234\"), \".\"), \"1234 Custom\")\n    self.assertEqual(nformat(CustomDecimal(\"1234.2\"), \".\"), \"1234.2 Custom\")\n    self.assertEqual(nformat(CustomDecimal(\"1234\"), \".\", decimal_pos=2), \"1234.00 Custom\")\n    self.assertEqual(nformat(CustomDecimal(\"1234\"), \".\", grouping=2, thousand_sep=\",\"), \"1234 Custom\")\n    self.assertEqual(nformat(CustomDecimal(\"1234\"), \".\", grouping=2, thousand_sep=\",\", force_grouping=True), \"12,34 Custom\")\n    self.assertEqual(nformat(CustomDecimal(\"-1234.33\"), \".\", decimal_pos=1), \"-1234.3 Custom\")\n", "    def test_decimal_subclass_formatting(self):\n        class EuroDecimal(Decimal):\n                amount = super().__format__(specifier, **kwargs)\n                return \"\u20ac {}\".format(amount)\n\n        self.assertEqual(nformat(EuroDecimal(\"1234.56\"), \".\"), \"\u20ac 1234.56\")\n        self.assertEqual(nformat(EuroDecimal(\"1234.56\"), \".\", decimal_pos=2), \"\u20ac 1234.56\")\n        self.assertEqual(nformat(EuroDecimal(\"1234.56\"), \".\", grouping=3, thousand_sep=\",\"), \"\u20ac 12,34.56\")\n", "def test_decimal_subclass_with_grouping(self):\n    class EuroDecimal(Decimal):\n        \"\"\"\n        Wrapper for Decimal which prefixes each amount with the \u20ac symbol.\n        \"\"\"\n\n            amount = super().__format__(specifier, **kwargs)\n            return \"\u20ac {}\".format(amount)\n\n    self.assertEqual(\n        nformat(EuroDecimal(\"1234567.89\"), \".\", grouping=3, thousand_sep=\",\", force_grouping=True),\n        \"\u20ac 1,234,567.89\"\n    )\n", "def test_decimal_subclass_with_formatting(self):\n    class CustomDecimal(Decimal):\n        \"\"\"\n        Custom Decimal subclass with custom formatting.\n        \"\"\"\n\n            amount = super().__format__(specifier, **kwargs)\n            return f\"${amount}USD\"\n\n    self.assertEqual(\n        nformat(CustomDecimal(\"1234.56\"), \".\", decimal_pos=2, grouping=3, thousand_sep=\",\"),\n        \"$1,234.56USD\"\n    )\n"], "sample_108": ["def test_linear_svc_max_iter_convergence():\n    # Test that LinearSVC converges when max_iter is set\n    clf = svm.LinearSVC(max_iter=10000, random_state=0)\n    clf.fit(X, Y)\n    assert clf.n_iter_ < 10000  # Check if max_iter was reached\n", "def test_linear_svc_decision_function():\n    # Test decision_function in LinearSVC\n    X = [[0], [1], [2], [3]]\n    y = [0, 1, 2, 3]\n    clf = svm.LinearSVC()\n    clf.fit(X, y)\n    dec = clf.decision_function(X)\n    expected_dec = np.array([[-2.5, -1.5, 0.5, 1.5]]).T\n    assert_array_almost_equal(dec, expected_dec)\n", "def test_svc_gamma_scale_non_zero_var():\n    # Test gamma='scale' with a dataset where variance is not zero.\n    X, y = np.random.rand(10, 20), np.random.randint(0, 2, 10)\n\n    clf = svm.SVC(gamma='scale')\n    assert_no_warnings(clf.fit, X, y)\n    assert_almost_equal(clf._gamma, 1.0 / (X.shape[1] * np.var(X)))\n", "def test_linear_svc_predict_proba():\n    # Test predict_proba method for LinearSVC\n    clf = svm.LinearSVC(random_state=0, probability=True).fit(X, Y)\n    with pytest.raises(AttributeError, match=\"predict_proba is not available when probability=False\"):\n        clf.predict_proba(T)\n\n    # Test predict_proba with probability=True\n    clf = svm.LinearSVC(random_state=0, probability=True)\n    clf.fit(iris.data, iris.target)\n    prob_predict = clf.predict_proba(iris.data)\n    assert_array_almost_equal(np.sum(prob_predict, 1), np.ones(iris.data.shape[0]))\n    assert np.mean(np.argmax(prob_predict, 1) == clf.predict(iris.data)) > 0.9\n\n    # Test predict_log_proba\n    assert_almost_equal(clf.predict_proba(iris.data), np.exp(clf.predict_log_proba(iris.data)), 8)\n", "def test_svc_decision_function_scale_parameter():\n    # Test that SVC's decision_function scales correctly with the gamma parameter\n    X, y = [[0.0], [1.0]], [0, 1]\n\n    clf = svm.SVC(kernel='rbf', gamma='scale')\n    assert_no_warnings(clf.fit, X, y)\n    dec_scale = clf.decision_function(X)\n\n    clf = svm.SVC(kernel='rbf', gamma='auto')\n    assert_no_warnings(clf.fit, X, y)\n    dec_auto = clf.decision_function(X)\n\n    assert np.all(np.abs(dec_scale) < np.abs(dec_auto))\n"], "sample_141": ["def test_issue_14547_addend_with_dimensions():\n    # Test the case where an addend has dimensions\n    from sympy.physics.units import foot, inch\n    e = foot + 2 * inch\n    assert e.is_Add and set(e.args) == {foot, 2 * inch}\n    assert e.simplify() == 26 * inch\n", "def test_issue_18107():\n    # Test that conversion to Planck units works correctly\n    from sympy.physics.units import gravitational_constant, speed_of_light, hbar\n    from sympy.physics.units import atomic_mass_constant\n    assert convert_to(atomic_mass_constant, [gravitational_constant, speed_of_light, hbar]).n() == 7.62963085040767e-20*gravitational_constant**(-0.5)*hbar**0.5*speed_of_light**0.5\n", "def test_issue_15678():\n    # Test conversion of units with multiplicative constant\n    u = Quantity('u')\n    u.set_global_relative_scale_factor(2, meter)\n    assert convert_to(u, centimeter) == 200 * centimeter\n    assert convert_to(u, inch) == 200 / 2.54 * inch\n", "def test_issue_14547_additional():\n    from sympy.physics.units import foot, inch\n    from sympy import Eq\n    assert (foot + inch).is_zero is None\n    assert (foot + inch).is_positive is None\n    assert (foot + inch).is_nonnegative is True\n    assert (foot + inch).is_negative is False\n    assert (foot + inch).is_algebraic is True\n    assert (foot + inch).is_rational is False\n    assert Eq(foot + inch, 1) is not None  # might be False or unevaluated\n", "def test_issue_14898():\n    from sympy.physics.units import foot, inch\n    from sympy import symbols\n    x = symbols('x', positive=True)\n    assert log(x*foot).simplify() == log(x) + log(foot)\n"], "sample_142": ["def test_has_variety():\n    assert has_variety((1, 2, 1)) is True\n    assert has_variety((1, 1, 1)) is False\n", "def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((1,))) == [(1,), (-1,)]\n    assert list(permute_signs((0,))) == [(0,)]\n    assert list(permute_signs((0, 1))) == [(0, 1), (0, -1)]\n    assert list(permute_signs((1, 0))) == [(1, 0), (-1, 0)]\n", "def test_rotations_generator():\n    assert isinstance(rotations('ab'), type(rotations('ab')))  # Test if rotations returns a generator\n    assert list(rotations('ab')) == [['a', 'b'], ['b', 'a']]\n    assert list(rotations(range(3))) == [[0, 1, 2], [1, 2, 0], [2, 0, 1]]\n    assert list(rotations(range(3), dir=-1)) == [[0, 1, 2], [2, 0, 1], [1, 2, 0]]\n", "def test_permutations():\n    assert list(permutations([1, 2, 3])) == [\n        (1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2), (3, 2, 1)\n    ]\n    assert list(permutations([1, 2, 3], 2)) == [\n        (1, 2), (1, 3), (2, 1), (2, 3), (3, 1), (3, 2)\n    ]\n    assert list(permutations([1, 2, 2])) == [\n        (1, 2, 2), (1, 2, 2), (2, 1, 2), (2, 2, 1), (2, 1, 2), (2, 2, 1)\n    ]\n    assert list(permutations([1, 2, 2], 2)) == [\n        (1, 2), (1, 2), (2, 1), (2, 1), (2, 2), (2, 2)\n    ]\n    assert list(permutations([])) == [()]\n    assert list(permutations([1])) == [(1,)]\n    assert list(permutations([1, 1])) == [(1, 1), (1, 1)]\n    assert list(permutations([1, 2], repetition=True)) == [\n        (1, 1), (1, 2), (2, 1), (2, 2)\n    ]\n    assert list(permutations([1, 2], repetition=True, length=2)) == [\n        (1, 1), (1, 2), (2, 1), (2, 2)\n    ]\n    assert list(permutations([1, 2], repetition=True, length=3)) == []\n", "def test_ibin():\n    assert ibin(10, 4) == (2, 2)\n    assert ibin(255, 8) == (11111111, 0)\n    assert ibin(0, 8) == (0, 0)\n    raises(ValueError, lambda: ibin(-1, 2))\n    raises(ValueError, lambda: ibin(10, 0))\n    raises(ValueError, lambda: ibin(10, -2))\n"], "sample_105": ["def test_transform_hard_voting():\n    \"\"\"Check transform method of VotingClassifier with hard voting on toy dataset.\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    X = np.array([[-1.1, -1.5], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n    y = np.array([1, 1, 2, 2])\n\n    eclf = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='hard').fit(X, y)\n\n    assert_array_equal(eclf.transform(X).shape, (4, 3))\n    assert_array_equal(eclf.transform(X), np.array([\n        [1, 1, 1],\n        [1, 1, 1],\n        [1, 2, 2],\n        [2, 2, 2]\n    ]))\n", "def test_transform_hard_voting():\n    \"\"\"Check transform method of VotingClassifier on toy dataset for hard voting.\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    X = np.array([[-1.1, -1.5], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n    y = np.array([1, 1, 2, 2])\n\n    eclf = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='hard').fit(X, y)\n\n    assert_array_equal(eclf.transform(X).shape, (4, 3))\n    assert_array_equal(eclf.transform(X), np.array([[1, 1, 1], [1, 1, 1], [2, 2, 1], [2, 2, 2]]))\n", "def test_regressor_sample_weight():\n    \"\"\"Tests sample_weight parameter of VotingRegressor\"\"\"\n    reg1 = DummyRegressor(strategy='mean')\n    reg2 = DummyRegressor(strategy='median')\n    ereg1 = VotingRegressor([('mean', reg1), ('median', reg2)],\n                            weights=[1, 2]).fit(X_r, y_r, sample_weight=np.ones((len(y_r),)))\n    ereg2 = VotingRegressor([('mean', reg1), ('median', reg2)],\n                            weights=[1, 2]).fit(X_r, y_r)\n    assert_array_equal(ereg1.predict(X_r), ereg2.predict(X_r))\n\n    sample_weight = np.random.RandomState(123).uniform(size=(len(y_r),))\n    ereg3 = VotingRegressor([('mean', reg1), ('median', reg2)],\n                            weights=[1, 2])\n    ereg3.fit(X_r, y_r, sample_weight)\n    reg1.fit(X_r, y_r, sample_weight)\n    assert_array_equal(ereg3.predict(X_r), reg1.predict(X_r))\n", "def test_transform_hard():\n    \"\"\"Check transform method of VotingClassifier with 'hard' voting.\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    X = np.array([[-1.1, -1.5], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n    y = np.array([1, 1, 2, 2])\n\n    eclf = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='hard').fit(X, y)\n\n    expected_transform = np.array([[1, 1, 1],\n                                   [1, 1, 1],\n                                   [1, 2, 2],\n                                   [2, 2, 2]])\n    assert_array_equal(eclf.transform(X), expected_transform)\n", "def test_regression_transform():\n    \"\"\"Check transform method of VotingRegressor on toy dataset.\"\"\"\n    reg1 = DummyRegressor(strategy='mean')\n    reg2 = DummyRegressor(strategy='median')\n    reg3 = DummyRegressor(strategy='quantile', quantile=.2)\n    X_r = np.array([[1.1], [2.2], [3.3], [4.4]])\n    y_r = np.array([1, 2, 3, 4])\n\n    ereg1 = VotingRegressor([('mean', reg1), ('median', reg2), ('quantile', reg3)]).fit(X_r, y_r)\n    ereg2 = VotingRegressor([('mean', reg1), ('median', reg2), ('quantile', reg3)], weights=[1, 2, 1]).fit(X_r, y_r)\n\n    assert_array_equal(ereg1.transform(X_r).shape, (4, 3))\n    assert_array_equal(ereg2.transform(X_r).shape, (4, 3))\n    assert_array_almost_equal(ereg1.transform(X_r), ereg2.transform(X_r))\n"], "sample_53": ["def test_add_custom_fk_with_hardcoded_to_and_m2m(self):\n    class HardcodedManyToManyField(models.ManyToManyField):\n            kwargs[\"to\"] = \"testapp.Author\"\n            super().__init__(*args, **kwargs)\n\n            name, path, args, kwargs = super().deconstruct()\n            del kwargs[\"to\"]\n            return name, path, args, kwargs\n\n    book_hardcoded_m2m_to = ModelState(\n        \"testapp\",\n        \"Book\",\n        [\n            (\"authors\", HardcodedManyToManyField()),\n        ],\n    )\n    changes = self.get_changes(\n        [self.author_empty],\n        [self.author_empty, book_hardcoded_m2m_to],\n    )\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Book\")\n", "def test_add_model_with_indexes_and_constraints(self):\n    author = ModelState(\n        \"otherapp\",\n        \"Author\",\n        [\n            (\"id\", models.AutoField(primary_key=True)),\n            (\"name\", models.CharField(max_length=200)),\n        ],\n        {\n            \"indexes\": [\n                models.Index(fields=[\"name\"], name=\"author_name_idx\")\n            ],\n            \"constraints\": [\n                models.CheckConstraint(\n                    check=models.Q(name__contains=\"Bob\"), name=\"name_contains_bob\"\n                )\n            ]\n        },\n    )\n    changes = self.get_changes([], [author])\n    added_index = models.Index(\n        fields=[\"name\"], name=\"author_name_idx\"\n    )\n    added_constraint = models.CheckConstraint(\n        check=models.Q(name__contains=\"Bob\"), name=\"name_contains_bob\"\n    )\n    self.assertEqual(len(changes[\"otherapp\"]), 1)\n    migration = changes[\"otherapp\"][0]\n    self.assertEqual(len(migration.operations), 3)\n    self.assertOperationTypes(\n        changes, \"otherapp\", 0, [\"CreateModel\", \"AddIndex\", \"AddConstraint\"]\n    )\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 0, name=\"Author\")\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 1, model_name=\"author\", index=added_index)\n    self.assertOperationAttributes(changes, \"otherapp\", 0, 2, model_name=\"author\", constraint=added_constraint)\n", "def test_create_model_with_through_model_and_index(self):\n    \"\"\"\n    Adding a m2m with a through model, an index, and the models that use it should be\n    ordered correctly.\n    \"\"\"\n    changes = self.get_changes(\n        [], [self.author_with_m2m_through_and_index, self.publisher, self.contract]\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(\n        changes,\n        \"testapp\",\n        0,\n        [\n            \"CreateModel\",\n            \"CreateModel\",\n            \"CreateModel\",\n            \"AddField\",\n            \"AddIndex\",\n        ],\n    )\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Author\")\n    self.assertOperationAttributes(changes, \"testapp\", 0, 1, name=\"Publisher\")\n    self.assertOperationAttributes(changes, \"testapp\", 0, 2, name=\"Contract\")\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 3, model_name=\"author\", name=\"publishers\"\n    )\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 4, model_name=\"contract\", name=\"author_publisher_idx\"\n    )\n", "def test_rename_fk_with_related_name(self):\n    \"\"\"\n    Tests autodetection of renamed models while simultaneously renaming the\n    related name of a field that points to the renamed model.\n    \"\"\"\n    changes = self.get_changes(\n        [self.author_with_book, self.book],\n        [self.author_renamed_with_book, self.book_with_field_and_author_renamed],\n        MigrationQuestioner({\"ask_rename\": True, \"ask_rename_model\": True}),\n    )\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"RenameModel\"])\n    self.assertOperationAttributes(\n        changes, \"testapp\", 0, 0, old_name=\"Author\", new_name=\"Writer\"\n    )\n    # Right number/type of migrations for related field rename?\n    self.assertNumberMigrations(changes, \"otherapp\", 1)\n    self.assertOperationTypes(changes, \"otherapp\", 0, [\"RenameField\"])\n    self.assertOperationAttributes(\n        changes, \"otherapp\", 0, 0, old_name=\"author\", new_name=\"writer\"\n    )\n", "    def test_add_custom_fk_with_hardcoded_to_and_custom_db_table(self):\n        class HardcodedForeignKey(models.ForeignKey):\n                kwargs[\"to\"] = \"testapp.Author\"\n                super().__init__(*args, **kwargs)\n\n                name, path, args, kwargs = super().deconstruct()\n                del kwargs[\"to\"]\n                return name, path, args, kwargs\n\n        author_custom_db_table = ModelState(\n            \"testapp\",\n            \"Author\",\n            [\n                (\"id\", models.AutoField(primary_key=True)),\n            ],\n            {\n                \"db_table\": \"custom_author_table\",\n            }\n        )\n        book_hardcoded_fk_to_and_custom_db_table = ModelState(\n            \"testapp\",\n            \"Book\",\n            [\n                (\"author\", HardcodedForeignKey(on_delete=models.CASCADE)),\n            ],\n            {\n                \"db_table\": \"custom_book_table\",\n            }\n        )\n        changes = self.get_changes(\n            [author_custom_db_table],\n            [author_custom_db_table, book_hardcoded_fk_to_and_custom_db_table],\n        )\n        self.assertNumberMigrations(changes, \"testapp\", 1)\n        self.assertOperationTypes(changes, \"testapp\", 0, [\"CreateModel\"])\n        self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"Book\")\n        # Check that the foreign key has the custom db_table\n        fk_field = changes[\"testapp\"][0].operations[0].fields[0][1]\n        self.assertEqual(fk_field.remote_field.model, \"testapp.Author\")\n        self.assertEqual(fk_field.remote_field.field_name, \""], "sample_137": ["def test_permutations():\n    assert list(permutations([1, 2, 3])) == [(1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2), (3, 2, 1)]\n    assert list(permutations([1, 2, 3], 2)) == [(1, 2), (1, 3), (2, 1), (2, 3), (3, 1), (3, 2)]\n    assert list(permutations('abc')) == [('a', 'b', 'c'), ('a', 'c', 'b'), ('b', 'a', 'c'), ('b', 'c', 'a'), ('c', 'a', 'b'), ('c', 'b', 'a')]\n    assert list(permutations('abc', 2)) == [('a', 'b'), ('a', 'c'), ('b', 'a'), ('b', 'c'), ('c', 'a'), ('c', 'b')]\n", "def test_permute_signs():\n    from sympy.utilities.iterables import permute_signs\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n", "def test_is_palindromic_with_examples():\n    assert is_palindromic('aba')\n    assert is_palindromic('abcba')\n    assert not is_palindromic('abcd')\n    assert is_palindromic('racecar', 2, 7)\n    assert not is_palindromic('racecar', 2, 6)\n    assert is_palindromic('12321')\n    assert not is_palindromic('123421')\n", "def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((1, 0, 0))) == [(1, 0, 0), (-1, 0, 0), (1, 0, -0), (-1, 0, -0)]\n", "def test_is_palindromic_different_data_types():\n    assert is_palindromic('abcba')\n    assert is_palindromic([1, 2, 3, 2, 1])\n    assert is_palindromic((1, 2, 3, 2, 1))\n    assert not is_palindromic('abccba')\n    assert not is_palindromic([1, 2, 3, 3, 1])\n    assert not is_palindromic((1, 2, 3, 3, 1))\n"], "sample_86": ["def test_record_testsuite_property_without_junitxml(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", \"all good\")\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 0\n", "def test_record_testsuite_property_type_checking_value(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", 10)\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p1_node.assert_attr(name=\"stats\", value=\"10\")\n", "def test_record_testsuite_property_value_conversion(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", 10)\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p1_node.assert_attr(name=\"stats\", value=\"10\")\n", "def test_record_testsuite_property_no_junit(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", \"all good\")\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 0\n    result.stdout.no_fnmatch_line(\"*test_record_testsuite_property_no_junit.py::test_func1*\")\n", "def test_record_testsuite_property_duplicate_keys(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", \"all good\")\n            record_testsuite_property(\"stats\", \"overwritten\")\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p2_node = properties_node.find_nth_by_tag(\"property\", 1)\n    p1_node.assert_attr(name=\"stats\", value=\"all good\")\n    p2_node.assert_attr(name=\"stats\", value=\"overwritten\")\n"], "sample_83": ["def test_template_option_with_empty_module(linter: PyLinter) -> None:\n    output = StringIO()\n    linter.reporter.out = output\n    linter.config.msg_template = \"{path}:{line}:{column}:{end_line}:{end_column}: {msg_id}: {msg} ({symbol})\"\n    linter.open()\n    linter.set_current_module(None)\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\"line-too-long\", line=2, end_lineno=2, end_col_offset=4, args=(3, 4))\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert out_lines[1] == \":1::: C0301: Line too long (1/2) (line-too-long)\"\n    assert out_lines[2] == \":2:0:2:4: C0301: Line too long (3/4) (line-too-long)\"\n", "def test_template_option_with_all_fields(linter: PyLinter) -> None:\n    output = StringIO()\n    linter.reporter.out = output\n    linter.config.msg_template = (\n        \"{path}:{line}:{column}:{end_line}:{end_column}: {msg_id}: {msg} ({symbol}) ({category})\"\n    )\n    linter.open()\n    linter.set_current_module(\"my_mod\")\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\n        \"line-too-long\", line=2, end_lineno=2, end_col_offset=4, args=(3, 4)\n    )\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert out_lines[1] == \"my_mod:1:0::: C0301: Line too long (1/2) (line-too-long) (convention)\"\n    assert out_lines[2] == \"my_mod:2:0:2:4: C0301: Line too long (3/4) (line-too-long) (convention)\"\n", "def test_template_option_with_symbol(linter: PyLinter) -> None:\n    output = StringIO()\n    linter.reporter.out = output\n    linter.config.msg_template = '{path}:{line}:{column}:{symbol}: {msg_id}: {msg}'\n    linter.open()\n    linter.set_current_module(\"my_mod\")\n\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\"line-too-long\", line=2, args=(3, 4))\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert out_lines[1] == \"my_mod:1:0:line-too-long: C0301: Line too long (1/2)\"\n    assert out_lines[2] == \"my_mod:2:0:line-too-long: C0301: Line too long (3/4)\"\n", "def test_color_mapping(linter: PyLinter) -> None:\n    \"\"\"Test the ColorizedTextReporter with custom color_mapping.\"\"\"\n    output = StringIO()\n    color_mapping = {\"C\": MessageStyle(\"cyan\", (\"bold\",)), \"W\": MessageStyle(\"yellow\")}\n    linter.register_reporter(ColorizedTextReporter, color_mapping=color_mapping)\n    linter.set_option(\"reports\", False)\n    linter.set_option(\"output-format\", \"colorized\")\n    linter.reporter.out = output\n    linter.open()\n    linter.set_current_module(\"my_mod\")\n\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\"import-error\", line=2, args=(\"some_module\",))\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert \"\\033[1;36m************* Module my_mod\\033[0m\" in out_lines[1]\n    assert \"\\033[1;36mC0301: Line too long (1/2) (line-too-long)\\033[0m\" in out_lines[2]\n    assert \"\\033[1;33mE0401: Unable to import 'some_module' (import-error)\\033[0m\" in out_lines[3]\n", "def test_color_mapping_option(linter):\n    \"\"\"Test the color_mapping option of ColorizedTextReporter.\"\"\"\n    output = StringIO()\n    linter.reporter.out = output\n    custom_color_mapping = {\n        \"C\": MessageStyle(\"blue\"),\n        \"W\": MessageStyle(\"yellow\"),\n        \"E\": MessageStyle(\"red\", (\"bold\",)),\n    }\n    linter.config.reporter_options = {\"color_mapping\": custom_color_mapping}\n    linter.set_option(\"output-format\", \"colorized\")\n    linter.open()\n    linter.set_current_module(\"my_module\")\n    linter.add_message(\"C0301\", line=1, args=(1, 2))\n    linter.add_message(\"W0301\", line=2, args=(3, 4))\n    linter.add_message(\"E0301\", line=3, args=(5, 6))\n\n    out_lines = output.getvalue().split(\"\\n\")\n    assert \"\\033[34m\" in out_lines[1]  # blue color for convention message\n    assert \"\\033[33m\" in out_lines[2]  # yellow color for warning message\n    assert \"\\033[31;1m\" in out_lines[3]  # red bold color for error message\n"], "sample_7": ["    def test_ticker_detects_file_changes(self):\n        reloader = autoreload.StatReloader()\n        reloader.watch_file(self.existing_file)\n        ticker = reloader.tick()\n        next(ticker)\n        self.increment_mtime(self.existing_file)\n        with mock.patch.object(reloader, 'notify_file_changed') as notify_mock:\n            next(ticker)\n        self.assertEqual(notify_mock.call_count, 1)\n        self.assertCountEqual(notify_mock.call_args[0], [self.existing_file])\n", "    def test_tick_increments_mtimes(self):\n        reloader = StatReloader()\n        reloader.watch_file(self.existing_file)\n        ticker = reloader.tick()\n        snapshot1 = dict(reloader.snapshot_files())\n        next(ticker)\n        self.increment_mtime(self.existing_file)\n        snapshot2 = dict(reloader.snapshot_files())\n        next(ticker)\n        self.assertNotEqual(snapshot1[self.existing_file], snapshot2[self.existing_file])\n", "    def test_get_child_arguments_with_main(self):\n        with mock.patch('django.__main__.__file__', '/usr/lib/pythonX.Y/site-packages/django/__main__.py'):\n            with mock.patch('django.utils.autoreload.sys.executable', '/usr/bin/python'):\n                with mock.patch('django.utils.autoreload.sys.warnoptions', ['all']):\n                    with mock.patch('django.utils.autoreload.sys.argv', ['/usr/lib/pythonX.Y/site-packages/django/__main__.py', 'runserver']):\n                        args = autoreload.get_child_arguments()\n        self.assertEqual(args, ['/usr/bin/python', '-Wall', '-m', 'django', 'runserver'])\n", "def test_file_deletion(self, mocked_modules, notify_mock):\n    self.reloader.watch_file(self.existing_file)\n    with self.tick_twice():\n        self.existing_file.unlink()\n    self.assertEqual(notify_mock.call_count, 0)\n", "    def test_notify_file_changed_with_signal_handler(self):\n            return kwargs.get('file_path') == self.existing_file\n\n        self.receiver = autoreload.file_changed.connect(mock_handler)\n        self.reloader = autoreload.BaseReloader()\n        self.reloader.watch_file(self.existing_file)\n        self.reloader.notify_file_changed(self.existing_file)\n        self.assertTrue(mock_handler.called)\n        self.assertEqual(mock_handler.call_count, 1)\n        autoreload.file_changed.disconnect(self.receiver)\n"], "sample_22": ["    def test_compress_string(self):\n        data = \"This is a test string to compress.\"\n        compressed_data = text.compress_string(data.encode())\n        self.assertLess(len(compressed_data), len(data.encode()))\n", "def test_camel_case_to_spaces(self):\n    items = [\n        ('HelloWorld', 'hello world'),\n        ('CamelCaseExample', 'camel case example'),\n        ('XMLHTTPRequest', 'xml http request'),\n        ('IDontKnow', 'i dont know'),\n        ('', ''),\n        ('ALongSingleWord', 'a long single word'),\n    ]\n    for value, output in items:\n        self.assertEqual(text.camel_case_to_spaces(value), output)\n        self.assertEqual(text.camel_case_to_spaces(lazystr(value)), output)\n", "def test_compress_string(self):\n    original_string = 'The quick brown fox jumped over the lazy dog.'\n    compressed_string = text.compress_string(original_string.encode())\n    decompressed_string = GzipFile(fileobj=BytesIO(compressed_string)).read().decode()\n    self.assertEqual(original_string, decompressed_string)\n", "def test_camel_case_to_spaces(self):\n    items = [\n        ('HelloWorld', 'hello world'),\n        ('HelloWorldTest', 'hello world test'),\n        ('HelloWorldTestExample', 'hello world test example'),\n        ('HelloWorldTEST', 'hello world t e s t'),\n    ]\n    for value, output in items:\n        self.assertEqual(text.camel_case_to_spaces(value), output)\n        self.assertEqual(text.camel_case_to_spaces(lazystr(value)), output)\n", "def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('HelloWorldTest'), 'hello world test')\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld123'), 'hello world123')\n    self.assertEqual(text.camel_case_to_spaces('HelloWorldTest123'), 'hello world test123')\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld_Test'), 'hello world_ test')\n    self.assertEqual(text.camel_case_to_spaces(lazystr('HelloWorld')), 'hello world')\n"], "sample_72": ["def test_toolmanager_add():\n    with pytest.warns(UserWarning, match=_EXPECTED_WARNING_TOOLMANAGER):\n        plt.rcParams['toolbar'] = 'toolmanager'\n    fig = plt.gcf()\n    initial_len = len(fig.canvas.manager.toolmanager.tools)\n    assert 'dummy' not in fig.canvas.manager.toolmanager.tools\n    fig.canvas.manager.toolmanager.add_tool('dummy', 'Dummy tool')\n    assert len(fig.canvas.manager.toolmanager.tools) == initial_len + 1\n    assert 'dummy' in fig.canvas.manager.toolmanager.tools\n", "def test_tight_layout_with_subfigs():\n    fig = plt.figure()\n    sfigs = fig.subfigures(2, 1)\n    axs1 = sfigs[0].subplots(1, 2)\n    axs2 = sfigs[1].subplots(2, 1)\n    fig.tight_layout()\n    # Add assertions to check if tight_layout was applied correctly\n", "def test_figure_ctor():\n    fig = Figure()\n    assert fig.get_tight_layout() is False\n\n    fig = Figure(tight_layout=True)\n    assert fig.get_tight_layout() is True\n\n    fig = Figure(constrained_layout=True)\n    assert fig.get_constrained_layout() is True\n\n    fig = Figure(layout='tight')\n    assert fig.get_tight_layout() is True\n\n    fig = Figure(layout='constrained')\n    assert fig.get_constrained_layout() is True\n\n    fig = Figure(layout='none')\n    assert fig.get_tight_layout() is False\n    assert fig.get_constrained_layout() is False\n\n    fig = Figure(layout=None)\n    assert fig.get_tight_layout() is False\n    assert fig.get_constrained_layout() is False\n\n    fig = Figure(tight_layout={'pad': 2.0})\n    assert fig.get_tight_layout() is True\n    assert fig.get_layout_engine().get()['pad'] == 2.0\n\n    fig = Figure(constrained_layout={'w_pad': 0.5})\n    assert fig.get_constrained_layout() is True\n    assert fig.get_layout_engine().get()['w_pad'] == 0.5\n\n    with pytest.raises(ValueError, match=\"Invalid value for 'layout': 'invalid'\"):\n        Figure(layout='invalid')\n\n    with pytest.warns(UserWarning, match=\"The Figure parameters 'tight_layout' and 'constrained_layout' cannot be used together\"):\n        Figure(tight_layout=True, constrained_layout=True)\n\n    with pytest.warns(UserWarning, match=\"The Figure parameters 'layout' and 'tight_layout' cannot be used together\"):\n        Figure(layout='tight', tight_layout=True)\n\n    with pytest.warns(UserWarning, match=\"The Figure parameters 'layout' and 'constrained_layout' cannot be used together\"):\n        Figure(layout='", "def test_widgetlock_zoompan_rubberband():\n    fig, ax = plt.subplots()\n    ax.plot([0, 1], [0, 1])\n    fig.canvas.widgetlock(ax)\n    tb = NavigationToolbar2(fig.canvas)\n    tb.zoom()\n    assert ax.get_navigate_mode() is None\n    tb.pan()\n    assert ax.get_navigate_mode() is None\n    tb.home()\n    assert ax.get_xlim() == (0, 1)\n    assert ax.get_ylim() == (0, 1)\n    tb.rubberband(use_blit=False)\n    assert ax.get_navigate_mode() == 'ZOOM'\n    tb.zoom()\n    assert ax.get_navigate_mode() == 'ZOOM'\n    tb.pan()\n    assert ax.get_navigate_mode() == 'PAN'\n    tb.zoom()\n    assert ax.get_navigate_mode() == 'ZOOM'\n", "def test_constrained_layout_with_colorbar(grid_spec):\n    fig, ax = plt.subplots(figsize=(4, 4), constrained_layout=True)\n    im = ax.imshow(np.arange(100).reshape((10, 10)))\n    cb = fig.colorbar(im, ax=ax, use_gridspec=grid_spec)\n\n    fig.canvas.draw()\n\n    # Check that the colorbar is not outside the figure\n    fig_bbox = fig.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n    cb_bbox = cb.ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n    assert fig_bbox.contains(cb_bbox)\n\n    # Check that the colorbar is not overlapping with the main axes\n    ax_bbox = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n    assert not ax_bbox.overlaps(cb_bbox)\n"], "sample_150": ["def test_solve_generic():\n    x0, y0, x1, y1, r = symbols('x0 y0 x1 y1 r')\n\n    f_1 = (x - x0)**2 + (y - y0)**2 - r**2\n    f_2 = (x - x1)**2 + (y - y1)**2 - r**2\n\n    result = solve_poly_system([f_1, f_2], x, y)\n\n    assert len(result) == 2 and all(len(r) == 2 for r in result)\n    assert all(r.count(x) == 1 and r.count(y) == 1 for r in flatten(result))\n", "def test_solve_generic():\n    x0, y0, x1, y1, r = symbols('x0 y0 x1 y1 r')\n\n    f_1 = (x - x0)**2 + (y - y0)**2 - r**2\n    f_2 = (x - x1)**2 + (y - y1)**2 - r**2\n\n    result = solve_poly_system([f_1, f_2], x, y)\n\n    assert len(result) == 2 and all(len(r) == 2 for r in result)\n    assert all(r.count(sqrt) == 2 for r in flatten(result))\n\n    # Test with a system that has no solutions\n    f_1 = x**2 + y - 2\n    f_2 = x + y**2 - 3\n\n    result = solve_poly_system([f_1, f_2], x, y)\n\n    assert result == []\n", "def test_solve_poly_system_mixed_polynomials():\n    x0, y0 = symbols('x0 y0')\n    f_1 = Poly(x0**2 + y0 - 1)\n    f_2 = y0**2 + x0 - 1\n    assert solve_poly_system([f_1, f_2], x0, y0) == [(1, 0), (0, 1)]\n", "def test_solve_poly_system_rational_coefficients():\n    x0, y0, x1, y1, r = symbols('x0 y0 x1 y1 r', rational=True)\n\n    f_1 = (x - x0)**2 + (y - y0)**2 - r**2\n    f_2 = (x - x1)**2 + (y - y1)**2 - r**2\n\n    result = solve_poly_system([f_1, f_2], x, y)\n\n    assert len(result) == 2 and all(len(r) == 2 for r in result)\n    assert all(len(r.atoms(Rational)) > 0 for r in flatten(result))\n", "def test_solve_poly_system_with_different_domains():\n    x, y = symbols('x y')\n\n    # Test with integers\n    assert solve_poly_system([x - y, x - 2*y], x, y, domain='ZZ') == [(0, 0)]\n\n    # Test with rational numbers\n    assert solve_poly_system([x*y - 2*y, 2*y**2 - x**2], x, y, domain='QQ') == \\\n        [(0, 0), (2, -sqrt(2)), (2, sqrt(2))]\n\n    # Test with complex numbers\n    assert solve_poly_system([y - x**2, y + x**2 + 1], x, y, domain='CC') == \\\n        [(-I*sqrt(S.Half), Rational(-1, 2)), (I*sqrt(S.Half), Rational(-1, 2))]\n"], "sample_40": ["def test_field_deep_copy_widget(self):\n    class CustomTextInput(TextInput):\n        custom_attribute = 'custom_value'\n\n    field = CharField(widget=CustomTextInput())\n    field_copy = copy.deepcopy(field)\n    self.assertIsInstance(field_copy.widget, CustomTextInput)\n    self.assertIsNot(field_copy.widget, field.widget)\n", "def test_field_deep_copy_widget(self):\n    class CustomTextInput(TextInput):\n        custom_attr = 'Custom attribute.'\n\n    widget = CustomTextInput()\n    widget_copy = copy.deepcopy(widget)\n    self.assertIsInstance(widget_copy, CustomTextInput)\n    self.assertIsNot(widget_copy.attrs, widget.attrs)\n    self.assertEqual(widget_copy.custom_attr, widget.custom_attr)\n", "def test_boundfield_initial(self):\n    \"\"\"BoundField.initial should return the initial value.\"\"\"\n    class SomeForm(Form):\n        field = CharField(initial='test')\n    boundfield = SomeForm()['field']\n    self.assertEqual(boundfield.initial, 'test')\n", "def test_label_tag_context(self):\n    class SomeForm(Form):\n        field = CharField()\n\n    boundfield = SomeForm()['field']\n    context = boundfield.label_tag(context={'class': 'custom'})\n    self.assertHTMLEqual(context, '<label for=\"id_field\" class=\"custom\">Field:</label>')\n", "def test_form_field_ordering(self):\n    class TestForm(Form):\n        field_order = ['field2', 'field4', 'field5', 'field6', 'field3']\n        field1 = CharField()\n        field2 = CharField()\n        field3 = CharField()\n        field4 = CharField()\n        field5 = CharField()\n        field6 = CharField()\n\n    p = TestForm()\n    self.assertEqual(list(p.fields), TestForm.field_order)\n\n    class TestFormMissing(Form):\n        field_order = ['field1']\n        field2 = CharField()\n        field4 = CharField()\n        field5 = CharField()\n        field6 = CharField()\n        field3 = CharField()\n\n    p = TestFormMissing()\n    self.assertEqual(list(p.fields), TestForm.field_order)\n\n    class TestFormInit(Form):\n            kwargs.setdefault('field_order', ['field2', 'field4', 'field5', 'field6', 'field3', 'field1'])\n            super().__init__(*args, **kwargs)\n\n        field1 = CharField()\n        field2 = CharField()\n        field3 = CharField()\n        field4 = CharField()\n        field5 = CharField()\n        field6 = CharField()\n\n    p = TestFormInit()\n    order = [*TestForm.field_order, 'field1']\n    self.assertEqual(list(p.fields), order)\n"], "sample_155": ["def test_physical_constant_property():\n    assert not meter.is_physical_constant\n    assert not joule.is_physical_constant\n    assert not day.is_physical_constant\n    assert not second.is_physical_constant\n    assert not volt.is_physical_constant\n    assert not ohm.is_physical_constant\n    assert not centimeter.is_physical_constant\n    assert not kilometer.is_physical_constant\n    assert not kilogram.is_physical_constant\n    assert not pebibyte.is_physical_constant\n    assert elementary_charge.is_physical_constant\n    assert speed_of_light.is_physical_constant\n", "def test_issue_24487():\n    from sympy.core.numbers import I\n    from sympy.physics.units import resistivity, conductivity, ohm, meter, siemens\n\n    rho = Quantity('rho')\n    sigma = Quantity('sigma')\n    SI.set_quantity_dimension(rho, resistivity)\n    SI.set_quantity_dimension(sigma, conductivity)\n    rho.set_global_relative_scale_factor(1, ohm*meter)\n    sigma.set_global_relative_scale_factor(1, siemens/meter)\n    expr = 1 + I * rho * sigma\n    assert SI._collect_factor_and_dimension(expr) == (1 + I, Dimension(1))\n", "def test_prefixed_quantity_definition():\n    pq = Quantity(\"pq\", abbrev=\"pmq\")\n    pq.set_global_relative_scale_factor(10*kilo, meter)\n\n    assert pq.abbrev == Symbol(\"pmq\")\n    assert pq.scale_factor == 10000\n    assert pq.is_prefixed\n", "def test_dimensional_expr_of_physical_constant():\n    assert SI.get_dimensional_expr(elementary_charge) == charge.name\n    assert SI.get_dimensional_expr(speed_of_light) == (length / time).name\n    assert SI.get_dimensional_expr(vacuum_permittivity) == (charge**2 / (length * mass * time**4)).name\n    assert SI.get_dimensional_expr(molar_gas_constant) == (length**2 * mass / (amount_of_substance * temperature * time**2)).name\n    assert SI.get_dimensional_expr(gravitational_constant) == (length**3 * mass / (time**2 * amount_of_substance**2)).name\n", "def test_issue_24062_derivative():\n    from sympy.core.numbers import E\n    from sympy.core.symbol import symbols\n    from sympy.physics.units import impedance, capacitance, time, ohm, farad, second\n\n    R = Quantity('R')\n    C = Quantity('C')\n    T = Quantity('T')\n    SI.set_quantity_dimension(R, impedance)\n    SI.set_quantity_dimension(C, capacitance)\n    SI.set_quantity_dimension(T, time)\n    R.set_global_relative_scale_factor(1, ohm)\n    C.set_global_relative_scale_factor(1, farad)\n    T.set_global_relative_scale_factor(1, second)\n    x = symbols('x')\n    expr = T / (R * C)\n    deriv_expr = diff(expr, x)\n    assert SI._collect_factor_and_dimension(deriv_expr) == (0, Dimension(1))\n\n    exp_expr = diff(exp(expr), x)\n    assert SI._collect_factor_and_dimension(exp_expr) == (0, Dimension(1))\n"], "sample_21": ["def test_fast_delete_with_signals(self):\n        pass\n\n    models.signals.post_delete.connect(log_post_delete)\n\n    a = Avatar.objects.create(desc='a')\n    User.objects.create(avatar=a)\n\n    # Signals are connected, so the delete should not be fast.\n    collector = Collector(using='default')\n    self.assertFalse(collector.can_fast_delete(a))\n\n    a.delete()\n\n    self.assertIsNone(a.pk)\n\n    models.signals.post_delete.disconnect(log_post_delete)\n", "def test_fast_delete_no_related_fields(self):\n    # Test that no related fields are queried during fast delete\n    base = Base.objects.create()\n    related = Related.objects.create(base=base)\n\n    with self.assertNumQueries(1):\n        base.delete()\n\n    self.assertFalse(Base.objects.filter(pk=base.pk).exists())\n    self.assertTrue(Related.objects.filter(pk=related.pk).exists())\n", "def test_fast_delete_inherited_related_object(self):\n    parent = Parent.objects.create()\n    child = Child.objects.create(parent_ptr=parent)\n    User.objects.create(parent=parent)\n    # User can be fast-deleted.\n    # 1 for self delete, 1 for fast delete of related users.\n    self.assertNumQueries(2, child.delete)\n    self.assertFalse(Child.objects.exists())\n    self.assertFalse(User.objects.exists())\n    self.assertEqual(Parent.objects.count(), 1)\n", "def test_fast_delete_qs_multiple_models(self):\n    u = User.objects.create()\n    a = Avatar.objects.create(user=u)\n    # 1 query to fast-delete the user\n    # 1 query to fast-delete the avatar\n    self.assertNumQueries(2, User.objects.all().delete)\n    self.assertFalse(User.objects.exists())\n    self.assertFalse(Avatar.objects.exists())\n", "def test_fast_delete_reverse_fk(self):\n    p = Parent.objects.create()\n    c = Child.objects.create(parent_ptr=p)\n    # 1 for self delete, 1 for fast delete of child\n    self.assertNumQueries(2, p.delete)\n    self.assertFalse(Parent.objects.exists())\n    self.assertFalse(Child.objects.exists())\n"], "sample_71": ["def test_context_with_list_of_styles():\n    original_value = 'gray'\n    other_value = 'blue'\n    third_value = 'red'\n    mpl.rcParams[PARAM] = original_value\n    with temp_style('test1', {PARAM: other_value}):\n        with temp_style('test2', {PARAM: third_value}):\n            with style.context(['test1', 'test2']):\n                assert mpl.rcParams[PARAM] == third_value\n    assert mpl.rcParams[PARAM] == original_value\n", "def test_context_with_after_reset():\n    original_value = 'gray'\n    other_value = 'blue'\n    mpl.rcParams[PARAM] = original_value\n    with temp_style('test', DUMMY_SETTINGS):\n        with style.context('test', after_reset=True):\n            assert mpl.rcParams[PARAM] == VALUE\n        assert mpl.rcParams[PARAM] == original_value\n", "def test_context_with_list():\n    original_value = 'gray'\n    other_value1 = 'blue'\n    other_value2 = 'red'\n    mpl.rcParams[PARAM] = original_value\n    with temp_style('test1', {PARAM: other_value1}):\n        with temp_style('test2', {PARAM: other_value2}):\n            with style.context(['test1', 'test2']):\n                assert mpl.rcParams[PARAM] == other_value2\n    assert mpl.rcParams[PARAM] == original_value\n", "def test_context_after_reset():\n    original_value = 'gray'\n    mpl.rcParams[PARAM] = original_value\n    with temp_style('test', DUMMY_SETTINGS):\n        with style.context('test', after_reset=True):\n            assert mpl.rcParams[PARAM] == VALUE\n    assert mpl.rcParams[PARAM] == original_value\n", "def test_context_with_list():\n    original_value1 = 'gray'\n    other_value1 = 'blue'\n    original_value2 = True\n    other_value2 = False\n    other_param = 'text.usetex'\n    mpl.rcParams[PARAM] = original_value1\n    mpl.rcParams[other_param] = original_value2\n    with temp_style('test1', {PARAM: other_value1}):\n        with temp_style('test2', {other_param: other_value2}):\n            with style.context(['test1', 'test2']):\n                assert mpl.rcParams[PARAM] == other_value1\n                assert mpl.rcParams[other_param] == other_value2\n    assert mpl.rcParams[PARAM] == original_value1\n    assert mpl.rcParams[other_param] == original_value2\n"], "sample_10": ["def test_isnull_none_rhs(self):\n    \"\"\"Lookup.can_use_none_as_rhs=True allows None as a lookup value.\"\"\"\n    season = Season.objects.create(year=2012, nulled_text_field='')\n    self.assertTrue(Season.objects.filter(pk=season.pk, nulled_text_field__isnull_none_rhs=None))\n", "def test_exact_lhs_transform(self):\n    \"\"\"Transforms are used for __exact=value.\"\"\"\n    season = Season.objects.create(year=2012, nulled_text_field='not null')\n    self.assertFalse(Season.objects.filter(nulled_text_field__exact=None))\n    self.assertTrue(Season.objects.filter(nulled_text_field__nulled__exact=None))\n    self.assertTrue(Season.objects.filter(nulled_text_field__nulled=None))\n    self.assertTrue(Season.objects.filter(nulled_text_field__nulled__isnull=True))\n", "def test_year_lookups(self):\n    # Test year lookups on a DateTimeField and a DateField\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year=2005),\n        ['<Article: Article 5>', '<Article: Article 6>', '<Article: Article 4>',\n         '<Article: Article 2>', '<Article: Article 3>', '<Article: Article 7>', '<Article: Article 1>'],\n        ordered=False\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gt=2005),\n        [],\n        ordered=False\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gte=2005),\n        ['<Article: Article 5>', '<Article: Article 6>', '<Article: Article 4>',\n         '<Article: Article 2>', '<Article: Article 3>', '<Article: Article 7>', '<Article: Article 1>'],\n        ordered=False\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lt=2005),\n        [],\n        ordered=False\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lte=2005),\n        ['<Article: Article 5>', '<Article: Article 6>', '<Article: Article 4>',\n         '<Article: Article 2>', '<Article: Article 3>', '<Article: Article 7>', '<Article: Article 1>'],\n        ordered=False\n    )\n", "def test_exact_queryset_rhs(self):\n    qs = Author.objects.filter(name=self.au1.name)\n    articles = Article.objects.filter(author__in=qs)\n    self.assertCountEqual(articles, [self.a1, self.a2, self.a3, self.a4])\n", "def test_custom_lookup_multiple_rhs(self):\n    \"\"\"Lookup.can_use_none_as_rhs=True allows multiple values as a lookup.\"\"\"\n    seasons = Season.objects.bulk_create([\n        Season(year=2012, nulled_text_field=None),\n        Season(year=2013, nulled_text_field='test'),\n        Season(year=2014, nulled_text_field=''),\n    ])\n    query = Season.objects.get_queryset().query\n    field = query.model._meta.get_field('nulled_text_field')\n    self.assertIsInstance(query.build_lookup(['in_none_rhs'], field, ['test', None]), InWithNoneAsRHS)\n    seasons_with_test_or_none = Season.objects.filter(nulled_text_field__in_none_rhs=['test', None])\n    self.assertCountEqual(seasons_with_test_or_none, seasons)\n"], "sample_25": ["def test_add_blank_datefield_and_timefield(self, mocked_ask_method):\n    \"\"\"\n    #23405 - Adding a NOT NULL and blank `DateField` or `TimeField`\n    without default should not prompt for a default.\n    \"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_with_birthdate_blank])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0)\n", "def test_remove_model_with_field_in_base_model(self):\n    \"\"\"\n    Removing a model that has a field with the same name as a base field\n    takes place after removing the field from the base model.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n        ], bases=('app.readable',)),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['DeleteModel', 'RemoveField'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='book')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='title', model_name='readable')\n", "def test_add_model_with_field_removed_from_base_model_and_altered(self):\n    \"\"\"\n    Removing a base field and altering it in the same base model takes place before\n    adding a new inherited model that has a field with the same name.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=300)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n        ], bases=('app.readable',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['AlterField', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n", "def test_add_model_with_field_added_to_base_model(self):\n    \"\"\"\n    Adding a new inherited model that has a field with the same name as a\n    field that is added to the base model takes place after the field is\n    added to the base model.\n    \"\"\"\n    before = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n        ]),\n    ]\n    after = [\n        ModelState('app', 'readable', [\n            ('id', models.AutoField(primary_key=True)),\n            ('title', models.CharField(max_length=200)),\n        ]),\n        ModelState('app', 'book', [\n            ('title', models.CharField(max_length=200)),\n        ], bases=('app.readable',)),\n    ]\n    changes = self.get_changes(before, after)\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['AddField', 'CreateModel'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='title', model_name='readable')\n    self.assertOperationAttributes(changes, 'app', 0, 1, name='book')\n", "def test_add_field_to_mti_model(self):\n    \"\"\"\n    Adding a field to a model that inherits from another model\n    should not remove the inheritance.\n    \"\"\"\n    parent = ModelState('app', 'Parent', [\n        ('id', models.AutoField(primary_key=True)),\n    ])\n    child = ModelState('app', 'Child', [], bases=('app.Parent',))\n    changes = self.get_changes([parent, child], [parent, child, ModelState('app', 'Child', [('new_field', models.CharField(max_length=200))])])\n    self.assertNumberMigrations(changes, 'app', 1)\n    self.assertOperationTypes(changes, 'app', 0, ['AddField'])\n    self.assertOperationAttributes(changes, 'app', 0, 0, name='new_field', model_name='child')\n"], "sample_9": ["def test_file_removal(self, mocked_modules, notify_mock):\n    self.reloader.watch_file(self.existing_file)\n    with self.tick_twice():\n        os.remove(self.existing_file)\n    self.assertEqual(notify_mock.call_count, 1)\n    self.assertCountEqual(notify_mock.call_args[0], [self.existing_file])\n", "def test_snapshot_files_updates_twice(self, mock_notify_file_changed):\n    with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file]):\n        ticker = self.reloader.tick()\n        next(ticker)\n        self.increment_mtime(self.existing_file)\n        next(ticker)\n        self.increment_mtime(self.existing_file)\n        next(ticker)\n        self.assertEqual(mock_notify_file_changed.call_count, 2)\n", "def test_tick_triggers_on_mtime_change(self, mock_notify_file_changed):\n    with mock.patch.object(self.reloader, 'watched_files', return_value=[self.existing_file]):\n        ticker = self.reloader.tick()\n        next(ticker)\n        self.increment_mtime(self.existing_file)\n        next(ticker)\n        mock_notify_file_changed.assert_called_once_with(self.existing_file)\n", "def test_file_removed(self, mocked_modules, notify_mock):\n    self.reloader.watch_file(self.existing_file)\n    with self.tick_twice():\n        self.existing_file.unlink()\n    self.assertEqual(notify_mock.call_count, 1)\n    self.assertCountEqual(notify_mock.call_args[0], [self.existing_file])\n", "def test_watched_files_includes_directory_globs(self):\n    self.reloader.watch_dir(self.tempdir, '*.py')\n    watched_files = list(self.reloader.watched_files())\n    glob_files = list(self.tempdir.glob('*.py'))\n    self.assertTrue(all(file in watched_files for file in glob_files))\n"], "sample_96": ["def test_ridge_classifier_sample_weights():\n    X = np.array([[-1.0, -1.0], [-1.0, 0], [-.8, -1.0],\n                  [1.0, 1.0], [1.0, 0.0]])\n    y = [1, 1, 1, -1, -1]\n    sample_weight = np.array([1.0, 0.5, 0.8, 1.2, 0.7])\n\n    reg = RidgeClassifier(sample_weight=sample_weight)\n    reg.fit(X, y)\n\n    assert_array_equal(reg.predict([[-.2, 2]]), np.array([-1]))\n", "def test_ridge_regression_no_intercept():\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 5, 10\n    X = rng.randn(n_samples, n_features)\n    y = rng.randn(n_samples)\n\n    coef_no_intercept = ridge_regression(X, y, alpha=1.0, fit_intercept=False)\n\n    X_with_intercept = np.hstack([X, np.ones((n_samples, 1))])\n    coef_with_intercept = ridge_regression(X_with_intercept, y, alpha=1.0, fit_intercept=False)\n\n    assert_array_almost_equal(coef_no_intercept, coef_with_intercept[:-1])\n", "def test_ridge_sparse_intercept():\n    # Test that Ridge regression works with sparse matrices and fit_intercept=True\n    rng = np.random.RandomState(42)\n    n_samples, n_features = 50, 10\n    X_sparse = sp.csr_matrix(rng.randn(n_samples, n_features))\n    y = rng.randn(n_samples)\n\n    ridge = Ridge(fit_intercept=True)\n    ridge.fit(X_sparse, y)\n    assert_equal(ridge.coef_.shape, (n_features,))\n    assert_equal(type(ridge.intercept_), np.float64)\n", "def test_ridge_classifier_sample_weight():\n    # Test sample weight in RidgeClassifier\n    X = np.array([[-1.0, -1.0], [-1.0, 0], [-.8, -1.0],\n                  [1.0, 1.0], [1.0, 0.0]])\n    y = [1, 1, 1, -1, -1]\n\n    reg = RidgeClassifier(sample_weight=[1, 2, 1, 2, 1])\n    reg.fit(X, y)\n\n    assert_array_equal(reg.predict([[0.2, -1.0]]), np.array([1]))\n", "def test_ridge_classifier_cv_gcv_mode_svd():\n    X = np.array([[-1.0, -1.0], [-1.0, 0], [-.8, -1.0],\n                  [1.0, 1.0], [1.0, 0.0]])\n    y = np.array([1, 1, 1, -1, -1])\n\n    # Test gcv_mode='svd' for RidgeClassifierCV.\n    # This should raise a TypeError because 'svd' mode is not supported for sparse matrices.\n    reg = RidgeClassifierCV(alphas=[.01, .1, 1], gcv_mode='svd')\n    with assert_raises(TypeError):\n        reg.fit(X, y)\n"], "sample_94": ["def test_decorator_with_args():\n    s = \"\"\"\\", "def test_expression_statement() -> None:\n    source = \"\"\"\\", "def test_decorator_with_args():\n    s = \"\"\"\\", "def test_indented_comment() -> None:\n    source = getstatement(1, \"if True:\\n    # comment\\n    pass\")\n    assert str(source) == \"    # comment\\n    pass\"\n", "def test_getstatementrange_with_decorator() -> None:\n    source = Source(\n        \"\"\"\\\n        @decorator1\n        @decorator2\n            pass\n        \"\"\"\n    )\n    assert len(source) == 4\n    assert source.getstatementrange(2) == (0, 4)\n    assert source.getstatementrange(3) == (0, 4)\n"], "sample_0": ["    def test_build_attrs_with_custom_placeholder(self):\n        form = AlbumForm()\n        attrs = form['band'].field.widget.build_attrs({'placeholder': 'Select a band'})\n        self.assertEqual(attrs['data-placeholder'], 'Select a band')\n", "def test_build_attrs_with_additional_attrs(self):\n    form = AlbumForm()\n    attrs = form['band'].field.widget.build_attrs({'data-custom-attr': 'custom-value'})\n    self.assertIn('data-custom-attr', attrs)\n    self.assertEqual(attrs['data-custom-attr'], 'custom-value')\n", "    def test_render_options_multiple_field(self):\n        beatles = Band.objects.create(name='The Beatles', style='rock')\n        who = Band.objects.create(name='The Who', style='rock')\n        album = Album.objects.create(name='Test Album', band=beatles)\n        album.featuring.add(who)\n\n        form = AlbumForm(instance=album)\n        output = form.as_table()\n        selected_option = '<option value=\"%s\" selected>The Beatles</option>' % beatles.pk\n        option = '<option value=\"%s\" selected>The Who</option>' % who.pk\n        self.assertIn(selected_option, output)\n        self.assertIn(option, output)\n", "def test_value_from_datadict_with_data(self):\n    form = AlbumForm()\n    data = {'band': '1'}\n    value = form['band'].field.widget.value_from_datadict(data, None, 'band')\n    self.assertEqual(value, '1')\n", "def test_build_attrs_with_custom_attributes(self):\n    custom_attrs = {'data-ajax--type': 'POST', 'data-placeholder': 'Select a band'}\n    form = AlbumForm()\n    attrs = form['band'].field.widget.get_context(name='my_field', value=None, attrs=custom_attrs)['widget']['attrs']\n    self.assertEqual(attrs, {\n        'class': 'my-class admin-autocomplete',\n        'data-ajax--cache': 'true',\n        'data-ajax--type': 'POST',\n        'data-ajax--url': '/admin_widgets/band/autocomplete/',\n        'data-theme': 'admin-autocomplete',\n        'data-allow-clear': 'false',\n        'data-placeholder': 'Select a band'\n    })\n"], "sample_27": ["def test_token_with_different_password(self):\n    \"\"\"Updating the user password invalidates the token.\"\"\"\n    user = User.objects.create_user('changepassworduser', 'test5@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk1), True)\n    user.set_password('newtestpw')\n    user.save()\n    self.assertIs(p0.check_token(user, tk1), False)\n", "def test_token_with_different_password(self):\n    \"\"\"Updating the user password invalidates the token.\"\"\"\n    user = User.objects.create_user('changepassworduser', 'test5@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk1), True)\n    user.set_password('newtestpw')\n    user.save()\n    self.assertIs(p0.check_token(user, tk1), False)\n", "def test_token_with_changed_password(self):\n    \"\"\"Updating the user password invalidates the token.\"\"\"\n    user = User.objects.create_user('changepwuser', 'test5@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk1), True)\n    user.set_password('newtestpw')\n    user.save()\n    self.assertIs(p0.check_token(user, tk1), False)\n", "def test_token_with_different_password(self):\n    \"\"\"Updating the user password invalidates the token.\"\"\"\n    user = User.objects.create_user('changepassworduser', 'test5@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk1), True)\n    user.set_password('newtestpw')\n    user.save()\n    self.assertIs(p0.check_token(user, tk1), False)\n", "def test_token_with_legacy_algorithm(self):\n    \"\"\"\n    A valid token can be checked using the legacy algorithm even when a\n    different algorithm is set.\n    \"\"\"\n    user = User.objects.create_user('legacyuser', 'test5@example.com', 'testpw')\n    new_algorithm = 'sha256'\n    # Create a token with the legacy algorithm.\n    p0 = PasswordResetTokenGenerator()\n    p0.algorithm = 'sha1'\n    tk0 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk0), True)\n    # Check a token with a different algorithm.\n    p1 = PasswordResetTokenGenerator()\n    p1.algorithm = new_algorithm\n    self.assertEqual(p1.algorithm, new_algorithm)\n    self.assertNotEqual(p1.algorithm, 'sha1')\n    self.assertIs(p1.check_token(user, tk0), True)\n"], "sample_145": ["def test_latex_StrPrinter():\n    from sympy.printing.str import StrPrinter\n    assert str(StrPrinter().doprint(I)) == \"I\"\n", "def test_latex_matrix_symbol_style():\n    # test cases for issue #15871\n    A = MatrixSymbol(\"A\", 2, 2)\n    assert latex(trace(A), mat_symbol_style='bold') == r\"\\operatorname{tr}\\left(\\mathbf{A} \\right)\"\n    assert latex(trace(A), mat_symbol_style='plain') == r\"\\operatorname{tr}\\left(A \\right)\"\n\n    A = MatrixSymbol(\"A\", 3, 3)\n    B = MatrixSymbol(\"B\", 3, 3)\n    C = MatrixSymbol(\"C\", 3, 3)\n\n    assert latex(-A, mat_symbol_style='bold') == r\"- \\mathbf{A}\"\n    assert latex(A - A*B - B, mat_symbol_style='bold') == r\"\\mathbf{A} - \\mathbf{A} \\mathbf{B} - \\mathbf{B}\"\n    assert latex(-A*B - A*B*C - B, mat_symbol_style='bold') == r\"- \\mathbf{A} \\mathbf{B} - \\mathbf{A} \\mathbf{B} \\mathbf{C} - \\mathbf{B}\"\n\n    A_k = MatrixSymbol(\"A_k\", 3, 3)\n    assert latex(A_k, mat_symbol_style='bold') == r\"\\mathbf{A}_{k}\"\n\n    A = MatrixSymbol(r\"\\nabla_k\", 3, 3)\n    assert latex(A, mat_symbol_style='bold') == r\"\\mathbf{\\nabla}_{k}\"\n", "def test_latex_Sum_order():\n    assert latex(Sum(x*y, (x, 0, 1), (y, 0, 2)), order='none') == \\\n        r\"\\sum_{x=0}^{1} \\sum_{y=0}^{2} x y\"\n    assert latex(Sum(x*y, (x, 0, 1), (y, 0, 2)), order='lex') == \\\n        r\"\\sum_{x=0}^{1} \\sum_{y=0}^{2} x y\"\n    assert latex(Sum(x*y, (x, 0, 1), (y, 0, 2)), order='rev-lex') == \\\n        r\"\\sum_{y=0}^{2} \\sum_{x=0}^{1} x y\"\n", "def test_latex_with_global_settings():\n    try:\n        # set a global setting\n        LatexPrinter.set_global_settings(imaginary_unit='j')\n        # check that it's used by the latex function\n        assert latex(I) == r'j'\n        # check that it's used by the latex method\n        assert I._latex(LatexPrinter()) == r'j'\n        # check that it's used by a custom printer\n        printer = LatexPrinter({'imaginary_unit': 'k'})\n        assert printer.doprint(I) == r'k'\n    finally:\n        # undo the global setting\n        del LatexPrinter._global_settings['imaginary_unit']\n", "def test_latex_ComplexDoublePrime():\n    from sympy.tensor.tensor import TensorIndexType, tensor_indices\n    L = TensorIndexType(\"L\")\n    i, j = tensor_indices(\"i j\", L)\n\n    assert latex(ComplexDoublePrime(i)) == r\"{}^{i}{}_{j}\"\n"], "sample_1": ["def test_read_write_with_errors(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3]))\n    t1.add_column(Column(name=\"a_err\", data=[0.1, 0.2, 0.3]))\n    t1.add_column(Column(name=\"b\", data=[4.0, 5.0, 6.0]))\n    t1.add_column(Column(name=\"b_perr\", data=[0.4, 0.5, 0.6]))\n    t1.add_column(Column(name=\"b_nerr\", data=[0.7, 0.8, 0.9]))\n    t1.write(test_file, format=\"ascii.qdp\", err_specs={'serr': [2], 'terr': [3]})\n    t2 = Table.read(test_file, table_id=0, format=\"ascii.qdp\", names=[\"a\", \"b\"])\n    assert np.all(t2[\"a\"] == t1[\"a\"])\n    assert np.all(t2[\"a_err\"] == t1[\"a_err\"])\n    assert np.all(t2[\"b\"] == t1[\"b\"])\n    assert np.all(t2[\"b_perr\"] == t1[\"b_perr\"])\n    assert np.all(t2[\"b_nerr\"] == t1[\"b_nerr\"])\n", "def test_read_write_simple_specify_err_specs(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3]))\n    t1.add_column(Column(name=\"b\", data=[4.0, 5.0, 6.0]))\n    t1.add_column(Column(name=\"c\", data=[7.0, 8.0, 9.0]))\n    t1.write(test_file, format=\"ascii.qdp\", err_specs={\"serr\": [2], \"terr\": [3]})\n    t2 = Table.read(test_file, table_id=0, format=\"ascii.qdp\", names=[\"a\", \"b\", \"c\"])\n    assert np.all(t2[\"a\"] == t1[\"a\"])\n    assert np.all(t2[\"b\"] == t1[\"b\"])\n    assert np.all(t2[\"c_perr\"] == t1[\"c\"])\n", "def test_read_write_simple_err_specs(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3, 4]))\n    t1.add_column(Column(name=\"a_err\", data=[0.1, 0.2, 0.3, 0.4]))\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"b\", mask=[False, False, False, True]\n        )\n    )\n    t1.add_column(Column(name=\"b_err\", data=[0.05, 0.06, 0.07, 0.08]))\n    t1.write(test_file, format=\"ascii.qdp\", err_specs={'serr': [2, 4]})\n    t2 = Table.read(test_file, table_id=0, format=\"ascii.qdp\", names=[\"a\", \"b\"])\n    assert np.allclose(t2[\"a\"], t1[\"a\"])\n    assert np.allclose(t2[\"a_err\"], t1[\"a_err\"])\n    assert np.allclose(t2[\"b\"][~np.isnan(t1[\"b\"])], t1[\"b\"][~np.isnan(t1[\"b\"])])\n    assert np.allclose(t2[\"b_err\"], t1[\"b_err\"])\n", "def test_read_write_simple_err_specs(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3]))\n    t1.add_column(Column(name=\"b\", data=[4.0, 5.0, 6.0]))\n    t1.add_column(Column(name=\"c\", data=[0.1, 0.2, 0.3]))\n    t1.write(test_file, format=\"ascii.qdp\", err_specs={\"serr\": [3]})\n    t2 = Table.read(test_file, table_id=0, format=\"ascii.qdp\", names=[\"a\", \"b\"])\n    assert np.all(t2[\"a\"] == t1[\"a\"])\n    assert np.all(t2[\"b\"] == t1[\"b\"])\n    assert np.all(t2[\"c_err\"] == t1[\"c\"])\n", "def test_read_write_with_err_specs(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3]))\n    t1.add_column(Column(name=\"a_err\", data=[0.1, 0.2, 0.3]))\n    t1.write(test_file, format=\"ascii.qdp\", err_specs={\"serr\": [2]})\n    t2 = Table.read(test_file, table_id=0, format=\"ascii.qdp\", names=[\"a\"])\n    assert np.allclose(t2[\"a\"], t1[\"a\"])\n    assert np.allclose(t2[\"a_err\"], t1[\"a_err\"])\n"], "sample_156": ["def test_parser_mathematica_tokenizer_advanced():\n    parser = MathematicaParser()\n\n    chain = lambda expr: parser._from_tokens_to_fullformlist(parser._from_mathematica_to_tokens(expr))\n\n    # Advanced patterns\n    assert chain(\"Sin[x]^2\") == [\"Power\", [\"Sin\", \"x\"], \"2\"]\n    assert chain(\"Sin[x]^2 Tan[y]\") == [\"Times\", [\"Power\", [\"Sin\", \"x\"], \"2\"], [\"Tan\", \"y\"]]\n    assert chain(\"F[7,5,3]\") == [\"F\", \"7\", \"5\", \"3\"]\n    assert chain(\"x*(a + b)\") == [\"Times\", \"x\", [\"Plus\", \"a\", \"b\"]]\n    assert chain(\"Times[x, Plus[a, b]]\") == [\"Times\", \"x\", [\"Plus\", \"a\", \"b\"]]\n    assert chain(\"{{a, b}, {c, d}}\") == [\"List\", [\"List\", \"a\", \"b\"], [\"List\", \"c\", \"d\"]]\n    assert chain(\"x_.\") == [\"Optional\", [\"Pattern\", \"x\", [\"Blank\"]]]\n    assert chain(\"Plus @@ {x, y, z}\") == [\"Apply\", \"Plus\", [\"List\", \"x\", \"y\", \"z\"]]\n    assert chain(\"f[x_, 3] := x^3 /; x > 0\") == [\"SetDelayed\", [\"f\", [\"Pattern\", \"x\", [\"Blank\"]], \"3\"], [\"Condition\", [\"Power\", \"x\", \"3\"], [\"Greater\", \"x\", \"0\"]]]\n", "def test_parser_mathematica_unsupported_functions():\n    parser = MathematicaParser()\n\n    # Unsupported functions\n    raises(ValueError, lambda: parser.parse(\"NonExistentFunction[x]\"))\n", "def test_parser_mathematica_function_arguments():\n    parser = MathematicaParser()\n\n    # Test with functions that take a variable number of arguments\n    assert parser._from_mathematica_to_tokens('f[x, y, z]') == ['f', '[', 'x', ',', 'y', ',', 'z', ']']\n    assert parser._from_tokens_to_fullformlist(['f', '[', 'x', ',', 'y', ',', 'z', ']']) == ['f', 'x', 'y', 'z']\n    assert parser._from_fullformlist_to_sympy(['f', 'x', 'y', 'z']) == Function('f')(x, y, z)\n\n    # Test with a function that takes no arguments\n    assert parser._from_mathematica_to_tokens('g[]') == ['g', '[', ']']\n    assert parser._from_tokens_to_fullformlist(['g', '[', ']']) == ['g']\n    assert parser._from_fullformlist_to_sympy(['g']) == Function('g')()\n\n    # Test with a function that takes one argument\n    assert parser._from_mathematica_to_tokens('h[x]') == ['h', '[', 'x', ']']\n    assert parser._from_tokens_to_fullformlist(['h', '[', 'x', ']']) == ['h', 'x']\n    assert parser._from_fullformlist_to_sympy(['h', 'x']) == Function('h')(x)\n", "def test_parser_mathematica_tokenizer_special_cases():\n    parser = MathematicaParser()\n    chain = lambda expr: parser._from_tokens_to_fullformlist(parser._from_mathematica_to_tokens(expr))\n\n    # Test cases for special mathematical functions\n    assert chain(\"Pochhammer[x, y]\") == [\"Pochhammer\", \"x\", \"y\"]\n    assert chain(\"ExpIntegralEi[x]\") == [\"ExpIntegralEi\", \"x\"]\n    assert chain(\"SinIntegral[x]\") == [\"SinIntegral\", \"x\"]\n    assert chain(\"CosIntegral[x]\") == [\"CosIntegral\", \"x\"]\n    assert chain(\"AiryAi[x]\") == [\"AiryAi\", \"x\"]\n    assert chain(\"AiryAiPrime[5]\") == [\"AiryAiPrime\", \"5\"]\n    assert chain(\"AiryBi[x]\") == [\"AiryBi\", \"x\"]\n    assert chain(\"AiryBiPrime[7]\") == [\"AiryBiPrime\", \"7\"]\n    assert chain(\"LogIntegral[4]\") == [\"LogIntegral\", \"4\"]\n    assert chain(\"PrimePi[7]\") == [\"PrimePi\", \"7\"]\n    assert chain(\"Prime[5]\") == [\"Prime\", \"5\"]\n    assert chain(\"PrimeQ[5]\") == [\"PrimeQ\", \"5\"]\n\n    # Test cases for compound expressions with special mathematical functions\n    assert chain(\"Pochhammer[x, y] + SinIntegral[x]\") == [\"Plus\", [\"Pochhammer\", \"x\", \"y\"], [\"SinIntegral\", \"x\"]]\n    assert chain(\"AiryAi[x] * AiryAiPrime[5]\") == [\"Times\", [\"AiryAi\", \"x\"], [\"AiryAiPrime\", \"5\"]]\n    assert chain(\"AiryBi[x]^2 - AiryBiPrime[7]\") == [\"Plus\", [\"Power\", [\"AiryBi\", \"x\"], \"2\"], [\"Times\", \"-1\", [\"AiryBiPrime\", \"7", "def test_parser_mathematica_derivative():\n    parser = MathematicaParser()\n\n    chain = lambda expr: parser._from_tokens_to_fullformlist(parser._from_mathematica_to_tokens(expr))\n\n    # Derivatives\n    assert chain(\"f'[x]\") == [\"Derivative\", \"f\", \"x\"]\n    assert chain(\"f''[x]\") == [\"Derivative\", \"f\", \"x\", \"x\"]\n    assert chain(\"f'''[x]\") == [\"Derivative\", \"f\", \"x\", \"x\", \"x\"]\n    assert chain(\"f''''[x]\") == [\"Derivative\", \"f\", \"x\", \"x\", \"x\", \"x\"]\n    assert chain(\"f'[x][y]\") == [[\"Derivative\", \"f\", \"x\"], \"y\"]\n    assert chain(\"f'''[x][y]\") == [[\"Derivative\", \"f\", \"x\", \"x\", \"x\"], \"y\"]\n    assert chain(\"f'[x, y]\") == [\"Derivative\", \"f\", \"x\", \"y\"]\n    assert chain(\"f''[x, y]\") == [\"Derivative\", \"f\", \"x\", \"x\", \"y\"]\n    assert chain(\"f'''[x, y]\") == [\"Derivative\", \"f\", \"x\", \"x\", \"x\", \"y\"]\n    assert chain(\"f''''[x, y]\") == [\"Derivative\", \"f\", \"x\", \"x\", \"x\", \"x\", \"y\"]\n\n    # Derivative with order\n    assert chain(\"D[f, x]\") == [\"Derivative\", \"f\", \"x\"]\n    assert chain(\"D[f, x, x]\") == [\"Derivative\", \"f\", \"x\", \"x\"]\n    assert chain(\"D[f, x, x, x]\") == [\"Derivative\", \"f\", \"x\", \"x\", \"x\"]\n    assert chain(\"D[f, x, x, x, x]\") == [\"Derivative\", \"f\", \"x\", \"x\", \"x\", \"x\"]\n    assert chain(\"D"], "sample_143": ["def test_issue_18272_alternative_notation():\n    x = Symbol('x')\n    n = Symbol('n')\n\n    assert upretty(ConditionSet(x, Eq(-x + exp(x), 0), S.Complexes)) == \\\n    '\u23a7            \u239b      x    \u239e\u23ab\\n'\\\n    '\u23a8x | x \u2208 \u2102 \u2227 \u239d-x + \u212f  = 0\u23a0\u23ac\\n'\\\n    '\u23a9                         \u23ad'\n    assert upretty(ConditionSet(x, Contains(n/2, Interval(0, oo)), FiniteSet(-n/2, n/2))) == \\\n    '\u23a7        \u23a7-n   n\u23ab   \u239bn         \u239e\u23ab\\n'\\\n    '\u23a8x | x \u2208 \u23a8\u2500\u2500\u2500, \u2500\u23ac \u2227 \u239c\u2500 \u2208 [0, \u221e)\u239f\u23ac\\n'\\\n    '\u23a9        \u23a9 2   2\u23ad   \u239d2         \u23a0\u23ad'\n    assert upretty(ConditionSet(x, Eq(Piecewise((1, x >= 3), (x/2 - 1/2, x >= 2), (1/2, x >= 1),\n                (x/2, True)) - 1/2, 0), Interval(0, 3))) == \\\n    '\u23a7                 \u239b\u239b\u23a7   1     for x \u2265 3\u239e          \u239e\u23ab\\n'\\\n    '\u23aa                 \u239c\u239c\u23aa                  \u239f          \u239f\u23aa\\n'\\\n    '\u23aa                 \u239c\u239c\u23aax                 \u239f          \u239f\u23aa\\n'\\\n    '\u23aa                 \u239c\u239c\u23aa\u2500 - 0.5  for x \u2265 2\u239f          ", "def test_issue_18273():\n    assert pretty(S.OneMatrix(2, 3, 4)) == '1'\n    assert upretty(S.OneMatrix(2, 3, 4)) == '\ud835\udfd9'\n", "def test_pretty_Str_with_symbol():\n    x = Symbol('x')\n    assert pretty(Str(x)) == 'Str(x)'\n    assert upretty(Str(x)) == 'Str(x)'\n", "def test_issue_18463():\n    from sympy import symbols, limit, sqrt, oo\n    x = symbols('x')\n    assert pretty(limit(sqrt(x**2 + 1) - x, x, oo)) == \\\n    'lim(sqrt(x**2 + 1) - x, x, oo)'\n\n    assert upretty(limit(sqrt(x**2 + 1) - x, x, oo)) == \\\n    'lim(\u221a(x\u00b2 + 1) - x, x, \u221e)'\n", "def test_issue_18596():\n    from sympy import symbols\n    from sympy.combinatorics import Permutation\n    i, j = symbols('i j', integer=True)\n    p = Permutation([j, i])\n    assert pretty(p) == 'Permutation([j, i])'\n    assert upretty(p) == '(i, j)'\n"], "sample_106": ["def test_input_output_shape():\n    \"\"\"Test that the output of transform has the expected shape.\"\"\"\n    X = iris_data\n    y = iris_target\n    n_components = 2\n\n    nca = NeighborhoodComponentsAnalysis(n_components=n_components, max_iter=5)\n    nca.fit(X, y)\n    X_transformed = nca.transform(X)\n\n    assert_equal(X_transformed.shape, (X.shape[0], n_components))\n", "def test_init_array_shape():\n    rng = np.random.RandomState(42)\n    X, y = make_blobs(n_samples=30, centers=6, n_features=5, random_state=0)\n\n    # Test init with a numpy array of valid shape\n    init = rng.rand(X.shape[1] - 1, X.shape[1])\n    nca = NeighborhoodComponentsAnalysis(init=init)\n    nca.fit(X, y)\n\n    # Test init with a numpy array of invalid shape\n    init = rng.rand(X.shape[1], X.shape[1] + 1)\n    nca = NeighborhoodComponentsAnalysis(init=init)\n    assert_raises(ValueError, nca.fit, X, y)\n", "def test_different_random_states():\n    \"\"\"Test that different random states give different transformations.\"\"\"\n    X = iris_data\n    y = iris_target\n\n    nca1 = NeighborhoodComponentsAnalysis(random_state=1)\n    nca1.fit(X, y)\n    transformation1 = nca1.components_\n\n    nca2 = NeighborhoodComponentsAnalysis(random_state=2)\n    nca2.fit(X, y)\n    transformation2 = nca2.components_\n\n    assert not np.array_equal(transformation1, transformation2)\n", "def test_transformation_shapes():\n    \"\"\"Test that the transformation shapes are as expected.\"\"\"\n    rng = np.random.RandomState(42)\n    X, y = make_blobs(n_samples=30, centers=6, n_features=5, random_state=0)\n\n    # Test transformation shape when n_components is not provided\n    nca = NeighborhoodComponentsAnalysis(random_state=rng)\n    nca.fit(X, y)\n    assert_equal(nca.components_.shape, (X.shape[1], X.shape[1]))\n\n    # Test transformation shape when n_components is provided\n    n_components = 3\n    nca = NeighborhoodComponentsAnalysis(n_components=n_components, random_state=rng)\n    nca.fit(X, y)\n    assert_equal(nca.components_.shape, (n_components, X.shape[1]))\n", "def test_max_iter_effect():\n    \"\"\"Test that the max_iter parameter has an effect on the transformation.\"\"\"\n    X = iris_data\n    y = iris_target\n\n    nca_short = NeighborhoodComponentsAnalysis(max_iter=5, random_state=0)\n    nca_short.fit(X, y)\n    transformation_short = nca_short.components_\n\n    nca_long = NeighborhoodComponentsAnalysis(max_iter=30, random_state=0)\n    nca_long.fit(X, y)\n    transformation_long = nca_long.components_\n\n    diff = np.sum(np.abs(transformation_long - transformation_short))\n    assert diff > 0.0, (\"The transformation did not change with different \"\n                        \"max_iter values.\")\n"], "sample_103": ["def test_mutual_info_regression_discrete_features():\n    # Here the target is continuous and there are two discrete features.\n    # The idea of this test is clear from the code.\n    X = np.array([[0, 0],\n                  [1, 1],\n                  [2, 0],\n                  [2, 0],\n                  [1, 1]])\n    y = np.array([0.1, 0.9, 0.2, 0.8, 0.7])\n\n    mi = mutual_info_regression(X, y, discrete_features=True)\n    assert_array_equal(np.argsort(-mi), [0, 1])\n", "def test_mutual_info_classif_sparse():\n    # Test the function with sparse matrix input\n    X = csr_matrix([[0, 1], [1, 0], [2, 0], [2, 0], [2, 0]])\n    y = np.array([0, 1, 2, 2, 1])\n\n    # Here X[:, 0] is the most informative feature, and X[:, 1] is weakly\n    # informative.\n    mi = mutual_info_classif(X, y, discrete_features='auto')\n    assert_array_equal(np.argsort(-mi), np.array([0, 1]))\n", "def test_mutual_info_regression_discrete():\n    # Here we have a discrete target and continuous features.\n    # The target is the sum of the first two features.\n    X = np.random.rand(1000, 3)\n    y = (X[:, 0] + X[:, 1] > 0.5).astype(int)\n\n    mi = mutual_info_regression(X, y, random_state=0)\n    # The target is the sum of the first two features,\n    # so the first two features should have the highest mutual information.\n    assert_array_equal(np.argsort(-mi), [0, 1, 2])\n", "def test_mutual_info_classif_sparse_input():\n    # Test that sparse input with continuous features raises a ValueError\n    X = csr_matrix(np.array([[0, 0, 0],\n                             [1, 1, 0],\n                             [2, 0, 1],\n                             [2, 0, 1],\n                             [2, 0, 1]]))\n    y = np.array([0, 1, 2, 2, 1])\n\n    with assert_raises(ValueError):\n        mutual_info_classif(X, y, discrete_features=False)\n", "def test_mutual_info_regression_sparse():\n    # Test mutual_info_regression with a sparse matrix and both discrete and continuous features\n    X = csr_matrix([[0, 0], [1, 0], [2, 0], [2, 0], [2, 0]])\n    y = np.array([0.5, 1.1, 2.3, 2.2, 1.9])\n    discrete_features = np.array([True, False])\n\n    # We expect an error because a sparse matrix can't have continuous features.\n    with assert_raises(ValueError):\n        mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n"], "sample_113": ["def test_column_transformer_get_set_params_with_remainder_transformer():\n    ct = ColumnTransformer(\n        [(\"trans1\", StandardScaler(), [0])], remainder=DoubleTrans()\n    )\n\n    exp = {\n        \"n_jobs\": None,\n        \"remainder\": ct.remainder,\n        \"remainder__constant\": None,\n        \"sparse_threshold\": 0.3,\n        \"trans1\": ct.transformers[0][1],\n        \"trans1__copy\": True,\n        \"trans1__with_mean\": True,\n        \"trans1__with_std\": True,\n        \"transformers\": ct.transformers,\n        \"transformer_weights\": None,\n        \"verbose_feature_names_out\": True,\n        \"verbose\": False,\n    }\n\n    assert ct.get_params() == exp\n\n    ct.set_params(remainder__constant=2.0)\n    assert ct.get_params()[\"remainder__constant\"] == 2.0\n\n    ct.set_params(trans1=\"passthrough\")\n    exp = {\n        \"n_jobs\": None,\n        \"remainder\": ct.remainder,\n        \"remainder__constant\": 2.0,\n        \"sparse_threshold\": 0.3,\n        \"trans1\": \"passthrough\",\n        \"transformers\": ct.transformers,\n        \"transformer_weights\": None,\n        \"verbose_feature_names_out\": True,\n        \"verbose\": False,\n    }\n    assert ct.get_params() == exp\n", "def test_column_transformer_get_feature_names_out_after_set_output():\n    pd = pytest.importorskip(\"pandas\")\n\n    X_df = pd.DataFrame({\"feat0\": [1.0, 2.0, 3.0], \"feat1\": [2.0, 3.0, 4.0]})\n    ct = ColumnTransformer(\n        [\n            (\"trans_0\", PandasOutTransformer(offset=3.0), [\"feat1\"]),\n            (\"trans_1\", \"passthrough\", [\"feat0\"]),\n        ]\n    )\n    ct.fit(X_df)\n    with pytest.raises(AttributeError, match=\"not provide get_feature_names_out\"):\n        ct.get_feature_names_out()\n\n    ct.set_output(transform=\"pandas\")\n    ct.fit(X_df)\n    expected_verbose_names = [\"trans_0__feat1\", \"trans_1__feat0\"]\n    assert_array_equal(ct.get_feature_names_out(), expected_verbose_names)\n\n    ct.set_params(verbose_feature_names_out=False)\n    ct.fit(X_df)\n    expected_non_verbose_names = [\"feat1\", \"feat0\"]\n    assert_array_equal(ct.get_feature_names_out(), expected_non_verbose_names)\n", "def test_column_transformer_pandas_out_and_feature_names_out():\n    \"\"\"Check that set_config(transform=\"pandas\") is compatible with transformers\n    that define get_feature_names_out and return a DataFrame.\n    \"\"\"\n    pd = pytest.importorskip(\"pandas\")\n\n    X_df = pd.DataFrame({\"feat0\": [1.0, 2.0, 3.0], \"feat1\": [2.0, 3.0, 4.0]})\n    ct = ColumnTransformer(\n        [\n            (\"trans_0\", PandasOutTransformer(offset=3.0), [\"feat1\"]),\n            (\"trans_1\", TransWithNames(feature_names_out=[\"out_feat0\"]), [\"feat0\"]),\n        ]\n    )\n    X_trans_np = ct.fit_transform(X_df)\n    assert isinstance(X_trans_np, np.ndarray)\n\n    ct.set_output(transform=\"pandas\")\n    X_trans_df = ct.fit_transform(X_df)\n    assert isinstance(X_trans_df, pd.DataFrame)\n    assert_array_equal(X_trans_df.columns, [\"trans_0__feat1\", \"trans_1__out_feat0\"])\n", "def test_column_transformer_set_output_no_feature_names_out():\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame(\n        {\n            \"pet\": pd.Series([\"dog\", \"cat\", \"snake\"], dtype=\"category\"),\n            \"color\": pd.Series([\"green\", \"blue\", \"red\"], dtype=\"object\"),\n            \"age\": [1.4, 2.1, 4.4],\n            \"height\": [20, 40, 10],\n            \"distance\": pd.Series([20, pd.NA, 100], dtype=\"Int32\"),\n        }\n    )\n    ct = ColumnTransformer(\n        [\n            (\n                \"color_encode\",\n                PandasOutTransformer(offset=1.0),\n                [\"color\"],\n            ),\n            (\"age\", StandardScaler(), [\"age\"]),\n        ],\n        remainder=\"passthrough\",\n        verbose_feature_names_out=False,\n    )\n    with pytest.raises(AttributeError, match=\"not provide get_feature_names_out\"):\n        ct.get_feature_names_out()\n    ct.set_output(transform=\"pandas\")\n    X_trans = ct.fit_transform(df)\n    assert isinstance(X_trans, pd.DataFrame)\n    expected_dtypes = {\n        \"color_encode__color\": \"object\",\n        \"age\": \"float64\",\n        \"pet\": \"category\",\n        \"height\": \"int64\",\n        \"distance\": \"Int32\",\n    }\n    for col, dtype in X_trans.dtypes.items():\n        assert dtype == expected_dtypes[col]\n", "def test_column_transformer_multiple_remainder():\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6], \"c\": [7, 8, 9]})\n    ct = ColumnTransformer([(\"trans\", Trans(), [\"a\"]), (\"remainder1\", \"passthrough\", [\"b\"]), (\"remainder2\", \"passthrough\", [\"c\"])])\n    ct.fit(df)\n    assert ct.transformers_ == [('trans', Trans(), ['a']), ('remainder1', 'passthrough', ['b']), ('remainder2', 'passthrough', ['c'])]\n"], "sample_97": ["def test_label_binarize_multilabel_binary():\n    y_ind = np.array([[0], [1], [0]])\n    classes = [0, 1]\n    pos_label = 2\n    neg_label = 0\n    expected = pos_label * y_ind\n    y_sparse = [sparse_matrix(y_ind)\n                for sparse_matrix in [coo_matrix, csc_matrix, csr_matrix,\n                                      dok_matrix, lil_matrix]]\n\n    for y in [y_ind] + y_sparse:\n        yield (check_binarized_results, y, classes, pos_label, neg_label,\n               expected)\n\n    assert_raises(ValueError, label_binarize, y, classes, neg_label=-1,\n                  pos_label=pos_label, sparse_output=True)\n", "def test_label_binarize_multiclass_zero_pos_label():\n    y = [0, 1, 2]\n    classes = [0, 1, 2]\n    pos_label = 0\n    neg_label = -1\n    expected = np.array([[-1, 0, 0], [0, -1, -1], [-1, -1, -1]])\n\n    yield check_binarized_results, y, classes, pos_label, neg_label, expected\n", "def test_label_binarize_multilabel_with_different_classes():\n    y_ind = np.array([[0, 1, 0], [1, 1, 1], [0, 0, 0]])\n    classes = [1, 2, 3]\n    pos_label = 2\n    neg_label = 0\n    expected = pos_label * np.array([[0, 1, 0], [1, 0, 0], [0, 0, 0]])\n    y_sparse = [sparse_matrix(y_ind)\n                for sparse_matrix in [coo_matrix, csc_matrix, csr_matrix,\n                                      dok_matrix, lil_matrix]]\n\n    for y in [y_ind] + y_sparse:\n        yield (check_binarized_results, y, classes, pos_label, neg_label,\n               expected)\n\n    assert_raises(ValueError, label_binarize, y, [0, 1, 2], neg_label=-1,\n                  pos_label=pos_label, sparse_output=True)\n", "def test_label_binarize_multilabel_indicator():\n    y_ind = np.array([[0, 1, 0], [1, 1, 1], [0, 0, 0]])\n    classes = [0, 1, 2]\n    pos_label = 2\n    neg_label = 0\n    expected = pos_label * y_ind\n    y_sparse = [sparse_matrix(y_ind)\n                for sparse_matrix in [coo_matrix, csc_matrix, csr_matrix,\n                                      dok_matrix, lil_matrix]]\n\n    for y in [y_ind] + y_sparse:\n        yield (check_binarized_results, y, classes, pos_label, neg_label,\n               expected)\n\n    assert_raises(ValueError, label_binarize, y, classes, neg_label=-1,\n                  pos_label=pos_label, sparse_output=True)\n", "def test_label_binarize_unseen_labels():\n    y = np.array([1, 2, 2, 3, 4])\n    classes = np.array([1, 2, 3])\n    expected = np.array([[1, 0, 0],\n                         [0, 1, 0],\n                         [0, 1, 0],\n                         [0, 0, 1],\n                         [0, 0, 0]])\n    assert_raises(ValueError, label_binarize, y, classes)\n\n    y = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n    classes = np.array([1, 2, 3, 4])\n    expected = np.array([[1, 1, 0, 0],\n                         [0, 1, 1, 0],\n                         [0, 0, 1, 1],\n                         [0, 0, 0, 1]])\n    assert_raises(ValueError, label_binarize, y, classes)\n"], "sample_26": ["    def test_serialize_circular_reference(self):\n        # serialize_db_to_string() handles circular references.\n        obj = Object.objects.create()\n        obj_ref = ObjectReference.objects.create(obj=obj)\n        obj.obj_ref = obj_ref\n        obj.save()\n        with mock.patch('django.db.migrations.loader.MigrationLoader') as loader:\n            # serialize_db_to_string() serializes only migrated apps, so mark\n            # the backends app as migrated.\n            loader_instance = loader.return_value\n            loader_instance.migrated_apps = {'backends'}\n            data = connection.creation.serialize_db_to_string()\n        # Deserialize objects and check if the circular reference is preserved.\n        Object.objects.all().delete()\n        ObjectReference.objects.all().delete()\n        connection.creation.deserialize_db_from_string(data)\n        obj = Object.objects.get()\n        obj_ref = ObjectReference.objects.get()\n        self.assertEqual(obj.obj_ref, obj_ref)\n        self.assertEqual(obj_ref.obj, obj)\n", "    def test_set_as_test_mirror(self):\n        # set_as_test_mirror() sets the test database name to the primary database name.\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        primary_settings_dict = {'NAME': 'primary_db'}\n        creation.set_as_test_mirror(primary_settings_dict)\n        self.assertEqual(test_connection.settings_dict['NAME'], 'primary_db')\n", "    def test_migrate_test_setting_default(self, mocked_sync_apps, mocked_migrate, *mocked_objects):\n        test_connection = get_connection_copy()\n        del test_connection.settings_dict['TEST']['MIGRATE']\n        creation = test_connection.creation_class(test_connection)\n        if connection.vendor == 'oracle':\n            # Don't close connection on Oracle.\n            creation.connection.close = mock.Mock()\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_create_test_db'):\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n            # Migrations run by default.\n            mocked_migrate.assert_called()\n            args, kwargs = mocked_migrate.call_args\n            self.assertEqual(args, ([('app_unmigrated', '0001_initial')],))\n            self.assertEqual(len(kwargs['plan']), 1)\n            # App is not synced.\n            mocked_sync_apps.assert_not_called()\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n", "    def test_destroy_test_db(self, *mocked_objects):\n        # destroy_test_db() destroys the test database when keepdb is False\n        test_connection = get_connection_copy()\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        test_database_name = creation._get_test_db_name()\n\n        # Mock the _create_test_db and _nodb_cursor methods to avoid actual DB operations\n        with mock.patch.object(creation, '_create_test_db', return_value=test_database_name):\n            with mock.patch.object(creation, '_nodb_cursor'):\n                # Create test database\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=False, keepdb=False)\n\n                # Mock the _destroy_test_db method to check if it's called\n                with mock.patch.object(creation, '_destroy_test_db') as mock_destroy:\n                    # Destroy test database\n                    creation.destroy_test_db(old_database_name, verbosity=0, keepdb=False)\n\n                    # Check if _destroy_test_db was called\n                    mock_destroy.assert_called_once_with(test_database_name, 0)\n", "def test_create_test_db_autoclobber(self, mock_nodb_cursor, mock_execute_create_test_db, *mocked_objects):\n    # create_test_db() handles the autoclobber option.\n    test_connection = get_connection_copy()\n    creation = test_connection.creation_class(test_connection)\n    mock_cursor = mock_nodb_cursor.return_value.__enter__.return_value\n    mock_execute_create_test_db.side_effect = Exception(\"Test error\")\n    # Simulate user input for autoclobber prompt.\n    mock_input = mock.Mock(return_value=\"yes\")\n    with mock.patch('builtins.input', mock_input):\n        with self.assertRaises(SystemExit):\n            creation.create_test_db(verbosity=0, autoclobber=False, serialize=False)\n    mock_execute_create_test_db.assert_has_calls([\n        mock.call(mock_cursor, mock.ANY),\n        mock.call(mock_cursor, mock.ANY),\n        mock.call(mock_cursor, mock.ANY),\n    ])\n    mock_input.assert_called_once()\n"], "sample_50": ["def test_extra_tags(self):\n    \"\"\"\n    A message with extra_tags is properly encoded/decoded.\n    \"\"\"\n    message = Message(constants.INFO, 'Test message', extra_tags='test-tag')\n    decoded_message = self.encode_decode(message)\n    self.assertEqual(message.extra_tags, decoded_message.extra_tags)\n", "def test_extra_tags(self):\n    \"\"\"\n    A message containing extra_tags is properly encoded/decoded by the custom JSON\n    encoder/decoder classes.\n    \"\"\"\n    message_with_tags = Message(constants.INFO, 'Test message', extra_tags='tag1 tag2')\n    encoded = self.encode_decode(message_with_tags)\n    self.assertIsInstance(encoded, Message)\n    self.assertEqual(encoded.message, 'Test message')\n    self.assertEqual(encoded.extra_tags, 'tag1 tag2')\n", "def test_extra_tags(self):\n    \"\"\"\n    A message containing extra_tags is properly stored and retrieved.\n    \"\"\"\n    storage = self.get_storage()\n    msg = 'Test message'\n    tags = 'extra-tag'\n    storage.add(constants.INFO, msg, extra_tags=tags)\n    response = self.get_response()\n    storage.update(response)\n    messages = storage._decode(response.cookies['messages'].value)\n    self.assertEqual(len(messages), 1)\n    self.assertEqual(messages[0].message, msg)\n    self.assertEqual(messages[0].extra_tags, tags)\n", "def test_extra_tags(self):\n    \"\"\"\n    A message containing extra_tags is properly encoded/decoded by the custom JSON\n    encoder/decoder classes.\n    \"\"\"\n    messages = [\n        Message(constants.INFO, 'Test message', extra_tags='test-tag'),\n        Message(constants.INFO, 'Another message'),\n    ]\n    encoder = MessageEncoder()\n    value = encoder.encode(messages)\n    decoded_messages = json.loads(value, cls=MessageDecoder)\n    self.assertEqual(messages[0].extra_tags, decoded_messages[0].extra_tags)\n    self.assertIsNone(decoded_messages[1].extra_tags)\n", "def test_message_decoder_with_extra_tags(self):\n    \"\"\"\n    MessageDecoder properly decodes messages with extra_tags.\n    \"\"\"\n    message = Message(constants.WARNING, 'Warning message', extra_tags='extra')\n    encoded_message = json.dumps(message, cls=MessageEncoder)\n    decoded_message = json.loads(encoded_message, cls=MessageDecoder)\n    self.assertEqual(message.extra_tags, decoded_message.extra_tags)\n"], "sample_90": ["def test_mark_option_considers_custom_mark(testdir):\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n            config.addinivalue_line(\"markers\", \"custom: custom marker\")\n    \"\"\"\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.custom\n            assert True\n    \"\"\"\n    )\n    rec = testdir.inline_run(\"-m\", \"custom\")\n    passed, skipped, fail = rec.listoutcomes()\n    assert len(passed) == 1\n    assert passed[0].nodeid.split(\"::\")[-1] == \"test_custom_marker\"\n", "def test_mark_option_with_reason(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        @pytest.mark.skip(reason=\"Some reason\")\n            pass\n    \"\"\"\n    )\n    rec = testdir.inline_run(\"-m\", \"skip\")\n    passed, skipped, fail = rec.listoutcomes()\n    assert len(skipped) == 1\n    assert \"Some reason\" in skipped[0].longrepr.reprcrash.message\n", "def test_mark_generator_with_args(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"version\", [\"1.0\", \"2.0\"])\n        @pytest.mark.foo(\"bar\")\n            pass\n    \"\"\"\n    )\n    items, rec = testdir.inline_genitems()\n    test_function = items[0]\n    markers = list(test_function.iter_markers())\n    assert len(markers) == 2\n    assert markers[0].name == \"parametrize\"\n    assert markers[1].name == \"foo\"\n    assert markers[1].args == (\"bar\",)\n", "def test_parametrize_iterator_nested(testdir):\n    \"\"\"Nested parametrized tests should work with generators (#5354).\"\"\"\n    py_file = testdir.makepyfile(\n        \"\"\"\\\n        import pytest\n\n            yield 1\n            yield 2\n\n            yield 'a'\n            yield 'b'\n\n        @pytest.mark.parametrize('a', gen1())\n        @pytest.mark.parametrize('b', gen2())\n            assert a >= 1\n            assert b in ['a', 'b']\n        \"\"\"\n    )\n    result = testdir.runpytest(py_file)\n    assert result.ret == 0\n    # should not skip any tests\n    result.stdout.fnmatch_lines([\"*4 passed*\"])\n", "def test_mark_evaluator_with_args(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        from _pytest.nodes import Node\n\n        @pytest.mark.custom(\"arg1\", \"arg2\", reason=\"custom reason\")\n            mark_eval = request.node.get_closest_marker(\"custom\")._evaluate(request.node)\n            assert mark_eval._istrue()\n            assert mark_eval.reason == \"custom reason\"\n            assert mark_eval._mark.args == (\"arg1\", \"arg2\")\n    \"\"\"\n    )\n\n    result = testdir.runpytest()\n    result.assert_outcomes(passed=1)\n"], "sample_125": ["def test_Float_Float_comparison():\n    fpi = Float(pi)\n    assert (fpi == pi) == (pi == fpi)\n    assert (fpi != pi) == (pi != fpi)\n    assert (fpi < pi) == (pi > fpi)\n    assert (fpi <= pi) == (pi >= fpi)\n    assert (fpi > pi) == (pi < fpi)\n    assert (fpi >= pi) == (pi <= fpi)\n", "def test_Rational_abs():\n    assert abs(Rational(-1, 2)) == Rational(1, 2)\n    assert abs(Rational(1, 2)) == Rational(1, 2)\n    assert abs(Rational(0, 2)) == Rational(0, 2)\n", "def test_Float_as_index():\n    assert 'hello'[Float(2.0):] == 'llo'\n    assert 'hello'[Float(2.5):] == 'o'\n", "def test_Integer_as_numerator():\n    # Test that Integer can be used as a numerator in a Rational\n    assert Rational(Integer(3), 4) == S(3)/4\n", "def test_Float_complex():\n    assert (Float(2) + I*Float(3)).is_complex is True\n    assert (Float(2) + I*Float(3)).is_real is False\n    assert (Float(2) + I*Float(3)).is_imaginary is False\n    assert (Float(2) + I*Float(3)).is_number is True\n    assert (Float(2) + I*Float(3)).is_finite is True\n    assert (Float(2) + I*Float(3)).is_infinite is False\n    assert (Float(2) + I*Float(3)).is_zero is False\n    assert (Float(2) + I*Float(3)).is_positive is None\n    assert (Float(2) + I*Float(3)).is_negative is None\n"], "sample_129": ["def test_Quaternion_latex_printing_zero():\n    q = Quaternion(0, 0, 0, 0)\n    assert latex(q) == \"0\"\n", "def test_Quaternion_latex_printing_with_fractions():\n    q = Quaternion(Rational(1, 2), Rational(1, 3), Rational(1, 4), Rational(1, 5))\n    assert latex(q) == r\"\\frac{1}{2} + \\frac{1}{3} i + \\frac{1}{4} j + \\frac{1}{5} k\"\n", "def test_Quaternion_latex_printing_with_zero_components():\n    q = Quaternion(0, y, 0, t)\n    assert latex(q) == \"y i + t k\"\n    q = Quaternion(x, 0, z, 0)\n    assert latex(q) == \"x + z j\"\n    q = Quaternion(0, 0, 0, 0)\n    assert latex(q) == \"0\"\n", "def test_latex_Quaternion_multiplication():\n    q1 = Quaternion(1, 2, 3, 4)\n    q2 = Quaternion(5, 6, 7, 8)\n    q_mul = q1 * q2\n    expected = \"-60 + 12 i + 24 j + 44 k\"\n    assert latex(q_mul) == expected\n", "def test_MatrixSymbol_slicing_printing():\n    A = MatrixSymbol(\"A\", 3, 3)\n    assert latex(A[:2, :2]) == r\"A\\left[:2, :2\\right]\"\n    assert latex(A[1:3, 1:3]) == r\"A\\left[1:3, 1:3\\right]\"\n    assert latex(A[::2, ::2]) == r\"A\\left[::2, ::2\\right]\"\n"], "sample_70": ["def test_legend_mode(mode):\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label='test')\n    leg = ax.legend(mode=mode)\n    assert leg._mode == mode\n", "def test_legend_edgecolor_from_line2d():\n    # Test that edgecolor can be copied for legend lines (#17960)\n    _edgecolors = ['r', 'g', 'b']\n    fig, ax = plt.subplots()\n    lines = [mlines.Line2D([0], [0], ls='None', marker='o', color=color)\n             for color in _edgecolors]\n    labels = [\"foo\", \"bar\", \"xyzzy\"]\n    edgecolors = [line.get_color() for line in lines]\n    legend = ax.legend(lines, labels)\n\n    new_edgecolors = [line.get_color() for line in legend.get_lines()]\n    new_labels = [text.get_text() for text in legend.get_texts()]\n\n    assert edgecolors == new_edgecolors == _edgecolors\n    assert labels == new_labels\n", "def test_legend_labelcolor_rcparam_markerfacecolor_short_invalid(color):\n    # test the labelcolor for an invalid labelcolor value\n    fig, ax = plt.subplots()\n    ax.plot(np.arange(10), np.arange(10)*1, label='#1', markerfacecolor='r')\n    ax.plot(np.arange(10), np.arange(10)*2, label='#2', markerfacecolor='g')\n    ax.plot(np.arange(10), np.arange(10)*3, label='#3', markerfacecolor='b')\n\n    mpl.rcParams['legend.labelcolor'] = color\n    with pytest.raises(ValueError):\n        ax.legend()\n", "def test_legend_handles_labels():\n    # Test _get_legend_handles_labels function\n    fig, ax = plt.subplots()\n    ax.plot(range(10), label='line1')\n    ax.plot(range(10, 0, -1), label='line2')\n\n    handles, labels = mlegend._get_legend_handles_labels([ax])\n    assert len(handles) == 2\n    assert labels == ['line1', 'line2']\n", "def test_legend_edgecolor_polycollection(edgecolor):\n    # Test the edgecolor for PolyCollection legend handler\n    fig, ax = plt.subplots()\n    ax.fill_between([0, 1, 2], [1, 2, 3], [2, 3, 4],\n                    facecolor='r', edgecolor=edgecolor, label='Fill')\n    leg = ax.legend()\n    assert leg.get_patches()[0].get_edgecolor() == plt.mcolors.to_rgba(edgecolor)\n"], "sample_3": ["def test_custom_model_separability():\n    @custom_model\n        return x + y, x - y\n\n    compound_model = model_b & model_b\n    expected_result = (np.array([False, False]),\n                      np.array([[True, True], [True, True]]))\n\n    assert_allclose(is_separable(compound_model), expected_result[0])\n    assert_allclose(separability_matrix(compound_model), expected_result[1])\n", "def test_custom_model_separability():\n    @custom_model\n        return x + y, x - y\n\n    result = _separable(model_b)\n    expected = np.array([[1, 1], [1, 1], [0, 0]])\n    assert_allclose(result, expected)\n", "def test_custom_model_separability():\n    @custom_model\n        return x + y, x - y\n\n    model_b.separable = True\n    result = is_separable(model_b)\n    assert_allclose(result, np.array([True, True]))\n\n    result = separability_matrix(model_b)\n    assert_allclose(result, np.array([[True, True], [True, True]]))\n\n    model_b.separable = False\n    result = is_separable(model_b)\n    assert_allclose(result, np.array([False, False]))\n\n    result = separability_matrix(model_b)\n    assert_allclose(result, np.array([[True, True], [True, True]]))\n", "def test_custom_model_separability():\n    @custom_model\n        return x * y, x - y\n\n    result = (np.array([True, True]), np.array([[True, True], [True, True]]))\n    assert_allclose(is_separable(model_b), result[0])\n    assert_allclose(separability_matrix(model_b), result[1])\n", "def test_arith_oper_ndarray(left, right, expected):\n    result = _arith_oper(left, right)\n    assert_allclose(result, expected)\n"], "sample_157": ["def test_tensor_product_trace():\n    assert Tr(TensorProduct(A, B)).doit() == Tr(A)*Tr(B)\n    assert Tr(TensorProduct(A, B), indices=(0,)).doit() == Tr(A)*B\n    assert Tr(TensorProduct(A, B), indices=(1,)).doit() == A*Tr(B)\n", "def test_tensor_product_trace():\n    assert Tr(TP(A, B)) == Tr(A) * Tr(B)\n    assert Tr(TP(A, B), indices=[0]) == Tr(A) * B\n    assert Tr(TP(A, B), indices=[1]) == Tr(B) * A\n", "def test_tensor_product_trace():\n    assert Tr(TP(A, B), indices=(0,)) == Tr(A) * B\n    assert Tr(TP(A, B), indices=(1,)) == A * Tr(B)\n    assert Tr(TP(A, B)) == Tr(A) * Tr(B)\n", "def test_tensor_product_trace():\n    assert Tr(TP(A, B)) == Tr(A) * Tr(B)\n    assert Tr(TP(A, B), indices=(0,)) == Tr(A) * B\n    assert Tr(TP(A, B), indices=(1,)) == A * Tr(B)\n", "def test_tensor_product_trace():\n    assert Tr(TP(A, B)).doit() == Tr(A)*Tr(B)\n    assert Tr(TP(A, B), indices=(0,)).doit() == Tr(B)\n    assert Tr(TP(A, B), indices=(1,)).doit() == Tr(A)\n    assert Tr(TP(A, B), indices=(0, 1)).doit() == 1\n"], "sample_139": ["def test_Abs_rewrite_sign():\n    x = Symbol('x', real=True)\n    a = Abs(x).rewrite(sign).expand()\n    assert a == x*sign(x)\n    for i in [-2, -1, 0, 1, 2]:\n        assert a.subs(x, i) == abs(i)\n    y = Symbol('y')\n    assert Abs(y).rewrite(sign) == Abs(y)\n", "def test_conjugate_zero():\n    z = Symbol('z', complex=True, zero=True)\n    assert conjugate(z) == z\n    assert im(z) == 0\n    assert re(z) == 0\n    assert Abs(z) == 0\n", "def test_conjugate_transpose_of_matrices():\n    from sympy import Matrix, I, conjugate, transpose\n    A = Matrix([[1, I], [2, 3]])\n    assert conjugate(transpose(A)) == Matrix([[1, -I], [2, 3]]).T\n    assert transpose(conjugate(A)) == Matrix([[1, -I], [2, 3]]).T\n", "def test_complex_functions_with_assumptions():\n    r = Symbol('r', real=True)\n    i = Symbol('i', imaginary=True)\n\n    assert sign(r).is_real is True\n    assert sign(r).is_integer is True\n    assert sign(r).is_zero is None\n    assert sign(r).is_positive is None\n    assert sign(r).is_nonnegative is None\n\n    assert sign(i).is_real is False\n    assert sign(i).is_integer is False\n    assert sign(i).is_zero is False\n    assert sign(i).is_positive is False\n    assert sign(i).is_nonnegative is False\n\n    assert Abs(r).is_real is True\n    assert Abs(r).is_integer is None\n    assert Abs(r).is_zero is None\n    assert Abs(r).is_positive is None\n    assert Abs(r).is_nonnegative is True\n\n    assert Abs(i).is_real is True\n    assert Abs(i).is_integer is False\n    assert Abs(i).is_zero is False\n    assert Abs(i).is_positive is True\n    assert Abs(i).is_nonnegative is True\n\n    assert arg(r).is_real is True\n    assert arg(r).is_integer is None\n    assert arg(r).is_zero is None\n    assert arg(r).is_positive is None\n    assert arg(r).is_nonnegative is None\n\n    assert arg(i).is_real is True\n    assert arg(i).is_integer is None\n    assert arg(i).is_zero is False\n    assert arg(i).is_positive is None\n    assert arg(i).is_nonnegative is None\n", "def test_Abs_properties_extended_real():\n    x = Symbol('x', extended_real=True)\n    assert Abs(x).is_real is True\n    assert Abs(x).is_extended_real is True\n    assert Abs(x).is_rational is None\n    assert Abs(x).is_positive is None\n    assert Abs(x).is_nonnegative is True\n    assert Abs(x).is_extended_positive is None\n    assert Abs(x).is_extended_nonnegative is True\n"], "sample_95": ["def test_mark_skip_item(pytester: Pytester) -> None:\n    # Ensure pytest.mark.skip works with non-Python Item\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n        class MyItem(pytest.Item):\n            nodeid = 'foo'\n                marker = pytest.mark.skip(reason=\"Expected skip\")\n                self.add_marker(marker)\n\n            return MyItem.from_parent(name=\"foo\", parent=parent)\n    \"\"\"\n    )\n    result = pytester.inline_run()\n    passed, skipped, failed = result.listoutcomes()\n    assert not failed\n    assert skipped\n", "def test_mark_skip_item(pytester: Pytester) -> None:\n    # Ensure pytest.mark.skip works with non-Python Item\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n        class MyItem(pytest.Item):\n            nodeid = 'foo'\n                marker = pytest.mark.skip(\"Skipped item\")\n                self.add_marker(marker)\n                assert False\n\n            return MyItem.from_parent(name=\"foo\", parent=parent)\n    \"\"\"\n    )\n    result = pytester.inline_run()\n    passed, skipped, failed = result.listoutcomes()\n    assert not failed\n    assert skipped\n", "def test_skipif_conditional_reason(pytester: Pytester) -> None:\n    item = pytester.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.skipif(\"hasattr(os, 'sep')\", reason=\"operating system condition\")\n            pass\n    \"\"\"\n    )\n    x = pytest.raises(pytest.skip.Exception, lambda: pytest_runtest_setup(item))\n    assert x.value.msg == \"operating system condition\"\n", "def test_mark_skip_item(pytester: Pytester) -> None:\n    # Ensure pytest.mark.skip works with non-Python Item\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n        class MyItem(pytest.Item):\n            nodeid = 'foo'\n                marker = pytest.mark.skip(reason=\"Skipped for a reason\")\n                self.add_marker(marker)\n                pass\n\n            return MyItem.from_parent(name=\"foo\", parent=parent)\n    \"\"\"\n    )\n    result = pytester.inline_run()\n    passed, skipped, failed = result.listoutcomes()\n    assert not failed\n    assert skipped\n", "def test_mark_skipif_item(pytester: Pytester) -> None:\n    # Ensure pytest.mark.skipif works with non-Python Item\n    pytester.makeconftest(\n        \"\"\"\n        import pytest\n\n        class MyItem(pytest.Item):\n            nodeid = 'foo'\n                marker = pytest.mark.skipif(True, reason=\"Skip test - true\")\n                self.add_marker(marker)\n                marker = pytest.mark.skipif(False, reason=\"Skip test - false\")\n                self.add_marker(marker)\n                assert False\n\n            return MyItem.from_parent(name=\"foo\", parent=parent)\n    \"\"\"\n    )\n    result = pytester.inline_run()\n    passed, skipped, failed = result.listoutcomes()\n    assert not failed\n    skipped_tests = [r for r in skipped if hasattr(r, \"skipped\")]\n    assert skipped_tests\n"], "sample_44": ["def test_limit_choices_to(self):\n    f = forms.ModelChoiceField(\n        Category.objects.all(),\n        limit_choices_to={'name__contains': 'test'},\n    )\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c2.pk, 'A test'),\n    ])\n", "def test_limit_choices_to(self):\n    limited_queryset = Category.objects.filter(slug__startswith='e')\n    f = forms.ModelChoiceField(queryset=Category.objects.all(), limit_choices_to={'slug__startswith': 'e'})\n    self.assertCountEqual(f.queryset, limited_queryset)\n", "def test_limit_choices_to(self):\n    # Test the limit_choices_to feature of the ModelChoiceField\n    f = forms.ModelChoiceField(Category.objects.all(), limit_choices_to={'name__startswith': 'Test'})\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c2.pk, 'A test'),\n    ])\n", "def test_queryset_limiting(self):\n    class ModelChoiceForm(forms.Form):\n        category = forms.ModelChoiceField(Category.objects.all(), limit_choices_to={'slug__contains': 'test'})\n\n    form = ModelChoiceForm()\n    self.assertCountEqual(form.fields['category'].queryset, [self.c2, self.c3])\n    self.assertCountEqual(form.fields['category'].choices, [('', '---------'), (self.c2.pk, 'A test'), (self.c3.pk, 'Third')])\n", "def test_limit_choices_to(self):\n    # Test the limit_choices_to attribute of the ModelChoiceField.\n    # Create some additional categories to test the limitation.\n    c4 = Category.objects.create(name='Fourth', slug='fourth', url='fourth')\n    c5 = Category.objects.create(name='Fifth', slug='fifth', url='fifth')\n\n    # Test with a dictionary.\n    f_dict = forms.ModelChoiceField(Category.objects.all(), limit_choices_to={'slug__startswith': 't'})\n    self.assertCountEqual(f_dict.choices, [\n        ('', '---------'),\n        (self.c2.pk, 'A test'),\n        (self.c3.pk, 'Third'),\n    ])\n\n    # Test with a callable.\n        return {'slug__startswith': 'e'}\n    f_callable = forms.ModelChoiceField(Category.objects.all(), limit_choices_to=limit_choices_to_callable)\n    self.assertCountEqual(f_callable.choices, [\n        ('', '---------'),\n        (self.c1.pk, 'Entertainment'),\n    ])\n"], "sample_76": ["def test_order_less_than_unique_x_values(self, df):\n\n    df = pd.DataFrame(dict(x=[1, 2, 3], y=[1, 2, 3]))\n    groupby = GroupBy([\"group\"])\n    res = PolyFit(order=3, gridsize=100)(df, groupby, \"x\", {})\n\n    assert res.empty\n", "def test_high_order(self, df):\n\n    groupby = GroupBy([\"color\"])\n    order = 3\n    res = PolyFit(order=order, gridsize=100)(df, groupby, \"x\", {})\n\n    assert res.columns.to_list() == [\"x\", \"y\", \"color\"]\n\n    for _, part in res.groupby(\"color\"):\n        x = part[\"x\"]\n        y = part[\"y\"]\n        if x.nunique() > order:\n            p = np.polyfit(x, y, order)\n            yy = np.polyval(p, x)\n            assert_array_almost_equal(y, yy)\n", "def test_order_too_high(self, df):\n\n    order = df[\"x\"].nunique() + 1\n    groupby = GroupBy([\"group\"])\n    res = PolyFit(order=order, gridsize=100)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n\n    assert_frame_equal(res, pd.DataFrame(columns=[\"x\", \"y\"]))\n", "def test_invalid_input(self, df):\n\n    groupby = GroupBy([\"group\"])\n    df[\"x\"] = \"invalid\"\n    with pytest.raises(TypeError):\n        PolyFit(order=1, gridsize=100)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n", "def test_different_orders(self, df):\n\n    groupby = GroupBy([\"color\"])\n    orders = [1, 2, 3]\n\n    for order in orders:\n        res = PolyFit(order=order, gridsize=100)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n\n        assert_array_equal(res.columns, [\"x\", \"y\"])\n\n        grid = np.linspace(df[\"x\"].min(), df[\"x\"].max(), 100)\n        assert_array_equal(res[\"x\"], grid)\n\n        # Check that the polynomial is of the correct order\n        assert_array_almost_equal(\n            res[\"y\"].diff().diff().dropna()[:-order+1], np.zeros(grid.size - 2 - order + 1)\n        )\n"], "sample_24": ["    def test_message_dict_property(self):\n        error_dict = {'field1': ['E1', 'E2'], 'field2': ['E3', 'E4']}\n        exception = ValidationError(error_dict)\n        self.assertEqual(exception.message_dict, error_dict)\n\n        with self.assertRaises(AttributeError):\n            exception = ValidationError('message')\n            exception.message_dict\n", "    def test_update_error_dict(self):\n        error_dict = {}\n        exception = ValidationError('error message')\n        updated_dict = exception.update_error_dict(error_dict)\n        self.assertEqual(updated_dict, {NON_FIELD_ERRORS: ['error message']})\n\n        error_dict = {}\n        exception = ValidationError({'field1': ['E1', 'E2'], 'field2': ['E3']})\n        updated_dict = exception.update_error_dict(error_dict)\n        self.assertEqual(updated_dict, {'field1': ['E1', 'E2'], 'field2': ['E3']})\n\n        error_dict = {'field1': ['E1']}\n        exception = ValidationError({'field2': ['E2'], 'field1': ['E3']})\n        updated_dict = exception.update_error_dict(error_dict)\n        self.assertEqual(updated_dict, {'field1': ['E1', 'E3'], 'field2': ['E2']})\n", "def test_message_dict(self):\n    message_dict = {'field1': ['E1', 'E2'], 'field2': ['E3', 'E4']}\n    exception = ValidationError(message_dict)\n    self.assertEqual(exception.message_dict, message_dict)\n    self.assertNotEqual(exception.message_dict, {'field1': ['E1', 'E3'], 'field2': ['E4']})\n", "    def test_update_error_dict(self):\n        error1 = ValidationError('message')\n        error2 = ValidationError({'field1': 'error1', 'field2': 'error2'})\n        error_dict = {}\n        error1.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {NON_FIELD_ERRORS: ['message']})\n        error2.update_error_dict(error_dict)\n        self.assertEqual(error_dict, {NON_FIELD_ERRORS: ['message'], 'field1': ['error1'], 'field2': ['error2']})\n", "def test_update_error_dict(self):\n    error1 = ValidationError('message')\n    error2 = ValidationError({'field1': 'error1', 'field2': 'error2'})\n    error3 = ValidationError(['error1', 'error2'])\n\n    error_dict = {}\n    error1.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['message']})\n\n    error_dict = {}\n    error2.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'field1': ['error1'], 'field2': ['error2']})\n\n    error_dict = {}\n    error3.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['error1', 'error2']})\n"], "sample_36": ["def test_combine_and_or_different_connectors(self):\n    q1 = Q(price__gt=F('discounted_price'))\n    q2 = Q(price=F('discounted_price'))\n    q3 = Q(name='product1')\n    q = (q1 | q2) & q3\n    path, args, kwargs = q.deconstruct()\n    self.assertEqual(args, (\n        (('price', F('discounted_price')), ('price__gt', F('discounted_price'))),\n        ('name', 'product1'),\n    ))\n    self.assertEqual(kwargs, {'_connector': 'AND'})\n", "def test_combine_and_with_q_objects(self):\n    q1 = Q(price__gt=F('discounted_price'))\n    q2 = Q(price=F('discounted_price'))\n    combined_q = q1 & q2\n    path, args, kwargs = combined_q.deconstruct()\n    self.assertEqual(args, (\n        ('price', F('discounted_price')),\n        ('price__gt', F('discounted_price')),\n    ))\n    self.assertEqual(kwargs, {})\n    self.assertEqual(combined_q, Q(price__gt=F('discounted_price')) & Q(price=F('discounted_price')))\n", "def test_combine_or_negation(self):\n    q1 = Q(price__gt=F('discounted_price'))\n    q2 = Q(price=F('discounted_price'))\n    q = ~(q1 | q2)\n    path, args, kwargs = q.deconstruct()\n    self.assertEqual(args, (\n        ('price', F('discounted_price')),\n        ('price__gt', F('discounted_price')),\n    ))\n    self.assertEqual(kwargs, {\n        '_connector': 'OR',\n        '_negated': True,\n    })\n", "def test_combine_and_negation(self):\n    q1 = Q(price__gt=F('discounted_price'))\n    q2 = ~Q(price=F('discounted_price'))\n    q = q1 & q2\n    path, args, kwargs = q.deconstruct()\n    self.assertEqual(args, (\n        ('price__gt', F('discounted_price')),\n        (('price', F('discounted_price')), {'_negated': True}),\n    ))\n    self.assertEqual(kwargs, {})\n", "def test_combine_or_single_filter(self):\n    q1 = Q(price__gt=10)\n    q2 = Q(price__lt=20)\n    combined_q = q1 | q2\n    path, args, kwargs = combined_q.deconstruct()\n    self.assertEqual(args, (\n        ('price__gt', 10),\n        ('price__lt', 20),\n    ))\n    self.assertEqual(kwargs, {'_connector': 'OR'})\n"], "sample_67": ["def test_register_invalid_serializer(self):\n    class InvalidSerializer:\n        pass\n\n    with self.assertRaisesMessage(\n        ValueError,\n        \"'InvalidSerializer' must inherit from 'BaseSerializer'.\",\n    ):\n        BaseSerializer.register(str, InvalidSerializer)\n", "def test_register_unregister_serializer(self):\n    from django.db.migrations.serializer import Serializer\n\n    class CustomSerializer(BaseSerializer):\n            return repr(self.value), {}\n\n    Serializer.register(complex, CustomSerializer)\n    self.assertSerializedResultEqual(1 + 2j, (\"complex('(1+2j)')\", {}))\n\n    Serializer.unregister(complex)\n    with self.assertRaises(ValueError):\n        self.assertSerializedEqual(1 + 2j)\n", "def test_register_serializer_usage(self):\n    BaseSerializer.register(complex, ComplexSerializer)\n    self.assertSerializedResultEqual(\n        complex(1, 2),\n        (\"complex((1+2j))\", set()),\n    )\n    BaseSerializer.unregister(complex)\n", "def test_register_serializer_with_complex(self):\n    BaseSerializer.register(complex, ComplexSerializer)\n    value = complex(1 + 2j)\n    result = self.serialize_round_trip(value)\n    self.assertEqual(result, value)\n    BaseSerializer.unregister(complex)\n", "def test_serialize_complex_objects(self):\n    complex_obj = 1 + 2j\n    self.assertSerializedResultEqual(\n        complex_obj,\n        (\"complex('(1+2j)')\", {}),\n    )\n\n    # Register a custom serializer for complex objects\n    BaseSerializer.register(complex, ComplexSerializer)\n    self.assertSerializedResultEqual(\n        complex_obj,\n        (\"complex((1+2j))\", {}),\n    )\n\n    # Unregister the custom serializer\n    BaseSerializer.unregister(complex)\n"], "sample_5": ["def test_fast_delete_signals(self):\n    calls = []\n\n        calls.append('')\n\n    models.signals.post_delete.connect(noop, sender=User)\n\n    u = User.objects.create(\n        avatar=Avatar.objects.create()\n    )\n    a = Avatar.objects.get(pk=u.avatar_id)\n    # 1 query to fast-delete the user\n    # 1 query to delete the avatar\n    self.assertNumQueries(2, a.delete)\n    self.assertFalse(User.objects.exists())\n    self.assertFalse(Avatar.objects.exists())\n    self.assertEqual(len(calls), 1)\n\n    models.signals.post_delete.disconnect(noop, sender=User)\n", "def test_fast_delete_with_listeners(self):\n        pass\n\n    models.signals.post_delete.connect(noop, sender=User)\n\n    u = User.objects.create()\n    # User can be fast-deleted.\n    collector = Collector(using='default')\n    self.assertTrue(collector.can_fast_delete(u))\n\n    models.signals.post_delete.disconnect(noop, sender=User)\n\n    u.delete()\n    self.assertIsNone(u.pk)\n", "    def test_fast_delete_with_signals(self):\n        # Attach a signal to make sure we will not do fast_deletes.\n        calls = []\n\n            calls.append('')\n        models.signals.post_delete.connect(noop, sender=User)\n\n        u = User.objects.create(\n            avatar=Avatar.objects.create()\n        )\n        a = Avatar.objects.get(pk=u.avatar_id)\n        # The signal should prevent fast_delete\n        self.assertNumQueries(3, a.delete)\n        self.assertFalse(User.objects.exists())\n        self.assertFalse(Avatar.objects.exists())\n        self.assertEqual(len(calls), 1)\n        models.signals.post_delete.disconnect(noop, sender=User)\n", "def test_fast_delete_cascade(self):\n    a = create_a('fast_cascade')\n    # Create related objects\n    r = R.objects.create()\n    a.fast_cascade.add(r)\n    # 1 to fast-delete a, 1 to fast-delete a's fast_cascade, 1 to fast-delete r\n    self.assertNumQueries(3, a.delete)\n    self.assertFalse(A.objects.exists())\n    self.assertFalse(R.objects.exists())\n", "def test_fast_delete_generic_fk(self):\n    content_type = ContentType.objects.get_for_model(Avatar)\n    a = Avatar.objects.create(desc='a')\n    GenericRelationFrom.objects.create(content_type=content_type, object_id=a.id)\n    # 1 to delete a, 1 to fast-delete GenericRelationFrom for a\n    self.assertNumQueries(2, a.delete)\n"], "sample_98": ["def test_check_array_accept_sparse_csc():\n    X = [[1, 2], [3, 4]]\n    X_csc = sp.csc_matrix(X)\n\n    X_checked = check_array(X_csc, accept_sparse='csc')\n    assert_equal(X_checked.format, 'csc')\n    assert_false(X_checked is X_csc)\n", "def test_check_array_dense_sparse_equal_output():\n    # Test that the output of check_array is equal for dense and sparse input\n    X_dense = np.array([[1, 2], [3, 4]], dtype=np.float64)\n    X_sparse = sp.csr_matrix(X_dense)\n\n    X_dense_checked = check_array(X_dense, accept_sparse=True)\n    X_sparse_checked = check_array(X_sparse, accept_sparse=True)\n\n    assert_allclose_dense_sparse(X_dense_checked, X_sparse_checked)\n", "def test_check_array_complex_data_warning():\n    # Test that complex data is handled correctly with warning\n    X_complex = np.array([[1 + 1j, 2 + 2j], [3 + 3j, 4 + 4j]])\n    X_complex_checked = assert_warns(DataConversionWarning, check_array, X_complex)\n    assert_equal(X_complex_checked.dtype, np.complex128)\n", "def test_check_array_ndim_greater_than_2():\n    X = np.arange(27).reshape(3, 3, 3)\n    assert_raises(ValueError, check_array, X, allow_nd=False)\n    check_array(X, allow_nd=True)  # doesn't raise\n", "def test_check_array_pandas_index_dtype_object_conversion():\n    # test that data-frame like objects with index dtype object\n    # get converted\n    X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=np.object)\n    X_df = pd.DataFrame(X, index=pd.Index([0, 1, 2], dtype=object))\n    assert_equal(check_array(X_df).dtype.kind, \"f\")\n    assert_equal(check_array(X_df, ensure_2d=False).dtype.kind, \"f\")\n"], "sample_120": ["def test_MatrixElement_subs():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', n, m)\n    assert (A[0, 0]).subs(A, B) == B[0, 0]\n", "def test_matmul_commutative():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, p)\n    C = MatrixSymbol('C', p, q)\n    assert (A * B) * C == A * (B * C)\n", "def test_matrix_element_diff_with_transpose():\n    dexpr = diff((D*w).T[0, k], w[p, 0])\n\n    assert w[p, k].diff(w[k, p]) == KroneckerDelta(k, p)\n    assert w[p, k].diff(w[0, 0]) == KroneckerDelta(p, 0)*KroneckerDelta(k, 0)\n    assert str(dexpr) == \"Sum(KroneckerDelta(p, 0)*D[p, k], (p, 0, n - 1))\"\n    assert str(dexpr.doit()) == 'Piecewise((D[0, k], (0 <= k) & (k <= n - 1)), (0, True))'\n", "def test_MatrixElement_sympify():\n    A = MatrixSymbol('A', n, m)\n    assert sympify(A[0, 0]) == MatrixElement(A, 0, 0)\n    assert sympify(A[n, m]) == MatrixElement(A, n, m)\n    assert sympify(A[0, 0]) != sympify(A[0, 1])\n", "def test_matrix_symbol_subs():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = MatrixSymbol('C', m, l)\n\n    assert A.subs(m, l) == MatrixSymbol('A', n, l)\n    assert (A*B).subs(A, C) == C*B\n    assert (A*B).subs(n, l) == MatrixSymbol('A', l, m)*B\n"], "sample_104": ["def test_indent_at_name_false():\n    # Render a pipeline object with indent_at_name=False\n    pp = _EstimatorPrettyPrinter(indent=4, indent_at_name=False)\n    pipeline = make_pipeline(StandardScaler(), LogisticRegression(C=999))\n    expected = \"\"\"", "def test_n_max_elements_to_show_with_tuples():\n\n    n_max_elements_to_show = 30\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=n_max_elements_to_show\n    )\n\n    # No ellipsis\n    steps = tuple((str(i), i) for i in range(n_max_elements_to_show))\n    pipeline = Pipeline(steps=steps)\n\n    expected = r\"\"\"", "def test_compact_true():\n    # Test with compact=True\n    pp = _EstimatorPrettyPrinter(compact=True, indent=1, indent_at_name=True)\n\n    lr = LogisticRegression(C=99, class_weight=.4, fit_intercept=False, tol=1234, verbose=True)\n    expected = \"\"\"", "def test_ellipsis_in_nested_dict():\n    n_max_elements_to_show = 30\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=n_max_elements_to_show\n    )\n\n    # Test ellipsis in nested dict\n    param_grid = {'reduce_dim': [PCA(iterated_power=7), NMF()],\n                  'reduce_dim__n_components': [i for i in range(n_max_elements_to_show + 1)],\n                  'classify__C': [1, 10, 100, 1000]}\n    gs = GridSearchCV(SVC(), param_grid)\n    expected = \"\"\"", "def test_ellipsis_in_dict_value():\n    # Test ellipsis in dict value\n    n_max_elements_to_show = 1\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=n_max_elements_to_show\n    )\n    vocabulary = {0: 'hello' * 1000}\n    vectorizer = CountVectorizer(vocabulary=vocabulary)\n    expected = r\"\"\""], "sample_87": ["def test_collect_pkg_init_only_not_collected(testdir):\n    subdir = testdir.mkdir(\"sub\")\n    init = subdir.ensure(\"__init__.py\")\n    init.write(\"__all__ = []\")\n\n    result = testdir.runpytest(str(subdir))\n    result.stdout.fnmatch_lines([\"*no tests ran in*\"])\n", "def test_collect_sub_with_duplicate_symlinks(testdir):\n    sub = testdir.mkdir(\"sub\")\n    sub.ensure(\"__init__.py\")\n    sub.ensure(\"test_file.py\").write(\"def test_file(): pass\")\n\n    # Symlink that points to the same file as another symlink.\n    sub.join(\"test_duplicate_symlink.py\").mksymlinkto(\"test_file.py\")\n\n    # Symlink that gets collected.\n    sub.join(\"test_symlink.py\").mksymlinkto(\"test_file.py\")\n\n    result = testdir.runpytest(\"-v\", str(sub))\n    result.stdout.fnmatch_lines(\n        [\n            \"sub/test_file.py::test_file PASSED*\",\n            \"sub/test_symlink.py::test_file PASSED*\",\n            # Check that the duplicate symlink is not collected.\n            \"sub/test_duplicate_symlink.py::test_file SKIPPED*\",\n            \"*2 passed, 1 skipped in*\",\n        ]\n    )\n", "def test_collect_sub_with_excluded_files(testdir):\n    sub = testdir.mkdir(\"sub\")\n    sub.ensure(\"__init__.py\")\n    sub.ensure(\"test_file.py\").write(\"def test_file(): pass\")\n\n    # Create a file that should be excluded.\n    sub.ensure(\"exclude_file.py\").write(\"def test_exclude(): pass\")\n    testdir.makeconftest(f\"collect_ignore = ['exclude_file.py']\")\n\n    result = testdir.runpytest(\"-v\", str(sub))\n    result.stdout.fnmatch_lines(\n        [\n            \"sub/test_file.py::test_file PASSED*\",\n            \"*1 passed in*\",\n        ]\n    )\n    result.stdout.no_fnmatch_line(\"sub/exclude_file.py::test_exclude*\")\n", "def test_collect_custom_nodes_multi_id_with_multiple_nodes(self, testdir):\n    p = testdir.makepyfile(\"def test_func(): pass\")\n    testdir.makeconftest(\n        \"\"\"\n        import pytest\n        class SpecialItem1(pytest.Item):\n                return # ok\n        class SpecialItem2(pytest.Item):\n                return # ok\n        class SpecialFile(pytest.File):\n                return [SpecialItem1(name=\"check1\", parent=self), SpecialItem2(name=\"check2\", parent=self)]\n            if path.basename == %r:\n                return SpecialFile(fspath=path, parent=parent)\n        \"\"\"\n        % p.basename\n    )\n    id = p.basename\n\n    items, hookrec = testdir.inline_genitems(id)\n    pprint.pprint(hookrec.calls)\n    assert len(items) == 3\n    hookrec.assert_contains(\n        [\n            (\"pytest_collectstart\", \"collector.fspath == collector.session.fspath\"),\n            (\"pytest_collectstart\", \"collector.__class__.__name__ == 'SpecialFile'\"),\n            (\"pytest_pycollect_makeitem\", \"name == 'check1'\"),\n            (\"pytest_pycollect_makeitem\", \"name == 'check2'\"),\n            (\"pytest_collectreport\", \"report.nodeid.startswith(p.basename)\"),\n        ]\n    )\n    assert len(self.get_reported_items(hookrec)) == 3\n", "def test_collect_sub_with_symlinks_and_ignore(testdir):\n    \"\"\"Test collection of symlink and ignore works.\"\"\"\n    sub = testdir.mkdir(\"sub\")\n    sub.ensure(\"__init__.py\")\n    sub.ensure(\"test_file.py\").write(\"def test_file(): pass\")\n\n    # Create a symlink that gets ignored.\n    sub.join(\"test_ignored.py\").mksymlinkto(\"test_file.py\")\n\n    testdir.makeconftest(\n        \"\"\"\n            if path.basename == 'test_ignored.py':\n                return True\n    \"\"\"\n    )\n\n    result = testdir.runpytest(\"-v\", str(sub))\n    result.stdout.fnmatch_lines(\n        [\n            \"sub/test_file.py::test_file PASSED*\",\n            \"*1 passed in*\",\n        ]\n    )\n    result.stdout.no_fnmatch_line(\"*test_ignored.py*\")\n"], "sample_78": ["def test_run_cert_path_exists(monkeypatch):\n    # cert file doesn't exist\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"non-existent-file\", \"--key\", __file__])\n\n    # key file doesn't exist\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", __file__, \"--key\", \"non-existent-file\"])\n", "def test_run_command_with_reload(runner, monkeypatch):\n        app = Flask(\"testapp\")\n\n        @app.route(\"/\")\n            return \"Hello, World!\"\n\n        return app\n\n    obj = ScriptInfo(create_app=create_app)\n    result = runner.invoke(run_command, [\"--reload\", \"--no-debugger\"], obj=obj)\n    assert result.exit_code == 0\n    assert \" * Serving Flask app 'testapp'\" in result.output\n    assert \" * Debug mode: off\" in result.output\n", "def test_run_extra_files(runner):\n    @click.command()\n    @click.pass_context\n        click.echo(str(ctx.params[\"extra_files\"]))\n\n    cli = FlaskGroup(create_app=lambda: Flask(\"test_extra_files\"))\n    cli.add_command(test_extra_files_cmd)\n\n    result = runner.invoke(cli, [\"test-extra-files\", \"--extra-files\", f\"{__file__}:{__file__}\"])\n    assert result.exit_code == 0\n    assert result.output == f\"['{__file__}', '{__file__}']\\n\"\n", "def test_run_command_extra_files(runner, monkeypatch):\n    @click.command(\"run\")\n    @with_appcontext\n        click.echo(str(current_app.config.get(\"EXTRA_FILES\")))\n\n    obj = ScriptInfo(create_app=lambda: Flask(\"testapp\"))\n    runner = CliRunner()\n\n    # Test with no extra files specified\n    result = runner.invoke(custom_run_command, obj=obj)\n    assert result.exit_code == 0\n    assert result.output == \"None\\n\"\n\n    # Test with extra files specified\n    extra_files = [\"file1\", \"file2\"]\n    result = runner.invoke(custom_run_command, [\"--extra-files\", os.pathsep.join(extra_files)], obj=obj)\n    assert result.exit_code == 0\n    assert eval(result.output.strip()) == extra_files\n\n    # Test with non-existent file\n    with pytest.raises(click.BadParameter):\n        runner.invoke(custom_run_command, [\"--extra-files\", \"nonexistentfile\"], obj=obj)\n", "def test_run_cert_options(monkeypatch):\n    # Adhoc certificate with key\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"adhoc\", \"--key\", __file__])\n\n    # SSLContext with key\n    ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n    monkeypatch.setitem(sys.modules, \"ssl_context\", ssl_context)\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"ssl_context\", \"--key\", __file__])\n"], "sample_92": ["def test_marked_xfail_with_boolean_without_reason(self, testdir) -> None:\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.xfail(True)\n            pass\n        \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_xfail_marks(item)\n    assert excinfo.value.msg is not None\n    assert (\n        \"\"\"Error evaluating 'xfail': you need to specify reason=STRING when using booleans as conditions.\"\"\"\n        in excinfo.value.msg\n    )\n", "def test_marked_skipif_with_boolean_with_reason(self, testdir) -> None:\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.skipif(True, reason=\"boolean with reason\")\n            pass\n        \"\"\"\n    )\n    skipped = evaluate_skip_marks(item)\n    assert skipped\n    assert skipped.reason == \"boolean with reason\"\n", "def test_skipif_with_invalid_syntax(self, testdir) -> None:\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.skipif(\"syntax error\")\n            pass\n        \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_skip_marks(item)\n    assert excinfo.value.msg is not None\n    assert \"Error evaluating 'skipif' condition\" in excinfo.value.msg\n    assert \"syntax error\" in excinfo.value.msg\n    assert \"SyntaxError: invalid syntax\" in excinfo.value.msg\n", "def test_skipif_with_invalid_boolean(self, testdir):\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n\n        class InvalidBool:\n                raise TypeError(\"INVALID\")\n\n        @pytest.mark.skipif(InvalidBool(), reason=\"xxx\")\n            pass\n    \"\"\"\n    )\n    with pytest.raises(pytest.skip.Exception) as excinfo:\n        evaluate_skip_marks(item)\n    assert excinfo.value.msg is not None\n    assert \"Error evaluating 'skipif' condition as a boolean\" in excinfo.value.msg\n    assert \"INVALID\" in excinfo.value.msg\n", "def test_marked_skipif_with_invalid_syntax(self, testdir):\n    item = testdir.getitem(\n        \"\"\"\n        import pytest\n        @pytest.mark.skipif(\"syntax error:)\n            pass\n        \"\"\"\n    )\n    with pytest.raises(pytest.fail.Exception) as excinfo:\n        evaluate_skip_marks(item)\n    assert excinfo.value.msg is not None\n    assert \"Error evaluating 'skipif' condition\" in excinfo.value.msg\n    assert \"syntax error:)\" in excinfo.value.msg\n"], "sample_107": ["def test_logistic_regression_path_deprecation_with_arguments():\n\n    assert_warns_message(DeprecationWarning,\n                         \"logistic_regression_path was deprecated\",\n                         logistic_regression_path, X, Y1, Cs=[1.0], penalty='l2')\n", "def test_logistic_regression_path_Cs(solver):\n    X, y = make_classification(n_samples=100, n_features=20, random_state=0)\n    Cs = [0.1, 1.0, 10.0]\n    coefs, _, _ = _logistic_regression_path(X, y, Cs=Cs, solver=solver, random_state=0)\n    assert coefs.shape == (len(Cs), X.shape[1] + 1)\n", "def test_logistic_regression_path_intercept_scaling():\n    # Test that intercept_scaling is correctly applied in logistic_regression_path\n    n_samples, n_features = 10, 5\n    X, y = make_classification(n_samples=n_samples, n_features=n_features, random_state=0)\n\n    # Fit intercept case with intercept_scaling\n    alpha = 1.\n    w = np.ones(n_features + 1)\n    coefs, _, _ = _logistic_regression_path(X, y, Cs=[1.], fit_intercept=True, intercept_scaling=2., alpha=alpha)\n\n    # Do not fit intercept but manually scale the intercept\n    X_ = np.hstack((X, np.ones(n_samples)[:, np.newaxis]))\n    w[-1] *= 2\n    coefs_no_scaling, _, _ = _logistic_regression_path(X_, y, Cs=[1.], fit_intercept=False, alpha=alpha)\n\n    # Check that the coefficients are the same\n    assert_array_almost_equal(coefs[-1], coefs_no_scaling[-1])\n", "def test_logistic_regression_path_exception():\n    # Test that logistic_regression_path raises an exception for invalid inputs\n    X, y = make_classification(n_samples=10, n_features=20, random_state=0)\n    invalid_Cs = [-1, 0]\n    for C in invalid_Cs:\n        assert_raises(ValueError, _logistic_regression_path, X, y, Cs=[C])\n\n    invalid_tol = [-1, 0]\n    for tol in invalid_tol:\n        assert_raises(ValueError, _logistic_regression_path, X, y, tol=tol)\n\n    invalid_max_iter = [-1, 0]\n    for max_iter in invalid_max_iter:\n        assert_raises(ValueError, _logistic_regression_path, X, y, max_iter=max_iter)\n\n    invalid_multi_class = ['invalid_option', 123]\n    for multi_class in invalid_multi_class:\n        assert_raises(ValueError, _logistic_regression_path, X, y, multi_class=multi_class)\n", "def test_logistic_regression_path_max_iter():\n    # Make sure that max_iter is respected by logistic_regression_path\n    X, y = make_classification(n_samples=100, n_features=20, random_state=0)\n    Cs = [1.0]\n    coefs, _, _ = _logistic_regression_path(X, y, penalty='l2', Cs=Cs,\n                                            solver='sag', random_state=0,\n                                            multi_class='ovr', max_iter=1)\n    assert_equal(coefs.shape[0], 1)  # Only one iteration was performed\n"], "sample_45": ["    def test_cache_page_decorator_http_request(self):\n        class MyClass:\n            @cache_page(60 * 15)\n                return HttpResponse()\n        msg = (\n            \"cache_page didn't receive an HttpRequest. If you are decorating \"\n            \"a classmethod, be sure to use @method_decorator.\"\n        )\n        with self.assertRaisesMessage(TypeError, msg):\n            MyClass().a_view(HttpRequest())\n", "def test_cache_control_decorator_args(self):\n    @cache_control(public=True, max_age=3600)\n        return HttpResponse()\n    r = a_view(HttpRequest())\n    self.assertEqual(r.headers['Cache-Control'], 'public, max-age=3600')\n\n    @cache_control(no_cache=True, no_store=True)\n        return HttpResponse()\n    r = another_view(HttpRequest())\n    self.assertEqual(set(r.headers['Cache-Control'].split(', ')), {'no-cache', 'no-store'})\n", "def test_cache_page_vary(self):\n        return \"response\"\n    my_view_cached = cache_page(123, cache='default', cache_alias='alias')(my_view)\n    request = HttpRequest()\n    request.META['HTTP_ACCEPT_LANGUAGE'] = 'en-us'\n    request.COOKIES['test'] = 'value'\n    response = my_view_cached(request)\n    self.assertIn('Vary', response)\n    self.assertEqual(response['Vary'], 'Accept-Language, Cookie')\n", "    def test_cache_page_decorator_http_request(self):\n        class MyClass:\n            @cache_page(123)\n                return HttpResponse()\n        msg = (\n            \"cache_page didn't receive an HttpRequest. If you are decorating \"\n            \"a classmethod, be sure to use @method_decorator.\"\n        )\n        with self.assertRaisesMessage(TypeError, msg):\n            MyClass().a_view(HttpRequest())\n", "    def test_cache_page_decorator_http_request(self):\n        class MyClass:\n            @cache_page(60 * 15)\n                return HttpResponse()\n        msg = (\n            \"cache_page didn't receive an HttpRequest. If you are decorating \"\n            \"a classmethod, be sure to use @method_decorator.\"\n        )\n        with self.assertRaisesMessage(TypeError, msg):\n            MyClass().a_view(HttpRequest())\n"], "sample_100": ["def test_one_hot_encoder_unsorted_categories_error():\n    X = np.array([[1, 2]]).T\n    enc = OneHotEncoder(categories=[[2, 1]])\n    msg = 'Unsorted categories are not supported'\n    with pytest.raises(ValueError, match=msg):\n        enc.fit_transform(X)\n", "def test_one_hot_encoder_unsorted_categories_for_numeric():\n    X = np.array([[1, 2]], dtype='int64').T\n\n    enc = OneHotEncoder(categories=[[2, 1, 3]])\n    msg = 'Unsorted categories are not supported'\n    with pytest.raises(ValueError, match=msg):\n        enc.fit_transform(X)\n\n    enc = OrdinalEncoder(categories=[[2, 1, 3]])\n    msg = 'Unsorted categories are not supported'\n    with pytest.raises(ValueError, match=msg):\n        enc.fit_transform(X)\n", "def test_ordinal_encoder_specified_categories_mixed_columns(X):\n    # multiple columns\n    enc = OrdinalEncoder(categories=[['abc', 'def', 'ghi'], [1, 2, 3]])\n    exp = np.array([[0, 1, 0], [1, 0, 0]], dtype='int64')\n    assert_array_equal(enc.fit_transform(X), exp.astype('float64'))\n    enc = OrdinalEncoder(categories=[['abc', 'def', 'ghi'], [1, 2, 3]], dtype='int64')\n    assert_array_equal(enc.fit_transform(X), exp)\n", "def test_one_hot_encoder_dtypes_sparse():\n    X = np.array([[1, 2], [3, 4]], dtype='int64')\n    enc = OneHotEncoder(categories='auto', sparse=True)\n    exp = np.array([[1., 0., 1., 0.], [0., 1., 0., 1.]], dtype='float64')\n    assert_array_equal(enc.fit_transform(X).toarray(), exp)\n", "def test_ordinal_encoder_handle_unknown():\n    X = np.array([[0, 2], [1, 0], [1, 2]])\n    X2 = np.array([[4, 1]])\n\n    # Test the error option, raises error for unknown features during transform.\n    enc = OrdinalEncoder(handle_unknown='error')\n    enc.fit(X)\n    assert_raises(ValueError, enc.transform, X2)\n\n    # Test the ignore option, handles unknown features by keeping them unchanged.\n    enc = OrdinalEncoder(handle_unknown='ignore')\n    enc.fit(X)\n    X2_passed = X2.copy()\n    assert_array_equal(enc.transform(X2_passed), X2)\n    # Ensure transformed data was not modified in place\n    assert_array_equal(X2, X2_passed)\n\n    # Raise error if handle_unknown is neither ignore or error.\n    enc = OrdinalEncoder(handle_unknown='42')\n    assert_raises(ValueError, enc.fit, X)\n"], "sample_77": ["def test_label_concise(self, t):\n\n    s = Temporal().label(concise=True)\n    a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n    a.set_view_interval(10, 1000)\n    label, = a.major.formatter.format_ticks([100])\n    assert label == \"1970\"\n", "def test_label_concise(self, t):\n\n    s = Temporal().label(concise=True)\n    a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n    a.set_view_interval(0, 365)\n    label, = a.major.formatter.format_ticks([100])\n    assert label != \"\"\n", "def test_label_concise_formatter(self, t):\n\n    s = Temporal().label(concise=True)\n    a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n    a.set_view_interval(10, 1000)\n    label, = a.major.formatter.format_ticks([100])\n    assert label == \"1970\"\n", "def test_label_concise(self, t):\n\n    s = Temporal().label(concise=True)\n    a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n    a.set_view_interval(0, 365 * 3)\n    labels = a.major.formatter.format_ticks(a.major.locator())\n    assert len(labels) == len(set(labels))  # Check for uniqueness\n    assert all(label.isnumeric() or label.endswith((\"y\", \"m\", \"d\")) for label in labels)\n", "def test_label_concise(self, t):\n\n    s = Temporal().label(concise=True)\n    a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n    a.set_view_interval(0, 365)\n    label, = a.major.formatter.format_ticks([100])\n    assert label != \"1970\"\n"], "sample_68": ["def test_update_conflicts_unique_fields_pk_name(self):\n    Country.objects.bulk_create(self.data)\n    self.assertEqual(Country.objects.count(), 4)\n\n    new_data = [\n        # Conflicting countries.\n        Country(\n            name=\"Germany\",\n            iso_two_letter=\"DE\",\n            description=(\"Germany is a country in Central Europe.\"),\n        ),\n        Country(\n            name=\"Czech Republic\",\n            iso_two_letter=\"CZ\",\n            description=(\n                \"The Czech Republic is a landlocked country in Central Europe.\"\n            ),\n        ),\n        # New countries.\n        Country(name=\"Australia\", iso_two_letter=\"AU\"),\n        Country(\n            name=\"Japan\",\n            iso_two_letter=\"JP\",\n            description=(\"Japan is an island country in East Asia.\"),\n        ),\n    ]\n    results = Country.objects.bulk_create(\n        new_data,\n        update_conflicts=True,\n        update_fields=[\"description\"],\n        unique_fields=[\"pk\", \"name\"],\n    )\n    self.assertEqual(len(results), len(new_data))\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(Country.objects.count(), 6)\n    self.assertCountEqual(\n        Country.objects.values(\"iso_two_letter\", \"description\"),\n        [\n            {\"iso_two_letter\": \"US\", \"description\": \"\"},\n            {\"iso_two_letter\": \"NL\", \"description\": \"\"},\n            {\n                \"iso_two_letter\": \"DE\",\n                \"description\": (\"Germany is a country in Central Europe.\"),\n            },\n            {\n                \"iso_two_letter\": \"CZ\",\n                \"description\": (", "def test_update_conflicts_with_db_columns(self):\n    data = [\n        FieldsWithDbColumns(name=\"Germany\", iso_two_letter=\"DE\"),\n        FieldsWithDbColumns(name=\"Czech Republic\", iso_two_letter=\"CZ\"),\n    ]\n    FieldsWithDbColumns.objects.bulk_create(data)\n\n    conflicting_objects = [\n        FieldsWithDbColumns(name=\"Germany\", iso_two_letter=\"DE\", description=\"Updated description\"),\n        FieldsWithDbColumns(name=\"Czech Republic\", iso_two_letter=\"CZ\", description=\"Updated description\"),\n    ]\n    results = FieldsWithDbColumns.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        update_fields=[\"description\"],\n        unique_fields=[\"iso_two_letter\"],\n    )\n    self.assertEqual(len(results), len(conflicting_objects))\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n    self.assertCountEqual(\n        FieldsWithDbColumns.objects.values(\"iso_two_letter\", \"description\"),\n        [\n            {\"iso_two_letter\": \"DE\", \"description\": \"Updated description\"},\n            {\"iso_two_letter\": \"CZ\", \"description\": \"Updated description\"},\n        ],\n    )\n", "def test_update_conflicts_ignore_on_conflict(self):\n    # Test that ignore_conflicts has no effect when update_conflicts is True\n    data = [\n        TwoFields(f1=1, f2=1),\n        TwoFields(f1=2, f2=2),\n        TwoFields(f1=3, f2=3),\n    ]\n    TwoFields.objects.bulk_create(data)\n    self.assertEqual(TwoFields.objects.count(), 3)\n\n    conflicting_objects = [\n        TwoFields(f1=2, f2=2),\n        TwoFields(f1=3, f2=3),\n    ]\n    TwoFields.objects.bulk_create(conflicting_objects, update_conflicts=True, ignore_conflicts=True, update_fields=[\"f2\"])\n    self.assertEqual(TwoFields.objects.count(), 3)\n    self.assertCountEqual(\n        TwoFields.objects.values(\"f1\", \"f2\"),\n        [\n            {\"f1\": 1, \"f2\": 1},\n            {\"f1\": 2, \"f2\": 2},\n            {\"f1\": 3, \"f2\": 3},\n        ],\n    )\n", "def test_update_conflicts_multiple_fields(self):\n    FieldsWithDbColumns.objects.bulk_create(\n        [\n            FieldsWithDbColumns(\n                char_field=\"a\", text_field=\"a\", integer_field=1,\n                float_field=1.1, decimal_field=\"1.11\", date_field=\"2022-01-01\",\n                datetime_field=\"2022-01-01 00:00:00\", time_field=\"00:00:00\",\n                binary_field=b\"a\", boolean_field=True\n            ),\n            FieldsWithDbColumns(\n                char_field=\"b\", text_field=\"b\", integer_field=2,\n                float_field=2.2, decimal_field=\"2.22\", date_field=\"2022-01-02\",\n                datetime_field=\"2022-01-02 00:00:00\", time_field=\"00:00:01\",\n                binary_field=b\"b\", boolean_field=False\n            ),\n        ]\n    )\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n\n    conflicting_objects = [\n        FieldsWithDbColumns(\n            char_field=\"a\", text_field=\"c\", integer_field=3,\n            float_field=3.3, decimal_field=\"3.33\", date_field=\"2022-01-03\",\n            datetime_field=\"2022-01-03 00:00:00\", time_field=\"00:00:02\",\n            binary_field=b\"c\", boolean_field=True\n        ),\n        FieldsWithDbColumns(\n            char_field=\"b\", text_field=\"d\", integer_field=4,\n            float_field=4.4, decimal_field=\"4.44\",", "def test_update_conflicts_db_columns(self):\n    FieldsWithDbColumns.objects.bulk_create(\n        [\n            FieldsWithDbColumns(name=\"John\", column_name=\"Johnny\"),\n            FieldsWithDbColumns(name=\"Mary\", column_name=\"Marie\"),\n        ]\n    )\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n\n    conflicting_objects = [\n        FieldsWithDbColumns(name=\"John\", column_name=\"John\"),\n        FieldsWithDbColumns(name=\"Mary\", column_name=\"Mary\"),\n    ]\n    results = FieldsWithDbColumns.objects.bulk_create(\n        conflicting_objects,\n        update_conflicts=True,\n        update_fields=[\"column_name\"],\n        unique_fields=[\"name\"],\n    )\n    self.assertEqual(len(results), len(conflicting_objects))\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(FieldsWithDbColumns.objects.count(), 2)\n    self.assertCountEqual(\n        FieldsWithDbColumns.objects.values(\"name\", \"column_name\"),\n        [\n            {\"name\": \"John\", \"column_name\": \"John\"},\n            {\"name\": \"Mary\", \"column_name\": \"Mary\"},\n        ],\n    )\n"], "sample_14": ["def test_serialize_complex(self):\n    self.assertSerializedEqual(complex(1, 2))\n    self.assertSerializedResultEqual(complex(1, 2), (\"complex((1+2j))\", set()))\n", "def test_serialize_complex_number(self):\n    self.assertSerializedEqual(complex(1, 2))\n    self.assertSerializedResultEqual(complex(1, 2), (\"complex((1+2j))\", {}))\n", "def test_complex_serializer(self):\n    \"\"\"\n    Test the custom serializer for complex numbers.\n    \"\"\"\n    complex_num = 1 + 2j\n    BaseSerializer.register(complex, ComplexSerializer)\n    string = MigrationWriter.serialize(complex_num)[0]\n    self.assertEqual(string, \"complex('(1+2j)')\")\n    self.assertEqual(self.serialize_round_trip(complex_num), complex_num)\n    BaseSerializer.unregister(complex)\n", "def test_register_serializer_usage(self):\n    BaseSerializer.register(complex, ComplexSerializer)\n    value = complex(1+2j)\n    result = self.serialize_round_trip(value)\n    self.assertEqual(result, value)\n    BaseSerializer.unregister(complex)\n", "def test_custom_serializer_registration(self):\n    class CustomClass:\n            self.value = value\n\n    class CustomSerializer(BaseSerializer):\n            return \"CustomClass(%s)\" % self.value, {'import migrations.test_writer'}\n\n    BaseSerializer.register(CustomClass, CustomSerializer)\n    value = CustomClass(42)\n    string, imports = MigrationWriter.serialize(value)\n    self.assertEqual(string, \"CustomClass(42)\")\n    self.assertEqual(imports, {'import migrations.test_writer'})\n    BaseSerializer.unregister(CustomClass)\n"], "sample_57": ["def test_formset_with_custom_prefix(self):\n    \"\"\"FormSets with custom prefix.\"\"\"\n    CustomPrefixChoiceFormSet = formset_factory(Choice, prefix='custom')\n    initial = [\n        {\"choice\": \"Calexico\", \"votes\": 100},\n        {\"choice\": \"Fergie\", \"votes\": 900},\n    ]\n    formset = CustomPrefixChoiceFormSet(initial=initial, auto_id=False)\n    self.assertHTMLEqual(\n        \"\\n\".join(form.as_ul() for form in formset.forms),\n        '<li>Choice: <input type=\"text\" name=\"custom-0-choice\" value=\"Calexico\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"custom-0-votes\" value=\"100\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"custom-1-choice\" value=\"Fergie\">'\n        \"</li>\"\n        '<li>Votes: <input type=\"number\" name=\"custom-1-votes\" value=\"900\"></li>'\n        '<li>Choice: <input type=\"text\" name=\"custom-2-choice\"></li>'\n        '<li>Votes: <input type=\"number\" name=\"custom-2-votes\"></li>',\n    )\n", "def test_formset_with_deletion_and_ordering_custom_widget(self):\n    \"\"\"FormSets with deletion, ordering, and custom widgets.\"\"\"\n    class DeletionOrderingAttributeFormSet(BaseFormSet):\n        deletion_widget = HiddenInput\n        ordering_widget = HiddenInput\n\n    class DeletionOrderingMethodFormSet(BaseFormSet):\n            return HiddenInput(attrs={\"class\": \"deletion\"})\n\n            return HiddenInput(attrs={\"class\": \"ordering\"})\n\n    tests = (\n        (DeletionOrderingAttributeFormSet, '<input type=\"hidden\" name=\"form-0-DELETE\">', '<input type=\"hidden\" name=\"form-0-ORDER\">'),\n        (DeletionOrderingMethodFormSet, '<input class=\"deletion\" type=\"hidden\" name=\"form-0-DELETE\">', '<input class=\"ordering\" type=\"hidden\" name=\"form-0-ORDER\">'),\n    )\n    for formset_class, delete_html, order_html in tests:\n        with self.subTest(formset_class=formset_class.__name__):\n            ArticleFormSet = formset_factory(\n                ArticleForm, formset=formset_class, can_delete=True, can_order=True\n            )\n            formset = ArticleFormSet(auto_id=False)\n            self.assertHTMLEqual(\n                \"\\n\".join(form.as_ul() for form in formset.forms),\n                (\n                    '<li>Title: <input type=\"text\" name=\"form-0-title\"></li>'\n                    '<li>Pub date: <input type=\"text\" name=\"form-0-pub_date\">'\n                    \"%s%s</li>\" % (delete_html, order_html)\n                ),\n            )\n", "def test_formset_total_error_count_with_deleted_forms(self):\n    \"\"\"A valid formset with deleted forms should have the correct total error count.\"\"\"\n    data = {\n        \"choices-TOTAL_FORMS\": \"3\",\n        \"choices-INITIAL_FORMS\": \"0\",\n        \"choices-MIN_NUM_FORMS\": \"0\",\n        \"choices-MAX_NUM_FORMS\": \"0\",\n        \"choices-0-choice\": \"Calexico\",\n        \"choices-0-votes\": \"100\",\n        \"choices-0-DELETE\": \"on\",\n        \"choices-1-choice\": \"The Decemberists\",\n        \"choices-1-votes\": \"200\",\n        \"choices-1-DELETE\": \"\",\n        \"choices-2-choice\": \"\",\n        \"choices-2-votes\": \"\",\n        \"choices-2-DELETE\": \"\",\n    }\n    ChoiceFormSet = formset_factory(Choice, can_delete=True)\n    formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n    self.assertEqual(formset.total_error_count(), 0)\n", "def test_formset_with_custom_templates(self):\n    \"\"\"\n    Formsets render using the formset template specified by the renderer.\n    \"\"\"\n    from django.forms.renderers import Jinja2\n\n    class CustomTemplates(Jinja2):\n        formset_template_name = \"custom/formset.html\"\n\n    data = {\n        \"choices-TOTAL_FORMS\": \"1\",\n        \"choices-INITIAL_FORMS\": \"0\",\n        \"choices-MIN_NUM_FORMS\": \"0\",\n        \"choices-MAX_NUM_FORMS\": \"0\",\n        \"choices-0-choice\": \"Calexico\",\n        \"choices-0-votes\": \"100\",\n    }\n    ChoiceFormSet = formset_factory(Choice, renderer=CustomTemplates)\n    formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n\n    with self.settings(TEMPLATES=jinja2_tests.TEMPLATES):\n        rendered = formset.render()\n\n    self.assertIn(\"custom/formset.html\", rendered)\n    self.assertIn(\"Calexico\", rendered)\n    self.assertIn(\"100\", rendered)\n", "def test_custom_formset_with_prefix(self):\n    class CustomPrefixFormSet(BaseFormSet):\n            return \"custom\"\n\n    CustomPrefixChoiceFormSet = formset_factory(Choice, formset=CustomPrefixFormSet)\n    formset = CustomPrefixChoiceFormSet(auto_id=False)\n    self.assertEqual(formset.management_form.prefix, \"custom\")\n    self.assertHTMLEqual(\n        str(formset.management_form),\n        '<input type=\"hidden\" name=\"custom-TOTAL_FORMS\" value=\"1\">'\n        '<input type=\"hidden\" name=\"custom-INITIAL_FORMS\" value=\"0\">'\n        '<input type=\"hidden\" name=\"custom-MIN_NUM_FORMS\" value=\"0\">'\n        '<input type=\"hidden\" name=\"custom-MAX_NUM_FORMS\" value=\"1000\">',\n    )\n"], "sample_151": ["def test_direction_cosine():\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(2, 3, 5)\n    assert p1.direction_cosine(p2) == [sqrt(6)/6, sqrt(6)/6, sqrt(6)/3]\n", "def test_direction_cosine():\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(2, 3, 5)\n    assert p1.direction_cosine(p2) == [sqrt(6)/6, sqrt(6)/6, sqrt(6)/3]\n", "def test_direction_ratio_and_cosine():\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(2, 3, 5)\n    assert p1.direction_ratio(p2) == [1, 1, 2]\n    assert p1.direction_cosine(p2) == [sqrt(6)/6, sqrt(6)/6, sqrt(6)/3]\n", "def test_issue_22684():\n    # Test that Point can be instantiated with a non-evaluated expression\n    x = Symbol('x', real=True)\n    p = Point(x, x**2)\n    assert p.x == x\n    assert p.y == x**2\n", "def test_issue_22684_2():\n    # Test different combinations of arguments and options\n    assert Point(1, 2) == Point([1, 2])\n    assert Point(1, 2) == Point((1, 2))\n    assert Point(1, 2) == Point(1, 2, dim=2)\n    assert Point(1, 2) == Point(1, 2, dim=3, on_morph='ignore')\n    assert Point(1, 2) == Point(1, 2, dim=4, on_morph='warn')\n    assert Point(1, 2) == Point(1, 2, evaluate=False)\n    assert Point(1, 2) == Point(1, 2, dim=2, evaluate=False)\n    assert Point(1, 2) == Point(1, 2, dim=3, evaluate=False, on_morph='ignore')\n    assert Point(1, 2) == Point(1, 2, dim=4, evaluate=False, on_morph='warn')\n"], "sample_43": ["def test_missing_model_admin(self):\n    \"\"\"\n    Accessing the autocomplete view for a model that is not registered with\n    the admin site raises PermissionDenied.\n    \"\"\"\n    opts = {\n        'app_label': 'admin_views',\n        'model_name': 'NonExistentModel',\n        'field_name': 'question'\n    }\n    request = self.factory.get(self.url, {'term': 'is', **opts})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "def test_search_results_order(self):\n    \"\"\"\n    Search results are ordered by question text.\n    \"\"\"\n    class TextOrderingQuestionAdmin(QuestionAdmin):\n        ordering = ['question']\n\n    Question.objects.create(question='Question 1')\n    Question.objects.create(question='Question 2')\n    Question.objects.create(question='Question 3')\n\n    request = self.factory.get(self.url, {'term': 'Question', **self.opts})\n    request.user = self.superuser\n\n    with model_admin(Question, TextOrderingQuestionAdmin):\n        response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n\n    self.assertEqual(response.status_code, 200)\n    data = json.loads(response.content.decode('utf-8'))\n    self.assertEqual(data, {\n        'results': [\n            {'id': str(q.pk), 'text': q.question}\n            for q in Question.objects.order_by('question')\n        ],\n        'pagination': {'more': False},\n    })\n", "def test_permission_denied_for_missing_app_label(self):\n    request = self.factory.get(self.url, {'term': 'is', **self.opts, 'app_label': 'does_not_exist'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "def test_invalid_request(self):\n    \"\"\"\n    Test that the view raises PermissionDenied if the request is missing\n    required parameters.\n    \"\"\"\n    request = self.factory.get(self.url, {'term': 'is'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n\n    request = self.factory.get(self.url, {'app_label': 'admin_views', 'model_name': 'Answer'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n\n    request = self.factory.get(self.url, {'app_label': 'admin_views', 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n\n    request = self.factory.get(self.url, {'model_name': 'Answer', 'field_name': 'question'})\n    request.user = self.superuser\n    with self.assertRaises(PermissionDenied):\n        AutocompleteJsonView.as_view(**self.as_view_args)(request)\n", "def test_search_filter(self):\n    \"\"\"\n    Search filter is applied correctly.\n    \"\"\"\n    Question.objects.create(question='Is this a question?')\n    Question.objects.create(question='Not a question.')\n    request = self.factory.get(self.url, {'term': 'not', **self.opts})\n    request.user = self.superuser\n    response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    self.assertEqual(response.status_code, 200)\n    data = json.loads(response.content.decode('utf-8'))\n    self.assertEqual(len(data['results']), 1)\n    self.assertEqual(data['results'][0]['text'], 'Not a question.')\n"], "sample_38": ["def test_inactive_user_custom_message(self):\n    data = {\n        'username': 'inactive',\n        'password': 'password',\n    }\n\n    class CustomAuthenticationForm(AuthenticationForm):\n        error_messages = {\n            'inactive': \"Custom inactive error message.\",\n        }\n\n    form = CustomAuthenticationForm(None, data)\n    self.assertFalse(form.is_valid())\n    self.assertEqual(form.non_field_errors(), [\"Custom inactive error message.\"])\n", "def test_empty_old_password(self):\n    user = User.objects.get(username='testclient')\n    data = {\n        'old_password': '',\n        'new_password1': 'abc123',\n        'new_password2': 'abc123',\n    }\n    form = PasswordChangeForm(user, data)\n    self.assertFalse(form.is_valid())\n    self.assertEqual(form[\"old_password\"].errors, [Field.default_error_messages['required']])\n", "def test_empty_username(self):\n    data = {'username': '', 'password1': 'password123', 'password2': 'password123'}\n    form = UserCreationForm(data)\n    required_error = [str(Field.default_error_messages['required'])]\n    self.assertFalse(form.is_valid())\n    self.assertEqual(form['username'].errors, required_error)\n", "def test_password_help_text_translation(self):\n    french_help_texts = [\n        'Votre mot de passe doit contenir au moins 8 caract\u00e8res.',\n        'Votre mot de passe ne peut pas \u00eatre tout en majuscules.',\n        'Votre mot de passe ne peut pas \u00eatre tout en minuscules.',\n        'Votre mot de passe ne peut pas \u00eatre un mot commun.',\n        'Votre mot de passe ne peut pas \u00eatre enti\u00e8rement num\u00e9rique.',\n    ]\n    form = AdminPasswordChangeForm(self.u1)\n    with translation.override('fr'):\n        html = form.as_p()\n        for french_text in french_help_texts:\n            self.assertIn(french_text, html)\n", "def test_password_help_text_translation(self):\n    french_help_text = 'Votre mot de passe ne peut pas \u0102\u0218tre trop semblable aux autres informations personnelles.'\n    form = AdminPasswordChangeForm(self.u1)\n    with translation.override('fr'):\n        html = form.as_p()\n        self.assertIn(french_help_text, html)\n"], "sample_79": ["def test_concat_index_as_dim(self):\n    foo = DataArray([1, 2], coords=[(\"x\", [1, 2])])\n    bar = DataArray([3, 4], coords=[(\"x\", [3, 4])])\n    dim = DataArray([5, 6], coords=[(\"z\", [5, 6])])\n    expected = DataArray([1, 2, 3, 4], dims=[\"z\"], coords={\"x\": [1, 2, 3, 4], \"z\": [5, 6]})\n    actual = concat((foo, bar), dim=dim)\n    assert_identical(actual, expected)\n", "def test_concat_join_kwarg_with_new_dimension(self):\n    ds1 = Dataset({\"a\": ((\"x\", \"y\"), [[0]])}, coords={\"x\": [0], \"y\": [0]})\n    ds2 = Dataset({\"a\": ((\"x\", \"y\"), [[0]])}, coords={\"x\": [1], \"y\": [0.0001]})\n\n    expected = {}\n    expected[\"override\"] = Dataset(\n        {\"a\": ((\"z\", \"x\", \"y\"), np.array([[[0]], [[0]]]))},\n        coords={\"z\": [0, 1], \"x\": [0, 1], \"y\": [0, 0.0001]},\n    )\n\n    for join in expected:\n        actual = concat([ds1, ds2], join=join, dim=\"z\")\n        assert_equal(actual, expected[join])\n", "def test_concat_dim_not_in_all_datasets(self):\n    # Test concatenation when the dimension is not present in all datasets\n    ds1 = Dataset({\"foo\": (\"x\", np.random.randn(10))}, {\"x\": np.arange(10)})\n    ds2 = Dataset({\"foo\": np.random.randn(10)}, {})\n    with pytest.raises(ValueError, match=\"'x' is not present in all datasets.\"):\n        concat([ds1, ds2], dim=\"x\")\n", "def test_concat_positions(self):\n    # Test the positions argument of concat\n    ds1 = Dataset({\"foo\": ((\"x\", \"y\"), [[1, 2], [3, 4]])}, coords={\"x\": [0, 1], \"y\": [0, 1]})\n    ds2 = Dataset({\"foo\": ((\"x\", \"y\"), [[5, 6], [7, 8]])}, coords={\"x\": [2, 3], \"y\": [0, 1]})\n    expected = Dataset(\n        {\"foo\": ((\"z\", \"x\", \"y\"), [[[1, 2], [3, 4]], [[5, 6], [7, 8]]])},\n        {\"x\": [0, 1, 2, 3], \"y\": [0, 1], \"z\": [0, 1]},\n    )\n    actual = concat([ds1, ds2], dim=\"z\", positions=[[0, 1], [2, 3]])\n    assert_identical(expected, actual)\n", "def test_concat_positions(self):\n    ds1 = Dataset({\"a\": (\"x\", [1, 2])}, {\"x\": [0, 1]})\n    ds2 = Dataset({\"a\": (\"x\", [3, 4])}, {\"x\": [2, 3]})\n    expected = Dataset({\"a\": (\"z\", [1, 2, 3, 4])}, {\"x\": (\"z\", [0, 1, 2, 3]), \"z\": [0, 1, 2, 3]})\n    actual = concat([ds1, ds2], dim=\"z\", positions=[[0, 1], [2, 3]])\n    assert_identical(expected, actual)\n"], "sample_135": ["def test_is_comparable():\n    from sympy import exp_polar\n    assert (I*exp_polar(I*pi/2)).is_comparable is True\n    assert (I*exp_polar(I*pi*2)).is_comparable is False\n\n    e = 2**pi*(1 + 2**pi)\n    dif = e - e.expand()\n    assert dif.is_comparable is False\n    assert dif.n(2)._prec == 1\n", "def test_assumptions0():\n    x = Symbol(\"x\", positive=True)\n    assert x.assumptions0 == {\n        'commutative': True,\n        'complex': True,\n        'extended_negative': False,\n        'extended_nonnegative': True,\n        'extended_nonpositive': False,\n        'extended_nonzero': True,\n        'extended_positive': True,\n        'extended_real': True,\n        'finite': True,\n        'hermitian': True,\n        'imaginary': False,\n        'infinite': False,\n        'negative': False,\n        'nonnegative': True,\n        'nonpositive': False,\n        'nonzero': True,\n        'positive': True,\n        'real': True,\n        'zero': False\n    }\n\n    y = Symbol(\"y\")\n    assert y.assumptions0 == {'commutative': True}\n", "def test_is_hypergeometric():\n    from sympy import hyper\n    assert hyper([1, 2], [3], x).is_hypergeometric(1) is True\n    assert hyper([1, 2], [3], x).is_hypergeometric(2) is False\n", "def test_canonical_variables_with_bound_symbol():\n    u, v, x, y, z, _0, _1 = symbols('u v x y z _0 _1')\n    assert Lambda(u, x + u).canonical_variables == {u: _0}\n    assert Lambda(u, x + u).as_dummy() == Lambda(_0, x + _0)\n", "def test_count_ops():\n    x, y, z = symbols('x y z')\n    expr = (x + y)*z\n    assert expr.count_ops() == 3\n    assert expr.count_ops(visual=True) == 4\n"], "sample_159": ["def test_prefix_combination():\n    k = PREFIXES['k']\n    m = PREFIXES['m']\n    Ki = BIN_PREFIXES['Ki']\n\n    assert k * Ki == 1024\n    assert Ki * m == Rational(1, 1024)\n", "def test_prefix_combination():\n    assert kilo * mega == PREFIXES['T']\n    assert mega / kilo == PREFIXES['M']\n    assert kibi * mebi == PREFIXES['Gi']\n    assert mebi / kibi == PREFIXES['Mi']\n", "def test_prefix_multiplication():\n    assert kilo * kibi == Prefix('kibio', 'Yk', 13, 2)\n    assert kibi * kilo == Prefix('kibikilo', 'Gi', 12, 2)\n", "def test_prefix_multiplication():\n    k = PREFIXES['k']\n    M = PREFIXES['M']\n    Gi = BIN_PREFIXES['Gi']\n\n    assert k * M == M**2\n    assert k * Gi == kibi\n    assert M * Gi == M * kilo\n", "def test_combine_prefixes():\n    m = PREFIXES['m']\n    k = PREFIXES['k']\n    M = PREFIXES['M']\n\n    assert m * m * m == k\n    assert k * k * k == M\n    assert m / m == S.One\n    assert k / k == m\n    assert M / m == k\n"], "sample_30": ["def test_inline_formset_error_message(self):\n    self.admin_login(username='super', password='secret')\n    self.selenium.get(self.live_server_url + reverse('admin:admin_inlines_holder5_add'))\n    stacked_inline_formset_selector = 'div#inner5stacked_set-group fieldset.module.collapse'\n    tabular_inline_formset_selector = 'div#inner5tabular_set-group fieldset.module.collapse'\n    show_links = self.selenium.find_elements_by_link_text('SHOW')\n    test_fields = ['#id_inner5stacked_set-0-dummy', '#id_inner5tabular_set-0-dummy']\n    for show_index, field_name in enumerate(test_fields):\n        show_links[show_index].click()\n        self.wait_until_visible(field_name)\n        self.selenium.find_element_by_id(field_name[1:]).send_keys(1)\n    self.selenium.find_element_by_xpath('//input[@value=\"Save\"]').click()\n    self.assertEqual(\n        len(self.selenium.find_elements_by_css_selector(stacked_inline_formset_selector + ' .errors li')), 1\n    )\n    self.assertEqual(\n        len(self.selenium.find_elements_by_css_selector(tabular_inline_formset_selector + ' .errors li')), 1\n    )\n    self.assertEqual(\n        self.selenium.find_element_by_css_selector(stacked_inline_formset_selector + ' .errors li').text,\n        'This field is required.'\n    )\n    self.assertEqual(\n        self.selenium.find_element_by_css_selector(tabular_inline_formset_selector + ' .errors li').text,\n        'This field is required.'\n    )\n", "def test_inline_editable_pk_min_num(self):\n    response = self.client.get(reverse('admin:admin_inlines_author_add'))\n    self.assertContains(\n        response,\n        '<input type=\"hidden\" name=\"editablepkbook_set-MIN_NUM_FORMS\" value=\"1\" id=\"id_editablepkbook_set-MIN_NUM_FORMS\">',\n        html=True, count=2\n    )\n    self.assertContains(\n        response,\n        '<input type=\"hidden\" name=\"editablepkbookchild_set-MIN_NUM_FORMS\" value=\"1\" id=\"id_editablepkbookchild_set-MIN_NUM_FORMS\">',\n        html=True, count=2\n    )\n", "def test_non_editable_stacked_inline_label(self):\n    \"\"\"Bug #13174.\"\"\"\n    holder = Holder.objects.create(dummy=42)\n    Inner.objects.create(holder=holder, dummy=42, readonly='')\n    response = self.client.get(\n        reverse('admin:admin_inlines_holder_change', args=(holder.id,))\n    )\n    self.assertContains(response, '<label>Inner readonly label:</label>')\n", "def test_inline_collapsed_add_view(self):\n    \"\"\"\n    Inline collapsible sections are collapsed by default in the add view.\n    \"\"\"\n    self.admin_login(username='super', password='secret')\n    self.selenium.get(self.live_server_url + reverse('admin:admin_inlines_holder_add'))\n    inline_id = '#inner_set-group'\n    self.assertEqual(len(self.selenium.find_elements_by_css_selector('%s.collapsed' % inline_id)), 1)\n", "def test_inline_with_modeladmin_form(self):\n    \"\"\"\n    Inline models can have a form specified in the ModelAdmin.\n    \"\"\"\n    class CustomChildModelInline(TabularInline):\n        model = SomeChildModel\n        form = SomeChildModelForm\n\n    modeladmin = ModelAdmin(SomeParentModel, admin_site)\n    modeladmin.inlines = [CustomChildModelInline]\n    request = self.factory.get(reverse('admin:admin_inlines_someparentmodel_add'))\n    request.user = User(username='super', is_superuser=True)\n    response = modeladmin.changeform_view(request)\n    self.assertContains(response, '<th class=\"column-name required\">New label</th>', html=True)\n"], "sample_154": ["def test_cupy_matmul():\n    if not cupy:\n        skip(\"CuPy not installed\")\n\n    xmat = Matrix([[x, y], [z, 1+z]])\n    ymat = Matrix([[x**2], [Abs(x)]])\n    mat_func = lambdify((x, y, z), xmat*ymat, modules=\"cupy\")\n    assert cupy.allclose(mat_func(0.5, 3, 4), cupy.array([[1.625], [3.5]]))\n    assert cupy.allclose(mat_func(-0.5, 3, 4), cupy.array([[1.375], [3.5]]))\n    # Multiple matrices chained together in multiplication\n    f = lambdify((x, y, z), xmat*xmat*xmat, modules=\"cupy\")\n    assert cupy.allclose(f(0.5, 3, 4), cupy.array([[72.125, 119.25], [159, 251]]))\n", "def test_lambdify_abs():\n    f = lambdify(x, Abs(x), \"numpy\")\n    assert f(-1) == 1\n    assert f(1) == 1\n    assert f(-2) == 2\n    assert f(2) == 2\n    assert f(-2.5) == 2.5\n    assert f(2.5) == 2.5\n", "def test_scipy_special_bessel():\n    if not scipy:\n        skip(\"scipy not installed\")\n\n    fns = [besseli, besselj, besselk, bessely]\n    for func in fns:\n        expr = func(x, y)\n        args = (x, y)\n        num_args = (2.3, 1.2)\n        f = lambdify(args, expr, modules='scipy')\n        result = f(*num_args)\n        reference = expr.subs(dict(zip(args, num_args))).evalf()\n        assert numpy.allclose(result, float(reference))\n", "def test_lambdify_cse_with_numpy():\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    case = Case(args=(x, y), exprs=(x*x + y, x*y + y*y), num_args=(2.0, 3.0), requires_numpy=True)\n    f = case.lambdify(cse=True)\n    result = f(*case.num_args)\n    case.assertAllClose(result)\n", "def test_lambdify_nested_functions():\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    f = implemented_function('f', lambda x: numpy.sin(x))\n    g = implemented_function('g', lambda x, y: numpy.power(x, y))\n    expr = g(f(x), y)\n    func = lambdify(x, expr, modules='numpy')\n\n    assert numpy.allclose(func(numpy.pi/2), numpy.power(1, y))\n"], "sample_18": ["def test_foreign_object_to_unique_field_with_multiple_unique_constraints(self):\n    class Person(models.Model):\n        country_id = models.IntegerField()\n        city_id = models.IntegerField()\n\n        class Meta:\n            constraints = [\n                models.UniqueConstraint(\n                    fields=['country_id'],\n                    name='tfotpuf_unique_country',\n                ),\n                models.UniqueConstraint(\n                    fields=['city_id'],\n                    name='tfotpuf_unique_city',\n                ),\n            ]\n\n    class MMembership(models.Model):\n        person_country_id = models.IntegerField()\n        person_city_id = models.IntegerField()\n        person = models.ForeignObject(\n            Person,\n            on_delete=models.CASCADE,\n            from_fields=['person_country_id', 'person_city_id'],\n            to_fields=['country_id', 'city_id'],\n        )\n\n    field = MMembership._meta.get_field('person')\n    self.assertEqual(field.check(), [])\n", "def test_foreign_object_to_non_unique_superset_fields(self):\n    class Person(models.Model):\n        country_id = models.IntegerField()\n        city_id = models.IntegerField()\n        postal_code = models.CharField(max_length=10)\n\n        class Meta:\n            unique_together = (('country_id', 'city_id', 'postal_code'),)\n\n    class MMembership(models.Model):\n        person_country_id = models.IntegerField()\n        person_city_id = models.IntegerField()\n        person = models.ForeignObject(\n            Person,\n            on_delete=models.CASCADE,\n            from_fields=('person_country_id', 'person_city_id'),\n            to_fields=('country_id', 'city_id'),\n        )\n\n    field = MMembership._meta.get_field('person')\n    self.assertEqual(field.check(), [\n        Error(\n            \"No subset of the fields 'country_id', 'city_id', 'postal_code' on model 'Person' is unique.\",\n            hint=(\n                'Mark a single field as unique=True or add a set of '\n                'fields to a unique constraint (via unique_together or a '\n                'UniqueConstraint (without condition) in the model '\n                'Meta.constraints).'\n            ),\n            obj=field,\n            id='fields.E310',\n        ),\n    ])\n", "def test_m2m_through_fields_with_intermediary_model(self):\n    class Fan(models.Model):\n        pass\n\n    class Event(models.Model):\n        invitees = models.ManyToManyField(\n            Fan,\n            through='Invitation',\n            through_fields=('event', 'invitee'),\n        )\n\n    class Invitation(models.Model):\n        event = models.ForeignKey(Event, models.CASCADE)\n        invitee = models.ForeignKey(Fan, models.CASCADE)\n        inviter = models.ForeignKey(Fan, models.CASCADE, related_name='+')\n\n    field = Event._meta.get_field('invitees')\n    self.assertEqual(field.check(from_model=Event), [])\n", "def test_m2m_through_fields_to_fields(self):\n    class Person(models.Model):\n        a = models.PositiveIntegerField()\n        b = models.PositiveIntegerField()\n\n    class Group(models.Model):\n        members = models.ManyToManyField(Person, through='Membership', through_fields=('person_a', 'person_b'))\n\n    class Membership(models.Model):\n        person_a = models.IntegerField()\n        person_b = models.IntegerField()\n        group = models.ForeignKey(Group, models.CASCADE)\n        person = models.ForeignObject(\n            Person,\n            on_delete=models.CASCADE,\n            from_fields=('person_a', 'person_b'),\n            to_fields=('a', 'b'),\n        )\n\n    field = Group._meta.get_field('members')\n    self.assertEqual(field.check(from_model=Group), [\n        Error(\n            \"The to_field 'a' doesn't exist on the related model 'invalid_models_tests.Person'.\",\n            obj=field,\n            id='fields.E312',\n        ),\n        Error(\n            \"The to_field 'b' doesn't exist on the related model 'invalid_models_tests.Person'.\",\n            obj=field,\n            id='fields.E312',\n        ),\n    ])\n", "def test_foreign_object_to_self_referential_field(self):\n    class SelfReferentialModel(models.Model):\n        parent = models.ForeignKey('self', models.SET_NULL, null=True, related_name='children')\n        value = models.CharField(max_length=255)\n\n    class RelatedModel(models.Model):\n        parent = models.ForeignObject(\n            SelfReferentialModel,\n            on_delete=models.SET_NULL,\n            from_fields=['parent'],\n            to_fields=['parent'],\n            related_name='related_objects',\n        )\n\n    field = RelatedModel._meta.get_field('parent')\n    self.assertEqual(field.check(from_model=RelatedModel), [])\n"], "sample_58": ["def test_default_dbname(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env(\n            {\n                \"USER\": \"someuser\",\n                \"PASSWORD\": \"somepassword\",\n                \"HOST\": \"somehost\",\n                \"PORT\": \"444\",\n            }\n        ),\n        (\n            [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"],\n            {\"PGPASSWORD\": \"somepassword\"},\n        ),\n    )\n", "def test_no_dbname_service(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env(\n            {\n                \"USER\": \"someuser\",\n                \"HOST\": \"somehost\",\n                \"PORT\": \"444\",\n            }\n        ),\n        (\n            [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"postgres\"],\n            None,\n        ),\n    )\n", "def test_empty_settings(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env({}),\n        (\n            [\"psql\", \"postgres\"],\n            None,\n        ),\n    )\n", "def test_connection_timeout(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env(\n            {\n                \"NAME\": \"dbname\",\n                \"USER\": \"someuser\",\n                \"PASSWORD\": \"somepassword\",\n                \"HOST\": \"somehost\",\n                \"PORT\": \"444\",\n                \"OPTIONS\": {\n                    \"connect_timeout\": \"5\",\n                },\n            }\n        ),\n        (\n            [\"psql\", \"-U\", \"someuser\", \"-h\", \"somehost\", \"-p\", \"444\", \"dbname\"],\n            {\"PGCONNECT_TIMEOUT\": \"5\"},\n        ),\n    )\n", "def test_no_host(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env(\n            {\n                \"NAME\": \"dbname\",\n                \"USER\": \"someuser\",\n                \"PASSWORD\": \"somepassword\",\n                \"PORT\": \"444\",\n            }\n        ),\n        (\n            [\"psql\", \"-U\", \"someuser\", \"-p\", \"444\", \"dbname\"],\n            {\"PGPASSWORD\": \"somepassword\"},\n        ),\n    )\n"], "sample_73": ["def test_offsetimage_properties():\n    data = np.random.rand(10, 10)\n    oi = OffsetImage(data)\n    assert_allclose(oi.get_data(), data)\n    assert oi.get_zoom() == 1\n\n    new_data = np.random.rand(20, 20)\n    oi.set_data(new_data)\n    oi.set_zoom(2)\n    assert_allclose(oi.get_data(), new_data)\n    assert oi.get_zoom() == 2\n", "def test_anchoredtext_vertical_alignment():\n    fig, ax = plt.subplots()\n\n    text0 = AnchoredText(\"test\", loc=\"lower left\", pad=0.2, prop={\"va\": \"bottom\"})\n    ax.add_artist(text0)\n    text1 = AnchoredText(\"test\", loc=\"center left\", pad=0.2, prop={\"va\": \"center\"})\n    ax.add_artist(text1)\n    text2 = AnchoredText(\"test\", loc=\"upper left\", pad=0.2, prop={\"va\": \"top\"})\n    ax.add_artist(text2)\n", "def test_offsetimage_set_data(fig_test, fig_ref):\n    ax_ref = fig_ref.add_subplot()\n    data_ref = np.random.rand(10, 10)\n    oi_ref = OffsetImage(data_ref)\n    ab_ref = AnnotationBbox(oi_ref, (0.5, 0.5))\n    ax_ref.add_artist(ab_ref)\n\n    ax_test = fig_test.add_subplot()\n    data_test = np.random.rand(10, 10)\n    oi_test = OffsetImage(data_test)\n    ab_test = AnnotationBbox(oi_test, (0.5, 0.5))\n    ax_test.add_artist(ab_test)\n\n    # Change the data of OffsetImage\n    new_data = np.random.rand(10, 10)\n    oi_test.set_data(new_data)\n", "def test_offsetbox_multilinebaseline():\n    # - create a plot\n    # - put an AnchoredOffsetbox with a TextArea child\n    #   at the center of the axes\n    # - set the text to a multiline string with different line heights\n    # - test multilinebaseline=True and False\n    # - see that the text is aligned differently with each setting\n    fig, ax = plt.subplots()\n    text = \"Line 1\\nLine 2\\nLine 3\"\n    ta = TextArea(text, textprops={'fontsize': 12}, multilinebaseline=True)\n    anchored_box1 = AnchoredOffsetbox(loc='center', child=ta, pad=0.5)\n    ax.add_artist(anchored_box1)\n\n    ta = TextArea(text, textprops={'fontsize': 12}, multilinebaseline=False)\n    anchored_box2 = AnchoredOffsetbox(loc='lower center', child=ta, pad=0.5)\n    ax.add_artist(anchored_box2)\n\n    fig.tight_layout()\n", "def test_paddedbox_multiline():\n    fig, ax = plt.subplots()\n\n    ta = TextArea(\"foo\\nbar\", multilinebaseline=True)\n    pb = PaddedBox(ta, pad=5, patch_attrs={'facecolor': 'r'}, draw_frame=True)\n    ab = AnchoredOffsetbox('center', child=pb)\n    ax.add_artist(ab)\n\n    ta = TextArea(\"foo\\nbar\\nbaz\", multilinebaseline=True)\n    pb = PaddedBox(ta, pad=10, patch_attrs={'facecolor': 'b'})\n    ab = AnchoredOffsetbox('lower left', child=pb)\n    ax.add_artist(ab)\n\n    ta = TextArea(\"foo\", multilinebaseline=False)\n    pb = PaddedBox(ta, pad=15, draw_frame=True)\n    ab = AnchoredOffsetbox('upper right', child=pb)\n    ax.add_artist(ab)\n"], "sample_121": ["def test_commutes_with():\n    p = Permutation([1, 5, 2, 0, 3, 6, 4])\n    q = Permutation([[1, 2, 3, 5, 6], [0, 4]])\n    assert p.commutes_with(q) is False\n    assert q.commutes_with(p) is False\n    p = Permutation([0, 1, 2, 3])\n    q = Permutation([3, 2, 1, 0])\n    assert p.commutes_with(q) is True\n    assert q.commutes_with(p) is True\n", "def test_conjugate():\n    p = Permutation([1, 2, 9])\n    q = Permutation([6, 9, 8])\n    c = p ^ q\n    assert c == ~q * p * q and p == q * c * ~q\n    r = Permutation(9)(4, 6, 8)\n    assert p ^ q ^ r == q ^ (p * r)\n    assert [i ^ p == p(i) for i in range(p.size)]\n    assert q ^ r * p ^ r == q ^ (r * p) ^ r\n", "def test_permutation_properties():\n    p = Permutation([0, 2, 1, 3])\n    assert p.is_odd\n    assert not p.is_even\n    assert not p.is_Identity\n    assert not p.is_Singleton\n    assert not p.is_Empty\n    assert p.cycles == 2\n    assert p.length() == 2\n    assert p.max() == 2\n    assert p.min() == 1\n    assert p.ascents() == [0]\n    assert p.descents() == [2]\n    assert p.inversions() == 1\n    assert p.signature() == -1\n    assert p.order() == 2\n    assert p.runs() == [[0, 2], [1], [3]]\n    assert p.index() == 1\n    assert p.cycle_structure == {2: 1, 1: 2}\n    q = Permutation([3, 2, 1, 0])\n    assert q.get_precedence_distance(p) == 3\n    assert q.get_adjacency_distance(p) == 4\n    assert q.get_positional_distance(p) == 8\n", "def test_commutes_with():\n    p = Permutation([1, 5, 2, 0, 3, 6, 4])\n    q = Permutation([[1, 2, 3, 5, 6], [0, 4]])\n    assert p.commutes_with(q) == False\n    assert q.commutes_with(p) == False\n    iden = Permutation([0, 1, 2, 3, 4, 5, 6])\n    assert p.commutes_with(iden) == True\n    assert q.commutes_with(iden) == True\n    assert iden.commutes_with(p) == True\n    assert iden.commutes_with(q) == True\n    r = Permutation([3, 2, 0, 1, 4, 6, 5])\n    assert p.commutes_with(r) == False\n    assert r.commutes_with(p) == False\n", "def test_printing_not_cyclic():\n    Permutation.print_cyclic = False\n    p1 = Permutation([0, 2, 1])\n    assert repr(p1) == 'Permutation([0, 2, 1])'\n    assert str(p1) == 'Permutation([0, 2, 1])'\n    p2 = Permutation()\n    assert repr(p2) == 'Permutation([])'\n    assert str(p2) == 'Permutation([])'\n    p3 = Permutation([1, 2, 0, 3])\n    assert repr(p3) == 'Permutation([1, 2, 0, 3])'\n    assert str(p3) == 'Permutation([1, 2, 0, 3])'\n"], "sample_158": ["def test_quantity_conversion():\n    from sympy.physics.units import meter, centimeter, inch\n    assert meter.convert_to(centimeter) == 100*centimeter\n    assert inch.convert_to(centimeter) == 2.54*centimeter\n    assert inch.convert_to(meter) == 0.0254*meter\n", "def test_physical_constant_property():\n    assert not meter.is_physical_constant\n    assert not joule.is_physical_constant\n    assert not day.is_physical_constant\n    assert not second.is_physical_constant\n    assert not volt.is_physical_constant\n    assert not ohm.is_physical_constant\n    assert not centimeter.is_physical_constant\n    assert not kilometer.is_physical_constant\n    assert not kilogram.is_physical_constant\n    assert not pebibyte.is_physical_constant\n    assert elementary_charge.is_physical_constant\n    assert speed_of_light.is_physical_constant\n", "def test_physical_constant_property():\n    assert not meter.is_physical_constant\n    assert not joule.is_physical_constant\n    assert not day.is_physical_constant\n    assert not second.is_physical_constant\n    assert not volt.is_physical_constant\n    assert not ohm.is_physical_constant\n    assert not centimeter.is_physical_constant\n    assert not kilometer.is_physical_constant\n    assert not kilogram.is_physical_constant\n    assert not pebibyte.is_physical_constant\n    assert elementary_charge.is_physical_constant\n    assert speed_of_light.is_physical_constant\n    assert molar_gas_constant.is_physical_constant\n    assert vacuum_permittivity.is_physical_constant\n    assert gravitational_constant.is_physical_constant\n", "def test_derived_units():\n    from sympy.physics.units import length, time, speed, meter, second\n\n    derived_units = SI.derived_units\n    assert isinstance(derived_units, dict)\n    assert length / time in derived_units\n    assert derived_units[length / time] == meter / second\n\n    # Test setting a new derived unit\n    SI.set_quantity_dimension(speed, length / time)\n    SI.set_quantity_scale_factor(speed, 1 * meter / second)\n    derived_units = SI.derived_units\n    assert speed in derived_units\n    assert derived_units[speed] == meter / second\n", "def test_issue_24212():\n    from sympy.physics.units import force, mass, acceleration, newton, kilogram, meter, second\n    F1 = Quantity('F1')\n    SI.set_quantity_dimension(F1, force)\n    SI.set_quantity_scale_factor(F1, 1 * newton)\n    m1 = Quantity('m1')\n    SI.set_quantity_dimension(m1, mass)\n    SI.set_quantity_scale_factor(m1, 1 * kilogram)\n\n    expr = F1 / m1\n    assert SI.get_dimensional_expr(expr) == acceleration.name\n    assert SI._collect_factor_and_dimension(expr) == (1, acceleration)\n\n    expr = F1 * meter / m1\n    assert SI.get_dimensional_expr(expr) == (acceleration * length).name\n    assert SI._collect_factor_and_dimension(expr) == (1, acceleration * length)\n"], "sample_59": ["def test_formset_with_deletion_custom_renderer(self):\n    from django.forms.renderers import Jinja2\n\n    class CustomDeletionFormSet(BaseFormSet):\n        deletion_widget = HiddenInput(attrs={\"class\": \"custom-deletion\"})\n\n    CustomDeletionArticleFormSet = formset_factory(\n        ArticleForm,\n        formset=CustomDeletionFormSet,\n        can_delete=True,\n        renderer=Jinja2(),\n    )\n    formset = CustomDeletionArticleFormSet(auto_id=False)\n    self.assertHTMLEqual(\n        \"\\n\".join([form.as_ul() for form in formset.forms]),\n        (\n            '<li>Title: <input type=\"text\" name=\"form-0-title\"></li>'\n            '<li>Pub date: <input type=\"text\" name=\"form-0-pub_date\">'\n            '<input class=\"custom-deletion\" type=\"hidden\" name=\"form-0-DELETE\"></li>'\n        ),\n    )\n", "def test_formset_get_default_prefix(self):\n    \"\"\"\n    A custom formset can define its own default prefix.\n    \"\"\"\n\n    class CustomPrefixFormSet(BaseFormSet):\n        @classmethod\n            return \"custom\"\n\n    CustomPrefixChoiceFormSet = formset_factory(Choice, formset=CustomPrefixFormSet)\n    formset = CustomPrefixChoiceFormSet()\n    self.assertEqual(formset.management_form.prefix, \"custom\")\n", "def test_formset_custom_default_error_message(self):\n    data = {\n        \"choices-TOTAL_FORMS\": \"1\",\n        \"choices-INITIAL_FORMS\": \"0\",\n        \"choices-0-choice\": \"Calexico\",\n        \"choices-0-votes\": \"\",\n    }\n    ChoiceFormSet = formset_factory(Choice)\n    formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\", error_messages={\"required\": \"This field is mandatory.\"})\n    self.assertFalse(formset.is_valid())\n    self.assertEqual(\n        formset.errors,\n        [{\"votes\": [\"This field is mandatory.\"]}],\n    )\n", "def test_custom_get_ordering_widget(self):\n    \"\"\"\n    A custom get_ordering_widget() method on a formset class is used when\n    rendering the formset.\n    \"\"\"\n\n    class CustomOrderingWidgetFormSet(BaseFormSet):\n            return HiddenInput(attrs={\"class\": \"custom-ordering\"})\n\n    ArticleFormSet = formset_factory(ArticleForm, formset=CustomOrderingWidgetFormSet, can_order=True)\n    formset = ArticleFormSet(auto_id=False)\n    self.assertHTMLEqual(\n        \"\\n\".join(form.as_ul() for form in formset.forms),\n        (\n            '<li>Title: <input type=\"text\" name=\"form-0-title\"></li>'\n            '<li>Pub date: <input type=\"text\" name=\"form-0-pub_date\">'\n            '<input class=\"custom-ordering\" type=\"hidden\" name=\"form-0-ORDER\"></li>'\n        ),\n    )\n", "    def test_custom_renderer_used_for_non_form_errors(self):\n        from django.forms.renderers import Jinja2\n\n        renderer = Jinja2()\n        data = {\n            \"choices-TOTAL_FORMS\": \"2\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Zero\",\n            \"choices-0-votes\": \"\",\n            \"choices-1-choice\": \"One\",\n            \"choices-1-votes\": \"\",\n        }\n        ChoiceFormSet = formset_factory(Choice, renderer=renderer)\n        formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertIs(formset.is_valid(), False)\n        self.assertEqual(formset.non_form_errors().renderer, renderer)\n"], "sample_60": ["def test_serialize_complex_serializer(self):\n    class Complex:\n            self.real = real\n            self.imag = imag\n\n    BaseSerializer.register(Complex, ComplexSerializer)\n    self.assertSerializedEqual(Complex(1, 2))\n    self.assertSerializedResultEqual(Complex(3, 4), (\"complex((3, 4))\", set()))\n", "    def test_complex_serializer(self):\n        complex_num = complex(2, 3)\n        BaseSerializer.register(complex, ComplexSerializer)\n        self.assertSerializedEqual(complex_num)\n        BaseSerializer.unregister(complex)\n", "def test_complex_serializer(self):\n    class Complex(complex):\n        pass\n\n    BaseSerializer.register(Complex, ComplexSerializer)\n    self.assertSerializedResultEqual(\n        Complex(1 + 2j), (\"complex((1+2j))\", set())\n    )\n    BaseSerializer.unregister(Complex)\n", "def test_register_complex_serializer(self):\n    class Complex:\n            self.real = real\n            self.imag = imag\n\n    BaseSerializer.register(Complex, ComplexSerializer)\n    self.assertSerializedEqual(Complex(1, 2))\n    self.assertSerializedResultEqual(Complex(3, 4), (\"complex((3, 4))\", {}))\n", "def test_registered_serializer(self):\n    class CustomType:\n        pass\n\n    BaseSerializer.register(CustomType, ComplexSerializer)\n    self.assertSerializedResultEqual(CustomType(), (\"complex(<migrations.test_writer.CustomType object at ...>)\", {}))\n    BaseSerializer.unregister(CustomType)\n"], "sample_102": ["def test_iforest_oob_score():\n    \"\"\"Test OOB score is not supported by IsolationForest.\"\"\"\n    X = iris.data\n    clf = IsolationForest()\n    with pytest.raises(NotImplementedError, match=\"OOB score not supported by iforest\"):\n        clf.fit(X[:100], oob_score=True)\n", "def test_iforest_parallel_execution():\n    \"\"\"Test the execution of Isolation Forest in parallel.\"\"\"\n    rng = check_random_state(0)\n\n    X_train, X_test, y_train, y_test = train_test_split(boston.data,\n                                                        boston.target,\n                                                        random_state=rng)\n\n    ensemble_parallel = IsolationForest(n_jobs=2,\n                                       random_state=0).fit(X_train)\n\n    ensemble_single = IsolationForest(n_jobs=1,\n                                     random_state=0).fit(X_train)\n\n    y_parallel = ensemble_parallel.predict(X_test)\n    y_single = ensemble_single.predict(X_test)\n    assert_array_equal(y_parallel, y_single)\n", "def test_iforest_with_sparse_csr_input():\n    \"\"\"Test Isolation Forest with sparse CSR input.\"\"\"\n    X = csr_matrix([[1, 1], [1, 2], [2, 1], [2, 2]])\n    clf = IsolationForest(random_state=rng).fit(X)\n    y_pred = clf.predict(X)\n    assert len(y_pred) == X.shape[0]\n    assert set(y_pred) == {-1, 1}\n", "def test_iforest_contamination_input_check():\n    \"\"\"Test input validation for contamination parameter.\"\"\"\n    X = iris.data\n\n    # Test contamination\n    assert_raises(ValueError,\n                  IsolationForest(contamination=-0.1).fit, X)\n    assert_raises(ValueError,\n                  IsolationForest(contamination=1.1).fit, X)\n    assert_raises(ValueError,\n                  IsolationForest(contamination='invalid').fit, X)\n\n    # Test behaviour='old' and contamination='auto'\n    assert_raises(ValueError,\n                  IsolationForest(behaviour='old', contamination='auto').fit, X)\n", "def test_iforest_with_sparse_input_and_max_features_1():\n    \"\"\"Test that iforest works with sparse input and max_features=1\"\"\"\n    X = csr_matrix([[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1], [6, 3], [-4, 7]])\n    clf = IsolationForest(max_features=1, random_state=rng)\n    clf.fit(X)\n    decision_func = -clf.decision_function(X)\n    pred = clf.predict(X)\n    # assert that the model is still able to detect outliers\n    assert_greater(np.min(decision_func[-2:]), np.max(decision_func[:-2]))\n    assert_array_equal(pred, 6 * [1] + 2 * [-1])\n"], "sample_109": ["def test_leave_p_out_empty_trainset():\n    cv = LeavePOut(p=2)\n    X, y = [[1]], [0]  # 1 sample\n    with pytest.raises(\n            ValueError,\n            match='Cannot perform LeavePOut with n_samples=1 and p=2'):\n        next(cv.split(X, y))\n", "def test_leave_p_out_empty_trainset():\n    cv = LeavePOut(p=2)\n    X, y = [[1]], [0]  # 1 sample\n    with pytest.raises(\n            ValueError,\n            match='Cannot perform LeavePOut with n_samples=1 and p=2'):\n        next(cv.split(X, y))\n", "def test_leave_p_out_empty_trainset():\n    cv = LeavePOut(p=1)\n    X, y = [[1]], [0]  # 1 sample\n    with pytest.raises(\n            ValueError,\n            match='Cannot perform LeavePOut with n_samples=1 and p=1'):\n        next(cv.split(X, y))\n", "def test_group_shuffle_split_empty_trainset():\n    cv = GroupShuffleSplit(test_size=.99)\n    X, y, groups = [[1], [1], [1]], [0, 0, 0], [1, 1, 1]  # 3 samples in 1 group\n    with pytest.raises(\n            ValueError,\n            match='With n_samples=3, test_size=0.99 and train_size=None, '\n            'the resulting train set will be empty'):\n        next(cv.split(X, y, groups))\n", "def test_leave_p_out_empty_trainset():\n    cv = LeavePOut(p=2)\n    X, y = [[1]], [0]  # 1 sample\n    with pytest.raises(\n            ValueError,\n            match='Cannot perform LeavePOut with n_samples=1 and p=2'):\n        next(cv.split(X, y))\n"], "sample_110": ["def test_affinity_propagation_sparse_input():\n    # Test AffinityPropagation with sparse input\n    X_sparse = csr_matrix(X)\n    af = AffinityPropagation(affinity=\"euclidean\")\n    labels_sparse = af.fit_predict(X_sparse)\n    labels_dense = af.fit_predict(X)\n    assert_array_equal(labels_sparse, labels_dense)\n", "def test_affinity_propagation_single_sample():\n    # Test AffinityPropagation with a single sample\n    X = np.array([[0, 0]])\n    af = AffinityPropagation(affinity=\"euclidean\")\n    labels = af.fit_predict(X)\n    assert_array_equal(labels, np.array([0]))\n    assert_array_equal(af.cluster_centers_, X)\n", "def test_affinity_propagation_single_sample():\n    # Test AffinityPropagation with a single sample\n    X = np.array([[0, 0]])\n    S = -euclidean_distances(X, squared=True)\n\n    # Test with preference < similarity\n    cluster_center_indices, labels = assert_warns_message(\n        UserWarning, \"mutually equal\", affinity_propagation, S, preference=-1)\n    assert_array_equal([0], cluster_center_indices)\n    assert_array_equal([0], labels)\n\n    # Test with preference > similarity\n    cluster_center_indices, labels = assert_no_warnings(\n        affinity_propagation, S, preference=1)\n    assert_array_equal([0], cluster_center_indices)\n    assert_array_equal([0], labels)\n\n    # Test with AffinityPropagation estimator\n    af = AffinityPropagation(preference=-1)\n    af.fit(X)\n    assert_array_equal([0], af.cluster_centers_indices_)\n    assert_array_equal([0], af.labels_)\n", "def test_affinity_propagation_sparse_input():\n    # Test AffinityPropagation with sparse input\n    X_sparse = csr_matrix(X)\n    af = AffinityPropagation(affinity=\"euclidean\")\n    labels_sparse = af.fit_predict(X_sparse)\n    labels = af.fit_predict(X)\n    assert_array_equal(labels, labels_sparse)\n", "def test_affinity_propagation_single_sample():\n    # Test Affinity Propagation with a single sample\n    X = np.array([[0]])\n    S = -euclidean_distances(X, squared=True)\n\n    # Setting preference > similarity\n    cluster_center_indices, labels = assert_warns_message(\n        UserWarning, \"mutually equal\", affinity_propagation, S, preference=0)\n\n    # Expect the single sample to become an exemplar\n    assert_array_equal([0], cluster_center_indices)\n    assert_array_equal([0], labels)\n\n    # Setting preference < similarity\n    cluster_center_indices, labels = assert_warns_message(\n        UserWarning, \"mutually equal\", affinity_propagation, S, preference=-1)\n\n    # Expect no clusters\n    assert_array_equal([], cluster_center_indices)\n    assert_array_equal([-1], labels)\n"], "sample_39": ["    def test_reverse_valid_patterns(self):\n        test_urls = [\n            ('lookahead-positive', {'city': 'a-city'}, '/lookahead+/a-city/'),\n            ('lookbehind-positive', {'city': 'a-city'}, '/lookbehind+/a-city/'),\n        ]\n        for name, kwargs, expected in test_urls:\n            with self.subTest(name=name, kwargs=kwargs):\n                self.assertEqual(reverse(name, kwargs=kwargs), expected)\n", "def test_view_detail_as_method_in_nested_view(self):\n    # Views which have a class name as part of their path within a nested view.\n    resolver = get_resolver('urlpatterns_reverse.nested_method_view_urls')\n    self.assertTrue(resolver._is_callback('urlpatterns_reverse.nested_method_view_urls.NestedViewContainer.ViewContainer.method_view'))\n    self.assertTrue(resolver._is_callback('urlpatterns_reverse.nested_method_view_urls.NestedViewContainer.ViewContainer.classmethod_view'))\n", "def test_include_patterns(self):\n    patterns = include(self.url_patterns)\n    self.assertIsInstance(patterns, tuple)\n    self.assertEqual(len(patterns), 3)\n    self.assertEqual(patterns[0], self.url_patterns)\n    self.assertIsNone(patterns[1])\n    self.assertIsNone(patterns[2])\n", "    def test_urlpattern_check(self):\n        # Test the check() method of URLPattern\n        pattern = URLPattern(RegexPattern(r'^test/(?P<arg1>[0-9]+)/(?P<arg2>[0-9]+)/$'), views.empty_view, name='test-view')\n        warnings = pattern.check()\n        self.assertEqual(warnings, [])\n\n        # Test the check() method of URLPattern with pattern name containing ':'\n        pattern = URLPattern(RegexPattern(r'^test/(?P<arg1>[0-9]+)/(?P<arg2>[0-9]+)/$'), views.empty_view, name='test:view')\n        warnings = pattern.check()\n        self.assertEqual(len(warnings), 1)\n        self.assertEqual(warnings[0].id, \"urls.W003\")\n\n        # Test the check() method of URLPattern with pattern starting with a '/'\n        pattern = URLPattern(RegexPattern(r'^/test/(?P<arg1>[0-9]+)/(?P<arg2>[0-9]+)/$'), views.empty_view, name='test-view')\n        warnings = pattern.check()\n        self.assertEqual(len(warnings), 1)\n        self.assertEqual(warnings[0].id, \"urls.W002\")\n", "    def test_resolver_match_route(self):\n        test_urls = [\n            ('/no_kwargs/42/37/', '/no_kwargs/([0-9]+)/([0-9]+)/'),\n            ('/included/normal/42/37/', '/included/normal/([0-9]+)/([0-9]+)/'),\n            ('/included/view_class/42/37/', '/included/view_class/([0-9]+)/([0-9]+)/'),\n            ('/test1/inner/42/37/', '/test1/inner/([0-9]+)/([0-9]+)/'),\n            ('/included/test3/inner/42/37/', '/included/test3/inner/([0-9]+)/([0-9]+)/'),\n            ('/ns-included1/normal/42/37/', '/ns-included1/normal/([0-9]+)/([0-9]+)/'),\n            ('/ns-included1/test3/inner/42/37/', '/ns-included1/test3/inner/([0-9]+)/([0-9]+)/'),\n        ]\n        for path, expected_route in test_urls:\n            with self.subTest(path=path):\n                match = resolve(path)\n                self.assertEqual(match.route, expected_route)\n"]}, "raw_scored_generations": {"sample_3": [false, false, false, false, false], "sample_2": [false, false, true, false, true], "sample_1": [false, false, false, false, false], "sample_0": [false, true, true, true, true], "sample_6": [true, true, true, true, true], "sample_4": [true, true, true, true, true], "sample_5": [false, false, false, true, true], "sample_7": [true, false, true, true, false], "sample_9": [true, true, true, true, true], "sample_8": [false, true, true, false, true], "sample_10": [true, true, true, true, true], "sample_11": [true, true, true, true, true], "sample_13": [true, true, false, false, false], "sample_12": [true, true, true, true, true], "sample_14": [true, true, true, true, false], "sample_15": [true, true, true, true, true], "sample_16": [true, true, true, true, true], "sample_17": [false, false, false, false, true], "sample_18": [true, true, true, true, true], "sample_19": [false, false, false, false, false], "sample_21": [false, true, true, true, true], "sample_20": [true, true, false, true, true], "sample_23": [true, true, true, true, true], "sample_22": [false, true, true, true, true], "sample_24": [true, false, true, false, true], "sample_25": [true, true, true, true, true], "sample_28": [false, false, false, true, true], "sample_26": [true, true, false, true, true], "sample_27": [true, true, true, true, true], "sample_29": [true, true, true, true, true], "sample_31": [true, true, true, false, true], "sample_30": [true, true, true, true, true], "sample_32": [true, true, true, true, true], "sample_33": [false, false, false, false, false], "sample_34": [true, true, false, true, true], "sample_35": [true, false, true, true, true], "sample_36": [true, true, true, true, true], "sample_37": [true, true, true, true, true], "sample_39": [true, true, true, false, false], "sample_38": [true, true, true, true, true], "sample_40": [true, true, true, true, false], "sample_42": [true, true, true, true, false], "sample_41": [false, true, true, false, true], "sample_43": [true, true, true, true, true], "sample_45": [false, false, false, false, false], "sample_44": [true, true, true, true, false], "sample_46": [false, false, false, false, false], "sample_48": [false, true, false, true, true], "sample_47": [false, true, true, true, true], "sample_50": [true, true, true, true, true], "sample_49": [true, true, true, true, true], "sample_51": [true, false, true, true, false], "sample_52": [true, false, true, true, true], "sample_53": [false, true, true, true, false], "sample_55": [true, true, false, false, true], "sample_54": [true, true, true, true, true], "sample_56": [true, false, true, false, true], "sample_58": [true, true, true, true, true], "sample_57": [true, false, true, true, false], "sample_60": [true, false, true, true, true], "sample_59": [true, false, true, false, true], "sample_61": [false, false, false, false, false], "sample_63": [true, true, false, true, true], "sample_62": [true, true, true, true, false], "sample_64": [true, true, true, true, true], "sample_66": [true, true, true, true, true], "sample_65": [true, true, true, true, true], "sample_68": [false, true, true, false, true], "sample_67": [true, false, true, true, true], "sample_69": [false, true, true, true, true], "sample_70": [false, true, false, true, false], "sample_71": [true, true, true, true, true], "sample_72": [false, true, false, false, false], "sample_73": [true, false, false, false, false], "sample_74": [true, true, false, true, false], "sample_75": [false, true, false, true, false], "sample_76": [false, false, false, false, false], "sample_77": [false, false, false, false, false], "sample_78": [true, false, false, false, true], "sample_79": [false, false, false, false, false], "sample_80": [false, false, false, false, false], "sample_82": [true, false, false, false, false], "sample_81": [false, false, false, false, false], "sample_83": [false, true, true, false, false], "sample_84": [false, false, false, false, false], "sample_85": [false, false, false, false, false], "sample_86": [false, false, false, false, false], "sample_87": [false, false, false, false, false], "sample_88": [false, false, false, false, false], "sample_89": [false, false, false, false, false], "sample_90": [false, false, false, false, false], "sample_91": [false, false, false, false, false], "sample_92": [false, false, false, false, false], "sample_93": [true, false, false, false, false], "sample_95": [false, false, false, false, false], "sample_94": [false, false, false, false, false], "sample_96": [false, false, true, false, false], "sample_97": [true, false, true, true, false], "sample_98": [false, false, false, true, false], "sample_99": [false, false, false, false, false], "sample_100": [true, true, false, true, false], "sample_101": [false, false, true, false, false], "sample_102": [false, true, false, false, false], "sample_103": [true, true, true, true, true], "sample_104": [false, false, false, false, false], "sample_105": [false, false, false, false, true], "sample_107": [true, false, false, false, true], "sample_106": [true, true, false, true, true], "sample_108": [true, false, true, false, false], "sample_109": [false, false, false, false, false], "sample_110": [true, true, false, true, false], "sample_111": [false, false, false, false, false], "sample_112": [false, true, false, true, false], "sample_113": [false, false, true, false, false], "sample_114": [false, false, false, false, false], "sample_115": [true, true, true, true, false], "sample_116": [false, false, false, false, false], "sample_117": [true, false, false, false, false], "sample_118": [false, false, false, false, false], "sample_119": [false, false, false, false, false], "sample_120": [true, false, false, false, false], "sample_121": [true, false, false, true, true], "sample_122": [true, true, true, false, false], "sample_123": [true, true, false, false, false], "sample_124": [false, false, false, false, true], "sample_125": [true, true, false, true, false], "sample_126": [true, false, false, false, false], "sample_127": [true, false, false, true, false], "sample_128": [true, true, false, false, true], "sample_129": [false, true, false, false, false], "sample_130": [true, true, true, false, false], "sample_131": [true, false, false, true, false], "sample_132": [false, true, true, true, false], "sample_133": [false, false, false, false, false], "sample_134": [true, true, true, true, true], "sample_135": [true, true, false, true, false], "sample_136": [true, false, false, false, false], "sample_137": [true, true, false, false, false], "sample_138": [true, false, false, false, false], "sample_139": [false, false, true, false, false], "sample_140": [true, true, false, false, true], "sample_142": [false, false, true, false, false], "sample_141": [false, false, false, false, false], "sample_143": [false, false, false, false, false], "sample_144": [true, true, true, true, false], "sample_145": [true, false, false, true, false], "sample_146": [false, true, false, true, false], "sample_147": [true, true, true, true, true], "sample_148": [false, false, false, false, true], "sample_149": [false, false, false, false, false], "sample_150": [false, false, false, true, false], "sample_151": [true, true, true, true, false], "sample_152": [true, false, true, true, true], "sample_153": [false, false, false, false, false], "sample_154": [true, false, true, true, true], "sample_155": [true, false, false, false, true], "sample_156": [true, false, false, false, false], "sample_157": [false, false, false, false, false], "sample_158": [false, true, true, false, false], "sample_159": [false, false, false, false, false]}}