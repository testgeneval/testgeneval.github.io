{"raw_generations": {"sample_33": ["def test_disconnect_multiple_receivers(self):\n    receiver_1 = Callable()\n    receiver_2 = Callable()\n    receiver_3 = Callable()\n    a_signal.connect(receiver_1)\n    a_signal.connect(receiver_2)\n    a_signal.connect(receiver_3)\n    a_signal.disconnect(receiver_1)\n    a_signal.disconnect(receiver_2)\n    a_signal.disconnect(receiver_3)\n    self.assertTestIsClean(a_signal)\n"], "sample_42": ["def test_serialize_deconstructable_class(self):\n    \"\"\"\n    Test serialization of a deconstructable class.\n    \"\"\"\n    class DeconstructableClass:\n            return ('DeconstructableClass', [], {})\n\n    self.assertSerializedResultEqual(\n        DeconstructableClass(),\n        (\"migrations.test_writer.DeconstructableClass\", {'import migrations.test_writer'})\n    )\n"], "sample_112": ["def test_isotonic_regression_out_of_bounds_clip_with_ties():\n    # Setup examples with ties on minimum\n    x = [1, 1, 2, 3, 4, 5]\n    y = [1, 2, 3, 4, 5, 6]\n    y_true = [1.5, 1.5, 3, 4, 5, 6]\n\n    # Check that we get identical results for fit/transform and fit_transform\n    ir = IsotonicRegression(y_min=0, y_max=10, out_of_bounds=\"clip\")\n    ir.fit(x, y)\n    assert_array_almost_equal(ir.transform(x), y_true, 4)\n    assert_array_almost_equal(ir.fit_transform(x, y), y_true, 4)\n"], "sample_84": ["    def test_setup(self, testdir, scope, ok, error):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope=%r, autouse=True)\n                for x in %r:\n                    assert hasattr(request, x)\n                for x in %r:\n                    pytest.raises(AttributeError, lambda:\n                        getattr(request, x))\n                assert request.session\n                assert request.config\n                pass\n        \"\"\"\n            % (scope, ok.split(), error.split())\n        )\n        reprec = testdir.inline_run(\"-l\")\n        reprec.assertoutcome(passed=1)\n"], "sample_85": ["def test_log_file_level_overrides_log_cli_level(testdir):\n    # Default log file level\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_file_handler.level == logging.INFO\n            logging.getLogger('catchlog').debug(\"This log message won't be shown\")\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    result = testdir.runpytest(\n        \"-s\", \"--log-file={}\".format(log_file), \"--log-cli-level=WARNING\", \"--log-file-level=INFO\"\n    )\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines([\"test_log_file_level_overrides_log_cli_level.py PASSED\"])\n\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert \"This log message will be shown\" in contents\n        assert \"This log message won't be shown\" not in contents\n"], "sample_4": ["    def test_content_type(self):\n        r = HttpResponse()\n        self.assertEqual(r['Content-Type'], 'text/html; charset=utf-8')\n        r['Content-Type'] = 'text/plain'\n        self.assertEqual(r['Content-Type'], 'text/plain')\n        self.assertEqual(r.charset, 'utf-8')\n        r.charset = 'latin-1'\n        self.assertEqual(r.charset, 'latin-1')\n        self.assertEqual(r['Content-Type'], 'text/plain; charset=latin-1')\n"], "sample_66": ["    def test_prepopulated_fields_with_one_to_one_field(self):\n        class TestModelAdmin(ModelAdmin):\n            prepopulated_fields = {\"best_friend\": (\"name\",)}\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'prepopulated_fields' refers to 'best_friend', which must \"\n            \"not be a DateTimeField, a ForeignKey, a OneToOneField, or a \"\n            \"ManyToManyField.\",\n            \"admin.E028\",\n        )\n"], "sample_116": ["def test_create_triple_index_with_name(app):\n    text = (\".. index:: triple: foo; bar; baz\\n\"\n            \"   :name: ref1\\n\"\n            \".. index:: triple: Python; Sphinx; reST\\n\"\n            \"   :name: ref2\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 5\n    assert index[0] == ('B', [('bar', [[], [('baz, foo', [('', '#index-0')])], None),\n                              ('baz', [[], [('foo bar', [('', '#index-0')])], None])])\n    assert index[1] == ('F', [('foo', [[], [('bar baz', [('', '#index-0')])], None)])\n    assert index[2] == ('P', [('Python', [[], [('Sphinx reST', [('', '#index-1')])], None)])\n    assert index[3] == ('R', [('reST', [[], [('Python Sphinx', [('', '#index-1')])], None)])\n    assert index[4] == ('S', [('Sphinx', [[], [('reST, Python', [('', '#index-1')])], None]])\n\n    # check the reference labels are created correctly\n    std = app.env.get_domain('std')\n    assert std.anonlabels['ref1'] == ('index', 'ref1')\n    assert std.anonlabels['ref2'] == ('index', 'ref2')\n"], "sample_52": ["    def test_references_field_by_through_model(self):\n        operation = FieldOperation(\n            \"Model\", \"field\", models.ManyToManyField(\"Other\", through=\"Through\")\n        )\n        self.assertIs(operation.references_field(\"Other\", \"whatever\", \"migrations\"), True)\n        self.assertIs(operation.references_field(\"Through\", \"whatever\", \"migrations\"), True)\n        self.assertIs(operation.references_field(\"Missing\", \"whatever\", \"migrations\"), False)\n"], "sample_69": ["def test_sticky_edges():\n    art = martist.Artist()\n    art.sticky_edges.x = [1, 2, 3]\n    art.sticky_edges.y = [4, 5, 6]\n    assert art.sticky_edges.x == [1, 2, 3]\n    assert art.sticky_edges.y == [4, 5, 6]\n    art.sticky_edges.x = [7, 8, 9]\n    art.sticky_edges.y = [10, 11, 12]\n    assert art.sticky_edges.x == [7, 8, 9]\n    assert art.sticky_edges.y == [10, 11, 12]\n"], "sample_127": ["def test_latex_Dict():\n    d = {Rational(1): 1, x**2: 2, x: 3, x**3: 4}\n    assert latex(d) == r'\\left \\{ 1 : 1, \\quad x : 3, \\quad x^{2} : 2, \\quad x^{3} : 4\\right \\}'\n    D = Dict(d)\n    assert latex(D) == r'\\left \\{ 1 : 1, \\quad x : 3, \\quad x^{2} : 2, \\quad x^{3} : 4\\right \\}'\n"], "sample_65": ["    def test_stringformat01(self):\n        output = self.engine.render_to_string(\"stringformat01\")\n        self.assertEqual(output, \"hello world\")\n"], "sample_28": ["    def setUp(self):\n        self.site = admin.AdminSite(name=\"test_adminsite\")\n        self.site.register(User)\n        self.site.register(Article)\n        self.request_factory = RequestFactory()\n"], "sample_89": ["def test_node_repr():\n    item = nodes.Item(\"test_name\", nodeid=\"test_name\")\n    assert str(item) == \"<Item test_name>\"\n    assert repr(item) == \"<Item test_name>\"\n"], "sample_80": ["def test_inline_dask_repr(self):\n    da = xr.DataArray(np.arange(100), dims=\"x\", chunks=10)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10,)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.arange(100), dims=\"x\", chunks=(10, 10))\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.arange(100), dims=\"x\", chunks=(10, 10, 10))\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10, 10)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.arange(100), dims=\"x\", chunks=(10, 10, 10, 10))\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10, 10, 10)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.arange(100), dims=\"x\", chunks=(10, 10, 10, 10, 10))\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10, 10, 10, 10)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.arange(100), dims=\"x\", chunks=(10, 10, 10, 10, 10, 10))\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10, 10, 10, 10, 10)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.arange(100), dims=\"x\", chunks=(10, 10, 10, 10, 10, 10, 10))\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10, 10, 10, 10, "], "sample_124": ["def test_acsch_series():\n    x = Symbol('x')\n    assert acsch(x).series(x, 0, 10) == \\\n        1/x - x/6 + 7*x**3/360 - 31*x**5/15120 + 127*x**7/604800 + O(x**8)\n    t5 = acsch(x).expansion_term(5, x)\n    assert t5 == -7*x**5/360\n    assert acsch(x).expansion_term(7, x, t5, 0) == -31*x**7/15120\n"], "sample_64": ["    def test_prepopulated_fields_js(self):\n        \"\"\"\n        prepopulated_fields_js template tag should pass whole context.\n        \"\"\"\n        article = Article.objects.all()[0]\n        request = self.request_factory.get(\n            reverse(\"admin:admin_views_article_change\", args=[article.pk])\n        )\n        request.user = self.superuser\n        admin = ArticleAdmin(Article, site)\n        extra_context = {\"extra\": True}\n        response = admin.change_view(\n            request, str(article.pk), extra_context=extra_context\n        )\n        template_context = prepopulated_fields_js(response.context_data)\n        self.assertIs(template_context[\"extra\"], True)\n        self.assertIn(\"prepopulated_fields\", template_context)\n        self.assertIn(\"prepopulated_fields_json\", template_context)\n"], "sample_15": ["def test_language_settings_consistent_with_multiple_languages(self):\n    msg = (\n        'You have provided a value for the LANGUAGE_CODE setting that is '\n        'not in the LANGUAGES setting.'\n    )\n    for tag in ['en', 'fr', 'fr-CA', 'fr-357']:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [\n                Error(msg, id='translation.E004'),\n            ])\n"], "sample_2": ["def test_sip_with_altkey():\n    \"\"\"\n    Test that when creating a WCS object using a key, CTYPE with\n    that key is looked at and not the primary CTYPE.\n    fix for #5443.\n    \"\"\"\n    with fits.open(get_pkg_data_filename('data/sip.fits')) as f:\n        w = wcs.WCS(f[0].header)\n    # create a header with two WCSs.\n    h1 = w.to_header(relax=True, key='A')\n    h2 = w.to_header(relax=False)\n    h1['CTYPE1A'] = \"RA---SIN-SIP\"\n    h1['CTYPE2A'] = \"DEC--SIN-SIP\"\n    h1.update(h2)\n    w = wcs.WCS(h1, key='A')\n    assert (w.wcs.ctype == np.array(['RA---SIN-SIP', 'DEC--SIN-SIP'])).all()\n"], "sample_41": ["def test_formset_can_order_with_initial_data(self):\n    \"\"\"\n    Formsets with ordering and initial data.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_order=True)\n    initial = [{'choice': 'Calexico', 'votes': 100}, {'choice': 'Fergie', 'votes': 900}]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_132": ["def test_closest_points():\n    p = Point2D(0, 0)\n    q = Point2D(3, 4)\n    r = Point2D(6, 8)\n    s = Point2D(9, 12)\n    t = Point2D(12, 16)\n    assert closest_points(p, q, r, s, t) == {(p, q)}\n    assert closest_points(p, q, r, s, t, Point2D(0, 0)) == {(p, q)}\n    assert closest_points(p, q, r, s, t, Point2D(0, 0), Point2D(0, 0)) == {(p, q)}\n    assert closest_points(p, q, r, s, t, Point2D(0, 0), Point2D(0, 0), Point2D(0, 0)) == {(p, q)}\n    assert closest_points(p, q, r, s, t, Point2D(0, 0), Point2D(0, 0), Point2D(0, 0), Point2D(0, 0)) == {(p, q)}\n    assert closest_points(p, q, r, s, t, Point2D(0, 0), Point2D(0, 0), Point2D(0, 0), Point2D(0, 0), Point2D(0, 0)) == {(p, q)}\n    assert closest_points(p, q, r, s, t, Point2D(0, 0), Point2D(0, 0), Point2D(0, 0), Point2D(0, 0), Point2D(0, 0), Point2D(0, 0)) == {(p, q)}\n    assert closest_points(p, q, r, s, t, Point2D(0, 0), Point2D(0, 0), Point2D(0, 0), Point2D(0, 0), Point2D(0, 0), Point2D(0, 0), Point2D(0, 0)) == {(p, q)}\n    assert closest_points(p, q, r, s, t, Point2D(0, 0), Point2D(0, 0"], "sample_152": ["def test_issue_12345():\n    A = ImmutableDenseNDimArray([[1, 2, 3], [4, 5, 6]])\n    B = ImmutableDenseNDimArray([[7, 8, 9], [10, 11, 12]])\n    assert A + B == ImmutableDenseNDimArray([[8, 10, 12], [14, 16, 18]])\n    assert A - B == ImmutableDenseNDimArray([[-6, -6, -6], [-6, -6, -6]])\n    assert A * 2 == ImmutableDenseNDimArray([[2, 4, 6], [8, 10, 12]])\n    assert 2 * A == ImmutableDenseNDimArray([[2, 4, 6], [8, 10, 12]])\n    assert A / 2 == ImmutableDenseNDimArray([[0.5, 1, 1.5], [2, 2.5, 3]])\n    assert A.conjugate() == ImmutableDenseNDimArray([[1, 2, 3], [4, 5, 6]])\n    assert A.transpose() == ImmutableDenseNDimArray([[1, 4], [2, 5], [3, 6]])\n    assert A.adjoint() == ImmutableDenseNDimArray([[1, 4], [2, 5], [3, 6]])\n    assert A.tolist() == [[1, 2, 3], [4, 5, 6]]\n    assert A[0, 0] == 1\n    assert A[0, 1] == 2\n    assert A[1, 0] == 4\n    assert A[1, 1] == 5\n    assert A[0, 2] == 3\n    assert A[1, 2] == 6\n    assert A[:, 0] == ImmutableDenseNDimArray([1, 4])\n    assert A[:, 1] == ImmutableDenseNDimArray([2, 5])\n    assert A[:, 2] == ImmutableDenseNDimArray([3, 6])\n    assert A[0, :] == ImmutableDenseNDimArray([1, 2, 3])\n    assert A[1, :] == ImmutableD"], "sample_51": ["def test_directory_index_template_translatable(self):\n    \"\"\"Test that the directory index template is translatable\"\"\"\n    response = self.client.get(\"/%s/\" % self.prefix)\n    self.assertContains(response, \"Index of ./\")\n    self.assertIn(\"subdir/\", response.context[\"file_list\"])\n    # Test that the template is translatable\n    self.assertIn(\"Index of ./\", response.content.decode(\"utf-8\"))\n    self.assertIn(\"Index of subdir/\", response.content.decode(\"utf-8\"))\n"], "sample_134": ["def test_issue_16858():\n    if not np:\n        skip(\"NumPy not installed\")\n\n    a_1 = MatrixSymbol('a_1', 10, 3)\n    a_2 = MatrixSymbol('a_2', 10, 3)\n    a_3 = MatrixSymbol('a_3', 10, 3)\n    a_4 = MatrixSymbol('a_4', 10, 3)\n    A = BlockMatrix([[a_1, a_2], [a_3, a_4]])\n    B = BlockMatrix([[a_1, a_2], [a_3, a_4]])\n\n    printer = NumPyPrinter()\n    assert printer.doprint(A + B) == 'numpy.add(numpy.block([[a_1, a_2], [a_3, a_4]]), numpy.block([[a_1, a_2], [a_3, a_4]]))'\n"], "sample_55": ["    def test_command_error_returncode(self):\n        with self.assertRaises(CommandError) as cm:\n            raise CommandError(\"Test error\", returncode=42)\n        self.assertEqual(cm.exception.returncode, 42)\n"], "sample_49": ["def test_template_changed_with_filesystem_loader(self):\n    template_path = Path(__file__).parent / 'templates' / 'index.html'\n    self.assertTrue(autoreload.template_changed(None, template_path))\n    mock_reset = mock.patch('django.template.autoreload.reset_loaders')\n    mock_reset.assert_called_once()\n"], "sample_13": ["    def test_fields_limit(self):\n        qs = 'a=1&b=2&c=3&d=4&e=5&f=6&g=7&h=8&i=9&j=10&k=11&l=12&'\n        with self.assertRaisesMessage(TooManyFieldsSent, 'The number of GET/POST parameters exceeded settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'):\n            limited_parse_qsl(qs, fields_limit=10)\n"], "sample_48": ["    def test_alter_field_with_index(self):\n        \"\"\"\n        Test AlterField operation with an index to ensure indexes created via\n        Meta.indexes don't get dropped with sqlite3 remake.\n        \"\"\"\n        project_state = self.set_up_test_model(\"test_alflin\", index=True)\n        operation = migrations.AlterField(\"Pony\", \"pink\", models.IntegerField(null=True))\n        new_state = project_state.clone()\n        operation.state_forwards(\"test_alflin\", new_state)\n        # Test the database alteration\n        self.assertColumnNotNull(\"test_alflin_pony\", \"pink\")\n        with connection.schema_editor() as editor:\n            operation.database_forwards(\"test_alflin\", editor, project_state, new_state)\n        # Index hasn't been dropped\n        self.assertIndexExists(\"test_alflin_pony\", [\"pink\"])\n        # And test reversal\n        with connection.schema_editor() as editor:\n            operation.database_backwards(\"test_alflin\", editor, new_state, project_state)\n        # Ensure the index is still there\n        self.assertIndexExists(\"test_alflin_pony\", [\"pink\"])\n"], "sample_12": ["def test_alter_field_to_foreign_key(self):\n    \"\"\"Tests autodetection of field type changes from non-foreign key to foreign key.\"\"\"\n    changes = self.get_changes([self.author_empty, self.book_with_no_author], [self.author_empty, self.book_with_author])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, model_name=\"book\", name=\"author\")\n    self.assertEqual(changes['otherapp'][0].operations[0].field.remote_field.model._meta.app_label, 'testapp')\n    self.assertEqual(changes['otherapp'][0].operations[0].field.remote_field.model._meta.object_name, 'Author')\n"], "sample_6": ["    def test_validate(self):\n        valid_usernames = ['joe', 'Ren\u00e9', '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f']\n        invalid_usernames = [\n            \"o'connell\", \"\u0639\u0628\u062f \u0627\u0644\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n"], "sample_153": ["def test_issue_23058():\n    from sympy import symbols, sin, cos, pi, UnevaluatedExpr\n\n    delop = Del()\n    CC_   = CoordSys3D(\"C\")\n    y     = CC_.y\n    xhat  = CC_.i\n\n    t = symbols(\"t\")\n    ten = symbols(\"10\", positive=True)\n    eps, mu = 4*pi*ten**(-11), ten**(-5)\n\n    Bx = 2 * ten**(-4) * cos(ten**5 * t) * sin(ten**(-3) * y)\n    vecB = Bx * xhat\n    vecE = (1/eps) * Integral(delop.cross(vecB/mu).doit(), t)\n    vecE = vecE.doit()\n\n    vecB_str = \"\"\"\\"], "sample_140": ["def test_auto_point_vel_if_tree_has_vel_but_inconsistent_pos_vector():\n    q1, q2 = dynamicsymbols('q1 q2')\n    B = ReferenceFrame('B')\n    S = ReferenceFrame('S')\n    P = Point('P')\n    P.set_vel(B, q1 * B.x)\n    P1 = Point('P1')\n    P1.set_pos(P, q2 * S.y)\n    P2 = Point('P2')\n    P2.set_pos(P1, q1 * B.x)\n    raises(ValueError, lambda : P2.vel(B)) # P2.pos_from(P1) can't be expressed in B\n    raises(ValueError, lambda : P2.vel(S)) # P.vel(S) not defined\n"], "sample_19": ["    def test_non_sensitive_request(self):\n        \"\"\"\n        Request info can bee seen in the default error reports for\n        non-sensitive requests.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n\n        with self.settings(DEBUG=False):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n"], "sample_119": ["def test_Sum():\n    assert mcode(Sum(sin(x), (x, 0, 10))) == \"Hold[Sum[Sin[x], {x, 0, 10}]\"\n"], "sample_133": ["def test_c_with_printer():\n    from sympy.printing.ccode import C99CodePrinter\n    class CustomPrinter(C99CodePrinter):\n            return \"fastpow({}, {})\".format(self._print(expr.base),\n                                            self._print(expr.exp))\n\n    x, y = symbols('x y')\n    expr = x**y\n    gen = C99CodeGen(printer=CustomPrinter())\n    expected = (\n        '#include \"expr.h\"\\n'\n        '#include <math.h>\\n'\n        'double expr(double x, double y) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastpow(x, y);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n    result = codegen(('expr', expr), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    assert source == expected\n"], "sample_148": ["def test_issue_19627():\n    from sympy import Abs, Function\n    f = Function('f', positive=True)\n    assert unchanged(Abs, f(x))\n    assert unchanged(Abs, f(x)**2)\n    assert unchanged(Abs, f(x)**3)\n    assert unchanged(Abs, f(x)**4)\n    assert unchanged(Abs, f(x)**5)\n"], "sample_23": ["def test_difference_with_distinct(self):\n    qs1 = Number.objects.filter(num__lt=10).distinct()\n    qs2 = Number.objects.filter(num__lt=9)\n    self.assertNumbersEqual(qs1.difference(qs2), [9], ordered=False)\n"], "sample_146": ["def test_Dict_printing():\n    d = Dict({1: 1 + x, 2: y*x})\n    assert str(d) == \"{1: x + 1, 2: x*y}\"\n    assert sstr(d) == \"{1: x + 1, 2: x*y}\"\n"], "sample_17": ["    def test_clone_test_db(self, mocked_migrate, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_clone_test_db'):\n                creation.clone_test_db(suffix='clone', verbosity=0, autoclobber=True, keepdb=False)\n                mocked_migrate.assert_called_once()\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_99": ["def test_radius_neighbors_regressor_sparse():\n    # Test radius-based regression on sparse matrices\n    # Like the above, but with various types of sparse matrices\n    rng = np.random.RandomState(0)\n    X = 2 * rng.rand(40, 5) - 1\n    y = np.sqrt((X ** 2).sum(1))\n    y /= y.max()\n    y = np.vstack([y, y]).T\n\n    for sparsemat in SPARSE_TYPES:\n        knn = neighbors.RadiusNeighborsRegressor(n_neighbors=3,\n                                                 algorithm='auto')\n        knn.fit(sparsemat(X), y)\n\n        knn_pre = neighbors.RadiusNeighborsRegressor(n_neighbors=3,\n                                                     metric='precomputed')\n        knn_pre.fit(pairwise_distances(X, metric='euclidean'), y)\n\n        for sparsev in SPARSE_OR_DENSE:\n            X2 = sparsev(X)\n            assert_true(np.mean(knn.predict(X2).round() == y) > 0.95)\n\n            X2_pre = sparsev(pairwise_distances(X, metric='euclidean'))\n            if issparse(sparsev(X2_pre)):\n                assert_raises(ValueError, knn_pre.predict, X2_pre)\n            else:\n                assert_true(\n                    np.mean(knn_pre.predict(X2_pre).round() == y) > 0.95)\n"], "sample_34": ["    def test_collision_in_same_model(self):\n        class Model(models.Model):\n            class Meta:\n                unique_together = [('id', 'name')]\n\n            id = models.AutoField(primary_key=True)\n            name = models.CharField(max_length=20)\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"unique_together 'id, name' is not unique for model \"\n                \"check_framework.Model.\",\n                id='models.E011',\n            ),\n        ])\n"], "sample_123": ["def test_issue_10368():\n    assert int(S(32442016954)/78058255275) == 42\n"], "sample_149": ["def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 3)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 4)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 5)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 6)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 7)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 8)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 9)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 10)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 11)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 12)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 13)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 14)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 15)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 16)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 17)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 18)) is None\n    assert monomial_ldiv((3"], "sample_46": ["    def test_references_table(self):\n        index = IndexName('table', ['first_column'], 'suffix', lambda table, columns, suffix: ', '.join(\"%s_%s_%s\" % (table, column, suffix) for column in columns))\n        self.assertIs(index.references_table('table'), True)\n        self.assertIs(index.references_table('other'), False)\n"], "sample_93": ["    def test_getbasetemp_custom_basetemp(self, tmp_path):\n        \"\"\"Test that getbasetemp returns the custom basetemp when given.\"\"\"\n        mytemp = tmp_path.joinpath(\"xyz\")\n        mytemp.mkdir()\n        config = cast(Config, FakeConfig(mytemp))\n        t = TempPathFactory.from_config(config, _ispytest=True)\n        assert t.getbasetemp() == mytemp\n"], "sample_16": ["    def test_quote(self):\n        \"\"\"\n        Tests for quote function\n        \"\"\"\n        self.assertEqual(quote('test'), 'test')\n        self.assertEqual(quote('test:'), 'test:_')\n        self.assertEqual(quote('test/'), 'test/_')\n        self.assertEqual(quote('test:\"'), 'test:_')\n        self.assertEqual(quote('test/'), 'test/_')\n        self.assertEqual(quote('test:\"'), 'test:_')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual(quote('test:\"/'), 'test:_/')\n        self.assertEqual("], "sample_82": ["def test_groupby_quantile_out_of_range():\n    array = xr.DataArray(\n        data=[1, 2, 3, 4, 5, 6], coords={\"x\": [1, 1, 1, 2, 2, 2]}, dims=\"x\"\n    )\n    with raises_regex(ValueError, \"q must be between 0 and 1\"):\n        array.groupby(\"x\").quantile(2)\n    with raises_regex(ValueError, \"q must be between 0 and 1\"):\n        array.groupby(\"x\").quantile(-1)\n"], "sample_20": ["    def test_unique_constraint_pointing_to_foreign_key_field(self):\n        class Parent(models.Model):\n            pass\n\n        class Child(models.Model):\n            parent = models.ForeignKey(Parent, models.CASCADE)\n\n            class Meta:\n                constraints = [models.UniqueConstraint(fields=['parent_id'], name='name')]\n\n        self.assertEqual(Child.check(databases=self.databases), [])\n"], "sample_136": ["def test_BlockMatrix_inverse():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n    assert block_collapse(X.I) == BlockMatrix([\n        [(-B*D.I*C + A).I, -A.I*B*(D + -C*A.I*B).I],\n        [-(D - C*A.I*B).I*C*A.I, (D - C*A.I*B).I]])\n\n    assert isinstance(X.I, Inverse)\n\n    assert not X.is_Identity\n\n    Z = BlockMatrix([[Identity(n), B], [C, D]])\n    assert not Z.is_Identity\n\n    # Test that the inverse of a BlockDiagMatrix is a BlockDiagMatrix\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', m, m)\n    C = MatrixSymbol('C', l, l)\n    X = BlockDiagMatrix(A, B, C)\n    assert block_collapse(X.I) == BlockDiagMatrix(A.I, B.I, C.I)\n"], "sample_91": ["    def test_xfail_raises_with_multiple_exceptions(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(raises=(TypeError, ValueError))\n                raise TypeError()\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n"], "sample_118": ["def test_ccode_AugmentedAssignment_with_Indexed():\n    from sympy.tensor import IndexedBase, Idx\n    from sympy import symbols\n    n, m = symbols('n m', integer=True)\n    A = IndexedBase('A')\n    x = IndexedBase('x')\n    y = IndexedBase('y')\n    i = Idx('i', m)\n    j = Idx('j', n)\n\n    s = (\n        'for (int i=0; i<m; i++){\\n'\n        '   for (int j=0; j<n; j++){\\n'\n        '      A[%s] += x[j];\\n' % (i*n + j) +\\\n        '   }\\n'\n        '}'\n    )\n    c = ccode(x[j] + A[i, j], assign_to=A[i, j])\n    assert c == s\n"], "sample_62": ["    def setUp(self):\n        super().setUp()\n        self.dirname = self.mkdtemp()\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n"], "sample_8": ["    def test_sensitive_variables_decorator(self):\n        \"\"\"\n        The sensitive_variables decorator works with function calls.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(sensitive_variables_function_caller)\n            self.verify_unsafe_email(sensitive_variables_function_caller)\n\n        with self.settings(DEBUG=False):\n            self.verify_safe_response(sensitive_variables_function_caller)\n            self.verify_safe_email(sensitive_variables_function_caller)\n"], "sample_101": ["def test_pipeline_memory_cache_hit():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        if LooseVersion(joblib_version) < LooseVersion('0.12'):\n            # Deal with change of API in joblib\n            memory = Memory(cachedir=cachedir, verbose=10)\n        else:\n            memory = Memory(location=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(gamma='scale', probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', clone(transf)), ('svc', clf)])\n        cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n                               memory=memory)\n\n        # Memoize the transformer at the first fit\n        cached_pipe.fit(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert not hasattr(transf, 'means_')\n        # Check that we are reading the cache while fitting\n        # a second time\n        cached_pipe.fit(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        # Check that the cache is hit\n        assert_equal(time.time() - cached_pipe.named_steps['transf'].timestamp_,\n                     0)\n    finally:\n        shutil.rmtree(cachedir)\n"], "sample_11": ["def test_serialize_deconstructable_class(self):\n    \"\"\"\n    Test serialization of a class that knows how to deconstruct itself.\n    \"\"\"\n    class DeconstructableClass:\n            return ('DeconstructableClass', [], {})\n\n    class DeconstructableClassSerializer(DeconstructableSerializer):\n            return self.serialize_deconstructed(*self.value.deconstruct())\n\n    serializer = DeconstructableClassSerializer(DeconstructableClass())\n    string, imports = serializer.serialize()\n    self.assertEqual(string, \"DeconstructableClass()\")\n    self.assertEqual(imports, set())\n\n    class DeconstructableClassWithArgs:\n            return ('DeconstructableClassWithArgs', [1, 2], {'kwarg1': 'value1'})\n\n    class DeconstructableClassWithArgsSerializer(DeconstructableSerializer):\n            return self.serialize_deconstructed(*self.value.deconstruct())\n\n    serializer = DeconstructableClassWithArgsSerializer(DeconstructableClassWithArgs())\n    string, imports = serializer.serialize()\n    self.assertEqual(string, \"DeconstructableClassWithArgs(1, 2, kwarg1='value1')\")\n    self.assertEqual(imports, set())\n\n    class DeconstructableClassWithKwargs:\n            return ('DeconstructableClassWithKwargs', [], {'kwarg1': 'value1'})\n\n    class DeconstructableClassWithKwargsSerializer(DeconstructableSerializer):\n            return self.serialize_deconstructed(*self.value.deconstruct())\n\n    serializer = DeconstructableClassWithKwargsSerializer(DeconstructableClassWithKwargs())\n    string, imports = serializer.serialize()\n    self.assertEqual(string, \"DeconstructableClassWithKwargs(kwarg1='value1')\")\n    self.assertEqual(imports, set())\n\n    class DeconstructableClassWithArgsAndKwargs:\n            return ('DeconstructableClassWithArgsAndKwargs', [1, 2], {'kwarg1': 'value1', 'kwarg2': 'value2'})\n\n    class DeconstructableClassWithArgsAndKwargsSerializer(DeconstructableSerializer):\n            return self.serialize_deconstructed(*self.value.deconstruct())\n\n    serializer = DeconstructableClassWithArgsAndKwargsSerializer(DeconstructableClassWithArgsAndKwargs())\n    string, imports = serializer.serialize()\n    self.assertEqual(string, \"De"], "sample_122": ["def test_LDLdecomposition():\n    A = SparseMatrix(((25, 15, -5), (15, 18, 0), (-5, 0, 11)))\n    L, D = A.LDLdecomposition()\n    assert L.is_lower\n    assert D.is_diagonal\n    assert (L*D*L.T) == A\n    assert L.rows == A.rows\n    assert D.rows == A.rows\n    assert L.cols == A.cols\n    assert D.cols == A.cols\n    assert L.nnz() == 6\n    assert D.nnz() == 3\n    assert L._smat == {(0, 0): 5, (1, 0): 3, (2, 0): -1, (0, 1): 0, (1, 1): 9, (2, 1): 0}\n    assert D._smat == {(0, 0): 25, (1, 1): 9, (2, 2): 9}\n"], "sample_54": ["def test_avoid_wrapping(self):\n    items = (\n        (\"Hello, world!\", \"Hello, world!\"),\n        (\"Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!  Hello, world!\"),\n        (\"Hello, world!\\nHello, world!\", \"Hello, world!\\nHello, world!\"),\n        (\"Hello, world!\\nHello, world!\\nHello, world!\", \"Hello, world!\\nHello, world!\\nHello, world!\"),\n        (\"Hello, world!\\nHello, world!\\nHello, world!\\nHello, world!\", \"Hello, world!\\nHello, world!\\nHello, world!\\nHello, world!\"),\n        (\"Hello, world!\\tHello, world!\", \"Hello, world!\\tHello, world!\"),\n        (\"Hello, world!\\tHello, world!\\tHello, world!\", \"Hello, world!\\tHello, world!\\tHello, world!\"),\n        (\"Hello, world!\\tHello, world!\\tHello, world!\\tHello, world!\", \"Hello, world!\\tHello, world!\\tHello, world!\\tHello, world!\"),\n    )\n    for value, output in items:\n        with self.subTest(value=value, output=output):\n            self.check_output(avoid_wrapping, value, output)\n            self.check_output(avoid_wrapping, lazystr(value), output)\n"], "sample_29": ["    def setUpTestData(cls):\n        cls.example_inc = Company.objects.create(\n            name=\"Example Inc.\", num_employees=2300, num_chairs=5,\n            ceo=Employee.objects.create(firstname=\"Joe\", lastname=\"Smith\", salary=10)\n        )\n        cls.foobar_ltd = Company.objects.create(\n            name=\"Foobar Ltd.\", num_employees=3, num_chairs=4, based_in_eu=True,\n            ceo=Employee.objects.create(firstname=\"Frank\", lastname=\"Meyer\", salary=20)\n        )\n        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.gmbh = Company.objects.create(name='Test GmbH', num_employees=32, num_chairs=1, ceo=cls.max)\n"], "sample_37": ["    def test_empty_list(self):\n        expr = ExpressionList()\n        self.assertEqual(expr.as_sql(None, connection), ('', []))\n"], "sample_56": ["    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n"], "sample_88": ["def test_repr_on_oldstyle():\n    \"\"\"Test saferepr() with old-style classes, which do not have __repr__ defined.\"\"\"\n    class OldStyleClass:\n        pass\n\n    assert saferepr(OldStyleClass()) == \"<OldStyleClass object at 0x{:x}>\".format(id(OldStyleClass()))\n"], "sample_74": ["def test_colorbar_set_ticks_minor_locator():\n    \"\"\"\n    Test that the minor locator is properly set when using set_ticks.\n    \"\"\"\n    fig, ax = plt.subplots()\n    x = np.arange(-3.0, 4.001)\n    y = np.arange(-4.0, 3.001)\n    X, Y = np.meshgrid(x, y)\n    Z = X * Y\n    Z = Z[:-1, :-1]\n    pcm = ax.pcolormesh(X, Y, Z)\n    cbar = fig.colorbar(pcm, ax=ax, extend='both',\n                        orientation='vertical')\n    ticks = cbar.get_ticks()\n    cbar.set_ticks(ticks, minor=True)\n    assert isinstance(cbar.minorlocator, ticker.FixedLocator)\n    assert cbar.minorlocator.nbins == len(ticks)\n    cbar.set_ticks(ticks, minor=False)\n    assert cbar.locator is cbar.ax.yaxis.get_major_locator()\n    assert cbar.minorlocator is None\n"], "sample_111": ["def test_empty_input(metric_name):\n    # All clustering metrics should raise a ValueError when given an empty input\n    y_true = []\n    y_pred = []\n    if metric_name in SUPERVISED_METRICS:\n        metric = SUPERVISED_METRICS[metric_name]\n        with pytest.raises(ValueError):\n            metric(y_true, y_pred)\n    else:\n        metric = UNSUPERVISED_METRICS[metric_name]\n        X = np.random.randint(10, size=(0, 10))\n        with pytest.raises(ValueError):\n            metric(X, y_true)\n"], "sample_47": ["def test_migrate_with_replaced_migration(self):\n    \"\"\"\n    Test migrating with a replaced migration.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Were the tables there before?\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_tribble\")\n    # Run it normally\n    self.assertEqual(\n        executor.migration_plan([(\"migrations\", \"0001_initial\")]),\n        [\n            (executor.loader.graph.nodes[\"migrations\", \"0001_initial\"], False),\n        ],\n    )\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n    # Are the tables there now?\n    self.assertTableExists(\"migrations_author\")\n    self.assertTableExists(\"migrations_tribble\")\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Create a replaced migration\n    replaced_migration = executor.loader.get_migration(\"migrations\", \"0002_second\")\n    replaced_migration.replaces = [(\"migrations\", \"0001_initial\")]\n    # Migrate to the replaced migration\n    executor.migrate([(\"migrations\", \"0002_second\")])\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Check that the replaced migration is marked as applied\n    self.assertIn(\n        (\"migrations\", \"0001_initial\"),\n        executor.recorder.applied_migrations(),\n    )\n    # Migrate back to clean up the database\n    executor.migrate([(\"migrations\", None)])\n    # Are the tables gone?\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_tribble\")\n"], "sample_75": ["def test_axesgrid_colorbar_log_smoketest_with_label_mode():\n    fig = plt.figure()\n    grid = AxesGrid(fig, 111,  # modified to be only subplot\n                    nrows_ncols=(1, 1),\n                    ngrids=1,\n                    label_mode=\"all\",\n                    cbar_location=\"top\",\n                    cbar_mode=\"single\",\n                    )\n\n    Z = 10000 * np.random.rand(10, 10)\n    im = grid[0].imshow(Z, interpolation=\"nearest\", norm=LogNorm())\n\n    grid.cbar_axes[0].colorbar(im)\n"], "sample_147": ["def test_MatMul_kind():\n    A = MatrixSymbol('A', 2,2)\n    assert MatMul(A, comm_x).kind is MatrixKind(NumberKind)\n    assert MatMul(A, A).kind is MatrixKind(MatrixKind(NumberKind))\n    assert MatMul(A, noncomm_x).kind is MatrixKind(UndefinedKind)\n    assert MatMul(noncomm_x, A).kind is MatrixKind(UndefinedKind)\n"], "sample_115": ["def test__wrap_in_pandas_container_sparse():\n    \"\"\"Check _wrap_in_pandas_container for sparse data.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X = csr_matrix([[1, 0, 3], [0, 0, 1]])\n    columns = np.asarray([\"f0\", \"f1\", \"f2\"], dtype=object)\n    index = np.asarray([0, 1])\n\n    with pytest.raises(ValueError, match=\"Pandas output does not support sparse data\"):\n        _wrap_in_pandas_container(X, columns=columns, index=index)\n"], "sample_126": ["def test_Float_precision():\n    # Make sure Float inputs for keyword args work\n    assert Float('1.0', dps=Float(15))._prec == 53\n    assert Float('1.0', precision=Float(15))._prec == 15\n    assert type(Float('1.0', precision=Float(15))._prec) == int\n    assert sympify(srepr(Float('1.0', precision=15))) == Float('1.0', precision=15)\n"], "sample_138": ["def test_BlockMatrix_inverse():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n    assert block_collapse(X.I) == BlockMatrix([\n        [(-B*D.I*C + A).I, -A.I*B*(D + -C*A.I*B).I],\n        [-(D - C*A.I*B).I*C*A.I, (D - C*A.I*B).I]])\n\n    assert isinstance(X.inverse(), Inverse)\n\n    assert not X.is_Identity\n\n    Z = BlockMatrix([[Identity(n), B], [C, D]])\n    assert not Z.is_Identity\n\n    # Test that BlockMatrices and MatrixSymbols can still mix\n    assert (X*M).is_MatMul\n    assert X._blockmul(M).is_MatMul\n    assert (X*M).shape == (n + m, p)\n    assert (X + N).is_MatAdd\n    assert X._blockadd(N).is_MatAdd\n    assert (X + N).shape == X.shape\n\n    E = MatrixSymbol('E', m, 1)\n    F = MatrixSymbol('F', k, 1)\n\n    Y = BlockMatrix(Matrix([[E], [F]]))\n\n    assert (X*Y).shape == (n + m, 1)\n    assert block_collapse(X*Y).blocks[0, 0] == A*E + B*F\n    assert block_collapse(X*Y).blocks[1, 0] == C*E + D*F\n\n    # Test that BlockMatrices can be used in assumptions\n    from sympy import assuming, Q\n    with assuming(Q.invertible(A)):\n        assert det(X) == det(A) * det(D - C*A.I*B)\n\n    assert isinstance(det(X), Expr)\n"], "sample_117": ["def test_stringify_type_hints_Annotated():\n    from typing import Annotated  # type: ignore\n    assert stringify(Annotated[int, \"foo\"]) == \"int\"\n    assert stringify(Annotated[str, \"foo\", \"bar\"]) == \"str\"  # NOQA\n    assert stringify(Annotated[None, \"foo\"]) == \"None\"\n    assert stringify(Annotated[bool, \"foo\"]) == \"bool\"\n    assert stringify(Annotated[bool, \"foo\", \"bar\"]) == \"bool\"  # NOQA\n"], "sample_63": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = UNUSABLE_PASSWORD_PREFIX + \"123\"\n        self.assertHTMLEqual(\n            widget.render(\"name\", value, {\"id\": \"id_password\"}),\n            '<div id=\"id_password\">'\n            \"    <strong>No password set.</strong>\"\n            \"</div>\",\n        )\n"], "sample_31": ["def test_shell_with_bpython_not_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import bpython interface.\"):\n        call_command('shell', interface='bpython')\n"], "sample_81": ["    def test_encoding_ascii(self) -> None:\n        code = \"\"\"a = 1\n                # FIXME message\n                \"\"\"\n        with self.assertNoMessages():\n            self.checker.process_module(_tokenize_str(code))\n"], "sample_114": ["def test_class_distribution_sparse_multilabel_explicit_zero():\n    y = np.array([[0, 1], [1, 0]])\n    y_sp = sparse_multilable_explicit_zero\n\n    classes, n_classes, class_prior = class_distribution(y)\n    classes_sp, n_classes_sp, class_prior_sp = class_distribution(y_sp)\n\n    classes_expected = [[0, 1]]\n    n_classes_expected = [2]\n    class_prior_expected = [0.5, 0.5]\n\n    for k in range(y.shape[1]):\n        assert_array_almost_equal(classes[k], classes_expected[k])\n        assert_array_almost_equal(n_classes[k], n_classes_expected[k])\n        assert_array_almost_equal(class_prior[k], class_prior_expected[k])\n\n        assert_array_almost_equal(classes_sp[k], classes_expected[k])\n        assert_array_almost_equal(n_classes_sp[k], n_classes_expected[k])\n        assert_array_almost_equal(class_prior_sp[k], class_prior_expected[k])\n"], "sample_130": ["def test_lambdify_with_indexed():\n    # Test for issue 10934\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    a = IndexedBase('a')\n    i, j = symbols('i j')\n    b = numpy.array([[1, 2], [3, 4]])\n    assert lambdify(a, a[i, j])(b) == b\n"], "sample_131": ["def test_Sum():\n    assert mcode(Sum(x, (x, 1, 10))) == \"Hold[Sum[x, {x, 1, 10}]}\"\n    assert mcode(Sum(x**2, (x, 1, 10))) == \"Hold[Sum[x^2, {x, 1, 10}]}\"\n    assert mcode(Sum(x**2, (x, 1, 10)) + x) == \"Hold[Sum[x^2, {x, 1, 10}] + x]\"\n    assert mcode(Sum(x**2, (x, 1, 10)) - x) == \"Hold[Sum[x^2, {x, 1, 10}] - x]\"\n    assert mcode(Sum(x**2, (x, 1, 10)) * x) == \"Hold[Sum[x^2, {x, 1, 10}] * x]\"\n"], "sample_32": ["    def test_ordering_by_key_transform(self):\n        values = [\n            {'ord': 93, 'name': 'bar'},\n            {'ord': 22.1, 'name': 'foo'},\n            {'ord': -1, 'name': 'baz'},\n            {'ord': 21.931902, 'name': 'spam'},\n            {'ord': -100291029, 'name': 'eggs'},\n        ]\n        for field_name in ['value', 'value_custom']:\n            with self.subTest(field=field_name):\n                objs = [\n                    NullableJSONModel.objects.create(**{field_name: value})\n                    for value in values\n                ]\n                query = NullableJSONModel.objects.filter(\n                    **{'%s__name__isnull' % field_name: False},\n                ).order_by('%s__ord' % field_name)\n                expected = [objs[4], objs[2], objs[3], objs[1], objs[0]]\n                if connection.vendor == 'oracle':\n                    # Oracle returns JSON values as strings.\n                    expected = [objs[2], objs[4], objs[3], objs[1], objs[0]]\n                self.assertSequenceEqual(query, expected)\n"], "sample_128": ["def test_BuildOptions():\n    opt = Options((x, y, z), {'domain': 'ZZ'})\n\n    assert opt.gens == (x, y, z)\n    assert opt.domain == ZZ\n    assert ('order' in opt) is False\n\n    new_opt = build_options((x, y, z), {'domain': 'ZZ'})\n\n    assert new_opt.gens == (x, y, z)\n    assert new_opt.domain == ZZ\n    assert ('order' in new_opt) is False\n\n    assert build_options((x, y, z), {'opt': {'domain': 'ZZ'}}).gens == (x, y, z)\n    assert build_options((x, y, z), {'opt': {'domain': 'ZZ'}}).domain == ZZ\n    assert ('order' in build_options((x, y, z), {'opt': {'domain': 'ZZ'}})) is False\n\n    raises(OptionError, lambda: build_options((x, y, z), {'gens': (x, y, z)}))\n    raises(OptionError, lambda: build_options((x, y, z), {'gens': (x, y, z), 'opt': {'domain': 'ZZ'}}))\n"], "sample_144": ["def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 0], Q.symmetric(X)) == X[0, 0]\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 1], Q.symmetric(X)) == X[1, 1]\n    assert refine(X[2, 2], Q.symmetric(X)) == X[2, 2]\n\n    assert refine(X[0, 0], ~Q.symmetric(X)) == X[0, 0]\n    assert refine(X[0, 1], ~Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], ~Q.symmetric(X)) == X[1, 0]\n    assert refine(X[1, 1], ~Q.symmetric(X)) == X[1, 1]\n    assert refine(X[2, 2], ~Q.symmetric(X)) == X[2, 2]\n\n    assert refine(X[0, 0], Q.symmetric(X) & Q.symmetric(X)) == X[0, 0]\n    assert refine(X[0, 1], Q.symmetric(X) & Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X) & Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 1], Q.symmetric(X) & Q.symmetric(X)) == X[1, 1]\n    assert refine(X[2, 2], Q.symmetric(X) & Q.symmetric(X)) == X[2, 2]\n\n    assert refine(X[0, 0], Q.symmetric(X) & ~Q.symmetric(X)) == X[0, 0]\n    assert refine(X[0, 1], Q.symmetric(X) & ~Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X) & ~Q.symmetric(X)) == X[1, 0]\n    assert refine(X[1, 1], Q.symmetric(X) & ~Q.symmetric(X)) == X[1, 1]\n    assert refine(X[2, 2], Q.symmetric(X) & ~"], "sample_35": ["    def test_modelform(self):\n        # Create choices for the model choice field tests below.\n        ChoiceModel.objects.create(pk=1, name='a')\n        ChoiceModel.objects.create(pk=2, name='b')\n        ChoiceModel.objects.create(pk=3, name='c')\n\n        # ModelForm\n        class TestModelForm(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = ['name']\n                error_messages = {\n                    'required': 'REQUIRED',\n                    'invalid_choice': 'INVALID CHOICE',\n                }\n\n        f = TestModelForm({'name': 'a'})\n        self.assertFormErrors([], f.clean)\n\n        f = TestModelForm({'name': 'd'})\n        self.assertFormErrors(['INVALID CHOICE'], f.clean)\n\n        # ModelForm with exclude\n        class TestModelFormExclude(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = ['name']\n                exclude = ['name']\n                error_messages = {\n                    'required': 'REQUIRED',\n                    'invalid_choice': 'INVALID CHOICE',\n                }\n\n        f = TestModelFormExclude({'name': 'a'})\n        self.assertFormErrors(['REQUIRED'], f.clean)\n\n        f = TestModelFormExclude({'name': 'd'})\n        self.assertFormErrors(['INVALID CHOICE'], f.clean)\n"], "sample_61": ["def test_decimal_pos_zero(self):\n    self.assertEqual(nformat(1234, \".\", decimal_pos=0), \"1234\")\n    self.assertEqual(nformat(1234.2, \".\", decimal_pos=0), \"1234\")\n    self.assertEqual(nformat(1234, \".\", decimal_pos=0, decimal_sep=\",\"), \"1234\")\n    self.assertEqual(nformat(1234, \".\", decimal_pos=0, decimal_sep=\",\"), \"1234\")\n    self.assertEqual(nformat(1234.2, \".\", decimal_pos=0, decimal_sep=\",\"), \"1234\")\n    self.assertEqual(nformat(1234, \".\", decimal_pos=0, grouping=2, thousand_sep=\",\"), \"1234\")\n    self.assertEqual(\n        nformat(1234, \".\", decimal_pos=0, grouping=2, thousand_sep=\",\", force_grouping=True),\n        \"12,34\",\n    )\n    self.assertEqual(nformat(-1234.33, \".\", decimal_pos=0), \"-1234\")\n    self.assertEqual(\n        nformat(Decimal(\"1234\"), \".\", decimal_pos=0), \"1234\"\n    )\n    self.assertEqual(\n        nformat(Decimal(\"1234.2\"), \".\", decimal_pos=0), \"1234\"\n    )\n    self.assertEqual(\n        nformat(Decimal(\"1234\"), \".\", decimal_pos=0, decimal_sep=\",\"), \"1234\"\n    )\n    self.assertEqual(\n        nformat(Decimal(\"1234\"), \".\", decimal_pos=0, decimal_sep=\",\"), \"1234\"\n    )\n    self.assertEqual(\n        nformat(Decimal(\"1234.2\"), \".\", decimal_pos=0, decimal_sep=\",\"), \"1234\"\n    )\n    self.assertEqual(\n        nformat(Decimal(\"1234\"), \".\", decimal_pos=0, grouping=2, thousand_sep=\",\"), \"1234\"\n    )\n    self.assertEqual(\n        nformat(\n            Decimal(\"1234\"),\n            \".\",\n            decimal_pos=0,\n            grouping=2,\n            thousand_sep=\",\",\n            force_grouping=True,\n        ),\n        \"12,34\",\n    )\n    self.assertEqual(\n        nformat(Decimal(\"-1234.33\"), \".\", decimal_pos=0), \"-1234\"\n    )\n"], "sample_108": ["def test_libsvm_sparse_predict_proba():\n    # Test sparse predict_proba\n    X = iris.data\n    y = iris.target\n\n    # rbf kernel\n    reg = svm.SVR(kernel='rbf', gamma=1).fit(X, y)\n\n    rbfs = rbf_kernel(X, reg.support_vectors_, gamma=reg.gamma)\n    dec = np.dot(rbfs, reg.dual_coef_.T) + reg.intercept_\n    assert_array_almost_equal(dec.ravel(), reg.predict(X).ravel())\n\n    # sparse input\n    X_sparse = sparse.csr_matrix(X)\n    reg_sparse = svm.SVR(kernel='rbf', gamma=1).fit(X_sparse, y)\n    rbfs_sparse = rbf_kernel(X_sparse, reg_sparse.support_vectors_, gamma=reg_sparse.gamma)\n    dec_sparse = np.dot(rbfs_sparse, reg_sparse.dual_coef_.T) + reg_sparse.intercept_\n    assert_array_almost_equal(dec_sparse.ravel(), reg_sparse.predict(X_sparse).ravel())\n\n    # precomputed kernel\n    K = np.dot(X, X.T)\n    reg_precomputed = svm.SVR(kernel='precomputed').fit(K, y)\n    dec_precomputed = reg_precomputed.decision_function(K)\n    assert_array_almost_equal(dec_precomputed.ravel(), reg_precomputed.predict(K).ravel())\n\n    # sparse precomputed kernel\n    K_sparse = sparse.csr_matrix(K)\n    reg_sparse_precomputed = svm.SVR(kernel='precomputed').fit(K_sparse, y)\n    dec_sparse_precomputed = reg_sparse_precomputed.decision_function(K_sparse)\n    assert_array_almost_equal(dec_sparse_precomputed.ravel(), reg_sparse_precomputed.predict(K_sparse).ravel())\n"], "sample_141": ["def test_quantity_simplify_with_prefixes():\n    u = Quantity(\"u\")\n    u.set_global_relative_scale_factor(kilo, meter)\n\n    assert quantity_simplify(u) == meter\n    assert quantity_simplify(kilo*u) == kilo*meter\n    assert quantity_simplify(kilo*u**2) == kilo*meter**2\n    assert quantity_simplify(kilo*u**-1) == meter/kilo\n    assert quantity_simplify(kilo*u**-2) == 1/(kilo*meter**2)\n\n    u = Quantity(\"u\")\n    u.set_global_relative_scale_factor(mega, meter)\n\n    assert quantity_simplify(u) == meter\n    assert quantity_simplify(mega*u) == mega*meter\n    assert quantity_simplify(mega*u**2) == mega*meter**2\n    assert quantity_simplify(mega*u**-1) == meter/mega\n    assert quantity_simplify(mega*u**-2) == 1/(mega*meter**2)\n\n    u = Quantity(\"u\")\n    u.set_global_relative_scale_factor(micro, meter)\n\n    assert quantity_simplify(u) == meter\n    assert quantity_simplify(micro*u) == micro*meter\n    assert quantity_simplify(micro*u**2) == micro*meter**2\n    assert quantity_simplify(micro*u**-1) == meter/micro\n    assert quantity_simplify(micro*u**-2) == 1/(micro*meter**2)\n"], "sample_142": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((0, 1, 2, 3))) == [(0, 1, 2, 3), (0, 1, 2, -3), (0, 1, -2, 3), (0, 1, -2, -3), (0, -1, 2, 3), (0, -1, 2, -3), (0, -1, -2, 3), (0, -1, -2, -3), (0, 2, 1, 3), (0, 2, 1, -3), (0, 2, -1, 3), (0, 2, -1, -3), (0, -2, 1, 3), (0, -2, 1, -3), (0, -2, -1, 3), (0, -2, -1, -3), (1, 0, 2, 3), (1, 0, 2, -3), (1, 0, -2, 3), (1, 0, -2, -3), (1, -0, 2, 3), (1, -0, 2, -3), (1, -0, -2, 3), (1, -0, -2, -3), (1, 2, 0, 3), (1, 2, 0, -3), (1, 2, -0, 3), (1, 2, -0, -3), (1, -2, 0, 3), (1, -2, 0, -3), (1, -2, -0, 3), (1, -2, -0, -3), (2, 0, 1, 3), (2, 0, 1, -3), (2, 0, -1, 3), (2, 0, -"], "sample_105": ["def test_transform_proba():\n    \"\"\"Check transform method of VotingClassifier on toy dataset.\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    X = np.array([[-1.1, -1.5], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n    y = np.array([1, 1, 2, 2])\n\n    eclf1 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft',\n        flatten_transform=True).fit(X, y)\n    eclf2 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft',\n        flatten_transform=False).fit(X, y)\n\n    assert_array_almost_equal(eclf1.transform(X).shape, (4, 6))\n    assert_array_almost_equal(eclf2.transform(X).shape, (3, 4, 2))\n    assert_array_almost_equal(eclf1.transform(X),\n                              eclf2.transform(X).reshape((4, 6)))\n"], "sample_53": ["def test_alter_field_with_default(self):\n    \"\"\"Tests autodetection of field default value changes.\"\"\"\n    changes = self.get_changes([self.author_name], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=\"Ada Lovelace\")\n"], "sample_137": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((0, 1, 2, 3))) == [\n        (0, 1, 2, 3), (0, 1, 2, -3), (0, 1, -2, 3), (0, 1, -2, -3),\n        (0, -1, 2, 3), (0, -1, 2, -3), (0, -1, -2, 3), (0, -1, -2, -3),\n        (1, 0, 2, 3), (1, 0, 2, -3), (1, 0, -2, 3), (1, 0, -2, -3),\n        (1, -0, 2, 3), (1, -0, 2, -3), (1, -0, -2, 3), (1, -0, -2, -3),\n        (1, 2, 0, 3), (1, 2, 0, -3), (1, 2, -0, 3), (1, 2, -0, -3),\n        (1, 2, -3, 0), (1, 2, -3, -0), (1, -2, 0, 3), (1, -2, 0, -3),\n        (1, -2, -0, 3), (1, -2, -0, -3), (1, -2, -3, 0), (1, -2, -3, -0),\n        (2, 0, 1, 3), (2, 0, 1, -3), (2, 0, -1, 3), (2, 0, -1, -3),\n        (2, -0, 1, 3), (2, -0, 1, -3), (2, -0, -1,"], "sample_86": ["def test_record_xml_attribute_junit_disabled(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_xml_attribute(\"foo\", \"bar\")\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 0\n"], "sample_83": ["def test_colorized_text_reporter_deprecation():\n    \"\"\"Test the deprecation of the colorized text reporter.\"\"\"\n    with warnings.catch_warnings(record=True) as cm:\n        warnings.simplefilter(\"always\")\n        ColorizedTextReporter()\n\n    assert len(cm) == 1\n    assert isinstance(cm[0].message, DeprecationWarning)\n\n"], "sample_7": ["    def setUp(self):\n        self._tempdir = tempfile.TemporaryDirectory()\n        self.tempdir = Path(self._tempdir.name).resolve().absolute()\n        self.existing_file = self.ensure_file(self.tempdir / 'test.py')\n        self.nonexistent_file = (self.tempdir / 'does_not_exist.py').absolute()\n        self.reloader = autoreload.StatReloader()\n"], "sample_22": ["def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123'), 'hello world123')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc'), 'hello world123abc')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456'), 'hello world123abc456')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456def'), 'hello world123abc456def')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghi'), 'hello world123abc456defghi')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghij'), 'hello world123abc456defghij')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijk'), 'hello world123abc456defghijk')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijkl'), 'hello world123abc456defghijkl')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklm'), 'hello world123abc456defghijklm')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmn'), 'hello world123abc456defghijklmn')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmno'), 'hello world123abc456defghijklmno')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnop'), 'hello world123abc456defghijklmnop')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnoP'), 'hello world123abc456defghijklmno p')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnopqrstuvwxyz'), 'hello world123abc456defghijklmnopqrstuvwxyz')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnopqrstuvwxyzA'), 'hello world123abc456defghijklmnopqrstuvwxyz a')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnopqrstuvwxyzAB'), 'hello world123abc456defghijklmnopqrstuvwxyz ab')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnop"], "sample_72": ["def test_figure_subplot_mosaic():\n    fig, axs = plt.subplots(2, 2)\n    fig.subplot_mosaic([[1, 2, 'edge'],\n                       [3, '.', 'edge']],\n                      sharex=True, sharey=True)\n    assert len(fig.axes) == 4\n    assert len(fig.axes[0].get_xticklabels()) == 1\n    assert len(fig.axes[1].get_xticklabels()) == 0\n    assert len(fig.axes[2].get_yticklabels()) == 1\n    assert len(fig.axes[3].get_yticklabels()) == 0\n"], "sample_150": ["def test_solve_generic():\n    x, y, z = symbols('x y z')\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    assert solve_generic([f_1, f_2, f_3], x, y, z) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0), (sqrt(2) - 1, sqrt(2) - 1, sqrt(2) - 1), (-sqrt(2) - 1, -sqrt(2) - 1, -sqrt(2) - 1)]\n\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n    f_4 = x + y + z - 2\n\n    assert solve_generic([f_1, f_2, f_3, f_4], x, y, z) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0)]\n\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n    f_4 = x + y + z - 2\n    f_5 = x + y + z - 3\n\n    assert solve_generic([f_1, f_2, f_3, f_4, f_5], x, y, z) == \\\n        [(0, 0, 1)]\n\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n    f_4 = x + y + z - 2\n    f_5 = x + y + z - 3\n    f_6 = x + y + z - 4\n\n    assert solve_generic([f_1, f"], "sample_40": ["def test_boundfield_subwidgets(self):\n    class SomeForm(Form):\n        field = MultipleChoiceField(\n            choices=[('a', 'A'), ('b', 'B')],\n            widget=CheckboxSelectMultiple,\n        )\n\n    form = SomeForm(auto_id='prefix_%s')\n    subwidgets = form['field'].subwidgets\n    self.assertEqual(len(subwidgets), 2)\n    self.assertEqual(subwidgets[0].id_for_label, 'prefix_field_0')\n    self.assertEqual(subwidgets[1].id_for_label, 'prefix_field_1')\n    self.assertEqual(subwidgets[0].choice_label, 'A')\n    self.assertEqual(subwidgets[1].choice_label, 'B')\n    self.assertEqual(subwidgets[0].data['attrs']['id'], 'prefix_field_0')\n    self.assertEqual(subwidgets[1].data['attrs']['id'], 'prefix_field_1')\n"], "sample_155": ["def test_get_dimensional_dependencies():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    w = Quantity(\"w\")\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    assert SI.get_dimension_system().get_dimensional_dependencies(u) == {\n        length: 1,\n        time: 0\n    }\n\n    assert SI.get_dimension_system().get_dimensional_dependencies(v) == {\n        length: 1,\n        time: 0\n    }\n\n    assert SI.get_dimension_system().get_dimensional_dependencies(w) == {\n        length: 0,\n        time: 1\n    }\n\n    assert SI.get_dimension_system().get_dimensional_dependencies(u + v) == {\n        length: 1,\n        time: 0\n    }\n\n    assert SI.get_dimension_system().get_dimensional_dependencies(u - v) == {\n        length: 1,\n        time: 0\n    }\n\n    assert SI.get_dimension_system().get_dimensional_dependencies(u * v) == {\n        length: 2,\n        time: 0\n    }\n\n    assert SI.get_dimension_system().get_dimensional_dependencies(u / v) == {\n        length: 1,\n        time: 0\n    }\n\n    assert SI.get_dimension_system().get_dimensional_dependencies(u ** 2) == {\n        length: 2,\n        time: 0\n    }\n\n    assert SI.get_dimension_system().get_dimensional_dependencies(u ** -1) == {\n        length: -1,\n        time: 0\n    }\n"], "sample_21": ["    def test_fast_delete_with_signal(self):\n        # Attach a signal to make sure we will not do fast_deletes.\n        calls = []\n\n            calls.append('')\n        models.signals.post_delete.connect(noop, sender=User)\n\n        u = User.objects.create(\n            avatar=Avatar.objects.create()\n        )\n        a = Avatar.objects.get(pk=u.avatar_id)\n        # 1 query to fast-delete the user\n        # 1 query to delete the avatar\n        self.assertNumQueries(2, a.delete)\n        self.assertFalse(User.objects.exists())\n        self.assertFalse(Avatar.objects.exists())\n        self.assertEqual(len(calls), 1)\n        models.signals.post_delete.disconnect(noop, sender=User)\n"], "sample_71": ["def test_context_with_multiple_styles():\n    original_value = 'gray'\n    other_value = 'blue'\n    mpl.rcParams[PARAM] = original_value\n    with temp_style('test', DUMMY_SETTINGS):\n        with style.context(['test', 'default', {PARAM: other_value}]):\n            assert mpl.rcParams[PARAM] == other_value\n    assert mpl.rcParams[PARAM] == original_value\n"], "sample_10": ["def test_year_lookup(self):\n    # year lookup can be performed using a direct value\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n            '<Article: Article 1>',\n        ]\n    )\n    # year lookup can be performed using a direct value with exact lookup\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__exact=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n            '<Article: Article 1>',\n        ]\n    )\n    # year lookup can be performed using a direct value with gt lookup\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gt=2005),\n        ['<Article: Article 5>', '<Article: Article 6>']\n    )\n    # year lookup can be performed using a direct value with gte lookup\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gte=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n            '<Article: Article 1>',\n        ]\n    )\n    # year lookup can be performed using a direct value with lt lookup\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lt=2005),\n        []\n    )\n    # year lookup can be performed using a direct value with lte lookup\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lte=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n            '<Article: Article 1>',\n        ]\n    )\n"], "sample_25": ["def test_alter_field_to_fk_dependency_other_app_with_unique_together(self):\n    \"\"\"\n    #23100 - ForeignKeys correctly depend on other apps' models.\n    \"\"\"\n    changes = self.get_changes([self.author_empty, self.book], [self.author_with_book, self.book_foo_together])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"book\")\n    self.assertMigrationDependencies(changes, 'testapp', 0, [(\"otherapp\", \"__first__\")])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, [\"AlterUniqueTogether\", \"AlterIndexTogether\"])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"book\", unique_together={(\"author\", \"title\")})\n    self.assertOperationAttributes(changes, 'otherapp', 0, 1, name=\"book\", index_together={(\"author\", \"title\")})\n"], "sample_9": ["    def test_iter_modules_and_files_with_zip_importer(self):\n        \"\"\"\n        Modules imported from zipped files have their archive location included\n        in the result.\n        \"\"\"\n        zip_file = self.temporary_file('zip_import.zip')\n        with zipfile.ZipFile(str(zip_file), 'w', zipfile.ZIP_DEFLATED) as zipf:\n            zipf.writestr('test_zipped_file.py', '')\n\n        with extend_sys_path(str(zip_file)):\n            self.import_and_cleanup('test_zipped_file')\n        self.assertFileFound(zip_file)\n"], "sample_96": ["def test_ridge_solver_switch():\n    # Test that the solver is correctly switched when fit_intercept is True\n    # and X is sparse.\n\n    X, y = make_regression(n_samples=1000, n_features=2, n_informative=2,\n                           bias=10., random_state=42)\n    X_csr = sp.csr_matrix(X)\n\n    for solver in ['saga', 'sag']:\n        dense = Ridge(alpha=1., tol=1.e-15, solver=solver, fit_intercept=True)\n        sparse = Ridge(alpha=1., tol=1.e-15, solver=solver, fit_intercept=True)\n        dense.fit(X, y)\n        sparse.fit(X_csr, y)\n        assert_almost_equal(dense.intercept_, sparse.intercept_)\n        assert_array_almost_equal(dense.coef_, sparse.coef_)\n\n    # test the solver switch and the corresponding warning\n    sparse = Ridge(alpha=1., tol=1.e-15, solver='lsqr', fit_intercept=True)\n    assert_warns(UserWarning, sparse.fit, X_csr, y)\n    assert_almost_equal(dense.intercept_, sparse.intercept_)\n    assert_array_almost_equal(dense.coef_, sparse.coef_)\n"], "sample_94": ["def test_getstatementrange_with_trailing_comment() -> None:\n    source = Source(\n        \"\"\"\\"], "sample_0": ["    def test_render_options_multiple_selected(self):\n        \"\"\"Multiple selected options are rendered.\"\"\"\n        beatles = Band.objects.create(name='The Beatles', style='rock')\n        who = Band.objects.create(name='The Who', style='rock')\n        # With 'band', a ForeignKey.\n        form = AlbumForm(initial={'band': [beatles.pk, who.pk]})\n        output = form.as_table()\n        selected_option = '<option value=\"%s\" selected>The Beatles</option>' % beatles.pk\n        option = '<option value=\"%s\" selected>The Who</option>' % who.pk\n        self.assertIn(selected_option, output)\n        self.assertIn(option, output)\n"], "sample_27": ["def test_token_with_different_password(self):\n    \"\"\"\n    A valid token can be created with a password other than the one used to\n    create the user.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    user.set_password('newpw')\n    user.save()\n    self.assertIs(p0.check_token(user, tk1), False)\n"], "sample_145": ["def test_latex_RandomDomain():\n    from sympy.stats import Normal, Die, Exponential, pspace, where\n    from sympy.stats.rv import RandomDomain\n\n    X = Normal('x1', 0, 1)\n    assert latex(where(X > 0)) == r\"\\text{Domain: }0 < x_{1} \\wedge x_{1} < \\infty\"\n\n    D = Die('d1', 6)\n    assert latex(where(D > 4)) == r\"\\text{Domain: }d_{1} = 5 \\vee d_{1} = 6\"\n\n    A = Exponential('a', 1)\n    B = Exponential('b', 1)\n    assert latex(\n        pspace(Tuple(A, B)).domain) == \\\n        r\"\\text{Domain: }0 \\leq a \\wedge 0 \\leq b \\wedge a < \\infty \\wedge b < \\infty\"\n\n    assert latex(RandomDomain(FiniteSet(x), FiniteSet(1, 2))) == \\\n        r'\\text{Domain: }\\left\\{x\\right\\}\\text{ in }\\left\\{1, 2\\right\\}'\n"], "sample_1": ["def test_read_write_simple_specify_delimiter(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3, 4]))\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"b\", mask=[False, False, False, True]\n        )\n    )\n    t1.write(test_file, format=\"ascii.qdp\", delimiter=\",\")\n    with pytest.warns(UserWarning) as record:\n        t2 = Table.read(test_file, format=\"ascii.qdp\", delimiter=\",\")\n    assert np.any(\n        [\n            \"table_id not specified. Reading the first available table\"\n            in r.message.args[0]\n            for r in record\n        ]\n    )\n\n    assert np.allclose(t2[\"col1\"], t1[\"a\"])\n    assert np.all(t2[\"col1\"] == t1[\"a\"])\n\n    good = ~np.isnan(t1[\"b\"])\n    assert np.allclose(t2[\"col2\"][good], t1[\"b\"][good])\n"], "sample_156": ["def test_parser_mathematica_tokenizer_invalid_input():\n    parser = MathematicaParser()\n\n    chain = lambda expr: parser._from_tokens_to_fullformlist(parser._from_mathematica_to_tokens(expr))\n\n    # Invalid input\n    assert chain(\"(\") == SyntaxError\n    assert chain(\")\") == SyntaxError\n    assert chain(\"[\") == SyntaxError\n    assert chain(\"]\") == SyntaxError\n    assert chain(\"{\") == SyntaxError\n    assert chain(\"}\") == SyntaxError\n    assert chain(\"(\") == SyntaxError\n    assert chain(\")\") == SyntaxError\n    assert chain(\"a\") == SyntaxError\n    assert chain(\"a b\") == SyntaxError\n    assert chain(\"a b c\") == SyntaxError\n    assert chain(\"a b c d\") == SyntaxError\n    assert chain(\"a b c d e\") == SyntaxError\n    assert chain(\"a b c d e f\") == SyntaxError\n    assert chain(\"a b c d e f g\") == SyntaxError\n    assert chain(\"a b c d e f g h\") == SyntaxError\n    assert chain(\"a b c d e f g h i\") == SyntaxError\n    assert chain(\"a b c d e f g h i j\") == SyntaxError\n    assert chain(\"a b c d e f g h i j k\") == SyntaxError\n    assert chain(\"a b c d e f g h i j k l\") == SyntaxError\n    assert chain(\"a b c d e f g h i j k l m\") == SyntaxError\n    assert chain(\"a b c d e f g h i j k l m n\") == SyntaxError\n    assert chain(\"a b c d e f g h i j k l m n o\") == SyntaxError\n    assert chain(\"a b c d e f g h i j k l m n o p\") == SyntaxError\n    assert chain(\"a b c d e f g h i j k l m n o p q\") == SyntaxError\n    assert chain(\"a b c d e f g h i j k l m n o p q r\") == SyntaxError\n    assert chain(\"a b c d e f g h i j k l m n o p q r s\") == SyntaxError\n    assert chain(\"a b c d e f g h i j k l m n o p q r s t\") == SyntaxError\n"], "sample_143": ["def test_pretty_RationalField():\n    from sympy import RationalField\n    from sympy.abc import x, y\n    F = RationalField(10)\n    assert pretty(F) == \"QQ[10]\"\n    assert upretty(F) == \"\u211a\u2081\u2080\"\n"], "sample_106": ["def test_callback_with_side_effect():\n    \"\"\"Test that the callback function is called with the correct arguments.\n\n    The callback function should be called with the current transformation and\n    the current iteration number.\n    \"\"\"\n    X = iris_data\n    y = iris_target\n\n        assert transformation.shape == (iris_data.shape[1]**2,)\n        assert n_iter >= 0\n\n    # assert that my_cb is called\n    nca = NeighborhoodComponentsAnalysis(max_iter=10,\n                                         callback=my_cb, verbose=1)\n    nca.fit(iris_data, iris_target)\n"], "sample_103": ["def test_mutual_info_regression_sparse():\n    # We generate sample from multivariate normal distribution, using\n    # transformation from initially uncorrelated variables. The zero\n    # variables after transformation is selected as the target vector,\n    # it has the strongest correlation with the variable 2, and\n    # the weakest correlation with the variable 1.\n    T = np.array([\n        [1, 0.5, 2, 1],\n        [0, 1, 0.1, 0.0],\n        [0, 0.1, 1, 0.1],\n        [0, 0.1, 0.1, 1]\n    ])\n    cov = T.dot(T.T)\n    mean = np.zeros(4)\n\n    rng = check_random_state(0)\n    Z = rng.multivariate_normal(mean, cov, size=1000)\n    X = csr_matrix(Z[:, 1:])\n    y = Z[:, 0]\n\n    mi = mutual_info_regression(X, y, random_state=0)\n    assert_array_equal(np.argsort(-mi), np.array([1, 2, 0]))\n"], "sample_113": ["def test_column_transformer_set_output_mixed_types():\n    \"\"\"Check ColumnTransformer outputs mixed types correctly.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame(\n        {\n            \"pet\": pd.Series([\"dog\", \"cat\", \"snake\"], dtype=\"category\"),\n            \"color\": pd.Series([\"green\", \"blue\", \"red\"], dtype=\"object\"),\n            \"age\": [1.4, 2.1, 4.4],\n            \"height\": [20, 40, 10],\n            \"distance\": pd.Series([20, pd.NA, 100], dtype=\"Int32\"),\n        }\n    )\n    ct = ColumnTransformer(\n        [\n            (\n                \"color_encode\",\n                OneHotEncoder(sparse_output=False, dtype=\"int8\"),\n                [\"color\"],\n            ),\n            (\"age\", StandardScaler(), [\"age\"]),\n        ],\n        verbose_feature_names_out=False,\n    ).set_output(transform=\"pandas\")\n    X_trans = ct.fit_transform(df)\n    assert isinstance(X_trans, pd.DataFrame)\n    assert_array_equal(X_trans.columns, ct.get_feature_names_out())\n\n    expected_dtypes = {\n        \"color_blue\": \"int8\",\n        \"color_green\": \"int8\",\n        \"color_red\": \"int8\",\n        \"age\": \"float64\",\n        \"pet\": \"category\",\n        \"height\": \"int64\",\n        \"distance\": \"Int32\",\n    }\n    for col, dtype in X_trans.dtypes.items():\n        assert dtype == expected_dtypes[col]\n"], "sample_97": ["def test_label_binarize_multiclass_thresholding():\n    y = [0.5, 1.5, 2.5]\n    classes = [0, 1, 2]\n    pos_label = 2\n    neg_label = 0\n    expected = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0]])\n\n    yield check_binarized_results, y, classes, pos_label, neg_label, expected\n\n    y = [0.5, 1.5, 2.5]\n    classes = [0, 1, 2]\n    pos_label = 2\n    neg_label = 0\n    threshold = 1.0\n    expected = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0]])\n\n    yield check_binarized_results, y, classes, pos_label, neg_label, expected, threshold\n\n    assert_raises(ValueError, label_binarize, y, classes, neg_label=-1,\n                  pos_label=pos_label, sparse_output=True)\n\n"], "sample_26": ["    def test_large_data(self):\n        # serialize_db_to_string() handles large amounts of data.\n        obj_1 = Object.objects.create()\n        obj_2 = Object.objects.create()\n        obj_3 = Object.objects.create()\n        obj_4 = Object.objects.create()\n        obj_5 = Object.objects.create()\n        obj_6 = Object.objects.create()\n        obj_7 = Object.objects.create()\n        obj_8 = Object.objects.create()\n        obj_9 = Object.objects.create()\n        obj_10 = Object.objects.create()\n        obj_11 = Object.objects.create()\n        obj_12 = Object.objects.create()\n        obj_13 = Object.objects.create()\n        obj_14 = Object.objects.create()\n        obj_15 = Object.objects.create()\n        obj_16 = Object.objects.create()\n        obj_17 = Object.objects.create()\n        obj_18 = Object.objects.create()\n        obj_19 = Object.objects.create()\n        obj_20 = Object.objects.create()\n        obj_21 = Object.objects.create()\n        obj_22 = Object.objects.create()\n        obj_23 = Object.objects.create()\n        obj_24 = Object.objects.create()\n        obj_25 = Object.objects.create()\n        obj_26 = Object.objects.create()\n        obj_27 = Object.objects.create()\n        obj_28 = Object.objects.create()\n        obj_29 = Object.objects.create()\n        obj_30 = Object.objects.create()\n        obj_31 = Object.objects.create()\n        obj_32 = Object.objects.create()\n        obj_33 = Object.objects.create()\n        obj_34 = Object.objects.create()\n        obj_35 = Object.objects.create()\n        obj_36 = Object.objects.create()\n        obj_37 = Object.objects.create()\n        obj_38 = Object.objects.create()\n        obj_39 = Object.objects.create()\n        obj_40 = Object.objects.create()\n        obj_41 = Object.objects.create()\n        obj_42 = Object.objects.create()\n        obj_43 = Object.objects.create()\n        obj_44 = Object.objects.create()\n        obj_45 = Object.objects.create()\n        obj_46 = Object.objects.create()\n        obj_47 = Object.objects.create()\n        obj_48 = Object.objects.create()\n        obj_49 = Object.objects.create()\n        obj_50 = Object.objects.create()\n        obj_51 = Object.objects.create()\n        obj_52 = Object.objects.create()\n        obj_53 ="], "sample_50": ["def test_encode_empty(self):\n    \"\"\"\n    Test that the _encode method correctly handles encoding an empty list of messages.\n    \"\"\"\n    storage = self.get_storage()\n    encoded_data = storage._encode([])\n    self.assertEqual(encoded_data, b'')\n    self.assertEqual(storage._decode(encoded_data), [])\n"], "sample_90": ["def test_mark_eval_invalid_syntax(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xyz\n            pass\n    \"\"\"\n    )\n    rec = testdir.inline_run(\"-m\", \"xyz\")\n    err = rec.stderr.fnmatch_lines([\"*SyntaxError: invalid syntax*\"])\n    assert err\n"], "sample_125": ["def test_Float_issue_10020():\n    assert oo**I is S.NaN\n    assert oo**(1 + I) is S.ComplexInfinity\n    assert oo**(-1 + I) is S.Zero\n    assert (-oo)**I is S.NaN\n    assert (-oo)**(-1 + I) is S.Zero\n    assert oo**t == Pow(oo, t, evaluate=False)\n    assert (-oo)**t == Pow(-oo, t, evaluate=False)\n"], "sample_129": ["def test_latex_Dict():\n    d = {Rational(1): 1, x**2: 2, x: 3, x**3: 4}\n    assert latex(d) == r'\\left \\{ 1 : 1, \\quad x : 3, \\quad x^{2} : 2, \\quad x^{3} : 4\\right \\}'\n    D = Dict(d)\n    assert latex(D) == r'\\left \\{ 1 : 1, \\quad x : 3, \\quad x^{2} : 2, \\quad x^{3} : 4\\right \\}'\n"], "sample_70": ["def test_legend_title_fontsize():\n    # test the title_fontsize kwarg\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontsize=22)\n    assert leg.get_title().get_fontsize() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontsize() == 20\n"], "sample_3": ["def test_separable_mapping():\n    # Test Mapping model\n    map1 = Mapping((0, 1, 0, 1))\n    assert is_separable(map1).all()\n    assert separability_matrix(map1).all()\n\n    # Test Mapping model with different dimensions\n    map2 = Mapping((0, 0, 1))\n    assert is_separable(map2).all()\n    assert separability_matrix(map2).all()\n\n    # Test Mapping model with different dimensions and separability\n    map3 = Mapping((0, 1))\n    assert not is_separable(map3).all()\n    assert separability_matrix(map3).all()\n\n    # Test Mapping model with different dimensions and separability\n    map4 = Mapping((0, 1, 0, 1, 0, 1))\n    assert is_separable(map4).all()\n    assert separability_matrix(map4).all()\n\n    # Test Mapping model with different dimensions and separability\n    map5 = Mapping((0, 0, 1, 0, 1))\n    assert not is_separable(map5).all()\n    assert separability_matrix(map5).all()\n\n    # Test Mapping model with different dimensions and separability\n    map6 = Mapping((0, 1, 0, 1, 0, 1, 0, 1))\n    assert is_separable(map6).all()\n    assert separability_matrix(map6).all()\n\n    # Test Mapping model with different dimensions and separability\n    map7 = Mapping((0, 0, 1, 0, 1, 0, 1, 0, 1))\n    assert not is_separable(map7).all()\n    assert separability_matrix(map7).all()\n"], "sample_157": ["def test_tensor_product_trace():\n    assert tensor_product_simp(TP(A, B).trace()) == Tr(A)\n    assert tensor_product_simp(TP(A, B).trace(0)) == Tr(B)\n    assert tensor_product_simp(TP(A, B).trace(1)) == Tr(A)\n    assert tensor_product_simp(TP(A, B).trace(0, 1)) == Tr(A)*Tr(B)\n"], "sample_139": ["def test_issue_14216():\n    from sympy import Matrix, simplify\n    A = Matrix([[1, 2], [3, 4]])\n    assert simplify(A.conjugate().transpose()) == A.transpose().conjugate()\n"], "sample_95": ["    def test_parametrize_with_indirect(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n                return request.param\n\n            @pytest.mark.parametrize(\"arg\", [1, 2], indirect=True)\n                assert arg == 1\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*1 passed*\"])\n"], "sample_44": ["def test_choice_iterator_passes_model_to_widget_with_to_field_name(self):\n    \"\"\"\n    Iterator passes model to widget even when to_field_name is specified.\n    \"\"\"\n    class CustomCheckboxSelectMultiple(CheckboxSelectMultiple):\n            option = super().create_option(name, value, label, selected, index, subindex, attrs)\n            # Modify the HTML based on the object being rendered.\n            c = value.instance\n            option['attrs']['data-slug'] = c.slug\n            return option\n\n    class CustomModelMultipleChoiceField(forms.ModelMultipleChoiceField):\n        widget = CustomCheckboxSelectMultiple\n\n    field = CustomModelMultipleChoiceField(Category.objects.all(), to_field_name='slug')\n    self.assertHTMLEqual(\n        field.widget.render('name', []),\n        \"\"\"<div>"], "sample_76": ["def test_order(self, df):\n\n    groupby = GroupBy([\"group\"])\n    res = PolyFit(order=3, gridsize=100)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n\n    assert_array_equal(res.columns, [\"x\", \"y\"])\n\n    grid = np.linspace(df[\"x\"].min(), df[\"x\"].max(), 100)\n    assert_array_equal(res[\"x\"], grid)\n    assert_array_almost_equal(\n        res[\"y\"].diff().diff().dropna(), np.zeros(grid.size - 2)\n    )\n\n    # Test that the order of the polynomial is correct\n    p = np.polyfit(df[\"x\"], df[\"y\"], 3)\n    yy = np.polyval(p, grid)\n    assert_array_almost_equal(res[\"y\"], yy)\n"], "sample_24": ["def test_hash_nested(self):\n    error_dict = {\n        'field1': ValidationError(\n            'error %(parm1)s %(parm2)s',\n            code='my_code',\n            params={'parm1': 'val1', 'parm2': 'val2'},\n        ),\n        'field2': ValidationError(\n            'error %(parm3)s %(parm4)s',\n            code='my_code',\n            params={'parm3': 'val3', 'parm4': 'val4'},\n        ),\n    }\n    error = ValidationError(error_dict)\n    self.assertEqual(hash(error), hash(ValidationError(dict(error_dict))))\n    self.assertEqual(hash(error), hash(ValidationError({\n        'field1': ValidationError(\n            'error %(parm1)s %(parm2)s',\n            code='my_code',\n            params={'parm2': 'val2', 'parm1': 'val1'},\n        ),\n        'field2': ValidationError(\n            'error %(parm3)s %(parm4)s',\n            code='my_code',\n            params={'parm4': 'val4', 'parm3': 'val3'},\n        ),\n    })))\n    self.assertNotEqual(hash(error), hash(ValidationError({\n        'field1': ValidationError(\n            'error %(parm1)s val2',\n            code='my_code',\n            params={'parm1': 'val1'},\n        ),\n        'field2': ValidationError(\n            'error %(parm3)s val4',\n            code='my_code',\n            params={'parm3': 'val3'},\n        ),\n    })))\n"], "sample_36": ["def test_combine_and_non_q_object(self):\n    q = Q(x=1)\n    obj = object()\n    with self.assertRaisesMessage(TypeError, str(obj)):\n        q & obj\n    with self.assertRaisesMessage(TypeError, str(obj)):\n        obj & q\n\n    q = Q(x__in={}.keys())\n    with self.assertRaisesMessage(TypeError, str(obj)):\n        q & obj\n    with self.assertRaisesMessage(TypeError, str(obj)):\n        obj & q\n"], "sample_67": ["def test_serialize_deconstructable_class(self):\n    class DeconstructableClass:\n            return (\"DeconstructableClass\", [], {})\n\n    self.assertSerializedResultEqual(\n        DeconstructableClass(),\n        (\"migrations.test_writer.DeconstructableClass\", {\"import migrations.test_writer\"}),\n    )\n"], "sample_5": ["    def test_delete_with_keeping_parents_and_related_objects(self):\n        child = RChild.objects.create()\n        parent_id = child.r_ptr_id\n        parent_referent_id = S.objects.create(r=child.r_ptr).pk\n        child.related_set.create(s=S.objects.create(r=child.r_ptr))\n        child.delete(keep_parents=True)\n        self.assertFalse(RChild.objects.filter(id=child.id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n        self.assertTrue(S.objects.filter(r=parent_id).exists())\n"], "sample_98": ["def test_check_X_y():\n    # Test check_X_y function\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # Test check_X_y with multi_output=True\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([[0, 1], [1, 0]])\n    X_checked, y_checked = check_X_y(X, y, multi_output=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # Test check_X_y with multi_output=False\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([[0, 1, 2], [1, 0, 1]])\n    with pytest.raises(ValueError):\n        check_X_y(X, y, multi_output=False)\n\n    # Test check_X_y with y_numeric=True\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y, y_numeric=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # Test check_X_y with y_numeric=False\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y, y_numeric=False)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # Test check_X_y with ensure_min_samples=1\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y, ensure_min_samples=1)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    # Test check_X_y with ensure_min_features=1\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y, ensure"], "sample_120": ["def test_matrix_symbol_subs():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = MatrixSymbol('C', n, n)\n\n    assert A.subs(n, m).shape == (m, m)\n    assert A.subs(m, l).shape == (n, l)\n\n    assert (A*B).subs(B, C) == A*C\n    assert (A*B).subs(n, m) == A*B\n\n    assert (A*B).subs(l, n) == A*B\n    assert (A*B).subs(m, l) == A*B\n\n    assert (A*B).subs(n, m).subs(m, l) == A*C\n\n    assert (A*B).subs(n, m).subs(l, n) == A*B\n"], "sample_104": ["def test_n_max_elements_to_show_with_dicts():\n    # Test that n_max_elements_to_show works with dictionaries\n    n_max_elements_to_show = 30\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=n_max_elements_to_show\n    )\n\n    # No ellipsis\n    param_grid = {'C': {i: i for i in range(n_max_elements_to_show)}}\n    gs = GridSearchCV(SVC(), param_grid)\n    expected = \"\"\""], "sample_87": ["    def test_collect_with_custom_norecursedirs(self, testdir):\n        testdir.makeini(\n            \"\"\"\n            [pytest]\n            norecursedirs = mydir xyz*\n        \"\"\"\n        )\n        tmpdir = testdir.tmpdir\n        tmpdir.ensure(\"mydir\", \"test_hello.py\").write(\"def test_1(): pass\")\n        tmpdir.ensure(\"xyz123\", \"test_2.py\").write(\"def test_2(): 0/0\")\n        tmpdir.ensure(\"xy\", \"test_ok.py\").write(\"def test_3(): pass\")\n        rec = testdir.inline_run()\n        rec.assertoutcome(passed=1)\n        rec = testdir.inline_run(\"xyz123/test_2.py\")\n        rec.assertoutcome(failed=1)\n"], "sample_78": ["def test_load_dotenv_suppress_error(monkeypatch):\n    # can't use monkeypatch.delitem since the keys don't exist yet\n    for item in (\"FOO\", \"BAR\", \"SPAM\", \"HAM\"):\n        monkeypatch._setitem.append((os.environ, item, notset))\n\n    monkeypatch.setenv(\"EGGS\", \"3\")\n    monkeypatch.chdir(test_path)\n    assert load_dotenv(\"non-existent-file\", suppress_errors=True)\n    assert Path.cwd() == test_path\n    # .flaskenv doesn't overwrite .env\n    assert os.environ[\"FOO\"] == \"env\"\n    # set only in .flaskenv\n    assert os.environ[\"BAR\"] == \"bar\"\n    # set only in .env\n    assert os.environ[\"SPAM\"] == \"1\"\n    # set manually, files don't overwrite\n    assert os.environ[\"EGGS\"] == \"3\"\n    # test env file encoding\n    assert os.environ[\"HAM\"] == \"\u706b\u817f\"\n"], "sample_92": ["    def test_xfail_raises_with_multiple_exceptions(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(raises=(TypeError, ValueError))\n                raise TypeError()\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n"], "sample_107": ["def test_logistic_regression_path_multinomial():\n    # Test that the path algorithm is consistent for the multinomial case\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = np.array([1] * 100 + [-1] * 100)\n    Cs = np.logspace(0, 4, 10)\n\n    for solver in ['sag', 'saga']:\n        coefs, Cs, _ = _logistic_regression_path(\n            X, y, Cs=Cs, fit_intercept=False, tol=1e-5, solver=solver,\n            multi_class='multinomial', random_state=0)\n        for i, C in enumerate(Cs):\n            lr = LogisticRegression(C=C, fit_intercept=False, tol=1e-5,\n                                    solver=solver, multi_class='multinomial',\n                                    random_state=0)\n            lr.fit(X, y)\n            lr_coef = lr.coef_.ravel()\n            assert_array_almost_equal(lr_coef, coefs[i], decimal=4,\n                                      err_msg=\"with solver = %s\" % solver)\n\n    # test for fit_intercept=True\n    for solver in ('lbfgs', 'newton-cg'):\n        Cs = [1e3]\n        coefs, Cs, _ = _logistic_regression_path(\n            X, y, Cs=Cs, fit_intercept=True, tol=1e-6, solver=solver,\n            intercept_scaling=10000., random_state=0, multi_class='multinomial')\n        lr = LogisticRegression(C=Cs[0], fit_intercept=True, tol=1e-4,\n                                intercept_scaling=10000., random_state=0,\n                                multi_class='multinomial', solver=solver)\n        lr.fit(X, y)\n        lr_coef = np.concatenate([lr.coef_.ravel(), lr.intercept_])\n        assert_array_almost_equal(lr_coef, coefs[0], decimal=4,\n                                  err_msg=\"with solver = %s\" % solver)\n"], "sample_45": ["    def test_cache_control_decorator(self):\n        \"\"\"\n        Test cache_control decorator with different cache control options.\n        \"\"\"\n        @cache_control(private=True, max_age=3600, must_revalidate=True)\n            return HttpResponse()\n\n        r = a_view(HttpRequest())\n        self.assertEqual(\n            set(r.headers['Cache-Control'].split(', ')),\n            {'max-age=3600', 'must-revalidate', 'private'},\n        )\n\n        @cache_control(private=False, no_cache=True, no_store=True)\n            return HttpResponse()\n\n        r = b_view(HttpRequest())\n        self.assertEqual(\n            set(r.headers['Cache-Control'].split(', ')),\n            {'max-age=0', 'no-cache', 'no-store', 'must-revalidate', 'private'},\n        )\n\n        @cache_control()\n            return HttpResponse()\n\n        r = c_view(HttpRequest())\n        self.assertEqual(\n            set(r.headers['Cache-Control'].split(', ')),\n            {'max-age=0', 'no-cache', 'no-store', 'must-revalidate', 'private'},\n        )\n"], "sample_100": ["def test_one_hot_encoder_dtype_sparse_pandas():\n    pd = pytest.importorskip('pandas')\n\n    X_df = pd.DataFrame({'A': ['a', 'b'], 'B': [1, 2]})\n    X_expected = np.array([[1., 0., 1., 0.], [0., 1., 0., 1.]], dtype='float64')\n\n    oh = OneHotEncoder(categories='auto', dtype='float64', sparse=True)\n    assert_array_equal(oh.fit_transform(X_df).toarray(), X_expected)\n    assert_array_equal(oh.fit(X_df).transform(X_df).toarray(), X_expected)\n\n    oh = OneHotEncoder(categories='auto', dtype='float64', sparse=True)\n    assert_array_equal(oh.fit_transform(X_df).toarray(), X_expected)\n    assert_array_equal(oh.fit(X_df).transform(X_df).toarray(), X_expected)\n"], "sample_77": ["    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n"], "sample_68": ["def test_bulk_update(self):\n    Restaurant.objects.bulk_create(\n        [\n            Restaurant(name=\"Sam's Shake Shack\"),\n            Restaurant(name=\"Betty's Beetroot Bar\"),\n        ]\n    )\n    self.assertEqual(Restaurant.objects.count(), 2)\n    Restaurant.objects.bulk_update(\n        [\n            Restaurant(name=\"Sam's Shake Shack\", address=\"123 Main St\"),\n            Restaurant(name=\"Betty's Beetroot Bar\", address=\"456 Elm St\"),\n        ],\n        [\"name\", \"address\"],\n    )\n    self.assertEqual(Restaurant.objects.count(), 2)\n    self.assertCountEqual(\n        Restaurant.objects.values(\"name\", \"address\"),\n        [\n            {\"name\": \"Sam's Shake Shack\", \"address\": \"123 Main St\"},\n            {\"name\": \"Betty's Beetroot Bar\", \"address\": \"456 Elm St\"},\n        ],\n    )\n"], "sample_14": ["def test_serialize_deconstructible_instances(self):\n    \"\"\"\n    Test serialization of deconstructible instances.\n    \"\"\"\n    self.assertSerializedEqual(DeconstructibleInstances())\n    self.assertSerializedEqual(DeconstructibleInstances())\n    self.assertSerializedResultEqual(\n        DeconstructibleInstances(),\n        (\"migrations.test_writer.DeconstructibleInstances()\", {'import migrations.test_writer'})\n    )\n"], "sample_57": ["    def test_custom_renderer(self):\n        \"\"\"\n        A custom renderer passed to a formset_factory() is passed to all forms\n        and ErrorList.\n        \"\"\"\n        from django.forms.renderers import Jinja2\n\n        renderer = Jinja2()\n        data = {\n            \"choices-TOTAL_FORMS\": \"2\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Zero\",\n            \"choices-0-votes\": \"\",\n            \"choices-1-choice\": \"One\",\n            \"choices-1-votes\": \"\",\n        }\n        ChoiceFormSet = formset_factory(Choice, renderer=renderer)\n        formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertEqual(formset.renderer, renderer)\n        self.assertEqual(formset.forms[0].renderer, renderer)\n        self.assertEqual(formset.management_form.renderer, renderer)\n        self.assertEqual(formset.non_form_errors().renderer, renderer)\n        self.assertEqual(formset.empty_form.renderer, renderer)\n"], "sample_151": ["def test_issue_12345():\n    \"\"\"Test that Point3D.direction_cosine and Point3D.direction_ratio work correctly.\"\"\"\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(4, 5, 6)\n    assert p1.direction_cosine(p2) == [sqrt(6)/sqrt(56), sqrt(35)/sqrt(56), sqrt(35)/sqrt(56)]\n    assert p1.direction_ratio(p2) == [3, 3, 3]\n"], "sample_43": ["def test_to_field_resolution_with_mti_multiple_levels(self):\n    \"\"\"\n    to_field resolution should correctly resolve for target models using\n    MTI with multiple levels.\n    \"\"\"\n    tests = [\n        (Manager, Bonus, 'recipient', Employee),\n        (Employee, WorkHour, 'employee', Manager),\n    ]\n    for Target, Remote, related_name, next_remote in tests:\n        with self.subTest(target_model=Target, remote_model=Remote, related_name=related_name, next_remote=next_remote):\n            o = Target.objects.create(name=\"Frida Kahlo\", gender=2, code=\"painter\", alive=False)\n            opts = {\n                'app_label': next_remote._meta.app_label,\n                'model_name': next_remote._meta.model_name,\n                'field_name': related_name,\n            }\n            request = self.factory.get(self.url, {'term': 'frida', **opts})\n            request.user = self.superuser\n            response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n            self.assertEqual(response.status_code, 200)\n            data = json.loads(response.content.decode('utf-8'))\n            self.assertEqual(data, {\n                'results': [{'id': str(o.pk), 'text': o.name}],\n                'pagination': {'more': False},\n            })\n"], "sample_38": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = '!' + UNUSABLE_PASSWORD_PREFIX + '!'\n        self.assertHTMLEqual(\n            widget.render('name', value, {'id': 'id_password'}),\n            \"\"\"\n            <div id=\"id_password\">\n                <strong>No password set.</strong>\n            </div>\n            \"\"\"\n        )\n"], "sample_79": ["def test_concat_fill_value_coord(self):\n    # Regression test for GH1298\n    ds1 = Dataset({\"foo\": (\"x\", [1, 2])}, {\"x\": [0, 1]})\n    ds2 = Dataset({\"foo\": (\"x\", [3, 4])}, {\"x\": [0, 1]})\n    expected = Dataset({\"foo\": ((\"x\", \"y\"), [[1, 2], [3, 4]])}, {\"x\": [0, 1], \"y\": [0, 1]})\n    actual = concat([ds1, ds2], dim=\"y\", fill_value=dtypes.NA)\n    assert_identical(expected, actual)\n"], "sample_135": ["def test_sort_key():\n    x, y, z = symbols('x y z')\n    assert Basic(x).sort_key() == (5, 0, 'Basic'), Basic(x).sort_key()\n    assert Basic(x, y).sort_key() == (5, 0, 'Basic'), Basic(x, y).sort_key()\n    assert Basic(x, y, z).sort_key() == (5, 0, 'Basic'), Basic(x, y, z).sort_key()\n    assert Basic(x).sort_key(order=1) == (5, 1, 'Basic'), Basic(x).sort_key(order=1)\n    assert Basic(x, y).sort_key(order=1) == (5, 1, 'Basic'), Basic(x, y).sort_key(order=1)\n    assert Basic(x, y, z).sort_key(order=1) == (5, 1, 'Basic'), Basic(x, y, z).sort_key(order=1)\n    assert Basic(x).sort_key(order=2) == (5, 2, 'Basic'), Basic(x).sort_key(order=2)\n    assert Basic(x, y).sort_key(order=2) == (5, 2, 'Basic'), Basic(x, y).sort_key(order=2)\n    assert Basic(x, y, z).sort_key(order=2) == (5, 2, 'Basic'), Basic(x, y, z).sort_key(order=2)\n    assert Basic(x).sort_key(order=3) == (5, 3, 'Basic'), Basic(x).sort_key(order=3)\n    assert Basic(x, y).sort_key(order=3) == (5, 3, 'Basic'), Basic(x, y).sort_key(order=3)\n    assert Basic(x, y, z).sort_key(order=3) == (5, 3, 'Basic'), Basic(x, y, z).sort_key(order=3)\n    assert Basic(x).sort_key(order=4) == (5, 4, 'Basic'), Basic(x).sort_key(order=4)\n    assert Basic(x, y).sort_key(order=4) == (5, 4, 'Basic'), Basic(x, y).sort_key(order=4)\n    assert Basic(x, y, z).sort_key(order=4) == (5, 4, 'Basic'), Basic(x, y, z"], "sample_159": ["def test_prefix_latex():\n    m = PREFIXES['m']\n    k = PREFIXES['k']\n    M = PREFIXES['M']\n    mu = PREFIXES['mu']\n\n    assert m._latex(None) == r'\\text{m}'\n    assert k._latex(None) == r'\\text{k}'\n    assert M._latex(None) == r'\\text{M}'\n    assert mu._latex(None) == r'\\mu'\n\n    assert m._latex_repr is None\n    k._latex_repr = r'\\mathrm{k}'\n    assert k._latex(None) == r'\\mathrm{k}'\n\n    assert mu._latex_repr == r\"\\mu\"\n    assert mu._latex(None) == r\"\\mu\"\n\n    assert kibi._latex(None) == r'\\mathrm{Y}'\n"], "sample_30": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n"], "sample_154": ["def test_lambdify_with_cupy():\n    if not cupy:\n        skip(\"CuPy not installed\")\n\n    f = lambdify(x, x**2, 'cupy')\n    assert f(2) == 4\n    assert f(2.5) == 6.25\n    assert f(-2) == 4\n    assert f(-2.5) == 6.25\n"], "sample_18": ["    def test_through_fields_with_non_unique_fields(self):\n        \"\"\"\n        ManyToManyField accepts the ``through_fields`` kwarg\n        only if an intermediary table is specified and the fields are unique.\n        \"\"\"\n        class Fan(models.Model):\n            pass\n\n        class Event(models.Model):\n            invitees = models.ManyToManyField(Fan, through='Invitation', through_fields=('invitee', 'event'))\n\n        class Invitation(models.Model):\n            event = models.ForeignKey(Event, models.CASCADE)\n            invitee = models.ForeignKey(Fan, models.CASCADE)\n            inviter = models.ForeignKey(Fan, models.CASCADE, related_name='+')\n\n        field = Event._meta.get_field('invitees')\n        self.assertEqual(field.check(from_model=Event), [\n            Error(\n                \"No subset of the fields 'event' on model 'Invitation' is unique.\",\n                hint=(\n                    'Mark a single field as unique=True or add a set of '\n                    'fields to a unique constraint (via unique_together or a '\n                    'UniqueConstraint (without condition) in the model '\n                    'Meta.constraints).'\n                ),\n                obj=field,\n                id='fields.E310',\n            ),\n        ])\n"], "sample_58": ["def test_empty_settings(self):\n    \"\"\"Test that settings_to_cmd_args_env returns an empty list and None when no settings are provided.\"\"\"\n    self.assertEqual(self.settings_to_cmd_args_env(), ([], None))\n"], "sample_73": ["def test_offsetbox_get_bbox():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100)\n    ab = AnnotationBbox(da, (0.5, 0.5), xybox=(-0.2, 0.5), xycoords='data',\n                        boxcoords=\"axes fraction\", box_alignment=(0., .5))\n    ax.add_artist(ab)\n    fig.canvas.draw()\n    renderer = fig.canvas.get_renderer()\n    bbox = ab.get_bbox(renderer)\n    assert_allclose(bbox.bounds, (0, 0, 100, 100))\n"], "sample_121": ["def test_inversion_vector():\n    p = Permutation([0, 1, 2, 3, 4])\n    q = Permutation([0, 2, 1, 3, 4])\n    r = Permutation([0, 1, 3, 2, 4])\n    assert p.inversion_vector() == [0, 0, 0, 0, 0]\n    assert q.inversion_vector() == [0, 1, 0, 0, 0]\n    assert r.inversion_vector() == [0, 0, 1, 0, 0]\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    q = Permutation([0, 2, 1, 3, 4, 5])\n    r = Permutation([0, 1, 3, 2, 4, 5])\n    assert p.inversion_vector() == [0, 0, 0, 0, 0, 0]\n    assert q.inversion_vector() == [0, 1, 0, 0, 0, 0]\n    assert r.inversion_vector() == [0, 0, 1, 0, 0, 0]\n    p = Permutation([0, 1, 2, 3, 4, 5, 6])\n    q = Permutation([0, 2, 1, 3, 4, 5, 6])\n    r = Permutation([0, 1, 3, 2, 4, 5, 6])\n    assert p.inversion_vector() == [0, 0, 0, 0, 0, 0, 0]\n    assert q.inversion_vector() == [0, 1, 0, 0, 0, 0, 0]\n    assert r.inversion_vector() == [0, 0, 1, 0, 0, 0, 0]\n    p = Permutation([0, 1, 2, 3, 4, 5, 6, 7])\n    q = Permutation([0, 2, 1, 3, 4, 5, 6, 7])\n    r = Per"], "sample_158": ["def test_get_dimension_system():\n    assert SI.get_dimension_system() == SI\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is not SI.get_unit_system(SI)\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI.get_dimension_system()\n    assert SI.get_dimension_system() is SI"], "sample_59": ["    def test_custom_renderer(self):\n        \"\"\"\n        A custom renderer passed to a formset_factory() is passed to all forms\n        and ErrorList.\n        \"\"\"\n        from django.forms.renderers import Jinja2\n\n        renderer = Jinja2()\n        data = {\n            \"choices-TOTAL_FORMS\": \"2\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Zero\",\n            \"choices-0-votes\": \"\",\n            \"choices-1-choice\": \"One\",\n            \"choices-1-votes\": \"\",\n        }\n        ChoiceFormSet = formset_factory(Choice, renderer=renderer)\n        formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertEqual(formset.renderer, renderer)\n        self.assertEqual(formset.forms[0].renderer, renderer)\n        self.assertEqual(formset.management_form.renderer, renderer)\n        self.assertEqual(formset.non_form_errors().renderer, renderer)\n        self.assertEqual(formset.empty_form.renderer, renderer)\n"], "sample_60": ["def test_serialize_deconstructable_class(self):\n    class DeconstructableClass:\n            return (\"DeconstructableClass\", [], {})\n\n    self.assertSerializedResultEqual(\n        DeconstructableClass(),\n        (\"migrations.test_writer.DeconstructableClass\", {\"import migrations.test_writer\"}),\n    )\n"], "sample_102": ["def test_iforest_max_features():\n    \"\"\"Check Isolation Forest for various max_features settings.\"\"\"\n    X_train = np.array([[0, 1], [1, 2]])\n    X_test = np.array([[2, 1], [1, 1]])\n\n    grid = ParameterGrid({\"max_features\": [1.0, 2, 0.5]})\n\n    with ignore_warnings():\n        for params in grid:\n            IsolationForest(random_state=rng, **params).fit(X_train).predict(X_test)\n"], "sample_109": ["def test_predefinedsplit():\n    # Check that PredefinedSplit can reproduce a split generated by Kfold.\n    folds = np.full(10, -1.)\n    kf_train = []\n    kf_test = []\n    for i, (train_ind, test_ind) in enumerate(KFold(5, shuffle=True).split(X)):\n        kf_train.append(train_ind)\n        kf_test.append(test_ind)\n        folds[test_ind] = i\n    ps = PredefinedSplit(folds)\n    # n_splits is simply the no of unique folds\n    assert len(np.unique(folds)) == ps.get_n_splits()\n    ps_train, ps_test = zip(*ps.split())\n    assert_array_equal(ps_train, kf_train)\n    assert_array_equal(ps_test, kf_test)\n\n    # Check that PredefinedSplit can reproduce a split generated by StratifiedKFold.\n    folds = np.full(10, -1.)\n    skf_train = []\n    skf_test = []\n    for i, (train_ind, test_ind) in enumerate(StratifiedKFold(5, shuffle=True).split(X, y)):\n        skf_train.append(train_ind)\n        skf_test.append(test_ind)\n        folds[test_ind] = i\n    ps = PredefinedSplit(folds)\n    # n_splits is simply the no of unique folds\n    assert len(np.unique(folds)) == ps.get_n_splits()\n    ps_train, ps_test = zip(*ps.split())\n    assert_array_equal(ps_train, skf_train)\n    assert_array_equal(ps_test, skf_test)\n\n    # Check that PredefinedSplit can reproduce a split generated by GroupKFold.\n    folds = np.full(10, -1.)\n    gkf_train = []\n    gkf_test = []\n    for i, (train_ind, test_ind) in enumerate(GroupKFold(5, shuffle=True).split(X, y, groups)):\n        gkf_train.append(train_ind)\n        gkf_test.append(test_ind)\n        folds[test_ind] = i\n    ps = PredefinedSplit(folds)\n    # n_splits is simply the no of unique folds\n    assert len(np.unique(folds)) == ps.get_n_splits()\n    ps_train, ps_test = zip(*ps.split())\n    assert_array_equal(ps_train, gkf_train)\n    assert_array_equal(ps_test, gkf_test)\n\n    # Check that PredefinedSplit can reproduce a split generated by TimeSeriesSplit.\n    folds = np.full(10, -1.)\n"], "sample_110": ["def test_affinity_propagation_fit_predict_error():\n    # Test exception in AffinityPropagation.fit_predict\n    # Not fitted.\n    af = AffinityPropagation(affinity=\"euclidean\")\n    with pytest.raises(ValueError):\n        af.fit_predict(X)\n\n    # Predict not supported when affinity=\"precomputed\".\n    S = np.dot(X, X.T)\n    af = AffinityPropagation(affinity=\"precomputed\")\n    af.fit(S)\n    with pytest.raises(ValueError):\n        af.fit_predict(X)\n"], "sample_39": ["    def test_include_namespace_with_variable_prefix(self):\n        \"\"\"\n        Using include() with namespaces when there is a regex variable in front of it.\n        \"\"\"\n        test_urls = [\n            ('inc-outer:inc-normal-view', [], {'outer': 42}, '/ns-outer/42/normal/'),\n            ('inc-outer:inc-normal-view', [42], {}, '/ns-outer/42/normal/'),\n            ('inc-outer:inc-normal-view', [], {'arg1': 37, 'arg2': 4, 'outer': 42}, '/ns-outer/42/normal/37/4/'),\n            ('inc-outer:inc-normal-view', [42, 37, 4], {}, '/ns-outer/42/normal/37/4/'),\n            ('inc-outer:inc-special-view', [], {'outer': 42}, '/ns-outer/42/+%5C$*/'),\n            ('inc-outer:inc-special-view', [42], {}, '/ns-outer/42/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n"]}, "raw_scored_generations": {"sample_0": [true], "sample_3": [false], "sample_2": [true], "sample_1": [true], "sample_6": [false], "sample_4": [false], "sample_5": [false], "sample_7": [false], "sample_9": [false], "sample_8": [false], "sample_10": [true], "sample_11": [false], "sample_13": [false], "sample_12": [true], "sample_14": [true], "sample_15": [true], "sample_16": [false], "sample_17": [false], "sample_18": [false], "sample_19": [false], "sample_21": [false], "sample_20": [true], "sample_23": [true], "sample_22": [false], "sample_24": [true], "sample_25": [true], "sample_28": [false], "sample_26": [false], "sample_27": [true], "sample_29": [false], "sample_31": [true], "sample_30": [false], "sample_32": [true], "sample_33": [true], "sample_34": [false], "sample_35": [false], "sample_36": [true], "sample_37": [false], "sample_39": [false], "sample_38": [false], "sample_40": [true], "sample_42": [false], "sample_41": [false], "sample_43": [true], "sample_45": [false], "sample_44": [false], "sample_46": [true], "sample_48": [false], "sample_47": [true], "sample_50": [true], "sample_49": [true], "sample_51": [true], "sample_52": [true], "sample_53": [true], "sample_55": [true], "sample_54": [false], "sample_56": [false], "sample_58": [true], "sample_57": [true], "sample_60": [false], "sample_59": [true], "sample_61": [true], "sample_63": [false], "sample_62": [false], "sample_64": [false], "sample_66": [true], "sample_65": [false], "sample_68": [true], "sample_67": [false], "sample_69": [false], "sample_70": [true], "sample_71": [true], "sample_72": [false], "sample_73": [false], "sample_74": [false], "sample_75": [false], "sample_76": [false], "sample_77": [false], "sample_78": [false], "sample_79": [false], "sample_80": [false], "sample_82": [false], "sample_81": [false], "sample_83": [false], "sample_84": [true], "sample_85": [false], "sample_86": [false], "sample_87": [true], "sample_88": [false], "sample_89": [false], "sample_90": [false], "sample_91": [true], "sample_92": [true], "sample_93": [true], "sample_95": [true], "sample_94": [false], "sample_96": [true], "sample_97": [true], "sample_98": [false], "sample_99": [false], "sample_100": [true], "sample_101": [false], "sample_102": [false], "sample_103": [false], "sample_104": [false], "sample_105": [false], "sample_107": [false], "sample_106": [false], "sample_108": [false], "sample_109": [false], "sample_110": [false], "sample_111": [false], "sample_112": [true], "sample_113": [true], "sample_114": [false], "sample_115": [true], "sample_116": [false], "sample_117": [true], "sample_118": [false], "sample_119": [false], "sample_120": [false], "sample_121": [false], "sample_122": [false], "sample_123": [false], "sample_124": [false], "sample_125": [true], "sample_126": [true], "sample_127": [true], "sample_128": [false], "sample_129": [true], "sample_130": [true], "sample_131": [false], "sample_132": [false], "sample_133": [false], "sample_134": [true], "sample_135": [false], "sample_136": [true], "sample_137": [false], "sample_138": [false], "sample_139": [true], "sample_140": [true], "sample_142": [false], "sample_141": [false], "sample_143": [false], "sample_144": [false], "sample_145": [true], "sample_146": [true], "sample_147": [false], "sample_148": [false], "sample_149": [false], "sample_150": [false], "sample_151": [false], "sample_152": [false], "sample_153": [false], "sample_154": [true], "sample_155": [false], "sample_156": [false], "sample_157": [false], "sample_158": [false], "sample_159": [false]}}