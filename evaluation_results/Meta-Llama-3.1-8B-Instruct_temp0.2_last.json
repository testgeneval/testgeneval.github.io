{"raw_generations": {"sample_200": ["    def test_email_message_repr(self):\n        email = EmailMessage('Subject', 'Content', 'from@example.com', ['to@example.com'])\n        self.assertEqual(repr(email), \"EmailMessage(subject='Subject', body='Content', from_email='from@example.com', to=['to@example.com'], bcc=[], cc=[], reply_to=[], headers={}, connection=None, attachments=[], extra_headers={}, encoding=None)\")\n"], "sample_1007": ["def test_subfactorial():\n    x = Symbol('x')\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True, nonnegative=True)\n    r = Symbol('r', integer=False)\n    s = Symbol('s', integer=False, negative=True)\n    t = Symbol('t', nonnegative=True)\n    u = Symbol('u', noninteger=True)\n\n    assert subfactorial(-2) == zoo\n    assert subfactorial(0) == 1\n    assert subfactorial(7) == 44\n    assert subfactorial(19) == 135292\n    assert subfactorial(n).func == subfactorial\n    assert subfactorial(2*n).func == subfactorial\n\n    assert subfactorial(x).is_integer is None\n    assert subfactorial(n).is_integer is None\n    assert subfactorial(k).is_integer\n    assert subfactorial(r).is_integer is None\n\n    assert subfactorial(n).is_positive is None\n    assert subfactorial(k).is_positive\n\n    assert subfactorial(x).is_real is None\n    assert subfactorial(n).is_real is None\n    assert subfactorial(k).is_real is True\n    assert subfactorial(r).is_real is None\n    assert subfactorial(s).is_real is True\n    assert subfactorial(t).is_real is True\n    assert subfactorial(u).is_real is True\n\n    assert subfactorial(x).is_composite is None\n    assert subfactorial(n).is_composite is None\n    assert subfactorial(k).is_composite is None\n    assert subfactorial(k + 3).is_composite is True\n    assert subfactorial(r).is_composite is None\n    assert subfactorial(s).is_composite is None\n    assert subfactorial(t).is_composite is None\n    assert subfactorial(u).is_composite is None\n\n    assert subfactorial(oo) == oo\n\n    assert subfactorial(n).diff(n) == \\\n        subfactorial(n - 1) + subfactorial(n - 2)\n\n    assert subfactorial(n).series(n, 0, 3) == \\\n        1 - n + n**2*(EulerGamma - 1/2) + O(n**3)\n\n    assert subfactorial(n).rewrite"], "sample_55": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n\n        cls.s1 = State.objects.create(name='New York')\n        cls.s2 = State.objects.create(name='Illinois')\n        cls.s3 = State.objects.create(name='California')\n        cls.c1 = City.objects.create(state=cls.s1, name='New York')\n        cls.c2 = City.objects.create(state=cls.s2, name='Chicago')\n        cls.c3 = City.objects.create(state=cls.s3, name='San Francisco')\n        cls.r1 = Restaurant.objects.create(city=cls.c1, name='Italian Pizza')\n        cls.r2 = Restaurant.objects.create(city=cls.c1, name='Boulevard')\n        cls.r3 = Restaurant.objects.create(city=cls.c2, name='Chinese Dinner')\n        cls.r4 = Restaurant.objects.create(city=cls.c2, name='Angels')\n        cls.r5 = Restaurant.objects.create(city=cls.c2, name='Take Away')\n        cls.r6 = Restaurant.objects.create(city=cls.c3, name='The Unknown Restaurant')\n        cls.w1 = Worker.objects.create(work_at=cls.r1, name='Mario', surname='Rossi')\n        cls.w2 = Worker.objects.create(work_at=cls.r1, name='Antonio', surname='Bianchi')\n        cls.w3 = Worker.objects.create(work_at=cls.r1, name='John', surname='Doe')\n"], "sample_744": ["def test_power_transformer_axis1():\n    X = np.abs(X_2d)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method='box-cox', standardize=standardize)\n\n        X_trans_class = pt.fit_transform(X.T).T\n        X_trans_func = power_transform(X.T, standardize=standardize).T\n\n        for X_trans in [X_trans_class, X_trans_func]:\n            for i in range(X_trans.shape[0]):\n                X_expected, lmbda = stats.boxcox(X_trans[i, :].flatten())\n\n                if standardize:\n                    X_expected = scale(X_expected)\n\n                assert_almost_equal(X_trans[i, :], X_expected)\n                assert_almost_equal(lmbda, pt.lambdas_[i])\n\n            # Test inverse transformation\n            X_inv = pt.inverse_transform(X_trans)\n            assert_array_almost_equal(X_inv, X)\n\n        assert len(pt.lambdas_) == X.shape[0]\n        assert isinstance(pt.lambdas_, np.ndarray)\n"], "sample_908": ["def test_unparse_arguments():\n    source = \"\"\"\n            pass\n    \"\"\"\n    expected = \"a, b, c=1, *, d, e=2\"\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].args) == expected\n"], "sample_1060": ["def test_print_Relational():\n    p = PythonCodePrinter()\n    assert p.doprint(Eq(x, y)) == '(x == y)'\n    assert p.doprint(Le(x, y)) == '(x <= y)'\n    assert p.doprint(Gt(x, y)) == '(x > y)'\n    assert p.doprint(x != y) == '(x != y)'\n    assert p.doprint(x == y) == '(x == y)'\n    assert p.doprint(x > y) == '(x > y)'\n    assert p.doprint(x < y) == '(x < y)'\n    assert p.doprint(x >= y) == '(x >= y)'\n    assert p.doprint(x <= y) == '(x <= y)'\n"], "sample_693": ["def test_teardown_class_failure_is_shown(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n        class MyTestCase(unittest.TestCase):\n                assert 0, \"down1\"\n            @classmethod\n                assert 0, \"down2\"\n                pass\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-s\")\n    assert result.ret == 1\n    result.stdout.fnmatch_lines(\n        [\n            \"*setUp*\",\n            \"*assert 0*down1*\",\n            \"*tearDownClass*\",\n            \"*assert 0*down2*\",\n            \"*1 failed*\",\n        ]\n    )\n"], "sample_488": ["    def test_lazy_model_operation(self):\n        \"\"\"\n        Tests apps.lazy_model_operation().\n        \"\"\"\n        model_classes = []\n        initial_pending = set(apps._pending_operations)\n\n            model_classes[:] = models\n\n        class LazyA(models.Model):\n            pass\n\n        # Test models appearing twice, and models appearing consecutively\n        model_keys = [\n            (\"apps\", model_name)\n            for model_name in [\"lazya\", \"lazyb\", \"lazyb\", \"lazyc\", \"lazya\"]\n        ]\n        apps.lazy_model_operation(test_func, *model_keys)\n\n        # LazyModelA shouldn't be waited on since it's already registered,\n        # and LazyModelC shouldn't be waited on until LazyModelB exists.\n        self.assertEqual(\n            set(apps._pending_operations) - initial_pending, {(\"apps\", \"lazyb\")}\n        )\n\n        # Multiple operations can wait on the same model\n        apps.lazy_model_operation(test_func, (\"apps\", \"lazyb\"))\n\n        class LazyB(models.Model):\n            pass\n\n        self.assertEqual(model_classes, [LazyB])\n\n        # Now we are just waiting on LazyModelC.\n        self.assertEqual(\n            set(apps._pending_operations) - initial_pending, {(\"apps\", \"lazyc\")}\n        )\n\n        class LazyC(models.Model):\n            pass\n\n        # Everything should be loaded - make sure the callback was executed properly.\n        self.assertEqual(model_classes, [LazyA, LazyB, LazyB, LazyC, LazyA])\n"], "sample_572": ["    def test_binwidth_roundoff(self, rng):\n\n        x = np.array([2.4, 2.5, 2.6])\n        h = Histogram(binwidth=0.01)\n        bin_kws = h.define_bin_params(x)\n        assert bin_kws[\"range\"] == (x.min(), x.max())\n        assert np.all(np.diff(bin_kws[\"bins\"]) == 0.01)\n"], "sample_416": ["def test_empty_settings(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env(\n            {\n                \"OPTIONS\": {\n                    \"sslmode\": \"verify-ca\",\n                    \"sslrootcert\": \"root.crt\",\n                    \"sslcert\": \"client.crt\",\n                    \"sslkey\": \"client.key\",\n                },\n            }\n        ),\n        (\n            [\"psql\"],\n            {\n                \"PGSSLMODE\": \"verify-ca\",\n                \"PGSSLROOTCERT\": \"root.crt\",\n                \"PGSSLCERT\": \"client.crt\",\n                \"PGSSLKEY\": \"client.key\",\n            },\n        ),\n    )\n"], "sample_1114": ["def test_ImageSet_iterable():\n    from sympy.abc import n, m\n    from sympy import I\n    assert imageset(Lambda(n, n), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + I), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + I*n), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + I*n + 1), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + I*n + 1 + I), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + I*n + 1 + I*n), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + I*n + 1 + I*n + I), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + I*n + 1 + I*n + I*n), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + I*n + 1 + I*n + I*n + I), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + I*n + 1 + I*n + I*n + I*n), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + I*n + 1 + I*n + I*n + I*n + I), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + I*n + 1 + I*n + I*n + I*n + I*n), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + I*n + 1 + I*n + I*n + I*n + I*n + I), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + I*n + 1 + I*n + I*n + I*n + I*n + I*n), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + I*n + 1 + I*n + I*n + I*n + I*n + I*n + I), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + I*n + 1 + I*n + I*n + I*n + I*n + I*n + I*n), S"], "sample_5": ["def test_models_repr(model):\n    if not HAS_SCIPY and model['class'] in SCIPY_MODELS:\n        pytest.skip()\n\n    m = model['class'](**model['parameters'])\n    assert str(m) == param_repr_oneline(m)\n"], "sample_1029": ["def test_MonogenicFiniteExtension():\n    assert srepr(FiniteExtension(Poly(x**2 + 1, x, domain='ZZ'))) == \\\n        \"FiniteExtension(Poly(x**2 + 1, x, domain='ZZ'))\"\n    assert srepr(FiniteExtension(Poly(x**2 + 1, x, domain='QQ'))) == \\\n        \"FiniteExtension(Poly(x**2 + 1, x, domain='QQ'))\"\n"], "sample_738": ["def test_vectorizer_dtype():\n    # test that the dtype of the output is preserved\n    vect = CountVectorizer(dtype=np.float32)\n    X = vect.fit_transform(ALL_FOOD_DOCS)\n    assert_equal(X.dtype, np.float32)\n\n    vect = HashingVectorizer(dtype=np.float64)\n    X = vect.transform(ALL_FOOD_DOCS)\n    assert_equal(X.dtype, np.float64)\n\n    vect = TfidfVectorizer(dtype=np.float32)\n    X = vect.fit_transform(ALL_FOOD_DOCS)\n    assert_equal(X.dtype, np.float32)\n"], "sample_272": ["def test_migrate_marks_replacement_applied_even_if_it_did_nothing_with_replacements(self):\n    \"\"\"\n    A new squash migration will be marked as applied even if all its replaced\n    migrations were previously already applied, and the replacement migration\n    itself does nothing.\n    \"\"\"\n    recorder = MigrationRecorder(connection)\n    # Record all replaced migrations as applied\n    recorder.record_applied(\"migrations\", \"0001_initial\")\n    recorder.record_applied(\"migrations\", \"0002_second\")\n    # Create a replacement migration that does nothing\n    executor = MigrationExecutor(connection)\n    executor.loader.replacements[(\"migrations\", \"0001_squashed_0002\")] = [\n        (\"migrations\", \"0001_initial\"),\n        (\"migrations\", \"0002_second\"),\n    ]\n    executor.migrate([(\"migrations\", \"0001_squashed_0002\")])\n\n    # Because 0001 and 0002 are both applied, even though this migrate run\n    # didn't apply anything new, their squashed replacement should be marked as\n    # applied.\n    self.assertIn(\n        (\"migrations\", \"0001_squashed_0002\"),\n        recorder.applied_migrations(),\n    )\n"], "sample_234": ["def test_difference_with_distinct(self):\n    qs1 = Number.objects.filter(num__lt=10).distinct()\n    qs2 = Number.objects.filter(num__lt=9)\n    self.assertNumbersEqual(qs1.difference(qs2), [9], ordered=False)\n"], "sample_312": ["def test_add_squash(self):\n    # start with the same children of node1 then add an item\n    node3 = Node(self.node1_children)\n    node3_added_child = ('c', 3)\n    # add() returns the added data when squash is False\n    self.assertEqual(node3.add(node3_added_child, Node.default, squash=False), node3_added_child)\n    # we added exactly one item, len() should reflect that\n    self.assertEqual(len(self.node1) + 1, len(node3))\n    self.assertEqual(str(node3), \"(DEFAULT: ('a', 1), ('b', 2), ('c', 3))\")\n"], "sample_584": ["    def test_combine_by_coords_with_no_variables(self):\n        ds1 = Dataset({'x': [0]})\n        ds2 = Dataset({'y': [1]})\n        actual = combine_by_coords([ds1, ds2])\n        expected = Dataset({'x': [0], 'y': [1]})\n        assert_identical(expected, actual)\n"], "sample_1138": ["def test_TR22():\n    assert TR22(1 + tan(x)**2) == sec(x)**2\n    assert TR22(1 + cot(x)**2) == csc(x)**2\n    assert TR22(tan(x)**2) == sec(x)**2 - 1\n    assert TR22(cot(x)**2) == csc(x)**2 - 1\n    assert TR22(1 + tan(x)**3) == sec(x)**3\n    assert TR22(1 + cot(x)**3) == csc(x)**3\n    assert TR22(tan(x)**3) == sec(x)**3 - 3*sec(x)\n    assert TR22(cot(x)**3) == csc(x)**3 - 3*csc(x)\n    assert TR22(1 + tan(x)**4) == sec(x)**4\n    assert TR22(1 + cot(x)**4) == csc(x)**4\n    assert TR22(tan(x)**4) == sec(x)**4 - 6*sec(x)**2 + 3\n    assert TR22(cot(x)**4) == csc(x)**4 - 6*csc(x)**2 + 3\n"], "sample_329": ["    def test_register_unregister_serializer(self):\n        class ComplexSerializer(BaseSerializer):\n                return 'complex(%r)' % self.value, {}\n        Serializer.register(models.Model, ComplexSerializer)\n        self.assertIn(models.Model, Serializer._registry)\n        self.assertEqual(Serializer._registry[models.Model], ComplexSerializer)\n        Serializer.unregister(models.Model)\n        self.assertNotIn(models.Model, Serializer._registry)\n"], "sample_1170": ["def test_Dict_printing():\n    d = Dict({1: 1 + x, 2: y*x})\n    assert str(d) == \"{1: x + 1, 2: x*y}\"\n    assert sstr(d) == \"{1: x + 1, 2: x*y}\"\n"], "sample_18": ["    def setup_class(self):\n        self.q = u.Quantity(np.arange(1.0, 5.0), \"m/s\")\n        self.q.info.name = \"v\"\n        self.q.info.description = \"air speed of a african swallow\"\n"], "sample_184": ["    def test_index_with_condition_and_include(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                indexes = [\n                    models.Index(\n                        fields=['age'],\n                        name='index_age_gte_10',\n                        condition=models.Q(age__gte=10),\n                        include=['id'],\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_partial_indexes else [\n            Warning(\n                '%s does not support indexes with conditions.' % connection.display_name,\n                hint=(\n                    \"Conditions will be ignored. Silence this warning if you \"\n                    \"don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W037',\n            )\n        ]\n        expected += [] if connection.features.supports_covering_indexes else [\n            Warning(\n                '%s does not support indexes with non-key columns.' % connection.display_name,\n                hint=(\n                    \"Non-key columns will be ignored. Silence this warning if \"\n                    \"you don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W040',\n            ),\n        ]\n        self.assertEqual(errors, expected)\n"], "sample_39": ["def test_sip_with_altkey():\n    \"\"\"\n    Test that when creating a WCS object using a key, CTYPE with\n    that key is looked at and not the primary CTYPE.\n    fix for #5443.\n    \"\"\"\n    with fits.open(get_pkg_data_filename('data/sip.fits')) as f:\n        w = wcs.WCS(f[0].header)\n    # create a header with two WCSs.\n    h1 = w.to_header(relax=True, key='A')\n    h2 = w.to_header(relax=False)\n    h1['CTYPE1A'] = \"RA---SIN-SIP\"\n    h1['CTYPE2A'] = \"DEC--SIN-SIP\"\n    h1.update(h2)\n    w = wcs.WCS(h1, key='A')\n    assert (w.wcs.ctype == np.array(['RA---SIN-SIP', 'DEC--SIN-SIP'])).all()\n"], "sample_45": ["def test_trunc_func_with_timezone_applied_before_truncation(self):\n    start_datetime = datetime(2016, 1, 1, 1, 30, 50, 321)\n    end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n\n    melb = pytz.timezone('Australia/Melbourne')\n    pacific = pytz.timezone('US/Pacific')\n\n    model = DTModel.objects.annotate(\n        melb_year=TruncYear('start_datetime', tzinfo=melb, is_dst=False),\n        pacific_year=TruncYear('start_datetime', tzinfo=pacific, is_dst=False),\n    ).order_by('start_datetime').get()\n\n    self.assertEqual(model.start_datetime, start_datetime)\n    self.assertEqual(model.melb_year, truncate_to(start_datetime, 'year', melb))\n    self.assertEqual(model.pacific_year, truncate_to(start_datetime, 'year', pacific))\n    self.assertEqual(model.start_datetime.year, 2016)\n    self.assertEqual(model.melb_year.year, 2016)\n    self.assertEqual(model.pacific_year.year, 2015)\n\n    model = DTModel.objects.annotate(\n        melb_year=TruncYear('start_datetime', tzinfo=melb, is_dst=True),\n        pacific_year=TruncYear('start_datetime', tzinfo=pacific, is_dst=True),\n    ).order_by('start_datetime').get()\n\n    self.assertEqual(model.start_datetime, start_datetime)\n    self.assertEqual(model.melb_year, truncate_to(start_datetime, 'year', melb))\n    self.assertEqual(model.pacific_year, truncate_to(start_datetime, 'year', pacific))\n    self.assertEqual(model.start_datetime.year, 2016)\n    self.assertEqual(model.melb_year.year, 2016)\n    self.assertEqual(model.pacific_year.year, 2015)\n"], "sample_686": ["def test_pytest_collect_directory_hook_is_deprecated(testdir):\n    \"\"\"Check that pytest_collect_directory hook is deprecated\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    with pytest.warns(PytestDeprecationWarning, match=\"The pytest_collect_directory hook is not working\"):\n        testdir.runpytest()\n"], "sample_391": ["def test_create_model_rename_field_not_through_m2m_through(self):\n    \"\"\"\n    RenameField should NOT optimize into CreateModel if it's an M2M using a\n    through that's created between them.\n    \"\"\"\n    self.assertDoesNotOptimize(\n        [\n            migrations.CreateModel(\"Employee\", []),\n            migrations.CreateModel(\"Employer\", []),\n            migrations.CreateModel(\n                \"Employment\",\n                [\n                    (\n                        \"employee\",\n                        models.ForeignKey(\"migrations.Employee\", models.CASCADE),\n                    ),\n                    (\n                        \"employment\",\n                        models.ForeignKey(\"migrations.Employer\", models.CASCADE),\n                    ),\n                ],\n            ),\n            migrations.AddField(\n                \"Employer\",\n                \"employees\",\n                models.ManyToManyField(\n                    \"migrations.Employee\",\n                    through=\"migrations.Employment\",\n                ),\n            ),\n            migrations.RenameField(\"Employment\", \"employee\", \"employee2\"),\n        ],\n    )\n"], "sample_688": ["    def test_importlib_imports_from_sibling_package(self, testdir):\n        \"\"\"--import-mode=importlib can import modules from sibling packages.\"\"\"\n        testdir.makepyfile(\n            **{\n                \"tests/test_foo.py\": \"def test_foo(): pass\",\n                \"tests/subpkg/__init__.py\": \"\",\n                \"tests/subpkg/test_bar.py\": \"def test_bar(): pass\",\n            }\n        )\n        result = testdir.runpytest(\"-v\", \"--import-mode=importlib\")\n        result.stdout.fnmatch_lines(\n            [\n                \"tests/test_foo.py::test_foo *\",\n                \"tests/subpkg/test_bar.py::test_bar *\",\n                \"* 2 passed in *\",\n            ]\n        )\n"], "sample_888": ["def test_iforest_offset():\n    \"\"\"Test that the offset is correctly calculated.\"\"\"\n    X_train = [[1, 1], [1, 2], [2, 1]]\n    clf = IsolationForest(contamination=0.1).fit(X_train)\n    assert clf.offset_ == -0.5\n\n    clf = IsolationForest(contamination=0.5).fit(X_train)\n    assert clf.offset_ == -0.5\n\n    clf = IsolationForest(contamination=0.0).fit(X_train)\n    assert clf.offset_ == -0.5\n\n    clf = IsolationForest(contamination=0.25).fit(X_train)\n    assert clf.offset_ == -0.5\n\n    clf = IsolationForest(contamination=\"auto\").fit(X_train)\n    assert clf.offset_ == -0.5\n"], "sample_1148": ["def test_matrix_derivative():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    D = MatrixSymbol('D', 2, 2)\n    E = MatrixSymbol('E', 2, 2)\n    w = MatrixSymbol('w', 2, 1)\n\n    dexpr = diff((D*w)[0,0], w[0,0])\n    assert dexpr == KroneckerDelta(0, 0, (0, 1))*KroneckerDelta(0, 0, (0, 1))\n\n    dexpr = diff((D*w)[0,0], w[1,0])\n    assert dexpr == KroneckerDelta(0, 1, (0, 1))*KroneckerDelta(0, 0, (0, 1))\n\n    dexpr = diff((D*w)[1,0], w[0,0])\n    assert dexpr == KroneckerDelta(1, 0, (0, 1))*KroneckerDelta(0, 0, (0, 1))\n\n    dexpr = diff((D*w)[1,0], w[1,0])\n    assert dexpr == KroneckerDelta(1, 1, (0, 1))*KroneckerDelta(0, 0, (0, 1))\n\n    dexpr = diff((D*w)[0,0], w[0,0])\n    dexpr = dexpr.doit()\n    assert dexpr == 1\n\n    dexpr = diff((D*w)[0,0], w[1,0])\n    dexpr = dexpr.doit()\n    assert dexpr == 0\n\n    dexpr = diff((D*w)[1,0], w[0,0])\n    dexpr = dexpr.doit()\n    assert dexpr == 0\n\n    dexpr = diff((D*w)[1,0], w[1,0])\n    dexpr = dexpr.doit()\n    assert dexpr == 1\n\n    dexpr = diff((D*w)[0,0], w[0,0])\n    dexpr = dexpr.doit()\n    assert dexpr == 1\n\n    dexpr = diff((D*w)[0,0], w[1"], "sample_802": ["def test_pipeline_memory_cache_hit():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        if LooseVersion(joblib_version) < LooseVersion('0.12'):\n            # Deal with change of API in joblib\n            memory = Memory(cachedir=cachedir, verbose=10)\n        else:\n            memory = Memory(location=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(gamma='scale', probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', clone(transf)), ('svc', clf)])\n        cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n                               memory=memory)\n\n        # Memoize the transformer at the first fit\n        cached_pipe.fit(X, y)\n        # Check that we are reading the cache while fitting\n        # a second time\n        cached_pipe.fit(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert_equal(time.time(), cached_pipe.named_steps['transf'].timestamp_)\n    finally:\n        shutil.rmtree(cachedir)\n"], "sample_1089": ["def test_issue_1234():\n    x, y = symbols('x,y')\n    assert factor_terms(x + y) == x + y\n    assert factor_terms(x + y, clear=False) == x + y\n    assert factor_terms(x + y, clear=True) == x + y\n    assert factor_terms(x + y, fraction=True) == x + y\n    assert factor_terms(x + y, fraction=False) == x + y\n    assert factor_terms(x + y, sign=True) == x + y\n    assert factor_terms(x + y, sign=False) == x + y\n"], "sample_647": ["def test_unformatted_warning_formatting(pytester: Pytester) -> None:\n    \"\"\"Test that UnformattedWarning is formatted correctly.\"\"\"\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        from _pytest.warning_types import UnformattedWarning\n\n            warning = UnformattedWarning(\n                category=pytest.PytestWarning,\n                template=\"This is a warning with a variable: {var}\"\n            )\n            assert str(warning) == \"pytest.PytestWarning: This is a warning with a variable: var\"\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines([\"*This is a warning with a variable: var\"])\n"], "sample_359": ["    def test_references_field_by_through_model(self):\n        operation = FieldOperation('Model', 'field', models.ManyToManyField('Other', through='Through'))\n        self.assertIs(operation.references_field('Other', 'whatever', 'migrations'), True)\n        self.assertIs(operation.references_field('Through', 'whatever', 'migrations'), True)\n        self.assertIs(operation.references_field('Missing', 'whatever', 'migrations'), False)\n"], "sample_14": ["def test_angle_to_quantity_with_non_angular_unit():\n    \"\"\"\n    Test that creating a Quantity from an Angle with a non-angular unit raises an error.\n    \"\"\"\n    with pytest.raises(u.UnitsError):\n        Angle(1.0*u.m).to(u.Quantity)\n"], "sample_465": ["    def setUpTestData(cls):\n        cls.band = Band.objects.create(\n            name=\"The Doors\",\n            bio=\"\",\n            sign_date=date(1965, 1, 1),\n        )\n"], "sample_273": ["    def test_collision_in_same_model(self):\n        class Model(models.Model):\n            class Meta:\n                unique_together = [('id', 'name')]\n\n            id = models.AutoField(primary_key=True)\n            name = models.CharField(max_length=20)\n\n        self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [\n            Error(\n                \"unique_together 'id, name' is not unique for model \"\n                \"check_framework.Model.\",\n                id='models.E011',\n            ),\n        ])\n"], "sample_1050": ["def test_SymPyPrinter():\n    p = SymPyPrinter()\n    assert p.doprint(x**y) == 'sympy.Symbol(x)**sympy.Symbol(y)'\n    assert p.doprint(Mod(x, 2)) == 'sympy.Mod(x, 2)'\n    assert p.doprint(And(x, y)) == 'sympy.And(x, y)'\n    assert p.doprint(Or(x, y)) == 'sympy.Or(x, y)'\n    assert p.doprint(acos(x)) == 'sympy.acos(x)'\n    assert p.doprint(Assignment(x, 2)) == 'sympy.Symbol(x) = 2'\n    assert p.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert p.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        '(3) if (x > 0) else None)'\n    assert p.doprint(sign(x)) == '(0.0 if x == 0 else sympy.copysign(1, x))'\n    assert p.doprint(p[0, 1]) == 'sympy.Symbol(p)[0, 1]'\n"], "sample_793": ["def test_iforest_max_features():\n    \"\"\"Check Isolation Forest for various max_features settings.\"\"\"\n    X_train = np.array([[0, 1], [1, 2]])\n    X_test = np.array([[2, 1], [1, 1]])\n\n    grid = ParameterGrid({\"max_features\": [1.0, 2, 3]})\n\n    with ignore_warnings():\n        for params in grid:\n            IsolationForest(random_state=rng,\n                            max_samples=0.5,\n                            **params).fit(X_train).predict(X_test)\n"], "sample_52": ["def test_limit_choices_to(self):\n    class ModelChoiceForm(forms.Form):\n        category = forms.ModelChoiceField(Category.objects.all(), limit_choices_to={'name__startswith': 'A'})\n\n            super().__init__(*args, **kwargs)\n            self.fields['category'].queryset = Category.objects.filter(slug__contains='test')\n\n    form = ModelChoiceForm()\n    self.assertEqual(list(form.fields['category'].choices), [\n        ('', '---------'),\n        (self.c2.pk, 'A test'),\n    ])\n    self.assertEqual(form.fields['category'].queryset.count(), 1)\n    self.assertEqual(form.fields['category'].queryset.get().name, 'A test')\n"], "sample_726": ["def test_label_binarize_multiclass_thresholding():\n    y = [0.5, 0.7, 0.3]\n    classes = [0, 1, 2]\n    pos_label = 2\n    neg_label = 0\n    threshold = 0.6\n    expected = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0]])\n\n    yield check_binarized_results, y, classes, pos_label, neg_label, expected\n\n    y = [0.5, 0.7, 0.3]\n    classes = [0, 1, 2]\n    pos_label = 2\n    neg_label = 0\n    threshold = 0.4\n    expected = np.array([[0, 1, 0], [1, 0, 0], [0, 0, 1]])\n\n    yield check_binarized_results, y, classes, pos_label, neg_label, expected\n\n    assert_raises(ValueError, label_binarize, y, classes, neg_label=-1,\n                  pos_label=pos_label, sparse_output=True)\n"], "sample_1028": ["def test_Mod_is_zero():\n    x, y = symbols('x y', zero=True)\n    assert (x % y).is_zero\n    assert (y % x).is_zero\n    assert (x % x).is_zero\n    assert (y % y).is_zero\n    assert (x % 0).is_zero is False\n    assert (0 % x).is_zero is False\n    assert (0 % 0).is_zero\n"], "sample_441": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = UNUSABLE_PASSWORD_PREFIX + \"123456789012345678901234567890\"\n        self.assertHTMLEqual(\n            widget.render(\"name\", value, {\"id\": \"id_password\"}),\n            '<div id=\"id_password\">'\n            \"    <strong>algorithm</strong>: <bdi>unknown</bdi>\"\n            \"    <strong>iterations</strong>: <bdi>unknown</bdi>\"\n            \"    <strong>salt</strong>: <bdi>123456789012345678901234567890</bdi>\"\n            \"    <strong>hash</strong>: \"\n            \"       <bdi>unknown</bdi>\"\n            \"</div>\",\n        )\n"], "sample_521": ["def test_scatter3d_sorting():\n    \"\"\"Test that marker properties are correctly sorted.\"\"\"\n    y, x = np.mgrid[:10, :10]\n    z = np.arange(x.size).reshape(x.shape)\n\n    sizes = np.full(z.shape, 25)\n    sizes[0::2, 0::2] = 100\n    sizes[1::2, 1::2] = 100\n\n    facecolors = np.full(z.shape, 'C0')\n    facecolors[:5, :5] = 'C1'\n    facecolors[6:, :4] = 'C2'\n    facecolors[6:, 6:] = 'C3'\n\n    edgecolors = np.full(z.shape, 'C4')\n    edgecolors[1:5, 1:5] = 'C5'\n    edgecolors[5:9, 1:5] = 'C6'\n    edgecolors[5:9, 5:9] = 'C7'\n\n    linewidths = np.full(z.shape, 2)\n    linewidths[0::2, 0::2] = 5\n    linewidths[1::2, 1::2] = 5\n\n    x, y, z, sizes, facecolors, edgecolors, linewidths = [\n        a.flatten()\n        for a in [x, y, z, sizes, facecolors, edgecolors, linewidths]\n    ]\n\n    ax = plt.figure().add_subplot(projection='3d')\n    ax.scatter(x, y, z, s=sizes, fc=facecolors, ec=edgecolors,\n               lw=linewidths, alpha=1)\n    ax.view_init(elev=0, azim=0, roll=0)\n    ax.set_xlim(-1, 11)\n    ax.set_ylim(-1, 11)\n    ax.set_zlim(-1, 11)\n"], "sample_490": ["    def test_deconstruction_with_expressions_and_fields(self):\n        fields = [\"foo\", \"bar\"]\n        name = \"unique_fields\"\n        constraint = models.UniqueConstraint(fields=fields, name=name)\n        path, args, kwargs = constraint.deconstruct()\n        self.assertEqual(path, \"django.db.models.UniqueConstraint\")\n        self.assertEqual(args, ())\n        self.assertEqual(kwargs, {\"fields\": tuple(fields), \"name\": name})\n"], "sample_141": ["    def _validate_output(serial_str):\n        try:\n            json.loads(serial_str)\n        except Exception:\n            return False\n        else:\n            return True\n"], "sample_626": ["    def test_sel(self) -> None:\n        index = PandasMultiIndex(\n            pd.MultiIndex.from_product([[\"a\", \"b\"], [1, 2]], names=(\"one\", \"two\")),\n            \"x\",\n        )\n\n        # test tuples inside slice are considered as scalar indexer values\n        actual = index.sel({\"x\": slice((\"a\", 1), (\"b\", 2))})\n        expected_dim_indexers = {\"x\": slice(0, 4)}\n        assert actual.dim_indexers == expected_dim_indexers\n\n        with pytest.raises(KeyError, match=r\"not all values found\"):\n            index.sel({\"x\": [0]})\n        with pytest.raises(KeyError):\n            index.sel({\"x\": 0})\n        with pytest.raises(ValueError, match=r\"cannot provide labels for both.*\"):\n            index.sel({\"one\": 0, \"x\": \"a\"})\n        with pytest.raises(ValueError, match=r\"invalid multi-index level names\"):\n            index.sel({\"x\": {\"three\": 0}})\n        with pytest.raises(IndexError):\n            index.sel({\"x\": (slice(None), 1, \"no_level\")})\n\n        # test boolean indexing\n        actual = index.sel({\"x\": {\"one\": True, \"two\": False}})\n        expected_dim_indexers = {\"x\": {\"one\": True, \"two\": False}}\n        assert actual.dim_indexers == expected_dim_indexers\n\n        # test datetime indexing\n        index = PandasMultiIndex(\n            pd.MultiIndex.from_product(\n                [pd.to_datetime([\"2000-01-01\", \"2001-01-01\"]), [1, 2]],\n                names=(\"one\", \"two\"),\n            ),\n            \"x\",\n        )\n        actual = index.sel({\"x\": \"2001-01-01\"})\n        expected_dim_indexers = {\"x\": 1}\n        assert actual.dim_indexers == expected_dim_indexers\n\n        actual = index.sel({\"x\": index.to_pandas_index().to_numpy()[1]})\n        assert actual.dim_indexers == expected_dim_indexers\n\n        # test unsorted datetime index raises\n        index = PandasMultiIndex(\n            pd.MultiIndex.from_product(\n                [pd.to_datetime([\"2001\", \"2000\", \"2002\"]), [1, 2]],\n                names=(\"one\", \"two\"),\n            ),\n            \"x\",\n        )\n        with pytest.raises(KeyError):\n            # pandas will try to"], "sample_204": ["def test_loading_squashed_multiple_replacements(self):\n    \"\"\"\n    Tests loading a squashed migration with multiple replacements.\n    \"\"\"\n    loader = MigrationLoader(connection)\n    recorder = MigrationRecorder(connection)\n    self.addCleanup(recorder.flush)\n\n    # Load with nothing applied: both migrations squashed.\n    loader.build_graph()\n    plan = set(loader.graph.forwards_plan(('migrations', '3_auto')))\n    plan = plan - loader.applied_migrations.keys()\n    expected_plan = {\n        ('migrations', '1_auto'),\n        ('migrations', '2_auto'),\n        ('migrations', '3_auto'),\n    }\n    self.assertEqual(plan, expected_plan)\n\n    # Fake-apply a few: unsquashes migration in migrations.\n    recorder.record_applied('migrations', '1_auto')\n    loader.build_graph()\n    plan = set(loader.graph.forwards_plan(('migrations', '3_auto')))\n    plan = plan - loader.applied_migrations.keys()\n    expected_plan = {\n        ('migrations', '2_auto'),\n        ('migrations', '3_auto'),\n    }\n    self.assertEqual(plan, expected_plan)\n\n    # Fake-apply another: unsquashes migration in migrations.\n    recorder.record_applied('migrations', '2_auto')\n    loader.build_graph()\n    plan = set(loader.graph.forwards_plan(('migrations', '3_auto')))\n    plan = plan - loader.applied_migrations.keys()\n    expected_plan = {\n        ('migrations', '3_auto'),\n    }\n    self.assertEqual(plan, expected_plan)\n"], "sample_984": ["def test_MatPow():\n    from sympy import MatrixSymbol\n    M = MatrixSymbol('X', 2, 2)\n    assert str(M**2) == 'X**2'\n    assert str(M**3) == 'X**3'\n    assert str(M**-1) == 'X**(-1)'\n    assert str(M**-2) == 'X**(-2)'\n"], "sample_422": ["    def test_m2m_forward_limit(self):\n        authors = Author.objects.all()[:2]  # Meta.ordering\n        with self.assertNumQueries(3):\n            books = list(\n                Book.objects.prefetch_related(\n                    Prefetch(\"authors\", authors),\n                    Prefetch(\"authors\", authors[1:], to_attr=\"authors_sliced\"),\n                )\n            )\n        for book in books:\n            with self.subTest(book=book):\n                self.assertEqual(book.authors_sliced, list(book.authors.all())[1:])\n"], "sample_1100": ["def test_Pow_is_zero_2():\n    z = Symbol('z', zero=True)\n    e = z**2\n    assert e.is_zero\n    assert e.is_positive is False\n    assert e.is_negative is False\n\n    assert Pow(0, 0, evaluate=False).is_zero is False\n    assert Pow(0, 3, evaluate=False).is_zero\n    assert Pow(0, oo, evaluate=False).is_zero\n    assert Pow(0, -3, evaluate=False).is_zero is False\n    assert Pow(0, -oo, evaluate=False).is_zero is False\n    assert Pow(2, 2, evaluate=False).is_zero is False\n\n    a = Symbol('a', zero=False)\n    assert Pow(a, 3).is_zero is False  # issue 7965\n\n    assert Pow(2, oo, evaluate=False).is_zero is False\n    assert Pow(2, -oo, evaluate=False).is_zero\n    assert Pow(S.Half, oo, evaluate=False).is_zero\n    assert Pow(S.Half, -oo, evaluate=False).is_zero is False\n"], "sample_226": ["    def test_serialize_db_to_string(self):\n        # serialize_db_to_string() handles large amounts of data.\n        obj_1 = Object.objects.create()\n        obj_2 = Object.objects.create()\n        obj_3 = Object.objects.create()\n        obj_4 = Object.objects.create()\n        obj_5 = Object.objects.create()\n        obj_6 = Object.objects.create()\n        obj_7 = Object.objects.create()\n        obj_8 = Object.objects.create()\n        obj_9 = Object.objects.create()\n        obj_10 = Object.objects.create()\n        obj_11 = Object.objects.create()\n        obj_12 = Object.objects.create()\n        obj_13 = Object.objects.create()\n        obj_14 = Object.objects.create()\n        obj_15 = Object.objects.create()\n        obj_16 = Object.objects.create()\n        obj_17 = Object.objects.create()\n        obj_18 = Object.objects.create()\n        obj_19 = Object.objects.create()\n        obj_20 = Object.objects.create()\n        obj_21 = Object.objects.create()\n        obj_22 = Object.objects.create()\n        obj_23 = Object.objects.create()\n        obj_24 = Object.objects.create()\n        obj_25 = Object.objects.create()\n        obj_26 = Object.objects.create()\n        obj_27 = Object.objects.create()\n        obj_28 = Object.objects.create()\n        obj_29 = Object.objects.create()\n        obj_30 = Object.objects.create()\n        obj_31 = Object.objects.create()\n        obj_32 = Object.objects.create()\n        obj_33 = Object.objects.create()\n        obj_34 = Object.objects.create()\n        obj_35 = Object.objects.create()\n        obj_36 = Object.objects.create()\n        obj_37 = Object.objects.create()\n        obj_38 = Object.objects.create()\n        obj_39 = Object.objects.create()\n        obj_40 = Object.objects.create()\n        obj_41 = Object.objects.create()\n        obj_42 = Object.objects.create()\n        obj_43 = Object.objects.create()\n        obj_44 = Object.objects.create()\n        obj_45 = Object.objects.create()\n        obj_46 = Object.objects.create()\n        obj_47 = Object.objects.create()\n        obj_48 = Object.objects.create()\n        obj_49 = Object.objects.create()\n        obj_50 = Object.objects.create()\n        obj_51 = Object.objects.create()\n        obj_52 = Object.objects.create()\n        obj_"], "sample_727": ["def test_imputation_axis_deprecation():\n    # Test that the axis parameter is deprecated.\n    imputer = Imputer(strategy=\"mean\", axis=1)\n    with assert_warns_message(DeprecationWarning,\n                             \"Parameter 'axis' has been deprecated in 0.20 and \"\n                             \"will be removed in 0.22. Future (and default) \"\n                             \"behavior is equivalent to 'axis=0' (impute along \"\n                             \"columns). Row-wise imputation can be performed \"\n                             \"with FunctionTransformer (e.g., \"\n                             \"\\\"FunctionTransformer(lambda X: Imputer().fit_transform(X.T).T)\\\"\"):\n        imputer.fit(np.random.rand(10, 5))\n"], "sample_855": ["def test_constant_strategy_regressor_multioutput():\n    random_state = np.random.RandomState(seed=1)\n\n    X_learn = random_state.randn(10, 10)\n    y_learn = random_state.randn(10, 5)\n\n    # test with 2d array\n    constants = random_state.randn(5)\n\n    X_test = random_state.randn(20, 10)\n    y_test = random_state.randn(20, 5)\n\n    # Correctness oracle\n    est = DummyRegressor(strategy=\"constant\", constant=constants)\n    est.fit(X_learn, y_learn)\n    y_pred_learn = est.predict(X_learn)\n    y_pred_test = est.predict(X_test)\n\n    _check_equality_regressor(\n        constants, y_learn, y_pred_learn, y_test, y_pred_test)\n    _check_behavior_2d_for_constant(est)\n\n    # test with 1d array\n    constants = random_state.randn(1)\n    est = DummyRegressor(strategy=\"constant\", constant=constants)\n    est.fit(X_learn, y_learn)\n    y_pred_learn = est.predict(X_learn)\n    y_pred_test = est.predict(X_test)\n\n    _check_equality_regressor(\n        np.tile(constants, (y_learn.shape[0], 1)), y_learn, y_pred_learn, y_test, y_pred_test)\n    _check_behavior_2d_for_constant(est)\n"], "sample_953": ["def test_quickstart_makefile_and_batchfile(tempdir):\n    answers = {\n        'Root path': tempdir,\n        'Project name': 'Sphinx Test',\n        'Author name': 'Georg Brandl',\n        'Project version': '0.1',\n        'Create Makefile': 'n',\n        'Create Windows command file': 'n',\n    }\n    qs.term_input = mock_input(answers)\n    d = {}\n    qs.ask_user(d)\n    qs.generate(d)\n\n    assert not (tempdir / 'Makefile').isfile()\n    assert not (tempdir / 'make.bat').isfile()\n\n    answers = {\n        'Root path': tempdir,\n        'Project name': 'Sphinx Test',\n        'Author name': 'Georg Brandl',\n        'Project version': '0.1',\n        'Create Makefile': 'y',\n        'Create Windows command file': 'y',\n    }\n    qs.term_input = mock_input(answers)\n    d = {}\n    qs.ask_user(d)\n    qs.generate(d)\n\n    assert (tempdir / 'Makefile').isfile()\n    assert (tempdir / 'make.bat').isfile()\n\n    answers = {\n        'Root path': tempdir,\n        'Project name': 'Sphinx Test',\n        'Author name': 'Georg Brandl',\n        'Project version': '0.1',\n        'Create Makefile': 'y',\n        'Create Windows command file': 'y',\n        'Do you want to use the epub builder': 'y',\n    }\n    qs.term_input = mock_input(answers)\n    d = {}\n    qs.ask_user(d)\n    qs.generate(d)\n\n    assert (tempdir / 'Makefile').isfile()\n    assert (tempdir / 'make.bat').isfile()\n    assert (tempdir / 'Makefile').isfile()\n    assert (tempdir / 'make.bat').isfile()\n"], "sample_1062": ["def test_TR22():\n    assert TR22(1 + tan(x)**2) == sec(x)**2\n    assert TR22(1 + cot(x)**2) == csc(x)**2\n    assert TR22(tan(x)**2) == sec(x)**2 - 1\n    assert TR22(cot(x)**2) == csc(x)**2 - 1\n    assert TR22(1 + tan(x)**4) == sec(x)**4 - 2\n    assert TR22(1 + cot(x)**4) == csc(x)**4 - 2\n    assert TR22(tan(x)**4) == sec(x)**4 - 2*tan(x)**2 - 1\n    assert TR22(cot(x)**4) == csc(x)**4 - 2*cot(x)**2 - 1\n    assert TR22(1 + tan(x)**6) == sec(x)**6 - 3*sec(x)**2 - 3\n    assert TR22(1 + cot(x)**6) == csc(x)**6 - 3*csc(x)**2 - 3\n    assert TR22(tan(x)**6) == sec(x)**6 - 6*sec(x)**4*tan(x)**2 + 3*sec(x)**2 + 3\n    assert TR22(cot(x)**6) == csc(x)**6 - 6*csc(x)**4*cot(x)**2 + 3*csc(x)**2 + 3\n"], "sample_300": ["def test_transform_with_lookup(self):\n    query = Query(Author, alias_cols=False)\n    with register_lookup(CharField, Lower):\n        where = query.build_where(Q(name__lower__exact='foo'))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, Exact)\n    self.assertIsInstance(lookup.lhs, Lower)\n    self.assertIsInstance(lookup.lhs.lhs, Col)\n    self.assertIsNone(lookup.lhs.lhs.alias)\n    self.assertEqual(lookup.lhs.lhs.target, Author._meta.get_field('name'))\n    self.assertEqual(lookup.rhs, 'foo')\n"], "sample_1045": ["def test_Float_as_coeff_Mul():\n    a = Float(3.5)\n    assert a.as_coeff_Mul() == (S.One, a)\n    assert a.as_coeff_Mul(rational=True) == (a, S.One)\n    assert a.as_coeff_Mul(rational=False) == (a, S.Zero)\n"], "sample_1071": ["def test_quantity_simplify_prefixes():\n    from sympy.physics.units.util import quantity_simple\n    from sympy.physics.units import kilo, meter, gram, second\n\n    assert quantity_simplify(kilo*meter) == 1000*meter\n    assert quantity_simplify(kilo*gram) == 1000*gram\n    assert quantity_simplify(kilo/gram) == 1/1000\n    assert quantity_simplify(kilo*meter/gram) == 1000*meter/gram\n    assert quantity_simplify(kilo*meter/second) == 1000*meter/second\n    assert quantity_simplify(kilo*meter/second**2) == 1000*meter/second**2\n    assert quantity_simplify(kilo*meter**2/second**2) == 1000*meter**2/second**2\n    assert quantity_simplify(kilo*meter**3/second**2) == 1000*meter**3/second**2\n    assert quantity_simplify(kilo*meter**4/second**2) == 1000*meter**4/second**2\n    assert quantity_simplify(kilo*meter**5/second**2) == 1000*meter**5/second**2\n    assert quantity_simplify(kilo*meter**6/second**2) == 1000*meter**6/second**2\n    assert quantity_simplify(kilo*meter**7/second**2) == 1000*meter**7/second**2\n    assert quantity_simplify(kilo*meter**8/second**2) == 1000*meter**8/second**2\n    assert quantity_simplify(kilo*meter**9/second**2) == 1000*meter**9/second**2\n    assert quantity_simplify(kilo*meter**10/second**2) == 1000*meter**10/second**2\n"], "sample_467": ["    def test_render_years_before_1900(self):\n        widget = SelectDateWidget(years=(\"1899\",))\n        self.check_html(\n            widget,\n            \"mydate\",\n            \"1899-04-15\",\n            html=(\n                \"\"\"\n            <select name=\"mydate_month\" id=\"id_mydate_month\">\n                <option value=\"\">---</option>\n                <option value=\"1\">January</option>\n                <option value=\"2\">February</option>\n                <option value=\"3\">March</option>\n                <option value=\"4\" selected>April</option>\n                <option value=\"5\">May</option>\n                <option value=\"6\">June</option>\n                <option value=\"7\">July</option>\n                <option value=\"8\">August</option>\n                <option value=\"9\">September</option>\n                <option value=\"10\">October</option>\n                <option value=\"11\">November</option>\n                <option value=\"12\">December</option>\n            </select>\n\n            <select name=\"mydate_day\" id=\"id_mydate_day\">\n                <option value=\"\">---</option>\n                <option value=\"1\">1</option>\n                <option value=\"2\">2</option>\n                <option value=\"3\">3</option>\n                <option value=\"4\">4</option>\n                <option value=\"5\">5</option>\n                <option value=\"6\">6</option>\n                <option value=\"7\">7</option>\n                <option value=\"8\">8</option>\n                <option value=\"9\">9</option>\n                <option value=\"10\">10</option>\n                <option value=\"11\">11</option>\n                <option value=\"12\">12</option>\n                <option value=\"13\">13</option>\n                <option value=\"14\">14</option>\n                <option value=\"15\">15</option>\n                <option value=\"16\">16</option>\n                <option value=\"17\">17</option>\n                <option value=\"18\">18</option>\n                <option value=\"19\">19</option>\n                <option value=\"20\">20</option>\n                <option value=\"21\">21</option>\n                <option value=\"22\">22</option>\n                <option value=\"23\">23</option>\n                <option value=\"24\">"], "sample_593": ["def test_repr_of_dataset_with_empty_data_vars(dataset):\n    ds = dataset.drop_vars(\"tmin\")\n    formatted = fh.dataset_repr(ds)\n    # coords, attrs, and data_vars are expanded\n    assert (\n        formatted.count(\"class='xr-section-summary-in' type='checkbox'  checked>\") == 2\n    )\n    assert \"&lt;U4\" in formatted or \"&gt;U4\" in formatted\n    assert \"&lt;IA&gt;\" in formatted\n"], "sample_712": ["def test_one_hot_encoder_handle_unknown_dtype():\n    X = np.array([[0, 2, 1], [1, 0, 3], [1, 0, 2]], dtype='int64')\n    X2 = np.array([[4, 1, 1]], dtype='int64')\n\n    # Test that one hot encoder raises error for unknown features\n    # present during transform.\n    oh = OneHotEncoder(handle_unknown='error', dtype='float64')\n    assert_warns(FutureWarning, oh.fit, X)\n    assert_raises(ValueError, oh.transform, X2)\n\n    # Test the ignore option, ignores unknown features (giving all 0's)\n    oh = OneHotEncoder(handle_unknown='ignore', dtype='float64')\n    oh.fit(X)\n    X2_passed = X2.copy()\n    assert_array_equal(\n        oh.transform(X2).toarray(),\n        np.array([[0.,  0.,  0.,  0.,  1.,  0.,  0.]]))\n    # ensure transformed data was not modified in place\n    assert_allclose(X2, X2_passed)\n\n    # Raise error if handle_unknown is neither ignore or error.\n    oh = OneHotEncoder(handle_unknown='42', dtype='float64')\n    assert_raises(ValueError, oh.fit, X)\n"], "sample_108": ["    def test_converter_reverse_with_invalid_input(self):\n        @DynamicConverter.register_to_python\n            raise ValueError('Invalid input')\n\n        @DynamicConverter.register_to_url\n            raise ValueError('Invalid input')\n\n        with self.assertRaises(NoReverseMatch):\n            reverse('dynamic', kwargs={'dynamic': 'abc'})\n\n        with self.assertRaises(Resolver404):\n            resolve('/dynamic/abc/')\n"], "sample_531": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect((1, 2, 3))\n    ax2.set_box_aspect((2, 1, 1))\n"], "sample_928": ["def test_heading():\n    env = Environment()\n    assert heading(env, 'Heading 1') == 'Heading 1====================================================\\n===================================================='\n    assert heading(env, 'Heading 2') == 'Heading 2-------------------------------------\\n-------------------------------------'\n    assert heading(env, 'Heading 3') == 'Heading 3~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~'\n    assert heading(env, 'Heading 1', level=2) == 'Heading 1-------------------------------------\\n-------------------------------------'\n    assert heading(env, 'Heading 2', level=3) == 'Heading 2~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~'\n    assert heading(env, 'Heading 3', level=1) == 'Heading 3====================================================\\n===================================================='\n\n    # Test with Japanese characters\n    env = Environment(language='ja')\n    assert heading(env, 'Heading 1') == 'Heading 1====================================================\\n===================================================='\n    assert heading(env, 'Heading 2') == 'Heading 2-------------------------------------\\n-------------------------------------'\n    assert heading(env, 'Heading 3') == 'Heading 3~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~'\n    assert heading(env, 'Heading 1', level=2) == 'Heading 1-------------------------------------\\n-------------------------------------'\n    assert heading(env, 'Heading 2', level=3) == 'Heading 2~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~'\n    assert heading(env, 'Heading 3', level=1) == 'Heading 3====================================================\\n===================================================='\n\n    # Test with ambiguous characters\n    env = Environment(language='ja')\n    assert heading(env, 'Heading 1', widechars='WFA') == 'Heading 1====================================================\\n===================================================='\n    assert heading(env, 'Heading 2', widechars='WFA') == 'Heading 2====================================================\\n===================================================='\n    assert heading(env, 'Heading 3', widechars='WFA') == 'Heading 3====================================================\\n===================================================='\n"], "sample_590": ["    def test_concat_compat(self, compat):\n        ds1 = Dataset({\"foo\": (\"x\", [1, 2])}, coords={\"x\": [0, 1]})\n        ds2 = Dataset({\"foo\": (\"x\", [3, 4])}, coords={\"x\": [0, 1]})\n        actual = concat([ds1, ds2], dim=\"x\", compat=compat)\n        expected = Dataset({\"foo\": (\"x\", [1, 2, 3, 4])}, coords={\"x\": [0, 1, 0, 1]})\n        assert_identical(expected, actual)\n"], "sample_550": ["def test_axes_set_position():\n    fig, ax = plt.subplots()\n    ax.set_position([0.1, 0.1, 0.8, 0.8])\n    assert ax.get_position().width == 0.8\n    assert ax.get_position().height == 0.8\n    assert ax.get_position().x == 0.1\n    assert ax.get_position().y == 0.1\n\n    ax.set_position([0.1, 0.1, 0.8, 0.8], which='active')\n    assert ax.get_position().width == 0.8\n    assert ax.get_position().height == 0.8\n    assert ax.get_position().x == 0.1\n    assert ax.get_position().y == 0.1\n\n    ax.set_position([0.1, 0.1, 0.8, 0.8], which='original')\n    assert ax.get_position().width == 0.8\n    assert ax.get_position().height == 0.8\n    assert ax.get_position().x == 0.1\n    assert ax.get_position().y == 0.1\n\n    ax.set_position([0.1, 0.1, 0.8, 0.8], which='active')\n    ax.reset_position()\n    assert ax.get_position().width == 0.8\n    assert ax.get_position().height == 0.8\n    assert ax.get_position().x == 0.1\n    assert ax.get_position().y == 0.1\n\n    ax.set_position([0.1, 0.1, 0.8, 0.8], which='original')\n    ax.reset_position()\n    assert ax.get_position().width == 0.8\n    assert ax.get_position().height == 0.8\n    assert ax.get_position().x == 0.1\n    assert ax.get_position().y == 0.1\n"], "sample_1151": ["def test_Mod_is_nonnegative_nonpositive():\n    x = Symbol('x', real=True)\n\n    k = Symbol('k', integer=True, nonnegative=True)\n    l = Symbol('l', integer=True, positive=True)\n    n = Symbol('n', even=True)\n    m = Symbol('m', odd=True)\n\n    assert (x % 4).is_nonnegative\n    assert (x % -4).is_nonpositive\n    assert (x % 2).is_nonnegative\n    assert (x % -2).is_nonpositive\n    assert (x % 3).is_nonnegative is None\n    assert (x % -3).is_nonpositive is None\n\n    assert (k % 4).is_nonnegative\n    assert (k % -4).is_nonpositive\n    assert (k % 2).is_nonnegative\n    assert (k % -2).is_nonpositive\n    assert (k % 3).is_nonnegative is None\n    assert (k % -3).is_nonpositive is None\n\n    assert (l % 4).is_nonnegative\n    assert (l % -4).is_nonpositive\n    assert (l % 2).is_nonnegative\n    assert (l % -2).is_nonpositive\n    assert (l % 3).is_nonnegative is None\n    assert (l % -3).is_nonpositive is None\n\n    assert ((-k) % 4).is_nonnegative\n    assert ((-k) % -4).is_nonpositive\n    assert ((-k) % 2).is_nonnegative\n    assert ((-k) % -2).is_nonpositive\n    assert ((-k) % 3).is_nonnegative is None\n    assert ((-k) % -3).is_nonpositive is None\n\n    assert ((-l) % 4).is_nonnegative\n    assert ((-l) % -4).is_nonpositive\n    assert ((-l) % 2).is_nonnegative\n    assert ((-l) % -2).is_nonpositive\n    assert ((-l) % 3).is_nonnegative is None\n    assert ((-l) % -3).is_nonpositive is None\n\n    assert (n % 4).is_nonnegative\n    assert (n % -4).is_nonpositive\n    assert (n % 2).is_nonnegative\n    assert ("], "sample_1099": ["def test_eval_partial_derivative_single_2nd_rank_tensors_by_tensor_with_multiple_derivatives():\n    tau, mu, nu = symbols(\"tau mu nu\")\n\n    expr1 = PartialDerivative(H(i, j), H(m, m1), H(n, n1))\n    assert expr1._perform_derivative() - L.delta(i, -m) * L.delta(j, -m1) * L.delta(n, -n1) == 0\n\n    expr2 = PartialDerivative(H(i, j), H(-m, m1), H(n, n1))\n    assert expr2._perform_derivative() - L.metric(i, L_0) * L.delta(-L_0, m) * L.delta(j, -m1) * L.delta(n, -n1) == 0\n\n    expr3 = PartialDerivative(H(i, j), H(m, -m1), H(n, n1))\n    assert expr3._perform_derivative() - L.delta(i, -m) * L.metric(j, L_0) * L.delta(-L_0, m1) * L.delta(n, -n1) == 0\n\n    expr4 = PartialDerivative(H(i, j), H(-m, -m1), H(n, n1))\n    assert expr4._perform_derivative() - L.metric(i, L_0) * L.delta(-L_0, m) * L.metric(j, L_1) * L.delta(-L_1, m1) * L.delta(n, -n1) == 0\n\n    expr5 = PartialDerivative(H(i, j), H(m, m1), H(-n, n1))\n    assert expr5._perform_derivative() - L.delta(i, -m) * L.delta(j, -m1) * L.metric(n, L_0) * L.delta(-L_0, n1) == 0\n\n    expr6 = PartialDerivative(H(i, j), H(-m, m1), H(-n, n1))\n    assert expr6._perform_derivative() - L.metric(i, L_0) * L.delta(-L_0, m) * L.delta(j, -m1) * L.metric(n, L_1) * L.delta(-L_1, n1) == 0\n\n    expr7 = PartialDerivative(H(i, j), H(m, -m1), H(-n"], "sample_863": ["def test_pipeline_fit_transform_with_intermediate_fit_params():\n    # tests that Pipeline passes fit_params to intermediate steps\n    # when fit_transform is invoked\n    pipe = Pipeline([('transf', TransfFitParams()), ('clf', FitParamT())])\n    pipe.fit_transform(X=None,\n                      y=None,\n                      transf__should_get_this=True,\n                      clf__should_succeed=True)\n    assert pipe.named_steps['transf'].fit_params['should_get_this']\n    assert pipe.named_steps['clf'].successful\n    assert 'should_succeed' not in pipe.named_steps['transf'].fit_params\n"], "sample_206": ["def test_pre_save(self):\n    \"\"\"\n    FileField.pre_save() commits the file to storage prior to saving the model.\n    \"\"\"\n    d = Document.objects.create(myfile='something.txt')\n    self.assertFalse(d.myfile._committed)\n    d.myfile.save('something.txt', ContentFile(b'content'), save=False)\n    self.assertTrue(d.myfile._committed)\n    d.save()\n    self.assertTrue(d.myfile._committed)\n"], "sample_532": ["def test_contour_label_font_properties():\n    x, y = np.meshgrid(np.arange(0, 10), np.arange(0, 10))\n    z = np.max(np.dstack([abs(x), abs(y)]), 2)\n\n    fig, ax = plt.subplots()\n    cs = ax.contour(x, y, z)\n    cs.clabel(fontsize='xx-large')\n    assert cs.labelFontProps.get_size() == 24\n    cs.clabel(fontsize='small')\n    assert cs.labelFontProps.get_size() == 8\n"], "sample_566": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect((1, 2, 3))\n    ax2.set_box_aspect((4, 5, 6))\n    fig.draw_without_rendering()\n    xn = np.zeros(3)\n    yn = np.zeros(3)\n    for nn, ax in enumerate([ax1, ax2]):\n        yn[nn] = ax.bbox.height\n        xn[nn] = ax.bbox.width\n    np.testing.assert_allclose(xn, [1, 1])\n    np.testing.assert_allclose(yn, [2, 6])\n"], "sample_990": ["def test_acsch_expansion():\n    x, y = symbols('x,y')\n    assert acsch(x+y).expand(trig=True) == acsch(x)*acsch(y) + csch(x)*csch(y)\n    assert acsch(2*x).expand(trig=True) == 2*acsch(x)*csch(x)\n    assert acsch(3*x).expand(trig=True).expand() == \\\n        acsch(x)**3 + 3*acsch(x)*csch(x)**2\n"], "sample_831": ["def test_export_text_multi_output():\n    # Test export_text for multi-output decision tree\n    clf = DecisionTreeClassifier(max_depth=2, random_state=0)\n    clf.fit(X, y2)\n\n    expected_report = dedent(\"\"\"\n    |--- feature_0 <= 0.00\n    |   |--- class: -1\n    |--- feature_0 >  0.00\n    |   |--- class: 1\n    \"\"\").lstrip()\n    assert export_text(clf) == expected_report\n\n    expected_report = dedent(\"\"\"\n    |--- a <= 0.00\n    |   |--- class: -1\n    |--- a >  0.00\n    |   |--- class: 1\n    \"\"\").lstrip()\n    assert export_text(clf, feature_names=['a']) == expected_report\n\n    expected_report = dedent(\"\"\"\n    |--- feature_0 <= 0.00\n    |   |--- weights: [3.0, 1.5, 0.0] class: -1\n    |--- feature_0 >  0.00\n    |   |--- weights: [3.0, 1.0, 0.5] class: 1\n    \"\"\").lstrip()\n    assert export_text(clf, show_weights=True) == expected_report\n\n    expected_report = dedent(\"\"\"\n    |- feature_0 <= 0.00\n    | |- class: -1\n    |- feature_0 >  0.00\n    | |- class: 1\n    \"\"\").lstrip()\n    assert export_text(clf, spacing=1) == expected_report\n\n    X_l = [[-2, -1], [-1, -1], [-1, -2], [1, 1], [1, 2], [2, 1], [-1, 1]]\n    y_l = [-1, -1, -1, 1, 1, 1, 2]\n    clf = DecisionTreeClassifier(max_depth=4, random_state=0)\n    clf.fit(X_l, y_l)\n    expected_report = dedent(\"\"\"\n    |--- feature_0 <= 0.00\n    |   |--- class: -1\n    |--- feature_0 >  0.00\n    |   |--- truncated branch of depth 2\n    \"\"\")."], "sample_8": ["    def test_masked_array_to_masked(self):\n        \"\"\"Check that we can initialize a MaskedArray properly.\"\"\"\n        ma = Masked(self.a, self.mask_a)\n        np_ma = np.ma.MaskedArray(ma)\n        assert type(np_ma) is np.ma.MaskedArray\n        assert type(np_ma.data) is self._data_cls\n        assert type(np_ma.mask) is np.ndarray\n        assert_array_equal(np_ma.data, self.a)\n        assert_array_equal(np_ma.mask, self.mask_a)\n"], "sample_914": ["def test_unparse_arguments():\n    module = ast.parse(\"def func(a, b, c=1, *args, d=2, **kwargs): pass\")\n    func_node = module.body[0]\n    assert ast.unparse(func_node.args) == \"a, b, c=1, *args, d=2, **kwargs\"\n"], "sample_161": ["    def test_through_fields_with_non_foreign_key(self):\n        \"\"\"\n        Providing a non-foreign key to ManyToManyField.through_fields\n        triggers validation errors.\n        \"\"\"\n        class Fan(models.Model):\n            pass\n\n        class Event(models.Model):\n            invitees = models.ManyToManyField(\n                Fan,\n                through='Invitation',\n                through_fields=('invitee', 'non_foreign_key'),\n            )\n\n        class Invitation(models.Model):\n            event = models.ForeignKey(Event, models.CASCADE)\n            invitee = models.ForeignKey(Fan, models.CASCADE)\n            inviter = models.ForeignKey(Fan, models.CASCADE, related_name='+')\n\n        field = Event._meta.get_field('invitees')\n        self.assertEqual(field.check(from_model=Event), [\n            Error(\n                \"'Invitation.non_foreign_key' is not a foreign key to 'Fan'.\",\n                hint=\"Did you mean one of the following foreign keys to 'Fan': invitee, inviter?\",\n                obj=field,\n                id='fields.E339',\n            ),\n        ])\n"], "sample_504": ["def test_colorbar_alpha():\n    \"\"\"\n    Test the alpha parameter of the Colorbar class.\n    \"\"\"\n    fig, ax = plt.subplots()\n    x = np.arange(1, 5).reshape(2, 2)/4\n    pc = ax.pcolormesh(x, alpha=x)\n    cb = fig.colorbar(pc, ax=ax)\n    assert cb.alpha is None\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n    cb.set_alpha([0.5, 0.7])\n    assert cb.alpha == [0.5, 0.7]\n    cb.set_alpha(None)\n    assert cb.alpha is None\n    fig.draw_without_rendering()\n"], "sample_1171": ["def test_ImageSet_simplification_with_rational():\n    from sympy.abc import n, m\n    assert imageset(Lambda(n, n/2), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/2), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/3), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/7), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/11), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/13), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/17), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/19), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/23), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/29), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/31), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/37), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/41), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/43), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/47), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/53), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/59), S.Integers) == S.Integers\n    assert imageset(Lambda(n, n/2 + 1/61), S.Integers) == S.Integers\n"], "sample_472": ["    def test_get_elided_page_range_with_zero_pages(self):\n        paginator = Paginator([], 10)\n        page_range = paginator.get_elided_page_range(1)\n        self.assertIsInstance(page_range, collections.abc.Generator)\n        self.assertEqual(list(page_range), [1])\n"], "sample_898": ["def test_coverage_error_invariance():\n    random_state = check_random_state(0)\n    y_true = random_state.randint(0, 2, size=(20, 5))\n    y_score = random_state.uniform(size=y_true.shape)\n\n    for name in THRESHOLDED_MULTILABEL_METRICS:\n        metric = ALL_METRICS[name]\n        error = metric(y_true, y_score)\n\n        for _ in range(3):\n            perm = random_state.permutation(y_true.shape[1])\n            assert_almost_equal(metric(y_true[:, perm], y_score[:, perm]),\n                                error,\n                                err_msg=\"%s is not dimension shuffling \"\n                                        \"invariant\" % name)\n"], "sample_985": ["def test_real_root():\n    x = symbols('x')\n    assert real_root(x) == x**(1/2)\n    assert real_root(x, 2) == x**(1/2)\n    assert real_root(x, 3) == x**(1/3)\n    assert real_root(x, -2) == x**(-1/2)\n    assert real_root(x, 2, 1) == -x**(1/2)\n    assert real_root(-8, 3) == 2*(-1)**(1/3)\n    assert real_root(-8, 3, 2) == -2*(-1)**(1/3)\n    assert real_root(-32, 5) == -2\n    assert real_root(-32, 5, 5//2) == -2\n    assert real_root(-32, 5, 3) == 2\n    assert real_root(-32, 5, 4) == -2\n    assert real_root(-32, 5, 6) == 2\n    assert real_root(-32, 5, 7) == -2\n    assert real_root(-32, 5, 8) == 2\n    assert real_root(-32, 5, 9) == -2\n    assert real_root(-32, 5, 10) == 2\n    assert real_root(-32, 5, 11) == -2\n    assert real_root(-32, 5, 12) == 2\n    assert real_root(-32, 5, 13) == -2\n    assert real_root(-32, 5, 14) == 2\n    assert real_root(-32, 5, 15) == -2\n    assert real_root(-32, 5, 16) == 2\n    assert real_root(-32, 5, 17) == -2\n    assert real_root(-32, 5, 18) == 2\n    assert real_root(-32, 5, 19) == -2\n    assert real_root(-32, 5, 20) == 2\n    assert real_root(-32, 5, 21) == -2\n    assert real_root(-32, 5, 22) == 2\n    assert real_root(-32, 5, 23) =="], "sample_942": ["def test_pydata_annotation(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :type: int\\n\"\n            \"   :value: 1\\n\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"version\"],\n                                                    [desc_annotation, (\": \",\n                                                                       [pending_xref, \"int\"])],\n                                                    [desc_annotation, \" = 1\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_annotation, \"int\", \" \", \" = \", nodes.inline, \"1\"])\n    assert_node(doctree[1][0][1][0], pending_xref, refdomain=\"py\", reftype=\"class\", reftarget=\"int\")\n"], "sample_818": ["def test_spectral_clustering_with_kmeans():\n    # Test that spectral_clustering is the same for kmeans and discretize assign_labels\n    X, y = make_blobs(n_samples=20, random_state=0,\n                      centers=[[1, 1], [-1, -1]], cluster_std=0.01)\n    labels_kmeans = spectral_clustering(X, n_clusters=2, assign_labels='kmeans',\n                                       random_state=0)\n    labels_discretize = spectral_clustering(X, n_clusters=2, assign_labels='discretize',\n                                           random_state=0)\n    assert adjusted_rand_score(y, labels_kmeans) == 1\n    assert adjusted_rand_score(y, labels_discretize) == 1\n    assert labels_kmeans is not labels_discretize\n"], "sample_435": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = UNUSABLE_PASSWORD_PREFIX + \"123456\"\n        self.assertHTMLEqual(\n            widget.render(\"name\", value, {\"id\": \"id_password\"}),\n            '<div id=\"id_password\">'\n            \"    <strong>No password set.</strong>\"\n            \"</div>\",\n        )\n"], "sample_1136": ["def test_Poly_sub():\n    assert Poly(0, x).sub(Poly(0, x)) == Poly(0, x)\n    assert Poly(0, x) - Poly(0, x) == Poly(0, x)\n\n    assert Poly(1, x).sub(Poly(0, x)) == Poly(1, x)\n    assert Poly(1, x, y) - Poly(0, x) == Poly(1, x, y)\n    assert Poly(0, x).sub(Poly(1, x, y)) == Poly(-1, x, y)\n    assert Poly(0, x, y) - Poly(1, x, y) == Poly(-1, x, y)\n\n    assert Poly(1, x) - x == Poly(1 - x, x)\n    with warns_deprecated_sympy():\n        Poly(1, x) - sin(x)\n\n    assert Poly(x, x) - 1 == Poly(x - 1, x)\n    assert 1 - Poly(x, x) == Poly(1 - x, x)\n"], "sample_705": ["def test_pytester_runresult_parseoutcomes_with_no_summary(pytester: Pytester) -> None:\n    p1 = pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n            pass\n\n            assert False\n    \"\"\"\n    )\n    result = pytester.runpytest(str(p1))\n    with pytest.raises(ValueError, match=\"Pytest terminal summary report not found\"):\n        result.parseoutcomes()\n"], "sample_1047": ["def test_issue_10451():\n    x = Symbol('x', real=True, finite=False)\n    assert x.is_finite is False\n    assert x.is_infinite is True\n    assert x.is_real is True\n    assert x.is_complex is True\n    assert x.is_noninteger is None\n    assert x.is_irrational is None\n    assert x.is_imaginary is None\n    assert x.is_positive is None\n    assert x.is_negative is None\n    assert x.is_nonpositive is None\n    assert x.is_nonnegative is None\n    assert x.is_even is None\n    assert x.is_odd is None\n    assert x.is_zero is None\n    assert x.is_nonzero is None\n"], "sample_1193": ["def test_are_coplanar():\n    from sympy.geometry import Point3D, Line3D, Plane\n    a = Line3D(Point3D(5, 0, 0), Point3D(1, -1, 1))\n    b = Line3D(Point3D(0, -2, 0), Point3D(3, 1, 1))\n    c = Line3D(Point3D(0, -1, 0), Point3D(5, -1, 9))\n    assert are_coplanar(a, b, c) == False\n    assert are_coplanar(a, b, Plane((0, 0, 0), (1, 1, 1))) == True\n    assert are_coplanar(a, b, Plane((0, 0, 0), (1, 1, 1), (2, 2, 2))) == True\n    assert are_coplanar(a, b, Plane((0, 0, 0), (1, 1, 1), (2, 2, 2), (3, 3, 3))) == True\n    assert are_coplanar(a, b, Plane((0, 0, 0), (1, 1, 1), (2, 2, 2), (3, 3, 3), (4, 4, 4))) == True\n    assert are_coplanar(a, b, Plane((0, 0, 0), (1, 1, 1), (2, 2, 2), (3, 3, 3), (4, 4, 4), (5, 5, 5))) == True\n    assert are_coplanar(a, b, Plane((0, 0, 0), (1, 1, 1), (2, 2, 2), (3, 3, 3), (4, 4, 4), (5, 5, 5), (6, 6, 6))) == True\n    assert are_coplanar(a, b, Plane((0, 0, 0), (1, 1, 1), (2, 2, 2), (3, 3, 3), (4, 4, "], "sample_666": ["    def test_log_cli_level(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n            import logging\n            import pytest\n\n                logging.getLogger().setLevel(logging.INFO)\n                logging.info(\"info\")\n                logging.warning(\"warning\")\n                logging.error(\"error\")\n                logging.critical(\"critical\")\n            \"\"\"\n        )\n        result = testdir.runpytest_subprocess(\"--log-cli-level=INFO\")\n        result.stdout.fnmatch_lines([\"*INFO*info*\", \"*WARNING*warning*\", \"*ERROR*error*\", \"*CRITICAL*critical*\"])\n        result.stderr.fnmatch_lines([\"*WARNING*warning*\", \"*ERROR*error*\", \"*CRITICAL*critical*\"])\n"], "sample_1115": ["def test_TensorIndexType_deprecated():\n    with warns_deprecated_sympy():\n        Lorentz = TensorIndexType('Lorentz', dummy_name='L')\n        Lorentz.data\n        Lorentz.data = [1, 2, 3, 4]\n        del Lorentz.data\n        Lorentz.data\n        Lorentz.get_kronecker_delta()\n        Lorentz.get_epsilon()\n        Lorentz._components_data_full_destroy()\n"], "sample_466": ["def test_serialize_deconstructible_class(self):\n    \"\"\"\n    Test serialization of a class that uses deconstructible.\n    \"\"\"\n    class DeconstructibleClass:\n            return (\"DeconstructibleClass\", [], {})\n\n    class DeconstructibleClassWithArgs:\n            return (\"DeconstructibleClassWithArgs\", [1, 2], {})\n\n    class DeconstructibleClassWithKwargs:\n            return (\"DeconstructibleClassWithKwargs\", [], {\"kwarg1\": 1})\n\n    class DeconstructibleClassWithArgsAndKwargs:\n            return (\"DeconstructibleClassWithArgsAndKwargs\", [1, 2], {\"kwarg1\": 1})\n\n    self.assertSerializedResultEqual(DeconstructibleClass, (\"DeconstructibleClass\", set()))\n    self.assertSerializedResultEqual(DeconstructibleClassWithArgs, (\"DeconstructibleClassWithArgs\", {\"import DeconstructibleClassWithArgs\"}))\n    self.assertSerializedResultEqual(DeconstructibleClassWithKwargs, (\"DeconstructibleClassWithKwargs\", {\"import DeconstructibleClassWithKwargs\"}))\n    self.assertSerializedResultEqual(DeconstructibleClassWithArgsAndKwargs, (\"DeconstructibleClassWithArgsAndKwargs\", {\"import DeconstructibleClassWithArgsAndKwargs\"}))\n"], "sample_486": ["def test_inlineformset_factory_nulls_default_pks_uuid_parent_uuid_child(self):\n    \"\"\"\n    #24958 - Variant of test_inlineformset_factory_nulls_default_pks for\n    the case of a parent object with a UUID primary key and a child object\n    with a UUID primary key.\n    \"\"\"\n    FormSet = inlineformset_factory(UUIDPKParent, UUIDPKChild, fields=\"__all__\")\n    formset = FormSet()\n    self.assertIsNone(formset.forms[0].fields[\"parent\"].initial)\n"], "sample_403": ["    def test_alter_field_with_db_column_noop(self):\n        \"\"\"\n        AlterField operation is a noop when adding only a db_column and the\n        column name is not changed.\n        \"\"\"\n        app_label = \"test_afadbn\"\n        project_state = self.set_up_test_model(app_label, related_model=True)\n        pony_table = \"%s_pony\" % app_label\n        new_state = project_state.clone()\n        operation = migrations.AlterField(\n            \"Pony\", \"weight\", models.FloatField(db_column=\"weight\")\n        )\n        operation.state_forwards(app_label, new_state)\n        self.assertIsNone(\n            project_state.models[app_label, \"pony\"].fields[\"weight\"].db_column,\n        )\n        self.assertEqual(\n            new_state.models[app_label, \"pony\"].fields[\"weight\"].db_column,\n            \"weight\",\n        )\n        self.assertColumnExists(pony_table, \"weight\")\n        with connection.schema_editor() as editor:\n            with self.assertNumQueries(0):\n                operation.database_forwards(app_label, editor, project_state, new_state)\n        self.assertColumnExists(pony_table, \"weight\")\n        with connection.schema_editor() as editor:\n            with self.assertNumQueries(0):\n                operation.database_backwards(\n                    app_label, editor, new_state, project_state\n                )\n        self.assertColumnExists(pony_table, \"weight\")\n\n        rider_table = \"%s_rider\" % app_label\n        new_state = project_state.clone()\n        operation = migrations.AlterField(\n            \"Rider\",\n            \"pony\",\n            models.ForeignKey(\"Pony\", models.CASCADE, db_column=\"pony_id\"),\n        )\n        operation.state_forwards(app_label, new_state)\n        self.assertIsNone(\n            project_state.models[app_label, \"rider\"].fields[\"pony\"].db_column,\n        )\n        self.assertIs(\n            new_state.models[app_label, \"rider\"].fields[\"pony\"].db_column,\n            \"pony_id\",\n        )\n        self.assertColumnExists(rider_table, \"pony_id\")\n        with connection.schema_editor() as editor:\n            with self.assertNumQueries(0):\n                operation.database_forwards(app_label, editor, project_state, new_state)\n        self.assertColumnExists(rider_table, \"pony_id\")\n        with connection.schema_editor() as editor:\n            with self"], "sample_1140": ["def test_pretty_RationalField():\n    from sympy import RationalField\n    assert pretty(RationalField(53)) == \"QQ[53]\"\n    assert upretty(RationalField(53)) == \"\u211a\u2085\u2083\"\n"], "sample_682": ["    def test_xfail_raises_with_multiple_exceptions(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(raises=(TypeError, ValueError))\n                raise TypeError()\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n"], "sample_679": ["def test_mark_eval_invalid_syntax(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.xyz\n            pass\n    \"\"\"\n    )\n    rec = testdir.inline_run(\"-m\", \"xyz\")\n    err = rec.stderr.fnmatch_lines([\"*SyntaxError: invalid syntax*\"])\n    assert err\n"], "sample_343": ["def test_get_content_type_with_id(self):\n    question = Question.objects.create(text='Who?')\n    content_type = ContentType.objects.get_for_model(Question)\n    self.assertEqual(Answer.question.get_content_type(id=content_type.pk), content_type)\n"], "sample_1059": ["def test_assoc_laguerre():\n    n = Symbol(\"n\")\n    m = Symbol(\"m\")\n    a = Symbol(\"a\")\n\n    assert assoc_laguerre(0, a, x) == 1\n    assert assoc_laguerre(1, a, x) == a - x + 1\n    assert assoc_laguerre(2, a, x) == a**2/2 + 3*a/2 + x**2/2 + x*(-a - 2) + 1\n    assert assoc_laguerre(3, a, x) == a**3/6 + a**2 + 11*a/6 - x**3/6 + x**2*(a/2 + 3/2) + \\\n        x*(-a**2/2 - 5*a/2 - 3) + 1\n\n    assert assoc_laguerre(n, a, 0) == binomial(a + n, a)\n\n    assert assoc_laguerre(n, a, x) == assoc_laguerre(n, a, x)\n\n    assert assoc_laguerre(n, 0, x) == laguerre(n, x)\n\n    assert diff(assoc_laguerre(n, a, x), x) == \\\n        -assoc_laguerre(n - 1, a + 1, x)\n\n    assert diff(assoc_laguerre(n, a, x), a).dummy_eq(Sum(assoc_laguerre(_k, a, x)/(-a + n), (_k, 0, n - 1)))\n\n    assert assoc_laguerre(n, a, x).rewrite(\"polynomial\").dummy_eq(\n        gamma(n + a + 1)/factorial(n)*Sum(RisingFactorial(-n, _k)/(gamma(_k + a + 1)*factorial(_k)), (_k, 0, n)))\n\n    raises(ValueError, lambda: assoc_laguerre(-2.1, a, x))\n    raises(ValueError, lambda: assoc_laguerre(Rational(5, 2), a, x))\n    raises(ArgumentIndexError, lambda: assoc_laguerre(n, a, x).fdiff(1))\n    raises(ArgumentIndexError, lambda: assoc_laguerre(n, a, x).fdiff(3))\n\n    assert conjugate"], "sample_142": ["def test_inline_formset_factory(self):\n    class SongInline(admin.TabularInline):\n        model = Song\n\n    class AlbumAdmin(admin.ModelAdmin):\n        inlines = [SongInline]\n\n    errors = AlbumAdmin(Album, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongInlineWithFkName(admin.TabularInline):\n        model = Song\n        fk_name = \"album\"\n\n    class AlbumAdminWithFkName(admin.ModelAdmin):\n        inlines = [SongInlineWithFkName]\n\n    errors = AlbumAdminWithFkName(Album, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongInlineWithoutFkName(admin.TabularInline):\n        model = Song\n\n    class AlbumAdminWithoutFkName(admin.ModelAdmin):\n        inlines = [SongInlineWithoutFkName]\n\n    errors = AlbumAdminWithoutFkName(Album, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"'admin_checks.Song' has more than one ForeignKey to 'admin_checks.Album'. \"\n            \"You must specify a 'fk_name' attribute.\",\n            obj=SongInlineWithoutFkName,\n            id='admin.E202',\n        )\n    ]\n    self.assertEqual(errors, expected)\n"], "sample_124": ["def test_boundfield_disabled(self):\n    class Person(Form):\n        name = CharField(disabled=True)\n\n    f = Person()\n    self.assertFalse(f['name'].has_changed(None, None))\n    self.assertFalse(f['name'].has_changed(None, ''))\n    self.assertFalse(f['name'].has_changed(None, 'John'))\n    self.assertFalse(f['name'].has_changed(None, 'John Doe'))\n    self.assertFalse(f['name'].has_changed(None, datetime.date(1940, 10, 9)))\n    self.assertFalse(f['name'].has_changed(None, datetime.datetime(1940, 10, 9)))\n\n    f = Person({'name': 'John'})\n    self.assertFalse(f['name'].has_changed(None, None))\n    self.assertFalse(f['name'].has_changed(None, ''))\n    self.assertFalse(f['name'].has_changed(None, 'John'))\n    self.assertFalse(f['name'].has_changed(None, 'John Doe'))\n    self.assertFalse(f['name'].has_changed(None, datetime.date(1940, 10, 9)))\n    self.assertFalse(f['name'].has_changed(None, datetime.datetime(1940, 10, 9)))\n\n    f = Person({'name': 'John Doe'})\n    self.assertFalse(f['name'].has_changed(None, None))\n    self.assertFalse(f['name'].has_changed(None, ''))\n    self.assertFalse(f['name'].has_changed(None, 'John'))\n    self.assertFalse(f['name'].has_changed(None, 'John Doe'))\n    self.assertFalse(f['name'].has_changed(None, datetime.date(1940, 10, 9)))\n    self.assertFalse(f['name'].has_changed(None, datetime.datetime(1940, 10, 9)))\n\n    f = Person({'name': datetime.date(1940, 10, 9)})\n    self.assertFalse(f['name'].has_changed(None, None))\n    self.assertFalse(f['name'].has_changed(None, ''))\n    self.assertFalse(f['name'].has_changed(None, 'John'))\n    self.assertFalse(f['name'].has_changed(None, 'John Doe'))\n    self.assertFalse(f['name'].has_changed(None, datetime.date(1940, 10, 9)))\n    self.assertFalse(f['name'].has_changed(None, datetime.datetime(1940, 10, 9)))\n\n    f = Person({'name': datetime.datetime(1940, 10, 9)})\n    self.assertFalse(f['name'].has_changed(None, None))\n   "], "sample_1011": ["def test_MatrixSlice():\n    A = Matrix([[1, 2, 3], [4, 5, 6]])\n    assert mcode(A[1, :]) == \"[4 5 6]\"\n    assert mcode(A[:, 1]) == \"[2; 5]\"\n    assert mcode(A[1, 1:]) == \"[5]\"\n    assert mcode(A[1:, 1]) == \"[5]\"\n    assert mcode(A[1:2, 1:3]) == \"[5 6]\"\n    assert mcode(A[1:2, 1:3]) == \"[5 6]\"\n    assert mcode(A[1:2, 1:3]) == \"[5 6]\"\n    assert mcode(A[1:2, 1:3]) == \"[5 6]\"\n"], "sample_186": ["def test_prepopulated_fields(self):\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title', 'nonexistent')}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'prepopulated_fields['slug']' refers to 'nonexistent', \"\n            \"which is not an attribute of 'admin_checks.Song'.\",\n            obj=SongAdmin,\n            id='admin.E027',\n        )\n    ]\n    self.assertEqual(errors, expected)\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n"], "sample_409": ["def test_i18n42(self):\n    \"\"\"simple translation of a variable with noop\"\"\"\n    output = self.engine.render_to_string(\"i18n42\", {\"bar\": \"\u00c5\"})\n    self.assertEqual(output, \"\u00c5\")\n"], "sample_709": ["def test_pytester_syspathinsert(pytester: Pytester) -> None:\n    pytester.syspathinsert()\n    assert pytester.path in sys.path\n    pytester.syspathinsert(None)\n    assert pytester.path not in sys.path\n"], "sample_362": ["def test_alter_field_with_default(self):\n    \"\"\"Tests autodetection of altered fields with a default.\"\"\"\n    changes = self.get_changes([self.author_name], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, 'testapp', 0, 0, default='Ada Lovelace')\n"], "sample_659": ["def test_raises_repr_exception_info(self):\n    class E(Exception):\n        pass\n\n    with pytest.raises(E) as excinfo:\n        raise E()\n\n    reprinfo = excinfo.traceback[-1].frame.code.fullsource\n    assert repr(excinfo) == reprinfo\n"], "sample_74": ["def test_empty_connection_params(self):\n    self.assertEqual(\n        self._run_it({\n            'database': 'dbname',\n        }), (\n            ['psql', 'dbname'],\n            {},\n        )\n    )\n"], "sample_1180": ["def test_issue_12345():\n    \"\"\"Test that Point3D.direction_cosine and Point3D.direction_ratio work correctly.\"\"\"\n    p1 = Point3D(1, 2, 3)\n    p2 = Point3D(4, 5, 6)\n    assert p1.direction_cosine(p2) == [sqrt(6)/sqrt(56), sqrt(35)/sqrt(56), sqrt(35)/sqrt(56)]\n    assert p1.direction_ratio(p2) == [3, 3, 3]\n"], "sample_385": ["    def test_get_context(self):\n        form = AlbumForm()\n        context = form[\"band\"].field.widget.get_context(\n            name=\"my_field\", value=None, attrs={}\n        )\n        self.assertIn(\"rendered_widget\", context)\n        self.assertIn(\"is_hidden\", context)\n        self.assertIn(\"name\", context)\n        self.assertIn(\"url_params\", context)\n        self.assertIn(\"model\", context)\n        self.assertIn(\"can_add_related\", context)\n        self.assertIn(\"can_change_related\", context)\n        self.assertIn(\"can_delete_related\", context)\n        self.assertIn(\"can_view_related\", context)\n        self.assertIn(\"add_related_url\", context)\n        self.assertIn(\"delete_related_template_url\", context)\n        self.assertIn(\"change_related_template_url\", context)\n"], "sample_631": ["    def setup_method(self):\n        super().setup_method()\n        self._to_consume_backup = self.checker._to_consume\n        self.checker._to_consume = []\n"], "sample_919": ["def test_template_params():\n    check('class', \"template<typename T> {key}A\", {2: \"I0E1A\"})\n    check('class', \"template<typename T> template<typename U> {key}A\", {2: \"I00E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> {key}A\", {2: \"I000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> {key}A\", {2: \"I0000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> template<typename X> {key}A\", {2: \"I00000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> template<typename X> template<typename Y> {key}A\", {2: \"I000000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> template<typename X> template<typename Y> template<typename Z> {key}A\", {2: \"I0000000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> template<typename X> template<typename Y> template<typename Z> template<typename AA> {key}A\", {2: \"I00000000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> template<typename X> template<typename Y> template<typename Z> template<typename AA> template<typename BB> {key}A\", {2: \"I000000000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> template<typename X> template<typename Y> template<typename Z> template<typename AA> template<typename BB> template<typename CC> {key}A\", {2: \"I0000000000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> template<typename X> template<typename Y> template<typename Z> template<typename AA> template<typename BB> template<typename CC> template<typename DD> {key}A\", {"], "sample_967": ["def test_mathjax_path(app, status, warning):\n    app.builder.build_all()\n\n    content = (app.outdir / 'index.html').read_text()\n    assert 'https://example.com/mathjax.js' in content\n"], "sample_318": ["    def test_urlpattern_repr(self):\n        url_pattern = URLPattern(RegexPattern(r'^$'), views.empty_view)\n        self.assertEqual(\n            repr(url_pattern),\n            \"<URLPattern ^$>\"\n        )\n"], "sample_555": ["def test_arc_in_collection_with_alpha(fig_test, fig_ref):\n    arc1 = Arc([.5, .5], .5, 1, theta1=0, theta2=60, angle=20)\n    arc2 = Arc([.5, .5], .5, 1, theta1=0, theta2=60, angle=20)\n    col = mcollections.PatchCollection(patches=[arc2], facecolors='none',\n                                       edgecolors='k', alpha=0.5)\n    fig_ref.subplots().add_patch(arc1)\n    fig_test.subplots().add_collection(col)\n"], "sample_975": ["def test_issue_11768():\n    x = Symbol('x')\n    eq = x**2/(1 - x)/(1 - 2*x)**2 - 100\n    # The root -2 was divided out, so make sure we don't find it.\n    assert nsolve(eq.as_numer_denom()[0], 0.46) == 0.46792545969349058\n"], "sample_194": ["    def setUpTestData(cls):\n        cls.p1, cls.p2 = UniqueConstraintProduct.objects.bulk_create([\n            UniqueConstraintProduct(name='p1', color='red'),\n            UniqueConstraintProduct(name='p2'),\n        ])\n"], "sample_236": ["    def test_delete_with_keeping_parents_reverse_relationships(self):\n        child = RChild.objects.create()\n        parent_id = child.r_ptr_id\n        child.delete(keep_parents=True)\n        self.assertFalse(RChild.objects.filter(id=child.id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(S.objects.filter(r=parent_id).exists())\n\n        childchild = RChildChild.objects.create()\n        parent_id = childchild.rchild_ptr.r_ptr_id\n        child_id = childchild.rchild_ptr_id\n        parent_referent_id = S.objects.create(r=childchild.rchild_ptr.r_ptr).pk\n        childchild.delete(keep_parents=True)\n        self.assertFalse(RChildChild.objects.filter(id=childchild.id).exists())\n        self.assertTrue(RChild.objects.filter(id=child_id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(S.objects.filter(r=parent_id).exists())\n"], "sample_443": ["    def setUp(self):\n        super().setUp()\n        self.dirname = self.mkdtemp()\n        # Caches location cannot be modified through override_settings /\n        # modify_settings, hence settings are manipulated directly here and the\n        # setting_changed signal is triggered manually.\n        for cache_params in settings.CACHES.values():\n            cache_params[\"LOCATION\"] = self.dirname\n        setting_changed.send(self.__class__, setting=\"CACHES\", enter=False)\n"], "sample_212": ["def test_process_request_sets_session(self):\n    \"\"\"\n    Test that process_request sets the session on the request.\n    \"\"\"\n    request = HttpRequest()\n    middleware = SessionMiddleware()\n    middleware.process_request(request)\n    self.assertIsNotNone(request.session)\n"], "sample_297": ["    def setUpTestData(cls):\n        cls.t1 = Tag.objects.create(name='t1', category=NamedCategory.objects.create(name='Generic'))\n        cls.t2 = Tag.objects.create(name='t2', parent=cls.t1, category=NamedCategory.objects.create(name='Generic'))\n        cls.t3 = Tag.objects.create(name='t3', parent=cls.t1)\n        cls.t4 = Tag.objects.create(name='t4', parent=cls.t3)\n        cls.t5 = Tag.objects.create(name='t5', parent=cls.t3)\n"], "sample_156": ["def test_boundfield_repr(self):\n    class SomeForm(Form):\n        field = CharField()\n\n    boundfield = SomeForm()['field']\n    self.assertEqual(repr(boundfield), \"<BoundField: field>\")\n    self.assertEqual(repr(boundfield), boundfield.__repr__())\n"], "sample_452": ["def test_rename_field_with_unique_together(self):\n    \"\"\"\n    Tests the RenameField operation with a unique_together constraint.\n    \"\"\"\n    project_state = self.set_up_test_model(\"test_rnflut\", unique_together=True)\n    operation = migrations.RenameField(\"Pony\", \"pink\", \"blue\")\n    new_state = project_state.clone()\n    operation.state_forwards(\"test_rnflut\", new_state)\n    # unique_together has the renamed column.\n    self.assertIn(\n        \"blue\",\n        new_state.models[\"test_rnflut\", \"pony\"].options[\"unique_together\"][0],\n    )\n    self.assertNotIn(\n        \"pink\",\n        new_state.models[\"test_rnflut\", \"pony\"].options[\"unique_together\"][0],\n    )\n    # Rename field.\n    self.assertColumnExists(\"test_rnflut_pony\", \"pink\")\n    self.assertColumnNotExists(\"test_rnflut_pony\", \"blue\")\n    with connection.schema_editor() as editor:\n        operation.database_forwards(\"test_rnflut\", editor, project_state, new_state)\n    self.assertColumnExists(\"test_rnflut_pony\", \"blue\")\n    self.assertColumnNotExists(\"test_rnflut_pony\", \"pink\")\n    # The unique constraint has been ported over.\n    with connection.cursor() as cursor:\n        cursor.execute(\"INSERT INTO test_rnflut_pony (blue, weight) VALUES (1, 1)\")\n        with self.assertRaises(IntegrityError):\n            with atomic():\n                cursor.execute(\n                    \"INSERT INTO test_rnflut_pony (blue, weight) VALUES (1, 1)\"\n                )\n        cursor.execute(\"DELETE FROM test_rnflut_pony\")\n    # Reversal.\n    with connection.schema_editor() as editor:\n        operation.database_backwards(\n            \"test_rnflut\", editor, new_state, project_state\n        )\n    self.assertColumnExists(\"test_rnflut_pony\", \"pink\")\n    self.assertColumnNotExists(\"test_rnflut_pony\", \"blue\")\n\n    # Test deconstruction\n    definition = operation.deconstruct()\n    self.assertEqual(definition[0], \"RenameField\")\n    self.assertEqual(definition[1], [])\n    self.assertEqual(\n        definition[2],\n        {\"model_name\": \"Pony\", \"old_name\": \"pink"], "sample_1120": ["def test_matrix_derivative():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', n, n)\n    E = MatrixSymbol('E', m, n)\n    w = MatrixSymbol('w', n, 1)\n\n    dexpr = diff((D*w)[k,0], w[p,0])\n\n    assert w[k, p].diff(w[k, p]) == 1\n    assert w[k, p].diff(w[0, 0]) == KroneckerDelta(0, k, (0, n-1))*KroneckerDelta(0, p, (0, 0))\n    _i_1 = Dummy(\"_i_1\")\n    assert dexpr.dummy_eq(Sum(KroneckerDelta(_i_1, p, (0, n-1))*D[k, _i_1], (_i_1, 0, n - 1)))\n    assert dexpr.doit() == D[k, p]\n\n    dexpr = diff((D*w)[k,0], w[0,0])\n    assert dexpr.dummy_eq(Sum(KroneckerDelta(_i_1, p, (0, n-1))*D[k, _i_1], (_i_1, 0, n - 1)))\n    assert dexpr.doit() == D[k, p]\n\n    dexpr = diff((D*w)[k,0], w[p,0])\n    assert dexpr.dummy_eq(Sum(KroneckerDelta(_i_1, p, (0, n-1))*D[k, _i_1], (_i_1, 0, n - 1)))\n    assert dexpr.doit() == D[k, p]\n\n    dexpr = diff((D*w)[k,0], w[p,0])\n    assert dexpr.dummy_eq(Sum(KroneckerDelta(_i_1, p, (0, n-1))*D[k, _i_1], (_i_1, 0, n - 1)))\n    assert dexpr.doit() == D[k, p]\n\n    dexpr = diff((D*w)[k,0], w[p,0])\n    assert dexpr.dummy_eq(Sum(KroneckerDelta(_i_1, p,"], "sample_34": ["def test_compose_into_arbitrary_units():\n    # Issue #1438\n    from ...constants import G\n    G.decompose([u.kg, u.km, u.Unit(\"15 s\")])\n"], "sample_368": ["def test_migrate_with_replaced_migration(self):\n    \"\"\"\n    Test migrating with a replaced migration.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Were the tables there before?\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_book\")\n    # Alright, let's try running it\n    executor.migrate([(\"migrations\", \"0001_squashed_0002\")])\n    # Are the tables there now?\n    self.assertTableExists(\"migrations_author\")\n    self.assertTableExists(\"migrations_book\")\n    # Rebuild the graph to reflect the new DB state\n    executor.loader.build_graph()\n    # Alright, let's undo what we did\n    executor.migrate([(\"migrations\", None)])\n    # Are the tables gone?\n    self.assertTableNotExists(\"migrations_author\")\n    self.assertTableNotExists(\"migrations_book\")\n"], "sample_994": ["def test_Float_precision():\n    # Make sure Float inputs for keyword args work\n    assert Float('1.0', dps=Float(15))._prec == 53\n    assert Float('1.0', precision=Float(15))._prec == 15\n    assert type(Float('1.0', precision=Float(15))._prec) == int\n    assert sympify(srepr(Float('1.0', precision=15))) == Float('1.0', precision=15)\n"], "sample_339": ["    def test_modelformset_factory_with_custom_save_method_related_instance(self):\n        \"\"\"\n        The ModelForm.save() method should be able to access the related object\n        if it exists in the database (#24395).\n        \"\"\"\n        class PoemForm2(forms.ModelForm):\n                poem = super().save(commit=False)\n                poem.name = \"%s by %s\" % (poem.name, poem.poet.name)\n                if commit:\n                    poem.save()\n                return poem\n\n        PoemFormSet = inlineformset_factory(Poet, Poem, form=PoemForm2, fields=\"__all__\")\n        data = {\n            'poem_set-TOTAL_FORMS': '1',\n            'poem_set-INITIAL_FORMS': '0',\n            'poem_set-MAX_NUM_FORMS': '',\n            'poem_set-0-name': 'Le Lac',\n        }\n        poet = Poet()\n        formset = PoemFormSet(data=data, instance=poet)\n        self.assertTrue(formset.is_valid())\n\n        # The Poet instance is saved after the formset instantiation. This\n        # happens in admin's changeform_view() when adding a new object and\n        # some inlines in the same request.\n        poet.name = 'Lamartine'\n        poet.save()\n        poem = formset.save()[0]\n        self.assertEqual(poem.name, 'Le Lac by Lamartine')\n"], "sample_598": ["def test_inline_sparse_repr(self):\n    array = sparse.COO(np.array([1, 2, 3]), (3,), (0, 1, 2))\n    expected = \"<COO: nnz=3, fill_value=0>\"\n    actual = formatting.inline_sparse_repr(array)\n    assert expected == actual\n\n    array = sparse.COO(np.array([1, 2, 3]), (3,), (0, 1, 2), fill_value=5)\n    expected = \"<COO: nnz=3, fill_value=5>\"\n    actual = formatting.inline_sparse_repr(array)\n    assert expected == actual\n\n    array = sparse.COO(np.array([1, 2, 3]), (3,), (0, 1, 2), fill_value=None)\n    expected = \"<COO: nnz=3>\"\n    actual = formatting.inline_sparse_repr(array)\n    assert expected == actual\n"], "sample_396": ["    def setUpTestData(cls):\n        cls.a1 = Author.objects.create(name=\"a1\", num=1001, extra=ExtraInfo.objects.create())\n        cls.a2 = Author.objects.create(name=\"a2\", num=2002, extra=ExtraInfo.objects.create())\n        cls.a3 = Author.objects.create(name=\"a3\", num=3003, extra=ExtraInfo.objects.create())\n        cls.a4 = Author.objects.create(name=\"a4\", num=4004, extra=ExtraInfo.objects.create())\n"], "sample_998": ["def test_latex_Dict():\n    d = {Rational(1): 1, x**2: 2, x: 3, x**3: 4}\n    assert latex(d) == r'\\left \\{ 1 : 1, \\quad x : 3, \\quad x^{2} : 2, \\quad x^{3} : 4\\right \\}'\n    D = Dict(d)\n    assert latex(D) == r'\\left \\{ 1 : 1, \\quad x : 3, \\quad x^{2} : 2, \\quad x^{3} : 4\\right \\}'\n"], "sample_1195": ["def test_kahane_simplify2():\n    i0,i1,i2,i3,i4,i5,i6,i7,i8,i9,i10,i11,i12,i13,i14,i15 = tensor_indices('i0:16', LorentzIndex)\n    mu, nu, rho, sigma = tensor_indices(\"mu, nu, rho, sigma\", LorentzIndex)\n    D = 4\n    t = G(i0)*G(i1)*G(i2)*G(i3)*G(-i0)*G(-i1)*G(-i2)*G(-i3)\n    r = kahane_simplify(t)\n    assert r.equals(4*G(i2)*G(i3)*G(i1))\n\n    t = G(i0)*G(i1)*G(i2)*G(i3)*G(-i0)*G(-i1)*G(-i2)*G(-i3)*G(i4)\n    r = kahane_simplify(t)\n    assert r.equals(4*G(i2)*G(i3)*G(i1)*G(i4))\n\n    t = G(i0)*G(i1)*G(i2)*G(i3)*G(-i0)*G(-i1)*G(-i2)*G(-i3)*G(i4)*G(i5)\n    r = kahane_simplify(t)\n    assert r.equals(4*G(i2)*G(i3)*G(i1)*G(i4)*G(i5))\n\n    t = G(i0)*G(i1)*G(i2)*G(i3)*G(-i0)*G(-i1)*G(-i2)*G(-i3)*G(i4)*G(i5)*G(i6)\n    r = kahane_simplify(t)\n    assert r.equals(4*G(i2)*G(i3)*G(i1)*G(i4)*G(i5)*G(i6))\n\n    t = G(i0)*G(i1)*G(i2)*G(i3)*G(-i0)*G(-i1)*G(-i2)*G(-i3)*G(i4)*G(i5)*G(i6)*G(i7)\n    r = kahane_simplify(t)\n    assert r.equals(4*G(i2)*G(i3)*G(i1)*G(i4)*G(i5)*G(i6)*G(i7))\n\n    t = G(i0)*"], "sample_49": ["def test_media_merge_with_none(self):\n    # Test that Media.merge() handles lists containing None values correctly\n    test_values = (\n        (([1, None, 2], [3, 4]), [1, 2, 3, 4]),\n        (([1, 2], [None, 3]), [1, 2, 3]),\n        (([None, 2], [1, 3]), [1, 2, 3]),\n        (([1, None, 3], [2, 3]), [1, 2, 3]),\n        (([1, 2], [1, None, 3]), [1, 2, 3]),\n        (([1, 2], [3, None, 2]), [1, 3, 2]),\n    )\n    for (list1, list2), expected in test_values:\n        with self.subTest(list1=list1, list2=list2):\n            self.assertEqual(Media.merge(list1, list2), expected)\n\n    # Test that Media.merge() warns when lists contain None values in different orders\n    msg = 'Detected duplicate Media files in an opposite order:\\n1\\n2'\n    with self.assertWarnsMessage(RuntimeWarning, msg):\n        self.assertEqual(Media.merge([1, None, 2], [2, 1]), [1, 2])\n"], "sample_987": ["def test_evalf_atan():\n    assert NS('atan(1)', 15) == '0.785398163397448'\n    assert NS('atan(10**-6)', 15) == '9.99999999999833e-7'\n    assert NS('atan(10**-6)', 20) == '9.999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999"], "sample_542": ["def test_wrap_line_width():\n    fig, ax = plt.subplots()\n    text = fig.text(0.5, 0.5, 'This is a very long text that should be wrapped multiple times.', wrap=True)\n    fig.canvas.draw()\n    assert text._get_wrap_line_width() == 2.0\n"], "sample_334": ["def test_boundfield_iterable(self):\n    class BeatleForm(Form):\n        name = ChoiceField(\n            choices=[('john', 'John'), ('paul', 'Paul'), ('george', 'George'), ('ringo', 'Ringo')],\n            widget=RadioSelect,\n        )\n\n    f = BeatleForm(auto_id=False)\n    self.assertEqual(\n        [str(bf) for bf in f['name']],\n        ['<label><input type=\"radio\" name=\"name\" value=\"john\" required> John</label>',\n         '<label><input type=\"radio\" name=\"name\" value=\"paul\" required> Paul</label>',\n         '<label><input type=\"radio\" name=\"name\" value=\"george\" required> George</label>',\n         '<label><input type=\"radio\" name=\"name\" value=\"ringo\" required> Ringo</label>']\n    )\n    self.assertEqual(\n        [str(bf) for bf in f['name'][1:]],\n        ['<label><input type=\"radio\" name=\"name\" value=\"paul\" required> Paul</label>',\n         '<label><input type=\"radio\" name=\"name\" value=\"george\" required> George</label>',\n         '<label><input type=\"radio\" name=\"name\" value=\"ringo\" required> Ringo</label>']\n    )\n    self.assertEqual(\n        [str(bf) for bf in f['name'][1:2]],\n        ['<label><input type=\"radio\" name=\"name\" value=\"paul\" required> Paul</label>']\n    )\n    self.assertEqual(\n        [str(bf) for bf in f['name'][1:3]],\n        ['<label><input type=\"radio\" name=\"name\" value=\"paul\" required> Paul</label>',\n         '<label><input type=\"radio\" name=\"name\" value=\"george\" required> George</label>']\n    )\n    self.assertEqual(\n        [str(bf) for bf in f['name'][1:4]],\n        ['<label><input type=\"radio\" name=\"name\" value=\"paul\" required> Paul</label>',\n         '<label><input type=\"radio\" name=\"name\" value=\"george\" required> George</label>',\n         '<label><input type=\"radio\" name=\"name\" value=\"ringo\" required> Ringo</label>']\n   "], "sample_835": ["def test_staged_predict_proba():\n    # Check staged predict_proba.\n    rng = np.random.RandomState(0)\n    iris_weights = rng.randint(10, size=iris.target.shape)\n    boston_weights = rng.randint(10, size=boston.target.shape)\n\n    clf = AdaBoostClassifier(n_estimators=10)\n    clf.fit(iris.data, iris.target, sample_weight=iris_weights)\n\n    proba = clf.predict_proba(iris.data)\n    staged_probas = [p for p in clf.staged_predict_proba(iris.data)]\n    score = clf.score(iris.data, iris.target, sample_weight=iris_weights)\n    staged_scores = [\n        s for s in clf.staged_score(\n            iris.data, iris.target, sample_weight=iris_weights)]\n\n    assert len(staged_probas) == 10\n    assert_array_almost_equal(proba, staged_probas[-1])\n    assert len(staged_scores) == 10\n    assert_array_almost_equal(score, staged_scores[-1])\n\n    # AdaBoost regression\n    clf = AdaBoostRegressor(n_estimators=10, random_state=0)\n    clf.fit(boston.data, boston.target, sample_weight=boston_weights)\n\n    proba = clf.predict_proba(boston.data)\n    staged_probas = [p for p in clf.staged_predict_proba(boston.data)]\n    score = clf.score(boston.data, boston.target, sample_weight=boston_weights)\n    staged_scores = [\n        s for s in clf.staged_score(\n            boston.data, boston.target, sample_weight=boston_weights)]\n\n    assert len(staged_probas) == 10\n    assert_array_almost_equal(proba, staged_probas[-1])\n    assert len(staged_scores) == 10\n    assert_array_almost_equal(score, staged_scores[-1])\n"], "sample_305": ["    def test_aggregate_with_subquery(self):\n        # Regression test for #12822: DatabaseError: aggregates not allowed in\n        # WHERE clause\n\n        # The subselect works and returns results equivalent to a\n        # query with the IDs listed.\n        qs = Book.objects.values('contact').annotate(Max('id'))\n        qs = qs.order_by('contact').values_list('id__max', flat=True)\n        # don't do anything with the queryset (qs) before including it as a\n        # subquery\n        books = Book.objects.order_by('id')\n        qs1 = books.filter(id__in=qs)\n        qs2 = books.filter(id__in=list(qs))\n        self.assertEqual(list(qs1), list(qs2))\n\n        # The subselect works and returns results equivalent to a\n        # query with the IDs listed.\n        qs = Book.objects.values('contact').annotate(Max('id'))\n        qs = qs.order_by('contact').values_list('id__max', flat=True)\n        # force the queryset (qs) for the subquery to be evaluated in its\n        # current state\n        list(qs)\n        books = Book.objects.order_by('id')\n        qs1 = books.filter(id__in=qs)\n        qs2 = books.filter(id__in=list(qs))\n        self.assertEqual(list(qs1), list(qs2))\n\n        # Regression test for #12822: DatabaseError: aggregates not allowed in\n        # WHERE clause\n\n        # The subselect works and returns results equivalent to a\n        # query with the IDs listed.\n        qs = Book.objects.values('contact').annotate(Max('id'))\n        qs = qs.order_by('contact').values_list('id__max', flat=True)\n        # don't do anything with the queryset (qs) before including it as a\n        # subquery\n        books = Book.objects.order_by('id')\n        qs1 = books.filter(id__in=qs)\n        qs2 = books.filter(id__in=list(qs))\n        self.assertEqual(list(qs1), list(qs2))\n\n        # The subselect works and returns results equivalent to a\n        # query with the IDs listed.\n        qs = Book.objects.values('contact').annotate(Max('id'))\n        qs = qs.order_by('contact').values_list('id__max', flat=True)\n        # force the queryset (qs) for the subquery to be evaluated in"], "sample_964": ["def test_pydata_with_union_type_operator_old(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :annotation: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0],\n                ([desc_name, \"version\"],\n                 [desc_annotation, ([desc_sig_punctuation, ':'],\n                                    desc_sig_space,\n                                    [pending_xref, \"int\"],\n                                    desc_sig_space,\n                                    [desc_sig_punctuation, \"|\"],\n                                    desc_sig_space,\n                                    [pending_xref, \"str\"])]))\n"], "sample_774": ["def test_one_hot_encoder_sparse_output():\n    X = np.array([[3, 2, 1], [0, 1, 1]])\n    enc = OneHotEncoder(sparse=True)\n    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):\n        X_trans = enc.fit_transform(X)\n        assert sparse.isspmatrix(X_trans)\n        assert_array_equal(X_trans.toarray().shape, (2, 5))\n        assert_array_equal(enc.active_features_,\n                           np.where([1, 0, 0, 1, 0, 1, 1, 0, 1])[0])\n        assert_array_equal(enc.feature_indices_, [0, 4, 7, 9])\n"], "sample_946": ["def test_pydata_with_union_type_operator_old(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :annotation: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0],\n                ([desc_name, \"version\"],\n                 [desc_annotation, (\": \",\n                                    [pending_xref, \"int\"],\n                                    \" \",\n                                    [desc_sig_punctuation, \"|\"],\n                                    \" \",\n                                    [pending_xref, \"str\"])]))\n"], "sample_962": ["def test_stringify_type_hints_ForwardRef():\n    from typing import ForwardRef  # type: ignore\n    assert stringify(ForwardRef(\"myint\")) == \"myint\"\n"], "sample_1013": ["def test_lambdify_with_indexed():\n    # Test for issue 10934\n    if not numpy:\n        skip(\"numpy not installed\")\n\n    a = IndexedBase('a')\n    i, j = symbols('i j')\n    b = numpy.array([[1, 2], [3, 4]])\n    assert lambdify(a, a[i, j])(b) == b\n"], "sample_459": ["    def test_exact_lookup(self):\n        \"\"\"\n        Exact lookups work as expected.\n        \"\"\"\n        instance = self.model.objects.create(value=1)\n        self.assertEqual(self.model.objects.get(value__exact=1), instance)\n        self.assertEqual(self.model.objects.get(value__exact=2), None)\n"], "sample_527": ["def test_figure_subplot_params():\n    fig = plt.figure()\n    assert fig.subplotpars.left == 0.125\n    assert fig.subplotpars.right == 0.9\n    assert fig.subplotpars.bottom == 0.1\n    assert fig.subplotpars.top == 0.9\n    assert fig.subplotpars.wspace == 0.2\n    assert fig.subplotpars.hspace == 0.2\n\n    fig.subplots_adjust(left=0.1, right=0.8, bottom=0.2, top=0.8)\n    assert fig.subplotpars.left == 0.1\n    assert fig.subplotpars.right == 0.8\n    assert fig.subplotpars.bottom == 0.2\n    assert fig.subplotpars.top == 0.8\n    assert fig.subplotpars.wspace == 0.2\n    assert fig.subplotpars.hspace == 0.2\n\n    fig.subplotpars.update(left=0.05, right=0.95, bottom=0.15, top=0.85)\n    assert fig.subplotpars.left == 0.05\n    assert fig.subplotpars.right == 0.95\n    assert fig.subplotpars.bottom == 0.15\n    assert fig.subplotpars.top == 0.85\n    assert fig.subplotpars.wspace == 0.2\n    assert fig.subplotpars.hspace == 0.2\n\n    with pytest.raises(ValueError):\n        fig.subplotpars.update(left=0.95, right=0.05)\n\n    with pytest.raises(ValueError):\n        fig.subplotpars.update(bottom=0.95, top=0.05)\n"], "sample_786": ["def test_inverse_transform_1d_behavior():\n    X = np.arange(4)\n    est = KBinsDiscretizer(n_bins=2)\n    est.fit(X.reshape(-1, 1))\n    assert_raises(ValueError, est.inverse_transform, X)\n"], "sample_387": ["    def test_inline_formset_formfield_overrides(self):\n        \"\"\"\n        Test that formfield_overrides are applied to inline formsets.\n        \"\"\"\n        class MyInline(admin.StackedInline):\n            model = Member\n            formfield_overrides = {\n                CharField: {\"widget\": forms.TextInput(attrs={\"size\": \"10\"})}\n            }\n\n        ma = MyInline(Member, admin.site)\n        ff = ma.formfield_for_dbfield(Member._meta.get_field(\"name\"), request=None)\n        self.assertIsInstance(ff.widget, forms.TextInput)\n        self.assertEqual(ff.widget.attrs[\"maxlength\"], 100)\n        self.assertEqual(ff.widget.attrs[\"size\"], 10)\n"], "sample_669": ["    def test_global_capture_is_disabled_by_option(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n                print(\"hello\")\n            \"\"\"\n        )\n        result = testdir.runpytest(\"--capture=no\")\n        result.stdout.fnmatch_lines([\"*hello*\"])\n"], "sample_27": ["def test_headerdiff_floating_point_atol(self):\n    ha = Header([(\"A\", 1), (\"B\", 1.0), (\"C\", 0.0)])\n    hb = ha.copy()\n    hb[\"B\"] = 1.00001\n    hb[\"C\"] = 0.000001\n    diff = HeaderDiff(ha, hb, atol=1e-6)\n    assert not diff.identical\n    assert diff.diff_keyword_values == {\"B\": [(1.0, 1.00001)]}\n    diff = HeaderDiff(ha, hb, atol=1e-5)  # strict inequality\n    assert not diff.identical\n    assert diff.diff_keyword_values == {\"B\": [(1.0, 1.00001)]}\n    diff = HeaderDiff(ha, hb, rtol=1e-5, atol=1e-5)\n    assert diff.identical\n    diff = HeaderDiff(ha, hb, atol=1.1e-5)\n    assert diff.identical\n    diff = HeaderDiff(ha, hb, rtol=1e-6, atol=1e-6)\n    assert not diff.identical\n"], "sample_673": ["    def test_doctest_report_ndiff_with_unicode(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n                '''\n                >>> foo()\n                   a  b\n                0  1  4\n                1  2  5\n                2  3  6\n                '''\n                print('   a  b\\\\n'\n                      '0  1  4\\\\n'\n                      '1  2  5\\\\n'\n                      '2  3  6')\n            \"\"\"\n        )\n        return testdir.runpytest(\"--doctest-modules\", \"--doctest-report\", \"ndiff\")\n"], "sample_710": ["def test_setup_teardown_failure_is_shown(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n        class MyTestCase(unittest.TestCase):\n                assert 0, \"down1\"\n                assert 0, \"down2\"\n                pass\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-s\")\n    assert result.ret == 1\n    result.stdout.fnmatch_lines([\"*setUp*\", \"*assert 0*down1*\", \"*tearDown*\", \"*assert 0*down2*\", \"*1 failed*\"])\n    result.stdout.no_fnmatch_line(\"*down1*\")\n"], "sample_834": ["def test_init_with_pca():\n    \"\"\"Test that PCA initialization is correct.\n\n    Puts four points in the input space where the opposite labels points are\n    next to each other. After transform the samples from the same class\n    should be next to each other.\n\n    \"\"\"\n    X = np.array([[0, 0], [0, 1], [2, 0], [2, 1]])\n    y = np.array([1, 0, 1, 0])\n    nca = NeighborhoodComponentsAnalysis(n_components=2, init='pca',\n                                         random_state=42)\n    nca.fit(X, y)\n    X_t = nca.transform(X)\n    assert_array_equal(pairwise_distances(X_t).argsort()[:, 1],\n                       np.array([2, 3, 0, 1]))\n"], "sample_678": ["def test_cleanup_candidates(tmp_path):\n    \"\"\"Ensure that cleanup_candidates returns the correct paths.\"\"\"\n    root = tmp_path / \"root\"\n    root.mkdir()\n    (root / \"prefix-1\").mkdir()\n    (root / \"prefix-2\").mkdir()\n    (root / \"prefix-3\").mkdir()\n\n    # Test that paths with numbers less than or equal to max_delete are returned.\n    max_existing = 2\n    keep = 1\n    max_delete = max_existing - keep\n    expected_paths = [root / \"prefix-1\"]\n    assert list(cleanup_candidates(root, \"prefix\", keep)) == expected_paths\n\n    # Test that paths with numbers greater than max_delete are not returned.\n    max_existing = 2\n    keep = 1\n    max_delete = max_existing - keep\n    expected_paths = [root / \"prefix-1\"]\n    assert list(cleanup_candidates(root, \"prefix\", keep)) == expected_paths\n\n    # Test that paths with numbers less than or equal to max_delete are returned when max_delete is -1.\n    max_existing = 2\n    keep = 1\n    max_delete = -1\n    expected_paths = [root / \"prefix-1\", root / \"prefix-2\", root / \"prefix-3\"]\n    assert list(cleanup_candidates(root, \"prefix\", keep)) == expected_paths\n\n    # Test that paths with numbers less than or equal to max_delete are returned when max_delete is greater than max_existing.\n    max_existing = 2\n    keep = 1\n    max_delete = 3\n    expected_paths = [root / \"prefix-1\", root / \"prefix-2\", root / \"prefix-3\"]\n    assert list(cleanup_candidates(root, \"prefix\", keep)) == expected_paths\n\n    # Test that paths with numbers less than or equal to max_delete are returned when max_delete is equal to max_existing.\n    max_existing = 2\n    keep = 1\n    max_delete = max_existing\n    expected_paths = [root / \"prefix-1\"]\n    assert list(cleanup_candidates(root, \"prefix\", keep)) == expected_paths\n\n    # Test that paths with numbers less than or equal to max_delete are returned when max_delete is less than 0.\n    max_existing = 2\n    keep = 1\n    max_delete = -10\n    expected_paths = [root / \"prefix-1\", root / \"prefix-2"], "sample_635": ["def test_finds_multiple_return_types_numpy(self) -> None:\n    \"\"\"Example of a function with multiple return types in the Numpy style docstring\"\"\"\n    node = astroid.extract_node(\n        \"\"\"\n            \"\"\"The docstring\n\n            Args\n            ----\n            named_arg : object\n                Returned\n\n            Returns\n            -------\n                object or None\n                    Maybe named_arg\n            \"\"\"\n            return named_arg\n        \"\"\"\n    )\n    with self.assertNoMessages():\n        self.checker.visit_functiondef(node)\n"], "sample_1156": ["def test_acsch_expansion():\n    x, y = symbols('x,y')\n    assert acsch(x+y).expand(trig=True) == acsch(x)*acsch(y) + 1/(x*y*(x + y))\n    assert acsch(2*x).expand(trig=True) == acsch(x)/x**2 + 1/(2*x*(x + 1))\n    assert acsch(3*x).expand(trig=True).expand() == \\\n        acsch(x)**3/x**6 + 3*acsch(x)/x**4 + 1/(3*x*(x + 1)*(x + 2))\n"], "sample_741": ["def test_grid_search_with_sparse_target():\n    # Test that grid search works with sparse target\n    X, y = make_classification(n_samples=200, n_features=100, random_state=0)\n    y = sp.csr_matrix(y)\n    Cs = [.1, 1, 10]\n    clf = LinearSVC()\n    grid_search = GridSearchCV(clf, {'C': Cs})\n    grid_search.fit(X, y)\n    assert_true(grid_search.best_estimator_.C in Cs)\n"], "sample_434": ["    def test_template_view_responds_correctly(self):\n        request_factory = RequestFactory()\n        view = TemplateView(template_name=\"test_template.html\")\n        response = view.get(request_factory.get(\"/\"))\n        self.assertIsInstance(response, TemplateResponse)\n"], "sample_529": ["def test_legend_title_fontsize():\n    # test the title_fontsize kwarg\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontsize=22)\n    assert leg.get_title().get_fontsize() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontsize() == 20\n"], "sample_1145": ["def test_refine_matrixelement():\n    X = MatrixSymbol('X', 3, 3)\n    assert refine(X[0, 1], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.symmetric(X)) == X[0, 1]\n    assert refine(X[1, 0], Q.asymmetric(X)) == X[1, 0]\n    assert refine(X[0, 1], Q.asymmetric(X)) == X[0, 1]\n    assert refine(X[0, 0], Q.symmetric(X)) == X[0, 0]\n    assert refine(X[0, 0], Q.asymmetric(X)) == X[0, 0]\n    assert refine(X[1, 2], Q.symmetric(X)) == X[1, 2]\n    assert refine(X[2, 1], Q.symmetric(X)) == X[1, 2]\n    assert refine(X[2, 1], Q.asymmetric(X)) == X[2, 1]\n    assert refine(X[1, 2], Q.asymmetric(X)) == X[1, 2]\n"], "sample_602": ["def test_open_dataset_chunks():\n    ds = xr.Dataset(\n        dict(a=2 * np.arange(5)), coords=dict(x=(\"x\", np.arange(5), dict(units=\"s\")))\n    )\n    chunks = {\"x\": 2}\n    actual = xr.open_dataset(\"fake_filename\", chunks=chunks, engine=\"netcdf4\")\n    expected = xr.Dataset(\n        dict(a=2 * np.arange(5)), coords=dict(x=(\"x\", np.arange(5), dict(units=\"s\")))\n    )\n    expected = expected.chunk(chunks)\n    assert_identical(expected, actual)\n"], "sample_1161": ["def test_Dict_printing():\n    d = Dict({1: 1 + x, 2: y*x})\n    assert str(d) == \"{1: x + 1, 2: x*y}\"\n    assert sstr(d) == \"{1: x + 1, 2: x*y}\"\n"], "sample_70": ["    def test_delete_with_keeping_parents_and_related_objects(self):\n        child = RChild.objects.create()\n        parent_id = child.r_ptr_id\n        parent_referent_id = S.objects.create(r=child.r_ptr).pk\n        child.related_set.create(s=S.objects.create(r=child.r_ptr))\n        child.delete(keep_parents=True)\n        self.assertFalse(RChild.objects.filter(id=child.id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n        self.assertTrue(S.objects.filter(r=parent_id).exists())\n"], "sample_811": ["def test_pairwise_distances_argmin_min_axis():\n    # Check pairwise minimum distances computation for any metric\n    X = [[0], [1]]\n    Y = [[-2], [3]]\n\n    Xsp = dok_matrix(X)\n    Ysp = csr_matrix(Y, dtype=np.float32)\n\n    expected_idx = [0, 1]\n    expected_vals = [2, 2]\n    expected_vals_sq = [4, 4]\n\n    # euclidean metric\n    idx, vals = pairwise_distances_argmin_min(X, Y, axis=0, metric=\"euclidean\")\n    idx2 = pairwise_distances_argmin(X, Y, axis=0, metric=\"euclidean\")\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(idx2, expected_idx)\n    assert_array_almost_equal(vals, expected_vals)\n    # sparse matrix case\n    idxsp, valssp = pairwise_distances_argmin_min(Xsp, Ysp, axis=0, metric=\"euclidean\")\n    assert_array_almost_equal(idxsp, expected_idx)\n    assert_array_almost_equal(valssp, expected_vals)\n    # We don't want np.matrix here\n    assert_equal(type(idxsp), np.ndarray)\n    assert_equal(type(valssp), np.ndarray)\n\n    # euclidean metric squared\n    idx, vals = pairwise_distances_argmin_min(X, Y, axis=0, metric=\"euclidean\",\n                                              metric_kwargs={\"squared\": True})\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(vals, expected_vals_sq)\n\n    # Non-euclidean scikit-learn metric\n    idx, vals = pairwise_distances_argmin_min(X, Y, axis=0, metric=\"manhattan\")\n    idx2 = pairwise_distances_argmin(X, Y, axis=0, metric=\"manhattan\")\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(idx2, expected_idx)\n    assert_array_almost_equal(vals, expected_vals)\n    # sparse matrix case\n    idxsp, valssp = pairwise_distances_argmin_min(Xsp, Ysp, axis=0, metric=\"manhattan\")\n    assert_array_almost_equal(idxsp, expected_idx)\n    assert_array_almost_equal(valssp, expected_vals)\n\n    # Non-euclidean Scipy distance (callable)\n    idx, vals = pairwise_distances_argmin_min(X, Y, axis=0, metric=minkowski,\n                                              metric_kwargs={\"p\": 2})\n    assert_array_almost_equal"], "sample_1073": ["def test_issue_12421():\n    I = S.ImaginaryUnit\n    assert sqrtdenest((3 + sqrt(2)*sqrt(4 + 3*I) + 3*I)/2) == I\n    e = 3 + sqrt(2)*sqrt(4 + I) + 3*I\n    assert sqrtdenest(e) == e\n"], "sample_716": ["def test_ridge_solver_switch():\n    # Test that solver switch works as expected\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([5, 6])\n\n    # Test that solver switch works as expected\n    for solver in ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']:\n        ridge = Ridge(solver=solver, fit_intercept=False)\n        ridge.fit(X, y)\n        assert_equal(ridge.coef_.shape, (X.shape[1], ))\n\n    # Test that solver switch works as expected when fit_intercept is True\n    for solver in ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']:\n        ridge = Ridge(solver=solver, fit_intercept=True)\n        ridge.fit(X, y)\n        assert_equal(ridge.coef_.shape, (X.shape[1], ))\n        assert_equal(ridge.intercept_.shape, ())\n\n    # Test that solver switch works as expected when sample_weight is provided\n    for solver in ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']:\n        ridge = Ridge(solver=solver, fit_intercept=False)\n        ridge.fit(X, y, sample_weight=np.array([1, 2]))\n        assert_equal(ridge.coef_.shape, (X.shape[1], ))\n\n    # Test that solver switch works as expected when normalize is True\n    for solver in ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']:\n        ridge = Ridge(solver=solver, normalize=True, fit_intercept=False)\n        ridge.fit(X, y)\n        assert_equal(ridge.coef_.shape, (X.shape[1], ))\n\n    # Test that solver switch works as expected when max_iter is provided\n    for solver in ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']:\n        ridge = Ridge(solver=solver, max_iter=10, fit_intercept=False)\n        ridge.fit(X, y)\n        assert_equal(ridge.coef_.shape, (X.shape[1], ))\n\n    # Test that solver switch works as expected when tol is provided\n    for solver in ['svd', 'cholesky', 'ls"], "sample_347": ["def test_make_naive_pytz_fold(self):\n    self.assertEqual(\n        timezone.make_naive(CET.localize(datetime.datetime(2011, 9, 1, 12, 20, 30, fold=0)), CET),\n        datetime.datetime(2011, 9, 1, 12, 20, 30)\n    )\n    self.assertEqual(\n        timezone.make_naive(CET.localize(datetime.datetime(2011, 9, 1, 12, 20, 30, fold=1)), CET),\n        datetime.datetime(2011, 9, 1, 12, 20, 30, fold=1)\n    )\n"], "sample_414": ["    def test_inline_formset_formfield_overrides(self):\n        class MyInline(admin.StackedInline):\n            model = Member\n            formfield_overrides = {\n                CharField: {\"widget\": forms.TextInput(attrs={\"size\": \"10\"})}\n            }\n\n        ma = MyInline(Member, admin.site)\n        f = ma.formfield_for_dbfield(Member._meta.get_field(\"name\"), request=None)\n        self.assertIsInstance(f.widget, forms.TextInput)\n        self.assertEqual(f.widget.attrs[\"maxlength\"], 100)\n        self.assertEqual(f.widget.attrs[\"size\"], 10)\n"], "sample_671": ["    def test_strict_xfail_with_reason(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.mark.xfail(reason='unsupported feature', strict=True)\n                pass\n        \"\"\"\n        )\n        result = testdir.runpytest(p, \"-rxX\")\n        result.stdout.fnmatch_lines([\"*XFAIL*\", \"*unsupported feature*\"])\n        assert result.ret == 0\n"], "sample_992": ["def test_MpmathPrinter():\n    p = MpmathPrinter()\n    assert 'mpmath' in p.module_imports\n    assert p.doprint(pi) == 'mpmath.pi'\n    assert p.doprint(acos(x)) == 'mpmath.acos(x)'\n    assert p.doprint(Mod(x, 2)) == 'mpmath.mpf(x % 2)'\n    assert p.doprint(And(x, y)) == 'mpmath.logical_and(x, y)'\n    assert p.doprint(Or(x, y)) == 'mpmath.logical_or(x, y)'\n    assert p.doprint(Not(x)) == 'mpmath.logical_not(x)'\n    assert p.doprint(x**y) == 'x**y'\n    assert p.doprint(Assignment(x, 2)) == 'x = 2'\n    assert p.doprint(x**y) == 'x**y'\n    assert p.doprint(Mod(x, 2)) == 'mpmath.mpf(x % 2)'\n    assert p.doprint(And(x, y)) == 'mpmath.logical_and(x, y)'\n    assert p.doprint(Or(x, y)) == 'mpmath.logical_or(x, y)'\n    assert p.doprint(Not(x)) == 'mpmath.logical_not(x)'\n    assert p.doprint(x**y) == 'x**y'\n    assert p.doprint(Assignment(x, 2)) == 'x = 2'\n    assert p.doprint(x**y) == 'x**y'\n    assert p.doprint(Mod(x, 2)) == 'mpmath.mpf(x % 2)'\n    assert p.doprint(And(x, y)) == 'mpmath.logical_and(x, y)'\n    assert p.doprint(Or(x, y)) == 'mpmath.logical_or(x, y)'\n    assert p.doprint(Not(x)) == 'mpmath.logical_not(x)'\n    assert p.doprint(x**y) == 'x**y'\n    assert p.doprint(Assignment(x, 2)) == 'x = 2'\n    assert p.doprint(x**y) == 'x**y'\n    assert p.doprint(Mod(x, 2)) == 'mpmath.mpf(x % 2)'\n    assert p.doprint(And(x, y)) =="], "sample_32": ["    def test_de_density_scale(self, cosmo):\n        \"\"\"Test :meth:`astropy.cosmology.Flatw0wzCDM.de_density_scale`.\"\"\"\n        # Test scalar\n        z = 0.5\n        expected = (z + 1.0) ** (3.0 * (1.0 + cosmo.w0 - cosmo.wz)) * exp(\n            3.0 * cosmo.wz * z\n        )\n        assert u.allclose(cosmo.de_density_scale(z), expected)\n\n        # Test array\n        z = np.array([0.0, 0.5, 1.0, 1.5, 2.3])\n        expected = (z + 1.0) ** (3.0 * (1.0 + cosmo.w0 - cosmo.wz)) * exp(\n            3.0 * cosmo.wz * z\n        )\n        assert u.allclose(cosmo.de_density_scale(z), expected)\n"], "sample_268": ["    def test_iter_modules_and_files_cache(self):\n        filename = self.temporary_file('test_module.py')\n        filename.write_text('import os')\n        with extend_sys_path(str(filename.parent)):\n            self.import_and_cleanup('test_module')\n        self.clear_autoreload_caches()\n        self.assertFileFound(filename)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().hits, 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().misses, 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().maxsize, 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().currsize, 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().get(autoreload.iter_modules_and_files.cache_info().keys()[0]), 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().get(autoreload.iter_modules_and_files.cache_info().keys()[1]), 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().get(autoreload.iter_modules_and_files.cache_info().keys()[2]), 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().get(autoreload.iter_modules_and_files.cache_info().keys()[3]), 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().get(autoreload.iter_modules_and_files.cache_info().keys()[4]), 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().get(autoreload.iter_modules_and_files.cache_info().keys()[5]), 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().get(autoreload.iter_modules_and_files.cache_info().keys()[6]), 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().get(autoreload.iter_modules_and_files.cache_info().keys()[7]), 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().get(autoreload.iter_modules_and_files.cache_info().keys()[8]), 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().get(autoreload.iter_modules_and_files.cache_info().keys()[9]), 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().get(autoreload.iter_modules_and_files.cache_info()."], "sample_355": ["    def create_users(self):\n        self.user = CustomUser._default_manager.create_user(\n            email='test@example.com',\n            password='test',\n            date_of_birth=date(2006, 4, 25)\n        )\n        self.superuser = CustomUser._default_manager.create_superuser(\n            email='test2@example.com',\n            password='test',\n            date_of_birth=date(1976, 11, 8)\n        )\n"], "sample_615": ["def test_unify_chunks() -> None:\n    array = np.arange(10)\n    variable = xr.Variable(\"x\", array)\n    data_array = xr.DataArray(variable, [(\"x\", -array)])\n    dataset = xr.Dataset({\"y\": variable}, {\"x\": -array})\n\n    unified = unify_chunks(array, variable, data_array, dataset)\n    assert_identical(array, unified[0])\n    assert_identical(variable, unified[1])\n    assert_identical(data_array, unified[2])\n    assert_identical(dataset, unified[3])\n\n    # test that the chunks are unified\n    assert unified[0].chunks == unified[1].chunks == unified[2].chunks == unified[3].chunks\n"], "sample_1192": ["def test_disambiguate():\n    S = sympify\n    x = Symbol('x')\n    y = Symbol('x')\n    z = Symbol('y')\n    w = Symbol('y')\n    assert disambiguate(x, y, z, w) == (x, y_1, y_2, z)\n"], "sample_278": ["    def test_deconstruct(self):\n        expr = ExpressionList(F('col'), F('anothercol'))\n        path, args, kwargs = expr.deconstruct()\n        self.assertEqual(path, 'django.db.models.expressions.ExpressionList')\n        self.assertEqual(args, (expr.expressions,))\n        self.assertEqual(kwargs, {})\n"], "sample_67": ["    def test_save_m2m(self):\n        class InventoryForm(forms.ModelForm):\n            class Meta:\n                model = Inventory\n                fields = '__all__'\n\n        inventory = Inventory.objects.create(barcode=86, name='Apple')\n        form = InventoryForm({'barcode': 87, 'name': 'Core', 'parent': inventory.pk})\n        self.assertTrue(form.is_valid())\n        inventory = form.save()\n        self.assertEqual(inventory.parent, inventory)\n        self.assertEqual(inventory.parent.name, 'Apple')\n"], "sample_753": ["def test_logistic_regression_path_convergence():\n    # Test that the path algorithm converges\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = [1] * 100 + [-1] * 100\n    Cs = [1e3]\n    assert_warns(ConvergenceWarning, logistic_regression_path,\n                 X, y, Cs=Cs, tol=0., max_iter=1, random_state=0, verbose=1)\n"], "sample_203": ["    def test_file_extension_validator(self):\n        class MyForm(forms.Form):\n            file = forms.FileField(validators=[validators.FileExtensionValidator(allowed_extensions=['txt'])])\n\n        file = SimpleUploadedFile('test.txt', b'Hello, world!')\n        form = MyForm({'file': file})\n        self.assertTrue(form.is_valid())\n\n        file = SimpleUploadedFile('test.pdf', b'Hello, world!')\n        form = MyForm({'file': file})\n        self.assertFalse(form.is_valid())\n        self.assertEqual(form.errors['file'], ['File extension \u201cpdf\u201d is not allowed. Allowed extensions are: txt.'])\n\n        file = SimpleUploadedFile('test.txt', b'Hello, world!')\n        form = MyForm({'file': file})\n        self.assertTrue(form.is_valid())\n\n        file = SimpleUploadedFile('test.txt', b'Hello, world!')\n        form = MyForm({'file': file})\n        self.assertTrue(form.is_valid())\n\n        file = SimpleUploadedFile('test.txt', b'Hello, world!')\n        form = MyForm({'file': file})\n        self.assertTrue(form.is_valid())\n\n        file = SimpleUploadedFile('test.txt', b'Hello, world!')\n        form = MyForm({'file': file})\n        self.assertTrue(form.is_valid())\n\n        file = SimpleUploadedFile('test.txt', b'Hello, world!')\n        form = MyForm({'file': file})\n        self.assertTrue(form.is_valid())\n\n        file = SimpleUploadedFile('test.txt', b'Hello, world!')\n        form = MyForm({'file': file})\n        self.assertTrue(form.is_valid())\n\n        file = SimpleUploadedFile('test.txt', b'Hello, world!')\n        form = MyForm({'file': file})\n        self.assertTrue(form.is_valid())\n\n        file = SimpleUploadedFile('test.txt', b'Hello, world!')\n        form = MyForm({'file': file})\n        self.assertTrue(form.is_valid())\n\n        file = SimpleUploadedFile('test.txt', b'Hello, world!')\n        form = MyForm({'file': file})\n        self.assertTrue(form.is_valid())\n\n        file = SimpleUploadedFile('test.txt', b'Hello, world!')\n        form = MyForm({'file': file})\n        self.assertTrue(form.is_valid())\n\n        file = SimpleUploadedFile('test.txt', b'Hello, world!')\n        form = MyForm({'file': file})\n        self.assertTrue(form.is_valid())\n\n        file = SimpleUploadedFile('test.txt', b'Hello, world"], "sample_17": ["    def setup_method(self):\n        self.q = np.array([1.0, 2.0, 3.0]) * u.m\n"], "sample_90": ["    def test_save_m2m(self):\n        class InventoryForm(forms.ModelForm):\n            class Meta:\n                model = Inventory\n                fields = '__all__'\n\n        inventory = Inventory.objects.create(barcode=86, name='Apple')\n        form = InventoryForm({'barcode': 87, 'name': 'Core', 'parent': inventory.pk})\n        self.assertTrue(form.is_valid())\n        inventory = form.save()\n        self.assertEqual(inventory.parent.name, 'Apple')\n        self.assertEqual(inventory.parent.barcode, 86)\n        self.assertEqual(inventory.parent.pk, 86)\n"], "sample_37": ["def test_sip_with_altkey():\n    \"\"\"\n    Test that when creating a WCS object using a key, CTYPE with\n    that key is looked at and not the primary CTYPE.\n    fix for #5443.\n    \"\"\"\n    with fits.open(get_pkg_data_filename('data/sip.fits')) as f:\n        w = wcs.WCS(f[0].header)\n    # create a header with two WCSs.\n    h1 = w.to_header(relax=True, key='A')\n    h2 = w.to_header(relax=False)\n    h1['CTYPE1A'] = \"RA---SIN-SIP\"\n    h1['CTYPE2A'] = \"DEC--SIN-SIP\"\n    h1.update(h2)\n    w = wcs.WCS(h1, key='A')\n    assert (w.wcs.ctype == np.array(['RA---SIN-SIP', 'DEC--SIN-SIP'])).all()\n"], "sample_568": ["def test_surface3d_zsort_nan():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n\n    x, y = np.mgrid[-2:2:0.1, -2:2:0.1]\n    z = np.sin(x)**2 + np.cos(y)**2\n    z[x.shape[0] // 2:, x.shape[1] // 2:] = np.nan\n\n    ax.plot_surface(x, y, z, cmap='jet')\n    ax.view_init(elev=45, azim=145)\n"], "sample_360": ["    def tearDown(self):\n        cache.clear()\n"], "sample_361": ["def test_urlize_with_nofollow(self):\n    tests = (\n        (\n            'Search for google.com/?q=! and see.',\n            'Search for <a href=\"http://google.com/?q=\" rel=\"nofollow\">google.com/?q=</a>! and see.'\n        ),\n        (\n            'Search for google.com/?q=1&lt! and see.',\n            'Search for <a href=\"http://google.com/?q=1%3C\" rel=\"nofollow\">google.com/?q=1&lt</a>! and see.'\n        ),\n        (\n            lazystr('Search for google.com/?q=!'),\n            'Search for <a href=\"http://google.com/?q=\" rel=\"nofollow\">google.com/?q=</a>!'\n        ),\n        ('foo@example.com', '<a href=\"mailto:foo@example.com\">foo@example.com</a>'),\n        ('http://example.com', '<a href=\"http://example.com\">http://example.com</a>'),\n    )\n    for value, output in tests:\n        with self.subTest(value=value):\n            self.assertEqual(urlize(value, nofollow=True), output)\n"], "sample_1112": ["def test_is_palindromic():\n    assert is_palindromic(12321) == True\n    assert is_palindromic(123456) == False\n    assert is_palindromic(12321, 2) == True\n    assert is_palindromic(123456, 2) == False\n    assert is_palindromic(0o121) == True\n    assert is_palindromic(0o123) == False\n    assert is_palindromic(0o121, 8) == True\n    assert is_palindromic(0o123, 8) == False\n    raises(ValueError, lambda: is_palindromic('a'))\n    raises(ValueError, lambda: is_palindromic(123, 1))\n"], "sample_932": ["def test_template_specialization():\n    check('class', \"template<> {key}A\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int>\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int, int>\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int, int, int>\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int, int, int, int>\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int, int, int, int, int>\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int>\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int>\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int, int>\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int, int, int>\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int, int, int, int>\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int, int, int, int, int>\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int, int, int, int, int, int>\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int, int, int, int, int, int, int>\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int, int, int, int, int,"], "sample_58": ["def test_boundfield_repr(self):\n    class SomeForm(Form):\n        field = CharField()\n\n    boundfield = SomeForm()['field']\n    self.assertEqual(repr(boundfield), \"<BoundField: field>\")\n    self.assertEqual(repr(boundfield), boundfield.__repr__())\n"], "sample_117": ["    def test_render_with_invalid_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = 'invalid_password'\n        self.assertHTMLEqual(\n            widget.render('name', value, {'id': 'id_password'}),\n            \"\"\"\n            <div id=\"id_password\">\n                <strong>Invalid password format or unknown hashing algorithm.</strong>\n            </div>\n            \"\"\"\n        )\n"], "sample_865": ["def test_min_impurity_decrease_with_min_samples_leaf():\n    # Test if min_impurity_decrease ensures that a split is made only if\n    # if the impurity decrease is atleast that value when min_samples_leaf > 0.\n    X, y = datasets.make_classification(n_samples=10000, random_state=42)\n\n    # test both DepthFirstTreeBuilder and BestFirstTreeBuilder\n    # by setting max_leaf_nodes\n    for max_leaf_nodes, name in product((None, 1000), ALL_TREES.keys()):\n        TreeEstimator = ALL_TREES[name]\n\n        # Check default value of min_impurity_decrease, 1e-7\n        est1 = TreeEstimator(max_leaf_nodes=max_leaf_nodes, random_state=0)\n        # Check with explicit value of 0.05\n        est2 = TreeEstimator(max_leaf_nodes=max_leaf_nodes,\n                             min_impurity_decrease=0.05, random_state=0)\n        # Check with a much lower value of 0.0001\n        est3 = TreeEstimator(max_leaf_nodes=max_leaf_nodes,\n                             min_impurity_decrease=0.0001, random_state=0)\n        # Check with a much lower value of 0.1\n        est4 = TreeEstimator(max_leaf_nodes=max_leaf_nodes,\n                             min_impurity_decrease=0.1, random_state=0)\n\n        for est, expected_decrease in ((est1, 1e-7), (est2, 0.05),\n                                       (est3, 0.0001), (est4, 0.1)):\n            assert est.min_impurity_decrease <= expected_decrease, (\n                \"Failed, min_impurity_decrease = {0} > {1}\".format(\n                    est.min_impurity_decrease,\n                    expected_decrease))\n            est.fit(X, y)\n            for node in range(est.tree_.node_count):\n                # If current node is a not leaf node, check if the split was\n                # justified w.r.t the min_impurity_decrease\n                if est.tree_.children_left[node] != TREE_LEAF:\n                    imp_parent = est.tree_.impurity[node]\n                    wtd_n_node = est.tree_.weighted_n_node_samples[node]\n\n                    left = est.tree_.children_left[node]\n                    wtd_n_left = est.tree_.weighted_n_node_samples[left]\n                    imp_left = est.tree_.impurity[left]\n"], "sample_3": ["def test_ecsv_round_trip_masked_table_serialize_null(tmpdir):\n    \"\"\"Test (mostly) round-trip of MaskedColumn through ECSV using null value\n    serialization.  Note:\n\n    >>> simple_table(masked=True)\n    <Table masked=True length=3>\n      a      b     c\n    int64 float64 str1\n    ----- ------- ----\n       --     1.0    c\n        2     2.0   --\n        3      --    e\n    \"\"\"\n    filename = str(tmpdir.join('test.ecsv'))\n\n    t = simple_table(masked=True)  # int, float, and str cols with one masked element\n    t.write(filename, serialize_method='null_value')\n\n    t2 = Table.read(filename)\n    assert t2.masked is False\n    assert t2.colnames == t.colnames\n    for name in t2.colnames:\n        # From formal perspective the round-trip columns are the \"same\"\n        assert np.all(t2[name].mask == t[name].mask)\n        assert np.all(t2[name] == t[name])\n\n        # But peeking under the mask shows that the underlying data are changed\n        # because by default ECSV uses \"\" to represent masked elements.\n        t[name].mask = False\n        t2[name].mask = False\n        assert not np.all(t2[name] == t[name])  # Expected diff\n"], "sample_911": ["def test_template_specialization():\n    check('class', 'template<int T> A', {2: \"I_iE1A\"})\n    check('class', 'template<int T> A<int>', {2: \"I_iE1A\"})\n    check('class', 'template<int T> A<int, int>', {2: \"I_iE1A\"})\n    check('class', 'template<int T> A<int, int, int>', {2: \"I_iE1A\"})\n    check('class', 'template<int T> A<int, int, int, int>', {2: \"I_iE1A\"})\n    check('class', 'template<int T> A<int, int, int, int, int>', {2: \"I_iE1A\"})\n    check('class', 'template<int T> A<int, int, int, int, int, int>', {2: \"I_iE1A\"})\n    check('class', 'template<int T> A<int, int, int, int, int, int, int>', {2: \"I_iE1A\"})\n    check('class', 'template<int T> A<int, int, int, int, int, int, int, int>', {2: \"I_iE1A\"})\n    check('class', 'template<int T> A<int, int, int, int, int, int, int, int, int>', {2: \"I_iE1A\"})\n    check('class', 'template<int T> A<int, int, int, int, int, int, int, int, int, int>', {2: \"I_iE1A\"})\n    check('class', 'template<int T> A<int, int, int, int, int, int, int, int, int, int, int>', {2: \"I_iE1A\"})\n    check('class', 'template<int T> A<int, int, int, int, int, int, int, int, int, int, int, int>', {2: \"I_iE1A\"})\n    check('class', 'template<int T> A<int, int, int, int, int, int, int, int, int, int, int, int, int>', {2: \"I_iE1A\"})\n    check('class', 'template<int T> A<int, int, int, int, int"], "sample_846": ["def test_column_transformer_sparse_threshold_zero():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n\n    # all sparse\n    ct = ColumnTransformer([('trans1', OneHotEncoder(sparse=True), [0]),\n                            ('trans2', OneHotEncoder(sparse=True), [1])],\n                           sparse_threshold=0.0)\n    res = ct.fit_transform(X_array)\n    assert sparse.issparse(res)\n    assert ct.sparse_output_\n\n    # all dense\n    ct = ColumnTransformer([('trans1', OneHotEncoder(sparse=False), [0]),\n                            ('trans2', OneHotEncoder(sparse=False), [1])],\n                           sparse_threshold=0.0)\n    res = ct.fit_transform(X_array)\n    assert not sparse.issparse(res)\n    assert not ct.sparse_output_\n\n    # mixed\n    ct = ColumnTransformer([('trans1', OneHotEncoder(sparse=True), [0]),\n                            ('trans2', OneHotEncoder(sparse=False), [1])],\n                           sparse_threshold=0.0)\n    res = ct.fit_transform(X_array)\n    assert sparse.issparse(res)\n    assert ct.sparse_output_\n"], "sample_895": ["def test_column_transformer_set_output_after_fitting_transform():\n    \"\"\"Check column transformer behavior with set_output after fitting and transforming.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame(\n        {\n            \"pet\": pd.Series([\"dog\", \"cat\", \"snake\"], dtype=\"category\"),\n            \"age\": [1.4, 2.1, 4.4],\n            \"height\": [20, 40, 10],\n        }\n    )\n    ct = ColumnTransformer(\n        [\n            (\n                \"color_encode\",\n                OneHotEncoder(sparse_output=False, dtype=\"int16\"),\n                [\"pet\"],\n            ),\n            (\"age\", StandardScaler(), [\"age\"]),\n        ],\n        verbose_feature_names_out=False,\n    )\n\n    # fit and transform without calling set_output\n    X_trans = ct.fit_transform(df)\n    assert isinstance(X_trans, np.ndarray)\n    assert X_trans.dtype == \"float64\"\n\n    ct.set_output(transform=\"pandas\")\n    X_trans_df = ct.transform(df)\n    expected_dtypes = {\n        \"pet_cat\": \"int16\",\n        \"pet_dog\": \"int16\",\n        \"pet_snake\": \"int16\",\n        \"height\": \"int64\",\n        \"age\": \"float64\",\n    }\n    for col, dtype in X_trans_df.dtypes.items():\n        assert dtype == expected_dtypes[col]\n"], "sample_530": ["def test_offsetbox_draw_frame():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100)\n    da.add_artist(mpatches.Rectangle((0, 0), 100, 100, linewidth=0))\n    ab = AnnotationBbox(da, (0.5, 0.5), xybox=(-0.2, 0.5), xycoords='data',\n                        boxcoords=\"axes fraction\", box_alignment=(0., .5),\n                        arrowprops=None)\n    ax.add_artist(ab)\n    ab.draw_frame = False\n    ab.draw(fig.canvas.get_renderer())\n    assert not ab.stale\n    ab.draw_frame = True\n    ab.draw(fig.canvas.get_renderer())\n    assert ab.stale\n"], "sample_538": ["def test_transformed_bbox():\n    t = mtransforms.Affine2D()\n    bbox = mtransforms.Bbox([[0, 0], [1, 1]])\n    trans_bbox = mtransforms.TransformedBbox(bbox, t)\n    assert_array_equal(trans_bbox.get_points(), t.transform(bbox.get_points()))\n    assert_array_equal(trans_bbox.get_points(), t.transform(bbox.get_points()))\n    # Changing the transform should change the result.\n    t.rotate(np.pi / 4)\n    assert_array_almost_equal(trans_bbox.get_points(),\n                            np.array([[0.7071067811865475, 0.7071067811865475],\n                                      [0.7071067811865475, -0.7071067811865475]]))\n    # Changing the bbox should change the result.\n    bbox.set_points(bbox.get_points() + 10)\n    assert_array_almost_equal(trans_bbox.get_points(),\n                            np.array([[0.7071067811865475, 0.7071067811865475],\n                                      [0.7071067811865475, -0.7071067811865475]]))\n"], "sample_941": ["def test_stringify_type_hints_Annotated():\n    from typing import Annotated  # type: ignore\n    assert stringify(Annotated[int, \"foo\"]) == \"int\"\n    assert stringify(Annotated[str, \"foo\", \"bar\"]) == \"str\"  # NOQA\n    assert stringify(Annotated[None, \"foo\"]) == \"None\"\n    assert stringify(Annotated[bool, \"foo\"]) == \"bool\"\n    assert stringify(Annotated[bool, \"foo\", \"bar\"]) == \"bool\"  # NOQA\n"], "sample_426": ["def test_time_strings_override(self):\n    \"\"\"Test that time_strings can be overridden.\"\"\"\n    time_strings = {\n        \"minute\": npgettext_lazy(\n            \"naturaltime-future\",\n            \"%(num)d minute\",\n            \"%(num)d minutes\",\n            \"num\",\n        ),\n        \"hour\": npgettext_lazy(\n            \"naturaltime-future\",\n            \"%(num)d hour\",\n            \"%(num)d hours\",\n            \"num\",\n        ),\n    }\n    with translation.override(\"cs\"):\n        self.assertEqual(\n            timesince(self.t, self.t + self.oneminute, time_strings=time_strings),\n            \"1\\xa0minut\",\n        )\n        self.assertEqual(\n            timesince(self.t, self.t + self.onehour, time_strings=time_strings),\n            \"1\\xa0hodina\",\n        )\n        self.assertEqual(\n            timesince(self.t, self.t + self.oneday, time_strings=time_strings),\n            \"1\\xa0den\",\n        )\n        self.assertEqual(\n            timesince(self.t, self.t + self.oneweek, time_strings=time_strings),\n            \"1\\xa0t\u00fdden\",\n        )\n        self.assertEqual(\n            timesince(self.t, self.t + self.onemonth, time_strings=time_strings),\n            \"1\\xa0m\u011bs\u00edc\",\n        )\n        self.assertEqual(\n            timesince(self.t, self.t + self.oneyear, time_strings=time_strings),\n            \"1\\xa0rok\",\n        )\n"], "sample_1103": ["def test_Pow_is_nonzero():\n    z = Symbol('z', zero=True)\n    e = z**2\n    assert e.is_zero\n    assert e.is_nonzero is False\n\n    assert Pow(0, 0, evaluate=False).is_nonzero is False\n    assert Pow(0, 3, evaluate=False).is_nonzero is False\n    assert Pow(0, oo, evaluate=False).is_nonzero is False\n    assert Pow(0, -3, evaluate=False).is_nonzero is True\n    assert Pow(0, -oo, evaluate=False).is_nonzero is True\n    assert Pow(2, 2, evaluate=False).is_nonzero is True\n\n    a = Symbol('a', zero=False)\n    assert Pow(a, 3).is_nonzero is True  # issue 7965\n\n    assert Pow(2, oo, evaluate=False).is_nonzero is True\n    assert Pow(2, -oo, evaluate=False).is_nonzero is False\n    assert Pow(S.Half, oo, evaluate=False).is_nonzero is False\n    assert Pow(S.Half, -oo, evaluate=False).is_nonzero is True\n\n    # All combinations of real/complex base/exponent\n    h = S.Half\n    T = True\n    F = False\n    N = None\n\n    pow_isnonzero = [\n        ['**',  0,  h,  1,  2, -h, -1,-2,-2*I,-I/2,I/2,1+I,oo,-oo,zoo],\n        [   0,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F],\n        [   h,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F],\n        [   1,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F,  F],\n        [   2,  F,  F,  F,  F,  F,  F,  F,  F"], "sample_310": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n        with captured_stderr() as self.docutils_stderr:\n            self.response = self.client.get(reverse('django-admindocs-models-detail', args=['admin_docs', 'Person']))\n"], "sample_267": ["    def test_database_features(self):\n        features = connection.features\n        self.assertTrue(features.supports_pragma_foreign_key_check)\n        self.assertTrue(features.supports_pragma_foreign_keys)\n        self.assertTrue(features.supports_savepoints)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self.assertTrue(features.supports_transactions)\n        self"], "sample_1206": ["def test_issue_10368():\n    a = Rational(32442016954, 78058255275)\n    assert int(a) == int(-a)\n"], "sample_623": ["    def create_dataset(self, shape, chunks):\n        \"\"\"Return a dataset with a variable with the given shape and chunks.\"\"\"\n        dims = tuple(f\"dim_{idx}\" for idx in range(len(shape)))\n        return xr.Dataset(\n            {\n                \"data\": xr.Variable(\n                    dims,\n                    np.empty(shape, dtype=np.dtype(\"V1\")),\n                    encoding={\"chunks\": dict(zip(dims, chunks))},\n                )\n            }\n        )\n"], "sample_832": ["def test_bayesian_ridge_intercept():\n    # Test BayesianRidge with intercept\n    X = np.array([[1], [2], [6], [8], [10]])\n    y = np.array([1, 2, 6, 8, 10])\n    clf = BayesianRidge(compute_score=True, fit_intercept=True)\n    clf.fit(X, y)\n\n    # Check that the model could approximately learn the identity function\n    test = [[1], [3], [4]]\n    assert_array_almost_equal(clf.predict(test), [1, 3, 4], 2)\n\n    # Check that the intercept is correctly set\n    assert_almost_equal(clf.intercept_, 0.0)\n"], "sample_289": ["    def test_dictwrapper_with_none_value(self):\n            return \"*%s\" % x\n        d = DictWrapper({'a': None}, f, 'xx_')\n        self.assertEqual(\n            \"Normal: %(a)s. Modified: %(xx_a)s\" % d,\n            'Normal: None. Modified: *None'\n        )\n"], "sample_815": ["def test_precision_recall_fscore_support_multilabel_1():\n    # Test precision_recall_fscore_support on a crafted multilabel example\n    # First crafted example\n\n    y_true = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 1]])\n    y_pred = np.array([[0, 1, 0, 0], [0, 1, 0, 0], [1, 0, 1, 0]])\n\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average=None)\n\n    # tp = [0, 1, 1, 0]\n    # fn = [1, 0, 0, 1]\n    # fp = [1, 1, 0, 0]\n    # Check per class\n\n    assert_array_almost_equal(p, [0.0, 0.5, 1.0, 0.0], 2)\n    assert_array_almost_equal(r, [0.0, 1.0, 1.0, 0.0], 2)\n    assert_array_almost_equal(f, [0.0, 1 / 1.5, 1, 0.0], 2)\n    assert_array_almost_equal(s, [1, 1, 1, 1], 2)\n\n    f2 = fbeta_score(y_true, y_pred, beta=2, average=None)\n    support = s\n    assert_array_almost_equal(f2, [0, 0.83, 1, 0], 2)\n\n    # Check macro\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred,\n                                                 average=\"macro\")\n    assert_almost_equal(p, 1.5 / 4)\n    assert_almost_equal(r, 0.5)\n    assert_almost_equal(f, 2.5 / 1.5 * 0.25)\n    assert_equal(s, None)\n    assert_almost_equal(fbeta_score(y_true, y_pred, beta=2, average=\"macro\"),\n                        np.mean(f2))\n\n    # Check micro\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred,\n                                                 average=\"micro\")\n    assert_almost_equal(p, 0.5"], "sample_163": ["    def test_password_change_fails_with_invalid_old_password_and_custom_form(self):\n        self.login()\n        response = self.client.post(\n            \"/password_change/custom/\",\n            {\n                \"old_password\": \"donuts\",\n                \"new_password1\": \"password1\",\n                \"new_password2\": \"password1\",\n            },\n        )\n        self.assertFormError(\n            response, PasswordChangeForm.error_messages[\"password_incorrect\"]\n        )\n"], "sample_367": ["    def test_cache_page_decorator_http_request(self):\n        class MyClass:\n            @cache_page(123)\n                return HttpResponse()\n\n        msg = (\n            \"cache_page didn't receive an HttpRequest. If you are decorating \"\n            \"a classmethod, be sure to use @method_decorator.\"\n        )\n        request = HttpRequest()\n        with self.assertRaisesMessage(TypeError, msg):\n            MyClass().a_view(request)\n        with self.assertRaisesMessage(TypeError, msg):\n            MyClass().a_view(HttpRequestProxy(request))\n"], "sample_567": ["def test_wrap_rotation():\n    fig = plt.figure(figsize=(6, 4))\n    s = 'This is a very long text that should be wrapped multiple times.'\n    text = fig.text(0.1, 0.7, s, wrap=True, rotation=30)\n    fig.canvas.draw()\n    assert text._get_wrapped_text() == ('This is a very long\\n'\n                                        'text that should be\\n'\n                                        'wrapped multiple\\n'\n                                        'times.')\n"], "sample_383": ["    def setUpTestData(cls):\n        cls.num1 = Number.objects.create(num=1)\n        cls.num2 = Number.objects.create(num=2)\n        cls.num3 = Number.objects.create(num=3)\n"], "sample_344": ["    def test_bound_field_sanity_check(self):\n        field = models.CharField(max_length=1)\n        field.model = models.Model\n        with self.assertRaisesMessage(ValueError, 'ModelState.fields cannot be bound to a model - \"field\" is.'):\n            ModelState('app', 'Model', [('field', field)])\n"], "sample_510": ["def test_matshow():\n    fig, ax = plt.subplots()\n    A = np.arange(9).reshape(3, 3)\n    matshow(A)\n    assert ax.get_images()[0].get_array().shape == A.shape\n    plt.close()\n"], "sample_1027": ["def test_Poly__hash__():\n    assert hash(Poly(x + 1)) == hash((Poly(x + 1).rep, (x,)))\n    assert hash(Poly(x + 1, x)) == hash((Poly(x + 1).rep, (x,)))\n    assert hash(Poly(x + 1, x, y)) == hash((Poly(x + 1).rep, (x, y)))\n    assert hash(Poly(x + 1, x, y, z)) == hash((Poly(x + 1).rep, (x, y, z)))\n\n    assert hash(Poly(x + 1, x, y, z, w)) == hash((Poly(x + 1).rep, (x, y, z, w))\n\n    assert hash(Poly(x + 1, x, y, z, w, v)) == hash((Poly(x + 1).rep, (x, y, z, w, v))\n\n    assert hash(Poly(x + 1, x, y, z, w, v, u)) == hash((Poly(x + 1).rep, (x, y, z, w, v, u))\n\n    assert hash(Poly(x + 1, x, y, z, w, v, u, t)) == hash((Poly(x + 1).rep, (x, y, z, w, v, u, t))\n\n    assert hash(Poly(x + 1, x, y, z, w, v, u, t, s)) == hash((Poly(x + 1).rep, (x, y, z, w, v, u, t, s))\n\n    assert hash(Poly(x + 1, x, y, z, w, v, u, t, s, r)) == hash((Poly(x + 1).rep, (x, y, z, w, v, u, t, s, r))\n\n    assert hash(Poly(x + 1, x, y, z, w, v, u, t, s, r, q)) == hash((Poly(x + 1).rep, (x, y, z, w, v, u, t, s, r, q))\n\n    assert hash(Poly(x + 1, x, y, z, w, v, u, t, s, r, q"], "sample_433": ["def test_add_field_with_default_value(self):\n    \"\"\"#22030 - Adding a field with a default value should work.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=\"Ada Lovelace\")\n"], "sample_316": ["    def test_image_dimensions_after_close(self):\n        \"\"\"\n        get_image_dimensions() should return (None, None) after the file has been closed.\n        \"\"\"\n        img_path = os.path.join(os.path.dirname(__file__), \"test.png\")\n        with open(img_path, 'rb') as fh:\n            image = images.ImageFile(fh)\n            size = image._get_image_dimensions()\n            image.close()\n            self.assertEqual(size, (None, None))\n"], "sample_314": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = UNUSABLE_PASSWORD_PREFIX + '123456'\n        self.assertHTMLEqual(\n            widget.render('name', value, {'id': 'id_password'}),\n            \"\"\"\n            <div id=\"id_password\">\n                <strong>No password set.</strong>\n            </div>\n            \"\"\"\n        )\n"], "sample_591": ["    def test_merge_fill_value(self):\n        ds1 = xr.Dataset({\"a\": (\"x\", [1, 2]), \"x\": [0, 1]})\n        ds2 = xr.Dataset({\"b\": (\"x\", [3, 4]), \"x\": [1, 2]})\n        expected = xr.Dataset(\n            {\"a\": (\"x\", [1, 2, np.nan]), \"b\": (\"x\", [np.nan, 3, 4])}, {\"x\": [0, 1, 2]}\n        )\n        assert expected.identical(ds1.merge(ds2, fill_value=np.nan))\n        assert expected.identical(ds2.merge(ds1, fill_value=np.nan))\n        assert expected.identical(xr.merge([ds1, ds2], fill_value=np.nan))\n\n        ds1 = xr.Dataset({\"a\": (\"x\", [1, 2]), \"x\": [0, 1]})\n        ds2 = xr.Dataset({\"b\": (\"x\", [3, 4]), \"x\": [1, 2]})\n        expected = xr.Dataset(\n            {\"a\": (\"x\", [1, 2, 2.0]), \"b\": (\"x\", [2.0, 3, 4])}, {\"x\": [0, 1, 2]}\n        )\n        assert expected.identical(ds1.merge(ds2, fill_value=2.0))\n        assert expected.identical(ds2.merge(ds1, fill_value=2.0))\n        assert expected.identical(xr.merge([ds1, ds2], fill_value=2.0))\n\n        ds1 = xr.Dataset({\"a\": (\"x\", [1, 2]), \"x\": [0, 1]})\n        ds2 = xr.Dataset({\"b\": (\"x\", [3, 4]), \"x\": [1, 2]})\n        expected = xr.Dataset(\n            {\"a\": (\"x\", [1, 2, 2]), \"b\": (\"x\", [2, 3, 4])}, {\"x\": [0, 1, 2]}\n        )\n        assert expected.identical(ds1.merge(ds2, fill_value=2))\n        assert expected.identical(ds2.merge(ds1, fill_value=2))\n        assert expected.identical(xr.merge([ds1, ds2], fill_value=2))\n"], "sample_371": ["    def test_non_sensitive_request(self):\n        \"\"\"\n        Request info can bee seen in the default error reports for\n        non-sensitive requests.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n\n        with self.settings(DEBUG=False):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n"], "sample_654": ["    def test_getfixturedefs(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n                return 1\n            @pytest.fixture\n                return 2\n        \"\"\"\n        )\n        testdir.makepyfile(\n            \"\"\"\n                pass\n        \"\"\"\n        )\n        fm = testdir.getfixturemanager()\n        fixturedefs = fm.getfixturedefs(\"arg1\", testdir.getitem().nodeid)\n        assert len(fixturedefs) == 1\n        assert fixturedefs[0].argname == \"arg1\"\n        fixturedefs = fm.getfixturedefs(\"arg2\", testdir.getitem().nodeid)\n        assert len(fixturedefs) == 1\n        assert fixturedefs[0].argname == \"arg2\"\n        fixturedefs = fm.getfixturedefs(\"arg3\", testdir.getitem().nodeid)\n        assert fixturedefs is None\n"], "sample_1190": ["def test_get_dimension_system():\n    u = Quantity(\"u\")\n    u.set_global_relative_scale_factor(S(10), meter)\n    assert u.get_dimension_system() == SI.get_dimension_system()\n    assert u.get_dimension_system() is not None\n    assert isinstance(u.get_dimension_system(), UnitSystem)\n"], "sample_164": ["    def test_uses_server_time(self):\n        server_time = '2016-09-25 10:20:30'\n        logger = logging.getLogger('django.server')\n        formatter = ServerFormatter()\n        logger.handlers[0].stream = StringIO()\n        logger.info('log message', extra={'server_time': server_time})\n        self.assertEqual('[%s] log message\\n' % server_time, logger.handlers[0].stream.getvalue())\n"], "sample_237": ["    def test_builtin_permission_name_max_length(self):\n        class Checked(models.Model):\n            class Meta:\n                permissions = [\n                    ('my_builtin_permission', 'Some permission'),\n                ]\n        errors = checks.run_checks(self.apps.get_app_configs())\n        permission_name_max_length = apps.get_model('auth', 'Permission')._meta.get_field('name').max_length\n        max_builtin_permission_name_length = max(len(name) for name in _get_builtin_permissions(Checked._meta).values())\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most %d \"\n                \"characters for its builtin permission names to be at most %d characters.\" % (\n                    permission_name_max_length - (max_builtin_permission_name_length - len(Checked._meta.verbose_name_raw)),\n                    permission_name_max_length,\n                ),\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n"], "sample_938": ["def test_man_make_section_directory_with_custom_section(app, status, warning):\n    app.builder.build_all()\n    assert (app.outdir / 'custom' / 'python.1').exists()\n    content = (app.outdir / 'custom' / 'python.1').read_text()\n    assert r'\\fBprint \\fP\\fIi\\fP\\fB\\en\\fP' in content\n    assert r'\\fBmanpage\\en\\fP' in content\n\n    # term of definition list including nodes.strong\n    assert '\\n.B term1\\n' in content\n    assert '\\nterm2 (\\\\fBstronged partially\\\\fP)\\n' in content\n\n    assert 'Footnotes' not in content\n"], "sample_228": ["def test_formset_can_order_with_initial_data(self):\n    \"\"\"\n    Formsets with ordering + initial data.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_order=True)\n    initial = [{'choice': 'Calexico', 'votes': 100}, {'choice': 'Fergie', 'votes': 900}]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_304": ["    def test_base_validator_clean(self):\n        validator = BaseValidator(lambda: 10)\n        self.assertEqual(validator.clean(10), 10)\n        self.assertEqual(validator.clean('10'), 10)\n        self.assertEqual(validator.clean('10.5'), 10)\n        self.assertEqual(validator.clean('10.5.5'), 10)\n        self.assertEqual(validator.clean('10.5.5.5'), 10)\n        self.assertEqual(validator.clean('10.5.5.5.5'), 10)\n        self.assertEqual(validator.clean('10.5.5.5.5.5'), 10)\n        self.assertEqual(validator.clean('10.5.5.5.5.5.5'), 10)\n        self.assertEqual(validator.clean('10.5.5.5.5.5.5.5'), 10)\n        self.assertEqual(validator.clean('10.5.5.5.5.5.5.5.5'), 10)\n        self.assertEqual(validator.clean('10.5.5.5.5.5.5.5.5.5'), 10)\n        self.assertEqual(validator.clean('10.5.5.5.5.5.5.5.5.5.5'), 10)\n        self.assertEqual(validator.clean('10.5.5.5.5.5.5.5.5.5.5.5'), 10)\n        self.assertEqual(validator.clean('10.5.5.5.5.5.5.5.5.5.5.5.5'), 10)\n        self.assertEqual(validator.clean('10.5.5.5.5.5.5.5.5.5.5.5.5.5'), 10)\n        self.assertEqual(validator.clean('10.5.5.5.5.5.5.5.5.5.5.5.5.5.5'), 10)\n        self.assertEqual(validator.clean('10.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5'), 10)\n        self.assertEqual(validator.clean('10.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5"], "sample_627": ["def test_concat_fill_value_with_dict() -> None:\n    datasets = create_typed_datasets(2, seed=123)\n    expected1 = concat(datasets, dim=\"day\", fill_value={\"float\": 0, \"string\": \"a\"})\n    expected2 = concat(datasets[::-1], dim=\"day\", fill_value={\"float\": 0, \"string\": \"a\"})\n    vars = [\"float\", \"float2\", \"string\", \"int\", \"datetime64\", \"timedelta64\"]\n    expected = [expected2, expected1]\n    for i, exp in enumerate(expected):\n        sl = slice(i * 2, (i + 1) * 2)\n        exp[\"float2\"][..., sl] = np.nan\n        exp[\"datetime64\"][..., sl] = np.nan\n        exp[\"timedelta64\"][..., sl] = np.nan\n        var = exp[\"int\"] * 1.0\n        var[..., sl] = np.nan\n        exp[\"int\"] = var\n        var = exp[\"string\"].astype(object)\n        var[..., sl] = np.nan\n        exp[\"string\"] = var\n\n    # set up the test data\n    datasets[1] = datasets[1].drop_vars(vars[1:])\n\n    actual = concat(datasets, dim=\"day\", fill_value={\"float\": 0, \"string\": \"a\"})\n\n    assert_identical(actual, expected[1])\n\n    # reversed\n    actual = concat(datasets[::-1], dim=\"day\", fill_value={\"float\": 0, \"string\": \"a\"})\n\n    assert_identical(actual, expected[0])\n"], "sample_290": ["def test_alter_field_to_not_null_with_default(self):\n    \"\"\"\n    #23609 - Tests autodetection of nullable to non-nullable alterations.\n    \"\"\"\n    changes = self.get_changes([self.author_name_null], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\", preserve_default=True)\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default='Ada Lovelace')\n"], "sample_681": ["def test_log_cli_level_file(testdir):\n    # Default log file level\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_handler.level == logging.INFO\n            logging.getLogger('catchlog').debug(\"This log message won't be shown\")\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    result = testdir.runpytest(\n        \"-s\", \"--log-file={}\".format(log_file), \"--log-cli-level=INFO\", \"--log-file-level=DEBUG\"\n    )\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines([\"test_log_cli_level_file.py PASSED\"])\n\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert \"This log message will be shown\" in contents\n        assert \"This log message won't be shown\" not in contents\n        assert \"debug\" in contents\n"], "sample_463": ["def test_alter_field_with_default(self):\n    \"\"\"#23609 - Altering a field with a default should work.\"\"\"\n    changes = self.get_changes([self.author_name], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=\"Ada Lovelace\")\n"], "sample_348": ["    def test_invalid_type(self):\n        class TestModelAdmin(ModelAdmin):\n            list_select_related = 'hello'\n\n        self.assertIsInvalid(\n            TestModelAdmin, ValidationTestModel,\n            \"The value of 'list_select_related' must be a boolean, tuple or list.\",\n            'admin.E117'\n        )\n"], "sample_1066": ["def test_print_Cross():\n    ACS = CoordSys3D('A')\n    assert mathml(Cross(ACS.i, ACS.j), printer='presentation') == \\\n        '<mrow><msub><mover><mi mathvariant=\"bold\">i</mi><mo>^</mo></mover>'\\\n        '<mi mathvariant=\"bold\">A</mi></msub><mo>&#xD7;</mo><msub><mover>'\\\n        '<mi mathvariant=\"bold\">j</mi><mo>^</mo></mover><mi mathvariant=\"bold\">'\\\n        'A</mi></msub></mrow>'\n    assert mathml(Cross(ACS.i, ACS.j*ACS.x*3+ACS.k), printer='presentation') == \\\n        '<mrow><msub><mover><mi mathvariant=\"bold\">i</mi><mo>^</mo></mover>'\\\n        '<mi mathvariant=\"bold\">A</mi></msub><mo>&#xD7;</mo><mfenced><mrow>'\\\n        '<mfenced><mrow><mn>3</mn><mo>&InvisibleTimes;</mo><msub>'\\\n        '<mi mathvariant=\"bold\">x</mi><mi mathvariant=\"bold\">A</mi></msub>'\\\n        '</mrow></mfenced><mo>&InvisibleTimes;</mo><msub><mover>'\\\n        '<mi mathvariant=\"bold\">j</mi><mo>^</mo></mover><mi mathvariant=\"bold\">'\\\n        'A</mi></msub><mo>+</mo><msub><mover><mi mathvariant=\"bold\">k</mi>'\\\n        '<mo>^</mo></mover><mi mathvariant=\"bold\">A</mi></msub></mrow></mfenced></mrow>'\n    assert mathml(x*Cross(ACS.i, ACS.j), printer='presentation') == \\\n        '<mrow><mi>x</mi><mo>&InvisibleTimes;</mo><mfenced><mrow><msub><mover>'\\\n        '<mi mathvariant=\"bold\">i</mi><mo>^</mo></mover>'\\\n        '<mi mathvariant=\"bold\">A</mi></msub><mo>&#xD7;</mo><msub><mover>'\\\n        '<mi mathvariant=\"bold\">j</mi><mo>^"], "sample_285": ["def test_dirs_not_directory(self):\n    \"\"\"Test that check_finders() raises a warning if a directory in STATICFILES_DIRS does not exist.\"\"\"\n    static_dir = Path(TEST_ROOT) / 'project' / 'non_existent_dir'\n    with self.settings(STATICFILES_DIRS=[static_dir]):\n        errors = check_finders(None)\n        self.assertEqual(len(errors), 1)\n        self.assertIsInstance(errors[0], Warning)\n        self.assertEqual(errors[0].id, 'staticfiles.W004')\n        self.assertEqual(errors[0].msg, f\"The directory '{static_dir}' in the STATICFILES_DIRS setting does not exist.\")\n"], "sample_456": ["    def test_custom_renderer(self):\n        \"\"\"\n        A custom renderer passed to a formset_factory() is passed to all forms\n        and ErrorList.\n        \"\"\"\n        from django.forms.renderers import Jinja2\n\n        renderer = Jinja2()\n        data = {\n            \"choices-TOTAL_FORMS\": \"2\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Zero\",\n            \"choices-0-votes\": \"\",\n            \"choices-1-choice\": \"One\",\n            \"choices-1-votes\": \"\",\n        }\n        ChoiceFormSet = formset_factory(Choice, renderer=renderer)\n        formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertEqual(formset.renderer, renderer)\n        self.assertEqual(formset.forms[0].renderer, renderer)\n        self.assertEqual(formset.management_form.renderer, renderer)\n        self.assertEqual(formset.non_form_errors().renderer, renderer)\n        self.assertEqual(formset.empty_form.renderer, renderer)\n"], "sample_940": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n        pass\n\n    @singledispatch\n        pass\n\n    assert inspect.is_singledispatch_function(func) is False\n    assert inspect.is_singledispatch_function(singledispatch_func) is True\n\n        pass\n\n    class Foo:\n        @singledispatch\n            pass\n\n    assert inspect.is_singledispatch_method(singledispatch_method) is False\n    assert inspect.is_singledispatch_method(singledispatch_method.__func__) is False\n    assert inspect.is_singledispatch_method(Foo().singledispatch_method) is True\n"], "sample_1048": ["def test_parabola_intersection():\n    a, b = symbols('a b')\n    p1 = Point(0, 0)\n    p2 = Point(3, 7)\n    p3 = Point(0, 4)\n    p4 = Point(6, 0)\n    p5 = Point(a, a)\n    d1 = Line(Point(4, 0), Point(4, 9))\n    d2 = Line(Point(7, 6), Point(3, 6))\n    d3 = Line(Point(4, 0), slope=oo)\n    d4 = Line(Point(7, 6), slope=0)\n    d5 = Line(Point(b, a), slope=oo)\n    d6 = Line(Point(a, b), slope=0)\n\n    pa1 = Parabola(p1, d1)\n    pa2 = Parabola(p2, d2)\n    pa3 = Parabola(p3, d2)\n    pa4 = Parabola(p4, d1)\n    pa5 = Parabola(p5, d5)\n    pa6 = Parabola(p5, d6)\n\n    # Test intersection with a point\n    assert pa1.intersection(p1) == []\n    assert pa2.intersection(p2) == []\n    assert pa3.intersection(p3) == []\n    assert pa4.intersection(p4) == []\n    assert pa5.intersection(p5) == []\n    assert pa6.intersection(p5) == []\n\n    # Test intersection with a line\n    assert pa1.intersection(d1) == []\n    assert pa2.intersection(d2) == [Point2D(3, 7)]\n    assert pa3.intersection(d2) == [Point2D(0, 4)]\n    assert pa4.intersection(d1) == [Point2D(6, 0)]\n    assert pa5.intersection(d5) == [Point2D(a, a)]\n    assert pa6.intersection(d6) == [Point2D(a, a)]\n\n    # Test intersection with a segment\n    s1 = Segment2D(p1, p2)\n    s2 = Segment2D(p3, p4)\n    s3 = Segment2D(p5, p5)\n    assert pa1.intersection(s1) == []\n    assert pa2.intersection(s2) == [Point2D(3, 7)]\n    assert pa3"], "sample_548": ["def test_colorbar_no_norm():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]])\n    fig.colorbar(im, norm=None)\n"], "sample_714": ["def test_brier_score_loss():\n    # Test Brier score loss\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    assert_almost_equal(brier_score_loss(y_true, y_prob), 0.037)\n\n    # Test Brier score loss with sample weights\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    sample_weight = np.array([1, 2, 3, 4])\n    assert_almost_equal(brier_score_loss(y_true, y_prob, sample_weight=sample_weight),\n                        (0.037 * 1 + 0.037 * 2 + 0.037 * 3 + 0.037 * 4) / 10)\n\n    # Test Brier score loss with pos_label\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    assert_almost_equal(brier_score_loss(y_true, y_prob, pos_label=1), 0.037)\n\n    # Test Brier score loss with pos_label and sample weights\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    sample_weight = np.array([1, 2, 3, 4])\n    assert_almost_equal(brier_score_loss(y_true, y_prob, pos_label=1,\n                                        sample_weight=sample_weight),\n                        (0.037 * 1 + 0.037 * 2 + 0.037 * 3 + 0.037 * 4) / 10)\n\n    # Test Brier score loss with categorical y_true\n    y_true = np.array([\"ham\", \"spam\", \"spam\", \"ham\"])\n    y_prob = np.array([[0.2, 0.7], [0.6, 0.5], [0.4, 0.1], [0.7, 0.2]])\n    assert_almost_equal(brier_score"], "sample_775": ["def test_n_max_elements_to_show_with_dicts():\n    # Test that n_max_elements_to_show works with dictionaries\n    n_max_elements_to_show = 30\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=n_max_elements_to_show\n    )\n\n    # No ellipsis\n    param_grid = {'C': {i: i for i in range(n_max_elements_to_show)}}\n    gs = GridSearchCV(SVC(), param_grid)\n    expected = \"\"\""], "sample_301": ["    def test_iter_modules_and_files_with_empty_modules(self):\n        self.assertEqual(autoreload.iter_modules_and_files((), frozenset()), frozenset())\n"], "sample_539": ["def test_cursor(ax):\n    cursor = widgets.Cursor(ax, horizOn=True, vertOn=True)\n    ax.set_xlim(0, 10)\n    ax.set_ylim(0, 10)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n    # Test that the cursor is drawn when the mouse is over the axes\n    do_event(cursor, 'motion_notify_event', xdata=5, ydata=5)\n    assert cursor.lineh.get_visible()\n    assert cursor.linev.get_visible()\n\n    # Test that the cursor is not drawn when the mouse is not over the axes\n    do_event(cursor, 'motion_notify_event', xdata=15, ydata=15)\n    assert not cursor.lineh.get_visible()\n    assert not cursor.linev.get_visible()\n\n    # Test that the cursor is not drawn when the canvas is locked\n    cursor.canvas.widgetlock.acquire()\n    do_event(cursor, 'motion_notify_event', xdata=5, ydata=5)\n    assert not cursor.lineh.get_visible()\n    assert not cursor.linev.get_visible()\n    cursor.canvas.widgetlock.release()\n\n    # Test that the cursor is drawn when the mouse is over the axes and the\n    # canvas is locked\n    cursor.canvas.widgetlock.acquire()\n    do_event(cursor, 'motion_notify_event', xdata=5, ydata=5)\n    assert cursor.lineh.get_visible()\n    assert cursor.linev.get_visible()\n    cursor.canvas.widgetlock.release()\n\n    # Test that the cursor is drawn when the mouse is over the axes and the\n    # canvas is locked and the cursor is visible\n    cursor.canvas.widgetlock.acquire()\n    cursor.visible = True\n    do_event(cursor, 'motion_notify_event', xdata=5, ydata=5)\n    assert cursor.lineh.get_visible()\n    assert cursor.linev.get_visible()\n    cursor.canvas.widgetlock.release()\n\n    # Test that the cursor is not drawn when the mouse is over the axes and the\n    # canvas is locked and the cursor is not visible\n    cursor.canvas.widgetlock.acquire()\n    cursor.visible = False\n    do_event(cursor, 'motion_notify_event', xdata=5, ydata=5)\n    assert not cursor.lineh.get_visible()\n    assert not cursor.linev.get_visible()\n    cursor.canvas.widgetlock.release()\n\n    # Test that the cursor is drawn when the mouse is over the axes and the\n    # canvas is locked and the cursor is visible and the cursor is"], "sample_1044": ["def test_Pow_is_finite():\n    x = Symbol('x')\n    y = Symbol('y')\n    assert (x**y).is_finite is None\n    assert (x**y).is_infinite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y).is_finite is None\n    assert (x**y"], "sample_1092": ["def test_issue_15082():\n    # Test that cse handles non-integer and non-rational numbers\n    assert cse(42) == ([], [42])\n    assert cse(0.5) == ([], [0.5])\n    assert cse(1/2) == ([], [1/2])\n    assert cse(1/3) == ([], [1/3])\n    assert cse(1/4) == ([], [1/4])\n    assert cse(1/5) == ([], [1/5])\n    assert cse(1/6) == ([], [1/6])\n    assert cse(1/7) == ([], [1/7])\n    assert cse(1/8) == ([], [1/8])\n    assert cse(1/9) == ([], [1/9])\n    assert cse(1/10) == ([], [1/10])\n"], "sample_951": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n        pass\n\n    func.register(int, lambda x: x)\n\n    assert inspect.is_singledispatch_function(func) is True\n\n        pass\n\n    assert inspect.is_singledispatch_function(func2) is False\n\n        pass\n\n    func3.register(int, lambda x: x)\n\n    assert inspect.is_singledispatch_function(func3) is False\n\n    class Foo:\n        @singledispatch\n            pass\n\n        @func.register\n            pass\n\n    assert inspect.is_singledispatch_function(Foo().func) is True\n\n    class Foo2:\n            pass\n\n    assert inspect.is_singledispatch_function(Foo2().func) is False\n"], "sample_822": ["def test_pairwise_distances_chunked_sparse():\n    # Test the pairwise_distance helper function.\n    rng = np.random.RandomState(0)\n    # Euclidean distance should be equivalent to calling the function.\n    X = csr_matrix(rng.random_sample((400, 4)))\n    check_pairwise_distances_chunked(X, None, working_memory=1,\n                                     metric='euclidean')\n    # Test small amounts of memory\n    for power in range(-16, 0):\n        check_pairwise_distances_chunked(X, None, working_memory=2 ** power,\n                                         metric='euclidean')\n    # X as list\n    check_pairwise_distances_chunked(X.todense().tolist(), None, working_memory=1,\n                                     metric='euclidean')\n    # Euclidean distance, with Y != X.\n    Y = csr_matrix(rng.random_sample((200, 4)))\n    check_pairwise_distances_chunked(X, Y, working_memory=1,\n                                     metric='euclidean')\n    check_pairwise_distances_chunked(X.todense().tolist(), Y.todense().tolist(),\n                                     working_memory=1, metric='euclidean')\n    # absurdly large working_memory\n    check_pairwise_distances_chunked(X, Y, working_memory=10000,\n                                     metric='euclidean')\n    # \"cityblock\" uses scikit-learn metric, cityblock (function) is\n    # scipy.spatial.\n    check_pairwise_distances_chunked(X, Y, working_memory=1,\n                                     metric='cityblock')\n    # Test that a value error is raised if the metric is unknown\n    assert_raises(ValueError, next,\n                  pairwise_distances_chunked(X, Y, metric=\"blah\"))\n\n    # Test precomputed returns all at once\n    D = pairwise_distances(X.todense())\n    gen = pairwise_distances_chunked(D,\n                                     working_memory=2 ** -16,\n                                     metric='precomputed')\n    assert isinstance(gen, GeneratorType)\n    assert next(gen) is D\n    assert_raises(StopIteration, next, gen)\n"], "sample_275": ["    def test_meta_ordered_delete_with_distinct(self):\n        # When a subquery is performed by deletion code, the subquery must be\n        # cleared of all ordering. There was a bug that caused _meta ordering\n        # to be used. Refs #19720.\n        h = House.objects.create(address='Foo')\n        OrderedPerson.objects.create(name='Jack', lives_in=h)\n        OrderedPerson.objects.create(name='Bob', lives_in=h)\n        OrderedPerson.objects.filter(lives_in__address='Foo').distinct().delete()\n        self.assertEqual(OrderedPerson.objects.count(), 0)\n"], "sample_715": ["def test_cross_validate_return_train_score_warn():\n    # Test that warnings are raised. Will be removed in 0.21\n\n    X, y = make_classification(random_state=0)\n    estimator = MockClassifier()\n\n    result = {}\n    for val in [False, True, 'warn']:\n        result[val] = assert_no_warnings(cross_validate, estimator, X, y,\n                                         return_train_score=val)\n\n    msg = (\n        'You are accessing a training score ({!r}), '\n        'which will not be available by default '\n        'any more in 0.21. If you need training scores, '\n        'please set return_train_score=True').format('train_score')\n    train_score = assert_warns_message(FutureWarning, msg,\n                                       result['warn'].get, 'train_score')\n    assert np.allclose(train_score, result[True]['train_score'])\n    assert 'train_score' not in result[False]\n"], "sample_420": ["    def test_save_m2m(self):\n        class BookForm(forms.ModelForm):\n            class Meta:\n                model = Book\n                fields = \"__all__\"\n\n        book = Book.objects.create(title=\"Test book\", author=Writer.objects.create(name=\"Test author\"))\n        form = BookForm({\"title\": \"New title\", \"author\": book.author.pk}, instance=book)\n        self.assertTrue(form.is_valid())\n        self.assertEqual(form.save().title, \"New title\")\n        self.assertEqual(Book.objects.get(id=book.id).title, \"New title\")\n"], "sample_1111": ["def test_zero_function():\n    x = Symbol('x')\n    lines = [\n        '      0 |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                     ',\n        '        |                                                    "], "sample_607": ["def test_guess_engine_installed_engines():\n    with pytest.raises(ValueError, match=r\"xarray is unable to open this file\"):\n        plugins.guess_engine(\"not-valid\")\n\n    with pytest.raises(ValueError, match=r\"xarray is unable to open this file\"):\n        plugins.guess_engine(\"foo.nc\")\n"], "sample_582": ["def test_flaskgroup_params(test_apps, runner):\n        return Flask(\"flaskgroup\")\n\n    cli = FlaskGroup(create_app=create_app, params=[\"--foo\", \"--bar\"])\n    result = runner.invoke(cli, [\"--foo\", \"--bar\"])\n    assert result.exit_code == 0\n    assert result.output == \"\"\n\n    result = runner.invoke(cli, [\"--help\"])\n    assert result.exit_code == 0\n    assert \"--foo\" in result.stdout\n    assert \"--bar\" in result.stdout\n"], "sample_324": ["    def _get_POST_request_with_token(self):\n        req = self._get_POST_csrf_cookie_request()\n        req.META['HTTP_HOST'] = 'www.example.com'\n        req.META['HTTP_REFERER'] = 'https://foo.example.com'\n        return req\n"], "sample_758": ["def test_check_X_y_dtype_stability():\n    # test that lists with ints don't get converted to floats\n    X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n    y = [1, 2, 3]\n    X_checked, y_checked = check_X_y(X, y)\n    assert_equal(X_checked.dtype.kind, \"i\")\n    assert_equal(y_checked.dtype.kind, \"i\")\n\n    X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n    y = [1.0, 2.0, 3.0]\n    X_checked, y_checked = check_X_y(X, y)\n    assert_equal(X_checked.dtype.kind, \"i\")\n    assert_equal(y_checked.dtype.kind, \"f\")\n\n    X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n    y = [1, 2, 3]\n    X_checked, y_checked = check_X_y(X, y, dtype=np.float64)\n    assert_equal(X_checked.dtype.kind, \"i\")\n    assert_equal(y_checked.dtype.kind, \"f\")\n\n    X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n    y = [1.0, 2.0, 3.0]\n    X_checked, y_checked = check_X_y(X, y, dtype=np.float64)\n    assert_equal(X_checked.dtype.kind, \"i\")\n    assert_equal(y_checked.dtype.kind, \"f\")\n\n    X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n    y = [1, 2, 3]\n    X_checked, y_checked = check_X_y(X, y, dtype=[np.float64, np.float32])\n    assert_equal(X_checked.dtype.kind, \"i\")\n    assert_equal(y_checked.dtype.kind, \"f\")\n\n    X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n    y = [1.0, 2.0, 3.0]\n    X_checked, y_checked = check_X_y(X, y, dtype=["], "sample_573": ["def test_order(self, df):\n\n    groupby = GroupBy([\"group\"])\n    res = PolyFit(order=3, gridsize=100)(df[[\"x\", \"y\"]], groupby, \"x\", {})\n\n    assert_array_equal(res.columns, [\"x\", \"y\"])\n\n    grid = np.linspace(df[\"x\"].min(), df[\"x\"].max(), 100)\n    assert_array_equal(res[\"x\"], grid)\n    assert_array_almost_equal(\n        res[\"y\"].diff().diff().dropna(), np.zeros(grid.size - 2)\n    )\n\n    # Test that the order of the polynomial is correct\n    p = np.polyfit(df[\"x\"], df[\"y\"], 3)\n    yy = np.polyval(p, grid)\n    assert_array_almost_equal(res[\"y\"], yy)\n"], "sample_1091": ["def test_issue_17567():\n    from sympy import symbols, sin, cos, Eq, simplify, trigsimp\n    x = symbols('x')\n    eq = Eq(sin(x), cos(x))\n    assert simplify(eq) == Eq(sin(x), cos(x))\n    assert trigsimp(eq) == Eq(sin(x), cos(x))\n    assert simplify(eq, ratio=0) != Eq(sin(x), cos(x))\n    assert trigsimp(eq, ratio=0) != Eq(sin(x), cos(x))\n"], "sample_122": ["    def test_cache_versioning_incr_decr_with_version(self):\n        cache.set('answer', 42, version=2)\n        self.assertEqual(cache.get('answer'), None)\n        self.assertEqual(cache.get('answer', version=2), 42)\n        self.assertEqual(cache.get('answer', version=3), None)\n        cache.incr('answer', version=2)\n        self.assertEqual(cache.get('answer', version=2), 43)\n        self.assertEqual(cache.get('answer', version=3), None)\n        cache.decr('answer', version=2)\n        self.assertEqual(cache.get('answer', version=2), 42)\n        self.assertEqual(cache.get('answer', version=3), None)\n"], "sample_580": ["def test_variable_type_datetime_object():\n    # Test datetime objects with different types\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2)])\n    assert variable_type(s) == \"datetime\"\n    assert variable_type(s.astype(object)) == \"datetime\"\n\n    # Test datetime objects with mixed types\n    s = pd.Series([pd.Timestamp(1), \"2022-01-01\", pd.Timestamp(3)])\n    assert variable_type(s) == \"datetime\"\n\n    # Test datetime objects with non-datetime values\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2), \"2022-01-01\"])\n    assert variable_type(s) == \"datetime\"\n\n    # Test datetime objects with non-datetime values and boolean\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2), True])\n    assert variable_type(s) == \"datetime\"\n\n    # Test datetime objects with non-datetime values and categorical\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2), \"category\"])\n    assert variable_type(s) == \"datetime\"\n\n    # Test datetime objects with non-datetime values and numeric\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2), 3])\n    assert variable_type(s) == \"datetime\"\n\n    # Test datetime objects with non-datetime values and unknown\n    s = pd.Series([pd.Timestamp(1), pd.Timestamp(2), \"unknown\"])\n    assert variable_type(s) == \"datetime\"\n"], "sample_978": ["def test_repeated_degree_2():\n    d = 2\n    knots = [0, 0, 1, 2, 2, 3, 4, 4]\n    splines = bspline_basis_set(d, knots, x)\n    b0 = Piecewise((x**2/2, Interval(0, 1).contains(x)),\n                   (Rational(3, 2) - 3*x + x**2, Interval(1, 2).contains(x)),\n                   (Rational(9, 2) - 3*x + x**2/2, Interval(1, 2).contains(x)),\n                   (Rational(-11, 2) + 5*x - x**2, Interval(2, 3).contains(x)),\n                   (8 - 4*x + x**2/2, Interval(3, 4).contains(x)),\n                   (0, True))\n    b1 = Piecewise((Rational(1, 2) - x + x**2/2, Interval(1, 2).contains(x)),\n                   (Rational(-11, 2) + 5*x - x**2, Interval(2, 3).contains(x)),\n                   (Rational(22, 2) - 10*x + 5*x**2/2, Interval(2, 3).contains(x)),\n                   (Rational(-32, 2) + 8*x - 2*x**2/2, Interval(3, 4).contains(x)),\n                   (0, True))\n    assert splines[0] == b0\n    assert splines[1] == b1\n"], "sample_929": ["def test_pyattribute_signature(app):\n    text = (\".. py:class:: Class\\n\"\n            \"\\n\"\n            \"   .. py:attribute:: attr\\n\"\n            \"      :type: int\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_annotation, \"class \"],\n                                                    [desc_name, \"Class\"])],\n                                  [desc_content, (addnodes.index,\n                                                  desc)])]))\n    assert_node(doctree[1][1][0], addnodes.index,\n                entries=[('single', 'attr (Class attribute)', 'Class.attr', '', None)])\n    assert_node(doctree[1][1][1], ([desc_signature, ([desc_name, \"attr\"],\n                                                     [desc_annotation, (\": \",\n                                                                        [pending_xref, \"int\"])],\n                                                     [desc_annotation, \" = 'None'\"])],\n                                   [desc_content, ()]))\n    assert_node(doctree[1][1][1][0][1], pending_xref, **{\"py:class\": \"Class\"})\n    assert 'Class.attr' in domain.objects\n    assert domain.objects['Class.attr'] == ('index', 'Class.attr', 'attribute')\n"], "sample_78": ["    def test_command_error_message(self):\n        \"\"\"CommandError should have a sensible error message.\"\"\"\n        e = CommandError(\"Something went wrong\")\n        self.assertIn(\"Error: Something went wrong\", str(e))\n"], "sample_369": ["def test_alter_field_to_fk_dependency_other_app_with_unique_together(self):\n    \"\"\"\n    #23100 - ForeignKeys correctly depend on other apps' models.\n    \"\"\"\n    changes = self.get_changes([self.author_empty, self.book], [self.author_empty, self.book_with_no_author_fk])\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, ['AlterField'])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"author\")\n    self.assertMigrationDependencies(changes, 'otherapp', 0, [('testapp', '__first__')])\n    self.assertOperationFieldAttributes(changes, 'otherapp', 0, 0, unique=True)\n"], "sample_792": ["def test_cnb_alpha():\n    # Test whether ComplementNB raises an error when alpha is negative\n    clf = ComplementNB(alpha=-0.1)\n    assert_raises(ValueError, clf.fit, [[0, 1], [1, 0]], [0, 1])\n    assert_raises(ValueError, clf.partial_fit, [[0, 1], [1, 0]], [0, 1],\n                  classes=[0, 1])\n"], "sample_889": ["def test_calibration_with_non_fitted_base_estimator():\n    \"\"\"Check that we raise an error if the base estimator is not fitted.\"\"\"\n    X, y = make_classification(n_samples=10, n_features=5, n_classes=2, random_state=7)\n    clf = LogisticRegression()\n    calib_clf = CalibratedClassifierCV(clf, cv=\"prefit\")\n    with pytest.raises(NotFittedError):\n        calib_clf.fit(X, y)\n"], "sample_864": ["def test_mean_shift_max_iter():\n    # Test MeanShift algorithm with max_iter\n    ms = MeanShift(bandwidth=1.2, max_iter=10)\n    labels = ms.fit(X).labels_\n    labels_unique = np.unique(labels)\n    n_clusters_ = len(labels_unique)\n    assert n_clusters_ == 3\n    assert labels_unique[0] == 0\n\n    cluster_centers, labels_mean_shift = mean_shift(X, max_iter=10)\n    labels_mean_shift_unique = np.unique(labels_mean_shift)\n    n_clusters_mean_shift = len(labels_mean_shift_unique)\n    assert n_clusters_mean_shift == 3\n    assert labels_mean_shift_unique[0] == 0\n"], "sample_894": ["def check_max_depth(name):\n    # Test that max_depth is respected.\n    X, y = hastie_X, hastie_y\n    ForestEstimator = FOREST_ESTIMATORS[name]\n    est = ForestEstimator(max_depth=1, n_estimators=1, random_state=0)\n    est.fit(X, y)\n    assert est.estimators_[0].get_depth() == 1\n\n"], "sample_251": ["    def setUpTestData(cls):\n        cls.a1 = Author.objects.create(name='Adrian Holovaty', age=34)\n        cls.a2 = Author.objects.create(name='Jacob Kaplan-Moss', age=35)\n        cls.a3 = Author.objects.create(name='James Bennett', age=34)\n        cls.a4 = Author.objects.create(name='Peter Norvig', age=57)\n        cls.a5 = Author.objects.create(name='Stuart Russell', age=46)\n        p1 = Publisher.objects.create(name='Apress', num_awards=3)\n\n        cls.b1 = Book.objects.create(\n            isbn='159059725', pages=447, rating=4.5, price=Decimal('30.00'),\n            contact=cls.a1, publisher=p1, pubdate=datetime.date(2007, 12, 6),\n            name='The Definitive Guide to Django: Web Development Done Right',\n        )\n        cls.b2 = Book.objects.create(\n            isbn='159059996', pages=300, rating=4.0, price=Decimal('29.69'),\n            contact=cls.a3, publisher=p1, pubdate=datetime.date(2008, 6, 23),\n            name='Practical Django Projects',\n        )\n        cls.b3 = Book.objects.create(\n            isbn='013790395', pages=1132, rating=4.0, price=Decimal('82.80'),\n            contact=cls.a4, publisher=p1, pubdate=datetime.date(1995, 1, 15),\n            name='Artificial Intelligence: A Modern Approach',\n        )\n        cls.b4 = Book.objects.create(\n            isbn='155860191', pages=946, rating=5.0, price=Decimal('75.00'),\n            contact=cls.a4, publisher=p1, pubdate=datetime.date(1991, 10, 15),\n            name='Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp',\n        )\n        cls.b1.authors.add(cls.a1, cls.a2)\n        cls.b2.authors.add(cls.a3)\n        cls.b3.authors.add(cls.a4, cls.a5)\n        cls.b4.authors.add(cls.a4)\n\n        Store.objects.create(\n            name='Amazon.com',\n            original_opening=datetime.datetime(1994, 4, 23, 9, 17, "], "sample_110": ["    def setUpTestData(cls):\n        cls.h1 = Happening.objects.create(when=datetime.datetime(2022, 1, 1))\n        cls.h2 = Happening.objects.create(when=datetime.datetime(2022, 1, 2))\n        cls.h3 = Happening.objects.create(when=datetime.datetime(2022, 1, 3))\n"], "sample_691": ["def test_timeout_config_value_invalid_input(pytester: Pytester) -> None:\n    \"\"\"Test that get_timeout_config_value returns 0.0 when invalid input is provided.\"\"\"\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        faulthandler_timeout = abc\n        \"\"\"\n    )\n    assert FaultHandlerHooks.get_timeout_config_value(pytester.config) == 0.0\n"], "sample_711": ["def test_get_fslocation_from_item() -> None:\n    \"\"\"Ensure that get_fslocation_from_item() returns the correct location for different node types.\"\"\"\n    # Test with location attribute\n    node = nodes.Item(name=\"test\", location=(\"path/to/file.py\", 10, \"test\"))\n    assert get_fslocation_from_item(node) == (\"path/to/file.py\", 10)\n\n    # Test with obj attribute\n    class Obj:\n        pass\n\n    node = nodes.Item(name=\"test\", obj=Obj())\n    assert get_fslocation_from_item(node) == (\"unknown location\", -1)\n\n    # Test with fspath attribute\n    node = nodes.Item(name=\"test\", fspath=\"path/to/file.py\")\n    assert get_fslocation_from_item(node) == (\"path/to/file.py\", -1)\n\n    # Test with no location attributes\n    node = nodes.Item(name=\"test\")\n    assert get_fslocation_from_item(node) == (\"unknown location\", -1)\n"], "sample_293": ["    def test_include_namespace_with_variable_prefix(self):\n        \"\"\"\n        Using include() with namespaces when there is a regex variable in front of it.\n        \"\"\"\n        test_urls = [\n            ('inc-outer:inc-normal-view', [], {'outer': 42}, '/ns-outer/42/normal/'),\n            ('inc-outer:inc-normal-view', [42], {}, '/ns-outer/42/normal/'),\n            ('inc-outer:inc-normal-view', [], {'arg1': 37, 'arg2': 4, 'outer': 42}, '/ns-outer/42/normal/37/4/'),\n            ('inc-outer:inc-normal-view', [42, 37, 4], {}, '/ns-outer/42/normal/37/4/'),\n            ('inc-outer:inc-special-view', [], {'outer': 42}, '/ns-outer/42/+%5C$*/'),\n            ('inc-outer:inc-special-view', [42], {}, '/ns-outer/42/+%5C$*/'),\n        ]\n        for name, args, kwargs, expected in test_urls:\n            with self.subTest(name=name, args=args, kwargs=kwargs):\n                self.assertEqual(reverse(name, args=args, kwargs=kwargs), expected)\n"], "sample_453": ["    def test_prepopulated_fields_js(self):\n        \"\"\"\n        prepopulated_fields_js template tag should pass whole context.\n        \"\"\"\n        article = Article.objects.all()[0]\n        request = self.request_factory.get(\n            reverse(\"admin:admin_views_article_change\", args=[article.pk])\n        )\n        request.user = self.superuser\n        admin = ArticleAdmin(Article, site)\n        extra_context = {\"extra\": True}\n        response = admin.change_view(\n            request, str(article.pk), extra_context=extra_context\n        )\n        template_context = prepopulated_fields_js(response.context_data)\n        self.assertIs(template_context[\"extra\"], True)\n        self.assertIn(\"prepopulated_fields\", template_context)\n        self.assertIn(\"prepopulated_fields_json\", template_context)\n"], "sample_877": ["def test_isotonic_regression_out_of_bounds_clip_with_ties():\n    # Setup examples with ties on minimum\n    x = [1, 1, 2, 3, 4, 5]\n    y = [1, 2, 3, 4, 5, 6]\n    y_true = [1.5, 1.5, 3, 4, 5, 6]\n\n    # Check that we get identical results for fit/transform and fit_transform\n    ir = IsotonicRegression(y_min=0, y_max=10, out_of_bounds=\"clip\")\n    ir.fit(x, y)\n    assert_array_almost_equal(ir.transform(x), y_true, 4)\n    assert_array_almost_equal(ir.fit_transform(x, y), y_true, 4)\n"], "sample_450": ["def test_get_admin_log(self):\n    \"\"\"\n    Test the get_admin_log template tag.\n    \"\"\"\n    log_entries = [\n        LogEntry.objects.create(\n            user=self.user,\n            content_type=ContentType.objects.get_for_model(Article),\n            object_id=self.a1.pk,\n            action_time=datetime(2022, 1, 1),\n            action_flag=CHANGE,\n            change_message=\"Changed something\",\n        ),\n        LogEntry.objects.create(\n            user=self.user,\n            content_type=ContentType.objects.get_for_model(Article),\n            object_id=self.a1.pk,\n            action_time=datetime(2022, 1, 2),\n            action_flag=CHANGE,\n            change_message=\"Changed something else\",\n        ),\n        LogEntry.objects.create(\n            user=self.user,\n            content_type=ContentType.objects.get_for_model(Article),\n            object_id=self.a1.pk,\n            action_time=datetime(2022, 1, 3),\n            action_flag=CHANGE,\n            change_message=\"Changed something again\",\n        ),\n    ]\n    response = self.client.get(reverse(\"admin:index\"))\n    self.assertContains(response, \"Changed something\")\n    self.assertContains(response, \"Changed something else\")\n    self.assertContains(response, \"Changed something again\")\n\n    # Test with limit\n    response = self.client.get(reverse(\"admin:index\") + \"?get_admin_log=2\")\n    self.assertContains(response, \"Changed something\")\n    self.assertNotContains(response, \"Changed something else\")\n    self.assertNotContains(response, \"Changed something again\")\n\n    # Test with user\n    response = self.client.get(reverse(\"admin:index\") + \"?get_admin_log=2 for_user 1\")\n    self.assertContains(response, \"Changed something\")\n    self.assertNotContains(response, \"Changed something else\")\n    self.assertNotContains(response, \"Changed something again\")\n\n    # Test with user object\n    response = self.client.get(reverse(\"admin:index\") + \"?get_admin_log=2 for_user user\")\n    self.assertContains(response, \"Changed something\")\n    self.assertNotContains(response, \"Changed something else\")\n    self.assertNotContains(response, \"Changed something again\")\n"], "sample_1198": ["def test_parser_mathematica_tokenizer_invalid_input():\n    parser = MathematicaParser()\n\n    chain = lambda expr: parser._from_tokens_to_fullformlist(parser._from_mathematica_to_tokens(expr))\n\n    # Invalid input\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n    assert chain(\"(*\") == [\"CompoundExpression\"]\n    assert chain(\"*)\") == [\"CompoundExpression\"]\n"], "sample_1096": ["def test_IndexedBase_offset():\n    i, j = symbols('i j', integer=True)\n    o, p = symbols('o p', integer=True)\n    n, m = symbols('n m', integer=True)\n    a = IndexedBase('a', shape=(o, p), offset=1)\n    assert a.shape == Tuple(o, p)\n    assert a.offset == 1\n    assert Indexed(a, Idx(i, m), Idx(j, n)).ranges == [Tuple(1, m), Tuple(1, n)]\n    assert Indexed(a, Idx(i, m), Idx(j, n)).shape == Tuple(o, p)\n    assert Indexed(a, Idx(i, m), Idx(j)).ranges == [Tuple(1, m), Tuple(None, None)]\n    assert Indexed(a, Idx(i, m), Idx(j)).shape == Tuple(o, p)\n"], "sample_956": ["def test_load_mappings_cache(tempdir, app, status, warning):\n    \"\"\"\n    load_mappings issues a warning if the cache is not cleared\n    \"\"\"\n    inv_file = tempdir / 'inventory'\n    inv_file.write_bytes(inventory_v2)\n    set_config(app, {\n        'https://docs.python.org/': inv_file,\n    })\n\n    # load the inventory and check if it's done correctly\n    normalize_intersphinx_mapping(app, app.config)\n    load_mappings(app)\n\n    # cache is not cleared, should raise an error\n    with pytest.raises(ValueError):\n        load_mappings(app)\n\n    # clear cache and try again\n    app.env.intersphinx_cache.clear()\n    load_mappings(app)\n\n    # cache is cleared, should not raise an error\n    load_mappings(app)\n"], "sample_1085": ["def test_Float_as_coeff_Mul():\n    a = Float(3.2)\n    assert a.as_coeff_Mul() == (Float(3.2), S.One)\n    a = Float(3.2, 10)\n    assert a.as_coeff_Mul() == (Float(3.2, 10), S.One)\n    a = Float(3.2, 10)\n    assert a.as_coeff_Mul(rational=True) == (S.Three, Float(1.2, 10))\n    a = Float(3.2, 10)\n    assert a.as_coeff_Mul(rational=False) == (Float(3.2, 10), S.One)\n"], "sample_139": ["def test_dynamic_list_filter_with_custom_lookup(self):\n    \"\"\"\n    Regression tests for ticket #17646: dynamic list_filter support with custom lookup.\n    \"\"\"\n    parent = Parent.objects.create(name='parent')\n    for i in range(10):\n        Child.objects.create(name='child %s' % i, parent=parent)\n\n    user_noparents = self._create_superuser('noparents')\n    user_parents = self._create_superuser('parents')\n\n    # Test with user 'noparents'\n    m = DynamicListFilterChildAdmin(Child, custom_site)\n    request = self._mocked_authenticated_request('/child/', user_noparents)\n    response = m.changelist_view(request)\n    self.assertEqual(response.context_data['cl'].list_filter, ['name', 'age'])\n\n    # Test with user 'parents'\n    m = DynamicListFilterChildAdmin(Child, custom_site)\n    request = self._mocked_authenticated_request('/child/', user_parents)\n    response = m.changelist_view(request)\n    self.assertEqual(response.context_data['cl'].list_filter, ('parent', 'name', 'age'))\n\n    # Test with custom lookup\n    with register_lookup(Field, Contains, lookup_name='cc'):\n        m = DynamicListFilterChildAdmin(Child, custom_site)\n        request = self._mocked_authenticated_request('/child/', user_parents)\n        response = m.changelist_view(request)\n        self.assertEqual(response.context_data['cl'].list_filter, ('parent', 'name', 'age', 'name__cc'))\n"], "sample_905": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n        pass\n\n    func.register(int, lambda x: x)\n\n    assert inspect.is_singledispatch_function(func) is True\n    assert inspect.is_singledispatch_function(singledispatch(func)) is False\n\n        pass\n\n    assert inspect.is_singledispatch_function(func2) is False\n\n    class Foo:\n        @singledispatch\n            pass\n\n        @func.register\n            pass\n\n    assert inspect.is_singledispatch_function(Foo().func) is True\n    assert inspect.is_singledispatch_function(Foo().func_int) is False\n\n    class Bar:\n        @singledispatch\n            pass\n\n    assert inspect.is_singledispatch_function(Bar().func) is True\n"], "sample_72": ["def test_serialize_enum_member(self):\n    class Color(enum.Enum):\n        RED = 1\n        GREEN = 2\n        BLUE = 3\n\n    self.assertSerializedResultEqual(\n        Color.RED,\n        (\"migrations.test_writer.Color.RED\", {'import migrations.test_writer'})\n    )\n    self.assertSerializedResultEqual(\n        Color.GREEN,\n        (\"migrations.test_writer.Color.GREEN\", {'import migrations.test_writer'})\n    )\n    self.assertSerializedResultEqual(\n        Color.BLUE,\n        (\"migrations.test_writer.Color.BLUE\", {'import migrations.test_writer'})\n    )\n\n    field = models.CharField(default=Color.RED, choices=[(m.value, m) for m in Color])\n    string = MigrationWriter.serialize(field)[0]\n    self.assertEqual(\n        string,\n        \"models.CharField(choices=[\"\n        \"(1, migrations.test_writer.Color.RED), \"\n        \"(2, migrations.test_writer.Color.GREEN), \"\n        \"(3, migrations.test_writer.Color.BLUE)], \"\n        \"default=migrations.test_writer.Color.RED)\"\n    )\n"], "sample_1077": ["def test_ImageSet_simplification_with_multiple_variables():\n    from sympy.abc import x, y\n    assert imageset(Lambda((x, y), x + y), S.Integers) == \\\n        ImageSet(Lambda(x, x), S.Integers)\n    assert imageset(Lambda((x, y), x + y), S.Naturals) == \\\n        ImageSet(Lambda(x, x), S.Naturals)\n    assert imageset(Lambda((x, y), x + y), S.Naturals0) == \\\n        ImageSet(Lambda(x, x), S.Naturals0)\n    assert imageset(Lambda((x, y), x + y), S.Integers) == \\\n        ImageSet(Lambda(x, x), S.Integers)\n    assert imageset(Lambda((x, y), x + y), S.Integers) == \\\n        ImageSet(Lambda(x, x), S.Integers)\n    assert imageset(Lambda((x, y), x + y), S.Integers) == \\\n        ImageSet(Lambda(x, x), S.Integers)\n    assert imageset(Lambda((x, y), x + y), S.Integers) == \\\n        ImageSet(Lambda(x, x), S.Integers)\n    assert imageset(Lambda((x, y), x + y), S.Integers) == \\\n        ImageSet(Lambda(x, x), S.Integers)\n    assert imageset(Lambda((x, y), x + y), S.Integers) == \\\n        ImageSet(Lambda(x, x), S.Integers)\n    assert imageset(Lambda((x, y), x + y), S.Integers) == \\\n        ImageSet(Lambda(x, x), S.Integers)\n    assert imageset(Lambda((x, y), x + y), S.Integers) == \\\n        ImageSet(Lambda(x, x), S.Integers)\n    assert imageset(Lambda((x, y), x + y), S.Integers) == \\\n        ImageSet(Lambda(x, x), S.Integers)\n    assert imageset(Lambda((x, y), x + y), S.Integers) == \\\n        ImageSet(Lambda(x, x), S.Integers)\n    assert imageset(Lambda((x, y), x + y), S.Integers) == \\\n        ImageSet(Lambda(x, x), S.Integers)\n    assert imageset(L"], "sample_740": ["def test_check_X_y():\n    # Test check_X_y function\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1, 2])\n    with pytest.raises(ValueError):\n        check_X_y(X, y)\n\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y, multi_output=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([[0, 1], [2, 3]])\n    X_checked, y_checked = check_X_y(X, y, multi_output=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y, multi_output=True, y_numeric=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y, multi_output=True, y_numeric=True)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y, multi_output=True, y_numeric=False)\n    assert_array_equal(X_checked, X)\n    assert_array_equal(y_checked, y)\n\n    X = np.array([[1, 2], [3, 4]])\n    y = np.array([0, 1])\n    X_checked, y_checked = check_X_y(X, y, multi_output=True, y_numeric=False)\n    assert"], "sample_328": ["    def test_update_json_field(self):\n        json_field = JSONFieldNullable.objects.create(json_field='{\"key\": \"value\"}')\n        json_field.json_field = '{\"key\": \"new_value\"}'\n        JSONFieldNullable.objects.bulk_update([json_field], ['json_field'])\n        json_field.refresh_from_db()\n        self.assertEqual(json_field.json_field, '{\"key\": \"new_value\"}')\n"], "sample_1131": ["def test_issue_16537():\n    from sympy import fresnelc, fresnels, airyai, airyaiprime, airybiprime, airybi\n    from sympy.abc import x\n\n    prntr = SciPyPrinter()\n    assert prntr.doprint(fresnelc(x)) == 'scipy.special.fresnel(x)[1]'\n    assert prntr.doprint(fresnels(x)) == 'scipy.special.fresnel(x)[0]'\n    assert prntr.doprint(airyai(x)) == 'scipy.special.airy(x)[0]'\n    assert prntr.doprint(airyaiprime(x)) == 'scipy.special.airy(x)[1]'\n    assert prntr.doprint(airybi(x)) == 'scipy.special.airy(x)[2]'\n    assert prntr.doprint(airybiprime(x)) == 'scipy.special.airy(x)[3]'\n\n    prntr = NumPyPrinter()\n    assert prntr.doprint(fresnelc(x)) == '  # Not supported in Python with NumPy:\\n  # fresnelc\\nfresnelc(x)'\n    assert prntr.doprint(fresnels(x)) == '  # Not supported in Python with NumPy:\\n  # fresnels\\nfresnels(x)'\n    assert prntr.doprint(airyai(x)) == '  # Not supported in Python with NumPy:\\n  # airyai\\nairyai(x)'\n    assert prntr.doprint(airyaiprime(x)) == '  # Not supported in Python with NumPy:\\n  # airyaiprime\\nairyaiprime(x)'\n    assert prntr.doprint(airybi(x)) == '  # Not supported in Python with NumPy:\\n  # airybi\\nairybi(x)'\n    assert prntr.doprint(airybiprime(x)) == '  # Not supported in Python with NumPy:\\n  # airybiprime\\nairybiprime(x)'\n\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(fresnelc(x)) == '  # Not supported in Python:\\n  # fresnelc\\nfresnelc(x)'\n    assert prntr.doprint(fresnels(x"], "sample_1043": ["def test_TribonacciConstant():\n    assert mcode(S.TribonacciConstant) == \"1/3 + (1/3)*(19 - 3*33^(1/2))^(1/3) + \" \\\n        \"(1/3)*(3*33^(1/2) + 19)^(1/3)\"\n    assert mcode(x**S.TribonacciConstant) == \"x^(1/3 + (1/3)*(19 - 3*33^(1/2))^(1/3) + \" \\\n        \"(1/3)*(3*33^(1/2) + 19)^(1/3))\"\n    assert mcode(S.TribonacciConstant + S.TribonacciConstant) == \"1/3 + (1/3)*(19 - 3*33^(1/2))^(1/3) + \" \\\n        \"(1/3)*(3*33^(1/2) + 19)^(1/3) + 1/3 + (1/3)*(19 - 3*33^(1/2))^(1/3) + \" \\\n        \"(1/3)*(3*33^(1/2) + 19)^(1/3)\"\n"], "sample_750": ["def test_omp_cv_with_precomputed_gram():\n    y_ = y[:, 0]\n    gamma_ = gamma[:, 0]\n    ompcv = OrthogonalMatchingPursuitCV(normalize=True, fit_intercept=False,\n                                        max_iter=10, cv=5, precompute=True)\n    ompcv.fit(X, y_)\n    assert_equal(ompcv.n_nonzero_coefs_, n_nonzero_coefs)\n    assert_array_almost_equal(ompcv.coef_, gamma_)\n    omp = OrthogonalMatchingPursuit(normalize=True, fit_intercept=False,\n                                    n_nonzero_coefs=ompcv.n_nonzero_coefs_,\n                                    precompute=True)\n    omp.fit(X, y_)\n    assert_array_almost_equal(ompcv.coef_, omp.coef_)\n"], "sample_474": ["    def setUpTestData(cls):\n        cls.john = Author.objects.create(name=\"John Smith\", alias=\"smithj\")\n        cls.elena = Author.objects.create(name=\"\u00c9lena Jordan\", alias=\"elena\")\n        cls.rhonda = Author.objects.create(name=\"Rhonda\")\n"], "sample_849": ["def test_train_test_split_sparse_input():\n    # Check that train_test_split converts scipy sparse matrices\n    # to csr, as stated in the documentation\n    X = np.arange(100).reshape((10, 10))\n    sparse_types = [csr_matrix, csc_matrix, coo_matrix]\n    for InputFeatureType in sparse_types:\n        X_s = InputFeatureType(X)\n        X_train, X_test = train_test_split(X_s)\n        assert isinstance(X_train, csr_matrix)\n        assert isinstance(X_test, csr_matrix)\n"], "sample_537": ["    def test_stride_windows_axis0(self):\n        x = np.arange(100)\n        y = mlab.stride_windows(x, 32, noverlap=16, axis=0)\n        yt = self.calc_window_target(x, 32, noverlap=16, axis=0)\n        assert_array_equal(yt, y)\n"], "sample_448": ["    def test_deconstruction_with_expressions_and_fields(self):\n        fields = [\"foo\", \"bar\"]\n        name = \"unique_fields\"\n        constraint = models.UniqueConstraint(fields=fields, name=name, expressions=(Lower(\"title\"),))\n        path, args, kwargs = constraint.deconstruct()\n        self.assertEqual(path, \"django.db.models.UniqueConstraint\")\n        self.assertEqual(args, (Lower(\"title\"),))\n        self.assertEqual(kwargs, {\"fields\": tuple(fields), \"name\": name})\n"], "sample_363": ["    def test_render(self):\n        # Backslash in verbose_name to ensure it is JavaScript escaped.\n        w = widgets.AutocompleteSelect('test\\\\', 'test')\n        self.assertHTMLEqual(\n            w.render('test', 'test'),\n            '<select name=\"test\" class=\"admin-autocomplete select2-hidden-accessible\">'\n            '<div class=\"select2-container select2-container--default select2-container--focus select2-container--above\" '\n            'id=\"select2-test-container\" style=\"width: 200px;\">'\n            '<div class=\"select2-search select2-search--dropdown select2-search--above\" '\n            'style=\"width: 200px;\">'\n            '<input class=\"select2-search__field\" type=\"search\" tabindex=\"0\" autocomplete=\"off\" placeholder=\"\">'\n            '</div>'\n            '<ul class=\"select2-results select2-results--open select2-results--more\" role=\"listbox\" aria-expanded=\"true\">'\n            '<li class=\"select2-results__option\" role=\"option\" aria-selected=\"false\">'\n            '<div class=\"select2-results__option__text\">test</div></li></ul></div></select>'\n        )\n"], "sample_10": ["    def test_1(self, table_types):\n        self._setup(table_types)\n        t = self.t\n        t.add_index('a')\n        g = t.groups\n        assert len(g) == 1\n        assert g.keys == ['a']\n        assert g.indices == [t.indices[0]]\n        assert g.indices[0].col_position('a') == 0\n\n        g = t.groups\n        assert len(g) == 1\n        assert g.keys == ['a']\n        assert g.indices == [t.indices[0]]\n        assert g.indices[0].col_position('a') == 0\n\n        g = t.groups\n        assert len(g) == 1\n        assert g.keys == ['a']\n        assert g.indices == [t.indices[0]]\n        assert g.indices[0].col_position('a') == 0\n\n        g = t.groups\n        assert len(g) == 1\n        assert g.keys == ['a']\n        assert g.indices == [t.indices[0]]\n        assert g.indices[0].col_position('a') == 0\n\n        g = t.groups\n        assert len(g) == 1\n        assert g.keys == ['a']\n        assert g.indices == [t.indices[0]]\n        assert g.indices[0].col_position('a') == 0\n\n        g = t.groups\n        assert len(g) == 1\n        assert g.keys == ['a']\n        assert g.indices == [t.indices[0]]\n        assert g.indices[0].col_position('a') == 0\n\n        g = t.groups\n        assert len(g) == 1\n        assert g.keys == ['a']\n        assert g.indices == [t.indices[0]]\n        assert g.indices[0].col_position('a') == 0\n\n        g = t.groups\n        assert len(g) == 1\n        assert g.keys == ['a']\n        assert g.indices == [t.indices[0]]\n        assert g.indices[0].col_position('a') == 0\n\n        g = t.groups\n        assert len(g) == 1\n        assert g.keys == ['a']\n        assert g.indices == [t.indices[0]]\n        assert g.indices[0].col_position('a') == 0\n\n        g = t.groups\n       "], "sample_624": ["def test_inline_dask_repr(self) -> None:\n    import dask.array as da\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(2, 3)>\"\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]), chunks=(1, 3))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(1, 3)>\"\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]), chunks=(2, 1))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(2, 1)>\"\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]), chunks=(2, 2))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(2, 2)>\"\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]), chunks=(1, 1))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(1, 1)>\"\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]), chunks=(3, 3))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(3, 3)>\"\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]), chunks=(4, 4))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(4, 4)>\"\n\n    da_array = da.from_array(np.array([[1, 2, 3], [4, 5, 6]]), chunks=(5, 5))\n    assert formatting.inline_dask_repr(da_array) == \"dask.array<chunksize=(5, 5)>\"\n\n    da_array = da.from_array(np.array([[1, 2, 3"], "sample_968": ["def test_pydata_with_union_type_operator_old(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :annotation: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0],\n                ([desc_name, \"version\"],\n                 [desc_annotation, ([desc_sig_punctuation, ':'],\n                                    desc_sig_space,\n                                    [pending_xref, \"int\"],\n                                    desc_sig_space,\n                                    [desc_sig_punctuation, \"|\"],\n                                    desc_sig_space,\n                                    [pending_xref, \"str\"])]))\n"], "sample_115": ["    def test_sensitive_variables_decorator(self):\n        \"\"\"\n        The sensitive_variables decorator works with function calls.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(sensitive_variables_wrapper)\n            self.verify_unsafe_email(sensitive_variables_wrapper)\n\n        with self.settings(DEBUG=False):\n            self.verify_safe_response(sensitive_variables_wrapper)\n            self.verify_safe_email(sensitive_variables_wrapper)\n"], "sample_578": ["    def test_mapped_color_indirect_alpha(self, x, y, color):\n\n        p = Plot(x, y, color=color).add(Bars(alpha=0.5)).plot()\n        ax = p._figure.axes[0]\n        fcs = ax.collections[0].get_facecolors()\n        C0, C1, C2, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        expected = to_rgba_array([to_rgba(C0, 0.5), to_rgba(C1, 0.5), to_rgba(C2, 0.5), to_rgba(C0, 0.5), to_rgba(C2, 0.5)])\n        assert_array_equal(fcs, expected)\n"], "sample_684": ["    def test_not_raise_exception_with_mixed_encoding(self, tw_mock) -> None:\n        locals_dict = {\"unicode_string\": \"S\u00e3o Paulo\", \"utf8_string\": b\"S\\xc3\\xa3o Paulo\"}\n\n        r = ReprLocals([f\"{key} = {value}\" for key, value in locals_dict.items()])\n        r.toterminal(tw_mock)\n\n        assert (\n            tw_mock.lines[0]\n            == \"unicode_string = S\u00e3o Paulo, utf8_string = b'S\\xc3\\xa3o Paulo'\"\n        )\n"], "sample_287": ["def test_prepopulated_fields(self):\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title', 'nonexistent')}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'prepopulated_fields['slug']' refers to 'nonexistent', \"\n            \"which is not a field of 'admin_checks.Song'.\",\n            obj=SongAdmin,\n            id='admin.E027',\n        )\n    ]\n    self.assertEqual(errors, expected)\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n"], "sample_323": ["def test_migrate_marks_replacement_unapplied_on_failure(self):\n    \"\"\"\n    A new squash migration will be marked as unapplied if all its replaced\n    migrations were previously already unapplied (#24628).\n    \"\"\"\n    recorder = MigrationRecorder(connection)\n    # Record all replaced migrations as unapplied\n    recorder.record_unapplied(\"migrations\", \"0001_initial\")\n    recorder.record_unapplied(\"migrations\", \"0002_second\")\n    executor = MigrationExecutor(connection)\n    executor.migrate([(\"migrations\", \"0001_squashed_0002\")])\n\n    # Because 0001 and 0002 are both unapplied, their squashed replacement\n    # should be marked as unapplied.\n    self.assertNotIn(\n        (\"migrations\", \"0001_squashed_0002\"),\n        recorder.applied_migrations(),\n    )\n    self.assertIn(\n        (\"migrations\", \"0001_squashed_0002\"),\n        recorder.unapplied_migrations(),\n    )\n"], "sample_764": ["def test_column_transformer_sparse_remainder_transformer_sparse_output():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           sparse_threshold=0.8)\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n    # SparseMatrixTrans creates 3 features for each column. There is\n    # one column in ``transformers``, thus:\n    assert X_trans.shape == (3, 3 + 1)\n\n    exp_array = np.hstack(\n        (X_array[:, 0].reshape(-1, 1), np.eye(3)))\n    assert_array_equal(X_trans.toarray(), exp_array)\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], SparseMatrixTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n\n    # test that sparse_output_ is set to True\n    assert ct.sparse_output_\n"], "sample_451": ["def test_replace_metacharacters(self):\n    \"\"\"\n    Test that replace_metacharacters() correctly removes metacharacters from a pattern.\n    \"\"\"\n    pattern = r\"\\?*+^$\"\n    expected_output = r\"\\?*^$\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\?*+^$\\\\\"\n    expected_output = r\"\\?*+^$\\\\\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\?*+^$\\\\?\"\n    expected_output = r\"\\?*+^$\\\\?\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\?*+^$\\\\[bBAZ]\"\n    expected_output = r\"\\?*+^$\\\\[bBAZ]\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\?*+^$\\\\[bBAZ]\"\n    expected_output = r\"\\?*+^$\\\\[bBAZ]\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\?*+^$\\\\[bBAZ]\"\n    expected_output = r\"\\?*+^$\\\\[bBAZ]\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\?*+^$\\\\[bBAZ]\"\n    expected_output = r\"\\?*+^$\\\\[bBAZ]\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\?*+^$\\\\[bBAZ]\"\n    expected_output = r\"\\?*+^$\\\\[bBAZ]\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\?*+^$\\\\[bBAZ]\"\n    expected_output = r\"\\?*+^$\\\\[bBAZ]\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\?*+^$\\\\[bBAZ]\"\n    expected_output = r\"\\?*+^$\\\\[bBAZ]\"\n    self.assertEqual(replace_metacharacters(pattern), expected_output)\n\n    pattern = r\"\\?*+^$\\\\[bBAZ]\"\n    expected_output = r\"\\?*+^$\\\\[bBAZ]\"\n   "], "sample_903": ["def test_bh_match_exact_with_different_perplexity():\n    # check that the ``barnes_hut`` method match the exact one when\n    # ``angle = 0`` and ``perplexity > n_samples / 3``\n    random_state = check_random_state(0)\n    n_features = 10\n    X = random_state.randn(30, n_features).astype(np.float32)\n    X_embeddeds = {}\n    n_iter = {}\n    for perplexity in [10, 20, 40]:\n        for method in ['exact', 'barnes_hut']:\n            tsne = TSNE(n_components=2, method=method, learning_rate=1.0,\n                        init=\"random\", random_state=0, n_iter=251,\n                        perplexity=perplexity, angle=0)\n            # Kill the early_exaggeration\n            tsne._EXPLORATION_N_ITER = 0\n            X_embeddeds[method] = tsne.fit_transform(X)\n            n_iter[method] = tsne.n_iter_\n\n    for perplexity in [10, 20, 40]:\n        assert n_iter['exact'] == n_iter['barnes_hut']\n        assert_array_almost_equal(X_embeddeds['exact'], X_embeddeds['barnes_hut'],\n                                 decimal=3)\n"], "sample_65": ["    def test_json_catalog(self):\n        \"\"\"The json_catalog returns the language catalog and settings as JSON.\"\"\"\n        with override('de'):\n            response = self.client.get('/jsoni18n/')\n            data = json.loads(response.content.decode())\n            self.assertIn('catalog', data)\n            self.assertIn('formats', data)\n            self.assertEqual(data['formats']['TIME_INPUT_FORMATS'], ['%H:%M:%S', '%H:%M:%S.%f', '%H:%M'])\n            self.assertEqual(data['formats']['FIRST_DAY_OF_WEEK'], 0)\n            self.assertIn('plural', data)\n            self.assertEqual(data['catalog']['month name\\x04May'], 'Mai')\n            self.assertIn('DATETIME_FORMAT', data['formats'])\n            self.assertEqual(data['plural'], '(n != 1)')\n"], "sample_41": ["def test_prefixes():\n    \"\"\"\n    Test for a few units that the unit summary table correctly reports\n    whether or not that unit supports prefixes.\n\n    Regression test for https://github.com/astropy/astropy/issues/3835\n    \"\"\"\n    from astropy.units import si\n\n    for summary in utils._iter_unit_summary(si.__dict__):\n        unit, _, _, _, prefixes = summary\n\n        if unit.name == 'm':\n            assert prefixes\n        elif unit.name == 'kg':\n            assert prefixes\n        elif unit.name == 's':\n            assert prefixes\n        elif unit.name == 'A':\n            assert prefixes\n        elif unit.name == 'K':\n            assert prefixes\n        elif unit.name == 'mol':\n            assert prefixes\n        elif unit.name == 'cd':\n            assert prefixes\n        elif unit.name == 'sr':\n            assert prefixes\n        elif unit.name == 'rad':\n            assert prefixes\n        elif unit.name == 'Hz':\n            assert prefixes\n        elif unit.name == 'N':\n            assert prefixes\n        elif unit.name == 'Pa':\n            assert prefixes\n        elif unit.name == 'J':\n            assert prefixes\n        elif unit.name == 'W':\n            assert prefixes\n        elif unit.name == 'C':\n            assert prefixes\n        elif unit.name == 'V':\n            assert prefixes\n        elif unit.name == 'F':\n            assert prefixes\n        elif unit.name == 'Ohm':\n            assert prefixes\n        elif unit.name == 'S':\n            assert prefixes\n        elif unit.name == 'Wb':\n            assert prefixes\n        elif unit.name == 'T':\n            assert prefixes\n        elif unit.name == 'H':\n            assert prefixes\n        elif unit.name == 'Omega':\n            assert prefixes\n        elif unit.name == 'Ampere':\n            assert prefixes\n        elif unit.name == 'Kelvin':\n            assert prefixes\n        elif unit.name == 'Mole':\n            assert prefixes\n        elif unit.name == 'Lumen':\n            assert prefixes\n        elif unit.name == 'Steradian':\n            assert prefixes\n        elif unit.name == 'Radian':\n            assert prefixes\n        elif unit.name == 'Hertz':\n            assert prefixes\n        elif unit.name == 'Newton':\n            assert prefixes\n        elif unit.name == 'Pascal':\n            assert prefixes\n        elif unit.name == 'Joule':\n            assert prefixes\n        elif unit.name == 'Watt':\n            assert prefixes\n        elif unit.name"], "sample_315": ["    def test_not_prefixed_with_prefix(self):\n        with translation.override('en'):\n            self.assertEqual(reverse('not-prefixed'), '/en/not-prefixed/')\n            self.assertEqual(reverse('not-prefixed-included-url'), '/en/not-prefixed-include/foo/')\n\n        with translation.override('nl'):\n            self.assertEqual(reverse('not-prefixed'), '/en/not-prefixed/')\n            self.assertEqual(reverse('not-prefixed-included-url'), '/en/not-prefixed-include/foo/')\n"], "sample_36": ["def test_biweight_midcorrelation_axis():\n    \"\"\"Test a 2D array with the axis keyword.\"\"\"\n    with NumpyRNGContext(12345):\n        ny = 100\n        nx = 200\n        data = normal(5, 2, (ny, nx))\n\n        bw = biweight_midcorrelation(data[:, 0], data[:, 1])\n        bwi = []\n        for i in range(nx):\n            bwi.append(biweight_midcorrelation(data[:, 0], data[:, i]))\n        bwi = np.array(bwi)\n        assert_allclose(bw, bwi)\n\n        bw = biweight_midcorrelation(data[0, :], data[1, :])\n        bwi = []\n        for i in range(ny):\n            bwi.append(biweight_midcorrelation(data[i, 0], data[i, 1]))\n        bwi = np.array(bwi)\n        assert_allclose(bw, bwi)\n"], "sample_446": ["    def test_floatformat03(self):\n        output = self.engine.render_to_string(\"floatformat03\", {\"a\": \"6666.6666\", \"b\": mark_safe(\"6666.6666\")})\n        self.assertEqual(output, \"6,667.00 6,667.00\")\n"], "sample_896": ["def test_nmf_fit_transform_equivalence(solver):\n    # Test that fit_transform is equivalent to fit.transform for NMF\n    rng = np.random.mtrand.RandomState(42)\n    A = np.abs(rng.randn(6, 5))\n    m = NMF(\n        solver=solver,\n        n_components=3,\n        init=\"random\",\n        random_state=0,\n        tol=1e-6,\n    )\n    ft = m.fit_transform(A)\n    t = m.fit(A).transform(A)\n    assert_allclose(ft, t, atol=1e-1)\n"], "sample_876": ["def test_mlp_regressor_max_iter():\n    # Test max_iter.\n    # It should limit the number of iterations for the solver.\n    X = X_reg\n    y = y_reg\n\n    for activation in ACTIVATION_TYPES:\n        mlp = MLPRegressor(\n            solver=\"lbfgs\",\n            hidden_layer_sizes=50,\n            max_iter=10,\n            shuffle=True,\n            random_state=1,\n            activation=activation,\n        )\n        with pytest.warns(ConvergenceWarning):\n            mlp.fit(X, y)\n        assert mlp.n_iter_ == 10\n"], "sample_860": ["def test_check_array_sparse_dtype():\n    # Test that check_array preserves the dtype of sparse matrices\n    X = sp.csr_matrix(np.ones((10, 10), dtype=np.float32))\n    X_checked = check_array(X, dtype=None)\n    assert X_checked.dtype == np.float32\n    X_checked = check_array(X, dtype=np.float64)\n    assert X_checked.dtype == np.float64\n    X_checked = check_array(X, dtype=np.float32)\n    assert X_checked.dtype == np.float32\n\n    # Test that check_array preserves the dtype of sparse matrices when\n    # accept_sparse is a list of formats\n    X = sp.csr_matrix(np.ones((10, 10), dtype=np.float32))\n    X_checked = check_array(X, accept_sparse=['csr', 'csc'])\n    assert X_checked.dtype == np.float32\n    X_checked = check_array(X, accept_sparse=['csr', 'csc'], dtype=np.float64)\n    assert X_checked.dtype == np.float64\n    X_checked = check_array(X, accept_sparse=['csr', 'csc'], dtype=np.float32)\n    assert X_checked.dtype == np.float32\n\n    # Test that check_array preserves the dtype of sparse matrices when\n    # accept_sparse is a string\n    X = sp.csr_matrix(np.ones((10, 10), dtype=np.float32))\n    X_checked = check_array(X, accept_sparse='csr')\n    assert X_checked.dtype == np.float32\n    X_checked = check_array(X, accept_sparse='csr', dtype=np.float64)\n    assert X_checked.dtype == np.float64\n    X_checked = check_array(X, accept_sparse='csr', dtype=np.float32)\n    assert X_checked.dtype == np.float32\n\n    # Test that check_array preserves the dtype of sparse matrices when\n    # accept_sparse is True\n    X = sp.csr_matrix(np.ones((10, 10), dtype=np.float32))\n    X_checked = check_array(X, accept_sparse=True)\n    assert X_checked.dtype == np.float32\n    X_checked = check_array(X, accept_sparse=True, dtype=np.float64)\n    assert X_checked.dtype == np.float64\n    X_checked = check_array(X, accept_sparse=True, dtype=np.float32)\n    assert X_checked.dtype == np.float32\n"], "sample_594": ["def test_inline_dask_repr(self):\n    da = xr.DataArray(np.arange(10), dims=\"x\", chunks=2)\n    expected = \"dask.array<chunksize=(2,)>\"\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.arange(10), dims=\"x\", chunks=(2, 2))\n    expected = \"dask.array<chunksize=(2, 2)>\"\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.arange(10), dims=\"x\", chunks=(2, 2, 2))\n    expected = \"dask.array<chunksize=(2, 2, 2)>\"\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.arange(10), dims=\"x\", chunks=(2, 2, 2, 2))\n    expected = \"dask.array<chunksize=(2, 2, 2, 2)>\"\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.arange(10), dims=\"x\", chunks=(2, 2, 2, 2, 2))\n    expected = \"dask.array<chunksize=(2, 2, 2, 2, 2)>\"\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.arange(10), dims=\"x\", chunks=(2, 2, 2, 2, 2, 2))\n    expected = \"dask.array<chunksize=(2, 2, 2, 2, 2, 2)>\"\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.arange(10), dims=\"x\", chunks=(2, 2, 2, 2, 2, 2, 2))\n    expected = \"dask.array<chunksize=(2, 2, 2, 2, 2, 2, 2)>\"\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.arange(10), dims=\"x\", chunks=(2, 2, 2, 2, 2, "], "sample_421": ["    def test_empty_when(self):\n        self.assertQuerysetEqual(\n            CaseTestModel.objects.annotate(\n                test=Case(\n                    When(integer=1, then=Value(\"one\")),\n                    When(integer=2, then=Value(\"two\")),\n                    When(integer=3, then=Value(\"three\")),\n                    When(integer=4, then=Value(\"four\")),\n                    When(integer=5, then=Value(\"five\")),\n                ),\n            ).order_by(\"pk\"),\n            [(1, \"one\"), (2, \"two\"), (3, \"three\"), (2, \"two\"), (3, \"three\"), (3, \"three\"), (4, \"four\")],\n            transform=attrgetter(\"integer\", \"test\"),\n        )\n"], "sample_570": ["    def test_ci_errorbars(self, rng):\n\n        x = rng.normal(0, 1, 100)\n        kde = KDE()\n        agg = EstimateAggregator(kde, \"ci\", n_boot=100000, seed=0)\n        out = agg(x, \"x\")\n        assert out[\"xmin\"] == pytest.approx(out[\"x\"] - out[\"xmax\"], abs=1e-2)\n        assert out[\"xmax\"] == pytest.approx(out[\"x\"] + out[\"xmin\"], abs=1e-2)\n"], "sample_687": ["def test_log_auto_indent(caplog):\n    caplog.set_level(logging.INFO)\n    logger.info(\"boo %s\", \"arg\")\n    assert caplog.messages[0] == \"boo arg\"\n    assert \"boo arg\" in caplog.text\n\n    try:\n        raise Exception(\"test\")\n    except Exception:\n        logger.exception(\"oops\")\n        assert \"oops\" in caplog.messages[-1]\n        # Tracebacks are stored in the record and not added until the formatter or handler.\n        assert \"Exception\" in caplog.text\n        assert \"Exception\" not in caplog.messages[-1]\n\n    caplog.set_level(logging.INFO, logger=sublogger.name)\n    sublogger.info(\"boo %s\", \"arg\")\n    assert caplog.messages[0] == \"boo arg\"\n    assert \"boo arg\" in caplog.text\n\n    caplog.set_level(logging.INFO, logger=sublogger.name, auto_indent=2)\n    sublogger.info(\"boo %s\\nbaz %s\", \"arg1\", \"arg2\")\n    assert \"  boo arg1\\n  baz arg2\" == caplog.messages[0]\n    assert \"  boo arg1\\n  baz arg2\" in caplog.text\n"], "sample_963": ["def test_restify_type_hints_NewType():\n    MyInt = NewType('MyInt', int)\n    assert restify(MyInt) == \":py:class:`tests.test_util_typing.MyInt`\"\n"], "sample_1051": ["def test_dotprint_styles():\n    styles = [(Basic, {'color': 'blue', 'shape': 'ellipse'}),\n              (Expr,  {'color': 'black', 'fontname': 'Arial'})]\n    text = dotprint(x+2, styles=styles)\n    assert all(e in text for e in dotedges(x+2, repeat=False))\n    assert all(n in text for n in [dotnode(expr, styles=styles, repeat=False) for expr in (x, Integer(2), x+2)])\n    assert 'digraph' in text\n    assert 'color' in text\n    assert 'shape' in text\n    assert 'fontname' in text\n"], "sample_1031": ["def test_dimensional_expr():\n    dimsys = UnitSystem((m, kg, s), (c,))\n    assert dimsys._system.base_dims == (m.dimension, kg.dimension, s.dimension)\n    assert dimsys._system.derived_dims == (c.dimension,)\n\n    # test that the dimensional expression of a quantity is correct\n    c_dim_expr = dimsys._system.get_dimensional_expr(c)\n    assert c_dim_expr == m.dimension / (s.dimension ** 2)\n\n    # test that the dimensional expression of a quantity with a scale factor is correct\n    kg_dim_expr = dimsys._system.get_dimensional_expr(kg)\n    assert kg_dim_expr == kg.dimension\n\n    # test that the dimensional expression of a quantity with a scale factor that is a product of units is correct\n    m_dim_expr = dimsys._system.get_dimensional_expr(m)\n    assert m_dim_expr == m.dimension\n"], "sample_511": ["def test_matshow(tmpdir):\n    # Smoke test for matshow\n    fig, ax = plt.subplots()\n    matshow(np.array([[1, 2], [3, 4]]))\n    plt.close()\n"], "sample_1181": ["def test_numpy_print_methods():\n    prntr = NumPyPrinter()\n    assert hasattr(prntr, '_print_acos')\n    assert hasattr(prntr, '_print_log')\n    assert hasattr(prntr, '_print_erf')\n    assert hasattr(prntr, '_print_erfc')\n    assert hasattr(prntr, '_print_gamma')\n    assert hasattr(prntr, '_print_loggamma')\n    assert hasattr(prntr, '_print_sign')\n    assert hasattr(prntr, '_print_exp2')\n    assert hasattr(prntr, '_print_logaddexp')\n    assert hasattr(prntr, '_print_logaddexp2')\n    assert hasattr(prntr, '_print_arccos')\n    assert hasattr(prntr, '_print_arcsin')\n    assert hasattr(prntr, '_print_arctan')\n    assert hasattr(prntr, '_print_arccosh')\n    assert hasattr(prntr, '_print_arcsinh')\n    assert hasattr(prntr, '_print_arctanh')\n    assert hasattr(prntr, '_print_arctan2')\n    assert hasattr(prntr, '_print_arctanh')\n    assert hasattr(prntr, '_print_euler_gamma')\n    assert hasattr(prntr, '_print_nan')\n    assert hasattr(prntr, '_print_pinf')\n    assert hasattr(prntr, '_print_ninf')\n"], "sample_372": ["    def test_urlpattern_repr(self):\n        url_pattern = URLPattern(RegexPattern(r'^$'), views.empty_view)\n        self.assertEqual(\n            repr(url_pattern),\n            \"<URLPattern ^$>\"\n        )\n"], "sample_410": ["    def test_get_session_auth_hash(self):\n        user = AbstractBaseUser(password=\"password\")\n        self.assertIsInstance(user.get_session_auth_hash(), str)\n        self.assertEqual(len(user.get_session_auth_hash()), 64)\n"], "sample_495": ["    def test_get_page_with_invalid_page_number(self):\n        \"\"\"\n        Paginator.get_page() raises EmptyPage if allow_empty_first_page=False\n        and object_list is empty and page_number is 1.\n        \"\"\"\n        paginator = Paginator([], 2, allow_empty_first_page=False)\n        with self.assertRaises(EmptyPage):\n            paginator.get_page(1)\n"], "sample_1139": ["def test_ImageSet_simplification_with_rational():\n    from sympy.abc import n, m\n    assert imageset(Lambda(n, Rational(1, 2) + n), S.Integers) == S.Rationals\n    assert imageset(Lambda(n, Rational(1, 2) + n), S.Naturals) == Range(1, oo, 1)\n    assert imageset(Lambda(n, Rational(1, 2) + n), S.Naturals0) == Range(0, oo, 1)\n    assert imageset(Lambda(n, Rational(1, 2) - n), S.Naturals) == Range(-oo, 0, -1)\n    assert imageset(Lambda(n, Rational(1, 2) - n), S.Naturals0) == Range(0, 1, -1)\n"], "sample_1162": ["def test_MatMul_kind():\n    A = MatrixSymbol('A', 2,2)\n    assert MatMul(A, comm_x).kind is MatrixKind(NumberKind)\n    assert MatMul(A, A).kind is MatrixKind(MatrixKind(NumberKind))\n    assert MatMul(A, noncomm_x).kind is MatrixKind(UndefinedKind)\n    assert MatMul(noncomm_x, A).kind is MatrixKind(UndefinedKind)\n"], "sample_167": ["def test_intword_l10n(self):\n    # Positive integers.\n    test_list_positive = (\n        '100', '1000000', '1200000', '1290000', '1000000000', '2000000000',\n        '6000000000000',\n    )\n    result_list_positive = (\n        '100', '1,0 Millionen', '1,2 Millionen', '1,3 Millionen',\n        '1,0 Milliarde', '2,0 Milliarden', '6,0 Billionen',\n    )\n    # Negative integers.\n    test_list_negative = ('-' + test for test in test_list_positive)\n    result_list_negative = ('-' + result for result in result_list_positive)\n    with self.settings(USE_L10N=True, USE_THOUSAND_SEPARATOR=True):\n        with translation.override('de'):\n            self.humanize_tester(\n                (*test_list_positive, *test_list_negative),\n                (*result_list_positive, *result_list_negative),\n                'intword',\n            )\n"], "sample_982": ["def test_primeomega():\n    assert primeomega(1) == 0\n    assert primeomega(2) == 1\n    assert primeomega(3) == 1\n    assert primeomega(4) == 1\n    assert primeomega(5) == 1\n    assert primeomega(6) == 2\n    assert primeomega(7) == 1\n    assert primeomega(8) == 1\n    assert primeomega(9) == 2\n    assert primeomega(10) == 2\n    assert primeomega(11) == 1\n    assert primeomega(12) == 3\n    assert primeomega(13) == 1\n    assert primeomega(14) == 2\n    assert primeomega(15) == 2\n    assert primeomega(16) == 1\n    assert primeomega(17) == 1\n    assert primeomega(18) == 2\n    assert primeomega(19) == 1\n    assert primeomega(20) == 2\n    assert primeomega(21) == 2\n    assert primeomega(22) == 2\n    assert primeomega(23) == 1\n    assert primeomega(24) == 3\n    assert primeomega(25) == 2\n    assert primeomega(26) == 2\n    assert primeomega(27) == 3\n    assert primeomega(28) == 2\n    assert primeomega(29) == 1\n    assert primeomega(30) == 2\n    assert primeomega(31) == 1\n    assert primeomega(32) == 2\n    assert primeomega(33) == 2\n    assert primeomega(34) == 2\n    assert primeomega(35) == 2\n    assert primeomega(36) == 3\n    assert primeomega(37) == 1\n    assert primeomega(38) == 2\n    assert primeomega(39) == 2\n    assert primeomega(40) == 3\n    assert primeomega(41) == 1\n    assert primeomega(42) == 3\n    assert primeomega(43) == 1\n    assert primeomega(44) == 2\n    assert primeomega(45) == 2\n    assert prime"], "sample_425": ["def test_serialize_deconstructible_class(self):\n    \"\"\"\n    Test serialization of a deconstructible class.\n    \"\"\"\n    class DeconstructibleClass:\n            return (\"DeconstructibleClass\", [], {})\n\n    class DeconstructibleClassWithArgs:\n            return (\"DeconstructibleClassWithArgs\", [1, 2], {})\n\n    class DeconstructibleClassWithKwargs:\n            return (\"DeconstructibleClassWithKwargs\", [], {\"kwarg\": 1})\n\n    class DeconstructibleClassWithArgsAndKwargs:\n            return (\"DeconstructibleClassWithArgsAndKwargs\", [1, 2], {\"kwarg\": 1})\n\n    self.assertSerializedResultEqual(DeconstructibleClass, (\"DeconstructibleClass\", set()))\n    self.assertSerializedResultEqual(DeconstructibleClassWithArgs, (\"DeconstructibleClassWithArgs(1, 2)\", set()))\n    self.assertSerializedResultEqual(DeconstructibleClassWithKwargs, (\"DeconstructibleClassWithKwargs(kwarg=1)\", set()))\n    self.assertSerializedResultEqual(DeconstructibleClassWithArgsAndKwargs, (\"DeconstructibleClassWithArgsAndKwargs(1, 2, kwarg=1)\", set()))\n"], "sample_704": ["def test_node_repr_failure_py() -> None:\n    \"\"\"Ensure that repr_failure_py() returns a TerminalRepr instance.\"\"\"\n    node = nodes.Node(\"test_node\", session=pytest.config)\n    excinfo = pytest.raises(SystemExit)(lambda: 1 / 0).with_traceback(None)\n    result = node._repr_failure_py(excinfo)\n    assert isinstance(result, pytest._code.TerminalRepr)\n"], "sample_768": ["def test_train_test_split_with_sparse_input():\n    # Check that train_test_split converts scipy sparse matrices\n    # to csr, as stated in the documentation\n    X = np.arange(100).reshape((10, 10))\n    X_s = coo_matrix(X)\n    X_s_2 = csr_matrix(X)\n    y = np.arange(10)\n\n    split = train_test_split(X_s, y, test_size=0.2, train_size=0.5)\n    X_train, X_test, y_train, y_test = split\n    assert isinstance(X_train, csr_matrix)\n    assert isinstance(X_test, csr_matrix)\n\n    split = train_test_split(X_s_2, y, test_size=0.2, train_size=0.5)\n    X_train, X_test, y_train, y_test = split\n    assert isinstance(X_train, csr_matrix)\n    assert isinstance(X_test, csr_matrix)\n"], "sample_1168": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((0, 1, 2, 3))) == [(0, 1, 2, 3), (0, 1, 2, -3), (0, 1, -2, 3), (0, 1, -2, -3), (0, -1, 2, 3), (0, -1, 2, -3), (0, -1, -2, 3), (0, -1, -2, -3), (1, 0, 2, 3), (1, 0, 2, -3), (1, 0, -2, 3), (1, 0, -2, -3), (1, -0, 2, 3), (1, -0, 2, -3), (1, -0, -2, 3), (1, -0, -2, -3), (2, 0, 1, 3), (2, 0, 1, -3), (2, 0, -1, 3), (2, 0, -1, -3), (2, -0, 1, 3), (2, -0, 1, -3), (2, -0, -1, 3), (2, -0, -1, -3), (2, 1, 0, 3), (2, 1, 0, -3), (2, 1, -0, 3), (2, 1, -0, -3), (2, -1, 0, 3), (2, -1, 0, -3), (2, -1, -0, 3), (2, -1, -0, -3), (3, 0, 1, 2), (3, 0, 1, -2), (3, 0, -1, 2), (3, 0, -"], "sample_166": ["    def test_get_random_string_length(self):\n        # Test that get_random_string() raises a warning when no length is provided\n        with self.assertWarns(RemovedInDjango40Warning):\n            get_random_string()\n\n        # Test that get_random_string() returns a string of the correct length\n        self.assertEqual(len(get_random_string(10)), 10)\n        self.assertEqual(len(get_random_string(20)), 20)\n\n        # Test that get_random_string() returns a string with the correct characters\n        self.assertIn('a', get_random_string(10))\n        self.assertIn('A', get_random_string(10))\n        self.assertIn('0', get_random_string(10))\n        self.assertIn('9', get_random_string(10))\n\n        # Test that get_random_string() raises a ValueError when length is not an integer\n        with self.assertRaises(TypeError):\n            get_random_string('abc')\n\n        # Test that get_random_string() raises a ValueError when length is less than 0\n        with self.assertRaises(ValueError):\n            get_random_string(-1)\n"], "sample_561": ["def test_marker_scaled_invalid():\n    marker = markers.MarkerStyle(\"o\")\n    with pytest.raises(ValueError):\n        new_marker = marker.scaled(2, 2, 3)\n    with pytest.raises(ValueError):\n        new_marker = marker.scaled(2, 3, 4)\n"], "sample_930": ["def test_create_triple_index_with_name(app):\n    text = (\".. index:: triple: foo; bar; baz\\n\"\n            \"   :name: ref1\\n\"\n            \".. index:: triple: Python; Sphinx; reST\\n\"\n            \"   :name: ref2\\n\")\n    restructuredtext.parse(app, text)\n    index = IndexEntries(app.env).create_index(app.builder)\n    assert len(index) == 5\n    assert index[0] == ('B', [('bar', [[], [('baz, foo', [('', '#index-0')])], None),\n                              ('baz', [[], [('foo bar', [('', '#index-0')])], None])])\n    assert index[1] == ('F', [('foo', [[], [('bar baz', [('', '#index-0')])], None)])\n    assert index[2] == ('P', [('Python', [[], [('Sphinx reST', [('', '#index-1')])], None)])\n    assert index[3] == ('R', [('reST', [[], [('Python Sphinx', [('', '#index-1')])], None)])\n    assert index[4] == ('S', [('Sphinx', [[], [('reST, Python', [('', '#index-1')])], None]])\n\n    # check the reference labels are created correctly\n    std = app.env.get_domain('std')\n    assert std.anonlabels['ref1'] == ('index', 'ref1')\n    assert std.anonlabels['ref2'] == ('index', 'ref2')\n"], "sample_366": ["    def test_iso8601_duration(self):\n        test_values = (\n            ('P1D', timedelta(days=1)),\n            ('P1DT12H', timedelta(days=1, hours=12)),\n            ('P1DT12H30M', timedelta(days=1, hours=12, minutes=30)),\n            ('P1DT12H30M30S', timedelta(days=1, hours=12, minutes=30, seconds=30)),\n            ('P1DT12H30M30.1S', timedelta(days=1, hours=12, minutes=30, seconds=30, milliseconds=100)),\n            ('P1DT12H30M30.01S', timedelta(days=1, hours=12, minutes=30, seconds=30, milliseconds=10)),\n            ('P1DT12H30M30.001S', timedelta(days=1, hours=12, minutes=30, seconds=30, milliseconds=1)),\n            ('P1DT12H30M30.0001S', timedelta(days=1, hours=12, minutes=30, seconds=30, microseconds=100)),\n            ('P1DT12H30M30.00001S', timedelta(days=1, hours=12, minutes=30, seconds=30, microseconds=10)),\n            ('P1DT12H30M30.000001S', timedelta(days=1, hours=12, minutes=30, seconds=30, microseconds=1)),\n            ('P1DT12H30M30,000001S', timedelta(days=1, hours=12, minutes=30, seconds=30, microseconds=1)),\n            ('P-1DT12H30M30S', timedelta(days=-1, hours=12, minutes=30, seconds=30)),\n            ('P-1DT12H30M30.1S', timedelta(days=-1, hours=12, minutes=30, seconds=30, milliseconds=100)),\n            ('P-1DT12H30M30.01S', timedelta(days=-1, hours=12, minutes=30, seconds=30, milliseconds=10)),\n            ('P-1DT12H30M30.001S', timedelta(days=-1, hours=12, minutes=30, seconds=30, milliseconds=1)),\n            ('P-1DT12H30M30.0001S', timedelta(days=-1,"], "sample_1199": ["def test_tensor_product_trace():\n    assert tensor_product_simp(TP(A, B).trace()) == Tr(A)\n    assert tensor_product_simp(TP(A, B).trace(0)) == Tr(A)\n    assert tensor_product_simp(TP(A, B).trace(1)) == Tr(B)\n    assert tensor_product_simp(TP(A, B).trace([0, 1])) == Tr(A)*Tr(B)\n"], "sample_641": ["def test__get_pdata_path_default_recur(path: str, pylint_home: Path, expected: Path) -> None:\n    \"\"\"Test _get_pdata_path with default recurs value.\"\"\"\n    assert _get_pdata_path(Path(path), 1, pylint_home) == expected\n"], "sample_1072": ["def test_frac_real_imaginary():\n    r = Symbol('r', real=True)\n    i = Symbol('i', imaginary=True)\n    assert frac(r + i).rewrite(floor) == (r + i) - floor(r + i)\n    assert frac(r + i).rewrite(ceiling) == (r + i) + ceiling(-r - i)\n    assert frac(r + i).rewrite(frac) == r + i\n    assert Eq(frac(r + i), (r + i) - floor(r + i))\n    assert Eq(frac(r + i), (r + i) + ceiling(-r - i))\n\n    assert frac(r + i).is_finite\n    assert frac(r + i).is_real is None\n    assert frac(r + i).is_imaginary\n    assert frac(r + i).is_integer is None\n    assert frac(r + i).is_zero is None\n"], "sample_569": ["    def test_regress_out(self):\n\n        x = np.random.randn(100)\n        y = x + np.random.randn(100)\n        z = x + np.random.randn(100)\n\n        p = lm._RegressionPlotter(y, z)\n        p.regress_out(x, z)\n\n        assert np.allclose(p.x, y)\n        assert np.allclose(p.y, z - np.mean(z))\n\n        p = lm._RegressionPlotter(y, z, x_partial=x)\n        p.regress_out(x, z)\n\n        assert np.allclose(p.x, y)\n        assert np.allclose(p.y, z - np.mean(z))\n\n        x = pd.Series(x)\n        y = pd.Series(y)\n        z = pd.Series(z)\n        p = lm._RegressionPlotter(y, z, x_partial=x)\n        p.regress_out(x, z)\n\n        assert np.allclose(p.x, y)\n        assert np.allclose(p.y, z - np.mean(z))\n"], "sample_239": ["    def test_non_form_errors_raised_by_clean(self):\n        class BaseCustomFormSet(BaseFormSet):\n                raise ValidationError(\"This is a non-form error\")\n\n        ChoiceFormSet = formset_factory(Choice, formset=BaseCustomFormSet)\n        data = {\n            'choices-TOTAL_FORMS': '1',\n            'choices-INITIAL_FORMS': '0',\n        }\n        formset = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIsInstance(formset.non_form_errors(), ErrorList)\n        self.assertEqual(list(formset.non_form_errors()), ['This is a non-form error'])\n"], "sample_995": ["def test_Float_issue_10368():\n    a = S(32442016954)/78058255275\n    assert type(int(a)) is type(int(-a)) is int\n"], "sample_820": ["def test_transform_multiclass():\n    \"\"\"Check transform method of VotingClassifier on multiclass dataset.\"\"\"\n    clf1 = LogisticRegression(random_state=123, multi_class='ovr')\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    X = np.array([[-1.1, -1.5], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n    y = np.array([1, 2, 3, 2])\n\n    eclf1 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft').fit(X, y)\n    eclf2 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft',\n        flatten_transform=True).fit(X, y)\n    eclf3 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft',\n        flatten_transform=False).fit(X, y)\n\n    assert_array_equal(eclf1.transform(X).shape, (4, 6))\n    assert_array_equal(eclf2.transform(X).shape, (4, 6))\n    assert_array_equal(eclf3.transform(X).shape, (3, 4, 3))\n    assert_array_almost_equal(eclf1.transform(X),\n                              eclf2.transform(X))\n    assert_array_almost_equal(\n            eclf3.transform(X).swapaxes(0, 1).reshape((4, 6)),\n            eclf2.transform(X)\n    )\n"], "sample_1143": ["def test_issue_10368():\n    a = Rational(32442016954, 78058255275)\n    assert int(a) == 41\n    assert int(-a) == -41\n"], "sample_6": ["def test_angle_wrap():\n    \"\"\"\n    Test wrapping of Angle objects.\n    \"\"\"\n    a1 = Angle([0, 45, 90, 180, 270, 360, 720.], unit=u.degree)\n    a2 = a1.wrap_at(180 * u.deg)\n    npt.assert_almost_equal(a2.value, [-180, -135, 90, 0, 90, 180, 180])\n\n    a3 = Angle([0, 45, 90, 180, 270, 360, 720.], unit=u.degree)\n    a4 = a3.wrap_at(360 * u.deg)\n    npt.assert_almost_equal(a4.value, [0, 45, 90, 180, 270, 360, 0])\n\n    a5 = Angle([0, 45, 90, 180, 270, 360, 720.], unit=u.degree)\n    a6 = a5.wrap_at(360 * u.deg, inplace=True)\n    npt.assert_almost_equal(a6.value, [0, 45, 90, 180, 270, 360, 0])\n\n    a7 = Angle([0, 45, 90, 180, 270, 360, 720.], unit=u.degree)\n    a8 = a7.wrap_at(180 * u.deg, inplace=True)\n    npt.assert_almost_equal(a8.value, [-180, -135, 90, 0, 90, 180, 180])\n\n    with pytest.raises(u.UnitsError):\n        a9 = Angle([0, 45, 90, 180, 270, 360, 720.]).wrap_at(180 * u.km)\n\n    with pytest.raises(TypeError):\n        a10 = Angle([0, 45, 90, 180, 270, 360, 720.]).wrap_at('180d')\n"], "sample_1134": ["def test_latex_RandomDomain():\n    from sympy.stats import Normal, Die, Exponential, pspace, where\n    from sympy.stats.rv import RandomDomain\n\n    X = Normal('x1', 0, 1)\n    assert latex(where(X > 0)) == r\"\\text{Domain: }0 < x_{1} \\wedge x_{1} < \\infty\"\n\n    D = Die('d1', 6)\n    assert latex(where(D > 4)) == r\"\\text{Domain: }d_{1} = 5 \\vee d_{1} = 6\"\n\n    A = Exponential('a', 1)\n    B = Exponential('b', 1)\n    assert latex(\n        pspace(Tuple(A, B)).domain) == \\\n        r\"\\text{Domain: }0 \\leq a \\wedge 0 \\leq b \\wedge a < \\infty \\wedge b < \\infty\"\n\n    assert latex(RandomDomain(FiniteSet(x), FiniteSet(1, 2))) == \\\n        r'\\text{Domain: }\\left\\{x\\right\\}\\text{ in }\\left\\{1, 2\\right\\}'\n"], "sample_806": ["def test_gradient_boosting_init_with_zero():\n    # Check that GradientBoostingRegressor works when init is 'zero'.\n    X, y = make_regression(random_state=0)\n    gb = GradientBoostingRegressor(init='zero')\n    gb.fit(X, y)\n    assert_array_almost_equal(gb.predict(X), np.mean(y))\n"], "sample_859": ["def test_enet_path_return_models():\n    # Test that enet_path with return_models=True gives the same result\n\n    # Some toy data\n    X = np.array([[1, 2, 3.1], [2.3, 5.4, 4.3]]).T\n    y = np.array([1, 2, 3.1])\n    alphas = [5., 1., .5]\n\n    # Use lars_path and enet_path(new output) with 1D linear interpolation\n    # to compute the same path\n    alphas_lars, _, coef_path_lars = lars_path(X, y, method='elasticnet')\n    coef_path_cont_lars = interpolate.interp1d(alphas_lars[::-1],\n                                               coef_path_lars[:, ::-1])\n    alphas_lasso2, coef_path_lasso2, _ = enet_path(X, y, alphas=alphas,\n                                                    return_models=True)\n    coef_path_cont_lasso = interpolate.interp1d(alphas_lasso2[::-1],\n                                                coef_path_lasso2[:, ::-1])\n\n    assert_array_almost_equal(\n        coef_path_cont_lasso(alphas), coef_path_cont_lars(alphas),\n        decimal=1)\n"], "sample_252": ["    def test_json_field_with_custom_encoder_and_decoder(self):\n        value = {'uuid': uuid.UUID('{d85e2076-b67c-4ee7-8c3a-2bf5a2cc2475}')}\n        obj = JSONModel(value=value)\n        obj.save()\n        obj.refresh_from_db()\n        self.assertEqual(obj.value, value)\n"], "sample_773": ["def test_logistic_regression_path_deprecation_warning():\n    # Test that logistic_regression_path raises a deprecation warning\n    # when called directly.\n    assert_warns_message(DeprecationWarning,\n                         \"logistic_regression_path was deprecated\",\n                         logistic_regression_path, X, Y1)\n"], "sample_172": ["    def test_inline_formset_formfield_callback(self):\n        class MyInline(admin.StackedInline):\n            model = Member\n            formfield_overrides = {\n                models.CharField: {'widget': forms.TextInput(attrs={'size': 10})}\n            }\n\n        ma = MyInline(Member, admin.site)\n        ff = ma.formfield_for_dbfield(Member._meta.get_field('name'), request=None)\n        self.assertIsInstance(ff.widget, forms.TextInput)\n        self.assertEqual(ff.widget.attrs['size'], 10)\n"], "sample_398": ["    def test_password_change_fails_with_mismatched_passwords_with_custom_form(self):\n        self.login()\n        response = self.client.post(\n            \"/password_change/custom/\",\n            {\n                \"old_password\": \"password\",\n                \"new_password1\": \"password1\",\n                \"new_password2\": \"donuts\",\n            },\n        )\n        self.assertFormError(\n            response, SetPasswordForm.error_messages[\"password_mismatch\"]\n        )\n"], "sample_547": ["def test_offsetbox_set_width_height():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100)\n    da.set_width(200)\n    da.set_height(300)\n    assert da.width == 200\n    assert da.height == 300\n    assert da.get_bbox(ax.figure._get_renderer()).bounds == (0, 0, 200, 300)\n"], "sample_470": ["def test_lazy_classproperty(self):\n    \"\"\"\n    classproperty behaves like a property that can be accessed directly from the class.\n    \"\"\"\n\n    class Foo:\n        foo_attr = 123\n\n            self.foo_attr = 456\n\n        @classproperty\n            return cls.foo_attr\n\n        @classproperty\n            return cls.foo_attr\n\n    self.assertEqual(Foo.foo, 123)\n    self.assertEqual(Foo.bar, 123)\n    self.assertEqual(Foo().foo, 456)\n    self.assertEqual(Foo().bar, 123)\n"], "sample_1101": ["def test_schur_number():\n    # Test SchurNumber object creation and evaluation\n    assert SchurNumber(1) == 1\n    assert SchurNumber(2) == 4\n    assert SchurNumber(3) == 13\n    assert SchurNumber(4) == 44\n    assert SchurNumber(5) == SchurNumber(5)  # Only lower bound information is available\n\n    # Test lower_bound method\n    assert SchurNumber(5).lower_bound() == (3**5 - 1)/2\n\n    # Test SchurNumber with non-integer and non-positive values\n    raises(ValueError, lambda: SchurNumber(-1))\n    raises(ValueError, lambda: SchurNumber(0))\n    raises(ValueError, lambda: SchurNumber(S.Infinity))\n    raises(ValueError, lambda: SchurNumber(Rational(1, 2)))\n\n    # Test SchurNumber with large values\n    assert SchurNumber(100).lower_bound() == (3**100 - 1)/2\n"], "sample_971": ["def test_prefixed_warnings(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    with logging.prefixed_warnings(\"prefix:\"):\n        logger.warning('message1')\n        logger.warning('message2')\n\n    assert 'prefix: message1' in warning.getvalue()\n    assert 'prefix: message2' in warning.getvalue()\n\n    with logging.prefixed_warnings(\"prefix2:\"):\n        logger.warning('message3')\n        logger.warning('message4')\n\n    assert 'prefix2: message3' in warning.getvalue()\n    assert 'prefix2: message4' in warning.getvalue()\n\n    # test that prefix is not added when already prefixed\n    with logging.prefixed_warnings(\"prefix:\"):\n        logger.warning('message5', prefix='prefix:')\n\n    assert 'prefix: message5' in warning.getvalue()\n\n    # test that prefix is not added when no warning handler\n    logger = logging.getLogger('nonexisting')\n    with logging.prefixed_warnings(\"prefix:\"):\n        logger.warning('message6')\n\n    assert 'message6' in warning.getvalue()\n"], "sample_829": ["def test_incremental_pca_batch_size_change():\n    # Test that changing batch_size will raise an error.\n    rng = np.random.RandomState(1999)\n    n_samples = 100\n    n_features = 20\n    X = rng.randn(n_samples, n_features)\n    ipca = IncrementalPCA(n_components=None, batch_size=10)\n    ipca.fit(X)\n    assert_raises(ValueError, ipca.set_params, batch_size=20)\n    # Returning to original setting\n    ipca.set_params(batch_size=10)\n    ipca.partial_fit(X)\n"], "sample_484": ["    def setUpTestData(cls):\n        Author.objects.create(name=\"John Smith\", alias=\"smithj\")\n        Author.objects.create(name=\"Rhonda\")\n"], "sample_609": ["def test_unify_chunks() -> None:\n    array = np.arange(12).reshape(3, 4)\n    variable = xr.Variable([\"x\", \"y\"], array)\n    data_array = xr.DataArray(variable, {\"x\": [\"a\", \"b\"], \"y\": [-1, -2]})\n    dataset = xr.Dataset({\"data\": data_array})\n\n    expected_array = np.arange(12).reshape(3, 4)\n    expected_variable = xr.Variable([\"x\", \"y\"], expected_array)\n    expected_data_array = xr.DataArray(expected_variable, {\"x\": [\"a\", \"b\"], \"y\": [-1, -2]})\n    expected_dataset = xr.Dataset({\"data\": expected_data_array})\n\n    unified_array = unify_chunks(array)\n    unified_variable = unify_chunks(variable)\n    unified_data_array = unify_chunks(data_array)\n    unified_dataset = unify_chunks(dataset)\n\n    assert_identical(expected_array, unified_array)\n    assert_identical(expected_variable, unified_variable)\n    assert_identical(expected_data_array, unified_data_array)\n    assert_identical(expected_dataset, unified_dataset)\n"], "sample_613": ["def test_groupby_dataset_fillna_with_dataset_with_attrs():\n    ds = Dataset({\"a\": (\"x\", [np.nan, 1, np.nan, 3])}, {\"x\": [0, 1, 2, 3]})\n    expected = Dataset({\"a\": (\"x\", range(4))}, {\"x\": [0, 1, 2, 3]})\n    for target in [ds, expected]:\n        target.coords[\"b\"] = (\"x\", [0, 0, 1, 1])\n    expected.attrs[\"attr\"] = \"ds\"\n    expected.a.attrs[\"attr\"] = \"da\"\n    actual = ds.groupby(\"b\").fillna(Dataset({\"a\": (\"b\", [0, 2])}).assign_attrs({\"attr\": \"ds\"}))\n    assert_identical(expected, actual)\n"], "sample_1061": ["def test_Pow():\n    x = Symbol('x')\n    assert Pow(x, 2).as_base_exp() == (x, 2)\n    assert Pow(x, -2).as_base_exp() == (x, -2)\n    assert Pow(x, 2).as_base_exp() == (x, 2)\n    assert Pow(x, -2).as_base_exp() == (x, -2)\n    assert Pow(x, 2).as_base_exp() == (x, 2)\n    assert Pow(x, -2).as_base_exp() == (x, -2)\n    assert Pow(x, 2).as_base_exp() == (x, 2)\n    assert Pow(x, -2).as_base_exp() == (x, -2)\n    assert Pow(x, 2).as_base_exp() == (x, 2)\n    assert Pow(x, -2).as_base_exp() == (x, -2)\n    assert Pow(x, 2).as_base_exp() == (x, 2)\n    assert Pow(x, -2).as_base_exp() == (x, -2)\n    assert Pow(x, 2).as_base_exp() == (x, 2)\n    assert Pow(x, -2).as_base_exp() == (x, -2)\n    assert Pow(x, 2).as_base_exp() == (x, 2)\n    assert Pow(x, -2).as_base_exp() == (x, -2)\n    assert Pow(x, 2).as_base_exp() == (x, 2)\n    assert Pow(x, -2).as_base_exp() == (x, -2)\n    assert Pow(x, 2).as_base_exp() == (x, 2)\n    assert Pow(x, -2).as_base_exp() == (x, -2)\n    assert Pow(x, 2).as_base_exp() == (x, 2)\n    assert Pow(x, -2).as_base_exp() == (x, -2)\n    assert Pow(x, 2).as_base_exp() == (x, 2)\n    assert Pow(x, -2).as_base_exp() == (x, -2)\n    assert Pow(x, 2).as_base_exp() == (x, 2)\n    assert Pow(x, -2).as_base_exp() == (x, -2)\n    assert Pow"], "sample_128": ["    def test_partial_index_condition_with_multiple_fields(self):\n        with connection.schema_editor() as editor:\n            index = Index(\n                name='recent_article_idx',\n                fields=['pub_date', 'headline'],\n                condition=Q(pub_date__gt=datetime.datetime(\n                    year=2015, month=1, day=1,\n                    tzinfo=timezone.get_current_timezone(),\n                )) & Q(headline__contains='China'),\n            )\n            self.assertIn(\n                'WHERE (%s' % editor.quote_name('pub_date'),\n                str(index.create_sql(Article, schema_editor=editor))\n            )\n            self.assertIn(\n                'AND %s' % editor.quote_name('headline'),\n                str(index.create_sql(Article, schema_editor=editor))\n            )\n            editor.add_index(index=index, model=Article)\n            with connection.cursor() as cursor:\n                self.assertIn(index.name, connection.introspection.get_constraints(\n                    cursor=cursor, table_name=Article._meta.db_table,\n                ))\n            editor.remove_index(index=index, model=Article)\n"], "sample_725": ["def test_check_memory():\n    # Test check_memory function\n    # Test that check_memory returns a Memory instance\n    memory = check_memory(None)\n    assert isinstance(memory, sklearn.externals.joblib.Memory)\n\n    # Test that check_memory raises ValueError for invalid memory\n    with pytest.raises(ValueError):\n        check_memory('invalid_memory')\n\n    # Test that check_memory raises ValueError for invalid memory with cache method\n    class InvalidMemory:\n            pass\n    with pytest.raises(ValueError):\n        check_memory(InvalidMemory())\n\n    # Test that check_memory returns a Memory instance with custom cachedir\n    memory = check_memory('/tmp/custom_cachedir')\n    assert isinstance(memory, sklearn.externals.joblib.Memory)\n    assert memory.cachedir == '/tmp/custom_cachedir'\n\n    # Test that check_memory returns a Memory instance with custom verbose\n    memory = check_memory('/tmp/custom_cachedir', verbose=2)\n    assert isinstance(memory, sklearn.externals.joblib.Memory)\n    assert memory.verbose == 2\n"], "sample_44": ["    def test_hash(self):\n        lq1 = u.Magnitude(np.arange(1., 10.)*u.Jy)\n        lq2 = u.Magnitude(np.arange(1., 10.)*u.Jy)\n        lq3 = u.Magnitude(np.arange(1., 10.)*u.m)\n        assert hash(lq1) == hash(lq2)\n        assert hash(lq1) != hash(lq3)\n        luset = {lq1, lq2, lq3}\n        assert len(luset) == 2\n"], "sample_812": ["def test_n_max_elements_to_show_on_estimator():\n    # Test that n_max_elements_to_show is respected on estimators\n    n_max_elements_to_show = 30\n    pp = _EstimatorPrettyPrinter(\n        compact=True, indent=1, indent_at_name=True,\n        n_max_elements_to_show=n_max_elements_to_show\n    )\n\n    # Test with a long list of parameters\n    param_grid = {'C': list(range(n_max_elements_to_show + 1))}\n    gs = GridSearchCV(SVC(), param_grid)\n    expected = \"\"\""], "sample_408": ["def test_alter_field_with_default(self):\n    \"\"\"Tests autodetection of field default value changes.\"\"\"\n    changes = self.get_changes([self.author_name], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=\"Ada Lovelace\")\n"], "sample_179": ["    def test_deferrable_unique_constraint_required_db_features(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                required_db_features = {'supports_deferrable_unique_constraints'}\n                constraints = [\n                    models.UniqueConstraint(\n                        fields=['age'],\n                        name='unique_age_deferrable',\n                        deferrable=models.Deferrable.DEFERRED,\n                    ),\n                ]\n\n        self.assertEqual(Model.check(databases=self.databases), [])\n"], "sample_176": ["def test_alter_field_to_foreign_key(self):\n    \"\"\"Tests autodetection of field type changes from non-foreign key to foreign key.\"\"\"\n    changes = self.get_changes([self.author_empty, self.book_with_no_author], [self.author_empty, self.book_with_author])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, model_name=\"book\", name=\"author\")\n    self.assertEqual(changes['otherapp'][0].operations[0].field.remote_field.model._meta.app_label, 'testapp')\n    self.assertEqual(changes['otherapp'][0].operations[0].field.remote_field.model._meta.object_name, 'Author')\n"], "sample_48": ["def test_aggregate_over_annotation_with_expression(self):\n    \"\"\"\n    Test that aggregate over annotation with expression works correctly.\n    \"\"\"\n    qs = Author.objects.annotate(\n        combined_ages=Sum(F('age') + F('friends__age'))\n    ).annotate(\n        max_combined_age=Max('combined_ages')\n    )\n    self.assertEqual(qs.aggregate(max_combined_age=Max('combined_ages'))['max_combined_age'], 176)\n\n    qs = Author.objects.annotate(\n        combined_ages=Sum(F('age') + F('friends__age'))\n    ).annotate(\n        max_combined_age=Max('combined_ages'),\n        sum_combined_age=Sum('combined_ages')\n    )\n    self.assertEqual(qs.aggregate(max_combined_age=Max('combined_ages'), sum_combined_age=Sum('combined_ages'))['max_combined_age'], 176)\n    self.assertEqual(qs.aggregate(max_combined_age=Max('combined_ages'), sum_combined_age=Sum('combined_ages'))['sum_combined_age'], 954)\n\n    with self.assertRaisesMessage(FieldError, \"Cannot compute Max('id__max'): 'id__max' is an aggregate\"):\n        Author.objects.annotate(Max('id')).annotate(\n            max_combined_age=Max('id__max')\n        )\n"], "sample_481": ["    def test_stringformat01(self):\n        output = self.engine.render_to_string(\"stringformat01\")\n        self.assertEqual(output, \"hello world\")\n"], "sample_633": ["def test_ignore_signatures_class_methods_empty() -> None:\n    output = StringIO()\n    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n        similar.Run([\"--ignore-signatures\", SIMILAR_CLS_A, SIMILAR_CLS_B])\n    assert ex.value.code == 0\n    assert (\n        output.getvalue().strip()\n        == \"\"\""], "sample_1021": ["def test_quaternion_multiplication():\n    q = Quaternion(x, y, z, w)\n    q1 = Quaternion(1, 2, 3, 4)\n    q2 = Quaternion(5, 6, 7, 8)\n\n    assert q * q == Quaternion(-w**2 + x**2 - y**2 - z**2, 2*x*y, 2*x*z, 2*w*x)\n    assert q1 * q2 == Quaternion(-S(7)/225, -S(1)/225, -S(1)/150, -S(2)/225)\n    assert q * q1 == Quaternion(-S(7)/225, -S(1)/225, -S(1)/150, -S(2)/225)\n    assert q1 * q == Quaternion(-S(7)/225, -S(1)/225, -S(1)/150, -S(2)/225)\n\n    q3 = Quaternion(3 + 4*I, 2 + 5*I, 0, 7 + 8*I, real_field = False)\n    q4 = Quaternion(1, 4, 7, 8)\n\n    assert q3 * q4 == Quaternion((3 + 4*I)*(1) + (2 + 5*I)*(4) + (0)*(7) + (7 + 8*I)*(8),\n                                (3 + 4*I)*(4) + (2 + 5*I)*(7) + (0)*(8) + (7 + 8*I)*(1),\n                                (3 + 4*I)*(7) + (2 + 5*I)*(8) + (0)*(1) + (7 + 8*I)*(4),\n                                (3 + 4*I)*(8) + (2 + 5*I)*(1) + (0)*(4) + (7 + 8*I)*(7))\n    assert q4 * q3 == Quaternion((1)*(3 + 4*I) + (4)*(2 + 5*I) + (7)*(0) + (8)*(7 + 8*I),\n                                (1)*(2 + 5*I) + (4)*(3 + 4*I) + (7)*(0) + (8)*(7 + 8*I),\n                                (1)*(0) + (4)*(7) + (7)*(3 + 4*I) + (8"], "sample_912": ["def test_pydata_signature_with_type_and_value(app):\n    text = (\".. py:data:: var\\n\"\n            \"   :type: int\\n\"\n            \"   :value: 1\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"var\"],\n                                                    [desc_annotation, \": int\"],\n                                                    [desc_annotation, \" = 1\"])],\n                                  [desc_content, ()])]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n    assert 'var' in domain.objects\n    assert domain.objects['var'] == ('index', 'var', 'data')\n"], "sample_307": ["def test_invalid_date_format_specifiers(self):\n    my_birthday = datetime(1979, 7, 8, 22, 00)\n\n    for specifier in ['b', 'c', 'd', 'D', 'E', 'F', 'I', 'j', 'l', 'L', 'm', 'M', 'n', 'N', 'o', 'r', 'S', 't', 'U', 'w', 'W', 'z']:\n        msg = (\n            \"The format for time objects may not contain date-related format specifiers (found '%s').\" % specifier\n        )\n        with self.assertRaisesMessage(TypeError, msg):\n            dateformat.format(my_birthday, specifier)\n"], "sample_480": ["    def test_key_transform_gt(self):\n        self.assertCountEqual(\n            NullableJSONModel.objects.filter(value__c__gt=2),\n            [self.objs[3], self.objs[4]],\n        )\n        self.assertCountEqual(\n            NullableJSONModel.objects.filter(value__c__gt=2.33),\n            [self.objs[3], self.objs[4]],\n        )\n        self.assertIs(NullableJSONModel.objects.filter(value__c__lt=5).exists(), False)\n"], "sample_342": ["def test_limit_choices_to_with_distinct(self):\n    # Answer.question_with_to_field defines limit_choices_to to \"those not\n    # starting with 'not'\".\n    q = Question.objects.create(question='Is this a question?')\n    Question.objects.create(question='Not a question.')\n    request = self.factory.get(self.url, {'term': 'is', **self.opts, 'field_name': 'question_with_to_field'})\n    request.user = self.superuser\n    response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n    self.assertEqual(response.status_code, 200)\n    data = json.loads(response.content.decode('utf-8'))\n    self.assertEqual(data, {\n        'results': [{'id': str(q.uuid), 'text': q.question}],\n        'pagination': {'more': False},\n    })\n"], "sample_788": ["def test_fit_transform_sparse():\n    X = sp.csr_matrix([[1, 2, 3], [4, 5, 6]])\n    est = KBinsDiscretizer(n_bins=3, encode='ordinal')\n    with pytest.raises(TypeError):\n        est.fit_transform(X)\n"], "sample_617": ["def test_polyval_datetime() -> None:\n    x = xr.DataArray(\n        np.array([1000, 2000, 3000], dtype=\"timedelta64[ns]\"), dims=\"x\"\n    )\n    coeffs = xr.DataArray([0, 1], dims=\"degree\", coords={\"degree\": [0, 1]})\n    expected = xr.DataArray(\n        [1000.0, 2000.0, 3000.0], dims=\"x\", coords={\"x\": np.timedelta64(1000, \"ns\")}\n    )\n    actual = xr.polyval(x, coeffs)\n    xr.testing.assert_allclose(actual, expected)\n"], "sample_22": ["def test_matrix_product():\n    \"\"\"Test the matrix product function.\"\"\"\n    # Test with two matrices\n    m1 = rotation_matrix(30 * u.deg, \"x\")\n    m2 = rotation_matrix(45 * u.deg, \"y\")\n    assert_allclose(matrix_product(m1, m2), np.dot(m1, m2), atol=1e-12)\n\n    # Test with three matrices\n    m3 = rotation_matrix(60 * u.deg, \"z\")\n    assert_allclose(matrix_product(m1, m2, m3), np.dot(np.dot(m1, m2), m3), atol=1e-12)\n\n    # Test with a stack of matrices\n    m4 = np.stack((m1, m2, m3))\n    assert_allclose(matrix_product(m4), np.dot(m4), atol=1e-12)\n\n    # Test with a mix of scalar and matrix arguments\n    m5 = rotation_matrix(90 * u.deg, \"x\")\n    assert_allclose(matrix_product(m5, m1), np.dot(m5, m1), atol=1e-12)\n    assert_allclose(matrix_product(m1, m5), np.dot(m1, m5), atol=1e-12)\n\n    # Test with a single matrix\n    assert_allclose(matrix_product(m1), m1, atol=1e-12)\n\n    # Test with an empty sequence\n    assert matrix_product() is None\n\n    # Test with a sequence containing a non-matrix argument\n    with pytest.raises(TypeError):\n        matrix_product(m1, 1)\n"], "sample_554": ["def test_bbox_position():\n    fig, ax = plt.subplots()\n    ax.text(0.5, 0.5, 'test', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n    ax.text(0.5, 0.5, 'test', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5, pad=0.1))\n    ax.text(0.5, 0.5, 'test', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5, pad=0.2))\n    ax.text(0.5, 0.5, 'test', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5, pad=0.3))\n    ax.text(0.5, 0.5, 'test', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5, pad=0.4))\n    ax.text(0.5, 0.5, 'test', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5, pad=0.5))\n    ax.text(0.5, 0.5, 'test', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5, pad=0.6))\n    ax.text(0.5, 0.5, 'test', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5, pad=0.7))\n    ax.text(0.5, 0.5, 'test', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5, pad=0.8))\n    ax.text(0.5, 0.5, 'test', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5, pad=0.9))\n    ax.text(0.5, 0.5, 'test', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5, pad=1.0))\n"], "sample_622": ["    def test_decode_cf_variable_with_unsigned_integer(self) -> None:\n        v = Variable([\"t\"], [1, 2, 3], {\"units\": \"m\", \"_Unsigned\": True})\n        v_decoded = conventions.decode_cf_variable(\"test2\", v)\n        assert_identical(v, v_decoded)\n"], "sample_357": ["def test_add_field_with_callable_default(self):\n    \"\"\"#23609 - Adding a field with a callable default should work.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, 'testapp', 0, 0, default='Ada Lovelace')\n"], "sample_1187": ["def test_hyperplane_parameters():\n    #  Test for 2D polytopes\n    triangle = Polygon(Point(0, 3), Point(5, 3), Point(1, 1))\n    assert hyperplane_parameters(triangle) == [((0, 1), 3), ((1, -2), -1), ((-2, -1), -3)]\n\n    #  Test for 3D polytopes\n    cube = [[(0, 0, 0), (0, 0, 5), (0, 5, 0), (0, 5, 5), (5, 0, 0),\\\n             (5, 0, 5), (5, 5, 0), (5, 5, 5)],\\\n            [2, 6, 7, 3], [3, 7, 5, 1], [7, 6, 4, 5], [1, 5, 4, 0],\\\n            [3, 1, 0, 2], [0, 4, 6, 2]]\n    assert hyperplane_parameters(cube[1:], cube[0]) == [([0, -1, 0], -5), ([0, 0, -1], -5), ([-1, 0, 0], -5),\n                                                     ([0, 1, 0], 0), ([1, 0, 0], 0), ([0, 0, 1], 0)]\n\n    #  Test for 2D polytopes with clockwise=True\n    triangle = Polygon(Point(0, 3), Point(5, 3), Point(1, 1))\n    assert hyperplane_parameters(triangle, clockwise=True) == [((0, 1), 3), ((1, -2), -1), ((-2, -1), -3)]\n\n    #  Test for 3D polytopes with clockwise=True\n    cube = [[(0, 0, 0), (0, 0, 5), (0, 5, 0), (0, 5, 5), (5, 0, 0),\\\n             (5, 0, 5), (5, 5, 0), (5, 5, 5"], "sample_524": ["def test_colorbar_extension_shape_proportional():\n    # Remove this line when this test image is regenerated.\n    plt.rcParams['pcolormesh.snap'] = False\n\n    # Create figures for uniform and proportionally spaced colorbars.\n    _colorbar_extension_shape('proportional')\n"], "sample_75": ["    def test_prefetch_related_with_limit(self):\n        with self.assertNumQueries(2):\n            qs = Book.objects.prefetch_related('authors').limit(1)\n            lists = [list(b.authors.all()) for b in qs]\n\n        normal_lists = [list(b.authors.all()) for b in Book.objects.all()]\n        self.assertEqual(lists, normal_lists[:1])\n"], "sample_92": ["    def setUpTestData(cls):\n        cls.user = User.objects.create_user('test', 'test@example.com', 'test')\n        cls.remote_user = 'test_remote_user'\n"], "sample_807": ["def test_calibration_class_weight():\n    \"\"\"Test calibration with class weights\"\"\"\n    n_samples = 100\n    X, y = make_classification(n_samples=2 * n_samples, n_features=6,\n                               random_state=42)\n    sample_weight = np.random.RandomState(seed=42).uniform(size=y.size)\n\n    X -= X.min()  # MultinomialNB only allows positive X\n\n    # split train and test\n    X_train, y_train, sw_train = \\\n        X[:n_samples], y[:n_samples], sample_weight[:n_samples]\n    X_test, y_test = X[n_samples:], y[n_samples:]\n\n    # Naive-Bayes\n    clf = MultinomialNB()\n    clf.fit(X_train, y_train, sample_weight=sw_train)\n    prob_pos_clf = clf.predict_proba(X_test)[:, 1]\n\n    # Naive Bayes with calibration\n    for this_X_train, this_X_test in [(X_train, X_test),\n                                      (sparse.csr_matrix(X_train),\n                                       sparse.csr_matrix(X_test))]:\n        for method in ['isotonic', 'sigmoid']:\n            pc_clf = CalibratedClassifierCV(clf, method=method, cv=2)\n            # Note that this fit overwrites the fit on the entire training\n            # set\n            pc_clf.fit(this_X_train, y_train, sample_weight=sw_train)\n            prob_pos_pc_clf = pc_clf.predict_proba(this_X_test)[:, 1]\n\n            # Check that brier score has improved after calibration\n            assert_greater(brier_score_loss(y_test, prob_pos_clf),\n                           brier_score_loss(y_test, prob_pos_pc_clf))\n\n            # Check invariance against relabeling [0, 1] -> [1, 2]\n            pc_clf.fit(this_X_train, y_train + 1, sample_weight=sw_train)\n            prob_pos_pc_clf_relabeled = pc_clf.predict_proba(this_X_test)[:, 1]\n            assert_array_almost_equal(prob_pos_pc_clf,\n                                      prob_pos_pc_clf_relabeled)\n\n            # Check invariance against relabeling [0, 1] -> [-1, 1]\n            pc_clf.fit(this_X_train, 2 * y_train - 1, sample_weight=sw_train)\n            prob_pos_pc_clf_relabeled = pc_clf.predict_proba(this_X_test)[:, 1]\n            assert"], "sample_224": ["def test_aggregate_subquery_annotation_values_list(self):\n    \"\"\"\n    Subquery annotations and external aliases are excluded from the GROUP\n    BY if they are not selected.\n    \"\"\"\n    books_qs = Book.objects.annotate(\n        first_author_the_same_age=Subquery(\n            Author.objects.filter(\n                age=OuterRef('contact__friends__age'),\n            ).order_by('age').values('id')[:1],\n        )\n    ).filter(\n        publisher=self.p1,\n        first_author_the_same_age__isnull=False,\n    ).annotate(\n        min_age=Min('contact__friends__age'),\n    ).values_list('name', 'min_age').order_by('name')\n    self.assertEqual(list(books_qs), [\n        ('Practical Django Projects', 34),\n        ('The Definitive Guide to Django: Web Development Done Right', 29),\n    ])\n\n    books_qs = Book.objects.annotate(\n        first_author_the_same_age=Subquery(\n            Author.objects.filter(\n                age=OuterRef('contact__friends__age'),\n            ).order_by('age').values('id')[:1],\n        )\n    ).filter(\n        publisher=self.p1,\n        first_author_the_same_age__isnull=False,\n    ).annotate(\n        min_age=Min('contact__friends__age'),\n    ).values_list('name', flat=True)\n    self.assertEqual(list(books_qs), [\n        'Practical Django Projects',\n        'The Definitive Guide to Django: Web Development Done Right',\n    ])\n\n    books_qs = Book.objects.annotate(\n        first_author_the_same_age=Subquery(\n            Author.objects.filter(\n                age=OuterRef('contact__friends__age'),\n            ).order_by('age').values('id')[:1],\n        )\n    ).filter(\n        publisher=self.p1,\n        first_author_the_same_age__isnull=False,\n    ).annotate(\n        min_age=Min('contact__friends__age'),\n    ).values_list('min_age')\n    self.assertEqual(list(books_qs), [34, 29])\n"], "sample_915": ["def test_getdoc_partial():\n        \"\"\"docstring.\"\"\"\n    func2 = functools.partial(func1, 1)\n    func2.__doc__ = \"func2\"\n    func3 = functools.partial(func2, 2)  # nested partial object\n\n    assert inspect.getdoc(func2) == \"func2\"\n    assert inspect.getdoc(func3) == \"func2\"\n    assert inspect.getdoc(func1) == \"docstring.\"\n"], "sample_211": ["    def _assert_extra_context(self, response):\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.context['title'], 'Title')\n        self.assertEqual(response.context['extra_key'], 'extra_value')\n"], "sample_1203": ["def test_kernel():\n    # FpGroup -> PermutationGroup\n    F, a, b = free_group(\"a, b\")\n    G = FpGroup(F, [a**3, b**3, (a*b)**2])\n    A = AlternatingGroup(4)\n    T = homomorphism(G, A, [a, b], [Permutation(3)(0, 1, 2), Permutation(3)(1, 2, 3)])\n    assert T.kernel().order() == 6\n    assert T.kernel().is_subgroup(G)\n\n    # FpGroup -> FpGroup\n    E, e = free_group(\"e\")\n    G = FpGroup(E, [e**8])\n    P = PermutationGroup([Permutation(0, 1, 2, 3), Permutation(0, 2)])\n    T = homomorphism(G, P, [e], [Permutation(0, 1, 2, 3)])\n    assert T.kernel().order() == 8\n    assert T.kernel().is_subgroup(G)\n\n    # PermutationGroup -> PermutationGroup\n    D = DihedralGroup(8)\n    p = Permutation(0, 1, 2, 3, 4, 5, 6, 7)\n    P = PermutationGroup(p)\n    T = homomorphism(P, D, [p], [p])\n    assert T.kernel().order() == 1\n    assert T.kernel().is_subgroup(P)\n\n    # FreeGroup -> FreeGroup\n    T = homomorphism(F, E, [a], [e])\n    assert T.kernel().order() == 1\n    assert T.kernel().is_subgroup(F)\n\n    # FreeGroup -> FpGroup\n    G = FpGroup(F, [a*b*a**-1*b**-1])\n    T = homomorphism(F, G, F.generators, G.generators)\n    assert T.kernel().order() == 1\n    assert T.kernel().is_subgroup(F)\n\n    # PermutationGroup -> PermutationGroup\n    T = homomorphism(P, P, P.generators, P.generators)\n    assert T.kernel().order() == 1\n    assert T.kernel().is_subgroup(P)\n"], "sample_689": ["def test_strict_option_is_deprecated(testdir: Testdir) -> None:\n    \"\"\"Test that the --strict option is deprecated.\"\"\"\n    threepass = testdir.makepyfile(\n        test_threepass=\"\"\"\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--strict\", threepass)\n    result.stdout.fnmatch_lines([\"*The --strict option is deprecated*\"])\n"], "sample_233": ["def test_token_with_different_password(self):\n    \"\"\"\n    A valid token can be created with a password other than the one used to\n    create the user.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    user.set_password('newpw')\n    user.save()\n    self.assertIs(p0.check_token(user, tk1), False)\n    # Create and check a token with the new password.\n    tk2 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk2), True)\n"], "sample_1090": ["def test_division():\n    with evaluate(False):\n        p = 5 / oo\n        assert isinstance(p, Mul) and p.args == (5, S.One / oo)\n        p = oo / 5\n        assert isinstance(p, Mul) and p.args == (S.One / 5, oo)\n        p = 5 / -oo\n        assert isinstance(p, Mul) and p.args == (5, S.One / -oo)\n        p = -oo / 5\n        assert isinstance(p, Mul) and p.args == (S.One / 5, -oo)\n        p = oo / -5\n        assert isinstance(p, Mul) and p.args == (S.One / -5, oo)\n        p = -5 / oo\n        assert isinstance(p, Mul) and p.args == (-5, S.One / oo)\n\n    with evaluate(False):\n        expr = x / x\n        assert isinstance(expr, Mul)\n        assert expr.args == (x, S.One / x)\n\n        with evaluate(True):\n            assert (x / x).args == (1, x)\n\n        assert (x / x).args == (x, S.One / x)\n\n    assert isinstance(x / x, Mul)\n\n    with evaluate(False):\n        assert S.One / 1 == Mul(1, S.One / 1)\n        assert 1 / S.One == Mul(1, S.One / 1)\n\n        assert S(4) / 3 == Mul(4, S.One / 3)\n        assert 3 / S(4) == Mul(3, S.One / 4)\n\n        assert S(2) / 9 == Mul(2, S.One / 9)\n        assert 9 / S(2) == Mul(9, S.One / 2)\n\n        assert S(6) / 3 == Mul(6, S.One / 3)\n        assert 3 / S(6) == Mul(3, S.One / 6)\n\n        assert S(2) / 4 == Mul(2, S.One / 4)\n        assert 4 / S(2) == Mul(4, S.One / 2)\n\n        assert S(4) / 7 == Mul(4, S.One / 7)\n        assert 7 / S(4) == Mul(7, S.One / 4)\n\n        assert S(2) / 2 == Mul("], "sample_1201": ["def test_conversion_to_from_farad():\n    assert convert_to(farad, coulomb_constant, cgs_gauss) == coulomb_constant/10**5*speed_of_light**2*centimeter\n    assert convert_to(coulomb_constant, farad, cgs_gauss) == 10**5*speed_of_light**2*centimeter*farad\n    assert convert_to(farad, coulomb_constant, SI) == farad\n    assert convert_to(coulomb_constant, farad, SI) == coulomb_constant\n\n    assert convert_to(farad, coulomb_constant, cgs_gauss) == coulomb_constant/10**5*speed_of_light**2*centimeter\n    assert convert_to(coulomb_constant, farad, cgs_gauss) == 10**5*speed_of_light**2*centimeter*farad\n"], "sample_847": ["def test_enet_path_return_models():\n    # Test that lasso_path with lars_path style output gives the\n    # same result\n\n    # Some toy data\n    X = np.array([[1, 2, 3.1], [2.3, 5.4, 4.3]]).T\n    y = np.array([1, 2, 3.1])\n    alphas = [5., 1., .5]\n\n    # Use lars_path and lasso_path(new output) with 1D linear interpolation\n    # to compute the same path\n    alphas_lars, _, coef_path_lars = lars_path(X, y, method='lasso')\n    coef_path_cont_lars = interpolate.interp1d(alphas_lars[::-1],\n                                               coef_path_lars[:, ::-1])\n    alphas_lasso2, coef_path_lasso2, _ = lasso_path(X, y, alphas=alphas,\n                                                    return_models=True)\n    coef_path_cont_lasso = interpolate.interp1d(alphas_lasso2[::-1],\n                                                coef_path_lasso2[:, ::-1])\n\n    assert_array_almost_equal(\n        coef_path_cont_lasso(alphas), coef_path_cont_lars(alphas),\n        decimal=1)\n"], "sample_478": ["    def test_prepopulated_fields_with_choices(self):\n        class TestModelAdmin(ModelAdmin):\n            prepopulated_fields = {\"choices\": (\"name\",)}\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'prepopulated_fields' refers to 'choices', which must \"\n            \"not be a DateTimeField, a ForeignKey, a OneToOneField, or a \"\n            \"ManyToManyField.\",\n            \"admin.E028\",\n        )\n"], "sample_1": ["def test_separability_matrix_custom_model():\n    @custom_model\n        return x\n\n    @custom_model\n        return x\n\n    @custom_model\n        return x\n\n    model = model_a & model_b | model_c\n    result = separability_matrix(model)\n    assert result.shape == (3, 1)\n    assert result[0, 0] == True\n    assert result[1, 0] == True\n    assert result[2, 0] == True\n\n    model = model_a & model_b\n    result = separability_matrix(model)\n    assert result.shape == (1, 2)\n    assert result[0, 0] == True\n    assert result[0, 1] == True\n\n    model = model_a | model_b\n    result = separability_matrix(model)\n    assert result.shape == (1, 2)\n    assert result[0, 0] == True\n    assert result[0, 1] == True\n\n    model = model_a + model_b\n    with pytest.raises(ModelDefinitionError, match=r\"Unsupported operands for arithmetic operator: .*\"):\n        separability_matrix(model)\n\n    model = model_a - model_b\n    with pytest.raises(ModelDefinitionError, match=r\"Unsupported operands for arithmetic operator: .*\"):\n        separability_matrix(model)\n\n    model = model_a * model_b\n    with pytest.raises(ModelDefinitionError, match=r\"Unsupported operands for arithmetic operator: .*\"):\n        separability_matrix(model)\n\n    model = model_a / model_b\n    with pytest.raises(ModelDefinitionError, match=r\"Unsupported operands for arithmetic operator: .*\"):\n        separability_matrix(model)\n\n    model = model_a ** model_b\n    with pytest.raises(ModelDefinitionError, match=r\"Unsupported operands for arithmetic operator: .*\"):\n        separability_matrix(model)\n"], "sample_798": ["def test_ridge_regression_return_intercept():\n    # Test that return_intercept=True works as expected\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 5, 10\n    X = rng.randn(n_samples, n_features)\n    y = rng.randn(n_samples)\n    Y = np.c_[y, 1 + y]\n\n    ridge = Ridge(fit_intercept=False, return_intercept=True)\n    ridge.fit(X, y)\n    assert_equal(ridge.coef_.shape, (n_features,))\n    assert_equal(ridge.intercept_.shape, ())\n\n    ridge.fit(X, Y)\n    assert_equal(ridge.coef_.shape, (2, n_features))\n    assert_equal(ridge.intercept_.shape, (2, ))\n\n    # Test that return_intercept=True works with sparse data\n    X_sparse = sp.csr_matrix(X)\n    ridge_sparse = Ridge(fit_intercept=False, return_intercept=True)\n    ridge_sparse.fit(X_sparse, y)\n    assert_equal(ridge_sparse.coef_.shape, (n_features,))\n    assert_equal(ridge_sparse.intercept_.shape, ())\n\n    ridge_sparse.fit(X_sparse, Y)\n    assert_equal(ridge_sparse.coef_.shape, (2, n_features))\n    assert_equal(ridge_sparse.intercept_.shape, (2, ))\n\n    # Test that return_intercept=True works with sample weights\n    sample_weight = 1.0 + rng.rand(n_samples)\n    ridge.fit(X, y, sample_weight=sample_weight)\n    assert_equal(ridge.coef_.shape, (n_features,))\n    assert_equal(ridge.intercept_.shape, ())\n\n    ridge.fit(X, Y, sample_weight=sample_weight)\n    assert_equal(ridge.coef_.shape, (2, n_features))\n    assert_equal(ridge.intercept_.shape, (2, ))\n\n    # Test that return_intercept=True works with sparse data and sample weights\n    X_sparse = sp.csr_matrix(X)\n    ridge_sparse.fit(X_sparse, y, sample_weight=sample_weight)\n    assert_equal(ridge_sparse.coef_.shape, (n_features,))\n    assert_equal(ridge_sparse.intercept_.shape, ())\n\n    ridge_sparse.fit(X_sparse, Y, sample_weight=sample_weight)\n    assert_equal(ridge_sparse.coef_.shape, (2, n_features))\n    assert_equal(ridge_sparse.intercept_.shape, (2, ))\n"], "sample_519": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect((1, 2, 3))\n    ax2.set_box_aspect((2, 1, 1))\n"], "sample_291": ["    def _assert_about(self, response):\n        response.render()\n        self.assertContains(response, '<h1>About</h1>')\n"], "sample_680": ["    def test_xfail_raises_with_multiple_exceptions(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(raises=(TypeError, ValueError))\n                raise TypeError()\n        \"\"\"\n        )\n        result = testdir.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n"], "sample_99": ["def test_trunc_func_with_timezone(self):\n    \"\"\"\n    If the truncated datetime transitions to a different offset (daylight\n    saving) then the returned value will have that new timezone/offset.\n    \"\"\"\n    start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n    end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n    start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n    end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n    self.create_model(end_datetime, start_datetime)\n\n    melb = pytz.timezone('Australia/Melbourne')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=DateTimeField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(melb), kind, melb)),\n                (end_datetime, truncate_to(end_datetime.astimezone(melb), kind, melb))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_date', kind, output_field=DateField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.date(), kind)),\n                (end_datetime, truncate_to(end_datetime.date(), kind))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_time', kind, output_field=TimeField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.time(), kind)),\n                (end_datetime, truncate_to(end_datetime.time(), kind))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_date_kind('year')\n    test_date_kind('quarter')\n    test_date_kind('month')\n    test_date_kind('week')\n    test_date_kind('day')\n    test_time_kind('hour')\n    test_time_kind"], "sample_516": ["def test_embed_ttf_font_subset():\n    # Test that the font subset is created correctly\n    font = FT2Font(get_glyphs_subset('path/to/font.ttf', 'subset'))\n    assert font.get_char_index(0x20AC) == 0\n    assert font.get_char_index(0x20AC + 1) == 1\n    assert font.get_char_index(0x20AC + 2) == 2\n    assert font.get_char_index(0x20AC + 3) == 3\n    assert font.get_char_index(0x20AC + 4) == 4\n    assert font.get_char_index(0x20AC + 5) == 5\n    assert font.get_char_index(0x20AC + 6) == 6\n    assert font.get_char_index(0x20AC + 7) == 7\n    assert font.get_char_index(0x20AC + 8) == 8\n    assert font.get_char_index(0x20AC + 9) == 9\n    assert font.get_char_index(0x20AC + 10) == 10\n    assert font.get_char_index(0x20AC + 11) == 11\n    assert font.get_char_index(0x20AC + 12) == 12\n    assert font.get_char_index(0x20AC + 13) == 13\n    assert font.get_char_index(0x20AC + 14) == 14\n    assert font.get_char_index(0x20AC + 15) == 15\n    assert font.get_char_index(0x20AC + 16) == 16\n    assert font.get_char_index(0x20AC + 17) == 17\n    assert font.get_char_index(0x20AC + 18) == 18\n    assert font.get_char_index(0x20AC + 19) == 19\n    assert font.get_char_index(0x20AC + 20) == 20\n    assert font.get_char_index(0x20AC + 21) == 21\n    assert font.get_char_index(0x20AC + 22) == 22\n    assert font.get_char_index(0x20AC + 23) == 23\n    assert font.get_char_index(0x20AC + 24) == 24"], "sample_87": ["    def test_iter_modules_and_files_cache(self):\n        filename = self.temporary_file('test_module.py')\n        filename.write_text('import os')\n        with extend_sys_path(str(filename.parent)):\n            self.import_and_cleanup('test_module')\n        self.assertFileFound(filename)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().hits, 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().misses, 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().maxsize, 1)\n        self.clear_autoreload_caches()\n        self.assertFileFound(filename)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().hits, 2)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().misses, 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().maxsize, 1)\n"], "sample_996": ["def test_issue_14321():\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True)\n    p = Product(1 + 1/(n**2 + k**2), (n, 1, oo), (k, 1, oo))\n    assert p.is_convergent() is S.false\n    assert product(1 + 1/(n**2 + k**2), (n, 1, oo), (k, 1, oo)) == p.doit()\n"], "sample_549": ["def test_safe_masked_invalid():\n    a = np.ma.array([1, 2, np.nan, 4, 5])\n    b = cbook.safe_masked_invalid(a)\n    assert_array_equal(b, np.array([1, 2, np.nan, 4, 5]))\n    assert_array_equal(b.mask, np.array([False, False, True, False, False]))\n    assert_array_equal(b.filled(), np.array([1, 2, 0, 4, 5]))\n    assert_array_equal(b.compressed(), np.array([1, 2, 4, 5]))\n\n    a = np.array([1, 2, np.nan, 4, 5])\n    b = cbook.safe_masked_invalid(a)\n    assert_array_equal(b, a)\n    assert_array_equal(b.mask, np.array([False, False, False, False, False]))\n    assert_array_equal(b.filled(), a)\n    assert_array_equal(b.compressed(), a)\n\n    a = np.array([1, 2, np.nan, 4, 5], dtype=np.float32)\n    b = cbook.safe_masked_invalid(a)\n    assert_array_equal(b, a)\n    assert_array_equal(b.mask, np.array([False, False, False, False, False]))\n    assert_array_equal(b.filled(), a)\n    assert_array_equal(b.compressed(), a)\n\n    a = np.array([1, 2, np.nan, 4, 5], dtype=np.float64)\n    b = cbook.safe_masked_invalid(a)\n    assert_array_equal(b, a)\n    assert_array_equal(b.mask, np.array([False, False, False, False, False]))\n    assert_array_equal(b.filled(), a)\n    assert_array_equal(b.compressed(), a)\n\n    a = np.array([1, 2, np.nan, 4, 5], dtype=np.int32)\n    b = cbook.safe_masked_invalid(a)\n    assert_array_equal(b, a)\n    assert_array_equal(b.mask, np.array([False, False, False, False, False]))\n    assert_array_equal(b.filled(), a)\n    assert_array_equal(b.compressed(), a)\n\n    a = np.array([1, 2, np.nan, 4, 5], dtype=np.int64)\n    b = cbook.safe_masked_invalid(a)\n    assert_array_equal(b, a)\n    assert_array_equal(b"], "sample_46": ["    def setUpTestData(cls):\n        cls.objs = [\n            UUIDModel.objects.create(field=uuid.uuid4()),\n            UUIDModel.objects.create(field='2022-01-01'),\n            UUIDModel.objects.create(field='2022-01-02'),\n        ]\n"], "sample_1137": ["def test_quantity_simplify_with_prefixes():\n    u = Quantity(\"u\")\n    u.set_global_relative_scale_factor(kilo, meter)\n\n    assert quantity_simplify(u) == meter\n    assert quantity_simplify(kilo*u) == kilo*meter\n    assert quantity_simplify(kilo*u**2) == kilo*meter**2\n    assert quantity_simplify(kilo*u**-1) == meter/kilo\n    assert quantity_simplify(kilo*u**-2) == 1/(kilo*meter**2)\n\n    u = Quantity(\"u\")\n    u.set_global_relative_scale_factor(micro, meter)\n\n    assert quantity_simplify(u) == meter\n    assert quantity_simplify(micro*u) == micro*meter\n    assert quantity_simplify(micro*u**2) == micro*meter**2\n    assert quantity_simplify(micro*u**-1) == meter/micro\n    assert quantity_simplify(micro*u**-2) == 1/(micro*meter**2)\n\n    u = Quantity(\"u\")\n    u.set_global_relative_scale_factor(milli, meter)\n\n    assert quantity_simplify(u) == meter\n    assert quantity_simplify(milli*u) == milli*meter\n    assert quantity_simplify(milli*u**2) == milli*meter**2\n    assert quantity_simplify(milli*u**-1) == meter/milli\n    assert quantity_simplify(milli*u**-2) == 1/(milli*meter**2)\n"], "sample_900": ["def test_max_fun():\n    # Test max_fun parameter.\n    # It should independently limit the number of iterations for lbfgs.\n    max_fun = 10\n    # classification tests\n    for activation in ACTIVATION_TYPES:\n        mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=50,\n                            max_iter=150, max_fun=max_fun, shuffle=True,\n                            random_state=1, activation=activation)\n        with pytest.warns(ConvergenceWarning):\n            mlp.fit(X_digits_binary[:150], y_digits_binary[:150])\n            assert max_fun >= mlp.n_iter_\n\n    # regression tests\n    for activation in ACTIVATION_TYPES:\n        mlp = MLPRegressor(solver='lbfgs', hidden_layer_sizes=50,\n                           max_iter=150, max_fun=max_fun, shuffle=True,\n                           random_state=1, activation=activation)\n        with pytest.warns(ConvergenceWarning):\n            mlp.fit(Xboston[:150], yboston[:150])\n            assert max_fun >= mlp.n_iter_\n\n    mlp.max_fun = -1\n    assert_raises(ValueError, mlp.fit, X_digits_binary[:150], y_digits_binary[:150])\n"], "sample_1097": ["def test_BlockMatrix_inverse():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, m)\n    C = MatrixSymbol('C', m, n)\n    D = MatrixSymbol('D', m, m)\n    X = BlockMatrix([[A, B], [C, D]])\n    assert block_collapse(X.I) == BlockMatrix([\n        [(-B*D.I*C + A).I, -A.I*B*(D + -C*A.I*B).I],\n        [-(D - C*A.I*B).I*C*A.I, (D - C*A.I*B).I]])\n\n    assert isinstance(X.I, Inverse)\n    assert X.is_square\n    assert not X.is_Identity\n\n    Y = BlockMatrix([[Identity(n), B], [C, D]])\n    assert block_collapse(Y.I) == BlockMatrix([\n        [Identity(n), -B*D.I*C + A],\n        [-C*A.I, (D - C*A.I*B).I]])\n\n    assert isinstance(Y.I, Inverse)\n    assert Y.is_square\n    assert not Y.is_Identity\n\n    Z = BlockMatrix([[Identity(n), B], [ZeroMatrix(m, n), D]])\n    assert block_collapse(Z.I) == BlockMatrix([\n        [Identity(n), -B*D.I],\n        [ZeroMatrix(m, n), D.I]])\n\n    assert isinstance(Z.I, Inverse)\n    assert Z.is_square\n    assert not Z.is_Identity\n"], "sample_162": ["    def test_no_default_ignore_enabled(self):\n        management.call_command('makemessages', locale=[LOCALE], verbosity=0, use_default_ignore_patterns=False)\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertMsgId('This literal should be included.', po_contents)\n            self.assertMsgId('This should be ignored.', po_contents)\n"], "sample_974": ["def test_ccode_For():\n    from sympy.tensor import IndexedBase, Idx\n    from sympy import symbols\n    n = symbols('n', integer=True)\n    i = Idx('i', n)\n    x = IndexedBase('x')\n    y = IndexedBase('y')\n    z = IndexedBase('z')\n    expr = For(i, x[i] + y[i] + z[i])\n    assert ccode(expr) == (\n        'for (int i=0; i<n; i++){\\n'\n        '   x[i] = y[i] + z[i];\\n'\n        '}')\n"], "sample_719": ["def test_hashingvectorizer_dtype():\n    # Non-regression test: HashingVectorizer used to ignore its \"dtype\" param.\n    v = HashingVectorizer(dtype=np.float32)\n    assert_equal(v.dtype, np.float32)\n\n    X = v.fit_transform(['hello world', 'hello hello']).toarray()\n    assert_equal(X.dtype, np.float32)\n    X2 = v.transform(['hello world', 'hello hello']).toarray()\n    assert_equal(X2.dtype, np.float32)\n"], "sample_1183": ["def test_Domain_unify_with_field():\n    F3 = GF(3)\n    F5 = GF(5)\n\n    assert unify(F3, F5) == F5\n    assert unify(F5, F3) == F5\n    assert unify(F3, QQ) == QQ\n    assert unify(QQ, F3) == QQ\n    assert unify(F3, RR) == RR\n    assert unify(RR, F3) == RR\n    assert unify(F3, CC) == CC\n    assert unify(CC, F3) == CC\n    assert unify(F3, ZZ[x]) == ZZ[x]\n    assert unify(ZZ[x], F3) == ZZ[x]\n    assert unify(F3, ZZ.frac_field(x)) == ZZ.frac_field(x)\n    assert unify(ZZ.frac_field(x), F3) == ZZ.frac_field(x)\n    assert unify(F3, EX) == EX\n    assert unify(EX, F3) == EX\n\n    assert unify(QQ, F3) == QQ\n    assert unify(F3, QQ) == QQ\n    assert unify(QQ, RR) == RR\n    assert unify(RR, QQ) == RR\n    assert unify(QQ, CC) == CC\n    assert unify(CC, QQ) == CC\n    assert unify(QQ, ZZ[x]) == QQ[x]\n    assert unify(ZZ[x], QQ) == QQ[x]\n    assert unify(QQ, ZZ.frac_field(x)) == QQ.frac_field(x)\n    assert unify(ZZ.frac_field(x), QQ) == QQ.frac_field(x)\n    assert unify(QQ, EX) == EX\n    assert unify(EX, QQ) == EX\n\n    assert unify(RR, F3) == RR\n    assert unify(F3, RR) == RR\n    assert unify(RR, CC) == CC\n    assert unify(CC, RR) == CC\n    assert unify(RR, ZZ[x]) == RR[x]\n    assert unify(ZZ[x], RR) == RR[x]\n    assert unify(RR, ZZ.frac_field(x)) == RR.frac_field(x)\n    assert unify(ZZ.frac_field(x), RR) == RR.frac_field(x)\n    assert unify(RR, EX) == EX\n    assert unify(EX, RR) == EX\n\n    assert unify(CC, F3) == CC\n    assert unify(F3, CC) == CC\n"], "sample_579": ["    def test_clustermap_annotation_with_limited_ticklabels(self):\n        kws = self.default_kws.copy()\n        kws[\"xticklabels\"] = False\n        kws[\"yticklabels\"] = False\n        g = mat.clustermap(self.df_norm, annot=True, fmt=\".2f\", **kws)\n        for val, text in zip(np.asarray(g.data2d).flat, g.ax_heatmap.texts):\n            assert text.get_text() == f\"{val:.2f}\"\n"], "sample_493": ["def test_aggregate_subquery_annotation_values_list(self):\n    \"\"\"\n    Subquery annotations and external aliases are excluded from the GROUP BY if\n    they are not selected.\n    \"\"\"\n    books_qs = (\n        Book.objects.annotate(\n            first_author_the_same_age=Subquery(\n                Author.objects.filter(\n                    age=OuterRef(\"contact__friends__age\"),\n                )\n                .order_by(\"age\")\n                .values(\"id\")[:1],\n            )\n        )\n        .filter(\n            publisher=self.p1,\n            first_author_the_same_age__isnull=False,\n        )\n        .annotate(\n            min_age=Min(\"contact__friends__age\"),\n        )\n        .values(\"name\", \"min_age\")\n        .order_by(\"name\")\n    )\n    self.assertEqual(\n        list(books_qs),\n        [\n            {\"name\": \"Practical Django Projects\", \"min_age\": 34},\n            {\n                \"name\": (\n                    \"The Definitive Guide to Django: Web Development Done Right\"\n                ),\n                \"min_age\": 29,\n            },\n        ],\n    )\n\n    books_qs = (\n        Book.objects.annotate(\n            first_author_the_same_age=Subquery(\n                Author.objects.filter(\n                    age=OuterRef(\"contact__friends__age\"),\n                )\n                .order_by(\"age\")\n                .values(\"id\")[:1],\n            )\n        )\n        .filter(\n            publisher=self.p1,\n            first_author_the_same_age__isnull=False,\n        )\n        .annotate(\n            min_age=Min(\"contact__friends__age\"),\n        )\n        .values_list(\"name\", \"min_age\")\n        .order_by(\"name\")\n    )\n    self.assertEqual(\n        list(books_qs),\n        [\n            (\"Practical Django Projects\", 34),\n            (\n                \"The Definitive Guide to Django: Web Development Done Right\",\n                29,\n            ),\n        ],\n    )\n\n    books_qs = (\n        Book.objects.annotate(\n            first_author_the_same_age=Subquery(\n                Author.objects.filter(\n                    age=OuterRef(\"contact__friends__age\"),\n                )\n                .order_by(\"age\")\n                .values(\"id\")[:1],\n            )\n        )\n        .filter(\n            publisher=self.p1,\n            first_author_the_same_age__isnull=False,\n        )\n        .annotate(\n            min_age=Min(\"contact__friends__age\"),\n        )\n        .values_list(\"name\", flat=True)\n        .order_by(\"name\")\n   "], "sample_1208": ["def test_MatrixStudentT_sample():\n    M = MatrixStudentT('M', 2, [[5, 6]], [[2, 1], [1, 2]], [4])\n    size = 5\n    samps = sample(M, size=size, library='scipy')\n    for sam in samps:\n        assert Matrix(sam) in M.pspace.distribution.set\n    M = MatrixStudentT('M', 2, [[5, 6]], [[2, 1], [1, 2]], [4])\n    samps = sample(M, size=size, library='numpy')\n    for sam in samps:\n        assert Matrix(sam) in M.pspace.distribution.set\n    M = MatrixStudentT('M', 2, [[5, 6]], [[2, 1], [1, 2]], [4])\n    samps = sample(M, size=size, library='pymc')\n    for sam in samps:\n        assert Matrix(sam) in M.pspace.distribution.set\n    M = MatrixStudentT('M', 2, [[5, 6]], [[2, 1], [1, 2]], [4])\n    raises(NotImplementedError, lambda: sample(M, size=3, library='scipy'))\n    M = MatrixStudentT('M', 2, [[5, 6]], [[2, 1], [1, 2]], [4])\n    raises(NotImplementedError, lambda: sample(M, size=3, library='numpy'))\n    M = MatrixStudentT('M', 2, [[5, 6]], [[2, 1], [1, 2]], [4])\n    raises(NotImplementedError, lambda: sample(M, size=3, library='pymc'))\n"], "sample_61": ["    def test_validate(self):\n        valid_usernames = ['joe', 'Ren\u00e9', '\u1d2e\u1d35\u1d33\u1d2e\u1d35\u1d3f\u1d30', '\u0623\u062d\u0645\u062f']\n        invalid_usernames = [\n            \"o'connell\", \"\u0639\u0628\u062f \u0627\u0644\",\n            \"zerowidth\\u200Bspace\", \"nonbreaking\\u00A0space\",\n            \"en\\u2013dash\", 'trailingnewline\\u000A',\n        ]\n        v = validators.ASCIIUsernameValidator()\n        for valid in valid_usernames:\n            with self.subTest(valid=valid):\n                v(valid)\n        for invalid in invalid_usernames:\n            with self.subTest(invalid=invalid):\n                with self.assertRaises(ValidationError):\n                    v(invalid)\n"], "sample_185": ["    def setUp(self):\n        super().setUp()\n        self.n = decimal.Decimal('66666.666')\n        self.f = 99999.999\n        self.d = datetime.date(2009, 12, 31)\n        self.dt = datetime.datetime(2009, 12, 31, 20, 50)\n        self.t = datetime.time(10, 15, 48)\n        self.long = 10000\n        self.ctxt = Context({\n            'n': self.n,\n            't': self.t,\n            'd': self.d,\n            'dt': self.dt,\n            'f': self.f,\n            'l': self.long,\n        })\n"], "sample_703": ["def test_invalid_idents() -> None:\n    \"\"\"Test that invalid identifiers raise a ParseError.\"\"\"\n    invalid_idents = (\n        \"1\",\n        \"123\",\n        \"123abc\",\n        \"abc123\",\n        \"abc123def\",\n        \"abc123and\",\n        \"notand\",\n        \"not_and\",\n        \"not[and\",\n        \"not]and\",\n        \"not+and\",\n        \"not-and\",\n        \"not and\",\n        \"not and or\",\n        \"not and(or\",\n        \"not and)or\",\n        \"not and or)\",\n        \"not and (or\",\n        \"not and (or)\",\n        \"not and (or)or\",\n        \"not and (or)and\",\n        \"not and (or)andor\",\n        \"not and (or)and(or\",\n        \"not and (or)and(or)\",\n        \"not and (or)and(or)or\",\n        \"not and (or)and(or)and\",\n        \"not and (or)and(or)andor\",\n        \"not and (or)and(or)and(or\",\n        \"not and (or)and(or)and(or)\",\n        \"not and (or)and(or)and(or)or\",\n        \"not and (or)and(or)and(or)and\",\n        \"not and (or)and(or)and(or)andor\",\n        \"not and (or)and(or)and(or)and(or\",\n        \"not and (or)and(or)and(or)and(or)\",\n        \"not and (or)and(or)and(or)and(or)or\",\n        \"not and (or)and(or)and(or)and(or)and\",\n        \"not and (or)and(or)and(or)and(or)andor\",\n        \"not and (or)and(or)and(or)and(or)and(or\",\n        \"not and (or)and(or)and(or)and(or)and(or)\",\n        \"not and (or)and(or)and(or)and(or)and(or)or\",\n        \"not and (or)and(or)and(or)and(or)and(or)and\",\n        \"not and (or)and(or)and(or)and(or)and(or)andor\",\n        \"not and (or)and(or)and(or)and(or)and(or)and(or\",\n        \"not and (or)and"], "sample_772": ["def check_max_depth(name):\n    # Test if max_depth is respected.\n    X, y = hastie_X, hastie_y\n    ForestEstimator = FOREST_ESTIMATORS[name]\n\n    # test boundary value\n    assert_raises(ValueError, ForestEstimator(max_depth=-1).fit, X, y)\n    assert_raises(ValueError, ForestEstimator(max_depth=0).fit, X, y)\n\n    est = ForestEstimator(max_depth=2, n_estimators=1, random_state=0)\n    est.fit(X, y)\n    assert_equal(est.estimators_[0].get_depth(), 2)\n\n    est = ForestEstimator(max_depth=1, n_estimators=1, random_state=0)\n    est.fit(X, y)\n    assert_equal(est.estimators_[0].get_depth(), 1)\n\n"], "sample_619": ["def test_decode_cf_datetime_uint64_with_cftime_overflow_warning():\n    units = \"days since 1700-01-01\"\n    num_dates = np.uint64(182621)\n    with pytest.warns(UserWarning):\n        result = decode_cf_datetime(num_dates, units)\n    expected = np.asarray(np.datetime64(\"2200-01-01\", \"ns\"))\n    np.testing.assert_equal(result, expected)\n"], "sample_966": ["def test_pydata_with_union_type_operator_old(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :annotation: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0],\n                ([desc_name, \"version\"],\n                 [desc_annotation, ([desc_sig_punctuation, ':'],\n                                    desc_sig_space,\n                                    [pending_xref, \"int\"],\n                                    desc_sig_space,\n                                    [desc_sig_punctuation, \"|\"],\n                                    desc_sig_space,\n                                    [pending_xref, \"str\"])]))\n"], "sample_199": ["def test_combined_expression_annotation_with_subquery(self):\n    \"\"\"\n    Test that a combined expression annotation can reference a subquery.\n    \"\"\"\n    long_books_qs = Book.objects.filter(\n        publisher=OuterRef('pk'),\n        pages__gt=400,\n    ).values('publisher').annotate(count=Count('pk')).values('count')\n    publisher_books_qs = Publisher.objects.annotate(\n        total_books=Count('book'),\n        combined=ExpressionWrapper(F('num_awards') + Subquery(long_books_qs, output_field=IntegerField()), output_field=IntegerField()),\n    ).filter(\n        total_books=Subquery(long_books_qs, output_field=IntegerField()),\n    ).values('name')\n    self.assertCountEqual(publisher_books_qs, [{'name': 'Sams'}, {'name': 'Morgan Kaufmann'}])\n"], "sample_783": ["def test_imputation_most_frequent_error_invalid_type():\n    # Test imputation using the most-frequent strategy with invalid type\n    X = np.array([\n        [-1, -1, 0, 5],\n        [-1, 2, -1, 3],\n        [-1, 1, 3, -1],\n        [-1, 2, 3, 7],\n    ])\n\n    with pytest.raises(ValueError, match=\"non-numeric data\"):\n        imputer = SimpleImputer(strategy=\"most_frequent\")\n        imputer.fit(X.astype(object))\n"], "sample_382": ["def test_template_changed_with_filesystem_loader(self):\n    template_path = Path(__file__).parent / 'templates' / 'index.html'\n    self.assertTrue(autoreload.template_changed(None, template_path))\n    mock_reset = mock.patch('django.template.autoreload.reset_loaders')\n    mock_reset.assert_called_once()\n"], "sample_983": ["def test_LDLdecomposition():\n    A = SparseMatrix(((25, 15, -5), (15, 18, 0), (-5, 0, 11)))\n    L, D = A.LDLdecomposition()\n    assert L.is_lower\n    assert D.is_diagonal\n    assert (L*D*L.T) == A\n    assert L.rows == A.rows\n    assert L.cols == A.cols\n    assert D.rows == A.rows\n    assert D.cols == A.cols\n"], "sample_1022": ["def test_repeated_decimals():\n    cases = {\n        '0.2[1]': sympy.Rational(19, 90),\n        '0.3[1]': sympy.Rational(1, 3),\n        '0.4[1]': sympy.Rational(4, 9),\n        '0.5[1]': sympy.Rational(5, 9),\n        '0.6[1]': sympy.Rational(6, 9),\n        '0.7[1]': sympy.Rational(7, 9),\n        '0.8[1]': sympy.Rational(8, 9),\n        '0.9[1]': sympy.Rational(9, 9),\n        '0.1[1]': sympy.Rational(1, 9),\n        '0.2[2]': sympy.Rational(29, 90),\n        '0.3[2]': sympy.Rational(1, 3),\n        '0.4[2]': sympy.Rational(4, 9),\n        '0.5[2]': sympy.Rational(5, 9),\n        '0.6[2]': sympy.Rational(6, 9),\n        '0.7[2]': sympy.Rational(7, 9),\n        '0.8[2]': sympy.Rational(8, 9),\n        '0.9[2]': sympy.Rational(9, 9),\n        '0.1[2]': sympy.Rational(1, 9),\n        '0.2[3]': sympy.Rational(19, 90),\n        '0.3[3]': sympy.Rational(1, 3),\n        '0.4[3]': sympy.Rational(4, 9),\n        '0.5[3]': sympy.Rational(5, 9),\n        '0.6[3]': sympy.Rational(6, 9),\n        '0.7[3]': sympy.Rational(7, 9),\n        '0.8[3]': sympy.Rational(8, 9),\n        '0.9[3]': sympy.Rational(9, 9),\n        '0."], "sample_47": ["    def test_sensitive_variables_decorator(self):\n        \"\"\"\n        The sensitive_variables decorator works with functions.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(sensitive_variables_wrapper)\n            self.verify_unsafe_email(sensitive_variables_wrapper)\n\n        with self.settings(DEBUG=False):\n            self.verify_safe_response(sensitive_variables_wrapper)\n            self.verify_safe_email(sensitive_variables_wrapper)\n"], "sample_662": ["    def test_repr_locals_serialization(self, testdir):\n        \"\"\"Check serialization/deserialization of report objects containing locals.\"\"\"\n        reprec = testdir.inline_runsource(\n            \"\"\"\n                x = 0\n                assert x\n            \"\"\",\n            \"--showlocals\",\n        )\n        reports = reprec.getreports(\"pytest_runtest_logreport\")\n        assert len(reports) == 3\n        rep = reports[1]\n        d = rep._to_json()\n        a = TestReport._from_json(d)\n\n        rep_entries = rep.longrepr.reprtraceback.reprentries\n        a_entries = a.longrepr.reprtraceback.reprentries\n        for i in range(len(a_entries)):\n            assert isinstance(rep_entries[i], ReprEntry)\n            assert rep_entries[i].lines == a_entries[i].lines\n            assert rep_entries[i].reprfileloc.lineno == a_entries[i].reprfileloc.lineno\n            assert (\n                rep_entries[i].reprfileloc.message == a_entries[i].reprfileloc.message\n            )\n            assert rep_entries[i].reprfileloc.path == a_entries[i].reprfileloc.path\n            assert rep_entries[i].reprfuncargs.args == a_entries[i].reprfuncargs.args\n            assert rep_entries[i].reprlocals.lines == a_entries[i].reprlocals.lines\n            assert rep_entries[i].style == a_entries[i].style\n            assert rep_entries[i].reprlocals.locals == a_entries[i].reprlocals.locals\n"], "sample_444": ["    def test_manifest_hash(self):\n        # Collect the additional file.\n        self.run_collectstatic()\n\n        _, manifest_hash_orig = storage.staticfiles_storage.load_manifest()\n        self.assertEqual(manifest_hash_orig, \"\")\n\n        # Saving doesn't change the hash.\n        storage.staticfiles_storage.save_manifest()\n        self.assertEqual(storage.staticfiles_storage.manifest_hash, \"\")\n\n        # Delete the original file from the app, collect with clear.\n        os.unlink(self._clear_filename)\n        self.run_collectstatic(clear=True)\n\n        # Hash is not changed.\n        _, manifest_hash = storage.staticfiles_storage.load_manifest()\n        self.assertEqual(manifest_hash, \"\")\n"], "sample_178": ["    def test_formset_with_ordering_and_deletion_and_min_num(self):\n        \"\"\"\n        FormSets with ordering, deletion, and min_num.\n        \"\"\"\n        ChoiceFormSet = formset_factory(Choice, can_order=True, can_delete=True, min_num=2)\n        initial = [\n            {'choice': 'Calexico', 'votes': 100},\n            {'choice': 'Fergie', 'votes': 900},\n        ]\n        formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n        self.assertHTMLEqual(\n            '\\n'.join(form.as_ul() for form in formset.forms),\n            \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_259": ["def test_prefetch_object_with_filter(self):\n    book1 = Book.objects.get(id=self.book1.id)\n    with self.assertNumQueries(1):\n        prefetch_related_objects([book1], Prefetch('authors__name__startswith', queryset=Author.objects.filter(name__startswith='A')))\n\n    with self.assertNumQueries(0):\n        self.assertCountEqual(book1.authors.all(), [self.author1, self.author2])\n"], "sample_761": ["def test_iterative_imputer_max_iter_zero():\n    # Test imputation with max_iter=0\n    rng = np.random.RandomState(0)\n\n    n = 100\n    d = 10\n    X = sparse_random_matrix(n, d, density=0.10, random_state=rng).toarray()\n    X[:, 0] = 1  # definitely no missing values in 0th column\n    X[0, 0] = 0  # definitely missing value in 0th column\n\n    imputer = IterativeImputer(max_iter=0, random_state=rng)\n    imputer.fit(X)\n    X_imputed = imputer.transform(X)\n    assert_allclose(X_imputed, imputer.initial_imputer_.transform(X))\n"], "sample_247": ["    def setUpTestData(cls):\n        cls.a1 = Author.objects.create(name='Adrian Holovaty', age=34)\n        cls.a2 = Author.objects.create(name='Jacob Kaplan-Moss', age=35)\n        cls.a3 = Author.objects.create(name='James Bennett', age=34)\n        cls.a4 = Author.objects.create(name='Peter Norvig', age=57)\n        cls.a5 = Author.objects.create(name='Stuart Russell', age=46)\n        p1 = Publisher.objects.create(name='Apress', num_awards=3)\n\n        cls.b1 = Book.objects.create(\n            isbn='159059725', pages=447, rating=4.5, price=Decimal('30.00'),\n            contact=cls.a1, publisher=p1, pubdate=datetime.date(2007, 12, 6),\n            name='The Definitive Guide to Django: Web Development Done Right',\n        )\n        cls.b2 = Book.objects.create(\n            isbn='159059996', pages=300, rating=4.0, price=Decimal('29.69'),\n            contact=cls.a3, publisher=p1, pubdate=datetime.date(2008, 6, 23),\n            name='Practical Django Projects',\n        )\n        cls.b3 = Book.objects.create(\n            isbn='013790395', pages=1132, rating=4.0, price=Decimal('82.80'),\n            contact=cls.a4, publisher=p1, pubdate=datetime.date(1995, 1, 15),\n            name='Artificial Intelligence: A Modern Approach',\n        )\n        cls.b4 = Book.objects.create(\n            isbn='155860191', pages=946, rating=5.0, price=Decimal('75.00'),\n            contact=cls.a4, publisher=p1, pubdate=datetime.date(1991, 10, 15),\n            name='Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp',\n        )\n        cls.b1.authors.add(cls.a1, cls.a2)\n        cls.b2.authors.add(cls.a3)\n        cls.b3.authors.add(cls.a4, cls.a5)\n        cls.b4.authors.add(cls.a4)\n\n        Store.objects.create(\n            name='Amazon.com',\n            original_opening=datetime.datetime(1994, 4, 23, 9, 17,"], "sample_884": ["def test_deprecated_class_inheritance():\n    # Test if the deprecation warning is propagated when a deprecated class is inherited\n    with pytest.warns(FutureWarning, match=\"qwerty\"):\n        MockClass5(42)\n    # Test if the deprecation warning is propagated when a deprecated class is instantiated\n    with pytest.warns(FutureWarning, match=\"qwerty\"):\n        MockClass5.__new__(MockClass1)\n"], "sample_1165": ["def test_quaternion_addition():\n    q1 = Quaternion(1, 2, 3, 4)\n    q2 = Quaternion(5, 6, 7, 8)\n    q3 = Quaternion(9, 10, 11, 12)\n\n    assert q1 + q2 == Quaternion(6, 8, 10, 12)\n    assert q1 + q3 == Quaternion(10, 12, 14, 16)\n    assert q2 + q3 == Quaternion(14, 16, 18, 20)\n\n    q4 = Quaternion(1, 2, 3, 4, real_field=False)\n    q5 = Quaternion(5, 6, 7, 8, real_field=False)\n    q6 = Quaternion(9, 10, 11, 12, real_field=False)\n\n    assert q4 + q5 == Quaternion(6 + 5*I, 8 + 6*I, 10 + 7*I, 12 + 8*I)\n    assert q4 + q6 == Quaternion(10 + 9*I, 12 + 10*I, 14 + 11*I, 16 + 12*I)\n    assert q5 + q6 == Quaternion(14 + 9*I, 16 + 10*I, 18 + 11*I, 20 + 12*I)\n\n    q7 = Quaternion(1, 2, 3, 4)\n    q8 = Quaternion(5, 6, 7, 8)\n    q9 = Quaternion(9, 10, 11, 12)\n\n    assert q7 + q8 + q9 == Quaternion(15, 18, 21, 24)\n    assert q8 + q9 + q7 == Quaternion(15, 18, 21, 24)\n    assert q9 + q7 + q8 == Quaternion(15, 18, 21, 24)\n\n    q10 = Quaternion(1, 2, 3, 4, real_field=False)\n    q11 = Quaternion(5, 6, 7, 8, real_field=False)\n    q12 = Quaternion(9, 10, 11, 12, real_field=False)\n\n    assert q10 + q11 + q12 == Quaternion(15 + 9*I, 18 + 10*I, 21"], "sample_836": ["def test_class_distribution_sparse_with_zero_class():\n    y = np.array([[1, 0, 0, 1],\n                  [2, 2, 0, 1],\n                  [1, 3, 0, 1],\n                  [4, 2, 0, 1],\n                  [2, 0, 0, 1],\n                  [1, 3, 0, 1]])\n    # Define the sparse matrix with a mix of implicit and explicit zeros\n    data = np.array([1, 2, 1, 4, 2, 1, 0, 2, 3, 2, 3, 1, 1, 1, 1, 1, 1])\n    indices = np.array([0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 5, 0, 1, 2, 3, 4, 5])\n    indptr = np.array([0, 6, 11, 11, 17])\n    y_sp = sp.csc_matrix((data, indices, indptr), shape=(6, 4))\n\n    classes, n_classes, class_prior = class_distribution(y)\n    classes_sp, n_classes_sp, class_prior_sp = class_distribution(y_sp)\n    classes_expected = [[1, 2, 4],\n                        [0, 2, 3],\n                        [0],\n                        [1]]\n    n_classes_expected = [3, 3, 1, 1]\n    class_prior_expected = [[3/6, 2/6, 1/6],\n                            [1/3, 1/3, 1/3],\n                            [1.0],\n                            [1.0]]\n\n    # Test that the class distribution is correct when there is a zero class\n    # in the sparse matrix\n    assert_array_almost_equal(classes[0], classes_expected[0])\n    assert_array_almost_equal(n_classes[0], n_classes_expected[0])\n    assert_array_almost_equal(class_prior[0], class_prior_expected[0])\n\n    assert_array_almost_equal(classes_sp[0], classes_expected[0])\n    assert_array_almost_equal(n_classes_sp[0], n_classes_expected[0])\n    assert_array_almost_equal(class_prior_sp[0], class_prior_expected[0])\n\n    # Test"], "sample_755": ["def test_davies_bouldin_score():\n    # Assert Davies-Bouldin score is 0 when all points are in the same cluster\n    assert 0. == davies_bouldin_score(np.ones((10, 2)), [0] * 10)\n\n    # Assert Davies-Bouldin score is 0 when all points are in different clusters\n    assert 0. == davies_bouldin_score([[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5,\n                                       [0] * 10 + [1] * 10)\n\n    # Assert Davies-Bouldin score is 0 when all clusters have the same centroid\n    assert 0. == davies_bouldin_score([[-1, -1], [1, 1]] * 10,\n                                       [0] * 10 + [1] * 10)\n\n    # Assert Davies-Bouldin score is not 0 when clusters have different centroids\n    X = [[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5\n    labels = [0] * 10 + [1] * 10\n    pytest.approx(0.5, davies_bouldin_score(X, labels))\n\n    # Test with non-numpy arrays\n    X = [[0, 0], [1, 1]] * 5 + [[3, 3], [4, 4]] * 5\n    labels = [0] * 10 + [1] * 10\n    pytest.approx(0.5, davies_bouldin_score(X, labels))\n\n    # Test with non-encoded labels\n    dataset = datasets.load_iris()\n    X = dataset.data\n    labels = dataset.target\n    pytest.approx(0.5, davies_bouldin_score(X, labels * 2 + 10))\n\n    # Test with non-numpy labels\n    dataset = datasets.load_iris()\n    X = dataset.data\n    y = dataset.target\n    pytest.approx(0.5, davies_bouldin_score(list(X), list(y)))\n"], "sample_219": ["    def setUpTestData(cls):\n        cls.e1 = Experiment.objects.create(\n            name='e1', assigned=datetime.date(2010, 6, 25),\n            start=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000),\n            end=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000),\n            completed=datetime.date(2010, 6, 25),\n            estimated_time=datetime.timedelta(0),\n        )\n        cls.e2 = Experiment.objects.create(\n            name='e2', assigned=datetime.date(2010, 6, 25),\n            start=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000),\n            end=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000),\n            completed=datetime.date(2010, 6, 25),\n            estimated_time=datetime.timedelta(0),\n        )\n        cls.e3 = Experiment.objects.create(\n            name='e3', assigned=datetime.date(2010, 6, 25),\n            start=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000),\n            end=datetime.datetime(2010, 6, 25, 12, 15, 30, 747000),\n            completed=datetime.date(2010, 6, 25),\n            estimated_time=datetime.timedelta(0),\n        )\n"], "sample_1023": ["def test_totient():\n    from sympy.ntheory.generate import sieve\n    sieve._reset()\n    assert totient(1) == 1\n    assert totient(2) == 1\n    assert totient(3) == 2\n    assert totient(4) == 2\n    assert totient(5) == 4\n    assert totient(6) == 2\n    assert totient(7) == 6\n    assert totient(8) == 4\n    assert totient(9) == 6\n    assert totient(10) == 4\n    assert totient(11) == 10\n    assert totient(12) == 4\n    assert totient(13) == 12\n    assert totient(14) == 6\n    assert totient(15) == 8\n    assert totient(16) == 8\n    assert totient(17) == 16\n    assert totient(18) == 6\n    assert totient(19) == 18\n    assert totient(20) == 8\n    assert totient(21) == 12\n    assert totient(22) == 10\n    assert totient(23) == 22\n    assert totient(24) == 8\n    assert totient(25) == 20\n    assert totient(26) == 12\n    assert totient(27) == 18\n    assert totient(28) == 12\n    assert totient(29) == 28\n    assert totient(30) == 8\n    assert totient(31) == 30\n    assert totient(32) == 16\n    assert totient(33) == 20\n    assert totient(34) == 12\n    assert totient(35) == 24\n    assert totient(36) == 12\n    assert totient(37) == 36\n    assert totient(38) == 18\n    assert totient(39) == 24\n    assert totient(40) == 16\n    assert totient(41) == 40\n    assert totient(42) == 12\n    assert totient(43) == 42\n    assert totient(44) == 20\n    assert totient("], "sample_991": ["def test_issue_12345():\n    n = Symbol('n', integer=True)\n    k = Symbol('k', integer=True)\n    p = Product(1 + 1/(n**2 + k**2), (n, 1, oo), (k, 1, oo))\n    assert p.is_convergent() is S.false\n    assert product(1 + 1/(n**2 + k**2), (n, 1, oo), (k, 1, oo)) == p.doit()\n"], "sample_589": ["def test_interpolate_na_max_gap():\n    da = xr.DataArray(\n        [np.nan, 1, 2, np.nan, np.nan, 5, np.nan, np.nan, np.nan, np.nan, 10],\n        dims=[\"t\"],\n    )\n    da[\"t\"] = pd.date_range(\"2001-01-01\", freq=\"H\", periods=11)\n    actual = da.interpolate_na(\"t\", max_gap=3)\n    expected = xr.DataArray(\n        [np.nan, 1, 2, 3, 4, 5, np.nan, np.nan, np.nan, np.nan, 10],\n        dims=[\"t\"],\n    )\n    assert_array_equal(actual, expected)\n"], "sample_56": ["def test_prepopulated_fields(self):\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {'slug': ('title',)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n"], "sample_393": ["    def test_no_default_ignore(self):\n        management.call_command(\n            \"makemessages\", locale=[LOCALE], verbosity=0, no_default_ignore=True\n        )\n        self.assertTrue(os.path.exists(self.PO_FILE))\n        with open(self.PO_FILE) as fp:\n            po_contents = fp.read()\n            self.assertMsgId(\"This literal should be included.\", po_contents)\n            self.assertMsgId(\"This should be ignored.\", po_contents)\n"], "sample_1196": ["def test_contains_eval():\n    x = Symbol('x')\n    assert Contains(x, S.Integers).eval() is S.true\n    assert Contains(x, S.Naturals).eval() is S.false\n    assert Contains(x, S.Reals).eval() is S.true\n    assert Contains(x, S.Complexes).eval() is S.true\n    assert Contains(x, S.Naturals0).eval() is S.false\n"], "sample_170": ["    def test_non_sensitive_request(self):\n        \"\"\"\n        Request info can bee seen in the default error reports for\n        non-sensitive requests.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n\n        with self.settings(DEBUG=False):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n"], "sample_893": ["def test_export_text_class_names_bool_support():\n    # Check that export_text treats class names correctly and supports bool\n    clf = DecisionTreeClassifier(max_depth=2, random_state=0)\n    clf.fit(X, y)\n\n    expected_report = dedent(\"\"\"\n    |--- feature_1 <= 0.00\n    |   |--- class: -1\n    |--- feature_1 >  0.00\n    |   |--- class: 1\n    \"\"\").lstrip()\n    assert export_text(clf, class_names=True) == expected_report\n\n    expected_report = dedent(\"\"\"\n    |--- feature_1 <= 0.00\n    |   |--- class: -1\n    |--- feature_1 >  0.00\n    |   |--- class: 1\n    \"\"\").lstrip()\n    assert export_text(clf, class_names=False) == expected_report\n"], "sample_24": ["    def setup_class(self):\n        self.a = np.array([1, 2, 3, 4, 5])\n        self.mask_a = np.array([True, False, False, False, False])\n        self.ma = Masked(self.a, mask=self.mask_a)\n        self.b = np.array([1, 2, 3, 4, 5])\n        self.mask_b = np.array([False, False, False, False, False])\n        self.mb = Masked(self.b, mask=self.mask_b)\n"], "sample_1095": ["def test_inversion_vector():\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    assert p.inversion_vector() == [0, 0, 0, 0, 0, 0]\n    p = Permutation([3, 2, 1, 0])\n    assert p.inversion_vector() == [3, 2, 1]\n    p = Permutation([0, 2, 1, 3, 4, 5])\n    assert p.inversion_vector() == [1, 0, 0, 0, 0, 0]\n    p = Permutation([0, 4, 1, 3, 2])\n    assert p.inversion_vector() == [1, 0, 0, 1, 0]\n    p = Permutation([0, 1, 4, 3, 2])\n    assert p.inversion_vector() == [1, 0, 1, 1, 0]\n    p = Permutation([0, 1, 2, 3, 4])\n    assert p.inversion_vector() == [0, 0, 0, 0, 0]\n    p = Permutation([0, 1, 2, 4, 3])\n    assert p.inversion_vector() == [0, 0, 0, 1, 0]\n    p = Permutation([0, 1, 3, 2, 4])\n    assert p.inversion_vector() == [0, 0, 1, 0, 0]\n    p = Permutation([0, 2, 1, 3, 4])\n    assert p.inversion_vector() == [1, 0, 0, 0, 0]\n    p = Permutation([0, 2, 3, 1, 4])\n    assert p.inversion_vector() == [1, 0, 1, 0, 0]\n    p = Permutation([0, 2, 4, 1, 3])\n    assert p.inversion_vector() == [1, 0, 1, 0, 0]\n    p = Permutation([0, 3, 1, 2, 4])\n    assert p.inversion_vector()"], "sample_306": ["    def test_iso8601_duration(self):\n        test_values = (\n            ('P4DT15H30M', timedelta(days=4, hours=15, minutes=30)),\n            ('P4DT15H30M30S', timedelta(days=4, hours=15, minutes=30, seconds=30)),\n            ('P4DT15H30M30.1S', timedelta(days=4, hours=15, minutes=30, milliseconds=100)),\n            ('P4DT15H30M30.01S', timedelta(days=4, hours=15, minutes=30, milliseconds=10)),\n            ('P4DT15H30M30.001S', timedelta(days=4, hours=15, minutes=30, milliseconds=1)),\n            ('P4DT15H30M30.0001S', timedelta(days=4, hours=15, minutes=30, microseconds=100)),\n            ('P4DT15H30M30.00001S', timedelta(days=4, hours=15, minutes=30, microseconds=10)),\n            ('P4DT15H30M30.000001S', timedelta(days=4, hours=15, minutes=30, microseconds=1)),\n            ('P4DT15H30M30,000001S', timedelta(days=4, hours=15, minutes=30, microseconds=1)),\n            ('P-4DT15H30M', timedelta(days=-4, hours=15, minutes=30)),\n            ('P-4DT15H30M30S', timedelta(days=-4, hours=15, minutes=30, seconds=30)),\n            ('P-4DT15H30M30.1S', timedelta(days=-4, hours=15, minutes=30, milliseconds=100)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_706": ["def test_invalid_idents() -> None:\n    \"\"\"Test that invalid identifiers raise a ParseError.\"\"\"\n    invalid_idents = (\n        \"1\",\n        \"1a\",\n        \"a1\",\n        \"a1b\",\n        \"a.b\",\n        \"a.b.c\",\n        \"a.b.c.d\",\n        \"a.b.c.d.e\",\n        \"a.b.c.d.e.f\",\n        \"a.b.c.d.e.f.g\",\n        \"a.b.c.d.e.f.g.h\",\n        \"a.b.c.d.e.f.g.h.i\",\n        \"a.b.c.d.e.f.g.h.i.j\",\n        \"a.b.c.d.e.f.g.h.i.j.k\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l.m\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l.m.n\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l.m.n.o\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l.m.n.o.p\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l.m.n.o.p.q\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l.m.n.o.p.q.r\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l.m.n.o.p.q.r.s\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l.m.n.o.p.q.r.s.t\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l.m.n.o.p.q.r.s.t.u\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l.m.n.o.p.q.r.s.t.u.v\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l.m.n.o.p.q.r.s.t.u.v.w\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l.m.n.o.p.q.r.s.t.u.v.w.x\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l.m.n.o.p.q.r.s.t.u.v.w.x.y\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l.m.n.o.p.q.r.s.t.u.v.w.x.y.z\",\n        \"a.b.c.d.e.f.g.h.i.j.k.l.m.n.o.p.q.r.s.t.u.v.w.x.y.z.a\",\n        \"a.b.c.d.e.f"], "sample_769": ["def test_balanced_accuracy_score_adjusted():\n    # Test balanced accuracy score with adjusted option\n    y_true = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n    y_pred = [0, 1, 2, 0, 1, 2, 0, 1, 2]\n\n    # compute balanced accuracy score with default adjusted=False\n    score = balanced_accuracy_score(y_true, y_pred)\n    assert_almost_equal(score, 0.33, 2)\n\n    # compute balanced accuracy score with adjusted=True\n    score = balanced_accuracy_score(y_true, y_pred, adjusted=True)\n    assert_almost_equal(score, 0.0, 2)\n"], "sample_187": ["def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123'), 'hello world123')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc'), 'hello world123abc')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456'), 'hello world123abc456')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456def'), 'hello world123abc456def')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghi'), 'hello world123abc456defghi')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghij'), 'hello world123abc456defghij')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijk'), 'hello world123abc456defghijk')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijkl'), 'hello world123abc456defghijkl')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklm'), 'hello world123abc456defghijklm')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmn'), 'hello world123abc456defghijklmn')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmno'), 'hello world123abc456defghijklmno')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnop'), 'hello world123abc456defghijklmnop')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnoP'), 'hello world123abc456defghijklmno p')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnopqrstuvwxyz'), 'hello world123abc456defghijklmnopqrstuvwxyz')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnopqrstuvwxyzA'), 'hello world123abc456defghijklmnopqrstuvwxyz a')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnopqrstuvwxyzAB'), 'hello world123abc456defghijklmnopqrstuvwxyz ab')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc456defghijklmnop"], "sample_2": ["def test_ccddata_init_with_array_electron_unit():\n    ccd = CCDData(np.zeros([2, 2]), unit=\"electron\")\n    assert ccd.unit is u.electron\n"], "sample_676": ["def test_terminalreporter_reportopt_disable_warnings(testdir):\n    testdir.makeini(\"[pytest]\\ndisable_warnings = True\")\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.fixture\n            tr = request.config.pluginmanager.getplugin(\"terminalreporter\")\n            return tr\n            assert not tr.hasopt('w')\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    result.stdout.fnmatch_lines([\"*1 passed*\"])\n"], "sample_1030": ["def test_closest_points():\n    p = Point2D(0, 0)\n    q = Point2D(3, 0)\n    r = Point2D(3, 4)\n    s = Point2D(0, 4)\n    t = Point2D(0, 2)\n    assert closest_points(p, q, r, s, t) == {(p, q)}\n    assert closest_points(p, q, r, s, t, t) == {(p, q)}\n    assert closest_points(p, q, r, s, t, t, t) == {(p, q)}\n    assert closest_points(p, q, r, s, t, t, t, t) == {(p, q)}\n    assert closest_points(p, q, r, s, t, t, t, t, t) == {(p, q)}\n    assert closest_points(p, q, r, s, t, t, t, t, t, t) == {(p, q)}\n    assert closest_points(p, q, r, s, t, t, t, t, t, t, t) == {(p, q)}\n    assert closest_points(p, q, r, s, t, t, t, t, t, t, t, t) == {(p, q)}\n    assert closest_points(p, q, r, s, t, t, t, t, t, t, t, t, t) == {(p, q)}\n    assert closest_points(p, q, r, s, t, t, t, t, t, t, t, t, t, t) == {(p, q)}\n    assert closest_points(p, q, r, s, t, t, t, t, t, t, t, t, t, t, t) == {(p, q)}\n    assert closest_points(p, q, r, s, t, t, t, t, t, t, t, t, t, t, t, t) == {(p, q)}\n    assert closest_points(p, q, r, s, t, t, t, t, t, t, t, t, t, t, t, t, t) == {(p, q)}\n    assert closest_points(p, q, r, s, t, t, t, t, t, t, t, t"], "sample_692": ["def test_getbasetemp_custom_removes_old_after_three_sessions(pytester: Pytester) -> None:\n    mytemp = pytester.path.joinpath(\"xyz\")\n    p = pytester.makepyfile(\n        \"\"\"\n            pass\n            pass\n            pass\n    \"\"\"\n    )\n    pytester.runpytest(p, \"--basetemp=%s\" % mytemp)\n    assert mytemp.exists()\n    mytemp.joinpath(\"hello\").touch()\n\n    pytester.runpytest(p, \"--basetemp=%s\" % mytemp)\n    assert mytemp.exists()\n    assert not mytemp.joinpath(\"hello\").exists()\n\n    pytester.runpytest(p, \"--basetemp=%s\" % mytemp)\n    assert mytemp.exists()\n    assert not mytemp.joinpath(\"hello\").exists()\n\n    pytester.runpytest(p, \"--basetemp=%s\" % mytemp)\n    assert mytemp.exists()\n    assert not mytemp.joinpath(\"hello\").exists()\n"], "sample_1178": ["def test_Element():\n    e = Element('x', 'i')\n    assert e.symbol == Symbol('x')\n    assert e.indices == (Symbol('i'),)\n    assert e.strides == none\n    assert e.offset == none\n    assert e.func(*e.args) == e\n\n    e2 = Element('x', 'ij')\n    assert e2.symbol == Symbol('x')\n    assert e2.indices == (Symbol('i'), Symbol('j'))\n    assert e2.strides == none\n    assert e2.offset == none\n    assert e2.func(*e2.args) == e2\n\n    e3 = Element('x', 'ijk', strides='lmn', offset='o')\n    assert e3.symbol == Symbol('x')\n    assert e3.indices == (Symbol('i'), Symbol('j'), Symbol('k'))\n    assert e3.strides == Tuple(Symbol('l'), Symbol('m'), Symbol('n'))\n    assert e3.offset == Symbol('o')\n    assert e3.func(*e3.args) == e3\n\n    e4 = Element('x', 'ijk', strides='lmn', offset=42)\n    assert e4.symbol == Symbol('x')\n    assert e4.indices == (Symbol('i'), Symbol('j'), Symbol('k'))\n    assert e4.strides == Tuple(Symbol('l'), Symbol('m'), Symbol('n'))\n    assert e4.offset == 42\n    assert e4.func(*e4.args) == e4\n\n    e5 = Element('x', 'ijk', strides='lmn', offset='o', offset=42)\n    assert e5.symbol == Symbol('x')\n    assert e5.indices == (Symbol('i'), Symbol('j'), Symbol('k'))\n    assert e5.strides == Tuple(Symbol('l'), Symbol('m'), Symbol('n'))\n    assert e5.offset == 42\n    assert e5.func(*e5.args) == e5\n\n    raises(TypeError, lambda: Element('x', 'ijk', strides='lmn', offset='o', offset=42))\n"], "sample_698": ["def test_coloredlogformatter_with_coloropts() -> None:\n    logfmt = \"%(levelname)-8s %(name)s:%(filename)s:%(lineno)d %(message)s\"\n    coloropts = {\"red\", \"bold\"}\n\n    record = logging.LogRecord(\n        name=\"dummy\",\n        level=logging.ERROR,\n        pathname=\"dummypath\",\n        lineno=10,\n        msg=\"Test Message\",\n        args=(),\n        exc_info=None,\n    )\n\n    tw = TerminalWriter()\n    tw.hasmarkup = True\n    formatter = ColoredLevelFormatter(tw, logfmt)\n    formatter.LOGLEVEL_COLOROPTS = {logging.ERROR: coloropts}\n    output = formatter.format(record)\n    assert output == (\n        \"\\x1b[31;1mERROR    \\x1b[0m dummy:dummypath:10 Test Message\"\n    )\n\n    tw.hasmarkup = False\n    formatter = ColoredLevelFormatter(tw, logfmt)\n    output = formatter.format(record)\n    assert output == (\"ERROR     dummy:dummypath:10 Test Message\")\n\n    tw.hasmarkup = True\n    formatter.LOGLEVEL_COLOROPTS = {logging.ERROR: set()}\n    output = formatter.format(record)\n    assert output == (\n        \"ERROR    dummy:dummypath:10 Test Message\"\n    )\n\n    tw.hasmarkup = False\n    formatter = ColoredLevelFormatter(tw, logfmt)\n    output = formatter.format(record)\n    assert output == (\"ERROR     dummy:dummypath:10 Test Message\")\n"], "sample_871": ["def test_silhouette_samples_precomputed_sparse_csr():\n    \"\"\"Check that silhouette_samples works for sparse CSR matrices correctly.\"\"\"\n    X = np.array([[0.2, 0.1, 0.1, 0.2, 0.1, 1.6, 0.2, 0.1]], dtype=np.float32).T\n    y = [0, 0, 0, 0, 1, 1, 1, 1]\n    pdist_dense = pairwise_distances(X)\n    pdist_sparse = csr_matrix(pdist_dense)\n    assert issparse(pdist_sparse)\n    output_with_sparse_input = silhouette_samples(pdist_sparse, y, metric=\"precomputed\")\n    output_with_dense_input = silhouette_samples(pdist_dense, y, metric=\"precomputed\")\n    assert_allclose(output_with_sparse_input, output_with_dense_input)\n\n"], "sample_581": ["def test_blueprint_static_folder(app, client):\n    bp = flask.Blueprint(\"bp\", __name__, static_folder=\"static\")\n\n    @bp.route(\"/static\")\n        return flask.send_static_file(\"test.txt\")\n\n    app.register_blueprint(bp)\n\n    assert client.get(\"/static\").data == b\"Admin File\"\n"], "sample_551": ["def test_patch_collection_3d_properties():\n    fig, ax = plt.subplots(subplot_kw=dict(projection='3d'))\n    patch = art3d.Patch3D(facecolor='red', edgecolor='blue', alpha=0.5)\n    ax.add_patch(patch)\n    ax.set_xlim(-1, 1)\n    ax.set_ylim(-1, 1)\n    ax.set_zlim(-1, 1)\n    patch.set_3d_properties(z=0.5, zdir='z')\n    assert patch.get_z() == 0.5\n    assert patch.get_zdir() == 'z'\n    patch.set_3d_properties(z=0.5, zdir='x')\n    assert patch.get_z() == 0.5\n    assert patch.get_zdir() == 'x'\n    patch.set_3d_properties(z=0.5, zdir='y')\n    assert patch.get_z() == 0.5\n    assert patch.get_zdir() == 'y'\n    patch.set_3d_properties(z=0.5, zdir=[1, 0, 0])\n    assert patch.get_z() == 0.5\n    assert patch.get_zdir() == [1, 0, 0]\n"], "sample_649": ["def test_log_cli_level_overridden_by_log_level(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_handler.level == logging.INFO\n            logging.getLogger('catchlog').debug(\"This log message won't be shown\")\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n    pytester.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n        log_level=DEBUG\n        \"\"\"\n    )\n\n    result = pytester.runpytest(\"-s\", \"--log-cli-level=INFO\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_log_cli_level_overridden_by_log_level.py*This log message will be shown\",\n            \"PASSED\",  # 'PASSED' on its own line because the log message prints a new line\n        ]\n    )\n    result.stdout.no_fnmatch_line(\"*This log message won't be shown*\")\n\n    # make sure that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n"], "sample_116": ["    def test_get_or_set_version(self):\n        cache.set('answer', 42, version=2)\n        self.assertIsNone(cache.get('answer'))\n        self.assertIsNone(cache.get('answer', version=1))\n        self.assertEqual(cache.get('answer', version=2), 42)\n        self.assertIsNone(cache.get('answer', version=3))\n\n        self.assertEqual(cache.get_or_set('answer', 43, version=2), 43)\n        self.assertIsNone(cache.get('answer'))\n        self.assertIsNone(cache.get('answer', version=1))\n        self.assertEqual(cache.get('answer', version=2), 43)\n        self.assertIsNone(cache.get('answer', version=3))\n\n        self.assertEqual(cache.get_or_set('answer', 44, version=1), 44)\n        self.assertEqual(cache.get('answer', version=1), 44)\n        self.assertIsNone(cache.get('answer'))\n        self.assertIsNone(cache.get('answer', version=2))\n        self.assertIsNone(cache.get('answer', version=3))\n\n        self.assertEqual(cache.get_or_set('answer', 45, version=3), 45)\n        self.assertIsNone(cache.get('answer'))\n        self.assertIsNone(cache.get('answer', version=1))\n        self.assertIsNone(cache.get('answer', version=2))\n        self.assertEqual(cache.get('answer', version=3), 45)\n"], "sample_552": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect((1, 2, 3))\n    ax2.set_box_aspect((4, 5, 6))\n    fig.tight_layout()\n    fig.draw_without_rendering()\n"], "sample_841": ["def test_ridge_regression_dtype_stability():\n    # Test that ridge regression is stable with respect to dtype\n    rng = np.random.RandomState(0)\n    n_samples, n_features = 6, 5\n    X = rng.randn(n_samples, n_features)\n    y = rng.randn(n_samples)\n    alpha = 1.0\n    results = dict()\n    for current_dtype in (np.float32, np.float64):\n        results[current_dtype] = ridge_regression(X.astype(current_dtype),\n                                                  y.astype(current_dtype),\n                                                  alpha=alpha,\n                                                  sample_weight=None,\n                                                  max_iter=500,\n                                                  tol=1e-10,\n                                                  return_n_iter=False,\n                                                  return_intercept=False)\n\n    assert results[np.float32].dtype == np.float32\n    assert results[np.float64].dtype == np.float64\n    assert_allclose(results[np.float32], results[np.float64], atol=1e-3)\n"], "sample_981": ["def test_inversion_vector():\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    assert p.inversion_vector() == [0, 0, 0, 0, 0, 0]\n    p = Permutation([4, 0, 1, 3, 2, 5])\n    assert p.inversion_vector() == [4, 3, 2, 1, 0, 0]\n    p = Permutation([3, 2, 1, 0, 4, 5])\n    assert p.inversion_vector() == [3, 2, 1, 0, 0, 0]\n    p = Permutation([5, 4, 3, 2, 1, 0])\n    assert p.inversion_vector() == [5, 4, 3, 2, 1, 0]\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([0, 2, 1, 3, 4, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([0, 1, 3, 2, 4, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([0, 1, 2, 4, 3, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([0, 1, 2, 3, 5, 4])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([0, 1, 2, 4, 5, 3])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([0, 1, 3, 4, 2, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    p = Permutation([0, 1, 4, 2, 3, 5])\n    assert Permutation.from_inversion_vector(p.inversion"], "sample_882": ["def test_mlp_regressor_batch_size():\n    # Test that batch_size affects the training process (it should)\n    X, y = make_regression(n_samples=50, n_features=5, n_targets=1, random_state=0)\n\n    # The coefficients will be identical if both do or do not shuffle\n    for batch_size in [1, 10, 50]:\n        mlp1 = MLPRegressor(\n            hidden_layer_sizes=1,\n            max_iter=1,\n            batch_size=batch_size,\n            random_state=0,\n        )\n        mlp2 = MLPRegressor(\n            hidden_layer_sizes=1,\n            max_iter=1,\n            batch_size=batch_size,\n            random_state=0,\n        )\n        mlp1.fit(X, y)\n        mlp2.fit(X, y)\n\n        assert np.array_equal(mlp1.coefs_[0], mlp2.coefs_[0])\n\n    # The coefficients will be slightly different if batch_size=1\n    mlp1 = MLPRegressor(\n        hidden_layer_sizes=1, max_iter=1, batch_size=1, random_state=0\n    )\n    mlp2 = MLPRegressor(\n        hidden_layer_sizes=1, max_iter=1, batch_size=10, random_state=0\n    )\n    mlp1.fit(X, y)\n    mlp2.fit(X, y)\n\n    assert not np.array_equal(mlp1.coefs_[0], mlp2.coefs_[0])\n"], "sample_852": ["def test_make_circles():\n    X, y = make_circles(n_samples=5, shuffle=False, noise=0.0, random_state=0)\n\n    assert X.shape == (5, 2), \"X shape mismatch\"\n    assert y.shape == (5,), \"y shape mismatch\"\n    assert np.unique(y).shape == (2,), \"Unexpected number of classes\"\n\n    # Test that points are on the unit circle\n    for x, label in zip(X, y):\n        center = [0.0, 0.0] if label == 0 else [1.0, 0.5]\n        dist_sqr = ((x - center) ** 2).sum()\n        assert_almost_equal(dist_sqr, 1.0,\n                            err_msg=\"Point is not on expected unit circle\")\n\n    # Test that points are on the outer circle\n    for x, label in zip(X[:3], y[:3]):\n        center = [0.0, 0.0]\n        dist_sqr = ((x - center) ** 2).sum()\n        assert_almost_equal(dist_sqr, 1.0,\n                            err_msg=\"Point is not on expected unit circle\")\n\n    # Test that points are on the inner circle\n    for x, label in zip(X[3:], y[3:]):\n        center = [1.0, 0.5]\n        dist_sqr = ((x - center) ** 2).sum()\n        assert_almost_equal(dist_sqr, 0.25,\n                            err_msg=\"Point is not on expected unit circle\")\n\n    # Test that points are not on the same circle\n    for i in range(3):\n        for j in range(i + 1, 3):\n            dist_sqr = ((X[i] - X[j]) ** 2).sum()\n            assert dist_sqr > 0.25, \"Points are on the same circle\"\n"], "sample_462": ["    def test_typedchoicefield_1(self):\n        f = TypedChoiceField(choices=[(\"1\", \"One\"), (\"2\", \"Two\")], coerce=int)\n        with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):\n            f.clean(\"\")\n        with self.assertRaisesMessage(ValidationError, \"'This field is required.'\"):\n            f.clean(None)\n        self.assertEqual(1, f.clean(1))\n        self.assertEqual(1, f.clean(\"1\"))\n        msg = \"'Select a valid choice. 3 is not one of the available choices.'\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            f.clean(\"3\")\n"], "sample_749": ["def test_column_transformer_remainder_transformer_sparse():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n\n    # second and third columns are doubled when remainder = DoubleTrans\n    X_res_both = X_array.copy()\n    X_res_both[:, 1:3] *= 2\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=DoubleTrans())\n\n    assert_array_equal(ct.fit_transform(X_array), X_res_both)\n    assert_array_equal(ct.fit(X_array).transform(X_array), X_res_both)\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], DoubleTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n\n    # test with sparse input\n    X_sparse = sparse.csr_matrix(X_array)\n    assert_array_equal(ct.fit_transform(X_sparse), X_res_both)\n    assert_array_equal(ct.fit(X_sparse).transform(X_sparse), X_res_both)\n    assert len(ct.transformers_) == 2\n    assert ct.transformers_[-1][0] == 'remainder'\n    assert isinstance(ct.transformers_[-1][1], DoubleTrans)\n    assert_array_equal(ct.transformers_[-1][2], [1, 2])\n"], "sample_276": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n        with captured_stderr() as self.docutils_stderr:\n            self.response = self.client.get(reverse('django-admindocs-templates', args=['admin_doc/template_detail.html']))\n"], "sample_605": ["def test_groupby_quantile_empty():\n    array = xr.DataArray([1, 2, 3], [(\"x\", [1, 2, 2])])\n    with pytest.raises(ValueError):\n        array.groupby(\"x\").quantile(0.5)\n"], "sample_950": ["def test_pydata_with_union_type_operator_old(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :annotation: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0],\n                ([desc_name, \"version\"],\n                 [desc_annotation, (\": \",\n                                    [pending_xref, \"int\"],\n                                    \" \",\n                                    [desc_sig_punctuation, \"|\"],\n                                    \" \",\n                                    [pending_xref, \"str\"])]))\n"], "sample_130": ["def test_annotation(self):\n    query = Query(Author)\n    where = query.build_where(Q(num__gt=F('id')))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertIsInstance(lookup.rhs, SimpleCol)\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.rhs.target, Author._meta.get_field('num'))\n\n    query = Query(Author)\n    where = query.build_where(Q(num__gt=F('id') + 1))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertIsInstance(lookup.rhs, SimpleCol)\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.rhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.rhs.value, 1)\n\n    query = Query(Author)\n    where = query.build_where(Q(num__gt=F('id') + F('name')))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertIsInstance(lookup.rhs, SimpleCol)\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.rhs.target, Author._meta.get_field('name'))\n    self.assertEqual(lookup.rhs.value, 1)\n\n    query = Query(Author)\n    where = query.build_where(Q(num__gt=F('id') + F('name') + 1))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertIsInstance(lookup.rhs, SimpleCol)\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.rhs.target, Author._meta.get_field('name'))\n    self.assertEqual(lookup.rhs.value, 2)\n"], "sample_1065": ["def test_subfactorial():\n    x = Symbol('x')\n    n = Symbol('n', integer=True)\n    nz = Symbol('nz', integer=True, nonzero=True)\n    k = Symbol('k', integer=True)\n    kp = Symbol('kp', integer=True, positive=True)\n    kn = Symbol('kn', integer=True, negative=True)\n    u = Symbol('u', negative=True)\n    v = Symbol('v', nonnegative=True)\n    p = Symbol('p', positive=True)\n    z = Symbol('z', zero=True)\n    nt = Symbol('nt', integer=False)\n    kt = Symbol('kt', integer=False)\n    a = Symbol('a', integer=True, nonnegative=True)\n    b = Symbol('b', integer=True, nonnegative=True)\n\n    assert subfactorial(-2) == 1\n    assert subfactorial(0) == 1\n    assert subfactorial(7) == 44\n    assert subfactorial(8) == 132\n\n    # The following is exhaustive\n    tt = Symbol('tt', integer=True, nonnegative=True)\n    tte = Symbol('tte', even=True, nonnegative=True)\n    tpe = Symbol('tpe', even=True, positive=True)\n    tto = Symbol('tto', odd=True, nonnegative=True)\n    tf = Symbol('tf', integer=True, nonnegative=False)\n    tfe = Symbol('tfe', even=True, nonnegative=False)\n    tfo = Symbol('tfo', odd=True, nonnegative=False)\n    ft = Symbol('ft', integer=False, nonnegative=True)\n    ff = Symbol('ff', integer=False, nonnegative=False)\n    fn = Symbol('fn', integer=False)\n    nt = Symbol('nt', nonnegative=True)\n    nf = Symbol('nf', nonnegative=False)\n    nn = Symbol('nn')\n    z = Symbol('z', zero=True)\n\n    assert subfactorial(n).is_integer is None\n    assert subfactorial(tt - 1).is_integer\n    assert subfactorial(tte - 1).is_integer\n    assert subfactorial(tpe - 3).is_integer\n    assert subfactorial(tto - 4).is_integer\n    assert subfactorial(tto - 2).is_integer\n    assert subfactorial(tf).is_integer is None\n    assert subfactorial(tfe).is_integer is None\n    assert subfactor"], "sample_757": ["def test_ordinal_encoder_dtype():\n    # check that dtypes are preserved when determining categories\n    enc = OrdinalEncoder(categories='auto')\n    exp = np.array([[0., 1.], [1., 0.]], dtype='float64')\n\n    for X in [np.array([[1, 2], [3, 4]], dtype='int64'),\n              np.array([[1, 2], [3, 4]], dtype='float64'),\n              np.array([['a', 'b'], ['c', 'd']]),  # string dtype\n              np.array([[1, 'a'], [3, 'b']], dtype='object')]:\n        enc.fit(X)\n        assert all([enc.categories_[i].dtype == X.dtype for i in range(2)])\n        assert_array_equal(enc.transform(X), exp.astype(X.dtype))\n\n    X = [[1, 2], [3, 4]]\n    enc.fit(X)\n    assert all([np.issubdtype(enc.categories_[i].dtype, np.integer)\n                for i in range(2)])\n    assert_array_equal(enc.transform(X), exp)\n\n    X = [[1, 'a'], [3, 'b']]\n    enc.fit(X)\n    assert all([enc.categories_[i].dtype == 'object' for i in range(2)])\n    assert_array_equal(enc.transform(X), exp)\n"], "sample_106": ["    def tearDown(self):\n        cache.clear()\n"], "sample_1204": ["def test_coset_factor_index():\n    a = Permutation([0, 2, 1])\n    b = Permutation([1, 0, 2])\n    G = PermutationGroup([a, b])\n    c = Permutation([2, 1, 0])\n    assert G.coset_factor(c, True) == [0, 1]\n    assert G.coset_factor(c, True, factor_index=True) == [0, 1]\n    assert G.coset_factor(c) == [0, 1]\n    assert G.coset_factor(c, factor_index=True) == [0, 1]\n    assert G.coset_factor(c, True, factor_index=False) == [0, 1]\n    assert G.coset_factor(c, factor_index=False) == [0, 1]\n    assert G.coset_factor(c, True, factor_index=True) == [0, 1]\n    assert G.coset_factor(c, factor_index=True) == [0, 1]\n    assert G.coset_factor(c, True, factor_index=False) == [0, 1]\n    assert G.coset_factor(c, factor_index=False) == [0, 1]\n    assert G.coset_factor(c, True, factor_index=True) == [0, 1]\n    assert G.coset_factor(c, factor_index=True) == [0, 1]\n    assert G.coset_factor(c, True, factor_index=False) == [0, 1]\n    assert G.coset_factor(c, factor_index=False) == [0, 1]\n    assert G.coset_factor(c, True, factor_index=True) == [0, 1]\n    assert G.coset_factor(c, factor_index=True) == [0, 1]\n    assert G.coset_factor(c, True, factor_index=False) == [0, 1]\n    assert G.coset_factor(c, factor_index=False) == [0, 1]\n    assert G.coset_factor(c, True, factor_index=True) == [0, 1]\n    assert G.coset_factor(c, factor_index=True) == [0, 1]\n    assert G.coset_factor(c, True, factor_index=False) == [0, 1]\n    assert G.coset_factor(c, factor_index=False) == [0, 1]\n    assert G.coset_factor(c, True, factor_index=True) == [0"], "sample_400": ["def test_alter_field_with_default(self):\n    \"\"\"Tests autodetection of field default value changes.\"\"\"\n    changes = self.get_changes([self.author_name], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=\"Ada Lovelace\")\n"], "sample_660": ["def test_record_testsuite_property_multiple_calls(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_testsuite_property(\"stats\", \"all good\")\n\n            record_testsuite_property(\"stats\", 10)\n            record_testsuite_property(\"stats\", 20)\n    \"\"\"\n    )\n    result, dom = runandparse(testdir)\n    assert result.ret == 0\n    node = dom.find_first_by_tag(\"testsuite\")\n    properties_node = node.find_first_by_tag(\"properties\")\n    p1_node = properties_node.find_nth_by_tag(\"property\", 0)\n    p2_node = properties_node.find_nth_by_tag(\"property\", 1)\n    p3_node = properties_node.find_nth_by_tag(\"property\", 2)\n    p1_node.assert_attr(name=\"stats\", value=\"all good\")\n    p2_node.assert_attr(name=\"stats\", value=\"10\")\n    p3_node.assert_attr(name=\"stats\", value=\"20\")\n"], "sample_535": ["def test_auto_fontsize():\n    fig = plt.figure()\n\n    # iterable list input\n    ax1 = fig.add_subplot(4, 1, 1)\n    ax1.axis('off')\n    tb1 = ax1.table(\n        cellText=[['Fit Text', 2],\n                  ['very long long text, Longer text than default', 1]],\n        rowLabels=[\"A\", \"B\"],\n        colLabels=[\"Col1\", \"Col2\"],\n        loc=\"center\")\n    tb1.auto_set_font_size(True)\n    tb1.set_fontsize(12)\n\n    # iterable tuple input\n    ax2 = fig.add_subplot(4, 1, 2)\n    ax2.axis('off')\n    tb2 = ax2.table(\n        cellText=[['Fit Text', 2],\n                  ['very long long text, Longer text than default', 1]],\n        rowLabels=[\"A\", \"B\"],\n        colLabels=[\"Col1\", \"Col2\"],\n        loc=\"center\")\n    tb2.auto_set_font_size(True)\n    tb2.set_fontsize(12)\n\n    # 3 single inputs\n    ax3 = fig.add_subplot(4, 1, 3)\n    ax3.axis('off')\n    tb3 = ax3.table(\n        cellText=[['Fit Text', 2],\n                  ['very long long text, Longer text than default', 1]],\n        rowLabels=[\"A\", \"B\"],\n        colLabels=[\"Col1\", \"Col2\"],\n        loc=\"center\")\n    tb3.auto_set_font_size(True)\n    tb3.set_fontsize(12)\n\n    # 4 non integer iterable input\n    ax4 = fig.add_subplot(4, 1, 4)\n    ax4.axis('off')\n    tb4 = ax4.table(\n        cellText=[['Fit Text', 2],\n                  ['very long long text, Longer text than default', 1]],\n        rowLabels=[\"A\", \"B\"],\n        colLabels=[\"Col1\", \"Col2\"],\n        loc=\"center\")\n    tb4.auto_set_font_size(True)\n    tb4.set_fontsize(12)\n    tb4.auto_set_font_size(False)\n    tb4.set_fontsize(12)\n"], "sample_152": ["    def test_delete_with_keeping_parents_reverse_relationships(self):\n        child = RChild.objects.create()\n        parent_id = child.r_ptr_id\n        parent_referent_id = S.objects.create(r=child.r_ptr).pk\n        child.delete(keep_parents=True)\n        self.assertFalse(RChild.objects.filter(id=child.id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n\n        childchild = RChildChild.objects.create()\n        parent_id = childchild.rchild_ptr.r_ptr_id\n        child_id = childchild.rchild_ptr_id\n        parent_referent_id = S.objects.create(r=childchild.rchild_ptr.r_ptr).pk\n        childchild.delete(keep_parents=True)\n        self.assertFalse(RChildChild.objects.filter(id=childchild.id).exists())\n        self.assertTrue(RChild.objects.filter(id=child_id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n"], "sample_15": ["    def test_power_scalar(self):\n        assert np.power(4.0 * u.m, 2.0) == 16.0 * u.m**2\n        assert np.power(4.0 * u.m, 200.0 * u.cm / u.m) == u.Quantity(\n            16.0, u.dimensionless_unscaled\n        )\n        # regression check on #1696\n        assert np.power(4.0 * u.m, 0.0) == 1.0 * u.dimensionless_unscaled\n"], "sample_121": ["    def test_field_name_starting_with_underscore(self):\n        class Model(models.Model):\n            _field = models.CharField(max_length=10)\n\n        self.assertEqual(Model.check(), [\n            Error(\n                'Field names must not start with an underscore.',\n                obj=Model._meta.get_field('_field'),\n                id='fields.E001',\n            ),\n        ])\n"], "sample_536": ["def test_cursor(ax):\n    cursor = widgets.Cursor(ax, horizOn=True, vertOn=True)\n    assert cursor.visible\n    assert cursor.horizOn\n    assert cursor.vertOn\n    assert cursor.useblit is False\n\n    cursor.visible = False\n    assert not cursor.visible\n\n    cursor.visible = True\n    assert cursor.visible\n\n    cursor.horizOn = False\n    assert not cursor.horizOn\n    assert cursor.vertOn\n    assert cursor.useblit is False\n\n    cursor.vertOn = False\n    assert not cursor.vertOn\n    assert not cursor.horizOn\n    assert cursor.useblit is False\n\n    cursor.useblit = True\n    assert cursor.useblit\n\n    cursor.visible = False\n    assert not cursor.visible\n\n    cursor.visible = True\n    assert cursor.visible\n\n    cursor.horizOn = True\n    assert cursor.horizOn\n    assert cursor.vertOn\n    assert cursor.useblit\n\n    cursor.vertOn = True\n    assert cursor.vertOn\n    assert cursor.horizOn\n    assert cursor.useblit\n\n    cursor.useblit = False\n    assert not cursor.useblit\n\n    cursor.visible = False\n    assert not cursor.visible\n\n    cursor.visible = True\n    assert cursor.visible\n\n    cursor.horizOn = False\n    assert not cursor.horizOn\n    assert cursor.vertOn\n    assert cursor.useblit is False\n\n    cursor.vertOn = False\n    assert not cursor.vertOn\n    assert not cursor.horizOn\n    assert cursor.useblit is False\n\n    cursor.useblit = True\n    assert cursor.useblit\n\n    cursor.visible = False\n    assert not cursor.visible\n\n    cursor.visible = True\n    assert cursor.visible\n\n    cursor.horizOn = True\n    assert cursor.horizOn\n    assert cursor.vertOn\n    assert cursor.useblit\n\n    cursor.vertOn = True\n    assert cursor.vertOn\n    assert cursor.horizOn\n    assert cursor.useblit\n\n    cursor.useblit = False\n    assert not cursor.useblit\n\n    cursor.visible = False\n    assert not cursor.visible\n\n    cursor.visible = True\n    assert cursor.visible\n\n    cursor.horizOn = False\n    assert not cursor.horizOn\n    assert cursor.vertOn\n    assert cursor.useblit is"], "sample_389": ["    def test_get_signed_cookie(self):\n        req = HttpRequest()\n        req.COOKIES[\"signed_cookie\"] = \"signed_value\"\n        self.assertEqual(req.get_signed_cookie(\"signed_cookie\"), \"signed_value\")\n        self.assertEqual(req.get_signed_cookie(\"signed_cookie\", default=\"default_value\"), \"default_value\")\n        with self.assertRaises(RawPostDataException):\n            req.get_signed_cookie(\"signed_cookie\", default=RAISE_ERROR)\n"], "sample_1024": ["def test_Float_floor():\n    assert Float(3.7).floor() == 3\n    assert Float(-3.7).floor() == -4\n    assert Float(0.0).floor() == 0\n    assert Float(-0.0).floor() == 0\n    assert Float('3.7').floor() == 3\n    assert Float('-3.7').floor() == -4\n    assert Float('0.0').floor() == 0\n    assert Float('-0.0').floor() == 0\n    assert Float(3.7).ceiling() == 4\n    assert Float(-3.7).ceiling() == -3\n    assert Float(0.0).ceiling() == 0\n    assert Float(-0.0).ceiling() == 0\n    assert Float('3.7').ceiling() == 4\n    assert Float('-3.7').ceiling() == -3\n    assert Float('0.0').ceiling() == 0\n    assert Float('-0.0').ceiling() == 0\n"], "sample_85": ["    def test_delete_with_keeping_parents_through(self):\n        child = RChildChild.objects.create()\n        parent_id = child.rchild_ptr_id\n        parent_referent_id = S.objects.create(r=child.rchild_ptr.r_ptr).pk\n        child.delete(keep_parents=True)\n        self.assertFalse(RChildChild.objects.filter(id=child.id).exists())\n        self.assertTrue(RChild.objects.filter(id=parent_id).exists())\n        self.assertTrue(R.objects.filter(id=parent_referent_id).exists())\n        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n"], "sample_1121": ["def test_Mul_is_nonzero():\n    x = Symbol('x', nonzero=True)\n    y = Symbol('y', nonzero=True)\n    z = Symbol('z', nonzero=False)\n    assert (x*y).is_nonzero\n    assert (x*z).is_nonzero is None\n    assert (z*y).is_nonzero is None\n    assert (x + y).is_nonzero is None\n    assert (x + z).is_nonzero is None\n    assert (z + y).is_nonzero is None\n    assert (x*y*z).is_nonzero is None\n    assert (x*y + z).is_nonzero is None\n    assert (x + y*z).is_nonzero is None\n    assert (z + y*x).is_nonzero is None\n"], "sample_1009": ["def test_Vector_sub():\n    q1, q2, q3, q4 = dynamicsymbols('q1 q2 q3 q4')\n    N = ReferenceFrame('N')\n    A = N.orientnew('A', 'Axis', [q3, N.z])\n    B = A.orientnew('B', 'Axis', [q2, A.x])\n    v1 = q2 * A.x + q3 * N.y\n    v2 = q3 * B.x + v1\n    v3 = v1.dt(B)\n    v4 = v2.dt(B)\n    v5 = q1*A.x + q2*A.y + q3*A.z\n\n    assert v1.subs(q2, 1) == q3 * N.y\n    assert v1.subs(q3, 1) == q2 * A.x\n    assert v2.subs(q2, 1) == q3 * B.x + q3 * N.y\n    assert v2.subs(q3, 1) == B.x + A.x\n    assert v3.subs(q2, 1) == q3 * q3d * N.x + q3d * N.y - q3 * cos(q3) * q2d * N.z\n    assert v3.subs(q3, 1) == q2d * A.x + q2 * q3d * A.y + q3d * N.y\n    assert v4.subs(q2, 1) == q3d * B.x + q3 * q3d * N.x + q3d * N.y\n    assert v4.subs(q3, 1) == q2d * A.x + q2 * q3d * A.y + q3d * B.x + q3d * N.y\n    assert v5.subs(q1, 1) == A.x + q2*A.y + q3*A.z\n    assert v5.subs(q2, 1) == A.x + q1*A.y + q3*A.z\n    assert v5.subs(q3, 1) == A.x + q2*A.y + q1*A.z\n\n    raises(TypeError, lambda: v1.subs('q2', 1))\n    raises(TypeError, lambda: v1.subs(q2, 'q2'))\n"], "sample_335": ["    def test_decimalfield_7(self):\n        f = DecimalField(max_digits=4, decimal_places=2)\n        with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 2 decimal places.'\"):\n            f.clean('1.2345')\n        with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 4 digits in total.'\"):\n            f.clean('12345')\n        with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 4 digits in total.'\"):\n            f.clean('1234.5')\n        with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 4 digits in total.'\"):\n            f.clean('1234.50')\n        with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 4 digits in total.'\"):\n            f.clean('1234.500')\n        with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 4 digits in total.'\"):\n            f.clean('1234.5000')\n        with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 4 digits in total.'\"):\n            f.clean('1234.50000')\n        with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 4 digits in total.'\"):\n            f.clean('1234.500000')\n        with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 4 digits in total.'\"):\n            f.clean('1234.5000000')\n        with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 4 digits in total.'\"):\n            f.clean('1234.50000000')\n        with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 4 digits in total.'\"):\n            f.clean('1234.500000000')\n        with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 4 digits in total.'\"):\n            f.clean('1234.5000000000')\n        with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 4 digits in total.'\"):\n            f.clean('1234.50000000000')\n        with self.assertRaisesMessage(ValidationError, \"'Ensure that there are no more than 4 digits in total.'\"):\n            f.clean('1234.500000000000')\n        with self.assertRaisesMessage(ValidationError, \"'Ensure"], "sample_1172": ["def test_solve_generic():\n    x, y, z = symbols('x y z')\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    a, b = sqrt(2) - 1, -sqrt(2) - 1\n\n    assert solve_generic([f_1, f_2, f_3], x, y, z) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0), (a, a, a), (b, b, b)]\n\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    assert solve_generic([f_1, f_2, f_3], x, y) is None\n\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    assert solve_generic([f_1, f_2, f_3], x, y, z, domain=QQ) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0)]\n\n    dom = QQ.algebraic_field(sqrt(2))\n\n    assert solve_generic([f_1, f_2, f_3], x, y, z, domain=dom) == \\\n        [(0, 0, 1), (0, 1, 0), (1, 0, 0), (a, a, a), (b, b, b)]\n\n    f_1 = x**2 + y + z - 1\n    f_2 = x + y**2 + z - 1\n    f_3 = x + y + z**2 - 1\n\n    assert solve_generic([f_1, f_2, f_3], x, y, z, domain=QQ, order='lex') == \\\n        [(0, 0, 1), (0,"], "sample_747": ["def test_power_transformer_axis1():\n    X = np.array([[0, 25, 50, 75, 100],\n                  [2, 4, 6, 8, 10],\n                  [2.6, 4.1, 2.3, 9.5, 0.1]])\n\n    transformer = PowerTransformer(method='box-cox')\n    X_trans = transformer.fit_transform(X.T)\n    X_trans_inv = transformer.inverse_transform(X_trans.T)\n    assert_array_almost_equal(X, X_trans_inv)\n\n    transformer = PowerTransformer(method='box-cox', standardize=True)\n    X_trans = transformer.fit_transform(X.T)\n    X_trans_inv = transformer.inverse_transform(X_trans.T)\n    assert_array_almost_equal(X, X_trans_inv)\n"], "sample_1093": ["def test_SymPyPrinter_print_Piecewise():\n    p = SymPyPrinter()\n    assert p.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == 'sympy.Piecewise((1, Eq(x, 0)), (2, x > 6))'\n    assert p.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == 'sympy.Piecewise((2, x <= 0), (3, x > 0))'\n"], "sample_870": ["def test_gpr_copy_X_train():\n    \"\"\"Check that the copy_X_train parameter is respected.\"\"\"\n    rng = np.random.RandomState(0)\n    X = rng.randn(10, 3)\n    y = rng.randn(10)\n\n    model = GaussianProcessRegressor(copy_X_train=False)\n    model.fit(X, y)\n    assert np.shares_memory(model.X_train_, X)\n\n    model = GaussianProcessRegressor(copy_X_train=True)\n    model.fit(X, y)\n    assert not np.shares_memory(model.X_train_, X)\n"], "sample_920": ["    def test_custom_sections(self):\n        docstring = \"\"\"\\"], "sample_401": ["def test_formset_can_delete_extra_forms(self):\n    \"\"\"\n    When can_delete_extra is False, extra forms should not be deletable.\n    \"\"\"\n    ChoiceFormFormset = formset_factory(form=Choice, can_delete=True, extra=2)\n    formset = ChoiceFormFormset(initial=[{\"choice\": \"Zero\", \"votes\": \"1\"}])\n    self.assertEqual(len(formset), 3)\n    self.assertIn(\"DELETE\", formset.forms[0].fields)\n    self.assertNotIn(\"DELETE\", formset.forms[1].fields)\n    self.assertNotIn(\"DELETE\", formset.forms[2].fields)\n\n    data = {\n        \"form-0-choice\": \"Zero\",\n        \"form-0-votes\": \"0\",\n        \"form-0-DELETE\": \"on\",\n        \"form-1-choice\": \"One\",\n        \"form-1-votes\": \"1\",\n        \"form-2-choice\": \"\",\n        \"form-2-votes\": \"\",\n        \"form-TOTAL_FORMS\": \"3\",\n        \"form-INITIAL_FORMS\": \"1\",\n    }\n    ChoiceFormFormset = formset_factory(form=Choice, can_delete=True, can_delete_extra=False, extra=2)\n    formset = ChoiceFormFormset(data, initial=[{\"choice\": \"Zero\", \"votes\": \"1\"}])\n    self.assertEqual(\n        formset.cleaned_data,\n        [\n            {\"choice\": \"Zero\", \"votes\": 0, \"DELETE\": True},\n            {\"choice\": \"One\", \"votes\": 1},\n            {},\n        ],\n    )\n    self.assertIs(formset._should_delete_form(formset.forms[0]), True)\n    self.assertIs(formset._should_delete_form(formset.forms[1]), False)\n    self.assertIs(formset._should_delete_form(formset.forms[2]), False)\n"], "sample_19": ["def test_sub_with_temporal():\n    \"\"\"\n    Test sub with temporal axis.\n    \"\"\"\n    w = wcs.WCS(naxis=3)\n    w.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\", \"TIME\"]\n    w.wcs.set()\n    assert w.has_temporal\n    assert w.sub([wcs.WCSSUB_TIME]).is_temporal\n    assert (\n        w.wcs_pix2world([[1, 2, 3]], 0)[0, 2]\n        == w.sub([wcs.WCSSUB_TIME]).wcs_pix2world([[3]], 0)[0, 0]\n    )\n"], "sample_933": ["def test_gettext_uuid(app):\n    app.builder.build_all()\n    catalog = (app.outdir / 'extapi.pot').read_text()\n    assert 'msgid \"uuid\"' in catalog\n    assert 'msgstr \"\"' in catalog\n    assert 'msgid \"uuid\"' in catalog\n    assert 'msgstr \"\"' in catalog\n    assert 'msgid \"uuid\"' in catalog\n    assert 'msgstr \"\"' in catalog\n"], "sample_1200": ["def test_get_dimensional_dependencies():\n    u = Quantity(\"u\")\n    v = Quantity(\"v\")\n    w = Quantity(\"w\")\n\n    u.set_global_relative_scale_factor(S(10), meter)\n    v.set_global_relative_scale_factor(S(5), meter)\n    w.set_global_relative_scale_factor(S(2), second)\n\n    assert SI.get_dimension_system().get_dimensional_dependencies(u) == {\n        length: 1,\n        time: 0\n    }\n    assert SI.get_dimension_system().get_dimensional_dependencies(v) == {\n        length: 1,\n        time: 0\n    }\n    assert SI.get_dimension_system().get_dimensional_dependencies(w) == {\n        length: 0,\n        time: 1\n    }\n\n    expr = u + v\n    Dq = Dimension(SI.get_dimensional_expr(expr))\n    assert SI.get_dimension_system().get_dimensional_dependencies(Dq) == {\n        length: 1,\n        time: 0\n    }\n\n    expr = u - v\n    Dq = Dimension(SI.get_dimensional_expr(expr))\n    assert SI.get_dimension_system().get_dimensional_dependencies(Dq) == {\n        length: 1,\n        time: 0\n    }\n\n    expr = u * v\n    Dq = Dimension(SI.get_dimensional_expr(expr))\n    assert SI.get_dimension_system().get_dimensional_dependencies(Dq) == {\n        length: 2,\n        time: 0\n    }\n\n    expr = u / v\n    Dq = Dimension(SI.get_dimensional_expr(expr))\n    assert SI.get_dimension_system().get_dimensional_dependencies(Dq) == {\n        length: 1,\n        time: 0\n    }\n\n    expr = u ** 2\n    Dq = Dimension(SI.get_dimensional_expr(expr))\n    assert SI.get_dimension_system().get_dimensional_dependencies(Dq) == {\n        length: 2,\n        time: 0\n    }\n\n    expr = u ** -1\n    Dq = Dimension(SI.get_dimensional_expr(expr))\n    assert SI.get_dimension_system().get_dimensional_dependencies(Dq) == {\n        length: -1,\n        time: 0\n    }\n"], "sample_850": ["def test_skewed_chi2_sampler_random_state():\n    # test that SkewedChi2Sampler approximates kernel on random data\n\n    # compute exact kernel\n    c = 0.03\n    # set on negative component but greater than c to ensure that the kernel\n    # approximation is valid on the group (-c; +\\infty) endowed with the skewed\n    # multiplication.\n    Y[0, 0] = -c / 2.\n\n    # abbreviations for easier formula\n    X_c = (X + c)[:, np.newaxis, :]\n    Y_c = (Y + c)[np.newaxis, :, :]\n\n    # we do it in log-space in the hope that it's more stable\n    # this array is n_samples_x x n_samples_y big x n_features\n    log_kernel = ((np.log(X_c) / 2.) + (np.log(Y_c) / 2.) + np.log(2.) -\n                  np.log(X_c + Y_c))\n    # reduce to n_samples_x x n_samples_y by summing over features in log-space\n    kernel = np.exp(log_kernel.sum(axis=2))\n\n    # approximate kernel mapping\n    transform = SkewedChi2Sampler(skewedness=c, n_components=1000,\n                                  random_state=42)\n    X_trans = transform.fit_transform(X)\n    Y_trans = transform.transform(Y)\n\n    kernel_approx = np.dot(X_trans, Y_trans.T)\n    assert_array_almost_equal(kernel, kernel_approx, 1)\n    assert np.isfinite(kernel).all(), \\\n        'NaNs found in the Gram matrix'\n    assert np.isfinite(kernel_approx).all(), \\\n        'NaNs found in the approximate Gram matrix'\n\n    # test that the random state is used correctly\n    transform = SkewedChi2Sampler(skewedness=c, n_components=1000,\n                                  random_state=42)\n    X_trans_1 = transform.fit_transform(X)\n    transform.random_state = 42  # change the random state\n    X_trans_2 = transform.fit_transform(X)\n    assert_array_equal(X_trans_1, X_trans_2)\n\n    # test that the random state is used correctly when fit_transform is called\n    transform = SkewedChi2Sampler(skewedness=c, n_components=1000,\n                                  random_state=42)\n    X_trans_1 = transform.fit_transform(X)\n    transform.random_state = 42  # change the random state\n   "], "sample_1130": ["def test_auto_point_vel_multiple_paths():\n    t = dynamicsymbols._t\n    q1, q2, u1, u2 = dynamicsymbols('q1 q2 u1 u2')\n    B = ReferenceFrame('B')\n    P = Point('P')\n    P.set_vel(B, u1 * B.x)\n    P1 = Point('P1')\n    P1.set_pos(P, q2 * B.y)\n    P1.set_vel(B, q1 * B.z)\n    P2 = Point('P2')\n    P2.set_pos(P1, q1 * B.z)\n    P3 = Point('P3')\n    P3.set_pos(P2, 10 * q1 * B.y)\n    P4 = Point('P4')\n    P4.set_pos(P3, q1 * B.x)\n    O = Point('O')\n    O.set_vel(B, u2 * B.y)\n    O1 = Point('O1')\n    O1.set_pos(O, q2 * B.z)\n    P4.set_pos(O1, q1 * B.x + q2 * B.z)\n    with warnings.catch_warnings(): #There are two possible paths in this point tree, thus a warning is raised\n        warnings.simplefilter(\"error\")\n        with ignore_warnings(UserWarning):\n            assert P4.vel(B) == q1.diff(t) * B.x + u2 * B.y + 2 * q2.diff(t) * B.z\n    P5 = Point('P5')\n    P5.set_pos(P4, q1 * B.y)\n    with warnings.catch_warnings(): #There are multiple possible paths in this point tree, thus a warning is raised\n        warnings.simplefilter(\"error\")\n        with ignore_warnings(UserWarning):\n            assert P5.vel(B) == q1.diff(t) * B.x + q1.diff(t) * B.y + u2 * B.y + 2 * q2.diff(t) * B.z\n"], "sample_909": ["    def test_custom_sections(self):\n        docstring = \"\"\"\\"], "sample_766": ["def test_dict_learning_max_iter():\n    n_components = 5\n    dico = DictionaryLearning(n_components, transform_algorithm='lasso_cd',\n                              transform_alpha=0.001, random_state=0,\n                              transform_max_iter=1)\n    with pytest.warns(ConvergenceWarning):\n        dico.fit(X)\n    assert dico.n_iter_ == 1\n"], "sample_418": ["    def test_empty_string(self):\n        self.assertIs(length_is(\"\", 0), True)\n        self.assertIs(length_is(\"\", 1), False)\n"], "sample_1124": ["def test_FracElement_compose():\n    F, x,y,z = field(\"x,y,z\", ZZ)\n    f = (x**2 + 3*y)/z\n\n    raises(NotImplementedError, lambda: f.compose(x, 1))\n    raises(NotImplementedError, lambda: f.compose(y, 1))\n    raises(NotImplementedError, lambda: f.compose(z, 1))\n\n    Fyz = field(\"y,z\", ZZ)[0]\n    f = (x**2 + 3*y)/z\n    g = (y + 1)/(z + 1)\n\n    assert f.compose(y, g) == (x**2 + 3*(y + 1))/((z + 1) + (y + 1))\n    assert f.compose(z, g) == (x**2 + 3*y)/((z + 1)*(y + 1))\n"], "sample_507": ["    def test_StrCategoryFormatterUpdate(self, ydata):\n        unit = cat.UnitData(ydata)\n        labels = cat.StrCategoryFormatter(unit._mapping)\n        unit.update([\"new\", \"hello\"])\n        assert labels(0) == \"new\"\n        assert labels(1) == \"hello\"\n        assert labels(2) == \"\"\n"], "sample_260": ["def test_create_model_add_index(self):\n    \"\"\"\n    AddIndex should optimize into CreateModel.\n    \"\"\"\n    managers = [('objects', EmptyManager())]\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[(\"name\", models.CharField(max_length=255))],\n                options={'verbose_name': 'Foo'},\n                bases=(UnicodeModel,),\n                managers=managers,\n            ),\n            migrations.AddIndex(\"Foo\", models.Index(fields=[\"name\"])),\n        ],\n        [\n            migrations.CreateModel(\n                name=\"Foo\",\n                fields=[\n                    (\"name\", models.CharField(max_length=255)),\n                ],\n                options={'verbose_name': 'Foo'},\n                bases=(UnicodeModel,),\n                managers=managers,\n                indexes=[\n                    models.Index(fields=[\"name\"]),\n                ],\n            ),\n        ],\n    )\n"], "sample_663": ["    def test_collect_with_maxfail_and_continue_on_collection_errors(self, testdir):\n        \"\"\"Verify tests are executed even when collection errors occur and that maxfail is honoured (including the collection error count).\n        4 tests: 2 collection errors + 1 failure + 1 success\n        test_4 is never executed because the test run is with --maxfail=3 which means it is interrupted after the 2 collection errors + 1 failure.\n        \"\"\"\n        testdir.makepyfile(**COLLECTION_ERROR_PY_FILES)\n\n        res = testdir.runpytest(\"--continue-on-collection-errors\", \"--maxfail=3\")\n        assert res.ret == 1\n\n        res.stdout.fnmatch_lines([\"collected 2 items / 2 errors\", \"*1 failed, 2 errors*\"])\n"], "sample_734": ["def test_homogeneity_completeness_v_measure():\n    # Check that homogeneity, completeness and V-measure are correctly\n    # computed for different clusterings\n    h, c, v = homogeneity_completeness_v_measure(\n        [0, 0, 1, 1, 2, 2],\n        [0, 0, 1, 1, 1, 1])\n    assert_almost_equal(h, 0.58, 2)\n    assert_almost_equal(c, 1.00, 2)\n    assert_almost_equal(v, 0.73, 2)\n\n    h, c, v = homogeneity_completeness_v_measure(\n        [0, 0, 0, 1, 1, 1],\n        [0, 1, 0, 1, 2, 2])\n    assert_almost_equal(h, 0.67, 2)\n    assert_almost_equal(c, 0.42, 2)\n    assert_almost_equal(v, 0.52, 2)\n\n    h, c, v = homogeneity_completeness_v_measure(\n        [0, 0, 0, 2, 2, 2],\n        [0, 1, 0, 1, 2, 2])\n    assert_almost_equal(h, 0.67, 2)\n    assert_almost_equal(c, 0.42, 2)\n    assert_almost_equal(v, 0.52, 2)\n\n    h, c, v = homogeneity_completeness_v_measure(\n        [0, 0, 0, 1, 1, 1],\n        [0, 4, 0, 4, 2, 2])\n    assert_almost_equal(h, 0.67, 2)\n    assert_almost_equal(c, 0.42, 2)\n    assert_almost_equal(v, 0.52, 2)\n\n    # Test with a very large array\n    a110 = np.array([list([0, 0, 0, 1, 1, 1]) * 110]).flatten()\n    b110 = np.array([list([0, 1, 0, 1, 2, 2]) * 110]).flatten()\n    h, c, v = homogeneity_completeness_v_measure(a110, b110)\n    assert_almost"], "sample_240": ["def test_token_with_different_password(self):\n    \"\"\"\n    A valid token can be created with a password other than the one used to\n    create the user.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    tk1 = p0.make_token(user)\n    user.set_password('newpw')\n    user.save()\n    self.assertIs(p0.check_token(user, tk1), False)\n    # Create and check a token with the new password.\n    tk2 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk2), True)\n"], "sample_1169": ["def test_FockStateFermionKet():\n    i, j, k, l = symbols('i j k l', below_fermi=True)\n    a, b, c, d = symbols('a b c d', above_fermi=True)\n    p, q, r, s = symbols('p q r s')\n    assert FKet([]) == FKet([])\n    assert FKet([i]) == FKet([i])\n    assert FKet([i, j]) == FKet([i, j])\n    assert FKet([i, j, k]) == FKet([i, j, k])\n    assert FKet([i, j, k, l]) == FKet([i, j, k, l])\n    assert FKet([i, j, k, l, a]) == FKet([i, j, k, l, a])\n    assert FKet([i, j, k, l, a, b]) == FKet([i, j, k, l, a, b])\n    assert FKet([i, j, k, l, a, b, c]) == FKet([i, j, k, l, a, b, c])\n    assert FKet([i, j, k, l, a, b, c, d]) == FKet([i, j, k, l, a, b, c, d])\n    assert FKet([i, j, k, l, a, b, c, d, p]) == FKet([i, j, k, l, a, b, c, d, p])\n    assert FKet([i, j, k, l, a, b, c, d, p, q]) == FKet([i, j, k, l, a, b, c, d, p, q])\n    assert FKet([i, j, k, l, a, b, c, d, p, q, r]) == FKet([i, j, k, l, a, b, c, d, p, q, r])\n    assert FKet([i, j, k, l, a, b, c, d, p, q, r, s]) == FKet([i, j, k, l, a, b, c, d, p, q, r, s])\n    assert FKet([i, j"], "sample_370": ["    def test_prefetch_related_manager(self):\n        with self.assertNumQueries(2):\n            qs = Author.objects.prefetch_related('books')\n            manager = qs[0].books\n            self.assertEqual(manager.model, Book)\n            self.assertEqual(manager.instance, self.author1)\n            self.assertEqual(manager._db, None)\n            self.assertEqual(manager._db_for_write, None)\n            self.assertEqual(manager._db_for_read, None)\n            self.assertEqual(manager._db, None)\n            self.assertEqual(manager._db_for_write, None)\n            self.assertEqual(manager._db_for_read, None)\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._prefetched_objects_cache, {})\n            self.assertEqual(manager._"], "sample_1079": ["def test_orthogonal_direction():\n    p1 = Point(1, 2)\n    p2 = Point(3, 4)\n    assert p1.orthogonal_direction == Point(-2, 1)\n    p3 = Point(0, 0)\n    assert p3.orthogonal_direction == Point(1, 0)\n    p4 = Point(1, 0)\n    assert p4.orthogonal_direction == Point(0, 1)\n    p5 = Point(0, 1)\n    assert p5.orthogonal_direction == Point(-1, 0)\n    p6 = Point(0, 0, 1)\n    assert p6.orthogonal_direction == Point(-1, 0, 0)\n    p7 = Point(0, 0, 0)\n    assert p7.orthogonal_direction == Point(-1, 0, 0)\n    p8 = Point(0, 1, 0)\n    assert p8.orthogonal_direction == Point(0, 0, -1)\n    p9 = Point(0, 0, 0)\n    assert p9.orthogonal_direction == Point(0, 0, -1)\n    p10 = Point(1, 0, 0)\n    assert p10.orthogonal_direction == Point(0, -1, 0)\n    p11 = Point(0, 0, 0)\n    assert p11.orthogonal_direction == Point(0, -1, 0)\n    p12 = Point(0, 0, 1)\n    assert p12.orthogonal_direction == Point(1, 0, 0)\n    p13 = Point(0, 0, 0)\n    assert p13.orthogonal_direction == Point(1, 0, 0)\n    p14 = Point(0, 1, 0)\n    assert p14.orthogonal_direction == Point(0, 0, 1)\n    p15 = Point(0, 0, 0)\n    assert p15.orthogonal_direction == Point(0, 0, 1)\n    p16 = Point(1, 0, 0)\n    assert p16.orthogonal_direction == Point(0, 1, 0)\n    p17 = Point(0, 0, 0)\n    assert p17.orth"], "sample_338": ["def test_alter_field_with_default(self):\n    \"\"\"#23609 - Altering a field with a default should work.\"\"\"\n    changes = self.get_changes([self.author_name], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, 'testapp', 0, 0, default='Ada Lovelace')\n"], "sample_866": ["def test_affinity_propagation_fit_predict_non_convergence_regressiontest():\n    # In case of non-convergence of affinity_propagation(), the cluster\n    # centers should be an empty array and training samples should be labelled\n    # as noise (-1)\n    X = np.array([[0, 0], [1, 1], [-2, -2]])\n\n    # Force non-convergence by allowing only a single iteration\n    af = AffinityPropagation(preference=-10, max_iter=1)\n\n    assert_warns(ConvergenceWarning, af.fit_predict, X)\n    assert_array_equal(np.array([-1, -1, -1]), af.labels_)\n"], "sample_64": ["    def test_content_type(self):\n        r = HttpResponse()\n        self.assertEqual(r['Content-Type'], 'text/html; charset=utf-8')\n        r['Content-Type'] = 'text/plain'\n        self.assertEqual(r['Content-Type'], 'text/plain')\n        self.assertEqual(r.charset, 'utf-8')\n        r.charset = 'latin-1'\n        self.assertEqual(r.charset, 'latin-1')\n        self.assertEqual(r['Content-Type'], 'text/plain; charset=latin-1')\n"], "sample_241": ["    def test_deconstruct(self):\n        f = F('name')\n        path, args, kwargs = f.deconstruct()\n        self.assertEqual(path, 'django.db.models.expressions.F')\n        self.assertEqual(args, (f.name,))\n        self.assertEqual(kwargs, {})\n"], "sample_81": ["    def test_reverse(self):\n        resolver = get_resolver()\n        view = lambda request: None\n        url_pattern = URLPattern(RegexPattern(_('translated/')), view)\n        resolver.urlconf_module = {'urlpatterns': [url_pattern]}\n        self.assertEqual(resolver.reverse('translated/'), '/translated/')\n        self.assertEqual(resolver.reverse('translated/', kwargs={'foo': 'bar'}), '/translated/?foo=bar')\n        with self.assertRaises(NoReverseMatch):\n            resolver.reverse('non_existent_view')\n"], "sample_1082": ["def test_acsch_expansion():\n    x, y = symbols('x,y')\n    assert acsch(x+y).expand(trig=True) == acsch(x)*acsch(y) + csch(x)*csch(y)\n    assert acsch(2*x).expand(trig=True) == 2*acsch(x)*csch(x)\n    assert acsch(3*x).expand(trig=True).expand() == \\\n        acsch(x)**3 + 3*acsch(x)*csch(x)**2\n"], "sample_438": ["def test_get_object_cache_respects_related_objects(self):\n    question = Question.objects.create(text=\"Who?\")\n    post1 = Post.objects.create(title=\"Answer 1\", parent=question)\n    post2 = Post.objects.create(title=\"Answer 2\", parent=question)\n\n    question_pk = question.pk\n    Question.objects.all().delete()\n\n    post1 = Post.objects.get(pk=post1.pk)\n    post2 = Post.objects.get(pk=post2.pk)\n    with self.assertNumQueries(1):\n        self.assertEqual(post1.object_id, question_pk)\n        self.assertEqual(post1.parent, question)\n        self.assertEqual(post2.object_id, question_pk)\n        self.assertEqual(post2.parent, question)\n"], "sample_897": ["def test_plot_partial_dependence_centered(\n    pyplot,\n    kind,\n    centered,\n    subsample,\n    shape,\n    clf_diabetes,\n    diabetes,"], "sample_118": ["def test_year_lookup(self):\n    # Year lookup can be performed using a direct value\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n            '<Article: Article 1>',\n        ]\n    )\n    # Year lookup can be performed using a direct value with exact lookup\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__exact=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n            '<Article: Article 1>',\n        ]\n    )\n    # Year lookup can be performed using a direct value with gt lookup\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gt=2005),\n        ['<Article: Article 5>', '<Article: Article 6>']\n    )\n    # Year lookup can be performed using a direct value with gte lookup\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gte=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n            '<Article: Article 1>',\n        ]\n    )\n    # Year lookup can be performed using a direct value with lt lookup\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lt=2005),\n        []\n    )\n    # Year lookup can be performed using a direct value with lte lookup\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lte=2005),\n        [\n            '<Article: Article 5>',\n            '<Article: Article 6>',\n            '<Article: Article 4>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 7>',\n            '<Article: Article 1>',\n        ]\n    )\n"], "sample_101": ["    def test_get(self):\n        \"\"\"\n        GET property returns a QueryDict instance.\n        \"\"\"\n        environ = self.request_factory._base_environ(\n            PATH_INFO=\"/\",\n            CONTENT_TYPE=\"application/x-www-form-urlencoded\",\n            REQUEST_METHOD=\"GET\",\n            QUERY_STRING=\"a=1&b=2\"\n        )\n\n        request = WSGIRequest(environ)\n\n        self.assertIsInstance(request.GET, QueryDict)\n        self.assertEqual(request.GET, {'a': ['1'], 'b': ['2']})\n"], "sample_86": ["def test_lazy_proxy_unpickle(self):\n    \"\"\"\n    Test that lazy proxy objects can be unpickled correctly.\n    \"\"\"\n        return 42\n\n    lazy_obj = lazy(func, int)()\n    pickled_obj = pickle.dumps(lazy_obj)\n    unpickled_obj = pickle.loads(pickled_obj)\n    self.assertEqual(unpickled_obj, 42)\n"], "sample_595": ["def test_isnumeric():\n    # 0x00bc: \u00bc VULGAR FRACTION ONE QUARTER\n    # 0x2605: \u2605 not number\n    # 0x1378: \u1378 ETHIOPIC NUMBER SEVENTY\n    # 0xFF13: \uff13 Em 3\n    values = [\"A\", \"3\", \"\u00bc\", \"\u2605\", \"\u1378\", \"\uff13\", \"four\"]\n    s = xr.DataArray(values)\n    numeric_e = [False, True, True, False, True, True, False]\n    decimal_e = [False, True, False, False, False, True, False]\n    assert_equal(s.str.isnumeric(), xr.DataArray(numeric_e))\n    assert_equal(s.str.isdecimal(), xr.DataArray(decimal_e))\n"], "sample_771": ["def test_power_transformer_inverse_transform_shape_exception():\n    # Exceptions should be raised for arrays with different num_columns\n    # than during fitting\n    pt = PowerTransformer(method='yeo-johnson')\n    X = np.abs(X_2d)\n    pt.fit(X)\n\n    # Exceptions should be raised for arrays with different num_columns\n    # than during fitting\n    wrong_shape_message = 'Input data has a different number of features'\n\n    assert_raise_message(ValueError, wrong_shape_message,\n                         pt.inverse_transform, X[:, 0:1])\n"], "sample_513": ["def test_legend_title_fontsize():\n    # test the title_fontsize kwarg\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontsize=22)\n    assert leg.get_title().get_fontsize() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontsize() == 20\n"], "sample_664": ["def test_funcargnames_deprecation(testdir):\n    \"\"\"Check that funcargnames is deprecated and raises a warning.\"\"\"\n    testdir.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    result = testdir.runpytest(\"--pyargs\", \"test_funcargnames_deprecation\")\n    result.stdout.fnmatch_lines([\"*The `funcargnames` attribute was an alias for `fixturenames`, *\"])\n"], "sample_823": ["def test_pairwise_distances_argmin_min_sparse():\n    # Check pairwise minimum distances computation for any metric\n    X = [[0], [1]]\n    Y = [[-2], [3]]\n    Xsp = csr_matrix(X)\n    Ysp = csr_matrix(Y, dtype=np.float32)\n\n    expected_idx = [0, 1]\n    expected_vals = [2, 2]\n    expected_vals_sq = [4, 4]\n\n    # euclidean metric\n    idx, vals = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"euclidean\")\n    idx2 = pairwise_distances_argmin(Xsp, Ysp, metric=\"euclidean\")\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(idx2, expected_idx)\n    assert_array_almost_equal(vals, expected_vals)\n    # sparse matrix case\n    idxsp, valssp = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"euclidean\")\n    assert_array_almost_equal(idxsp, expected_idx)\n    assert_array_almost_equal(valssp, expected_vals)\n    # We don't want np.matrix here\n    assert_equal(type(idxsp), np.ndarray)\n    assert_equal(type(valssp), np.ndarray)\n\n    # euclidean metric squared\n    idx, vals = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"euclidean\",\n                                              metric_kwargs={\"squared\": True})\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(vals, expected_vals_sq)\n\n    # Non-euclidean scikit-learn metric\n    idx, vals = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"manhattan\")\n    idx2 = pairwise_distances_argmin(Xsp, Ysp, metric=\"manhattan\")\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(idx2, expected_idx)\n    assert_array_almost_equal(vals, expected_vals)\n    # sparse matrix case\n    idxsp, valssp = pairwise_distances_argmin_min(Xsp, Ysp, metric=\"manhattan\")\n    assert_array_almost_equal(idxsp, expected_idx)\n    assert_array_almost_equal(valssp, expected_vals)\n\n    # Non-euclidean Scipy distance (callable)\n    idx, vals = pairwise_distances_argmin_min(Xsp, Ysp, metric=minkowski,\n                                              metric_kwargs={\"p\": 2})\n    assert_array_almost_equal(idx, expected_idx)\n    assert_array_almost_equal(vals, expected_vals"], "sample_824": ["def test_pairwise_distances_chunked_sparse():\n    # Test the pairwise_distance helper function.\n    rng = np.random.RandomState(0)\n    # Euclidean distance should be equivalent to calling the function.\n    X = rng.random_sample((400, 4))\n    X_sparse = csr_matrix(X)\n    check_pairwise_distances_chunked(X_sparse, None, working_memory=1,\n                                     metric='euclidean')\n    # Test small amounts of memory\n    for power in range(-16, 0):\n        check_pairwise_distances_chunked(X_sparse, None, working_memory=2 ** power,\n                                         metric='euclidean')\n    # X as list\n    check_pairwise_distances_chunked(X_sparse.todense().tolist(), None,\n                                     working_memory=1, metric='euclidean')\n    # Euclidean distance, with Y != X.\n    Y = rng.random_sample((200, 4))\n    Y_sparse = csr_matrix(Y)\n    check_pairwise_distances_chunked(X_sparse, Y_sparse, working_memory=1,\n                                     metric='euclidean')\n    check_pairwise_distances_chunked(X_sparse.todense().tolist(),\n                                     Y_sparse.todense().tolist(), working_memory=1,\n                                     metric='euclidean')\n    # absurdly large working_memory\n    check_pairwise_distances_chunked(X_sparse, Y_sparse, working_memory=10000,\n                                     metric='euclidean')\n    # \"cityblock\" uses scikit-learn metric, cityblock (function) is\n    # scipy.spatial.\n    check_pairwise_distances_chunked(X_sparse, Y_sparse, working_memory=1,\n                                     metric='cityblock')\n    # Test that a value error is raised if the metric is unknown\n    assert_raises(ValueError, next,\n                  pairwise_distances_chunked(X_sparse, Y_sparse, metric=\"blah\"))\n\n    # Test precomputed returns all at once\n    D = pairwise_distances(X_sparse)\n    gen = pairwise_distances_chunked(D,\n                                     working_memory=2 ** -16,\n                                     metric='precomputed')\n    assert isinstance(gen, GeneratorType)\n    assert next(gen) is D\n    assert_raises(StopIteration, next, gen)\n"], "sample_352": ["        def as_sql(self, compiler, connection):\n            return 'dummy', []\n"], "sample_574": ["    def x(self):\n        return pd.Series([1, 10, 100], name=\"x\", dtype=float)\n"], "sample_492": ["def test_serialize_deconstructible_class(self):\n    class DeconstructibleClass:\n            return (\"DeconstructibleClass\", [], {})\n\n    self.assertSerializedResultEqual(\n        DeconstructibleClass(),\n        (\"migrations.test_writer.DeconstructibleClass\", {\"import migrations.test_writer\"}),\n    )\n"], "sample_599": ["def test_CFScaleOffsetCoder_decode_offset():\n    original = xr.Variable((\"x\",), [0, 10, 20], {\"add_offset\": 10})\n    expected = xr.Variable((\"x\",), [0, 0, 10])\n    coder = variables.CFScaleOffsetCoder()\n    encoded = coder.decode(original)\n    assert_identical(expected, encoded)\n"], "sample_1094": ["def test_sort_key():\n    x, y, z = symbols('x y z')\n    assert Basic(x + y, z).sort_key() == (5, 0, 'Basic') + (1, (x + y, z),) + (1, (x, y, z),) + (1, (1,),)\n    assert Basic(x + y, z).sort_key(order='lex') == (5, 0, 'Basic') + (1, (x + y, z),) + (1, (x, y, z),) + (1, (1,),)\n    assert Basic(x + y, z).sort_key(order='grlex') == (5, 0, 'Basic') + (1, (x + y, z),) + (1, (x, y, z),) + (1, (1,))\n    assert Basic(x + y, z).sort_key(order='grlex') == (5, 0, 'Basic') + (1, (x + y, z),) + (1, (x, y, z),) + (1, (1,))\n    assert Basic(x + y, z).sort_key(order='lex') == (5, 0, 'Basic') + (1, (x + y, z),) + (1, (x, y, z),) + (1, (1,))\n    assert Basic(x + y, z).sort_key(order='grlex') == (5, 0, 'Basic') + (1, (x + y, z),) + (1, (x, y, z),) + (1, (1,))\n    assert Basic(x + y, z).sort_key(order='lex') == (5, 0, 'Basic') + (1, (x + y, z),) + (1, (x, y, z),) + (1, (1,))\n    assert Basic(x + y, z).sort_key(order='grlex') == (5, 0, 'Basic') + (1, (x + y, z),) + (1, (x, y, z),) + (1, (1,))\n    assert Basic(x + y, z).sort_key(order='lex') == (5, 0, 'Basic') + (1, (x + y, z),) + (1"], "sample_1197": ["def test_get_dimension_system():\n    u = Quantity(\"u\")\n    u.set_global_relative_scale_factor(S(10), meter)\n    assert u.get_dimension_system() == SI.get_dimension_system()\n    assert u.get_dimension_system() is u.get_dimension_system()\n    assert u.get_dimension_system() is not None\n"], "sample_428": ["def test_format_large_decimal(self):\n    # Test large decimal numbers.\n    large_decimal = Decimal(\"17976931348623157081452742373170435679807056752584499659891747680315726078002853876058955863276687817154045895351438246423432132688946418276846754670353751698604991057655128207624549009038932894407586850845513394230458323690322294816580855933212334827479782620414472316873817718091929988125040402618412485836)\n    self.assertEqual(nformat(large_decimal, \".\"), \"17976931348623157081452742373170435679807056752584499659891747680315726078002853876058955863276687817154045895351438246423432132688946418276846754670353751698604991057655128207624549009038932894407586850845513394230458323690322294816580855933212334827479782620414472316873817718091929988125040402618412485836\")\n    self.assertEqual(nformat(large_decimal, \".\", decimal_pos=2), \"17976931348623157081452742373170435679807056752584499659891747680315726078002853876058955863276687817154045895351438246423432132688946418276846754670353751698604991057655128207624549009038932894407586850845513394230458323690322294816580855933212334827479782620414472316873817718091929988125040402618412485836.00\")\n    self.assertEqual(nformat(large_decimal, \".\", grouping=2, thousand_sep=\",\"), \"17976931348623157081452742373170435679807056752584499659891747680315726078002853876058955863276687817154045895351438246423432132688946418276846754670353751698604991057655128207624549009038932894407586850845513394230458323690322294816580855933212334827479782620414472316873817718091929988125040402618412485836\")\n    self.assertEqual(nformat(large_decimal, \".\", grouping=2, thousand_sep=\",\", force_grouping=True),"], "sample_1113": ["def test_block_inverse():\n    n, m, k = symbols('n m k', integer=True, positive=True)\n    i, j = symbols('i j', integer=True, nonnegative=True)\n    A1 = MatrixSymbol('A1', n, n)\n    A2 = MatrixSymbol('A2', n, m)\n    A3 = MatrixSymbol('A3', n, k)\n    A4 = MatrixSymbol('A4', m, n)\n    A5 = MatrixSymbol('A5', m, m)\n    A6 = MatrixSymbol('A6', m, k)\n    A7 = MatrixSymbol('A7', k, n)\n    A8 = MatrixSymbol('A8', k, m)\n    A9 = MatrixSymbol('A9', k, k)\n    A = BlockMatrix([[A1, A2, A3], [A4, A5, A6], [A7, A8, A9]])\n    A_inv = A.inv()\n    assert A_inv.structurally_equal(A.inv())\n    assert A_inv.as_explicit().equals(A.inv().as_explicit())\n"], "sample_402": ["def test_prepend_www_append_slash_slashless_custom_urlconf(self):\n    \"\"\"\n    APPEND_SLASH should prepend www. to slashless URLs in custom URLconf.\n    \"\"\"\n    request = self.rf.get(\"/customurlconf/slash\")\n    request.urlconf = \"middleware.extra_urls\"\n    r = CommonMiddleware(get_response_empty).process_request(request)\n    self.assertEqual(r.status_code, 301)\n    self.assertEqual(r.url, \"http://www.testserver/customurlconf/slash/\")\n"], "sample_29": ["def test_write_latex_invalid_format(self, write):\n    \"\"\"Test passing an invalid format.\"\"\"\n    fp = tmp_path / \"test_write_latex_invalid_format.tex\"\n    with pytest.raises(ValueError, match=\"format must be 'latex', not\"):\n        write(fp, format=\"pdf\")\n"], "sample_833": ["def test_logistic_regression_path_multinomial():\n    # Test that the path algorithm is consistent for the multinomial case.\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = np.array([1] * 100 + [-1] * 100)\n    Cs = np.logspace(0, 4, 10)\n\n    for solver in ['sag', 'saga']:\n        coefs, Cs, _ = _logistic_regression_path(\n            X, y, Cs=Cs, fit_intercept=False, tol=1e-5, solver=solver,\n            multi_class='multinomial', random_state=0)\n        for i, C in enumerate(Cs):\n            lr = LogisticRegression(C=C, fit_intercept=False, tol=1e-5,\n                                    solver=solver, multi_class='multinomial',\n                                    random_state=0)\n            lr.fit(X, y)\n            lr_coef = lr.coef_.ravel()\n            assert_array_almost_equal(lr_coef, coefs[i], decimal=4,\n                                      err_msg=\"with solver = %s\" % solver)\n\n    # test for fit_intercept=True\n    for solver in ('lbfgs', 'newton-cg'):\n        Cs = [1e3]\n        coefs, Cs, _ = _logistic_regression_path(\n            X, y, Cs=Cs, fit_intercept=True, tol=1e-6, solver=solver,\n            intercept_scaling=10000., random_state=0, multi_class='multinomial')\n        lr = LogisticRegression(C=Cs[0], fit_intercept=True, tol=1e-4,\n                                intercept_scaling=10000., random_state=0,\n                                multi_class='multinomial', solver=solver)\n        lr.fit(X, y)\n        lr_coef = np.concatenate([lr.coef_.ravel(), lr.intercept_])\n        assert_array_almost_equal(lr_coef, coefs[0], decimal=4,\n                                  err_msg=\"with solver = %s\" % solver)\n"], "sample_384": ["    def test_update_with_update_conflicts(self):\n        Note.objects.bulk_create([Note(note=\"test\", misc=\"test\") for _ in range(10)])\n        Note.objects.bulk_update(\n            [Note.objects.get(id=1), Note.objects.get(id=2)],\n            fields=[\"note\"],\n            update_conflicts=True,\n            update_fields=[\"note\"],\n            unique_fields=[\"id\"],\n        )\n        self.assertEqual(Note.objects.get(id=1).note, \"test\")\n        self.assertEqual(Note.objects.get(id=2).note, \"test\")\n"], "sample_91": ["def test_csrf_token_in_403(self):\n    \"\"\"\n    The 403 page should have the csrf_token available in the context\n    \"\"\"\n    # See ticket #14565\n    for url in self.nonexistent_urls:\n        response = self.client.get(url)\n        self.assertNotEqual(response.content, b'NOTPROVIDED')\n        self.assertNotEqual(response.content, b'')\n"], "sample_83": ["    def setUp(self):\n        self.library = Library()\n"], "sample_512": ["def test_matshow():\n    fig, ax = plt.subplots()\n    matshow(np.array([[1, 2], [3, 4]]))\n    assert ax.get_images()[0].get_array().shape == (2, 2)\n    assert ax.get_images()[0].get_array().tolist() == [[1, 2], [3, 4]]\n"], "sample_821": ["def test_affinity_propagation_damping():\n    # Test AffinityPropagation with damping\n    af = AffinityPropagation(damping=0.9)\n    labels = af.fit(X).labels_\n    assert_array_equal(np.unique(labels), np.array([0, 1, 2]))\n\n    af = AffinityPropagation(damping=0.5)\n    labels = af.fit(X).labels_\n    assert_array_equal(np.unique(labels), np.array([0, 1, 2]))\n\n    # Test damping out of range\n    af = AffinityPropagation(damping=0.4)\n    assert_raises(ValueError, af.fit, X)\n\n    af = AffinityPropagation(damping=1.1)\n    assert_raises(ValueError, af.fit, X)\n"], "sample_69": ["    def test_iter_modules_and_files_cache(self):\n        \"\"\"\n        iter_modules_and_files() uses functools.lru_cache. Test that it's\n        working correctly.\n        \"\"\"\n        filename = self.temporary_file('test_module.py')\n        filename.write_text('import os')\n        with extend_sys_path(str(filename.parent)):\n            self.import_and_cleanup('test_module')\n        self.assertFileFound(filename)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().hits, 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().misses, 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().maxsize, 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().currsize, 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().get(autoreload.iter_modules_and_files.cache_info().keys()[0]), (filename,))\n"], "sample_1191": ["def test_hermite_normal_form():\n    m = DM([[12, 6, 4], [3, 9, 6], [2, 16, 14]], ZZ)\n    hnf = DM([[10, 0, 2], [0, 15, 3], [0, 0, 2]], ZZ)\n    assert hermite_normal_form(m).to_dense() == hnf\n\n    m = DM([[1, 0, 0], [0, 1, 0], [0, 0, 1]], ZZ)\n    assert hermite_normal_form(m).to_dense() == m\n\n    m = DM([[2, 0], [0, 2]], ZZ)\n    assert hermite_normal_form(m).to_dense() == m\n\n    m = DM([[2, 0, 0], [0, 2, 0], [0, 0, 2]], ZZ)\n    assert hermite_normal_form(m).to_dense() == m\n\n    m = DM([[2, 0, 0], [0, 3, 0], [0, 0, 4]], ZZ)\n    hnf = DM([[1, 0, 0], [0, 3, 0], [0, 0, 4], [0, 0, 0]], ZZ)\n    assert hermite_normal_form(m).to_dense() == hnf\n\n    m = DM([[2, 0, 0], [0, 3, 0], [0, 0, 4], [0, 0, 0]], ZZ)\n    assert hermite_normal_form(m).to_dense() == m\n\n    m = DM([[2, 0, 0], [0, 3, 0], [0, 0, 4], [0, 0, 0], [0, 0, 0]], ZZ)\n    assert hermite_normal_form(m).to_dense() == m\n\n    m = DM([[2, 0, 0], [0, 3, 0], [0, 0, 4], [0, 0, 0], [0, 0, 0], [0, 0, 0]], ZZ)\n    assert hermite_normal_form(m).to_dense() == m\n\n    m = DM([[2,"], "sample_885": ["def test_interval_real_not_int():\n    \"\"\"Check that the Interval constraint for real numbers does not accept integers.\"\"\"\n    interval = Interval(Real, 0, 1, closed=\"both\")\n    assert not interval.is_satisfied_by(0)\n    assert not interval.is_satisfied_by(1)\n    assert interval.is_satisfied_by(0.5)\n    assert interval.is_satisfied_by(0.42)\n"], "sample_954": ["def test_manpage_with_productionlist(app, status, warning):\n    app.builder.build_all()\n    content = (app.outdir / 'sphinxtests.1').read_text()\n    assert r'\\fBproduction list\\n' in content\n    assert r'\\fBterm1\\n' in content\n    assert r'\\fBterm2\\n' in content\n    assert r'\\fBterm3\\n' in content\n    assert r'\\fBterm4\\n' in content\n    assert r'\\fBterm5\\n' in content\n    assert r'\\fBterm6\\n' in content\n    assert r'\\fBterm7\\n' in content\n    assert r'\\fBterm8\\n' in content\n    assert r'\\fBterm9\\n' in content\n    assert r'\\fBterm10\\n' in content\n    assert r'\\fBterm11\\n' in content\n    assert r'\\fBterm12\\n' in content\n    assert r'\\fBterm13\\n' in content\n    assert r'\\fBterm14\\n' in content\n    assert r'\\fBterm15\\n' in content\n    assert r'\\fBterm16\\n' in content\n    assert r'\\fBterm17\\n' in content\n    assert r'\\fBterm18\\n' in content\n    assert r'\\fBterm19\\n' in content\n    assert r'\\fBterm20\\n' in content\n    assert r'\\fBterm21\\n' in content\n    assert r'\\fBterm22\\n' in content\n    assert r'\\fBterm23\\n' in content\n    assert r'\\fBterm24\\n' in content\n    assert r'\\fBterm25\\n' in content\n    assert r'\\fBterm26\\n' in content\n    assert r'\\fBterm27\\n' in content\n    assert r'\\fBterm28\\n' in content\n    assert r'\\fBterm29\\n' in content\n    assert r'\\fBterm30\\n' in content\n    assert r'\\fBterm31\\n' in content\n    assert r'\\fBterm32\\n' in content\n    assert r'\\fBterm33\\n' in content\n    assert r'\\fBterm34\\n' in content\n    assert r'\\fBterm35\\n' in content\n    assert r'\\"], "sample_321": ["    def _get_GET_csrf_cookie_request(self, cookie=None):\n        \"\"\"The cookie argument defaults to the valid test cookie.\"\"\"\n        if cookie is None:\n            cookie = self._csrf_id_cookie\n        req = TestingHttpRequest()\n        req.COOKIES[settings.CSRF_COOKIE_NAME] = cookie\n        return req\n"], "sample_796": ["def test_huber_alpha():\n    # Test that the regularization parameter alpha is correctly used\n    X, y = make_regression_with_outliers()\n    huber = HuberRegressor(fit_intercept=True, alpha=1.0, max_iter=100)\n    huber.fit(X, y)\n    huber_coef = huber.coef_.copy()\n    huber.fit(X, y, alpha=0.1)\n    assert_array_almost_equal(huber.coef_, huber_coef, 1)\n\n    # Test that the regularization parameter alpha is correctly used with warm start\n    huber_warm = HuberRegressor(\n        fit_intercept=True, alpha=1.0, max_iter=10000, warm_start=True,\n        tol=1e-1)\n    huber_warm.fit(X, y)\n    huber_warm_coef = huber_warm.coef_.copy()\n    huber_warm.fit(X, y, alpha=0.1)\n    assert_array_almost_equal(huber_warm.coef_, huber_warm_coef, 1)\n\n    # Test that the regularization parameter alpha is correctly used with sparse data\n    X_csr = sparse.csr_matrix(X)\n    huber_sparse = HuberRegressor(fit_intercept=True, alpha=1.0)\n    huber_sparse.fit(X_csr, y)\n    huber_sparse_coef = huber_sparse.coef_.copy()\n    huber_sparse.fit(X_csr, y, alpha=0.1)\n    assert_array_almost_equal(huber_sparse.coef_, huber_sparse_coef, 1)\n"], "sample_217": ["def test_media_property_overrides(self):\n    # Media properties can override the media of their parents\n    class MyWidget1(TextInput):\n        class Media:\n            css = {\n                'all': ('path/to/css1', '/path/to/css2')\n            }\n            js = ('/path/to/js1', 'http://media.other.com/path/to/js2', 'https://secure.other.com/path/to/js3')\n\n    class MyWidget2(MyWidget1):\n            return Media(css={'all': ('/other/path',)}, js=('/other/js',))\n        media = property(_media)\n\n    w2 = MyWidget2()\n    self.assertEqual(\n        str(w2.media),\n        \"\"\"<link href=\"/other/path\" type=\"text/css\" media=\"all\" rel=\"stylesheet\">"], "sample_28": ["def test_rvkc_keyword_update(self):\n    \"\"\"\n    Regression test for https://github.com/astropy/astropy/issues/11486\n\n    Tests updating the keyword of a record-valued keyword card.\n    \"\"\"\n\n    h = fits.Header()\n    h[\"DP1\"] = \"NAXIS: 2\"\n    h[\"DP1\"] = \"AXIS.1: 1\"\n    assert h[\"DP1\"] == \"AXIS.1: 1\"\n    assert h[\"DP1.NAXIS\"] == 2.0\n    assert h[\"DP1.AXIS.1\"] == 1.0\n\n    h[\"DP1\"] = \"AXIS.2: 2\"\n    assert h[\"DP1\"] == \"AXIS.2: 2\"\n    assert h[\"DP1.NAXIS\"] == 2.0\n    assert h[\"DP1.AXIS.1\"] == 1.0\n    assert h[\"DP1.AXIS.2\"] == 2.0\n\n    h[\"DP1\"] = \"NAXIS: 3\"\n    assert h[\"DP1\"] == \"NAXIS: 3\"\n    assert h[\"DP1.NAXIS\"] == 3.0\n    assert h[\"DP1.AXIS.1\"] == 1.0\n    assert h[\"DP1.AXIS.2\"] == 2.0\n\n    h[\"DP1\"] = \"AXIS.3: 3\"\n    assert h[\"DP1\"] == \"AXIS.3: 3\"\n    assert h[\"DP1.NAXIS\"] == 3.0\n    assert h[\"DP1.AXIS.1\"] == 1.0\n    assert h[\"DP1.AXIS.2\"] == 2.0\n    assert h[\"DP1.AXIS.3\"] == 3.0\n"], "sample_373": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n        with captured_stderr() as self.docutils_stderr:\n            self.response = self.client.get(reverse('django-admindocs-models-detail', args=['admin_docs', 'Person']))\n"], "sample_583": ["    def test_setitem(self):\n        original = np.arange(10)\n        wrapped = indexing.NumpyIndexingAdapter(original)\n        wrapped[B[:]] = 0\n        assert_array_equal(original, np.arange(10))\n        assert_array_equal(wrapped, np.zeros(10))\n"], "sample_762": ["def test_clone_transformer():\n    # Test that clone works for transformers\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.decomposition import PCA\n\n    scaler = StandardScaler()\n    pca = PCA(n_components=2)\n    transformer = Pipeline([('scaler', scaler), ('pca', pca)])\n\n    new_transformer = clone(transformer)\n    assert transformer is not new_transformer\n    assert_equal(transformer.get_params(), new_transformer.get_params())\n    assert_array_equal(transformer.transform([[1, 2]]), new_transformer.transform([[1, 2]]))\n"], "sample_296": ["def test_empty_cookie(self):\n    \"\"\"\n    When the cookie is empty, the storage should return an empty list.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n    self.assertEqual(list(storage), [])\n"], "sample_265": ["def test_templatetag_libraries_priority(self):\n    \"\"\"\n    Libraries passed in OPTIONS take precedence over discovered ones.\n    \"\"\"\n    engine = DjangoTemplates({\n        'DIRS': [],\n        'APP_DIRS': False,\n        'NAME': 'django',\n        'OPTIONS': {\n            'libraries': {\n                'alternate': 'django.templatetags.static',\n            },\n        },\n    })\n\n    self.assertEqual(\n        engine.engine.libraries['alternate'],\n        'django.templatetags.static',\n    )\n    self.assertEqual(\n        engine.engine.libraries['static'],\n        'django.templatetags.static',\n    )\n"], "sample_399": ["def test_aggregate_subquery_annotation_values_list(self):\n    \"\"\"\n    Subquery annotations and external aliases are excluded from the GROUP BY if\n    they are not selected.\n    \"\"\"\n    books_qs = (\n        Book.objects.annotate(\n            first_author_the_same_age=Subquery(\n                Author.objects.filter(\n                    age=OuterRef(\"contact__friends__age\"),\n                )\n                .order_by(\"age\")\n                .values(\"id\")[:1],\n            )\n        )\n        .filter(\n            publisher=self.p1,\n            first_author_the_same_age__isnull=False,\n        )\n        .annotate(\n            min_age=Min(\"contact__friends__age\"),\n        )\n        .values(\"name\", \"min_age\")\n        .order_by(\"name\")\n    )\n    self.assertEqual(\n        list(books_qs),\n        [\n            {\"name\": \"Practical Django Projects\", \"min_age\": 34},\n            {\n                \"name\": (\n                    \"The Definitive Guide to Django: Web Development Done Right\"\n                ),\n                \"min_age\": 29,\n            },\n        ],\n    )\n\n    books_qs = (\n        Book.objects.annotate(\n            first_author_the_same_age=Subquery(\n                Author.objects.filter(\n                    age=OuterRef(\"contact__friends__age\"),\n                )\n                .order_by(\"age\")\n                .values(\"id\")[:1],\n            )\n        )\n        .filter(\n            publisher=self.p1,\n            first_author_the_same_age__isnull=False,\n        )\n        .annotate(\n            min_age=Min(\"contact__friends__age\"),\n        )\n        .values_list(\"name\", \"min_age\")\n        .order_by(\"name\")\n    )\n    self.assertEqual(\n        list(books_qs),\n        [\n            (\"Practical Django Projects\", 34),\n            (\n                \"The Definitive Guide to Django: Web Development Done Right\",\n                29,\n            ),\n        ],\n    )\n\n    books_qs = (\n        Book.objects.annotate(\n            first_author_the_same_age=Subquery(\n                Author.objects.filter(\n                    age=OuterRef(\"contact__friends__age\"),\n                )\n                .order_by(\"age\")\n                .values(\"id\")[:1],\n            )\n        )\n        .filter(\n            publisher=self.p1,\n            first_author_the_same_age__isnull=False,\n        )\n        .annotate(\n            min_age=Min(\"contact__friends__age\"),\n        )\n        .values_list(\"name\", flat=True)\n        .order_by(\"name\")\n   "], "sample_515": ["def test_colorbar_alpha():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[0, 1], [2, 3]], alpha=0.3)\n    cb = fig.colorbar(im)\n    assert cb.alpha is None\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n    cb.set_alpha([0.5, 0.7])\n    assert cb.alpha is None\n    cb.set_alpha([0.5, 0.7, 0.9])\n    assert cb.alpha is None\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n    cb.set_alpha([0.5, 0.7])\n    assert cb.alpha is None\n    cb.set_alpha([0.5, 0.7, 0.9])\n    assert cb.alpha is None\n"], "sample_215": ["    def test_non_sensitive_request(self):\n        \"\"\"\n        Request info can bee seen in the default error reports for non-sensitive requests.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n\n        with self.settings(DEBUG=False):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n"], "sample_79": ["    def test_negative_integers(self):\n        self.assertEqual(pluralize(-1), '')\n        self.assertEqual(pluralize(-0), 's')\n        self.assertEqual(pluralize(-2), 's')\n"], "sample_559": ["def test_bar_label():\n    fig, ax = plt.subplots()\n    ax.bar([1, 2, 3], [1, 2, 3])\n    ax.bar_label(ax.containers[0], labels=['a', 'b', 'c'])\n    ax.set_title('bar_label demo')\n"], "sample_100": ["    def setUp(self):\n        self._tempdir = tempfile.TemporaryDirectory()\n        self.tempdir = Path(self._tempdir.name).resolve().absolute()\n        self.existing_file = self.ensure_file(self.tempdir / 'test.py')\n        self.nonexistent_file = (self.tempdir / 'does_not_exist.py').absolute()\n        self.reloader = autoreload.StatReloader()\n"], "sample_733": ["def test_hashingvectorizer_dtype():\n    # test that the dtype of the output is preserved\n    vect = HashingVectorizer(dtype=np.float32)\n    X = vect.fit_transform(ALL_FOOD_DOCS)\n    assert_equal(X.dtype, np.float32)\n"], "sample_937": ["def test_unparse_Starred():\n    source = \"1, 2, *3\"\n    expected = \"1, 2, *3\"\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].value) == expected\n"], "sample_340": ["def test_loading_replacing_migration(self):\n    \"\"\"\n    Tests loading a migration that replaces another migration.\n    \"\"\"\n    loader = MigrationLoader(connection)\n    recorder = MigrationRecorder(connection)\n    self.record_applied(recorder, 'migrations', '0001_initial')\n    self.record_applied(recorder, 'migrations', '0002_second')\n    loader.build_graph()\n    self.assertEqual(\n        len([x for x in loader.graph.nodes if x[0] == \"migrations\"]),\n        1,\n    )\n    self.assertEqual(\n        loader.graph.nodes[(\"migrations\", \"0002_second\")].replaces,\n        [(\"migrations\", \"0001_initial\")],\n    )\n"], "sample_1098": ["def test_hyper_period():\n    from sympy import hyper, pi, I, exp_polar\n    from sympy.abc import a, b, c, z\n    assert hyper((1, 2), [3], z).get_period() == 2*pi\n    assert hyper((1, 2, 3), [4], z).get_period() == 0\n    assert hyper((1, 2), (3, 4), z).get_period() == oo\n    assert hyper((0, 1, 2), [4], z).get_period() == oo\n    assert hyper((-1, 1, 2), [-4], z).get_period() == 0\n    assert hyper((-1, -2, 2), [-1], z).get_period() == oo\n    assert hyper((-1, 2), [-1, -2], z).get_period() == 0\n    assert hyper([-1, 1, 3], [-2, 2], z).get_period() == 2*pi\n    assert hyper([-1, 1], [-2, 2], z).get_period() == oo\n    assert hyper([-1, 1, 3], [-2], z).get_period() == 0\n    assert hyper((-1, 2, 3, 4), [], z).get_period() == oo\n\n    assert hyper([1, 1], [3], 1).get_period() == 2*pi\n    assert hyper([1, 1], [2], 1).get_period() == 0\n    assert hyper([1, 1], [2], -1).get_period() == 2*pi\n    assert hyper([1, 1], [1], -1).get_period() == 0\n"], "sample_801": ["def test_repr_with_nan():\n    # Test that repr handles NaN values correctly\n    imputer = SimpleImputer(strategy=\"mean\")\n    imputer.missing_values = np.nan\n    expected = \"\"\"SimpleImputer(strategy='mean')\"\"\"\n    assert imputer.__repr__() == expected\n\n    imputer = SimpleImputer(strategy=\"mean\")\n    imputer.missing_values = float('nan')\n    expected = \"\"\"SimpleImputer(strategy='mean')\"\"\"\n    assert imputer.__repr__() == expected\n\n    imputer = SimpleImputer(strategy=\"mean\")\n    imputer.missing_values = np.nan\n    imputer.fill_value = float('nan')\n    expected = \"\"\"SimpleImputer(strategy='mean')\"\"\"\n    assert imputer.__repr__() == expected\n\n    imputer = SimpleImputer(strategy=\"mean\")\n    imputer.missing_values = float('nan')\n    imputer.fill_value = np.nan\n    expected = \"\"\"SimpleImputer(strategy='mean')\"\"\"\n    assert imputer.__repr__() == expected\n\n    imputer = SimpleImputer(strategy=\"mean\")\n    imputer.missing_values = np.nan\n    imputer.fill_value = float('nan')\n    imputer.verbose = 1\n    expected = \"\"\"SimpleImputer(strategy='mean', verbose=1)\"\"\"\n    assert imputer.__repr__() == expected\n\n    imputer = SimpleImputer(strategy=\"mean\")\n    imputer.missing_values = float('nan')\n    imputer.fill_value = np.nan\n    imputer.verbose = 1\n    expected = \"\"\"SimpleImputer(strategy='mean', verbose=1)\"\"\"\n    assert imputer.__repr__() == expected\n"], "sample_192": ["    def test_non_form_errors_raised_by_clean(self):\n        class BaseCustomFormSet(BaseFormSet):\n                raise ValidationError(\"This is a non-form error\")\n\n        ChoiceFormSet = formset_factory(Choice, formset=BaseCustomFormSet)\n        data = {\n            'choices-TOTAL_FORMS': '1',\n            'choices-INITIAL_FORMS': '0',\n        }\n        formset = ChoiceFormSet(data, auto_id=False, prefix='choices')\n        self.assertIsInstance(formset.non_form_errors(), ErrorList)\n        self.assertEqual(list(formset.non_form_errors()), ['This is a non-form error'])\n"], "sample_878": ["def test_column_transformer_set_output_mixed_types():\n    \"\"\"Check ColumnTransformer outputs mixed types correctly.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    df = pd.DataFrame(\n        {\n            \"pet\": pd.Series([\"dog\", \"cat\", \"snake\"], dtype=\"category\"),\n            \"color\": pd.Series([\"green\", \"blue\", \"red\"], dtype=\"object\"),\n            \"age\": [1.4, 2.1, 4.4],\n            \"height\": [20, 40, 10],\n            \"distance\": pd.Series([20, pd.NA, 100], dtype=\"Int32\"),\n        }\n    )\n    ct = ColumnTransformer(\n        [\n            (\n                \"color_encode\",\n                OneHotEncoder(sparse_output=False, dtype=\"int8\"),\n                [\"color\"],\n            ),\n            (\"age\", StandardScaler(), [\"age\"]),\n        ],\n        verbose_feature_names_out=False,\n    ).set_output(transform=\"pandas\")\n    X_trans = ct.fit_transform(df)\n\n    assert isinstance(X_trans, pd.DataFrame)\n    assert_array_equal(X_trans.columns, ct.get_feature_names_out())\n\n    expected_dtypes = {\n        \"color_blue\": \"int8\",\n        \"color_green\": \"int8\",\n        \"color_red\": \"int8\",\n        \"age\": \"float64\",\n        \"pet\": \"category\",\n        \"height\": \"int64\",\n        \"distance\": \"Int32\",\n    }\n    for col, dtype in X_trans.dtypes.items():\n        assert dtype == expected_dtypes[col]\n"], "sample_33": ["def test_dtype_bytes_or_chars():\n    assert misc.dtype_bytes_or_chars(np.dtype('int32')) == 4\n    assert misc.dtype_bytes_or_chars(np.dtype('float64')) == 8\n    assert misc.dtype_bytes_or_chars(np.dtype('U5')) == 5\n    assert misc.dtype_bytes_or_chars(np.dtype('f8')) == 8\n    assert misc.dtype_bytes_or_chars(np.dtype('int32')) is None\n    assert misc.dtype_bytes_or_chars(np.dtype('object')) is None\n"], "sample_787": ["def test_balanced_accuracy_score_adjusted():\n    # Test balanced accuracy score with adjusted option\n    y_true = [0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1]\n    y_pred = [0, 1, 2, 0, 1, 2, 0, 1, 0, 0, 1, 0, 1, 0, 1]\n\n    # compute scores with default labels introspection\n    score = balanced_accuracy_score(y_true, y_pred)\n    adjusted_score = balanced_accuracy_score(y_true, y_pred, adjusted=True)\n\n    # The balanced accuracy is 0.33\n    assert_almost_equal(score, 0.33, 2)\n\n    # The adjusted balanced accuracy is 0.0\n    assert_almost_equal(adjusted_score, 0.0, 2)\n\n    # Test with binary classification\n    y_true = [0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1]\n    y_pred = [0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1]\n\n    # compute scores with default labels introspection\n    score = balanced_accuracy_score(y_true, y_pred)\n    adjusted_score = balanced_accuracy_score(y_true, y_pred, adjusted=True)\n\n    # The balanced accuracy is 0.33\n    assert_almost_equal(score, 0.33, 2)\n\n    # The adjusted balanced accuracy is 0.0\n    assert_almost_equal(adjusted_score, 0.0, 2)\n"], "sample_881": ["def test_top_k_accuracy_score_multiclass_with_labels_as_ndarray():\n    \"\"\"Test when labels and y_score are multiclass.\"\"\"\n    y_true = np.array([0, 1, 1, 2])\n    labels = np.array([0, 1, 2, 3])\n    y_score = np.array(\n        [\n            [0.4, 0.3, 0.2, 0.1],\n            [0.1, 0.4, 0.3, 0.2],\n            [0.4, 0.1, 0.2, 0.3],\n            [0.3, 0.2, 0.4, 0.1],\n        ]\n    )\n\n    score = top_k_accuracy_score(y_true, y_score, k=2, labels=labels)\n    assert score == pytest.approx(0.75)\n"], "sample_62": ["    def setUp(self):\n        self.site = admin.AdminSite()\n"], "sample_667": ["def test_getbasetemp_custom_removes_old_symlink(testdir):\n    mytemp = testdir.tmpdir.mkdir(\"xyz\")\n    p = testdir.makepyfile(\n        \"\"\"\n            pass\n    \"\"\"\n    )\n    testdir.runpytest(p, \"--basetemp=%s\" % mytemp)\n    mytemp.check()\n    mytemp.ensure(\"hello\")\n\n    testdir.runpytest(p, \"--basetemp=%s\" % mytemp)\n    mytemp.check()\n    assert not mytemp.join(\"hello\").check()\n\n    # create a symlink to the base temp dir\n    linktemp = testdir.tmpdir.join(\"symlinktemp\")\n    attempt_symlink_to(linktemp, str(mytemp))\n\n    testdir.runpytest(p, \"--basetemp=%s\" % linktemp)\n    mytemp.check()\n    assert not mytemp.join(\"hello\").check()\n"], "sample_427": ["    def test_custom_renderer(self):\n        \"\"\"\n        A custom renderer passed to a formset_factory() is passed to all forms\n        and ErrorList.\n        \"\"\"\n        from django.forms.renderers import Jinja2\n\n        renderer = Jinja2()\n        data = {\n            \"choices-TOTAL_FORMS\": \"2\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Zero\",\n            \"choices-0-votes\": \"\",\n            \"choices-1-choice\": \"One\",\n            \"choices-1-votes\": \"\",\n        }\n        ChoiceFormSet = formset_factory(Choice, renderer=renderer)\n        formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertEqual(formset.renderer, renderer)\n        self.assertEqual(formset.forms[0].renderer, renderer)\n        self.assertEqual(formset.management_form.renderer, renderer)\n        self.assertEqual(formset.non_form_errors().renderer, renderer)\n        self.assertEqual(formset.empty_form.renderer, renderer)\n"], "sample_119": ["def test_group_by(self):\n    query = Query(Author)\n    where = query.build_where(Q(num__gt=2))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertEqual(lookup.rhs, 2)\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('num'))\n    query.set_group_by()\n    self.assertEqual(query.group_by, (Author._meta.get_field('num'),))\n"], "sample_379": ["def test_mark_safe_decorator_does_not_affect_non_callable(self):\n    \"\"\"\n    mark_safe doesn't affect non-callable objects.\n    \"\"\"\n    s = 'a&b'\n    self.assertIs(mark_safe(s), s)\n"], "sample_901": ["def test_k_means_init_callable():\n    # Test that a callable init function is properly called\n        return np.array([[0, 0], [1, 1]])\n\n    km = KMeans(init=test_init, n_clusters=2, random_state=42)\n    km.fit(X)\n    _check_fitted_model(km)\n"], "sample_557": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect((1, 2, 3))\n    ax2.set_box_aspect((2, 1, 1))\n"], "sample_412": ["def test_avoid_wrapping(self):\n    items = (\n        (\"Hello, world!\", \"Hello, world!\"),\n        (\"Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!  Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello,"], "sample_151": ["def test_alter_field_to_foreign_key(self):\n    \"\"\"Tests autodetection of field type changes from non-foreign key to foreign key.\"\"\"\n    changes = self.get_changes([self.author_empty, self.book_with_no_author], [self.author_empty, self.book_with_author])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, model_name=\"book\", name=\"author\")\n    self.assertEqual(changes['otherapp'][0].operations[0].field.remote_field.model._meta.app_label, 'testapp')\n    self.assertEqual(changes['otherapp'][0].operations[0].field.remote_field.model._meta.object_name, 'Author')\n"], "sample_496": ["    def setUp(self):\n        self.write_settings('settings.py')\n"], "sample_284": ["    def test_manifest(self):\n        self.assertIsNone(storage.staticfiles_storage.load_manifest())\n        self.assertIsNone(storage.staticfiles_storage.read_manifest())\n        self.assertEqual(storage.staticfiles_storage.hashed_files, {})\n        self.assertEqual(storage.staticfiles_storage.manifest_name, 'staticfiles.json')\n        self.assertEqual(storage.staticfiles_storage.manifest_version, '1.0')\n        self.assertEqual(storage.staticfiles_storage.manifest_strict, True)\n        self.assertEqual(storage.staticfiles_storage.keep_intermediate_files, False)\n"], "sample_789": ["def test_staged_predict_proba():\n    # Check staged predict_proba.\n    rng = np.random.RandomState(0)\n    iris_weights = rng.randint(10, size=iris.target.shape)\n    boston_weights = rng.randint(10, size=boston.target.shape)\n\n    # AdaBoost classification\n    for alg in ['SAMME', 'SAMME.R']:\n        clf = AdaBoostClassifier(algorithm=alg, n_estimators=10)\n        clf.fit(iris.data, iris.target, sample_weight=iris_weights)\n\n        proba = clf.predict_proba(iris.data)\n        staged_probas = [p for p in clf.staged_predict_proba(iris.data)]\n        score = clf.score(iris.data, iris.target, sample_weight=iris_weights)\n        staged_scores = [\n            s for s in clf.staged_score(\n                iris.data, iris.target, sample_weight=iris_weights)]\n\n        assert_equal(len(staged_probas), 10)\n        assert_array_almost_equal(proba, staged_probas[-1])\n        assert_equal(len(staged_scores), 10)\n        assert_array_almost_equal(score, staged_scores[-1])\n\n    # AdaBoost regression\n    clf = AdaBoostRegressor(n_estimators=10, random_state=0)\n    clf.fit(boston.data, boston.target, sample_weight=boston_weights)\n\n    proba = clf.predict_proba(boston.data)\n    staged_probas = [p for p in clf.staged_predict_proba(boston.data)]\n    score = clf.score(boston.data, boston.target, sample_weight=boston_weights)\n    staged_scores = [\n        s for s in clf.staged_score(\n            boston.data, boston.target, sample_weight=boston_weights)]\n\n    assert_equal(len(staged_probas), 10)\n    assert_array_almost_equal(proba, staged_probas[-1])\n    assert_equal(len(staged_scores), 10)\n    assert_array_almost_equal(score, staged_scores[-1])\n"], "sample_249": ["    def test_serialize_db_to_string_with_large_data(self):\n        # serialize_db_to_string() handles large amounts of data.\n        obj = Object.objects.create(obj_ref=ObjectReference.objects.create(obj=Object.objects.create()))\n        obj_ref = ObjectReference.objects.create(obj=obj)\n        obj_1 = ObjectSelfReference.objects.create(key='X')\n        obj_2 = ObjectSelfReference.objects.create(key='Y', obj=obj_1)\n        obj_1.obj = obj_2\n        obj_1.save()\n        obj_a = CircularA.objects.create(key='A')\n        obj_b = CircularB.objects.create(key='B', obj=obj_a)\n        obj_a.obj = obj_b\n        obj_a.save()\n        # Serialize objects.\n        with mock.patch('django.db.migrations.loader.MigrationLoader') as loader:\n            # serialize_db_to_string() serializes only migrated apps, so mark\n            # the backends app as migrated.\n            loader_instance = loader.return_value\n            loader_instance.migrated_apps = {'backends'}\n            data = connection.creation.serialize_db_to_string()\n        # Deserialize objects.\n        connection.creation.deserialize_db_from_string(data)\n        self.assertEqual(obj.obj_ref, obj_ref)\n        self.assertEqual(obj_ref.obj, obj)\n        obj_1 = ObjectSelfReference.objects.get(key='X')\n        obj_2 = ObjectSelfReference.objects.get(key='Y')\n        self.assertEqual(obj_1.obj, obj_2)\n        self.assertEqual(obj_2.obj, obj_1)\n        obj_a = CircularA.objects.get()\n        obj_b = CircularB.objects.get()\n        self.assertEqual(obj_a.obj, obj_b)\n        self.assertEqual(obj_b.obj, obj_a)\n"], "sample_809": ["def test_mutual_info_regression_sparse():\n    # We generate sample from multivariate normal distribution, using\n    # transformation from initially uncorrelated variables. The zero\n    # variables after transformation is selected as the target vector,\n    # it has the strongest correlation with the variable 2, and\n    # the weakest correlation with the variable 1.\n    T = np.array([\n        [1, 0.5, 2, 1],\n        [0, 1, 0.1, 0.0],\n        [0, 0.1, 1, 0.1],\n        [0, 0.1, 0.1, 1]\n    ])\n    cov = T.dot(T.T)\n    mean = np.zeros(4)\n\n    rng = check_random_state(0)\n    Z = rng.multivariate_normal(mean, cov, size=1000)\n    X = csr_matrix(Z[:, 1:])\n    y = Z[:, 0]\n\n    mi = mutual_info_regression(X, y, random_state=0)\n    assert_array_equal(np.argsort(-mi), np.array([1, 2, 0]))\n"], "sample_718": ["def test_check_estimators_pickle():\n    # check that we can pickle all estimators\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.linear_model import RidgeClassifier\n    from sklearn.linear_model import SGDClassifier\n    from sklearn.linear_model import ElasticNet\n    from sklearn.linear_model import Lasso\n    from sklearn.linear_model import LassoLars\n    from sklearn.linear_model import PassiveAggressiveClassifier\n    from sklearn.linear_model import Perceptron\n    from sklearn.linear_model import Ridge\n    from sklearn.linear_model import SGDRegressor\n    from sklearn.linear_model import ElasticNetCV\n    from sklearn.linear_model import LassoCV\n    from sklearn.linear_model import LassoLarsCV\n    from sklearn.linear_model import PassiveAggressiveRegressor\n    from sklearn.linear_model import Perceptron\n    from sklearn.linear_model import RidgeCV\n    from sklearn.linear_model import SGDClassifierCV\n    from sklearn.linear_model import SGDRegressorCV\n    from sklearn.linear_model import OrthogonalMatchingPursuit\n    from sklearn.linear_model import OrthogonalMatchingPursuitCV\n    from sklearn.linear_model import TheilSenRegressor\n    from sklearn.linear_model import ARDRegression\n    from sklearn.linear_model import BayesianRidge\n    from sklearn.linear_model import ElasticNetCV\n    from sklearn.linear_model import LassoLarsCV\n    from sklearn.linear_model import LassoCV\n    from sklearn.linear_model import RidgeCV\n    from sklearn.linear_model import SGDRegressorCV\n    from sklearn.linear_model import SGDClassifierCV\n    from sklearn.linear_model import PassiveAggressiveRegressor\n    from sklearn.linear_model import PassiveAggressiveClassifier\n    from sklearn.linear_model import Perceptron\n    from sklearn.linear_model import ElasticNet\n    from sklearn.linear_model import Lasso\n    from sklearn.linear_model import LassoLars\n    from sklearn.linear_model import Ridge\n    from sklearn.linear_model import SGDRegressor\n    from sklearn.linear_model import SGDClassifier\n    from sklearn.linear_model import OrthogonalMatchingPursuit\n    from sklearn.linear_model import OrthogonalMatchingPursuitCV\n    from sklearn.linear_model import TheilSenRegressor\n    from sklearn.linear_model import ARDRegression\n    from sklearn.linear_model import BayesianRidge\n\n    for Estimator in [LogisticRegression, RidgeClassifier, SGDClassifier,\n                      ElasticNet, Lasso, LassoLars, PassiveAggressiveClassifier,\n                      Perceptron, Ridge, SGDRegressor, ElasticNetCV,\n                      LassoCV,"], "sample_477": ["def test_random03(self):\n    output = self.engine.render_to_string(\n        \"random03\", {\"a\": [\"a&b\", \"a&b\"], \"b\": [mark_safe(\"a&b\"), mark_safe(\"a&b\")]}\n    )\n    self.assertEqual(output, \"a&b a&b\")\n"], "sample_745": ["def test_inverse_transform_with_sparse_input():\n    X_sparse = sparse.csr_matrix(np.array([[1, 2], [3, 4]]))\n\n    # Test that inverse_transform works correctly with sparse input\n    F = FunctionTransformer(\n        func=lambda X: X.toarray(),\n        inverse_func=lambda X: sparse.csr_matrix(X),\n    )\n    assert_array_equal(\n        F.inverse_transform(F.transform(X_sparse)).toarray(),\n        X_sparse.toarray(),\n    )\n"], "sample_1209": ["def test_prefix_latex():\n    m = PREFIXES['m']\n    k = PREFIXES['k']\n    M = PREFIXES['M']\n\n    assert m._latex(None) == r'\\text{m}'\n    assert k._latex(None) == r'\\text{k}'\n    assert M._latex(None) == r'\\text{M}'\n\n    assert m._latex_repr is None\n    k._latex_repr = r'\\mathrm{k}'\n    assert k._latex(None) == r'\\mathrm{k}'\n\n    assert kibi._latex(None) == r'\\mathrm{Y}'\n"], "sample_374": ["    def test_prefetch_related_with_prefetch_related(self):\n        with self.assertNumQueries(2):\n            lists = [list(b.authors.all()) for b in Book.objects.prefetch_related('authors').prefetch_related('authors')]\n        normal_lists = [list(b.authors.all()) for b in Book.objects.all()]\n        self.assertEqual(lists, normal_lists)\n"], "sample_254": ["    def setUp(self):\n        self.client.force_login(self.superuser)\n"], "sample_479": ["def test_create_model_add_constraint(self):\n    \"\"\"\n    AddConstraint should optimize into CreateModel.\n    \"\"\"\n    self.assertOptimizesTo(\n        [\n            migrations.CreateModel(\n                \"Foo\", [(\"name\", models.CharField(max_length=255))]\n            ),\n            migrations.AddConstraint(\"Foo\", models.CheckConstraint(check=models.Q(name=\"test\"))),\n        ],\n        [\n            migrations.CreateModel(\n                \"Foo\",\n                [(\"name\", models.CharField(max_length=255))],\n                options={\"constraints\": [models.CheckConstraint(check=models.Q(name=\"test\"))]},\n            ),\n        ],\n    )\n"], "sample_60": ["    def setUp(self):\n        self.site = AdminSite()\n"], "sample_837": ["def test_get_blas_info():\n    blas_info = _get_blas_info()\n\n    assert 'macros' in blas_info\n    assert 'lib_dirs' in blas_info\n    assert 'cblas_libs' in blas_info\n\n    # Test that macros is a string\n    assert isinstance(blis_info['macros'], str)\n\n    # Test that lib_dirs is a string\n    assert isinstance(blis_info['lib_dirs'], str)\n\n    # Test that cblas_libs is a string\n    assert isinstance(blis_info['cblas_libs'], str)\n"], "sample_868": ["def test_empty_labels(metric_name):\n    # All clustering metrics should raise an error when given empty labels\n    y_true = []\n    y_pred = [0, 1, 2, 3, 4, 5]\n    if metric_name in SUPERVISED_METRICS:\n        metric = SUPERVISED_METRICS[metric_name]\n        with pytest.raises(ValueError):\n            metric(y_true, y_pred)\n    else:\n        metric = UNSUPERVISED_METRICS[metric_name]\n        X = np.random.randint(10, size=(6, 10))\n        with pytest.raises(ValueError):\n            metric(X, y_true)\n\n    y_true = [0, 0, 0, 0, 1, 1, 1, 1]\n    y_pred = []\n    if metric_name in SUPERVISED_METRICS:\n        metric = SUPERVISED_METRICS[metric_name]\n        with pytest.raises(ValueError):\n            metric(y_true, y_pred)\n    else:\n        metric = UNSUPERVISED_METRICS[metric_name]\n        X = np.random.randint(10, size=(8, 10))\n        with pytest.raises(ValueError):\n            metric(X, y_true)\n"], "sample_728": ["def test_make_circles():\n    X, y = make_circles(n_samples=100, shuffle=False, noise=0.0, random_state=0)\n\n    assert_equal(X.shape, (100, 2), \"X shape mismatch\")\n    assert_equal(y.shape, (100,), \"y shape mismatch\")\n    assert_equal(np.unique(y).shape, (2,), \"Unexpected number of classes\")\n\n    # Check that points are on the circle\n    for x, label in zip(X, y):\n        center = [0.0, 0.0] if label == 0 else [1.0, 0.5]\n        dist_sqr = ((x - center) ** 2).sum()\n        assert_almost_equal(dist_sqr, 1.0,\n                            err_msg=\"Point is not on expected unit circle\")\n\n    # Check that points are not on the inner circle\n    for x, label in zip(X, y):\n        if label == 1:\n            dist_sqr = ((x - [0.5, 0.5]) ** 2).sum()\n            assert_greater(dist_sqr, 0.1, \"Point is on inner circle\")\n\n    # Test with noise\n    X, y = make_circles(n_samples=100, shuffle=False, noise=0.1, random_state=0)\n    for x, label in zip(X, y):\n        center = [0.0, 0.0] if label == 0 else [1.0, 0.5]\n        dist_sqr = ((x - center) ** 2).sum()\n        assert_less(dist_sqr, 1.1, \"Point is not on expected unit circle\")\n"], "sample_238": ["def test_aggregate_subquery_annotation_values_list(self):\n    \"\"\"\n    Subquery annotations and external aliases are excluded from the GROUP\n    BY if they are not selected.\n    \"\"\"\n    books_qs = Book.objects.annotate(\n        first_author_the_same_age=Subquery(\n            Author.objects.filter(\n                age=OuterRef('contact__friends__age'),\n            ).order_by('age').values('id')[:1],\n        )\n    ).filter(\n        publisher=self.p1,\n        first_author_the_same_age__isnull=False,\n    ).annotate(\n        min_age=Min('contact__friends__age'),\n    ).values_list('name', 'min_age')\n    self.assertEqual(list(books_qs), [\n        ('The Definitive Guide to Django: Web Development Done Right', 29),\n        ('Practical Django Projects', 34),\n    ])\n\n    books_rating_qs = Book.objects.filter(\n        publisher=OuterRef('pk'),\n        price=Decimal('29.69'),\n    ).values('rating')\n    publisher_qs = Publisher.objects.filter(\n        book__contact__age__gt=20,\n        name=self.p1.name,\n    ).annotate(\n        rating=Subquery(books_rating_qs),\n        contacts_count=Count('book__contact'),\n    ).values_list('rating').annotate(total_count=Count('rating'))\n    self.assertEqual(list(publisher_qs), [\n        (4.0, 2),\n    ])\n"], "sample_799": ["def test_cross_validate_return_estimator():\n    X, y = make_classification(n_samples=30, random_state=0)\n    clf = SVC(kernel=\"linear\", random_state=0)\n    cv = KFold(n_splits=5)\n    scores = cross_validate(clf, X, y, cv=cv, return_estimator=True)\n    assert_equal(len(scores['estimator']), 5)\n    for est in scores['estimator']:\n        assert_equal(est.coef_.shape, clf.coef_.shape)\n        assert_almost_equal(est.intercept_, clf.intercept_)\n"], "sample_436": ["    def test_suppressed_options(self):\n        \"\"\"runserver doesn't support --verbosity and --traceback options.\"\"\"\n        out, err = self.run_manage([\"runserver\", \"--help\"])\n        self.assertNotInOutput(out, \"--verbosity\")\n        self.assertNotInOutput(out, \"--traceback\")\n        self.assertOutput(out, \"--settings\")\n"], "sample_634": ["    def test_expand_modules_single_file(self, files_or_modules, expected):\n        \"\"\"Test expand_modules with a single file or package\"\"\"\n        ignore_list, ignore_list_re = [], []\n        modules, errors = expand_modules(\n            files_or_modules,\n            ignore_list,\n            ignore_list_re,\n            get_global_option(self, \"ignore-paths\"),\n        )\n        modules.sort(key=lambda d: d[\"name\"])\n        assert modules == expected\n        assert not errors\n"], "sample_803": ["def test_label_ranking_loss_sparse():\n    # Test that label_ranking_loss works with sparse csr matrices\n    y_true = csr_matrix(np.array([[0, 1, 0], [1, 1, 0]]))\n    y_score = np.array([[0.1, 10, -3], [3, 1, 3]])\n    assert_almost_equal(label_ranking_loss(y_true, y_score), 1 / 2.)\n\n    y_true = csr_matrix(np.array([[0, 0, 1], [0, 1, 1], [1, 1, 0]]))\n    y_score = np.array([[0.1, 10, -3], [0, 1, 3], [0, 2, 0]])\n    assert_almost_equal(label_ranking_loss(y_true, y_score), (0 + 2 / 2 + 1 / 2) / 3.)\n\n    y_true = csr_matrix(np.array([[0, 0, 1], [1, 1, 0], [0, 1, 1]]))\n    y_score = np.array([[0.1, 10, -3], [3, 1, 3], [0, 2, 0]])\n    assert_almost_equal(label_ranking_loss(y_true, y_score), (0 + 2 / 2 + 1 / 2) / 3.)\n"], "sample_867": ["def test_grid_search_with_pre_dispatch():\n    # Test that GridSearchCV with pre_dispatch parameter works correctly\n    X, y = make_classification(n_samples=100, n_features=4, random_state=0)\n    clf = LinearSVC(random_state=0)\n    param_grid = {'C': [0.1, 1.0]}\n    cv = KFold(n_splits=3)\n    gs = GridSearchCV(clf, param_grid, cv=cv, pre_dispatch=1)\n    gs.fit(X, y)\n    assert hasattr(gs, \"cv_results_\")\n"], "sample_21": ["def test_read_write_with_err_specs(tmp_path):\n    test_file = tmp_path / \"test.qdp\"\n    t1 = Table()\n    t1.add_column(Column(name=\"a\", data=[1, 2, 3, 4]))\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"b\", mask=[False, False, False, True]\n        )\n    )\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"c\", mask=[False, False, False, True]\n        )\n    )\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"d\", mask=[False, False, False, True]\n        )\n    )\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"e\", mask=[False, False, False, True]\n        )\n    )\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"f\", mask=[False, False, False, True]\n        )\n    )\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"g\", mask=[False, False, False, True]\n        )\n    )\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"h\", mask=[False, False, False, True]\n        )\n    )\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"i\", mask=[False, False, False, True]\n        )\n    )\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0, np.nan, 3.0, 1.0], name=\"j\", mask=[False, False, False, True]\n        )\n    )\n    t1.add_column(\n        MaskedColumn(\n            data=[4.0"], "sample_248": ["def test_shell_with_bpython_not_installed(self, select):\n    select.return_value = ([], [], [])\n    with self.assertRaisesMessage(CommandError, \"Couldn't import bpython interface.\"):\n        call_command('shell', interface='bpython')\n"], "sample_333": ["def test_boundfield_disabled_initial(self):\n    class PersonForm(Form):\n        name = CharField(initial='John Doe', disabled=True)\n\n    # Without form data.\n    form = PersonForm()\n    self.assertEqual(form['name'].value(), 'John Doe')\n\n    # With form data. As the field is disabled, the value should not be\n    # affected by the form data.\n    form = PersonForm({'name': 'Jane Doe'})\n    self.assertEqual(form['name'].value(), 'John Doe')\n"], "sample_390": ["def test_directory_index_template_translatable(self):\n    \"\"\"Test that the directory index template is translatable\"\"\"\n    response = self.client.get(\"/%s/\" % self.prefix)\n    self.assertIn(\"Index of ./\", response.content.decode(\"utf-8\"))\n    self.assertIn(\"Index of ./\", response.context[\"template_translatable\"])\n"], "sample_810": ["def test_pipeline_fit_transform_with_intermediate_fit_params_and_transform():\n    # tests that Pipeline passes fit_params to intermediate steps\n    # when fit_transform is invoked\n    pipe = Pipeline([('transf', TransfFitParams()), ('clf', FitParamT())])\n    pipe.fit_transform(X=None,\n                      y=None,\n                      transf__should_get_this=True,\n                      clf__should_succeed=True)\n    assert pipe.named_steps['transf'].fit_params['should_get_this']\n    assert pipe.named_steps['clf'].successful\n    assert 'should_succeed' not in pipe.named_steps['transf'].fit_params\n"], "sample_1122": ["def test_issue_14216():\n    from sympy import Matrix, simplify\n    A = Matrix([[1, 2], [3, 4]])\n    assert simplify(A.conjugate().transpose()) == A.transpose().conjugate()\n    assert simplify(A.transpose().conjugate()) == A.conjugate().transpose()\n"], "sample_245": ["    def test_no_default_ignore(self):\n        cmd = MakeMessagesCommand()\n        cmd.use_default_ignore_patterns = False\n        cmd.ignore_patterns = ['CVS', '.*', '*~', '*.pyc']\n        cmd.symlinks = False\n        cmd.domain = 'django'\n        cmd.extensions = ['html', 'txt', 'py']\n        cmd.verbosity = 0\n        cmd.locale_paths = []\n        cmd.default_locale_path = os.path.join(self.test_dir, 'locale')\n        found_files = cmd.find_files(self.test_dir)\n        found_exts = {os.path.splitext(tfile.file)[1] for tfile in found_files}\n        self.assertEqual(found_exts.difference({'.py', '.html', '.txt'}), set())\n\n        cmd.extensions = ['js']\n        cmd.domain = 'djangojs'\n        found_files = cmd.find_files(self.test_dir)\n        found_exts = {os.path.splitext(tfile.file)[1] for tfile in found_files}\n        self.assertEqual(found_exts.difference({'.js'}), set())\n"], "sample_541": ["def test_cursor(ax):\n    cursor = widgets.Cursor(ax, horizOn=True, vertOn=True)\n    assert cursor.visible\n    assert cursor.horizOn\n    assert cursor.vertOn\n    assert cursor.useblit is False\n\n    cursor.visible = False\n    assert not cursor.visible\n\n    cursor.visible = True\n    assert cursor.visible\n\n    cursor.horizOn = False\n    assert not cursor.horizOn\n    assert cursor.vertOn\n    assert cursor.useblit is False\n\n    cursor.horizOn = True\n    assert cursor.horizOn\n    assert cursor.vertOn\n    assert cursor.useblit is False\n\n    cursor.vertOn = False\n    assert not cursor.vertOn\n    assert cursor.horizOn\n    assert cursor.useblit is False\n\n    cursor.useblit = True\n    assert cursor.useblit\n\n    cursor.useblit = False\n    assert not cursor.useblit\n\n    cursor.lineh.set_visible(False)\n    assert not cursor.lineh.get_visible()\n    cursor.linev.set_visible(False)\n    assert not cursor.linev.get_visible()\n\n    cursor.lineh.set_visible(True)\n    assert cursor.lineh.get_visible()\n    cursor.linev.set_visible(True)\n    assert cursor.linev.get_visible()\n\n    cursor.lineh.set_visible(False)\n    cursor.linev.set_visible(False)\n    cursor.update()\n    assert not cursor.lineh.get_visible()\n    assert not cursor.linev.get_visible()\n\n    cursor.lineh.set_visible(True)\n    cursor.linev.set_visible(True)\n    cursor.update()\n    assert cursor.lineh.get_visible()\n    assert cursor.linev.get_visible()\n\n    cursor.lineh.set_visible(False)\n    cursor.linev.set_visible(False)\n    cursor.clear()\n    assert not cursor.lineh.get_visible()\n    assert not cursor.linev.get_visible()\n\n    cursor.lineh.set_visible(True)\n    cursor.linev.set_visible(True)\n    cursor.clear()\n    assert cursor.lineh.get_visible()\n    assert cursor.linev.get_visible()\n\n    cursor.lineh.set_visible(False)\n    cursor.linev.set_visible(False)\n    cursor.onmove(mock.Mock(spec=noop, return_value=None))\n    assert not cursor.lineh.get_visible()\n    assert not cursor.linev.get_visible()\n\n    cursor.lineh.set_visible(True)\n    cursor.linev.set_visible(True)\n    cursor.onmove(mock.Mock(spec=noop, return_value=None))\n    assert cursor.lineh.get_visible()\n    assert cursor.line"], "sample_181": ["def test_filtered_aggregate_with_exists(self):\n    agg = Sum('age', filter=Q(exists=Exists(Book.objects.filter(contact__pk=OuterRef('pk'))))\n    self.assertEqual(Author.objects.aggregate(age=agg)['age'], 200)\n"], "sample_564": ["def test_text3D_modification(fig_test, fig_ref):\n    ax = fig_test.add_subplot(projection=\"3d\")\n    ax.text(0, 0, 0, \"text\")\n    ax.text(0, 0, 0, \"text\", zdir=\"x\")\n    ax.text(0, 0, 0, \"text\", zdir=\"y\")\n    ax.text(0, 0, 0, \"text\", zdir=\"z\")\n    ax.text(0, 0, 0, \"text\", zdir=(1, 1, 0))\n    ax.text(0, 0, 0, \"text\", zdir=(1, 1, 1))\n\n    ax = fig_ref.add_subplot(projection=\"3d\")\n    ax.text(0, 0, 0, \"text\")\n    ax.text(0, 0, 0, \"text\", zdir=\"x\")\n    ax.text(0, 0, 0, \"text\", zdir=\"y\")\n    ax.text(0, 0, 0, \"text\", zdir=\"z\")\n    ax.text(0, 0, 0, \"text\", zdir=(1, 1, 0))\n    ax.text(0, 0, 0, \"text\", zdir=(1, 1, 1))\n"], "sample_643": ["def test_colorized_output_deprecated():\n    \"\"\"TODO remove in 3.0.\"\"\"\n    reporter = ColorizedTextReporter()\n    # noinspection PyDeprecation\n    reporter.set_output(sys.stdout)\n    warning = warnings.warn(\n        \"In pylint 3.0, the ColorizedTextReporter will only accept ColorMappingDict as color_mapping parameter\",\n        DeprecationWarning,\n    )\n    assert \"ColorizedTextReporter will only accept ColorMappingDict as color_mapping parameter\" in str(warning)\n    assert reporter.out == sys.stdout\n\n"], "sample_1055": ["def test_encipher_decipher_atbash():\n    assert encipher_atbash(\"ABC\") == \"ZYX\"\n    assert encipher_atbash(\"ZYX\") == \"ABC\"\n    assert decipher_atbash(\"ABC\") == \"ZYX\"\n    assert decipher_atbash(\"ZYX\") == \"ABC\"\n    assert encipher_atbash(\"Hello, World!\") == \"Svool, Dliow!\"\n    assert decipher_atbash(\"Svool, Dliow!\") == \"Hello, World!\"\n"], "sample_1109": ["def test_frac_real_imaginary():\n    r = Symbol('r', real=True)\n    i = Symbol('i', imaginary=True)\n    assert frac(r + i) == I*frac(r) + frac(r)\n    assert frac(r - i) == I*frac(r) + frac(r)\n    assert frac(r + 2*i) == I*frac(r) + frac(r)\n    assert frac(r - 2*i) == I*frac(r) + frac(r)\n    assert frac(r + 3*i) == I*frac(r) + frac(r)\n    assert frac(r - 3*i) == I*frac(r) + frac(r)\n"], "sample_38": ["def test_sip_foc2pix():\n    \"\"\"\n    Test that sip_foc2pix returns the correct values\n    \"\"\"\n    header = get_pkg_data_contents('data/sip.fits', encoding='binary')\n    w = wcs.WCS(header)\n    x, y = w.sip_foc2pix(72, 72, 0)\n    assert_allclose(x, 200, 1e-3)\n    assert_allclose(y, 200, 1e-3)\n"], "sample_708": ["def test_getstatementrange_with_nested_try_except() -> None:\n    source = Source(\n        \"\"\"\\"], "sample_1179": ["def test_Dict_printing():\n    d = Dict({1: 1 + x, 2: y*x})\n    assert str(d) == \"{1: x + 1, 2: x*y}\"\n    assert sstr(d) == \"{1: x + 1, 2: x*y}\"\n"], "sample_336": ["    def test_resolve_error_handler(self):\n        \"\"\"\n        Test that resolve_error_handler() returns the correct view for a given status code.\n        \"\"\"\n        resolver = get_resolver('urlpatterns_reverse.urls')\n        self.assertEqual(resolver.resolve_error_handler(400), empty_view)\n        self.assertEqual(resolver.resolve_error_handler(404), empty_view)\n        self.assertEqual(resolver.resolve_error_handler(500), empty_view)\n"], "sample_325": ["def test_boundfield_subwidgets(self):\n    class SomeForm(Form):\n        field = MultipleChoiceField(\n            choices=[('a', 'A'), ('b', 'B')],\n            widget=CheckboxSelectMultiple,\n        )\n\n    form = SomeForm(auto_id='prefix_%s')\n    subwidgets = form['field'].subwidgets\n    self.assertEqual(len(subwidgets), 2)\n    self.assertEqual(subwidgets[0].id_for_label, 'prefix_field_0')\n    self.assertEqual(subwidgets[1].id_for_label, 'prefix_field_1')\n    self.assertEqual(subwidgets[0].choice_label, 'A')\n    self.assertEqual(subwidgets[1].choice_label, 'B')\n    self.assertEqual(subwidgets[0].data['attrs']['id'], 'prefix_field_0')\n    self.assertEqual(subwidgets[1].data['attrs']['id'], 'prefix_field_1')\n"], "sample_533": ["def test_contour_label_manual_selection():\n    x, y = np.meshgrid(np.arange(0, 10), np.arange(0, 10))\n    z = np.max(np.dstack([abs(x), abs(y)]), 2)\n\n    fig, ax = plt.subplots()\n    cs = ax.contour(x, y, z)\n    pts = np.array([(1.0, 3.0), (1.0, 4.4), (1.0, 6.0)])\n    cs.clabel(manual=pts)\n    assert len(cs.labelTexts) == len(pts)\n    assert len(cs.labelXYs) == len(pts)\n    assert len(cs.labelCValues) == len(pts)\n"], "sample_558": ["def test_imagegrid_cbar_mode_each():\n    arr = np.arange(16).reshape((4, 4))\n\n    fig = plt.figure(figsize=(18, 9))\n\n    positions = (241, 242, 243, 244, 245, 246, 247, 248)\n    directions = ['row']*4 + ['column']*4\n    cbar_locations = ['left', 'right', 'top', 'bottom']*2\n\n    for position, direction, location in zip(\n            positions, directions, cbar_locations):\n        grid = ImageGrid(fig, position,\n                         nrows_ncols=(2, 2),\n                         direction=direction,\n                         cbar_location=location,\n                         cbar_size='20%',\n                         cbar_mode='each')\n        ax1, ax2, ax3, ax4 = grid\n\n        ax1.imshow(arr, cmap='nipy_spectral')\n        ax2.imshow(arr.T, cmap='hot')\n        ax3.imshow(np.hypot(arr, arr.T), cmap='jet')\n        ax4.imshow(np.arctan2(arr, arr.T), cmap='hsv')\n\n        # In each row/column, the \"first\" colorbars must be overwritten by the\n        # \"second\" ones.  To achieve this, clear out the axes first.\n        for ax in grid:\n            ax.cax.cla()\n            cb = ax.cax.colorbar(ax.images[0])\n"], "sample_904": ["def test_productionlist_with_colon(app):\n    text = (\".. productionlist:: P1\\n\"\n            \"   A: `A`\\n\"\n            \"   B: `P2:A`\\n\")\n    doctree = restructuredtext.parse(app, text)\n    refnodes = list(doctree.findall(pending_xref))\n    assert_node(refnodes[0], pending_xref, reftarget=\"A\")\n    assert_node(refnodes[1], pending_xref, reftarget=\"P1:A\")\n    assert_node(refnodes[0], [pending_xref, nodes.literal, \"A\"])\n    assert_node(refnodes[1], [pending_xref, nodes.literal, \"P1:A\"])\n\n    domain = app.env.get_domain(\"std\")\n    objects = list(domain.get_objects())\n    assert (\"A\", \"A\", \"token\", \"index\", \"grammar-token-P1-A\", -1) in objects\n    assert (\"P1:A\", \"P1:A\", \"token\", \"index\", \"grammar-token-P1-A\", -1) in objects\n"], "sample_651": ["    def test_record_matches(self) -> None:\n        with pytest.warns(UserWarning, match=r\"must be \\d+$\") as record:\n            warnings.warn(\"value must be 42\", UserWarning)\n\n        assert len(record) == 1\n        assert record[0].matches(record[0])\n"], "sample_364": ["    def test_dynamic_converter_inclusion(self):\n        @DynamicConverter.register_to_url\n            return value.upper()\n\n        @DynamicConverter.register_to_python\n            return value.lower()\n\n        urlconf_module = import_module('urlpatterns.path_dynamic_urls')\n        urlconf_module.urlpatterns = [\n            path('dynamic/<str:dynamic>/', lambda r: None),\n        ]\n\n        match = resolve('/dynamic/ABC/')\n        self.assertEqual(match.url_name, 'dynamic')\n        self.assertEqual(match.kwargs, {'dynamic': 'ABC'})\n        self.assertEqual(match.route, 'dynamic/<str:dynamic>/')\n\n        url = reverse('dynamic', kwargs={'dynamic': 'abc'})\n        self.assertEqual(url, '/dynamic/abc/')\n"], "sample_743": ["def test_radius_neighbors_regressor_sparse():\n    # Test radius-based regression on sparse matrices\n    rng = np.random.RandomState(0)\n    X = 2 * rng.rand(40, 5) - 1\n    y = np.sqrt((X ** 2).sum(1))\n    y /= y.max()\n    y = np.vstack([y, y]).T\n\n    for sparsemat in SPARSE_TYPES:\n        knn = neighbors.RadiusNeighborsRegressor(n_neighbors=3,\n                                                 algorithm='auto')\n        knn.fit(sparsemat(X), y)\n\n        knn_pre = neighbors.RadiusNeighborsRegressor(n_neighbors=3,\n                                                    metric='precomputed')\n        knn_pre.fit(pairwise_distances(X, metric='euclidean'), y)\n\n        for sparsev in SPARSE_OR_DENSE:\n            X2 = sparsev(X)\n            assert_true(np.mean(knn.predict(X2).round() == y) > 0.95)\n\n            X2_pre = sparsev(pairwise_distances(X, metric='euclidean'))\n            if issparse(sparsev(X2_pre)):\n                assert_raises(ValueError, knn_pre.predict, X2_pre)\n            else:\n                assert_true(\n                    np.mean(knn_pre.predict(X2_pre).round() == y) > 0.95)\n"], "sample_1133": ["def test_refraction_angle_total_internal_reflection():\n    n1, n2 = symbols('n1, n2')\n    m1 = Medium('m1', n=n1)\n    m2 = Medium('m2', n=n2)\n    r1 = Ray3D(Point3D(-1, -1, 1), Point3D(0, 0, 0))\n    P = Plane(Point3D(0, 0, 0), normal_vector=[0, 0, 1])\n    assert refraction_angle(r1, m1, m2, plane=P) is None\n    assert refraction_angle(r1, m1, m2, normal=Matrix([0, 0, 1])) is None\n    assert refraction_angle(r1, m1, m2, normal=Matrix([0, 0, 1])) is None\n    assert refraction_angle(r1, m1, m2, normal=Ray3D(Point3D(0, 0, 0), Point3D(0, 0, 1))) is None\n    assert refraction_angle(r1, m1, m2, normal=Ray3D(Point3D(0, 0, 0), Point3D(0, 0, 1))) is None\n    assert refraction_angle(r1, m1, m2, normal=Ray3D(Point3D(0, 0, 0), Point3D(0, 0, 1))) is None\n    assert refraction_angle(r1, m1, m2, normal=Ray3D(Point3D(0, 0, 0), Point3D(0, 0, 1))) is None\n    assert refraction_angle(r1, m1, m2, normal=Ray3D(Point3D(0, 0, 0), Point3D(0, 0, 1))) is None\n    assert refraction_angle(r1, m1, m2, normal=Ray3D(Point3D(0, 0, 0), Point3D(0, 0, 1))) is None\n    assert refraction_angle(r1, m1, m2, normal=Ray3D(Point3D(0, 0, 0), Point3D(0, 0, 1))) is None\n"], "sample_805": ["def test_mean_squared_log_error_at_zero():\n    assert_almost_equal(mean_squared_log_error([0.], [0.]), 0.00, 2)\n    assert_almost_equal(mean_squared_log_error([0.], [0.], squared=False), 0.00, 2)\n    assert_raises_regex(ValueError, \"Mean Squared Logarithmic Error cannot be used \"\n                        \"when targets contain negative values.\",\n                        mean_squared_log_error, [-1.], [-1.])\n    assert_raises_regex(ValueError, \"Mean Squared Logarithmic Error cannot be used \"\n                        \"when targets contain negative values.\",\n                        mean_squared_log_error, [1., 2., 3.], [1., -2., 3.])\n    assert_raises_regex(ValueError, \"Mean Squared Logarithmic Error cannot be used \"\n                        \"when targets contain negative values.\",\n                        mean_squared_log_error, [1., -2., 3.], [1., 2., 3.])\n"], "sample_326": ["def test_avoid_wrapping(self):\n    items = (\n        ('Hello, world!', 'Hello, world!'),\n        ('Hello, world!  Hello, world!', 'Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello,"], "sample_93": ["def test_subquery_annotation_with_expression(self):\n    \"\"\"\n    Subquery annotations with expressions are excluded from the GROUP BY if\n    they are not explicitly grouped against.\n    \"\"\"\n    latest_book_pubdate_qs = Book.objects.filter(\n        publisher=OuterRef('pk')\n    ).order_by('-pubdate').values('pubdate')[:1]\n    publisher_qs = Publisher.objects.annotate(\n        latest_book_pubdate=Subquery(latest_book_pubdate_qs, output_field=DurationField()),\n    ).annotate(count=Count('book'))\n    with self.assertNumQueries(1) as ctx:\n        list(publisher_qs)\n    self.assertEqual(ctx[0]['sql'].count('SELECT'), 2)\n\n    # Test that the subquery annotation is not included in the GROUP BY\n    self.assertNotIn('GROUP BY', ctx[0]['sql'].upper())\n\n    # Test that the subquery annotation is included in the GROUP BY if it's\n    # grouped against\n    publisher_qs = Publisher.objects.values_list(\n        Subquery(latest_book_pubdate_qs, output_field=DurationField()),\n    ).annotate(total=Count('*')).values('latest_book_pubdate')\n    with self.assertNumQueries(1) as ctx:\n        list(publisher_qs)\n    self.assertEqual(ctx[0]['sql'].count('SELECT'), 2)\n    self.assertIn('GROUP BY', ctx[0]['sql'].upper())\n"], "sample_460": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(\n            username=\"super\", password=\"secret\", email=\"super@example.com\"\n        )\n        cls.s1 = Section.objects.create(name=\"Test section\")\n        cls.a1 = Article.objects.create(\n            content=\"<p>Middle content</p>\",\n            date=datetime.datetime(2008, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.a2 = Article.objects.create(\n            content=\"<p>Oldest content</p>\",\n            date=datetime.datetime(2000, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.a3 = Article.objects.create(\n            content=\"<p>Newest content</p>\",\n            date=datetime.datetime(2009, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.p1 = PrePopulatedPost.objects.create(\n            title=\"A Long Title\", published=True, slug=\"a-long-title\"\n        )\n"], "sample_844": ["def test_min_eps():\n    # Test that we check a minimum epsilon\n    msg = \"Specify an epsilon smaller than 0.15. Got 0.3.\"\n    centers = [[1, 1], [-1, -1], [1, -1]]\n    X, labels_true = make_blobs(n_samples=750, centers=centers,\n                                cluster_std=0.4, random_state=0)\n\n    # Compute OPTICS\n    clust = OPTICS(max_eps=5.0 * 0.03,\n                   cluster_method='dbscan',\n                   eps=0.3, min_samples=10)\n    assert_raise_message(ValueError, msg, clust.fit, X)\n"], "sample_528": ["def test_context_with_multiple_styles():\n    original_value = 'gray'\n    other_value = 'blue'\n    mpl.rcParams[PARAM] = original_value\n    with temp_style('test', DUMMY_SETTINGS):\n        with style.context(['test', 'default', {PARAM: other_value}]):\n            assert mpl.rcParams[PARAM] == other_value\n    assert mpl.rcParams[PARAM] == original_value\n"], "sample_216": ["def test_add_field_with_default_and_deconstructible(self):\n    \"\"\"#22030 - Adding a field with a default that is a deconstructible object should work.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_name_deconstructible_1])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n\n    changes = self.get_changes([self.author_empty], [self.author_name_deconstructible_2])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n\n    changes = self.get_changes([self.author_empty], [self.author_name_deconstructible_3])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n\n    changes = self.get_changes([self.author_empty], [self.author_name_deconstructible_4])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\")\n"], "sample_104": ["    def setUp(self):\n        super().setUp()\n\n        temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, 'test'))\n        self._clear_filename = os.path.join(temp_dir, 'test', 'cleared.txt')\n        with open(self._clear_filename, 'w') as f:\n            f.write('to be deleted in one test')\n\n        self.patched_settings = self.settings(\n            STATICFILES_DIRS=settings.STATICFILES_DIRS + [temp_dir],\n        )\n        self.patched_settings.enable()\n        self.addCleanup(shutil.rmtree, temp_dir)\n        self._manifest_strict = storage.staticfiles_storage.manifest_strict\n"], "sample_1041": ["def test_matrix_derivative():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', n, n)\n    E = MatrixSymbol('E', n, n)\n    F = MatrixSymbol('F', n, n)\n    G = MatrixSymbol('G', n, n)\n    H = MatrixSymbol('H', n, n)\n    I = MatrixSymbol('I', n, n)\n    J = MatrixSymbol('J', n, n)\n    K = MatrixSymbol('K', n, n)\n    L = MatrixSymbol('L', n, n)\n    M = MatrixSymbol('M', n, n)\n    N = MatrixSymbol('N', n, n)\n    O = MatrixSymbol('O', n, n)\n    P = MatrixSymbol('P', n, n)\n    Q = MatrixSymbol('Q', n, n)\n    R = MatrixSymbol('R', n, n)\n    S = MatrixSymbol('S', n, n)\n    T = MatrixSymbol('T', n, n)\n    U = MatrixSymbol('U', n, n)\n    V = MatrixSymbol('V', n, n)\n    W = MatrixSymbol('W', n, n)\n    X = MatrixSymbol('X', n, n)\n    Y = MatrixSymbol('Y', n, n)\n    Z = MatrixSymbol('Z', n, n)\n\n    assert diff(A, A) == ZeroMatrix(n, n)\n    assert diff(A, B) == ZeroMatrix(n, n)\n    assert diff(A, C) == ZeroMatrix(n, n)\n    assert diff(A, D) == ZeroMatrix(n, n)\n    assert diff(A, E) == ZeroMatrix(n, n)\n    assert diff(A, F) == ZeroMatrix(n, n)\n    assert diff(A, G) == ZeroMatrix(n, n)\n    assert diff(A, H) == ZeroMatrix(n, n)\n    assert diff(A, I) == ZeroMatrix(n, n)\n    assert diff(A, J) == ZeroMatrix(n, n)\n    assert diff(A, K) == ZeroMatrix(n, n)\n    assert diff(A, L) == ZeroMatrix(n, n)\n    assert diff(A, M) == ZeroMatrix(n, n)\n    assert diff(A, N) == ZeroMatrix"], "sample_54": ["    def test_file_from_buffer_with_filename(self):\n        response = FileResponse(io.BytesIO(b'binary content'), filename='example.txt')\n        self.assertEqual(response['Content-Length'], '14')\n        self.assertEqual(response['Content-Type'], 'application/octet-stream')\n        self.assertEqual(response['Content-Disposition'], 'inline; filename=\"example.txt\"')\n        self.assertEqual(list(response), [b'binary content'])\n"], "sample_845": ["def test_hashingvectorizer_dtype():\n    # Non-regression test: HashingVectorizer used to ignore its \"dtype\" param.\n    v = HashingVectorizer(dtype=np.float32)\n    assert v.dtype == np.float32\n\n    X = v.transform(['hello world', 'hello hello']).toarray()\n    assert X.dtype == np.float32\n\n    # Check that the rows are normalized\n    for i in range(X.shape[0]):\n        assert_almost_equal(np.linalg.norm(X[0].data, 2), 1.0)\n\n    # Check that the rows are normalized\n    for i in range(X.shape[0]):\n        assert_almost_equal(np.linalg.norm(X[0].data, 2), 1.0)\n\n    # Check that the rows are normalized\n    for i in range(X.shape[0]):\n        assert_almost_equal(np.linalg.norm(X[0].data, 2), 1.0)\n"], "sample_193": ["    def test_custom_manager_swappable(self):\n        \"\"\"\n        Tests making a ProjectState from unused models with custom managers\n        \"\"\"\n        new_apps = Apps(['migrations'])\n\n        class Food(models.Model):\n\n            food_mgr = FoodManager('a', 'b')\n            food_qs = FoodQuerySet.as_manager()\n            food_no_mgr = NoMigrationFoodManager('x', 'y')\n\n            class Meta:\n                app_label = \"migrations\"\n                apps = new_apps\n                swappable = 'TEST_SWAPPABLE_MODEL'\n\n        food_state = ModelState.from_model(Food)\n\n        # The default manager is used in migrations\n        self.assertEqual([name for name, mgr in food_state.managers], ['food_mgr'])\n        self.assertEqual(food_state.managers[0][1].args, ('a', 'b', 1, 2))\n"], "sample_517": ["def test_bbox_position_size():\n    fig, ax = plt.subplots()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax.transAxes)\n    fig.canvas.draw()\n    ax.text(0.5, 0.5, 'test', transform=ax"], "sample_1015": ["def test_ccode_PreIncrement():\n    x = symbols('x')\n    assert ccode(x++) == '++x'\n    assert ccode(x++, assign_to='y') == 'y = ++x;'\n"], "sample_231": ["    def test_non_sensitive_request(self):\n        \"\"\"\n        Request info can bee seen in the default error reports for non-sensitive requests.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n\n        with self.settings(DEBUG=False):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n"], "sample_256": ["    def test_render_with_unusable_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = 'django.contrib.auth.hashers.UNUSABLE_PASSWORD_PREFIX + \"abc123\"'\n        self.assertHTMLEqual(\n            widget.render('name', value, {'id': 'id_password'}),\n            \"\"\"\n            <div id=\"id_password\">\n                <strong>No password set.</strong>\n            </div>\n            \"\"\"\n        )\n"], "sample_417": ["    def test_floatformat03(self):\n        output = self.engine.render_to_string(\n            \"floatformat03\", {\"a\": \"6666.6666\", \"b\": mark_safe(\"6666.6666\")}\n        )\n        self.assertEqual(output, \"6,667.00 6,667.00\")\n"], "sample_858": ["def test_transform_proba():\n    \"\"\"Check transform method of VotingClassifier on toy dataset.\"\"\"\n    clf1 = LogisticRegression(random_state=123)\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    X = np.array([[-1.1, -1.5], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n    y = np.array([1, 1, 2, 2])\n\n    eclf1 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft',\n        flatten_transform=False).fit(X, y)\n    eclf2 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft',\n        flatten_transform=True).fit(X, y)\n\n    probas1 = eclf1.transform(X)\n    probas2 = eclf2.transform(X)\n\n    assert_array_almost_equal(probas1, probas2)\n    assert_array_almost_equal(probas1,\n                              np.array([[[0.59790391, 0.40209609],\n                                         [0.57622162, 0.42377838],\n                                         [0.50728456, 0.49271544],\n                                         [0.40241774, 0.59758226]],\n                                        [[0.8, 0.2],\n                                         [0.8, 0.2],\n                                         [0.2, 0.8],\n                                         [0.3, 0.7]],\n                                        [[0.9985082, 0.0014918],\n                                         [0.99845843, 0.00154157],\n                                         [0., 1.],\n                                         [0., 1.]]]))\n"], "sample_1185": ["def test_decompogen_polynomial_with_multiple_variables():\n    x, y = symbols('x y')\n    assert decompogen(x**2 + 2*x*y + y**2, x) == [y**2 + 2*x*y + x**2]\n    assert decompogen(x**2 + 2*x*y + y**2, y) == [x**2 + 2*x*y + y**2]\n    assert decompogen(x**2 + 2*x*y + y**2, y) == [x**2 + 2*x*y + y**2]\n    assert decompogen(x**2 + 2*x*y + y**2, x) == [y**2 + 2*x*y + x**2]\n    assert decompogen(x**2 + 2*x*y + y**2, y) == [x**2 + 2*x*y + y**2]\n    assert decompogen(x**2 + 2*x*y + y**2, x) == [y**2 + 2*x*y + x**2]\n    assert decompogen(x**2 + 2*x*y + y**2, y) == [x**2 + 2*x*y + y**2]\n    assert decompogen(x**2 + 2*x*y + y**2, x) == [y**2 + 2*x*y + x**2]\n    assert decompogen(x**2 + 2*x*y + y**2, y) == [x**2 + 2*x*y + y**2]\n    assert decompogen(x**2 + 2*x*y + y**2, x) == [y**2 + 2*x*y + x**2]\n    assert decompogen(x**2 + 2*x*y + y**2, y) == [x**2 + 2*x*y + y**2]\n    assert decompogen(x**2 + 2*x*y + y**2, x) == [y**2 + 2*x*y + x**2]\n    assert decompogen(x**2 + 2*x*y + y**2, y) == [x**2 + 2*x*y + y**2]\n    assert decompogen(x**2 + 2*x*y + y**2, x) == [y**2 + 2*x*y + x**"], "sample_699": ["    def test_allow_unicode(self, pytester: Pytester):\n        pytester.maketxtfile(\n            test_doc=\"\"\"\n            >>> b'12'.decode('ascii')\n            '12'\n        \"\"\"\n        )\n        reprec = pytester.inline_run()\n        reprec.assertoutcome(passed=1)\n"], "sample_1081": ["def test_is_amicable():\n    assert is_amicable(220, 284) is True\n    assert is_amicable(1184, 1210) is True\n    assert is_amicable(1184, 1210) is True\n    assert is_amicable(1184, 1210) is True\n    assert is_amicable(1184, 1210) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220, 284) is True\n    assert is_amicable(220"], "sample_800": ["def test_check_estimators_pickle():\n    # check that we can pickle all estimators\n    check_estimators_pickle(\"estimator\", LogisticRegression())\n"], "sample_525": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect((1, 2, 3))\n    ax2.set_box_aspect((2, 1, 1))\n"], "sample_729": ["def test_enet_path_return_models():\n    # Test that lasso_path with models output gives the same result\n\n    # Some toy data\n    X = np.array([[1, 2, 3.1], [2.3, 5.4, 4.3]]).T\n    y = np.array([1, 2, 3.1])\n    alphas = [5., 1., .5]\n\n    # Use lars_path and lasso_path(models output) to compute the same path\n    alphas_lars, active, coef_path_lars = lars_path(X, y, method='lasso')\n    coef_path_cont_lars = interpolate.interp1d(alphas_lars[::-1],\n                                               coef_path_lars[:, ::-1])\n    alphas_lasso, coefs_lasso, _ = lasso_path(X, y, alphas=alphas,\n                                               return_models=True)\n    coef_path_cont_lasso = interpolate.interp1d(alphas_lasso[::-1],\n                                                coefs_lasso[:, ::-1])\n\n    assert_array_almost_equal(\n        coef_path_cont_lasso(alphas), coef_path_cont_lars(alphas),\n        decimal=1)\n"], "sample_107": ["    def test_sensitive_variables_decorator(self):\n        \"\"\"\n        The sensitive_variables decorator works with functions.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(sensitive_variables_function)\n            self.verify_unsafe_email(sensitive_variables_function)\n\n        with self.settings(DEBUG=False):\n            self.verify_safe_response(sensitive_variables_function)\n            self.verify_safe_email(sensitive_variables_function)\n"], "sample_949": ["def test_man_make_section_directory_with_multiple_pages(app, status, warning):\n    app.builder.build_all()\n    assert (app.outdir / 'man1' / 'index.1').exists()\n    assert (app.outdir / 'man1' / 'stasi.1').exists()\n    assert (app.outdir / 'man1' / 'python.1').exists()\n\n    content = (app.outdir / 'man1' / 'index.1').read_text()\n    assert r'\\fBprint \\fP\\fIi\\fP\\fB\\en\\fP' in content\n    assert r'\\fBmanpage\\en\\fP' in content\n\n    # term of definition list including nodes.strong\n    assert '\\n.B term1\\n' in content\n    assert '\\nterm2 (\\\\fBstronged partially\\\\fP)\\n' in content\n\n    assert 'Footnotes' not in content\n\n    content = (app.outdir / 'man1' / 'stasi.1').read_text()\n    assert r'\\fBprint \\fP\\fIi\\fP\\fB\\en\\fP' in content\n    assert r'\\fBmanpage\\en\\fP' in content\n\n    # term of definition list including nodes.strong\n    assert '\\n.B term1\\n' in content\n    assert '\\nterm2 (\\\\fBstronged partially\\\\fP)\\n' in content\n\n    assert 'Footnotes' not in content\n\n    content = (app.outdir / 'man1' / 'python.1').read_text()\n    assert ('.sp\\n'\n            'caption \\\\fItest\\\\fP rb\\n'\n            '.INDENT 0.0\\n'\n            '.INDENT 3.5\\n'\n            '.sp\\n'\n            '.nf\\n'\n            '.ft C\\n'\n            'def ruby?\\n'\n            '    false\\n'\n            'end\\n'\n            '.ft P\\n'\n            '.fi\\n'\n            '.UNINDENT\\n'\n            '.UNINDENT\\n' in content)\n"], "sample_497": ["    def test_set_units(self):\n        fig, ax = plt.subplots()\n        ax.xaxis.set_units('s')\n        assert ax.xaxis.get_units() == 's'\n        ax.xaxis.set_units(None)\n        assert ax.xaxis.get_units() is None\n"], "sample_157": ["    def test_clone_test_db(self, mocked_migrate, mocked_ensure_connection):\n        test_connection = get_connection_copy()\n        test_connection.settings_dict['TEST']['MIGRATE'] = True\n        creation = test_connection.creation_class(test_connection)\n        old_database_name = test_connection.settings_dict['NAME']\n        try:\n            with mock.patch.object(creation, '_clone_test_db'):\n                creation.clone_test_db(suffix='clone', verbosity=0, autoclobber=True, keepdb=False)\n                mocked_migrate.assert_called_once()\n        finally:\n            with mock.patch.object(creation, '_destroy_test_db'):\n                creation.destroy_test_db(old_database_name, verbosity=0)\n"], "sample_4": ["def test_read_html_table_cosmology_in_meta(self, cosmo, read, write, tmp_path, add_cu):\n    \"\"\"Test cosmology -> ascii.html -> cosmology with cosmology in meta.\"\"\"\n    fp = tmp_path / \"test_read_html_table_cosmology_in_meta.html\"\n\n    # ------------\n    # To Table\n\n    write(fp, format=\"ascii.html\", cosmology_in_meta=True)\n\n    # some checks on the saved file\n    tbl = QTable.read(fp)\n    assert tbl.meta[\"cosmology\"] == cosmo.__class__.__qualname__\n    assert tbl[\"name\"] == cosmo.name\n\n    # ------------\n    # From Table\n\n    # tests are different if the last argument is a **kwarg\n    if tuple(cosmo._init_signature.parameters.values())[-1].kind == 4:\n        got = read(fp, format=\"ascii.html\")\n\n        assert got.__class__ is cosmo.__class__\n        assert got.name == cosmo.name\n        assert got.meta == cosmo.meta\n\n        return  # don't continue testing\n\n    # read with mismatching parameters errors\n    with pytest.raises(TypeError, match=\"there are unused parameters\"):\n        read(fp, format=\"ascii.html\")\n\n    # unless mismatched are moved to meta\n    got = read(fp, format=\"ascii.html\", move_to_meta=True)\n    assert got == cosmo\n    assert got.meta == cosmo.meta\n\n    # it won't error if everything matches up\n    got = read(fp, format=\"ascii.html\")\n    assert got == cosmo\n    assert got.meta == cosmo.meta\n\n    # and it will also work if the cosmology is a class\n    # Note this is not the default output of ``write``.\n    got = read(fp, format=\"ascii.html\")\n    assert got == cosmo\n    assert got.meta == cosmo.meta\n"], "sample_476": ["    def test_update_dimensions(self):\n        \"\"\"\n        Dimensions are updated correctly when the image is updated.\n        \"\"\"\n        p = self.PersonModel(name=\"Joe\")\n        p.mugshot.save(\"mug\", self.file1)\n        self.check_dimensions(p, 4, 8)\n\n        # Update the image and check dimensions.\n        p.mugshot.save(\"mug\", self.file2)\n        self.check_dimensions(p, 8, 4)\n\n        # Update the image again and check dimensions.\n        p.mugshot.save(\"mug\", self.file1)\n        self.check_dimensions(p, 4, 8)\n"], "sample_736": ["def test_logistic_regression_path_convergence():\n    # Test that the path algorithm converges\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = [1] * 100 + [-1] * 100\n    Cs = np.logspace(0, 4, 10)\n\n    f = ignore_warnings\n    # can't test with fit_intercept=True since LIBLINEAR\n    # penalizes the intercept\n    for solver in ['sag', 'saga']:\n        coefs, Cs, _ = f(logistic_regression_path)(\n            X, y, Cs=Cs, fit_intercept=False, tol=1e-5, solver=solver,\n            max_iter=1000,\n            random_state=0)\n        for i, C in enumerate(Cs):\n            lr = LogisticRegression(C=C, fit_intercept=False, tol=1e-5,\n                                    solver=solver,\n                                    random_state=0)\n            lr.fit(X, y)\n            lr_coef = lr.coef_.ravel()\n            assert_array_almost_equal(lr_coef, coefs[i], decimal=4,\n                                      err_msg=\"with solver = %s\" % solver)\n\n    # test for fit_intercept=True\n    for solver in ('lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'):\n        Cs = [1e3]\n        coefs, Cs, _ = f(logistic_regression_path)(\n            X, y, Cs=Cs, fit_intercept=True, tol=1e-6, solver=solver,\n            intercept_scaling=10000., random_state=0)\n        lr = LogisticRegression(C=Cs[0], fit_intercept=True, tol=1e-4,\n                                intercept_scaling=10000., random_state=0)\n        lr.fit(X, y)\n        lr_coef = np.concatenate([lr.coef_.ravel(), lr.intercept_])\n        assert_array_almost_equal(lr_coef, coefs[0], decimal=4,\n                                  err_msg=\"with solver = %s\" % solver)\n"], "sample_999": ["def test_latex_Dict():\n    d = {Rational(1): 1, x**2: 2, x: 3, x**3: 4}\n    assert latex(d) == r'\\left \\{ 1 : 1, \\quad x : 3, \\quad x^{2} : 2, \\quad x^{3} : 4\\right \\}'\n    D = Dict(d)\n    assert latex(D) == r'\\left \\{ 1 : 1, \\quad x : 3, \\quad x^{2} : 2, \\quad x^{3} : 4\\right \\}'\n"], "sample_207": ["    def setUpTestData(cls):\n        cls.primitives = [True, False, 'yes', 7, 9.6]\n        values = [\n            None,\n            [],\n            {},\n            {'a': 'b', 'c': 14},\n            {\n                'a': 'b',\n                'c': 14,\n                'd': ['e', {'f': 'g'}],\n                'h': True,\n                'i': False,\n                'j': None,\n                'k': {'l': 'm'},\n                'n': [None],\n            },\n            [1, [2]],\n            {'k': True, 'l': False},\n            {\n                'foo': 'bar',\n                'baz': {'a': 'b', 'c': 'd'},\n                'bar': ['foo', 'bar'],\n                'bax': {'foo': 'bar'},\n            },\n        ]\n        cls.objs = [\n            NullableJSONModel.objects.create(value=value)\n            for value in values\n        ]\n        if connection.features.supports_primitives_in_json_field:\n            cls.objs.extend([\n                NullableJSONModel.objects.create(value=value)\n                for value in cls.primitives\n            ])\n        cls.raw_sql = '%s::jsonb' if connection.vendor == 'postgresql' else '%s'\n"], "sample_838": ["def test_column_transformer_sparse_output():\n    X_array = np.array([[0, 1, 2],\n                        [2, 4, 6],\n                        [8, 6, 4]]).T\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           sparse_threshold=0.8)\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n    assert X_trans.shape == (3, 3 + 1)\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           sparse_threshold=0.1)\n\n    X_trans = ct.fit_transform(X_array)\n    assert not sparse.issparse(X_trans)\n    assert X_trans.shape == (3, 3 + 1)\n\n    ct = ColumnTransformer([('trans1', Trans(), [0])],\n                           remainder=SparseMatrixTrans(),\n                           sparse_threshold=0.8)\n\n    X_trans = ct.fit_transform(X_array)\n    assert sparse.issparse(X_trans)\n    assert X_trans.shape == (3, 3 + 1)\n"], "sample_358": ["    def test_references_table(self):\n        index = IndexName('table', ['first_column'], 'suffix', lambda table, columns, suffix: 'index_%s_%s' % (table, columns[0]))\n        self.assertIs(index.references_table('table'), True)\n        self.assertIs(index.references_table('other'), False)\n"], "sample_777": ["def test_gradient_boosting_init_zero():\n    # Test if init='zero' works for regression and classification.\n    X = iris.data\n    y = np.array(iris.target)\n\n    est = GradientBoostingClassifier(n_estimators=20, max_depth=1,\n                                     random_state=1, init='zero')\n    est.fit(X, y)\n\n    assert_greater(est.score(X, y), 0.96)\n\n    # binary clf\n    mask = y != 0\n    y[mask] = 1\n    y[~mask] = 0\n    est = GradientBoostingClassifier(n_estimators=20, max_depth=1,\n                                     random_state=1, init='zero')\n    est.fit(X, y)\n    assert_greater(est.score(X, y), 0.96)\n\n    est = GradientBoostingRegressor(n_estimators=20, max_depth=1,\n                                     random_state=1, init='zero')\n    est.fit(boston.data, boston.target)\n    y_pred = est.predict(boston.data)\n    mse = mean_squared_error(boston.target, y_pred)\n    assert_almost_equal(mse, 33.0, decimal=0)\n\n    est = GradientBoostingRegressor(n_estimators=20, max_depth=1,\n                                     random_state=1, init='foobar')\n    assert_raises(ValueError, est.fit, boston.data, boston.target)\n"], "sample_292": ["def test_good_origin_wildcard_csrf_trusted_origin_matches_cookie_domain(self):\n    \"\"\"\n    A POST HTTPS request with a good origin that matches a CSRF_TRUSTED_ORIGINS\n    wildcard and a cookie domain should be accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['HTTP_REFERER'] = 'https://foo.example.com'\n    req.META['SERVER_PORT'] = '443'\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.process_request(req)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n    self.assertEqual(mw.allowed_origins_exact, set())\n    self.assertEqual(mw.allowed_origin_subdomains, {'https': ['.example.com']})\n"], "sample_266": ["def test_loading_replacing(self):\n    \"\"\"\n    Tests loading a replacing migration.\n    \"\"\"\n    loader = MigrationLoader(connection)\n    recorder = MigrationRecorder(connection)\n    self.addCleanup(recorder.flush)\n\n    # Load with nothing applied: replacing migration is not used.\n    loader.build_graph()\n    plan = set(loader.graph.forwards_plan(('migrations', '0002_second')))\n    plan = plan - loader.applied_migrations.keys()\n    expected_plan = {\n        ('migrations', '0001_initial'),\n        ('migrations', '0002_second'),\n    }\n    self.assertEqual(plan, expected_plan)\n\n    # Fake-apply the migration it replaces: replacing migration is used.\n    recorder.record_applied('migrations', '0001_initial')\n    loader.build_graph()\n    plan = set(loader.graph.forwards_plan(('migrations', '0002_second')))\n    plan = plan - loader.applied_migrations.keys()\n    expected_plan = {\n        ('migrations', '0002_second'),\n    }\n    self.assertEqual(plan, expected_plan)\n"], "sample_30": ["def test_get_field_by_id_or_name():\n    votable = parse(get_pkg_data_filename(\"data/regression.xml\"))\n    table = votable.get_first_table()\n    field = table.get_field_by_id_or_name(\"string_test\")\n    assert field.name == \"string_test\"\n    assert field.ID == \"string_test\"\n    field = table.get_field_by_id_or_name(\"string_test_2\")\n    assert field.name == \"string_test_2\"\n    assert field.ID == \"string_test_2\"\n    field = table.get_field_by_id_or_name(\"nonexistent\")\n    with pytest.raises(KeyError):\n        field = table.get_field_by_id_or_name(\"nonexistent\")\n"], "sample_739": ["def test_label_binarizer_sparse_output_binary():\n    y = [0, 1, 0]\n    classes = [0, 1]\n    pos_label = 2\n    neg_label = -1\n    expected = np.array([[2, -1], [-1, 2], [2, -1]])[:, 1].reshape((-1, 1))\n\n    yield check_binarized_results, y, classes, pos_label, neg_label, expected\n\n    # Binary case where sparse_output = True will not result in a ValueError\n    y = [0, 1, 0]\n    classes = [0, 1]\n    pos_label = 3\n    neg_label = 0\n    expected = np.array([[3, 0], [0, 3], [3, 0]])[:, 1].reshape((-1, 1))\n\n    yield check_binarized_results, y, classes, pos_label, neg_label, expected\n\n"], "sample_375": ["    def test_custom_manager_swappable(self):\n        \"\"\"\n        Tests making a ProjectState from unused models with custom managers\n        \"\"\"\n        new_apps = Apps(['migrations'])\n\n        class Food(models.Model):\n\n            food_mgr = FoodManager('a', 'b')\n            food_qs = FoodQuerySet.as_manager()\n            food_no_mgr = NoMigrationFoodManager('x', 'y')\n\n            class Meta:\n                app_label = \"migrations\"\n                apps = new_apps\n                swappable = 'TEST_SWAPPABLE_MODEL'\n\n        food_state = ModelState.from_model(Food)\n\n        # The default manager is used in migrations\n        self.assertEqual([name for name, mgr in food_state.managers], ['food_mgr'])\n        self.assertEqual(food_state.managers[0][1].args, ('a', 'b', 1, 2))\n"], "sample_500": ["def test_colorbar_alpha():\n    fig, ax = plt.subplots()\n    x = np.arange(1, 5).reshape(2, 2)/4\n    pc = ax.pcolormesh(x, alpha=x)\n    cb = fig.colorbar(pc, ax=ax)\n    assert cb.alpha is None\n    assert pc.get_alpha() is x\n    fig.draw_no_output()\n\n    cb.set_alpha(0.5)\n    assert cb.alpha == 0.5\n    assert pc.get_alpha() is None\n    fig.draw_no_output()\n\n    cb.set_alpha([0.5, 0.7])\n    assert cb.alpha == [0.5, 0.7]\n    assert pc.get_alpha() is None\n    fig.draw_no_output()\n\n    cb.set_alpha(np.array([0.5, 0.7]))\n    assert cb.alpha is None\n    assert pc.get_alpha() is np.array([0.5, 0.7])\n    fig.draw_no_output()\n"], "sample_776": ["def test_lars_path_positive_constraint_with_precomputed_gram():\n    # this is the main test for the positive parameter on the lars_path method\n    # the estimator classes just make use of this function\n\n    # we do the test on the diabetes dataset\n\n    # ensure that we get negative coefficients when positive=False\n    # and all positive when positive=True\n    # for method 'lar' (default) and lasso\n\n    # Once deprecation of LAR + positive option is done use these:\n    # assert_raises(ValueError, linear_model.lars_path, diabetes['data'],\n    #               diabetes['target'], method='lar', positive=True)\n\n    with pytest.warns(DeprecationWarning, match=\"broken\"):\n        linear_model.lars_path(diabetes['data'], diabetes['target'],\n                               return_path=True, method='lar',\n                               positive=True, Gram=np.dot(diabetes['data'].T,\n                                                         diabetes['data']))\n\n    method = 'lasso'\n    alpha, active, coefs = \\\n        linear_model.lars_path(diabetes['data'], diabetes['target'],\n                               return_path=True, method=method,\n                               positive=False, Gram=np.dot(diabetes['data'].T,\n                                                           diabetes['data']))\n    assert coefs.min() < 0\n\n    alpha, active, coefs = \\\n        linear_model.lars_path(diabetes['data'], diabetes['target'],\n                               return_path=True, method=method,\n                               positive=True, Gram=np.dot(diabetes['data'].T,\n                                                           diabetes['data']))\n    assert coefs.min() >= 0\n"], "sample_159": ["    def test_builtin_permission_name_max_length(self):\n        class Checked(models.Model):\n            class Meta:\n                permissions = [\n                    ('my_builtin_permission', 'Some permission'),\n                ]\n        errors = checks.run_checks(self.apps.get_app_configs())\n        max_builtin_permission_name_length = 255 - len(Checked._meta.verbose_name_raw)\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most %d \"\n                \"characters for its builtin permission names to be at most 255 characters.\" % max_builtin_permission_name_length,\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n"], "sample_632": ["def test_ignore_signatures_multiline():\n    output = StringIO()\n    with redirect_stdout(output), pytest.raises(SystemExit) as ex:\n        similar.Run([\"--ignore-signatures\", SIMILAR5, SIMILAR6])\n    assert ex.value.code == 0\n    assert (\n        output.getvalue().strip()\n        == \"\"\""], "sample_892": ["def test_adaboost_consistent_staged_predict():\n    # check that staged_predict and predict give consistent results\n    # regression test for:\n    # https://github.com/scikit-learn/scikit-learn/issues/14084\n    X_train, X_test, y_train, y_test = train_test_split(\n        *datasets.load_digits(return_X_y=True), random_state=42\n    )\n    model = AdaBoostClassifier(random_state=42)\n    model.fit(X_train, y_train)\n\n    assert_array_equal(\n        np.argmax(model.predict_proba(X_test), axis=1), model.predict(X_test)\n    )\n    assert_array_equal(\n        np.argmax(model.staged_predict(X_test), axis=1), model.predict(X_test)\n    )\n"], "sample_1010": ["def test_latex_Dict():\n    d = {x: 1, y: 2, z: 3}\n    assert latex(d) == r'\\left \\{ x : 1, \\quad y : 2, \\quad z : 3\\right \\}'\n    D = Dict(d)\n    assert latex(D) == r'\\left \\{ x : 1, \\quad y : 2, \\quad z : 3\\right \\}'\n"], "sample_674": ["def test_NodeMeta_warning():\n    \"\"\"Ensure that NodeMeta.warns about using from_parent.\"\"\"\n    class TestNode(Node, metaclass=nodes.NodeMeta):\n        pass\n\n    with pytest.warns(UserWarning, match=\"NODE_USE_FROM_PARENT\"):\n        TestNode.from_parent(None)\n\n"], "sample_432": ["def test_get_search_results_with_custom_lookup(self):\n    \"\"\"\n    Regression tests for #15819: If a field listed in search_fields is a\n    non-unique related object, results shouldn't appear more than once.\n    \"\"\"\n    lead = Musician.objects.create(name=\"Vox\")\n    band = Group.objects.create(name=\"The Hype\")\n    Concert.objects.create(name=\"Woodstock\", group=band)\n    Membership.objects.create(music=lead, group=band, role=\"lead voice\")\n    Membership.objects.create(music=lead, group=band, role=\"bass player\")\n\n    m = ConcertAdmin(Concert, custom_site)\n    m.search_fields = [\"group__members__name__cc\"]\n    with register_lookup(Field, Contains, lookup_name=\"cc\"):\n        request = self.factory.get(\"/\", data={SEARCH_VAR: \"Vox\"})\n        request.user = self.superuser\n        cl = m.get_changelist_instance(request)\n        self.assertEqual(cl.queryset.count(), 1)\n        # Queryset must be deletable.\n        self.assertIs(cl.queryset.query.distinct, False)\n        cl.queryset.delete()\n        self.assertEqual(cl.queryset.count(), 0)\n"], "sample_25": ["def test_header_remove_all(self):\n    \"\"\"Test removing all instances of a keyword.\"\"\"\n    header = fits.Header([(\"A\", \"B\"), (\"C\", \"D\"), (\"A\", \"F\")])\n    header.remove(\"A\", remove_all=True)\n    assert \"A\" not in header\n    assert len(header) == 1\n    assert list(header) == [\"C\"]\n    assert header[0] == \"D\"\n"], "sample_1135": ["def test_Mul_is_nonzero():\n    x = Symbol('x', nonzero=True)\n    y = Symbol('y', nonzero=True)\n    z = Symbol('z', nonzero=False)\n    assert (x*y).is_nonzero\n    assert (x*y*z).is_nonzero is None\n    assert (x*y*z).is_zero is None\n    assert (x*y*z).is_positive is None\n    assert (x*y*z).is_negative is None\n    assert (x*y*z).is_nonpositive is None\n    assert (x*y*z).is_nonnegative is None\n"], "sample_621": ["    def indexes(self) -> Indexes[Index]:\n        x_idx = PandasIndex(pd.Index([1, 2, 3], name=\"x\"), \"x\")\n        y_idx = PandasIndex(pd.Index([4, 5, 6], name=\"y\"), \"y\")\n        z_midx = PandasMultiIndex(\n            pd.MultiIndex.from_product([[\"a\", \"b\"], [1, 2]], names=(\"one\", \"two\")),\n            \"z\",\n        )\n\n        indexes = Indexes({\"x\": x_idx, \"y\": y_idx, \"z\": z_midx})\n\n        return indexes\n"], "sample_155": ["    def test_file_from_buffer_with_filename(self):\n        response = FileResponse(io.BytesIO(b'binary content'), filename='example.txt')\n        self.assertEqual(response['Content-Length'], '14')\n        self.assertEqual(response['Content-Type'], 'application/octet-stream')\n        self.assertEqual(response['Content-Disposition'], 'inline; filename=\"example.txt\"')\n        self.assertEqual(list(response), [b'binary content'])\n"], "sample_286": ["    def test_state_is_reset_after_save(self):\n        a = Article(\n            id=None,\n            headline='Parrot programs in Python',\n            pub_date=datetime(2005, 7, 28),\n        )\n        self.assertTrue(a._state.adding)\n        self.assertIsNone(a._state.db)\n        a.save()\n        self.assertFalse(a._state.adding)\n        self.assertEqual(a._state.db, \"default\")\n"], "sample_137": ["def test_replace_named_groups(self):\n    pattern = r'^(?P<model>\\w+)/(?P<app>\\w+)/(\\w+)$'\n    expected_output = r'^<model>/<app>/<var>$'\n    self.assertEqual(replace_named_groups(pattern), expected_output)\n"], "sample_767": ["def test_column_transformer_sparse_output():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    X_sparse = sparse.eye(3, 2).tocsr()\n\n    # test that sparse_output_ is correctly set when all transformers are sparse\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', SparseMatrixTrans(), 1)],\n                           sparse_threshold=0.8)\n    ct.fit(X_array)\n    assert ct.sparse_output_\n\n    # test that sparse_output_ is correctly set when all transformers are dense\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', TransNo2D(), 1)])\n    ct.fit(X_array)\n    assert not ct.sparse_output_\n\n    # test that sparse_output_ is correctly set when transformers are mixed\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', SparseMatrixTrans(), 1)],\n                           sparse_threshold=0.8)\n    ct.fit(X_array)\n    assert ct.sparse_output_\n\n    # test that sparse_output_ is correctly set when all transformers are sparse\n    # and sparse_threshold is 0\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', SparseMatrixTrans(), 1)],\n                           sparse_threshold=0)\n    ct.fit(X_array)\n    assert ct.sparse_output_\n\n    # test that sparse_output_ is correctly set when all transformers are dense\n    # and sparse_threshold is 0\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', TransNo2D(), 1)],\n                           sparse_threshold=0)\n    ct.fit(X_array)\n    assert not ct.sparse_output_\n\n    # test that sparse_output_ is correctly set when all transformers are sparse\n    # and sparse_threshold is 1\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', SparseMatrixTrans(), 1)],\n                           sparse_threshold=1)\n    ct.fit(X_array)\n    assert not ct.sparse_output_\n\n    # test that sparse_output_ is correctly set when all transformers are dense\n    # and sparse_threshold is 1\n    ct = ColumnTransformer([('trans1', Trans(), [0]),\n                            ('trans2', TransNo2D(), 1)],\n                           sparse_threshold=1)\n    ct.fit(X_array"], "sample_377": ["    def test_non_sensitive_request(self):\n        \"\"\"\n        Everything (request info and frame variables) can bee seen\n        in the default error reports for non-sensitive requests.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(non_sensitive_view)\n            self.verify_unsafe_email(non_sensitive_view)\n\n        with self.settings(DEBUG=False):\n            self.verify_unsafe_response(non_sensitive_view)\n            self.verify_unsafe_email(non_sensitive_view)\n"], "sample_830": ["def test_get_blas_info():\n    blas_info = _get_blas_info()\n\n    assert 'macros' in blas_info\n    assert 'lib_dirs' in blas_info\n    assert 'cblas_libs' in blas_info\n\n    # Test that macros is a string\n    assert isinstance(blis_info['macros'], str)\n\n    # Test that lib_dirs is a string\n    assert isinstance(blis_info['lib_dirs'], str)\n\n    # Test that cblas_libs is a string\n    assert isinstance(blis_info['cblas_libs'], str)\n"], "sample_606": ["def test_unify_chunks() -> None:\n    array = np.arange(12).reshape(3, 4)\n    variable = xr.Variable([\"x\", \"y\"], array)\n    data_array = xr.DataArray(variable, {\"x\": [\"a\", \"b\"], \"y\": [-1, -2]})\n    dataset = xr.Dataset({\"data\": data_array})\n\n    expected_array = np.arange(12).reshape(3, 4)\n    expected_variable = xr.Variable([\"x\", \"y\"], expected_array)\n    expected_data_array = xr.DataArray(expected_variable, {\"x\": [\"a\", \"b\"], \"y\": [-1, -2]})\n    expected_dataset = xr.Dataset({\"data\": expected_data_array})\n\n    unified_array = unify_chunks(array)\n    assert_identical(expected_array, unified_array)\n\n    unified_variable = unify_chunks(variable)\n    assert_identical(expected_variable, unified_variable)\n\n    unified_data_array = unify_chunks(data_array)\n    assert_identical(expected_data_array, unified_data_array)\n\n    unified_dataset = unify_chunks(dataset)\n    assert_identical(expected_dataset, unified_dataset)\n\n    unified_data_array = unify_chunks(data_array.groupby(\"x\"))\n    assert_identical(expected_data_array, unified_data_array)\n\n    unified_dataset = unify_chunks(dataset.groupby(\"x\"))\n    assert_identical(expected_dataset, unified_dataset)\n"], "sample_202": ["def test_hash_collision(self):\n    \"\"\"\n    A hash collision should not be accepted.\n    \"\"\"\n    storage = self.get_storage()\n    # Set initial data.\n    example_messages = ['test', 'me']\n    set_cookie_data(storage, example_messages)\n    # Create a hash collision.\n    collision = storage._hash('test')\n    # Set the cookie with the collision.\n    set_cookie_data(storage, example_messages, invalid=False, encode_empty=False)\n    # The message actually contains what we expect.\n    self.assertEqual(list(storage), example_messages)\n    # Set the cookie with the collision.\n    set_cookie_data(storage, example_messages, invalid=False, encode_empty=False)\n    # The message should be empty.\n    self.assertEqual(list(storage), [])\n"], "sample_1184": ["def test_geometric_conj_ab_infinite():\n    from sympy.physics.optics import geometric_conj_ab\n    a, b = symbols('a b')\n    assert streq(geometric_conj_ab(a, oo), a)\n    assert streq(geometric_conj_ab(oo, b), b)\n"], "sample_658": ["    def test_namespace_doctestfile_multiple_fixtures(self, testdir, scope):\n        \"\"\"\n        Check that inserting something into the namespace works in a\n        simple text file doctest with multiple fixtures\n        \"\"\"\n        testdir.makeconftest(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture(autouse=True, scope=\"{scope}\")\n                doctest_namespace['cl'] = contextlib\n\n            @pytest.fixture(autouse=True, scope=\"{scope}\")\n                doctest_namespace['os'] = os\n        \"\"\".format(\n                scope=scope\n            )\n        )\n        p = testdir.maketxtfile(\n            \"\"\"\n            >>> print(cl.__name__)\n            contextlib\n            >>> os.path.join('a', 'b')\n            'a/b'\n        \"\"\"\n        )\n        reprec = testdir.inline_run(p)\n        reprec.assertoutcome(passed=2)\n"], "sample_672": ["def test_repr_on_oldstyle():\n    \"\"\"Test saferepr() with old-style classes, which do not have __repr__ defined.\"\"\"\n\n    class OldStyleClass:\n        pass\n\n    assert saferepr(OldStyleClass()) == \"<OldStyleClass object at 0x{:x}>\".format(id(OldStyleClass()))\n"], "sample_520": ["def test_scatter3d_sorting():\n    \"\"\"Test that marker properties are correctly sorted.\"\"\"\n    y, x = np.mgrid[:10, :10]\n    z = np.arange(x.size).reshape(x.shape)\n\n    sizes = np.full(z.shape, 25)\n    sizes[0::2, 0::2] = 100\n    sizes[1::2, 1::2] = 100\n\n    facecolors = np.full(z.shape, 'C0')\n    facecolors[:5, :5] = 'C1'\n    facecolors[6:, :4] = 'C2'\n    facecolors[6:, 6:] = 'C3'\n\n    edgecolors = np.full(z.shape, 'C4')\n    edgecolors[1:5, 1:5] = 'C5'\n    edgecolors[5:9, 1:5] = 'C6'\n    edgecolors[5:9, 5:9] = 'C7'\n\n    linewidths = np.full(z.shape, 2)\n    linewidths[0::2, 0::2] = 5\n    linewidths[1::2, 1::2] = 5\n\n    x, y, z, sizes, facecolors, edgecolors, linewidths = [\n        a.flatten()\n        for a in [x, y, z, sizes, facecolors, edgecolors, linewidths]\n    ]\n\n    ax = plt.figure().add_subplot(projection='3d')\n    ax.scatter(x, y, z, s=sizes, fc=facecolors, ec=edgecolors,\n               lw=linewidths, alpha=1, depthshade=False)\n"], "sample_1149": ["def test_Singleton_registry():\n    S.register(Rational)\n    assert S.Rational is Rational(0)\n    assert S.Rational(1, 2) is Rational(1, 2)\n    assert S.Rational(1, 2) is S.Rational(1, 2)\n    S.register(Rational)\n    assert S.Rational is Rational(0)\n    assert S.Rational(1, 2) is Rational(1, 2)\n    assert S.Rational(1, 2) is S.Rational(1, 2)\n"], "sample_491": ["def test_boundfield_render_template(self):\n    class MyForm(Form):\n        first_name = CharField()\n\n    f = MyForm()\n    self.assertHTMLEqual(\n        f[\"first_name\"].render(template_name=\"forms_tests/custom_field.html\"),\n        '<label for=\"id_first_name\">First name:</label><p>Custom Field<p>'\n        '<input type=\"text\" name=\"first_name\" required id=\"id_first_name\">',\n    )\n"], "sample_746": ["def test_brier_score_loss():\n    # Test Brier score loss\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    assert_almost_equal(brier_score_loss(y_true, y_prob), 0.037)\n\n    # Test Brier score loss with sample weights\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    sample_weight = np.array([1, 2, 3, 4])\n    assert_almost_equal(brier_score_loss(y_true, y_prob, sample_weight=sample_weight), 0.037)\n\n    # Test Brier score loss with pos_label\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    assert_almost_equal(brier_score_loss(y_true, y_prob, pos_label=1), 0.037)\n\n    # Test Brier score loss with pos_label and sample weights\n    y_true = np.array([0, 1, 1, 0])\n    y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n    sample_weight = np.array([1, 2, 3, 4])\n    assert_almost_equal(brier_score_loss(y_true, y_prob, sample_weight=sample_weight, pos_label=1), 0.037)\n\n    # Test Brier score loss with categorical y_true\n    y_true = np.array([\"ham\", \"spam\", \"spam\", \"ham\"])\n    y_prob = np.array([[0.2, 0.7], [0.6, 0.5], [0.4, 0.1], [0.7, 0.2]])\n    assert_almost_equal(brier_score_loss(y_true, y_prob), 1.0383217)\n\n    # Test Brier score loss with categorical y_true and sample weights\n    y_true = np.array([\"ham\", \"spam\", \"spam\", \"ham\"])\n    y_prob = np.array([[0.2, 0.7], [0"], "sample_737": ["def test_vectorizer_fit_transform_twice():\n    # raw documents\n    data = ALL_FOOD_DOCS\n\n    # test that fit_transform can be called twice\n    vect = CountVectorizer()\n    X1 = vect.fit_transform(data)\n    X2 = vect.fit_transform(data)\n    assert_array_equal(X1.toarray(), X2.toarray())\n\n    # test that fit and transform can be called twice\n    vect = CountVectorizer()\n    X1 = vect.fit(data)\n    X2 = vect.transform(data)\n    assert_array_equal(X1.toarray(), X2.toarray())\n\n    # test that fit_transform can be called twice with different data\n    vect = CountVectorizer()\n    X1 = vect.fit_transform(data)\n    X2 = vect.fit_transform(NOTJUNK_FOOD_DOCS)\n    assert_not_equal(X1.toarray(), X2.toarray())\n"], "sample_1002": ["def test_issue_10368():\n    a = S(32442016954)/78058255275\n    assert int(a) == 41\n    assert int(-a) == -41\n"], "sample_331": ["    def test_parse_iso8601_format(self):\n        test_values = (\n            ('P4DT15H30M', timedelta(days=4, hours=15, minutes=30)),\n            ('P4DT15H30M30S', timedelta(days=4, hours=15, minutes=30, seconds=30)),\n            ('P4DT15H30M30.1S', timedelta(days=4, hours=15, minutes=30, milliseconds=100)),\n            ('P4DT15H30M30.01S', timedelta(days=4, hours=15, minutes=30, milliseconds=10)),\n            ('P4DT15H30M30.001S', timedelta(days=4, hours=15, minutes=30, milliseconds=1)),\n            ('P4DT15H30M30.0001S', timedelta(days=4, hours=15, minutes=30, microseconds=100)),\n            ('P4DT15H30M30.00001S', timedelta(days=4, hours=15, minutes=30, microseconds=10)),\n            ('P4DT15H30M30.000001S', timedelta(days=4, hours=15, minutes=30, microseconds=1)),\n            ('P4DT15H30M30,000001S', timedelta(days=4, hours=15, minutes=30, microseconds=1)),\n            ('P-4DT15H30M', timedelta(days=-4, hours=15, minutes=30)),\n            ('P-4DT15H30M30S', timedelta(days=-4, hours=15, minutes=30, seconds=30)),\n            ('P-4DT15H30M30.1S', timedelta(days=-4, hours=15, minutes=30, milliseconds=100)),\n            ('P-4DT15H30M30.01S', timedelta(days=-4, hours=15, minutes=30, milliseconds=10)),\n            ('P-4DT15H30M30.001S', timedelta(days=-4, hours=15, minutes=30, milliseconds=1)),\n            ('P-4DT15H30M30.0001S', timedelta(days=-4, hours=15, minutes=30, microseconds=100)),\n            ('P-4DT15H30M30.00001S', timedelta(days=-4, hours=15, minutes=30, microseconds="], "sample_790": ["def test_kernel_pca_kernel_params():\n    rng = np.random.RandomState(0)\n    X_fit = rng.random_sample((5, 4))\n    X_pred = rng.random_sample((2, 4))\n\n    for eigen_solver in (\"auto\", \"dense\", \"arpack\"):\n        for kernel in (\"poly\", \"sigmoid\"):\n            # transform fit data\n            kpca = KernelPCA(4, kernel=kernel, eigen_solver=eigen_solver,\n                             kernel_params={\"degree\": 2})\n            X_fit_transformed = kpca.fit_transform(X_fit)\n            X_fit_transformed2 = kpca.fit(X_fit).transform(X_fit)\n            assert_array_almost_equal(np.abs(X_fit_transformed),\n                                      np.abs(X_fit_transformed2))\n\n            # transform new data\n            X_pred_transformed = kpca.transform(X_pred)\n            assert_equal(X_pred_transformed.shape[1],\n                         X_fit_transformed.shape[1])\n\n            # inverse transform\n            # X_pred2 = kpca.inverse_transform(X_pred_transformed)\n            # assert_equal(X_pred2.shape, X_pred.shape)\n\n            # test that kernel_params are passed to the kernel function\n            kpca = KernelPCA(4, kernel=kernel, eigen_solver=eigen_solver,\n                             kernel_params={\"degree\": 2})\n            K = kpca._get_kernel(X_fit)\n            assert_equal(kpca.kernel_params, {\"degree\": 2})\n            assert_equal(K.shape, (5, 5))\n"], "sample_123": ["    def test_invalid_input(self):\n        with self.assertRaises(ValueError):\n            urlsafe_base64_decode('invalid input')\n"], "sample_494": ["    def test_serialize_deconstructible_instances(self):\n        self.assertSerializedEqual(DeconstructibleInstances())\n        self.assertSerializedResultEqual(\n            DeconstructibleInstances(),\n            (\"migrations.test_writer.DeconstructibleInstances\", {\"import migrations.test_writer\"}),\n        )\n"], "sample_945": ["def test_pydata_with_union_type_operator_old(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :annotation: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0],\n                ([desc_name, \"version\"],\n                 [desc_annotation, (\": \",\n                                    [pending_xref, \"int\"],\n                                    \" \",\n                                    [desc_sig_punctuation, \"|\"],\n                                    \" \",\n                                    [pending_xref, \"str\"])]))\n"], "sample_875": ["def test_fbeta_score_multiclass():\n    # Test fbeta_score on a crafted multiclass example\n    y_true = np.array([0, 1, 2, 2])\n    y_pred = np.array([0, 1, 2, 1])\n\n    # compute scores with default labels introspection\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average=None)\n    assert_array_almost_equal(p, [1.0, 0.5, 0.0], 2)\n    assert_array_almost_equal(r, [1.0, 0.5, 0.0], 2)\n    assert_array_almost_equal(f, [1.0, 0.5, 0.0], 2)\n    assert_array_equal(s, [1, 1, 2])\n\n    f2 = fbeta_score(y_true, y_pred, beta=2, average=None)\n    support = s\n    assert_array_almost_equal(f2, [1.0, 0.5, 0.0], 2)\n\n    # Check macro\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average=\"macro\")\n    assert_almost_equal(p, 0.5)\n    assert_almost_equal(r, 0.5)\n    assert_almost_equal(f, 0.5)\n    assert s is None\n    assert_almost_equal(\n        fbeta_score(y_true, y_pred, beta=2, average=\"macro\"), np.mean(f2)\n    )\n\n    # Check micro\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average=\"micro\")\n    assert_almost_equal(p, 0.5)\n    assert_almost_equal(r, 0.5)\n    assert_almost_equal(f, 0.5)\n    assert s is None\n    assert_almost_equal(\n        fbeta_score(y_true, y_pred, beta=2, average=\"micro\"),\n        (1 + 3) * p * r / (3 * p + r),\n    )\n\n    # Check weighted\n    p, r, f, s = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n    assert_almost_equal(p, 0.5)\n    assert_almost_equal(r, 0.5)\n    assert_almost_equal(f, 0.5)\n"], "sample_445": ["def test_time_strings_override(self):\n    \"\"\"\n    Test that time_strings can be overridden.\n    \"\"\"\n    time_strings = {\n        \"year\": ngettext_lazy(\"%(num)d year\", \"%(num)d years\", \"num\"),\n        \"month\": ngettext_lazy(\"%(num)d month\", \"%(num)d months\", \"num\"),\n        \"week\": ngettext_lazy(\"%(num)d week\", \"%(num)d weeks\", \"num\"),\n        \"day\": ngettext_lazy(\"%(num)d day\", \"%(num)d days\", \"num\"),\n        \"hour\": ngettext_lazy(\"%(num)d hour\", \"%(num)d hours\", \"num\"),\n        \"minute\": ngettext_lazy(\"%(num)d minute\", \"%(num)d minutes\", \"num\"),\n    }\n    self.assertEqual(timesince(self.t, self.t + self.oneminute, time_strings=time_strings), \"1\\xa0minute\")\n    self.assertEqual(timeuntil(self.t + self.oneminute, self.t, time_strings=time_strings), \"1\\xa0minute\")\n    self.assertEqual(timesince(self.t, self.t + self.onemonth, time_strings=time_strings), \"1\\xa0month\")\n    self.assertEqual(timeuntil(self.t + self.onemonth, self.t, time_strings=time_strings), \"1\\xa0month\")\n    self.assertEqual(timesince(self.t, self.t + self.oneweek, time_strings=time_strings), \"1\\xa0week\")\n    self.assertEqual(timeuntil(self.t + self.oneweek, self.t, time_strings=time_strings), \"1\\xa0week\")\n    self.assertEqual(timesince(self.t, self.t + self.oneday, time_strings=time_strings), \"1\\xa0day\")\n    self.assertEqual(timeuntil(self.t + self.oneday, self.t, time_strings=time_strings), \"1\\xa0day\")\n    self.assertEqual(timesince(self.t, self.t + self.onehour, time_strings=time_strings), \"1\\xa0hour\")\n    self.assertEqual(timeuntil(self.t + self.onehour, self.t, time_strings=time_strings), \"1\\xa0hour\")\n"], "sample_386": ["def test_mark_safe_decorator_does_not_affect_non_callable(self):\n    \"\"\"\n    mark_safe doesn't affect non-callable objects.\n    \"\"\"\n\n    class NonCallable:\n        pass\n\n    self.assertIs(mark_safe(NonCallable), NonCallable)\n"], "sample_856": ["def test_train_test_split_with_sparse_input():\n    # Check that train_test_split converts scipy sparse matrices\n    # to csr, as stated in the documentation\n    X = np.arange(100).reshape((10, 10))\n    X_s = coo_matrix(X)\n    y = np.arange(10)\n\n    split = train_test_split(X_s, y, test_size=None, train_size=.5)\n    X_train, X_test, y_train, y_test = split\n    assert isinstance(X_train, csr_matrix)\n    assert isinstance(X_test, csr_matrix)\n"], "sample_126": ["def test_alter_field_to_foreign_key(self):\n    \"\"\"Tests autodetection of field alterations from ForeignKey to other types.\"\"\"\n    changes = self.get_changes([self.author_empty, self.book], [self.author_empty, self.book_with_field_and_author_renamed])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, model_name=\"book\", name=\"author\")\n    self.assertEqual(changes['otherapp'][0].operations[0].field.__class__.__name__, 'ForeignKey')\n"], "sample_1046": ["def test_TensorIndexType_data():\n    Lorentz = TensorIndexType('Lorentz', dim=4)\n    Lorentz.data = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\n    m0, m1, m2, m3 = tensor_indices('m0:4', Lorentz)\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert Lorentz.metric.data == Lorentz.data\n    assert"], "sample_469": ["    def setUpTestData(cls):\n        cls.a1 = Author.objects.create(name=\"Adrian Holovaty\", age=34)\n        cls.a2 = Author.objects.create(name=\"Jacob Kaplan-Moss\", age=35)\n        cls.a3 = Author.objects.create(name=\"Brad Dayley\", age=45)\n        cls.a4 = Author.objects.create(name=\"James Bennett\", age=29)\n        cls.a5 = Author.objects.create(name=\"Jeffrey Forcier\", age=37)\n        cls.a6 = Author.objects.create(name=\"Paul Bissex\", age=29)\n        cls.a7 = Author.objects.create(name=\"Wesley J. Chun\", age=25)\n        cls.a8 = Author.objects.create(name=\"Peter Norvig\", age=57)\n        cls.a9 = Author.objects.create(name=\"Stuart Russell\", age=46)\n        cls.a1.friends.add(cls.a2, cls.a4)\n        cls.a2.friends.add(cls.a1, cls.a7)\n        cls.a4.friends.add(cls.a1)\n        cls.a5.friends.add(cls.a6, cls.a7)\n        cls.a6.friends.add(cls.a5, cls.a7)\n        cls.a7.friends.add(cls.a2, cls.a5, cls.a6)\n        cls.a8.friends.add(cls.a9)\n        cls.a9.friends.add(cls.a8)\n\n        cls.p1 = Publisher.objects.create(name=\"Apress\", num_awards=3)\n        cls.p2 = Publisher.objects.create(name=\"Sams\", num_awards=1)\n        cls.p3 = Publisher.objects.create(name=\"Prentice Hall\", num_awards=7)\n        cls.p4 = Publisher.objects.create(name=\"Morgan Kaufmann\", num_awards=9)\n        cls.p5 = Publisher.objects.create(name=\"Jonno's House of Books\", num_awards=0)\n\n        cls.b1 = Book.objects.create(\n            isbn=\"159059725\",\n            name=\"The Definitive Guide to Django: Web Development Done Right\",\n            pages=447,\n            rating=4.5,\n            price=Decimal(\"30.00\"),\n            contact=cls.a1,\n            publisher=cls.p1,\n            pubdate=datetime.date(2007, 12, 6),\n        )\n        cls.b2 = Book.objects.create(\n            isbn=\"067232959\",\n            name=\"Sams Teach Yourself Django in 24 Hours\",\n            pages=528,\n"], "sample_214": ["    def setUpTestData(cls):\n        cls.primitives = [True, False, 'yes', 7, 9.6]\n        values = [\n            None,\n            [],\n            {},\n            {'a': 'b', 'c': 14},\n            {\n                'a': 'b',\n                'c': 14,\n                'd': ['e', {'f': 'g'}],\n                'h': True,\n                'i': False,\n                'j': None,\n                'k': {'l': 'm'},\n                'n': [None],\n            },\n            [1, [2]],\n            {'k': True, 'l': False},\n            {\n                'foo': 'bar',\n                'baz': {'a': 'b', 'c': 'd'},\n                'bar': ['foo', 'bar'],\n                'bax': {'foo': 'bar'},\n            },\n        ]\n        cls.objs = [\n            NullableJSONModel.objects.create(value=value)\n            for value in values\n        ]\n        if connection.features.supports_primitives_in_json_field:\n            cls.objs.extend([\n                NullableJSONModel.objects.create(value=value)\n                for value in cls.primitives\n            ])\n        cls.raw_sql = '%s::jsonb' if connection.vendor == 'postgresql' else '%s'\n"], "sample_759": ["def test_one_hot_encoder_dtype_sparse_pandas():\n    pd = pytest.importorskip('pandas')\n\n    X_df = pd.DataFrame({'A': ['a', 'b'], 'B': [1, 2]})\n    X_expected = np.array([[1., 0., 1., 0.], [0., 1., 0., 1.]], dtype='float64')\n\n    oh = OneHotEncoder(categories='auto', dtype='float64', sparse=True)\n    assert_array_equal(oh.fit_transform(X_df).toarray(), X_expected)\n    assert_array_equal(oh.fit(X_df).transform(X_df).toarray(), X_expected)\n\n    oh = OneHotEncoder(categories='auto', dtype='float64', sparse=True)\n    assert_array_equal(oh.fit_transform(X_df).toarray(), X_expected)\n    assert_array_equal(oh.fit(X_df).transform(X_df).toarray(), X_expected)\n"], "sample_146": ["def test_language_settings_consistent_with_multiple_languages(self):\n    msg = (\n        'You have provided a value for the LANGUAGE_CODE setting that is '\n        'not in the LANGUAGES setting.'\n    )\n    for tag in ['en', 'fr', 'en-CA', 'fr-CA', 'en-357']:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag):\n            self.assertEqual(check_language_settings_consistent(None), [\n                Error(msg, id='translation.E004'),\n            ])\n"], "sample_1147": ["def test_latex_RandomDomain():\n    from sympy.stats import Normal, Die, Exponential, pspace, where\n    from sympy.stats.rv import RandomDomain\n\n    X = Normal('x1', 0, 1)\n    assert latex(where(X > 0)) == r\"\\text{Domain: }0 < x_{1} \\wedge x_{1} < \\infty\"\n\n    D = Die('d1', 6)\n    assert latex(where(D > 4)) == r\"\\text{Domain: }d_{1} = 5 \\vee d_{1} = 6\"\n\n    A = Exponential('a', 1)\n    B = Exponential('b', 1)\n    assert latex(\n        pspace(Tuple(A, B)).domain) == \\\n        r\"\\text{Domain: }0 \\leq a \\wedge 0 \\leq b \\wedge a < \\infty \\wedge b < \\infty\"\n\n    assert latex(RandomDomain(FiniteSet(x), FiniteSet(1, 2))) == \\\n        r'\\text{Domain: }\\left\\{x\\right\\}\\text{ in }\\left\\{1, 2\\right\\}'\n"], "sample_13": ["def test_longitude_wrap_at_zero():\n    \"\"\"\n    Test that Longitude wraps at zero correctly\n    \"\"\"\n    # Test that Longitude wraps at zero correctly\n    lon = Longitude([0, 360, 720] * u.deg)\n    assert np.all(lon == Longitude([0, 0, 0] * u.deg))\n    assert np.all(lon == Angle([0, 0, 0] * u.deg))\n\n    # Test that Longitude wraps at zero correctly with a wrap_angle of 180\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='180d')\n    assert np.all(lon == Longitude([-180, -180, -180] * u.deg))\n    assert np.all(lon == Angle([-180, -180, -180] * u.deg))\n\n    # Test that Longitude wraps at zero correctly with a wrap_angle of 360\n    lon = Longitude([0, 360, 720] * u.deg, wrap_angle='360d')\n    assert np.all(lon == Longitude([0, 0, 0] * u.deg))\n    assert np.all(lon == Angle([0, 0, 0] * u.deg))\n"], "sample_980": ["def test_inversion_vector():\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    assert p.inversion_vector() == [0, 0, 0, 0, 0, 0]\n    p = Permutation([3, 2, 1, 0, 4, 5])\n    assert p.inversion_vector() == [3, 2, 1, 0, 0, 0]\n    p = Permutation([4, 3, 2, 1, 0, 5])\n    assert p.inversion_vector() == [4, 3, 2, 1, 0, 0]\n    p = Permutation([5, 4, 3, 2, 1, 0])\n    assert p.inversion_vector() == [5, 4, 3, 2, 1, 0]\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    q = Permutation([0, 1, 2, 3, 4, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    assert Permutation.from_inversion_vector(q.inversion_vector()) == q\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    q = Permutation([0, 1, 2, 3, 4, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    assert Permutation.from_inversion_vector(q.inversion_vector()) == q\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    q = Permutation([0, 1, 2, 3, 4, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    assert Permutation.from_inversion_vector(q.inversion_vector()) == q\n    p = Permutation([0, 1, 2, 3, 4, 5])\n    q = Permutation([0, 1, 2, 3, 4, 5])\n    assert Permutation.from_inversion_vector(p.inversion_vector()) == p\n    assert Permutation.from_inversion_vector(q.inversion"], "sample_223": ["    def setUpTestData(cls):\n        cls.a1 = Author.objects.create(name='a1', num=1001)\n        cls.a2 = Author.objects.create(name='a2', num=2002)\n        cls.a3 = Author.objects.create(name='a3', num=3003)\n        cls.a4 = Author.objects.create(name='a4', num=4004)\n        cls.a5 = Author.objects.create(name='a5', num=5005)\n        cls.a6 = Author.objects.create(name='a6', num=6006)\n        cls.a7 = Author.objects.create(name='a7', num=7007)\n        cls.a8 = Author.objects.create(name='a8', num=8008)\n        cls.a9 = Author.objects.create(name='a9', num=9009)\n        cls.a10 = Author.objects.create(name='a10', num=10010)\n        cls.a11 = Author.objects.create(name='a11', num=11011)\n        cls.a12 = Author.objects.create(name='a12', num=12012)\n        cls.a13 = Author.objects.create(name='a13', num=13013)\n        cls.a14 = Author.objects.create(name='a14', num=14014)\n        cls.a15 = Author.objects.create(name='a15', num=15015)\n        cls.a16 = Author.objects.create(name='a16', num=16016)\n        cls.a17 = Author.objects.create(name='a17', num=17017)\n        cls.a18 = Author.objects.create(name='a18', num=18018)\n        cls.a19 = Author.objects.create(name='a19', num=19019)\n        cls.a20 = Author.objects.create(name='a20', num=20020)\n        cls.a21 = Author.objects.create(name='a21', num=21021)\n        cls.a22 = Author.objects.create(name='a22', num=22022)\n        cls.a23 = Author.objects.create(name='a23', num=23023)\n        cls.a24 = Author.objects.create(name='a24', num=24024)\n        cls.a25 = Author.objects.create(name='a25', num=25025)\n        cls.a26 = Author.objects.create(name='a26', num=26026)\n        cls.a27 = Author.objects.create(name='a27', num=27027)\n       "], "sample_522": ["def test_colorbar_orientation():\n    fig, ax = plt.subplots()\n    pc = ax.pcolormesh(np.random.randn(10, 10))\n    cb = fig.colorbar(pc, orientation='horizontal')\n    assert cb.ax.get_orientation() == 'horizontal'\n    cb = fig.colorbar(pc, orientation='vertical')\n    assert cb.ax.get_orientation() == 'vertical'\n"], "sample_670": ["def test_nested_not_and_or(expr: str, expected: bool) -> None:\n    matcher = {\"true\": True, \"false\": False}.__getitem__\n    assert evaluate(expr, matcher) is expected\n"], "sample_327": ["    def test_invalid_json_with_custom_decoder(self):\n        class CustomDecoder(json.JSONDecoder):\n                return super().__init__(object_hook=self.as_uuid, *args, **kwargs)\n\n                if 'uuid' in dct:\n                    dct['uuid'] = uuid.UUID(dct['uuid'])\n                return dct\n\n        field = JSONField(decoder=CustomDecoder)\n        with self.assertRaisesMessage(ValidationError, 'Enter a valid JSON.'):\n            field.clean('{some badly formed: json}')\n"], "sample_625": ["def test_polyval_dtype() -> None:\n    x = xr.DataArray([1, 2, 3], dims=\"x\")\n    coeffs = xr.DataArray([2, 3, 4], dims=\"degree\", coords={\"degree\": [0, 1, 2]})\n    with pytest.raises(ValueError):\n        xr.polyval(x, coeffs.astype(float))\n"], "sample_16": ["    def setup_method(self):\n        self.q = np.array([1.0, 2.0, 3.0]) * u.m\n"], "sample_277": ["def test_combine_and_non_q_object(self):\n    obj = object()\n    q = Q(x=1)\n    with self.assertRaisesMessage(TypeError, str(obj)):\n        q & obj\n    with self.assertRaisesMessage(TypeError, str(obj)):\n        q | obj\n"], "sample_20": ["def test_fits_write_drop_nonstandard_units(tmp_path):\n    # While we are generous on input (see above), we are strict on\n    # output, dropping units not recognized by the fits standard.\n    filename = tmp_path / \"test_nonstandard_units.fits\"\n    spam = u.def_unit(\"spam\")\n    t = Table()\n    t[\"a\"] = [1.0, 2.0, 3.0] * spam\n    with pytest.warns(AstropyUserWarning, match=\"spam\") as w:\n        t.write(filename)\n    assert len(w) == 1\n    if table_type is Table:\n        assert \"cannot be recovered in reading. \" in str(w[0].message)\n    else:\n        assert \"lost to non-astropy fits readers\" in str(w[0].message)\n\n    with fits.open(filename) as ff:\n        hdu = ff[1]\n        assert \"TUNIT1\" not in hdu.header\n"], "sample_1123": ["def test_CondSet_with_Assumptions():\n    x = Symbol('x', real=True)\n    c = ConditionSet(x, x > 0, S.Reals)\n    assert c == ConditionSet(x, x > 0, S.Reals)\n    assert c.subs(x, x) == c\n    assert c.subs(x, x + 1) == c\n    assert c.subs(x, x - 1) == c\n    assert c.subs(x, x + I) == c\n    assert c.subs(x, x + I**2) == c\n    assert c.subs(x, x + I**3) == c\n    assert c.subs(x, x + I**4) == c\n    assert c.subs(x, x + I**5) == c\n    assert c.subs(x, x + I**6) == c\n    assert c.subs(x, x + I**7) == c\n    assert c.subs(x, x + I**8) == c\n    assert c.subs(x, x + I**9) == c\n    assert c.subs(x, x + I**10) == c\n    assert c.subs(x, x + I**11) == c\n    assert c.subs(x, x + I**12) == c\n    assert c.subs(x, x + I**13) == c\n    assert c.subs(x, x + I**14) == c\n    assert c.subs(x, x + I**15) == c\n    assert c.subs(x, x + I**16) == c\n    assert c.subs(x, x + I**17) == c\n    assert c.subs(x, x + I**18) == c\n    assert c.subs(x, x + I**19) == c\n    assert c.subs(x, x + I**20) == c\n    assert c.subs(x, x + I**21) == c\n    assert c.subs(x, x + I**22) == c\n    assert c.subs(x, x + I**23) == c\n    assert c.subs(x, x + I**24) == c\n    assert c.subs(x, x + I**25) == c\n    assert c.subs(x, x + I**26) == c\n"], "sample_1019": ["def test_issue_6919():\n    from sympy.core.exprtools import _monotonic_sign\n    from sympy.abc import x, y, z\n    from sympy import symbols\n\n    a, b, c = symbols('a b c', commutative=False)\n    assert _monotonic_sign(a + b) is None\n    assert _monotonic_sign(a + b + c) is None\n    assert _monotonic_sign(a + b + c + a) is None\n    assert _monotonic_sign(a + b + c + a + b) is None\n    assert _monotonic_sign(a + b + c + a + b + c) is None\n    assert _monotonic_sign(a + b + c + a + b + c + a) is None\n    assert _monotonic_sign(a + b + c + a + b + c + a + b) is None\n    assert _monotonic_sign(a + b + c + a + b + c + a + b + c) is None\n    assert _monotonic_sign(a + b + c + a + b + c + a + b + c + a) is None\n    assert _monotonic_sign(a + b + c + a + b + c + a + b + c + a + b) is None\n    assert _monotonic_sign(a + b + c + a + b + c + a + b + c + a + b + c) is None\n    assert _monotonic_sign(a + b + c + a + b + c + a + b + c + a + b + c + a) is None\n    assert _monotonic_sign(a + b + c + a + b + c + a + b + c + a + b + c + a + b) is None\n    assert _monotonic_sign(a + b + c + a + b + c + a + b + c + a + b + c + a + b + c) is None\n    assert _monotonic_sign(a + b + c + a + b + c + a + b + c + a + b + c + a + b + c + a) is None\n    assert _monotonic_sign(a + b + c + a + b + c + a + b + c + a + b + c"], "sample_861": ["def test_grid_search_with_precomputed_kernel_sparse():\n    # Test that grid search works with both dense and sparse matrices\n    # when the input features are given in the form of a precomputed kernel matrix\n    X_, y_ = make_classification(n_samples=200, n_features=100, random_state=0)\n\n    # compute the training kernel matrix corresponding to the linear kernel\n    K_train = np.dot(X_[:180], X_[:180].T)\n    y_train = y_[:180]\n\n    clf = SVC(kernel='precomputed')\n    cv = GridSearchCV(clf, {'C': [0.1, 1.0]})\n    cv.fit(K_train.tocsr(), y_train)\n\n    assert cv.best_score_ >= 0\n\n    # compute the test kernel matrix\n    K_test = np.dot(X_[180:], X_[:180].T)\n    y_test = y_[180:]\n\n    y_pred = cv.predict(K_test.tocsr())\n\n    assert np.mean(y_pred == y_test) >= 0\n\n    # test error is raised when the precomputed kernel is not array-like\n    # or sparse\n    assert_raises(ValueError, cv.fit, K_train.tolist(), y_train)\n\n    # test error is raised when the precomputed kernel is not square\n    K_train = np.zeros((10, 20))\n    y_train = np.ones((10, ))\n    clf = SVC(kernel='precomputed')\n    cv = GridSearchCV(clf, {'C': [0.1, 1.0]})\n    assert_raises(ValueError, cv.fit, K_train, y_train)\n"], "sample_644": ["    def test_import_outside_toplevel(self) -> None:\n        module = astroid.MANAGER.ast_from_module_name(\"import_outside_toplevel\", REGR_DATA)\n        import_from = module.body[0]\n\n        msg = MessageTest(\n            msg_id=\"import-outside-toplevel\",\n            node=import_from,\n            args=\"import_outside_toplevel\",\n            confidence=UNDEFINED,\n            line=1,\n            col_offset=0,\n            end_line=1,\n            end_col_offset=25,\n        )\n        with self.assertAddsMessages(msg):\n            self.checker.visit_importfrom(import_from)\n"], "sample_471": ["    def test_integerfield_7(self):\n        f = IntegerField(step_size=3, min_value=10)\n        self.assertWidgetRendersTo(\n            f,\n            '<input name=\"f\" min=\"10\" step=\"3\" type=\"number\" id=\"id_f\" required>',\n        )\n        msg = (\n            \"Ensure this value is a multiple of step size 3, starting from 10, e.g. \"\n            \"10, 13, 16, and so on.\"\n        )\n        with self.assertRaisesMessage(ValidationError, msg):\n            f.clean(\"9\")\n        self.assertEqual(f.clean(\"12\"), 12)\n        self.assertEqual(f.clean(\"10\"), 10)\n        self.assertEqual(f.step_size, 3)\n        self.assertEqual(f.min_value, 10)\n"], "sample_407": ["def test_save_related_object(self):\n    # Regression for #12190 -- Should be able to save a related object\n    # outside of a model, and interrogate its related field.\n    cat = models.ForeignKey(Category, models.CASCADE)\n    cat2 = Category.objects.create(name=\"test\")\n    cat.remote_field.model.objects.create(name=\"test2\", category=cat2)\n    self.assertEqual(cat.remote_field.model.objects.count(), 1)\n"], "sample_1017": ["def test_issue_10240():\n    assert (Not(And(x > 2, x < 3))).as_set() == Union(Interval(-oo, 2), Interval(3, oo))\n"], "sample_111": ["def test_distinct_for_m2m_in_list_filter_with_params(self):\n    \"\"\"\n    If a ManyToManyField is in list_filter and is in lookup params, the\n    changelist's query should have distinct.\n    \"\"\"\n    m = BandAdmin(Band, custom_site)\n    request = self.factory.get('/band/', data={'name': 'test', 'genres': '0'})\n    request.user = self.superuser\n    cl = m.get_changelist_instance(request)\n    self.assertTrue(cl.queryset.query.distinct)\n"], "sample_270": ["    def test_index_with_condition_and_include(self):\n        class Model(models.Model):\n            age = models.IntegerField()\n\n            class Meta:\n                indexes = [\n                    models.Index(\n                        fields=['age'],\n                        name='index_age_gte_10',\n                        condition=models.Q(age__gte=10),\n                        include=['id'],\n                    ),\n                ]\n\n        errors = Model.check(databases=self.databases)\n        expected = [] if connection.features.supports_partial_indexes else [\n            Warning(\n                '%s does not support indexes with conditions.'\n                % connection.display_name,\n                hint=(\n                    \"Conditions will be ignored. Silence this warning if you \"\n                    \"don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W037',\n            )\n        ]\n        expected += [] if connection.features.supports_covering_indexes else [\n            Warning(\n                '%s does not support indexes with non-key columns.'\n                % connection.display_name,\n                hint=(\n                    \"Non-key columns will be ignored. Silence this warning if \"\n                    \"you don't care about it.\"\n                ),\n                obj=Model,\n                id='models.W040',\n            )\n        ]\n        self.assertEqual(errors, expected)\n"], "sample_840": ["def test_pls_transform_copy():\n    # check that the \"copy\" keyword works\n    d = load_linnerud()\n    X = d.data\n    Y = d.target\n    clf = pls_.PLSCanonical()\n    X_copy = X.copy()\n    Y_copy = Y.copy()\n    clf.fit(X, Y)\n    # check that results are identical with copy\n    assert_array_almost_equal(clf.transform(X, Y), clf.transform(X.copy(), Y.copy(), copy=False))\n    # check also if passing only X\n    assert_array_almost_equal(clf.transform(X), clf.transform(X.copy(), copy=False))\n    # check that copy doesn't destroy\n    # we do want to check exact equality here\n    assert_array_equal(X_copy, X)\n    assert_array_equal(Y_copy, Y)\n    # also check that mean wasn't zero before (to make sure we didn't touch it)\n    assert np.all(X.mean(axis=0) != 0)\n"], "sample_986": ["def test_evalf_issue_11518():\n    assert NS(2*x**2.5, 5) == '2.0000*x**2.5000'\n    assert NS(2*x**2.5, 10) == '2.000000000*x**2.50000000'\n    assert NS(2*x**2.5, 15) == '2.00000000000000*x**2.50000000000000'\n    assert NS(2*x**2.5, 20) == '2.000000000000000000*x**2.500000000000000000'\n"], "sample_526": ["def test_date_formatter_callable():\n    class _Locator:\n\n        return [dt.strftime('%d-%m//%Y') for dt in dates]\n\n    formatter = mdates.AutoDateFormatter(_Locator())\n    formatter.scaled[-10] = callable_formatting_function\n    assert formatter([datetime.datetime(2014, 12, 25)]) == ['25-12//2014']\n    assert formatter([datetime.datetime(2014, 12, 25), datetime.datetime(2015, 1, 1)]) == ['25-12//2014', '01-01//2015']\n"], "sample_131": ["    def test_migrate_test_setting_true(self, mocked_migrate, mocked_ensure_connection):\n        creation = connection.creation_class(connection)\n        saved_settings = copy.deepcopy(connection.settings_dict)\n        try:\n            connection.settings_dict['TEST']['MIGRATE'] = True\n            with mock.patch.object(creation, '_create_test_db'):\n                creation.create_test_db(verbosity=0, autoclobber=True, serialize=False)\n            mocked_migrate.assert_called_once_with(\n                verbosity=0,\n                database=DEFAULT_DB_ALIAS,\n                run_syncdb=True,\n                interactive=False,\n            )\n        finally:\n            connection.settings_dict = saved_settings\n"], "sample_957": ["def test_stringify_type_hints_Annotated():\n    from typing import Annotated  # type: ignore\n    assert stringify(Annotated[int, \"foo\", \"bar\"]) == \"int\"  # NOQA\n"], "sample_910": ["def test_prefixed_warnings(app, status, warning):\n    logging.setup(app, status, warning)\n    logger = logging.getLogger(__name__)\n\n    with logging.prefixed_warnings(\"prefix:\"):\n        logger.warning('message1')\n        logger.warning('message2')\n\n    assert 'prefix: message1' in warning.getvalue()\n    assert 'prefix: message2' in warning.getvalue()\n\n    with logging.prefixed_warnings(\"prefix2:\"):\n        logger.warning('message3')\n        logger.warning('message4')\n\n    assert 'prefix2: message3' in warning.getvalue()\n    assert 'prefix2: message4' in warning.getvalue()\n\n    # test that prefix is reset after exiting the context manager\n    assert 'prefix: message5' not in warning.getvalue()\n    logger.warning('message5')\n    assert 'prefix2: message6' not in warning.getvalue()\n    logger.warning('message6')\n"], "sample_979": ["def test_Transpose():\n    A = MatrixSymbol('A', n, m)\n    B = MatrixSymbol('B', m, l)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', n, n)\n    E = MatrixSymbol('E', m, n)\n    w = MatrixSymbol('w', n, 1)\n\n    assert (A.T).shape == (m, n)\n    assert (B.T).shape == (l, m)\n    assert (C.T).shape == (n, n)\n    assert (D.T).shape == (n, n)\n    assert (E.T).shape == (n, m)\n\n    assert (A.T).T == A\n    assert (B.T).T == B\n    assert (C.T).T == C\n    assert (D.T).T == D\n    assert (E.T).T == E\n\n    assert (A.T * B).shape == (m, l)\n    assert (B.T * A).shape == (l, n)\n\n    assert (A.T + B).shape == (m, l)\n    assert (B.T + A).shape == (l, n)\n\n    assert (A.T * 2).shape == (m, n)\n    assert (2 * A.T).shape == (m, n)\n\n    assert (A.T * B.T).shape == (m, l)\n    assert (B.T * A.T).shape == (l, n)\n\n    assert (A.T * (B + C)).shape == (m, n)\n    assert (B + C).T * A.T == (A.T * (B + C)).T\n\n    assert (A.T * (B * C)).shape == (m, n)\n    assert (B * C).T * A.T == (A.T * (B * C)).T\n\n    assert (A.T * (B + C + D)).shape == (m, n)\n    assert (B + C + D).T * A.T == (A.T * (B + C + D)).T\n\n    assert (A.T * (B * C * D)).shape == (m, n)\n    assert (B * C * D).T * A.T == (A.T * (B * C * D)).T\n\n    assert (A.T * (B + C + D + E)).shape =="], "sample_506": ["def test_spine_bounds():\n    \"\"\"Test Spine bounds.\"\"\"\n    fig, ax = plt.subplots()\n    spine = ax.spines['left']\n    spine.set_bounds(0, 1)\n    assert spine.get_bounds() == (0, 1)\n    spine.set_bounds(1)\n    assert spine.get_bounds() == (1, 1)\n    spine.set_bounds(0, 1, 2)\n    assert spine.get_bounds() == (0, 1)\n    with pytest.raises(ValueError, match='unable to set bounds for spine'):\n        spine.set_bounds(0, 1, 2, 3)\n    with pytest.raises(ValueError, match='unable to set bounds for spine'):\n        spine.set_bounds(0, 1, 2, 3, 4)\n    with pytest.raises(ValueError, match='unable to set bounds for spine'):\n        spine.set_bounds(0, 1, 2, 3, 4, 5)\n    with pytest.raises(ValueError, match='unable to set bounds for spine'):\n        spine.set_bounds(0, 1, 2, 3, 4, 5, 6)\n    with pytest.raises(ValueError, match='unable to set bounds for spine'):\n        spine.set_bounds(0, 1, 2, 3, 4, 5, 6, 7)\n    with pytest.raises(ValueError, match='unable to set bounds for spine'):\n        spine.set_bounds(0, 1, 2, 3, 4, 5, 6, 7, 8)\n    with pytest.raises(ValueError, match='unable to set bounds for spine'):\n        spine.set_bounds(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n    with pytest.raises(ValueError, match='unable to set bounds for spine'):\n        spine.set_bounds(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n    with pytest.raises(ValueError, match='unable to set bounds for spine'):\n        spine.set_bounds(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11)\n    with pytest.raises(ValueError, match='unable to set bounds for spine'):\n        spine.set_bounds(0, "], "sample_665": ["    def test_parametrize_with_indirect(self, testdir):\n        testdir.makepyfile(\n            \"\"\"\n                assert fix == request.param\n            @pytest.fixture\n                return request.param\n            pytest.mark.parametrize(\"fix\", [1, 2], indirect=True)(test_func)\n        \"\"\"\n        )\n        items, reprec = testdir.inline_genitems()\n        assert len(items) == 2\n        assert items[0].name == \"test_func[1]\"\n        assert items[1].name == \"test_func[2]\"\n"], "sample_125": ["    def test_set_cookie_with_secure_and_domain(self):\n        \"\"\"set_cookie() accepts secure and domain parameters.\"\"\"\n        response = HttpResponse()\n        response.set_cookie('example', secure=True, domain='example.com')\n        example_cookie = response.cookies['example']\n        self.assertIn('; %s' % cookies.Morsel._reserved['secure'], str(example_cookie))\n        self.assertEqual(example_cookie['domain'], 'example.com')\n"], "sample_656": ["    def test_global_capture_is_resumed_after_teardown(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n                print(\"teardown\")\n                print(\"in func\")\n            \"\"\"\n        )\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"*teardown*\", \"*in func*\"])\n"], "sample_1182": ["def test_SymPyPrinter():\n    p = SymPyPrinter()\n    assert p.doprint(S.Pi) == 'sympy.pi'\n    assert p.doprint(S.Exp1) == 'sympy.E'\n    assert p.doprint(S.EulerGamma) == 'sympy.EulerGamma'\n    assert p.doprint(S.NaN) == 'sympy.nan'\n    assert p.doprint(S.Infinity) == 'sympy.oo'\n    assert p.doprint(S.NegativeInfinity) == 'sympy.NegativeInfinity'\n    assert p.doprint(loggamma(x)) == 'sympy.loggamma(x)'\n    assert p.doprint(acos(x)) == 'sympy.acos(x)'\n    assert p.doprint(Assignment(x, 2)) == 'x = 2'\n    assert p.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert p.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert p.doprint(sign(x)) == '(0.0 if x == 0 else sympy.copysign(1, x))'\n    assert p.doprint(p[0, 1]) == 'p[0, 1]'\n    assert p.doprint(KroneckerDelta(x,y)) == '(1 if x == y else 0)'\n"], "sample_1104": ["def test_Derivative_printing():\n    from sympy import symbols, Function, diff\n    x, y = symbols('x y')\n    f = Function('f')\n    assert str(diff(f(x), x)) == \"Derivative(f(x), x)\"\n    assert str(diff(f(x), x, 2)) == \"Derivative(f(x), x, 2)\"\n    assert str(diff(f(x), x, 3)) == \"Derivative(f(x), x, 3)\"\n    assert str(diff(f(x), x, 4)) == \"Derivative(f(x), x, 4)\"\n    assert str(diff(f(x), x, 5)) == \"Derivative(f(x), x, 5)\"\n    assert str(diff(f(x), x, 6)) == \"Derivative(f(x), x, 6)\"\n    assert str(diff(f(x), x, 7)) == \"Derivative(f(x), x, 7)\"\n    assert str(diff(f(x), x, 8)) == \"Derivative(f(x), x, 8)\"\n    assert str(diff(f(x), x, 9)) == \"Derivative(f(x), x, 9)\"\n    assert str(diff(f(x), x, 10)) == \"Derivative(f(x), x, 10)\"\n"], "sample_1102": ["def test_Poly__hash__():\n    assert hash(Poly(x + 1)) == hash((x + 1, x))\n    assert hash(Poly(x + 1, x)) == hash((x + 1, x))\n    assert hash(Poly(x + 1, x, y)) == hash((x + 1, x, y))\n    assert hash(Poly(x + 1, x, y, z)) == hash((x + 1, x, y, z))\n    assert hash(Poly(x + 1, x, y, z, w)) == hash((x + 1, x, y, z, w))\n    assert hash(Poly(x + 1, x, y, z, w, t)) == hash((x + 1, x, y, z, w, t))\n\n    assert hash(Poly(x + 1, x, y, z, w, t, u)) == hash((x + 1, x, y, z, w, t, u))\n\n    assert hash(Poly(x + 1, x, y, z, w, t, u, v)) == hash((x + 1, x, y, z, w, t, u, v))\n\n    assert hash(Poly(x + 1, x, y, z, w, t, u, v, s)) == hash((x + 1, x, y, z, w, t, u, v, s))\n\n    assert hash(Poly(x + 1, x, y, z, w, t, u, v, s, r)) == hash((x + 1, x, y, z, w, t, u, v, s, r))\n\n    assert hash(Poly(x + 1, x, y, z, w, t, u, v, s, r, q)) == hash((x + 1, x, y, z, w, t, u, v, s, r, q))\n\n    assert hash(Poly(x + 1, x, y, z, w, t, u, v, s, r, q, p)) == hash((x + 1, x, y, z, w, t, u, v, s, r, q, p))\n\n    assert hash(Poly(x + 1, x, y"], "sample_1084": ["def test_ProductSet():\n    from sympy.sets.fancysets import ProductSet\n    from sympy.sets.sets import FiniteSet, Union, Intersection\n    from sympy import symbols, Interval, S\n\n    A = FiniteSet(1, 2, 3)\n    B = FiniteSet(4, 5, 6)\n    C = FiniteSet(7, 8, 9)\n\n    assert ProductSet(A, B, C) == FiniteSet((1, 4, 7), (1, 4, 8), (1, 4, 9),\n                                            (1, 5, 7), (1, 5, 8), (1, 5, 9),\n                                            (1, 6, 7), (1, 6, 8), (1, 6, 9),\n                                            (2, 4, 7), (2, 4, 8), (2, 4, 9),\n                                            (2, 5, 7), (2, 5, 8), (2, 5, 9),\n                                            (2, 6, 7), (2, 6, 8), (2, 6, 9),\n                                            (3, 4, 7), (3, 4, 8), (3, 4, 9),\n                                            (3, 5, 7), (3, 5, 8), (3, 5, 9),\n                                            (3, 6, 7), (3, 6, 8), (3, 6, 9))\n\n    assert ProductSet(A, B) == FiniteSet((1, 4), (1, 5), (1, 6),\n                                        (2, 4), (2, 5), (2, 6),\n                                        (3, 4), (3, 5), (3, 6))\n\n    assert ProductSet(A, B, C).intersect(ProductSet(A, B)) == ProductSet(A, B)\n\n    assert ProductSet(A, B).intersect(ProductSet(A, C)) == S.EmptySet\n\n    assert ProductSet(A, B).intersect(ProductSet(B, C)) == S.EmptySet\n\n    assert ProductSet(A, B).intersect(ProductSet(C, B)) == S.EmptySet\n\n    assert ProductSet(A, B"], "sample_405": ["    def test_references_field_by_through_model(self):\n        operation = FieldOperation(\n            \"Model\", \"field\", models.ManyToManyField(\"Other\", through=\"Through\")\n        )\n        self.assertIs(operation.references_field(\"Other\", \"whatever\", \"migrations\"), True)\n        self.assertIs(operation.references_field(\"Through\", \"whatever\", \"migrations\"), True)\n        self.assertIs(operation.references_field(\"Missing\", \"whatever\", \"migrations\"), False)\n"], "sample_424": ["    def test_references_field_by_through_model(self):\n        operation = FieldOperation(\n            \"Model\", \"field\", models.ManyToManyField(\"Other\", through=\"Through\")\n        )\n        self.assertIs(operation.references_field(\"Other\", \"whatever\", \"migrations\"), True)\n        self.assertIs(operation.references_field(\"Through\", \"whatever\", \"migrations\"), True)\n        self.assertIs(operation.references_field(\"Missing\", \"whatever\", \"migrations\"), False)\n"], "sample_114": ["def test_alter_field_to_not_null_with_default_and_blank(self):\n    \"\"\"\n    #23609 - Tests autodetection of nullable to non-nullable alterations.\n    \"\"\"\n    changes = self.get_changes([self.author_name_blank], [self.author_name_default])\n    self.assertEqual(changes, {})\n"], "sample_149": ["    def test_builtin_permission_name_max_length(self):\n        class Checked(models.Model):\n            class Meta:\n                permissions = [\n                    ('my_builtin_permission', 'Some permission'),\n                ]\n        errors = checks.run_checks(self.apps.get_app_configs())\n        permission_name_max_length = apps.get_model('auth', 'Permission')._meta.get_field('name').max_length\n        max_builtin_permission_name_length = permission_name_max_length - len(Checked._meta.verbose_name_raw)\n        self.assertEqual(errors, [\n            checks.Error(\n                \"The verbose_name of model 'auth_tests.Checked' must be at most %d characters \"\n                \"for its builtin permission names to be at most %d characters.\" % (max_builtin_permission_name_length, permission_name_max_length),\n                obj=Checked,\n                id='auth.E007',\n            ),\n        ])\n"], "sample_66": ["    def test_querydict_fromkeys(self):\n        q = QueryDict.fromkeys(['a', 'b', 'c'], 'value', encoding='utf-8')\n        self.assertEqual(q, {'a': ['value'], 'b': ['value'], 'c': ['value']})\n"], "sample_1177": ["def test_issue_22190():\n    x = Symbol('x')\n    for a in (sqrt(7 - 2*x) + 2, 1 + x):\n        assert Abs(a) + Abs(-a) == 2*Abs(a), a\n"], "sample_11": ["def test_dropped_dimensions_2d():\n    wcs = WCS_SPECTRAL_CUBE\n\n    sub = SlicedLowLevelWCS(wcs, np.s_[0, :])\n\n    dwd = sub.dropped_world_dimensions\n    wao_classes = dwd.pop(\"world_axis_object_classes\")\n    validate_info_dict(dwd, {\n        \"value\": [12.86995801],\n        \"world_axis_physical_types\": [\"pos.galactic.lat\"],\n        \"world_axis_names\": [\"Latitude\"],\n        \"world_axis_units\": [\"deg\"],\n        \"serialized_classes\": False,\n        \"world_axis_object_components\": [('celestial', 1, 'spherical.lat.degree')],\n        })\n\n    assert wao_classes['celestial'][0] is SkyCoord\n    assert wao_classes['celestial'][1] == ()\n    assert isinstance(wao_classes['celestial'][2]['frame'], Galactic)\n    assert wao_classes['celestial'][2]['unit'] is u.deg\n\n    sub = SlicedLowLevelWCS(wcs, np.s_[5, :])\n\n    dwd = sub.dropped_world_dimensions\n    wao_classes = dwd.pop(\"world_axis_object_classes\")\n    validate_info_dict(dwd, {\n        \"value\": [11.67648267],\n        \"world_axis_physical_types\": [\"pos.galactic.lat\"],\n        \"world_axis_names\": [\"Latitude\"],\n        \"world_axis_units\": [\"deg\"],\n        \"serialized_classes\": False,\n        \"world_axis_object_components\": [('celestial', 1, 'spherical.lat.degree')],\n        })\n\n    assert wao_classes['celestial'][0] is SkyCoord\n    assert wao_classes['celestial'][1] == ()\n    assert isinstance(wao_classes['celestial'][2]['frame'], Galactic)\n    assert wao_classes['celestial'][2]['unit'] is u.deg\n\n    sub = SlicedLowLevelWCS(wcs, np.s_[:, 0])\n\n    dwd = sub.dropped_world_dimensions\n    wao_classes = dwd.pop(\"world_axis_object_classes\")\n    validate_info_dict(dwd, {\n        \"value\": [0.5],\n        \"world_axis_physical_types\": [\"em.freq\"],\n        \"world_axis_names\": [\"Frequency\"],\n        \"world_axis_units\": [\"Hz\"],\n        \"serialized_classes\": False,\n        \"world_axis_object_components\": [('spectral', 0)],\n        })\n\n    assert wao_classes['spectral'][0]"], "sample_717": ["def test_load_lfw_pairs_too_restrictive():\n    assert_raises(ValueError, fetch_lfw_pairs, data_home=SCIKIT_LEARN_DATA,\n                 subset='train', min_faces_per_person=100, download_if_missing=False)\n"], "sample_31": ["def test_write_latex_cosmology_in_meta(self, write, tmp_path, format):\n    \"\"\"Test that cosmology_in_meta is False.\"\"\"\n    fp = tmp_path / \"test_write_latex_cosmology_in_meta.tex\"\n    write(fp, format=format, cosmology_in_meta=True)\n    tbl = QTable.read(fp)\n    assert not tbl.meta.get(\"cosmology_in_meta\")\n"], "sample_160": ["def test_format_large_decimal(self):\n    # Test large decimal numbers.\n    large_decimal = Decimal('1.234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012"], "sample_848": ["def test_multioutput_regressor_sample_weights():\n    # weighted regressor\n    Xw = [[1, 2, 3], [4, 5, 6]]\n    yw = [[3.141, 2.718], [2.718, 3.141]]\n    w = np.asarray([2., 1.])\n    rgr_w = MultiOutputRegressor(GradientBoostingRegressor(random_state=0))\n    rgr_w.fit(Xw, yw, w)\n\n    # unweighted, but with repeated samples\n    X = [[1, 2, 3], [1, 2, 3], [4, 5, 6]]\n    y = [[3.141, 2.718], [3.141, 2.718], [2.718, 3.141]]\n    rgr = MultiOutputRegressor(GradientBoostingRegressor(random_state=0))\n    rgr.fit(X, y)\n\n    X_test = [[1.5, 2.5, 3.5], [3.5, 4.5, 5.5]]\n    assert_almost_equal(rgr.predict(X_test), rgr_w.predict(X_test))\n"], "sample_140": ["    def test_sensitive_variables_decorator_preserves_function_signature(self):\n        \"\"\"\n        The sensitive_variables decorator preserves the function signature.\n        \"\"\"\n        @sensitive_variables('password')\n            pass\n\n        self.assertEqual(inspect.signature(test_func), inspect.signature(lambda password: None))\n"], "sample_675": ["def test_log_cli_format(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_cli_handler.level == logging.INFO\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_cli=true\n        log_cli_format = %(asctime)s - %(name)s - %(levelname)s - %(message)s\n    \"\"\"\n    )\n\n    result = testdir.runpytest(\"-s\", \"--log-cli-level=INFO\")\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines(\n        [\n            \"*test_log_cli_format.py*This log message will be shown\",\n            \"PASSED\",  # 'PASSED' on its own line because the log message prints a new line\n        ]\n    )\n    result.stdout.no_fnmatch_line(\"*This log message will be shown*\")\n\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n"], "sample_661": ["def test_record_xml_attribute_junit_disabled(testdir):\n    testdir.makepyfile(\n        \"\"\"\n            record_xml_attribute(\"foo\", \"bar\")\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 0\n"], "sample_468": ["def test_context_processors(self):\n    \"\"\"\n    Test that context processors are applied correctly.\n    \"\"\"\n    engine = Engine(\n        loaders=[\n            (\n                \"django.template.loaders.locmem.Loader\",\n                {\n                    \"child\": '{{ var|default:\"none\" }}',\n                },\n            )\n        ]\n    )\n    request = self.request_factory.get(\"/\")\n    ctx = RequestContext(request, {\"var\": \"parent\"})\n    ctx._processors = (context_process_returning_none,)\n    self.assertEqual(\n        engine.from_string('{% include \"child\" %}').render(ctx), \"parent\"\n    )\n    self.assertEqual(\n        engine.from_string('{% include \"child\" only %}').render(ctx), \"parent\"\n    )\n    ctx._processors = ()\n    self.assertEqual(\n        engine.from_string('{% include \"child\" only %}').render(ctx), \"none\"\n    )\n"], "sample_816": ["def test_hashingvectorizer_dtype():\n    # Non-regression test: HashingVectorizer used to ignore its \"dtype\" param.\n    v = HashingVectorizer(dtype=np.float32)\n    assert v.dtype == np.float32\n\n    X = v.transform(['hello world', 'hello hello']).toarray()\n    assert X.dtype == np.float32\n\n    v = HashingVectorizer(dtype=np.float64)\n    X = v.transform(['hello world', 'hello hello']).toarray()\n    assert X.dtype == np.float64\n"], "sample_261": ["    def test_iso8601_duration(self):\n        test_values = (\n            ('P4DT15H30M', timedelta(days=4, hours=15, minutes=30)),\n            ('P4DT15H30M30S', timedelta(days=4, hours=15, minutes=30, seconds=30)),\n            ('P4DT15H30M30.1S', timedelta(days=4, hours=15, minutes=30, milliseconds=100)),\n            ('P4DT15H30M30.01S', timedelta(days=4, hours=15, minutes=30, milliseconds=10)),\n            ('P4DT15H30M30.001S', timedelta(days=4, hours=15, minutes=30, milliseconds=1)),\n            ('P4DT15H30M30.0001S', timedelta(days=4, hours=15, minutes=30, microseconds=100)),\n            ('P4DT15H30M30.00001S', timedelta(days=4, hours=15, minutes=30, microseconds=10)),\n            ('P4DT15H30M30.000001S', timedelta(days=4, hours=15, minutes=30, microseconds=1)),\n            ('P4DT15H30M30,000001S', timedelta(days=4, hours=15, minutes=30, microseconds=1)),\n            ('P-4DT15H30M', timedelta(days=-4, hours=15, minutes=30)),\n            ('P-4DT15H30M30S', timedelta(days=-4, hours=15, minutes=30, seconds=30)),\n            ('P-4DT15H30M30.1S', timedelta(days=-4, hours=15, minutes=30, milliseconds=100)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_257": ["    def test_raw_expression(self):\n        expr = RawSQL(self.raw_sql, ['{\"x\": \"bar\"}'])\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(value__foo=expr),\n            [self.objs[7]],\n        )\n"], "sample_1144": ["def test_requires_partial_with_multiple_derivatives():\n    x, y, z = symbols('x y z')\n    f = x * y * z\n    assert requires_partial(Derivative(f, x, y)) is True\n    assert requires_partial(Derivative(f, x, y, z)) is True\n    assert requires_partial(Derivative(f, x, x)) is True\n    assert requires_partial(Derivative(f, y, y)) is True\n    assert requires_partial(Derivative(f, z, z)) is True\n\n    f = x ** 2 * y ** 2 * z ** 2\n    assert requires_partial(Derivative(f, x, y)) is True\n    assert requires_partial(Derivative(f, x, y, z)) is True\n    assert requires_partial(Derivative(f, x, x)) is True\n    assert requires_partial(Derivative(f, y, y)) is True\n    assert requires_partial(Derivative(f, z, z)) is True\n\n    f = x * y * z * (x + y + z)\n    assert requires_partial(Derivative(f, x, y)) is True\n    assert requires_partial(Derivative(f, x, y, z)) is True\n    assert requires_partial(Derivative(f, x, x)) is True\n    assert requires_partial(Derivative(f, y, y)) is True\n    assert requires_partial(Derivative(f, z, z)) is True\n\n    f = x * y * z * (x + y + z) ** 2\n    assert requires_partial(Derivative(f, x, y)) is True\n    assert requires_partial(Derivative(f, x, y, z)) is True\n    assert requires_partial(Derivative(f, x, x)) is True\n    assert requires_partial(Derivative(f, y, y)) is True\n    assert requires_partial(Derivative(f, z, z)) is True\n"], "sample_198": ["    def setUpTestData(cls):\n        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max2 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max3 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max4 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max5 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max6 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max7 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max8 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max9 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max10 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max11 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max12 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max13 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max14 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max15 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max16 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max17 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max18 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max19 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max20 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max21 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max22 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max23 = Employee.objects.create(firstname='"], "sample_720": ["def test_power_transformer_axis1():\n    X = np.abs(X_2d)\n\n    for standardize in [True, False]:\n        pt = PowerTransformer(method='box-cox', standardize=standardize)\n\n        X_trans_class = pt.fit_transform(X.T)\n        X_trans_func = power_transform(X.T, standardize=standardize)\n\n        for X_trans in [X_trans_class, X_trans_func]:\n            for i in range(X_trans.shape[1]):\n                X_expected, lmbda = stats.boxcox(X[:, i].flatten())\n\n                if standardize:\n                    X_expected = scale(X_expected)\n\n                assert_almost_equal(X_trans[:, i], X_expected)\n                assert_almost_equal(lmbda, pt.lambdas_[i])\n\n            # Test inverse transformation\n            X_inv = pt.inverse_transform(X_trans)\n            assert_array_almost_equal(X_inv.T, X.T)\n\n        assert len(pt.lambdas_) == X.shape[0]\n        assert isinstance(pt.lambdas_, np.ndarray)\n"], "sample_404": ["    def test_debugging_with_context(self):\n        \"\"\"\n        # 16770 -- The template system doesn't wrap exceptions, but annotates\n        them.\n        \"\"\"\n        engine = self._engine(debug=True)\n        c = Context({\"coconuts\": lambda: 42 / 0})\n        t = engine.from_string(\"{{ coconuts }}\")\n\n        with self.assertRaises(ZeroDivisionError) as e:\n            t.render(c)\n\n        if self.debug_engine:\n            debug = e.exception.template_debug\n            self.assertEqual(debug[\"start\"], 0)\n            self.assertEqual(debug[\"end\"], 14)\n            self.assertEqual(debug[\"name\"], \"unknown\")\n            self.assertEqual(debug[\"line\"], 1)\n            self.assertEqual(debug[\"total\"], 1)\n            self.assertEqual(debug[\"top\"], 1)\n            self.assertEqual(debug[\"bottom\"], 1)\n            self.assertEqual(debug[\"before\"], \"\")\n            self.assertEqual(debug[\"during\"], \"{{ coconuts }}\")\n            self.assertEqual(debug[\"after\"], \"\")\n            self.assertEqual(debug[\"message\"], \"(Could not get exception message)\")\n"], "sample_677": ["def test_or_precedence(expr: str, expected: bool) -> None:\n    matcher = {\"true\": True, \"false\": False}.__getitem__\n    assert evaluate(expr, matcher) is expected\n"], "sample_397": ["def test_template_loaders_configurable(self):\n    \"\"\"Template loaders can be configured.\"\"\"\n    engine = DjangoTemplates(\n        {\n            \"DIRS\": [],\n            \"APP_DIRS\": False,\n            \"NAME\": \"django\",\n            \"OPTIONS\": {\n                \"loaders\": [\n                    \"django.template.loaders.cached.Loader\",\n                    \"django.template.loaders.filesystem.Loader\",\n                ],\n            },\n        }\n    )\n    self.assertEqual(\n        engine.engine.loaders,\n        [\n            (\n                \"django.template.loaders.cached.Loader\",\n                [\n                    \"django.template.loaders.filesystem.Loader\",\n                ],\n            )\n        ],\n    )\n\n    engine = DjangoTemplates(\n        {\n            \"DIRS\": [],\n            \"APP_DIRS\": False,\n            \"NAME\": \"django\",\n            \"OPTIONS\": {\n                \"loaders\": [\n                    \"django.template.loaders.app_directories.Loader\",\n                    \"django.template.loaders.filesystem.Loader\",\n                ],\n            },\n        }\n    )\n    self.assertEqual(\n        engine.engine.loaders,\n        [\n            (\n                \"django.template.loaders.cached.Loader\",\n                [\n                    \"django.template.loaders.app_directories.Loader\",\n                    \"django.template.loaders.filesystem.Loader\",\n                ],\n            )\n        ],\n    )\n\n    engine = DjangoTemplates(\n        {\n            \"DIRS\": [],\n            \"APP_DIRS\": False,\n            \"NAME\": \"django\",\n            \"OPTIONS\": {\n                \"loaders\": [\n                    \"django.template.loaders.app_directories.Loader\",\n                    \"django.template.loaders.filesystem.Loader\",\n                    \"django.template.loaders.cached.Loader\",\n                ],\n            },\n        }\n    )\n    self.assertEqual(\n        engine.engine.loaders,\n        [\n            (\n                \"django.template.loaders.cached.Loader\",\n                [\n                    \"django.template.loaders.app_directories.Loader\",\n                    \"django.template.loaders.filesystem.Loader\",\n                ],\n            )\n        ],\n    )\n\n    engine = DjangoTemplates(\n        {\n            \"DIRS\": [],\n            \"APP_DIRS\": False,\n            \"NAME\": \"django\",\n            \"OPTIONS\": {\n                \"loaders\": [\n                    \"django.template.loaders.filesystem.Loader\",\n                    \"django.template.loaders.app_directories.Loader\",\n                    \"django.template.loaders.cached.Loader\",\n                ],\n            },\n        }\n    )\n    self.assertEqual(\n        engine.engine.loaders,\n        [\n            (\n                \"django.template.loaders.cached.Loader\",\n                [\n                    \"django.template.loaders.filesystem.Loader\",\n                    \"django.template.loaders.app_directories.Loader\",\n"], "sample_406": ["    def test_manager_attributes(self):\n        self.assertEqual(Article.objects.model, Article)\n        self.assertEqual(Article.objects.name, 'objects')\n        self.assertEqual(Article.objects._db, None)\n        self.assertEqual(Article.objects._hints, {})\n        self.assertEqual(Article.objects.creation_counter, BaseManager.creation_counter)\n        self.assertEqual(Article.objects.auto_created, False)\n        self.assertEqual(Article.objects.use_in_migrations, False)\n"], "sample_785": ["def test_predefinedsplit_repr():\n    # Check that PredefinedSplit has a correct repr\n    ps = PredefinedSplit([1, 1, 2, 2])\n    assert_equal(repr(ps), \"PredefinedSplit(test_fold=array([1, 1, 2, 2]))\")\n"], "sample_1207": ["def test_lambda_notation():\n    x = Symbol('x')\n    y = Symbol('y')\n    z = Symbol('z')\n    assert parse_expr('lambda x: x + y', transformations=lambda_notation) == Lambda(x, x + y)\n    assert parse_expr('lambda x, y: x + y', transformations=lambda_notation) == Lambda(x, Lambda(y, x + y))\n    assert parse_expr('lambda x: x + lambda y: y + z', transformations=lambda_notation) == Lambda(x, Lambda(y, y + z) + x)\n    assert parse_expr('lambda x: x + lambda y: y + lambda z: z', transformations=lambda_notation) == Lambda(x, Lambda(y, Lambda(z, z) + y) + x)\n    assert parse_expr('lambda x: x + lambda y: y + lambda z: z + lambda w: w', transformations=lambda_notation) == Lambda(x, Lambda(y, Lambda(z, Lambda(w, w) + z) + y) + x)\n"], "sample_760": ["def test_make_scorer_needs_proba_needs_threshold():\n    # Test that make_scorer raises an error when both needs_proba and needs_threshold are True\n    scorer = make_scorer(roc_auc_score, needs_proba=True, needs_threshold=True)\n    assert_raises(ValueError, scorer, None, None, None)\n"], "sample_652": ["    def test_setup(self, testdir, scope, ok, error):\n        testdir.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.fixture(scope=%r, autouse=True)\n                for x in %r:\n                    assert hasattr(request, x)\n                for x in %r:\n                    pytest.raises(AttributeError, lambda:\n                        getattr(request, x))\n                assert request.session\n                assert request.config\n                pass\n        \"\"\"\n            % (scope, ok.split(), error.split())\n        )\n        reprec = testdir.inline_run(\"-l\")\n        reprec.assertoutcome(passed=1)\n"], "sample_1074": ["def test_is_solvable():\n    # every abelian group is solvable\n    for i in (1, 2, 3):\n        C = CyclicGroup(i)\n        Ab = AbelianGroup(i, i + 2)\n        assert C.is_solvable\n        assert Ab.is_solvable\n    Ab = AbelianGroup(5, 7, 10)\n    assert Ab.is_solvable\n    # A_5 is not solvable\n    assert AlternatingGroup(5).is_solvable is False\n"], "sample_113": ["    def test_field_description(self):\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.EmailField()),\n            'Email address'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.CharField(max_length=255)),\n            'Character field (max length: 255)'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.CharField(max_length=255, blank=True)),\n            'Character field (max length: 255, blank=True)'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.CharField(max_length=255, null=True)),\n            'Character field (max length: 255, null=True)'\n        )\n        self.assertEqual(\n            views.get_readable_field_data_type(fields.CharField(max_length=255, blank=True, null=True)),\n            'Character field (max length: 255, blank=True, null=True)'\n        )\n"], "sample_1003": ["def test_BuildOptions():\n    opt = Options((x, y, z), {'domain': 'ZZ'})\n\n    assert opt.gens == (x, y, z)\n    assert opt.domain == ZZ\n    assert ('order' in opt) is False\n\n    new_opt = build_options((x, y, z), {'domain': 'ZZ'})\n\n    assert new_opt.gens == (x, y, z)\n    assert new_opt.domain == ZZ\n    assert ('order' in new_opt) is False\n\n    new_opt = build_options((x, y, z), {'opt': {'domain': 'ZZ'}})\n\n    assert new_opt.gens == (x, y, z)\n    assert new_opt.domain == ZZ\n    assert ('order' in new_opt) is False\n\n    raises(OptionError, lambda: build_options((x, y, z), {'opt': {'domain': 'abc'}))\n"], "sample_629": ["def test_expand_modules_empty_list():\n    patterns = [\n        re.compile(\".*enchilada.*\"),\n        re.compile(\"unittest_.*\"),\n        re.compile(\".*tests/.*\"),\n    ]\n    ignore_list = [\"unittest_utils.py\"]\n    ignore_list_re = patterns\n    ignore_list_paths_re = []\n    result, errors = expand_modules([], ignore_list, ignore_list_re, ignore_list_paths_re)\n    assert result == []\n    assert errors == []\n"], "sample_89": ["    def test_iter_modules_and_files_cache(self):\n        filename = self.temporary_file('test_module.py')\n        filename.write_text('import os')\n        with extend_sys_path(str(filename.parent)):\n            self.import_and_cleanup('test_module')\n        self.assertFileFound(filename)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().hits, 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().misses, 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().maxsize, 1)\n        self.clear_autoreload_caches()\n        self.assertFileFound(filename)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().hits, 2)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().misses, 1)\n"], "sample_59": ["    def test_unique_together_validation(self):\n        # Test that validate_unique() raises a ValidationError when a unique_together constraint is violated\n        article = Article.objects.create(headline=\"Article 1\", pub_date=datetime.datetime.now())\n        article2 = Article.objects.create(headline=\"Article 1\", pub_date=datetime.datetime.now())\n        with self.assertRaises(ValidationError):\n            article2.validate_unique()\n"], "sample_411": ["    def test_command_error_returncode(self):\n        with self.assertRaises(CommandError) as cm:\n            raise CommandError(\"Test error\", returncode=5)\n        self.assertEqual(cm.exception.returncode, 5)\n"], "sample_221": ["def test_pickle_values_list_flat(self):\n    qs = Happening.objects.values_list('name', flat=True)\n    reloaded = Happening.objects.all()\n    reloaded.query = pickle.loads(pickle.dumps(qs.query))\n    self.assertEqual(reloaded.get(), 'test')\n"], "sample_813": ["def test_bayesian_ridge_parameter_init():\n    # Test correctness of lambda_ and alpha_ parameters with initial values\n    X = np.array([[1, 1], [3, 4], [5, 7], [4, 1], [2, 6], [3, 10], [3, 2]])\n    y = np.array([1, 2, 3, 2, 0, 4, 5]).T\n\n    # A Ridge regression model using an alpha value equal to the ratio of\n    # lambda_ and alpha_ from the Bayesian Ridge model must be identical\n    br_model = BayesianRidge(alpha_init=1., lambda_init=1e-3).fit(X, y)\n    rr_model = Ridge(alpha=br_model.lambda_ / br_model.alpha_).fit(X, y)\n    assert_array_almost_equal(rr_model.coef_, br_model.coef_)\n    assert_almost_equal(rr_model.intercept_, br_model.intercept_)\n"], "sample_188": ["    def setUpTestData(cls):\n        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max2 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max3 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max4 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max5 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max6 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max7 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max8 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max9 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max10 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max11 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max12 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max13 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max14 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max15 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max16 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max17 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max18 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max19 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max20 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max21 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max22 = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max23 = Employee.objects.create(firstname='"], "sample_177": ["    def test_custom_manager_swappable(self):\n        \"\"\"\n        Tests making a ProjectState from unused models with custom managers\n        \"\"\"\n        new_apps = Apps(['migrations'])\n\n        class Food(models.Model):\n\n            food_mgr = FoodManager('a', 'b')\n            food_qs = FoodQuerySet.as_manager()\n            food_no_mgr = NoMigrationFoodManager('x', 'y')\n\n            class Meta:\n                app_label = \"migrations\"\n                apps = new_apps\n                swappable = 'TEST_SWAPPABLE_MODEL'\n\n        food_state = ModelState.from_model(Food)\n\n        # The default manager is used in migrations\n        self.assertEqual([name for name, mgr in food_state.managers], ['food_mgr'])\n        self.assertEqual(food_state.managers[0][1].args, ('a', 'b', 1, 2))\n"], "sample_168": ["def test_include_stale_apps(self):\n    \"\"\"\n    include_stale_apps option deletes stale content types including ones from\n    previously installed apps that have been removed from INSTALLED_APPS.\n    \"\"\"\n    self.app_config = apps.get_app_config('empty_models')\n    ContentType.objects.create(app_label='empty_models', model='Fake 1')\n    ContentType.objects.create(app_label='no_models', model='Fake 2')\n    apps.apps_ready.disconnect('empty_models')\n    apps.apps_ready.connect('empty_models')\n    with mock.patch('builtins.input', return_value='yes'), captured_stdout() as stdout:\n        call_command('remove_stale_contenttypes', include_stale_apps=True, verbosity=2)\n    self.assertIn(\n        \"Deleting stale content type 'empty_models | Fake 1'\",\n        stdout.getvalue(),\n    )\n    self.assertIn(\n        \"Deleting stale content type 'no_models | Fake 2'\",\n        stdout.getvalue(),\n    )\n    self.assertEqual(ContentType.objects.count(), self.before_count + 1)\n"], "sample_345": ["    def test_iter_modules_and_files_with_zip_import(self):\n        \"\"\"\n        Modules imported from zipped files have their archive location included\n        in the result.\n        \"\"\"\n        zip_file = self.temporary_file('zip_import.zip')\n        with zipfile.ZipFile(str(zip_file), 'w', zipfile.ZIP_DEFLATED) as zipf:\n            zipf.writestr('test_zipped_file.py', '')\n\n        with extend_sys_path(str(zip_file)):\n            self.import_and_cleanup('test_zipped_file')\n        self.assertFileFound(zip_file)\n"], "sample_169": ["    def test_json_field_with_custom_encoder_and_decoder(self):\n        value = {'uuid': uuid.UUID('{d85e2076-b67c-4ee7-8c3a-2bf5a2cc2475}')}\n        obj = JSONModel(value=value)\n        obj.save()\n        obj.refresh_from_db()\n        self.assertEqual(obj.value, value)\n"], "sample_283": ["def test_empty_settings(self):\n    self.assertEqual(\n        self.settings_to_cmd_args_env({\n            'NAME': '',\n            'USER': '',\n            'HOST': '',\n            'PORT': '',\n        }), (\n            ['psql'],\n            {},\n        )\n    )\n"], "sample_696": ["def test_argument_percent_default_is_deprecated() -> None:\n    with pytest.warns(\n        pytest.PytestDeprecationWarning,\n        match=re.escape(\n            \"'%default' should be changed to '%(default)s'\"\n        ),\n    ):\n        pytest.main([\"-h\"])\n"], "sample_637": ["    def test_encoding_ascii(self) -> None:\n        code = \"\"\"a = 1\n                # FIXME message\n                \"\"\"\n        with self.assertNoMessages():\n            self.checker.process_module(nodes.Module(code))\n"], "sample_701": ["def test_argument_percent_default_is_deprecated() -> None:\n    with pytest.warns(\n        pytest.PytestDeprecationWarning,\n        match=re.escape(\n            \"'pytest now uses argparse. \"%default\" should be changed to \"%(default)s\"'\n        ),\n    ):\n        pytest.main([\"--help\"])\n"], "sample_76": ["def test_language_settings_consistent(self):\n    # Test that LANGUAGE_CODE is consistent with LANGUAGES\n    for tag in self.valid_tags:\n        with self.subTest(tag), self.settings(LANGUAGE_CODE=tag, LANGUAGES=[(tag, tag)]):\n            self.assertEqual(check_language_settings_consistent(None), [])\n\n    # Test that LANGUAGE_CODE is not in LANGUAGES\n    with self.settings(LANGUAGE_CODE='en', LANGUAGES=[('en-us', 'English (US)')]):\n        self.assertEqual(check_language_settings_consistent(None), [E004])\n\n    # Test that LANGUAGE_CODE is in LANGUAGES but LANGUAGES is empty\n    with self.settings(LANGUAGE_CODE='en', LANGUAGES=[]):\n        self.assertEqual(check_language_settings_consistent(None), [E004])\n\n    # Test that LANGUAGE_CODE is not in LANGUAGES and LANGUAGES is empty\n    with self.settings(LANGUAGE_CODE='en', LANGUAGES=[]):\n        self.assertEqual(check_language_settings_consistent(None), [E004])\n\n    # Test that LANGUAGE_CODE is not in LANGUAGES_BIDI\n    with self.settings(LANGUAGE_CODE='en', LANGUAGES_BIDI=['en-us']):\n        self.assertEqual(check_language_settings_consistent(None), [E004])\n\n    # Test that LANGUAGE_CODE is in LANGUAGES_BIDI\n    with self.settings(LANGUAGE_CODE='en', LANGUAGES_BIDI=['en']):\n        self.assertEqual(check_language_settings_consistent(None), [])\n\n    # Test that LANGUAGE_CODE is in LANGUAGES but LANGUAGES_BIDI is empty\n    with self.settings(LANGUAGE_CODE='en', LANGUAGES_BIDI=[]):\n        self.assertEqual(check_language_settings_consistent(None), [])\n\n    # Test that LANGUAGE_CODE is not in LANGUAGES and LANGUAGES_BIDI is empty\n    with self.settings(LANGUAGE_CODE='en', LANGUAGES_BIDI=[]):\n        self.assertEqual(check_language_settings_consistent(None), [E004])\n"], "sample_936": ["def test_stringify_type_hints_Generic():\n    class MyGeneric(Generic[T]):\n        pass\n\n    assert stringify(MyGeneric) == \"Generic[T]\"\n    assert stringify(MyGeneric[int]) == \"Generic[int]\"\n    assert stringify(MyGeneric[str]) == \"Generic[str]\"\n    assert stringify(MyGeneric[int, str]) == \"Generic[int, str]\"\n"], "sample_255": ["    def test_get_environ(self):\n        \"\"\"WSGIRequestHandler strips headers with underscores from the WSGI environ.\"\"\"\n            \"\"\"A WSGI app that just reflects its HTTP environ.\"\"\"\n            start_response('200 OK', [])\n            http_environ_items = sorted(\n                '%s:%s' % (k, v) for k, v in environ.items()\n                if k.startswith('HTTP_')\n            )\n            yield (','.join(http_environ_items)).encode()\n\n        rfile = BytesIO()\n        rfile.write(b\"GET / HTTP/1.0\\r\\n\")\n        rfile.write(b\"Some-Header: good\\r\\n\")\n        rfile.write(b\"Some_Header: bad\\r\\n\")\n        rfile.write(b\"Other_Header: bad\\r\\n\")\n        rfile.seek(0)\n\n        # WSGIRequestHandler closes the output file; we need to make this a\n        # no-op so we can still read its contents.\n        class UnclosableBytesIO(BytesIO):\n                pass\n\n        wfile = UnclosableBytesIO()\n\n            if mode == 'rb':\n                return rfile\n            elif mode == 'wb':\n                return wfile\n\n        handler = WSGIRequestHandler(\n            Stub(environ={'HTTP_Some-Header': 'good', 'HTTP_Some_Header': 'bad', 'HTTP_Other_Header': 'bad'}),\n            '192.168.0.2', None\n        )\n        environ = handler.get_environ()\n        self.assertIn('HTTP_Some-Header', environ)\n        self.assertNotIn('HTTP_Some_Header', environ)\n        self.assertNotIn('HTTP_Other_Header', environ)\n"], "sample_857": ["def test_min_impurity_decrease_with_min_samples_split():\n    # Test if min_impurity_decrease ensures that a split is made only if\n    # if the impurity decrease is atleast that value when min_samples_split is\n    # used.\n    X, y = datasets.make_classification(n_samples=10000, random_state=42)\n\n    # test both DepthFirstTreeBuilder and BestFirstTreeBuilder\n    # by setting max_leaf_nodes\n    for max_leaf_nodes, name in product((None, 1000), ALL_TREES.keys()):\n        TreeEstimator = ALL_TREES[name]\n\n        # Check default value of min_impurity_decrease, 1e-7\n        est1 = TreeEstimator(max_leaf_nodes=max_leaf_nodes, random_state=0)\n        # Check with explicit value of 0.05\n        est2 = TreeEstimator(max_leaf_nodes=max_leaf_nodes,\n                             min_impurity_decrease=0.05, random_state=0)\n        # Check with a much lower value of 0.0001\n        est3 = TreeEstimator(max_leaf_nodes=max_leaf_nodes,\n                             min_impurity_decrease=0.0001, random_state=0)\n        # Check with a much lower value of 0.1\n        est4 = TreeEstimator(max_leaf_nodes=max_leaf_nodes,\n                             min_impurity_decrease=0.1, random_state=0)\n\n        for est, expected_decrease in ((est1, 1e-7), (est2, 0.05),\n                                       (est3, 0.0001), (est4, 0.1)):\n            assert est.min_impurity_decrease <= expected_decrease, (\n                \"Failed, min_impurity_decrease = {0} > {1}\".format(\n                    est.min_impurity_decrease,\n                    expected_decrease))\n            est.fit(X, y, min_samples_split=10)\n            for node in range(est.tree_.node_count):\n                # If current node is a not leaf node, check if the split was\n                # justified w.r.t the min_impurity_decrease\n                if est.tree_.children_left[node] != TREE_LEAF:\n                    imp_parent = est.tree_.impurity[node]\n                    wtd_n_node = est.tree_.weighted_n_node_samples[node]\n\n                    left = est.tree_.children_left[node]\n                    wtd_n_left = est.tree_.weighted_n_node_samples[left]\n                    imp_left"], "sample_702": ["def test_pytester_syspathinsert(pytester: Pytester) -> None:\n    pytester.syspathinsert(\"/tmp\")\n    assert \"/tmp\" in sys.path\n    pytester._finalize()\n    assert \"/tmp\" not in sys.path\n"], "sample_337": ["def test_https_good_referer_matches_cookie_domain_with_different_port_and_trusted_origin(self):\n    \"\"\"\n    A POST HTTPS request with a good referer should be accepted from a subdomain\n    that's allowed by CSRF_COOKIE_DOMAIN and a non-443 port, and also from a\n    trusted origin.\n    \"\"\"\n    self._test_https_good_referer_matches_cookie_domain_with_different_port()\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_REFERER'] = 'https://dashboard.example.com'\n    req.META['HTTP_HOST'] = 'www.example.com'\n    req.META['SERVER_PORT'] = '4443'\n    mw = CsrfViewMiddleware(post_form_view)\n    mw.process_request(req)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n"], "sample_354": ["    def setUp(self):\n        self.email = Email.objects.create(email='mymail@gmail.com')\n        self.group = Group.objects.create(name='mygroup')\n"], "sample_288": ["    def test_ordering_grouping_by_key_transform_with_custom_decoder(self):\n        NullableJSONModel.objects.create(value_custom={'a': 'b'})\n        qs = NullableJSONModel.objects.filter(value_custom__isnull=False)\n        self.assertSequenceEqual(\n            qs.values(\n                'value_custom__a',\n            ).annotate(\n                count=Count('id'),\n            ).order_by('value_custom__a'),\n            [{'value_custom__a': 'b', 'count': 1}],\n        )\n"], "sample_902": ["def test_pipeline_memory_cache_hit():\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    cachedir = mkdtemp()\n    try:\n        memory = Memory(cachedir=cachedir, verbose=10)\n        # Test with Transformer + SVC\n        clf = SVC(probability=True, random_state=0)\n        transf = DummyTransf()\n        pipe = Pipeline([('transf', clone(transf)), ('svc', clf)])\n        cached_pipe = Pipeline([('transf', transf), ('svc', clf)],\n                               memory=memory)\n\n        # Memoize the transformer at the first fit\n        cached_pipe.fit(X, y)\n        # Check that the cache is hit when fitting a second time\n        cached_pipe.fit(X, y)\n        # Check that cached_pipe and pipe yield identical results\n        assert_array_equal(pipe.predict(X), cached_pipe.predict(X))\n        assert_array_equal(pipe.predict_proba(X), cached_pipe.predict_proba(X))\n        assert_array_equal(pipe.predict_log_proba(X),\n                           cached_pipe.predict_log_proba(X))\n        assert_array_equal(pipe.score(X, y), cached_pipe.score(X, y))\n        assert_array_equal(pipe.named_steps['transf'].means_,\n                           cached_pipe.named_steps['transf'].means_)\n        assert_false(hasattr(transf, 'means_'))\n    finally:\n        shutil.rmtree(cachedir)\n"], "sample_648": ["def test_parametrize_with_empty_sequence(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"arg\", [])\n            pass\n    \"\"\"\n    )\n    result = pytester.runpytest()\n    result.stdout.fnmatch_lines(\n        [\n            \"collected 0 items / 1 error\",\n            \"* ERROR collecting test_parametrize_with_empty_sequence.py *\",\n            \"Empty parameter set in 'test_func' at line 3\",\n            \"*= 1 error in *\",\n        ]\n    )\n    assert result.ret == ExitCode.INTERRUPTED\n"], "sample_1188": ["def test_issue_23058():\n    from sympy import symbols, sin, cos, pi, UnevaluatedExpr\n\n    delop = Del()\n    CC_   = CoordSys3D(\"C\")\n    y     = CC_.y\n    xhat  = CC_.i\n\n    t = symbols(\"t\")\n    ten = symbols(\"10\", positive=True)\n    eps, mu = 4*pi*ten**(-11), ten**(-5)\n\n    Bx = 2 * ten**(-4) * cos(ten**5 * t) * sin(ten**(-3) * y)\n    vecB = Bx * xhat\n    vecE = (1/eps) * Integral(delop.cross(vecB/mu).doit(), t)\n    vecE = vecE.doit()\n\n    vecB_str = \"\"\"\\"], "sample_722": ["def test_mb_kmeans_init_size_warning():\n    # Check that a warning is raised when init_size is smaller than n_clusters\n    mb_k_means = MiniBatchKMeans(init_size=10, n_clusters=20, random_state=42)\n    assert_warns(RuntimeWarning, mb_k_means.fit, X)\n"], "sample_553": ["def test_movie_writer_finish(tmpdir):\n    class DummyMovieWriter(animation.MovieWriter):\n            pass\n\n            self.fig = fig\n            self.outfile = outfile\n            self.dpi = dpi\n            self.args = args\n            self._count = 0\n\n            from matplotlib.animation import _validate_grabframe_kwargs\n            _validate_grabframe_kwargs(savefig_kwargs)\n            self.savefig_kwargs = savefig_kwargs\n            self._count += 1\n\n            self._proc.returncode = 1\n\n    fig, ax = plt.subplots()\n    filename = \"unused.null\"\n    dpi = 50\n    savefig_kwargs = dict(foo=0)\n    writer = DummyMovieWriter()\n\n    with tmpdir.as_cwd():\n        with writer.saving(fig, filename, dpi):\n            writer.grab_frame()\n            writer.finish()\n\n    assert writer.fig == plt.figure(1)  # The figure used by anim fixture\n    assert writer.outfile == filename\n    assert writer.dpi == dpi\n    assert writer.args == ()\n    # we enrich the savefig kwargs to ensure we composite transparent\n    # output to an opaque background\n    for k, v in savefig_kwargs.items():\n        assert writer.savefig_kwargs[k] == v\n    assert writer._count == 1\n    assert writer._proc.returncode == 1\n"], "sample_993": ["def test_FreeGroupElm_cyclic_reduction():\n    w = x**2*y**2*x**-1\n    assert w.cyclic_reduction() == (x*y**2, x**-1)\n    assert w.cyclic_reduction(removed=True) == ((x*y**2, x**-1), x)\n\n    w2 = x**-3*y**-1*x**5\n    assert w2.cyclic_reduction() == (y**-1*x**2, x**-3)\n    assert w2.cyclic_reduction(removed=True) == ((y**-1*x**2, x**-3), x**5)\n\n    w3 = x**2*y**-1*x**-1\n    assert w3.cyclic_reduction() == (x*y**-1, x**-2)\n    assert w3.cyclic_reduction(removed=True) == ((x*y**-1, x**-2), x)\n\n    w4 = x**-3*y**-1*x**5\n    assert w4.cyclic_reduction() == (y**-1*x**2, x**-3)\n    assert w4.cyclic_reduction(removed=True) == ((y**-1*x**2, x**-3), x**5)\n\n    w5 = x**-3*y**-1*x**5\n    assert w5.cyclic_reduction() == (y**-1*x**2, x**-3)\n    assert w5.cyclic_reduction(removed=True) == ((y**-1*x**2, x**-3), x**5)\n\n    w6 = x**-3*y**-1*x**5\n    assert w6.cyclic_reduction() == (y**-1*x**2, x**-3)\n    assert w6.cyclic_reduction(removed=True) == ((y**-1*x**2, x**-3), x**5)\n\n    w7 = x**-3*y**-1*x**5\n    assert w7.cyclic_reduction() == (y**-1*x**2, x**-3)\n    assert w7.cyclic_reduction(removed=True) == ((y**-1*x**2, x**-3), x**5)\n\n    w8 = x**-3*y**-1*x**5\n    assert w8.cyclic_reduction() == (y**-1*x**2,"], "sample_35": ["def test_minversion():\n    # Test that minversion returns False when the module version is less than the specified version\n    assert not minversion('astropy', '0.4.5')\n    assert not minversion('astropy', '0.4.4', inclusive=False)\n\n    # Test that minversion returns True when the module version is greater than or equal to the specified version\n    assert minversion('astropy', '0.4.4')\n    assert minversion('astropy', '0.4.4', inclusive=False)\n\n    # Test that minversion returns False when the module version is not a string\n    with pytest.raises(ValueError):\n        minversion('astropy', 0.4.4)\n\n    # Test that minversion returns False when the module is not found\n    with pytest.raises(ImportError):\n        minversion('nonexistent_module', '0.4.4')\n\n    # Test that minversion returns False when the module has a version that is not a string\n    class TestModule:\n        __version__ = 0.4.4\n    assert not minversion(TestModule, '0.4.4')\n\n    # Test that minversion returns False when the version path is not a string\n    class TestModule:\n        __version__ = '0.4.4'\n    assert not minversion(TestModule, '0.4.4', version_path=123)\n"], "sample_189": ["    def test_cache_versioning_touch(self):\n        cache.set('answer1', 42, version=2)\n        self.assertIsNone(cache.get('answer1'))\n        self.assertIsNone(cache.get('answer1', version=1))\n        self.assertEqual(cache.get('answer1', version=2), 42)\n        self.assertIsNone(cache.get('answer1', version=3))\n\n        self.assertIs(cache.touch('answer1', version=2), True)\n        self.assertEqual(cache.get('answer1', version=2), 42)\n        self.assertIsNone(cache.get('answer1', version=3))\n\n        caches['v2'].set('answer2', 42)\n        self.assertEqual(caches['v2'].get('answer2'), 42)\n        self.assertIsNone(caches['v2'].get('answer2', version=1))\n        self.assertEqual(caches['v2'].get('answer2', version=2), 42)\n        self.assertIsNone(caches['v2'].get('answer2', version=3))\n\n        self.assertIs(caches['v2'].touch('answer2', version=2), True)\n        self.assertEqual(caches['v2'].get('answer2', version=2), 42)\n        self.assertIsNone(caches['v2'].get('answer2', version=3))\n\n        with self.assertRaises(ValueError):\n            cache.touch('does_not_exist', version=2)\n\n        with self.assertRaises(ValueError):\n            caches['v2'].touch('does_not_exist', version=2)\n"], "sample_791": ["def test_one_hot_encoder_sparse_output():\n    X = [[3, 2, 1], [0, 1, 1]]\n    enc = OneHotEncoder(sparse=True)\n    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):\n        X_trans = enc.fit_transform(X)\n        assert sparse.isspmatrix_csr(X_trans)\n        assert_array_equal(X_trans.toarray(), [[0., 1., 0., 1., 1.],\n                                              [1., 0., 1., 0., 1.]])\n"], "sample_784": ["def test_calibration_brier_score():\n    \"\"\"Test that brier score is improved by calibration\"\"\"\n    n_samples = 100\n    X, y = make_classification(n_samples=2 * n_samples, n_features=6,\n                               random_state=42)\n    sample_weight = np.random.RandomState(seed=42).uniform(size=y.size)\n\n    X -= X.min()  # MultinomialNB only allows positive X\n\n    # split train and test\n    X_train, y_train, sw_train = \\\n        X[:n_samples], y[:n_samples], sample_weight[:n_samples]\n    X_test, y_test = X[n_samples:], y[n_samples:]\n\n    # Naive-Bayes\n    clf = MultinomialNB().fit(X_train, y_train, sample_weight=sw_train)\n    prob_pos_clf = clf.predict_proba(X_test)[:, 1]\n\n    pc_clf = CalibratedClassifierCV(clf, cv=2)\n    pc_clf.fit(X_train, y_train, sample_weight=sw_train)\n    prob_pos_pc_clf = pc_clf.predict_proba(X_test)[:, 1]\n\n    # Check that brier score has improved after calibration\n    assert_greater(brier_score_loss(y_test, prob_pos_clf),\n                   brier_score_loss(y_test, prob_pos_pc_clf))\n\n    # Check that calibration improves brier score for different methods\n    for method in ['isotonic', 'sigmoid']:\n        pc_clf = CalibratedClassifierCV(clf, method=method, cv=2)\n        pc_clf.fit(X_train, y_train, sample_weight=sw_train)\n        prob_pos_pc_clf = pc_clf.predict_proba(X_test)[:, 1]\n        assert_greater(brier_score_loss(y_test, prob_pos_clf),\n                       brier_score_loss(y_test, prob_pos_pc_clf))\n\n    # Check that calibration improves brier score for different base estimators\n    for base_estimator in [RandomForestClassifier(n_estimators=10),\n                          LinearSVC(random_state=42)]:\n        pc_clf = CalibratedClassifierCV(base_estimator, cv=2)\n        pc_clf.fit(X_train, y_train, sample_weight=sw_train)\n        prob_pos_pc_clf = pc_clf.predict_proba(X_test)[:, 1]\n        assert_greater(brier_score_loss(y_test, prob_pos_clf),\n                       brier_score_loss(y_test, prob_pos_pc_clf))\n"], "sample_851": ["def test_mean_squared_log_error_at_zero():\n    # Test that mean_squared_log_error returns 0 when y_true and y_pred are both 0\n    assert_almost_equal(mean_squared_log_error([0], [0]), 0.00, 2)\n    assert_almost_equal(mean_squared_log_error([0], [0], squared=False), 0.00, 2)\n\n    # Test that mean_squared_log_error raises a ValueError when y_true or y_pred is negative\n    err_msg = (\"Mean Squared Logarithmic Error cannot be used when targets \"\n               \"contain negative values.\")\n    with pytest.raises(ValueError, match=err_msg):\n        mean_squared_log_error([-1], [1])\n    with pytest.raises(ValueError, match=err_msg):\n        mean_squared_log_error([1], [-1])\n    with pytest.raises(ValueError, match=err_msg):\n        mean_squared_log_error([-1], [-1])\n\n    # Test that mean_squared_log_error raises a ValueError when y_true or y_pred is zero\n    err_msg = (\"Mean Squared Logarithmic Error cannot be used when targets \"\n               \"contain zero values.\")\n    with pytest.raises(ValueError, match=err_msg):\n        mean_squared_log_error([0], [1])\n    with pytest.raises(ValueError, match=err_msg):\n        mean_squared_log_error([1], [0])\n    with pytest.raises(ValueError, match=err_msg):\n        mean_squared_log_error([0], [0])\n"], "sample_218": ["def test_trunc_func_with_timezone_and_output_field(self):\n    start_datetime = datetime(2015, 6, 15, 14, 30, 50, 321)\n    end_datetime = datetime(2016, 6, 15, 14, 10, 50, 123)\n    if settings.USE_TZ:\n        start_datetime = timezone.make_aware(start_datetime, is_dst=False)\n        end_datetime = timezone.make_aware(end_datetime, is_dst=False)\n    self.create_model(start_datetime, end_datetime)\n    self.create_model(end_datetime, start_datetime)\n\n    melb = pytz.timezone('Australia/Melbourne')\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_datetime', kind, output_field=DateTimeField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.astimezone(melb), kind, melb)),\n                (end_datetime, truncate_to(end_datetime.astimezone(melb), kind, melb))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_date', kind, output_field=DateField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.date(), kind)),\n                (end_datetime, truncate_to(end_datetime.date(), kind))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n        self.assertQuerysetEqual(\n            DTModel.objects.annotate(\n                truncated=Trunc('start_time', kind, output_field=TimeField(), tzinfo=melb)\n            ).order_by('start_datetime'),\n            [\n                (start_datetime, truncate_to(start_datetime.time(), kind, melb)),\n                (end_datetime, truncate_to(end_datetime.time(), kind, melb))\n            ],\n            lambda m: (m.start_datetime, m.truncated)\n        )\n\n    test_date_kind('year')\n    test_date_kind('quarter')\n    test_date_kind('month')\n    test_date_kind('week')\n    test_date_kind('day')\n    test_time_kind('hour')\n    test_time_kind('minute')\n    test_time_kind('second')\n"], "sample_175": ["    def test_delete_with_keeping_parents_reverse_relationships(self):\n        child = RChild.objects.create()\n        parent_id = child.r_ptr_id\n        parent_referent_id = S.objects.create(r=child.r_ptr).pk\n        child.delete(keep_parents=True)\n        self.assertFalse(RChild.objects.filter(id=child.id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n\n        childchild = RChildChild.objects.create()\n        parent_id = childchild.rchild_ptr.r_ptr_id\n        child_id = childchild.rchild_ptr_id\n        parent_referent_id = S.objects.create(r=childchild.rchild_ptr.r_ptr).pk\n        childchild.delete(keep_parents=True)\n        self.assertFalse(RChildChild.objects.filter(id=childchild.id).exists())\n        self.assertTrue(RChild.objects.filter(id=child_id).exists())\n        self.assertTrue(R.objects.filter(id=parent_id).exists())\n        self.assertTrue(S.objects.filter(pk=parent_referent_id).exists())\n"], "sample_281": ["def test_to_field_resolution_with_fk(self):\n    \"\"\"\n    to_field resolution should correctly resolve for target models using FK.\n    \"\"\"\n    tests = [\n        (Author, Authorship, 'author'),\n        (Book, Authorship, 'author'),\n    ]\n    for Target, Remote, related_name in tests:\n        with self.subTest(target_model=Target, remote_model=Remote, related_name=related_name):\n            o = Target.objects.create(name=\"Frida Kahlo\", gender=2, code=\"painter\", alive=False)\n            opts = {\n                'app_label': Remote._meta.app_label,\n                'model_name': Remote._meta.model_name,\n                'field_name': related_name,\n            }\n            request = self.factory.get(self.url, {'term': 'frida', **opts})\n            request.user = self.superuser\n            response = AutocompleteJsonView.as_view(**self.as_view_args)(request)\n            self.assertEqual(response.status_code, 200)\n            data = json.loads(response.content.decode('utf-8'))\n            self.assertEqual(data, {\n                'results': [{'id': str(o.pk), 'text': o.name}],\n                'pagination': {'more': False},\n            })\n"], "sample_395": ["def test_template_dirs_with_filesystem_loader(self):\n    self.assertSetEqual(\n        autoreload.get_template_directories(),\n        {\n            ROOT / \"absolute_str\",\n            Path.cwd() / \"template_tests/relative_str\",\n        },\n    )\n"], "sample_171": ["def test_migrate_plan_unapplied(self):\n    \"\"\"\n    Tests migrate --plan output when there are unapplied migrations.\n    \"\"\"\n    recorder = MigrationRecorder(connection)\n    recorder.record_applied(\"migrations\", \"0001_initial\")\n    out = io.StringIO()\n    with self.assertRaises(SystemExit):\n        call_command('migrate', 'migrations', '0002', check_unapplied=True, plan=True, stdout=out)\n    self.assertEqual(\n        'Planned operations:\\n'\n        'migrations.0001_initial\\n'\n        '    Undo Create model Salamander\\n'\n        \"    Raw SQL operation -> ['SELECT * FROM migrations_salamand\u2026\\n\"\n        'migrations.0002_second\\n'\n        '    Undo Create model Book\\n'\n        \"    Raw SQL operation -> ['SELECT * FROM migrations_book']\\n\",\n        out.getvalue()\n    )\n"], "sample_332": ["def test_formset_can_order_with_initial_data(self):\n    \"\"\"\n    Formsets with ordering + initial data.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_order=True)\n    initial = [{'choice': 'Calexico', 'votes': 100}, {'choice': 'Fergie', 'votes': 900}]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_457": ["    def test_deconstruction_with_expressions_and_fields(self):\n        fields = [\"foo\", \"bar\"]\n        name = \"unique_fields\"\n        constraint = models.UniqueConstraint(fields=fields, name=name, expressions=[F(\"baz\")])\n        path, args, kwargs = constraint.deconstruct()\n        self.assertEqual(path, \"django.db.models.UniqueConstraint\")\n        self.assertEqual(args, (F(\"baz\"),))\n        self.assertEqual(kwargs, {\"fields\": tuple(fields), \"name\": name})\n"], "sample_638": ["def test_graphviz_unsupported_image_format(mock_writer, capsys):\n    \"\"\"Test that Graphviz is used if the image format is not supported.\"\"\"\n    mock_subprocess.run.return_value.stderr = (\n        'Format: \"XYZ\" not recognized. Use one of: '\n        \"bmp canon cgimage cmap cmapx cmapx_np dot dot_json eps exr fig gd \"\n        \"gd2 gif gv icns ico imap imap_np ismap jp2 jpe jpeg jpg json json0 \"\n        \"mp pct pdf pic pict plain plain-ext png pov ps ps2 psd sgi svg svgz \"\n        \"tga tif tiff tk vdx vml vmlz vrml wbmp webp xdot xdot1.2 xdot1.4 xdot_json\"\n    )\n    with pytest.raises(SystemExit) as wrapped_sysexit:\n        # we have to catch the SystemExit so the test execution does not stop\n        main.Run([\"-o\", \"xyz\", TEST_DATA_DIR])\n    # Check that the right info message is shown to the user\n    assert (\n        f\"Format xyz is not supported natively. Pyreverse will try to generate it using Graphviz...\"\n        in capsys.readouterr().out\n    )\n    # Check that pyreverse actually made the call to create the diagram and we exit cleanly\n    mock_writer.DiagramWriter().write.assert_called_once()\n    assert wrapped_sysexit.value.code == 0\n"], "sample_563": ["def test_offsetbox_set_width_height():\n    fig, ax = plt.subplots()\n    da = DrawingArea(100, 100)\n    da.set_width(50)\n    da.set_height(75)\n    assert da.width == 50\n    assert da.height == 75\n    assert da.get_bbox(ax.figure._get_renderer()).bounds == (0, -75, 50, 100)\n"], "sample_298": ["def test_token_with_different_algorithm(self):\n    \"\"\"\n    A valid token can be created with a different algorithm.\n    \"\"\"\n    user = User.objects.create_user('tokentestuser', 'test2@example.com', 'testpw')\n    p0 = PasswordResetTokenGenerator()\n    p0.algorithm = 'sha1'\n    tk0 = p0.make_token(user)\n    self.assertIs(p0.check_token(user, tk0), True)\n    # Create and check a token with the default algorithm.\n    p1 = PasswordResetTokenGenerator()\n    self.assertEqual(p1.algorithm, 'sha256')\n    self.assertNotEqual(p1.algorithm, 'sha1')\n    tk1 = p1.make_token(user)\n    # Tokens created with a different algorithm don't validate.\n    self.assertIs(p0.check_token(user, tk1), False)\n    self.assertIs(p1.check_token(user, tk0), False)\n"], "sample_614": ["def test_inline_dask_repr(self) -> None:\n    da = xr.DataArray(np.arange(100), dims=\"x\", chunks=(10,))\n\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10,)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.arange(100), dims=\"x\", chunks=(10, 10))\n\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.arange(100), dims=\"x\", chunks=(10, 10, 10))\n\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10, 10)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.arange(100), dims=\"x\", chunks=(10, 10, 10, 10))\n\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10, 10, 10)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.arange(100), dims=\"x\", chunks=(10, 10, 10, 10, 10))\n\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10, 10, 10, 10)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.arange(100), dims=\"x\", chunks=(10, 10, 10, 10, 10, 10))\n\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10, 10, 10, 10, 10)>\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert expected == actual\n\n    da = xr.DataArray(np.arange(100), dims=\"x\", chunks=(10, 10, 10, 10, 10, 10, 10))\n\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10, 10, 10, 10,"], "sample_183": ["    def setUpTestData(cls):\n        o = CaseTestModel.objects.create(integer=1, integer2=1, string='1')\n        FKCaseTestModel.objects.create(fk=o, integer=1)\n        FKCaseTestModel.objects.create(fk=o, integer=2)\n        FKCaseTestModel.objects.create(fk=o, integer=3)\n"], "sample_351": ["def test_choices_frozen(self):\n    f = forms.ModelChoiceField(Category.objects.all())\n    # Freeze the queryset.\n    f.queryset = f.queryset._frozen = True\n    self.assertEqual(len(f.choices), 4)\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c1.pk, 'Entertainment'),\n        (self.c2.pk, 'A test'),\n        (self.c3.pk, 'Third'),\n    ])\n    # Delete a Category object.\n    Category.objects.get(url='third').delete()\n    # The choices should not change.\n    self.assertEqual(len(f.choices), 4)\n    self.assertEqual(list(f.choices), [\n        ('', '---------'),\n        (self.c1.pk, 'Entertainment'),\n        (self.c2.pk, 'A test'),\n        (self.c3.pk, 'Third'),\n    ])\n"], "sample_1166": ["def test_monomial_ldiv():\n    assert monomial_ldiv((3, 4, 1), (1, 2, 0)) == (2, 2, 1)\n    assert monomial_ldiv((3, 4, 1), (1, 2, 2)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 3)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 4)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 5)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 6)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 7)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 8)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 9)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 10)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 11)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 12)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 13)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 14)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 15)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 16)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 17)) is None\n    assert monomial_ldiv((3, 4, 1), (1, 2, 18)) is None\n    assert monomial_ldiv((3"], "sample_1032": ["def test_issue_12345():\n    from sympy.abc import x, y, z\n    n = Symbol('n', negative=True)\n    p = Symbol('p', positive=True)\n    np = Symbol('np', nonpositive=True)\n    nn = Symbol('nn', nonnegative=True)\n\n    # test that Min and Max handle non-real arguments correctly\n    assert Min(I, x).is_real is False\n    assert Max(I, x).is_real is False\n    assert Min(I, x).is_nonnegative is None\n    assert Max(I, x).is_nonnegative is None\n    assert Min(I, x).is_positive is None\n    assert Max(I, x).is_positive is None\n\n    # test that Min and Max handle non-comparable arguments correctly\n    assert Min(x, y).is_real is True\n    assert Max(x, y).is_real is True\n    assert Min(x, y).is_nonnegative is None\n    assert Max(x, y).is_nonnegative is None\n    assert Min(x, y).is_positive is None\n    assert Max(x, y).is_positive is None\n\n    # test that Min and Max handle arguments with different assumptions correctly\n    assert Min(n, p).is_real is True\n    assert Max(n, p).is_real is True\n    assert Min(n, p).is_nonnegative is None\n    assert Max(n, p).is_nonnegative is None\n    assert Min(n, p).is_positive is None\n    assert Max(n, p).is_positive is None\n\n    # test that Min and Max handle arguments with different assumptions and non-real arguments correctly\n    assert Min(n, I).is_real is False\n    assert Max(n, I).is_real is False\n    assert Min(n, I).is_nonnegative is None\n    assert Max(n, I).is_nonnegative is None\n    assert Min(n, I).is_positive is None\n    assert Max(n, I).is_positive is None\n\n    # test that Min and Max handle arguments with different assumptions and non-comparable arguments correctly\n    assert Min(n, x).is_real is True\n    assert Max(n, x).is_real is True\n    assert Min(n, x).is_nonnegative is None\n    assert Max(n, x).is_nonnegative is None\n    assert Min(n, x).is_positive is None\n    assert Max(n, x).is_positive is None"], "sample_210": ["    def _assert_about(self, response):\n        response.render()\n        self.assertContains(response, '<h1>About</h1>')\n"], "sample_429": ["    def test_base_equality(self):\n        self.assertEqual(\n            BaseValidator(True),\n            BaseValidator(True),\n        )\n        self.assertEqual(\n            BaseValidator(True),\n            mock.ANY,\n        )\n        self.assertNotEqual(\n            BaseValidator(True),\n            BaseValidator(False),\n        )\n        self.assertNotEqual(\n            BaseValidator(True),\n            MaxValueValidator(44),\n        )\n        self.assertNotEqual(\n            MaxValueValidator(44),\n            MinValueValidator(44),\n        )\n"], "sample_77": ["def test_avoid_wrapping(self):\n    items = (\n        ('Hello, world!', 'Hello, world!'),\n        ('Hello, world!  Hello, world!', 'Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!', 'Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!'),\n        ('Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello,"], "sample_439": ["def test_boundfield_subwidgets(self):\n    class SomeForm(Form):\n        field = MultipleChoiceField(\n            choices=[(\"a\", \"A\"), (\"b\", \"B\")],\n            widget=CheckboxSelectMultiple,\n        )\n\n    form = SomeForm(auto_id=False)\n    subwidgets = form[\"field\"].subwidgets\n    self.assertEqual(len(subwidgets), 2)\n    self.assertIsInstance(subwidgets[0], CheckboxSelectMultiple)\n    self.assertIsInstance(subwidgets[1], CheckboxSelectMultiple)\n    self.assertEqual(subwidgets[0].value(), \"a\")\n    self.assertEqual(subwidgets[1].value(), \"b\")\n    self.assertEqual(subwidgets[0].label(), \"A\")\n    self.assertEqual(subwidgets[1].label(), \"B\")\n    self.assertEqual(subwidgets[0].id_for_label, None)\n    self.assertEqual(subwidgets[1].id_for_label, None)\n    self.assertEqual(subwidgets[0].tag(), '<input type=\"checkbox\" name=\"field\" value=\"a\">')\n    self.assertEqual(subwidgets[1].tag(), '<input type=\"checkbox\" name=\"field\" value=\"b\">')\n    self.assertEqual(subwidgets[0].label_tag(), \"A\")\n    self.assertEqual(subwidgets[1].label_tag(), \"B\")\n    self.assertEqual(subwidgets[0].legend_tag(), \"A\")\n    self.assertEqual(subwidgets[1].legend_tag(), \"B\")\n    self.assertEqual(subwidgets[0].css_classes(), \"\")\n    self.assertEqual(subwidgets[1].css_classes(), \"\")\n    self.assertEqual(subwidgets[0].css_classes(extra_classes=\"test\"), \"test\")\n    self.assertEqual(subwidgets[1].css_classes(extra_classes=\"test\"), \"test\")\n    self.assertEqual(subwidgets[0].css_classes(extra_classes=\"test test\"), \"test\")\n    self.assertEqual(subwidgets[1].css_classes(extra_classes=\"test test\"), \"test\")\n    self.assertEqual(subwidgets[0].value(), \"a\")\n    self.assertEqual(subwidgets[1].value(), \"b\")\n    self.assertEqual(subwidgets[0].value(), \"a\")\n    self.assertEqual(subwidgets[1].value(), \"b\")\n    self.assertEqual(subwidgets[0].value(), \"a\")\n    self.assertEqual(subwidgets[1].value(), \"b\")\n    self.assertEqual(subwidgets[0].value(), \"a\")\n    self.assertEqual(subwidgets[1].value(), \"b\")\n    self.assertEqual(subwidgets[0].value(), \"a\")\n    self"], "sample_883": ["def test_bayesian_ridge_fit_intercept():\n    # Test correctness of fit_intercept parameter\n    X = np.array([[1, 1], [3, 4], [5, 7], [4, 1], [2, 6], [3, 10], [3, 2]])\n    y = np.array([1, 2, 3, 2, 0, 4, 5]).T\n\n    # A Ridge regression model using an alpha value equal to the ratio of\n    # lambda_ and alpha_ from the Bayesian Ridge model must be identical\n    br_model = BayesianRidge(compute_score=True, fit_intercept=False).fit(X, y)\n    rr_model = Ridge(alpha=br_model.lambda_ / br_model.alpha_).fit(X, y)\n    assert_array_almost_equal(rr_model.coef_, br_model.coef_)\n    assert_almost_equal(rr_model.intercept_, br_model.intercept_)\n"], "sample_147": ["def test_difference_with_distinct(self):\n    qs1 = Number.objects.filter(num__lte=5)\n    qs2 = Number.objects.filter(num__lte=4)\n    self.assertNumbersEqual(qs1.difference(qs2, distinct=True), [5], ordered=False)\n"], "sample_487": ["    def test_prepopulated_fields_with_one_to_one_field(self):\n        class TestModelAdmin(ModelAdmin):\n            prepopulated_fields = {\"best_friend\": (\"name\",)}\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'prepopulated_fields' refers to 'best_friend', which must \"\n            \"not be a DateTimeField, a ForeignKey, a OneToOneField, or a \"\n            \"ManyToManyField.\",\n            \"admin.E028\",\n        )\n"], "sample_997": ["def test_function_exponentiation():\n    transformations = standard_transformations + (function_exponentiation,)\n    x = Symbol('x')\n    assert parse_expr('sin**2(x)', transformations=transformations) == sin(x)**2\n    assert parse_expr('sin**2(x)**3', transformations=transformations) == (sin(x)**2)**3\n    assert parse_expr('sin**2(x)**3 + cos**2(x)', transformations=transformations) == (sin(x)**2)**3 + cos(x)**2\n"], "sample_707": ["def test_get_fslocation_from_item() -> None:\n    \"\"\"Ensure that get_fslocation_from_item() returns the correct location.\"\"\"\n    node = nodes.Item(\"test\", parent=None, config=None, session=None)\n    node.location = (\"path/to/file.py\", 10, \"function\")\n    assert get_fslocation_from_item(node) == (\"path/to/file.py\", 10)\n\n    node = nodes.Item(\"test\", parent=None, config=None, session=None)\n    node.fspath = \"path/to/file.py\"\n    assert get_fslocation_from_item(node) == (\"path/to/file.py\", None)\n\n    node = nodes.Item(\"test\", parent=None, config=None, session=None)\n    node.obj = object()\n    assert get_fslocation_from_item(node) == (\"path/to/file.py\", None)\n\n    node = nodes.Item(\"test\", parent=None, config=None, session=None)\n    assert get_fslocation_from_item(node) == (\"unknown location\", -1)\n"], "sample_508": ["def test_sticky_edges():\n    art = martist.Artist()\n    art.sticky_edges.x = [1, 2, 3]\n    art.sticky_edges.y = [4, 5, 6]\n    assert art.sticky_edges.x == [1, 2, 3]\n    assert art.sticky_edges.y == [4, 5, 6]\n    art.sticky_edges.x = [7, 8, 9]\n    art.sticky_edges.y = [10, 11, 12]\n    assert art.sticky_edges.x == [7, 8, 9]\n    assert art.sticky_edges.y == [10, 11, 12]\n"], "sample_282": ["def test_bound_field_errors(self):\n    form = ComplexFieldForm({\n        'field1_0': 'some text',\n        'field1_1': ['X', 'P'],\n        'field1_2_0': '2007-04-25',\n        'field1_2_1': '06:24:00',\n    })\n    form.is_valid()\n    self.assertEqual(form.errors['field1'], ['Select a valid choice. X is not one of the available choices.'])\n"], "sample_80": ["def test_annotation(self):\n    query = Query(Author)\n    where = query.build_where(Q(num__gt=F('id')))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, GreaterThan)\n    self.assertIsInstance(lookup.rhs, SimpleCol)\n    self.assertIsInstance(lookup.lhs, SimpleCol)\n    self.assertEqual(lookup.rhs.target, Author._meta.get_field('id'))\n    self.assertEqual(lookup.lhs.target, Author._meta.get_field('num'))\n"], "sample_1164": ["def test_cg_simp():\n    a, b, c, d = symbols('a,b,c,d')\n    cg1 = CG(a, b, c, d, a, b)\n    cg2 = CG(a, b, c, d, a, b)\n    cg3 = CG(a, b, c, d, a, b)\n    cg4 = CG(a, b, c, d, a, b)\n    cg5 = CG(a, b, c, d, a, b)\n    cg6 = CG(a, b, c, d, a, b)\n    cg7 = CG(a, b, c, d, a, b)\n    cg8 = CG(a, b, c, d, a, b)\n    cg9 = CG(a, b, c, d, a, b)\n    cg10 = CG(a, b, c, d, a, b)\n    cg11 = CG(a, b, c, d, a, b)\n    cg12 = CG(a, b, c, d, a, b)\n    cg13 = CG(a, b, c, d, a, b)\n    cg14 = CG(a, b, c, d, a, b)\n    cg15 = CG(a, b, c, d, a, b)\n    cg16 = CG(a, b, c, d, a, b)\n    cg17 = CG(a, b, c, d, a, b)\n    cg18 = CG(a, b, c, d, a, b)\n    cg19 = CG(a, b, c, d, a, b)\n    cg20 = CG(a, b, c, d, a, b)\n    cg21 = CG(a, b, c, d, a, b)\n    cg22 = CG(a, b, c, d, a, b)\n    cg23 = CG(a, b, c, d, a, b)\n    cg24 = CG(a, b, c, d, a, b)\n    cg25 = CG(a, b, c, d, a, b)\n    cg26 = CG(a, b, c, d, a, b)\n    cg27 = CG(a, b, c, d, a, b)\n    cg28 = CG(a, b, c, d, a, b)\n    cg29 = CG(a, b, c,"], "sample_1040": ["def test_print_assoc_op():\n    mml = mpp._print(x + y)\n    assert mml.childNodes[0].nodeName == 'mi'\n    assert mml.childNodes[0].childNodes[0].nodeValue == '+'\n    assert mml.childNodes[1].nodeName == 'mi'\n    assert mml.childNodes[1].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[2].nodeName == 'mi'\n    assert mml.childNodes[2].childNodes[0].nodeValue == 'y'\n\n    mml = mpp._print(x - y)\n    assert mml.childNodes[0].nodeName == 'mi'\n    assert mml.childNodes[0].childNodes[0].nodeValue == '-'\n    assert mml.childNodes[1].nodeName == 'mi'\n    assert mml.childNodes[1].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[2].nodeName == 'mi'\n    assert mml.childNodes[2].childNodes[0].nodeValue == 'y'\n\n    mml = mpp._print(x * y)\n    assert mml.childNodes[0].nodeName == 'mi'\n    assert mml.childNodes[0].childNodes[0].nodeValue == '&InvisibleTimes;'\n    assert mml.childNodes[1].nodeName == 'mi'\n    assert mml.childNodes[1].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[2].nodeName == 'mi'\n    assert mml.childNodes[2].childNodes[0].nodeValue == 'y'\n\n    mml = mpp._print(x / y)\n    assert mml.childNodes[0].nodeName == 'mfrac'\n    assert mml.childNodes[0].childNodes[0].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[0].childNodes[1].childNodes[0].nodeValue == 'y'\n"], "sample_440": ["def test_update_conflicts_unique_fields_no_unique_fields(self):\n    self._test_update_conflicts(unique_fields=[])\n"], "sample_839": ["def test_hashingvectorizer_dtype():\n    # Non-regression test: HashingVectorizer used to ignore its \"dtype\" param.\n    v = HashingVectorizer(dtype=np.float32)\n    assert v.dtype == np.float32\n\n    X = v.transform(['hello world', 'hello hello']).toarray()\n    assert X.dtype == np.float32\n\n    # check the ability to change the dtype\n    v = HashingVectorizer(dtype=np.float64)\n    X = v.transform(['hello world', 'hello hello']).toarray()\n    assert X.dtype == np.float64\n"], "sample_190": ["def test_year_lookup(self):\n    # Year lookup can be performed using the year attribute of a DateField or DateTimeField.\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n        ]\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__exact=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n        ]\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gt=2005),\n        []\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__gte=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n        ]\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lt=2005),\n        []\n    )\n    self.assertQuerysetEqual(\n        Article.objects.filter(pub_date__year__lte=2005),\n        [\n            '<Article: Article 1>',\n            '<Article: Article 2>',\n            '<Article: Article 3>',\n            '<Article: Article 4>',\n        ]\n    )\n"], "sample_721": ["def test_check_array_sparse_dtype_conversion():\n    # Test that sparse matrices are converted to the correct dtype\n    X = sp.csr_matrix(np.arange(4).reshape(2, 2))\n    X_checked = check_array(X, dtype=np.float32)\n    assert_equal(X_checked.dtype, np.float32)\n    assert_equal(X_checked.format, 'csr')\n\n    X = sp.csr_matrix(np.arange(4).reshape(2, 2))\n    X_checked = check_array(X, dtype=np.float64)\n    assert_equal(X_checked.dtype, np.float64)\n    assert_equal(X_checked.format, 'csr')\n\n    X = sp.csr_matrix(np.arange(4).reshape(2, 2))\n    X_checked = check_array(X, dtype=np.float32, accept_sparse='csr')\n    assert_equal(X_checked.dtype, np.float32)\n    assert_equal(X_checked.format, 'csr')\n\n    X = sp.csr_matrix(np.arange(4).reshape(2, 2))\n    X_checked = check_array(X, dtype=np.float64, accept_sparse='csr')\n    assert_equal(X_checked.dtype, np.float64)\n    assert_equal(X_checked.format, 'csr')\n\n    X = sp.csr_matrix(np.arange(4).reshape(2, 2))\n    X_checked = check_array(X, dtype=np.float32, accept_sparse=['csr'])\n    assert_equal(X_checked.dtype, np.float32)\n    assert_equal(X_checked.format, 'csr')\n\n    X = sp.csr_matrix(np.arange(4).reshape(2, 2))\n    X_checked = check_array(X, dtype=np.float64, accept_sparse=['csr'])\n    assert_equal(X_checked.dtype, np.float64)\n    assert_equal(X_checked.format, 'csr')\n\n    X = sp.csr_matrix(np.arange(4).reshape(2, 2))\n    X_checked = check_array(X, dtype=np.float32, accept_sparse=('csr',))\n    assert_equal(X_checked.dtype, np.float32)\n    assert_equal(X_checked.format, 'csr')\n\n    X = sp.csr_matrix(np.arange(4).reshape(2, 2))\n    X_checked = check_array(X, dtype=np.float64, accept_sparse=('csr',))\n    assert_equal(X_checked.dtype, np.float64)\n    assert_equal(X_checked.format, 'csr')\n\n    # Test that sparse matrices are not converted to the wrong dtype\n    X = sp.csr_matrix(np.arange(4).reshape(2, 2"], "sample_51": ["    def test_iso8601_duration(self):\n        test_values = (\n            ('P4DT15H30M', timedelta(days=4, hours=15, minutes=30)),\n            ('P4DT15H30M30S', timedelta(days=4, hours=15, minutes=30, seconds=30)),\n            ('P4DT15H30M30.1S', timedelta(days=4, hours=15, minutes=30, milliseconds=100)),\n            ('P4DT15H30M30.01S', timedelta(days=4, hours=15, minutes=30, milliseconds=10)),\n            ('P4DT15H30M30.001S', timedelta(days=4, hours=15, minutes=30, milliseconds=1)),\n            ('P4DT15H30M30.0001S', timedelta(days=4, hours=15, minutes=30, microseconds=100)),\n            ('P4DT15H30M30.00001S', timedelta(days=4, hours=15, minutes=30, microseconds=10)),\n            ('P4DT15H30M30.000001S', timedelta(days=4, hours=15, minutes=30, microseconds=1)),\n            ('P-4DT15H30M', timedelta(days=-4, hours=15, minutes=30)),\n            ('P-4DT15H30M30S', timedelta(days=-4, hours=15, minutes=30, seconds=30)),\n            ('P-4DT15H30M30.1S', timedelta(days=-4, hours=15, minutes=30, milliseconds=100)),\n        )\n        for source, expected in test_values:\n            with self.subTest(source=source):\n                self.assertEqual(parse_duration(source), expected)\n"], "sample_1033": ["def test_Mul_is_irrational():\n    x = Symbol('x', real=True)\n    y = Symbol('y', real=True)\n    z = Symbol('z', real=True)\n\n    assert (x*y).is_irrational is None\n    assert (x*y*z).is_irrational is None\n    assert (x*y*z + 1).is_irrational is None\n    assert (x*y*z + 2).is_irrational is None\n    assert (x*y*z + 3).is_irrational is None\n    assert (x*y*z + 4).is_irrational is None\n    assert (x*y*z + 5).is_irrational is None\n    assert (x*y*z + 6).is_irrational is None\n    assert (x*y*z + 7).is_irrational is None\n    assert (x*y*z + 8).is_irrational is None\n    assert (x*y*z + 9).is_irrational is None\n    assert (x*y*z + 10).is_irrational is None\n    assert (x*y*z + 11).is_irrational is None\n    assert (x*y*z + 12).is_irrational is None\n    assert (x*y*z + 13).is_irrational is None\n    assert (x*y*z + 14).is_irrational is None\n    assert (x*y*z + 15).is_irrational is None\n    assert (x*y*z + 16).is_irrational is None\n    assert (x*y*z + 17).is_irrational is None\n    assert (x*y*z + 18).is_irrational is None\n    assert (x*y*z + 19).is_irrational is None\n    assert (x*y*z + 20).is_irrational is None\n    assert (x*y*z + 21).is_irrational is None\n    assert (x*y*z + 22).is_irrational is None\n    assert (x*y*z + 23).is_irrational is None\n    assert (x*y*z + 24).is_irrational is None\n    assert (x*y*z + 25).is_irrational is None\n    assert (x*y*z + 26).is_irrational is None\n   "], "sample_814": ["def test_gradient_boosting_init_estimator_supports_sample_weight():\n    # Check that an error is raised if the init estimator does not support\n    # sample weights.\n    X, y = make_classification(n_samples=100, random_state=0)\n    init = ZeroEstimator()\n    gb = GradientBoostingClassifier(init=init)\n    with pytest.raises(ValueError, match=\"The initial estimator ZeroEstimator does not support sample weights\"):\n        gb.fit(X, y, sample_weight=np.ones(X.shape[0]))\n"], "sample_1083": ["def test_acsch_expansion():\n    x, y = symbols('x,y')\n    assert acsch(x+y).expand(trig=True) == acsch(x)*acsch(y) + 1/(x*y*(x + y))\n    assert acsch(2*x).expand(trig=True) == acsch(x)/x**2 + 1/(2*x*(x + 1))\n    assert acsch(3*x).expand(trig=True).expand() == \\\n        acsch(x)**3 + 3*acsch(x)*acsch(x)**2/x + 1/(x*(x + 1)*(x + 2))\n"], "sample_1132": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((0, 1, 2, 3))) == [(0, 1, 2, 3), (0, 1, 2, -3), (0, 1, -2, 3), (0, 1, -2, -3), (0, -1, 2, 3), (0, -1, 2, -3), (0, -1, -2, 3), (0, -1, -2, -3), (1, 0, 2, 3), (1, 0, 2, -3), (1, 0, -2, 3), (1, 0, -2, -3), (1, -0, 2, 3), (1, -0, 2, -3), (1, -0, -2, 3), (1, -0, -2, -3), (2, 0, 1, 3), (2, 0, 1, -3), (2, 0, -1, 3), (2, 0, -1, -3), (2, -0, 1, 3), (2, -0, 1, -3), (2, -0, -1, 3), (2, -0, -1, -3), (2, 1, 0, 3), (2, 1, 0, -3), (2, 1, -0, 3), (2, 1, -0, -3), (2, -1, 0, 3), (2, -1, 0, -3), (2, -1, -0, 3), (2, -1, -0, -3), (3, 0, 1, 2), (3, 0, 1, -2), (3, 0, -1, 2), (3, 0, -"], "sample_68": ["    def test_sensitive_kwargs_function_caller(self):\n        \"\"\"\n        Sensitive variables don't leak in the sensitive_variables decorator's\n        frame, when those variables are passed as keyword arguments to the\n        decorated function.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(sensitive_kwargs_function_caller)\n            self.verify_unsafe_email(sensitive_kwargs_function_caller)\n\n        with self.settings(DEBUG=False):\n            self.verify_safe_response(sensitive_kwargs_function_caller, check_for_POST_params=False)\n            self.verify_safe_email(sensitive_kwargs_function_caller, check_for_POST_params=False)\n"], "sample_540": ["def test_movie_writer_finish():\n    class DummyMovieWriter(animation.MovieWriter):\n            pass\n\n            self.fig = fig\n            self.outfile = outfile\n            self.dpi = dpi\n            self.args = args\n            self._count = 0\n\n            self.savefig_kwargs = savefig_kwargs\n            self._count += 1\n\n            self._count += 1\n\n    fig = plt.figure()\n    filename = \"unused.null\"\n    writer = DummyMovieWriter()\n    writer.setup(fig, filename)\n    writer.finish()\n    assert writer._count == 2\n"], "sample_365": ["def test_lazy_classproperty(self):\n    \"\"\"\n    classproperty behaves like a property when accessed from an instance.\n    \"\"\"\n    class Foo:\n        foo_attr = 123\n\n            self.foo_attr = 456\n\n        @classproperty\n            return cls.foo_attr\n\n    foo = Foo()\n    self.assertIsInstance(foo.foo, property)\n    self.assertEqual(foo.foo, 123)\n\n    class Bar:\n        bar = classproperty()\n\n        @bar.getter\n            return 123\n\n    bar = Bar()\n    self.assertIsInstance(bar.bar, property)\n    self.assertEqual(bar.bar, 123)\n"], "sample_449": ["    def test_close_connection(self):\n        request = WSGIRequest(self.request_factory.get(\"/\").environ)\n        request.makefile = lambda *args, **kwargs: BytesIO()\n        handler = WSGIRequestHandler(request, \"192.168.0.2\", None)\n\n        # Test that close_connection is set to True after handle_one_request\n        handler.handle_one_request()\n        self.assertTrue(handler.close_connection)\n\n        # Test that close_connection is set to True after multiple requests\n        handler.close_connection = False\n        handler.handle_one_request()\n        self.assertTrue(handler.close_connection)\n"], "sample_695": ["def test_get_fslocation_from_item() -> None:\n    \"\"\"Ensure that get_fslocation_from_item() correctly handles different node types.\"\"\"\n    class FakeNode(Node):\n            self.path = path\n            self.location = location\n\n    node = FakeNode(Path(\"path/to/file.py\"), (\"path/to/file.py\", 1, \"content\"))\n    assert get_fslocation_from_item(node) == (\"path/to/file.py\", 1)\n\n    node = FakeNode(Path(\"path/to/file.py\"), None)\n    assert get_fslocation_from_item(node) == (\"path/to/file.py\", -1)\n\n    node = FakeNode(None, (\"path/to/file.py\", 1, \"content\"))\n    assert get_fslocation_from_item(node) == (\"path/to/file.py\", -1)\n\n    node = FakeNode(None, None)\n    assert get_fslocation_from_item(node) == (\"unknown location\", -1)\n"], "sample_646": ["def test_teardown_class_failure_is_shown(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import unittest\n        class MyTestCase(unittest.TestCase):\n                assert 0, \"down1\"\n            @classmethod\n                assert 0, \"down2\"\n    \"\"\"\n    )\n    result = pytester.runpytest(\"-s\")\n    assert result.ret == 1\n    result.stdout.fnmatch_lines(\n        [\n            \"*setUp*\",\n            \"*assert 0*down1*\",\n            \"*tearDownClass*\",\n            \"*assert 0*down2*\",\n            \"*1 failed*\",\n        ]\n    )\n"], "sample_447": ["    def setUpTestData(cls):\n        cls.a1 = Author.objects.create(name=\"Adrian Holovaty\", age=34)\n        cls.a2 = Author.objects.create(name=\"Jacob Kaplan-Moss\", age=35)\n        cls.a3 = Author.objects.create(name=\"Brad Dayley\", age=45)\n        cls.a4 = Author.objects.create(name=\"James Bennett\", age=29)\n        cls.a5 = Author.objects.create(name=\"Jeffrey Forcier\", age=37)\n        cls.a6 = Author.objects.create(name=\"Paul Bissex\", age=29)\n        cls.a7 = Author.objects.create(name=\"Wesley J. Chun\", age=25)\n        cls.a8 = Author.objects.create(name=\"Peter Norvig\", age=57)\n        cls.a9 = Author.objects.create(name=\"Stuart Russell\", age=46)\n        cls.a1.friends.add(cls.a2, cls.a4)\n        cls.a2.friends.add(cls.a1, cls.a7)\n        cls.a4.friends.add(cls.a1)\n        cls.a5.friends.add(cls.a6, cls.a7)\n        cls.a6.friends.add(cls.a5, cls.a7)\n        cls.a7.friends.add(cls.a2, cls.a5, cls.a6)\n        cls.a8.friends.add(cls.a9)\n        cls.a9.friends.add(cls.a8)\n\n        cls.p1 = Publisher.objects.create(name=\"Apress\", num_awards=3)\n        cls.p2 = Publisher.objects.create(name=\"Sams\", num_awards=1)\n        cls.p3 = Publisher.objects.create(name=\"Prentice Hall\", num_awards=7)\n        cls.p4 = Publisher.objects.create(name=\"Morgan Kaufmann\", num_awards=9)\n        cls.p5 = Publisher.objects.create(name=\"Jonno's House of Books\", num_awards=0)\n\n        cls.b1 = Book.objects.create(\n            isbn=\"159059725\",\n            name=\"The Definitive Guide to Django: Web Development Done Right\",\n            pages=447,\n            rating=4.5,\n            price=Decimal(\"30.00\"),\n            contact=cls.a1,\n            publisher=cls.p1,\n            pubdate=datetime.date(2007, 12, 6),\n        )\n        cls.b2 = Book.objects.create(\n            isbn=\"067232959\",\n            name=\"Sams Teach Yourself Django in 24 Hours\",\n            pages=528,\n"], "sample_597": ["    def test_merge_fill_value_dict(self):\n        ds1 = xr.Dataset({\"a\": (\"x\", [1, 2]), \"x\": [0, 1]})\n        ds2 = xr.Dataset({\"b\": (\"x\", [3, 4]), \"x\": [1, 2]})\n        expected = xr.Dataset(\n            {\"a\": (\"x\", [1, 2, np.nan]), \"b\": (\"x\", [np.nan, 3, 4])}, {\"x\": [0, 1, 2]}\n        )\n        fill_value = {\"a\": np.nan, \"b\": 2}\n        assert expected.identical(ds1.merge(ds2, fill_value=fill_value))\n        assert expected.identical(ds2.merge(ds1, fill_value=fill_value))\n        assert expected.identical(xr.merge([ds1, ds2], fill_value=fill_value))\n\n        ds1 = xr.Dataset({\"a\": (\"x\", [1, 2]), \"x\": [0, 1]})\n        ds2 = xr.Dataset({\"b\": (\"x\", [3, 4]), \"x\": [1, 2]})\n        fill_value = {\"a\": 2, \"b\": np.nan}\n        expected = xr.Dataset(\n            {\"a\": (\"x\", [1, 2, 2]), \"b\": (\"x\", [np.nan, 3, 4])}, {\"x\": [0, 1, 2]}\n        )\n        assert expected.identical(ds1.merge(ds2, fill_value=fill_value))\n        assert expected.identical(ds2.merge(ds1, fill_value=fill_value))\n        assert expected.identical(xr.merge([ds1, ds2], fill_value=fill_value))\n\n        ds1 = xr.Dataset({\"a\": (\"x\", [1, 2]), \"x\": [0, 1]})\n        ds2 = xr.Dataset({\"b\": (\"x\", [3, 4]), \"x\": [1, 2]})\n        fill_value = {\"a\": 2, \"b\": 2}\n        expected = xr.Dataset(\n            {\"a\": (\"x\", [1, 2, 2]), \"b\": (\"x\", [2, 3, 4])}, {\"x\": [0, 1, 2]}\n        )\n        assert expected.identical(ds1.merge(ds2, fill_value=fill_value))\n"], "sample_899": ["def test_check_estimators_pickle_works_on_deprecated_fit():\n    # Tests that check_estimators_pickle works on a class with a deprecated fit method\n\n    class TestEstimatorWithDeprecatedFitMethod(BaseEstimator):\n        @deprecated(\"Deprecated for the purpose of testing check_estimators_pickle\")\n            return self\n\n    check_estimators_pickle(\"test\", TestEstimatorWithDeprecatedFitMethod())\n"], "sample_872": ["def test_top_k_accuracy_score_multiclass():\n    # Test top_k_accuracy_score for multiclass classification\n    y_true = np.array([0, 1, 2, 2])\n    y_score = np.array(\n        [\n            [0.5, 0.2, 0.1],\n            [0.4, 0.5, 0.3],\n            [0.1, 0.2, 0.6],\n            [0.2, 0.3, 0.5],\n        ]\n    )\n    assert top_k_accuracy_score(y_true, y_score, k=2) == pytest.approx(0.75)\n\n    y_true = np.array([0, 1, 2, 2])\n    y_score = np.array(\n        [\n            [0.5, 0.2, 0.1],\n            [0.4, 0.5, 0.3],\n            [0.1, 0.2, 0.6],\n            [0.2, 0.3, 0.5],\n        ]\n    )\n    assert top_k_accuracy_score(y_true, y_score, k=3) == pytest.approx(1.0)\n\n    y_true = np.array([0, 1, 2, 2])\n    y_score = np.array(\n        [\n            [0.5, 0.2, 0.1],\n            [0.4, 0.5, 0.3],\n            [0.1, 0.2, 0.6],\n            [0.2, 0.3, 0.5],\n        ]\n    )\n    assert top_k_accuracy_score(y_true, y_score, k=4) == pytest.approx(1.0)\n\n    y_true = np.array([0, 1, 2, 2])\n    y_score = np.array(\n        [\n            [0.5, 0.2, 0.1],\n            [0.4, 0.5, 0.3],\n            [0.1, 0.2, 0.6],\n            [0.2, 0.3, 0.5],\n        ]\n    )\n    assert top_k_accuracy_score(y_true, y_score, k=5) == pytest.approx(1.0)\n\n    y_true = np.array([0"], "sample_890": ["def test_n_jobs():\n    # Test that n_jobs is respected\n\n    n_features = 10\n    X, y = make_regression(n_features=n_features, random_state=0)\n    sfs = SequentialFeatureSelector(\n        LinearRegression(),\n        n_features_to_select=\"auto\",\n        direction=\"forward\",\n        cv=2,\n        n_jobs=2,\n    )\n    sfs.fit(X, y)\n\n    assert sfs.n_features_to_select_ == sfs._get_support_mask().sum()\n    assert sfs.transform(X).shape[1] == sfs.n_features_to_select_\n"], "sample_961": ["def test_pydata_with_union_type_operator_old(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :annotation: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0],\n                ([desc_name, \"version\"],\n                 [desc_annotation, (\": \",\n                                    [pending_xref, \"int\"],\n                                    \" \",\n                                    [desc_sig_punctuation, \"|\"],\n                                    \" \",\n                                    [pending_xref, \"str\"])]))\n"], "sample_921": ["def test_isabstractmethod():\n    class Foo:\n        @abstractmethod\n            pass\n\n    class Bar(Foo):\n            pass\n\n    assert inspect.isabstractmethod(Foo.meth) is True\n    assert inspect.isabstractmethod(Bar.meth) is False\n"], "sample_227": ["    def setUp(self):\n        self.book1 = Book.objects.create(title='Book 1', author=self.alfred)\n        self.book2 = Book.objects.create(title='Book 2', author=self.bob)\n        self.book3 = Book.objects.create(title='Book 3', author=self.lisa)\n        self.taggeditem1 = TaggedItem.objects.create(content_object=self.book1, tag='tag1')\n        self.taggeditem2 = TaggedItem.objects.create(content_object=self.book2, tag='tag1')\n        self.taggeditem3 = TaggedItem.objects.create(content_object=self.book3, tag='tag2')\n"], "sample_7": ["def test_insert_string_type_error_masked(self, Column):\n    \"\"\"\n    Test that inserting a non-string value into a string MaskedColumn raises a TypeError.\n    \"\"\"\n    c = table.MaskedColumn(['a', 'b'])\n    with pytest.raises(TypeError, match='string operation on non-string array'):\n        c.insert(0, 1)\n"], "sample_545": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect(.5)\n    ax2.set_box_aspect((2, 1, 1))\n    fig.tight_layout()\n    fig.draw_without_rendering()\n    xn = np.zeros(4)\n    yn = np.zeros(4)\n    for nn, ax in enumerate(fig.axes):\n        yn[nn] = ax.xaxis.label.get_position()[1]\n        xn[nn] = ax.yaxis.label.get_position()[0]\n    np.testing.assert_allclose(xn[:2], xn[2:])\n    np.testing.assert_allclose(yn[::2], yn[1::2])\n"], "sample_40": ["def test_with_H0():\n    H0 = 67.4 * u.km / u.s / u.Mpc\n    h100 = u.with_H0(H0)\n    assert_quantity_allclose(h100[0].to_value(u.km / u.s / u.Mpc, u.dimensionless_angles()), 0.674)\n    assert_quantity_allclose(h100[0].to_value(u.km / u.s / u.Mpc, u.dimensionless_angles()), 0.674)\n    assert h100[0].unit.is_equivalent(u.km / u.s / u.Mpc)\n    assert h100[0].unit.is_equivalent(u.dimensionless_angles())\n    assert h100[0].unit.is_equivalent(u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n    assert h100[0].unit.is_equivalent(u.H0.value * u.littleh)\n   "], "sample_989": ["def test_issue_10020():\n    assert oo**I is S.NaN\n    assert oo**(1 + I) is S.ComplexInfinity\n    assert oo**(-1 + I) is S.Zero\n    assert (-oo)**I is S.NaN\n    assert (-oo)**(-1 + I) is S.Zero\n    assert oo**t == Pow(oo, t, evaluate=False)\n    assert (-oo)**t == Pow(-oo, t, evaluate=False)\n"], "sample_735": ["def test_gaussian_mixture_lower_bound():\n    # Test that the lower bound is computed correctly\n    rng = np.random.RandomState(0)\n    rand_data = RandomData(rng, scale=7)\n    n_components = rand_data.n_components\n\n    for covar_type in COVARIANCE_TYPE:\n        X = rand_data.X[covar_type]\n        gmm = GaussianMixture(n_components=n_components,\n                              covariance_type=covar_type, random_state=rng)\n        gmm.fit(X)\n        lower_bound = gmm.lower_bound_\n        log_prob_norm = gmm._estimate_log_prob(X)\n        assert_almost_equal(gmm._compute_lower_bound(X, log_prob_norm), lower_bound)\n"], "sample_1078": ["def test_IndexedBase_shape_inheritance():\n    i, j = symbols('i j', integer=True)\n    A = IndexedBase('A', shape=(i, j))\n    B = IndexedBase('B', shape=(i, j))\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A.shape == (i, j)\n    assert B.shape == (i, j)\n    assert A.shape == B.shape\n    assert A"], "sample_1006": ["def test_subfactorial():\n    x = Symbol('x')\n    n = Symbol('n', integer=True)\n    nz = Symbol('nz', integer=True, nonzero=True)\n    k = Symbol('k', integer=True)\n    kp = Symbol('kp', integer=True, positive=True)\n    kn = Symbol('kn', integer=True, negative=True)\n    u = Symbol('u', negative=True)\n    p = Symbol('p', positive=True)\n    z = Symbol('z', zero=True)\n    nt = Symbol('nt', integer=False)\n    kt = Symbol('kt', integer=False)\n    a = Symbol('a', integer=True, nonnegative=True)\n    b = Symbol('b', integer=True, nonnegative=True)\n\n    assert subfactorial(-2) == zoo\n    assert subfactorial(0) == 1\n    assert subfactorial(7) == 44\n    assert subfactorial(19) == 1134903170\n\n    assert subfactorial(n).func == subfactorial\n    assert subfactorial(2*n).func == subfactorial\n\n    assert subfactorial(x).is_integer is None\n    assert subfactorial(n).is_integer is None\n    assert subfactorial(k).is_integer\n    assert subfactorial(r).is_integer is None\n\n    assert subfactorial(n).is_positive is None\n    assert subfactorial(k).is_positive\n\n    assert subfactorial(x).is_real is None\n    assert subfactorial(n).is_real is None\n    assert subfactorial(k).is_real is True\n    assert subfactorial(r).is_real is None\n    assert subfactorial(s).is_real is True\n    assert subfactorial(t).is_real is True\n    assert subfactorial(u).is_real is True\n\n    assert subfactorial(x).is_composite is None\n    assert subfactorial(n).is_composite is None\n    assert subfactorial(k).is_composite is None\n    assert subfactorial(k + 3).is_composite is True\n    assert subfactorial(r).is_composite is None\n    assert subfactorial(s).is_composite is None\n    assert subfactorial(t).is_composite is None\n    assert subfactorial(u).is_composite is None\n\n    assert subfactorial(oo) == oo\n\n    assert subfactorial(n).diff(n) =="], "sample_378": ["    def test_update_fields_with_update_conflicts(self):\n        custom_pks = [\n            CustomPk.objects.create(name='pk-%s' % i, extra='')\n            for i in range(10)\n        ]\n        for model in custom_pks:\n            model.extra = 'extra-%s' % model.pk\n        with self.assertRaisesMessage(NotSupportedError, 'This database backend does not support updating conflicts.'):\n            CustomPk.objects.bulk_update(custom_pks, ['extra'], update_conflicts=True)\n"], "sample_765": ["def test_balanced_accuracy_score_adjusted():\n    # Test balanced accuracy score with adjusted option\n    y_true = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n    y_pred = [0, 1, 2, 0, 1, 2, 0, 1, 2]\n\n    # Test with unadjusted option\n    score = balanced_accuracy_score(y_true, y_pred)\n    assert_almost_equal(score, 0.33)\n\n    # Test with adjusted option\n    score = balanced_accuracy_score(y_true, y_pred, adjusted=True)\n    assert_almost_equal(score, 0.0)\n"], "sample_939": ["def test_unparse_With():\n    expected = \"with open('file.txt', 'r') as f: pass\"\n    source = \"with open('file.txt', 'r') as f: pass\"\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].value) == expected\n"], "sample_763": ["def test_check_X_y_dtype_stability():\n    # test that lists with ints don't get converted to floats\n    X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n    y = [1, 2, 3]\n    X_checked, y_checked = check_X_y(X, y)\n    assert_equal(X_checked.dtype.kind, \"i\")\n    assert_equal(y_checked.dtype.kind, \"i\")\n\n    # test that lists with ints don't get converted to floats when multi_output=True\n    X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n    y = [[1, 2], [3, 4], [5, 6]]\n    X_checked, y_checked = check_X_y(X, y, multi_output=True)\n    assert_equal(X_checked.dtype.kind, \"i\")\n    assert_equal(y_checked.dtype.kind, \"i\")\n\n    # test that lists with ints don't get converted to floats when multi_output=False\n    X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n    y = [1, 2, 3]\n    X_checked, y_checked = check_X_y(X, y, multi_output=False)\n    assert_equal(X_checked.dtype.kind, \"i\")\n    assert_equal(y_checked.dtype.kind, \"i\")\n\n    # test that lists with ints don't get converted to floats when multi_output=False\n    # and y_numeric=True\n    X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n    y = [1, 2, 3]\n    X_checked, y_checked = check_X_y(X, y, multi_output=False, y_numeric=True)\n    assert_equal(X_checked.dtype.kind, \"i\")\n    assert_equal(y_checked.dtype.kind, \"f\")\n\n    # test that lists with ints don't get converted to floats when multi_output=True\n    # and y_numeric=True\n    X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n    y = [[1, 2], [3, 4], [5, 6]]\n    X_checked, y_checked = check_X_y(X,"], "sample_482": ["    def test_basic(self):\n        output = self.engine.render_to_string(\n            \"truncatechars_basic\",\n            {\"a\": \"Hello, World!\", \"b\": mark_safe(\"Hello, World!\")},\n        )\n        self.assertEqual(output, \"Hello, Worl... -- Hello, Worl...\")\n"], "sample_26": ["    def test_scale_with_explicit_bscale_and_bzero(self):\n        \"\"\"\n        Regression test for https://github.com/astropy/astropy/issues/6399\n        \"\"\"\n        hdu2 = fits.ImageHDU(np.random.rand(100, 100))\n        # The line below raised an exception in astropy 2.0, so if it does not\n        # raise an error here, that is progress.\n        hdu2.scale(type=\"uint8\", bscale=1.0, bzero=0.0)\n"], "sample_103": ["def test_aggregate_over_subquery_annotation(self):\n    \"\"\"Subquery annotations are excluded from the GROUP BY if they are\n    not explicitly grouped against.\"\"\"\n    latest_book_pubdate_qs = Book.objects.filter(\n        publisher=OuterRef('pk')\n    ).order_by('-pubdate').values('pubdate')[:1]\n    publisher_qs = Publisher.objects.annotate(\n        latest_book_pubdate=Subquery(latest_book_pubdate_qs),\n    ).annotate(count=Count('book'))\n    with self.assertNumQueries(1) as ctx:\n        list(publisher_qs)\n    self.assertEqual(ctx[0]['sql'].count('SELECT'), 2)\n\n    # Test that the subquery annotation is included in the GROUP BY when\n    # grouped against.\n    latest_book_pubdate_qs = Book.objects.filter(\n        publisher=OuterRef('pk')\n    ).order_by('-pubdate').values('pubdate')[:1]\n    publisher_qs = Publisher.objects.values('latest_book_pubdate').annotate(\n        count=Count('book')\n    )\n    with self.assertNumQueries(1) as ctx:\n        list(publisher_qs)\n    self.assertEqual(ctx[0]['sql'].count('SELECT'), 2)\n"], "sample_931": ["def test_pydata_signature_with_type_and_value(app):\n    text = (\".. py:data:: var\\n\"\n            \"   :type: int\\n\"\n            \"   :value: 1\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"var\"],\n                                                    [desc_annotation, (\": \",\n                                                                       [pending_xref, \"int\"])],\n                                                    [desc_annotation, \" = 1\"])],\n                                  [desc_content, ()])]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n    assert_node(doctree[1][0][1],\n                [desc_annotation, \" = 1\"])\n    assert 'var' in domain.objects\n    assert domain.objects['var'] == ('index', 'var', 'data')\n"], "sample_105": ["    def test_extra_context(self):\n        \"\"\"\n        Test a view that renders a template on GET with extra context.\n        \"\"\"\n        response = self.client.get('/template/extra_context/')\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.context['title'], 'Title')\n        self.assertEqual(response.context['extra_key'], 'extra_value')\n"], "sample_503": ["def test_set_markerfacecolor_fillstyle_none():\n    \"\"\"Test that markerfacecolor does not override fillstyle='none'.\"\"\"\n    l, = plt.plot([1, 3, 2], marker=MarkerStyle('o', fillstyle='none'),\n                  markerfacecolor='red')\n    assert l.get_fillstyle() == 'none'\n    assert l.get_markerfacecolor() == 'none'\n"], "sample_271": ["    def test_iter_modules_and_files_cache(self):\n        filename = self.temporary_file('test_module.py')\n        filename.write_text('import os')\n        with extend_sys_path(str(filename.parent)):\n            self.import_and_cleanup('test_module')\n        self.assertFileFound(filename)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().hits, 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().misses, 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().maxsize, 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().currsize, 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_info().get(autoreload.iter_modules_and_files.cache_info().keys()[0]), 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_clear().hits, 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_clear().misses, 0)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_clear().maxsize, 1)\n        self.assertEqual(autoreload.iter_modules_and_files.cache_clear().currsize, 0)\n"], "sample_244": ["def test_formset_can_order_with_initial_data(self):\n    \"\"\"\n    Formsets with ordering and initial data.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_order=True)\n    initial = [{'choice': 'Calexico', 'votes': 100}, {'choice': 'Fergie', 'votes': 900}]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_1049": ["def test_plane_arbitrary_point():\n    x, y, z, u, v = symbols('x y z u v', real=True)\n    p1 = Point3D(0, 0, 0)\n    p2 = Point3D(1, 1, 1)\n    p3 = Point3D(1, 2, 3)\n    pl3 = Plane(p1, p2, p3)\n    pl4 = Plane(p1, normal_vector=(1, 1, 1))\n    pl5 = Plane(p3, normal_vector=(1, 2, 3))\n\n    assert pl3.arbitrary_point(u) == Point3D(-sqrt(30)*sin(u)/30 + \\\n        2*sqrt(5)*cos(u)/5, sqrt(30)*sin(u)/15 + sqrt(5)*cos(u)/5, sqrt(30)*sin(u)/6)\n    assert pl3.arbitrary_point(u, v) == Point3D(2*u - v, u + 2*v, 5*v)\n\n    assert pl5.arbitrary_point(u) == Point3D(-sqrt(14)*sin(u)/14 + \\\n        3*sqrt(7)*cos(u)/7, sqrt(14)*sin(u)/7 + 3*sqrt(7)*cos(u)/7, sqrt(14)*sin(u)/7)\n    assert pl5.arbitrary_point(u, v) == Point3D(3*u - v, u + 3*v, 7*v)\n\n    assert pl3.arbitrary_point(u).distance(pl3.p1) == 1\n    assert pl3.arbitrary_point(u, v).distance(pl3.p1) == 1\n    assert pl5.arbitrary_point(u).distance(pl5.p1) == 1\n    assert pl5.arbitrary_point(u, v).distance(pl5.p1) == 1\n\n    assert pl3.arbitrary_point(u).distance(pl3.arbitrary_point(u)) == 0\n    assert pl3.arbitrary_point(u, v).distance(pl3.arbitrary_point(u, v)) == 0\n    assert pl5.arbitrary_point(u).distance(pl5.arbitrary_point(u)) == 0\n    assert pl5.arbitrary_point(u, v).distance(pl5.arbitrary_point(u, v)) == 0\n\n    assert pl3.arbitrary_point(u).distance(pl5.arbitrary_point"], "sample_794": ["def test_ridge_regression_sample_weights_sparse():\n    # Test that sample weights work with sparse matrices\n    rng = np.random.RandomState(0)\n\n    for solver in (\"cholesky\", ):\n        for n_samples, n_features in ((6, 5), (5, 10)):\n            for alpha in (1.0, 1e-2):\n                y = rng.randn(n_samples)\n                X = rng.randn(n_samples, n_features)\n                sample_weight = 1.0 + rng.rand(n_samples)\n                X_sparse = sp.csr_matrix(X)\n                coefs = ridge_regression(X_sparse, y,\n                                         alpha=alpha,\n                                         sample_weight=sample_weight,\n                                         solver=solver)\n\n                # Sample weight can be implemented via a simple rescaling\n                # for the square loss.\n                coefs2 = ridge_regression(\n                    X_sparse * np.sqrt(sample_weight)[:, np.newaxis],\n                    y * np.sqrt(sample_weight),\n                    alpha=alpha, solver=solver)\n                assert_array_almost_equal(coefs, coefs2)\n"], "sample_1176": ["def test_issue_12345():\n    from sympy.core.numbers import igcdex\n    from sympy.core.numbers import igcd\n    from sympy.core.numbers import igcd2\n    from sympy.core.numbers import igcd_lehmer\n    from sympy.core.numbers import mod_inverse\n    from sympy.core.numbers import ilcm\n    from sympy.core.numbers import igcdex\n    from sympy.core.numbers import igcdex\n\n    assert igcdex(0, 0) == (0, 1, 0)\n    assert igcdex(1, 0) == (1, 0, 1)\n    assert igcdex(0, 1) == (0, 1, 1)\n    assert igcdex(1, 1) == (1, 1, 1)\n    assert igcdex(2, 1) == (1, 1, 1)\n    assert igcdex(1, 2) == (1, 1, 1)\n    assert igcdex(2, 2) == (2, 1, 1)\n    assert igcdex(3, 2) == (1, 1, 1)\n    assert igcdex(2, 3) == (1, 1, 1)\n    assert igcdex(3, 3) == (3, 1, 1)\n    assert igcdex(4, 3) == (1, 1, 1)\n    assert igcdex(3, 4) == (1, 1, 1)\n    assert igcdex(4, 4) == (4, 1, 1)\n    assert igcdex(5, 4) == (1, 1, 1)\n    assert igcdex(4, 5) == (1, 1, 1)\n    assert igcdex(5, 5) == (5, 1, 1)\n    assert igcdex(6, 5) == (1, 1, 1)\n    assert igcdex(5, 6) == (1, 1, 1)\n    assert igcdex(6, 6) == (6, 1, 1)\n    assert igcdex(7,"], "sample_556": ["def test_tightbbox_box_aspect():\n    fig = plt.figure()\n    gs = fig.add_gridspec(1, 2)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1], projection='3d')\n    ax1.set_box_aspect((1, 2, 3))\n    ax2.set_box_aspect((2, 1, 1))\n"], "sample_498": ["def test_legend_title_fontsize():\n    # test the title_fontsize kwarg\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontsize=22)\n    assert leg.get_title().get_fontsize() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontsize() == 20\n"], "sample_311": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(username='super', password='secret', email='super@example.com')\n        cls.s1 = Section.objects.create(name='Test section')\n        cls.a1 = Article.objects.create(\n            content='<p>Middle content</p>', date=datetime.datetime(2008, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a2 = Article.objects.create(\n            content='<p>Oldest content</p>', date=datetime.datetime(2000, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.a3 = Article.objects.create(\n            content='<p>Newest content</p>', date=datetime.datetime(2009, 3, 18, 11, 54, 58), section=cls.s1\n        )\n        cls.p1 = PrePopulatedPost.objects.create(title='A Long Title', published=True, slug='a-long-title')\n"], "sample_143": ["def test_camel_case_to_spaces(self):\n    self.assertEqual(text.camel_case_to_spaces('HelloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123'), 'hello world123')\n    self.assertEqual(text.camel_case_to_spaces('helloWorld123abc'), 'hello world123abc')\n    self.assertEqual(text.camel_case_to_spaces(''), '')\n    self.assertEqual(text.camel_case_to_spaces('hello'), 'hello')\n    self.assertEqual(text.camel_case_to_spaces('hello world'), 'hello world')\n    self.assertEqual(text.camel_case_to_spaces('hello world123'), 'hello world123')\n    self.assertEqual(text.camel_case_to_spaces('hello world123abc'), 'hello world123abc')\n    self.assertEqual(text.camel_case_to_spaces(lazystr('HelloWorld')), 'hello world')\n"], "sample_925": ["def test_MockObject_repr():\n    mock = _MockObject()\n    assert repr(mock) == '_MockObject'\n\n    mock = _MockObject('MockObjectWithArgs', (1, 2, 3))\n    assert repr(mock) == 'MockObjectWithArgs'\n\n    mock = _MockObject('MockObjectWithKwargs', a=1, b=2)\n    assert repr(mock) == 'MockObjectWithKwargs'\n\n    class SubClass(_MockObject):\n        pass\n\n    obj = SubClass('SubClassWithArgs', (1, 2, 3))\n    assert repr(obj) == 'SubClassWithArgs'\n\n    obj = SubClass('SubClassWithKwargs', a=1, b=2)\n    assert repr(obj) == 'SubClassWithKwargs'\n"], "sample_543": ["def test_cursor(ax):\n    cursor = widgets.Cursor(ax, horizOn=True, vertOn=True)\n    assert cursor.visible\n    assert cursor.horizOn\n    assert cursor.vertOn\n    assert cursor.useblit is False\n\n    cursor.visible = False\n    assert not cursor.visible\n\n    cursor.visible = True\n    assert cursor.visible\n\n    cursor.horizOn = False\n    assert not cursor.horizOn\n    cursor.horizOn = True\n    assert cursor.horizOn\n\n    cursor.vertOn = False\n    assert not cursor.vertOn\n    cursor.vertOn = True\n    assert cursor.vertOn\n\n    cursor.useblit = True\n    assert cursor.useblit\n    cursor.useblit = False\n    assert not cursor.useblit\n\n    cursor.lineh.set_visible(False)\n    assert not cursor.lineh.get_visible()\n    cursor.lineh.set_visible(True)\n    assert cursor.lineh.get_visible()\n\n    cursor.linev.set_visible(False)\n    assert not cursor.linev.get_visible()\n    cursor.linev.set_visible(True)\n    assert cursor.linev.get_visible()\n\n    cursor._update()\n    cursor.update()\n"], "sample_209": ["    def test_related_gt_lookup(self):\n        \"\"\"\n        Regression test for #10153: foreign key __gt lookups.\n        \"\"\"\n        Worker.objects.filter(department__gt=0)\n"], "sample_413": ["    def setUpClass(cls):\n        super().setUpClass()\n        cls.error_same_tags = Error(\n            E003.msg.format(\n                \"'same_tags'\",\n                \"'check_framework.template_test_apps.same_tags_app_1.\"\n                \"templatetags.same_tags', \"\n                \"'check_framework.template_test_apps.same_tags_app_2.\"\n                \"templatetags.same_tags'\",\n            ),\n            id=E003.id,\n        )\n"], "sample_1146": ["def test_latex_RationalField():\n    assert latex(S.Rationals) == r'\\mathbb{Q}'\n"], "sample_608": ["def test_inline_sparse_repr(self) -> None:\n    arr = sparse.COO(np.array([1, 2, 3]), np.array([0, 1, 2]), np.array([0, 1, 2]))\n    expected = \"<COO: nnz=3, fill_value=0>\"\n    actual = formatting.inline_sparse_repr(arr)\n    assert expected == actual\n\n    arr = sparse.COO(np.array([1, 2, 3]), np.array([0, 1, 2]), np.array([0, 1, 2]),\n                     fill_value=5)\n    expected = \"<COO: nnz=3, fill_value=5>\"\n    actual = formatting.inline_sparse_repr(arr)\n    assert expected == actual\n\n    arr = sparse.COO(np.array([1, 2, 3]), np.array([0, 1, 2]), np.array([0, 1, 2]),\n                     fill_value=np.nan)\n    expected = \"<COO: nnz=3, fill_value=nan>\"\n    actual = formatting.inline_sparse_repr(arr)\n    assert expected == actual\n"], "sample_499": ["def test_legend_title_fontprop_fontsize():\n    # test the title_fontsize kwarg\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontproperties=FontProperties(\n                                       family='serif', size=22))\n    assert leg.get_title().get_size() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontsize() == 20\n"], "sample_98": ["    def test_ssl_support(self):\n        \"\"\"\n        Launched server supports SSL.\n        \"\"\"\n        # Create a self-signed certificate and private key\n        cert_path = os.path.join(TEST_ROOT, 'server.crt')\n        key_path = os.path.join(TEST_ROOT, 'server.key')\n        with open(cert_path, 'w') as f:\n            f.write('-----BEGIN CERTIFICATE-----\\n')\n            f.write('your certificate here\\n')\n            f.write('-----END CERTIFICATE-----\\n')\n        with open(key_path, 'w') as f:\n            f.write('-----BEGIN RSA PRIVATE KEY-----\\n')\n            f.write('your private key here\\n')\n            f.write('-----END RSA PRIVATE KEY-----\\n')\n\n        # Run the server with SSL support\n        run(addr='localhost', port=8000, wsgi_handler=get_internal_wsgi_application(), ipv6=False, server_cls=WSGIServer, threading=False)\n\n        # Test the server with SSL\n        conn = HTTPConnection('localhost', 8000, timeout=1)\n        try:\n            conn.request('GET', '/example_view/', headers={'Connection': 'close'})\n            response = conn.getresponse()\n            self.assertEqual(response.status, 200)\n            self.assertEqual(response.read(), b'example view')\n        finally:\n            conn.close()\n"], "sample_742": ["def test_logistic_regression_path_convergence():\n    # Test that the path algorithm converges\n    rng = np.random.RandomState(0)\n    X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n    y = [1] * 100 + [-1] * 100\n    Cs = np.logspace(0, 4, 10)\n\n    f = ignore_warnings\n    # can't test with fit_intercept=True since LIBLINEAR\n    # penalizes the intercept\n    for solver in ['sag', 'saga']:\n        coefs, Cs, _ = f(logistic_regression_path)(\n            X, y, Cs=Cs, fit_intercept=False, tol=1e-5, solver=solver,\n            max_iter=1000,\n            random_state=0)\n        for i, C in enumerate(Cs):\n            lr = LogisticRegression(C=C, fit_intercept=False, tol=1e-5,\n                                    solver=solver,\n                                    random_state=0)\n            lr.fit(X, y)\n            lr_coef = lr.coef_.ravel()\n            assert_array_almost_equal(lr_coef, coefs[i], decimal=4,\n                                      err_msg=\"with solver = %s\" % solver)\n\n    # test for fit_intercept=True\n    for solver in ('lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'):\n        Cs = [1e3]\n        coefs, Cs, _ = f(logistic_regression_path)(\n            X, y, Cs=Cs, fit_intercept=True, tol=1e-6, solver=solver,\n            intercept_scaling=10000., random_state=0)\n        lr = LogisticRegression(C=Cs[0], fit_intercept=True, tol=1e-4,\n                                intercept_scaling=10000., random_state=0)\n        lr.fit(X, y)\n        lr_coef = np.concatenate([lr.coef_.ravel(), lr.intercept_])\n        assert_array_almost_equal(lr_coef, coefs[0], decimal=4,\n                                  err_msg=\"with solver = %s\" % solver)\n\n    # Test that the path algorithm converges with a very small tolerance\n    Cs = [1e3]\n    coefs, Cs, _ = f(logistic_regression_path)(\n        X, y, Cs=Cs, fit_intercept=True, tol=1e-"], "sample_955": ["def test_unparse_BoolOp_with_multiple_values():\n    source = \"a and b and c\"\n    expected = \"a and b and c\"\n    module = ast.parse(source)\n    assert ast.unparse(module.body[0].value, source) == expected\n"], "sample_94": ["    def test_password_validation_minimum_length(self):\n        \"\"\"\n        Creation should fail if the password fails validation.\n        \"\"\"\n        new_io = StringIO()\n\n        # The first two passwords are too short, but the second two are valid.\n        entered_passwords = [\"a\", \"a\", \"password\", \"password\"]\n\n            return entered_passwords.pop(0)\n\n        @mock_inputs({\n            'password': short_passwords_then_valid,\n            'username': 'joe1234567890',\n            'email': '',\n            'bypass': 'n',\n        })\n            call_command(\n                \"createsuperuser\",\n                interactive=True,\n                stdin=MockTTY(),\n                stdout=new_io,\n                stderr=new_io,\n            )\n            self.assertEqual(\n                new_io.getvalue().strip(),\n                \"This password is too short.\\n\"\n                \"Superuser created successfully.\"\n            )\n\n        test(self)\n"], "sample_685": ["def test_log_auto_indent(caplog):\n    caplog.set_level(logging.INFO)\n    logger.info(\"boo %s\", \"arg\")\n    assert caplog.messages[0] == \"boo arg\"\n    assert caplog.text.count(\"\\n\") == 0\n    assert len(caplog.text.splitlines()) == 1\n\n    logger.info(\"bar %s\\nbaz %s\", \"arg1\", \"arg2\")\n    assert caplog.messages[1] == \"bar arg1\\nbaz arg2\"\n    assert caplog.text.count(\"\\n\") == 1\n    assert len(caplog.text.splitlines()) == 2\n\n    try:\n        raise Exception(\"test\")\n    except Exception:\n        logger.exception(\"oops\")\n\n    assert \"oops\" in caplog.text\n    assert \"oops\" in caplog.messages[-1]\n    # Tracebacks are stored in the record and not added until the formatter or handler.\n    assert \"Exception\" in caplog.text\n    assert \"Exception\" not in caplog.messages[-1]\n"], "sample_518": ["def test_fancyarrow_patch_draw():\n    fig, ax = plt.subplots()\n    arrow = FancyArrowPatch((0, 0), (1, 1), arrowstyle=\"->\")\n    ax.add_patch(arrow)\n    ax.set_xlim([0, 2])\n    ax.set_ylim([0, 2])\n    ax.set_aspect('equal')\n    fig.canvas.draw()\n    # Check that the arrow is drawn correctly\n    assert np.allclose(arrow.get_path().vertices, np.array([[0, 0], [0.5, 0.5], [1, 1]]))\n"], "sample_571": ["    def test_regress_out(self):\n\n        x = np.random.randn(100)\n        y = x + np.random.randn(100)\n        z = x + np.random.randn(100)\n\n        p = lm._RegressionPlotter(y, z)\n        _, r_orig = np.corrcoef(p.x, p.y)[0]\n\n        p = lm._RegressionPlotter(y, z, x_partial=x)\n        _, r_semipartial = np.corrcoef(p.x, p.y)[0]\n        assert r_semipartial < r_orig\n\n        p = lm._RegressionPlotter(y, z, x_partial=x, y_partial=x)\n        _, r_partial = np.corrcoef(p.x, p.y)[0]\n        assert r_partial < r_orig\n\n        x = pd.Series(x)\n        y = pd.Series(y)\n        p = lm._RegressionPlotter(y, z, x_partial=x, y_partial=x)\n        _, r_partial = np.corrcoef(p.x, p.y)[0]\n        assert r_partial < r_orig\n"], "sample_419": ["    def test_custom_renderer(self):\n        \"\"\"\n        A custom renderer passed to a formset_factory() is passed to all forms\n        and ErrorList.\n        \"\"\"\n        from django.forms.renderers import Jinja2\n\n        renderer = Jinja2()\n        data = {\n            \"choices-TOTAL_FORMS\": \"2\",\n            \"choices-INITIAL_FORMS\": \"0\",\n            \"choices-MIN_NUM_FORMS\": \"0\",\n            \"choices-0-choice\": \"Zero\",\n            \"choices-0-votes\": \"\",\n            \"choices-1-choice\": \"One\",\n            \"choices-1-votes\": \"\",\n        }\n        ChoiceFormSet = formset_factory(Choice, renderer=renderer)\n        formset = ChoiceFormSet(data, auto_id=False, prefix=\"choices\")\n        self.assertEqual(formset.renderer, renderer)\n        self.assertEqual(formset.forms[0].renderer, renderer)\n        self.assertEqual(formset.management_form.renderer, renderer)\n        self.assertEqual(formset.non_form_errors().renderer, renderer)\n        self.assertEqual(formset.empty_form.renderer, renderer)\n"], "sample_645": ["def test_log_file(caplog, pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n            logger = logging.getLogger('catchlog')\n            logger.info('log from test1')\n            assert 0\n    \"\"\"\n    )\n    result = pytester.runpytest(\"--log-file=pytest.log\")\n    result.assert_outcomes(passed=1)\n    assert result.ret == 0\n    with open(\"pytest.log\", \"r\") as f:\n        log_contents = f.read()\n    assert \"log from test1\" in log_contents\n"], "sample_523": ["def test_legend_title_fontsize():\n    # test the title_fontsize kwarg\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontsize=22)\n    assert leg.get_title().get_fontsize() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontsize() == 20\n"], "sample_730": ["def test_enet_path_return_models():\n    # Test that enet_path with return_models=True gives the same result\n\n    # Some toy data\n    X = np.array([[1, 2, 3.1], [2.3, 5.4, 4.3]]).T\n    y = np.array([1, 2, 3.1])\n    alphas = [5., 1., .5]\n\n    # Use lars_path and enet_path(return_models=True) to compute the same path\n    alphas_lars, active, coef_path_lars = lars_path(X, y, method='elasticnet')\n    coef_path_cont_lars = interpolate.interp1d(alphas_lars[::-1],\n                                               coef_path_lars[:, ::-1])\n    alphas_lasso2, coefs_lasso2, _ = enet_path(X, y, alphas=alphas,\n                                                return_models=True)\n    coef_path_cont_lasso = interpolate.interp1d(alphas_lasso2[::-1],\n                                                coefs_lasso2[:, ::-1])\n\n    assert_array_almost_equal(\n        coef_path_cont_lasso(alphas), coef_path_cont_lars(alphas),\n        decimal=1)\n"], "sample_754": ["def test_mini_batch_fit_transform_parallel(norm_comp):\n    raise SkipTest(\"skipping mini_batch_fit_transform_parallel.\")\n    alpha = 1\n    rng = np.random.RandomState(0)\n    Y, _, _ = generate_toy_data(3, 10, (8, 8), random_state=rng)  # wide array\n    spca_lars = MiniBatchSparsePCA(n_components=3, random_state=0,\n                                   alpha=alpha,\n                                   normalize_components=norm_comp).fit(Y)\n    U1 = spca_lars.transform(Y)\n    # Test multiple CPUs\n    if sys.platform == 'win32':  # fake parallelism for win32\n        import sklearn.externals.joblib.parallel as joblib_par\n        _mp = joblib_par.multiprocessing\n        joblib_par.multiprocessing = None\n        try:\n            spca = MiniBatchSparsePCA(n_components=3, n_jobs=2, alpha=alpha,\n                                      random_state=0,\n                                      normalize_components=norm_comp)\n            U2 = spca.fit(Y).transform(Y)\n        finally:\n            joblib_par.multiprocessing = _mp\n    else:  # we can efficiently use parallelism\n        spca = MiniBatchSparsePCA(n_components=3, n_jobs=2, alpha=alpha,\n                                  random_state=0,\n                                  normalize_components=norm_comp)\n        U2 = spca.fit(Y).transform(Y)\n    assert_true(not np.all(spca_lars.components_ == 0))\n    assert_array_almost_equal(U1, U2)\n    # Test that CD gives similar results\n    spca_lasso = MiniBatchSparsePCA(n_components=3, method='cd', alpha=alpha,\n                                    random_state=0,\n                                    normalize_components=norm_comp).fit(Y)\n    assert_array_almost_equal(spca_lasso.components_, spca_lars.components_)\n"], "sample_109": ["def test_build_attrs_i18n(self):\n    with translation.override('fr'):\n        form = AlbumForm()\n        attrs = form['band'].field.widget.get_context(name='my_field', value=None, attrs={})['widget']['attrs']\n        self.assertEqual(attrs['data-theme'], 'admin-autocomplete')\n        with translation.override('es'):\n            attrs = form['band'].field.widget.get_context(name='my_field', value=None, attrs={})['widget']['attrs']\n            self.assertEqual(attrs['data-theme'], 'admin-autocomplete')\n            i18n_name = SELECT2_TRANSLATIONS.get(get_language())\n            i18n_file = ('admin/js/vendor/select2/i18n/%s.js' % i18n_name,) if i18n_name else ()\n            self.assertIn('admin/js/vendor/select2/i18n/fr.js', form['band'].field.widget.media.js)\n            self.assertNotIn('admin/js/vendor/select2/i18n/es.js', form['band'].field.widget.media.js)\n"], "sample_683": ["    def test_global_capture_stops_on_keyboard_interrupt(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\\\n                import os\n                os.write(1, b'42')\n                raise KeyboardInterrupt()\n            \"\"\"\n        )\n        result = testdir.runpytest_subprocess(p)\n        result.stdout.fnmatch_lines([\"*KeyboardInterrupt*\"])\n        assert result.ret == 2\n        assert result.stderr.fnmatch_lines([\"*Captured stdout*\"])\n        assert result.stderr.fnmatch_lines([\"*Captured stderr*\"])\n"], "sample_943": ["def test_maxdepth(make_app, apidoc):\n    outdir = apidoc.outdir\n    assert (outdir / 'conf.py').isfile()\n    assert (outdir / 'a.rst').isfile()\n    assert (outdir / 'a.b.rst').isfile()\n    assert not (outdir / 'a.b.c.rst').isfile()\n\n    app = make_app('text', srcdir=outdir)\n    app.build()\n    print(app._status.getvalue())\n    print(app._warning.getvalue())\n\n    builddir = outdir / '_build' / 'text'\n    assert (builddir / 'a.txt').isfile()\n    assert (builddir / 'a.b.txt').isfile()\n\n    with open(builddir / 'a.txt') as f:\n        txt = f.read()\n        assert \"a package\\n\" in txt\n\n    with open(builddir / 'a.b.txt') as f:\n        txt = f.read()\n        assert \"a.b module\\n\" in txt\n"], "sample_694": ["def test_argparse_percent_default_is_deprecated() -> None:\n    with pytest.warns(\n        pytest.PytestRemovedIn8Warning,\n        match=re.escape(\n            \"pytest now uses argparse. '%default' should be changed to '%(default)s'\"\n        ),\n    ):\n        pytest.main([\"--help\"])\n"], "sample_690": ["    def test_xfail_raises(self, pytester: Pytester, raises, expected) -> None:\n        p = pytester.makepyfile(\n            \"\"\"\n            import pytest\n            @pytest.mark.xfail(raises=%s)\n                raise %s()\n        \"\"\"\n            % (raises, raises)\n        )\n        result = pytester.runpytest(p)\n        result.stdout.fnmatch_lines([\"*1 xfailed*\"])\n        assert expected in result.stdout.str()\n"], "sample_138": ["    def test_manifest(self):\n        self.assertIsNone(storage.staticfiles_storage.load_manifest())\n        self.assertIsNone(storage.staticfiles_storage.read_manifest())\n        self.assertIsNone(storage.staticfiles_storage.save_manifest())\n        self.assertIsNone(storage.staticfiles_storage.manifest_storage.load_manifest())\n        self.assertIsNone(storage.staticfiles_storage.manifest_storage.read_manifest())\n        self.assertIsNone(storage.staticfiles_storage.manifest_storage.save_manifest())\n"], "sample_1194": ["def test_julia_matrix_power():\n    A = Matrix([[1, 2], [3, 4]])\n    assert julia_code(A**2) == \"[[1 2; 3 4] * [1 2; 3 4]]\"\n    A = MatrixSymbol('A', 2, 2)\n    assert julia_code(A**2) == \"A ^ 2\"\n    assert julia_code(A**3) == \"A ^ 3\"\n    assert julia_code(A**S.Half) == \"A ^ (1 // 2)\"\n"], "sample_388": ["    def test_create_unknown_user(self):\n        \"\"\"\n        The unknown user created should be configured with an email address\n        provided in the request header.\n        \"\"\"\n        num_users = User.objects.count()\n        response = self.client.get(\n            \"/remote_user/\",\n            **{\n                self.header: \"newuser\",\n                self.email_header: \"user@example.com\",\n            },\n        )\n        self.assertEqual(response.context[\"user\"].username, \"newuser\")\n        self.assertEqual(response.context[\"user\"].email, \"user@example.com\")\n        self.assertEqual(response.context[\"user\"].last_name, \"\")\n        self.assertEqual(User.objects.count(), num_users + 1)\n        newuser = User.objects.get(username=\"newuser\")\n        self.assertEqual(newuser.email, \"user@example.com\")\n"], "sample_262": ["def test_lazy_class_preparation_caching_multiple_types(self):\n    # lazy() should prepare the proxy class only once i.e. the first time\n    # it's used, even if multiple types are specified.\n    lazified = lazy(lambda: 0, int, str, bytes)\n    __proxy__ = lazified().__class__\n    with mock.patch.object(__proxy__, '__prepare_class__') as mocked:\n        lazified()\n        mocked.assert_called_once()\n"], "sample_322": ["def test_migrate_with_replaced_migration(self):\n    \"\"\"\n    Test migrating with a replaced migration.\n    \"\"\"\n    executor = MigrationExecutor(connection)\n    # Prepare for migration\n    executor.migrate([(\"migrations\", \"0001_initial\")])\n    executor.migrate([(\"migrations2\", \"0001_initial\")])\n    executor.loader.build_graph()\n    # Create a replaced migration\n    replaced_migration = executor.loader.get_migration(\"migrations\", \"0002_second\")\n    replaced_migration.replaces = [(\"migrations2\", \"0001_initial\")]\n    # Migrate with the replaced migration\n    executor.migrate([(\"migrations\", \"0002_second\")])\n    # Check that the replaced migration was applied\n    self.assertIn(\n        (\"migrations\", \"0002_second\"),\n        executor.recorder.applied_migrations(),\n    )\n    self.assertIn(\n        (\"migrations2\", \"0001_initial\"),\n        executor.recorder.applied_migrations(),\n    )\n    # Migrate back to clean up the database\n    executor.migrate([(\"migrations\", None)])\n    executor.migrate([(\"migrations2\", None)])\n    # Check that the replaced migration was unapplied\n    self.assertNotIn(\n        (\"migrations\", \"0002_second\"),\n        executor.recorder.applied_migrations(),\n    )\n    self.assertNotIn(\n        (\"migrations2\", \"0001_initial\"),\n        executor.recorder.applied_migrations(),\n    )\n"], "sample_514": ["def test_colorbar_set_alpha():\n    fig, ax = plt.subplots()\n    im = ax.imshow([[1, 2], [3, 4]])\n    cbar = fig.colorbar(im)\n    cbar.set_alpha(0.5)\n    assert cbar.ax.get_facecolor() == (0.5, 0.5, 0.5, 0.5)\n    cbar.set_alpha(1.0)\n    assert cbar.ax.get_facecolor() == (0.0, 0.0, 0.0, 1.0)\n    cbar.set_alpha(None)\n    assert cbar.ax.get_facecolor() == (0.0, 0.0, 0.0, 1.0)\n    cbar.set_alpha(np.array([0.5, 0.7]))\n    assert cbar.ax.get_facecolor() == (0.0, 0.0, 0.0, 1.0)\n    cbar.set_alpha(0.5)\n    assert cbar.ax.get_facecolor() == (0.5, 0.5, 0.5, 0.5)\n"], "sample_751": ["def test_forest_classifier():\n    # Check consistency on dataset iris.\n    classes = np.unique(iris.target)\n    clf_samme = prob_samme = None\n\n    for alg in ['SAMME', 'SAMME.R']:\n        clf = RandomForestClassifier(algorithm=alg)\n        clf.fit(iris.data, iris.target)\n\n        assert_array_equal(classes, clf.classes_)\n        proba = clf.predict_proba(iris.data)\n        if alg == \"SAMME\":\n            clf_samme = clf\n            prob_samme = proba\n        assert_equal(proba.shape[1], len(classes))\n        assert_equal(clf.decision_function(iris.data).shape[1], len(classes))\n\n        score = clf.score(iris.data, iris.target)\n        assert score > 0.9, \"Failed with algorithm %s and score = %f\" % \\\n            (alg, score)\n\n        # Check we used multiple estimators\n        assert_greater(len(clf.estimators_), 1)\n        # Check for distinct random states (see issue #7408)\n        assert_equal(len(set(est.random_state for est in clf.estimators_)),\n                     len(clf.estimators_))\n\n    # Somewhat hacky regression test: prior to\n    # ae7adc880d624615a34bafdb1d75ef67051b8200,\n    # predict_proba returned SAMME.R values for SAMME.\n    clf_samme.algorithm = \"SAMME.R\"\n    assert_array_less(0,\n                      np.abs(clf_samme.predict_proba(iris.data) - prob_samme))\n"], "sample_1175": ["compilation error"], "sample_71": ["def test_decimal_pos_zero(self):\n    self.assertEqual(nformat(1234, '.', decimal_pos=0), '1234')\n    self.assertEqual(nformat(1234.2, '.', decimal_pos=0), '1234')\n    self.assertEqual(nformat(1234, '.', decimal_pos=0, decimal_sep='.'), '1234')\n    self.assertEqual(nformat(1234, '.', decimal_pos=0, decimal_sep=',', thousand_sep='.'), '1234')\n    self.assertEqual(nformat(1234, '.', decimal_pos=0, decimal_sep=',', thousand_sep='.', grouping=2), '1234')\n    self.assertEqual(nformat(1234, '.', decimal_pos=0, decimal_sep=',', thousand_sep='.', grouping=2, force_grouping=True), '1234')\n    self.assertEqual(nformat(1234.33, '.', decimal_pos=0, decimal_sep=',', thousand_sep='.', grouping=2, force_grouping=True), '1234')\n    self.assertEqual(nformat(1234, '.', decimal_pos=0, decimal_sep=',', thousand_sep='.', grouping=2, force_grouping=True, use_l10n=True), '1234')\n    self.assertEqual(nformat(1234, '.', decimal_pos=0, decimal_sep=',', thousand_sep='.', grouping=2, force_grouping=True, use_l10n=False), '1234')\n    self.assertEqual(nformat(Decimal('1234'), '.', decimal_pos=0), '1234')\n    self.assertEqual(nformat(Decimal('1234.2'), '.', decimal_pos=0), '1234')\n    self.assertEqual(nformat(Decimal('1234'), '.', decimal_pos=0, decimal_sep='.'), '1234')\n    self.assertEqual(nformat(Decimal('1234'), '.', decimal_pos=0, decimal_sep=',', thousand_sep='.'), '1234')\n    self.assertEqual(nformat(Decimal('1234'), '.', decimal_pos=0, decimal_sep=',', thousand_sep='.', grouping=2), '1234')\n    self.assertEqual(nformat(Decimal('1234'), '.', decimal_pos=0, decimal_sep=',', thousand_sep='.', grouping=2, force_grouping=True), '1234')\n    self.assertEqual(nformat(Decimal('1234.33'), '.', decimal_pos=0, decimal_sep=',', thousand_sep='.', grouping=2, force_grouping=True), '1234')\n    self.assertEqual(nformat(Decimal('1234"], "sample_1086": ["def test_Dict_printing():\n    d = Dict({1: 1 + x, 2: y*x})\n    assert str(d) == \"{1: x + 1, 2: x*y}\"\n    assert sstr(d) == \"{1: x + 1, 2: x*y}\"\n"], "sample_222": ["    def test_locking_multiple_files(self):\n        file_path = Path(__file__).parent / 'test.png'\n        with open(file_path) as f1, open(file_path) as f2, open(file_path) as f3:\n            self.assertIs(locks.lock(f1, locks.LOCK_EX), True)\n            self.assertIs(locks.lock(f2, locks.LOCK_SH | locks.LOCK_NB), True)\n            self.assertIs(locks.lock(f3, locks.LOCK_EX | locks.LOCK_NB), False)\n            self.assertIs(locks.unlock(f1), True)\n            self.assertIs(locks.unlock(f2), True)\n            self.assertIs(locks.unlock(f3), True)\n"], "sample_612": ["def test_groupby_dataset_fillna_with_attrs() -> None:\n    ds = Dataset({\"a\": (\"x\", [np.nan, 1, np.nan, 3])}, {\"x\": [0, 1, 2, 3]})\n    expected = Dataset({\"a\": (\"x\", range(4))}, {\"x\": [0, 1, 2, 3]})\n    for target in [ds, expected]:\n        target.coords[\"b\"] = (\"x\", [0, 0, 1, 1])\n    actual = ds.groupby(\"b\").fillna(DataArray([0, 2], dims=\"b\"))\n    assert_identical(expected, actual)\n\n    actual = ds.groupby(\"b\").fillna(Dataset({\"a\": (\"b\", [0, 2])}))\n    assert_identical(expected, actual)\n\n    # attrs with groupby\n    ds.attrs[\"attr\"] = \"ds\"\n    ds.a.attrs[\"attr\"] = \"da\"\n    actual = ds.groupby(\"b\").fillna(Dataset({\"a\": (\"b\", [0, 2])}))\n    assert actual.attrs == ds.attrs\n    assert actual.a.name == \"a\"\n    assert actual.a.attrs == ds.a.attrs\n"], "sample_205": ["def test_update_error_dict(self):\n    error1 = ValidationError('message')\n    error2 = ValidationError('message', code='my_code1')\n    error3 = ValidationError('message', code='my_code2')\n    error4 = ValidationError(\n        'error %(parm1)s %(parm2)s',\n        code='my_code1',\n        params={'parm1': 'val1', 'parm2': 'val2'},\n    )\n    error5 = ValidationError({'field1': 'message', 'field2': 'other'})\n    error6 = ValidationError({'field1': 'message'})\n    error7 = ValidationError([\n        ValidationError({'field1': 'field error', 'field2': 'other'}),\n        'message',\n    ])\n\n    error_dict = {}\n    error1.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['message']})\n    error2.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['message', 'message']})\n    error3.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['message', 'message', 'message']})\n    error4.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['message', 'message', 'message', 'error val1 val2']})\n    error5.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['message', 'message', 'message', 'error val1 val2', 'field1', 'field2']})\n    error6.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['message', 'message', 'message', 'error val1 val2', 'field1', 'field2']})\n    error7.update_error_dict(error_dict)\n    self.assertEqual(error_dict, {'__all__': ['message', 'message', 'message', 'error val1 val2', 'field1', 'field2', 'field error', 'other', 'message']})\n\n    error_dict = {}\n    error1.update_error_dict(error_dict, 'field1')\n    self.assertEqual(error_dict, {'field1': ['message']})\n    error2.update_error_dict(error_dict, 'field1')\n    self.assertEqual(error_dict, {'field1': ['message', 'message']})\n    error3.update_error_dict(error_dict, 'field1')\n    self.assertEqual(error_dict, {'field1': ['message', 'message', 'message"], "sample_668": ["def test_fixture_positional_arguments_warning():\n    \"\"\"Check that passing arguments to pytest.fixture() as positional arguments raises a warning\"\"\"\n    with pytest.warns(FUNCARGNAMES):\n        pytest.fixture(\"test_func\", \"arg1\", \"arg2\")\n"], "sample_1000": ["def test_LambertW_with_multiple_arguments():\n    assert mcode(LambertW(x, y)) == \"lambertw(y, x)\"\n"], "sample_1160": ["def test_imageset_intersection_interval():\n    from sympy.abc import n\n    f1 = ImageSet(Lambda(n, n*pi), S.Integers)\n    f2 = ImageSet(Lambda(n, 2*n), Interval(0, pi))\n    f3 = ImageSet(Lambda(n, 2*n*pi + pi/2), S.Integers)\n    # complex expressions\n    f4 = ImageSet(Lambda(n, n*I*pi), S.Integers)\n    f5 = ImageSet(Lambda(n, 2*I*n*pi + pi/2), S.Integers)\n    # non-linear expressions\n    f6 = ImageSet(Lambda(n, log(n)), S.Integers)\n    f7 = ImageSet(Lambda(n, n**2), S.Integers)\n    f8 = ImageSet(Lambda(n, Abs(n)), S.Integers)\n    f9 = ImageSet(Lambda(n, exp(n)), S.Naturals0)\n\n    assert f1.intersect(Interval(-1, 1)) == FiniteSet(0)\n    assert f1.intersect(Interval(0, 2*pi, False, True)) == FiniteSet(0, pi)\n    assert f2.intersect(Interval(1, 2)) == Interval(1, 2)\n    assert f3.intersect(Interval(-1, 1)) == S.EmptySet\n    assert f3.intersect(Interval(-5, 5)) == FiniteSet(pi*Rational(-3, 2), pi/2)\n    assert f4.intersect(Interval(-1, 1)) == FiniteSet(0)\n    assert f4.intersect(Interval(1, 2)) == S.EmptySet\n    assert f5.intersect(Interval(0, 1)) == S.EmptySet\n    assert f6.intersect(Interval(0, 1)) == FiniteSet(S.Zero, log(2))\n    assert f7.intersect(Interval(0, 10)) == Intersection(f7, Interval(0, 10))\n    assert f8.intersect(Interval(0, 2)) == Intersection(f8, Interval(0, 2))\n    assert f9.intersect(Interval(1, 2)) == Intersection(f9, Interval(1, 2))\n\n    # test intersection with other ImageSets\n    f10 = ImageSet(Lambda(n, n**2), S.Integers)\n    f11 ="], "sample_1067": ["def test_issue_5706():\n    x, y = symbols('x y')\n    a, b = symbols('a b', cls=Wild, exclude=(x, y))\n    e = 2*(x + 1)*y\n    assert e.match(a*x + b*y) == {a: 2, b: 1}\n    assert e.match(a*y + b*x) == {a: 1, b: 2}\n    assert e.match(a*y + b) is None\n    assert e.match(a + b*y) is None\n    assert e.match(a + b) is None\n"], "sample_501": ["def test_legend_title_fontprop_fontsize():\n    # test the title_fontsize kwarg\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontproperties=FontProperties(\n                                       family='serif', size=22))\n    assert leg.get_title().get_size() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontsize() == 20\n"], "sample_752": ["def test_iforest_offset():\n    \"\"\"Check that the offset is correctly computed.\"\"\"\n    X_train = [[1, 1], [1, 2], [2, 1]]\n    clf1 = IsolationForest(contamination=0.1).fit(X_train)\n    clf2 = IsolationForest(contamination=0.5).fit(X_train)\n    assert_array_almost_equal(clf1.offset_, -0.5)\n    assert_array_almost_equal(clf2.offset_, sp.stats.scoreatpercentile(\n        clf2.score_samples(X_train), 100. * 0.5))\n"], "sample_502": ["def test_matshow(tmpdir):\n    # Smoke test for matshow\n    fig, ax = plt.subplots()\n    matshow(np.random.rand(10, 10))\n    plt.close()\n"], "sample_230": ["    def test_invalid_json_with_custom_decoder(self):\n        class CustomDecoder(json.JSONDecoder):\n                return super().__init__(object_hook=self.as_uuid, *args, **kwargs)\n\n                if 'uuid' in dct:\n                    dct['uuid'] = uuid.UUID(dct['uuid'])\n                return dct\n\n        field = JSONField(decoder=CustomDecoder)\n        with self.assertRaisesMessage(ValidationError, 'Enter a valid JSON.'):\n            field.clean('{some badly formed: json}')\n"], "sample_1202": ["def test_issue_10368():\n    a = Rational(32442016954, 78058255275)\n    assert int(a) == 41\n    assert int(-a) == -41\n    assert int(a) == int(-a)\n    assert type(int(a)) is type(int(-a)) is int\n"], "sample_349": ["    def test_build_attrs_i18n(self):\n        with translation.override('fr'):\n            form = AlbumForm()\n            attrs = form['band'].field.widget.get_context(name='my_field', value=None, attrs={})['widget']['attrs']\n            self.assertEqual(attrs['lang'], 'fr')\n"], "sample_636": ["def test_duplicate_code_raw_strings_disable_scope_nested(self) -> None:\n    \"\"\"Tests disabling duplicate-code at an inner scope level in a nested scope.\"\"\"\n    path = join(DATA, \"raw_strings_disable_scope_nested\")\n    expected_output = \"Similar lines in 2 files\"\n    self._test_output(\n        [path, \"--disable=all\", \"--enable=duplicate-code\"],\n        expected_output=expected_output,\n    )\n"], "sample_1129": ["def test_SymPyPrinter():\n    p = SymPyPrinter()\n    expr = expm1(x)\n    assert p.doprint(expr) == 'sympy.exp(x - 1)'\n    expr = log1p(x)\n    assert p.doprint(expr) == 'sympy.log(x + 1)'\n    expr = cosm1(x)\n    assert p.doprint(expr) == 'sympy.cos(x - 1)'\n"], "sample_317": ["def test_rss2_feed_enclosures(self):\n    \"\"\"\n    Test the structure and content of enclosures in RSS feeds generated by Rss201rev2Feed.\n    \"\"\"\n    response = self.client.get('/syndication/rss2/enclosures/')\n    doc = minidom.parseString(response.content)\n    chan = doc.getElementsByTagName('rss')[0].getElementsByTagName('channel')[0]\n    items = chan.getElementsByTagName('item')\n    for item in items:\n        enclosures = item.getElementsByTagName('enclosure')\n        self.assertEqual(len(enclosures), 1)\n        enclosure = enclosures[0]\n        self.assertEqual(enclosure.getAttribute('url'), 'http://example.com/enclosure.mp3')\n        self.assertEqual(enclosure.getAttribute('length'), '123456')\n        self.assertEqual(enclosure.getAttribute('type'), 'audio/mpeg')\n"], "sample_464": ["def test_content_disposition_buffer_filename(self):\n    \"\"\"\n    Test that the filename is correctly set when using a buffer.\n    \"\"\"\n    response = FileResponse(io.BytesIO(b\"binary content\"), filename=\"custom_name.py\")\n    self.assertEqual(response.headers[\"Content-Disposition\"], 'inline; filename=\"custom_name.py\"')\n"], "sample_489": ["def test_update_conflicts_update_fields_pk(self):\n    Country.objects.bulk_create(self.data)\n    self.assertEqual(Country.objects.count(), 4)\n\n    new_data = [\n        # Conflicting countries.\n        Country(\n            name=\"Germany\",\n            iso_two_letter=\"DE\",\n            description=(\"Germany is a country in Central Europe.\"),\n        ),\n        Country(\n            name=\"Czech Republic\",\n            iso_two_letter=\"CZ\",\n            description=(\n                \"The Czech Republic is a landlocked country in Central Europe.\"\n            ),\n        ),\n        # New countries.\n        Country(name=\"Australia\", iso_two_letter=\"AU\"),\n        Country(\n            name=\"Japan\",\n            iso_two_letter=\"JP\",\n            description=(\"Japan is an island country in East Asia.\"),\n        ),\n    ]\n    results = Country.objects.bulk_create(\n        new_data,\n        update_conflicts=True,\n        update_fields=[\"pk\"],\n    )\n    self.assertEqual(len(results), len(new_data))\n    if connection.features.can_return_rows_from_bulk_insert:\n        for instance in results:\n            self.assertIsNotNone(instance.pk)\n    self.assertEqual(Country.objects.count(), 6)\n    self.assertCountEqual(\n        Country.objects.values(\"iso_two_letter\", \"description\"),\n        [\n            {\"iso_two_letter\": \"US\", \"description\": \"\"},\n            {\"iso_two_letter\": \"NL\", \"description\": \"\"},\n            {\n                \"iso_two_letter\": \"DE\",\n                \"description\": (\"Germany is a country in Central Europe.\"),\n            },\n            {\n                \"iso_two_letter\": \"CZ\",\n                \"description\": (\n                    \"The Czech Republic is a landlocked country in Central Europe.\"\n                ),\n            },\n            {\"iso_two_letter\": \"AU\", \"description\": \"\"},\n            {\n                \"iso_two_letter\": \"JP\",\n                \"description\": (\"Japan is an island country in East Asia.\"),\n            },\n        ],\n    )\n"], "sample_475": ["    def test_prepopulated_fields_with_choices(self):\n        class TestModelAdmin(ModelAdmin):\n            prepopulated_fields = {\"state\": (\"name\",)}\n\n        self.assertIsInvalid(\n            TestModelAdmin,\n            ValidationTestModel,\n            \"The value of 'prepopulated_fields' refers to 'state', which must not be \"\n            \"a DateTimeField, a ForeignKey, a OneToOneField, or a ManyToManyField.\",\n            \"admin.E028\",\n        )\n"], "sample_63": ["    def test_loader_not_found(self):\n        engine = Engine(dirs=[TEMPLATE_DIR])\n        with self.assertRaisesMessage(TemplateDoesNotExist, 'index.html'):\n            engine.get_template('index.html')\n"], "sample_700": ["    def test_parametrize_with_indirect(self, pytester: Pytester) -> None:\n        pytester.makepyfile(\n            \"\"\"\n            import pytest\n\n            @pytest.fixture\n                return request.param\n\n            @pytest.mark.parametrize(\"arg\", [1, 2], indirect=True)\n                assert arg == 1\n            @pytest.mark.parametrize(\"arg\", [3, 4], indirect=True)\n                assert arg == 3\n        \"\"\"\n        )\n        result = pytester.runpytest()\n        result.stdout.fnmatch_lines([\"*1 passed*2 passed*\"])\n"], "sample_213": ["    def setUp(self):\n        self.storage = FileSystemStorage(location=tempfile.mkdtemp())\n"], "sample_313": ["    def test_watch_for_template_changes_multiple_backends(self):\n        mock_reloader = mock.MagicMock()\n        autoreload.watch_for_template_changes(mock_reloader)\n        self.assertSequenceEqual(\n            sorted(mock_reloader.watch_dir.call_args_list),\n            [\n                mock.call(ROOT / 'templates', '**/*'),\n                mock.call(ROOT / 'templates_extra', '**/*')\n            ]\n        )\n"], "sample_952": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n        pass\n\n    func.register(int, lambda x: x)\n\n    assert inspect.is_singledispatch_function(func) is True\n    assert inspect.is_singledispatch_function(singledispatch(func)) is True\n    assert inspect.is_singledispatch_function(lambda x: x) is False\n    assert inspect.is_singledispatch_function(1) is False\n"], "sample_756": ["def test_max_eps_warning():\n    # Test that we warn when max_eps is close to scaled epsPrime\n\n    centers = [[1, 1], [-1, -1], [1, -1]]\n    X, labels_true = make_blobs(n_samples=750, centers=centers,\n                                cluster_std=0.4, random_state=0)\n\n    # Compute OPTICS\n    clust = OPTICS(max_eps=1.0, min_samples=10)\n    clust3 = clust.fit(X)\n    # check warning when centers are passed\n    assert_warns(RuntimeWarning, clust3.extract_dbscan, .3)\n    # Cluster ordering starts at 0; max cluster label = 2 is 3 clusters\n    assert_equal(max(clust3.extract_dbscan(.3)[1]), 2)\n"], "sample_423": ["def test_alter_field_with_default(self):\n    \"\"\"Tests autodetection of field default value changes.\"\"\"\n    changes = self.get_changes([self.author_name], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=\"Ada Lovelace\")\n"], "sample_808": ["def test_iforest_max_features():\n    \"\"\"Check Isolation Forest for various max_features settings.\"\"\"\n    X_train = np.array([[0, 1], [1, 2]])\n    X_test = np.array([[2, 1], [1, 1]])\n\n    grid = ParameterGrid({\"max_features\": [1.0, 2, 0.5]})\n\n    with ignore_warnings():\n        for params in grid:\n            IsolationForest(random_state=rng, **params).fit(X_train).predict(X_test)\n"], "sample_23": ["def test_angle_to_quantity_with_non_angular_unit():\n    \"\"\"\n    Test that creating a Quantity from an Angle with a non-angular unit raises an error\n    \"\"\"\n    with pytest.raises(u.UnitsError):\n        Angle(1.0 * u.m).to(u.Quantity)\n"], "sample_269": ["    def test_jsi18n_with_no_packages(self):\n        \"\"\"\n        The javascript_catalog can be deployed with no packages.\n        \"\"\"\n        response = self.client.get('/jsi18n/')\n        self.assertEqual(response.headers['Content-Type'], 'text/javascript; charset=\"utf-8\"')\n        # response content must include a line like:\n        # \"this is to be translated\": <value of trans_txt Python variable>\n        # json.dumps() is used to be able to check Unicode strings.\n        self.assertContains(response, json.dumps('this is to be translated'), 1)\n"], "sample_1008": ["def test_orientnew_respects_input_latexs_variables():\n    N = ReferenceFrame('N')\n    q1 = dynamicsymbols('q1')\n    A = N.orientnew('a', 'Axis', [q1, N.z])\n\n    #build default and alternate latex_vecs and variables:\n    def_latex_vecs = [(r\"\\mathbf{\\hat{%s}_%s}\" % (A.name.lower(),\n                      A.indices[0])), (r\"\\mathbf{\\hat{%s}_%s}\" %\n                      (A.name.lower(), A.indices[1])),\n                      (r\"\\mathbf{\\hat{%s}_%s}\" % (A.name.lower(),\n                      A.indices[2]))]\n\n    name = 'b'\n    indices = [x+'1' for x in N.indices]\n    new_latex_vecs = [(r\"\\mathbf{\\hat{%s}_{%s}}\" % (name.lower(),\n                      indices[0])), (r\"\\mathbf{\\hat{%s}_{%s}}\" %\n                      (name.lower(), indices[1])),\n                      (r\"\\mathbf{\\hat{%s}_{%s}}\" % (name.lower(),\n                      indices[2]))]\n\n    new_variables = ['notb_'+x+'1' for x in N.indices]\n    B = N.orientnew(name, 'Axis', [q1, N.z], latexs=new_latex_vecs,\n                    variables=new_variables)\n\n    assert A.latex_vecs == def_latex_vecs\n    assert B.latex_vecs == new_latex_vecs\n    assert B.indices != indices\n    for j,var in enumerate(A.varlist):\n        assert var.name == A.name + '_' + A.indices[j]\n    for j,var in enumerate(B.varlist):\n        assert var.name == new_variables[j]\n"], "sample_180": ["    def test_unique_constraint_pointing_to_foreign_key_field(self):\n        class Parent(models.Model):\n            pass\n\n        class Child(models.Model):\n            parent = models.ForeignKey(Parent, models.CASCADE)\n\n            class Meta:\n                constraints = [\n                    models.UniqueConstraint(fields=['parent_id'], name='name'),\n                ]\n\n        self.assertEqual(Child.check(databases=self.databases), [\n            Error(\n                \"'constraints' refers to the nonexistent field, related field, \"\n                \"or lookup 'parent_id'.\",\n                obj=Child,\n                id='models.E015',\n            ),\n        ])\n"], "sample_191": ["    def setUp(self):\n        self._tempdir = tempfile.TemporaryDirectory()\n        self.tempdir = Path(self._tempdir.name).resolve(strict=True).absolute()\n        self.existing_file = self.ensure_file(self.tempdir / 'test.py')\n        self.nonexistent_file = (self.tempdir / 'does_not_exist.py').absolute()\n        self.reloader = autoreload.StatReloader()\n"], "sample_922": ["def test_pydata_signature_old_type(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :type: int\\n\"\n            \"   :value: 1\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"version\"],\n                                                    [desc_annotation, (\": \",\n                                                                       [pending_xref, \"int\"])],\n                                                    [desc_annotation, \" = 1\"])],\n                                  desc_content)]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n    assert 'version' in domain.objects\n    assert domain.objects['version'] == ('index', 'version', 'data')\n"], "sample_620": ["def test_concat_fill_value_dict() -> None:\n    # Test that fill_value dict is correctly applied to variables\n    da1 = DataArray([1, 2], coords=[(\"x\", [1, 2])], attrs={\"a\": 1})\n    da2 = DataArray([1, 2], coords=[(\"x\", [1, 3])], attrs={\"a\": 2})\n    expected = DataArray(\n        [[1, 2, 2], [1, 1, 2]],\n        dims=[\"y\", \"x\"],\n        coords={\"x\": [1, 2, 3]},\n        attrs={\"a\": 1},\n    )\n    actual = concat((da1, da2), dim=\"y\", fill_value={\"a\": 2})\n    assert_identical(actual, expected)\n"], "sample_483": ["def test_prepopulated_fields(self):\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\", \"nonexistent\")}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    expected = [\n        checks.Error(\n            \"The value of 'prepopulated_fields[\\\"slug\\\"]' refers to 'nonexistent', \"\n            \"which is not a field of 'admin_checks.Song'.\",\n            obj=SongAdmin,\n            id=\"admin.E030\",\n        )\n    ]\n    self.assertEqual(errors, expected)\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin.ModelAdmin):\n        prepopulated_fields = {\"slug\": (\"title\",)}\n\n    errors = SongAdmin(Song, AdminSite()).check()\n    self.assertEqual(errors, [])\n\n    class SongAdmin(admin"], "sample_655": ["    def test_global_capture_is_disabled(self, testdir):\n        p = testdir.makepyfile(\n            \"\"\"\n                print(\"hello\")\n            \"\"\"\n        )\n        result = testdir.runpytest_subprocess(\"--capture=no\")\n        result.stdout.fnmatch_lines([\"*hello*\"])\n        assert result.ret == 0\n"], "sample_886": ["def test__wrap_in_pandas_container_sparse():\n    \"\"\"Check _wrap_in_pandas_container for sparse data.\"\"\"\n    pd = pytest.importorskip(\"pandas\")\n    X = csr_matrix([[1, 0, 3], [0, 0, 1]])\n    columns = np.asarray([\"f0\", \"f1\", \"f2\"], dtype=object)\n    index = np.asarray([0, 1])\n\n    with pytest.raises(ValueError, match=\"Pandas output does not support sparse data\"):\n        _wrap_in_pandas_container(X, columns=columns, index=index)\n"], "sample_795": ["def test_check_estimators_pickle_works_on_deprecated_fit():\n    # Tests that check_estimators_pickle works on a class with a deprecated fit method\n\n    class TestEstimatorWithDeprecatedFitMethod(BaseEstimator):\n        @deprecated(\"Deprecated for the purpose of testing check_estimators_pickle\")\n            return self\n\n    check_estimators_pickle(\"test\", TestEstimatorWithDeprecatedFitMethod())\n"], "sample_1128": ["def test_auto_point_vel_if_tree_has_vel_but_inconsistent_pos_vector():\n    q1, q2 = dynamicsymbols('q1 q2')\n    B = ReferenceFrame('B')\n    S = ReferenceFrame('S')\n    P = Point('P')\n    P.set_vel(B, q1 * B.x)\n    P1 = Point('P1')\n    P1.set_pos(P, q2 * S.y)\n    P2 = Point('P2')\n    P2.set_pos(P1, q1 * B.x)\n    raises(ValueError, lambda : P2.vel(B)) # P1.pos_from(P) can't be expressed in B\n    raises(ValueError, lambda : P2.vel(S)) # P.vel(S) not defined\n"], "sample_129": ["    def test_floatformat03(self):\n        output = self.engine.render_to_string('floatformat03', {\"a\": \"1.42\", \"b\": mark_safe(\"1.42\")})\n        self.assertEqual(output, \"1 1\")\n"], "sample_330": ["    def test_typecast_date(self):\n        \"\"\"\n        Test the custom typecast_date function.\n        \"\"\"\n        self.assertEqual(typecast_date('2022-01-01'), datetime.date(2022, 1, 1))\n        self.assertIsNone(typecast_date(None))\n"], "sample_53": ["    def test_build_attrs_with_custom_attrs(self):\n        form = AlbumForm()\n        attrs = form['band'].field.widget.get_context(name='my_field', value=None, attrs={'class': 'my-class', 'data-test': 'test'})['widget']['attrs']\n        self.assertEqual(attrs, {\n            'class': 'my-class admin-autocomplete data-test=\"test\"',\n            'data-ajax--cache': 'true',\n            'data-ajax--type': 'GET',\n            'data-ajax--url': '/admin_widgets/band/autocomplete/',\n            'data-theme': 'admin-autocomplete',\n            'data-allow-clear': 'false',\n            'data-placeholder': ''\n        })\n"], "sample_299": ["    def test_relative_path(self):\n        with self.settings(CACHES={\n            'default': {\n                'BACKEND': 'django.core.cache.backends.filebased.FileBasedCache',\n                'LOCATION': 'cache',\n            },\n        }):\n            self.assertEqual(check_file_based_cache_is_absolute(None), [\n                Warning(\n                    \"Your 'default' cache LOCATION path is relative. Use an \"\n                    \"absolute path instead.\",\n                    id='caches.W003',\n                ),\n            ])\n"], "sample_880": ["def test_class_distribution_sparse_multilabel_explicit_zero():\n    y = np.array([[0, 1], [1, 0]])\n    y_sp = sparse_multilable_explicit_zero\n    classes, n_classes, class_prior = class_distribution(y)\n    classes_sp, n_classes_sp, class_prior_sp = class_distribution(y_sp)\n    classes_expected = [[0, 1]]\n    n_classes_expected = [2]\n    class_prior_expected = [0.5, 0.5]\n\n    assert_array_almost_equal(classes[0], classes_expected[0])\n    assert_array_almost_equal(n_classes[0], n_classes_expected[0])\n    assert_array_almost_equal(class_prior[0], class_prior_expected)\n\n    assert_array_almost_equal(classes_sp[0], classes_expected[0])\n    assert_array_almost_equal(n_classes_sp[0], n_classes_expected[0])\n    assert_array_almost_equal(class_prior_sp[0], class_prior_expected)\n"], "sample_12": ["def test_longitude_wrap_at_zero():\n    \"\"\"\n    Test that Longitude's wrap_at method works correctly when the wrap angle is 0\n    \"\"\"\n    lon = Longitude([0, 360, 720] * u.deg)\n    assert np.all(lon.wrap_at(0 * u.deg).degree == np.array([0., 0., 0.]))\n    assert np.all(lon.wrap_at(0 * u.deg, inplace=True).degree == np.array([0., 0., 0.]))\n    assert np.all(lon.wrap_at('0d').degree == np.array([0., 0., 0.]))\n    assert np.all(lon.wrap_at('0d', inplace=True).degree == np.array([0., 0., 0.]))\n    assert np.all(lon.wrap_at(0 * u.deg).value == np.array([0., 0., 0.]))\n    assert np.all(lon.wrap_at(0 * u.deg, inplace=True).value == np.array([0., 0., 0.]))\n"], "sample_748": ["def test_grid_search_cv_results_keys():\n    # Test the search.cv_results_ contains all the required results\n    X, y = make_classification(n_samples=50, n_features=4, random_state=42)\n\n    n_splits = 3\n    n_grid_points = 6\n    params = [dict(kernel=['rbf', ], C=[1, 10], gamma=[0.1, 1]),\n              dict(kernel=['poly', ], degree=[1, 2])]\n\n    param_keys = ('param_C', 'param_degree', 'param_gamma', 'param_kernel')\n    score_keys = ('mean_test_score', 'mean_train_score',\n                  'rank_test_score',\n                  'split0_test_score', 'split1_test_score',\n                  'split2_test_score',\n                  'split0_train_score', 'split1_train_score',\n                  'split2_train_score',\n                  'std_test_score', 'std_train_score',\n                  'mean_fit_time', 'std_fit_time',\n                  'mean_score_time', 'std_score_time')\n    n_candidates = n_grid_points\n\n    for iid in (False, True):\n        search = GridSearchCV(SVC(gamma='scale'), cv=n_splits, iid=iid,\n                              param_grid=params)\n        search.fit(X, y)\n        cv_results = search.cv_results_\n        check_cv_results_keys(cv_results, param_keys, score_keys, n_candidates)\n"], "sample_376": ["def test_max_cookie_length_empty(self):\n    \"\"\"\n    If the data exceeds what is allowed in a cookie, older messages are\n    removed before saving (and returned by the ``update`` method), even when\n    there are no messages to remove.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n    # When storing as a cookie, the cookie has constant overhead of approx\n    # 54 chars. We aim for a size which will fit 1 message into the cookie,\n    # but not 2.\n    msg_size = int((CookieStorage.max_cookie_size - 54) / 2 - 37)\n    first_msg = None\n    # Generate the same (tested) content every time that does not get run\n    # through zlib compression.\n    random.seed(42)\n    for i in range(2):\n        msg = get_random_string(msg_size)\n        storage.add(constants.INFO, msg)\n        if i == 0:\n            first_msg = msg\n    unstored_messages = storage.update(response)\n\n    cookie_storing = self.stored_messages_count(storage, response)\n    self.assertEqual(cookie_storing, 1)\n\n    self.assertEqual(len(unstored_messages), 1)\n    self.assertEqual(unstored_messages[0].message, first_msg)\n"], "sample_84": ["    def test_empty_query_string(self):\n        self.assertEqual(limited_parse_qsl('', keep_blank_values=True), [])\n"], "sample_96": ["    def test_not_iterable(self):\n        class TestModelAdmin(ModelAdmin):\n            readonly_fields = 10\n\n        self.assertIsInvalid(\n            TestModelAdmin, ValidationTestModel,\n            \"The value of 'readonly_fields' must be a list or tuple.\",\n            'admin.E034'\n        )\n"], "sample_220": ["    def test_set_cookie_with_domain(self):\n        \"\"\"set_cookie() accepts a domain for the cookie.\"\"\"\n        response = HttpResponse()\n        response.set_cookie('example', domain='example.com')\n        example_cookie = response.cookies['example']\n        self.assertEqual(example_cookie['domain'], 'example.com')\n"], "sample_601": ["def test_cftime_round_accessor(cftime_rounding_dataarray, cftime_date_type, use_dask):\n    import dask.array as da\n\n    freq = \"D\"\n    expected = xr.DataArray(\n        [\n            [cftime_date_type(1, 1, 1, 0), cftime_date_type(1, 1, 1, 0)],\n            [cftime_date_type(1, 1, 1, 0), cftime_date_type(1, 1, 2, 0)],\n        ],\n        name=\"round\",\n    )\n\n    if use_dask:\n        chunks = {\"dim_0\": 1}\n        # Currently a compute is done to inspect a single value of the array\n        # if it is of object dtype to check if it is a cftime.datetime (if not\n        # we raise an error when using the dt accessor).\n        with raise_if_dask_computes(max_computes=1):\n            result = cftime_rounding_dataarray.chunk(chunks).dt.round(freq)\n        expected = expected.chunk(chunks)\n        assert isinstance(result.data, da.Array)\n        assert result.chunks == expected.chunks\n    else:\n        result = cftime_rounding_dataarray.dt.round(freq)\n\n    assert_identical(result, expected)\n"], "sample_592": ["def test_inline_dask_repr(self):\n    da = xr.DataArray(np.random.randn(10), dims=\"x\", coords={\"x\": np.arange(10)})\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10,) meta=np.ndarray>\"\"\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10), dims=\"x\", coords={\"x\": np.arange(10)})\n    da.chunks = (10,)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10,) meta=np.ndarray>\"\"\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10), dims=\"x\", coords={\"x\": np.arange(10)})\n    da._meta = np.array([1, 2, 3])\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10,) meta=np.ndarray>\"\"\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10), dims=\"x\", coords={\"x\": np.arange(10)})\n    da._meta = np.array([1, 2, 3])\n    da.chunks = (10,)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(10,) meta=np.ndarray>\"\"\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10), dims=\"x\", coords={\"x\": np.arange(10)})\n    da._meta = np.array([1, 2, 3])\n    da.chunks = (5, 5)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(5, 5) meta=np.ndarray>\"\"\"\n    )\n    actual = formatting.inline_dask_repr(da)\n    assert actual == expected\n\n    da = xr.DataArray(np.random.randn(10), dims=\"x\", coords={\"x\": np.arange(10)})\n    da._meta = np.array([1, 2, 3])\n    da.chunks = (5, 5)\n    expected = dedent(\n        \"\"\"\\\n        dask.array<chunksize=(5, 5) meta=np.ndarray>\"\"\"\n    )\n    actual = formatting.inline_dask"], "sample_1110": ["def test_print_Relational():\n    from sympy import Eq, Ne, Lt, Le, Gt, Ge\n    p = PythonCodePrinter()\n    assert p.doprint(Eq(x, y)) == '(x == y)'\n    assert p.doprint(Ne(x, y)) == '(x != y)'\n    assert p.doprint(Lt(x, y)) == '(x < y)'\n    assert p.doprint(Le(x, y)) == '(x <= y)'\n    assert p.doprint(Gt(x, y)) == '(x > y)'\n    assert p.doprint(Ge(x, y)) == '(x >= y)'\n\n    p = NumPyPrinter()\n    assert p.doprint(Eq(x, y)) == 'numpy.equal(x, y)'\n    assert p.doprint(Ne(x, y)) == 'numpy.not_equal(x, y)'\n    assert p.doprint(Lt(x, y)) == 'numpy.less(x, y)'\n    assert p.doprint(Le(x, y)) == 'numpy.less_equal(x, y)'\n    assert p.doprint(Gt(x, y)) == 'numpy.greater(x, y)'\n    assert p.doprint(Ge(x, y)) == 'numpy.greater_equal(x, y)'\n"], "sample_862": ["def test_hashingvectorizer_dtype():\n    # Non-regression test: HashingVectorizer used to ignore its \"dtype\" param.\n    v = HashingVectorizer(dtype=np.float32)\n    assert v.dtype == np.float32\n\n    X = v.transform(['hello world', 'hello hello']).toarray()\n    assert X.dtype == np.float32\n"], "sample_797": ["def test_power_transformer_inverse_transform_zero_lambda():\n    # Test the inverse_transform() method when lambda = 0\n    pt = PowerTransformer(method='box-cox', standardize=False)\n    X = np.abs(X_2d)[:, 0:1]\n    pt.lambdas_ = np.array([0])\n    X_trans = pt.transform(X)\n    X_inv = pt.inverse_transform(X_trans)\n    assert_array_almost_equal(X_inv, X)\n"], "sample_73": ["    def setUp(self):\n        super().setUp()\n\n        temp_dir = tempfile.mkdtemp()\n        os.makedirs(os.path.join(temp_dir, 'test'))\n        self._clear_filename = os.path.join(temp_dir, 'test', 'cleared.txt')\n        with open(self._clear_filename, 'w') as f:\n            f.write('to be deleted in one test')\n\n        self.patched_settings = self.settings(\n            STATICFILES_DIRS=settings.STATICFILES_DIRS + [temp_dir],\n        )\n        self.patched_settings.enable()\n        self.addCleanup(shutil.rmtree, temp_dir)\n        self._manifest_strict = storage.staticfiles_storage.manifest_strict\n"], "sample_1012": ["def test_PythonCodePrinter_precision():\n    prntr = PythonCodePrinter(settings={'precision': 3})\n    assert prntr.doprint(x**y) == 'x**y'\n    assert prntr.doprint(Mod(x, 2)) == 'x % 2'\n    assert prntr.doprint(And(x, y)) == 'x and y'\n    assert prntr.doprint(Or(x, y)) == 'x or y'\n    assert not prntr.module_imports\n    assert prntr.doprint(pi) == 'math.pi'\n    assert prntr.module_imports == {'math': {'pi'}}\n    assert prntr.doprint(acos(x)) == 'math.acos(x)'\n    assert prntr.doprint(Assignment(x, 2)) == 'x = 2'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(sign(x)) == '(0.0 if x == 0 else math.copysign(1, x))'\n    assert prntr.doprint(oo) == 'oo'\n    assert prntr.doprint(zoo) == 'zoo'\n"], "sample_1016": ["def test_MatrixSlice():\n    A = Matrix([[1, 2, 3], [4, 5, 6]])\n    assert mcode(A[1:2, 0:2]) == \"[4 5]\"\n    assert mcode(A[1:2, 0:2]) == \"[4 5]\"\n    assert mcode(A[1:2, 0:2]) == \"[4 5]\"\n    assert mcode(A[:, 0:2]) == \"[1 2; 4 5]\"\n    assert mcode(A[0:2, :]) == \"[1 2 3; 4 5 6]\"\n    assert mcode(A[0:2, 0:2]) == \"[1 2; 4 5]\"\n    assert mcode(A[0:2, 0:2]) == \"[1 2; 4 5]\"\n    assert mcode(A[0:2, 0:2]) == \"[1 2; 4 5]\"\n    assert mcode(A[0:2, 0:2]) == \"[1 2; 4 5]\"\n    assert mcode(A[0:2, 0:2]) == \"[1 2; 4 5]\"\n    assert mcode(A[0:2, 0:2]) == \"[1 2; 4 5]\"\n    assert mcode(A[0:2, 0:2]) == \"[1 2; 4 5]\"\n    assert mcode(A[0:2, 0:2]) == \"[1 2; 4 5]\"\n    assert mcode(A[0:2, 0:2]) == \"[1 2; 4 5]\"\n    assert mcode(A[0:2, 0:2]) == \"[1 2; 4 5]\"\n    assert mcode(A[0:2, 0:2]) == \"[1 2; 4 5]\"\n    assert mcode(A[0:2, 0:2]) == \"[1 2; 4 5]\"\n    assert mcode(A[0:2, 0:2]) == \"[1 2; 4 5]\"\n    assert mcode(A[0:2, 0:2]) == \"[1 2; 4 5]\"\n"], "sample_577": ["    def test_move_group_by_orient(self, long_df):\n\n        class MoveWithGroupByOrient(Move):\n            group_by_orient = True\n\n                self.orient_at_call = orient\n                return data\n\n        m = MoveWithGroupByOrient()\n        Plot(long_df, x=\"a\", y=\"z\").add(m).plot()\n        assert m.orient_at_call == \"x\"\n"], "sample_1053": ["def test_issue_10368():\n    a = S(32442016954)/78058255275\n    assert int(a) == 41\n"], "sample_225": ["    def setUp(self):\n        self.site = admin.AdminSite()\n"], "sample_158": ["    def test_through_fields_with_non_foreign_key(self):\n        \"\"\"\n        ManyToManyField accepts the ``through_fields`` kwarg\n        only if an intermediary table is specified, and the fields\n        specified must be foreign keys.\n        \"\"\"\n        class Fan(models.Model):\n            pass\n\n        class Event(models.Model):\n            invitees = models.ManyToManyField(Fan, through='Invitation', through_fields=('invitee', 'event'))\n\n        class Invitation(models.Model):\n            event = models.ForeignKey(Event, models.CASCADE)\n            invitee = models.ForeignKey(Fan, models.CASCADE)\n            value = models.CharField(max_length=255)\n\n        field = Event._meta.get_field('invitees')\n        self.assertEqual(field.check(from_model=Event), [\n            Error(\n                \"'Invitation.event' is not a foreign key to 'Fan'.\",\n                hint=\"Did you mean one of the following foreign keys to 'Fan': invitee?\",\n                obj=field,\n                id='fields.E339',\n            ),\n        ])\n"], "sample_9": ["def test_write_table_html_fill_values_masked_multicolumn():\n    \"\"\"\n    Test that passing masked values in fill_values should only replace\n    masked columns or values for multidimensional tables\n    \"\"\"\n    buffer_output = StringIO()\n    t = Table([[1, 2, 3, 4], [(1.0, 1.0), (2.0, 2.0), (3.0, 3.0), (4.0, 4.0)],\n               [('a', 'a', 'a', 'a'), ('b', 'b', 'b', 'b'), ('c', 'c', 'c', 'c')]],\n              names=('a', 'b', 'c'))\n    t['a'][0:2] = np.ma.masked\n    t['b'][0:2] = np.ma.masked\n    ascii.write(t, buffer_output, fill_values=(ascii.masked, 'MASKED'),\n                format='html')\n\n    t_expected = Table([[1, 2, 3, 4], [(1.0, 1.0), (2.0, 2.0), (3.0, 3.0), (4.0, 4.0)],\n                       [('MASKED', 'MASKED', 'MASKED', 'MASKED'), ('b', 'b', 'b', 'b'), ('c', 'c', 'c', 'c')]],\n                      names=('a', 'b', 'c'))\n    buffer_expected = StringIO()\n    ascii.write(t_expected, buffer_expected, format='html')\n    print(buffer_expected.getvalue())\n\n    assert buffer_output.getvalue() == buffer_expected.getvalue()\n"], "sample_50": ["def test_empty_conn_params(self):\n    self.assertEqual(\n        self._run_it({\n            'database': 'dbname',\n        }), (\n            ['psql', 'dbname'],\n            None,\n        )\n    )\n"], "sample_294": ["def test_csrf_trusted_origin_subdomain_allowed(self):\n    \"\"\"\n    A POST request with an origin that matches a CSRF_TRUSTED_ORIGINS wildcard\n    and a subdomain is accepted.\n    \"\"\"\n    req = self._get_POST_request_with_token()\n    req._is_secure_override = True\n    req.META['HTTP_HOST'] = 'subdomain.example.com'\n    req.META['HTTP_REFERER'] = 'https://subdomain.example.com'\n    mw = CsrfViewMiddleware(post_form_view)\n    self.assertIs(mw._origin_verified(req), True)\n    response = mw.process_view(req, post_form_view, (), {})\n    self.assertIsNone(response)\n    self.assertEqual(mw.allowed_origins_exact, set())\n    self.assertEqual(mw.allowed_origin_subdomains, {'https': ['.example.com']})\n"], "sample_853": ["def test_transform_target_regressor_clone_regressor():\n    # regression test for gh-issue #11618\n    # check that we clone the regressor\n    X, y = friedman\n    ttr = TransformedTargetRegressor(\n        regressor=DummyRegressorWithExtraFitParams(),\n        transformer=DummyTransformer()\n    )\n    ttr.fit(X, y)\n    assert ttr.regressor_.__class__ == DummyRegressorWithExtraFitParams\n    assert ttr.regressor_.check_input == False\n"], "sample_246": ["    def test_no_default_ignore(self):\n        cmd = MakeMessagesCommand()\n        cmd.use_default_ignore_patterns = False\n        cmd.ignore_patterns = []\n        cmd.find_files(self.test_dir)\n        self.assertEqual(cmd.ignore_patterns, ['CVS', '.*', '*~', '*.pyc'])\n"], "sample_43": ["def test_events_fitness_homoscedastic():\n    rng = np.random.RandomState(0)\n    t = np.concatenate([rng.rand(100),\n                        1 + rng.rand(200)])\n\n    x = np.ones_like(t)\n    x[:20] += 1\n\n    bins1 = bayesian_blocks(t, fitness='events')\n    bins2 = bayesian_blocks(t, x=x, fitness='events')\n\n    assert_allclose(bins1, bins2)\n"], "sample_112": ["    def test_prepopulated_fields_js(self):\n        \"\"\"\n        prepopulated_fields_js template tag should pass whole context.\n        \"\"\"\n        request = self.request_factory.get(reverse('admin:auth_user_change', args=[self.superuser.pk]))\n        request.user = self.superuser\n        admin = UserAdmin(User, site)\n        extra_context = {'extra': True}\n        response = admin.change_view(request, str(self.superuser.pk), extra_context=extra_context)\n        template_context = prepopulated_fields_js(response.context_data)\n        self.assertIs(template_context['extra'], True)\n        self.assertIn('prepopulated_fields', template_context)\n        self.assertIn('prepopulated_fields_json', template_context)\n"], "sample_1150": ["def test_ImageSet_simplification():\n    from sympy.abc import n, m\n    assert imageset(Lambda(n, n), S.Integers) == S.Integers\n    assert imageset(Lambda(n, sin(n)),\n                    imageset(Lambda(m, tan(m)), S.Integers)) == \\\n            imageset(Lambda(m, sin(tan(m))), S.Integers)\n    assert imageset(n, 1 + 2*n, S.Naturals) == Range(3, oo, 2)\n    assert imageset(n, 1 + 2*n, S.Naturals0) == Range(1, oo, 2)\n    assert imageset(n, 1 - 2*n, S.Naturals) == Range(-1, -oo, -2)\n    assert imageset(Lambda(n, n**2), S.Naturals) == Range(0, oo, 2)\n    assert imageset(Lambda(n, n**2), S.Naturals0) == Range(0, oo, 2)\n    assert imageset(Lambda(n, n**2), S.Integers) == Range(-oo, oo, 2)\n    assert imageset(Lambda(n, n**2), S.Rationals) == Range(-oo, oo, 2)\n    assert imageset(Lambda(n, n**2), S.Reals) == Range(-oo, oo, 2)\n    assert imageset(Lambda(n, n**2), S.Complexes) == Range(-oo, oo, 2)\n    assert imageset(Lambda(n, n**2 + 1), S.Naturals) == Range(1, oo, 2)\n    assert imageset(Lambda(n, n**2 + 1), S.Naturals0) == Range(1, oo, 2)\n    assert imageset(Lambda(n, n**2 + 1), S.Integers) == Range(-oo, oo, 2)\n    assert imageset(Lambda(n, n**2 + 1), S.Rationals) == Range(-oo, oo, 2)\n    assert imageset(Lambda(n, n**2 + 1), S.Reals) == Range(-oo, oo, 2)\n    assert imageset(Lambda(n, n**2 + 1), S.Complexes) == Range(-oo, oo, 2)\n    assert"], "sample_174": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_135": ["def test_date_format_specifiers(self):\n    my_birthday = date(1984, 8, 7)\n\n    for specifier in ['b', 'c', 'd', 'D', 'E', 'F', 'j', 'l', 'L', 'm', 'M', 'n', 'N', 'o', 'r', 'S', 't', 'U', 'w', 'W', 'y', 'Y', 'z']:\n        self.assertEqual(dateformat.format(my_birthday, specifier), getattr(my_birthday, specifier))\n"], "sample_57": ["    def test_render_with_invalid_password(self):\n        widget = ReadOnlyPasswordHashWidget()\n        value = 'invalid_password'\n        self.assertHTMLEqual(\n            widget.render('name', value, {'id': 'id_password'}),\n            \"\"\"\n            <div id=\"id_password\">\n                <strong>label</strong>: Invalid password format or unknown hashing algorithm.\n            </div>\n            \"\"\"\n        )\n"], "sample_485": ["def test_avoid_wrapping(self):\n    items = (\n        (\"Hello, world!\", \"Hello, world!\"),\n        (\"Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!  Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\", \"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!\"),\n        (\"Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello, world!  Hello,"], "sample_148": ["    def test_quote(self):\n        \"\"\"\n        Tests for quote function\n        \"\"\"\n        self.assertEqual(quote('test'), 'test')\n        self.assertEqual(quote('test/'), 'test/_')\n        self.assertEqual(quote('test:'), 'test:_')\n        self.assertEqual(quote('test:\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'), 'test:_')\n        self.assertEqual(quote('test:\"\"'),"], "sample_653": ["def test_log_file_level_overridden_by_cli(testdir):\n    log_file = testdir.tmpdir.join(\"pytest.log\").strpath\n\n    testdir.makeini(\n        \"\"\"\n        [pytest]\n        log_file={}\n        log_file_level = INFO\n        \"\"\".format(\n            log_file\n        )\n    )\n    testdir.makepyfile(\n        \"\"\"\n        import pytest\n        import logging\n            plugin = request.config.pluginmanager.getplugin('logging-plugin')\n            assert plugin.log_file_handler.level == logging.INFO\n            logging.getLogger('catchlog').debug(\"This log message won't be shown\")\n            logging.getLogger('catchlog').info(\"This log message will be shown\")\n            print('PASSED')\n    \"\"\"\n    )\n\n    result = testdir.runpytest(\n        \"-s\", \"--log-file={}\".format(log_file), \"--log-file-level=ERROR\"\n    )\n\n    # fnmatch_lines does an assertion internally\n    result.stdout.fnmatch_lines([\"test_log_file_level_overridden_by_cli.py PASSED\"])\n\n    # make sure that that we get a '0' exit code for the testsuite\n    assert result.ret == 0\n    assert os.path.isfile(log_file)\n    with open(log_file) as rfh:\n        contents = rfh.read()\n        assert \"This log message will be shown\" not in contents\n        assert \"This log message won't be shown\" not in contents\n"], "sample_1167": ["def test_latex_Dict():\n    d = {Rational(1): 1, x**2: 2, x: 3, x**3: 4}\n    assert latex(d) == r'\\left\\{ 1 : 1, \\  x : 3, \\  x^{2} : 2, \\  x^{3} : 4\\right\\}'\n    D = Dict(d)\n    assert latex(D) == r'\\left\\{ 1 : 1, \\  x : 3, \\  x^{2} : 2, \\  x^{3} : 4\\right\\}'\n"], "sample_913": ["def test_pydata_signature_with_type_and_value(app):\n    text = (\".. py:data:: var\\n\"\n            \"   :type: int\\n\"\n            \"   :value: 1\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"var\"],\n                                                    [desc_annotation, \": int\"],\n                                                    [desc_annotation, \" = 1\"])],\n                                  [desc_content, ()])]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n    assert 'var' in domain.objects\n    assert domain.objects['var'] == ('index', 'var', 'data')\n"], "sample_1020": ["def test_Sum():\n    assert mcode(Sum(sin(x), (x, 0, 10))) == \"Hold[Sum[Sin[x], {x, 0, 10}]\"\n"], "sample_1186": ["def test_issue_12345():\n    A = ImmutableDenseNDimArray([[1, 2, 3], [4, 5, 6]])\n    B = ImmutableDenseNDimArray([[7, 8, 9], [10, 11, 12]])\n    assert (A + B).shape == (2, 3)\n    assert (A + B).tolist() == [[8, 10, 12], [14, 16, 18]]\n    assert (A - B).shape == (2, 3)\n    assert (A - B).tolist() == [[-6, -6, -6], [-6, -6, -6]]\n    assert (A * 2).shape == (2, 3)\n    assert (A * 2).tolist() == [[2, 4, 6], [8, 10, 12]]\n    assert (2 * A).shape == (2, 3)\n    assert (2 * A).tolist() == [[2, 4, 6], [8, 10, 12]]\n    assert (A / 2).shape == (2, 3)\n    assert (A / 2).tolist() == [[0.5, 1, 1.5], [2, 2.5, 3]]\n    assert (-A).shape == (2, 3)\n    assert (-A).tolist() == [[-1, -2, -3], [-4, -5, -6]]\n"], "sample_356": ["def test_alter_field_to_foreign_key(self):\n    \"\"\"Tests autodetection of field type changes from a concrete field to a ForeignKey.\"\"\"\n    changes = self.get_changes([self.author_empty, self.book_with_field_and_author_renamed], [self.author_empty, self.book])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'otherapp', 1)\n    self.assertOperationTypes(changes, 'otherapp', 0, [\"AlterField\", \"RemoveField\"])\n    self.assertOperationAttributes(changes, 'otherapp', 0, 0, name=\"writer\")\n    self.assertOperationAttributes(changes, 'otherapp', 0, 1, model_name=\"book\", name=\"author\")\n"], "sample_697": ["def test_tmp_path_factory_create_directory_with_safe_permissions_on_windows(\n    tmp_path: Path, monkeypatch: MonkeyPatch"], "sample_887": ["def test_calibration_with_non_fitted_base_estimator():\n    \"\"\"Check that we raise an error if the base estimator is not fitted.\"\"\"\n    X, y = make_classification(n_samples=10, n_features=5, n_classes=2, random_state=7)\n    clf = LinearSVC(C=1)\n    calib_clf = CalibratedClassifierCV(clf, cv=\"prefit\")\n    with pytest.raises(NotFittedError):\n        calib_clf.fit(X, y)\n"], "sample_182": ["def test_difference_with_distinct(self):\n    qs1 = Number.objects.filter(num__lte=5)\n    qs2 = Number.objects.filter(num__lte=4)\n    self.assertNumbersEqual(qs1.difference(qs2, distinct=True), [5], ordered=False)\n"], "sample_1070": ["def test_log_polar():\n    x, y = symbols('x,y', polar=True)\n    assert log(exp_polar(x)).expand() == x\n    assert log(exp_polar(x*y)).expand() == log(x*y)\n    assert log(exp_polar(x**y)).expand() == y*log(x)\n    assert log(exp_polar(x + y)).expand() == log(x + y)\n    assert log(exp_polar(x - y)).expand() == log(x - y)\n    assert log(exp_polar(x*y)).expand() == log(x*y)\n    assert log(exp_polar(x/y)).expand() == log(x/y)\n    assert log(exp_polar(x**y)).expand() == y*log(x)\n    assert log(exp_polar(x**y)).expand(force=True) == y*log(x)\n    assert log(exp_polar(x**y)).expand(mul=False) != y*log(x)\n"], "sample_392": ["    def test_nested_key_transform_annotation_expression_with_subquery(self):\n        obj = NullableJSONModel.objects.create(\n            value={\"d\": [{\"f\": \"g\"}, {\"f\": \"g\"}]}\n        )\n        self.assertSequenceEqual(\n            NullableJSONModel.objects.filter(\n                value__d__1__f=F(\"value__d__0__f\")\n            ).filter(value__d__1__f=\"g\"),\n            [obj],\n        )\n"], "sample_600": ["def test_CFScaleOffsetCoder_encode_scale_factor():\n    original = xr.Variable((\"x\",), np.arange(10.0), encoding=dict(scale_factor=10))\n    coder = variables.CFScaleOffsetCoder()\n    encoded = coder.encode(original)\n    assert encoded.dtype == np.float32\n    roundtripped = coder.decode(encoded)\n    assert_identical(original, roundtripped)\n    assert roundtripped.dtype == np.float32\n"], "sample_82": ["def test_selectdate_empty_label_placeholder(self):\n    w = SelectDateWidget(years=('2014',), empty_label=('empty_year', 'empty_month', 'empty_day'))\n    self.check_html(w, 'mydate', '', html=(\n        \"\"\"\n        <select name=\"mydate_month\" id=\"id_mydate_month\">\n            <option selected value=\"\">empty_month</option>\n            <option value=\"1\">January</option>\n            <option value=\"2\">February</option>\n            <option value=\"3\">March</option>\n            <option value=\"4\">April</option>\n            <option value=\"5\">May</option>\n            <option value=\"6\">June</option>\n            <option value=\"7\">July</option>\n            <option value=\"8\">August</option>\n            <option value=\"9\">September</option>\n            <option value=\"10\">October</option>\n            <option value=\"11\">November</option>\n            <option value=\"12\">December</option>\n        </select>\n\n        <select name=\"mydate_day\" id=\"id_mydate_day\">\n            <option selected value=\"\">empty_day</option>\n            <option value=\"1\">1</option>\n            <option value=\"2\">2</option>\n            <option value=\"3\">3</option>\n            <option value=\"4\">4</option>\n            <option value=\"5\">5</option>\n            <option value=\"6\">6</option>\n            <option value=\"7\">7</option>\n            <option value=\"8\">8</option>\n            <option value=\"9\">9</option>\n            <option value=\"10\">10</option>\n            <option value=\"11\">11</option>\n            <option value=\"12\">12</option>\n            <option value=\"13\">13</option>\n            <option value=\"14\">14</option>\n            <option value=\"15\">15</option>\n            <option value=\"16\">16</option>\n            <option value=\"17\">17</option>\n            <option value=\"18\">18</option>\n            <option value=\"19\">19</option>\n            <option value=\"20\">20</option>\n            <option value=\"21\">21</option>\n            <option value=\"22\">22</option>\n            <option value=\"23\">23</option>\n            <option value=\"24\">24</option>\n            <option value"], "sample_136": ["    def test_querydict_fromkeys(self):\n        q = QueryDict.fromkeys(['key1', 'key2', 'key3'], 'value')\n        self.assertEqual(q, {'key1': ['value'], 'key2': ['value'], 'key3': ['value']})\n"], "sample_0": ["def test_repr(UncertClass):\n    fake_uncert = UncertClass([1, 2, 3])\n    assert repr(fake_uncert) == 'FakeUncertainty([1, 2, 3])'\n    fake_uncert = UncertClass([1, 2, 3], unit=u.adu)\n    assert repr(fake_uncert) == 'FakeUncertainty([1, 2, 3])'\n    fake_uncert = UncertClass([1, 2, 3], unit=u.adu, copy=False)\n    assert repr(fake_uncert) == 'FakeUncertainty([1, 2, 3])'\n    fake_uncert = UncertClass([1, 2, 3], unit=u.adu, copy=False)\n    assert repr(fake_uncert) == 'FakeUncertainty([1, 2, 3])'\n"], "sample_639": ["def test_base_checker_consistency() -> None:\n    \"\"\"Test that the consistency of msgid is checked.\"\"\"\n    basic = OtherBasicChecker()\n    basic.msgs = {\n        \"W0001\": (\n            \"Basic checker has an example.\",\n            \"basic-checker-example\",\n            \"Used nowhere and serves no purpose.\",\n        ),\n        \"W0002\": (\n            \"Basic checker has another example.\",\n            \"basic-checker-another-example\",\n            \"Used nowhere and serves no purpose.\",\n        ),\n    }\n    basic.check_consistency()\n\n    # Test that the check_consistency method raises an InvalidMessageError\n    # when the checker id in the messages are not always the same.\n    basic.msgs = {\n        \"W0001\": (\n            \"Basic checker has an example.\",\n            \"basic-checker-example\",\n            \"Used nowhere and serves no purpose.\",\n        ),\n        \"W0003\": (\n            \"Basic checker has another example.\",\n            \"basic-checker-another-example\",\n            \"Used nowhere and serves no purpose.\",\n        ),\n    }\n    with pytest.raises(InvalidMessageError):\n        basic.check_consistency()\n\n    # Test that the check_consistency method raises an InvalidMessageError\n    # when the msgid is not a string of len 4.\n    basic.msgs = {\n        \"W0001\": (\n            \"Basic checker has an example.\",\n            \"basic-checker-example\",\n            \"Used nowhere and serves no purpose.\",\n        ),\n        \"W0002\": (\n            \"Basic checker has another example.\",\n            \"basic-checker-another-example\",\n            \"Used nowhere and serves no purpose.\",\n        ),\n        \"W0003\": (\n            \"Basic checker has another example.\",\n            \"basic-checker-another-example\",\n            \"Used nowhere and serves no purpose.\",\n        ),\n    }\n    with pytest.raises(InvalidMessageError):\n        basic.check_consistency()\n\n    # Test that the check_consistency method raises an InvalidMessageError\n    # when the msgid is not a string of len 4.\n    basic.msgs = {\n        \"W0001\": (\n            \"Basic checker has an example.\",\n            \"basic-checker-example\",\n            \"Used nowhere and serves no purpose.\",\n        ),\n        \"W0002\": (\n            \"Basic checker has another example.\",\n            \"basic-checker-another-example\",\n            \"Used nowhere and serves no purpose.\",\n        ),\n        \"W000\": (\n            \"Basic checker has another example.\",\n            \"basic-checker-an"], "sample_1001": ["def test_latex_Dict():\n    d = {Rational(1): 1, x**2: 2, x: 3, x**3: 4}\n    assert latex(d) == r'\\left \\{ 1 : 1, \\quad x : 3, \\quad x^{2} : 2, \\quad x^{3} : 4\\right \\}'\n    D = Dict(d)\n    assert latex(D) == r'\\left \\{ 1 : 1, \\quad x : 3, \\quad x^{2} : 2, \\quad x^{3} : 4\\right \\}'\n"], "sample_274": ["    def test_modelform(self):\n        # Create choices for the model choice field tests below.\n        ChoiceModel.objects.create(pk=1, name='a')\n        ChoiceModel.objects.create(pk=2, name='b')\n        ChoiceModel.objects.create(pk=3, name='c')\n\n        # ModelForm\n        class TestModelForm(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = ('name',)\n\n            name = ModelChoiceField(queryset=ChoiceModel.objects.all(), error_messages={\n                'required': 'REQUIRED',\n                'invalid_choice': 'INVALID CHOICE',\n            })\n\n        e = {'name': 'REQUIRED'}\n        f = TestModelForm({'name': ''})\n        self.assertFormErrors(e, f.clean)\n\n        e = {'name': 'INVALID CHOICE'}\n        f = TestModelForm({'name': '4'})\n        self.assertFormErrors(e, f.clean)\n\n        # ModelForm with ModelMultipleChoiceField\n        class TestModelForm(ModelForm):\n            class Meta:\n                model = ChoiceModel\n                fields = ('name',)\n\n            name = ModelMultipleChoiceField(queryset=ChoiceModel.objects.all(), error_messages={\n                'required': 'REQUIRED',\n                'invalid_choice': '%(value)s IS INVALID CHOICE',\n                'invalid_list': 'NOT A LIST OF VALUES',\n            })\n\n        e = {'name': 'REQUIRED'}\n        f = TestModelForm({'name': ''})\n        self.assertFormErrors(e, f.clean)\n\n        e = {'name': 'NOT A LIST OF VALUES'}\n        f = TestModelForm({'name': '3'})\n        self.assertFormErrors(e, f.clean)\n\n        e = {'name': '3 IS INVALID CHOICE'}\n        f = TestModelForm({'name': ['3']})\n        self.assertFormErrors(e, f.clean)\n"], "sample_562": ["def test_set_linestyle_with_invalid_onoffseq():\n    line = mlines.Line2D([], [])\n    with pytest.raises(ValueError):\n        line.set_linestyle((0, (1, 2, 3, 4, 5)))\n"], "sample_817": ["def test_threshold_zero():\n    # Test VarianceThreshold with threshold set to zero.\n    for X in [data, csr_matrix(data), csc_matrix(data), bsr_matrix(data)]:\n        sel = VarianceThreshold(threshold=0.).fit(X)\n        assert_array_equal([0, 1, 2, 3, 4], sel.get_support(indices=True))\n\n    assert_raises(ValueError, VarianceThreshold(threshold=0.).fit, [[0, 1, 2, 3]])\n    assert_raises(ValueError, VarianceThreshold(threshold=0.).fit, [[0, 1], [0, 1]])\n"], "sample_263": ["    def test_dumpdata_with_natural_primary_keys_and_foreign_keys(self):\n        management.call_command('loaddata', 'fixture1.json', verbosity=0)\n        self._dumpdata_assert(\n            ['fixtures'],\n            '[{\"model\": \"fixtures.category\", \"fields\": {\"description\": \"Latest news stories\", \"title\": \"News Stories\"}}, '\n            '{\"model\": \"fixtures.article\", \"fields\": {\"headline\": \"Poker on TV is great!\", \"pub_date\": \"2006-06-16T11:00:00\"}}, '\n            '{\"model\": \"fixtures.article\", \"fields\": {\"headline\": \"Copyright is fine the way it is\", \"pub_date\": \"2006-06-16T14:00:00\"}}, '\n            '{\"model\": \"fixtures.article\", \"fields\": {\"headline\": \"Django conquers world!\", \"pub_date\": \"2006-06-16T15:00:00\"}}, '\n            '{\"model\": \"fixtures.article\", \"fields\": {\"headline\": \"XML identified as leading cause of cancer\", \"pub_date\": \"2006-06-16T16:00:00\"}}, '\n            '{\"model\": \"fixtures.tag\", \"fields\": {\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"copyright\", \"tagged_id\": 3}}, '\n            '{\"model\": \"fixtures.tag\", \"fields\": {\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"legal\", \"tagged_id\": 3}}, '\n            '{\"model\": \"fixtures.tag\", \"fields\": {\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"django\", \"tagged_id\": 4}}, '\n            '{\"model\": \"fixtures.tag\", \"fields\": {\"tagged_type\": [\"fixtures\", \"article\"], \"name\": \"world domination\", \"tagged_id\": 4}}, '\n            '{\"model\": \"fixtures.person\", \"fields\": {\"name\": \"Django Reinhardt\"}}, '\n            '{\"model\": \"fixtures.person\", \"fields\": {\"name\": \"Stephane Grappelli\"}}, '\n            '{\"model\": \"fixtures.person\", \"fields\": {\"name\": \"Artist formerly known as \\\"Prince\\\"\"}}, '\n            '{\"model\": \"fixtures.visa\", \"fields\": {\"person\": [\"Django Reinhardt\"], \"permissions\": [[\"add_user\", \""], "sample_1107": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((0, 1, 2, 3))) == [(0, 1, 2, 3), (0, -1, 2, 3), (0, 1, -2, 3), (0, -1, -2, 3), (0, 1, 2, -3), (0, -1, 2, -3), (0, 1, -2, -3), (0, -1, -2, -3), (1, 0, 2, 3), (1, 0, -2, 3), (1, 0, 2, -3), (1, 0, -2, -3), (1, -0, 2, 3), (1, -0, -2, 3), (1, -0, 2, -3), (1, -0, -2, -3), (-1, 0, 2, 3), (-1, 0, -2, 3), (-1, 0, 2, -3), (-1, 0, -2, -3), (-1, -0, 2, 3), (-1, -0, -2, 3), (-1, -0, 2, -3), (-1, -0, -2, -3), (2, 0, 1, 3), (2, 0, -1, 3), (2, 0, 1, -3), (2, 0, -1, -3), (2, -0, 1, 3), (2, -0, -1, 3), (2, -0, 1, -3), (2, -0, -1, -3), (-2, 0, 1, 3), (-2, 0, -1, 3), (-2, 0, 1, -3), (-2, 0, -"], "sample_264": ["def test_max_cookie_length_empty(self):\n    \"\"\"\n    If the data exceeds what is allowed in a cookie, an empty list is returned\n    by the ``update`` method.\n    \"\"\"\n    storage = self.get_storage()\n    response = self.get_response()\n\n    # When storing as a cookie, the cookie has constant overhead of approx\n    # 54 chars, and each message has a constant overhead of about 37 chars\n    # and a variable overhead of zero in the best case. We aim for a message\n    # size which will fit 0 messages into the cookie, but not 1.\n    # See also FallbackTest.test_session_fallback\n    msg_size = int((CookieStorage.max_cookie_size - 54) / 37)\n    first_msg = None\n    # Generate the same (tested) content every time that does not get run\n    # through zlib compression.\n    random.seed(42)\n    for i in range(1):\n        msg = get_random_string(msg_size)\n        storage.add(constants.INFO, msg)\n        if i == 0:\n            first_msg = msg\n    unstored_messages = storage.update(response)\n\n    self.assertEqual(unstored_messages, [])\n"], "sample_1039": ["def test_print_assoc_op():\n    mml = mpp._print(x + y)\n    assert mml.nodeName == 'mrow'\n    assert mml.childNodes[0].nodeName == 'mi'\n    assert mml.childNodes[0].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[1].nodeName == 'mo'\n    assert mml.childNodes[1].childNodes[0].nodeValue == '+'\n    assert mml.childNodes[2].nodeName == 'mi'\n    assert mml.childNodes[2].childNodes[0].nodeValue == 'y'\n\n    mml = mpp._print(x - y)\n    assert mml.nodeName == 'mrow'\n    assert mml.childNodes[0].nodeName == 'mi'\n    assert mml.childNodes[0].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[1].nodeName == 'mo'\n    assert mml.childNodes[1].childNodes[0].nodeValue == '-'\n    assert mml.childNodes[2].nodeName == 'mi'\n    assert mml.childNodes[2].childNodes[0].nodeValue == 'y'\n\n    mml = mpp._print(x * y)\n    assert mml.nodeName == 'mrow'\n    assert mml.childNodes[0].nodeName == 'mn'\n    assert mml.childNodes[0].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[1].nodeName == 'mo'\n    assert mml.childNodes[1].childNodes[0].nodeValue == '&InvisibleTimes;'\n    assert mml.childNodes[2].nodeName == 'mi'\n    assert mml.childNodes[2].childNodes[0].nodeValue == 'y'\n\n    mml = mpp._print(x / y)\n    assert mml.nodeName == 'mfrac'\n    assert mml.childNodes[0].nodeName == 'mi'\n    assert mml.childNodes[0].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[1].nodeName == 'mi'\n    assert mml.childNodes[1].childNodes[0].nodeValue == 'y'\n\n    mml = mpp._print(x ** y)\n    assert mml.nodeName == 'msup'\n    assert mml.childNodes[0].nodeName == 'mi'\n    assert mml.childNodes[0].childNodes[0].nodeValue == 'x'\n    assert mml.childNodes[1].nodeName == 'mi'\n    assert mml.childNodes[1].childNodes[0].nodeValue == 'y'\n\n    mml"], "sample_534": ["def test_contour_label_font_properties():\n    # Test that label font properties are correctly set\n    x, y = np.meshgrid(np.arange(0, 10), np.arange(0, 10))\n    z = np.max(np.dstack([abs(x), abs(y)]), 2)\n\n    fig, ax = plt.subplots()\n    cs = ax.contour(x, y, z)\n    cs.clabel(fontsize='xx-large', use_clabeltext=True)\n\n    for label in cs.labelTexts:\n        assert label.get_fontproperties().get_size() == 24\n        assert label.get_fontproperties().get_family() == 'sans-serif'\n        assert label.get_fontproperties().get_style() == 'normal'\n        assert label.get_fontproperties().get_variant() == 'normal'\n        assert label.get_fontproperties().get_weight() == 'normal'\n        assert label.get_fontproperties().get_stretch() == 'normal'\n        assert label.get_fontproperties().get_underline() == False\n        assert label.get_fontproperties().get_overline() == False\n        assert label.get_fontproperties().get_oblique() == False\n"], "sample_197": ["def test_zero_depth(self):\n    \"\"\" Test timesince and timeuntil with depth 0. \"\"\"\n    self.assertEqual(timesince(self.t, self.t, depth=0), '')\n    self.assertEqual(timeuntil(self.t, self.t, depth=0), '')\n    self.assertEqual(timesince(self.t, self.t + self.oneminute, depth=0), '')\n    self.assertEqual(timeuntil(self.t, self.t - self.oneminute, depth=0), '')\n    self.assertEqual(timesince(self.t, self.t + self.oneday, depth=0), '')\n    self.assertEqual(timeuntil(self.t, self.t - self.oneday, depth=0), '')\n"], "sample_145": ["    def test_prepopulated_fields_with_non_existent_field(self):\n        class TestModelAdmin(ModelAdmin):\n            prepopulated_fields = {'slug': ('non_existent_field',)}\n\n        self.assertIsInvalid(\n            TestModelAdmin, ValidationTestModel,\n            \"The value of 'prepopulated_fields[\\\"slug\\\"][0]' refers to 'non_existent_field', \"\n            \"which is not an attribute of 'modeladmin.ValidationTestModel'.\",\n            'admin.E030'\n        )\n"], "sample_650": ["def test_log_auto_indent(pytester: Pytester) -> None:\n    pytester.makepyfile(\n        \"\"\"\n        import logging\n\n        logger = logging.getLogger(__name__)\n\n            logger.info('text going to logger from call')\n            assert False\n        \"\"\"\n    )\n    result = pytester.runpytest(\"--log-level=INFO\", \"--log-auto-indent=on\")\n    assert result.ret == 1\n    result.stdout.fnmatch_lines(\n        [\n            \"*-- Captured log call --*\",\n            \"    text going to logger from call\",\n        ]\n    )\n"], "sample_713": ["def test_ridge_solver_switch():\n    # Test that solver switch works as expected\n    X = np.eye(3)\n    y = np.ones(3)\n    ridge = Ridge(solver='auto')\n    ridge.fit(X, y)\n    assert_equal(ridge.solver, 'cholesky')\n\n    ridge = Ridge(solver='cholesky')\n    ridge.fit(X, y)\n    assert_equal(ridge.solver, 'cholesky')\n\n    ridge = Ridge(solver='sparse_cg')\n    ridge.fit(X, y)\n    assert_equal(ridge.solver, 'sparse_cg')\n\n    ridge = Ridge(solver='lsqr')\n    ridge.fit(X, y)\n    assert_equal(ridge.solver, 'lsqr')\n\n    ridge = Ridge(solver='sag')\n    ridge.fit(X, y)\n    assert_equal(ridge.solver, 'sag')\n\n    ridge = Ridge(solver='saga')\n    ridge.fit(X, y)\n    assert_equal(ridge.solver, 'saga')\n\n    ridge = Ridge(solver='svd')\n    ridge.fit(X, y)\n    assert_equal(ridge.solver, 'svd')\n\n    # Test that solver switch works with sample weights\n    ridge = Ridge(solver='auto')\n    ridge.fit(X, y, sample_weight=np.ones(3))\n    assert_equal(ridge.solver, 'cholesky')\n\n    ridge = Ridge(solver='cholesky')\n    ridge.fit(X, y, sample_weight=np.ones(3))\n    assert_equal(ridge.solver, 'cholesky')\n\n    ridge = Ridge(solver='sparse_cg')\n    ridge.fit(X, y, sample_weight=np.ones(3))\n    assert_equal(ridge.solver, 'sparse_cg')\n\n    ridge = Ridge(solver='lsqr')\n    ridge.fit(X, y, sample_weight=np.ones(3))\n    assert_equal(ridge.solver, 'lsqr')\n\n    ridge = Ridge(solver='sag')\n    ridge.fit(X, y, sample_weight=np.ones(3))\n    assert_equal(ridge.solver, 'sag')\n\n    ridge = Ridge(solver='saga')\n    ridge.fit(X, y, sample_weight=np.ones(3))\n    assert_equal(ridge.solver, 'saga')\n\n    ridge = Ridge(solver='svd')\n    ridge.fit(X, y, sample_weight=np.ones(3))\n    assert_equal(ridge.solver, 'svd')\n"], "sample_461": ["    def test_urlfield_clean_empty_scheme(self):\n        f = URLField(assume_scheme=None)\n        msg = \"'Enter a valid URL.'\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            f.clean(\"example.com\")\n        f = URLField(assume_scheme=\"\")\n        msg = \"'Enter a valid URL.'\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            f.clean(\"example.com\")\n        f = URLField(assume_scheme=\"\")\n        msg = \"'Enter a valid URL.'\"\n        with self.assertRaisesMessage(ValidationError, msg):\n            f.clean(\"example.com\")\n"], "sample_442": ["    def test_timestamp_signer_max_age(self):\n        \"\"\"TimestampSigner should raise SignatureExpired if max_age is exceeded\"\"\"\n        value = \"hello\"\n        with freeze_time(123456789):\n            signer = signing.TimestampSigner(key=\"predictable-key\")\n            ts = signer.sign(value)\n            self.assertNotEqual(ts, signing.Signer(key=\"predictable-key\").sign(value))\n            self.assertEqual(signer.unsign(ts), value)\n\n        with freeze_time(123456800):\n            with self.assertRaises(signing.SignatureExpired):\n                signer.unsign(ts, max_age=10)\n\n        with freeze_time(123456800):\n            with self.assertRaises(signing.SignatureExpired):\n                signer.unsign(ts, max_age=datetime.timedelta(seconds=10))\n\n        with freeze_time(123456800):\n            self.assertEqual(signer.unsign(ts, max_age=12), value)\n            self.assertEqual(\n                signer.unsign(ts, max_age=datetime.timedelta(seconds=11)), value\n            )\n"], "sample_565": ["def test_inset_axes_invalid_bbox_to_anchor():\n    fig, ax = plt.subplots(figsize=[5, 4])\n\n    # prepare the demo image\n    # Z is a 15x15 array\n    Z = cbook.get_sample_data(\"axes_grid/bivariate_normal.npy\")\n    extent = (-3, 4, -4, 3)\n    Z2 = np.zeros((150, 150))\n    ny, nx = Z.shape\n    Z2[30:30+ny, 30:30+nx] = Z\n\n    ax.imshow(Z2, extent=extent, interpolation=\"nearest\",\n              origin=\"lower\")\n\n    # creating our inset axes with a bbox_transform parameter\n    with pytest.raises(ValueError):\n        inset_axes(ax, width=1., height=1.2, bbox_to_anchor=(200, 100),\n                   loc=3, borderpad=0, bbox_transform=ax.transAxes)\n\n    with pytest.raises(ValueError):\n        inset_axes(ax, width=1., height=1.2, bbox_to_anchor=(200, 100),\n                   loc=3, borderpad=0, bbox_transform=ax.transAxes,\n                   width=\"40%\")\n\n    with pytest.raises(ValueError):\n        inset_axes(ax, width=1., height=1.2, bbox_to_anchor=(200, 100),\n                   loc=3, borderpad=0, bbox_transform=ax.transAxes,\n                   height=\"30%\")\n"], "sample_394": ["    def setUpTestData(cls):\n        cls.superuser = User.objects.create_superuser(\n            username=\"super\", password=\"secret\", email=\"super@example.com\"\n        )\n        cls.s1 = Section.objects.create(name=\"Test section\")\n        cls.a1 = Article.objects.create(\n            content=\"<p>Middle content</p>\",\n            date=datetime.datetime(2008, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.a2 = Article.objects.create(\n            content=\"<p>Oldest content</p>\",\n            date=datetime.datetime(2000, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.a3 = Article.objects.create(\n            content=\"<p>Newest content</p>\",\n            date=datetime.datetime(2009, 3, 18, 11, 54, 58),\n            section=cls.s1,\n        )\n        cls.p1 = PrePopulatedPost.objects.create(\n            title=\"A Long Title\", published=True, slug=\"a-long-title\"\n        )\n"], "sample_1205": ["def test_PolyElement_imul_num():\n    R, x = ring(\"x\", ZZ)\n\n    assert (x + 1).imul_num(3) == 3*x + 3\n    assert (x + 1).imul_num(0) == R.zero\n    assert (x + 1).imul_num(-3) == -3*x - 3\n\n    assert (x).imul_num(3) == 3*x\n    assert (x).imul_num(0) == R.zero\n    assert (x).imul_num(-3) == -3*x\n\n    assert R(1).imul_num(3) == 3\n    assert R(1).imul_num(0) == R.zero\n    assert R(1).imul_num(-3) == -3\n\n    assert R(0).imul_num(3) == R.zero\n    assert R(0).imul_num(0) == R.zero\n    assert R(0).imul_num(-3) == R.zero\n\n    R, x, y = ring(\"x,y\", ZZ)\n\n    assert (x + y).imul_num(3) == 3*x + 3*y\n    assert (x + y).imul_num(0) == R.zero\n    assert (x + y).imul_num(-3) == -3*x - 3*y\n\n    assert (x).imul_num(3) == 3*x\n    assert (x).imul_num(0) == R.zero\n    assert (x).imul_num(-3) == -3*x\n\n    assert (y).imul_num(3) == 3*y\n    assert (y).imul_num(0) == R.zero\n    assert (y).imul_num(-3) == -3*y\n\n    assert R(1).imul_num(3) == 3\n    assert R(1).imul_num(0) == R.zero\n    assert R(1).imul_num(-3) == -3\n\n    assert R(0).imul_num(3) == R.zero\n    assert R(0).imul_num(0) == R.zero\n    assert R(0).imul_num(-3) == R.zero\n\n    R, x, y, z = ring(\"x,y,z\", ZZ)\n\n    assert"], "sample_854": ["def test_libsvm_sparse_predict_proba():\n    # Test sparse predict_proba\n    X = sparse.csr_matrix([[1, 2], [3, 4]])\n    clf = svm.SVC(kernel='linear').fit(X, [0, 1])\n    assert_array_equal(clf.predict_proba(X), [[0.5, 0.5], [0, 1]])\n    assert_array_equal(clf.predict_log_proba(X), [[-0.693147, -0.693147], [-inf, 0]])\n"], "sample_642": ["def test_preprocess_options() -> None:\n    \"\"\"Test that we correctly preprocess options.\"\"\"\n    with tempdir() as chroot:\n        with fake_home():\n            chroot_path = Path(chroot)\n            testutils.create_files([\"a/b/c/d/__init__.py\"])\n            os.chdir(chroot_path / \"a/b/c\")\n            with pytest.raises(SystemExit):\n                Run([\"--init-hook\", \"import os\"])\n            assert _preprocess_options(Run([]), [\"--init-hook\", \"import os\"]) == []\n            with pytest.raises(SystemExit):\n                Run([\"--rcfile\", \"non-existent-file\"])\n            assert _preprocess_options(Run([]), [\"--rcfile\", \"non-existent-file\"]) == []\n            with pytest.raises(SystemExit):\n                Run([\"--output\", \"non-existent-file\"])\n            assert _preprocess_options(Run([]), [\"--output\", \"non-existent-file\"]) == []\n            with pytest.raises(SystemExit):\n                Run([\"--load-plugins\", \"non-existent-plugin\"])\n            assert _preprocess_options(Run([]), [\"--load-plugins\", \"non-existent-plugin\"]) == []\n            with pytest.raises(SystemExit):\n                Run([\"--verbose\", \"value\"])\n            assert _preprocess_options(Run([]), [\"--verbose\", \"value\"]) == []\n            with pytest.raises(SystemExit):\n                Run([\"-v\", \"value\"])\n            assert _preprocess_options(Run([]), [\"-v\", \"value\"]) == []\n            with pytest.raises(SystemExit):\n                Run([\"--enable-all-extensions\", \"value\"])\n            assert _preprocess_options(Run([]), [\"--enable-all-extensions\", \"value\"]) == []\n"], "sample_235": ["    def setUp(self):\n        self.notified = []\n"], "sample_353": ["    def setUp(self):\n        self.group = Group.objects.create(name='mygroup')\n        self.email = Email.objects.create(email='mymail@gmail.com')\n"], "sample_1014": ["def test_indexed_base():\n    from sympy.abc import x, y, z\n    M = ImmutableDenseNDimArray([[x, y], [z, x*y]])\n    A = IndexedBase(\"A\", (2, 2))\n    assert A[0, 0].subs(A, M) == x\n    assert A[0, 1].subs(A, M) == y\n    assert A[1, 0].subs(A, M) == z\n    assert A[1, 1].subs(A, M) == x*y\n\n    assert A[0, 0].subs({A[0, 0]: 1}) == 1\n    assert A[0, 1].subs({A[0, 1]: 2}) == 2\n    assert A[1, 0].subs({A[1, 0]: 3}) == 3\n    assert A[1, 1].subs({A[1, 1]: 4}) == 4\n\n    assert A[0, 0].subs({A[0, 0]: 1, A[1, 1]: 4}) == 1\n    assert A[0, 1].subs({A[0, 0]: 1, A[1, 1]: 4}) == y\n    assert A[1, 0].subs({A[0, 0]: 1, A[1, 1]: 4}) == z\n    assert A[1, 1].subs({A[0, 0]: 1, A[1, 1]: 4}) == 4\n\n    raises(ValueError, lambda: A[0, 3])\n    raises(ValueError, lambda: A[0, -1])\n    raises(ValueError, lambda: A[3, 0])\n    raises(ValueError, lambda: A[-1, 0])\n\n    raises(ValueError, lambda: A[0, 3])\n    raises(ValueError, lambda: A[0, -1])\n    raises(ValueError, lambda: A[3, 0])\n    raises(ValueError, lambda: A[-1, 0])\n"], "sample_1189": ["def test_lambdify_with_numpy_array():\n    if not numpy:\n        skip(\"numpy not installed\")\n    a = numpy.array([1, 2, 3])\n    f = lambdify(x, x**2)\n    assert numpy.allclose(f(a), a**2)\n"], "sample_258": ["def test_disconnect_multiple_uids(self):\n        pass\n\n        pass\n\n        pass\n\n    a_signal.connect(uid_based_receiver_1, dispatch_uid=\"uid1\")\n    a_signal.connect(uid_based_receiver_2, dispatch_uid=\"uid2\")\n    a_signal.connect(uid_based_receiver_3, dispatch_uid=\"uid1\")\n    self.assertEqual(len(a_signal.receivers), 2)\n    a_signal.disconnect(dispatch_uid=\"uid1\")\n    self.assertEqual(len(a_signal.receivers), 1)\n    a_signal.disconnect(dispatch_uid=\"uid2\")\n    self.assertTestIsClean(a_signal)\n"], "sample_229": ["def test_difference_with_distinct(self):\n    qs1 = Number.objects.filter(num__lt=10).distinct()\n    qs2 = Number.objects.filter(num__lt=9)\n    self.assertNumbersEqual(qs1.difference(qs2), [9], ordered=False)\n"], "sample_879": ["def test_one_hot_encoder_handle_unknown_strings_sparse():\n    \"\"\"Check the ignore option, when categories are numpy string dtype\n    particularly when the known category strings are larger than the unknown\n    category strings, with sparse output.\"\"\"\n    X = np.array([\"11111111\", \"22\", \"333\", \"4444\"]).reshape((-1, 1))\n    X2 = np.array([\"55555\", \"22\"]).reshape((-1, 1))\n    # Non Regression test for the issue #12470\n    # Test the ignore option, when categories are numpy string dtype\n    # particularly when the known category strings are larger than the unknown\n    # category strings\n    oh = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n    oh.fit(X)\n    X2_passed = X2.copy()\n    assert_array_equal(\n        oh.transform(X2_passed).toarray(),\n        np.array([[0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]]),\n    )\n    # ensure transformed data was not modified in place\n    assert_array_equal(X2, X2_passed)\n"], "sample_350": ["def test_difference_with_values_list_and_order_by_alias(self):\n    ReservedName.objects.create(name='rn1', order=2)\n    qs1 = ReservedName.objects.all()\n    qs2 = ReservedName.objects.none()\n    reserved_name = qs1.difference(qs2).values('name', 'order', 'id').order_by('name').get()\n    self.assertEqual(reserved_name['name'], 'rn1')\n    self.assertEqual(reserved_name['order'], 2)\n    reserved_name = qs1.difference(qs2).values_list('name', 'order', 'id').order_by('name').get()\n    self.assertEqual(reserved_name[:2], ('rn1', 2))\n"], "sample_977": ["def test_Sum():\n    assert mcode(Sum(sin(x), (x, 0, 10))) == \"Hold[Sum[Sin[x], {x, 0, 10}]\"\n"], "sample_173": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_819": ["def test_transform_multiclass():\n    \"\"\"Check transform method of VotingClassifier on multiclass dataset.\"\"\"\n    clf1 = LogisticRegression(random_state=123, multi_class='ovr')\n    clf2 = RandomForestClassifier(random_state=123)\n    clf3 = GaussianNB()\n    X = np.array([[-1.1, -1.5], [-1.2, -1.4], [-3.4, -2.2], [1.1, 1.2]])\n    y = np.array([1, 2, 3, 2])\n\n    eclf1 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft').fit(X, y)\n    eclf2 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft',\n        flatten_transform=True).fit(X, y)\n    eclf3 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft',\n        flatten_transform=False).fit(X, y)\n\n    assert_array_equal(eclf1.transform(X).shape, (4, 6))\n    assert_array_equal(eclf2.transform(X).shape, (4, 6))\n    assert_array_equal(eclf3.transform(X).shape, (3, 4, 3))\n    assert_array_almost_equal(eclf1.transform(X),\n                              eclf2.transform(X))\n    assert_array_almost_equal(\n            eclf3.transform(X).swapaxes(0, 1).reshape((4, 6)),\n            eclf2.transform(X)\n    )\n"], "sample_1052": ["def test_c_with_printer():\n    #issue 13586\n    from sympy.printing.ccode import C99CodePrinter\n    class CustomPrinter(C99CodePrinter):\n            return \"fastpow({}, {})\".format(self._print(expr.base),\n                                            self._print(expr.exp))\n\n    x, y = symbols('x y')\n    expr = x**y\n\n    # replace math.h with a different header\n    gen = C99CodeGen(printer=CustomPrinter())\n\n    expected = (\n        '#include \"expr.h\"\\n'\n        '#include <math.h>\\n'\n        'double expr(double x, double y) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastpow(x, y);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n\n    result = codegen(('expr', expr), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    assert source == expected\n\n    # use both math.h and an external header\n    gen = C99CodeGen()\n    gen.preprocessor_statements.append('#include \"fastexp.h\"')\n\n    expected = (\n        '#include \"expr.h\"\\n'\n        '#include <math.h>\\n'\n        '#include \"fastexp.h\"\\n'\n        'double expr(double x, double y) {\\n'\n        '   double expr_result;\\n'\n        '   expr_result = fastpow(x, y);\\n'\n        '   return expr_result;\\n'\n        '}\\n'\n    )\n\n    result = codegen(('expr', expr), header=False, empty=False, code_gen=gen)\n    source = result[0][1]\n    assert source == expected\n"], "sample_134": ["def test_serialize_deconstructible_instances(self):\n    \"\"\"\n    Test serialization of deconstructible instances.\n    \"\"\"\n    self.assertSerializedEqual(DeconstructibleInstances())\n    self.assertSerializedEqual(DeconstructibleInstances())\n    self.assertSerializedResultEqual(\n        DeconstructibleInstances(),\n        (\"migrations.test_writer.DeconstructibleInstances()\", {'import migrations.test_writer'})\n    )\n"], "sample_295": ["    def setUpTestData(cls):\n        cls.max = Employee.objects.create(firstname='Max', lastname='Mustermann', salary=30)\n        cls.max2 = Employee.objects.create(firstname='Max2', lastname='Mustermann2', salary=30)\n        cls.max3 = Employee.objects.create(firstname='Max3', lastname='Mustermann3', salary=30)\n        cls.max4 = Employee.objects.create(firstname='Max4', lastname='Mustermann4', salary=30)\n        cls.max5 = Employee.objects.create(firstname='Max5', lastname='Mustermann5', salary=30)\n        cls.max6 = Employee.objects.create(firstname='Max6', lastname='Mustermann6', salary=30)\n        cls.max7 = Employee.objects.create(firstname='Max7', lastname='Mustermann7', salary=30)\n        cls.max8 = Employee.objects.create(firstname='Max8', lastname='Mustermann8', salary=30)\n        cls.max9 = Employee.objects.create(firstname='Max9', lastname='Mustermann9', salary=30)\n        cls.max10 = Employee.objects.create(firstname='Max10', lastname='Mustermann10', salary=30)\n        cls.max11 = Employee.objects.create(firstname='Max11', lastname='Mustermann11', salary=30)\n        cls.max12 = Employee.objects.create(firstname='Max12', lastname='Mustermann12', salary=30)\n        cls.max13 = Employee.objects.create(firstname='Max13', lastname='Mustermann13', salary=30)\n        cls.max14 = Employee.objects.create(firstname='Max14', lastname='Mustermann14', salary=30)\n        cls.max15 = Employee.objects.create(firstname='Max15', lastname='Mustermann15', salary=30)\n        cls.max16 = Employee.objects.create(firstname='Max16', lastname='Mustermann16', salary=30)\n        cls.max17 = Employee.objects.create(firstname='Max17', lastname='Mustermann17', salary=30)\n        cls.max18 = Employee.objects.create(firstname='Max18', lastname='Mustermann18', salary=30)\n        cls.max19 = Employee.objects.create(firstname='Max19', lastname='Mustermann19', salary=30)\n        cls.max20 = Employee.objects.create(firstname='Max20', lastname='Mustermann20', salary=30)\n        cls.max21 = Employee.objects.create(firstname='Max21', lastname='Must"], "sample_891": ["def test_top_k_accuracy_score_multiclass():\n    # Test top-k accuracy score for multiclass classification\n    y_true = np.array([0, 1, 2, 2])\n    y_score = np.array(\n        [\n            [0.4, 0.3, 0.2, 0.1],\n            [0.1, 0.4, 0.3, 0.2],\n            [0.4, 0.1, 0.2, 0.3],\n            [0.3, 0.2, 0.4, 0.1],\n        ]\n    )\n    score = top_k_accuracy_score(y_true, y_score, k=2)\n    assert score == pytest.approx(0.75)\n\n    y_true = np.array([0, 1, 2, 2])\n    y_score = np.array(\n        [\n            [0.4, 0.3, 0.2, 0.1],\n            [0.1, 0.4, 0.3, 0.2],\n            [0.4, 0.1, 0.2, 0.3],\n            [0.3, 0.2, 0.4, 0.1],\n        ]\n    )\n    score = top_k_accuracy_score(y_true, y_score, k=3)\n    assert score == pytest.approx(1.0)\n\n    y_true = np.array([0, 1, 2, 2])\n    y_score = np.array(\n        [\n            [0.4, 0.3, 0.2, 0.1],\n            [0.1, 0.4, 0.3, 0.2],\n            [0.4, 0.1, 0.2, 0.3],\n            [0.3, 0.2, 0.4, 0.1],\n        ]\n    )\n    score = top_k_accuracy_score(y_true, y_score, k=4)\n    assert score == pytest.approx(1.0)\n\n    y_true = np.array([0, 1, 2, 2])\n    y_score = np.array(\n        [\n            [0.4, 0.3, 0.2, 0.1],\n            ["], "sample_1042": ["def test_IndexedBase_shape_precedence():\n    i, j = symbols('i j', integer=True)\n    o, p = symbols('o p', integer=True)\n    n, m = symbols('n m', integer=True)\n    a = IndexedBase('a', shape=(o, p))\n    assert Indexed(a, Idx(i, m), Idx(j, n)).ranges == [Tuple(0, m - 1), Tuple(0, n - 1)]\n    assert Indexed(a, Idx(i, m), Idx(j, n)).shape == Tuple(o, p)\n    assert Indexed(a, Idx(i, m), Idx(j)).ranges == [Tuple(0, m - 1), Tuple(None, None)]\n    assert Indexed(a, Idx(i, m), Idx(j)).shape == Tuple(o, p)\n"], "sample_120": ["def test_serialize_deconstructable_class(self):\n    \"\"\"\n    Test that a class that knows how to deconstruct can be serialized.\n    \"\"\"\n    class DeconstructableClass:\n            return ('DeconstructableClass', [], {})\n\n    string, imports = MigrationWriter.serialize(DeconstructableClass)\n    self.assertEqual(string, 'DeconstructableClass()')\n    self.assertEqual(imports, set())\n\n    class DeconstructableClassWithArgs:\n            return ('DeconstructableClassWithArgs', ['arg1', 'arg2'], {})\n\n    string, imports = MigrationWriter.serialize(DeconstructableClassWithArgs())\n    self.assertEqual(string, 'DeconstructableClassWithArgs(arg1=\"arg1\", arg2=\"arg2\")')\n    self.assertEqual(imports, set())\n\n    class DeconstructableClassWithKwargs:\n            return ('DeconstructableClassWithKwargs', [], {'kwarg1': 'kwarg1_value'})\n\n    string, imports = MigrationWriter.serialize(DeconstructableClassWithKwargs())\n    self.assertEqual(string, 'DeconstructableClassWithKwargs(kwarg1=\"kwarg1_value\")')\n    self.assertEqual(imports, set())\n\n    class DeconstructableClassWithArgsAndKwargs:\n            return ('DeconstructableClassWithArgsAndKwargs', ['arg1', 'arg2'], {'kwarg1': 'kwarg1_value'})\n\n    string, imports = MigrationWriter.serialize(DeconstructableClassWithArgsAndKwargs())\n    self.assertEqual(string, 'DeconstructableClassWithArgsAndKwargs(arg1=\"arg1\", arg2=\"arg2\", kwarg1=\"kwarg1_value\")')\n    self.assertEqual(imports, set())\n"], "sample_165": ["    def test_modelform(self):\n        class TestModel(models.Model):\n            name = models.CharField(max_length=10)\n\n        class TestForm(forms.ModelForm):\n            class Meta:\n                model = TestModel\n                fields = ('name',)\n\n        e = {\n            'required': 'REQUIRED',\n        }\n        f = TestForm({'name': ''}, error_messages=e)\n        self.assertFormErrors(['REQUIRED'], f.clean)\n\n        f = TestForm({'name': 'a' * 11}, error_messages=e)\n        self.assertFormErrors(['LENGTH 11, MAX LENGTH 10'], f.clean)\n\n        f = TestForm({'name': 'a' * 10}, error_messages=e)\n        self.assertFormErrors([], f.clean)\n\n        class TestModel(models.Model):\n            name = models.CharField(max_length=10)\n            email = models.EmailField(max_length=254)\n\n        class TestForm(forms.ModelForm):\n            class Meta:\n                model = TestModel\n                fields = ('name', 'email')\n\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'min_length': 'LENGTH %(show_value)s, MIN LENGTH %(limit_value)s',\n            'max_length': 'LENGTH %(show_value)s, MAX LENGTH %(limit_value)s',\n        }\n        f = TestForm({'name': 'a' * 11, 'email': 'a' * 255}, error_messages=e)\n        self.assertFormErrors(['LENGTH 11, MAX LENGTH 10'], f.clean)\n        self.assertFormErrors(['LENGTH 255, MAX LENGTH 254'], f.clean)\n\n        f = TestForm({'name': 'a' * 10, 'email': 'a' * 255}, error_messages=e)\n        self.assertFormErrors([], f.clean)\n\n        class TestModel(models.Model):\n            name = models.CharField(max_length=10)\n            email = models.EmailField(max_length=254)\n\n        class TestForm(forms.ModelForm):\n            class Meta:\n                model = TestModel\n                fields = ('name', 'email')\n\n        e = {\n            'required': 'REQUIRED',\n            'invalid': 'INVALID',\n            'min_length': 'LENGTH %(show_value)s, MIN LENGTH %(limit_value)s',\n            'max_length': 'LENGTH %(show_value)s, MAX LENGTH %(limit_value)s',\n        }\n        f = TestForm({'name': 'a'"], "sample_1018": ["def test_fcode_Indexed_with_looking_for_contraction():\n    len_y = 5\n    y = IndexedBase('y', shape=(len_y,))\n    x = IndexedBase('x', shape=(len_y,))\n    Dy = IndexedBase('Dy', shape=(len_y-1,))\n    i = Idx('i', len_y-1)\n    e=Eq(Dy[i], (y[i+1]-y[i])/(x[i+1]-x[i]))\n    code = fcode(e.rhs, assign_to=e.lhs, contract=True)\n    expected = (\n        \"do i = 1, 4\\n\"\n        \"   Dy(i) = (y(i + 1) - y(i))/(x(i + 1) - x(i))\\n\"\n        \"end do\"\n    )\n    assert code == expected\n"], "sample_381": ["def test_alter_field_with_default(self):\n    \"\"\"#23609 - Altering a field with a default should work.\"\"\"\n    changes = self.get_changes([self.author_name], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"name\", preserve_default=True)\n    self.assertOperationFieldAttributes(changes, 'testapp', 0, 0, default='Ada Lovelace')\n"], "sample_965": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n        pass\n\n    func.register(int, lambda x: x)\n\n    assert inspect.is_singledispatch_function(func) is True\n    assert inspect.is_singledispatch_function(singledispatch(func)) is True\n    assert inspect.is_singledispatch_function(object()) is False\n"], "sample_95": ["    def test_cache_control_decorator(self):\n        \"\"\"\n        Test the cache_control decorator.\n        \"\"\"\n            return HttpResponse()\n\n        my_view_cached = cache_control(private=True, max_age=123)(my_view)\n        response = my_view_cached(HttpRequest())\n        self.assertEqual(response['Cache-Control'], 'private, max-age=123')\n\n        my_view_cached = cache_control(private=True, max_age=123, no_cache=True)(my_view)\n        response = my_view_cached(HttpRequest())\n        self.assertEqual(response['Cache-Control'], 'private, max-age=123, no-cache')\n\n        my_view_cached = cache_control(private=True, max_age=123, no_store=True)(my_view)\n        response = my_view_cached(HttpRequest())\n        self.assertEqual(response['Cache-Control'], 'private, max-age=123, no-store')\n\n        my_view_cached = cache_control(private=True, max_age=123, must_revalidate=True)(my_view)\n        response = my_view_cached(HttpRequest())\n        self.assertEqual(response['Cache-Control'], 'private, max-age=123, must-revalidate')\n"], "sample_585": ["def test_groupby_quantile():\n    # test groupby with quantile for GH1132\n    # create test data\n    times = pd.date_range('2000-01-01', periods=4)\n    foo = xr.DataArray([1, 2, 3, 4], coords=dict(time=times), dims='time')\n    # create test index\n    dd = times.to_pydatetime()\n    reference_dates = [dd[0], dd[2]]\n    labels = reference_dates[0:1] * 2 + reference_dates[1:2] * 2\n    ind = xr.DataArray(labels, coords=dict(time=times), dims='time',\n                       name='reference_date')\n    g = foo.groupby(ind)\n    actual = g.quantile(0.5, dim='time')\n    expected = xr.DataArray([2, 3],\n                            coords=dict(reference_date=reference_dates),\n                            dims='reference_date')\n    assert actual.equals(expected)\n"], "sample_505": ["def test_date2num_tz():\n    # Test for github issue #3896, but in date2num with a timezone-aware\n    # datetime object.\n\n    class dt_tzaware(datetime.datetime):\n        \"\"\"\n        This bug specifically occurs because of the normalization behavior of\n        datetime objects, so in order to replicate it, we need a datetime-like\n        object that applies timezone normalization after subtraction.\n        \"\"\"\n\n            r = super().__sub__(other)\n            tzinfo = getattr(r, 'tzinfo', None)\n\n            if tzinfo is not None:\n                localizer = getattr(tzinfo, 'normalize', None)\n                if localizer is not None:\n                    r = tzinfo.normalize(r)\n\n            if isinstance(r, datetime.datetime):\n                r = self.mk_tzaware(r)\n\n            return r\n\n            return self.mk_tzaware(super().__add__(other))\n\n            dt = super().astimezone(tzinfo)\n            return self.mk_tzaware(dt)\n\n        @classmethod\n            kwargs = {}\n            attrs = ('year',\n                     'month',\n                     'day',\n                     'hour',\n                     'minute',\n                     'second',\n                     'microsecond',\n                     'tzinfo')\n\n            for attr in attrs:\n                val = getattr(datetime_obj, attr, None)\n                if val is not None:\n                    kwargs[attr] = val\n\n            return cls(**kwargs)\n\n    # Create a timezone-aware datetime object in UTC\n    dtstart = dt_tzaware(2014, 3, 30, 0, 0, tzinfo=mdates.UTC)\n\n    # Create a list of timezone-aware datetime objects in UTC\n    dt_utc = [dtstart + datetime.timedelta(minutes=33, seconds=45) for _ in range(8)]\n\n    # Convert the list to a numpy array\n    dt_utc = np.array(dt_utc)\n\n    # Convert the numpy array to Matplotlib dates\n    mdates.date2num(dt_utc)\n"], "sample_473": ["    def test_request_aborted(self):\n        handler = ASGIHandler()\n        with self.assertRaises(RequestAborted):\n            handler.handle({\"type\": \"http\", \"method\": \"GET\"}, lambda *a, **k: {\"type\": \"http.disconnect\"}, lambda *a, **k: None)\n"], "sample_782": ["def test_column_transformer_sparse_output():\n    X_array = np.array([[0, 1, 2], [2, 4, 6]]).T\n    col_trans = ColumnTransformer([('trans1', Trans(), [0]),\n                                   ('trans2', TransNo2D(), 1)],\n                                  sparse_threshold=0.8)\n    col_trans.fit(X_array)\n    X_trans = col_trans.transform(X_array)\n    assert not sparse.issparse(X_trans)\n    assert not col_trans.sparse_output_\n\n    col_trans = ColumnTransformer([('trans1', Trans(), [0]),\n                                   ('trans2', TransNo2D(), 1)],\n                                  sparse_threshold=0.1)\n    col_trans.fit(X_array)\n    X_trans = col_trans.transform(X_array)\n    assert sparse.issparse(X_trans)\n    assert col_trans.sparse_output_\n\n    col_trans = ColumnTransformer([('trans1', Trans(), [0]),\n                                   ('trans2', TransNo2D(), 1)],\n                                  sparse_threshold=0.5)\n    col_trans.fit(X_array)\n    X_trans = col_trans.transform(X_array)\n    assert sparse.issparse(X_trans)\n    assert col_trans.sparse_output_\n"], "sample_640": ["def test_is_subscriptable_pep585() -> None:\n    code = astroid.extract_node(\n        \"\"\"\n    from typing import List\n    class C(List): #@\n        pass\n    \"\"\"\n    )\n    assert utils.is_class_subscriptable_pep585_with_postponed_evaluation_enabled(code, None)\n    assert not utils.is_class_subscriptable_pep585_with_postponed_evaluation_enabled(\n        astroid.extract_node(\"class C: pass\"), None\n    )\n"], "sample_97": ["    def test_module_with_spec_without_location(self):\n        module = types.ModuleType('test_module')\n        module.__spec__ = types.ModuleSpec('test_module', None)\n        self.assertEqual(autoreload.iter_modules_and_files((module,), frozenset()), frozenset())\n"], "sample_102": ["def test_difference_with_values_list_and_order(self):\n    ReservedName.objects.create(name='rn1', order=7)\n    ReservedName.objects.create(name='rn2', order=5)\n    ReservedName.objects.create(name='rn0', order=6)\n    ReservedName.objects.create(name='rn9', order=-1)\n    qs1 = ReservedName.objects.filter(order__gte=6)\n    qs2 = ReservedName.objects.filter(order__lte=5)\n    union_qs = qs1.union(qs2)\n    for qs, expected_result in (\n        # Order by a single column.\n        (union_qs.order_by('-pk').values_list('order', flat=True), [-1, 6, 5, 7]),\n        (union_qs.order_by('pk').values_list('order', flat=True), [7, 5, 6, -1]),\n        (union_qs.values_list('order', flat=True).order_by('-pk'), [-1, 6, 5, 7]),\n        (union_qs.values_list('order', flat=True).order_by('pk'), [7, 5, 6, -1]),\n        # Order by multiple columns.\n        (union_qs.order_by('-name', 'pk').values_list('order', flat=True), [-1, 5, 7, 6]),\n        (union_qs.values_list('order', flat=True).order_by('-name', 'pk'), [-1, 5, 7, 6]),\n    ):\n        with self.subTest(qs=qs):\n            self.assertEqual(list(qs), expected_result)\n"], "sample_380": ["def test_aggregate_default_with_coalesce(self):\n    result = Publisher.objects.aggregate(\n        value=Coalesce(Sum('num_awards'), 0),\n    )\n    self.assertEqual(result['value'], 30)\n\n    result = Publisher.objects.aggregate(\n        value=Coalesce(Sum('num_awards'), None, 0),\n    )\n    self.assertEqual(result['value'], 30)\n\n    result = Publisher.objects.aggregate(\n        value=Coalesce(Coalesce(Sum('num_awards'), None), 0),\n    )\n    self.assertEqual(result['value'], 30)\n\n    result = Publisher.objects.aggregate(\n        value=Coalesce(Coalesce(Sum('num_awards'), None), None, 0),\n    )\n    self.assertEqual(result['value'], 30)\n"], "sample_596": ["def test_concat_fill_value_dict():\n    da1 = DataArray([1, 2], coords=[(\"x\", [1, 2])])\n    da2 = DataArray([1, 2], coords=[(\"x\", [1, 3])])\n    expected = DataArray(\n        [[1, 2, np.nan], [1, np.nan, 2]],\n        dims=[\"y\", \"x\"],\n        coords={\"x\": [1, 2, 3]},\n    )\n    actual = concat((da1, da2), dim=\"y\", fill_value={\"a\": np.nan, \"b\": 0})\n    assert_identical(actual, expected)\n"], "sample_1127": ["def test_coset_rank_coset_unrank():\n    a = Permutation([0, 2, 1])\n    b = Permutation([1, 0, 2])\n    G = PermutationGroup([a, b])\n    assert G.coset_rank(G[0]) == 0\n    assert G.coset_unrank(0) == G[0]\n    assert G.coset_rank(G[1]) == 1\n    assert G.coset_unrank(1) == G[1]\n    assert G.coset_rank(G[2]) == 2\n    assert G.coset_unrank(2) == G[2]\n    assert G.coset_rank(G[3]) == 3\n    assert G.coset_unrank(3) == G[3]\n    assert G.coset_rank(G[4]) == 4\n    assert G.coset_unrank(4) == G[4]\n    assert G.coset_rank(G[5]) == 5\n    assert G.coset_unrank(5) == G[5]\n    assert G.coset_rank(G[6]) == 6\n    assert G.coset_unrank(6) == G[6]\n    assert G.coset_rank(G[7]) == 7\n    assert G.coset_unrank(7) == G[7]\n    assert G.coset_rank(G[8]) == 8\n    assert G.coset_unrank(8) == G[8]\n    assert G.coset_rank(G[9]) == 9\n    assert G.coset_unrank(9) == G[9]\n    assert G.coset_rank(G[10]) == 10\n    assert G.coset_unrank(10) == G[10]\n    assert G.coset_rank(G[11]) == 11\n    assert G.coset_unrank(11) == G[11]\n    assert G.coset_rank(G[12]) == 12\n    assert G.coset_unrank(12) == G[12]\n    assert G.coset_rank(G[13]) == 13\n    assert G.coset_unrank(13) == G[13]\n    assert G.coset_rank(G[14]) == 14\n    assert G.coset_unrank(14) == G[14]\n    assert G.coset_rank(G[15]) == 15\n    assert G.coset_unrank(15) =="], "sample_960": ["def test_pydata_with_union_type_operator_old(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :annotation: int | str\")\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree[1][0],\n                ([desc_name, \"version\"],\n                 [desc_annotation, (\": \",\n                                    [pending_xref, \"int\"],\n                                    \" \",\n                                    [desc_sig_punctuation, \"|\"],\n                                    \" \",\n                                    [pending_xref, \"str\"])]))\n"], "sample_1080": ["def test_refine_Pow():\n    assert refine((-1)**x, Q.real(x)) == refine((-1)**x, True)\n    assert refine((-1)**x, Q.complex(x)) == refine((-1)**x, True)\n    assert refine((-1)**x, Q.positive(x)) == refine((-1)**x, Q.real(x))\n    assert refine((-1)**x, Q.negative(x)) == refine((-1)**x, Q.real(x))\n\n    assert refine((-1)**(x + y), Q.real(x) & Q.real(y)) == refine((-1)**(x + y), True)\n    assert refine((-1)**(x + y), Q.real(x) & Q.complex(y)) == refine((-1)**(x + y), True)\n    assert refine((-1)**(x + y), Q.real(x) & Q.positive(y)) == refine((-1)**(x + y), Q.real(x))\n    assert refine((-1)**(x + y), Q.real(x) & Q.negative(y)) == refine((-1)**(x + y), Q.real(x))\n\n    assert refine((-1)**(x + y + z), Q.real(x) & Q.real(y) & Q.real(z)) == refine((-1)**(x + y + z), True)\n    assert refine((-1)**(x + y + z), Q.real(x) & Q.real(y) & Q.complex(z)) == refine((-1)**(x + y + z), True)\n    assert refine((-1)**(x + y + z), Q.real(x) & Q.real(y) & Q.positive(z)) == refine((-1)**(x + y + z), Q.real(x) & Q.real(y))\n    assert refine((-1)**(x + y + z), Q.real(x) & Q.real(y) & Q.negative(z)) == refine((-1)**(x + y + z), Q.real(x) & Q.real(y))\n\n    assert refine((-1)**(x + y + 1), Q.real(x) & Q.real(y)) == refine((-1)**(x + y + 1), True)\n    assert refine((-1)**(x + y + 1), Q.real(x) & Q.complex(y)) == refine((-1)**(x + y + 1), True)\n    assert refine((-1)**(x + y + 1), Q.real(x)"], "sample_458": ["    def test_floatformat03(self):\n        output = self.engine.render_to_string(\n            \"floatformat03\", {\"a\": \"66666.666\", \"b\": mark_safe(\"66666.666\")}\n        )\n        self.assertEqual(output, \"66,667.00 66,667.67\")\n"], "sample_944": ["def test_restify_type_hints_Annotated():\n    from typing import Annotated  # type: ignore\n    assert restify(Annotated[int, \"foo\", \"bar\"]) == \":class:`int`\"\n\n    if sys.version_info >= (3, 9):\n        assert restify(Annotated[str, \"foo\", \"bar\"]) == \":class:`str`\"\n    else:\n        assert restify(Annotated[str, \"foo\", \"bar\"]) == \":class:`str`\"\n"], "sample_1108": ["def test_permute_signs():\n    assert list(permute_signs((0, 1, 2))) == [(0, 1, 2), (0, -1, 2), (0, 1, -2), (0, -1, -2)]\n    assert list(permute_signs((0, 1, 2, 3))) == [(0, 1, 2, 3), (0, 1, 2, -3), (0, 1, -2, 3), (0, 1, -2, -3), (0, -1, 2, 3), (0, -1, 2, -3), (0, -1, -2, 3), (0, -1, -2, -3), (1, 0, 2, 3), (1, 0, 2, -3), (1, 0, -2, 3), (1, 0, -2, -3), (1, -0, 2, 3), (1, -0, 2, -3), (1, -0, -2, 3), (1, -0, -2, -3), (2, 0, 1, 3), (2, 0, 1, -3), (2, 0, -1, 3), (2, 0, -1, -3), (2, -0, 1, 3), (2, -0, 1, -3), (2, -0, -1, 3), (2, -0, -1, -3), (2, 1, 0, 3), (2, 1, 0, -3), (2, 1, -0, 3), (2, 1, -0, -3), (2, -1, 0, 3), (2, -1, 0, -3), (2, -1, -0, 3), (2, -1, -0, -3), (3, 0, 1, 2), (3, 0, 1, -2), (3, 0, -1, 2), (3, 0, -"], "sample_560": ["def test_legend_title_fontprop_fontsize():\n    # test the title_fontsize kwarg\n    plt.plot(range(10))\n    with pytest.raises(ValueError):\n        plt.legend(title='Aardvark', title_fontsize=22,\n                   title_fontproperties={'family': 'serif', 'size': 22})\n\n    leg = plt.legend(title='Aardvark', title_fontproperties=FontProperties(\n                                       family='serif', size=22))\n    assert leg.get_title().get_size() == 22\n\n    fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n    axes = axes.flat\n    axes[0].plot(range(10))\n    leg0 = axes[0].legend(title='Aardvark', title_fontsize=22)\n    assert leg0.get_title().get_fontsize() == 22\n    axes[1].plot(range(10))\n    leg1 = axes[1].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif', 'size': 22})\n    assert leg1.get_title().get_fontsize() == 22\n    axes[2].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = None\n    leg2 = axes[2].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg2.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[3].plot(range(10))\n    leg3 = axes[3].legend(title='Aardvark')\n    assert leg3.get_title().get_fontsize() == mpl.rcParams['font.size']\n    axes[4].plot(range(10))\n    mpl.rcParams['legend.title_fontsize'] = 20\n    leg4 = axes[4].legend(title='Aardvark',\n                          title_fontproperties={'family': 'serif'})\n    assert leg4.get_title().get_fontsize() == 20\n    axes[5].plot(range(10))\n    leg5 = axes[5].legend(title='Aardvark')\n    assert leg5.get_title().get_fontsize() == 20\n"], "sample_280": ["def test_aggregation_default_using_boolean_from_python(self):\n    result = Publisher.objects.filter(num_awards__gt=3).aggregate(\n        value=Sum('book__price', default=True),\n    )\n    self.assertTrue(result['value'])\n\n    result = Publisher.objects.filter(num_awards__gt=3).aggregate(\n        value=Sum('book__price', default=False),\n    )\n    self.assertFalse(result['value'])\n\n    result = Publisher.objects.filter(num_awards__gt=3).aggregate(\n        value=Sum('book__price', default=None),\n    )\n    self.assertIsNone(result['value'])\n\n    result = Publisher.objects.filter(num_awards__gt=3).aggregate(\n        value=Sum('book__price', default=1),\n    )\n    self.assertEqual(result['value'], 1)\n\n    result = Publisher.objects.filter(num_awards__gt=3).aggregate(\n        value=Sum('book__price', default=0),\n    )\n    self.assertEqual(result['value'], 0)\n"], "sample_630": ["def test_get_annotation_annassign_listassign(assign, label):\n    \"\"\"AnnAssign\"\"\"\n    node = astroid.extract_node(assign)\n    got = get_annotation(node.value).name\n    assert isinstance(node, astroid.AnnAssign)\n    assert got == label, f\"got {got} instead of {label} for value {node}\"\n\n"], "sample_778": ["def test_nmf_solver_choice():\n    # Test that the solver choice affects the results\n    n_samples = 20\n    n_features = 10\n    n_components = 5\n    alpha = 0.1\n    l1_ratio = 0.5\n    n_iter = 20\n\n    # initialization\n    rng = np.random.mtrand.RandomState(42)\n    X = rng.randn(n_samples, n_features)\n    np.abs(X, X)\n    W0, H0 = nmf._initialize_nmf(X, n_components, init='random', random_state=42)\n\n    for solver in ('cd', 'mu'):\n        W, H = W0.copy(), H0.copy()\n        W_cd, H_cd, _ = non_negative_factorization(\n            X, W, H, n_components, init='custom', update_H=True,\n            solver=solver, beta_loss=2, max_iter=n_iter, alpha=alpha,\n            l1_ratio=l1_ratio, regularization='both', random_state=42)\n        W_mu, H_mu, _ = non_negative_factorization(\n            X, W, H, n_components, init='custom', update_H=True,\n            solver=solver, beta_loss=2, max_iter=n_iter, alpha=alpha,\n            l1_ratio=l1_ratio, regularization='both', random_state=42)\n\n        assert_array_almost_equal(W_cd, W_mu, decimal=7)\n        assert_array_almost_equal(H_cd, H_mu, decimal=7)\n\n        # Compare with almost same beta_loss, since some values have a specific\n        # behavior, but the results should be continuous w.r.t beta_loss\n        beta_loss = 2.0001\n        W, H = W0.copy(), H0.copy()\n        W_cd, H_cd, _ = non_negative_factorization(\n            X, W, H, n_components, init='custom', update_H=True,\n            solver=solver, beta_loss=beta_loss, max_iter=n_iter, alpha=alpha,\n            l1_ratio=l1_ratio, regularization='both', random_state=42)\n\n        assert_array_almost_equal(W_cd, W_mu, decimal=4)\n        assert_array_almost_equal(H_cd, H_mu, decimal=4)\n"], "sample_341": ["def test_formset_can_order_with_initial_data(self):\n    \"\"\"\n    Formsets with ordering + initial data.\n    \"\"\"\n    ChoiceFormSet = formset_factory(Choice, can_order=True)\n    initial = [{'choice': 'Calexico', 'votes': 100}, {'choice': 'Fergie', 'votes': 900}]\n    formset = ChoiceFormSet(initial=initial, auto_id=False, prefix='choices')\n    self.assertHTMLEqual(\n        '\\n'.join(form.as_ul() for form in formset.forms),\n        \"\"\"<li>Choice: <input type=\"text\" name=\"choices-0-choice\" value=\"Calexico\"></li>"], "sample_869": ["def test_balanced_accuracy_score_binary():\n    # Test balanced accuracy score for binary classification task\n    y_true, y_pred, _ = make_prediction(binary=True)\n\n    # compute balanced accuracy score\n    balanced = balanced_accuracy_score(y_true, y_pred)\n    assert_almost_equal(balanced, 0.625)\n\n    # compute balanced accuracy score with adjusted\n    balanced = balanced_accuracy_score(y_true, y_pred, adjusted=True)\n    assert_almost_equal(balanced, (0.625 - 0.5) / (1 - 0.5))\n"], "sample_208": ["def test_add_field_with_default_and_blank(self):\n    \"\"\"#22030 - Adding a field with a default and blank=True should work.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_with_biography_blank])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, 'testapp', 1)\n    self.assertOperationTypes(changes, 'testapp', 0, [\"AddField\", \"AddField\"])\n    self.assertOperationAttributes(changes, 'testapp', 0, 0, name=\"biography\")\n    self.assertOperationAttributes(changes, 'testapp', 0, 1, name=\"name\")\n"], "sample_88": ["    def test_email_message_repr(self):\n        email = EmailMessage('Subject', 'Content', 'from@example.com', ['to@example.com'])\n        self.assertEqual(repr(email), \"EmailMessage(subject='Subject', body='Content', from_email='from@example.com', to=['to@example.com'], bcc=[], cc=[], reply_to=[], headers={}, connection=None, attachments=[], extra_headers={}, encoding=None)\")\n"], "sample_509": ["def test_date_formatter_usetex():\n    style.use(\"default\")\n\n    d1 = datetime.datetime(1997, 1, 1)\n    d2 = d1 + datetime.timedelta(weeks=520)\n\n    locator = mdates.AutoDateLocator()\n    formatter = mdates.AutoDateFormatter(locator, usetex=True)\n    ax = plt.subplot()\n    ax.plot([d1, d2], [0, 0])\n    fig = plt.gcf()\n    fig.canvas.draw()\n    assert formatter.get_offset() == ''\n    assert formatter(19000.0) == r'{\\fontfamily{\\familydefault}\\selectfont 1997}'\n"], "sample_546": ["def test_figure_subplot_mosaic():\n    fig, axs = plt.subplots(2, 2)\n    fig.subplot_mosaic([[1, 2, 'edge'],\n                       [3, '.', 'edge']],\n                      sharex=True, sharey=True)\n    assert len(fig.axes) == 4\n    assert len(fig.axes[0].get_xticklabels()) == 1\n    assert len(fig.axes[1].get_xticklabels()) == 0\n    assert len(fig.axes[2].get_yticklabels()) == 1\n    assert len(fig.axes[3].get_yticklabels()) == 0\n"], "sample_1163": ["def test_issue_19627():\n    from sympy import Abs, Function\n    f = Function('f', positive=True)\n    assert Abs(f(x)) == f(x)\n    assert Abs(f(x)**2) == f(x)**2\n    assert Abs(f(x) + y) == Abs(f(x) + y)\n    assert Abs(f(x) - y) == Abs(f(x) - y)\n    assert Abs(f(x) * y) == Abs(f(x) * y)\n    assert Abs(f(x) / y) == Abs(f(x) / y)\n    assert Abs(-f(x)) == Abs(-f(x))\n"], "sample_127": ["    def setUp(self):\n        self.data = [\n            Country(name=\"United States of America\", iso_two_letter=\"US\"),\n            Country(name=\"The Netherlands\", iso_two_letter=\"NL\"),\n            Country(name=\"Germany\", iso_two_letter=\"DE\"),\n            Country(name=\"Czech Republic\", iso_two_letter=\"CZ\")\n        ]\n"], "sample_618": ["def test_polyval_datetime() -> None:\n    x = xr.DataArray(\n        np.array([1000, 2000, 3000], dtype=\"timedelta64[ns]\"), dims=\"x\"\n    )\n    coeffs = xr.DataArray([0, 1], dims=\"degree\", coords={\"degree\": [0, 1]})\n    expected = xr.DataArray(\n        [1000.0, 2000.0, 3000.0], dims=\"x\", coords={\"x\": np.timedelta64(1000, \"ns\")}\n    )\n    actual = xr.polyval(x, coeffs)\n    xr.testing.assert_allclose(actual, expected)\n"], "sample_1054": ["def test_ImageSet_iterable():\n    from sympy.abc import n\n    assert imageset(Lambda(n, n), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Naturals).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Naturals0).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Reals).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Complexes).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi), S.Integers).is_iterable\n    assert imageset(Lambda(n, n + pi"], "sample_253": ["    def setUp(self):\n        self._tempdir = tempfile.TemporaryDirectory()\n        self.tempdir = Path(self._tempdir.name).resolve(strict=True).absolute()\n        self.existing_file = self.ensure_file(self.tempdir / 'test.py')\n        self.nonexistent_file = (self.tempdir / 'does_not_exist.py').absolute()\n        self.reloader = autoreload.StatReloader()\n"], "sample_201": ["def test_legacy_hash(self):\n    \"\"\"\n    A message is properly decoded when using the legacy hash.\n    \"\"\"\n    storage = self.get_storage()\n    # Set initial data.\n    example_messages = ['test', 'me']\n    set_cookie_data(storage, example_messages)\n    # The message contains what's expected.\n    self.assertEqual(list(storage), example_messages)\n\n    # Set initial (invalid) data with legacy hash.\n    set_cookie_data(storage, example_messages, invalid=True)\n    # The message actually contains what we expect.\n    self.assertEqual(list(storage), [])\n\n    # Test that the legacy hash is used when the signer is not available.\n    with self.settings(SIGNING_BACKEND='django.core.signing.fallback.Signer'):\n        set_cookie_data(storage, example_messages, invalid=True)\n        # The message actually contains what we expect.\n        self.assertEqual(list(storage), [])\n\n    # Test that the legacy hash is used when the signer is not available and the\n    # data is empty.\n    with self.settings(SIGNING_BACKEND='django.core.signing.fallback.Signer'):\n        set_cookie_data(storage, [], invalid=True)\n        # The message actually contains what we expect.\n        self.assertEqual(list(storage), [])\n\n    # Test that the legacy hash is used when the signer is not available and the\n    # data is not empty.\n    with self.settings(SIGNING_BACKEND='django.core.signing.fallback.Signer'):\n        set_cookie_data(storage, example_messages)\n        # The message actually contains what we expect.\n        self.assertEqual(list(storage), example_messages)\n"], "sample_250": ["def test_date_format_with_leap_year(self):\n    my_birthday = datetime(2000, 2, 29, 22, 00)\n    self.assertEqual(dateformat.format(my_birthday, 'L'), 'True')\n"], "sample_988": ["def test_issue_13348():\n    assert Eq(True, 1) is S.false\n    assert Eq(False, 0) is S.false\n    assert Eq(True, 0) is S.false\n    assert Eq(False, 1) is S.false\n    assert Eq(True, True) is S.true\n    assert Eq(False, False) is S.true\n    assert Eq(True, False) is S.false\n    assert Eq(False, True) is S.false\n"], "sample_770": ["def test_davies_bouldin_score():\n    # Assert Davies-Bouldin score is 0 when there is only one cluster\n    X = [[0, 0], [1, 1], [2, 2], [3, 3], [4, 4]]\n    labels = np.array([0, 0, 0, 0, 0])\n    assert_equal(davies_bouldin_score(X, labels), 0.0)\n\n    # Assert Davies-Bouldin score is 0 when all points are in different clusters\n    X = [[0, 0], [1, 1], [2, 2], [3, 3], [4, 4]]\n    labels = np.array([0, 1, 2, 3, 4])\n    assert_equal(davies_bouldin_score(X, labels), 0.0)\n\n    # Assert Davies-Bouldin score is 0 when all points are identical\n    X = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]\n    labels = np.array([0, 0, 0, 0, 0])\n    assert_equal(davies_bouldin_score(X, labels), 0.0)\n\n    # Assert Davies-Bouldin score is 0 when all points are in the same cluster\n    X = [[0, 0], [1, 1], [2, 2], [3, 3], [4, 4]]\n    labels = np.array([0, 0, 0, 0, 0])\n    assert_equal(davies_bouldin_score(X, labels), 0.0)\n\n    # Assert Davies-Bouldin score is not 0 when points are in different clusters\n    X = [[0, 0], [1, 1], [2, 2], [3, 3], [4, 4]]\n    labels = np.array([0, 1, 2, 3, 4])\n    assert_greater(davies_bouldin_score(X, labels), 0.0)\n\n    # Assert Davies-Bouldin score is not 0 when points are in different clusters\n    # with different sizes\n    X = [[0, 0], [1, 1], [2, 2],"], "sample_918": ["def test_pydata_signature_old_value(app):\n    text = (\".. py:data:: version\\n\"\n            \"   :value: 1\\n\")\n    domain = app.env.get_domain('py')\n    doctree = restructuredtext.parse(app, text)\n    assert_node(doctree, (addnodes.index,\n                          [desc, ([desc_signature, ([desc_name, \"version\"],\n                                                    [desc_annotation, \" = 1\"])],\n                                  [desc_content, ()])]))\n    assert_node(doctree[1], addnodes.desc, desctype=\"data\",\n                domain=\"py\", objtype=\"data\", noindex=False)\n    assert 'version' in domain.objects\n    assert domain.objects['version'] == ('index', 'version', 'data')\n"], "sample_657": ["def test_parametrize_empty_parameterset_mark_name(testdir):\n    testdir.makeini(\n        \"\"\"\n    [pytest]\n    {}=skip\n    \"\"\".format(\n            EMPTY_PARAMETERSET_OPTION\n        )\n    )\n\n    config = testdir.parseconfig()\n    from _pytest.mark import pytest_configure, get_empty_parameterset_mark\n\n    pytest_configure(config)\n\n    p1 = testdir.makepyfile(\n        \"\"\"\n        import pytest\n\n        @pytest.mark.parametrize(\"empty\", [])\n            pass\n        \"\"\"\n    )\n    result = testdir.runpytest(str(p1))\n    result.stdout.fnmatch_lines(\n        [\n            \"collected 0 items / 1 errors\",\n            \"* ERROR collecting test_parametrize_empty_parameterset_mark_name.py *\",\n            \"got empty parameter set [], function test at line 3\",\n            \"*= 1 error in *\",\n        ]\n    )\n    assert result.ret == EXIT_INTERRUPTED\n"], "sample_42": ["def test_with_h0():\n    H0 = 67.4 * u.km / (u.s * u.Mpc)\n    h100 = u.with_H0(H0)\n    assert_quantity_allclose(h100[0].to_value(u.dimensionless_unscaled), 0.674)\n    assert h100[0].unit.is_equivalent(u.dimensionless_unscaled)\n    assert h100[1] is None\n"], "sample_628": ["def test_docstring_lines_that_look_like_comments_6(self):\n    stmt = astroid.extract_node(\n        '''def f():\n    \"\"\"\n    # cat\n    msitake\n    \"\"\"'''\n    )\n    with self.assertAddsMessages(\n        Message(\n            \"wrong-spelling-in-docstring\",\n            line=3,\n            args=(\n                \"msitake\",\n                \"    msitake\",\n                \"    ^^^^^^^\",\n                self._get_msg_suggestions(\"msitake\"),\n            ),\n        )\n    ):\n        self.checker.visit_functiondef(stmt)\n"], "sample_804": ["def test_one_hot_encoder_sparse_output():\n    X = np.array([[3, 2, 1], [0, 1, 1]])\n    enc = OneHotEncoder(sparse=True)\n    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):\n        X_trans = enc.fit_transform(X)\n        assert sparse.isspmatrix_csr(X_trans)\n        assert_array_equal(X_trans.toarray(), np.array([[0., 1., 0., 1., 1.],\n                                                      [1., 0., 1., 0., 1.]]))\n"], "sample_616": ["def test_polyval_datetime() -> None:\n    # GH 5285\n    x = xr.DataArray(pd.date_range(\"1970-01-01\", freq=\"s\", periods=3), dims=\"x\")\n    coeffs = xr.DataArray([0, 1], dims=\"degree\", coords={\"degree\": [0, 1]})\n    expected = xr.DataArray(\n        [0, 1e9, 2e9],\n        dims=\"x\",\n        coords={\"x\": pd.date_range(\"1970-01-01\", freq=\"s\", periods=3)},\n    )\n    actual = xr.polyval(x, coeffs)\n    xr.testing.assert_allclose(actual, expected)\n"], "sample_346": ["    def test_cache_control_decorator(self):\n        \"\"\"\n        Test cache_control decorator with different cache control options.\n        \"\"\"\n        @cache_control(private=True, max_age=3600)\n            return HttpResponse()\n\n        r = a_view(HttpRequest())\n        self.assertEqual(\n            set(r.headers['Cache-Control'].split(', ')),\n            {'max-age=3600', 'private'},\n        )\n\n        @cache_control(no_cache=True, must_revalidate=True)\n            return HttpResponse()\n\n        r = b_view(HttpRequest())\n        self.assertEqual(\n            set(r.headers['Cache-Control'].split(', ')),\n            {'max-age=0', 'must-revalidate', 'no-cache'},\n        )\n\n        @cache_control(no_store=True, public=True)\n            return HttpResponse()\n\n        r = c_view(HttpRequest())\n        self.assertEqual(\n            set(r.headers['Cache-Control'].split(', ')),\n            {'max-age=0', 'no-cache', 'no-store', 'must-revalidate', 'public'},\n        )\n"], "sample_144": ["def test_inheritance_delete_related_objects(self):\n    \"\"\"\n    Regression test for #7276: calling delete() on a model with\n    multi-table inheritance should delete the associated rows from any\n    ancestor tables, as well as any descendent objects.\n    \"\"\"\n    place1 = Place.objects.create(name=\"Guido's House of Pasta\", address='944 W. Fullerton')\n    place1.save_base(raw=True)\n    restaurant = Restaurant(\n        place_ptr=place1,\n        serves_hot_dogs=True,\n        serves_pizza=False,\n    )\n    restaurant.save_base(raw=True)\n    italian_restaurant = ItalianRestaurant(restaurant_ptr=restaurant, serves_gnocchi=True)\n    italian_restaurant.save_base(raw=True)\n\n    # This should delete both Restaurants, plus the related places, plus\n    # the ItalianRestaurant.\n    Restaurant.objects.all().delete()\n\n    with self.assertRaises(Place.DoesNotExist):\n        Place.objects.get(pk=place1.pk)\n    with self.assertRaises(ItalianRestaurant.DoesNotExist):\n        ItalianRestaurant.objects.get(pk=italian_restaurant.pk)\n"], "sample_544": ["def test_imshow_masked_under():\n    # Test that masked_under is handled correctly when the data is masked.\n    cmap = mpl.colormaps['viridis'].with_extremes(under='w')\n\n    N = 20\n    n = colors.Normalize(vmin=0, vmax=N*N-1)\n\n    data = np.arange(N*N, dtype=float).reshape(N, N)\n\n    data[5, 5] = -1\n    # This will cause crazy ringing for the higher-order\n    # interpolations\n    data[15, 5] = 1e5\n\n    mask = np.zeros_like(data).astype('bool')\n    mask[5, 15] = True\n\n    data = np.ma.masked_array(data, mask)\n\n    fig, ax_grid = plt.subplots(1, 6)\n    interps = sorted(mimage._interpd_)\n    interps.remove('antialiased')\n\n    for interp, ax in zip(interps, ax_grid.ravel()):\n        ax.set_title(interp)\n        ax.imshow(data, norm=n, cmap=cmap, interpolation=interp)\n        ax.axis('off')\n"], "sample_843": ["def test_kernel_exponentiation():\n    # Test that exponentiation of a kernel is consistent.\n    kernel = RBF(length_scale=2.0)\n    K = kernel(X)\n    K_exp = (kernel ** 2)(X)\n    assert_almost_equal(K, K_exp)\n\n    # Test that gradient of exponentiation of a kernel is correct.\n    K_exp, K_exp_gradient = (kernel ** 2)(X, eval_gradient=True)\n    K, K_gradient = kernel(X, eval_gradient=True)\n    K_exp_gradient = K_exp * (2 * K_exp_gradient[:, :, np.newaxis] + K[:, :, np.newaxis] ** 2)\n    assert_almost_equal(K_exp_gradient, K_exp_gradient)\n\n    # Test that exponentiation of a kernel with a fixed parameter is consistent.\n    kernel = RBF(length_scale=2.0)\n    kernel.hyperparameters[0].bounds = \"fixed\"\n    K = kernel(X)\n    K_exp = (kernel ** 2)(X)\n    assert_almost_equal(K, K_exp)\n\n    # Test that gradient of exponentiation of a kernel with a fixed parameter is correct.\n    K_exp, K_exp_gradient = (kernel ** 2)(X, eval_gradient=True)\n    K, K_gradient = kernel(X, eval_gradient=True)\n    K_exp_gradient = K_exp * (2 * K_exp_gradient[:, :, np.newaxis] + K[:, :, np.newaxis] ** 2)\n    assert_almost_equal(K_exp_gradient, K_exp_gradient)\n"], "sample_1158": ["def test_issue_20124():\n    class A:\n            return Symbol(\"x\")\n\n    a = A()\n    assert sympify(a) == x\n    assert sympify(a, strict=True) == x\n"], "sample_587": ["    def test_merge_no_conflicts_fill_value(self):\n        ds1 = xr.Dataset({\"x\": 0})\n        ds2 = xr.Dataset({\"x\": np.nan})\n        actual = ds1.merge(ds2, compat=\"no_conflicts\", fill_value=2)\n        expected = xr.Dataset({\"x\": 0})\n        assert expected.identical(actual)\n\n        ds1 = xr.Dataset({\"x\": np.nan})\n        ds2 = xr.Dataset({\"x\": 0})\n        actual = ds1.merge(ds2, compat=\"no_conflicts\", fill_value=2)\n        expected = xr.Dataset({\"x\": 0})\n        assert expected.identical(actual)\n\n        ds1 = xr.Dataset({\"x\": 0})\n        ds2 = xr.Dataset({\"x\": (\"y\", [np.nan, np.nan])})\n        actual = ds1.merge(ds2, compat=\"no_conflicts\", fill_value=2)\n        expected = xr.Dataset({\"x\": (\"y\", [0, 0])})\n        assert expected.identical(actual)\n\n        ds1 = xr.Dataset({\"x\": (\"y\", [np.nan, np.nan])})\n        ds2 = xr.Dataset({\"x\": 0})\n        actual = ds1.merge(ds2, compat=\"no_conflicts\", fill_value=2)\n        expected = xr.Dataset({\"x\": (\"y\", [0, 0])})\n        assert expected.identical(actual)\n"], "sample_970": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n        pass\n\n    func.register(int, lambda x: x)\n\n    assert inspect.is_singledispatch_function(func) is True\n    assert inspect.is_singledispatch_function(singledispatch(func)) is True\n    assert inspect.is_singledispatch_function(lambda x: x) is False\n    assert inspect.is_singledispatch_function(1) is False\n"], "sample_150": ["    def test_base_command_init(self):\n        cmd = BaseCommand()\n        self.assertEqual(cmd.help, '')\n        self.assertFalse(cmd._called_from_command_line)\n        self.assertFalse(cmd.output_transaction)\n        self.assertFalse(cmd.requires_migrations_checks)\n        self.assertTrue(cmd.requires_system_checks)\n        self.assertEqual(cmd.base_stealth_options, ('stderr', 'stdout'))\n        self.assertEqual(cmd.stealth_options, ())\n"], "sample_972": ["def test_stringify_type_hints_NewType():\n    MyInt = NewType('MyInt', int)\n    assert stringify(MyInt) == \"MyInt\"\n    assert stringify(MyInt, \"fully-qualified\") == \"tests.test_util_typing.MyInt\"\n    assert stringify(MyInt, \"smart\") == \"~tests.test_util_typing.MyInt\"\n\n    assert stringify(NewType('MyInt', int)) == \"MyInt\"\n    assert stringify(NewType('MyInt', int), \"fully-qualified\") == \"tests.test_util_typing.MyInt\"\n    assert stringify(NewType('MyInt', int), \"smart\") == \"~tests.test_util_typing.MyInt\"\n"], "sample_1105": ["def test_matmul_shape():\n    assert MatMul(A, B).shape == (n, l)\n    assert MatMul(C, D).shape == (n, n)\n    assert MatMul(A, C, D).shape == (n, n)\n    assert MatMul(C, A, D).shape == (n, n)\n    assert MatMul(C, D, A).shape == (n, n)\n"], "sample_916": ["def test_template_specialization():\n    check('function', 'template<> void A<int>()', {2: 'IE1Av', 4: 'IE1Avv'})\n    check('function', 'template<> void A<int, int>()', {2: 'IE1Av', 4: 'IE1Avv'})\n    check('function', 'template<> void A<int, int, int>()', {2: 'IE1Av', 4: 'IE1Avv'})\n    check('function', 'template<> void A<int, int, int, int>()', {2: 'IE1Av', 4: 'IE1Avv'})\n    check('function', 'template<> void A<int, int, int, int, int>()', {2: 'IE1Av', 4: 'IE1Avv'})\n    check('function', 'template<> void A<int, int, int, int, int, int>()', {2: 'IE1Av', 4: 'IE1Avv'})\n    check('function', 'template<> void A<int, int, int, int, int, int, int>()', {2: 'IE1Av', 4: 'IE1Avv'})\n    check('function', 'template<> void A<int, int, int, int, int, int, int, int>()', {2: 'IE1Av', 4: 'IE1Avv'})\n    check('function', 'template<> void A<int, int, int, int, int, int, int, int, int>()', {2: 'IE1Av', 4: 'IE1Avv'})\n    check('function', 'template<> void A<int, int, int, int, int, int, int, int, int, int>()', {2: 'IE1Av', 4: 'IE1Avv'})\n    check('function', 'template<> void A<int, int, int, int, int, int, int, int, int, int, int>()', {2: 'IE1Av', 4: 'IE1Avv'})\n    check('function', 'template<> void A<int, int, int, int, int, int, int, int, int, int, int, int>()', {2: 'IE1Av', 4: 'IE1Avv'})\n    check('function', 'template<> void A<int"], "sample_320": ["    def test_references_field_by_through_model(self):\n        operation = FieldOperation(\n            \"Model\", \"field\", models.ManyToManyField(\"Other\", through=\"Through\")\n        )\n        self.assertIs(operation.references_field(\"Other\", \"whatever\", \"migrations\"), True)\n        self.assertIs(operation.references_field(\"Through\", \"whatever\", \"migrations\"), True)\n        self.assertIs(operation.references_field(\"Missing\", \"whatever\", \"migrations\"), False)\n"], "sample_1157": ["def test_function_exponentiation_application():\n    t = standard_transformations + (implicit_multiplication_application,)\n    x = Symbol('x')\n    y = Symbol('y')\n    a = Symbol('a')\n    yfcn = Function('y')\n    assert parse_expr(\"sin**2(x)\", transformations=t) == (sin(x))**2\n    assert parse_expr(\"sin**y(x)\", transformations=t) == (sin(x))**y\n    assert parse_expr(\"exp**y(x)\", transformations=t) == (exp(x))**y\n    assert parse_expr(\"E**y(x)\", transformations=t) == exp(yfcn(x))\n    assert parse_expr(\"a**y(x)\", transformations=t) == a**(yfcn(x))\n"], "sample_947": ["def test_struct_definitions():\n    check('struct', '{key}A', {1: 'A'})\n\n    check('struct', '{key}A.B', {1: 'A.B'})\n\n    check('struct', '{key}A.B.C', {1: 'A.B.C'})\n\n    check('struct', '{key}A.B.C.D', {1: 'A.B.C.D'})\n\n    check('struct', '{key}A.B.C.D.E', {1: 'A.B.C.D.E'})\n\n    check('struct', '{key}A.B.C.D.E.F', {1: 'A.B.C.D.E.F'})\n\n    check('struct', '{key}A.B.C.D.E.F.G', {1: 'A.B.C.D.E.F.G'})\n\n    check('struct', '{key}A.B.C.D.E.F.G.H', {1: 'A.B.C.D.E.F.G.H'})\n\n    check('struct', '{key}A.B.C.D.E.F.G.H.I', {1: 'A.B.C.D.E.F.G.H.I'})\n\n    check('struct', '{key}A.B.C.D.E.F.G.H.I.J', {1: 'A.B.C.D.E.F.G.H.I.J'})\n\n    check('struct', '{key}A.B.C.D.E.F.G.H.I.J.K', {1: 'A.B.C.D.E.F.G.H.I.J.K'})\n\n    check('struct', '{key}A.B.C.D.E.F.G.H.I.J.K.L', {1: 'A.B.C.D.E.F.G.H.I.J.K.L'})\n\n    check('struct', '{key}A.B.C.D.E.F.G.H.I.J.K.L.M', {1: 'A.B.C.D.E.F.G.H.I.J.K.L.M'})\n\n    check('struct', '{key}A.B.C.D.E.F.G.H.I.J.K.L.M.N', {1: 'A.B.C.D.E.F.G.H.I.J.K.L.M.N'})\n\n    check('struct', '{key}A.B.C.D.E.F.G.H.I.J.K.L.M.N.O', {1: 'A.B.C.D.E.F.G.H.I.J.K.L.M.N.O'})\n\n    check('struct', '{key}A.B.C.D.E.F.G.H.I.J.K.L.M.N.O.P', {1: 'A.B.C.D.E.F.G.H.I.J.K.L.M.N.O.P'})\n\n    check('struct', '{key}"], "sample_874": ["def test_clone():\n    \"\"\"Test the clone method of BaseEstimator.\"\"\"\n    sel = StepSelector()\n    sel_clone = clone(sel)\n    assert isinstance(sel_clone, StepSelector)\n    assert sel_clone.step == sel.step\n    assert sel_clone.n_features_in_ == sel.n_features_in_\n    assert sel_clone.feature_names_in_ == sel.feature_names_in_\n\n    # Test cloning with a different step value\n    sel_clone = clone(sel, safe=False)\n    assert sel_clone.step == sel.step\n    assert sel_clone.n_features_in_ == sel.n_features_in_\n    assert sel_clone.feature_names_in_ == sel.feature_names_in_\n\n    # Test cloning with a different class\n    class NewSelector(SelectorMixin, BaseEstimator):\n            self.step = step\n\n            X = self._validate_data(X, accept_sparse=\"csc\")\n            return self\n\n            mask = np.zeros(self.n_features_in_, dtype=bool)\n            if self.step >= 1:\n                mask[:: self.step] = True\n            return mask\n\n    new_sel = NewSelector()\n    new_sel_clone = clone(new_sel)\n    assert isinstance(new_sel_clone, NewSelector)\n    assert new_sel_clone.step == new_sel.step\n    assert new_sel_clone.n_features_in_ == new_sel.n_features_in_\n    assert new_sel_clone.feature_names_in_ == new_sel.feature_names_in_\n"], "sample_1005": ["def test_latex_Dict():\n    d = {Rational(1): 1, x**2: 2, x: 3, x**3: 4}\n    assert latex(d) == r'\\left \\{ 1 : 1, \\quad x : 3, \\quad x^{2} : 2, \\quad x^{3} : 4\\right \\}'\n    D = Dict(d)\n    assert latex(D) == r'\\left \\{ 1 : 1, \\quad x : 3, \\quad x^{2} : 2, \\quad x^{3} : 4\\right \\}'\n"], "sample_1153": ["def test_issue_19627():\n    from sympy import Abs, Function\n    f = Function('f', positive=True)\n    assert Abs(f(x)**2) == f(x)**2\n"], "sample_924": ["def test_template_params():\n    check('class', \"template<typename T> {key}A\", {2: \"I0E1A\"})\n    check('class', \"template<typename T1, typename T2> {key}A\", {2: \"I00E1A\"})\n    check('class', \"template<typename T1, typename T2, typename T3> {key}A\", {2: \"I000E1A\"})\n    check('class', \"template<typename T1, typename T2, typename T3, typename T4> {key}A\", {2: \"I0000E1A\"})\n    check('class', \"template<typename T1, typename T2, typename T3, typename T4, typename T5> {key}A\", {2: \"I00000E1A\"})\n    check('class', \"template<typename T1, typename T2, typename T3, typename T4, typename T5, typename T6> {key}A\", {2: \"I000000E1A\"})\n    check('class', \"template<typename T1, typename T2, typename T3, typename T4, typename T5, typename T6, typename T7> {key}A\", {2: \"I0000000E1A\"})\n    check('class', \"template<typename T1, typename T2, typename T3, typename T4, typename T5, typename T6, typename T7, typename T8> {key}A\", {2: \"I00000000E1A\"})\n    check('class', \"template<typename T1, typename T2, typename T3, typename T4, typename T5, typename T6, typename T7, typename T8, typename T9> {key}A\", {2: \"I000000000E1A\"})\n    check('class', \"template<typename T1, typename T2, typename T3, typename T4, typename T5, typename T6, typename T7, typename T8, typename T9, typename T10> {key}A\", {2: \"I0000000000E1A\"})\n    check('class', \"template<typename T1, typename T2, typename T3, typename T4, typename T5, typename T6, typename T7, typename T8, typename T9, typename T10,"], "sample_308": ["def test_date_format_with_leap_year(self):\n    my_birthday = datetime(2000, 2, 29, 22, 00)\n    self.assertEqual(dateformat.format(my_birthday, 'L'), 'True')\n"], "sample_232": ["    def test_custom_decoder(self):\n        field = models.JSONField(decoder=CustomJSONDecoder)\n        value = {'uuid': uuid.UUID('d85e2076-b67c-4ee7-8c3a-2bf5a2cc2475')}\n        field.clean({'uuid': value}, None)\n        self.assertEqual(field.to_python({'uuid': value}), value)\n"], "sample_610": ["def test_infer_freq_non_monotonic():\n    \"\"\"Test that infer_freq returns None for non-monotonic input.\"\"\"\n    cf_indx = xr.cftime_range(\"2000-01-01\", periods=3, freq=\"D\")\n    assert xr.infer_freq(cf_indx[np.array([0, 2, 1, 3])]) is None\n"], "sample_455": ["    def setUpTestData(cls):\n        cls.p1 = UniqueConstraintProduct.objects.create(name=\"p1\", color=\"red\")\n        cls.p2 = UniqueConstraintProduct.objects.create(name=\"p2\")\n"], "sample_576": ["    def test_default_layout_engine(self):\n\n        p = Plot().plot()\n        assert p._figure.get_tight_layout() is None\n\n        p = Plot().on(mpl.figure.Figure()).plot()\n        assert p._figure.get_tight_layout() is None\n\n        p = Plot().layout(engine=\"tight\").plot()\n        assert p._figure.get_tight_layout()\n\n        p = Plot().on(mpl.figure.Figure()).layout(engine=\"tight\").plot()\n        assert p._figure.get_tight_layout()\n"], "sample_724": ["def test_imputation_axis_error():\n    # Test that an error is raised when axis is not 0 or 1\n    imputer = Imputer(strategy=\"mean\", axis=2)\n    X = np.array([[1, 2, 3], [4, 5, 6]])\n    assert_raises(ValueError, imputer.fit, X)\n"], "sample_242": ["    def test_relabeled_clone(self):\n        lookup = Lookup(Value(1), Value(2))\n        relabels = {'lhs': 'new_lhs', 'rhs': 'new_rhs'}\n        new_lookup = lookup.relabeled_clone(relabels)\n        self.assertEqual(new_lookup.identity, ('Lookup', 'new_lhs', 'new_rhs'))\n        self.assertEqual(new_lookup.lhs, 'new_lhs')\n        self.assertEqual(new_lookup.rhs, 'new_rhs')\n        self.assertEqual(new_lookup.bilateral_transforms, lookup.bilateral_transforms)\n"], "sample_842": ["def test_kernel_clone_after_fit(kernel):\n    # This test is to verify that using clone on a kernel after it has been fit\n    # does not break it.\n    # This used to break because in kernels such as the RBF, non-trivial\n    # logic that modified the length scale used to be in the fit method\n    # See https://github.com/scikit-learn/scikit-learn/issues/6961\n    # for more details.\n    kernel.fit(X)\n    kernel_cloned = clone(kernel)\n    assert (kernel.get_params() == kernel_cloned.get_params())\n    assert id(kernel_cloned) != id(kernel)\n    check_hyperparameters_equal(kernel, kernel_cloned)\n"], "sample_1026": ["def test_lambdify_with_tensorflow_and_numpy():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    if not numpy:\n        skip(\"numpy not installed.\")\n    x = sympy.Symbol('x')\n    f = lambdify(x, x**2, modules=['tensorflow', 'numpy'])\n    assert f(2) == 4\n    assert isinstance(f(2), tensorflow.Tensor)\n    assert isinstance(f(2), numpy.ndarray)\n"], "sample_153": ["    def test_model_checks_called(self):\n        model = self.create_test_model()\n        errors = model.check()\n        self.assertEqual(len(errors), 0)\n"], "sample_1056": ["def test_custom_printed_object():\n    obj = CustomPrintedObject()\n    l = lambdarepr(obj)\n    assert l == \"lambda\"\n    l = lambdarepr(obj, method=\"tensorflow\")\n    assert l == \"tensorflow\"\n    l = lambdarepr(obj, method=\"numpy\")\n    assert l == \"numpy\"\n    l = lambdarepr(obj, method=\"numexpr\")\n    assert l == \"numexpr\"\n    l = lambdarepr(obj, method=\"mpmath\")\n    assert l == \"mpmath\"\n    raises(TypeError, lambda: lambdarepr(obj, method=\"garbage\"))\n"], "sample_1076": ["def test_SymPyPrinter():\n    p = SymPyPrinter()\n    assert p.doprint(acos(x)) == 'sympy.acos(x)'\n    assert p.doprint(Assignment(x, 2)) == 'x = 2'\n    assert p.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert p.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert p.doprint(sign(x)) == '(0.0 if x == 0 else sympy.copysign(1, x))'\n    assert p.doprint(p[0, 1]) == 'p[0, 1]'\n"], "sample_1057": ["def test_render_as_module_fully_qualified_modules():\n    # Arrange\n    content = Print('x**2')\n    expected_imports = 'from sympy import symbols\\nfrom sympy import printing\\nfrom sympy import core\\nfrom sympy import printer\\nfrom sympy import core\\nfrom sympy import printer\\nfrom sympy import printer\\n'\n    expected_code = 'from sympy import symbols\\nfrom sympy import printing\\nfrom sympy import core\\nfrom sympy import printer\\nfrom sympy import core\\nfrom sympy import printer\\n\\nx = symbols(\\'x\\')\\nprint(printer.doprint(x**2))'\n\n    # Act\n    result = render_as_module(content, standard='python3')\n\n    # Assert\n    assert result == expected_imports + '\\n\\n' + expected_code\n"], "sample_196": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_1106": ["def test_matadd_scalar_Matrix_doit():\n    # Issue 9053\n    X = Matrix([[1, 2], [3, 4]])\n    assert MatAdd(2, X).doit() == 2 + X\n"], "sample_1088": ["def test_viete():\n    x, a, b, c, r1, r2 = symbols('x,a:c,r1:3')\n\n    # Test with a monic polynomial\n    assert viete(a*x**2 + b*x + c, [r1, r2], x) == [(r1 + r2, -b/a), (r1*r2, c/a)]\n\n    # Test with a non-monic polynomial\n    assert viete(a*x**2 + b*x + c, [r1, r2], x) == [(r1 + r2, -b/a), (r1*r2, c/a)]\n\n    # Test with a polynomial of degree 0\n    assert viete(c, [r1, r2], x) == [(r1 + r2, 0), (r1*r2, c)]\n\n    # Test with a polynomial of degree 1\n    assert viete(a*x + b, [r1, r2], x) == [(r1 + r2, -b/a), (r1*r2, 0)]\n\n    # Test with a polynomial of degree 3\n    assert viete(a*x**3 + b*x**2 + c*x + d, [r1, r2, r3], x) == [\n        (r1 + r2 + r3, -c/a),\n        (r1*r2 + r1*r3 + r2*r3, b/a),\n        (r1*r2*r3, -d/a),\n        (r1*r2*r3, 0)\n    ]\n\n    # Test with a polynomial of degree 4\n    assert viete(a*x**4 + b*x**3 + c*x**2 + d*x + e, [r1, r2, r3, r4], x) == [\n        (r1 + r2 + r3 + r4, -d/a),\n        (r1*r2 + r1*r3 + r1*r4 + r2*r3 + r2*r4 + r3*r4, c/a),\n        (r1*r2*r3 + r1*r2*r4 + r1*r3*r4 + r2*r3*r4, -e/a),\n        (r1*r2*r3*r4, 0)\n    ]\n\n    # Test with a non-list of roots\n    assert viete(a*x"], "sample_1068": ["def test_MatrixSlice():\n    A = Matrix([[1, 2, 3], [4, 5, 6]])\n    assert mcode(A[1, :]) == \"[4 5 6]\"\n    assert mcode(A[:, 1]) == \"[2; 5]\"\n    assert mcode(A[1, 1:3]) == \"[5 6]\"\n    assert mcode(A[:, 1:3]) == \"[2 5; 5 6]\"\n    assert mcode(A[1, 1:3:2]) == \"[5]\"\n    assert mcode(A[:, 1:3:2]) == \"[2; 5]\"\n    assert mcode(A[1, 1:]) == \"[5 6]\"\n    assert mcode(A[:, 1:]) == \"[2; 5 6]\"\n    assert mcode(A[1, :3]) == \"[4 5]\"\n    assert mcode(A[:, :3]) == \"[1 2; 4 5]\"\n    assert mcode(A[1, :3:2]) == \"[4]\"\n    assert mcode(A[:, :3:2]) == \"[1; 4]\"\n"], "sample_973": ["def test_is_singledispatch_function():\n    from functools import singledispatch\n\n        pass\n\n    singledispatch(func)(int)(lambda x: x)\n\n    assert inspect.is_singledispatch_function(func) is True\n\n"], "sample_1154": ["def test__linsolve_underdetermined():\n    # Test underdetermined system with a single equation\n    eqs = [x + y]\n    sol = {x: -y}\n    assert _linsolve(eqs, (x, y)) == sol\n\n    # Test underdetermined system with multiple equations\n    eqs = [x + y, x + 2*y]\n    sol = {x: -2*y}\n    assert _linsolve(eqs, (x, y)) == sol\n\n    # Test underdetermined system with multiple variables\n    eqs = [x + y, x + z]\n    sol = {x: -z, y: z}\n    assert _linsolve(eqs, (x, y, z)) == sol\n\n    # Test underdetermined system with no solution\n    eqs = [x + y, x + y]\n    assert _linsolve(eqs, (x, y)) is None\n"], "sample_1119": ["def test_inverse_matrix():\n    A = Matrix([[1, 2], [3, 4]])\n    assert A.inv().is_square\n    assert A.inv().is_invertible\n    assert A.inv().is_symmetric\n    assert A.inv().is_diagonalizable\n    assert A.inv().is_positive_definite\n    assert A.inv().is_positive_semidefinite\n    assert A.inv().is_negative_definite\n    assert A.inv().is_negative_semidefinite\n    assert A.inv().is_indefinite\n\n    A = Matrix([[1, 0], [0, 1]])\n    assert A.inv().is_square\n    assert A.inv().is_invertible\n    assert A.inv().is_symmetric\n    assert A.inv().is_diagonalizable\n    assert A.inv().is_positive_definite\n    assert A.inv().is_positive_semidefinite\n    assert not A.inv().is_negative_definite\n    assert not A.inv().is_negative_semidefinite\n    assert not A.inv().is_indefinite\n\n    A = Matrix([[1, 0], [0, -1]])\n    assert A.inv().is_square\n    assert A.inv().is_invertible\n    assert A.inv().is_symmetric\n    assert A.inv().is_diagonalizable\n    assert not A.inv().is_positive_definite\n    assert not A.inv().is_positive_semidefinite\n    assert A.inv().is_negative_definite\n    assert A.inv().is_negative_semidefinite\n    assert not A.inv().is_indefinite\n\n    A = Matrix([[1, 0], [0, 0]])\n    assert A.inv().is_square\n    assert not A.inv().is_invertible\n    assert A.inv().is_symmetric\n    assert A.inv().is_diagonalizable\n    assert not A.inv().is_positive_definite\n    assert not A.inv().is_positive_semidefinite\n    assert not A.inv().is_negative_definite\n    assert not A.inv().is_negative_semidefinite\n    assert A.inv().is_indefinite\n\n    A = Matrix([[0, 0], [0, 0]])\n    assert A.inv().is_square\n    assert not A.inv().is_invertible\n    assert A.inv().is_symmetric\n    assert A.inv().is_diagonalizable\n    assert not A.inv().is_positive_definite\n    assert not A.inv().is_positive"], "sample_1036": ["def test_matmul_args_cnc_noncommutative():\n    a, b = symbols('a b', commutative=False)\n    assert MatMul(n, a, b, A, A.T).args_cnc() == [[n], [a, b, A, A.T]]\n    assert MatMul(n, a, A, b, A.T).args_cnc() == [[n], [a, A, b, A.T]]\n"], "sample_927": ["def test_template_params():\n    check('class', \"template<typename T> {key}A\", {2: \"I0E1A\"})\n    check('class', \"template<typename T> template<typename U> {key}A\", {2: \"I00E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> {key}A\", {2: \"I000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> {key}A\", {2: \"I0000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> template<typename X> {key}A\", {2: \"I00000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> template<typename X> template<typename Y> {key}A\", {2: \"I000000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> template<typename X> template<typename Y> template<typename Z> {key}A\", {2: \"I0000000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> template<typename X> template<typename Y> template<typename Z> template<typename AA> {key}A\", {2: \"I00000000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> template<typename X> template<typename Y> template<typename Z> template<typename AA> template<typename BB> {key}A\", {2: \"I000000000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> template<typename X> template<typename Y> template<typename Z> template<typename AA> template<typename BB> template<typename CC> {key}A\", {2: \"I0000000000E1A\"})\n    check('class', \"template<typename T> template<typename U> template<typename V> template<typename W> template<typename X> template<typename Y> template<typename Z> template<typename AA> template<typename BB> template<typename CC> template<typename DD> {key}A\", {"], "sample_588": ["    def test_fill_value(self, create_combined_ids):\n        shape = (2, 3)\n        combined_ids = create_combined_ids(shape)\n        result = _combine_nd(\n            combined_ids,\n            concat_dims=[\"dim1\"],\n            data_vars=\"all\",\n            coords=\"different\",\n            fill_value=2,\n            join=\"outer\",\n        )\n\n        expected = concat(\n            [create_test_data(0), create_test_data(1)],\n            dim=\"dim1\",\n            fill_value=2,\n        )\n        assert_equal(result, expected)\n\n        result = _combine_nd(\n            combined_ids,\n            concat_dims=[\"dim1\"],\n            data_vars=\"all\",\n            coords=\"different\",\n            fill_value=2.0,\n            join=\"outer\",\n        )\n\n        expected = concat(\n            [create_test_data(0), create_test_data(1)],\n            dim=\"dim1\",\n            fill_value=2.0,\n        )\n        assert_equal(result, expected)\n\n        result = _combine_nd(\n            combined_ids,\n            concat_dims=[\"dim1\"],\n            data_vars=\"all\",\n            coords=\"different\",\n            fill_value=dtypes.NA,\n            join=\"outer\",\n        )\n\n        expected = concat(\n            [create_test_data(0), create_test_data(1)],\n            dim=\"dim1\",\n            fill_value=np.nan,\n        )\n        assert_equal(result, expected)\n"], "sample_430": ["def test_add_field_with_default_callable(self):\n    \"\"\"#23609 - Adding a field with a callable default should work.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AddField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n    self.assertEqual(\n        changes[\"testapp\"][0].operations[0].field.default, \"Ada Lovelace\"\n    )\n"], "sample_959": ["def test_domain_cpp_ast_declarator():\n    check('class', '{key}A', {1: \"A\", 2: \"1A\"})\n    check('class', '{key}A::B', {1: \"A::B\", 2: \"N1A1BE\"})\n    check('function', 'void f(::A a)', {1: \"f__A\", 2: \"1f1A\"})\n    check('function', 'void f(::A::B a)', {1: \"f__A::B\", 2: \"1fN1A1BE\"})\n\n    check('class', '{key}A', {1: \"A\", 2: \"1A\"})\n    check('class', '{key}A::B::C', {1: \"A::B::C\", 2: \"N1A1B1CE\"})\n    check('class', '{key}A : B', {1: \"A\", 2: \"1A\"})\n    check('class', '{key}A : private B', {1: \"A\", 2: \"1A\"})\n    check('class', '{key}A : public B', {1: \"A\", 2: \"1A\"})\n    check('class', '{key}A : B, C', {1: \"A\", 2: \"1A\"})\n    check('class', '{key}A : B, protected C, D', {1: \"A\", 2: \"1A\"})\n    check('class', 'A : virtual private B', {1: 'A', 2: '1A'}, output='{key}A : private virtual B')\n    check('class', '{key}A : private virtual B', {1: 'A', 2: '1A'})\n    check('class', '{key}A : B, virtual C', {1: 'A', 2: '1A'})\n    check('class', '{key}A : public virtual B', {1: 'A', 2: '1A'})\n    check('class', '{key}A : B, C...', {1: 'A', 2: '1A'})\n    check('class', '{key}A : B..., C', {1: 'A', 2: '1A'})\n\n    check('class', 'template<class, class ="], "sample_1118": ["def test_matpow():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    assert MatPow(A, 0).args == (A, S.Zero)\n    assert MatPow(A, 0).shape == (2, 2)\n    assert MatPow(A, 1).args == (A, S.One)\n    assert MatPow(A, 1).shape == (2, 2)\n    assert MatPow(A, 2).args == (A, 2)\n    assert MatPow(A, 2).shape == (2, 2)\n    assert MatPow(A, -1).args == (A, -1)\n    assert MatPow(A, -1).shape == (2, 2)\n    assert MatPow(A, -2).args == (A, -2)\n    assert MatPow(A, -2).shape == (2, 2)\n\n    assert MatPow(B, 0).args == (B, S.Zero)\n    assert MatPow(B, 0).shape == (2, 2)\n    assert MatPow(B, 1).args == (B, S.One)\n    assert MatPow(B, 1).shape == (2, 2)\n    assert MatPow(B, 2).args == (B, 2)\n    assert MatPow(B, 2).shape == (2, 2)\n    assert MatPow(B, -1).args == (B, -1)\n    assert MatPow(B, -1).shape == (2, 2)\n    assert MatPow(B, -2).args == (B, -2)\n    assert MatPow(B, -2).shape == (2, 2)\n\n    assert MatPow(A, 0)*MatPow(B, 0) == Identity(2)\n    assert MatPow(A, 1)*MatPow(B, 1) == A*B\n    assert MatPow(A, 2)*MatPow(B, 2) == A**2*B**2\n    assert MatPow(A, -1)*MatPow(B, -1) == A**-1*B**-1\n    assert MatPow(A, -2)*MatPow(B, -2) == A**-2*B**-2\n\n    assert MatPow(A, 0).doit() == Identity(2)\n    assert"], "sample_969": ["def test_stringify_type_hints_Callable_with_defaults():\n    assert stringify(Callable[[str], int, None], False) == \"Callable[[str], int, None]\"\n    assert stringify(Callable[[str], int, None], True) == \"~typing.Callable[[str], int, None]\"\n\n    if sys.version_info >= (3, 7):\n        assert stringify(Callable[..., int, None], False) == \"Callable[[...], int, None]\"\n        assert stringify(Callable[..., int, None], True) == \"~typing.Callable[[...], int, None]\"\n    else:\n        assert stringify(Callable[..., int, None], False) == \"Callable[..., int, None]\"\n        assert stringify(Callable[..., int, None], True) == \"~typing.Callable[..., int, None]\"\n"], "sample_1141": ["def test_MatrixElement_subs():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    D = MatrixSymbol('D', 2, 2)\n    E = MatrixSymbol('E', 2, 2)\n    F = MatrixSymbol('F', 2, 2)\n    G = MatrixSymbol('G', 2, 2)\n    H = MatrixSymbol('H', 2, 2)\n    I = MatrixSymbol('I', 2, 2)\n    J = MatrixSymbol('J', 2, 2)\n    K = MatrixSymbol('K', 2, 2)\n    L = MatrixSymbol('L', 2, 2)\n    M = MatrixSymbol('M', 2, 2)\n    N = MatrixSymbol('N', 2, 2)\n    O = MatrixSymbol('O', 2, 2)\n    P = MatrixSymbol('P', 2, 2)\n    Q = MatrixSymbol('Q', 2, 2)\n    R = MatrixSymbol('R', 2, 2)\n    S = MatrixSymbol('S', 2, 2)\n    T = MatrixSymbol('T', 2, 2)\n    U = MatrixSymbol('U', 2, 2)\n    V = MatrixSymbol('V', 2, 2)\n    W = MatrixSymbol('W', 2, 2)\n    X = MatrixSymbol('X', 2, 2)\n    Y = MatrixSymbol('Y', 2, 2)\n    Z = MatrixSymbol('Z', 2, 2)\n    a = symbols('a')\n    b = symbols('b')\n    c = symbols('c')\n    d = symbols('d')\n    e = symbols('e')\n    f = symbols('f')\n    g = symbols('g')\n    h = symbols('h')\n    i = symbols('i')\n    j = symbols('j')\n    k = symbols('k')\n    l = symbols('l')\n    m = symbols('m')\n    n = symbols('n')\n    o = symbols('o')\n    p = symbols('p')\n    q = symbols('q')\n    r = symbols('r')\n    s = symbols('s')\n    t = symbols('t"], "sample_1174": ["def test_issue_19627():\n    from sympy import Function, Abs\n    f = Function('f', positive=True)\n    assert unchanged(Abs, f(x))\n    assert unchanged(Abs, f(x)**2)\n    assert unchanged(Abs, f(x)**3)\n    assert unchanged(Abs, f(x)**4)\n    assert unchanged(Abs, f(x)**5)\n    assert unchanged(Abs, f(x)**6)\n    assert unchanged(Abs, f(x)**7)\n    assert unchanged(Abs, f(x)**8)\n    assert unchanged(Abs, f(x)**9)\n    assert unchanged(Abs, f(x)**10)\n"], "sample_133": ["    def test_json_catalog(self):\n        \"\"\"The json_catalog returns the language catalog and settings as JSON.\"\"\"\n        with override('de'):\n            response = self.client.get('/jsoni18n/')\n            data = json.loads(response.content.decode())\n            self.assertIn('catalog', data)\n            self.assertIn('formats', data)\n            self.assertEqual(data['formats']['TIME_INPUT_FORMATS'], ['%H:%M:%S', '%H:%M:%S.%f', '%H:%M'])\n            self.assertEqual(data['formats']['FIRST_DAY_OF_WEEK'], 0)\n            self.assertIn('plural', data)\n            self.assertEqual(data['catalog']['month name\\x04May'], 'Mai')\n            self.assertIn('DATETIME_FORMAT', data['formats'])\n            self.assertEqual(data['plural'], '(n != 1)')\n"], "sample_1058": ["def test_print_Relational():\n    p = PythonCodePrinter()\n    assert p._print_Relational(Eq(x, y)) == '(x == y)'\n    assert p._print_Relational(Le(x, y)) == '(x <= y)'\n    assert p._print_Relational(Gt(x, y)) == '(x > y)'\n    assert p._print_Relational(x == y) == '(x == y)'\n    assert p._print_Relational(x <= y) == '(x <= y)'\n    assert p._print_Relational(x > y) == '(x > y)'\n    assert p._print_Relational(x != y) == '(x != y)'\n    assert p._print_Relational(x >= y) == '(x >= y)'\n    assert p._print_Relational(x < y) == '(x < y)'\n"], "sample_828": ["def test_pairwise_distances_chunked_sparse():\n    # Test the pairwise_distance helper function.\n    rng = np.random.RandomState(0)\n    # Euclidean distance should be equivalent to calling the function.\n    X = rng.random_sample((400, 4))\n    X_sparse = csr_matrix(X)\n    check_pairwise_distances_chunked(X_sparse, None, working_memory=1,\n                                     metric='euclidean')\n    # Test small amounts of memory\n    for power in range(-16, 0):\n        check_pairwise_distances_chunked(X_sparse, None, working_memory=2 ** power,\n                                         metric='euclidean')\n    # X as list\n    check_pairwise_distances_chunked(X_sparse.todense().tolist(), None,\n                                     working_memory=1, metric='euclidean')\n    # Euclidean distance, with Y != X.\n    Y = rng.random_sample((200, 4))\n    Y_sparse = csr_matrix(Y)\n    check_pairwise_distances_chunked(X_sparse, Y_sparse, working_memory=1,\n                                     metric='euclidean')\n    check_pairwise_distances_chunked(X_sparse.todense().tolist(),\n                                     Y_sparse.todense().tolist(), working_memory=1,\n                                     metric='euclidean')\n    # absurdly large working_memory\n    check_pairwise_distances_chunked(X_sparse, Y_sparse, working_memory=10000,\n                                     metric='euclidean')\n    # \"cityblock\" uses scikit-learn metric, cityblock (function) is\n    # scipy.spatial.\n    check_pairwise_distances_chunked(X_sparse, Y_sparse, working_memory=1,\n                                     metric='cityblock')\n    # Test that a value error is raised if the metric is unknown\n    assert_raises(ValueError, next,\n                  pairwise_distances_chunked(X_sparse, Y_sparse, metric=\"blah\"))\n\n    # Test precomputed returns all at once\n    D = pairwise_distances(X_sparse.todense())\n    gen = pairwise_distances_chunked(D,\n                                     working_memory=2 ** -16,\n                                     metric='precomputed')\n    assert isinstance(gen, GeneratorType)\n    assert next(gen) is D\n    assert_raises(StopIteration, next, gen)\n"], "sample_827": ["def test_csr_row_median():\n    # Test csc_row_median actually calculates the median.\n\n    # Test that it gives the same output when X is dense.\n    rng = np.random.RandomState(0)\n    X = rng.rand(100, 50)\n    dense_median = np.median(X, axis=0)\n    csr = sp.csr_matrix(X)\n    sparse_median = csc_median_axis_0(csr.T)\n    assert_array_equal(sparse_median, dense_median)\n\n    # Test that it gives the same output when X is sparse\n    X = rng.rand(51, 100)\n    X[X < 0.7] = 0.0\n    ind = rng.randint(0, 50, 10)\n    X[ind] = -X[ind]\n    csr = sp.csr_matrix(X)\n    dense_median = np.median(X, axis=0)\n    sparse_median = csc_median_axis_0(csr.T)\n    assert_array_equal(sparse_median, dense_median)\n\n    # Test for toy data.\n    X = [[0, -2], [-1, -1], [1, 0], [2, 1]]\n    csr = sp.csr_matrix(X)\n    assert_array_equal(csc_median_axis_0(csr.T), np.array([0.5, -0.5]))\n    X = [[0, -2], [-1, -5], [1, -3]]\n    csr = sp.csr_matrix(X)\n    assert_array_equal(csc_median_axis_0(csr.T), np.array([0., -3]))\n\n    # Test that it raises an Error for non-csr matrices.\n    assert_raises(TypeError, csc_median_axis_0, sp.csc_matrix(X))\n"], "sample_154": ["    def test_database_checks_called_with_kwargs(self, mocked_check):\n        check_database_backends(databases=self.databases, enforce_no_triggers=True)\n        mocked_check.assert_called_once_with(enforce_no_triggers=True)\n"], "sample_319": ["def test_alter_field_with_default(self):\n    \"\"\"Tests autodetection of fields with default values.\"\"\"\n    changes = self.get_changes([self.author_empty], [self.author_name_default])\n    # Right number/type of migrations?\n    self.assertNumberMigrations(changes, \"testapp\", 1)\n    self.assertOperationTypes(changes, \"testapp\", 0, [\"AlterField\"])\n    self.assertOperationAttributes(changes, \"testapp\", 0, 0, name=\"name\")\n    self.assertOperationFieldAttributes(changes, \"testapp\", 0, 0, default=\"Ada Lovelace\")\n"], "sample_415": ["    def setUpTestData(cls):\n        cls.p1 = UniqueConstraintProduct.objects.create(name=\"p1\", color=\"red\")\n        cls.p2 = UniqueConstraintProduct.objects.create(name=\"p2\")\n"], "sample_826": ["def test_one_hot_encoder_sparse_output():\n    X = np.array([[3, 2, 1], [0, 1, 1]])\n    enc = OneHotEncoder(sparse=True)\n    with ignore_warnings(category=(DeprecationWarning, FutureWarning)):\n        X_trans = enc.fit_transform(X)\n        assert sparse.isspmatrix_csr(X_trans)\n        assert_array_equal(X_trans.toarray(), [[0., 1., 0., 1., 1.],\n                                              [1., 0., 1., 0., 1.]])\n"], "sample_781": ["def check_min_impurity_split(name):\n    # Test if min_impurity_split of base estimators is set\n    # Regression test for #8006\n    X, y = datasets.make_hastie_10_2(n_samples=100, random_state=1)\n    all_estimators = [RandomForestClassifier, RandomForestRegressor,\n                      ExtraTreesClassifier, ExtraTreesRegressor]\n\n    for Estimator in all_estimators:\n        est = Estimator(min_impurity_split=0.1)\n        est = assert_warns_message(DeprecationWarning, \"min_impurity_decrease\",\n                                   est.fit, X, y)\n        for tree in est.estimators_:\n            assert_equal(tree.min_impurity_split, 0.1)\n\n"], "sample_195": ["    def setUp(self):\n        self.ops = BaseDatabaseOperations(connection=connection)\n"], "sample_1152": ["def test_powsimp_issue_12345():\n    x, y = symbols('x y', positive=True)\n    assert powsimp((x**y)**(x*y)) == (x*y)**(x*y)\n    assert powsimp((x**y)**(x*y), combine='exp') == x**(y*(x*y))\n    assert powsimp((x**y)**(x*y), combine='base') == (x**y)**(x*y)\n"], "sample_934": ["def test_template_args():\n    check('function', \"template<typename T> void f(T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T,"], "sample_132": ["    def test_non_sensitive_request(self):\n        \"\"\"\n        Request info can bee seen in the default error reports for non-sensitive requests.\n        \"\"\"\n        with self.settings(DEBUG=True):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n\n        with self.settings(DEBUG=False):\n            self.verify_unsafe_response(non_sensitive_view, check_for_vars=False)\n"], "sample_731": ["def test_california_housing_feature_names():\n    \"\"\"Test that the feature names are correctly returned.\"\"\"\n    data = fetch_california_housing(return_X_y=True)\n    expected_feature_names = [\"MedInc\", \"HouseAge\", \"AveRooms\", \"AveBedrms\",\n                             \"Population\", \"AveOccup\", \"Latitude\", \"Longitude\"]\n    assert np.array_equal(data[0].feature_names, expected_feature_names)\n"], "sample_603": ["def test_repr_of_dataset_with_empty_attributes(dataset):\n    dataset.attrs = {}\n    formatted = fh.dataset_repr(dataset)\n    # coords, attrs, and data_vars are expanded\n    assert (\n        formatted.count(\"class='xr-section-summary-in' type='checkbox'  checked>\") == 3\n    )\n    assert \"&lt;U4\" in formatted or \"&gt;U4\" in formatted\n    assert \"&lt;IA&gt;\" in formatted\n\n    with xr.set_options(\n        display_expand_coords=False,\n        display_expand_data_vars=False,\n        display_expand_attrs=False,\n    ):\n        formatted = fh.dataset_repr(dataset)\n        # coords, attrs, and data_vars are collapsed\n        assert (\n            formatted.count(\"class='xr-section-summary-in' type='checkbox'  checked>\")\n            == 0\n        )\n        assert \"&lt;U4\" in formatted or \"&gt;U4\" in formatted\n        assert \"&lt;IA&gt;\" in formatted\n"], "sample_935": ["def test_template_specialization():\n    check('class', \"template<> {key}A\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<int>\", {2: \"IE1AI1iE\"})\n    check('class', \"template<> {key}A<int, int>\", {2: \"IE1AI1iE1iE\"})\n    check('class', \"template<> {key}A<int, int, int>\", {2: \"IE1AI1iE1iE1iE\"})\n    check('class', \"template<> {key}A<int, int, int, int>\", {2: \"IE1AI1iE1iE1iE1iE\"})\n    check('class', \"template<> {key}A<int, int, int, int, int>\", {2: \"IE1AI1iE1iE1iE1iE1iE\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int>\", {2: \"IE1AI1iE1iE1iE1iE1iE1iE\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int>\", {2: \"IE1AI1iE1iE1iE1iE1iE1iE1iE\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int, int>\", {2: \"IE1AI1iE1iE1iE1iE1iE1iE1iE1iE\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int, int, int>\", {2: \"IE1AI1iE1iE1iE1iE1iE1iE1iE1iE1iE\"})\n    check('class', \"template<> {key}A<int, int, int, int, int, int, int, int, int, int>\", {2: \"IE1AI1iE1iE1iE1iE1iE1iE1iE1iE1iE1iE\"})\n   "], "sample_923": ["def test_template_args():\n    check('function', 'template<typename T> void f(T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T,"], "sample_302": ["    def test_settings_to_cmd_args_env_with_all_options(self):\n        settings_dict = {\n            'OPTIONS': {\n                'passfile': 'passfile',\n                'service': 'service',\n                'sslmode': 'sslmode',\n                'sslrootcert': 'sslrootcert',\n                'sslcert': 'sslcert',\n                'sslkey': 'sslkey'\n            },\n            'HOST': 'host',\n            'PORT': 1234,\n            'NAME': 'dbname',\n            'USER': 'user',\n            'PASSWORD': 'passwd'\n        }\n        parameters = ['param1', 'param2']\n        args, env = DatabaseClient.settings_to_cmd_args_env(settings_dict, parameters)\n        self.assertEqual(args, ['psql', '-U', 'user', '-h', 'host', '-p', '1234', 'dbname', 'param1', 'param2'])\n        self.assertEqual(env, {\n            'PGPASSWORD': 'passwd',\n            'PGSERVICE': 'service',\n            'PGSSLMODE': 'sslmode',\n            'PGSSLROOTCERT': 'sslrootcert',\n            'PGSSLCERT': 'sslcert',\n            'PGSSLKEY': 'sslkey',\n            'PGPASSFILE': 'passfile'\n        })\n"], "sample_732": ["def test_percent10_return_X_y():\n    try:\n        data = fetch_kddcup99(download_if_missing=False, return_X_y=True)\n    except IOError:\n        raise SkipTest(\"kddcup99 dataset can not be loaded.\")\n\n    assert_equal(data[0].shape, (494021, 41))\n    assert_equal(data[1].shape, (494021,))\n\n    data_shuffled = fetch_kddcup99(shuffle=True, random_state=0, return_X_y=True)\n    assert_equal(data[0].shape, data_shuffled[0].shape)\n    assert_equal(data[1].shape, data_shuffled[1].shape)\n\n    data = fetch_kddcup99('SA', return_X_y=True)\n    assert_equal(data[0].shape, (100655, 41))\n    assert_equal(data[1].shape, (100655,))\n\n    data = fetch_kddcup99('SF', return_X_y=True)\n    assert_equal(data[0].shape, (73237, 4))\n    assert_equal(data[1].shape, (73237,))\n\n    data = fetch_kddcup99('http', return_X_y=True)\n    assert_equal(data[0].shape, (58725, 3))\n    assert_equal(data[1].shape, (58725,))\n\n    data = fetch_kddcup99('smtp', return_X_y=True)\n    assert_equal(data[0].shape, (9571, 3))\n    assert_equal(data[1].shape, (9571,))\n"], "sample_575": ["    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n"], "sample_926": ["def test_template_args_with_default():\n    check('function', 'template<typename T = int> void f()',\n          {2: 'I0E1fv', 4: 'I0E1fiv'})\n"], "sample_279": ["    def setUpTestData(cls):\n        cls.p1, cls.p2 = UniqueConstraintProduct.objects.bulk_create([\n            UniqueConstraintProduct(name='p1', color='red'),\n            UniqueConstraintProduct(name='p2'),\n        ])\n"], "sample_611": ["compilation error"], "sample_1064": ["def test_tensorflow_piecewise():\n    if not tf:\n        skip(\"TensorFlow not installed\")\n\n    expr = Piecewise((x, x > 0), (y, x < 0))\n    assert tensorflow_code(expr) == \"tensorflow.where(x > 0, x, y)\"\n    _compare_tensorflow_scalar((x, y), expr)\n\n    expr = Piecewise((x, x > 0), (y, x < 0), (z, x == 0))\n    assert tensorflow_code(expr) == \"tensorflow.where(x > 0, x, tensorflow.where(x < 0, y, z))\"\n    _compare_tensorflow_scalar((x, y, z), expr)\n\n    expr = Piecewise((x, x > 0), (y, x < 0), (z, x == 0), (w, x == 1))\n    assert tensorflow_code(expr) == \"tensorflow.where(x > 0, x, tensorflow.where(x < 0, tensorflow.where(x == 0, z, w), y))\"\n    _compare_tensorflow_scalar((x, y, z, w), expr)\n\n    expr = Piecewise((x, x > 0), (y, x < 0), (z, x == 0), (w, x == 1), (v, x == 2))\n    assert tensorflow_code(expr) == \"tensorflow.where(x > 0, x, tensorflow.where(x < 0, tensorflow.where(x == 0, tensorflow.where(x == 1, w, z), tensorflow.where(x == 2, v, y))))\"\n\n    expr = Piecewise((x, x > 0), (y, x < 0), (z, x == 0), (w, x == 1), (v, x == 2), (u, x == 3))\n    assert tensorflow_code(expr) == \"tensorflow.where(x > 0, x, tensorflow.where(x < 0, tensorflow.where(x == 0, tensorflow.where(x == 1, tensorflow.where(x == 2, tensorflow.where(x == 3, u, v), w), z), tensorflow.where(x == 2, v, y))))\"\n\n    expr = Piecewise((x, x > 0), (y, x < 0), (z, x == 0), (w, x == 1), (v, x == 2), (u, x"], "sample_948": ["def test_template_specialization():\n    check('class', \"template<> {key}A\", {2: \"IE1A\"})\n    check('class', \"template<> {key}A<NS::B>\", {2: \"IE1AIN2NS1BEEE\"})\n    check('class', \"template<> {key}A<NS::B, C>\", {2: \"IE1AIN2NS1BEE1CE\"})\n    check('class', \"template<> {key}A<NS::B, C, D>\", {2: \"IE1AIN2NS1BEE1CE1DE\"})\n    check('class', \"template<> {key}A<NS::B, C, D, E>\", {2: \"IE1AIN2NS1BEE1CE1DE1EE\"})\n    check('class', \"template<> {key}A<NS::B, C, D, E, F>\", {2: \"IE1AIN2NS1BEE1CE1DE1EE1FE\"})\n    check('class', \"template<> {key}A<NS::B, C, D, E, F, G>\", {2: \"IE1AIN2NS1BEE1CE1DE1EE1FE1GE\"})\n    check('class', \"template<> {key}A<NS::B, C, D, E, F, G, H>\", {2: \"IE1AIN2NS1BEE1CE1DE1EE1FE1GE1HE\"})\n    check('class', \"template<> {key}A<NS::B, C, D, E, F, G, H, I>\", {2: \"IE1AIN2NS1BEE1CE1DE1EE1FE1GE1HE1IE\"})\n    check('class', \"template<> {key}A<NS::B, C, D, E, F, G, H, I, J>\", {2: \"IE1AIN2NS1BEE1CE1DE1EE1FE1GE1HE1IE1JE\"})\n    check('class', \"template<> {key}A<NS::B, C, D, E, F, G, H, I, J, K>\", {2: \"IE1AIN2NS1BEE1CE1DE1EE1FE1GE1HE1IE1"], "sample_1069": ["def test_MatrixElement_printing_issue_14820():\n    # test cases for issue #14820\n    A = MatrixSymbol(\"A\", 1, 3)\n    B = MatrixSymbol(\"B\", 1, 3)\n    C = MatrixSymbol(\"C\", 1, 3)\n\n    assert mcode(A[0, 0] + B[0, 0]) == \"A(1, 1) + B(1, 1)\"\n    assert mcode(A[0, 0] - B[0, 0]) == \"A(1, 1) - B(1, 1)\"\n    assert mcode(A[0, 0] * B[0, 0]) == \"A(1, 1).*B(1, 1)\"\n    assert mcode(A[0, 0] / B[0, 0]) == \"A(1, 1)./B(1, 1)\"\n"], "sample_1125": ["def test_differential_operator():\n    x = symbols('x')\n    f = symbols('f', cls=Function)\n    d = DifferentialOperator(Derivative(f(x), x), f(x))\n    assert d.function == f(x)\n    assert d.variables == (x,)\n    assert d.expr == Derivative(f(x), x)\n    assert d.free_symbols == {x}\n\n    d = DifferentialOperator(Derivative(f(x, y), x) + Derivative(f(x, y), y), f(x, y))\n    assert d.function == f(x, y)\n    assert d.variables == (x, y)\n    assert d.expr == Derivative(f(x, y), x) + Derivative(f(x, y), y)\n    assert d.free_symbols == {x, y}\n\n    w = symbols('w', cls=Wavefunction)\n    assert d._apply_operator_Wavefunction(w) == Wavefunction(f(x), x)\n    assert d._eval_derivative(x) == DifferentialOperator(Derivative(f(x), x), f(x))\n"], "sample_723": ["def test_imputation_axis_error():\n    # Test that an error is raised when axis is not 0 or 1.\n    X = np.array([[1, 2], [3, 4]])\n\n    for axis in [-1, 2, 3]:\n        imputer = SimpleImputer(strategy=\"mean\", axis=axis)\n        assert_raises(ValueError, imputer.fit, X)\n"], "sample_1142": ["def test_matrix_derivative():\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    C = MatrixSymbol('C', 2, 2)\n    D = MatrixSymbol('D', 2, 2)\n    E = MatrixSymbol('E', 2, 2)\n    F = MatrixSymbol('F', 2, 2)\n    G = MatrixSymbol('G', 2, 2)\n    H = MatrixSymbol('H', 2, 2)\n    I = MatrixSymbol('I', 2, 2)\n    J = MatrixSymbol('J', 2, 2)\n    K = MatrixSymbol('K', 2, 2)\n    L = MatrixSymbol('L', 2, 2)\n    M = MatrixSymbol('M', 2, 2)\n    N = MatrixSymbol('N', 2, 2)\n    O = MatrixSymbol('O', 2, 2)\n    P = MatrixSymbol('P', 2, 2)\n    Q = MatrixSymbol('Q', 2, 2)\n    R = MatrixSymbol('R', 2, 2)\n    S = MatrixSymbol('S', 2, 2)\n    T = MatrixSymbol('T', 2, 2)\n    U = MatrixSymbol('U', 2, 2)\n    V = MatrixSymbol('V', 2, 2)\n    W = MatrixSymbol('W', 2, 2)\n    X = MatrixSymbol('X', 2, 2)\n    Y = MatrixSymbol('Y', 2, 2)\n    Z = MatrixSymbol('Z', 2, 2)\n    a = MatrixSymbol('a', 2, 2)\n    b = MatrixSymbol('b', 2, 2)\n    c = MatrixSymbol('c', 2, 2)\n    d = MatrixSymbol('d', 2, 2)\n    e = MatrixSymbol('e', 2, 2)\n    f = MatrixSymbol('f', 2, 2)\n    g = MatrixSymbol('g', 2, 2)\n    h = MatrixSymbol('h', 2, 2)\n    i = MatrixSymbol('i', 2, 2)\n    j = MatrixSymbol('j', 2, 2)\n"], "sample_309": ["    def test_invalid_input(self):\n        for s in ['', 'foo', 'foo bar', 'foo=bar', 'foo=bar=', 'foo=bar=', 'foo=bar=']:\n            with self.assertRaises(ValueError):\n                urlsafe_base64_decode(s)\n"], "sample_1038": ["def test_matrix_derivative():\n    A = MatrixSymbol('A', n, n)\n    B = MatrixSymbol('B', n, n)\n    C = MatrixSymbol('C', n, n)\n    D = MatrixSymbol('D', n, n)\n    E = MatrixSymbol('E', n, n)\n    F = MatrixSymbol('F', n, n)\n    G = MatrixSymbol('G', n, n)\n    H = MatrixSymbol('H', n, n)\n    I = MatrixSymbol('I', n, n)\n    J = MatrixSymbol('J', n, n)\n    K = MatrixSymbol('K', n, n)\n    L = MatrixSymbol('L', n, n)\n    M = MatrixSymbol('M', n, n)\n    N = MatrixSymbol('N', n, n)\n    O = MatrixSymbol('O', n, n)\n    P = MatrixSymbol('P', n, n)\n    Q = MatrixSymbol('Q', n, n)\n    R = MatrixSymbol('R', n, n)\n    S = MatrixSymbol('S', n, n)\n    T = MatrixSymbol('T', n, n)\n    U = MatrixSymbol('U', n, n)\n    V = MatrixSymbol('V', n, n)\n    W = MatrixSymbol('W', n, n)\n    X = MatrixSymbol('X', n, n)\n    Y = MatrixSymbol('Y', n, n)\n    Z = MatrixSymbol('Z', n, n)\n\n    assert (A.diff(A)).shape == (n, n)\n    assert (A.diff(B)).shape == (n, n)\n    assert (A.diff(C)).shape == (n, n)\n    assert (A.diff(D)).shape == (n, n)\n    assert (A.diff(E)).shape == (n, n)\n    assert (A.diff(F)).shape == (n, n)\n    assert (A.diff(G)).shape == (n, n)\n    assert (A.diff(H)).shape == (n, n)\n    assert (A.diff(I)).shape == (n, n)\n    assert (A.diff(J)).shape == (n, n)\n    assert (A.diff(K)).shape == (n, n)\n    assert (A.diff(L)).shape == (n, n)\n    assert (A.diff(M)).shape == (n, n)\n    assert (A.diff(N)).shape == ("], "sample_431": ["    def test_state_attributes(self):\n        a = Article(\n            id=None,\n            headline=\"Parrot programs in Python\",\n            pub_date=datetime(2005, 7, 28),\n        )\n        self.assertIsNone(a._state.db)\n        self.assertTrue(a._state.adding)\n        self.assertEqual(a._state.fields_cache, ModelStateFieldsCacheDescriptor())\n"], "sample_604": ["def test_inline_sparse_repr():\n    from scipy.sparse import coo_matrix\n\n    data = coo_matrix(np.array([[1, 2], [3, 4]]))\n    expected = \"<COO: nnz=4, fill_value=0>\"\n    actual = formatting.inline_sparse_repr(data)\n    assert expected == actual\n\n    data = coo_matrix(np.array([[1, 0], [0, 4]]))\n    expected = \"<COO: nnz=2, fill_value=0>\"\n    actual = formatting.inline_sparse_repr(data)\n    assert expected == actual\n\n    data = coo_matrix(np.array([[1, 0], [0, 0]]))\n    expected = \"<COO: nnz=1, fill_value=0>\"\n    actual = formatting.inline_sparse_repr(data)\n    assert expected == actual\n\n    data = coo_matrix(np.array([[0, 0], [0, 0]]))\n    expected = \"<COO: nnz=0, fill_value=0>\"\n    actual = formatting.inline_sparse_repr(data)\n    assert expected == actual\n\n    data = coo_matrix(np.array([[1, 2], [3, 4]]), fill_value=5)\n    expected = \"<COO: nnz=4, fill_value=5>\"\n    actual = formatting.inline_sparse_repr(data)\n    assert expected == actual\n\n    data = coo_matrix(np.array([[1, 0], [0, 4]]), fill_value=5)\n    expected = \"<COO: nnz=2, fill_value=5>\"\n    actual = formatting.inline_sparse_repr(data)\n    assert expected == actual\n\n    data = coo_matrix(np.array([[1, 0], [0, 0]]), fill_value=5)\n    expected = \"<COO: nnz=1, fill_value=5>\"\n    actual = formatting.inline_sparse_repr(data)\n    assert expected == actual\n\n    data = coo_matrix(np.array([[0, 0], [0, 0]]), fill_value=5)\n    expected = \"<COO: nnz=0, fill_value=5>\"\n    actual = formatting.inline_sparse_repr(data)\n    assert expected == actual\n"], "sample_917": ["def test_template_parameter_lists():\n    check('class', 'template<typename T> A', {2: \"I0E1A\"})\n    check('class', 'template<typename T, typename U> A', {2: \"I00E1A\"})\n    check('class', 'template<typename T, typename U, typename V> A', {2: \"I000E1A\"})\n    check('class', 'template<typename T, typename U, typename V, typename W> A', {2: \"I0000E1A\"})\n    check('class', 'template<typename T, typename U, typename V, typename W, typename X> A', {2: \"I00000E1A\"})\n    check('class', 'template<typename T, typename U, typename V, typename W, typename X, typename Y> A', {2: \"I000000E1A\"})\n    check('class', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z> A', {2: \"I0000000E1A\"})\n    check('class', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename AA> A', {2: \"I00000000E1A\"})\n    check('class', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename AA, typename BB> A', {2: \"I000000000E1A\"})\n    check('class', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename AA, typename BB, typename CC> A', {2: \"I0000000000E1A\"})\n    check('class', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename AA, typename BB, typename CC, typename DD> A', {2: \"I00000000000E1A\"})\n    check('class', 'template<typename T, typename U, typename V, typename W, typename X, typename Y, typename Z, typename AA, typename BB, typename CC, typename DD, typename EE> A', {2: \"I000000000000E1A\"})\n    check('class', 'template<typename T, typename U, typename V, typename"], "sample_1159": ["def test_issue_10519():\n    x = Symbol('x', extended_real=True)\n    assert x.is_finite is None\n    assert x.is_infinite is None\n    assert x.is_extended_real is True\n    assert x.is_real is None\n    assert x.is_complex is None\n    assert x.is_noninteger is None\n    assert x.is_irrational is None\n    assert x.is_imaginary is None\n    assert x.is_positive is None\n    assert x.is_negative is None\n    assert x.is_nonpositive is None\n    assert x.is_nonnegative is None\n    assert x.is_even is None\n    assert x.is_odd is None\n    assert x.is_finite is None\n    assert x.is_infinite is None\n    assert x.is_comparable is True\n    assert x.is_prime is None\n    assert x.is_composite is None\n    assert x.is_number is None\n"], "sample_1173": ["def test_function_exponentiation_application():\n    t = standard_transformations + (function_exponentiation, implicit_multiplication_application)\n    x = Symbol('x')\n    y = Symbol('y')\n    a = Symbol('a')\n    yfcn = Function('y')\n    assert parse_expr(\"sin**2(x)\", transformations=t) == sin(x)**2\n    assert parse_expr(\"sin**y(x)\", transformations=t) == sin(x)**y\n    assert parse_expr(\"exp**y(x)\", transformations=t) == exp(x)**y\n    assert parse_expr(\"E**y(x)\", transformations=t) == exp(yfcn(x))\n    assert parse_expr(\"a**y(x)\", transformations=t) == a**(yfcn(x))\n"], "sample_1034": ["def test_apply_grover():\n        return qubits == IntQubit(3)\n\n    nqubits = 2\n    expected = IntQubit(3, nqubits=nqubits)\n    assert qapply(apply_grover(return_one_on_three, nqubits)) == expected\n\n    nqubits = 4\n    expected = (-13*superposition_basis(nqubits))/64 + 264*IntQubit(2, nqubits)/256\n    assert qapply(apply_grover(return_one_on_two, nqubits)) == expected\n\n    nqubits = 1\n    try:\n        apply_grover(return_one_on_two, nqubits)\n        assert False, \"Expected QuantumError for nqubits <= 0\"\n    except QuantumError as e:\n        assert str(e) == 'Grover\\'s algorithm needs nqubits > 0, received 1 qubits'\n\n    nqubits = 0\n    try:\n        apply_grover(return_one_on_two, nqubits)\n        assert False, \"Expected QuantumError for nqubits <= 0\"\n    except QuantumError as e:\n        assert str(e) == 'Grover\\'s algorithm needs nqubits > 0, received 0 qubits'\n"], "sample_437": ["    def test_thread_sharing(self):\n        conn = connections[DEFAULT_DB_ALIAS]\n        conn.inc_thread_sharing()\n        self.assertTrue(conn.allow_thread_sharing)\n        self.assertEqual(conn._thread_sharing_count, 1)\n        conn.dec_thread_sharing()\n        self.assertFalse(conn.allow_thread_sharing)\n        self.assertEqual(conn._thread_sharing_count, 0)\n"], "sample_1155": ["def test_construct_domain_with_multiple_extensions():\n    alg1 = QQ.algebraic_field(sqrt(2))\n    alg2 = QQ.algebraic_field(sqrt(3))\n\n    assert construct_domain([7, sqrt(2), sqrt(3)], extension=True) == \\\n        (alg1.algebraic_field(sqrt(3)), [alg1.algebraic_field(sqrt(3)).convert(7), alg1.convert(sqrt(2)), alg2.convert(sqrt(3))])\n\n    alg3 = QQ.algebraic_field(sqrt(2) + sqrt(3))\n\n    assert construct_domain([7, sqrt(2), sqrt(3)], extension=True) == \\\n        (alg3, [alg3.convert(7), alg3.convert(sqrt(2)), alg3.convert(sqrt(3))])\n\n    alg4 = QQ.algebraic_field(sqrt(2) + sqrt(3) + sqrt(5))\n\n    assert construct_domain([7, sqrt(2), sqrt(3), sqrt(5)], extension=True) == \\\n        (alg4, [alg4.convert(7), alg4.convert(sqrt(2)), alg4.convert(sqrt(3)), alg4.convert(sqrt(5))])\n\n    alg5 = QQ.algebraic_field(sqrt(2) + sqrt(3) + sqrt(5) + sqrt(7))\n\n    assert construct_domain([7, sqrt(2), sqrt(3), sqrt(5), sqrt(7)], extension=True) == \\\n        (alg5, [alg5.convert(7), alg5.convert(sqrt(2)), alg5.convert(sqrt(3)), alg5.convert(sqrt(5)), alg5.convert(sqrt(7))])\n"], "sample_1037": ["def test_MatMul_refine():\n    from sympy import MatrixSymbol, Q, assuming, refine\n    A = MatrixSymbol('A', 2, 2)\n    B = MatrixSymbol('B', 2, 2)\n    with assuming(Q.orthogonal(A)):\n        assert refine(A*B).is_Identity\n    with assuming(Q.orthogonal(B)):\n        assert refine(B*A).is_Identity\n    with assuming(Q.unitary(A)):\n        assert refine(A.conjugate()).is_Identity\n    with assuming(Q.unitary(B)):\n        assert refine(B.conjugate()).is_Identity\n"], "sample_1063": ["def test_lambdify_with_tensorflow_and_numpy():\n    if not tensorflow:\n        skip(\"tensorflow not installed.\")\n    if not numpy:\n        skip(\"numpy not installed.\")\n    expr = Max(sin(x), Abs(1/(x+2)))\n    func = lambdify(x, expr, modules=[\"tensorflow\", \"numpy\"])\n    with tensorflow.compat.v1.Session() as s:\n        a = tensorflow.constant(0, dtype=tensorflow.float32)\n        assert func(a).eval(session=s) == 0.5\n"], "sample_586": ["def test_concat_compat_no_conflicts():\n    ds1 = Dataset(\n        {\n            \"has_x_y\": ((\"y\", \"x\"), [[1, 2]]),\n            \"has_x\": (\"x\", [1, 2]),\n            \"no_x_y\": (\"z\", [1, 2]),\n        },\n        coords={\"x\": [0, 1], \"y\": [0], \"z\": [-1, -2]},\n    )\n    ds2 = Dataset(\n        {\n            \"has_x_y\": ((\"y\", \"x\"), [[3, 4]]),\n            \"has_x\": (\"x\", [1, 2]),\n            \"no_x_y\": ((\"q\", \"z\"), [[1, 2]]),\n        },\n        coords={\"x\": [0, 1], \"y\": [1], \"z\": [-1, -2], \"q\": [0]},\n    )\n\n    result = concat([ds1, ds2], dim=\"y\", data_vars=\"minimal\", compat=\"no_conflicts\")\n    assert_equal(ds2.no_x_y, result.no_x_y.transpose())\n\n    for var in [\"has_x\", \"no_x_y\"]:\n        assert \"y\" not in result[var]\n\n    with raises_regex(ValueError, \"'q' is not present in all datasets\"):\n        concat([ds1, ds2], dim=\"q\", data_vars=\"all\", compat=\"no_conflicts\")\n"], "sample_780": ["def test_lda_learning_decay():\n    # Test LDA learning decay for online learning\n    # perplexity should be lower after each iteration\n    n_components, X = _build_sparse_mtx()\n    lda_1 = LatentDirichletAllocation(n_components=n_components,\n                                      max_iter=1, learning_method='online',\n                                      learning_decay=0.9, random_state=0)\n    lda_2 = LatentDirichletAllocation(n_components=n_components,\n                                      max_iter=10, learning_method='online',\n                                      learning_decay=0.9, random_state=0)\n    lda_1.fit(X)\n    perp_1 = lda_1.perplexity(X, sub_sampling=False)\n\n    lda_2.fit(X)\n    perp_2 = lda_2.perplexity(X, sub_sampling=False)\n    assert_greater_equal(perp_1, perp_2)\n\n    perp_1_subsampling = lda_1.perplexity(X, sub_sampling=True)\n    perp_2_subsampling = lda_2.perplexity(X, sub_sampling=True)\n    assert_greater_equal(perp_1_subsampling, perp_2_subsampling)\n\n    # Test learning decay with different values\n    lda_3 = LatentDirichletAllocation(n_components=n_components,\n                                      max_iter=1, learning_method='online',\n                                      learning_decay=0.5, random_state=0)\n    lda_4 = LatentDirichletAllocation(n_components=n_components,\n                                      max_iter=10, learning_method='online',\n                                      learning_decay=0.5, random_state=0)\n    lda_3.fit(X)\n    perp_3 = lda_3.perplexity(X, sub_sampling=False)\n\n    lda_4.fit(X)\n    perp_4 = lda_4.perplexity(X, sub_sampling=False)\n    assert_greater_equal(perp_3, perp_4)\n\n    perp_3_subsampling = lda_3.perplexity(X, sub_sampling=True)\n    perp_4_subsampling = lda_4.perplexity(X, sub_sampling=True)\n    assert_greater_equal(perp_3_subsampling, perp_4_subsampling)\n"], "sample_1075": ["def test_beta_function_eval():\n    x, y = Symbol('x'), Symbol('y')\n    beta_func = beta(x, y)\n    assert beta_func._eval_expand_func() == gamma(x)*gamma(y) / gamma(x + y)\n"], "sample_906": ["def test_domain_cpp_ast_macros():\n    check('macro', 'void f()', {1: 'f', 2: '1fv'})\n    check('macro', 'void f(int)', {1: 'f__i', 2: '1f1i'})\n    check('macro', 'void f(int, int)', {1: 'f__i.i', 2: '1f1i1i'})\n    check('macro', 'void f(int, int, int)', {1: 'f__i.i.i', 2: '1f1i1i1i'})\n    check('macro', 'void f(int, int, int, int)', {1: 'f__i.i.i.i', 2: '1f1i1i1i1i'})\n    check('macro', 'void f(int, int, int, int, int)', {1: 'f__i.i.i.i.i', 2: '1f1i1i1i1i1i'})\n    check('macro', 'void f(int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i', 2: '1f1i1i1i1i1i1i'})\n    check('macro', 'void f(int, int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i.i', 2: '1f1i1i1i1i1i1i1i'})\n    check('macro', 'void f(int, int, int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i.i.i', 2: '1f1i1i1i1i1i1i1i1i'})\n    check('macro', 'void f(int, int, int, int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i.i.i.i', 2: '1f1i1i1i1i1i1i1i1i1i'})\n    check('macro', 'void f(int, int, int, int, int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i.i.i.i.i', 2: '1f1i1i1i"], "sample_825": ["def test_pls_transform_copy():\n    # check that the \"copy\" keyword works\n    d = load_linnerud()\n    X = d.data\n    Y = d.target\n    clf = pls_.PLSCanonical()\n    X_copy = X.copy()\n    Y_copy = Y.copy()\n    clf.fit(X, Y)\n    # check that results are identical with copy\n    assert_array_almost_equal(clf.transform(X, copy=False), clf.transform(X))\n    assert_array_almost_equal(clf.transform(X, Y, copy=False), clf.transform(X, Y))\n    # check that copy doesn't destroy\n    # we do want to check exact equality here\n    assert_array_equal(X_copy, X)\n    assert_array_equal(Y_copy, Y)\n    # also check that mean wasn't zero before (to make sure we didn't touch it)\n    assert np.all(X.mean(axis=0) != 0)\n"], "sample_1004": ["def test_CondSet_base_set():\n    C = ConditionSet\n    I = S.Integers\n    assert C(x, x < 1, C(x, x < 2, I)) == C(x, (x < 1) & (x < 2), I)\n    assert C(x, x < 1, C(y, y < 2, I)) == C(x, (x < 1) & (y < 2), I)\n    assert C(x, x < 1, C(x, y < x, I)) == C(x, (x < 1) & (y < x), I)\n    assert C(x, x < 1, C(x, x < y, I)) == C(x, (x < 1) & (x < y), I)\n    assert C(x, x < 1, C(x, x < y, FiniteSet(x, y))) == C(x, (x < 1) & (x < y), FiniteSet(x, y))\n    assert C(x, x < 1, C(x, x < y, C(x, y < x, I))) == C(x, (x < 1) & (x < y) & (y < x), I)\n    assert C(x, x < 1, C(x, x < y, C(y, y < x, I))) == C(x, (x < 1) & (x < y) & (y < x), I)\n    assert C(x, x < 1, C(x, x < y, C(x, y < x, FiniteSet(x, y)))) == C(x, (x < 1) & (x < y) & (x < y), FiniteSet(x, y))\n"], "sample_958": ["def test_domain_cpp_ast_macros():\n    check('macro', 'void f()', {1: 'f', 2: '1f'})\n    check('macro', 'void f(int)', {1: 'f__i', 2: '1f1i'})\n    check('macro', 'void f(int, int)', {1: 'f__i.i', 2: '1f2i1i'})\n    check('macro', 'void f(int, int, int)', {1: 'f__i.i.i', 2: '1f3i1i1i'})\n    check('macro', 'void f(int, int, int, int)', {1: 'f__i.i.i.i', 2: '1f4i1i1i1i'})\n    check('macro', 'void f(int, int, int, int, int)', {1: 'f__i.i.i.i.i', 2: '1f5i1i1i1i1i'})\n    check('macro', 'void f(int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i', 2: '1f6i1i1i1i1i1i'})\n    check('macro', 'void f(int, int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i.i', 2: '1f7i1i1i1i1i1i1i'})\n    check('macro', 'void f(int, int, int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i.i.i', 2: '1f8i1i1i1i1i1i1i1i'})\n    check('macro', 'void f(int, int, int, int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i.i.i.i', 2: '1f9i1i1i1i1i1i1i1i1i'})\n    check('macro', 'void f(int, int, int, int, int, int, int, int, int, int)', {1: 'f__i.i.i.i.i.i.i.i.i.i', 2: '1f10i1i1i"], "sample_303": ["def test_runshell(self):\n    with mock.patch('subprocess.run') as mock_run:\n        self.client.runshell(None)\n        mock_run.assert_called_once_with([], env=None, check=True)\n"], "sample_1126": ["def test_dagger_on_expr():\n    x = symbols('x')\n    expr = x + 2*x\n    assert Dagger(expr) == Dagger(x) + Dagger(2)*Dagger(x)\n    assert Dagger(expr) == Dagger(2)*Dagger(x) + Dagger(x)\n\n    expr = x**2\n    assert Dagger(expr) == Dagger(x)**2\n\n    expr = x + I*x\n    assert Dagger(expr) == Dagger(x) + Dagger(I)*Dagger(x)\n    assert Dagger(expr) == Dagger(I)*Dagger(x) + Dagger(x)\n"], "sample_1117": ["def test_matrix_element_sets_slices_blocks():\n    X = MatrixSymbol('X', 4, 4)\n    assert ask(Q.real_elements(X[1, :]), Q.real_elements(X))\n    assert ask(Q.integer_elements(X[1, :]), Q.integer_elements(X))\n    assert ask(Q.complex_elements(X[1, :]), Q.complex_elements(X))\n    assert ask(Q.real_elements(X[:, 1]), Q.real_elements(X))\n    assert ask(Q.integer_elements(X[:, 1]), Q.integer_elements(X))\n    assert ask(Q.complex_elements(X[:, 1]), Q.complex_elements(X))\n    assert ask(Q.real_elements(X[1:3, 1:3]), Q.real_elements(X))\n    assert ask(Q.integer_elements(X[1:3, 1:3]), Q.integer_elements(X))\n    assert ask(Q.complex_elements(X[1:3, 1:3]), Q.complex_elements(X))\n    from sympy.matrices.expressions import BlockMatrix\n    assert ask(Q.real_elements(BlockMatrix([[X], [X]])), Q.real_elements(X))\n    assert ask(Q.integer_elements(BlockMatrix([[X], [X]])), Q.integer_elements(X))\n    assert ask(Q.complex_elements(BlockMatrix([[X], [X]])), Q.complex_elements(X))\n"], "sample_1035": ["def test_measure_all():\n    nqubits = 2\n    basis_states = superposition_basis(nqubits)\n    assert measure_all(basis_states) == [\n        (basis_states, 1/4),\n        (IntQubit(1, nqubits=nqubits), 1/4),\n        (IntQubit(2, nqubits=nqubits), 1/4),\n        (IntQubit(3, nqubits=nqubits), 1/4)\n    ]\n\n    nqubits = 3\n    basis_states = superposition_basis(nqubits)\n    assert measure_all(basis_states) == [\n        (basis_states, 1/8),\n        (IntQubit(1, nqubits=nqubits), 1/8),\n        (IntQubit(2, nqubits=nqubits), 1/8),\n        (IntQubit(3, nqubits=nqubits), 1/8),\n        (IntQubit(4, nqubits=nqubits), 1/8),\n        (IntQubit(5, nqubits=nqubits), 1/8),\n        (IntQubit(6, nqubits=nqubits), 1/8),\n        (IntQubit(7, nqubits=nqubits), 1/8)\n    ]\n\n    nqubits = 2\n    basis_states = superposition_basis(nqubits)\n    assert measure_all(basis_states, normalize=False) == [\n        (basis_states, 1/4),\n        (IntQubit(1, nqubits=nqubits), 1/4),\n        (IntQubit(2, nqubits=nqubits), 1/4),\n        (IntQubit(3, nqubits=nqubits), 1/4)\n    ]\n\n    nqubits = 3\n    basis_states = superposition_basis(nqubits)\n    assert measure_all(basis_states, normalize=False) == [\n        (basis_states, 1/8),\n        (IntQubit(1, nqubits=nqubits), 1/8),\n        (IntQubit(2, nqubits=nqubits), 1/8),\n        (IntQubit(3, nqubits=nqubits), 1/8),\n        (IntQubit(4, nqubits=nqubits), "], "sample_1116": ["def test_inverse_conjugate():\n    from sympy import conjugate\n    assert refine(Inverse(C), Q.orthogonal(C)) == C.conjugate().T\n    assert refine(Inverse(C), Q.unitary(C)) == C.conjugate()\n    assert refine(Inverse(C), Q.singular(C)) == C\n\n    assert refine(Inverse(C)*C, Q.orthogonal(C)) == Identity(C.rows)\n    assert refine(Inverse(C)*C, Q.unitary(C)) == C.conjugate()\n    assert refine(Inverse(C)*C, Q.singular(C)) == ZeroMatrix(C.rows, C.cols)\n\n    assert refine(C*Inverse(C), Q.orthogonal(C)) == Identity(C.rows)\n    assert refine(C*Inverse(C), Q.unitary(C)) == C.conjugate()\n    assert refine(C*Inverse(C), Q.singular(C)) == ZeroMatrix(C.rows, C.cols)\n"], "sample_779": ["def test_check_estimators_pickle():\n    # Test that we can pickle all estimators\n    check_methods = [\"predict\", \"transform\", \"decision_function\",\n                     \"predict_proba\"]\n\n    X, y = make_blobs(n_samples=30, centers=[[0, 0, 0], [1, 1, 1]],\n                      random_state=0, n_features=2, cluster_std=0.1)\n\n    # some estimators can't do features less than 0\n    X -= X.min()\n    X = pairwise_estimator_convert_X(X, LinearRegression())\n    y = multioutput_estimator_convert_y_2d(LinearRegression(), y)\n\n    estimator = clone(LinearRegression())\n    set_random_state(estimator)\n    estimator.fit(X, y)\n\n    result = dict()\n    for method in check_methods:\n        if hasattr(estimator, method):\n            result[method] = getattr(estimator, method)(X)\n\n    # pickle and unpickle!\n    pickled_estimator = pickle.dumps(estimator)\n    unpickled_estimator = pickle.loads(pickled_estimator)\n\n    result = dict()\n    for method in check_methods:\n        if hasattr(estimator, method):\n            result[method] = getattr(estimator, method)(X)\n\n    for method in result:\n        unpickled_result = getattr(unpickled_estimator, method)(X)\n        assert_allclose_dense_sparse(result[method], unpickled_result)\n"], "sample_454": ["    def setUpTestData(cls):\n        cls.p1 = ExclusionConstraintProduct.objects.create(name=\"p1\", color=\"red\")\n        cls.p2 = ExclusionConstraintProduct.objects.create(name=\"p2\")\n"], "sample_1087": ["def test_fateman_poly_F_3():\n    f, g, h = fateman_poly_F_3(1)\n    F, G, H = dmp_fateman_poly_F_3(1, ZZ)\n\n    assert [ t.rep.rep for t in [f, g, h] ] == [F, G, H]\n\n    f, g, h = fateman_poly_F_3(3)\n    F, G, H = dmp_fateman_poly_F_3(3, ZZ)\n\n    assert [ t.rep.rep for t in [f, g, h] ] == [F, G, H]\n"], "sample_243": ["def test_transform_with_lookup(self):\n    query = Query(Author, alias_cols=False)\n    with register_lookup(CharField, Lower):\n        where = query.build_where(Q(name__lower__startswith='foo'))\n    lookup = where.children[0]\n    self.assertIsInstance(lookup, Exact)\n    self.assertIsInstance(lookup.lhs, Lower)\n    self.assertIsInstance(lookup.lhs.lhs, Col)\n    self.assertIsNone(lookup.lhs.lhs.alias)\n    self.assertEqual(lookup.lhs.lhs.target, Author._meta.get_field('name'))\n    self.assertIsInstance(lookup.rhs, Col)\n    self.assertIsNone(lookup.rhs.alias)\n    self.assertEqual(lookup.rhs.target, Author._meta.get_field('name'))\n    self.assertEqual(lookup.rhs.output_field, CharField())\n    self.assertEqual(lookup.rhs.output_field.max_length, 255)\n"], "sample_1025": ["def test_PythonCodePrinter_Piecewise():\n    prntr = PythonCodePrinter()\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6))) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n    assert prntr.doprint(Piecewise((2, Le(x, 0)),\n                        (3, Gt(x, 0)), evaluate=False)) == '((2) if (x <= 0) else'\\\n                                                        ' (3) if (x > 0) else None)'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6), default=3)) == '((1) if (x == 0) else (2) if (x > 6) else 3)'\n    assert prntr.doprint(Piecewise((1, Eq(x, 0)),\n                        (2, x>6), default=None)) == '((1) if (x == 0) else (2) if (x > 6) else None)'\n"], "sample_976": ["def test_Dummy_sort_key():\n    d1 = Dummy('d')\n    d2 = Dummy('d')\n    d3 = Dummy('e')\n    d4 = Dummy('e')\n\n    assert d1.sort_key() < d2.sort_key()\n    assert d3.sort_key() < d4.sort_key()\n    assert d1.sort_key() < d3.sort_key()\n    assert d2.sort_key() < d4.sort_key()\n"], "sample_907": ["def test_domain_cpp_ast_template_declarations():\n    check('class', 'template<typename T> {key}A', {2: 'I0E1A'})\n    check('class', 'template<typename T> {key}A<T>', {2: 'I0E1AI1TE'})\n    check('class', 'template<typename T> {key}A<T, U>', {2: 'I0E1AI1TE1UE'})\n    check('class', 'template<typename T> {key}A<T, U, V>', {2: 'I0E1AI1TE1UE1VE'})\n    check('class', 'template<typename T> {key}A<T, U, V, W>', {2: 'I0E1AI1TE1UE1VE1WE'})\n    check('class', 'template<typename T> {key}A<T, U, V, W, X>', {2: 'I0E1AI1TE1UE1VE1WE1XE'})\n    check('class', 'template<typename T> {key}A<T, U, V, W, X, Y>', {2: 'I0E1AI1TE1UE1VE1WE1XE1YE'})\n    check('class', 'template<typename T> {key}A<T, U, V, W, X, Y, Z>', {2: 'I0E1AI1TE1UE1VE1WE1XE1YE1ZE'})\n    check('class', 'template<typename T> {key}A<T, U, V, W, X, Y, Z, S>', {2: 'I0E1AI1TE1UE1VE1WE1XE1YE1ZE1SE'})\n    check('class', 'template<typename T> {key}A<T, U, V, W, X, Y, Z, S, T>', {2: 'I0E1AI1TE1UE1VE1WE1XE1YE1ZE1SE1TE'})\n    check('class', 'template<typename T> {key}A<T, U, V, W, X, Y, Z, S, T, U>', {2: 'I0E1AI1TE1UE1VE1WE1XE1YE1ZE1SE1TE1UE'})\n    check('class', 'template<typename T"], "sample_873": ["def test_get_feature_names_out():\n    sel = StepSelector()\n    sel.fit(X, y)\n    assert_array_equal(feature_names_t, sel.get_feature_names_out())\n    assert_array_equal(feature_names_t, sel.get_feature_names_out(input_features=feature_names))\n    with pytest.raises(ValueError):\n        sel.get_feature_names_out(input_features=[\"a\", \"b\", \"c\"])\n"]}, "raw_scored_generations": {"sample_0": [false], "sample_3": [true], "sample_2": [true], "sample_1": [false], "sample_4": [false], "sample_5": [false], "sample_6": [false], "sample_7": [false], "sample_8": [true], "sample_9": [false], "sample_10": [true], "sample_11": [false], "sample_12": [false], "sample_13": [false], "sample_14": [true], "sample_15": [true], "sample_16": [false], "sample_17": [false], "sample_18": [false], "sample_19": [true], "sample_20": [false], "sample_21": [false], "sample_22": [false], "sample_23": [true], "sample_24": [false], "sample_25": [false], "sample_26": [false], "sample_27": [false], "sample_28": [false], "sample_29": [false], "sample_30": [false], "sample_31": [false], "sample_32": [false], "sample_33": [false], "sample_34": [false], "sample_35": [false], "sample_36": [false], "sample_37": [true], "sample_38": [true], "sample_39": [true], "sample_40": [false], "sample_41": [false], "sample_42": [false], "sample_43": [true], "sample_44": [false], "sample_45": [true], "sample_46": [false], "sample_47": [false], "sample_48": [true], "sample_49": [true], "sample_50": [true], "sample_51": [false], "sample_52": [false], "sample_54": [false], "sample_53": [false], "sample_55": [false], "sample_58": [true], "sample_56": [true], "sample_57": [false], "sample_59": [false], "sample_60": [false], "sample_61": [false], "sample_62": [false], "sample_63": [false], "sample_64": [false], "sample_65": [true], "sample_67": [false], "sample_66": [false], "sample_68": [false], "sample_69": [false], "sample_70": [false], "sample_71": [false], "sample_72": [true], "sample_73": [false], "sample_75": [false], "sample_74": [true], "sample_76": [true], "sample_77": [false], "sample_78": [false], "sample_79": [false], "sample_80": [true], "sample_82": [false], "sample_81": [false], "sample_83": [false], "sample_85": [true], "sample_84": [false], "sample_86": [false], "sample_88": [false], "sample_87": [false], "sample_89": [false], "sample_90": [false], "sample_91": [true], "sample_92": [false], "sample_93": [true], "sample_94": [false], "sample_95": [false], "sample_98": [false], "sample_96": [true], "sample_99": [false], "sample_97": [false], "sample_100": [false], "sample_102": [true], "sample_101": [false], "sample_103": [true], "sample_104": [false], "sample_107": [false], "sample_106": [false], "sample_105": [false], "sample_108": [false], "sample_109": [true], "sample_111": [true], "sample_110": [false], "sample_112": [false], "sample_113": [false], "sample_114": [true], "sample_115": [false], "sample_116": [false], "sample_117": [true], "sample_118": [true], "sample_119": [true], "sample_120": [false], "sample_121": [false], "sample_122": [true], "sample_123": [false], "sample_124": [true], "sample_125": [true], "sample_126": [true], "sample_127": [false], "sample_128": [true], "sample_129": [false], "sample_130": [true], "sample_131": [false], "sample_132": [false], "sample_133": [true], "sample_135": [true], "sample_134": [true], "sample_136": [false], "sample_139": [true], "sample_137": [true], "sample_138": [false], "sample_140": [false], "sample_141": [false], "sample_142": [true], "sample_143": [true], "sample_144": [true], "sample_145": [true], "sample_146": [true], "sample_147": [true], "sample_148": [false], "sample_151": [true], "sample_149": [false], "sample_152": [true], "sample_150": [false], "sample_153": [false], "sample_154": [false], "sample_155": [false], "sample_156": [true], "sample_157": [false], "sample_158": [false], "sample_159": [false], "sample_160": [false], "sample_161": [false], "sample_162": [true], "sample_163": [false], "sample_164": [true], "sample_165": [false], "sample_166": [false], "sample_167": [false], "sample_168": [true], "sample_169": [false], "sample_171": [true], "sample_170": [false], "sample_172": [true], "sample_173": [false], "sample_174": [false], "sample_175": [true], "sample_176": [true], "sample_177": [true], "sample_178": [false], "sample_180": [false], "sample_179": [true], "sample_182": [true], "sample_181": [false], "sample_183": [false], "sample_184": [true], "sample_185": [false], "sample_186": [true], "sample_187": [false], "sample_188": [false], "sample_189": [false], "sample_190": [true], "sample_191": [false], "sample_192": [false], "sample_193": [true], "sample_194": [false], "sample_195": [false], "sample_196": [false], "sample_198": [false], "sample_197": [true], "sample_199": [true], "sample_200": [false], "sample_201": [true], "sample_202": [true], "sample_203": [false], "sample_204": [true], "sample_205": [false], "sample_206": [true], "sample_207": [false], "sample_208": [true], "sample_209": [false], "sample_210": [true], "sample_211": [true], "sample_213": [false], "sample_212": [true], "sample_214": [false], "sample_215": [false], "sample_216": [true], "sample_217": [false], "sample_218": [false], "sample_219": [false], "sample_220": [true], "sample_221": [true], "sample_222": [false], "sample_223": [false], "sample_224": [true], "sample_225": [false], "sample_226": [false], "sample_227": [false], "sample_228": [false], "sample_229": [true], "sample_230": [false], "sample_231": [false], "sample_232": [false], "sample_233": [true], "sample_234": [true], "sample_235": [false], "sample_236": [false], "sample_237": [false], "sample_238": [true], "sample_239": [false], "sample_240": [true], "sample_241": [true], "sample_242": [false], "sample_243": [true], "sample_244": [false], "sample_245": [true], "sample_246": [true], "sample_247": [false], "sample_248": [true], "sample_249": [false], "sample_250": [true], "sample_251": [false], "sample_252": [false], "sample_253": [false], "sample_254": [false], "sample_256": [false], "sample_255": [false], "sample_257": [false], "sample_258": [false], "sample_259": [true], "sample_260": [true], "sample_261": [false], "sample_262": [true], "sample_263": [false], "sample_264": [true], "sample_265": [true], "sample_266": [true], "sample_267": [false], "sample_268": [false], "sample_269": [true], "sample_270": [true], "sample_271": [false], "sample_272": [true], "sample_273": [false], "sample_274": [false], "sample_275": [false], "sample_276": [false], "sample_277": [true], "sample_278": [false], "sample_279": [false], "sample_280": [true], "sample_281": [true], "sample_282": [true], "sample_283": [true], "sample_284": [false], "sample_285": [true], "sample_286": [true], "sample_287": [true], "sample_288": [true], "sample_289": [false], "sample_290": [true], "sample_291": [true], "sample_292": [true], "sample_293": [false], "sample_294": [true], "sample_295": [false], "sample_296": [true], "sample_297": [false], "sample_298": [true], "sample_299": [true], "sample_300": [true], "sample_301": [true], "sample_302": [false], "sample_303": [true], "sample_304": [false], "sample_305": [true], "sample_306": [false], "sample_307": [true], "sample_308": [true], "sample_309": [false], "sample_310": [false], "sample_312": [true], "sample_311": [false], "sample_313": [false], "sample_314": [false], "sample_315": [false], "sample_316": [false], "sample_317": [true], "sample_318": [false], "sample_319": [true], "sample_320": [true], "sample_321": [false], "sample_322": [true], "sample_323": [true], "sample_324": [false], "sample_325": [true], "sample_326": [false], "sample_327": [false], "sample_328": [true], "sample_329": [false], "sample_330": [false], "sample_331": [false], "sample_332": [false], "sample_333": [true], "sample_334": [false], "sample_335": [false], "sample_336": [false], "sample_337": [true], "sample_338": [true], "sample_339": [false], "sample_340": [true], "sample_341": [false], "sample_342": [true], "sample_343": [true], "sample_344": [true], "sample_345": [false], "sample_346": [false], "sample_347": [true], "sample_348": [true], "sample_349": [false], "sample_350": [true], "sample_351": [true], "sample_352": [false], "sample_353": [false], "sample_354": [false], "sample_355": [false], "sample_356": [true], "sample_357": [true], "sample_358": [true], "sample_359": [true], "sample_360": [false], "sample_361": [true], "sample_362": [true], "sample_363": [true], "sample_364": [false], "sample_365": [false], "sample_366": [false], "sample_367": [false], "sample_368": [true], "sample_369": [true], "sample_370": [false], "sample_371": [false], "sample_372": [false], "sample_373": [false], "sample_374": [false], "sample_375": [true], "sample_376": [true], "sample_377": [false], "sample_378": [false], "sample_379": [true], "sample_380": [true], "sample_381": [true], "sample_382": [true], "sample_383": [false], "sample_384": [false], "sample_385": [false], "sample_386": [true], "sample_387": [true], "sample_388": [false], "sample_389": [false], "sample_390": [true], "sample_391": [true], "sample_392": [true], "sample_393": [true], "sample_394": [false], "sample_395": [true], "sample_396": [false], "sample_397": [false], "sample_398": [false], "sample_399": [false], "sample_400": [true], "sample_401": [true], "sample_402": [true], "sample_403": [false], "sample_404": [true], "sample_405": [true], "sample_406": [false], "sample_407": [true], "sample_408": [true], "sample_409": [true], "sample_410": [false], "sample_411": [true], "sample_412": [false], "sample_413": [false], "sample_414": [true], "sample_415": [false], "sample_416": [true], "sample_417": [false], "sample_418": [true], "sample_419": [true], "sample_420": [false], "sample_421": [false], "sample_422": [false], "sample_423": [true], "sample_424": [true], "sample_425": [false], "sample_426": [true], "sample_427": [true], "sample_428": [false], "sample_429": [true], "sample_430": [true], "sample_431": [false], "sample_432": [true], "sample_433": [true], "sample_434": [false], "sample_435": [false], "sample_436": [true], "sample_437": [true], "sample_438": [true], "sample_439": [true], "sample_440": [false], "sample_441": [false], "sample_442": [true], "sample_443": [false], "sample_444": [false], "sample_445": [true], "sample_446": [false], "sample_447": [false], "sample_448": [false], "sample_449": [false], "sample_450": [true], "sample_451": [true], "sample_453": [false], "sample_452": [false], "sample_454": [false], "sample_455": [false], "sample_456": [true], "sample_457": [false], "sample_458": [false], "sample_459": [false], "sample_460": [false], "sample_461": [false], "sample_462": [false], "sample_463": [true], "sample_464": [true], "sample_465": [false], "sample_466": [false], "sample_467": [false], "sample_469": [false], "sample_468": [true], "sample_470": [false], "sample_471": [false], "sample_472": [true], "sample_473": [false], "sample_474": [false], "sample_475": [false], "sample_476": [false], "sample_477": [true], "sample_478": [false], "sample_479": [true], "sample_480": [true], "sample_481": [false], "sample_482": [false], "sample_483": [false], "sample_484": [false], "sample_485": [false], "sample_486": [true], "sample_487": [true], "sample_488": [false], "sample_489": [true], "sample_490": [true], "sample_491": [true], "sample_492": [false], "sample_493": [false], "sample_494": [false], "sample_495": [true], "sample_496": [false], "sample_497": [true], "sample_498": [true], "sample_499": [true], "sample_500": [false], "sample_501": [true], "sample_502": [false], "sample_503": [true], "sample_504": [true], "sample_505": [false], "sample_506": [false], "sample_507": [true], "sample_508": [false], "sample_509": [false], "sample_510": [false], "sample_511": [false], "sample_512": [false], "sample_513": [true], "sample_514": [false], "sample_515": [false], "sample_516": [false], "sample_517": [false], "sample_518": [false], "sample_519": [false], "sample_520": [false], "sample_521": [false], "sample_522": [false], "sample_523": [true], "sample_524": [false], "sample_525": [false], "sample_526": [false], "sample_527": [true], "sample_528": [true], "sample_529": [true], "sample_530": [false], "sample_531": [false], "sample_532": [false], "sample_533": [true], "sample_534": [false], "sample_535": [false], "sample_536": [false], "sample_537": [true], "sample_538": [false], "sample_539": [false], "sample_540": [false], "sample_541": [false], "sample_542": [false], "sample_543": [false], "sample_544": [false], "sample_545": [false], "sample_546": [false], "sample_547": [false], "sample_548": [false], "sample_549": [false], "sample_550": [false], "sample_551": [false], "sample_552": [false], "sample_553": [false], "sample_554": [false], "sample_555": [false], "sample_556": [false], "sample_557": [false], "sample_558": [false], "sample_559": [false], "sample_560": [true], "sample_561": [false], "sample_562": [false], "sample_563": [false], "sample_564": [false], "sample_565": [false], "sample_566": [false], "sample_567": [false], "sample_568": [false], "sample_569": [false], "sample_570": [false], "sample_571": [true], "sample_572": [false], "sample_573": [false], "sample_574": [false], "sample_575": [false], "sample_576": [false], "sample_577": [false], "sample_578": [true], "sample_579": [true], "sample_580": [false], "sample_581": [false], "sample_582": [false], "sample_583": [true], "sample_584": [false], "sample_585": [false], "sample_586": [true], "sample_587": [true], "sample_588": [false], "sample_589": [false], "sample_590": [false], "sample_591": [true], "sample_592": [false], "sample_593": [false], "sample_594": [false], "sample_595": [true], "sample_596": [true], "sample_597": [false], "sample_598": [false], "sample_599": [false], "sample_600": [false], "sample_601": [false], "sample_602": [false], "sample_603": [false], "sample_604": [false], "sample_605": [false], "sample_606": [false], "sample_607": [false], "sample_608": [false], "sample_609": [false], "sample_610": [false], "sample_611": [false], "sample_612": [true], "sample_613": [false], "sample_614": [false], "sample_615": [false], "sample_616": [true], "sample_617": [false], "sample_618": [false], "sample_619": [false], "sample_620": [false], "sample_621": [false], "sample_622": [true], "sample_623": [false], "sample_624": [false], "sample_625": [false], "sample_626": [false], "sample_627": [false], "sample_628": [false], "sample_629": [true], "sample_630": [false], "sample_631": [false], "sample_632": [false], "sample_633": [false], "sample_634": [false], "sample_635": [false], "sample_636": [false], "sample_637": [false], "sample_638": [false], "sample_639": [false], "sample_640": [false], "sample_641": [false], "sample_642": [false], "sample_643": [false], "sample_644": [false], "sample_645": [false], "sample_646": [false], "sample_647": [false], "sample_648": [false], "sample_649": [false], "sample_650": [false], "sample_651": [false], "sample_652": [true], "sample_653": [false], "sample_654": [true], "sample_655": [true], "sample_656": [false], "sample_657": [false], "sample_658": [true], "sample_659": [false], "sample_660": [false], "sample_661": [false], "sample_662": [false], "sample_663": [true], "sample_664": [false], "sample_665": [true], "sample_666": [false], "sample_667": [false], "sample_668": [false], "sample_669": [false], "sample_670": [false], "sample_671": [true], "sample_672": [false], "sample_673": [false], "sample_674": [false], "sample_675": [false], "sample_676": [false], "sample_677": [false], "sample_678": [false], "sample_679": [false], "sample_680": [true], "sample_681": [false], "sample_682": [true], "sample_683": [true], "sample_684": [false], "sample_685": [false], "sample_686": [false], "sample_687": [false], "sample_688": [false], "sample_689": [false], "sample_690": [true], "sample_691": [false], "sample_692": [false], "sample_693": [false], "sample_694": [false], "sample_695": [false], "sample_696": [false], "sample_697": [false], "sample_698": [false], "sample_699": [true], "sample_700": [true], "sample_701": [false], "sample_702": [true], "sample_703": [false], "sample_704": [false], "sample_705": [false], "sample_706": [false], "sample_707": [false], "sample_708": [false], "sample_709": [false], "sample_710": [false], "sample_711": [false], "sample_712": [true], "sample_713": [false], "sample_714": [false], "sample_715": [true], "sample_716": [false], "sample_717": [true], "sample_718": [false], "sample_719": [true], "sample_720": [false], "sample_721": [false], "sample_722": [true], "sample_723": [true], "sample_724": [true], "sample_725": [false], "sample_726": [true], "sample_727": [false], "sample_728": [false], "sample_729": [true], "sample_730": [false], "sample_731": [false], "sample_732": [true], "sample_733": [true], "sample_734": [false], "sample_735": [false], "sample_736": [true], "sample_737": [false], "sample_738": [false], "sample_739": [true], "sample_740": [false], "sample_741": [false], "sample_742": [false], "sample_743": [false], "sample_744": [false], "sample_745": [false], "sample_746": [false], "sample_747": [false], "sample_748": [false], "sample_749": [false], "sample_750": [false], "sample_751": [false], "sample_752": [false], "sample_753": [true], "sample_754": [false], "sample_755": [false], "sample_756": [true], "sample_757": [false], "sample_758": [false], "sample_759": [true], "sample_760": [false], "sample_761": [true], "sample_762": [false], "sample_763": [false], "sample_764": [true], "sample_765": [false], "sample_766": [false], "sample_767": [false], "sample_768": [true], "sample_769": [true], "sample_770": [false], "sample_771": [true], "sample_772": [true], "sample_773": [true], "sample_774": [true], "sample_775": [false], "sample_776": [true], "sample_777": [true], "sample_778": [false], "sample_779": [false], "sample_780": [true], "sample_781": [true], "sample_782": [false], "sample_783": [false], "sample_784": [true], "sample_785": [true], "sample_786": [true], "sample_787": [false], "sample_788": [true], "sample_789": [false], "sample_790": [true], "sample_791": [true], "sample_792": [false], "sample_793": [false], "sample_794": [false], "sample_795": [false], "sample_796": [false], "sample_797": [true], "sample_798": [false], "sample_799": [false], "sample_800": [false], "sample_801": [false], "sample_802": [false], "sample_803": [false], "sample_804": [true], "sample_805": [false], "sample_806": [false], "sample_807": [false], "sample_808": [false], "sample_809": [false], "sample_810": [false], "sample_811": [true], "sample_812": [false], "sample_813": [true], "sample_814": [false], "sample_815": [false], "sample_816": [true], "sample_817": [false], "sample_818": [false], "sample_819": [false], "sample_820": [false], "sample_821": [false], "sample_822": [false], "sample_823": [false], "sample_824": [false], "sample_825": [false], "sample_826": [true], "sample_827": [false], "sample_828": [false], "sample_829": [false], "sample_830": [false], "sample_831": [false], "sample_832": [true], "sample_833": [false], "sample_834": [true], "sample_835": [false], "sample_836": [true], "sample_837": [false], "sample_838": [true], "sample_839": [true], "sample_840": [true], "sample_841": [true], "sample_842": [false], "sample_843": [false], "sample_844": [true], "sample_845": [true], "sample_846": [false], "sample_847": [true], "sample_848": [true], "sample_849": [true], "sample_850": [true], "sample_851": [false], "sample_852": [false], "sample_853": [false], "sample_854": [false], "sample_855": [false], "sample_856": [true], "sample_857": [false], "sample_858": [false], "sample_859": [false], "sample_860": [false], "sample_861": [false], "sample_862": [true], "sample_863": [false], "sample_864": [true], "sample_865": [true], "sample_866": [true], "sample_867": [true], "sample_868": [false], "sample_869": [false], "sample_870": [true], "sample_871": [true], "sample_872": [false], "sample_873": [false], "sample_874": [false], "sample_875": [false], "sample_876": [false], "sample_877": [true], "sample_878": [true], "sample_879": [true], "sample_880": [false], "sample_881": [true], "sample_882": [true], "sample_883": [false], "sample_884": [false], "sample_885": [false], "sample_886": [true], "sample_887": [true], "sample_888": [false], "sample_889": [true], "sample_890": [true], "sample_891": [false], "sample_892": [false], "sample_893": [false], "sample_894": [false], "sample_895": [true], "sample_896": [false], "sample_897": [false], "sample_898": [false], "sample_899": [false], "sample_900": [false], "sample_901": [false], "sample_902": [false], "sample_903": [true], "sample_904": [false], "sample_905": [false], "sample_906": [false], "sample_907": [false], "sample_908": [false], "sample_909": [false], "sample_910": [true], "sample_911": [false], "sample_912": [true], "sample_913": [true], "sample_914": [true], "sample_915": [false], "sample_916": [false], "sample_917": [false], "sample_918": [true], "sample_919": [false], "sample_920": [false], "sample_921": [false], "sample_922": [true], "sample_923": [false], "sample_924": [false], "sample_925": [false], "sample_926": [false], "sample_927": [false], "sample_928": [false], "sample_929": [false], "sample_930": [false], "sample_931": [false], "sample_932": [false], "sample_933": [false], "sample_934": [false], "sample_935": [false], "sample_936": [false], "sample_937": [false], "sample_938": [false], "sample_939": [false], "sample_940": [false], "sample_941": [true], "sample_942": [false], "sample_943": [false], "sample_944": [false], "sample_945": [false], "sample_946": [false], "sample_947": [false], "sample_948": [false], "sample_949": [false], "sample_950": [false], "sample_951": [false], "sample_952": [false], "sample_953": [false], "sample_954": [false], "sample_955": [true], "sample_956": [false], "sample_957": [true], "sample_958": [false], "sample_959": [false], "sample_960": [false], "sample_961": [false], "sample_962": [true], "sample_963": [false], "sample_964": [false], "sample_965": [false], "sample_966": [false], "sample_967": [false], "sample_968": [false], "sample_969": [false], "sample_970": [false], "sample_971": [false], "sample_972": [false], "sample_973": [false], "sample_974": [false], "sample_975": [true], "sample_976": [false], "sample_977": [false], "sample_978": [false], "sample_979": [false], "sample_980": [false], "sample_981": [false], "sample_982": [false], "sample_983": [true], "sample_984": [false], "sample_985": [false], "sample_986": [false], "sample_987": [false], "sample_988": [true], "sample_989": [true], "sample_990": [false], "sample_991": [false], "sample_992": [false], "sample_993": [false], "sample_994": [true], "sample_995": [true], "sample_996": [false], "sample_997": [false], "sample_998": [true], "sample_999": [true], "sample_1000": [true], "sample_1001": [true], "sample_1002": [false], "sample_1003": [false], "sample_1004": [false], "sample_1005": [true], "sample_1006": [false], "sample_1007": [false], "sample_1008": [true], "sample_1009": [false], "sample_1010": [true], "sample_1011": [false], "sample_1012": [false], "sample_1013": [true], "sample_1014": [false], "sample_1015": [false], "sample_1016": [true], "sample_1017": [true], "sample_1018": [false], "sample_1019": [false], "sample_1020": [false], "sample_1021": [false], "sample_1022": [false], "sample_1023": [false], "sample_1024": [true], "sample_1025": [false], "sample_1026": [true], "sample_1027": [false], "sample_1028": [false], "sample_1029": [true], "sample_1030": [false], "sample_1031": [false], "sample_1032": [false], "sample_1033": [true], "sample_1034": [false], "sample_1035": [false], "sample_1036": [false], "sample_1037": [false], "sample_1038": [false], "sample_1039": [false], "sample_1040": [false], "sample_1041": [false], "sample_1042": [true], "sample_1043": [false], "sample_1044": [false], "sample_1045": [false], "sample_1046": [false], "sample_1047": [false], "sample_1048": [false], "sample_1049": [false], "sample_1050": [false], "sample_1051": [false], "sample_1052": [false], "sample_1053": [false], "sample_1054": [false], "sample_1055": [false], "sample_1056": [false], "sample_1057": [false], "sample_1058": [false], "sample_1059": [false], "sample_1060": [false], "sample_1061": [true], "sample_1062": [false], "sample_1063": [true], "sample_1064": [false], "sample_1065": [false], "sample_1066": [false], "sample_1067": [false], "sample_1068": [false], "sample_1069": [true], "sample_1070": [false], "sample_1071": [false], "sample_1072": [false], "sample_1073": [false], "sample_1074": [true], "sample_1075": [true], "sample_1076": [false], "sample_1077": [false], "sample_1078": [true], "sample_1079": [false], "sample_1080": [false], "sample_1081": [false], "sample_1082": [false], "sample_1083": [false], "sample_1084": [false], "sample_1085": [false], "sample_1086": [true], "sample_1087": [true], "sample_1088": [false], "sample_1089": [true], "sample_1090": [false], "sample_1091": [false], "sample_1092": [true], "sample_1093": [false], "sample_1094": [false], "sample_1095": [false], "sample_1096": [false], "sample_1097": [false], "sample_1098": [false], "sample_1099": [false], "sample_1100": [true], "sample_1101": [false], "sample_1102": [false], "sample_1103": [false], "sample_1104": [false], "sample_1105": [false], "sample_1106": [false], "sample_1107": [false], "sample_1108": [false], "sample_1109": [false], "sample_1110": [true], "sample_1111": [false], "sample_1112": [false], "sample_1113": [false], "sample_1114": [false], "sample_1115": [false], "sample_1116": [false], "sample_1117": [true], "sample_1118": [false], "sample_1119": [false], "sample_1120": [false], "sample_1121": [true], "sample_1122": [true], "sample_1123": [false], "sample_1124": [false], "sample_1125": [false], "sample_1126": [false], "sample_1127": [false], "sample_1128": [true], "sample_1129": [false], "sample_1130": [true], "sample_1131": [false], "sample_1132": [false], "sample_1133": [false], "sample_1134": [true], "sample_1135": [true], "sample_1136": [true], "sample_1137": [false], "sample_1138": [false], "sample_1139": [false], "sample_1140": [false], "sample_1141": [false], "sample_1142": [false], "sample_1143": [false], "sample_1144": [true], "sample_1145": [false], "sample_1146": [true], "sample_1147": [true], "sample_1148": [false], "sample_1149": [false], "sample_1150": [false], "sample_1151": [false], "sample_1152": [false], "sample_1153": [false], "sample_1154": [false], "sample_1155": [false], "sample_1156": [false], "sample_1157": [false], "sample_1158": [false], "sample_1159": [false], "sample_1160": [false], "sample_1161": [true], "sample_1162": [false], "sample_1163": [false], "sample_1164": [false], "sample_1165": [false], "sample_1166": [false], "sample_1167": [true], "sample_1168": [false], "sample_1169": [false], "sample_1170": [true], "sample_1171": [false], "sample_1172": [false], "sample_1173": [false], "sample_1174": [false], "sample_1175": [false], "sample_1176": [false], "sample_1177": [true], "sample_1178": [false], "sample_1179": [true], "sample_1180": [false], "sample_1181": [false], "sample_1182": [false], "sample_1183": [true], "sample_1184": [true], "sample_1185": [false], "sample_1186": [true], "sample_1187": [false], "sample_1188": [false], "sample_1189": [true], "sample_1190": [false], "sample_1191": [false], "sample_1192": [false], "sample_1193": [false], "sample_1194": [false], "sample_1195": [false], "sample_1196": [false], "sample_1197": [false], "sample_1198": [false], "sample_1199": [false], "sample_1200": [false], "sample_1201": [false], "sample_1202": [false], "sample_1203": [false], "sample_1204": [false], "sample_1205": [false], "sample_1206": [true], "sample_1207": [false], "sample_1208": [false], "sample_1209": [false]}}